% Use only this section
%###########################################################################################
% Introduction
%###########################################################################################
@article{Fan2023EnhancingMS,
  title={Enhancing multilingual speech recognition in air traffic control by sentence-level language identification},
  author={Peng Fan and Dongyue Guo and Jianwei Zhang and Bo Yang and Yi Lin},
  journal={ArXiv},
  year={2023},
  volume={abs/2305.00170},
  url={https://api.semanticscholar.org/CorpusID:258426556}
}
@article{Ohneiser2021IntegratingEA,
  title={Integrating Eye- and Mouse-Tracking with Assistant Based Speech Recognition for Interaction at Controller Working Positions},
  author={Oliver Ohneiser and Jyothsna Adamala and Ioan-Teodor Salomea},
  journal={Aerospace},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:239250230}
}
@article{Villalobos2022MachineLM,
  title={{Machine Learning Model Sizes and the Parameter Gap}},
  author={Pablo Villalobos and Jaime Sevilla and Tamay Besiroglu and Lennart Heim and An Chang Ho and Marius Hobbhahn},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.02852},
  url={https://api.semanticscholar.org/CorpusID:250334766}
}

%###########################################################################################
% Military Relevance
%###########################################################################################

@article{Smith2020UnderstandingRA,
  title={{Understanding realistic attacks on airborne collision avoidance systems}},
  author={Matthew Smith and Martin Strohmeier and Vincent Lenders and Ivan Martinovic},
  journal={Journal of Transportation Security},
  year={2020},
  volume={15},
  pages={87 - 118},
  url={https://api.semanticscholar.org/CorpusID:222124915}
}

@article{Zdorova2021DoWR,
  title={Do we rely on good-enough processing in reading under auditory and visual noise?},
  author={Nina Zdorova and Svetlana Malyutina and Anna K. Laurinavichyute and Anastasiia Kaprielova and Anastasia Ziubanova and Anastasiya Lopukhina},
  journal={PLOS ONE},
  year={2021},
  volume={18},
  url={https://api.semanticscholar.org/CorpusID:239420488}
}

%###########################################################################################
% Literature review
%###########################################################################################
% Source of Dataset Info
@article{Wang2024EnhancingAT,
  title={{Enhancing Air Traffic Control Communication Systems with Integrated Automatic Speech Recognition: Models, Applications and Performance Evaluation}},
  author={Zhuang Wang and Peiyuan Jiang and Zixuan Wang and Boyuan Han and Haijun Liang and Yi Ai and Weijun Pan},
  journal={Sensors (Basel, Switzerland)},
  year={2024},
  volume={24},
  url={https://api.semanticscholar.org/CorpusID:271392005}
}

%atcosim
@inproceedings{hofbauer-etal-2008-atcosim,
    title = {{The {ATCOSIM} Corpus of Non-Prompted Clean Air Traffic Control Speech}},
    author = "Hofbauer, Konrad  and
      Petrik, Stefan  and
      Hering, Horst",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tapias, Daniel",
    booktitle = "Proceedings of the Sixth International Conference on Language Resources and Evaluation ({LREC}`08)",
    month = may,
    year = "2008",
    address = "Marrakech, Morocco",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L08-1507/",
    abstract = "Air traffic control (ATC) is based on voice communication between pilots and controllers and uses a highly task and domain specific language. Due to this very reason, spoken language technologies for ATC require domain-specific corpora, of which only few exist to this day. The ATCOSIM Air Traffic Control Simulation Speech corpus is a speech database of non-prompted and clean ATC operator speech. It consists of ten hours of speech data, which were recorded in typical ATC control room conditions during ATC real-time simulations. The database includes orthographic transcriptions and additional information on speakers and recording sessions. The ATCOSIM corpus is publicly available and provided online free of charge. In this paper, we first give an overview of ATC related corpora and their shortcomings. We then show the difficulties in obtaining operational ATC speech recordings and propose the use of existing ATC real-time simulations. We describe the recording, transcription, production and validation process of the ATCOSIM corpus, and outline an application example for automatic speech recognition in the ATC domain."
}

%AcListant
@inproceedings{rataj2019aclistant,
	title = {{AcListant} with {Continuous} {Learning}: {Speech} {Recognition} in {Air} {Traffic} {Control}},
    booktitle = {EIWAC 2019},
	shorttitle = {{AcListant} with {Continuous} {Learning}},
	abstract = {Increasing air traffic creates many challenges for ATM. A general answer to these challenges is to increase automation. However, communication between air traffic controllers (ATCos) and pilots is widely analog and far away from digital ATM components. As communication content is important for the ATM system, commands are entered manually by the ATCo, to enable the ATM system to react to the communication. However, the disadvantage is an additional workload of ATCos. To avoid this effort automatic speech recognition (ASR) can automatically analyze the communication and extract the content of commands. To achieve low failure rates, DLR together with Saarland University invented the AcListant® system, the first assistant based speech recognition (ABSR). AcListant® validation trials reveal also shortcomings, like problems with the costly adaptations of the recognizer to specific environments. SESAR 2020 Exploratory Research funded project MALORCA developed machine learning algorithms to automatically adapt ABSR to different airports. SESAR Industrial Research funded solution PJ 16-04 developed an ontology for ATC command transcription to enable reuse of expensive manually transcribed ATC communication. Finally, results and experiences are used in SESAR Wave-2 Solutions 96 and 97. This paper presents the evolution from AcListant® via MALORCA, PJ.16-04 to Wave-2 Solutions 96 and 97.},
	author = {Rataj, Jürgen and Helmke, Hartmut and Ohneiser, Oliver},
	month = oct,
	year = {2019},
}

%Airbus-ATCC
@article{pellegrini2018airbus,
  author       = {Thomas Pellegrini and
                  J{\'{e}}r{\^{o}}me Farinas and
                  Estelle Delpech and
                  Fran{\c{c}}ois Lancelot},
  title        = {{The Airbus Air Traffic Control speech recognition 2018 challenge:
                  towards {ATC} automatic transcription and call sign detection}},
  journal      = {CoRR},
  volume       = {abs/1810.12614},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.12614},
  eprinttype    = {arXiv},
  eprint       = {1810.12614},
  timestamp    = {Thu, 08 Nov 2018 10:57:46 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-12614.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%AWB ATCC
@article{smidl2019ATCC,
author = {Šmídl, Luboš and Švec, Jan and Tihelka, Daniel and Matoušek, Jindřich and Romportl, Jan and Ircing, Pavel},
year = {2019},
month = {02},
pages = {},
title = {{Air traffic control communication (ATCC) speech corpora and their use for ASR and TTS development}},
volume = {53},
journal = {Language Resources and Evaluation},
doi = {10.1007/s10579-019-09449-5}
}
%SESAR

%HAAWAII
@misc{helmke2023haawaii,
author = {Hartmut Helmke and Matthias Kleinert and Arthur Linß and Petr Motlicek, Hanno Wiese, Lucas Klamert and Julia Harfmann and Nuno Cebola, Hörður Arilíusson and Teodor Simiganoschi},
year = {2023},
month = {11},
pages = {},
title = {{The HAAWAII Framework for Automatic SpeechUnderstanding of Air Traffic Communication}},
}

% ATCO2
@misc{zuluaga2023atco2,
      title={{ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech Recognition and Natural Language Understanding of Air Traffic Control Communications}}, 
      author={Juan Zuluaga-Gomez and Karel Veselý and Igor Szöke and Alexander Blatt and Petr Motlicek and Martin Kocour and Mickael Rigault and Khalid Choukri and Amrutha Prasad and Seyyed Saeed Sarfjoo and Iuliia Nigmatulina and Claudia Cevenini and Pavel Kolčárek and Allan Tart and Jan Černocký and Dietrich Klakow},
      year={2023},
      eprint={2211.04054},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.04054}, 
}
% ATCSpeech
@article{yang2019atcspeech,
  author       = {Bo Yang and
                  Xianlong Tan and
                  Zhengmao Chen and
                  Bing Wang and
                  Dan Li and
                  Zhongping Yang and
                  Xiping Wu and
                  Yi Lin},
  title        = {{ATCSpeech: a multilingual pilot-controller speech corpus from real
                  Air Traffic Control environment}},
  journal      = {CoRR},
  volume       = {abs/1911.11365},
  year         = {2019},
  url          = {http://arxiv.org/abs/1911.11365},
  eprinttype    = {arXiv},
  eprint       = {1911.11365},
  timestamp    = {Tue, 03 Dec 2019 14:15:54 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1911-11365.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

%Currently Available Models
%whisper and terminologies (Radiological)
@article {Jelassi2024RevolutionizingRA,
  title={{Revolutionizing Radiological Analysis: The Future of French Language Automatic Speech Recognition in Healthcare}},
  author={Mariem Jelassi and Oumaima Jemai and Jacques Demongeot},
  journal={Diagnostics},
  year={2024},
  volume={14},
  url={https://api.semanticscholar.org/CorpusID:269421510}
}
%Terminologies in ATC
@article{Chen2023EffectsOL,
  title={{Effects of Language Ontology on Transatlantic Automatic Speech Understanding Research Collaboration in the Air Traffic Management Domain}},
  author={Shuo Chen and Hartmut Helmke and Robert M. Tarakan and Oliver Ohneiser and Hunter D. Kopald and Matthias Kleinert},
  journal={Aerospace},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259053606}
}
% ATC Terminologies
@article{Ahrenhold2023ValidatingAS,
  title={{Validating Automatic Speech Recognition and Understanding for Pre-Filling Radar Labels—Increasing Safety While Reducing Air Traffic Controllers’ Workload}},
  author={Nils Ahrenhold and Hartmut Helmke and Thorsten M{\"u}hlhausen and Oliver Ohneiser and Matthias Kleinert and Heiko Ehr and Lucas Klamert and Juan Pablo Zuluaga},
  journal={Aerospace},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259115093}
}

%jlvdoorn
@article{jlvdoorn2024WhisperATC,
    author = {van Doorn, Jan and Sun, Junzi and Hoekstra, J.M. and Jonk, Patrick and de Vries, Vincent},
    title = {{Whisper-ATC Open Models for Air Traffic Control Automatic Speech Recognition with Accuracy}},
    journal = {ICRAT},
    year = {2024}
}

%jlvdoorn model
@misc {wlv3-atco2-asr-atcosim,
  author       = { {J.L.P.M. van Doorn} },
  title        = { whisper-large-v3-atco2-asr-atcosim },
  year         = 2023,
  url          = { https://huggingface.co/jlvdoorn/whisper-large-v3-atco2-asr-atcosim },
  doi          = { 10.57967/hf/1388 },
  publisher    = { Hugging Face }
},

% Noise
@article{Lin2021SpokenIU,
  title={{Spoken Instruction Understanding in Air Traffic Control: Challenge, Technique, and Application}},
  author={Yi Lin},
  journal={Aerospace},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:233789045}
}
% Noise in ATC
@article{Zuluaga2023LessonsLI,
  title={{Lessons Learned in Transcribing 5000 h of Air Traffic Control Communications for Robust Automatic Speech Understanding}},
  author={Juan Pablo Zuluaga and Iuliia Nigmatulina and Amrutha Prasad and Petr Motl{\'i}cek and Driss Khalil and Srikanth R. Madikeri and Allan Tart and Igor Szoke and Vincent Lenders and Mickael Rigault and Khalid Choukri},
  journal={Aerospace},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:264391192}
}

%WER
@article{Kheddar2023DeepTL,
  title={Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization},
  author={Hamza Kheddar and Yassine Himeur and Somaya Ali Al-Maadeed and Abbes Amira and Fayçal Bensaali},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.14535},
  url={https://api.semanticscholar.org/CorpusID:258418066}
}

% Speech Echo
@article{Yu2023ROSEAR,
  title={{ROSE: A Recognition-Oriented Speech Enhancement Framework in Air Traffic Control Using Multi-Objective Learning}},
  author={Xincheng Yu and Dongyue Guo and Jianwei Zhang and Yi Lin},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2023},
  volume={32},
  pages={3365-3378},
  url={https://api.semanticscholar.org/CorpusID:266162865}
}

% Speech enhancement errors
@inproceedings{Iwamoto2022HowBA,
  title={{How Bad Are Artifacts?: Analyzing the Impact of Speech Enhancement Errors on ASR}},
  author={Kazuma Iwamoto and Tsubasa Ochiai and Marc Delcroix and Rintaro Ikeshita and Hiroshi Sato and Shoko Araki and Shigeru Katagiri},
  booktitle={Interspeech},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:246015341}
}
% Training using different Accents
@article{Prabhu2023AccentedSR,
  title={{Accented Speech Recognition With Accent-specific Codebooks}},
  author={Darshan Prabhu and Preethi Jyothi and Sriram Ganapathy and Vinit Unni},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.15970},
  url={https://api.semanticscholar.org/CorpusID:264439549}
}
% A study found that the recognition accuracy of the Whisper-based ATC speech recognition model is lower when the control area is different from the training data%
@article{Pan2024AssessmentAA,
  title={Assessment and analysis of accents in air traffic control speech: a fusion of deep learning and information theory},
  author={Weijun Pan and Jian Zhang and Yumei Zhang and Peiyuan Jiang and Shuai Han},
  journal={Frontiers in Neurorobotics},
  year={2024},
  volume={18},
  url={https://api.semanticscholar.org/CorpusID:268533437}
}
% Semi supervised Model 
@incollection{karpov_semi-supervised_2018,
	address = {Cham},
	title = {{Semi-{Supervised} {Training} of {DNN}-{Based} {Acoustic} {Model} for {ATC} {Speech} {Recognition}}},
	volume = {11096},
	isbn = {978-3-319-99578-6 978-3-319-99579-3},
	url = {http://link.springer.com/10.1007/978-3-319-99579-3_66},
	urldate = {2024-11-19},
	booktitle = {Speech and {Computer}},
	publisher = {Springer International Publishing},
	author = {Šmídl, Luboš and Švec, Jan and Pražák, Aleš and Trmal, Jan},
	editor = {Karpov, Alexey and Jokisch, Oliver and Potapova, Rodmonga},
	year = {2018},
	doi = {10.1007/978-3-319-99579-3_66},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {646--655},
}

% Accents on ASR
@article{Graham2024EvaluatingOW,
    author = {Graham, Calbert and Roll, Nathan},
    title = {{Evaluating OpenAI's Whisper ASR: Performance analysis across diverse accents and speaker traits}},
    journal = {JASA Express Letters},
    volume = {4},
    number = {2},
    pages = {025206},
    year = {2024},
    month = {02},
    abstract = {This study investigates Whisper's automatic speech recognition (ASR) system performance across diverse native and non-native English accents. Results reveal superior recognition in American compared to British and Australian English accents with similar performance in Canadian English. Overall, native English accents demonstrate higher accuracy than non-native accents. Exploring connections between speaker traits [sex, native language (L1) typology, and second language (L2) proficiency] and word error rate uncovers notable associations. Furthermore, Whisper exhibits enhanced performance in read speech over conversational speech with modifications based on speaker gender. The implications of these findings are discussed.},
    issn = {2691-1191},
    doi = {10.1121/10.0024876},
    url = {https://doi.org/10.1121/10.0024876},
    eprint = {https://pubs.aip.org/asa/jel/article-pdf/doi/10.1121/10.0024876/19692982/025206\_1\_10.0024876.pdf},
}

% Accents in ATC
@article{pan2024assessment,
  title={Assessment and analysis of accents in air traffic control speech: a fusion of deep learning and information theory},
  author={Pan, Weijun and Zhang, Jian and Zhang, Yumei and Jiang, Peiyuan and Han, Shuai},
  journal={Frontiers in neurorobotics},
  volume={18},
  pages={1360094},
  year={2024},
  publisher={Frontiers Media SA}
}\

% Same geography may not have same accent but share same accent features
@article{Xie2024FromFE,
  title={From first encounters to longitudinal exposure: a repeated exposure-test paradigm for monitoring speech adaptation},
  author={Xin Xie and Chigusa Kurumada},
  journal={Frontiers in Psychology},
  year={2024},
  volume={15},
  url={https://api.semanticscholar.org/CorpusID:270165369}
}
% Accent in military
@article{Romanov2021TheUM,
  title={The U.S. military culture system of values mirrored by professional lingo},
  author={Alexander S. Romanov and Sergey A. Stepanov and Marina Vladimirovna Poluboyarova and Mariya Angaleva and Natalya Belaya},
  journal={SHS Web of Conferences},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235836591}
}
% Democratizing ASR
@article{Sanabria2023TheEI,
  title={{The Edinburgh International Accents of English Corpus: Towards the Democratization of English ASR}},
  author={Ramon Sanabria and Nikolay Bogoychev and Nina Markl and Andrea Carmantini and Ondrej Klejch and Peter Bell},
  journal={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2023},
  pages={1-5},
  url={https://api.semanticscholar.org/CorpusID:257901049}
}
% Self Supervised Accent Adaptation
@article{Deng2021ImprovingAI,
  title={{Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-supervised Learning}},
  author={Keqi Deng and Songjun Cao and Long Ma},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.07349},
  url={https://api.semanticscholar.org/CorpusID:237513397}
}

% Military limitations %
% Speed Accuracy tradeoff Villalobos

% Speed Accuracy tradeoff
@article{ivanov_speed_nodate,
	title = {Speed vs. {Accuracy}: {Designing} an {Optimal} {ASR} {System} for {Spontaneous} {Non}-{Native} {Speech} in a {Real}-{Time} {Application}},
	abstract = {Automatic dialog interaction with remote interlocutors is a difﬁcult application area for speech recognition technology because of the limited acoustic context, poor signal representation, high variability of spontaneous speech and limited time available to do the recognition of noncanonical spoken production. We present the speech recognition system for the non-native dialog applications that we are currently developing. We ﬁnd that our system broadly matches human performance; that minimum Bayes risk decoding improves accuracy, and that the posterior probabilities have good power towards predicting errors. We also explore the temporal distribution of errors made by the recognizer with online speaker adaptation, the frequency of errors among auto-semantic and function words, as well as the distribution of error rates among the heterogeneous speaker population. Our ﬁndings motivate further development directions for dialog speech recognition systems.},
	language = {en},
	author = {Ivanov, Alexei V and Lange, Patrick L and Suendermann-Oeft, David and Qian, Yao and Yu, Zhou and Tao, Jidong},
    year = {2015},
    journal = {IWSDS2016},
}

% Whisper Size
@article{Li2024SONARAS,
  title={{SONAR: A Synthetic AI-Audio Detection Framework and Benchmark}},
  author={Xiang Li and Pin-Yu Chen and Wenqi Wei},
  journal={ArXiv},
  year={2024},
  volume={abs/2410.04324},
  url={https://api.semanticscholar.org/CorpusID:273185714}
}

% Cloud Implementations
@article{Abel2021DeploymentOI,
  title={Deployment of internet of things-based cloudlet-cloud for surveillance operations},
  author={Edje E. Abel and Abd Latiff Muhammad Shafie and Weng Howe Chan},
  journal={IAES International Journal of Artificial Intelligence},
  year={2021},
  volume={10},
  pages={24-34},
  url={https://api.semanticscholar.org/CorpusID:229420405}
}
% IOT Implementations
@article{HS2024HybridAU,
  title={{Hybrid Approach Using Machine Learning and IOT for Soldier Rescue : A Review}},
  author={Harshitha H S and J Nagaraja},
  journal={International Journal of Innovative Science and Research Technology (IJISRT)},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:270991642}
}
% Compute Required %Security Limitations
@article{Rashid2023ArtificialII,
  title={{Artificial Intelligence in the Military: An Overview of the Capabilities, Applications, and Challenges}},
  author={Adib Bin Rashid and Ashfakul Karim Kausik and Ahamed Al Hassan Sunny and Mehedy Hasan Bappy},
  journal={Int. J. Intell. Syst.},
  year={2023},
  volume={2023},
  pages={1-31},
  url={https://api.semanticscholar.org/CorpusID:265200275}
}
% Research Objectives

@article{Lu2023SecurityAP,
  title={{Security and Privacy of Internet of Things: A Review of Challenges and Solutions}},
  author={Yujing Lu},
  journal={J. Cyber Secur. Mobil.},
  year={2023},
  volume={12},
  pages={813-844},
  url={https://api.semanticscholar.org/CorpusID:265287997}
}

% Methodology%

%Whisper
@misc{RadfordWhisper2022,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford,  Alec and Kim,  Jong Wook and Xu,  Tao and Brockman,  Greg and McLeavey,  Christine and Sutskever,  Ilya},
  keywords = {Audio and Speech Processing (eess.AS),  Computation and Language (cs.CL),  Machine Learning (cs.LG),  Sound (cs.SD),  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Electrical engineering,  electronic engineering,  information engineering,  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {{Robust Speech Recognition via Large-Scale Weak Supervision}},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

%ATC Controllers
@article{Zaballos2016-ue,
  title    = "Air traffic controllers' long-term speech-in-noise training
              effects: A control group study",
  author   = "Zaballos, Maria T P and Plasencia, Daniel P and Gonz{\'a}lez,
              Mar{\'\i}a L Z and de Miguel, Angel R and Mac{\'\i}as, {\'A}ngel
              R",
  abstract = "INTRODUCTION: Speech perception in noise relies on the capacity
              of the auditory system to process complex sounds using sensory
              and cognitive skills. The possibility that these can be trained
              during adulthood is of special interest in auditory disorders,
              where speech in noise perception becomes compromised. Air traffic
              controllers (ATC) are constantly exposed to radio communication,
              a situation that seems to produce auditory learning. The
              objective of this study has been to quantify this effect.
              SUBJECTS AND METHODS: 19 ATC and 19 normal hearing individuals
              underwent a speech in noise test with three signal to noise
              ratios: 5, 0 and -5 dB. Noise and speech were presented through
              two different loudspeakers in azimuth position. Speech tokes were
              presented at 65 dB SPL, while white noise files were at 60, 65
              and 70 dB respectively. RESULTS: Air traffic controllers
              outperform the control group in all conditions [P<0.05 in ANOVA
              and Mann-Whitney U tests]. Group differences were largest in the
              most difficult condition, SNR=-5 dB. However, no correlation
              between experience and performance were found for any of the
              conditions tested. The reason might be that ceiling performance
              is achieved much faster than the minimum experience time
              recorded, 5 years, although intrinsic cognitive abilities cannot
              be disregarded. DISCUSSION: ATC demonstrated enhanced ability to
              hear speech in challenging listening environments. This study
              provides evidence that long-term auditory training is indeed
              useful in achieving better speech-in-noise understanding even in
              adverse conditions, although good cognitive qualities are likely
              to be a basic requirement for this training to be effective.
              CONCLUSION: Our results show that ATC outperform the control
              group in all conditions. Thus, this study provides evidence that
              long-term auditory training is indeed useful in achieving better
              speech-in-noise understanding even in adverse conditions.",
  journal  = "Noise Health",
  volume   =  18,
  number   =  85,
  pages    = "376--381",
  month    =  nov,
  year     =  2016,
  language = "en"
}

%Garbageingarbageout
@inproceedings{Geiger_2020, series={FAT* ’20},
   title={{Garbage in, garbage out?: do machine learning application papers in social computing report where human-labeled training data comes from?}},
   url={http://dx.doi.org/10.1145/3351095.3372862},
   DOI={10.1145/3351095.3372862},
   booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
   publisher={ACM},
   author={Geiger, R. Stuart and Yu, Kevin and Yang, Yanlai and Dai, Mindy and Qiu, Jie and Tang, Rebekah and Huang, Jenny},
   year={2020},
   month=jan, pages={325–336},
   collection={FAT* ’20} }

@inproceedings{Librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={{Librispeech: An ASR corpus based on public domain audio books}}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  keywords={Resource description framework;Genomics;Bioinformatics;Blogs;Information services;Electronic publishing;Speech Recognition;Corpus;LibriVox},
  doi={10.1109/ICASSP.2015.7178964}}

%Preprocessing
@article{sainburg2020finding,
  title={Finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires},
  author={Sainburg, Tim and Thielk, Marvin and Gentner, Timothy Q},
  journal={PLoS computational biology},
  volume={16},
  number={10},
  pages={e1008228},
  year={2020},
  publisher={Public Library of Science}
}

@software{tim_sainburg_2019_3243139,
  author       = {Tim Sainburg},
  title        = {timsainb/noisereduce: v1.0},
  month        = jun,
  year         = 2019,
  publisher    = {Zenodo},
  version      = {db94fe2},
  doi          = {10.5281/zenodo.3243139},
  url          = {https://doi.org/10.5281/zenodo.3243139}
}

% Domain Learning for accents
@article{Maison2023ImprovingAS,
  title={{Improving Accented Speech Recognition with Multi-Domain Training}},
  author={Lucas Maison and Y. Est{\`e}ve},
  journal={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2023},
  pages={1-5},
  url={https://api.semanticscholar.org/CorpusID:257505352}
}

%% Managing the non-linearity of the signal using Tanh Augs
@misc{Gardner2022ContinuousGW,
  title={Continuous gravitational waves in the lab: recovering audio signals with a table-top optical microphone},
  author={James W. Gardner and Hannah Middleton and Changrong Liu and Andrew Melatos and Robin J. Evans and William Moran and Deeksha Beniwal and Huy Tuong Cao and Craig Ingram and Daniel Brown and Sebastian W. S. Ng},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:245853636}
}

% Reduction of Noise in Single Channel EMG
@article{Boyer2023ReducingNA,
  title={{Reducing Noise, Artifacts and Interference in Single-Channel EMG Signals: A Review}},
  author={Marianne Boyer and Laurent J. Bouyer and J. S. Roy and Alexandre Campeau-Lecours},
  journal={Sensors (Basel, Switzerland)},
  year={2023},
  volume={23},
  url={https://api.semanticscholar.org/CorpusID:257481291}
}


% phraseology 
@inproceedings{Alharasees2023Misunderstandings,
  title={{Misunderstandings in Aviation Communication}},
  author={Alharasees, Omar and Jazzar, Abeer and Kale, Utku},
  booktitle={Advances in Electric Aviation},
  pages={131--138},
  year={2023},
  publisher={Springer},
  doi={10.1007/978-3-031-32639-4_18},
  url={https://link.springer.com/chapter/10.1007/978-3-031-32639-4_18}
}


%audio normalization
@inproceedings{Kowalski2022Normalization,
  title={Normalization of audio signals for the needs of machine learning},
  author={Kowalski, Mateusz and Kaczmarek, Piotr and Kostek, Bozena},
  booktitle={2022 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)},
  pages={1--6},
  year={2022},
  organization={IEEE},
  doi={10.1109/SPA53837.2022.10372705},
  url={https://ieeexplore.ieee.org/document/10372705}
}
%wer for atc

@inproceedings{Faria2022Switchboard,
  title={{Toward Zero Oracle Word Error Rate on the Switchboard Benchmark}},
  author={Faria, Arlo and Janin, Adam and Adkoli, Sidhi and Riedhammer, Korbinian},
  booktitle={Interspeech 2022},
  publisher={ISCA},
  year={2022},
  month=sep,
  pages={3973--3977},
  doi={10.21437/interspeech.2022-10959},
  url={http://dx.doi.org/10.21437/interspeech.2022-10959}
}
@inproceedings{Zuluaga2020ATC,
  title={{Automatic Speech Recognition Benchmark for Air-Traffic Communications}},
  author={Zuluaga-Gomez, Juan and Motlicek, Petr and Zhan, Qingran and Vesel{\'y}, Karel and Braun, Rudolf},
  booktitle={Interspeech 2020},
  publisher={ISCA},
  year={2020},
  month=oct,
  pages={2297--2301},
  doi={10.21437/interspeech.2020-2173},
  url={http://dx.doi.org/10.21437/interspeech.2020-2173}
}

@inproceedings{Munteanu2006Measuring,
  title={Measuring the acceptable word error rate of machine-generated webcast transcripts},
  author={Munteanu, Cosmin and Penn, Gerald and Baecker, Ron and Toms, Elaine and James, David},
  booktitle={Interspeech 2006},
  publisher={ISCA},
  year={2006},
  month=sep,
  pages={1756--Mon1CaP.2-0},
  doi={10.21437/interspeech.2006-40},
  url={http://dx.doi.org/10.21437/interspeech.2006-40}
}

@techreport{Fish2006WER,
  author={Fish, Randall and Hu, Qian and Boykin, Stanley},
  title={{Using Audio Quality to Predict Word Error Rate in an Automatic Speech Recognition System}},
  institution={The MITRE Corporation},
  year={2006},
  type={Technical Report},
  url={https://www.mitre.org/sites/default/files/pdf/06_1154.pdf}
}

%whisper prompting
@article{Yang2024Do,
  title={{Do Prompts Really Prompt? Exploring the Prompt Understanding Capability of Whisper}},
  author={Yang, Chih-Kai and Huang, Kuan-Po and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2406.05806},
  year={2024},
  url={https://arxiv.org/abs/2406.05806}
}

%model result explanation
@article{Ircing2019ATCC,
  title = {Air traffic control communication (ATCC) speech corpora and their use for ASR and TTS development},
  author = {Ircing, Pavel and Tihelka, Daniel},
  journal = {Language Resources and Evaluation},
  volume = {53},
  pages = {601--621},
  year = {2019},
  publisher = {Springer},
  doi = {10.1007/s10579-019-09449-5},
  url = {https://link.springer.com/article/10.1007/s10579-019-09449-5}
}

@article{Wang2024ASR,
  title = {{Enhancing Air Traffic Control Communication Systems with Integrated Automatic Speech Recognition: Models, Applications and Performance Evaluation}},
  author = {Wang, Zhuang and Jiang, Peiyuan and Wang, Zixuan and Han, Boyuan and Liang, Haijun and Ai, Yi and Pan, Weijun},
  journal = {Sensors},
  volume = {24},
  number = {14},
  pages = {4715},
  year = {2024},
  publisher = {MDPI},
  doi = {10.3390/s24144715},
  url = {https://www.mdpi.com/1424-8220/24/14/4715}
}

@article{Zuluaga_Gomez_2023,
  title = {{Lessons Learned in Transcribing 5000 h of Air Traffic Control Communications for Robust Automatic Speech Understanding}},
  author = {Zuluaga-Gomez, Juan and Nigmatulina, Iuliia and Prasad, Amrutha and Motlicek, Petr and Khalil, Driss and Madikeri, Srikanth and Tart, Allan and Szoke, Igor and Lenders, Vincent and Rigault, Mickael and Choukri, Khalid},
  journal = {Aerospace},
  volume = {10},
  number = {10},
  pages = {898},
  year = {2023},
  month = {oct},
  publisher = {MDPI AG},
  issn = {2226-4310},
  doi = {10.3390/aerospace10100898},
  url = {http://dx.doi.org/10.3390/aerospace10100898}
}

@manual{FAA2025Glossary,
  title = {Pilot/Controller Glossary},
  author = {{Federal Aviation Administration (FAA)}},
  year = {2025},
  url = {https://www.faa.gov/air_traffic/publications/atpubs/pcg_html/},
  note = {Accessed: January 8, 2025}
}
% Noise reducer

@manual{ICAO2018Standardization,
  title = {Manual of Radiotelephony},
  author = {{International Civil Aviation Organization (ICAO)}},
  year = {2018},
  url = {https://skybrary.aero/sites/default/files/bookshelf/115.pdf},
  note = {Accessed: January 8, 2025}
}



%tactical computing
@inproceedings{Im2019Optimization,
  title = {Optimization Problems with Low SWAP Tactical Computing},
  author = {Im, Mee Seong and Dasari, Venkateswara R. and Beshaj, Lubjana and Shires, Dale R.},
  editor = {Blowers, Misty and Hall, Russell D. and Dasari, Venkateswara R.},
  booktitle = {Disruptive Technologies in Information Sciences II},
  publisher = {SPIE},
  year = {2019},
  month = {may},
  pages = {14},
  doi = {10.1117/12.2518917},
  url = {http://dx.doi.org/10.1117/12.2518917}
}

@article{Dasari2019Complexity,
  title = {Complexity and Mission Computability of Adaptive Computing Systems},
  author = {Dasari, Venkat R. and Im, Mee Seong and Geerhart, Billy},
  journal = {The Journal of Defense Modeling and Simulation: Applications, Methodology, Technology},
  volume = {19},
  number = {1},
  pages = {5--11},
  year = {2019},
  month = {sep},
  publisher = {SAGE Publications},
  issn = {1557-380X},
  doi = {10.1177/1548512919869567},
  url = {http://dx.doi.org/10.1177}
}

% End of Use this Section
% introduction
@techreport{zeek1949investigation,
    author = {Zeek, R. W.},
    title = {{Investigation and Analysis of "Capture Effect" in F-M and A-M Communication Systems}},
    institution = {Naval Research Laboratory, Washington, DC},
    year = {1949}
}

% % This is also part of problems
@inproceedings{fritz2024analyzing,
  title={{Analyzing the Impact of HF-Specific Signal Degradation on Automatic Speech Recognition}},
  author={Fritz, Fabian and Cornaggia-Urrigshardt, Alessia and Henneke, Lukas and Kurth, Frank and Wilkinghoff, Kevin},
  booktitle={2024 International Conference on Military Communication and Information Systems (ICMCIS)},
  pages={1--10},
  year={2024},
  organization={IEEE}
}

@article{dichristofano2022global,
  title={{Global performance disparities between English-language accents in automatic speech recognition}},
  author={DiChristofano, Alex and Shuster, Henry and Chandra, Shefali and Patwari, Neal},
  journal={arXiv preprint arXiv:2208.01157},
  year={2022}
}

@inproceedings{jahchan2021towards,
  title={{Towards an Accent-Robust Approach for ATC Communications Transcription.}},
  author={Jahchan, Nataly and Barbier, Florentin and Gita, Ariyanidevi Dharma and Khelif, Khaled and Delpech, Estelle},
  booktitle={Interspeech},
  pages={3281--3285},
  year={2021}
}


% workload
@article{xu2023analyzing,
  title={{Analyzing Multi-Mode Fatigue Information from Speech and Gaze Data from Air Traffic Controllers}},
  author={Xu, Lin and Ma, Shanxiu and Shen, Zhiyuan and Huang, Shiyu and Nan, Ying},
  journal={Aerospace},
  volume={11},
  number={1},
  pages={15},
  year={2023},
  publisher={MDPI}
}


% prior work: datasets
@inproceedings{hofbauer2008atcosim,
  title={{The ATCOSIM Corpus of Non-Prompted Clean Air Traffic Control Speech}},
  author={Hofbauer, Konrad and Petrik, Stefan and Hering, Horst},
  booktitle={LREC},
  year={2008},
  organization={Citeseer}
}

@article{vsmidl2019air,
  title={{Air traffic control communication (ATCC) speech corpora and their use for ASR and TTS development}},
  author={{\v{S}}m{\'\i}dl, Lubo{\v{s}} and {\v{S}}vec, Jan and Tihelka, Daniel and Matou{\v{s}}ek, Jind{\v{r}}ich and Romportl, Jan and Ircing, Pavel},
  journal={Language Resources and Evaluation},
  volume={53},
  pages={449--464},
  year={2019},
  publisher={Springer}
}



% military

@misc{vinson_towards_2024,
	title = {Towards {Sustainable} {Workplace} {Mental} {Health}: {A} {Novel} {Approach} to {Early} {Intervention} and {Support}},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	shorttitle = {Towards {Sustainable} {Workplace} {Mental} {Health}},
	url = {https://arxiv.org/abs/2402.01592},
	doi = {10.48550/ARXIV.2402.01592},
	abstract = {Employee well-being is a critical concern in the contemporary workplace, as highlighted by the American Psychological Association's 2021 report, indicating that 71\% of employees experience stress or tension. This stress contributes significantly to workplace attrition and absenteeism, with 61\% of attrition and 16\% of sick days attributed to poor mental health. A major challenge for employers is that employees often remain unaware of their mental health issues until they reach a crisis point, resulting in limited utilization of corporate well-being benefits. This research addresses this challenge by presenting a groundbreaking stress detection algorithm that provides real-time support preemptively. Leveraging automated chatbot technology, the algorithm objectively measures mental health levels by analyzing chat conversations, offering personalized treatment suggestions in real-time based on linguistic biomarkers. The study explores the feasibility of integrating these innovations into practical learning applications within real-world contexts and introduces a chatbot-style system integrated into the broader employee experience platform. This platform, encompassing various features, aims to enhance overall employee well-being, detect stress in real time, and proactively engage with individuals to improve support effectiveness, demonstrating a 22\% increase when assistance is provided early. Overall, the study emphasizes the importance of fostering a supportive workplace environment for employees' mental health.},
	urldate = {2024-11-25},
	publisher = {arXiv},
	author = {Vinson, David W. and Arcan, Mihael and Niland, David-Paul and Delahunty, Fionn},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences},
}

@article{chyan_hybrid_2023,
	title = {Hybrid {Deep} {Learning} {Approach} {For} {Stress} {Detection} {Model} {Through} {Speech} {Signal}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by-sa/4.0},
	issn = {2549-9904, 2549-9610},
	url = {http://joiv.org/index.php/joiv/article/view/2026},
	doi = {10.30630/joiv.7.4.2026},
	abstract = {Stress is a psychological condition that requires proper treatment due to its potential long-term effects on health and cognitive faculties. This is particularly pertinent when considering pre- and early-school-age children, where stress can yield a range of adverse effects. Furthermore, detection in children requires a particular approach different from adults because of their physical and cognitive limitations. Traditional approaches, such as psychological assessments or the measurement of biosignal parameters prove ineffective in this context. Speech is also one of the approaches used to detect stress without causing discomfort to the subject and does not require prerequisites for a certain level of cognitive ability. Therefore, this study introduced a hybrid deep learning approach using supervised and unsupervised learning in a stress detection model. The model predicted the stress state of the subject and provided positional data point analysis in the form of a cluster map to obtain information on the degree using CNN and GSOM algorithms. The results showed an average accuracy and F1 score of 94.7\% and 95\%, using the children's voice dataset. To compare with the state-of-the-art, model were tested with the open-source DAIC Woz dataset and obtained average accuracy and F1 scores of 89\% and 88\%. The cluster map generated by GSOM further underscored the discerning capability in identifying stress and quantifying the degree experienced by the subjects, based on their speech patterns},
	number = {4},
	urldate = {2024-11-25},
	journal = {JOIV : International Journal on Informatics Visualization},
	author = {Chyan, Phie and Achmad, Andani and Nurtanio, Ingrid and Areni, Intan Sari},
	month = dec,
	year = {2023},
	pages = {2474},
}

% % Cognitive superiority
@article{helmke_automatic_nodate,
	title = {Automatic {Speech} {Recognition} and {Understanding} for {Radar} {Label} {Maintenance} {Support} {Increases} {Safety} and {Reduces} {Air} {Traffic} {Controllers}’ {Workload}},
	abstract = {Air traffic controllers (ATCos) from Austro Control together with DLR quantified the benefits of automatic speech recognition and understanding (ASRU) on workload and flight safety. As the baseline procedure, ATCos enter all clearances manually (by mouse) into the aircraft radar labels. As part of our proposed solution, the ATCos are supported by ASRU, which is capable of delivering the required inputs automatically. The ATCos are only prompted to make corrections, when ASRU provided incorrect output. Overall amount of time required for manually inserting clearances, i.e., by clicking and selecting the correct input on the screen, reduced from 12,800 seconds during 14 hours of simulations time down to 405 seconds, when ATCos were supported by ASRU. A reduction of radar label maintenance time through ASRU might not be surprising given earlier experiments. However, a factor greater than 30 outperforms earlier findings. In addition, this paper also considers safety aspects, i.e., how often ATCos support provided an incorrect input into the aircraft radar labels with and without ASRU. This paper shows that ASRU systems based on artificial intelligence are reliable enough for their integration into air traffic control operations rooms.},
	language = {en},
	author = {Helmke, Hartmut and Kleinert, Matthias and Ahrenhold, Nils and Ehr, Heiko and Mühlhausen, Thorsten and Ohneiser, Oliver and Klamert, Lucas and Motlicek, Petr and Prasad, Amrutha and Zuluaga-Gomez, Juan and Dokic, Jelena and Chauvin, Ella Pinska},
    journal = {ATM2023},
    year = {2023},
}

@inproceedings{nigmatulina_two-step_2022,
	address = {Singapore, Singapore},
	title = {A {Two}-{Step} {Approach} to {Leverage} {Contextual} {Data}: {Speech} {Recognition} in {Air}-{Traffic} {Communications}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66540-540-9},
	shorttitle = {A {Two}-{Step} {Approach} to {Leverage} {Contextual} {Data}},
	url = {https://ieeexplore.ieee.org/document/9746563/},
	doi = {10.1109/ICASSP43922.2022.9746563},
	urldate = {2024-11-25},
	booktitle = {{ICASSP} 2022 - 2022 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Nigmatulina, Iuliia and Zuluaga-Gomez, Juan and Prasad, Amrutha and Saeed Sarfjoo, Seyyed and Motlicek, Petr},
	month = may,
	year = {2022},
	pages = {6282--6286},
}


@article{yang_natural_2023,
	title = {Natural {Language} {Processing} ({NLP}) in {Aviation} {Safety}: {Systematic} {Review} of {Research} and {Outlook} into the {Future}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2226-4310},
	shorttitle = {Natural {Language} {Processing} ({NLP}) in {Aviation} {Safety}},
	url = {https://www.mdpi.com/2226-4310/10/7/600},
	doi = {10.3390/aerospace10070600},
	abstract = {Advanced digital data-driven applications have evolved and significantly impacted the transportation sector in recent years. This systematic review examines natural language processing (NLP) approaches applied to aviation safety-related domains. The authors use Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) to conduct this review, and three databases (Web of Science, Scopus, and Transportation Research International Documentation) are screened. Academic articles from the period 2010–2022 are reviewed after applying two rounds of filtering criteria. The sub-domains, including aviation incident/accident reports analysis and air traffic control (ATC) communications, are investigated. The specific NLP approaches, related machine learning algorithms, additional causality models, and the corresponding performance are identified and summarized. In addition, the challenges and limitations of current NLP applications in aviation, such as ambiguity, limited training data, lack of multilingual support, are discussed. Finally, this review uncovers future opportunities to leverage NLP models to facilitate the safety and efficiency of the aviation system.},
	language = {en},
	number = {7},
	urldate = {2024-11-25},
	journal = {Aerospace},
	author = {Yang, Chuyang and Huang, Chenyu},
	month = jun,
	year = {2023},
	pages = {600},
}

@inproceedings{ling_adapting_2024,
	address = {Seoul, Korea, Republic of},
	title = {Adapting {Large} {Language} {Model} with {Speech} for {Fully} {Formatted} {End}-to-{End} {Speech} {Recognition}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350344851},
	url = {https://ieeexplore.ieee.org/document/10448204/},
	doi = {10.1109/ICASSP48485.2024.10448204},
	urldate = {2024-11-25},
	booktitle = {{ICASSP} 2024 - 2024 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Ling, Shaoshi and Hu, Yuxuan and Qian, Shuangbei and Ye, Guoli and Qian, Yao and Gong, Yifan and Lin, Ed and Zeng, Michael},
	month = apr,
	year = {2024},
	pages = {11046--11050},
}

@misc{adedeji_sound_2024,
	title = {The {Sound} of {Healthcare}: {Improving} {Medical} {Transcription} {ASR} {Accuracy} with {Large} {Language} {Models}},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {The {Sound} of {Healthcare}},
	url = {https://arxiv.org/abs/2402.07658},
	doi = {10.48550/ARXIV.2402.07658},
	abstract = {In the rapidly evolving landscape of medical documentation, transcribing clinical dialogues accurately is increasingly paramount. This study explores the potential of Large Language Models (LLMs) to enhance the accuracy of Automatic Speech Recognition (ASR) systems in medical transcription. Utilizing the PriMock57 dataset, which encompasses a diverse range of primary care consultations, we apply advanced LLMs to refine ASR-generated transcripts. Our research is multifaceted, focusing on improvements in general Word Error Rate (WER), Medical Concept WER (MC-WER) for the accurate transcription of essential medical terms, and speaker diarization accuracy. Additionally, we assess the role of LLM post-processing in improving semantic textual similarity, thereby preserving the contextual integrity of clinical dialogues. Through a series of experiments, we compare the efficacy of zero-shot and Chain-of-Thought (CoT) prompting techniques in enhancing diarization and correction accuracy. Our findings demonstrate that LLMs, particularly through CoT prompting, not only improve the diarization accuracy of existing ASR systems but also achieve state-of-the-art performance in this domain. This improvement extends to more accurately capturing medical concepts and enhancing the overall semantic coherence of the transcribed dialogues. These findings illustrate the dual role of LLMs in augmenting ASR outputs and independently excelling in transcription tasks, holding significant promise for transforming medical ASR systems and leading to more accurate and reliable patient records in healthcare settings.},
	urldate = {2024-11-25},
	publisher = {arXiv},
	author = {Adedeji, Ayo and Joshi, Sarita and Doohan, Brendan},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Audio and Speech Processing (eess.AS), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Sound (cs.SD)},
	annote = {Other
31 pages, 17 figures},
}

@article{pinska-chauvin_ensuring_2023,
	title = {Ensuring {Safety} for {Artificial}-{Intelligence}-{Based} {Automatic} {Speech} {Recognition} in {Air} {Traffic} {Control} {Environment}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2226-4310},
	url = {https://www.mdpi.com/2226-4310/10/11/941},
	doi = {10.3390/aerospace10110941},
	abstract = {This paper describes the safety assessment conducted in SESAR2020 project PJ.10-W2-96 ASR on automatic speech recognition (ASR) technology implemented for air traffic control (ATC) centers. ASR already now enables the automatic recognition of aircraft callsigns and various ATC commands including command types based on controller–pilot voice communications for presentation at the controller working position. The presented safety assessment process consists of defining design requirements for ASR technology application in normal, abnormal, and degraded modes of ATC operations. A total of eight functional hazards were identified based on the analysis of four use cases. The safety assessment was supported by top-down and bottom-up modelling and analysis of the causes of hazards to derive system design requirements for the purposes of mitigating the hazards. Assessment of achieving the specified design requirements was supported by evidence generated from two real-time simulations with pre-industrial ASR prototypes in approach and en-route operational environments. The simulations, focusing especially on the safety aspects of ASR application, also validated the hypotheses that ASR reduces controllers’ workload and increases situational awareness. The missing validation element, i.e., an analysis of the safety effects of ASR in ATC, is the focus of this paper. As a result of the safety assessment activities, mitigations were derived for each hazard, demonstrating that the use of ASR does not increase safety risks and is, therefore, ready for industrialization.},
	language = {en},
	number = {11},
	urldate = {2024-11-25},
	journal = {Aerospace},
	author = {Pinska-Chauvin, Ella and Helmke, Hartmut and Dokic, Jelena and Hartikainen, Petri and Ohneiser, Oliver and Lasheras, Raquel García},
	month = nov,
	year = {2023},
	pages = {941},
}

@article{lin2019real-time,
	title = {Real-time {Controlling} {Dynamics} {Sensing} in {Air} {Traffic} {System}},
	volume = {19},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/19/3/679},
	doi = {10.3390/s19030679},
	abstract = {In order to obtain real-time controlling dynamics in air traffic system, a framework is proposed to introduce and process air traffic control (ATC) speech via radiotelephony communication. An automatic speech recognition (ASR) and controlling instruction understanding (CIU)-based pipeline is designed to convert the ATC speech into ATC related elements, i.e., controlling intent and parameters. A correction procedure is also proposed to improve the reliability of the information obtained by the proposed framework. In the ASR model, acoustic model (AM), pronunciation model (PM), and phoneme- and word-based language model (LM) are proposed to unify multilingual ASR into one model. In this work, based on their tasks, the AM and PM are defined as speech recognition and machine translation problems respectively. Two-dimensional convolution and average-pooling layers are designed to solve special challenges of ASR in ATC. An encoder–decoder architecture-based neural network is proposed to translate phoneme labels into word labels, which achieves the purpose of ASR. In the CIU model, a recurrent neural network-based joint model is proposed to detect the controlling intent and label the controlling parameters, in which the two tasks are solved in one network to enhance the performance with each other based on ATC communication rules. The ATC speech is now converted into ATC related elements by the proposed ASR and CIU model. To further improve the accuracy of the sensing framework, a correction procedure is proposed to revise minor mistakes in ASR decoding results based on the flight information, such as flight plan, ADS-B. The proposed models are trained using real operating data and applied to a civil aviation airport in China to evaluate their performance. Experimental results show that the proposed framework can obtain real-time controlling dynamics with high performance, only 4\% word-error rate. Meanwhile, the decoding efficiency can also meet the requirement of real-time applications, i.e., an average 0.147 real time factor. With the proposed framework and obtained traffic dynamics, current ATC applications can be accomplished with higher accuracy. In addition, the proposed ASR pipeline has high reusability, which allows us to apply it to other controlling scenes and languages with minor changes.},
	language = {en},
	number = {3},
	urldate = {2024-11-21},
	journal = {Sensors},
	author = {Lin, Yi and Tan, Xianlong and Yang, Bo and Yang, Kai and Zhang, Jianwei and Yu, Jing},
	month = feb,
	year = {2019},
	pages = {679},
}




% prior work: transcription
@misc{torch_compile,
	title = {Accelerating {Generative} {AI} with {PyTorch} {II}: {GPT}, {Fast}},
	shorttitle = {Accelerating {Generative} {AI} with {PyTorch} {II}},
	url = {https://pytorch.org/blog/accelerating-generative-ai-2/},
	abstract = {This post is the second part of a multi-series blog focused on how to accelerate generative AI models with pure, native PyTorch. We are excited to share a breadth of newly released PyTorch performance features alongside practical examples to see how far we can push PyTorch native performance. In part one, we showed how to accelerate Segment Anything over 8x using only pure, native PyTorch. In this blog we’ll focus on LLM optimization.},
	language = {en},
	urldate = {2024-11-18},
	journal = {PyTorch},
}

@misc{systranfaster-whisper_2024,
	title = {{SYSTRAN}/faster-whisper},
	copyright = {MIT},
	url = {https://github.com/SYSTRAN/faster-whisper},
	abstract = {Faster Whisper transcription with CTranslate2},
	urldate = {2024-11-18},
	publisher = {SYSTRAN},
	month = nov,
	year = {2024},
	note = {original-date: 2023-02-11T09:17:27Z},
	keywords = {deep-learning, inference, openai, quantization, speech-recognition, speech-to-text, transformer, whisper},
}

@misc{hf_torch_compile,
	title = {Optimize inference using torch.compile()},
	url = {https://huggingface.co/docs/transformers/en/perf_torch_compile},
	abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
	urldate = {2024-11-19},
}

@book{helmke_automatic_2024,
	title = {Automatic {Speech} {Recognition} and {Understanding} in {Air} {Traffic} {Management}},
	isbn = {978-3-7258-0315-6 978-3-7258-0316-3},
	url = {https://www.mdpi.com/books/reprint/8877},
	language = {en},
	urldate = {2024-11-19},
	publisher = {MDPI},
	editor = {Helmke, Hartmut and Ohneiser, Oliver},
	month = mar,
	year = {2024},
	doi = {10.3390/books978-3-7258-0315-6},
}

@inproceedings{srinivasamurthy_semi-supervised_2017,
	title = {Semi-{Supervised} {Learning} with {Semantic} {Knowledge} {Extraction} for {Improved} {Speech} {Recognition} in {Air} {Traffic} {Control}},
	url = {https://www.isca-archive.org/interspeech_2017/srinivasamurthy17_interspeech.html},
	doi = {10.21437/Interspeech.2017-1446},
	language = {en},
	urldate = {2024-11-19},
	booktitle = {Interspeech 2017},
	publisher = {ISCA},
	author = {Srinivasamurthy, Ajay and Motlicek, Petr and Himawan, Ivan and Szaszák, György and Oualil, Youssef and Helmke, Hartmut},
	month = aug,
	year = {2017},
	pages = {2406--2410},
	file = {PDF:C\:\\Users\\MarcusW\\Zotero\\storage\\BZ2LGRUR\\Srinivasamurthy et al. - 2017 - Semi-Supervised Learning with Semantic Knowledge Extraction for Improved Speech Recognition in Air T.pdf:application/pdf},
}




@article{lin_atcspeechnet_2021,
	title = {{ATCSpeechNet}: {A} multilingual end-to-end speech recognition framework for air traffic control systems},
	volume = {112},
	issn = {15684946},
	shorttitle = {{ATCSpeechNet}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1568494621007699},
	doi = {10.1016/j.asoc.2021.107847},
	abstract = {In this paper, a multilingual end-to-end framework, called as ATCSpeechNet, is proposed to tackle the issue of translating communication speech into human-readable text in air traffic control (ATC) systems. In the proposed framework, we focus on integrating the multilingual automatic speech recognition (ASR) into one model, in which an end-to-end paradigm is developed to convert speech waveform into text directly, without any feature engineering or lexicon. In order to make up for the deficiency of the handcrafted feature engineering caused by ATC challenges, including multilingual, multi-speaker dialog and unstable speech rate, a speech representation learning (SRL) network is proposed to capture robust and discriminative speech representations from the raw wave. The self-supervised training strategy is adopted to optimize the SRL network from unlabeled data, and further to predict the speech features, i.e., wave-to-feature. An end-to-end architecture is improved to complete the ASR task, in which a grapheme-based modeling unit is applied to address the multilingual ASR issue. Facing the problem of small transcribed samples in the ATC domain, an unsupervised approach with mask prediction is applied to pre-train the backbone network of the ASR model on unlabeled data by a feature-to-feature process. Finally, by integrating the SRL with ASR, an end-to-end multilingual ASR framework is formulated in a supervised manner, which is able to translate the raw wave into text in one model, i.e., wave-to-text. Experimental results on the ATCSpeech corpus demonstrate that the proposed approach achieves a high performance with a very small labeled corpus and less resource consumption, only 4.20\% label error rate on the 58-hour transcribed corpus. Compared to the baseline model, the proposed approach obtains over 100\% relative performance improvement which can be further enhanced with the increasing of the size of the transcribed samples. It is also confirmed that the proposed SRL and training strategies make significant contributions to improve the final performance. In addition, the effectiveness of the proposed framework is also validated on common corpora (AISHELL and Librispeech). More importantly, the proposed multilingual framework not only reduces the system complexity, but also obtains higher accuracy compared to that of the independent monolingual ASR models. The proposed approach can also greatly save the cost of annotating samples, which benefits to advance the ASR technique to industrial applications. Based on the proposed framework, a real-time sensing approach is expected to be implemented to further support ATC-related applications.},
	language = {en},
	urldate = {2024-11-19},
	journal = {Applied Soft Computing},
	author = {Lin, Yi and Yang, Bo and Li, Linchao and Guo, Dongyue and Zhang, Jianwei and Chen, Hu and Zhang, Yi},
	month = nov,
	year = {2021},
	pages = {107847},
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}


@article{moon2011air,
  title={Air traffic volume and air traffic control human errors},
  author={Moon, Woo-Choon and Yoo, Kwang-Eui and Choi, Youn-Chul and others},
  journal={Journal of Transportation Technologies},
  volume={1},
  number={03},
  pages={47},
  year={2011},
  publisher={Scientific Research Publishing}
}

// Problem 


// Methodology

@inproceedings{Huang2022E2ESJ,
  title={E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR},
  author={W. Ronny Huang and Shuo-yiin Chang and David Rybach and Rohit Prabhavalkar and Tara N. Sainath and Cyril Allauzen and Cal Peyser and Zhiyun Lu},
  booktitle={Interspeech},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:248366641}
}

        //Whisper


@inproceedings{Likhomanenko2021CAPEER,
  title={CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings},
  author={Tatiana Likhomanenko and Qiantong Xu and Ronan Collobert and Gabriel Synnaeve and Alexey Rogozhnikov},
  booktitle={Neural Information Processing Systems},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235358538}
}

@article{Lee2023VIFSAE,
  title={VIFS: An End-to-End Variational Inference for Foley Sound Synthesis},
  author={Junhyeok Lee and Hyeonuk Nam and Yong-Hwa Park},
  journal={ArXiv},
  year={2023},
  volume={abs/2306.05004},
  url={https://api.semanticscholar.org/CorpusID:259108897}
}

// yz: help sort
@article{lin2021spoken,
AUTHOR = {Lin, Yi},
TITLE = {{Spoken Instruction Understanding in Air Traffic Control: Challenge, Technique, and Application}},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2226-4310/8/3/65},
ISSN = {2226-4310},
ABSTRACT = {In air traffic control (ATC), speech communication with radio transmission is the primary way to exchange information between the controller and aircrew. A wealth of contextual situational dynamics is embedded implicitly; thus, understanding the spoken instruction is particularly significant to the ATC research. In this paper, a comprehensive review related to spoken instruction understanding (SIU) in the ATC domain is provided from the perspective of the challenges, techniques, and applications. Firstly, a full pipeline is represented to achieve the SIU task, including automatic speech recognition, language understanding, and voiceprint recognition. A total of 10 technique challenges are analyzed based on the ATC task specificities. In succession, the common techniques for SIU tasks are categorized from common applications, and extensive works in the ATC domain are also reviewed. Finally, a series of future research topics are also prospected based on the corresponding challenges. The author sincerely hopes that this work is able to provide a clear technical roadmap for the SIU tasks in the ATC domain and further make contributions to the research community.},
DOI = {10.3390/aerospace8030065}
}



@inproceedings{segura2007hiwire,
  title={The HIWIRE database: A noisy and non-native English speech corpus for cockpit communication},
  author={Segura, J.C. and Ehrette, T. and Potamianos, A. and Fohr, D. and Illina, I. and Breton, P.-A. and Clot, V. and Gemello, R. and Matassoni, M. and Maragos, P.},
  booktitle={Proceedings of the 8th Annual Conference of the International Speech Communication Association (INTERSPEECH 2007)},
  pages={1493--1496},
  year={2007}
}

@misc{LDC94S14A,
  title = {Air Traffic Control Complete (ATCC)},
  year = {1994},
  publisher = {Linguistic Data Consortium},
  note = {LDC94S14A},
  url = {https://catalog.ldc.upenn.edu/LDC94S14A},
  author = {Godfrey, John J}
}

@inproceedings{kopald2013applying,
  title={Applying automatic speech recognition technology to air traffic management},
  author={Kopald, Hunter D and Chanen, Ari and Chen, Shuo and Smith, Elida C and Tarakan, Robert M},
  booktitle={2013 IEEE/AIAA 32nd Digital Avionics Systems Conference (DASC)},
  pages={6C3--1},
  year={2013},
  organization={IEEE}
}

@Inbook{Noyes2010,
    author="Noyes, Jan M. and Haas, Ellen",
    editor="Chen, Fang and Jokinen, Kristiina",
    title="Military Applications: Human Factors Aspects of Speech-Based Systems",
    bookTitle="Speech Technology: Theory and Applications",
    year="2010",
    publisher="Springer US",
    address="New York, NY",
    pages="251--270",
    isbn="978-0-387-73819-2",
    doi="10.1007/978-0-387-73819-2_13",
    url="https://doi.org/10.1007/978-0-387-73819-2_13"
}

@article{walker_redefining_2017,
	title = {Redefining the incidents to learn from: {Safety} science insights acquired on the journey from black boxes to {Flight} {Data} {Monitoring}},
	volume = {99},
	issn = {09257535},
	shorttitle = {Redefining the incidents to learn from},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925753517309086},
	doi = {10.1016/j.ssci.2017.05.010},
	language = {en},
	urldate = {2024-11-20},
	journal = {Safety Science},
	author = {Walker, Guy},
	month = nov,
	year = {2017},
	pages = {14--22},
}


@article{weinstein_opportunities_1991,
	title = {Opportunities for advanced speech processing in military computer-based systems},
	volume = {79},
	issn = {1558-2256},
	url = {https://ieeexplore.ieee.org/abstract/document/118986},
	doi = {10.1109/5.118986},
	number = {11},
	urldate = {2024-11-20},
	journal = {Proceedings of the IEEE},
	author = {Weinstein, C.J.},
	month = nov,
	year = {1991},
	keywords = {Speech processing, Management training, Natural languages, Data communication, Speech enhancement, Air traffic control, Command and control systems, Spectral analysis, Artificial intelligence, Vocabulary},
	pages = {1626--1641},
}


@inproceedings{li_improved_2008,
	title = {Improved {Voice} {Activity} {Detection} {Based} on {Iterative} {Spectral} {Subtraction} and {Double} {Thresholds} for {CVR}},
	url = {https://ieeexplore.ieee.org/document/4634834},
	doi = {10.1109/PEITS.2008.84},
	urldate = {2024-11-20},
	booktitle = {2008 {Workshop} on {Power} {Electronics} and {Intelligent} {Transportation} {System}},
	author = {Li, Xiangbin and Li, Guo and Li, Xueren},
	month = aug,
	year = {2008},
	keywords = {Speech, Noise, Signal to noise ratio, Speech enhancement, Speech processing, Iterative methods, Frequency domain analysis, Cockpit voice recorder (CVR), Voice activity detection, Iterative spectral subtraction, Double thresholds},
	pages = {153--156},
}



@inproceedings{Kumar2024PerformanceEO,
    title={Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward},
    author={Shashi Kumar and Iuliia Thorbecke and Sergio Burdisso and Esa{\'u} Villatoro-Tello and E ManjunathK and Kadri Haciouglu and Pradeep Rangappa and Petr Motlicek and Aravind Ganapathiraju and Andreas Stolcke},
    year={2024},
    booktitle={ICASSP 2025 SALMA Workshop},
    url={https://api.semanticscholar.org/CorpusID:273850605}
}


@article{aksenova2022AccentedSR,
  title={Accented Speech Recognition: Benchmarking, Pre-training, and Diverse Data},
  author={Alena Aksenova and Zhehuai Chen and Chung-Cheng Chiu and Daan van Esch and Pavel Golik and Wei Han and Levi King and Bhuvana Ramabhadran and Andrew Rosenberg and Suzan Schwartz and Gary Wang},
  journal={ArXiv},
  year={2022},
  volume={abs/2205.08014},
  url={https://api.semanticscholar.org/CorpusID:248834135}
}

@inproceedings{sun2018domain,
  title={Domain adversarial training for accented speech recognition},
  author={Sun, Sining and Yeh, Ching-Feng and Hwang, Mei-Yuh and Ostendorf, Mari and Xie, Lei},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4854--4858},
  year={2018},
  organization={IEEE}
}

@article{han2021supervised,
  title={Supervised contrastive learning for accented speech recognition},
  author={Han, Tao and Huang, Hantao and Yang, Ziang and Han, Wei},
  journal={arXiv preprint arXiv:2107.00921},
  year={2021}
}

@article{li2021accent,
  title={Accent-robust automatic speech recognition using supervised and unsupervised wav2vec embeddings},
  author={Li, Jialu and Manohar, Vimal and Chitkara, Pooja and Tjandra, Andros and Picheny, Michael and Zhang, Frank and Zhang, Xiaohui and Saraf, Yatharth},
  journal={arXiv preprint arXiv:2110.03520},
  year={2021}
}