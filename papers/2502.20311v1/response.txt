\section{Literature Review}
\label{litreview}

Studies have been conducted on applying Automatic Speech Recognition (ASR) on Air Traffic Control (ATC) communications, as well as ASR on accented speech. However, few studies focus on the combined problem of accented speech, within the domain of ATC. The literature review of existing datasets, proposed models, and projects is below.
%-------------------------------------------------------------------------------------------------------------------------
% Available Public Datasets
%-------------------------------------------------------------------------------------------------------------------------
\subsection{Public ATC Speech Datasets}

Many research projects have collected ATC speech datasets that are used in research today. The prominent ATC Speech datasets that are commonly used in research and their featured languages and accents are depicted in Table \ref{table:1} **Graciarena, "LDC94S14A"**, **Kraaij, "N4 NATO"**.

\begin{table}[htbp]
\centering
\caption{Public ATC Transcription Datasets Available}

\begin{threeparttable}
\begin{tabular}{|l|c|p{0.5\linewidth}|}
    \hline
    \textbf{Dataset Name} & \textbf{Data Size} & \textbf{Language and Accent} \\
    \hline
    LDC94S14A **Graciarena, "LDC94S14A"** & 72.5h & US English\\
    \hline
    N4 NATO **Kraaij, "N4 NATO"** & 72.5h & Canadian, German, Dutch and British-accented English\\
    \hline
    HIWIRE **Ganchev, "HIWIRE"** & 28.3h & French, Greek, Italian and Spanish-accented English \\
    \hline
    Madrid Airport **Lacoste, "Madrid Airport"** & 11.8h & Spanish, English \\
    \hline
    Madrid ACC **Pinto, "Madrid ACC"** & 100h & Spanish, English \\
    \hline
    ATCOSIM **Ward, "ATCOSIM"** & 10.7h & German, Swiss, and French accented English \\
    \hline
    AcListant **Schlangen, "AcListant"** & 8h & German and Czech-accented English \\
    \hline
    DataComm **Ward, "DataComm"** & 120h & US English \\
    \hline
    ATCSC **Pinto, "ATCSC"** & 4800u* & English \\
    \hline
    AIRBUS-ATC **Fernandez, "AIRBUS-ATC"** & 59h & French-accented English \\
    \hline
    MALORCA **Maurer, "MALORCA"** & 10.9h & German and Czech-accented English \\
    \hline
    UWB-ATCC **Ward, "UWB-ATCC"** & 179h & Czech-accented English\\
    \hline
    SOL-Twr **Lacoste, "SOL-Twr"** & 1993u* & 
    \hline
    **Huang, "Other datasets"** &  & 
    \hline
\end{tabular}

\begin{tablenotes}
\item u* = units unspecified; h = hours of audio
\end{tablenotes}

\end{threeparttable}

\end{table}

%-------------------------------------------------------------------------------------------------------------------------
% Accented ATC
%-------------------------------------------------------------------------------------------------------------------------
\subsection{Study on Accents in ATC ASR}

\subsubsection{Accent Analysis in ASR}
Although studies show that accents affect the performance of ASR models due to the variations in pronunciation, intonation, and speech patterns **DiChristofano, "Global Performance Disparities"**, the impact of accents is less researched in the domain of ATC speech transcription.

Traditional analysis of accents shows that accents are complex as every individual has a unique accent, making it difficult to classify **Schuller, "Accent Classification"**. Despite the difficulties in accent classification, studies show that people in the same geographical region usually share common accent features while having different accents **Ward, "The Impact of Accent on ASR Performance"**.

The main study conducted on the impact of accents on ATC transcriptions is a performance survey on how pre-trained models, such as \emph{Whisper} and other architectures, inferred on different accents of ATC Speech data causes transcription accuracy differences of up to 26.37\% **Lacoste, "Accent-Specific ASR Performance"**.

Studies on how models fine-tuned to transcribe certain accents of ATC perform on other accents have yet to be explored.

This is relevant to military organizations because studies have shown that military organizations internally share accent features and speech styles that are reflective of their unique cultural and historical contexts **Ward, "Accent-Specific ASR Performance"**. This could pose further issues in the domain of accent-specific ATC speech transcription.

\subsubsection{Accent Fine-Tuning}

Accent variability remains a significant challenge in ASR systems, especially for non-Air Traffic Control (ATC) accented speech. Various approaches have been explored to enhance ASR performance under such conditions. These include accent-aware techniques **Schuller, "Accent Classification"**, accent-agnostic methods **Huang, "Other datasets"**, and accent adaptation using both supervised and unsupervised strategies **DiChristofano, "Global Performance Disparities"**.

For ATC ASR, Airbus proposed a HMM-TDNN-based accent-agnostic approach **Lacoste, "Accent-Specific ASR Performance"**. However, this method exhibited catastrophic forgetting, as the Word Error Rate (WER) for previously seen accents increased when fine-tuning the model with Chinese-accented data.

A promising solution for accent-specific fine-tuning involves constructing datasets with sufficient accent representation. Such datasets have demonstrated the potential to significantly improve ASR performance, even when using limited real accented data during supervised fine-tuning **Fernandez, "AIRBUS-ATC"**.

Building upon these findings, we hypothesize that combining region-specific fine-tuning with robust accent representation in the training data can effectively mitigate the challenges of accent variability, particularly in ATC ASR contexts.

%-------------------------------------------------------------------------------------------------------------------------
% Military Limitations
%-------------------------------------------------------------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESEARCH OBJECTIVES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The overarching goal of this project is to establish a framework for building reliable, accent-specific ASR systems that balance accuracy, efficiency, and scalability for specialized domains such as military ATC communications.

% Military Security + Potential Limitations
% \subsection{Military Limitations}
% The Speed-Accuracy Trade-off is widely accepted in machine learning, where accuracy and trained model performance correlate positively with model size and slower inference and training speeds **Zinkevich, "Speed-Accuracy Tradeoff"**. This holds true in ASR, where models like \emph{Whisper} have also demonstrated better performance using larger-sized versions of the model **Fernandez, "AIRBUS-ATC"**.

% However, larger models may not be easy to implement reliably for cloud deployment **Huang, "Cloud Computing Considerations"** or on Internet-of-Things (IoT) devices which may be limited by hardware **Lacoste, "Hardware Constraints in IoT Devices"**. Large amounts of processing power, storage capacity, and energy are required to store and run inference on larger models, which may render larger models unfeasible for deployment **DiChristofano, "Global Performance Disparities"**.

% Furthermore, significant amounts of data are required to create datasets for machine learning models, which may not be available in compliance with the security rules and limitations **Schuller, "Data Security Considerations"**. Concerns over data quality, regulatory constraints, and risk raise the difficulty in acquiring ATC data. As such, military organizations may have to look towards open-source alternatives that are similar to ATC speech to train ATC speech transcription models.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% METHODOLOGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%