%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{booktabs}

\setlength{\floatsep}{0pt}      % Space between floats
\setlength{\textfloatsep}{0pt}  % Space between a float and text
\setlength{\intextsep}{0pt}     % Space between an inline float and text

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}

\usepackage{amsmath, amsthm, amssymb}

\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}


\newtheorem{prop}{Proposition}
\newenvironment{sproof}{%
  \renewcommand{\proofname}{Sketch Proof}\proof}{\endproof}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}


% Attempt to make hyperref and algorithmic work together better:
% \newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
% \usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny,textwidth=5in]{todonotes}



% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Expert-Agnostic Learning to Defer}

\begin{document}

\twocolumn[
\icmltitle{Expert-Agnostic Learning to Defer}

\begin{icmlauthorlist}
\icmlauthor{Joshua Strong}{yyy}
\icmlauthor{Pramit Saha}{yyy}
\icmlauthor{Yasin Ibrahim}{yyy}
\icmlauthor{Cheng Ouyang}{yyy}
\icmlauthor{Alison Noble}{yyy}
\end{icmlauthorlist}

\icmlaffiliation{yyy}{Department of Engineering Science, University of Oxford, Oxford, United Kingdom}

\icmlcorrespondingauthor{Joshua Strong}{joshua.strong@eng.ox.ac.uk}

\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

\printAffiliationsAndNotice{} % otherwise use the standard text.

\begin{abstract}
Learning to Defer (L2D) learns autonomous systems to independently manage straightforward cases, while deferring uncertain cases to human experts. Recent advancements in this field have introduced features enabling flexibility to unseen experts at test-time, but we find these approaches have significant limitations. To address these, we introduce EA-L2D: Expert-Agnostic Learning to Defer, a novel L2D framework that leverages a Bayesian approach to model expert behaviour in an expert-agnostic manner, facilitating optimal deferral decisions. EA-L2D offers several critical improvements over prior methods, including the ability to incorporate prior knowledge about experts, a reduced reliance on expert-annotated data, and robust performance when deferring to experts with expertise not seen during training. Evaluating on CIFAR-10, HAM10000, German Traffic Lights, Breast Ultrasound, Axial Organ Slices, and Blood Cell MNIST, we observe performance gains over the next state-of-the-art of 1-16\% for seen experts and 4-28\% for unseen experts in settings with high expert diversity.
\end{abstract}

\section{Introduction}
\label{sec:intro}

%%%%%%%%% What we are trying to do any why is it relevant?
% Introduce L2D
% practical motivation
The practical implementation of artificial intelligence (AI) in decision-sensitive environments often involves a delicate trade-off between the benefits of autonomy and the consequences of errors. The primary approach in achieving this balance is through Learning to Defer (L2D) \cite{madras2018predictresponsiblyimprovingfairness}, a training paradigm in which an AI system is trained to autonomously and accurately make predictions on straightforward cases while deferring more challenging cases to a human expert. This strategy is particularly valuable in high-stakes environments, such as healthcare or finance, where the inclusion of a deferral mechanism mitigates the risk of severe errors. In this work, we focus on healthcare due to its unique ethical implications, where erroneous decisions can directly impact patient safety and outcomes.

Recently, the L2D field has seen substantial advancements, including the development of consistent surrogate losses for training these systems \cite{mozannar2021consistentestimatorslearningdefer, verma2022calibratedlearningdeferonevsall}, and extensions that allow for deferral to multiple experts \cite{verma2023learningdefermultipleexperts}. Recent work by \citet{tailor2024learningdeferpopulationmetalearning} proposed a meta-learning solution for L2D systems that can adapt to experts not seen during the training regime through meta-learning representations of expert behaviours, enabling the system to quickly adapt to new experts using a small set of their example predictions, denoted \textit{context predictions}. However, this approach exhibits a key weakness in limited generalisation to experts with expertise unseen during training. Additionally, their solution poses problems seen more widely in L2D literature, including a dependency on large volumes of expert predictions, and an inability to incorporate prior expert knowledge into the system.

% How do we solve it (i.e. our contribution!)
In this paper, we introduce Expert-Agnostic Learning to Defer (EA-L2D), a novel framework designed to address these limitations. EA-L2D makes deferral decisions based solely on dynamically quantifying the expert’s strengths and the AI’s confidence, making the system expert-agnostic and hence robust to experts with unseen expertise. We utilise a Bayesian framework to learn representations of expert behaviour, allowing for the incorporation of prior knowledge about experts. This \textit{Bayesian Beta-Binomial} model provides an in-built approximation of expert predictions, which we exploit to significantly reduce the need for large amounts of expert's predictions of which is traditionally required for every expert and training image in existing L2D setups.

% How do we verify that we solved it
We conduct experiments across a diverse set of 5 benchmarks and realistic datasets, including CIFAR-10, German Traffic Lights, HAM10000, Breast Ultrasound, Axial Organ Slices, and Blood Cell MNIST. We evaluate the system’s performance across a range of scenarios, considering variations in the diversity of expert population behaviour and the degree to which individual experts possess multiple areas of expertise. Additionally, we conduct an experiment to evaluate the effect that inaccurate and accurate priors on expert behaviour have on deferral performance. We observe performance gains over the next state-of-the-art of 1-16\% for seen experts and 4-28\% for unseen experts in settings with high expert diversity. Our key contributions are as follows:
\vspace{-1mm}
\begin{enumerate}[noitemsep, nolistsep]
    \item We introduce EA-L2D, an expert-agnostic framework for learning to defer that leverages a Bayesian Beta-Binomial model to effectively adapt to new experts without the need for retraining.
    \item Our proposed EA-L2D framework relaxes the requirement for expert annotations across the entire training dataset. 
    \item To the best of our knowledge, our L2D framework is the first to enable the incorporation of prior information on expert performance. We demonstrate that this significantly enhances deferral accuracy.
\end{enumerate}

\section{Related Literature}
\paragraph{Learning to Defer (L2D)} The L2D paradigm, introduced by \citet{madras2018predictresponsiblyimprovingfairness}, extends Rejection Learning \cite{5222035,1054406} by integrating human expert predictions into deferral decisions. It aims to achieve a joint decision system that incorporates the defer-to-human ability in its design while pursuing Bayesian optimality for the entire decision system. Since then, numerous extensions have emerged, such as L2D for multiple experts \cite{verma2023learningdefermultipleexperts,mao2024principledapproacheslearningdefer}, frameworks designed for limited expert annotations \cite{hemmer2023learningdeferlimitedexpert,anonymous2024probabilistic,alves2024costsensitivelearningdefermultiple}, systems that learn to complement humans rather than just defer to human experts \cite{zhang2025learning}, systems which seek to control workload distribution of deferred cases \cite{anonymous2024probabilistic,alves2024costsensitivelearningdefermultiple}, and two-stage L2D systems where the classifier and rejector are trained separately \cite{mao2023twostage}. Additionally, practical applications of L2D have been explored in domains such as healthcare \cite{joshi2021learning}, fraud detection \cite{alves2023fifar}, and content moderation \cite{lykouris2024learningdefercontentmoderation}.

\paragraph{Learning to Defer to a Population: L2D-Pop} Our work's setting of adapting to unseen experts during test-time is most closely related to \cite{tailor2024learningdeferpopulationmetalearning}, which proposed a meta-learning solution for L2D systems, L2D-Pop. Their approach addresses a key limitation of prior works: once experts are integrated into the system, they become fixed, meaning that replacing an expert with another exhibiting different behaviour could harm performance. L2D-Pop overcomes this limitation by meta-learning representations of expert behaviours, allowing the system to adapt to new experts using a few representative examples of their behaviour, referred to as \textit{context predictions}. Unfortunately, we observe that experts with expertise not seen during training of L2D-Pop suffer from performance degradation. In contrast, our work achieves robust performance on experts with expertise unseen during training while bypassing the cumbersome meta-learning process.

\paragraph{L2D With Limited Expert Predictions} Our work also relates to L2D frameworks designed to address the constraint of limited expert predictions. For example, \citet{alves2024costsensitivelearningdefermultiple} employs a human expertise model trained to predict an expert’s response to a given instance, but unrealistically requires one expert prediction per instance. Similarly, \citet{anonymous2024probabilistic} employs a probabilistic framework leveraging the Expectation-Maximization algorithm to infer and optimise missing expert annotations as latent variables, enabling training with incomplete data. \citet{hemmer2023learningdeferlimitedexpert} proposes training an embedding model to approximate expert capabilities using an expertise predictor, which can generate artificial expert predictions. In contrast, our approach relaxes the reliance on complete expert annotations without requiring auxiliary models for generating accurate predictions. Critically, our framework uniquely ensures applicability to previously unseen experts, allowing our L2D framework to adapt to any experts at test time. This data efficiency can be further enhanced by incorporating prior knowledge of expert behaviour into L2D at inference time— a capability that, to the best of our knowledge, no prior L2D work has achieved.

\section{Background}
\label{sec:preliminaries}
\subsection{Learning to Defer}
\paragraph{Setup}
We consider a classification task where the goal is to predict a target \( y \in \mathcal{Y} = \{1, \ldots, K\} \) given inputs \( \boldsymbol{x} \in \mathcal{X} \), with \( (\boldsymbol{x}, y) \sim \mathcal{P} \). In the L2D framework, we assume access to an expert \( E \) providing predictions \( m \in \mathcal{M} = \mathcal{Y} \). A dataset of size \( N \) is given as \( \mathcal{D} = \{(\boldsymbol{x}_i, y_i, m_i)\}_{i=1}^{N} \). The objective is to construct a predictor \( \hat{Y}: \mathcal{X} \to \mathcal{Y} \cup \{\perp\} \), where \( \perp \) represents deferral to the expert. This involves jointly learning a \textit{classifier} \( h: \mathcal{X} \to \mathcal{Y} \) and a \textit{rejector} \( r: \mathcal{X} \to \{0, 1\} \). The classifier predicts \( y \), while the rejector decides whether to rely on \( h \) or defer to the expert.

\paragraph{L2D Optimisation}
To define a loss for the system, we assume that deferring and classifying incur costs \( l_{\text{exp}}(\boldsymbol{x}, y, m) \) and \( l(\boldsymbol{x}, y, h(\boldsymbol{x})) \), respectively. The system loss combining both models is given by:
\begin{align}
\label{eqn:1}
    L(h, r) = & \; \mathbb{E}_{(\boldsymbol{x}, y) \sim \mathcal{P}, m \sim M | (\boldsymbol{x}, y)} \Big[ 
    l(\boldsymbol{x}, y, h(\boldsymbol{x})) \mathbb{I}_{r(\boldsymbol{x}) = 0} \\
    & \; + l_{\text{exp}}(\boldsymbol{x}, y, m) \mathbb{I}_{r(\boldsymbol{x}) = 1} 
    \Big]. \nonumber
\end{align}
However, \( L(h, r) \) is non-convex and computationally challenging to optimise. \citet{mozannar2021consistentestimatorslearningdefer} proposed a consistent surrogate loss for Eq.~\ref{eqn:1}, derived via a reduction to cost-sensitive learning and the Bayes minimiser of the 0-1 system loss. Here, we describe the latter. The 0-1 loss for Eq.~\ref{eqn:1} is given by
\begin{align*}
L_{0-1}(h, r) = &\\ \mathbb{E}_{(\boldsymbol{x}, y) \sim \mathcal P, m \sim M | (\boldsymbol{x}, y)}&\left[ \mathbb{I}_{h(\boldsymbol{x}) \neq y} \mathbb{I}_{r(\boldsymbol{x}) = 0} + \mathbb{I}_{m \neq y} \mathbb{I}_{r(\boldsymbol{x}) = 1} \right].
\end{align*}
Minimising this loss leads to the Bayes-optimal classifier $h^*(\boldsymbol{x})$ and rejector $r^*(\boldsymbol{x})$:

\[
h^*(\boldsymbol{x}) = \arg \max_{y \in \mathcal{Y}} \, \mathbb{P}(\mathcal Y = y | \mathcal X = \boldsymbol{x}),
\]
\[
r^*(\boldsymbol{x}) = \mathbb{I} \left[ \mathbb{P}(\mathcal Y = \mathcal M | \mathcal X = \boldsymbol{x}) \geq \max_{y \in \mathcal{Y}} \, \mathbb{P}(\mathcal Y = y | \mathcal X = \boldsymbol{x}) \right].
\]
Let \( g_y: \mathcal{X} \rightarrow \mathbb{R} \) for \( y \in \mathcal{Y} \), and define \( h(\boldsymbol{x}) = \arg\max_{y \in \mathcal{Y}} g_y \). Similarly, let \( g_{\perp}: \mathcal{X} \rightarrow \mathbb{R} \), and define 
\( r(\boldsymbol{x}) = \mathbb{I}\left[\max_{y \in \mathcal{Y}} g_y(\boldsymbol{x}) \leq g_{\perp}\right] \). A consistent surrogate softmax-based loss for \( L_{0-1} \) is then given by:
 \begin{align}
\label{l2d}
&L_{CE}(g_1, \ldots, g_K, g_{\perp} ; \boldsymbol{x}, y, m)= \\
 & \quad-\log \left(\frac{\exp \left\{g_y(\boldsymbol{x})\right\}}{\sum_{y^{\prime} \in \mathcal{Y} \cup \perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x})\right\}}\right) \notag  \\
& \quad-\mathbb{I}[m=y] \log \left(\frac{\exp \left\{g_{\perp}(\boldsymbol{x})\right\}}{\sum_{y^{\prime} \in \mathcal{Y}\cup\perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x})\right\}}\right) . \notag 
\end{align}
Intuitively, this loss comprises two components: the first optimises the classifier, while the second optimises the rejector by encouraging deferral when the expert prediction is correct. During inference, cases are deferred to the expert when $ g_{\perp} \geq \max_{y \in \mathcal{Y}} g_y(\boldsymbol{x})$.

\section{Expert-Agnostic Learning to Defer}
\begin{figure*}
\begin{center}
\centerline{\includegraphics[scale=0.6]{ea-l2d-fig5.png}}
\caption{Overview of the Expert-Agnostic Learning to Defer system. When a new expert \( E \) is introduced to the system, their predictions on context data \( \mathcal{D}_c^E \) transforms into the expert's behaviour representation \( \mathcal{R}_E \) through the Beta-Binomial Model. At inference time, the rejector computes the deferral logit \( g_\perp \) using \( \mathcal{R}_E \) and the classifier's class logits on the input test data (query). If \( g_\perp \) exceeds all class logits, the query is deferred to the expert; otherwise, handled autonomously by the classifier}
\label{eal2dfig}
\end{center}
\vskip -0.2in
\end{figure*}


\label{sec:methods}
In this section, we present the architecture of EA-L2D and our key contributions:  
\begin{enumerate}[noitemsep, nolistsep]
\item Incorporating prior information (§\ref{rep}, \ref{priors}),
\item An expert-agnostic design enabling robust deferral to unseen experts (§\ref{def_logit}),
\item Relaxing the need for expert annotations on all training data (§\ref{eal2d_optm}).
\end{enumerate}
For clarity, we divide our methodology into four parts: \textbf{\ref{rep}. Constructing Expert Behaviour Representations}, \textbf{\ref{def_logit}. Estimating the Deferral Logit}, and \textbf{\ref{eal2d_optm}. Optimisation of EA-L2D with Reduced Expert Annotations}, concluding with \textbf{\ref{priors}. Incorporating Expert Priors}. Figure \ref{eal2dfig} illustrates the system, and Algorithm \ref{alg:eald} in App \ref{appd_algs} provides implementation details.

\paragraph{Setup}  
For a single expert \( E \), we assume access to a \textit{context dataset} \( \mathcal{D}_E^C = \{\boldsymbol{x}_i^C, y_i^C, m_{i,E}^C \}_{i=1}^{N_E^C} \) and a \textit{query dataset} \( \mathcal{D}_E^Q = \{\boldsymbol{x}_i^Q, y_i^Q, m_{i,E}^Q \}_{i=1}^{N_Q} \), where \( N_E^C \) and \( N^Q \) denote the number of context and query data points, respectively. The context dataset is used to estimate expert behaviour (in practice often the historical expert predictions), whereas the query dataset is used to learn deferral decisions. We assume \( N_E^C \ll N^Q \) and \( \mathcal{D}_E^C \cap \mathcal{D}^Q = \emptyset \). While \( N_E^C \) may vary across experts, \( N^Q \) is fixed. 

\subsection{Constructing Expert's Behavioural Representations}
\label{rep}

EA-L2D constructs the \textit{behavioural representation} $\mathcal{R}_E$ for a given expert $E$ using the context set $\mathcal{D}_c^E$ from a Bayesian perspective. This approach provides several advantages: it naturally incorporates prior knowledge about expert performance, handles limited context data robustly, offers theoretical guarantees on inference accuracy, and updates beliefs about each expert’s accuracy as more data is observed. Additionally, it supports permutation-invariant and variable-length context data. To prevent overfitting, we sample a subset \( d^E_c \subset \mathcal{D}^E_c \) in each training batch when constructing these representations.

For each expert $E$ and class $k \in K$, we define:
\begin{itemize}[noitemsep, nolistsep]
    \item $n_k := \sum_{i} \mathbb{I}[y_i^C = k]$: Total number of context samples in class $k$.
    \item $t_k^{(E)} := \sum_{i} \mathbb{I}[y_i^C = m_i^E]$: Number of correct predictions by expert $E$ for context samples in class $k$.
\end{itemize}

We model the expert’s accuracy in class $k$ as the probability $\theta_k^{(E)}$ of correctly predicting the label when the true label is $k$, using a \textit{conjugate Beta-Binomial} framework. Without prior information about an expert's performance, we assume a uniform prior $\text{Beta}(1, 1)$:
\begin{equation*}
    \theta_k^{(E)} \sim \text{Beta}(\alpha_k^{(E)}, \beta_k^{(E)}), \quad \text{where } \alpha_k^{(E)} = \beta_k^{(E)} = 1, \quad \forall k.
\end{equation*}

The prior is updated using observations of correct and incorrect predictions in class $k$ to form the posterior:
\begin{equation*}
    \theta_k^{(E)} | t_k^{(E)}, n_k^{(E)} \sim \text{Beta}(\alpha_k^{(E)} + t_k^{(E)}, \beta_k^{(E)} + n_k^{(E)} - t_k^{(E)}).
\end{equation*}

The posterior mean, representing the expected accuracy of expert $E$ in class $k$, is:
\begin{align*}
    \mu_k^{E} := \mathbb{E}[\theta_k^{(E)} | t_k^{(E)}, n_k^{(E)}] = \frac{\alpha_k + t_k^{(E)}}{\alpha_k + \beta_k + n_k^{(E)}}.
\end{align*}

The \textit{expertise} class $E^*$, or the expert's best-performing class, is the one with the largest posterior mean:
\begin{equation*}
    E^* := \arg \max_{k \in K} \mu_k^{E}.
\end{equation*}

Finally, the behavioural representation $\mathcal{R}_E$ for expert $E$ is constructed as the vector of posterior means across all classes:
\begin{equation*}
    \mathcal{R}_E := \left[ \mu_{k=1}^{E}, \ldots, \mu_{k=K}^{E} \right] \in \mathbb{R}^{K}.
\end{equation*}

\begin{prop}
\label{propn1}
As the number of context samples \( n_k \to \infty \) for each class \( k \), the posterior mean estimate \( \mu_k^{E} \) of the expert's accuracy \( \theta_k^{(E)} \) converges to the true accuracy \( \theta_k^{(E)} \) almost surely. Furthermore, the class \( E^* \), identified as having the highest posterior mean, corresponds to the class with the highest true accuracy with high probability as \( n_k \) increases.
\end{prop}
\vspace{-3mm}
\begin{sproof}
See App. \ref{prop1proof} for the full proof. The result follows from the Law of Large Numbers, ensuring that the empirical mean \( \hat{\theta}_k \) converges to \( \theta_k^{(E)} \) as \( n_k \to \infty \). With Bayesian updating, the posterior mean also converges to \( \theta_k^{(E)} \) as the influence of the prior diminishes. Consequently, the class \( E^* \) with the highest true accuracy will have the largest posterior mean with high probability as \( n_k \to \infty \).
\end{sproof}

\begin{prop}
\label{prop2}
Let \( K \) denote the number of classes, with true accuracy probabilities \( \theta_k^* \) for each class \( k \). Assume expert \( E \) has expertise class \( k^* \), where \( \theta_{k^*}^* = \max_k \theta_k^* \) and \( \theta_{k^*}^* > \theta_k^* \) for all \( k \neq k^* \). Then, as the total number of samples increases, the probability of predicting \( k^* \) converges to 1. Additionally, if there are at least \( n \) samples from each class, and
\[
n \geq \frac{\ln\left(\frac{2K}{\delta}\right)}{2 \left(\frac{\Delta}{2}\right)^2},
\]
where \( \Delta = \theta_{k^*}^* - \max_{k \neq k^*} \theta_k^* \), the probability that the posterior mean \( \mathbb{E}[\theta_{k^*} | t_{k^*}, n_{k^*}] \) exceeds \( \mathbb{E}[\theta_k | t_k, n_k] \) for all \( k \neq k^* \) is at least \( 1 - \delta \). In other words, the correct class is predicted with probability \( 1 - \delta \).
\end{prop}
\vspace{-3mm}
\begin{sproof}
See App. \ref{prop2proof} for the full proof. Using the Law of Large Numbers and Hoeffding's inequality \cite{doi:10.1080/01621459.1963.10500830}, we show that as \( n \) increases, empirical estimates of true accuracy for each class become tightly concentrated around their true values. Proposition \ref{propn1} ensures that posterior mean estimates converge to the true accuracies. Here, we extend this to demonstrate that the empirical estimate for the expert class \( k^* \) remains higher than those for other classes. By bounding deviations with Hoeffding's inequality and applying the union bound across all classes, we derive the minimum \( n \) to ensure a confidence level of at least \( 1 - \delta \).
\end{sproof}
\vspace{-4mm}
Proposition \ref{propn1} ensures that EA-L2D's estimated accuracy converges to the true accuracy as context samples increase, guaranteeing reliability with sufficient data. Proposition \ref{prop2} demonstrates that with enough samples and sufficient accuracy differences between classes, the top expert class is identified with high probability. It also provides a sample size requirement to achieve a specified confidence level, offering guidance for data collection and reliability planning. Together, these results establish a strong theoretical foundation for EA-L2D, ensuring accurate and dependable deferral decisions as data availability grows.

\subsection{Estimating the Deferral Logit}
\label{def_logit}
Having established a framework for estimating expert behavioural representations \( \mathcal{R}_E \), we now describe how EA-L2D uses these representations alongside query data to estimate the deferral logit \( g_{\perp} \).

We first define:
\begin{itemize}[noitemsep, nolistsep]
    \item \( \rho_k \coloneq \sigma(g_k) = h_k(\boldsymbol{x}^Q) \): The softmax output for the \( k^{\text{th}} \) class of the query input \( \boldsymbol{x}^Q \) from classifier \( h \),
    \item \( \rho^* := \max_{k} \rho_k \): The largest softmax output, representing the probability of the most likely class for \( \boldsymbol{x}^Q \),
    \item \( k^* := \arg \max_{k} \rho_k \): The most likely class.
\end{itemize}

The deferral mechanism in EA-L2D is implemented via a feedforward neural network \( r_{\phi}(\cdot, \cdot, \cdot, \cdot) \), which takes four key inputs to estimate the deferral logit \( g_{\perp} \):
\begin{enumerate}[noitemsep, nolistsep]
        \item \( \rho_{E^*} \): The softmax probability for \( \boldsymbol{x}^Q \) corresponding to the expert’s expertise class, estimated by classifier \( h \),
            \item \( \rho^* \): The softmax probability for the most likely class,
    \item \( \mu_{E^*}^E \): The estimated posterior mean accuracy for expert \( E \)'s expertise class,
    \item \( \mu^E_{k = k^*} \): Expert \( E \)'s estimated posterior mean accuracy for the classifier's most likely class.
\end{enumerate}

The deferral logit is estimated as:
\begin{equation*}
    g_{\perp} := r_{\phi}( \rho_{E^*}, \rho^*, \mu^E_{k = k^*}, \mu_{E^*}^E) = r(\mathcal{R}_E, \boldsymbol{x}^Q).
\end{equation*}
By selecting these inputs, the rejector learns to be expert-agnostic, basing deferral decisions not on the expert’s identity but through a comparison of the relative strengths of the classifier and expert. An example of this mechanism can be seen in Figure \ref{fig:al}.

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.49]{fig_al.png}
    \vspace{-0.5cm}
    \caption{Example inputs and outputs for EA-L2D's rejector. For Expert A, the classifier predicts that there is $\approx 0\%$ chance that this image is the expert's expertise class. The Beta-Binomial model reveals the expert is $22\%$ accurate for the classifier's predicted class. The rejector outputs an overwhelmingly negative deferral logit (i.e. should not defer). For Expert B, the classifier predicts with $58\%$ confidence of its most likely class. The Beta-Binomial model supplies information that the expert is $89\%$ accurate at this class. The rejector outputs a positive deferral logit, indicating this image should be deferred to the expert.}
    \vspace{0.5cm}
    \label{fig:al}
\end{figure}

\begin{prop}
EA-L2D is expert-agnostic, meaning its deferral decisions depend only on the statistical performance of experts and are independent of their specific expertise.
\end{prop}
\vspace{-3mm}
\begin{proof}
The deferral logit \( g_{\perp} \) is defined as:
\[
g_{\perp} := r_{\phi}( \rho_{E^*}, \rho^*, \mu^E_{k = k^*}, \mu_{E^*}^E),
\]
where:
\begin{itemize}[noitemsep, nolistsep]
 \item \( \rho_{E^*} \) and \( \rho^* \) are computed from the classifier's softmax outputs for the query input \( \boldsymbol{x}^Q \).
    \item \( \mu_{E^*}^E \) and \( \mu^E_{k = k^*} \) are derived from \( \mathcal{R}_E \), the representation \( \mathcal{R}_E := [\mu_1^E, \ldots, \mu_K^E] \),
    \item \( \mathcal{R}_E \) depends solely on aggregate statistics \( (t_k^{(E)}, n_k^{(E)}) \) for each class \( k \),
\end{itemize}

From Proposition~\ref{propn1}, as \( n_k \to \infty \), \( \mu_k^E \to \theta_k^{(E)} \), where \( \theta_k^{(E)} \) is the true accuracy of expert \( E \) in class \( k \). Thus, \( \mathcal{R}_E \) captures the expert's statistical performance without relying on specific class expertise. Since \( r \) operates only on \( \mathcal{R}_E \) and classifier outputs, \( g_{\perp} \) is independent of the specific class expertise of the expert. Therefore, EA-L2D is expert-agnostic.
\end{proof}


\subsection{Optimisation of EA-L2D with Reduced Expert Annotations}
\label{eal2d_optm}
Having formulated the approach for producing the deferral logit \( g_{\perp} \), we now detail the optimisation strategy for EA-L2D using the loss function \( L_{CE} \) (Eq. \ref{l2d}) including how our method reduces reliance on extensive expert predictions. \( L_{CE} \) is a cross-entropy loss function that uses input data \( \boldsymbol{x} \), ground-truth labels \( y \), and expert predictions \( m \). Similar to alternative L2D frameworks, we use input data and corresponding ground truth labels. However, a key advantage of EA-L2D lies in its ability to approximate \( m \) via the expert's estimated expertise class, $E^*$, thereby reducing the need for expert predictions on all query data. This reduction is achieved by selectively activating the deferral component of \( L_{CE} \) when the ground-truth label corresponds to the expert’s expertise class \( E^* \), as indicated by \( \mathbb{I}[E^* = y^Q] \) (see \(\spadesuit\) in Eqn \ref{ea-lce}). Additionally, we weight the deferral loss by \( \mu_{k = y}^{E} \) to promote deferral decisions when the beta-binomial model is confident in the expert’s capability and to discourage deferral when confidence is low (see \(\clubsuit\) in Eqn \ref{ea-lce}). Hence, for EA-L2D, our query dataset is $\mathcal{D}^Q = \{(x_i^Q, y_i^Q)\}_{i=1}^{N^Q}$.
\begin{align}
\label{ea-lce}
&L_{CE}\big( g_1, \ldots, g_K, g_{\perp} ; \boldsymbol{x}^Q, y^Q, \mathcal R_E \big) = \\
& -\log \left(\frac{\exp \left\{g_y(\boldsymbol{x}^Q)\right\}}{\sum_{y^{\prime} \in \mathcal{Y} \cup \perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x}^Q)\right\}}\right) \notag \\
& - \underbrace{\mu_{k = y}^{E}}_{\clubsuit} \times \underbrace{\mathbb{I}[E^* = y^Q]}_{\spadesuit} \log \left(\frac{\exp \left\{g_{\perp}(\mathcal R_E, \boldsymbol{x}^Q)\right\}}{\sum_{y^{\prime} \in \mathcal{Y} \cup \perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x}^Q)\right\}}\right). \notag
\end{align}
\subsection{Incorporating Expert Priors}
\label{priors}
EA-L2D integrates expert prior knowledge to enhance behavioural estimation, especially when expert context data is sparse or unavailable. By embedding self-assessed accuracy and confidence into the conjugate Beta-Binomial model, this approach enables flexible incorporation of prior expertise while allowing for data-driven updates. For each expert, we collect:
\begin{itemize}[noitemsep, nolistsep]
    \item \textbf{Self-Assessed Accuracy} \( p_k^{(E)} \in [0, 1] \): The expert's estimated probability of correct classification for class \( k \).
    \item \textbf{Confidence Level} \( c_k^{(E)} \in [0, 1] \): The expert's confidence in this accuracy estimate.
\end{itemize}

The Beta prior for the accuracy \( \theta_k^{(E)} \) is parameterised as:
\begin{align*}
    \alpha_k^{(E)} &= 1 + c_k^{(E)} \, p_k^{(E)} (s - 2), \\
    \beta_k^{(E)} &= 1 + c_k^{(E)} [1 - p_k^{(E)}] (s - 2),
\end{align*}
where \( s \geq 2 \) controls the prior’s strength. Non-informative priors (\( c_k^{(E)} = 0 \)) default to \( \text{Beta}(1, 1) \), while increasing \( c_k^{(E)} \) emphasises the expert's input. We recommend \( s = 10 \) for moderate influence, with larger \( s \) prioritising priors and smaller \( s \) favouring context data.


\section{Experiments}
We perform three key experiments to demonstrate the effectiveness of EA-L2D. Firstly, we conduct experiments varying the diversity of experts to evaluate the performance of the deferral system in contrast to alternative models. Secondly, we investigate the impact of experts possessing multiple areas of expertise. Finally, we illustrate how EA-L2D can leverage prior information about experts to enhance performance. See App. \ref{apdB} for full details on experimental procedures.

\paragraph{Datasets} We evaluate our approach with CIFAR-10 \cite{krizhevsky2009learning}, HAM10000 \cite{Tschandl_2018}, GTSRB \cite{Houben-IJCNN-2013}, Breast Ultrasound \cite{ALDHABYANI2020104863}, Axial Organ Slices \cite{BILIC2023102680} and Blood Cell MNIST \cite{bloodmnist}. HAM10000, Breast Ultrasound, Axial Organ Slices, and Blood Cell MNIST provide realistic medical settings characterised by high class imbalance with different medical imaging modalities. GTSRB,
with its large number of classes, allows us to test the model’s
performance in scenarios of high class diversity. CIFAR-10 serves as a benchmark for general performance in a balanced, image classification setting. 

\paragraph{Evaluating L2D Under Variable Deferral Budgets}
L2D systems are typically evaluated using \textit{system accuracy}, a weighted combination of expert accuracy for deferred cases and classifier accuracy for non-deferred cases. Deferral occurs when the system’s confidence in deferring, $g_\perp$, exceeds its highest prediction confidence, $\max_{y \in \mathcal{Y}} g_y(\boldsymbol{x})$. However, this binary deferral mechanism---cases are either deferred or not---limits flexibility in accommodating trade-offs across varying deferral budgets. For example, two models, one deferring all cases and another classifying 99\% independently with deferrals handled perfectly by humans, achieve identical system accuracy despite differing human reliance. This overlooks the practical benefits of reduced intervention, which depend on organisational constraints and resources.

To address this, we extend the Area Under the Accuracy-Rejection Curve (AUARC) \cite{pmlr-v8-nadeem10a} with two new metrics: the \textit{Area Under Rejection System Accuracy Curve} (AURSAC) and the \textit{Area Under Rejection Deferral Accuracy Curve} (AURDAC). AURSAC reflects overall system effectiveness by integrating classifier and expert performance, while AURDAC focuses on deferred-case expert accuracy. Both use L2D softmax probabilities for deferral priority, calculated as:
\begin{align*}
    \perp_{i}^E &= r_{\phi}(\mathcal R_E, \boldsymbol{x}_i^Q) - \max\left[h_1(\boldsymbol{x}^Q_i), \ldots, h_k(\boldsymbol{x}^Q_i)\right],
\end{align*}
where $\perp_{i}^E \in [-1,1]$, with higher values indicating higher deferral priority.

In particular, if a user wishes to evaluate a specific range of deferral proportions, AURSAC and AURDAC can be further restricted to a specific deferral ranges for actionable insights. For range \([d_{\text{min}}, d_{\text{max}}]\), we define:
\begin{equation*}
\text{AURSAC}(d_{\text{min}}, d_{\text{max}}) = \frac{\int_{d_{\text{min}}}^{d_{\text{max}}} \text{SystemAccuracy}(d) \, \mathrm{d}d}{d_{\text{max}} - d_{\text{min}}},
\end{equation*}
\begin{equation*}
\text{AURDAC}(d_{\text{min}}, d_{\text{max}}) = \frac{\int_{d_{\text{min}}}^{d_{\text{max}}} \text{ExpertAccuracy}(d) \, \mathrm{d}d}{d_{\text{max}} - d_{\text{min}}},
\end{equation*}
where \(\text{SystemAccuracy}(d)\) and \(\text{ExpertAccuracy}(d)\) are accuracy metrics at deferral rate \(d\). For discrete \(d\), numerical integration (e.g., trapezoidal rule) approximates these integrals. Metrics are normalised by \((d_{\text{max}} - d_{\text{min}})\) to ensure comparability.

  \begin{table*}[t]
    \hspace{-20mm}
    \centering\fontsize{7}{7}\selectfont\caption{Performance comparison of EA-L2D, L2D-Pop, Pop-Avg, and Multi-Expert L2D models on CIFAR-10, HAM10000, Breast Ultrasound and Axial Organ Slices datasets over \( p \) =\{.2, .5, .8\} for both in-distribution (ID) and out-of-distribution (OOD) experts. Each result is presented as mean ± standard deviation across three seeds. Results in \textbf{bold} indicate the statistically significant best result for the row, for both AURSAC(0,100) and AURDAC(0,100) (abbreviated as SAC and DAC, respectively, in the table). Higher the better.}
    \vspace{1mm}
    \label{tab:performance_comparison}
    \begin{tabular}{lll cc cc cc cc}
    \toprule
    \multirow{3}{*}{\textbf{Dataset}} & \multirow{3}{*}{$p$} & \multirow{3}{*}{\textbf{Experts}} & \multicolumn{2}{c}{\textbf{EA-L2D}} & \multicolumn{2}{c}{\textbf{L2D-Pop}} & \multicolumn{2}{c}{\textbf{Pop-Avg}} & \multicolumn{2}{c}{\textbf{Multi-Expert L2D}} \\
    & & & \multicolumn{2}{c}{\scriptsize(\textit{Ours - Uninformative Prior})} & \multicolumn{2}{c}{\scriptsize(\citet{tailor2024learningdeferpopulationmetalearning})} & \multicolumn{2}{c}{\scriptsize(\textit{Natural Baseline})} & \multicolumn{2}{c}{\scriptsize(\citet{verma2023learningdefermultipleexperts})} \\
    \cmidrule{4-5} \cmidrule{6-7} \cmidrule{8-9} \cmidrule{10-11}
    & & & \textbf{SAC} & \textbf{DAC} & \textbf{SAC} & \textbf{DAC} & \textbf{SAC} & \textbf{DAC} & \textbf{SAC} & \textbf{DAC } \\
    \midrule
    \multirow{6}{*}{\shortstack[l]{\\\\\textbf{CIFAR-10} \\\\ 10 Classes\\ 5/5  ID/OOD Experts\\ 150 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.82 ± 0.00} & \textbf{0.73 ± 0.01} & 0.79 ± 0.01 & 0.72 ± 0.02 & 0.62 ± 0.01 & 0.37 ± 0.01 & 0.62 ± 0.00 & 0.37 ± 0.01 \\
  &  & OOD & \textbf{0.81 ± 0.00} & \textbf{0.76 ± 0.02} & 0.62 ± 0.01 & 0.35 ± 0.02 & 0.61 ± 0.00 & 0.34 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.87 ± 0.00} & \textbf{0.84 ± 0.01} & 0.84 ± 0.00 & 0.80 ± 0.02 & 0.75 ± 0.01 & 0.60 ± 0.00 & 0.74 ± 0.00 & 0.61 ± 0.00 \\
  &  & OOD & \textbf{0.87 ± 0.00} & \textbf{0.85 ± 0.01} & 0.74 ± 0.01 & 0.58 ± 0.02 & 0.74 ± 0.00 & 0.59 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.90 ± 0.01} & \textbf{0.90 ± 0.03} & \textbf{0.91 ± 0.00} & 0.88 ± 0.02 & 0.87 ± 0.00 & 0.84 ± 0.01 & 0.86 ± 0.00 & 0.84 ± 0.01 \\
  &  & OOD & \textbf{0.90 ± 0.01} & \textbf{0.92 ± 0.02} & 0.88 ± 0.01 & 0.83 ± 0.00 & 0.87 ± 0.00 & 0.84 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack[l]{\\\\\textbf{HAM10000} \\\\ 7 Classes \\ 3/4 ID/OOD Experts \\ 105 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.69 ± 0.03} & \textbf{0.51 ± 0.06} & 0.67 ± 0.02 & 0.47 ± 0.07 & 0.64 ± 0.02 & 0.37 ± 0.05 & 0.63 ± 0.02 & 0.37 ± 0.03 \\
  &  & OOD & \textbf{0.87 ± 0.01} & \textbf{0.76 ± 0.01} & 0.74 ± 0.04 & 0.53 ± 0.06 & 0.69 ± 0.01 & 0.45 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.80 ± 0.01} & \textbf{0.69 ± 0.02} & 0.78 ± 0.01 & 0.63 ± 0.02 & 0.77 ± 0.00 & 0.61 ± 0.01 & 0.75 ± 0.01 & 0.62 ± 0.02 \\
  &  & OOD & \textbf{0.90 ± 0.00} & \textbf{0.90 ± 0.01} & 0.79 ± 0.02 & 0.64 ± 0.02 & 0.79 ± 0.01 & 0.65 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.89 ± 0.01} & \textbf{0.86 ± 0.02} & \textbf{0.89 ± 0.00} & \textbf{0.86 ± 0.01} & \textbf{0.89 ± 0.01} & 0.84 ± 0.02 & 0.87 ± 0.00 & 0.84 ± 0.00 \\
  &  & OOD & \textbf{0.91 ± 0.02} & \textbf{0.94 ± 0.03} & \textbf{0.91 ± 0.01} & 0.87 ± 0.02 & 0.90 ± 0.01 & 0.86 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack[l]
{\\\\\textbf{GTSRB} \\\\ 43 Classes \\ 20/23 ID/OOD Experts \\ 215 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.84 ± 0.03} & \textbf{0.79 ± 0.04} & 0.82 ± 0.03 & 0.68 ± 0.04 & 0.62 ± 0.00 & 0.24 ± 0.00 & 0.59 ± 0.00 & 0.24 ± 0.01 \\
  &  & OOD & \textbf{0.89 ± 0.02} & \textbf{0.85 ± 0.03} & 0.61 ± 0.00 & 0.23 ± 0.01 & 0.62 ± 0.00 & 0.24 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.90 ± 0.02} & \textbf{0.87 ± 0.02} & 0.84 ± 0.00 & 0.67 ± 0.00 & 0.76 ± 0.00 & 0.53 ± 0.01 & 0.74 ± 0.01 & 0.53 ± 0.02 \\
  &  & OOD & \textbf{0.93 ± 0.02} & \textbf{0.92 ± 0.03} & 0.76 ± 0.01 & 0.53 ± 0.01 & 0.76 ± 0.00 & 0.53 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.91 ± 0.01} & \textbf{0.87 ± 0.02} & \textbf{0.91 ± 0.00} & 0.83 ± 0.00 & 0.90 ± 0.00 & 0.81 ± 0.00 & 0.89 ± 0.01 & 0.81 ± 0.00 \\
  &  & OOD & \textbf{0.93 ± 0.01} & \textbf{0.90 ± 0.01} & 0.90 ± 0.00 & 0.81 ± 0.01 & 0.91 ± 0.00 & 0.82 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack[l]{\\\\\textbf{Breast Ultrasound} \\\\ 3 Classes \\ 1/2 ID/OOD Experts \\ 35 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.70 ± 0.01} & \textbf{0.64 ± 0.02} & \textbf{0.69 ± 0.01} & 0.61 ± 0.04 & \textbf{0.69 ± 0.02} & 0.60 ± 0.01 & \textbf{0.69 ± 0.03} & 0.58 ± 0.02 \\
  &  & OOD & \textbf{0.77 ± 0.04} & \textbf{0.73 ± 0.03} & 0.73 ± 0.03 & 0.64 ± 0.05 & 0.73 ± 0.02 & 0.66 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.81 ± 0.01} & \textbf{0.81 ± 0.01} & 0.78 ± 0.03 & 0.78 ± 0.03 & 0.78 ± 0.04 & 0.77 ± 0.04 & 0.77 ± 0.04 & 0.77 ± 0.03 \\
  &  & OOD & \textbf{0.82 ± 0.01} & \textbf{0.78 ± 0.04} & 0.78 ± 0.04 & \textbf{0.77 ± 0.05} & 0.80 ± 0.03 & \textbf{0.78 ± 0.05} & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.86 ± 0.01} & \textbf{0.91 ± 0.02} & \textbf{0.85 ± 0.02} & \textbf{0.90 ± 0.03} & \textbf{0.85 ± 0.02} & \textbf{0.89 ± 0.03} & 0.81 ± 0.02 & \textbf{0.90 ± 0.01} \\
  &  & OOD & \textbf{0.88 ± 0.02} & \textbf{0.94 ± 0.03} & 0.86 ± 0.03 & 0.92 ± 0.02 & 0.86 ± 0.04 & 0.91 ± 0.04 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack[l]{\\\\\textbf{Axial Organ Slices} \\\\ 11 Classes \\ 5/6 ID/OOD Experts \\ 35 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.80 ± 0.01} & \textbf{0.65 ± 0.00} & 0.64 ± 0.01 & 0.34 ± 0.01 & 0.63 ± 0.02 & 0.34 ± 0.04 & 0.63 ± 0.00 & 0.33 ± 0.02 \\
  &  & OOD & \textbf{0.76 ± 0.01} & \textbf{0.54 ± 0.02} & 0.63 ± 0.02 & 0.33 ± 0.04 & 0.63 ± 0.01 & 0.31 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.86 ± 0.00} & \textbf{0.77 ± 0.01} & 0.76 ± 0.00 & 0.57 ± 0.01 & 0.75 ± 0.00 & 0.58 ± 0.01 & 0.74 ± 0.01 & 0.59 ± 0.01 \\
  &  & OOD & \textbf{0.85 ± 0.02} & \textbf{0.72 ± 0.03} & 0.75 ± 0.01 & 0.57 ± 0.02 & 0.76 ± 0.01 & 0.58 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.91 ± 0.01} & \textbf{0.88 ± 0.01} & 0.88 ± 0.00 & 0.82 ± 0.00 & 0.88 ± 0.01 & 0.83 ± 0.02 & 0.87 ± 0.01 & 0.84 ± 0.02 \\
  &  & OOD & \textbf{0.91 ± 0.00} & \textbf{0.88 ± 0.01} & 0.88 ± 0.01 & 0.84 ± 0.01 & 0.89 ± 0.01 & 0.86 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\midrule
      \multirow{6}{*}{\shortstack[l]{\\\\\textbf{Blood Cell MNIST} \\\\ 10 Classes \\ 4/6 ID/OOD Experts \\ 40 Context Preds}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.80 ± 0.01} & \textbf{0.72 ± 0.03} & \textbf{0.80 ± 0.01} & 0.66 ± 0.02 & 0.65 ± 0.00 & 0.37 ± 0.01 & 0.65 ± 0.00 & 0.38 ± 0.01 \\
  &  & OOD & \textbf{0.81 ± 0.04} & \textbf{0.69 ± 0.10} & 0.63 ± 0.01 & 0.30 ± 0.02 & 0.64 ± 0.01 & 0.34 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.86 ± 0.01} & \textbf{0.81 ± 0.02} & 0.81 ± 0.01 & 0.66 ± 0.02 & 0.78 ± 0.00 & 0.59 ± 0.01 & 0.76 ± 0.01 & 0.59 ± 0.01 \\
  &  & OOD & \textbf{0.84 ± 0.01} & \textbf{0.72 ± 0.05} & 0.77 ± 0.00 & 0.59 ± 0.02 & 0.78 ± 0.00 & 0.60 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.92 ± 0.01} & \textbf{0.91 ± 0.01} & 0.90 ± 0.01 & 0.85 ± 0.01 & 0.90 ± 0.00 & 0.84 ± 0.01 & 0.90 ± 0.00 & 0.85 ± 0.01 \\
  &  & OOD & \textbf{0.93 ± 0.01} & \textbf{0.92 ± 0.01} & 0.90 ± 0.00 & 0.84 ± 0.01 & 0.90 ± 0.00 & 0.84 ± 0.01 & N/A ± N/A & N/A ± N/A \\
    \bottomrule
    \end{tabular}
    \end{table*}


\paragraph{Simulated Experts}
Following common L2D practices, we generate synthetic experts by assigning each an expertise class sampled without replacement. Experts act as oracles for their expertise class, providing perfect predictions, and predict non-expertise classes correctly with probability \( p \) (termed the \textit{overlap probability}) or uniformly at random otherwise. We vary \( p \) (0.2, 0.5, 0.8), transitioning experts from highly specialised (low \( p \)) to nearly identical (high \( p \)). At \( p = 0.8 \), experts are highly specialised, enabling L2D systems to demonstrate accurate deferral to suitable experts, while higher \( p \) values reduce this challenge. At \( p = 0.2 \), all experts are considered to be close to oracles for all classes. Each dataset has one expert for each class. During training, we sample approximately half the classes as in-distribution (ID) expertise and evaluate systems against both ID and out-of-distribution (OOD) experts. Experts are provided practically small, class-scaled context sets: 150 predictions for CIFAR-10 (10 classes), 105 for HAM10000 (7 classes), 645 for GTSRB (43 classes), 35 for Axial Organ Slices (11 classes), and 35 for Breast Ultrasound (3 classes). During inference, deferral systems can defer to any expert within the cohort.

\paragraph{Baselines}
We compare EA-L2D against three baselines: L2D-Pop, Pop-Avg and Multi-Expert L2D. Pop-Avg is formulated as the first natural baseline of adapting fixed-expert vanilla L2D to an unfixed setting, suitable for comparison against EA-L2D and L2D-Pop. In short, it is formulated by taking the mode predictions of experts as the signal to incorporate deferral loss. Pop-Avg is formulated fully in App. \ref{appD}. Additionally, we include Multi-Expert L2D as a comparison for ID experts. Since this method is unsuitable for deferring to unseen experts, we omit the results for OOD experts.

\subsection{Varying Population Diversity}
    Table \ref{tab:performance_comparison} compares the performance of EA-L2D, L2D-Pop, Pop-Avg, and Multi-Expert L2D on all datasets across overlap probabilities \( p \) (0.2, 0.5, 0.8) for both ID and OOD experts. \textbf{It is important to recall that when analysing these results, unlike all other methods, EA-L2D does not rely on any expert annotations on the training query dataset. Additionally, here we consider EA-L2D operating without any prior information, using the weakest form of the uninformative prior.} We evaluate these methods using AUSAC(0,100) and AUDAC(0,100) to assess their performance from a holistic perspective. See App. \ref{zerofifty} for evaluations of deferral proportions across (0,50). 
    
    EA-L2D consistently achieves the best or joint-best AURSAC scores across all datasets and overlap probabilities, even with ID experts. In populations of highly specialised experts (\( p = 0.2 \)), it excels in deferral decisions, significantly outperforming other models in AURDAC. This superior deferral accuracy enhances overall system performance, as reflected in higher AURSAC scores. As expected, performance differences between models decrease in low-diversity expert populations. EA-L2D also demonstrates greater robustness in OOD expert scenarios, maintaining high deferral accuracy across all overlap probabilities, unlike L2D-Pop, which suffers substantial AURDAC drops for OOD experts. This behaviour is particularly pronounced in datasets with greater numbers of experts, where the chance of randomly deferring to the correct expert becomes lower.

\subsection{Multi-Expertise Experts}
\begin{figure}[t]
    \centering
    \hspace{-4mm}
    \includegraphics[scale=0.64]{multi_oracle.png}
    \caption{Performance comparison (AURSAC) of EA-L2D and L2D-Pop for a single in-distribution (ID) and out of distribution (OOD) expert with varying number of expertise classes, $E^*$, against datasets CIFAR-10, and Organs Axial.}
    \label{fig:multi_oracle}
    \vspace{2mm}
\end{figure}
We examine a scenario where experts have multiple areas of expertise $E^*$. Using datasets CIFAR-10 and Organs Axial. We create two experts: one for ID and one for OOD. Varying their number of expertise classes, we measure AURSAC for EA-L2D and L2D-Pop (Figure~\ref{fig:multi_oracle}). Results show that EA-L2D remains robust to multi-expertise experts on CIFAR-10, outperforming L2D-Pop in both ID and OOD settings. For Organs Axial, EA-L2D’s OOD performance matches L2D-Pop’s ID performance.

\subsection{Incorporating Expert Prior Information}
\label{exp_priors}
We conduct a simple experiment to assess the impact of incorporating expert prior information into EA-L2D. Using the HAM10000 dataset, we simulate the scenario where no context data is available for an expert specialising in diagnosing Benign Keratosis-like lesions (class 0). We evaluated three configurations: one with accurate informative priors (\( p_0 = 0.8 \), \( c_0 = 0.8 \)), one with uninformative priors, and one with inaccurate informative priors, where class 0 remains uninformative, but instead the model is given incorrect priors, suggesting expertise in class 6 (\( p_6 = 0.8 \), \( c_6 = 0.8 \)). We set \( s = 15 \) for each configuration. Figure \ref{fig:example_reports} shows the deferral-accuracy curves for these experiments. Our results indicate that accurate informative priors significantly enhance deferral accuracy compared to uninformative priors. However, highly inaccurate informative priors are detrimental, demonstrating the critical importance of correctly incorporating expert knowledge.

\begin{figure}[t]
    \centering
    \includegraphics[scale=0.55]{exp4.png}
    \vspace{-0.5cm}
     \caption{Deferral-accuracy curves for our simulated expert with three priors on HAM10000. Solid lines show mean values, shaded areas show standard deviations over three seeds, and AURDAC scores are the area under the curves. The informative prior peaks early, reflecting effective case deferral, with curves converging as all cases defer to the expert.}
    \vspace{0.5cm}
    \label{fig:example_reports}
\end{figure}

\section{Conclusion}

In this work, we introduced \textit{Expert-Agnostic Learning to Defer} (EA-L2D), a novel framework that addresses key limitations of existing L2D systems such as L2D-Pop. EA-L2D employs a Bayesian approach to construct aggregate, expert-agnostic representations, enabling deferral decisions to be based on the quantified strengths of expert performance rather than individual identities. This design allows the model to proficiently adapt to new experts with unseen behaviours, even with limited context, leveraging prior information about their perceived expertise. Our expert-agnostic framework minimises retraining requirements when expert pools change, enhances flexibility in dynamic environments, and reduces reliance on exhaustive annotations by approximating expert predictions. Experimental results demonstrate that EA-L2D consistently outperforms prior models in overall system performance (AURSAC) and deferral accuracy (AURDAC). It excels in all scenarios, with specialised or OOD experts, maintaining robust performance where other methods degrade.
\paragraph{Limitations} One limitation of EA-L2D exists in the subjectivity of incorporating self-assessed accuracy in the form of priors. While this approach performs well in controlled scenarios (as demonstrated in Experiment~\ref{exp_priors}), its effectiveness depends on the quality of the self-assessed priors, which may vary due to subjectivity. Confidence calibration—how well subjective confidence aligns with objective accuracy—is rarely perfect in clinical practice, with systematic miscalibration observed across clinician experience levels and exacerbated by case complexity and contextual factors \cite{aiyerconfidence}. Although there are emerging methodologies aimed at eliciting calibrated responses from clinicians \cite{CostaFilho2019,Garbayo2023, Kuhn2021} they remain imperfect, and developing such frameworks fall outside the scope of this paper.


\clearpage

\bibliography{main}
\bibliographystyle{icml2025}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\onecolumn
\section{Detailed Proofs}
\label{appA}
\begin{theorem}[Hoeffding's Inequality]
\label{hoeffding}
 Let $Z_1, \dots, Z_n$ be random independent, identically distributed random variables, such that $0 \leq Z_i \leq 1$. Then,
\[
\Pr\left[ \left| \frac{1}{n} \sum_{i=1}^n Z_i - \mathbb{E}[Z] \right| > \epsilon \right] \leq \delta = 2 \exp(-2n\epsilon^2)
\]
\end{theorem}

\begin{theorem}[Boole's Inequality]
\label{boole}
For any countable collection of events \( A_1, A_2, \dots, A_n \) in a probability space,
\[
\Pr\left( \bigcup_{i=1}^n A_i \right) \leq \sum_{i=1}^n \Pr(A_i).
\]
\end{theorem}

\subsection{Derivation of $\mu_k^E$} \label{derivation}
To derive the posterior mean $\mu_k^{E}$ for the expert accuracy $\theta_k^{(E)}$, we start by considering the conjugate Beta-Binomial model.

\textbf{Prior Distribution:}  
We assume a uniform prior for the accuracy parameter $\theta_k^{(E)}$, which is modelled as a Beta distribution:
\begin{equation*}
    \theta_k^{(E)} \sim \text{Beta}(\alpha_k^{(E)}, \beta_k^{(E)}),
\end{equation*}
where $\alpha_k^{(E)} = 1$ and $\beta_k^{(E)} = 1$ for all classes $k$.

Given the context data, the number of correct predictions $t_k^{(E)}$ out of $n_k^{(E)}$ samples in class $k$ follows a Binomial distribution:
\begin{equation*}
    t_k^{(E)} | \theta_k^{(E)} \sim \text{Binomial}(n_k^{(E)}, \theta_k^{(E)}).
\end{equation*}

Using the conjugacy of the Beta prior with the Binomial likelihood, the posterior distribution of $\theta_k^{(E)}$ given the observed data $(t_k^{(E)}, n_k^{(E)})$ is also a Beta distribution:
\begin{equation*}
    \theta_k^{(E)} | t_k^{(E)}, n_k^{(E)} \sim \text{Beta}(\alpha_k^{(E)} + t_k^{(E)}, \beta_k^{(E)} + n_k^{(E)} - t_k^{(E)}).
\end{equation*}

\textbf{Posterior Mean $\mu_k^{E}$:}  
The expected value of $\theta_k^{(E)}$ under the posterior distribution is given by:
\begin{align*}
    \mu_k^{E} &= \mathbb{E}[\theta_k^{(E)} | t_k^{(E)}, n_k^{(E)}] \\
    &= \frac{\alpha_k^{(E)} + t_k^{(E)}}{\alpha_k^{(E)} + \beta_k^{(E)} + n_k^{(E)}} \\
    &= \frac{1 + t_k^{(E)}}{1 + 1 + n_k^{(E)}} \\
    &= \frac{1 + t_k^{(E)}}{2 + n_k^{(E)}}.
\end{align*}
Here, the expectation of a Beta distributed random variable $\text{Beta}(a, b)$ is $\frac{a}{a + b}$. Applying this property to the posterior distribution yields the expression for $\mu_k^{E}$.

Combining the above derivation, the posterior mean accuracy of expert $E$ in class $k$ is:
\begin{equation*}
    \mu_k^{E} = \frac{\alpha_k^{(E)} + t_k^{(E)}}{\alpha_k^{(E)} + \beta_k^{(E)} + n_k^{(E)}}.
\end{equation*}
With the uniform prior ($\alpha_k^{(E)} = \beta_k^{(E)} = 1$), this simplifies to:
\begin{equation*}
    \mu_k^{E} = \frac{1 + t_k^{(E)}}{2 + n_k^{(E)}}.
\end{equation*}


\subsection{Proof of Proposition \ref{propn1}} \label{prop1proof}Step 1: Convergence of \( \mu_k^E \) to \( \theta_k^{(E)} \). For each class \( k \), the expert's accuracy \( \theta_k^{(E)} \) is modelled as a Beta distribution with parameters \( \alpha_k \) and \( \beta_k \). After observing \( n_k \) samples, the posterior distribution for \( \theta_k^{(E)} \) is:
\[
\theta_k^{(E)} \sim \text{Beta}(\alpha_k^{(E)} + t_k^{(E)}, \beta_k^{(E)} + n_k - t_k^{(E)}),
\]
where:
\[
t_k^{(E)} = \sum_{i=1}^{n_k} \mathbb{I}[y_i^C = m_i^E]
\]
is the number of correct predictions made by the expert for samples in class \( k \). The posterior mean \( \mu_k^E \) is given by:
\[
\mu_k^E = \frac{\alpha_k^{(E)} + t_k^{(E)}}{\alpha_k^{(E)} + \beta_k^{(E)} + n_k}.
\]
As \( n_k \to \infty \), by the Law of Large Numbers, the empirical accuracy \( \hat{\theta}_k^{(E)} = \frac{t_k^{(E)}}{n_k} \) converges almost surely to the true accuracy \( \theta_k^{(E)} \). Since the influence of the prior (\( \alpha_k^{(E)}, \beta_k^{(E)} \)) diminishes as \( n_k \to \infty \), the posterior mean \( \mu_k^E \) also converges almost surely to \( \theta_k^{(E)} \).

Step 2: Identifying the Class with the Highest True Accuracy. Let \( \theta_k^{(E)} \) be the true accuracy for each class \( k \). Denote the class with the highest true accuracy as:
\[
k^* = \arg \max_{k} \theta_k^{(E)}.
\]

As shown in Step 1, the posterior mean \( \mu_k^E \) converges to the true accuracy \( \theta_k^{(E)} \) for all \( k \). Hence, for sufficiently large \( n_k \), the posterior mean \( \mu_k^E \) for class \( k \) will satisfy:
\[
\mu_k^E \approx \theta_k^{(E)}.
\]

Consequently, the class \( E^* \), identified as:
\[
E^* = \arg \max_{k} \mu_k^E,
\]
will correspond to the class with the highest true accuracy \( k^* \) with high probability as \( n_k \to \infty \).

\subsection{Proof of Proposition \ref{prop2}} \label{prop2proof}
Let \( K \) be the number of classes, with true accuracy probabilities \( \theta_k^* \) for each class \( k \). Assume that there exists an \textit{expert class} \( k^* \) where the true accuracy \( \theta_{k^*}^* \) is strictly higher than the accuracy of any other class, such that \( \theta_{k^*}^* = \max_{k} \theta_k^* \) and \( \theta_{k^*}^* > \theta_k^* \) for all \( k \neq k^* \).
Our goal is to show 
\begin{enumerate}
    \item As the number of context samples \( n \) grows, the probability of correctly identifying the expert class \( k^* \) with the largest posterior mean approaches 1,
    \item  Additionally, we can find a lower bound on \( n \) such that the probability of misidentifying the expert class is at most \( \delta \).
\end{enumerate}

Define the gap between the true accuracy of the expert class and the highest accuracy among non-expert classes as
\[
\Delta := \theta_{k^*}^* - \max_{k \neq k^*} \theta_k^*.
\]
For each class \( k \), let \( t_k^{(E)} \) denote the number of correct predictions made by expert \( E \) out of \( n_k \) samples from class \( k \). Then the empirical accuracy estimate \( \hat{\theta}_k \) for class \( k \) is given by
\[
\hat{\theta}_k := \frac{t_k^{(E)}}{n_k}.
\]
By the Law of Large Numbers, as \( n_k \to \infty \), \( \hat{\theta}_k \) converges to the true accuracy \( \theta_k^* \) for each class \( k \).
\\
To ensure that \( \hat{\theta}_k \) is close to \( \theta_k^* \) with high probability, we apply Hoeffding's inequality (Theorem \ref{hoeffding}): For any \( \epsilon > 0 \),
\[
P\left( |\hat{\theta}_k - \theta_k^*| \geq \epsilon \right) \leq 2 \exp(-2 \epsilon^2 n_k).
\]
To correctly identify the expert class, we need \( \hat{\theta}_{k^*} \) and \( \hat{\theta}_k \) (for all \( k \neq k^* \)) to be separated enough. We design this separation to be:
\[
 \quad |\hat{\theta}_k - \theta_k^*| < \frac{\Delta}{2}\, \forall k.
\]
These ensures that $
\hat{\theta}_{k^*} > \hat{\theta}_k \quad \text{for all } k \neq k^*$
which means the expert class \( k^* \) will have the highest empirical accuracy estimate.

Set \( \epsilon = \Delta / 2 \) in Hoeffding's inequality, we obtain:
\[
P\left( |\hat{\theta}_k - \theta_k^*| \geq \frac{\Delta}{2} \right) \leq 2 \exp\left(-2 \left(\frac{\Delta}{2}\right)^2 n_k\right).
\]


To ensure sure that all classes \( k \) meet the desired deviation bound \( |\hat{\theta}_k - \theta_k^*| < \Delta/2 \) simultaneously, we apply the union bound (Theorem \ref{boole}). Set \( A_k \) be the event \( \{|\hat{\theta}_k - \theta_k^*| \geq \Delta/2\} \). Then:
\[
P\left(\exists k \text{ s.t } |\hat{\theta}_k - \theta_k^*| \geq \frac{\Delta}{2}\right) \leq \sum_{k=1}^K P\left(|\hat{\theta}_k - \theta_k^*| \geq \frac{\Delta}{2}\right).
\]

Assuming we have at least \(n\) samples from each class, by Hoeffding's Inequality:
\[
P\left(\exists k \text{ s.t } |\hat{\theta}_k - \theta_k^*| \geq \frac{\Delta}{2}\right) \leq 2K \exp\left(-2 \left(\frac{\Delta}{2}\right)^2 n\right) 
\]

To ensure that the probability of misidentifying the expert class is at most \( \delta \):
\[
2K \exp\left(-2 \left(\frac{\Delta}{2}\right)^2 n\right) \leq \delta.
\]
Taking logs:
\[
\ln(2K) - 2 \left(\frac{\Delta}{2}\right)^2 n \leq \ln(\delta),
\]
Which simplifies to:
\[
n \geq \frac{\ln\left(\frac{2K}{\delta}\right)}{2 \left(\frac{\Delta}{2}\right)^2}.
\]

\section{EA-L2D Algorithms}
\label{appd_algs}
\begin{algorithm}[H]
\caption{Training Expert-Agnostic Learning to Defer}\label{alg:eald}
\begin{algorithmic}[1]
\Require Context data $\mathcal{D}^C$, query data $\mathcal{D}^Q$, rejector $r$, classifier $h$, number of classes $K$, batch size $B$, context sample size $\lambda$, calculated priors $\{\alpha_k^{\text{prior}}, \beta_k^{\text{prior}}\}$ if informative setting.
\For{\textbf{each} batch $\mathcal{D}^Q_b \subseteq \mathcal{D}^Q$ of size $B$}
    \State Sample subset of context data $d_c^E \subset \mathcal D_c^E$ of size $\lambda$
    \For{\textbf{each} expert $E$}
        \For{\textbf{each} class $k = 1, \dots, K$}
            \If{using uninformative prior}
                \State Initialise $\alpha_k \leftarrow 1$, $\beta_k \leftarrow 1$
            \Else
                \State Initialise $\alpha_k \leftarrow \alpha_k^{\text{prior}}$, $\beta_k \leftarrow \beta_k^{\text{prior}}$
            \EndIf
            \State Compute $n_k \leftarrow \sum_i \mathbb{I}[y_i^C = k]$
            \State Compute $t_k^{(E)} \leftarrow \sum_i \mathbb{I}[y_i^C = m_{i,E}^C]$
            \State Update $\alpha_k^{(E)} \leftarrow \alpha_k + t_k^{(E)}$
            \State Update $\beta_k^{(E)} \leftarrow \beta_k + n_k - t_k^{(E)}$
            \State $\mu_k^E \leftarrow \frac{\alpha_k^{(E)}}{\alpha_k^{(E)} + \beta_k^{(E)}}$
        \EndFor
        \State $E^* \leftarrow \arg \max_{k} \mu_k^E$
        \State Compute $\rho_k \leftarrow h_k(\boldsymbol{x}^Q)$ for $k = 1, \dots, K$
        \State $\rho^* \leftarrow \max_k \rho_k$, $k^* \leftarrow \arg \max_k g_k$
        \State $g_{\perp} \leftarrow r_{\phi}(\mu^E_{k = k^*}, \mu_{E^*}^E, \rho_{E^*}, \rho^*),$
        \State Compute loss $L_{CE}$ (Eqn \ref{ea-lce}) and backpropagate
    \EndFor
\EndFor
\end{algorithmic}
\end{algorithm}

\section{Experimental Details}
\label{apdB}
\paragraph{Classifier Models}
The classifier architecture varies by dataset: a Wide Residual Network \cite{zagoruyko2017wideresidualnetworks} is used for CIFAR-10, ResNet-34 \cite{he2015deepresiduallearningimage} for HAM10000, and a pretrained EfficientNet B0  \cite{tan2020efficientnetrethinkingmodelscaling} for Breast Ultrasound and Axial Organ Slices, and ResNet-20 \cite{he2015deepresiduallearningimage} for GTSRB. 
\paragraph{Training Details} Context batch sizes (\( \mathcal{D}_b^Q \) in Algorithm \ref{alg:eald})  are set to 50 for CIFAR-10 and HAM10000, and 215 for
GTSRB. For CIFAR-10, 5 in-distribution and 5 out-of-distribution experts are randomly sampled. For HAM10000 (7
classes), we sample 3 in-distribution and 4 out-of-distribution experts, while for GTSRB (43 classes), 20 in-distribution and
23 out-of-distribution experts are used. We utilise training and validation batch sizes of 128 for all datasets. For GTSRB, CIFAR-10, and HAM10000, we use a learning rate of 0.01 for Wide ResNet and 0.0001 for other components, with a weight decay of 0.0005. For Breast Ultrasound and Axial Organ Slices, these values are reduced to 0.001 and 0.00001, respectively, with a lower weight decay of 0.00005 to prevent over-regularization. Models are trained for 250 epochs (500 for HAM10000), with early stopping at 50 epochs (100 for HAM10000).



\section{Pop-Avg Baseline Details}
\label{appD}
Following \citet{tailor2024learningdeferpopulationmetalearning}, we consider a baseline that models the average expert using their predictions on query data. Unlike \citet{tailor2024learningdeferpopulationmetalearning}, who incorporate the deferral component of the loss for every data point and weight it based on the population of expert accuracies, we compute the average prediction as the \textbf{mode} of the expert predictions for each query data point. Additionally, we only incorporate the deferral component when the mode response matches the ground-truth label (similar to $L_{CE}$). This baseline serves as an initial inference method for multi-expert L2D scenarios, particularly for cases with unseen experts at test time, enabling a natural baseline for a direct comparison with L2D-Pop and EA-L2D.

\begin{align*}
\label{l2dpop-inf}
L_{CE}\big(& g_1, \ldots, g_K, g_{\perp} ; \boldsymbol{x}^Q, y^Q, \{m_E^Q\}_{e=1}^E \big) = \\
& -\log \left(\frac{\exp \left\{g_y(\boldsymbol{x})\right\}}{\sum_{y^{\prime} \in \mathcal{Y} \cup \perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x})\right\}}\right) \notag \\
& - \mathbb{I}[\mathcal{M} = y] \log \left(\frac{\exp \left\{g_{\perp}(\boldsymbol{x})\right\}}{\sum_{y^{\prime} \in \mathcal{Y} \cup \perp} \exp \left\{g_{y^{\prime}}(\boldsymbol{x})\right\}}\right). \notag
\end{align*}
where \( \mathcal{M} = \text{Mode}(\{m_E^Q\}_{e=1}^E) \).


\section{Additional Experiments}
\label{app_exp}
\subsection{Varying Population Density Evaluated with AUSAC(0,50) and AUDAC(0,50)}
\label{zerofifty}

\begin{table*}[h]
\centering\fontsize{7}{7}\selectfont\caption{Performance comparison of EA-L2D, L2D-Pop, Pop-Avg, and Multi-Expert L2D models on CIFAR-10, HAM10000, Breast Ultrasound and Axial Organ Slices datasets over \( p \) =\{.2, .5, .8\} for both in-distribution (ID) and out-of-distribution (OOD) experts. Each result is presented as mean ± standard deviation across three seeds. Results in \textbf{bold} indicate the statistically significant best result for the row, for both AURSAC(0,50) and AURDAC(0,50) (abbreviated as SAC(0,50) and DAC(0,50), respectively, in the table). Higher the better}
\vspace{1mm}
\begin{tabular}{lll cc cc cc cc}
\toprule
\multirow{3}{*}{\textbf{Dataset}} & \multirow{3}{*}{$p$} & \multirow{3}{*}{\textbf{Experts}} 
& \multicolumn{2}{c}{\textbf{EA-L2D}} & \multicolumn{2}{c}{\textbf{L2D-Pop}} 
& \multicolumn{2}{c}{\textbf{Pop-Avg}} & \multicolumn{2}{c}{\textbf{Multi-Expert L2D}} \\
& & & \multicolumn{2}{c}{\scriptsize(\textit{Ours - Uninformative Prior})} 
& \multicolumn{2}{c}{\scriptsize(\citet{tailor2024learningdeferpopulationmetalearning})} 
& \multicolumn{2}{c}{\scriptsize(\textit{Natural Baseline})} 
& \multicolumn{2}{c}{\scriptsize(\citet{verma2023learningdefermultipleexperts})} \\
\cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}
& & & \textbf{SAC(0,50)} & \textbf{DAC(0,50)} 
& \textbf{SAC(0,50)} & \textbf{DAC(0,50)} 
& \textbf{SAC(0,50)} & \textbf{DAC(0,50)} 
& \textbf{SAC(0,50)} & \textbf{DAC(0,50)} \\
\midrule
\multirow{6}{*}{\shortstack{CIFAR-10}}
& \multirow{2}{*}{0.2} & ID & \textbf{0.87 ± 0.00} & \textbf{0.74 ± 0.01} & 0.83 ± 0.01 & 0.74 ± 0.03 & 0.74 ± 0.01 & 0.37 ± 0.02 & 0.74 ± 0.00 & 0.38 ± 0.01 \\
&  & OOD & \textbf{0.86 ± 0.00} & \textbf{0.80 ± 0.03} & 0.75 ± 0.01 & 0.35 ± 0.01 & 0.73 ± 0.00 & 0.34 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.5} & ID & \textbf{0.89 ± 0.00} & \textbf{0.86 ± 0.02} & 0.86 ± 0.00 & 0.79 ± 0.03 & 0.82 ± 0.01 & 0.61 ± 0.01 & 0.81 ± 0.00 & 0.62 ± 0.01 \\
&  & OOD & \textbf{0.88 ± 0.00} & \textbf{0.87 ± 0.01} & 0.81 ± 0.01 & 0.58 ± 0.02 & 0.81 ± 0.01 & 0.59 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.8} & ID & \textbf{0.89 ± 0.01} & \textbf{0.91 ± 0.03} & \textbf{0.90 ± 0.01} & 0.87 ± 0.02 & \textbf{0.89 ± 0.00} & 0.84 ± 0.01 & 0.87 ± 0.00 & 0.84 ± 0.01 \\
&  & OOD & \textbf{0.89 ± 0.00} & \textbf{0.92 ± 0.02} & \textbf{0.89 ± 0.01} & 0.83 ± 0.00 & \textbf{0.89 ± 0.00} & 0.84 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack{HAM10000}}
& \multirow{2}{*}{0.2} & ID & \textbf{0.82 ± 0.02} & \textbf{0.61 ± 0.08} & 0.80 ± 0.02 & 0.53 ± 0.09 & 0.78 ± 0.02 & 0.38 ± 0.07 & 0.76 ± 0.01 & 0.38 ± 0.04 \\
&  & OOD & \textbf{0.87 ± 0.01} & \textbf{0.68 ± 0.01} & 0.80 ± 0.01 & 0.47 ± 0.03 & 0.79 ± 0.00 & 0.43 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.5} & ID & \textbf{0.86 ± 0.01} & \textbf{0.74 ± 0.03} & \textbf{0.85 ± 0.01} & 0.64 ± 0.01 & 0.84 ± 0.00 & 0.62 ± 0.02 & 0.81 ± 0.00 & 0.64 ± 0.02 \\
&  & OOD & \textbf{0.89 ± 0.00} & \textbf{0.87 ± 0.02} & 0.84 ± 0.01 & 0.62 ± 0.02 & 0.85 ± 0.01 & 0.65 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.8} & ID & \textbf{0.90 ± 0.00} & \textbf{0.88 ± 0.02} & \textbf{0.91 ± 0.00} & 0.87 ± 0.01 & \textbf{0.90 ± 0.00} & 0.84 ± 0.02 & 0.88 ± 0.01 & 0.84 ± 0.00 \\
&  & OOD & \textbf{0.90 ± 0.01} & \textbf{0.93 ± 0.03} & \textbf{0.91 ± 0.01} & 0.86 ± 0.04 & \textbf{0.91 ± 0.00} & 0.85 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack{GTSRB}}
& \multirow{2}{*}{0.2} & ID & \textbf{0.95 ± 0.01} & \textbf{0.92 ± 0.01} & 0.93 ± 0.01 & 0.73 ± 0.01 & 0.80 ± 0.00 & 0.24 ± 0.00 & 0.76 ± 0.01 & 0.24 ± 0.01 \\
&  & OOD & \textbf{0.96 ± 0.00} & \textbf{0.91 ± 0.01} & 0.80 ± 0.00 & 0.23 ± 0.01 & 0.80 ± 0.00 & 0.24 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.5} & ID & \textbf{0.96 ± 0.00} & \textbf{0.95 ± 0.00} & 0.91 ± 0.01 & 0.66 ± 0.02 & 0.88 ± 0.00 & 0.53 ± 0.01 & 0.84 ± 0.01 & 0.53 ± 0.02 \\
&  & OOD & \textbf{0.96 ± 0.00} & \textbf{0.96 ± 0.01} & 0.87 ± 0.00 & 0.53 ± 0.02 & 0.88 ± 0.00 & 0.53 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.8} & ID & 0.93 ± 0.00 & \textbf{0.87 ± 0.03} & \textbf{0.95 ± 0.00} & 0.82 ± 0.00 & \textbf{0.95 ± 0.00} & 0.81 ± 0.01 & 0.92 ± 0.01 & 0.80 ± 0.00 \\
&  & OOD & \textbf{0.94 ± 0.01} & \textbf{0.90 ± 0.01} & \textbf{0.95 ± 0.00} & 0.82 ± 0.01 & \textbf{0.95 ± 0.00} & 0.81 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack{Breast Ultrasound}}
& \multirow{2}{*}{0.2} & ID & \textbf{0.75 ± 0.03} & \textbf{0.71 ± 0.02} & 0.73 ± 0.01 & 0.64 ± 0.06 & \textbf{0.74 ± 0.02} & 0.62 ± 0.01 & 0.74 ± 0.04 & 0.59 ± 0.02 \\
&  & OOD & \textbf{0.76 ± 0.03} & \textbf{0.71 ± 0.04} & 0.73 ± 0.01 & 0.60 ± 0.05 & 0.74 ± 0.02 & 0.64 ± 0.07 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.5} & ID & \textbf{0.81 ± 0.01} & \textbf{0.85 ± 0.01} & 0.77 ± 0.04 & 0.80 ± 0.05 & 0.78 ± 0.05 & 0.78 ± 0.05 & 0.76 ± 0.04 & 0.78 ± 0.03 \\
&  & OOD & \textbf{0.79 ± 0.02} & 0.72 ± 0.05 & 0.77 ± 0.04 & \textbf{0.78 ± 0.09} & \textbf{0.78 ± 0.03} & 0.75 ± 0.07 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.8} & ID & \textbf{0.82 ± 0.02} & \textbf{0.92 ± 0.03} & 0.80 ± 0.04 & 0.88 ± 0.04 & 0.81 ± 0.02 & 0.89 ± 0.03 & 0.75 ± 0.04 & 0.90 ± 0.03 \\
&  & OOD & \textbf{0.82 ± 0.02} & \textbf{0.92 ± 0.04} & 0.81 ± 0.04 & 0.90 ± 0.02 & 0.82 ± 0.04 & \textbf{0.92 ± 0.04} & N/A ± N/A & N/A ± N/A \\
\midrule
\multirow{6}{*}{\shortstack{Axial Organ Slices}}
& \multirow{2}{*}{0.2} & ID & \textbf{0.87 ± 0.01} & \textbf{0.65 ± 0.03} & 0.77 ± 0.01 & 0.34 ± 0.04 & 0.77 ± 0.02 & 0.34 ± 0.06 & 0.76 ± 0.01 & 0.33 ± 0.04 \\
&  & OOD & \textbf{0.84 ± 0.01} & \textbf{0.51 ± 0.04} & 0.76 ± 0.02 & 0.32 ± 0.05 & 0.76 ± 0.00 & 0.30 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.5} & ID & \textbf{0.89 ± 0.01} & \textbf{0.76 ± 0.03} & 0.83 ± 0.00 & 0.56 ± 0.02 & 0.83 ± 0.00 & 0.58 ± 0.01 & 0.80 ± 0.00 & 0.59 ± 0.01 \\
&  & OOD & \textbf{0.88 ± 0.02} & \textbf{0.70 ± 0.03} & 0.83 ± 0.01 & 0.57 ± 0.03 & 0.83 ± 0.00 & 0.58 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
& \multirow{2}{*}{0.8} & ID & \textbf{0.91 ± 0.01} & \textbf{0.87 ± 0.02} & 0.89 ± 0.00 & 0.82 ± 0.01 & 0.89 ± 0.01 & 0.84 ± 0.02 & 0.88 ± 0.00 & 0.84 ± 0.02 \\
&  & OOD & \textbf{0.91 ± 0.01} & \textbf{0.87 ± 0.01} & 0.89 ± 0.00 & 0.84 ± 0.02 & 0.90 ± 0.02 & 0.86 ± 0.02 & N/A ± N/A & N/A ± N/A \\
\midrule
    \multirow{6}{*}{\shortstack{Blood Cell MNIST}}
  & \multirow{2}{*}{0.2} & ID & \textbf{0.89 ± 0.01} & \textbf{0.81 ± 0.05} & 0.88 ± 0.00 & 0.68 ± 0.02 & 0.79 ± 0.00 & 0.37 ± 0.01 & 0.79 ± 0.00 & 0.39 ± 0.01 \\
  &  & OOD & \textbf{0.88 ± 0.03} & \textbf{0.73 ± 0.11} & 0.79 ± 0.00 & 0.30 ± 0.03 & 0.79 ± 0.00 & 0.34 ± 0.03 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.5} & ID & \textbf{0.90 ± 0.01} & \textbf{0.84 ± 0.03} & 0.88 ± 0.00 & 0.65 ± 0.03 & 0.86 ± 0.00 & 0.59 ± 0.01 & 0.84 ± 0.01 & 0.59 ± 0.01 \\
  &  & OOD & \textbf{0.88 ± 0.01} & \textbf{0.69 ± 0.07} & 0.86 ± 0.00 & 0.60 ± 0.02 & 0.86 ± 0.00 & 0.60 ± 0.00 & N/A ± N/A & N/A ± N/A \\
\cmidrule(lr){2-11}
  & \multirow{2}{*}{0.8} & ID & \textbf{0.93 ± 0.01} & \textbf{0.92 ± 0.02} & \textbf{0.93 ± 0.00} & 0.85 ± 0.01 & \textbf{0.93 ± 0.00} & 0.84 ± 0.01 & 0.92 ± 0.01 & 0.85 ± 0.01 \\
  &  & OOD & \textbf{0.93 ± 0.01} & \textbf{0.91 ± 0.01} & 0.92 ± 0.01 & 0.85 ± 0.01 & \textbf{0.93 ± 0.00} & 0.85 ± 0.01 & N/A ± N/A & N/A ± N/A \\
\bottomrule
\end{tabular}
\end{table*}

\end{document}


