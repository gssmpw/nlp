\section{Algorithm for verifying single attention head}

\begin{algorithm}[H]
	\caption{$\softmaxCheck:$ Check the softmax}
	\KwData{$k, \nfree, \aExt, \aDic^{min}, \aDic^{max}, \vExt, \vDic^{min}, \vquery$}
	\KwResult{Verification of $\bot$ or $\top$}
	\lev{We need a \emph{upper bound} on $\aDic$ as well}
	Set
	\[
		w = \frac{\sum_{i\in [k]} \exp(\aDic^{min})}{\sum_{i \in [k]} \exp(\aDic^{max}) +
		\sum_{i \in [\nfree]} \exp(\aExt)}.\;
	\]
	%\lev{Hrmm this kind of implies $w > \half$ so if we get $w$ so large it does not really matter if we have the right associated $v$. Maybe instead of thinking about $\tThresh$ we can phrase it as $\calD_{next}$}\;
 \lev{We need to bound \emph{the subtraction} potential from $\vDic$}
	If $w \cdot \vDic^{min} \geq (1 - w) \cdot \vExt$ return $\top$ otherwise return $\bot$ \;
\end{algorithm}

\begin{algorithm}[H]
	\caption{$\findKRep$: find number of times to repeat token $\tau$ at the end of a free ranging sequence of $\nfree$ tokens to ensure a dictator restriction \lev{We can probably have better bounds vis a vis position by writing an expectation} \lev{re-write in terms of infinity norms}}
	\KwData{$\xQuery, \xDic, \nfree, \klen$}
	\KwResult{Result in $\{\top, \bot\}$}
	Fix $\tQuery = \OneHot(\xQuery), \tDic = \OneHot(\xDic)$	\;
	Let $\pQuery = \OneHot(\nfree + k)$\;
	Let $\aExt = \frac{1}{\sqrt{d}} \max_{i \in [\dVocab]} \left[\tQuery EQK^T E^T \OneHot(i)^T + \norm{\pQuery QK^TP^T}_\infty \right]$ \;
	Let $\aDic^{min} = \frac{1}{\sqrt{d}} \left(\tQuery E_q QK^T E^T \cdot \tDic^T - \norm{\pQuery QK^TP^T}_\infty \right)$ \;
	Let $\aDic^{max} = \frac{1}{\sqrt{d}} \left(\tQuery E_q QK^T E^T \cdot \tDic^T + \norm{\pQuery QK^TP^T}_\infty \right)$ \;
	$\tThresh = \OneHot\left(\arg \max_{i \in [\dVocab]} \tDic \cdot EVOU \cdot \OneHot(i)^T - \norm{PVOU \cdot \OneHot(i)^T}_\infty + \tQuery E_q U \cdot \OneHot(i)^T \right)$ \;
	\lev{TODO: monotonicity theorem necessary}\;
	$\vDic^{min} = \tDic \cdot EVOU \cdot \tThresh^T - \norm{PVOU \cdot \tThresh^T}_\infty + \tQuery E_qU \cdot \tThresh^T$\;
	$\vExt = \max_i \max_j \left(\OneHot(i) \cdot EVOU \cdot \OneHot(j)^T + \norm{PVOU \cdot \OneHot(j)^T}_\infty\right)$\;
	\If{$\vDic^{min} \leq 0$}{
		\Return $\bot$\;
	}
	\Return $\softmaxCheck(k, \nfree, \aExt, \aDic^{min}, \aDic^{max}, \vExt, \vDic^{min})$\;
\end{algorithm}

\subsection{Soundness}

Sketch for proof is using the lemmas below.

\begin{lemma}[Infinity Norm for Positional Encoding Bound]
    Fill in lemma
\end{lemma}
\begin{proof}
    Should be easy \lev{TODO}
\end{proof}

\begin{lemma}[Passing $\softmaxCheck$ line $2$ implies fixing (assuming extremal next-token)]
	Assume that the dictator tokens, $\xDic$, are in location $L \subset [\nfree + k]$ where $|L| = k$ and that for some one hot token, $\vec{t}$, $\tDic \cdot EVOU \cdot \vec{t} + \frac{1}{k} \sum_{\ell \in L} \OneHot(\ell) \cdot PVOU \cdot \vec{t} \geq \vDic^{min}$.
	Also, assume that the token $x$ corresponding to $\vec{t}$ is the maximum of such possible sequences.
	Then if $\softmaxCheck$ return $\top$, we have a dictator sequence where the next token is $x$
\end{lemma}
\begin{proof}
	We begin by noting that	$\vExt$ is the maximum possible value of $(\mathbf{x}E + P_{enc}) VOU \OneHot(j)$ for all possible tokens $j$.
	As such, if $(1 - w) \cdot \vExt < z$ for any $z$, then $(1 - w) \cdot \frac{1}{N} \sum_{a \in N} (T_a \cdot E + P_a \cdot P) VOU \cdot {T'_a}^T < z$ for all settings of tokens $T, T' \subseteq {\{\OneHot(1), \dots \OneHot(\dVocab)\}}^N$ and positions $P \subseteq \{\OneHot(0), \dots \OneHot(\nctx)\}^\nctx$.
	So, if for a token $\vec{t}$, we have that $w \cdot \left[\sum_{i \in L} (\tDic E + \OneHot(L_i)) VOU \cdot \vec{t}^T + \tQuery E_q U \cdot \vec{t} \right] > (1 - w) \cdot \vExt$, then a greedy sampling strategy for the next token will select $\vec{t}$ unless there is a token $\vec{t'}$ where 
	\[
		 \sum_{i \in L} (\tDic E + \OneHot(L_i)) VOU \cdot \vec{t}^T + \tQuery E_q U \cdot \vec{t} > \sum_i (\tDic E + \OneHot(L_i)) VOU \cdot \vec{t}^T + \tQuery E_q U \cdot \vec{t}^T.
	\]
	But then, $\vec{t'}$ is selected irrespective of the non-dictator tokens as well.
	We can also see that 
	\[
		\frac{1}{k} \sum_{i \in L} (\tDic E + \OneHot(L_i)) VOU \cdot \vec{t}^T + \tQuery E_q U \cdot \vec{t}^T \geq \vDic.
	\]
	And so, we have a dictator token.

\end{proof}

\begin{lemma}[Monotonicity of extremal token and $\softmaxCheck$]
	If there is another token which is more likely to be outputted, then the $k$ value should pass even if its smaller
\end{lemma}
\begin{proof}
	Application of the above using $L$...
\end{proof}

\begin{lemma}[Non-extremal next token okay]
	Show how if there is a token with more weight (due to say position reasons) then that's okay)
	Use above lemma
\end{lemma}


\begin{lemma}[Passing $\softmaxCheck$ implies fixing]
	Part of this is assuming all the inputs represent proper bounds \emph{for the predicted token} are correct (does not need to be fixed to the predicted token as monotonicity there)
\end{lemma}

\begin{theorem}[Soundness for $k$]
	Just need to prove that the inputs to $\softmaxCheck$ are indeed extremal
\end{theorem}

\section{Verifying Attention with Parallel Linear Layer}
We will use the following model

\begin{align}
	\mathcal{M}(\textbf{t}) =& \sigma^* 
	       \left( (\tQuery E + \pQuery  P) Q K^T  (P^T + E^T \textbf{x}^T) /\sqrt{d} \right) \cdot (\textbf{x}E+P)VOU + (\tQuery E + \pQuery P)U\\
        &+ \pQuery \cdot \relu((\textbf{x}E + P) A_{enc} + b) A_{dec}
\end{align}

Then,
\begin{align}\label{eq:linlayer}
    \pQuery \cdot \relu((\textbf{x}E + P) A_{enc} + b) A_{dec} = 
    \relu((\tQuery E + \pQuery P) A_{enc} + b) A_{dec}
\end{align}

\cref{eq:linlayer} is fixed by $\pQuery$ and $\tQuery$ being one hot vectors.
We can then use the same technique as before

% TODO: Remove P from inifinty norm (its just VOU)

\lev{TODO: Ask people in AI if sequential or parallel are more popular}

\section{Adding in the Layer Norm}
\lev{Write somewhere that $ \tQuery \cdot \relu(\mathcal{L} \cdot A_{enc} + b) \cdot A_{dec} =  \cdot \relu(\tQuery \cdot \mathcal{L} \cdot A_{enc} + b) \cdot A_{dec}$}
\begin{align*}
	\mathcal{M}(\textbf{t}) =& \sigma^* 
	       \left(\tQuery \mathcal{L} \cdot  Q K^T  \mathcal{L}^T /\sqrt{d} \right) \cdot \mathcal{L} VOU + \tQuery\mathcal{L} U\\
        &+ \tQuery \cdot \relu(\mathcal{L} \cdot A_{enc} + b) \cdot A_{dec}
\end{align*}
where
\[
    \mathcal{L} = LN(\mathbf{x} E + P)
\]
\newcommand{\tild}[1]{\widetilde{#1}}

\lev{Specify normalized normalized all one. Specifify, that everything is entrywise!!...
Maybe fix a column and then write out the operation!}
\newcommand{\LNInp}{\tild{\mathbf{x}}}

We define $LN(\tild{\mathbf{x}})$ as 
\[
	LN(\LNInp) = \frac{\LNInp - \OneMat \cdot \LNInp}{\sqrt{\OneMat \cdot (\LNInp\circ\LNInp) - (\OneMat \cdot \LNInp) \circ (\OneMat \cdot \LNInp) + \eps \cdot \OneMat'}} \cdot \gamma + \beta \cdot \OneMat'
\]

Where $\OneMat \in \mathbb{R}^{\nctx \times \nctx}$ and $\OneMat' \in \mathbb{R}^{\nctx \times \dEmb}$ are the matrices with all ones and $\eps$ is a small constant.

\lev{positional encoding in layer norm make things tricky!}
\lev{Think of layernorm as a left multiplication by a fixed vector/ matrix and fixed offset.}

\lev{I think that bounds here need to bounded in a smarter way. Maybe consider your sequence length of repeated tokens, and then this gives us a much tighter average bound and upper bound for the denominator (simply done by maximizing variance?).}

\subsection{Bounding the Layer Norm Scalars}
Given that layernorm acts \emph{coordinate}-wise (column-wise) in the columns of the input, we can provide bounds per coordinate $c \in [\dEmb]$.

\begin{lemma}[Upper bound on expectation]
	\label{lemma:upperExpBound}
	For a token repeated $\klen$ times with $\nfree$ tokens, the expectation in the layer norm is upper bounded by
	\[
		\frac{\klen \left(\tDic \cdot E \cdot \vec{t}_c^T\right)}{\klen + \nfree} +
			\frac{\nfree \left(\norm{E \cdot \vec{t}_c^T}_\infty\right)}{\klen + \nfree} + \norm{P \cdot \vec{t}_c^T}_\infty.
	\]	
\end{lemma}
\begin{proof}
	The proof follows from a simple expansion expectation and noting that the dictator token is repeated $\klen$ times.
\end{proof}

\begin{lemma}[Lower bound on expectation]
	\label{lemma:lowerExpBound}
	\[
		\frac{\klen \left(\tDic \cdot E \cdot \vec{t}_c^T\right)}{\klen + \nfree} -
			\frac{\nfree \left(\norm{E \cdot \vec{t}_c^T}_\infty\right)}{\klen + \nfree} - \norm{P \cdot \vec{t}_c^T}_\infty.
	\]
\end{lemma}

\begin{lemma}[Upper bound on variance]
	\label{lemma:upperVarBound}
	(Pretty easy by combining bounds on expectation)

	For a token repeated $\klen$ times with $\nfree$ tokens, the variance in the layer norm is upper bounded by
	\[
		AHAHA
	\]
\end{lemma}

\lev{Easier to state lemma below when Layer norm is properly defined column wise}
\lev{add in the epsilon part, epsilon. }
\begin{lemma}[Upper bound on denominator]
    For a token repeated $\klen$ times with $\nfree$ tokens, the denominator in the layer norm is upper bounded by, ignoring the $\eps$,
    % https://stats.stackexchange.com/questions/142651/does-the-uniform-distribution-have-the-greatest-variance-among-all-concave-distr#:~:text=The%20uniform%20distribution%20on%20a,two%20points%20of%20the%20graph).
    \[
	    \frac{\left(\norm{E \cdot \vec{t_c}^T}_\infty + \norm{P \cdot \vec{t_c}^T}_\infty \right)}{\sqrt{3}}.
    \]
\end{lemma}
\begin{proof}
	We first (\lev{TODO: cite}) note that for any random variable bounded in $[-a + b, a + b]$, the standard deviation is at most $a/\sqrt{3}$.
	Then, we can note that the difference between the maximum and minimum of the embedding summed with positional encoding is at most $2(\norm{E \cdot \vec{t_c}^T}_\infty + \norm{P \cdot \vec{t_c}^T}_\infty)$.
 \lev{elaborate a bit maybe?}
\end{proof}

\begin{lemma}[Lower bound on denominator]
	The denominator in the layer norm is lower bounded by, ignoring the $\eps$,
	\[
		AHAHAH %\frac{1}{\sqrt{\nctx}} \sqrt{\sum_{p \in [\nctx]} \left(\min(\vec{t_p} \cdot P \cdot \vec{t_c}^T)\right)^2}
	\]
\end{lemma}
\begin{proof}
	For $E_c = E \cdot \vec{t}_c, P_c = P \cdot \vec{t}_c$, we can rewrite the denominator as the squareroot of
	\begin{align*}
		\OneMat \cdot (xE_c + P_c) \circ (xE_c + P_c) - (\OneMat \cdot (xE_c + P_c)) \circ (\OneMat \cdot (xE_c + P_c)) =& \OneMat \cdot (xE_c \circ xE_c) + \OneMat \cdot (P_c \circ P_c) + 2 \cdot \OneMat \cdot (xE_c \circ P_c)	\\
														 &- (\OneMat \cdot (xE_c))^2 - (\OneMat \cdot P_c)^2 - 2 \cdot (\OneMat xE_c \circ \OneMat P_c).
	\end{align*}
	Then, $\OneMat \cdot(xE_c \circ xE_c) - (\OneMat \cdot xE_c)^2 \geq 0$ and $\OneMat \cdot (P_c \circ P_c) - (\OneMat \cdot P_c)^2$ is a fixed value.

	So, we now must find
	\[
		\min_x (\OneMat \cdot (xE \circ P) - \OneMat xE \circ \OneMat P).
	\]
    \lev{Given series of fixed shifts, can we move the fixed shift back to 0? Look at pairwise differences in $E$ and in $P$ ($O(\dVocab^2$). Write out pairwise matrix, build a bound. Easy to show something about average sequence.
    Worth looking at, is $\beta$ positive? Because otherwise repeated entries get subtracted off}
    \lev{Maybe there is a way to remove the bounds}
\end{proof}

\pagebreak

