\newcommand{\ModelFinal}{\Model^{final}}
\newcommand{\peakToPeak}{\mathrm{PTP}}
\newcommand{\RepIndxs}{\mathcal{R}}
\newcommand{\FreeIndxs}{\mathcal{F}}
\newcommand{\softSumMaxF}{\alpha_{free}^{\max}}
\newcommand{\softSumMinR}{\alpha_{fix}^{\min}}
\newcommand{\softSumMaxR}{\alpha_{fix}^{\max}}
\newcommand{\softSumMinF}{\alpha_{free}^{\min}}

\newcommand{\ssMaxFA}{{\alpha}_{free}^{\max}}
\newcommand{\ssMinRA}{{\alpha}_{fix}^{\min}}
\newcommand{\ssMaxRA}{{\alpha}_{fix}^{\max}}
\newcommand{\ssMinFA}{{\alpha}_{free}^{\min}}


\newcommand{\ssMaxFB}{{\beta}_{free}^{\max}}
\newcommand{\ssMinRB}{{\beta}_{fix}^{\min}}
\newcommand{\ssMaxRB}{{\beta}_{fix}^{\max}}
\newcommand{\ssMinFB}{{\beta}_{free}^{\min}}

\newcommand{\logRMin}{L_{fix}^{\min}}
\newcommand{\logRMax}{L_{fix}^{\max}}
\newcommand{\logFMin}{L_{free}^{\min}}
\newcommand{\logFMax}{L_{free}^{\max}}
\newcommand{\Samp}{\textsf{Samp}}
\newcommand{\varAt}{{\Var_j^{(k)}}}
\newcommand{\varAtMin}{{\Var_{j, \min}^{(k)}}}
\newcommand{\varAtMax}{{\Var_{j, \max}^{(k)}}}
\newcommand{\preSMMax}{\ell_{i, \max}^{(k)}}
\newcommand{\preSMMin}{\ell_{i, \min}^{(k)}}

\section{Input Restrictions and Proving Overwhelming}
\label{sec:meta_framework}

In this section, we will provide an algorithm to decide ``overwhelming."
Along the way, we develop a generalizable method of upper-bounding the worst-case deviation of a single layer of a transformer model under input restriction.

\subsubsection*{Input Restrictions and Designed Space}
We use the notation from \textit{Analysis of Boolean Functions} to denote restrictions on inputs to a function \cite{o2014analysis}.
The restriction will fix certain tokens to be a specific value and leave the rest of the tokens free.

\begin{definition}[Input Restriction, \cite{o2014analysis} definition 3.18]
	\label{def:input_restriction}
	Let $f : \calX^n \rightarrow \calY$ be some function and $J \subset [n]$ and $\notJ = [n] \setminus J$.
	Let $z \in \calX^\notJ$.
	Then, we write $f_{J \mid z} : \calX^J \rightarrow \calY$ (``the restriction of $f$ to $J$ given $z$'') as the subfunction of $f$ that is obtained by fixing the coordinates of $\notJ$ to the values in $z$.
	Given $y \in \calX^J$ and $z \in \calX^\notJ$, we write $f_{J \mid z}(y)$ as $f(y, z)$ even though $y$ and $z$ are not literally concatenated.
\end{definition}

Throughout this paper, we will consider a specific input restriction where the first $\nfix$ tokens are restricted to a string $\desSet$ and the last token is fixed to token $\query$.
We will denote said restriction as $\desF{f}$ where $(\nfix, \nctx)$ denotes the set $\{ \nfix + 1, \ldots, \nctx - 1\}$.

Next, it will be useful to define the set of all possible inputs under an input restriction.

\begin{definition}[Designed Space]
	\label{def:InpSpace}
	Recall, from \cref{def:one_hot_space}, that $\OneHotSpace$ is the set of all one-hot vectors of size $\dVocab$.
	We denote by $\OneHotSpace^n$ the set of matrices where each row is a one-hot vector of size $\dVocab$.
	Then, let $\InpSpace \subset \OneHotSpace^\nctx$ designate the set of all possible inputs under a \textbf{specific} input restriction.
	That is, 
	\[
		\InpSpace = \left\{ X \in \R^{\nctx \times \dVocab} \mid X = 
		\begin{bmatrix}
			\vece_{\desSet_1} \\
			\vece_{\desSet_2} \\
			\vdots \\
			\vece_{\desSet_s} \\
			Y \\
			\vecQuery
		\end{bmatrix}, Y \in \freeSpace
		\right\}.
	\]
	where $\freeSpace$ is the space of free tokens.
\end{definition}
\subsection{Algorithm for deciding Overwhelming}
Here we consider zero temperature sampling setting where we can define our model with sampling as
\[
	\ModelFinal(X) = \arg\max_{i \in [\dVocab]} \Model(X) \cdot \vec{e}_i^T
\]
where $\Model$ is defined in \cref{def:one_layer_transformer}.
The model simply selects the token with the highest logit weight rather than sampling from the output distribution. 
% \footnote{This is equivalent to setting the sampling temperature to zero.}

We define the ``peak-to-peak difference'' to be the difference between the logit for the most likely token and the logit for the second most likely token for sample $X$.

\begin{definition}[Peak-to-peak difference]
    Let $X \in \InpSpace$ be any element from the restriction and $k = \ModelFinal(X)$.
    Then, we let 
    \[
    	\peakToPeak(\Model, X) = \min_{j \in [\dVocab], j \neq k} \Model(X) \cdot \left(\vec{e}_{k}^T - \vec{e}_j^T\right).
    \]
\end{definition}

\iffalse
\begin{algorithm}[H] \label{alg:overwhelmCheck}
	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
	\Input{A fixed single-layer transformer model $\Model$, a string of tokens $s$ denoting a fixed part of the input to $\Model$, integer $\nfree$ denoting the number of free tokens in the input to $\Model$, and a final query token $q$
	}
	\Output{Either the string ``Overwhelmed'' indicating that the output of the model $\Model$ evaluated on $s$ concatenated with $\nfree$ free tokens and query token $q$ is proven to be invariant under the choice of the free tokens, OR the string ``Inconclusive'' if no such proof is obtained.} 

	Calculate a bound $W$ such that $\WD(\vec{e}_\nctx \cdot \desF{\Model}, X) \leq W$ \\
	\If{
		$
		W < \peakToPeak(\desF{\Model}, \InpSpace) / 2
	$ }{\Return ``Overwhelmed''  }

	\Else{\Return ``Inconclusive''}
	\caption{Overwhelmed Verifier - Algorithm Sketch }
\end{algorithm} 
\fi

To prove a model is overwhelmed by a fixed input we bound the worst-case deviation by the peak-to-peak difference.
The following theorem summarizes the bound our algorithm is tasked with verifying. 
\begin{theorem} \label{thm:metathm}
        If
        \[
		\WD(\Model; \InpSpace)_\infty < \peakToPeak(\Model, X) / 2
	\]
        for some $X \in \InpSpace$,
	then the output of $\ModelFinal$ is ``overwhelmed'' under the restriction.
\end{theorem}
\begin{proof}
	As $\ModelFinal$ always selects the token with the maximum logit value, if the coordinate-wise deviation of the restricted model's output never differs by more than $\peakToPeak(\desF{\Model}, X) / 2$ for any $X \in \InpSpace$, the token with the second highest logit value will never exceed that of the token with the highest value.
\end{proof}

Ultimately, we will want to make use of the above theorem alongside \cref{alg:overwhelmCheckDet} to prove the following theorem:
\begin{theorem}[Input Restriction] \label{thm:InpRes}
	%The model $\desF{\ModelFinal}$ over domain $[X]$ if 
	If
    \begin{align*}
	    &\WD(\desF{\Model}; \InpSpace)_\infty
        \\&< \peakToPeak(\desF{\Model}, X) / 2,
    \end{align*}
	then the output of model $\desF{\Model}$ is fixed for all inputs in $\InpSpace$.
	Moreover, we can use \cref{alg:overwhelmCheckDet} to produce an upper bound $W$ for $\WD(\desF{\Model}; \InpSpace)_\infty$.
\end{theorem}

To prove the above theorem, we will:
\begin{itemize}[nosep]
    \item break down the model into its components.
    \item bound the worst-case deviation of each component as a function of the blowup and shift from layer-normalization.
    \item use the triangle inequality of worst-case deviation to bound the worst-case deviation of the model prior to unembedding.
    \item use the Lipschitz constant of the unembedding matrix to bound the worst-case deviation of the model.
\end{itemize}
The formal proof can also be found in \cref{subsec:InpResProof}.

\begin{algorithm}[tb] 
	\caption{Algorithm for deciding Overwhelming}
	\label{alg:overwhelmCheckDet}
	\begin{algorithmic}
		\STATE {\bfseries Input:}  Model $\Model$, fixed string $s$, contenxt length $\nctx$, query token $q$.
		\STATE {\bfseries Output:} ``Overwhelmed'' or ``Inconclusive''.
		\STATE
		\STATE Calculate $B^{\min}, B^{\max}, S^{\min}, S^{\max}$ as in \cref{def:blowup_shift}.
            \STATE Calculate pre-softmax extremal logit values $\ell^{\min}$ and $\ell^{\max}$ via \cref{alg:lminlmax}.
		\STATE Using the above, calculate $\ssMaxRB$ and $\ssMinRB$ as in \cref{def:soft-extrem-values} and \cref{lem:min_max_softmax}.
		\STATE Calculate upper-bound $W^{\attn}$ as in \cref{lem:att_bound}.
		\STATE Calculate upper-bound $W^{\fenc}$ as in \cref{lem:WD_fenc}.
		\STATE Calculate \begin{align*}
			&W = \Lip(\Unembed) \\
                &\cdot \left(W^{\attn} + \LipMLP_\infty \cdot W^{\fenc} + W^{\fenc}\right)
		\end{align*}
		as per \cref{lem:mlpbound} and 
		\STATE Sample $X \gets \InpSpace$
		\IF{$W < \peakToPeak(\desF{\Model}, X) / 2$ }
		\STATE Return ``Overwhelmed''
		\ELSE
		\STATE Return ``Inconclusive''
		\ENDIF
	\end{algorithmic}
\end{algorithm}


%
%\begin{algorithm}[H] \label{alg:overwhelmCheckDet}
%	\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
%	\Input{A fixed single-layer transformer model $\Model$, a string of tokens $s$ denoting a fixed part of the input to $\Model$, integer $\nctx$ denoting the number of total tokens in the input to $\Model$, and a final query token $q$.}
%	\Output{Either the string ``Overwhelmed'' indicating that the output of the model $\Model$ evaluated on $s$ concatenated with $\nfree$ free tokens and query token $q$ is proven to be invariant under the choice of the free tokens, OR the string ``Inconclusive'' if no such proof is obtained.} 
%	Calculate $B^{\min}, B^{\max}, S^{\min}, S^{\max}$ as in \cref{def:blowup_shift}.
%	\\
%	Calculate $\ssMaxRB$ and $\ssMinRB$ as in \cref{def:soft-extrem-values} and \cref{lem:min_max_softmax}.
%	\\
%	Calculate \begin{align*}
%		W^{\attn} &= 2 \cdot (\ssMaxRB - \ssMinRB) \cdot \left(\max_{B \in [B^{\min}, B^{\max}]} \|E[\desSet \cup \{q\}, j] \cdot \diag(B)\|  + \max(\norm{S^{\min}}_\infty, \norm{S^{\max}}_\infty \right) \\
%			  &+ 2 \cdot \ssMaxFB \cdot \max_{B, S} \norm{(E B + S) \cdot V}_{\frobInf}
%	\end{align*}
%	as in \cref{lem:att_bound}.
%	\\
%	Calculate  $W^{\fenc} = \max_{t \in [\dVocab]} 
%	\max_{j \in [\dEmb]}
%	\max_{B \in [\vec{0}, B^{\max} - B^{\min}]}
%	\left|X[t] \cdot \Embed \cdot \diag(B) \cdot \vec{e}_j\right| + S_j^{\max} - S_j^{\min}$ as per \cref{lem:worst_case_deviation}.
%	\\
%	Calculate $W = \Lip(\Unembed) \cdot \left(W^{\attn} + \LipMLP_\infty \cdot W^{\fenc} + W^{\fenc}\right)$ 
%	as per \cref{lem:mlpbound} and 
%	\\
%	Calculate $\peakToPeak(\desF{\Model}, \InpSpace)$ by evaluating $\desF{\Model}$ on $X \gets \InpSpace$ \\
%	\If{
%	$W < \peakToPeak(\desF{\Model}, \InpSpace) / 2$ }{\Return ``Overwhelmed''
%}
%\Else{\Return ``Inconclusive''}
%
%\caption{Algorithm for deciding Overwhelming}
%\end{algorithm} 



\subsection{Proof Overview of \cref{thm:InpRes} (Algorithm Correctness)} \label{sec:algoCorrectness}
The proofs for all the lemmas and statements in this section are deferred to \cref{sec:proofs_framework}.

\subsubsection*{Breaking Down the Model}
Discussing normalization as a function of expectation and variance is a bit cumbersome.
So, we will first define an analagous ``blowup'' and ``shift'' for normalization.

\begin{definition}[Blowup and Shift Sets]
	\label{def:blowup_shift}
	For some $X \in \InpSpace$, Let $B_j(X)$ (for blowup) denote
	\[
		\frac{1}{\sqrt{\Var[X \Embed \cdot e_j^T] + \eps}} \cdot \gamma
	\]
	and let $S_j(X)$ (for shift) denote
	\[
		\frac{-\E[X \Embed \cdot e_j^T]}{\sqrt{\Var[X \Embed \cdot e_j^T] + \eps}} \cdot \gamma + \beta.
	\]
	We define $\blowupSet_j = \{B_j(X) | X \in  \InpSpace \}$, and  $\shiftSet_j  = \{S_j(X) | X \in  \InpSpace \}$.
	Moreover, for ease of notation, we will define
	\[
		\blowupSet = \{ (B_1(X), \dots, B_\dEmb(X) \mid X \in \InpSpace\}
	\]
	\[
		\shiftSet = \{ (S_1(X), \dots, S_\dEmb(X)) \mid X \in \InpSpace \}
	\]
	and the set $\blowupSet\shiftSet$ to equal
	\[
		\left\{ \bigg((B_1(X), \dots, B_\dEmb(X)), (S_1(X), \dots, S_\dEmb(X))\bigg)  \right\}
	\]
	where $X \in \InpSpace$.
	Finally, let $B^{\min}_j = \min(\blowupSet_j) $, $B^{\max}_j = \max(\blowupSet_j)$, $S^{\min}_j = \min(\shiftSet_j)$ and $S^{\max}_j = \max(\shiftSet_j)$.
\end{definition}

We will now break down the model in a way such that it is easier to analyze.
For component $\component \in \{\attn, \MLP, \Iden\}$, we will use $f^{\component} : \OneHotSpace^\nctx \times \blowupSet\shiftSet \to \R^{\nctx \times \dVocab}$ to denote the following function:
\[
	f^{\component}(X, (B, S)) = \component \circ \fenc(X, (B, S)) 
\]
where
\[
	\fenc(X, (B, S)) = (X \cdot \Embed \cdot \diag(B) + S).
\]
Note that $\fenc(X, (B(X), S(X)))$ is exactly equal to $\LayerNorm(X \cdot \Embed)$ for layernorm function $\LayerNorm$.

We can rewrite our model as
\[
    \Model = \Unembed \circ (f^{\attn} + f^{\MLP} + f^{\Iden}) 
\]
and so, by the monotonicity of lifting for worst-case deviation,
\begin{align*}    
    &\WD(\desF{\Model}; \InpSpace) \\
    \leq& \sum_{\component} \WD(\Unembed \cdot \vec{e}_\nctx \cdot \desF{f^{\component}}; \InpSpace \times \blowupSet \shiftSet)
\end{align*}
for $\component \in \{\attnH, \MLP, \Iden\}$.


% To bound the output behavior of a single-layer transformer model, we will need to bound the components of the model to get a valid upper bound $W$ on worst-case deviation where  $W$ is the calculated upper-bound in \cref{alg:overwhelmCheckDet}.

% We can then use Lipschitz constant for the unembedding matrix to get
% \begin{align*}
% 	&\WD(\desF{\Model}; \InpSpace)
%     \\ &\leq \sum_{\component} \WD(\Unembed \cdot \vec{e}_\nctx \cdot \desF{f^{\component}} ; \InpSpace \times \blowupSet \shiftSet)_\infty \\
% 			  &\leq
% 			  \Lip(\Unembed)_\infty \sum_{\component} \WD(\vec{e}_\nctx \cdot \desF{f^{\component}} ; \InpSpace \times \blowupSet \shiftSet)_\infty \\
% 			  &\leq \frac{1}{2} \cdot \peakToPeak(\desF{\Model}, X).
% \end{align*}
% for a large enough $\ndes$.

\subsubsection{Bounding Blowup and Shift}
We can get rather straightforward bounds on the blowup and shift of the model.
\begin{lemma}[Blowup and Shift Bounds]
	\label{lem:boundsBS}
	We bound blowup and shift: for every $B_j \in \blowupSet_j$ and $S_j \in \shiftSet_j$
	\[
		\frac{\gamma}{\sqrt{\Var_j^{\max} + \eps}} \leq B_j \leq \frac{\gamma}{\sqrt{\Var_j^{\min} + \eps}}
	\]
	and
	\begin{align*}
	&\min\left(B_j^{\min} \mu_j^{\min}, B_j^{\min} \mu_j^{\max}, B_j^{\max}, \mu_j^{\min}, B_j^{\max} \mu_j^{\max}\right)
	\leq
	S_j\\
	&\leq
	\max\left(B_j^{\min} \mu_j^{\min}, B_j^{\min} \mu_j^{\max}, B_j^{\max}, \mu_j^{\min}, B_j^{\max} \mu_j^{\max}\right)
	\end{align*}
	where $\mu^{\min}_j, \mu^{\max}_j$ are the lower and upper bounds on the expectation of the $j$-th column of $X \cdot \Embed$. $\Var_j^{\min}, \Var_j^{\max}$ are similarly defined for the variance.
    Both are bounded in \cref{lem:boundsVar} within \cref{sec:proofs_framework}.
\end{lemma}
Moreover, we let $B^{\min}$ be a vector of the minimum values of the blowup and $B^{\max}$ be a vector of the maximum values of the blowup.
Define $S^{\min}$ and $S^{\max}$ similarly for the shift.

\subsubsection{Bounding Attention}
\label{subsec:attention_bounds}
For a multi-headed attention mechanism, $\attn(X) = [\attnH_1(X); \ldots; \attnH_H(X)]$: i.e.\ the output is a concatenation of the individual attention head outputs.
So, the infinity norm worst-case deviation is simply bounded by the maximum worst-case deviation over the individual attention heads.
We thus have the following lemma:
\begin{lemma}
	\label{lem:att_bound_by_heads}
	\begin{align*}
		&\WD(\vec{e}_\nctx \cdot \desF{f^{\attn}} ; \InpSpace \times \blowupSet \shiftSet)_\infty 
	     \\ &\leq 
	     \max_h \WD(\vec{e}_\nctx \cdot \desF{f^{\attnH_h}} ; \InpSpace \times \blowupSet \shiftSet)_\infty.
	\end{align*}
\end{lemma}
The rest of this section will focus on bounding the worst-case deviation of a single attention head which will be the most challenging part of the proof.

We will show how to bound the contribution of each token to the attention weights by:
(1) establishing bounds for the attention weight coming from fixed tokens to the query token, (2) establishing an upper bound for the attention weight coming from free tokens to the query token.
We can then demonstrate that the attention weights are heavily biased towards the fixed tokens.

We implicitly consider rotary-type positional encodings in the attention mechanism, where the positional encodings are absorbed into the calculation of the logits.
As previously mentioned, we use $\ell$ to denote the logits on the query token.  It will be useful, in the proof of our results, to define and compute worst-case upper and lower bounds for $\ell$, which we define formally in \cref{def:lminlmax}.
% Denote the minimum and maximum values of the logits as $\ell^{\min}$ and $\ell^{\max}$ respectively.
To obtain bounds $\ell^{\min}$ and $\ell^{\max}$, we provide a simple algorithm in \cref{alg:lminlmax} to compute a bound on the logits:
\begin{lemma}[Bounds on Logits]
	\label{lem:lminlmax}
	Algorithm~\ref{alg:lminlmax} computes the minimum and maximum values of the logits $\ell$ given point-wise bounds $B^{\min}$, $B^{\max}$, $S^{\min}$, and $S^{\max}$ as specified in \cref{lem:boundsBS}.
\end{lemma}
% \vspace{-0.2cm}


% In the following lemmas, we represent the positions of restricted tokens (including the query token) as elements of the set $\{1, 2, \dots, \nfix \} \cup \{ \nctx \}$ (denoted by $[\nfix] \cup \{\nctx\}$), and the free tokens (including the query token for simplicity) as elements of the set $\{\nfix + 1, \ndes+2, \dots, \nctx - 1\}$ (denoted by $(\nfix, \nctx)$).
% \footnote{Technically, the query token is part of the restriction.
% However, to simplify the notation and the proof, we consider the query token as a free token without loss of generality.}

We now define the most consequential value to bound the worst-case deviation of the attention mechanism.
\begin{definition}[Softmax Extremal Values]\label{def:soft-extrem-values}
	Let $\softSumMinF = \sum_{j \in (\nfix, \nctx)} e^{\ell_j^{\min}}$ and $\softSumMaxF = \sum_{j \in (\nfix, \nctx)} e^{\ell_j^{\max}}$.
	Similarly, let $\softSumMinR = \sum_{i \in [\nfix] \cup \{\nctx\}} e^{\ell_i^{\min}}$ and $\softSumMaxR = \sum_{i \in [\nfix] \cup \{\nctx\}} e^{\ell_i^{\max}}$.
	Then, 
	\[
		\ssMinFB = \frac{\softSumMinF}{\softSumMaxR + \softSumMinF} \quad \text{and} \quad \ssMaxFB = \frac{\softSumMaxF}{\softSumMinR + \softSumMaxF}
	\]
	and
	\[
		\ssMinRB = \frac{\softSumMinR}{\softSumMinR + \softSumMaxF} \quad \text{and} \quad \ssMaxRB = \frac{\softSumMaxR}{\softSumMaxR + \softSumMinF}.
	\]
	%Let the lower-bound (resp. upper-bound) for softmax in \cref{eq:softmax_upper} be $\ssMinFB$ ($\ssMaxRB$) and
	%the lower-bound (resp. upper-bound) of softmax in \cref{eq:softmax_lower} be $\ssMinRB$ ($\ssMaxRB$).
\end{definition}

These extremal values can be used to get the bounds:

\begin{lemma}[Minimum and Maximum after Softmax]
	\label{lem:min_max_softmax}
	\begin{equation}
		\label{eq:softmax_upper}
		\ssMinFB \leq
		\sum_{j \in (\nfix, \nctx)} \softmax(\ell_j) \leq
		\ssMaxFB
	\end{equation}
	aswell as,
	\begin{align}
		\label{eq:softmax_lower}
		\ssMinRB \leq
		\sum_{j \in [\nfix] \cup \{\nctx\}} \softmax(\ell_j) \leq
		\ssMaxRB.
	\end{align}
\end{lemma}


In the following, $E[[\nfix] \cup \{\nctx\}, :] \in \R^{\nfix \times \dEmb}$ denotes the matrix with the rows in $[\nfix] \cup \{\nctx\}$ selected. 

\begin{lemma}[Worst-case Deviation of Attention]
	\label{lem:att_bound}
	Worst-case deviation of attention is bounded as follows,
	\begin{align*}
		&\WD(\vecNctx \cdot f^{\attnH}_{\ndes \mid r, q} ; \InpSpace \times \blowupSet \shiftSet)_\infty
	     \\ &\leq
	     2 \cdot (\ssMaxRB - \ssMinRB) \cdot \\
         &\max_{B, S}\norm{\Embed[[\nfix] \cup \{\nctx\}, :] \cdot \diag(B) + S}_{\frobInf} \\
		&+ 2 \cdot \ssMaxFB \cdot \max_{B, S} \norm{(E \cdot \diag(B) + S) \cdot V}_{\frobInf}\\
		&+ \norm{V}_\infty \cdot \ssMaxFB \cdot \max_{t \in s \cup \{q\}} \WD(\fenc; \{\vece_t \} \times \blowupSet \shiftSet\}))_\infty
	\end{align*}
        where $V$ is the value matrix in the attention head (see \cref{sec:appendix_model}).
\end{lemma}

Building on the above, we obtain a worst-case deviation bound using point-wise upper and lower bounds on $B \in \blowupSet$ and $S \in \shiftSet$.

%\begin{definition}[$B^{\min} $, $B^{\max}$, $S^{\min}$ ,$S^{\max}$]

%\end{definition}
\begin{corollary} \label{cor:Bmax} 
	Let $B^{\min} $, $B^{\max}$, $S^{\min}$, and $S^{\max}$ be as defined at the end of Definition \ref{def:blowup_shift}.
	Then, we have
	\begin{align*}
		\WD&(\vecNctx \cdot f^{\attnH}_{\ndes \mid r, q} ; \InpSpace \times \blowupSet \shiftSet)_\infty \leq  \\
		   & 2 \cdot (\ssMaxRB - \ssMinRB) \cdot \bigg(\max_{B \in [B^{\min}, B^{\max}]} \|E[[\nfix] \cup \{\nctx\}, :] \\
		   &\cdot \diag(B)\|_{\frobInf}  
	   + \max\big(\|{S^{\min}}\|_\infty, \|{S^{\max}}\|_\infty \big)\bigg) \\
		   &+ 2 \cdot \ssMaxFB \cdot \max_{B, S} \norm{(E B + S) \cdot V}_{\frobInf} \\
		   &+ \norm{V}_\infty \cdot \ssMaxFB \cdot \max_{t \in s \cup \{q\}} \WD(\fenc; \{\vece_t\} \times \blowupSet \shiftSet))_\infty
	\end{align*}
	where the maximization can be calculated with a simple linear program
    \footnote{
        We use the notation $B \in [B^{\min}, B^{\max}]$ to denote the set of vectors, $B$, where $B_j^{\min} \leq B_j \leq B_j^{\max}$.
    }.
\end{corollary}


\subsubsection{Bounding MLP and Identity}
Because the MLP and identity components are simple feed-forward networks without any ``cross-talk'' between tokens, we can use simple Lipschitz bounds.

\begin{lemma}[Worst-case Deviation of MLP and Identity]
	\label{lem:mlpbound}
	\begin{align*}
		\WD(\vec{e}_\nctx \cdot \desF{f^{\MLP}} ; \InpSpace \times \blowupSet \shiftSet)_\infty 
		\\ \leq
		\LipMLP_\infty \cdot \WD(\vec{e}_\nctx \cdot  \fenc; \InpSpace \times \blowupSet \shiftSet)_\infty
	\end{align*}
	and
	\begin{align*}
		\WD(\vec{e}_\nctx \cdot \desF{f^{\Iden}}  ; \InpSpace \times \blowupSet \shiftSet)_\infty \\ = \WD(\vec{e}_\nctx \cdot \fenc; \InpSpace \times \blowupSet \shiftSet)_\infty.
	\end{align*}
\end{lemma}

