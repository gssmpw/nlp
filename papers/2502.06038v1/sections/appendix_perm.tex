\section{Appendix for Permutation Invariance}
\label{sec:appendix_perm}

\begin{algorithm}[tb] 
	\caption{Naive Algorithm to find $\ssMinFA$.\\
		To find $\ssMaxFA$, switch the $\min$ to a $\max$ in the objective.
	}
	\label{alg:naiveAlpha}
	\begin{algorithmic}
	\STATE \textbf{Input:} {$\fenc$ and model $\Model$}
	% \Output{\lev{TODO}}
	Let $\fenc(\vec{e}) = \vec{e} \cdot \Embed \cdot \diag(B) + S$ \\
	\FOR{$k \in (\ndes, \nctx]$}
	\STATE {
		Set \begin{align*}
			\vec{\ell}^{\min}_k = \frac{1}{\sqrt{\dEmb}} \min_{t \in \freeToks} 
			\fenc(\vecQuery) \cdot Q \PosRot_{k, \nctx} K^T \cdot \fenc(\vec{e}_t)^T
		\end{align*}
	}
	\ENDFOR
	\STATE Return $\ssMinFA = \sum_k \exp\left(\vec{\ell}^{\min}_k\right)$
	\end{algorithmic}
\end{algorithm}

\subsection{Proof of Attention Worst-Case Deviation}
In this subsection, we provide a proof of \cref{lem:corrAlpha} and \cref{lem:attn_perm}.
First, we prove the correcntess of the algorithms to find $\ssMinFA$ and $\ssMaxFA$.
\begin{lemma}[Restatement of \cref{lem:corrAlpha}]
	 Both \cref{alg:LPAlpha} and \cref{alg:naiveAlpha} provide valid bounds on $\ssMinFA$ and $\ssMaxFA$.
\end{lemma}
\begin{proof}
	We provide a proof for $\ssMinFA$; the proof for $\ssMaxFA$ is analogous.

	First note that the blowup and shift are fixed and thus $\fenc$ is only a function of the its input token: i.e.\ we can rewrite $\fenc(\vec{e}_t, BS)$ as $\fenc(\vec{e}) = \vece \cdot E \cdot \diag(B) + S$ for fixed $B$ and $S$.
	Then, for the naive algorithm, \cref{alg:naiveAlpha}, the correctness follows from the fact that the minimum possible logit value from each position can be calculated by enumerating over all the free tokens.

	For the LP-based algorithm, \cref{alg:LPAlpha}, we first consider the LP as an integer linear program.
	Consider the permutation matrix $X$ with entries $x_{j, t}$, where $x_{j, t} = 1$ if token $t$ is selected for position $j$ and $x_{j, t} = 0$ otherwise.
	Then, the LP can be seen as finding the permutation matrix which minizes the objective function, $\ssMinFA$.
	So, the relaxed LP is a lower bound on the integer LP which is a lower bound on the true value of $\ssMinFA$.
\end{proof}

We now restate the lemma for the worst-case deviation of attention.
\begin{lemma}
	Worst-case deviation of attention is bounded as follows for fixed blowup $B$ and shift $S$ when considering the permutation class $[X]$ with free tokens $\freeToks$:
	\begin{align*}
		&\WD(\vecNctx \cdot f^{\attnH}_{\ndes \mid r, q} ; \InpSpace \times \blowupSet \shiftSet)_\infty
	     \\ &\leq
		2 \cdot (\ssMaxRB - \ssMinRB) \cdot \norm{\Embed[[\nfix] \cup \{\nctx\}, :] \cdot B + S}_{\frobInf} \\
		&+ 2 \cdot \ssMaxFB \cdot \norm{(E[(\nfix,\nctx),: ] B + S) \cdot V}_{\frobInf}.
	\end{align*}
\end{lemma}
\begin{proof}
	The proof follows analogously to the proof of \cref{lem:att_bound} (bound on worst-case deviation of attention in the generic case).
	The main difference is that we have a singleton set for the blowup and shift and that we restrict the free tokens.
	First, this implies that the restriction of $\blowupSet, \shiftSet$ to singelton sets means that no optimization over blowup and shift are needed in the bounds as the blowup and shift become constants.
	Second, the restriction of the free tokens means that the worst-case contribution from the value function, $(E \diag(B) + S \cdot V)$, is restricted to the embeddings selected by the free tokens.
	So, we replace $\norm{E \diag(B) + S \cdot V}_{\frobInf}$ with $\norm{(E[(\nfix,\nctx),: ] \diag(B) + S) \cdot V}_{\frobInf}$.
	Moreover, $\WD(\fenc; \{\vece_t\} \times \blowupSet \shiftSet)_\infty = 0$ as the blowup and shift are fixed and so we can drop the last term in the bound in \cref{lem:att_bound}.
\end{proof}

\subsection{Proof of \cref{thm:InpResPermInv}}
\label{subsec:proofInpResPermInv}
We first restate the theorem for convenience.
\begin{theorem}
	If
	\[
		\WD(\desF{\Model}; [X])_\infty < \peakToPeak(\desF{\Model}, X) / 2
	\]
	then the output of model $\desF{\Model}$ is fixed for all inputs in $[X]$.
	Moreover, we \cref{alg:overwhelmCheck2} in \cref{sec:appendix_perm} produces an upper bound $W$ for $\WD(\desF{\Model}; \InpSpace \times \blowupSet \shiftSet)_\infty$.
\end{theorem}
\begin{proof}
	The proof follows analogously to the proof of \cref{thm:InpRes} in \cref{subsec:InpResProof}.
	The key difference is that, due to the fixing of the blowup and shift, the bound on $W$ simplifies.
	First, the worst-case deviation of $\vece_{\nctx} \cdot \fenc(X)$ is $0$ as the blowup and shift are fixed.
	So, the worst-case deviation of the MLP and identity function are $0$ as well.
	Then, algorithm uses either \cref{alg:naiveAlpha} or \cref{alg:LPAlpha} to find bounds on the extremal values of attention with provable correctness as per \cref{lem:corrAlpha}.
	Next, the algorithm simplified worst-case deviation of attention (as per \cref{lem:attn_perm}) to bound the worst-case deviation of attention.
	Finally, the algorithm uses the Lipschitz constant of the unembedding function, invoking \cref{lemma:worst_case_deviation_properties}, to bound the worst-case deviation of the model.
\end{proof}
