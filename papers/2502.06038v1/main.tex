\documentclass{article}
\pdfoutput=1
\usepackage{Custom}
%\usepackage{Custom2}
\usepackage{icml2025/fancyhdr}
\usepackage{icml2025/algorithm}
\usepackage{icml2025/algorithmic}
\usepackage[accepted]{icml2025/icml2025}
\usepackage{listings}
\usepackage{multicol}
\usepackage{authblk}
\usepackage{multirow}
\bibliographystyle{icml2025/icml2025}


%\date{today}
\title{\bfseries\Large
    Provably Overwhelming Transformer Models with Designed Inputs
}

\renewcommand\Affilfont{\fontsize{9}{10.8}\itshape}

%\author[1, 2]{Lev Stambler{\href{mailto:levstamb@umd.edu}{levstamb@umd.edu}}}
%\author[1, 2]{Seyed Sajjad Nezhadi}
%\author[1, 2, 3]{Matthew Coudron}
%
%\affil[1]{Joint Center for Quantum Information and Computer Science, University of Maryland}
%\affil[2]{Department of Computer Science, University of Maryland}
%% \affil[3]{Neon Tetra LLC}
%\affil[3]{National Institute of Standards and Technology}
% If you read this, I hope that you are having a nice day!

\newcommand{\mnote}[1]{{\highlightname{Matt C.}{#1}{blue}}}
\newcommand{\snote}[1]{{\highlightname{Sajjad}{#1}{red}}}
\newcommand{\mkd}[1]{{\highlightname{Matt K}{#1}{orange}}}
\newcommand{\lev}[1]{{\highlightname{Lev}{#1}{purple}}}
\newcommand{\claude}[1]{{\highlightname{Claude}{#1}{green}}}

 %\renewcommand{\mnote}[1]{}
 %\renewcommand{\snote}[1]{}
 %\renewcommand{\mkd}[1]{}
 %\renewcommand{\lev}[1]{}
 %\renewcommand{\claude}[1]{}



% Worst-Case Over-Squashing Proofs for Transformer Models
% Provably Overwhelming Transformer Models with Designed Inputs

\icmltitlerunning{
    Provably Overwhelming Transformer Models with Designed Inputs
}
\begin{document}
\sloppy


\twocolumn[
\icmltitle{
    Provably Overwhelming Transformer Models with Designed Inputs
}
\begin{icmlauthorlist}
	\icmlauthor{Lev Stambler}{Quics,UMD,NT}
	\icmlauthor{Seyed Sajjad Nezhadi}{Quics,UMD,Iluvatar}
	\icmlauthor{Matthew Coudron}{Quics,UMD,NIST}
\end{icmlauthorlist}
\icmlaffiliation{Quics}{Joint Center for Quantum Information and Computer Science, University of Maryland}
\icmlaffiliation{UMD}{Department of Computer Science, University of Maryland}
\icmlaffiliation{NIST}{National Institute of Standards and Technology}
\icmlaffiliation{NT}{Neon Tetra LLC}
\icmlaffiliation{Iluvatar}{iluvatar Technologies}
\icmlcorrespondingauthor{Lev Stambler}{levstamb@umd.edu}


\icmlkeywords{ML Theory, Formal Guarantees, Transformers, Interpretability, Machine Learning, ICML}

\vskip 0.3in
]
\numberwithin{theorem}{section}  % This links theorem numbers with section numbers

\theoremstyle{plain}     % For theorems, lemmas, etc.


% \maketitle

\input{sections/commands.tex}

\printAffiliationsAndNotice{} % otherwise use the standard text.

\iffalse
\begin{abstract}
We develop an algorithm which, given a trained single-layer transformer model $\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$ and an integer $n_{free}$, can generate a mathematical proof that $\mathcal{M}$ is ``overwhelmed'' by $s$.
We say that $\mathcal{M}$ is ``overwhelmed'' by $s$ when the output of the model evaluated on this string plus any additional string $t$, $\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$ whenever $\text{length}(t) \leq n_{free}$.
   
An exhaustive approach to verifying such a worst-case statement would require time exponential in $n_{free}$, but our approach uses a carefully designed analysis of Lipschitz continuity, combined with convex relaxations to produce a worst-case proof in time and space $\widetilde{O}(n_{fix}^2 + n_{free}^3)$. 
Along the way, we prove a particularly strong worst-case form of ``over-squashing'' \cite{alon2021bottleneckgraphneuralnetworks, barbero2024transformers}, which we use to bound the model's behavior.

Our technique uses computer-aided proofs to establish this type of operationally relevant guarantee about transformer models.
We empirically test our algorithm on a single layer transformer complete with an attention head, layer-norm, MLP/ReLU layers, and RoPE positional encoding.
For this model, our algorithm produces proofs of natural overwhelming strings when the ``free string'' is restricted to be an element of a permutation set.  

We believe that this work is a stepping stone towards the difficult task of obtaining useful guarantees for trained transformer models.
For example, ``overwhelming'' strings can be used to prove no-go results for prompt engineering: no ``prompt'' can equip a model $\mathcal{M}$ to properly execute specific tasks like correcting errors in code.
\end{abstract}
\fi

\begin{abstract}
We develop an algorithm which, given a trained transformer model $\mathcal{M}$ as input, as well as a string of tokens $s$ of length $n_{fix}$ and an integer $n_{free}$, can generate a mathematical proof that $\mathcal{M}$ is ``overwhelmed'' by $s$, in time and space $\widetilde{O}(n_{fix}^2 + n_{free}^3)$.
We say that $\mathcal{M}$ is ``overwhelmed'' by $s$ when the output of the model evaluated on this string plus any additional string $t$, $\mathcal{M}(s + t)$, is completely insensitive to the value of the string $t$ whenever length($t$) $\leq n_{free}$.
Along the way, we prove a particularly strong worst-case form of ``over-squashing'' \cite{alon2021bottleneckgraphneuralnetworks, barbero2024transformers}, which we use to bound the model's behavior.
Our technique uses computer-aided proofs to establish this type of operationally relevant guarantee about transformer models.
We empirically test our algorithm on a single layer transformer complete with an attention head, layer-norm, MLP/ReLU layers, and RoPE positional encoding.
We believe that this work is a stepping stone towards the difficult task of obtaining useful guarantees for trained transformer models.
\end{abstract}

%%%%%% general TODOs
% \pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{sections/intro.tex}
\input{sections/notation.tex}
\input{sections/model.tex}
\input{sections/framework.tex}
\input{sections/technical_precurse.tex}
\input{sections/concrete_case.tex}
\input{sections/model_collapse.tex}
\input{sections/model_eval.tex}
\input{sections/conclusion.tex}

%\input{sections/find_k_alg.tex}
%\include{sections/list_of_ideas}
%\include{sections/notes}

\bibliography{cubebib}

\appendix
\onecolumn
\input{sections/appendix_plots.tex}
\input{sections/appendix_model.tex}
\input{sections/appendix_framework.tex}
\input{sections/appendix_techincal.tex}
\input{sections/appendix_perm.tex}
\input{sections/appendix_det_eps.tex}


\end{document}
