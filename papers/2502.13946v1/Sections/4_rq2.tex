\section{How Does TASA Cause Inference-time Vulnerabilities of LLMs}
\label{sec:rq2}


While TASA has been broadly observed across various safety-tuned LLMs, its role in causing vulnerabilities, particularly in the context of jailbreak attacks, remains unclear. To investigate this, we address two key questions: First, to what extent does TASA influence the model's initial output and affect its overall safety? Second, how is TASA connected to jailbreak attacks during generation?

\input{Figures/fig4}

\input{Figures/fig6}


\subsection{TASA's Impact on Response Generation}
\label{subsec:tasa_resp}

To investigate the impact of TASA on the model's safety capability, we intervene in the information from template positions during response generation for harmful requests, and evaluate whether the model can still produce refusal responses.



\paragraph{Method.} 
During the forward process of each token in the response, we replace the value states of a specific proportion of attention heads at template positions with the corresponding value states from processing the harmful input (See \Cref{appendix:temp_patch}).
We refer to this operation as \textsc{TempPatch} and evaluate its performance on the Harmbench test set. For comparison, we also evaluate three representative jailbreak attack methods: (1) \textbf{AIM} \cite{wei2023jailbroken}, a carefully crafted attack prompt; (2) \textbf{PAIR} \cite{chao2023jailbreaking}, which iteratively optimizes attack instructions using an attacker LLM; and (3) \textbf{AmpleGCG} \cite{liao2024amplegcg}, an efficient approach for generating adversarial suffixes \cite{zou2023universal} (See \Cref{appendix:jb_details}). To assess compliance, we employ a compliance detector \cite{xie2024sorry} to identify whether the model complies with the provided inputs. The effectiveness of each method is measured by the \textit{attack success rate} (\textbf{ASR}), defined as the proportion of inputs for which the model complies.



\paragraph{Results.} 
As shown in \Cref{fig:asr_eval}, \textsc{TempPatch} significantly increases the ASRs of LLMs, achieving results that are comparable to or even surpass those of other specialized jailbreak attack methods. These findings further validate the deep connection between TASA and the safety mechanisms of LLMs. Moreover, while other attack methods demonstrate limited effectiveness against certain models, particularly the Llama-3 8B and 3B variants, \textsc{TempPatch} achieves notably higher ASR in comparison. This contrast suggests that \subconc{what might seem like stronger safety alignment could actually depend more on shortcut-based safety mechanisms, which may potentially introduce unseen vulnerabilities when faced with scenarios outside the training distribution}.


\subsection{Probing Attack Effects on Template}

\label{subsec:prob_attack}

To understand how jailbreak attacks affect information processing in the template region, we probe how harmfulness features are represented in the intermediate states under different attack scenarios.


\paragraph{Method.} 
We feed both harmful and harmless inputs from \( \gD_{\text{anlz}} \) into Llama-3-8B-Instruct and collect residual streams at the template region across all layers. At each intermediate location, we construct a probe \( \vd^{-} \coloneqq -\vd^{+} \), using the method described in \Cref{eq:diff_prob}, but applied in the reverse direction. This probe is used to determine whether a state is harmful, defined as the predicted logit exceeding a decision threshold. The threshold is set at the midpoint between the average logits of harmful and harmless inputs. To quantify the harmfulness features at a specific intermediate location, we calculate the \emph{harmful rate}, defined as the proportion of intermediate states classified as harmful.




\paragraph{Results.}
\Cref{fig:prob_in_temp} illustrates the harmful rate of residual streams across different layers and template positions. Our analysis highlights two key findings:
(1) Successful attacks consistently reduce the harmful rate in residual streams across all template positions, indicating a uniform disruption in the processing of harmfulness features throughout the template region.
(2) Notable patterns emerge at the last positions close to the ending (e.g., from `\texttt{assistant}' to \texttt{`\texttt{\textbackslash n\textbackslash n}'}): For failed attacks, the harmful rate starts low but rises sharply in the middle layers, eventually plateauing at levels comparable to those of typical harmful inputs. In contrast, successful attacks exhibit only a modest increase across layers.
These observations suggest that intermediate template regions are critical for aggregating harmful information: \subconc{Successful attacks deeply suppress this aggregation process, whereas failed attacks are ultimately ``exposed''}.

Recalling the insights about TASA (\Cref{sec:rq1}), \mainconc{the loss of harmfulness information in the template region caused by attacks disrupts initial safety evaluations, leading to incorrect decisions and ultimately resulting in unsafe behaviors}.
