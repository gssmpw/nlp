\section{Literature Review}
\label{sec:literature-review}
As a communication system, natural language comprises of structured sequences of sounds, symbols, or gestures that convey meaning in spoken, written, or signed forms. 
From a formalisation perspective, languages are composed of structured strings of lexical categories (pre-terminals), forming well-defined sentences that facilitate statistical analysis of their structure \cite{culy1996formal, gunther2022language}. Advancements in Artificial Intelligence (AI) and Machine Learning (ML) have provided powerful tools for processing languages through NLP techniques. However, the effectiveness of NLP models depends on the availability of extensive and relevant linguistic resources, leading to a fundamental divide between high-resource and low-resource languages. High-resource languages (HRLs), such as English, French, and Spanish, benefit from abundant digital resources and large-scale initiatives like the Linguistic Data Consortium, which facilitate access to multilingual text resources in standardised and compatible formats \cite{graff1994multilingual,cho2014properties}. These resources, sourced from governmental bodies, international organisations, news agencies, and publishers, play a crucial role in advancing various NLP applications. 
Efforts to enrich and digitise LRLs, such as transducing texts \cite{randell1998hausar}, resource enrichment \cite{adegbola2009building}, and digitising indigenous poetry \cite{hausapoetry} are essential for their integration into computational frameworks. 

\subsubsection{Past Reviews} 
As previously noted, advancements in NLP have predominantly benefited high-resource languages, while LR-NLP continues to face unique challenges owing to limited linguistic resources. Several past studies \cite{zhang2017embracing,fadaee2017data,fan2021beyond,costa2022no,adebara2022afrolid,robertson2022understanding,raychawdhary2024optimizing,zhou2024character} have examined the state of LR-NLP, highlighting these challenges to LRL development. Similarly, numerous studies have investigated NLP research involving the three major languages in Nigeria. However, these studies tend to focus on either a single language such as Hausa \cite{zakari2021systematic}, Yorùbá \cite{yusof2013review}, Igbo \cite{nwankwegu2021leveraging,maryann2021machine,orji2024igbo} or they concentrate on specific NLP tasks like machine translation \cite{benito2022machine,haddow2022survey}, text summarisation \cite{edwards2023text}, automatic speech recognition for tonal languages \cite{kaur2021automatic}, and sentiment analysis \cite{raychawdhary2024enhancing}. Other reviews adopt a broader perspective by covering various African languages \cite{caron2020methodological,hedderich2020survey,asubiaro2021state,asubiaro2021evaluating,adelani2022natural,obiajuludigital,emmanuelcurrent,ezugwu2023machine,abdou2024review,hu2024review}. 
While these studies offer valuable insights, they provide only a fragmented perspective on the current state of NLP research in the targeted languages. Our review builds upon previous studies by incorporating a wider scope, accounting for recent advancements, open-access resources, and community-driven initiatives. 
Thus, we provide a comprehensive analysis of the NaijaNLP landscape, examining ongoing research efforts, available datasets, tools, language communities, and initiatives aimed at facilitating LR-NLP development. The subsequent discussions involving the three languages are organised alphabetically by language, following the order: Hausa, Igbo, Yorùbá. 

\subsection{Formal Grammar and Knowledge Representation} 
\label{sec:grammar-and-knowledge-representation}
We begin our review with formal grammar and knowledge representation due to their fundamental role in developing robust NLP tools and applications. Computational grammar facilitates language enrichment through systematic analyses of syntax, semantics and linguistic structures, enabling the creation of reusable linguistic resources for LRLs \cite{crysmann2012hag}. In this regard, several studies have explored grammatical formalisation \cite{abdoulaye1992aspects,culy1996formal,crysmann2009autosegmental,copestake2002implementing,crysmann2012hag,blasi2017grammars}, morphological analysis \cite{finkel2009computational,eludiora2018computational}, and knowledge representation \cite{eze1997aspects,aina2021ontology,ifeanyi2022semantic,aina2023human} for Hausa, Igbo and Yorùbá languages. 
Notably, \citet{abdoulaye1992aspects} apply the Role and Reference Grammar framework\footnote{see \citet{van1980role}} to provide new insights into Hausa sentence structure and linguistic processes. 
Similarly, \citet{crysmann2009autosegmental} examine lexical and grammatical tone and vowel length in Hausa, utilising bidirectional Head-Driven Phrase Structure Grammar (HPSG) based on the Lingo Grammar Matrix \cite{bender2002grammar}. This effort also incorporates a Linguistic Knowledge Builder \cite{copestake2002implementing} representation inspired by linguistic and computational work on Autosegmental Phonology \cite{crysmann2009autosegmental}. Additionally, \citet{crysmann2012hag} implement a formal grammar for Hausa, leading to the development of the HaG platform for grammatical structure generation. Beyond these studies, \citet{blasi2017grammars} analyse the transmission of grammatical features across 48 creole and 111 non-creole languages. Further discussions on morphological analysis and diacritic restoration - particularly for Yorùbá and Igbo - are presented in \S~\ref{sec:language-particularity}. 

Noting that a key challenge in knowledge representation is maintaining logical consistency, particularly in narrative structures, \citet{alade2019issues} analyse issues in standardised knowledge representation for Yorùbá narrative. Their study identify challenges such as imprecise event codification and concept representation. In the context of Hausa NLP, \citet{abubakar2019hausa} develop Hausa WordNet, a lexical resource that extracts knowledge from Kamus (Hausa dictionary). For collocational analysis, \citet{umaraspects} examine collocational patterns in Hausa, investigating their semantic significance and degree of collocability. To further advance lexicographic resources, \citet{enguehard2014computerization} propose a system for converting bilingual African language-French dictionaries (including Bambara, Hausa, Kanuri, Tamajaq, and Songhai-Zarma) from Word format to XML, following the Lexical Markup Framework. 

Despite their importance, studies on formal grammar and knowledge representation remain limited for NaijaNLP. Nevertheless, they provide a crucial foundation for digital language resource development by offering structured frameworks for language processing. 

\subsection{Language Particularities}  
\label{sec:language-particularity}
Languages exhibit distinct structural, phonetic, and orthographic characteristics that influence how they are written, pronounced, and processed. These particularities manifest in diverse orthographic systems, including alphabets, abjads, syllabaries, and logograms, which shape word formation and written representation. Additionally, phonetic variations - such as differences in phonemes, stress patterns, and tonal systems - impact how languages are spoken and understood. Recognising and integrating these linguistic nuances is essential for developing effective NLP tools that accurately represent the unique feature of each language \cite{adebara2022towards}. 
Several Nigerian languages are tonal and employ characters beyond the basic Latin alphabet, making them structurally distinct from English and other high-resource languages. A failure to adequately account for these particularities often hinders the adaptation and effectiveness of existing NLP tools developed primarily for English and other HRLs in the context of LRLs. Addressing this challenge, numerous studies have explored the linguistic diversity and specific needs of Nigeria's major languages \cite{amuda2010limited,oyinloye2015issues,abdulkareem2016yorcall,adewumi2020challenge}. Furthermore, \citet{adebara2022towards} examined key linguistic and sociopolitical challenges affecting NLP development for African languages. This section reviews existing studies on the linguistic particularities of Nigerian languages, with a focus on morphological analysis and diacritic restoration. 
Both morphological analysis and diacritic restoration play crucial roles in improving the accuracy and performance of NLP applications. Among Nigeria's three major languages, Igbo and Yorùbá make extensive use of diacritical marks, further emphasising the need for language-specific NLP approaches. 

\subsubsection{Morphological Analysis}
\label{sec:morphological-analysis}
Morphological analysis explores word structure and formation. The languages within NaijaNLP exhibit rich morphological complexity, which has been documented in various studies. 
To that end, \citet{iheanetu2017some} analyse the morphological structure of Igbo language, identifying key challenges that hinder practical NLP applications. 
Building on this, \citet{iheanetu2019addressing} develop a data-driven model capable of inducing non-concatenative morphological structures, cascaded affixation, and affix labelling using a frequent pattern-based induction approach. To uncover deeper linguistic patterns, \citet{ochu2019corpus} apply concordance line strategies to extract multiword expressions in Igbo. 
Further examining text representation strategies, \citet{chidiebere2020analysis} investigate collocation patterns, word order, compounding, and lexical ambiguity in Igbo, offering insights into language processing challenges. Additionally, \citet{henry2020performance} evaluate a text-based intelligent system designed to determine the optimal operational level for Igbo NLP applications. 
Similar studies have been conducted for Yorùbá, further highlighting the linguistic complexities and computational challenges associated with morphological analysis in NaijaNLP. 
\citet{oyinloye2015issues} develop VerbMorpher, a computational system designed for morphological analysis of standard Yorùbá verbs. This system incorporates linguistic resources that can be utilised for spell-checking, syntax analysis, and dictionary functionalities. 
To enhance morphological analysis efficiency, \citet{adegbola2016pattern} employ an unsupervised induction approach to infer morphological rules for standard Yorùbá. Unlike conventional methods that rely on word-segment frequency, their approach is pattern-based, leveraging word-pattern frequency. Although the study alluded to lexicons collected for the development of a Yorùbá speech synthesizer project, access to the data remains unavailable.  
Similarly, to improve data curation and quality, \citet{adewole2017token} develop a token validation system for automated corpus collection from online sources. To further standardise Yorùbá linguistic resources, \citet{oluwatoyinstochastic} introduce YoTEx (Yoruba Text Lexicon), a repository that learns from English language corpora to enhance Yorùbá text processing. 
In related work, \citet{okediya2019building} leverage various online resources - including books, blogs, social websites, and Yorùbá dictionaries - to construct a general - purpose lexical ontology for Yorùbá NLP applications. 


Addressing the morphological and structural complexities of Yorùbá in translation, \citet{adebara2021translating} develop a strategy for handling language-specific morphological marking, particularly in cases where features present in English (e.g. morphological markers) are contextually inferred in Yorùbá. 
Motivated by the lack of machine-readable sense inventory for ambiguous Yorùbá words, \citet{adegokedevelopment} design a disambiguation component for a Yorùbá-English machine translation system. Additionally, \citet{akinwonmi2024rule} introduce the declarative rule-based syllabification algorithm to address syllabification errors in Yorùbá, particularly for consonant-vowel-nasal and diphthong-vowel-nasal structures. Their approach involves curating a corpus for syllabic misclassification detection, which is subsequently evaluated using ML models. A more recent study by \citet{frohmann2024segment} explores alternative sentence segmentation strategies, moving beyond traditional rule-based and statistical methods that rely solely on lexical features. Their approach presents novel insights into text segmentation techniques applicable to Yorùbá NLP. 

\subsubsection{Diacritic Restoration} 
\label{sec:diacritic-restoration} 
Diacritic restoration involves adding or correcting diacritical marks\footnote{Such as accents, umlauts (two dots), and tildes.} in textual data. This process is essential for handling historical texts, user-generated content, and datasets where diacritics may have been omitted due to technical constraints. 
Given that many African languages utilise Latin-based scripts with diacritical marks, \citet{scannell2011statistical} propose a strategy and open-source package for automatic unicodification\footnote{The process of converting ASCII text into its proper Unicode form \cite{scannell2011statistical}.} across multiple languages. 
Addressing orthographic and tonal diacritics, \citet{ezeani2016automatic} apply n-gram models trained on the Igbo Bible corpus for word-level diacritic restoration. Recognising the role of diacritics in pronunciation, meaning differentiation, and lexical disambiguation, \citet{ezeani2017lexical} develop a disambiguation strategy through diacritic restoration for the Igbo language. Further advancements in this domain include the use of embedding models for text similarity computation and diacritic restoration \cite{ezeani2018transferred,ezeani2018igbo}. 
For Yorùbá diacritic restoration, \citet{de2007automatic} explore various ML models to improve diacritic restoration accuracy. 
\citet{tunji2011design} propose an enhanced approach that integrates tonal information into text-to-speech systems for the standard Yorùbá language. 
Recognising that omitting tonal information leads to performance degradation, \citet{adegbola2012quantifying} evaluate ML models for handling tone-mark representation in Yorùbá text processing. Inconsistencies in diacritic usage within electronic Yorùbá documents have been examined in \citet{asubiaro2015statistical}, highlighting their impact on NLP applications. 
Additionally, \citet{asahiah2017restoring}, \citet{orife2018attentive}, and \citet{alabi2020massive} investigate optimal strategies for integrating diacritics and analyse their effects on model performance for Yorùbá NLP tasks. The broader challenge of machine translation for African languages particularly Yorùbá is explored in \citet{odoje201612}. To improve word embeddings for diacritic-sensitive languages, \citet{orife2020improving} and \citet{adewumi2020challenge} examine the impact of working with undiacritised (normalised) datasets. \citet{adewumi2020challenge} further introduce new analogy sets to aid evaluation and a rule-based framework for Elision resolution\footnote{The omission of tone or syllable from a text.} in Yorùbá is proposed by \citet{adewole2020automatic}, while \citet{asahiah2023diacritic} develop a spell-checking and correction system that explicitly accounts for diacritic presence. Additionally, \citet{ogheneruemu2022development} leverage deep learning for diacritic restoration in tonal languages such as Yorùbá. 
In addressing diacritic usage and pronunciation challenges, \citet{abdulkareem2016yorcall} introduce the YorCALL system, which aims to enhance user proficiency in applying diacritics correctly in Yorùbá. 

\subsubsection{Numerical System} 
The challenges stemming from the lack of or limited standardised linguistic resources extend beyond textual to numerical data. A key area of interest is assessing whether NaijaNLP possesses the necessary linguistic resources, such as well-defined numerical lexicons, for developing numerical systems through published research. The earliest attempt at analysing Hausa numerals for machine processing dates back to the Automatic Text Comprehension project \cite{sigurd1980numbers}. This project surveyed numerical systems and examined challenges related to converting spoken numerals into decimal representations, ultimately leading to the development of an automated rule-based systems. The system enabled bidirectional conversion between mathematical representations and their linguistic counterparts, i.e., numerals \cite{sigurd1980numbers}. 
In a related effort, \citet{agbeyangi2016web} introduce a numeral translation system for English-Yorùbá, while \citet{mustapha2023automated} formulate an algorithm for converting numerical figures into words in Hausa. Similarly, \citet{rhoda2017computational} develop a number-text conversion system for Igbo, contributing to the broader goal of numerical processing in LRLs. 
Beyond numerical conversion, advancements in handwritten numerical recognition have been explored. For instance, \citet{ajao2022yoruba} develop a Yorùbá handwritten character recognition using convolutional recurrent neural networks, demonstrating the application of deep learning techniques in linguistic digitisation efforts. 
Despite these developments, research on numerical systems in NaijaNLP remains limited, highlighting the need for further studies and resource development to ensure accurate numerical representation and processing across languages.  

\subsection{LR-NLP Tools and Resources} 
The development of relevant tools, resources, and techniques is essential to enable various NLP downstream tasks and to facilitate wider language coverage for robust LR-NLP applications \cite{crysmann2009autosegmental}. The lack of sufficient linguistic resources and pre-processing tools presents a significant challenge for LRLs, particularly when diacritic and morphological features must be considered. 
To address these challenges, several initiatives, resources, and tools have been developed to support LRLs. A case in point is the low-resource Human Language Technology (LoReHLT) project, which evaluates the DARPA\footnote{Defense Advanced Research Projects Agency (DARPA) - \url{https://www.darpa.mil/}} Low-Resource Languages for Emergent Incidents (LORELEI) research program \cite{christianson2018overview}. The LORELEI initiative includes both Hausa and Yorùbá, providing researchers with resource packages for LRLs. These packages comprise monolingual and parallel texts, a bilingual dictionary, text annotated with part-of-speech (POS) tags, named-entity-recognition (NER), and noun-phase-chunking annotations. Furthermore, language processing tools such as segmenters and morphological analysers, aimed at improving NLP capabilities for these languages have been included \cite{christianson2018overview}. 
Another significant contribution is AfroLID, a neural language identification (LID) toolkit designed to support LR-NLP and web data mining for approximately 517 African languages \cite{adebara2022afrolid}. 

In analysing the available tools and resources for NaijaNLP, we focus on relevant key research areas aligned with the LORELEI research initiative \cite{christianson2018overview}. Additional research areas outside these categories will also be considered necessary to ensure a comprehensive evaluation of available LR-NLP tools and resources.

\subsubsection{Linguistic Resources} 
\label{sec:linguistic-resources-datasets} 
Linguistic resources constitute a fundamental component in the development of robust NLP applications. Several initiatives have been introduced to support NaijaNLP. \citet{adegbola2009building} highlight key initiatives, notably the African Languages Technology Initiative (Alt-i), aimed at enhancing NLP support for major Nigerian languages. Similarly, \citet{chiarcos2011information} provide tools and annotation resource to facilitate NLP downstream tasks across 25 sub-Saharan languages, including Hausa, Yorùbá and Igbo. 
As part of this effort, they develop ANNIS - ANNotation of Information Structure - a corpus tool that offers unified access to various linguistic annotations and data archives. To further advance lexicographic resources, \citet{bigi2017developing}, introduce language resources and Human Language Technologies (HLT) tools for Nigerian Pidgin, consisting of a tokeniser and automatic speech system for predicting word pronunciation and segmentation. 
For Igbo NLP, \citet{onyenwe2018basic} propose POS-tagging resources including a POS tagset and a tagged subcorpus. 
Addressing the broader LR-NLP landscape, \citet{costa2022no} explore strategies to narrow the performance gap between high-resource and low-resource languages. Their approach involves exploratory interviews with native speakers, data creation, and model development. Meanwhile, \citet{turki2024text} investigate the role of text categorisation in optimising stopwords extraction, with a specific focus on African languages. 

%\subsubsection{Datasets} 
%\noindent\textbf{Datasets - } 
\vspace{0.36cm}\noindent \textbf{Datasets - }
Data serve as a fundamental building block for NLP technologies. Recognising this, researchers have developed various datasets of differing sizes and levels of diversity to support LR-NLP tasks. The following section provides a review of available datasets for NaijaNLP. 

\paragraph{Hausa Datasets}
Several efforts have been made to develop datasets for NLP applications in the Hausa language. 
\citet{imam2022first} compile a dataset of approximately 2600 articles to support fake news detection in Hausa language and \citet{vargas2024hausahate} introduce the first expert-annotated dataset for Hausa hate speech detection, consisting of 2,000 comments extracted from Facebook. 
\citet{zandam2023online} curate a Hausa dataset containing threatening lexicons, sourced from Twitter. 
\citet{inuwa2021first} provide an expansive dataset containing both formal and informal Hausa text. 
For sentiment analysis, \citet{mohammed2024lexicon} develop a Hausa dataset comprising 14,663 instances (4,154 positive, 4,310 negative, and 6,199 neutral sentiments). The dataset was created using words and phrases from Hausa dictionary\footnote{see \textit{Kamus na Hausa zuwa Turanci} \cite{rigdon2017english}} and further expanded through data augmentation techniques.
Similarly, \citet{shehu2024unveiling} develop a Hausa sentiment analysis lexicon alongside a customised stemming method to enhance model performance.
\citet{awwalu2021corpus} construct the Hausa Tagset (HTS) for POS tagging, while \citet{salifou2014design} design a spell-checking and correction tool for Hausa, which is accessible via LyTexEditor and includes an extension (add-on) for \url{OpenOffice.org}. 
\citet{adam2024detection} compile a dataset of offensive content in Hausa language, and \citet{ibrahimnecat} develop a parallel datasets closely aligned with the target languages to enhance machine translation involving Hausa. 

\paragraph{Igbo Dataset}
Several studies have contributed to the development of datasets supporting NLP tasks in the Igbo language as well. 
\citet{onuora2024machine} and \citet{ana2024ai} curate datasets for Igbo hate speech detection.
For cyberbullying detection, \citet{okoloegbomultilingual,okoloegbo2022multilingual} develop datasets covering both Igbo and Nigerian Pidgin English. 
\citet{onyemaechi2023some} present a database consisting of 158 Chi-prefixed Igbo personal names, categorised into praise, thanksgiving, testimony, prayer, and declarative groups. 
\citet{chiomaweb} compile an Igbo thesaurus, covering a comprehensive set of words and their meanings.
\citet{nganga2020spoken} describe a methodology for creating a digital dialectal dictionary for Igbo, sourced from spoken-word corpora and oral traditions.
\citet{ajao2023recurrent} develop an RNN-based handwritten character recognition system for Igbo using data from native speakers.


\paragraph{Yorùbá Datasets}
Similarly, multiple datasets have been developed to support various NLP applications in Yorùbá language. 
\citet{fagbolu2015digital} introduce one of the earliest Yorùbá corpora to support machine translation and other NLP downstream tasks. 
\citet{ademusire2023development} curate annotated Yorùbá data for event extraction and \citet{akpobi2024yankari} develop Yankari, a large-scale monolingual Yorùbá dataset. 
\citet{orife2018attentive} offer datasets and source code for various Yorùbá NLP applications. 
\citet{ahia2024voices} provide text and speech data to address dialectal discrepancies in Yorùbá.  
%Audio and Speech Recognition: 
\citet{afolabi2013implementation} develop an audio database for Yorùbá consonant-vowel syllables, the alphabet, and a text-to-speech system. 
In a related work, \citet{iyanda2015statistical} compile a Yorùbá corpus for speech generation, sourced from textbooks, newspapers, and online materials. 
\citet{gutkin2020developing} produce a speech synthesis dataset, comprising over four hours of 48 kHz recordings in Yorùbá, while \citet{akinwonmi2021development} develop annotated prosodic read-speech syllabic data, extracted from fictional books and online scriptures. 

\paragraph{Multilingual Datasets} 
To address the challenges of LRLs and mitigate reliance on costly annotation, several initiatives have contributed to multilingual datasets. 
\citet{hedderich2022weak} propose a weak-supervision and noise-handling strategy to facilitate LRLs data expansion. 
To support the provision of high-quality human-annotated cross-lingual information retrieval resources for African languages, \citet{adeyemi2024ciral} present CIRAL\footnote{Available at \url{https://github.com/ciralproject/ciral}}, a publicly available test collection for cross-lingual retrieval, covering English queries with passages in Hausa, Somali, Swahili, and Yorùbá.  
\citet{muhammad2022naijasenti} introduce the first large-scale human-annotated Twitter sentiment dataset, covering Hausa, Igbo, Nigerian Pidgin, and Yorùbá, with approximately 30,000 annotated tweets per language, including code-mixed examples.  
In a related effort, \cite{adelani2021masakhaner} introduce a large-scale, publicly available dataset for NER across ten African languages. Furthermore, \cite{muhammad2025afrihate} develop AfriHate, a multilingual corpus of annotated hate speech and abusive language data spanning 15 African languages.  
\citet{aliyubeyond} compile datasets in Hausa, Yorùbá, and Igbo for hate speech detection and \citet{varab2021massivesumm} develop multilingual text summarisation data consisting of 28.8 million articles from 92 languages. 
\citet{adelani2023masakhanews} develop MasakhaNEWS, the largest dataset for news classification in 16 African languages. 
\citet{varab2021massivesumm} introduce a multilingual text summarisation dataset containing 28.8 million articles across 92 languages. 
\citet{ferroggiaro2018social} develop hate speech lexicons for several Nigerian languages, and \citet{ogunleye2023using} utilise 346,000 Nigerian banking-related tweets to develop SentiLeye, a lexicon-based sentiment analysis dataset for Nigerian Pidgin.
\citet{adelani2022natural} introduce large-scale human-annotated datasets for NER and machine translation across 21 African languages. 
\citet{scholar2022development} develop a multilingual electronic dictionary covering English, Hausa, Yorùbá, and Igbo, designed for handheld devices. 

To support multilingual machine translation, \citet{fan2021beyond} provide an open-source training dataset covering thousands of language pairs with parallel data. \citet{ekpenyong2022towards} introduce a parallel Hausa-English corpus and explore initiatives for multilingual machine translation.
\citet{adewumi2023afriwoz} compile high-quality dialogue datasets for six African languages (Swahili, Wolof, Hausa, Nigerian Pidgin, Kinyarwanda, and Yorùbá), accessible via Hugging Face.
\citet{ajagbe2024developing} develop a multilingual Nigerian speech dataset (English, Yorùbá, and Pidgin) for antenatal orientation, sourced from six antenatal clinics.
\citet{amuda2010limited} contribute the UISpeech corpus, an audio-visual dataset of Nigerian-accented English, recorded from native speakers of Hausa, Igbo, Yorùbá, Tiv, and Fulfulde. 
\citet{parida2023havqa} develop HAVQA, a Hausa multimodal dataset that integrates descriptive images to enhance Hausa-English translation. \citet{abdulmumin2022hausa} develop HaVG, a Hausa multimodal translation dataset, integrating descriptive images to enhance Hausa-English translation.
\citet{kolak2005ocr} propose a lexicon-free OCR post-processing method for low-density languages.
\citet{omotayo2024state} examine how the limited availability of computing resources and datasets constrains computer vision research in Hausa, Yorùbá, and Igbo.
In a related effort, \citet{ibrahim2021convolutional} apply CNNs to classify traditional male attire from these ethnic groups. 
\citet{adewumi2022itakuroso} explore cross-lingual transfer learning and provide Hugging Face model checkpoints for African LRLs.
\citet{goyal2022flores} introduce FLORES, a benchmark dataset for evaluating multilingual NLP performance in low-resource languages. 
To ensure the integrity and utility of the FLORES data, \citet{abdulmumin2024correcting} engage native speakers to identify and correct inaccurate and inconsistent cases in Hausa, Northern Sotho (Sepedi), Xitsonga, and isiZulu languages. 
\citet{aremunaijarc} develop NaijaRC, a multichoice reading comprehension dataset for Hausa, Igbo, and Yorùbá.
\citet{godslove2024trilingual} present a trilingual model for multi-dialect conversational AI in African languages.

These datasets serve as essential resources for advancing NLP applications, including fake news and hate speech detection, machine translation, sentiment analysis, and linguistic annotation. The increasing number of multilingual resources highlights a growing trend of collaborative research and initiatives aimed at enriching NaijaNLP. 

\paragraph{Linguistic Tools} 
Building on existing corpora, various linguistic tools have been developed to enrich and ensure the accurate representation of LRL. Some of these tools address the specific linguistic characteristics of individual languages, while others focus on enhancing linguistic resources more broadly. Notable examples include automatic spell checkers and correctors for Yorùbá \cite{oluwaseyi2024automatic} and Hausa \cite{mijinguini2003ƙaramin,salifou2014design}, an automatic Hausa stopword constructor \cite{bichi2022automatic}, and an Igbo text analyser \cite{azubuike2024design}. 
The following section provides a detailed examination of linguistic tools including part-of-speech (POS) tagging and named entity recognition (NER) tools within NaijaNLP.  

\subsubsection{Part-of-Speech Tagging and Named Entity Recognition}  
Each word in a text belongs to a grammatical category, such as noun, verb, adjective, or adverb, depending on its context and definition. Part-of-Speech (POS) tagging assigns words to their corresponding grammatical categories, facilitating the structural analysis of sentences. Similarly, some words in a text refer to specific entities such as people, organisations, locations, dates, and quantities. Thus, Named Entity Recognition (NER) identifies and classifies such entities accordingly. To that end, several studies have explored POS tagging and NER for NaijaNLP. 
\citet{ren2016automatic} present data-driven methods for recognising entities in large-scale, domain-specific text corpora across both high- and low-resource languages. 
\citet{adelani2020distant} examine NER in Hausa and Yorùbá, while \citet{model2020accent} explore accent classification for Nigerian-Accented English, covering Hausa, Yorùbá, and Igbo. 
\citet{oyewusi2021naijaner} develop NER models for Nigerian Pidgin English, Igbo, Yorùbá, and Hausa. 
\citet{tukur2024towards} introduce a POS tagger for Kanuri\footnote{A Nilo-Saharan language spoken in the Lake Chad Basin of West and Central Africa} and corresponding corpus. 
\citet{adewumi2022itakuroso} explore cross-lingual transfer learning to optimise Hausa and Yorùbá POS and NER tasks. 
\citet{mehari2024semi} employ semi-supervised data augmentation combined with pretrained language models to enhance NER for LRLs. 

\paragraph{Hausa POS \& NER}
Given the limitations of classic stemmers based on Porter’s algorithm \cite{porter1980algorithm}, researchers have developed Hausa-specific stemming techniques \cite{bashir2015word,bimba2016stemming,musa2022improved}. 
Essentially, \citet{bashir2015word} introduce an automatic Hausa word stemming system to optimise text processing. 
\citet{bimba2016stemming} develop a stemming strategy using affix-stripping rules\footnote{78 affix-stripping rules applied in 4 steps} and reference lookup\footnote{A database of 1,500 Hausa root words}. 
Recognising the importance of entity extraction in disaster response and large-scale incidents\footnote{e.g., disease outbreaks and natural calamities}, \citet{lu2016multi} present a method for learning entity priors from extensive Hausa text corpora.  
\citet{zhang2017embracing} propose a low-resource POS tagging strategy aimed at minimising noise in supervised learning methods by integrating diverse linguistic sources\footnote{e.g., the World Atlas of Linguistic Structure, CIA names, PanLex, and survival guides}.
To address challenges posed by the use of non-standard words (NSWs) in Hausa social media communication, \citet{maitama2014text} propose a text normalisation system based on handcrafted rules for converting NSWs into standard Hausa text. 
\citet{tukurcorpus,tukur2019tagging,tukur2020parts} explore POS tagging techniques to facilitate sentiment analysis of Hausa web content.
\citet{awwalu2021corpus} develop the Hausa Tagset (HTS) for POS tagging, while \citet{musa2022improved} introduce a stemming algorithm to enhance Hausa information retrieval.

\paragraph{Igbo POS \& NER} 
Several linguistic tools and resources have been developed for Igbo. 
\citet{onyenwe2015use, onyenwe2016predicting} contribute to Igbo linguistic resource development. 
\citet{onyenwe2014part, onyenwe2019toward} and \citet{olamma2019hidden} develop POS taggers for Igbo. 
\citet{anbootstrapping} propose cross-lingual and monolingual POS tag projection approaches for Igbo POS tagging. 
For NER in Igbo, researchers have focused on cross-lingual learning. 
\citet{chukwuneke2023igboner} introduce an Igbo NER system based on a cross-language projection method, leveraging parallel English-Igbo corpora and \citet{soronnadienhancing} develop IgboBERTa, a transformer-based model optimised for Igbo NLP tasks, including NER, text classification, and sentiment analysis. 

\paragraph{Yorùbá POS \& NER}
Similarly, significant efforts have been made to advance Yorùbá POS tagging and NER. 
\citet{kumolalo2010development} propose a rule-based approach to enhance Yorùbá syllabification, mapping words to their corresponding syllables. 
\citet{adedjouma2013part} curate a Yorùbá corpus focused on POS tagging, and \citet{abiola2014web} develop an English-to-Yorùbá translation system. 
\citet{adegunlehin2019investigation} improve Yorùbá NER by incorporating contextual information such as surrounding words and POS tags. 
\citet{omolaoye2020proverb} introduce a computational approach for the representation of Yorùbá proverbs, contributing to indigenous knowledge preservation. 
\citet{ugwu2024part} train a POS tagger using Yorùbá religious texts and dictionary entries.
\citet{toyin2024hidden} introduce a Hidden Markov Model (HMM)-based POS tagger, contributing a manually annotated dataset of 1,000 Yorùbá sentences drawn from various domains. 

The development of POS tagging and NER tools for Hausa, Igbo, and Yorùbá has contributed significantly to NaijaNLP. These tools are critical in addressing language-specific challenges, enhancing computational linguistic resources, and facilitating various downstream tasks. 
While existing resources have proven useful, further research and dataset expansion are needed to bridge gaps and improve linguistic tool development for NaijaNLP. 

\subsection{Downstream Tasks} 
In NLP, downstream tasks such as text classification, sentiment analysis, text summarisation, machine translation, and speech recognition rely fundamentally on robust linguistic resources, including annotated datasets, computational models, and standardised frameworks. In this section, we review the existing downstream tasks and applicable resources developed for Hausa, Igbo, and Yorùbá languages. 

\subsubsection{Text Classification and Summarisation} 
Text classification (TC) involves assigning textual data to predefined classes based on similarity or dissimilarity, using a range of methodologies from rule-based approaches to machine learning, deep learning, and transformer-based models. Complementary to text classification, text summarisation (TS) aims to generate concise and coherent summaries that retain the essential information of longer texts. 
To that end, \citet{asubiaro2018word} propose a strategy for language identification at the word-level to enhance model performance for LRLs, thereby improving the prediction of a word's language. In a related effort, \citet{varab2021massivesumm} develop a multilingual text summarisation framework by enriching existing resources to facilitate machine translation (MT) on a large scale. Furthermore, \citet{olalekan2022machine} introduce multilingual text classification models for English, Yorùbá, and Hausa, while \citet{bashir2017automatic} present a model trained on a corpus of Hausa documents for automatic summarisation. Additional contributions include the work of \citet{bichi2023graph,bichi2024integrating}, who develop an automatic summarisation strategy for Hausa text. 
For Igbo, \citet{ifeanyi2020comparative} and \citet{ifeanyin} propose classification systems based on n-gram models and k-nearest neighbours techniques to improve text representation and classification. In parallel, \citet{mbonu2022igbosum1500} offer a detailed discussion about the development of the IgboSum1500 dataset, a dedicated resource for Igbo text summarisation. Meanwhile, \citet{adegokeestimating} explore models designed to compute semantic similarity between Yorùbá sentences. 
For text summarisation, in particular, the development of more purposive datasets and models capable of better contextual understanding, semantics, and inter-textual relationships will further enrich NaijaNLP.

\subsubsection{Sentiment Analysis} 
\label{sec:downstream-task-sentiment-analysis}
Sentiment analysis (SA), a specialised form of text classification, involves the identification and extraction of subjective information from the text to determine its sentiment - typically categorised as positive, negative, or neutral. In addressing the unique linguistic characteristics of LRLs, several studies have contributed to advancing SA in NaijaNLP. For example, \citet{shehu2024unveiling} employ deep learning techniques and hierarchical attention networks to enhance sentiment analysis in Hausa. Similarly, \citet{akande2022tweerify} and \citet{ibrahim2024deep} develop models to detect aspect-level sentiment in tweets and Hausa movie reviews, respectively. 
Furthermore, multilingual sentiment analysis systems have been proposed by \citet{raychawdhary2023transformer,raychawdhary2024optimizing} and \citet{abdullahi2023hausanlp}, which recognise the linguistic diversity inherent in LRLs such as Hausa, Yorùbá, and Igbo. In addition, \citet{abdou2025monitoring} present a framework for assessing online geopolitical news based on sentiment and public attention across multiple African countries including Kenya, Nigeria, Senegal, and South Africa. Complementary approaches include \citet{abubakar2021enhanced}, who develop a multilingual sentiment analysis system for English and Hausa tweets using an enhanced feature acquisition method, and \citet{rakhmanov2022sentiment}, who propose a system for analysing Hausa student comments via both monolingual and cross-lingual approaches—further supported by a stemming algorithm and a training dataset comprising over 40,000 comments.

There are additional studies that focus on domain-specific challenges. For instance, \citet{sani2022sentiment} develop a system for sentiment analysis on Hausa data extracted from BBC Hausa's Twitter handle\footnote{\url{https://www.bbc.com/hausa} and \url{https://x.com/bbchausa}}. \citet{mohammed2023building} build a lexicon-based sentiment analysis system tailored for LRLs, and \citet{abdullahi2024twitter} refine sentiment analysis for abbreviated terms in Hausa using an improved dataset with resolved abbreviations and acronyms. In the Igbo context, \citet{ogbuju2020development} introduce general-purpose sentiment lexicons (IgboSentilex), and \citet{okoloegbo2022multilingual} present an interactive system for detecting, monitoring, and regulating cyberbullying content in Igbo and Pidgin English. For Yorùbá, \citet{adeniji2024framework} propose a system for disambiguating sentiment lexicons in Yorùbá texts, supported by curated sentiment lexicons derived from diverse sources, while \citet{abegunde1832design} and \citet{shode2022yosm} explore enhancement strategies and develop datasets (e.g., YOSM) based on movie reviews to support sentiment analysis. 

Collectively, these studies rely on traditional approaches—including lexicon-based techniques, classical machine learning, hybrid methods, and some more recent deep learning and transformer-based models to address sentiment analysis. 
While relevant datasets have been contributed, there is a compelling need for more high-quality annotated data to train models that are better equipped to capture complex linguistic patterns, including sarcasm, irony, and context-dependent sentiments in NaijaNLP.

\subsubsection{Machine Translation} 
Machine Translation (MT) focuses on the automatic translation of text or speech from one language to another, and it has evolved from rule-based systems and statistical methods to neural networks and transformer-based models. Effective MT systems are heavily dependent on large volumes of parallel data to generate accurate translations. 
\citet{mahata2020performance} explore the correlation between performance improvements and the positioning of languages within transfer learning frameworks, highlighting the significance of parallel data in MT. In addressing the needs of LRLs, \citet{akinfaderin2020hausamt} develop a translation system for English–Hausa that leverages parallel corpora. Additionally, \citet{tresner2023intent} propose a system for intent recognition in user messages directed to a chatbot (askNivi), which is designed to facilitate discussions on sexual and reproductive health topics in Hausa, Hindi, and Swahili.
Responding to the need for on-demand MT, \citet{watt2023edge} present an approach for deploying MT on the edge, thereby enabling an embedded system for English–Hausa translation. In another useful approach, \citet{brugnone2024ought} leverage the wisdom of the crowd and unsupervised learning strategies to identify subpopulations based on value-laden statements extracted from Hausa narratives related to maternal and child healthcare, which are subsequently translated into English for further analysis. 

A multimodal strategy is presented by \citet{hatami2024english}, who integrate visual (contextual) and textual information to enhance translation accuracy across language pairs including English, Hindi, Malayalam, Bengali, and Hausa, achieving superior performance compared to text-only baselines.  
\citet{robertson2022understanding} propose strategies to improve translation accuracy for chat agents in LRLs, including Igbo, while \citet{maryann2022enhanced} and \citet{usip2023text} develop MT systems for English–Igbo using both rule-based and corpus-based approaches. Additionally, \citet{ohuoba2024quantifying} contribute an MT system for English–Igbo translation.
For Yorùbá, \citet{adegbola2011localising} discuss a strategy for localising the MS Vista operating system by translating relevant English lexicons into Yorùbá terminologies. Further contributions to English–Yorùbá translation can be found in the work of \citet{folajimi2012using} and \citet{odoje2014investigating}. 
\citet{eludiora2015development} develop a rule-based system to address tone changes in Yorùbá verbs and \citet{fagbolu2016applying} design an accessible MT system for English–Yorùbá translation via mobile and web platforms. 
\citet{eludiora2016development} develop an English–Yorùbá translator and \citet{sundaydevelopment} investigate a multi-layer hybrid approach that combines data-driven and rule-based methods. Finally, \citet{timothybilingual} focus on mitigating challenges such as vanishing gradients, translation accuracy, and computational efficiency in English–Yorùbá MT systems.

Although MT is one of the most widely utilised NLP applications, its performance on LRL pairs remains suboptimal compared to that of HRL \cite{robertson2022understanding}, primarily due to the paucity of adequate parallel data. Future research should emphasise the development of more and richer parallel data to train models that can effectively capture complex linguistic patterns, manage long-range dependencies, accommodate domain-specific terminology, and preserve cultural nuances for NaijaNLP.

\subsection{Automatic Speech Recognition} 
Automatic speech recognition (ASR), interchangeably referred to as speech recognition, involves converting spoken language into text using pattern matching, machine learning, deep learning, and transformer-based models. However, LRLs often suffer from an acute shortage of high-quality, annotated speech data that is critical for the development of effective ASR systems. To mitigate these challenges, several studies have proposed innovative techniques and system frameworks. 
\citet{zhou2024character} propose a technique that leverages meta-learning by pre-training on speech data from ten languages, followed by fine-tuning on data from the target language. 
\citet{gibbonmarketspeak} describe an approach to develop speech technology infrastructure specifically for the Igbo language.
Addressing bias in ASR, \citet{ngueajio2022hey} examine and mitigate systematic biases in speech recognition systems, particularly biases related to gender, race, and disabilities. 
For Hausa, \citet{luka2012neural} develop an ASR system based on neural network pattern recognition, while \citet{aliero10taxonomy} present a text-to-speech system employing deep neural networks. 
\citet{ibrahim2022framework} propose an integrated framework for Hausa ASR that encompasses data creation, as well as the development of both acoustic and language models. 
Noting that the removal of diacritics can increase homography and degrade recognition accuracy, \citet{abubakar2024development} develop an ASR system for Hausa that emphasises diacritised word forms.
\citet{ibrahim2022graphic} create a Hausa text-to-speech system using BERT in conjunction with digital signal processing techniques.
As part of the OkwuGbé initiative—which aims to develop ASR systems for various African LRLs—\citet{dossou2021okwugb} present a similar system for Fon and Igbo.
\citet{odelobi2008recognition} report on ASR for standard Yorùbá, while \citet{aoga2016integration} discuss the integration of Yorùbá into MaryTTS, a tool used for text-to-speech research, development, and teaching.
Further contributions for Yorùbá include the development of speech-to-text recognition systems by \citet{akintola2017machine} and \citet{babatunde2024speech}, as well as a system based on concatenative methods by \citet{afolabi2013development}.
Additionally, \citet{oyesanmi2024towards} describe the implementation of a Google navigation voice system in Yorùbá.

Despite these advances, the overall progress and volume of studies in ASR for NaijaNLP remain limited. There is a pressing need for additional resources to develop models capable of managing complex acoustic and linguistic patterns, including diverse accents, diacritic preservation, and variable speech patterns. Thus, the development of more comprehensive annotated and parallel speech datasets is essential.

\subsubsection{Dialogue Agent}
Dialogue agents are designed to support information retrieval and respond to frequently asked questions. In this context, several initiatives have been undertaken to develop multilingual and dialect-sensitive chatbots. 
\citet{mabrouk2021multilingual} develop a multilingual chat agent that supports African dialects using a general-purpose neural embedding model capable of addressing a broad range of tasks \cite{wu2018starspace}. 
Translators without Borders\footnote{\url{https://translatorswithoutborders.org/chatbot-release-northeast-nigeria/}} offer a chatbot, \textit{Shehu}, to enhance COVID-19 understanding in Northeast Nigeria. This chatbot supports user queries in English, Hausa, or Kanuri, and provides immediate, conversational responses.
\citet{haruna2021hausa} create a Hausa-language chatbot intended to engage users in storytelling and facilitate language learning among native speakers.
\citet{aremu2024utilising} explore the potential of AI-powered chatbots in supporting the learning of endangered Nigerian languages.
While promising developments in dialogue agent technology have been observed, the overall progress remains modest. Continued research and linguistic resource expansion are necessary to further refine pretrained models that can adeptly handle the acoustic and linguistic complexities inherent in NaijaNLP, ultimately enabling more effective and culturally relevant dialogue systems.