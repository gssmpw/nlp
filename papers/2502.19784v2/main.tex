%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
%\documentclass[acmsmall,nonacm]{acmart}
\documentclass[manuscript,screen,nonacm,a4paper,margin=1in]{acmart}
%\documentclass[manuscript,screen,a4paper,margin=1in]{acmart}
%\documentclass[manuscript,screen,review,a4paper,margin=1in]{acmart}
%\documentclass[11pt,manuscript,screen,review]{acmart}
%\documentclass[12pt,manuscript,screen,review]{acmart}
%\documentclass[12pt]{acmart} %change the font size here (global change)
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2025}
%\acmYear{2025}
%\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
%\acmConference[Conference acronym 'XX]{Make sure to enter the correct
%  conference title from your rights confirmation email}{June 03--05,
%  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
%\acmISBN{978-1-4503-XXXX-X/2018/06}

\settopmatter{printacmref=false} % Removes citation information below abstract 
\renewcommand\footnotetextcopyrightpermission[1]{} % Removes footnote with conference information
\pagestyle{plain} % Removes running headers

%\acmSubmissionID{} % Clears the submission text
%\makeatletter
%\def\@acmSubmissionID{} % Removes "Manuscript submitted to ACM"
%\makeatother

%\makeatletter
%\patchcmd{\@acmSubmissionID}{Manuscript submitted to ACM}{}{}{}
%\makeatother



%% -- Disable copyright statement --
%\setcopyright{none}
%\copyrightyear{0}
%\acmYear{0}
%\acmDOI{}
%\acmPrice{}
%\acmISBN{}

%######### disable the footerinformation: Manuscript submited to ACM: 

\usepackage{etoolbox}
\usepackage{array}
\usepackage{booktabs}
%\usepackage{tikz}
%\usepackage[a4paper, margin=1in]{geometry}
%\usetikzlibrary{positioning, shapes.geometric, arrows}
\usepackage{enumitem} 
\usepackage{pifont}   %circled numbers
\usepackage{graphicx}     
\usepackage{adjustbox}    
\usepackage{colortbl}     
\usepackage{xcolor}       
\usepackage{multirow}
\usepackage{subcaption}

\usepackage{forest}
\usepackage{geometry} % To adjust page layout for wide tables
%\geometry{a4paper, margin=1in}
%\usepackage[a4paper, margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{pifont}
%\usepackage{fontspec}

\newcommand{\cmark}{\ding{51}} % Checkmark symbol
\newcommand{\xmark}{\ding{55}} % Cross symbol

\DeclareUnicodeCharacter{00F9}{\`u} % For ù
\DeclareUnicodeCharacter{00E1}{\'a} % For á
\DeclareUnicodeCharacter{1ECD}{\d{o}}
\DeclareUnicodeCharacter{0300}{\`}
\DeclareUnicodeCharacter{0301}{\'} % Combining acute accent
\DeclareUnicodeCharacter{0198}{K} % Latin capital letter K with hook (Ƙ)
\DeclareUnicodeCharacter{1ECC}{\d{O}} % Latin capital letter O with dot below (Ọ)

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{NaijaNLP: A Survey of Nigerian Low-Resource Languages}


%\author{Anonymous Author(s)}
\author{Isa Inuwa-Dutse}
%\authornotemark[1]
%\authornote{Both authors contributed equally to this research.}
%\email{i.inuwa-dutse@hud.ac.uk}
%\orcid{1234-5678-9012}
\affiliation{%
  \institution{University of Huddersfield}
%  \city{Dublin}
%  \state{Ohio}
  \country{United Kingdom}
}

\authorsaddresses{} % Leave empty to remove the text


%\renewcommand{\shortauthors}{Author et al.}
\renewcommand{\shortauthors}{Inuwa-Dutse}

\begin{abstract}

With over 500 languages in Nigeria, three languages - Hausa, Yorùbá and Igbo - spoken by over 175 million people, account for about 60\% of the spoken languages. However, these languages are categorised as low-resource due to insufficient resources to support tasks in computational linguistics. 
Several research efforts and initiatives have been presented, however, a coherent understanding of the state of Natural Language Processing (NLP) - from grammatical formalisation to linguistic resources that support complex tasks such as language understanding and generation is lacking. 
This study presents the first comprehensive review of advancements in low-resource NLP (LR-NLP) research across the three major Nigerian languages (NaijaNLP).  
We quantitatively assess the available linguistic resources and identify key challenges. Although a growing body of literature addresses various NLP downstream tasks in Hausa, Igbo, and Yorùbá, only about $25.1\%$ of the reviewed studies contribute new linguistic resources. This finding highlights a persistent reliance on repurposing existing data rather than generating novel, high-quality resources. Additionally, language-specific challenges, such as the accurate representation of diacritics, remain under-explored. To advance NaijaNLP and LR-NLP more broadly, we emphasise the need for intensified efforts in resource enrichment, comprehensive annotation, and the development of open collaborative initiatives. 
 
\end{abstract}

%216 characters - 200 characters allowed!
%With over 500 languages in Nigeria, three languages - Hausa, Yorùbá and Igbo - spoken by over 175 million people, account for about 60\% of the spoken languages. However, these languages are categorised as low-resource due to insufficient resources to support tasks in computational linguistics. 
%Several research efforts and initiatives have been presented, however, a coherent understanding of the state of Natural Language Processing (NLP) - from grammatical formalisation to linguistic resources that support complex tasks such as language understanding and generation is lacking. 
%As NLP research activities proliferate, it is vital to understand the state of affairs to strengthen meaningful enrichment interventions. This study presents the first comprehensive review of advancements in low-resource NLP (LR-NLP) research across the three major Nigerian languages (NaijaNLP).  
%We quantitatively assess the available linguistic resources and identify key challenges. Although a growing body of literature addresses various NLP downstream tasks in Hausa, Igbo, and Yorùbá, only about $25.1\%$ of the reviewed studies contribute new linguistic resources. This finding highlights a persistent reliance on repurposing existing data rather than generating novel, high-quality resources. Additionally, language-specific challenges, such as the accurate representation of diacritics, remain under-explored. To advance NaijaNLP and LR-NLP more broadly, we emphasise the need for intensified efforts in resource enrichment, comprehensive annotation, and the development of open collaborative initiatives. 


%###########
%%%###

%\begin{CCSXML}
%<ccs2012>
%   <concept>
%       <concept_id>10010147.10010178.10010179.10010186</concept_id>
%       <concept_desc>Computing methodologies~Language resources</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
%   <concept>
%       <concept_id>10010147.10010178.10010179.10010180</concept_id>
%       <concept_desc>Computing methodologies~Machine translation</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
%   <concept>
%       <concept_id>10010147.10010178.10010179.10010185</concept_id>
%       <concept_desc>Computing methodologies~Phonology / morphology</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
%%   <concept>
%       <concept_id>10010147.10010178.10010179.10010184</concept_id>
%       <concept_desc>Computing methodologies~Lexical semantics</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
%   <concept>
%%       <concept_id>10010147.10010178.10010179.10010183</concept_id>
%       <concept_desc>Computing methodologies~Speech recognition</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
%   <concept>
%       <concept_id>10010147.10010178.10010179.10003352</concept_id>
%       <concept_desc>Computing methodologies~Information extraction</concept_desc>
%       <concept_significance>500</concept_significance>
%       </concept>
% </ccs2012>
%\end{CCSXML}

%\ccsdesc[500]{Computing methodologies~Language resources}
%\ccsdesc[500]{Computing methodologies~Machine translation}
%\ccsdesc[500]{Computing methodologies~Phonology / morphology}
%\ccsdesc[500]{Computing methodologies~Lexical semantics}
%\ccsdesc[500]{Computing methodologies~Speech recognition}
%\ccsdesc[500]{Computing methodologies~Information extraction}

%#####
%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\keywords{African Languages, Nigerian Languages, NLP, Hausa, Yorùbá, Igbo, low-resource Language, Natural Language Processing.} 

%\received{20 February 2025}
%\received[revised]{12 March 2025}
%\received[accepted]{5 June 2025}

%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.


\maketitle       




%########################################################################################################################################################### 
\section{Introduction}
\label{sec:introduction} 

Of the 7,164 distinct languages spoken globally \cite{globallang2025}, over 90\% are classified as low-resource (LR) from a computational perspective. 
While there is no universal consensus on what constitutes a low-resource language \cite{nigatu2024zeno}, a language is generally considered low-resource if it suffers from insufficient parallel source-target data \cite{ortega2021love}. 
In other words, low-resource languages (LRLs) are languages for which statistical methods cannot be directly applied due to scarce resources \cite{magueresse2020low}. 
Essentially, the term low-resource encompasses a broad spectrum of resource conditions and application domains \cite{duong2017natural,hedderich2020survey,yazar2023low,avetisyan2023large,krasadakis2024survey,maddu2024survey,masethe2024word}. 
Numerous studies have explored low-resource natural language processing (LR-NLP) across diverse domains, including misinformation detection \cite{wang2024monolingual}, security and defence
\cite{teze2024future}, neural machine translation \cite{andrabi2021review,shi2022low}, cyberbullying detection \cite{mahmud2023cyberbullying}, and sentiment analysis \cite{ghafoor2021impact,mabokela2022multilingual,girija2023analysis,yusuf2024sentiment}. 
A common denominator across these tasks is that LRLs suffer from a severe lack of linguistic resources, resulting in suboptimal performance in downstream NLP applications.  
The lack of sufficient linguistic resources affect LR-NLP within broader research topics \cite{joshi2020state}. 
A similar gap exists in the literature regarding NLP for Nigerian languages, particularly the three major languages (Hausa, Yorùbá, and Igbo), collectively referred to as NaijaNLP in this work. 
Many studies have treated low-resource languages as a homogeneous category, overlooking critical variations in data availability, linguistic resources, and computational support. The binary classification - differentiating languages as merely low-resource or high-resource - has been a dominant approach in NLP research \cite{hedderich2020survey,yazar2023low,krasadakis2024survey,maddu2024survey,masethe2024word}. 
However, we argue that this dichotomy may impede language enrichment progress, as it fails to account for the unique challenges faced by individual or regional language groups. Instead, we advocate for a more nuanced approach that examines specific linguistic and regional contexts, identifies their distinct challenges and develops tailored solutions. 

\paragraph{Scope}
This study investigates the traditional NLP landscape for NaijaNLP, with a particular focus on foundational methodologies and linguistic resources. Our primary objective is to examine classical NLP approaches, linguistic resources, and tools that have been developed to address the unique challenges faced by these three major Nigerian languages. While generative AI and similar cutting-edge technologies are transforming NLP, they fall outside the scope of this study due to the need to first establish foundational progress in traditional NLP. Instead, we offer limited coverage of applicable embedding techniques and pre-trained models relevant to NaijaNLP. To this end, we explore the NLP landscape of Nigerian languages focusing on the three major languages - Hausa, Yorùbá, and Igbo to provide targeted recommendations that can facilitate the development and expansion of LR-NLP for these languages and beyond.  

\paragraph{NaijaNLP} 
Nigeria\footnote{see \url{https://nigeria.gov.ng/} and \url{https://en.wikipedia.org/wiki/Nigeria}}, the most populous country in Africa, is home to three major languages\footnote{\url{https://en.wikipedia.org/wiki/Hausa_language}; \url{https://en.wikipedia.org/wiki/Yoruba_language}; \url{https://en.wikipedia.org/wiki/Igbo_language}} - Hausa, Yorùbá and Igbo - alongside numerous other languages and ethnic groups\footnote{\url{https://en.wikipedia.org/wiki/Demographics_of_Nigeria}}. Hausa, a Chadic language \cite{britannica2014}, is predominantly spoken in northern Nigeria and southern Niger but is widely used across West and Central Africa, including Ghana, Cameroon, Benin, Togo, Chad, Ivory Coast, and Sudan. Ranked 19th globally in terms of number of speakers\footnote{\url{https://en.wikipedia.org/wiki/List_of_languages_by_total_number_of_speakers}}, Hausa functions as a lingua franca for non-native speakers across many African countries, making it one of the most influential Chadic languages.  
Similarly, Yorùbá, a Niger-Congo language, is widely spoken in Nigeria and other parts of Africa, especially the Western part, with over 50 million speakers. 
Igbo is another major language predominant in southeastern Nigeria, spoken by over 31 million people. As a tonal language, Igbo words can differ in meaning based solely on tone, with high and low tones marked by acute and grave accents, respectively \cite{goldsmith1976autosegmental,clark2011tonal}. 
Consequently, the language employs digraphs and diacritical marks for accurate phonetic transcription. 

At least one of these three major languages is spoken by nearly every Nigerian citizen, and together, they serve as primary communication mediums for over 200 million people worldwide. Despite their significance, digital resources for these languages remain limited, even though they possess a substantial corpus of undigitised literature, including scholarly articles, books, newspapers, and pamphlets. 
While Internet use in Nigeria is increasing \cite{internetusengn2024}, the number of digitised linguistic resources remains insufficient. In this study, we adopt the term NaijaNLP\footnote{Derived from Naija, a term based on the etymon Niger, which gave its name to the river and, subsequently Nigeria.} to refer to NLP research activities and tasks related to the three major Nigerian languages: Hausa, Yorùbá, and Igbo. \citet{caron2020methodological} was our first encounter with the term \textit{Naija} utilised in the NLP context to describe research on Nigerian Pidgin. 

\paragraph{Research Questions} To identify the factors hindering the development of LRLs and their ability to fully benefit from advancements in NLP, we analyse existing studies, linguistic resources, and community support related to Nigeria's major three languages. 
To proceed with this investigation, we put forward the following key research questions:   
\begin{enumerate}[label=\ding{\numexpr171+\value*}]
    \item \textbf{State of affairs:} To assess the current landscape of NaijaNLP, we explore the following:
    \begin{itemize}
        \item[-] What linguistic and NLP resources are currently available for NaijaNLP?  
        \item[-] What efforts are underway to expand and enhance these resources?  
    \end{itemize}
    \item \textbf{Challenges and Future Prospects:} To identify barriers and opportunities for the advancement of NaijaNLP, we examine: 
    \begin{itemize}
        \item[-] What challenges prevent NaijaNLP from fully leveraging state-of-the-art NLP developments?
        \item[-] What strategies can be implemented to overcome these challenges and drive progress? 
    \end{itemize} 
\end{enumerate} 

\paragraph{Contributions} 
Our synthesis of the aforementioned research questions has led to the following key contributions: 
    \begin{enumerate}[label=\ding{\numexpr171+\value*}]
        \item \textbf{Comprehensive Analysis of NaijaNLP:} We present the first comprehensive study of NLP research on Nigeria's major languages, systematically consolidating discussions on language particularities including morphological analysis, diacritic restoration and language formalisation, which have thus far remained fragmented. Additionally, we provide a structured review of available linguistic resources, NLP tools, and initiatives driving the growth of NaijaNLP. 
        \item \textbf{Identification of of Challenges and Strategic Recommendations:} Through a critical examination of NaijaNLP, we identify its limitations, challenges, and opportunities. Based on this analysis, we propose targeted recommendations to facilitate the development and expansion of these languages in the broader context of low-resource NLP. 
        \item \textbf{Development of a Tracking Resource Hub:} Finally, we establish a dedicated platform to systematically track the progress of NaijaNLP, offering researchers a structured access to recent studies, linguistic resources, and community-driven initiatives to foster collaboration and sustained development. The repository containing research papers and tracking relevant resources for NaijaNLP is available here\footnote{\url{https://github.com/ijdutse/naija-nlp/blob/main/README.md}}. %The repository can be accessed via the following link: \url{https://github.com/ijdutse/naija-nlp}. This platform serves as a central hub for ongoing updates and collaborative contributions related to the paper and its associated resources. 
    \end{enumerate} 

The remainder of this paper is structured as follows: ~\S ~\ref{sec:methodology} details the methodology adopted in this study while ~\S ~\ref{sec:literature-review} reviews related work in NaijaNLP. Our findings and recommendations are presented in \S~\ref{sec:results-discussion}. Finally, \S~\ref{sec:conclusion} provides concluding remarks. 

\section{Methodology} 
\label{sec:methodology} 
This review systematically explores the landscape of LR-NLP research, with a specific focus on NaijaNLP to (1) examine existing NLP resources (2) identify factors affecting linguistic resource availability as well as challenges, and (3) provide recommendations for future development of NaijaNLP. 

\subsection{Databases and Search Strategies}
Figure~\ref{fig:literature-search} provides an overview of the review process, including the research questions, search terms, consulted databases, and the screening process. 
The search strategy was conducted across several academic databases\footnote{comprising of \url{https://ieeexplore.ieee.org/},\url{https://dl.acm.org/},\url{https://www.scopus.com/},\url{https://link.springer.com/},\url{https://aclanthology.org/}}, including IEEE Xplore, ACM Digital Library, Scopus/Elsevier, Springer Nature\, and ACL Anthology. Additionally, grey literature\footnote{\url{https://arxiv.org/} and \url{https://scholar.google.com}} including preprint servers such as arXiv, and relevant articles retrieved via Google Scholar, were incorporated into the review.  
To further expand the literature base, we employed a snowballing search strategy, iteratively identifying relevant studies through backward snowballing (tracing references cited in key papers), and forward snowballing (identifying subsequent papers that cite the key studies).  

    \begin{figure} 
        \centering
        \includegraphics[width=\linewidth]{figures/literature-search.png}
        \caption{Overview of the review process, highlighting (1) guiding questions and search keywords (2) search databases and corresponding retrieved results, and (3) the screening process. Variations in the final article counts are due to overlapping entries retrieved from Google's search engine and other academic databases.} 
        \label{fig:literature-search}
    \end{figure} 

\paragraph{Search Terms} To ensure a comprehensive retrieval of relevant papers, we incorporated a permutation of search terms across three key categories: 
\begin{enumerate}[label=\ding{\numexpr171+\value*}]
    \item \textbf{Language-related:} These terms include Hausa, Yorùbá, and Igbo languages 
    \item \textbf{NLP-related:} Covers terms like low-resource languages, natural language processing (NLP), machine learning (ML), deep neural network (DNN), artificial neural network (ANN), and artificial intelligence (AI).  
    \item \textbf{Task-specific:} Encompass downstream tasks such as text classification, text summarisation, sentiment analysis, speech recognition, machine translation, POS, and NER. 
\end{enumerate}  
A more detailed list of the integrated search terms is provided in Table~\ref{tab:search-terms}. 

\paragraph{Inclusion and Exclusion Criteria} 
The selection criteria encompass theses and relevant non-seminal publications originating locally. We surmise that excluding these sources could result in the omission of valuable resources and insights beneficial to the research community. Studies are excluded if they: (1) do not pertain to NaijaNLP, i.e. the study falls outside the three major Nigerian languages (2) focus on languages with substantial resources, unless they explicitly address the targeted languages. To ensure relevance and rigour, we perform a title and abstract screening to identify studies that align with the guiding research questions. This is further reinforced through a final review of the selected papers. 

\paragraph{Preliminary Analysis} 
Our initial analysis revealed significant overlap in retrieved results, likely due to the frequent co-occurrence of these languages in research queries or studies involving at least two of them. As a result, the total number of retrieved studies may not directly reflect the number of relevant studies specifically addressing each language. Furthermore, an examination of major academic databases highlighted a scarcity or complete absence of NaijaNLP research from high-impact venues such as Nature, NeurIPS, the main tracks of ICLR, ACL, and AAAI (see Figure~\ref{fig:publication-venues}). However, the increasing volume of NaijaNLP research output in Figure~\ref{fig:publication-trend}, particularly from 2020 onward, signals a promising rise in contributions to linguistic resources and advancements in the field. 

    \begin{figure}[htbp]
        \centering
        \begin{subfigure}[b]{0.48\textwidth} 
            \centering
            %\includegraphics[width=\linewidth]{figures/publication_trend_over_years.png}
            \includegraphics[width=\linewidth]{figures/publication_trend_over_years1.png}
            \caption{Publication trend from the initial search before the snowbowling search.}
            \label{fig:publication-trend}
        \end{subfigure}
        \hfill %####################
        %%%%%%%
        %\begin{subfigure}[b]{0.48\textwidth}
        \begin{subfigure}[b]{0.49\textwidth}
            \centering
            %\includegraphics[width=\linewidth]{figures/publication_counts_heatmap.png}
            \includegraphics[width=\linewidth]{figures/publication_counts_heatmap1.png}
            \caption{Publication year and venue.}
            \label{fig:publication-venues}
        \end{subfigure}
        \caption{Frequency of research output and publication venues for NaijaNLP.} %The increasing volume of NaijaNLP research output, particularly from 2023 and beyond, serves as a positive indicator of growing contributions to linguistic resources and advancements in the field.} 
        \label{fig:publication-trend-venues}
    \end{figure}

\section{Literature Review}
\label{sec:literature-review}
As a communication system, natural language comprises of structured sequences of sounds, symbols, or gestures that convey meaning in spoken, written, or signed forms. 
From a formalisation perspective, languages are composed of structured strings of lexical categories (pre-terminals), forming well-defined sentences that facilitate statistical analysis of their structure \cite{culy1996formal, gunther2022language}. Advancements in Artificial Intelligence (AI) and Machine Learning (ML) have provided powerful tools for processing languages through NLP techniques. However, the effectiveness of NLP models depends on the availability of extensive and relevant linguistic resources, leading to a fundamental divide between high-resource and low-resource languages. High-resource languages (HRLs), such as English, French, and Spanish, benefit from abundant digital resources and large-scale initiatives like the Linguistic Data Consortium, which facilitate access to multilingual text resources in standardised and compatible formats \cite{graff1994multilingual,cho2014properties}. These resources, sourced from governmental bodies, international organisations, news agencies, and publishers, play a crucial role in advancing various NLP applications. 
Efforts to enrich and digitise LRLs, such as transducing texts \cite{randell1998hausar}, resource enrichment \cite{adegbola2009building}, and digitising indigenous poetry \cite{hausapoetry} are essential for their integration into computational frameworks. 

\subsubsection{Past Reviews} 
As previously noted, advancements in NLP have predominantly benefited high-resource languages, while LR-NLP continues to face unique challenges owing to limited linguistic resources. Several past studies \cite{zhang2017embracing,fadaee2017data,fan2021beyond,costa2022no,adebara2022afrolid,robertson2022understanding,raychawdhary2024optimizing,zhou2024character} have examined the state of LR-NLP, highlighting these challenges to LRL development. Similarly, numerous studies have investigated NLP research involving the three major languages in Nigeria. However, these studies tend to focus on either a single language such as Hausa \cite{zakari2021systematic}, Yorùbá \cite{yusof2013review}, Igbo \cite{nwankwegu2021leveraging,maryann2021machine,orji2024igbo} or they concentrate on specific NLP tasks like machine translation \cite{benito2022machine,haddow2022survey}, text summarisation \cite{edwards2023text}, automatic speech recognition for tonal languages \cite{kaur2021automatic}, and sentiment analysis \cite{raychawdhary2024enhancing}. Other reviews adopt a broader perspective by covering various African languages \cite{caron2020methodological,hedderich2020survey,asubiaro2021state,asubiaro2021evaluating,adelani2022natural,obiajuludigital,emmanuelcurrent,ezugwu2023machine,abdou2024review,hu2024review}. 
While these studies offer valuable insights, they provide only a fragmented perspective on the current state of NLP research in the targeted languages. Our review builds upon previous studies by incorporating a wider scope, accounting for recent advancements, open-access resources, and community-driven initiatives. 
Thus, we provide a comprehensive analysis of the NaijaNLP landscape, examining ongoing research efforts, available datasets, tools, language communities, and initiatives aimed at facilitating LR-NLP development. The subsequent discussions involving the three languages are organised alphabetically by language, following the order: Hausa, Igbo, Yorùbá. 

\subsection{Formal Grammar and Knowledge Representation} 
\label{sec:grammar-and-knowledge-representation}
We begin our review with formal grammar and knowledge representation due to their fundamental role in developing robust NLP tools and applications. Computational grammar facilitates language enrichment through systematic analyses of syntax, semantics and linguistic structures, enabling the creation of reusable linguistic resources for LRLs \cite{crysmann2012hag}. In this regard, several studies have explored grammatical formalisation \cite{abdoulaye1992aspects,culy1996formal,crysmann2009autosegmental,copestake2002implementing,crysmann2012hag,blasi2017grammars}, morphological analysis \cite{finkel2009computational,eludiora2018computational}, and knowledge representation \cite{eze1997aspects,aina2021ontology,ifeanyi2022semantic,aina2023human} for Hausa, Igbo and Yorùbá languages. 
Notably, \citet{abdoulaye1992aspects} apply the Role and Reference Grammar framework\footnote{see \citet{van1980role}} to provide new insights into Hausa sentence structure and linguistic processes. 
Similarly, \citet{crysmann2009autosegmental} examine lexical and grammatical tone and vowel length in Hausa, utilising bidirectional Head-Driven Phrase Structure Grammar (HPSG) based on the Lingo Grammar Matrix \cite{bender2002grammar}. This effort also incorporates a Linguistic Knowledge Builder \cite{copestake2002implementing} representation inspired by linguistic and computational work on Autosegmental Phonology \cite{crysmann2009autosegmental}. Additionally, \citet{crysmann2012hag} implement a formal grammar for Hausa, leading to the development of the HaG platform for grammatical structure generation. Beyond these studies, \citet{blasi2017grammars} analyse the transmission of grammatical features across 48 creole and 111 non-creole languages. Further discussions on morphological analysis and diacritic restoration - particularly for Yorùbá and Igbo - are presented in \S~\ref{sec:language-particularity}. 

Noting that a key challenge in knowledge representation is maintaining logical consistency, particularly in narrative structures, \citet{alade2019issues} analyse issues in standardised knowledge representation for Yorùbá narrative. Their study identify challenges such as imprecise event codification and concept representation. In the context of Hausa NLP, \citet{abubakar2019hausa} develop Hausa WordNet, a lexical resource that extracts knowledge from Kamus (Hausa dictionary). For collocational analysis, \citet{umaraspects} examine collocational patterns in Hausa, investigating their semantic significance and degree of collocability. To further advance lexicographic resources, \citet{enguehard2014computerization} propose a system for converting bilingual African language-French dictionaries (including Bambara, Hausa, Kanuri, Tamajaq, and Songhai-Zarma) from Word format to XML, following the Lexical Markup Framework. 

Despite their importance, studies on formal grammar and knowledge representation remain limited for NaijaNLP. Nevertheless, they provide a crucial foundation for digital language resource development by offering structured frameworks for language processing. 

\subsection{Language Particularities}  
\label{sec:language-particularity}
Languages exhibit distinct structural, phonetic, and orthographic characteristics that influence how they are written, pronounced, and processed. These particularities manifest in diverse orthographic systems, including alphabets, abjads, syllabaries, and logograms, which shape word formation and written representation. Additionally, phonetic variations - such as differences in phonemes, stress patterns, and tonal systems - impact how languages are spoken and understood. Recognising and integrating these linguistic nuances is essential for developing effective NLP tools that accurately represent the unique feature of each language \cite{adebara2022towards}. 
Several Nigerian languages are tonal and employ characters beyond the basic Latin alphabet, making them structurally distinct from English and other high-resource languages. A failure to adequately account for these particularities often hinders the adaptation and effectiveness of existing NLP tools developed primarily for English and other HRLs in the context of LRLs. Addressing this challenge, numerous studies have explored the linguistic diversity and specific needs of Nigeria's major languages \cite{amuda2010limited,oyinloye2015issues,abdulkareem2016yorcall,adewumi2020challenge}. Furthermore, \citet{adebara2022towards} examined key linguistic and sociopolitical challenges affecting NLP development for African languages. This section reviews existing studies on the linguistic particularities of Nigerian languages, with a focus on morphological analysis and diacritic restoration. 
Both morphological analysis and diacritic restoration play crucial roles in improving the accuracy and performance of NLP applications. Among Nigeria's three major languages, Igbo and Yorùbá make extensive use of diacritical marks, further emphasising the need for language-specific NLP approaches. 

\subsubsection{Morphological Analysis}
\label{sec:morphological-analysis}
Morphological analysis explores word structure and formation. The languages within NaijaNLP exhibit rich morphological complexity, which has been documented in various studies. 
To that end, \citet{iheanetu2017some} analyse the morphological structure of Igbo language, identifying key challenges that hinder practical NLP applications. 
Building on this, \citet{iheanetu2019addressing} develop a data-driven model capable of inducing non-concatenative morphological structures, cascaded affixation, and affix labelling using a frequent pattern-based induction approach. To uncover deeper linguistic patterns, \citet{ochu2019corpus} apply concordance line strategies to extract multiword expressions in Igbo. 
Further examining text representation strategies, \citet{chidiebere2020analysis} investigate collocation patterns, word order, compounding, and lexical ambiguity in Igbo, offering insights into language processing challenges. Additionally, \citet{henry2020performance} evaluate a text-based intelligent system designed to determine the optimal operational level for Igbo NLP applications. 
Similar studies have been conducted for Yorùbá, further highlighting the linguistic complexities and computational challenges associated with morphological analysis in NaijaNLP. 
\citet{oyinloye2015issues} develop VerbMorpher, a computational system designed for morphological analysis of standard Yorùbá verbs. This system incorporates linguistic resources that can be utilised for spell-checking, syntax analysis, and dictionary functionalities. 
To enhance morphological analysis efficiency, \citet{adegbola2016pattern} employ an unsupervised induction approach to infer morphological rules for standard Yorùbá. Unlike conventional methods that rely on word-segment frequency, their approach is pattern-based, leveraging word-pattern frequency. Although the study alluded to lexicons collected for the development of a Yorùbá speech synthesizer project, access to the data remains unavailable.  
Similarly, to improve data curation and quality, \citet{adewole2017token} develop a token validation system for automated corpus collection from online sources. To further standardise Yorùbá linguistic resources, \citet{oluwatoyinstochastic} introduce YoTEx (Yoruba Text Lexicon), a repository that learns from English language corpora to enhance Yorùbá text processing. 
In related work, \citet{okediya2019building} leverage various online resources - including books, blogs, social websites, and Yorùbá dictionaries - to construct a general - purpose lexical ontology for Yorùbá NLP applications. 


Addressing the morphological and structural complexities of Yorùbá in translation, \citet{adebara2021translating} develop a strategy for handling language-specific morphological marking, particularly in cases where features present in English (e.g. morphological markers) are contextually inferred in Yorùbá. 
Motivated by the lack of machine-readable sense inventory for ambiguous Yorùbá words, \citet{adegokedevelopment} design a disambiguation component for a Yorùbá-English machine translation system. Additionally, \citet{akinwonmi2024rule} introduce the declarative rule-based syllabification algorithm to address syllabification errors in Yorùbá, particularly for consonant-vowel-nasal and diphthong-vowel-nasal structures. Their approach involves curating a corpus for syllabic misclassification detection, which is subsequently evaluated using ML models. A more recent study by \citet{frohmann2024segment} explores alternative sentence segmentation strategies, moving beyond traditional rule-based and statistical methods that rely solely on lexical features. Their approach presents novel insights into text segmentation techniques applicable to Yorùbá NLP. 

\subsubsection{Diacritic Restoration} 
\label{sec:diacritic-restoration} 
Diacritic restoration involves adding or correcting diacritical marks\footnote{Such as accents, umlauts (two dots), and tildes.} in textual data. This process is essential for handling historical texts, user-generated content, and datasets where diacritics may have been omitted due to technical constraints. 
Given that many African languages utilise Latin-based scripts with diacritical marks, \citet{scannell2011statistical} propose a strategy and open-source package for automatic unicodification\footnote{The process of converting ASCII text into its proper Unicode form \cite{scannell2011statistical}.} across multiple languages. 
Addressing orthographic and tonal diacritics, \citet{ezeani2016automatic} apply n-gram models trained on the Igbo Bible corpus for word-level diacritic restoration. Recognising the role of diacritics in pronunciation, meaning differentiation, and lexical disambiguation, \citet{ezeani2017lexical} develop a disambiguation strategy through diacritic restoration for the Igbo language. Further advancements in this domain include the use of embedding models for text similarity computation and diacritic restoration \cite{ezeani2018transferred,ezeani2018igbo}. 
For Yorùbá diacritic restoration, \citet{de2007automatic} explore various ML models to improve diacritic restoration accuracy. 
\citet{tunji2011design} propose an enhanced approach that integrates tonal information into text-to-speech systems for the standard Yorùbá language. 
Recognising that omitting tonal information leads to performance degradation, \citet{adegbola2012quantifying} evaluate ML models for handling tone-mark representation in Yorùbá text processing. Inconsistencies in diacritic usage within electronic Yorùbá documents have been examined in \citet{asubiaro2015statistical}, highlighting their impact on NLP applications. 
Additionally, \citet{asahiah2017restoring}, \citet{orife2018attentive}, and \citet{alabi2020massive} investigate optimal strategies for integrating diacritics and analyse their effects on model performance for Yorùbá NLP tasks. The broader challenge of machine translation for African languages particularly Yorùbá is explored in \citet{odoje201612}. To improve word embeddings for diacritic-sensitive languages, \citet{orife2020improving} and \citet{adewumi2020challenge} examine the impact of working with undiacritised (normalised) datasets. \citet{adewumi2020challenge} further introduce new analogy sets to aid evaluation and a rule-based framework for Elision resolution\footnote{The omission of tone or syllable from a text.} in Yorùbá is proposed by \citet{adewole2020automatic}, while \citet{asahiah2023diacritic} develop a spell-checking and correction system that explicitly accounts for diacritic presence. Additionally, \citet{ogheneruemu2022development} leverage deep learning for diacritic restoration in tonal languages such as Yorùbá. 
In addressing diacritic usage and pronunciation challenges, \citet{abdulkareem2016yorcall} introduce the YorCALL system, which aims to enhance user proficiency in applying diacritics correctly in Yorùbá. 

\subsubsection{Numerical System} 
The challenges stemming from the lack of or limited standardised linguistic resources extend beyond textual to numerical data. A key area of interest is assessing whether NaijaNLP possesses the necessary linguistic resources, such as well-defined numerical lexicons, for developing numerical systems through published research. The earliest attempt at analysing Hausa numerals for machine processing dates back to the Automatic Text Comprehension project \cite{sigurd1980numbers}. This project surveyed numerical systems and examined challenges related to converting spoken numerals into decimal representations, ultimately leading to the development of an automated rule-based systems. The system enabled bidirectional conversion between mathematical representations and their linguistic counterparts, i.e., numerals \cite{sigurd1980numbers}. 
In a related effort, \citet{agbeyangi2016web} introduce a numeral translation system for English-Yorùbá, while \citet{mustapha2023automated} formulate an algorithm for converting numerical figures into words in Hausa. Similarly, \citet{rhoda2017computational} develop a number-text conversion system for Igbo, contributing to the broader goal of numerical processing in LRLs. 
Beyond numerical conversion, advancements in handwritten numerical recognition have been explored. For instance, \citet{ajao2022yoruba} develop a Yorùbá handwritten character recognition using convolutional recurrent neural networks, demonstrating the application of deep learning techniques in linguistic digitisation efforts. 
Despite these developments, research on numerical systems in NaijaNLP remains limited, highlighting the need for further studies and resource development to ensure accurate numerical representation and processing across languages.  

\subsection{LR-NLP Tools and Resources} 
The development of relevant tools, resources, and techniques is essential to enable various NLP downstream tasks and to facilitate wider language coverage for robust LR-NLP applications \cite{crysmann2009autosegmental}. The lack of sufficient linguistic resources and pre-processing tools presents a significant challenge for LRLs, particularly when diacritic and morphological features must be considered. 
To address these challenges, several initiatives, resources, and tools have been developed to support LRLs. A case in point is the low-resource Human Language Technology (LoReHLT) project, which evaluates the DARPA\footnote{Defense Advanced Research Projects Agency (DARPA) - \url{https://www.darpa.mil/}} Low-Resource Languages for Emergent Incidents (LORELEI) research program \cite{christianson2018overview}. The LORELEI initiative includes both Hausa and Yorùbá, providing researchers with resource packages for LRLs. These packages comprise monolingual and parallel texts, a bilingual dictionary, text annotated with part-of-speech (POS) tags, named-entity-recognition (NER), and noun-phase-chunking annotations. Furthermore, language processing tools such as segmenters and morphological analysers, aimed at improving NLP capabilities for these languages have been included \cite{christianson2018overview}. 
Another significant contribution is AfroLID, a neural language identification (LID) toolkit designed to support LR-NLP and web data mining for approximately 517 African languages \cite{adebara2022afrolid}. 

In analysing the available tools and resources for NaijaNLP, we focus on relevant key research areas aligned with the LORELEI research initiative \cite{christianson2018overview}. Additional research areas outside these categories will also be considered necessary to ensure a comprehensive evaluation of available LR-NLP tools and resources.

\subsubsection{Linguistic Resources} 
\label{sec:linguistic-resources-datasets} 
Linguistic resources constitute a fundamental component in the development of robust NLP applications. Several initiatives have been introduced to support NaijaNLP. \citet{adegbola2009building} highlight key initiatives, notably the African Languages Technology Initiative (Alt-i), aimed at enhancing NLP support for major Nigerian languages. Similarly, \citet{chiarcos2011information} provide tools and annotation resource to facilitate NLP downstream tasks across 25 sub-Saharan languages, including Hausa, Yorùbá and Igbo. 
As part of this effort, they develop ANNIS - ANNotation of Information Structure - a corpus tool that offers unified access to various linguistic annotations and data archives. To further advance lexicographic resources, \citet{bigi2017developing}, introduce language resources and Human Language Technologies (HLT) tools for Nigerian Pidgin, consisting of a tokeniser and automatic speech system for predicting word pronunciation and segmentation. 
For Igbo NLP, \citet{onyenwe2018basic} propose POS-tagging resources including a POS tagset and a tagged subcorpus. 
Addressing the broader LR-NLP landscape, \citet{costa2022no} explore strategies to narrow the performance gap between high-resource and low-resource languages. Their approach involves exploratory interviews with native speakers, data creation, and model development. Meanwhile, \citet{turki2024text} investigate the role of text categorisation in optimising stopwords extraction, with a specific focus on African languages. 

%\subsubsection{Datasets} 
%\noindent\textbf{Datasets - } 
\vspace{0.36cm}\noindent \textbf{Datasets - }
Data serve as a fundamental building block for NLP technologies. Recognising this, researchers have developed various datasets of differing sizes and levels of diversity to support LR-NLP tasks. The following section provides a review of available datasets for NaijaNLP. 

\paragraph{Hausa Datasets}
Several efforts have been made to develop datasets for NLP applications in the Hausa language. 
\citet{imam2022first} compile a dataset of approximately 2600 articles to support fake news detection in Hausa language and \citet{vargas2024hausahate} introduce the first expert-annotated dataset for Hausa hate speech detection, consisting of 2,000 comments extracted from Facebook. 
\citet{zandam2023online} curate a Hausa dataset containing threatening lexicons, sourced from Twitter. 
\citet{inuwa2021first} provide an expansive dataset containing both formal and informal Hausa text. 
For sentiment analysis, \citet{mohammed2024lexicon} develop a Hausa dataset comprising 14,663 instances (4,154 positive, 4,310 negative, and 6,199 neutral sentiments). The dataset was created using words and phrases from Hausa dictionary\footnote{see \textit{Kamus na Hausa zuwa Turanci} \cite{rigdon2017english}} and further expanded through data augmentation techniques.
Similarly, \citet{shehu2024unveiling} develop a Hausa sentiment analysis lexicon alongside a customised stemming method to enhance model performance.
\citet{awwalu2021corpus} construct the Hausa Tagset (HTS) for POS tagging, while \citet{salifou2014design} design a spell-checking and correction tool for Hausa, which is accessible via LyTexEditor and includes an extension (add-on) for \url{OpenOffice.org}. 
\citet{adam2024detection} compile a dataset of offensive content in Hausa language, and \citet{ibrahimnecat} develop a parallel datasets closely aligned with the target languages to enhance machine translation involving Hausa. 

\paragraph{Igbo Dataset}
Several studies have contributed to the development of datasets supporting NLP tasks in the Igbo language as well. 
\citet{onuora2024machine} and \citet{ana2024ai} curate datasets for Igbo hate speech detection.
For cyberbullying detection, \citet{okoloegbomultilingual,okoloegbo2022multilingual} develop datasets covering both Igbo and Nigerian Pidgin English. 
\citet{onyemaechi2023some} present a database consisting of 158 Chi-prefixed Igbo personal names, categorised into praise, thanksgiving, testimony, prayer, and declarative groups. 
\citet{chiomaweb} compile an Igbo thesaurus, covering a comprehensive set of words and their meanings.
\citet{nganga2020spoken} describe a methodology for creating a digital dialectal dictionary for Igbo, sourced from spoken-word corpora and oral traditions.
\citet{ajao2023recurrent} develop an RNN-based handwritten character recognition system for Igbo using data from native speakers.


\paragraph{Yorùbá Datasets}
Similarly, multiple datasets have been developed to support various NLP applications in Yorùbá language. 
\citet{fagbolu2015digital} introduce one of the earliest Yorùbá corpora to support machine translation and other NLP downstream tasks. 
\citet{ademusire2023development} curate annotated Yorùbá data for event extraction and \citet{akpobi2024yankari} develop Yankari, a large-scale monolingual Yorùbá dataset. 
\citet{orife2018attentive} offer datasets and source code for various Yorùbá NLP applications. 
\citet{ahia2024voices} provide text and speech data to address dialectal discrepancies in Yorùbá.  
%Audio and Speech Recognition: 
\citet{afolabi2013implementation} develop an audio database for Yorùbá consonant-vowel syllables, the alphabet, and a text-to-speech system. 
In a related work, \citet{iyanda2015statistical} compile a Yorùbá corpus for speech generation, sourced from textbooks, newspapers, and online materials. 
\citet{gutkin2020developing} produce a speech synthesis dataset, comprising over four hours of 48 kHz recordings in Yorùbá, while \citet{akinwonmi2021development} develop annotated prosodic read-speech syllabic data, extracted from fictional books and online scriptures. 

\paragraph{Multilingual Datasets} 
To address the challenges of LRLs and mitigate reliance on costly annotation, several initiatives have contributed to multilingual datasets. 
\citet{hedderich2022weak} propose a weak-supervision and noise-handling strategy to facilitate LRLs data expansion. 
To support the provision of high-quality human-annotated cross-lingual information retrieval resources for African languages, \citet{adeyemi2024ciral} present CIRAL\footnote{Available at \url{https://github.com/ciralproject/ciral}}, a publicly available test collection for cross-lingual retrieval, covering English queries with passages in Hausa, Somali, Swahili, and Yorùbá.  
\citet{muhammad2022naijasenti} introduce the first large-scale human-annotated Twitter sentiment dataset, covering Hausa, Igbo, Nigerian Pidgin, and Yorùbá, with approximately 30,000 annotated tweets per language, including code-mixed examples.  
In a related effort, \cite{adelani2021masakhaner} introduce a large-scale, publicly available dataset for NER across ten African languages. Furthermore, \cite{muhammad2025afrihate} develop AfriHate, a multilingual corpus of annotated hate speech and abusive language data spanning 15 African languages.  
\citet{aliyubeyond} compile datasets in Hausa, Yorùbá, and Igbo for hate speech detection and \citet{varab2021massivesumm} develop multilingual text summarisation data consisting of 28.8 million articles from 92 languages. 
\citet{adelani2023masakhanews} develop MasakhaNEWS, the largest dataset for news classification in 16 African languages. 
\citet{varab2021massivesumm} introduce a multilingual text summarisation dataset containing 28.8 million articles across 92 languages. 
\citet{ferroggiaro2018social} develop hate speech lexicons for several Nigerian languages, and \citet{ogunleye2023using} utilise 346,000 Nigerian banking-related tweets to develop SentiLeye, a lexicon-based sentiment analysis dataset for Nigerian Pidgin.
\citet{adelani2022natural} introduce large-scale human-annotated datasets for NER and machine translation across 21 African languages. 
\citet{scholar2022development} develop a multilingual electronic dictionary covering English, Hausa, Yorùbá, and Igbo, designed for handheld devices. 

To support multilingual machine translation, \citet{fan2021beyond} provide an open-source training dataset covering thousands of language pairs with parallel data. \citet{ekpenyong2022towards} introduce a parallel Hausa-English corpus and explore initiatives for multilingual machine translation.
\citet{adewumi2023afriwoz} compile high-quality dialogue datasets for six African languages (Swahili, Wolof, Hausa, Nigerian Pidgin, Kinyarwanda, and Yorùbá), accessible via Hugging Face.
\citet{ajagbe2024developing} develop a multilingual Nigerian speech dataset (English, Yorùbá, and Pidgin) for antenatal orientation, sourced from six antenatal clinics.
\citet{amuda2010limited} contribute the UISpeech corpus, an audio-visual dataset of Nigerian-accented English, recorded from native speakers of Hausa, Igbo, Yorùbá, Tiv, and Fulfulde. 
\citet{parida2023havqa} develop HAVQA, a Hausa multimodal dataset that integrates descriptive images to enhance Hausa-English translation. \citet{abdulmumin2022hausa} develop HaVG, a Hausa multimodal translation dataset, integrating descriptive images to enhance Hausa-English translation.
\citet{kolak2005ocr} propose a lexicon-free OCR post-processing method for low-density languages.
\citet{omotayo2024state} examine how the limited availability of computing resources and datasets constrains computer vision research in Hausa, Yorùbá, and Igbo.
In a related effort, \citet{ibrahim2021convolutional} apply CNNs to classify traditional male attire from these ethnic groups. 
\citet{adewumi2022itakuroso} explore cross-lingual transfer learning and provide Hugging Face model checkpoints for African LRLs.
\citet{goyal2022flores} introduce FLORES, a benchmark dataset for evaluating multilingual NLP performance in low-resource languages. 
To ensure the integrity and utility of the FLORES data, \citet{abdulmumin2024correcting} engage native speakers to identify and correct inaccurate and inconsistent cases in Hausa, Northern Sotho (Sepedi), Xitsonga, and isiZulu languages. 
\citet{aremunaijarc} develop NaijaRC, a multichoice reading comprehension dataset for Hausa, Igbo, and Yorùbá.
\citet{godslove2024trilingual} present a trilingual model for multi-dialect conversational AI in African languages.

These datasets serve as essential resources for advancing NLP applications, including fake news and hate speech detection, machine translation, sentiment analysis, and linguistic annotation. The increasing number of multilingual resources highlights a growing trend of collaborative research and initiatives aimed at enriching NaijaNLP. 

\paragraph{Linguistic Tools} 
Building on existing corpora, various linguistic tools have been developed to enrich and ensure the accurate representation of LRL. Some of these tools address the specific linguistic characteristics of individual languages, while others focus on enhancing linguistic resources more broadly. Notable examples include automatic spell checkers and correctors for Yorùbá \cite{oluwaseyi2024automatic} and Hausa \cite{mijinguini2003ƙaramin,salifou2014design}, an automatic Hausa stopword constructor \cite{bichi2022automatic}, and an Igbo text analyser \cite{azubuike2024design}. 
The following section provides a detailed examination of linguistic tools including part-of-speech (POS) tagging and named entity recognition (NER) tools within NaijaNLP.  

\subsubsection{Part-of-Speech Tagging and Named Entity Recognition}  
Each word in a text belongs to a grammatical category, such as noun, verb, adjective, or adverb, depending on its context and definition. Part-of-Speech (POS) tagging assigns words to their corresponding grammatical categories, facilitating the structural analysis of sentences. Similarly, some words in a text refer to specific entities such as people, organisations, locations, dates, and quantities. Thus, Named Entity Recognition (NER) identifies and classifies such entities accordingly. To that end, several studies have explored POS tagging and NER for NaijaNLP. 
\citet{ren2016automatic} present data-driven methods for recognising entities in large-scale, domain-specific text corpora across both high- and low-resource languages. 
\citet{adelani2020distant} examine NER in Hausa and Yorùbá, while \citet{model2020accent} explore accent classification for Nigerian-Accented English, covering Hausa, Yorùbá, and Igbo. 
\citet{oyewusi2021naijaner} develop NER models for Nigerian Pidgin English, Igbo, Yorùbá, and Hausa. 
\citet{tukur2024towards} introduce a POS tagger for Kanuri\footnote{A Nilo-Saharan language spoken in the Lake Chad Basin of West and Central Africa} and corresponding corpus. 
\citet{adewumi2022itakuroso} explore cross-lingual transfer learning to optimise Hausa and Yorùbá POS and NER tasks. 
\citet{mehari2024semi} employ semi-supervised data augmentation combined with pretrained language models to enhance NER for LRLs. 

\paragraph{Hausa POS \& NER}
Given the limitations of classic stemmers based on Porter’s algorithm \cite{porter1980algorithm}, researchers have developed Hausa-specific stemming techniques \cite{bashir2015word,bimba2016stemming,musa2022improved}. 
Essentially, \citet{bashir2015word} introduce an automatic Hausa word stemming system to optimise text processing. 
\citet{bimba2016stemming} develop a stemming strategy using affix-stripping rules\footnote{78 affix-stripping rules applied in 4 steps} and reference lookup\footnote{A database of 1,500 Hausa root words}. 
Recognising the importance of entity extraction in disaster response and large-scale incidents\footnote{e.g., disease outbreaks and natural calamities}, \citet{lu2016multi} present a method for learning entity priors from extensive Hausa text corpora.  
\citet{zhang2017embracing} propose a low-resource POS tagging strategy aimed at minimising noise in supervised learning methods by integrating diverse linguistic sources\footnote{e.g., the World Atlas of Linguistic Structure, CIA names, PanLex, and survival guides}.
To address challenges posed by the use of non-standard words (NSWs) in Hausa social media communication, \citet{maitama2014text} propose a text normalisation system based on handcrafted rules for converting NSWs into standard Hausa text. 
\citet{tukurcorpus,tukur2019tagging,tukur2020parts} explore POS tagging techniques to facilitate sentiment analysis of Hausa web content.
\citet{awwalu2021corpus} develop the Hausa Tagset (HTS) for POS tagging, while \citet{musa2022improved} introduce a stemming algorithm to enhance Hausa information retrieval.

\paragraph{Igbo POS \& NER} 
Several linguistic tools and resources have been developed for Igbo. 
\citet{onyenwe2015use, onyenwe2016predicting} contribute to Igbo linguistic resource development. 
\citet{onyenwe2014part, onyenwe2019toward} and \citet{olamma2019hidden} develop POS taggers for Igbo. 
\citet{anbootstrapping} propose cross-lingual and monolingual POS tag projection approaches for Igbo POS tagging. 
For NER in Igbo, researchers have focused on cross-lingual learning. 
\citet{chukwuneke2023igboner} introduce an Igbo NER system based on a cross-language projection method, leveraging parallel English-Igbo corpora and \citet{soronnadienhancing} develop IgboBERTa, a transformer-based model optimised for Igbo NLP tasks, including NER, text classification, and sentiment analysis. 

\paragraph{Yorùbá POS \& NER}
Similarly, significant efforts have been made to advance Yorùbá POS tagging and NER. 
\citet{kumolalo2010development} propose a rule-based approach to enhance Yorùbá syllabification, mapping words to their corresponding syllables. 
\citet{adedjouma2013part} curate a Yorùbá corpus focused on POS tagging, and \citet{abiola2014web} develop an English-to-Yorùbá translation system. 
\citet{adegunlehin2019investigation} improve Yorùbá NER by incorporating contextual information such as surrounding words and POS tags. 
\citet{omolaoye2020proverb} introduce a computational approach for the representation of Yorùbá proverbs, contributing to indigenous knowledge preservation. 
\citet{ugwu2024part} train a POS tagger using Yorùbá religious texts and dictionary entries.
\citet{toyin2024hidden} introduce a Hidden Markov Model (HMM)-based POS tagger, contributing a manually annotated dataset of 1,000 Yorùbá sentences drawn from various domains. 

The development of POS tagging and NER tools for Hausa, Igbo, and Yorùbá has contributed significantly to NaijaNLP. These tools are critical in addressing language-specific challenges, enhancing computational linguistic resources, and facilitating various downstream tasks. 
While existing resources have proven useful, further research and dataset expansion are needed to bridge gaps and improve linguistic tool development for NaijaNLP. 

\subsection{Downstream Tasks} 
In NLP, downstream tasks such as text classification, sentiment analysis, text summarisation, machine translation, and speech recognition rely fundamentally on robust linguistic resources, including annotated datasets, computational models, and standardised frameworks. In this section, we review the existing downstream tasks and applicable resources developed for Hausa, Igbo, and Yorùbá languages. 

\subsubsection{Text Classification and Summarisation} 
Text classification (TC) involves assigning textual data to predefined classes based on similarity or dissimilarity, using a range of methodologies from rule-based approaches to machine learning, deep learning, and transformer-based models. Complementary to text classification, text summarisation (TS) aims to generate concise and coherent summaries that retain the essential information of longer texts. 
To that end, \citet{asubiaro2018word} propose a strategy for language identification at the word-level to enhance model performance for LRLs, thereby improving the prediction of a word's language. In a related effort, \citet{varab2021massivesumm} develop a multilingual text summarisation framework by enriching existing resources to facilitate machine translation (MT) on a large scale. Furthermore, \citet{olalekan2022machine} introduce multilingual text classification models for English, Yorùbá, and Hausa, while \citet{bashir2017automatic} present a model trained on a corpus of Hausa documents for automatic summarisation. Additional contributions include the work of \citet{bichi2023graph,bichi2024integrating}, who develop an automatic summarisation strategy for Hausa text. 
For Igbo, \citet{ifeanyi2020comparative} and \citet{ifeanyin} propose classification systems based on n-gram models and k-nearest neighbours techniques to improve text representation and classification. In parallel, \citet{mbonu2022igbosum1500} offer a detailed discussion about the development of the IgboSum1500 dataset, a dedicated resource for Igbo text summarisation. Meanwhile, \citet{adegokeestimating} explore models designed to compute semantic similarity between Yorùbá sentences. 
For text summarisation, in particular, the development of more purposive datasets and models capable of better contextual understanding, semantics, and inter-textual relationships will further enrich NaijaNLP.

\subsubsection{Sentiment Analysis} 
\label{sec:downstream-task-sentiment-analysis}
Sentiment analysis (SA), a specialised form of text classification, involves the identification and extraction of subjective information from the text to determine its sentiment - typically categorised as positive, negative, or neutral. In addressing the unique linguistic characteristics of LRLs, several studies have contributed to advancing SA in NaijaNLP. For example, \citet{shehu2024unveiling} employ deep learning techniques and hierarchical attention networks to enhance sentiment analysis in Hausa. Similarly, \citet{akande2022tweerify} and \citet{ibrahim2024deep} develop models to detect aspect-level sentiment in tweets and Hausa movie reviews, respectively. 
Furthermore, multilingual sentiment analysis systems have been proposed by \citet{raychawdhary2023transformer,raychawdhary2024optimizing} and \citet{abdullahi2023hausanlp}, which recognise the linguistic diversity inherent in LRLs such as Hausa, Yorùbá, and Igbo. In addition, \citet{abdou2025monitoring} present a framework for assessing online geopolitical news based on sentiment and public attention across multiple African countries including Kenya, Nigeria, Senegal, and South Africa. Complementary approaches include \citet{abubakar2021enhanced}, who develop a multilingual sentiment analysis system for English and Hausa tweets using an enhanced feature acquisition method, and \citet{rakhmanov2022sentiment}, who propose a system for analysing Hausa student comments via both monolingual and cross-lingual approaches—further supported by a stemming algorithm and a training dataset comprising over 40,000 comments.

There are additional studies that focus on domain-specific challenges. For instance, \citet{sani2022sentiment} develop a system for sentiment analysis on Hausa data extracted from BBC Hausa's Twitter handle\footnote{\url{https://www.bbc.com/hausa} and \url{https://x.com/bbchausa}}. \citet{mohammed2023building} build a lexicon-based sentiment analysis system tailored for LRLs, and \citet{abdullahi2024twitter} refine sentiment analysis for abbreviated terms in Hausa using an improved dataset with resolved abbreviations and acronyms. In the Igbo context, \citet{ogbuju2020development} introduce general-purpose sentiment lexicons (IgboSentilex), and \citet{okoloegbo2022multilingual} present an interactive system for detecting, monitoring, and regulating cyberbullying content in Igbo and Pidgin English. For Yorùbá, \citet{adeniji2024framework} propose a system for disambiguating sentiment lexicons in Yorùbá texts, supported by curated sentiment lexicons derived from diverse sources, while \citet{abegunde1832design} and \citet{shode2022yosm} explore enhancement strategies and develop datasets (e.g., YOSM) based on movie reviews to support sentiment analysis. 

Collectively, these studies rely on traditional approaches—including lexicon-based techniques, classical machine learning, hybrid methods, and some more recent deep learning and transformer-based models to address sentiment analysis. 
While relevant datasets have been contributed, there is a compelling need for more high-quality annotated data to train models that are better equipped to capture complex linguistic patterns, including sarcasm, irony, and context-dependent sentiments in NaijaNLP.

\subsubsection{Machine Translation} 
Machine Translation (MT) focuses on the automatic translation of text or speech from one language to another, and it has evolved from rule-based systems and statistical methods to neural networks and transformer-based models. Effective MT systems are heavily dependent on large volumes of parallel data to generate accurate translations. 
\citet{mahata2020performance} explore the correlation between performance improvements and the positioning of languages within transfer learning frameworks, highlighting the significance of parallel data in MT. In addressing the needs of LRLs, \citet{akinfaderin2020hausamt} develop a translation system for English–Hausa that leverages parallel corpora. Additionally, \citet{tresner2023intent} propose a system for intent recognition in user messages directed to a chatbot (askNivi), which is designed to facilitate discussions on sexual and reproductive health topics in Hausa, Hindi, and Swahili.
Responding to the need for on-demand MT, \citet{watt2023edge} present an approach for deploying MT on the edge, thereby enabling an embedded system for English–Hausa translation. In another useful approach, \citet{brugnone2024ought} leverage the wisdom of the crowd and unsupervised learning strategies to identify subpopulations based on value-laden statements extracted from Hausa narratives related to maternal and child healthcare, which are subsequently translated into English for further analysis. 

A multimodal strategy is presented by \citet{hatami2024english}, who integrate visual (contextual) and textual information to enhance translation accuracy across language pairs including English, Hindi, Malayalam, Bengali, and Hausa, achieving superior performance compared to text-only baselines.  
\citet{robertson2022understanding} propose strategies to improve translation accuracy for chat agents in LRLs, including Igbo, while \citet{maryann2022enhanced} and \citet{usip2023text} develop MT systems for English–Igbo using both rule-based and corpus-based approaches. Additionally, \citet{ohuoba2024quantifying} contribute an MT system for English–Igbo translation.
For Yorùbá, \citet{adegbola2011localising} discuss a strategy for localising the MS Vista operating system by translating relevant English lexicons into Yorùbá terminologies. Further contributions to English–Yorùbá translation can be found in the work of \citet{folajimi2012using} and \citet{odoje2014investigating}. 
\citet{eludiora2015development} develop a rule-based system to address tone changes in Yorùbá verbs and \citet{fagbolu2016applying} design an accessible MT system for English–Yorùbá translation via mobile and web platforms. 
\citet{eludiora2016development} develop an English–Yorùbá translator and \citet{sundaydevelopment} investigate a multi-layer hybrid approach that combines data-driven and rule-based methods. Finally, \citet{timothybilingual} focus on mitigating challenges such as vanishing gradients, translation accuracy, and computational efficiency in English–Yorùbá MT systems.

Although MT is one of the most widely utilised NLP applications, its performance on LRL pairs remains suboptimal compared to that of HRL \cite{robertson2022understanding}, primarily due to the paucity of adequate parallel data. Future research should emphasise the development of more and richer parallel data to train models that can effectively capture complex linguistic patterns, manage long-range dependencies, accommodate domain-specific terminology, and preserve cultural nuances for NaijaNLP.

\subsection{Automatic Speech Recognition} 
Automatic speech recognition (ASR), interchangeably referred to as speech recognition, involves converting spoken language into text using pattern matching, machine learning, deep learning, and transformer-based models. However, LRLs often suffer from an acute shortage of high-quality, annotated speech data that is critical for the development of effective ASR systems. To mitigate these challenges, several studies have proposed innovative techniques and system frameworks. 
\citet{zhou2024character} propose a technique that leverages meta-learning by pre-training on speech data from ten languages, followed by fine-tuning on data from the target language. 
\citet{gibbonmarketspeak} describe an approach to develop speech technology infrastructure specifically for the Igbo language.
Addressing bias in ASR, \citet{ngueajio2022hey} examine and mitigate systematic biases in speech recognition systems, particularly biases related to gender, race, and disabilities. 
For Hausa, \citet{luka2012neural} develop an ASR system based on neural network pattern recognition, while \citet{aliero10taxonomy} present a text-to-speech system employing deep neural networks. 
\citet{ibrahim2022framework} propose an integrated framework for Hausa ASR that encompasses data creation, as well as the development of both acoustic and language models. 
Noting that the removal of diacritics can increase homography and degrade recognition accuracy, \citet{abubakar2024development} develop an ASR system for Hausa that emphasises diacritised word forms.
\citet{ibrahim2022graphic} create a Hausa text-to-speech system using BERT in conjunction with digital signal processing techniques.
As part of the OkwuGbé initiative—which aims to develop ASR systems for various African LRLs—\citet{dossou2021okwugb} present a similar system for Fon and Igbo.
\citet{odelobi2008recognition} report on ASR for standard Yorùbá, while \citet{aoga2016integration} discuss the integration of Yorùbá into MaryTTS, a tool used for text-to-speech research, development, and teaching.
Further contributions for Yorùbá include the development of speech-to-text recognition systems by \citet{akintola2017machine} and \citet{babatunde2024speech}, as well as a system based on concatenative methods by \citet{afolabi2013development}.
Additionally, \citet{oyesanmi2024towards} describe the implementation of a Google navigation voice system in Yorùbá.

Despite these advances, the overall progress and volume of studies in ASR for NaijaNLP remain limited. There is a pressing need for additional resources to develop models capable of managing complex acoustic and linguistic patterns, including diverse accents, diacritic preservation, and variable speech patterns. Thus, the development of more comprehensive annotated and parallel speech datasets is essential.

\subsubsection{Dialogue Agent}
Dialogue agents are designed to support information retrieval and respond to frequently asked questions. In this context, several initiatives have been undertaken to develop multilingual and dialect-sensitive chatbots. 
\citet{mabrouk2021multilingual} develop a multilingual chat agent that supports African dialects using a general-purpose neural embedding model capable of addressing a broad range of tasks \cite{wu2018starspace}. 
Translators without Borders\footnote{\url{https://translatorswithoutborders.org/chatbot-release-northeast-nigeria/}} offer a chatbot, \textit{Shehu}, to enhance COVID-19 understanding in Northeast Nigeria. This chatbot supports user queries in English, Hausa, or Kanuri, and provides immediate, conversational responses.
\citet{haruna2021hausa} create a Hausa-language chatbot intended to engage users in storytelling and facilitate language learning among native speakers.
\citet{aremu2024utilising} explore the potential of AI-powered chatbots in supporting the learning of endangered Nigerian languages.
While promising developments in dialogue agent technology have been observed, the overall progress remains modest. Continued research and linguistic resource expansion are necessary to further refine pretrained models that can adeptly handle the acoustic and linguistic complexities inherent in NaijaNLP, ultimately enabling more effective and culturally relevant dialogue systems. 

\section{Discussion and Findings}
\label{sec:results-discussion}
Our findings are organised around several key dimensions derived from our research questions (outlined in \S~\ref{sec:introduction}), encompassing the current state of NaijaNLP, as well as the challenges and prospects for future development. 

\subsection{State of Affairs in NaijaNLP} 
This section explores the existing linguistic and NLP resources for NaijaNLP, alongside ongoing efforts to expand and enhance them. Table~\ref{tab:language-particularity-linguistic-resources} provides an aggregated overview of the available resources and related studies across NaijaNLP languages. Additionally, Table~\ref{tab:datasets-and-downstream-tasks} outlines specific datasets and their corresponding downstream tasks. 
A key takeaway from our review is the growing body of literature addressing various NLP downstream tasks for Hausa, Igbo, and Yorùbá languages. However, a significant gap remains in effectively handling language-specific particularities in both monolingual and multilingual context. Notably, about $25.1\%$ of the reviewed studies have contributed novel resources (see Table~\ref{tab:language-particularity-linguistic-resources}), with around 70 new resources emerging from a final set of approximately 279 papers (refer to Figure~\ref{fig:literature-search}). This suggests a disproportionate reliance on existing linguistic resources. Such over-dependence on repurposing existing data, rather than creating new, high-quality, and well-annotated datasets, underscores the need for increased efforts in linguistic resource development, comprehensive annotation, and fostering open, collaborative initiatives to advance the field. 

\subsubsection{State of Linguistic Resources and NLP Tools} 
We discuss the state of linguistic resources for NaijaNLP in relation to grammar, knowledge representation, language particularities, datasets, and downstream tasks.  

\paragraph{Grammar and Knowledge Representation} 
Studies on grammar and knowledge representation are reviewed in \S~\ref{sec:grammar-and-knowledge-representation}. Notably, formal grammar and its analysis is particularly prominent in research involving Hausa, focusing on grammatical formalisation \cite{abdoulaye1992aspects,culy1996formal,crysmann2009autosegmental,copestake2002implementing,crysmann2012hag,blasi2017grammars}. 
Despite their significance, research in formal grammar and knowledge representation remains limited within NaijaNLP. Nevertheless, such studies provide a critical foundation for the development of digital language resources by offering structured frameworks for language processing. Expanding research in these areas is crucial to enhancing the representation of LRLs and improving the performance of generative AI models for these languages. Although existing studies, particularly those in digital forms, remained constrained, further research and digitalisation of linguistic resources will strengthen NaijaNLP and narrow the divide between theoretical linguistics and practical applications. 

\paragraph{Language Particularities}
As previously noted, Nigerian languages often exhibit distinct orthographic, phonetic, and syntactic characteristics that set them apart from English and other high-resource languages. Inadequate consideration of these unique characteristics impeded the adaptation and performance of NLP tools developed primarily for HRLs when applied to low-resource contexts. Numerous studies have addressed the linguistic diversity and specific needs of Nigeria's major languages \cite{amuda2010limited,oyinloye2015issues,abdulkareem2016yorcall,adewumi2020challenge}. Languages within NaijaNLP, especially Igbo and Yorùbá, exhibit rich morphological structures and extensive diacritic use. Various studies have examined these challenges pertaining to Igbo \cite{iheanetu2017some,iheanetu2019addressing,ochu2019corpus,chidiebere2020analysis,henry2020performance} and Yorùbá \cite{oyinloye2015issues,adegbola2016pattern,abdulkareem2016yorcall,adewole2017token,oluwatoyinstochastic,okediya2019building}, with additional work by \citet{alade2019issues,oyekanmi2013intelligent,adebara2021translating,adegokedevelopment,akinwonmi2024rule,frohmann2024segment} further exploring these issues. 
Additionally, diacritic restoration plays a crucial role in processing historical texts, user-generated content, and datasets where diacritics may have been omitted due to technical constraints. Several studies have addressed orthographic and tonal diacritics in NaijaNLP, specifically for Igbo \cite{ezeani2016automatic,ezeani2017lexical,ezeani2018transferred,ezeani2018igbo} and Yorùbá \cite{de2007automatic,tunji2011design,adegbola2012quantifying,asubiaro2015statistical,asahiah2017restoring,orife2018attentive,alabi2020massive,adewumi2020challenge} languages.  
Although significant theoretical and analytical work has been undertaken, advancing research in this domain requires more comprehensive datasets and greater community involvement to ensure cultural relevance and accurate diacritic processing in NaijaNLP. For additional details on morphological analysis and diacritic restoration, refer to \S~\ref{sec:morphological-analysis} and \S~\ref{sec:diacritic-restoration}, respectively. 
 
Furthermore, there has been limited research focused on enriching linguistic resources related to numerical systems in NaijaNLP. The earliest attempts at analysing Hausa numerals for machine processing date back to \cite{sigurd1980numbers}. Subsequent efforts have explored the conversion between spoken numerals and decimal representations \cite{sigurd1980numbers,agbeyangi2016web,mustapha2023automated,rhoda2017computational,ajao2022yoruba}. Overall, research on numerical systems within NaijaNLP remains sparse, underscoring the need for further studies and resource development to ensure accurate numerical representation and processing across Nigerian languages.
Despite these efforts, our review reveals a paucity of comprehensive evaluation datasets and newly developed linguistic resources (see Table~\ref{tab:language-particularity-linguistic-resources}). Addressing these gaps will necessitate increased community involvement and collaborative initiatives to improve resource availability and ensure accurate diacritic processing in NaijaNLP. 


\paragraph{Monolingual and Multilingual Data}
In addition to the datasets detailed in Section~\ref{sec:linguistic-resources-datasets}, Table~\ref{tab:language-particularity-linguistic-resources} presents a summary of the open resources currently identified for NaijaNLP. 
Numerous corpora have been curated for Hausa, Igbo and Yorùbá languages. Moreover, a range of strategies, including data augmentation techniques, have been proposed to enhance the linguistic resources critical for effective NLP applications in low-resource settings. These efforts aim to improve both the quality and quantity of digital data, thereby facilitating the development of more robust models. 
From Tables~\ref{tab:language-particularity-linguistic-resources} and \ref{tab:datasets-and-downstream-tasks}, it is evident that the majority of high-volume, high-quality data employed across various downstream tasks come from the cross-lingual category, a result of collaborative initiatives. While these efforts are commendable, a significant portion of the available datasets remains low. %, often raw and unlabelled. 
This shortfall underscores the urgent need for further refinement and systematic annotation to advance state-of-the-art NLP research. Enhanced linguistic support and additional initiatives, akin to those presented by \cite{adegbola2009building, bigi2017developing, adeyemi2024ciral}, are essential to fully realising the potential of NaijaNLP. 

  \begin{table}[ht]
        \centering
        %\renewcommand{\arraystretch}{1.3}
        \renewcommand{\arraystretch}{1.1}
        \adjustbox{max width=\textwidth}{
        %\adjustbox{max width=\textwidth}{
        %\begin{tabular}{l|ccc|ccccccc}
        \begin{tabular}{l|cc|ccccccc}
        \toprule
        \rowcolor{gray!30}
        \multirow{2}{*}{\textbf{Language}} & \multicolumn{2}{c|}{\textbf{Language Particularities}} & \multicolumn{6}{c}{\textbf{New Datasets for Downstream Tasks}} \\
        %\rowcolor{gray!20}
        \cmidrule(lr){2-3} \cmidrule(lr){4-9}
        \rowcolor{gray!20}
         & \textbf{MA} & \textbf{DA} & \textbf{MT/ASR} & \textbf{SA} & \textbf{POS/NER} & \textbf{QA} & \textbf{TC/TS} & \textbf{Misc} \\
        \midrule
        Hausa (ha) & \cellcolor{red!25}\xmark & \cellcolor{green!25}\cmark\cite{abubakar2024development}  
        & \cellcolor{green!25}\cmark\cite{ibrahimnecat,aliero10taxonomy,abubakar2024development,akinfaderin2020hausamt} & \cellcolor{green!25}\cmark\cite{sani2022sentiment,rakhmanov2022sentiment,mohammed2024lexicon,abdullahi2024twitter} & \cellcolor{green!25}\cmark\cite{abubakar2019hausa} & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\cmark\cite{inuwa2021first,abdulmumin2022hausa,imam2022first,zandam2023online,parida2023havqa,vargas2024hausahate,mohammed2024lexicon,adam2024detection}  \\
        
        Igbo (ig) & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark  
        & \cellcolor{green!25}\cmark\cite{onuora2024machine,ana2024ai} & \cellcolor{green!25}\cmark\cite{ogbuju2020development} & \cellcolor{green!25}\cmark\cite{onyenwe2018basic} & \cellcolor{green!25}\cmark\cite{mbonu2022igbosum1500} & \cellcolor{red!25}\xmark & \cellcolor{green!25}\cmark\cite{chiarcos2011information,onyemaechi2023some,chiomaweb} \\
        
        Yorùbá (yo) & \cellcolor{green!25}\cmark\cite{oluwatoyinstochastic,okediya2019building} & \cellcolor{green!25}\cmark\cite{scannell2011statistical,adegbola2011localising,adewole2020automatic,adebara2021translating}  
        & \cellcolor{green!25}\cmark\cite{afolabi2013implementation,iyanda2015statistical,fagbolu2015digital,gutkin2020developing,akinwonmi2021development,ahia2024voices} & \cellcolor{green!25}\cmark\cite{ademusire2023development,shode2022yosm,adeniji2024framework} & \cellcolor{green!25}\cmark\cite{adedjouma2013part,toyin2024hidden} & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\cmark\cite{chiarcos2011information,orife2018attentive,akpobi2024yankari} \\


        Multilingual & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark 
        & \cellcolor{green!25} \cmark\cite{amuda2010limited,dossou2021okwugb,ekpenyong2022towards,fan2021beyond,adelani2022natural,ajagbe2024developing,godslove2024trilingual} & \cellcolor{green!25}\cmark\cite{muhammad2022naijasenti,ogunleye2023using,mohammed2023building} & \cellcolor{green!25}\cmark\cite{onyenwe2018basic,adelani2021masakhaner} & \cellcolor{green!25}\cmark\cite{aremunaijarc} & \cellcolor{green!25}\cmark\cite{varab2021massivesumm,olalekan2022machine,adelani2023masakhanews} & \cellcolor{green!25}\cmark\cite{kolak2005ocr,arikpo2018development,ferroggiaro2018social,adewumi2022itakuroso,mbonu2022igbosum1500,aliyubeyond,adelani2024irokobench,adeyemi2024ciral,muhammad2025afrihate} \\ 
        \bottomrule
        \end{tabular}
        }
        \caption{Relevant linguistic resources ($n=70$) contributed to the development of NaijaNLP. The above acronyms refer to the following: MA - Morphological Analysis; DR - Diacritic Restoration; Misc - Miscellaneous downstream tasks. Green cells marked with ~\cmark~ indicate the downstream tasks in which the datasets have been utilised, while red cells marked with ~\xmark~ denote tasks for which no resources are found.} %NOTE THIS TABLE COMBINES BOTH NEW AND EXISTING RESOURCES/DATA
        \label{tab:language-particularity-linguistic-resources}
    \end{table} 

%\paragraph{State of Downstream Tasks}
\vspace{0.36cm}\noindent \textbf{State of Downstream Tasks - }
Substantial research has been dedicated to various NLP downstream tasks within NaijaNLP. This section synthesises key findings regarding the development of these tasks. 

\paragraph{POS and NER}
Numerous studies have explored POS tagging and NER within the context of NaijaNLP, addressing language-specific challenges and nuances. Research has been conducted in monolingual contexts for Hausa \cite{bashir2015word,bimba2016stemming,lu2016multi,tukurcorpus,tukur2019tagging,tukur2020parts,awwalu2021corpus}, Igbo \cite{onyenwe2015use,onyenwe2016predicting,onyenwe2014part,onyenwe2019toward,olamma2019hidden,anbootstrapping,chukwuneke2023igboner,soronnadienhancing}, and Yorùbá \cite{kumolalo2010development,adedjouma2013part,abiola2014web,adegunlehin2019investigation,omolaoye2020proverb,ugwu2024part,toyin2024hidden} languages, as well as in multilingual contexts \cite{ren2016automatic,zhang2017embracing,adelani2020distant,model2020accent,oyewusi2021naijaner,tukur2024towards,adewumi2022itakuroso,mehari2024semi}. These contributions have significantly addressed language-specific challenges and enhanced the computational linguistic resources underlying various NLP applications. However, while existing resources have proven valuable, further research and extensive dataset expansion are required to advance linguistic tools for NaijaNLP.

\paragraph{Text Classification and Sentiment Analysis}%Text Summarisation}
While numerous studies have focused on text classification and summarisation \cite{varab2021massivesumm,olalekan2022machine,bashir2017automatic,bichi2023graph,bichi2024integrating,ifeanyi2020comparative,ifeanyin,mbonu2022igbosum1500,adegokeestimating}, there remains a pressing need for linguistic resources and models capable of effectively capturing context, semantics, and intertextual relationships. 
In addition to text classification, significant research has been conducted on sentiment analysis using datasets from social media and other sources (see \S~\ref{sec:downstream-task-sentiment-analysis}). Approaches range from traditional bag-of-words models to state-of-the-art transformer-based techniques, each addressing the nuances of sentiment expression in low-resource contexts \cite{abubakar2021enhanced,shehu2024unveiling,akande2022tweerify,ibrahim2024deep,sani2022sentiment,mohammed2023building,abdullahi2024twitter,ogbuju2020development,adeniji2024framework,abegunde1832design,shode2022yosm}, with some more recent deep learning and transformer-based models \cite{raychawdhary2023transformer,raychawdhary2024optimizing,abdullahi2023hausanlp,abdou2025monitoring,rakhmanov2022sentiment} aimed at addressing sentiment analysis in NaijaNLP.
Although lexicon-based techniques, classical ML, and hybrid methods have yielded measurable progress, the implementation of pretrained models—particularly those trained on indigenous data—remains limited \cite{muhammad2022naijasenti,muhammad2025afrihate}. There is a need for more linguistic data and models that can effectively capture complex linguistic phenomena, including sarcasm, irony, and context-dependent sentiments in NaijaNLP.

\paragraph{Machine Translation and Automatic Speech Recognition}
Several studies have focused on machine translation for Hausa \cite{akinfaderin2020hausamt,tresner2023intent,hatami2024english}, Igbo \cite{robertson2022understanding,maryann2022enhanced,usip2023text,ohuoba2024quantifying}, and Yorùbá \cite{adegbola2011localising,folajimi2012using,odoje2014investigating,eludiora2015development,fagbolu2016applying,eludiora2016development,sundaydevelopment,timothybilingual} languages.
Despite notable progress, MT systems for LRL pairs remain suboptimal, mainly due to the limited availability of parallel corpora. Future research should emphasise the development of parallel data and pretrained models specifically trained on indigenous data. These models will be better positioned to capture complex linguistic particularities and improve translation quality for NaijaNLP. Additionally, more collaborative efforts on cross-lingual work covering the major three languages in Nigeria are essential. 
%\paragraph{Automatic Speech Recognition}
Furthermore, research in speech technologies has explored both automatic speech recognition and text-to-speech (TTS) systems, with particular emphasis on addressing challenges such as diacritic preservation and tonal variation inherent to NaijaNLP. Various studies have been conducted involving Hausa \cite{luka2012neural,aliero10taxonomy,ibrahim2022framework,abubakar2024development,ibrahim2022graphic}, Igbo \cite{gibbonmarketspeak,ngueajio2022hey}, and Yorùbá \cite{dossou2021okwugb,odelobi2008recognition,aoga2016integration,akintola2017machine,babatunde2024speech,afolabi2013development,oyesanmi2024towards}.
There remains a need to develop more comprehensive annotated and parallel speech data to enable the development of pretrained models capable of managing complex acoustic and linguistic patterns.

\paragraph{Embedding and Pretrained Models}
Embeddings provide numerical representations of words, sentences, or documents that capture semantic meaning in a continuous vector space, serving as the backbone of modern NLP. Pretrained models, developed on vast datasets, act as versatile starting points for fine-tuning on tasks such as text classification, machine translation, question answering, text generation, and summarisation. Together, embeddings and pretrained models underpin both language understanding and generation. However, embeddings for LRLs often suffer from an overreliance on large-scale datasets dominated by high-resource languages (HRLs), hindering effective knowledge transfer. In response, \citet{yousuf2024improving} propose a contrastive learning strategy to better align embeddings by optimizing semantic distances between similar and dissimilar sentences. Despite such efforts, research specifically addressing embeddings for low-resource Nigerian languages remains scarce \cite{abdulmumin2019hauwe,alabi2020massive,yousuf2024improving}. 

    \begin{table}[h!]
            \centering
            \renewcommand{\arraystretch}{1.3}
            \adjustbox{max width=\textwidth}{
            \begin{tabular}{|l|cccccc|cc|c|}
                \hline
                \rowcolor{gray!20} 
                \multicolumn{9}{|c|}{\cellcolor{gray!30} \textbf{Datasets and Application Areas}} \\ \hline

                \rowcolor{gray!20} 
                \textbf{Dataset} & \textbf{Proportion (\%)} & \textbf{MT/ASR} & \textbf{SA} & \textbf{TC/TS} & \textbf{POS/NER} & \textbf{QA} & \textbf{IR} & \textbf{Misc} \\ 
                \hline
                
                Hausa Only & \cellcolor{blue!25} 24.7\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark \\
    
                Hausa-Igbo-Yorùbá & \cellcolor{blue!25} 5.6\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark \\
    
                Hausa-Yorùbá-Others & \cellcolor{blue!25} 2.3\% & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark  \\
    
                Hausa-English & \cellcolor{blue!25} 4.5\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark  \\
    
                Hausa-Others & \cellcolor{blue!25} 5.6\% & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark  \\
                
                Igbo Only & \cellcolor{blue!25} 10.1\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark \\
    
                Igbo-Yorùbá-English & \cellcolor{blue!25} 2.3\% & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark  \\
    
                Igbo-Others & \cellcolor{blue!25} 3.4\% & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark  \\
                
                Yorùbá Only & \cellcolor{blue!25}14.6\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark \\
    
                Yorùbá-English & \cellcolor{blue!25} 3.4\% & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark  \\
    
                Yorùbá-Others & \cellcolor{blue!25} 4.5\% & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark \\
                %others: 
    
                African Languages & \cellcolor{blue!25} 7.9\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark & \cellcolor{red!25}\xmark & \cellcolor{red!25}\xmark & \cellcolor{green!25}\checkmark \\
                
                Hausa-Igbo-Yorùbá-English-Others & \cellcolor{blue!25} 11.2\% & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark \\
                \hline
            \end{tabular}
            }
            \caption{Overview of reported datasets across the languages documented in the reviewed literature. The above acronyms refer to the following: MT/ASR – Machine Translation/Automatic Speech Recognition; SA – Sentiment Analysis; TC/TS – Text Classification/Text Summarisation; POS/NER – Part-of-Speech Tagging \& Named Entity Recognition; QA – Questions and Answers; IR – Information Retrieval; Misc – Miscellaneous downstream tasks. A green checkmark (\checkmark) indicates the availability of the resource, whereas a red $X$ (\xmark) signifies its absence.} %datasets ($n=89$) and associated linguistic resources/tools 
            \label{tab:datasets-and-downstream-tasks}
        \end{table}        

\subsubsection{State of Linguistic Resource Enhancement}
Linguistic resources are fundamental to the development of effective NLP applications. This section reviews initiatives aimed at enhancing digital resources, tools, and collaborative efforts within NaijaNLP, particularly focusing on community-driven projects designed to advance LRLs within the NaijaNLP ecosystem. 
Several initiatives have been introduced to support NaijaNLP. 
Notably, \citet{adegbola2009building} introduce the Alt-i, which aims to enhance NLP support for Nigerian languages. Additionally, \citet{chiarcos2011information} provide tools facilitating downstream tasks across 25 sub-Saharan languages.
Efforts to advance lexicographic resources include a system for converting bilingual African language-French dictionaries \cite{enguehard2014computerization}, and the Human Language Technologies tools for Nigerian Pidgin, including a tokenizer and an automatic speech system for predicting word pronunciation and segmentation \cite{bigi2017developing}. Various linguistic resources for NaijaNLP languages, such as POS-tagging \cite{onyenwe2018basic} and knowledge extraction tools \cite{abubakar2019hausa,umaraspects}, have also been presented. In the broader LR-NLP landscape, \citet{costa2022no} explore strategies to reduce the performance gap between high-resource and low-resource languages. We discuss about additional initiatives in \S~\ref{sec:mitigation-strategies-and-prospects}. 

\subsection{Challenges and Future Prospects for NaijaNLP}  
This section discusses the challenges hindering NaijaNLP from fully leveraging state-of-the-art NLP advances and suggests potential mitigation strategies. 

\subsubsection{Challenges Affecting NaijaNLP}
\paragraph{Linguistic Resources – Computational Grammar and Knowledge Representation}
Computational grammar and knowledge representation are foundational to digital language resources, providing structured frameworks for language processing \cite{crysmann2012hag}. However, research in these areas remains sparse within NaijaNLP \cite{abdoulaye1992aspects,culy1996formal,crysmann2009autosegmental,copestake2002implementing,blasi2017grammars,eze1997aspects,aina2021ontology,ifeanyi2022semantic,aina2023human}.

\paragraph{Linguistic Diversity and Data Processing Challenges} %\cite{amuda2010limited,oyinloye2015issues,abdulkareem2016yorcall,adewumi2020challenge}
The linguistic diversity of Nigerian languages presents significant challenges for NLP because these languages feature unique orthographic systems, pronunciation patterns, and syntactic structures, including the use of diacritics and tonal variations.  
Such characteristics, particularly in Igbo and Yorùbá, complicate the adaptation of NLP tools developed for high-resource languages. Inconsistent diacritic usage negatively affects text readability and performance in downstream tasks, especially in text-to-speech applications. Additionally, complex morphological structures, such as rich affixation and non-concatenative morphology, further complicate processing. The frequent omission or misapplication of diacritics, as well as issues like mis-syllabification and elision, emphasise the need for specialised linguistic resources tailored to NaijaNLP. 

\paragraph{Limited Digital and Standardised Resources} 
While NLP advancements have largely benefited HRLs, NaijaNLP faces a critical challenge due to the scarcity of digital resources for computational tasks. Despite their widespread use, Hausa, Igbo, and Yorùbá are classified as low-resource languages in NLP, primarily due to the lack of digital data. These languages collectively have fewer than 200,000 Wikipedia articles, a significant bottleneck for training NLP models. Table~\ref{tab:wiki_articles_language} provides a subset of the 353 languages with official Wikipedia editions. As shown in sub-tables (b) and (c) of Table~\ref{tab:wiki_articles_language}, LRLs like Hausa, Igbo, and Yorùbá have minimal digital presence. Expanding these resources is essential for enhancing the digital footprint, research potential, and NLP capabilities of these languages. 

    \begin{table}[h]
            \centering
            \renewcommand{\arraystretch}{1.2} 
            \setlength{\tabcolsep}{4pt} 
            \resizebox{\textwidth}{!}{ 
            \begin{tabular}{lccr | lccr | lccr}
                \toprule
                \multicolumn{4}{c}{\textbf{(a) High-Article Languages (1M+)}} & \multicolumn{4}{c}{\textbf{(b) Low-Article Languages (50K-100K)}} & \multicolumn{4}{c}{\textbf{(c) Very Low-Article Languages (20K-49K)}} \\
                \cmidrule(lr){1-4} \cmidrule(lr){5-7} \cmidrule(lr){8-12}
                \textbf{Language} & \textbf{\#Articles} & \textbf{\#Active Users}  & \textbf{Ratio} & \textbf{Language} & \textbf{\#Articles} & \textbf{\#Active Users} & \textbf{Ratio} & \textbf{Language} & \textbf{Articles} & \textbf{\#Active Users} & \textbf{Ratio} \\
                \midrule
                1. en  & 6,951,121  & 126,690 & 55  & 92. vec  & 69,388  & 49  & 1.4k & 105. tl  & 48,253  & 135 & 357 \\
                2. ceb & 6,116,828  & 146    & 42k   & 93. lb  & 64,614   & 80   & 808 & 106. glk  & 48,131  & 20 & 2.4k \\
                3. de  & 2,985,570  & 19,166   & 156 & 94. ba  & 63,782   & 70   & 911 & 107. an  & 47,819  & 67 & 714 \\
                4. fr  & 2,663,233  & 18,763   & 142 & 95. su  & 61,883   & 60   & 1k & 108. wuu  & 44,841  & 79  & 568 \\
                5. sv  & 2,603,307  & 2,203   & 1.2k & 96. ga  & 61,392   & 129   & 476 & 109. diq  & 42,293  & 41  & 1k \\
                6. nl  & 2,179,293  & 3,896   & 560 & 97. is  & 59,713   & 179   & 334 & 110. vo  & 40,037  & 30  & 1.3k \\
                7. ru  & 2,023,915  & 9,735   & 208 & 98. szl  & 58,731   & 36   & 1.6k & 111. \cellcolor{green!25}ig  & \cellcolor{green!25}38,915  & \cellcolor{green!25}98  & \cellcolor{green!25}398\\
                8. es  & 2,007,615  & 14,592   & 138 & 99. cv  & 57,270   & 48   & 1.2k & 112. \cellcolor{green!25}yo  & \cellcolor{green!25}35,067  & \cellcolor{green!25}58  & \cellcolor{green!25}605\\
                9. it  & 1,903,500  & 8,002   & 238 & 100. pa  & 56,226   & 78   & 721 & 113. sco  & 34,425  & 88  & 391\\
                10. pl  & 1,647,505  & 4,955   & 333 & 101. fy  & 55,871   & 75   & 745 & 114. kn  & 33,338  & 149  & 224\\
                11. arz  & 1,626,474  & 221   & 74k & 102. \cellcolor{green!25}ha  & \cellcolor{green!25}54,052   & \cellcolor{green!25}180 & \cellcolor{green!25}300  & 11.115. als  & 30,848  & 93  & 332\\
                12. zh  & 1,462,403  & 7,031   & 208 & 103. io  & 53,009   & 61   & 869 & 116. gu  & 30,490  & 49  & 622\\
                13. ja & 1,447,971  & 13,135   & 110 & 104. mzn  & 50,406   & 41   & 1.2k & 117. avk  & 29,877  & 16  & 1.9k\\
                \bottomrule                
            \end{tabular}
            } 
            \caption{Summary of the languages with the (a) highest (b) low and (c) very low number of digital articles as tracked by Wikipedia. In sub-table $b$ Hausa (ha) has just above 54K articles while both Igbo (ig) and Yorùbá (yo) in sub-table $c$ have about 39K and 35k articles, respectively. These numbers are very small compared to the population size and number of Internet users. Based on the ratio of the number of articles relative to active users contributing to the number of articles, there are few users contributing to digital content for the 3 languages.}
            \label{tab:wiki_articles_language}
    \end{table}


\subsubsection{Mitigation Strategies and Future Prospects}
\label{sec:mitigation-strategies-and-prospects}
This section discusses strategies to mitigate challenges facing NaijaNLP and explores future prospects for enhancing NLP tools for Nigerian languages.

\paragraph{Repurposing LLMs to Suit LRLs} 
While LLMs have achieved remarkable results on high-resource languages (HRLs), their performance on LRLs is typically restricted to few-shot learning due to their HRL-centric training data and evaluation protocols. Benchmark studies \cite{chowdhery2023palm,srivastava2022beyond} often overlook the complexities inherent in NaijaNLP tasks. For example, \citet{lawalcontextual} evaluate select LLMs (e.g., ChatGPT-3.5, Gemini, and PaLM 2) for generating contextually relevant Yorùbá content, and \citet{orok2024pharmacy} examine their use in Nigerian pharmacy education, highlighting integration challenges and academic concerns. Similarly, \citet{ojo2023good} demonstrate that, across six tasks in 60 African languages, LLMs generally underperform relative to HRLs. In response to limited resources, current strategies repurpose techniques from well-resourced languages—for instance, \citet{ezeani2018multi} use alignment-based projection to transfer pretrained English embeddings to Igbo, while \citet{ogundepo2023enabling} introduce AfriCLIRMatrix, a cross-lingual retrieval dataset spanning 15 African languages. Additionally, \citet{oladipo2024backbones} assess dense retrieval models with multilingual backbones, and \citet{abdou2024multilingual} leverage self-supervised pretraining to address resource limitations in both monolingual and multilingual contexts.
%\paragraph{Transfer Learning and Adaptive Fine-Tuning} 
Adapting NLP models for LRLs frequently involves transfer learning and task-adaptive fine-tuning. \citet{gururangan2020don} demonstrate the feasibility of customising pretrained models for domain-specific tasks—such as those in biomedical literature or computer science—enhances performance \cite{muller2020being}. Comparative studies reveal that while some LRLs benefit significantly from transfer learning, others face challenges, partly due to script-related issues. To address out-of-distribution scenarios, \citet{jiang2023low} propose a non-parametric approach that combines compression algorithms with k-nearest-neighbour classifiers, using compressor-based distance metrics \cite{fadaee2017data}. In machine translation, data augmentation targeting low-frequency words has been introduced to generate synthetic parallel data. Moreover, \citet{dossou2022afrolm} present AfroLM—a multilingual language model pretrained from scratch on 23 African languages—while \citet{remy2024trans} propose a cross-lingual vocabulary transfer strategy, termed trans-tokenisation, to adapt LLMs for LRLs. %Hydra LLMs, featuring swappable language modelling heads and embedding tables, further enhance model adaptability for low-resource contexts. 
Our discussion here focuses on repurposing and fine-tuning strategies for LLMs, with a more detailed exploration reserved for future work.

\paragraph{Multilingual Models} 
Several multilingual models have been proposed for NaijaNLP. For instance, \citet{adewumi2022vector} introduce resources that enhance various NLP tasks through deep neural networks and cross-lingual transfer. Pretrained models such as RoBERTa, XLM-R, and mBERT have been applied to address code-switching in sentiment analysis between Hausa and English using tweets \cite{yusuf2023fine}. Additionally, \citet{oladipo2022exploration} investigate the cross-lingual capabilities of models trained on languages like Amharic, Hausa, and Swahili, demonstrating that a shared vocabulary space benefits both zero- and few-shot settings, although gains plateau beyond a certain number of languages. In another study, \citet{dione2021multilingual} develop a multilingual dependency parsing system for LRLs, including Yorùbá, and explore syntactic knowledge transfer using multilingual BERT's self-attention mechanism. 
Recognising the computational challenges of training language-specific models—which can hinder cross-lingual transfer due to over-specialisation—\citet{alabi2022adapting} propose a multilingual adaptive fine-tuning strategy that leverages data from 17 well-resourced African languages alongside three HRLs to mitigate performance gaps in unseen languages. Furthermore, \citet{adelani2024irokobench} present IrokoBench, a human-translated benchmark dataset encompassing 16 typologically diverse low-resource African languages, covering natural language inference (AfriXNLI), mathematical reasoning (AfriMGSM), and multiple-choice knowledge-based question answering (AfriMMLU). 

While large-scale pretraining of multilingual models yields notable performance gains in cross-lingual transfer tasks \cite{conneau2019unsupervised}, existing benchmarks often focus on multilingual contexts or treat LRLs as a single target group alongside HRLs. Superior performance is likely if LRLs are prioritised as primary target languages with dedicated resources for their development. 

\paragraph{Low-Resource Languages for Evaluation}
Low-resource languages are often utilised as evaluation benchmarks rather than as primary targets for dedicated resource development. For example, Hausa and related languages have been used to assess systems like the graphmax function, which leverages co-occurrence information for text alignment \cite{liu2023graphmax}. Moreover, although multilingual machine translation systems aim to translate between any pair of languages, they remain largely English-centric, with training data typically translated from or into English \cite{fan2021beyond}. To address this shortcoming, \citet{fan2021beyond} introduce a many-to-many multilingual translation model that directly translates among 100 languages, incorporating Hausa, Yorùbá, and Igbo for evaluation. Additionally, \citet{wang2023noise} propose a fine-tuning strategy for LLMs to reduce noise, an important consideration given the inherently noisy labels from complex annotation process

\paragraph{Shared Tasks and Workshops}
Community-driven initiatives and collaborative efforts are crucial for advancing linguistic resources in NaijaNLP. Key projects, such as the African Languages Technology Initiative (Alt-i) \cite{adegbola2009building}, the Low-Resource Human Language Technology (LoReHLT) project \cite{christianson2018overview}, and AfroLID \cite{adebara2022afrolid} play a pivotal role in this regard. High-impact conferences like ACL and ICLR\footnote{\url{https://www.aclweb.org/} and \url{https://iclr.cc/}} further support these efforts by hosting workshops and shared tasks that unite researchers from academia, industry, and research laboratories to address defined NLP challenges. Notable examples include: 
    \begin{itemize} 
        \item[-] \textbf{SemEval Shared Tasks:} These tasks provide a platform for in-depth exploration of language semantics, with significant contributions in semantic textual relatedness \cite{salahudeen2024hausanlp,ousidhoum-etal-2024-semeval}, translation \cite{chen2021university,nowakowski2021adam,tran2021facebook,yousuf2024improving}, and sentiment analysis \cite{benlahbib2023nlp,raychawdhary2023seals_lab,ramanathan2023techssn}. 
        \item[-] \textbf{AfricaNLP Workshops:} Co-located with prominent conferences like ICLR, these workshops foster focused dialogue and collaborative research on thematic issues in low-resource African languages. 
    \end{itemize}

\paragraph{Improving Existing Linguistic Resources}
In high-impact research settings, low-resource NLP is often treated as a subsidiary topic within broader themes. Major technology groups seldom prioritise the enrichment of linguistic resources for individual or regional LRLs, frequently addressing them as a homogeneous group or solely for evaluation \cite{dabre2020survey,muller2020being,jiang2023low,fadaee2017data}. Consequently, large-scale digitisation initiatives, which are essential for capturing the nuanced particularities of these languages, remain critically under-explored. This limited focus constrains both the depth of linguistic investigation and the development of domain-specific datasets, prompting researchers to either collectively address LRL issues or adapt models originally trained on high-resource languages. To overcome these persistent barriers and ensure that LRLs are not marginalised in the AI revolution, innovative strategies such as comprehensive digitisation of existing resources are urgently needed. Recent global commitments, including AI for Development (AI4D) Funders Collaborative \cite{AI4D2024}, underscore the importance of enhancing the representation of African languages in LLMs. Efforts to transduce texts \cite{randell1998hausar}, enrich resources \cite{adegbola2009building}, and digitise indigenous poetry\cite{hausapoetry} are essential steps toward integrating these languages into modern computational frameworks. 
%\footnote{\url{http://aflang.humanities.ucla.edu/language-materials/chadic-languages/hausa/hausa-poetry-song/}}

\section{Conclusion} 
\label{sec:conclusion}
Low-resource NLP continues to confront enduring challenges that require targeted, innovative strategies. This study has provided a comprehensive review of the state of NLP in Nigeria, with a focus on its three major languages - Hausa, Igbo, and Yorùbá (collectively termed NaijaNLP). By examining the unique linguistic characteristics and resource constraints of these languages, our review offers actionable recommendations to advance and sustain NaijaNLP within the broader realm of low-resource NLP (LR-NLP) research. 
Despite the numerical predominance of LRLs, languages within NaijaNLP are often treated as a homogeneous group. We surmise that this practice obscures significant variations in resource availability and quality and may impede targeted technological development. To that effect, we argue for a more nuanced, language-specific approach to address the unique challenges faced by individual languages. The prevalent reliance on HRL-based models further highlights the need to invest in bespoke, indigenous models.  
Essentially, our investigation spans available linguistic resources, language particularities, computational tools, and collaborative initiatives, revealing significant progress alongside challenges. These challenges underscore the urgent need for greater investment in high-quality data, robust computational tools, and enhanced community collaboration to fully harness the potential of LRLs in NLP applications. To address these challenges, we recommend: 

    \begin{enumerate}[label=\ding{\numexpr171+\value*}]
    %\begin{itemize} 
        \item Emphasising the critical role of formal grammar and linguistic analysis in developing reusable linguistic resources. 
        \item Prioritising the collection and annotation of larger, more diverse datasets that capture language particularities such as morphological and dialectal variations. 
        \item Investing in the creation of models tailored to the unique needs of each language, including the development of large language models built from scratch using indigenous data, rather than relying solely on models repurposed from high-resource languages. 
        \item Fostering collaborative research efforts and community engagement to ensure the sustained development of NLP resources for LRLs. 
    \end{enumerate} 
In summary, advancing NaijaNLP demands dedicated efforts to overcome linguistic, resource, and sociopolitical challenges. By prioritising language-specific approaches and fostering robust collaborative research, we can pave the way for more inclusive and effective NLP solutions for low-resource languages. 


\bibliographystyle{ACM-Reference-Format}
\bibliography{main}


\appendix
%\section{Research Methods}%\subsection{Part One}

\begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \resizebox{\textwidth}{!}{ % Adjusts table width dynamically
    \begin{tabular}{@{}p{4cm}p{12cm}@{}}
        \toprule
        \textbf{Category} & \textbf{Search Terms} \\ 
        \midrule
        \textbf{Language-Related Terms} & 
        \begin{itemize}
            \item[-] \texttt{"Hausa" OR "Hausa Language"}
            \item[-] \texttt{"Igbo" OR "Igbo Language"}
            \item[-] \texttt{"Yorùbá" OR "Yorùbá Language"}
        \end{itemize} \\ 
        
        \textbf{NLP-Related Terms} & 
        \begin{itemize}
            \item[-] \texttt{"natural language processing" OR "deep learning" OR "machine learning" OR "artificial intelligence"}
            \item[-] \texttt{"low-resource language" OR "low-resource languages" OR "low-resource NLP"}
            \item[-] \texttt{"sentiment analysis" OR "machine translation" OR "part-of-speech tagging" OR "named entity recognition"}
            \item[-] \texttt{"automatic speech recognition" OR "text-to-speech" OR "speech recognition"}
        \end{itemize} \\ 
        
        \textbf{Combined Search Queries} & 
        \begin{itemize}
            \item[-] \texttt{("Hausa" OR "Hausa Language") AND ("natural language processing" OR "deep learning" OR "machine learning" OR "artificial intelligence")}
            \item[-] \texttt{("Hausa" OR "Hausa Language") AND ("low-resource languages" OR "low-resource languages" OR "low-resource NLP")}
            \item[-] \texttt{("Yorùbá" OR "Yoruba Language") AND ("natural language processing" OR "deep learning" OR "machine learning" OR "artificial intelligence")}
            \item[-] \texttt{("Yorùbá" OR "Yoruba Language") AND ("low-resource languages" OR "low-resource languages" OR "low-resource NLP")}
            \item[-] \texttt{("Igbo" OR "Igbo Language") AND ("natural language processing" OR "deep learning" OR "machine learning" OR "artificial intelligence")}
            \item[-] \texttt{("Igbo" OR "Igbo Language") AND ("low-resource languages" OR "low-resource languages" OR "low-resource NLP")}
        \end{itemize} \\ 
        \bottomrule
    \end{tabular}
    } 
    \caption{An example of the systematic search strategy for NaijaNLP review. Terms were structured to address (1) language-specific terms (Hausa, Igbo, Yorùbá), (2) NLP-related, and (3) example of the combined integrated search queries.} 
    \label{tab:search-terms}
\end{table}

%############################################################################################################################################################




\end{document}

