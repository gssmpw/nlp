@inproceedings{abdine2024prot2text,
  title={Prot2text: Multimodal proteinâ€™s function generation with gnns and transformers},
  author={Abdine, Hadi and Chatzianastasis, Michail and Bouyioukos, Costas and Vazirgiannis, Michalis},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  
  pages={10757--10765},
  year={2024}

}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{char2024protnote,
  title={ProtNote: a multimodal method for protein-function annotation},
  author={Char, Samir and Corley, Nathaniel and Alamdari, Sarah and Yang, Kevin K and Amini, Ava P},
  journal={bioRxiv},
  pages={2024--10},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{fang2024moltc,
  title={Moltc: Towards molecular relational modeling in language models},
  author={Fang, Junfeng and Zhang, Shuai and Wu, Chang and Yang, Zhengyi and Liu, Zhiyuan and Li, Sihang and Wang, Kun and Du, Wenjie and Wang, Xiang},
  journal={arXiv preprint arXiv:2402.03781},
  year={2024}
}

@article{gligorijevic2021structure,
  title={Structure-based protein function prediction using graph convolutional networks},
  author={Gligorijevi{\'c}, Vladimir and Renfrew, P Douglas and Kosciolek, Tomasz and Leman, Julia Koehler and Berenberg, Daniel and Vatanen, Tommi and Chandler, Chris and Taylor, Bryn C and Fisk, Ian M and Vlamakis, Hera and others},
  journal={Nature communications},
  volume={12},
  number={1},
  pages={3168},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{guo2023proteinchat,
  title={Proteinchat: Towards achieving chatgpt-like functionalities on protein 3d structures},
  author={Guo, Han and Huo, Mingjia and Zhang, Ruiyi and Xie, Pengtao},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}

@article{hayes2024simulating,
  title={Simulating 500 million years of evolution with a language model},
  author={Hayes, Tomas and Rao, Roshan and Akin, Halil and Sofroniew, Nicholas J and Oktay, Deniz and Lin, Zeming and Verkuil, Robert and Tran, Vincent Q and Deaton, Jonathan and Wiggert, Marius and others},
  journal={bioRxiv},
  pages={2024--07},
  year={2024},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{lin2023evolutionary,
  title={Evolutionary-scale prediction of atomic-level protein structure with a language model},
  author={Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and others},
  journal={Science},
  volume={379},
  number={6637},
  pages={1123--1130},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@article{liu2024prott3,
  title={ProtT3: Protein-to-Text Generation for Text-based Protein Understanding},
  author={Liu, Zhiyuan and Zhang, An and Fei, Hao and Zhang, Enzhi and Wang, Xiang and Kawaguchi, Kenji and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2405.12564},
  year={2024}
}

@article{luo2023biomedgpt,
  title={Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine},
  author={Luo, Yizhen and Zhang, Jiahuan and Fan, Siqi and Yang, Kai and Wu, Yushuai and Qiao, Mu and Nie, Zaiqing},
  journal={arXiv preprint arXiv:2308.09442},
  year={2023}
}

@article{lyu2023macaw,
  title={Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration},
  author={Lyu, Chenyang and Wu, Minghao and Wang, Longyue and Huang, Xinting and Liu, Bingshuai and Du, Zefeng and Shi, Shuming and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2306.09093},
  year={2023}
}

@inproceedings{notin2022tranception,
  title={Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval},
  author={Notin, Pascal and Dias, Mafalda and Frazer, Jonathan and Marchena-Hurtado, Javier and Gomez, Aidan N and Marks, Debora and Gal, Yarin},
  booktitle={International Conference on Machine Learning},
  pages={16990--17017},
  year={2022},
  organization={PMLR}
}

@article{rives2021biological,
  title={Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
  author={Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C Lawrence and Ma, Jerry and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={118},
  number={15},
  pages={e2016239118},
  year={2021},
  publisher={National Acad Sciences}
}

@article{shi2023relm,
  title={Relm: Leveraging language models for enhanced chemical reaction prediction},
  author={Shi, Yaorui and Zhang, An and Zhang, Enzhi and Liu, Zhiyuan and Wang, Xiang},
  journal={arXiv preprint arXiv:2310.13590},
  year={2023}
}

@article{su2023saprot,
  title={Saprot: Protein language modeling with structure-aware vocabulary},
  author={Su, Jin and Han, Chenchen and Zhou, Yuyang and Shan, Junjie and Zhou, Xibin and Yuan, Fajie},
  journal={bioRxiv},
  pages={2023--10},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}

@article{taylor2022galactica,
  title={Galactica: A large language model for science},
  author={Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
  journal={arXiv preprint arXiv:2211.09085},
  year={2022}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={200--212},
  year={2021}
}

@article{van2022foldseek,
  title={Foldseek: fast and accurate protein structure search},
  author={van Kempen, Michel and Kim, Stephanie S and Tumescheit, Charlotte and Mirdita, Milot and Gilchrist, Cameron LM and S{\"o}ding, Johannes and Steinegger, Martin},
  journal={Biorxiv},
  pages={2022--02},
  year={2022},
  publisher={Cold Spring Harbor Laboratory}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{wang2023instructprotein,
  title={Instructprotein: Aligning human and protein language via knowledge instruction},
  author={Wang, Zeyuan and Zhang, Qiang and Ding, Keyan and Qin, Ming and Zhuang, Xiang and Li, Xiaotong and Chen, Huajun},
  journal={arXiv preprint arXiv:2310.03269},
  year={2023}
}

@article{wang2024protchatgpt,
  title={Protchatgpt: Towards understanding proteins with large language models},
  author={Wang, Chao and Fan, Hehe and Quan, Ruijie and Yang, Yi},
  journal={arXiv preprint arXiv:2402.09649},
  year={2024}
}

@article{xiang2024fapm,
  title={FAPM: Functional Annotation of Proteins using Multi-Modal Models Beyond Structural Modeling},
  author={Xiang, Wenkai and Xiong, Zhaoping and Chen, Huan and Xiong, Jiacheng and Zhang, Wei and Fu, Zunyun and Zheng, Mingyue and Liu, Bing and Shi, Qian},
  journal={Bioinformatics},
  pages={btae680},
  year={2024},
  publisher={Oxford University Press}
}

@article{zhang2023video,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}

@article{zhuang2024instructbiomol,
  title={InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions},
  author={Zhuang, Xiang and Ding, Keyan and Lyu, Tianwen and Jiang, Yinuo and Li, Xiaotong and Xiang, Zhuoyi and Wang, Zeyuan and Qin, Ming and Feng, Kehua and Wang, Jike and others},
  journal={arXiv preprint arXiv:2410.07919},
  year={2024}
}

