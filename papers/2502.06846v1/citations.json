[
  {
    "index": 0,
    "papers": [
      {
        "key": "notin2022tranception",
        "author": "Notin, Pascal and Dias, Mafalda and Frazer, Jonathan and Marchena-Hurtado, Javier and Gomez, Aidan N and Marks, Debora and Gal, Yarin",
        "title": "Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "vaswani2017attention",
        "author": "Vaswani, A",
        "title": "Attention is all you need"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "rives2021biological",
        "author": "Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C Lawrence and Ma, Jerry and others",
        "title": "Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences"
      },
      {
        "key": "lin2023evolutionary",
        "author": "Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and others",
        "title": "Evolutionary-scale prediction of atomic-level protein structure with a language model"
      },
      {
        "key": "hayes2024simulating",
        "author": "Hayes, Tomas and Rao, Roshan and Akin, Halil and Sofroniew, Nicholas J and Oktay, Deniz and Lin, Zeming and Verkuil, Robert and Tran, Vincent Q and Deaton, Jonathan and Wiggert, Marius and others",
        "title": "Simulating 500 million years of evolution with a language model"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gligorijevic2021structure",
        "author": "Gligorijevi{\\'c}, Vladimir and Renfrew, P Douglas and Kosciolek, Tomasz and Leman, Julia Koehler and Berenberg, Daniel and Vatanen, Tommi and Chandler, Chris and Taylor, Bryn C and Fisk, Ian M and Vlamakis, Hera and others",
        "title": "Structure-based protein function prediction using graph convolutional networks"
      },
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "van2022foldseek",
        "author": "van Kempen, Michel and Kim, Stephanie S and Tumescheit, Charlotte and Mirdita, Milot and Gilchrist, Cameron LM and S{\\\"o}ding, Johannes and Steinegger, Martin",
        "title": "Foldseek: fast and accurate protein structure search"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "su2023saprot",
        "author": "Su, Jin and Han, Chenchen and Zhou, Yuyang and Shan, Junjie and Zhou, Xibin and Yuan, Fajie",
        "title": "Saprot: Protein language modeling with structure-aware vocabulary"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "tsimpoukelli2021multimodal",
        "author": "Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix",
        "title": "Multimodal few-shot learning with frozen language models"
      },
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2023video",
        "author": "Zhang, Hang and Li, Xin and Bing, Lidong",
        "title": "Video-llama: An instruction-tuned audio-visual language model for video understanding"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "lyu2023macaw",
        "author": "Lyu, Chenyang and Wu, Minghao and Wang, Longyue and Huang, Xinting and Liu, Bingshuai and Du, Zefeng and Shi, Shuming and Tu, Zhaopeng",
        "title": "Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "shi2023relm",
        "author": "Shi, Yaorui and Zhang, An and Zhang, Enzhi and Liu, Zhiyuan and Wang, Xiang",
        "title": "Relm: Leveraging language models for enhanced chemical reaction prediction"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "fang2024moltc",
        "author": "Fang, Junfeng and Zhang, Shuai and Wu, Chang and Yang, Zhengyi and Liu, Zhiyuan and Li, Sihang and Wang, Kun and Du, Wenjie and Wang, Xiang",
        "title": "Moltc: Towards molecular relational modeling in language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      },
      {
        "key": "alayrac2022flamingo",
        "author": "Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others",
        "title": "Flamingo: a visual language model for few-shot learning"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "li2023blip",
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "driess2023palm",
        "author": "Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others",
        "title": "Palm-e: An embodied multimodal language model"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "taylor2022galactica",
        "author": "Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert",
        "title": "Galactica: A large language model for science"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "char2024protnote",
        "author": "Char, Samir and Corley, Nathaniel and Alamdari, Sarah and Yang, Kevin K and Amini, Ava P",
        "title": "ProtNote: a multimodal method for protein-function annotation"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "guo2023proteinchat",
        "author": "Guo, Han and Huo, Mingjia and Zhang, Ruiyi and Xie, Pengtao",
        "title": "Proteinchat: Towards achieving chatgpt-like functionalities on protein 3d structures"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "wang2024protchatgpt",
        "author": "Wang, Chao and Fan, Hehe and Quan, Ruijie and Yang, Yi",
        "title": "Protchatgpt: Towards understanding proteins with large language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zhuang2024instructbiomol",
        "author": "Zhuang, Xiang and Ding, Keyan and Lyu, Tianwen and Jiang, Yinuo and Li, Xiaotong and Xiang, Zhuoyi and Wang, Zeyuan and Qin, Ming and Feng, Kehua and Wang, Jike and others",
        "title": "InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "wang2023instructprotein",
        "author": "Wang, Zeyuan and Zhang, Qiang and Ding, Keyan and Qin, Ming and Zhuang, Xiang and Li, Xiaotong and Chen, Huajun",
        "title": "Instructprotein: Aligning human and protein language via knowledge instruction"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "abdine2024prot2text",
        "author": "Abdine, Hadi and Chatzianastasis, Michail and Bouyioukos, Costas and Vazirgiannis, Michalis",
        "title": "Prot2text: Multimodal protein\u2019s function generation with gnns and transformers"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "liu2024prott3",
        "author": "Liu, Zhiyuan and Zhang, An and Fei, Hao and Zhang, Enzhi and Wang, Xiang and Kawaguchi, Kenji and Chua, Tat-Seng",
        "title": "ProtT3: Protein-to-Text Generation for Text-based Protein Understanding"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "xiang2024fapm",
        "author": "Xiang, Wenkai and Xiong, Zhaoping and Chen, Huan and Xiong, Jiacheng and Zhang, Wei and Fu, Zunyun and Zheng, Mingyue and Liu, Bing and Shi, Qian",
        "title": "FAPM: Functional Annotation of Proteins using Multi-Modal Models Beyond Structural Modeling"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "luo2023biomedgpt",
        "author": "Luo, Yizhen and Zhang, Jiahuan and Fan, Siqi and Yang, Kai and Wu, Yushuai and Qiao, Mu and Nie, Zaiqing",
        "title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine"
      }
    ]
  }
]