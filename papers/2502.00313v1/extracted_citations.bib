@inproceedings{AherICML,
  author       = {Gati V. Aher and
                  Rosa I. Arriaga and
                  Adam Tauman Kalai},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Using Large Language Models to Simulate Multiple Humans and Replicate
                  Human Subject Studies},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {337--371},
  publisher    = {{PMLR}},
  year         = {2023}
}

@article{B&O00,
 ISSN = {00028282},
 abstract = {We demonstrate that a simple model, constructed on the premise that people are motivated by both their pecuniary payoff and their relative payoff standing, organizes a large and seemingly disparate set of laboratory observations as one consistent pattern. The model is incomplete information but nevertheless posed entirely in terms of directly observable variables. The model explains observations from games where equity is thought to be a factor, such as ultimatum and dictator, games where reciprocity is thought to play a role, such as the prisoner's dilemma and gift exchange, and games where competitive behavior is observed, such as Bertrand markets.},
 author = {Gary E Bolton and Axel Ockenfels},
 journal = {The American Economic Review},
 number = {1},
 pages = {166--193},
 publisher = {American Economic Association},
 title = {{ERC}: {A} Theory of Equity, Reciprocity, and Competition},
 urldate = {2023-09-25},
 volume = {90},
 year = {2000}
}

@article{BramsDavid,
 ISSN = {07388942, 15499219},
 URL = {http://www.jstor.org/stable/26273187},
 abstract = {The agreement between Egypt and Israel at Camp David in 1978 is used to illustrate how a fair-division procedure called Adjusted Winner (AW), in which two sides allocate 100 points over the issues that divide them, could have been used to reach a settlement. AW satisfies the properties of envy-freeness (each side is ensured of receiving at least 50 of its points and hence does not envy the other side), equitability (each side receives the same number of points over 50), and efficiency (there is no other settlement better for both players). While the actual agreement at Camp David seems to reflect quite well what AW would have yielded on the six issues that divided the two sides, this agreement probably could have been achieved more expeditiously, and in a less crisis-driven atmosphere, if AW had been used.},
 author = {Steven J. Brams and Jeffrey M. Togman},
 journal = {Conflict Management and Peace Science},
 number = {1},
 pages = {99--112},
 publisher = {Sage Publications, Ltd.},
 title = {CAMP DAVID: WAS THE AGREEMENT FAIR?},
 urldate = {2024-02-07},
 volume = {15},
 year = {1996}
}

@TechReport{BramsSpratly,
  author={Brams, Steven J. and Denoon, David},
  title={{Fair Division: A New Approach to the Spratly Islands Controversy}},
  year=1996,
  institution={C.V. Starr Center for Applied Economics, New York University},
  type={Working Papers},
  url={https://ideas.repec.org/p/cvs/starer/96-10.html},
  number={96-10},
  abstract={No abstract is available for this item.},
  keywords={Fair division; bargaining; envy-freeness; Spratly Islands},
  doi={},
}

@article{C&R02,
 ISSN = {00335533, 15314650},
 abstract = {Departures from self-interest in economic experiments have recently inspired model s of "social preferences." We design a range of simple experimental games that test these theories more directly than existing experiments. Our experiments show that subjects are more concerned with increasing social welfare-sacrificing to increase the payoffs for all recipients, especially low-payoff recipients-than with reducing differences in payoffs (as supposed in recent models). Subjects are also motivated by reciprocity: they withdraw willingness to sacrifice to achieve a fair outcome when others are themselves unwilling to sacrifice, and sometimes punish unfair behavior.},
 author = {Gary Charness and Matthew Rabin},
 journal = {The Quarterly Journal of Economics},
 number = {3},
 pages = {817--869},
 publisher = {Oxford University Press},
 title = {Understanding Social Preferences with Simple Tests},
 urldate = {2023-09-25},
 volume = {117},
 year = {2002}
}

@article{Chang2024Survey,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
doi = {10.1145/3641289},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@techreport{CharnessLLM2023,
 title = "Generation Next: Experimentation with AI",
 author = "Charness, Gary and Jabarian, Brian and List, John A",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "31679",
 year = "2023",
 month = "September",
 doi = {10.3386/w31679},
 abstract = {We investigate the potential for Large Language Models (LLMs) to enhance scientific practice within experimentation by identifying key areas, directions, and implications. First, we discuss how these models can improve experimental design, including improving the elicitation wording, coding experiments, and producing documentation. Second, we delve into the use of LLMs in experiment implementation, with an emphasis on bolstering causal inference through creating consistent experiences, improving instruction comprehension, and real-time monitoring of participant engagement. Third, we underscore the role of LLMs in analyzing experimental data, encompassing tasks like pre-processing, data cleaning, and assisting reviewers and replicators in examining studies. Each of these tasks improves the probability of reporting accurate findings. Lastly, we suggest a scientific governance framework that mitigates the potential risks of using LLMs in experimental research while amplifying their advantages. This could pave the way for open science opportunities and foster a culture of policy and industry experimentation at scale.},
}

@inproceedings{Dziri2023Faith,
  author       = {Nouha Dziri and
                  Ximing Lu and
                  Melanie Sclar and
                  Xiang Lorraine Li and
                  Liwei Jiang and
                  Bill Yuchen Lin and
                  Sean Welleck and
                  Peter West and
                  Chandra Bhagavatula and
                  Ronan Le Bras and
                  Jena D. Hwang and
                  Soumya Sanyal and
                  Xiang Ren and
                  Allyson Ettinger and
                  Za{\"{\i}}d Harchaoui and
                  Yejin Choi},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Faith and Fate: Limits of Transformers on Compositionality},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
}

@article{E&S04,
 ISSN = {00028282},
 abstract = {We present simple one-shot distribution experiments comparing the relative importance of efficiency concerns, maximin preferences, and inequality aversion, as well as the relative performance of the fairness theories by Gary E Bolton and Axel Ockenfels and by Ernst Fehr and Klaus M. Schmidt. While the Fehr-Schmidt theory performs better in a direct comparison, this appears to be due to being in line with maximin preferences. More importantly, we find that a combination of efficiency concerns, maximin preferences, and selfishness can rationalize most of the data while the Bolton-Ockenfels and Fehr-Schmidt theories are unable to explain important patterns.},
 author = {Dirk Engelmann and Martin Strobel},
 journal = {The American Economic Review},
 number = {4},
 pages = {857--869},
 publisher = {American Economic Association},
 title = {Inequality Aversion, Efficiency, and Maximin Preferences in Simple Distribution Experiments},
 urldate = {2023-09-25},
 volume = {94},
 year = {2004}
}

@article{F&S00,
 ISSN = {00335533, 15314650},
 abstract = {There is strong evidence that people exploit their bargaining power in competitive markets but not in bilateral bargaining situations. There is also strong evidence that people exploit free-riding opportunities in voluntary cooperation games. Yet, when they are given the opportunity to punish free riders, stable cooperation is maintained, although punishment is costly for those who punish. This paper asks whether there is a simple common principle that can explain this puzzling evidence. We show that if some people care about equity the puzzles can be resolved. It turns out that the economic environment determines whether the fair types or the selfish types dominate equilibrium behavior.},
 author = {Ernst Fehr and Klaus M. Schmidt},
 journal = {The Quarterly Journal of Economics},
 number = {3},
 pages = {817--868},
 publisher = {Oxford University Press},
 title = {A Theory of Fairness, Competition, and Cooperation},
 urldate = {2023-09-25},
 volume = {114},
 year = {1999}
}

@article{Frohlich87,
 ISSN = {00925853, 15405907},
 abstract = {Experimental methods involving imperfect information are used to generate group choices of principles of distributive justice. Conditions approximating John Rawls's "original position" in A Theory of Justice serve as the starting point, and his conjectures are contrasted with those of John Harsanyi. Three "predictions" implicit in the Rawlsian argument are tested: (1) individuals choosing a principle of economic distribution would be able to reach unanimous agreement; (2) they would always choose the same principle; and (3) they would always choose to maximize the welfare of the worst-off individual. Our results indicate that individuals reach consensus, strongly reject the minimax principle, and largely choose what Rawls has called an "intuitionistic" principle. Overwhelmingly, the chosen principle is maximizing the average income with a floor constraint: a principle which is a compromise between those proposed by Rawls and Harsanyi. It takes into account not only the position of the worst-off individual but also the potential expected gain for the rest of society.},
 author = {Norman Frohlich and Joe A. Oppenheimer and Cheryl L. Eavey},
 journal = {American Journal of Political Science},
 number = {3},
 pages = {606--636},
 publisher = {[Midwest Political Science Association, Wiley]},
 title = {Choices of Principles of Distributive Justice in Experimental Groups},
 urldate = {2024-01-08},
 volume = {31},
 year = {1987}
}

@article{Gaertner200,
author={Gaertner,Wulf and Jungeilges,Jochen},
year={2002},
month={01},
title={Evaluation via extended orderings: Empirical findings from Western and Eastern Europe},
journal={Social Choice and Welfare},
volume={19},
number={1},
pages={29-55},
note={Copyright - Copyright Springer-Verlag 2002; Last updated - 2023-11-25},
keywords={Social Services And Welfare; Economics; Students; Society; Utilitarianism},
isbn={01761714},
language={English},
url={https://ezaccess.libraries.psu.edu/login?url=https://www-proquest-com.ezaccess.libraries.psu.edu/scholarly-journals/evaluation-via-extended-orderings-empirical/docview/236413721/se-2},
}

@article{Gates2020,
author = {Gates, Vael and Griffiths, Thomas L. and Dragan, Anca D.},
title = {How to Be Helpful to Multiple People at Once},
journal = {Cognitive Science},
volume = {44},
number = {6},
pages = {e12841},
keywords = {Fairness, Preferences, Assistive artificial intelligence, Maximin, Modeling},
doi = {https://doi.org/10.1111/cogs.12841},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12841},
abstract = {Abstract When someone hosts a party, when governments choose an aid program, or when assistive robots decide what meal to serve to a family, decision-makers must determine how to help even when their recipients have very different preferences. Which combination of people’s desires should a decision-maker serve? To provide a potential answer, we turned to psychology: What do people think is best when multiple people have different utilities over options? We developed a quantitative model of what people consider desirable behavior, characterizing participants’ preferences by inferring which combination of “metrics” (maximax, maxsum, maximin, or inequality aversion [IA]) best explained participants’ decisions in a drink-choosing task. We found that participants’ behavior was best described by the maximin metric, describing the desire to maximize the happiness of the worst-off person, though participant behavior was also consistent with maximizing group utility (the maxsum metric) and the IA metric to a lesser extent. Participant behavior was consistent across variation in the agents involved and  tended to become more maxsum-oriented when participants were told they were players in the task (Experiment 1). In later experiments, participants maintained maximin behavior across multi-step tasks rather than shortsightedly focusing on the individual steps therein (Experiment 2, Experiment 3). By repeatedly asking participants what choices they would hope for in an optimal, just decision-maker, and carefully disambiguating which quantitative metrics describe these nuanced choices, we help constrain the space of what behavior we desire in leaders, artificial intelligence systems helping decision-makers, and the assistive robots and decision-makers of the future.},
year = {2020}
}

@article{H&P07,
title = {Distributing Indivisible Goods Fairly: Evidence from a Questionnaire Study},
author = {Dorothea Herreiner and Clemens Puppe},
pages = {235--258},
volume = {29},
number = {2},
journal = {Analyse \& Kritik},
doi = {doi:10.1515/auk-2007-0208},
year = {2007},
lastchecked = {2023-09-25}
}

@article{HP10,
title = {Inequality aversion and efficiency with ordinal and cardinal social preferences—{A}n experimental study},
journal = {Journal of Economic Behavior \& Organization},
volume = {76},
number = {2},
pages = {238-253},
year = {2010},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2010.06.002},
author = {Dorothea Herreiner and Clemens Puppe}
}

@article{KRITIKOS2001,
title = {Distributional concerns: equity- or efficiency-oriented?},
journal = {Economics Letters},
volume = {73},
number = {3},
pages = {333-338},
year = {2001},
issn = {0165-1765},
doi = {https://doi.org/10.1016/S0165-1765(01)00503-1},
url = {https://www.sciencedirect.com/science/article/pii/S0165176501005031},
author = {Alexander Kritikos and Friedel Bolle},
keywords = {Dictator game, Altruism, Reciprocity, Difference aversion, Efficiency},
abstract = {This paper provides experimental evidence that in binary-choice dictator games the majority of participants are efficiency rather than equity-oriented — even if their own payoff is reduced by the respective choice. Therefore, altruistic and — as a consequence — reciprocal motives need to be modelled explicitly if we aim to predict behavior in experiments correctly.}
}

@article{KYROPOULOU202228,
title = {Fair cake-cutting in practice},
journal = {Games and Economic Behavior},
volume = {133},
pages = {28-49},
year = {2022},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2022.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0899825622000331},
author = {Maria Kyropoulou and Josué Ortega and Erel Segal-Halevi},
keywords = {Cake-cutting, Selfridge-Conway, Cut-and-choose, Envy, Fairness, Preference manipulation, Experimentation and learning},
abstract = {Using two lab experiments, we investigate the real-life performance of envy-free and proportional cake-cutting procedures with respect to fairness and preference manipulation. Although the observed subjects' strategic behavior eliminates the fairness guarantees of envy-free procedures, we nonetheless find evidence that suggests that envy-free procedures are fairer than their proportional counterparts. Our results support the practical use of the celebrated Selfridge-Conway procedure, and more generally, of envy-free cake-cutting mechanisms. We also find that subjects learn their opponents' preferences after repeated interaction and use this knowledge to improve their allocated share of the cake. Learning increases strategic behavior, but also reduces envy.}
}

@article{Konow03,
 ISSN = {00220515},
 URL = {http://www.jstor.org/stable/3217459},
 author = {James Konow},
 journal = {Journal of Economic Literature},
 number = {4},
 pages = {1188--1239},
 publisher = {American Economic Association},
 title = {Which Is the Fairest One of All? A Positive Analysis of Justice Theories},
 urldate = {2023-09-25},
 volume = {41},
 year = {2003}
}

@inproceedings{LeeFR17,
author = {Lee, Min Kyung and Kim, Ji Tae and Lizarondo, Leah},
title = {A Human-Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management That Allocates Donations to Non-Profit Organizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025884},
doi = {10.1145/3025453.3025884},
abstract = {Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service-organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens-in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3365–3376},
numpages = {12},
keywords = {donation, allocation, service design, automation, community service, fairness, algorithmic services, motivation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@article{LeeWBAI19,
  author       = {Min Kyung Lee and
                  Daniel Kusbit and
                  Anson Kahng and
                  Ji Tae Kim and
                  Xinran Yuan and
                  Allissa Chan and
                  Daniel See and
                  Ritesh Noothigattu and
                  Siheon Lee and
                  Alexandros Psomas and
                  Ariel D. Procaccia},
  title        = {We{B}uild{AI}: Participatory Framework for Algorithmic Governance},
  journal      = {Proc. {ACM} Hum. Comput. Interact.},
  volume       = {3},
  number       = {{CSCW}},
  pages        = {181:1--181:35},
  year         = {2019},
  url          = {https://doi.org/10.1145/3359283},
  doi          = {10.1145/3359283},
  timestamp    = {Mon, 28 Aug 2023 21:21:42 +0200},
  biburl       = {https://dblp.org/rec/journals/pacmhci/LeeKKKYCSNLPP19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Massoud02,
 ISSN = {00220027, 15528766},
 URL = {http://www.jstor.org/stable/174630},
 abstract = {A dispute resolution mechanism called Adjusted Winner (AW), developed by Brams and Taylor, is used to propose a plausible solution to the final status issues between Israel and the Palestinians. Unlike conventional negotiating procedures, AW possesses desirable qualities including equitability, efficiency, and envy freeness. Based on data from an original survey, results show that when the issues of security and borders are kept separate, Israel is likely to have its demands met on the issues of security, East Jerusalem, normalization of relations, and water. The Palestinians will win on the issues of sovereignty, Israeli settlements in the West Bank, Israeli settlements in Gaza, and Palestinian refugees. Both sides will need to compromise on the issue of boundaries. If security and borders are lumped together as one issue, Israel and the Palestinians will share on the issue of East Jerusalem.},
 author = {Tansa George Massoud},
 journal = {The Journal of Conflict Resolution},
 number = {3},
 pages = {333--358},
 publisher = {Sage Publications, Inc.},
 title = {Fair Division, Adjusted Winner Procedure (AW), and the Israeli-Palestinian Conflict},
 urldate = {2024-02-02},
 volume = {44},
 year = {2000}
}

@Inbook{Overlaet1991,
author="Overlaet, Bert
and Schokkaert, Erik",
editor="Steensma, Herman
and Vermunt, Ri{\"e}l",
title="Criteria for Distributive Justice in a Productive Context",
bookTitle="Social Justice in Human Relations: Societal and Psychological Consequences of Justice and Injustice",
year="1991",
publisher="Springer US",
address="Boston, MA",
pages="197--208",
abstract="In 1977, the Center for Community Psychology started a research program on the attitudes toward redistribution of income. In 1981, we presented an analysis and interpretation of questionnaire data of 180 subjects (Lagrou, Overlaet, {\&} Schokkaert, 1981). We questioned our subjects on how they perceived and evaluated the existing income distribution. In general, there appeared a strong tendency to redistribute incomes by reducing the span between high and low-income groups. The structure of the income distribution was left unchanged. These results were further elaborated into a formal mathematical model (Overlaet {\&} Lagrou, 1981; Schokkaert {\&} Lagrou, 1983).",
isbn="978-1-4899-2629-6",
doi="10.1007/978-1-4899-2629-6_10",
url="https://doi.org/10.1007/978-1-4899-2629-6_10"
}

@article{Pratt90,
 ISSN = {00251909, 15265501},
 URL = {http://www.jstor.org/stable/2632606},
 abstract = {This paper presents a general model for aggregating votes from a preferential ballot. The thrust of the model is to accord each candidate a fair assessment in terms of his overall standing vis-a-vis first place, second place,..., kth place votes. The form of the model is a combined index $\sum_{j=1}^{k}\ W_{j}v_{ij}$ where vij is the number of the jth place votes received by the ith candidate. The weights Wj are assumed to form a monotonically decreasing sequence with Wj — Wj+1 ≥ d(j, ε). These constraints correspond to the assurance region (AR) side constraints in the DEA framework. The properties of the model are examined in terms of this discrimination intensity function d, and in the special case that d(j, ε) = ε, our model is shown to be equivalent to the consensus models of Borda and Kendall.},
 author = {John Winsor Pratt and Richard Jay Zeckhauser},
 journal = {Management Science},
 number = {11},
 pages = {1293--1301},
 publisher = {INFORMS},
 title = {The Fair and Efficient Division of the Winsor Family Silver},
 urldate = {2024-01-15},
 volume = {36},
 year = {1990}
}

@book{RawlsTOJ,
 ISBN = {9780674880108},
 abstract = {
John Rawls aims to express an essential part of the common core
of the democratic tradition-justice as fairness-and to provide an
alternative to utilitarianism, which had dominated the Anglo-Saxon
tradition of political thought since the nineteenth century. Rawls
substitutes the ideal of the social contract as a more satisfactory
account of the basic rights and liberties of citizens as free and
equal persons. "Each person," writes Rawls, "possesses an
inviolability founded on justice that even the welfare of society
as a whole cannot override." Advancing the ideas of Rousseau, Kant,
Emerson, and Lincoln, Rawls's theory is as powerful today as it was
when first published. Though the revised edition of A Theory of
Justice, published in 1999, is the definitive statement of
Rawls's view, much of the extensive literature on his theory refers
to the original. This first edition is available for scholars and
serious students of Rawls's work.
},
 author = {John Rawls},
 publisher = {Harvard University Press},
 title = {A Theory of Justice: Original Edition},
 urldate = {2023-11-17},
 year = {1971}
}

@article{Schnieder04,
author={Schneider,Gerald and Krämer,Ulrike S.},
year={2004},
month={08},
title={The Limitations of Fair Division: AN EXPERIMENTAL EVALUATION OF THREE PROCEDURES},
journal={The Journal of Conflict Resolution},
volume={48},
number={4},
pages={506-524},
note={Copyright - Copyright SAGE PUBLICATIONS, INC. Aug 2004; Document feature - tables; Last updated - 2023-11-27; CODEN - JCFRAL},
abstract={Mathematical procedures that promise an envy-free, equitable, and efficient solution to distributional conflicts have received widespread attention. Two fair-division mechanisms, adjusted Knaster and proportional Knaster, which are similar to the well-known adjusted-winner procedure, are compared with the less fair divide-and-choose mechanism. Results show that participants largely prefer the adjusted-Knaster procedure to the two alternatives. Adjusted Knaster, closely followed by proportional Knaster, also promises the highest average payoff. Yet the sophisticated mechanisms cease to perform better than divide-and-choose once actors receive the possibility to deviate from the mandatory bargaining protocols of fair-division procedures. The preference for adjusted and proportional Knaster is found to be a partial function of the participants' psychological profile. The more "antisocial" a participant, the more likely this respondent is to opt for a procedure with a compensatory mechanism. Publication Abstract]},
keywords={Political Science--International Relations; Fair division; Prioritization; Fair; Political science; Experiments; Contract negotiations; Conflict resolution; Bargaining; Expected utility; Game theory; Preferences; Protocol; Credibility; Efficiency; 9130:Experimental/theoretical; 1210:Politics & political behavior},
isbn={00220027},
language={English},
url={https://ezaccess.libraries.psu.edu/login?url=https://www-proquest-com.ezaccess.libraries.psu.edu/scholarly-journals/limitations-fair-division-experimental-evaluation/docview/224557997/se-2},
}

@article{akata2023playing,
  title={Playing repeated games with large language models},
  author={Akata, Elif and Schulz, Lion and Coda-Forno, Julian and Oh, Seong Joon and Bethge, Matthias and Schulz, Eric},
  journal={arXiv preprint arXiv:2305.16867},
  year={2023}
}

@inproceedings{bianchi2024well,
  author       = {Federico Bianchi and
                  Patrick John Chia and
                  Mert Y{\"{u}}ksekg{\"{o}}n{\"{u}}l and
                  Jacopo Tagliabue and
                  Dan Jurafsky and
                  James Zou},
  title        = {How Well Can {LLMs} Negotiate? {N}egotiation{A}rena Platform and Analysis},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@article{chen2023put,
  title={Put your money where your mouth is: Evaluating strategic planning and execution of {LLM} agents in an auction arena},
  author={Chen, Jiangjie and Yuan, Siyu and Ye, Rong and Majumder, Bodhisattwa Prasad and Richardson, Kyle},
  journal={arXiv preprint arXiv:2310.05746},
  year={2023}
}

@article{conitzer2024social,
  title={Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback},
  author={Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday, Wesley H and Jacobs, Bob M and Lambert, Nathan and Moss{\'e}, Milan and Pacuit, Eric and Russell, Stuart and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2404.10271},
  year={2024}
}

@inproceedings{dupuis2011simpler,
  title={The simpler, the better: A new challenge for fair-division theory},
  author={Dupuis-Roy, Nicolas and Gosselin, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@article{fish2024algorithmic,
  title={Algorithmic Collusion by Large Language Models},
  author={Fish, Sara and Gonczarowski, Yannai A and Shorrer, Ran I},
  journal={arXiv preprint arXiv:2404.00806},
  year={2024}
}

@inproceedings{fish2024generative,
author = {Fish, Sara and G\"{o}lz, Paul and Parkes, David C. and Procaccia, Ariel D. and Rusak, Gili and Shapira, Itai and W\"{u}thrich, Manuel},
title = {Generative Social Choice},
year = {2024},
isbn = {9798400707049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670865.3673547},
doi = {10.1145/3670865.3673547},
booktitle = {Proceedings of the 25th ACM Conference on Economics and Computation},
pages = {985},
numpages = {1},
keywords = {computational social choice, large language models, proportional representation, democratic participation, AI governance},
location = {New Haven, CT, USA},
series = {EC '24}
}

@article{fontana2024nicer,
  title={Nicer Than Humans: How do Large Language Models Behave in the Prisoner's Dilemma?},
  author={Fontana, Nicol{\'o} and Pierri, Francesco and Aiello, Luca Maria},
  journal={arXiv preprint arXiv:2406.13605},
  year={2024}
}

@inproceedings{gal2016rent,
  author       = {Kobi Gal and
                  Ariel D. Procaccia and
                  Moshe Mash and
                  Yair Zick},
  title        = {Which is the fairest (rent division) of them all?},
  journal      = {Commun. {ACM}},
  volume       = {61},
  number       = {2},
  pages        = {93--100},
  year         = {2018},
  url          = {https://doi.org/10.1145/3166068},
  doi          = {10.1145/3166068},
}

@article{gandhi2023strategic,
  title={Strategic reasoning with language models},
  author={Gandhi, Kanishk and Sadigh, Dorsa and Goodman, Noah D},
  journal={arXiv preprint arXiv:2305.19165},
  year={2023}
}

@article{ge2024axioms,
  title={Axioms for AI Alignment from Human Feedback},
  author={Ge, Luise and Halpern, Daniel and Micha, Evi and Procaccia, Ariel D and Shapira, Itai and Vorobeychik, Yevgeniy and Wu, Junlin},
  journal={arXiv preprint arXiv:2405.14758},
  year={2024}
}

@article{goli2023can,
  title={Can {LLM}s Capture Human Preferences?},
  author={Goli, Ali and Singh, Amandeep},
  journal={arXiv preprint arXiv:2305.02531},
  year={2023}
}

@article{gui2023challenge,
  author       = {George Gui and
                  Olivier Toubia},
  title        = {The Challenge of Using {LLM}s to Simulate Human Behavior: {A} Causal
                  Inference Perspective},
  journal      = {CoRR},
  volume       = {abs/2312.15524},
  year         = {2023},
  doi          = {10.48550/ARXIV.2312.15524},
  eprinttype    = {arXiv},
  eprint       = {2312.15524},
}

@article{guo2023gpt,
  title={{GPT} in game theory experiments},
  author={Guo, Fulin},
  journal={arXiv preprint arXiv:2305.05516},
  year={2023}
}

@article{guo2024econnli,
  title={Econ{NLI}: Evaluating Large Language Models on Economics Reasoning},
  author={Guo, Yue and Yang, Yi},
  journal={arXiv preprint arXiv:2407.01212},
  year={2024}
}

@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}

@techreport{horton2023large,
  title={Large language models as simulated economic agents: What can we learn from homo silicus?},
  author={Horton, John J},
  year={2023},
  institution={National Bureau of Economic Research}
}

@article{hua2024game,
  title={Game-theoretic {LLM}: Agent Workflow for Negotiation Games},
  author={Hua, Wenyue and Liu, Ollie and Li, Lingyao and Amayuelas, Alfonso and Chen, Julie and Jiang, Lucas and Jin, Mingyu and Fan, Lizhou and Sun, Fei and Wang, William and others},
  journal={arXiv preprint arXiv:2411.05990},
  year={2024}
}

@article{leng2023llm,
  title={Do {{LLM}} Agents Exhibit Social Behavior?},
  author={Leng, Yan and Yuan, Yuan},
  journal={arXiv preprint arXiv:2312.15198},
  year={2023}
}

@article{mondorf2024beyond,
  author       = {Philipp Mondorf and
                  Barbara Plank},
  title        = {Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language
                  Models - {A} Survey},
  journal      = {CoRR},
  volume       = {abs/2404.01869},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.01869},
  doi          = {10.48550/ARXIV.2404.01869},
  eprinttype    = {arXiv},
  eprint       = {2404.01869},
}

@article{quan2024econlogicqa,
  title={EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning},
  author={Quan, Yinzhu and Liu, Zefang},
  journal={arXiv preprint arXiv:2405.07938},
  year={2024}
}

@article{raman2024rationality,
  title={{STEER}: Assessing the Economic Rationality of Large Language Models},
  author={Raman, Narun and Lundy, Taylor and Amouyal, Samuel and Levine, Yoav and Leyton-Brown, Kevin and Tennenholtz, Moshe},
  journal={arXiv preprint arXiv:2402.09552},
  year={2024}
}

@article{scherrer2024evaluating,
  title={Evaluating the moral beliefs encoded in {LLM}s},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhang2024llm,
  author       = {Yadong Zhang and
                  Shaoguang Mao and
                  Tao Ge and
                  Xun Wang and
                  Adrian de Wynter and
                  Yan Xia and
                  Wenshan Wu and
                  Ting Song and
                  Man Lan and
                  Furu Wei},
  title        = {{LLM} as a Mastermind: {A} Survey of Strategic Reasoning with Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2404.01230},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.01230},
  doi          = {10.48550/ARXIV.2404.01230},
  eprinttype    = {arXiv},
  eprint       = {2404.01230},
}

