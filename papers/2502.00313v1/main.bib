@article{reid2024gemini,
  author       = {Machel Reid and
                  Nikolay Savinov and
                  Denis Teplyashin and
                  Dmitry Lepikhin and
                  Timothy P. Lillicrap and
                  Jean{-}Baptiste Alayrac and
                  Radu Soricut and
                  Angeliki Lazaridou and
                  Orhan Firat and
                  Julian Schrittwieser and
                  Ioannis Antonoglou and
                  Rohan Anil and
                  Sebastian Borgeaud and
                  Andrew M. Dai and
                  Katie Millican and
                  Ethan Dyer and
                  Mia Glaese and
                  Thibault Sottiaux and
                  Benjamin Lee and
                  Fabio Viola and
                  Malcolm Reynolds and
                  Yuanzhong Xu and
                  James Molloy and
                  Jilin Chen and
                  Michael Isard and
                  Paul Barham and
                  Tom Hennigan and
                  Ross McIlroy and
                  Melvin Johnson and
                  Johan Schalkwyk and
                  Eli Collins and
                  Eliza Rutherford and
                  Erica Moreira and
                  Kareem Ayoub and
                  Megha Goel and
                  Clemens Meyer and
                  Gregory Thornton and
                  Zhen Yang and
                  Henryk Michalewski and
                  Zaheer Abbas and
                  Nathan Schucher and
                  Ankesh Anand and
                  Richard Ives and
                  James Keeling and
                  Karel Lenc and
                  Salem Haykal and
                  Siamak Shakeri and
                  Pranav Shyam and
                  Aakanksha Chowdhery and
                  Roman Ring and
                  Stephen Spencer and
                  Eren Sezener and
                  et al.},
  title        = {Gemini 1.5: Unlocking multimodal understanding across millions of
                  tokens of context},
  journal      = {CoRR},
  volume       = {abs/2403.05530},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2403.05530},
  doi          = {10.48550/ARXIV.2403.05530},
  eprinttype    = {arXiv},
  eprint       = {2403.05530},
}

@article{achiam2023gpt,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {CoRR},
  volume       = {abs/2303.08774},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.08774},
  doi          = {10.48550/ARXIV.2303.08774},
  eprinttype    = {arXiv},
  eprint       = {2303.08774},
}

@article{goli2023language,
  author       = {Ali Goli and
                  Amandeep Singh},
  title        = {Language, Time Preferences, and Consumer Behavior: Evidence from Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.02531},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.02531},
  doi          = {10.48550/ARXIV.2305.02531},
  eprinttype    = {arXiv},
  eprint       = {2305.02531},
}

@article{gui2023challenge,
  author       = {George Gui and
                  Olivier Toubia},
  title        = {The Challenge of Using {LLM}s to Simulate Human Behavior: {A} Causal
                  Inference Perspective},
  journal      = {CoRR},
  volume       = {abs/2312.15524},
  year         = {2023},
  doi          = {10.48550/ARXIV.2312.15524},
  eprinttype    = {arXiv},
  eprint       = {2312.15524},
}

@inproceedings{park2023generative,
  author       = {Joon Sung Park and
                  Joseph C. O'Brien and
                  Carrie Jun Cai and
                  Meredith Ringel Morris and
                  Percy Liang and
                  Michael S. Bernstein},
  editor       = {Sean Follmer and
                  Jeff Han and
                  J{\"{u}}rgen Steimle and
                  Nathalie Henry Riche},
  title        = {Generative Agents: Interactive Simulacra of Human Behavior},
  booktitle    = {Proceedings of the 36th Annual {ACM} Symposium on User Interface Software
                  and Technology, {UIST} 2023, San Francisco, CA, USA, 29 October 2023-
                  1 November 2023},
  pages        = {2:1--2:22},
  publisher    = {{ACM}},
  year         = {2023},
  url          = {https://doi.org/10.1145/3586183.3606763},
  doi          = {10.1145/3586183.3606763},
}

@inproceedings{AherICML,
  author       = {Gati V. Aher and
                  Rosa I. Arriaga and
                  Adam Tauman Kalai},
  editor       = {Andreas Krause and
                  Emma Brunskill and
                  Kyunghyun Cho and
                  Barbara Engelhardt and
                  Sivan Sabato and
                  Jonathan Scarlett},
  title        = {Using Large Language Models to Simulate Multiple Humans and Replicate
                  Human Subject Studies},
  booktitle    = {International Conference on Machine Learning, {ICML} 2023, 23-29 July
                  2023, Honolulu, Hawaii, {USA}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {337--371},
  publisher    = {{PMLR}},
  year         = {2023}
}

@inproceedings{gal2016rent,
  author       = {Kobi Gal and
                  Ariel D. Procaccia and
                  Moshe Mash and
                  Yair Zick},
  title        = {Which is the fairest (rent division) of them all?},
  journal      = {Commun. {ACM}},
  volume       = {61},
  number       = {2},
  pages        = {93--100},
  year         = {2018},
  url          = {https://doi.org/10.1145/3166068},
  doi          = {10.1145/3166068},
}


@inproceedings{chu2023survey,
  author       = {Zheng Chu and
                  Jingchang Chen and
                  Qianglong Chen and
                  Weijiang Yu and
                  Tao He and
                  Haotian Wang and
                  Weihua Peng and
                  Ming Liu and
                  Bing Qin and
                  Ting Liu},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {Navigate through Enigmatic Labyrinth {A} Survey of Chain of Thought
                  Reasoning: {A}dvances, Frontiers and Future},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {1173--1203},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  doi          = {10.18653/V1/2024.ACL-LONG.65},
}

@article{Frohlich87,
 ISSN = {00925853, 15405907},
 abstract = {Experimental methods involving imperfect information are used to generate group choices of principles of distributive justice. Conditions approximating John Rawls's "original position" in A Theory of Justice serve as the starting point, and his conjectures are contrasted with those of John Harsanyi. Three "predictions" implicit in the Rawlsian argument are tested: (1) individuals choosing a principle of economic distribution would be able to reach unanimous agreement; (2) they would always choose the same principle; and (3) they would always choose to maximize the welfare of the worst-off individual. Our results indicate that individuals reach consensus, strongly reject the minimax principle, and largely choose what Rawls has called an "intuitionistic" principle. Overwhelmingly, the chosen principle is maximizing the average income with a floor constraint: a principle which is a compromise between those proposed by Rawls and Harsanyi. It takes into account not only the position of the worst-off individual but also the potential expected gain for the rest of society.},
 author = {Norman Frohlich and Joe A. Oppenheimer and Cheryl L. Eavey},
 journal = {American Journal of Political Science},
 number = {3},
 pages = {606--636},
 publisher = {[Midwest Political Science Association, Wiley]},
 title = {Choices of Principles of Distributive Justice in Experimental Groups},
 urldate = {2024-01-08},
 volume = {31},
 year = {1987}
}


@article{LeeWBAI19,
  author       = {Min Kyung Lee and
                  Daniel Kusbit and
                  Anson Kahng and
                  Ji Tae Kim and
                  Xinran Yuan and
                  Allissa Chan and
                  Daniel See and
                  Ritesh Noothigattu and
                  Siheon Lee and
                  Alexandros Psomas and
                  Ariel D. Procaccia},
  title        = {We{B}uild{AI}: Participatory Framework for Algorithmic Governance},
  journal      = {Proc. {ACM} Hum. Comput. Interact.},
  volume       = {3},
  number       = {{CSCW}},
  pages        = {181:1--181:35},
  year         = {2019},
  url          = {https://doi.org/10.1145/3359283},
  doi          = {10.1145/3359283},
  timestamp    = {Mon, 28 Aug 2023 21:21:42 +0200},
  biburl       = {https://dblp.org/rec/journals/pacmhci/LeeKKKYCSNLPP19.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{zhang2024llm,
  author       = {Yadong Zhang and
                  Shaoguang Mao and
                  Tao Ge and
                  Xun Wang and
                  Adrian de Wynter and
                  Yan Xia and
                  Wenshan Wu and
                  Ting Song and
                  Man Lan and
                  Furu Wei},
  title        = {{LLM} as a Mastermind: {A} Survey of Strategic Reasoning with Large
                  Language Models},
  journal      = {CoRR},
  volume       = {abs/2404.01230},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.01230},
  doi          = {10.48550/ARXIV.2404.01230},
  eprinttype    = {arXiv},
  eprint       = {2404.01230},
}

@article{Schnieder04,
author={Schneider,Gerald and Krämer,Ulrike S.},
year={2004},
month={08},
title={The Limitations of Fair Division: AN EXPERIMENTAL EVALUATION OF THREE PROCEDURES},
journal={The Journal of Conflict Resolution},
volume={48},
number={4},
pages={506-524},
note={Copyright - Copyright SAGE PUBLICATIONS, INC. Aug 2004; Document feature - tables; Last updated - 2023-11-27; CODEN - JCFRAL},
abstract={Mathematical procedures that promise an envy-free, equitable, and efficient solution to distributional conflicts have received widespread attention. Two fair-division mechanisms, adjusted Knaster and proportional Knaster, which are similar to the well-known adjusted-winner procedure, are compared with the less fair divide-and-choose mechanism. Results show that participants largely prefer the adjusted-Knaster procedure to the two alternatives. Adjusted Knaster, closely followed by proportional Knaster, also promises the highest average payoff. Yet the sophisticated mechanisms cease to perform better than divide-and-choose once actors receive the possibility to deviate from the mandatory bargaining protocols of fair-division procedures. The preference for adjusted and proportional Knaster is found to be a partial function of the participants' psychological profile. The more "antisocial" a participant, the more likely this respondent is to opt for a procedure with a compensatory mechanism. Publication Abstract]},
keywords={Political Science--International Relations; Fair division; Prioritization; Fair; Political science; Experiments; Contract negotiations; Conflict resolution; Bargaining; Expected utility; Game theory; Preferences; Protocol; Credibility; Efficiency; 9130:Experimental/theoretical; 1210:Politics & political behavior},
isbn={00220027},
language={English},
url={https://ezaccess.libraries.psu.edu/login?url=https://www-proquest-com.ezaccess.libraries.psu.edu/scholarly-journals/limitations-fair-division-experimental-evaluation/docview/224557997/se-2},
}

@techreport{CharnessLLM2023,
 title = "Generation Next: Experimentation with AI",
 author = "Charness, Gary and Jabarian, Brian and List, John A",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "31679",
 year = "2023",
 month = "September",
 doi = {10.3386/w31679},
 abstract = {We investigate the potential for Large Language Models (LLMs) to enhance scientific practice within experimentation by identifying key areas, directions, and implications. First, we discuss how these models can improve experimental design, including improving the elicitation wording, coding experiments, and producing documentation. Second, we delve into the use of LLMs in experiment implementation, with an emphasis on bolstering causal inference through creating consistent experiences, improving instruction comprehension, and real-time monitoring of participant engagement. Third, we underscore the role of LLMs in analyzing experimental data, encompassing tasks like pre-processing, data cleaning, and assisting reviewers and replicators in examining studies. Each of these tasks improves the probability of reporting accurate findings. Lastly, we suggest a scientific governance framework that mitigates the potential risks of using LLMs in experimental research while amplifying their advantages. This could pave the way for open science opportunities and foster a culture of policy and industry experimentation at scale.},
}

@article{mondorf2024beyond,
  author       = {Philipp Mondorf and
                  Barbara Plank},
  title        = {Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language
                  Models - {A} Survey},
  journal      = {CoRR},
  volume       = {abs/2404.01869},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2404.01869},
  doi          = {10.48550/ARXIV.2404.01869},
  eprinttype    = {arXiv},
  eprint       = {2404.01869},
}

@article{Yang2023Foundation,
  author       = {Sherry Yang and
                  Ofir Nachum and
                  Yilun Du and
                  Jason Wei and
                  Pieter Abbeel and
                  Dale Schuurmans},
  title        = {Foundation Models for Decision Making: Problems, Methods, and Opportunities},
  journal      = {CoRR},
  volume       = {abs/2303.04129},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.04129},
  doi          = {10.48550/ARXIV.2303.04129},
  eprinttype    = {arXiv},
  eprint       = {2303.04129},
}

@inproceedings{Liu2024Position,
  author       = {Xiaoqian Liu and
                  Xingzhou Lou and
                  Jianbin Jiao and
                  Junge Zhang},
  title        = {Position: Foundation Agents as the Paradigm Shift for Decision Making},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}


@inproceedings{Dziri2023Faith,
  author       = {Nouha Dziri and
                  Ximing Lu and
                  Melanie Sclar and
                  Xiang Lorraine Li and
                  Liwei Jiang and
                  Bill Yuchen Lin and
                  Sean Welleck and
                  Peter West and
                  Chandra Bhagavatula and
                  Ronan Le Bras and
                  Jena D. Hwang and
                  Soumya Sanyal and
                  Xiang Ren and
                  Allyson Ettinger and
                  Za{\"{\i}}d Harchaoui and
                  Yejin Choi},
  editor       = {Alice Oh and
                  Tristan Naumann and
                  Amir Globerson and
                  Kate Saenko and
                  Moritz Hardt and
                  Sergey Levine},
  title        = {Faith and Fate: Limits of Transformers on Compositionality},
  booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference
                  on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans,
                  LA, USA, December 10 - 16, 2023},
  year         = {2023},
}

@article{Dutting2024Optimal,
  author       = {Paul D{\"{u}}tting and
                  Zhe Feng and
                  Harikrishna Narasimhan and
                  David C. Parkes and
                  Sai Srivatsa Ravindranath},
  title        = {Optimal Auctions through Deep Learning: Advances in Differentiable
                  Economics},
  journal      = {J. {ACM}},
  volume       = {71},
  number       = {1},
  pages        = {5:1--5:53},
  year         = {2024},
  doi          = {10.1145/3630749},
}

@article{Sai2021Deep,
  author       = {Sai Srivatsa Ravindranath and
                  Zhe Feng and
                  Shira Li and
                  Jonathan Ma and
                  Scott Duke Kominers and
                  David C. Parkes},
  title        = {Deep Learning for Two-Sided Matching},
  journal      = {CoRR},
  volume       = {abs/2107.03427},
  year         = {2021},
  eprinttype    = {arXiv},
  eprint       = {2107.03427},
}

---------------------------------

@article{wang2024can,
  title={Can {LLM}s reason with rules? logic scaffolding for stress-testing and improving {LLM}s},
  author={Wang, Siyuan and Wei, Zhongyu and Choi, Yejin and Ren, Xiang},
  journal={arXiv preprint arXiv:2402.11442},
  year={2024}
}

@Inbook{Chakrabarty2016,
author="Chakrabarty, Deeparnab",
editor="Kao, Ming-Yang",
title="Max-Min Allocation",
bookTitle="Encyclopedia of Algorithms",
year="2016",
publisher="Springer New York",
address="New York, NY",
pages="1244--1247",
isbn="978-1-4939-2864-4",
doi="10.1007/978-1-4939-2864-4_539",
url="https://doi.org/10.1007/978-1-4939-2864-4_539"
}


@article{yim2024evaluating,
  title={Evaluating and enhancing {LLM}s agent based on theory of mind in guandan: A multi-player cooperative game under imperfect information},
  author={Yim, Yauwai and Chan, Chunkit and Shi, Tianyu and Deng, Zheye and Fan, Wei and Zheng, Tianshi and Song, Yangqiu},
  journal={arXiv preprint arXiv:2408.02559},
  year={2024}
}

@article{mirzadeh2024gsm,
  title={Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models},
  author={Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2410.05229},
  year={2024}
}

@article{fan2023nphardeval,
  title={Nphardeval: Dynamic benchmark on reasoning ability of large language models via complexity classes},
  author={Fan, Lizhou and Hua, Wenyue and Li, Lingyao and Ling, Haoyang and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2312.14890},
  year={2023}
}

@article{Khan_2024,
title={On the Capability of {LLM}s in Combinatorial Optimization},
DOI={10.36227/techrxiv.173092026.60478567/v1},
publisher={Institute of Electrical and Electronics Engineers (IEEE)},
author={Khan, Muhammad Asif and Hamad, Layth},
year={2024},
month=nov }

@inproceedings{LiRelationalReasoning,
author = {Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
title = {{LLM}s for Relational Reasoning: How Far are We?},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648387},
doi = {10.1145/3643795.3648387},
abstract = {Large language models ({LLM}s) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the {LLM}s. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the {LLM}s possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the {LLM}s are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art {LLM}s' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art {LLM}s are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting1.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {119–126},
numpages = {8},
keywords = {large language models, relational reasoning, program induction},
location = {Lisbon, Portugal},
series = {{LLM}4Code '24}
}

@article{mittal2024puzzlebench,
  title={PuzzleBench: Can {LLM}s Solve Challenging First-Order Combinatorial Reasoning Problems?},
  author={Mittal, Chinmay and Kartik, Krishna and Singla, Parag and others},
  journal={arXiv preprint arXiv:2402.02611},
  year={2024}
}

@article{
ChenRevealedPreference2023,
author = {Yiting Chen  and Tracy Xiao Liu  and You Shan  and Songfa Zhong },
title = {The emergence of economic rationality of {GPT}},
journal = {Proceedings of the National Academy of Sciences},
volume = {120},
number = {51},
pages = {e2316205120},
year = {2023},
doi = {10.1073/pnas.2316205120},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2316205120},
abstract = {It is increasingly important to examine the capacity of large language models like Generative Pre-trained Transformer model (GPT) beyond language processing. We instruct GPT to make risk, time, social, and food decisions and measure how rational these decisions are. We show that GPT’s decisions are mostly rational and even score higher than human decisions. The performance is affected by the way questions are framed, but not by settings of demographic information and randomness. Moreover, the estimated preference parameters of GPT, compared to those of human subjects, are slightly different and exhibit a substantially higher degree of homogeneity. Overall, these findings suggest that GPT could have the potential in assisting human decision-making, but more research is needed to fully assess their performance and underpinnings. As large language models ({LLM}s) like GPT become increasingly prevalent, it is essential that we assess their capabilities beyond language processing. This paper examines the economic rationality of GPT by instructing it to make budgetary decisions in four domains: risk, time, social, and food preferences. We measure economic rationality by assessing the consistency of GPT’s decisions with utility maximization in classic revealed preference theory. We find that GPT’s decisions are largely rational in each domain and demonstrate higher rationality score than those of human subjects in a parallel experiment and in the literature. Moreover, the estimated preference parameters of GPT are slightly different from human subjects and exhibit a lower degree of heterogeneity. We also find that the rationality scores are robust to the degree of randomness and demographic settings such as age and gender but are sensitive to contexts based on the language frames of the choice situations. These results suggest the potential of {LLM}s to make good decisions and the need to further understand their capabilities, limitations, and underlying mechanisms.}}

@article{hua2024game,
  title={Game-theoretic {LLM}: Agent Workflow for Negotiation Games},
  author={Hua, Wenyue and Liu, Ollie and Li, Lingyao and Amayuelas, Alfonso and Chen, Julie and Jiang, Lucas and Jin, Mingyu and Fan, Lizhou and Sun, Fei and Wang, William and others},
  journal={arXiv preprint arXiv:2411.05990},
  year={2024}
}

@article{gandhi2023strategic,
  title={Strategic reasoning with language models},
  author={Gandhi, Kanishk and Sadigh, Dorsa and Goodman, Noah D},
  journal={arXiv preprint arXiv:2305.19165},
  year={2023}
}

@article{Abdelnabi2023,
author = "Sahar Abdelnabi and Amr Gomaa and Sarath Sivaprasad and Lea Schönherr and Mario Fritz",
title = "{{LLM}-Deliberation: Evaluating {LLM}s with Interactive Multi-Agent Negotiation Games.}",
year = "2023",
month = "9",
url = "https://publications.cispa.de/articles/journal_contribution/{LLM}-Deliberation_Evaluating_{LLM}s_with_Interactive_Multi-Agent_Negotiation_Games_/25233028",
doi = "10.60882/cispa.25233028.v1"
}

@article{guo2024econnli,
  title={Econ{NLI}: Evaluating Large Language Models on Economics Reasoning},
  author={Guo, Yue and Yang, Yi},
  journal={arXiv preprint arXiv:2407.01212},
  year={2024}
}

@article{quan2024econlogicqa,
  title={EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning},
  author={Quan, Yinzhu and Liu, Zefang},
  journal={arXiv preprint arXiv:2405.07938},
  year={2024}
}

@article{chen2023put,
  title={Put your money where your mouth is: Evaluating strategic planning and execution of {LLM} agents in an auction arena},
  author={Chen, Jiangjie and Yuan, Siyu and Ye, Rong and Majumder, Bodhisattwa Prasad and Richardson, Kyle},
  journal={arXiv preprint arXiv:2310.05746},
  year={2023}
}

@article{fish2024algorithmic,
  title={Algorithmic Collusion by Large Language Models},
  author={Fish, Sara and Gonczarowski, Yannai A and Shorrer, Ran I},
  journal={arXiv preprint arXiv:2404.00806},
  year={2024}
}

@inproceedings{bianchi2024well,
  author       = {Federico Bianchi and
                  Patrick John Chia and
                  Mert Y{\"{u}}ksekg{\"{o}}n{\"{u}}l and
                  Jacopo Tagliabue and
                  Dan Jurafsky and
                  James Zou},
  title        = {How Well Can {LLMs} Negotiate? {N}egotiation{A}rena Platform and Analysis},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@article{scherrer2024evaluating,
  title={Evaluating the moral beliefs encoded in {LLM}s},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{ross2024LLM,
  author       = {Jillian Ross and
                  Yoon Kim and
                  Andrew W. Lo},
  title        = {{{LLM}} economicus? {M}apping the Behavioral Biases of {LLM}s via Utility
                  Theory},
  journal      = {CoRR},
  volume       = {abs/2408.02784},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2408.02784},
  doi          = {10.48550/ARXIV.2408.02784},
  eprinttype    = {arXiv},
  eprint       = {2408.02784},
  timestamp    = {Thu, 12 Sep 2024 21:06:49 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2408-02784.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Gaertner200,
author={Gaertner,Wulf and Jungeilges,Jochen},
year={2002},
month={01},
title={Evaluation via extended orderings: Empirical findings from Western and Eastern Europe},
journal={Social Choice and Welfare},
volume={19},
number={1},
pages={29-55},
note={Copyright - Copyright Springer-Verlag 2002; Last updated - 2023-11-25},
keywords={Social Services And Welfare; Economics; Students; Society; Utilitarianism},
isbn={01761714},
language={English},
url={https://ezaccess.libraries.psu.edu/login?url=https://www-proquest-com.ezaccess.libraries.psu.edu/scholarly-journals/evaluation-via-extended-orderings-empirical/docview/236413721/se-2},
}

@Inbook{Overlaet1991,
author="Overlaet, Bert
and Schokkaert, Erik",
editor="Steensma, Herman
and Vermunt, Ri{\"e}l",
title="Criteria for Distributive Justice in a Productive Context",
bookTitle="Social Justice in Human Relations: Societal and Psychological Consequences of Justice and Injustice",
year="1991",
publisher="Springer US",
address="Boston, MA",
pages="197--208",
abstract="In 1977, the Center for Community Psychology started a research program on the attitudes toward redistribution of income. In 1981, we presented an analysis and interpretation of questionnaire data of 180 subjects (Lagrou, Overlaet, {\&} Schokkaert, 1981). We questioned our subjects on how they perceived and evaluated the existing income distribution. In general, there appeared a strong tendency to redistribute incomes by reducing the span between high and low-income groups. The structure of the income distribution was left unchanged. These results were further elaborated into a formal mathematical model (Overlaet {\&} Lagrou, 1981; Schokkaert {\&} Lagrou, 1983).",
isbn="978-1-4899-2629-6",
doi="10.1007/978-1-4899-2629-6_10",
url="https://doi.org/10.1007/978-1-4899-2629-6_10"
}

@article{Gates2020,
author = {Gates, Vael and Griffiths, Thomas L. and Dragan, Anca D.},
title = {How to Be Helpful to Multiple People at Once},
journal = {Cognitive Science},
volume = {44},
number = {6},
pages = {e12841},
keywords = {Fairness, Preferences, Assistive artificial intelligence, Maximin, Modeling},
doi = {https://doi.org/10.1111/cogs.12841},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12841},
abstract = {Abstract When someone hosts a party, when governments choose an aid program, or when assistive robots decide what meal to serve to a family, decision-makers must determine how to help even when their recipients have very different preferences. Which combination of people’s desires should a decision-maker serve? To provide a potential answer, we turned to psychology: What do people think is best when multiple people have different utilities over options? We developed a quantitative model of what people consider desirable behavior, characterizing participants’ preferences by inferring which combination of “metrics” (maximax, maxsum, maximin, or inequality aversion [IA]) best explained participants’ decisions in a drink-choosing task. We found that participants’ behavior was best described by the maximin metric, describing the desire to maximize the happiness of the worst-off person, though participant behavior was also consistent with maximizing group utility (the maxsum metric) and the IA metric to a lesser extent. Participant behavior was consistent across variation in the agents involved and  tended to become more maxsum-oriented when participants were told they were players in the task (Experiment 1). In later experiments, participants maintained maximin behavior across multi-step tasks rather than shortsightedly focusing on the individual steps therein (Experiment 2, Experiment 3). By repeatedly asking participants what choices they would hope for in an optimal, just decision-maker, and carefully disambiguating which quantitative metrics describe these nuanced choices, we help constrain the space of what behavior we desire in leaders, artificial intelligence systems helping decision-makers, and the assistive robots and decision-makers of the future.},
year = {2020}
}

@inproceedings{dupuis2011simpler,
  title={The simpler, the better: A new challenge for fair-division theory},
  author={Dupuis-Roy, Nicolas and Gosselin, Fr{\'e}d{\'e}ric},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@article{cetre2019preferences,
title = {Preferences over income distribution: Evidence from a choice experiment},
journal = {Journal of Economic Psychology},
volume = {74},
pages = {102202},
year = {2019},
issn = {0167-4870},
doi = {https://doi.org/10.1016/j.joep.2019.102202},
url = {https://www.sciencedirect.com/science/article/pii/S0167487019301084},
author = {Sophie Cetre and Max Lobeck and Claudia Senik and Thierry Verdier},
keywords = {Distributive preferences, Inequality, Choice experiment, Luck versus Merit, Rawls},
}

@article{E&S04,
 ISSN = {00028282},
 abstract = {We present simple one-shot distribution experiments comparing the relative importance of efficiency concerns, maximin preferences, and inequality aversion, as well as the relative performance of the fairness theories by Gary E Bolton and Axel Ockenfels and by Ernst Fehr and Klaus M. Schmidt. While the Fehr-Schmidt theory performs better in a direct comparison, this appears to be due to being in line with maximin preferences. More importantly, we find that a combination of efficiency concerns, maximin preferences, and selfishness can rationalize most of the data while the Bolton-Ockenfels and Fehr-Schmidt theories are unable to explain important patterns.},
 author = {Dirk Engelmann and Martin Strobel},
 journal = {The American Economic Review},
 number = {4},
 pages = {857--869},
 publisher = {American Economic Association},
 title = {Inequality Aversion, Efficiency, and Maximin Preferences in Simple Distribution Experiments},
 urldate = {2023-09-25},
 volume = {94},
 year = {2004}
}

@article{KRITIKOS2001,
title = {Distributional concerns: equity- or efficiency-oriented?},
journal = {Economics Letters},
volume = {73},
number = {3},
pages = {333-338},
year = {2001},
issn = {0165-1765},
doi = {https://doi.org/10.1016/S0165-1765(01)00503-1},
url = {https://www.sciencedirect.com/science/article/pii/S0165176501005031},
author = {Alexander Kritikos and Friedel Bolle},
keywords = {Dictator game, Altruism, Reciprocity, Difference aversion, Efficiency},
abstract = {This paper provides experimental evidence that in binary-choice dictator games the majority of participants are efficiency rather than equity-oriented — even if their own payoff is reduced by the respective choice. Therefore, altruistic and — as a consequence — reciprocal motives need to be modelled explicitly if we aim to predict behavior in experiments correctly.}
}

@article{costarelli2024gamebench,
  title={Gamebench: Evaluating strategic reasoning abilities of {LLM} agents},
  author={Costarelli, Anthony and Allen, Mat and Hauksson, Roman and Sodunke, Grace and Hariharan, Suhas and Cheng, Carlson and Li, Wenjie and Clymer, Joshua and Yadav, Arjun},
  journal={arXiv preprint arXiv:2406.06613},
  year={2024}
}

@article{duan2024gtbench,
  title={Gtbench: Uncovering the strategic reasoning limitations of {LLM}s via game-theoretic evaluations},
  author={Duan, Jinhao and Zhang, Renming and Diffenderfer, James and Kailkhura, Bhavya and Sun, Lichao and Stengel-Eskin, Elias and Bansal, Mohit and Chen, Tianlong and Xu, Kaidi},
  journal={arXiv preprint arXiv:2402.12348},
  year={2024}
}

@article{goli2023can,
  title={Can {LLM}s Capture Human Preferences?},
  author={Goli, Ali and Singh, Amandeep},
  journal={arXiv preprint arXiv:2305.02531},
  year={2023}
}

@inproceedings{qiao-etal-2023-reasoning,
    title = "Reasoning with Language Model Prompting: A Survey",
    author = "Qiao, Shuofei  and
      Ou, Yixin  and
      Zhang, Ningyu  and
      Chen, Xiang  and
      Yao, Yunzhi  and
      Deng, Shumin  and
      Tan, Chuanqi  and
      Huang, Fei  and
      Chen, Huajun",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.acl-long.294",
    pages = "5368--5393",
    abstract = "Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at \url{https://github.com/zjunlp/Prompt4ReasoningPapers} (updated periodically).",
}

@misc{Anthropic_2024, title={Claude 3.5 Sonnet}, url={https://www.anthropic.com/news/claude-3-5-sonnet}, journal={Anthropic}, author={Anthropic}, year={2024}, month=jun, language={en} }

@article{berglund2023reversal,
  title={The reversal curse: {{LLM}} trained on" a is b" fail to learn" b is a"},
  author={Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain},
  journal={arXiv preprint arXiv:2309.12288},
  year={2023}
}

@article{he2024does,
  title={Does Prompt Formatting Have Any Impact on {{LLM}} Performance?},
  author={He, Jia and Rungta, Mukund and Koleczek, David and Sekhon, Arshdeep and Wang, Franklin X and Hasan, Sadid},
  journal={arXiv preprint arXiv:2411.10541},
  year={2024}
}

@article{voronov2024mind,
  title={Mind your format: Towards consistent evaluation of in-context learning improvements},
  author={Voronov, Anton and Wolf, Lena and Ryabinin, Max},
  journal={arXiv preprint arXiv:2401.06766},
  year={2024}
}

@article{errica2024did,
  title={What Did {I} Do Wrong? Quantifying {{LLM}s}' Sensitivity and Consistency to Prompt Engineering},
  author={Errica, Federico and Siracusano, Giuseppe and Sanvito, Davide and Bifulco, Roberto},
  journal={arXiv preprint arXiv:2406.12334},
  year={2024}
}

@inproceedings{sclar-etal-2023-minding,
    title = "Minding Language Models{'} (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker",
    author = "Sclar, Melanie  and
      Kumar, Sachin  and
      West, Peter  and
      Suhr, Alane  and
      Choi, Yejin  and
      Tsvetkov, Yulia",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.acl-long.780",
    pages = "13960--13980",
    abstract = "Theory of Mind (ToM){---}the ability to reason about the mental states of other people{---}is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity{'}s beliefs, their estimation of other entities{'} beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks{'} theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",
}

@article{lewis2024evaluating,
  title={Evaluating the Robustness of Analogical Reasoning in Large Language Models},
  author={Lewis, Martha and Mitchell, Melanie},
  journal={arXiv preprint arXiv:2411.14215},
  year={2024}
}

@article{charness2002understanding,
  title={Understanding social preferences with simple tests},
  author={Charness, Gary and Rabin, Matthew},
  journal={The quarterly journal of economics},
  volume={117},
  number={3},
  pages={817--869},
  year={2002},
  publisher={MIT Press}
}

@article{engelmann2004inequality,
  title={Inequality aversion, efficiency, and maximin preferences in simple distribution experiments},
  author={Engelmann, Dirk and Strobel, Martin},
  journal={American economic review},
  volume={94},
  number={4},
  pages={857--869},
  year={2004},
  publisher={American Economic Association}
}

@article{gates2020helpful,
author = {Gates, Vael and Griffiths, Thomas L. and Dragan, Anca D.},
title = {How to Be Helpful to Multiple People at Once},
journal = {Cognitive Science},
volume = {44},
number = {6},
pages = {e12841},
keywords = {Fairness, Preferences, Assistive artificial intelligence, Maximin, Modeling},
doi = {https://doi.org/10.1111/cogs.12841},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12841},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12841},
year = {2020}
}

@article{argyle2023out,
  title={Out of one, many: Using language models to simulate human samples},
  author={Argyle, Lisa P and Busby, Ethan C and Fulda, Nancy and Gubler, Joshua R and Rytting, Christopher and Wingate, David},
  journal={Political Analysis},
  volume={31},
  number={3},
  pages={337--351},
  year={2023},
  publisher={Cambridge University Press}
}

@article{akata2023playing,
  title={Playing repeated games with large language models},
  author={Akata, Elif and Schulz, Lion and Coda-Forno, Julian and Oh, Seong Joon and Bethge, Matthias and Schulz, Eric},
  journal={arXiv preprint arXiv:2305.16867},
  year={2023}
}

@article{li2023metaagents,
  title={Metaagents: Simulating interactions of human behaviors for {{LLM}}-based task-oriented coordination via collaborative generative agents},
  author={Li, Yuan and Zhang, Yixuan and Sun, Lichao},
  journal={arXiv preprint arXiv:2310.06500},
  year={2023}
}

@article{leng2024can,
  title={Can {{LLM}}s Mimic Human-Like Mental Accounting and Behavioral Biases?},
  author={Leng, Yan},
  journal={Available at SSRN 4705130},
  year={2024}
}

@article{fan2023can,
  title={Can large language models serve as rational players in game theory? {A} systematic analysis},
  author={Fan, Caoyun and Chen, Jindou and Jin, Yaohui and He, Hao},
  journal={arXiv preprint arXiv:2312.05488},
  year={2023}
}

@article{
ChenEcon,
author = {Yiting Chen  and Tracy Xiao Liu  and You Shan  and Songfa Zhong },
title = {The emergence of economic rationality of GPT},
journal = {Proceedings of the National Academy of Sciences},
volume = {120},
number = {51},
pages = {e2316205120},
year = {2023},
doi = {10.1073/pnas.2316205120},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2316205120}
}

@article{leng2023llm,
  title={Do {{LLM}} Agents Exhibit Social Behavior?},
  author={Leng, Yan and Yuan, Yuan},
  journal={arXiv preprint arXiv:2312.15198},
  year={2023}
}

@techreport{horton2023large,
  title={Large language models as simulated economic agents: What can we learn from homo silicus?},
  author={Horton, John J},
  year={2023},
  institution={National Bureau of Economic Research}
}

@article{Pratt90,
 ISSN = {00251909, 15265501},
 URL = {http://www.jstor.org/stable/2632606},
 abstract = {This paper presents a general model for aggregating votes from a preferential ballot. The thrust of the model is to accord each candidate a fair assessment in terms of his overall standing vis-a-vis first place, second place,..., kth place votes. The form of the model is a combined index $\sum_{j=1}^{k}\ W_{j}v_{ij}$ where vij is the number of the jth place votes received by the ith candidate. The weights Wj are assumed to form a monotonically decreasing sequence with Wj — Wj+1 ≥ d(j, ε). These constraints correspond to the assurance region (AR) side constraints in the DEA framework. The properties of the model are examined in terms of this discrimination intensity function d, and in the special case that d(j, ε) = ε, our model is shown to be equivalent to the consensus models of Borda and Kendall.},
 author = {John Winsor Pratt and Richard Jay Zeckhauser},
 journal = {Management Science},
 number = {11},
 pages = {1293--1301},
 publisher = {INFORMS},
 title = {The Fair and Efficient Division of the Winsor Family Silver},
 urldate = {2024-01-15},
 volume = {36},
 year = {1990}
}

@inproceedings{LeeFR17,
author = {Lee, Min Kyung and Kim, Ji Tae and Lizarondo, Leah},
title = {A Human-Centered Approach to Algorithmic Services: Considerations for Fair and Motivating Smart Community Service Management That Allocates Donations to Non-Profit Organizations},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025884},
doi = {10.1145/3025453.3025884},
abstract = {Algorithms are increasingly being incorporated into diverse services that orchestrate multiple stakeholders' needs and interests. How can we design these algorithmic services to make decisions that are not only efficient, but also fair and motivating? We take a human-centered approach to identify and address challenges in building human-centered algorithmic services. We are in the process of building an allocation algorithm for 412 Food Rescue, an organization that matches food donations with non-profit organizations. As part of this ongoing project, we conducted interviews with multiple stakeholders in the service-organization staff, donors, volunteers, recipient non-profits and their clients, and everyday citizens-in order to understand how the allocation algorithm, interfaces, and surrounding work practices should be designed. The findings suggest that we need to understand and account for varying fairness notions held by stakeholders; consider people, contexts, and interfaces for algorithms to work fairly in the real world; and preserve meaningfulness and social interaction in automation in order to build fair and motivating algorithmic services.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {3365–3376},
numpages = {12},
keywords = {donation, allocation, service design, automation, community service, fairness, algorithmic services, motivation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@TechReport{BramsSpratly,
  author={Brams, Steven J. and Denoon, David},
  title={{Fair Division: A New Approach to the Spratly Islands Controversy}},
  year=1996,
  institution={C.V. Starr Center for Applied Economics, New York University},
  type={Working Papers},
  url={https://ideas.repec.org/p/cvs/starer/96-10.html},
  number={96-10},
  abstract={No abstract is available for this item.},
  keywords={Fair division; bargaining; envy-freeness; Spratly Islands},
  doi={},
}

@article{BramsDavid,
 ISSN = {07388942, 15499219},
 URL = {http://www.jstor.org/stable/26273187},
 abstract = {The agreement between Egypt and Israel at Camp David in 1978 is used to illustrate how a fair-division procedure called Adjusted Winner (AW), in which two sides allocate 100 points over the issues that divide them, could have been used to reach a settlement. AW satisfies the properties of envy-freeness (each side is ensured of receiving at least 50 of its points and hence does not envy the other side), equitability (each side receives the same number of points over 50), and efficiency (there is no other settlement better for both players). While the actual agreement at Camp David seems to reflect quite well what AW would have yielded on the six issues that divided the two sides, this agreement probably could have been achieved more expeditiously, and in a less crisis-driven atmosphere, if AW had been used.},
 author = {Steven J. Brams and Jeffrey M. Togman},
 journal = {Conflict Management and Peace Science},
 number = {1},
 pages = {99--112},
 publisher = {Sage Publications, Ltd.},
 title = {CAMP DAVID: WAS THE AGREEMENT FAIR?},
 urldate = {2024-02-07},
 volume = {15},
 year = {1996}
}

@article{Massoud02,
 ISSN = {00220027, 15528766},
 URL = {http://www.jstor.org/stable/174630},
 abstract = {A dispute resolution mechanism called Adjusted Winner (AW), developed by Brams and Taylor, is used to propose a plausible solution to the final status issues between Israel and the Palestinians. Unlike conventional negotiating procedures, AW possesses desirable qualities including equitability, efficiency, and envy freeness. Based on data from an original survey, results show that when the issues of security and borders are kept separate, Israel is likely to have its demands met on the issues of security, East Jerusalem, normalization of relations, and water. The Palestinians will win on the issues of sovereignty, Israeli settlements in the West Bank, Israeli settlements in Gaza, and Palestinian refugees. Both sides will need to compromise on the issue of boundaries. If security and borders are lumped together as one issue, Israel and the Palestinians will share on the issue of East Jerusalem.},
 author = {Tansa George Massoud},
 journal = {The Journal of Conflict Resolution},
 number = {3},
 pages = {333--358},
 publisher = {Sage Publications, Inc.},
 title = {Fair Division, Adjusted Winner Procedure (AW), and the Israeli-Palestinian Conflict},
 urldate = {2024-02-02},
 volume = {44},
 year = {2000}
}

@phdthesis{DF67,
    author = {Foley, Duncan K.},
    year={1966},
    title={Resource Allocation and the Public Sector},
    journal={ProQuest Dissertations and Theses},
    pages={90},
    note={Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Last updated - 2023-02-18},
    keywords={Social sciences; Economic theory; 0511:Economic theory},
    isbn={9798657998818},
    language={English},
    url={https://ezaccess.libraries.psu.edu/login?url=https://www.proquest.com/dissertations-theses/resource-allocation-public-sector/docview/302230213/se-2},
}

@article{H&P07,
title = {Distributing Indivisible Goods Fairly: Evidence from a Questionnaire Study},
author = {Dorothea Herreiner and Clemens Puppe},
pages = {235--258},
volume = {29},
number = {2},
journal = {Analyse \& Kritik},
doi = {doi:10.1515/auk-2007-0208},
year = {2007},
lastchecked = {2023-09-25}
}

@article{SteinhausProp49,
 ISSN = {00129682, 14680262},
 author = {H. Steinhaus},
 journal = {Econometrica},
 pages = {315--319},
 publisher = {[Wiley, Econometric Society]},
 title = {Sur la division pragmatique},
 urldate = {2023-10-15},
 volume = {17},
 year = {1949}
}

@book{RawlsTOJ,
 ISBN = {9780674880108},
 abstract = {
John Rawls aims to express an essential part of the common core
of the democratic tradition-justice as fairness-and to provide an
alternative to utilitarianism, which had dominated the Anglo-Saxon
tradition of political thought since the nineteenth century. Rawls
substitutes the ideal of the social contract as a more satisfactory
account of the basic rights and liberties of citizens as free and
equal persons. "Each person," writes Rawls, "possesses an
inviolability founded on justice that even the welfare of society
as a whole cannot override." Advancing the ideas of Rousseau, Kant,
Emerson, and Lincoln, Rawls's theory is as powerful today as it was
when first published. Though the revised edition of A Theory of
Justice, published in 1999, is the definitive statement of
Rawls's view, much of the extensive literature on his theory refers
to the original. This first edition is available for scholars and
serious students of Rawls's work.
},
 author = {John Rawls},
 publisher = {Harvard University Press},
 title = {A Theory of Justice: Original Edition},
 urldate = {2023-11-17},
 year = {1971}
}

@inproceedings{Amanatidis22,
  title     = {Fair Division of Indivisible Goods: A  Survey},
  author    = {Amanatidis, Georgios and Birmpas, Georgios and Filos-Ratsikas, Aris and Voudouris, Alexandros A.},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {5385--5393},
  year      = {2022},
  month     = {7},
  note      = {Survey Track},
  doi       = {10.24963/ijcai.2022/756},
  url       = {https://doi.org/10.24963/ijcai.2022/756},
}

@article{KONOW1996,
title = {A positive theory of economic fairness},
journal = {Journal of Economic Behavior & Organization},
volume = {31},
number = {1},
pages = {13-35},
year = {1996},
issn = {0167-2681},
doi = {https://doi.org/10.1016/S0167-2681(96)00862-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167268196008621},
author = {James Konow},
keywords = {Distributive justice, Equity, Fairness},
abstract = {This paper presents a positive theory of economic fairness which strives for generality by characterizing the fairness values which people share across differing contexts. The study attempts to isolate these underlying values from the more situation-specific perceptual effects (e.g., framing effects) which may have an impact on reported fairness. Central to the proposed theory is the Accountability Principle which, roughly speaking, requires that a person's fair allocation (e.g., of income) vary in proportion to the relevant variables which he can influence (e.g., work effort), but not according to those which he cannot reasonably influence (e.g., a physical handicap). The results of telephone interviews and written questionnaires are presented in support of the theory.}
}

@article{C&R02,
 ISSN = {00335533, 15314650},
 abstract = {Departures from self-interest in economic experiments have recently inspired model s of "social preferences." We design a range of simple experimental games that test these theories more directly than existing experiments. Our experiments show that subjects are more concerned with increasing social welfare-sacrificing to increase the payoffs for all recipients, especially low-payoff recipients-than with reducing differences in payoffs (as supposed in recent models). Subjects are also motivated by reciprocity: they withdraw willingness to sacrifice to achieve a fair outcome when others are themselves unwilling to sacrifice, and sometimes punish unfair behavior.},
 author = {Gary Charness and Matthew Rabin},
 journal = {The Quarterly Journal of Economics},
 number = {3},
 pages = {817--869},
 publisher = {Oxford University Press},
 title = {Understanding Social Preferences with Simple Tests},
 urldate = {2023-09-25},
 volume = {117},
 year = {2002}
}

@article{KKT86,
 ISSN = {00028282},
 URL = {http://www.jstor.org/stable/1806070},
 abstract = {Community standards of fairness for the setting of prices and wages were elicited by telephone surveys. In customer or labor markets, it is acceptable for a firm to raise prices (or cut wages) when profits are threatened and to maintain prices when costs diminish. It is unfair to exploit shifts in demand by raising prices or cutting wages. Several market anomalies are explained by assuming that these standards of fairness influence the behavior of firms.},
 author = {Daniel Kahneman and Jack L. Knetsch and Richard Thaler},
 journal = {The American Economic Review},
 number = {4},
 pages = {728--741},
 publisher = {American Economic Association},
 title = {Fairness as a Constraint on Profit Seeking: Entitlements in the Market},
 urldate = {2023-11-25},
 volume = {76},
 year = {1986}
}

@article{Konow03,
 ISSN = {00220515},
 URL = {http://www.jstor.org/stable/3217459},
 author = {James Konow},
 journal = {Journal of Economic Literature},
 number = {4},
 pages = {1188--1239},
 publisher = {American Economic Association},
 title = {Which Is the Fairest One of All? A Positive Analysis of Justice Theories},
 urldate = {2023-09-25},
 volume = {41},
 year = {2003}
}

@article{KYROPOULOU202228,
title = {Fair cake-cutting in practice},
journal = {Games and Economic Behavior},
volume = {133},
pages = {28-49},
year = {2022},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2022.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0899825622000331},
author = {Maria Kyropoulou and Josué Ortega and Erel Segal-Halevi},
keywords = {Cake-cutting, Selfridge-Conway, Cut-and-choose, Envy, Fairness, Preference manipulation, Experimentation and learning},
abstract = {Using two lab experiments, we investigate the real-life performance of envy-free and proportional cake-cutting procedures with respect to fairness and preference manipulation. Although the observed subjects' strategic behavior eliminates the fairness guarantees of envy-free procedures, we nonetheless find evidence that suggests that envy-free procedures are fairer than their proportional counterparts. Our results support the practical use of the celebrated Selfridge-Conway procedure, and more generally, of envy-free cake-cutting mechanisms. We also find that subjects learn their opponents' preferences after repeated interaction and use this knowledge to improve their allocated share of the cake. Learning increases strategic behavior, but also reduces envy.}
}


@article{HP10,
title = {Inequality aversion and efficiency with ordinal and cardinal social preferences—{A}n experimental study},
journal = {Journal of Economic Behavior \& Organization},
volume = {76},
number = {2},
pages = {238-253},
year = {2010},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2010.06.002},
author = {Dorothea Herreiner and Clemens Puppe}
}

@book{BlandfordHCI,
author = {Blandford, Ann and Furniss, Dominic and Makri, Stephann},
title = {Qualitative Hci Research: Going Behind the Scenes},
year = {2016},
isbn = {1627057595},
publisher = {Morgan \& Claypool Publishers},
abstract = {HCI addresses problems of interaction design: evaluating existing designs, delivering novel designs, and understanding user needs for future designs. Qualitative methods have an essential role to play in this enterprise, particularly in understanding user needs and behaviors and evaluating situated use of technology. In this lecture, we draw on the analogy of making a documentary film: historically, the film was presented as a finished product, giving the viewer little insight into the production process; more recently, there has been a trend to go 'behind the scenes' to expose some of the painstaking work that went into creating the raw footage behind the film; but still much essential work remains hidden. Similarly, in qualitative research, the essential work 'behind the scenes' is rarely discussed. There are many "how to" guides for particular methods, but few texts that discuss the important details of how to select a suitable method, how to adapt it to fit the study context, or how to deal with unexpected challenges that arise. We address this gap by presenting a repertoire of techniques for understanding user needs, practices and experiences with technology, including practical considerations such as tactics for recruiting participants when aiming for a particular sampling strategy, and ways of getting started when faced with a pile of interview transcripts. We present illustrative case studies drawn from prior experience. Our particular focus is on semi-structured qualitative studies, which occupy a space between ethnography and surveys, typically involving observations, interviews and similar methods for data gathering, and methods for analysis based on systematic coding of data. Just as a documentary team faces challenges that often go unreported when arranging expeditions or interviews, gathering footage or editing the story, within time and budget pressures, so the qualitative research team faces challenge in obtaining ethic}
}


@article{TracyBigTent,
author = {Sarah J. Tracy},
title ={Qualitative Quality: Eight “Big-Tent” Criteria for Excellent Qualitative Research},
journal = {Qualitative Inquiry},
volume = {16},
number = {10},
pages = {837-851},
year = {2010},
doi = {10.1177/1077800410383121},
URL = {    
        https://doi.org/10.1177/1077800410383121
},
eprint = {   
        https://doi.org/10.1177/1077800410383121
},
    abstract = { This article presents a model for quality in qualitative research that is uniquely expansive, yet flexible, in that it makes distinctions among qualitative research’s means (methods and practices) and its ends. The article first provides a contextualization and rationale for the conceptualization. Then the author presents and explores eight key markers of quality in qualitative research including (a) worthy topic, (b) rich rigor, (c) sincerity, (d) credibility, (e) resonance, (f) significant contribution, (g) ethics, and (h) meaningful coherence. This eight-point conceptualization offers a useful pedagogical model and provides a common language of qualitative best practices that can be recognized as integral by a variety of audiences. While making a case for these markers of quality, the article leaves space for dialogue, imagination, growth, and improvisation. }
}

@book{Crotty1998,
    author = {Michael Crotty},
    title = {The Foundations of Social Research: Meaning and Perspective in the Research Process},
    publisher = {Sage Publications},
    year = {1998}
}

@article{barter1999use,
  title={The use of vignettes in qualitative research},
  author={Barter, Christine and Renold, Emma},
  journal={Social research update},
  volume={25},
  number={9},
  pages={1--6},
  year={1999}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{SaldanaQC,
    author = {Johnny M. Saldana},
    title = {The Coding Manual for Qualitative Researchers},
    journal = {SAGE Publications},
    year = {2015}
}

@article{
MeiTuring24,
author = {Qiaozhu Mei  and Yutong Xie  and Walter Yuan  and Matthew O. Jackson },
title = {A {T}uring test of whether {AI} chatbots are behaviorally similar to humans},
journal = {Proceedings of the National Academy of Sciences},
volume = {121},
number = {9},
pages = {e2313925121},
year = {2024},
doi = {10.1073/pnas.2313925121},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2313925121},
abstract = {We administer a Turing test to AI chatbots. We examine how chatbots behave in a suite of classic behavioral games that are designed to elicit characteristics such as trust, fairness, risk-aversion, cooperation, etc., as well as how they respond to a traditional Big-5 psychological survey that measures personality traits. ChatGPT-4 exhibits behavioral and personality traits that are statistically indistinguishable from a random human from tens of thousands of human subjects from more than 50 countries. Chatbots also modify their behavior based on previous experience and contexts “as if” they were learning from the interactions and change their behavior in response to different framings of the same strategic situation. Their behaviors are often distinct from average and modal human behaviors, in which case they tend to behave on the more altruistic and cooperative end of the distribution. We estimate that they act as if they are maximizing an average of their own and partner’s payoffs.}}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wu2023autogen,
      title={AutoGen: Enabling Next-Gen {{LLM}} Applications via Multi-Agent Conversation Framework},
      author={Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Shaokun Zhang and Erkang Zhu and Beibin Li and Li Jiang and Xiaoyun Zhang and Chi Wang},
      year={2023},
      eprint={2308.08155},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{DubinsEQ,
 ISSN = {00029890, 19300972},
 author = {L. E. Dubins and E. H. Spanier},
 journal = {The American Mathematical Monthly},
 number = {1},
 pages = {1--17},
 publisher = {Mathematical Association of America},
 title = {How to Cut A Cake Fairly},
 urldate = {2023-12-21},
 volume = {68},
 year = {1961}
}

@article{Budish11,
 ISSN = {00223808, 1537534X},
 URL = {http://www.jstor.org/stable/10.1086/664613},
 abstract = {This paper proposes a new mechanism for combinatorial assignment—for example, assigning schedules of courses to students—based on an approximation to competitive equilibrium from equal incomes (CEEI) in which incomes are unequal but arbitrarily close together. The main technical result is an existence theorem for approximate CEEI. The mechanism is approximately efficient, satisfies two new criteria of outcome fairness, and is strategyproof in large markets. Its performance is explored on real data, and it is compared to alternatives from theory and practice: all other known mechanisms are either unfair ex post or manipulable even in large markets, and most are both manipulable and unfair.},
 author = {Eric Budish},
 journal = {Journal of Political Economy},
 number = {6},
 pages = {1061--1103},
 publisher = {The University of Chicago Press},
 title = {The Combinatorial Assignment Problem: Approximate Competitive Equilibrium from Equal Incomes},
 urldate = {2023-09-25},
 volume = {119},
 year = {2011}
}


@inproceedings{Lipton04,
author = {Lipton, R. J. and Markakis, E. and Mossel, E. and Saberi, A.},
title = {On Approximately Fair Allocations of Indivisible Goods},
year = {2004},
isbn = {1581137710},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/988772.988792},
doi = {10.1145/988772.988792},
abstract = {We study the problem of fairly allocating a set of indivisible goods to a set of people from an algorithmic perspective. fair division has been a central topic in the economic literature and several concepts of fairness have been suggested. The criterion that we focus on is envy-freeness. In our model, a monotone utility function is associated with every player specifying the value of each subset of the goods for the player. An allocation is envy-free if every player prefers her own share than the share of any other player. When the goods are divisible, envy-free allocations always exist. In the presence of indivisibilities, we show that there exist allocations in which the envy is bounded by the maximum marginal utility, and present a simple algorithm for computing such allocations. We then look at the optimization problem of finding an allocation with minimum possible envy. In the general case the problem is not solvable or approximable in polynomial time unless P = NP. We consider natural special cases (e.g.additive utilities) which are closely related to a class of job scheduling problems. Approximation algorithms as well as inapproximability results are obtained. Finally we investigate the problem of designing truthful mechanisms for producing allocations with bounded envy.},
booktitle = {Proceedings of the 5th ACM Conference on Electronic Commerce},
pages = {125–131},
numpages = {7},
keywords = {envy, fairness, truthfulness, approximation algorithm},
location = {New York, NY, USA},
series = {EC '04}
}

@article{Carag19,
author = {Caragiannis, Ioannis and Kurokawa, David and Moulin, Herv\'{e} and Procaccia, Ariel D. and Shah, Nisarg and Wang, Junxing},
title = {The Unreasonable Fairness of Maximum Nash Welfare},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {2167-8375},
url = {https://doi.org/10.1145/3355902},
doi = {10.1145/3355902},
abstract = {The maximum Nash welfare (MNW) solution—which selects an allocation that maximizes the product of utilities—is known to provide outstanding fairness guarantees when allocating divisible goods. And while it seems to lose its luster when applied to indivisible goods, we show that, in fact, the MNW solution is strikingly fair even in that setting. In particular, we prove that it selects allocations that are envy-free up to one good—a compelling notion that is quite elusive when coupled with economic efficiency. We also establish that the MNW solution provides a good approximation to another popular (yet possibly infeasible) fairness property, the maximin share guarantee, in theory and—even more so—in practice. While finding the MNW solution is computationally hard, we develop a nontrivial implementation and demonstrate that it scales well on real data. These results establish MNW as a compelling solution for allocating indivisible goods and underlie its deployment on a popular fair-division website.},
journal = {ACM Trans. Econ. Comput.},
month = {sep},
articleno = {12},
numpages = {32},
keywords = {resource allocation, Nash welfare, Fair division}
}

%% 3
@article{F&S00,
 ISSN = {00335533, 15314650},
 abstract = {There is strong evidence that people exploit their bargaining power in competitive markets but not in bilateral bargaining situations. There is also strong evidence that people exploit free-riding opportunities in voluntary cooperation games. Yet, when they are given the opportunity to punish free riders, stable cooperation is maintained, although punishment is costly for those who punish. This paper asks whether there is a simple common principle that can explain this puzzling evidence. We show that if some people care about equity the puzzles can be resolved. It turns out that the economic environment determines whether the fair types or the selfish types dominate equilibrium behavior.},
 author = {Ernst Fehr and Klaus M. Schmidt},
 journal = {The Quarterly Journal of Economics},
 number = {3},
 pages = {817--868},
 publisher = {Oxford University Press},
 title = {A Theory of Fairness, Competition, and Cooperation},
 urldate = {2023-09-25},
 volume = {114},
 year = {1999}
}


%% 4
@article{B&O00,
 ISSN = {00028282},
 abstract = {We demonstrate that a simple model, constructed on the premise that people are motivated by both their pecuniary payoff and their relative payoff standing, organizes a large and seemingly disparate set of laboratory observations as one consistent pattern. The model is incomplete information but nevertheless posed entirely in terms of directly observable variables. The model explains observations from games where equity is thought to be a factor, such as ultimatum and dictator, games where reciprocity is thought to play a role, such as the prisoner's dilemma and gift exchange, and games where competitive behavior is observed, such as Bertrand markets.},
 author = {Gary E Bolton and Axel Ockenfels},
 journal = {The American Economic Review},
 number = {1},
 pages = {166--193},
 publisher = {American Economic Association},
 title = {{ERC}: {A} Theory of Equity, Reciprocity, and Competition},
 urldate = {2023-09-25},
 volume = {90},
 year = {2000}
}

@article{caragiannis2019unreasonable,
  title={The unreasonable fairness of maximum Nash welfare},
  author={Caragiannis, Ioannis and Kurokawa, David and Moulin, Herv{\'e} and Procaccia, Ariel D and Shah, Nisarg and Wang, Junxing},
  journal={ACM Transactions on Economics and Computation (TEAC)},
  volume={7},
  number={3},
  pages={1--32},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{wang2022self,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
    year = {2022},
  booktitle={The Eleventh International Conference on Learning Representations}
}

@article{Murphy84,
author={Murphy-Berman,Viginia and Berman,John J. and Singh,Purnima and Pachauri,Anju and Kumar,Pramod},
year={1984},
month={06},
title={Factors affecting allocation to needy and meritorious recipients: A cross-cultural comparison},
journal={Journal of personality and social psychology},
volume={46},
pages={1267-1272},
abstract={Examined the effect of culture (India vs the US), sex of allocator, sex of allocation target, the positive or negative value of the allocation, and the short- or long-term impact of the allocation decision on respondents' distribution of money to a hypothetical recipient. 53 Indian male, 44 Indian female, 40 US male, and 44 US female undergraduates served as Ss. Results reveal that Indian Ss distributed more on the basis of need and less on the basis of merit or equality than did the Americans. Also, the Indian males and the American males and females distributed more to the needy recipient and less to the meritorious recipient when money cutbacks rather than rewards were involved. Indian females, on the other hand, gave most to the needy in all cases. Findings support the idea that perceptions of fairness are culturally relative and bound to specific socialization practices and societal norms. (18 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
keywords={sex of allocator & allocation target & positive vs negative value of allocation & short vs long term impact of decision, distribution of money to needy vs meritorious recipients, college students, India vs US; Psychology; Empirical Study; Human; Adulthood (18 yrs & older); Equity (Payment); Cross Cultural Differences; Human Sex Differences; US; article; India; 3040:Social Perception & Cognition},
isbn={0022-3514, 0022-3514},
language={English},
}

@article{freeman2019equitable,
  title={Equitable allocations of indivisible goods},
  author={Freeman, Rupert and Sikdar, Sujoy and Vaish, Rohit and Xia, Lirong},
  journal={arXiv preprint arXiv:1905.10656},
  year={2019}
}

@article{Hosseini2022Hide,
  author       = {Hadi Hosseini and
                  Joshua Kavner and
                  Sujoy Sikdar and
                  Rohit Vaish and
                  Lirong Xia},
  title        = {Hide, Not Seek: Perceived Fairness in Envy-Free Allocations of Indivisible
                  Goods},
  journal      = {CoRR},
  volume       = {abs/2212.04574},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2212.04574},
  doi          = {10.48550/ARXIV.2212.04574},
  eprinttype    = {arXiv},
  eprint       = {2212.04574},
  timestamp    = {Mon, 05 Feb 2024 20:18:17 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2212-04574.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@techreport{Charness{LLM}2023,
 title = "Generation Next: Experimentation with {AI}",
 author = "Charness, Gary and Jabarian, Brian and List, John A",
 institution = "National Bureau of Economic Research",
 type = "Working Paper",
 series = "Working Paper Series",
 number = "31679",
 year = "2023",
 month = "September",
 doi = {10.3386/w31679},
 URL = "http://www.nber.org/papers/w31679"
}

@inproceedings{ren-etal-2024-valuebench,
    title = "{V}alue{B}ench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models",
    author = "Ren, Yuanyi  and
      Ye, Haoran  and
      Fang, Hanjun  and
      Zhang, Xin  and
      Song, Guojie",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.111/",
    doi = "10.18653/v1/2024.acl-long.111",
    pages = "2015--2040"
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{Chang2024Survey,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
doi = {10.1145/3641289},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@article{hadi2023survey,
  title={A survey on large language models: Applications, challenges, limitations, and practical usage},
  author={Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal={Authorea Preprints},
  year={2023},
  publisher={Authorea}
}

@article{Spliddit,
author = {Goldman, Jonathan and Procaccia, Ariel D.},
title = {Spliddit: Unleashing Fair Division Algorithms},
year = {2015},
issue_date = {December 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
url = {https://doi.org/10.1145/2728732.2728738},
doi = {10.1145/2728732.2728738},
abstract = {Spliddit is a first-of-its-kind fair division website, which offers provably fair solutions for the division of rent, goods, and credit. In this note, we discuss Spliddit's goals, methods, and implementation.},
journal = {SIGecom Exch.},
month = {jan},
pages = {41–46},
numpages = {6},
keywords = {fair division}
}

@article{belrose2023eliciting,
  title={Eliciting latent predictions from transformers with the tuned lens},
  author={Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2303.08112},
  year={2023}
}

@inproceedings{halawioverthinking,
  title={Overthinking the Truth: Understanding how Language Models Process False Demonstrations},
  author={Halawi, Danny and Denain, Jean-Stanislas and Steinhardt, Jacob},
    year = {2024},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@article{CasariSelection07,
Author = {Casari, Marco and Ham, John C. and Kagel, John H.},
Title = {Selection Bias, Demographic Effects, and Ability Effects in Common Value Auction Experiments},
Journal = {American Economic Review},
Volume = {97},
Number = {4},
Year = {2007},
Month = {September},
Pages = {1278–1304},
DOI = {10.1257/aer.97.4.1278}}

@article{Levitt07,
 ISSN = {08953309},
 author = {Steven D. Levitt and John A. List},
 journal = {The Journal of Economic Perspectives},
 number = {2},
 pages = {153--174},
 publisher = {American Economic Association},
 title = {What Do Laboratory Experiments Measuring Social Preferences Reveal about the Real World?},
 urldate = {2025-01-07},
 volume = {21},
 year = {2007}
}


@article{zhang2024negative,
  title={Negative preference optimization: From catastrophic collapse to effective unlearning},
  author={Zhang, Ruiqi and Lin, Licong and Bai, Yu and Mei, Song},
  journal={arXiv preprint arXiv:2404.05868},
  year={2024}
}

@article{setlur2024rl,
  title={{RL} on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold},
  author={Setlur, Amrith and Garg, Saurabh and Geng, Xinyang and Garg, Naman and Smith, Virginia and Kumar, Aviral},
  journal={arXiv preprint arXiv:2406.14532},
  year={2024}
}

@article{burnell2023rethink,
  title={Rethink reporting of evaluation results in {AI}},
  author={Burnell, Ryan and Schellaert, Wout and Burden, John and Ullman, Tomer D and Martinez-Plumed, Fernando and Tenenbaum, Joshua B and Rutar, Danaja and Cheke, Lucy G and Sohl-Dickstein, Jascha and Mitchell, Melanie and others},
  journal={Science},
  volume={380},
  number={6641},
  pages={136--138},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@article{ge2024axioms,
  title={Axioms for AI Alignment from Human Feedback},
  author={Ge, Luise and Halpern, Daniel and Micha, Evi and Procaccia, Ariel D and Shapira, Itai and Vorobeychik, Yevgeniy and Wu, Junlin},
  journal={arXiv preprint arXiv:2405.14758},
  year={2024}
}

@article{alkan1991fair,
  title={Fair allocation of indivisible goods and criteria of justice},
  author={Alkan, Ahmet and Demange, Gabrielle and Gale, David},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1023--1039},
  year={1991},
  publisher={JSTOR}
}

@article{brams2006better,
  title={Better ways to cut a cake},
  author={Brams, Steven J and Jones, Michael A and Klamler, Christian and others},
  journal={Notices of the AMS},
  volume={53},
  number={11},
  pages={1314--1321},
  year={2006}
}


@article{alon1987splitting,
  title={Splitting necklaces},
  author={Alon, Noga},
  journal={Advances in Mathematics},
  volume={63},
  number={3},
  pages={247--253},
  year={1987},
  publisher={Elsevier}
}

@book{foley1966resource,
  title={Resource allocation and the public sector},
  author={Foley, Duncan Karl},
  year={1966},
  publisher={Yale University}
}

@article{gabriel2020artificial,
  title={Artificial intelligence, values, and alignment},
  author={Gabriel, Iason},
  journal={Minds and Machines},
  volume={30},
  number={3},
  pages={411--437},
  year={2020},
  publisher={Springer}
}


@book{sen2017collective,
  title={Collective choice and social welfare: Expanded edition},
  author={Sen, Amartya},
  year={2017},
  publisher={Penguin UK}
}

@book{brandt2016handbook,
  title={Handbook of computational social choice},
  author={Brandt, Felix and Conitzer, Vincent and Endriss, Ulle and Lang, J{\'e}r{\^o}me and Procaccia, Ariel D},
  year={2016},
  publisher={Cambridge University Press}
}

@book{brams1996fair,
  title={Fair Division: From cake-cutting to dispute resolution},
  author={Brams, Steven J and Taylor, Alan D},
  year={1996},
  publisher={Cambridge University Press}
}

@article{zhi2024beyond,
  title={Beyond preferences in {AI} alignment},
  author={Zhi-Xuan, Tan and Carroll, Micah and Franklin, Matija and Ashton, Hal},
  journal={Philosophical Studies},
  pages={1--51},
  year={2024},
  publisher={Springer}
}

@article{kirchner2022researching,
  title={Researching alignment research: Unsupervised analysis},
  author={Kirchner, Jan H and Smith, Logan and Thibodeau, Jacques and McDonell, Kyle and Reynolds, Laria},
  journal={arXiv preprint arXiv:2206.02841},
  year={2022}
}

@article{allen2024using,
  title={Using games to understand the mind},
  author={Allen, Kelsey and Br{\"a}ndle, Franziska and Botvinick, Matthew and Fan, Judith E and Gershman, Samuel J and Gopnik, Alison and Griffiths, Thomas L and Hartshorne, Joshua K and Hauser, Tobias U and Ho, Mark K and others},
  journal={Nature Human Behaviour},
  pages={1--9},
  year={2024},
  publisher={Nature Publishing Group UK London}
}


@inproceedings{milli2020literal,
  title={Literal or pedagogic human? analyzing human model misspecification in objective learning},
  author={Milli, Smitha and Dragan, Anca D},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={925--934},
  year={2020},
  organization={PMLR}
}

@article{liu2024large,
  title={Large language models assume people are more rational than we really are},
  author={Liu, Ryan and Geng, Jiayi and Peterson, Joshua C and Sucholutsky, Ilia and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2406.17055},
  year={2024}
}

@inproceedings{fish2024generative,
author = {Fish, Sara and G\"{o}lz, Paul and Parkes, David C. and Procaccia, Ariel D. and Rusak, Gili and Shapira, Itai and W\"{u}thrich, Manuel},
title = {Generative Social Choice},
year = {2024},
isbn = {9798400707049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670865.3673547},
doi = {10.1145/3670865.3673547},
booktitle = {Proceedings of the 25th ACM Conference on Economics and Computation},
pages = {985},
numpages = {1},
keywords = {computational social choice, large language models, proportional representation, democratic participation, AI governance},
location = {New Haven, CT, USA},
series = {EC '24}
}

@inproceedings{huang2024collective,
  title={Collective Constitutional AI: Aligning a Language Model with Public Input},
  author={Huang, Saffron and Siddarth, Divya and Lovitt, Liane and Liao, Thomas I and Durmus, Esin and Tamkin, Alex and Ganguli, Deep},
  booktitle={The 2024 ACM Conference on Fairness, Accountability, and Transparency},
  pages={1395--1417},
  year={2024}
}

@article{conitzer2024social,
  title={Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback},
  author={Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday, Wesley H and Jacobs, Bob M and Lambert, Nathan and Moss{\'e}, Milan and Pacuit, Eric and Russell, Stuart and Schoelkopf, Hailey and others},
  journal={arXiv preprint arXiv:2404.10271},
  year={2024}
}

@article{tessler2024ai,
  title={AI can help humans find common ground in democratic deliberation},
  author={Tessler, Michael Henry and Bakker, Michiel A and Jarrett, Daniel and Sheahan, Hannah and Chadwick, Martin J and Koster, Raphael and Evans, Georgina and Campbell-Gillingham, Lucy and Collins, Tantum and Parkes, David C and others},
  journal={Science},
  volume={386},
  number={6719},
  pages={eadq2852},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{klingefjord2024human,
  title={What are human values, and how do we align AI to them?},
  author={Klingefjord, Oliver and Lowe, Ryan and Edelman, Joe},
  journal={arXiv preprint arXiv:2404.10636},
  year={2024}
}

@article{gallegos2024bias,
  title={Bias and fairness in large language models: A survey},
  author={Gallegos, Isabel O and Rossi, Ryan A and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K},
  journal={Computational Linguistics},
  pages={1--79},
  year={2024},
  publisher={MIT Press 255 Main Street, 9th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{li2023survey,
  title={A survey on fairness in large language models},
  author={Li, Yingji and Du, Mengnan and Song, Rui and Wang, Xin and Wang, Ying},
  journal={arXiv preprint arXiv:2308.10149},
  year={2023}
}

@article{brosnan2003monkeys,
  title={Monkeys reject unequal pay},
  author={Brosnan, Sarah F and De Waal, Frans BM},
  journal={Nature},
  volume={425},
  number={6955},
  pages={297--299},
  year={2003},
  publisher={Nature Publishing Group UK London}
}

@article{miller1975self,
  title={Self-serving biases in the attribution of causality: Fact or fiction?},
  author={Miller, Dale T and Ross, Michael},
  journal={Psychological bulletin},
  volume={82},
  number={2},
  pages={213},
  year={1975},
  publisher={American Psychological Association}
}

@inproceedings{hosseini2024fairness,
  title={The Fairness Fair: Bringing Human Perception into Collective Decision-Making},
  author={Hosseini, Hadi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={20},
  pages={22624--22631},
  year={2024}
}

@article{fish2023generative,
  title={Generative social choice},
  author={Fish, Sara and G{\"o}lz, Paul and Parkes, David C and Procaccia, Ariel D and Rusak, Gili and Shapira, Itai and W{\"u}thrich, Manuel},
  journal={arXiv preprint arXiv:2309.01291},
  year={2023}
}


@article{mei2024turing,
  title={A Turing test of whether {AI} chatbots are behaviorally similar to humans},
  author={Mei, Qiaozhu and Xie, Yutong and Yuan, Walter and Jackson, Matthew O},
  journal={Proceedings of the National Academy of Sciences},
  volume={121},
  number={9},
  pages={e2313925121},
  year={2024},
  publisher={National Academcy of Sciences}
}

@article{kapoor2024reforms,
  title={REFORMS: Consensus-based Recommendations for Machine-learning-based Science},
  author={Kapoor, Sayash and Cantrell, Emily and Peng, Kenny and Pham, Than Hien and Bail, Christopher A and Gundersen, Odd Erik and Hofman, Jake and Hullman, Jessica and Lones, Michael Adam and Malik, Momin M and others},
  journal={Science Advances},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{fan2024can,
  title={Can large language models serve as rational players in game theory? a systematic analysis},
  author={Fan, Caoyun and Chen, Jindou and Jin, Yaohui and He, Hao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17960--17967},
  year={2024}
}

@inproceedings{zhao2024expel,
  title={Expe{L}: {LLM} agents are experiential learners},
  author={Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19632--19642},
  year={2024}
}


@article{raman2024rationality,
  title={{STEER}: Assessing the Economic Rationality of Large Language Models},
  author={Raman, Narun and Lundy, Taylor and Amouyal, Samuel and Levine, Yoav and Leyton-Brown, Kevin and Tennenholtz, Moshe},
  journal={arXiv preprint arXiv:2402.09552},
  year={2024}
}


@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}


@article{gandhi2024understanding,
  title={Understanding social reasoning in language models with language models},
  author={Gandhi, Kanishk and Fr{\"a}nken, Jan-Philipp and Gerstenberg, Tobias and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{duetting2024mechanism,
  title={Mechanism design for large language models},
  author={Duetting, Paul and Mirrokni, Vahab and Paes Leme, Renato and Xu, Haifeng and Zuo, Song},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={144--155},
  year={2024}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@article{brand2023using,
  title={Using {GPT} for market research},
  author={Brand, James and Israeli, Ayelet and Ngwe, Donald},
  journal={Harvard Business School Marketing Unit Working Paper},
  number={23-062},
  year={2023}
}

@article{fontana2024nicer,
  title={Nicer Than Humans: How do Large Language Models Behave in the Prisoner's Dilemma?},
  author={Fontana, Nicol{\'o} and Pierri, Francesco and Aiello, Luca Maria},
  journal={arXiv preprint arXiv:2406.13605},
  year={2024}
}

@article{schramowski2022large,
  title={Large pre-trained language models contain human-like biases of what is right and wrong to do},
  author={Schramowski, Patrick and Turan, Cigdem and Andersen, Nico and Rothkopf, Constantin A and Kersting, Kristian},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  pages={258--268},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{aher2023using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}

@techreport{korinek2023language,
  title={Language models and cognitive automation for economic research},
  author={Korinek, Anton},
  year={2023},
  institution={National Bureau of Economic Research}
}

@article{kosinski2023theory,
  title={Theory of mind might have spontaneously emerged in large language models},
  author={Kosinski, Michal},
  journal={arXiv preprint arXiv:2302.02083},
  year={2023}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{guth1982experimental,
  title={An experimental analysis of ultimatum bargaining},
  author={G{\"u}th, Werner and Schmittberger, Rolf and Schwarze, Bernd},
  journal={Journal of economic behavior \& organization},
  volume={3},
  number={4},
  pages={367--388},
  year={1982},
  publisher={Elsevier}
}

@article{eckel2001chivalry,
  title={Chivalry and solidarity in ultimatum games},
  author={Eckel, Catherine C and Grossman, Philip J},
  journal={Economic inquiry},
  volume={39},
  number={2},
  pages={171--188},
  year={2001},
  publisher={Wiley Online Library}
}


@article{guo2023gpt,
  title={{GPT} in game theory experiments},
  author={Guo, Fulin},
  journal={arXiv preprint arXiv:2305.05516},
  year={2023}
}


@article{bommasani2023foundation,
  title={The foundation model transparency index},
  author={Bommasani, Rishi and Klyman, Kevin and Longpre, Shayne and Kapoor, Sayash and Maslej, Nestor and Xiong, Betty and Zhang, Daniel and Liang, Percy},
  journal={arXiv preprint arXiv:2310.12941},
  year={2023}
}


%%%%%%%%%%%%%%%%

