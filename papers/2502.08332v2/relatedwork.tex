\section{Related Works}
\subsection{Watermarking for LLM}

% There has been a recent emergence of watermarking specific patterns into language models for AI detection. 
Kirchenbauer et al.\cite{kirchenbauer23a} introduced a pioneering watermarking framework tailored for LLMs that embeds watermarks with minimal text quality impact. It creates ``green" token list randomly before generating tokens, and encouraging the model to choose from them. This type of watermarking method increases robustness, but it disrupts the output distribution of the model\cite{singh2023newevaluationmetricscapture}. To reduce the impact on the quality of text generation, Lee\cite{lee2024wrote} considered text entropy to modify logits adaptively. To enhance the robustness of the watermark, Zhao\cite{zhao2024provable} improved the robustness by fixing the division of the red and green lists. However, the above methods cannot avoid affecting the quality of the text generated by the LLM. To ensure the quality of text generation, Hu et al.\cite{hu2024unbiased} and Wu et al.\cite{wu2024dip} proposed unbiased watermark algorithms that can maintain probability distribution while embedding watermark.
%proposed the first LLM watermark algorithm, which uses a hash function to randomly divide the candidate word library into a red list and a green list, and by increasing the logits of the tokens in the green list, the output text comes more from the green list.