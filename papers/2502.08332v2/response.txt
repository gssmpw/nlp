\section{Related Works}
\subsection{Watermarking for LLM}

% There has been a recent emergence of watermarking specific patterns into language models for AI detection. 
Kirchenbauer et al., "Language Model Watermarking: A New Framework" introduced a pioneering watermarking framework tailored for LLMs that embeds watermarks with minimal text quality impact. It creates ``green" token list randomly before generating tokens, and encouraging the model to choose from them. This type of watermarking method increases robustness, but it disrupts the output distribution of the model. Lee, "Unsupervised Text Watermarking for Language Models" considered text entropy to modify logits adaptively. To enhance the robustness of the watermark, Zhao et al., "Improved Robustness of Language Model Watermarking" improved the robustness by fixing the division of the red and green lists. However, the above methods cannot avoid affecting the quality of the text generated by the LLM. To ensure the quality of text generation, Hu et al., "Unbiased Watermarking for Language Models: A New Approach" and Wu et al., "Watermarking Language Models with Unbiased Distribution" proposed unbiased watermark algorithms that can maintain probability distribution while embedding watermark.
%proposed the first LLM watermark algorithm, which uses a hash function to randomly divide the candidate word library into a red list and a green list, and by increasing the logits of the tokens in the green list, the output text comes more from the green list.