\section{Related Work}
\label{sect:related_work}

\textit{SSseg vs OCL}.
Both Self-Supervised Segmentation (SSseg) ____ and OCL can discovery objects, i.e., segmenting objects and the background in images or video frames without supervision. 
SSseg only outputs object segmentation masks, while OCL further represents objects as \textit{slots}. 
These slots can be directly used in downstream object-centric world models ____ for dynamics modeling, which is demanded in advanced vision tasks.
Thus a direct comparison between them is beyond the scope of this work.

\textit{OCL encoding}. 
The stronger encoder that extracts feature maps of better objectness contributes more to OCL performance. 
Early milestone methods like IODINE____ and SA ____ use small naive CNNs ____ as OCL encoder. 
Followups like SAVi ____, SAVi++ ____, SLATE ____ and STEVE ____ employ pretrained ResNets ____, and fine-tune them on OCL datasets. 
State-of-the-arts like SlotDiffusion ____ and DINOSAUR ____ utilize VFMs like DINO ____ and DINO2 ____ ViTs (Vision Transformers) to extract highly object-separable feature map from input pixels, improving OCL performance significantly.
Although SAM ____ and SAM2 ____ are also well recognized VFMs, they remain unexploited in OCL setting. 
Our VVO supports various VFMs for OCL encoding.

\textit{OCL aggregation}. SlotAttention ____ is the footstone for mainstream OCL methods. Subsequent works like BO-QSA ____, ISA ____ and SysBind ____ are all its variants, which are designed without changing the external interface. But considering their performance boosts, we only integrate BO-QSA by default.

\textit{OCL decoding}. 
With SlotAttention as the aggregator, the decoder and its reconstruction target affect OCL performance the most, as it is the source of supervision.
Mixture-based decoding, used in SAVi, SAVi++, DINOSAUR and VideoSAUR ____, decodes each slot's spatial broadcast ____ using naive CNNs or MLPs, and mixes them with corresponding weights into the reconstruction.
Transformer-based decoding, used in SLATE, STEVE and SPOT ____, reconstructs VAE representation of the input auto-regressively with slots as the condition.
Diffusion-based decoding in LSD ____ and SlotDiffusion drives slots to recover noise added to the input's VAE representation.
Our VVO supports all these types of OCL decoding.

\textit{VAE for OCL}. % TODO XXX VAE GDR MSF
Variational Autoencoders (VAEs), like dVAE ____ in SLATE and VQ-VAE ____ in SlotDiffusion, are employed to produce reconstruction targets for OCL training.
Since these VAEs are designed for image generation, some methods adapt them for OCL.
Inspired by channel or weight grouping, GDR ____ decomposes features into attributes and combine them to produce VAE representation as reconstruction targets to guide OCL better.
MSF ____ firstly exploits the multi-scale idea in the OCL setting with VAE-specific designs.
Based on recent advancement RVQ ____ and SimVQ ____, we design our own VQ variant for OCL.



\begin{figure*}[]
\centering
\includegraphics[width=0.975\linewidth]{res/vvo_arch.pdf}
% \\\vspace{-0.5\baselineskip}
\caption{\textmd{
VVO is a unified architecture that fully utilizes VFMs in OCL. It not only extracts VFM features with better objectness to facilitate object information aggregation; but further quantizes those VFM features as reconstruction targets to strengthen OCL training supervision. With typical SlotAttention or it variants as the \textcolor{purple2}{aggregator} and Vector-Quantization as the \textcolor{purple2}{quantizer}, VVO supports different VFMs as the \textcolor{purple2}{encoder}, and supports mainstream mixture, auto-regression and diffusion models as the \textcolor{purple2}{decoder}.
}}
\label{fig:vvo_arch}
\end{figure*}
% \vspace{-0.5\baselineskip}