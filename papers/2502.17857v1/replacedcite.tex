\section{Related Work}
Small hand annotated corpora ____ provides useful insights into empathy expression; however, their limited size may not be sufficient for fine-tuning LLMs. We focus on large-scale, textual corpora that are suitable for training and fine-tuning most LMs in use today.

% new %
% The aim of our work is to generate empathetic responses using a LLM and compile them into one corpus. So, we further examine previous works that either compile an empathy focused corpus or attempt to generate empathy using LLMs.


\subsection{Empathy Corpora}
Table~\ref{tab:corpora comparison} provides a comprehensive comparison of key metrics and characteristics of existing empathy corpora as well as SYNTHEMPATHY. 
% The last row refers to whether the corpus was built with intent by evenly distributing the topics of the examples in the corpus.

\begin{table*}
  \centering
  \begin{tabular}{lccccc}
    \hline
     & \textbf{ED} & \textbf{EPITOME} & \textbf{OSED} & \textbf{SoulChatCorpus} & \textbf{SYNTHEMPATHY} \\
    \hline
    Num. Examples & 24k & 10k & 1M & 200k & 105k                          \\
    Utterances per Example & 4.31 & 2.00 & 3.49 & 11.50 & 2.00  \\
    Crowdsourced & \color{green}{\ding{51}} & \color{green}{\ding{51}} & \color{green}{\ding{51}} & \color{green}{\ding{51}} & \color{red}{\ding{55}}      \\
    Topics Evenly Distributed & \color{green}{\ding{51}} & \color{green}{\ding{51}} & \color{red}{\ding{55}} & \color{red}{\ding{55}} & \color{green}{\ding{51}}      \\
    \hline
  \end{tabular}
  \caption{Comparison of key metrics of empathy corpora. Our SYNTHEMPATHY dataset is the first large-scale corpus that excludes crowdsourcing and balances the topic distributions.}
  \label{tab:corpora comparison}
\end{table*}


Earlier efforts in empathetic dataset collection and annotation, such as the EmpatheticDialogues (ED) ____ and EPITOME ____ have predominantly relied on crowdsourcing. Specifically, ED is a multi-turn empathy corpus, assembled by engaging 810 Amazon MTurk workers to chat in pairs, each conversation prompted by one of 32 assigned emotion labels. 
% ____ produced the EmpatheticDialogues (ED) corpus by employing 810 crowdsourced workers based in the United States. These workers, hired through Amazon MTurk, were paired up and given one of $32$ emotion label before having to converse according to their label. 
% ED is an example of a multi-turn empathy corpus since each example is a back and forth conversation instead of being one post and response per example.

The EPITOME empathy corpus ____ was created by web crawling from Reddit and the online mental health forum TalkLife, and subsequently annotated through crowdsourcing, which required fewer crowdsourced workers. Eight crowdsourced workers evaluated the post-response pairs by scoring each each based on how well it expressed emotional reaction (ER), interpretation (IP), and exploration (EX).
% ____ compiled the EPITOME empathy corpus by crawling Reddit and online mental health forum TalkLife. Eight crowdsourced workers annotated the post response pairs by scoring each one in how well it expresses emotional reaction (ER), interpretation (IP), and exploration (EX). 
ER is a crucial indicator of empathy as revealing one's own emotions can foster empathetic rapport with the original poster. IP signals understanding of the poster's struggles, paving the way for deeper empathetic connections. Lastly, EX suggests new perspectives on the seeker’s experience, crucial for conveying empathy-driven interest.
% ER is a good indicator for measuring empathy because revealing one's own emotions can help build empathetic rapport with the original poster. IP signals to the poster that their struggles have been understood which opens the gateway for a deeper empathetic connection. Finally, EX is relevant for empathy because it actively suggests new ways to view the seeker's experience which is key to conveying empathy-driven interest ____. 
These three empathetic metrics are similar to practices used in psychotherapy ____.

More recently, researchers have combined crowdsourcing with further extrapolation using LLMs to expand dataset sizes.
____ developed the OpenSubtitles Emotional Dialogue (OSED) by extracting 1M dialogues from movie subtitles. Each dialogue contains utterance-level labels for emotion and empathetic intent, assigned by a BERT-based classifier fine-tuned on a development set of 9k dialogues, which had been manually corrected by Amazon MTurk workers. Due to the high cost of scaling crowdsourcing, only about 0.91\% of the dialogues were manually checked, underscoring the challenge of expanding manual checks in large datasets.
% on $9,000$ dialogues before having it manually corrected by Amazon MTurk workers. The improved classifier then annotates the remaining $991,000$ dialogues. The proportion of manually checked dialogues is only around $0.91\%$ of the full data because the cost of doing more manual checks grows quickly as crowdsourcing is expensive to scale.
The SoulChatCorpus ____ was built by initially collecting 215,813 question-answer pairs through crowdsourcing, followed by utilizing ChatGPT as a rewriting tool to transform each pair into a multi-turn dialogue. Each dialogue ranges from 8 to 20 turns, resulting in approximately 2M utterances. Both SoulChatCorpus and OSED are limited by their reliance on crowdsourced workers to create an initial high-quality subset of the corpus.

\subsection{Empathy Generation}

Previous efforts to generate empathetic responses from LLMs have involved modifying the underlying model architecture, fine-tuning on empathy corpora, or employing meticulous prompting to improve empathy levels of the outputs.
% Previous works that aim to generate empathetic responses from LLMs either modify the underlying model architecture, fine-tune on an empathy corpus, or use meticulous prompting to maximize empathy.
Adding emotion tags or emotional embeddings
____ improves response generation. 
% ____ modified the Transformer-XL architecture by adding an emotional embedding alongside the positional embedding before the encoder step. 
____ attached a normal distribution random sampler right before the decoder in order to inject more stochasticity into empathetic dialogue agents making its empathetic responses sound personalized. Due to the lack of large empathy corpora, very few studies focus on fine-tuning. ____ fine-tuned ChatGLM-6B on the SoulChatCorpus corpus to determine how much the base model improves. 
% There are not too many papers that focus on fine-tuning due to the lack of large empathy corpora.

Prompt engineering, especially Chain of Thought prompting, is increasingly popular in enhancing LLMs for downstream tasks in zero-shot or few-shot settings ____. LLMs generate more empathetic responses when the prompts incorporate psychotherapy approaches used by professional therapists, that is the Chain of Empathy (CoE) prompting ____. 
% The authors called this Chain of Empathy (CoE) prompting since it is meant to adapt the Chain of Thought prompting developed by ____ to the domain of empathy. 
% ____ did this by mimicking the step by step prompting style of Chain of Thought prompting. 
% They appended the reasoning for why a client needs empathy to the base explanation of the client's situation. This was done in four flavors: Cognitive Behavioral Therapy (CBT), Dialectical Behavior Therapy (DBT), Person-Centered Therapy (PCT), and Reality Therapy (RT). More details on each therapy approach can be found in appendix A.1. We utilize \citeposs{lee2023chain} CoE prompting as an integral part of our pipeline.
 This approach involves step-by-step prompts that not only describe a client’s situation but also include reasoning for why empathy is needed, modeled after various therapeutic styles including Cognitive Behavioral Therapy (CBT), Dialectical Behavior Therapy (DBT), Person-Centered Therapy (PCT), and Reality Therapy (RT). Further details on each therapy approach are available in Appendix A.1. Our pipeline incorporates \citeposs{lee2023chain} CoE prompting as a crucial component.