\section{LLMs as Data Enhancers}\label{sec:enhancer}
Education is a high-stake area where any form of LLMs' hallucination could cause devastating harm to humans' cognition activities~\cite{ho2024mitigating}. One of the hallucination causes is from data~\cite{huang2023survey}. Therefore, high-quality and diverse data resources~\cite{long-etal-2024-llms} are critical to ensuring the reliability of incorporating LLMs into FLE. The 1) \textit{creation}, 2) \textit{reformation}, and 3) \textit{annotation} of educational materials are crucial to delivering effective and engaging teaching. Traditional resource development methods often lack the scalability, adaptability, and personalization necessary to meet the diverse needs of learners~\cite{feng-etal-2021-survey,shorten2021text}. In contrast, LLMs emerge as transformative tools capable of enhancing these processes~\cite{wang2024survey,liu2024best}. This section explores how LLMs serve as data enhancers in FLE.


\subsection{Data Creation}
Creating pedagogically sound and learner-specific data is a cornerstone of personalized learning. However, manually creating such resources is time-consuming and often fails to address the wide range of learner needs~\cite{cochran2022improving}. LLMs can revolutionize this process by generating tailored and diverse educational content or responses on demand~\cite{zha2023data,cochran2023improving}.

% \paragraph{Educational Materials Generation.} One of the most direct applications of LLMs is the \textit{generation of educational questions} tailored to specific learning objectives. Many question generation methods have been proposed, from traditional rule-based to advanced neural network-based methods~\cite{kurdi2020systematic,rathod-etal-2022-educational,mulla2023automatic}. LLMs have been proven adept at generating contextually relevant questions and distractors for various learning objectives~\cite{doughty2024comparative,biancini2024multiple,lee2024few} than previous methods. They can produce answer-aware (whose target answer is known) or answer-agnostic (whose answer is open)~\cite{zhang2021review} for reading comprehension questions~\cite{xiao-etal-2023-evaluating} based on a specific topic. The generated questions can be combined into a systematic simulated exam for students' learning diagnosis, a prerequisite for the subsequent design of personalized learning paths. In addition to text-based materials~\cite{rashid2024humanizing}, LLMs show promise in contributing to the creating multimodal educational resources that integrate slides, images, audio, and video.

\paragraph{Educational Materials Generation.} A primary use of LLMs in data creation is the \textit{generation of educational questions} aligned with specific learning objectives. Due to their superior contextual understanding, classic rule-based approaches have largely been eclipsed by neural network-based techniques~\cite{kurdi2020systematic,rathod-etal-2022-educational,mulla2023automatic}. LLMs can produce answer-aware (whose target answer is known) or answer-agnostic (whose answer is open)~\cite{zhang2021review}, resulting in more nuanced exercises and assessments~\cite{xiao-etal-2023-evaluating}.

\paragraph{Student Simulation.} Simulating the learner’s perspective is crucial for designing adaptive instructional materials. Traditional surveys and standardized tests often fail to capture the complexity of dynamic learner behaviors~\cite{kaser2024simulated}. In contrast, LLM-based approaches enable high-fidelity, context-aware \textit{student simulations}~\cite{liu2024personality,yue2024mathvc}, generating synthetic learners who exhibit realistic mastery levels and evolving behaviors. For instance, \textit{Generative Students}~\cite{lu2024generative} create simulated learners with various competency levels, while \textit{EduAgent}~\cite{xu2024eduagent} integrates cognitive priors to model complex learning trajectories and behaviors better.

\paragraph{Discussion.} While LLMs excel at generating educational content, current approaches mainly focus on question creation, leaving many areas of FLE underexplored. Essential tasks like generating culturally rich reading materials, context-dependent writing prompts, or dynamic comprehension exercises are still lacking in diversity and depth. Additionally, the student simulations created by LLMs often fail to reflect long-term learning trajectories or the intricacies of individual learning progress, leading to challenges in creating truly adaptive systems.


\subsection{Data Reformation}
In addition to creating new content, LLMs can adapt \textit{existing} materials to better align with current needs. This process, commonly referred to as data reformation, involves (1) changing data types or modalities, (2) paraphrasing materials to match learner proficiency, and (3) enriching raw data with auxiliary signals or contextual content.

\paragraph{Teaching Material Transformation.} Transforming existing materials into different forms can yield more comprehensive and immersive learning experiences. For example, \textit{Book2Dial}\cite{wang-etal-2024-book2dial} generates teacher-student dialogues grounded in textbooks, keeping the content both relevant and informative. Their approach includes multi-turn question generation and answering\cite{kim-etal-2022-generating}, dialogue inpainting~\cite{dai2022dialog}, and role-playing. Likewise, \textit{Slide2Lecture}~\cite{zhang2024awaking} automatically converts lecture slides into structured teaching agendas, enabling interactive follow-up and deeper learner engagement.

\paragraph{Simplification and Paraphrasing.} Another vital application is simplifying or paraphrasing complex texts to specified readability levels~\cite{huang2024generating} without losing key concepts~\cite{al2021automated}. This is particularly beneficial in FLE settings, where language beginners often face advanced vocabulary and complex structures~\cite{day2025evaluating}. Recent advancements in controllable generation~\cite{zhang2023survey} leverage model fine-tuning on curated datasets~\cite{zeng-etal-2023-seen} or decoding-time interventions~\cite{liang2024controllable}, thereby allowing educators to specify text complexity, style, or tone.

\paragraph{Cultural Context Adaptation.} Beyond linguistic correctness, cultural nuance is pivotal in FLE~\cite{byram1989cultural,byram2008foreign}. LLMs can facilitate this process by recontextualizing existing materials to reflect the cultural and social norms of the target language~\cite{liu2024culturally}. For instance, a short story originally set in an English-speaking environment may be adapted for French or Japanese learners by adjusting the characters’ names, idiomatic expressions, or social customs, while still preserving core instructional goals. This cultural adaptation not only enhances learner engagement but also strengthens cross-cultural competencies.

\paragraph{Discussion.} While LLM-based data reformation can significantly enhance FLE, several gaps warrant attention. Most current studies prioritize textual forms or single-modal approaches, which may overlook valuable \textit{multimodal} resources such as interactive video and audio-based content~\cite{ghosal2023text}. Furthermore, cultural adaptation, although promising, remains underexplored in practical classroom scenarios, particularly for underrepresented personas and culturally sensitive topics. \citet{alkhamissi-etal-2024-investigating} demonstrate how cultural misalignment can increase bias, suggesting \textit{Anthropological Prompting} to strengthen cultural alignment. However, robust empirical \textit{evaluations} are still limited across diverse learners and linguistic backgrounds. These issues highlight the importance of interdisciplinary research, where educators, linguists, and technologists collaborate to refine data reformation techniques that broaden inclusivity and effectiveness in FLE.

\subsection{Data Annotation}
While \textit{Data Creation} focuses on generating learner-specific data, it often prioritizes diversity and adaptability over precision. The approach is particularly useful for tasks with large label spaces~\cite{ding-etal-2024-data}. In contrast, \textit{Data Annotation} emphasizes producing high-quality, meticulously labeled data that is essential for tasks requiring accuracy and consistency. Unlike data creation, annotated data often undergoes rigorous validation to ensure its accuracy and relevancy~\cite{artemova2024hands}.

\paragraph{Annotation Generation.} LLMs can be central to generating a variety of annotations, including categorical labels, rationales, pedagogical feedback, and linguistic features such as discourse relations. Recent prompt engineering and fine-tuning techniques have further expanded LLMs’ annotation capabilities. For instance, \citet{ye2024excgec} leverage GPT-4 to annotate structured explanations for Chinese grammatical error correction, while \citet{samuel-etal-2024-llms} examine GPT-4 as a surrogate for human annotators in low-resource reading comprehension tasks. Likewise, \citet{li-etal-2024-eden} deploy GPT-4-Turbo for audio transcript annotations. However, inconsistencies across LLMs~\cite{tornberg2024best} remain a serious challenge, posing risks to educational reliability.

\paragraph{Annotation Assessment.} Although LLM-based annotation generation is efficient, it also raises critical issues of bias, calibration, and validity—particularly in low-resource language contexts~\cite{bhat-varma-2023-large,jadhav2024limitations}. Automated or semi-automated evaluation strategies have emerged to address these quality concerns. For example, LLMs-as-Judges~\cite{li2024generation,li2024llms,gu2024survey} reduce human overhead by automating evaluation, an approach increasingly explored in education-focused applications~\cite{chiang-etal-2024-large,zhou-etal-2024-llm}. However, purely automated frameworks can still propagate errors or bias.

% if LLM outputs are taken at face value.

\paragraph{Discussion.} Although LLMs provide efficient data annotation, the inconsistency across different models remains a critical concern, affecting the quality and reliability of annotated educational materials. These discrepancies hinder the creation of universally reliable FLE content, especially in diverse linguistic and cultural contexts. Additionally, automated annotations often lack the nuance needed for pedagogical applications, making it essential to involve human oversight in critical cases to mitigate errors or biases.

\begin{tcolorbox}[top=1pt, bottom=1pt, left=1pt, right=1pt]
\textbf{Our position.} We acknowledge the current limitations in LLM-based data creation, reformation, and annotation for FLE. However, we believe that with continued interdisciplinary collaboration, including input from educators, linguists, and technologists, these challenges can be addressed. \textit{Future advancements} should focus on enhancing the accuracy and diversity of generated content, improving multimodal and culturally sensitive learning materials, and integrating more robust systems for human-LLM collaboration~\cite{li-etal-2023-coannotating,wang2024human} in data annotation. This approach will ensure that LLMs can fully realize their potential as effective tutors in FLE.
\end{tcolorbox}

% adaptive and effective tutors in FLE.
