\input{figures/paradigm}

\section{Background}\label{sec:background}
\subsection{Foreign Language Education}
FLE~\cite{watzke2003lasting,rashov2024modern} has long been a cornerstone of global communication and cultural exchange. Traditional methods often emphasize grammar rules, vocabulary memorization, and repetitive practice, supplemented by limited opportunities for real-world application. Such approaches are often constrained by the availability of skilled teachers, the diversity of learners' needs, and the lack of personalized feedback~\cite{williams2004learners}. To bridge the gaps, many technologies for FLE have been proposed~\cite{alhusaiyan2024systematic}, focusing on solving specific tasks instead of describing the whole picture of foreign language tutoring. While intelligent language tutoring systems~\cite{schwind1990intelligent,c1993towards} have the potential to create adaptive environments, attention to this field is relatively less compared to other subjects like science and mathematics. One key reason lies in the inherent complexity of language as an \textit{ill-defined} domain~\cite{schmidt2022artificial}, posing a great challenge in establishing a valid automatic analysis of learner languages due to the vast variability and unpredictability of human language.


% In the era of artificial intelligence (AI), FLE is undergoing a paradigm shift~\cite{hou2020foreign}. Introducing AI-powered tools has brought opportunities and challenges to the field. For \textit{students}, AI tools such as language learning apps~\cite{bicknell2023duolingo,shetye2024evaluation}, virtual tutors~\cite{lin2023artificial}, and conversational agents~\cite{zhang2024simulating} have made language practice more accessible and flexible. These tools offer personalized learning paths, instant feedback, and interactive experiences that can supplement traditional instruction. However, they also raise concerns about over-reliance on technology and the potential loss of human interaction, which remains a vital component of language learning.

% For \textit{educators}, AI has introduced both promise and disruption~\cite{pokrivcakova2019preparing,lee23generative}. On one hand, AI technologies can assist teachers by automating routine tasks such as grading, providing supplementary materials, and identifying individual students' strengths and weaknesses. On the other hand, the increasing adoption of AI tools has sparked debates about the evolving role of teachers in the classroom. Educators now face the challenge of integrating these technologies effectively while ensuring that they complement, rather than replace, the human elements of teaching, such as empathy, cultural context, and nuanced communication.


\subsection{Large Language Models}
The potential of LLMs in education~\cite{alhafni2024llms}, particularly in FLE~\cite{gao2024exploring,karatacs2024incorporating}, is immense. Benefiting from large-scale pre-training on extensive corpora, LLMs have demonstrated emergent abilities including (1) \textit{in-context learning}~\cite{dong2022survey}, which allows the model to adapt to new tasks and provide contextually relevant responses based on a few examples provided during the interaction; (2) \textit{instruction following}~\cite{zeng2024evaluating}, which enables the model to process and execute complex user instructions with high accuracy; and (3) \textit{reasoning and planning}~\cite{huang2024understanding}, which allows the model to generate coherent, structured, and context-aware outputs, even for tasks that require multi-step thinking.

However, these fundamental capabilities, while impressive, are not sufficient to fully meet the unique demands of FLE. Teaching a foreign language requires more than generating grammatically correct sentences or providing accurate translations; it demands a nuanced understanding of pedagogy, learner psychology, and cultural context. \citet{maurya2024unifying} propose an evaluation taxonomy that identifies eight critical dimensions for assessing AI tutors. These dimensions can be broadly categorized into two groups. (1) \textit{Problem-solving abilities} assess the technical capabilities of LLMs to perform tasks relevant to FLE. (2) \textit{Pedagogical alignment abilities} evaluate how well the LLM aligns with effective teaching and learning principles. Pedagogical alignment includes the model's ability to adapt to the learner's proficiency level, provide scaffolded feedback, foster engagement, and maintain motivation. While LLMs can give direct answers, their ability to replicate these nuanced teaching strategies remains a challenge~\cite{wang2024challenges}. Additionally, pedagogical alignment requires sensitivity to cultural and contextual factors, ensuring that the learning experience is relevant and meaningful to the student.


% For instance, problem-solving abilities include the model's proficiency in generating accurate translations, correcting grammatical errors, and providing context-sensitive explanations of linguistic concepts. 
% For example, human tutors often employ strategies like offering hints, breaking down complex concepts, and encouraging self-reflection to guide learners toward solutions.


\section{Paradigm Shift}\label{sec:paradigm}
% The development of AI models for FLE can be categorized into four key generations: (1) \textit{rule-based models}, (2) \textit{statistical models}, (3) \textit{neural models}, and (4) \textit{large language models}. Rule-based systems~\cite{grosan2011rule,c1993towards}, like PLATO~\cite{hart1981language} and Systran~\cite{toma1977systran}, dominant from the 1960s to the 1990s, relied on manually crafted linguistic rules and were effective for structured tasks but lacked flexibility and scalability. The advent of statistical models in the 1990s, such as Google Translate (Early Version)~\cite{och2006statistical} and Dragon NaturallySpeaking~\cite{blair1997dragon}, shifted the paradigm by leveraging large datasets to identify probabilistic language patterns, enabling more dynamic applications, though these models struggled with semantic understanding. Neural models, emerging in the 2010s, introduced deep learning architectures like RNNs~\cite{yu2019review} and Transformers~\cite{vaswani2017attention}, which captured contextual and semantic nuances, significantly advancing tasks like text writing (Grammarly~\cite{fitria2021grammarly}) and personalized learning (Duolingo~\cite{vesselinov2012duolingo}). Most recently, LLMs, exemplified by GPT models~\cite{achiam2023gpt}, have transformed the landscape by combining vast pre-training on diverse corpora with generative capabilities, enabling not only contextual understanding but also dynamic content creation, personalized feedback, and multimodal integration, positioning them as powerful tools (Khanmigo~\cite{anand2023khan}) for FLE.

The development of AI models for FLE can be broadly categorized into four successive generations as shown in Figure~\ref{fig:paradigm}: (1) \textit{rule-based models}, (2) \textit{statistical models}, (3) \textit{neural models}, and (4) \textit{large language models}. We leave the detailed description in Appendix~\ref{app:roadmap}.

\begin{tcolorbox}[top=1pt, bottom=1pt, left=1pt, right=1pt]
\textbf{Our position.} We foresee next-generation LLMs with deeper alignment to pedagogical principles and stronger guardrails to mitigate misinformation and bias. Future models may integrate multimodal data (e.g., text, image, video, speech) and employ meta-learning to adapt in real time to diverse learner profiles. These improvements will reinforce the position that LLMs can evolve into even more effective tutors for FLE.
\end{tcolorbox}



% \footnote{\url{https://app.grammarly.com/}}
% \footnote{\url{https://www.duolingo.com/}}
