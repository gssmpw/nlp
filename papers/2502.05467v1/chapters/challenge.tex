\section{Challenges and Future Directions}\label{sec:challenge}
While we posit that LLMs have the potential to revolutionize FLE, realizing their full promise requires addressing key challenges. This section offers a concise overview of these challenges, followed by directions that could guide future research and deployment.

\paragraph{Ensuring Reliability and Mitigating Hallucinations.}
LLMs may produce hallucinations~\cite{huang2023survey} that can mislead learners and undermine pedagogical goals. This risk intensifies in high-stakes educational environments, where trust and correctness are paramount. Efforts to increase data quality~\cite{long-etal-2024-llms}, combine model outputs with structured domain knowledge, and employ rigorous validation mechanisms (including human oversight) are crucial for minimizing such detrimental outcomes.

\paragraph{Addressing Bias and Ethical Considerations.}
As LLMs inherit biases from their training data, these systems may produce culturally insensitive or unfair responses, potentially harming students from diverse linguistic and sociocultural backgrounds. Moreover, privacy concerns emerge when collecting and using learner data to personalize instruction. Robust governance frameworks, transparent documentation of data sources, and bias mitigation strategies~\cite{borah2024towards} can help ensure that LLMs serve as equitable tools in FLE.

\paragraph{Aligning With Pedagogical Principles.}
LLMs excel at generating language but often lack pedagogical alignment, particularly for tasks requiring developmental sensitivity, motivation, or differentiated instruction. Their general-purpose nature means they do not inherently account for language acquisition theories or curricular standards~\cite{razafinirina2024pedagogical}. To fully realize their potential, LLM-based tutors should be guided by robust pedagogical frameworks and co-designed with educators who understand learnersâ€™ cognitive and developmental needs.

% \paragraph{Integrating With Existing Ecosystems.} Adopting LLM-based tutoring in real classrooms requires compatibility with existing educational ecosystems. Teachers may resist or feel threatened by novel AI-driven methods, particularly if the technology is perceived as opaque or cumbersome~\cite{pokrivcakova2019preparing}. Successful integration, therefore, hinges on professional development, user-friendly tooling, and institutional support to ensure that teachers utilize LLMs as complementary aids rather than replacements.


\section{Alternative Views}\label{sec:alternative_views}
% While this paper supports using LLMs in FLE, it is essential to consider alternative perspectives.
% Below, we discuss two key opposing views and provide counterarguments.

\subsection{Task-Specific or Language-Specific Models as Better Alternatives}
Some argue that specialized or language-specific models, including classical ML systems with carefully engineered features, can outperform general-purpose LLMs in narrowly defined tasks (e.g., phonetics or grammar drills~\cite{fang2023chatgpt}). By focusing on limited objectives, such models avoid the computational overhead and potential inaccuracies of LLMs, which aim to handle a broader range of inputs and contexts~\cite{shen2024language}.

\paragraph{Counterargument.} While specialized models may excel in isolated tasks, they lack the flexibility required for comprehensive FLE, which involves cultural nuances, conversations, and evolving learner needs. In contrast, LLMs can be fine-tuned for specific goals while still offering broader linguistic competence~\cite{song2024multilingual}. Additionally, relying on multiple specialized models can be resource-intensive, whereas a well-configured LLM provides a unified framework that balances specialization and scalability.

\subsection{Concerns About Over-Reliance on LLMs}
Critics warn that over-reliance on LLMs may lead to problems such as generating misleading outputs~\cite{nahar2024fakes}, reducing human interaction, and over-standardizing teaching methods. These issues could undermine the interpersonal and motivational aspects of language learning.

\paragraph{Counterargument.} These risks highlight the need for balanced integration rather than the replacement of human tutors. LLMs can complement educators by automating repetitive tasks, allowing teachers to focus on individualized support and motivation. Advances in AI safety, such as feedback loops~\cite{tong2024can} and human-in-the-loop systems~\cite{wu2022survey}, can help minimize inaccuracies~\cite{ho2024mitigating}. Additionally, the fine-tuning capabilities of LLMs ensure adaptability, supporting diverse and inclusive learning experiences~\cite{lee2024human}.

% rather than enforcing a one-size-fits-all approach.
