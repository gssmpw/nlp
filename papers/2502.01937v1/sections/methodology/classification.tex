\subsection{Classification and Labeling}

To mitigate potential subjective biases during the labeling phase, we allocated each of the \numbug merged bug-fix pull requests to two co-authors, who are also contributors and developers of both Apollo and Autoware open-source projects and possess enough background in the ADS domain. 
We employed the open-coding strategy of intercoder reliability~\cite{intercoder_reliability} to help strengthen the labeling process.
Our methodology necessitated that each co-author independently assess the bug, which involved meticulous examination of the source code, commit logs, code reviews, pull request information, and associated issue descriptions to recognize the labeling items.

In our work, we commenced with the root cause and symptom taxonomies in a previous ADS bug study~\cite{GarciaF0AXC20} and also taxonomy of generic \bfps focusing on the syntactic level~\cite{PanKW09,SotoTWGL16,CamposM17,IslamZ20}
as a foundation for ADS bug analysis. 
The taxonomy of root causes was subsequently augmented by employing an open-coding paradigm, thereby broadening the spectrum. 
For the pull request that eluded classification within the foundational taxonomy, each co-author designated a label for it. Post-labeling, co-authors collaboratively reconciled any discrepancies in their classifications. 
We added two root causes, \textbf{Syntax, Naming, and Typography (SNT)} that involves errors in the basic structure of the code, including syntactical mistakes, naming conventions, and typographical errors, and \textbf{Dependency Issues (DEP)} related to importing, versioning, and managing dependencies.

For semantic \bfps ~\yuntianyihl{and \bfas}, none of the previous work could provide a useful taxonomy due to the domain-specific nature of ADS. In this research, the open coding process was employed to refine and identify distinct semantic \bfps~\yuntianyihl{and \bfas}.
A preliminary investigation was conducted involving two co-authors who independently examined the bug fixes to establish a tentative classification framework. Each rater recommended a series of categories, which were later amalgamated and refined during a face-to-face session attended by all contributing authors. This meeting served as a platform to validate and integrate the classification schemes proposed by the individual raters. This reconciliation process led to updates in the classification scheme. 
\yuntianyihl{We validated the final classification by consulting with researchers in the ADS domain and developers from Apollo and Autoware. Their expertise helped refine the classification scheme, and we relabeled the affected pull requests accordingly.}
The classification result is presented in \autoref{sec:taxonomy}.
Our findings indicated that a single bug origin may result in multiple symptoms and \bfps. Therefore, certain bugs were cataloged into multiple categories, unlike the previous study~\cite{GarciaF0AXC20} only considered a single symptom for each bug.
In the process of labeling, two co-authors, possessing expertise in ADS, were engaged to categorize the \bfps according to the specified schema. 
The degree of concordance between these raters was quantified using Cohen's Kappa coefficient~\cite{VieiraKS10}, which was used by a recent \bfp study~\cite{IslamPNR20}. 
In instances of labeling discrepancies, periodic discussions were conducted to achieve reconciliation. 
Throughout this process, the Kappa score persistently exceeded 80\%, indicative of a robust understanding and unanimous agreement among the raters~\cite{mchugh2012interrater}.
