\begin{abstract}
A hallmark of human intelligence is the ability to create complex artifacts through structured multi-step processes. Generating procedural tutorials with AI is a longstanding but challenging goal, facing three key obstacles: (1) scarcity of multi-task procedural datasets, (2) maintaining logical continuity and visual consistency between steps, and (3) generalizing across multiple domains. To address these challenges, we propose a multi-domain dataset covering 21 tasks with over 24,000 procedural sequences. Building upon this foundation, we introduce MakeAnything, a framework based on the diffusion transformer (DIT), which leverages fine-tuning to activate the in-context capabilities of DIT for generating consistent procedural sequences. We introduce asymmetric low-rank adaptation (LoRA) for image generation, which balances generalization capabilities and task-specific performance by freezing encoder parameters while adaptively tuning decoder layers. Additionally, our ReCraft model enables image-to-process generation through spatiotemporal consistency constraints, allowing static images to be decomposed into plausible creation sequences.  Extensive experiments demonstrate that MakeAnything surpasses existing methods, setting new performance benchmarks for procedural generation tasks. Code is released at \href{https://github.com/showlab/MakeAnything}{https://github.com/showlab/MakeAnything}
\end{abstract}


% 人类智能的一个标志是能够通过结构化的多步骤过程创造复杂的工艺品。让AI生成连贯的创作教程是一直想要但是困难的，面临三个挑战：（1）多任务过程数据集的稀缺（2）在步骤之间保持逻辑连续性和视觉一致性，以及 （3）多个领域的泛化。我们收集了多任务数据集，涵盖了21个任务，共计超过24,000个序列。提出了一个基于扩散变换器（DIT）的框架MakeAnything，通过微调激活DiT的in-context 能力来生成前后一致的过程序列。我们为图像生成引入了非对称低秩适应（LoRA），通过冻结编码器参数同时适应性调整解码器层在泛化能力与任务特定性能之间实现平衡。此外，我们的ReCraft模型通过时空一致性约束实现了从图像到过程的生成，允许将静态图像分解为合理的创造序列。广泛的实验表明，MakeAnything 超越了现有方法，为流程生成任务设立了新的性能基准。



% 人类智能的一个标志是能够以逐步方式创造复杂的人工制品。然而，为绘画、手工制作和烹饪等任务生成多步骤的流程仍然充满挑战。我们提出了 **MakeAnything**，一个利用扩散变换器（Diffusion Transformer, DIT）生成高质量指令序列的框架。我们精心构建的数据集涵盖了绘画、手工制作、SVG创建、乐高搭建和烹饪等21个类别，共计超过15,000个序列。为减轻在小规模类别上的过拟合问题，我们采用了非对称LoRA策略，在泛化能力与任务特定性能之间实现平衡。此外，我们引入了 **ReCraft**，支持将现有图像分解为一致的逐步序列，以及 **Strategy Adapter**，通过少量样本快速适应未见任务的需求。广泛的实验表明，MakeAnything 超越了现有方法，为流程生成任务设立了新的性能基准。

% % 图
%1. 又大又好看的teaser 概括任务，text2， image2， 策略encoder？
%2. method illustrator （simple）(可选）
%3. method illustrator （detail）
%4. dataset 统计图，类型和比重, 合成数据方案
%5. 结果图，text2， image2，策略encoder, 拼大图
%6. 类内泛化，类间泛化， real world application
%7. 对比实验结果, with PP
%8. 消融实验, 1. 不对称LORA 2. 

% 表
% T1， 对比实验定量结果
% T2， 我们方法的评估结果， FID？， GPT4 score
% T3， User study结果

% 文字
% 1. 方法细节， 公式化描述，  策略 encoder？ 讲清楚最关键的不对称LORA和 泛化。 和IC LORA区别！！位置编码！！ 4帧数据LORA 如何出9帧
% 2. Relate work 缩减篇幅
% 3. 讨论实验结果，过程策略的异同，雕刻减法策略， 绘画加法策略， 转变过程（变形金刚，烹饪）same prompt, different B
% 4. Userstudy 细节
% 5. 图和表的分析

%数据集概念的分布不均匀

% motivation， 每个模块的motivation， key insights， finding， 如何组合这些Blora? 不同B加权


% 实验
% 1. Flux LoRA Merge, replace ReCraft baseModel
% 2. Strategy Adapter training
% 3. VAE pintu, S dataset



% Todo：1.teaser 改caption 2.Adapter 3 图3大小写 4.图表分析 5.检查引用