
\section{Experiment}

\subsection{Experimental Setting}
% 我们基于预训练的Flux 1.0 dev 实现了MakeAnything. 我们基于Kohayss的Flux LoRA训练代码，并将优化器从Adam优化器换为CAME优化器，实验发现这一设置能获得更好的生成质量。不对称LoRA和ReCraft model训练阶段，分辨率被设置为1024*1024， LoRA rank 64， 学习率 1e-4， batch size 2。 不对称LoRA和ReCraft model分别训练40000step和15000step。 

\textbf{Setup.} We implemented MakeAnything based on the pre-trained Flux 1.0 dev. We replaced the Adam optimizer with the CAME optimizer, and experiments showed that this setup achieved better generation quality. During the training phases of Asymmetric LoRA and the ReCraft model, the resolution was set to 1024, LoRA rank was 64, learning rate was 1e-4, and batch size was 2. Asymmetric LoRA and the ReCraft model were trained for 40,000 steps and 15,000 steps, respectively.

% The Strategy Adapter leverages the pre-trained model of InstantX Flux IP-Adapter. The number of image tokens is set to 128, and the model is trained on the 100k dataset with a batch size of 128 over 30k training steps.

\textbf{Baselines.} In the Text-to-Sequence task, we compare our approach with state-of-the-art baseline methods, namely ProcessPainter \cite{processpainter}, Flux 1.0 \cite{flux}, and the commercial API Ideogram \cite{ideogram}. We categorize the test prompts into two types: painting and others, because some baselines only support painting. In the Image-to-Sequence task, our baselines are Inverse Painting \cite{inverse} and PaintsUndo \cite{paintsundo}, which are capable of predicting the creation process of a painting.

% 在Text-to-Tutorial 任务中， 我们和最先进的baseline方法对比，分别是ProcessPainter，Flux 1.0, 商业API Ideogram，我们将测试prompt分为绘画和其他两类，因为部分baseline仅支持绘画。
% 在Image-to-Tutorial 任务中，我们对比的baseline是Inverse Painting 和 PaintsUndo， 可以预测画作的创作过程。

\textbf{Evaluation Metrics.} A good procedural sequence needs to be coherent, logical, and useful; however, evaluating procedural sequence generation and its rationality lacks precedents. We employ the CLIP Score to assess the text-image alignment of the generated results. Additionally, we evaluate the coherence and usability of the generated results using GPT-4o and human evaluations. Specifically, we meticulously design the input prompts for GPT-4o and scoring rules to align with human preferences.  In the comparative experiments, we concatenate the results from various baselines with our results, input them into GPT-4o all at once, and have it select the best results across different evaluation dimensions.

% 一个好的教程需要是连贯的、合逻辑的并且有用的；然而，评估教程生成及其合理性还没有先例。我们采用CLIP得分来评估生成结果的文本-图像对齐。此外，我们还使用PT4-o和人类评估来评价生成结果的连贯性和实用性。具体来说，我们精心设计了GPT-4o的输入提示和评分规则，以符合人类的偏好。在比较实验中，我们将不同基准的结果与我们的结果进行拼接，一次性输入GPT-4o，并让其选择在不同评价维度上最好的结果。

% \begin{table*}[ht]
% \centering
% \tiny % Makes the font smaller than \footnotesize
% \caption{Evaluation of Tutorial Generation Model Across Different Tasks}
% \label{tab:task_evaluation}
% \begin{tabular}{m{1.5cm} c c c m{1.5cm} c c c m{1.5cm} c c c}
% \toprule % Top line
% \multicolumn{12}{c}{\textbf{GPT Evaluation}} \\
% \midrule
% \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} & \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} & \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} \\ 
% \midrule
% Painting & 4.50 & 4.80 & 4.60 & Sketch & 4.10 & 4.70 & 4.10 & Sand Art & 4.20 & 4.70 & 4.30 \\
% Portrait & 4.25 & 5.00 & 4.05 & Icon & 2.75 & 3.45 & 2.65 & Landscape Ill. & 4.55 & 4.85 & 4.50 \\
% Illustration & 2.35 & 3.40 & 2.45 & LEGO & 4.60 & 4.90 & 4.75 & Transformer & 4.75 & 4.90 & 4.75 \\
% Cook & 3.20 & 4.25 & 3.65 & Clay Toys & 4.30 & 4.50 & 4.20 & Pencil Sketch & 3.85 & 4.50 & 3.80 \\
% Chinese Painting & 4.80 & 4.90 & 4.70 & Fabric Toys & 4.35 & 4.6 & 4.4 & Oil Painting & 4.90 & 4.95 & 4.85 \\
% Wood Sculpture & 4.65 & 4.85 & 4.65 & Clay Sculpture & 4.30 & 4.50 & 4.20 & Brush Modeling & 4.20 & 4.15 & 4.05 \\
% Jade Carving & 4.90 & 4.85 & 4.75 & Line Draw & 4.10 & 4.20 & 3.90 & Emoji & 2.55 & 2.45 & 2.20 \\
% % \bottomrule % Bottom line
% \midrule
% \multicolumn{12}{c}{\textbf{Human Evaluation}} \\
% \midrule % Middle line
% \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} & \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} & \textbf{Task} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} \\
% \midrule % Middle line
% Painting & & & & Sketch & & & & Sand Art & & & \\
% Portrait & & & & Icon & & & & Landscape Ill. & & & \\
% Illustration & & & & LEGO & & & & Transformer & & & \\
% Cook & & & & Clay Toys & & & & Pencil Sketch & & & \\
% Chinese Painting & & & & Fabric Toys & & & & Oil Painting & & & \\
% Wood Sculpture & & & & Clay Sculpture & & & & Brush Modeling & & & \\
% Jade Carving & & & & Line Draw & & & & Emoji & & & \\
% \bottomrule % Bottom line
% \end{tabular}
% \end{table*}

\begin{table}[ht]
\centering
\tiny % Makes the font smaller than \footnotesize
\caption{Combined Evaluation of Procedural Sequence Generation Results Across Different Tasks. Abbreviations: G = GPT score, H = Human evaluation, C = CLIP score.}
\label{tab:task_evaluation}
\begin{tabular}{l c c c}
\toprule % Top line
\textbf{Task} & \textbf{Alignment (G \textbar\ H \textbar\ C)} & \textbf{Coherence (G \textbar\ H)} & \textbf{Usability (G \textbar\ H)} \\ 
\midrule
Painting & 4.50 \textbar\ 4.27 \textbar\ 34.24 & 4.80 \textbar\ 3.98 & 4.60 \textbar\ 4.13 \\
Sketch & 4.10 \textbar\ 3.97 \textbar\ 29.35 & 4.70 \textbar\ 4.11 & 4.10 \textbar\ 4.13 \\
Sand Art & 4.20 \textbar\ 4.30 \textbar\ 31.82 & 4.70 \textbar\ 4.12 & 4.30 \textbar\ 4.18 \\
Portrait & 4.25 \textbar\ 4.28 \textbar\ 33.84 & 5.00 \textbar\ 4.28 & 4.05 \textbar\ 4.33 \\
Icon & 3.45 \textbar\ 4.33 \textbar\ 31.46 & 3.50 \textbar\ 4.17 & 3.15 \textbar\ 4.25 \\
Landscape Ill. & 4.55 \textbar\ 4.28 \textbar\ 32.25 & 4.85 \textbar\ 3.95 & 4.50 \textbar\ 4.12 \\
Illustration & 3.12 \textbar\ 4.17 \textbar\ 31.68 & 3.40 \textbar\ 4.07 & 2.45 \textbar\ 4.07 \\
LEGO & 4.60 \textbar\ 4.32 \textbar\ 34.40 & 4.90 \textbar\ 4.15 & 4.75 \textbar\ 4.00 \\
Transformer & 4.75 \textbar\ 4.30 \textbar\ 33.03 & 4.90 \textbar\ 4.23 & 4.75 \textbar\ 4.15 \\
Cook & 3.20 \textbar\ 4.21 \textbar\ 34.41 & 4.25 \textbar\ 4.03 & 3.65 \textbar\ 3.90 \\
Clay Toys & 4.30 \textbar\ 4.17 \textbar\ 35.25 & 4.50 \textbar\ 4.30 & 4.20 \textbar\ 4.30 \\
Pencil Sketch & 3.85 \textbar\ 4.33 \textbar\ 34.44 & 4.50 \textbar\ 4.20 & 3.80 \textbar\ 4.25 \\
Chinese Painting & 4.80 \textbar\ 4.37 \textbar\ 33.46 & 4.90 \textbar\ 4.22 & 4.70 \textbar\ 4.33 \\
Fabric Toys & 4.35 \textbar\ 4.30 \textbar\ 32.83 & 4.60 \textbar\ 4.08 & 4.40 \textbar\ 4.30 \\
Oil Painting & 4.90 \textbar\ 4.30 \textbar\ 37.30 & 4.95 \textbar\ 4.17 & 4.85 \textbar\ 4.20 \\
Wood Sculpture & 4.65 \textbar\ 4.32 \textbar\ 33.83 & 4.85 \textbar\ 4.23 & 4.65 \textbar\ 4.08 \\
Clay Sculpture & 4.30 \textbar\ 4.17 \textbar\ 35.25 & 4.50 \textbar\ 4.30 & 4.20 \textbar\ 4.30 \\
Brush Modeling & 4.20 \textbar\ 4.33 \textbar\ 32.27 & 4.15 \textbar\ 4.03 & 4.05 \textbar\ 4.25 \\
Jade Carving & 4.90 \textbar\ 4.28 \textbar\ 32.93 & 4.85 \textbar\ 4.12 & 4.75 \textbar\ 4.00 \\
Line Draw & 4.10 \textbar\ 4.20 \textbar\ 30.76 & 4.20 \textbar\ 3.97 & 3.90 \textbar\ 4.08 \\
Emoji & 3.75 \textbar\ 4.25 \textbar\ 34.20 & 3.60 \textbar\ 4.17 & 3.80 \textbar\ 4.18 \\
\bottomrule % Bottom line
\label{tab1}
\end{tabular}
\end{table}





% \begin{table}[ht]
% \centering
% \tiny % Makes the font smaller than \footnotesize
% \caption{Compare with Text-to-Tutorial methods (GPT)}
% \label{tab:task_evaluation}
% \begin{tabular}{c c c c c c}
% \toprule % Top line
% \textbf{Category} & \textbf{Methods} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} \\ 
% \midrule % Middle line
% \multirow{4}{*}{Painting} & Processpainter & 0.24 & 0.26 & 0.22 \\
%                                 & Ideogram & 0.32 & 0.14 & 0.26 \\
%                                 & Flux & 0.02 & 0.04 & 0.00 \\
%                                 & Ours & \textbf{0.42} & \textbf{0.56} & \textbf{0.52} \\
% \midrule % Separate section
% \multirow{3}{*}{Others} & Ideogram & 0.36 & 0.30 & 0.32 \\
%                       & Flux & 0.28 & 0.28 & 0.30 \\
%                       & Ours & \textbf{0.36} & \textbf{0.42} & \textbf{0.38} \\
% \bottomrule % Bottom line
% \label{tab2}
% \end{tabular}
% \end{table}


% \begin{table}[ht]
% \centering
% \tiny % Makes the font smaller than \footnotesize
% \caption{Compare with Image-to-Tutorial methods (GPT)}
% \begin{tabular}{c c c c c c}
% \toprule % Top line
% \textbf{Category} & \textbf{Methods} & \textbf{Consistency} & \textbf{Coherence} & \textbf{Usability} \\ 
% \midrule % Middle line
% \multirow{3}{*}{Painting} & Inverse Paints & 0.02 & 0.00 & 0.02 \\
%                                 &PaintsUndo  & 0.18 & 0.30 & 0.24 \\
%                                 &Ours & \textbf{0.80} & \textbf{0.70} & \textbf{0.74} \\
% \bottomrule % Bottom line
% \label{tab3}
% \end{tabular}
% \end{table}


% \begin{table}[ht]
% \centering
% \tiny % Makes the font smaller than \footnotesize
% \caption{Compare with Text-to-Tutorial methods (Human)}
% \label{tab:task_evaluation}
% \begin{tabular}{c c c c c c}
% \toprule % Top line
% \textbf{Category} & \textbf{Methods} & \textbf{Alignment} & \textbf{Coherence} & \textbf{Usability} \\ 
% \midrule % Middle line
% \multirow{4}{*}{Painting} & Processpainter & 0.06 & 0.10 & 0.14   \\
%                                 & Ideogram & 0.06 & 0.06  & 0.10 \\
%                                 & Flux & 0.21 & 0.15 & 0.13 \\
%                                 & Ours & \textbf{0.67} & \textbf{0.69} & \textbf{0.63} \\
% \midrule % Separate section
% \multirow{3}{*}{Others} & Ideogram & 0.19 & 0.19 & 0.17 \\
%                       & Flux & 0.11 & 0.13 & 0.12 \\
%                       & Ours & \textbf{0.70} & \textbf{0.68} & \textbf{0.71} \\
% \bottomrule % Bottom line
% \label{tab4}
% \end{tabular}
% \end{table}


% \begin{table}[ht]
% \centering
% \tiny % Makes the font smaller than \footnotesize
% \caption{Compare with Image-to-Tutorial methods (Human)}
% \begin{tabular}{c c c c c c}
% \toprule % Top line
% \textbf{Category} & \textbf{Methods} & \textbf{Consistency} & \textbf{Coherence} & \textbf{Usability} \\ 
% \midrule % Middle line
% \multirow{3}{*}{Painting} & Inverse Paints & 0.27 & 0.31  & 0.33 \\
%                                 &PaintsUndo  & 0.18 & 0.08 & 0.06 \\
%                                 &Ours & \textbf{0.55} & \textbf{0.61} & \textbf{0.61}  \\
% \bottomrule % Bottom line
% \label{tab5}
% \end{tabular}
% \end{table}





\subsection{Experimental Results}
% 图 \ref{fig4}(a) 展示了从文本描述生成过程序列的结果。得益于高质量数据集、健壮的预训练模型和创新的方法设计，MakeAnything一致地产生了高质量和逻辑连贯的过程序列。表1展示了MakeAnything在21个任务上的定量评估结果，包括GPT和人工评分， 每个ren w

% 图 \ref{fig4}(b) 突出显示了模型基于输入图像生成过程序列的能力。结果显示生成的序列与原始图像内容高度一致。这展示了模型解释复杂视觉输入并重构逻辑一致的创作过程的能力，使其能够在逆向工程和教育教程等多个领域中应用。

Fig. \ref{fig4}(a) showcases the results of generating process sequences from textual descriptions. Benefiting from high-quality datasets, a robust pre-trained model, and an innovative method design, MakeAnything consistently produces high-quality and logically coherent process sequences. Table \ref{tab1} presents the quantitative evaluation results of MakeAnything across 21 tasks, including scores from GPT and human assessments, with 20 sequences generated per task, with 20 sequences generated per task.

Fig. \ref{fig4}(b) highlights the model's ability to generate process sequences conditioned on input images. The results indicate a high degree of alignment between the generated sequences and the original image content. This showcases the model's capacity to interpret complex visual inputs and reconstruct logically consistent creation processes, enabling its application in diverse fields such as reverse engineering and educational tutorials.

% 图4 (c) 展示了MakeAnything 在unseen domain 上的结果，我们从civitai网站收集了 水彩、浮雕、冰雕、衍纸画等LoRA，并和我们的教程LoRA组合使用。可以看出，MakeAnything展示出相当不错的泛化能力，尽管训练时没有见过这些题材的创作过程。

Fig. \ref{fig4}(c) shows the results of MakeAnything in unseen domains. We collected various LoRAs from the Civitai \cite{civitai2025} website, including watercolor, relief, ice sculpture, and paper quilling art, and combined them with our procedural LoRA. It is evident that MakeAnything demonstrates quite impressive generalization capabilities, despite not having been trained on these creative processes.


\begin{figure*}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{images/ablation.pdf} % Replace with your image file
    \vspace{-4mm}
    \caption{Ablation study results.}
    \vspace{-4mm}
    \label{fig6}
\end{figure*}

\begin{figure}[htp]
    \centering
    \includegraphics[width=1.0\linewidth]{images/userstudyf.pdf} % Replace with your image file
    \caption{Comparison results on three tasks, evaluated by GPT and humans respectively.}
    \vspace{-2mm}
    \label{fig7}
\end{figure}


\subsection{Comparation and  Evaluation} 
This section consolidates the comparative evaluations of our method against baseline approaches on 50 sequence groups. Fig. \ref{fig5}(a) and (b), demonstrate that MakeAnything produces higher quality procedural sequence with superior logic and coherence, unlike the baseline methods which struggle with consistency. Fig. \ref{fig5}(c) compares the ReCraft model to a baseline, highlighting our method's training on diverse real data, resulting in varied and authentic creative processes. Quantitative results in  Fig. \ref{fig7} confirm MakeAnything's superiority in Text-Image Alignment, Coherence, and Usability across all tested metrics.

% 这一节整合了我们的方法与基线方法的比较评估， 测试集的为50组序列. 如图5(a)和(b)所示，MakeAnything生成的教程质量更高，逻辑和连贯性也更好，而基线方法则在一致性上存在问题。图5(c)展示了ReCraft模型与基线方法的比较结果，我们的方法在多样的真实数据上进行训练，而不仅仅是合成数据或人类绘画序列的模拟，这使得生成的绘画过程更加多样化且贴近艺术家的实际创作过程。图6的定量评估结果也证明了MakeAnything在文本-图像对齐、连贯性和可用性所有测试指标上的领先。

% This section presents the comparative results between our method and the baseline approaches. As shown in Fig. \ref{fig5}(a) and (b), MakeAnything generates tutorials of higher quality, whereas the baseline methods fail to produce consistent procedural sequences, lacking in logic and coherence.  Fig. \ref{fig6} displays the quantitative evaluation results, where MakeAnything excels in Text-Image Alignment, Coherence, and Usability.

% Fig. \ref{fig5}(c) illustrates the comparison results between the ReCraft model and the baseline method. The baseline method employs a uniform process strategy, whereas our method is trained on a diverse set of real data, not synthetic data or simulations of human painting sequences. This enables the generation of various types of painting processes that align more closely with artists' actual creative processes. Fig. \ref{fig6} shows the quantitative evaluation results, with our method leading across all metrics.

% 本节展示本文方法和baseline方法的对比结果， 如图5所示， MakeAnything 教程生成结果质量更高，baseline方法并不能稳定的生成过程序列，逻辑性和一致性不足。表3展示了定量评估结果，MakeAnything在 Text-Image Align， Coherence， 和Usability上取得了最好的结果。 

% 图5展示了ReCraft model和baseline method的对比结果，baseline 方法生成的过程策略单一， 我们的方法在多样的真实数据上训练，而不是合成数据或对人类绘画顺序的模拟，能够生成不同种类的绘画过程， 结果和画家的创作过程更一致。 图6 展示了GPT和人类评估结果， 我们的方法在所有指标上取得领先。


\subsection{User Study}
% 为了充分研究MakeAnything的有效性和改进方向， 我们进行了详细的用户研究。我们设计了问卷，将本文方法的结果和baseline方法的结果同时展示，让用户选择 Alignment、Coherence、Usability、Consistency 更好的序列。图7展示了用户研究结果，MakeAnything的结果全面领先。此外我们收集了用户对MakeAnything的改进建议。一些用户表示，创建过程希望是图文并茂的，加入必要的文字介绍。一些用户认为更详细的过程是有用的，4帧的创建过程在有些任务上不够详细。

% To thoroughly evaluate the effectiveness of {MakeAnything and identify potential areas for improvement, we conducted a detailed user study. A questionnaire was designed to gather user preferences, asking participants to select the most preferred and the most helpful process sequences. Fig. \ref{fig7} presents the results of the user study, showing that MakeAnything outperformed all competitors comprehensively. 

To comprehensively evaluate MakeAnything's effectiveness, we conducted a user study comparing our method against baselines. Participants rated sequences across four metrics: Alignment (text-image similarity), Coherence (logical step progression), Usability (practical value), and Consistency (consistency between image condition). As shown in Fig. \ref{fig7}, MakeAnything demonstrates comprehensive superiority across all metrics. 


%此外我们收集了用户对MakeAnything的改进建议。一些用户表示，创建过程希望是图文并茂的，加入必要的文字介绍。一些用户认为更详细的过程是有用的，4帧的创建过程在有些任务上不够详细。

% Additionally, we collected user feedback on how to improve MakeAnything. Some users have expressed a desire for the creation process to be illustrated with both images and necessary textual descriptions. Some users believe that a more detailed process is useful, as a 4-frame creation process is not sufficiently detailed for some tasks.


\subsection{Ablation Study} 
% 本节，我们对 不对称LoRA的进行了消融实验，图6对比了肖像生成 和 sketch生成的效果。前者在50张肖像绘画序列上训练， 后者在300张卡通角色 sketch 序列上训练。我们对比了，base model 的结果、标准LoRA的结果，和采用对不对称LoRA，共享A矩阵的结果。从结果可以看出，尽管base model无法生成合理的分步骤结果，但是text following整体不错。采用标准LoRA在类别分布不均匀的小数据上训练导致了严重的过拟合，虽然分步骤的过程合理，text-image alignment 显著变差。 而采用不对称LoRA结果很好的兼顾过程合理性和text-image alignment。我们认为在海量过程数据上训练的A矩阵学习到了更多通用的知识，有利于缓解过拟合。表2展示了在更多任务上的定量实验结果，进一步证实结论。

% In this section, we conducted ablation experiments on asymmetric LoRA, and Fig. \ref{fig6} compares the results of portrait and sketch tutorial generation task. The former was trained on 50 portrait painting sequences, while the latter was trained on 300 cartoon character sketch sequences. We compared the results of the base model, standard LoRA, and asymmetric LoRA with a shared A matrix. The results show that although the base model fails to generate reasonable step-by-step results, the text following is overall quite good. Training standard LoRA on small datasets with uneven category distribution led to severe overfitting; although the step-by-step process was reasonable, text-image alignment significantly worsened. In contrast, using asymmetric LoRA effectively balanced process rationality and text-image alignment. We believe that the A matrix, trained on a massive amount of procedural data, learned more general knowledge, helping to mitigate overfitting. Table. \ref{ab} presents quantitative experimental results on additional tasks, further confirming the conclusions.

In this section, we conducted ablation experiments on asymmetric LoRA, and Fig. \ref{fig6} compares the results of portrait and sketch tutorial generation task. The former was trained on 50 portrait painting sequences, while the latter was trained on 300 cartoon character sketch sequences. While the base model produces coherent text but fails in step-by-step synthesis, standard LoRA exhibits severe overfitting on small datasets with imbalanced class distributions—yielding plausible steps but compromised text-image alignment. Our method achieves both procedural rationality and text-image alignment by leveraging knowledge from large-scale pretraining. Quantitative results across more tasks (Table~\ref{ab}) further validate these findings.

\begin{table}[ht]
\centering
\tiny % Makes the font smaller than \footnotesize
\caption{Ablation Study Results Using GPT Evaluation and CLIP Score.}  
\label{tab:task_evaluation}
\begin{tabular}{ccccc}
\toprule % Top line
\textbf{Model} & \textbf{Task} & \textbf{Alignment(G \textbar\ C)} & \textbf{Coherence} & \textbf{Usability} \\ 
\midrule % Middle line
\multirow{3}{*}{Base Model} & Portrait & 3.75\textbar\ 29.78 & 3.45 & 3.35 \\
                                & Wood & 3.25\textbar\ \textbf{35.29}  & 2.95 & 2.65 \\
                                & Fabric toys & 3.55\textbar\ \textbf{32.95}  & 4.00 & 3.85 \\
\midrule % Middle line
\multirow{3}{*}{w/o Asymmetric LoRA} & Portrait & 4.25\textbar\ 31.08  & 4.50 & 4.15 \\
                                & Wood Sculpture & 3.55\textbar\ 31.05  & \textbf{4.35} & 3.75 \\
                                & Fabric toys & 3.75\textbar\ 30.72  & 3.15 & 3.20 \\
\midrule % Separate section
\multirow{3}{*}{Full} & Portrait & \textbf{4.55}\textbar\ \textbf{32.95}  & \textbf{4.75} & \textbf{4.25} \\
                      & Wood Sculpture & \textbf{4.25}\textbar\ 33.89  & 3.80 & \textbf{4.05} \\
                      & Fabric toys & \textbf{4.40}\textbar\ 32.01  & \textbf{4.25} & \textbf{4.35} \\
\bottomrule % Bottom line
\label{ab}
\end{tabular}
\end{table}


\section{Limitations and Future Work}
The current grid-based composition strategy in MakeAnything introduces two inherent limitations: constrained output resolution (max 1024×1024) and fixed frame count (up to 9 steps). We plan to address these limitations in future work, enabling arbitrary-length sequence generation with high-fidelity outputs.

% MakeAnything中当前的基于网格的构图策略引入了两个固有的限制：受限的输出分辨率（最高1024×1024）和固定的帧数（最多9步）。这些限制源于我们的设计选择，通过空间平铺来统一多帧生成。我们计划在未来的工作中解决这些限制，从而实现具有高保真输出的任意长度序列生成。

\section{Conclusion}
We introduced MakeAnything, a novel framework for generating high-quality process sequences using the DiT model with LoRA fine-tuning. By leveraging multi-domain procedural dataset and adopting an asymmetric LoRA design, our approach effectively balances generalization and task-specific performance. Additionally, the image-conditioned plugin enables controllable and interpretable sequence generation. Extensive experiments demonstrated the superiority of our method across diverse tasks, establishing a new benchmark in this field. Our contributions pave the way for further exploration of step-by-step process generation, opening up exciting possibilities in computer vision and related applications.

% 在本文中，我们提出了MakeAnything，这是一种通过DiT模型结合LoRA微调生成高质量过程序列的新颖框架。通过利用精心收集的多领域数据集并采用不对称LoRA设计，我们的方法有效地平衡了泛化能力和任务特定性能。此外，图像条件插件支持可控且可解释的序列生成。广泛的实验表明，我们的方法在各种任务上表现出色，确立了该领域的新基准。我们的贡献为进一步探索逐步过程生成开辟了新途径，为计算机视觉及相关应用带来了激动人心的可能性。