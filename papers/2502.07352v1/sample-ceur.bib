
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@misc{george1949zipf,
  title={Zipf. Human behavior and the principle of least effort},
  author={George, K},
  year={1949},
  publisher={Addison-Wesley}
}

@inproceedings{papadimitriou1998LSI,
  title={Latent semantic indexing: A probabilistic analysis},
  author={Papadimitriou, Christos H and Tamaki, Hisao and Raghavan, Prabhakar and Vempala, Santosh},
  booktitle={Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems},
  pages={159--168},
  year={1998}
}

@article{blei2003LDA,
  title         = {Latent dirichlet allocation},
  author        = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal       = {Journal of machine Learning research},
  volume        = {3},
  number        = {Jan},
  pages         = {993--1022},
  year          = {2003},
  URL           = {https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=http://githubhelp.com}
}

@article{mcauliffe2007sLDA,
  title={Supervised topic models},
  author={Mcauliffe, Jon and Blei, David},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@inproceedings{wang2011CTR,
  title={Collaborative topic modeling for recommending scientific articles},
  author={Wang, Chong and Blei, David M},
  booktitle={Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={448--456},
  year={2011},
  url={https://dl.acm.org/doi/pdf/10.1145/2020408.2020480?casa_token=UGUJF7fZ6GUAAAAA:waueAG1puyy2FUPBTCy2AlQmss76XGQ-ry6Zy6NW-qp14GudXSUAYrsup6LL9Ic5uJqIUxYa6k3A}
}

@inproceedings{kingma2014stochastic,
  title         ={Stochastic gradient VB and the variational auto-encoder},
  author        ={Kingma, Diederik P and Welling, Max},
  booktitle     ={Second international conference on learning representations, ICLR},
  volume        ={19},
  pages         ={121},
  year          ={2014}
}

@inproceedings{rezende2014stochastic,
  title         ={Stochastic backpropagation and variational inference in deep latent gaussian models},
  author        ={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle     ={International conference on machine learning},
  volume        ={2},
  pages         ={2},
  year          ={2014},
  URL           ={https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=aac82518e8a27669db11c1a372a88db05ade1c6d}
}

@article{Gerlach2019,
    title={A universal information theoretic approach to the identification of stopwords},
    author={Gerlach M, Shi H, Amaral LAN},
    abstract={One of the most widely used approaches in natural language processing and information retrieval is the so-called bag-of-words model. A common component of such methods is the removal of uninformative words, commonly referred to as stopwords. Currently, most practitioners use manually curated stopword lists. This approach is problematic because it cannot be readily generalized across knowledge domains or languages. As a result of the difficulty in rigorously defining stopwords, there have been few systematic studies on the effect of stopword removal on algorithm performance, which is reflected in the ongoing debate on whether to keep or remove stopwords. Here we address this challenge by formulating an information theoretic framework that automatically identifies uninformative words in a corpus. We show that our framework not only outperforms other stopword heuristics, but also allows for a substantial reduction of document size in applications of topic modelling. Our findings can be readily generalized to other bag-of-words-type approaches beyond language such as in the statistical analysis of transcriptomics, audio or image corpora.},
    journal={Nature Machine Intelligence},
    volume={1},
    doi={10.1038/s42256-019-0112-6},
    year={2019},
    month={DEC},
    day={2},
    pages={606--612},
}

@inproceedings{sia-etal-2020-tired,
  title         = "Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics too!",
  author        = "Sia, Suzanna  and
      Dalmia, Ayush  and
      Mielke, Sabrina J.",
  editor        = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
  booktitle     = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
  month         = nov,
  year          = "2020",
  address       = "Online",
  publisher = "Association for Computational Linguistics",
  url           = "https://aclanthology.org/2020.emnlp-main.135",
  doi           = "10.18653/v1/2020.emnlp-main.135",
  pages         = "1728--1736",
  abstract      = "Topic models are a useful analysis tool to uncover the underlying themes within document collections. The dominant approach is to use probabilistic topic models that posit a generative story, but in this paper we propose an alternative way to obtain topics: clustering pre-trained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA. The best performing combination for our approach performs as well as classical topic models, but with lower runtime and computational complexity.",
}

@article{sarica2021stopwords,
  title={Stopwords in technical language processing},
  author={Sarica, Serhad and Luo, Jianxi},
  journal={Plos one},
  volume={16},
  number={8},
  pages={e0254937},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{zhang-etal-2022-neural,
  title         = "Is Neural Topic Modelling Better than Clustering? An Empirical Study on Clustering with Contextual Embeddings for Topics",
  author        = "Zhang, Zihan  and
                      Fang, Meng  and
                      Chen, Ling  and
                      Namazi Rad, Mohammad Reza",
  editor        = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
  booktitle     = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month         = jul,
  year          = "2022",
  address       = "Seattle, United States",
  publisher     = "Association for Computational Linguistics",
  url           = "https://aclanthology.org/2022.naacl-main.285",
  doi           = "10.18653/v1/2022.naacl-main.285",
  pages         = "3886--3893",
  abstract = "Recent work incorporates pre-trained word embeddings such as BERT embeddings into Neural Topic Models (NTMs), generating highly coherent topics. However, with high-quality contextualized document representations, do we really need sophisticated neural models to obtain coherent and interpretable topics? In this paper, we conduct thorough experiments showing that directly clustering high-quality sentence embeddings with an appropriate word selecting method can generate more coherent and diverse topics than NTMs, achieving also higher efficiency and simplicity.",
}


@inproceedings{frohmann-etal-2024-segment,
    title = "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation",
    author = "Frohmann, Markus  and
      Sterner, Igor  and
      Vuli{\'c}, Ivan  and
      Minixhofer, Benjamin  and
      Schedl, Markus",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.665",
    pages = "11908--11941"
}

@article{eichin2024semantic,
  title         ={Semantic Component Analysis: Discovering Patterns in Short Texts Beyond Topics},
  author        ={Eichin, Florian and Schuster, Carolin and Groh, Georg and Hedderich, Michael A},
  journal       ={arXiv preprint arXiv:2410.21054},
  year          ={2024}
}

@article{wu2024survey,
  title         ={A survey on neural topic models: methods, applications, and challenges},
  author        ={Wu, Xiaobao and Nguyen, Thong and Luu, Anh Tuan},
  journal       ={Artificial Intelligence Review},
  volume        ={57},
  number        ={2},
  pages         ={18},
  year          ={2024},
  publisher     ={Springer}
}

@Article{Abril07,
  author        = "Patricia S. Abril and Robert Plant",
  title         = "The patent holder's dilemma: Buy, sell, or troll?",
  journal       = "Communications of the ACM",
  volume        = "50",
  number        = "1",
  month         = jan,
  year          = "2007",
  pages         = "36--44",
  doi           = "10.1145/1188913.1188915",
  OPTurl           = "http://doi.acm.org/10.1145/1219092.1219093",
  note          = "",
}

@Article{Cohen07,
  author        = "Sarah Cohen and Werner Nutt and Yehoshua Sagic",
  title         = "Deciding equivalances among conjunctive aggregate queries",
  journal       = JACM,
  articleno     = "5",
  numpages      = "50",
  volume        = "54",
  number        = "2",
  month         = apr,
  year          = "2007",
  doi           = "10.1145/1219092.1219093",
  OPTurl           = "http://doi.acm.org/10.1145/1219092.1219093",
  acmid         = "1219093",
  note          = "",
}


@Proceedings{JCohen96,
  key =          "Cohen",
  editor =       "Jacques Cohen",
  title =        "Special issue: Digital Libraries",
  journal =      CACM,
  volume =       "39",
  number =       "11",
  month =        nov,
  year =         "1996",
}


@Book{Kosiur01,
  author =       "David Kosiur",
  title =        "Understanding Policy-Based Networking",
  publisher =    "Wiley",
  year =         "2001",
  address =      "New York, NY",
  edition =      "2nd.",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Harel79,
  author =       "David Harel",
  year =         "1979",
  title =        "First-Order Dynamic Logic",
  series =       "Lecture Notes in Computer Science",
  volume =       "68",
  address =      "New York, NY",
  publisher =    "Springer-Verlag",
  doi =          "10.1007/3-540-09237-4",
  OPTurl =          "http://dx.doi.org/10.1007/3-540-09237-4",
  editor =       "",
  number =       "",
  month =        "",
  note =         "",
}


@Inbook{Editor00,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book one",
  subtitle =     "The book subtitle",
  series =       "The name of the series one",
  year =         "2007",
  volume =       "9",
  address =      "Chicago",
  edition =      "1st.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  OPTurl =          "http://dx.doi.org/10.1007/3-540-09456-9",
  chapter =      "",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}

%
@InBook{Editor00a,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book two",
  subtitle =     "The book subtitle",
  series =       "The name of the series two",
  year =         "2008",
  address =      "Chicago",
  edition =      "2nd.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  OPTurl =          "http://dx.doi.org/10.1007/3-540-09456-9",
  volume =       "",
  chapter =      "100",
  pages =        "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Spector90,
  author =       "Asad Z. Spector",
  title =        "Achieving application requirements",
  booktitle =    "Distributed Systems",
  publisher =    "ACM Press",
  address =      "New York, NY",
  year =         "1990",
  edition =      "2nd.",
  chapter =      "",
  editor =       "Sape Mullender",
  pages =        "19--33",
  doi =          "10.1145/90417.90738",
  OPTurl =          "http://doi.acm.org/10.1145/90417.90738",
  volume =       "",
  number =       "",
  series =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Douglass98,
  author =       "Bruce P. Douglass and David Harel and Mark B. Trakhtenbrot",
  title =        "Statecarts in use: structured analysis and object-orientation",
  series =       "Lecture Notes in Computer Science",
  booktitle =    "Lectures on Embedded Systems",
  publisher =    "Springer-Verlag",
  address =      "London",
  volume =       "1494",
  year =         "1998",
  chapter =      "",
  editor =       "Grzegorz Rozenberg and Frits W. Vaandrager",
  pages =        "368--394",
  doi =          "10.1007/3-540-65193-4_29",
  OPTurl =          "http://dx.doi.org/10.1007/3-540-65193-4_29",
  edition =      "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


@Book{Knuth97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.)",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  year =         "1997",
  address =      "",
  edition =      "",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Knuth98,
  author =       "Donald E. Knuth",
  year =         "1998",
  title =        "The Art of Computer Programming",
  series =       "Fundamental Algorithms",
  volume =       "1",
  edition =      "3rd",
  address =      "",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  doi =          "",
  url =          "",
  editor =       "",
  number =       "",
  month =        "",
  note =         "(book)",
}

%Inbook{Knuth97,
%  author =       "Donald E. Knuth",
%  title =        "The Art of Computer Programming",
%  booktitle =    "the booktitle",
%  edition =      "3",
%  volume =       "1",
%  year =         "1997",
%  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
%  editor =       "",
%  number =       "",
%  series =       "Fundamental Algorithms",
%  type =         "",
%  chapter =      "",
%  pages =        "",
%  address =      "",
%  month =        "",
%  note =         "(inbook)",
%}

%INBOOK{DK:73-inbook-full,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (inbook w series)",
%   volume = 1,
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   edition = "Second",
%   month = "10~" # jan,
%   year = "1973",
%   type = "Section",
%   chapter = "1.2",
%   pages = "10--119",
%   note = "Full INBOOK entry (w series)",
%}

%INcollection{DK:74-incoll,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1974",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor",
%}

%INcollection{DK:75-incollws,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll w series)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1975",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor and series",
%}


@incollection{GM05,
Author= "Dan Geiger and Christopher Meek",
Title= "Structured Variational Inference Procedures and their Realizations (as incol)",
Year= 2005,
Booktitle="Proceedings of Tenth International Workshop on Artificial Intelligence and Statistics, {\rm The Barbados}",
Publisher="The Society for Artificial Intelligence and Statistics",
Month= jan,
Editors= "Z. Ghahramani and R. Cowell"
}

@Inproceedings{Smith10,
  author =       "Stan W. Smith",
  title =        "An experiment in bibliographic mark-up: Parsing metadata for XML export",
  booktitle =    "Proceedings of the 3rd. annual workshop on Librarians and Computers",
  series =       "LAC '10",
  editor =       "Reginald N. Smythe and Alexander Noble",
  volume =       "3",
  year =         "2010",
  publisher =    "Paparazzi Press",
  address =      "Milan Italy",
  pages =        "422--431",
  doi =          "99.9999/woot07-S422",
  OPTurl =          "http://dx.doi.org/99.0000/woot07-S422",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy07,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2007",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '07",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "7",
  numpages =     "9",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy08,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2008",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '08",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "7",
  numpages =     "2",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "99-100",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy09,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2009",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '09",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "",
  numpages =     "",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "90--100",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{Andler79,
  author =       "Sten Andler",
  title =        "Predicate Path expressions",
  booktitle =    "Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages",
  series =       "POPL '79",
  year =         "1979",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "226--236",
  doi =          "10.1145/567752.567774",
  OPTurl =          "http://doi.acm.org/10.1145/567752.567774",
  editor =       "",
  volume =       "",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Techreport{Harel78,
  author =       "David Harel",
  year =         "1978",
  title =        "LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         "",
}

@MASTERSTHESIS{anisi03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}


@Phdthesis{Clarkson85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        "",
}


@misc{Thornburg01,
  author =       "Harry Thornburg",
  year =         "2001",
  title =        "Introduction to Bayesian Statistics",
  url =          "http://ccrma.stanford.edu/~jos/bayes/bayes.html",
  month =        mar,
  lastaccessed = "March 2, 2005",
}


@misc{Ablamowicz07,
  author =       "Rafal Ablamowicz and Bertfried Fauser",
  year =         "2007",
  title =        "CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11",
  url =          "http://math.tntech.edu/rafal/cliff11/index.html",
  lastaccessed = "February 28, 2008",
}


@misc{Poker06,
  author =       "Poker-Edge.Com",
  year =         "2006",
  month =        mar,
  title =        "Stats and Analysis",
  lastaccessed = "June 7, 2006",
  url =          "http://www.pkredge.com/statsYYFWWQ.php",
}

@misc{Obama08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A more perfect union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  "",
}

@misc{JoeScientist001,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = "",
}


@Inproceedings{Novak03,
  author =       "Dave Novak",
  title =        "Solder man",
  booktitle =    "ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27--27, 2003)",
  year =         "2003",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "4",
  month =        "March 21, 2008",
  doi =          "99.9999/woot07-S422",
  url =          "http://video.google.com/videoplay?docid=6528042696351994555",
  note =         "",
  howpublished = "Video",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  organization = "",
}


@article{Lee05,
  author =       "Newton Lee",
  year =         "2005",
  title =        "Interview with Bill Kinder: January 13, 2005",
  journal =      "Comput. Entertain.",
  eid =          "4",
  volume =       "3",
  number =       "1",
  month =        "Jan.-March",
  doi =          "10.1145/1057270.1057278",
  OPTurl =          "http://doi.acm.org/10.1145/1057270.1057278",
  howpublished = "Video",
  note =         "",
}

@article{Rous08,
  author =       "Bernard Rous",
  year =         "2008",
  title =        "The Enabling of Digital Libraries",
  journal =      "Digital Libraries",
  volume =       "12",
  number =       "3",
  month =        jul,
  articleno =    "5",
  doi =          "",
  url =          "",
  howpublished = "",
  note =         "To appear",
}

@article{384253,
 author = {Werneck,, Renato and Setubal,, Jo\~{a}o and da Conceic\~{a}o,, Arlindo},
 title = {(old) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 year = {2000},
 issn = {1084-6654},
 pages = {11},
 doi = {10.1145/351827.384253},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@article{Werneck:2000:FMC:351827.384253,
 author = {Werneck, Renato and Setubal, Jo\~{a}o and da Conceic\~{a}o, Arlindo},
 title = {(new) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 month = dec,
 year = {2000},
 issn = {1084-6654},
 articleno = {11},
 OPTurl = {http://portal.acm.org/citation.cfm?id=351827.384253},
 doi = {10.1145/351827.384253},
 acmid = {384253},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(old) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 doi = {10.1016/j.inffus.2009.01.002},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Conti:2009:DDS:1555009.1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(new) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 month = oct,
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 numpages = {12},
 OPTurl = {http://portal.acm.org/citation.cfm?id=1555009.1555162},
 doi = {10.1016/j.inffus.2009.01.002},
 acmid = {1555162},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Clone detection, Distributed protocol, Securing data fusion, Wireless sensor networks},
}

@inproceedings{Li:2008:PUC:1358628.1358946,
 author = {Li, Cheng-Lun and Buyuktur, Ayse G. and Hutchful, David K. and Sant, Natasha B. and Nainwal, Satyendra K.},
 title = {Portalis: using competitive online interactions to support aid initiatives for the homeless},
 booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 pages = {3873--3878},
 numpages = {6},
 OPTurl = {http://portal.acm.org/citation.cfm?id=1358628.1358946},
 doi = {10.1145/1358628.1358946},
 acmid = {1358946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cscw, distributed knowledge acquisition, incentive design, online games, recommender systems, reputation systems, user studies, virtual community},
}

@book{Hollis:1999:VBD:519964,
 author = {Hollis, Billy S.},
 title = {Visual Basic 6: Design, Specification, and Objects with Other},
 year = {1999},
 isbn = {0130850845},
 edition = {1st},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
 }


@book{Goossens:1999:LWC:553897,
 author = {Goossens, Michel and Rahtz, S. P. and Moore, Ross and Sutor, Robert S.},
 title = {The  Latex Web Companion: Integrating TEX, HTML, and XML},
 year = {1999},
 isbn = {0201433117},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

% need to test genres for errant isbn output

% techreport
@techreport{897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

@techreport{Buss:1987:VTB:897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

% whole proceedings

@proceedings{Czerwinski:2008:1358628,
 author = {},
 note = {General Chair-Czerwinski, Mary and General Chair-Lund, Arnie and Program Chair-Tan, Desney},
 title = {CHI '08: CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 order_no = {608085},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

% phdthesis

@phdthesis{Clarkson:1985:ACP:911891,
 author = {Clarkson, Kenneth Lee},
 advisor = {Yao, Andrew C.},
 title = {Algorithms for Closest-Point Problems (Computational Geometry)},
 year = {1985},
 note = {AAT 8506171},
 school = {Stanford University},
 address = {Stanford, CA, USA},
 }
% school is being picked up -- but not publisher (which is OK)
% Also -- the title is NOT being output in italics !!! Arrrrgh! - I fixed it. :-)


%%% compare with 'old'
%%% atsign-Phdthesis{Clarkson85,
%%%  author =       "Kenneth L. Clarkson",
%%%  year =         "1985",
%%%  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
%%%  school =       "Stanford University",
%%%  address =      "Palo Alto, CA",
%%%  note =         "UMI Order Number: AAT 8506171",
%%%  type =         "",
%%%  month =        "",
%%%}

% A bibliography
@Article{1984:1040142,
 key = {{$\!\!$}},
 journal = {SIGCOMM Comput. Commun. Rev.},
 year = {1984},
 issn = {0146-4833},
 volume = {13-14},
 number = {5-1},
 issue_date = {January/April 1984},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


% grinder
@inproceedings{2004:ITE:1009386.1010128,
 key = {IEEE},
 title = {IEEE TCSC Executive Committee},
 booktitle = {Proceedings of the IEEE International Conference on Web Services},
 series = {ICWS '04},
 year = {2004},
 isbn = {0-7695-2167-3},
 pages = {21--22},
 OPTurl = {http://dx.doi.org/10.1109/ICWS.2004.64},
 doi = {10.1109/ICWS.2004.64},
 acmid = {1010128},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

% div book
@book{Mullender:1993:DS(:302430,
 editor = {Mullender, Sape},
 title = {Distributed systems (2nd Ed.)},
 year = {1993},
 isbn = {0-201-62427-3},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 address = {New York, NY, USA},
 }

% master thesis (as techreport and thesis)

@techreport{Petrie:1986:NAD:899644,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 publisher = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }

@MASTERSTHESIS{Petrie:1986:NAD:12345,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 school = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }




@BOOK{book-minimal,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   publisher = "Addison-Wesley",
   year = "1981",
}

% incollection (has an editor, title, and possibly a booktitle)
@INcollection{KA:2001,
 author = {Kong, Wei-Chang},
 Title = {The implementation of electronic commerce in SMEs in Singapore (as Incoll)},
 booktitle = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 OPTurl = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}


% with bibfield 'type' before chapter (note no editor)
@INBOOK{KAGM:2001,
 author = {Kong, Wei-Chang},
 type = {Name of Chapter:},
 chapter = {The implementation of electronic commerce in SMEs in Singapore (Inbook-w-chap-w-type)},
 title = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 OPTurl = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

%%% Notes! This is because the atsign-INBOOK citation type specifies EITHER
%%% editor or author, but not both. In my experiments with the harvard/dcu
%%% bibtex style (and presumably this applies to other styles too), bibtex
%%% ignores the editor information if author information exists in an
%%% atsign-INBOOK entry. atsign-INCOLLECTION is far more commonly used in my references,
%%% and in the absence of an editor I believe most bibtex styles will just
%%% ommit the editor from the reference - the chapter information will not
%%% end up in the in-text citation as you suggest it should be but at least
%%% there is a place to put the editor if necessary.



% was 'Inbook' -- changed to incollection - (editor is different to author) - need to tell Asad to codify as such.
@incollection{Kong:2002:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {Chapter 9},
  booktitle =   {E-commerce and cultural values (Incoll-w-text (chap 9) 'title')},
  year =        {2002},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  OPTurl =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}

% incol when the chapter is 'text' - due to presence of editor (different to author)
@incollection{Kong:2003:IEC:887006.887011,
 author = {Kong, Wei-Chang},
 title = {The implementation of electronic commerce in SMEs in Singapore (Incoll)},
 booktitle = {E-commerce and cultural values},
 editor = {Thanasankit, Theerasak},
 year = {2003},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 OPTurl = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

% ------ test
%incollection{Kong:2003:IEC:887006.887010,
% author = {Kong, Wei-Chang},
% chapter = {The implementation of electronic commerce in SMEs in Singapore (Incoll-text-in-chap)},
% booktitle = {booktitle E-commerce and cultural values},
% title =   {The title},
% editor = {Thanasankit, Theerasak},
% year = {2003},
% isbn = {1-59140-056-2},
% pages = {51--74},
% numpages = {24},
% url = {http://portal.acm.org/citation.cfm?id=887006.887010},
% acmid = {887010},
% publisher = {IGI Publishing},
% address = {Hershey, PA, USA},
%}


% ---------





% Need inbook with num in chapter

% and inbook with number in chapter
@InBook{Kong:2004:IEC:123456.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values - (InBook-num-in-chap)},
  chapter =     {9},
  year =        {2004},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  OPTurl =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}


% and inbook with text in chapter
@Inbook{Kong:2005:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-text-in-chap)},
  chapter =     {The implementation of electronic commerce in SMEs in Singapore},
  year =        {2005},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  OPTurl =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter:},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and inbook with a num and type field
@Inbook{Kong:2006:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-num chap)},
  chapter =     {22},
  year =        {2006},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  OPTurl =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter (in type field)},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and incol coz we have a BLANK chapter - due to presence of editor
%atIncollection{Kong:2006:IEC:887006.887011,
%  author =     {Kong, Wei-Chang},
%  editor =     {Theerasak Thanasankit},
%  title =      "The title"
%  booktitle =  {E-commerce and cultural values (Incol-coz-blank-chap)},
%  year =       {2006},
%  address =    {Hershey, PA, USA},
%  publisher =  {IGI Publishing},
%  url =        {http://portal.acm.org/citation.cfm?id=887006.887010},
%  type =       {Type!},
%  chapter =    {},
%  pages =      {51--74},
%  numpages =   {24},
%  acmid =      {887010},
%  isbn =       {1-59140-056-2},
%  number =     "",
%  month =      "",
%  note =       "",
%}

@article{SaeediMEJ10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi},
            title = {A library-based synthesis methodology for reversible logic},
            journal = {Microelectron. J.},
            volume = {41},
            number = {4},
            month = apr,
            year = {2010},
            pages = {185--194},
}

@ARTICLE{SaeediJETC10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi and Zahra Sasanian},
            title = {Synthesis of Reversible Circuit Using Cycle-Based Approach},
            journal = {J. Emerg. Technol. Comput. Syst.},
            volume = {6},
            number = {4},
            month = dec,
            year = {2010}
            }

% Asad's new version
@article{Kirschmer:2010:AEI:1958016.1958018,
 author = {Kirschmer, Markus and Voight, John},
 title = {Algorithmic Enumeration of Ideal Classes for Quaternion Orders},
 journal = {SIAM J. Comput.},
 issue_date = {January 2010},
 volume = {39},
 number = {5},
 month = jan,
 year = {2010},
 issn = {0097-5397},
 pages = {1714--1747},
 numpages = {34},
 url = {http://dx.doi.org/10.1137/080734467},
 doi = {10.1137/080734467},
 acmid = {1958018},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {ideal classes, maximal orders, number theory, quaternion algebras},
}


% incol due to presence of booktitle
@incollection{Hoare:1972:CIN:1243380.1243382,
 author = {Hoare, C. A. R.},
 title = {Chapter II: Notes on data structuring},
 booktitle = {Structured programming (incoll)},
 editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
 year = {1972},
 isbn = {0-12-200550-3},
 pages = {83--174},
 numpages = {92},
 OPTurl = {http://portal.acm.org/citation.cfm?id=1243380.1243382},
 acmid = {1243382},
 publisher = {Academic Press Ltd.},
 address = {London, UK, UK},
}

% incol due to presence of booktitle
@incollection{Lee:1978:TQA:800025.1198348,
 author = {Lee, Jan},
 title = {Transcript of question and answer session},
 booktitle = {History of programming languages I (incoll)},
 editor = {Wexelblat, Richard L.},
 year = {1981},
 isbn = {0-12-745040-8},
 pages = {68--71},
 numpages = {4},
 OPTurl = {http://doi.acm.org/10.1145/800025.1198348},
 doi = {10.1145/800025.1198348},
 acmid = {1198348},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Dijkstra:1979:GSC:1241515.1241518,
 author = {Dijkstra, E.},
 title = {Go to statement considered harmful},
 booktitle = {Classics in software engineering (incoll)},
 year = {1979},
 isbn = {0-917072-14-6},
 pages = {27--33},
 numpages = {7},
 OPTurl = {http://portal.acm.org/citation.cfm?id=1241515.1241518},
 acmid = {1241518},
 publisher = {Yourdon Press},
 address = {Upper Saddle River, NJ, USA},
}

% incol due to booktitle
@incollection{Wenzel:1992:TVA:146022.146089,
 author = {Wenzel, Elizabeth M.},
 title = {Three-dimensional virtual acoustic displays},
 booktitle = {Multimedia interface design (incoll)},
 year = {1992},
 isbn = {0-201-54981-6},
 pages = {257--288},
 numpages = {32},
 OPTurl = {http://portal.acm.org/citation.cfm?id=146022.146089},
 doi = {10.1145/146022.146089},
 acmid = {146089},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Mumford:1987:MES:54905.54911,
 author = {Mumford, E.},
 title = {Managerial expert systems and organizational change: some critical research issues},
 booktitle = {Critical issues in information systems research (incoll)},
 year = {1987},
 isbn = {0-471-91281-6},
 pages = {135--155},
 numpages = {21},
 OPTurl = {http://portal.acm.org/citation.cfm?id=54905.54911},
 acmid = {54911},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

@book{McCracken:1990:SSC:575315,
 author = {McCracken, Daniel D. and Golden, Donald G.},
 title = {Simplified Structured COBOL with Microsoft/MicroFocus COBOL},
 year = {1990},
 isbn = {0471514071},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

% Let's include Boris / BBeeton entries  (multi-volume works)

@book {MR781537,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {III}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Pseudodifferential operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {viii+525},
      ISBN = {3-540-13828-5},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781536 (87d:35002a)},
MRREVIEWER = {Min You Qi},
}

@book {MR781536,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {IV}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Fourier integral operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {vii+352},
      ISBN = {3-540-13829-3},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781537 (87d:35002b)},
MRREVIEWER = {Min You Qi},
}

%%%%%%%%%%%%%%%%%%%%%% Start of Aptara sample bib entries

% acmsmall-sam.bib
@InProceedings{Adya-01,
  author        = {A. Adya and P. Bahl and J. Padhye and A.Wolman and L. Zhou},
  title         = {A multi-radio unification protocol for {IEEE} 802.11 wireless networks},
  booktitle     = {Proceedings of the IEEE 1st International Conference on Broadnets Networks (BroadNets'04)},
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "210--217"
}

@article{Akyildiz-01,
  author        = {I. F. Akyildiz and W. Su and Y. Sankarasubramaniam and E. Cayirci},
  title         = {Wireless Sensor Networks: A Survey},
  journal       = {Comm. ACM},
  volume        = 38,
  number        = "4",
  year          = {2002},
  pages         = "393--422"
}

@article{Akyildiz-02,
  author        = {I. F. Akyildiz and T. Melodia and K. R. Chowdhury},
  title         = {A Survey on Wireless Multimedia Sensor Networks},
  journal       = {Computer Netw.},
  volume        = 51,
  number        = "4",
  year          = {2007},
  pages         = "921--960"
}

@InProceedings{Bahl-02,
  author        = {P. Bahl and R. Chancre and J. Dungeon},
  title         = {{SSCH}: Slotted Seeded Channel Hopping for Capacity Improvement in {IEEE} 802.11 Ad-Hoc Wireless Networks},
  booktitle     = {Proceeding of the 10th International Conference on Mobile Computing and Networking (MobiCom'04)},
  publisher     = "ACM",
  address       = "New York, NY",
  year          = {2004},
  pages         = "112--117"
}

@misc{CROSSBOW,
  key       = {CROSSBOW},
  title     = {{XBOW} Sensor Motes Specifications},
  note      = {http://www.xbow.com},
  year      = 2008
}

@article{Culler-01,
  author        = {D. Culler and D. Estrin and M. Srivastava},
  title         = {Overview of Sensor Networks},
  journal       = {IEEE Comput.},
  volume        = 37,
  number        = "8 (Special Issue on Sensor Networks)",
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "41--49"
}

@misc{Harvard-01,
    key         = {Harvard CodeBlue},
    title       = {{CodeBlue}: Sensor Networks for Medical Care},
    note        = {http://www.eecs.harvard.edu/mdw/ proj/codeblue/},
    year        = 2008
}

@InProceedings{Natarajan-01,
    author      = {A. Natarajan and M. Motani and B. de Silva and K. Yap and K. C. Chua},
    title       = {Investigating Network Architectures for Body Sensor Networks},
    booktitle   = {Network Architectures},
    editor      = {G. Whitcomb and P. Neece},
    publisher   = "Keleuven Press",
    address     = "Dayton, OH",
    year        = {2007},
    pages       = "322--328",
    eprint      = "960935712",
    primaryclass = "cs",
}

@techreport{Tzamaloukas-01,
  author        = {A. Tzamaloukas and J. J. Garcia-Luna-Aceves},
  title         = {Channel-Hopping Multiple Access},
  number =        {I-CA2301},
  institution =   {Department of Computer Science, University of California},
  address =       {Berkeley, CA},
  year          = {2000}
}

@BOOK{Zhou-06,
  author        = {G. Zhou and J. Lu and C.-Y. Wan and M. D. Yarvis and J. A. Stankovic},
  title         = {Body Sensor Networks},
  publisher     = "MIT Press",
  address       = "Cambridge, MA",
  year          = {2008}
}

@mastersthesis{ko94,
author = "Jacob Kornerup",
title = "Mapping Powerlists onto Hypercubes",
school = "The University of Texas at Austin",
note = "(In preparation)",
year = "1994"}
%month = "dec",}

@PhdThesis{gerndt:89,
  author =       "Michael Gerndt",
  title =        "Automatic Parallelization for Distributed-Memory
                  Multiprocessing Systems",
  school =       "University of Bonn",
  year =         1989,
  address =      "Bonn, Germany",
  month =        dec
}

@article{6:1:1,
author = "J. E. {Archer, Jr.} and R. Conway and F. B. Schneider",
title = "User recovery and reversal in interactive systems",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "1",
month = jan,
year = 1984,
pages = "1--19"}

@article{7:1:137,
author = "D. D. Dunlop and V. R. Basili",
title = "Generalizing specifications for uniformly implemented loops",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "1",
month = jan,
year = 1985,
pages = "137--158"}

@article{7:2:183,
author = "J. Heering and P. Klint",
title = "Towards monolingual programming environments",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "2",
month = apr,
year = 1985,
pages = "183--213"}

@book{knuth:texbook,
author = "Donald E. Knuth",
title = "The {\TeX{}book}",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1984}

@article{6:3:380,
author = "E. Korach and D.  Rotem and N. Santoro",
title = "Distributed algorithms for finding centers and medians in networks",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "3",
month = jul,
year = 1984,
pages = "380--401"}

@book{lamport:latex,
author = "Leslie Lamport",
title = "{\LaTeX}: A Document Preparation System",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1986}

@article{7:3:359,
author = "F. Nielson",
title = "Program transformations in a denotational setting",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "3",
month = jul,
year = 1985,
pages = "359--379"}

%testing
@BOOK{test,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   volume = 2,
   series = "The Art of Computer Programming",
   publisher = "Addison-Wesley",
   address = "Reading, MA",
   edition = "2nd",
   month = "10~" # jan,
   year = "1981",
}

@inproceedings{reid:scribe,
author = "Brian K. Reid",
title = "A high-level approach to computer document formatting",
booktitle = "Proceedings of the 7th Annual Symposium on Principles of
  Programming Languages",
month = jan,
year = 1980,
publisher = "ACM",
address = "New York",
pages = "24--31"}

@article{Zhou:2010:MMS:1721695.1721705,
 author = {Zhou, Gang and Wu, Yafeng and Yan, Ting and He, Tian and Huang, Chengdu and Stankovic, John A. and Abdelzaher, Tarek F.},
 title = {A multifrequency MAC specially designed for wireless sensor network applications},
 journal = {ACM Trans. Embed. Comput. Syst.},
 issue_date = {March 2010},
 volume = 9,
 number = 4,
 month = {April},
 year = 2010,
 issn = {1539-9087},
 pages = {39:1--39:41},
 articleno = 39,
 numpages = 41,
 OPTurl = {http://doi.acm.org/10.1145/1721695.1721705},
 doi = {10.1145/1721695.1721705},
 acmid = 1721705,
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Wireless sensor networks, media access control, multi-channel, radio interference, time synchronization},
}


@misc{TUGInstmem,
  key =          {TUG},
  year  =        2017,
  title =        "Institutional members of the {\TeX} Users Group",
  url =          "http://www.tug.org/instmem.html",
  lastaccessed = "May 27, 2017",
}

@ARTICLE{bowman:reasoning,
    author = {Bowman, Mic and Debray, Saumya K. and Peterson, Larry L.},
    title = {Reasoning About Naming Systems},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {795-825},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161471},
}

@ARTICLE{braams:babel,
    author = {Braams, Johannes},
    title = {Babel, a Multilingual Style-Option System for Use with LaTeX's Standard Document Styles},
    journal = {TUGboat},
    volume = {12},
    number = {2},
    pages = {291-301},
    month = {June},
    year = {1991},
}

@INPROCEEDINGS{clark:pct,
  AUTHOR = "Malcolm Clark",
  TITLE = "Post Congress Tristesse",
  BOOKTITLE = "TeX90 Conference Proceedings",
  PAGES = "84-89",
  ORGANIZATION = "TeX Users Group",
  MONTH = "March",
  YEAR = {1991}
}

@ARTICLE{herlihy:methodology,
    author = {Herlihy, Maurice},
    title = {A Methodology for Implementing Highly Concurrent Data Objects},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {745-770},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161469},
}

@BOOK{salas:calculus,
  AUTHOR = "S.L. Salas and Einar Hille",
  TITLE = "Calculus: One and Several Variable",
  PUBLISHER = "John Wiley and Sons",
  ADDRESS = "New York",
  YEAR = "1978"
}

@MANUAL{Fear05,
  title =        {Publication quality tables in {\LaTeX}},
  author =       {Simon Fear},
  month =        {April},
  year =         2005,
  note =         {\url{http://www.ctan.org/pkg/booktabs}}
}

@Manual{Amsthm15,
  title =        {Using the amsthm Package},
  organization = {American Mathematical Society},
  month =        {April},
  year =         2015,
  note =         {\url{http://www.ctan.org/pkg/amsthm}}
}

@misc{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
}

@misc{UMassCitations,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}

@article{grootendorst2022bertopic,
  title={BERTopic: Neural topic modeling with a class-based TF-IDF procedure},
  author={Grootendorst, Maarten},
  journal={arXiv preprint arXiv:2203.05794},
  year={2022}
}

@misc{openai-assistants,
  author = {{OpenAI}},
  title = {Overview of OpenAI Assistants},
  year = {2023},
  howpublished = {\url{https://platform.openai.com/docs/assistants/overview}},
  note = {Accessed: 2023-05-15}
}

@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{stammbach2023revisiting,
  title={Revisiting Automated Topic Model Evaluation with Large Language Models},
  author={Stammbach, Dominik and Zouhar, Vil{\'e}m and Hoyle, Alexander and Sachan, Mrinmaya and Ash, Elliott},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={9348--9357},
  year={2023}
}

@inproceedings{shang2020nettaxo,
  title={Nettaxo: Automated topic taxonomy construction from text-rich network},
  author={Shang, Jingbo and Zhang, Xinyang and Liu, Liyuan and Li, Sha and Han, Jiawei},
  booktitle={Proceedings of the web conference 2020},
  pages={1908--1919},
  year={2020}
}

@inproceedings{langlais2023rate,
  title={RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap},
  author={Langlais, Philippe and Gao, Tianjian Lucas},
  booktitle={Proceedings of the 15th International Conference on Computational Semantics},
  pages={173--182},
  year={2023}
}

@article{bhat2014taxonomies,
  title={Taxonomies in knowledge organisation—Need, description and benefits},
  author={Bhat, Mohammed Hanief and Shafi, Sheikh Mohammad and others},
  journal={Annals of Library and Information Studies (ALIS)},
  volume={61},
  number={2},
  pages={102--111},
  year={2014}
}

@inproceedings{moura2008proposal,
  title={A proposal for building domain topic taxonomies.},
  author={Moura, Maria Fernanda and Marcacini, Ricardo Marcondes and Nogueira, Bruno M and CONRADO, M da S and Rezende, Solange Oliveira},
  year={2008},
  organization={In: WORKSHOP ON WEB AND TEXT INTELLIGENCE, 1.; SIMP{\'O}SIO BRASILEIRO EM~…}
}

@article{kotitsas2023scinobo,
  title={SCINOBO: a novel system classifying scholarly communication in a dynamically constructed hierarchical Field-of-Science taxonomy},
  author={Kotitsas, Sotiris and Pappas, Dimitris and Manola, Natalia and Papageorgiou, Haris},
  journal={Frontiers in Research Metrics and Analytics},
  volume={8},
  pages={1149834},
  year={2023},
  publisher={Frontiers}
}

@inproceedings{dauxais2022towards,
  title={Towards automation of topic taxonomy construction},
  author={Dauxais, Yann and Zaratiana, Urchade and Laneuville, Matthieu and Hernandez, Simon David and Holat, Pierre and Grosman, Charlie},
  booktitle={International Symposium on Intelligent Data Analysis},
  pages={26--38},
  year={2022},
  organization={Springer}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{mcinnes2017hdbscan,
  title={hdbscan: Hierarchical density based clustering.},
  author={McInnes, Leland and Healy, John and Astels, Steve and others},
  journal={J. Open Source Softw.},
  volume={2},
  number={11},
  pages={205},
  year={2017}
}


@article{waltman2012new,
  title={A new methodology for constructing a publication-level classification system of science},
  author={Waltman, Ludo and Van Eck, Nees Jan},
  journal={Journal of the American Society for Information Science and Technology},
  volume={63},
  number={12},
  pages={2378--2392},
  year={2012},
  publisher={Wiley Online Library}
}


@misc{priem2022openalex,
    title={OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts}, 
    author={Jason Priem and Heather Piwowar and Richard Orr},
    year={2022},
    eprint={2205.01833},
    archivePrefix={arXiv},
    primaryClass={cs.DL},
    url={https://arxiv.org/pdf/2205.01833v2}
}

@unpublished{OpenAlex2024,
    author={},
    title = {OpenAlex: End-to-End Process for Topic Classification},
    note = {a work in progress},
    url = {https://docs.google.com/document/d/1bDopkhuGieQ4F8gGNj7sEc8WSE8mvLZS/edit#heading=h.5w2tb5fcg77r}
}

@article{Blei2012PLDA,
author = {Blei, David M.},
title = {Probabilistic topic models},
year = {2012},
issue_date = {April 2012},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/2133806.2133826},
doi = {10.1145/2133806.2133826},
abstract = {Surveying a suite of algorithms that offer a solution to managing large document archives.},
journal = {Commun. ACM},
month = apr,
pages = {77–84},
numpages = {8}
}

@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "http://arxiv.org/abs/1908.10084",
}

@misc{mcinnes2020umap,
    title={UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}, 
    author={Leland McInnes and John Healy and James Melville},
    year={2020},
    eprint={1802.03426},
    archivePrefix={arXiv},
    primaryClass={stat.ML},
    url = "https://arxiv.org/abs/1802.03426"
}

@article{traag2019louvain,
    title={From Louvain to Leiden: guaranteeing well-connected communities},
    author={Traag, Vincent A and Waltman, Ludo and Van Eck, Nees Jan},
    journal={Scientific reports},
    volume={9},
    number={1},
    pages={5233},
    year={2019},
    publisher={Nature Publishing Group UK London}
}

@dataset{vaneck202410560276,
    author= {Van Eck, Nees Jan},
    title= {{Classification of research publications based on data from OpenAlex}},
    month={jan},
    year={2024},
    publisher={Zenodo},
    version={2023nov},
    doi={10.5281/zenodo.10560276},
    url={https://doi.org/10.5281/zenodo.10560276}
}

@misc{openai2024gpt4turbo,
    author={OpenAI},
    title={GPT-4 Turbo},
    year=2024,
    howpublished ={\url{https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4}},
    note={Large language model}
}

@inproceedings{ostendorff-etal-2022-neighborhood,
    title = "Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings",
    author = "Ostendorff, Malte  and
      Rethmeier, Nils  and
      Augenstein, Isabelle  and
      Gipp, Bela  and
      Rehm, Georg",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.802",
    doi = "10.18653/v1/2022.emnlp-main.802",
    pages = "11670--11688",
    abstract = "Learning scientific document representations can be substantially improved through contrastive learning objectives, where the challenge lies in creating positive and negative training samples that encode the desired similarity semantics. Prior work relies on discrete citation relations to generate contrast samples. However, discrete citations enforce a hard cut-off to similarity. This is counter-intuitive to similarity-based learning and ignores that scientific papers can be very similar despite lacking a direct citation - a core problem of finding related research. Instead, we use controlled nearest neighbor sampling over citation graph embeddings for contrastive learning. This control allows us to learn continuous similarity, to sample hard-to-learn negatives and positives, and also to avoid collisions between negative and positive samples by controlling the sampling margin between them. The resulting method SciNCL outperforms the state-of-the-art on the SciDocs benchmark. Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods. Perhaps surprisingly, even training a general-domain language model this way outperforms baselines pretrained in-domain.",
}

@inproceedings{newman2010automatic,
  title={Automatic evaluation of topic coherence},
  author={Newman, David and Lau, Jey Han and Grieser, Karl and Baldwin, Timothy},
  booktitle={Human language technologies: The 2010 annual conference of the North American chapter of the association for computational linguistics},
  pages={100--108},
  year={2010}
}

@inproceedings{aletras2013evaluating,
  title={Evaluating topic coherence using distributional semantics},
  author={Aletras, Nikolaos and Stevenson, Mark},
  booktitle={Proceedings of the 10th international conference on computational semantics (IWCS 2013)--Long Papers},
  pages={13--22},
  year={2013}
}

@inproceedings{hofmann1999pLSI,
  title         = {Probabilistic latent semantic indexing},
  author        = {Hofmann, T},
  booktitle     = {Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval},
  year          = {1999},
  URL           = {https://sigir.org/wp-content/uploads/2017/06/p211.pdf}
}

@article{Griffiths2004Gibbs,
  author        = {Thomas L. Griffiths  and Mark Steyvers },
  title         = {Finding scientific topics},
  journal       = {Proceedings of the National Academy of Sciences},
  volume        = {101},
  number        = {suppl\_1},
  pages         = {5228-5235},
  year          = {2004},
  doi           = {10.1073/pnas.0307752101},
  URL           = {https://dyurovsky.github.io/learning-humans-machines/class/24-class/papers/griffiths2004.pdf},
}

@article{blei2007CTM,
  title={A correlated topic model of Science},
  author={David M. Blei and John D. Lafferty},
  journal={The Annals of Applied Statistics},
  year={2007},
  volume={1},
  pages={17-35},
  url={https://projecteuclid.org/journals/annals-of-applied-statistics/volume-1/issue-1/A-correlated-topic-model-of-Science/10.1214/07-AOAS114.full}
}

@article{mcauliffe2007sLDA,
  title={Supervised topic models},
  author={Mcauliffe, Jon and Blei, David},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@inproceedings{wang2008cDTM,
author = {Wang, Chong and Blei, David and Heckerman, David},
title = {Continuous time dynamic topic models},
year = {2008},
isbn = {0974903949},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a "topic" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.},
booktitle = {Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence},
pages = {579–586},
numpages = {8},
location = {Helsinki, Finland},
series = {UAI'08}
}

@article{bouma2009NPMI,
  title={Normalized (pointwise) mutual information in collocation extraction},
  author={Bouma, Gerlof},
  journal={Proceedings of GSCL},
  volume={30},
  pages={31--40},
  year={2009},
  publisher={Potsdam}
}

@article{newman2009distributed,
  title={Distributed algorithms for topic models.},
  author={Newman, David and Asuncion, Arthur and Smyth, Padhraic and Welling, Max},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={8},
  year={2009}
}

@inproceedings{Hinton2009UndirectedTM,
 author = {Hinton, Geoffrey E and Salakhutdinov, Russ R},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Replicated Softmax: an Undirected Topic Model},
 url = {https://proceedings.neurips.cc/paper_files/paper/2009/file/31839b036f63806cba3f47b93af8ccb5-Paper.pdf},
 volume = {22},
 year = {2009}
}

@inproceedings{chang2009HumanTeaLeaves,
 author = {Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-graber, Jordan and Blei, David},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Reading Tea Leaves: How Humans Interpret Topic Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2009/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf},
 volume = {22},
 year = {2009}
}

@inproceedings{newman2010automaticHuman,
    title = "Automatic Evaluation of Topic Coherence",
    author = "Newman, David  and
      Lau, Jey Han  and
      Grieser, Karl  and
      Baldwin, Timothy",
    editor = "Kaplan, Ron  and
      Burstein, Jill  and
      Harper, Mary  and
      Penn, Gerald",
    booktitle = "Human Language Technologies: The 2010 Annual Conference of the North {A}merican Chapter of the Association for Computational Linguistics",
    month = jun,
    year = "2010",
    address = "Los Angeles, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N10-1012",
    pages = "100--108",
}

@inproceedings{Newman2010TMforDL,
    author = {Newman, David and Noh, Youn and Talley, Edmund and Karimi, Sarvnaz and Baldwin, Timothy},
    title = {Evaluating topic models for digital libraries},
    year = {2010},
    isbn = {9781450300858},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1816123.1816156},
    doi = {10.1145/1816123.1816156},
    abstract = {Topic models could have a huge impact on improving the ways users find and discover content in digital libraries and search interfaces through their ability to automatically learn and apply subject tags to each and every item in a collection, and their ability to dynamically create virtual collections on the fly. However, much remains to be done to tap this potential, and empirically evaluate the true value of a given topic model to humans. In this work, we sketch out some sub-tasks that we suggest pave the way towards this goal, and present methods for assessing the coherence and interpretability of topics learned by topic models. Our large-scale user study includes over 70 human subjects evaluating and scoring almost 500 topics learned from collections from a wide range of genres and domains. We show how scoring model -- based on pointwise mutual information of word-pair using Wikipedia, Google and MEDLINE as external data sources - performs well at predicting human scores. This automated scoring of topics is an important first step to integrating topic modeling into digital libraries},
    booktitle = {Proceedings of the 10th Annual Joint Conference on Digital Libraries},
    pages = {215–224},
    numpages = {10},
    keywords = {evaluation, topic models, topic quality, user studies},
    location = {Gold Coast, Queensland, Australia},
    series = {JCDL '10}
}

@inproceedings{mimno2011optimizing,
    title = "Optimizing Semantic Coherence in Topic Models",
    author = "Mimno, David  and
      Wallach, Hanna  and
      Talley, Edmund  and
      Leenders, Miriam  and
      McCallum, Andrew",
    editor = "Barzilay, Regina  and
      Johnson, Mark",
    booktitle = "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland, UK.",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D11-1024",
    pages = "262--272",
}

@inproceedings{wang2011CTR,
  title={Collaborative topic modeling for recommending scientific articles},
  author={Wang, Chong and Blei, David M},
  booktitle={Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={448--456},
  year={2011},
  url={https://dl.acm.org/doi/pdf/10.1145/2020408.2020480?casa_token=UGUJF7fZ6GUAAAAA:waueAG1puyy2FUPBTCy2AlQmss76XGQ-ry6Zy6NW-qp14GudXSUAYrsup6LL9Ic5uJqIUxYa6k3A}
}

@inproceedings{aletras2013TC,
    title = "Evaluating Topic Coherence Using Distributional Semantics",
    author = "Aletras, Nikolaos  and
      Stevenson, Mark",
    editor = "Koller, Alexander  and
      Erk, Katrin",
    booktitle = "Proceedings of the 10th International Conference on Computational Semantics ({IWCS} 2013) {--} Long Papers",
    month = mar,
    year = "2013",
    address = "Potsdam, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W13-0102",
    pages = "13--22",
}

@inproceedings{lau2014machineTeaLeaves,
    title = "Machine Reading Tea Leaves: Automatically Evaluating Topic Coherence and Topic Model Quality",
    author = "Lau, Jey Han  and
      Newman, David  and
      Baldwin, Timothy",
    editor = "Wintner, Shuly  and
      Goldwater, Sharon  and
      Riezler, Stefan",
    booktitle = "Proceedings of the 14th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2014",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E14-1056",
    doi = "10.3115/v1/E14-1056",
    pages = "530--539",
}

@inproceedings{Kingma2014VAE,
  title = {{Auto-Encoding Variational Bayes}},
  added-at = {2020-10-15T14:36:56.000+0200},
  author = {Kingma, Diederik P. and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/242e5be6faa01cba2587f4907ac99dce8/annakrause},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  eprint = {http://arxiv.org/abs/1312.6114v10},
  eprintclass = {stat.ML},
  eprinttype = {arXiv},
  file = {:http\://arxiv.org/pdf/1312.6114v10:PDF;:KingmaWelling_Auto-EncodingVariationalBayes.pdf:PDF},
  interhash = {a626a9d77a123c52405a08da983203cb},
  intrahash = {42e5be6faa01cba2587f4907ac99dce8},
  keywords = {cs.LG stat.ML vae},
  timestamp = {2021-02-01T17:13:18.000+0100},
  year = 2014
}

@inproceedings{kingma2014stochastic,
  title         ={Stochastic gradient VB and the variational auto-encoder},
  author        ={Kingma, Diederik P and Welling, Max},
  booktitle     ={Second international conference on learning representations, ICLR},
  volume        ={19},
  pages         ={121},
  year          ={2014}
}

@inproceedings{rezende2014stochastic,
  title         ={Stochastic backpropagation and variational inference in deep latent gaussian models},
  author        ={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle     ={International conference on machine learning},
  volume        ={2},
  pages         ={2},
  year          ={2014},
  URL           ={https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=aac82518e8a27669db11c1a372a88db05ade1c6d}
}

@inproceedings{roder2015CV,
    author = {R\"{o}der, Michael and Both, Andreas and Hinneburg, Alexander},
    title = {Exploring the Space of Topic Coherence Measures},
    year = {2015},
    isbn = {9781450333177},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2684822.2685324},
    doi = {10.1145/2684822.2685324},
    abstract = {Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guaranty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. nFinally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.},
    booktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
    pages = {399–408},
    numpages = {10},
    keywords = {topic model, topic evaluation, topic coherence},
    location = {Shanghai, China},
    series = {WSDM '15}
}

@inproceedings{schnabel2015EmbeddingEvalTM,
    title = "Evaluation methods for unsupervised word embeddings",
    author = "Schnabel, Tobias  and
      Labutov, Igor  and
      Mimno, David  and
      Joachims, Thorsten",
    editor = "M{\`a}rquez, Llu{\'\i}s  and
      Callison-Burch, Chris  and
      Su, Jian",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1036",
    doi = "10.18653/v1/D15-1036",
    pages = "298--307",
}

@inproceedings{Nikolenko2016EmbeddingEvalTM,
author = {Nikolenko, Sergey I.},
title = {Topic Quality Metrics Based on Distributed Word Representations},
year = {2016},
isbn = {9781450340694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2911451.2914720},
doi = {10.1145/2911451.2914720},
abstract = {Automated evaluation of topic quality remains an important unsolved problem in topic modeling and represents a major obstacle for development and evaluation of new topic models. Previous attempts at the problem have been formulated as variations on the coherence and/or mutual information of top words in a topic. In this work, we propose several new metrics for evaluating topic quality with the help of distributed word representations; our experiments suggest that the new metrics are a better match for human judgement, which is the gold standard in this case, than previously developed approaches.},
booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1029–1032},
numpages = {4},
keywords = {text mining, topic modeling, topic quality},
location = {Pisa, Italy},
series = {SIGIR '16}
}

@InProceedings{miao2016NVDM,
  title = 	 {Neural Variational Inference for Text Processing},
  author = 	 {Miao, Yishu and Yu, Lei and Blunsom, Phil},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1727--1736},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/miao16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/miao16.html},
  abstract = 	 {Recent advances in neural variational inference have spawned a renaissance in deep latent variable models. In this paper we introduce a generic variational inference framework for generative and conditional models of text. While traditional variational methods derive an analytic approximation for the intractable distributions over latent variables, here we construct an inference network conditioned on the discrete text input to provide the variational distribution. We validate this framework on two very different text modelling applications, generative document modelling and supervised question answering. Our neural variational document model combines a continuous stochastic document representation with a bag-of-words generative model and achieves the lowest reported perplexities on two standard test corpora. The neural answer selection model employs a stochastic representation layer within an attention mechanism to extract the semantics between a question and answer pair. On two question answering benchmarks this model exceeds all previous published benchmarks.}
}


@InProceedings{miao2017GSM-GSB-RSB,
  title = 	 {Discovering Discrete Latent Topics with Neural Variational Inference},
  author =       {Yishu Miao and Edward Grefenstette and Phil Blunsom},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2410--2419},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/miao17a/miao17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/miao17a.html},
}


@inproceedings{srivastava2017ProdLDA-AVITM,
    title={Autoencoding Variational Inference For Topic Models},
    author={Akash Srivastava and Charles Sutton},
    booktitle={International Conference on Learning Representations},
    year={2017},
    url={https://openreview.net/forum?id=BybtVK9lg}
}

@inproceedings{bhatia2017DocumentTopicEval,
    title = "An Automatic Approach for Document-level Topic Model Evaluation",
    author = "Bhatia, Shraey  and
      Lau, Jey Han  and
      Baldwin, Timothy",
    editor = "Levy, Roger  and
      Specia, Lucia",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1022",
    doi = "10.18653/v1/K17-1022",
    pages = "206--215",
    abstract = "Topic models jointly learn topics and document-level topic distribution. Extrinsic evaluation of topic models tends to focus exclusively on topic-level evaluation, e.g. by assessing the coherence of topics. We demonstrate that there can be large discrepancies between topic- and document-level model quality, and that basing model evaluation on topic-level analysis can be highly misleading. We propose a method for automatically predicting topic model quality based on analysis of document-level topic allocations, and provide empirical evidence for its robustness.",
}

@inproceedings{ding2018coherenceNTM,
    title = "Coherence-Aware Neural Topic Modeling",
    author = "Ding, Ran  and
      Nallapati, Ramesh  and
      Xiang, Bing",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1096",
    doi = "10.18653/v1/D18-1096",
    pages = "830--836",
    abstract = "Topic models are evaluated based on their ability to describe documents well (i.e. low perplexity) and to produce topics that carry coherent semantic meaning. In topic modeling so far, perplexity is a direct optimization target. However, topic coherence, owing to its challenging computation, is not optimized for and is only evaluated after training. In this work, under a neural variational inference framework, we propose methods to incorporate a topic coherence objective into the training process. We demonstrate that such a coherence-aware topic model exhibits a similar level of perplexity as baseline models but achieves substantially higher topic coherence.",
}

@inproceedings{card2018SCHOLAR,
    title = "Neural Models for Documents with Metadata",
    author = "Card, Dallas  and
      Tan, Chenhao  and
      Smith, Noah A.",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1189",
    doi = "10.18653/v1/P18-1189",
    pages = "2031--2040",
    abstract = "Most real-world document collections involve various types of metadata, such as author, source, and date, and yet the most commonly-used approaches to modeling text corpora ignore this information. While specialized models have been developed for particular applications, few are widely used in practice, as customization typically requires derivation of a custom inference algorithm. In this paper, we build on recent advances in variational inference methods and propose a general neural framework, based on topic models, to enable flexible incorporation of metadata and allow for rapid exploration of alternative models. Our approach achieves strong performance, with a manageable tradeoff between perplexity, coherence, and sparsity. Finally, we demonstrate the potential of our framework through an exploration of a corpus of articles about US immigration.",
}

@article{Zhang2018WHAI,
  title={WHAI: Weibull hybrid autoencoding inference for deep topic modeling},
  author={Zhang, Hao and Chen, Bo and Guo, Dandan and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:1803.01328},
  year={2018}
}

@article{Korencic2018DocumenCoherence,
title = {Document-based topic coherence measures for news media text},
journal = {Expert Systems with Applications},
volume = {114},
pages = {357-373},
year = {2018},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.07.063},
url = {https://www.sciencedirect.com/science/article/pii/S0957417418304883},
author = {Damir Korenčić and Strahil Ristov and Jan Šnajder},
keywords = {Topic models, Topic coherence, Topic model evaluation, Text analysis, News text, Exploratory analysis},
abstract = {There is a rising need for automated analysis of news text, and topic models have proven to be useful tools for this task. However, as the quality of the topics induced by topic models greatly varies, much research effort has been devoted to their automated evaluation. Recent research has focused on topic coherence as a measure of a topic’s quality. Existing topic coherence measures work by considering the semantic similarity of topic words. This makes them unfit to detect the coherence of transient topics with semantically unrelated topic words, which abound in news media texts. In this paper, we introduce the notion of document-based topic coherence and propose novel topic coherence measures that estimate topic coherence based on topic documents rather than topic words. We evaluate the proposed measures on two datasets containing topics manually labeled for document-based coherence, on which the proposed measures outperform a strong baseline as well as word-based coherence measures. We also demonstrate the usefulness of document-based coherence measures for automated topic discovery from news media texts.}
}

@inproceedings{bhatia2018topicIntrusionEval,
    title = "Topic Intrusion for Automatic Topic Model Evaluation",
    author = "Bhatia, Shraey  and
      Lau, Jey Han  and
      Baldwin, Timothy",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1098",
    doi = "10.18653/v1/D18-1098",
    pages = "844--849",
    abstract = "Topic coherence is increasingly being used to evaluate topic models and filter topics for end-user applications. Topic coherence measures how well topic words relate to each other, but offers little insight on the utility of the topics in describing the documents. In this paper, we explore the topic intrusion task {---} the task of guessing an outlier topic given a document and a few topics {---} and propose a method to automate it. We improve upon the state-of-the-art substantially, demonstrating its viability as an alternative method for topic model evaluation.",
}

@article{wang2019ATM,
title = {ATM: Adversarial-neural Topic Model},
journal = {Information Processing \& Management},
volume = {56},
number = {6},
pages = {102098},
year = {2019},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2019.102098},
url = {https://www.sciencedirect.com/science/article/pii/S0306457319300500},
author = {Rui Wang and Deyu Zhou and Yulan He},
keywords = {Generative adversarial net, Neural-based topic model, Open domain event extraction, Topic modeling},
abstract = {Topic models are widely used for thematic structure discovery in text. But traditional topic models often require dedicated inference procedures for specific tasks at hand. Also, they are not designed to generate word-level semantic representations. To address the limitations, we propose a neural topic modeling approach based on the Generative Adversarial Nets (GANs), called Adversarial-neural Topic Model (ATM) in this paper. To our best knowledge, this work is the first attempt to use adversarial training for topic modeling. The proposed ATM models topics with dirichlet prior and employs a generator network to capture the semantic patterns among latent topics. Meanwhile, the generator could also produce word-level semantic representations. Besides, to illustrate the feasibility of porting ATM to tasks other than topic modeling, we apply ATM for open domain event extraction. To validate the effectiveness of the proposed ATM, two topic modeling benchmark corpora and an event dataset are employed in the experiments. Our experimental results on benchmark corpora show that ATM generates more coherence topics (considering five topic coherence measures), outperforming a number of competitive baselines. Moreover, the experiments on event dataset also validate that the proposed approach is able to extract meaningful events from news articles.}
}

@article{Burkhardt2019TopicRedundancy,
  author  = {Sophie Burkhardt and Stefan Kramer},
  title   = {Decoupling Sparsity and Smoothness in the Dirichlet Variational Autoencoder Topic Model},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {131},
  pages   = {1--27},
  url     = {http://jmlr.org/papers/v20/18-569.html}
}

@inproceedings{nan2019TopicUniqueness,
    title = "Topic Modeling with {W}asserstein Autoencoders",
    author = "Nan, Feng  and
      Ding, Ran  and
      Nallapati, Ramesh  and
      Xiang, Bing",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1640",
    doi = "10.18653/v1/P19-1640",
    pages = "6345--6381",
    abstract = "We propose a novel neural topic model in the Wasserstein autoencoders (WAE) framework. Unlike existing variational autoencoder based models, we directly enforce Dirichlet prior on the latent document-topic vectors. We exploit the structure of the latent space and apply a suitable kernel in minimizing the Maximum Mean Discrepancy (MMD) to perform distribution matching. We discover that MMD performs much better than the Generative Adversarial Network (GAN) in matching high dimensional Dirichlet distribution. We further discover that incorporating randomness in the encoder output during training leads to significantly more coherent topics. To measure the diversity of the produced topics, we propose a simple topic uniqueness metric. Together with the widely used coherence measure NPMI, we offer a more wholistic evaluation of topic quality. Experiments on several real datasets show that our model produces significantly better topics than existing topic models.",
}

@inproceedings{wang2020BAT,
    title = "Neural Topic Modeling with Bidirectional Adversarial Training",
    author = "Wang, Rui  and
      Hu, Xuemeng  and
      Zhou, Deyu  and
      He, Yulan  and
      Xiong, Yuxuan  and
      Ye, Chenchen  and
      Xu, Haiyang",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.32",
    doi = "10.18653/v1/2020.acl-main.32",
    pages = "340--350",
    abstract = "Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for model inference as in traditional topic models such as Latent Dirichlet Allocation (LDA). However, these models either typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a two-way projection between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an encoder for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6{\%} is observed in accuracy.",
}

@article{dieng2020ETM,
    title = "Topic Modeling in Embedding Spaces",
    author = "Dieng, Adji B.  and
      Ruiz, Francisco J. R.  and
      Blei, David M.",
    editor = "Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2020.tacl-1.29",
    doi = "10.1162/tacl_a_00325",
    pages = "439--453",
}

@inproceedings{sia2020tired-cluster,
  title         = "Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics too!",
  author        = "Sia, Suzanna  and
      Dalmia, Ayush  and
      Mielke, Sabrina J.",
  editor        = "Webber, Bonnie  and
      Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
  booktitle     = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
  month         = nov,
  year          = "2020",
  address       = "Online",
  publisher = "Association for Computational Linguistics",
  url           = "https://aclanthology.org/2020.emnlp-main.135",
  doi           = "10.18653/v1/2020.emnlp-main.135",
  pages         = "1728--1736",
  abstract      = "Topic models are a useful analysis tool to uncover the underlying themes within document collections. The dominant approach is to use probabilistic topic models that posit a generative story, but in this paper we propose an alternative way to obtain topics: clustering pre-trained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA. The best performing combination for our approach performs as well as classical topic models, but with lower runtime and computational complexity.",
}

@inproceedings{bianchi2021EmbedingCentroidTD,
    title = "Cross-lingual Contextualized Topic Models with Zero-shot Learning",
    author = "Bianchi, Federico  and
      Terragni, Silvia  and
      Hovy, Dirk  and
      Nozza, Debora  and
      Fersini, Elisabetta",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.143",
    doi = "10.18653/v1/2021.eacl-main.143",
    pages = "1676--1683",
    abstract = "Many data sets (e.g., reviews, forums, news, etc.) exist parallelly in multiple languages. They all cover the same content, but the linguistic differences make it impossible to use traditional, bag-of-word-based topic models. Models have to be either single-language or suffer from a huge, but extremely sparse vocabulary. Both issues can be addressed by transfer learning. In this paper, we introduce a zero-shot cross-lingual topic model. Our model learns topics on one language (here, English), and predicts them for unseen documents in different languages (here, Italian, French, German, and Portuguese). We evaluate the quality of the topic predictions for the same document in different languages. Our results show that the transferred topics are coherent and stable across languages, which suggests exciting future research directions.",
}

@InProceedings{Terragni2021EmbedingTD,
author="Terragni, Silvia
and Fersini, Elisabetta
and Messina, Enza",
editor="M{\'e}tais, Elisabeth
and Meziane, Farid
and Horacek, Helmut
and Kapetanios, Epaminondas",
title="Word Embedding-Based Topic Similarity Measures",
booktitle="Natural Language Processing and Information Systems",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="33--45",
abstract="Topic models aim at discovering a set of hidden themes in a text corpus. A user might be interested in identifying the most similar topics of a given theme of interest. To accomplish this task, several similarity and distance metrics can be adopted. In this paper, we provide a comparison of the state-of-the-art topic similarity measures and propose novel metrics based on word embeddings. The proposed measures can overcome some limitations of the existing approaches, highlighting good capabilities in terms of several topic performance measures on benchmark datasets.",
isbn="978-3-030-80599-9"
}

@inproceedings{bianchi2021CombinedTM,
    title = "Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence",
    author = "Bianchi, Federico  and
      Terragni, Silvia  and
      Hovy, Dirk",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.96",
    doi = "10.18653/v1/2021.acl-short.96",
    pages = "759--766",
    abstract = "Topic models extract groups of words from documents, whose interpretation as a topic hopefully allows for a better understanding of the data. However, the resulting word groups are often not coherent, making them harder to interpret. Recently, neural topic models have shown improvements in overall coherence. Concurrently, contextual embeddings have advanced the state of the art of neural models in general. In this paper, we combine contextualized representations with neural topic models. We find that our approach produces more meaningful and coherent topics than traditional bag-of-words topic models and recent neural models. Our results indicate that future improvements in language models will translate into better topic models.",
}

@article{korenvcic2021CoverageEval,
  title={A topic coverage approach to evaluation of topic models},
  author={Koren{\v{c}}i{\'c}, Damir and Ristov, Strahil and Repar, Jelena and {\v{S}}najder, Jan},
  journal={IEEE access},
  volume={9},
  pages={123280--123312},
  year={2021},
  publisher={IEEE}
}

@article{sarica2021stopwords,
  title={Stopwords in technical language processing},
  author={Sarica, Serhad and Luo, Jianxi},
  journal={Plos one},
  volume={16},
  number={8},
  pages={e0254937},
  year={2021},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{zhang-etal-2022-neural,
  title         = "Is Neural Topic Modelling Better than Clustering? An Empirical Study on Clustering with Contextual Embeddings for Topics",
  author        = "Zhang, Zihan  and
                      Fang, Meng  and
                      Chen, Ling  and
                      Namazi Rad, Mohammad Reza",
  editor        = "Carpuat, Marine  and
      de Marneffe, Marie-Catherine  and
      Meza Ruiz, Ivan Vladimir",
  booktitle     = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
  month         = jul,
  year          = "2022",
  address       = "Seattle, United States",
  publisher     = "Association for Computational Linguistics",
  url           = "https://aclanthology.org/2022.naacl-main.285",
  doi           = "10.18653/v1/2022.naacl-main.285",
  pages         = "3886--3893",
  abstract = "Recent work incorporates pre-trained word embeddings such as BERT embeddings into Neural Topic Models (NTMs), generating highly coherent topics. However, with high-quality contextualized document representations, do we really need sophisticated neural models to obtain coherent and interpretable topics? In this paper, we conduct thorough experiments showing that directly clustering high-quality sentence embeddings with an appropriate word selecting method can generate more coherent and diverse topics than NTMs, achieving also higher efficiency and simplicity.",
}

@inproceedings{stammbach2023revisitingLLM,
    title = "Revisiting Automated Topic Model Evaluation with Large Language Models",
    author = "Stammbach, Dominik  and
      Zouhar, Vil{\'e}m  and
      Hoyle, Alexander  and
      Sachan, Mrinmaya  and
      Ash, Elliott",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.581",
    doi = "10.18653/v1/2023.emnlp-main.581",
    pages = "9348--9357",
    abstract = "Topic models help us make sense of large text collections. Automatically evaluating their output and determining the optimal number of topics are both longstanding challenges, with no effective automated solutions to date. This paper proposes using large language models (LLMs) for these tasks. We find that LLMs appropriately assess the resulting topics, correlating more strongly with human judgments than existing automated metrics. However, the setup of the evaluation task is crucial {---} LLMs perform better on coherence ratings of word sets than on intrustion detection. We find that LLMs can also assist us in guiding us towards a reasonable number of topics. In actual applications, topic models are typically used to answer a research question related to a collection of texts. We can incorporate this research question in the prompt to the LLM, which helps estimating the optimal number of topics.",
}

@inproceedings{wu2023ECRTM,
  title={Effective neural topic modeling with embedding clustering regularization},
  author={Wu, Xiaobao and Dong, Xinshuai and Nguyen, Thong Thanh and Luu, Anh Tuan},
  booktitle={International Conference on Machine Learning},
  pages={37335--37357},
  year={2023},
  organization={PMLR}
}

@article{wu2024survey,
  title={A survey on neural topic models: methods, applications, and challenges},
  author={Wu, Xiaobao and Nguyen, Thong and Luu, Anh Tuan},
  journal={Artificial Intelligence Review},
  volume={57},
  number={2},
  pages={18},
  year={2024},
  publisher={Springer}
}

@inproceedings{rahimi2024contextualizedCoherence,
    title = "Contextualized Topic Coherence Metrics",
    author = "Rahimi, Hamed  and
      Mimno, David  and
      Hoover, Jacob  and
      Naacke, Hubert  and
      Constantin, Camelia  and
      Amann, Bernd",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.123",
    pages = "1760--1773",
    abstract = "This article proposes a new family of LLM-based topic coherence metrics called Contextualized Topic Coherence (CTC) and inspired by standard human topic evaluation methods. CTC metrics simulate human-centered coherence evaluation while maintaining the efficiency of other automated methods. We compare the performance of our CTC metrics and five other baseline metrics on seven topic models and show that CTC metrics better reflect human judgment, particularly for topics extracted from short text collections by avoiding highly scored topics that are meaningless to humans.",
}

@inproceedings{mu2024llmtm,
    title = "Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling",
    author = "Mu, Yida  and
      Dong, Chun  and
      Bontcheva, Kalina  and
      Song, Xingyi",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.887",
    pages = "10160--10171",
    abstract = "Topic modelling, as a well-established unsupervised technique, has found extensive use in automatically detecting significant topics within a corpus of documents. However, classic topic modelling approaches (e.g., LDA) have certain drawbacks, such as the lack of semantic understanding and the presence of overlapping topics. In this work, we investigate the untapped potential of large language models (LLMs) as an alternative for uncovering the underlying topics within extensive text corpora. To this end, we introduce a framework that prompts LLMs to generate topics from a given set of documents and establish evaluation protocols to assess the clustering efficacy of LLMs. Our findings indicate that LLMs with appropriate prompts can stand out as a viable alternative, capable of generating relevant topic titles and adhering to human guidelines to refine and merge topics. Through in-depth experiments and evaluation, we summarise the advantages and constraints of employing LLMs in topic extraction.",
}

@misc{mu2024llmtm-granularity-hallucination,
      title={Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling}, 
      author={Yida Mu and Peizhen Bai and Kalina Bontcheva and Xingyi Song},
      year={2024},
      eprint={2405.00611},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00611}, 
}

@article{yang2024llm,
  title         ={LLM Reading Tea Leaves: Automatically Evaluating Topic Models with Large Language Models},
  author        ={Yang, Xiaohao and Zhao, He and Phung, Dinh and Buntine, Wray and Du, Lan},
  journal       ={arXiv preprint arXiv:2406.09008},
  year          ={2024}
}

@inproceedings{pham2024topicgpt,
    title = "{T}opic{GPT}: A Prompt-based Topic Modeling Framework",
    author = "Pham, Chau  and
      Hoyle, Alexander  and
      Sun, Simeng  and
      Resnik, Philip  and
      Iyyer, Mohit",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.164",
    doi = "10.18653/v1/2024.naacl-long.164",
    pages = "2956--2984",
    abstract = "Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require {``}reading the tea leaves{''} to interpret; additionally, they offer users minimal control over the formatting and specificity of resulting topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also more interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, human-centered approach to topic modeling.",
}

@article{llm-amatriain-arxiv,
  title={Transformer models: an introduction and catalog},
  author={Amatriain, Xavier and Sankar, Ananth and Bing, Jie and Bodigutla, Praveen Kumar and Hazen, Timothy J and Kazi, Michaeel},
  journal={arXiv preprint arXiv:2302.07730},
  year={2023}
}

@misc{llm-dsouza-orkg,
  doi = {10.48366/R609337},
  url = {https://orkg.org/comparison/R609337/},
  author = {D’Souza, Jennifer},
  keywords = {Artificial Intelligence},
  language = {en},
  title = {A Catalog of Transformer Models},
  publisher = {Open Research Knowledge Graph},
  year = {2023},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}