\section{Results and Interpretation}
This section presents our main results and findings, beginning with a feature ablation study. Building upon the best feature set identified, we then present the results of an architecture study to find the best number of parameters for OJN-EPV. The best-performing architecture is next used to evaluate the performance of the resulting model. We highlight the inclusion of ball height as a key model feature, demonstrating its impact on enhancing game state predictions. Finally, we conduct a quantitative evaluation of the best-performing OJN-EPV model using the OJN-Pass-EPV benchmark.

\subsection{Feature Ablation Study}\label{ablation_study}

In our feature ablation study, we investigate the effects of various feature combinations on model performance. Across all models, adding features beyond the \textit{fundamental features} (i) player positions and velocities, (ii) distance to the ball for every location, and (iii) ball height, yielded only negligible performance gains in aggregate metrics such as loss and ECE. However, closer inspection of the value models, including visual evaluations of predicted probability surfaces, reveals that \textit{distance to goal} and \textit{angle to goal} substantially improve contextual accuracy. Without these features, the model underestimates value in scenarios near the penalty area.

We hypothesize that the lack of improvement in overall loss and ECE metrics is partly due to the relatively small number of goals in football, causing these effects to be overshadowed. However, retaining distance to goal and angle to goal produces more realistic and domain-consistent predictions, underscoring the importance of complementing quantitative measurements with qualitative assessments when refining EPV models.


\subsection{Architecture Study}

To validate the model architecture, we examine various setups, specifically focusing on the number of filters (8, 16, 32) and the filter dimensions (3x3, 5x5). We find that using only 8 filters significantly reduces performance for all models except the pass value models. We hypothesize that the outputs of the value models are relatively simple and consistent across different game states, primarily because the predicted value is largely influenced by the position of the successful or failed pass. Conversely, the success and likelihood models have more intricate outputs that depend heavily on the specific game state, requiring a greater capacity to effectively capture the dynamics of each scenario. For the models using 32 filters, we find that these models do show slightly better performance compared to the models using 16 filters, but due to only slight improvements and significantly more parameters, especially in the case of 32 filters and a filter dimension of 5x5, we choose to use 16 filters with dimension 5x5 for the OJN-EPV model. This configuration results in 372.355 parameters for the pass success model, 372.359 for the pass likelihood model, and 373.201 parameters for both pass value models (successful and unsuccessful). Note that this is the model described in Section \ref{model_architecture_and_selection}

\subsection{Model Performance}
This section assesses the performance of the OJN-EPV model, focusing on the loss and calibration metrics.

We begin by presenting the loss results for the success, likelihood, and value models. The value models, in particular, showcase the new computation of the loss. This is derived from the probabilities obtained from the softmax function for each class (-1 (conceding a goal) , 0 (no goal), and 1 (scoring a goal)). We use categorical cross entropy loss for the value model and binary cross-entropy loss for the per-class loss computation. To get the overall ECE for the value models, we subtract the probability that a goal is scored by the probability that a goal is conceded.

We use ECE with 10 bins as the calibration metric. To enhance model calibration, temperature scaling is applied to the pass success and pass value models. All models, except one, show the best calibration with a temperature of 1.0, thus no temperature scaling. Only the value unsuccessful model trained and validated on the Eredivisie data shows better calibration with a temperature value of 1.1.

Table \ref{tab:overall_model_performance_test_eredivisie} displays the various models trained solely on Eredivisie data and Table \ref{tab:overall_model_performance_test_world_cup} the models trained additionally on World Cup data, where training begins with Eredivisie model weights and fine-tuning is done using the World Cup dataset. All models are tested on both datasets. It is noted that the success and likelihood models show reduced loss values when assessed on the World Cup dataset, as opposed to the Eredivisie dataset. This improvement likely stems from multiple factors: the competition level in World Cup matches may be more uniform, and the World Cup data could be of higher quality. Furthermore, we notice that fine-tuning on the World Cup dataset does not improve loss measures nor calibration measures significantly.

\begin{table}[h!]
\centering
\caption{Loss and ECE on both datasets for models trained on Eredivisie data}
\label{tab:overall_model_performance_test_eredivisie}
\scriptsize

\vspace{5mm}
\begin{tabular}{|l|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{Model} & \textbf{Loss on Eredivisie} & \textbf{ECE on Eredivisie} & \textbf{Loss on World Cup} & \textbf{ECE on World Cup} \\ \hline
Pass Success & 0.1558 & 0.0024 & 0.1355 & 0.0122\\ \hline
Pass Likelihood & 4.7225 & - & 4.4528 & - \\ \hline
Pass Value (Successful) & 0.0689 & 0.0016 & 0.0835 & 0.0060 \\ \hline
Pass Value (Unsuccessful) & 0.0663 & 0.0042 & 0.0726 & 0.0056\\ \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\centering
\caption{Loss and ECE on both datasets for models fine-tuned on World Cup data}
\label{tab:overall_model_performance_test_world_cup}
\scriptsize

\vspace{3mm}
\begin{tabular}{|l|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|p{1.8cm}|}
\hline
\textbf{Model} & \textbf{Loss on Eredivisie} & \textbf{ECE on Eredivisie} & \textbf{Loss on World Cup} & \textbf{ECE on World Cup} \\ \hline
Pass Success & 0.1568 & 0.0090 & 0.1326 & 0.0047 \\ \hline
Pass Likelihood & 4.7227 & - & 4.4367 & - \\ \hline
Pass Value (Successful) & 0.0687 & 0.0024  & 0.0836 & 0.0065  \\ \hline
Pass Value (Unsuccessful) & 0.0671 & 0.0045 & 0.0740 & 0.0050 \\ \hline
\end{tabular}
\end{table}


The detailed loss per class based on the value model, as shown in Tables \ref{tab:detailed_loss_by_class_test_eredivisie} and \ref{tab:detailed_loss_by_class_test_world_cup}, provides a representation of the model's subtle understanding of pass outcomes. Low loss and calibration scores indicate the model's capability in precisely forecasting if a pass will lead to scoring, conceding, or no goal within 15 seconds for the team in ball possession.


\begin{table}[h!]
\centering
\caption{Pass value model - loss and ECE by class for model trained on Eredivisie data}
\label{tab:detailed_loss_by_class_test_eredivisie}
\footnotesize

\vspace{3mm}
\begin{tabular}{|l|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{Pass Value Model - Detailed Loss by Class}} \\ \hline
\textbf{Class} & \textbf{Loss on Eredivisie} & \textbf{ECE on Eredivisie} & \textbf{Loss on World Cup} & \textbf{ECE on World Cup} \\ \hline
Scoring goal (Successful Passes) & 0.0590 & 0.0018 & 0.0689 & 0.0048 \\ \hline
No goal (Successful Passes) & 0.0660 & 0.0040 & 0.0791 & 0.0035 \\ \hline
Conceding goal (Successful Passes) & 0.0096 & 0.0023 & 0.0144 & 0.0022 \\ \hline
Scoring goal (Unsuccessful Passes) & 0.0379 & 0.0060 & 0.0357 & 0.0074 \\ \hline
No goal (Unsuccessful Passes) & 0.0620 & 0.0105 & 0.0663 & 0.0134 \\ \hline
Conceding goal (Unsuccessful Passes) & 0.0271 & 0.0041 & 0.0362 & 0.0062 \\ \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\caption{Pass value model - loss and ECE by class for model fine-tuned on World Cup data}
\label{tab:detailed_loss_by_class_test_world_cup}
\footnotesize

\vspace{3mm}
\begin{tabular}{|l|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{\textbf{Pass Value Model - Detailed Loss by Class}} \\ \hline
\textbf{Class} & \textbf{Loss on Eredivisie} & \textbf{ECE on Eredivisie} & \textbf{Loss on World Cup} & \textbf{ECE on World Cup} \\ \hline
Scoring goal (Successful Passes) & 0.0590 & 0.0011 & 0.0693 & 0.0057 \\ \hline
No goal (Successful Passes) & 0.0658 & 0.0032 & 0.0793 & 0.0042 \\ \hline
Conceding goal (Successful Passes) & 0.0093 &0.0021 & 0.0141 &0.0020 \\ \hline
Scoring goal (Unsuccessful Passes) & 0.0385 & 0.0064 & 0.0366 & 0.0081 \\ \hline
No goal (Unsuccessful Passes) & 0.0629 & 0.0110 & 0.0675 & 0.0155 \\ \hline
Conceding goal (Unsuccessful Passes) & 0.0273 & 0.0046 & 0.0366 & 0.0071 \\ \hline
\end{tabular}
\end{table}



\subsection{Influence of Ball Height on Predictions}
Incorporating the ball's height (z-axis) into the model significantly impacts the pass likelihood predictions by adding the crucial vertical dimension to the analysis. Figure \ref{fig:ball_heights} illustrates this by contrasting two scenarios: a ground pass \ref{fig:ball_height_ground} and an aerial pass with the ball at 2 meters high \ref{fig:ball_height_aerial}. In the aerial pass scenario, the model recognizes that the ball can be passed over opponents and also shows increased uncertainty about the pass's destination, assuming it will likely be a header. These predictions align with real-world football knowledge: headers are generally less precise than ground passes due to reduced control. While ball height doesn't substantially affect overall loss or ECE metrics because of the rarity of aerial passes, Figure \ref{fig:ball_heights} demonstrates a specific instance where it's highly relevant. This highlights the practical importance of considering ball height for specific passing situations. 

\begin{figure}[h!]
\centering
\begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\linewidth]{event_12_low_ball.png}
    \caption{Ground pass scenario (0 meters ball height)}
    \label{fig:ball_height_ground}
\end{subfigure}
\hfill
\begin{subfigure}{0.48\textwidth}
    \includegraphics[width=\linewidth]{event_12_high_ball.png}
    \caption{Aerial pass scenario (2 meters ball height)}
    \label{fig:ball_height_aerial}
\end{subfigure}
\caption{Comparative visualization of pass likelihood based on ball height. In both scenarios, the red team (red dots) is in possession, with the ball carrier highlighted in yellow and the ball depicted in violet. The opposing team is represented in blue (blue dots). The color intensity on the pitch indicates the likelihood of the pass reaching a location - the darker the shade, the higher the probability. Figure~\ref{fig:ball_height_aerial} shows how the model recognizes that aerial passes can be made over opponents, while also showing increased uncertainty about the pass destination compared to the ground pass in Figure~\ref{fig:ball_height_ground}.}
\label{fig:ball_heights}
\end{figure}

\newpage
\subsection{Relevance of Decomposing Pass Value in Reward and Risk}

Decomposing pass EPV into reward and risk components offers a more nuanced perspective on the complexities of passing decisions in football. By separating the potential positive and negative impacts of a pass, we can gain deeper insights into the underlying volatility of seemingly straightforward game states.  Figure \ref{fig:event1500} depicts one such game state, where the decomposition of EPV reveals the trade-offs inherent in a passing decision.

In this game state, the pass value model trained on successful passes assigns a slightly negative overall value (i.e., -0.0047) for the end location of the pass marked with a "+". This implies that even if the pass is completed, the blue team is still considered more likely to score within 15 seconds than the red team. Unlike earlier approaches that define risk as the value associated with losing possession and reward as the value associated with keeping the ball, our analysis highlights a different perspective. Even a successful pass can lead to an unpredictable game state, potentially detrimental for the team in possession, depending on factors such as opponent pressure. This assessment is based on potential outcomes: the blue team has a 0.0199 probability of scoring compared to 0.0152 for the red team. This analysis illustrates the complex trade-offs that can be present in passing decisions.


\begin{figure}[h!]
\centering
\includegraphics[width=\linewidth]{event_1500.png}
\caption{Game state showing a pass scenario. The ball carrier, marked with a yellow dot and belonging to the red team, is making a pass to the target location marked by "+".}
\label{fig:event1500}
\end{figure}

\newpage

\subsection{Benchmark performance}\label{benchmark_performance}

Prior to incorporating \emph{distance to goal} and \emph{angle to goal} features in our pass value models, the benchmark performance for the model trained only on the Eredivisie dataset was 68\% on the OJN-Pass-EPV benchmark, rising to 70\% after fine-tuning on the World Cup data. Once we added these two features, the global loss and calibration metrics did not show a pronounced improvement (see Section~\ref{ablation_study}). However, the benchmark performance for both the Eredivisie-trained and World Cup fine-tuned models increased to 78\%.

This result underscores the importance of supplementing aggregate metrics (like loss and calibration) with a real-world evaluation such as our OJN-Pass-EPV benchmark. A pair of features (distance and angle to goal) can make the difference in identifying the game state with a higher probability of scoring even if the global loss and ECE measures remain largely unchanged.

The OJN-EPV model thus achieves a performance level of 78\% on our OJN-Pass-EPV benchmark. The benchmark creation, as described in Section \ref{benchmark_creation}, was designed to include a considerable number of challenging game state pairs, such as those with small but impactful differences in player positioning. Even a 0.5-meter shift in position can influence the value of a game state, and with a model granularity of approximately 1 x 1 meter, this poses a clear challenge.

One conclusion is that the OJN-EPV model underperforms in scenarios involving offside players, assigning a higher pass EPV to a game state in which a player is offside (resulting in an inevitable unsuccessful pass). This issue arises in three instances within the benchmark. Other pairs also highlight scenarios where the model fails to recognize the more valuable game state, reflecting the benchmarkâ€™s intent to include difficult cases that guide further model improvements. Nonetheless, with a benchmark performance of 78\%, the OJN-EPV model generally delivers accurate predictions across a wide range of game state pairs.

