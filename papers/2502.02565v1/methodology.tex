\section{Methodology}

% Benchmark Creation
\subsection{Benchmark Creation}\label{benchmark_creation}

To enable quantitative evaluation of the performance of EPV models, we create the OJN-Pass-EPV benchmark. This benchmark consists of 50 \textit{modified} game state pairs, where we use a real game state and realistically alter aspects of it (e.g. player positions and velocities). 
% and \textit{comparative game states}, where we select pairs of real game states we want to compare. 
The OJN-Pass-EPV benchmark focuses solely on the overall pass value of game states, making it suitable for evaluating pass models. However, the principle behind the OJN-Pass-EPV benchmark can be used to evaluate other aspects, such as \textit{dribble value}, \textit{shot value}, action selection probabilities, and ultimately, overall EPV.

\cite{davis2024methodology} emphasize that evaluating the effectiveness of deep learning models in sports is both essential and challenging due to the intricate and noisy nature of sports data and outline that one approach to do such an evaluation is to perform an analysis with the assistance of domain experts. Following that we rely on a panel of football experts, including members of the Royal Dutch Football Association (KNVB), to judge which of the two game states in each game state pair has a higher pass EPV. We focus on relative EPVs rather than absolute EPVs, as the latter are often more subjective. While acknowledging that even relative judgments can be subjective, we hypothesize that this is less likely to be a significant issue. In designing the benchmark, we select game state pairs that we expect to have widely accepted relative values. 

Details of the benchmark creation process and the complete set of game state pairs are available in the GitHub repository: 
%\textbf{Anonymous}. 
\citep{Overmeer2025} \url{https://github.com/EAISI/OJN-EPV-benchmark}.
Note that to ensure unbiased evaluation, the game states used in the benchmark are excluded from our training, validation, and test sets.

% Initial Replication Attempts and Challenges
\subsection{Initial Replication Attempts and Challenges}

In replicating the F21-EPV model, we encounter discrepancies in model parameters and the vanishing gradient problem, which hinder our ability to reproduce the reported results using our dataset. These challenges, potentially stemming from subtle implementation differences or dataset variations, led us to adjust our model's architecture. By exploring alternative activation functions, loss calculations, and layer configurations, we develop OJN-EPV, an enhanced EPV model that addresses these challenges.

% Data Collection
\subsection{Data Collection}

The data used in this study are sourced from the KNVB, encompassing the 2021/22 and 2022/23 seasons of the Dutch Eredivisie, as well as data from the 2022 World Cup. The data consists of 10 Hz tracking data for player and ball positions, accompanied by event data. The dataset is collected and processed ensuring the alignment of both event and tracking data.

Our analysis uses data from 624 Eredivisie matches and 63 World Cup matches. This combination captures a range of performance levels and playing styles, providing a solid foundation for OJN-EPV.

% Data Preprocessing and Feature Engineering
\subsection{Data Preprocessing and Feature Engineering}

We transform the raw event and tracking data for integration into our models through the following steps:

\begin{itemize}
    \item \textbf{Scaling and Smoothing:} To optimize data processing, we scale the X and Y coordinates to a field representation of 103x67, resulting in a grid of 104x68 for efficient indexing in NumPy and TensorFlow. Velocities are smoothed using a Savitzky-Golay filter to reduce noise \citep{shaw_2020}.

    \item \textbf{Normalization and Cleaning:}  We standardize the data by ensuring all attacks proceed uniformly from left to right. Additionally, we remove instances of players recorded outside the pitch boundaries to improve data integrity.

    \item \textbf{Real Playing Time Calculation:} To accurately assess pass value, we calculate the actual playing time, excluding periods when the ball is out of play. This ensures that our 15-second evaluation window following each pass reflects only the active duration of the game, providing a more precise assessment of in-game actions.

    \item \textbf{Data Alignment:}  To ensure synchronicity, we align the event data with the tracking data. This ensures that each pass event is accurately reflected in the tracking data, enabling precise spatial and temporal analysis.
\end{itemize}

For the pass likelihood, pass success, and pass value models, we use the features described in \cite{Fernández2021} and additionally incorporate the z-value (height) of the ball.

% Model Architecture
\subsection{Model Architecture} \label{model_architecture_and_selection}

Our pass EPV model employs a U-Net-type convolutional neural network (CNN) architecture \citep{ronneberger2015unet}. This architecture processes game state data represented on a 104x68 grid, with the output mirroring the input dimensions.  The model comprises encoder and decoder blocks, incorporating max pooling, replication padding, attention gates, and concatenation layers.

Each encoder block features two repetitions of the following sequence: a replication padding layer, a convolutional layer with filter sizes of 16, 32, 64, 32, or 16 (depending on the block), a 5x5 filter, batch normalization, and a LeakyReLU activation function (alpha= 0.1). Decoder blocks consist of an upsampling layer, replication padding, a convolutional layer with matching filter numbers to the concatenated outputs, a 5x5 filter, batch normalization, and a LeakyReLU activation function (alpha= 0.1).

Each encoder block in the contracting path is followed by max pooling to reduce dimensionality and prevent overfitting. Max pooling is omitted in the third encoder block to preserve dimensions.  The most contracted feature maps have dimensions of 26x17.

Two decoder blocks upsample the feature maps, each followed by an attention gate, concatenation, and an encoder block. This symmetrical design captures both local and global context.

The final layer utilizes a sigmoid activation for the pass success model and softmax for the pass likelihood model. The pass value model includes a softmax layer with three classes, representing goal outcomes within a 15-second timeframe: a goal for the passing team, no goal, or a goal for the opposing team. For this model, we apply categorical cross-entropy loss to the output probabilities (e.g., [0.1, 0.8, 0.1] indicating the probabilities of a goal by the same team, no goal, and a goal by the opponent within 15 seconds, respectively) compared to the ground truth (e.g., [0, 1, 0] if no goal is scored within 15 seconds). This 15-second duration is based on Fernández et al. (2021), reflecting the average possession duration in football.

Attempts using a sigmoid activation and linear transformation for pass value, similar to \cite{Fernández2021}, encountered vanishing gradient issues.  The U-Net architecture is selected for its proven effectiveness in image segmentation and its ability to capture both local and global contextual information, which is crucial for accurate EPV predictions.

% Model Training and Evaluation
\subsection{Model Training and Evaluation}

We split the matches into training, validation and test sets using an 80-10-10 split for Eredivisie matches and a 60-20-20 split for World Cup matches. Due to the smaller size of the World Cup data set, we assigned a higher percentage of samples to the validation and test sets to enhance their statistical relevance. Table \ref{tab:passes_comparison} shows the number of pass samples for each set.

\begin{table}[ht]
\centering
\caption{Comparison of Successful and Unsuccessful Passes}
\label{tab:passes_comparison}
\begin{tabular}{lccccc}
\hline
Dataset & Total & Training & Validation & Test & \%\_success \\ \hline
Eredivisie & 507,953  & 406,495 & 49,542 & 51,916 & 79.79\% \\
2022 World Cup & 58,569 & 34,093 & 11,787 & 12,689 & 81.52\% \\
\hline
\end{tabular}
\end{table}

The training of the EPV-OJN model using the Eredivisie dataset employs a cyclic learning rate \citep{smith2017cyclical}, which fluctuates between a base learning rate of $1 \times 10^{-6}$ and a maximum learning rate of $1 \times 10^{-4}$ following a triangular policy with a full cycle lasting 8 epochs. This method helps to avoid local minima. Subsequently, we fine-tune the model using data from the 2022 World Cup, where the maximum learning rate is decreased to $1 \times 10^{-5}$.

A batch size of 128 is used for all EPV-OJN models. This size helps improve training speed and accuracy for pass value models, as larger batches increase the likelihood of including goal-scoring events. Training stops when the validation loss does not improve for 8 consecutive epochs. After training converges, we select the epoch that provides a suitable balance between loss and calibration (as measured by ECE). One epoch covers the complete training set, and one validation step covers all validation samples. The Adam optimizer \citep{Kingma2014AdamAM} with default settings in TensorFlow 2.18 \citep{tensorflow2015-whitepaper} is employed for all models.

The models are trained and evaluated on the basis of their respective loss functions. For the pass likelihood model, binary cross-entropy loss is used to compare the predicted and actual pass destinations. The pass success model also uses binary cross-entropy loss to compare predicted pass success probabilities against actual outcomes.

For the pass value model, categorical cross-entropy loss is applied to the output probabilities (e.g., [0.1, 0.8, 0.1] indicating the probabilities of scoring a goal, having no goal, and conceding a goal within 15 seconds, respectively) compared to ground truth (e.g., [0, 1, 0] if no goal is scored within 15 seconds). The 15-second duration is based on \cite{Fernández2021}, reflecting the average possession duration in football.

Both pass success and pass value models employ temperature scaling as a post-processing step. The optimal temperature value, ranging from 0.1 to 2 with a step size of 0.1, is selected to minimize the calibration error on the validation set. Model calibration is measured using Expected Calibration Error (ECE) as described in \cite{Fernández2021}, pushing the predicted probabilities to align with the actual probabilities.
