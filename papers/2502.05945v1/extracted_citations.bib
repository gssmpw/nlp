@inproceedings{Koo2024apr,
    author = {Koo, Junghyun and Wichern, Gordon and Germain, Fran√ßois G and Khurana, Sameer and Le Roux, Jonathan},
    title = {Understanding and Controlling Generative Music Transformers by Probing Individual Attention Heads},
    booktitle = {IEEE ICASSP Satellite Workshop on Explainable Machine Learning for Speech and Audio (XAI-SA)},
    year = 2024,
    month = apr,
    url = {https://www.merl.com/publications/TR2024-032}
    }

@misc{arditi2024refusal,
    author = {Andy Arditi and Oscar Balcells Obeso and Aaquib111 and Wes Gurnee and Neel Nanda},
    title = {Refusal in LLMs is Mediated by a Single Direction},
    year = {2024},
    howpublished = {\url{https://www.alignmentforum.org/posts/jGuXSZgv6qfdhMCuJ/refusal-in-llms-is-mediated-by-a-single-direction}},
    note = {Accessed: 2024-05-21}
}

@article{gopal2023will,
  title={Will releasing the weights of large language models grant widespread access to pandemic agents?},
  author={Gopal, Anjali and Helm-Burger, Nathan and Justen, Lenni and Soice, Emily H and Tzeng, Tiffany and Jeyapragasan, Geetha and Grimm, Simon and Mueller, Benjamin and Esvelt, Kevin M},
  journal={arXiv preprint arXiv:2310.18233},
  year={2023}
}

@article{jorgensen2023improving,
  title={Improving activation steering in language models with mean-centring},
  author={Jorgensen, Ole and Cope, Dylan and Schoots, Nandi and Shanahan, Murray},
  journal={arXiv preprint arXiv:2312.03813},
  year={2023}
}

@article{lermen2023lora,
  title={Lora fine-tuning efficiently undoes safety training in llama 2-chat 70b},
  author={Lermen, Simon and Rogers-Smith, Charlie and Ladish, Jeffrey},
  journal={arXiv preprint arXiv:2310.20624},
  year={2023}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{marks2023geometry,
  title={The geometry of truth: Emergent linear structure in large language model representations of true/false datasets},
  author={Marks, Samuel and Tegmark, Max},
  journal={arXiv preprint arXiv:2310.06824},
  year={2023}
}

@article{qiu2024spectral,
  title={Spectral Editing of Activations for Large Language Model Alignment},
  author={Qiu, Yifu and Zhao, Zheng and Ziser, Yftah and Korhonen, Anna and Ponti, Edoardo M and Cohen, Shay B},
  journal={arXiv preprint arXiv:2405.09719},
  year={2024}
}

@article{rimsky2023steering,
  title={Steering llama 2 via contrastive activation addition},
  author={Rimsky, Nina and Gabrieli, Nick and Schulz, Julian and Tong, Meg and Hubinger, Evan and Turner, Alexander Matt},
  journal={arXiv preprint arXiv:2312.06681},
  year={2023}
}

@article{turner2023activation,
  title={Activation addition: Steering language models without optimization},
  author={Turner, Alex and Thiergart, Lisa and Udell, David and Leech, Gavin and Mini, Ulisse and MacDiarmid, Monte},
  journal={arXiv preprint arXiv:2308.10248},
  year={2023}
}

@article{van2024extending,
  title={Extending Activation Steering to Broad Skills and Multiple Behaviours},
  author={van der Weij, Teun and Poesio, Massimo and Schoots, Nandi},
  journal={arXiv preprint arXiv:2403.05767},
  year={2024}
}

@article{xu2024uncovering,
  title={Uncovering Safety Risks in Open-source LLMs through Concept Activation Vector},
  author={Xu, Zhihao and Huang, Ruixuan and Wang, Xiting and Wu, Fangzhao and Yao, Jing and Xie, Xing},
  journal={arXiv preprint arXiv:2404.12038},
  year={2024}
}

