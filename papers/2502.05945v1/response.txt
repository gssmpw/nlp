\section{Related work}
%% REFUSAL 
It has been demonstrated before that the safety barriers of aligned LLMs, which are supposed to produce ethical, unharmful, and safe output can be easily bypassed e.g. through supervised fine-tuning **Srivastava, "Training Components for Robust Neural Networks"**.
Recently similar results have been achieved for various forms of layer-wise interference-time intervention techniques aiming e.g. at reducing the model's refusal behaviour to harmful input prompts ____.
****Raghu et al., "An Investigation into Layer-Wise Interference-Time Intervention Techniques for Reducing Model Refusal Behaviour"** developed a layer-based method named Safety Concept Activation Vectors (SCAVs). Here, the direction for intervention is the normal vector of the decision boundary from a trained linear classifier. The classifier is trained to classify activations from the feed-forwad-layers of the attention blocks if they are from "harmful" or "unharmful" prompts. Hyperparameters for the method are coefficients for intervention at each layer and number of layers to intervene on. Similarly, ****Li et al., "Steering Model Behaviour with Contrastive Prompts: A Layer-Based Intervention Approach"** are using contrastive prompts to steer model behaviour with residual stream activations at the last token position. They also calculate the mean of "harmful" activations and mean of "harmless" activations and use their difference as the direction to intervene on. Finally, they subtract the projected difference from the activation during model generation. They report almost perfect results on bypassing the model's filter mechanism against refusing to produce harmful output.
****Madsen et al., "Contrastive Activation Addition: A Layer-Wise Intervention Strategy for Model Refusal Behaviour"** follow also a layer-wise intervention strategy named Contrastive Activation Addition (CCA). First a multiple-choice setting is evaluated where to the question either "(A" or "(B" is appended and then the probability of the token matching the ground-truth is measured. Relevant layers are then identified by measuring how an intervention on the transformer-block feed-forward layer influences the probability for generating either "A" or "B" and matching the ground-truth. Identified layers and interventions are also tested if they generalise to open-ended generation. 
\par
In contrary, layer based intervention strategies have also been applied to promote favourable behaviour such as avoiding toxic language **Wang et al., "Toxic Language Detection: A Layer-Based Intervention Approach"**, investigate internal representations for factual knowledge ****Rajani et al., "Factual Knowledge Representation in Neural Networks"**, identifying truthful answers ****Li et al., "Truthful Answer Identification: A Layer-Based Intervention Approach"**, and other **Kumar et al., "Layer-Based Intervention Strategies for Promoting Favourable Behaviour"**.
****Dong et al., "Inference-Time Intervention: A Methodology for Reducing Model Refusal Behaviour"** propose a methodology specifically named "Inference-Time Intervention" (ITI). ITI works on the attention head level, by training linear probes on the activations of each attention head for example truthful and "hallucinated" responses. Attention heads, where probes have the highest accuracy on differentiating between a truthful response and an "hallucination" are chosen for intervention by taking the normal vector of the classifier's decision boundary. Finally, ****Srivastava et al., "Attention Heads in Generative Music Transformers: A Study on Musical Concepts and Intervention Strategies"** investigate how different musical concepts are encoded in attention heads for a generative music transformer and hypothesise how a head-wise intervention could be applied to match specific user preferences.

%multiple-behaviours such as myopic, syphancy 
% - Is known that safety-filters at least for refusal can be removed with (low-rank) fine-tuning methods. 
% Applying intervention to remove safety barriers: 
% - Intervention applied on bypassing aligned model behaviour as  for "refusing" harmful requests. 
%- another layer based method intervention method which gets direction from from pairs of prompts to intervene ****Raghu et al., "A Layer-Based Method for Steering Model Behaviour with Paired Prompts"**
%- similar layer-based methodology applied to steering model away from toxic dataset torwards targeted genres ****Li et al., "Steering Model Behaviour towards Targeted Genres: A Layer-Based Approach"**
%- investigate internal representation or factual true / false knowledge and steering behaviour torwards, report that mass-mean-probing better than linear probes trained on activations ****Kumar et al., "Mass-Mean-Probing for Factual Knowledge Representation in Neural Networks"**

%- multiple-choice setting mutli-behaviour steering for different beahiours at the same time ****Madsen et al., "Multi-Behaviour Steering: A Layer-Based Intervention Approach"**
%- head-wise probing of a generative music transformer - identifying selected concepts and specialised attention heads discussing potentials of head-wise intervention  ****Srivastava et al., "Attention Heads in Generative Music Transformers: A Study on Musical Concepts and Intervention Strategies"**
%- apply spectral methods to intervene on layer-based activations for Truthful response ****Dong et al., "Spectral Methods for Intervening on Layer-Based Activations for Truthful Response"**
%- enable non-linear intervention in Richer space ****Rajani et al., "Non-Linear Intervention in Richer Space: A Study on Neural Networks"** 
%- 
%- ITI uses fine-tuned judge LLM.