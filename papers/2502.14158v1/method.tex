\section{Method}
In this section, we first present the preliminary knowledge. Then, we detail our proposed SMILE, which consists of two components: node representation learning and dual-level mixup strategy. To facilitate better understanding, we present the overall framework of the model in Fig. \ref{overall}.
\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{picture/flowchart_fin_fin.pdf}
    \caption{The overall architecture of SMILE.}
    \label{overall}
\end{figure*}
%\vspace{-1em}

\subsection{Preliminary}
Given a graph $\mathcal{G}\!=\!\{\mathcal{V},\mathcal{E},\mathrm{Z},\mathrm{A}\}$, $\mathcal{V}$ and $\mathcal{E}$ represent the sets of nodes and edges, respectively. $\mathrm{Z}\!\in\!\mathbb R^{n\times d}$ is the feature matrix of nodes and $\mathrm{A}\!\in\!\mathbb R^{n\times n}$ is the corresponding adjacency matrix. Our model adheres to the prevalent meta-learning training paradigm, which involves training on sampled tasks. In this work, we mainly focus on few-shot node classification, which is the most prevailing and representative task in graph few-shot learning. Moreover, we highlight that in our focused scenarios, the number of available meta-training tasks sampled from an unknown task distribution is extremely small compared to traditional experimental settings, referred to as \textit{few-shot node classification with fewer tasks}. Our goal is to enable the model to effectively extract meta-knowledge even from such limited tasks, which can generalize to novel tasks in the meta-testing phase. For better understanding, we summarize the main symbols of this work in \textbf{Appendix} \ref{symbol}.


\subsection{Node Representation Learning}

%\noindent \textbf{Node Representation Learning.}
Generally, the initial step involves encoding the nodes within the graph into a latent space, thereby transforming them into low-dimensional hidden vectors. GNNs have become the foremost choice for node embedding due to its powerful representational capabilities on graphs. It follows a message-passing mechanism, continuously aggregating messages from neighboring nodes to iteratively update the embedding of the target node. Guided by the simple philosophy, we adopt the SGC model \cite{wu2019simplifying} to learn node embeddings. Specifically, which can be defined as:
\begin{equation}
\label{sgc}
\begin{aligned}
\mathrm{H}\!=\!\breve{\mathrm{A}}\cdots\breve{\mathrm{A}}\mathrm{Z}\mathrm{W}^{(0)}\mathrm{W}^{(1)}\cdots\mathrm{W}^{(\ell-1)}\!=\!\breve{\mathrm{A}}^\ell\mathrm{Z}\mathrm{W}^\ast,
\end{aligned}   %\mathrm{H}^{\ell+1}\!=\!\breve{\mathrm{A}}\mathrm{H}^{\ell},
\end{equation}
%where $\breve{\mathrm{A}}\!=\!\hat{\mathrm{D}}^{-1/2}\hat{\mathrm{A}}\hat{\mathrm{D}}^{-1/2}$ is the symmetric normalized adjacency matrix with added self-loops, \textit{i.e.}, $\hat{\mathrm{A}}\!=\!\mathrm{A}+\mathrm{I}$. $\hat{\mathrm{D}}_i\!=\!\sum_j\hat{\mathrm{A}}_{i,j}$ denotes the corresponding degree matrix. $\mathrm{H}^{\ell}$ is the $\ell$-th node embeddings and $\mathrm{H}^{0}\!=\!\mathrm{Z}$ is the initialized node features. After performing graph convolution operations, we can obtain the node vectors $\mathrm{H}\!\in\!\mathbb R^{n\times d}$ that simultaneously encode node features and topology structure. %, denote as $\mathrm{X}$. %as the output node embeddings by the graph encoder.
where $\breve{\mathrm{A}}\!=\!\hat{\mathrm{D}}^{-1/2}\hat{\mathrm{A}}\hat{\mathrm{D}}^{-1/2}$ is the symmetric normalized adjacency matrix with added self-loops, \textit{i.e.}, $\hat{\mathrm{A}}\!=\!\mathrm{A}+\mathrm{I}$. $\hat{\mathrm{D}}_i\!=\!\sum_j\hat{\mathrm{A}}_{i,j}$ denotes the corresponding degree matrix. $\mathrm{W}^{\ast}$ is the collapsing weight matrices. After performing graph convolution operations, we can obtain the node vectors $\mathrm{H}\!\in\!\mathbb R^{n\times d}$ that simultaneously encode node features and topology structure. %, denote as $\mathrm{X}$. %as the output node embeddings by the graph encoder.

Given that few-shot models are highly noise-sensitivity \cite{zhang2019variational}, it is necessary to incorporate more prior knowledge to refine representations. Such prior knowledge is often reflected on node degree about the node popularity and importance \cite{Park2019estimating}. %Therefore, we consider explicitly incorporating it into the node encoding process. Specifically, we first perform linear transformation to the derived node features to assign initial scores $\kappa\!\in\!\mathbb R^{n\times 1}$. Then, based on the node degree information, we obtain the node centralities $\alpha\!\in\!\mathbb R^{n\times 1}$ to adjust the initial scores. Finally, we acquire the refined node representations $\mathrm{X}\!\in\!\mathbb R^{n\times d}$ using the adjusted scores $\beta\!\in\!\mathbb R^{n\times 1}$. The above procedures can be formulated as follows:
Therefore, we consider explicitly incorporating it to evaluate each node. Specifically, we first adopt another SGC to derive the interaction weights $\kappa\!\in\!\mathbb R^{n\times 1}$ for all nodes. Then, based on the node degree information, we obtain the node centralities $\alpha\!\in\!\mathbb R^{n\times 1}$ to perform degree normalization for adjusting $\kappa$. Finally, we acquire the refined node representations $\mathrm{X}\!\in\!\mathbb R^{n\times d}$ using the adjusted scores $\beta\!\in\!\mathbb R^{n\times 1}$. The above procedures can be formulated as follows:
\begin{equation}
\label{refine}
    \begin{aligned}
        &\kappa\!=\!\breve{\mathrm{A}}^\ell\mathrm{Z}\mathrm{W}, \quad
        \alpha\!=\!\log(\{\hat{\mathrm{D}}_i\}_{i=1}^n), \\
        &\beta\!=\!\text{softmax}(\delta(\alpha\odot\kappa)), \quad
        \mathrm{X}\!=\!\beta \odot \mathrm{H},
    \end{aligned}
\end{equation}
where $\mathrm{W}\!\in\!\mathbb R^{d\times1}$ is the trainable parameters and $\delta(\cdot)$ is the sigmoid function. $\odot$ denotes the element-wise product.

After completing the node representation learning, we introduce the few-shot setting by defining some key notations. The meta-training tasks $\mathcal{D}_{org}\!=\!\{\mathcal{T}_{t}\}_{t=1}^{\mathrm{T}_{org}}$ are sampled from a task distribution $p(\mathcal{T})$, where each task contains a support set $\mathcal{S}_t\!=\!\{(\mathrm{X}_{t,i}^s,\mathrm{Y}_{t,i}^s)\}_{i=1}^{n_s}$ and a query set $\mathcal{Q}_t\!=\!\{(\mathrm{X}_{t,i}^q,\mathrm{Y}_{t,i}^q)\}_{i=1}^{n_q}$, denoted as $\mathcal{T}_t\!=\!\{\mathcal{S}_t,\mathcal{Q}_t\}$. Here, $\mathrm{X}_{t,i}^\ast$ and $\mathrm{Y}_{t,i}^\ast\!\in\!\mathcal{Y}_{tra}$ denote the node embeddings and its label, where $\mathcal{Y}_{tra}$ denotes the set of base classes. For the meta-testing task $\mathcal{T}_{tes}\!=\!\{\mathcal{S}_{tes},\mathcal{Q}_{tes}\}\!=\!\{\{(\mathrm{X}_{tes,i}^s,\mathrm{Y}_{tes,i}^s)\}_{i=1}^{n_s}, \{(\mathrm{X}_{tes,i}^q,\mathrm{Y}_{tes,i}^q)\}_{i=1}^{n_q}\}$, it is composed in the same way as the meta-training task $\mathcal{T}_t$, with the only difference being that the node label belong to the novel class set $\mathcal{Y}_{tes}$, which is disjoint from $\mathcal{Y}_{tra}$, \textit{i.e.}, $\mathcal{Y}_{tra}\!\cap\!\mathcal{Y}_{tes}\!=\!\emptyset$. When the support set $\mathcal{S}_{tes}$ consists of $N$ sampled classes, each with $K$ nodes, we refer to it as an $N$-way $K$-shot problem. The construction of $\mathcal{Q}_{tes}$ is the same as $\mathcal{S}_{tes}$, except that each class has $M$ nodes. Typically, the model is first trained on the meta-training tasks $\mathcal{D}_{org}$. During the meta-testing stage, the model is fine-tuned on $\mathcal{S}_{tes}$ and then is evaluated the performance on $\mathcal{Q}_{tes}$. 
\subsection{Dual-level Mixup Strategy}
%As stated before, if

%\noindent \textbf{Dual-level Mixup Strategy.}
If we directly conduct few-shot learning on the refined representations, the model's performance would be degraded due to overfitting and constrained generalization. Therefore, we introduce a dual-level mixup strategy, including within-task and across-task mixup, to deal with this issue. Next, we will provide detailed descriptions of each technique.

%\paragraph{Intra-task Mixup.}
%\noindent \textbf{Within-task Mixup.} 
\subsubsection{Within-task Mixup} 
Due to the exceedingly restricted number of sampled nodes in both the support set and query set for each task during the meta-training phase, the efficiency of the meta-training is considerably compromised. Hence, we propose using the within-task mixup strategy to generate more samples for increasing the diversity of the data. Concretely, for a given meta-training task $\mathcal{T}_t$, we perform random sampling on the support set $\mathcal{S}_t$ and query set $\mathcal{Q}_t$, selecting two samples $i$ and $j$ from the same category $k$ for linear interpolation to generate a new one $r$. The above procedure can be formulated as:
\begin{equation}
    \label{intra}
    \begin{aligned}
        \mathrm{X}_{t,r;k}^{\prime s}\!=\!\lambda\mathrm{X}_{t,i;k}^s\!+\! (1\!-\!\lambda)\mathrm{X}_{t,j;k}^s, \quad     \mathrm{X}_{t,r;k}^{\prime q}\!=\!\lambda\mathrm{X}_{t,i;k}^q\!+\! (1\!-\!\lambda)\mathrm{X}_{t,j;k}^q,
    \end{aligned}
\end{equation}
where $\lambda\!\in\![0,1]$ is sampled from the Beta distribution $Beta(\eta,\gamma)$ specified by $\eta$ and $\gamma$.%, \textit{i.e.}, $\lambda\sim Beta(\eta,\gamma)$.

Here, we do not perform label interpolation as the labels of the two sampled nodes are the same, resulting in identical labels for the generated node. There are two reasons for this. First, interpolating samples from different categories would make it difficult to compute prototypes of the mixed labels while expanding the node label space of the original task. Second, this would pose intricate troubles for the subsequent across-task interpolation.

We iteratively apply Eq.\ref{intra} to generate the additional support set $\mathcal{S}_t^\prime\!=\!\{(\mathrm{X}_{t,i}^{\prime s},\mathrm{Y}_{t,i}^s)\}_{i=1}^{n_{s^\prime}}$ and query set $\mathcal{Q}_t^\prime\!=\!\{(\mathrm{X}_{t,i}^{\prime q},\mathrm{Y}_{t,i}^q)\}_{i=1}^{n_{q^\prime}}$, which are subsequently merged with the original corresponding sets to obtain the augmented task $\mathcal{T}_t$ (To avoid introducing extra symbols, we consistently use $\mathcal{T}_t$ to denote the task that undergoes within-task mixup in the following sections.), \textit{i.e.}, $\mathcal{T}_t\!=\!\{\mathcal{S}_t\!\cup\!\mathcal{S}_t^\prime,\mathcal{Q}_t\!\cup\!\mathcal{Q}_t^\prime\}$. The number of nodes in the amplified support and query sets of the augmented task $\mathcal{T}_t$ are $m^\prime\!=\!n_s\!+\!n_{s^\prime}$ and $m\!=\!n_q\!+\!n_{q^\prime}$, respectively.

%\paragraph{Inter-task Mixup.}
%\noindent \textbf{Across-task Mixup.} 
\subsubsection{Across-task Mixup} 
Solely conducting within-task mixup does not address the issue of the limited number of tasks. Therefore, we utilize across-task mixup to directly create new tasks, densifying the task distribution. Specifically, \textit{in the first step}, we randomly select two tasks, $\mathcal{T}_i$ and $\mathcal{T}_j$, from the given meta-training tasks $\mathcal{D}_{org}\!=\!\{\mathcal{T}_t\}_{t=1}^{\mathrm{T}_{org}}$. \textit{In the second step}, we randomly sample a class $k$ from the support set $\mathcal{S}_i$ of $\mathcal{T}_i$ and a class $k^\prime$ from the support set $\mathcal{S}_j$ of $\mathcal{T}_j$, and then compute class-specified support prototypes. This procedure can be expressed as:
%\vspace{-1em}
\begin{equation}
\label{prototype}
    \begin{aligned}
        &\mathrm{C}_{i;k}^s\!=\!\frac{1}{|\mathcal{S}_{i;k}|}\sum_{(\mathrm{X}_{i,\varrho}^s\;,\mathrm{Y}_{i,\varrho}^s)\in\mathcal{S}_{i}}\mathbb{I}_{\mathrm{Y}_{i,\varrho}=k}\mathrm{X}_{i,\varrho}^s \;, \\ &\mathrm{C}_{j;k^\prime}^s\!=\!\frac{1}{|\mathcal{S}_{j;k^\prime}|}\sum_{(\mathrm{X}_{j,\varrho}^s\;,\mathrm{Y}_{j,\varrho}^s)\in\mathcal{S}_{j}}\mathbb{I}_{\mathrm{Y}_{j,\varrho}=k^\prime}\mathrm{X}_{j,\varrho}^s\;,
    \end{aligned}
\end{equation}
where $\mathbb I(\cdot)$ is the indicator function that is 1 when $\mathrm{Y}_{i,\varrho}\!=\!k$, and 0 otherwise. Similarly, we can obtain query prototypes $\mathrm{C}_{i;k}^q$ for class $k$ and $\mathrm{C}_{j;k^\prime}^q$ for class $k^\prime$ by applying Eq.\ref{prototype} to the query sets $\mathcal{Q}_i$ of $\mathcal{T}_i$ and $\mathcal{Q}_j$ of $\mathcal{T}_j$.

\textit{In the third step}, we individually perform feature-level linear interpolation on the support prototypes and query prototypes to generate new samples. Considering that different tasks have different label spaces, we directly treat the label associated with the interpolated data as a new class $\tilde{k}$. We can formulate the above process as:
\begin{equation}
\label{proto_mix}
    \begin{aligned}
        %\tilde{\mathrm{X}}_{t;\tilde{k}}^s\!&=\!\lambda\mathrm{X}_{i;k}^s\!+\!(1\!-\!\lambda)\mathrm{X}_{j;k^\prime}^s, \quad \tilde{\mathrm{Y}}_{t;\tilde{k}}^s\!=\!\Phi(\mathrm{Y}_{i;k}^s,\mathrm{Y}_{j;k^\prime}^s), \\
        %\tilde{\mathrm{X}}_{t;\tilde{k}}^q\!&=\!\lambda\mathrm{X}_{i;k}^q\!+\!(1\!-\!\lambda)\mathrm{X}_{j;k^\prime}^q, \quad \tilde{\mathrm{Y}}_{t;\tilde{k}}^q\!=\!\Phi(\mathrm{Y}_{i;k}^q,\mathrm{Y}_{j;k^\prime}^q), \\
        \tilde{\mathrm{X}}_{t,\varrho;\tilde{k}}^s\!&=\!\lambda\mathrm{C}_{i;k}^s\!+\!(1\!-\!\lambda)\mathrm{C}_{j;k^\prime}^s, \quad \tilde{\mathrm{Y}}_{t,\varrho;\tilde{k}}^s\!=\!\Phi(\mathrm{Y}_{i;k}^s,\mathrm{Y}_{j;k^\prime}^s), \\
        \tilde{\mathrm{X}}_{t,\varrho;\tilde{k}}^q\!&=\!\lambda\mathrm{C}_{i;k}^q\!+\!(1\!-\!\lambda)\mathrm{C}_{j;k^\prime}^q, \quad \tilde{\mathrm{Y}}_{t,\varrho;\tilde{k}}^q\!=\!\Phi(\mathrm{Y}_{i;k}^q,\mathrm{Y}_{j;k^\prime}^q),
    \end{aligned}
\end{equation}
where $\Phi(\cdot,\cdot)$ represents the label uniquely determined by the pair $(\cdot,\cdot)$. We perform $m^\prime$ iterations for the support data and $m$ iterations for the query data in Eq.\ref{proto_mix}, %We execute Eq.\ref{proto_mix} $K$ times to yield $K$-shot samples, 
\textit{i.e.}, $\{\tilde{\mathrm{X}}_{t,\varrho;\tilde{k}}^s,\tilde{\mathrm{Y}}_{t,\varrho;\tilde{k}}^s\}_{\varrho=1}^{m^\prime}$ and $\{\tilde{\mathrm{X}}_{t,\varrho;\tilde{k}}^q,\tilde{\mathrm{Y}}_{t,\varrho;\tilde{k}}^q\}_{\varrho=1}^{m}$. Note that the sampled $\lambda$ each time is different.

\textit{Finally}, we repeat the second and third steps $N$ times to construct an $N$-way $m^\prime$-shot interpolation task $\mathcal{T}_t^{aug}\!=\!\{\tilde{\mathcal{S}}_t,\tilde{\mathcal{Q}}_t\}\!=\!\{\{\tilde{\mathrm{X}}_{t;\tilde{k}}^s,\tilde{\mathrm{Y}}_{t;\tilde{k}}^s\}_{\tilde k=1}^N, \{\tilde{\mathrm{X}}_{t;\tilde{k}}^q, \tilde{\mathrm{Y}}_{t;\tilde{k}}^q\}_{\tilde k=1}^N\}$. We can conduct the above process multiple times to obtain the interpolated tasks $\mathcal{D}_{aug}\!=\!\{\mathcal{T}_t^{aug}\}_{t=1}^{\mathrm{T}_{aug}}$ and merge them with the original tasks $\mathcal{D}_{org}$ to form the final meta-training tasks $\mathcal{D}_{all}\!=\!\mathcal{D}_{org}\!\cup\!\mathcal{D}_{aug}$. The number of tasks in $\mathcal{D}_{all}$ is $\mathrm{T}\!=\!\mathrm{T}_{org}\!+\!\mathrm{T}_{aug}$.
%\subsection{Model Training}

\noindent \textbf{Model Training.}
After performing the dual-level mixup operation, we adopt a classic metric-based episodic training for few-shot node classification. We first derive the prototype $\mathrm{C}_k$ in the support set $\mathcal{S}_t$ of each task $\mathcal{T}_t$ from $\mathcal{D}_{all}$ with the manner shown in Eq.\ref{prototype}.
% \begin{equation}
% \label{compute}
%     \mathrm{C}_k\!=\!\frac{1}{|\mathcal{S}_{t,k}|}\sum_{(\mathrm{X}_{t,i}^s,\mathrm{Y}_{t,i}^s)\in\mathcal{S}_{t}}\mathbb{I}_{\mathrm{Y}_{t,i}=k}\mathrm{X}_{t,i}^s,
% \end{equation}
% where $\mathbb I(\cdot)$ is the indicator function that is 1 when $\mathrm{Y}_{t,i}\!=\!k$, and 0 otherwise.

Next, we optimize the parameters of the model by performing distance-based cross-entropy loss function on all query sets in $\mathcal{D}_{all}$ as:
\begin{equation}
\label{proto}
    \mathcal{L}=%\mathbb E_{\mathcal{T}\sim p(\mathcal{T})}\left[-\sum_{i,k}\log p(\mathrm{Y}_i^q=k|\mathrm{X}_i^q)\right]=\mathbb E_{\mathcal{T}}
\sum_{t=1}^\mathrm{T}\sum_{i=1}^{m}\mathbb I_{\mathrm{Y}_{t,i}=k}\log\frac{\exp(-d(\theta^\top\mathrm{X}_{t,i}^q,\mathrm{C}_k))}{\sum\nolimits_{k^\prime}\exp(-d(\theta^\top\mathrm{X}_{t,i}^q,\mathrm{C}_{k^\prime}))},
\end{equation}
where $d(\cdot,\cdot)$ is the Euclidean distance function and $\theta$ is the trainable vector.

In the meta-testing stage, we do not perform any mixup operations for the evaluated task $\mathcal{T}_{tes}$. Actually, we first use the well-trained model to compute class prototypes on the support set, and then assign samples in the query set to their nearest prototype, defined as: %we fine-tune the well-trained model on the $\mathcal{S}_{tes}$ and apply it into $\mathcal{Q}_{tes}$ to obtain the model performance.
\begin{equation}
    \label{meta-test}
    \begin{aligned}
        &\mathrm{C}_{k}\!=\!\frac{1}{|\mathcal{S}_{tes,k}|}\sum_{(\mathrm{X}_{tes,i}^s,\mathrm{Y}_{tes,i}^s)\in\mathcal{S}_{tes}}\mathbb{I}_{\mathrm{Y}_{tes,i}=k}\mathrm{X}_{tes,i}^s, \\        &\mathrm{Y}_{tes,\ast}^q\!=\!\text{argmin}_kd(\theta^\top\mathrm{X}, \mathrm{C}_k).
    \end{aligned}
\end{equation}

We present the process of proposed SMILE in \textbf{Appendix} \ref{training_procedure}. The time complexity analysis of SMILE are presented in \textbf{Appendix} \ref{complexity}.