\section{Introduction}
As a fundamental data structure, graphs can effectively model complex relationships between objects and they are ubiquitous in the real world. %Node classification, as a crucial task in graph learning, has consistently garnered sustained attention from researchers. 
Graph neural networks (GNNs) %, due to their powerful representation capabilities for graph-structured data, 
have been widely employed as an effective tool for graph %to learn informative node embeddings for downstream 
task analysis \cite{kipf2016semi, liu2021vplag, liu2021deep, liu2023time, liulocal, li2024simple, liu2024simple, liu2024improved, liu2024resolving, liu2025boosting, liu2025improved, liu2025enhancing}. Prevailing GNN models are designed under the supervised learning paradigm, which implies that they require abundant labeled data to achieve satisfactory classification performance \cite{ding2020graph, tan2022transductive}. Given the limited number of labeled nodes per class, known as few-shot cases \cite{zhang2022few, liu2022few}, 
these models suffer from severe overfitting, leading to a significant performance decline \cite{liu2019learning, huang2020graph}. %In cases of scarce labels, particularly in few-shot scenarios, they are highly susceptible to overfitting issues, leading to severe performance degradation \cite{liu2019learning}. 

Meta-learning has emerged as a viable option for effectively learning from limited labeled data. %The currently prevalent meta-learning models, 
Its core concept is to train on tasks instead of instances as training units, aiming to capture the differences between tasks to enhance the model generalizability \cite{hospedales2021meta}. Several pioneering models \cite{zhou2019meta, wang2022task} have attempted to leverage integrate GNNs and meta-learning techniques to address graph few-shot learning problems. %few-shot node classification, a representative task in graph few-shot learning, %with few-shot node classification as a representative task, and have achieved remarkable performance. %with impressive performance. 
However, these graph meta-learning models all assume the existence of abundant accessible meta-training tasks to extract generalizable meta-knowledge for rapid adaptation to meta-testing tasks with only a few labeled instances. In other words, their outstanding performance critically depends on a wide range of meta-training tasks. %all presuppose the availability of a substantial number of accessible meta-training tasks, which are utilized to extract generalizable meta-knowledge for swift adaptation to meta-testing tasks characterized by a limited number of labeled instances. In essence, the exceptional performance of these models is heavily contingent on a diverse array of meta-training tasks.
For many real-world applications, due to the difficulty of task generation or data collection, we may not be able to obtain an adequate number of meta-training tasks \cite{tan2022transductive, yao2021meta, lee2022set}. For molecular property prediction, %given the limited known chemical properties (\textit{i.e.}, classes), 
labeling newly discovered chemical compounds requires extensive domain knowledge and expensive wet-lab experiments \cite{Guo21few}. Moreover, even after annotation, the currently known chemical properties (\textit{i.e.}, classes) are limited, encompassing only common molecular characteristics such as polarity, solubility, and toxicity \cite{livingstone2000characterization}. %Therefore, it is infeasible to construct numerous meta-training tasks in the real-world. %For example, 
%If we only know six types of chemical properties, each with a few labeled compounds, then we can construct at most six 5-way meta-training tasks. %For example, in biological networks, numerous domain knowledge is required to label newly discovered protein nodes, which is a challenging task even for veteran researchers \cite{hu2019strategies}. 

To further support our argument, we select three representative graph meta-learning models (\textit{i.e.}, GPN \cite{ding2020graph}, G-Meta \cite{huang2020graph}, and Meta-GPS \cite{liu2022few}) and evaluate their performance under varying numbers of meta-training tasks in Fig. \ref{comparison}. We distinctly observe that as the number of available meta-training tasks decreases, the overall performance of all methods greatly deteriorates. Because they tend to memorize meta-training tasks directly, which significantly constrains their generalization ability to novel tasks in the meta-testing stage \cite{rajendran2020meta}.
%\vspace{-0.5em}
\begin{figure}
    \centering
    \subfigure[Amazon-Clothing]{\includegraphics[width=0.22\textwidth]{picture/task_num_clothing.pdf}}
        \subfigure[Cora-Full]{\includegraphics[width=0.22\textwidth]{picture/task_num_corafull.pdf}}
    \caption{Model performance varies with the number of meta-training tasks across different datasets.}
    \label{comparison}
\end{figure}
%\vspace{-0.01em}
This naturally raises a pressing question for us in more realistic scenarios: \textit{How can we perform graph few-shot learning in scenarios with fewer tasks to extract as much transferable meta-knowledge as possible, thereby enhancing the model generalization performance?} Regarding this, although some recent studies \cite{tan2023virtual, kim2023task} have made some efforts on this issue, they primarily employ intricate network architectures to endow models with favorable characteristics, yet there is still room for improvement. We argue that there are two serious issues for our focused scenarios, which greatly hamper the model performance. \textit{On the one hand}, there are only limited support samples available for training within each meta-training task, which complicates the accurate reflection of the real data distribution. Therefore, it poses a challenge for the model to effectively capture the data characteristics, severely affecting its inductive bias capability \cite{ni2021data}. \textit{On the other hand}, when there are only limited meta-training tasks available, the model tends to directly fit the biased task distribution. This implies not only a shortage of data for each task, but also a reduced number of available tasks. %This means that not only is there a scarcity of data for each task, but there are also fewer tasks available. %It means that not only is there scarcity of data in each task, but also fewer tasks available. %That be saying, not only is there scarcity of data in each task, but there are also fewer tasks available. %In summary, there is a scarcity of data within each task, and there are also fewer tasks available. 
The combined effect of these two factors increases the unnecessary oscillation during predictions outside the training examples, leading to reduced generalization capability. %These two factors together increase the unnecessary oscillation of the model when making predictions outside the training examples, leading to reduced generalization capability.
%As the number of available meta-training tasks decreases, these models are susceptible to overfitting as they tend to memorize ones directly, significantly constraining their generalization ability to novel tasks in the meta-testing stage. We select several representative graph meta-learning models, and show their performance with varying numbers of meta-training tasks in Fig. \ref{comparison}. The results distinctly support our argument. %The results presented in Fig. \ref{comparison} distinctly corroborates our argument.

%However, optimizing the single model is prone to overfitting since we are given only a small number of meta-training tasks. The meta-learner tends to memorize the meta-training tasks, which limits its generalization to new tasks at meta-test time \cite{ yin2019meta, rajendran2020meta}.
%Our model considerably outperforms other baselines and can even achieve up to 20\% improvement on certain datasets.

To address these issues mentioned above, we develop a \textbf{S}i\textbf{M}ple yet effect\textbf{I}ve approach for graph few-shot \textbf{L}earning with f\textbf{E}wer tasks, namely, \textbf{SMILE}. %In this work, we mainly focus on few-shot node classification tasks, which is a fundamental task extensively studies by previous researches. 
Specifically, given the graph data, we first obtain discriminative node embeddings using our designed graph encoder. In this process, we introduce node degrees as prior information to fully utilize valuable information present in the existing graph. Then, we introduce a dual-level mixup strategy that operates on the obtained hidden node representations, consisting of both within-task and across-task mixup. The former involves random sampling of two instances from the same category within a task and applies linear interpolation to generate new samples, thereby enriching the data distribution. The latter requires computing class prototypes in two randomly selected original meta-training tasks, and then linearly interpolating class prototypes from different tasks to generate new tasks, thereby densifying the task distribution. %The latter entails computing class prototypes within randomly selected two original meta-training tasks, and then applying linear interpolation to classes prototypes from different tasks to generate new tasks, thereby densifying the task distribution. 
These two employed strategies effectively mitigate the adverse effects caused by sample and task scarcity. %The two strategies employed effectively mitigate the adverse effects brought about by sample scarcity and task scarcity. %The former randomly samples two instances of the same category within a task and performs linear interpolation to generate new instances, enriching the data distribution. While the latter randomly samples two original meta-training tasks and performs linear interpolation to generate new tasks, densifying the task distribution.
Empirically, despite its simplicity and the absence of sophisticated techniques, the proposed approach demonstrates remarkable performance. %exhibits impressive performance. 
Furthermore, we provide a theoretical elucidation of the underlying mechanism of our method, demonstrating its ability to constrict the upper bound of generalization error and consequently achieve superior generalization. %Moreover, theoretically, we elucidate the underlying mechanism of our method, showcasing its capacity to tight the upper bound of generalization error and thus achieve superior generalization. %we present the working mechanism behind our method, demonstrating its ability to tight the generalization error, thereby achieving better generalization. 
In summary, our contributions can be summarized as follows:

\noindent $\bullet$ We propose a simple yet effective approach, SMILE, which leverages dual-level task mixup technique and incorporates the node degrees prior information, for graph few-shot learning with fewer tasks. 

\noindent $\bullet$ We theoretically analyze the reasons why our approach works, demonstrating its ability to enhance generalization performance by regularizing model weights.

\noindent $\bullet$ We conduct extensive experiments on the several datasets, and the results show that SMILE can considerably outperform other competitive baselines by a large margin with in-domain and cross-domain settings.