\section*{Appendix}
\section{Description of Symbols}
\label{symbol}

We summarize the used important symbols in Table \ref{symbols}.

\begin{table}[!ht]
\renewcommand{\thetable}{S1}
\centering
\caption{Descriptions of the symbols.}
\label{symbols}
\resizebox{0.5\textwidth}{!}{%
\begin{tabular}{@{}c|c@{}}
\toprule
Symbols & Descriptions \\ \midrule
    $\mathcal{G}, \mathcal{V}, \mathcal{E}$    & Graph, node set, and edge set             \\
    $\mathrm{Z}, \mathrm{A}$    & Initialized node features and adjacency matrix             \\
    $\hat{\mathrm{D}}, \mathrm{H}, \mathrm{X}$    &  Degree matrix, hidden vectors, and refined vectors            \\
    $\kappa, \alpha, \beta$    &   Interaction weights, node centralities, and adjusted scores           \\
    $N, K, M$    & $N$ way, $K$ shot, $M$ query \\
    $\mathcal{D}_{org}$    &   Original meta-training tasks           \\ 
    $\mathcal{D}_{aug}$ & Generated meta-training tasks \\ 
    $\mathcal{D}_{all}$ & All original and generated meta-training tasks  \\
    $\mathcal{S}_t, \mathcal{Q}_t$ & Support and query set \\
    $n_s, n_q$ & Number of samples in $\mathcal{S}_t$ and $\mathcal{Q}_t$ \\
    $\mathcal{T}_{tes}$ & Meta-testing task \\
    $\mathcal{S}_{tes}, \mathcal{Q}_{tes}$ & Support and query set of $\mathcal{T}_{tes}$ \\
    $\eta, \zeta$ & Hyperparameters in Beta distribution \\
    $\lambda$ & Random variable drawn from Beta distribution \\
    $\mathcal{S}_t^\prime, \mathcal{Q}_t^\prime$ & Generated support and query set \\
    $n_{s^\prime}, n_{q^\prime}$ & Number of samples in $\mathcal{S}_t^\prime$ and $\mathcal{Q}_t^\prime$ \\
    $m^\prime, m$ & Number of samples in $\mathcal{S}_t\cup\mathcal{S}_t^\prime$ and $\mathcal{Q}_t\cup\mathcal{Q}_t^\prime$ \\
    $\mathcal{T}_t^{aug}, \tilde{\mathcal{S}}, \tilde{\mathcal{Q}}$ & Interpolated task with its support and query set \\
    $\mathrm{T}_{org}$ & Number of tasks in $\mathcal{D}_{org}$ \\
    $\mathrm{T}_{aug}$ & Number of tasks in $\mathcal{D}_{aug}$ \\
    $\mathrm{T}$ & Number of tasks in $\mathcal{D}_{all}$ \\
    \bottomrule
\end{tabular} %
}
\end{table}


\section{Training Procedure}
We present the training procedure of the proposed SMILE in Algorithm \ref{pseudo}.

\label{training_procedure}
\begin{algorithm}[ht]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\caption{The process of SMILE}
\label{pseudo}
\begin{algorithmic}[1]
\REQUIRE A graph $\mathcal{G}\!=\!\{\mathcal{V},\mathcal{E},\mathrm{Z},\mathrm{A}\}$.\\
\ENSURE The well-trained SMILE.
\STATE // \textit{Meta-training process}
    \WHILE{\textit{not convergence}}
    \STATE Learn node embeddings using Eq.\ref{sgc}.
    \STATE Refine node embeddings using Eq.\ref{refine}.
    \STATE Construct meta-training tasks $\mathcal{D}_{org}$. %and meta-testing task $\mathcal{T}_{tes}$.
    \STATE Perform within-task mixup to obtain the augmented task $\mathcal{T}_t$ using Eq.\ref{intra}.
    \STATE Perform across-task mixup to obtain the interpolated task $\mathcal{T}_t^{aug}$ using Eqs.\ref{prototype} and \ref{proto_mix}.
    \STATE Form the interpolated tasks $\mathcal{D}_{aug}$.
    \STATE Obtain the enriched meta-training tasks $\mathcal{D}_{all}$.
    \STATE Compute the prototypes of support set for each task using Eq.\ref{prototype}.
    \STATE Optimize the model using Eq.\ref{proto}.
    \ENDWHILE
    \STATE // \textit{Meta-testing process}
    \STATE Construct meta-testing task $\mathcal{T}_{tes}$.
    \STATE Compute the prototypes in $\mathcal{S}_{tes}$ %and  predict the node labels in $\mathcal{Q}_{tes}$ 
    using Eq.\ref{meta-test}.  %Fine-tune the model using $\mathcal{S}_{tes}$.
    \STATE Predict the node labels in $\mathcal{Q}_{tes}$. %using the fine-tuned model. 
\end{algorithmic}
\end{algorithm}


\section{Complexity Analysis}
\label{complexity}
We analyze the time complexity of our proposed model to demonstrate its effectiveness. Our model mainly contains two parts, including node presentation learning and dual-level mixup. As linear interpolation is employed in the dual-level mixup, it does not introduce additional time complexity. Basically, most of the time-consuming operations arise from the node embedding process. Here, we choose SGC as the base graph encoder, which removes layer-wise non-linear operations and performs feature extraction in a parameter-free manner. The required time complexity of this step is $O(n^2d)$, where $n$ and $d$ denote the number of nodes and the dimension of node features, respectively. Note that as feature extraction does not require any weights, it is essentially equivalent to a preprocessing step and can be precomputed in practice. Moreover, in the procedure of incorporating degree-based prior information to obtain the refined node representations, the required time complexity is $O(2nd+n)$. Thus, the overall time complexity of our approach is $O(n^2d) + O(2nd+n)$, which is acceptable to us.

\section{Statistics and Descriptions of Datasets}
\label{dataset_description}
In this section, we provide detailed statistics and descriptions of the used datasets, which have been widely used in previous studies \cite{ding2020graph, liu2022few, wang2022task}. The detailed descriptions are provided below.

\noindent $\bullet$ \textbf{Amazon-Clothing} \cite{mcauley2015inferring}: It is a product network constructed from the ``Clothing, Shoes, and Jewelry'' category on Amazon. In this dataset, each product is treated as a node, and its description is used to construct node features. A link is created between products if they are co-viewed. The labels are defined as the low-level product class. For this dataset, we use the 40/17/20 class split for meta-training/meta-validation/meta-testing.

\noindent $\bullet$ \textbf{CoraFull} \cite{bojchevski2017deep}: It is a prevalent citation network. Each node represents a paper, and an edge is created between two papers if one cites the other. The nodes are labeled based on the topics of the papers. This dataset extends the previously widely used small dataset Cora by extracting raw data from the entire network. For this dataset, we use a 25/20/25 node class split for meta-training/meta-validation/meta-testing.

\noindent $\bullet$ \textbf{Amazon-Electronics} \cite{mcauley2015inferring}: It is another Amazon product network that contains products belonging to the ``Electronics" category. Each node represents a product, with its features representing the product description. An edge is created between products if there is a co-purchasing relationship. The low-level product categories are used as class labels. For this dataset, we use a 90/37/40 node category split for meta-training/meta-validation/meta-testing.

\noindent $\bullet$ \textbf{DBLP} \cite{tang2008arnetminer}: It is a citation network where each node represents a paper, and the edges represent citation relationships between different papers. The abstracts of the papers are used to construct node features. The class labels of the nodes are defined as the publication venues of the papers. For this dataset, we use an 80/27/30 node category split for meta-training/meta-validation/meta-testing.


\section{Descriptions of Baselines}
\label{baseline}
In this section, we present the detailed descriptions of the selected baselines below.

\subsection{Traditional Meta-learning Method}
\noindent \textbf{Protonet} \cite{snell2017prototypical}: It learns a metric space by acquiring prototypes of different categories from the support set and computes the similarity between the query samples and each prototype to predict their categories.

\noindent \textbf{MAML} \cite{finn2017model}: It enables the meta-trainer to obtain a well-initialized parameter by performing one or more gradient update steps on the model parameters, allowing for rapid adaptation to downstream novel tasks with limited labeled data.

\subsection{Meta-learning with Fewer Tasks Method}
\noindent \textbf{MetaMix} \cite{yao2021improving}: It enhances meta-training tasks by linearly combining the features and labels of samples from the support and query sets to improve the generalization of the model.

\noindent \textbf{MLTI} \cite{yao2021meta}: It generates additional tasks by randomly sampling a pair of tasks and interpolating their corresponding features and labels, replacing the original tasks for training.

\noindent \textbf{Meta-Inter} \cite{lee2022set}: It proposes a domain-agnostic task augmentation method that utilizes expressive neural set functions to densify the distribution of meta-training tasks through a bi-level optimization process.

\subsection{Graph Meta-learning Method}
\noindent \textbf{Meta-GNN} \cite{zhou2019meta}: It seamlessly integrates MAML and GNNs in a straightforward manner, leveraging the MAML framework to acquire useful prior knowledge from previous tasks during the process of learning node embeddings, enabling it to rapidly adapt to novel tasks.

\noindent \textbf{GPN} \cite{ding2020graph}: It adopts the concept of Protonet for the few-shot node classification task. It uses a GNN-based encoder and evaluator to learn node embeddings and assess the importance of these nodes, while assigning novel samples to their closest categories.

\noindent \textbf{G-Meta} \cite{huang2020graph}: It constructs an individual subgraph for each node, transmits node-specific information within these subgraphs, and employs meta-gradients to learn transferable knowledge based on the MAML framework.

\noindent \textbf{Meta-GPS} \cite{liu2022few}: It cleverly introduces prototype-based parameter initialization, scaling, and shifting transformations to better learn transferable meta-knowledge within the MAML framework and adapts to novel tasks more quickly.

\noindent \textbf{X-FNC} \cite{wang2023few}: It first performs label propagation to obtain rich pseudo-labeled nodes based on Poisson learning, and then filters out irrelevant information through classifying nodes and an information bottleneck-based method to gather meta-knowledge across different meta-tasks with extremely supervised information.

\noindent \textbf{COSMIC} \cite{wang2023contrastive}: It proposes a contrastive meta-learning framework, which first explicitly aligns node embeddings by contrasting two-step optimization within each episode, and then generates hard node classes through a similarity-sensitive mixing strategy.

\noindent \textbf{TLP} \cite{tan2022transductive}: It introduces the concept of transductive linear probing, initially pretraining a graph encoder through graph contrastive learning, and then applying it to obtain node embeddings during the meta-testing phase for downstream tasks. 

\noindent \textbf{TEG} \cite{kim2023task}: It designs a task-equivariant graph few-shot learning framework, leveraging equivariant neural networks to learn adaptive task-specific strategies, aimed at capturing task inductive biases to quickly adapt to unseen tasks.

\subsection{Implementation Details of Baselines}
For traditional meta-learning models, we follow the same settings as \cite{ding2020graph, liu2022few}, and conduct careful hyperparameter search and report their optimal performance. For meta-learning with fewer tasks models, we uniformly use SGC as the graph encoder. Moreover, we adopt the following additional experimental settings. Specifically, for MetaMix, we allow it to perform task augmentation by generating the same number of nodes as those in the original support and query sets for each meta-training task. For MLTI and Meta-Inter, we make them to generate the same number of additional tasks as in our experiments to ensure fairness. For graph meta-learning baselines, we use the hyperparameters recommended in the original papers. All the experiments are conducted by NVIDIA 3090Ti GPUs with the Python 3.7 and PyTorch 1.13 environment.


% \section{Visualization Study}
% \label{visualization_study}
% \begin{figure*}[ht]
% \renewcommand{\thefigure}{S3}
%     \centering
%     \subfigure[within-task mixup]{\includegraphics[width=0.52\textwidth]{picture/intra_task_emb_fin.pdf}}
%     \subfigure[across-task mixup]{\includegraphics[width=0.505\textwidth]{picture/inter_task_embedding_fin.pdf}}
%     \caption{Visualization of the dual-level mixup strategies. In (a), the original nodes in each task are represented by triangles, while the generated nodes are represented by circles, with colors indicating the corresponding classes. In (b), the original tasks are represented by triangles, the generated tasks are represented by circles, and the colors indicate the most similar original tasks.}
%     \label{Vis}
% \end{figure*}
% To visually present the introduced dual-level mixup strategy, we leverage t-SNE \cite{van2008visualizing} to visualize the results of dual-level mixup on the Amazon-clothing dataset under the 5-way 5-shot with 5 tasks few-shot setting, as shown in Fig. \ref{Vis}. Specifically, in the within-task mixup, we randomly select one task consisting of support and query sets. In the across-task, we interpolate 50 tasks, where the task embeddings are the average of the contained node embeddings. According to Fig. \ref{Vis}, we observe that the interpolated nodes within each task and the interpolated tasks generated by SMILE indeed densify the node and task distributions, thereby enhancing the model generalization capability.