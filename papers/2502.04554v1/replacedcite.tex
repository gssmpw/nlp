\section{Related Work}
\label{sec:related}
\subsection{Data Valuation}\label{sec:related_dv}

Data valuation seeks to quantify the contribution of individual training samples to model performance. Game-theoretic approaches have dominated this field, beginning with Data Shapley ____, which adapts the Shapley value from cooperative game theory to quantify data contributions. This seminal work inspired various extensions, including Beta Shapley ____, which introduces a family of semi-values through Beta function weighting, and Data Banzhaf ____, which provide robust valuation frameworks through binary-weighted marginal contributions. While these general methods are computationally intensive, specialized approaches like ____ achieve near-linear time complexity by exploiting algorithmic structures such as K-Nearest Neighbors, compared to the exponential complexity of model-agnostic approaches. Recent developments address specific challenges in data valuation: ____ proposed CS-Shapley for better handling class-wise contributions in classification tasks, while ____ introduced PC-Winter value to tackle the unique challenges of graph-structured data valuation. Alternative theoretical frameworks, such as the Core ____, have also emerged to address coalition stability in data valuation. 

Recent work has focused on improving computational efficiency and valuation accuracy. ____ proposed learning data utility functions to avoid repeated model retraining, while ____ developed DU-Shapley as an efficient proxy through discrete uniform distributions. ____ introduced EcoVal, which accelerates valuation by clustering similar data points and propagating values within clusters. P-Shapley ____ leverages predicted probabilities instead of accuracy for finer-grained utility differentiation. 

Parallel efforts have explored training-free and task-agnostic directions. DAVINZ ____ enables data valuation at network initialization by theoretically deriving domain-aware generalization bounds, while ____ proposed a task-agnostic framework based on statistical properties without validation requirements. Alternative paradigms include reinforcement learning-based approaches like DVRL ____, complexity-gap scoring ____, and Wasserstein distance-based frameworks ____, which offer diverse perspectives beyond traditional game-theoretic methods.


\subsection{Approximate Dynamic Programming}\label{sec:related_sdm}
Markov Decision Process (MDP) provides one of the most fundamental frameworks for modeling sequential decision-making problems since the seminal work of ____. While MDPs can be solved optimally through dynamic programming ____, they suffer from the curse of dimensionality as the state and action spaces grow. To address these computational challenges, Approximate Dynamic Programming (ADP) has emerged as a powerful paradigm that decomposes the original problem into more tractable subproblems through various approximation strategies ____.

Several key developments have shaped modern ADP approaches. ____ established theoretical foundations for approximate linear programming in average-cost dynamic programming, while ____ advanced the practical applicability through constraint sampling techniques. ____ unified various competing strategies into a common framework, bridging the gap between communities such as stochastic programming, dynamic programming, and stochastic search. Recent work has focused on specific challenges: ____ developed methods for continuous, convex decision sets in storage problems, while ____ introduced distributionally robust ADP with guaranteed convergence properties. The effectiveness of ADP has been demonstrated across diverse applications. In game-playing domains, ____ achieved breakthrough performance in Tetris through policy-based ADP, while ____ extended these methods to two-player zero-sum Markov games. Recent advances continue to push boundaries, with ____ developing tensor-based approximations for hybrid control systems and ____ establishing polynomial-time guarantees for constrained reinforcement learning through novel ADP formulations.

\subsection{Parallel Work on Unifying Data Selection Methods}
Recent work by ____ presents a comprehensive tutorial on data selection methods for foundation models, focusing on both heuristic and principled approaches to data curation. While their work provides valuable insights into the practical aspects of data selection in foundation model training pipelines, our work differs in several key aspects: First, we focus specifically on the optimization perspective of data selection with data values, providing theoretical guarantees of optimality under our proposed sequential decision making and approximate dynamic programming framework. Their work takes a broader view, covering various selection strategies without explicit optimization guarantees. Our work presents a novel unifying framework via approximate dynamic programming (ADP) ____. This framework reveals that many existing data valuation methods can be interpreted as specific instances of myopic cost function approximation heuristic ____, which is a classical strategy in the ADP literature. This theoretical connection not only provides new insights into why existing methods work but also suggests principled ways to improve them. Third, while both works aim to bridge the gap between heuristic and principled approaches, we focus more on the theoretical foundations of data valuation methods for selection tasks. We provide rigorous analysis of the limitations of data attribution methods and characterize the conditions under which they can achieve optimal performance. Our work thus complements theirs by providing deeper theoretical understanding of data valuation based selection methods, while their tutorial offers broader practical guidance across different selection paradigms. Together, these parallel efforts contribute to advancing both the theoretical foundations and practical applications of data selection methods.