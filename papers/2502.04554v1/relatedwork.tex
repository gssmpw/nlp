\section{Related Work}
\label{sec:related}
\subsection{Data Valuation}\label{sec:related_dv}

Data valuation seeks to quantify the contribution of individual training samples to model performance. Game-theoretic approaches have dominated this field, beginning with Data Shapley \citep{ghorbani2019data}, which adapts the Shapley value from cooperative game theory to quantify data contributions. This seminal work inspired various extensions, including Beta Shapley \citep{kwon2021beta}, which introduces a family of semi-values through Beta function weighting, and Data Banzhaf \citep{wang2023data}, which provide robust valuation frameworks through binary-weighted marginal contributions. While these general methods are computationally intensive, specialized approaches like \citep{jia2019efficient} achieve near-linear time complexity by exploiting algorithmic structures such as K-Nearest Neighbors, compared to the exponential complexity of model-agnostic approaches. Recent developments address specific challenges in data valuation: \citet{schoch2022cs} proposed CS-Shapley for better handling class-wise contributions in classification tasks, while \citet{chi2024precedence} introduced PC-Winter value to tackle the unique challenges of graph-structured data valuation. Alternative theoretical frameworks, such as the Core \citep{yan2021if}, have also emerged to address coalition stability in data valuation. 

Recent work has focused on improving computational efficiency and valuation accuracy. \citet{wang2021improving} proposed learning data utility functions to avoid repeated model retraining, while \citet{garrido2023shapley} developed DU-Shapley as an efficient proxy through discrete uniform distributions. \citet{tarun2024ecoval} introduced EcoVal, which accelerates valuation by clustering similar data points and propagating values within clusters. P-Shapley \citep{xia2024p} leverages predicted probabilities instead of accuracy for finer-grained utility differentiation. 

Parallel efforts have explored training-free and task-agnostic directions. DAVINZ \citep{wu2022davinz} enables data valuation at network initialization by theoretically deriving domain-aware generalization bounds, while \citet{amiri2023fundamentals} proposed a task-agnostic framework based on statistical properties without validation requirements. Alternative paradigms include reinforcement learning-based approaches like DVRL \citep{yoon2020data}, complexity-gap scoring \citep{nohyun2022data}, and Wasserstein distance-based frameworks \citep{just2023lava}, which offer diverse perspectives beyond traditional game-theoretic methods.


\subsection{Approximate Dynamic Programming}\label{sec:related_sdm}
Markov Decision Process (MDP) provides one of the most fundamental frameworks for modeling sequential decision-making problems since the seminal work of \citet{bellman1957markovian}. While MDPs can be solved optimally through dynamic programming \citep{bellman1966dynamic}, they suffer from the curse of dimensionality as the state and action spaces grow. To address these computational challenges, Approximate Dynamic Programming (ADP) has emerged as a powerful paradigm that decomposes the original problem into more tractable subproblems through various approximation strategies \citep{powell2007approximate, bertsekas2024course}.

Several key developments have shaped modern ADP approaches. \citet{roy2002approximate} established theoretical foundations for approximate linear programming in average-cost dynamic programming, while \citet{de2004constraint} advanced the practical applicability through constraint sampling techniques. \citet{powell2014clearing} unified various competing strategies into a common framework, bridging the gap between communities such as stochastic programming, dynamic programming, and stochastic search. Recent work has focused on specific challenges: \citet{hannah2011approximate} developed methods for continuous, convex decision sets in storage problems, while \citet{petrik2012approximate} introduced distributionally robust ADP with guaranteed convergence properties. The effectiveness of ADP has been demonstrated across diverse applications. In game-playing domains, \citet{gabillon2013approximate} achieved breakthrough performance in Tetris through policy-based ADP, while \citet{perolat2015approximate} extended these methods to two-player zero-sum Markov games. Recent advances continue to push boundaries, with \citet{shetty2024generalized} developing tensor-based approximations for hybrid control systems and \citet{mcmahan2024deterministic} establishing polynomial-time guarantees for constrained reinforcement learning through novel ADP formulations.

\subsection{Parallel Work on Unifying Data Selection Methods}
Recent work by \citet{wang2024advancing} presents a comprehensive tutorial on data selection methods for foundation models, focusing on both heuristic and principled approaches to data curation. While their work provides valuable insights into the practical aspects of data selection in foundation model training pipelines, our work differs in several key aspects: First, we focus specifically on the optimization perspective of data selection with data values, providing theoretical guarantees of optimality under our proposed sequential decision making and approximate dynamic programming framework. Their work takes a broader view, covering various selection strategies without explicit optimization guarantees. Our work presents a novel unifying framework via approximate dynamic programming (ADP) \citep{bertsekas2024course}. This framework reveals that many existing data valuation methods can be interpreted as specific instances of myopic cost function approximation heuristic \citep{powell2016perspectives,rempel2021review}, which is a classical strategy in the ADP literature. This theoretical connection not only provides new insights into why existing methods work but also suggests principled ways to improve them. Third, while both works aim to bridge the gap between heuristic and principled approaches, we focus more on the theoretical foundations of data valuation methods for selection tasks. We provide rigorous analysis of the limitations of data attribution methods and characterize the conditions under which they can achieve optimal performance. Our work thus complements theirs by providing deeper theoretical understanding of data valuation based selection methods, while their tutorial offers broader practical guidance across different selection paradigms. Together, these parallel efforts contribute to advancing both the theoretical foundations and practical applications of data selection methods.