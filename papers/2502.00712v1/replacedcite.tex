\section{Related Work}
\subsection{AI in Prostate Cancer Diagnosis and Biopsy}
Ultrasound-guided biopsy is the most widely used approach due to its real-time imaging capability and relatively low cost. Grayscale transrectal ultrasound (TRUS)____ is the most commonly adopted imaging method. However, its inherently low signal-to-noise ratio makes tumor identification challenging, with more than 50\% of tumors likely to be missed____. Recent advances in ultrasound-based imaging (such as shear-wave elastography____, color Doppler ultrasound____, contrast-enhanced ultrasound____, and micro-ultrasound____) have shown promise in improving tumor clarity by providing additional functional and structural information. Despite these advancements, relatively few studies have leveraged AI technologies to detect prostate tumors by analyzing ultrasound images alone____. Some researchers have developed various machine learning and deep learning methods to identify prostate tumors from ultrasound images____. However, due to the low-quality and unclear nature of prostate ultrasound images, AI-based analysis typically achieves limited performance, with Dice scores often reported to be low____.

MRI is increasingly utilized for detecting prostate cancer____. It plays a critical role in guiding MRI-ultrasound fusion biopsies and supporting treatment planning. It is widely recognized as the most sensitive noninvasive imaging modality, capable of accurately visualizing, detecting, and localizing prostate cancer. Recent advancements have shown promising results in leveraging AI for prostate cancer detection on MRI____. These AI-driven approaches primarily aim to identify tumors on MRI scans and subsequently map the detected tumors onto ultrasound images during clinical procedures, facilitating precise guidance for biopsies.

Here, we propose an approach similar to TRUS-MRI fusion, where MRI and TRUS are used to train the model. However, instead of identifying tumors on MRI and mapping them onto TRUS, our method directly identifies tumors on TRUS images. This approach eliminates the performance degradation caused by registration errors, offering a more streamlined and accurate solution for tumor detection.

\subsection{Multimodal Fusion Method}
Multimodal fusion methods, which integrate various types of data, have become a crucial approach to improving model performance in numerous tasks____. The primary strategies for multimodal data fusion can be categorized into early fusion, intermediate fusion, and late fusion. These methods differ mainly in the stages at which the data are combined during the model's processing. Early fusion involves concatenating different data types before entering them into the model____. This approach allows the model to learn from the combined features of the input data simultaneously____. Intermediate fusion, on the other hand, concatenates the features extracted by the model from the different modalities. This method leverages the model's ability to independently extract relevant features from each modality before combining them. Lastly, late fusion combines the outputs of models that process each modality separately and then feeds the concatenated outputs into another model, which makes the final decision related to the task____. Regardless of whether early, intermediate, or late fusion is used, the primary data fusion technique involves directly concatenating raw data or extracted features. These concatenation operations do not account for the spatial positional information of the data. In this work, we propose a feature fusion method based on data alignment, which first aligns the spatial information of multimodal data to enhance the performance of segmentation models. This approach is crucial because the spatial positioning of the multimodal data significantly impacts the segmentation performance of the model. 

\subsection{Joint Registration and Segmentation Methods}
Recently, some studies have integrated registration and segmentation to improve semantic segmentation tasks ____. One common strategy alternates the optimization of segmentation and registration networks. For example, DeepAtlas ____ and RegSegNet ____ alternate one registration step with one segmentation step in an iterative process. In these approaches, separate phases are employed, where registration and segmentation are independently trained for each epoch, with prior phases frozen and subsequent ones excluded.
Another approach treats registration and segmentation as two tasks trained simultaneously. For instance, the Cross-Stitch Network treats registration and segmentation as a multi-task learning problem, enabling parameter sharing between the tasks to enhance performance ____. Most existing methods rely heavily on deformable registration techniques, significantly increasing model complexity. For example, DeepAtlas fixes one task while training the other due to GPU memory limitations, preventing the simultaneous optimization of both tasks ____.
In this work, we adopt affine registration to reduce the complexity of the registration process. Our method uses registration primarily to align data and provide it as input for the segmentation task. This design prioritizes segmentation accuracy, leveraging registration as a supporting process to improve the quality of the input data. Experimental results demonstrate that this framework achieves improved performance and efficiency in semantic segmentation.