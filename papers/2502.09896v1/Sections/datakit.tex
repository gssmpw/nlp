\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{Figures/dataprocess.pdf}
    \caption{The construction of data processing toolkit \datakit. After collecting various IoT security datasets, \datakit\ first parses the raw data to get elements of multi-modal (step~\textcircled{1}), and then converts the multi-modal elements into text by utilizing LLM (step~\textcircled{2}). Finally, \datakit\ uses LLM to select fields for the page\_content and metadata of documents (step~\textcircled{3}), and optimizes the chunking strategy (step~\textcircled{4}).}
    \label{fig:dataprocess}
\end{figure*}

\subsection{Data Processing Toolkit}\label{sec:toolkit}

The raw data of the collected datasets are of different formats, \eg, PDF and JSON. These formats are not suitable for RAG processing directly, and thus we develop our end-to-end data processing \datakit. As shown in Figure~\ref{fig:dataprocess}, \datakit\ works in four steps:
\begin{itemize}
    \item[\ding{172}] \textbf{Parse Raw Data.} The initial step involves parsing raw data into distinct content elements such as text, tables, figures, and code. Leveraging existing tools like the unstructured library\footnote{\scriptsize \url{https://pypi.org/project/unstructured/}} helps in extracting textual content from threat reports, while the JSON library\footnote{\scriptsize \url{https://python.readthedocs.io/en/v2.7.2/library/json.html}} is useful for handling structured data from sources like VARIoT and MITRE ATT\&CK.
    
    \item[\ding{173}] \textbf{Convert Multi-Modal Elements to Text.} Once parsed, any multi-modal elements (\eg, tables, figures, code) must be converted into text descriptions for further processing. LLMs like LLaVA (for images)~\cite{liu2023llava,liu2023improvedllava,liu2024llavanext}, LLaMA3:8B (for tables), and CodeLlama (for code)~\cite{roziere2023code} are employed to generate these descriptions. This modular approach allows for easy integration of other LLMs to handle different types of multi-modal content.

    \item[\ding{174}] \textbf{Field Selection for Page\_Content \& Metadata.} In structured formats like JSON, content is often stored across multiple fields.
    Instead of using all fields, it is crucial to identify and utilize the most relevant ones for retrievers. This is done by sampling example items from each field and using an LLM (\eg, LLaMA3:8B) to intelligently select fields that best represent the document's page\_content and metadata, and the prompt is shown in Figure~\ref{fig:dataprocess}.
    Concretely, the selected fields for page\_content and metadata of each dataset are shown in \S~\ref{sec:exp-field}.

    \item[\ding{175}] \textbf{Optimize Chunking Strategy.} The final step involves selecting an appropriate chunking strategy, including the chunking size, overlap, and splitting method. The Ragas library~\cite{es2023ragas} is used to optimize this process, and the details are shown in algorithm~\ref{alg:chunkopt}.
\end{itemize}

\input{Algorithm/chunkopt}

After obtaining the optimized chunking strategy, we split the documents into small chunks and use the all-MiniLM model for chunked text embedding. 
The documents are composed of chunked text, embedding, and metadata.
This approach ensures that the IoT security and threat datasets are processed efficiently and ready for further analysis or use in LLM. 
Note while many of these technologies are adapted from existing works, we foucs on putting them all together to develop an end-to-end data processing toolkit, which might be of independent interest and useful in practical applications.