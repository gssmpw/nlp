\subsection{Construction of \iotrgen}\label{sec:retrieval}

%\input{Algorithm/IoTGen}

As shown in Figure.~\ref{fig:system}, \iotrgen\ consists of \textit{Adaptive Retrieval} and \textit{Guided Generation}.
We present their detailed constructions as follows.
%The third component utilizes LLM $\mathcal{M}$ to generate the response based on retrieved documents, role, and query, following a straightforward process. 
%This subsection will provide the detailed constructions of the Retriever Selector and Retrievers.

\subsubsection{Adaptive Retrieval}\label{sec:rca}
Recall that we have multiple retrievers, each dedicated to retrieving documents generated from a specific dataset. We achieve adaptive retrieval mechanism works in two aspects: 
\romannumeral1) selecting which retrievers should be activated and \romannumeral2) trying to retrieve only relevant documents while discarding irrelevant ones, even for the activated retrievers.

\smallskip
\noindent \textbf{Design of Selector.}
When user \textsf{role} submits a query $Q$, a straightforward and \textit{static} approach is to $Q$ to all retrievers and gather retrieved documents from them. 
However, this method has the following drawbacks:
\romannumeral1) \textit{Irrelevant Retrievers.} Documents of some retrievers may not be relevant to the query. Retrieving them not only fails to improve the quality of the generated answer but may even negatively affect it.
\romannumeral2) \textit{Resource Costs.} Retrieving unnecessary retrievers leads to increased resource costs, such as computational overhead, during both the retrieval and generation processes.

To address these issues, we introduce an LLM-based adaptive \textit{Selector}. As shown in Figure~\ref{fig:system}, we put the user \textsf{role} with the background, the query $Q$, and the descriptions of all retrievers as \textit{Selector Prompt (SPT)} and input SPT to LLM $\mathcal{M}$, which generates $\{\mathcal{S}_i\}_{i=1}^n$,
where $\mathcal{S}_i = \mathsf{True}$ implies that the retriever $\mathcal{R}_i$ should be activated, and $\mathsf{False}$ indicates not. 
In Table~\ref{tab:selectorexample}, we present the configurations generated by LLaMA3:8B for some example queries submitted by different users.

\input{Tables/selector}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.48\textwidth]{Figures/retriever.pdf}
    \caption{The construction of self-querying retriever based on LangChain and Elastic. When $\mathcal{S}_i=\mathsf{True}$, retrieve documents that are semantically similar to query $Q$ and filtered by metadata.}
    \label{fig:retri}
\end{figure}


\smallskip
\noindent \textbf{Self-Querying Retrievers.}
However, even the activated retrievers may return information that does not meet requirements, \eg, mismatch \textit{id} and \textit{products}. To address this problem, we make use of a self-querying technique to filter documents by \textsf{metadata}. 

\input{Figures/vulmetadata}
\input{Figures/QueryTranslator}

As illustrated in Figure~\ref{fig:retri}, the self-querying retriever is composed of a Query Constructor, Query Translator, Search Params, and VectorStore.
When the user's query $Q$ is passed to Query Constructor, LLM will generate \textit{internal query language elements} based on pre-defined \textit{metadata\_field information} and \textit{metadata\_examples}.
Query Translator converts these elements into a \textit{structured query} with appropriate filters. 
Finally, the structured query and search parameters are applied to the Vector Store to retrieve documents. 
To specialize the self-querying retriever for IoT security, we take the following steps:
\begin{itemize}
    \item[\textcircled{1}] \textbf{Metadata \& Examples.} We provide the metadata field information and examples from relevant datasets. For instance, in the VARIoT vulnerabilities dataset, fields \textit{id} and \textit{products} are utilized as metadata. The corresponding \textit{metadata\_field\_info} and \textit{examples} are illustrated in Figure~\ref{fig:variotvulcode}, And details for other datasets are available in Appendix~\ref{appendix:metadataother}. This ensures the LLM can gain the necessary IoT security-specific knowledge to generate effective internal query language elements from the user's query.
    
    \item[\textcircled{2}] \textbf{Create Structured Queries.} Based on the above customized internal query language elements, Query Translator can create specific structured queries for each retriever. 
    Figure~\ref{fig:querytrans} shows how to enable the retrieval of VARIoT vulnerabilities and CLS lists that are both semantically similar to the query and appropriately filtered by their respective metadata.
\end{itemize}


%Specifically, given any query $Q$ in natural language, the retriever uses LLM-based to extract filters $F$ from $Q$, generate the structured query $\mathcal{Q}$ from $Q$ and $F$, and finally applies $\mathcal{Q}$ to its underlying VectorStore. 

\input{Figures/consumer-info}

\subsubsection{Guided Generation}\label{sec:resgen}

After retrieval, one direct step is feeding the retrieved documents and query to LLM to generate the answer. 
However, this simple approach is likely to result in user-unfriendly outputs. 
For example, consumers often lack the expertise needed to fully comprehend highly technical content, making such answers unhelpful and not actionable for them.

To address this issue, we incorporate user-specific backgrounds, including knowledge, goals, and requirements, into each user type's user-friendly prompt template \textit{UPT}. This adjustment guides LLM in generating answers tailored to the user's needs.
The specific background for the general consumer is shown in Figure~\ref{fig:usecasedef-consumer}, demonstrating how we simplify content for easy understanding. The background specifications of other user types can be referred to Appendix~\ref{appendix:bk}.


\input{Algorithm/IoTGen}

Formally, we summarize and show the workflow of \iotrgen\ in algorithm~\ref{alg:iotrgen}.
