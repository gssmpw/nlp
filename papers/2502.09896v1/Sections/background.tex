\section{Background}\label{sec:back}

\subsection{IoT Threat Intelligence}\label{sec:iotintell}
IoT threat intelligence has emerged as a critical element in addressing security challenges, it refers to the collected and analyzed data related to threats, vulnerabilities, and attack patterns. 
In the context of IoT, threat intelligence helps to monitor and analyze threats specific to IoT ecosystems, including device vulnerabilities~\cite{VARIoT_db}, communication protocols~\cite{dragomir2016survey}, malware~\cite{alrawi2021circle}, tactics, techniques, and procedures (TTPs)~\cite{strom2018mitre} used by attackers, and others~\cite{iacovazzi2023towards,bou2020cyber,wagner2019cyber}.
Recent research has highlighted the importance of IoT threat intelligence in identifying zero-day vulnerabilities~\cite{saurabh2024hms} and mitigating threats using collaborative defense mechanisms~\cite{ahmed2023securing}.
The dynamic and fast-evolving nature of IoT systems, coupled with their diverse deployments, including both consumer and industrial settings, highlight the need for up-to-date and automated threat intelligence solutions capable of addressing its unique security challenges.



\begin{figure*}[ht]
    \centering
    \includegraphics[width=\linewidth]{Figures/chaiotsystem.pdf}
    \caption{System architecture of \chatiot. Our system consists of modules \datakit\ and \iotrgen, and operates in three steps: \textcircled{1} \datakit\ processes IoT security datasets from various formats to documents for building retrievers. \textcircled{2} \iotrgen\ provides an interface for the user to submit the query and retrieves relevant documents adaptively: \romannumeral1) Selector first determines which retrievers should be activated, and \romannumeral2) The activated self-querying $\mathcal{R}_i$s retrieve similar documents and filter out unsatisfied ones based on metadata.
    \textcircled{3} LLM will synthesize all information to generate the answer.}
    \label{fig:system}
\end{figure*}


\subsection{Large Language Model}\label{sec:llm}
Large Language Model (LLM) is pre-trained on billions of available datasets, enabling it to capture vast amounts of linguistic, factual, and contextual knowledge. 
Due to the extensive training data, LLM can be directly employed for many downstream tasks, ranging from language translation to complex reasoning tasks~\cite{gpt,zhuge2021kaleido,docformer,kim2022ocr}.
However, LLM has certain limitations, particularly when it comes to handling highly specialized or constantly evolving domains.
Since LLM relies solely on the data they were trained on, which may not always reflect the latest information, it may generate incomplete or outdated responses for specific queries.
This is where Retrieval-Augmented Generation (RAG) comes into play.

RAG~\cite{fan2024survey,lewis2020retrieval} is a powerful approach that combines the generative capabilities of LLM with the latest external information retrieval. 
Instead of solely relying on the LLM's internal knowledge, RAG augments the LLM by retrieving relevant, up-to-date information from external databases or documents at the time of generation. 
The process involves querying an external knowledge source, retrieving the most relevant documents, and using the retrieved information to guide or enhance the LLM's response generation. 
By bridging the gap between static pre-trained knowledge and dynamic, real-world data, RAG enhances the performance of LLM on tasks that require both advanced language understanding, reasoning, and up-to-date information. This makes it particularly effective for specialized domains where access to the latest, domain-specific information is crucial.