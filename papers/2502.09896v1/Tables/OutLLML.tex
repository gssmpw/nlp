\begin{table*}
\centering
\caption{Comparison of \chatiot\ with LLM alone method (LLM-A). The experimental results are for the most advanced LLMs LLaMA3.1:70B and GPT-4o. We use LLaMA3:70B as the evaluator for all experiments.}\label{tab:exp_llm}
\begin{tabular}{c|c|cc|cc}
\toprule \toprule
\multirow{2}{*}{Role} & \multirow{2}{*}{Metric} & \multicolumn{2}{c|}{LLaMA3.1:70B} & \multicolumn{2}{c}{GPT-4o} \\
&  & \chatiot & LLM-A & \chatiot & LLM-A \\
\midrule
\multirow{4}{*}{Consumer} & Reliability & 4.40 ($+$0.70) & 3.70 & 4.55 ($+$0.55) & 4.00 \\
& Relevance & 4.90 ($+$0.90) & 4.00 & 4.85 ($+$0.75) & 4.10 \\
& Technical & 4.50 ($+$0.70) & 3.80 & 4.40 ($+$0.25) & 4.15 \\
& Friendliness & 4.70 ($+$1.00) & 3.70 & 4.80 ($+$0.75) & 4.05 \\
\midrule
\multirow{4}{*}{Security Analyst} & Reliability & 4.70 ($+$0.65) & 4.05 & 4.80 ($+$1.29) & 3.51 \\
& Relevance & 4.93 ($+$0.81) & 4.12 & 4.83 ($+$1.18) & 3.65 \\
& Technical & 4.82 ($+$0.84) & 3.98 & 4.83 ($+$1.18) & 3.65 \\
& Friendliness & 4.09 ($+$0.80) & 3.29 & 4.14 ($+$0.61) & 3.45 \\
\midrule
\multirow{4}{*}{Technical Officer} & Reliability & 4.45 ($+$0.37) & 4.08 & 4.85 ($+$0.61) & 4.24 \\
& Relevance & 4.71 ($+$0.51) & 4.20 & 4.88 ($+$0.63) & 4.25 \\
& Technical & 4.55 ($+$0.31) & 4.24 & 4.88 ($+$0.65) & 4.23 \\
& Friendliness & 4.13 ($+$0.27) & 3.86 & 4.49 ($+$0.61) & 3.88 \\
\midrule
\multirow{4}{*}{Developer} & Reliability & 4.35 ($-$0.14) & 4.49 & 4.75 ($+$0.93) & 3.82 \\
& Relevance & 4.54 ($+$0.02) & 4.52 & 4.81 ($+$0.97) & 3.84 \\
& Technical & 4.52 ($+$0.02) & 4.52 & 4.86 ($+$0.87) & 3.99 \\
& Friendliness & 3.96 ($-$0.24) & 4.30 & 4.11 ($+$0.63) & 3.48 \\
\midrule
\multirow{4}{*}{Trainer} & Reliability & 4.30 ($-$0.31) & 4.61 & 4.40 ($+$0.17) & 4.23 \\
& Relevance & 4.62 ($-$0.08) & 4.70 & 4.54 ($+$0.39) & 4.15 \\
& Technical & 4.31 ($-$0.23) & 4.54 & 4.53 ($+$0.21) & 4.32 \\
& Friendliness & 4.25 ($-$0.40) & 4.65 & 4.46 ($+$0.22) & 4.24 \\
\bottomrule \bottomrule
\end{tabular}
\end{table*}