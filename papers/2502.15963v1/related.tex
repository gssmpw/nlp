\section{Related Work}\label{sec:related}

In this section, we summarize and discuss existing research on human and social factors affecting code review processes. Based on the literature we surveyed, ``social'' aspects pertain to group-level interactions, relationships, and dynamics within the SE environment, such as communication and collaboration. Social also entails behaviors inherent to group dynamics such as trust, perception of fairness, and conflicts. On the other hand, ``human'' aspects are particular to individual' behaviors and characteristics such as cognitive load, motivation, and emotional responses.

\subsection{Social aspects in SE}

In this stream of work, researchers examined the social concerns arising from the inherently human-intensive aspects of the code review. German et al. study fairness by examining how practitioners perceive the treatment they receive from their peers during a code review \citep{german2018my}. They found that a sense of unfairness is predominant among developers. This is more typical with authors of code than reviewers, and there is an often misplaced sense that the merits of the code should dictate acceptance~\citep{german2018my}.

Gon\c{c}alves et al reported that developers find code review conflict-causing \citep{goncalves22}. However, neither that study nor the fairness study \citep{german2018my} examined how conflict or unfairness might impact personal accountability, although Gon\c{c}alves et al noted organizational factors, such as autonomy, might result in developers' improved ``effort in doing a good job.'' Role inequality was, as we will also show, less important as long as the critiques were constructive \citep{goncalves22}. 

Bosu et al. and Bosu and Carver studied reviewers' perceptions of their peers in the review process \citep{bosu2013impact,bosu2016process}, particularly how it emerges and influences the practice. Both studies conclude that the review process influences impression formation, especially peers' competence. Subpar code changes influence perception negatively and subsequently become a perception of authors in future reviews \citep{bosu2013impact,bosu2016process}.

Egelman et al. looked at negative interactions in code review (``pushback'') at Google~\citep{Egelman2020}. They found interpersonal conflict had several causes, such as confrontational comments. 

In our previous work, we found that the process of code review is strategically used as a mechanism for ensuring accountability for code quality, aiming to compel software engineers to adhere to established quality standards \citep{alami2024understanding}.

\subsection{Human Aspects in SE}

This stream of work focuses on specific reviewer behavior \citep{davila2021systematic}. Kitagawa et al. used simulation to understand developer engagement during code review \citep{kitagawa2016code}. They used a situational model based on a snowdrift game. The key finding of the study is that reviewers partake in the review when they perceive that the value of their participation outweighs the cost \citep{kitagawa2016code}. Baum et al. carried out an experiment study to investigate the relationship between reviewers' cognitive burden and their performance during the review \citep{baum2019associating}. The main finding is the relation between working memory capacity and the reviewer's efficacy in detecting delocalized flaws, as well as the negative effect of larger and more complex code changes on reviews' performance \citep{baum2019associating}.

Alami et al. sought to understand the motivation of open-source contributors to participate in code reviews \citep{alami2019does}. They conclude that contributors' motivation is rooted in hackers ethics (e.g., improvement of quality and passion for coding). Despite rejections and toxic communication, contributors show resilience, driven by their intrinsic and extrinsic motives to participate. Some of the intrinsic drivers are the passion for coding and caring about the quality of the code. Extrinsically, contributors partake in code review to showcase their skills and maintain a reputation in the community \citep{alami2019does}.

The distinction between open-source code review and institutional code review is important. Open source code review has been the focus of the majority of the research. However, it is more often \textbf{asynchronous} and \textbf{distributed}, compared to institutional reviews. For example, the systematic review of Badampudi et al.~\citep{badampudi2023modern} explained that ``when discussing reviewer interactions, human aspects received much attention in the reviewed primary studies. However, the investigation of review dynamics, social interactions, and review performance is focused on OSS projects. It is not known if such interactions differ in proprietary projects'' ~\citep{badampudi2023modern}.

\subsection{Accountability in SE}

Our earlier study \citep{alami2024understanding} examined the broader concept of accountability in SE and was not directly concerned with code review. That broad investigation of individual accountability within software engineers highlighted two factors driving accountability: institutionalized and grassroots. Institutional accountability, such as financial rewards and punishment (e.g., denial of promotion), is purposefully designed by the organization to control accountability. Grassroots accountability, by contrast, is either peer-driven or innate. Software engineers feel accountable to their peers, fostering a sense of collective responsibility. Their accountability for their outcomes, including code quality, is also driven by their intrinsic drivers, such as the desire to maintain personal standards and professional integrity. The study also identified several mechanisms to control accountability, such as performance review (institutionalized) and code review (grassroots) \citep{alami2024understanding}. We build on our earlier study's foundational understanding of accountability to examine the role of intrinsic drivers in accountability in the context of peer-led versus LLM-based code reviews. In Sect. \ref{sec:chase}, we elaborate further on the methodological and empirical relation to our previous work reported in \citep{alami2024understanding}.

In summary, related work highlights the importance of both human and social factors in shaping code review practices, from individual behaviors like cognitive load and motivation to social constructs such as trust, fairness, and conflict resolution. However, much of this work has focused on open-source settings, leaving gaps in understanding how these factors operate in institutional contexts. Furthermore, while prior studies, including our own, i.e, \citep{alami2024understanding}, have explored accountability as a broader construct in SE, how accountability manifests and influences the code review process remains underexplored. Furthermore, the specific role of intrinsic drivers in shaping accountability within peer-led and LLM-assisted reviews is yet to be investigated. In this study, we address these gaps by examining how intrinsic drivers influence accountability for code quality in peer-led and LLM-assisted reviews.

