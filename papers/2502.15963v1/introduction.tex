\section{Introduction}\label{sec:introduction}

\noindent \textbf{Accountability is the expectation of being held responsible for one's actions and the need to provide explanations and reasoning for such actions to others in the future} \citep{de2007justifying,lerner1999accounting,frink1998toward}. To software engineers, accountability for code quality is to adhere and meet expectations and justify their coding decisions. Either these expectations are set at the organizational or team levels, or they align with widely recognized quality standards~\citep{alami2024understanding}.

Developing software is done as part of a social system. Accountability maintains stability in these social systems~\citep{frink2004advancing}. Accountability mechanisms thus have profound consequences for core organizational functions, yet the software engineering (SE) research community has paid little attention to them \citep{alami2024understanding}. The absence of accountability in a social system like software development may result in individuals acting with little regard to the consequences imposed by others \citep{hall2017accountability}. Consequently, organizations may find it challenging to effectively manage their operations \citep{frink1998toward}. 

A key area of accountability in software engineering is deciding which changes to make in a codebase and the applicable quality standards. These decisions are often taken as part of a socio-technical process called code review \citep{meneely2014empirical,bosu2016process}. Code reviews can lead to \emph{social dilemmas} because individual and collective interests may conflict \citep{de2009paying,de2001less}. A social dilemma is a situation when individuals are faced with a choice between pursuing their own interests at the expense of a group or cooperating for the greater benefit of the collective \citep{de2009paying,de2001less}. The dilemma arises because if everyone pursues their own self-interest, the collective outcome is worse than if everyone cooperated \citep{de2009paying,de2001less}.

In our previous work, we reported that intrinsic drivers such as personal standards and professional integrity underpin software engineers' sense of accountability for code quality \citep{alami2024understanding}. They shape how developers perceive and respond to their responsibilities in meeting code quality expectations. Peer-led review is a well-established code quality assurance practice, where peers review each other's code for errors, readability, and adherence to agreed coding standards \citep{mcintosh2016empirical,alami2019affiliated}. Group dynamics, human interactions, and mutual expectations influence accountability in this process, bringing a social dimension to it \citep{alami2024understanding}.

Large Language Models (LLMs) like GPT-4 are powerful multipurpose products, capable of generating code and assisting in software development activities, including documentation, debugging, design suggestions, and code review \cite{fan2023large}. The versatility and broad applicability of LLMs have the potential to influence the landscape of software engineering by either reducing the reliance on human-led activities or supporting tasks that were previously considered too complex for automation, including code review \cite{svyatkovskiy2020,zohair2018future}.
 
However, SE activities and practices are highly collaborative. The introduction of LLM-assisted reviews to traditionally human-led activities may influence or even shift accountability dynamics. The reduction in human interactions may weaken the reinforcement of team norms and informal accountability mechanisms used to enforce it \citep{alami2024understanding}.

During code reviews, software developers may face pressure to justify their decisions and actions to the rest of the group, fearing negative evaluations, a type of social dilemma known as a public good dilemma~\citep{de2008reputational,leary2019self,tyler1999people}. They need to justify their coding decisions, and failing to do so may tarnish their reputation as reliable and cooperative team members. 

Analogous to social dilemmas, where individuals are evaluated against group expectations \cite{de2007justifying}, software developers in code reviews face similar conditions. They must navigate justifying and defending their coding decisions and maintaining their image as competent and collaborative team members. Drawing from the broader social dilemma literature \cite{de2003accountability,de2001less}, where the failure to align with group expectations risks one being perceived as untrustworthy, non-cooperative, and sometimes leading to reputational consequences \cite{de2009paying,de2007justifying}. Social dilemma research has shown that individuals exhibit reduced self-interest when they are subjected to accountability measures \cite{de2009paying,de2007justifying}. To understand whether the condition of being held accountable in code review influences developers' code quality, our study aims to explore the intrinsic drivers that motivate software engineers in these contexts and how they influence their sense of accountability. By examining the impact of both peer-led and LLM-assisted code reviews, we seek to learn the underlying mechanisms that shape accountability for code quality within the socio-technical system of software development. 

Human and social aspects of code review have received little attention from SE research~\citep{davila2021systematic,badampudi2023modern}. We elaborate on the few studies that have, later in Sect. \ref{sec:related}. Like most SE research, code review studies have primarily focused on technical artifact analysis in open source communities~\citep{Storey2020}. 

Building on our earlier study that laid a basic understanding of accountability in SE \citep{alami2024understanding}, we now delve into software engineers' innate qualities, which we term their \emph{intrinsic drivers} \cite{deci2000and}. Recognizing the importance of social dilemmas within the code review process, we seek to understand software engineers' intrinsic drivers, how they affect accountability during peer-led code reviews, and the impact of the integration of LLM-assisted code reviews. With this focus, we aim to provide an understanding of accountability for code quality decisions within the socio-technical system of software development, beyond the technical aspects. 

\textbf{Intrinsic drivers} are factors such as adhering to self-imposed personal standards and reputation that drive behavior and influence outcomes \citep{cameron1994reinforcement,fishbach2022structure}. Our previous work showed the importance of intrinsic drivers for software engineers, nurturing their feeling of accountability for their work \citep{alami2024understanding}. However, how these intrinsic qualities shape individuals' accountability is unreported in both the accountability theories \citep{frink1998toward,frink2004advancing} and software engineering \citep{alami2024understanding}, leaving a gap in understanding the role of intrinsic drivers in influencing accountability in SE. Therefore, we propose exploring intrinsic drivers within SE to fully comprehend their impact on professional behavior and outcomes.

Understanding intrinsic drivers' role in driving accountability for code quality is a relevant software engineering problem. Quality assurance practices like testing and code review serve as accountability mechanisms for ensuring code quality \citep{alami2024understanding,bosu2013impact}. Without a clear understanding of how the human and social factors, such as intrinsic drivers influence accountability, organizations risk relying on extrinsic motivators (e.g., promotion) and technical processes (e.g., continuous integration), which alone may not be as effective in sustaining long-term accountability as relying on both personal qualities and other social enablers.

In addition, the increased adoption of artificial intelligence (AI) in SE \citep{fan2023large} introduces a potential alteration to established social dynamics due to reduced opportunities for peer interaction and group norms. Therefore, for designing interventions that preserve the social fabric of software engineering teams in future AI-augmented SE, it is crucial to understand the influence of intrinsic drivers in both peer-led and LLM-assisted contexts. For example, engineers who derive accountability from professional integrity and peer validation may struggle to adapt in an environment where feedback is predominantly AI-driven. This understanding will also lay the foundation for future work to create more resilient accountability practices that integrate human and AI collaboration effectively.

In our previous work, we identified several outcomes software engineers bear accountability for, namely meeting deadlines, software security, and code quality \citep{alami2024understanding}. We also examined a broad set of drivers, including extrinsic motivators such as financial rewards. 

While our previous work focused on the building blocks of accountability \citep{alami2024understanding}, in this study, we aim to focus on a specific SE outcome, code quality, in a common SE practice, code review. We build on our prior findings by investigating how intrinsic drivers influence accountability in a specific SE practice and how an evolving technology, such as LLMs, might reshape the evolution of accountability at the individual and team levels. By exploring accountability within a socio-technical context like code review, we aim to identify the interplay between human drivers, accountability for an important SE outcome, and potential implications of AI integration. By doing so, we seek to address gaps left unexamined in our earlier work.

In this study, we expand on this work and focus on a particular outcome, code quality, a critically important SE outcome \citep{alami2022scrum,vasilescu2015quality}. This leads us to propose:

\medskip
    
    \noindent \textbf{RQ1:} What are the key intrinsic drivers of software engineers that influence their sense of accountability towards the quality of their code?
    
\medskip

To address \textbf{RQ1}, we carried out a two-phased sequential qualitative study ($\textbf{interviews} \rightarrow \textbf{focus groups}$) \citep{creswell2017designing}. In Phase I (16 interviews), we sought to investigate the intrinsic drivers of software engineers influencing their sense of accountability for code quality, relying on self-reported claims. However, relying on self-reported data for complex and subjective topics like accountability is subject to biases and inaccuracies caused by social desirability bias, recall bias, and self-perception \citep{podsakoff2003common}. Therefore, in Phase II, we tested these traits and claims in a more natural setting by simulating traditional peer-led reviews using four focus groups (5--6 participants each). This design allowed us to compensate for the inherent methodological weaknesses of each phase, a strength of mixed methods studies \citep{creswell2017designing}. By design, focus groups foster social interaction~\citep{Kontio2008}, which can test self-reported intrinsic drivers influencing personal accountability in professional-like settings~\citep{carroll2003making}. This interaction helped us to further understand how software engineers navigate the challenges of maintaining their intrinsic drivers for accountability in a complex social setting.

In Phase I of the study, we identified four intrinsic drivers that influence software engineers' sense of accountability to meet established expectations for code quality: \emph{personal standards}, \emph{professional integrity}, \emph{pride in code quality}, and \emph{maintaining personal reputation}.

In Phase I and our previous work \citep{alami2024understanding}, code review emerged as a significant accountability mechanism for code quality. Participants frequently referred to code review as a central process to demonstrate and enforce accountability. This emergent finding provided a natural basis for shifting the focus of the secondary analysis to code review, aligning with the broader goal of understanding accountability in socio-technical systems. Moreover, participants emphasized the relevance of code review as an accountability mechanism. These discussions underscored its importance as both a collaborative and evaluative process, making it a relevant context for deeper exploration in the secondary analysis.

Recent advances in AI technologies such as neural network architectures, recurrent neural networks, and transformers \cite{vaswani2017attention} have led to the development of several commercial products such as Tabnine\footnote{\url{https://www.tabnine.com/}}, CodeX\footnote{\url{https://openai.com/index/openai-codex/}}, and Github's Copilot\footnote{\url{https://github.com/features/copilot/}}. Although these products are mainly directed to code generation, Large Language Models (LLM) are multi-task products capable of assisting in other SE tasks \citep{fan2023large,lu2023llama}, traditionally governed by humans.

As efforts in code review automation are growing, e.g., \cite{pandya2022corms,shi2019automatic}, the \textbf{integration of LLMs} into code review is either already happening \cite{lu2023llama,li2022automating} or just a matter of time \cite{lu2023llama}. This may bring a significant shift from traditional code review. For example, in response to \textbf{RQ1}, we learned that engineers feel accountable for the quality of their code to their peers. In an LLM-assisted code review, by comparison, human feedback and interaction are replaced by a machine equivalent. This shift has prompted us to examine the resilience and perseverance of human factors, such as the desire to maintain professional integrity, in a machine-based evaluation process. 

While \textbf{RQ1} delves into the intrinsic traits driving software engineers' accountability in a human-led code review process, \textbf{RQ2} seeks to understand the ramifications for accountability in LLM-assisted code review. Most SE activities are highly collaborative. Thus, the integration of AI into the already complex human and social practices requires a thorough understanding of potential implications. Specifically, the introduction of AI in practices traditionally dominated by human expertise raises questions about the human-AI engagement and behavioral responses of software engineers. For example, Malone et al. suggest that the most challenging changes in AI integration are not computers replacing humans but rather people and computers working together as an integrated approach \cite{malone2020artificial}. To effectively augment SE practices with the integration of AI, it is crucial to understand how software engineering teams engage with and respond to AI tools in their workflows. AI is a newcomer to an already socially loaded process like code review, where accountability for code quality---a key and highly sought-after SE outcome \citep{vasilescu2015quality,krasner2018,alami2022scrum}---is shaped by complex human interactions and social norms. AI integration into SE raises many questions about how it may influence the social fabric of these processes, especially in terms of accountability. Therefore, we inquire:

\medskip

    \noindent \textbf{RQ2:} How does LLM-assisted code review affect software engineers' accountability for code quality?
    
\medskip

LLM-assisted code review refers to the process of utilizing a Large Language Model, such as GPT-4 or Gemini, to evaluate and provide feedback on software code. For our study, we designed a specific prompt for the LLM to simulate the role of a reviewer by analyzing the attached code and generating feedback (see Sect. \ref{sec:methods}).

To address \textbf{RQ2}, we carried out LLM-assisted reviews in the second part of our focus groups. Our focus groups were scheduled over two hours. In the first hour, we conducted peer-led reviews (\textbf{RQ1}), and in the second hour, LLM-assisted reviews (further details in Sect. \ref{sec:methods}). 

We contribute:

\begin{itemize}

    \item [-] \textbf{Elucidation of individual and collective accountability in code review:} Our study provides a comprehensive examination of how intrinsic drivers such as professional integrity, pride, personal standards, and reputation influence software engineers' sense of individual accountability towards code quality. During the code review, we identified a complex accountability process. Accountability for code quality shifts from the individual-level when writing code to the collective-level when peers reciprocate accountability for code quality during the review. This contribution shows that code quality is beyond standards, processes, or metrics but a shared value that is cultivated through a sense of individual and collective accountability. This implies that code quality is not solely achieved through tools and technical practices like testing and coding standards but is also deeply personal and collectively fostered through social norms and human interactions. Our findings underscores the importance of balancing the ``socio'' and ``technical'' dimensions in pursuing code quality. By integrating both human-driven and technical practices, SE teams can create environments where accountability for code quality is cultivated through shared values.

    \item [-] \textbf{Insights into the impact of LLM-assisted code review:} Our work assesses the impact of LLM-assisted code review on accountability for code quality. We provide insights into the challenges and disruptions introduced by integrating AI technologies into traditional SE practices. When we introduced LLM-assisted reviews, we learned that this newcomer disrupts the collective sense of accountability for code quality. This disruption does not only accentuate the social fundamentals of code review but also emphasizes the need for designing AI integration in SE that supports rather than disrupts the social fabric of SE teams. While AI will continue augmenting SE practices, our findings inform future research and organizations that integrating AI into the inherently socio-technical processes of SE is not a simple out-of-the-box integration. The disruption to collective accountability demonstrates the importance of considering the social impact of AI integration. The design of future AI integration in SE should account for the social fabric of SE teams.

    \item [-] \textbf{Identification of LLM-related factors disrupting collective accountability for code quality:} We identified LLM-related factors that contribute to the disruption of collective accountability within code review, mainly trust in LLMs and their inherent limitations. This contribution emphasizes the importance of addressing trust in AI technologies and preserving the social aspects of the adoption process. Our findings show that software engineers remain skeptical about the reliability of AI as a partner. This trust issue stems from the training constraints of the AI tools and limitations in integrating seamlessly into SE processes. These findings highlight that the technology's current shortcomings undermine confidence in its ability to support SE effectively. Addressing these limitations is essential for advancing AI tools as reliable partners in SE processes.
    
\end{itemize}

We structure the remainder of this paper as follows: In the next section \ref{sec:theory}, we discuss the theoretical frameworks reported in social and organizational sciences literature. In Sect. \ref{sec:related}, we discuss related work. Section \ref{sec:methods} describes our research design and methods. Section \ref{sec:findings} is dedicated to the data interpretation from our first and second phases of the study. The implications of our results, in both existing theory and practice, are then discussed in Sect. \ref{sec:discussion}. In section \ref{sec:trust}, we discuss the study's trustworthiness, limitations, and trade-offs. Section \ref{sec:conclusion} brings us to a close.


    


