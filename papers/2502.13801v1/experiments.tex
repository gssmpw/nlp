\section{Experiments}

To appreciate the performance of our method, we conducted experiments on two environments: a custom goal-based version of the gymnasium CartPole environment \cite{towers2024gymnasium} with continuous actions that we call \textit{CartPoleGC}, and a goal environment based on the Skydio X2 drone from the Mujoco menagerie \cite{menagerie2022github} that we call \textit{SkydioX2GC}. We performed an ablation study to validate our design choices and compared our approach with the state-of-the-art GC method SAC + HER. Finally, as our general objective is zero error during exploration, we analyze the causes of the few mistakes we obtained during safe exploration for the best strategy.

\subsection{Experimental setup}

CartPoleGC and SkydioX2GC are interesting environments due to their inherent instability as random actions or even actions near 0 lead to mistakes.

\begin{figure}[ht]
    \begin{subfigure}{0.25\textwidth}  % 0.3
        \centering 
        \includegraphics[width=\textwidth]{images/cartpole_gc.png}
        \caption{CartPoleGC with a goal in red}
        \label{fig:cartpole_gc}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.14\textwidth} % 0.16
        \centering
        \includegraphics[width=\textwidth]{images/x2.png}
        \caption{SkydioX2GC}
        \label{fig:x2}
    \end{subfigure}
    \caption{Environments}
    \Description{Environments}
    \label{fig:envs}
\end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.4\textwidth]{images/cartpole_gc.png}
%     \includegraphics[width=0.1\textwidth]{images/x2.png}
%     \caption{CartpoleGC environment}
%     \Description{CartpoleGC environment}
%     \label{fig:cartpole_gc}
% \end{figure}

\subsubsection{CartPoleGC}
The state $s = (x, \dot{x}, \theta, \dot{\theta}) \in \stateSpace$ contains the position $x$ of the cart, its velocity $\dot{x}$, the angle of the pole $\theta$, and its 
velocity $\dot{\theta}$. $x$ lies in $[-2.4m, 2.4m]$, and $\theta$ in $[-0.41rad, 0.41rad]$.
Getting out of these bounds is considered a mistake, leading to episode termination. 
Action $a \in \actionSpace = [-1, 1]$ is proportional to the lateral force applied to the cart. 
$1$ corresponds to $1$ in the original discrete version and $-1$ to $0$. 
Goals are desired positions of the cart: $\goalSpace = [-2.16, 2.16]$, sampled uniformly. 
The agent gets a goal reward when the cart is less than $0.05m$ near the the desired goal.
The agent gets a safety reward when the $x$ position lies in $[-2.2, 2.2]$ and other state variables in 
$[-0.05, 0.05]$, so $\neighborhood = [-2.2, 2.2] \times [-0.05, 0.05]^3$.

\subsubsection{Skydio X2}
The system physics is fully characterized by position $(x, y, z)$ of the center of gravity, orientation (quaternions),
linear velocity $(\dot{x}, \dot{y}, \dot{z})$ and angular velocity (Euler angles).
The state is the concatenation of these elements. The $(x, y)$ position lies in $[-3m, 3m]^2$, altitude $z$ in $(1m, 4m)$, 
while roll and pitch angles are bounded to $30 \deg$ of amplitude around $0$. 
Getting out of these bounds is considered a mistake, leading to episode termination. 
The action space $\actionSpace = [-1, 1]^4$ corresponds to the forces applied on the rotors.
Goals are desired $(x, y, z)$ positions in the cube $[-2.6m, 2.6m] \times [-2.6m, 2.6m] \times [1.4m, 3.6m]$,
sampled uniformly. The agent gets a goal reward when its less than $0.25m$ near the goal, and a safety reward when
it is in the cube $\neighborhood = [-2.8m, 2.8m] \times [-2.8m, 2.8m] \times [1.2m, 3.8m]$.

Function $h$ has the same structure in both environments. For a bounded state variable, \textit{eg} $x$ for CartPoleGC,
corresponds a function $h_x$, computed according to equation \refEq{eq:h_cartpole}. 
\begin{equation}
    h_x(x) = \max \{ -1 - 2 \frac{x - x_{middle}}{x_{max} - x_{min}}, 2 \frac{x - x_{middle}}{x_{max} - x_{min}} - 1 \}
    \label{eq:h_cartpole} 
\end{equation}
where $x_{middle} = (x_{max} + x_{min}) / 2$. The constraint value $h(s)$ is the maximum over all bounded state variables.
The advantage of such a formulation is that $h_x$ is bounded in $[-1.0, 0.]$, so that $\lambda \overline{R}^{\piS}$ and 
$\overline{Q}^{\piS}$ have the same scale (Cf \refSection{subsection:safety_policy_learning}). 
Finally, for both environments, an episode is terminated when $h(s) > 0$ and truncated when the number of steps
exceeds $500$. Note that achieving a goal is not terminal. Thus the GC policy can be aggressive to
reach the goal and maintain safety once the goal is reached. For both environments, reset anywhere is performed in pretraining, while in safe exploration a noisy reset centered on a single state is applied.

\subsubsection{Baseline} 
For each environment, we compared our best safe exploration variant in terms of safety with 
the combination of SAC and HER (SAC + HER), with $80\%$ of relabelling and 
\textit{future} strategy, 
in terms of success rate and occurrence of mistakes \cite{SAC, HER}.

\subsubsection{Comparisons settings}
We trained safe exploration variants and the baseline 12 times with CartPoleGC and 9 times with SkydioX2GC. We performed fewer runs on SkydioX2GC because of the computational cost. To obtain the 12 runs on CartPoleGC, we performed 4 pretrainings using 4 different seeds. Then, for each of these pre-trained safety policies, we trained 3 safe exploring agents with 3 seeds. The idea behind this is to avoid cherry picking and draw a fair comparison between algorithms as the quality of safe exploration strongly depends on the the pretraining. In the same way, we performed 3 pretrainings on Skydio with 3 different seeds and 3 safe explorations for each pretraining seed. Each pretraining takes $2$ million steps for CartPoleGC and $2.5$ million steps for SkydioX2GC. For safe exploration, it takes respectively $500\,000$ and $1$ million steps. 
We are interested in minimizing the occurrence of mistakes 
for the worst possible run of each tested variant. So we show the mean, the minimum, and the maximum in our plots of mistake occurrence. As for the success rate, we show the mean and the standard deviation. In all our 
experiments we set $\tau = 0.9$, considering the $10\%$ worst cases to compute the risk measure, and 
a margin $\epsilon = 0.1$ (Cf section \ref{subsection:Action selection mechanism}).

\subsection{Comparison with the baseline}

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/cartpole_comp_baseline/terminated_regret.pdf}
        \caption{}
        \label{fig:cartpole_comp_baseline/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/cartpole_comp_baseline/is_success_final.pdf}
        \caption{}
        \label{fig:cartpole_comp_baseline/is_success_final}
    \end{subfigure}
    \caption{Comparison between our method (Cf $L\&S$ in \refSection{subsec:ablation_dist}) and the baseline on the CartPoleGC environment in terms of safety during exploration and coverage.}
    \Description{Comparison between our method (Cf $L\&S$ in \refSection{subsec:ablation_dist})and the baseline on the CartPoleGC environment in terms of safety during exploration and coverage.}
    \label{fig:cartpole_comp_baseline}
\end{figure}

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/skydio_comp_gc_vs_best_safe_exp/terminated_regret.pdf}
        \caption{}
        \label{fig:skydio_comp_gc_vs_best_safe_exp/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/skydio_comp_gc_vs_best_safe_exp/is_success_final.pdf}
        \caption{}
        \label{fig:skydio_comp_gc_vs_best_safe_exp/is_success_final}
    \end{subfigure}
    \caption{Comparison between our method (Cf $S$ in \refSection{subsec:ablation_dist}) and the baseline on the SkydioX2GC environment in terms of safety during exploration and coverage.}
    \Description{Comparison between our method (Cf $S$ in \refSection{subsec:ablation_dist}) and the baseline on the SkydioX2GC environment in terms of safety during exploration and coverage.}
    \label{fig:skydio_comp_gc_vs_best_safe_exp}
\end{figure}

For both environments, we show that our approach can considerably reduce the number of mistakes 
during exploration in comparison to the baseline, as it does not take safety into account
(Figures \ref{fig:cartpole_comp_baseline} and \ref{fig:skydio_comp_gc_vs_best_safe_exp}). 
However, the baseline obtains a better success rate, around $98\%$ on average against $70\%$ 
for CartPoleGC (\refFig{fig:cartpole_comp_baseline/is_success_final}) 
while on SkydioX2GC safe exploration offers almost the same performance in coverage but with higher
variance (\refFig{fig:skydio_comp_gc_vs_best_safe_exp/is_success_final}). 
CartPoleGC's poorer coverage can be explained by the fact that some goals are near terminal states
so the policy prevents the cart from reaching it. We leave a coverage map in the supplementary material.
Most importantly, we want to stress the minimum and maximum performance regarding safety.
With CartPoleGC we obtained at most 27 mistakes, and with 7 mistakes SkydioX2GC, but for some runs,
we obtained 0 mistakes for the whole training.
As shown in \refSection{subsection:analysing failures}, these differences 
correspond to different pre-trained safety policies.

\subsection{Ablation study}

\subsubsection{Effect of the reachability critics}
\label{subsec:ablation_dist}
In section \ref{subsection:Action selection mechanism}, we describe three strategies to compute 
the risk function: Time, Constraint, and Time-constraint, that we would like to rate in terms of safety during exploration and coverage. Also, the $\lambda$ factor used in pretraining can be set to $0$ or
$100$ to take reachability critics into account or not in the actor update. 
The constraint (only) strategy led to catastrophic results 
in our preliminary experiments, both for learning and action selection, 
so we left it in the supplementary material. Four classes remain: $L\&S$ (reachability is taken into account both in safety learning and action selection), $L$ (learning only), $S$ (action selection only), $None$ (reachability is not taken into account).

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/cartpole_dist_ablation_full/terminated_regret.pdf}
        \caption{}
        \label{fig:cartpole_dist_ablation_full/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/cartpole_dist_ablation_full/is_success_final.pdf}
        \caption{}
        \label{fig:cartpole_dist_ablation_full/is_success_final}
    \end{subfigure}
    \caption{Effect of the reachability critics on safe exploration with CartPoleGC for different variants. $L\&S$ (reachability in safety learning and action selection), $L$ (learning only), $S$ (action selection only), $None$ (no reachability)}
    \Description{Effect of the reachability critics on safe exploration with CartPoleGC for different variants. $L\&S$ (reachability in safety learning and action selection), $L$ (learning only), $S$ (action selection only), $None$ (no reachability)}
    \label{fig:cartpole_dist_ablation_full}
\end{figure}

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/skydio_ablation_dist_full_std/terminated_regret.pdf}
        \caption{}
        \label{fig:skydio_ablation_dist_full_std/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/skydio_ablation_dist_full_std/is_success_final.pdf}
        \caption{}
        \label{fig:skydio_ablation_dist_full_std/is_success_final}
    \end{subfigure}
    \caption{Effect of the reachability critics on safe exploration with SkydioX2GC for different variants. $L\&S$ (reachability in safety learning and action selection), $L$ (learning only), $S$ (action selection only), $None$ (no reachability)}
    \Description{Effect of the reachability critics on safe exploration with SkydioX2GC for different variants. $L\&S$ (reachability in safety learning and action selection), $L$ (learning only), $S$ (action selection only), $None$ (no reachability)}
    \label{fig:skydio_ablation_dist_full_std}
\end{figure}

First, it is interesting to note the difference between the two environments. In the case of CartPoleGC, 
the $L\&S$ combination is the best as it obtains the least mistakes (\refFig{fig:cartpole_dist_ablation_full/terminated_regret}) 
with the highest coverage (\refFig{fig:cartpole_dist_ablation_full/is_success_final}). $S$ obtains the least 
number of mistakes for SkydioX2GC (\refFig{fig:skydio_ablation_dist_full_std/terminated_regret}) 
while it performs poorly on CartPoleGC both in safety and coverage \refFig{fig:cartpole_dist_ablation_full}.
Also, while $L$ offers the second-best safety performance for CartPoleGC, it obtains the worst safety performance 
with SkydioX2GC. Eventually, as $L\&S$ obtains a maximum of 10 mistakes against 7 for $S$ and clearly outperforms 
$S$ in terms of coverage, it appears as the default choice for both environments.
Also one may observe a common pattern in Figures \ref{fig:cartpole_dist_ablation_full} and 
\ref{fig:skydio_ablation_dist_full_std}. In both cases including the reachability critic in the actor loss
($L$ and $L\&S$) leads to better coverage than other approaches.
In the case of SkydioX2GC, we can see that other ablations than $S$ perform way better in terms of coverage.

\subsubsection{Effect of the thresholds and hysteresis}

By construction, our method implies a tradeoff between safety during exploration and coverage.
For instance, we remark that switching between the safety policy and the GC policy delays 
goal achievement in comparison to the full GC baseline. We leave videos in the supplementary material.
Again, the results are very different between environments. As for CartPoleGC, we show that high thresholds
(70 70 in \refFig{fig:cartpole_hysteresis})
lead to catastrophic performance in terms of safety during exploration, but also lead to
better coverage. On the contrary low thresholds (30 30 in \refFig{fig:cartpole_hysteresis})
lead to zero safety violations for all seeds but also to very poor coverage.
The best tradeoff between safety and coverage is obtained with $(\thGCtoS, \thStoGC) = (70, 30)$,
leading to a hysteresic behavior of the action selection mechanism. This choice was motivated by the 
fact that we have less confidence in the GC policy than in the safety policy to ensure safe exploration.
As for SkydioX2GC, the result is the exact opposite. Equal thresholds lead the the best safety performance 
while the hysteresic choice seems to generate way more instability.

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/cartpole_hysteresis/terminated_regret.pdf}
        \caption{}
        \label{fig:cartpole_hysteresis/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/cartpole_hysteresis/is_success_final.pdf}
        \caption{}
        \label{fig:cartpole_hysteresis/is_success_final}
    \end{subfigure}
    \caption{Effect of the thresholds on safe exploration with CartPoleGC for $(\thGCtoS, \thStoGC) \in \{ (30, 30), (70, 70), (70, 30)\}$ and the $L\&S$ variant.}
    \Description{Effect of the thresholds on safe exploration with CartPoleGC for $(\thGCtoS, \thStoGC) \in \{ (30, 30), (70, 70), (70, 30)\}$ and the $L\&S$ variant.}
    \label{fig:cartpole_hysteresis}
\end{figure}

\begin{figure}[ht]
    \begin{subfigure}{0.22\textwidth}  
        \centering 
        \includegraphics[width=\textwidth]{images/skydio_hysteresis/terminated_regret.pdf}
        \caption{}
        \label{fig:skydio_hysteresis/terminated_regret}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.22\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/skydio_hysteresis/is_success_final.pdf}
        \caption{}
        \label{fig:skydio_hysteresis/is_success_final}
    \end{subfigure}
    \caption{Effect of the thresholds on safe exploration with SkydioX2GC for $(\thGCtoS, \thStoGC) \in \{ (10, 10), (20, 20), (20, 10)\}$ and the $S$ variant.}
    \Description{Effect of the thresholds on safe exploration with SkydioX2GC for $(\thGCtoS, \thStoGC) \in \{ (30, 30), (70, 70), (70, 30)\}$ and the $S$ variant.}
\end{figure}

\subsection{Analysing failure modes}
\label{subsection:analysing failures}


\begin{SCfigure}
\includegraphics[width=0.22\textwidth]{images/cartpole_different_learn_seed_70_30/terminated_regret.pdf}
\caption{Occurrence of mistakes obtained during safe exploration for different pre-train policies with the CartPoleGC environment and $(\thGCtoS, \thStoGC) = (70, 30)$}
\Description{Occurrence of mistakes obtained during safe exploration for different pre-train policies 
with the CartPoleGC environment and $(\thGCtoS, \thStoGC) = (70, 30)$}
\label{fig:pretrain_effect}
\end{SCfigure}


%\begin{figure}[ht]
%\centering
%\includegraphics[width=0.22\textwidth]{images/cartpole_different_learn_seed_70_30/terminated_regret.pdf}
%\caption{$}
%\Description{Occurrence of mistakes obtained during safe exploration for different pretraining policies 
%with the CartPoleGC environment, $(\thGCtoS, \thStoGC) = (70, 30)$}
%\label{fig:pretrain_effect}
%\end{figure}

%\begin{wrapfigure}{r}{0.22\textwidth}
%\begin{center}
%    \includegraphics[width=0.21\textwidth]{images/cartpole_different_learn_seed_70_30/terminated_regret.pdf}
%\end{center}
%\caption{Occurrence of mistakes obtained during safe exploration for different pretraining seeds 
%with the CartPoleGC environment, $\thGCtoS = 70$ and $\thGCtoS = 30$}
%\Description{Occurrence of mistakes obtained during safe exploration for different pretraining seeds
%with the CartPoleGC environment, $\thGCtoS = 70$ and $\thGCtoS = 30$}
%\label{fig:pretrain_effect}
%\end{wrapfigure}
In this section, we propose to analyze the causes of the few mistakes we obtained with our
safe exploration method.
\refFig{fig:pretrain_effect} shows that the result strongly depends on pretraining. For one 
safety policy (policy 3), we obtain zero mistakes over the $3$ seeds of safe exploration training
while we obtain more than $25$ mistakes with the worst observed safety policy (policy 1). 
In order to avoid exhausting model selection engineering or cherry picking, we conducted a 
study to identify the failures' causes and obtain less variance with future algorithms.
Although one could decide to reduce thresholds, we do not want to penalize 
coverage because of simplistic choices.
Instead, we decided to analyse the trajectories stored in the episodic replay buffer $\buffer$ that ended
with a mistake to make a diagnosis. 
For CartpoleGC, with $(\thGCtoS, \thStoGC) = (70,30)$, 
all mistakes occur when the safety policy is active, meaning that the action selection mechanism
has seen the danger and switched too late from the GC to the safety policy. 
\refFig{fig:analyse_failures/921_scritic_critic_disagreement} shows a typical example of failure, 
characterized by a huge disagreement between critics before the mistake happens. This tends to
show that the safety policy has not been trained a lot on the corresponding states and actions. 
It also offers two straightforward complementary perspectives of research. The first is to take disagreement into 
account in the switching mechanism. The second is to finetune the safety policy during the safe exploration phase
to improve it, which is also confirmed by further analysis we left in the supplementary material.



% \begin{figure}[ht]
%     \includegraphics[width=0.25\textwidth]{images/cartpole_different_learn_seed_70_30/terminated_regret.pdf}
%     \caption{Mistakes occurrence obtained with the same safe exploration hyperparameters but with 
%     different pretrained policies, each associated to a seed.}
%     \label{fig:cartpole_different_learn_seed_70_30/terminated_regret}
%     \Description{Mistakes occurrence obtained with different seeds}
% \end{figure}

% \begin{figure}[ht]
%     \includegraphics[width=0.4\textwidth]{images/analyse_failures/921_safety_value_estimation.pdf}
%     \caption{}
%     \label{fig:analyse_failures/921_safety_value_estimation}
%     \Description{}
% \end{figure}

\begin{figure}[ht]
    \includegraphics[width=0.4\textwidth]{images/analyse_failures/921_scritic_critic_disagreement.pdf}
    \caption{Critic disagreement in $L_1$ norm between the quantile critics of the 
    same ensemble $Z^{\piS}$ along a failed episode of the CartPoleGC.
    Dots are green when the GC policy is activated and blue when the safety policy is activated.}
    \label{fig:analyse_failures/921_scritic_critic_disagreement}
    \Description{Critic disagreement in $L_1$ norm between the quantile critics of the 
    same ensemble $Z^{\piS}$ along an episode of the CartPoleGC.}
\end{figure}
