\section{Introduction}\label{sec:int}

Language models have demonstrated remarkable capabilities~\cite{openai2022intro,openai2023gpt,llmchallenges}, yet hallucinations and factual inaccuracies remain a significant limitation~\cite{ji2023survey,wang2023survey}. Furnishing the context with relevant evidence is a popular approach to enhance LM's ability to generate factually correct grounded responses~\cite{incontext_rag,activerag}.
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{figs/intro.png}
    \caption{
        \se workflow on a real example with Llama3.1-8B.
        By locating and explicitly highlighting the initially overlooked 2nd-hop evidence (“SAS was founded in 1941 ...") within the context, \se guides the model to arrive at the correct answer “1941”.
    }
    \label{fig:intro}
    \vspace{-10pt}
\end{figure}
However, recent studies find that LMs can fail to properly leverage supporting facts within context, leading to incorrect answers despite available evidence~\cite{shi2024cad,zhao2024cd}.
Such failure largely stems from the noise and irrelevant information in context~\cite{wu2024ragirrelevant, cuconasu2024ragnoise}, which is usually inevitable in practice~\cite{gao2023ragsurvey}.

Recently, improved prompting~\cite{zhou2023prompt} or decoding~\cite{shi2024cad} methods have been proposed to enhance the focus on context. However, they treat the whole context as a single entity, overlooking the fact that not all information provided in the context is important.
In this work, we investigate how to leverage contextual information at a finer granularity to help LMs focus more effectively on the key evidence within the context. 
Our contributions in this work are as follows:
\begin{itemize}
    \item By analyzing the attention scores during response generation, we demonstrate that the LMs have an inherent ability to identify the relevant evidence in the context, regardless of whether they respond correctly or not. This observation holds across various LM families.
    \item Leveraging this inherent ability, we propose an inference time context augmentation approach, \se, that highlights the important evidence in the context and improves LM's ability to provide factually correct grounded responses. \se is \textbf{efficient} for inference, \textbf{training-free}, and \textbf{robust} to noise and hyper-parameter choice.
    \item In a comprehensive study, we show the significant performance improvement that \se brings across model families and benchmarks. We also provide detailed studies for hyper-parameters in \se and additional analysis on its ability to elicit relevant evidence robustly from noisy context.
\end{itemize}
Fig.~\ref{fig:intro} illustrates the \se workflow. By identifying and highlighting key evidence within the context, \se guides the LM towards important information that it might otherwise overlook, leading to more factual responses.