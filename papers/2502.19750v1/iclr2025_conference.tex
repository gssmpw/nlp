
\documentclass{article} % For LaTeX2e
\usepackage{iclr2025_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}
% \usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{url}
\usepackage{multirow}
\usepackage{array}
\usepackage{booktabs} 
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{mathtools}
% \usepackage[table]{xcolor} %
\setlist[itemize]{leftmargin=*}

\definecolor{kleinblue}{rgb}{0,0.18,0.65}
\hypersetup{colorlinks=true,citecolor=kleinblue, linkcolor=black, urlcolor=kleinblue}

\title{CirT: Global Subseasonal-to-Seasonal Forecasting with Geometry-inspired Transformer}

\iclrfinalcopy
% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

% \author{Antiquus S.~Hippocampus, Natalia Cerebro \& Amelie P. Amygdale \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.  Funding acknowledgements go at the end of the paper.} \\
% Department of Computer Science\\
% Cranberry-Lemon University\\
% Pittsburgh, PA 15213, USA \\
% \texttt{\{hippo,brain,jen\}@cs.cranberry-lemon.edu} \\
% \And
% Ji Q. Ren \& Yevgeny LeNet \\
% Department of Computational Neuroscience \\
% University of the Witwatersrand \\
% Joburg, South Africa \\
% \texttt{\{robot,net\}@wits.ac.za} \\
% \AND
% Coauthor \\
% Affiliation \\
% Address \\
% \texttt{email}
% }
\author{Yang Liu\textsuperscript{1,2}\thanks{Equal contribution.}, Zinan Zheng\textsuperscript{1}\footnotemark[1], Jiashun Cheng\textsuperscript{1,2}, Fugee Tsung\textsuperscript{1,2}, Deli Zhao\textsuperscript{3}, Yu Rong\textsuperscript{3}\thanks{Corresponding authors (\texttt{jialee@ust.hk, yu.rong@hotmail.com})}, Jia Li\textsuperscript{1,2}\footnotemark[2]\\
$^{1}$The Hong Kong University of Science and Technology (Guangzhou) \\
$^{2}$The Hong Kong University of Science and Technology$\,$ $^{3}$DAMO Academy, Alibaba Group\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Accurate Subseasonal-to-Seasonal (S2S) climate forecasting is pivotal for decision-making including agriculture planning and disaster preparedness but is known to be challenging due to its chaotic nature. Although recent data-driven models have shown promising results, their performance is limited by inadequate consideration of geometric inductive biases. Usually, they treat the spherical weather data as planar images, resulting in an inaccurate representation of locations and spatial relations. In this work, we propose the geometric-inspired Circular Transformer (CirT) to model the cyclic characteristic of the graticule, consisting of two key designs: (1) Decomposing the weather data by latitude into circular patches that serve as input tokens to the Transformer; (2) Leveraging Fourier transform in self-attention to capture the global information and model the spatial periodicity. Extensive experiments on the Earth Reanalysis 5 (ERA5) reanalysis dataset demonstrate our model yields a significant improvement over the advanced data-driven models, including PanguWeather and GraphCast, as well as skillful ECMWF systems. Additionally, we empirically show the effectiveness of our model designs and high-quality prediction over spatial and temporal dimensions. The code link is: \url{https://github.com/compasszzn/CirT}.

\end{abstract}

\section{Introduction}


Subseasonal-to-seasonal (S2S) forecasting, which predicts meteorological variables 2 to 6 weeks in advance, is crucial for agriculture, resource allocation, and disaster preparedness (e.g., heatwaves and droughts)~\citep{mouatadid2024subseasonalclimateusa}. Despite its high socioeconomic benefits, such a task has long been considered a ``predictability desert''~\citep{vitart2012subseasonal} due to the chaotic nature of the atmosphere. Compared with medium-range (up to 15 days) and seasonal predictions (3-6 months)~\citep{vitart2017subseasonal}, the S2S timescale is long enough to lose much of the memory of atmospheric initial conditions, while it is too short for slowly evolving earth system components such as the ocean that strongly influence the atmosphere~\citep{black2017predictors,phakula2024literature}. The existing S2S near-real-time forecasting models rely on physics-based Numerical Weather Prediction (NWP) models that discretize governing equations of thermodynamics, fluid flow, etc~\citep{nathaniel2024chaosbench}. However, these models generally suffer considerable biases~\citep{mouatadid2023adaptive} and require massive computational resources to perform numerical integration at fine-grained resolutions~\citep{schneider2023harnessing}.

Multiple studies utilize the potential of data-driven models to mitigate the above weakness, in which most works~\citep{hwang2019improving,he2022learning,mouatadid2024subseasonalclimateusa} focus on regional forecasting. However, the regional weather is often influenced by conditions in other areas on the S2S timescale, indicating the insufficiency of relying solely on regional inputs for S2S forecasting~\citep{vitart2012subseasonal,lau2011intraseasonal,robertson2015improving}. With the development of the high-quality Earth Reanalysis 5 (ERA5) dataset~\citep{hersbach2020era5} and weather foundation models~\citep{pathak2022fourcastnet,lam2022graphcast,bi2023accurate}, a few studies~\citep{chen2024machine,nguyen2023climax,weyn2021sub} have proposed global data-driven S2S forecasting models and achieved promising results. Specifically, they treat weather parameter values on the latitude-longitude grid (i.e., graticule) as image data, represented as 3-dimensional tensors, and employ the Transformer~\citep{dosovitskiy2020image} to forecast the future weather parameter values as an image generation task. Despite the promising results, the inconsistency between the planar and sphere geometry leads to significant distortions in learning dynamics, resulting in incorrect spatial relations. Figure~\ref{fig:intro} depicts the example of this heavy distortion in planar projection.

\begin{wrapfigure}[17]{r}{0.4\textwidth}
    \centering
    \vspace{-5ex}
    \includegraphics[width=\linewidth]{distortion.pdf}
    \vspace{-5ex}
    \caption{Planar and the spherical view of 2-metre temperature. Treating it as an image results in distortion.}
    \label{fig:intro}
\end{wrapfigure}


Therefore, we re-investigate the transformer design for graticule by considering two geometric inductive biases. First, existing methods decompose the planar latitude-longitude image into the fixed-degree patch, such as $3^\circ\times 3^\circ$, ignoring that parallels have unequal geometric lengths. For example in Figure 1, although the patch size is the same in the planar view, the area of Patch 2 is significantly larger than that of Patch 1.
Thus, the generated patches are of varying sizes and shapes in the sphere, especially in high-altitude regions, leading to an uneven distribution of information across patches. Second, the graticule demonstrates latitudinal spatial periodicity. Overlooking such an inductive bias results in inaccurate spatial relation modeling. As shown in Figure~\ref{fig:intro}, the left and right boundaries of the planar view are connected while appear separated.
% It remains unchanged under latitudinal rotation, describing the cyclic structure in the sphere. In contrast, as shown in Figure 1, the left and right boundaries of the distorted view are disconnected. 

In this work, we propose a Circular Transformer (CirT) that implements an equidistant circular patching strategy and self-attention incorporating spatial periodicity. To construct undistorted spatial relations among patches, CirT partitions the graticule uniformly by latitude, treating weather variables distributed on each parallel as a patch. Thus, the generated patches are in the same shape with geometric lengths determined by latitudes. Meanwhile, the adjacent patches are equidistant. Considering the weather signals are spatially periodic on the circular patch, we treat it as a spatial signal of $2\pi$ periodicity and leverage the Fourier transform to extract the global features and perform self-attention to mix patches on the frequency domain. The frequencies are inversely transformed into the spatial domain to make the final forecasting. Finally, instead of learning autoregressive models like previous works~\citep{chen2024machine,nguyen2023climax,weyn2021sub}, we directly train CirT to predict in S2S timescale, which avoids the large accumulation errors and learns the connections between the initial and target states. 
Through extensive experiments on the ERA5 dataset, we find that
\begin{itemize}
    \item Remarkably, CirT outperforms skillful numerical S2S systems including UKMO, NCEP, CMA, and ECMWF, as well as state-of-the-art data-driven models including ClimaX, FourCastNetV2, PanguWeather, and GraphCast on S2S forecasting. 
    \item Most methods, including data-driven and numerical models, achieve a larger bias in high-latitude areas. In contrast, we show that CirT produces more structurally consistent results with ground truth and performs better in these areas. 
    \item Ablation studies show that the proposed two simple designs, circular patching and patch mixing in the frequency domain, significantly enhance the model performance.
\end{itemize}



\section{Preliminary}

\paragraph{Problem Definition} 

We study the bi-weekly forecasting of $K$ weather parameters at the latitude-longitude grid $\bm{\mathcal{G}} \in \mathbb{R}^{H \times W\times 2}$. 
$H$ and $W$ are the height and width of the grid that depends on the resolution of latitude and longitude, and $\bm{\mathcal{G}}_{h, w, :} = (\lambda_{h}, \phi_{w}) \in \Omega = [-90^{\circ}, 90^{\circ}]\times [-180^{\circ}, 180^{\circ}]$.
At day $t$, the state of global weather is represented by a 3-dimensional tensor $\bm{\mathcal{X}}_{t} \in \mathbb{R}^{H \times W \times K}$. 
Following previous works~\citep{chen2024machine,mouatadid2023adaptive,nguyen2023climax}, given the initial condition $(\bm{\mathcal{G}}, \bm{\mathcal{X}}_{t_1})$, our objective is to learn a neural network to predict the average value of weather variables over weeks 3-4 and weeks 5-6, as shown in the following:
\begin{equation}
\begin{aligned}
    (\bm{\hat{\mathcal{X}}}_{t_{15}:t_{28}}, \bm{\hat{\mathcal{X}}}_{t_{29}:t_{42}}) = f_{\Theta}(\bm{\mathcal{G}}, \bm{\mathcal{X}}_{t_1}),
\end{aligned}
\end{equation}
where $\Theta$ denotes the parameters of neural networks. $\bm{\hat{\mathcal{X}}}_{t_{15}:t_{28}}$ and $\bm{\hat{\mathcal{X}}}_{t_{29}:t_{42}}$ are predicted average value over weeks 3-4 (from day 15 to day 28) and weeks 5-6 (from day 29 to day 42). 
Distinct from data-driven medium-range models that iteratively produce the results, we aim to learn a model that directly predicts these two values.



\paragraph{Fourier Transform and Inversion}
Fourier Transform is known to be an effective tool to extract features from periodic signals. Consider a sequence of $N$ grid-based real-valued observations of a function, denoted by $\bm{s} = (s_{1}, ..., s_{N}) \in \mathbb{R}^{N}$. 
The Discrete Fourier Transform (DFT), represented by $\mathcal{F}$, converts this sequence into the frequency domain with a periodicity of $2\pi$ as follows:
\begin{equation}\label{eqn:dft}
\begin{aligned}
    S_{k} = \sum_{n=1}^{N} s_{n} \cos \Bigl( 2\pi \frac{k}{N} n \Bigr) - i \sum_{n=1}^{N} s_{n} \sin \Bigl( 2\pi \frac{k}{N} n \Bigr) = A_{k} - B_{k} i,
\end{aligned}
\end{equation}
where $\bm{S} = \mathcal{F}(\bm{s}) = (S_{1}, ..., S_{N}) \in \mathbb{R}^{N}$ and $i$ is the imaginary unit. 
$A_{k}$ and $B_{k}$ are the real and imaginary parts of the complex number $S_{k}$ in the frequency domain, respectively. 
The inverse transformation, which reconstructs the original sequence from the frequency domain, is given by:
\begin{equation}
    s_{n} = \frac{1}{N} \sum_{k=1}^{N} S_{k} \Bigl( \cos \Bigl( 2\pi \frac{n}{N} k \Bigr) + i \sin \Bigl( 2\pi \frac{n}{N} k \Bigr) \Bigr),
\end{equation}
or equivalently by substituting $S_{k} = A_{k} - B_{k} i$ ,
\begin{equation}\label{eqn:idft}
     s_{n} = \frac{1}{N} \sum_{k=1}^{N} \Bigl( A_{k} \cos \Bigl( 2\pi \frac{n}{N} k \Bigr) - B_{k} \sin \Bigl( 2\pi \frac{n}{N} k \Bigr) \Bigr),
\end{equation}
where the imaginary unit is canceled out. 
We express the inverse transform as $\bm{s} = \mathcal{F}^{-1}(\bm{S})$ for symmetry.



\begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{CirT.pdf}
    \caption{CirT architecture and circular patching examples. The input tensors are first decomposed by latitudes, resulting in a set of circular patches. Then they are fed into a series of Transformer blocks where DFT and IDFT are applied in each block to transform information between frequency and spatial domain. Finally, the output head maps the representation to biweekly predictions.}
    \label{fig:cirt}
\end{figure}


\section{CirT Model}

Our CirT architecture is illustrated in Figure~\ref{fig:cirt}. The input $\bm{\mathcal{X}}_{t_{1}}$ is split to $H$ embedded circular patches and then fed into the Transformer encoder to predict the Weeks 3-4 and Weeks 5-6 results. In the following, we elaborate on the model structure including circular patching and transformer encoder.

\paragraph{Circular Patching}

CirT first divides the input $\bm{\mathcal{X}}_{t_{1}}$ into $H$ latitudinal non-overlapping patches $\{ \bm{X}^{(h)} \}_{h=1}^{H}$ where $\bm{X}^{(h)} \in \mathbb{R}^{W \times K}$ and its $w$-th row $\bm{X}^{(h)}_{w} \in \mathbb{R}^{K}$ denotes the $K$ weather values at the coordinate $(\lambda_{h},\phi_{w})$. Thus, the geometric distance of adjacent patches $\bm{X}^{(h)}_{w}$ and  $\bm{X}^{(h)}_{w+1}$ is fixed to $R\Delta\phi$ where $\Delta\phi$ is the longitude resolution and $R$ is the earth radius. Meanwhile, the geometric length of the patch $\bm{X}^{(h)}$ can be determined by $2\pi R\cos(\lambda_h)$. These patches are then flattened and stacked into a matrix $\bm{X}^{F} \in \mathbb{R}^{H \times (W \cdot K)}$, which is subsequently projected into latent space to generate initial embedding $\bm{E} \in \mathbb{R}^{H \times D}$ as follows:
\begin{equation}
\begin{aligned}
     \bm{E} = \bm{X}^{F} \bm{W}_{p} + \bm{W}_{pos},
\end{aligned}
\end{equation}
where $\bm{W}_{p} \in \mathbb{R}^{(W \cdot K) \times D}$ and $\bm{W}_{pos} \in \mathbb{R}^{H \times D}$ denote the learnable projection matrix and additive position embedding, respectively. 
Subsequently, the initial embedding is fed into the Transformer encoder for further processing.

\paragraph{CirT Transformer Encoder}

Considering the circular patch satisfies $X_{w} = X_{w + W}$. Therefore, instead of directly inputting $X$ into the transformer, we consider its Fourier transform, composed of coefficients from a series of periodic basis functions.
The Fourier Transform offers insights into the wave frequencies present in the periodic signals, which aligns well with data with inherent periodicities~\citep{zhou2022fedformer,NEURIPS2023_8e2a75e0}.
Our approach aims to incorporate such an inductive bias into the learning process by operating in the frequency domain.
Specifically, at the $l$-th transformer block, we begin by applying DFT to each row of input embedding $\bm{E}^{(l)} \in \mathbb{R}^{H \times D}$, where $\bm{E}_{h}^{(l)} = (E_{h, 1}^{(l)}, ..., E_{h, D}^{(l)}) \in \mathbb{R}^{D}$ corresponds to the embedding of the $h$-th patch.
According to Eqn.~\ref{eqn:dft},
\begin{equation}
\begin{aligned}
    S_{h, k}^{(l)} = \sum_{n=1}^{D} E_{h, n}^{(l)} \cos \Bigl( 2\pi \frac{k}{N} n \Bigr) - i \sum_{n=1}^{D} E_{h, n}^{(l)} \sin \Bigl( 2\pi \frac{k}{N} n \Bigr) = A_{h, k}^{(l)} - B_{h, k}^{(l)} i,
\end{aligned}
\end{equation}
where $\bm{S}_{h}^{(l)} = \mathcal{F}(\bm{E}_{h}^{(l)}) \in \mathbb{R}^{D}$ represents the complex frequency embedding, and $\bm{A}_{h}^{(l)} = \text{Re}(\bm{S}_{h}^{(l)})$ and $\bm{B}_{h}^{(l)} = \text{Im}(\bm{S}_{h}^{(l)})$ represent its real and imaginary parts, respectively.
These components of all patches are then stacked into matrices $\bm{A}^{(l)} \in \mathbb{R}^{N \times D}$ and $\bm{B}^{(l)} \in \mathbb{R}^{N \times D}$, which are then jointly fed to the multi-head attention to consider their correlation.

For the $m$-th attention head, we compute the query, key, and value matrices of $\bm{C}^{(l)} = [\bm{A}^{(l)}, \bm{B}^{(l)}] \in \mathbb{R}^{H \times 2D}$ following standard attention operations:
\begin{equation}
    \bm{Q}^{(l, m)}=\bm{C}^{(l)} \bm{W}_{m}^{Q}, \quad \bm{K}^{(l, m)}=\bm{C}^{(l)} \bm{W}_{m}^{K}, \quad \bm{V}^{(l, m)}=\bm{C}^{(l)} \bm{W}_{m}^{V}, 
\end{equation}
where $\bm{W}_{m}^{Q/K/V} \in \mathbb{R}^{2D \times 2D}$ are learned projection matrices.
The attention output $\bm{\tilde{A}}^{(l, m)}$ and $\bm{\tilde{B}}^{(l, m)}$ are then computed using scaled production:
\begin{equation}
    \bm{\tilde{C}}^{(l, m)} = [ \bm{\tilde{A}}^{(l, m)}, \bm{\tilde{B}}^{(l, m)}] = \text{softmax}(\frac{\bm{Q}^{(l, m)} \bm{K}^{(l, m)}}{\sqrt{D}})\bm{V}^{(l, m)},
\end{equation}
where $\bm{\tilde{A}}^{(l, m)}$ consists of the first $D$ columns of the output $\bm{\tilde{C}}^{(l, m)}$ while $\bm{\tilde{B}}^{(l, m)}$ corresponds to the rest.
% An analogous process is applied to the matrix $\bm{B}^{(l)} \in \mathbb{R}^{N \times D}$, yielding the corresponding attention output $\bm{\tilde{B}}^{(l, m)}$.
For the $h$-th patch, the processed frequency-domain representation is then rearranged as $\bm{\tilde{S}}^{(l, m)}_{h} = \bm{\tilde{A}}^{(l, m)}_{h} - \bm{\tilde{B}}^{(l, m)}_{h} i$.
This representation is then converted back to the original domain by applying the inverse DFT following Eqn.~\ref{eqn:idft}:
\begin{equation}
    \tilde{E}^{(l, m)}_{h, n} = \frac{1}{D} \sum_{k=1}^{D} \Bigl( \tilde{A}^{(l, m)}_{h, k} \cos \Bigl( 2\pi \frac{n}{N} k \Bigr) - \tilde{B}^{(l, m)}_{h, k} \sin \Bigl( 2\pi \frac{n}{N} k \Bigr) \Bigr),
\end{equation}
where $\bm{\tilde{E}}^{(l, m)}_{h} = \mathcal{F}^{-1}(\bm{\tilde{S}}^{(l, m)}_{h})$ is the inverse-transformed representation of the patch.
By stacking these transformed representations, we obtain the reconstructed embedding $\bm{\tilde{E}}^{(l, m)}$. 
Finally, a feed-forward network is used to generate the output embedding $\bm{E}^{(l+1)}$ by passing the reconstructed embeddings from all heads:
\begin{equation}
\begin{aligned}
     \bm{E}^{(l+1)} = \text{MLP}([\bm{\tilde{E}}^{(l, 1)}, \cdots, \bm{\tilde{E}}^{(l, M)}]).
\end{aligned}
\end{equation}
For brevity, we omit the LayerNorm layers in the forward process of the Transformer block, as shown in Figure~\ref{fig:cirt}.


\paragraph{Training}
Given the output representation of the Transformer encoder, a flattened MLP is used to obtain the prediction results of weeks 3-4 and weeks 5-6. 
The model is trained to minimize the discrepancy between the prediction and ground truth. The loss in each variable and location is gathered and averaged over weeks 3-4 and 5-6 to calculate the overall objective loss:
\begin{equation}
\begin{aligned}
     \mathcal{L} = \frac{1}{2 \times K \times H \times W} ( || \bm{\hat{\mathcal{X}}}_{t_{15}:t_{28}} - \bm{\mathcal{X}}_{t_{15}:t_{28}} ||_{2}^{2} + || \bm{\hat{\mathcal{X}}}_{t_{29}:t_{42}} - \bm{\mathcal{X}}_{t_{29}:t_{42}} ||_{2}^{2} ),
\end{aligned}
\end{equation}
where $\bm{\mathcal{X}}_{t_{15}:t_{28}}$ and $\bm{\mathcal{X}}_{t_{29}:t_{42}}$ are the ground truth. 


\section{Experiments}

\paragraph{Dataset}
We evaluate the effectiveness of CirT on the ERA5 reanalysis dataset~\citep{hersbach2020era5} which provides the comprehensive pressure and single levels climate variables. The resolution is set to $1.5^{\circ}$, resulting in a 121$\times$240 latitude-longitude grid. We use 6 pressure level variables, including geopotential ($z$), specific humidity ($q$), temperature ($t$), u component of wind ($u$), v component of wind ($v$), and vertical velocity ($w$) at 10 pressure levels: 10, 50, 100, 200, 300, 500, 700, 850, 925 and 1000 hPa. Besides, we integrate 3 more single levels variables: 2m temperature ($t2m$), 10m u component of wind ($10u$), 10m v component of wind ($10v$), totaling 63 variables. We use the 1979–2016 (38 years of) data for training, the 2017 data for validation, and the 2018 for testing.
 
\paragraph{Metric} 
Following existing works~\citep{rasp2024weatherbench,nathaniel2024chaosbench}, we adopt latitude-weighted RMSE and Anomaly Correlation Coefficient (ACC) to evaluate the model performance with $K = 1$, which are defined as follows:
{\small
\begin{equation}\label{eq:lat_rmse}
    \mathbf{\mathrm{RMSE}} = \sqrt{\frac{1}{H W} \sum_{h, w} \alpha(h) (\bm{\hat{X}}_{h,w} - \bm{X}_{h,w})^2}, \, \mathbf{\mathrm{ACC}} = \frac{\sum_{h,w} \alpha(h) \bm{\hat{X}}'_{h, w} \bm{X}'_{h, w}}{\sqrt{\sum_{h,w} \alpha(h) \bm{\hat{X}}_{h, w}^{'2} \sum_{h,w} \alpha(h) \bm{X}_{h, w}^{'2} }},
\end{equation}}
where $\alpha(h) = \cos(\lambda_{h}) / \frac{1}{H} \sum_{h'} \cos(\lambda
_{h'})$ is the latitude weighting factor.
$\bm{X} = \bm{\mathcal{X}}_{t, :, :, 1} \in \mathbb{R}^{H \times W}$ is the ground truth for specific day $t$ with its prediction $\bm{\hat{X}}$. 
$\bm{X}'_{h, w} = \bm{X}_{h, w} - C$ and $\bm{\hat{X}}'_{h, w} = \bm{\hat{X}}_{h, w} - C$, where $C$ is the observational climatology (i.e., empirical mean of observational data).


\paragraph{Data-driven baselines} 
Following the existing S2S benchmark~\citep{nathaniel2024chaosbench}, we compare CirT with state-of-the-art data-driven models, including FourCastNetV2~\citep{pathak2022fourcastnet},  PanguWeather~\citep{bi2023accurate}, GraphCast~\citep{lam2022graphcast} and ClimaX~\citep{nguyen2023climax}. Among them, FourCastNetV2, PanguWeather, and ClimaX follow a ViT process, while GraphCast is a graph neural network. 

\paragraph{Physics-based baselines}
To further evaluate the model performance of CirT, we compare it with various advanced physics-based models, including  UK Meteorological Office (UKMO)~\citep{williams2015met},  National Centers for Environmental Prediction (NCEP)~\citep{saha2014ncep}, China Meteorological Administration (CMA)~\citep{wu2019beijing},  European Centre for Medium-Range Weather Forecasts (ECMWF)~\citep{molteni1996ecmwf}. Among them, ECMWF is recognized as the most skillful S2S
modeling system~\citep{chen2024machine,domeisen2022advances}. More details are shown in the Appendix. 

\paragraph{Implementation details} We use the following hyper-parameters for all direct training baselines: Batch size 16, the hidden dimension 256, and the attention head 16. All models are set to 8 layers and the learning rate is 0.01. All models are trained for 20 epochs. All models are implemented based on Pytorch Lightning, trained on 8 GeForce RTX 4090 GPU. We train ClimaX the same as CirT and download trained FourCastNetV2, PanguWeather, and GraphCast through API\footnote{https://github.com/ecmwf-lab/ai-models} provided by ECMWF. We perform the inference of Download models in NVIDIA A800 80G GPU. We use the download parameters and do not finetune them to the S2S timescale due to the limited computational resources.
Note that although FourCastNetV2 and PanguWeather report the 2-meter predictions, the retrieved model in ECMWF does not include its inference and GraphCast is out-of-memory when performing inference for Weeks 5-6.


\subsection{Overall Performance}

\paragraph{Compared with data-driven models}
We display the model performance in 7 target variables: geopotential at 500hPa ($z500$), geopotential at 850hPa ($z850$), temperature at 500hPa ($t500$), temperature at 850hPa ($t850$), 2m temperature ($t2m$), 10 metre U wind component ($u10$) and 10 metre V wind component ($v10$) in Table~\ref{table:overall}. Based on these results, we have the following observations:
\begin{itemize}
    \item CirT consistently outperforms all baselines in all cases. Specifically, compared to the best baseline, the average RMSE improvement on geopotential ($\text{m}^2/\text{s}^2$) and temperature ($K$) over Weeks 3-4 and Weeks 5-6 is $96.5, 0.369$, and $111, 0.843$, demonstrating significant improvement. 
    \item CirT achieves larger improvement over Weeks 5-6 than Weeks 3-4 predictions. The iterative models (i.e., FourCastNetV2 and PanguWeath) accumulate errors in each step, leading to inaccurate predictions when the iterative step is large. In contrast, the direct prediction models aim to capture the relations between initial and subseasonal states, resulting in lower performance drops.
    \item Compared with ViT-based iterative models, GraphCast achieves relatively better performance in Weeks 3-4 predictions. The reason can be attributed to that it employs mesh to model the sphere geometry, leading to lower accumulated errors.
    \item We can find that wind forecasting is more challenging than other comparing variables. For example, Weeks 3-4 t850 ACC of FourCastNetV2 is 0.957 while u10 ACC is 0.830. Under such cases, CirT still performs the best, further verifying its effectiveness.
\end{itemize}
In addition, we provide a relative RMSE comparison in Figure~\ref{fig:heatmap}. We can observe that CirT generally achieves lower errors across all pressure levels. When the lead time increases from Weeks 3-4 to 5-6, the performance of baselines significantly reduces, especially in Temperature. In contrast, CirT maintains relatively low errors.


\begin{table}[t]
    \setlength{\tabcolsep}{0.5mm}
    \centering 
    \caption{
    Global S2S forecasting results of data-driven models. The lower RMSE and higher ACC indicate better results.}
    \label{table:overall}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{ccccccc|ccccc}
    \toprule
    \multicolumn{2}{c}{\multirow{2}{*}{\textbf{Metric}}}  & \multicolumn{5}{c|}{\textbf{RMSE ($\downarrow$)}} &  \multicolumn{5}{c}{\textbf{ACC ($\uparrow$)}} \\
      & & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT \\
    \midrule
    
   \multirow{7}{*}{\rotatebox{90}{\textbf{Weeks 3-4}}} & z500 ($\text{m}^2/\text{s}^2$)  &615  &618  & 649    &\underline{602}   &\textbf{477} & 0.947   &0.973 &0.963    &\underline{0.977}  &\textbf{0.984}\\
    & z850 ($\text{m}^2/\text{s}^2$)  &402   &411 &416    & \underline{372} &\textbf{304} & 0.896   &0.931 &0.926  &\underline{0.949 } &\textbf{0.963}\\
    &t500 ($K$)  &\underline{2.093}  &2.176  &2.271   & 2.186  &\textbf{1.687} &0.966    &0.979 &0.966  & \underline{0.981} &\textbf{0.988}\\
    & t850 ($K$) &2.390  & \underline{2.370}  & 2.569   &2.618   &\textbf{1.903} & 0.957   &\underline{0.982} &0.963 &0.981  &\textbf{0.988}\\
    &t2m ($K$) & --  & \underline{2.158}  & --   &2.998   & \textbf{2.007} & --  & \underline{0.991}  & -- &0.985  &\textbf{0.993}\\

    & u10 ($\text{m}/\text{s}$) &\underline{2.328}  &--  &2.431  &2.334  &\textbf{1.806}  &\underline{0.830}  &--  &0.812  & 0.817 &\textbf{0.896}\\

    &v10 ($\text{m}/\text{s}$) &\underline{1.896}   &--  &1.984  &1.906  &\textbf{1.511} & \underline{0.712 } &--  &0.686 &0.667  &\textbf{0.811}\\
    \midrule
    \multirow{7}{*}{\rotatebox{90}{\textbf{Weeks 5-6}}}& z500 ($\text{m}^2/\text{s}^2$) &652   &--  &754     &\underline{619}   &\textbf{471} &0.943    & -- &0.956 &\underline{0.976}  &\textbf{0.985}\\
    & z850 ($\text{m}^2/\text{s}^2$) &426  &--   &461    & \underline{375} &\textbf{301} &0.889    &--  &0.911  &\underline{0.948}  &\textbf{0.964}\\
    &t500 ($K$)  &\underline{2.250} &--   & 2.829   &2.254   &\textbf{1.672} &  0.963  &--  &0.958  & \underline{0.980}&\textbf{0.988}\\
    & t850 ($K$) & 2.567  &--  & 2.998   &\underline{2.741}   &\textbf{1.933} & 0.953   &--  &0.957  &\underline{0.980}&\textbf{0.989}\\
    &t2m ($K$) & --  & --  & --     &\underline{3.168}   & \textbf{2.026} & --  & --  & --  & \underline{0.984}&\textbf{0.992}\\
    
    & u10 ($\text{m}/\text{s}$)&2.479   &--  &2.679   &\underline{2.355}  &\textbf{1.809}  &0.812  &--  &0.783  &\underline{0.814}  &\textbf{0.895}\\
    
    &v10 ($\text{m}/\text{s}$) &1.980   &--  &2.104  &\underline{1.939}  &\textbf{1.512} &\underline{0.691}   &--  &0.655  &0.659  &\textbf{0.812}\\

    \bottomrule
    \end{tabular}
    }
\end{table}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{heatmap_ai.pdf}
    \includegraphics[width=1\textwidth]{heatmap.pdf}
    \includegraphics[width=1\textwidth]{heatmap_ai_wind.pdf}
    \includegraphics[width=1\textwidth]{heatmap_nw_wind.pdf}
    \caption{RMSE comparison between CirT and data-driven and numerical methods on geopotential $z$, temperature $t$, wind $u$, and $v$ of different pressure levels. FCN, GC, and PW are short for FourCastNetV2, GraphCast, and PanguWeather. A lighter color indicates better results: CirT consistently outperforms all models.}
    % \vspace{-2ex}
    \label{fig:heatmap}
\end{figure*}

\paragraph{Compared with numerical models}
To better investigate the performance of CirT, we compare it and numerical models in Figure~\ref{fig:heatmap}, where lighter colors indicate lower RMSE. The ACC results are shown in the Appendix. From the results, we can find that:
\begin{itemize}
    \item CirT remarkably outperforms numerical models in almost all cases, demonstrating the effectiveness of direct data-driven models. In addition, numerical methods underperform at low-pressure levels, especially at the 10 hPa level, while CirT still performs better.
    \item Compared with the results of Weeks 3-4 and 5-6, we can observe that similar to iterative data-driven models, the performance of numerical models decreases when the lead time increases but the performance drop is smaller than data-driven models. Such results show that physics-based models are more stable than iterative data-driven models.  
    Overall, CirT which directly predicts the biweekly states maintains the best performance. 
\end{itemize}

\begin{table}[t]
    \setlength{\tabcolsep}{0.6mm}
    \centering 
    \caption{
    Ablation studies of patching strategies and Fourier transform.}
    \label{table:abl}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{cccccccccc|ccccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Patch}} & \textbf{Fourier} & \multicolumn{7}{c|}{\textbf{RMSE ($\downarrow$)}} &  \multicolumn{7}{c}{\textbf{ACC ($\uparrow$)}} \\
     & &  \textbf{Transform} & z500  & z850  & t500  & t850  & t2m  &u10 &v10 & z500 & z850  & t500  & t850  & t2m &u10 & v10\\
    \midrule
    \multirow{4}{*}{\rotatebox{90}{\textbf{Weeks 3-4}}} & Grid & $\times$ &516  &319 &1.910 &2.168 &2.554 &1.946 &1.616&0.983 &0.959 &0.986 &0.987&0.990 &0.877 &0.782 \\
    & Circular & $\times$ &502  &313 &1.74 &2.077 &2.000 &1.827 &1.503 &0.983 &0.961 &0.987 &0.988&0.993 &0.893 &0.811 \\
    & Grid & \checkmark &497  &324 &1.733 &2.050 &2.583 &1.970 &1.614 &0.983 &0.958 &0.988 &0.988&0.990 &0.875 &0.782\\
    & Circular & \checkmark &\textbf{477}  &\textbf{304} &\textbf{1.687} &\textbf{1.903} &\textbf{2.007} &\textbf{1.806} &\textbf{1.511} &\textbf{0.984} &\textbf{0.963} &\textbf{0.988} &\textbf{0.988} &\textbf{0.993} &\textbf{0.896} &\textbf{0.811}\\
    \midrule
    \multirow{4}{*}{\rotatebox{90}{\textbf{Weeks 5-6}}} & Grid & $\times$ &501  &319 &1.808 &2.113 &2.578 &1.932 &1.614 &0.983 &0.959 &0.987 &0.987&0.989 &0.879 &0.783\\
    & Circular & $\times$ &498  &311 &1.707 &2.008 &2.178 &1.812 & 1.515&0.984 &0.962 &0.987 &0.989&0.992 &0.895 &0.810\\
    & Grid & \checkmark &494  &320 &1.737 &2.112 &2.650 &1.963 &1.621 &0.983 &0.960 &0.988 &0.988&0.989 &0.877 &0.781\\
    & Circular & \checkmark &\textbf{471} &\textbf{301} &\textbf{1.672} &\textbf{1.933}&\textbf{2.026} &\textbf{1.809} &\textbf{1.512} &\textbf{0.985} &\textbf{0.964} &\textbf{0.988} &\textbf{0.989}&\textbf{0.993} &\textbf{0.895} &\textbf{0.812}\\
    \bottomrule
    \end{tabular}
    }
\end{table}

\begin{table}[t]
    \setlength{\tabcolsep}{0.6mm}
    \centering 
    \caption{
    RMSE comparison w.r.t. latitude. CirT generally achieves the best performance and has a higher relative improvement in mid-/high-latitude areas.}
    \label{table:lat}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{ccccccc|ccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Variable}}  & \multicolumn{5}{c|}{\textbf{Weeks 3-4}} &  \multicolumn{5}{c}{\textbf{Weeks 5-6}} \\
    & & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  \\
    \midrule
   \multirow{7}{*}{\rotatebox{90}{\textbf{Low-Lat.}}}& z500    &\textbf{200}  &229 &293    &234 &\underline{206}  &\underline{223}  &-- &468    &242 &\textbf{185}\\
    & z850     & \underline{134} &150 &168    &159 & \textbf{112} &\underline{153}  &-- &236    &158 &\textbf{107} \\
     & t500    &\underline{1.090}  &1.357 &1.490    &1.321 &\textbf{1.076}  &\underline{1.199}&--  &2.278 &1.364    &\textbf{1.008} \\
     & t850   &\underline{1.403}  &1.488 &1.762    &1.902 &\textbf{1.310}  &\underline{1.564}  &-- &2.332    &2.002 &\textbf{1.290} \\
    &  t2m  &--  &\underline{1.363} & --   &2.044 &\textbf{1.308}  &--  &-- &--    & \underline{2.156}&\textbf{1.264} \\

    &  u10  &\underline{1.789} &-- &1.953  &2.119 &\textbf{1.459} &\underline{1.986}  &-- &2.295  &2.165 &\textbf{1.467}\\

    & v10  &\underline{1.399} &-- &1.494  &1.713 &\textbf{1.165} &\underline{1.503}  &-- &1.679  &1.779 &\textbf{1.177} \\
    \midrule
    \multirow{7}{*}{\rotatebox{90}{\textbf{Mid-Lat.}}}& z500    &\underline{799}  &809 & 842   &837 &\textbf{632}  &\underline{852}  &-- &936    &860 &\textbf{633} \\
    & z850     & 521 &539 & 541   &\underline{506} &\textbf{404}  &552  &-- & 584   &\underline{511} &\textbf{406} \\
     & t500   &\underline{2.591}  &2.630 & 2.749   &2.832 &\textbf{2.082}  &\underline{2.819}  &-- &3.226    &2.932 &\textbf{2.072} \\
     & t850    &\underline{2.750}  &2.787 &2.984    &3.093 &\textbf{2.217}  &\underline{2.950}  &-- &3.349    &3.249 &\textbf{2.260} \\
    &  t2m  & -- &\underline{2.212} &--    &3.276 &\textbf{2.031}  &--  &-- &--    &\underline{3.496}&\textbf{2.071} \\

    &  u10  &2.895 &-- &2.967  &\underline{2.481} &\textbf{2.154} &3.004  &-- &3.122  &\underline{2.474}&\textbf{2.150} \\

    &  v10  & 2.327&-- &2.422  & \underline{2.015} & \textbf{1.829}&2.388  &-- &2.492  &\underline{2.014} &\textbf{1.824} \\
    \midrule
    \multirow{7}{*}{\rotatebox{90}{\textbf{High-Lat.}}}& z500    &1804  &1019 &1238    &\underline{861} &\textbf{756}  &1856  &-- &1299    &\underline{880} &\textbf{743} \\
    & z850     &1050  &689 &715    &\underline{566} &\textbf{514}  &1074  &-- &772    &\underline{569} &\textbf{498} \\
     & t500   &5.249  &3.297 &4.667    &\underline{2.833} &\textbf{2.414}  &5.465  &-- &4.857    &\underline{2.879 }&\textbf{2.497 }\\
     & t850    &7.927  &3.832 &6.265    &\underline{3.560} &\textbf{2.833}  &8.244  &-- &6.459    &\underline{3.678} &\textbf{2.955} \\
    &  t2m  &-- &\underline{4.153} &--    &4.874 &\textbf{3.601}  &--  &-- &--    &\underline{5.086} & \textbf{3.674} \\

    &  u10  &\underline{2.559}&-- &2.567 &2.641 &\textbf{1.918} &2.414 &-- & 2.453 &\underline{2.377} &\textbf{1.765} \\

    & v10  &\underline{2.625} &-- &2.661  &2.657 &\textbf{1.927} &2.457  &-- &2.493  &\underline{2.392} &\textbf{1.755} \\
  
    \bottomrule
    \end{tabular}
    }
\end{table}

\subsection{Ablation Study}
To validate the effect of each model design on the overall model performance, we compare CirT with several invariants based on whether they use grid or circular patching as well as Fourier transform. The results are shown in Table~\ref{table:abl}, where we can observe that:
\begin{itemize}
    \item Fourier transform is a strong inductive bias and directly applying it does not always enhance model performance. From the table, we can observe that employing FT for grid patches increases the z850 and t2m errors in Weeks 3-4 as well as z850, t850, and t2m errors in Weeks 5-6, indicating the necessity of designing suitable patching approaches.
    \item Employing the circular patching strategy improves model performance, especially when the model uses the FT. For example, when no FT, employing circular patching reduces z500 Weeks 3-4/5-6 RMSE from 516/501 to 502/498. In contrast, in the case of the FT, employing circular patching significantly reduces z500 Weeks 3-4/5-6 RMSE from 497/494 to 477/471. Such results not only suggest the effectiveness of our model designs but also validate the effectiveness of utilizing the FT to extract the spatial periodic signal from circular patches.
\end{itemize}

\subsection{Empirical Analysis}

\paragraph{Latitudinal forecasting}
To investigate the model performance w.r.t. the latitude, we compare their results at low-latitude (0$^{\circ}$-30$^{\circ}$), mid-latitude (30$^{\circ}$-60$^{\circ}$), and high-latitude (60$^{\circ}$-90$^{\circ}$) areas. The results are displayed in Table~\ref{table:lat}. From them, we can discover that CirT generally outperforms baselines in all areas. Moreover, CirT achieves larger relative improvement in mid-latitude and high-latitude areas. For example, in the t500 Weeks 3-4 prediction, CirT has a 1.2\% relative improvement in low-latitude areas over the best baseline and 19.6\%/16.2\% in mid-/high-latitude areas. Such improvement can be attributed to the consideration of geometric inductive bias.


\begin{figure*}[t]
    \centering
    \includegraphics[width=0.98\textwidth]{globalone.pdf}
    \caption{The global RMSE distribution of t850 with lead times weeks 3-4 in testing set: CirT demonstrates significant performance across different areas. }
    \label{fig:position}
\end{figure*}

\paragraph{Global visualization}
To provide a global view of model predictions, we visualize the Weeks 3-4 RMSE distribution in Figure~\ref{fig:position}. More visualizations such as Weeks 5-6 predictions and different variables can be found in the Appendix. As shown in the figure, all models achieve the best results in the equatorial region. Higher RMSE values are primarily concentrated in south polar areas and the continents of the Northern Hemisphere, especially in North America and the Bering Strait. Among these methods, CirT demonstrates significantly lower errors, even in the above areas,
further validating our framework of incorporating geometric information.


\begin{figure*}[t]
    \centering
    \hspace{-5ex}
    \includegraphics[width=1\textwidth]{line.pdf}
    \caption{The monthly RMSE of t500 in testing set: CirT outperforms baselines across all months. }
    \label{fig:month}
    \vspace{-2ex}
\end{figure*}

\paragraph{Performance w.r.t. month}
We further compare the model performance over different months, which is shown in Figure~\ref{fig:month}. The results of other variables can be found in the Appendix. CirT has superior predictive capabilities in forecasting at all times, outperforming all competing methods at all months. In particular, it has the largest improvement in June for both Weeks 3-4 and 5-6 predictions.



\section{Related Work}

The advances in numerical weather prediction have dominated weather and climate modeling over the last century. They model the complex Earth dynamics as coupled physical systems such as earth system models (ESM)~\citep{hurrell2013community}, integrating the simulations of the atmosphere, cryosphere, land, and ocean processes. With the development of machine learning models~\citep{DBLP:journals/corr/abs-1912-12180,guibas2021efficient} and the accessibility of high-quality weather data, various data-driven models have been proposed to mitigate the weaknesses of NWP such as high computational demands and sensitivity to initial conditions. Early studies target regional forecasting on specific variables, such as precipitation nowcasting in Hong Kong~\citep{shi2015convolutional}, wind prediction in Stuttgart~\citep{harbola2019one}, and air temperature prediction in Australia~\citep{salcedo2016monthly}. A notable progress is the publication of the ECMWF reanalysis v5 (ERA5) dataset~\citep{hersbach2020era5}, which combines historical observations with results from a high-fidelity integrated Forecasting System (IFS)~\citep{wedi2015modelling}. Based on such a dataset, pioneer works~\citep{scher2018toward,weyn2019can,weyn2020improving,rasp2020weatherbench,rasp2021data} study the global forecasting of specific variables such as 500 hPa Geopotential and 300 hPa zonal wind, but at relatively coarser resolutions~\citep{verma2024climode}.

Recently, the development of foundation models has significantly advanced data-driven weather and climate forecasting. They are trained on large-scale high-resolution global data and target various weather variables. FourCastNet~\citep{pathak2022fourcastnet} and a follow-up work SFNO~\citep{bonev2023spherical} are built on the framework of the Fourier Neural Operator~\citep{li2020fourier,guibas2021efficient}. Graph-based models~\citep{lam2022graphcast,keisler2022forecasting} such as GraphCast~\citep{keisler2022forecasting} first create a mesh grid on the spherical surface and perform message passing~\citep{DBLP:conf/iclr/LiuCZXZT0R24,DBLP:conf/kdd/ZhengLL0R24,DBLP:journals/tkde/LiuCHPZT22} on it. Besides these studies, a series of works are based on Transformer~\citep{vaswani2017attention,dosovitskiy2020image}. Pangu-Weather~\citep{bi2023accurate} leverages sliding window attention to model spatial relations. Based on a similar backbone, Fuxi~\citep{chen2023fuxi} and FengWu~\citep{chen2023fengwu} improve training strategies to reduce accumulation errors and incorporate multi-model/task perspectives respectively. Climax~\citep{nguyen2023climax} demonstrates its ability for various weather and climate tasks and CaFA~\citep{li2024cafa} considers the spherical geometry. 

Despite the progress of current foundation models, S2S forecasting receives less attention due to its difficulty. \citeauthor{hwang2019improving}~\citep{hwang2019improving} and \citeauthor{he2022learning}~\citep{he2022learning} study regional S2S forecasting via traditional machine learning models such as AutoKNN and XGBoost~\citep{chen2016xgboost}. \citeauthor{weyn2021sub}~\citep{weyn2021sub} designs an ensemble system based on convolution neural networks to predict six atmospheric variables. It's only been recently that Climax~\citep{nguyen2023climax} and Fuxi-S2S~\citep{chen2024machine} have been developed to try to tackle these issues based on pre-trained foundation models. Therefore, how to build an effective data-driven S2S forecasting model is still an open problem. In this work, we propose CirT and study the performance of the direct prediction model and show that it outperforms current iterative models. Moreover, existing S2S models generally treat global data as planar which introduces geometric inconsistency while we leverage spherical inductive bias in model designs to alleviate such problems. 

Although both GraphCast~\citep{lam2022graphcast} and CirT leverage geometric inductive biases, GraphCast focuses on local state aggregation and relies on message passing~\citep{DBLP:conf/aaai/LiuRGCXTL23} to aggregate local information without explicitly accounting for spatial periodicity. In contrast, CirT employs circular patching to normalize patch geometry and leverages its Fourier representation, consisting of coefficients of periodic basis functions, as inputs to the transformer encoders. Compared with FourcastNet~\citep{pathak2022fourcastnet} which aims to design an efficient token mixer for Vision Transformers that can effectively handle high-resolution inputs, CirT performs multi-head attention in the frequency domain to model the interactions among weather patches across various latitudes. Moreover, FourcastNet employs regular grid patching while CirT introduces circular patching to standardize patch geometry.
Pangu Weather also designs an earth-specific positional bias to integrate spherical information, encoding relative coordinates with learnable parameters into the attention weight computation. Nevertheless, they still employ cube patching and implicitly learn the geometric bias from data, while CirT explicitly leverages spherical bias in the patching strategy.


\section{Conclusion and Future Work}
In this work, we highlight the geometric inductive bias in Transformer designs for S2S forecasting and introduce CirT, consisting of a circular patching strategy and latitudinal spatial periodicity modeling. It learns to mix patch embeddings in frequency domains and inverse transform to the spatial domain. Finally, it is trained to predict the future states in the S2S timescale. Extensive experiments on the ERA5 dataset demonstrate that CirT not only outperforms advanced data-driven models but also skillful numerical methods. Ablation studies have further substantiated the effectiveness of model designs and additional empirical analysis illustrates the superior performance in spatial and time dimensions. In the future, we are interested in incorporating slowly evolving earth system components including ocean, land, and sea ice in the proposed framework. In addition, CirT is a 2D transformer that encodes the inputs of different pressure levels into a single embedding. Nevertheless,  failure to incorporate the vertical inductive biases may result in incomplete cross-pressure level interaction. We plan to generalize the 2D CirT to the 3D transformer to incorporate such inductive biases.

\subsubsection*{Acknowledgments}
This work is funded by National Natural Science Foundation of China Grant No. 72371217, the Guangzhou Industrial Informatic and Intelligence Key Laboratory No. 2024A03J0628, the Nansha Key Area Science and Technology Project No. 2023ZD003, and Project No. 2021JC02X191.


\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\newpage

\appendix
\section{Appendix}
\subsection{Additional Experimental Details}
\subsubsection{Baseline}
\begin{itemize}
    \item \textbf{UKMO} The UK Meteorological Office uses the Global Seasonal forecast system version 6 (GloSea6) model to generate daily control forecasts for 60-day lead time.
    \item \textbf{NCEP} The National Centers for Environmental Prediction uses the Climate Forecast System 2 (CFSv2) model to generate daily control forecasts for 45-day lead time.
    \item \textbf{CMA} The China Meteorological Administration uses the Beijing Climate Center (BCC) fully-coupled BCC-CSM2-HR model to generate control forecasts each Monday and Thursday for 60-day lead time. 
   \item \textbf{ECMWF} The European Centre for Medium-Range Weather Forecasts uses the operational Integrated Forecasting System (IFS) to generate control forecasts each Monday and Thursday for 46-day lead time. We use the CY48R1 version to forcast.
    \item \textbf{FourCastNetV2}  Iterative data-driven model built upon Vision Transformer. FourCastNetV2 patches all the variables and uses the Adaptive Fourier Neural Operator to mix the spatial patches. We use the API \url{https://github.com/ecmwf-lab/ai-models} to perform inference. Due to the data loss in October 2018, we utilized the available data from the remaining 11 months.
    \item \textbf{GraphCast} Iterative data-driven model built upon Graph Neural Network. It use multi-mesh method to construct the graph to learn the complex dynamics. We use the API \url{https://github.com/ecmwf-lab/ai-models} to perform inference. The GPU's memory only allows us to perform inference on data spanning a maximum of 4 weeks. Therefore, we only present the results for weeks 3-4.
    \item \textbf{PanguWeather} Iterative data-driven model built upon Vision Transformer. We use the API \url{https://github.com/ecmwf-lab/ai-models} to perform inference. PanguWeather patches the pressure level and single-level data separately and merge them in the transformer. Using hierarchical temporal aggregation method to train the mdoel.
    \item \textbf{ClimaX} Direct training data-driven model built upon Vision Transformer. Each variable is independently tokenized and aggregated by variable aggregation.
\end{itemize}

\subsubsection{Dataset}
For all data-driven models, we utilize the same approach to transform $0.25^{\circ}\times 0.25^{\circ}$ grid to $1.5^{\circ}\times 1.5^{\circ}$ grid, including obtaining the prediction of FourCastNetV2, Graphcast, and PanguWeather as well as the training grid data of CirT. Specifically, we first obtain the results of $0.25^{\circ}\times 0.25^{\circ}$ models (e.g., PanguWeather), which are represented on a $721 \times 1440$ grid. This grid corresponds to the coordinates $(\lambda, \phi)$ within the domain $\Omega = [-90^{\circ}, -89.75^{\circ}, \ldots, 89.75^{\circ}, 90^{\circ}] \times [-180^{\circ}, -179.75^{\circ}, \ldots, 179.75^{\circ}, 180^{\circ}]$, where $\lambda$ denotes longitude and $\phi$ denotes latitude. Subsequently, we retrieve the results of coordinates $(\lambda, \phi)$ that correspond to the $1.5^{\circ}\times 1.5^{\circ}$ grid, which is represented on a $121 \times 240$ grid within the domain $\Omega = [-90^{\circ}, -88.5^{\circ}, \ldots, 88.5^{\circ}, 90^{\circ}] \times [-180^{\circ}, -178.5^{\circ}, \ldots, 178.5^{\circ}, 180^{\circ}]$.


\subsection{Additional Results}

\paragraph{Acc results} 
ACC comparison between CirT and numerical models at all pressure levels are shown in Figure~\ref{fig:heatmap_acc} and ACC comparison w.r.t. latitudes are displayed in Table~\ref{table:lat_acc}.

\paragraph{Regional forecasting} 
We additionally evaluate models in regional forecasting, constrained to the bounding boxes of North America and Europe. The results are shown in Table~\ref{table:region}. We can observe that CirT outperforms baselines in all cases.

\paragraph{Additional visualization}
The global visualization of t850 Weeks 5-6 predictions and other variables including t500, z500, and z850 are shown in Figure 7-13.

\paragraph{Additional results w.r.t month}
Additional results of variables t850, z500, and z850 are shown in Figure 14-16.

\paragraph{Comparison of model computation complexity/size} 
 We compare CirT's Floating point operations (FLOPs) and parameters with two representative models, Graphcast and PanguWeather. The results are shown in Table~\ref{table:size}. We can observe that CirT achieves better S2S predictivity with less computation and smaller model size, verifying our model designs.


\paragraph{Comparison of autoregressive and direct prediction} 
 We adapted CirT's output head to forecast next-day weather variables based on the input date for autoregressive prediction. For inference, it iteratively predicts next-day weather variables up to the S2S timescale. The results are shown in Table~\ref{table:auto}. From the results, we can observe that the direct method performs better. The autoregressive CirT still accumulates errors, resulting in inaccurate S2S predictions.

\paragraph{Additional results on fine-tuning CirT.} 
 We further evaluate the performance of fine-tuning the trained autoregressive CirT. We freeze the transformer encoder and replace the embedding layers and output head with newly initialized networks to forecast weather variables for Weeks 3-4 and 5-6. The results are in Table~\ref{table:fine}. From the result, we can observe that direct training still performs best in most cases. Meanwhile, we find that fine-tuned embedding layer and decoder improve the performance in several variables such as $t850$.

\paragraph{Multi-scale structural similarity} 
Following the previous work~\citep{nathaniel2024chaosbench}, we also compare the Multi-Scale Structural Similarity~\citep{wang2003multiscale} of the data-driven models. The result are shown in Table~\ref{table:ssim}. CirT achieves the best performance. GraphCast is the best baseline for Weeks 3-4 predictions. The reason can be attributed to that it employs mesh to model the sphere geometry, consistent with the observations in Table~\ref{table:overall}.



\begin{table}[t]
\setlength{\tabcolsep}{5mm}
\centering 
\caption{
Computation complexity and model size comparison.
}
\label{table:size}
{
\resizebox{0.5\textwidth}{!}{
\begin{tabular}{cccc}
\toprule
\textbf{Model}  & \textbf{GraphCast} & \textbf{PanguWeather} & \textbf{CirT}\\
\midrule
\textbf{FLOPs} & 110 T  & 168 T   & 2.2 G \\ 
\textbf{Params} & 37M  &256M  &16M \\ 
\bottomrule
\end{tabular}
}}
\end{table}

\begin{table}[t]
    \setlength{\tabcolsep}{1mm}
    \centering 
    \caption{
   Ablation study of autoregressive prediction vs directly predicting all the future values.}
    \label{table:auto}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{ccccccccc|ccccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Model}}  & \multicolumn{7}{c|}{\textbf{RMSE ($\downarrow$)}} &  \multicolumn{7}{c}{\textbf{ACC ($\uparrow$)}} \\
     &  & z500  & z850  & t500  & t850  & t2m  &u10 &v10 & z500 & z850  & t500  & t850  & t2m &u10 & v10\\
    \midrule
    \multirow{2}{*}{\rotatebox{90}{\textbf{3-4}}} & Autoregressive &781  &453 &3.406 &4.014 &4.584 &2.806 &2.267 &0.962 &0.922 &0.956 &0.957&0.968 &0.763 &0.610\\

    & Direct  &\textbf{477}  &\textbf{304} &\textbf{1.687} &\textbf{1.903} &\textbf{2.007} &\textbf{1.806} &\textbf{1.511} &\textbf{0.984} &\textbf{0.963} &\textbf{0.988} &\textbf{0.988} &\textbf{0.993} &\textbf{0.896} &\textbf{0.811}\\
    \midrule
    \multirow{2}{*}{\rotatebox{90}{\textbf{5-6}}} & Autoregressive &813  &455 &3.636 &4.357 &5.047 &2.855 &2.324 &0.960 &0.923 &0.950 &0.949&0.960 &0.758 &0.599\\
    & Direct &\textbf{471} &\textbf{301} &\textbf{1.672} &\textbf{1.933}&\textbf{2.026} &\textbf{1.809} &\textbf{1.512} &\textbf{0.985} &\textbf{0.964} &\textbf{0.988} &\textbf{0.989}&\textbf{0.993} &\textbf{0.895} &\textbf{0.812}\\
    \bottomrule
    \end{tabular}
     }
\end{table}

\begin{table}[t]
    \setlength{\tabcolsep}{2mm}
    \centering 
    \caption{
   Ablation study of fine-tuning CirT model.}
    \label{table:fine}
    \resizebox{0.9\textwidth}{!}{
    \begin{tabular}{ccccccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Model}}  & \multicolumn{7}{c}{\textbf{RMSE ($\downarrow$)}}  \\
     &  & z500  & z850  & t500  & t850  & t2m  &u10 &v10 \\
    \midrule
    \multirow{3}{*}{\rotatebox{90}{\textbf{3-4}}} 
    & Fine-tuning embedding and decoder &480&315&\textbf{1.660}&\textbf{1.870}&\textbf{1.983}&1.842&1.530\\
    & Fine-tuning Decoder &540&346&1.885&2.327&2.715&2.013&1.619\\

    & Direct Training  &\textbf{477}  &\textbf{304} &1.687 &1.903 &2.007 &\textbf{1.806} &\textbf{1.511} \\
    \midrule
    \multirow{3}{*}{\rotatebox{90}{\textbf{5-6}}}     
    & Fine-tuning embedding and decoder&485&312&1.679&\textbf{1.923}&2.032&1.847&1.535 \\
    & Fine-tuning Decoder &588&354&2.190&2.702&3.145&2.043&1.650\\
    & Direct Training &\textbf{471} &\textbf{301} &\textbf{1.672} &1.933&\textbf{2.026} &\textbf{1.809} &\textbf{1.512} \\
    \bottomrule
    \end{tabular}
    }
\end{table}


\begin{table}[t]
    \setlength{\tabcolsep}{0.6mm}
    \centering 
    \caption{
    RMSE comparison w.r.t. regions. CirT generally achieves the best performance and has a higher relative improvement in mid-/high-latitude areas. N-America is short for North America}
    \label{table:region}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{ccccccc|ccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Variable}}  & \multicolumn{5}{c|}{\textbf{Weeks 3-4}} &  \multicolumn{5}{c}{\textbf{Week 5-6}} \\
    & & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  \\
    \midrule
   \multirow{5}{*}{\rotatebox{90}{\textbf{N-America}}}& z500    &1017  &1014&996   &\underline{879} &\textbf{801} &1037  &-- &1063    &\underline{916} &\textbf{774}\\
    & z850      &709  &714&690   &\underline{606} &\textbf{552} &715  &-- &744    &\underline{634} &\textbf{538} \\
     & t500     &2.770  &2.704&2.793   &\underline{2.392} &\textbf{2.128} &2.858  &-- &3.221    &\underline{2.431} &\textbf{2.136} \\
     & t850    &3.012  &2.962&3.041   &\underline{2.802} &\textbf{2.333} &3.110  &-- &3.454    &\underline{2.826} &\textbf{2.347} \\
    &  t2m   &--  &\underline{3.184}&--   &3.618 &\textbf{2.556} &--  &-- &--    &\underline{3.669} &\textbf{2.617} \\
    \midrule
    \multirow{5}{*}{\rotatebox{90}{\textbf{Europe}}}& z500    &892  &905&909   &\underline{855} &\textbf{651} &953  &-- &995    &\underline{854} &\textbf{640}\\
    & z850      &606  &617&620   &\underline{551} &\textbf{427} &636  &-- & 675   &\underline{555} &\textbf{415} \\
     & t500    &2.862  &2.828&2.869   &\underline{2.573} &\textbf{2.111} &3.094  &-- &3.282    &\underline{2.516} &\textbf{2.163}\\
     & t850     & 2.848 &2.910&3.035   &\underline{2.827} &\textbf{2.083} &3.078  &-- & 3.382   &\underline{2.828} &\textbf{2.139} \\
    &  t2m   &  --&\underline{2.972}&--   &3.561 &\textbf{2.334} &--  &-- &--    &\underline{3.619} &\textbf{2.396}\\
  
    \bottomrule
    \end{tabular}
    }
\end{table}

\begin{table}[t]
    \setlength{\tabcolsep}{1mm}
    \centering 
    \caption{
    Multi-scale structural similarity of data-driven models.}
    \label{table:ssim}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{cccccc|ccccc}
    \toprule
    \multirow{2}{*}{\textbf{Variable}}  & \multicolumn{5}{c|}{\textbf{Week 3-4}} &  \multicolumn{5}{c}{\textbf{Week 5-6}} \\
     & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT \\
    \midrule
    z500   &0.814  &\underline{0.872}  &0.865      &0.862   &\textbf{0.909} &0.808  &--  & 0.846    &\underline{0.854}  &\textbf{0.909}\\
     z850   &0.799  &\underline{0.811}  & 0.802     &0.794   &\textbf{0.874} & 0.786 &--  &0.772      &\underline{0.789}   & \textbf{0.874} \\
    t500   &0.866  & \underline{0.889} &0.882     &0.875   &\textbf{0.925} &0.857  &--  & 0.860     &\underline{0.869} &\textbf{0.924}\\
     t850  &0.882   &\underline{0.919}  &0.913      &0.893   &\textbf{0.942} &0.876  &--  &\underline{0.901}    &0.885   &\textbf{0.942} \\
    t2m &-- &\underline{0.966} &--      &0.928   &\textbf{0.969} &--  &--  & --   &\underline{0.921}   &\textbf{0.968} \\
    \bottomrule
    \end{tabular}
    }
\end{table}

\begin{figure*}[h]
    \centering
    \includegraphics[width=1\textwidth]{heatmap_acc.pdf}
    \caption{The ACC comparison between numerical models and CirT. }
    \label{fig:heatmap_acc}
\end{figure*}

\begin{table}[t]
    \setlength{\tabcolsep}{0.6mm}
    \centering 
    \caption{
    ACC comparison w.r.t. latitude. CirT generally achieves the best performance and has a higher relative improvement in mid-/high-latitude areas.}
    \label{table:lat_acc}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{ccccccc|ccccc}
    \toprule
    & \multirow{2}{*}{\textbf{Variable}}  & \multicolumn{5}{c|}{\textbf{Weeks 3-4}} &  \multicolumn{5}{c}{\textbf{Week 5-6}} \\
    & & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  & FourCastNetV2 & GraphCast & PanguWeather  & ClimaX & CirT  \\
    \midrule
   \multirow{5}{*}{\rotatebox{90}{\textbf{Low-Lat.}}}& z500    &\underline{0.998}&\underline{0.998}&\underline{0.998}&0.997 &\textbf{0.999}&0.998  &--&0.997   &0.997 &\textbf{0.999}\\
    & z850      &\underline{0.993}&0.991&0.990&0.991 &\textbf{0.995}&\underline{0.991}  &--&0.983   &\underline{0.991} &\textbf{0.996} \\
     & t500    &\underline{0.997}&0.996&0.996&0.995 &\textbf{0.998}&\underline{0.996}  &--& 0.994   &0.995 &\textbf{0.997}\\
     & t850     &\underline{0.995}&\underline{0.995}&\underline{0.995}&0.993&\textbf{0.997} &\underline{0.995}  &--&0.993  &0.992 &\textbf{0.996} \\
    &  t2m   &--&\underline{0.997}&--&0.994&\textbf{0.998} &--&--  &--   &\underline{0.994}&\textbf{0.998}\\
    \midrule
    \multirow{5}{*}{\rotatebox{90}{\textbf{Mid-Lat.}}}& z500    &\underline{0.932}&0.927&0.921&0.920 &\textbf{0.955}&\underline{0.923}  &--&0.902   &0.915 &\textbf{0.954}\\
    & z850      &\underline{0.888}&0.878&0.874&0.887 &\textbf{0.929}&0.876  &--&0.852   &\underline{0.886 }&\textbf{0.929} \\
     & t500    &\underline{0.943}&0.937&0.932&0.923 &\textbf{0.959}&\underline{0.932}  &--&0.907   &0.917 &\textbf{0.959}\\
     & t850     &\underline{0.951}&0.947&0.939&0.931 &\textbf{0.965}&\underline{0.942}  &--&0.922   &0.923 &\textbf{0.963} \\
    &  t2m   &--&\underline{0.976}&--&0.944 &\textbf{0.978}&--  &--&--   &\underline{0.936 }&\textbf{0.978}\\
    \midrule
    \multirow{5}{*}{\rotatebox{90}{\textbf{High-Lat.}}}& z500    &0.927&0.969&0.952&\underline{0.978} &\textbf{0.983}&0.923  &--&0.948   & \underline{0.977}&\textbf{0.984}\\
    & z850      &0.870&0.925&0.918&\underline{0.952 }&\textbf{0.961}&0.863  &--&0.904   &\underline{0.951 }&\textbf{0.963} \\
     & t500    &0.951&0.978&0.952&\underline{0.982} &\textbf{0.987}&0.948  &--&0.952   &\underline{0.981 }&\textbf{0.988}\\
     & t850     &0.942&0.982&0.946&\underline{0.983 }&\textbf{0.989}&0.938  &--&0.944   &\underline{0.982 }&\textbf{0.989} \\
    &  t2m   &--&\underline{0.990}&--&0.986 &\textbf{0.992}&--  &--&--   &\underline{0.984 }&\textbf{0.992}\\
    \bottomrule
    \end{tabular}
    }
\end{table}





\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_tem_850_56.pdf}
    \caption{The global RMSE maps of t850 with lead times weeks 5-6 in 2018. }
    \vspace{-3ex}
    \label{fig:position_tem_850_56}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_tem_500_34.pdf}
    \caption{The global RMSE maps of t500 with lead times weeks 3-4 in 2018. }
    \vspace{-3ex}
    \label{fig:position_tem_500_34}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_tem_500_56.pdf}
    \caption{The global RMSE maps of t500 with lead times weeks 5-6 in 2018. }
    \vspace{-3ex}
    \label{fig:position_tem_500_56}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_geo_500_34.pdf}
    \caption{The global RMSE maps of z500 with lead times weeks 3-4 in 2018. }
    \vspace{-3ex}
    \label{fig:position_geo_500_34}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_geo_500_56.pdf}
    \caption{The global RMSE maps of z500 with lead times weeks 5-6 in 2018. }
    \vspace{-3ex}
    \label{fig:position_geo_500_56}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_geo_850_34.pdf}
    \caption{The global RMSE maps of z850 with lead times weeks 3-4 in 2018. }
    \vspace{-3ex}
    \label{fig:position_geo_850_34}


\end{figure*}
\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{globalone_geo_850_56.pdf}
C    \caption{The global RMSE maps of z850 with lead times weeks 5-6 in 2018. }
    \vspace{-3ex}
    \label{fig:position_geo_850_56}


\end{figure*}


\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{line_t850.pdf}
    \caption{The monthly RMSE of t850 in testing set: CirT outperforms other models across all months. }
    \label{fig:month_t850}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{line_z500.pdf}
    \caption{The monthly RMSE of z500 in testing set: CirT outperforms other models across all months. }
    \label{fig:month_z500}
\end{figure*}

\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{line_z850.pdf}
    \caption{The monthly RMSE of z850 in testing set: CirT outperforms other models across all months. }
    \label{fig:month_z850}
\end{figure*}



\end{document}


