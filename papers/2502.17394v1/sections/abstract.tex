\begin{abstract}

% V1
% Recently, Large Language Model (LLM) guided data generation has become one of the prominent techniques used in low-resource settings for various structured prediction tasks.
% However, several such works fail to consider the availability of unlabeled high-quality data in the data generation pipeline.
% In this work, we extensively analyze the utility of data generation in the pretext of available unannotated data on the task of Event Detection (ED) across three diverse domains of news, social media, and biomedical text.
% Due to lack of target domain distribution, raw data generation methods perform poorly and have a larger data distribution gap.
% To bridge this gap, we introduce a hybrid data generation approach \modelName{} which combines the extraction and generation paradigms while also utilizing the unlabeled data to reduce the data distribution gap.
% Under zero-shot settings, we show strong improvements of \modelName{} over other data generation baselines; however, a strong yet simple \extracttrain baseline performs the best.
% This highlights how noisy annotations on human data (\extracttrain) is better than clean annotations on generated data (data generation methods).
% Contrarily, as we increase the availability of few-shot examples, data generation methods show strong gains in performance and surpass the \extracttrain baselines.

% V2
% Large Language Model (LLM)-guided data generation has emerged as a key technique for structured prediction tasks in low-resource settings. 
% However, existing approaches often overlook the availability of unannotated data in the data generation pipeline, leading to suboptimal performance.
% In this work, we study data generation in the presence of unannotated data for the task of Event Detection (ED) across three diverse domains: news, social media, and biomedical text.
% We observe that naive raw data generation methods suffer from poor performance due to a significant distribution shift from the target domain. To mitigate this issue, we propose \modelName{}, a hybrid data generation framework that integrates extraction-based and generative approaches while leveraging unlabeled data to minimize distributional discrepancies.
% Under zero-shot settings, \modelName{} demonstrates substantial improvements over standard data generation baselines. However, a simple yet effective \extracttrain{} approach—leveraging noisy human-annotated data—outperforms all methods, suggesting that noisy human-labeled data is more informative than clean synthetic annotations.
% Interestingly, as the availability of few-shot examples increases, generative methods exhibit significant performance gains, surpassing \extracttrain{}.

% V3
% Large Language Model (LLM)-guided inverse data generation has emerged as a key technique for synthetic data creation in low-resource settings.
% In this work, we conduct an in-depth analysis of its effectiveness and limitations for structured prediction tasks like Event Detection (ED), evaluating using three diverse datasets across three LLMs under zero-shot and few-shot settings.
% We discover how prior approaches overlook unlabeled target-domain data, leading to a distributional gap between synthesized and test data.
% To address this, we introduce \modelName{}, which incorporates unlabeled data into the generation pipeline, reducing this gap and achieving downstream XX\% F1 gains over previous methods.
% However, our findings reveal a key limitation of inverse generation wherein a simpler reasoning-based weak supervision method outperforms \modelName{} by XX\% F1; thus, suggesting that noisy human-labeled data can be more informative than clean synthetic annotations for ED.
% Further analysis suggest a possible hypothesis that generation and reasoning capabilities in LLMs function independently, as they exhibit different trends with increasing model size and few-shot samples.
% Overall, our work establishes ED as a challenging benchmark for inverse data generation.

% V4
% Event Detection (ED) helps detect event mentions from natural language text.
% However, procuring supervised data for any new event to train models is infeasible, highlighting the need for low-resource ED.
% To this end, prior works have utilized synthetic data generation to train downstream ED models.
% Two major paradigms have been explored for data generation: forward generation (generating labels for unlabeled sentences) and inverse generation (generating sentences from sampled/generated labels).
% In this work, we extensively analyze these approaches across three ED datasets and reveal that inverse generation struggles to generate domain-specific synthetic data reflected by a distributional gap between their synthetic and real-world event data.
% To address this, we propose \modelName, a hybrid method that leverages forward generation on unlabeled data to extract domain cues and inverse generation to enhance data diversity. 
% Experiments reveal that \modelName{} outperforms the best baseline achieving average gains of 3.3\% F1 and 5.4\% F1 of ED performance in the zero-shot and few-shot settings respectively.
% We further show how fine-tuning on the unlabeled data and data-mixing with forward generation can yield further gains of XX\% and YY\% F1 respectively.
% Human evaluation of \modelName's generated data further strengthening its efficacy and better quality.
% <Some line from analysis>

% V5
Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains.
However, procuring supervised data for thousands of events for various domains is a laborious and expensive task.
To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations.
However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations.
To address these challenges, we introduce \modelName{}, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data.
\modelName{} further enhances its synthetic data by adding missing annotations through forward generation-based refinement.
Experimentation on three ED datasets from diverse domains reveals that \modelName{} outperforms the best baseline, achieving average gains of 3.3\% F1 and 5.4\% F1 in the zero-shot and few-shot settings, respectively.
Analyzing the generated trigger hit rate and human evaluation substantiates \modelName{}'s superior domain alignment and data quality compared to existing baselines.
We will release our code at \url{https://github.com/PlusLabNLP/FIG}.

\end{abstract}

% Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains. However, procuring supervised data for thousands of events for various domains is a laborious and expensive task. To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations. However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations. To address these challenges, we introduce FIG, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data. FIG further enhances its synthetic data by adding missing annotations through forward generation-based refinement. Experimentation on three ED datasets from diverse domains reveals that FIG outperforms the best baseline achieving average gains of 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively. Analyzing the generated trigger hit rate and human evaluation substantiates FIG's superior domain alignment and data quality compared to existing baselines.