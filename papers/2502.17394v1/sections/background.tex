\section{Problem Definition}

We focus on the task of Event Detection (ED) \cite{sundheim-1992-overview, doddington-etal-2004-automatic} for this work.
The task of ED aims to extract mentions of any events of interest from natural language text.
Following ACE 2005 \cite{doddington-etal-2004-automatic}, we define an \textit{event} as something that happens or describes a change of state and is labeled by a specific \textit{event type}.
The word/phrase that most distinctly highlights the occurrence of the event is defined as the \textit{event trigger}, and the trigger-event type pair is referred to as the \textit{event mention}.
\textit{Event Detection}, in particular, requires extracting the event \emph{triggers} from the sentence and classifying it into one of the pre-defined event types.
We provide an illustration of this task below where \textit{arrested} and \textit{campaigns} are the trigger words for the event types \textit{Justice: Arrest-Jail} and \textit{Conflict: Demonstrate} respectively.

% Wrapped sentence with inline trigger words
\begin{tcolorbox}[width=0.48\textwidth, colback=white, colframe=gray, boxrule=0.5pt,
                  left=2mm, right=2mm, top=2mm, bottom=7mm]
Some 3,000 people have been 
\tikz[baseline, remember picture] \node[anchor=base, inner sep=0pt, outer sep=0pt] (arrested) {\textbf{\textcolor{triggercolor2}{arrested}}}; 
since the disobedience 
\tikz[baseline, remember picture] \node[anchor=base, inner sep=0pt, outer sep=0pt] (campaigns) {\textbf{\textcolor{triggercolor1}{campaigns}}}; 
began last week.
\end{tcolorbox}

% Overlay arrows and event labels
\begin{tikzpicture}[remember picture, overlay]
  % Event labels
  \node[event1] (event1) at ($(arrested.north)+(0.0,-1.20)$) 
    {\textcolor{white}{Justice: Arrest-Jail}};
  \node[event2] (event2) at ($(campaigns.north)+(-1.75,-0.725)$) 
    {\textcolor{white}{Conflict: Demonstrate}};
  
  % Arrows from trigger words to the top of their event labels
  \draw[->, thick, gray] ([yshift=-2.0ex]arrested.north) -- (event1.north);
  \draw[->, thick, gray] ([yshift=-2.0ex]campaigns.north) -- ([xshift=-3.0ex]event2.north east);
\end{tikzpicture}

In our work, we specifically focus on ED in diverse and specialized domains (e.g., biomedical), where procuring a training dataset $D_T$ of annotated data points is expensive, whereas reasonable-sized unlabeled data $D_T'$ is available.
We focus on two realistic low-resource data setups - \textbf{zero-shot} (zero labeled data) and \textbf{few-shot} ($k$ labeled datapoints per event type) settings.
% In our work, we focus on the low-resource ED - specifically \textbf{zero-shot} (zero labeled data) and \textbf{few-shot} ($k$ labeled datapoints per event type) settings - 
% with access to unlabeled target domain data $D_T'$.
Different from domain transfer, we do not consider any labeled data for the source domain and directly optimize model performance for the target domain.

% Since supervised models are data-hungry, they do not perform well in such settings.
% Direct inference using LLMs \cite{huang-etal-2024-textee} has also proven to be subpar.
% Recent works \cite{josifoski-etal-2023-exploiting, star} have explored the utility of LLMs for synthetic data generation using inverse generation (i.e. generating text from structured events/triggers). Finally, downstream supervised models are trained on this synthetic data.
% However, these works strongly presume the lack of access to any unlabeled text, which in reality is not true.
% In our work, we study and develop better data generation techniques in pretext of access to unlabeled text for low-resource ED.
