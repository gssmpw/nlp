\section*{Acknowledgments}

We express our gratitude to Anh Mac, Po-Nien Kung, and Christina Chance for their valuable time, reviews of our work, and constructive feedback.

\section*{Limitations}

We consider only Event Detection (ED) as the main task for data generation, but our method can be extended to other structured prediction tasks as well.
We leave this exploration for future works.
We consider three specialized domains of news, social media, and biomedical to provide a proof-of-concept of our work.
There are other specialized domains for ED as well which can be explored as part of future work.
Finally, our proposed method \modelName{} makes a practical assumption of access to unlabeled data to procure target domain cues to guide the data generation.
However, for specific super-specialized domains or if data has privacy concerns, this may not be possible and our method may not be applicable here.
We assume such cases to be super rare and beyond the scope of our work.

\section*{Ethical Considerations}

The theme of our work is to generate high-quality domain-specific data using Large Language Models (LLMs) using forward-inverse generations.
The inherent LLMs can have certain biases, which can lead to potentially harmful or biased generations.
Furthermore, the LLM can introduce potential hallucinations in the annotations which can hurt the model performance.
We do not check or consider any bias/hallucination detection method as part of our work, as it is beyond the scope.
So future users should take due consideration of this vulnerability.

Our proposed method \modelName{} utilizes unlabeled data as a basis to procure domain-specific cues.
If there are any biases in this data, it can propogate to the downstream model as well.
We provide a proof-of-concept about our method in this work but do not detect or rectify such biases.

Since the inverse generation paradigm causes the LLM to generate sentences/passages, which can potentially be copied from the pre-training data the LLM has been trained on.
This can potentially lead to copyright infringements and we do not consider any of such violations under consideration for our method.
Users should consider this vulnerability before usage in commercial applications.

We would also like to mention and acknowledge that we have utilized AI chatbots to help with the writing of the work.
