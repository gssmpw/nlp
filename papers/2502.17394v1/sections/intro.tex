\section{Introduction}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/teaser-figure.pdf}
    \caption{Comparing different data generation paradigms. Owing to poor LLM ED reasoning skills, forward generation (top) struggles with noisy labels. Inverse generation (middle) suffers from domain drift owing to lack of domain-specific cues. We introduce \modelName{} (bottom), a hybrid forward and inverse approach, to overcome both issues to generate better quality data.}
    \label{fig:teaser-figure}
\end{figure}

% Inverse data generation ($Y \rightarrow X$) \cite{gao-etal-2021-making, DBLP:journals/corr/abs-2202-04538} constructs synthetic training data by first generating a target output ($Y$) and then synthesizing a corresponding input passage ($X$).
% The advent of Large Language Models (LLMs) has significantly enhanced its effectiveness in low-resource NLP, with frameworks like Self-Instruct \cite{wang-etal-2023-self-instruct} demonstrating its flexibility and impact.
% In this work, we study inverse data generation for structured prediction tasks like Event Detection (ED) that deals with extracting event information from natural language text.

% Compared to general-purpose instruction data generation, ED poses unique challenges as it requires domain-specific reasoning; in turn, requiring domain-specific rather than generic synthetic data.
% While previous works \cite{josifoski-etal-2023-exploiting, star} have applied inverse generation for ED, their evaluation is limited to general-domain datasets - resulting in inadequate assessment of their domain-specific effectiveness.
% Our evaluation on domain-specific datasets reveal how they struggle owing to a distributional gap between their synthetic data and the target test data, as illustrated in Figure~\ref{fig:teaser-figure}(a).
% A key factor for this distributional gap is lack of utilization of unlabeled target-domain data in the process of inverse data generation.

% In this work, we present a comprehensive analysis of inverse data generation for ED in the context of unlabeled target domain data, evaluating on three diverse domain datasets across three LLMs under zero-shot and few-shot settings.
% To aid better adaptation to the target domain, we introduce Extract-Generate (\modelName{}), a novel approach that integrates unlabeled target data into the inverse generation pipeline (Figure~\ref{fig:teaser-figure}(b)).
% Instead of generating event triggers from scratch, \modelName{} extracts candidate triggers from the unlabeled data, providing a crucial inductive bias.
% \modelName{} further minimizes the distribution gap by using an LLM fine-tuned on unlabeled target data for passage generation.
% In addition, we investigate and compare with LLM inference and weak supervision (Figure~\ref{fig:teaser-figure}(c)) as two strong non-inverse data generation baselines.

Event Detection (ED) \cite{sundheim-1992-overview, doddington-etal-2004-automatic} involves identifying and categorizing significant events from natural language text based on a pre-defined ontology. It has applications in widespread domains like biomedicine \cite{mlee}, epidemiology \cite{parekh-etal-2024-speed, parekh-etal-2024-event}, law \cite{DBLP:conf/lrec/2010legal}, etc.
However, procuring annotations for each domain-specific ontology to train models is expensive and impractical.
Although recent works introduce zero-shot LLM-reasoning \cite{DBLP:journals/corr/abs-2303-03836, cai-etal-2024-improving-event}, their performance falls short of supervised approaches \cite{huang-etal-2024-textee}.
% This underlines the need for low-resource ED empowering model training using zero (zero-shot) or few (few-shot) annotated datapoints.

To mitigate the need for extensive annotations to train supervised models, prior work has explored LLM-powered synthetic data generation to enhance downstream model training.
A widely used approach is a forward generation or weak supervision \cite{DBLP:journals/corr/abs-2106-06168, chia-etal-2022-relationprompt}, where labels are assigned to existing unlabeled data (i.e., $X\rightarrow Y'$). This generation is limited by LLM ED reasoning, often leading to noisy labels.
To address this, inverse generation has been proposed \cite{DBLP:journals/corr/abs-2202-04538, wang-etal-2023-self-instruct}, where sentences are generated based on sampled or generated labels (i.e $Y \rightarrow X'$).
However, inverse generation introduces a domain drift between synthetic and target data owing to the lack of any domain-specific cues, as illustrated in Figure~\ref{fig:teaser-figure}.

In our work, we propose \textbf{F}orward-\textbf{I}nverse \textbf{G}eneration (\modelName), a hybrid approach that integrates forward and inverse generation to enhance synthetic data quality.
Instead of generating event triggers from scratch — an inherently high-variance process — we first apply forward generation to unlabeled data, extracting domain-specific triggers.
Next, we utilize inverse generation to synthesize diverse sentences conditioned on the domain-specific triggers.
Finally, a second forward generation annotates any missing events in the generated data to ensure high data quality.
This approach produces cleaner synthetic data compared to forward generation while maintaining a closer domain alignment with target data than inverse generation, as shown in Figure~\ref{fig:teaser-figure}.

We evaluate \modelName{} on ED datasets from three different domains: ACE \cite{doddington-etal-2004-automatic} (news), SPEED \cite{parekh-etal-2024-event} (social media), and GENIA2011 \cite{kim-etal-2011-overview-genia} (biomedical).
Our primary method of evaluation is testing ED performance of DEGREE \cite{hsu-etal-2022-degree} trained on the generated data.
In the zero-shot setting, \modelName{} outperforms STAR \cite{star} (inverse generation baseline) and weak supervision (forward generation baseline) by an average of 16.8\% and 3.5\% Tri-C F1, respectively.
Similarly, in the few-shot setting, \modelName{} surpasses the strongest baseline by an average of 6.2\% Tri-C F1.
We study the generated trigger hit rate (relative to the gold trigger set) and demonstrate how \modelName's triggers have about 7.3\% better hit rate compared to the best baseline, which contributes to its superior performance.
Finally, we also conduct human evaluation, which supports \modelName's superior domain relevance and data annotation quality.

% In conclusion, we introduce \modelName{}, a novel hybrid approach that combines forward and inverse generation to produce high-quality synthetic data for domain-specific event detection.
% We extensively evaluate \modelName{} against three baselines across three diverse datasets using three base LLMs in both zero-shot and few-shot settings.
% Our experiments and analyses demonstrate \modelName{}'s superior domain alignment and data quality, resulting in the strongest ED downstream model performance.
% In conclusion, we make the following contributions:
% (1) Extensive evaluation and analysis of data generation methods for ED in the pretext of unlabeled data on ...
% (2) Introduce a domain-adapted inverse data generation method \modelName{} which ...
% (3) Highlight the challenge of inverse data generation for ED which requires domain-specific 

% We mainly want to explore three research questions in our work:
% 1) How do we adapt data generation methods to better adapt to target domain in the presence of external unlabeled data?
% 2) How do data generation methods compare with extraction-based methods for zero-shot settings?
% 3) How do the trends change in the few-shot setting? Why?
