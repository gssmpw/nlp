\section{Related Work}
\label{section:related_work}
% Due to the domain shift which leads to performance degradation, domain adaptation has been extensively researched. In the context of conventional domain adaptation, there is a source domain $\D_s = \{X_s, Y_s\}$ and a target domain $\D_t = \{X_t\}$, and they follow different distributions, \textit{i.e.}, $P(X_s) \neq P(X_t)$. This can be easily caused by different generation processes, such as using different devices under different environments. Generally, the source task is the same as the target task, thus, $Y_s$ and $Y_t$ are in the same label space $Y$. Semi-supervised domain adaptation**Ben-David et al., "A Theory of Learning from Different Domains"** assumes that there are a few labeled data in the target domain. On the other hand, unsupervised domain adaptation**Ben-David et al., "Unsupervised Domain Adaptation by Redistributing an Adversarial Example"** refers to the case in which the data in the target domain are completely unlabeled, which is more practical in real-world situation. Thus, we follow the same setting with unsupervised domain adaptation. In this section, we focus on recent unsupervised domain adaptation methods based on Convolutional Neural Networks (CNNs) due to its superior performance.
In this section, we focus on recent unsupervised domain adaptation methods based on Convolutional Neural Networks (CNNs) due to its superior performance.

Most domain adaptation methods mitigate the distribution discrepancy between domains according to**Ben-David et al., "Theory of Learning from Different Domains"**. The expected error on the target domain is bounded by: 1) the expected error on the source domain; 2) the domain discrepancy between the source and target domains; and 3) a shared expected loss which is expected to be small**Ben-David et al., "A Theory of Learning from Different Domains"**. The expected error on the source domain can be minimized by using labeled data in the source domain. Thus the core task becomes to minimize the discrepancy between domains. %Many works follow this direction and achieve remarkable progresses. 
Deep Domain Confusion (DDC)**Ghifary et al., "Deep Domain Confusion: A Novel Method for Adaptive Transfer Learning"** and Deep Adaptation Networks (DAN)**Long et al., "Learning Transferable Representations with Simultaneous Deep Adaptation Networks"** adopt maximum mean discrepancy**Fukumizu et al., "Hilbert Space Embeddings of Graphs"** on the final multiple layers to enforce the distribution similarity between source and target features. Joint Adaptation Networks (JAN)**Long et al., "Learning Transferable Representations with Simultaneous Deep Adaptation Networks"** uses the joint maximum mean discrepancy to align the joint distributions among multiple layers. Deep CORAL**Sun et al., "Deep CORAL: Decoupling Representation Learning from Domain Alignment"** use feature covariance to measure the domain discrepancy. Philip \textit{et al.},**Philip et al., "Domain Adaptation with Adversarial Training"**, enforce the associations of similar features within two domains. In addition to these methods of measuring distribution discrepancy, maximizing the domain confusion via adversarial training can be used to align distributions. Domain Adversarial Neural Network (DANN)**Ganin et al., "Domain-Adversarial Neural Networks"**, introduces a domain classifier and renders the extracted features from two domains indistinguishable by a gradient reversal layer**Ganin et al., "Domain-Adversarial Neural Networks"**. These adversarial training based methods show effective adaptation performances**Murella et al., "Learning with Limited Labeled Data"**. Pinheiro \textit{et al.}, include the adversarial loss and a similarity-based classifier**Saito et al., " Adversarial Multi-Task Learning for Domain Adaptation"**, to improve the model generalization. To integrate category information into the learning of domain-invariant features, Multi-Adversarial Domain Adaptation (MADA)**Sun et al., "Deep CORAL: Decoupling Representation Learning from Domain Alignment"** adopts multiple domain discriminators which correspond to each category. In**Saito et al., " Adversarial Multi-Task Learning for Domain Adaptation"**, instead of relying on a domain discriminator,  propose two task classifiers to align distributions by minimizing their discrepancy.**Murella et al., "Learning with Limited Labeled Data"**, adopts sliced Wasserstein metric to measure the dissimilarity of classifiers.

Inspired by GAN**Goodfellow et al., "Generative Adversarial Networks"**, recent works achieve feature distribution alignment based on a generative model. Sankaranarayanan \textit{et al.}, propose a GenerateToAdapt model**Sankaranarayanan et al., "Generate to Adapt: Aligning Domains using a Generative Adversarial Network"** which induces the extracted source or target embeddings to produce source-like images, such that the extracted features are expected to be domain-invariant. DuplexGAN**Liu et al., "Unsupervised Image-to-Image Translation Networks"**, uses two discriminators for two domains to ensure that the extracted features can generate images on both domains based on a domain code. Image-to-image translation**Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"**, provides a new direction for domain adaptation, which achieves the distribution alignment in the data space. In the absence of paired domain data, preserving the content will be non-trivial, and several recent works perform unsupervised image-to-image translation by including an extra constraint between input and the transformed output. SimGAN**Bousmalis et al., "Domain Adversarial Training of Neural Networks"**, employs a reconstruction loss between them, while PixelDA**Tsai et al., "Learning to Adapt Task-Specific Representations with Domain-Invariant Regularization"**, and DTN**Chen et al., "Deep Transfer Network: Towards Fast Adaptation"**, encourage the output to have the same class label and the semantic features as input, respectively. CoGAN**Yi et al., "DualGAN: Unsupervised Disentanglement via Adversarial Mutual Learning"**, and UNIT**Liu et al., "Unsupervised Image-to-Image Translation Networks"**, learn a feature space based on shared or non-shared strategies to perform cross-domain generation. Zhu \textit{et al.}, propose CycleGAN**Zhu et al., "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"** which involves bi-directional translations with a cycle-consistency loss, which enforces the condition that the translated image can be mapped back to input. DiscoGAN**Kim et al., "Learning to Discover Cross-Domain Relations with Generative Adversarial Networks"**, and DualGAN**Yi et al., "DualGAN: Unsupervised Disentanglement via Adversarial Mutual Learning"**, share the same idea and achieve promising unsupervised image translation performance. CyCADA**Chen et al., "CyCADA: Cycle-Consistent Adversarial Domain Adaptation"**, is based on CycleGAN and delivers good performance on multiple domain adaptation tasks.

Additionally, some works further explore using unlabeled target data to improve generalization by co-training**Saito et al., "Adversarial Multi-Task Learning for Domain Adaptation"**, pseudo-labeling**Chen et al., "Deep Transfer Network: Towards Fast Adaptation"**, and entropy regularization**Murella et al., "Learning with Limited Labeled Data"**. Some recent works focus on open set adaptation problems**Sankaranarayanan et al., "Adversarial Discriminative Domain Adaptation"**. However, these works require source data during adaptation. Thus, most previous works are not applicable to the proposed model adaptation problem. Some incremental learning works**Chen et al., "A Closer Look at Few-Shot Learning for Deep Learning Models"**, are relevant to us, but they need labeled target data for new tasks. In this paper, we propose to simply use the unlabeled target dataset to adapt the pre-trained model to the target domain.