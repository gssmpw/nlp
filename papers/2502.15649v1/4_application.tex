\section{Application in Surveillance}
\label{sec:application}

The trained RL agent was tested on the Boston Dynamics Spot robot in a surveillance task conducted inside one of Queen's University buildings. The robot was tasked with safely visiting multiple waypoints within the building using the navigation system shown in Fig.~\ref{fig:navigation_system}.

\subsection{Description of the Navigation System}
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth, trim=0.0cm 0cm 0.0cm 0.0cm, clip]{figures/nav_system_2.png}
    \caption{The navigation system used for the surveillance task.}
    \label{fig:navigation_system}
\end{figure}

The navigation system, illustrated in Fig.~\ref{fig:navigation_system} is comprised of the following sub-modules:

\begin{figure}
    \begin{subfigure}{1.0\linewidth}
    \centering
    \includegraphics[width=0.85\linewidth, trim=0.1cm 0.2cm 0.2cm 0.1cm, clip]{figures/mitchell_hall_successes_goal_0.pdf}
    \caption{}
    \label{fig:executed_path_a}
    \vspace{1em} 
    \end{subfigure}
    \begin{subfigure}{1.0\linewidth}
    \centering
    \includegraphics[width=1.0\linewidth]{figures/robot_mitchell_hall.pdf}
    \caption{}
    \label{fig:executed_path_b}
    \end{subfigure}
    \caption{(a) Executed trajectory (in red) using the trained RL agent on the test site map represented as an occupancy grid (white is free space, black is occupied, and grey is unknown) and (b) photo of the robot near the first waypoint.}
    \label{fig:executed_path}
\end{figure}

\subsubsection{Inputs}
The inputs of the navigation system include the task, represented as a sequence of waypoints $(\mathbf{w}_1,\mathbf{w}_2, \cdots, \mathbf{w}_N)$, the map of the building, obtained using SLAM with a resolution of $0.05$ m, and the robot sensors comprised of the internal odometry and distance measurements using a VLP-16 Velodyne LiDAR. 

\subsubsection{Localization}
The localization system consisted of the Adaptive Monte Carlo Localization (AMCL) library available for ROS that implements an adaptive particle filter to estimate the robot's pose.

\subsubsection{Planner}
The state lattice planner available in the Nav2 ROS library was used to generate the paths. This algorithm uses motion primitives based on the robot's kinematics to find a collision-free path between two configurations. This planner is capable of generating motion primitives for both car-like and omnidirectional robots. However, the omnidirectional version produced paths that required the robot to move sideways, which is the slowest direction, for the majority of the task execution. In contrast, the car-like version generated more suitable paths, wherein the robot faced forward for most of the task. A small steering radius of $0.1$ m was chosen to allow the robot to turn in place. The state lattice planner outputs paths with the same resolution as the map, $0.05$ m. To account for the RL agent tolerance of $0.3$ m, the path was under-sampled to contain $1$ m segments.

\subsubsection{Controller}
The RL agent controller, trained through the pipeline, followed the planned path by sequentially controlling the robot toward each point in the path. This was achieved by representing the path as a sequence of sub-goals. Once the robot reaches a sub-goal within the specified tolerances $\epsilon_p$ and $\epsilon_\theta$, the robot is sent to the next sub-goal in the path.

\subsection{Application to Surveillance}

Fig.~\ref{fig:executed_path} shows Spot's path during the surveillance task. The robot was positioned near the centre of the space, indicated by the green circle, with waypoints selected near the extremities of each side of the building, indicated as red circles.

During the execution, the robot's speeds ($a_x$, $a_y$, $a_{\theta}$) were limited to $1$~m$/$s. This limit was added as a security measure to keep the robot within the speed limits of the identified model. The total length of the path executed was 197~m, and the robot completed the task in $201$~s. This results in an average speed of $0.98$~m$/$s. A slightly lower average speed is expected since the robot has to change directions at each waypoint.

While the robot completed the task with the expected tolerances and speeds, some oscillations were observed in the path. These oscillations are particularly noticeable near the first and third waypoints. Although the exact causes are still unclear, they were not present in Fig.~\ref{fig:policy_results_c} experiment. Therefore, these oscillations probably appeared due to the integration of the RL agent and the navigation system. One possible reason for some of the oscillations is a sudden change in orientation in the planned path. Additionally, the RL agent may be overcompensating due to larger variations in the estimated pose than what it was trained to handle. Further experiments are needed to understand better these oscillations and how to mitigate them.