[
  {
    "index": 0,
    "papers": [
      {
        "key": "hou2024bridging",
        "author": "Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian",
        "title": "Bridging language and items for retrieval and recommendation"
      },
      {
        "key": "zhang2024text",
        "author": "Zhang, Yang and Bao, Keqin and Yan, Ming and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation"
      },
      {
        "key": "sheng2024language",
        "author": "Sheng, Leheng and Zhang, An and Zhang, Yi and Chen, Yuxin and Wang, Xiang and Chua, Tat-Seng",
        "title": "Language Representations Can be What Recommenders Need: Findings and Potentials"
      },
      {
        "key": "lee2024star",
        "author": "Lee, Dong-Ho and Kraft, Adam and Jin, Long and Mehta, Nikhil and Xu, Taibai and Hong, Lichan and Chi, Ed H and Yi, Xinyang",
        "title": "STAR: A Simple Training-free Approach for Recommendations using Large Language Models"
      },
      {
        "key": "yuan2023go",
        "author": "Yuan, Zheng and Yuan, Fajie and Song, Yu and Li, Youhua and Fu, Junchen and Yang, Fei and Pan, Yunzhu and Ni, Yongxin",
        "title": "Where to go next for recommender systems? id-vs. modality-based recommender models revisited"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "xi2024towards",
        "author": "Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong",
        "title": "Towards open-world recommendation with knowledge augmentation from large language models"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "liu2024llm",
        "author": "Liu, Qidong and Wu, Xian and Wang, Yejing and Zhang, Zijian and Tian, Feng and Zheng, Yefeng and Zhao, Xiangyu",
        "title": "Llm-esr: Large language models enhancement for long-tailed sequential recommendation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ren2024representation",
        "author": "Ren, Xubin and Wei, Wei and Xia, Lianghao and Su, Lixin and Cheng, Suqi and Wang, Junfeng and Yin, Dawei and Huang, Chao",
        "title": "Representation learning with large language models for recommendation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sun2024large",
        "author": "Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun",
        "title": "Large language models enhanced collaborative filtering"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "huang2022towards",
        "author": "Huang, Jie and Chang, Kevin Chen-Chuan",
        "title": "Towards reasoning in large language models: A survey"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "hou2024bridging",
        "author": "Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian",
        "title": "Bridging language and items for retrieval and recommendation"
      },
      {
        "key": "zhang2024text",
        "author": "Zhang, Yang and Bao, Keqin and Yan, Ming and Wang, Wenjie and Feng, Fuli and He, Xiangnan",
        "title": "Text-like Encoding of Collaborative Information in Large Language Models for Recommendation"
      },
      {
        "key": "sheng2024language",
        "author": "Sheng, Leheng and Zhang, An and Zhang, Yi and Chen, Yuxin and Wang, Xiang and Chua, Tat-Seng",
        "title": "Language Representations Can be What Recommenders Need: Findings and Potentials"
      },
      {
        "key": "lee2024star",
        "author": "Lee, Dong-Ho and Kraft, Adam and Jin, Long and Mehta, Nikhil and Xu, Taibai and Hong, Lichan and Chi, Ed H and Yi, Xinyang",
        "title": "STAR: A Simple Training-free Approach for Recommendations using Large Language Models"
      },
      {
        "key": "yuan2023go",
        "author": "Yuan, Zheng and Yuan, Fajie and Song, Yu and Li, Youhua and Fu, Junchen and Yang, Fei and Pan, Yunzhu and Ni, Yongxin",
        "title": "Where to go next for recommender systems? id-vs. modality-based recommender models revisited"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "xi2024towards",
        "author": "Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong",
        "title": "Towards open-world recommendation with knowledge augmentation from large language models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2024llm",
        "author": "Liu, Qidong and Wu, Xian and Wang, Yejing and Zhang, Zijian and Tian, Feng and Zheng, Yefeng and Zhao, Xiangyu",
        "title": "Llm-esr: Large language models enhancement for long-tailed sequential recommendation"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "ren2024representation",
        "author": "Ren, Xubin and Wei, Wei and Xia, Lianghao and Su, Lixin and Cheng, Suqi and Wang, Junfeng and Yin, Dawei and Huang, Chao",
        "title": "Representation learning with large language models for recommendation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "sun2024large",
        "author": "Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun",
        "title": "Large language models enhanced collaborative filtering"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "o1_blog",
        "author": "OpenAI",
        "title": "Learning to Reason with LLMs"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "snell2024Scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      },
      {
        "key": "zhang2024accessing",
        "author": "Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b"
      },
      {
        "key": "chen2024alphamath",
        "author": "Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai",
        "title": "AlphaMath Almost Zero: process Supervision without process"
      },
      {
        "key": "yang2024qwen2",
        "author": "Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others",
        "title": "Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement"
      },
      {
        "key": "shao2024deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ji2025test",
        "author": "Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min",
        "title": "Test-time Computing: from System-1 Thinking to System-2 Thinking"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "snell2024Scaling",
        "author": "Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral",
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "qi2024mutual",
        "author": "Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao",
        "title": "Mutual reasoning makes smaller llms stronger problem-solvers"
      },
      {
        "key": "zhang2024accessing",
        "author": "Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli",
        "title": "Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b"
      },
      {
        "key": "chen2024alphamath",
        "author": "Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai",
        "title": "AlphaMath Almost Zero: process Supervision without process"
      },
      {
        "key": "yang2024qwen2",
        "author": "Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others",
        "title": "Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement"
      },
      {
        "key": "shao2024deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "yue2024inference",
        "author": "Yue, Zhenrui and Zhuang, Honglei and Bai, Aijun and Hui, Kai and Jagerman, Rolf and Zeng, Hansi and Qin, Zhen and Wang, Dong and Wang, Xuanhui and Bendersky, Michael",
        "title": "Inference scaling for long-context retrieval augmented generation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "sun2025rearter",
        "author": "Sun, Zhongxiang and Wang, Qipeng and Yu, Weijie and Zang, Xiaoxue and Zheng, Kai and Xu, Jun and Zhang, Xiao and Yang, Song and Li, Han",
        "title": "ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding"
      }
    ]
  }
]