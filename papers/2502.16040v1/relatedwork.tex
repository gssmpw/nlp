\section{Related Work}
% \textbf{LLMs for Rec.} LLMs can be leveraged to enhance recommendation systems by providing contextual understanding and powerful reasoning. Recent studies utilizing LLMs for augmentation can be divided into two paths: one is using LLMs for text embedding. The arrtibutes of users, items can be combined and calculate the embedding~\citep{hou2024bridging, zhang2024text, sheng2024language, lee2024star, yuan2023go}. Another line is to utilize LLMs to generate additional information. For example, KAR~\citep{xi2024towards} requires LLMs to generate item descriptions and user reasoning preferences. LLM-ESR~\citep{liu2024llm} also summarizes user preferences. RLMRec~\citep{ren2024representation} describes user and item, also reason more collaborative information. LLM-CF~\citep{sun2024large} generate a CoT of user decision. However, previous works rely on fast thinking, and it often leads to incomplete coverage and insufficient concreteness~\citep{ji2025test}.

\textbf{LLMs for Rec.} LLMs can enhance recommendation systems by providing contextual understanding and reasoning abilities~\citep{huang2022towards}. Recent work on LLM-based augmentation in recommendation generally follows two main directions. The first approach leverages LLMs for text embedding, integrating user and item attributes into unified representations~\citep{hou2024bridging, zhang2024text, sheng2024language, lee2024star, yuan2023go}. The second approach focuses on generating additional information for recommendations. For instance, KAR~\citep{xi2024towards} instructs LLMs to produce item descriptions and user preference rationales, while LLM-ESR~\citep{liu2024llm} summarizes user preferences. RLMRec~\citep{ren2024representation} describes both user and item attributes, incorporating collaborative information, and LLM-CF~\citep{sun2024large} uses a chain-of-thought to represent user decisions. However, most of these methods rely on relatively fast inference, frequently resulting in incomplete coverage and insufficient specificity~\citep{ji2025test}.

% \textbf{Inference Computation Scaling.} Inference scaling is to allocate more computation resources into inference stages~\citep{o1_blog}, so that LLMs can reason based on more previous steps, shifting from System-1 fast thinking to System-2 slow thinking model~\citep{ji2025test}. ~\citealp{snell2024Scaling} first investigates the relationship between performance and inference time. Recent works~\citep{qi2024mutual, zhang2024accessing, chen2024alphamath, yang2024qwen2, shao2024deepseekmath} have shown promising results in math and coding problems, but none of them investigate whether this inference scaling techniques can indeed perform well in personalized tasks such as recommendations.
\textbf{Inference Computation Scaling.} Inference scaling involves allocating more computational resources to the inference stage, allowing LLMs to reason based on additional prior steps. This shift from System-1 (fast thinking) to System-2 (slow thinking) reasoning enhances their ability to process complex tasks~\citep{ji2025test}. The relationship between performance and inference time was first examined by~\citet{snell2024Scaling}, and recent studies~\citep{qi2024mutual, zhang2024accessing, chen2024alphamath, yang2024qwen2, shao2024deepseekmath} have demonstrated promising results in math and coding tasks. Moreover,~\citet{yue2024inference} investigates inference scaling for Retrieval Augmented Generation, and~\citet{sun2025rearter} employs test-time scaling to address challenges in complex multi-step reasoning.
However, none of these works have investigated whether inference scaling can help address the incomplete coverage problem in recommendation tasks, and we aim to explore how this technique can improve personalized recommendation systems through feature augmentation.