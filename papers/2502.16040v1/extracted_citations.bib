@article{chen2024alphamath,
  title={AlphaMath Almost Zero: process Supervision without process},
  author={Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai},
  journal={arXiv preprint arXiv:2405.03553},
  year={2024}
}

@article{hou2024bridging,
  title={Bridging language and items for retrieval and recommendation},
  author={Hou, Yupeng and Li, Jiacheng and He, Zhankui and Yan, An and Chen, Xiusi and McAuley, Julian},
  journal={arXiv preprint arXiv:2403.03952},
  year={2024}
}

@article{huang2022towards,
  title={Towards reasoning in large language models: A survey},
  author={Huang, Jie and Chang, Kevin Chen-Chuan},
  journal={arXiv preprint arXiv:2212.10403},
  year={2022}
}

@article{ji2025test,
  title={Test-time Computing: from System-1 Thinking to System-2 Thinking},
  author={Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min},
  journal={arXiv preprint arXiv:2501.02497},
  year={2025}
}

@article{lee2024star,
  title={STAR: A Simple Training-free Approach for Recommendations using Large Language Models},
  author={Lee, Dong-Ho and Kraft, Adam and Jin, Long and Mehta, Nikhil and Xu, Taibai and Hong, Lichan and Chi, Ed H and Yi, Xinyang},
  journal={arXiv preprint arXiv:2410.16458},
  year={2024}
}

@inproceedings{liu2024llm,
  title={Llm-esr: Large language models enhancement for long-tailed sequential recommendation},
  author={Liu, Qidong and Wu, Xian and Wang, Yejing and Zhang, Zijian and Tian, Feng and Zheng, Yefeng and Zhao, Xiangyu},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

@misc{o1_blog,
      title={Learning to Reason with LLMs}, 
      author={OpenAI},
      year={2024},
      url={https://openai.com/index/learning-to-reason-with-llms/},
}

@article{qi2024mutual,
  title={Mutual reasoning makes smaller llms stronger problem-solvers},
  author={Qi, Zhenting and Ma, Mingyuan and Xu, Jiahang and Zhang, Li Lyna and Yang, Fan and Yang, Mao},
  journal={arXiv preprint arXiv:2408.06195},
  year={2024}
}

@inproceedings{ren2024representation,
  title={Representation learning with large language models for recommendation},
  author={Ren, Xubin and Wei, Wei and Xia, Lianghao and Su, Lixin and Cheng, Suqi and Wang, Junfeng and Yin, Dawei and Huang, Chao},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={3464--3475},
  year={2024}
}

@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{sheng2024language,
  title={Language Representations Can be What Recommenders Need: Findings and Potentials},
  author={Sheng, Leheng and Zhang, An and Zhang, Yi and Chen, Yuxin and Wang, Xiang and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2407.05441},
  year={2024}
}

@article{snell2024Scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@inproceedings{sun2024large,
  title={Large language models enhanced collaborative filtering},
  author={Sun, Zhongxiang and Si, Zihua and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Zhang, Xiao and Xu, Jun},
  booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
  pages={2178--2188},
  year={2024}
}

@article{sun2025rearter,
  title={ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process Rewarding},
  author={Sun, Zhongxiang and Wang, Qipeng and Yu, Weijie and Zang, Xiaoxue and Zheng, Kai and Xu, Jun and Zhang, Xiao and Yang, Song and Li, Han},
  journal={arXiv preprint arXiv:2501.07861},
  year={2025}
}

@inproceedings{xi2024towards,
  title={Towards open-world recommendation with knowledge augmentation from large language models},
  author={Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong},
  booktitle={Proceedings of the 18th ACM Conference on Recommender Systems},
  pages={12--22},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5-math technical report: Toward mathematical expert model via self-improvement},
  author={Yang, An and Zhang, Beichen and Hui, Binyuan and Gao, Bofei and Yu, Bowen and Li, Chengpeng and Liu, Dayiheng and Tu, Jianhong and Zhou, Jingren and Lin, Junyang and others},
  journal={arXiv preprint arXiv:2409.12122},
  year={2024}
}

@inproceedings{yuan2023go,
  title={Where to go next for recommender systems? id-vs. modality-based recommender models revisited},
  author={Yuan, Zheng and Yuan, Fajie and Song, Yu and Li, Youhua and Fu, Junchen and Yang, Fei and Pan, Yunzhu and Ni, Yongxin},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2639--2649},
  year={2023}
}

@article{yue2024inference,
  title={Inference scaling for long-context retrieval augmented generation},
  author={Yue, Zhenrui and Zhuang, Honglei and Bai, Aijun and Hui, Kai and Jagerman, Rolf and Zeng, Hansi and Qin, Zhen and Wang, Dong and Wang, Xuanhui and Bendersky, Michael},
  journal={arXiv preprint arXiv:2410.04343},
  year={2024}
}

@article{zhang2024accessing,
  title={Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree self-refine with llama-3 8b},
  author={Zhang, Di and Huang, Xiaoshui and Zhou, Dongzhan and Li, Yuqiang and Ouyang, Wanli},
  journal={arXiv preprint arXiv:2406.07394},
  year={2024}
}

@article{zhang2024text,
  title={Text-like Encoding of Collaborative Information in Large Language Models for Recommendation},
  author={Zhang, Yang and Bao, Keqin and Yan, Ming and Wang, Wenjie and Feng, Fuli and He, Xiangnan},
  journal={arXiv preprint arXiv:2406.03210},
  year={2024}
}

