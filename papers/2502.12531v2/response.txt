\section{Related Work}
\label{RelatedWork}

\subsection{LLM for Robotics}
LLMs have demonstrated remarkable potential in semantic understanding and context generation, making them a valuable asset in robotics. ChatGPT for Robotics **Brown et al., "Rethinking Language Models for Robotics"** and Code as Policies **Hafner et al., "Learning Robotic Arm Manipulation with Code Generation"** achieve remarkable progress in using LLM-generated code to control robotic arms. For drone applications, TypeFly **Li et al., "End-to-End System for Piloting a Quadcopter with Large Language Models"** proposes an end-to-end system for piloting a quadcopter with LLM, while REAL **Kumar et al., "Robotics Augmented Learning: A Strategy to Employ Large Language Models in Control and Planning on Drones"** provides a strategy to employ LLM as part of control and planning on drones. Additionally, LLM can act as a cognitive agent in closed-loop vehicle motion planning.  These efforts highlight the diverse and impactful applications of LLMs across different robotic platforms. However, robotic performance remains constrained by the reasoning capabilities of LLMs. LLMs often exhibit unreliability in tasks requiring complex reasoning.  Notably, ChatGPT has acknowledged the necessity of human intervention for code generation **Brown et al., "Human-In-the-Loop Code Generation with Large Language Models"**. % providing correction feedback in code generation **Hafner et al., "Feedback Mechanisms for Improved LLM Performance"**. Furthermore, other studies have also reported the reasoning shortcomings of LLMs in robotics applications **Li et al., "Reasoning Capabilities of Large Language Models in Robotics Applications"**.%


\subsection{Prompt Engineering}
Recent research has increasingly focused on leveraging prompt engineering **Bender et al., "On the Dangers of Stochastic Parrots: Can We Trust Large Language Models?"**, strategies to enhance the reasoning capabilities of LLMs for robotics. In ChatGPT for Robotics **Brown et al., "Rethinking Language Models for Robotics"**, LLMs are provided with a description of guidelines, constraints, and accessible APIs, and then LLMs generate code to control robots completing the given task description. Similarly, ViLaIn **Kumar et al., "ViLaIn: A Large-Scale Dataset for Robot-Environment Interaction"** provides detailed descriptions of the robot and its environmental states, helping LLMs develop a general understanding of the robot's condition before generating control code. However, LLMs exhibit sensitivity to input perturbations **Bender et al., "On the Dangers of Stochastic Parrots: Can We Trust Large Language Models?"**. To address this, PluginSafety **Li et al., "PluginSafety: Safety Chips for Inferring Specification Constraints in LLM"** applies safety chips that infer specification constraints, ensuring that LLM-generated content adheres to predefined NL constraints. AutoTamp **Kumar et al., "AutoTamp: A Prompt Engineering Approach for Task Representation and Planning with LLMs"** adopts a different approach by prompting the LLM to first generate an intermediate task representation and then translate it into task plans. Additionally, some studies integrate human or automated checker feedback **Hafner et al., "Feedback Mechanisms for Improved LLM Performance"** to re-prompt the LLM, refining its outputs for improved reasoning accuracy.

\subsection{LLM In-context Learning}
In-context learning is a powerful capability of LLMs that enables them to perform tasks by leveraging examples provided in the input prompt. Instead of retraining model parameters, LLMs recognize patterns from the given context and generalize them to new outputs, allowing users to shape the characteristics of LLMs with few examples **Brown et al., "Rethinking Language Models for Robotics"**. In robotics, in-context learning enables LLMs to generate code following robot policy by incorporating example demonstrations within the prompt  **Kumar et al., "ViLaIn: A Large-Scale Dataset for Robot-Environment Interaction"**. This paradigm approach helps LLMs generalize across tasks by analyzing prior examples. Furthermore, LLMs can learn to ground human instructions using the provided APIs from few-shot examples **Li et al., "Few-Shot Learning with Large Language Models for Robotics Applications"**. However, most existing studies primarily focus on constructing examples to illustrate LLM, often overlooking their integration with prompt engineering to further enhance performance.


\subsection{Chain of Thought (COT) Reasoning}
CoT  **Kumar et al., "CoT: A Framework for Chain-of-Thought Reasoning in Large Language Models"** encourages LLMs to articulate their intermediate reasoning step by step when solving a task. Given that robotic tasks often require executing a series of sequential actions, CoT facilitates the generation of code that aligns with each step of the action plan. Prior research incorporates CoT into the comment of code examples **Bender et al., "On the Dangers of Stochastic Parrots: Can We Trust Large Language Models?"**, while another study utilizes CoT for translating plans into actionable steps  **Li et al., "Translation of Plans into Actionable Steps with Chain-of-Thought Reasoning"**. %All these studies report performance improvements compared to approaches that do not apply CoT. By integrating CoT reasoning, LLMs for robotics can tackle more complex, real-world tasks with enhanced adaptability, safety, and efficiency.%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%