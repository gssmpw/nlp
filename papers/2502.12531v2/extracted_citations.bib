@article{AdaptiveRAG,
  title={OPTIMISING UAV DYNAMICS: USER-CENTRIC LARGE LANGUAGE MODEL INTEGRATION FOR DYNAMIC ADAPTATION},
  author={Rui, Zeaus Koh Jin and Serene, Zhang Ning An and Perrie, Lim En-lye and Le, Lim Gang and Jeremy, Wong Rui Ming}
}

@INPROCEEDINGS{AutoTAMP,
  author={Chen, Yongchao and Arkin, Jacob and Dawson, Charles and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers}, 
  year={2024},
  volume={},
  number={},
  pages={6695-6702},
  keywords={Runtime;Semantics;Optimization methods;Syntactics;Market research;Planning;Trajectory},
  doi={10.1109/ICRA57147.2024.10611163}}

@inproceedings{CLEAR,
  title={Language, Camera, Autonomy! Prompt-engineered Robot Control for Rapidly Evolving Deployment},
  author={Macdonald, Jacob P and Mallick, Rohit and Wollaber, Allan B and Pe{\~n}a, Jaime D and McNeese, Nathan and Siu, Ho Chit},
  booktitle={Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={717--721},
  year={2024}
}

@misc{ChatGPTRobotics,
      title={ChatGPT for Robotics: Design Principles and Model Abilities}, 
      author={Sai Vemprala and Rogerio Bonatti and Arthur Bucker and Ashish Kapoor},
      year={2023},
      eprint={2306.17582},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2306.17582}, 
}

@inproceedings{CoT,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2024},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@misc{CodeasPolicies,
      title={Code as Policies: Language Model Programs for Embodied Control}, 
      author={Jacky Liang and Wenlong Huang and Fei Xia and Peng Xu and Karol Hausman and Brian Ichter and Pete Florence and Andy Zeng},
      year={2023},
      eprint={2209.07753},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.07753}, 
}

@INPROCEEDINGS{EnsureSafety,
  author={Wang, Ziming and Liu, Qingchen and Qin, Jiahu and Li, Man},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Ensuring Safety in LLM-Driven Robotics: A Cross-Layer Sequence Supervision Mechanism}, 
  year={2024},
  volume={},
  number={},
  pages={9620-9627},
  keywords={Cross layer design;Limiting;Automata;Syntactics;Real-time systems;Safety;Planning;Logic;Robots;Monitoring},
  doi={10.1109/IROS58592.2024.10801576}}

@inproceedings{HighlightSafetyConcern,
title={On the Safety Concerns of Deploying {LLM}s/{VLM}s in Robotics: Highlighting the Risks and Vulnerabilities},
author={Xiyang Wu and Ruiqi Xian and Tianrui Guan and Jing Liang and Souradip Chakraborty and Fuxiao Liu and Brian M. Sadler and Dinesh Manocha and Amrit Bedi},
booktitle={First Vision and Language for Autonomous Driving and Robotics Workshop},
year={2024},
url={https://openreview.net/forum?id=4FpuOMoxsX}
}

@INPROCEEDINGS{ISR-LLM,
  author={Zhou, Zhehua and Song, Jiayang and Yao, Kunpeng and Shu, Zhan and Ma, Lei},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning}, 
  year={2024},
  volume={},
  number={},
  pages={2081-2088},
  keywords={Large language models;Data preprocessing;Reliability engineering;Natural language processing;Planning;Iterative methods;Task analysis},
  doi={10.1109/ICRA57147.2024.10610065}}

@misc{JailbreakingLLM,
      title={Jailbreaking Black Box Large Language Models in Twenty Queries}, 
      author={Patrick Chao and Alexander Robey and Edgar Dobriban and Hamed Hassani and George J. Pappas and Eric Wong},
      year={2024},
      eprint={2310.08419},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.08419}, 
}

@INPROCEEDINGS{Lifelong,
  author={Parakh, Meenal and Fong, Alisha and Simeonov, Anthony and Chen, Tao and Gupta, Abhishek and Agrawal, Pulkit},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Lifelong Robot Learning with Human Assisted Language Planners}, 
  year={2024},
  volume={},
  number={},
  pages={523-529},
  keywords={Large language models;Natural languages;Robot learning;Cognition;6-DOF;Planning;Task analysis},
  doi={10.1109/ICRA57147.2024.10610225}}

@article{PlanAgent,
  publtype={informal},
  author={Yupeng Zheng and Zebin Xing and Qichao Zhang and Bu Jin and Pengfei Li and Yuhang Zheng and Zhongpu Xia and Kun Zhan and Xianpeng Lang and Yaran Chen and Dongbin Zhao},
  title={PlanAgent: A Multi-modal Large Language Agent for Closed-loop Vehicle Motion Planning},
  year={2024},
  cdate={1704067200000},
  journal={CoRR},
  volume={abs/2406.01587},
  url={https://doi.org/10.48550/arXiv.2406.01587}
}

@INPROCEEDINGS{PluginSafety,
  author={Yang, Ziyi and Raman, Shreyas S. and Shah, Ankit and Tellex, Stefanie},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents}, 
  year={2024},
  volume={},
  number={},
  pages={14435-14442},
  keywords={Service robots;Pressing;Cognition;Encoding;Production facilities;Safety;Reliability},
  doi={10.1109/ICRA57147.2024.10611447}
}

@INPROCEEDINGS{PromptBook,
  author={Arenas, Montserrat Gonzalez and Xiao, Ted and Singh, Sumeet and Jain, Vidhi and Ren, Allen and Vuong, Quan and Varley, Jake and Herzog, Alexander and Leal, Isabel and Kirmani, Sean and Prats, Mario and Sadigh, Dorsa and Sindhwani, Vikas and Rao, Kanishka and Liang, Jacky and Zeng, Andy},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={How to Prompt Your Robot: A PromptBook for Manipulation Skills with Code as Policies}, 
  year={2024},
  volume={},
  number={},
  pages={4340-4348},
  keywords={Codes;Scalability;Large language models;Semantics;Grasping;Manipulators;Cognition},
  doi={10.1109/ICRA57147.2024.10610784}}

@misc{PromptEngineering,
    author = {Microsoft Learn},
    year = {2025},
    title = {Prompt engineering techniques},
    note = {Accessed: 2-Feb-2025},
    howpublished = {\url{https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/prompt-engineering?tabs=chat}}    
}

@misc{REAL,
      title={REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots}, 
      author={Andrea Tagliabue and Kota Kondo and Tong Zhao and Mason Peterson and Claudius T. Tewari and Jonathan P. How},
      year={2023},
      eprint={2311.01403},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2311.01403}, 
}

@article{TypeFly,
  title={Typefly: Flying drones with large language model},
  author={Chen, Guojun and Yu, Xiaojing and Ling, Neiwen and Zhong, Lin},
  journal={arXiv preprint arXiv:2312.14950},
  year={2023}
}

@misc{URIAL,
      title={The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning}, 
      author={Bill Yuchen Lin and Abhilasha Ravichander and Ximing Lu and Nouha Dziri and Melanie Sclar and Khyathi Chandu and Chandra Bhagavatula and Yejin Choi},
      year={2023},
      eprint={2312.01552},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.01552}, 
}

@INPROCEEDINGS{VisionPlanning,
  author={Shirai, Keisuke and Beltran-Hernandez, Cristian C. and Hamaya, Masashi and Hashimoto, Atsushi and Tanaka, Shohei and Kawaharazuka, Kento and Tanaka, Kazutoshi and Ushiku, Yoshitaka and Mori, Shinsuke},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Vision-Language Interpreter for Robot Task Planning}, 
  year={2024},
  volume={},
  number={},
  pages={2051-2058},
  keywords={Measurement;Accuracy;Codes;Large language models;Refining;Linguistics;Market research},
  doi={10.1109/ICRA57147.2024.10611112}}

