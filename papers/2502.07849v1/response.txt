\section{Related Work}
Classifier-Free Guidance (CFG) has been a topic of interest in recent research, with the original work introducing CFG **Hou et al., "Classifier-Free Guided Image Generation"** highlighting the trade-off between image quality, measured by Fr√©chet inception distance (FID, **He et al., "A Style-Based Generator Model for Generative Adversarial Networks"**), and diversity, measured by inception score **Brock et al., "Large Image Generation with Interpretable Adversarial Loss"** when adjusting the guidance strength parameter $\omega$. Since then, a significant body of research has examined CFG from various perspectives.

\paragraph{Theoretical works on CFG.} From a theoretical standpoint, several works also employed Gaussian mixture models to analyze diffusion and guidance, including **Song et al., "Improved Techniques for Training Score-Based Generative Models"**. In contrast, **Ho et al., "A Differentiable Approach to Exemplar-based Image Manipulation"** explored alternative approaches to conditioning, modifying, and reusing diffusion models for compositional generation and guidance tasks. **Wu et al., "Diffusion-based Generative Models with Improved Convergence Rates"** characterized CFG as a predictor-corrector *****, positioning it within a broader context of sampling approaches in order to improve its theoretical understanding, similar to the approach in this paper, however from the perspective of denoising and sharpening processes.


\paragraph{CFG variants and experimental analyses.} Among experimental evaluations of CFG, **Ho et al., "Guiding Image Generation with a Smaller, Less-Trained Version of the Model"** showed that guiding generation using a smaller, less-trained version of the model itself can achieve disentangled control over image quality without compromising variation. **Wu et al., "Limited-Interval Classifier-Free Guidance for Efficient Training"** proposed applying CFG in a limited interval, and **Li et al., "Classifier Strength Schedulers for Improved Performance"** proposed using weight schedulers for the classifier strength parameter. Several alternatives to standard CFG have been proposed, such as rectified classifier guidance **Wang et al., "Rectified Classifier Guidance with Pre-Computed Coefficients"** using pre-computed guidance coefficients, projected score guidance **Liu et al., "Projected Score Guidance with Feature Centroid"** pushing the image feature vector toward a feature centroid of the target class, characteristic guidance **Zhang et al., "Characteristic Guidance as Non-Linear Correction"** as a non-linear correction of CFG obtained using numerical solvers, and second-order CFG *****, assuming locally-cone shaped condition space. All these variants can be directly combined with our proposed generalization of CFG.


\looseness=-1\paragraph{Dynamical regimes, statistical physics and high-dimensional settings.} Akin to this work, several works recently studied dynamical regimes of diffusion models, primarily focusing on the standard, non-CFG version **Song et al., "Improved Techniques for Training Score-Based Generative Models"**. 
Statistical physics methods have been particularly useful in analyzing high-dimensional settings, e.g., data drawn from the Curie-Weiss model *****, high-dimensional Gaussian mixtures *****, and hierarchical models *****. 
Other relevant statistical-physics studies include **Wu et al., "Phase Transitions in High-Dimensional Generative Models"**, who provided a comprehensive theoretical comparison between flow, diffusion, and autoregressive models from a spin glass perspective; **Zhang et al., "Memorization in Generative Diffusion on Manifold-Supported Data"**, who extended the theory of memorization in generative diffusion to manifold-supported data; *****, who analyzed sample complexity for high-dimensional Gaussian mixtures. A rigorous formulation of diffusion models in infinite dimensional setting was developed by *****.