Recent studies have raised concerns about the effectiveness of Classifier-Free Guidance (CFG), indicating that in low-dimensional settings, it can lead to overshooting the target distribution and reducing sample diversity. In this work, we  demonstrate that  in infinite and sufficiently high-dimensional contexts CFG effectively reproduces the target distribution, revealing a ``blessing-of-dimensionality'' result. Additionally, we explore finite-dimensional effects, precisely characterizing  overshoot and variance reduction.
%and validate our theoretical framework on numerical simulations on Gaussian mixtures, as  well as  diffusion models trained image data. 
Based on our analysis, we introduce non-linear generalizations of CFG. Through numerical simulations on Gaussian mixtures and  experiments on class-conditional and text-to-image diffusion models %trained on real data (ImageNet-1k, CC12M and YFCC100M), 
we validate our analysis and show that our non-linear CFG %retains the beneficial properties of standard  CFG while 
offers improved flexibility and generation quality without additional computation cost. 
 %and -1k, and text-to-image models trained on Shutterstock, YFCC100M and CC12M data. 
%Our findings provide new insights into CFG's behavior in high-dimensional settings, underscoring its potential for enhancing generative models.