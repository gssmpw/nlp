\section{Discussion and Conclusion}
\subsection{Limitation}
Since our method depends on human body fitting and foreground segmentation, artifacts may occur due to inaccuracies in these videos within the processes. Despite incorporating pose optimization to correct poses, the reconstruction of hand parts and body shape may still exhibit artifacts in certain cases, as shown in the videos. While our approach generally yields more realistic results, similar to many existing methods~\cite{instant_nvr,weng2022humannerf,hu2023gaussianavatar}, it still faces challenges in accurately modeling loose attire, such as dresses, underscoring areas for potential improvement in future iterations.






\subsection{Conclusion}

In this paper, we introduce \name, a novel approach for high-quality dynamic human reconstruction from monocular videos. By leveraging 2D diffusion model priors, \name effectively reconstructs and infers the unseen parts of 3D human avatars. We introduce Dual-Space Optimization, which applies Score Distillation Sampling (SDS) in both canonical and observation spaces, ensuring visual consistency and realism across various poses. Furthermore, View Selection and Pose Feature Injection strategies resolve conflicts between SDS predictions and observed data, enhancing overall avatar fidelity. Extensive experiments on benchmarks demonstrate that \name outperforms state-of-the-art methods, particularly in rendering the unseen parts of the human body.


% In this paper, we introduced Wonder Human, among the pioneering methods utilizing the explicit representation of 3DGS for the efficient reconstruction of human avatars from partial-view videos. Our method achieves photorealistic rendering and reconstruction of invisible appearance. Experiments demonstrate that our approach surpasses state-of-the-art methods in terms of rendering quality for invisible region synthesis. Furthermore, we proposed dual space fine-tuning and appearance optimization, including view selection and pose feature injection, both of which proved effective in enhancing rendering quality. We anticipate that our innovative approach will stimulate further research in high-quality animatable human avatar synthesis from partial-view videos.
