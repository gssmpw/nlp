\subsection{Datasets}
We choose 4 datasets for our experiments: three domain-specific corpora -- MultiHop-RAG~\citep{DBLP:journals/corr/abs-2401-15391}, --AllSides~\citep{baly-etal-2020-detect} and AGNews~\citep{DBLP:conf/nips/YuZZMRKSZ23} from \citet{DBLP:journals/corr/abs-2405-02714} -- as well as the general-domain dataset Natural Questions dataset~(\citealp[NQ]{kwiatkowski-etal-2019-natural}).

For AllSides and AGNews, we mainly adopt queries from \citet{DBLP:journals/corr/abs-2405-02714}.
In the case of AGNews, we replace the similar document part in queries with another attribute of perspective, as we focus on the query retrieval rather than document similarity search.

For NQ, we use the ``old document'' split from \citet{DBLP:conf/icml/KishoreWLAW23}, which constructs a subset of Wikipedia pages containing all positive candidates for training and testing, while keeping the corpus size manageable for generative retrieval training.
