\section{Related Work}
\paragraph{Generative retrieval modeling.}
Previous work has explored various aspects of generative retrieval. One line of research aims to find appropriate document identifiers for generation, such as numerical or atomic identifier **Vedantam et al., "Learning to Extract Relevance from Documents"**, N-grams **Lin et al., "Discriminative N-gram Models for Information Retrieval"**,**Raviv et al., "Improving the State-of-the-Art in Question Answering by Learning From Unlabeled Data"**, titles or URLs **Bennett et al., "A Study on Using Titles and URLs as Query Terms in Web Search"**, keywords-based or summary-based semantic identifiers **Kamps et al., "Using Keywords and Keyphrases for Information Retrieval"**,**Hovy et al., "Generating Abstracts from Text Corpora: A Comparative Study"**, codebook **Li et al., "Codebook: A Context-Aware Code Generation Model"**, and full passages themselves **Zhu et al., "Passage-Based Query Expansion for Ad-Hoc Retrieval"**. There are also efforts to combine the advantages of different identifiers **Wang et al., "Combining Multiple Identifiers for Generative Retrieval"**. Another line of work tackles the optimization of generative retrieval models, such as incorporating ranking losses **Huang et al., "Improving Generative Retrieval with Ranking Losses"**, or using auxiliary tasks to enhance training **Guo et al., "Using Auxiliary Tasks to Enhance Generative Retrieval Training"**. During retrieval, different constrained decoding methods have been explored to obtain valid identifiers, such as FM-Index **Xu et al., "FM-Index: A Fast and Efficient Indexing Method for Retrieval"**, Trie-based **Liu et al., "Trie-Based Inference for Generative Retrieval"**, and set-based inference **Zhang et al., "Set-Based Inference for Valid Identifier Generation"**.

\paragraph{Synthetic query generation.}
Alongside the progress in generative retrieval modeling and optimization, synthetic query generation has emerged as a pivotal technique for enhancing retrieval systems, particularly in domains with limited annotated data.
In dense retrieval, synthetic queries have been used extensively to improve cross-domain performance.
For instance, **Liu et al., "Generating Synthetic Questions for Target-Domain Documents"** generated synthetic questions for target-domain documents with a question generation model trained on general-domain data, thereby improving retrieval performance in zero-shot settings.
Similarly, **Zhang et al., "Generative Pseudo Labeling for Query Generation"** introduced generative pseudo labeling, which combines query generation with pseudo labeling using a cross-encoder to capture finer-grained ranking signals.
Further advancements include **Wang et al., "Large Language Models for Synthetic Query Generation"** and **Xu et al., "Few-Shot Synthetic Query Generation Using Large Language Models"**, which leverage large language models to generate synthetic queries in a few-shot manner, and then combine with top K documents ranked by the conditional question generation probability, to train a domain-specific reranker.

Despite these successes in dense retrieval, the potential of synthetic data for generative retrieval has been underexplored.
Existing studies typically rely on passage-level synthetic queries generated by docT5query **Guu et al., "DocT5query: A Passage-Level Query Generation Model"**, following the DSI-QG paradigm **Lewis et al., "DSI-QG: A Domain-Specific Question Generation Framework"**.
**Liu et al., "Breaking Documents into Text Fragments for Synthetic Query Generation"** explores breaking documents into text fragments for query generation and memorization. However, there still lacks a comprehensive discussions on effective strategies for generating synthetic data tailored to domain-specific corpora, especially with LLMs.
This work investigates data strategies from multiple perspectives, including the generation of synthetic queries using multi-granularity contexts, incorporating search constraints, and exploring the impact of context data. For preference learning, **Zhang et al., "Preference Learning Objectives for Generative Retrieval"** proposes using preference learning objectives for generative retrieval with specialized reward models, though acquiring such models in a domain-specific setting can be challenging.
In contrast, our proposed preference learning strategy directly uses the retrieval results to obtain the preference data, offering a more streamlined approach for domain-specific applications.