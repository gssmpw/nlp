% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1

\documentclass[11pt]{article}
\usepackage[dvipsnames]{xcolor}

\usepackage[final]{acl}

\usepackage{times}
\usepackage{latexsym}

\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{microtype}

\usepackage{inconsolata}

\usepackage{graphicx}

\usepackage{xurl}


\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{verbatim}

\usepackage{tabularx}
\usepackage{booktabs}
\newcolumntype{C}{>{\centering\arraybackslash}X}
\usepackage{multirow}
\usepackage{diagbox}
\usepackage{hhline}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{soul}

\definecolor{RoseQuartzBg}{HTML}{F7CAC9}
\definecolor{RoseQuartz}{HTML}{F5A798}
\definecolor{Serenity}{HTML}{92A8D1}
\definecolor{OrangeRed}{rgb}{1.0, 0.27, 0.0}
\definecolor{Turquoise}{HTML}{0F4C81}

\usepackage{arydshln}
\setlength\dashlinedash{1.5pt}
\setlength\dashlinegap{2pt}
\setlength\arrayrulewidth{0.3pt}

\definecolor{themered}{HTML}{FF8375}

\usepackage{xparse}
\usepackage{bbm}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{stfloats}
\usepackage{pifont}
\newcommand*\colourcheck[1]{
  \expandafter\newcommand\csname #1check\endcsname{\textcolor{#1}{\ding{52}}}
}
\newcommand*\colourxmark[1]{
  \expandafter\newcommand\csname #1xmark\endcsname{\textcolor{#1}{\ding{56}}}
}

\colourcheck{green}
\colourxmark{red}
\usepackage{cancel}
\usepackage{transparent}
\usepackage{float}
\usepackage{tcolorbox}
\tcbset{colframe=black,colback=white,size=small,colbacktitle=gray!30!white,coltitle=black,fonttitle=\bfseries,fontupper=\footnotesize\ttfamily}

\newcommand{\yz}[1]{\textcolor{orange}{YZ: #1}}

\NewDocumentCommand{\haoyang}{ mO{} }{
\textcolor{Turquoise}{\textsuperscript{\textsc{Haoyang}}\textsf{\textbf{\small[#1]}}}}


\title{On Synthetic Data Strategies for Domain-Specific Generative Retrieval}


\author{Haoyang Wen$^\ddagger$, Jiang Guo$^\dagger$\thanks{Corresponding author}, Yi Zhang$^\dagger$, Jiarong Jiang$^\dagger$, Zhiguo Wang$^\dagger$\\
    $^\ddagger$Language Technologies Institute, Carnegie Mellon University~~~~$^\dagger$AWS AI\\
    \texttt{hwen3@cs.cmu.edu}\\
    \texttt{\{gujiang, imyi, jiarongj, zhiguow\}@amazon.com}}


\begin{document}
\maketitle
\begin{abstract}
This paper investigates synthetic data generation strategies in developing generative retrieval models for domain-specific corpora, thereby addressing the scalability challenges inherent in manually annotating in-domain queries. We study the data strategies for a two-stage training framework: in the first stage, which focuses on learning to decode document identifiers from queries, we investigate LLM-generated queries across multiple granularity (e.g. chunks, sentences) and domain-relevant search constraints that can better capture nuanced relevancy signals. In the second stage, which aims to refine document ranking through preference learning, we explore the strategies for mining hard negatives based on the initial model's predictions. Experiments on public datasets over diverse domains demonstrate the effectiveness of our synthetic data generation and hard negative sampling approach.
\end{abstract}
\input{1_introduction}
\input{2_basic_framework}
\input{3_sft}
\input{4_preference_learning}
\input{5_experiments}
\input{6_related_work}
\input{7_conclusion}

\bibliography{anthology,custom}
\appendix
\input{_app_data_specific_setup}
\input{_app_dense_model_comparison}
\input{_app_llm_prompts_v2}
\end{document}
