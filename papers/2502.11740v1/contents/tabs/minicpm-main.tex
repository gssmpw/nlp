\begin{table*}[ht]
  \centering
  \small
  \begin{tabular}{lccccccccccc}
    \toprule   
    \multirow{2}{*}{Method} & \multirow{2}{*}{\#Params} & \multicolumn{7}{c}{Pre-trained tasks} & \multicolumn{1}{c}{Target task} & \multicolumn{2}{c}{Metrics} \\
    \cmidrule(lr){3-9} \cmidrule(lr){10-10} \cmidrule(lr){11-12}
    &                       & \textbf{VizWiz} & \textbf{A-OKVQA} & \textbf{OKVQA} & \textbf{TextVQA} & \textbf{IconQA} & \textbf{POPE} & \textbf{MMBench} & \textbf{PathVQA} & \textbf{Avg} & \textbf{Hscore} \\
    \midrule
    \textbf{Zero-shot}       & -     & 55.27  & 79.39 & 64.86 & 77.98 & 79.01 & 88.93 & 70.98 & 5.44 & 65.23   & 10.04\\
    \midrule
    \textbf{Fine-tune}       & 517M  & 52.91  & 76.94 & 59.06 & 58.34 & 76.96 & \textbf{89.60} & 70.16 & \underline{11.04} & 61.88  & \underline{18.74}\\
    \textbf{LoRA}            & 35M & 52.95  & 76.24 & \textbf{64.45} & 77.18 & 77.80 & 88.08 & 67.47 & \textbf{15.03} & 64.90 & \textbf{24.41}\\
    \midrule
    \textbf{MDGD}           &  517M  & \textbf{55.73}  & 78.25 & \underline{64.33} & \underline{77.54} & \textbf{79.45} & \underline{89.19} & \textbf{71.94} & 9.09 & \textbf{65.69}   & 15.97\\
    ~~w/o visual align & 517M  & 54.92  & \underline{78.52} & 64.17 & 77.42 & \underline{79.37} & 89.10 & 70.96 & 8.49 & \underline{65.37}  & 15.03\\
   \textbf{ MDGD-GM}  & 52M  & \underline{55.04}  & \textbf{78.78} & 64.31 & \textbf{77.78} & 79.10 & 88.76 & \underline{70.98} & 5.72 & 65.06  & 10.52 \\
    
    \bottomrule
    \toprule
    
    \multirow{2}{*}{Method} & \multirow{2}{*}{\#Params} & \multicolumn{7}{c}{Pre-trained tasks} & \multicolumn{1}{c}{Target task} & \multicolumn{2}{c}{Metrics} \\
    \cmidrule(lr){3-9} \cmidrule(lr){10-10} \cmidrule(lr){11-12}
    &                        & \textbf{VizWiz} & \textbf{A-OKVQA} & \textbf{OKVQA} & \textbf{TextVQA} & \textbf{IconQA} & \textbf{POPE} & \textbf{MMBench} & \textbf{TextCaps} & \textbf{Avg} & \textbf{Hscore} \\
    \midrule
    \textbf{Zero-shot}        & -     & 55.27  & 79.39 & 64.86 & 77.98 & 79.01 & 88.93 & 70.98 & 15.77 & 66.52 & 25.50  \\
    \midrule
    \textbf{Fine-tune}        & 517M  & 52.03  & 77.73 & 59.16 & 67.24 & 78.67 & 88.20 & 71.42 & \textbf{33.85} & 66.04 & \textbf{44.76} \\
    \textbf{LoRA}             & 35M  & 53.30  & \underline{78.17}          & \underline{63.99} & \underline{77.68} & 78.28 & 87.31 & 69.23 & \underline{32.41} & 67.55 & \underline{43.80} \\
    \midrule
    \textbf{MDGD}             & 517M  & \textbf{55.17}  & \underline{78.17} & 63.67          & 76.08 & \underline{79.40} & \textbf{89.11} & \underline{71.58} & 28.90 & \underline{67.76} & 40.52 \\
    ~~w/o visual align & 517M  & 51.35           & 78.08            & 63.06          & 76.48 & 78.99                & \underline{88.98} & 71.30 & 25.93 & 66.77 & 37.35 \\
    \textbf{MDGD-GM}  & 52M   & \underline{55.04}  & \textbf{78.43} & \textbf{65.26} & \textbf{78.08} & \textbf{79.65} & 88.93           & \textbf{71.88} & 29.14 & \textbf{68.30} & 40.85 \\
    \bottomrule
  \end{tabular}
  \caption{
  Performance on various pre-trained tasks of MiniCPM-V2.5 models fine-tuned on PathVQA and TextCaps. 
  We report the best performance for each task in a \textbf{bold font} while the second best performance \underline{underlined}.
  }
  \label{tab:minicpm}
  \vspace{-.8cm}
\end{table*}
