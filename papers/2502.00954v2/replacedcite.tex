\section{Related Work}
\subsection{3D Scene Update} 

The evolving nature of 3D environments requires continuous scene updates for effective understanding, particularly in autonomous driving ____ and robotic navigation ____. A fundamental approach to scene updating involves reconstructing the entire scene from scratch. Advances in 3D reconstruction, such as multi-view stereo ____, depth sensor-based ____, and volumetric methods ____, have improved reconstruction fidelity. But current methods struggle to balance accuracy, efficiency, and scalability ____, making reconstruction primarily suitable for situations involving major changes. Recently, radiance-based 3D scene editing approaches, such as NeRF and 3D Gaussian Splatting (3DGS), have emerged as more efficient alternatives for incremental scene updates. NeRF-based methods ____ were limited to basic object edits and struggled with complex, cluttered scenes ____. 3DGS-based methods enable finer control over scene content, including geometry ____, texture ____, and lighting ____. However, they struggle to disentangle these components and require costly re-optimization, limiting editability and efficiency ____. 

Therefore, accurate and efficient 3D scene updates remain a challenge, making real-time scene acquisition not always feasible. This highlights the need for hypothetical reasoning.

\subsection{3D Visual Question Answering}
3D Visual Question Answering (3D VQA), a key task for evaluating 3D reasoning, has advanced with the rise of Vision-Language Models (VLMs) ____. By integrating vision encoders with Large Language Models (LLMs) ____, VLMs enable multimodal perception of 3D scenes using inputs like top-view maps and point clouds. As models advance, there is growing interest in developing more comprehensive benchmarks to better assess their 3D reasoning capabilities. Initial 3DQA dataset ____, derived from ScanNet ____, introduced 6K manually annotated QA pairs for scene-level reasoning. ScanQA ____ expanded this with 41K QA pairs using automated question generation and human refinement. Qian et al. ____ further extended 3D VQA to autonomous driving scenarios, offering domain-specific challenges. SQA3D ____ introduced “situated reasoning,” requiring models to contextualize answers based on an agent’s position and orientation. MRSA ____ and SPARTUN3D ____ further scaled SQA3D, adding multimodal inputs such as images for richer situational context. 

Unlike previous benchmarks, where answers are derived fully from the given scene, Hypo3D hypothetically applies a change to the scene and derives answers from the changed scene, increasing the hallucination risk.