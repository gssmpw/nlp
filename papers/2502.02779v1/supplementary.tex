\newpage
\appendix

\renewcommand{\figurename}{Supplementary Figure}
\renewcommand{\tablename}{Supplementary Table}
\setcounter{figure}{0}
\setcounter{table}{0}

\input{plots/batch_effect_analysis}


\section{Details of datasets}
This section provides additional details about the dataset used to evaluate the downstream tasks. \Cref{tab:disease_definition} lists the ICD-10 codes and medications used to identify the diagnoses for each disease. \Cref{tab:characteristic} presents the distribution of patient characteristics for each disease. \Cref{fig:nyu_langone_prevalence,fig:nyu_longisland_prevalence} illustrates the prevalence of each disease in the downstream tasks for the NYU Langone and NYU Long Island datasets, highlighting the imbalances present in these tasks.

\input{tables/disease_definition}
\input{tables/characteristic_table}
\input{plots/prevalence_plot}


\section{Data augmentation details}
\label{sec:dataaug_details}
We applied Random Flipping across all three dimensions, Random Shift Intensity with offset $0.1$ for both pre-training and fine-tuning. For DINO training. random Gaussian Smoothing with sigma=$(0.5-1.0)$ is applied across all dimensions, Random Gamma Adjust is applied with gamma=$(0.2-1.0)$.


\section{Additional experiment results}
This section provides additional experimental results with more details.
Supplementary \Cref{fig:channels-ablation,fig:patches-ablation} compares the performance of the foundation model using different numbers of channels and patch sizes, demonstrating that the architecture design of our foundation model is optimal. 

Supplementary \Cref{fig:radar-comparison-merlin} compares our foundation model with a foundation CT model from previous studies, Merlin\cite{blankemeier2024merlinvisionlanguagefoundation}, which was trained on abdomen CT scans with corresponding radiology report pairs. Our model demonstrates superior performance on head CT scans.

Supplementary \Cref{fig:probing-comparison-gemini} compares our foundation model with Google CT Foundation model~\cite{yang2024advancingmultimodalmedicalcapabilities}, which was trained on large scale and diverse CT scans from different anatomy with corresponding radiology report pairs. Our model consistently shows improved performance across the board even though our model was pre-trained with less samples.

Supplementary \Cref{fig:probing_comparison} compares the performance on downstream tasks with various supervised tuning methods applied to foundation models pretrained with the MAE and DINO frameworks. Per-pathology comparisons are shown in Supplementary \Cref{fig:probing-comparison-perpath,fig:probing-comparison-perpath-dino}. Meanwhile, supplementary \Cref{fig:boxplot_scaling} complements \Cref{fig:scaling_law}, illustrating the per-pathology performances of foundation models pretrained with different scales of training data.

Supplementary \Cref{fig:batch_effect,fig:thickness-ablation} studies the impact of batch effect caused by different CT scan protocols of slice thickness and machine manufacturer. Detailed per-pathology performances are shown in Supplementary \Cref{fig:slice_thickness_per_pathology,fig:manufacturer_per_pathology}.

\input{plots/channels_ablation}

\input{plots/patches_ablation}

\input{plots/radar_comparison}

\input{plots/probing_comparison}

\input{plots/gemini_comparison}

\input{plots/probing_comparison_per_path}







\input{plots/pretrain_percentage_comparison_per_path}

\newpage

\section{Time complexity increase with reduced patch size}
\label{apd:self_attention_rate}
Assume we have 3D image input of shape $H\times W\times D$, patch size $P$ and reducing factor $s$. By time complexity of self-attention $O(n^2 d)$ for sequence length $n$ and embedding dimension $d$, the new time complexity after reducing patch size can be derived as
\begin{align*}
    O(n^2d)&=O((\frac{H\times W\times D}{(\frac{P}{s})^3})^2d) \\
           &=O((\frac{H\times W\times D}{P^3})^2 s^6d)  \\
           &=O(s^6)O(n_{ori}^2d)
\end{align*}
where $n_{ori}=\frac{H\times W\times D}{P^3}$ is the original sequence length before reducing patch size.



















\newpage
\input{plots/slice_thickness_manufacturer}
