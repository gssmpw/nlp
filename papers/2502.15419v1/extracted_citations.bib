@ARTICLE{10.3389/frai.2024.1341697,
    AUTHOR={Quelle, Dorian  and Bovet, Alexandre },
    TITLE={The perils and promises of fact-checking with large language models},
    JOURNAL={Frontiers in Artificial Intelligence},
    VOLUME={7},
    YEAR={2024},
    URL={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1341697},
    DOI={10.3389/frai.2024.1341697},
    ISSN={2624-8212},
    ABSTRACT={<p>Automated fact-checking, using machine learning to verify claims, has grown vital as misinformation spreads beyond human fact-checking capacity. Large language models (LLMs) like GPT-4 are increasingly trusted to write academic papers, lawsuits, and news articles and to verify information, emphasizing their role in discerning truth from falsehood and the importance of being able to verify their outputs. Understanding the capacities and limitations of LLMs in fact-checking tasks is therefore essential for ensuring the health of our information ecosystem. Here, we evaluate the use of LLM agents in fact-checking by having them phrase queries, retrieve contextual data, and make decisions. Importantly, in our framework, agents explain their reasoning and cite the relevant sources from the retrieved context. Our results show the enhanced prowess of LLMs when equipped with contextual information. GPT-4 outperforms GPT-3, but accuracy varies based on query language and claim veracity. While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy. Our investigation calls for further research, fostering a deeper comprehension of when agents succeed and when they fail.</p>}
}

@inproceedings{10317251,
  author={Cheung, Tsun-Hin and Lam, Kin-Man},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking}, 
  year={2023},
  volume={},
  number={},
  pages={846-853},
  doi={10.1109/APSIPAASC58517.2023.10317251}
}

@inproceedings{NielsenMcConville2022,
  title = {MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset},
  author = {Dan Saattrup Nielsen and Ryan McConville},
  booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)},
  year = {2022},
  publisher = {ACM},
  eprint = {2202.11684}
}

@inproceedings{bussotti-etal-2024-unknown,
    title = "Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data",
    author = "Bussotti, Jean-Flavien  and
      Ragazzi, Luca  and
      Frisoni, Giacomo  and
      Moro, Gianluca  and
      Papotti, Paolo",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.675/",
    doi = "10.18653/v1/2024.emnlp-main.675",
    pages = "12105--12122",
    abstract = "Computational fact-checking (FC) relies on supervised models to verify claims based on given evidence, requiring a resource-intensive process to annotate large volumes of training data. We introduce Unown, a novel framework that generates training instances for FC systems automatically using both textual and tabular content. Unown selects relevant evidence and generates supporting and refuting claims with advanced negation artifacts. Designed to be flexible, Unown accommodates various strategies for evidence selection and claim generation, offering unparalleled adaptability. We comprehensively evaluate Unown on both text-only and table+text benchmarks, including Feverous, SciFact, and MMFC, a new multi-modal FC dataset. Our results prove that Unown examples are of comparable quality to expert-labeled data, even enabling models to achieve up to 5{\%} higher accuracy. The code, data, and models are available at https://github.com/disi-unibo-nlp/unown"
}

@inproceedings{chan2024balancing,
    title={Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for {LLM}s},
    author={Yung-Chieh Chan and George Pu and Apaar Shanker and Parth Suresh and Penn Jenks and John Heyer and Samuel Marc Denton},
    booktitle={NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability},
    year={2024},
    url={https://openreview.net/forum?id=hRjFiTxv1v}
}

@article{goyal2024systematic,
  title={A systematic review of synthetic data generation techniques using generative AI},
  author={Goyal, Mandeep and Mahmoud, Qusay H},
  journal={Electronics},
  volume={13},
  number={17},
  pages={3509},
  year={2024},
  publisher={MDPI}
}

@inproceedings{gupta2021x,
  title={X-Fact: A New Benchmark Dataset for Multilingual Fact Checking},
  author={Gupta, Ashim and Srikumar, Vivek},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  pages={675--682},
  year={2021}
}

@inproceedings{hu2024towards,
    title={Towards Understanding Factual Knowledge of Large Language Models},
    author={Xuming Hu and Junzhe Chen and Xiaochuan Li and Yufei Guo and Lijie Wen and Philip S. Yu and Zhijiang Guo},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=9OevMUdods}
}

@inproceedings{khouja-2020-stance,
    title = "Stance Prediction and Claim Verification: An {A}rabic Perspective",
    author = "Khouja, Jude",
    editor = "Christodoulopoulos, Christos  and
      Thorne, James  and
      Vlachos, Andreas  and
      Cocarascu, Oana  and
      Mittal, Arpit",
    booktitle = "Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.fever-1.2/",
    doi = "10.18653/v1/2020.fever-1.2",
    pages = "8--17",
    abstract = "This work explores the application of textual entailment in news claim verification and stance prediction using a new corpus in Arabic. The publicly available corpus comes in two perspectives: a version consisting of 4,547 true and false claims and a version consisting of 3,786 pairs (claim, evidence). We describe the methodology for creating the corpus and the annotation process. Using the introduced corpus, we also develop two machine learning baselines for two proposed tasks: claim verification and stance prediction. Our best model utilizes pretraining (BERT) and achieves 76.7 F1 on the stance prediction task and 64.3 F1 on the claim verification task. Our preliminary experiments shed some light on the limits of automatic claim verification that relies on claims text only. Results hint that while the linguistic features and world knowledge learned during pretraining are useful for stance prediction, such learned representations from pretraining are insufficient for verifying claims without access to context or evidence."
}

@misc{li2020mmcovid,
  title={MM-COVID: A Multilingual and Multimodal Data Repository for Combating COVID-19 Disinformation}, 
  author={Yichuan Li and Bohan Jiang and Kai Shu and Huan Liu},
  year={2020},
  eprint={2011.04088},
  archivePrefix={arXiv},
  primaryClass={cs.SI}
}

@inproceedings{li2023synthetic,
    title={Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations},
    author={Zhuoyan Li and Hangxiao Zhu and Zhuoran Lu and Ming Yin},
    booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
    year={2023},
    url={https://openreview.net/forum?id=MmBjKmHIND}
}

@inproceedings{long-etal-2024-llms,
    title = "On {LLM}s-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey",
    author = "Long, Lin  and
      Wang, Rui  and
      Xiao, Ruixuan  and
      Zhao, Junbo  and
      Ding, Xiao  and
      Chen, Gang  and
      Wang, Haobo",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.658/",
    doi = "10.18653/v1/2024.findings-acl.658",
    pages = "11065--11082",
    abstract = "Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However, current investigations into this field lack a unified framework and mostly stay on the surface. Therefore, this paper provides an organization of relevant studies based on a generic workflow of synthetic data generation. By doing so, we highlight the gaps within existing research and outline prospective avenues for future study. This work aims to shepherd the academic and industrial communities towards deeper, more methodical inquiries into the capabilities and applications of LLMs-driven synthetic data generation."
}

@inproceedings{norregaard-derczynski-2021-danfever,
    title = "{D}an{FEVER}: claim verification dataset for {D}anish",
    author = "N{\o}rregaard, Jeppe  and
      Derczynski, Leon",
    editor = "Dobnik, Simon  and
      {\O}vrelid, Lilja",
    booktitle = "Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)",
    month = may # " 31--2 " # jun,
    year = "2021",
    address = "Reykjavik, Iceland (Online)",
    publisher = {Link{\"o}ping University Electronic Press, Sweden},
    url = "https://aclanthology.org/2021.nodalida-main.47/",
    pages = "422--428",
    abstract = "We present a dataset, DanFEVER, intended for multilingual misinformation research. The dataset is in Danish and has the same format as the well-known English FEVER dataset. It can be used for testing methods in multilingual settings, as well as for creating models in production for the Danish language."
}

@inproceedings{patel2024datadreamer,
  title = "{D}ata{D}reamer: A Tool for Synthetic Data Generation and Reproducible {LLM} Workflows",
    author = "Patel, Ajay  and
      Raffel, Colin  and
      Callison-Burch, Chris",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.208/",
    doi = "10.18653/v1/2024.acl-long.208",
    pages = "3781--3799",
    abstract = "Large language models (LLMs) have become a dominant and important tool for NLP researchers in a wide range of tasks. Today, many researchers use LLMs in synthetic data generation, task evaluation, fine-tuning, distillation, and other model-in-the-loop research workflows. However, challenges arise when using these models that stem from their scale, their closed source nature, and the lack of standardized tooling for these new and emerging workflows. The rapid rise to prominence of these models and these unique challenges has had immediate adverse impacts on open science and on the reproducibility of work that uses them. In this ACL 2024 theme track paper, we introduce DataDreamer, an open source Python library that allows researchers to write simple code to implement powerful LLM workflows. DataDreamer also helps researchers adhere to best practices that we propose to encourage open science and reproducibility. The library and documentation are available at: https://github.com/datadreamer-dev/DataDreamer."
}

@inproceedings{schuster-etal-2021-get,
    title = "Get Your Vitamin {C}! Robust Fact Verification with Contrastive Evidence",
    author = "Schuster, Tal  and
      Fisch, Adam  and
      Barzilay, Regina",
    editor = "Toutanova, Kristina  and
      Rumshisky, Anna  and
      Zettlemoyer, Luke  and
      Hakkani-Tur, Dilek  and
      Beltagy, Iz  and
      Bethard, Steven  and
      Cotterell, Ryan  and
      Chakraborty, Tanmoy  and
      Zhou, Yichao",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.52/",
    doi = "10.18653/v1/2021.naacl-main.52",
    pages = "624--643",
    abstract = "Typical fact verification models use retrieved written evidence to verify claims. Evidence sources, however, often change over time as more information is gathered and revised. In order to adapt, models must be sensitive to subtle differences in supporting evidence. We present VitaminC, a benchmark infused with challenging cases that require fact verification models to discern and adjust to slight factual changes. We collect over 100,000 Wikipedia revisions that modify an underlying fact, and leverage these revisions, together with additional synthetically constructed ones, to create a total of over 400,000 claim-evidence pairs. Unlike previous resources, the examples in VitaminC are contrastive, i.e., they contain evidence pairs that are nearly identical in language and content, with the exception that one supports a given claim while the other does not. We show that training using this design increases robustness{---}improving accuracy by 10{\%} on adversarial fact verification and 6{\%} on adversarial natural language inference (NLI). Moreover, the structure of VitaminC leads us to define additional tasks for fact-checking resources: tagging relevant words in the evidence for verifying the claim, identifying factual revisions, and providing automatic edits via factually consistent text generation."
}

@inproceedings{shafayat2024multifact,
    title={Multi-{FA}ct: Assessing Factuality of Multilingual {LLM}s using {FA}ctScore},
    author={Sheikh Shafayat and Eunsu Kim and Juhyun Oh and Alice Oh},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=lkrH6ovzsj}
}

@inproceedings{shahifakecovid,
    title={Fake{C}ovid -- A Multilingual Cross-domain Fact Check News Dataset for COVID-19},
    author={Shahi, Gautam Kishore and Nandini, Durgesh},
    booktitle={Workshop Proceedings of the 14th International {AAAI} {C}onference on {W}eb and {S}ocial {M}edia},
    year = {2020},
    url = {http://workshop-proceedings.icwsm.org/pdf/2020_14.pdf}
}

@inproceedings{singhal-etal-2024-multilingual,
    title = "Multilingual Fact-Checking using {LLM}s",
    author = "Singhal, Aryan  and
      Law, Thomas  and
      Kassner, Coby  and
      Gupta, Ayushman  and
      Duan, Evan  and
      Damle, Aviral  and
      Li, Ryan Luo",
    editor = "Dementieva, Daryna  and
      Ignat, Oana  and
      Jin, Zhijing  and
      Mihalcea, Rada  and
      Piatti, Giorgio  and
      Tetreault, Joel  and
      Wilson, Steven  and
      Zhao, Jieyu",
    booktitle = "Proceedings of the Third Workshop on NLP for Positive Impact",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.nlp4pi-1.2/",
    doi = "10.18653/v1/2024.nlp4pi-1.2",
    pages = "13--31",
    abstract = "Due to the recent rise in digital misinformation, there has been great interest shown in using LLMs for fact-checking and claim verification. In this paper, we answer the question: Do LLMs know multilingual facts and can they use this knowledge for effective fact-checking? To this end, we create a benchmark by filtering multilingual claims from the X-fact dataset and evaluating the multilingual fact-checking capabilities of five LLMs across five diverse languages: Spanish, Italian, Portuguese, Turkish, and Tamil on our benchmark. We employ three different prompting techniques: Zero-Shot, English Chain-of-Thought, and Cross-Lingual Prompting, using both greedy and self-consistency decoding. We extensively analyze our results and find that GPT-4o achieves the highest accuracy, but zero-shot prompting with self-consistency was the most effective overall. We also show that techniques like Chain-of-Thought and Cross-Lingual Prompting, which are designed to improve reasoning abilities, do not necessarily improve the fact-checking abilities of LLMs. Interestingly, we find a strong negative correlation between model accuracy and the amount of internet content for a given language. This suggests that LLMs are better at fact-checking from knowledge in low-resource languages. We hope that this study will encourage more work on multilingual fact-checking using LLMs."
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1074/",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
    abstract = "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources."
}

@inproceedings{tianfine,
  title={Fine-Tuning Language Models for Factuality},
  year={2024},
  author={Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea},
  booktitle={The Twelfth International Conference on Learning Representations}
}

@inproceedings{wright-etal-2022-generating,
    title = "Generating Scientific Claims for Zero-Shot Scientific Fact Checking",
    author = "Wright, Dustin  and
      Wadden, David  and
      Lo, Kyle  and
      Kuehl, Bailey  and
      Cohan, Arman  and
      Augenstein, Isabelle  and
      Wang, Lucy Lu",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.175/",
    doi = "10.18653/v1/2022.acl-long.175",
    pages = "2448--2460",
    abstract = "Automated scientific fact checking is difficult due to the complexity of scientific language and a lack of significant amounts of training data, as annotation requires domain expertise. To address this challenge, we propose scientific claim generation, the task of generating one or more atomic and verifiable claims from scientific sentences, and demonstrate its usefulness in zero-shot fact checking for biomedical claims. We propose CLAIMGEN-BART, a new supervised method for generating claims supported by the literature, as well as KBIN, a novel method for generating claim negations. Additionally, we adapt an existing unsupervised entity-centric method of claim generation to biomedical claims, which we call CLAIMGEN-ENTITY. Experiments on zero-shot fact checking demonstrate that both CLAIMGEN-ENTITY and CLAIMGEN-BART, coupled with KBIN, achieve up to 90{\%} performance of fully supervised models trained on manually annotated claims and evidence. A rigorous evaluation study demonstrates significant improvement in generated claim and negation quality over existing baselines"
}

@article{xu2024magpie,
  title={Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing},
  author={Zhangchen Xu and Fengqing Jiang and Luyao Niu and Yuntian Deng and Radha Poovendran and Yejin Choi and Bill Yuchen Lin},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.08464},
  url={https://api.semanticscholar.org/CorpusID:270391432}
}

@inproceedings{xu2024wizardlm,
    title={Wizard{LM}: Empowering Large Pre-Trained Language Models to Follow Complex Instructions},
    author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Qingwei Lin and Daxin Jiang},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=CfXh93NDgH}
}

@inproceedings{yu2024metamath,
    title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models},
    author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng YU and Zhengying Liu and Yu Zhang and James Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=N8N0hgNDRt}
}

