@book{cooper1999coordination,
  title={Coordination games},
  author={Cooper, Russell},
  year={1999},
  publisher={cambridge university Press}
}
@article{harsanyi1988general,
  title={A general theory of equilibrium selection in games},
  author={Harsanyi, John C and Selten, Reinhard},
  journal={MIT Press Books},
  volume={1},
  year={1988},
  publisher={The MIT Press}
}
@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}
@article{hernandez2019survey,
  title={A survey and critique of multiagent deep reinforcement learning},
  author={Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={33},
  number={6},
  pages={750--797},
  year={2019},
  publisher={Springer}
}
@inproceedings{subramaniam2025multiagent,
  title={Multiagent Finetuning of Language Models},
  author={Subramaniam, Vighnesh and Du, Yilun and Tenenbaum, Joshua B and Torralba, Antonio and Li, Shuang and Mordatch, Igor},
  booktitle={ICLR},
  year={2025}
}
@inproceedings{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICLR},
  year={2019}
}
@article{zhang2016quantal,
  title={Quantal response methods for equilibrium selection in 2$\times$ 2 coordination games},
  author={Zhang, Boyu and Hofbauer, Josef},
  journal={Games and Economic Behavior},
  volume={97},
  pages={19--31},
  year={2016},
  publisher={Elsevier}
}
@article{zhao2025sirius,
  title={SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning},
  author={Zhao, Wanjia and  Yuksekgonul, Mert  and Wu, Shirley and James Zou },
  journal={arXiv preprint arXiv:2502.04780},
  year={2025}
}
@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}
@inproceedings{holtzman2019curious,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  booktitle={ICLR},
  year={2020}
}
@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}
@article{hadfield2017inverse,
  title={Inverse reward design},
  author={Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart J and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}
@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}
@article{feng2025llmdroolsmultillmcollaboration,
      title={When One LLM Drools, Multi-LLM Collaboration Rules}, 
      author={Shangbin Feng and Wenxuan Ding and Alisa Liu and Zifeng Wang and Weijia Shi and Yike Wang and Zejiang Shen and Xiaochuang Han and Hunter Lang and Chen-Yu Lee and Tomas Pfister and Yejin Choi and Yulia Tsvetkov},
      year={2025},
  journal={arXiv preprint arXiv:2502.04506},
}
@article{harsanyi1995new,
  title={A new theory of equilibrium selection for games with complete information},
  author={Harsanyi, John C},
  journal={Games and Economic Behavior},
  volume={8},
  number={1},
  pages={91--122},
  year={1995},
  publisher={Elsevier}
}
@inproceedings{kumar2024training,
  title={Training language models to self-correct via reinforcement learning},
  author={Kumar, Aviral and Zhuang, Vincent and Agarwal, Rishabh and Su, Yi and Co-Reyes, John D and Singh, Avi and Baumli, Kate and Iqbal, Shariq and Bishop, Colton and Roelofs, Rebecca and others},
  booktitle={ICLR},
  year={2025}
}
@inproceedings{stengel2024teaching,
  title={Teaching models to balance resisting and accepting persuasion},
  author={Stengel-Eskin, Elias and Hase, Peter and Bansal, Mohit},
  booktitle={NAACL},
  year={2025}
}
@article{huttenrauch2017guided,
  title={Guided deep reinforcement learning for swarm systems},
  author={H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={arXiv preprint arXiv:1709.06011},
  year={2017}
}
@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}
@article{kim2023fantom,
  title={FANToM: A benchmark for stress-testing machine theory of mind in interactions},
  author={Kim, Hyunwoo and Sclar, Melanie and Zhou, Xuhui and Bras, Ronan Le and Kim, Gunhee and Choi, Yejin and Sap, Maarten},
  journal={arXiv preprint arXiv:2310.15421},
  year={2023}
}
@article{liu2023tinygsm,
  title={Tinygsm: achieving> 80\% on gsm8k with small language models},
  author={Liu, Bingbin and Bubeck, Sebastien and Eldan, Ronen and Kulkarni, Janardhan and Li, Yuanzhi and Nguyen, Anh and Ward, Rachel and Zhang, Yi},
  journal={arXiv preprint arXiv:2312.09241},
  year={2023}
}
@inproceedings{zhu2023principled,
  title={Principled reinforcement learning with human feedback from pairwise or k-wise comparisons},
  author={Zhu, Banghua and Jordan, Michael and Jiao, Jiantao},
  booktitle={International Conference on Machine Learning},
  pages={43037--43067},
  year={2023},
  organization={PMLR}
}
@inproceedings{kim2024adaptive,
  title={MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making},
  author={Kim, Yubin and Park, Chanwoo and Jeong, Hyewon and Chan, Yik Siu and Xu, Xuhai and McDuff, Daniel and Breazeal, Cynthia and Park, Hae Won},
  booktitle={NeurIPS},
  year={2024}
}
@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}
@inproceedings{yu2023outcome,
  title={OVM,Outcome-supervised Value Models for Planning in Mathematical Reasoning},
  author={Yu, Fei and Gao, Anningzhe and Wang, Benyou},
  booktitle={NAACL Findings},
  year={2024}
}
@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}
@inproceedings{nie2019adversarial,
  title={Adversarial NLI: A new benchmark for natural language understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  booktitle={ACL},
  year={2020}
}
@article{li2024personalized,
  title={Personalized Language Modeling from Personalized Human Feedback},
  author={Li, Xinyu and Lipton, Zachary C and Leqi, Liu},
  journal={arXiv preprint arXiv:2402.05133},
  year={2024}
}
@inproceedings{park2024llm,
  title={Do llm agents have regret? a case study in online learning and games},
  author={Park, Chanwoo and Liu, Xiangyu and Ozdaglar, Asuman and Zhang, Kaiqing},
  booktitle={ICLR},
  year={2025}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{park2024principled,
  title={Principled rlhf from heterogeneous feedback via personalization and preference aggregation},
  author={Park, Chanwoo and Liu, Mingyang and Zhang, Kaiqing and Ozdaglar, Asuman},
  journal={arXiv preprint arXiv:2405.00254},
  year={2024}
}
@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Yu and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}
@article{wang2023math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, RX and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Y and Sui, Zhifang},
  journal={CoRR, abs/2312.08935},
  year={2023}
}

@article{park2024multi,
  title={Multi-player zero-sum Markov games with networked separable interactions},
  author={Park, Chanwoo and Zhang, Kaiqing and Ozdaglar, Asuman},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}
@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}
@article{li2023prd,
  title={Prd: Peer rank and discussion improve large language model based evaluations},
  author={Li, Ruosen and Patel, Teerth and Du, Xinya},
  journal={arXiv preprint arXiv:2307.02762},
  year={2023}
}
@inproceedings{huang2023large,
  title={Large language models cannot self-correct reasoning yet},
  author={Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  booktitle={ICLR},
  year={2024}
}
@inproceedings{chen2024reconcile,
      title={ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs}, 
      author={Justin Chih-Yao Chen and Swarnadeep Saha and Mohit Bansal},
      year={2024},
      booktitle={ACL}
}

@inproceedings{wang2023selfconsistency,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      booktitle={ICLR}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{mao2020model,
  title={Model-free non-stationary {RL}: Near-optimal regret and applications in multi-agent {RL} and inventory control},
  author={Mao, Weichao and Zhang, Kaiqing and Zhu, Ruihao and Simchi-Levi, David and Ba{\c{s}}ar, Tamer},
  journal={arXiv preprint arXiv:2010.03161},
  year={2020}
}
@article{blum2007external,
  title={From external to internal regret},
  author={Blum, Avrim and Mansour, Yishay},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={6},
  year={2007}
}
@book{van2000asymptotic,
  title={Asymptotic statistics},
  author={Van der Vaart, Aad W},
  volume={3},
  year={2000},
  publisher={Cambridge university press}
}
@article{hofbauer2002global,
  title={On the global convergence of stochastic fictitious play},
  author={Hofbauer, Josef and Sandholm, William H},
  journal={Econometrica},
  volume={70},
  number={6},
  pages={2265--2294},
  year={2002},
  publisher={Wiley Online Library}
}
@article{
reed2022generalist,
title={A Generalist Agent},
author={Scott Reed and Konrad Zolna and Emilio Parisotto and Sergio G{\'o}mez Colmenarejo and Alexander Novikov and Gabriel Barth-maron and Mai Gim{\'e}nez and Yury Sulsky and Jackie Kay and Jost Tobias Springenberg and Tom Eccles and Jake Bruce and Ali Razavi and Ashley Edwards and Nicolas Heess and Yutian Chen and Raia Hadsell and Oriol Vinyals and Mahyar Bordbar and Nando de Freitas},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2022},
url={https://openreview.net/forum?id=1ikK0kHjvj},
note={Featured Certification, Outstanding Certification}
}
@article{balseiro2019learning,
  title={Learning in repeated auctions with budgets: {R}egret minimization and equilibrium},
  author={Balseiro, Santiago R and Gur, Yonatan},
  journal={Management Science},
  volume={65},
  number={9},
  pages={3952--3968},
  year={2019},
  publisher={INFORMS}
}
@inproceedings{nekipelov2015econometrics,
  title={Econometrics for learning agents},
  author={Nekipelov, Denis and Syrgkanis, Vasilis and Tardos, Eva},
  booktitle={ACM Conference on Economics and Computation},
  pages={1--18},
  year={2015}
}
@article{erev1998predicting,
  title={Predicting how people play games: {R}einforcement learning in experimental games with unique, mixed strategy equilibria},
  author={Erev, Ido and Roth, Alvin E},
  journal={American Economic Review},
  pages={848--881},
  year={1998},
  publisher={JSTOR}
}
@article{fudenberg1993learning,
  title={Learning mixed equilibria},
  author={Fudenberg, Drew and Kreps, David M},
  journal={Games and Economic Behavior},
  volume={5},
  number={3},
  pages={320--367},
  year={1993},
  publisher={Elsevier}
}
@article{liu2023chain,
  title={Chain of hindsight aligns language models with feedback},
  author={Liu, Hao and Sferrazza, Carmelo and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2302.02676},
  volume={3},
  year={2023}
}

@article{zimmert2021tsallis,
  title={Tsallis-inf: An optimal algorithm for stochastic and adversarial bandits},
  author={Zimmert, Julian and Seldin, Yevgeny},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={1310--1358},
  year={2021},
  publisher={JMLRORG}
}
@article{kasprzak2022good,
  title={How good is your Gaussian approximation of the posterior? Finite-sample computable error bounds for a variety of useful divergences},
  author={Kasprzak, Miko{\l}aj J and Giordano, Ryan and Broderick, Tamara},
  journal={arXiv preprint arXiv:2209.14992},
  year={2022}
}
@article{besbes2014stochastic,
  title={Stochastic multi-armed-bandit problem with non-stationary rewards},
  author={Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@article{swan2023math,
  title={Math agents: Computational infrastructure, mathematical embedding, and genomics},
  author={Swan, Melanie and Kido, Takashi and Roland, Eric and Santos, Renato P dos},
  journal={arXiv preprint arXiv:2307.02502},
  year={2023}
}
@article{wang2023voyager,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}
@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{shen2023hugginggpt,
  title={Hugginggpt: Solving {AI}  tasks with chatgpt and its friends in huggingface},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Neural Information Processing Systems},
  year={2023}
}
@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={International Conference on Machine Learning},
  pages={928--936},
  year={2003}
}
@inproceedings{blum2008regret,
  title={Regret minimization and the price of total anarchy},
  author={Blum, Avrim and Hajiaghayi, MohammadTaghi and Ligett, Katrina and Roth, Aaron},
  booktitle={Proceedings of the fortieth annual ACM symposium on Theory of computing},
  pages={373--382},
  year={2008}
}
@article{roughgarden2017price,
  title={The price of anarchy in auctions},
  author={Roughgarden, Tim and Syrgkanis, Vasilis and Tardos, Eva},
  journal={Journal of Artificial Intelligence Research},
  volume={59},
  pages={59--101},
  year={2017}
}
@inproceedings{syrgkanis2013composable,
  title={Composable and efficient mechanisms},
  author={Syrgkanis, Vasilis and Tardos, Eva},
  booktitle={Proceedings of the forty-fifth annual ACM symposium on Theory of computing},
  pages={211--220},
  year={2013}
}
@article{roughgarden2015intrinsic,
  title={Intrinsic robustness of the price of anarchy},
  author={Roughgarden, Tim},
  journal={Journal of the ACM (JACM)},
  volume={62},
  number={5},
  pages={1--42},
  year={2015},
  publisher={ACM New York, NY, USA}
}
@article{littlestone1994weighted,
  title={The weighted majority algorithm},
  author={Littlestone, Nick and Warmuth, Manfred K},
  journal={Information and computation},
  volume={108},
  number={2},
  pages={212--261},
  year={1994},
  publisher={Elsevier}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}
@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3-4},
  pages={285--294},
  year={1933},
  publisher={Oxford University Press}
}
@article{robbins1952some,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  year={1952}
}
@article{shalev2007primal,
  title={A primal-dual perspective of online learning algorithms},
  author={Shalev-Shwartz, Shai and Singer, Yoram},
  journal={Machine Learning},
  volume={69},
  pages={115--142},
  year={2007},
  publisher={Springer}
}
@article{freund1997decision,
  title={A decision-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Journal of computer and system sciences},
  volume={55},
  number={1},
  pages={119--139},
  year={1997},
  publisher={Elsevier}
}
@article{kalai2005efficient,
  title={Efficient algorithms for online decision problems},
  author={Kalai, Adam and Vempala, Santosh},
  journal={Journal of Computer and System Sciences},
  volume={71},
  number={3},
  pages={291--307},
  year={2005},
  publisher={Elsevier}
}
@article{arora2012multiplicative,
  title={The multiplicative weights update method: a meta-algorithm and applications},
  author={Arora, Sanjeev and Hazan, Elad and Kale, Satyen},
  journal={Theory of computing},
  volume={8},
  number={1},
  pages={121--164},
  year={2012},
  publisher={Theory of Computing Exchange}
}
@article{jiang2023latent,
  title={A latent space theory for emergent abilities in large language models},
  author={Jiang, Hui},
  journal={arXiv preprint arXiv:2304.09960},
  year={2023}
}
@article{wang2023large,
  title={Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning},
  author={Wang, Xinyi and Zhu, Wanrong and Wang, William Yang},
  journal={International Conference on Machine Learning 2023 Workshop ES-FoMO},
  year={2023}
}
@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={International Conference on Learning Representations},
  year={2022}
}
@book{young2004strategic,
  title={Strategic learning and its limits},
  author={Young, H Peyton},
  year={2004},
  publisher={OUP Oxford}
}
@book{camerer2011behavioral,
  title={Behavioral game theory: Experiments in strategic interaction},
  author={Camerer, Colin F},
  year={2011},
  publisher={Princeton University Press}
}
@book{fudenberg1998theory,
  title={The theory of learning in games},
  author={Fudenberg, Drew and Levine, David K},
  volume={2},
  year={1998},
  publisher={MIT Press}
}
@article{xu2023exploring,
  title={Exploring large language models for communication games: An empirical study on werewolf},
  author={Xu, Yuzhuang and Wang, Shuo and Li, Peng and Luo, Fuwen and Wang, Xiaolong and Liu, Weidong and Liu, Yang},
  journal={arXiv preprint arXiv:2309.04658},
  year={2023}
}
@article{mukobi2023welfare,
  title={Welfare Diplomacy: Benchmarking Language Model Cooperation},
  author={Mukobi, Gabriel and Erlebach, Hannah and Lauffer, Niklas and Hammond, Lewis and Chan, Alan and Clifton, Jesse},
  journal={arXiv preprint arXiv:2310.08901},
  year={2023}
}
@book{berge1877topological,
  title={Topological spaces: Including a treatment of multi-valued functions, vector spaces and convexity},
  author={Berge, Claude},
  year={1877},
  publisher={Oliver \& Boyd}
}
@inproceedings{wei2021non,
  title={Non-stationary reinforcement learning without prior knowledge: An optimal black-box approach},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle={Conference on learning theory},
  pages={4300--4354},
  year={2021},
  organization={PMLR}
}
@article{brookins2023playing,
  title={Playing games with {GPT}: What can we learn about a large language model from canonical strategic games?},
  author={Brookins, Philip and DeBacker, Jason Matthew},
  journal={Available at SSRN 4493398},
  year={2023}
}
@article{cesa1996worst,
  title={Worst-case quadratic loss bounds for prediction using linear functions and gradient descent},
  author={Cesa-Bianchi, Nicolo and Long, Philip M and Warmuth, Manfred K},
  journal={IEEE Transactions on Neural Networks},
  volume={7},
  number={3},
  pages={604--619},
  year={1996},
  publisher={IEEE}
}
@book{shalev2007online,
  title={Online learning: Theory, algorithms, and applications},
  author={Shalev-Shwartz, Shai},
  year={2007},
  publisher={Hebrew University}
}
@article{chen2023emergence,
  title={The emergence of economic rationality of GPT},
  author={Chen, Yiting and Liu, Tracy Xiao and Shan, You and Zhong, Songfa},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={51},
  pages={e2316205120},
  year={2023},
  publisher={National Acad Sciences}
}
@article{zhang2023building,
  title={Building cooperative embodied agents modularly with large language models},
  author={Zhang, Hongxin and Du, Weihua and Shan, Jiaming and Zhou, Qinhong and Du, Yilun and Tenenbaum, Joshua B and Shu, Tianmin and Gan, Chuang},
  journal={International Conference on Learning Representations},
  year={2024}
}
@article{chan2023chateval,
  title={Chateval: {T}owards better llm-based evaluators through multi-agent debate},
  author={Chan, Chi-Min and Chen, Weize and Su, Yusheng and Yu, Jianxuan and Xue, Wei and Zhang, Shanghang and Fu, Jie and Liu, Zhiyuan},
  journal={International Conference on Learning Representations},
  year={2024}
}
@article{chen2023agentverse,
  title={Agentverse: {F}acilitating multi-agent collaboration and exploring emergent behaviors in agents},
  author={Chen, Weize and Su, Yusheng and Zuo, Jingwei and Yang, Cheng and Yuan, Chenfei and Qian, Chen and Chan, Chi-Min and Qin, Yujia and Lu, Yaxi and Xie, Ruobing and others},
  journal={International Conference on Learning Representations},
  year={2024}
}
@article{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}
@article{danskin1966theory,
  title={The theory of max-min, with applications},
  author={Danskin, John M},
  journal={SIAM Journal on Applied Mathematics},
  volume={14},
  number={4},
  pages={641--664},
  year={1966},
  publisher={SIAM}
}
@book{danskin2012theory,
  title={The theory of max-min and its application to weapons allocation problems},
  author={Danskin, John M},
  volume={5},
  year={2012},
  publisher={Springer Science \& Business Media}
}
@inproceedings{lattimore2021mirror,
  title={Mirror descent and the information ratio},
  author={Lattimore, Tor and Gyorgy, Andras},
  booktitle={Conference on Learning Theory},
  pages={2965--2992},
  year={2021},
  organization={PMLR}
}
@article{lattimore2020improved,
  title={Improved regret for zeroth-order adversarial bandit convex optimisation},
  author={Lattimore, Tor},
  journal={Mathematical Statistics and Learning},
  volume={2},
  number={3},
  pages={311--334},
  year={2020}
}
@software{Significant_Gravitas_AutoGPT,
author = {{Significant Gravitas}},
title = {AutoGPT},
url = {https://github.com/Significant-Gravitas/AutoGPT},
licence = {MIT},
year={2023}
}
@article{opaluch1989rational,
  title={Rational roots of “irrational” behavior: New theories of economic decision-making},
  author={Opaluch, James J and Segerson, Kathleen},
  journal={Northeastern Journal of Agricultural and Resource Economics},
  volume={18},
  number={2},
  pages={81--95},
  year={1989},
  publisher={Cambridge University Press}
}
@article{ge2023provable,
  title={On the provable advantage of unsupervised pretraining},
  author={Ge, Jiawei and Tang, Shange and Fan, Jianqing and Jin, Chi},
  journal={arXiv preprint arXiv:2303.01566},
  year={2023}
}
@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={International Conference on Machine Learning},
  year={2023}
}
@article{wang2023describe,
  title={Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents},
  author={Wang, Zihao and Cai, Shaofei and Liu, Anji and Ma, Xiaojian and Liang, Yitao},
  journal={Advances in neural information processing systems},
  year={2023}
}
@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}
@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={International Conference on Learning Representations},
  year={2023}
}
@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}
@inproceedings{valmeekam2023planbench,
  title={PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change},
  author={Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2023}
}
@article{gagne1974instruction,
  title={Instruction and the conditions of learning},
  author={Gagne, Robert M},
  journal={Psychology of school learning: Views of the learner},
  volume={1},
  pages={153--175},
  year={1974},
  publisher={ERIC}
}
@article{al2011effect,
  title={The effect of project-based learning on collaboration skills of high school students},
  author={Al Rasyid, Muhamad and Khoirunnisa, Fitriah},
  journal={Jurnal Pendidikan Sains (Jps)},
  volume={9},
  number={1},
  pages={113--119},
  year={2011}
}
@book{hertz2013learning,
  title={Learning to cooperate, cooperating to learn},
  author={Hertz-Lazarowitz, R and Kagan, S and Sharan, Shlomo and Slavin, R and Webb, Clark},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@article{macy1991learning,
  title={Learning to cooperate: Stochastic and tacit collusion in social exchange},
  author={Macy, Michael W},
  journal={American Journal of Sociology},
  volume={97},
  number={3},
  pages={808--843},
  year={1991},
  publisher={University of Chicago Press}
}
@inproceedings{hao2023reasoning,
    title = "Reasoning with Language Model is Planning with World Model",
    author = "Hao, Shibo  and
      Gu, Yi  and
      Ma, Haodi  and
      Hong, Joshua  and
      Wang, Zhen  and
      Wang, Daisy  and
      Hu, Zhiting",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.507",
    doi = "10.18653/v1/2023.emnlp-main.507",
    pages = "8154--8173",
    abstract = "Large language models (LLMs) have shown remarkable reasoning capabilities, particularly with Chain-of-Thought-style prompts. However, LLMs can still struggle with problems that are easy for humans, such as generating action plans for executing tasks or performing complex math or logical reasoning. This is due to LLMs{'} absence of an internal world model for predicting world states (e.g., environment status, variable values) and simulating long-term action outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, Reasoning via Planning (RAP). RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm (based on Monte Carlo Tree Search) for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and task-specific rewards, properly balancing exploration v.s. exploitation to achieve a high-reward reasoning path efficiently. We apply RAP to a variety of challenging reasoning problems, such as plan generation, math reasoning, and logical inference. Empirical results demonstrate the superiority of RAP over various strong baselines, including CoT and least-to-most prompting with self-consistency, e.g., RAP on LLaMA-33B surpasses CoT on GPT-4 with 33{\%} relative improvement in plan generation.",
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}
@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={Transactions on Machine Learning Research},
  year={2023}
}
@article{cheng2023transformers,
  title={Transformers Implement Functional Gradient Descent to Learn Non-Linear Functions In Context},
  author={Cheng, Xiang and Chen, Yuxin and Sra, Suvrit},
  journal={arXiv preprint arXiv:2312.06528},
  year={2023}
}
@article{engel2023integrating,
  title={Integrating Machine Behavior into Human Subject Experiments: A User-Friendly Toolkit and Illustrations},
  author={Engel, Christoph and Grossmann, Max RP and Ockenfels, Axel},
  journal={Available at SSRN},
  year={2023}
}
@inproceedings{fan2023can,
  title={Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis},
  author={Fan, Caoyun and Chen, Jindou and Jin, Yaohui and He, Hao},
  booktitle={AAAI},
  year={2024}
}
@article{schaeffer2023emergent,
  title={Are emergent abilities of Large Language Models a mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}
@article{lore2023strategic,
  title={Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing},
  author={Lor{\`e}, Nunzio and Heydari, Babak},
  journal={arXiv preprint arXiv:2309.05898},
  year={2023}
}
@book{cesa2006prediction,
  title={Prediction, Learning, and Games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge University Press}
}
@inproceedings{lattimore2019information,
  title={An information-theoretic approach to minimax regret in partial monitoring},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  booktitle={Conference on Learning Theory},
  pages={2111--2139},
  year={2019},
  organization={PMLR}
}
@article{foster2022complexity,
  title={On the complexity of adversarial decision making},
  author={Foster, Dylan J and Rakhlin, Alexander and Sekhari, Ayush and Sridharan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35404--35417},
  year={2022}
}
@inproceedings{kirschner2023regret,
  title={Regret Minimization via Saddle Point Optimization},
  author={Kirschner, Johannes and Bakhtiari, Alireza and Chandak, Kushagra and Tkachuk, Volodymyr and Szepesvari, Csaba},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@article{ding2022myopic,
  title={Myopic Quantal Response Policy: Thompson Sampling Meets Behavioral Economics},
  author={Ding, Jingying and Feng, Yifan and Rong, Ying},
  journal={arXiv preprint arXiv:2207.01028},
  year={2022}
}
@article{hazan2016introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}
@article{shalev2012online,
  title={Online learning and online convex optimization},
  author={Shalev-Shwartz, Shai},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={2},
  pages={107--194},
  year={2012},
  publisher={Now Publishers, Inc.}
}
@article{waterhouse1983symmetric,
  title={Do symmetric problems have symmetric solutions?},
  author={Waterhouse, William C},
  journal={The American Mathematical Monthly},
  volume={90},
  number={6},
  pages={378--387},
  year={1983},
  publisher={Taylor \& Francis}
}
@article{mcfadden1976quantal,
  title={Quantal choice analaysis: A survey},
  author={McFadden, Daniel L},
  journal={Annals of Economic and Social Measurement, Volume 5, number 4},
  pages={363--390},
  year={1976},
  publisher={NBER}
}
@article{mckelvey1995quantal,
  title={Quantal response equilibria for normal form games},
  author={McKelvey, Richard D and Palfrey, Thomas R},
  journal={Games and economic behavior},
  volume={10},
  number={1},
  pages={6--38},
  year={1995},
  publisher={Elsevier}
}
@article{li2017beyond,
  title={Beyond the Hazard Rate: More Perturbation Algorithms for Adversarial Multi-armed Bandits.},
  author={Li, Zifan and Tewari, Ambuj},
  journal={J. Mach. Learn. Res.},
  volume={18},
  pages={183--1},
  year={2017}
}
@inproceedings{liu2023nonstationary,
  title={Nonstationary bandit learning via predictive sampling},
  author={Liu, Yueyang and Van Roy, Benjamin and Xu, Kuang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6215--6244},
  year={2023},
  organization={PMLR}
}
@article{lin2023transformers,
  title={Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining},
  author={Lin, Licong and Bai, Yu and Mei, Song},
  journal={International Conference on Learning Representations},
  year={2024}
}
@inproceedings{kim2020randomized,
  title={Randomized exploration for non-stationary stochastic linear bandits},
  author={Kim, Baekjin and Tewari, Ambuj},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={71--80},
  year={2020},
  organization={PMLR}
}
@inproceedings{wu2018learning,
  title={Learning contextual bandits in a non-stationary environment},
  author={Wu, Qingyun and Iyer, Naveen and Wang, Hongning},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={495--504},
  year={2018}
}
@article{abernethy2015fighting,
  title={Fighting bandits with a new kind of smoothness},
  author={Abernethy, Jacob D and Lee, Chansoo and Tewari, Ambuj},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}
@inproceedings{abernethy2014online,
  title={Online linear optimization via smoothing},
  author={Abernethy, Jacob and Lee, Chansoo and Sinha, Abhinav and Tewari, Ambuj},
  booktitle={Conference on Learning Theory},
  pages={807--823},
  year={2014},
  organization={PMLR}
}
@article{syrgkanis2015fast,
  title={Fast convergence of regularized learning in games},
  author={Syrgkanis, Vasilis and Agarwal, Alekh and Luo, Haipeng and Schapire, Robert E},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}
@book{robinson2005topology,
  title={The topology of the 2x2 games: a new periodic table},
  author={Robinson, David and Goforth, David},
  volume={3},
  year={2005},
  publisher={Psychology Press}
}
@article{sadasivan2023can,
  title={Can ai-generated text be reliably detected?},
  author={Sadasivan, Vinu Sankar and Kumar, Aounon and Balasubramanian, Sriram and Wang, Wenxiao and Feizi, Soheil},
  journal={arXiv preprint arXiv:2303.11156},
  year={2023}
}
@article{de2023llm,
  title={LLM-Informed Multi-Armed Bandit Strategies for Non-Stationary Environments},
  author={de Curt{\`o}, J and de Zarz{\`a}, I and Roig, Gemma and Cano, Juan Carlos and Manzoni, Pietro and Calafate, Carlos T},
  journal={Electronics},
  volume={12},
  number={13},
  pages={2814},
  year={2023},
  publisher={MDPI}
}
@article{dasgupta2022language,
  title={Language models show human-like content effects on reasoning},
  author={Dasgupta, Ishita and Lampinen, Andrew K and Chan, Stephanie CY and Creswell, Antonia and Kumaran, Dharshan and McClelland, James L and Hill, Felix},
  journal={arXiv preprint arXiv:2207.07051},
  year={2022}
}
@article{chen2020hedging,
  title={Hedging in games: Faster convergence of external and swap regrets},
  author={Chen, Xi and Peng, Binghui},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18990--18999},
  year={2020}
}
@book{ahsanullah2013introduction,
  title={An introduction to order statistics},
  author={Ahsanullah, Mohammad and Nevzorov, Valery B and Shakil, Mohammad},
  volume={8},
  year={2013},
  publisher={Springer}
}
@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge university press}
}
@article{gao2017properties,
  title={On the properties of the softmax function with application in game theory and reinforcement learning},
  author={Gao, Bolin and Pavel, Lacra},
  journal={arXiv preprint arXiv:1704.00805},
  year={2017}
}
@article{von2023uncovering,
  title={Uncovering mesa-optimization algorithms in transformers},
  author={von Oswald, Johannes and Niklasson, Eyvind and Schlegel, Maximilian and Kobayashi, Seijin and Zucchet, Nicolas and Scherrer, Nino and Miller, Nolan and Sandler, Mark and Vladymyrov, Max and Pascanu, Razvan and others},
  journal={arXiv preprint arXiv:2309.05858},
  year={2023}
}
@article{daskalakis2021near,
  title={Near-optimal no-regret learning in general games},
  author={Daskalakis, Constantinos and Fishelson, Maxwell and Golowich, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27604--27616},
  year={2021}
}
@article{rakhlin2013optimization,
  title={Optimization, learning, and games with predictable sequences},
  author={Rakhlin, Sasha and Sridharan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}
@inproceedings{liu2023reason,
  title={Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM Agents},
  author={Liu, Zhihan and Hu, Hao and Zhang, Shenao and Guo, Hongyi and Ke, Shuqi and Liu, Boyi and Wang, Zhaoran},
  booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},
  year={2023}
}
@article{zhou2023far,
  title={How FaR Are Large Language Models From Agents with Theory-of-Mind?},
  author={Zhou, Pei and Madaan, Aman and Potharaju, Srividya Pranavi and Gupta, Aditya and McKee, Kevin R and Holtzman, Ari and Pujara, Jay and Ren, Xiang and Mishra, Swaroop and Nematzadeh, Aida and others},
  journal={arXiv preprint arXiv:2310.03051},
  year={2023}
}
@article{zhao2023competeai,
  title={CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents},
  author={Zhao, Qinlin and Wang, Jindong and Zhang, Yixuan and Jin, Yiqiao and Zhu, Kaijie and Chen, Hao and Xie, Xing},
  journal={arXiv preprint arXiv:2310.17512},
  year={2023}
}
@misc{
guo2024large,
title={Large Language Models as Rational Players in Competitive Economics Games},
author={Shangmin Guo and Haochuan Wang and Haoran Bu and Yi Ren and Dianbo Sui and Yu-Ming Shang and Siting Lu},
year={2024},
url={https://openreview.net/forum?id=NMPLBbjYFq}
}
@article{anony2023gameagent, 
title={Large Language Models as Gaming Agents}, 
author={Anonymous},
journal={International Conference on Learning Representations 2024 Submission}, 
year = {2023},
url={https://openreview.net/forum?id=iS3fQooCaa}
}
@article{xu2023language,
  title={Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game},
  author={Xu, Zelai and Yu, Chao and Fang, Fei and Wang, Yu and Wu, Yi},
  journal={arXiv preprint arXiv:2310.18940},
  year={2023}
}
@article{meta2022human,
  title={Human-level play in the game of Diplomacy by combining language models with strategic reasoning},
  author={Bakhtin, Anton and Brown, Noam and Dinan, Emily and Farina, Gabriele and Flaherty, Colin and Fried, Daniel and Goff, Andrew and Gray, Jonathan and Hu, Hengyuan and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1067--1074},
  year={2022},
  publisher={American Association for the Advancement of Science}
}
@article{tarzanagh2023transformers,
  title={Transformers as support vector machines},
  author={Tarzanagh, Davoud Ataee and Li, Yingcong and Thrampoulidis, Christos and Oymak, Samet},
  journal={arXiv preprint arXiv:2308.16898},
  year={2023}
}
@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}
@article{neu2015explore,
  title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits},
  author={Neu, Gergely},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}
@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}
@article{hannan1957approximation,
  title={Approximation to Bayes risk in repeated play},
  author={Hannan, James},
  journal={Contributions to the Theory of Games},
  volume={3},
  pages={97--139},
  year={1957}
}
@article{blackwell1956analog,
  title={An analog of the minimax theorem for vector payoffs.},
  author={Blackwell, David},
  year={1956}
}
@article{li2023camel,
  title={Camel: Communicative agents for" mind" exploration of large scale language model society},
  author={Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
  journal={Neural Information Processing
Systems},
  year={2023}
}
@article{bai2023transformers,
  title={Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection},
  author={Bai, Yu and Chen, Fan and Wang, Huan and Xiong, Caiming and Mei, Song},
  journal={Advanced in Neural Information Processing
Systems},
  year={2023}
}
@article{argyle2023out,
  title={Out of one, many: Using language models to simulate human samples},
  author={Argyle, Lisa P and Busby, Ethan C and Fulda, Nancy and Gubler, Joshua R and Rytting, Christopher and Wingate, David},
  journal={Political Analysis},
  volume={31},
  number={3},
  pages={337--351},
  year={2023},
  publisher={Cambridge University Press}
}
@article{li2023you,
  title={Are you in a Masquerade? Exploring the Behavior and Impact of Large Language Model Driven Social Bots in Online Social Networks},
  author={Li, Siyu and Yang, Jin and Zhao, Kui},
  journal={arXiv preprint arXiv:2307.10337},
  year={2023}
}
@article{li2023quantifying,
  title={Quantifying the Impact of Large Language Models on Collective Opinion Dynamics},
  author={Li, Chao and Su, Xing and Fan, Chao and Han, Haoying and Xue, Cong and Zheng, Chunmo},
  journal={arXiv preprint arXiv:2308.03313},
  year={2023}
}
@article{yun2019transformers,
  title={Are transformers universal approximators of sequence-to-sequence functions?},
  author={Yun, Chulhee and Bhojanapalli, Srinadh and Rawat, Ankit Singh and Reddi, Sashank J and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1912.10077},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={International Conference on Learning Representations},
  year={2021}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}
@inproceedings{min2022rethinking,
    title = "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    author = "Min, Sewon  and
      Lyu, Xinxi  and
      Holtzman, Ari  and
      Artetxe, Mikel  and
      Lewis, Mike  and
      Hajishirzi, Hannaneh  and
      Zettlemoyer, Luke",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.759",
    doi = "10.18653/v1/2022.emnlp-main.759",
    pages = "11048--11064",
    abstract = "Large language models (LMs) are able to in-context learn{---}perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required{---}randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of endtask performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone.",
}

@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={International Conference on Learning Representations},
  year={2023}
}
@inproceedings{von2023transformers,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  booktitle={International Conference on Machine Learning},
  pages={35151--35174},
  year={2023},
  organization={PMLR}
}
@inproceedings{dai2022can,
    title = "Why Can {GPT} Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
    author = "Dai, Damai  and
      Sun, Yutao  and
      Dong, Li  and
      Hao, Yaru  and
      Ma, Shuming  and
      Sui, Zhifang  and
      Wei, Furu",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.247",
    doi = "10.18653/v1/2023.findings-acl.247",
    pages = "4005--4019",
    abstract = "Large pretrained language models have shown surprising in-context learning (ICL) ability. With a few demonstration input-label pairs, they can predict the label for an unseen input without parameter updates. Despite the great success in performance, its working mechanism still remains an open question. In this paper, we explain language models as meta-optimizers and understand in-context learning as implicit finetuning. Theoretically, we figure out that Transformer attention has a dual form of gradient descent. On top of it, we understand ICL as follows: GPT first produces meta-gradients according to the demonstration examples, and then these meta-gradients are applied to the original GPT to build an ICL model. We comprehensively compare the behaviors of in-context learning and explicit finetuning on real tasks to provide empirical evidence that supports our understanding. Experimental results show that in-context learning behaves similarly to explicit finetuning from multiple perspectives. Inspired by the dual form between Transformer attention and gradient descent, we design a momentum-based attention by analogy with gradient descent with momentum. The improved performance over vanilla attention further supports our understanding from another perspective, and more importantly, shows the potential to utilize our understanding for future model design. The code is available at \url{https://aka.ms/icl}.",
}

@article{li2023transformers,
  title={Transformers as algorithms: Generalization and stability in in-context learning},
  author={Li, Yingcong and Ildiz, Muhammed Emrullah and Papailiopoulos, Dimitris and Oymak, Samet},
  year={2023},
  journal = {International Conference on Machine Learning}
}
@article{becker1962irrational,
  title={Irrational behavior and economic theory},
  author={Becker, Gary S},
  journal={Journal of political economy},
  volume={70},
  number={1},
  pages={1--13},
  year={1962},
  publisher={The University of Chicago Press}
}
@inproceedings{rakhlin2013online,
  title={Online learning with predictable sequences},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  pages={993--1019},
  year={2013},
  organization={PMLR}
}
@article{zhang2023and,
  title={What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization},
  author={Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2305.19420},
  year={2023}
}
@article{ahn2023transformers,
  title={Transformers learn to implement preconditioned gradient descent for in-context learning},
  author={Ahn, Kwangjun and Cheng, Xiang and Daneshmand, Hadi and Sra, Suvrit},
  journal={Advanced in Neural Information Processing Systems},
  year={2023}
}
@article{zhang2023trained,
  title={Trained Transformers Learn Linear Models In-Context},
  author={Zhang, Ruiqi and Frei, Spencer and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2306.09927},
  year={2023}
}
@article{mahankali2023one,
  title={One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention},
  author={Mahankali, Arvind and Hashimoto, Tatsunori B and Ma, Tengyu},
  journal={International Conference on Learning Representations},
  year={2023}
}
@inproceedings{liang2023encouraging,
  title={Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
  author={Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Tu, Zhaopeng and Shi, Shuming},
  booktitle={EMNLP},
  year={2024}
}
@article{zhu2023ghost,
  title={Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}
@article{laskin2022context,
  title={In-context reinforcement learning with algorithm distillation},
  author={Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others},
  journal={International Conference on Learning Representations},
  year={2023}
}
@inproceedings{yang2023looped,
  title={Looped Transformers are Better at Learning Learning Algorithms},
  author={Yang, Liu and Lee, Kangwook and Nowak, Robert D and Papailiopoulos, Dimitris},
  booktitle={Workshop on Efficient Systems for Foundation Models@ ICML2023},
  year={2023}
}
@article{fu2023improving,
  title={Improving language model negotiation with self-play and in-context learning from ai feedback},
  author={Fu, Yao and Peng, Hao and Khot, Tushar and Lapata, Mirella},
  journal={arXiv preprint arXiv:2305.10142},
  year={2023}
}
@inproceedings{xiong2023diving,
    title = "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
    author = "Xiong, Kai  and
      Ding, Xiao  and
      Cao, Yixin  and
      Liu, Ting  and
      Qin, Bing",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.508",
    doi = "10.18653/v1/2023.findings-emnlp.508",
    pages = "7572--7590",
    abstract = "Large Language Models (LLMs) have shown impressive capabilities in various applications, but they still face various inconsistency issues. Existing works primarily focus on the inconsistency issues within a single LLM, while we complementarily explore the inter-consistency among multiple LLMs for collaboration. To examine whether LLMs can collaborate effectively to achieve a consensus for a shared goal, we focus on commonsense reasoning, and introduce a formal debate framework (FORD) to conduct a three-stage debate among LLMs with real-world scenarios alignment: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on various datasets, LLMs can effectively collaborate to reach a consensus despite noticeable inter-inconsistencies, but imbalances in their abilities can lead to domination by superior LLMs. Leveraging a more advanced LLM like GPT-4 as an authoritative judge can boost collaboration performance. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for developing future collaboration methods. Codes and data are available at https://github.com/Waste-Wood/FORD.",
}

@article{qian2023communicative,
  title={Communicative agents for software development},
  author={Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2307.07924},
  year={2023}
}
@article{hong2023metagpt,
  title={Metagpt: Meta programming for multi-agent collaborative framework},
  author={Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and others},
  journal={nternational Conference on Learning Representations},
  year={2024}
}

@article{wu2023autogen,
  title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}

@inproceedings{du2023improving,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  booktitle={ICML},
  year={2024}
}
@article{schick2022peer,
  title={Peer: A collaborative language model},
  author={Schick, Timo and Dwivedi-Yu, Jane and Jiang, Zhengbao and Petroni, Fabio and Lewis, Patrick and Izacard, Gautier and You, Qingfei and Nalmpantis, Christoforos and Grave, Edouard and Riedel, Sebastian},
  journal={International Conference on Learning Representations},
  year={2023}
}
@article{giannou2023looped,
  title={Looped transformers as programmable computers},
  author={Giannou, Angeliki and Rajput, Shashank and Sohn, Jy-yong and Lee, Kangwook and Lee, Jason D and Papailiopoulos, Dimitris},
  journal={International Conference on Machine Learning},
  year={2023}
}

@article{arora2023theory,
  title={A Theory for Emergence of Complex Skills in Language Models},
  author={Arora, Sanjeev and Goyal, Anirudh},
  journal={arXiv preprint arXiv:2307.15936},
  year={2023}
}
@article{zhao2023antgpt,
  title={AntGPT: Can Large Language Models Help Long-term Action Anticipation from Videos?},
  author={Zhao, Qi and Zhang, Ce and Wang, Shijie and Fu, Changcheng and Agarwal, Nakul and Lee, Kwonjoon and Sun, Chen},
  journal={arXiv preprint arXiv:2307.16368},
  year={2023}
}
@article{scherrer2023evaluating,
  title={Evaluating the Moral Beliefs Encoded in LLMs},
  author={Scherrer, Nino and Shi, Claudia and Feder, Amir and Blei, David M},
  journal={arXiv preprint arXiv:2307.14324},
  year={2023}
}
@article{hartmann2023political,
  title={The political ideology of conversational AI: Converging evidence on ChatGPT's pro-environmental, left-libertarian orientation},
  author={Hartmann, Jochen and Schwenzow, Jasper and Witte, Maximilian},
  journal={arXiv preprint arXiv:2301.01768},
  year={2023}
}
@article{santurkar2023whose,
  title={Whose opinions do language models reflect?},
  author={Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2303.17548},
  year={2023}
}
@article{coda2023inducing,
  title={Inducing anxiety in large language models increases exploration and bias},
  author={Coda-Forno, Julian and Witte, Kristin and Jagadish, Akshay K and Binz, Marcel and Akata, Zeynep and Schulz, Eric},
  journal={arXiv preprint arXiv:2304.11111},
  year={2023}
}
@article{gupta2023chatgpt,
  title={Are ChatGPT and GPT-4 Good Poker Players?--A Pre-Flop Analysis},
  author={Gupta, Akshat},
  journal={arXiv preprint arXiv:2308.12466},
  year={2023}
}
@article{tsai2023can,
  title={Can Large Language Models Play Text Games Well? Current State-of-the-Art and Open Questions},
  author={Tsai, Chen Feng and Zhou, Xiaochen and Liu, Sierra S and Li, Jing and Yu, Mo and Mei, Hongyuan},
  journal={arXiv preprint arXiv:2304.02868},
  year={2023}
}
@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={Transactions on Machine Learning Research},
  year={2022}
}
@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}
@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}
@article{vemprala2023chatgpt,
  title={Chatgpt for robotics: Design principles and model abilities},
  author={Vemprala, Sai and Bonatti, Rogerio and Bucker, Arthur and Kapoor, Ashish},
  journal={Microsoft Auton. Syst. Robot. Res},
  volume={2},
  pages={20},
  year={2023}
}
@article{lu2023emergent,
  title={Are Emergent Abilities in Large Language Models just In-Context Learning?},
  author={Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2309.01809},
  year={2023}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{akata2023playing,
  title={Playing repeated games with Large Language Models},
  author={Akata, Elif and Schulz, Lion and Coda-Forno, Julian and Oh, Seong Joon and Bethge, Matthias and Schulz, Eric},
  journal={arXiv preprint arXiv:2305.16867},
  year={2023}
}
@article{wei2022statistically,
  title={Statistically meaningful approximation: a case study on approximating turing machines with transformers},
  author={Wei, Colin and Chen, Yining and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12071--12083},
  year={2022}
}

@article{fraser2022does,
  title={Does Moral Code Have a Moral Code? Probing Delphi's Moral Philosophy},
  author={Fraser, Kathleen C and Kiritchenko, Svetlana and Balkir, Esma},
  journal={arXiv preprint arXiv:2205.12771},
  year={2022}
}
@inproceedings{abdulhai2022moral,
  title={Moral Foundations of Large Language Models},
  author={Abdulhai, Marwa and Crepy, Cl{\'e}ment and Valter, Daria and Canny, John and Jaques, Natasha},
  booktitle={AAAI 2023 Workshop on Representation Learning for Responsible Human-Centric AI},
  year={2022}
}
@article{openai2023gpt4,
    author = {Openai},
    title = {Gpt-4 technical report},
    year = {2023}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@inproceedings{park2022social,
  title={Social simulacra: Creating populated prototypes for social computing systems},
  author={Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages={1--18},
  year={2022}
}
@inproceedings{park2023generative,
author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},
title = {Generative Agents: Interactive Simulacra of Human Behavior},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606763},
doi = {10.1145/3586183.3606763},
abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {2},
numpages = {22},
keywords = {large language models, generative AI, agents, Human-AI interaction},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {UIST '23}
}
@inproceedings{aher2022using,
  title={Using large language models to simulate multiple humans and replicate human subject studies},
  author={Aher, Gati V and Arriaga, Rosa I and Kalai, Adam Tauman},
  booktitle={International Conference on Machine Learning},
  pages={337--371},
  year={2023},
  organization={PMLR}
}
@techreport{horton2023large,
  title={Large language models as simulated economic agents: What can we learn from homo silicus?},
  author={Horton, John J},
  year={2023},
  institution={National Bureau of Economic Research}
}
@article{ziems2023can,
  title={Can Large Language Models Transform Computational Social Science?},
  author={Ziems, Caleb and Held, William and Shaikh, Omar and Chen, Jiaao and Zhang, Zhehao and Yang, Diyi},
  journal={arXiv preprint arXiv:2305.03514},
  year={2023}
}
@article{lee2023supervised,
  title={Supervised Pretraining Can Learn In-Context Reinforcement Learning},
  author={Lee, Jonathan N and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma},
  journal={Neural Information Processing
Systems},
  year={2023}
}
@article{lu2023structured,
  title={Structured state space models for in-context reinforcement learning},
  author={Lu, Chris and Schroecker, Yannick and Gu, Albert and Parisotto, Emilio and Foerster, Jakob and Singh, Satinder and Behbahani, Feryal},
  journal={arXiv preprint arXiv:2303.03982},
  year={2023}
}
Ask AI to edit or generate...

@article{lee2013efficient,
  title={Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems},
  author={Lee, Yin Tat and Sidford, Aaron},
  journal={FOCS},
  year={2013},
}
@incollection{combettes2011,
year={2011},
booktitle={Fixed-Point Algorithms for Inverse Problems in Science and Engineering},
editor={H. H. Bauschke and R. S. Burachik and P. L. Combettes and V. Elser and D. R. Luke and H. Wolkowicz},
title={Proximal Splitting Methods in Signal Processing},
XXXseries={Springer Optimization and Its Applications},
XXXvolume={49},
XXXpublisher={Springer New York},
author={P. L. Combettes and J.-C. Pesquet},
pages={185--212},
}
@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
}
@article{zhang2021unified,
  title={A unified analysis of first-order methods for smooth games via integral quadratic constraints},
  author={Zhang, Guodong and Bao, Xuchan and Lessard, Laurent and Grosse, Roger},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={103},
  pages={1--39},
  year={2021}
}
@article{seidman2019control,
  title={A control-theoretic approach to analysis and parameter selection of {D}ouglas--{R}achford splitting},
  author={Seidman, Jacob H and Fazlyab, Mahyar and Preciado, Victor M and Pappas, George J},
  journal={IEEE Control Systems Letters},
  volume={4},
  number={1},
  pages={199--204},
  year={2019},
  publisher={IEEE}
}
@article{golowich2020last,
  title={Last Iterate is Slower than Averaged iterate in Smooth Convex-Concave Saddle Point Problems},
  author={Golowich, Noah and Pattathil, Sarath and Daskalakis, Constantinos and Ozdaglar, Asuman},
  journal = {COLT},
  year={2020},
}
@article{zhou2021practical,
  title={Practical Schemes for Finding Near-Stationary Points of Convex Finite-Sums},
  author={Zhou, Kaiwen and Tian, Lai and So, Anthony Man-Cho and Cheng, James},
  journal={arXiv preprint arXiv:2105.12062},
  year={2021}
}
@article{lee2021geometric,
      title={A Geometric Structure of Acceleration and Its Role in Making Gradients Small Fast}, 
      author={Jongmin Lee and Chanwoo Park and Ernest K Ryu},
      year={2021},
    journal={NeurIPS},
}

@article{tseng2008accelerated,
  title={On accelerated proximal gradient methods for convex-concave optimization},
  author={Tseng, Paul},
  journal={submitted to SIAM Journal on Optimization},

  year={2008}
}

@book{helmke2012optimization,
  title={Optimization and dynamical systems},
  author={Helmke, Uwe and Moore, John B},
  year={2012},
 }
 @article{lin2014accelerated,
  title={An accelerated proximal coordinate gradient method},
  author={Lin, Qihang and Lu, Zhaosong and Xiao, Lin},
  journal={NeurIPS},
  year={2014},
}
@article{donoho2006compressed,
  title={Compressed sensing},
  author={Donoho, David L},
  journal={IEEE Transactions on Information Theory},
  volume={52},
  number={4},
  pages={1289--1306},
  year={2006},
  publisher={IEEE}
}
@article{kim2018another,
  title={Another look at the fast iterative shrinkage/thresholding algorithm ({F}{I}{S}{T}{A})},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={1},
  pages={223--250},
  year={2018},
  publisher={SIAM}
}
@article{daubechies2004iterative,
  title={An iterative thresholding algorithm for linear inverse problems with a sparsity constraint},
  author={Daubechies, Ingrid and Defrise, Michel and De Mol, Christine},
  journal={Communications on Pure and Applied Mathematics},
  volume={57},
  number={11},
  pages={1413--1457},
  year={2004},
  publisher={Wiley Online Library}
}

@article{nemirovsky1991optimality,
  title={On optimality of {Krylov's} information when solving linear operator equations},
  author={Nemirovsky, Arkadi S.},
  journal={Journal of Complexity},
  volume={7},
  number={2},
  pages={121--130},
  year={1991},
  publisher={Academic Press}
}
@article{nemirovsky1992information,
  title={Information-based complexity of linear operator equations},
  author={Nemirovsky, Arkadi S},
  journal={Journal of Complexity},
  volume={8},
  number={2},
  pages={153--175},
  year={1992},
  publisher={Academic Press}
}
@article{ghadimi2016accelerated,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1-2},
  pages={59--99},
  year={2016},
  publisher={Springer}
}
@article{ryu2019scaled,
  title={Scaled relative graph: Nonexpansive operators via 2D Euclidean geometry},
  author={Ryu, Ernest K and Hannah, Robert and Yin, Wotao},
  journal={Mathematical Programming},
  year={2021}
}

@article{nesterov2020primal,
  title={Primal--dual accelerated gradient methods with small-dimensional relaxation oracle},
  author={Nesterov, Yu and Gasnikov, Alexander and Guminov, Sergey and Dvurechensky, Pavel},
  journal={Optimization Methods and Software},
  pages={1--38},
  year={2020},
  publisher={Taylor \& Francis}
}
@article{nemirovski2004prox,
  title={Prox-method with rate of convergence $\mathcal{O} (1/t)$ for variational inequalities with {L}ipschitz continuous monotone operators and smooth convex-concave saddle point problems},
  author={Nemirovski, Arkadi},
  journal={SIAM Journal on Optimization},
  volume={15},
  number={1},
  pages={229--251},
  year={2004},
  publisher={SIAM}
}

@article{diakonikolas2020halpern,
  title={Halpern iteration for near-optimal and parameter-free monotone inclusion and strong solutions to variational inequalities},
  author={Diakonikolas, Jelena},
  journal={COLT},
  year={2020}
}
@article{diakonikolas2021complementary,
  title={Complementary composite minimization, small gradients in general norms, and applications to regression problems},
  author={Diakonikolas, Jelena and Guzm{\'a}n, Crist{\'o}bal},
  journal={arXiv preprint arXiv:2101.11041},
  year={2021}
}

@article{nesterov2012make,
  title={How to make the gradients small},
  author={Nesterov, Yu},
  journal={Optima. Mathematical Optimization Society Newsletter},
  number={88},
  pages={10--11},
  year={2012}
}

@article{huang2021riemannian,
  title={Riemannian proximal gradient methods},
  author={Huang, Wen and Wei, Ke},
  journal={Mathematical Programming},
  year={2021},
  publisher={Springer}
}
@article{li2015accelerated,
  title={Accelerated proximal gradient methods for nonconvex programming},
  author={Li, Huan and Lin, Zhouchen},
  journal={NeurIPS},
  year={2015}
}
 @article{lu2020s,
  title={An $ \mathcal{O}(s^{r}) $-Resolution ODE Framework for Discrete-Time Optimization Algorithms and Applications to Convex-Concave Saddle-Point Problems},
  author={Lu, Haihao},
  journal={arXiv preprint arXiv:2001.08826},
  year={2020}
}
 @article{schropp2000dynamical,
  title={A dynamical systems approach to constrained minimization},
  author={Schropp, Johannes and Singer, I},
  journal={Numerical Functional Analysis and Optimization},
  volume={21},
  number={3-4},
  pages={537--551},
  year={2000},
  publisher={Taylor \& Francis}
}


@phdthesis{taylor2017convex,
  author       = {Taylor, Adrien B},
  title        = {Convex interpolation and performance estimation of first-order methods for convex optimization},
  school       = {Catholic University of Louvain, Louvain-la-Neuve, Belgium},
  year         = 2017,
}



@article{park2021factor,
  title={Factor-$\sqrt{2}$ Acceleration of Accelerated Gradient Methods},
  author={Park, Chanwoo and Park, Jisun and Ryu, Ernest K},
  journal={arXiv preprint arXiv:2102.07366},
  year={2021}
}
@article{taylor2019stochastic,
  title={Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions},
  author={Taylor, Adrien B and Bach, Francis},
  journal = {COLT},
  year={2019}
}
@article{barre2020principled,
  title={Principled Analyses and Design of First-Order Methods with Inexact Proximal Operators},
  author={Barr{\'e}, Mathieu and Taylor, Adrien B and Bach, Francis},
  journal={arXiv preprint arXiv:2006.06041},
  year={2020}
}

@article{van2017fastest,
  title={The fastest known globally convergent first-order method for minimizing strongly convex functions},
  author={Van Scoy, Bryan and Freeman, Randy A and Lynch, Kevin M},
  journal={IEEE Control Systems Letters},
  volume={2},
  number={1},
  pages={49--54},
  year={2017},
  publisher={IEEE}
}
@article{kim2021accelerated,
  title={Accelerated proximal point method for maximally monotone operators},
  author={Kim, Donghwan},
  journal={Mathematical Programming},
  year={2021},
  publisher={Springer}
}
@article{de2017worst,
  title={On the worst-case complexity of the gradient method with exact line search for smooth strongly convex functions},
  author={De Klerk, Etienne and Glineur, Fran{\c{c}}ois and Taylor, Adrien B},
  journal={Optimization Letters},
  volume={11},
  number={7},
  pages={1185--1199},
  year={2017},
  publisher={Springer}
}

@article{taylor2021optimal,
  title={An optimal gradient method for smooth (possibly strongly) convex minimization},
  author={Taylor, Adrien B and Drori, Yoel},
  journal={arXiv preprint arXiv:2101.09741},
  year={2021}
}

@article{kim2018adaptive,
  title={Adaptive restart of the optimized gradient method for convex optimization},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={Journal of Optimization Theory and Applications},
  volume={178},
  number={1},
  pages={240--263},
  year={2018},
  publisher={Springer}
}

@article{drori2021oracle,
  title={On the oracle complexity of smooth strongly convex minimization},
  author={Drori, Yoel and Taylor, Adrien B},
  journal={arXiv preprint arXiv:2101.09740},
  year={2021}
}
@article{diakonikolas2021potential,
  title={Potential Function-based Framework for Making the Gradients Small in Convex and Min-Max Optimization},
  author={Diakonikolas, Jelena and Wang, Puqian},
  journal={arXiv preprint arXiv:2101.12101},
  year={2021}
}
@article{hu2017dissipativity,
  title={Dissipativity theory for {N}esterov’s accelerated method},
  author={Hu, Bin and Lessard, Laurent},
  journal = {ICML},
  year={2017}
}
@article{d2021acceleration,
  title={Acceleration methods},
  author={d'Aspremont, Alexandre and Scieur, Damien and Taylor, Adrien B},
  journal={arXiv preprint arXiv:2101.09545},
  year={2021}
}
@article{ryu2020operator,
  title={Operator splitting performance estimation: Tight contraction factors and optimal parameter selection},
  author={Ryu, Ernest K and Taylor, Adrien B and Bergeling, Carolina and Giselsson, Pontus},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={3},
  pages={2251--2271},
  year={2020},
  publisher={SIAM}
}
@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen},
  journal={Foundations and Trends in Optimization},
  volume={1},
  number={3},
  pages={127--239},
  year={2014},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}
@article{taylor2018exact,
  title={Exact worst-case convergence rates of the proximal gradient method for composite convex minimization},
  author={Taylor, Adrien B and Hendrickx, Julien M and Glineur, Fran{\c{c}}ois},
  journal={Journal of Optimization Theory and Applications},
  volume={178},
  number={2},
  pages={455--476},
  year={2018},
  publisher={Springer}
}

@article{fazlyab2018analysis,
  title={Analysis of optimization algorithms via integral quadratic constraints: {N}onstrongly convex problems},
  author={Fazlyab, Mahyar and Ribeiro, Alejandro and Morari, Manfred and Preciado, Victor M},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={3},
  pages={2654--2689},
  year={2018},
  publisher={SIAM}
}

@article{kim2016optimized,
  title={Optimized first-order methods for smooth convex minimization},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={Mathematical Programming},
  volume={159},
  number={1},
  pages={81--107},
  year={2016},
  publisher={Springer}
}

@article{kim2021optimizing,
  title={Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={Journal of Optimization Theory and Applications},
  volume={188},
  number={1},
  pages={192--219},
  year={2021},
  publisher={Springer}
}

@article{guler1992new,
  title={New proximal point algorithms for convex minimization},
  author={G{\"u}ler, Osman},
  journal={SIAM Journal on Optimization},
  volume={2},
  number={4},
  pages={649--664},
  year={1992},
  publisher={SIAM}
}
@article{su2014differential,
  title={A differential equation for modeling {N}esterov’s accelerated gradient method: Theory and insights},
  author={Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
  journal={NeurIPS},
  year={2014}
}

@article{wibisono2016variational,
  title={A variational perspective on accelerated methods in optimization},
  author={Wibisono, Andre and Wilson, Ashia C and Jordan, Michael I},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  year = {2016}
}

@article{donoho2010precise,
  title={Precise undersampling theorems},
  author={Donoho, David L and Tanner, Jared},
  journal={Proceedings of the IEEE},
  volume={98},
  number={6},
  pages={913--924},
  year={2010},
  publisher={IEEE}
}

@article{candes2006robust,
  title={Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information},
  author={Cand{\`e}s, Emmanuel J and Romberg, Justin and Tao, Terence},
  journal={IEEE Transactions on Information Theory},
  volume={52},
  number={2},
  pages={489--509},
  year={2006},
  publisher={IEEE}
}
@article{candes2006near,
  title={Near-optimal signal recovery from random projections: Universal encoding strategies?},
  author={Cand{\`e}s, Emmanuel J and Tao, Terence},
  journal={IEEE Transactions on Information Theory},
  volume={52},
  number={12},
  pages={5406--5425},
  year={2006},
  publisher={IEEE}
}
@article{betancourt2018symplectic,
  title={On symplectic optimization},
  author={Betancourt, Michael and Jordan, Michael I and Wilson, Ashia C},
  journal={arXiv preprint arXiv:1802.03653},
  year={2018}
}

@article{shi2018understanding,
  title={Understanding the acceleration phenomenon via high-resolution differential equations},
  author={Shi, Bin and Du, Simon S and Jordan, Michael I and Su, Weijie J},
  journal={arXiv preprint arXiv:1810.08907},
  year={2018}
}

@article{MAL-050,
url = {http://dx.doi.org/10.1561/2200000050},
year = {2015},
volume = {8},
journal = {Foundations and Trends® in Machine Learning},
title = {Convex Optimization: Algorithms and Complexity},
doi = {10.1561/2200000050},
issn = {1935-8237},
number = {3-4},
pages = {231-357},
author = {Sébastien Bubeck}
}

@article{drusvyatskiy2018optimal,
  title={An optimal first order method based on optimal quadratic averaging},
  author={Drusvyatskiy, Dmitriy and Fazel, Maryam and Roy, Scott},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={1},
  pages={251--271},
  year={2018},
  publisher={SIAM}
}

@article{chen2016geometric,
  title={Geometric descent method for convex composite minimization},
  author={Chen, Shixiang and Ma, Shiqian and Liu, Wei},
  journal={NeurIPS},
  year={2017}
}

@article{karimi2017single,
  title={A single potential governing convergence of conjugate gradient, accelerated gradient and geometric descent},
  author={Karimi, Sahar and Vavasis, Stephen},
  journal={arXiv preprint arXiv:1712.09498},
  year={2017}
}

@article{allen2014linear,
  title={Linear coupling: An ultimate unification of gradient and mirror descent},
  author={Allen-Zhu, Zeyuan and Orecchia, Lorenzo},
  journal={ITCS},
  year={2017}
}


@article{drori2014performance,
  title={Performance of first-order methods for smooth convex minimization: a novel approach},
  author={Drori, Yoel and Teboulle, Marc},
  journal={Mathematical Programming},
  volume={145},
  number={1},
  pages={451--482},
  year={2014},
  publisher={Springer}
}

@article{taylor2017smooth,
  title={Smooth strongly convex interpolation and exact worst-case performance of first-order methods},
  author={Taylor, Adrien B and Hendrickx, Julien M and Glineur, Fran{\c{c}}ois},
  journal={Mathematical Programming},
  volume={161},
  number={1-2},
  pages={307--345},
  year={2017},
  publisher={Springer}
}


@article{lessard2016analysis,
  title={Analysis and design of optimization algorithms via integral quadratic constraints},
  author={Lessard, Laurent and Recht, Benjamin and Packard, Andrew},
  journal={SIAM Journal on Optimization},
  volume={26},
  number={1},
  pages={57--95},
  year={2016},
  publisher={SIAM}
}

@article{drori2017exact,
  title={The exact information-based complexity of smooth convex minimization},
  author={Drori, Yoel},
  journal={Journal of Complexity},
  volume={39},
  pages={1--16},
  year={2017},
  publisher={Elsevier}
}

@article{10029946121,
author={Nesterov, Yu},
title= {A method for unconstrained convex minimization problem with the rate of
convergence $\mathcal{O}(1/k^2)$},
journal="Proceedings of the USSR Academy of Sciences",
year="1983",
volume="269",
pages="543-547",
}


@article{nesterov2005smooth,
  title={Smooth minimization of non-smooth functions},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={103},
  number={1},
  pages={127--152},
  year={2005},
  publisher={Springer}
}
@article{nesterov2008accelerating,
  title={Accelerating the cubic regularization of {N}ewton’s method on convex problems},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={112},
  number={1},
  pages={159--181},
  year={2008},
  publisher={Springer}
}
@article{beck2009fast,
  title={A fast iterative shrinkage-thresholding algorithm for linear inverse problems},
  author={Beck, Amir and Teboulle, Marc},
  journal={SIAM Journal on Imaging Sciences},
  volume={2},
  number={1},
  pages={183--202},
  year={2009},
  publisher={SIAM}
}
@book{ryu2020LSCOMO,
  title={Large-Scale Convex Optimization via Monotone Operators},
  author={Ernest K Ryu and Wotao Yin},
  year={2021},
  publisher={Draft}
}
@techreport{baes2009estimate,
     title={Estimate sequence methods: extensions and approximations},
     author={Baes, Michel},
     year = {2009},
     institution = {Institute for Operations Research, ETH, Z{\"u}rich, Switzerland}
}

@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}
@article{auslender2006interior,
  title={Interior gradient and proximal methods for convex and conic optimization},
  author={Auslender, Alfred and Teboulle, Marc},
  journal={SIAM Journal on Optimization},
  volume={16},
  number={3},
  pages={697--725},
  year={2006},
  publisher={SIAM}
}
@article{nesterov2017efficiency,
  title={Efficiency of the accelerated coordinate descent method on structured optimization problems},
  author={Nesterov, Yu and Stich, Sebastian U},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={1},
  pages={110--123},
  year={2017},
  publisher={SIAM}
}

@article{allen2016even,
  title={Even faster accelerated coordinate descent using non-uniform sampling},
  author={Allen-Zhu, Zeyuan and Qu, Zheng and Richt{\'a}rik, Peter and Yuan, Yang},
  journal={ICML},
  year={2016}
}
@article{allen2016using,
  title={Using optimization to obtain a width-independent, parallel, simpler, and faster positive {S}{D}{P} solver},
  author={Allen-Zhu, Zeyuan and Lee, Yin Tat and Orecchia, Lorenzo},
  journal={SODA},
  year={2016},
}

@article{nesterov2013gradient,
  title={Gradient methods for minimizing composite functions},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={140},
  number={1},
  pages={125--161},
  year={2013},
  publisher={Springer}
}
@article{necoara2016iteration,
  title={Iteration complexity analysis of dual first-order methods for conic convex programming},
  author={Necoara, Ion and Patrascu, Andrei},
  journal={Optimization Methods and Software},
  volume={31},
  number={3},
  pages={645--678},
  year={2016},
  publisher={Taylor \& Francis}
}
@article{v015a004,
 author = {Bansal, Nikhil and Gupta, Anupam},
 title = {Potential-Function Proofs for Gradient Methods},
 year = {2019},
 pages = {1--32},
 publisher = {Theory of Computing},
 journal = {Theory of Computing},
 volume = {15},
 number = {4},
}
@article{chambolle2015convergence,
  title={On the convergence of the iterates of the “fast iterative shrinkage/thresholding algorithm”},
  author={Chambolle, Antonin and Dossal, Ch},
  journal={Journal of optimization theory and applications},
  volume={166},
  number={3},
  pages={968--982},
  year={2015},
  publisher={Springer}
}


@article{drori2020efficient,
  title={Efficient first-order methods for convex minimization: a constructive approach},
  author={Drori, Yoel and Taylor, Adrien B},
  journal={Mathematical Programming},
  volume={184},
  number={1},
  pages={183--220},
  year={2020},
  publisher={Springer}
}
@article{li2020revisit,
  title={Revisit of estimate sequence for accelerated gradient methods},
  author={Li, Bingcong and Couti{\~n}o, Mario and Giannakis, Georgios B},
  journal={ICASSP},
  year={2020}
}
@article{ahn2020nesterov,
  title={From {N}esterov's Estimate Sequence to {R}iemannian Acceleration},
  author={Ahn, Kwangjun and Sra, Suvrit},
  journal={COLT},
  year={2020}
}

@article{polyak1964some,
  title={Some methods of speeding up the convergence of iteration methods},
  author={Polyak, Boris T},
  journal={USSR Computational Mathematics and Mathematical Physics},
  volume={4},
  number={5},
  pages={1--17},
  year={1964},
  publisher={Elsevier}
}
@article{duchi2010composite,
  title={Composite Objective Mirror Descent.},
  author={Duchi, John C and Shalev-Shwartz, Shai and Singer, Yoram and Tewari, Ambuj},
  journal={COLT},
  year={2010}
}
@misc{golub1996matrix,
  title={Matrix computations. {J}ohns {H}opkins studies in the mathematical sciences},
  author={Golub, Gene H and Van Loan, Charles F},
  year={1996},
  publisher={Johns Hopkins University Press, Baltimore, MD,}
}
@article{kim2017convergence,
  title={On the convergence analysis of the optimized gradient method},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={Journal of Optimization Theory and Applications},
  volume={172},
  number={1},
  pages={187--205},
  year={2017},
  publisher={Springer}
}
@article{kim2018generalizing,
  title={Generalizing the optimized gradient method for smooth convex minimization},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1920--1950},
  year={2018},
  publisher={SIAM}
}
@article{gu2020tight,
  title={Tight Sublinear Convergence Rate of the Proximal Point Algorithm for Maximal Monotone Inclusion Problems},
  author={Gu, Guoyong and Yang, Junfeng},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={3},
  pages={1905--1921},
  year={2020},
  publisher={SIAM}
}


@article{lieder2020convergence,
  title={On the convergence rate of the {H}alpern-iteration},
  author={Lieder, Felix},
  journal={Optimization Letters},
  year={2021},
  volume = {15},
  number = {2},
  pages = {405--418},
  publisher={Springer}
}



@article{taylor2017exact,
  title={Exact worst-case performance of first-order methods for composite convex optimization},
  author={Taylor, Adrien B and Hendrickx, Julien M and Glineur, Fran{\c{c}}ois},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={3},
  pages={1283--1313},
  year={2017},
  publisher={SIAM}
}

@book{nemirovsky1983problem,
  title={Problem Complexity and Method Efficiency in Optimization.},
  author={Nemirovsky, Arkadi Semenovich and Yudin, David Borisovich},
  year={1983}
}
@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}
@article{nesterov2009primal,
  title={Primal-dual subgradient methods for convex problems},
  author={Nesterov, Yu},
  journal={Mathematical Programming},
  volume={120},
  number={1},
  pages={221--259},
  year={2009},
  publisher={Springer}
}


@article{Dragomir2021,
author = {R.-A. Dragomir and Taylor, Adrien B and A. d'Aspremont and J. Bolte},
title = {Optimal Complexity and Certification of {B}regman First-Order Methods},
journal = {Mathematical Programming},
year = {2021},
}

@article{allen2016variance,
title={Variance reduction for faster non-convex optimization},
author={Allen-Zhu, Zeyuan and Hazan, Elad},
journal = {ICML},
year={2016},
}

@article{allen2017katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={8194--8244},
  year={2017},
  publisher={JMLR. org}
}

@article{allen2014using,
  title={Using optimization to break the epsilon barrier: A faster and simpler width-independent algorithm for solving positive linear programs in parallel},
  author={Allen-Zhu, Zeyuan and Orecchia, Lorenzo},
  journal = {SODA},
  year={2014},
}

@article{de2020worst,
  title={Worst-case convergence analysis of inexact gradient and Newton methods through semidefinite programming performance estimation},
  author={De Klerk, Etienne and Glineur, Francois and Taylor, Adrien B},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={3},
  pages={2053--2082},
  year={2020},
  publisher={SIAM}
}
@article{aujol2017optimal,
  title={Optimal Rate of Convergence of an {ODE} Associated to the Fast Gradient Descent schemes for {$b> 0$}},
  author={Aujol, Jean-Fran{\c{c}}ois and Dossal, Ch},
  year={2017},
  journal = {HAL Archives Ouvertes}
}
@article{aujol2019rates,
  title={Rates of Convergence of Perturbed {FISTA}-based algorithms},
  author={Aujol, Jean-Fran{\c{c}}ois and Dossal, Charles and Fort, Gersende and Moulines, {\'E}ric},
  year={2019},
  journal = {HAL Archives Ouvertes}
}
@article{aujol2019optimal,
  title={Optimal convergence rates for {N}esterov acceleration},
  author={Aujol, Jean-Francois and Dossal, Charles and Rondepierre, Aude},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={4},
  pages={3131--3153},
  year={2019},
  publisher={SIAM}
}
@article{moreau1962fonctions,
  title={Fonctions convexes duales et points proximaux dans un espace hilbertien},
  author={Moreau, Jean Jacques},
  journal={Comptes rendus hebdomadaires des s{\'e}ances de l'Acad{\'e}mie des sciences},
  volume={255},
  pages={2897--2899},
  year={1962}
}
@article{moreau1965proximite,
  title={Proximit{\'e} et dualit{\'e} dans un espace hilbertien},
  author={Moreau, Jean-Jacques},
  journal={Bulletin de la Soci{\'e}t{\'e} math{\'e}matique de France},
  volume={93},
  pages={273--299},
  year={1965}
}

@book{rockafellar1970,
  title={Convex Analysis},
  author={R. T. Rockafellar},
  year={1970},
}









@article{doi:10.1287/moor.2016.0817,
author = {Bauschke, Heinz H. and Bolte, J. and Teboulle, Marc},
title = {A Descent Lemma Beyond {L}ipschitz Gradient Continuity: First-Order Methods Revisited and Applications},
journal = {Mathematics of Operations Research},
volume = {42},
number = {2},
pages = {330--348},
year = {2017},
}










@article{doi:10.1137/16M1099546,
author = {Lu, Haihao and Freund, Robert M. and Nesterov, Yu},
title = {Relatively Smooth Convex Optimization by First-Order Methods, and Applications},
journal = {SIAM Journal on Optimization},
volume = {28},
number = {1},
pages = {333--354},
year = {2018},
}



@article{ryu2016primer,
  title={Primer on monotone operator methods},
  author={Ryu, Ernest K and Boyd, Stephen},
  journal={Appl. Comput. Math},
  volume={15},
  number={1},
  pages={3--43},
  year={2016}
}

@article{huang2019scaled,
title = {Tight Coefficients of Averaged Operators via Scaled Relative Graph},
author = {Xinmeng Huang and Ernest K Ryu and Wotao Yin},
  journal={Journal of Mathematical Analysis and Applications},
volume = {490},
number = {1},
pages = "124211",
  year={2020}
}

@article{bauschke2011convex,
  title={Convex analysis and monotone operator theory in {H}ilbert spaces},
  author={Bauschke, Heinz H and Combettes, Patrick L and others},
  year={2011},
}

@article{huang2019matrix,
title = {Scaled Relative Graph of Normal Matrices},
author = {Xinmeng Huang and Ernest K Ryu and Wotao Yin},
  journal={arXiv preprint arXiv:2001.02061},
  year={2019}
}

@article{NEURIPS2018_996a7fa0,
 author = {Allen-Zhu, Zeyuan},
 journal = {NeurIPS},
 title = {How To Make the Gradients Small Stochastically: Even Faster Convex and Nonconvex {SGD}},
 year = {2018}
}



@misc{nem99,
  author        = {Arkadi S. Nemirovski},
  title         = {Optimization {II}: Numerical methods for nonlinear continuous optimization.},
  year          = {1999},
}



@article{bruck1977,
title = "On the weak convergence of an ergodic iteration for the solution of variational inequalities for monotone operators in {H}ilbert space",
journal = "Journal of Mathematical Analysis and Applications",
ajournal = "J. Math. Anal. Appl.",
volume = "61",
number = "1",
pages = "159--164",
year = "1977",
author = "R. E. Bruck"
}




@article{passty1979,
title = "Ergodic convergence to a zero of the sum of monotone operators in {H}ilbert space",
journal = "Journal of Mathematical Analysis and Applications",
ajournal = "J. Math. Anal. Appl.",
volume = "72",
number = "2",
pages = "383--390",
year = "1979",
author = "G. B. Passty"
}
@article{combettes2005,
author = {P. L. Combettes and V. R. Wajs},
title = {Signal Recovery by Proximal Forward-Backward Splitting},
journal = {Multiscale Modeling and Simulation},
ajournal = {Multiscale Model. Simul.},
volume = {4},
number = {4},
pages = {1168--1200},
year = {2005},
}



@article{NEURIPS2018_d4b2aeb2,
 author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={NeurIPS},
 title = {{NEON2}: Finding Local Minima via First-Order Oracles},
 year = {2018}
}



@article{ge2015,
  title={Escaping From Saddle Points --- Online Stochastic Gradient for Tensor Decomposition
},
  author={Rong Ge and Furong Huang and Chi Jin and Yang Yuan},
  journal = {COLT},
  year={2015},
}

@article{NEURIPS2018_217e342f,
 author = {Xu, Yi and Jin, Rong and Yang, Tianbao},
  journal={NeurIPS},
 title = {First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time},
 year = {2018}
}

@article{yoon2021accelerated,
  title={Accelerated Algorithms for Smooth Convex-Concave Minimax Problems with $\mathcal{O}(1/k^2)$ Rate on Squared Gradient Norm},
  author={Yoon, TaeHo and Ryu, Ernest K},
  journal={ICML},
  year={2021}
}


@article{gasnikov2018,
author = {Gasnikov, A. V. and Nesterov, Y. E.},
title = {Universal Method for Stochastic Composite Optimization Problems},
journal = {Computational Mathematics and Mathematical Physics},
volume = {58},
number = {1},
pages = {48--64},
year = {2018},
}

@book{nesterov2018,
   title = "Lectures on Convex Optimization",
   author = "Yu Nesterov",
   year = 2018,
   edition = {2nd},
}


@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={ICLR},
  year={2018}
}
@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{lamb2019interpolated,
  title={Interpolated adversarial training: Achieving robust neural networks without sacrificing too much accuracy},
  author={Lamb, Alex and Verma, Vikas and Kannala, Juho and Bengio, Yoshua},
  journal={Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security},
  year={2019}
}
@article{arazo2019unsupervised,
  title={Unsupervised label noise modeling and loss correction},
  author={Arazo, Eric and Ortego, Diego and Albert, Paul and O’Connor, Noel and McGuinness, Kevin},
  journal={ICML},
  year={2019}
}
@article{zhang2020does,
  title={How does mixup help with robustness and generalization?},
  author={Zhang, Linjun and Deng, Zhun and Kawaguchi, Kenji and Ghorbani, Amirata and Zou, James},
  journal={ICLR},
  year={2021}
}
@article{wager2013dropout,
  title={Dropout training as adaptive regularization},
  author={Wager, Stefan and Wang, Sida and Liang, Percy S},
  journal={NeurIPS},
  year={2013}
}
@article{carratino2020mixup,
  title={On mixup regularization},
  author={Carratino, Luigi and Ciss{\'e}, Moustapha and Jenatton, Rodolphe and Vert, Jean-Philippe},
  journal={arXiv preprint arXiv:2006.06049},
  year={2020}
}
@article{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  journal={ICCV},
  year={2019}
}
@article{liu2022decoupled,
  title={Decoupled Mixup for Data-efficient Learning},
  author={Liu, Zicheng and Li, Siyuan and Wang, Ge and Tan, Cheng and Wu, Lirong and Li, Stan Z},
  journal={arXiv preprint arXiv:2203.10761},
  year={2022}
}
@article{chidambaram2021towards,
  title={Towards Understanding the Data Dependency of Mixup-style Training},
  author={Chidambaram, Muthu and Wang, Xiang and Hu, Yuzheng and Wu, Chenwei and Ge, Rong},
  journal={ICLR},
  year={2022}
}

@article{liu2021unveiling,
  title={Automix: Unveiling the power of mixup},
  author={Liu, Zicheng and Li, Siyuan and Wu, Di and Chen, Zhiyuan and Wu, Lirong and Guo, Jianzhu and Li, Stan Z},
  journal={ECCV},
  year={2022}
}

@article{sohn2022genlabel,
  title={GenLabel: Mixup Relabeling using Generative Models},
  author={Sohn, Jy Yong and Shang, Liang and Chen, Hongxu and Moon, Jaekyun and Papailiopoulos, Dimitris and Lee, Kangwook},
  journal={arXiv preprint arXiv:2201.02354},
  year={2022}
}

@article{faramarzi2020patchup,
  title={Patchup: A regularization technique for convolutional neural networks},
  author={Faramarzi, Mojtaba and Amini, Mohammad and Badrinaaraayanan, Akilesh and Verma, Vikas and Chandar, Sarath},
  journal={arXiv preprint arXiv:2006.07794},
  year={2020}
}

@article{verma2019manifold,
  title={Manifold mixup: Better representations by interpolating hidden states},
  author={Verma, Vikas and Lamb, Alex and Beckham, Christopher and Najafi, Amir and Mitliagkas, Ioannis and Lopez-Paz, David and Bengio, Yoshua},
  journal={ICML},
  year={2019}
}
@article{devries2017cutout,  
  title={Improved Regularization of Convolutional Neural Networks with Cutout},  
  author={DeVries, Terrance and Taylor, Graham W},  
  journal={arXiv preprint arXiv:1708.04552},  
  year={2017}  
}

@article{kim2020puzzle,
  title={Puzzle mix: Exploiting saliency and local statistics for optimal mixup},
  author={Kim, Jang Hyun and Choo, Wonho and Song, Hyun Oh},
  journal={ICML},
  year={2020}
  }
  
@article{kim2021co,
  title={Co-mixup: Saliency guided joint mixup with supermodular diversity},
  author={Kim, Jang Hyun and Choo, Wonho and Jeong, Hosan and Song, Hyun Oh},
  journal={ICLR},
  year={2021}
}
@article{dabouei2021supermix,
  title={Supermix: Supervising the mixing data augmentation},
  author={Dabouei, Ali and Soleymani, Sobhan and Taherkhani, Fariborz and Nasrabadi, Nasser M},
  journal={CVPR},
  year={2021}
}
@article{qin2020resizemix,
  title={Resizemix: Mixing data with preserved object information and true labels},
  author={Qin, Jie and Fang, Jiemin and Zhang, Qian and Liu, Wenyu and Wang, Xingang and Wang, Xinggang},
  journal={arXiv preprint arXiv:2012.11101},
  year={2020}
}
@article{walawalkar2020attentive,
  title={Attentive cutmix: An enhanced data augmentation approach for deep learning based image classification},
  author={Walawalkar, Devesh and Shen, Zhiqiang and Liu, Zechun and Savvides, Marios},
  journal={arXiv preprint arXiv:2003.13048},
  year={2020}
}
@article{uddin2020saliencymix,
  title={Saliencymix: A saliency guided data augmentation strategy for better regularization},
  author={Uddin, AFM and Monira, Mst and Shin, Wheemyung and Chung, TaeChoong and Bae, Sung Ho and others},
  journal={ICLR},
  year={2021}
}

@article{harris2020fmix,
  title={Fmix: Enhancing mixed sample data augmentation},
  author={Harris, Ethan and Marcu, Antonia and Painter, Matthew and Niranjan, Mahesan and Pr{\"u}gel-Bennett, Adam and Hare, Jonathon},
  journal={arXiv preprint arXiv:2002.12047},
  year={2020}
}

@article{chen2020gridmask,
  title={Gridmask data augmentation},
  author={Chen, Pengguang and Liu, Shu and Zhao, Hengshuang and Jia, Jiaya},
  journal={arXiv preprint arXiv:2001.04086},
  year={2020}
}

@article{beckham2019adversarial,
  title={On adversarial mixup resynthesis},
  author={Beckham, Christopher and Honari, Sina and Verma, Vikas and Lamb, Alex M and Ghadiri, Farnoosh and Hjelm, R Devon and Bengio, Yoshua and Pal, Chris},
  journal={NeurIPS},
  year={2019}
}

@article{verma2022interpolation,
  title={Interpolation consistency training for semi-supervised learning},
  author={Verma, Vikas and Kawaguchi, Kenji and Lamb, Alex and Kannala, Juho and Solin, Arno and Bengio, Yoshua and Lopez-Paz, David},
  journal={Neural Networks},
  volume={145},
  pages={90--106},
  year={2022},
  publisher={Elsevier}
}

@article{berthelot2019mixmatch,
  title={Mixmatch: A holistic approach to semi-supervised learning},
  author={Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A},
  journal={NeurIPS},
  year={2019}
}
@article{thulasidasan2019mixup,
  title={On mixup training: Improved calibration and predictive uncertainty for deep neural networks},
  author={Thulasidasan, Sunil and Chennupati, Gopinath and Bilmes, Jeff A and Bhattacharya, Tanmoy and Michalak, Sarah},
  journal={NeurIPS}, 
  year={2019}
}

@article{bartlett2002rademacher,
  title={Rademacher and Gaussian complexities: Risk bounds and structural results},
  author={Bartlett, Peter L and Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={463--482},
  year={2002}
}
@article{kawaguchi2017generalization,
  title={Generalization in deep learning},
  author={Kawaguchi, Kenji and Kaelbling, Leslie Pack and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.05468},
  year={2017}
}
@article{sun2016depth,
  title={On the depth of deep neural networks: A theoretical view},
  author={Sun, Shizhao and Chen, Wei and Wang, Liwei and Liu, Xiaoguang and Liu, Tie-Yan},
  journal={AAAI},
  year={2016}
}

@article{hardt2016train,
  title={Train faster, generalize better: Stability of stochastic gradient descent},
  author={Hardt, Moritz and Recht, Ben and Singer, Yoram},
  journal={ICML},
  year={2016}
}

@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  journal={NeurIPS}, 
  year={2017}
}

@article{arora2018stronger,
  title={Stronger generalization bounds for deep nets via a compression approach},
  author={Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  journal={ICML},
  year={2018}
}

@article{neyshabur2018towards,
  title={Towards understanding the role of over-parametrization in generalization of neural networks},
  author={Neyshabur, Behnam and Li, Zhiyuan and Bhojanapalli, Srinadh and LeCun, Yann and Srebro, Nathan},
  journal={ICLR},
  year={2018}
}

@article{yao2021improving,
  title={Improving generalization in meta-learning via task augmentation},
  author={Yao, Huaxiu and Huang, Long-Kai and Zhang, Linjun and Wei, Ying and Tian, Li and Zou, James and Huang, Junzhou and others},
  journal = {ICML},
  year={2021}
}

@article{zhang2021and,
  title={When and How Mixup Improves Calibration},
  author={Zhang, Linjun and Deng, Zhun and Kawaguchi, Kenji and Zou, James},
  journal={arXiv preprint arXiv:2102.06289},
  year={2021}
}

@article{greenewald2021k,
  title={k-Mixup Regularization for Deep Learning via Optimal Transport},
  author={Greenewald, Kristjan and Gu, Anming and Yurochkin, Mikhail and Solomon, Justin and Chien, Edward},
  journal={arXiv preprint arXiv:2106.02933},
  year={2021}
}

@article{ren2015faster,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NeurIPS},
  year={2015}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={NAACL},
  year={2019}
}
@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={ICLR},
  year={2015}
}

@article{tsipras2018robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={ICLR},
  year={2019}
}

@article{rebuffi2021fixing,
  title={Fixing data augmentation to improve adversarial robustness},
  author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan A and Stimberg, Florian and Wiles, Olivia and Mann, Timothy},
  journal={arXiv preprint arXiv:2103.01946},
  year={2021}
}

@article{rebuffi2021data,
  title={Data Augmentation Can Improve Robustness},
  author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan Andrei and Stimberg, Florian and Wiles, Olivia and Mann, Timothy A},
  journal={NeurIPS},
  year={2021}
}

@articlee{borgnia2021strong,
  title={Strong data augmentation sanitizes poisoning and backdoor attacks without an accuracy tradeoff},
  author={Borgnia, Eitan and Cherepanova, Valeriia and Fowl, Liam and Ghiasi, Amin and Geiping, Jonas and Goldblum, Micah and Goldstein, Tom and Gupta, Arjun},
  journal={ICASSP},
  year={2021}
}

@article{guo2019augmenting,
  title={Augmenting data with mixup for sentence classification: An empirical study},
  author={Guo, Hongyu and Mao, Yongyi and Zhang, Richong},
  journal={arXiv preprint arXiv:1905.08941},
  year={2019}
}
@article{jindal2020leveraging,
  title={Leveraging BERT with mixup for sentence classification (student abstract)},
  author={Jindal, Amit and Gnaneshwar, Dwaraknath and Sawhney, Ramit and Shah, Rajiv Ratn},
  journal={AAAI},
  year={2020}
}
@article{medennikov2018investigation,
  title={An Investigation of Mixup Training Strategies for Acoustic Models in ASR.},
  author={Medennikov, Ivan and Khokhlov, Yuri Y and Romanenko, Aleksei and Popov, Dmitry and Tomashenko, Natalia A and Sorokin, Ivan and Zatvornitskiy, Alexander},
  journal={Interspeech},
  year={2018}
}
@article{meng2021mixspeech,
  title={MixSpeech: Data augmentation for low-resource automatic speech recognition},
  author={Meng, Linghui and Xu, Jin and Tan, Xu and Wang, Jindong and Qin, Tao and Xu, Bo},
  journal={ICASSP},
  year={2021}
}

@article{chang2020mixup,
  title={Mixup-cam: Weakly-supervised semantic segmentation via uncertainty regularization},
  author={Chang, Yu-Ting and Wang, Qiaosong and Hung, Wei-Chih and Piramuthu, Robinson and Tsai, Yi-Hsuan and Yang, Ming-Hsuan},
  journal={arXiv preprint arXiv:2008.01201},
  year={2020}
}

@article{french2019semi,
  title={Semi-supervised semantic segmentation needs strong, varied perturbations},
  author={French, Geoff and Laine, Samuli and Aila, Timo and Mackiewicz, Michal and Finlayson, Graham},
  journal={BMVC},
  year={2020}
}

@article{kim2021specmix,
  title={SpecMix: A mixed sample data augmentation method for training withTime-frequency domain features},
  author={Kim, Gwantae and Han, David K and Ko, Hanseok},
  journal={INTERSPEECH},
  year={2021}
}

@article{tokozume2017learning,
  title={Learning from between-class examples for deep sound recognition},
  author={Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={ICLR},
  year={2018}
}

@article{inoue2018data,
  title={Data augmentation by pairing samples for images classification},
  author={Inoue, Hiroshi},
  journal={arXiv preprint arXiv:1801.02929},
  year={2018}
}

@article{arora2021dropout,
  title={Dropout: Explicit forms and capacity control},
  author={Arora, Raman and Bartlett, Peter and Mianjy, Poorya and Srebro, Nathan},
  journal={ICML},
  year={2021}
}

@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@article{chen2014semantic,
  title={Semantic image segmentation with deep convolutional nets and fully connected crfs},
  author={Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L},
  journal={ICLR},
  year={2016}
}
@article{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  journal = {ICCV},
  year={2017}
}
@article{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  year={2021},
  journal={ICML}
}
@article{misra2019mish,
  title={Mish: A self regularized non-monotonic activation function},
  author={Misra, Diganta},
  journal={BMVC},
  year={2020}
}
@article{yun2021re,
  title={Re-labeling imagenet: from single to multi-labels, from global to localized labels},
  author={Yun, Sangdoo and Oh, Seong Joon and Heo, Byeongho and Han, Dongyoon and Choe, Junsuk and Chun, Sanghyuk},
  journal={CVPR},
  year={2021}
}
@article{mustafa2020input,
  title={Input Hessian Regularization of Neural Networks},
  author={Mustafa, Waleed and Vandermeulen, Robert A and Kloft, Marius},
  journal={arXiv preprint arXiv:2009.06571},
  year={2020}
}
@article{ma2021linear,
  title={On Linear Stability of SGD and Input-Smoothness of Neural Networks},
  author={Ma, Chao and Ying, Lexing},
  journal={NeurIPS},
  year={2021}
}
@article{moosavi2019robustness,
  title={Robustness via curvature regularization, and vice versa},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Uesato, Jonathan and Frossard, Pascal},
  journal={CVPR},
  year={2019}
}
@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={NeurIPS},
  year={2020}
}
@article{instagramnet,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  journal={ECCV},
  year={2018}
}
@article{align_google,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
  journal={ICML},
  year={2021}
}
@article{tokozume2018between,
  title={Between-class learning for image classification},
  author={Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={CVPR},
  year={2018}
}

@article{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn, Kihyuk and Berthelot, David and Carlini, Nicholas and Zhang, Zizhao and Zhang, Han and Raffel, Colin A and Cubuk, Ekin Dogus and Kurakin, Alexey and Li, Chun-Liang},
  journal={NeurIPS},
  year={2020}
}

@article{kim2020mixco,
  title={Mixco: Mix-up contrastive learning for visual representation},
  author={Kim, Sungnyun and Lee, Gihun and Bae, Sangmin and Yun, Se-Young},
  journal={arXiv preprint arXiv:2010.06300},
  year={2020}
}

@article{randaug,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  journal={CVPR},
  year={2020}
}

@article{specaug,
  title={Specaugment: A simple data augmentation method for automatic speech recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={Interspeech},
  year={2019}
}

@article{hossjer2022sharp,
  title={Sharp lower and upper bounds for the covariance of bounded random variables},
  author={H{\"o}ssjer, Ola and Sj{\"o}lander, Arvid},
  journal={Statistics \& Probability Letters},
  volume={182},
  pages={109323},
  year={2022},
  publisher={Elsevier}
}
@article{barnett2004some,
  title={Some further inequalities for univariate moments and some new ones for the covariance},
  author={Barnett, Neil S and Dragomir, Sever S},
  journal={Computers \& Mathematics with Applications},
  volume={47},
  number={1},
  pages={23--36},
  year={2004},
  publisher={Elsevier}
}

@article{kalantidis2020hard,
  title={Hard negative mixing for contrastive learning},
  author={Kalantidis, Yannis and Sariyildiz, Mert Bulent and Pion, Noe and Weinzaepfel, Philippe and Larlus, Diane},
  journal={NeurIPS},
  year={2020}
}

@article{
lee2021imix,
title={{\$}i{\$}-Mix: A Domain-Agnostic Strategy for Contrastive Representation Learning},
author={Kibok Lee and Yian Zhu and Kihyuk Sohn and Chun-Liang Li and Jinwoo Shin and Honglak Lee},
journal={ICLR},
year={2021},
}

@article{jeong2021observations,
  title={Observations on K-image Expansion of Image-Mixing Augmentation for Classification},
  author={Jeong, Joonhyun and Cha, Sungmin and Yoo, Youngjoon and Yun, Sangdoo and Moon, Taesup and Choi, Jongwon},
  journal={arXiv preprint arXiv:2110.04248},
  year={2021}
}

@article{ren2022sdmp,
  title     = {A Simple Data Mixing Prior for Improving Self-Supervised Learning},
  author    = {Ren, Sucheng and Wang, Huiyu and Gao, Zhengqi and He, Shengfeng and Yuille, Alan and Zhou, Yuyin and Xie, Cihang},
  journal = {CVPR},
  year      = {2022}
}
}

@article{
Li2020DivideMix,
title={DivideMix: Learning with Noisy Labels as Semi-supervised Learning},
author={Junnan Li and Richard Socher and Steven C.H. Hoi},
journal = {ICLR},
year={2020},
}


@article{takahashi2019ricap,
  title={Data augmentation using random image cropping and patching for deep CNNs},
  author={Takahashi, Ryo and Matsubara, Takashi and Uehara, Kuniaki},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={30},
  number={9},
  pages={2917--2931},
  year={2019},
  publisher={IEEE}
}

@article{wightman2021resnet,
  title={Resnet strikes back: An improved training procedure in timm},
  author={Wightman, Ross and Touvron, Hugo and J{\'e}gou, Herv{\'e}},
  journal={NeurIPS},
  year={2021}
}

@article{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  journal={CVPR},
  year={2009}
}

@misc{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={CVPR},
  year={2016}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={BMVC},
  year={2016}
}
@article{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal = {ECCV},
  year={2016}
}

@article{keskar2016largebatch,
  title = {On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
  author = {Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal = {ICLR},
  year = 2017
 }

@article{garipov2018fge,
  title={Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew Gordon},
  journal={NeurIPS},
  year={2018}
}

@article{izmailov2018swa,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={UAI},
  year={2018}
}

@article{foret2020sharpness,
  title={Sharpness-Aware Minimization for Efficiently Improving Generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={ICLR},
  year={2021}
}

@article{cha2021swad,
    title={SWAD: Domain Generalization by Seeking Flat Minima},
    author={Cha, Junbum and Chun, Sanghyuk and Lee, Kyungjae and Cho, Han-Cheol and Park, Seunghyun and Lee, Yunsung and Park, Sungrae},
    year={2021},
    journal={NeurIPS},
}

@article{tian2019contrastive,
  title={Contrastive Multiview Coding},
  author={Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  journal={arXiv preprint arXiv:1906.05849},
  year={2019}
}


@article{buitinck2013api,
  title={API design for machine learning software: experiences from the scikit-learn project},
  author={Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and others},
  journal={arXiv preprint arXiv:1309.0238},
  year={2013}
}

@article{hendrycks2018benchmarking,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={ICLR},
  year={2018}
}

@article{fgsm,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={ICLR},
  year={2015}
}

@article{hong2021stylemix,
  title={Stylemix: Separating content and style for enhanced data augmentation},
  author={Hong, Minui and Choi, Jinwoo and Kim, Gunhee},
  journal={CVPR},
  year={2021}
}

@article{chun2019icmlw,
    title={An Empirical Evaluation on Robustness and Uncertainty of Regularization Methods},
    author={Chun, Sanghyuk and Oh, Seong Joon and Yun, Sangdoo and Han, Dongyoon and Choe, Junsuk and Yoo, Youngjoon},
    year={2019},
    journal={ICML Workshop on Uncertainty and Robustness in Deep Learning},
}

@article{chun2021styleaugment,
    title={StyleAugment: Learning Texture De-biased Representations by Style Augmentation without Pre-defined Textures},
    author={Chun, Sanghyuk and Park, Song},
    year={2021},
    journal={arXiv preprint arXiv:2108.10549},
}

@article{yun2020videomix,
  title={VideoMix: Rethinking Data Augmentation for Video Classification},
  author={Yun, Sangdoo and Oh, Seong Joon and Heo, Byeongho and Han, Dongyoon and Kim, Jinhyung},
  journal={arXiv preprint arXiv:2012.03457},
  year={2020}
}

@article{shen2022mix,
  title={Un-mix: Rethinking image mixtures for unsupervised visual representation learning},
  author={Shen, Zhiqiang and Liu, Zechun and Liu, Zhuang and Savvides, Marios and Darrell, Trevor and Xing, Eric},
  journal={AAAI},
  pages={2216--2224},
  year={2022}
}

@misc{timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}
@misc{alphastarblog,
	title="{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}",
	author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
	howpublished={\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
	year={2019}
}

@article{silver2016mastering,
  title={Mastering the game of \relax{G}o with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{silver2017mastering,
	title={Mastering the game of \relax{G}o without human knowledge},
	author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
	journal={Nature},
	volume={550},
	number={7676},
	pages={354--359},
	year={2017},
	publisher={Nature Research}
}
@article{brown2018superhuman,
	title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
	author={Brown, Noam and Sandholm, Tuomas},
	journal={Science},
	volume={359},
	number={6374},
	pages={418--424},
	year={2018},
	publisher={American Association for the Advancement of Science}
} 
@article{vinyals2017starcraft,
	title={Starcraft {II}: A new challenge for reinforcement learning},
	author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
	journal={arXiv preprint arXiv:1708.04782},
	year={2017}
}
@article{vinyals2019grandmaster,
	title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
	author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
	journal={Nature},
	volume={575},
	number={7782},
	pages={350--354},
	year={2019},
	publisher={Nature Publishing Group}
}
@article{kober2013reinforcement,
	title={Reinforcement learning in robotics: {A} survey},
	author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
	journal={International Journal of Robotics Research},
	volume={32},
	number={11},
	pages={1238--1274},
	year={2013},
	publisher={SAGE Publications Sage UK: London, England}
}
@article{shalev2016safe,
	title={Safe, multi-agent, reinforcement learning for autonomous driving},
	author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
	journal={arXiv preprint arXiv:1610.03295},
	year={2016}
}
@article{baker2019emergent,
	title={Emergent tool use from multi-agent autocurricula},
	author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
	journal={ICLR},
	year={2020}
}
@article{jin2021v,
  title={V-Learning--A Simple, Efficient, Decentralized Algorithm for Multiagent RL},
  author={Jin, Chi and Liu, Qinghua and Wang, Yuanhao and Yu, Tiancheng},
  journal={ICLR 2022 workshop ``Gamification and Multiagent Solutions''},
  year = {2022}
 }
@article{song2021can,
  title={When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?},
  author={Song, Ziang and Mei, Song and Bai, Yu},
  journal={ICLR},
  year={2021}
}
@article{mao2022provably,
  title={Provably efficient reinforcement learning in decentralized general-sum markov games},
  author={Mao, Weichao and Ba{\c{s}}ar, Tamer},
  journal={Dynamic Games and Applications},
  pages={1--22},
  year={2022},
  publisher={Springer}
}

@article{mao2022improving,
  title={On improving model-free algorithms for decentralized multi-agent reinforcement learning},
  author={Mao, Weichao and Yang, Lin and Zhang, Kaiqing and Basar, Tamer},
  journal={ICML},
  year={2022},
 }

@article{qu2022scalable,
  title={Scalable Reinforcement Learning for Multiagent Networked Systems},
  author={Qu, Guannan and Wierman, Adam and Li, Na},
  journal={Operations Research},
  year={2022},
  publisher={INFORMS}
}
@article{zocca2019temporal,
  title={Temporal starvation in multi-channel CSMA networks: an analytical framework},
  author={Zocca, Alessandro},
  journal={Queueing Systems},
  volume={91},
  number={3},
  pages={241--263},
  year={2019},
  publisher={Springer}
}
@article{block2016spatial,
  title={Spatial fairness in multi-channel CSMA line networks},
  author={Block, Robbe and Van Houdt, Benny},
  journal={Performance Evaluation},
  volume={103},
  pages={69--85},
  year={2016},
  publisher={Elsevier}
}

@article{kim2011achievable,
  title={On the achievable throughput of CSMA under imperfect carrier sensing},
  author={Kim, Tae Hyun and Ni, Jian and Srikant, R and Vaidya, Nitin H},
  journal={IEEE Infocom},
  year={2011},
}

@article{mei2017dynamics,
  title={On the dynamics of deterministic epidemic propagation over networks},
  author={Mei, Wenjun and Mohagheghi, Shadi and Zampieri, Sandro and Bullo, Francesco},
  journal={Annual Reviews in Control},
  volume={44},
  pages={116--128},
  year={2017},
  publisher={Elsevier}
}

@article{ruhi2016analysis,
  title={Analysis of exact and approximated epidemic models over complex networks},
  author={Ruhi, Navid Azizan and Ahn, Hyoung Jun and Hassibi, Babak},
  journal={arXiv preprint arXiv:1609.09565},
  year={2016}
}

@inproceedings{preciado2013optimal,
  title={Optimal vaccine allocation to control epidemic outbreaks in arbitrary networks},
  author={Preciado, Victor M and Zargham, Michael and Enyioha, Chinwendu and Jadbabaie, Ali and Pappas, George},
  booktitle={52nd IEEE conference on decision and control},
  pages={7486--7491},
  year={2013},
  organization={IEEE}
}

@inproceedings{ruhi2016improved,
  title={Improved bounds on the epidemic threshold of exact SIS models on complex networks},
  author={Ruhi, Navid Azizan and Thrampoulidis, Christos and Hassibi, Babak},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={3560--3565},
  year={2016},
  organization={IEEE}
}
@article{kuznetsov1994bifurcation,
  title={Bifurcation analysis of periodic SEIR and SIR epidemic models},
  author={Kuznetsov, Yu A and Piccardi, Carlo},
  journal={Journal of mathematical biology},
  volume={32},
  number={2},
  pages={109--121},
  year={1994},
  publisher={Springer}
}
@article{britton2010stochastic,
  title={Stochastic epidemic models: a survey},
  author={Britton, Tom},
  journal={Mathematical biosciences},
  volume={225},
  number={1},
  pages={24--35},
  year={2010},
  publisher={Elsevier}
}
@article{morris2021optimal,
  title={Optimal, near-optimal, and robust epidemic control},
  author={Morris, Dylan H and Rossine, Fernando W and Plotkin, Joshua B and Levin, Simon A},
  journal={Communications Physics},
  volume={4},
  number={1},
  pages={1--8},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{acemoglu2016network,
  title={Network security and contagion},
  author={Acemoglu, Daron and Malekian, Azarakhsh and Ozdaglar, Asu},
  journal={Journal of Economic Theory},
  volume={166},
  pages={536--585},
  year={2016},
  publisher={Elsevier}
}

@article{kok2005non,
  title={Non-communicative multi-robot coordination in dynamic environments},
  author={Kok, Jelle R and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Robotics and Autonomous Systems},
  volume={50},
  number={2-3},
  pages={99--114},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{kok2005utile,
  title={Utile coordination: Learning interdependencies among cooperative agents},
  author={Kok, Jelle R and Hoen, Eter Jan and Bakker, Bram and Vlassis, Nikos},
  booktitle={EEE Symp. on Computational Intelligence and Games, Colchester, Essex},
  pages={29--36},
  year={2005}
}
@article{guestrin2002context,
  title={Context-specific multiagent coordination and planning with factored MDPs},
  author={Guestrin, Carlos and Venkataraman, Shobha and Koller, Daphne},
  journal={AAAI},
  year={2002}
}
@article{yan2013survey,
  title={A survey and analysis of multi-robot coordination},
  author={Yan, Zhi and Jouandeau, Nicolas and Cherif, Arab Ali},
  journal={International Journal of Advanced Robotic Systems},
  volume={10},
  number={12},
  pages={399},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{goyal2014attack,
  title={Attack, defence, and contagion in networks},
  author={Goyal, Sanjeev and Vigier, Adrien},
  journal={The Review of Economic Studies},
  volume={81},
  number={4},
  pages={1518--1542},
  year={2014},
  publisher={Oxford University Press}
}

@article{kovenock2018optimal,
  title={The optimal defense of networks of targets},
  author={Kovenock, Dan and Roberson, Brian},
  journal={Economic Inquiry},
  volume={56},
  number={4},
  pages={2195--2211},
  year={2018},
  publisher={Wiley Online Library}
}

@article{zhang2021gradient,
  title={Gradient play in stochastic games: stationary points, convergence, and sample complexity},
  author={Zhang, Runyu and Ren, Zhaolin and Li, Na},
  journal={arXiv preprint arXiv:2106.00198},
  year={2021}
}

@article{cai2011minmax,
  title={On minmax theorems for multiplayer games},
  author={Cai, Yang and Daskalakis, Constantinos},
  journal={SODA},
  year={2011},
}
@inproceedings{daskalakis2009network,
  title={On a network generalization of the minmax theorem},
  author={Daskalakis, Constantinos and Papadimitriou, Christos H},
  booktitle={International Colloquium on Automata, Languages, and Programming},
  pages={423--434},
  year={2009},
  organization={Springer}
}
@inproceedings{kempe2003maximizing,
  title={Maximizing the spread of influence through a social network},
  author={Kempe, David and Kleinberg, Jon and Tardos, {\'E}va},
  booktitle={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={137--146},
  year={2003}
}

@article{bergman1987methods,
  title={Methods of determining equilibrium situations in zero-sum polymatrix games},
  author={Bergman, LM and Fokin, IN},
  journal={Optimizatsia},
  volume={40},
  number={57},
  pages={70--82},
  year={1987}
}

@article{bergman1998separable,
  title={On separable non-cooperative zero-sum games},
  author={Bergman, LM and Fokin, IN},
  journal={Optimization},
  volume={44},
  number={1},
  pages={69--84},
  year={1998},
  publisher={Taylor \& Francis}
}

@article{leonardos2021global,
  title={Global convergence of multi-agent policy gradient in markov potential games},
  author={Leonardos, Stefanos and Overman, Will and Panageas, Ioannis and Piliouras, Georgios},
  journal={ICLR},
  year={2022}
}
@article{fox2022independent,
  title={Independent natural policy gradient always converges in Markov potential games},
  author={Fox, Roy and Mcaleer, Stephen M and Overman, Will and Panageas, Ioannis},
  journal={AISTATS},
  year={2022},
}
@article{ding2022independent,
  title={Independent policy gradient for large-scale markov potential games: Sharper rates, function approximation, and game-agnostic convergence},
  author={Ding, Dongsheng and Wei, Chen-Yu and Zhang, Kaiqing and Jovanovic, Mihailo},
  journal = {ICML}, 
  year={2022}
}

@article{macua2018learning,
  title={Learning parametric closed-loop policies for markov potential games},
  author={Macua, Sergio Valcarcel and Zazo, Javier and Zazo, Santiago},
  journal={arXiv preprint arXiv:1802.00899},
  year={2018}
}
@article{alfano2021dimension,
  title={Dimension-Free Rates for Natural Policy Gradient in Multi-Agent Reinforcement Learning},
  author={Alfano, Carlo and Rebeschini, Patrick},
  journal={arXiv preprint arXiv:2109.11692},
  year={2021}
}
@article{qu2020scalable,
  title={Scalable multi-agent reinforcement learning for networked systems with average reward},
  author={Qu, Guannan and Lin, Yiheng and Wierman, Adam and Li, Na},
  journal={NeurIPS},
  year={2020}
}

@article{qu2019exploiting,
  title={Exploiting fast decaying and locality in multi-agent mdp with tree dependence structure},
  author={Qu, Guannan and Li, Na},
  journal={CDC},
  year={2019}
}

@article{lin2020distributed,
  title={Distributed reinforcement learning in multi-agent networked systems},
  author={Lin, Yiheng and Qu, Guannan and Huang, Longbo and Wierman, Adam},
  journal={arXiv},
  year={2020}
}

@article{gu2021mean,
  title={Mean-field multi-agent reinforcement learning: A decentralized network approach},
  author={Gu, Haotian and Guo, Xin and Wei, Xiaoli and Xu, Renyuan},
  journal={arXiv preprint arXiv:2108.02731},
  year={2021}
}

@article{lin2020multi,
  title={Multi-Agent Reinforcement Learning in Stochastic Networked Systems},
  author={Lin, Yiheng and Qu, Guannan and Huang, Longbo and Wierman, Adam},
  journal={NeurIPS},
  year={2021}
}

@incollection{georgii2011gibbs,
  title={Gibbs measures and phase transitions},
  author={Georgii, Hans-Otto},
  booktitle={Gibbs Measures and Phase Transitions},
  year={2011},
  publisher={de Gruyter}
}
@article{li2020sample,
  title={Sample complexity of asynchronous Q-learning: Sharper analysis and variance reduction},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={NeurIPS},
  year={2020}
}
@article{wei2021learning,
  title={Learning infinite-horizon average-reward mdps with linear function approximation},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Jain, Rahul},
  journal={AISTATS},
  year={2021}
  }
  
@article{fink1964equilibrium,
	title={Equilibrium in a stochastic $ n $-person game},
	author={Fink, Arlington M and others},
	journal={Journal of Science of the Hiroshima University, Series A-I (Mathematics)},
	volume={28},
	number={1},
	pages={89--93},
	year={1964},
	publisher={Hiroshima University, Department of Mathematics}
}

@article{chen2009settling,
  title={Settling the complexity of computing two-player Nash equilibria},
  author={Chen, Xi and Deng, Xiaotie and Teng, Shang-Hua},
  journal={Journal of the ACM (JACM)},
  volume={56},
  number={3},
  pages={1--57},
  year={2009},
  publisher={ACM New York, NY, USA}
}

@article{daskalakis2009complexity,
  title={The complexity of computing a Nash equilibrium},
  author={Daskalakis, Constantinos and Goldberg, Paul W and Papadimitriou, Christos H},
  journal={SIAM Journal on Computing},
  volume={39},
  number={1},
  pages={195--259},
  year={2009},
  publisher={SIAM}
}
@inproceedings{chen20053,
  title={3-Nash is PPAD-complete},
  author={Chen, Xi and Deng, Xiaotie},
  booktitle={Electronic Colloquium on Computational Complexity},
  volume={134},
  pages={2--29},
  year={2005},
  organization={Citeseer}
}
@inproceedings{daskalakis2005three,
  title={Three-player games are hard},
  author={Daskalakis, Constantinos and Papadimitriou, Christos H},
  booktitle={Electronic colloquium on computational complexity},
  volume={139},
  pages={81--87},
  year={2005}
}

@article{cai2016zero,
  title={Zero-sum polymatrix games: A generalization of minmax},
  author={Cai, Yang and Candogan, Ozan and Daskalakis, Constantinos and Papadimitriou, Christos},
  journal={Mathematics of Operations Research},
  volume={41},
  number={2},
  pages={648--655},
  year={2016},
  publisher={INFORMS}
}

@article{daskalakis2022complexity,
  title={The complexity of markov equilibrium in stochastic games},
  author={Daskalakis, Constantinos and Golowich, Noah and Zhang, Kaiqing},
  journal={arXiv preprint arXiv:2204.03991},
  year={2022}
}

@article{zhang2022policy,
  title={Policy Optimization for Markov Games: Unified Framework and Faster Convergence},
  author={Zhang, Runyu and Liu, Qinghua and Wang, Huan and Xiong, Caiming and Li, Na and Bai, Yu},
  journal={NeurIPS},
  year={2022}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the national academy of sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}
@article{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  journal={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}
@article{littman2001friend,
  title={Friend-or-foe Q-learning in general-sum games},
  author={Littman, Michael L and others},
  journal={ICML},
  year={2001}
}@article{hu2003nash,
  title={Nash Q-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={JMLR},
  year={2003}
}

@article{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  journal={ICML},
  year={2020}
}

@article{littman2001value,
  title={Value-function reinforcement learning in Markov games},
  author={Littman, Michael L},
  journal={Cognitive systems research},
  volume={2},
  number={1},
  pages={55--66},
  year={2001},
  publisher={Elsevier}
}

@article{sidford2020solving,
  title={Solving discounted stochastic two-player games with near-optimal time and sample complexity},
  author={Sidford, Aaron and Wang, Mengdi and Yang, Lin and Ye, Yinyu},
  journal = {AISTATS}, 
  year={2020}
}

@article{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  journal={COLT},
  year={2020}
}
@article{bai2020near,
  title={Near-optimal reinforcement learning with self-play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={NeurIPS},
  year={2020}
}

@article{liu2021sharp,
  title={A sharp analysis of model-based reinforcement learning with self-play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  journal={ICML},
  year={2021}
  }

@article{zhao2021provably,
  title={Provably efficient policy gradient methods for two-player zero-sum Markov games},
  author={Zhao, Yulai and Tian, Yuandong and Lee, Jason D and Du, Simon S},
  journal={AISTATS},
  year={2022}
}

@article{erez2022regret,
  title={Regret minimization and convergence to equilibria in general-sum markov games},
  author={Erez, Liad and Lancewicki, Tal and Sherman, Uri and Koren, Tomer and Mansour, Yishay},
  journal={arXiv preprint arXiv:2207.14211},
  year={2022}
}

@article{guestrin2002algorithm,
  title={Algorithm-directed exploration for model-based reinforcement learning in factored MDPs},
  author={Guestrin, Carlos and Patrascu, Relu and Schuurmans, Dale},
  journal={ICML},
  year={2002}
}

@article{kearns1999efficient,
  title={Efficient reinforcement learning in factored MDPs},
  author={Kearns, Michael and Koller, Daphne},
  journal={IJCAI},
  year={1999}
}

@inproceedings{strehl2007model,
  title={Model-based reinforcement learning in factored-state MDPs},
  author={Strehl, Alexander L},
  booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning},
  pages={103--110},
  year={2007},
  organization={IEEE}
}

@article{szita2009optimistic,
  title={Optimistic initialization and greediness lead to polynomial time learning in factored MDPs},
  author={Szita, Istv{\'a}n and L{\H{o}}rincz, Andr{\'a}s},
  journal ={ICML},
  year={2009}
}

@article{osband2014near,
  title={Near-optimal reinforcement learning in factored mdps},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={NeurIPS},
  year={2014}
}
@article{xu2020near,
  title={Near-optimal Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms for the Non-episodic Setting.},
  author={Xu, Ziping and Tewari, Ambuj},
  year={2020}
}

@article{tian2020towards,
  title={Towards minimax optimal reinforcement learning in factored markov decision processes},
  author={Tian, Yi and Qian, Jian and Sra, Suvrit},
  journal={NeurIPS},
  year={2020}
}

@incollection{huang2018factored,
  title={Factored markov game theory for secure interdependent infrastructure networks},
  author={Huang, Linan and Chen, Juntao and Zhu, Quanyan},
  booktitle={Game theory for security and risk management},
  pages={99--126},
  year={2018},
  publisher={Springer}
}

@article{ni2022representation,
  title={Representation Learning for General-sum Low-rank Markov Games},
  author={Ni, Chengzhuo and Song, Yuda and Zhang, Xuezhou and Jin, Chi and Wang, Mengdi},
  journal={arXiv preprint arXiv:2210.16976},
  year={2022}
}

@article{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  journal={ICML},
  year={1993}
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI},
  volume={1998},
  year={1998}
}

@article{zhang2022global,
  title={Global Convergence of Localized Policy Iteration in Networked Multi-Agent Reinforcement Learning},
  author={Zhang, Yizhou and Qu, Guannan and Xu, Pan and Lin, Yiheng and Chen, Zaiwei and Wierman, Adam},
  journal={arXiv preprint arXiv:2211.17116},
  year={2022}
}

@article{liu2022scalable,
  title={Scalable and Sample Efficient Distributed Policy Gradient Algorithms in Multi-Agent Networked Systems},
  author={Liu, Xin and Wei, Honghao and Ying, Lei},
  journal={arXiv preprint arXiv:2212.06357},
  year={2022}
}

@incollection{jackson2015games,
  title={Games on networks},
  author={Jackson, Matthew O and Zenou, Yves},
  booktitle={Handbook of game theory with economic applications},
  volume={4},
  pages={95--163},
  year={2015},
  publisher={Elsevier}
}


@article{kearns2013graphical,
  title={Graphical models for game theory},
  author={Kearns, Michael and Littman, Michael L and Singh, Satinder},
  journal={UAI},
  year={2001}
}

@article{kakade2003correlated,
  title={Correlated equilibria in graphical games},
  author={Kakade, Sham and Kearns, Michael and Langford, John and Ortiz, Luis},
  journal={EC},
  year={2003}
}

@article{leonardos2021exploration,
  title={Exploration-exploitation in multi-agent competition: convergence with bounded rationality},
  author={Leonardos, Stefanos and Piliouras, Georgios and Spendlove, Kelly},
  journal={NeurIPS},
  year={2021}
}

@article{anagnostides2022last,
  title={On Last-Iterate Convergence Beyond Zero-Sum Games},
  author={Anagnostides, Ioannis and Panageas, Ioannis and Farina, Gabriele and Sandholm, Tuomas},
  journal={ICML},
  year={2022}
}

@article{ao2022asynchronous,
  title={Asynchronous Gradient Play in Zero-Sum Multi-agent Games},
  author={Ao, Ruicheng and Cen, Shicong and Chi, Yuejie},
  journal={arXiv preprint arXiv:2211.08980},
  year={2022}
}

@article{pattathil2022symmetric,
  title={Symmetric (Optimistic) Natural Policy Gradient for Multi-agent Learning with Parameter Convergence},
  author={Pattathil, Sarath and Zhang, Kaiqing and Ozdaglar, Asuman},
  journal={arXiv preprint arXiv:2210.12812},
  year={2022}
}

@article{alacaoglu2022natural,
  title={A natural actor-critic framework for zero-sum Markov games},
  author={Alacaoglu, Ahmet and Viano, Luca and He, Niao and Cevher, Volkan},
  journal={ICML},
  year={2022}
}

@article{cen2021fast,
  title={Fast policy extragradient methods for competitive games with entropy regularization},
  author={Cen, Shicong and Wei, Yuting and Chi, Yuejie},
  journal={NeurIPS},
  year={2021}
}

@article{chen2021sample,
  title={Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game},
  author={Chen, Ziyi and Ma, Shaocong and Zhou, Yi},
  journal={ICLR},
  year={2021}
}

@article{daskalakis2020independent,
  title={Independent policy gradient methods for competitive reinforcement learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={NeurIPS},
  year={2020}
}

@article{zeng2022regularized,
  title={Regularized Gradient Descent Ascent for Two-Player Zero-Sum Markov Games},
  author={Zeng, Sihan and Doan, Thinh T and Romberg, Justin},
  journal={NeurIPS},
  year={2022}
}
@article{wei2021last,
  title={Last-iterate convergence of decentralized optimistic gradient descent/ascent in infinite-horizon competitive markov games},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={COLT},
  year={2021}
}

@article{cen2022faster,
  title={Faster last-iterate convergence of policy optimization in zero-sum markov games},
  author={Cen, Shicong and Chi, Yuejie and Du, Simon S and Xiao, Lin},
  journal={arXiv preprint arXiv:2210.01050},
  year={2022}
}

@article{daskalakis2022non,
  title={Non-Concave Games: A Challenge for Game Theory’s Next 100 Years},
  author={Daskalakis, Constantinos},
  year={2022}
}
@article{mertikopoulos2016learning,
  title={Learning in games via reinforcement and regularization},
  author={Mertikopoulos, Panayotis and Sandholm, William H},
  journal={Mathematics of Operations Research},
  volume={41},
  number={4},
  pages={1297--1324},
  year={2016},
  publisher={INFORMS}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={NeurIPS},
  year={2018}
}

@article{brown1951iterative,
  title={Iterative solution of games by fictitious play},
  author={Brown, George W},
  journal={Act. Anal. Prod Allocation},
  volume={13},
  number={1},
  pages={374},
  year={1951}
}
@article{robinson1951iterative,
  title={An iterative method of solving a game},
  author={Robinson, Julia},
  journal={Annals of mathematics},
  pages={296--301},
  year={1951},
  publisher={JSTOR}
}

@article{miyasawa1961convergence,
  title={On the convergence of the learning process in a 2 x 2 non-zero-sum two-person game},
  author={Miyasawa, Koichi},
  year={1961},
  publisher={Princeton University}
}

@article{monderer1996fictitious,
  title={Fictitious play property for games with identical interests},
  author={Monderer, Dov and Shapley, Lloyd S},
  journal={Journal of economic theory},
  volume={68},
  number={1},
  pages={258--265},
  year={1996},
  publisher={Elsevier}
}

@article{berger2005fictitious,
  title={Fictitious play in 2 x n games},
  author={Berger, Ulrich},
  journal={Journal of Economic Theory},
  volume={120},
  number={2},
  pages={139--154},
  year={2005},
  publisher={Elsevier}
}
@article{perrin2020fictitious,
  title={Fictitious play for mean field games: Continuous time analysis and applications},
  author={Perrin, Sarah and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Geist, Matthieu and Elie, Romuald and Pietquin, Olivier},
  journal={NeurIPS},
  year={2020}
}

@article{leslie2020best,
  title={Best-response dynamics in zero-sum stochastic games},
  author={Leslie, David S and Perkins, Steven and Xu, Zibo},
  journal={Journal of Economic Theory},
  volume={189},
  pages={105095},
  year={2020},
  publisher={Elsevier}
}

@article{ozdaglar2021independent,
  title={Independent learning in stochastic games},
  author={Ozdaglar, Asuman and Sayin, Muhammed O and Zhang, Kaiqing},
  journal={International Congress of Mathematicians},
  year={2022}
}
@article{sayin2021decentralized,
  title={Decentralized Q-learning in zero-sum Markov games},
  author={Sayin, Muhammed and Zhang, Kaiqing and Leslie, David and Basar, Tamer and Ozdaglar, Asuman},
  journal={NeurIPS},
  year={2021}
}
@article{sayin2022fictitious,
  title={Fictitious play in zero-sum stochastic games},
  author={Sayin, Muhammed O and Parise, Francesca and Ozdaglar, Asuman},
  journal={SIAM Journal on Control and Optimization},
  volume={60},
  number={4},
  pages={2095--2114},
  year={2022},
  publisher={SIAM}
}
@article{sayin2022global,
  title={On the global convergence of stochastic fictitious play in stochastic games with turn-based controllers},
  author={Sayin, Muhammed O},
  journal={CDC},
  year={2022}
}
@article{shapley1964some,
  title={Some topics in two-person games},
  author={Shapley, Lloyd},
  journal={Advances in game theory},
  volume={52},
  pages={1--29},
  year={1964}
}

@article{baudin2022fictitious,
  title={Fictitious play and best-response dynamics in identical interest and zero-sum stochastic games},
  author={Baudin, Lucas and Laraki, Rida},
  journal={ICML},
  year={2022}
}

@inproceedings{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  booktitle={AAMAS},
  year={2018}
}
@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={JMLR},
  year={2020}
}
@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of reinforcement learning and control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}
@article{dou2022understanding,
  title={Understanding Value Decomposition Algorithms in Deep Cooperative Multi-Agent Reinforcement Learning},
  author={Dou, Zehao and Kuba, Jakub Grudzien and Yang, Yaodong},
  journal={arXiv preprint arXiv:2202.04868},
  year={2022}
}
@article{benaim2005stochastic,
  title={Stochastic approximations and differential inclusions},
  author={Bena{\"\i}m, Michel and Hofbauer, Josef and Sorin, Sylvain},
  journal={SIAM Journal on Control and Optimization},
  volume={44},
  number={1},
  pages={328--348},
  year={2005},
  publisher={SIAM}
}
@article{harris1998rate,
  title={On the rate of convergence of continuous-time fictitious play},
  author={Harris, Christopher},
  journal={Games and Economic Behavior},
  volume={22},
  number={2},
  pages={238--259},
  year={1998},
  publisher={Elsevier}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{welleckgenerating,
  title={Generating Sequences by Learning to Self-Correct},
  author={Welleck, Sean and Lu, Ximing and West, Peter and Brahman, Faeze and Shen, Tianxiao and Khashabi, Daniel and Choi, Yejin},
  booktitle={The Eleventh International Conference on Learning Representations},
year={2023}
}

@inproceedings{qu2024recursive,
  title={Recursive Introspection: Teaching Language Model Agents How to Self-Improve},
  author={Qu, Yuxiao and Zhang, Tianjun and Garg, Naman and Kumar, Aviral},
  booktitle={NeurIPS},
  year={2024}
}

@article{zelikman2022star,
  title={Star: Bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15476--15488},
  year={2022}
}

@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{khandebating,
  title={Debating with More Persuasive LLMs Leads to More Truthful Answers},
  author={Khan, Akbir and Hughes, John and Valentine, Dan and Ruis, Laura and Sachan, Kshitij and Radhakrishnan, Ansh and Grefenstette, Edward and Bowman, Samuel R and Rockt{\"a}schel, Tim and Perez, Ethan},
  booktitle={Forty-first International Conference on Machine Learning}, 
year={2024}
}

@inproceedings{zhao2024longagent,
  title={LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration},
  author={Zhao, Jun and Zu, Can and Xu, Hao and Lu, Yi and He, Wei and Ding, Yiwen and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
  booktitle={EMNLP},
  year={2024}
}

@inproceedings{li2024improving,
  title={Improving Multi-Agent Debate with Sparse Communication Topology},
  author={Li, Yunxuan and Du, Yibing and Zhang, Jiageng and Hou, Le and Grabowski, Peter and Li, Yeqing and Ie, Eugene},
  booktitle={EMNLP Findings},
  year={2024}
}

@article{kirchner2024prover,
  title={Prover-Verifier Games improve legibility of LLM outputs},
  author={Kirchner, Jan Hendrik and Chen, Yining and Edwards, Harri and Leike, Jan and McAleese, Nat and Burda, Yuri},
  journal={arXiv preprint arXiv:2407.13692},
  year={2024}
}

@inproceedings{tianfine,
  title={Fine-Tuning Language Models for Factuality},
  author={Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@inproceedings{ahmadian-etal-2024-back,
    title = "Back to Basics: Revisiting {REINFORCE}-Style Optimization for Learning from Human Feedback in {LLM}s",
    author = {Ahmadian, Arash  and
      Cremer, Chris  and
      Gall{\'e}, Matthias  and
      Fadaee, Marzieh  and
      Kreutzer, Julia  and
      Pietquin, Olivier  and
      {\"U}st{\"u}n, Ahmet  and
      Hooker, Sara},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.662",
    doi = "10.18653/v1/2024.acl-long.662",
    pages = "12248--12267",
    abstract = "AI alignment in the shape of Reinforcement Learning from Human Feedback (RLHF) is increasingly treated as a crucial ingredient for high performance large language models. Proximal Policy Optimization (PPO) has been installed by the seminal literature as the standard method for the RL part of RLHF. However, it involves both high computational cost and sensitive hyperparameter tuning. We posit that most of the motivational principles that led to the development of PPO are less of a practical concern in RLHF and advocate for a less computationally expensive method that preserves and even increases performance. We revisit how alignment from human preferences is formulated in the context of RL. Keeping simplicity as a guiding principle, we show that many components of PPO are unnecessary in an RLHF context and that far simpler REINFORCE-style optimization variants outperform both PPO and newly proposed {``}RL-free{''} methods such as DPO and RAFT. Our work suggests that careful adaptation to LLMs alignment characteristics allows benefiting from online RL optimization at low cost.",
}

@inproceedings{shani2024multi,
  title={Multi-turn Reinforcement Learning from Preference Human Feedback},
  author={Shani, Lior and Rosenberg, Aviv and Cassel, Asaf and Lang, Oran and Calandriello, Daniele and Zipori, Avital and Noga, Hila and Keller, Orgad and Piot, Bilal and Szpektor, Idan and others},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{xiong2024building,
  title={Building Math Agents with Multi-Turn Iterative Preference Learning},
  author={Xiong, Wei and Shi, Chengshuai and Shen, Jiaming and Rosenberg, Aviv and Qin, Zhen and Calandriello, Daniele and Khalman, Misha and Joshi, Rishabh and Piot, Bilal and Saleh, Mohammad and others},
  booktitle={ICLR},
  year={2025}
}

@article{kim2024language,
  title={Language models can solve computer tasks},
  author={Kim, Geunwoo and Baldi, Pierre and McAleer, Stephen},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{yang2018hotpotqa,
  title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William and Salakhutdinov, Ruslan and Manning, Christopher D},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2369--2380},
  year={2018}
}

@inproceedings{skyrms2001stag,
  title={The stag hunt},
  author={Skyrms, Brian},
  booktitle={Proceedings and Addresses of the American Philosophical Association},
  volume={75},
  number={2},
  pages={31--41},
  year={2001},
  organization={JSTOR}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@inproceedings{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  booktitle={ICLR},
  year={2016}
}

@inproceedings{hulora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}