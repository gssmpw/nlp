@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}


@article{Alcami2003,
  author    = {Antonio Alcami},
  title     = {Viral mimicry of cytokines, chemokines and their receptors},
  journal   = {Nature Reviews Immunology},
  volume    = {3},
  number    = {1},
  pages     = {36--50},
  year      = {2003},
  doi       = {10.1038/nri980}
}

@article{Felix2017,
  author    = {Jan Felix and Savvas N. Savvides},
  title     = {Mechanisms of immunomodulation by mammalian and viral decoy receptors: insights from structures},
  journal   = {Nature Reviews Immunology},
  volume    = {17},
  number    = {2},
  pages     = {112--129},
  year      = {2017},
  doi       = {10.1038/nri.2016.134}
}

@article{Seet2003,
  author    = {Bruce T. Seet and James B. Johnston and Craig R. Brunetti and John W. Barrett and Helen Everett and Cheryl Cameron and Joanna Sypula and Steven H. Nazarian and Alexandra Lucas and Grant McFadden},
  title     = {Poxviruses and immune evasion},
  journal   = {Annual Review of Immunology},
  volume    = {21},
  pages     = {377--423},
  year      = {2003},
  doi       = {10.1146/annurev.immunol.21.120601.141049}
}

@article{Maizels2018,
  author    = {Rick M. Maizels and Hermelijn H. Smits and Henry J. McSorley},
  title     = {Modulation of Host Immunity by Helminths: The Expanding Repertoire of Parasite Effector Molecules},
  journal   = {Immunity},
  volume    = {49},
  number    = {5},
  pages     = {801--818},
  year      = {2018},
  doi       = {10.1016/j.immuni.2018.10.016}
}


@misc{openai2024openaio1card,
      title={OpenAI o1 System Card}, 
      author={OpenAI and : and Aaron Jaech and Adam Kalai and Adam Lerer and Adam Richardson and Ahmed El-Kishky and Aiden Low and Alec Helyar and Aleksander Madry and Alex Beutel and Alex Carney and Alex Iftimie and Alex Karpenko and Alex Tachard Passos and Alexander Neitz and Alexander Prokofiev and Alexander Wei and Allison Tam and Ally Bennett and Ananya Kumar and Andre Saraiva and Andrea Vallone and Andrew Duberstein and Andrew Kondrich and Andrey Mishchenko and Andy Applebaum and Angela Jiang and Ashvin Nair and Barret Zoph and Behrooz Ghorbani and Ben Rossen and Benjamin Sokolowsky and Boaz Barak and Bob McGrew and Borys Minaiev and Botao Hao and Bowen Baker and Brandon Houghton and Brandon McKinzie and Brydon Eastman and Camillo Lugaresi and Cary Bassin and Cary Hudson and Chak Ming Li and Charles de Bourcy and Chelsea Voss and Chen Shen and Chong Zhang and Chris Koch and Chris Orsinger and Christopher Hesse and Claudia Fischer and Clive Chan and Dan Roberts and Daniel Kappler and Daniel Levy and Daniel Selsam and David Dohan and David Farhi and David Mely and David Robinson and Dimitris Tsipras and Doug Li and Dragos Oprica and Eben Freeman and Eddie Zhang and Edmund Wong and Elizabeth Proehl and Enoch Cheung and Eric Mitchell and Eric Wallace and Erik Ritter and Evan Mays and Fan Wang and Felipe Petroski Such and Filippo Raso and Florencia Leoni and Foivos Tsimpourlas and Francis Song and Fred von Lohmann and Freddie Sulit and Geoff Salmon and Giambattista Parascandolo and Gildas Chabot and Grace Zhao and Greg Brockman and Guillaume Leclerc and Hadi Salman and Haiming Bao and Hao Sheng and Hart Andrin and Hessam Bagherinezhad and Hongyu Ren and Hunter Lightman and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian Osband and Ignasi Clavera Gilaberte and Ilge Akkaya and Ilya Kostrikov and Ilya Sutskever and Irina Kofman and Jakub Pachocki and James Lennon and Jason Wei and Jean Harb and Jerry Twore and Jiacheng Feng and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joaquin Quiñonero Candela and Joe Palermo and Joel Parish and Johannes Heidecke and John Hallman and John Rizzo and Jonathan Gordon and Jonathan Uesato and Jonathan Ward and Joost Huizinga and Julie Wang and Kai Chen and Kai Xiao and Karan Singhal and Karina Nguyen and Karl Cobbe and Katy Shi and Kayla Wood and Kendra Rimbach and Keren Gu-Lemberg and Kevin Liu and Kevin Lu and Kevin Stone and Kevin Yu and Lama Ahmad and Lauren Yang and Leo Liu and Leon Maksin and Leyton Ho and Liam Fedus and Lilian Weng and Linden Li and Lindsay McCallum and Lindsey Held and Lorenz Kuhn and Lukas Kondraciuk and Lukasz Kaiser and Luke Metz and Madelaine Boyd and Maja Trebacz and Manas Joglekar and Mark Chen and Marko Tintor and Mason Meyer and Matt Jones and Matt Kaufer and Max Schwarzer and Meghan Shah and Mehmet Yatbaz and Melody Y. Guan and Mengyuan Xu and Mengyuan Yan and Mia Glaese and Mianna Chen and Michael Lampe and Michael Malek and Michele Wang and Michelle Fradin and Mike McClay and Mikhail Pavlov and Miles Wang and Mingxuan Wang and Mira Murati and Mo Bavarian and Mostafa Rohaninejad and Nat McAleese and Neil Chowdhury and Neil Chowdhury and Nick Ryder and Nikolas Tezak and Noam Brown and Ofir Nachum and Oleg Boiko and Oleg Murk and Olivia Watkins and Patrick Chao and Paul Ashbourne and Pavel Izmailov and Peter Zhokhov and Rachel Dias and Rahul Arora and Randall Lin and Rapha Gontijo Lopes and Raz Gaon and Reah Miyara and Reimar Leike and Renny Hwang and Rhythm Garg and Robin Brown and Roshan James and Rui Shu and Ryan Cheu and Ryan Greene and Saachi Jain and Sam Altman and Sam Toizer and Sam Toyer and Samuel Miserendino and Sandhini Agarwal and Santiago Hernandez and Sasha Baker and Scott McKinney and Scottie Yan and Shengjia Zhao and Shengli Hu and Shibani Santurkar and Shraman Ray Chaudhuri and Shuyuan Zhang and Siyuan Fu and Spencer Papay and Steph Lin and Suchir Balaji and Suvansh Sanjeev and Szymon Sidor and Tal Broda and Aidan Clark and Tao Wang and Taylor Gordon and Ted Sanders and Tejal Patwardhan and Thibault Sottiaux and Thomas Degry and Thomas Dimson and Tianhao Zheng and Timur Garipov and Tom Stasi and Trapit Bansal and Trevor Creech and Troy Peterson and Tyna Eloundou and Valerie Qi and Vineet Kosaraju and Vinnie Monaco and Vitchyr Pong and Vlad Fomenko and Weiyi Zheng and Wenda Zhou and Wes McCabe and Wojciech Zaremba and Yann Dubois and Yinghai Lu and Yining Chen and Young Cha and Yu Bai and Yuchen He and Yuchen Zhang and Yunyun Wang and Zheng Shao and Zhuohan Li},
      year={2024},
      eprint={2412.16720},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.16720}, 
}


@misc{openai2024o3mini,
  author    = {OpenAI},
  title     = {OpenAI o3-mini System Card},
  year      = {January 31, 2025},
  url       = {https://cdn.openai.com/o3-mini-system-card.pdf},
  note      = {Accessed: 2025-02-11}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@misc{deepmind2024flashthinking,
  author    = {Google DeepMind},
  title     = {Gemini 2.0 Flash Thinking},
  year      = {2024},
  url       = {https://deepmind.google/technologies/gemini/flash-thinking/},
  note      = {2024}
}

@misc{arrieta2025o3minivsdeepseekr1safer,
      title={o3-mini vs DeepSeek-R1: Which One is Safer?}, 
      author={Aitor Arrieta and Miriam Ugarte and Pablo Valle and José Antonio Parejo and Sergio Segura},
      year={2025},
      eprint={2501.18438},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2501.18438}, 
}


@article{arrieta2025early,
  title={Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation},
  author={Arrieta, Aitor and Ugarte, Miriam and Valle, Pablo and Parejo, Jos{\'e} Antonio and Segura, Sergio},
  journal={arXiv preprint arXiv:2501.17749},
  year={2025}
}

@article{ren2024derail,
  title={Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues},
  author={Ren, Qibing and Li, Hao and Liu, Dongrui and Xie, Zhanxu and Lu, Xiaoya and Qiao, Yu and Sha, Lei and Yan, Junchi and Ma, Lizhuang and Shao, Jing},
  journal={arXiv preprint arXiv:2410.10700},
  year={2024}
}

@article{Wei2023JailbreakAG,
  title={Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations},
  author={Zeming Wei and Yifei Wang and Yisen Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.06387},
  url={https://api.semanticscholar.org/CorpusID:263830179}
}

@article{guan2024deliberative,
  title={Deliberative alignment: Reasoning enables safer language models},
  author={Guan, Melody Y and Joglekar, Manas and Wallace, Eric and Jain, Saachi and Barak, Boaz and Heylar, Alec and Dias, Rachel and Vallone, Andrea and Ren, Hongyu and Wei, Jason and others},
  journal={arXiv preprint arXiv:2412.16339},
  year={2024}
}

@inproceedings{
kang2025rguard,
title={\$R{\textasciicircum}2\$-Guard: Robust Reasoning Enabled {LLM} Guardrail via Knowledge-Enhanced Logical Reasoning},
author={Mintong Kang and Bo Li},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=CkgKSqZbuC}
}

@inproceedings{
kuo2025proactive,
title={Proactive Privacy Amnesia for Large Language Models: Safeguarding {PII} with Negligible Impact on Model Utility},
author={Martin Kuo and Jingyang Zhang and Jianyi Zhang and Minxue Tang and Louis DiValentin and Aolin Ding and Jingwei Sun and William Chen and Amin Hass and Tianlong Chen and Yiran Chen and Hai Li},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=io8uRPYktn}
}


@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@misc{xie2024montecarlotreesearch,
      title={Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning}, 
      author={Yuxi Xie and Anirudh Goyal and Wenyue Zheng and Min-Yen Kan and Timothy P. Lillicrap and Kenji Kawaguchi and Michael Shieh},
      year={2024},
      eprint={2405.00451},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2405.00451}, 
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{Renze2024SelfReflectionIL,
  title={Self-Reflection in LLM Agents: Effects on Problem-Solving Performance},
  author={Matthew Renze and Erhan Guven},
  journal={ArXiv},
  year={2024},
  volume={abs/2405.06682},
  url={https://api.semanticscholar.org/CorpusID:269757480}
}

@misc{zeng2024perceivereflectplandesigning,
      title={Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions}, 
      author={Qingbin Zeng and Qinglong Yang and Shunan Dong and Heming Du and Liang Zheng and Fengli Xu and Yong Li},
      year={2024},
      eprint={2408.04168},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.04168}, 
}


@inproceedings{
zhang2024restmcts,
title={Re{ST}-{MCTS}*: {LLM} Self-Training via Process Reward Guided Tree Search},
author={Dan Zhang and Sining Zhoubian and Ziniu Hu and Yisong Yue and Yuxiao Dong and Jie Tang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=8rcFOqEud5}
}

@misc{zhong2024evaluationopenaio1opportunities,
      title={Evaluation of OpenAI o1: Opportunities and Challenges of AGI}, 
      author={Tianyang Zhong and Zhengliang Liu and Yi Pan and Yutong Zhang and Yifan Zhou and Shizhe Liang and Zihao Wu and Yanjun Lyu and Peng Shu and Xiaowei Yu and Chao Cao and Hanqi Jiang and Hanxu Chen and Yiwei Li and Junhao Chen and Huawen Hu and Yihen Liu and Huaqin Zhao and Shaochen Xu and Haixing Dai and Lin Zhao and Ruidong Zhang and Wei Zhao and Zhenyuan Yang and Jingyuan Chen and Peilong Wang and Wei Ruan and Hui Wang and Huan Zhao and Jing Zhang and Yiming Ren and Shihuan Qin and Tong Chen and Jiaxi Li and Arif Hassan Zidan and Afrar Jahin and Minheng Chen and Sichen Xia and Jason Holmes and Yan Zhuang and Jiaqi Wang and Bochen Xu and Weiran Xia and Jichao Yu and Kaibo Tang and Yaxuan Yang and Bolun Sun and Tao Yang and Guoyu Lu and Xianqiao Wang and Lilong Chai and He Li and Jin Lu and Lichao Sun and Xin Zhang and Bao Ge and Xintao Hu and Lian Zhang and Hua Zhou and Lu Zhang and Shu Zhang and Ninghao Liu and Bei Jiang and Linglong Kong and Zhen Xiang and Yudan Ren and Jun Liu and Xi Jiang and Yu Bao and Wei Zhang and Xiang Li and Gang Li and Wei Liu and Dinggang Shen and Andrea Sikora and Xiaoming Zhai and Dajiang Zhu and Tianming Liu},
      year={2024},
      eprint={2409.18486},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.18486}, 
}



@misc{yi2024jailbreakattacksdefenseslarge,
      title={Jailbreak Attacks and Defenses Against Large Language Models: A Survey}, 
      author={Sibo Yi and Yule Liu and Zhen Sun and Tianshuo Cong and Xinlei He and Jiaxing Song and Ke Xu and Qi Li},
      year={2024},
      eprint={2407.04295},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2407.04295}, 
}

@misc{peng2024jailbreakingmitigationvulnerabilitieslarge,
      title={Jailbreaking and Mitigation of Vulnerabilities in Large Language Models}, 
      author={Benji Peng and Ziqian Bi and Qian Niu and Ming Liu and Pohsun Feng and Tianyang Wang and Lawrence K. Q. Yan and Yizhu Wen and Yichao Zhang and Caitlyn Heqi Yin},
      year={2024},
      eprint={2410.15236},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.15236}, 
}

@misc{zou2023universaltransferableadversarialattacks,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.15043}, 
}

@misc{liu2024autodangeneratingstealthyjailbreak,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.04451}, 
}


@misc{li2024deepinceptionhypnotizelargelanguage,
      title={DeepInception: Hypnotize Large Language Model to Be Jailbreaker}, 
      author={Xuan Li and Zhanke Zhou and Jianing Zhu and Jiangchao Yao and Tongliang Liu and Bo Han},
      year={2024},
      eprint={2311.03191},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2311.03191}, 
}


@misc{yuan2024gpt4smartsafestealthy,
      title={GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher}, 
      author={Youliang Yuan and Wenxiang Jiao and Wenxuan Wang and Jen-tse Huang and Pinjia He and Shuming Shi and Zhaopeng Tu},
      year={2024},
      eprint={2308.06463},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.06463}, 
}

@misc{zhao2024weaktostrongjailbreakinglargelanguage,
      title={Weak-to-Strong Jailbreaking on Large Language Models}, 
      author={Xuandong Zhao and Xianjun Yang and Tianyu Pang and Chao Du and Lei Li and Yu-Xiang Wang and William Yang Wang},
      year={2024},
      eprint={2401.17256},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.17256}, 
}

@misc{liu2024makingaskanswerjailbreaking,
      title={Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction}, 
      author={Tong Liu and Yingjie Zhang and Zhe Zhao and Yinpeng Dong and Guozhu Meng and Kai Chen},
      year={2024},
      eprint={2402.18104},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.18104}, 
}



@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{latif2023artificial,
  title={Artificial general intelligence (AGI) for education},
  author={Latif, Ehsan and Mai, Gengchen and Nyaaba, Matthew and Wu, Xuansheng and Liu, Ninghao and Lu, Guoyu and Li, Sheng and Liu, Tianming and Zhai, Xiaoming},
  journal={arXiv preprint arXiv:2304.12479},
  volume={1},
  year={2023}
}


@article{dou2023towards,
  title={Towards artificial general intelligence (agi) in the internet of things (iot): Opportunities and challenges},
  author={Dou, Fei and Ye, Jin and Yuan, Geng and Lu, Qin and Niu, Wei and Sun, Haijian and Guan, Le and Lu, Guoyu and Mai, Gengchen and Liu, Ninghao and others},
  journal={arXiv preprint arXiv:2309.07438},
  year={2023}
}

@article{masters2024preparing,
  title={Preparing for artificial general intelligence (AGI) in health professions education: AMEE Guide No. 172},
  author={Masters, Ken and Herrmann-Werner, Anne and Festl-Wietek, Teresa and Taylor, David},
  journal={Medical Teacher},
  volume={46},
  number={10},
  pages={1258--1271},
  year={2024},
  publisher={Taylor \& Francis}
}

@misc{openai2025modelspec,
  author    = {OpenAI},
  title     = {Model Specification},
  year      = {2025},
  url       = {https://model-spec.openai.com/2025-02-12.html},
  note      = {2025}
} 


@article{qi2023fine,
  title={Fine-tuning aligned language models compromises safety, even when users do not intend to!},
  author={Qi, Xiangyu and Zeng, Yi and Xie, Tinghao and Chen, Pin-Yu and Jia, Ruoxi and Mittal, Prateek and Henderson, Peter},
  journal={arXiv preprint arXiv:2310.03693},
  year={2023}
}


@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{llama3modelcard,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}



@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}



@misc{openai-chatgpt,
  title = {Introducing ChatGPT},
  author = {OpenAI},
  howpublished = {\url{https://openai.com/blog/chatgpt/}},
  year = {2022},
  month = {November},
}


@ARTICLE{GPT4report,
       author = {{OpenAI}},
        title = "{GPT-4 Technical Report}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
         year = 2023,
        month = mar,
          eid = {arXiv:2303.08774},
        pages = {arXiv:2303.08774},
          doi = {10.48550/arXiv.2303.08774},
archivePrefix = {arXiv},
       eprint = {2303.08774},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2023arXiv230308774O},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}


@inproceedings{NEURIPS2024_0939f13f,
 author = {Zhang, Jianyi and Juan, Da-Cheng and Rashtchian, Cyrus and Ferng, Chun-Sung and Jiang, Heinrich and Chen, Yiran},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {5188--5209},
 publisher = {Curran Associates, Inc.},
 title = {SLED: Self Logits Evolution Decoding for Improving Factuality in Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/0939f13ffce3ff487509d902ddba4571-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}


@article{joren2024sufficient,
  title={Sufficient Context: A New Lens on Retrieval Augmented Generation Systems},
  author={Joren, Hailey and Zhang, Jianyi and Ferng, Chun-Sung and Juan, Da-Cheng and Taly, Ankur and Rashtchian, Cyrus},
  journal={arXiv preprint arXiv:2411.06037},
  year={2024}
}

@inproceedings{zhang-etal-2023-reaugkd,
    title = "{R}e{A}ug{KD}: Retrieval-Augmented Knowledge Distillation For Pre-trained Language Models",
    author = "Zhang, Jianyi  and
      Muhamed, Aashiq  and
      Anantharaman, Aditya  and
      Wang, Guoyin  and
      Chen, Changyou  and
      Zhong, Kai  and
      Cui, Qingjun  and
      Xu, Yi  and
      Zeng, Belinda  and
      Chilimbi, Trishul  and
      Chen, Yiran",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-short.97/",
    doi = "10.18653/v1/2023.acl-short.97",
    pages = "1128--1136",
    abstract = "Knowledge Distillation (KD) is one of the most effective approaches to deploying large-scale pre-trained language models in low-latency environments by transferring the knowledge contained in the large-scale models to smaller student models. Prior KD approaches use the soft labels and intermediate activations generated by the teacher to transfer knowledge to the student model parameters alone. In this paper, we show that having access to non-parametric memory in the form of a knowledge base with the teacher`s soft labels and predictions can further improve student generalization. To enable the student to retrieve from the knowledge base effectively, we propose a new framework and loss function that preserves the semantic similarities of teacher and student training examples. We show through extensive experiments that our retrieval mechanism can achieve state-of-the-art performance for task-specific knowledge distillation on the GLUE benchmark."
}



@article{zhang2024mllm,
  title={Mllm-fl: Multimodal large language model assisted federated learning on heterogeneous and long-tailed data},
  author={Zhang, Jianyi and Yang, Hao Frank and Li, Ang and Guo, Xin and Wang, Pu and Wang, Haiming and Chen, Yiran and Li, Hai},
  journal={arXiv preprint arXiv:2409.06067},
  year={2024}
}


@article{zhang2024artist,
  title={ARTIST: Improving the Generation of Text-rich Images by Disentanglement},
  author={Zhang, Jianyi and Zhou, Yufan and Gu, Jiuxiang and Wigington, Curtis and Yu, Tong and Chen, Yiran and Sun, Tong and Zhang, Ruiyi},
  journal={arXiv preprint arXiv:2406.12044},
  year={2024}
}


@article{yao2024federated,
  title={Federated large language models: Current progress and future directions},
  author={Yao, Yuhang and Zhang, Jianyi and Wu, Junda and Huang, Chengkai and Xia, Yu and Yu, Tong and Zhang, Ruiyi and Kim, Sungchul and Rossi, Ryan and Li, Ang and others},
  journal={arXiv preprint arXiv:2409.15723},
  year={2024}
}


@article{zhang2024min,
  title={Min-k\%++: Improved baseline for detecting pre-training data from large language models},
  author={Zhang, Jingyang and Sun, Jingwei and Yeats, Eric and Ouyang, Yang and Kuo, Martin and Zhang, Jianyi and Yang, Hao Frank and Li, Hai},
  journal={arXiv preprint arXiv:2404.02936},
  year={2024}
}


@INPROCEEDINGS{federatedgpt,
  author={Zhang, Jianyi and Vahidian, Saeed and Kuo, Martin and Li, Chunyuan and Zhang, Ruiyi and Yu, Tong and Wang, Guoyin and Chen, Yiran},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Building The Federatedgpt: Federated Instruction Tuning}, 
  year={2024},
  volume={},
  number={},
  pages={6915-6919},
  keywords={Training;Performance evaluation;Costs;Sensitivity;Instruction sets;Oral communication;Signal processing},
  doi={10.1109/ICASSP48485.2024.10447454}}


@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}