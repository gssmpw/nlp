\section{INTRODUCTION}
% Introduce Multimodal Federated Learning (MFL) with missing modalities.
Multimodal Federated Learning (MFL) has emerged as a transformative approach for collaboratively training machine learning models across distributed clients with multimodal data, especially in privacy-sensitive domains like healthcare \cite{MLF_healthcare_review,MFL_a_survey,survey_of_MFL}. By integrating diverse data modalities, MFL facilitates the development of robust and accurate models for intelligent clinical decision support systems. However, real-world healthcare applications, particularly in cross-institutional brain imaging analysis, often face the challenge of modality incompleteness \cite{FedMI}. Specifically, some institutions  may have access solely to PET imaging data, while others may have access only to MRI data. This disparity in available modalities significantly undermines the performance of traditional federated learning frameworks, which typically assume that all clients have access to the same set of modalities.

% Introduce prototype-based methods and their limitations
To address this challenge, researchers have proposed various methods to mitigate the impact of missing modalities in MFL. These methods can be broadly categorized into prototype-based approaches and generative approaches, each with distinct strengths and limitations. Prototype-based methods \cite{FedMI,MFCPL,PmcmFL} leverage the average of feature embeddings within the same class to serve as prototypes for feature alignment or modality completion. While this approach is effective in capturing general class-level characteristics, it struggles to encapsulate the inherent diversity and complexity of individual data points \cite{prototype_limiation1,prototype_limiation2,prototype_limiation3}. As a result, the simplistic averaging process often produces prototypes that inadequately represent the underlying data distribution, leading to suboptimal alignment of modality-specific feature embeddings and ultimately degrading the global model's performance.

% Introduce generative methods and their limitations
On the other hand, generative approaches attempt to reconstruct missing modalities using generative models, which hold promise for improving data completeness \cite{FedMed-GAN,CACMRN, wu2024deep}. However, these generative methods typically require modality-complete instances for effective training, yet such instances are often scarce in real-world settings of modality-incomplete MFL \cite{CACMRN}. This limitation restricts their applicability to incomplete data and increases the likelihood of introducing noise or inaccuracies during the reconstruction process. Moreover, methods based on Generative Adversarial Networks (GANs) \cite{goodfellow2020generative} are particularly susceptible to mode collapse,  where the model fails to capture the full diversity of the data, leading to the generation of highly similar, non-representative samples \cite{model_collapse1,model_collapse2}. These limitations render generative approaches less robust and reliable in practical applications of modality-incomplete MFL.

% Introduce the limitation on the simulation of federated multimodal scenario.
Beyond the limitations of prototype-based and generative approaches in addressing modality incompleteness in MFL, existing studies on modality-incomplete MFL share several common shortcomings from the perspective of federated learning. One such limitation is the unrealistic simulation of MFL scenarios, which assumes uniform modality availability or consistent missing patterns across all clients. These oversimplified simulations fail to accurately represent real-world modality incompleteness scenarios, thereby limiting their practical applicability, particularly in cross-institutional brain imaging analysis \cite{FedMAC}. Furthermore, much of the current work on MFL with missing modalities employs uniform aggregation weights for different modules within the model during the federated learning process \cite{10654835}. This uniform approach overlooks the varying modality distributions across clients, resulting in suboptimal global model performance.


% Moreover, existing research on modality-incomplete MFL shares several common shortcomings. A significant number of studies assume uniform modality availability or consistent missing patterns across all clients, which limits their practical applicability. Such oversimplified simulations fail to adequately reflect the real-world scenarios of modality incompleteness, particularly in cross-institutional brain imaging analysis \cite{FedMAC}.

% % Introduce the drawback of aggregation method in existing work
% Furthermore, much of the current work on MFL with missing modalities employs uniform aggregation weights for different modules within the model during the federated learning process \cite{10654835}. This uniform approach fails to account for the varying modality distributions across clients, resulting in suboptimal global model performance. 
% % In the absence of adaptive mechanisms to balance the contributions of clients to different modules, the resulting models often do not realize their full potential.

To more accurately reflect the modality incompleteness in real-world scenarios of cross-institutional brain imaging analysis, this paper introduces a realistic and comprehensive setting for modality distribution. Unlike prior studies that assume uniform modality availability or consistent missing modalities across clients, our setting simulates both client-level and instance-level modality incompleteness, as illustrated in \Cref{fig:setting}, capturing the diversity and complexity of modality distribution in real-world applications.

Building on this simulation, we propose ClusMFL, a novel framework designed to address the challenges of modality incompleteness in MFL. Concretely, we apply the FINCH clustering algorithm \cite{FINCH} to cluster feature embeddings and construct a pool of cluster centers for each pair of modality and label across clients, providing a finer-grained representation of data distributions compared to traditional prototype-based methods. To ensure that modality-specific encoders accurately extract modality-specific features related to the labels, we perform feature alignment by employing supervised contrastive loss \cite{supervised_contrastive_loss} over local feature embeddings and the pool of cluster centers. Furthermore, to mitigate the impact of severe modality incompleteness, we use these cluster centers as proxies for the feature embeddings of the missing modalities during the training process, enabling cross-modality knowledge transfer. In addition, we utilize a modality-aware aggregation method that assigns different aggregation weights to various modules of the model based on the modality distributions, effectively balancing the contributions from each client to different modules.

To evaluate the effectiveness of the proposed framework, we conduct extensive experiments under various settings of modality incompleteness and compare ClusMFL with several traditional federated learning algorithms, as well as algorithms specifically designed for modality-incomplete MFL. 
Specifically, we use brain imaging data from the real-world ADNI dataset, which includes structural MRI and PET scans for 915 participants stratified into three diagnostic categories: healthy controls, mild cognitive impairment (MCI), and Alzheimerâ€™s disease (AD) patients. By simulating realistic settings of modality incompleteness on this dataset, we aim to evaluate our framework under conditions that reflect real-world clinical challenges. 
The results show that ClusMFL outperforms existing approaches, particularly in scenarios with substantial modality incompleteness, underscoring its capability to address real-world challenges in MFL.




