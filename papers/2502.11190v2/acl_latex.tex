% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[final]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{wrapfig}   % 用于实现文字环绕图片
\usepackage{float}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{mdframed}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{lipsum}
\usepackage{array}
\usepackage{chngcntr}
\usepackage{ragged2e}
\tcbuselibrary{breakable}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{caption}
\usepackage{colortbl}
\lstset{
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
}

% Define custom column types for better alignment

% \usepackage{colortbl}    % For cell colors
% \usepackage{array}       % For column formatting
% \usepackage{xcolor}
% \newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}}
% \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{ReLearn: Unlearning via Learning  for Large Language Models}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}
\author{
    Haoming Xu\textsuperscript{\rm 1 \thanks{Equal contribution and shared co-first authorship.}},  
    Ningyuan Zhao\textsuperscript{\rm 2 \footnotemark[1]},  
    Liming Yang\textsuperscript{\rm 3},  \\
    \textbf{Sendong Zhao}\textsuperscript{\rm 4},  
    \textbf{Shumin Deng}\textsuperscript{\rm 5},  
    \textbf{Mengru Wang}\textsuperscript{\rm 1}, \\
    \textbf{Bryan Hooi}\textsuperscript{\rm 5}, 
    \textbf{Nay Oo}\textsuperscript{\rm 5},
    \textbf{Huajun Chen}\textsuperscript{\rm 1 \thanks{Corresponding author.}},  
    \textbf{Ningyu Zhang}\textsuperscript{\rm 1 \dag}  
    \\  
    \textsuperscript{\rm 1} Zhejiang University \quad
    \textsuperscript{\rm 2} Xiamen University \quad
    \textsuperscript{\rm 3} Tsinghua University \quad \\
    \textsuperscript{\rm 4} Harbin Institude of Technology \quad
    \textsuperscript{\rm 5} National University of Singapore\\  
    \texttt{\{haomingxu2003, nyzhao2001, uriazdrucker\}@gmail.com} \\  
    \texttt{\{huajunsir, zhangningyu\}@zju.edu.cn}  
}

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\begin{abstract}
Current unlearning methods for large language models usually rely on reverse optimization to reduce target token probabilities. However, this paradigm disrupts the subsequent tokens prediction, degrading model performance and linguistic coherence. Moreover, existing evaluation metrics overemphasize contextual forgetting while inadequately assessing response fluency and relevance. To address these challenges, we propose \textbf{ReLearn}, a data augmentation and fine-tuning pipeline for effective unlearning, along with a comprehensive evaluation framework. This framework introduces Knowledge Forgetting Rate (KFR) and Knowledge Retention Rate (KRR) to measure knowledge-level preservation, and Linguistic Score (LS) to evaluate generation quality. Our experiments show that ReLearn successfully achieves targeted forgetting while preserving high-quality output. Through mechanistic analysis, we further demonstrate how reverse optimization disrupts coherent text generation, while ReLearn preserves this essential capability\footnote{Code is available at \url{https://github.com/zjunlp/unlearn}.}.
\vspace{-1ex}
\begin{center}
  \textit{``The illiterate of the future are not those who can’t read or write but those who cannot learn, unlearn, and relearn.''} — Alvin Toffler
\end{center}
\end{abstract}

\input{sections/1.intro}
\input{sections/2.preliminary}
\input{sections/3.methodology}
\input{sections/4.experiments}
\input{sections/5.analysis}
\input{sections/6.related}
\input{sections/7.conclusion}
% \section*{Acknowledgments}
\section*{Ethical Statement}
This research is conducted with a strong commitment to ethical principles. 
We affirm that all datasets used in this study are either publicly available or synthetically generated to simulate privacy-sensitive scenarios. 
These synthetic datasets contain no personally identifiable information, ensuring that no privacy violations or copyright infringements occurred. 
Furthermore, this work draws inspiration from cognitive linguistic research on Alzheimer's disease, specifically on how linguistic abilities are affected.
However, this is solely for the purpose of analysis and comparison, and we expressly condemn any form of discrimination against individuals with Alzheimer's disease or any other health conditions. 
This study aims to advance knowledge in the field of LLM unlearning in an ethical and responsible manner.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\appendix

\input{sections/8.appendix}

\end{document}
