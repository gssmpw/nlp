\section{Conclusion}

%In this work, we propose an adaptive pruning strategy search framework, named \textsc{OptiShear}, to automatically identify the optimal pruning metrics and layerwise pruning ratios for LLMs with varying weight distributions. Inspired by the recent discovery of emergent large weight magnitude and massive input activation features in LLMs, we introduce a meta pruning metric to adjust the proper relationship between weight and input activation magnitudes. Building upon this, we further search for the optimal non-uniform sparsity ratios across different layers. Without the need for any retraining or weight update procedures, \textsc{OptiShear} can identify effective sparse networks within pretrained LLMs. Through our further generalization evaluation, we demonstrate that the pruning metric derived from the most superior model for arithmetic reasoning also performs well on simpler tasks for models that have similar weight distributions.
In this work, we propose an adaptive pruning strategy search framework, named \textsc{OptiShear}, to automatically identify the optimal pruning metrics and layerwise pruning ratios for LLMs with varying weight distributions. Inspired by the discovery of significant weight and activation features in LLMs, we create a meta pruning metric to balance these magnitudes. \textsc{OptiShear} identifies effective sparse networks in pretrained LLMs without retraining. Our evaluation shows that the metric from the best model for arithmetic reasoning also excels in simpler tasks with similar weight distributions.
% We present \textsc{OptiShear}, an adaptive pruning framework that automatically determines optimal pruning metrics and layer-specific ratios for LLMs with varying weight distributions. Building on insights about important weight and activation patterns in LLMs, we develop a meta pruning metric that balances these magnitudes. 
% \textsc{OptiShear} identifies effective sparse networks in pretrained LLMs without requiring retraining. 
% Our findings show that the metric derived from the best-performing model on arithmetic reasoning transfers effectively to simpler tasks with similar weight distributions.