\section{Proposed Method: \RAEXMC}
\label{sec:method}



%In this section, we introduce \RAEXMC, a novel retrieval-augmented encoder framework for the \XMC problem. We start by formulating the \RAEXMC framework as the \textit{retrieve-from-memory} then \textit{predict} procedure in Section ~\ref{sec:rae-framework}. Then in Section~\ref{sec:rae-modeling}, we describe the model architecture for each component of \RAEXMC. Next, in Section~\ref{sec:rae-inference}, we present the concrete inference algorithm of \RAEXMC for fast retrieving labels in \XMC tasks. In Section~\ref{sec:rae-training}, we discuss the training objective to learn the model parameters of \RAEXMC. \jj{I'd feel this paragraph is a bit redundant, but it might not be critical to keep or remove.}


\subsection{Overall Framework}
\label{sec:rae-framework}
The performance of Dual-Encoder (\DE) methods for \XMC is often hindered by the inherent challenge of \textit{memorization}, requiring the encoding of every detail to effectively predict head labels.
Inspired by the recent success of retrieval-augmented language models~\citep{khandelwal2020generalization,guu2020retrieval,izacard2023atlas,borgeaud2022improving},which have demonstrated remarkable efficacy in leveraging external knowledge to reduce the necessity of encoding all the factual knowledge, we propose the \RAEXMC framework.
Rather than relying solely on the encoding capabilities of \DE models, which may struggle to encapsulate all relevant information, \RAEXMC integrates retrieval mechanisms to augment the inference process.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/RAE-method.002.pdf}
    \caption{The proposed \RAEXMC framework. The knowledge retriever consists of an encoder and a $k$-NN searcher, which retrieves the top $b$ (key, value) pairs from a joint knowledge memory. The key consists of embeddings of training instances and label text descriptions, while the value consists of their corresponding one-hot label vectors. A lightweight predictor then combines the labels based on their scores to generate the final prediction.}
\label{fig:method}
\end{figure}

The overall framework is illustrated in Figure~\ref{fig:method}. 
\RAEXMC decomposes $p(y_\ell \mid  q)$, the conditional probability of label $\ell$ being relevant to a test input $q$, into two steps: (1) \textit{retrieve-from-memory} and (2) \textit{predict}.
Given the test input $q$, we first retrieve possibly relevant
%\jj{helpful sounds weird here.., might be relevant or concretely noting why it's helpful} 
keys $k$ from a knowledge memory $\gK$, which can be modeled by a sampling process from the retriever distribution $p(k \mid q; \theta)$.
Next, conditioned on both the retrieved key $k$ and the test input $q$,
we define the predictive score for label $y_\ell$, denote as $p(y_\ell \mid k, q)$.
In the second step, we compute the predictive score $p(y_\ell \mid k, q)$ for the label $y_\ell$.
Specifically, the inference process of \RAEXMC is defined as 
\begin{equation}
    p(y_\ell \mid q) = \sum_{k \in \gK}
    \underbrace{p(y_\ell  \mid  k, q)}_{\text{Predictor}} \cdot
    \underbrace{p(k  \mid  q; \theta)}_{\text{Retriever}}.
    \label{eq:rae-score}
\end{equation}
In Section~\ref{sec:rae-modeling}, we further reveal the modeling choice of the parametrized knowledge retriever $p(k  \mid  q; \theta)$ and the lightweight (non-parametric) knowledge-augmented predictor $p(y_\ell  \mid  k, q)$ . 



\subsection{Model Architecture}
\label{sec:rae-modeling}

\paragraph{Knowledge Memory.}
For \XMC tasks, we define the knowledge memory $\gK$ as the union of the input instance space $\gX$ and the label space $\gL$, namely $\gK = \gX \cup \gL$.
In other words, the knowledge memory $\gK$ can be viewed as a set of key value pairs, where the key is input/label embeddings and the value is the corresponding one-hot label vectors.
We now present the knowledge memory in the matrix form $\gK = (\rmK, \rmV)$, as defined as
\begin{align}
    \rmK &= [\rvx_1^\top, \ldots, \rvx_{N}^{\top}, \rvz_1^{\top}, \ldots, \rvz_L^{\top} ]
    = [\rmX, \rmZ ] \in \sR^{ (N + L) \times d} \label{eq:rae-key-mat} \\
    \rmV &= [\lambda \rmY, (1-\lambda) \rmI_L] \in [0, 1]^{ (N + L) \times L}, \label{eq:rae-val-mat}
\end{align}
where the key matrix $\rmK$ consists of row-wise stack of training input embeddings $\rvx_i, \forall i=1,\ldots N$,
followed by label embeddings $\rvz_\ell, \forall \ell=1,\ldots,L$.
The value matrix $\rmV$ consists of row-wise stack of the ground truth label matrix $\rmY$ from training set and the diagonal one matrix $\rmI_L$.
Note that we introduce a coefficient $\lambda$ in $\rmV$, which trade-off the impact of predictive scores between the input space $\gX$ and the label space $\gL$.
%We defer the discussion of $\lambda$ to Section~\ref{sec:rae-inference} and its resulting impact on performance to Section~\ref{sec:exp-head-tail}.
We further discuss the impact of $\lambda$ on inference in Section~\ref{sec:rae-inference},
as well as its performance in Section~\ref{sec:exp-head-tail} and Appendix~\ref{sec:exp-lambda}.
%\jj{We further discuss the impact of $\lambda$ on inference and performance in Section~\ref{sec:rae-inference} and Section~\ref{sec:exp-head-tail}.}
%\yaushian{there is also a Section in Appendix~\ref{sec:exp-lambda} discussing this.}
%\peter{Update the $\rmY$ to be $\ell_1$ normalized.}

\paragraph{Knowledge Retriever.}
Given the test input $q$, the retriever of \RAEXMC defines the Softmax distribution over all relevance scores in $\gK$: 
\begin{equation}
    p(k  \mid  q; \theta)
    = \frac{ \exp\big( s_\theta(q, k) / \tau \big) }{ \sum_{k' \in \gK} \exp\big( s_\theta(q, k^{'}) / \tau \big) }
    \sim \text{Softmax}(\rvq^\top \rmK^\top  / \tau),    
\end{equation}
where the underlying scorer is a dense embedding-based model
$s_{\theta}(k, q) = \langle f_\theta(k), f_\theta(q) \rangle$
and $\tau$ is the temperature controlling the skewness of the Softmax distribution.
Note that we adopt the shared encoder setup for both input $q$ and label $\ell$,
which is commonly-used in the \XMC literature~\citep{dahiya2023ngame,dahiya2023deep,gupta2024dual}.
For the embedding function, we consider average pooling of the hidden states from the last layer of the BERT-based Transformer encoder and apply L2-normalization to project the $d$-dimensional vector into the unit-sphere $\sS^{d-1}$:
$\rvk = f_\theta(k) / \| f_\theta(k) \|_2$ and 
$\rvq = f_\theta(q) / \| f_\theta(q) \|_2$.
% \begin{equation*}
%     \rvk = \frac{ f_\theta(k) } { \| f_\theta(k) \|_2 } \in \sS^{d-1}, \quad
%     \rvq = \frac{ f_\theta(q) } { \| f_\theta(q) \|_2 } \in \sS^{d-1}.
% \end{equation*}


\paragraph{Lightweight Predictor.}
Given the test input $q$ and a retrieved key $k$, the knowledge-augmented predictor defines predictive score for label $\ell$ via $p(y_\ell \mid k, q)$.
For knowledge-intense NLP applications that \textit{do not} have strict real-time latency constraints, it is common to learn $p(y_\ell  \mid  k, q)$ via another complex language model (parameterized by $\psi$), which can be encoder-only LMs~\citep{guu2020retrieval}, encoder-decoder LMs~\citep{lewis2020retrieval,izacard2023atlas} or even decoder-only LMs~\citep{borgeaud2022improving}.
While large LMs excel at processing retrieved documents~\citep{gao2024retrievalaugmented},
achieving optimal performance on domain-specific \XMC datasets may necessitate additional fine-tuning, rendering it impractical to scale to extremely enormous label spaces.


On the other hand, practitioners in the \XMC community~\citep{etter2021accelerating,yu2022pecos} often focus on real-time retrieving labels from the extremely large output space, which has high requirements on the inference latency.
Thus, for the \XMC tasks, we aim to design a lightweight predictor by directly looking up the $k$th row and $\ell$ columns of the ground truth Value matrix $\rmV_{k,\ell}$ given the retrieved $k$ and the desirable label $\ell$:
\begin{equation}
    p(y_\ell  \mid  k, q) = \rmV_{k,\ell} \in \{0, 1\}.
\end{equation}
Note that the retrieved key $k \in \gX \cup \gL$ may come from either the training input space $\gX$ or the label space $\gL$.
When $k \in \gX$, we are then essentially using the ground truth label matrix $\rmY_{k,\ell}$ as the predictions (cf., Eq~\ref{eq:rae-val-mat}).
When $k \in \gL$, $V_{k,\ell} = 1 \ \text{iff} \ k = \ell$ due to the diagonal matrix $\rmI_L$ in Equation~\ref{eq:rae-val-mat}, which falls back to using the retrieved label $\ell$ from the knowledge retriever as the predictions. 


\subsection{Inference of \RAEXMC}
\label{sec:rae-inference}
With the modeling choice of knowledge retriever $p(k \mid q; \theta)$ and lightweight predictor $p(y_\ell \mid k, q)$ in Section~\ref{sec:rae-modeling},
we can rewrite Equation~\ref{eq:rae-score} into the matrix form as:
\begin{equation}
    \hat{\rvp}
    = \text{Softmax}(\rvq^\top \rmK^\top / \tau) \rmV \in \sR^{1 \times L},
    \label{eq:rae-inference-exact}
\end{equation}
which outputs $L$-dimensional predictive scores $\hat{\rvp} = [p(y_1 \mid q), \ldots, p(y_\ell \mid q), \ldots, p(y_L \mid q)] \in \sR^L$.

Note that $\lambda$ in $\rmV$ (c.f., Eq~\ref{eq:rae-val-mat}) plays a crucial role.
For $\lambda = \{0.0, 1.0\}$, the inference becomes
\begin{equation}
    \hat{\rvp} =
    \begin{cases}
        \text{Softmax}(\rvq^\top \rmZ^\top / \tau)    , & \ \text{ if } \lambda = 0.0, \\
        \text{Softmax}(\rvq^\top \rmX^\top / \tau)\rmY, & \ \text{ if } \lambda = 1.0.
    \end{cases}
    \label{eq:rase-inference-lambda}
\end{equation}
From the above, we see that the inference of \RAEXMC with $\lambda=0.0$ is equivalent to the inference procedure of dual-encoder models, where the relevance score $\hat{\rvp}_\ell$ is solely determined by the test input embedding $\rvq$ and label embedding $\rvz_\ell$.
On the other hand, the inference of \RAEXMC with $\lambda=1.0$ resembles the classical non-parametric kNN classifiers for multi-label learning~\citep{zhang2007ml},
where the relevance score $\hat{\rvp}_{\ell}$ is determined by the votes from the labels of retrieved training instances.

%\vspace{-.5em}
\paragraph{Implementation.}
Computing relevance scores for all keys in the Softmax distribution costs $\gO(N+L)$,
which is prohibitively expensive for \XMC problems.
Instead, we consider taking only top $b$ keys with highest probability under $\text{Softmax}(\rvq^\top \rmK^\top/\tau)$,
which is reasonable if most keys have near zero probability under certain temperatures.
In Appendix~\ref{sec:key_num}, we found the performance consistently increases with larger $b$, and saturates after some point that is sufficient to approximate the full Softmax distribution.
We employ Approximate Nearest Neighbor Search (\ANN) algorithms to find top $b$ keys efficiently.
For example, the graph-based \ANN method (e.g., \HNSWLIB~\citep{malkov2018efficient}) has a search complexity of $\gO((\log(N + L))$.
The pseudo code of the inference procedure is shown in Algorithm~\ref{alg:rae-inference}, and the indexing algorithm (that built the indexer and $\rmV$) can be found at Appendix~\ref{sup:impl}.

%\vspace{-.5em}
\paragraph{Time Complexity.}
For real-time inference (i.e., batch size of $1$), the time complexity of Algorithm~\ref{alg:rae-inference} is
$\gO\big(\gC(f_\theta) + \log(N+L) + b\log(L)\big)$.
$\gO(\gC(f_\theta))$ is the complexity of embedding the test input $\rvq$.
$\gO(\log(N+L))$ is the \ANN search time complexity.
$\gO(b\log(L))$ is the complexity of sparse matrix vector multiplication between $\rvq^{\top}\rmK^{\top}$ and $\rmV$,
where we assume the average number of positive labels per input follows $\bar{L}=\log(L)$,
which is a commonly-used assumption in the \XMC literature~\citep{yen2016pd,prabhu2018parabel}.

%\vspace{-0.7em}
\begin{algorithm}[H]
    \caption{Inference of \RAEXMC}
    \label{alg:rae-inference}
    \begin{minted}{python}
def InferenceRAE(Q_txt, f_enc, indexer, V_mat, b, tau=0.04):
    Q_emb = f_enc(Q_txt) # [bsz, d]
    QKT = indexer.search(Q_emb, topk=b) # [bsz, (N+L)], a sparse matrix
    QKT = Softmax(-QKT / tau, axis=1)
    return QKT.dot(V_mat) # [bsz, L] = [bsz, (N+L)] * [(N+L), L]
    \end{minted}
\end{algorithm}

%\vspace{-1.5em}
\subsection{Training of \RAEXMC}
\label{sec:rae-training}
%\vspace{-0.5em}

Our proposed method differs from conventional approaches, which require intensive encoder training to capture subtle differences in label descriptions and enhance memorization. 
In contrast, a standard InfoNCE contrastive loss in Equation~\ref{eq:learning}, is sufficient to achieve strong performance within the \RAEXMC inference framework. 

To pursue optimal performance, as noted by \DEXML~\citep{gupta2024dual}, using other positive labels as negatives for the current positive label leads the loss function to penalize positive labels that are easier to predict.
We further apply decoupled softmax loss, which removes the positive labels $P(\rvy)=\{ \ell  \mid  \forall \ell \in [L]: y_{\ell}=1 \}$ from the denominator:
\begin{equation}
    J(x, \rvy; s_{\theta}) =
    - \sum_{\ell \in [L]}  y_{\ell} \cdot \log
    \frac{ e^{s_{\theta}(x,\ell)/\tau} }
    {e^{s_{\theta}(x,\ell)/\tau} + \sum_{\forall \ell^{'} \not\in P(\rvy)} e^{s_{\theta}(x,\ell^{'})/\tau} }.
    \label{eq:in-batch}
\end{equation}
\RAEXMC performs inference over a joint input instance and label space. 
To enhance consistency between inference and training, we propose utilizing in-batch input instances as negatives~\citep{moiseev2023samtone}. 
This approach forces the model to contrast both instance and label spaces to accurately classify the correct label. 
The training objective of \RAEXMC{} is:


\begin{equation}
    J(x, \rvy; s_{\theta}) =
    - \sum_{\ell \in L}  y_{\ell} \cdot \log
    \frac{ e^{s_{\theta}(x,\ell)/\tau } }
    {e^{s_{\theta}(x,\ell)/\tau} + \sum_{ \forall \ell^{'} \not\in P(\rvy)}e^{s_{\theta}(x,\ell')/\tau} + \sum_{x' \in Q(\rvy)} e^{s_{\theta}(x, x')/\tau}},
\end{equation}
where $Q(\rvy) = \{ x'  \mid  \forall (x', \rvy') \in B : P(\rvy) \cap P(\rvy')=\emptyset\}$ and $B$ is the mini-batch of training set $\mathcal{D}$. 
$Q(\rvy)$ is the set of the negative input instance $x'$ that do not share any positive labels with the current input $x$, which prevents pushing of input instances with shared labels further apart.

\paragraph{Implementation.}
In practice, it is infeasible to sum over all the labels to accurately estimate the model predicted label distribution without using gradient caching~\citep{guo2020accelerating}.
To approximate the label distribution, for each input $x$, we randomly sample one positive label from $P(\rvy)$ and sample $m$ negative labels through hard negative mining.



% We also consider multilabel-to-multiclass reduction and employ Softmax loss:
% \begin{equation}
%     J(x, \rvy; s_\theta)
%     = H(\rvy, \hat{p})
%     = -\sum_{\ell \in [L]} y_\ell \cdot \log \Big( \hat{p}(y_\ell|x) \Big).
% \end{equation}

% In our current implementation, the $\hat{p}(y_\ell | x)$ is defined as  
% \begin{equation}
%     \hat{p}(y_\ell|x) \propto
%     \biggl( 
%         \frac{ \exp\big(s_{\theta}(x,\ell)\big) }
%         { \sum_{k \in \gK} \exp\big(s_{\theta}(x,k)\big) } \Biggr)
%         \label{eq:rae-train-loss}
% \end{equation}

% Current difficulty:
% \begin{itemize}
%     \item Eq~\ref{eq:rae-train-loss} is NOT CONSISTENT to $\hat{\rvp}$ of \RAEXMC (Eq~\ref{eq:rae-inference-exact}), when $\lambda \in (0,1]$
%     \item Eq~\ref{eq:rae-train-loss} is CONSISTENT to $\hat{\rvp}$ of \RAEXMC (Eq~\ref{eq:rae-inference-exact}), ONLY when $\lambda = 0$.
% \end{itemize}

