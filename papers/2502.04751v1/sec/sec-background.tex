\begin{figure*}[t]
    \centering
    \includegraphics[width=0.999\linewidth]{pic/framework_split.pdf}
    \caption{The overall framework of the proposed HG-MCTS method. The left panel outlines the iterative Monte Carlo tree search procedure with a global checklist and memory mechanism, including different actions in MCTS. The right panel provides a detailed explanation of node expansion and the corresponding reward modeling process with quantitative progress reward and progress feedback.}
    \label{fig:framework}
\end{figure*}

\section{Preliminaries}

We begin by formally defining the task of intricate information seeking, then present the Monte Carlo Tree Search~(MCTS) algorithm based on large language models (LLMs), and provide the formulation of our MCTS-driven information seeking task.



\paratitle{Intricate Information Seeking.} The intricate information seeking task involves the systematic exploration and retrieval of information from various sources to address complex and multifaceted queries. Formally, given a query $\bm{x}$, the goal of search assistant $\mathcal{M}_\theta$ is to retrieve a set of documents $\mathcal{D}=\{d_1,...,d_K\}$ and generate an answer $\bm{y} = \langle y_1,...,y_m \rangle$ based on the retrieved information, where $y_t$ denotes a token from a pre-defined vocabulary $\mathcal{V}$. Compared to traditional web search tasks where queries are often straightforward and focused on specific pieces of information (\eg ``\emph{current weather in London}''), the queries in intricate information seeking involve multiple dimensions or subtopics that require aggregating information from various aspects (\eg ``\emph{the medal standings of the past five Summer Olympic}''). Besides, our task emphasizes gathering a wide range of documents to provide exhaustive coverage of topics, requiring retrieving data from diverse types of sources (\eg government reports and factual articles). Based on the accessed information, intricate information seeking aims to incorporate the main content from multiple sources, integrating facts, insights, and diverse viewpoints to ensure that the final answer is sufficiently accurate and comprehensive to address the query.

\paratitle{Monte Carlo Tree Search.} Monte Carlo Tree Search is a search technique for possible solutions in the field of artificial intelligence. It combines the principles of tree exploration and random simulation to estimate the potential outcomes of actions. MCTS is especially effective in decision-making tasks with large action spaces, such as AlphaGO~\cite{alphago} and Atari~\cite{YeLKAG21}. 
In complex reasoning tasks, previous work (\eg Chain-of-Thoughts~\cite{wei2022chain} and ReAct~\cite{yao2023react}) mainly focused on chain-based reasoning paradigm, where any intermediate reasoning errors may lead to incorrect final answers. Furthermore, although some studies incorporated MCTS into retrieval~\cite{lee2024zero,jiang2024rag}, they simply apply RAG in each expansion step and search for the most effective intermediate answers aiming to derive the final answer, which may become trapped in locally optimal search paths or overlook critical pieces of required information.
In contrast, we reformulate the task as an information collection process that mainly focus on collecting accurate and comprehensive information with MCTS and utilizing the extracted information stored in the memory to generate the final answer. Specifically, we introduce an adaptive checklist to provide global guidance for the exploration and reward modeling in MCTS. By imposing atomic sub-goals on the tree search process, our approach systematically advances toward the overall goal. It effectively minimizes ineffective searches and ensures the comprehensive collection of all necessary information. We also incorporate progress feedback to update the checklist and provide the next direction. Consequently, the final answers become more precise and are accompanied by accurate retrieval references, thereby enhancing the explainability of the information seeking process.



\paratitle{MCTS-based Information Seeking.} Inspired by previous studies on complex reasoning~\cite{kang2024mindstar, wang2024q*, jiang2024technical}, we propose to integrate MCTS to deal with the intricate information seeking task. In our study, MCTS aims to build a search tree $\mathcal{T}$ based on a policy model $\pi_{\theta}$, which is usually the target LLM $\mathcal{M}_\theta$. To provide holistic guiding signals, we incorporate a global checklist $p$ listing sub-goals for addressing the input complex query.
In the search tree $\mathcal{T}$, a node $s_t = [q_t, p, \mathcal{D}]$ denotes the state at the $t$-th tree level, where $q_t$ is an intermediate sub-query for retrieval, $p$ is the dynamically updated checklist indicating solved and unsolved sub-goals, and $\mathcal{D}$ denotes the current knowledge memory containing a set of extracted knowledge from retrieved documents so far. Based on the policy model, we sample candidate actions from its probability distribution $\mathcal{M}_\theta(a_t|s_t)$, transiting from the current state $s_t$ to the next state $s_{t+1}$. The MCTS process begins from a root node $s_0=[\bm{x}]$, as the initial input query, and iterates four key steps (\ie selection, expansion, evaluation, and backpropagation) to finally access a comprehensive set of knowledge memory $\mathcal{D} = \{k_1,..., k_T$\}, where $k_t$ denotes knowledge snippet extracted from retrieved documents at the $t$-th step and $T$ is the number of MCTS iterations. Based on the collected information $\mathcal{D}$, the policy model $\mathcal{M}_\theta$ generates the final answer $\bm{y}$ to the input query.

