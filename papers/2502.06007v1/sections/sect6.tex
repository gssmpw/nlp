\section{Discussions}\label{sect5}
This section discusses the limitations on the theory part of this work and points to future working directions. 
\paragraph{Limitations.} Our limitations in the theoretical results can be summarized as follows: \textbf{(1)} From the theoretical perspective, our results guarantee the performance of ERM solutions whereas the true estimator is obtained through stochastic gradient descent method; \textbf{(2)} Our theoretical results utilize the context-augmented matrix $\bfa P$, which is verified removable from our empirical results. 
\paragraph{Future Works.} Beyond resolving the limitations in this work, other future working directions from this work include: \textbf{(1)} Taking into consideration of the layer norm in the Transformer architecture. \textbf{(2)} Resolving the universal approximation problem raised in section \ref{approx3}; \textbf{(3)} Removing the initialization procedure in the theory.




\section*{Impact Statement}
This paper theoretically analyzes the capability of Transformers in performing EM algorithm. Due to the theoretical nature of this work, there is no negative sociatal impact.
% Due to the theoretical nature of this work, the sociatal impact is minor. Though it is possible that Transformer models might induce safety issues when used improperly.