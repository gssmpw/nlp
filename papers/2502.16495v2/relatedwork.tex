\section{Related Works}
\label{relatedwork} 

\subsection{SLAM \& Edge SLAM}
Recently, SLAM has become a critical enabling technology for many emerging human-centered applications, such as AR/VR \cite{savva2019habitat}, HD map \cite{ahmad2020carmap, qiu2018avr}, and autonomous navigation \cite{vithalani2020autonomous}. 
In terms of mobile robotics systems with limited computation resources, edge-assisted SLAM has drawn substantial attention since it has a great potential to reduce the computation burden on the client side, such as autonomous vehicles \cite{zhang2019mobile}, UVAs \cite{chen2021edge}. The existing works that are closely related to edge SLAM include
\cite{braud2020multipath}\cite{ahmad2020carmap}\cite{xu2020edge}\cite{ben2020edge}\cite{liu2021edgesharing}\cite{xu2022swarmmap}. 

Specifically, Tristan et al. \cite{braud2020multipath} and Jingao et al. \cite{xu2020edge} focus on offloading sub-tasks of mobile SLAM, i.e., the SLAM system on handheld devices. Tristan et al. \cite{braud2020multipath} develop a scheduler to dispatch sub-tasks over two edge servers while Jingao et al. \cite{xu2020edge} consider the collaboration of two nearby handheld devices for edge SLAM. Fawad et al. \cite{ahmad2020carmap} propose a light HD map construction system by formalizing an edge-SLAM architecture for autonomous vehicles. The authors verify that the compressed vision data is an efficient way in edge SLAM. Edge-SLAM \cite{ben2020edge} is the first work of system-level decomposition for edge SLAM, i.e., the authors propose to decompose sub-tasks and offload part of them into the edge server. Luyang et al. \cite{liu2021edgesharing} construct a crowd SLAM at the edge by collecting data from clients and then sharing global SLAM information with them. Jingao et al. \cite{xu2022swarmmap} design a framework for collaborative SLAM at the edge, in order to scale up collaborative SLAM services. Different from existing SLAM-related works, this work focuses more on the adaptation of edge SLAM, i.e., adaptive offloading and adaptive scheduling, especially in the multi-server scenario. In addition, we highlight the importance of user requirements in SLAM systems and propose an efficient learning framework to address that.
  
\subsection{Learning to Offloading} 
Our work gains important insights from the existing works that investigate the offloading strategies for vision-supported applications e.g., AR/VR, video analytics \cite{guo2018small, galanopoulosautoml, wang2020joint, ren2021adaptive}. Specifically, an important principle in those works is to strike the balance between inference accuracy and communication overhead via offloading compressed vision data. However, the compression options are usually configured for the whole frame. The diverse sensitivity of different frame regions to data distortion caused by compression has not been considered. For example, the frame regions containing small objects need a higher resolution to guarantee object detection accuracy according to the conclusion in \cite{guo2018small}. Notably, this problem will become severe in vSLAM since pixel-level feature extraction in vSLAM (e.g., the ORB algorithm \cite{mur2017orb}) is more sensitive to data distortion than object detection. 

Several works focus on tile-oriented compression solutions \cite{liu2019edge, wang2021edgeduet, du2020server}. Similarly, we further investigate the tile-level importance on the client side and configure adaptive compression in various network environments.
 
\subsection{Learning to Scheduling} 
Scheduling tasks among multiple servers or between the server and Cloud is an important research topic in the computer community. Several recent works provide us with valuable insights \cite{mao2019learning}\cite{zhang2020towards}\cite{ayala2019vrain}\cite{shen2023collaborative}. Specifically, Hongzi et al. \cite{mao2019learning} proposes a learning-based scheduling algorithm to efficiently schedule jobs whose tasks have complex dependencies. The authors employ GNN to extract the dependency property of tasks. Shigeng et al. \cite{zhang2020towards} focus on the problem of partition and offloading of DNN models and propose a Directed Acyclic Graph (DAG)-based problem formulation with an optimal partition algorithm. Jose et al. \cite{ayala2019vrain} propose an autoencoder-based mining method to extract latency representation from high-dimensional context data for resource allocation in the virtualization of radio access networks. The high-dimensional context data in \cite{ayala2019vrain} is heterogeneous, e.g., the combination of traffic and signal quality patterns. The difference is that our work focuses on the vision data. Shihao et al. \cite{shen2023collaborative} develop a scheduling framework for dispatching tasks among the edge and Cloud in the kubernetes system. 

Nevertheless, most of the existing scheduling-related works partially focus on load balancing or task processing performance. In our work, users' requirements (e.g., tasks processing DDL) highly affect the SLAM performance while those requirements are usually implicit and time-varying. 
% In addition, the newly proposed input-dependent learning framework can be used in existing scheduling works by just adding a safety guarantee module during training.

{
\subsection{Other Vision or Non-Vision Based Methods} 
One of the advantages of visual SLAM is its ability to simultaneously construct environmental map and estimate the camera's pose, which facilitate the localization, navigation, and control of mobile robotic systems. 

% In recent years, many new technologies have been exploited to enhance the mapping and localization performance of mobile robotic systems by enhancing their ability in understanding environments. 

In recent years, many new technologies have been exploited to enhance 
devices' ability to understand their environment, thereby improving the mapping and localization performance. In the field of computer vision, 3D scene reconstruction is an emerging technology that enhances the understanding of both indoor and outdoor environments. 
% 3D scene reconstruction can facilitate many downstream tasks, such as motion planning, navigation, by capturing the 3D profile of objects and identifying the 3D coordinates of any point on the profile.
Recently, 3D scene reconstruction has been significantly improved with the use of generative models, such as the diffusion model-based SceneDiffuser \cite{huang2023diffusion} and the Gaussian splitting-based Drivinggaussian \cite{zhou2024drivinggaussian}. 
Another promising approach in computer vision for understanding 3D environments is based on analyzing geometric points. 
For example, point clouds are an important type of geometric point set. The problem of how to extract useful environment-related features by processing point clouds has been widely studied via deep learning methods\cite{qi2017pointnet++}. 

In addition to vision-based methods, there are also many promising technologies that leverage wireless signals to understand environments. Radio-based SLAM \cite{leitinger2019belief} is a type of SLAM mechanism that constructs radio maps and localizes devices by estimating channel multipath angles. 
% It has a potential to realize integrated sensing and communication design for mobile robotic systems. 
Another efficient approach to understanding environments is based on the Neural Radiance Fields \cite{zhao2023nerf2}. The key idea is to represent a scene or object as a neural radiance field, which is trained using a small number of signal measurements. By efficiently synthesizing the spatial spectrum given the position of a transmitter (TX) or receiver (RX), It has demonstrated excellent performance in localization and wireless communications.

Although these aforementioned methods can achieve decent mapping or localization performance in their targeted scenarios, it remains unclear whether they can be effectively applied in autonomous driving scenarios. Most existing 3D scene reconstruction methods require extensive training. The performance of radio-based methods are easily affected by wireless interference, and will be degraded in complex propagation environments. }