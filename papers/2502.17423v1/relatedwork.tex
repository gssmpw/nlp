\section{Background and Related Work}
We review background on diffusion models and  ODEs, solvers for diffusion ODEs, and  learning-based samplers. 
We also provide detailed comparisons with existing approaches in Appendix~\ref{app:related-work-comp}.

\subsection{Background: Diffusion Models}
Let $\x_0\in\R^d$ be a random variable from an unknown data distribution $p_0(\x_0)$. 
Diffusion models (DMs)~\cite{ho2020denoising,song2020score} define a forward process $\{\x_t\}_{t\in[0,T]}$ with $T>0$ that starts from $\x_0$ and progressively adds Gaussian noise to converge to a marginal distribution, $p_T(\x_T)$, that approximates an isotropic Gaussian, i.e. $p_T(\x_T)\approx \mc{N}(\x_T;\bm{0}, \tilde\sigma^2\id)$ at time $T$ for some $\tilde\sigma>0$.
Given $\x_0$, we can characterize the process of adding Gaussian noise by the transition kernel
$p_{0t}(\x_t|\x_0)=\mc{N}\big(\x_t; \alpha_t\x_0, \sigma_t^2 \id\big)$,
for all $t\in[0,T]$, where $\alpha_t, \sigma_t > 0$ are selected such that the \emph{signal-to-noise ratio} (SNR), $\alpha_t^2/\sigma_t^2$, decays as $t$ increases.
Remarkably,~\citet{song2020score} demonstrated that this forward process shares the same marginal distribution $p_t$ as the \emph{probability flow ODE}, a reverse-time ODE starting at $\x_T\sim p_T(\x_T)$ given by:
\begin{equation}
    \label{eqn:pf-ode}
    d\x_t = \left[f(t)\x_t - \frac{1}{2}g^2(t)\nabla_\x \log p_t(\x_t)\right] dt,
\end{equation}
where $f(t)={d\log\alpha_t}/{dt}$ and $g(t)= ({d\sigma_t^2}/{dt})-2({d\log \alpha_t}/{dt})\sigma_t^2$ \cite{kingma2021variational}.
Since the score function $\nabla_\x\log p_t(\x_t)$ in \eqref{eqn:pf-ode} is unknown, DMs learn it using a \emph{noise prediction} neural network to minimize:
\begin{equation*}
    \mc{L}(\bm\theta)=\E_{\x_0, \bm\epsilon,t}[w(t)\|\noisemodel(\x_t,t)-\bm\epsilon\|_2^2]
\end{equation*}
where $\x_0\sim p_(\x_0)$, $\bm\epsilon\sim\mc{N}(\bm 0 , \id)$, $t\sim \mc{U}[0,T]$, $w(t)$ is a time-dependent weighting function, and $\x_t=\alpha_t\x_0+\sigma_t\bm\epsilon$ is a noisy sample at time $t$~\cite{ho2020denoising,lu2022dpm}.
By Tweedie's formula, $\noisemodel(\x_t,t)$ learns to approximate $-\sigma_t\nabla_\x\log p_t(x)$, thereby defining the \emph{diffusion ODE}:
\begin{equation}
    \label{eqn:diff-ODE}
    d\x_t = \left[f(t)\x_t + \frac{g^2(t)}{2\sigma_t}\noisemodel(\x_t,t)\right]dt,
\end{equation}
with initial condition $\x_T\sim p_T(\x_T)$.
To exactly solve the diffusion ODE at $\x_t$ given an initial value $\x_s$, where $ t<s$,~\citet{lu2022dpm} reparametrizes \eqref{eqn:diff-ODE} in terms of the log signal-to-noise ratio $\lambda_t := \log(\alpha_t/\sigma_t)$, yielding:
\begin{equation}
\label{eqn:lambda-exact-soln}
\x_{t_i}=\frac{\alpha_{t_i}}{\alpha_{t_{i-1}}}\x_{t_{i-1}} - \alpha_{t_i}\int_{\lambda_{t_{i-1}}}^{\lambda_{t_i}} e^{-\lambda} \hatnoisemodel(\hat\x_\lambda,\lambda)d\lambda,
\end{equation}
where $\hat\x_\lambda$ and $\noisemodel(\hat\x_\lambda,\lambda)$ denote the reparametrized forms of $\x_t$ and $\noisemodel(\x_t,t)$ in the $\lambda$ domain.

\subsection{Background: Solving the Diffusion ODE}\label{sec:background-diff-ode}
Sampling from a DM requires numerically solving the diffusion ODE in \eqref{eqn:diff-ODE}.
Given a decreasing sequence of $N$ discretization steps $\{t_i\}_{i=0}^N$ from $t_0=T$ to $t_N=0$, we iteratively compute a sequence of estimates $\{\tilde \x_{t_i}\}_{i=0}^N$ starting from $\tilde \x_{t_0}=\x_T\sim \mc{N}(\x_T;\bm{0}, \tilde\sigma^2\id)$ such that the \emph{global} truncation error between $\tilde \x_{t_N}$ and the true solution $\x_{t_N}$ is low.
The standard approach of controlling this error is to bound the \emph{local} truncation error between $\tilde \x_{t_i}$ and $\x_{t_i}$ at each $t_i$.
Since \eqref{eqn:lambda-exact-soln} gives the exact solution of the diffusion ODE given an initial value $\tilde\x_{t_{i-1}}$, an accurate approximation of the integral in turn provides an accurate approximation $\tilde \x_{t_i}$ for the true solution at time $t_{i-1}$.
One can take a Taylor expansion of $\hatnoisemodel(\hat\x_\lambda,\lambda)$ about $\lambda_{t_{i-1}}$ in \eqref{eqn:lambda-exact-soln}, yielding:
\begin{align}
\tilde\x_{t_i} \;\; = \;\; \frac{\alpha_{t_i}}{\alpha_{t_{i-1}}} \tilde{\x}_{t_{i-1}} 
   - \alpha_{t_i} \sum_{n=0}^{k-1} \hatnoisemodel^{(n)}(&\hat{\x}_{\lambda_{t_{i-1}}}, \lambda_{t_{i-1}}) \psi_n(h)  
   + \mathcal{O}(h_i^{k+1})\;, \label{eqn:lambda-taylor-soln}
\end{align}
for some $\psi_n(h)$ depending on $n$, $\lambda_{t_i}$, and $\lambda_{t_{i-1}}$; see \appref{app:taylor} for further details.
Computing such $k$-th order approximation requires accurate estimates of the derivatives $\hatnoisemodel^{(n)}$ up to order $n=k-1$. 
Existing methods use two main approaches from ODE literature: single-step methods~\citep{lu2022dpm, lu2022dpmpp, zheng2023dpm, zhao2023unipc, zhang2022fast, karras2022elucidating}, which use $k-1$ intermediate points in $(t_i, t_{i-1})$, and linear multi-step methods~\citep{lu2022dpmpp,zheng2023dpm,zhao2023unipc,zhang2022fast,liu2022pseudo}, which use information from $k-1$ previous steps. 
For low order methods $(k\leq 4$), under appropriate regularity conditions (see \appref{app:regularity}) and when $h_{max}:=\max_{1\leq i\leq N} h_i$ is bounded by $\mc{O}(1/N)$, these methods achieve local truncation error of $\mc{O}(h_i^{k+1})$ and therefore global error of $\mc{O}(h_{max}^k)$.

When the number of NFEs is large and thus $h_{max}$ is small, local truncation error control yields high quality samples   
\cite{lu2022dpm,lu2022dpmpp,zhang2022fast}. 
However, with few NFEs and large $h_{max}$, the higher-order Taylor errors dominate, leading to large global error.
In contrast, our approach in \eqref{eqn:hard-objective} directly minimizes the global error.

\begin{table}[t]
\small
\begin{tabular*}{\linewidth}{@{\extracolsep{\fill}}c|c|c|cc@{}}
\toprule
Solver Type & $\Delta_i(\phi)$ & $\phi$ & NFEs per Step & \# Params. \\
\midrule
LMS & $\displaystyle\sum_{j=1}^{k}b_{j,i} \noisemodel(\tilde{x}_{t_{i-j}}, t_{i-j})$ & $\{b_{j,i}\}$ & 1 & $k(2N + 1 - k)/2$ \\
\midrule
SS & $\begin{array}{c}\displaystyle\sum_{j=1}^k b_{j,i}\kappa_j, \\ \kappa_j = \noisemodel\!\left(\tilde{x}_{t_{i-1}} + \sum_{l=1}^{j-1} a_{j,i,l} \kappa_l, t_{i-1}+c_{j,i} \right)\end{array}$ & $\{b_{j,i}, a_{j,i,l}, c_{j,i}\}$ & $k$ & $(k^2+k-1)N$ \\
\midrule
LMS+PC & $\displaystyle\sum_{j=1}^k a_{j,i}^c \noisemodel(\tilde{x}_{t_{i-j}}, t_{i-j})$ & $\{b_{j,i}\} + \{a_{j,i}^c\}$ & 1 & $k(2N + 1 - k)$ \\
\bottomrule
\end{tabular*}
\caption{We apply S4S to three types of diffusion ODE solvers; we show their increment ($\Delta_i$), learnable parameters, number of NFEs per step, and total parameter count over $N+1$ steps. By default, we use a linear multi-step predictor for the PC method, so $\{a_{j,i}^c\}$ refer to coefficients during the correction step, and the total set of learnable parameters accounts for the underlying multi-step predictor.}
\label{table:solver-types}
\end{table}

\subsection{Related Work: Learned Samplers} 
In practice, no single pair of ODE solver and a time discretization generates high quality samples universally across various datasets and model architectures, e.g. \appref{app:fid-tables} and \citet{tong2024learning}.
This inspired {\em learning}-based methods for deriving ODE solvers and time discretizations adapted to the given task and architecture.
We give a brief survey here and discuss in detail in \appref{app:related-work-comp}. 
One popular approach exclusively learns the discretization steps ~\cite{watson2021learning,sabour2024align,xue2024accelerating,tong2024learning,pmlr-v235-chen24bm}. 
Our approach S4S learns the solver coefficients, complementing the gains of such methods and universally improving the performance in all scenarios, as seen in \tabref{tab:s4s-coeff} and comprehensively in \appref{app:fid-tables}.
Another line of research focuses on optimizing only the solver coefficients \cite{zheng2023dpm,zhang2023accelerating}, or jointly optimizing both solver coefficients and time discretizations \cite{zhou2024fast,zheng2023dpm,liu2023unified,shaul2023bespoke}.  
However, these methods are designed to minimize the {\em local} approximation error through the same methods as in \eqref{eqn:lambda-taylor-soln} or by closely matching the \emph{entire trajectory} of the teacher solver.
Instead, by minimizing the \emph{global} error by matching the \emph{end} of the teacher trajectory, as in \eqref{eqn:hard-objective}, S4S significantly improves over these approaches.
Closest to our approach is BNS \cite{shaul2024bespoke}, which learns both the solver coefficients and time discretizations to minimize global error.
We provide comparisons in \tabref{tab:s4s-compute-comp} and explain our improvements over BNS in \appref{app:related-bns}.