\section{Experiment}
\label{sec:experiment}






\subsection{Experiment setup}

\paragraph{Datasets and evaluation metrics}
The following four person ReID datasets are used: Market-1501~\cite{market}, MSMT17~\cite{msmt}, CUHK03-NP~\cite{cuhk_np}, and PersonX~\cite{personx}, where PersonX is a synthetic dataset.
We follow the new protocol of CUHK03~\cite{cuhk}.
Among them, MSMT17 is known as the most challenging dataset.
VeRi-776~\cite{veri} is additionally used as a vehicle ReID dataset.
Their statistics are provided in Table~\ref{tab:dataset_statistics}. 
For evaluation metrics, the mean average precision (mAP) and cumulative matching characteristics (CMC) Rank-1 (R1), Rank-5 (R5), and Rank-10 (R10) are used.
The NMI scores of the clustering results are also reported as in Section~\ref{sec:motivation}.

\paragraph{Implementation details}
For experiments on the camera-adaptive feature debiasing, we use the pretrained models from their official Github repositories. 
When the model weights are unavailable, we train the models ourselves with the official code.
For experiments on our training strategy for unsupervised learning, we use the DBSCAN~\cite{dbscan} algorithm to obtain pseudo labels.
The person and vehicle images are resized to $384\times128$ and $256\times256$, respectively, following the setup of PPLR.
We train the models on a H100 GPU with batch size 256 and 100 training epochs.


