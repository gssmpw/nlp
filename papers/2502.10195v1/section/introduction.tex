\section{Introduction}
\label{sec:introduction}
Person re-identification (ReID) is a process of retrieving images of a query identity from gallery images.
With recent advances in deep learning, a wide range of challenging ReID scenarios have been covered, including object occlusion~\citep{miao2019pose,somers2023body}, change of appearance~\citep{jin2022cloth}, and infrared images~\citep{wu2017rgb,wu2023unsupervised}.
In general, the inter-camera sample matching is not trivial since the shared information among images from the same camera can mislead a model easily.
This phenomenon is known as the problem of camera bias, where samples from the same camera tend to gather closer in the feature space.
This increases the false matching between the query-gallery samples since the samples of different identities from the same camera can be considered too similar.
To address the issue, camera-aware ReID methods~\citep{luo2020generalizing,wang2021camera,chen2021ice,cho2022part,lee2023camera} have been proposed, aiming to learn camera-invariant representations by leveraging camera labels of samples during training.

However, the previous works on camera bias of ReID models have mainly focused on seen domains of the models, while 
the camera bias of ReID models on unseen domains has been overlooked.
We observe that existing ReID models exhibit a large camera bias for unseen domain data. 
For example, Figure~\ref{fig:motivation} describes the feature distance distributions between samples of a camera-aware model~\citep{cho2022part} trained on the Market-1501~\citep{market} dataset, using samples from the MSMT17~\citep{msmt} dataset.
Compared to the distance distributions of the seen domain samples, the distance distributions of the unseen domain samples are more separable.

In this paper, we first investigate the camera bias of existing ReID models on seen and unseen domain data.
We observe that, regardless of the model types, there is a large camera bias in distribution shifts, and unsupervised models are vulnerable to camera bias even on seen domains.
As a straightforward debiasing technique for unseen domains, we revisit the normalization method on the embedding features of ReID models.
Through comprehensive empirical analysis, we reveal why the feature normalization effectively reduces biases towards camera labels and fine-grained factors such as low-level image properties and body angles, as well as demonstrating its general applicability for various ReID models.
Additionally, we explore the inherent risk of camera bias in unsupervised learning (USL) of ReID models, observing the negative impact of camera-biased pseudo labels on training.
Based on our analysis, we suggest simple training strategies applicable to existing USL algorithms, which significantly improve the performance.

The main contributions of this work are summarized as follows:
\begin{itemize}
    \item 
    We investigate the camera bias of ReID models on unseen domain data, which has not been thoroughly studied. 
    We provide comprehensive analysis encompassing various learning methods and model architectures.
    \item 
    We revisit the debiasing effects of normalization on embedding vectors of ReID models. 
    The empirical analysis explains why it is effective for bias mitigation and shows its applicability to detailed bias factors and multiple models.
    % Furthermore, we validate the generalizability of the normailzation with multiple models and benchmarks.
    \item  
    We explore the risk of camera bias inherent in unsupervised learning of ReID models.
    From this, we show that the performance of existing unsupervised algorithms can be effectively enhanced by simple modifications to reduce the risk.
\end{itemize}


\begin{figure}[t]
  \centering
  \setlength\tabcolsep{1pt}  % 4.5pt
  \begin{tabular}{cc}
    \multicolumn{2}{c}{\includegraphics[height=.28\linewidth]{figure/iclr/pplr_cam_market_msmt.pdf}} \\
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ (a)  & 
    ~~~~~~~~~~~~~~~~~~~~~~~~~~ (b)\\
  \end{tabular}
  \vspace{-2mm}
  \caption{
  % ~\citep{cho2022part}
    Cosine distance distributions of a camera-aware ReID model on (a) the training domain (Market-1501) and (b) the unseen domain (MSMT17).
    The distances between samples within the same cameras are more skewed to the left when the data distribution is shifted. 
  }
 %\vspace{-2mm}
  \label{fig:motivation}
\end{figure}