


\section{Related work}
\label{sec:related_work}

% \paragraph{Supervised and unsupervised person ReID}
In traditional person ReID methods, the convolutional neural networks (CNN) architectures have been popularly adopted with cross-entropy and triplet loss~\citep{
zheng2017discriminatively,hermans2017defense,luo2019bag,ye2021deep}.
When identity labels of training data are unavailable, the pseudo labels are used instead based on clustering on the extracted features~\citep{fan2018unsupervised,lin2019bottom,yu2019unsupervised,zhang2019self,dai2022cluster}.
Recently, the transformer backbones~\citep{he2021transreid,luo2021self,chen2023beyond} and self-supervised pretraining~\citep{fu2021unsupervised,fu2022large,luo2021self,chen2023beyond} significantly improve the ReID performance.
To enhance the generalization ability of the models, a variety of domain generalizable techniques have been also proposed~\citep{dai2021generalizable,song2019generalizable,liao2021transmatcher,pat,dou2023identity}.

% \paragraph{Camera-aware person ReID}
However, it has been found that the ReID models are biased towards the camera views of given data.
The camera-aware methods have been proposed to alleviate this problem, where camera labels of the samples are utilized in model training as auxiliary information~\citep{luo2020generalizing,zhuang2020rethinking,zhang2021unsupervised,wang2021camera,chen2021ice,cho2022part,lee2023camera}.
For example, an inter-camera contrastive loss is proposed to minimize the variations of the features from different cameras within the same class~\citep{wang2021camera,cho2022part}.
\cite{zhuang2020rethinking} replace batch normalization layers of a model with camera-based batch normalization layers conditional to the camera labels of inputs to reduce the distribution gap.
Some other studies~\citep{gu20201st,luo2021empirical} post-process a feature by subtracting the mean feature within its camera view, but this is performed without justification and is limited to an unsupervised domain adaptation task.
These previous studies have primarily focused on the bias of the models on the training domain data, while the bias on unseen domain data has been neglected.
Meanwhile, we call the methods which do not take the camera views into account camera-agnostic methods.



