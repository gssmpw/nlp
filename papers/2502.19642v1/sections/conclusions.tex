\section{Conclusions} \label{sec:conclusions}

In this paper, we proposed cMIM, a novel contrastive extension of the MIM framework. Our experiments demonstrate that cMIM can learn more discriminative features than MIM and consistently outperforms MIM in various downstream tasks. Additionally, cMIM achieves comparable reconstruction quality to MIM, suggesting that it may perform similarly in generative tasks, though empirical validation of this hypothesis is left for future work.

We also introduced a novel method for extracting embeddings from encoder-decoder models, termed \textit{informative embeddings}, which enhance the utility of the learned representations for downstream applications.

We hope that our work marks a step towards developing a single, powerful model capable of excelling in both discriminative and generative tasks, and that it will inspire further research in this direction.
