\section{Related Work}
\label{sec:related-work}
\subsection{Bilingual Knowledge for LLMs}
\paragraph{L1 interference in humans and LMs} 
Native language profoundly influences L2 language use in humans~\cite{levenston1971over,Schachter1974-dq,Kleinmann1977-vt,brooke2013native}. This \textit{language interference} effect biases, for example, the syntactic constructions~\cite{felker2021role} and discourse flows ~\cite{bailey2021digital} in L2, and the dialogue patterns are not an exception ~\cite{veivo2025dialogue}.
% impacting interacting patterns with LLMs~\cite{abbasiantaeb2024let}. 
When it comes to neural LMs, the cross-lingual transferability of LMs and their human-likeness has also gained attention, but prior studies have exclusively focused on sentence-level evaluations~\cite{oba-etal-2023-second,yadavalli-etal-2023-slabert,elshin2024general}. 
Such perspectives can easily be extended to the dialogue level, involving discourse-level cohesion/coherence and L1-dependent, nuanced differences in dialogue strategy~\cite{abe2019interactional,gao2024interaction}.
Moreover, LLMs are now deployed to generate dialogue (e.g., chat interactions); evaluating their ability in a dialogue scenario generally aligns with their practical usage~\cite{jin2024better,veivo2025dialogue}. That said, our scope is limited to just simulating L2-like language use in a behavioral sense; LM's cognitive plausibility as an L2 learner, while interesting and related, is beyond of the scope of this paper.

\paragraph{Bilingual Knowledge in LLMs}
Bilingual knowledge typically impacts LLM in cross-lingual and multilingual tasks ~\cite{miah2024multimodal}. 
For example, leveraging shared grammatical features, bilingual LLM excels with typologically similar language pairs like English-Spanish, improving coherence and fluency through transfer learning ~\cite{jeon2022information}. On the other hand, handling distant cross-lingual pairs, such as English-Chinese, poses challenges (i.e., negative language transfer) due to differences in their grammatical features such as word order~\cite{ranaldi2023does}, requiring targeted training and alignment of grammatical constructs~\cite{pvribavn2024comparative}. 
In the context of dialogue tasks, limited L2 dialogue data and linguistic inconsistencies sometimes hinder LLM performance for non-native English speakers to interact~\cite{gan2024clarq}. There are case studies that optimize bilingual knowledge integration and enhance cross-lingual grammatical understanding~\cite{huzaifah2024evaluating}, as well as improve LLMs' ability to generate accurate and coherent dialogue, benefiting non-native English users~\cite{han2024llm}.


\subsection{Evaluation of L2 Capabilities of LLMs} 
Evaluating human-like LLMs is a key focus in educational NLP. Studies explore their use in online platforms~\cite{manoharanmaximizing}, personalized language tutoring~\cite{mejeh2024taking}, and L2 chatbots~\cite{yigci2024large}, but often rely on human judgments due to the complexity of L2 dialogues. Some worked propose automated evaluation tools for L2 interactions~\cite{gao-etal-2025-interaction} and language practice~\cite{huzaifah2024evaluating}, yet LLM performance of generation of non-native language in these settings remains under explored.

%knowledge-based capabilities across diverse scenarios, such as text-based dialogues~\citet{ou-etal-2024-dialogbench}, by evaluating the performance of LLMs by proposing a benchmark on English text dialogues. These works move beyond traditional evaluation tasks which focused solely on factual recall, and offer an understanding of human-like evaluation. However, a gap still exist in interactive dialogues, which has more generalizable context for deploying LLM, such as L2 interactions~\cite{gao-etal-2025-interaction} and language practice~\cite{huzaifah2024evaluating}. 
%JHL1: i struggle follow this section a bit - what's knowledged-based capabilities? what does evaluating the performance of LLMs by proposing a benchmark on English text dialogues mean? Does it have anything to do with L2 (which is what this section is about)?
%RG: Improved with more L2 fouced. 

\paragraph{Mimicking Human-like L2 Dialogues} 
Developing effective L2 dialogue generation systems requires a robust evaluation framework that facilitates linguistic knowledge transfer from L1 to L2, particularly for Asian L1 speakers with distinct syntactic structures from English~\cite{li-qiu-2023-finding}. Such a framework is crucial for integrating prior linguistic competence, enabling models to generate more context-aware utterances~\cite{sung-etal-2024-context,gao2024cnima}. To address this, evaluation protocols should incorporate cross-linguistic benchmarking and error analysis to identify language-specific grammatical challenges~\cite{kobayashi-etal-2024-large}. Systematic analysis of these errors provides insights into LLMsâ€™ bilingual grammatical understanding and representation, ensuring they not only grasp cross-lingual constructs but also generate language-specific nuances, enhancing real-world multilingual applications~\cite{cong2025demystifying,gao2024interaction,singh2024three,poole2024llm}.
%A challenge in developing effective dialogue generation systems for L2 contexts lies in establishing a robust evaluation framework that helps to transfer linguistic knowledge from a speaker's L1 to the target L2, especially for Asian L1 speakers with more distinct syntactical structures compared with English~\cite{li-qiu-2023-finding}. Such a framework is essential, as it provides a structured way to integrate prior linguistic competence, helping models more intuitively learn meaningful, context-aware utterances~\cite{sung-etal-2024-context,gao2024cnima}. To bridge these gaps, evaluation protocols should incorporate cross-linguistic benchmarking~\cite{king-flanigan-2023-diverse} and error analysis~\cite{kobayashi-etal-2024-large} to pinpoint the grammatical errors that frequently occur in specific languages. By systematically analyzing these errors, researchers can gain insights into the underlying issues related to grammatical understanding and representations of LLMs~\cite{cong2025demystifying}. This targeted evaluation process ultimately ensures that LLMs not only understand cross-lingual grammatical constructs but also excel in generating the unique knowledge of each language, leading to more effective language models in real-world cross-lingual applications ~\cite{gao2024interaction,singh2024three,poole2024llm}.