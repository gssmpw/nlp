@article{Kleinmann1977-vt,
  title     = "{AVOIDANCE} {BEHAVIOR} {IN} {ADULT} {SECOND} {LANGUAGE}
               {ACQUISITION}$^{1}$",
  author    = "Kleinmann, Howard H",
  journal   = "Lang. Learn.",
  publisher = "Wiley",
  volume    =  27,
  number    =  1,
  pages     = "93--107",
  abstract  = "A study was designed to ascertain whether syntactic avoidance
               behavior could be demonstrated for two groups of ESL
               learners—native speakers of Arabic and native speakers of Spanish
               and Portuguese—in accordance with contrastive analysis (CA)
               difficulty predictions. The study also investigated the
               predictability of learners' avoiding the use of various
               structures. Subjects participated in tasks designed to elicit
               passive, present progressive, infinitive complement, and direct
               object pronoun structures. An avoidance pattern was found, in
               accordance with CA difficulty predictions, which could not be
               attributed to differences between the groups' comprehension of
               the target structures. Furthermore, when the frequency of use of
               the target structures was correlated with various affective
               measures, the following pattern emerged: for those structures
               which a particular group avoided, several of the affective
               variables correlated with use in the predicted direction; for
               those structures which a particular group did not avoid, the
               affective variables did not correlate significantly with use. The
               findings suggest that while CA is a fairly good predictor of
               avoidance there is an intersection of linguistic and
               psychological variables in determining learner behavior in a
               second language in that structures which otherwise would be
               avoided are likely to be produced depending on the affective
               state of the learner.",
  month     =  jan,
  year      =  1977,
  language  = "en"
}

@article{Schachter1974-dq,
  title     = "{AN} {ERROR} {IN} {ERROR} {ANALYSIS}$^{1}$",
  author    = "Schachter, Jacquelyn",
  journal   = "Lang. Learn.",
  publisher = "Wiley",
  volume    =  24,
  number    =  2,
  pages     = "205--214",
  abstract  = "Presently, a number of proponents of an error analysis approach
               to the investigation of 2nd language learning argue that
               contrastive analysis (CA) apriori is inadequate as an account of
               target language learning problems. They claim that the only
               tenable version of CA is an aposteriori approach, i.e. CA in just
               those areas that have been proven by error analysis to be
               difficulties in production. This claim is disputed in a study
               involving the acquisition of English relative clauses by speakers
               of Persian, Arabic, Chinese, and Japanese. The aposteriori
               approach obscured the fact that the Chinese and Japanese learners
               have more difficulty with relative clauses and therefore avoid
               them, a fact predicted by the apriori approach.",
  month     =  dec,
  year      =  1974,
  language  = "en"
}

@inproceedings{abbasiantaeb2024let,
  title={Let the llms talk: Simulating human-to-human conversational qa via zero-shot llm-to-llm interactions},
  author={Abbasiantaeb, Zahra and Yuan, Yifei and Kanoulas, Evangelos and Aliannejadi, Mohammad},
  booktitle={Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
  pages={8--17},
  year={2024}
}

@article{abe2019interactional,
  title={Interactional competence in L2 text-chat interactions: First-idea proffering in task openings},
  author={Abe, Makoto and Roever, Carsten},
  journal={Journal of Pragmatics},
  volume={144},
  pages={1--14},
  year={2019},
  publisher={Elsevier}
}

@article{bailey2021digital,
  title={Digital storytelling with chatbots: Mapping L2 participation and perception patterns},
  author={Bailey, Daniel and Southam, Ashleigh and Costley, Jamie},
  journal={Interactive Technology and Smart Education},
  volume={18},
  number={1},
  pages={85--103},
  year={2021},
  publisher={Emerald Publishing Limited}
}

@inproceedings{brooke2013native,
  title={Native language detection with ‘cheap’learner corpora},
  author={Brooke, Julian and Hirst, Graeme},
  booktitle={Twenty Years of Learner Corpus Research. Looking Back, Moving Ahead: Proceedings of the First Learner Corpus Research Conference (LCR 2011)},
  volume={1},
  pages={37},
  year={2013},
  organization={Presses universitaires de Louvain}
}

@article{cong2025demystifying,
  title={Demystifying large language models in second language development research},
  author={Cong, Yan},
  journal={Computer Speech \& Language},
  volume={89},
  pages={101700},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{elshin2024general,
  title={From general LLM to translation: How we dramatically improve translation quality using human evaluation data for LLM finetuning},
  author={Elshin, Denis and Karpachev, Nikolay and Gruzdev, Boris and Golovanov, Ilya and Ivanov, Georgy and Antonov, Alexander and Skachkov, Nickolay and Latypova, Ekaterina and Layner, Vladimir and Enikeeva, Ekaterina and others},
  booktitle={Proceedings of the Ninth Conference on Machine Translation},
  pages={247--252},
  year={2024}
}

@article{felker2021role,
  title={The role of corrective feedback and lexical guidance in perceptual learning of a novel L2 accent in dialogue},
  author={Felker, Emily and Broersma, Mirjam and Ernestus, Mirjam},
  journal={Applied Psycholinguistics},
  volume={42},
  number={4},
  pages={1029--1055},
  year={2021},
  publisher={Cambridge University Press}
}

@article{gan2024clarq,
  title={ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog},
  author={Gan, Yujian and Li, Changling and Xie, Jinxia and Wen, Luou and Purver, Matthew and Poesio, Massimo},
  journal={arXiv preprint arXiv:2409.06097},
  year={2024}
}

@inproceedings{gao-etal-2025-interaction,
    title = "Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on {E}nglish Second Language Conversations",
    author = "Gao, Rena  and
      Roever, Carsten  and
      Lau, Jey Han",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.729/",
    pages = "10977--11012",
    abstract = "We present an evaluation framework for interactive dialogue assessment in the context of English as a Second Language (ESL) speakers. Our framework collects dialogue-level interactivity labels (e.g., topic management; 4 labels in total) and micro-level span features (e.g., backchannels; 17 features in total). Given our annotated data, we study how the micro-level features influence the (higher level) interactivity quality of ESL dialogues by constructing various machine learning-based models. Our results demonstrate that certain micro-level features strongly correlate with interactivity quality, like reference words (e.g., she, her, he), revealing new insights about the interaction between higher-level dialogue quality and lower-level fundamental linguistic signals. Our framework also provides a means to assess ESL communication, which is useful for language assessment."
}

@article{gao2024cnima,
  title={An Interpretable and Crosslingual Method for Evaluating Second-Language Dialogues},
  author={Gao, Rena and Wu, Jingxuan and Roever, Carsten and Wu, Xuetong and Wu, Jing and Lv, Long and Lau, Jey Han},
  journal={In Proceedings of NAACL 2025, Albuquerque, New Mexico.},
  year={2025}
}

@article{gao2024interaction,
  title={Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on English Second Language Conversations},
  author={Gao, Rena and Roever, Carsten and Lau, Jey Han},
  journal={arXiv preprint arXiv:2407.06479 (to be appeared at the 31st International Conference on Computational Linguistics 2025)},
  year={2024}
}

@inproceedings{han2024llm,
  title={LLM-as-a-tutor in EFL Writing Education: Focusing on Evaluation of Student-LLM Interaction},
  author={Han, Jieun and Yoo, Haneul and Myung, Junho and Kim, Minsun and Lim, Hyunseung and Kim, Yoonsu and Lee, Tak Yeon and Hong, Hwajung and Kim, Juho and Ahn, So-Yeon and others},
  booktitle={Proceedings of the 1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual (CustomNLP4U)},
  pages={284--293},
  year={2024}
}

@inproceedings{huzaifah2024evaluating,
  title={Evaluating Code-Switching Translation with Large Language Models},
  author={Huzaifah, Muhammad and Zheng, Weihua and Chanpaisit, Nattapol and Wu, Kui},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={6381--6394},
  year={2024}
}

@article{jeon2022information,
  title={An information-theoretic framework for deep learning},
  author={Jeon, Hong Jun and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3279--3291},
  year={2022}
}

@inproceedings{jin2024better,
  title={Better to ask in English: Cross-lingual evaluation of large language models for healthcare queries},
  author={Jin, Yiqiao and Chandra, Mohit and Verma, Gaurav and Hu, Yibo and De Choudhury, Munmun and Kumar, Srijan},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2627--2638},
  year={2024}
}

@inproceedings{king-flanigan-2023-diverse,
    title = "Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking",
    author = "King, Brendan  and
      Flanigan, Jeffrey",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.344",
    doi = "10.18653/v1/2023.findings-acl.344",
    pages = "5570--5585",
    abstract = "There has been significant interest in zero and few-shot learning for dialogue state tracking (DST) due to the high cost of collecting and annotating task-oriented dialogues. Recent work has demonstrated that in-context learning requires very little data and zero parameter updates, and even outperforms trained methods in the few-shot setting. We propose RefPyDST, which advances the state of the art with three advancements to in-context learning for DST.First, we formulate DST as a Python programming task, explicitly modeling language coreference as variable reference in Python. Second, since in-context learning depends highly on the context examples, we propose a method to retrieve a diverse set of relevant examples to improve performance. Finally, we introduce a novel re-weighting method during decoding that takes into account probabilities of competing surface forms, and produces a more accurate dialogue state prediction. We evaluate our approach using MultiWOZ and achieve state-of-the-art multi-domain joint-goal accuracy in zero and few-shot settings.",
}

@inproceedings{kobayashi-etal-2024-large,
    title = "Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction",
    author = "Kobayashi, Masamune  and
      Mita, Masato  and
      Komachi, Mamoru",
    editor = {Kochmar, Ekaterina  and
      Bexte, Marie  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Tack, Ana{\"\i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng},
    booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bea-1.6",
    pages = "68--77",
    abstract = "Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall{'}s rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.",
}

@misc{levenston1971over,
  title={Over-indulgence and under-representation: Aspects of mother-tongue interference},
  author={Levenston, Edwards},
  year={1971},
  publisher={Papers in contrastive linguistics/Cambridge University Press}
}

@inproceedings{li-qiu-2023-finding,
    title = "Finding Support Examples for In-Context Learning",
    author = "Li, Xiaonan  and
      Qiu, Xipeng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.411",
    doi = "10.18653/v1/2023.findings-emnlp.411",
    pages = "6219--6235",
    abstract = "In-context learning is a new learning paradigm where a language model observes a few examples and directly outputs the test input{'}s prediction. Previous works have shown that it is sensitive to the provided examples and randomly sampled examples probably cause inferior performance. In this paper, we propose finding {``}support examples{''} for in-context learning: Given a training dataset, it aims to select one permutation of a few examples, which can well characterize the task for in-context learning and thus lead to superior performance. Although for traditional gradient-based training, there are extensive methods to find a coreset from the entire dataset, they struggle to find important in-context examples, because in-context learning occurs in the language model{'}s forward process without gradients or parameter updates and thus has a significant gap with traditional training. Additionally, the strong dependence among in-context examples makes it an NP-hard combinatorial optimization problem and enumerating all permutations is infeasible. Hence we propose **LENS**, a fi**L**ter-th**EN**-**S**earch method to tackle this challenge in two stages: irst we filter the dataset to obtain individually informative in-context examples. Specifically, we propose a novel metric, InfoScore, to evaluate the example{'}s in-context informativeness based on the language model{'}s feedback, and further propose a progressive filtering process to filter out uninformative examples. Then we propose diversity-guided example search which iteratively refines and evaluates the selected example permutations, to find examples that fully depict the task. The experimental results show that LENS significantly outperforms a wide range of baselines and further analyses show that each component contribute critically to the improvements and shed light on the principles of supporting examples and in-context learning.",
}

@article{manoharanmaximizing,
author = {Manoharan, Ashok and Nagar, Gourav},
year = {2021},
month = {12},
pages = {01-10},
title = {Maximizing Learning Trajectories: An Investigation into AI-Driven Natural Language Processing Integration in Online Educational Platforms},
volume = {03},
journal = {International Research Journal of Modernization in Engineering Technology and Science},
doi = {10.56726/IRJMETS18093}
}

@article{mejeh2024taking,
  title={Taking adaptive learning in educational settings to the next level: Leveraging natural language processing for improved personalization},
  author={Mejeh, Mathias and Rehm, Martin},
  journal={Educational technology research and development},
  pages={1--25},
  year={2024},
  publisher={Springer}
}

@article{miah2024multimodal,
  title={A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM},
  author={Miah, Md Saef Ullah and Kabir, Md Mohsin and Sarwar, Talha Bin and Safran, Mejdl and Alfarhood, Sultan and Mridha, MF},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={9603},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{oba-etal-2023-second,
    title = "Second Language Acquisition of Neural Language Models",
    author = "Oba, Miyu  and
      Kuribayashi, Tatsuki  and
      Ouchi, Hiroki  and
      Watanabe, Taro",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.856",
    doi = "10.18653/v1/2023.findings-acl.856",
    pages = "13557--13572",
    abstract = "With the success of neural language models (LMs), their language acquisition has gained much attention. This work sheds light on the second language (L2) acquisition of LMs, while previous work has typically explored their first language (L1) acquisition. Specifically, we trained bilingual LMs with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives. Our exploratory experiments demonstrated that the L1 pretraining accelerated their linguistic generalization in L2, and language transfer configurations (e.g., the L1 choice, and presence of parallel texts) substantially affected their generalizations. These clarify their (non-)human-like L2 acquisition in particular aspects.",
}

@inproceedings{ou-etal-2024-dialogbench,
    title = "{D}ialog{B}ench: Evaluating {LLM}s as Human-like Dialogue Systems",
    author = "Ou, Jiao  and
      Lu, Junda  and
      Liu, Che  and
      Tang, Yihong  and
      Zhang, Fuzheng  and
      Zhang, Di  and
      Gai, Kun",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.341",
    doi = "10.18653/v1/2024.naacl-long.341",
    pages = "6137--6170",
    abstract = "Large language models (LLMs) have achieved remarkable breakthroughs in new dialogue capabilities by leveraging instruction tuning,which refreshes human impressions of dialogue systems. The long-standing goal of dialogue systems is to be human-like enough to establish long-term connections with users. Therefore, there has been an urgent need to evaluate LLMs as human-like dialogue systems. In this paper, we propose DialogBench, a dialogue evaluation benchmark that contains 12 dialogue tasks to probe the capabilities of LLMs as human-like dialogue systems should have. Specifically, we prompt GPT-4 to generate evaluation instances for each task. We first design the basic prompt based on widely used design principles and further mitigate the existing biases to generate higher-quality evaluation instances. Our extensive tests on English and Chinese DialogBench of 26 LLMs show that instruction tuning improves the human likeness of LLMs to a certain extent, but most LLMs still have much room for improvement as human-like dialogue systems. Interestingly, results also show that the positioning of assistant AI can make instruction tuning weaken the human emotional perception of LLMs and their mastery of information about human daily life.",
}

@article{poole2024llm,
  title={LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users},
  author={Poole-Dayan, Elinor and Roy, Deb and Kabbara, Jad},
  journal={arXiv preprint arXiv:2406.17737},
  year={2024}
}

@article{pvribavn2024comparative,
  title={A comparative study of cross-lingual sentiment analysis},
  author={P{\v{r}}ib{\'a}{\v{n}}, Pavel and {\v{S}}m{\'\i}d, Jakub and Steinberger, Josef and Mi{\v{s}}tera, Adam},
  journal={Expert Systems with Applications},
  volume={247},
  pages={123247},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{ranaldi2023does,
  title={Does the English matter? elicit cross-lingual abilities of large language models},
  author={Ranaldi, Leonardo and Pucci, Giulia},
  booktitle={Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL)},
  pages={173--183},
  year={2023}
}

@article{singh2024three,
  title={A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs},
  author={Singh, Vaibhav and Krishna, Amrith and NJ, Karthika and Ramakrishnan, Ganesh},
  journal={arXiv preprint arXiv:2406.17377},
  year={2024}
}

@inproceedings{sung-etal-2024-context,
    title = "Context-Aware {LLM} Translation System Using Conversation Summarization and Dialogue History",
    author = "Sung, Mingi  and
      Lee, Seungmin  and
      Kim, Jiwon  and
      Kim, Sejoon",
    editor = "Haddow, Barry  and
      Kocmi, Tom  and
      Koehn, Philipp  and
      Monz, Christof",
    booktitle = "Proceedings of the Ninth Conference on Machine Translation",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.wmt-1.102",
    doi = "10.18653/v1/2024.wmt-1.102",
    pages = "1011--1015",
    abstract = "Translating conversational text, particularly in customer support contexts, presents unique challenges due to its informal and unstructured nature. We propose a context-aware LLM translation system that leverages conversation summarization and dialogue history to enhance translation quality for the English-Korean language pair. Our approach incorporates the two most recent dialogues as raw data and a summary of earlier conversations to manage context length effectively. We demonstrate that this method significantly improves translation accuracy, maintaining coherence and consistency across conversations. This system offers a practical solution for customer support translation tasks, addressing the complexities of conversational text.",
}

@article{veivo2025dialogue,
  title={Dialogue breakdowns in robot-assisted L2 learning},
  author={Veivo, Outi and Mutta, Maarit},
  journal={Computer Assisted Language Learning},
  volume={38},
  number={1-2},
  pages={30--51},
  year={2025},
  publisher={Taylor \& Francis}
}

@inproceedings{yadavalli-etal-2023-slabert,
    title = "{SLABERT} Talk Pretty One Day: Modeling Second Language Acquisition with {BERT}",
    author = "Yadavalli, Aditya  and
      Yadavalli, Alekhya  and
      Tobin, Vera",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.657",
    doi = "10.18653/v1/2023.acl-long.657",
    pages = "11763--11777",
    abstract = "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker{'}s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Mutlilingual Age Ordered CHILDES (MAO-CHILDES){---}a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese{---}to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data. Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
}

@article{yigci2024large,
  title={Large Language Model-Based Chatbots in Higher Education},
  author={Yigci, Defne and Eryilmaz, Merve and Yetisen, Ail K and Tasoglu, Savas and Ozcan, Aydogan},
  journal={Advanced Intelligent Systems},
  pages={2400429},
  year={2024},
  publisher={Wiley Online Library}
}

