% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{ishikawa2018icnale,
  title={ICNALE: the international corpus network of Asian learners of English},
  author={Ishikawa, Shin’ichiro},
  journal={Icnale: the international corpus network of asian learners of english},
  year={2018}
}

@inproceedings{yannakoudakis2011new,
  title={A new dataset and method for automatically grading ESOL texts},
  author={Yannakoudakis, Helen and Briscoe, Ted and Medlock, Ben},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies},
  pages={180--189},
  year={2011}
}

@inproceedings{brooke2013native,
  title={Native language detection with ‘cheap’learner corpora},
  author={Brooke, Julian and Hirst, Graeme},
  booktitle={Twenty Years of Learner Corpus Research. Looking Back, Moving Ahead: Proceedings of the First Learner Corpus Research Conference (LCR 2011)},
  volume={1},
  pages={37},
  year={2013},
  organization={Presses universitaires de Louvain}
}

@inproceedings{brooke-hirst-2012-measuring,
    title = "Measuring Interlanguage: Native Language Identification with {L}1-influence Metrics",
    author = "Brooke, Julian  and
      Hirst, Graeme",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Declerck, Thierry  and
      Do{\u{g}}an, Mehmet U{\u{g}}ur  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Eighth International Conference on Language Resources and Evaluation ({LREC}'12)",
    month = may,
    year = "2012",
    address = "Istanbul, Turkey",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2012/pdf/129_Paper.pdf",
    pages = "779--784",
    abstract = "The task of native language (L1) identification suffers from a relative paucity of useful training corpora, and standard within-corpus evaluation is often problematic due to topic bias. In this paper, we introduce a method for L1 identification in second language (L2) texts that relies only on much more plentiful L1 data, rather than the L2 texts that are traditionally used for training. In particular, we do word-by-word translation of large L1 blog corpora to create a mapping to L2 forms that are a possible result of language transfer, and then use that information for unsupervised classification. We show this method is effective in several different learner corpora, with bigram features being particularly useful.",
}

@inproceedings{chen2020bridging,
  title={Bridging the gap between prior and posterior knowledge selection for knowledge-grounded dialogue generation},
  author={Chen, Xiuyi and Meng, Fandong and Li, Peng and Chen, Feilong and Xu, Shuang and Xu, Bo and Zhou, Jie},
  booktitle={Proceedings of the 2020 Conference on empirical methods in natural language processing (EMNLP)},
  pages={3426--3437},
  year={2020}
}

@article{watanabe2007effects,
  title={Effects of proficiency differences and patterns of pair interaction on second language learning: Collaborative dialogue between adult ESL learners},
  author={Watanabe, Yuko and Swain, Merrill},
  journal={Language teaching research},
  volume={11},
  number={2},
  pages={121--142},
  year={2007},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@book{ishikawa2023icnale,
  title={The ICNALE Guide: An Introduction to a Learner Corpus Study on Asian Learners’ L2 English},
  author={Ishikawa, Shin'ichiro},
  year={2023},
  publisher={Taylor \& Francis}
}

@article{wang2024probing,
  title={Probing the Emergence of Cross-lingual Alignment during LLM Training},
  author={Wang, Hetong and Minervini, Pasquale and Ponti, Edoardo M},
  journal={arXiv preprint arXiv:2406.13229},
  year={2024}
}


@article{fujii2024continual,
  title={Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities},
  author={Fujii, Kazuki and Nakamura, Taishi and Loem, Mengsay and Iida, Hiroki and Ohi, Masanari and Hattori, Kakeru and Shota, Hirai and Mizuki, Sakae and Yokota, Rio and Okazaki, Naoaki},
  journal={arXiv preprint arXiv:2404.17790},
  year={2024}
}

@article{wang2024multimodal,
  title={Multimodal LLM Enhanced Cross-lingual Cross-modal Retrieval},
  author={Wang, Yabing and Wang, Le and Zhou, Qiang and Wang, Zhibin and Li, Hao and Hua, Gang and Tang, Wei},
  journal={arXiv preprint arXiv:2409.19961},
  year={2024}
}

@article{chua2024crosslingual,
  title={Crosslingual Capabilities and Knowledge Barriers in Multilingual Large Language Models},
  author={Chua, Lynn and Ghazi, Badih and Huang, Yangsibo and Kamath, Pritish and Kumar, Ravi and Manurangsi, Pasin and Sinha, Amer and Xie, Chulin and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2406.16135},
  year={2024}
}

@article{singh2024three,
  title={A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual LLMs},
  author={Singh, Vaibhav and Krishna, Amrith and NJ, Karthika and Ramakrishnan, Ganesh},
  journal={arXiv preprint arXiv:2406.17377},
  year={2024}
}

@article{lu2024llamax,
  title={Llamax: Scaling linguistic horizons of llm by enhancing translation capabilities beyond 100 languages},
  author={Lu, Yinquan and Zhu, Wenhao and Li, Lei and Qiao, Yu and Yuan, Fei},
  journal={arXiv preprint arXiv:2407.05975},
  year={2024}
}

@inproceedings{nikolova2024llm,
  title={LLM-Generated Contexts to Practice Specialised Vocabulary: Corpus Presentation and Comparison},
  author={Nikolova, Iglika and Bibauw, Serge and Dumont, Amandine and Stas, Fran{\c{c}}oise and Watrin, Patrick and Fran{\c{c}}ois, Thomas},
  booktitle={35{\`e}mes Journ{\'e}es d’{\'E}tudes sur la Parole (JEP 2024) 31{\`e}me Conf{\'e}rence sur le Traitement Automatique des Langues Naturelles (TALN 20},
  year={2024}
}

@article{weissweiler2024hybrid,
  title={Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena},
  author={Weissweiler, Leonie and K{\"o}ksal, Abdullatif and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2403.06965},
  year={2024}
}

@article{requeima2024llm,
  title={LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language},
  author={Requeima, James and Bronskill, John and Choi, Dami and Turner, Richard E and Duvenaud, David},
  journal={arXiv preprint arXiv:2405.12856},
  year={2024}
}

@article{poole2024llm,
  title={LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users},
  author={Poole-Dayan, Elinor and Roy, Deb and Kabbara, Jad},
  journal={arXiv preprint arXiv:2406.17737},
  year={2024}
}

@article{kmainasi2024native,
  title={Native vs non-native language prompting: A comparative analysis},
  author={Kmainasi, Mohamed Bayan and Khan, Rakif and Shahroor, Ali Ezzat and Bendou, Boushra and Hasanain, Maram and Alam, Firoj},
  journal={arXiv preprint arXiv:2409.07054},
  year={2024}
}

@article{gao2023enabling,
  title={Enabling large language models to generate text with citations},
  author={Gao, Tianyu and Yen, Howard and Yu, Jiatong and Chen, Danqi},
  journal={arXiv preprint arXiv:2305.14627},
  year={2023}
}

@article{kantharuban2023quantifying,
  title={Quantifying the dialect gap and its correlates across languages},
  author={Kantharuban, Anjali and Vuli{\'c}, Ivan and Korhonen, Anna},
  journal={arXiv preprint arXiv:2310.15135},
  year={2023}
}

@article{lin2024one,
  title={One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks},
  author={Lin, Fangru and Mao, Shaoguang and La Malfa, Emanuele and Hofmann, Valentin and de Wynter, Adrian and Yao, Jing and Chen, Si-Qing and Wooldridge, Michael and Wei, Furu},
  journal={arXiv preprint arXiv:2410.11005},
  year={2024}
}

@article{ye2023prompt,
  title={Prompt engineering a prompt engineer},
  author={Ye, Qinyuan and Axmed, Maxamed and Pryzant, Reid and Khani, Fereshte},
  journal={arXiv preprint arXiv:2311.05661},
  year={2023}
}

@inproceedings{zhong2022describing,
  title={Describing differences between text distributions with natural language},
  author={Zhong, Ruiqi and Snell, Charlie and Klein, Dan and Steinhardt, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={27099--27116},
  year={2022},
  organization={PMLR}
}

@article{pyatkin2021possible,
  title={The possible, the plausible, and the desirable: Event-based modality detection for language processing},
  author={Pyatkin, Valentina and Sadde, Shoval and Rubinstein, Aynat and Portner, Paul and Tsarfaty, Reut},
  journal={arXiv preprint arXiv:2106.08037},
  year={2021}
}

@article{xu2024chain,
  title={Chain of Thought Explanation for Dialogue State Tracking},
  author={Xu, Lin and Peng, Ningxin and Zhou, Daquan and Ng, See-Kiong and Fu, Jinlan},
  journal={arXiv preprint arXiv:2403.04656},
  year={2024}
}

@article{wang2024information,
  title={An Information-Theoretic Approach to Analyze NLP Classification Tasks},
  author={Wang, Luran and Gales, Mark and Raina, Vatsal},
  journal={arXiv preprint arXiv:2402.00978},
  year={2024}
}

@inproceedings{aoyama2024modeling,
  title={Modeling Nonnative Sentence Processing with L2 Language Models},
  author={Aoyama, Tatsuya and Schneider, Nathan},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={4927--4940},
  year={2024}
}

@article{downey2023embedding,
  title={Embedding structure matters: Comparing methods to adapt multilingual vocabularies to new languages},
  author={Downey, CM and Blevins, Terra and Goldfine, Nora and Steinert-Threlkeld, Shane},
  journal={arXiv preprint arXiv:2309.04679},
  year={2023}
}

@article{gao2024listenership,
  title={Listenership always matters: active listening ability in L2 business English paired speaking tasks},
  author={Gao, Rena and Wang, Menghan},
  journal={International Review of Applied Linguistics in Language Teaching},
  publisher={De Gruyter}
}

@article{gao2024interaction,
  title={Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on English Second Language Conversations},
  author={Gao, Rena and Roever, Carsten and Lau, Jey Han},
  journal={arXiv preprint arXiv:2407.06479 (to be appeared at the 31st International Conference on Computational Linguistics 2025)},
  year={2024}
}

@article{lyu2024regional,
  title={Regional bias in monolingual English language models},
  author={Lyu, Jiachen and Dost, Katharina and Koh, Yun Sing and Wicker, J{\"o}rg},
  journal={Machine Learning},
  volume={113},
  number={9},
  pages={6663--6696},
  year={2024},
  publisher={Springer}
}

%================= New added articles about role-play ===============
@inproceedings{cherednichenko2024large,
author = {Cherednichenko, Olga and Yanholenko, Olha and Badan, Antonina and Onishchenko, Nataliia and Akopiants, Nunu},
year = {2024},
month = {07},
pages = {},
title = {Large language models for foreign language acquisition},
doi = {10.31110/COLINS/2024-4/008}
}

@article{tamoyan2024llm,
  title={Llm roleplay: Simulating human-chatbot interaction},
  author={Tamoyan, Hovhannes and Schuff, Hendrik and Gurevych, Iryna},
  journal={arXiv preprint arXiv:2407.03974},
  year={2024}
}

@article{kong2024self,
  title={Self-prompt tuning: Enable autonomous role-playing in llms},
  author={Kong, Aobo and Zhao, Shiwan and Chen, Hao and Li, Qicheng and Qin, Yong and Sun, Ruiqi and Zhou, Xin and Zhou, Jiaming and Sun, Haoqin},
  journal={arXiv preprint arXiv:2407.08995},
  year={2024}
}

@article{wu2024role,
  title={From Role-Play to Drama-Interaction: An LLM Solution},
  author={Wu, Weiqi and Wu, Hongqiu and Jiang, Lai and Liu, Xingyuan and Hong, Jiale and Zhao, Hai and Zhang, Min},
  journal={arXiv preprint arXiv:2405.14231},
  year={2024}
}

@article{chen2024roleinteract,
  title={RoleInteract: Evaluating the Social Interaction of Role-Playing Agents},
  author={Chen, Hongzhan and Chen, Hehong and Yan, Ming and Xu, Wenshen and Gao, Xing and Shen, Weizhou and Quan, Xiaojun and Li, Chenliang and Zhang, Ji and Huang, Fei and others},
  journal={arXiv preprint arXiv:2403.13679},
  year={2024}
}

@article{zhou2024llm,
  title={An LLM Feature-based Framework for Dialogue Constructiveness Assessment},
  author={Zhou, Lexin and Farag, Youmna and Vlachos, Andreas},
  journal={arXiv preprint arXiv:2406.14760},
  year={2024}
}

@article{abe2019interactional,
  title={Interactional competence in L2 text-chat interactions: First-idea proffering in task openings},
  author={Abe, Makoto and Roever, Carsten},
  journal={Journal of Pragmatics},
  volume={144},
  pages={1--14},
  year={2019},
  publisher={Elsevier}
}

@article{syamkumar2024improving,
  title={Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education},
  author={Syamkumar, Anand and Tseng, Nora and Barron, Kaycie and Yang, Shanglin and Karumbaiah, Shamya and Uppal, Rheeya and Hu, Junjie},
  journal={arXiv preprint arXiv:2411.04308},
  year={2024}
}

@article{lai2024llms,
  title={LLMs Beyond English: Scaling the Multilingual Capability of LLMs with Cross-Lingual Feedback},
  author={Lai, Wen and Mesgar, Mohsen and Fraser, Alexander},
  journal={arXiv preprint arXiv:2406.01771},
  year={2024}
}

@article{zhang2023don,
  title={Don't Trust ChatGPT when Your Question is not in English: A Study of Multilingual Abilities and Types of LLMs},
  author={Zhang, Xiang and Li, Senyu and Hauer, Bradley and Shi, Ning and Kondrak, Grzegorz},
  journal={arXiv preprint arXiv:2305.16339},
  year={2023}
}

@article{gan2024clarq,
  title={ClarQ-LLM: A Benchmark for Models Clarifying and Requesting Information in Task-Oriented Dialog},
  author={Gan, Yujian and Li, Changling and Xie, Jinxia and Wen, Luou and Purver, Matthew and Poesio, Massimo},
  journal={arXiv preprint arXiv:2409.06097},
  year={2024}
}
@article{roever2023validating,
  title={Validating a test of L2 routine formulae to detect pragmatics learning in stay abroad},
  author={Roever, Carsten and Higuchi, Yuki and Sasaki, Miyuki and Yashima, Tomoko and Nakamuro, Makiko},
  journal={Applied Pragmatics},
  volume={5},
  number={1},
  pages={41--63},
  year={2023},
  publisher={John Benjamins Publishing Company Amsterdam/Philadelphia}
}

@article{jackson2018production,
  title={The production of subject-verb agreement among Swedish and Chinese second language speakers of English},
  author={Jackson, Carrie N and Mormer, Elizabeth and Brehm, Laurel},
  journal={Studies in Second Language Acquisition},
  volume={40},
  number={4},
  pages={907--921},
  year={2018},
  publisher={Cambridge University Press}
}

@article{kasanga2007cross,
  title={Cross-cultural linguistic realization of politeness: A study of apologies in English and Setswana},
  author={Kasanga, Luanga A and Lwanga-Lumu, Joy-Christine},
  year={2007},
  publisher={Walter de Gruyter}
}

@article{yossatorn2022thai,
  title={Thai EFL university students’ productions of the English past counterfactuals and their influences from interlanguage fossilization},
  author={Yossatorn, Yossiri and Binali, Theerapong and Chokthawikit, Sirisira and Weng, Cathy},
  journal={SAGE Open},
  volume={12},
  number={1},
  pages={21582440221079892},
  year={2022},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{milliere2024language,
  title={Language models as models of language},
  author={Milli{\`e}re, Rapha{\"e}l},
  journal={arXiv preprint arXiv:2408.07144},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{chen2024llm,
  title={LLM-based Translation Inference with Iterative Bilingual Understanding},
  author={Chen, Andong and Chen, Kehai and Xiang, Yang and Bai, Xuefeng and Yang, Muyun and Zhao, Tiejun and others},
  journal={arXiv preprint arXiv:2410.12543},
  year={2024}
}
@article{majewska2023cross,
  title={Cross-lingual dialogue dataset creation via outline-based generation},
  author={Majewska, Olga and Razumovskaia, Evgeniia and Ponti, Edoardo M and Vuli{\'c}, Ivan and Korhonen, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={139--156},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

=======in context learning literature========

@article{bocklisch2024task,
  title={Task-oriented dialogue with in-context learning},
  author={Bocklisch, Tom and Werkmeister, Thomas and Varshneya, Daksh and Nichol, Alan},
  journal={arXiv preprint arXiv:2402.12234},
  year={2024}
}
}



@article{atox2024evaluating,
  title={Evaluating large language models through the lens of linguistic proficiency and world knowledge: A comparative study},
  author={Atox, Nathan and Clark, Mason},
  journal={Authorea Preprints},
  year={2024},
  publisher={Authorea}
}


@article{chang2024survey,
  title={A survey on evaluation of large language models},
  author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={3},
  pages={1--45},
  year={2024},
  publisher={ACM New York, NY}
}

@article{zhou2024linguistic,
  title={Linguistic Minimal Pairs Elicit Linguistic Similarity in Large Language Models},
  author={Zhou, Xinyu and Chen, Delong and Cahyawijaya, Samuel and Duan, Xufeng and Cai, Zhenguang G},
  journal={arXiv preprint arXiv:2409.12435},
  year={2024}
}


@article{cong2025demystifying,
  title={Demystifying large language models in second language development research},
  author={Cong, Yan},
  journal={Computer Speech \& Language},
  volume={89},
  pages={101700},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{miaschi2024evaluating,
  title={Evaluating Large Language Models via Linguistic Profiling},
  author={Miaschi, Alessio and Dell’Orletta, Felice and Venturi, Giulia},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={2835--2848},
  year={2024}
}

@article{philippy2023identifying,
  title={Identifying the correlation between language distance and cross-lingual transfer in a multilingual representation space},
  author={Philippy, Fred and Guo, Siwen and Haddadan, Shohreh},
  journal={arXiv preprint arXiv:2305.02151},
  year={2023}
}

@article{ang2011collocations,
  title={Collocations in Malaysian English learners’ writing: A corpus-based error analysis},
  author={Ang, Leng Hong and Rahim, Hajar Abdul and Tan, Kim Hua and Salehuddin, Khazriyati},
  journal={3L: The Southeast Asian Journal of English Language Studies},
  volume={17},
  number={Special Issues},
  pages={31--44},
  year={2011},
  publisher={Penerbit UKM}
}

@article{kamarudin2020examining,
  title={Examining ESL learners’ knowledge of collocations},
  author={Kamarudin, Rafidah and Abdullah, Shazila and Aziz, Roslina Abdul},
  journal={International Journal of Applied Linguistics and English Literature},
  volume={9},
  number={1},
  pages={1--6},
  year={2020}
}

@inproceedings{kim2010structures,
  title={The structures of modality in Korean},
  author={Kim, Shin-Sook},
  booktitle={Proceedings of the 6th Workshop on Altaic Formal Linguistics},
  pages={171--180},
  year={2010},
  organization={Citeseer}
}

@inproceedings{abbas2009lexical,
  title={Lexical functional grammar for Urdu modal verbs},
  author={Abbas, Qaiser and Khan, Ahsan Nabi},
  booktitle={2009 International Conference on Emerging Technologies},
  pages={7--12},
  year={2009},
  organization={IEEE}
}

@article{abbas2016morphologically,
  title={Morphologically rich Urdu grammar parsing using Earley algorithm},
  author={Abbas, Qaiser},
  journal={Natural Language Engineering},
  volume={22},
  number={5},
  pages={775--810},
  year={2016},
  publisher={Cambridge University Press}
}

@article{dai2019including,
  title={Including L2-English varieties in listening tests for adolescent ESL learners: L1 effects and learner perceptions},
  author={Dai, David Wei and Roever, Carsten},
  journal={Language Assessment Quarterly},
  volume={16},
  number={1},
  pages={64--86},
  year={2019},
  publisher={Taylor \& Francis}
}

@inproceedings{fincham2024using,
  title={Using Large Language Models (LLMs) to facilitate L2 proficiency development through personalized feedback and scaffolding: An empirical study},
  author={Fincham, Naiyi Xie and Alvarez, Aitor Arronte},
  booktitle={Proceedings of the International CALL Research Conference},
  volume={2024},
  pages={59--64},
  year={2024}
}

@article{liang2024controllable,
  title={Controllable text generation for large language models: A survey},
  author={Liang, Xun and Wang, Hanyu and Wang, Yezhaohui and Song, Shichao and Yang, Jiawei and Niu, Simin and Hu, Jie and Liu, Dan and Yao, Shunyu and Xiong, Feiyu and others},
  journal={arXiv preprint arXiv:2408.12599},
  year={2024}
}

@article{takahashi2024l1,
  title={L1 Japanese Perceptual Drift in Late Learners of L2 English},
  author={Takahashi, Chikako},
  journal={Languages},
  volume={9},
  number={1},
  pages={23},
  year={2024},
  publisher={MDPI}
}

@article{schwandt2001understanding,
  title={Understanding dialogue as practice},
  author={Schwandt, Thomas A},
  journal={Evaluation},
  volume={7},
  number={2},
  pages={228--237},
  year={2001},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@inproceedings{sun2021conversations,
  title={Conversations powered by cross-lingual knowledge},
  author={Sun, Weiwei and Meng, Chuan and Meng, Qi and Ren, Zhaochun and Ren, Pengjie and Chen, Zhumin and Rijke, Maarten de},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1442--1451},
  year={2021}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

==============================Results section to discuss===========================================

@phdthesis{srisuruk2011politeness,
  title={Politeness and pragmatic competence in Thai speakers of English},
  author={Srisuruk, Patana},
  year={2011},
  school={Newcastle University}
}

@article{batool2023comparative,
  title={Comparative construction morphology of diminutive forms in English and Urdu},
  author={Batool, Rabia and Saleem, Tahir},
  journal={Cogent Arts \& Humanities},
  volume={10},
  number={1},
  pages={2238998},
  year={2023},
  publisher={Taylor \& Francis}
}


@article{chaiphet2021structure,
  title={The Structure of Classifier-Modifier Recursion in Thai},
  author={Chaiphet, Khanin},
  year={2021}
}

=================information theory===========================

@inproceedings{wu2020information,
  title={Information-theoretic analysis for transfer learning},
  author={Wu, Xuetong and Manton, Jonathan H and Aickelin, Uwe and Zhu, Jingge},
  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)},
  pages={2819--2824},
  year={2020},
  organization={IEEE}
}

=================ref for grammatical categories=============
@article{mousavi2024llms,
  title={Are LLMs Robust for Spoken Dialogues?},
  author={Mousavi, Seyed Mahed and Roccabruna, Gabriel and Alghisi, Simone and Rizzoli, Massimo and Ravanelli, Mirco and Riccardi, Giuseppe},
  journal={arXiv preprint arXiv:2401.02297},
  year={2024}
}

@article{park2024chatlang,
  title={ChatLang-8: An LLM-Based Synthetic Data Generation Framework for Grammatical Error Correction},
  author={Park, Jeiyoon and Park, Chanjun and Lim, Heuiseok},
  journal={arXiv preprint arXiv:2406.03202},
  year={2024}
}

@article{watts2024pariksha,
  title={PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data},
  author={Watts, Ishaan and Gumma, Varun and Yadavalli, Aditya and Seshadri, Vivek and Swaminathan, Manohar and Sitaram, Sunayana},
  journal={arXiv preprint arXiv:2406.15053},
  year={2024}
}

@article{andriushchenko2024does,
  title={Does Refusal Training in LLMs Generalize to the Past Tense?},
  author={Andriushchenko, Maksym and Flammarion, Nicolas},
  journal={arXiv preprint arXiv:2407.11969},
  year={2024}
}

@article{kallini2024mission,
  title={Mission: Impossible language models},
  author={Kallini, Julie and Papadimitriou, Isabel and Futrell, Richard and Mahowald, Kyle and Potts, Christopher},
  journal={arXiv preprint arXiv:2401.06416},
  year={2024}
}

@article{gupta2023probing,
  title={Probing quantifier comprehension in large language models},
  author={Gupta, Akshat},
  journal={arXiv preprint arXiv:2306.07384},
  year={2023}
}

===================Linguistics bib for right grammatical==================
@article{li2022developmental,
  title={Developmental patterns of English modal verbs in the writings of Chinese learners of English: a corpus-based approach},
  author={Li, Lexi Xiaoduo},
  journal={Cogent Education},
  volume={9},
  number={1},
  pages={2050457},
  year={2022},
  publisher={Taylor \& Francis}
}

@book{ross2013assessing,
  title={Assessing second language pragmatics},
  author={Ross, Steven and Kasper, Gabriele},
  year={2013},
  publisher={Springer}
}

@article{chow2023dialogic,
  title={Dialogic teaching in English-as-a-second-language classroom: Its effects on first graders with different levels of vocabulary knowledge},
  author={Chow, Bonnie Wing-Yin and Hui, Anna Na-Na and Li, Zhen and Dong, Yang},
  journal={Language Teaching Research},
  volume={27},
  number={6},
  pages={1408--1430},
  year={2023},
  publisher={Sage Publications Sage UK: London, England}
}

@article{bahns1993should,
  title={Should we teach EFL students collocations?},
  author={Bahns, Jens and Eldaw, Moira},
  journal={System},
  volume={21},
  number={1},
  pages={101--114},
  year={1993},
  publisher={Elsevier}
}

@article{oetting2021marking,
  title={Marking of tense and agreement in language samples by children with and without specific language impairment in African American English and Southern White English: Evaluation of scoring approaches and cut scores across structures},
  author={Oetting, Janna B and Rivi{\`e}re, Andrew M and Berry, Jessica R and Gregory, Kyomi D and Villa, Tina M and McDonald, Janet},
  journal={Journal of Speech, Language, and Hearing Research},
  volume={64},
  number={2},
  pages={491--509},
  year={2021},
  publisher={ASHA}
}

@article{chung2022dialogic,
  title={A dialogic approach to promoting professional development: Understanding change in Hong Kong language teachers’ beliefs and practices regarding vocabulary teaching and learning},
  author={Chung, Edsoulla and Fisher, Linda},
  journal={System},
  volume={110},
  pages={102901},
  year={2022},
  publisher={Elsevier}
}

@article{zhang2022comparative,
  title={A comparative study on lexical and syntactic features of ESL versus EFL learners’ writing},
  author={Zhang, Chao and Kang, Shumin},
  journal={Frontiers in Psychology},
  volume={13},
  pages={1002090},
  year={2022},
  publisher={Frontiers Media SA}
}

@book{taguchi2020second,
  title={Second language pragmatics},
  author={Taguchi, Naoko and Roever, Carsten},
  year={2020},
  publisher={Oxford University Press}
}


=================updated published reference=================
@inproceedings{li-qiu-2023-finding,
    title = "Finding Support Examples for In-Context Learning",
    author = "Li, Xiaonan  and
      Qiu, Xipeng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.411",
    doi = "10.18653/v1/2023.findings-emnlp.411",
    pages = "6219--6235",
    abstract = "In-context learning is a new learning paradigm where a language model observes a few examples and directly outputs the test input{'}s prediction. Previous works have shown that it is sensitive to the provided examples and randomly sampled examples probably cause inferior performance. In this paper, we propose finding {``}support examples{''} for in-context learning: Given a training dataset, it aims to select one permutation of a few examples, which can well characterize the task for in-context learning and thus lead to superior performance. Although for traditional gradient-based training, there are extensive methods to find a coreset from the entire dataset, they struggle to find important in-context examples, because in-context learning occurs in the language model{'}s forward process without gradients or parameter updates and thus has a significant gap with traditional training. Additionally, the strong dependence among in-context examples makes it an NP-hard combinatorial optimization problem and enumerating all permutations is infeasible. Hence we propose **LENS**, a fi**L**ter-th**EN**-**S**earch method to tackle this challenge in two stages: irst we filter the dataset to obtain individually informative in-context examples. Specifically, we propose a novel metric, InfoScore, to evaluate the example{'}s in-context informativeness based on the language model{'}s feedback, and further propose a progressive filtering process to filter out uninformative examples. Then we propose diversity-guided example search which iteratively refines and evaluates the selected example permutations, to find examples that fully depict the task. The experimental results show that LENS significantly outperforms a wide range of baselines and further analyses show that each component contribute critically to the improvements and shed light on the principles of supporting examples and in-context learning.",
}



@article{jeon2022information,
  title={An information-theoretic framework for deep learning},
  author={Jeon, Hong Jun and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3279--3291},
  year={2022}
}

@inproceedings{dorbala-etal-2024-llms,
    title = "Can {LLM}{'}s Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis",
    author = "Dorbala, Vishnu Sashank  and
      Chowdhury, Sanjoy  and
      Manocha, Dinesh",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-short.24",
    doi = "10.18653/v1/2024.naacl-short.24",
    pages = "258--271",
    abstract = "We present a novel approach to automatically synthesize {``}wayfinding instructions{''} for an embodied robot agent. In contrast to prior approaches that are heavily reliant on human-annotated datasets designed exclusively for specific simulation platforms, our algorithm uses in-context learning to condition an LLM to generate instructions using just a few references. Using an LLM-based Visual Question Answering strategy, we gather detailed information about the environment which is used by the LLM for instruction synthesis. We implement our approach on multiple simulation platforms including Matterport3D, AI Habitat and ThreeDWorld, thereby demonstrating its platform-agnostic nature. We subjectively evaluate our approach via a user study and observe that 83.3{\%} of users find the synthesized instructions accurately capture the details of the environment and show characteristics similar to those of human-generated instructions. Further, we conduct zero-shot navigation with multiple approaches on the REVERIE dataset using the generated instructions, and observe very close correlation with the baseline on standard success metrics ({\textless} 1{\%} change in SR), quantifying the viability of generated instructions in replacing human-annotated data. We finally discuss the applicability of our approach in enabling a generalizable evaluation of embodied navigation policies. To the best of our knowledge, ours is the first LLM-driven approach capable of generating {``}human-like{''} instructions in a platform-agnostic manner, without training.",
}

@inproceedings{liu2024make,
  title={Make llm a testing expert: Bringing human-like interaction to mobile gui testing via functionality-aware decisions},
  author={Liu, Zhe and Chen, Chunyang and Wang, Junjie and Chen, Mengzhuo and Wu, Boyu and Che, Xing and Wang, Dandan and Wang, Qing},
  booktitle={Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
  pages={1--13},
  year={2024}
}

@inproceedings{ou-etal-2024-dialogbench,
    title = "{D}ialog{B}ench: Evaluating {LLM}s as Human-like Dialogue Systems",
    author = "Ou, Jiao  and
      Lu, Junda  and
      Liu, Che  and
      Tang, Yihong  and
      Zhang, Fuzheng  and
      Zhang, Di  and
      Gai, Kun",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.naacl-long.341",
    doi = "10.18653/v1/2024.naacl-long.341",
    pages = "6137--6170",
    abstract = "Large language models (LLMs) have achieved remarkable breakthroughs in new dialogue capabilities by leveraging instruction tuning,which refreshes human impressions of dialogue systems. The long-standing goal of dialogue systems is to be human-like enough to establish long-term connections with users. Therefore, there has been an urgent need to evaluate LLMs as human-like dialogue systems. In this paper, we propose DialogBench, a dialogue evaluation benchmark that contains 12 dialogue tasks to probe the capabilities of LLMs as human-like dialogue systems should have. Specifically, we prompt GPT-4 to generate evaluation instances for each task. We first design the basic prompt based on widely used design principles and further mitigate the existing biases to generate higher-quality evaluation instances. Our extensive tests on English and Chinese DialogBench of 26 LLMs show that instruction tuning improves the human likeness of LLMs to a certain extent, but most LLMs still have much room for improvement as human-like dialogue systems. Interestingly, results also show that the positioning of assistant AI can make instruction tuning weaken the human emotional perception of LLMs and their mastery of information about human daily life.",
}

@inproceedings{sung-etal-2024-context,
    title = "Context-Aware {LLM} Translation System Using Conversation Summarization and Dialogue History",
    author = "Sung, Mingi  and
      Lee, Seungmin  and
      Kim, Jiwon  and
      Kim, Sejoon",
    editor = "Haddow, Barry  and
      Kocmi, Tom  and
      Koehn, Philipp  and
      Monz, Christof",
    booktitle = "Proceedings of the Ninth Conference on Machine Translation",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.wmt-1.102",
    doi = "10.18653/v1/2024.wmt-1.102",
    pages = "1011--1015",
    abstract = "Translating conversational text, particularly in customer support contexts, presents unique challenges due to its informal and unstructured nature. We propose a context-aware LLM translation system that leverages conversation summarization and dialogue history to enhance translation quality for the English-Korean language pair. Our approach incorporates the two most recent dialogues as raw data and a summary of earlier conversations to manage context length effectively. We demonstrate that this method significantly improves translation accuracy, maintaining coherence and consistency across conversations. This system offers a practical solution for customer support translation tasks, addressing the complexities of conversational text.",
}

@inproceedings{kobayashi-etal-2024-large,
    title = "Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction",
    author = "Kobayashi, Masamune  and
      Mita, Masato  and
      Komachi, Mamoru",
    editor = {Kochmar, Ekaterina  and
      Bexte, Marie  and
      Burstein, Jill  and
      Horbach, Andrea  and
      Laarmann-Quante, Ronja  and
      Tack, Ana{\"\i}s  and
      Yaneva, Victoria  and
      Yuan, Zheng},
    booktitle = "Proceedings of the 19th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bea-1.6",
    pages = "68--77",
    abstract = "Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall{'}s rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.",
}

@inproceedings{dong-etal-2024-survey,
    title = "A Survey on In-context Learning",
    author = "Dong, Qingxiu  and
      Li, Lei  and
      Dai, Damai  and
      Zheng, Ce  and
      Ma, Jingyuan  and
      Li, Rui  and
      Xia, Heming  and
      Xu, Jingjing  and
      Wu, Zhiyong  and
      Chang, Baobao  and
      Sun, Xu  and
      Li, Lei  and
      Sui, Zhifang",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.64",
    doi = "10.18653/v1/2024.emnlp-main.64",
    pages = "1107--1128",
    abstract = "With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, prompt designing strategies, and related analysis. Additionally, we explore various ICL application scenarios, such as data engineering and knowledge updating. Finally, we address the challenges of ICL and suggest potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.",
}

@inproceedings{kallini-etal-2024-mission,
    title = "Mission: Impossible Language Models",
    author = "Kallini, Julie  and
      Papadimitriou, Isabel  and
      Futrell, Richard  and
      Mahowald, Kyle  and
      Potts, Christopher",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.787",
    doi = "10.18653/v1/2024.acl-long.787",
    pages = "14691--14714",
    abstract = "Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim. Here, we develop a set of synthetic impossible languages of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at one end are languages that are inherently impossible, such as random and irreversible shuffles of English words, and on the other, languages that may not be intuitively impossible but are often considered so in linguistics, particularly those with rules based on counting word positions. We report on a wide range of evaluations to assess the capacity of GPT-2 small models to learn these uncontroversially impossible languages, and crucially, we perform these assessments at various stages throughout training to compare the learning process for each language. Our core finding is that GPT-2 struggles to learn impossible languages when compared to English as a control, challenging the core claim. More importantly, we hope our approach opens up a productive line of inquiry in which different LLM architectures are tested on a variety of impossible languages in an effort to learn more about how LLMs can be used as tools for these cognitive and typological investigations.",
}

@article{perkins2024effect,
  title={The effect of first language transfer on second language acquisition and learning: From contrastive analysis to contemporary neuroimaging},
  author={Perkins, Kyle and Zhang, Lawrence Jun},
  journal={RELC Journal},
  volume={55},
  number={1},
  pages={162--178},
  year={2024},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{abbasiantaeb2024let,
  title={Let the llms talk: Simulating human-to-human conversational qa via zero-shot llm-to-llm interactions},
  author={Abbasiantaeb, Zahra and Yuan, Yifei and Kanoulas, Evangelos and Aliannejadi, Mohammad},
  booktitle={Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
  pages={8--17},
  year={2024}
}

@inproceedings{elshin2024general,
  title={From general LLM to translation: How we dramatically improve translation quality using human evaluation data for LLM finetuning},
  author={Elshin, Denis and Karpachev, Nikolay and Gruzdev, Boris and Golovanov, Ilya and Ivanov, Georgy and Antonov, Alexander and Skachkov, Nickolay and Latypova, Ekaterina and Layner, Vladimir and Enikeeva, Ekaterina and others},
  booktitle={Proceedings of the Ninth Conference on Machine Translation},
  pages={247--252},
  year={2024}
}

@inproceedings{muraoka2023cross,
  title={Cross-Lingual Transfer of Large Language Model by Visually-Derived Supervision toward Low-Resource Languages},
  author={Muraoka, Masayasu and Bhattacharjee, Bishwaranjan and Merler, Michele and Blackwood, Graeme and Li, Yulong and Zhao, Yang},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  pages={3637--3646},
  year={2023}
}

@article{miah2024multimodal,
  title={A multimodal approach to cross-lingual sentiment analysis with ensemble of transformer and LLM},
  author={Miah, Md Saef Ullah and Kabir, Md Mohsin and Sarwar, Talha Bin and Safran, Mejdl and Alfarhood, Sultan and Mridha, MF},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={9603},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{ranaldi2023does,
  title={Does the English matter? elicit cross-lingual abilities of large language models},
  author={Ranaldi, Leonardo and Pucci, Giulia},
  booktitle={Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL)},
  pages={173--183},
  year={2023}
}

@article{pvribavn2024comparative,
  title={A comparative study of cross-lingual sentiment analysis},
  author={P{\v{r}}ib{\'a}{\v{n}}, Pavel and {\v{S}}m{\'\i}d, Jakub and Steinberger, Josef and Mi{\v{s}}tera, Adam},
  journal={Expert Systems with Applications},
  volume={247},
  pages={123247},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{huzaifah2024evaluating,
  title={Evaluating Code-Switching Translation with Large Language Models},
  author={Huzaifah, Muhammad and Zheng, Weihua and Chanpaisit, Nattapol and Wu, Kui},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={6381--6394},
  year={2024}
}

@inproceedings{han2024llm,
  title={LLM-as-a-tutor in EFL Writing Education: Focusing on Evaluation of Student-LLM Interaction},
  author={Han, Jieun and Yoo, Haneul and Myung, Junho and Kim, Minsun and Lim, Hyunseung and Kim, Yoonsu and Lee, Tak Yeon and Hong, Hwajung and Kim, Juho and Ahn, So-Yeon and others},
  booktitle={Proceedings of the 1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual (CustomNLP4U)},
  pages={284--293},
  year={2024}
}

@inproceedings{jin2024better,
  title={Better to ask in English: Cross-lingual evaluation of large language models for healthcare queries},
  author={Jin, Yiqiao and Chandra, Mohit and Verma, Gaurav and Hu, Yibo and De Choudhury, Munmun and Kumar, Srijan},
  booktitle={Proceedings of the ACM on Web Conference 2024},
  pages={2627--2638},
  year={2024}
}

@inproceedings{king-flanigan-2023-diverse,
    title = "Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking",
    author = "King, Brendan  and
      Flanigan, Jeffrey",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.344",
    doi = "10.18653/v1/2023.findings-acl.344",
    pages = "5570--5585",
    abstract = "There has been significant interest in zero and few-shot learning for dialogue state tracking (DST) due to the high cost of collecting and annotating task-oriented dialogues. Recent work has demonstrated that in-context learning requires very little data and zero parameter updates, and even outperforms trained methods in the few-shot setting. We propose RefPyDST, which advances the state of the art with three advancements to in-context learning for DST.First, we formulate DST as a Python programming task, explicitly modeling language coreference as variable reference in Python. Second, since in-context learning depends highly on the context examples, we propose a method to retrieve a diverse set of relevant examples to improve performance. Finally, we introduce a novel re-weighting method during decoding that takes into account probabilities of competing surface forms, and produces a more accurate dialogue state prediction. We evaluate our approach using MultiWOZ and achieve state-of-the-art multi-domain joint-goal accuracy in zero and few-shot settings.",
}

@inproceedings{chen-2023-large,
    title = "Large Language Models are few(1)-shot Table Reasoners",
    author = "Chen, Wenhu",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.83",
    doi = "10.18653/v1/2023.findings-eacl.83",
    pages = "1120--1130",
    abstract = "Recent literature has shown that large language models (LLMs) are generally excellent few-shot reasoners to solve text reasoning tasks. However, the capability of LLMs on table reasoning tasks is yet to be explored. In this paper, we aim at understanding how well LLMs can perform table-related tasks with few-shot in-context learning. Specifically, we evaluated LLMs on popular table QA and fact verification datasets like WikiTableQuestion, FetaQA, TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning over table structures, though these models are not pre-trained on any table corpus. When combined with {`}chain of thoughts{'} prompting, LLMs can achieve very strong performance with only a 1-shot demonstration, even on par with some SoTA models. We show that LLMs are even more competent at generating comprehensive long-form answers on FetaQA than tuned T5-large. We further manually studied the reasoning chains elicited from LLMs and found that these reasoning chains are highly consistent with the underlying semantic form. We believe that LLMs can serve as a simple yet generic baseline for future research. The code and data are released in \url{https://github.com/wenhuchen/TableCoT}.",
}

@inproceedings{gillin2024one,
  title={One-Shot Prompt for Language Variety Identification},
  author={Gillin, Nat},
  booktitle={Proceedings of the Eleventh Workshop on NLP for Similar Languages, Varieties, and Dialects (VarDial 2024)},
  pages={230--234},
  year={2024}
}


@article{hu2022context,
  title={In-context learning for few-shot dialogue state tracking},
  author={Hu, Yushi and Lee, Chia-Hsuan and Xie, Tianbao and Yu, Tao and Smith, Noah A and Ostendorf, Mari},
  journal={arXiv preprint arXiv:2203.08568},
  year={2022}
}

@inproceedings{zhang-etal-2023-xdial,
    title = "x{D}ial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark",
    author = "Zhang, Chen  and
      D{'}Haro, Luis  and
      Tang, Chengguang  and
      Shi, Ke  and
      Tang, Guohua  and
      Li, Haizhou",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.371",
    doi = "10.18653/v1/2023.findings-emnlp.371",
    pages = "5579--5601",
    abstract = "Recent advancements in reference-free learned metrics for open-domain dialogue evaluation have been driven by the progress in pre-trained language models and the availability of dialogue data with high-quality human annotations. However, current studies predominantly concentrate on English dialogues, and the generalization of these metrics to other languages has not been fully examined. This is largely due to the absence of a multilingual dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval, built on top of open-source English dialogue evaluation datasets. xDial-Eval includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930 annotated turns and 8691 annotated dialogues respectively. The English dialogue data are extended to nine other languages with commercial machine translation systems. On xDial-Eval, we conduct comprehensive analyses of previous BERT-based metrics and the recently-emerged large language models. Lastly, we establish strong self-supervised and multilingual baselines. In terms of average Pearson correlations over all datasets and languages, the best baseline outperforms OpenAI{'}s ChatGPT by absolute improvements of 6.5{\%} and 4.6{\%} at the turn and dialogue levels respectively, albeit with much fewer parameters. The data and code are publicly available at https://github.com/e0397123/xDial-Eval.",
}

@article{slabakova2017pronoun,
  title={Pronoun interpretation in the second language: Effects of computational complexity},
  author={Slabakova, Roumyana and White, Lydia and Brambatti Guzzo, Nat{\'a}lia},
  journal={Frontiers in psychology},
  volume={8},
  pages={1236},
  year={2017},
  publisher={Frontiers Media SA}
}

@inproceedings{lam2023large,
  title={Large Language Models Are Partially Primed in Pronoun Interpretation},
  author={Lam, Suet-Ying and Zeng, Qingcheng and Zhang, Kexun and You, Chenyu and Voigt, Rob},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={9493--9506},
  year={2023}
}

}
@inproceedings{oba-etal-2023-second,
    title = "Second Language Acquisition of Neural Language Models",
    author = "Oba, Miyu  and
      Kuribayashi, Tatsuki  and
      Ouchi, Hiroki  and
      Watanabe, Taro",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.856",
    doi = "10.18653/v1/2023.findings-acl.856",
    pages = "13557--13572",
    abstract = "With the success of neural language models (LMs), their language acquisition has gained much attention. This work sheds light on the second language (L2) acquisition of LMs, while previous work has typically explored their first language (L1) acquisition. Specifically, we trained bilingual LMs with a scenario similar to human L2 acquisition and analyzed their cross-lingual transfer from linguistic perspectives. Our exploratory experiments demonstrated that the L1 pretraining accelerated their linguistic generalization in L2, and language transfer configurations (e.g., the L1 choice, and presence of parallel texts) substantially affected their generalizations. These clarify their (non-)human-like L2 acquisition in particular aspects.",
}
@inproceedings{yadavalli-etal-2023-slabert,
    title = "{SLABERT} Talk Pretty One Day: Modeling Second Language Acquisition with {BERT}",
    author = "Yadavalli, Aditya  and
      Yadavalli, Alekhya  and
      Tobin, Vera",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.657",
    doi = "10.18653/v1/2023.acl-long.657",
    pages = "11763--11777",
    abstract = "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker{'}s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Mutlilingual Age Ordered CHILDES (MAO-CHILDES){---}a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese{---}to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data. Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
}
@inproceedings{settles-etal-2018-second,
    title = "Second Language Acquisition Modeling",
    author = "Settles, Burr  and
      Brust, Chris  and
      Gustafson, Erin  and
      Hagiwara, Masato  and
      Madnani, Nitin",
    editor = "Tetreault, Joel  and
      Burstein, Jill  and
      Kochmar, Ekaterina  and
      Leacock, Claudia  and
      Yannakoudakis, Helen",
    booktitle = "Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W18-0506",
    doi = "10.18653/v1/W18-0506",
    pages = "56--65",
    abstract = "We present the task of \textit{second language acquisition (SLA) modeling}. Given a history of errors made by learners of a second language, the task is to predict errors that they are likely to make at arbitrary points in the future. We describe a large corpus of more than 7M words produced by more than 6k learners of English, Spanish, and French using Duolingo, a popular online language-learning app. Then we report on the results of a shared task challenge aimed studying the SLA task via this corpus, which attracted 15 teams and synthesized work from various fields including cognitive science, linguistics, and machine learning.",
}
@article{ge2024scaling,
  title={Scaling synthetic data creation with 1,000,000,000 personas},
  author={Ge, Tao and Chan, Xin and Wang, Xiaoyang and Yu, Dian and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2406.20094},
  year={2024}
}
@inproceedings{aoyama-schneider-2024-modeling,
    title = "Modeling Nonnative Sentence Processing with {L}2 Language Models",
    author = "Aoyama, Tatsuya  and
      Schneider, Nathan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.283",
    doi = "10.18653/v1/2024.emnlp-main.283",
    pages = "4927--4940",
    abstract = "We study LMs pretrained sequentially on two languages ({``}L2LMs{''}) for modeling nonnative sentence processing. In particular, we pretrain GPT2 on 6 different first languages (L1s), followed by English as the second language (L2). We examine the effect of the choice of pretraining L1 on the model{'}s ability to predict human reading times, evaluating on English readers from a range of L1 backgrounds. Experimental results show that, while all of the LMs{'} word surprisals improve prediction of L2 reading times, especially for human L1s distant from English, there is no reliable effect of the choice of L2LM{'}s L1. We also evaluate the learning trajectory of a monolingual English LM: for predicting L2 as opposed to L1 reading, it peaks much earlier and immediately falls off, possibly mirroring the difference in proficiency between the native and nonnative populations. Lastly, we provide examples of L2LMs{'} surprisals, which could potentially generate hypotheses about human L2 reading.",
}

@article{gao2024cnima,
  title={An Interpretable and Crosslingual Method for Evaluating Second-Language Dialogues},
  author={Gao, Rena and Wu, Jingxuan and Roever, Carsten and Wu, Xuetong and Wu, Jing and Lv, Long and Lau, Jey Han},
  journal={In Proceedings of NAACL 2025, Albuquerque, New Mexico.},
  year={2025}
}
@inproceedings{gao-etal-2025-interaction,
    title = "Interaction Matters: An Evaluation Framework for Interactive Dialogue Assessment on {E}nglish Second Language Conversations",
    author = "Gao, Rena  and
      Roever, Carsten  and
      Lau, Jey Han",
    editor = "Rambow, Owen  and
      Wanner, Leo  and
      Apidianaki, Marianna  and
      Al-Khalifa, Hend  and
      Eugenio, Barbara Di  and
      Schockaert, Steven",
    booktitle = "Proceedings of the 31st International Conference on Computational Linguistics",
    month = jan,
    year = "2025",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.coling-main.729/",
    pages = "10977--11012",
    abstract = "We present an evaluation framework for interactive dialogue assessment in the context of English as a Second Language (ESL) speakers. Our framework collects dialogue-level interactivity labels (e.g., topic management; 4 labels in total) and micro-level span features (e.g., backchannels; 17 features in total). Given our annotated data, we study how the micro-level features influence the (higher level) interactivity quality of ESL dialogues by constructing various machine learning-based models. Our results demonstrate that certain micro-level features strongly correlate with interactivity quality, like reference words (e.g., she, her, he), revealing new insights about the interaction between higher-level dialogue quality and lower-level fundamental linguistic signals. Our framework also provides a means to assess ESL communication, which is useful for language assessment."
}


====================New linguiststics ref=================================
@article{timpe2022using,
  title={Using spoken dialogue technology for L2 speaking practice: What do teachers think?},
  author={Timpe-Laughlin, Veronika and Sydorenko, Tetyana and Daurio, Phoebe},
  journal={Computer Assisted Language Learning},
  volume={35},
  number={5-6},
  pages={1194--1217},
  year={2022},
  publisher={Taylor \& Francis}
}
@article{bibauw2022dialogue2,
  title={Dialogue systems for language learning: A meta-analysis},
  author={Bibauw, Serge and Van den Noortgate, Wim and Fran{\c{c}}ois, Thomas and Desmet, Piet},
  year={2022},
  publisher={University of Hawaii National Foreign Language Resource Center}
}

@incollection{bibauw2022dialogue,
  title={Dialogue systems for language learning: Chatbots and beyond},
  author={Bibauw, Serge and Fran{\c{c}}ois, Thomas and Desmet, Piet},
  booktitle={The Routledge handbook of second language acquisition and technology},
  pages={121--135},
  year={2022},
  publisher={Routledge}
}
@article{felker2021role,
  title={The role of corrective feedback and lexical guidance in perceptual learning of a novel L2 accent in dialogue},
  author={Felker, Emily and Broersma, Mirjam and Ernestus, Mirjam},
  journal={Applied Psycholinguistics},
  volume={42},
  number={4},
  pages={1029--1055},
  year={2021},
  publisher={Cambridge University Press}
}
@article{santiago2023inclusion,
  title={Inclusion of L2 (Basque) learners in Dialogic Literary Gatherings in a linguistically diverse context},
  author={Santiago-Garabieta, Maite and Garc{\'\i}a-Carri{\'o}n, Roc{\'\i}o and Zubiri-Esnaola, Harkaitz and L{\'o}pez de Aguileta, Garazi},
  journal={Language Teaching Research},
  volume={27},
  number={6},
  pages={1532--1551},
  year={2023},
  publisher={Sage Publications Sage UK: London, England}
}
@article{bailey2021digital,
  title={Digital storytelling with chatbots: Mapping L2 participation and perception patterns},
  author={Bailey, Daniel and Southam, Ashleigh and Costley, Jamie},
  journal={Interactive Technology and Smart Education},
  volume={18},
  number={1},
  pages={85--103},
  year={2021},
  publisher={Emerald Publishing Limited}
}
@article{veivo2025dialogue,
  title={Dialogue breakdowns in robot-assisted L2 learning},
  author={Veivo, Outi and Mutta, Maarit},
  journal={Computer Assisted Language Learning},
  volume={38},
  number={1-2},
  pages={30--51},
  year={2025},
  publisher={Taylor \& Francis}
}
@article{govindarajoo2022common,
  title={Common errors made in English writing by Malaysian Chinese primary year 6 ESL learners at a tuition centre in Puchong, Malaysia},
  author={Govindarajoo, Mallika Vasugi and Hui, Chow Chin and Aziz, Siti Farhah A},
  journal={Asian Journal of University Education},
  volume={18},
  number={3},
  pages={674--691},
  year={2022}
}
@article{ramzan2023evacuation,
  title={Evacuation of difficulties and challenges for academic writing in ESL learning},
  author={Ramzan, Muhammad and Mushtaq, Amna and Ashraf, Zahira},
  journal={University of Chitral Journal of Linguistics and Literature},
  volume={7},
  number={I},
  pages={42--49},
  year={2023}
}
@article{chansamrong2014effectiveness,
  title={Effectiveness of cooperative and blended learning to assist Thai ESL students in learning grammar},
  author={Chansamrong, Atchara and Tubsree, Chalong and Kiratibodee, Prateep},
  journal={HRD JOURNAL},
  volume={5},
  number={2},
  pages={105--115},
  year={2014}
}
==========================Literature review new added ref====================================
@article{manoharanmaximizing,
author = {Manoharan, Ashok and Nagar, Gourav},
year = {2021},
month = {12},
pages = {01-10},
title = {Maximizing Learning Trajectories: An Investigation into AI-Driven Natural Language Processing Integration in Online Educational Platforms},
volume = {03},
journal = {International Research Journal of Modernization in Engineering Technology and Science},
doi = {10.56726/IRJMETS18093}
}

@article{mejeh2024taking,
  title={Taking adaptive learning in educational settings to the next level: Leveraging natural language processing for improved personalization},
  author={Mejeh, Mathias and Rehm, Martin},
  journal={Educational technology research and development},
  pages={1--25},
  year={2024},
  publisher={Springer}
}

@article{yigci2024large,
  title={Large Language Model-Based Chatbots in Higher Education},
  author={Yigci, Defne and Eryilmaz, Merve and Yetisen, Ail K and Tasoglu, Savas and Ozcan, Aydogan},
  journal={Advanced Intelligent Systems},
  pages={2400429},
  year={2024},
  publisher={Wiley Online Library}
}
@article{pan2024impoliteness,
  title={Impoliteness in polylogal intercultural communication among Asian EFL learners},
  author={Pan, Zhaoyi},
  journal={Intercultural Pragmatics},
  volume={21},
  number={2},
  pages={227--254},
  year={2024},
  publisher={De Gruyter}
}
@article{chan2010toward,
  title={Toward a taxonomy of written errors: Investigation into the written errors of Hong Kong Cantonese ESL learners},
  author={Chan, Alice YW},
  journal={Tesol Quarterly},
  volume={44},
  number={2},
  pages={295--319},
  year={2010},
  publisher={Wiley Online Library}
}
@article{roever2024relationship,
  title={The relationship between L2 interactional competence and proficiency},
  author={Roever, Carsten and Ikeda, Naoki},
  journal={Applied Linguistics},
  volume={45},
  number={4},
  pages={676--698},
  year={2024},
  publisher={Oxford University Press UK}
}
@inproceedings{mott2024thing,
  title={What a Thing to Say! Which Linguistic Politeness Strategies Should Robots Use in Noncompliance Interactions?},
  author={Mott, Terran and Fanganello, Aaron and Williams, Tom},
  booktitle={Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={501--510},
  year={2024}
}
====================model explaination==============
@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}
@article{sravanthi2024pub,
  title={PUB: A Pragmatics Understanding Benchmark for Assessing LLMs' Pragmatics Capabilities},
  author={Sravanthi, Settaluri Lakshmi and Doshi, Meet and Kalyan, Tankala Pavan and Murthy, Rudra and Bhattacharyya, Pushpak and Dabre, Raj},
  journal={arXiv preprint arXiv:2401.07078},
  year={2024}
}
@article{saleem2021social,
  title={Social distance and speech behavior: A case of Pakistani English speakers’ apology responses},
  author={Saleem, Tahir and Unjum, Uzma and Ahmed, Munawar Iqbal and Qadeer, Ayaz},
  journal={Cogent Arts \& Humanities},
  volume={8},
  number={1},
  pages={1890410},
  year={2021},
  publisher={Taylor \& Francis}
}
@article{macuch2024strategic,
  title={Strategic use of English quantifiers in the reporting of quantitative information},
  author={Macuch Silva, Vinicius and Lorson, Alexandra and Franke, Michael and Cummins, Chris and Winter, Bodo},
  journal={Discourse Processes},
  volume={61},
  number={10},
  pages={498--523},
  year={2024},
  publisher={Taylor \& Francis}
}

@article{Kleinmann1977-vt,
  title     = "{AVOIDANCE} {BEHAVIOR} {IN} {ADULT} {SECOND} {LANGUAGE}
               {ACQUISITION}$^{1}$",
  author    = "Kleinmann, Howard H",
  journal   = "Lang. Learn.",
  publisher = "Wiley",
  volume    =  27,
  number    =  1,
  pages     = "93--107",
  abstract  = "A study was designed to ascertain whether syntactic avoidance
               behavior could be demonstrated for two groups of ESL
               learners—native speakers of Arabic and native speakers of Spanish
               and Portuguese—in accordance with contrastive analysis (CA)
               difficulty predictions. The study also investigated the
               predictability of learners' avoiding the use of various
               structures. Subjects participated in tasks designed to elicit
               passive, present progressive, infinitive complement, and direct
               object pronoun structures. An avoidance pattern was found, in
               accordance with CA difficulty predictions, which could not be
               attributed to differences between the groups' comprehension of
               the target structures. Furthermore, when the frequency of use of
               the target structures was correlated with various affective
               measures, the following pattern emerged: for those structures
               which a particular group avoided, several of the affective
               variables correlated with use in the predicted direction; for
               those structures which a particular group did not avoid, the
               affective variables did not correlate significantly with use. The
               findings suggest that while CA is a fairly good predictor of
               avoidance there is an intersection of linguistic and
               psychological variables in determining learner behavior in a
               second language in that structures which otherwise would be
               avoided are likely to be produced depending on the affective
               state of the learner.",
  month     =  jan,
  year      =  1977,
  language  = "en"
}

@article{Schachter1974-dq,
  title     = "{AN} {ERROR} {IN} {ERROR} {ANALYSIS}$^{1}$",
  author    = "Schachter, Jacquelyn",
  journal   = "Lang. Learn.",
  publisher = "Wiley",
  volume    =  24,
  number    =  2,
  pages     = "205--214",
  abstract  = "Presently, a number of proponents of an error analysis approach
               to the investigation of 2nd language learning argue that
               contrastive analysis (CA) apriori is inadequate as an account of
               target language learning problems. They claim that the only
               tenable version of CA is an aposteriori approach, i.e. CA in just
               those areas that have been proven by error analysis to be
               difficulties in production. This claim is disputed in a study
               involving the acquisition of English relative clauses by speakers
               of Persian, Arabic, Chinese, and Japanese. The aposteriori
               approach obscured the fact that the Chinese and Japanese learners
               have more difficulty with relative clauses and therefore avoid
               them, a fact predicted by the apriori approach.",
  month     =  dec,
  year      =  1974,
  language  = "en"
}

@misc{levenston1971over,
  title={Over-indulgence and under-representation: Aspects of mother-tongue interference},
  author={Levenston, Edwards},
  year={1971},
  publisher={Papers in contrastive linguistics/Cambridge University Press}
}