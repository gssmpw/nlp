Our goal is to measure the spiral of silence across topics and communities. We first need a set of controversial topics that may trigger the spiral of silence. This analysis requires us to identify topics that community members agree are permissible to discuss in their community in principle, but may not feel comfortable sharing in practice. Mining existing posts is insufficient because this data will not capture the opinions that users may be hesitant to share. In other words, starting with existing topics runs the risk of only identifying topics that are so safe as to appear commonly in the community. 

Instead, we use large language models (LLMs) to nominate potential controversial topics that are relevant to each community, even if those topics are not posted in the community, then validate those proposed topics with active subreddit members. We then survey community members to capture the rate of self-silencing on those topics. 

In this section, we start by discussing the scope of our study and our definition of self-silencing. Then, we provide an overview of our method, describing the topic generation process and survey instrument.

\subsubsection{Scope of the Study} One important distinction we make in this work is between when community members self-silence because they are uncomfortable sharing an opinion versus when an opinion is not considered acceptable to be shared within a community. Our study is constrained only to the former. In other words, we focus only on perspectives that lead to disagreement while still falling within the bounds of the community norms. We do not seek to make any normative claims about what should or should not be shared to a subreddit. Instead, we are interested in what is not being shared even when most community members agree the opinion \emph{should} be allowed to be discussed. 


\subsection{Topic Generation}
\label{sub:topic-generation}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.95\textwidth]{Figures/SoS_Method.pdf}
    \caption{We generate controversial viewpoints specific to a provided community. Using the community name, description, and rules, we prompt an LLM to propose controversial topics. For each topic, we enumerate statements representing different stances on the topic. Finally, the generated topics and viewpoints are validated by community members to ensure they are relevant and fall within the norms of what is accepted in the community. }
    \label{fig:generation_method}
\end{figure*}

Our methodological approach involves using an LLM to propose controversial topics and opposing viewpoints for each topic, then surveying actual community members to select viewpoints for our study. While manually selecting topics is the de facto approach when studying the spiral of silence across more than one issue type~\cite{gearhart2018same,lee2004cross}, manual selection is challenging to perform across many communities on Reddit as each community has its own rules and norms~\cite{fiesler2018reddit}. Deciding what topics are controversial will be imprecise for those without specific knowledge of the community~\cite{hessel2019something,chen2013and}. Directly looking at Reddit data is not adequate in this scenario either, as we are interested in the opinions that are unlikely to be shared to the community, rather than those that are already present. In addition to providing a scalable option, LLM-based methods can be used to identify topics that are relevant to the community and might result in self-silencing. However, we cannot assume that all the topics LLMs suggest might be relevant, so we develop a human-plus-AI pipeline that uses an LLM to suggest topics and then has active community members validate the relevancy of these proposals.

Topic generation is a three-step process (see Fig.~\ref{fig:generation_method}). We provide a community name, description, and rules as input to an LLM (\texttt{GPT-4}) to propose 20 potentially controversial topics for the provided community. ``Controversial'' is defined as being likely to cause disagreement between community members. Then, for each proposed topic, the LLM generates viewpoints representing different sides of the issue using few-shot prompting techniques. The viewpoints must follow the rules of the subreddit, which are again provided to the model. Finally, the viewpoints are manually validated by active community members. 

\subsubsection{Proposing Controversial Political Topics and Viewpoints}
\label{subsec:sublist}
First, we must select which subreddits to provide as input to the LLM. We focus on subreddits that focus on political and social issues, since \citet{noelle1974spiral} posits that morally laden subjects typically trigger the spiral of silence. To identify these communities, we start with the 2,040 subreddits on \texttt{r/ListOfSubreddits} and sample the 50 hottest submissions in each. We then filter for the following criteria: (1)~the majority of submissions are in English as classified by \texttt{langdetect}~\cite{nakatani2010langdetect}; (2)~$\geq80\%$ of submissions are classified to contain political content; and (3)~the subreddit has over 100K members. Filtering leaves us with 23 political subreddits.

Since we seek to compare variation in opinion expression on topics based on community-level differences, we want to identify a single, static set of topics that are relevant across all 23 subreddits. We select \texttt{r/politics} and \texttt{r/worldnews} as the communities to input to the LLM based on their size and high proportion of political content. Using our pipeline, we generate 40 topics (i.e., 20 per subreddit) with opposing viewpoints for each topic.

\subsubsection{Validating Generated Topics and Viewpoints}
\label{sec:valid_generate}
Next, we validate the generated topics and viewpoints. Starting with the 40 topics from the prior step, we check the generated outputs for comprehension. Four had incomplete viewpoints (i.e., \texttt{GPT-4} only provided viewpoints representing one side) and three were either worded in a confusing manner or presented viewpoints that did not present opposite stances, leaving us with 33 topics. 

We further validated the remaining topics by working with Prolific participants who self-reported as active members of \texttt{r/politics} or \texttt{r/worldnews}. First, participants completed a screening quiz to confirm their knowledge about the subreddits. In the quiz, participants selected which post titles were likely to appear in their selected subreddit from a set of three titles---two from their selected subreddit and one from another political subreddit (see Appendix~\ref{sec:app_kq} for examples). If they identified all the correct post titles, participants qualified for the survey. Participants were asked whether a given topic is relevant to the subreddit.

Ultimately, from the 33 topics, we randomly selected 11 for our final study to ensure there are an adequate number of responses per topic for our analysis. These topics covered a range of political and social issues, including abortion rights, military spending, and affirmative action. Each identified \textit{topic} contains two \textit{viewpoints} that articulate two main clusters of opinion on the topic: for example, with affirmative action, one viewpoint states, ``I believe affirmative action counters systemic
biases and fosters a diverse, inclusive society,'' and the other viewpoint states, ``I believe affirmative action could unintentionally
cause reverse discrimination and undermine merit,
potentially increasing societal division.'' For the full list of topics and viewpoints, refer to Appendix Table~\ref{tab:viewpoint_list}. 




\subsection{Opinion Expression Survey}
Next, we use the generated viewpoints to gauge the rate of self-silencing among active community members. Since these self-silenced viewpoints will not be posted on Reddit, we directly survey community members to measure this phenomenon. The goal of our survey is to identify how willing an individual is to share their opinion on a topic to a subreddit. Specifically, we are interested in the following dimensions: (1) differences in sharing behavior when individuals view themselves as being in the majority versus minority; and (2) how self-silencing differs across subreddits.


\subsubsection{Survey Instrument}
For each topic, our survey captures the likelihood that participants would share their viewpoint on each subreddit. After selecting subreddits and passing the screening quiz for those subreddits, participants chose up to five topics they thought were relevant to each subreddit. For each topic, they indicated the viewpoint they agreed with. Importantly, this process allowed us to validate that the generated topics are germane to the subreddit. For example, for \texttt{r/combatfootage}, selected topics included ``ethics of drone warfare in the Middle East,'' ``military spending,'' and ``the role of NATO in maintaining global peace.'' In \texttt{r/askfeminists}, the only relevant topic was ``abortion rights.''

After selecting their preferred viewpoint, participants rated the extent to which they agreed with the viewpoint, how much they believed the majority of subreddit members agreed with the viewpoint, and whether they thought the viewpoint should be allowed to be posted on the subreddit. For all viewpoints the participant agreed with and thought should be allowed on the subreddit, we asked about their likelihood of sharing that viewpoint on the subreddit and their likelihood of upvoting that viewpoint if someone else shares it on the subreddit. The order in which the topics were presented for each subreddit was randomized.

\subsubsection{Participants} 
Survey participants were recruited via Prolific. To qualify, participants were required to live in the United States, be at least 18 years old, and identify as an active member of at least one political subreddit included in our list. This list contains \texttt{r/politics} and \texttt{r/worldnews} as well as the 21 additional political subreddits from Section~\ref{subsec:sublist}. We include these additional subreddits to obtain a larger pool of participants.

Participants selected up to three subreddits they were an active member of from the list of 23 subreddits used in the pre-screener. Participants could, if desired, provide up to one additional political subreddit not included in our list. We verify participants are active members of the subreddit using the same knowledge quiz on identifying relevant post titles from the topic generation process. A total of 489 participants completed the pre-screener; 337 self-reported as members of a listed subreddit; and 290 passed the knowledge quiz.

Based on an a priori power analysis, we needed to collect 624 responses (participants $\times$ topics $\times$ subreddit), or in other words, approximately 124 participants to achieve $90\%$ power if $\alpha=0.05$ and a change in $R^2 > 0.02$ were assumed to be the minimum effect size of interest. We collected 906 responses from 125 participants. Since we focus on political topics, we recruited a balanced sample of participants by political leaning. We asked for participant's political leaning in our screening quiz and stratified recruitment, resulting in 40 Democrats, 38 Republicans, 40 Independents, and 7 participants with other political ideologies. For quality assurance, we removed 46 responses from 10 participants who failed our attention checks. We also removed individual responses if: (1)~the participant felt the viewpoint should \emph{not} be shared on the subreddit (N=74); (2)~the participant selected ``don't know'' when asked to pick a viewpoint for a topic (N=122); (3)~the participant later disagreed with the viewpoint they selected as representing their stance (N=31); (4)~the participant selected a subreddit that we later did not have adequate data to analyze (N=6). After filtering, we used the remaining \textbf{627 responses} (i.e., likelihood of sharing a viewpoint for a specific subreddit) covering 33 subreddits for our analysis, meeting our original power analysis requirements.


\subsection{Measures}
We detail the measures used in our study. Our dependent variable is the likelihood of opinion expression. We introduce four independent variables: opinion incongruence, community inclusion, community diversity, and content removal rate. Finally, we include controls for individual-level factors that can influence opinion expression.

\subsubsection{Likelihood of Opinion Expression}
Our main dependent variable is a participant's likelihood of opinion expression. Participants are asked to imagine they see a post on their selected subreddit related to the controversial topic. Then we ask their likelihood of sharing the viewpoint, or \textit{Share Likelihood}, from their main account on a scale from 1 to 7. We also ask participants to provide the likelihood of upvoting the viewpoint (\textit{Upvote Likelihood}) on a seven-point scale. 
\subsubsection{Opinion Incongruency}
For a given viewpoint, \textit{Incongruency} is a binary variable indicating whether a participant believes their opinion is held by the majority~(0) or minority~(1) of other subreddit members. Following prior work~\cite{neuwirth2007spiral,chia2014authoritarian}, we operationalize incongruency as the difference between how much a participant agrees with a viewpoint and how much they believe the majority of subreddit members agree. Both agreement scores are measured on a 7-point scale. When converting the difference into a binary variable, we indicate all instances when the participant agrees with the viewpoint and they believe the majority of subreddit members also agree as 0. Conversely, if the participant agrees with the viewpoint but believes the majority of subreddit members are neutral or disagree, incongruency is marked as 1. 

\subsubsection{Community Inclusion and Diversity}
We collect self-perceived community inclusivity and diversity from participants using~\citet{weld2022makes}'s instrument for measuring community values across subreddits. For a given subreddit, participants report their perception of the current state of \textit{Inclusion} (i.e., ``How included and able to contribute do new and existing members feel?'') and \textit{Diversity} (i.e., ``How diverse are the people?''). The response was recorded on an 11-point scale (from 1-11) for consistency with prior work~\cite{weld2022makes}. 

\subsubsection{Community Moderation}
We use content removal as our main measure of community moderation. Using Pushshift data from Jan. 2022 - Dec. 2023, we compute \textit{Content Removal Rate} as the percentage of submissions removed by moderators within a subreddit~\cite{jhaver2019does}. In total, there were 1.74 million submissions across 33 subreddits. The removal rate ranged from $4.1\%$ (\texttt{r/austrianeconomics}) to $46.0\%$ (\texttt{r/againsthatesubreddits}), with a median of $26.3\%$ percent per subreddit. We apply a logarithmic transformation with base 2 after adding a start-value of 1 to the computed values.

 

\subsubsection{Controls}
In addition to binary variables for demographics (gender, race, and political leaning), we include the following controls for personality and Reddit usage:

\begin{itemize}
[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex,leftmargin=5pt]
    \item \emph{Willingness to self-censor (WTSC)}: Individual personality differences can impact the likelihood of sharing~\cite{gearhart2014gay}. We use \citet{hayes2005willingness} well-validated composite measure, consisting of eight questions capturing an individual's likelihood of withholding their opinion when they sense others disagree. A larger \textit{WTSC} value means the individual is more disposed to self-censoring.
    \item \emph{Agreement Intensity}: How strongly an individual agrees with a viewpoint impacts the chance that the spiral of silence occurs~\cite{matthes2010spiral}. We measure agreement on a 7-point scale from ``strongly disagree'' to ``agree.'' Since we only consider viewpoints that participants agree with, we report intensity on a 3-point scale from ``somewhat agree'' to ``strongly agree.''
    \item \emph{Posting}: To control for different base rates of posting frequency~\cite{gong2015characterizing}, we include a measure, \textit{Posting}, which captures a participant's self-reported likelihood of posting (over lurking) on a 5-point scale.
    \item \emph{Account Tenure}: Since newcomers may exhibit different sharing behavior compared to platform veterans~\cite{yang2017commitment}, we include a control capturing the age of the participant's Reddit account in years. 
\end{itemize}

