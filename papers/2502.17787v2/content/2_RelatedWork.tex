
\section{Related Work}

\subsection{Instruction Generation}

Instruction tuning is essential for aligning Large Language Models (LLMs) with user intentions~\cite{ouyang2022training,cao2023instruction}. Initially, this involved collecting and cleaning existing data, such as open-source NLP datasets~\cite{wang2023far,ding2023enhancing}. With the importance of instruction quality recognized, manual annotation methods emerged~\cite{wang2023far,zhou2024lima}. As larger datasets became necessary, approaches like Self-Instruct~\cite{wang2022self} used models to generate high-quality instructions~\cite{guo2024human}. However, complex instructions are rare, leading to strategies for synthesizing them by extending simpler ones~\cite{xu2023wizardlm,sun2024conifer,he2024can}. However, existing methods struggle with scalability and diversity.


\subsection{Back Translation}

Back-translation, a process of translating text from the target language back into the source language, is mainly used for data augmentation in tasks like machine translation~\cite{sennrich2015improving, hoang2018iterative}. ~\citet{li2023self} first applied this to large-scale instruction generation using unlabeled data, with Suri~\cite{pham2024suri} and Kun~\cite{zheng2024kun} extending it to long-form and Chinese instructions, respectively. ~\citet{nguyen2024better} enhanced this method by adding quality assessment to filter and revise data. Building on this, we further investigated methods to generate high-quality complex instruction dataset using back-translation.

