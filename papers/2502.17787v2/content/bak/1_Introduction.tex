\section{Introduction}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{source/intro.pdf}
    \caption{Illustration of how humans iteratively refine instructions to be more complex.}
    \label{fig: intro}
    \vspace{-1mm}
\end{figure}

Recent advancements in Large Language Models (LLMs) have shown impressive performance across a wide range of tasks~\cite{zhao2023survey, li2024graphreader}. Inspired by vast amounts of data and efficient training, most current LLMs are capable of effectively following user instructions and aligning to a certain extent with human preferences~\cite{ouyang2022training,li20242d}.
However, despite these successes, they still face significant challenges when it comes to following complex instructions~\cite{jiang2023followbench,wen2024benchmarking}.

Existing complex instructions datasets are primarily derived from two sources: (1) curated data from open-source datasets or human annotations~\cite{zhou2024lima,zhang2024cfbench,he2024can}, which are resource-intensive and \textbf{lack scalability}, and (2) the transformation of simple instructions into complex ones using LLMs, such as WizardLM~\cite{xu2023wizardlm} and Conifer~\cite{sun2024conifer}. 
While these methods enhance scalability, the generated constraints tend to be shaped by the model’s inherent biases or the limited diversity of its few-shot examples, resulting in \textbf{limited diversity} in the produced instructions.
Furthermore, these constraints may not align with user instructions, as the model might produce overly rigid or irrelevant constraints, and fail to follow specific instructions, leading to unnatural and impractical outcomes.

Recently,
back-translation, which involves translating text from the target language back into the source language, 
has been proposed to generate scalable and diverse instructions by leveraging the large web corpus~\cite{sennrich2015improving,hoang2018iterative,zheng2024kun,li2023self}. 
% Some studies have explored how back-translation can be leveraged to better generate instructions for fine-tuning large models~\cite{li2023self,zheng2024kun,nguyen2024better}. 
However, these methods typically focus on generating \textbf{simple instruction} and have not fully explored the rich knowledge contained in the web corpus.

To address the scalability and diversity of producing complex instructions,
in this paper, we propose an \textbf{Automatic Iterative Refinement (AIR)} framework for generating high-quality complex instructions through back-translation.
Specifically,
our approach is based on two key observations: (1) existing web resources contain many valuable knowledge and human preferences that can convert to specific constraints, such as formatting conventions in legal documents, and (2) inspired by human behavior, individuals often refine complex instructions iteratively based on feedback from model outputs. As illustrated in Figure~\ref{fig: intro}, simple instructions are progressively adjusted and enriched to better align with specific user requirements, which plays a critical role in crafting more precise and effective complex instructions.

Thus, our AIR framework uses document-based knowledge and the LLM as a judge to assess and iteratively improve instructions. 
Specifically, the framework consists of two key stages: (1) Initial Instruction Generation, in which the model generates initial instructions based on the document, and (2) Iterative Instruction Refinement, in which instructions are iteratively refined with LLM-as-judge guidance by comparing the model's output with the document to identify and incorporate valuable constraints. This iterative process allows the framework to generate more challenging instructions that align more closely with real-world scenarios. In summary, the contributions are as follows: 

\begin{itemize}[leftmargin=4mm]
    \item  To better align with real-world complex instruction, we propose the \textbf{AIR} framework, which iteratively refines complex instructions with LLM-as-judge guidance by comparing the model’s output with the document.

    \item We present a 10K instruction dataset (AIR-10K) generated using our framework. Experimental results demonstrate that our fine-tuned model significantly outperforms existing models on complex instruction benchmarks.

    \item We provide a comprehensive experimental analysis to evaluate the individual components of our framework, validating the contribution of each stage to the overall improvement in model performance on complex instructions.
\end{itemize}