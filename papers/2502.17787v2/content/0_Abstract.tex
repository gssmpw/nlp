\begin{abstract}
With the development of large language models, their ability to follow simple instructions has significantly improved. However, adhering to complex instructions remains a major challenge. Current approaches to generating complex instructions are often irrelevant to the current instruction requirements or suffer from limited scalability and diversity. Moreover, methods such as back-translation, while effective for simple instruction generation, fail to leverage the rich knowledge and formatting in human written documents.
In this paper, we propose a novel \textbf{A}utomatic \textbf{I}terative \textbf{R}efinement  (\textbf{AIR}) framework to generate complex instructions with constraints,
which not only better reflects the requirements of real scenarios but also significantly enhances LLMs' ability to follow complex instructions.
The AIR framework consists of two stages: 1) Generate an initial instruction from a document; 2) Iteratively refine instructions with LLM-as-judge guidance by comparing the model's output with the document to incorporate valuable constraints.
% These ensure that the instructions are both more challenging and realistic.
Finally, we construct the AIR-10K dataset with 10K complex instructions and demonstrate that instructions generated with our approach significantly improve the modelâ€™s ability to follow complex instructions, outperforming existing methods for instruction generation\textsuperscript{1}.
%\footnote{Codes and data are anonymously available at \url{https://github.com/WeiLiuAH/AIR-Automatic-Iterative-Refinement}.}

\end{abstract}