\section{Conclusion}
This paper introduces the Automatic Iterative Refinement (AIR) framework, a novel approach for generating complex instructions that better align with real-world scenarios. The framework employs an iterative refinement process guided by LLM-as-judge to generate high-quality complex constraints. We also construct a complex instruction dataset, AIR-10K, to facilitate the research and application of complex instruction following.

While previous methods for complex instruction following often introduce constraints without clear justification, it is crucial to understand what authentic complex instruction entails. In the future, we will conduct further research on the effectiveness and efficiency of complex instruction data.

% Furthermore, our ablation studies demonstrate the framework's robustness across different guidance model sizes and data quantities, making it practically applicable in various resource settings. Looking forward, we identify two key directions for future research. First, we aim to develop automated methods for determining optimal iteration counts to enhance the framework's effectiveness and efficiency. Second, we plan to expand the framework to incorporate diverse document sources, such as mathematical proofs and programming repositories, enabling the generation of more specialized and domain-specific instructions. 


\section*{Limitations}

Our work has several limitations. 1) Although our evaluation includes multiple established benchmarks and metrics, including human evaluation could further improve its credibility. Due to time and resource limitation, we have to leave this as future work. 2) Despite meticulous preprocessing, the Dolma dataset remains relatively noisy. Incorporating more high-quality documents (for example, judicial documents made public) could provide more knowledge and formality to support constraint construction. 3) The iterative nature of our framework requires multiple rounds of model inference, resulting in higher computational demands. While our ablation studies demonstrate effectiveness even with smaller guidance models and fewer samples, the computational cost remains a challenge for researchers with limited resources.

\section*{Ethical Considerations}
Our data construction framework primarily leverages proprietary models such as Llama-3-70B-Instruct, which have undergone extensive preference optimization to minimize the likelihood of generating instructions that raise ethical concerns. However, large-scale web corpora—our primary data sources—are uncensored and may contain harmful or toxic content. To address this, we recommend implementing more rigorous and meticulous filtering mechanisms to proactively identify and remove such instances if possible.

While the AIR framework mainly aims to enhance models' ability to follow complex instructions, it is important to note that some user constraints may conflict with system constraints set by developers. For example, users may request the generation of harmful or toxic content. Although our study does not specifically investigate conflicting constraints, there is a potential risk that the pipeline could prioritize user requests over developer-defined safeguards.