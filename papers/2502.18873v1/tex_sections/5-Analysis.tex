

\input{tables/exp-with_rstar}
% \input{tables/exp-ablation}



\section{Analysis}
\label{sec:exp:analysis}

We perform a comprehensive analysis on \mosa{} in this section. 
% with controlled experiments.
Specifically, we scale the diversity of the single-LLM search baseline in $\S$~\ref{sec:analysis:diversity} and compare it with \mosa{}.
% and show that there is a trade-off between diversity and performance. Besides, even with near-optimal sampling parameters, the single-LLM baseline still underperforms \mosa{}.
In $\S$~\ref{sec:analysis:number_of_agents}, we vary the number of distinct LLMs in \mosa{}.
In $\S$~\ref{sec:analysis:action_set}, we combine \mosa{} with the rich set of actions proposed by \citet{qi2024mutual}.
Finally, we evaluate variations of \mosa{} by ablating the numbers of proposers and aggregators in $\S$~\ref{sec:analysis:number_of_pro_agg}.




\subsection{Diversity \textit{versus} Performance}

\label{sec:analysis:diversity}

% A common technique to boost diversity is to scale up sampling temperature.
For single-LLM search, a common technique to increase generation diversity is to manipulate with decoding hyper-parameters, e.g., the sampling temperature. 
We modify the temperature of the RAP + Single-LLM as Aggregator baseline on two datasets, with $T=\{0.25, 0.5, 0.75, 1.0, 1.25\}$. 
Diversity is assessed by calculating the $\{1,2,3,4\}$-gram Vendi Score~\cite{friedman2023vendi} across search trajectories.
Figure~\ref{fig:diveristy_vs_acc} illustrates that while the reasoning accuracy of RAP initially improves with increasing diversity, it subsequently declines. 
More importantly, the two benchmarks favor different temperature values.
This suggests that attaining an optimal balance between diversity and reasoning performance requires careful tuning, as balancing diversity and quality can be challenging~\cite{tradeoff}.
In contrast, RAP + \mosa{} with the default sampling parameters consistently holds an advantageous position.


%\paragraph{Effects of LLM Diversity}
%To evaluate the impact of varying the number of distinct LLMs in \mosa{}, we conducted an analysis using 1 to 4 LLMs across four benchmarks.
%It is important to note that all four variants utilized approximately the same number of LLM forward calls.
%As illustrated in Figure~\ref{fig:num_of_agents}, we observed that an increase in the number of distinct LLMs generally correlates with higher reasoning accuracy, with the the only decrease as the number of LLMs changes from 3 to 4 on MATH.
%This trend indicates that the diverse expertise contributed by different LLMs significantly enhances search-based reasoning performance.



%\paragraph{Effects of LLM Diversity}
%To evaluate the impact of varying the number of different LLMs in \mosa{}, we conduct an analysis using 1 to 4 LLMs across four benchmarks. 
%It is important to note that all four variants utilize approximately the same number of LLM forward calls, ensuring the only ablation is the number of distinct LLMs involved.
%As illustrated in Figure~\ref{fig:num_of_agents}, we observed that an increase in the number of different LLMs tends to correlate with higher reasoning accuracy, with the only decrease occurring when the number of LLMs changes from 3 to 4 on the MATH benchmark. 
%This trend indicates that the diverse expertise contributed by different LLMs significantly enhances search-based reasoning performance.


\subsection{Ablation of LLM Collaboration}
\label{sec:analysis:number_of_agents}

To evaluate the impact of varying the number of different LLMs in \mosa{}, we conduct an analysis using 1 to 4 LLMs across four benchmarks, prioritizing them in the following order: Llama, GLM, Qwen, Ministral.
All four variants utilize approximately the same number of LLM forward calls, ensuring that the only variable is the number of distinct LLMs involved. 
Figure~\ref{fig:num_of_agents} shows that increasing the number of different LLMs generally correlates with higher reasoning accuracy, except for a slight decrease in performance when the number of LLMs increases from 3 to 4 on MATH-500. 
This trend indicates that the diverse expertise contributed by different LLMs significantly enhances search-based reasoning performance.





% \paragraph{Mixture-of-Agents (MoA) is a specific case of MoSA}




% \paragraph{\mosa{} is compatible with other SoTA methods}
% rStar~\cite{qi2024mutual} is one of the recent state-of-the-art (SoTA) MCTS methods. It proposes using a comprehensive set of actions, $A = \{A1, A2, A3, A4, A5\}$, consisting of:

% \begin{itemize}
%     \item $A1$: Propose a one-step thought;
%     \item $A2$: Propose the remaining thought steps;
%     \item $A3$: Propose the next sub-question along with its answer;
%     \item $A4$: Answer the sub-question again;
%     \item $A5$: Rephrase the question.
% \end{itemize}


%\paragraph{Support for Different Action Sets}
%% \mosa{} is compatible with different choices of action sets.
%rStar~\cite{qi2024mutual} proposes using a comprehensive set of actions in MCTS-based LLM reasoning.
%Since to enrich the action set is orthogonal to \ourmethod{}, we hypothesize that \mosa{} is compatible with different choices of action sets.
%The results in Table~\ref{tab:with_rstar} verified our hypothesis.
%For example, rStar + \ourmethod{} boosts the reasoning accuracy on MATH from 59.00\% to 63.20\% (\emph{w/o} aggregators) and 63.60\% (\emph{w/} aggregators).
%We also find out that enriching the action set is not always beneficial.
%On StrategyQA, the enlarged action set yielded inferior performances; but we note that \ourmethod{} still demonstrates improvements.

\subsection{Support for Extended Action Set}
\label{sec:analysis:action_set}

rStar~\cite{qi2024mutual} proposes using a comprehensive set of actions in MCTS-based LLM reasoning. 
Since enriching the action set is orthogonal to our method, we hypothesize that \mosa{} is compatible with the enlarged action set. 
The results in Table~\ref{tab:with_rstar} support our hypothesis. 
For example, rStar combined with \ourmethod{} boosts the reasoning accuracy on MATH-500 from 59.00\% to 63.20\% (+ \mosa{} as Proposers) and 63.60\% (+ \mosa{} as Proposers \& Aggregators). 
We also found that enriching the action set is not always beneficial. 
On StrategyQA, the expanded action set yielded inferior performance; however, we note that \mosa{} still demonstrates improvements.





\begin{figure}[t]
\vskip 0.2in
\begin{center}

\includegraphics[width=0.84\columnwidth]{figures/diversity_vs_accuracy_MATH.pdf}

\includegraphics[width=0.84\columnwidth]{figures/diversity_vs_accuracy_SVAMP.pdf}

\caption{
Diversity \emph{versus} accuracy. \textit{T} = Temperature.
% \revise{modify terminology to be consistent with methodology.}
}
\label{fig:diveristy_vs_acc}
\end{center}
\vskip -0.3in
\end{figure}



\input{tables/exp-ablation}






\subsection{Ablation of Proposers \& Aggregators}
\label{sec:analysis:number_of_pro_agg}

% % \paragraph{Variations of \mosa{}}
% We consider the following variations to test the effectiveness of \mosa{} as Proposers and \mosa{} as Aggregators, respectively:
% \begin{itemize}
%     \item RAP (\emph{w/o} aggregators) is the baseline method introduced in $\S$~\ref{sec:method:background}. As shown in Figure~\ref{fig:baseline}, it adopts a single search agent (Llama-3.1-8B-Instruct in our case) as the proposer. 
    
%     \item RAP (\emph{w/} aggregators) can be seen as adding an aggregator component over the baseline method shown in Figure~\ref{fig:baseline}. It adopts a single LLM agent (Llama-3.1-8B-Instruct in our case) as both the proposer and the aggregator. 

%     \item \ourmethod{} (\emph{w/o} aggregators) replaces the single search agent in the baseline RAP method with \mosa{}. It can be seen as the simplest form of \ourmethod{}, as no aggregator is involved.

%     \item \ourmethod{} (\emph{single} aggregator) additionally adopts a single LLM agent (Llama-3.1-8B-Instruct in our case) as the aggregator comparing with \ourmethod{} (\emph{w/o} aggregators).


%     \item \ourmethod{} (\emph{single} proposer) adopts a single LLM agent (Llama-3.1-8B-Instruct in our case) as the proposer and \mosa{} as the aggregators.
    
%     \item \ourmethod{} is the finalized version. It adopts multiple search agents as both proposers and aggregators in each search step.
% \end{itemize}

We consider to isolate the effects of \mosa{} as Proposers and \mosa{} as Aggregators by ablating the number of distinct LLMs for those two roles.
As shown in Table~\ref{tab:ablation}, changing the number of distinct proposers to be single yields a larger decrease comparing with ablating the number of aggregators (-1.23\% \emph{versus} -0.47\%), suggesting that \mosa{} brings more benefits as proposers.
