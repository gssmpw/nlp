



%\section{Related Work}
%The recent trend surrounding large language models stems partly from their outstanding performance in solving complex reasoning tasks.
%The most representative work is Chain-of-Thought (CoT,~\cite{wei2023chainofthoughtpromptingelicitsreasoning}).
%Recent advances include self-consistency~\cite{wang2023selfconsistency}, problem decomposition~\cite{zhou2023leasttomost}, using tools~\cite{pal,chen2023program}, search~\cite{hao-etal-2023-reasoning,yao2024tree,qi2024mutual}, etc.
%Among them, \mosa{} is mostly related to the line of search-based reasoning methods.
%
%\paragraph{Search-based Reasoning}
%As reasoning problems often involve multiple thought steps, search-based reasoning has been shown to be effective, especially for complicated problems~\cite{hao-etal-2023-reasoning,yao2024tree,chen2024understandingtreethoughtssucceeds,zhang2024accessinggpt4levelmathematical,chen2024alphamathzeroprocesssupervision,qi2024mutual}.
%Among them, rStar~\cite{qi2024mutual} is one of the recent SoTA search-based LLM reasoning systems.
%It mainly involves two innovations: (1) It enriches the action space of MCTS-reasoning, from typically one or two types of actions to five types of actions; (2) It employs a second LLM to verify the reasoning trajectories generated by the first LLM through MCTS.
%In $\S$~\ref{sec:analysis:action_set}, we empirically show that our method is orthogonal to the enriched action set of rStar.
%
%
%\subsection{LLM Ensemble}
%Ensemble is a popular way to collect the strengths of multiple models and remains effective in the era of LLMs.
%\citet{jiang-etal-2023-llm} proposed to pairwisely rerank the outputs of LLMs and to fuse multiple responses with a trained generative model.
%A few studies proposed to train a routing function to pair a query with an LLM~\cite{lu2023routingexpertefficientrewardguided,shnitzer2023largelanguagemodelrouting,wang2024fusing}.
%Some others proposed to average the output distributions of multiple LLMs~\cite{huang2024ensemblelearningheterogeneouslarge}.
%% Several studies focused on merging the weights of multiple LLMs~\cite{wan2024knowledge}
%
%Another line of work focused on multi-agent collaboration, where multiple LLMs interact with each other to discuss or debate over a specific topic~\cite{du2023improvingfactualityreasoninglanguage,liang-etal-2024-encouraging,chan2023chatevalbetterllmbasedevaluators,xu2023reasoninglargelanguagemodels,liu2024a,he-etal-2023-lego,chen-etal-2024-reconcile,zhang-etal-2024-exploring}.
%Among them, common design variations include the agentic roles for LLMs (e.g.,  debaters and judges) and the mechanisms of discussions (e.g., symmetric \emph{versus} asymmetric).


\section{Related Work}

\subsection{Reasoning with LLMs}
The recent focus on large language models is partly due to their exceptional performance in solving complex reasoning tasks.
A prominent example is Chain-of-Thought (CoT) reasoning~\cite{wei2023chainofthoughtpromptingelicitsreasoning}.
Recent advancements include self-consistency~\cite{wang2023selfconsistency}, problem decomposition~\cite{zhou2023leasttomost}, the use of tools~\cite{pal,chen2023program}, and search-based methods~\cite{hao-etal-2023-reasoning,yao2024tree,qi2024mutual}. 
Among these approaches, \mosa{} is most closely aligned with search-based reasoning methods.

\textbf{Search-based Reasoning}
\hspace{5pt}
Search-based reasoning has demonstrated effectiveness, particularly for solving complex, multi-step problems~\cite{hao-etal-2023-reasoning,yao2024tree,chen2024understandingtreethoughtssucceeds,zhang2024accessinggpt4levelmathematical,chen2024alphamathzeroprocesssupervision,qi2024mutual,zhang2024restmctsllmselftrainingprocess,zhou2023language,koh2024treesearchlanguagemodel}. 
One of the recent state-of-the-art systems in this domain is rStar~\cite{qi2024mutual}. 
rStar introduces two key innovations: (1) expanding the Monte Carlo Tree Search (MCTS) action space from one or two actions to five; and (2) employing a secondary LLM to verify the reasoning trajectories generated by the primary LLM through MCTS.
In $\S$~\ref{sec:analysis:action_set}, we empirically demonstrate that our method is complementary to the enriched action set of rStar.





\input{figures/num_of_agents}






\subsection{LLM Ensemble}
Ensembling, a widely used technique for leveraging the strengths of multiple models, remains highly effective in the era of LLMs.
\citet{jiang-etal-2023-llm} proposed pairwise reranking of LLM outputs and fusing multiple responses using a trained generative model. 
Several studies have proposed training routing functions to match queries with appropriate LLMs~\cite{lu2023routingexpertefficientrewardguided,shnitzer2023largelanguagemodelrouting,wang2024fusing}. 
Others have proposed averaging the output distributions of multiple LLMs~\cite{huang2024ensemblelearningheterogeneouslarge}.

Another line of research focuses on multi-agent collaboration, where multiple LLMs interact to discuss or debate specific topics~\cite{du2023improvingfactualityreasoninglanguage,liang-etal-2024-encouraging,chan2023chatevalbetterllmbasedevaluators,xu2023reasoninglargelanguagemodels,liu2024a,he-etal-2023-lego,chen-etal-2024-reconcile,zhang-etal-2024-exploring}. 
Common design variations in this paradigm include role assignments for LLMs (e.g., debaters and judges) and discussion mechanisms (e.g., symmetric versus asymmetric interactions).


% A recent study, Mixture-of-Agents (MoA) by~\citet{moa}, also adopted multiple different LLM agents.
% These agents prompt LLMs to directly generate the final answer for instruction-following tasks, such as AlpacaEval~\cite{}.
% While it is debatable whether using "direct CoT" as the only available action qualifies as search-based reasoning, it can still be considered a specific case of \textsc{MoSA} upon limiting the action space to direct CoT.
% though it (1) focused on instruction following tasks (i.e., AlpacaEval~\cite{}, Arena-Hard~\cite{}, MT-Bench~\cite{}, and FLASK~\cite{}) and (2) 
% The differences are: (1) MoA has little to do with search.








