\section{Conclusions}
\label{sec:concl}
We present \textbf{Controllable Surgical Simulation via Scene Graph to Image Diffusion (SurGrID)}, the first controllable surgical simulator based on Scene Graph to Image Diffusion. We demonstrate the potential of SGs to encode semantic and spatial information of surgical scenes and as informative conditioning for synthesising new, unseen images with Denoising Diffusion Models. We also demonstrate that by interactively modifying the SGs, changes are directly reflected in the generated image, enabling precise control over the generation process. This overcomes the limitations of text prompts, which lack precision, and segmentation masks, which are difficult to modify and interact with. In our user study, surgeons verified the generated images to be realistic and coherent with the changes made to the scene graphs, highlighting SurGrID's substantial potential for realistic surgical simulation controlled by scene graphs. Our method surpasses state-of-the-art techniques in image quality and coherence to the graph input, which we demonstrate quantitatively and qualitatively. This paves the way for photorealistic surgical simulations that are trainable from real surgical videos while retaining the high controllability needed for surgical simulation. 