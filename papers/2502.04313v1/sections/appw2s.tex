\section{Weak-to-Strong Training}

\subsection{Setup}
\label{sec:w2ssetup}
\begin{table}[h]
    \centering
    \caption{Datasets, Weak Models and Strong Models Used in the Weak to Strong Experiments.}
    \begin{tabular}{l|l}
        \hline
        \textbf{Models} & \textbf{Datasets} \\
        \hline
        \textbf{Weak Models} &  \texttt{sciq}~\citep{welbl2017crowdsourcing} \\
        \texttt{google/gemma-2-2b}~\citep{gemmateam2024gemma2improvingopen} & \texttt{anli-r2}~\citep{nie2019adversarial}\\
        \texttt{Qwen/Qwen2.5-1.5B}~\citep{qwen2025qwen25technicalreport} & \texttt{boolq}~\citep{clark2019boolq} \\
        \texttt{meta-llama/Llama-3.2-1B}~\citep{grattafiori2024llama3herdmodels} & \texttt{cola}~\citep{warstadt2019neural} \\
        \texttt{microsoft/phi-2}~\citep{li2023textbooksneediiphi15} &  \texttt{ethics-utilitarianism}~\citep{hendrycks2020aligning} \\
         \textbf{Strong Models} & \texttt{sst2}~\citep{socher2013recursive} \\
        \texttt{google/gemma-2-9b} &  \texttt{twitter-sentiment}~\citep{paws2019naacl} \\
         \texttt{Qwen/Qwen2.5-7B}  & \texttt{dream}~\citep{sun2019dream} \\
         \texttt{meta-llama/Llama-3.1-8B}  & \texttt{mc-taco}~\citep{Zhou19taco} \\
         &  \texttt{multirc}~\citep{khashabi2018looking} \\
         & \texttt{quail}~\citep{rogers2020getting} \\
         &  \texttt{quartz}~\citep{tajford19quartz} \\
         &  \texttt{social-i-qa}~\citep{sap2019socialiqa} \\
         &  \texttt{wic}~\citep{pilehvar2018wic} \\
         &  \texttt{cosmos-qa}~\citep{huang2019cosmos} \\
        \hline
    \end{tabular}
    \label{tab:weak_strong_datasets}
\end{table}

We follow the weak to strong generalization setup proposed in \citet{burns2024weaktostrong}, focusing on NLP tasks. The original paper reported results with GPT~\citep{radford2019language} model versions. Instead, we use larger, more capable and recent open-weight models to make observations at the frontier. For this, we used the codebase of \citet{scherlis2024w2seleuther} that uses open-weight models on Huggingface instead. We now describe the full setup here.

The setup uses a pretrained weak base model $W$, a pretrained strong base model $S$ and a dataset $D$, where $D_{tr}, D_{val}, D_{te}$ are the training (10,000 samples), validation (1,000 samples) and test (5,000 samples) datasplits respectively. $D_{tr}$ is divided into two halves, independently assigning each sample to $D_{tr1}$, $D_{tr2}$ with $50\%$ probability each. All the datasets studied convert standard NLP MCQ datasets into binary classification, by randomly sampling one of the wrong options. Predictions $\geq 0.5$ are considered as class $1$, and $< 0.5$ as class 0. We highlight the models and datasets used in our study in Table~\ref{tab:weak_strong_datasets}.

First, the weak base model $W$ is finetuned on ground-truth labels in $D_{tr1}$ to obtain the weak supervisor $W_{s}$. In the original setup, this is meant to simulate a human that is an expert at the given task. Then, $W_{gt}$ annotates samples in $D_{tr2}$, and the strong student model $S$ is finetuned on these annotations to obtain the Weak to Strong trained model $S_{w2s}$. In the original setup, the strong base model simulates a future model with superhuman intelligence, but not finetuned for specific domain knowledge. 

\textbf{Finetuning Methodology}: For the above finetuning steps we use Low Rank Adapters (LoRA) \citep{hu2021lora} due to budget constraints, and train a binary classifier the same as \citet{scherlis2024w2seleuther}. We use the confidence weighted loss proposed by \citet{burns2024weaktostrong}. This loss encourages the strong model's predictions to align with both a weaker model and its own "hardened" predictions. The hardened predictions are derived by thresholding the strong model's output. The loss function is defined as:

\begin{equation}
\label{eq:conf_loss_appendix}
\mathcal{L}(f) = (1-\alpha) \cdot \text{CE}(f(x), f_w(x)) + \alpha \cdot \text{CE}(f(x), \hat{f}(x))
\end{equation}

where \(f(x)\) is the strong model's output, \(f_w(x)\) is the weak model's output, \(\hat{f}(x) = \mathbb{I}[f(x) > t]\) represents the hardened predictions using an adaptive threshold \(t\), and \(\alpha\) is a weight that increases over the initial phase of training.

Following \citet{scherlis2024w2seleuther} we use a cosine learning rate schedule, with $40$ warmup steps, the learning rates for the weak, strong model are $\num{5e-4}, \num{8e-5}$ respectively, and we train for $3$ epochs which is sufficient for the train and validation loss to stabilize.

\textbf{Weak to Strong Gain Metric}: We wish to study the gain achieved from weak to strong training for the strong student model. To characterize the initial accuracy of the strong student model, we train a binary classifier head to obtain $S_b$. The weak to strong gain is then quantified as:
\begin{equation}
    \label{eq:w2sgain}
    Acc(S_{w2s}) - Acc(S_b)
\end{equation} 
Note that this is different from the PGR metric reported by \citet{burns2024weaktostrong}. Their goal was to show weak to strong training can make the strong student cross the accuracy of the weak supervisor. Thus, they measured accuracy gained over the weak supervisor $Acc(S_{w2s}) - Acc(W_{gt})$, normalizing it by an ``upper-bound'' obtained by training the strong student on ground-truth labels on $D_{tr2}$, giving $PGR = 
\frac{Acc(S_{w2s}) - Acc(W_{gt})}{Acc(S_{gt})- Acc(W_{gt})}$. In our work, we show that leveraging complementary knowledge effectively might actually allow $S_{w2s} > S_{gt}$, questioning their ``upper-bound''. Thus we stick to reporting how much the student model improved as described in Equation~\ref{eq:w2sgain}.

\textbf{Similarity vs Weak to Strong Gain}: In Figure~\ref{fig:similarityvsgain_dataset} we reported weak-to-strong gain (Equation~\ref{eq:w2sgain}) on the Y-axis, and similarity ($\goelpi$) on the X-axis. We plot linear grouped by model pair, thus varying the task within each model pair for the linear fit. Figure~\ref{fig:similarityvsgain_dataset} shows the same scatter points but colored based on the dataset. This shows that weak-to-strong gain is consistently higher for tasks where models are less similar, and how similar two models are depends mostly on the task, i.e. there is not much variance in similarity across the model pairs for a fixed task. 

\textbf{Discarded Results}: We had initially run experiments with three more weak models: SmolLM 1.7B, Qwen-2.5-0.5B, Llama-3.2-1B against the same list of strong models reported above. However, we found that on some tasks, the weak-to-strong gain was negative. The weak supervisor ($W_{gt}$) models had lower accuracy compared to the strong student $S_b$, leading to a decrease in accuracy for the strong student after weak to strong training. We thus removed these weak models from our analysis. Similarly, we had also tried the Hellaswag dataset, but found that both weak and strong models had very low accuracies, often below 60\% where chance is 50\% for binary classification, consistent with \citet{scherlis2024w2seleuther}, and decided to not include it in our analysis.

\subsection{Elicitation vs Complementary Knowledge}
\label{app:elicitation_complementary}
\begin{table*}[htbp]
  \centering
  \caption{\textbf{Models and Sources of Knowledge in Complementary Knowledge vs Elicitation Comparison}. }
  \label{tab:w2s_sources}
  \resizebox{0.8\linewidth}{!}{
  \begin{tabular}{lcccc}
    \toprule
    \textbf{Model} & \textbf{Ground-truth labels in $D_{tr1}$} & \textbf{Latent Knowledge of $W$} & \textbf{Latent Knowledge of $S$}  \\
    \midrule
    % $S_{b}$ & \cmark & \cmark & \xmark & \xmark \\
    $W_{gt}$ & \cmark & \cmark & \xmark \\
    $S_{gt}$ & \cmark & \xmark & \cmark \\
    \midrule
    $S_{w2s}$ & \cmark\footnote{This is obtained indirectly through distillation from $W_{gt}$.} & \cmark & \cmark \\
    \bottomrule
  \end{tabular}}
\end{table*}

Figure~\ref{fig:kappavsgain} points to the fact that similarity or difference between the weak supervisor and the initial strong student are strong predictors of weak-to-strong gain. However, the initially proposed explanation of weak-to-strong generalization is ``elicitation'', i.e. the strong student has latent capabilities that are brought out by finetuning on weak annotations~\citep{burns2024weaktostrong}. To quantify the contribution of these two sources for weak-to-strong gain, elicitation and complementary knowledge, we establish the following setup.

First, our functional similarity metric cannot capture latent knowledge in the strong student's representations. For this, we follow \citet{burns2024weaktostrong} and finetune the strong student $S$ on ground-truth labels of $D_{tr1}$ to obtain the elicited strong student model $S_{gt}$. Note that we use $D_{tr1}$ instead of $D_{tr2}$ here so that the training set of $S_{w2s}$, $D_{tr2}$, remains held-out, and we can analyze the relative effect of eliciation and complementary knowledge on both the train and test set. 

Table~\ref{tab:w2s_sources} summarizes sources of knowledge for the weak supervisor $W_{gt}$, strong elicited $S_{gt}$, and weak-to-strong trained student $S_{w2s}$ in our setup. $S_{w2s}$ benefits from the latent knowledge of $S$, complementary knowledge transfer of latent knowledge of $W$, and distillation of knowledge in $D_{tr1}$ from $W_{gt}$. It learns imperfectly from all three sources of knowledge. Given this, we now discuss how Figure~\ref{fig:conftest} compares elicitation and complementary knowledge transfer: 
\begin{itemize}
    \item \textbf{Bottom-Left = Elicitation}: $W_{gt}$ does not benefit from latent knowledge of $S$, so $S_{w2s}$ accuracy on samples where it is wrong but $S_{gt}$ is correct signify knowledge that could only be from elicitation.
    \item \textbf{Top-Right = Complementary Knowledge Transfer}: $S_{gt}$ does not benefit from the latent knowledge of $W$, so $S_{w2s}$ accuracy on samples where it is wrong but $W_{gt}$ is correct signify knowledge that could only be from complementary knowledge transfer.
    \item \textbf{Top-Left = Could be Both}: Accuracy of $S_{w2s}$ on samples where both $W_{gt}, S_{gt}$ are correct could come from both their latent knowledge, and the ground-truth annotations in $D_{tr1}$. Thus, these could be both elicitation and complementary knowledge transfer, or also learning from the finetuning data.
    \item \textbf{Bottom-Right = Random flips}: We find that $10\%$ predictions can flip even when finetuning $W, S$ on ground-truth labels from $D_{tr2}$ instead of $D_{tr1}$, which were split into two halves at random from $D_{tr}$. Thus, the roughly 10\% accuracy on samples that both $W_{gt}, S_{gt}$ got wrong could just be random flips to the correct prediction (since its a binary classification setting). 
\end{itemize}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\linewidth]{fig/new_conf_mat_accs_train.pdf}
    \caption{We decompose the accuracy of the weak to strong trained model on four parts of the train data distribution based on whether the weak supervisor and an oracle strong elicited model (using ground-truth annotations) are correct or wrong. All results are averaged over 15 datasets. Sub-rectangles represent weak, strong model pairs. On the train dataset, complementary knowledge transfer (mean accuracy $0.59$) plays an equal role as elicitation (mean accuracy $0.56$).}
    \label{fig:conftrain}
    % \vspace{-0cm}
\end{figure}

\textbf{Behavior on the Train Set}: Figure~\ref{fig:conftrain} reports the same comparison of elicitation and complementary knowledge transfer but on $D_{tr2}$ on which the weak-to-strong training occurs. This set is unseen for both the weak supervisor $W_{gt}$ and the strong elicited model $S_{gt}$. We find that in fitting the training data complementary knowledge transfer plays an equal or bigger role than elicitation. This is to be expected as $S_{w2s}$ is trained by fitting on $W_{gt}$'s annotations of $D_{tr2}$. The weak-to-strong trained student however still generalizes more similarly to the strong elicited model than the weak supervisor, though complementary knowledge transfer is also visible on test set predictions as seen in Figure~\ref{fig:conftest}. 


\subsection{Effect of Different similarity metrics}
\begin{figure}[h!]
  \centering
  \begin{subfigure}{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/kpgain_dataset.pdf}
  \end{subfigure}\hfill
  \begin{subfigure}{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/ecgain_dataset.pdf}
  \end{subfigure}
  \begin{subfigure}{0.33\textwidth}
    \includegraphics[width=\textwidth]{fig/JSDgain_dataset.pdf}
  \end{subfigure}\hfill
  \begin{subfigure}{\textwidth}
    \includegraphics[width=\textwidth]{fig/legendgain_dataset.pdf}
  \end{subfigure}
  \caption{\textbf{Various Similarity Metrics vs Weak-to-Strong gain}. The highest correlation is seen for CAPA $\goelpi$, though in the binary classification setup of weak-to-strong generalization the probabilistic information does not add much value compared to error consistency. $1 - JSD$ gives a more noisy scatter plot, with lower correlation ($r$).}
  \label{fig:similarityvsgain_dataset}
\end{figure}

We now report similarity vs weak-to-strong gain for various alternate similarity metrics. Here, we color the scatter points by dataset instead of model pair, and fit a single line, for ease of interpretation. We report the following similarity metrics:
\begin{itemize}
    \item Error Consistency - In this setting of binary classification, this is equivalent to the non-probabilistic version of CAPA, as there is only one incorrect option so models cannot disagree when both are incorrect on a sample.
    \item CAPA ($\goelpi$) - Our metric which incorporates probabilistic information into error consistency.
    \item $1 - JSD$ - Since Jensen-Shannon Distance measures difference between distributions and is normalized between 0 and 1, by subtracting it from 1 we can obtain a similarity metric for ease of comparison with the previous metrics.
\end{itemize}

In Figure~\ref{fig:similarityvsgain_dataset} we see that all metrics can show the same trend, that is, tasks where models differ more have larger gain from weak-to-strong training. The highest correlation is seen for CAPA, though in the binary classification setup of weak-to-strong generalization the probabilistic information does not add much value compared to error consistency. $1 - JSD$ gives a more noisy scatter plot, with lower correlation ($r$).

\subsection{Accuracies in Weak-to-Strong training}
\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/grouped_bar_plot_accs_test.pdf}
    \caption{\textbf{Test Accuracies for various models and ceiling estimates in Weak-to-Strong training}. The accuracies are averaged over 12 model pairs. The initial strong student model has consistently lower accuracy than the weak supervisor consistent with~\citet{burns2024weaktostrong, scherlis2024w2seleuther}. The weak-to-strong trained student surpasses the weak-supervisor across datasets. However it has lower accuracy than the elicitation ceiling which trains the strong student on ground-truth annotations. Finally, our new estimated ceiling which incorporates the complementary knowledge of the weak supervisor has even higher accuracies, showing even more scope for improvements.}
    \label{fig:w2sacctest}
    % \vspace{-0cm}
\end{figure}

In Figure~\ref{fig:w2sacctest} we report average across the 12 model pairs for all 15 datasets. Consistently, the ordering is as follows: the initial strong student has lower accuracy than the weak supervisor, but surpasses it after weak-to-strong training. However, it is not able to match the performance ceiling of ground-truth elicitation. Finally, if the take a union over the correct predictions of the weak supervisor and strong elicited model, the performance ceiling can be even higher.

\subsection{Weak-to-strong Accuracy Value Details in Elicitation vs Complementary Knowledge Analysis}
In Table~\ref{tab:test_quadrants} and Table~\ref{tab:train_quadrants} we report the underlying numbers for Figure~\ref{fig:conftest} and Figure~\ref{fig:conftrain} respectively. The astute observer may be confused about the around 12\% accuracy on the test set when when both the weak supervisor and strong elicited model are wrong (bottom-right quadrant). We find that merely finetuning on a different random subset of training data leads to around 11\% predictions being flipped. Thus, much of this accuracy could just be due to random chance because of the binary classification setup. This also indicates that complementary knowledge transfer explains much of the beyond-chance accuracy not accounted for by elicitation.

\begin{table}[ht!]
\centering
\caption{\textbf{Weak-to-strong trained model's accuracies on four parts of the test data distribution, based on relative mistakes of weak-supervisor, strong elicited model}. This table reports the underlying numbers for Figure~\ref{fig:conftest}, with accuracy averaged across the 15 datasets studied for each model pair. We see that the weak-to-strong model is almost always correct when both the weak-supervisor, strong elicited model are correct. It is more correct when the strong elicited model is correct and the weak-supervisor is wrong than vice-versa. This indicates weak-to-strong training currently exploits more of the possible gains from elicitation, but less of the possible gains from complementary knowledge transfer.}
\label{tab:test_quadrants}
\begin{tabular}{cc}
\toprule
\multicolumn{1}{c}{\textbf{Common Knowledge}} & \multicolumn{1}{c}{\textbf{Complementary Knowledge Transfer}} \\
\midrule
%-------------------- cc
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 97.4 \\
(gemma-2-2b, Qwen2.5-7B)   & 97.1 \\
(gemma-2-2b, Llama-3.1-8B) & 97.0 \\
(Qwen2.5-1.5B, gemma-2-9b) & 97.1 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 97.4 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 96.5 \\
(Llama-3.2-3B, gemma-2-9b)   & 97.6 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 97.5 \\
(Llama-3.2-3B, Llama-3.1-8B) & 97.3 \\
(phi-2, gemma-2-9b)          & 97.3 \\
(phi-2, Qwen2.5-7B)          & 97.3 \\
(phi-2, Llama-3.1-8B)        & 97.4 \\
\bottomrule
\end{tabular}
&
%-------------------- cw
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 45.2 \\
(gemma-2-2b, Qwen2.5-7B)   & 34.9 \\
(gemma-2-2b, Llama-3.1-8B) & 40.1 \\
(Qwen2.5-1.5B, gemma-2-9b) & 47.1 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 36.9 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 39.6 \\
(Llama-3.2-3B, gemma-2-9b)   & 46.2 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 36.2 \\
(Llama-3.2-3B, Llama-3.1-8B) & 41.7 \\
(phi-2, gemma-2-9b)          & 50.2 \\
(phi-2, Qwen2.5-7B)          & 44.2 \\
(phi-2, Llama-3.1-8B)        & 44.2 \\
\bottomrule
\end{tabular}
\\
\midrule
\multicolumn{1}{c}{\textbf{Elicitation}} & \multicolumn{1}{c}{\textbf{Both Wrong}} \\
%-------------------- wc
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 71.0 \\
(gemma-2-2b, Qwen2.5-7B)   & 75.0 \\
(gemma-2-2b, Llama-3.1-8B) & 72.3 \\
(Qwen2.5-1.5B, gemma-2-9b) & 69.4 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 73.3 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 72.1 \\
(Llama-3.2-3B, gemma-2-9b)   & 71.0 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 77.2 \\
(Llama-3.2-3B, Llama-3.1-8B) & 73.4 \\
(phi-2, gemma-2-9b)          & 67.9 \\
(phi-2, Qwen2.5-7B)          & 71.1 \\
(phi-2, Llama-3.1-8B)        & 69.0 \\
\bottomrule
\end{tabular}
&
%-------------------- ww
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 12.9 \\
(gemma-2-2b, Qwen2.5-7B)   & 10.7 \\
(gemma-2-2b, Llama-3.1-8B) & 13.0 \\
(Qwen2.5-1.5B, gemma-2-9b) & 11.4 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 11.6 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 13.5 \\
(Llama-3.2-3B, gemma-2-9b)   & 12.5 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 11.2 \\
(Llama-3.2-3B, Llama-3.1-8B) & 13.8 \\
(phi-2, gemma-2-9b)          & 12.3 \\
(phi-2, Qwen2.5-7B)          & 11.6 \\
(phi-2, Llama-3.1-8B)        & 11.5 \\
\bottomrule
\end{tabular}
\\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[ht!]
\centering
\caption{\textbf{Weak-to-strong trained model's accuracies on four parts of the train data distribution, based on relative mistakes of weak-supervisor, strong elicited model}. This table reports the underlying numbers for Figure~\ref{fig:conftrain}, with accuracy averaged across the 15 datasets studied for each model pair. On the train distribution, the weak-to-strong model is almost equally correct on the only-elicitable and only learnable from complementary knowledge samples, with a slight lean towards the latter. Yet, Table~\ref{tab:test_quadrants} showed it generalizes more similarly to the strong elicited model.}
\label{tab:train_quadrants}
\begin{tabular}{cc}
\toprule
\multicolumn{1}{c}{\textbf{Common Knowledge}} & \multicolumn{1}{c}{\textbf{Complementary Knowledge Transfer}} \\
\midrule
%-------------------- cc
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 98.6 \\
(gemma-2-2b, Qwen2.5-7B)   & 98.6 \\
(gemma-2-2b, Llama-3.1-8B) & 98.5 \\
(Qwen2.5-1.5B, gemma-2-9b) & 98.5 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 98.6 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 98.5 \\
(Llama-3.2-3B, gemma-2-9b)   & 98.7 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 98.7 \\
(Llama-3.2-3B, Llama-3.1-8B) & 98.5 \\
(phi-2, gemma-2-9b)          & 98.0 \\
(phi-2, Qwen2.5-7B)          & 98.4 \\
(phi-2, Llama-3.1-8B)        & 98.2 \\
\bottomrule
\end{tabular}
&
%-------------------- cw
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 66.8 \\
(gemma-2-2b, Qwen2.5-7B)   & 52.5 \\
(gemma-2-2b, Llama-3.1-8B) & 56.8 \\
(Qwen2.5-1.5B, gemma-2-9b) & 65.2 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 56.9 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 57.0 \\
(Llama-3.2-3B, gemma-2-9b)   & 67.2 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 53.8 \\
(Llama-3.2-3B, Llama-3.1-8B) & 58.8 \\
(phi-2, gemma-2-9b)          & 64.4 \\
(phi-2, Qwen2.5-7B)          & 53.7 \\
(phi-2, Llama-3.1-8B)        & 54.8 \\
\bottomrule
\end{tabular}
\\
\midrule
\multicolumn{1}{c}{\textbf{Elicitation}} & \multicolumn{1}{c}{\textbf{Both Wrong}} \\
%-------------------- wc
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 50.7 \\
(gemma-2-2b, Qwen2.5-7B)   & 63.5 \\
(gemma-2-2b, Llama-3.1-8B) & 57.3 \\
(Qwen2.5-1.5B, gemma-2-9b) & 49.2 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 62.2 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 58.2 \\
(Llama-3.2-3B, gemma-2-9b)   & 47.9 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 60.3 \\
(Llama-3.2-3B, Llama-3.1-8B) & 52.4 \\
(phi-2, gemma-2-9b)          & 52.6 \\
(phi-2, Qwen2.5-7B)          & 62.3 \\
(phi-2, Llama-3.1-8B)        & 60.1 \\
\bottomrule
\end{tabular}
&
%-------------------- ww
\begin{tabular}{l r}
\toprule
\textbf{Pair} & \textbf{Acc (\%)} \\
\midrule
(gemma-2-2b, gemma-2-9b)   & 8.6 \\
(gemma-2-2b, Qwen2.5-7B)   & 8.3 \\
(gemma-2-2b, Llama-3.1-8B) & 9.5 \\
(Qwen2.5-1.5B, gemma-2-9b) & 9.6 \\
(Qwen2.5-1.5B, Qwen2.5-7B) & 7.4 \\
(Qwen2.5-1.5B, Llama-3.1-8B) & 7.7 \\
(Llama-3.2-3B, gemma-2-9b)   & 8.8 \\
(Llama-3.2-3B, Qwen2.5-7B)   & 7.9 \\
(Llama-3.2-3B, Llama-3.1-8B) & 8.5 \\
(phi-2, gemma-2-9b)          & 10.8 \\
(phi-2, Qwen2.5-7B)          & 9.4 \\
(phi-2, Llama-3.1-8B)        & 9.1 \\
\bottomrule
\end{tabular}
\\
\bottomrule
\end{tabular}
\end{table}

