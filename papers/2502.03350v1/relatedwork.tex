\section{Related work}
The effects of curriculum learning have been extensively studied in the reinforcement learning (RL) literature \citep{elman1993learning, krueger2009flexible, narvekar2020curriculum}. However, these studies primarily focus on learning a single challenging task by sequentially training on simpler tasks, leaving open the question of how to design a curriculum for learning multiple tasks of similar difficulty. A limited number of works have explored task-order optimization for continual/lifelong learning across multiple tasks by contrast.

\citet{lad2009toward} demonstrated that ordering tasks based on pairwise order preferences can lead to better classification performance compared to random task ordering. More recently, \citet{bell2022effect} investigated task-order optimization by examining Hamiltonian paths on a task dissimilarity graph (see Sec. \ref{sec_task_order_optim} for details). They hypothesized that the shortest Hamiltonian path would be optimal but instead found that the longest Hamiltonian path significantly outperformed both random task ordering and the shortest path in continual image classification tasks. Our work provides analytical insights into when and why this is the case.
\citet{lin2023theory} analyzed generalization error and task-order optimization in continual learning for linear regression. Our work advances this theoretical framework in several important ways. First, we introduce a latent structure model for considering the effect of input similarity and reveal how tasks' relative positions—not just their absolute positions as in \citet{lin2023theory}'s Equation 10—influence the model's final performance. We validate this theoretical finding through experiments on both synthetic data and image classification tasks. Furthermore, we extend beyond the synthetic task settings of \citet{lin2023theory} by demonstrating these effects in a general continual learning framework using data-driven similarity estimation.
Task-order effects on continual learning have also been analyzed in \citep{pentina2015curriculum, evron2023continual, singh2023learning}.


The linear teacher-student model used in this work is a widely adopted framework for analyzing the average properties of neural networks by explicitly modeling the data generation process through a teacher model \citep{gardner1989three, zdeborova2016statistical, bahri2020statistical}. Due to their analytical tractability, these models have offered deep insights into various aspects of statistical learning problems, including generalization \citep{seung1992statistical, advani2020high}, learning dynamics \citep{saad1995line, werfel2003learning, saxe2013exact}, and representation learning \citep{saxe2019mathematical, tian2021understanding}. Many studies have also applied this framework to explore various aspects of continual learning \citep{asanuma2021statistical, lee2021continual, evron2022catastrophic, goldfarb2023analysis, li2023statistical, lin2023theory, evron2024joint, hiratani2024disentangling, mori2024optimal}.

\begin{figure*}[tb]
\begin{center}
\centerline{\includegraphics[width=0.8\linewidth]{figs/fig_lst_theory-simul1-1.pdf}}
\vskip -0.1in
\caption{
\textbf{a)} Schematic of the teacher-student model. 
\textbf{b)} Comparison between the analytical and numerical evaluations of the error $\epsilon_f$ under various number of tasks. Each point represents the errors under a randomly sampled task similarity matrices $(C^{in}, C^{out})$ (see Appendix \ref{sec_implementation_details} for implementation details).
\textbf{c)} Optimal task order for three task learning. In the white regions, $C^{in}$ is not a positive-definite matrix, hence the tasks are not well-defined. 
}
\label{lin_theory_simul}
\end{center}
\vskip -0.2in
\end{figure*}