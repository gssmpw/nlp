\documentclass{article}

\usepackage{microtype}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}

\newcommand*{\defeq}{\stackrel{\text{def}}{=}}
\newcommand{\argmin}{\mathop{\mathrm{argmin}}\limits}
\newcommand{\argmax}{\mathop{\mathrm{argmax}}\limits}
\newcommand{\KL}[2]{\text{KL}\left(#1\Vert #2\right)}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algrenewcommand\algorithmicensure{\textbf{Output:}}
\usepackage{subcaption}
\graphicspath{{./images/}}
\usepackage{wrapfig}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{multirow}
\usepackage[skip=1ex]{caption}
\usepackage{tabularray}
\UseTblrLibrary{siunitx, booktabs}
\usepackage[makeroom]{cancel}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{wasysym}
\usepackage{todonotes}

\usepackage[capitalize,noabbrev]{cleveref}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage{titlesec}
\titleformat{\subsubsection}[runin]{\bfseries}{\thesubsubsection}{1em}{}{}
\titlespacing{\subsubsection}{0pt}{0pt}{1em}

\icmltitlerunning{Categorical Schrödinger Bridge Matching}

\begin{document}

\twocolumn[
\icmltitle{Categorical Schrödinger Bridge Matching}

\begin{icmlauthorlist}
    \icmlauthor{Grigoriy Ksenofontov}{sk,mipt}
    \icmlauthor{Alexander Korotin}{sk,airi}
\end{icmlauthorlist}

\icmlaffiliation{sk}{Skoltech, Moscow, Russia}
\icmlaffiliation{mipt}{MIPT, Dolgoprudny, Russia}
\icmlaffiliation{airi}{AIRI, Moscow, Russia}

\icmlcorrespondingauthor{Grigoriy Ksenofontov}{g.ksenofontov@skoltech.ru, ksenofontov.gs@phystech.edu}
\icmlcorrespondingauthor{Alexander Korotin}{a.korotin@skoltech.ru}


\icmlkeywords{Schrödinger Bridge, Entropic Optimal Transport, Optimal transport, Unpaired Learning, Discrete space}

\vskip 0.3in
]

\printAffiliationsAndNotice{}

\begin{abstract}
    The Schrödinger Bridge (SB) is a powerful framework for solving generative modeling tasks such as unpaired domain translation. Most SB-related research focuses on continuous data space $\mathbb{R}^{D}$ and leaves open theoretical and algorithmic questions about applying SB methods to discrete data, e.g, on finite spaces $\mathbb{S}^{D}$. Notable examples of such sets $\mathbb{S}$ are codebooks of vector-quantized (VQ) representations of modern autoencoders, tokens in texts, categories of atoms in molecules, etc. In this paper, we provide a theoretical and algorithmic foundation for solving SB in discrete spaces using the recently introduced Iterative Markovian Fitting (IMF) procedure. Specifically, we theoretically justify the convergence of discrete-time IMF (D-IMF) to SB in discrete spaces. This enables us to develop a practical computational algorithm for SB which we call Categorical Schrödinger Bridge Matching (CSBM). We show the performance of CSBM via a series of experiments with synthetic data and VQ representations of images.
\end{abstract}

\section{Introduction}
\label{sec:intro}

The Schrodinger bridge \citep[SB]{schrodinger1931umkehrung} problem has recently attracted the attention of the machine learning community due to its relevance to modern challenges in generative modeling and unpaired learning. Recently, a variety of methods have been proposed to solve SB in \textit{continuous spaces}, see \citep{gushchin2023building} for a recent survey.

One modern approach to solving SB is the Iterative Markovian Fitting (IMF) framework \cite{peluchetti2023diffusion,shi2023diffusion,gushchin2024adversarial}. Specifically, within this framework, discrete-time IMF procedure \citep[D-IMF]{gushchin2024adversarial} has shown promising results in certain unpaired learning problems, allowing to speed up the generation (inference) time of its predecessors.

Unfortunately, the D-IMF procedure heavily relies on certain theoretical properties of particular SB setups in continuous spaces. At the same time, a vast amount of real-world data is either \textit{discrete} by nature (texts \cite{austin2021structured, gat2024discrete}, molecular graphs \cite{vignac2022digress, qin2024defog, luo2024crystalflow}, sequences \cite{campbell2024generative}, etc.) or by construction (vector-quantized representations of images, audio \cite{van2017neural, esser2021taming}), making it impossible to apply D-IMF for such data. Our work addresses this gap and delivers the following \textbf{contributions:}
\begin{itemize}[leftmargin=*]
    \item \textbf{Theory.} We provide the theoretical grounds for applying the D-IMF to solve the SB problem in discrete spaces.
    \item \textbf{Practice.} We provide a computational algorithm to implement the D-IMF in practice for discrete spaces.
\end{itemize}

\paragraph{Notations.} Consider a \emph{state space} $\mathcal{X}$ and a \emph{time set} $\{t_n\}_{n=0}^{N+1}$, where $0=t_{0}<t_{1}<\dots<t_{N} < t_{N+1}=1$ are $N \geq 1$ time moments. The space $\mathcal{X}^{N+2}$ is referred to as the \emph{path space} and represents all possible trajectories $(x_0, x_{\text{in}}, x_{t_{N+1}})$, where $x_{\text{in}} \defeq (x_{t_1}, \dots, x_{t_N})$ corresponds to the intermediate states. Let $\mathcal{P}(\mathcal{X}^{N+2})$ be the space of probability distributions over paths. Each $q\in\mathcal{P}(\mathcal{X}^{N+2})$ can be interpreted as a discrete in time $\mathcal{X}$-valued stochastic process. We use $q(x_0, x_{\text{in}}, x_{t_{N+1}})$ to denote its density at $(x_0, x_{\text{in}}, x_{t_{N+1}}) \in \mathcal{X}^{N+2}$ and use $q(\cdot|\cdot)$ to denote its conditional distributions, e.g., $q(x_1|x_0)$, $q(x_{\text{in}}|x_0,x_1)$. Finally, we introduce $\mathcal{M}(\mathcal{X}^{N+2}) \subset \mathcal{P}(\mathcal{X}^{N+2})$ as the set of all \emph{Markov processes} $q$, i.e., those processes which satisfy the equality $q(x_0, x_{\text{in}}, x_{t_{N+1}})=q(x_0)\prod_{n=1}^{N+1}q(x_{t_n}|x_{t_{n-1}})$.


\section{Background and Related Works}

\subsection{The Static Schrödinger Bridge Problem}
Consider two distributions $p_0, p_1 \in \mathcal{P}(\mathcal{X})$ and all distributions $q\in\mathcal{P}(\mathcal{X}^{2})$ whose marginal distributions are $p_0,p_1$, respectively. The set of such distributions $\Pi(p_0, p_1) \subset \mathcal{P}(\mathcal{X}^2)$ is called the set of \emph{transport plans}. In addition, suppose we are given a reference distribution $q^{\text{ref}} \in \mathcal{P}(\mathcal{X}^2)$.

\emph{The Static Schrödinger Bridge (SB) problem} \cite{schrodinger1931umkehrung, leonard2013survey} consists of finding the transport plan $q \in \Pi(p_0, p_1)$ closest to $q^{\text{ref}}$ in terms of the Kullback–Leibler (KL) divergence:
\begin{equation}
    \label{eq:static_sb}
    q^*(x_0, x_1) = \argmin_{q \in \Pi(p_0, p_1)}\text{KL}(q(x_0, x_1)||q^{\text{ref}}(x_0, x_1)),
\end{equation}
With mild assumptions on components of the problem ($\mathcal{X}, p_0, p_1, q^{\text{ref}}$), the solution $q^*$ to this problem uniquely exists; it is called the static SB.

Notably, the static SB problem is equivalent to another well-celebrated problem -- the \emph{Entropic Optimal Transport} \citep[EOT]{cuturi2013sinkhorn}. Indeed, \eqref{eq:static_sb} can be written as
\begin{eqnarray}
    \min_{q \in \Pi(p_0, p_1)}  \mathbb{E}_{q(x_0, x_1)}\log \frac{q(x_0,x_1)}{q^{\text{ref}}(x_0,x_1)}
    =
    \nonumber
    \\
    \min_{q \in \Pi(p_0, p_1)}\big\{ \mathbb{E}_{q(x_0, x_1)}\underbrace{\left[-\log q^{\text{ref}}(x_0, x_1)\right]}_{\defeq c(x_0,x_1)} - H(q)\big\}=
    \nonumber
    \\
    \min_{q \in \Pi(p_0, p_1)} \left\{ \mathbb{E}_{q(x_0, x_1)}c(x_0,x_1) - H(q)\right\}.
    \label{eq:eot}
\end{eqnarray}

where $H(q)$ denotes the entropy of transport plan $q(x_0, x_1)$ and $c(x_0,x_1)$ is transport cost function.

\subsection{Practical Learning Setup of SB}
\label{sec:background-setup-generative}

Over the last decade, researchers have approached SB/EOT problems in various studies because of their relevance to real-world tasks \cite{peyre2019computational,gushchin2023building}. In our paper, we consider the following learning setup, which is usually called the \textit{generative} setup.

We assume that a learner is given empirical datasets $\{x^m_0\}_{m=1}^M \subset \mathcal{X}$ and $\{x^k_1\}_{k=1}^K \subset \mathcal{X}$, which are i.i.d. samples from unknown data distributions $p_0$ and $p_1$, respectively. The goal is to leverage these samples to find a solution $\widehat{q}\approx q^{*}$ to the SB problem \eqref{eq:eot} between the distributions $p_0, p_1$. The solution should permit the \textbf{out-of-sample estimation}, i.e., for any $x_{0}^{\text{new}}$, one should be able to generate new $x_{1}^{\text{new}}\sim \widehat{q}(x_1|x_{0}^{\text{new}})$.

In the related literature, this setup is mainly explored in the context of unpaired (unsupervised) domain translation. In this task, the datasets consist of samples from two different data distributions (domains), and the goal is to learn a transformation from one domain to the other \citep[Figure 2]{zhu2017unpaired}. The problem is inherently ill-posed because theoretically, there may be multiple possible transformations. In many applications of unpaired learning, it is crucial to preserve semantic information during the translation, for example, the image content in image-to-image translation. Therefore, SB and EOT are suitable tools for this task as they allow controlling the properties of the learned translation by selecting the reference distribution $q^{\text{ref}}$ in \eqref{eq:static_sb} or the transport cost $c$ in \eqref{eq:eot}. Over the last several years, many such SB/EOT methods for unpaired learning have been developed, see \citep{gushchin2023building} for a survey.

\subsection{Discrete and Continuous State Space $\mathcal{X}$ in SB}
\label{sec:bg-space}

Most methods \cite{mokrov2023energy,de2021diffusion,vargas2021solving,gushchin2023entropic,gushchin2024adversarial,korotin2024light,gushchin2024light,shi2023diffusion,liu2022deep,chen2022likelihood} use neural networks to approximate $q^{*}$ and \textit{specifically} focus on solving SB in \textbf{continuous state spaces}, e.g., ${\mathcal{X}=\mathbb{R}^{D}}$. This allows us to apply SB to many unpaired translation problems, e.g., the above-mentioned image-to-image translation or biological tasks related to the analysis and modeling of the single-cell data \cite{pariset2023unbalanced,tong2024simulation}.

Despite advances in computational SB methods, significant challenges remain when adapting these generative approaches to \textbf{discrete state spaces} $\mathcal{X}$:
\begin{enumerate}[leftmargin=*]
    \item Their underlying methodological principles are mostly incompatible with discrete spaces $\mathcal{X}$. For example, \cite{shi2023diffusion,gushchin2023entropic,vargas2021solving,liu2022deep} use stochastic differential equations (SDE) which are not straightforward to generalize and use in discrete spaces; \citep{mokrov2023energy} heavily relies on MCMC sampling from unnormalized density which is also a separate challenge for large discrete spaces $\mathcal{X}$; \citep{gushchin2024light,korotin2024light,gushchin2024adversarial} theoretically work only for the EOT problem with the quadratic cost on $\mathcal{X}=\mathbb{R}^{D}$, etc. 
    \item Extending any generative modeling techniques to discrete data is usually a challenge. For example, models such as GANs \citep{goodfellow2014generative} require backpropagation through the generator -- for discrete data is usually done via heuristics related to the Gumbel trick \citep{jang2017categorical}; flow matching methods \cite{liu2022flow} can be used for discrete data \citep{gat2024discrete} but require numerous methodological changes, etc.
\end{enumerate}

At the same time, a significant portion of modern data is inherently discrete (recall \wasyparagraph\ref{sec:intro}). Despite such data's prevalence, Schrödinger Bridges's framework for discrete spaces remains underdeveloped, which motivates our focus on addressing this gap. 

We assume that the state space $\mathcal{X}$ is discrete and represented as $\mathcal{X}=\mathbb{S}^{D}$. Here $\mathbb{S}$ is a finite set and, for convenience, we say that it is the space of categories, e.g., $\mathbb{S}=\{1,2,\dots, S\}$. One may also consider $\mathcal{X}=\mathbb{S}_{1}\times \dots \times \mathbb{S}_{D}$ for $D$ categorical sets. This does not make any principal difference, so we use $\mathbb{S}_{1}=\dots=\mathbb{S}_{D}$ to keep the paper exposition simple.

\paragraph{Discrete EOT methods.} We would like to mention, for the sake of completeness, that there is a broad area of research known as discrete EOT, which might appear to be closely related to our work. It includes, e.g., the well-celebrated Sinkhorn algorithm \citep{cuturi2013sinkhorn} and gradient-based methods \cite{dvurechensky2018computational,dvurechenskii2018decentralize}. However, such algorithms \textbf{are not relevant} to our work as they consider a different to the generative setting (\wasyparagraph\ref{sec:background-setup-generative}) and target different problems. Specifically, discrete EOT assumes that the available data samples are themself discrete distributions, i.e., $p_0 =\frac{1}{M}\sum^M_{m=1}\delta_{x_0^m},$ $p_1 = \frac{1}{K}\sum^K_{k=1}\delta_{x^k_0}$ (the weights be may not equal), and the goal is to find a bi-stochastic matrix $\in\mathbb{R}^{M\times K}$ (a.k.a. the discrete EOT plan) which optimally matches the given samples. Since this matrix is a discrete object, such methods are called discrete. Works \citep{hutter2021minimax, pooladian2021entropic, manole2021plugin, deb2021rates} aim to advance discrete EOT methods to be used in generative setups by providing out-of-sample estimators. However, they work only for continuous state space $\mathcal{X}=\mathbb{R}^{D}$. It remains an open question whether discrete solvers can be adapted for generative scenarios in discrete space $\mathcal{X}=\mathbb{S}^{D}$.

\subsection{From Static to Dynamic SB Problems}
The static SB problem \eqref{eq:static_sb} can be thought of as a problem of finding a stochastic process acting at times $t=0,1$. Usually, one considers an extension of this problem by incorporating additional time moments \cite{de2021diffusion,gushchin2024adversarial}. Let us introduce $N \geq 1$ intermediate time points $0 = t_0 < t_1 < \dots < t_N < t_{N+1} = 1$, extending $q$ to these moments. Consequently, $q$ becomes a process over the states at all time steps, i.e., $q \in \mathcal{P}(\mathcal{X}^{N+2})$. Similarly to the static formulation \eqref{eq:static_sb}, let us given marginal distributions $p_0,p_1 \in \mathcal{P}(\mathcal{X})$ with a reference process $q^{\text{ref}}\in\mathcal{P}(\mathcal{X}^{N+2})$. Then the \emph{dynamic Schrödinger Bridge} problem is
\begin{multline}
    \label{eq:disc_dyn_sb}
    \min_{q \in \Pi_{N}(p_0, p_1)}\text{KL}(q(x_0, x_{\text{in}}, x_1)||q^{\text{ref}}(x_0, x_{\text{in}}, x_1)),
\end{multline}
where $\Pi_{N}(p_0, p_1) \subset \mathcal{P}(\mathcal{X}^{N+2})$ is a set of all discrete-time stochastic processes in which initial and terminal marginal distributions are $p_0$ and $p_1$. In turn, the solution $q^{*}$ to this itself becomes an $\mathcal{X}$-valued stochastic process.

Note that:
\begin{eqnarray}
    \label{eq:disc_disintegration}
    \text{KL}(q(x_0, x_{\text{in}}, x_1)|| q^{\text{ref}}(x_0, x_{\text{in}}, x_1)) = 
    \nonumber
    \\
    \text{KL}(q(x_0, x_1)||q^{\text{ref}}(x_0, x_1)) + 
    \nonumber
    \\ \mathbb{E}_{q(x_0,x_1)} \left[\text{KL}(q(x_{\text{in}}|x_0, x_1)||q^{\text{ref}}(x_{\text{in}}|x_0, x_1)) \right]. 
    \label{kl-reciprocal-zero}
\end{eqnarray}

Since conditional distributions $q(x_{\text{in}}|x_0, x_1)$ can be chosen independently of $q(x_0, x_1)$, we can consider $q(x_{\text{in}}|x_0, x_1) = q^{\text{ref}}(x_{\text{in}}|x_0, x_1)$. It follows that the second term becomes $0$ for every $x_0,x_1$. As a result, we see that the joint distribution $q^{*}(x_0,x_1)$ for time $t=0,1$ of the dynamic SB \eqref{eq:disc_dyn_sb} is the solution to the static SB \eqref{eq:static_sb} for the reference distribution given by the $q^{\text{ref}}(x_0,x_1)$.

At this point, a reader may naturally wonder: \textit{why does one consider the more complicated Dynamic SB, especially taking into account that it boils down to simpler Static SB}?

In short, the dynamic solution adds additional properties for $q^{*}$ which can be efficiently exploited for designing computational algorithms for SB. In fact, \textbf{most} of the computational methods listed at the beginning of \wasyparagraph\ref{sec:bg-space} operate with the dynamic SB formulation. While some methods \cite{de2021diffusion,gushchin2024adversarial} consider formulation \eqref{eq:disc_dyn_sb} with discrete time and finite amount $N$ of time moments, \citep{shi2023diffusion,chen2022likelihood,gushchin2024light} work with continuous time $t\in [0,1]$. \textbf{Informally}, one may identify it with discrete time but $N=\infty$. In discussions, we will refer to this case this way in the rest of the paper \textit{to avoid unnecessary objects and notations}. The scope of our paper is exclusively the discrete-time in dynamic SB ($N<\infty$) as it is more transparent and feasible to analyze.

To conclude this section, we introduce an important definition that is specifically relevant to the dynamic SB.

\paragraph{Reciprocal processes.} A process $r \in \mathcal{P}(\mathcal{X}^{N+2})$ is called a reciprocal process with respect to the reference process $q^{\text{ref}}$ if its conditional distributions given the endpoints $x_0, x_1$ match those of the reference process, i.e.:
\begin{equation*}
    r(x_{\text{in}} \mid x_0, x_1) = q^{\text{ref}}(x_{\text{in}} \mid x_0, x_1).
\end{equation*}
    
The set of all reciprocal processes for the reference process $q^{\text{ref}}$ is denoted by $\mathcal{R}^{\text{ref}}(\mathcal{X}^{N+2}) \subset \mathcal{P}(\mathcal{X}^{N+2})$.

\subsection{Iterative Markovian Fitting (IMF) Procedure}
\label{sec:imf}
\begin{table*}[t]
    \centering
    \begin{tblr}{colspec={Q[c,m]|[0.7pt]Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]}}
        \toprule
         & \SetCell[c=2]{c} {\textbf{Continuous time} \\ ($N=\infty$)} & & \SetCell[c=2]{c,m} {\textbf{Discrete time} \\ ($N<\infty$)} \\
         \cline{2-5}
         & {\textit{Theory} \\ (SB characterization)} & {\textit{Practice} \\ (SB algorithm)} & {\textit{Theory} \\ (SB characterization)} & {\textit{Practice} \\ (SB algorithm)} \\
        \midrule
        {\textbf{Continuous space} \\ $\mathcal{X}=\mathbb{R}^D$} & \SetCell[r=2]{c,m} {Theorem 3.2 \\  \cite{leonard2014reciprocal}} & {DSBM \wasyparagraph 4 \\ \cite{shi2023diffusion}} & {Theorem 3.1 \\ \cite{gushchin2024adversarial}} & {ASBM \wasyparagraph 3.5 \\ \cite{gushchin2024adversarial}}  \\ 
        \cline{1,3-5}
        {\textbf{Discrete space} \\ $\mathcal{X}=\mathbb{S}^D$} &  & {DDSBM \wasyparagraph 3.1 \\ \cite{kim2024discrete}} & \SetCell[c=2]{c,m} \textbf{Our work} (\wasyparagraph\ref{sec-main}) \\
        \bottomrule
    \end{tblr}
    \caption{A summary of SB problem setups and existing (D-)IMF-related results. The table lists theoretical statements characterizing the SB solution (\textit{as the unique both Markovian and reciprocal process between two given distributions}) which allows to apply the IMF (D-IMF) procedure to provably get the SB solution $q^{*}$, see \citep[Theorem 8]{shi2023diffusion}. The table also lists related computational algorithms.}
    \label{tab:sb_setups}
\end{table*}

In practice, the most commonly considered case of dynamic SB is when $q^{\text{ref}}\in\mathcal{M}(\mathcal{X}^{N+2})\subset \mathcal{P}(\mathcal{X}^{N+2})$, i.e., $q^{\text{ref}}$ is a \textit{Markovian process}. In this case, the solution $q^{*}$ to SB is also known to be a Markovian process. This feature motivated the researchers to develop the \textit{Iterative Markovian Fitting} (IMF) procedure for solving SB based on Markovian and reciprocal projections of stochastic processes.

Originally, the procedure \citep{peluchetti2023diffusion,shi2023diffusion} was considered the continuous time $(N=\infty)$, but recently it has been extended to the finite amount of time moments \citep{gushchin2024adversarial}, i.e., $N<\infty$. We recall their definitions of the projections for finite $N$. In this case, the procedure is called the \textbf{D-IMF} (discrete-time IMF).

\paragraph{Reciprocal projection.} Consider a process $q\!\in\! \mathcal{P}(\mathcal{X}^{N+2})$. Then the reciprocal projection $\text{proj}_{\mathcal{R}^{\text{ref}}}(q)$ with respect to the reference process $q^{\text{ref}}$ is a process given by:
\begin{equation}
    \label{eq:recip_proj}
    \left[proj_{\mathcal{R}^{\text{ref}}}(q)\right](x_0, x_{\text{in}}, x_1) = q^{\text{ref}}(x_{\text{in}}| x_0, x_1)q(x_0, x_1)
    \nonumber.
\end{equation}

\paragraph{Markovian projection.} Consider a process ${q\!\in \!\mathcal{P}(\mathcal{X}^{N+2})}$. Then the Markovian projection $\text{proj}_{\mathcal{M}}(q)$ is given by:
\begin{multline}
    \left[proj_{\mathcal{M}}(q)\right](x_0, x_{\text{in}}, x_1) = \\ = \underbrace{q(x_0)\prod_{n=1}^{N+1}q(x_{t_{n}}|x_{t_{n-1}})}_{\text{forward representation}} = \\ = \underbrace{q(x_1)\prod_{n=1}^{N+1}q(x_{t_{n-1}}|x_{t_{n}})}_{\text{backward representation}}
    \label{eq:markov_proj}
\end{multline}

The reciprocal projection obviously preserves the joint distribution $q(x_0,x_1)$ of a process at time moments $t=0,1$. The Markovian projection, in general, alters $q(x_0,x_1)$ but preserves the joint distributions $\{q(x_{t_n},x_{t_{n-1}})\}_{n=1}^{N+1}$ at neighboring time moments and the marginal distributions $q(x_{t_{n}})$.

\textbf{The D-IMF procedure} is initialized with any process $q^0 \in \Pi_{N}(p_0, p_1)$. Then the procedure alternates between reciprocal $proj_{\mathcal{R}^{\text{ref}}}$ and Markovian $proj_{\mathcal{M}}$ projections:
\begin{equation}
    \label{eq:d_imf}
    \begin{gathered}
        q^{2l+1} = proj_{\mathcal{R}^{\text{ref}}}\left(q^{2l}\right),
        \\
        q^{2l+2} = proj_{\mathcal{M}}\left(q^{2l+1}\right).
    \end{gathered}
\end{equation}
Since both the Markovian and reciprocal projections preserve marginals $p_0,p_1$ at times $t=0,1$, respectively, we have that each $q^{l}\in\Pi_{N}(p_0,p_1)$. In certain configurations of $N$, $\mathcal{X}$, $q^{\text{ref}}$, IMF provably converges to the dynamic SB $q^{*}$ in KL, i.e., $\lim_{l\rightarrow\infty}\KL{q^{l}}{q^{*}}=0$. Specifically, the convergence easily follows from the generic proof argument in \citep[Theorem 8]{shi2023diffusion} \textit{as soon it is known that $q^{*}$ is the unique process in $\Pi_{N}(p_0,p_1)$ that is both Markovian and reciprocal}. We provide Table \ref{tab:sb_setups} summarizing the configurations for which this \textbf{characterization} of SB is known. We also list the related practical algorithms which implement the (D-)IMF procedure.

Finally, we would like to emphasize that the \textit{convergence rate of (D-)IMF procedure notably depends on the number $N$ of time steps}. In fact, for each $N$ it is its own separate procedure with different Markovian projection \eqref{eq:markov_proj}, see \citep[Figure 6a]{gushchin2024adversarial}.

\subsection{Object of Study}
As it is clear from Table \ref{tab:sb_setups}, for the setup with the discrete space $\mathcal{X}=\mathbb{S}^{D}$ and finite amount of time moments $N<\infty$, there is still no theoretical guarantee that the SB is the unique Markovian and reciprocal process. This leaves a large gap in D-IMF usage in this case, and we close it in our paper. 

At the same time, we note that there is a very recent IMF-based algorithm DDSBM \cite{kim2024discrete} for the discrete state space $\mathcal{X}$ but continuous time ($N=\infty$). However, since working with continuous time is infeasible in practice, the authors discretize the time grid to large finite $N$. Due to this, in fact, the authors apply the D-IMF procedure, although it still lacks any theoretical ground in this case. In contrast, our work shows that \textit{theoretically} even $N=1$ is enough.

\section{Categorical Schrödinger Bridge Matching}
\label{sec-main}
We start by establishing the convergence of the D-IMF framework ($N<\infty$) to the Schrödinger Bridge under a general Markov reference process (\wasyparagraph\ref{sec:theory}). Then we provide a practical optimization procedure and implementation details that illustrate the proposed method (\wasyparagraph\ref{sec:practice}).

\subsection{Theoretical Foundation}
\label{sec:theory}
The result of \citep[Theorem 3.6]{gushchin2024adversarial} characterizes the SB solution in $\mathcal{X}=\mathbb{R}^{D}$ and $N<\infty$ as the unique Markovian and Reciprocal process which allows the usage of D-IMF procedure. However, their proof works only for a specific reference process $q^{\text{ref}}=q^{W}$ induced by the Wiener process $W$ (EOT with the quadratic cost) and does not work for general Markov $q^{\text{ref}}$ or discrete $\mathcal{X}$.

Below we provide our main theoretical result for the \textit{discrete} space $\mathcal{X}$ and \textit{general} Markov reference process $q^{\text{ref}}$ which characterizes SB and immediately allows the usage of D-IMF ($N<\infty$) procedure to get it.\footnote{In fact, our proof argument can be applied to any $\mathcal{X}$, i.e., not only discrete allowing ASBM algorithm \citep{gushchin2024adversarial} for \textit{continuous} $\mathcal{X}=\mathbb{R}^{D}$ to be applied for general Markov $q^{\text{ref}}$.}

\begin{tcolorbox}[colback=gray!20, colframe=gray!20, arc=2mm, boxrule=0pt, width=1\linewidth, boxsep=-1pt]
\begin{theorem}[Characterization of the solution for the dynamic SB problem on a discrete space $\mathcal{X}$ with a Markovian reference $q^{\textup{ref}}$]
    \label{thm:main}
    Let $\mathcal{X}$ be a finite discrete space. Let $q^{\textup{ref}} \in \mathcal{M}(\mathcal{X}^{N+2})$ be a given reference Markov process. If $q^*\in \mathcal{P}(\mathcal{X}^{N+2})$ satisfies the following conditions:
    \begin{enumerate}
        \item $q^*(x_0) = p_0(x_0)$ and $q^*(x_1) = p_1(x_1)$, i.e., $q^{*}(p_0,p_1)$ is a \textbf{transport plan} from $\Pi(x_0, x_1)$;
        \item $q^{*}\in\mathcal{M}(\mathcal{X}^{N+2})$ and $q^{*}\in\mathcal{R}^{\textup{ref}}(\mathcal{X}^{N+2})$, i.e., $q^*$ satisfies both the \textbf{reciprocal} and \textbf{Markovian} properties;
    \end{enumerate}
    then $q^{*}$ is the unique solution of the dynamic SB \eqref{eq:disc_dyn_sb}.
\end{theorem}
\end{tcolorbox}

Our theorem immediately yields the following corollary.

\begin{corollary}[Convergence of D-IMF on discrete spaces]
    The sequence $\{q^{l}\}_{l=0}^{\infty}$ produced by the D-IMF procedure on a discrete space $\mathcal{X}$ and for a Markov reference process from the theorem above converges to $q^{*}$ in KL:
    $$\lim_{l\rightarrow\infty} \KL{q^{l}}{q^{*}}=0.$$
\end{corollary}

\subsection{Practical Implementation}
\label{sec:practice}

In this subsection, we discuss our computational algorithm to implement D-IMF and get SB problem solution $q^{*}$.

Since we consider a finite amount $N$ of time steps, the processes $q\in\mathcal{P}(\mathcal{X}^{N+2})$ are discrete-time Markov chains (DTMC). A DTMC is defined by $N+1$ transition matrices $Q_n$ of size $|\mathcal{X}|\times|\mathcal{X}|$, where $[Q_n]_{x_{t_{n-1}}x_{t_n}}$ represents the probability of transitioning from state $x_{t_{n-1}}$ to state $x_{t_n}$:
$$q(x_{t_n} | x_{t_{n-1}}) = [Q_n]_{x_{t_{n-1}}x_{t_n}}.$$
Thus, in theory, one can model any such DTMC $q$ explicitly. However, in practice, the size $|\mathcal{X}|$ may be large. In particular, we consider the case $\mathcal{X}=\mathbb{S}^{D}$, where $\mathbb{S}$ is a categorical space leading to exponential amount $S^{D}$ of elements in $\mathcal{X}$.

This raises two natural questions: \textbf{(a)} how to choose a reference process $q^{\text{ref}}$ and work with it? and \textbf{(b)} how to parameterize and update the process $q$ during D-IMF steps? Both these questions will be answered in the following generic discussion about the parameterization and implementation of reciprocal and Markovian projections.

\subsubsection{Implementing the reciprocal projection.} The reciprocal projection is rather straightforward if we can draw samples from our current process $q(x_0, x_1)$ and the reference bridge $q^{\text{ref}}(x_{t_{n-1}}|x_0,x_1)$. Indeed, generating a sample $(x_0,x_{t_{n-1}},x_1)\sim \left[proj_{\mathcal{R}^{\text{ref}}}(q)\right]$ is just merging these two.

\subsubsection{Choosing a reference process.} As it is clear from the paragraph above, it is reasonable to consider reference processes $q^{\text{ref}}\in\mathcal{M}(\mathcal{X}^{N+2})$ for which sampling from their bridge $q^{\text{ref}}(x_{t_{n-1}}|x_0,x_1)$ is easy.
We give two popular examples of $q^{\text{ref}}$ which appear in related work \cite{austin2021structured} that lead to practically meaningful cost $c$ for EOT \eqref{eq:eot}.

\paragraph{Case 1 (Uniform Reference $q^{\text{unif}}$).} Consider $D=1$ and assume that the set of categories $\mathbb{S}$ is unordered, e.g., atom types, text tokens, latent variables, etc. Define a process where the state remains in the current category $x_{t_{n-1}}$ with high probability, while the remaining probability is distributed uniformly among all other categories. 
This process $q^{\text{unif}}$ is called \emph{uniform} and has transitions matrices $Q_n$:
\begin{equation}
    [Q_{n}]_{x_{t_{n-1}}x_{t_n}}=\begin{cases}
        1 - \frac{S-1}{S} \alpha, & \text{if } x_{t_n} = x_{t_{n-1}}, \\
        \frac{1}{S} \alpha, & \text{if } x_{t_n} \neq x_{t_{n-1}},
    \end{cases}
\end{equation}
where $\alpha\in [0,1]$ is the \emph{stochasticity parameter} that controls the probability of transitioning to a different category.

\paragraph{Case 2 (Gaussian Reference $q^{\text{gauss}}$).} If we know that the categories are ordered, specifically, $\mathbb{S}=(1,2,\dots, S)$, and two neighboring categories are assumed to be related, the transitions may be chosen to reflect this. Consider the  \emph{Gaussian}-like reference process $q^{\text{gauss}}$ with $[Q_{n}]_{x_{t_{n-1}}x_{t_n}}=$
\begin{equation} 
    \begin{cases} 
        \frac{\exp\left(-\frac{4 (x_{t_n} - x_{t_{n-1}})^2}{(S-1)^2 \alpha}\right)}{\sum_{s=-(S-1)}^{(S-1)} \exp\left(-\frac{4 s^2}{(S-1)^2 \alpha}\right)}, & x_{t_n} \neq x_{t_{n-1}}, \\ 
        1 - \sum_{x_{t_n} \neq x_{t_{n-1}}} [Q_n]_{x_{t_{n-1}} x_{t_n}}, & x_{t_n} = x_{t_{n-1}},
    \end{cases} 
\end{equation}
where $\alpha>0$ is an analog of the variance parameter.

The construction of $q^{\text{unif}}$  (or $q^{\text{gauss}}$) generalizes to $D>1$ by combining several such independent processes (one per dimension). The bridges $q^{\text{ref}}(x_{\text{in}}|x_0,x_1)$ can be easily derived analytically and sampled thanks to the Markov property and the Bayes formula.

\subsubsection{Parameterization of the learnable process.} There are $|\mathbb{S}^D| = S^D$ possible states $x = (x^1, \dots, x^D)$ in the space, where $S$ is the number of categories for each variable. Consequently, each transition matrix $Q_n$ is of size ${S^D\times S^D}$, i.e., it grows exponentially in dimension $D$. Due to this, explicit modeling of transition matrices of the process we learn is computationally infeasible. We follow the standard practice in discrete generative models \citep{hoogeboom2021argmax, austin2021structured, gat2024discrete, campbell2024generative} and model the transition probability via combining two popular techniques: posterior sampling and factorization over the dimensions. Specifically, we first parameterize the transitions $q_{\theta}(x_{t_{n}} | x_{t_{n-1}})$ as follows
\begin{multline}
    q_{\theta}(x_{t_{n}} | x_{t_{n-1}}) = \mathbb{E}_{\widetilde{q_{\theta}}(\widetilde{x}_1 | x_{t_{n-1}})}\left[q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \widetilde{x}_1)\right],
    \label{parameterization}
\end{multline}
where $\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})$ is a learnable distribution. This parameterization assumes that sampling of $x_{t_n}$ given $x_{t_{n-1}}$ can be done by first sampling some ``endpoint'' $\widetilde{x}_1 \sim \widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})$, and then sampling from the bridge $q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \widetilde{x}_1)$. Second, the parameterization for $\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})$ is factorized:
$$
    \widetilde{q}_{\theta}(\widetilde{x}_{1} | x_{t_{n-1}})\approx\prod_{d=1}^{D}\widetilde{q}_{\theta}(\widetilde{x}_{1}^{d} | x_{t_{n-1}}).
$$
In this case, for each $x_{t_{n-1}}$, we just need to predict a row-stochastic $D\times S$ matrix of probabilities $\widetilde{q}_{\theta}(\widetilde{x}_{1}^{d} | x_{t_{n-1}})$. Following the common practices, we employ a neural network $S^{D}\rightarrow D\times S$ which outputs a row-stochastic matrix for each input $x_{t_{n-1}}$. Since, in fact, we need $N+1$ neural nets to to do the prediction of endpoints at each time step, we simply use a single neural network with an extra input $n$.

\subsubsection{Implementing the Markovian projection.} The Markovian projection is a little bit more complex than the reciprocal one and requires learning a process. From \wasyparagraph\ref{sec:imf}, the goal of the projection is to find a Markov process whose transition probabilities match those of the given reciprocal process $q$. Fortunately, we show that this can be achieved by minimizing an objective that closely resembles the optimization of the variational bound used in diffusion models \cite{ho2020denoising, austin2021structured, hoogeboom2021argmax}. 

\begin{proposition}  
    \label{prop:markov_proj}
    Let $q\in\mathcal{R}^{\textup{ref}}(\mathcal{X}^{N+2})$ be a given reciprocal process. Then, the Markovian projection $proj_{\mathcal{M}}(q) \in \mathcal{M}(\mathcal{X}^{N+2})$ can be obtained by minimizing:  
    \begin{multline}  
        \label{eq:decomp}
        L(m) \stackrel{\textup{def}}{=} \mathbb{E}_{q(x_0,x_1)}\Bigg[\sum_{n=1}^{N}\mathbb{E}_{q^{\textup{ref}}(x_{t_{n-1}} | x_0, x_1)} \\   
         \textup{KL}\left(q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1) || m(x_{t_{n}} | x_{t_{n-1}})\right) - \\ -\mathbb{E}_{q^{\textup{ref}}(x_{t_N} | x_0, x_1)}\left[\log m(x_1 | x_{t_N})\right]\Bigg], 
    \end{multline}  
    among the Markov processes $m\in \mathcal{M}(\mathcal{X}^{N+2})$. Furthermore, this objective is also equivalent to optimizing $\sum_{n=1}^{N+1}\textup{KL}\left(q^{\textup{ref}}(x_{t_{n}} | x_{t_{n-1}}) || m(x_{t_{n}} | x_{t_{n-1}})\right)$.
\end{proposition}

\begin{algorithm}[t]
   \caption{Categorical SB matching (CSBM)}
   \label{alg:csbm}
    \begin{algorithmic}
        {\Require number of intermediate time steps $N$; \\
        number of outer iteration $K \in \mathbb{N}$; \\
        initial coupling $q^0(x_{0}, x_1)$; \\
        reference process $q^{\text{ref}}$.
        }
        {\Ensure forward model $q_{\theta}(x_{t_{n}}|x_{t_{n-1}})$; \\
        backward model $q_{\eta}(x_{t_{n-1}|x_{t_{n}}})$.}
        \For{$k = 0$ {\bfseries to} $K-1$}
            \State {\bfseries Forward step} (repeat until convergence){\bfseries:} 
            \State \quad Sample $n \sim U[1, N+1]$;
            \State \quad Sample $(x_0, x_1) \sim p_1(x_1)q_\eta(x_0 | x_1)$;
            \State \quad Sample $x_{t_{n-1}} \sim q^{\text{ref}}(x_{t_{n-1}} | x_0, x_1)$;
            \State \quad Train $q_\theta$ by minimizing $L_\theta$ \eqref{eq:forward_loss};
            \State {\bfseries Backward step} (repeat until convergence){\bfseries:}
            \State \quad Sample $n \sim U[1, N+1]$;
            \State \quad Sample $(x_0, x_1) \sim p_0(x_0)q_\theta(x_1 | x_0)$;
            \State \quad Sample $x_{t_{n}} \sim q^{\text{ref}}(x_{t_{n}} | x_0, x_1)$;
            \State \quad Train $q_\eta$ by minimizing $L_\eta$ \eqref{eq:backward_loss};
        \EndFor
    \end{algorithmic}
    \vspace{-0.5mm}
\end{algorithm}
\vspace{-0.5mm}

Note that the key distinction from standard losses in diffusion models, such as \citep[Equation 1]{austin2021structured}, lies in the sampling of $x_{t_{n-1}}$. Instead of drawing from the noising process $q^{\text{ref}}(x_{t_{n-1}} | x_1)$, it is sampled from the reference bridge distribution $q^{\text{ref}}(x_{t_{n-1}} | x_0, x_1)$. As a result, with the proposed parametrization and Markovian projection representation, we can effectively apply the learning methodology from D3PM \cite{austin2021structured}. The explicit \underline{loss formulation} is provided in Appendix \ref{apx:explicit_loss}.

\textbf{3.2.5. Practical implementation of the D-IMF procedure.} With the reciprocal and Markovian projections fully established, we now proceed to the implementation of the D-IMF procedure. This method is conventionally applied in a bidirectional manner \cite{shi2023diffusion, gushchin2024adversarial}, incorporating both forward and backward representations \eqref{eq:markov_proj}. This is because training in a unidirectional manner has been shown to introduce an error in IMF \citep[Appendix I]{de2024schr}. Therefore, we follow a bidirectional approach, which naturally leads to the \textbf{Categorical Schrödinger Bridge Matching (CSBM)} Algorithm \ref{alg:csbm}.

\section{Experimental Illustrations}
We evaluate our proposed CSBM algorithm across several setups. To begin with, we show how our CSBM approach works with different reference processes in illustrative 2D experiments (\wasyparagraph\ref{sec:toy_exp}). Next, we test the ability of CSBM to translate images on colored MNIST dataset (\wasyparagraph\ref{sec:cmnist_exp}) and consider the different number of steps $N$. Finally, we present an experiment with the CelebA dataset (\wasyparagraph\ref{sec:celeba_exp}) showing the capabilities of CSBM in a discrete latent space. The \underline{experiments details} are given in Appendix \ref{apx:aspects}.

\subsection{Illustrative 2D experiments}
\label{sec:toy_exp}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/input.png}
        \caption{\centering ${x\sim p_0}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/target.png}
        \caption{\centering ${x\sim p_1}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/csbm_gaus_0.02.png}
        \caption{\centering Low stochasticity, $q^{\text{gauss}}$\newline$\alpha=0.02$}
        \label{fig:toy_gaus_low}
    \end{subfigure}
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/csbm_gaus_0.05.png}
        \caption{\centering High stochasticity, $q^{\text{gauss}}$\newline$\alpha=0.05$}
        \label{fig:toy_gaus_high}
    \end{subfigure}
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/csbm_unif_0.005.png}
        \caption{\centering Low stochasticity, $q^{\text{unif}}$\newline$\alpha=0.005$}
        \label{fig:toy_unif_low}
    \end{subfigure}
    \begin{subfigure}[b]{0.46\linewidth}
        \centering
        \includegraphics[width=0.995\linewidth]{toy/csbm_unif_0.01.png}
        \caption{\centering High stochasticity, $q^{\text{unif}}$\newline$\alpha=0.01$}
        \label{fig:toy_unif_high}
    \end{subfigure}
    \caption{SB between 2D \textit{Gaussian} and \textit{Swiss Roll} distributions learned by our CSBM algorithm with different reference processes $q^{\text{unif}}$ and $q^{\text{gauss}}$ with varying parameters $\alpha$.}
    \label{fig:toy_images}
    \vspace{-4mm}
\end{figure}

Here we examine the impact of the reference processes $q^{\text{gauss}}$ and $q^{\text{unif}}$. The initial distribution $p_0$ is a 2-dimensional Gaussian, while the target distribution $p_1$ is a Swiss roll. Both are discretized into $S = 50$ categories, i.e., we work in $2$-dimensional categorical space with $|\mathcal{X}|=S^{2}=50\times 50$ number of  points. We train CSBM with $N = 10$ intermediate steps with different stochasticity parameters $\alpha$ in $q^{\text{ref}}$. For $q^{\text{gauss}}$, we test $\alpha \in \{0.02, 0.05\}$. In the case of $q^{\text{unif}}$ we use $\alpha \in \{0.01, 0.005\}$.

Figure \ref{fig:toy_images} demonstrates that the increase of parameter $\alpha$ increases the number of jumps. In the case of $q^{\text{gauss}}$, the jumps mostly happen only to neighboring categories (Figures \ref{fig:toy_gaus_low} and \ref{fig:toy_gaus_high}). In the case of $q^{\text{unif}}$, the jumps happen to all categories (Figures \ref{fig:toy_unif_low} and \ref{fig:toy_unif_high}). This is aligned with the construction of the reference processes.

\subsection{Unpaired Translation on Colored MNIST}
\label{sec:cmnist_exp}
Here, we work with the MNIST dataset with randomly colored digits. Inspired by \citep[Appendix C.3]{gushchin2024adversarial}, we consider an unpaired translation problem between classes ``2'' and ``3'' of digits. In our case, we work in the discrete space of images but not continuous. Specifically, each pixel is represented using three 8-bit channels (RGB), i.e., $S=256$, and the data space is of size $256^{D}$, where $D=32\times 32\times 3$. The goal of this experiment is to evaluate the capability of CSBM to perform unpaired translation with different numbers of intermediate steps $N$. Since each color channel values have an inherent order, we utilize the Gaussian reference process $q^{\text{gauss}}$ with $\alpha = 0.01$. 

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.08\textwidth}
        \centering
        \includegraphics[width=0.58\linewidth]{cmnist/cmnist_pics_orig_vert.png}
        \caption{$x \sim p_0$}
    \end{subfigure}
    \begin{subfigure}[b]{0.18\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_2.png}
        \caption{$N=2$}
    \end{subfigure}
    \begin{subfigure}[b]{0.18\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_4.png}
        \caption{$N=4$}
    \end{subfigure}
    \\
    \vspace{1mm}
    \begin{subfigure}[b]{0.08\textwidth}
        \centering
        \includegraphics[width=0.58\linewidth]{cmnist/cmnist_pics_orig_vert.png}
        \caption{$x \sim p_0$}
    \end{subfigure}
    \begin{subfigure}[b]{0.18\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_10.png}
        \caption{$N=10$}
    \end{subfigure}
    \begin{subfigure}[b]{0.18\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_25.png}
        \caption{$N=25$}
    \end{subfigure}
    \caption{\centering Results of unpaired translation between colored digits ``3'' and ``2'' learned by our CSBM algorithm with reference process $q^{\text{gauss}}$ and varying number of time moments $N$.}
    \label{fig:cmnist_images}
    \vspace{-4mm}
\end{figure}

The results in Figure \ref{fig:cmnist_images} suggest that even with a low $N=2$, the generated outputs maintain decent visual quality and preserve the image color. However, some pixelation appears in the generated digits ``2''. This is likely due to the factorization of the learned process. The effect slightly diminishes as $N$ increases which points to a trade-off between the simplicity of the factorized model and its capacity to capture inter-feature dependencies.

\subsection{Unpaired Translation of CelebA Faces}
\label{sec:celeba_exp}
\begin{figure*}[t]
    \centering
    \begin{minipage}{0.01\textwidth}
        \centering
        \vspace{-60mm}
        \rotatebox{90}{\textbf{Low stochasticity}}
    \end{minipage}
    \begin{subfigure}[b]{0.11\textwidth}
        \centering
        \includegraphics[width=0.652\linewidth]{celeba/celeba_128_f_start_data_samples.png}
        \caption{\centering ${x\sim p_0}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/csbm_0.005.png}
        \caption{\centering CSBM (\textbf{ours})}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/asbm_celeba_128_samples_eps_1.png}
        \caption{\centering ASBM \cite{gushchin2024adversarial}}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{images/celeba/dsbm_celeba_128_samples_eps_1_imf_5.png}
        \caption{\centering DSBM \cite{shi2023diffusion}}
    \end{subfigure}
        \begin{minipage}{0.01\textwidth}
        \centering
        \vspace{-60mm}
        \rotatebox{90}{\textbf{High stochasticity}}
    \end{minipage}
    \begin{subfigure}[b]{0.11\textwidth}
        \centering
        \includegraphics[width=0.652\linewidth]{celeba/celeba_128_f_start_data_samples.png}
        \caption{\centering ${x\sim p_0}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/csbm_0.01.png}
        \caption{CSBM (\textbf{ours})}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/asbm_celeba_128_samples_eps_10.png}
        \caption{\centering ASBM \cite{gushchin2024adversarial}}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{images/celeba/dsbm_celeba_128_samples_eps_10_imf_5.png}
        \caption{\centering DSBM \cite{shi2023diffusion}}
    \end{subfigure}

    \caption{\centering Comparison of \textit{male} $\rightarrow$ \textit{female} translation on the CelebA $128 \times 128$ dataset using CSBM (ours), ASBM, and DSBM. The low-stochasticity setting for CSBM corresponds to $\alpha=0.005$, while the high-stochasticity setting corresponds to $\alpha=0.01$. The stochasticity parameters for ASBM and DSBM are taken from \cite{gushchin2024adversarial}.}
    \label{fig:celeba_images}
\end{figure*}  

Here, we present an unpaired image-to-image translation experiment on the CelebA dataset using vector quantization. Specifically, we focus on translating images from the \textit{male} to the \textit{female} domain. We train VQ-GAN autoencoder \cite{esser2021taming} to represent $128\times 128$ images as $D=256$ features with $S=1024$ categories (a.k.a. the codebook). This formulation reduces complexity, as the data to be modeled has a dimensionality of $S^{D}=1024^{256}$. Indeed, this is smaller than the raw colored MNIST image space (\wasyparagraph\ref{sec:cmnist_exp}) and considerably smaller than the raw pixel space of CelebA. As there is no clear relation between the elements of the codebook, we use uniform reference $q^{\text{ref}}$. We test $\alpha\in\{0.005, 0.01\}$ and $N=100$.

For completeness, we compare our CSBM method with CSBM with ASBM \cite{gushchin2024adversarial} and DSBM \cite{shi2023diffusion} which operate in the continuous data space. We take their results from \citep[\wasyparagraph 4.2]{gushchin2024adversarial}. Qualitatively, we achieve comparable visual results (Figure \ref{fig:celeba_images}). Notably, the background remains nearly identical across all images for CSBM, which is not the case for all other methods, especially in setups with high stochasticity.

\begin{table}[h]
    \vspace{-2mm}
    \caption{Metrics comparison of CSBM (\textbf{ours}), \citep[ASBM]{gushchin2024adversarial}, and \citep[DSBM]{shi2023diffusion} for unpaired \textit{male} $\rightarrow$ \textit{female} translation on the CelebA $128 \times 128$ dataset.}
    \centering
    \resizebox{\columnwidth}{!}{
    \begin{tblr}{rcccccc}
        \toprule
         & \SetCell[c=3]{c} Low stochasticity & & & \SetCell[c=3]{c} High stochasticity \\
        \cline[0.8pt]{2-4} \cline[0.8pt]{5-7}
        Metric & {CSBM \\ $\alpha=0.005$} & {ASBM \\ $\epsilon=1$} & {DSBM \\ $\epsilon=1$} & {CSBM \\ $\alpha=0.01$} & {ASBM \\ $\epsilon=10$} & {DSBM \\ $\epsilon=10$} \\
        \midrule  
        FID ($\downarrow$) & \textbf{10.60} & 16.86 & 24.06 & \textbf{14.68} & 17.44 & 92.15 \\
        \midrule
        CMMD ($\downarrow$) & \textbf{0.165} & 0.216 & 0.365 & \textbf{0.212} & 0.231 & 1.140 \\
        \bottomrule
    \end{tblr}}
    \label{tab:metrics}
    \vspace{-3mm}
\end{table}

The standard FID \citep{heusel2017gans} \& CMMD \citep{jayasumana2024rethinking} metric comparison in Table \ref{tab:metrics} quantitatively demonstrates that our approach achieves better results than the other methods. Still, it is important to note that our experiments are conducted with $N=100$ in D-IMF, which is higher than the $N = 3$ used in continuous-space D-IMF in ASBM, i.e., the trade-off between the number of time steps $N$ and the generation quality should be taken into account.

\section{Discussion}
\paragraph{Limitations.} One limitation of the proposed algorithm stems from the factorization of the transitional probabilities (see \wasyparagraph\ref{sec:practice}). This simplification comes at the cost of losing some information, as dependencies between features at the same step are not explicitly accounted for. However, it should be taken into account that this limitation is inherent to all modern flow-based \cite{campbell2024generative, gat2024discrete} and diffusion-based \cite{hoogeboom2021argmax, austin2021structured} methods for discrete data.

\textbf{Impact Statement}.
This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here.


\bibliography{references}
\bibliographystyle{icml2025}

\newpage
\appendix
\onecolumn

\section{Proofs}
\label{apx:proofs}
\begin{proof}[Proof of Theorem \ref{thm:main}]
    As stated in the theorem, we consider a process $q(x_0, x_{\text{in}}, x_1) \in \Pi_{N}(p_0, p_1)$  with $N \geq 1$ intermediate time steps which are both Markov and reciprocal and a reference process $q^{\text{ref}}
    \in\mathcal{M}(\mathcal{X}^{N+2})$. We focus on the joint distribution of the boundary elements $x_0$, $x_1$, and a selected intermediate state $x_{t_n}$, where $n \in [1, N]$. This distribution, $p(x_0, x_{t_n}, x_1)$, can be expressed in two equivalent ways: one using the Markov property and the other using the reciprocal property:
    \begin{equation}
        \underbrace{q(x_0, x_1)q^{\text{ref}}(x_{t_n} | x_0, x_1)}_{\text{by reciprocal property}} = q(x_0, x_{t_n}, x_1) = \underbrace{p(x_0)q(x_{t_n} | x_0)q(x_1 | x_{t_n})}_{\text{by Markov property}}.
    \end{equation}
    
    Rearranging this equation and applying logarithm thus we get:
    \begin{equation}
        \log q(x_1|x_0) = \log q(x_t|x_0) + \log q(x_1|x_{t_n}) - \log q^{\text{ref}}(x_{t_n}|x_0, x_1)
    \end{equation}

    The knowledge that the last term $\log q^{\text{ref}}(x_{t_n}|x_0, x_1)$ is Markov leads to following equation:
    \begin{multline}
        \log q(x_1|x_0) = \log q(x_{t_n}|x_0) + \log q(x_1|x_{t_n}) - \log \left(\frac{ q^{\text{ref}}(x_0)q^{\text{ref}}( x_{t_n}|x_0)q^{\text{ref}}( x_1|x_{t_n}))}{q^{\text{ref}}(x_0, x_1)}\right)= \\ = \underbrace{\log q(x_{t_n}|x_0) - \log q^{\text{ref}}( x_{t_n}|x_0)- \log q^{\text{ref}}(x_0)}_{f_0(x_0,x_{t_n})} + \underbrace{\log q(x_1|x_{t_n}) - \log q^{\text{ref}}( x_1|x_{t_n})}_{f_1(x_{t_n},x_1)} + \log q^{\text{ref}}(x_0, x_1).
    \end{multline}

    Thus we get:
    \begin{equation}
        \label{eq:sum_of_f}
        f(x_0, x_1) = \log q(x_1|x_0) - \log q^{\text{ref}}(x_0, x_1) = f_0(x_0,x_{t_n}) + f_1(x_{t_n},x_1).
    \end{equation}

    Notably, $f(x_0, x_1)$ depends only on $x_0$ and $x_1$. This follows from setting $x_1 = x^{\dagger}$ in \eqref{eq:sum_of_f}, where $x^{\dagger}\in\mathcal{X}$ is some fixed point in the state space. Indeed, we have
    \begin{equation}
        \underbrace{f(x_0, x_1) - \overbrace{f(x_0, x^{\dagger})}^{g_0(x_0)}}_{g_1(x_1)} = \cancel{f_0(x_0, x_{t_n})} + f_1(x_{t_n}, x_1) - \cancel{f_0(x_0, x_{t_n})} - f_1(x_{t_n}, x^{\dagger}) = f_1(x_{t_n}, x_1) - f_1(x_{t_n}, x^{\dagger}).
    \end{equation}
    
    Thus, we obtain:  
    \begin{equation}
        \log q(x_1 | x_0) = g_0(x_0) + g_1(x_1) + \log q^{\text{ref}}(x_0, x_1).
    \end{equation}
    
    Exponentiating both sides and multiplying by $p(x_0)$, we derive:  
    \begin{equation}
        q(x_0, x_1) = \underbrace{e^{g_0(x_0)}}_{\psi(x_0)} q^{\text{ref}}(x_1 | x_0) \underbrace{e^{g_1(x_1)}}_{\phi(x_1)}.
    \end{equation}
    
    According to \citep[Theorem 2.8]{leonard2013survey}, this formulation describes the optimal transport plan $q^*$ for the Static Schrödinger Bridge problem between $p_0$ and $p_1$. Given that the assumption of the theorem ensures $q(x_{\text{in}} | x_0, x_1) = q^{\text{ref}}(x_{\text{in}} | x_0, x_1)$, it follows that $q(x_0, x_{\text{in}}, x_1)$ is a dynamic Schrödinger Bridge $q^*(x_0, x_{\text{in}}, x_1)$.
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:markov_proj}]
    Thanks to \citep[Proposition 3.5]{gushchin2024adversarial}, it is known that
    \begin{equation}
        [proj_{\mathcal{M}}(q)](x_0, x_{\text{in}}, x_1) = \argmin_{m\in\mathcal{M}(\mathcal{X}^{N+2})} \KL{q(x_0, x_{\text{in}}, x_1)}{m(x_0, x_{\text{in}}, x_1)},
    \end{equation}
    where $q \in \mathcal{R}^{\text{ref}}(\mathcal{X}^{N+2})$ is a reciprocal process. Thus, we can decompose this KL divergence as follows:
    \begin{multline}
        \label{eq:decomp_eq_1}
        \KL{q(x_0, x_{\text{in}}, x_1)}{m(x_0, x_{\text{in}}, x_1)} = \mathbb{E}_{q(x_0, x_{\text{in}}, x_1)} \log \frac{q(x_0, x_{\text{in}}, x_1)}{m(x_0, x_{\text{in}}, x_1)} \\
        = \mathbb{E}_{q(x_0, x_{\text{in}}, x_1)} \log \frac{{\color{blue} p_0(x_0)} q(x_1 | x_0) \color{violet} q^{\text{ref}}(x_{\text{in}} | x_0, x_1)}{\color{blue} m(x_0) \color{red} m(x_1 | x_{t_N}) \color{violet} \prod_{n=1}^{N} m(x_{t_{n}} | x_{t_{n-1}})}.
    \end{multline}
    Here, the denominator holds because $m$ is a Markov process, while the numerator holds because $q$ is a reciprocal process. Next, we separate the corresponding colored terms, leading to:
    \begin{multline}
        \label{eq:decomp_eq_2}
        \eqref{eq:decomp_eq_1} = \underbrace{\color{red} -\mathbb{E}_{q(x_0, x_{t_1}, x_1)}\left[\log m(x_1 | x_{t_N})\right]}_{\color{red}L_1} + {\color{violet} \mathbb{E}_{q(x_0, x_{\text{in}}, x_1)} \log \frac{\color{violet} \prod_{n=1}^{N} q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, x_1)}{\prod_{n=1}^{N} m(x_{t_{n}} | x_{t_{n-1}})}} + \\ + \underbrace{\color{blue} \KL{p_0(x_0)}{m(x_0)}}_{\color{blue} L_0} + \underbrace{\left( - \mathbb{E}_{q(x_1, x_0)} \left[ \log q(x_1 | x_0) \right] \right)}_{C_1}.
    \end{multline}
    
    Rewriting the product inside the logarithm ({\color{violet} violet term}) as a sum of KL divergences, we obtain the following equation:
    \begin{equation}
        \label{eq:decomp_eq_3}
        \eqref{eq:decomp_eq_2} = {\color{red}L_1}+{\color{violet}\sum_{n=1}^{N} \mathbb{E}_{q(x_1, x_{t_{n-1}}, x_{t_n})} \KL{q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, x_1)}{m(x_{t_{n}} | x_{t_{n-1}})}} + {\color{blue}L_0} + C_1.
    \end{equation}
    
    We observe that, by construction, the Markov process $m$ preserves the terminal distribution when represented in a forward manner \eqref{eq:markov_proj}, i.e., $m(x_0) = p_0(x_0)$. Consequently, {\color{blue}$L_0$} can be omitted since $\text{KL} = 0$, which completes the proof:
    \begin{equation}
        \eqref{eq:decomp_eq_3} = {\color{red}L_1} + {\color{violet} \sum_{n=1}^{N}  \mathbb{E}_{q(x_1, x_{t_{n}}, x_{t_{n-1}})} \text{KL}(q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, x_1) \parallel m(x_{t_{n}} | x_{t_{n-1}}))} + C_1.
    \end{equation}
    
    Additionally, we demonstrate that this minimization objective seeks to align the conditional distributions between neighboring time steps $x_t$ with those of the given reciprocal process $q$. To achieve this, we revisit \eqref{eq:decomp_eq_1} and express the reference process in the reverse direction:
    \begin{multline}
        \label{eq:decomp_eq_4}
        \eqref{eq:decomp_eq_1} = \mathbb{E}_{q(x_0, x_{\text{in}}, x_1)} \log \frac{{\color{blue} p_0(x_0)} q(x_1 | x_0) \color{violet} q^{\text{ref}}(x_{\text{in}} | x_0, x_1)}{\color{blue} m(x_0) \color{red} m(x_{t_1} | x_0) \color{violet} \prod_{n=2}^{N+1} m(x_{t_{n}} | x_{t_{n-1}})} = \\ = {\color{red} -\mathbb{E}_{q(x_0, x_{t_{1}})}\left[\log m(x_{t_{1}} | x_0)\right]} + {\color{violet} \mathbb{E}_{q(x_0, x_{\text{in}}, x_1)} \log \frac{\color{violet} \prod_{n=2}^{N+1} q^{\text{ref}}(x_{t_{n-1}} | x_{t_{n}}, x_0)}{\prod_{n=2}^{N+1} m(x_{t_{n}} | x_{t_{n-1}})}} + {\color{blue} L_0} + C_1.
    \end{multline}
    
    Using Bayes' theorem and Markov property of $q^{\text{ref}}$ we can rewrite conditional distribution in following manner:
    \begin{equation}
        q^{\text{ref}}(x_{t_{n-1}} | x_{t_{n}}, x_0) = \frac{q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \cancel{x_0})q^{\text{ref}}(x_{t_{n-1} | x_0})}{q^{\text{ref}}(x_{t_{n}} | x_0)}.
    \end{equation}
    
    Thus, substituting it into \eqref{eq:decomp_eq_5}, factoring out $q^{\text{ref}}(x_{t_{n}} | x_0)$ and $q^{\text{ref}}(x_{t_{n-1}} | x_0)$ as constants, and finally expressing the logarithm of a product as the sum of logarithms, we obtain:
    \begin{multline}
        \label{eq:decomp_eq_5}
        \eqref{eq:decomp_eq_4} = {\color{red} -\mathbb{E}_{q(x_0, x_{t_{1}})}\left[\log m(x_{t_{1}} | x_0)\right]} + {\color{violet} \sum_{n=2}^{N+1}  \mathbb{E}_{q(x_{t_{n-1}}, x_{t_n})} \KL{q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}})}{m(x_{t_{n}} | x_{t_{n-1}})}} + \\ + {\color{blue} L_0} + \underbrace{\sum_{n=2}^{N+1}\mathbb{E}_{q(x_0, x_{t_{n-1}}, x_{t_n})}\log\left(\frac{q^{\text{ref}}(x_{t_{n-1}} | x_0)}{q^{\text{ref}}(x_{t_{n}} | x_0)}\right) + C_1}_{C_2}.
    \end{multline}
    
    Finally, we introduce a zero term:  
    \begin{equation}
        {\color{red} \mathbb{E}_{q^{\text{ref}}(x_0, x_{t_{1}})}\left[\log q^{\text{ref}}(x_{t_{1}} | x_0)\right]} - \mathbb{E}_{q(x_0, x_{t_{1}})}\left[\log q^{\text{ref}}(x_{t_{1}} | x_0)\right] = 0
    \end{equation}
    where the {\color{red} red terms} are combined to account for the missing $n = 1$ element in the {\color{violet} violet term}:
    \begin{multline}
        \label{eq:decomp_eq_6}
        \eqref{eq:decomp_eq_5} = {\color{red} \mathbb{E}_{q(x_0, x_{t_{1}})}\KL{q^{\text{ref}}(x_{t_{1}}| x_0)}{m(x_{t_{1}} | x_0)}} + {\color{violet} \sum_{n=2}^{N+1}  \mathbb{E}_{q(x_{t_{n-1}}, x_{t_{n}})} \KL{q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}})}{m(x_{t_{n}} | x_{t_{n-1}})}} + \\ + {\color{blue} L_0} + \underbrace{C_2 - \mathbb{E}_{q(x_0, x_{t_{1}})}\left[\log q^{\text{ref}}(x_{t_{1}} | x_0)\right]}_{C_3} = \\ = {\color{violet} \sum_{n=1}^{N+1}  \mathbb{E}_{q(x_{t_{n}}, x_{t_{n-1}})} \KL{q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}})}{m(x_{t_{n}} | x_{t_{n-1}})}} + {\color{blue} L_0} + C_3.
    \end{multline}

    Similarly, we discard {\color{blue} $L_0$}, leaving us with an objective that minimizes the divergence between the given reference process $p^{\text{ref}}$ and the desired Markov process $m$.
\end{proof}

\section{Experiment details}
\subsection{Loss function of CSBM} 
\label{apx:explicit_loss}

In this section, we focus on the optimization procedure for our considered parameterization \eqref{parameterization}, i.e., when we substitute $m=q_{\theta}$ in \eqref{eq:decomp}. Indeed let us start by combining both equations:
\begin{multline}
    L(m) \defeq \mathbb{E}_{q(x_0,x_1)}\Bigg[\sum_{n=1}^{N}\mathbb{E}_{q^{\textup{ref}}(x_{t_{n-1}} | x_0, x_1)} \\ 
    \textup{KL}\left(q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1) || \mathbb{E}_{\widetilde{q_{\theta}}(\widetilde{x}_1 | x_{t_{n-1}})}\left[q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \widetilde{x}_1)\right]\right) - \\ 
    -\mathbb{E}_{q^{\textup{ref}}(x_{t_N} | x_0, x_1)}\left[\log \widetilde{q}_\theta(x_1 | x_{t_N})\right]\Bigg].
\end{multline}

Let us consider the first term, the KL divergence, particularly:
\begin{multline}
    \label{eq:kl}
    \text{KL}(\cdot) = \mathbb{E}_{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}\left[\log\frac{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}{\mathbb{E}_{\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})}\left[q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \widetilde{x}_1)\right]}\right] \leq \\
    \leq \mathbb{E}_{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}\left[\log q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1) - \mathbb{E}_{\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})}\left[\log q^{\text{ref}}(x_{t_{n}} | x_{t_{n-1}}, \widetilde{x}_1)\right]\right] = \\
    = \mathbb{E}_{\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})}\mathbb{E}_{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}\left[\log\frac{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},\widetilde{x}_1)}\right] = \mathbb{E}_{\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})} \KL{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},\widetilde{x}_1)},
\end{multline}
where the inequality holds due to Jensen's inequality.

From \eqref{eq:kl}, we observe that the only scenario where the KL divergence is zero is when $x_1 = \widetilde{x}_1$. Therefore, minimizing the KL divergence requires $\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})$ to concentrate all its probability mass on the true $x_1$. This leads to the following objective:
$$
L_{\text{simple}} = - \mathbb{E}_{q^{\textup{ref}}(x_{t_{n-1}} | x_0, x_1)}\left[\log \widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})\right],
$$ 
as noted in \cite{austin2021structured}, and is conceptually similar to the simplified objective introduced in \cite{ho2020denoising, austin2021structured} for diffusion models.

Thus, applying the reparametrization from \eqref{parameterization} and incorporating $L_{\text{simple}}$ with a weighting factor $\lambda$, we obtain:
\begin{multline}
    \label{eq:forward_loss}
    L(\theta) = \mathbb{E}_{q(x_0,x_1)}\Bigg[\sum_{n=1}^{N}\mathbb{E}_{q^{\textup{ref}}(x_{t_{n-1}} | x_0, x_1)} \mathbb{E}_{\widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})} \\ 
    \KL{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},x_1)}{q^{\textup{ref}}(x_{t_{n}}|x_{t_{n-1}},\widetilde{x}_1)} - \lambda\overbrace{\log \widetilde{q}_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})}^{L_{\text{simple}}} \\ 
    -\mathbb{E}_{q^{\textup{ref}}(x_{t_N} | x_0, x_1)}\left[\log \widetilde{q}_\theta(x_1 | x_{t_N})\right]\Bigg].
\end{multline}

Importantly, adding $L_{\text{simple}}$ into the objective \eqref{eq:forward_loss} does not violate the conditions of D-IMF. Since $L_{\text{simple}}$ is specifically designed to minimize the error in predicting the noise component while maintaining the probabilistic structure of the generative process, its inclusion does not introduce inconsistencies or deviations in the D-IMF procedure.

Since the backward decomposition of $m$ also holds for Proposition \ref{eq:decomp}, we can similarly derive the loss for the backward parametrization. In this case, we use a neural network with parameters $\eta$ to predict $x_0$:
\begin{multline}
    \label{eq:backward_loss}
    L(\eta) = \mathbb{E}_{q(x_0,x_1)}\Bigg[\sum_{n=2}^{N+1}\mathbb{E}_{q^{\textup{ref}}(x_{t_{n}} | x_0, x_1)} \mathbb{E}_{\widetilde{q}_{\eta}(\widetilde{x}_0 | x_{t_{n}})} \\ 
    \KL{q^{\textup{ref}}(x_{t_{n-1}}|x_{t_{n}},x_0)}{q^{\textup{ref}}(x_{t_{n-1}}|x_{t_{n}},\widetilde{x}_0)} - \lambda\overbrace{\log \widetilde{q}_{\eta}(\widetilde{x}_0 | x_{t_{n}})}^{L_{\text{simple}}} \\ 
    -\mathbb{E}_{q^{\textup{ref}}(x_{t_1} | x_0, x_1)}\left[\log \widetilde{q}_\eta(x_0 | x_{t_1})\right]\Bigg].
\end{multline}

For further details on the training process, we refer the reader to \cite{austin2021structured}.

\subsection{Training aspects}  
\label{apx:aspects}
For the implementation of the training logic, we use the official D3PM repository \cite{austin2021structured} as a reference:
\begin{center}
    \url{https://github.com/google-research/google-research/tree/master/d3pm}
\end{center}

\paragraph{Shared training aspects.}  For all experiments, we use the AdamW optimizer with fixed betas of $0.95$ and $0.99$. Additionally, we apply Exponential Moving Average (EMA) smoothing to stabilize training and enhance final model performance. The EMA decay rate is consistently tuned across all experiments and set to $0.999$, except for the Colored MNIST experiment, where it is set to $0.9999$. For all experiments, we set the weighting factor of $L_\text{simple}$ to $0.001$.

For the 2D and colored MNIST experiment, we follow the preprocessing approach from \cite{austin2021structured}, where the logits of $q_{\theta}(\widetilde{x}_1 | x_{t_{n-1}})$ are modeled directly as the output of a neural network. Specifically, we represent $x_{t_{n-1}}$ using both integer and one-hot encodings, denoted as $x_{t_{n-1}}^{\text{int}}$ and $x_{t_n}^{\text{one-hot}}$, respectively. The logits are computed as:  
\begin{equation}
    \text{logits} = \text{nn}_{\theta}(\text{normalize}(x_{t_{n-1}}^{\text{int}})) + x_{t_{n-1}}^{\text{one-hot}},
\end{equation}
where $\text{normalize}(x_{t_{n-1}}^{\text{int}})$ maps integer values $\{0, \dots, S-1\}$ to the range $[-1, 1]$, ensuring numerical stability before being processed by the neural network.

Notably, various previous works have introduced different initial couplings $q^0(x_0, x_1)$, such as the standard independent coupling $p_0(x_0) p_1(x_1)$ \cite{shi2023diffusion, gushchin2024adversarial}, couplings derived from a reference process, e.g., $p_0(x_0) q^{\text{ref}}(x_1 | x_0)$ \cite{shi2023diffusion} and mini-batch OT couplings referred as MB, i.e. discrete Optimal Transport solved on mini-batch samples \cite{tong2024simulation}. For a more comprehensive overview of coupling strategies, see \cite{kholkin2024diffusion}. In this work, we focus exclusively on the independent and mini-batch coupling.

\paragraph{Experiment-specific training aspects.} For the \textbf{2D experiment} (\wasyparagraph\ref{sec:toy_exp}), we use a simple MLP model with hidden layers of size $[128, 128, 128]$ and ReLU activations. To condition on time, we use a simple lookup table, i.e., an embedding layer of size $2$ from PyTorch.

For the \textbf{colored MNIST experiment} (\wasyparagraph\ref{sec:cmnist_exp}), we follow \cite{austin2021structured} and use an architecture based on a PixelCNN++ backbone \cite{salimans2016improved}, utilizing a U-Net \cite{ronneberger2015u} with a ResNet-like structure. The model operates at four feature map resolutions, with two convolutional residual blocks per resolution level and a channel multiplier of $(1, 2, 2, 2)$. At the $16 \times 16$ resolution level, a self-attention block is incorporated between the convolutional blocks. For time encoding, we apply Transformer sinusoidal position embeddings to each residual block. We train the model on a training subset of size $60,000$ and generate images from the hold-out set.

For the \textbf{CelebA experiment}, we employ VQ-Diffusion \cite{gu2022vector}, which consists of two models: VQ-GAN \cite{esser2021taming} and a transformer-based diffusion model. The VQ-GAN component is trained using the official GitHub repository:
\begin{center} 
    \url{https://github.com/CompVis/taming-transformers}
\end{center}

We slightly modify the experimental setup of unconditional generation for CelebAHQ from \cite{esser2021taming} by reducing the number of resolution levels to three, with scaling factors of $(1, 2, 4)$. This adjustment accounts for our use of CelebA at $128 \times 128$ resolution, compared to $256 \times 256$ in CelebAHQ.

The diffusion model is adopted from the following GitHub repository:
\begin{center} 
    \url{https://github.com/microsoft/VQ-Diffusion}
\end{center}

Our diffusion model consists of multiple transformer blocks, each incorporating full attention and a feed-forward network (FFN). We follow the small model configuration from \cite{gu2022vector}, which consists of 18 transformer blocks with an increased channel size of 256. The FFN is implemented using two convolutional layers with a kernel size of 3, and the channel expansion rate is set to 2. Additionally, we inject time step information through the AdaLN operator.

We train the model on $162770$ prequantized images of celebrities. For evaluation, we compute FID and CMMD using $11816$ images to ensure consistency with the evaluation protocol from \cite{gushchin2024adversarial}. Likewise, the images presented in the main text of the paper are generated using this hold-out set.

The rest hyperparameters are presented in Table \ref{tab:hyperparams}.

\begin{table}[t]
    \centering
    \begin{tblr}{colspec={Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]|Q[c,m]}}
        \toprule
        Experiment & {Initial \\ coupling} & {D-IMF \\ outer iterations} & {D-IMF=0 \\ grad updates} & {D-IMF \\ grad updates} & $N$ & {Batch \\ size} & Lr & Params \\
        \midrule
        2D & Ind & $10$ & $400000$ & $40000$ & $10$ & $512$ & $0.0004$ &  46588 \\
        \hline
        Colored MNIST & MB & $3$ & $200000$ & $40000$ & {$2, 4,$ \\ $10, 25$} & $128$ & $0.0002$  & 34m \\
        \hline
        CelebA & Ind & $4$ & $800000$ & $40000$ & $100$ & $32$ & $0.0004$  & {93m \\ + \\ 70m} \\
        \bottomrule
    \end{tblr}
    \caption{Hyperparameters for experiments. Lr denotes the learning rate, and \textit{m} represents millions. Params indicate the number of model parameters, where for the CelebA dataset, the first value corresponds to the model and the second to the VQ-GAN.}
    \label{tab:hyperparams}
\end{table}

\paragraph{Computational Time.} Training the 2D experiment requires several hours on a single A100 GPU. The colored MNIST experiment takes approximately two days to train using two A100 GPUs. The most computationally demanding task, the CelebA experiment, requires around five days of training on four A100 GPUs.

\subsection{Additional results}

\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.098\textwidth}
        \centering
        \includegraphics[width=0.58\linewidth]{cmnist/cmnist_pics_orig_vert_backward.png}
        \caption{$x \sim p_1$}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_2_backward.png}
        \caption{$N=2$}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_4_backward.png}
        \caption{$N=4$}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_10_backward.png}
        \caption{$N=10$}
    \end{subfigure}
    \begin{subfigure}[b]{0.22\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{cmnist/csbm_25_backward.png}
        \caption{$N=25$}
    \end{subfigure}
    \caption{\centering Results of unpaired translation between colored digits ``2'' and ``3'' learned by our CSBM algorithm with reference process $q^{\text{gauss}}$ and varying number of time moments $N$.}
    \label{fig:cmnist_images_backward}
\end{figure}

\begin{figure*}[!t]
    \centering
    \begin{minipage}{0.01\textwidth}
        \centering
        \vspace{-60mm}
        \rotatebox{90}{\textbf{Low stochasticity}}
    \end{minipage}
    \begin{subfigure}[b]{0.11\textwidth}
        \centering
        \includegraphics[width=0.652\linewidth]{celeba/celeba_128_b_start_data_samples.png}
        \caption{\centering ${x\sim p_0}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/csbm_0.005_backward.png}
        \caption{\centering CSBM (\textbf{ours})}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/asbm_b_celeba_128_samples_eps_1.png}
        \caption{\centering ASBM \cite{gushchin2024adversarial}}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/dsbm_b_celeba_128_samples_eps_1.png}
        \caption{\centering DSBM \cite{shi2023diffusion}}
    \end{subfigure}
        \begin{minipage}{0.01\textwidth}
        \centering
        \vspace{-60mm}
        \rotatebox{90}{\textbf{High stochasticity}}
    \end{minipage}
    \begin{subfigure}[b]{0.11\textwidth}
        \centering
        \includegraphics[width=0.652\linewidth]{celeba/celeba_128_b_start_data_samples.png}
        \caption{\centering ${x\sim p_0}$}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/csbm_0.01_backward.png}
        \caption{CSBM (\textbf{ours})}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/asbm_b_celeba_128_samples_eps_10.png}
        \caption{\centering ASBM \cite{gushchin2024adversarial}}
    \end{subfigure}
    \begin{subfigure}[b]{0.285\textwidth}
        \centering
        \includegraphics[width=0.995\linewidth]{celeba/dsbm_b_celeba_128_samples_eps_10.png}
        \caption{\centering DSBM \cite{shi2023diffusion}}
    \end{subfigure}

    \caption{\centering Comparison of \textit{female} $\rightarrow$ \textit{male} translation on the CelebA $128 \times 128$ dataset using CSBM (ours), ASBM, and DSBM. The low-stochasticity setting for CSBM corresponds to $\alpha=0.005$, while the high-stochasticity setting corresponds to $\alpha=0.01$. The stochasticity parameters for ASBM and DSBM are taken from \cite{gushchin2024adversarial}.}
    \label{fig:celeba_images_backward}
\end{figure*}  

\begin{figure*}
    \includegraphics[width=0.995\linewidth]{celeba/csbm_traj_0.01.png}
    \caption{\centering \textit{male} $\rightarrow$ \textit{female} translation trajectories on the CelebA $128 \times 128$ dataset using CSBM with $\alpha = 0.01$. Each column corresponds to time moments $0$, $10$, $25$, $50$, $75$, $90$, and $101$.}
\end{figure*}

\begin{figure*}
    \includegraphics[width=0.995\linewidth]{celeba/csbm_traj_0.005.png}
    \caption{\centering \textit{male} $\rightarrow$ \textit{female} translation trajectories on the CelebA $128 \times 128$ dataset using CSBM with $\alpha = 0.005$. Each column corresponds to time moments $0$, $10$, $25$, $50$, $75$, $90$, and $101$.}
\end{figure*}

\begin{figure*}
    \includegraphics[width=0.995\linewidth]{celeba/csbm_traj_0.01_backward.png}
    \caption{\centering \textit{female} $\rightarrow$ \textit{male} translation trajectories on the CelebA $128 \times 128$ dataset using CSBM with $\alpha = 0.01$. Each column corresponds to time moments $0$, $10$, $25$, $50$, $75$, $90$, and $101$.}
\end{figure*}

\begin{figure*}
    \includegraphics[width=0.995\linewidth]{celeba/csbm_traj_0.005_backward.png}
    \caption{\centering \textit{female} $\rightarrow$ \textit{male} translation trajectories on the CelebA $128 \times 128$ dataset using CSBM with $\alpha = 0.005$. Each column corresponds to time moments $0$, $10$, $25$, $50$, $75$, $90$, and $101$.}
\end{figure*}

\end{document}