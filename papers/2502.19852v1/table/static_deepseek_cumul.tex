\begin{table*}[htb!]
    \centering
    \caption{CC-Recall on \oursstatic logs of DeepSeek-Coder-6.7B-Instruct in \ourslive. The dashed line separates the closed-source (above) and open-source (below) LLMs. For each column, Bold and underscore mean $1$st and $2$nd performance among the same source.\footnotemark[7]}
    \small
    \begin{tabular}{lccccccccccccccc}
        \thickhline
        \small Compilation Feedback & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\
        \small Execution Feedback & \small \cmark & \small \cmark & \xmark & \small \cmark & \small \cmark \\ 
        \small Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        \small Simulated User Feedback & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\ 
        \small User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \small GPT-4-0613 & 82.5 & \underline{131.0} & \underline{81.6} & \textbf{96.8} & \underline{99.5}\\
        \small GPT-4-Turbo-2024-04-09 & \underline{89.9} & 127.8 & 77.8 & 87.8 & 90.1\\
        \small GPT-4o-2024-05-13 & \textbf{96.0} & \textbf{132.7} & \textbf{82.9} & \underline{96.7} & \textbf{99.8}\\\hdashline
        \small DeepSeek-Coder-V2-Lite-Instruct & \textbf{24.5} & \phantom{0}\textbf{43.3} & \underline{47.2} & \textbf{57.8} & \textbf{55.1}\\
        \small CodeQwen1.5-7B-Chat & \underline{12.9} & \phantom{0}\underline{27.6} & 41.9 & \underline{47.4} & 45.4\\
        \small CodeLlama-7B-Instruct-hf & \phantom{0}6.4 & \phantom{0}10.3 & 33.9 & 39.3 & 32.2\\
        \small ReflectionCoder-DS-6.7B & 11.9 & \phantom{0}26.2 & 45.0 & 49.8 & 46.4\\
        \rowcolor{gray!10}
        \small DeepSeek-Coder-6.7B-Instruct (ref.) & \phantom{0}7.7 & \phantom{0}12.5 & \textbf{47.5} & 47.1 & \underline{47.8}\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_cumul_pass_gain_static}
\end{table*}