\begin{table*}[h]
    \subsubsection{Reference Model: GPT-4-0613}
    \centering
    \caption{MRR and Recall results on \oursstatic using logs of GPT-4-0613 in \ourslive. {\protect\xmark} indicates that no feedback of that type is provided ($\phi$). 
    For each column, bold and underscore indicate $1$st and $2$nd place performance within the same model group.}
    \scriptsize
    \begin{tabular}{lccccccccccccccc}
        \thickhline
        & \multicolumn{5}{c}{\multirow{1.4}{*}{MRR}} & \multicolumn{5}{c}{\multirow{1.4}{*}{Recall}} \\
        \cmidrule(lr){2-6} \cmidrule(lr){7-11}
        Compilation Feedback  & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ \\
        Execution Feedback & $f_e$ & $f_e^*$ & \xmark & $f_e$ & $f_e^*$ & $f_e$ & $f_e^*$ & \xmark & $f_e$ & $f_e^*$ \\ 
        % Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        Verbal Feedback & $f_v$ & $f_v$ & $f_v^*$ & $f_v^*$ & $f_v^*$ & $f_v$ & $f_v$ & $f_v^*$ & $f_v^*$ & $f_v^*$ \\\hline
        % User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \multicolumn{11}{c}{Closed-Source Models}\\
        GPT-4-Turbo-2024-04-09 & \underline{60.3} & \underline{64.1} & \underline{69.9} & \underline{70.9} & \underline{71.6} & \underline{67.2} & \underline{76.7} & \underline{91.6} & \underline{92.8} & \underline{94.2}\\
        GPT-4o-2024-05-13 & \textbf{61.6} & \textbf{65.0} & \textbf{70.6} & \textbf{71.5} & \textbf{72.3} & \textbf{68.6} & \textbf{77.2} & \textbf{91.9} & \textbf{93.0} & \textbf{94.3}\\\hdashline
        \multicolumn{11}{c}{Open-Source Models ($\geq 30\textrm{B}$)}\\
        Llama-3.1-70B-Instruct & \textbf{60.9} & \textbf{64.2} & \textbf{69.9} & \textbf{70.9} & \textbf{71.5} & \textbf{68.8} & \textbf{77.7} & \textbf{92.2} & \textbf{93.5} & \textbf{94.6}\\
        DeepSeek-Coder-33B-Instruct & 58.3 & 61.9 & 68.2 & 69.3 & 69.9 & \underline{66.5} & \underline{75.9} & 91.9 & 93.2 & 94.3\\
        ReflectionCoder-DS-33B & \underline{58.9} & \underline{62.4} & \underline{68.8} & \underline{70.0} & \underline{70.3} & \underline{66.5} & \underline{75.9} & 91.8 & \underline{93.3} & \underline{94.5}\\
        Qwen1.5-72B-Chat & 57.5 & 60.4 & 67.3 & 68.3 & 69.1 & 66.0 & 73.9 & 91.5 & 92.5 & 94.2\\
        Qwen1.5-32B-Chat & 56.6 & 60.6 & 66.8 & 67.6 & 67.7 & 65.4 & 75.7 & 91.4 & 92.7 & 92.9\\
        CodeLlama-34B-Instruct & 56.2 & 59.9 & 66.8 & 67.8 & 68.4 & 64.7 & 74.8 & \textbf{92.2} & 93.1 & 94.4\\\hdashline
        \multicolumn{11}{c}{Open-Source Models ($< 30\textrm{B}$)}\\
        Llama-3.1-8B-Instruct & 56.9 & 60.6 & 67.4 & 68.3 & 68.9 & 65.4 & 74.8 & 91.8 & 92.8 & 94.3\\
        DeepSeek-Coder-V2-Lite-Instruct & \underline{58.8} & \textbf{62.4} & \textbf{68.9} & \textbf{69.7} & \underline{70.1} & \underline{66.4} & \underline{75.5} & 91.8 & 92.6 & 93.9\\
        DeepSeek-Coder-6.7B-Instruct & 57.5 & 61.1 & 67.4 & 68.7 & 69.2 & 65.7 & \underline{75.5} & 91.2 & \textbf{93.1} & \textbf{94.4}\\
        ReflectionCoder-DS-6.7B & 57.9 & 61.5 & 68.0 & 69.1 & 69.7 & 65.7 & 75.2 & \textbf{91.9} & \underline{93.0} & 94.1\\
        CodeQwen1.5-7B-Chat & \textbf{59.0} & \textbf{62.4} & \underline{68.5} & \underline{69.6} & \textbf{70.2} & \textbf{67.1} & \textbf{76.1} & 91.8 & 92.9 & \textbf{94.4}\\
        % \rowcolor{gray!10}
        % CodeLlama-7B-Instruct (ref.) & 23.5 & 25.2 & 35.0 & 33.4 & 33.9\\
        StarCoder2-15B-Instruct-v0.1 & 58.3 & 61.8 & 68.0 & 68.9 & 69.7 & 66.0 & 75.3 & 91.2 & 92.5 & 94.0\\
        CodeLlama-13B-Instruct & 56.1 & 59.9 & 66.4 & 67.5 & 68.1 & 64.9 & 74.6 & 91.5 & 92.6 & \textbf{94.4}\\
        CodeLlama-7B-Instruct  & 54.8 & 58.4 & 65.5 & 66.4 & 67.0 & 63.7 & 73.4 & \textbf{91.9} & 92.5 & 93.6\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_static_gpt4o}
\end{table*}