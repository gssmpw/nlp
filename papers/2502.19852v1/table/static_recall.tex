\begin{table*}[htb!]
    \subsection{C-Recall Results}
    \label{appendix:static_recall}
    \caption{C-Recall results on \oursstatic logs of DeepSeek-Coder-6.7B-Instruct in \ourslive. The dashed line separates the closed-source (above) and open-source (below) LLMs. For each column, Bold and underscore mean $1$st and $2$nd performance among the same source.\footnotemark[7]}
    \centering
    \small
    \begin{tabular}{lccccccccccccccc}
        \\
        \thickhline
        \small Compilation Feedback  & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\
        \small Execution Feedback & \small \cmark & \small \cmark & \xmark & \small \cmark & \small \cmark \\ 
        \small Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        \small Simulated User Feedback & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\ 
        \small User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \small GPT-4-0613 & \underline{61.8} & \textbf{68.9} & \textbf{89.9} & \textbf{90.6} & \textbf{91.0}\\
        \small GPT-4-Turbo-2024-04-09 & 61.7 & 68.3 & 89.0 & 89.9 & 90.0\\
        \small GPT-4o-2024-05-13 & \textbf{63.1} & \textbf{68.9} & \underline{89.8} & \underline{90.1} & \underline{90.5}\\\hdashline
        \small DeepSeek-Coder-V2-Lite-Instruct & \textbf{56.4} & \textbf{61.7} & \underline{86.2} & \textbf{87.1} & \textbf{87.7}\\
        \small CodeQwen1.5-7B-Chat & \underline{55.2} & \underline{60.8} & 86.1 & \underline{86.8} & \underline{87.4}\\
        \small CodeLlama-7B-Instruct-hf & 48.9 & 53.2 & \textbf{86.3} & 86.1 & 85.4\\
        \small ReflectionCoder-DS-6.7B & 52.5 & 56.9 & 85.8 & 85.9 & 86.4\\
        \rowcolor{gray!10}
        \small DeepSeek-Coder-6.7B-Instruct (ref.) & 43.3 & 48.2 & 82.8 & 82.5 & 83.1\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_recall_static}
\end{table*}

\begin{table*}[htb!]
    \centering
    \caption{C-Recall results on \oursstatic logs of CodeLlama-7B-Instruct-hf in \ourslive. The dashed line separates the closed-source (above) and open-source (below) LLMs. For each column, Bold and underscore mean $1$st and $2$nd performance among the same source.\footnotemark[7]}
    \small
    \begin{tabular}{lccccccccccccccc}
        \thickhline
        \small Compilation Feedback  & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\
        \small Execution Feedback & \small \cmark & \small \cmark & \xmark & \small \cmark & \small \cmark \\ 
        \small Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        \small Simulated User Feedback & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\ 
        \small User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \small GPT-4-0613 & 59.5 & 65.7 & 85.9 & \textbf{82.3} & 83.1\\
        \small GPT-4-Turbo-2024-04-09 & \underline{61.8} & \textbf{68.2} & \textbf{86.8} & 81.4 & \underline{84.2}\\
        \small GPT-4o-2024-05-13 & \textbf{62.1} & \underline{68.1} & \underline{86.2} & \underline{81.9} & \textbf{84.7}\\\hdashline
        \small DeepSeek-Coder-V2-Lite-Instruct & \textbf{51.1} & \textbf{55.6} & \textbf{82.0} & 74.7 & \underline{77.9}\\
        \small CodeQwen1.5-7B-Chat & \underline{49.1} & \underline{53.2} & 78.0 & 74.1 & 76.3\\
        \rowcolor{gray!10}
        \small CodeLlama-7B-Instruct-hf (ref.)  & 26.2 & 30.5 & 61.7 & 53.9 & 55.2\\
        \small ReflectionCoder-DS-6.7B & 46.7 & 51.6 & 79.3 & \underline{74.8} & 75.9\\
        \small DeepSeek-Coder-6.7B-Instruct & 46.8 & 52.9 & \underline{81.3} & \textbf{77.5} & \textbf{78.7}\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_recall_static_codellama}
\end{table*}

\begin{table*}[htb!]
    \caption{C-Recall results on \oursstatic logs of GPT-4-0613 in \ourslive. The dashed line separates the closed-source (above) and open-source (below) LLMs. For each column, Bold and underscore mean $1$st and $2$nd performance among the same source.\footnotemark[7]}
    \centering
    \small
    \begin{tabular}{lccccccccccccccc}
        \thickhline
        \small Compilation Feedback  & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\
        \small Execution Feedback & \small \cmark & \small \cmark & \xmark & \small \cmark & \small \cmark \\ 
        \small Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        \small Simulated User Feedback & \small \cmark & \small \cmark & \small \cmark & \small \cmark & \small \cmark \\ 
        \small User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \rowcolor{gray!10}
        \small GPT-4-0613 (ref.) & 61.9 & 72.5 & 89.7 & 91.1 & 92.5\\
        \small GPT-4-Turbo-2024-04-09 & \underline{67.2} & \underline{76.7} & \underline{91.6} & \underline{92.8} & \underline{94.2}\\
        \small GPT-4o-2024-05-13 & \textbf{68.6} & \textbf{77.2} & \textbf{91.9} & \textbf{93.0} & \textbf{94.3}\\\hdashline
        \small DeepSeek-Coder-V2-Lite-Instruct & \underline{66.4} & \underline{75.5} & 91.8 & 92.6 & 93.9\\
        \small CodeQwen1.5-7B-Chat & \textbf{67.1} & \textbf{76.1} & 91.8 & 92.9 & \textbf{94.4}\\
        \small CodeLlama-7B-Instruct-hf & 63.7 & 73.4 & \textbf{91.9} & 92.5 & 93.6\\
        \small ReflectionCoder-DS-6.7B & 65.7 & 75.2 & \textbf{91.9} & \underline{93.0} & 94.1\\
        \small DeepSeek-Coder-6.7B-Instruct & 65.7 & \underline{75.5} & 91.2 & \textbf{93.1} & \textbf{94.4}\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_recall_static_gpt4o}
\end{table*}

