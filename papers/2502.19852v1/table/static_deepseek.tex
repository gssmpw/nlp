\begin{table*}[htb!]
    \section{\oursstatic}
    \label{appendix:convcodebench}
    \subsection{MRR and Recall Results}
    \subsubsection{Reference Model: DeepSeek-Coder-6.7B-Instruct}
    \centering
    \caption{MRR and Recall results on \oursstatic using logs of DeepSeek-Coder-6.7B-Instruct in \ourslive. {\protect\xmark} indicates that no feedback of that type is provided ($\phi$). 
    For each column, bold and underscore indicate $1$st and $2$nd place performance within the same model group.}
    \scriptsize
    \begin{tabular}{lccccccccccccccc}
        \thickhline
        & \multicolumn{5}{c}{\multirow{1.4}{*}{MRR}} & \multicolumn{5}{c}{\multirow{1.4}{*}{Recall}} \\
        \cmidrule(lr){2-6} \cmidrule(lr){7-11}
        Compilation Feedback  & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ & $f_c$ \\
        Execution Feedback & $f_e$ & $f_e^*$ & \xmark & $f_e$ & $f_e^*$ & $f_e$ & $f_e^*$ & \xmark & $f_e$ & $f_e^*$ \\ 
        % Test Coverage & \scriptsize part. &\scriptsize full &  &\scriptsize part. &\scriptsize full \\ 
        Verbal Feedback & $f_n$ & $f_n$ & $f_n^*$ & $f_n^*$ & $f_n^*$ & $f_n$ & $f_n$ & $f_n^*$ & $f_n^*$ & $f_n^*$ \\\hline
        % User Expertise & \scriptsize novice & \scriptsize novice & \scriptsize expert & \scriptsize expert & \scriptsize expert \\\hline
        \multicolumn{11}{c}{Closed-Source Models}\\
        GPT-4-0613 & 56.2 & 59.1 & 66.9 & 67.4 & 68.2 & \underline{61.8} & \textbf{68.9} & \textbf{89.9} & \textbf{90.6} & \textbf{91.0}\\
        GPT-4-Turbo-2024-04-09 & \underline{57.4} & \underline{60.1} & \underline{67.6} & \underline{68.3} & \underline{69.0} & 61.7 & 68.3 & 89.0 & 89.9 & 90.0\\
        GPT-4o-2024-05-13 & \textbf{58.8} & \textbf{61.3} & \textbf{69.0} & \textbf{69.3} & \textbf{70.2} & \textbf{63.1} & \textbf{68.9} & \underline{89.8} & \underline{90.1} & \underline{90.5}\\\hdashline
        \multicolumn{11}{c}{Open-Source Models ($\geq 30\textrm{B}$)}\\
        Llama-3.1-70B-Instruct & \textbf{57.2} & \textbf{59.2} & \textbf{67.2} & \textbf{67.7} & \textbf{68.5} & \textbf{62.3} & \textbf{67.0} & \textbf{89.4} & \textbf{89.7} & \textbf{90.4}\\
        DeepSeek-Coder-33B-Instruct & 52.4 & 54.0 & 63.4 & 64.4 & \underline{65.3} & 56.2 & 60.7 & 86.8 & 87.8 & 88.6\\
        ReflectionCoder-DS-33B & \underline{52.6} & \underline{54.7} & \underline{64.0} & \underline{64.5} & \underline{65.3} & \underline{56.4} & \underline{62.0} & 86.8 & 87.8 & 88.2\\
        Qwen1.5-72B-Chat & 49.1 & 52.0 & 61.4 & 61.9 & 62.7 & 54.6 & 61.8 & \underline{87.6} & \underline{88.2} & \underline{88.8}\\
        Qwen1.5-32B-Chat & 48.6 & 50.8 & 60.4 & 59.9 & 60.1 & 54.1 & 59.2 & 86.3 & 84.8 & 84.8\\
        CodeLlama-34B-Instruct & 47.2 & 48.8 & 60.6 & 61.1 & 61.6 & 51.7 & 56.4 & 87.4 & \underline{88.2} & 88.2\\\hdashline
        \multicolumn{11}{c}{Open-Source Models ($< 30\textrm{B}$)}\\
        Llama-3.1-8B-Instruct & 50.6 & 52.5 & 62.3 & 62.8 & 63.4 & \underline{55.8} & \underline{61.2} & \textbf{87.3} & \textbf{88.3} & \textbf{88.2}\\
        DeepSeek-Coder-V2-Lite-Instruct & \textbf{52.4} & \textbf{54.4} & \textbf{63.1} & \textbf{63.8} & \textbf{64.7} & \textbf{56.4} & \textbf{61.7} & 86.2 & \underline{87.1} & \underline{87.7}\\
        % DeepSeek-Coder-6.7B-Instruct & \\
        ReflectionCoder-DS-6.7B & 48.5 & 50.2 & 61.0 & 61.2 & 61.8 & 52.5 & 56.9 & 85.8 & 85.9 & 86.4\\
        CodeQwen1.5-7B-Chat & \underline{51.5} & \underline{53.6} & \underline{62.8} & \underline{63.5} & \underline{64.0} & 55.2 & 60.8 & 86.1 & 86.8 & 87.4\\
        % \rowcolor{gray!10}
        StarCoder2-15B-Instruct-v0.1 & 49.7 & 51.7 & 62.3 & 62.2 & 62.8 & 52.9 & 58.1 & \underline{86.6} & 85.9 & 86.6\\
        CodeLlama-13B-Instruct & 47.4 & 49.3 & 60.4 & 60.4 & 61.1 & 51.8 & 56.8 & \underline{86.6} & 86.2 & 87.4\\
        CodeLlama-7B-Instruct & 44.2 & 45.7 & 57.9 & 57.9 & 58.3 & 48.9 & 53.2 & 86.3 & 86.1 & 85.4\\
        \thickhline
    \end{tabular}
    \normalsize
    \label{tab:convcodebench_static_deepseek}
\end{table*}

