\section{Related Work}
%
\label{sec:related-work}

\subsection{Fault Localization}%
\label{sub:related-fault-localization}

Fault localization is a critical area in software debugging.
It aims to pinpoint the exact locations in the code responsible for failures.
Several traditional techniques have been extensively studied, particularly statistical methods that introduce similarity coefficients such as \TARANTULA{}~\cite{jones2005tarantula}, \OCHIAI{}~\cite{abreu2006ochiai}, \DSTAR{}~\cite{wong2012dstar}, \GP{}~\cite{xie2013gp}, \AMPLE{}~\cite{dallmeier2005ample}, \JACCARD{}~\cite{chen2002jaccard}, and many others.
Spectrum-based fault localization (SBFL) techniques, including those mentioned, are especially notable for using execution traces to estimate the likelihood that specific code elements are faulty statistically.
In recent years, these techniques have gained traction in automated debugging, particularly within automatic program repair frameworks, where they significantly contribute to identifying code regions for repair~\cite{qi2013apr,lutellier2020coconut}.

Other research in this area has shifted the focus from using lines as the unit for localization to other coverage-based information.
Zhang et al.~\cite{zhang2009capturing} examined basic blocks, Le et al.~\cite{le2010path} investigated paths, Jiang et al.~\cite{jiang2023variable} leveraged variables and decision trees, and Vancsics et al.~\cite{vancsics2021calls} considered call frequency.
Ribeiro et al.~\cite{ribeiro2019dataflow} used data flow for localizing faults.
The work by Yu et al.~\cite{yu2011models} leverages data and control dependency models to calculate suspiciousness scores.
In contrast, Yan et al.~\cite{yan2023context} employ traditional SBFL but modify the scores afterward based on the context in which the fault propagates.
Other approaches do not consider coverage of the traditional SBFL.
Soremekun et al.~\cite{soremekun2021slicing} present an approach that builds on program slices for localization, while Papadakis et al.~\cite{papadakis2014mutation,papadakis2015mutation} leverage mutation analysis.

The extensive research in this area has led to numerous metrics designed to assess the correlation between code locations and failures~\cite{daniel2013sbfl,landsberg2015sfl,naish2011sbfl}.
Parnin et al.~\cite{parnin2011automated} critically evaluate these techniques and question their practical applicability for developers.
They conclude that while these approaches can reduce the search space, they often overwhelm developers with numerous potential fault locations, making pinpointing the exact faulty lines challenging.
Another comprehensive survey by Soremekun et al.~\cite{soremekun2023evaluating} investigates general assumptions of fault localization, finding that most developers would prefer a diagnosis to locations for debugging.
Other studies, such as those by Abreu et al.~\cite{abreu2009practical}, Pearson et al.~\cite{pearson2017sfl}, Heiden et al.~\cite{heidengkkhfl19}, and Widyasari et al.~\cite{widyasari2022sfl}, have evaluated fault localization techniques across different benchmarks to assess their effectiveness and limitations.
In contrast to our work, they did not consider multiple features in their evaluation but concentrated on lines as the unit of measure for localization.

Beyond traditional fault localization, recent research has expanded to leverage these techniques in novel ways.
For instance, Le et al.~\cite{lelgg16} use a learning-to-rank-based approach that integrates knowledge from mined likely invariants~\cite{ernstpgmptx07} to prioritize functions that are more likely to be the cause of faults.
Additionally, approaches like \ENTBUG{}~\cite{camposafd13} utilize fault localization to drive test generation, incorporating localization metrics into the fitness of a genetic test generator.

Considering how statistical fault localization needs to execute the entire test suite to provide relevant code locations, Jiang et al.~\cite{jiangzctc12} explore how test case prioritization could improve the process.
Yoo et al.~\cite{yoo2013priorization} and Gonzales-Sanchez et al.~\cite{gonzalez-sanchezagg11} build an approach that applies prioritization not only to reduce execution time but also to enhance fault localization results.
Gong et al.~\cite{gongwsm13} directly reduce the test suite to achieve similar improvements.
In contrast, Xuan et al.~\cite{xuanm14b} purify test cases by splitting them into smaller parts, providing more granular insights, and leveraging these purified tests to improve statistical fault localization.
Moreover, test generation can also enhance fault localization results.
For example, Artzi et al.~\cite{artzidtp10b} show that generating directed test cases maximizing the similarity between path constraints of generated tests and those of faulty executions outperforms undirected generation.
While our approach seeks to maximize execution differences, the concept aligns with test generation methodologies.

With the rise of machine learning techniques, researchers have explored using various learning techniques for fault localization~\cite{li2019deepfl,li2021covrepresentation,widyasari2022xai4fl,wang2024mtltransfer,yang2024multilingual,li2022cc}.
Notably, feature-based fault localization approaches by Lei et al.~\cite{lei2022featurefl} abstract program behaviors as features, while Meng et al.~\cite{meng2022transfer} leverage semantic features.
Additionally, research has investigated the impact of large language models on fault localization~\cite{kang2024llm}.

This body of work highlights both the progress made in fault localization and the challenges that remain, particularly in enhancing the practical utility and precision of these techniques for developers.


\subsection{Feature-based Debugging}%
\label{sub:related-execution-features}

Recent research also uses \emph{features} for deriving debugging diagnoses.
\ALHAZEN{}~\cite{kampmann2020alhazen} was one of the first approaches that leveraged features for debugging.
The approach learns a decision tree from a set of \emph{input features} and iteratively refines the tree by generating new inputs that aim to trigger the failure.
From the decision tree, \ALHAZEN{} derives a diagnosis.
Similar to \ALHAZEN{}, \AVICENNA{}~\cite{eberlein2023avicenna} leverages \emph{input features} for debugging.
It follows the same refinement loop but leverages a sophisticated constraint learner to derive a diagnosis and generates new inputs by solving these constraints.

In contrast, our work opens the field for \emph{execution-feature-driven debugging} that can generate diagnoses explaining the actual program behavior that leads to a failure, providing a more comprehensive understanding of the failure while \ALHAZEN{} and \AVICENNA{} focus on the input space that is not as useful for debugging as the execution space.
However, our approach can, at this point, not effortlessly generate new inputs to trigger the failure since we cannot directly map the execution features to the input space, but this is mitigated by the fact that \ALHAZEN{} and \AVICENNA{} require a specification of the input space. In contrast, our approach runs out-of-the-box on any program.
We believe that \ALHAZEN{} or \AVICENNA{} would complement our approach.