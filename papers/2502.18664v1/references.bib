
@InProceedings{	  6624018,
  author	= {Herzig, K. and Zeller, A.},
  booktitle	= {Mining Software Repos. (MSR), 2013 10th IEEE Working
		  Conference on},
  title		= {The impact of tangled code changes},
  year		= {2013},
  doi		= {10.1109/MSR.2013.6624018},
  issn		= {2160-1852},
  month		= {May}
}

@InProceedings{	  abreu2006evaluation,
  author	= {Abreu, Rui and Zoeteweij, Peter and Van Gemund, Arjan
		  J.c.},
  booktitle	= {2006 12th Pacific Rim International Symposium on
		  Dependable Computing (PRDC'06)},
  title		= {An Evaluation of Similarity Coefficients for Software
		  Fault Localization},
  year		= {2006},
  volume	= {},
  number	= {},
  pages		= {39-46},
  keywords	= {Fault diagnosis;Software debugging;Software
		  reliability;Computer bugs;Embedded system;Software
		  testing;System testing;Particle
		  measurements;Mathematics;Computer science},
  doi		= {10.1109/PRDC.2006.18}
}

@InProceedings{	  abreu2006ochiai,
  author	= {Abreu, Rui and Zoeteweij, Peter and Gemund, Arjan J. C.
		  van},
  title		= {An Evaluation of Similarity Coefficients for Software
		  Fault Localization},
  year		= {2006},
  isbn		= {0769527248},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/PRDC.2006.18},
  doi		= {10.1109/PRDC.2006.18},
  abstract	= {Automated diagnosis of software faults can improve the
		  efficiency of the debugging process, and is therefore an
		  important technique for the development of dependable
		  software. In this paper we study different similarity
		  coefficients that are applied in the context of a program
		  spectral approach to software fault localization (single
		  programming mistakes). The coefficients studied are taken
		  from the systems diagnosis / automated debugging tools
		  Pinpoint, Tarantula, and AMPLE, and from the molecular
		  biology domain (the Ochiai coefficient). We evaluate these
		  coefficients on the Siemens Suite of benchmark faults, and
		  assess their effectiveness in terms of the position of the
		  actual fault in the probability ranking of fault candidates
		  produced by the diagnosis technique. Our experiments
		  indicate that the Ochiai coefficient consistently
		  outperforms the coefficients currently used by the tools
		  mentioned. In terms of the amount of code that needs to be
		  inspected, this coefficient improves 5% on average ove},
  booktitle	= {Proceedings of the 12th Pacific Rim International
		  Symposium on Dependable Computing},
  pages		= {39–46},
  numpages	= {8},
  series	= {PRDC '06}
}

###InProceedings{ abreu2006ochiai,
  author	= {Abreu, Rui and Zoeteweij, Peter and Gemund, Arjan J. C.
		  van},
  title		= {An Evaluation of Similarity Coefficients for Software
		  Fault Localization},
  year		= {2006},
  isbn		= {0769527248},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/PRDC.2006.18},
  doi		= {10.1109/PRDC.2006.18},
  abstract	= {Automated diagnosis of software faults can improve the
		  efficiency of the debugging process, and is therefore an
		  important technique for the development of dependable
		  software. In this paper we study different similarity
		  coefficients that are applied in the context of a program
		  spectral approach to software fault localization (single
		  programming mistakes). The coefficients studied are taken
		  from the systems diagnosis / automated debugging tools
		  Pinpoint, Tarantula, and AMPLE, and from the molecular
		  biology domain (the Ochiai coefficient). We evaluate these
		  coefficients on the Siemens Suite of benchmark faults, and
		  assess their effectiveness in terms of the position of the
		  actual fault in the probability ranking of fault candidates
		  produced by the diagnosis technique. Our experiments
		  indicate that the Ochiai coefficient consistently
		  outperforms the coefficients currently used by the tools
		  mentioned. In terms of the amount of code that needs to be
		  inspected, this coefficient improves 5% on average ove},
  booktitle	= {Proceedings of the 12th Pacific Rim International
		  Symposium on Dependable Computing},
  pages		= {39–46},
  numpages	= {8},
  series	= {PRDC '06}
}

@InProceedings{	  abreu2007accuracy,
  author	= {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan
		  J.C.},
  booktitle	= {Testing: Academic and Industrial Conference Practice and
		  Research Techniques - MUTATION (TAICPART-MUTATION 2007)},
  title		= {On the Accuracy of Spectrum-based Fault Localization},
  year		= {2007},
  volume	= {},
  number	= {},
  pages		= {89-98},
  doi		= {10.1109/TAIC.PART.2007.13}
}

###InProceedings{ abreu2007accuracy,
  author	= {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan
		  J.C.},
  booktitle	= {Testing: Academic and Industrial Conference Practice and
		  Research Techniques - MUTATION (TAICPART-MUTATION 2007)},
  title		= {On the Accuracy of Spectrum-based Fault Localization},
  year		= {2007},
  volume	= {},
  number	= {},
  pages		= {89-98},
  doi		= {10.1109/TAIC.PART.2007.13}
}

@InProceedings{	  abreu2007zg,
  author	= {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan
		  J.C.},
  booktitle	= {Testing: Academic and Industrial Conference Practice and
		  Research Techniques - MUTATION (TAICPART-MUTATION 2007)},
  title		= {On the Accuracy of Spectrum-based Fault Localization},
  year		= {2007},
  volume	= {},
  number	= {},
  pages		= {89-98},
  keywords	= {Software testing;Automatic testing;Fault
		  diagnosis;Debugging;Computer industry;Benchmark
		  testing;Failure analysis;Fault detection;Fault
		  location;Mathematics},
  doi		= {10.1109/TAIC.PART.2007.13}
}

@Article{	  abreu2009practical,
  author	= {Abreu, Rui and Zoeteweij, Peter and Golsteijn, Rob and van
		  Gemund, Arjan J. C.},
  title		= {A Practical Evaluation of Spectrum-based Fault
		  Localization},
  journal	= {J. Syst. Softw.},
  issue_date	= {November, 2009},
  volume	= {82},
  number	= {11},
  month		= nov,
  year		= {2009},
  issn		= {0164-1212},
  pages		= {1780--1792},
  numpages	= {13},
  url		= {http://dx.doi.org/10.1016/j.jss.2009.06.035},
  doi		= {10.1016/j.jss.2009.06.035},
  acmid		= {1630274},
  _publisher	= {Elsevier Science Inc.},
  address	= {New York, NY, USA},
  keywords	= {Consumer electronics, Program spectra, Real-time and
		  embedded systems, Software fault diagnosis, Test data
		  analysis}
}

###Article{	  abreu2009practical,
  title		= {A practical evaluation of spectrum-based fault
		  localization},
  volume	= {82},
  issn		= {0164-1212},
  doi		= {https://doi.org/10.1016/j.jss.2009.06.035},
  abstractnote	= {Spectrum-based fault localization (SFL) shortens the
		  test–diagnose–repair cycle by reducing the debugging
		  effort. As a light-weight automated diagnosis technique it
		  can easily be integrated with existing testing schemes.
		  Since SFL is based on discovering statistical coincidences
		  between system failures and the activity of the different
		  parts of a system, its diagnostic accuracy is inherently
		  limited. Using a common benchmark consisting of the Siemens
		  set and the space program, we investigate this diagnostic
		  accuracy as a function of several parameters (such as
		  quality and quantity of the program spectra collected
		  during the execution of the system), some of which directly
		  relate to test design. Our results indicate that the
		  superior performance of a particular similarity
		  coefficient, used to analyze the program spectra, is
		  largely independent of test design. Furthermore,
		  near-optimal diagnostic accuracy (exonerating over 80% of
		  the blocks of code on average) is already obtained for
		  low-quality error observations and limited numbers of test
		  cases. In addition to establishing these results in the
		  controlled environment of our benchmark set, we show that
		  SFL can effectively be applied in the context of embedded
		  software development in an industrial environment.},
  number	= {11},
  journal	= {Journal of Systems and Software},
  author	= {Abreu, Rui and Zoeteweij, Peter and Golsteijn, Rob and
		  Gemund, Arjan J. C. van},
  year		= {2009},
  pages		= {1780–1792}
}

@InProceedings{	  abreu2009spectrum,
  author	= {Abreu, Rui and Zoeteweij, Peter and van Gemund, Arjan
		  J.C.},
  booktitle	= {2009 IEEE/ACM International Conference on Automated
		  Software Engineering},
  title		= {Spectrum-Based Multiple Fault Localization},
  year		= {2009},
  volume	= {},
  number	= {},
  pages		= {88-99},
  keywords	= {Fault diagnosis;Bayesian methods;Mathematical
		  model;Logic;Computational
		  complexity;Costs;Debugging;Software engineering;Embedded
		  software;Mathematics;Software fault diagnosis;program
		  spectra;statistical and reasoning approaches},
  doi		= {10.1109/ASE.2009.25}
}

@Misc{		  additionalmaterial1,
  author	= {Fabian Keller and Lars Grunske and Simon Heiden and
		  Antonio Filieri and Andre van Hoorn and David Lo},
  title		= {{An Evaluation of Pure Spectrum-Based Fault Localization
		  Techniques for Large-Scale Software Systems - Additional
		  Material}},
  howpublished	= {{www.informatik.hu-berlin.de/de/forschung/gebiete/se/research/material/SPE1819}},
  label		= {additionalMaterial1}
}

@Article{	  aflsmart,
  author	= {V. {Pham} and M. {B{\"o}hme} and A. E. {Santosa} and A. R.
		  {Caciulescu} and A. {Roychoudhury}},
  journal	= {IEEE Transactions on Software Engineering},
  title		= {Smart Greybox Fuzzing},
  year		= {2019},
  doi		= {10.1109/TSE.2019.2941681}
}

###Article{	  aflsmart,
  author	= {V. {Pham} and M. {B{\"o}hme} and A. E. {Santosa} and A. R.
		  {Caciulescu} and A. {Roychoudhury}},
  journal	= {IEEE Transactions on Software Engineering},
  title		= {Smart Greybox Fuzzing},
  year		= {2019},
  doi		= {10.1109/TSE.2019.2941681}
}

@Article{	  almaghairber17,
  author	= {Rafig Almaghairbe and Marc Roper},
  title		= {Separating passing and failing test executions by
		  clustering anomalies},
  journal	= {Softw. Qual. J.},
  volume	= {25},
  number	= {3},
  pages		= {803--840},
  year		= {2017},
  url		= {https://doi.org/10.1007/s11219-016-9339-1},
  doi		= {10.1007/s11219-016-9339-1}
}

@InProceedings{	  alvesgjd11,
  author	= {Alves, Elton and Gligoric, Milos and Jagannath, Vilas and
		  d'Amorim, Marcelo},
  booktitle	= {2011 26th IEEE/ACM International Conference on Automated
		  Software Engineering (ASE 2011)},
  title		= {Fault-localization using dynamic slicing and change impact
		  analysis},
  year		= {2011},
  volume	= {},
  number	= {},
  pages		= {520-523},
  keywords	= {Inspection;Computational
		  efficiency;Schedules;Measurement;Testing;Filtering;USA
		  Councils},
  doi		= {10.1109/ASE.2011.6100114}
}

@InProceedings{	  artzidtp10,
  author	= {Artzi, Shay and Dolby, Julian and Tip, Frank and Pistoia,
		  Marco},
  title		= {Practical fault localization for dynamic web
		  applications},
  year		= {2010},
  isbn		= {9781605587196},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1806799.1806840},
  doi		= {10.1145/1806799.1806840},
  abstract	= {We leverage combined concrete and symbolic execution and
		  several fault-localization techniques to create a uniquely
		  powerful tool for localizing faults in PHP applications.
		  The tool automatically generates tests that expose
		  failures, and then automatically localizes the faults
		  responsible for those failures, thus overcoming the
		  limitation of previous fault-localization techniques that a
		  test suite be available upfront. The fault-localization
		  techniques we employ combine variations on the Tarantula
		  algorithm with a technique based on maintaining a mapping
		  between statements and the fragments of output they
		  produce. We implemented these techniques in a tool called
		  Apollo, and evaluated them by localizing 75 randomly
		  selected faults that were exposed by automatically
		  generated tests in four PHP applications. Our findings
		  indicate that, using our best technique, 87.7\% of the
		  faults under consideration are localized to within 1\% of
		  all executed statements, which constitutes an almost
		  five-fold improvement over the Tarantula algorithm.},
  booktitle	= {Proceedings of the 32nd ACM/IEEE International Conference
		  on Software Engineering - Volume 1},
  pages		= {265–274},
  numpages	= {10},
  location	= {Cape Town, South Africa},
  series	= {ICSE '10}
}

@InProceedings{	  artzidtp10b,
  author	= {Artzi, Shay and Dolby, Julian and Tip, Frank and Pistoia,
		  Marco},
  title		= {Directed test generation for effective fault
		  localization},
  year		= {2010},
  isbn		= {9781605588230},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1831708.1831715},
  doi		= {10.1145/1831708.1831715},
  abstract	= {Fault-localization techniques that apply statistical
		  analyses to execution data gathered from multiple tests are
		  quite effective when a large test suite is available.
		  However, if no test suite is available, what is the best
		  approach to generate one? This paper investigates the
		  fault-localization effectiveness of test suites generated
		  according to several test-generation techniques based on
		  combined concrete and symbolic (concolic) execution. We
		  evaluate these techniques by applying the Ochiai
		  fault-localization technique to generated test suites in
		  order to localize 35 faults in four PHP Web applications.
		  Our results show that the test-generation techniques under
		  consideration produce test suites with similar high
		  fault-localization effectiveness, when given a large time
		  budget. However, a new, "directed" test-generation
		  technique, which aims to maximize the similarity between
		  the path constraints of the generated tests and those of
		  faulty executions, reaches this level of effectiveness with
		  much smaller test suites. On average, when compared to test
		  generation based on standard concolic execution techniques
		  that aims to maximize code coverage, the new directed
		  technique preserves fault-localization effectiveness while
		  reducing test-suite size by 86.1\% and test-suite
		  generation time by 88.6\%.},
  booktitle	= {Proceedings of the 19th International Symposium on
		  Software Testing and Analysis},
  pages		= {49–60},
  numpages	= {12},
  keywords	= {testing web applications, concolic testing, automated
		  testing},
  location	= {Trento, Italy},
  series	= {ISSTA '10}
}

@Misc{		  aspectj,
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  label		= {AspectJ},
  organization	= {Eclipse Foundation},
  sorttitle	= {AspectJ},
  title		= {{AspectJ} language extension},
  howpublished	= {\url{http://www.eclipse.org/aspectj}},
  url		= {http://www.eclipse.org/aspectj/},
  bdsk-url-1	= {http://www.eclipse.org/aspectj/}
}

@Article{	  barrhmsy15,
  author	= {Earl T. Barr and Mark Harman and Phil McMinn and Muzammil
		  Shahbaz and Shin Yoo},
  title		= {The Oracle Problem in Software Testing: {A} Survey},
  journal	= {{IEEE} Trans. Software Eng.},
  volume	= {41},
  number	= {5},
  pages		= {507--525},
  year		= {2015},
  url		= {https://doi.org/10.1109/TSE.2014.2372785},
  doi		= {10.1109/TSE.2014.2372785}
}

@InProceedings{	  baudryft06,
  author	= {Baudry, Benoit and Fleurey, Franck and Le Traon, Yves},
  title		= {Improving test suites for efficient fault localization},
  year		= {2006},
  isbn		= {1595933751},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1134285.1134299},
  doi		= {10.1145/1134285.1134299},
  abstract	= {The need for testing-for-diagnosis strategies has been
		  identified for a long time, but the explicit link from
		  testing to diagnosis (fault localization) is rare.
		  Analyzing the type of information needed for efficient
		  fault localization, we identify the attribute (called
		  Dynamic Basic Block) that restricts the accuracy of a
		  diagnosis algorithm. Based on this attribute, a
		  test-for-diagnosis criterion is proposed and validated
		  through rigorous case studies: it shows that a test suite
		  can be improved to reach a high level of diagnosis
		  accuracy. So, the dilemma between a reduced testing effort
		  (with as few test cases as possible) and the diagnosis
		  accuracy (that needs as much test cases as possible to get
		  more information) is partly solved by selecting test cases
		  that are dedicated to diagnosis.},
  booktitle	= {Proceedings of the 28th International Conference on
		  Software Engineering},
  pages		= {82–91},
  numpages	= {10},
  keywords	= {test generation, mutation analysis, diagnosis},
  location	= {Shanghai, China},
  series	= {ICSE '06}
}

@InProceedings{	  boehme2016aflfast,
  author	= {B\"{o}hme, Marcel and Pham, Van-Thuan and Roychoudhury,
		  Abhik},
  title		= {Coverage-Based Greybox Fuzzing as Markov Chain},
  year		= {2016},
  isbn		= {9781450341394},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2976749.2978428},
  doi		= {10.1145/2976749.2978428},
  abstract	= {Coverage-based Greybox Fuzzing (CGF) is a random testing
		  approach that requires no program analysis. A new test is
		  generated by slightly mutating a seed input. If the test
		  exercises a new and interesting path, it is added to the
		  set of seeds; otherwise, it is discarded. We observe that
		  most tests exercise the same few "high-frequency" paths and
		  develop strategies to explore significantly more paths with
		  the same number of tests by gravitating towards
		  low-frequency paths. We explain the challenges and
		  opportunities of CGF using a Markov chain model which
		  specifies the probability that fuzzing the seed that
		  exercises path i generates an input that exercises path j.
		  Each state (i.e., seed) has an energy that specifies the
		  number of inputs to be generated from that seed. We show
		  that CGF is considerably more efficient if energy is
		  inversely proportional to the density of the stationary
		  distribution and increases monotonically every time that
		  seed is chosen. Energy is controlled with a power
		  schedule.We implemented the exponential schedule by
		  extending AFL. In 24 hours, AFLFAST exposes 3 previously
		  unreported CVEs that are not exposed by AFL and exposes 6
		  previously unreported CVEs 7x faster than AFL. AFLFAST
		  produces at least an order of magnitude more unique crashes
		  than AFL.},
  booktitle	= {Proceedings of the 2016 ACM SIGSAC Conference on Computer
		  and Communications Security},
  pages		= {1032–1043},
  numpages	= {12},
  keywords	= {vulnerability detection, testing efficiency, software
		  security, fuzzing, foundations},
  location	= {Vienna, Austria},
  series	= {CCS '16}
}

###InProceedings{ boehme2016aflfast,
  author	= {B\"{o}hme, Marcel and Pham, Van-Thuan and Roychoudhury,
		  Abhik},
  title		= {Coverage-Based Greybox Fuzzing as Markov Chain},
  year		= {2016},
  isbn		= {9781450341394},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2976749.2978428},
  doi		= {10.1145/2976749.2978428},
  abstract	= {Coverage-based Greybox Fuzzing (CGF) is a random testing
		  approach that requires no program analysis. A new test is
		  generated by slightly mutating a seed input. If the test
		  exercises a new and interesting path, it is added to the
		  set of seeds; otherwise, it is discarded. We observe that
		  most tests exercise the same few "high-frequency" paths and
		  develop strategies to explore significantly more paths with
		  the same number of tests by gravitating towards
		  low-frequency paths. We explain the challenges and
		  opportunities of CGF using a Markov chain model which
		  specifies the probability that fuzzing the seed that
		  exercises path i generates an input that exercises path j.
		  Each state (i.e., seed) has an energy that specifies the
		  number of inputs to be generated from that seed. We show
		  that CGF is considerably more efficient if energy is
		  inversely proportional to the density of the stationary
		  distribution and increases monotonically every time that
		  seed is chosen. Energy is controlled with a power
		  schedule.We implemented the exponential schedule by
		  extending AFL. In 24 hours, AFLFAST exposes 3 previously
		  unreported CVEs that are not exposed by AFL and exposes 6
		  previously unreported CVEs 7x faster than AFL. AFLFAST
		  produces at least an order of magnitude more unique crashes
		  than AFL.},
  booktitle	= {Proceedings of the 2016 ACM SIGSAC Conference on Computer
		  and Communications Security},
  pages		= {1032–1043},
  numpages	= {12},
  keywords	= {vulnerability detection, testing efficiency, software
		  security, fuzzing, foundations},
  location	= {Vienna, Austria},
  series	= {CCS '16}
}

@InProceedings{	  boehme2020learn2fix,
  author	= {B\"{o}hme, Marcel and Geethal, Charaka and Pham,
		  Van-Thuan},
  booktitle	= {2020 IEEE 13th International Conference on Software
		  Testing, Validation and Verification (ICST)},
  title		= {Human-In-The-Loop Automatic Program Repair},
  year		= {2020},
  volume	= {},
  number	= {},
  pages		= {274-285},
  doi		= {10.1109/ICST46399.2020.00036}
}

###InProceedings{ boehme2020learn2fix,
  author	= {B\"{o}hme, Marcel and Geethal, Charaka and Pham,
		  Van-Thuan},
  booktitle	= {2020 IEEE 13th International Conference on Software
		  Testing, Validation and Verification (ICST)},
  title		= {Human-In-The-Loop Automatic Program Repair},
  year		= {2020},
  volume	= {},
  number	= {},
  pages		= {274-285},
  doi		= {10.1109/ICST46399.2020.00036}
}

@InProceedings{	  bohmes0uz17,
  author	= {B\"{o}hme, Marcel and Soremekun, Ezekiel O. and
		  Chattopadhyay, Sudipta and Ugherughe, Emamurho and Zeller,
		  Andreas},
  title		= {Where is the bug and how is it fixed? an experiment with
		  practitioners},
  year		= {2017},
  isbn		= {9781450351058},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3106237.3106255},
  doi		= {10.1145/3106237.3106255},
  abstract	= {Research has produced many approaches to automatically
		  locate, explain, and repair software bugs. But do these
		  approaches relate to the way practitioners actually locate,
		  understand, and fix bugs? To help answer this question, we
		  have collected a dataset named DBGBENCH --- the correct
		  fault locations, bug diagnoses, and software patches of 27
		  real errors in open-source C projects that were
		  consolidated from hundreds of debugging sessions of
		  professional software engineers. Moreover, we shed light on
		  the entire debugging process, from constructing a
		  hypothesis to submitting a patch, and how debugging time,
		  difficulty, and strategies vary across practitioners and
		  types of errors. Most notably, DBGBENCH can serve as
		  reality check for novel automated debugging and repair
		  techniques.},
  booktitle	= {Proceedings of the 2017 11th Joint Meeting on Foundations
		  of Software Engineering},
  pages		= {117–128},
  numpages	= {12},
  keywords	= {Debugging in practice, Evaluation, User as tool benchmark,
		  User studies},
  location	= {Paderborn, Germany},
  series	= {ESEC/FSE 2017}
}

@TechReport{	  britton2013reversible,
  author	= {Britton, Tom and Jeng, Lisa and Carver, Graham and Cheak,
		  Paul and Katzenellenbogen, Tomer},
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  institution	= {Technical report, University of Cambridge, Judge Business
		  School},
  title		= {Reversible debugging software},
  year		= {2013}
}

@Misc{		  bugsinpysource,
  author	= {Widyasari, Ratnadira and Sim, Sheng Qin and Lok, Camellia
		  and Qi, Haodi and Phan, Jack and Tay, Qijin and Tan,
		  Constance and Wee, Fiona and Tan, Jodie Ethelda and Yieh,
		  Yuheng and Goh, Brian and Thung, Ferdian and Kang, Hong Jin
		  and Hoang, Thong and Lo, David and Ouh, Eng Lieh},
  year		= {2020},
  title		= {BugsInPy},
  howpublished	= {\url{https://github.com/soarsmu/BugsInPy/tree/master/projects}}
}

###Misc{	  bugsinpysource,
  author	= {Widyasari, Ratnadira and Sim, Sheng Qin and Lok, Camellia
		  and Qi, Haodi and Phan, Jack and Tay, Qijin and Tan,
		  Constance and Wee, Fiona and Tan, Jodie Ethelda and Yieh,
		  Yuheng and Goh, Brian and Thung, Ferdian and Kang, Hong Jin
		  and Hoang, Thong and Lo, David and Ouh, Eng Lieh},
  year		= {2020},
  title		= {BugsInPy},
  howpublished	= {\url{https://github.com/soarsmu/BugsInPy/tree/master/projects}}
}

@InProceedings{	  camposafd13,
  author	= {Campos, Jos{\'e} and Abreu, Rui and Fraser, Gordon and
		  d'Amorim, Marcelo},
  title		= {Entropy-based Test Generation for Improved Fault
		  Localization},
  booktitle	= {Proceedings of the 28th IEEE/ACM International Conference
		  on Automated Software Engineering},
  _booktitle	= {ASE'13},
  year		= {2013},
  isbn		= {978-1-4799-0215-6},
  location	= {Silicon Valley, CA, USA},
  pages		= {257--267},
  numpages	= {11},
  url		= {https://doi.org/10.1109/ASE.2013.6693085},
  doi		= {10.1109/ASE.2013.6693085},
  acmid		= {3107690},
  _publisher	= {IEEE Press},
  address	= {Piscataway, NJ, USA},
  keywords	= {fault localization, test case generation}
}

###InProceedings{ camposafd13,
  author	= {Campos, Jos{\'e} and Abreu, Rui and Fraser, Gordon and
		  d'Amorim, Marcelo},
  title		= {Entropy-based Test Generation for Improved Fault
		  Localization},
  booktitle	= {ASE'13},
  year		= {2013},
  isbn		= {978-1-4799-0215-6},
  location	= {Silicon Valley, CA, USA},
  pages		= {257--267},
  numpages	= {11},
  url		= {https://doi.org/10.1109/ASE.2013.6693085},
  doi		= {10.1109/ASE.2013.6693085},
  acmid		= {3107690},
  publisher	= {IEEE Press},
  address	= {Piscataway, NJ, USA},
  keywords	= {fault localization, test case generation}
}

@InProceedings{	  casanova2011architecture,
  author	= {Casanova, Paulo and Schmerl, Bradley and Garlan, David and
		  Abreu, Rui},
  title		= {Architecture-based run-time fault diagnosis},
  year		= {2011},
  isbn		= {9783642237973},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  abstract	= {An important step in achieving robustness to run-time
		  faults is the ability to detect and repair problems when
		  they arise in a running system. Effective fault detection
		  and repair could be greatly enhanced by run-time fault
		  diagnosis and localization, since it would allow the repair
		  mechanisms to focus adaptation effort on the parts most in
		  need of attention. In this paper we describe an approach to
		  run-time fault diagnosis that combines architectural models
		  with spectrum-based reasoning for multiple fault
		  localization. Spectrum-based reasoning is a lightweight
		  technique that takes a form of trace abstraction and
		  produces a list (ordered by probability) of likely fault
		  candidates. We show how this technique can be combined with
		  architectural models to support run-time diagnosis that can
		  (a) scale to modern distributed software systems; (b)
		  accommodate the use of black-box components and proprietary
		  infrastructure for which one has neither a specification
		  nor source code; and (c) handle inherent uncertainty about
		  the probable cause of a problem even in the face of
		  transient faults and faults that arise only when certain
		  combinations of system components interact.},
  booktitle	= {Proceedings of the 5th European Conference on Software
		  Architecture},
  pages		= {261–277},
  numpages	= {17},
  keywords	= {software architecture, run-time, diagnosis, autonomic
		  computing},
  location	= {Essen, Germany},
  series	= {ECSA'11}
}

@InProceedings{	  cellierdfr08,
  author	= {Cellier, Peggy and Ducass\'{e}, Mireille and Ferr\'{e},
		  S\'{e}bastien and Ridoux, Olivier},
  title		= {Formal concept analysis enhances fault localization in
		  software},
  year		= {2008},
  isbn		= {3540781366},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  abstract	= {Recent work in fault localization crosschecks traces of
		  correct and failing execution traces. The implicit
		  underlying technique is to search for association rules
		  which indicate that executing a particular source line will
		  cause the whole execution to fail. This technique, however,
		  has limitations. In this article, we first propose to
		  consider more expressive association rules where several
		  lines imply failure. We then propose to use Formal Concept
		  Analysis (FCA) to analyze the resulting numerous rules in
		  order to improve the readability of the information
		  contained in the rules. The main contribution of this
		  article is to show that applying two data mining
		  techniques, association rules and FCA, produces better
		  results than existing fault localization techniques.},
  booktitle	= {Proceedings of the 6th International Conference on Formal
		  Concept Analysis},
  pages		= {273–288},
  numpages	= {16},
  location	= {Montreal, Canada},
  series	= {ICFCA'08}
}

@InProceedings{	  chen2002jaccard,
  author	= {Chen, Mike and Kiciman, Emre and Fratkin, Eugene and Fox,
		  Armando and Brewer, Eric},
  year		= {2002},
  month		= {02},
  title		= {Pinpoint: problem determination in large, dynamic Internet
		  services},
  isbn		= {0-7695-1101-5},
  doi		= {10.1109/DSN.2002.1029005},
  booktitle	= {Proceedings of the 2002 International Conference on
		  Dependable Systems and Networks},
  pages		= {595-604},
  keywords	= {Web and internet services;Failure analysis;Tagging;Data
		  mining;Detectors;Middleware;Instruments;Data
		  analysis;Search engines;Fault diagnosis}
}

###InProceedings{ chen2002jaccard,
  author	= {Chen, Mike and Kiciman, Emre and Fratkin, Eugene and Fox,
		  Armando and Brewer, Eric},
  year		= {2002},
  month		= {02},
  pages		= {595- 604},
  title		= {Pinpoint: problem determination in large, dynamic Internet
		  services},
  isbn		= {0-7695-1101-5},
  journal	= {Proceedings of the 2002 International Conference on
		  Dependable Systems and Networks},
  doi		= {10.1109/DSN.2002.1029005}
}

@Article{	  choi2010survey,
  title		= {A survey of binary similarity and distance measures},
  author	= {Choi, Seung-Seok and Cha, Sung-Hyuk and Tappert, Charles
		  C},
  journal	= {Journal of Systemics, Cybernetics and Informatics},
  volume	= {8},
  number	= {1},
  pages		= {43--48},
  year		= {2010}
}

@InProceedings{	  clevez05,
  author	= {Cleve, Holger and Zeller, Andreas},
  title		= {Locating causes of program failures},
  year		= {2005},
  isbn		= {1581139632},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1062455.1062522},
  doi		= {10.1145/1062455.1062522},
  abstract	= {Which is the defect that causes a software failure? By
		  comparing the program states of a failing and a passing
		  run, we can identify the state differences that cause the
		  failure. However, these state differences can occur all
		  over the program run. Therefore, we focus in space on those
		  variables and values that are relevant for the failure, and
		  in time on those moments where cause transitions
		  occur---moments where new relevant variables begin being
		  failure causes: "Initially, variable argc was 3; therefore,
		  at shell_sort(), variable [2] was 0, and therefore, the
		  program failed." In our evaluation, cause transitions
		  locate the failure-inducing defect twice as well as the
		  best methods known so far.},
  booktitle	= {Proceedings of the 27th International Conference on
		  Software Engineering},
  pages		= {342–351},
  numpages	= {10},
  keywords	= {adaptive testing, automated debugging, program analysis,
		  tracing},
  location	= {St. Louis, MO, USA},
  series	= {ICSE '05}
}

@Misc{		  cookiecutter,
  title		= {Cookiecutter},
  author	= {Audrey Roy Greenfeld},
  year		= {2022},
  url		= {https://www.cookiecutter.io/},
  note		= {\url{https://www.cookiecutter.io/}}
}

###Misc{	  cookiecutter,
  title		= {Cookiecutter},
  author	= {Audrey Roy Greenfeld},
  year		= {2022},
  url		= {https://www.cookiecutter.io/},
  note		= {\url{https://www.cookiecutter.io/}}
}

@InProceedings{	  dallmeier2005ample,
  author	= {Dallmeier, Valentin and Lindig, Christian and Zeller,
		  Andreas},
  title		= {Lightweight Bug Localization with {AMPLE}},
  year		= {2005},
  isbn		= {1595930507},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1085130.1085143},
  doi		= {10.1145/1085130.1085143},
  abstract	= {AMPLE locates likely failure-causing classes by comparing
		  method call sequences of passing and failing runs. A
		  difference in method call sequences, such as multiple
		  deallocation of the same resource, is likely to point to
		  the erroneous class. Such sequences can be collected from
		  arbitrary Java programs at low cost; comparing
		  object-specific sequences predicts defects better than
		  simply comparing coverage. AMPLE comes as a plug-in for the
		  Java IDE Eclipse that is automatically invoked as soon as a
		  JUnit test fails.},
  booktitle	= {Proceedings of the Sixth International Symposium on
		  Automated Analysis-Driven Debugging},
  pages		= {99–104},
  numpages	= {6},
  location	= {Monterey, California, USA},
  series	= {AADEBUG'05}
}

###InProceedings{ dallmeier2005ample,
  author	= {Dallmeier, Valentin and Lindig, Christian and Zeller,
		  Andreas},
  title		= {Lightweight Bug Localization with {AMPLE}},
  year		= {2005},
  isbn		= {1595930507},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1085130.1085143},
  doi		= {10.1145/1085130.1085143},
  abstract	= {AMPLE locates likely failure-causing classes by comparing
		  method call sequences of passing and failing runs. A
		  difference in method call sequences, such as multiple
		  deallocation of the same resource, is likely to point to
		  the erroneous class. Such sequences can be collected from
		  arbitrary Java programs at low cost; comparing
		  object-specific sequences predicts defects better than
		  simply comparing coverage. AMPLE comes as a plug-in for the
		  Java IDE Eclipse that is automatically invoked as soon as a
		  JUnit test fails.},
  booktitle	= {Proceedings of the Sixth International Symposium on
		  Automated Analysis-Driven Debugging},
  pages		= {99–104},
  numpages	= {6},
  location	= {Monterey, California, USA},
  series	= {AADEBUG'05}
}

@InProceedings{	  dallmeier2007extraction,
  author	= {Dallmeier, Valentin and Zimmermann, Thomas},
  title		= {Extraction of bug localization benchmarks from history},
  year		= {2007},
  isbn		= {9781595938824},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1321631.1321702},
  doi		= {10.1145/1321631.1321702},
  abstract	= {Researchers have proposed a number of tools for automatic
		  bug localization. Given a program and a description of the
		  failure, such tools pinpoint a set of statements that are
		  most likely to contain the bug. Evaluating bug localization
		  tools is a difficult task because existing benchmarks are
		  limited in size of subjects and number of bugs. In this
		  paper we present iBUGS, an approach that semiautomatically
		  extracts benchmarks for bug localization from the history
		  of a project. For ASPECTJ, we extracted 369 bugs, 223 out
		  of these had associated test cases. We demonstrate the
		  relevance of our dataset with a case study on the bug
		  localization tool AMPLE},
  booktitle	= {Proceedings of the 22nd IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {433–436},
  numpages	= {4},
  keywords	= {defect localization, benchmarking},
  location	= {Atlanta, Georgia, USA},
  series	= {ASE '07}
}

@Article{	  daniel2013sbfl,
  title		= {Spectrum-based Fault Localization: A Pair Scoring
		  Approach},
  author	= {Patrick Daniel and Kwan Yong Sim},
  journal	= {Journal of Industrial and Intelligent Information},
  year		= {2013},
  volume	= {1},
  pages		= {185-190},
  doi		= {10.12720/jiii.1.4.185-190},
  url		= {https://doi.org/10.12720/jiii.1.4.185-190}
}

###Article{	  daniel2013sbfl,
  title		= {Spectrum-based Fault Localization: A Pair Scoring
		  Approach},
  author	= {Patrick Daniel and Kwan Yong Sim},
  journal	= {Journal of Industrial and Intelligent Information},
  year		= {2013},
  volume	= {1},
  pages		= {185-190},
  doi		= {10.12720/jiii.1.4.185-190},
  url		= {https://doi.org/10.12720/jiii.1.4.185-190}
}

@InProceedings{	  debroy2010mutrepair,
  author	= {Debroy, Vidroha and Wong, W. Eric},
  booktitle	= {2010 Third International Conference on Software Testing,
		  Verification and Validation},
  title		= {Using Mutation to Automatically Suggest Fixes for Faulty
		  Programs},
  year		= {2010},
  volume	= {},
  number	= {},
  pages		= {65-74},
  keywords	= {Genetic mutations;Programming
		  profession;Debugging;Software testing;Humans;Fault
		  detection;Computer science;Benchmark
		  testing;Explosives;Manuals;program debugging;mutation;fault
		  localization;fault-fixing;software testing},
  doi		= {10.1109/ICST.2010.66}
}

@Article{	  debroyw13,
  author	= {Debroy, Vidroha and Wong, W. Eric},
  title		= {A consensus-based strategy to improve the quality of fault
		  localization},
  journal	= {Software: Practice and Experience},
  volume	= {43},
  number	= {8},
  pages		= {989-1011},
  keywords	= {consensus, software fault localization, program debugging,
		  suspiciousness-based ranking},
  doi		= {https://doi.org/10.1002/spe.1146},
  url		= {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.1146},
  eprint	= {https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.1146},
  abstract	= {SUMMARYA vast number of software fault localization
		  techniques have been proposed recently with the growing
		  realization that manual debugging is time-consuming,
		  tedious, and error-prone, and fault localization is one of
		  the most expensive debugging activities. Although some
		  techniques perform better than others on a large number of
		  data sets, they do not do so on all data sets and
		  therefore, the actual quality of fault localization can
		  vary considerably by using just one technique. This paper
		  proposes the use of a consensus-based strategy that
		  combines the results of multiple fault localization
		  techniques to consistently provide high quality
		  performance, irrespective of data set. Empirical evidence
		  based on case studies conducted on six sets of programs
		  (seven programs of the Siemens suite, and the gzip, grep,
		  make, space, and Ant programs) and three different fault
		  localization techniques (Tarantula, Ochiai, and H3)
		  suggests that the consensus-based strategy holds merit and
		  generally provides close to the best, if not the best,
		  results. Empirically, we show that this is true of both
		  single-fault and multifault programs. Additionally, the
		  consensus-based strategy makes use of techniques that all
		  operate on the same set of input data, minimizing the
		  overhead. It is also simple to include or exclude
		  techniques from consensus, making it an easily extensible
		  or tractable strategy. Copyright © 2011 John Wiley \&
		  Sons, Ltd.},
  year		= {2013}
}

@Article{	  desouza18mck,
  title		= {Contextualizing spectrum-based fault localization},
  volume	= {94},
  issn		= {0950-5849},
  doi		= {https://doi.org/10.1016/j.infsof.2017.10.014},
  abstractnote	= {Context: Fault localization is among the most expensive
		  tasks in software development. Spectrum-based fault
		  localization (SFL) techniques seek to pinpoint faulty
		  program elements (e.g., statements), by sorting them only
		  by their suspiciousness scores. Developers tend to fall
		  back on another debugging strategy if they do not find the
		  bug in the first positions of a suspiciousness list.
		  Objective: In this study, we assess techniques to
		  contextualize code inspection whose goal is two-fold: to
		  provide guidance during fault localization, and to improve
		  the effectiveness of SFL techniques in classifying bugs
		  within the first picks. Code Hierarchy (CH) and Integration
		  Coverage-based Debugging (ICD) techniques provide a search
		  roadmap—a list of methods—that guide the developer
		  toward faults. CH assigns a method with the highest
		  suspiciousness score of its blocks, and ICD captures method
		  call relationships from testing to establish the roadmap.
		  Two new filtering strategies—Fixed Budget (FB) and Level
		  Score (LS)—are combined with ICD and CH for reducing the
		  amount of blocks to inspect in each method. Method: We
		  evaluated the effectiveness of ICD, CH, FB, LS, and a
		  suspiciousness block list (BL) on 62 bugs from 7 real
		  programs. Results: ICD and CH using FB found more faults
		  inspecting less blocks than BL with statistical
		  significance. More than 50% of the faults were found
		  inspecting at most 10 blocks using ICD-FB and CH-FB.
		  Moreover, ICD and CH located 70% of the faults by
		  inspecting, at most, 4 methods. Conclusions: These results
		  suggest that the contextualization provided by roadmaps and
		  filtering strategies is useful for guiding developers
		  toward faults and improves the performance of SFL
		  techniques.},
  journal	= {Information and Software Technology},
  author	= {Souza, Higor A. de and Mutti, Danilo and Chaim, Marcos L.
		  and Kon, Fabio},
  year		= {2018},
  pages		= {245–261}
}

@InProceedings{	  dinellarml22,
  author	= {Elizabeth Dinella and Gabriel Ryan and Todd Mytkowicz and
		  Shuvendu K. Lahiri},
  title		= {{TOGA:} {A} Neural Method for Test Oracle Generation},
  booktitle	= {44th {IEEE/ACM} 44th International Conference on Software
		  Engineering, {ICSE} 2022},
  pages		= {2130--2141},
  publisher	= {{ACM}},
  year		= {2022},
  url		= {https://doi.org/10.1145/3510003.3510141},
  doi		= {10.1145/3510003.3510141}
}

@Article{	  do2005supporting,
  author	= {Do, Hyunsook and Elbaum, Sebastian and Rothermel, Gregg},
  title		= {Supporting Controlled Experimentation with Testing
		  Techniques: An Infrastructure and Its Potential Impact},
  journal	= {Empirical Softw. Engg.},
  issue_date	= {October 2005},
  volume	= {10},
  number	= {4},
  month		= oct,
  year		= {2005},
  issn		= {1382-3256},
  pages		= {405--435},
  numpages	= {31},
  url		= {http://dx.doi.org/10.1007/s10664-005-3861-2},
  doi		= {10.1007/s10664-005-3861-2},
  acmid		= {1089928},
  publisher	= {Kluwer Academic publishers},
  address	= {Hingham, MA, USA},
  keywords	= {Software testing, controlled experimentation, experiment
		  infrastructure, regression testing}
}

@InProceedings{	  eberlein2023avicenna,
  author	= {Martin Eberlein and Marius Smytzek and Dominic
		  Steinh{\"{o}}fel and Lars Grunske and Andreas Zeller},
  editor	= {Satish Chandra and Kelly Blincoe and Paolo Tonella},
  title		= {Semantic Debugging},
  booktitle	= {Proceedings of the 31st {ACM} Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering, {ESEC/FSE} 2023, San Francisco, CA,
		  USA, December 3-9, 2023},
  pages		= {438--449},
  publisher	= {{ACM}},
  year		= {2023},
  url		= {https://doi.org/10.1145/3611643.3616296},
  doi		= {10.1145/3611643.3616296},
  timestamp	= {Mon, 04 Dec 2023 12:10:56 +0100},
  biburl	= {https://dblp.org/rec/conf/sigsoft/EberleinSSGZ23.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

###InProceedings{ eberlein2023avicenna,
  author	= {Martin Eberlein and Marius Smytzek and Dominic
		  Steinh{\"{o}}fel and Lars Grunske and Andreas Zeller},
  editor	= {Satish Chandra and Kelly Blincoe and Paolo Tonella},
  title		= {Semantic Debugging},
  booktitle	= {Proceedings of the 31st {ACM} Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering, {ESEC/FSE} 2023, San Francisco, CA,
		  USA, December 3-9, 2023},
  pages		= {438--449},
  publisher	= {{ACM}},
  year		= {2023},
  url		= {https://doi.org/10.1145/3611643.3616296},
  doi		= {10.1145/3611643.3616296},
  timestamp	= {Mon, 04 Dec 2023 12:10:56 +0100},
  biburl	= {https://dblp.org/rec/conf/sigsoft/EberleinSSGZ23.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  eberlein2023semanticdebugging,
  author	= {Eberlein, Martin and Smytzek, Marius and Steinh\"{o}fel,
		  Dominic and Grunske, Lars and Zeller, Andreas},
  title		= {Semantic Debugging},
  year		= {2023},
  isbn		= {9798400703270},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3611643.3616296},
  doi		= {10.1145/3611643.3616296},
  abstract	= {Why does my program fail? We present a novel and general
		  technique to automatically determine failure causes and
		  conditions, using logical properties over input elements:
		  “The program fails if and only if int(<length>) >
		  len(<payload>) holds—that is, the given <length> is
		  larger than the <payload> length.” Our AVICENNA prototype
		  uses modern techniques for inferring properties of passing
		  and failing inputs and validating and refining hypotheses
		  by having a constraint solver generate supporting test
		  cases to obtain such diagnoses. As a result, AVICENNA
		  produces crisp and expressive diagnoses even for complex
		  failure conditions, considerably improving over the state
		  of the art with diagnoses close to those of human
		  experts.},
  booktitle	= {Proceedings of the 31st ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {438–449},
  numpages	= {12},
  keywords	= {behavior explanation, debugging, program behavior,
		  testing},
  location	= {San Francisco, CA, USA},
  series	= {ESEC/FSE 2023}
}

@Article{	  ernstpgmptx07,
  author	= {Michael D. Ernst and Jeff H. Perkins and Philip J. Guo and
		  Stephen McCamant and Carlos Pacheco and Matthew S. Tschantz
		  and Chen Xiao},
  title		= {The {Daikon} system for dynamic detection of likely
		  invariants},
  journal	= {Sci. Comput. Program.},
  volume	= {69},
  number	= {1-3},
  pages		= {35--45},
  year		= {2007},
  url		= {https://doi.org/10.1016/j.scico.2007.01.015},
  doi		= {10.1016/j.scico.2007.01.015}
}

###Article{	  ernstpgmptx07,
  author	= {Michael D. Ernst and Jeff H. Perkins and Philip J. Guo and
		  Stephen McCamant and Carlos Pacheco and Matthew S. Tschantz
		  and Chen Xiao},
  title		= {The Daikon system for dynamic detection of likely
		  invariants},
  journal	= {Sci. Comput. Program.},
  volume	= {69},
  number	= {1-3},
  pages		= {35--45},
  year		= {2007},
  url		= {https://doi.org/10.1016/j.scico.2007.01.015},
  doi		= {10.1016/j.scico.2007.01.015}
}

@Misc{		  fastapi,
  title		= {{FastAPI}},
  author	= {Sebasti{\'a}n Ram{\'i}rez},
  year		= {2018},
  url		= {https://fastapi.tiangolo.com/},
  note		= {\url{https://fastapi.tiangolo.com/}}
}

###Misc{	  fastapi,
  title		= {{FastAPI}},
  author	= {Sebasti{\'a}n Ram{\'i}rez},
  year		= {2018},
  url		= {https://fastapi.tiangolo.com/},
  note		= {\url{https://fastapi.tiangolo.com/}}
}

@Article{	  feyzip18,
  author	= {Farid Feyzi and Saeed Parsa},
  title		= {{FPA-FL:} Incorporating static fault-proneness analysis
		  into statistical fault localization},
  journal	= {Journal of Systems and Software},
  volume	= {136},
  pages		= {39--58},
  year		= {2018},
  url		= {https://doi.org/10.1016/j.jss.2017.11.002},
  doi		= {10.1016/j.jss.2017.11.002},
  timestamp	= {Fri, 22 Dec 2017 15:37:43 +0100},
  biburl	= {https://dblp.org/rec/bib/journals/jss/FeyziP18},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  fioraldi2020aflpp,
  author	= {Fioraldi, Andrea and Maier, Dominik and Ei\ss{}feldt,
		  Heiko and Heuse, Marc},
  title		= {AFL++: Combining Incremental Steps of Fuzzing Research},
  year		= {2020},
  publisher	= {USENIX Association},
  address	= {USA},
  abstract	= {In this paper, we present AFL++, a community-driven
		  open-source tool that incorporates state-of-the-art fuzzing
		  research, to make the research comparable, reproducible,
		  combinable and--most importantly - useable. It offers a
		  variety of novel features, for example its Custom Mutator
		  API, able to extend the fuzzing process at many stages.
		  With it, mutators for specific targets can also be written
		  by experienced security testers. We hope for AFL++ to
		  become a new baseline tool not only for current, but also
		  for future research, as it allows to test new techniques
		  quickly, and evaluate not only the effectiveness of the
		  single technique versus the state-of-the-art, but also in
		  combination with other techniques. The paper gives an
		  evaluation of hand-picked fuzzing technologies -- shining
		  light on the fact that while each novel fuzzing method can
		  increase performance in some targets -- it decreases
		  performance for other targets. This is an insight future
		  fuzzing research should consider in their evaluations.},
  booktitle	= {Proceedings of the 14th USENIX Conference on Offensive
		  Technologies},
  articleno	= {10},
  numpages	= {1},
  series	= {WOOT'20}
}

###InProceedings{ fioraldi2020aflpp,
  author	= {Fioraldi, Andrea and Maier, Dominik and Ei\ss{}feldt,
		  Heiko and Heuse, Marc},
  title		= {AFL++: Combining Incremental Steps of Fuzzing Research},
  year		= {2020},
  publisher	= {USENIX Association},
  address	= {USA},
  abstract	= {In this paper, we present AFL++, a community-driven
		  open-source tool that incorporates state-of-the-art fuzzing
		  research, to make the research comparable, reproducible,
		  combinable and--most importantly - useable. It offers a
		  variety of novel features, for example its Custom Mutator
		  API, able to extend the fuzzing process at many stages.
		  With it, mutators for specific targets can also be written
		  by experienced security testers. We hope for AFL++ to
		  become a new baseline tool not only for current, but also
		  for future research, as it allows to test new techniques
		  quickly, and evaluate not only the effectiveness of the
		  single technique versus the state-of-the-art, but also in
		  combination with other techniques. The paper gives an
		  evaluation of hand-picked fuzzing technologies -- shining
		  light on the fact that while each novel fuzzing method can
		  increase performance in some targets -- it decreases
		  performance for other targets. This is an insight future
		  fuzzing research should consider in their evaluations.},
  booktitle	= {Proceedings of the 14th USENIX Conference on Offensive
		  Technologies},
  articleno	= {10},
  numpages	= {1},
  series	= {WOOT'20}
}

@InCollection{	  fuzzingbook2023greyboxfuzzer,
  author	= {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and
		  Gordon Fraser and Christian Holler},
  booktitle	= {The Fuzzing Book},
  title		= {Greybox Fuzzing},
  year		= {2023},
  publisher	= {CISPA Helmholtz Center for Information Security},
  howpublished	= {\url{https://www.fuzzingbook.org/html/GreyboxFuzzer.html}},
  note		= {Retrieved 2023-01-07 14:25:07+01:00},
  url		= {https://www.fuzzingbook.org/html/GreyboxFuzzer.html},
  urldate	= {2023-01-07 14:25:07+01:00}
}

###InCollection{  fuzzingbook2023greyboxfuzzer,
  author	= {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and
		  Gordon Fraser and Christian Holler},
  booktitle	= {The Fuzzing Book},
  title		= {Greybox Fuzzing},
  year		= {2023},
  publisher	= {CISPA Helmholtz Center for Information Security},
  howpublished	= {\url{https://www.fuzzingbook.org/html/GreyboxFuzzer.html}},
  note		= {Retrieved 2023-01-07 14:25:07+01:00},
  url		= {https://www.fuzzingbook.org/html/GreyboxFuzzer.html},
  urldate	= {2023-01-07 14:25:07+01:00}
}

@InCollection{	  fuzzingbook2023mutationfuzzer,
  author	= {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and
		  Gordon Fraser and Christian Holler},
  booktitle	= {The Fuzzing Book},
  title		= {Mutation-Based Fuzzing},
  year		= {2023},
  publisher	= {CISPA Helmholtz Center for Information Security},
  howpublished	= {\url{https://www.fuzzingbook.org/html/MutationFuzzer.html}},
  note		= {Retrieved 2023-01-07 14:53:00+01:00},
  url		= {https://www.fuzzingbook.org/html/MutationFuzzer.html},
  urldate	= {2023-01-07 14:53:00+01:00}
}

###InCollection{  fuzzingbook2023mutationfuzzer,
  author	= {Andreas Zeller and Rahul Gopinath and Marcel B{\"o}hme and
		  Gordon Fraser and Christian Holler},
  booktitle	= {The Fuzzing Book},
  title		= {Mutation-Based Fuzzing},
  year		= {2023},
  publisher	= {CISPA Helmholtz Center for Information Security},
  howpublished	= {\url{https://www.fuzzingbook.org/html/MutationFuzzer.html}},
  note		= {Retrieved 2023-01-07 14:53:00+01:00},
  url		= {https://www.fuzzingbook.org/html/MutationFuzzer.html},
  urldate	= {2023-01-07 14:53:00+01:00}
}

@InProceedings{	  goffigep16,
  author	= {Alberto Goffi and Alessandra Gorla and Michael D. Ernst
		  and Mauro Pezz{\`{e}}},
  editor	= {Andreas Zeller and Abhik Roychoudhury},
  title		= {Automatic generation of oracles for exceptional
		  behaviors},
  booktitle	= {Proceedings of the 25th International Symposium on
		  Software Testing and Analysis, {ISSTA} 2016,
		  Saarbr{\"{u}}cken, Germany, July 18-20, 2016},
  pages		= {213--224},
  publisher	= {{ACM}},
  year		= {2016},
  url		= {https://doi.org/10.1145/2931037.2931061},
  doi		= {10.1145/2931037.2931061}
}

@InProceedings{	  gong12ljz,
  author	= {Gong, Liang and Lo, David and Jiang, Lingxiao and Zhang,
		  Hongyu},
  title		= {Diversity Maximization Speedup for Fault Localization},
  booktitle	= {Proceedings of the 27th IEEE/ACM International Conference
		  on Automated Software Engineering},
  year		= {2012},
  isbn		= {978-1-4503-1204-2},
  location	= {Essen, Germany},
  pages		= {30--39},
  numpages	= {10},
  url		= {http://doi.acm.org/10.1145/2351676.2351682},
  doi		= {10.1145/2351676.2351682},
  acmid		= {2351682},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Fault Localization, Test Case Prioritization}
}

@Article{	  gongwsm13,
  author	= {Dandan, Gong and Tiantian, Wang and Xiaohong, Su and
		  Peijun, Ma},
  title		= {A Test-suite Reduction Approach to Improving
		  Fault-localization Effectiveness},
  journal	= {Comput. Lang. Syst. Struct.},
  issue_date	= {October, 2013},
  volume	= {39},
  number	= {3},
  month		= oct,
  year		= {2013},
  issn		= {1477-8424},
  pages		= {95--108},
  numpages	= {14},
  url		= {http://dx.doi.org/10.1016/j.cl.2013.04.001},
  doi		= {10.1016/j.cl.2013.04.001},
  acmid		= {2528896},
  publisher	= {Elsevier Science publishers B. V.},
  address	= {Amsterdam, The Netherlands, The Netherlands},
  keywords	= {Fault localization, Software debugging, Test-suite
		  reduction}
}

@InProceedings{	  gonzalez-sanchezagg11,
  author	= {Alberto Gonz{\'{a}}lez{-}Sanchez and Rui Abreu and
		  Hans{-}Gerhard Gross and Arjan J. C. van Gemund},
  editor	= {Perry Alexander and Corina S. Pasareanu and John G.
		  Hosking},
  title		= {Prioritizing tests for fault localization through
		  ambiguity group reduction},
  booktitle	= {26th {IEEE/ACM} International Conference on Automated
		  Software Engineering ({ASE} 2011)},
  pages		= {83--92},
  publisher	= {{IEEE} Computer Society},
  year		= {2011},
  url		= {https://doi.org/10.1109/ASE.2011.6100153},
  doi		= {10.1109/ASE.2011.6100153}
}

@Article{	  gonzalezsanchezpgg10,
  author	= {Gonzalez-Sanchez, Alberto and Piel, {\'E}ric and Abreu,
		  Rui and Gross, Hans-Gerhard and van Gemund, Arjan J. C.},
  title		= {Prioritizing Tests for Software Fault Diagnosis},
  journal	= {Softw. Pract. Exper.},
  issue_date	= {September 2011},
  volume	= {41},
  number	= {10},
  month		= sep,
  year		= {2011},
  issn		= {0038-0644},
  pages		= {1105--1129},
  numpages	= {25},
  url		= {http://dx.doi.org/10.1002/spe.1065},
  doi		= {10.1002/spe.1065},
  acmid		= {2030316},
  publisher	= {John Wiley \& Sons, Inc.},
  address	= {New York, NY, USA},
  keywords	= {diagnosis, test prioritization, testing}
}

@Article{	  gulwani2017synthesis,
  url		= {http://dx.doi.org/10.1561/2500000010},
  year		= {2017},
  volume	= {4},
  journal	= {Foundations and Trends in Programming Languages},
  title		= {Program Synthesis},
  doi		= {10.1561/2500000010},
  issn		= {2325-1107},
  number	= {1-2},
  pages		= {1--119},
  author	= {Sumit Gulwani and Oleksandr Polozov and Rishabh Singh}
}

###Article{	  gulwani2017synthesis,
  url		= {http://dx.doi.org/10.1561/2500000010},
  year		= {2017},
  volume	= {4},
  journal	= {Foundations and Trends in Programming Languages},
  title		= {Program Synthesis},
  doi		= {10.1561/2500000010},
  issn		= {2325-1107},
  number	= {1-2},
  pages		= {1--119},
  author	= {Sumit Gulwani and Oleksandr Polozov and Rishabh Singh}
}

@Article{	  haoxzwsm10,
  author	= {Dan Hao and Tao Xie and Lu Zhang and Xiaoyin Wang and
		  Jiasu Sun and Hong Mei},
  title		= {Test input reduction for result inspection to facilitate
		  fault localization},
  journal	= {Autom. Softw. Eng.},
  volume	= {17},
  number	= {1},
  pages		= {5--31},
  year		= {2010},
  url		= {https://doi.org/10.1007/s10515-009-0056-x},
  doi		= {10.1007/s10515-009-0056-x},
  timestamp	= {Fri, 06 Oct 2017 17:24:20 +0200},
  biburl	= {http://dblp.org/rec/bib/journals/ase/HaoXZWSM10},
  bibsource	= {dblp computer science bibliography, http://dblp.org}
}

@Article{	  haozxms09,
  author	= {Dan Hao and Lu Zhang and Tao Xie and Hong Mei and Jiasu
		  Sun},
  title		= {Interactive Fault Localization Using Test Information},
  journal	= {J. Comput. Sci. Technol.},
  volume	= {24},
  number	= {5},
  pages		= {962--974},
  year		= {2009},
  url		= {https://doi.org/10.1007/s11390-009-9270-z},
  doi		= {10.1007/s11390-009-9270-z},
  timestamp	= {Fri, 06 Oct 2017 17:24:20 +0200},
  biburl	= {https://dblp.org/rec/bib/journals/jcst/HaoZXMS09},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  haozzsm09,
  author	= {Dan Hao and Lingming Zhang and Lu Zhang and Jiasu Sun and
		  Hong Mei},
  title		= {{VIDA:} Visual interactive debugging},
  booktitle	= {31st International Conference on Software Engineering,
		  {ICSE} 2009, Vancouver, Canada, Proceedings},
  pages		= {583--586},
  publisher	= {{IEEE}},
  year		= {2009},
  url		= {https://doi.org/10.1109/ICSE.2009.5070561},
  doi		= {10.1109/ICSE.2009.5070561},
  timestamp	= {Tue, 23 May 2017 01:11:37 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/icse/HaoZZSM09},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Article{	  harrold2000empirical,
  author	= {Harrold, Mary Jean and Rothermel, Gregg and Sayre, Kent
		  and Wu, Rui and Yi, Liu},
  title		= {An empirical investigation of the relationship between
		  spectra differences and regression faults},
  journal	= {Software Testing, Verification and Reliability},
  volume	= {10},
  number	= {3},
  publisher	= {John Wiley & Sons, Ltd.},
  issn		= {1099-1689},
  url		= {http://dx.doi.org/10.1002/1099-1689(200009)10:3<171::AID-STVR209>3.0.CO;2-J},
  doi		= {10.1002/1099-1689(200009)10:3<171::AID-STVR209>3.0.CO;2-J},
  pages		= {171--194},
  keywords	= {program spectra, software testing, empirical studies},
  year		= {2000}
}

@Article{	  heidengkkhfl19,
  author	= {Simon Heiden and Lars Grunske and Timo Kehrer and Fabian
		  Keller and Andr{\'{e}} van Hoorn and Antonio Filieri and
		  David Lo},
  title		= {An evaluation of pure spectrum-based fault localization
		  techniques for large-scale software systems},
  journal	= {Softw. Pract. Exp.},
  volume	= {49},
  number	= {8},
  pages		= {1197--1224},
  year		= {2019},
  url		= {https://doi.org/10.1002/spe.2703},
  doi		= {10.1002/spe.2703}
}

###Article{	  heidengkkhfl19,
  author	= {Simon Heiden and Lars Grunske and Timo Kehrer and Fabian
		  Keller and Andr{\'{e}} van Hoorn and Antonio Filieri and
		  David Lo},
  title		= {An evaluation of pure spectrum-based fault localization
		  techniques for large-scale software systems},
  journal	= {Softw. Pract. Exp.},
  volume	= {49},
  number	= {8},
  pages		= {1197--1224},
  year		= {2019},
  url		= {https://doi.org/10.1002/spe.2703},
  doi		= {10.1002/spe.2703}
}

@InProceedings{	  herzig2013misclassification,
  author	= {Herzig, Kim and Just, Sascha and Zeller, Andreas},
  title		= {It\&\#039;s Not a Bug, It\&\#039;s a Feature: How
		  Misclassification Impacts Bug Prediction},
  booktitle	= {Proceedings of the 2013 International Conference on
		  Software Engineering},
  year		= {2013},
  isbn		= {978-1-4673-3076-3},
  location	= {San Francisco, CA, USA},
  pages		= {392--401},
  numpages	= {10},
  url		= {http://dl.acm.org/citation.cfm?id=2486788.2486840},
  acmid		= {2486840},
  publisher	= {IEEE Press},
  address	= {Piscataway, NJ, USA}
}

@Article{	  hongkljkkk17,
  author	= {Shin Hong and Taehoon Kwak and Byeongcheol Lee and Yiru
		  Jeon and Bongseok Ko and Yunho Kim and Moonzoo Kim},
  title		= {{MUSEUM:} Debugging real-world multilingual programs using
		  mutation analysis},
  journal	= {Information {\&} Software Technology},
  volume	= {82},
  pages		= {80--95},
  year		= {2017},
  url		= {https://doi.org/10.1016/j.infsof.2016.10.002},
  doi		= {10.1016/j.infsof.2016.10.002},
  timestamp	= {Wed, 17 May 2017 10:55:32 +0200},
  biburl	= {https://dblp.org/rec/bib/journals/infsof/HongKLJKKK17},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  honglkjkkk15,
  author	= {Shin Hong and Byeongcheol Lee and Taehoon Kwak and Yiru
		  Jeon and Bongsuk Ko and Yunho Kim and Moonzoo Kim},
  editor	= {Myra B. Cohen and Lars Grunske and Michael Whalen},
  title		= {Mutation-Based Fault Localization for Real-World
		  Multilingual Programs},
  booktitle	= {30th {IEEE/ACM} International Conference on Automated
		  Software Engineering, {ASE} 2015, Lincoln, NE, USA,
		  November 9-13, 2015},
  pages		= {464--475},
  publisher	= {{IEEE} Computer Society},
  year		= {2015},
  url		= {https://doi.org/10.1109/ASE.2015.14},
  doi		= {10.1109/ASE.2015.14},
  timestamp	= {Tue, 23 May 2017 01:06:50 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/kbse/HongLKJKKK15},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Article{	  hossainfdev23,
  author	= {Soneya Binta Hossain and Antonio Filieri and Matthew B.
		  Dwyer and Sebastian G. Elbaum and Willem Visser},
  title		= {Neural-Based Test Oracle Generation: {A} Large-scale
		  Evaluation and Lessons Learned},
  journal	= {CoRR},
  volume	= {abs/2307.16023},
  year		= {2023},
  url		= {https://doi.org/10.48550/arXiv.2307.16023},
  doi		= {10.48550/arXiv.2307.16023},
  eprinttype	= {arXiv},
  eprint	= {2307.16023}
}

@InProceedings{	  hu2019refactory,
  author	= {Hu, Yang and Ahmed, Umair Z. and Mechtaev, Sergey and
		  Leong, Ben and Roychoudhury, Abhik},
  booktitle	= {2019 34th IEEE/ACM International Conference on Automated
		  Software Engineering (ASE)},
  title		= {Re-Factoring Based Program Repair Applied to Programming
		  Assignments},
  year		= {2019},
  volume	= {},
  number	= {},
  pages		= {388-398},
  doi		= {10.1109/ASE.2019.00044}
}

###InProceedings{ hu2019refactory,
  author	= {Hu, Yang and Ahmed, Umair Z. and Mechtaev, Sergey and
		  Leong, Ben and Roychoudhury, Abhik},
  booktitle	= {2019 34th IEEE/ACM International Conference on Automated
		  Software Engineering (ASE)},
  title		= {Re-Factoring Based Program Repair Applied to Programming
		  Assignments},
  year		= {2019},
  volume	= {},
  number	= {},
  pages		= {388-398},
  doi		= {10.1109/ASE.2019.00044}
}

@InProceedings{	  ibrahimzadavtj22,
  author	= {Ali Reza Ibrahimzada and Yigit Varli and Dilara Tekinoglu
		  and Reyhaneh Jabbarvand},
  editor	= {Abhik Roychoudhury and Cristian Cadar and Miryung Kim},
  title		= {Perfect is the enemy of test oracle},
  booktitle	= {Proceedings of the 30th {ACM} Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering, {ESEC/FSE} 2022},
  pages		= {70--81},
  publisher	= {{ACM}},
  year		= {2022},
  url		= {https://doi.org/10.1145/3540250.3549086},
  doi		= {10.1145/3540250.3549086}
}

@InProceedings{	  jahangirovacht16,
  author	= {Gunel Jahangirova and David Clark and Mark Harman and
		  Paolo Tonella},
  editor	= {Andreas Zeller and Abhik Roychoudhury},
  title		= {Test oracle assessment and improvement},
  booktitle	= {Proceedings of the 25th International Symposium on
		  Software Testing and Analysis, {ISSTA} 2016},
  pages		= {247--258},
  publisher	= {{ACM}},
  year		= {2016},
  url		= {https://doi.org/10.1145/2931037.2931062},
  doi		= {10.1145/2931037.2931062}
}

@Article{	  jahangirovacht21,
  author	= {Gunel Jahangirova and David Clark and Mark Harman and
		  Paolo Tonella},
  title		= {An Empirical Validation of Oracle Improvement},
  journal	= {{IEEE} Trans. Software Eng.},
  volume	= {47},
  number	= {8},
  pages		= {1708--1728},
  year		= {2021},
  url		= {https://doi.org/10.1109/TSE.2019.2934409},
  doi		= {10.1109/TSE.2019.2934409}
}

@InProceedings{	  jiang2019combining,
  author	= {Jiang, Jiajun and Wang, Ran and Xiong, Yingfei and Chen,
		  Xiangping and Zhang, Lu},
  title		= {Combining Spectrum-Based Fault Localization and
		  Statistical Debugging: An Empirical Study},
  year		= {2019},
  isbn		= {9781728125084},
  publisher	= {IEEE Press},
  url		= {https://doi.org/10.1109/ASE.2019.00054},
  doi		= {10.1109/ASE.2019.00054},
  abstract	= {Program debugging is a time-consuming task, and
		  researchers have proposed different kinds of automatic
		  fault localization techniques to mitigate the burden of
		  manual debugging. Among these techniques, two popular
		  families are spectrum-based fault localization (SBFL) and
		  statistical debugging (SD), both localizing faults by
		  collecting statistical information at runtime. Though the
		  ideas are similar, the two families have been developed
		  independently and their combinations have not been
		  systematically explored.In this paper we perform a
		  systematical empirical study on the combination of SBFL and
		  SD. We first build a unified model of the two techniques,
		  and systematically explore four types of variations,
		  different predicates, different risk evaluation formulas,
		  different granularities of data collection, and different
		  methods of combining suspicious scores.Our study leads to
		  several findings. First, most of the effectiveness of the
		  combined approach contributed by a simple type of
		  predicates: branch conditions. Second, the risk evaluation
		  formulas of SBFL significantly outperform that of SD.
		  Third, fine-grained data collection significantly
		  outperforms coarse-grained data collection with a little
		  extra execution overhead. Fourth, a linear combination of
		  SBFL and SD predicates outperforms both individual
		  approaches.According to our empirical study, we propose a
		  new fault localization approach, PredFL (Predicate-based
		  Fault Localization), with the best configuration for each
		  dimension under the unified model. Then, we explore its
		  complementarity to existing techniques by integrating
		  PredFL with a state-of-the-art fault localization
		  framework. The experimental results show that PredFL can
		  further improve the effectiveness of state-of-the-art fault
		  localization techniques. More concretely, integrating
		  PredFL results in an up to 20.8% improvement w.r.t the
		  faults successfully located at Top-1, which reveals that
		  PredFL complements existing techniques.},
  booktitle	= {Proceedings of the 34th IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {502–514},
  numpages	= {13},
  keywords	= {program debugging, software engineering, fault
		  localization},
  location	= {San Diego, California},
  series	= {ASE '19}
}

###InProceedings{ jiang2019combining,
  author	= {Jiang, Jiajun and Wang, Ran and Xiong, Yingfei and Chen,
		  Xiangping and Zhang, Lu},
  title		= {Combining Spectrum-Based Fault Localization and
		  Statistical Debugging: An Empirical Study},
  year		= {2019},
  isbn		= {9781728125084},
  publisher	= {IEEE Press},
  url		= {https://doi.org/10.1109/ASE.2019.00054},
  doi		= {10.1109/ASE.2019.00054},
  abstract	= {Program debugging is a time-consuming task, and
		  researchers have proposed different kinds of automatic
		  fault localization techniques to mitigate the burden of
		  manual debugging. Among these techniques, two popular
		  families are spectrum-based fault localization (SBFL) and
		  statistical debugging (SD), both localizing faults by
		  collecting statistical information at runtime. Though the
		  ideas are similar, the two families have been developed
		  independently and their combinations have not been
		  systematically explored.In this paper we perform a
		  systematical empirical study on the combination of SBFL and
		  SD. We first build a unified model of the two techniques,
		  and systematically explore four types of variations,
		  different predicates, different risk evaluation formulas,
		  different granularities of data collection, and different
		  methods of combining suspicious scores.Our study leads to
		  several findings. First, most of the effectiveness of the
		  combined approach contributed by a simple type of
		  predicates: branch conditions. Second, the risk evaluation
		  formulas of SBFL significantly outperform that of SD.
		  Third, fine-grained data collection significantly
		  outperforms coarse-grained data collection with a little
		  extra execution overhead. Fourth, a linear combination of
		  SBFL and SD predicates outperforms both individual
		  approaches.According to our empirical study, we propose a
		  new fault localization approach, PredFL (Predicate-based
		  Fault Localization), with the best configuration for each
		  dimension under the unified model. Then, we explore its
		  complementarity to existing techniques by integrating
		  PredFL with a state-of-the-art fault localization
		  framework. The experimental results show that PredFL can
		  further improve the effectiveness of state-of-the-art fault
		  localization techniques. More concretely, integrating
		  PredFL results in an up to 20.8% improvement w.r.t the
		  faults successfully located at Top-1, which reveals that
		  PredFL complements existing techniques.},
  booktitle	= {Proceedings of the 34th IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {502–514},
  numpages	= {13},
  keywords	= {program debugging, software engineering, fault
		  localization},
  location	= {San Diego, California},
  series	= {ASE '19}
}

@Article{	  jiang2023variable,
  author	= {Jiang, Jiajun and Wang, Yumeng and Chen, Junjie and Lv,
		  Delin and Liu, Mengjiao},
  title		= {Variable-based Fault Localization via Enhanced Decision
		  Tree},
  year		= {2023},
  issue_date	= {February 2024},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {33},
  number	= {2},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/3624741},
  doi		= {10.1145/3624741},
  abstract	= {Fault localization, aiming at localizing the root cause of
		  the bug under repair, has been a longstanding research
		  topic. Although many approaches have been proposed in past
		  decades, most of the existing studies work at
		  coarse-grained statement or method levels with very limited
		  insights about how to repair the bug (granularity problem),
		  but few studies target the finer-grained fault
		  localization. In this article, we target the granularity
		  problem and propose a novel finer-grained variable-level
		  fault localization technique. Specifically, the basic idea
		  of our approach is that fault-relevant variables may
		  exhibit different values in failed and passed test runs,
		  and variables that have higher discrimination ability have
		  a larger possibility to be the root causes of the failure.
		  Based on this, we propose a program-dependency-enhanced
		  decision tree model to boost the identification of
		  fault-relevant variables via discriminating failed and
		  passed test cases based on the variable values. To evaluate
		  the effectiveness of our approach, we have implemented it
		  in a tool called VarDT and conducted an extensive study
		  over the Defects4J benchmark. The results show that VarDT
		  outperforms the state-of-the-art fault localization
		  approaches with at least 268.4\% improvement in terms of
		  bugs located at Top-1, and the average improvement is
		  351.3\%. Besides, to investigate whether our finer-grained
		  fault localization result can further improve the
		  effectiveness of downstream APR techniques, we have adapted
		  VarDT to the application of patch filtering, where we use
		  the variables located by VarDT to filter incorrect patches.
		  The results denote that VarDT outperforms the
		  state-of-the-art PATCH-SIM and BATS by filtering 14.8\% and
		  181.8\% more incorrect patches, respectively, demonstrating
		  the effectiveness of our approach. It also provides a new
		  way of thinking for improving automatic program repair
		  techniques.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {dec},
  articleno	= {41},
  numpages	= {32},
  keywords	= {Fault localization, program debugging, decision tree}
}

@InProceedings{	  jiangs07,
  author	= {Jiang, Lingxiao and Su, Zhendong},
  title		= {Context-aware Statistical Debugging: From Bug Predictors
		  to Faulty Control Flow Paths},
  booktitle	= {Proceedings of the Twenty-second IEEE/ACM International
		  Conference on Automated Software Engineering},
  year		= {2007},
  isbn		= {978-1-59593-882-4},
  location	= {Atlanta, Georgia, USA},
  pages		= {184--193},
  numpages	= {10},
  url		= {http://doi.acm.org/10.1145/1321631.1321660},
  doi		= {10.1145/1321631.1321660},
  acmid		= {1321660},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {bug localization, control flow analysis, machine learning,
		  statistical debugging}
}

@Article{	  jiangzctc12,
  author	= {Jiang, Bo and Zhang, Zhenyu and Chan, W. K. and Tse, T. H.
		  and Chen, Tsong Yueh},
  title		= {How Well Does Test Case Prioritization Integrate with
		  Statistical Fault Localization?},
  journal	= {Inf. Softw. Technol.},
  issue_date	= {July, 2012},
  volume	= {54},
  number	= {7},
  month		= jul,
  year		= {2012},
  issn		= {0950-5849},
  pages		= {739--758},
  numpages	= {20},
  url		= {http://dx.doi.org/10.1016/j.infsof.2012.01.006},
  doi		= {10.1016/j.infsof.2012.01.006},
  acmid		= {2206503},
  publisher	= {Butterworth-Heinemann},
  address	= {Newton, MA, USA},
  keywords	= {Adaptive random testing, Continuous integration, Coverage,
		  Software process integration, Statistical fault
		  localization, Test case prioritization}
}

@Article{	  jiangzctz13,
  author	= {Jiang, Bo and Zhai, Ke and Chan, W. K. and Tse, T. H. and
		  Zhang, Zhenyu},
  title		= {On the Adoption of MC/DC and Control-flow Adequacy for a
		  Tight Integration of Program Testing and Statistical Fault
		  Localization},
  journal	= {Inf. Softw. Technol.},
  issue_date	= {May, 2013},
  volume	= {55},
  number	= {5},
  month		= may,
  year		= {2013},
  issn		= {0950-5849},
  pages		= {897--917},
  numpages	= {21},
  url		= {http://dx.doi.org/10.1016/j.infsof.2012.10.001},
  doi		= {10.1016/j.infsof.2012.10.001},
  acmid		= {2452125},
  publisher	= {Butterworth-Heinemann},
  address	= {Newton, MA, USA},
  keywords	= {Adequacy criterion, Fault localization, MC/DC, Test case
		  prioritization, Testing-debugging integration}
}

@InProceedings{	  jin10ox,
  author	= {Jin, Wei and Orso, Alessandro and Xie, Tao},
  title		= {Automated Behavioral Regression Testing},
  booktitle	= {Proceedings of the 2010 Third International Conference on
		  Software Testing, Verification and Validation},
  year		= {2010},
  isbn		= {978-0-7695-3990-4},
  pages		= {137--146},
  numpages	= {10},
  url		= {http://dx.doi.org/10.1109/ICST.2010.64},
  doi		= {10.1109/ICST.2010.64},
  acmid		= {1828455},
  publisher	= {IEEE Computer Society},
  address	= {Washington, DC, USA},
  keywords	= {Regression testing, software evolution, dynamic analysis}
}

@InProceedings{	  jones07hb,
  author	= {Jones, James A. and Bowring, James F. and Harrold, Mary
		  Jean},
  title		= {Debugging in Parallel},
  booktitle	= {Proceedings of the 2007 International Symposium on
		  Software Testing and Analysis},
  year		= {2007},
  isbn		= {978-1-59593-734-6},
  location	= {London, United Kingdom},
  pages		= {16--26},
  numpages	= {11},
  url		= {http://doi.acm.org/10.1145/1273463.1273468},
  doi		= {10.1145/1273463.1273468},
  acmid		= {1273468},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {automated debugging, empirical study, execution
		  clustering, fault localization, program analysis}
}

@InProceedings{	  jones2002tarantula,
  author	= {Jones, James A. and Harrold, Mary Jean and Stasko, John},
  title		= {Visualization of Test Information to Assist Fault
		  Localization},
  booktitle	= {Proceedings of the 24th International Conference on
		  Software Engineering},
  _booktitle	= {ICSE '02},
  year		= {2002},
  isbn		= {1-58113-472-X},
  location	= {Orlando, Florida},
  pages		= {467--477},
  numpages	= {11},
  url		= {http://doi.acm.org/10.1145/581339.581397},
  doi		= {10.1145/581339.581397},
  acmid		= {581397},
  _publisher	= {ACM},
  address	= {New York, NY, USA}
}

###InProceedings{ jones2002tarantula,
  author	= {Jones, J.A. and Harrold, M.J. and Stasko, J.},
  booktitle	= {Proceedings of the 24th International Conference on
		  Software Engineering. ICSE 2002},
  title		= {Visualization of test information to assist fault
		  localization},
  year		= {2002},
  volume	= {},
  number	= {},
  pages		= {467-477},
  doi		= {10.1145/581396.581397}
}

@InProceedings{	  jones2002visualization,
  author	= {Jones, James A. and Harrold, Mary Jean and Stasko, John},
  title		= {Visualization of Test Information to Assist Fault
		  Localization},
  booktitle	= {Proceedings of the 24th International Conference on
		  Software Engineering},
  year		= {2002},
  isbn		= {1-58113-472-X},
  location	= {Orlando, Florida},
  pages		= {467--477},
  numpages	= {11},
  url		= {http://doi.acm.org/10.1145/581339.581397},
  doi		= {10.1145/581339.581397},
  acmid		= {581397},
  publisher	= {ACM},
  address	= {New York, NY, USA}
}

@InProceedings{	  jones2005empirical,
  title		= {Empirical evaluation of the tarantula automatic
		  fault-localization technique},
  author	= {Jones, James A and Harrold, Mary Jean},
  booktitle	= {Proceedings of the 20th IEEE/ACM international Conference
		  on Automated software engineering},
  pages		= {273--282},
  year		= {2005},
  organization	= {ACM}
}

@InProceedings{	  jones2005tarantula,
  author	= {Jones, James A. and Harrold, Mary Jean},
  title		= {Empirical evaluation of the {Tarantula} automatic
		  fault-localization technique},
  year		= {2005},
  isbn		= {1581139934},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1101908.1101949},
  doi		= {10.1145/1101908.1101949},
  abstract	= {The high cost of locating faults in programs has motivated
		  the development of techniques that assist in fault
		  localization by automating part of the process of searching
		  for faults. Empirical studies that compare these techniques
		  have reported the relative effectiveness of four existing
		  techniques on a set of subjects. These studies compare the
		  rankings that the techniques compute for statements in the
		  subject programs and the effectiveness of these rankings in
		  locating the faults. However, it is unknown how these four
		  techniques compare with Tarantula, another existing
		  fault-localization technique, although this technique also
		  provides a way to rank statements in terms of their
		  suspiciousness. Thus, we performed a study to compare the
		  Tarantula technique with the four techniques previously
		  compared. This paper presents our study---it overviews the
		  Tarantula technique along with the four other techniques
		  studied, describes our experiment, and reports and
		  discusses the results. Our studies show that, on the same
		  set of subjects, the Tarantula technique consistently
		  outperforms the other four techniques in terms of
		  effectiveness in fault localization, and is comparable in
		  efficiency to the least expensive of the other four
		  techniques.},
  booktitle	= {Proceedings of the 20th IEEE/ACM International Conference
		  on Automated Software Engineering},
  pages		= {273–282},
  numpages	= {10},
  keywords	= {automated debugging, empirical study, fault localization,
		  program analysis},
  location	= {Long Beach, CA, USA},
  series	= {ASE '05}
}

###InProceedings{ jones2005tarantula,
  author	= {Jones, James A. and Harrold, Mary Jean},
  title		= {Empirical Evaluation of the tarantula Automatic
		  Fault-Localization Technique},
  year		= {2005},
  isbn		= {1581139934},
  publisher	= acm,
  publisheraddress={New York, NY, USA},
  url		= {https://doi.org/10.1145/1101908.1101949},
  doi		= {10.1145/1101908.1101949},
  booktitle	= ase,
  pages		= {273--282},
  numpages	= {10},
  keywords	= {program analysis, fault localization, automated debugging,
		  empirical study},
  location	= {Long Beach, CA, USA}
}

@PhDThesis{	  jones2008semi,
  author	= {Jones, James Arthur},
  advisor	= {Harrold, Mary Jean},
  title		= {Semi-automatic Fault Localization},
  year		= {2008},
  isbn		= {978-0-549-55983-2},
  note		= {AAI3308774},
  publisher	= {Georgia Institute of Technology},
  address	= {Atlanta, GA, USA}
}

@Article{	  jones2014fault,
  author	= {Digiuseppe, Nicholas and Jones, James A.},
  title		= {Fault Density, Fault Types, and Spectra-based Fault
		  Localization},
  journal	= {Empirical Softw. Engg.},
  issue_date	= {August 2015},
  volume	= {20},
  number	= {4},
  month		= aug,
  year		= {2015},
  issn		= {1382-3256},
  pages		= {928--967},
  numpages	= {40},
  url		= {http://dx.doi.org/10.1007/s10664-014-9304-1},
  doi		= {10.1007/s10664-014-9304-1},
  acmid		= {2790635},
  publisher	= {Kluwer Academic publishers},
  address	= {Hingham, MA, USA},
  keywords	= {Debugging, Fault behavior, Fault localization}
}

@InProceedings{	  just2018sfl,
  author	= {Just, Ren\'{e} and Parnin, Chris and Drosos, Ian and
		  Ernst, Michael D.},
  title		= {Comparing developer-provided to user-provided tests for
		  fault localization and automated program repair},
  year		= {2018},
  isbn		= {9781450356992},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3213846.3213870},
  doi		= {10.1145/3213846.3213870},
  abstract	= {To realistically evaluate a software testing or debugging
		  technique, it must be run on defects and tests that are
		  characteristic of those a developer would encounter in
		  practice. For example, to determine the utility of a fault
		  localization or automated program repair technique, it
		  could be run on real defects from a bug tracking system,
		  using real tests that are committed to the version control
		  repository along with the fixes. Although such a
		  methodology uses real tests, it may not use tests that are
		  characteristic of the information a developer or tool would
		  have in practice. The tests that a developer commits after
		  fixing a defect may encode more information than was
		  available to the developer when initially diagnosing the
		  defect. This paper compares, both quantitatively and
		  qualitatively, the developer-provided tests committed along
		  with fixes (as found in the version control repository)
		  versus the user-provided tests extracted from bug reports
		  (as found in the issue tracker). It provides evidence that
		  developer-provided tests are more targeted toward the
		  defect and encode more information than user-provided
		  tests. For fault localization, developer-provided tests
		  overestimate a technique’s ability to rank a defective
		  statement in the list of the top-n most suspicious
		  statements. For automated program repair,
		  developer-provided tests overestimate a technique’s
		  ability to (efficiently) generate correct
		  patches—user-provided tests lead to fewer correct patches
		  and increased repair time. This paper also provides
		  suggestions for improving the design and evaluation of
		  fault localization and automated program repair
		  techniques.},
  booktitle	= {Proceedings of the 27th ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {287–297},
  numpages	= {11},
  keywords	= {Test effectiveness, Fault localization, Automated program
		  repair},
  location	= {Amsterdam, Netherlands},
  series	= {ISSTA 2018}
}

@InProceedings{	  justje14,
  author	= {Just, Ren{\'e} and Jalali, Darioush and Ernst, Michael D.},
  title		= {Defects4J: A Database of Existing Faults to Enable
		  Controlled Testing Studies for Java Programs},
  booktitle	= {Proceedings of the 2014 International Symposium on
		  Software Testing and Analysis},
  year		= {2014},
  isbn		= {978-1-4503-2645-2},
  location	= {San Jose, CA, USA},
  pages		= {437--440},
  numpages	= {4},
  url		= {http://doi.acm.org/10.1145/2610384.2628055},
  doi		= {10.1145/2610384.2628055},
  acmid		= {2628055},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Bug database, real bugs, testing framework}
}

@InProceedings{	  kampmann2020alhazen,
  author	= {Kampmann, Alexander and Havrikov, Nikolas and Soremekun,
		  Ezekiel O. and Zeller, Andreas},
  title		= {When does my program do this? learning circumstances of
		  software behavior},
  year		= {2020},
  isbn		= {9781450370431},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3368089.3409687},
  doi		= {10.1145/3368089.3409687},
  abstract	= {A program fails. Under which circumstances does the
		  failure occur? Our Alhazenapproach starts with a run that
		  exhibits a particular behavior and automatically determines
		  input features associated with the behavior in question:
		  (1) We use a grammar to parse the input into individual
		  elements. (2) We use a decision tree learner to observe and
		  learn which input elements are associated with the behavior
		  in question. (3) We use the grammar to generate additional
		  inputs to further strengthen or refute hypotheses as
		  learned associations. (4) By repeating steps
		  2&nbsp;and&nbsp;3, we obtain a theory that explains and
		  predicts the given behavior. In our evaluation using inputs
		  for find, grep, NetHack, and a JavaScript transpiler, the
		  theories produced by Alhazen predict and produce failures
		  with high accuracy and allow developers to focus on a small
		  set of input features: “grep fails whenever the
		  --fixed-strings option is used in conjunction with an empty
		  search string.”},
  booktitle	= {Proceedings of the 28th ACM Joint Meeting on European
		  Software Engineering Conference and Symposium on the
		  Foundations of Software Engineering},
  pages		= {1228–1239},
  numpages	= {12},
  keywords	= {debugging, error diagnosis, machine learning, software
		  behavior},
  location	= {Virtual Event, USA},
  series	= {ESEC/FSE 2020}
}

@Article{	  kang2024llm,
  author	= {Kang, Sungmin and An, Gabin and Yoo, Shin},
  title		= {A Quantitative and Qualitative Evaluation of LLM-Based
		  Explainable Fault Localization},
  year		= {2024},
  issue_date	= {July 2024},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {1},
  number	= {FSE},
  url		= {https://doi.org/10.1145/3660771},
  doi		= {10.1145/3660771},
  abstract	= {Fault Localization (FL), in which a developer seeks to
		  identify which part of the code is malfunctioning and needs
		  to be fixed, is a recurring challenge in debugging. To
		  reduce developer burden, many automated FL techniques have
		  been proposed. However, prior work has noted that existing
		  techniques fail to provide rationales for the suggested
		  locations, hindering developer adoption of these
		  techniques. With this in mind, we propose AutoFL, a Large
		  Language Model (LLM)-based FL technique that generates an
		  explanation of the bug along with a suggested fault
		  location. AutoFL prompts an LLM to use function calls to
		  navigate a repository, so that it can effectively localize
		  faults over a large software repository and overcome the
		  limit of the LLM context length. Extensive experiments on
		  798 real-world bugs in Java and Python reveal AutoFL
		  improves method-level acc@1 by up to 233.3\% over
		  baselines. Furthermore, developers were interviewed on
		  their impression of AutoFL-generated explanations, showing
		  that developers generally liked the natural language
		  explanations of AutoFL, and that they preferred reading a
		  few, high-quality explanations instead of many.},
  journal	= {Proc. ACM Softw. Eng.},
  month		= {jul},
  articleno	= {64},
  numpages	= {23},
  keywords	= {debugging, fault localization, language models}
}

@InProceedings{	  kawrykow2011,
  author	= {Kawrykow, David and Robillard, Martin P.},
  title		= {Non-essential Changes in Version Histories},
  booktitle	= {Proceedings of the 33rd International Conference on
		  Software Engineering},
  year		= {2011},
  isbn		= {978-1-4503-0445-0},
  location	= {Waikiki, Honolulu, HI, USA},
  pages		= {351--360},
  numpages	= {10},
  url		= {http://doi.acm.org/10.1145/1985793.1985842},
  doi		= {10.1145/1985793.1985842},
  acmid		= {1985842},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {differencing algorithms, mining software repositories,
		  software change analysis}
}

@Article{	  king76,
  author	= {James C. King},
  title		= {Symbolic Execution and Program Testing},
  journal	= {Commun. {ACM}},
  volume	= {19},
  number	= {7},
  pages		= {385--394},
  year		= {1976},
  url		= {https://doi.org/10.1145/360248.360252},
  doi		= {10.1145/360248.360252}
}

@InProceedings{	  kochharxll16,
  author	= {Kochhar, Pavneet Singh and Xia, Xin and Lo, David and Li,
		  Shanping},
  title		= {Practitioners' Expectations on Automated Fault
		  Localization},
  booktitle	= {ISSTA 2016},
  year		= {2016},
  isbn		= {978-1-4503-4390-9},
  location	= {Saarbr\&\#252;cken, Germany},
  pages		= {165--176},
  numpages	= {12},
  url		= {http://doi.acm.org/10.1145/2931037.2931051},
  doi		= {10.1145/2931037.2931051},
  acmid		= {2931051},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Empirical Study, Fault Localization, Practitioners\&\#039;
		  Expectations}
}

@InProceedings{	  kom08,
  author	= {Andrew Jensen Ko and Brad A. Myers},
  editor	= {Wilhelm Sch{\"{a}}fer and Matthew B. Dwyer and Volker
		  Gruhn},
  title		= {Debugging reinvented: asking and answering why and why not
		  questions about program behavior},
  booktitle	= {30th International Conference on Software Engineering
		  {(ICSE} 2008), Leipzig, Germany, May 10-18, 2008},
  pages		= {301--310},
  publisher	= {{ACM}},
  year		= {2008},
  url		= {http://doi.acm.org/10.1145/1368088.1368130},
  doi		= {10.1145/1368088.1368130}
}

@Article{	  korel1988dynamic,
  author	= {Korel, B. and Laski, J.},
  title		= {Dynamic Program Slicing},
  journal	= {Inf. Process. Lett.},
  issue_date	= {October 26, 1988},
  volume	= {29},
  number	= {3},
  month		= oct,
  year		= {1988},
  issn		= {0020-0190},
  pages		= {155--163},
  numpages	= {9},
  url		= {http://dx.doi.org/10.1016/0020-0190(88)90054-3},
  doi		= {10.1016/0020-0190(88)90054-3},
  acmid		= {56386},
  publisher	= {Elsevier North-Holland, Inc.},
  address	= {Amsterdam, The Netherlands, The Netherlands}
}

@InProceedings{	  landsberg2015sfl,
  author	= {Landsberg, David and Chockler, Hana and Kroening, Daniel
		  and Lewis, Matt},
  editor	= {Egyed, Alexander and Schaefer, Ina},
  title		= {Evaluation of Measures for Statistical Fault Localisation
		  and an Optimising Scheme},
  booktitle	= {Fundamental Approaches to Software Engineering},
  year		= {2015},
  publisher	= {Springer Berlin Heidelberg},
  address	= {Berlin, Heidelberg},
  pages		= {115--129},
  url		= {https://doi.org/10.1007/978-3-662-46675-9_8},
  doi		= {10.1007/978-3-662-46675-9_8},
  abstract	= {Statistical Fault Localisation (SFL) is a widely used
		  method for localizing faults in software. SFL gathers
		  coverage details of passed and failed executions over a
		  faulty program and then uses a measure to assign a degree
		  of suspiciousness to each of a chosen set of program
		  entities (statements, predicates, etc.) in that program.
		  The program entities are then inspected by the engineer in
		  descending order of suspiciousness until the bug is found.
		  The effectiveness of this process relies on the quality of
		  the suspiciousness measure. In this paper, we compare 157
		  measures, 95 of which are new to SFL and borrowed from
		  other branches of science and philosophy. We also present a
		  new measure optimiser Lexg, which optimises a given measure
		  g according to a criterion of single bug optimality. An
		  experimental comparison on benchmarks from the
		  Software-artifact Infrastructure Repository (SIR) indicates
		  that many of the new measures perform competitively with
		  the established ones. Furthermore, the large-scale
		  comparison reveals that the new measures LexOchiaiand
		  Pattern-Similarity perform best overall.},
  isbn		= {978-3-662-46675-9}
}

###InProceedings{ landsberg2015sfl,
  author	= {Landsberg, David and Chockler, Hana and Kroening, Daniel
		  and Lewis, Matt},
  editor	= {Egyed, Alexander and Schaefer, Ina},
  title		= {Evaluation of Measures for Statistical Fault Localisation
		  and an Optimising Scheme},
  booktitle	= {Fundamental Approaches to Software Engineering},
  year		= {2015},
  publisher	= {Springer Berlin Heidelberg},
  address	= {Berlin, Heidelberg},
  pages		= {115--129},
  url		= {https://doi.org/10.1007/978-3-662-46675-9_8},
  doi		= {10.1007/978-3-662-46675-9_8},
  abstract	= {Statistical Fault Localisation (SFL) is a widely used
		  method for localizing faults in software. SFL gathers
		  coverage details of passed and failed executions over a
		  faulty program and then uses a measure to assign a degree
		  of suspiciousness to each of a chosen set of program
		  entities (statements, predicates, etc.) in that program.
		  The program entities are then inspected by the engineer in
		  descending order of suspiciousness until the bug is found.
		  The effectiveness of this process relies on the quality of
		  the suspiciousness measure. In this paper, we compare 157
		  measures, 95 of which are new to SFL and borrowed from
		  other branches of science and philosophy. We also present a
		  new measure optimiser Lexg, which optimises a given measure
		  g according to a criterion of single bug optimality. An
		  experimental comparison on benchmarks from the
		  Software-artifact Infrastructure Repository (SIR) indicates
		  that many of the new measures perform competitively with
		  the established ones. Furthermore, the large-scale
		  comparison reveals that the new measures LexOchiaiand
		  Pattern-Similarity perform best overall.},
  isbn		= {978-3-662-46675-9}
}

@InProceedings{	  langdonyh17,
  author	= {William B. Langdon and Shin Yoo and Mark Harman},
  title		= {Inferring Automatic Test Oracles},
  booktitle	= {10th {IEEE/ACM} International Workshop on Search-Based
		  Software Testing, SBST@ICSE 2017},
  pages		= {5--6},
  publisher	= {{IEEE}},
  year		= {2017},
  url		= {https://doi.org/10.1109/SBST.2017.1},
  doi		= {10.1109/SBST.2017.1}
}

@InProceedings{	  le13l,
  author	= {Tien{-}Duy B. Le and David Lo},
  booktitle	= {ICSM},
  title		= {Will Fault Localization Work for These Failures? An
		  Automated Approach to Predict Effectiveness of Fault
		  Localization Tools},
  year		= {2013},
  pages		= {310--319},
  doi		= {10.1109/ICSM.2013.42},
  issn		= {1063-6773},
  month		= {Sept}
}

@InProceedings{	  le2010path,
  author	= {Le, Wei and Soffa, Mary Lou},
  title		= {Path-based fault correlations},
  year		= {2010},
  isbn		= {9781605587912},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1882291.1882336},
  doi		= {10.1145/1882291.1882336},
  abstract	= {Although a number of automatic tools have been developed
		  to detect faults, much of the diagnosis is still being done
		  manually. To help with the diagnostic tasks, we formally
		  introduce fault correlation, a causal relationship between
		  faults. We statically determine correlations based on the
		  expected dynamic behavior of a fault. If the occurrence of
		  one fault causes another fault to occur, we say they are
		  correlated. With the identification of the correlated
		  faults, we can better understand fault behaviors and the
		  risks of faults. If one fault is uniquely correlated with
		  another, we know fixing the first fault will fix the other.
		  Correlated faults can be grouped, enabling prioritization
		  of diagnoses of the fault groups. In this paper, we develop
		  an interprocedural, path-sensitive, and scalable algorithm
		  to automatically compute correlated faults in a program. In
		  our approach, we first statically detect faults and
		  determine their error states. By propagating the effects of
		  the error state along a path, we detect the correlation of
		  pairs of faults. We automatically construct a correlation
		  graph which shows how correlations occur among multiple
		  faults and along different paths. Guided by a correlation
		  graph, we can reduce the number of faults required for
		  diagnosis to find root causes. We implemented our
		  correlation algorithm and found through experimentation
		  that faults involved in the correlations can be of
		  different types and located in different procedures. Using
		  correlation information, we are able to automate diagnostic
		  tasks that previously had to be done manually.},
  booktitle	= {Proceedings of the Eighteenth ACM SIGSOFT International
		  Symposium on Foundations of Software Engineering},
  pages		= {307–316},
  numpages	= {10},
  keywords	= {path-sensitive, fault correlation, error state,
		  demand-driven},
  location	= {Santa Fe, New Mexico, USA},
  series	= {FSE '10}
}

@InProceedings{	  le2015topk,
  author	= {Le, Tien-Duy B. and Lo, David and Li, Ming},
  title		= {Constrained feature selection for localizing faults},
  year		= {2015},
  isbn		= {9781467375320},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/ICSM.2015.7332502},
  doi		= {10.1109/ICSM.2015.7332502},
  abstract	= {Developers often take much time and effort to find buggy
		  program elements. To help developers debug, many past
		  studies have proposed spectrum-based fault localization
		  techniques. These techniques compare and contrast correct
		  and faulty execution traces and highlight suspicious
		  program elements. In this work, we propose constrained
		  feature selection algorithms that we use to localize
		  faults. Feature selection algorithms are commonly used to
		  identify important features that are helpful for a
		  classification task. By mapping an execution trace to a
		  classification instance and a program element to a feature,
		  we can transform fault localization to the feature
		  selection problem. Unfortunately, existing feature
		  selection algorithms do not perform too well, and we extend
		  its performance by adding a constraint to the feature
		  selection formulation based on a specific characteristic of
		  the fault localization problem. We have performed
		  experiments on a popular benchmark containing 154 faulty
		  versions from 8 programs and demonstrate that several
		  variants of our approach can outperform many fault
		  localization techniques proposed in the literature. Using
		  Wilcoxon rank-sum test and Cliff's d effect size, we also
		  show that the improvements are both statistically
		  significant and substantial.},
  booktitle	= {Proceedings of the 2015 IEEE International Conference on
		  Software Maintenance and Evolution (ICSME)},
  pages		= {501–505},
  numpages	= {5},
  series	= {ICSME '15}
}

@Article{	  lee2009naish,
  author	= {Lee, Hua and Naish, Lee and Ramamohanarao, Kotagiri},
  year		= {2009},
  month		= {08},
  pages		= {127-134},
  title		= {The Effectiveness of Using Non redundant Test Cases with
		  Program Spectra for Bug Localization},
  volume	= {0},
  isbn		= {978-1-4244-4519-6},
  journal	= {Computer Science and Information Technology, International
		  Conference on},
  doi		= {10.1109/ICCSIT.2009.5234587}
}

###Article{	  lee2009naish,
  author	= {Lee, Hua and Naish, Lee and Ramamohanarao, Kotagiri},
  year		= {2009},
  month		= {08},
  pages		= {127-134},
  title		= {The Effectiveness of Using Non redundant Test Cases with
		  Program Spectra for Bug Localization},
  volume	= {0},
  isbn		= {978-1-4244-4519-6},
  journal	= {Computer Science and Information Technology, International
		  Conference on},
  doi		= {10.1109/ICCSIT.2009.5234587}
}

@Article{	  lei2022featurefl,
  author	= {Lei, Yan and Xie, Huan and Zhang, Tao and Yan, Meng and
		  Xu, Zhou and Sun, Chengnian},
  journal	= {IEEE Transactions on Reliability},
  title		= {Feature-FL: Feature-Based Fault Localization},
  year		= {2022},
  volume	= {71},
  number	= {1},
  pages		= {264-283},
  keywords	= {Location awareness;Feature
		  extraction;Correlation;Debugging;Data models;Codes;Computer
		  bugs;Execution probability;fault localization;feature
		  selection;statistical debugging;suspiciousness},
  doi		= {10.1109/TR.2022.3140453}
}

@InProceedings{	  lelgg16,
  author	= {Tien{-}Duy B. Le and David Lo and Claire {Le Goues} and
		  Lars Grunske},
  _editor	= {Andreas Zeller and Abhik Roychoudhury},
  title		= {A learning-to-rank based fault localization approach using
		  likely invariants},
  booktitle	= {Proceedings of the 25th International Symposium on
		  Software Testing and Analysis, {ISSTA} 2016},
  pages		= {177--188},
  _publisher	= {{ACM}},
  year		= {2016},
  url		= {http://doi.acm.org/10.1145/2931037.2931049},
  doi		= {10.1145/2931037.2931049}
}

###InProceedings{ lelgg16,
  author	= {Tien{-}Duy B. Le and David Lo and Claire {Le Goues} and
		  Lars Grunske},
  editor	= {Andreas Zeller and Abhik Roychoudhury},
  title		= {A learning-to-rank based fault localization approach using
		  likely invariants},
  booktitle	= {Proceedings of the 25th International Symposium on
		  Software Testing and Analysis, {ISSTA} 2016},
  pages		= {177--188},
  publisher	= {{ACM}},
  year		= {2016},
  url		= {http://doi.acm.org/10.1145/2931037.2931049},
  doi		= {10.1145/2931037.2931049}
}

@InProceedings{	  lemieux2018fairfuzz,
  author	= {Caroline Lemieux and Koushik Sen},
  _editor	= {Marianne Huchard and Christian K{\"{a}}stner and Gordon
		  Fraser},
  title		= {FairFuzz: a targeted mutation strategy for increasing
		  greybox fuzz testing coverage},
  booktitle	= {Proceedings of the 33rd {ACM/IEEE} International
		  Conference on Automated Software Engineering, {ASE} 2018},
  pages		= {475--485},
  publisher	= {{ACM}},
  year		= {2018},
  url		= {https://doi.org/10.1145/3238147.3238176},
  doi		= {10.1145/3238147.3238176},
  timestamp	= {Thu, 23 Jun 2022 19:54:17 +0200},
  biburl	= {https://dblp.org/rec/conf/kbse/LemieuxS18.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

###InProceedings{ lemieux2018fairfuzz,
  author	= {Caroline Lemieux and Koushik Sen},
  _editor	= {Marianne Huchard and Christian K{\"{a}}stner and Gordon
		  Fraser},
  title		= {FairFuzz: a targeted mutation strategy for increasing
		  greybox fuzz testing coverage},
  booktitle	= {Proceedings of the 33rd {ACM/IEEE} International
		  Conference on Automated Software Engineering, {ASE} 2018},
  pages		= {475--485},
  publisher	= {{ACM}},
  year		= {2018},
  url		= {https://doi.org/10.1145/3238147.3238176},
  doi		= {10.1145/3238147.3238176},
  timestamp	= {Thu, 23 Jun 2022 19:54:17 +0200},
  biburl	= {https://dblp.org/rec/conf/kbse/LemieuxS18.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  lemieux2018perffuzz,
  author	= {Caroline Lemieux and Rohan Padhye and Koushik Sen and Dawn
		  Song},
  editor	= {Frank Tip and Eric Bodden},
  title		= {PerfFuzz: automatically generating pathological inputs},
  booktitle	= {Proceedings of the 27th {ACM} {SIGSOFT} International
		  Symposium on Software Testing and Analysis},
  pages		= {254--265},
  publisher	= {{ACM}},
  year		= {2018},
  url		= {https://doi.org/10.1145/3213846.3213874},
  doi		= {10.1145/3213846.3213874},
  timestamp	= {Wed, 21 Nov 2018 12:44:15 +0100},
  biburl	= {https://dblp.org/rec/conf/issta/LemieuxPSS18.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

###InProceedings{ lemieux2018perffuzz,
  author	= {Caroline Lemieux and Rohan Padhye and Koushik Sen and Dawn
		  Song},
  editor	= {Frank Tip and Eric Bodden},
  title		= {PerfFuzz: automatically generating pathological inputs},
  booktitle	= {Proceedings of the 27th {ACM} {SIGSOFT} International
		  Symposium on Software Testing and Analysis},
  pages		= {254--265},
  publisher	= {{ACM}},
  year		= {2018},
  url		= {https://doi.org/10.1145/3213846.3213874},
  doi		= {10.1145/3213846.3213874},
  timestamp	= {Wed, 21 Nov 2018 12:44:15 +0100},
  biburl	= {https://dblp.org/rec/conf/issta/LemieuxPSS18.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  leol15,
  author	= {Tien{-}Duy B. Le and Richard Jayadi Oentaryo and David
		  Lo},
  title		= {Information retrieval and spectrum based bug localization:
		  better together},
  booktitle	= {Proceedings of the 2015 10th Joint Meeting on Foundations
		  of Software Engineering, {ESEC/FSE} 2015},
  pages		= {579--590},
  year		= {2015}
}

@Article{	  li2017transforming,
  title		= {Transforming programs and tests in tandem for fault
		  localization},
  author	= {Li, Xia and Zhang, Lingming},
  journal	= {Proceedings of the ACM on Programming Languages},
  volume	= {1},
  number	= {OOPSLA},
  pages		= {92},
  year		= {2017},
  publisher	= {ACM}
}

@InProceedings{	  li2019deepfl,
  author	= {Li, Xia and Li, Wei and Zhang, Yuqun and Zhang, Lingming},
  title		= {DeepFL: integrating multiple fault diagnosis dimensions
		  for deep fault localization},
  year		= {2019},
  isbn		= {9781450362245},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3293882.3330574},
  doi		= {10.1145/3293882.3330574},
  abstract	= {Learning-based fault localization has been intensively
		  studied recently. Prior studies have shown that traditional
		  Learning-to-Rank techniques can help precisely diagnose
		  fault locations using various dimensions of fault-diagnosis
		  features, such as suspiciousness values computed by various
		  off-the-shelf fault localization techniques. However, with
		  the increasing dimensions of features considered by
		  advanced fault localization techniques, it can be quite
		  challenging for the traditional Learning-to-Rank algorithms
		  to automatically identify effective existing/latent
		  features. In this work, we propose DeepFL, a deep learning
		  approach to automatically learn the most effective
		  existing/latent features for precise fault localization.
		  Although the approach is general, in this work, we collect
		  various suspiciousness-value-based, fault-proneness-based
		  and textual-similarity-based features from the fault
		  localization, defect prediction and information retrieval
		  areas, respectively. DeepFL has been studied on 395 real
		  bugs from the widely used Defects4J benchmark. The
		  experimental results show DeepFL can significantly
		  outperform state-of-the-art TraPT/FLUCCS (e.g., localizing
		  50+ more faults within Top-1). We also investigate the
		  impacts of deep model configurations (e.g., loss functions
		  and epoch settings) and features. Furthermore, DeepFL is
		  also surprisingly effective for cross-project prediction.},
  booktitle	= {Proceedings of the 28th ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {169–180},
  numpages	= {12},
  keywords	= {Deep learning, Fault localization, Mutation testing},
  location	= {Beijing, China},
  series	= {ISSTA 2019}
}

@InProceedings{	  li2021covrepresentation,
  author	= {Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
  title		= {Fault Localization with Code Coverage Representation
		  Learning},
  year		= {2021},
  isbn		= {9781450390859},
  publisher	= {IEEE Press},
  url		= {https://doi.org/10.1109/ICSE43902.2021.00067},
  doi		= {10.1109/ICSE43902.2021.00067},
  abstract	= {In this paper, we propose DEEPRL4FL, a deep learning fault
		  localization (FL) approach that locates the buggy code at
		  the statement and method levels by treating FL as an image
		  pattern recognition problem. DEEPRL4FL does so via novel
		  code coverage representation learning (RL) and data
		  dependencies RL for program statements. Those two types of
		  RL on the dynamic information in a code coverage matrix are
		  also combined with the code representation learning on the
		  static information of the usual suspicious source code.
		  This combination is inspired by crime scene investigation
		  in which investigators analyze the crime scene (failed test
		  cases and statements) and related persons (statements with
		  dependencies), and at the same time, examine the usual
		  suspects who have committed a similar crime in the past
		  (similar buggy code in the training data).For the code
		  coverage information, DEEPRL4FL first orders the test cases
		  and marks error-exhibiting code statements, expecting that
		  a model can recognize the patterns discriminating between
		  faulty and non-faulty statements/methods. For dependencies
		  among statements, the suspiciousness of a statement is seen
		  taking into account the data dependencies to other
		  statements in execution and data flows, in addition to the
		  statement by itself. Finally, the vector representations
		  for code coverage matrix, data dependencies among
		  statements, and source code are combined and used as the
		  input of a classifier built from a Convolution Neural
		  Network to detect buggy statements/methods. Our empirical
		  evaluation shows that DEEPRL4FL improves the top-1 results
		  over the state-of-the-art statement-level FL baselines from
		  173.1\% to 491.7\%. It also improves the top-1 results over
		  the existing method-level FL baselines from 15.0\% to
		  206.3\%.},
  booktitle	= {Proceedings of the 43rd International Conference on
		  Software Engineering},
  pages		= {661–673},
  numpages	= {13},
  keywords	= {representation learning, machine learning, fault
		  localization, deep learning, code coverage},
  location	= {Madrid, Spain},
  series	= {ICSE '21}
}

@InProceedings{	  li2022cc,
  author	= {Li, Yi and Wang, Shaohua and Nguyen, Tien N.},
  title		= {Fault localization to detect co-change fixing locations},
  year		= {2022},
  isbn		= {9781450394130},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3540250.3549137},
  doi		= {10.1145/3540250.3549137},
  abstract	= {Fault Localization (FL) is a precursor step to most
		  Automated Program Repair (APR) approaches, which fix the
		  faulty statements identified by the FL tools. We present
		  FixLocator, a Deep Learning (DL)-based fault localization
		  approach supporting the detection of faulty statements in
		  one or multiple methods that need to be modified
		  accordingly in the same fix. Let us call them co-change
		  (CC) fixing locations for a fault. We treat this FL problem
		  as dual-task learning with two models. The method-level FL
		  model, MethFL, learns the methods to be fixed together. The
		  statement-level FL model, StmtFL, learns the statements to
		  be co-fixed. Correct learning in one model can benefit the
		  other and vice versa. Thus, we simultaneously train them
		  with soft-sharing the models' parameters via cross-stitch
		  units to enable the propagation of the impact of MethFL and
		  StmtFL onto each other. Moreover, we explore a novel
		  feature for FL: the co-changed statements. We also use
		  Graph-based Convolution Network to integrate different
		  types of program dependencies.
		  
		  Our empirical results show that FixLocator relatively
		  improves over the state-of-the-art statement-level FL
		  baselines by locating 26.5\%–155.6\% more CC fixing
		  statements. To evaluate its usefulness in APR, we used
		  FixLocator in combination with the state-of-the-art APR
		  tools. The results show that FixLocator+DEAR (the original
		  FL in DEAR replaced by FixLocator) and FixLocator+CURE
		  improve relatively over the original DEAR and Ochiai+CURE
		  by 10.5\% and 42.9\% in terms of the number of fixed bugs.},
  booktitle	= {Proceedings of the 30th ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {659–671},
  numpages	= {13},
  keywords	= {Fault Localization, Deep Learning, Co-Change Fixing
		  Locations},
  location	= {Singapore, Singapore},
  series	= {ESEC/FSE 2022}
}

@InProceedings{	  liblit05nzaj,
  author	= {Liblit, Ben and Naik, Mayur and Zheng, Alice X. and Aiken,
		  Alex and Jordan, Michael I.},
  title		= {Scalable Statistical Bug Isolation},
  booktitle	= {PLDI '05},
  year		= {2005},
  isbn		= {1-59593-056-6},
  location	= {Chicago, IL, USA},
  pages		= {15--26},
  numpages	= {12},
  url		= {http://doi.acm.org/10.1145/1065010.1065014},
  doi		= {10.1145/1065010.1065014},
  acmid		= {1065014},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {bug isolation, feature selection, invariants, random
		  sampling, statistical debugging}
}

@Article{	  liblit2005sd,
  author	= {Liblit, Ben and Naik, Mayur and Zheng, Alice X. and Aiken,
		  Alex and Jordan, Michael I.},
  title		= {Scalable Statistical Bug Isolation},
  year		= {2005},
  issue_date	= {June 2005},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {40},
  number	= {6},
  issn		= {0362-1340},
  url		= {https://doi.org/10.1145/1064978.1065014},
  doi		= {10.1145/1064978.1065014},
  abstract	= {We present a statistical debugging algorithm that isolates
		  bugs in programs containing multiple undiagnosed bugs.
		  Earlier statistical algorithms that focus solely on
		  identifying predictors that correlate with program failure
		  perform poorly when there are multiple bugs. Our new
		  technique separates the effects of different bugs and
		  identifies predictors that are associated with individual
		  bugs. These predictors reveal both the circumstances under
		  which bugs occur as well as the frequencies of failure
		  modes, making it easier to prioritize debugging efforts.
		  Our algorithm is validated using several case studies,
		  including examples in which the algorithm identified
		  previously unknown, significant crashing bugs in widely
		  used systems.},
  journal	= {SIGPLAN Not.},
  month		= {jun},
  pages		= {15–26},
  numpages	= {12},
  keywords	= {feature selection, statistical debugging, random sampling,
		  bug isolation, invariants}
}

###Article{	  liblit2005sd,
  author	= {Liblit, Ben and Naik, Mayur and Zheng, Alice X. and Aiken,
		  Alex and Jordan, Michael I.},
  title		= {Scalable Statistical Bug Isolation},
  year		= {2005},
  issue_date	= {June 2005},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {40},
  number	= {6},
  issn		= {0362-1340},
  url		= {https://doi.org/10.1145/1064978.1065014},
  doi		= {10.1145/1064978.1065014},
  abstract	= {We present a statistical debugging algorithm that isolates
		  bugs in programs containing multiple undiagnosed bugs.
		  Earlier statistical algorithms that focus solely on
		  identifying predictors that correlate with program failure
		  perform poorly when there are multiple bugs. Our new
		  technique separates the effects of different bugs and
		  identifies predictors that are associated with individual
		  bugs. These predictors reveal both the circumstances under
		  which bugs occur as well as the frequencies of failure
		  modes, making it easier to prioritize debugging efforts.
		  Our algorithm is validated using several case studies,
		  including examples in which the algorithm identified
		  previously unknown, significant crashing bugs in widely
		  used systems.},
  journal	= {SIGPLAN Not.},
  month		= {jun},
  pages		= {15–26},
  numpages	= {12},
  keywords	= {feature selection, statistical debugging, random sampling,
		  bug isolation, invariants}
}

@InProceedings{	  linsxld17,
  author	= {Yun Lin and Jun Sun and Yinxing Xue and Yang Liu and Jin
		  Song Dong},
  editor	= {Sebasti{\'{a}}n Uchitel and Alessandro Orso and Martin P.
		  Robillard},
  title		= {Feedback-based debugging},
  booktitle	= {Proceedings of the 39th International Conference on
		  Software Engineering, {ICSE} 2017, Buenos Aires, Argentina,
		  May 20-28, 2017},
  pages		= {393--403},
  publisher	= {{IEEE} / {ACM}},
  year		= {2017},
  url		= {https://doi.org/10.1109/ICSE.2017.43},
  doi		= {10.1109/ICSE.2017.43},
  timestamp	= {Thu, 07 Sep 2017 09:27:12 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/icse/LinSXLD17},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  liu05yfhm,
  author	= {Liu, Chao and Yan, Xifeng and Fei, Long and Han, Jiawei
		  and Midkiff, Samuel P.},
  title		= {SOBER: Statistical Model-based Bug Localization},
  booktitle	= {ESEC/FSE '05},
  year		= {2005},
  isbn		= {1-59593-014-0},
  location	= {Lisbon, Portugal},
  pages		= {286--295},
  numpages	= {10},
  url		= {http://doi.acm.org/10.1145/1081706.1081753},
  doi		= {10.1145/1081706.1081753},
  acmid		= {1081753},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {localization metrics, statistical debugging}
}

@Article{	  liu06fyhm,
  author	= {Chao Liu and Long Fei and Yan, X. and Jiawei Han and
		  Midkiff, S.P.},
  journal	= {IEEE Transactions on Software Engineering},
  publisher	= {IEEE},
  title		= {Statistical Debugging: A Hypothesis Testing-Based
		  Approach},
  year		= {2006},
  month		= {Oct},
  volume	= {32},
  number	= {10},
  pages		= {831--848},
  doi		= {10.1109/TSE.2006.105},
  issn		= {0098-5589}
}

@InProceedings{	  liulxy23,
  author	= {Zhongxin Liu and Kui Liu and Xin Xia and Xiaohu Yang},
  editor	= {Ren{\'{e}} Just and Gordon Fraser},
  title		= {Towards More Realistic Evaluation for Neural Test Oracle
		  Generation},
  booktitle	= {Proceedings of the 32nd {ACM} {SIGSOFT} International
		  Symposium on Software Testing and Analysis, {ISSTA} 2023},
  pages		= {589--600},
  publisher	= {{ACM}},
  year		= {2023},
  url		= {https://doi.org/10.1145/3597926.3598080},
  doi		= {10.1145/3597926.3598080}
}

@InProceedings{	  lizdo18,
  author	= {Xiangyu Li and Shaowei Zhu and Marcelo d’Amorim and
		  Alessandro Orso},
  title		= {Enlightened Debugging},
  booktitle	= {ICSE '18},
  year		= {2018},
  location	= {Gothenburg, Sweden},
  pages		= {82--92},
  numpages	= {10},
  publisher	= {ACM},
  address	= {New York, NY, USA}
}

@InProceedings{	  long2015spr,
  author	= {Long, Fan and Rinard, Martin},
  title		= {Staged program repair with condition synthesis},
  year		= {2015},
  isbn		= {9781450336758},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2786805.2786811},
  doi		= {10.1145/2786805.2786811},
  abstract	= {We present SPR, a new program repair system that combines
		  staged program repair and condition synthesis. These
		  techniques enable SPR to work productively with a set of
		  parameterized transformation schemas to generate and
		  efficiently search a rich space of program repairs.
		  Together these techniques enable SPR to generate correct
		  repairs for over five times as many defects as previous
		  systems evaluated on the same benchmark set.},
  booktitle	= {Proceedings of the 2015 10th Joint Meeting on Foundations
		  of Software Engineering},
  pages		= {166–178},
  numpages	= {13},
  keywords	= {Staged repair, Program repair, Condition synthesis},
  location	= {Bergamo, Italy},
  series	= {ESEC/FSE 2015}
}

@InProceedings{	  long2016search,
  author	= {Long, Fan and Rinard, Martin},
  title		= {An analysis of the search spaces for generate and validate
		  patch generation systems},
  year		= {2016},
  isbn		= {9781450339001},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2884781.2884872},
  doi		= {10.1145/2884781.2884872},
  abstract	= {We present the first systematic analysis of key
		  characteristics of patch search spaces for automatic patch
		  generation systems. We analyze sixteen different
		  configurations of the patch search spaces of SPR and
		  Prophet, two current state-of-the-art patch generation
		  systems. The analysis shows that 1) correct patches are
		  sparse in the search spaces (typically at most one correct
		  patch per search space per defect), 2) incorrect patches
		  that nevertheless pass all of the test cases in the
		  validation test suite are typically orders of magnitude
		  more abundant, and 3) leveraging information other than the
		  test suite is therefore critical for enabling the system to
		  successfully isolate correct patches.We also characterize a
		  key tradeoff in the structure of the search spaces. Larger
		  and richer search spaces that contain correct patches for
		  more defects can actually cause systems to find fewer, not
		  more, correct patches. We identify two reasons for this
		  phenomenon: 1) increased validation times because of the
		  presence of more candidate patches and 2) more incorrect
		  patches that pass the test suite and block the discovery of
		  correct patches. These fundamental properties, which are
		  all characterized for the first time in this paper, help
		  explain why past systems often fail to generate correct
		  patches and help identify challenges, opportunities, and
		  productive future directions for the field.},
  booktitle	= {Proceedings of the 38th International Conference on
		  Software Engineering},
  pages		= {702–713},
  numpages	= {12},
  keywords	= {search space, program repair, patch generation},
  location	= {Austin, Texas},
  series	= {ICSE '16}
}

@InProceedings{	  lucia2014fusion,
  author	= {Lucia and Lo, David and Xia, Xin},
  title		= {Fusion Fault Localizers},
  booktitle	= {ASE '14},
  year		= {2014},
  isbn		= {978-1-4503-3013-8},
  location	= {Vasteras, Sweden},
  pages		= {127--138},
  numpages	= {12},
  url		= {http://doi.acm.org/10.1145/2642937.2642983},
  doi		= {10.1145/2642937.2642983},
  acmid		= {2642983},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {data fusion, fault localization}
}

@InProceedings{	  lucialx14,
  author	= {Lucia and David Lo and Xin Xia},
  title		= {Fusion fault localizers},
  booktitle	= {{ACM/IEEE} International Conference on Automated Software
		  Engineering, {ASE} '14},
  pages		= {127--138},
  year		= {2014}
}

@InProceedings{	  lundberg2017shap,
  author	= {Lundberg, Scott M. and Lee, Su-In},
  title		= {A Unified Approach to Interpreting Model Predictions},
  year		= {2017},
  isbn		= {9781510860964},
  publisher	= {Curran Associates Inc.},
  address	= {Red Hook, NY, USA},
  abstract	= {Understanding why a model makes a certain prediction can
		  be as crucial as the prediction's accuracy in many
		  applications. However, the highest accuracy for large
		  modern datasets is often achieved by complex models that
		  even experts struggle to interpret, such as ensemble or
		  deep learning models, creating a tension between accuracy
		  and interpretability. In response, various methods have
		  recently been proposed to help users interpret the
		  predictions of complex models, but it is often unclear how
		  these methods are related and when one method is preferable
		  over another. To address this problem, we present a unified
		  framework for interpreting predictions, SHAP (SHapley
		  Additive exPlanations). SHAP assigns each feature an
		  importance value for a particular prediction. Its novel
		  components include: (1) the identification of a new class
		  of additive feature importance measures, and (2)
		  theoretical results showing there is a unique solution in
		  this class with a set of desirable properties. The new
		  class unifies six existing methods, notable because several
		  recent methods in the class lack the proposed desirable
		  properties. Based on insights from this unification, we
		  present new methods that show improved computational
		  performance and/or better consistency with human intuition
		  than previous approaches.},
  booktitle	= {Proceedings of the 31st International Conference on Neural
		  Information Processing Systems},
  pages		= {4768–4777},
  numpages	= {10},
  location	= {Long Beach, California, USA},
  series	= {NIPS'17}
}

###InProceedings{ lundberg2017shap,
  author	= {Lundberg, Scott M. and Lee, Su-In},
  title		= {A Unified Approach to Interpreting Model Predictions},
  year		= {2017},
  isbn		= {9781510860964},
  publisher	= {Curran Associates Inc.},
  address	= {Red Hook, NY, USA},
  abstract	= {Understanding why a model makes a certain prediction can
		  be as crucial as the prediction's accuracy in many
		  applications. However, the highest accuracy for large
		  modern datasets is often achieved by complex models that
		  even experts struggle to interpret, such as ensemble or
		  deep learning models, creating a tension between accuracy
		  and interpretability. In response, various methods have
		  recently been proposed to help users interpret the
		  predictions of complex models, but it is often unclear how
		  these methods are related and when one method is preferable
		  over another. To address this problem, we present a unified
		  framework for interpreting predictions, SHAP (SHapley
		  Additive exPlanations). SHAP assigns each feature an
		  importance value for a particular prediction. Its novel
		  components include: (1) the identification of a new class
		  of additive feature importance measures, and (2)
		  theoretical results showing there is a unique solution in
		  this class with a set of desirable properties. The new
		  class unifies six existing methods, notable because several
		  recent methods in the class lack the proposed desirable
		  properties. Based on insights from this unification, we
		  present new methods that show improved computational
		  performance and/or better consistency with human intuition
		  than previous approaches.},
  booktitle	= {Proceedings of the 31st International Conference on Neural
		  Information Processing Systems},
  pages		= {4768–4777},
  numpages	= {10},
  location	= {Long Beach, California, USA},
  series	= {NIPS'17}
}

@Article{	  lundberg2020trees,
  title		= {From local explanations to global understanding with
		  explainable AI for trees},
  volume	= {2},
  issn		= {2522-5839},
  doi		= {10.1038/s42256-019-0138-9},
  abstractnote	= {Tree-based machine learning models such as random forests,
		  decision trees and gradient boosted trees are popular
		  nonlinear predictive models, yet comparatively little
		  attention has been paid to explaining their predictions.
		  Here we improve the interpretability of tree-based models
		  through three main contributions. (1) A polynomial time
		  algorithm to compute optimal explanations based on game
		  theory. (2) A new type of explanation that directly
		  measures local feature interaction effects. (3) A new set
		  of tools for understanding global model structure based on
		  combining many local explanations of each prediction. We
		  apply these tools to three medical machine learning
		  problems and show how combining many high-quality local
		  explanations allows us to represent global structure while
		  retaining local faithfulness to the original model. These
		  tools enable us to (1) identify high-magnitude but
		  low-frequency nonlinear mortality risk factors in the US
		  population, (2) highlight distinct population subgroups
		  with shared risk characteristics, (3) identify nonlinear
		  interaction effects among risk factors for chronic kidney
		  disease and (4) monitor a machine learning model deployed
		  in a hospital by identifying which features are degrading
		  the model`s performance over time. Given the popularity of
		  tree-based machine learning models, these improvements to
		  their interpretability have implications across a broad set
		  of domains.},
  number	= {1},
  journal	= {Nature Machine Intelligence},
  author	= {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and
		  DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and
		  Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and
		  Lee, Su-In},
  year		= {2020},
  month		= {Jan},
  pages		= {56–67}
}

###Article{	  lundberg2020trees,
  title		= {From local explanations to global understanding with
		  explainable AI for trees},
  volume	= {2},
  issn		= {2522-5839},
  doi		= {10.1038/s42256-019-0138-9},
  abstractnote	= {Tree-based machine learning models such as random forests,
		  decision trees and gradient boosted trees are popular
		  nonlinear predictive models, yet comparatively little
		  attention has been paid to explaining their predictions.
		  Here we improve the interpretability of tree-based models
		  through three main contributions. (1) A polynomial time
		  algorithm to compute optimal explanations based on game
		  theory. (2) A new type of explanation that directly
		  measures local feature interaction effects. (3) A new set
		  of tools for understanding global model structure based on
		  combining many local explanations of each prediction. We
		  apply these tools to three medical machine learning
		  problems and show how combining many high-quality local
		  explanations allows us to represent global structure while
		  retaining local faithfulness to the original model. These
		  tools enable us to (1) identify high-magnitude but
		  low-frequency nonlinear mortality risk factors in the US
		  population, (2) highlight distinct population subgroups
		  with shared risk characteristics, (3) identify nonlinear
		  interaction effects among risk factors for chronic kidney
		  disease and (4) monitor a machine learning model deployed
		  in a hospital by identifying which features are degrading
		  the model`s performance over time. Given the popularity of
		  tree-based machine learning models, these improvements to
		  their interpretability have implications across a broad set
		  of domains.},
  number	= {1},
  journal	= {Nature Machine Intelligence},
  author	= {Lundberg, Scott M. and Erion, Gabriel and Chen, Hugh and
		  DeGrave, Alex and Prutkin, Jordan M. and Nair, Bala and
		  Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and
		  Lee, Su-In},
  year		= {2020},
  month		= {Jan},
  pages		= {56–67}
}

@InProceedings{	  lutellier2020coconut,
  author	= {Lutellier, Thibaud and Pham, Hung Viet and Pang, Lawrence
		  and Li, Yitong and Wei, Moshi and Tan, Lin},
  title		= {CoCoNuT: combining context-aware neural translation models
		  using ensemble for program repair},
  year		= {2020},
  isbn		= {9781450380089},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3395363.3397369},
  doi		= {10.1145/3395363.3397369},
  abstract	= {Automated generate-and-validate (GV) program repair
		  techniques (APR) typically rely on hard-coded rules, thus
		  only fixing bugs following specific fix patterns. These
		  rules require a significant amount of manual effort to
		  discover and it is hard to adapt these rules to different
		  programming languages. To address these challenges, we
		  propose a new G&V technique—CoCoNuT, which uses ensemble
		  learning on the combination of convolutional neural
		  networks (CNNs) and a new context-aware neural machine
		  translation (NMT) architecture to automatically fix bugs in
		  multiple programming languages. To better represent the
		  context of a bug, we introduce a new context-aware NMT
		  architecture that represents the buggy source code and its
		  surrounding context separately. CoCoNuT uses CNNs instead
		  of recurrent neural networks (RNNs), since CNN layers can
		  be stacked to extract hierarchical features and better
		  model source code at different granularity levels (e.g.,
		  statements and functions). In addition, CoCoNuT takes
		  advantage of the randomness in hyperparameter tuning to
		  build multiple models that fix different bugs and combines
		  these models using ensemble learning to fix more bugs. Our
		  evaluation on six popular benchmarks for four programming
		  languages (Java, C, Python, and JavaScript) shows that
		  CoCoNuT correctly fixes (i.e., the first generated patch is
		  semantically equivalent to the developer’s patch) 509
		  bugs, including 309 bugs that are fixed by none of the 27
		  techniques with which we compare.},
  booktitle	= {Proceedings of the 29th ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {101–114},
  numpages	= {14},
  keywords	= {AI and Software Engineering, Automated program repair,
		  Deep Learning, Neural Machine Translation},
  location	= {Virtual Event, USA},
  series	= {ISSTA 2020}
}

@Article{	  maoldqw14,
  author	= {Xiaoguang Mao and Yan Lei and Ziying Dai and Yuhua Qi and
		  Chengsong Wang},
  title		= {Slice-based statistical fault localization},
  journal	= {Journal of Systems and Software},
  volume	= {89},
  pages		= {51--62},
  year		= {2014},
  url		= {https://doi.org/10.1016/j.jss.2013.08.031},
  doi		= {10.1016/j.jss.2013.08.031}
}

@InProceedings{	  martinez2016astor,
  author	= {Martinez, Matias and Monperrus, Martin},
  title		= {ASTOR: a program repair library for Java (demo)},
  year		= {2016},
  isbn		= {9781450343909},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2931037.2948705},
  doi		= {10.1145/2931037.2948705},
  abstract	= {During the last years, the software engineering research
		  community has proposed approaches for automatically
		  repairing software bugs. Unfortunately, many software
		  artifacts born from this research are not available for
		  repairing Java programs. To-reimplement those approaches
		  from scratch is costly. To facilitate experimental
		  replications and comparative evaluations, we present Astor,
		  a publicly available program repair library that includes
		  the implementation of three notable repair approaches
		  (jGenProg, jKali and jMutRepair). We envision that the
		  research community will use Astor for setting up
		  comparative evaluations and explore the design space of
		  automatic repair for Java. Astor offers researchers ways to
		  implement new repair approaches or to modify existing ones.
		  Astor repairs in total 33 real bugs from four large open
		  source projects.},
  booktitle	= {Proceedings of the 25th International Symposium on
		  Software Testing and Analysis},
  pages		= {441–444},
  numpages	= {4},
  keywords	= {software defects, Automated software repair},
  location	= {Saarbr\"{u}cken, Germany},
  series	= {ISSTA 2016}
}

@InProceedings{	  martinez2018cardumen,
  address	= {Cham},
  title		= {Ultra-Large Repair Search Space with Automatically Mined
		  Templates: The Cardumen Mode of Astor},
  isbn		= {978-3-319-99241-9},
  abstractnote	= {Astor is a program repair library which has different
		  modes. In this paper, we present the Cardumen mode of
		  Astor, a repair approach based mined templates that has an
		  ultra-large search space. We evaluate the capacity of
		  Cardumen to discover test-suite adequate patches (aka
		  plausible patches) over the 356 real bugs from Defects4J
		  [11]. Cardumen finds 8935 patches over 77 bugs of
		  Defects4J. This is the largest number of automatically
		  synthesized patches ever reported, all patches being
		  available in an open-science repository. Moreover, Cardumen
		  identifies 8 unique patches, that are patches for Defects4J
		  bugs that were never repaired in the whole history of
		  program repair.},
  booktitle	= {Search-Based Software Engineering},
  publisher	= {Springer International Publishing},
  author	= {Martinez, Matias and Monperrus, Martin},
  editor	= {Colanzi, Thelma Elita and McMinn, Phil},
  year		= {2018},
  pages		= {65–86}
}

@InProceedings{	  masria10,
  author	= {Wes Masri and Rawad Abou Assi},
  title		= {Cleansing Test Suites from Coincidental Correctness to
		  Enhance Fault-Localization},
  booktitle	= {Third International Conference on Software Testing,
		  Verification and Validation, {ICST} 2010},
  pages		= {165--174},
  publisher	= {{IEEE} Computer Society},
  year		= {2010},
  url		= {https://doi.org/10.1109/ICST.2010.22},
  doi		= {10.1109/ICST.2010.22}
}

@InProceedings{	  mastropaoloscnp21,
  author	= {Antonio Mastropaolo and Simone Scalabrino and Nathan
		  Cooper and David Nader{-}Palacio and Denys Poshyvanyk and
		  Rocco Oliveto and Gabriele Bavota},
  title		= {Studying the Usage of Text-To-Text Transfer Transformer to
		  Support Code-Related Tasks},
  booktitle	= {43rd {IEEE/ACM} International Conference on Software
		  Engineering, {ICSE} 2021},
  pages		= {336--347},
  publisher	= {{IEEE}},
  year		= {2021},
  url		= {https://doi.org/10.1109/ICSE43902.2021.00041},
  doi		= {10.1109/ICSE43902.2021.00041}
}

@InProceedings{	  meng2022transfer,
  author	= {Meng, Xiangxin and Wang, Xu and Zhang, Hongyu and Sun,
		  Hailong and Liu, Xudong},
  title		= {Improving fault localization and program repair with deep
		  semantic features and transferred knowledge},
  year		= {2022},
  isbn		= {9781450392211},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3510003.3510147},
  doi		= {10.1145/3510003.3510147},
  abstract	= {Automatic software debugging mainly includes two tasks of
		  fault localization and automated program repair. Compared
		  with the traditional spectrum-based and mutation-based
		  methods, deep learning-based methods are proposed to
		  achieve better performance for fault localization. However,
		  the existing methods ignore the deep semantic features or
		  only consider simple code representations. They do not
		  leverage the existing bug-related knowledge from
		  large-scale open-source projects either. In addition,
		  existing template-based program repair techniques can
		  incorporate project specific information better than
		  deep-learning approaches. However, they are weak in
		  selecting the fix templates for efficient program repair.
		  In this work, we propose a novel approach called TRANSFER,
		  which leverages the deep semantic features and transferred
		  knowledge from open-source data to improve fault
		  localization and program repair. First, we build two
		  large-scale open-source bug datasets and design 11
		  BiLSTM-based binary classifiers and a BiLSTM-based
		  multi-classifier to learn deep semantic features of
		  statements for fault localization and program repair,
		  respectively. Second, we combine semantic-based,
		  spectrum-based and mutation-based features and use an
		  MLP-based model for fault localization. Third, the
		  semantic-based features are leveraged to rank the fix
		  templates for program repair. Our extensive experiments on
		  widely-used benchmark De-fects4J show that TRANSFER
		  outperforms all baselines in fault localization, and is
		  better than existing deep-learning methods in automated
		  program repair. Compared with the typical template-based
		  work TBar, TRANSFER can correctly repair 6 more bugs (47 in
		  total) on Defects4J.},
  booktitle	= {Proceedings of the 44th International Conference on
		  Software Engineering},
  pages		= {1169–1180},
  numpages	= {12},
  keywords	= {fault localization, neural networks, program repair,
		  software debugging, transfer learning},
  location	= {Pittsburgh, Pennsylvania},
  series	= {ICSE '22}
}

@InProceedings{	  mikolov2013word2vec,
  author	= {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and
		  Corrado, Greg and Dean, Jeffrey},
  title		= {Distributed representations of words and phrases and their
		  compositionality},
  year		= {2013},
  publisher	= {Curran Associates Inc.},
  address	= {Red Hook, NY, USA},
  abstract	= {The recently introduced continuous Skip-gram model is an
		  efficient method for learning high-quality distributed
		  vector representations that capture a large number of
		  precise syntactic and semantic word relationships. In this
		  paper we present several extensions that improve both the
		  quality of the vectors and the training speed. By
		  subsampling of the frequent words we obtain significant
		  speedup and also learn more regular word representations.
		  We also describe a simple alternative to the hierarchical
		  softmax called negative sampling.An inherent limitation of
		  word representations is their indifference to word order
		  and their inability to represent idiomatic phrases. For
		  example, the meanings of "Canada" and "Air" cannot be
		  easily combined to obtain "Air Canada". Motivated by this
		  example, we present a simple method for finding phrases in
		  text, and show that learning good vector representations
		  for millions of phrases is possible.},
  booktitle	= {Proceedings of the 26th International Conference on Neural
		  Information Processing Systems - Volume 2},
  pages		= {3111–3119},
  numpages	= {9},
  location	= {Lake Tahoe, Nevada},
  series	= {NIPS'13}
}

@InProceedings{	  moonkky14,
  author	= {Seokhyeon Moon and Yunho Kim and Moonzoo Kim and Shin
		  Yoo},
  title		= {Ask the Mutants: Mutating Faulty Programs for Fault
		  Localization},
  booktitle	= {Seventh {IEEE} International Conference on Software
		  Testing, Verification and Validation, {ICST} 2014, March 31
		  2014-April 4, 2014, Cleveland, Ohio, {USA}},
  pages		= {153--162},
  publisher	= {{IEEE} Computer Society},
  year		= {2014},
  url		= {https://doi.org/10.1109/ICST.2014.28},
  doi		= {10.1109/ICST.2014.28},
  timestamp	= {Wed, 24 May 2017 08:30:37 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/icst/MoonKKY14},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  motwanib19,
  author	= {Manish Motwani and Yuriy Brun},
  editor	= {Joanne M. Atlee and Tevfik Bultan and Jon Whittle},
  title		= {Automatically generating precise Oracles from structured
		  natural language specifications},
  booktitle	= {Proceedings of the 41st International Conference on
		  Software Engineering, {ICSE} 2019},
  pages		= {188--199},
  publisher	= {{IEEE} / {ACM}},
  year		= {2019},
  url		= {https://doi.org/10.1109/ICSE.2019.00035},
  doi		= {10.1109/ICSE.2019.00035}
}

@Article{	  naish2011model,
  author	= {Naish, Lee and Lee, Hua Jie and Ramamohanarao, Kotagiri},
  title		= {A Model for Spectra-based Software Diagnosis},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  issue_date	= {2011},
  volume	= {20},
  number	= {3},
  month		= aug,
  year		= {2011},
  issn		= {1049-331X},
  pages		= {1--32},
  articleno	= {11},
  numpages	= {32},
  url		= {http://doi.acm.org/10.1145/2000791.2000795},
  doi		= {10.1145/2000791.2000795},
  acmid		= {2000795},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Fault localization, program spectra, statistical
		  debugging}
}

@Article{	  naish2011sbfl,
  author	= {Naish, Lee and Lee, Hua Jie and Ramamohanarao, Kotagiri},
  title		= {A Model for Spectra-Based Software Diagnosis},
  year		= {2011},
  issue_date	= {August 2011},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {20},
  number	= {3},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/2000791.2000795},
  doi		= {10.1145/2000791.2000795},
  abstract	= {This article presents an improved approach to assist
		  diagnosis of failures in software (fault localisation) by
		  ranking program statements or blocks in accordance with to
		  how likely they are to be buggy. We present a very simple
		  single-bug program to model the problem. By examining
		  different possible execution paths through this model
		  program over a number of test cases, the effectiveness of
		  different proposed spectral ranking methods can be
		  evaluated in idealised conditions. The results are
		  remarkably consistent to those arrived at empirically using
		  the Siemens test suite and Space benchmarks. The model also
		  helps identify groups of metrics that are equivalent for
		  ranking. Due to the simplicity of the model, an optimal
		  ranking method can be devised. This new method out-performs
		  previously proposed methods for the model program, the
		  Siemens test suite and Space. It also helps provide insight
		  into other ranking methods.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {aug},
  articleno	= {11},
  numpages	= {32},
  keywords	= {statistical debugging, program spectra, Fault
		  localization}
}

###Article{	  naish2011sbfl,
  author	= {Naish, Lee and Lee, Hua Jie and Ramamohanarao, Kotagiri},
  title		= {A Model for Spectra-Based Software Diagnosis},
  year		= {2011},
  issue_date	= {August 2011},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {20},
  number	= {3},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/2000791.2000795},
  doi		= {10.1145/2000791.2000795},
  abstract	= {This article presents an improved approach to assist
		  diagnosis of failures in software (fault localisation) by
		  ranking program statements or blocks in accordance with to
		  how likely they are to be buggy. We present a very simple
		  single-bug program to model the problem. By examining
		  different possible execution paths through this model
		  program over a number of test cases, the effectiveness of
		  different proposed spectral ranking methods can be
		  evaluated in idealised conditions. The results are
		  remarkably consistent to those arrived at empirically using
		  the Siemens test suite and Space benchmarks. The model also
		  helps identify groups of metrics that are equivalent for
		  ranking. Due to the simplicity of the model, an optimal
		  ranking method can be devised. This new method out-performs
		  previously proposed methods for the model program, the
		  Siemens test suite and Space. It also helps provide insight
		  into other ranking methods.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {aug},
  articleno	= {11},
  numpages	= {32},
  keywords	= {statistical debugging, program spectra, Fault
		  localization}
}

@InProceedings{	  naish2013duals,
  title		= {Duals in spectral fault localization},
  author	= {Naish, Lee and Lee, Hua Jie},
  booktitle	= {Software Engineering Conference (ASWEC), 2013 22nd
		  Australian},
  pages		= {51--59},
  year		= {2013},
  organization	= {IEEE}
}

@Article{	  neelofar2017hyperbolic,
  author	= {Neelofar, N. and Naish, Lee and Ramamohanarao, Kotagiri},
  title		= {Spectral-based fault localization using hyperbolic
		  function},
  journal	= {Software: Practice and Experience},
  issn		= {1097-024X},
  url		= {http://dx.doi.org/10.1002/spe.2527},
  doi		= {10.1002/spe.2527},
  pages		= {1--24},
  keywords	= {deterministic bugs, dynamic analysis, fault localization,
		  nondeterministic bugs, optimization methods, spectral
		  debugging},
  note		= {spe.2527},
  year		= {2017},
  publisher	= {Wiley}
}

@Article{	  neelofarnlr17,
  author	= {Neelofar and Lee Naish and Jason Lee and Kotagiri
		  Ramamohanarao},
  title		= {Improving spectral-based fault localization using static
		  analysis},
  journal	= {Softw., Pract. Exper.},
  volume	= {47},
  number	= {11},
  pages		= {1633--1655},
  year		= {2017},
  url		= {https://doi.org/10.1002/spe.2490},
  doi		= {10.1002/spe.2490},
  timestamp	= {Thu, 28 Dec 2017 16:12:06 +0100},
  biburl	= {https://dblp.org/rec/bib/journals/spe/NeelofarNLR17},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Misc{		  openhubaspectjcommits,
  author	= {Openhub},
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  note		= {[Online; accessed 29-September-2014]},
  title		= {The AspectJ Open Source Project on Open Hub : Commits
		  Summary Page},
  url		= {https://www.openhub.net/p/freshmeat_aspectj/commits/summary},
  year		= {2014},
  bdsk-url-1	= {https://www.openhub.net/p/freshmeat_aspectj/commits/summary}
}

@Misc{		  openhubaspectjlanguages,
  author	= {Openhub},
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  note		= {[Online; accessed 1-July-2018]},
  title		= {The AspectJ Open Source Project on Open Hub : Languages
		  Page},
  url		= {https://www.openhub.net/p/freshmeat_aspectj/analyses/latest/languages_summary},
  howpublished	= {\url{https://www.openhub.net/p/freshmeat_aspectj/analyses/latest/languages_summary}},
  year		= {2018},
  bdsk-url-1	= {https://www.openhub.net/p/freshmeat_aspectj/analyses/latest/languages_summary}
}

@InProceedings{	  orso2014researchtravelogue,
  author	= {Orso, Alessandro and Rothermel, Gregg},
  title		= {Software Testing: A Research Travelogue (2000--2014)},
  booktitle	= {FOSE 2014},
  year		= {2014},
  isbn		= {978-1-4503-2865-4},
  location	= {Hyderabad, India},
  pages		= {117--132},
  numpages	= {16},
  doi		= {10.1145/2593882.2593885},
  acmid		= {2593885},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Software testing}
}

@Article{	  p2021loops,
  author	= {Pruthviraj P},
  title		= {Fine Grained Statistical Debugging for the Identification
		  of Multiple Bugs},
  year		= {2021},
  volume	= {10},
  abstractnote	= {Commercial software ships with undetected bugs despite the
		  combined efforts of programmers, sophisticated bug
		  detection tools and extensive testing. So, the
		  identification and localization of the bugs in the software
		  becomes essential issues in program debugging. Traditional
		  software debugging is a difficult task to accomplish which
		  requires a lot of time, effort and very good understanding
		  of the source code. Given the scale and complexity of the
		  job, automating the process of program debugging is very
		  essential. Our approach aims at automating the process of
		  program debugging. The earlier proposed approaches namely,
		  statistical debugging and decision tree were able to
		  identify only the most frequently occurring bugs and they
		  failed to identify masked, simultaneously and
		  non-frequently occurring bugs. We propose two approaches:
		  one is decision tree based and the other uses bi-clustering
		  for the task. The results obtained by our proposed
		  approaches showed great improvements in the results in
		  terms of purity, mis-classification rate and over
		  splitting. Our proposed approaches were able to identify
		  all the bugs present in the software including the masked
		  and nonfrequently occurring bugs.},
  number	= {05},
  journal	= {International Journal of Engineering Research},
  pages		= {7},
  language	= {en}
}

###Article{	  p2021loops,
  author	= {Pruthviraj P},
  title		= {Fine Grained Statistical Debugging for the Identification
		  of Multiple Bugs},
  year		= {2021},
  volume	= {10},
  abstractnote	= {Commercial software ships with undetected bugs despite the
		  combined efforts of programmers, sophisticated bug
		  detection tools and extensive testing. So, the
		  identification and localization of the bugs in the software
		  becomes essential issues in program debugging. Traditional
		  software debugging is a difficult task to accomplish which
		  requires a lot of time, effort and very good understanding
		  of the source code. Given the scale and complexity of the
		  job, automating the process of program debugging is very
		  essential. Our approach aims at automating the process of
		  program debugging. The earlier proposed approaches namely,
		  statistical debugging and decision tree were able to
		  identify only the most frequently occurring bugs and they
		  failed to identify masked, simultaneously and
		  non-frequently occurring bugs. We propose two approaches:
		  one is decision tree based and the other uses bi-clustering
		  for the task. The results obtained by our proposed
		  approaches showed great improvements in the results in
		  terms of purity, mis-classification rate and over
		  splitting. Our proposed approaches were able to identify
		  all the bugs present in the software including the masked
		  and nonfrequently occurring bugs.},
  number	= {05},
  journal	= {International Journal of Engineering Research},
  pages		= {7},
  language	= {en}
}

@InProceedings{	  papadakis2014mutation,
  author	= {Papadakis, Mike and Le Traon, Yves},
  title		= {Effective fault localization via mutation analysis: a
		  selective mutation approach},
  year		= {2014},
  isbn		= {9781450324694},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2554850.2554978},
  doi		= {10.1145/2554850.2554978},
  abstract	= {When programs fail, developers face the problem of
		  identifying the code fragments responsible for this
		  failure. To this end, fault localization techniques try to
		  identify suspicious program places (program statements) by
		  observing the spectrum of the failing and passing test
		  executions. These statements are then pointed out to assist
		  the debugging activity. This paper considers mutation-based
		  fault localization and suggests the use of a sufficient
		  mutant set to locate effectively the faulty statements.
		  Experimentation reveals that mutation-based fault
		  localization is significantly more effective than current
		  state-of-the-art fault localization techniques.
		  Additionally, the results show that the proposed approach
		  is capable of reducing the overheads of mutation analysis.
		  In particular the number of mutants to be considered is
		  reduced to 20\% with only a limited loss on the method's
		  effectiveness.},
  booktitle	= {Proceedings of the 29th Annual ACM Symposium on Applied
		  Computing},
  pages		= {1293–1300},
  numpages	= {8},
  keywords	= {program debugging, mutation analysis, fault localization},
  location	= {Gyeongju, Republic of Korea},
  series	= {SAC '14}
}

@Article{	  papadakis2015mutation,
  author	= {Papadakis, Mike and Le Traon, Yves},
  title		= {Metallaxis-FL: mutation-based fault localization},
  year		= {2015},
  issue_date	= {August 2015},
  publisher	= {John Wiley and Sons Ltd.},
  address	= {GBR},
  volume	= {25},
  number	= {5–7},
  issn		= {0960-0833},
  url		= {https://doi.org/10.1002/stvr.1509},
  doi		= {10.1002/stvr.1509},
  abstract	= {Fault localization methods seek to identify faulty program
		  statements based on the information provided by the failing
		  and passing test executions. Spectrum-based methods are
		  among the most popular ones and assist programmers by
		  assigning suspiciousness values on program statements
		  according to their probability of being faulty. This paper
		  proposes Metallaxis, a fault localization approach based on
		  mutation analysis. The innovative part of Metallaxis is
		  that it uses mutants and links them with the faulty program
		  places. Thus, mutants that are killed mostly by failing
		  tests provide a good indication about the location of a
		  fault. Experimentation using Metallaxis suggests that it is
		  significantly more effective than statement-based
		  approaches. This is true even in the case where mutation
		  cost-reduction techniques, such as mutant sampling, are
		  facilitated. Additionally, results from a controlled
		  experiment show that the use of mutation as a testing
		  technique provides benefits to the fault localization
		  process. Therefore, fault localization is significantly
		  improved by using mutation-based tests instead of
		  block-based or branch-based test suites. Finally, evidence
		  in support of the methods' scalability is also given.
		  Copyright © 2013 John Wiley \& Sons, Ltd.},
  journal	= {Softw. Test. Verif. Reliab.},
  month		= {aug},
  pages		= {605–628},
  numpages	= {24},
  keywords	= {debugging, fault localization, mutation analysis}
}

@InProceedings{	  papadakist14,
  author	= {Mike Papadakis and Yves Le Traon},
  editor	= {Yookun Cho and Sung Y. Shin and Sang{-}Wook Kim and
		  Chih{-}Cheng Hung and Jiman Hong},
  title		= {Effective fault localization via mutation analysis: a
		  selective mutation approach},
  booktitle	= {Symposium on Applied Computing, {SAC} 2014},
  pages		= {1293--1300},
  publisher	= {{ACM}},
  year		= {2014},
  url		= {http://doi.acm.org/10.1145/2554850.2554978},
  doi		= {10.1145/2554850.2554978}
}

@Article{	  papadakist15,
  author	= {Mike Papadakis and Yves Le Traon},
  title		= {Metallaxis-FL: mutation-based fault localization},
  journal	= {Softw. Test., Verif. Reliab.},
  volume	= {25},
  number	= {5-7},
  pages		= {605--628},
  year		= {2015},
  url		= {https://doi.org/10.1002/stvr.1509},
  doi		= {10.1002/stvr.1509}
}

@InProceedings{	  park2010,
  author	= {Park, Sangmin and Vuduc, Richard W. and Harrold, Mary
		  Jean},
  title		= {Falcon: Fault Localization in Concurrent Programs},
  booktitle	= {ICSE '10},
  year		= {2010},
  isbn		= {978-1-60558-719-6},
  location	= {Cape Town, South Africa},
  pages		= {245--254},
  numpages	= {10},
  url		= {http://doi.acm.org/10.1145/1806799.1806838},
  doi		= {10.1145/1806799.1806838},
  acmid		= {1806838},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {atomicity violation, concurrency, debugging, fault
		  localization, order violation}
}

@InProceedings{	  parnin2011automated,
  author	= {Parnin, Chris and Orso, Alessandro},
  title		= {Are Automated Debugging Techniques Actually Helping
		  Programmers?},
  year		= {2011},
  isbn		= {9781450305624},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2001420.2001445},
  doi		= {10.1145/2001420.2001445},
  abstract	= {Debugging is notoriously difficult and extremely time
		  consuming. Researchers have therefore invested a
		  considerable amount of effort in developing automated
		  techniques and tools for supporting various debugging
		  tasks. Although potentially useful, most of these
		  techniques have yet to demonstrate their practical
		  effectiveness. One common limitation of existing
		  approaches, for instance, is their reliance on a set of
		  strong assumptions on how developers behave when debugging
		  (e.g., the fact that examining a faulty statement in
		  isolation is enough for a developer to understand and fix
		  the corresponding bug). In more general terms, most
		  existing techniques just focus on selecting subsets of
		  potentially faulty statements and ranking them according to
		  some criterion. By doing so, they ignore the fact that
		  understanding the root cause of a failure typically
		  involves complex activities, such as navigating program
		  dependencies and rerunning the program with different
		  inputs. The overall goal of this research is to investigate
		  how developers use and benefit from automated debugging
		  tools through a set of human studies. As a first step in
		  this direction, we perform a preliminary study on a set of
		  developers by providing them with an automated debugging
		  tool and two tasks to be performed with and without the
		  tool. Our results provide initial evidence that several
		  assumptions made by automated debugging techniques do not
		  hold in practice. Through an analysis of the results, we
		  also provide insights on potential directions for future
		  work in the area of automated debugging.},
  booktitle	= {Proceedings of the 2011 International Symposium on
		  Software Testing and Analysis},
  pages		= {199–209},
  numpages	= {11},
  keywords	= {user studies, statistical debugging},
  location	= {Toronto, Ontario, Canada},
  series	= {ISSTA '11}
}

###InProceedings{ parnin2011automated,
  author	= {Parnin, Chris and Orso, Alessandro},
  title		= {Are Automated Debugging Techniques Actually Helping
		  Programmers?},
  year		= {2011},
  isbn		= {9781450305624},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2001420.2001445},
  doi		= {10.1145/2001420.2001445},
  abstract	= {Debugging is notoriously difficult and extremely time
		  consuming. Researchers have therefore invested a
		  considerable amount of effort in developing automated
		  techniques and tools for supporting various debugging
		  tasks. Although potentially useful, most of these
		  techniques have yet to demonstrate their practical
		  effectiveness. One common limitation of existing
		  approaches, for instance, is their reliance on a set of
		  strong assumptions on how developers behave when debugging
		  (e.g., the fact that examining a faulty statement in
		  isolation is enough for a developer to understand and fix
		  the corresponding bug). In more general terms, most
		  existing techniques just focus on selecting subsets of
		  potentially faulty statements and ranking them according to
		  some criterion. By doing so, they ignore the fact that
		  understanding the root cause of a failure typically
		  involves complex activities, such as navigating program
		  dependencies and rerunning the program with different
		  inputs. The overall goal of this research is to investigate
		  how developers use and benefit from automated debugging
		  tools through a set of human studies. As a first step in
		  this direction, we perform a preliminary study on a set of
		  developers by providing them with an automated debugging
		  tool and two tasks to be performed with and without the
		  tool. Our results provide initial evidence that several
		  assumptions made by automated debugging techniques do not
		  hold in practice. Through an analysis of the results, we
		  also provide insights on potential directions for future
		  work in the area of automated debugging.},
  booktitle	= {Proceedings of the 2011 International Symposium on
		  Software Testing and Analysis},
  pages		= {199–209},
  numpages	= {11},
  keywords	= {user studies, statistical debugging},
  location	= {Toronto, Ontario, Canada},
  series	= {ISSTA '11}
}

@InBook{	  parnin2021automated,
  author	= {Parnin, Chris and Orso, Alessandro},
  title		= {Automated Debugging: Past, Present, and Future (ISSTA
		  Impact Paper Award)},
  year		= {2021},
  isbn		= {9781450384599},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3460319.3472397},
  abstract	= {The paper titled “Are Automated Debugging Techniques
		  Actually Helping Programmers?” was published in the
		  proceedings of the International Symposium on Software
		  Testing and Analysis (ISSTA) in 2011, and has been selected
		  to receive the ISSTA 2021 Impact Paper Award. The paper
		  investigated, through two user studies, how developers used
		  and benefited from popular automated debugging techniques.
		  The results of the studies provided (1) evidence that
		  several assumptions made by automated debugging techniques
		  did not hold in practice and (2) insights on limitations of
		  existing approaches and how these limitations could be
		  addressed. In this talk, we revisit the original paper and
		  the work that led to it. We then assess the impact of that
		  research by reviewing how the area of automated debugging
		  has evolved since the paper was published. Finally, we
		  conclude the talk by reflecting on the current state of the
		  art in this area and discussing open issues and potential
		  directions for future work.},
  booktitle	= {Proceedings of the 30th ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {1},
  numpages	= {1}
}

###InBook{	  parnin2021automated,
  author	= {Parnin, Chris and Orso, Alessandro},
  title		= {Automated Debugging: Past, Present, and Future (ISSTA
		  Impact Paper Award)},
  year		= {2021},
  isbn		= {9781450384599},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3460319.3472397},
  abstract	= {The paper titled “Are Automated Debugging Techniques
		  Actually Helping Programmers?” was published in the
		  proceedings of the International Symposium on Software
		  Testing and Analysis (ISSTA) in 2011, and has been selected
		  to receive the ISSTA 2021 Impact Paper Award. The paper
		  investigated, through two user studies, how developers used
		  and benefited from popular automated debugging techniques.
		  The results of the studies provided (1) evidence that
		  several assumptions made by automated debugging techniques
		  did not hold in practice and (2) insights on limitations of
		  existing approaches and how these limitations could be
		  addressed. In this talk, we revisit the original paper and
		  the work that led to it. We then assess the impact of that
		  research by reviewing how the area of automated debugging
		  has evolved since the paper was published. Finally, we
		  conclude the talk by reflecting on the current state of the
		  art in this area and discussing open issues and potential
		  directions for future work.},
  booktitle	= {Proceedings of the 30th ACM SIGSOFT International
		  Symposium on Software Testing and Analysis},
  pages		= {1},
  numpages	= {1}
}

@InProceedings{	  pearson2017evaluating,
  title		= {Evaluating and improving fault localization},
  author	= {Pearson, Spencer and Campos, Jos{\'e} and Just, Ren{\'e}
		  and Fraser, Gordon and Abreu, Rui and Ernst, Michael D and
		  Pang, Deric and Keller, Benjamin},
  booktitle	= {Proceedings of the 39th International Conference on
		  Software Engineering},
  pages		= {609--620},
  year		= {2017},
  organization	= {IEEE Press}
}

@InProceedings{	  pearson2017sfl,
  author	= {Pearson, Spencer and Campos, Jos\'{e} and Just, Ren\'{e}
		  and Fraser, Gordon and Abreu, Rui and Ernst, Michael D. and
		  Pang, Deric and Keller, Benjamin},
  title		= {Evaluating and improving fault localization},
  year		= {2017},
  isbn		= {9781538638682},
  publisher	= {IEEE Press},
  url		= {https://doi.org/10.1109/ICSE.2017.62},
  doi		= {10.1109/ICSE.2017.62},
  abstract	= {Most fault localization techniques take as input a faulty
		  program, and produce as output a ranked list of suspicious
		  code locations at which the program may be defective. When
		  researchers propose a new fault localization technique,
		  they typically evaluate it on programs with known faults.
		  The technique is scored based on where in its output list
		  the defective code appears. This enables the comparison of
		  multiple fault localization techniques to determine which
		  one is better.Previous research has evaluated fault
		  localization techniques using artificial faults, generated
		  either by mutation tools or manually. In other words,
		  previous research has determined which fault localization
		  techniques are best at finding artificial faults. However,
		  it is not known which fault localization techniques are
		  best at finding real faults. It is not obvious that the
		  answer is the same, given previous work showing that
		  artificial faults have both similarities to and differences
		  from real faults.We performed a replication study to
		  evaluate 10 claims in the literature that compared fault
		  localization techniques (from the spectrum-based and
		  mutation-based families). We used 2995 artificial faults in
		  6 real-world programs. Our results support 7 of the
		  previous claims as statistically significant, but only 3 as
		  having non-negligible effect sizes. Then, we evaluated the
		  same 10 claims, using 310 real faults from the 6 programs.
		  Every previous result was refuted or was statistically and
		  practically insignificant. Our experiments show that
		  artificial faults are not useful for predicting which fault
		  localization techniques perform best on real faults.In
		  light of these results, we identified a design space that
		  includes many previously-studied fault localization
		  techniques as well as hundreds of new techniques. We
		  experimentally determined which factors in the design space
		  are most important, using an overall set of 395 real
		  faults. Then, we extended this design space with new
		  techniques. Several of our novel techniques outperform all
		  existing techniques, notably in terms of ranking defective
		  code in the top-5 or top-10 reports.},
  booktitle	= {Proceedings of the 39th International Conference on
		  Software Engineering},
  pages		= {609–620},
  numpages	= {12},
  location	= {Buenos Aires, Argentina},
  series	= {ICSE '17}
}

@Article{	  pedregosa2011scikit,
  title		= {Scikit-learn: Machine Learning in {P}ython},
  author	= {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and
		  Michel, V. and Thirion, B. and Grisel, O. and Blondel, M.
		  and Prettenhofer, P. and Weiss, R. and Dubourg, V. and
		  Vanderplas, J. and Passos, A. and Cournapeau, D. and
		  Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal	= {Journal of Machine Learning Research},
  volume	= {12},
  pages		= {2825--2830},
  year		= {2011}
}

###Article{	  pedregosa2011scikit,
  title		= {Scikit-learn: Machine Learning in {P}ython},
  author	= {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and
		  Michel, V. and Thirion, B. and Grisel, O. and Blondel, M.
		  and Prettenhofer, P. and Weiss, R. and Dubourg, V. and
		  Vanderplas, J. and Passos, A. and Cournapeau, D. and
		  Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal	= {Journal of Machine Learning Research},
  volume	= {12},
  pages		= {2825--2830},
  year		= {2011}
}

@InProceedings{	  perezad17,
  author	= {Alexandre Perez and Rui Abreu and Arie van Deursen},
  editor	= {Sebasti{\'{a}}n Uchitel and Alessandro Orso and Martin P.
		  Robillard},
  title		= {A test-suite diagnosability metric for spectrum-based
		  fault localization approaches},
  booktitle	= {Proceedings of the 39th International Conference on
		  Software Engineering, {ICSE} 2017},
  pages		= {654--664},
  publisher	= {{IEEE} / {ACM}},
  year		= {2017},
  url		= {https://doi.org/10.1109/ICSE.2017.66},
  doi		= {10.1109/ICSE.2017.66}
}

@InProceedings{	  polikarpovacm09,
  author	= {Nadia Polikarpova and Ilinca Ciupa and Bertrand Meyer},
  editor	= {Gregg Rothermel and Laura K. Dillon},
  title		= {A comparative study of programmer-written and
		  automatically inferred contracts},
  booktitle	= {Proceedings of the Eighteenth International Symposium on
		  Software Testing and Analysis, {ISSTA} 2009},
  pages		= {93--104},
  publisher	= {{ACM}},
  year		= {2009},
  url		= {https://doi.org/10.1145/1572272.1572284},
  doi		= {10.1145/1572272.1572284}
}

@Article{	  qi12rlv,
  author	= {Dawei Qi and Abhik Roychoudhury and Zhenkai Liang and
		  Kapil Vaswani},
  title		= {{DARWIN:} An approach to debugging evolving programs},
  journal	= {{ACM} Trans. Softw. Eng. Methodol.},
  volume	= {21},
  number	= {3},
  pages		= {19},
  year		= {2012},
  doi		= {10.1145/2211616.2211622}
}

@InProceedings{	  qi2013apr,
  author	= {Qi, Yuhua and Mao, Xiaoguang and Lei, Yan and Wang,
		  Chengsong},
  title		= {Using Automated Program Repair for Evaluating the
		  Effectiveness of Fault Localization Techniques},
  year		= {2013},
  isbn		= {9781450321594},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2483760.2483785},
  doi		= {10.1145/2483760.2483785},
  abstract	= {Many techniques on automated fault localization (AFL) have
		  been introduced to assist developers in debugging. Prior
		  studies evaluate the localization technique from the
		  viewpoint of developers: measuring how many benefits that
		  developers can obtain from the localization technique used
		  when debugging. However, these evaluation approaches are
		  not always suitable, because it is difficult to quantify
		  precisely the benefits due to the complex debugging
		  behaviors of developers. In addition, recent user studies
		  have presented that developers working with AFL do not
		  correct the defects more efficiently than ones working with
		  only traditional debugging techniques such as breakpoints,
		  even when the effectiveness of AFL is artificially
		  improved. In this paper we attempt to propose a new
		  research direction of developing AFL techniques from the
		  viewpoint of fully automated debugging including the
		  program repair of automation, for which the activity of AFL
		  is necessary. We also introduce the NCP score as the
		  evaluation measurement to assess and compare various
		  techniques from this perspective. Our experiment on 15
		  popular AFL techniques with 11 subject programs shipping
		  with real-life field failures presents the evidence that
		  these AFL techniques performing well in prior studies do
		  not have better localization effectiveness according to NCP
		  score. We also observe that Jaccard has the better
		  performance over other techniques in our experiment.},
  booktitle	= {Proceedings of the 2013 International Symposium on
		  Software Testing and Analysis},
  pages		= {191–201},
  numpages	= {11},
  keywords	= {automated debugging, Fault localization, automated program
		  repair},
  location	= {Lugano, Switzerland},
  series	= {ISSTA 2013}
}

###InProceedings{ qi2013apr,
  author	= {Qi, Yuhua and Mao, Xiaoguang and Lei, Yan and Wang,
		  Chengsong},
  title		= {Using Automated Program Repair for Evaluating the
		  Effectiveness of Fault Localization Techniques},
  year		= {2013},
  isbn		= {9781450321594},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2483760.2483785},
  doi		= {10.1145/2483760.2483785},
  abstract	= {Many techniques on automated fault localization (AFL) have
		  been introduced to assist developers in debugging. Prior
		  studies evaluate the localization technique from the
		  viewpoint of developers: measuring how many benefits that
		  developers can obtain from the localization technique used
		  when debugging. However, these evaluation approaches are
		  not always suitable, because it is difficult to quantify
		  precisely the benefits due to the complex debugging
		  behaviors of developers. In addition, recent user studies
		  have presented that developers working with AFL do not
		  correct the defects more efficiently than ones working with
		  only traditional debugging techniques such as breakpoints,
		  even when the effectiveness of AFL is artificially
		  improved. In this paper we attempt to propose a new
		  research direction of developing AFL techniques from the
		  viewpoint of fully automated debugging including the
		  program repair of automation, for which the activity of AFL
		  is necessary. We also introduce the NCP score as the
		  evaluation measurement to assess and compare various
		  techniques from this perspective. Our experiment on 15
		  popular AFL techniques with 11 subject programs shipping
		  with real-life field failures presents the evidence that
		  these AFL techniques performing well in prior studies do
		  not have better localization effectiveness according to NCP
		  score. We also observe that Jaccard has the better
		  performance over other techniques in our experiment.},
  booktitle	= {Proceedings of the 2013 International Symposium on
		  Software Testing and Analysis},
  pages		= {191–201},
  numpages	= {11},
  keywords	= {automated debugging, Fault localization, automated program
		  repair},
  location	= {Lugano, Switzerland},
  series	= {ISSTA 2013}
}

@InProceedings{	  qi2015kali,
  author	= {Qi, Zichao and Long, Fan and Achour, Sara and Rinard,
		  Martin},
  title		= {An analysis of patch plausibility and correctness for
		  generate-and-validate patch generation systems},
  year		= {2015},
  isbn		= {9781450336208},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2771783.2771791},
  doi		= {10.1145/2771783.2771791},
  abstract	= {We analyze reported patches for three existing
		  generate-and- validate patch generation systems (GenProg,
		  RSRepair, and AE). The basic principle behind
		  generate-and-validate systems is to accept only plausible
		  patches that produce correct outputs for all inputs in the
		  validation test suite. Because of errors in the patch
		  evaluation infrastructure, the majority of the reported
		  patches are not plausible — they do not produce correct
		  outputs even for the inputs in the validation test suite.
		  The overwhelming majority of the reported patches are not
		  correct and are equivalent to a single modification that
		  simply deletes functionality. Observed negative effects
		  include the introduction of security vulnerabilities and
		  the elimination of desirable functionality. We also present
		  Kali, a generate-and-validate patch generation system that
		  only deletes functionality. Working with a simpler and more
		  effectively focused search space, Kali generates at least
		  as many correct patches as prior GenProg, RSRepair, and AE
		  systems. Kali also generates at least as many patches that
		  produce correct outputs for the inputs in the validation
		  test suite as the three prior systems. We also discuss the
		  patches produced by ClearView, a generate-and-validate
		  binary hot patching system that lever- ages learned
		  invariants to produce patches that enable systems to
		  survive otherwise fatal defects and security attacks. Our
		  analysis indicates that ClearView successfully patches 9 of
		  the 10 security vulnerabilities used to evaluate the
		  system. At least 4 of these patches are correct.},
  booktitle	= {Proceedings of the 2015 International Symposium on
		  Software Testing and Analysis},
  pages		= {24–36},
  numpages	= {13},
  keywords	= {Automatic Repair, Function Elimination, Patch Analysis},
  location	= {Baltimore, MD, USA},
  series	= {ISSTA 2015}
}

@InProceedings{	  qrs2017,
  author	= {F. Keller and L. Grunske and S. Heiden and A. Filieri and
		  A. van Hoorn and D. Lo},
  booktitle	= {2017 IEEE International Conference on Software Quality,
		  Reliability and Security (QRS)},
  title		= {A Critical Evaluation of Spectrum-Based Fault Localization
		  Techniques on a Large-Scale Software System},
  year		= {2017},
  pages		= {114--125},
  doi		= {10.1109/QRS.2017.22},
  month		= {July}
}

@InProceedings{	  renr07,
  author	= {Xiaoxia Ren and Barbara G. Ryder},
  editor	= {David S. Rosenblum and Sebastian G. Elbaum},
  title		= {Heuristic ranking of java program edits for fault
		  localization},
  booktitle	= {Proceedings of the {ACM/SIGSOFT} International Symposium
		  on Software Testing and Analysis, {ISSTA} 2007},
  pages		= {239--249},
  publisher	= {{ACM}},
  year		= {2007},
  url		= {http://doi.acm.org/10.1145/1273463.1273495},
  doi		= {10.1145/1273463.1273495}
}

@InProceedings{	  reps1997s,
  author	= {Reps, Thomas and Ball, Thomas and Das, Manuvir and Larus,
		  James},
  title		= {The Use of Program Profiling for Software Maintenance with
		  Applications to the Year 2000 Problem},
  year		= {1997},
  isbn		= {3540635319},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  url		= {https://doi.org/10.1145/267895.267925},
  doi		= {10.1145/267895.267925},
  booktitle	= {Proceedings of the 6th European SOFTWARE ENGINEERING
		  Conference Held Jointly with the 5th ACM SIGSOFT
		  International Symposium on Foundations of Software
		  Engineering},
  pages		= {432–449},
  numpages	= {18},
  location	= {Zurich, Switzerland},
  series	= {ESEC '97/FSE-5}
}

###InProceedings{ reps1997s,
  author	= {Reps, Thomas and Ball, Thomas and Das, Manuvir and Larus,
		  James},
  title		= {The Use of Program Profiling for Software Maintenance with
		  Applications to the Year 2000 Problem},
  year		= {1997},
  isbn		= {3540635319},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  url		= {https://doi.org/10.1145/267895.267925},
  doi		= {10.1145/267895.267925},
  booktitle	= {Proceedings of the 6th European SOFTWARE ENGINEERING
		  Conference Held Jointly with the 5th ACM SIGSOFT
		  International Symposium on Foundations of Software
		  Engineering},
  pages		= {432–449},
  numpages	= {18},
  location	= {Zurich, Switzerland},
  series	= {ESEC '97/FSE-5}
}

@InCollection{	  reps1997use,
  title		= {The use of program profiling for software maintenance with
		  applications to the year 2000 problem},
  author	= {Reps, Thomas and Ball, Thomas and Das, Manuvir and Larus,
		  James},
  booktitle	= {Software Engineering—ESEC/FSE'97},
  pages		= {432--449},
  year		= {1997},
  publisher	= {Springer}
}

@InProceedings{	  ribeiro2019dataflow,
  author	= {Ribeiro, Henrique L. and Roberto de Araujo, P. A. and
		  Chaim, Marcos L. and Souza, Higor A. de and Kon, Fabio},
  booktitle	= {2019 ACM/IEEE International Symposium on Empirical
		  Software Engineering and Measurement (ESEM)},
  title		= {Evaluating data-flow coverage in spectrum-based fault
		  localization},
  year		= {2019},
  volume	= {},
  number	= {},
  pages		= {1-11},
  keywords	= {Measurement;Computer bugs;Testing;Debugging;Software;Task
		  analysis;Computer science;Fault
		  localization;Spectrum-based;Debugging;Structural
		  testing;Data-flow;Control-flow},
  doi		= {10.1109/ESEM.2019.8870182}
}

@InProceedings{	  rossler12fzo,
  author	= {Jeremias R{\"{o}}{\ss}ler and Gordon Fraser and Andreas
		  Zeller and Alessandro Orso},
  title		= {Isolating Failure Causes Through Test Case Generation},
  booktitle	= {ISSTA},
  year		= {2012},
  isbn		= {978-1-4503-1454-1},
  location	= {Minneapolis, MN, USA},
  pages		= {309--319},
  numpages	= {11},
  url		= {http://doi.acm.org/10.1145/2338965.2336790},
  doi		= {10.1145/2338965.2336790},
  acmid		= {2336790},
  publisher	= {ACM},
  address	= {New York, NY, USA}
}

@InProceedings{	  santelices2009defuse,
  author	= {Santelices, Raul and Jones, James A. and Yanbing Yu and
		  Harrold, Mary Jean},
  title		= {Lightweight Fault-Localization Using Multiple Coverage
		  Types},
  year		= {2009},
  isbn		= {9781424434534},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/ICSE.2009.5070508},
  doi		= {10.1109/ICSE.2009.5070508},
  abstract	= {Lightweight fault-localization techniques use program
		  coverage to isolate the parts of the code that are most
		  suspicious of being faulty. In this paper, we present the
		  results of a study of three types of program
		  coverage—statements, branches, and data dependencies—to
		  compare their effectiveness in localizing faults. The study
		  shows that no single coverage type performs best for all
		  faults—different kinds of faults are best localized by
		  different coverage types. Based on these results, we
		  present a new coverage-based approach to fault localization
		  that leverages the unique qualities of each coverage type
		  by combining them. Because data dependencies are noticeably
		  more expensive to monitor than branches, we also
		  investigate the effects of replacing data-dependence
		  coverage with an approximation inferred from branch
		  coverage. Our empirical results show that (1) the cost of
		  fault localization using combinations of coverage is less
		  than using any individual coverage type and closer to the
		  best case (without knowing in advance which kinds of faults
		  are present), and (2) using inferred data-dependence
		  coverage retains most of the benefits of combinations.},
  booktitle	= {Proceedings of the 31st International Conference on
		  Software Engineering},
  pages		= {56–66},
  numpages	= {11},
  series	= {ICSE '09}
}

###InProceedings{ santelices2009defuse,
  author	= {Santelices, Raul and Jones, James A. and Yanbing Yu and
		  Harrold, Mary Jean},
  title		= {Lightweight Fault-Localization Using Multiple Coverage
		  Types},
  year		= {2009},
  isbn		= {9781424434534},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/ICSE.2009.5070508},
  doi		= {10.1109/ICSE.2009.5070508},
  abstract	= {Lightweight fault-localization techniques use program
		  coverage to isolate the parts of the code that are most
		  suspicious of being faulty. In this paper, we present the
		  results of a study of three types of program
		  coverage—statements, branches, and data dependencies—to
		  compare their effectiveness in localizing faults. The study
		  shows that no single coverage type performs best for all
		  faults—different kinds of faults are best localized by
		  different coverage types. Based on these results, we
		  present a new coverage-based approach to fault localization
		  that leverages the unique qualities of each coverage type
		  by combining them. Because data dependencies are noticeably
		  more expensive to monitor than branches, we also
		  investigate the effects of replacing data-dependence
		  coverage with an approximation inferred from branch
		  coverage. Our empirical results show that (1) the cost of
		  fault localization using combinations of coverage is less
		  than using any individual coverage type and closer to the
		  best case (without knowing in advance which kinds of faults
		  are present), and (2) using inferred data-dependence
		  coverage retains most of the benefits of combinations.},
  booktitle	= {Proceedings of the 31st International Conference on
		  Software Engineering},
  pages		= {56–66},
  numpages	= {11},
  series	= {ICSE '09}
}

@Article{	  schneidewind1992methodology,
  author	= {Schneidewind, Norman F.},
  title		= {Methodology for Validating Software Metrics},
  journal	= {IEEE Trans. Softw. Eng.},
  issue_date	= {May 1992},
  volume	= {18},
  number	= {5},
  month		= may,
  year		= {1992},
  issn		= {0098-5589},
  pages		= {410--422},
  numpages	= {13},
  url		= {http://dx.doi.org/10.1109/32.135774},
  doi		= {10.1109/32.135774},
  acmid		= {129977},
  publisher	= {IEEE},
  address	= {Piscataway, NJ, USA}
}

@InProceedings{	  smytzek2022sflkit,
  author	= {Smytzek, Marius and Zeller, Andreas},
  title		= {{SFLKit}: {A} workbench for statistical fault
		  localization},
  year		= {2022},
  isbn		= {9781450394130},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3540250.3558915},
  doi		= {10.1145/3540250.3558915},
  abstract	= {Statistical fault localization aims at detecting execution
		  features that correlate with failures, such as whether
		  individual lines are part of the execution. We introduce
		  SFLKit, an out-of-the-box workbench for statistical fault
		  localization. The framework provides straightforward access
		  to the fundamental concepts of statistical fault
		  localization. It supports five predicate types, four
		  coverage-inspired spectra, like lines, and 44 similarity
		  coefficients, e.g., TARANTULA or OCHIAI, for statistical
		  program analysis.
		  
		  SFLKit separates the execution of tests from the analysis
		  of the results and is therefore independent of the used
		  testing framework. It leverages program instrumentation to
		  enable the logging of events and derives the predicates and
		  spectra from these logs. This instrumentation allows for
		  introducing multiple programming languages and the
		  extension of new concepts in statistical fault
		  localization. Currently, SFLKit supports the
		  instrumentation of Python programs. It is highly
		  configurable, requiring only the logging of the required
		  events.},
  booktitle	= {Proceedings of the 30th ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {1701–1705},
  numpages	= {5},
  keywords	= {statistical fault localization, statistical debugging,
		  spectrum-based fault localization, similarity coefficient},
  location	= {Singapore, Singapore},
  series	= {ESEC/FSE 2022}
}

###InProceedings{ smytzek2022sflkit,
  author	= {Smytzek, Marius and Zeller, Andreas},
  title		= {SFLKit: A Workbench for Statistical Fault Localization},
  year		= {2022},
  isbn		= {9781450394130},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3540250.3558915},
  doi		= {10.1145/3540250.3558915},
  abstract	= {Statistical fault localization aims at detecting execution
		  features that correlate with failures, such as whether
		  individual lines are part of the execution. We introduce
		  SFLKit, an out-of-the-box workbench for statistical fault
		  localization. The framework provides straightforward access
		  to the fundamental concepts of statistical fault
		  localization. It supports five predicate types, four
		  coverage-inspired spectra, like lines, and 44 similarity
		  coefficients, e.g., TARANTULA or OCHIAI, for statistical
		  program analysis. SFLKit separates the execution of tests
		  from the analysis of the results and is therefore
		  independent of the used testing framework. It leverages
		  program instrumentation to enable the logging of events and
		  derives the predicates and spectra from these logs. This
		  instrumentation allows for introducing multiple programming
		  languages and the extension of new concepts in statistical
		  fault localization. Currently, SFLKit supports the
		  instrumentation of Python programs. It is highly
		  configurable, requiring only the logging of the required
		  events.},
  booktitle	= {Proceedings of the 30th ACM Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {1701–1705},
  numpages	= {5},
  keywords	= {statistical debugging, spectrum-based fault localization,
		  statistical fault localization, similarity coefficient},
  location	= {Singapore, Singapore},
  series	= {ESEC/FSE 2022}
}

@Misc{		  smytzek2023tests4py,
  title		= {Tests4Py: A Benchmark for System Testing},
  author	= {Marius Smytzek and Martin Eberlein and Batuhan Serce and
		  Lars Grunske and Andreas Zeller},
  year		= {2023},
  eprint	= {2307.05147},
  archiveprefix	= {arXiv},
  primaryclass	= {cs.SE}
}

###Misc{	  smytzek2023tests4py,
  title		= {Tests4Py: A Benchmark for System Testing},
  author	= {Marius Smytzek and Martin Eberlein and Batuhan Serce and
		  Lars Grunske and Andreas Zeller},
  year		= {2023},
  eprint	= {2307.05147},
  archiveprefix	= {arXiv},
  primaryclass	= {cs.SE}
}

@InProceedings{	  smytzek2024tests4py,
  author	= {Smytzek, Marius and Eberlein, Martin and Ser\c{c}e,
		  Batuhan and Grunske, Lars and Zeller, Andreas},
  title		= {Tests4Py: A Benchmark for System Testing},
  year		= {2024},
  isbn		= {9798400706585},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3663529.3663798},
  doi		= {10.1145/3663529.3663798},
  abstract	= {Benchmarks are among the main drivers of progress in
		  software engineering research. However, many current
		  benchmarks are limited by inadequate system oracles and
		  sparse unit tests.
		  
		  Our Tests4Py benchmark, derived from the BugsInPy
		  benchmark, addresses these limitations.
		  
		  It includes 73 bugs from seven real-world Python
		  applications and six bugs from example programs.
		  
		  Each subject in Tests4Py is equipped with an oracle for
		  verifying functional correctness and supports both system
		  and unit test generation.
		  
		  This allows for comprehensive qualitative studies and
		  extensive evaluations, making Tests4Py a cutting-edge
		  benchmark for research in test generation, debugging, and
		  automatic program repair.},
  booktitle	= {Companion Proceedings of the 32nd ACM International
		  Conference on the Foundations of Software Engineering},
  pages		= {557–561},
  numpages	= {5},
  keywords	= {Benchmark, Python, Test generation},
  location	= {Porto de Galinhas, Brazil},
  series	= {FSE 2024}
}

@InProceedings{	  sobreiraddmm18,
  author	= {Victor Sobreira and Thomas Durieux and Fernanda Madeiral
		  Delfim and Martin Monperrus and Marcelo de Almeida Maia},
  editor	= {Rocco Oliveto and Massimiliano Di Penta and David C.
		  Shepherd},
  title		= {Dissection of a bug dataset: Anatomy of 395 patches from
		  Defects4J},
  booktitle	= {25th International Conference on Software Analysis,
		  Evolution and Reengineering, {SANER} 2018, Campobasso,
		  Italy, March 20-23, 2018},
  pages		= {130--140},
  publisher	= {{IEEE} Computer Society},
  year		= {2018},
  url		= {https://doi.org/10.1109/SANER.2018.8330203},
  doi		= {10.1109/SANER.2018.8330203}
}

@InProceedings{	  sohny17,
  author	= {Jeongju Sohn and Shin Yoo},
  editor	= {Tevfik Bultan and Koushik Sen},
  title		= {{FLUCCS:} using code and change metrics to improve fault
		  localization},
  booktitle	= {Proceedings of the 26th {ACM} {SIGSOFT} International
		  Symposium on Software Testing and Analysis, Santa Barbara,
		  CA, USA, July 10 - 14, 2017},
  pages		= {273--283},
  publisher	= {{ACM}},
  year		= {2017},
  url		= {http://doi.acm.org/10.1145/3092703.3092717},
  doi		= {10.1145/3092703.3092717},
  timestamp	= {Thu, 13 Jul 2017 14:52:13 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/issta/SohnY17},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Article{	  soremekun2021slicing,
  author	= {Soremekun, Ezekiel and Kirschner, Lukas and B\"{o}hme,
		  Marcel and Zeller, Andreas},
  title		= {Locating faults with program slicing: an empirical
		  analysis},
  year		= {2021},
  issue_date	= {May 2021},
  publisher	= {Kluwer Academic Publishers},
  address	= {USA},
  volume	= {26},
  number	= {3},
  issn		= {1382-3256},
  url		= {https://doi.org/10.1007/s10664-020-09931-7},
  doi		= {10.1007/s10664-020-09931-7},
  abstract	= {Statistical fault localization is an easily deployed
		  technique for quickly determining candidates for faulty
		  code locations. If a human programmer has to search the
		  fault beyond the top candidate locations, though, more
		  traditional techniques of following dependencies along
		  dynamic slices may be better suited. In a large study of
		  457 bugs (369 single faults and 88 multiple faults) in 46
		  open source C programs, we compare the effectiveness of
		  statistical fault localization against dynamic slicing. For
		  single faults, we find that dynamic slicing was eight
		  percentage points more effective than the best performing
		  statistical debugging formula; for 66\% of the bugs,
		  dynamic slicing finds the fault earlier than the best
		  performing statistical debugging formula. In our
		  evaluation, dynamic slicing is more effective for programs
		  with single fault, but statistical debugging performs
		  better on multiple faults. Best results, however, are
		  obtained by a hybrid approach: If programmers first examine
		  at most the top five most suspicious locations from
		  statistical debugging, and then switch to dynamic slices,
		  on average, they will need to examine 15\% (30 lines) of
		  the code. These findings hold for 18 most effective
		  statistical debugging formulas and our results are
		  independent of the number of faults (i.e. single or
		  multiple faults) and error type (i.e. artificial or real
		  errors).},
  journal	= {Empirical Softw. Engg.},
  month		= {may},
  numpages	= {45},
  keywords	= {Software engineering, Software debugging, Software
		  testing, Automated fault localization, Program slicing,
		  Statistical debugging}
}

@InProceedings{	  soremekun2023evaluating,
  author	= {Soremekun, Ezekiel and Kirschner, Lukas and B\"{o}hme,
		  Marcel and Papadakis, Mike},
  title		= {Evaluating the Impact of Experimental Assumptions in
		  Automated Fault Localization},
  year		= {2023},
  isbn		= {9781665457019},
  publisher	= {IEEE Press},
  url		= {https://doi.org/10.1109/ICSE48619.2023.00025},
  doi		= {10.1109/ICSE48619.2023.00025},
  abstract	= {Much research on automated program debugging often assumes
		  that bug fix location(s) indicate the faults' root causes
		  and that root causes of faults lie within single code
		  elements (statements). It is also often assumed that the
		  number of statements a developer would need to inspect
		  before finding the first faulty statement reflects
		  debugging effort. Although intuitive, these three
		  assumptions are typically used (55\% of experiments in
		  surveyed publications make at least one of these three
		  assumptions) without any consideration of their effects on
		  the debugger's effectiveness and potential impact on
		  developers in practice. To deal with this issue, we perform
		  controlled experimentation, split testing in particular,
		  using 352 bugs from 46 open-source C programs, 19 Automated
		  Fault Localization (AFL) techniques (18 statistical
		  debugging formulas and dynamic slicing), two (2)
		  state-of-the-art automated program repair (APR) techniques
		  (GenProg and Angelix) and 76 professional developers. Our
		  results show that these assumptions conceal the difficulty
		  of debugging. They make AFL techniques appear to be (up to
		  38\%) more effective, and make APR tools appear to be (2X)
		  less effective. We also find that most developers (83\%)
		  consider these assumptions to be unsuitable for debuggers
		  and, perhaps worse, that they may inhibit development
		  productivity. The majority (66\%) of developers prefer
		  debugging diagnoses without these assumptions twice as much
		  as with the assumptions. Our findings motivate the need to
		  assess debuggers conservatively, i.e., without these
		  assumptions.},
  booktitle	= {Proceedings of the 45th International Conference on
		  Software Engineering},
  pages		= {159–171},
  numpages	= {13},
  keywords	= {user study, program repair, fault localization},
  location	= {Melbourne, Victoria, Australia},
  series	= {ICSE '23}
}

@Article{	  souzamck18,
  author	= {Higor Amario de Souza and Danilo Mutti and Marcos Lordello
		  Chaim and Fabio Kon},
  title		= {Contextualizing spectrum-based fault localization},
  journal	= {Information {\&} Software Technology},
  volume	= {94},
  pages		= {245--261},
  year		= {2018},
  url		= {https://doi.org/10.1016/j.infsof.2017.10.014},
  doi		= {10.1016/j.infsof.2017.10.014},
  timestamp	= {Tue, 21 Nov 2017 16:36:15 +0100},
  biburl	= {https://dblp.org/rec/bib/journals/infsof/SouzaMCK18},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  staatshkr12,
  author	= {Matt Staats and Shin Hong and Moonzoo Kim and Gregg
		  Rothermel},
  editor	= {Mats Per Erik Heimdahl and Zhendong Su},
  title		= {Understanding user understanding: determining correctness
		  of generated program invariants},
  booktitle	= {International Symposium on Software Testing and Analysis,
		  {ISSTA} 2012},
  pages		= {188--198},
  publisher	= {{ACM}},
  year		= {2012},
  url		= {https://doi.org/10.1145/2338965.2336776},
  doi		= {10.1145/2338965.2336776},
  timestamp	= {Thu, 02 Dec 2021 11:46:17 +0100},
  biburl	= {https://dblp.org/rec/conf/issta/StaatsHKR12.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  staatswh11,
  author	= {Matt Staats and Michael W. Whalen and Mats Per Erik
		  Heimdahl},
  editor	= {Richard N. Taylor and Harald C. Gall and Nenad
		  Medvidovic},
  title		= {Programs, tests, and oracles: the foundations of testing
		  revisited},
  booktitle	= {Proceedings of the 33rd International Conference on
		  Software Engineering, {ICSE} 2011},
  pages		= {391--400},
  publisher	= {{ACM}},
  year		= {2011},
  url		= {https://doi.org/10.1145/1985793.1985847},
  doi		= {10.1145/1985793.1985847}
}

@InProceedings{	  steimann13fa,
  author	= {Steimann, Friedrich and Frenkel, Marcus and Abreu, Rui},
  title		= {Threats to the Validity and Value of Empirical Assessments
		  of the Accuracy of Coverage-based Fault Locators},
  booktitle	= {ISSTA '13},
  year		= {2013},
  isbn		= {978-1-4503-2159-4},
  location	= {Lugano, Switzerland},
  pages		= {314--324},
  numpages	= {11},
  url		= {http://doi.acm.org/10.1145/2483760.2483767},
  doi		= {10.1145/2483760.2483767},
  acmid		= {2483767},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Fault localization, Threats to validity}
}

@InProceedings{	  steimann2013threats,
  author	= {Steimann, Friedrich and Frenkel, Marcus and Abreu, Rui},
  title		= {Threats to the validity and value of empirical assessments
		  of the accuracy of coverage-based fault locators},
  year		= {2013},
  isbn		= {9781450321594},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2483760.2483767},
  doi		= {10.1145/2483760.2483767},
  abstract	= {Resuming past work on coverage-based fault localization,
		  we find that empirical assessments of its accuracy are
		  subject to so many imponderables that they are of limited
		  value. To improve on this situation, we have compiled a
		  comprehensive list of threats to be considered when
		  attempting such assessments in the future. In addition, we
		  propose the establishment of theoretical lower and upper
		  bounds of fault localization accuracy that depend on
		  properties of the subject programs (including their test
		  suites) only. We make a suggestion for a lower bound and
		  show that well-known fault locators do not uniformly
		  perform better.},
  booktitle	= {Proceedings of the 2013 International Symposium on
		  Software Testing and Analysis},
  pages		= {314–324},
  numpages	= {11},
  keywords	= {Threats to validity, Fault localization},
  location	= {Lugano, Switzerland},
  series	= {ISSTA 2013}
}

@InProceedings{	  taneja11xth,
  author	= {Kunal Taneja and Tao Xie and Nikolai Tillmann and Jonathan
		  de Halleux},
  title		= {eXpress: guided path exploration for efficient regression
		  test generation},
  booktitle	= {Proceedings of the 20th International Symposium on
		  Software Testing and Analysis, {ISSTA} 2011},
  pages		= {1--11},
  publisher	= {{ACM}},
  year		= {2011},
  url		= {http://doi.acm.org/10.1145/2001420.2001422},
  doi		= {10.1145/2001420.2001422}
}

@Article{	  tangcyz17,
  author	= {Chung Man Tang and W. K. Chan and Yuen{-}Tak Yu and Zhenyu
		  Zhang},
  title		= {Accuracy Graphs of Spectrum-Based Fault Localization
		  Formulas},
  journal	= {{IEEE} Trans. Reliability},
  volume	= {66},
  number	= {2},
  pages		= {403--424},
  year		= {2017},
  url		= {https://doi.org/10.1109/TR.2017.2688487},
  doi		= {10.1109/TR.2017.2688487}
}

@Article{	  tantithamthavornahim18,
  author	= {Chakkrit Tantithamthavorn and Surafel Lemma Abebe and
		  Ahmed E. Hassan and Akinori Ihara and Kenichi Matsumoto},
  title		= {The Impact of IR-based Classifier Configuration on the
		  Performance and the Effort of Method-Level Bug
		  Localization},
  journal	= {CoRR},
  volume	= {abs/1806.07727},
  year		= {2018},
  url		= {http://arxiv.org/abs/1806.07727},
  archiveprefix	= {arXiv},
  eprint	= {1806.07727},
  timestamp	= {Tue, 03 Jul 2018 18:25:23 +0200},
  biburl	= {https://dblp.org/rec/bib/journals/corr/abs-1806-07727},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{	  terragnijtp20,
  author	= {Valerio Terragni and Gunel Jahangirova and Paolo Tonella
		  and Mauro Pezz{\`{e}}},
  editor	= {Prem Devanbu and Myra B. Cohen and Thomas Zimmermann},
  title		= {Evolutionary improvement of assertion oracles},
  booktitle	= {{ESEC/FSE} '20: 28th {ACM} Joint European Software
		  Engineering Conference and Symposium on the Foundations of
		  Software Engineering},
  pages		= {1178--1189},
  publisher	= {{ACM}},
  year		= {2020},
  url		= {https://doi.org/10.1145/3368089.3409758},
  doi		= {10.1145/3368089.3409758}
}

@InProceedings{	  tsimpourlasra21,
  author	= {Foivos Tsimpourlas and Ajitha Rajan and Miltiadis
		  Allamanis},
  editor	= {Chih{-}Cheng Hung and Jiman Hong and Alessio Bechini and
		  Eunjee Song},
  title		= {Supervised learning over test executions as a test
		  oracle},
  booktitle	= {{SAC} '21: The 36th {ACM/SIGAPP} Symposium on Applied
		  Computing, 2021},
  pages		= {1521--1531},
  publisher	= {{ACM}},
  year		= {2021},
  url		= {https://doi.org/10.1145/3412841.3442027},
  doi		= {10.1145/3412841.3442027}
}

@InProceedings{	  tufanodss22,
  author	= {Michele Tufano and Dawn Drain and Alexey Svyatkovskiy and
		  Neel Sundaresan},
  title		= {Generating Accurate Assert Statements for Unit Test Cases
		  using Pretrained Transformers},
  booktitle	= {{IEEE/ACM} International Conference on Automation of
		  Software Test, AST@ICSE 2022},
  pages		= {54--64},
  publisher	= {{ACM/IEEE}},
  year		= {2022},
  url		= {https://doi.org/10.1145/3524481.3527220},
  doi		= {10.1145/3524481.3527220}
}

@InProceedings{	  vancsics2021calls,
  author	= {Vancsics, B\'{e}la and Horv\'{a}th, Ferenc and
		  Szatm\'{a}ri, Attila and Besz\'{e}des, \'{A}rp\'{a}d},
  booktitle	= {2021 IEEE International Conference on Software Analysis,
		  Evolution and Reengineering (SANER)},
  title		= {Call Frequency-Based Fault Localization},
  year		= {2021},
  volume	= {},
  number	= {},
  pages		= {365-376},
  keywords	= {Location awareness;Ranking (statistics);Computer
		  bugs;Benchmark testing;Data structures;Software;Frequency
		  measurement;Spectrum-Based Fault Localization;Method Call
		  Frequency;Call Stacks;Testing;Debugging},
  doi		= {10.1109/SANER50967.2021.00041}
}

@InProceedings{	  wang2019superion,
  author	= {Junjie Wang and Bihuan Chen and Lei Wei and Yang Liu},
  editor	= {Joanne M. Atlee and Tevfik Bultan and Jon Whittle},
  title		= {Superion: grammar-aware greybox fuzzing},
  booktitle	= {Proceedings of the 41st International Conference on
		  Software Engineering, {ICSE} 2019},
  pages		= {724--735},
  publisher	= {{IEEE} / {ACM}},
  year		= {2019},
  url		= {https://doi.org/10.1109/ICSE.2019.00081},
  doi		= {10.1109/ICSE.2019.00081},
  timestamp	= {Mon, 26 Jun 2023 20:43:00 +0200},
  biburl	= {https://dblp.org/rec/conf/icse/Wang0WL19.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

###InProceedings{ wang2019superion,
  author	= {Junjie Wang and Bihuan Chen and Lei Wei and Yang Liu},
  editor	= {Joanne M. Atlee and Tevfik Bultan and Jon Whittle},
  title		= {Superion: grammar-aware greybox fuzzing},
  booktitle	= {Proceedings of the 41st International Conference on
		  Software Engineering, {ICSE} 2019},
  pages		= {724--735},
  publisher	= {{IEEE} / {ACM}},
  year		= {2019},
  url		= {https://doi.org/10.1109/ICSE.2019.00081},
  doi		= {10.1109/ICSE.2019.00081},
  timestamp	= {Mon, 26 Jun 2023 20:43:00 +0200},
  biburl	= {https://dblp.org/rec/conf/icse/Wang0WL19.bib},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Article{	  wang2024mtltransfer,
  author	= {Wang, Xu and Yu, Hongwei and Meng, Xiangxin and Cao,
		  Hongliang and Zhang, Hongyu and Sun, Hailong and Liu,
		  Xudong and Hu, Chunming},
  title		= {MTL-TRANSFER: Leveraging Multi-task Learning and
		  Transferred Knowledge for Improving Fault Localization and
		  Program Repair},
  year		= {2024},
  issue_date	= {July 2024},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {33},
  number	= {6},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/3654441},
  doi		= {10.1145/3654441},
  abstract	= {Fault localization (FL) and automated program repair (APR)
		  are two main tasks of automatic software debugging.
		  Compared with traditional methods, deep learning-based
		  approaches have been demonstrated to achieve better
		  performance in FL and APR tasks. However, the existing deep
		  learning-based FL methods ignore the deep semantic features
		  or only consider simple code representations. And for APR
		  tasks, existing template-based APR methods are weak in
		  selecting the correct fix templates for more effective
		  program repair, which are also not able to synthesize
		  patches via the embedded end-to-end code modification
		  knowledge obtained by training models on large-scale
		  bug-fix code pairs. Moreover, in most of FL and APR
		  methods, the model designs and training phases are
		  performed separately, leading to ineffective sharing of
		  updated parameters and extracted knowledge during the
		  training process. This limitation hinders the further
		  improvement in the performance of FL and APR tasks. To
		  solve the above problems, we propose a novel approach
		  called MTL-TRANSFER, which leverages a multi-task learning
		  strategy to extract deep semantic features and transferred
		  knowledge from different perspectives. First, we construct
		  a large-scale open-source bug datasets and implement 11
		  multi-task learning models for bug detection and patch
		  generation sub-tasks on 11 commonly used bug types, as well
		  as one multi-classifier to learn the relevant semantics for
		  the subsequent fix template selection task. Second, an
		  MLP-based ranking model is leveraged to fuse
		  spectrum-based, mutation-based and semantic-based features
		  to generate a sorted list of suspicious statements. Third,
		  we combine the patches generated by the neural patch
		  generation sub-task from the multi-task learning strategy
		  with the optimized fix template selecting order gained from
		  the multi-classifier mentioned above. Finally, the more
		  accurate FL results, the optimized fix template selecting
		  order, and the expanded patch candidates are combined
		  together to further enhance the overall performance of APR
		  tasks. Our extensive experiments on widely-used benchmark
		  Defects4J show that MTL-TRANSFER outperforms all baselines
		  in FL and APR tasks, proving the effectiveness of our
		  approach. Compared with our previously proposed FL method
		  TRANSFER-FL (which is also the state-of-the-art
		  statement-level FL method), MTL-TRANSFER increases the
		  faults hit by 8/11/12 on Top-1/3/5 metrics (92/159/183 in
		  total). And on APR tasks, the number of successfully
		  repaired bugs of MTL-TRANSFER under the perfect
		  localization setting reaches 75, which is 8 more than our
		  previous APR method TRANSFER-PR. Furthermore, another
		  experiment to simulate the actual repair scenarios shows
		  that MTL-TRANSFER can successfully repair 15 and 9 more
		  bugs (56 in total) compared with TBar and TRANSFER, which
		  demonstrates the effectiveness of the combination of our
		  optimized FL and APR components.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {jun},
  articleno	= {148},
  numpages	= {31},
  keywords	= {Fault localization, automated program repair, deep neural
		  networks, transfer learning, multi-task learning, neural
		  machine translation}
}

@InProceedings{	  wangljll11,
  author	= {Shaowei Wang and David Lo and Lingxiao Jiang and Lucia and
		  Hoong Chuin Lau},
  title		= {Search-based fault localization},
  booktitle	= {26th {IEEE/ACM} International Conference on Automated
		  Software Engineering {(ASE} 2011)},
  pages		= {556--559},
  year		= {2011}
}

@InProceedings{	  watsontmbp20,
  author	= {Cody Watson and Michele Tufano and Kevin Moran and
		  Gabriele Bavota and Denys Poshyvanyk},
  editor	= {Gregg Rothermel and Doo{-}Hwan Bae},
  title		= {On learning meaningful assert statements for unit test
		  cases},
  booktitle	= {{ICSE} '20: 42nd International Conference on Software
		  Engineering, 2020},
  pages		= {1398--1409},
  publisher	= {{ACM}},
  year		= {2020},
  url		= {https://doi.org/10.1145/3377811.3380429},
  doi		= {10.1145/3377811.3380429}
}

@InProceedings{	  weimer2009genprog,
  series	= {ICSE ’09},
  title		= {Automatically finding patches using genetic programming},
  doi		= {10.1109/ICSE.2009.5070536},
  booktitle	= {Proceedings of the 31st International Conference on
		  Software Engineering},
  author	= {Weimer, Westley and Nguyen, ThanhVu and Goues, Claire Le
		  and Forrest, Stephanie},
  year		= {2009},
  pages		= {364–374},
  collection	= {ICSE ’09}
}

@InProceedings{	  weimer2013ae,
  author	= {Weimer, Westley and Fry, Zachary P. and Forrest,
		  Stephanie},
  booktitle	= {2013 28th IEEE/ACM International Conference on Automated
		  Software Engineering (ASE)},
  title		= {Leveraging program equivalence for adaptive program
		  repair: Models and first results},
  year		= {2013},
  volume	= {},
  number	= {},
  pages		= {356-366},
  keywords	= {Maintenance engineering;Approximation
		  algorithms;Testing;Algorithm design and analysis;Adaptation
		  models;Optimization;Search problems;Automated program
		  repair;mutation testing;program equivalence;search-based
		  software engineering},
  doi		= {10.1109/ASE.2013.6693094}
}

@InProceedings{	  weiser1981program,
  author	= {Weiser, Mark},
  booktitle	= {Proceedings of the 5th international conference on
		  Software engineering},
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  organization	= {IEEE Press},
  pages		= {439--449},
  title		= {Program slicing},
  year		= {1981}
}

@InProceedings{	  wen12,
  author	= {Wanzhi Wen},
  editor	= {Martin Glinz and Gail C. Murphy and Mauro Pezz{\`{e}}},
  title		= {Software fault localization based on program slicing
		  spectrum},
  booktitle	= {34th International Conference on Software Engineering,
		  {ICSE} 2012},
  pages		= {1511--1514},
  publisher	= {{IEEE} Computer Society},
  year		= {2012},
  url		= {https://doi.org/10.1109/ICSE.2012.6227049},
  doi		= {10.1109/ICSE.2012.6227049}
}

@InProceedings{	  white2019deeprepair,
  author	= {White, Martin and Tufano, Michele and Martínez, Matías
		  and Monperrus, Martin and Poshyvanyk, Denys},
  booktitle	= {2019 IEEE 26th International Conference on Software
		  Analysis, Evolution and Reengineering (SANER)},
  title		= {Sorting and Transforming Program Repair Ingredients via
		  Deep Learning Code Similarities},
  year		= {2019},
  volume	= {},
  number	= {},
  pages		= {479-490},
  keywords	= {Maintenance engineering;Redundancy;Computer bugs;Deep
		  learning;Transforms;Cloning;Sorting;software testing and
		  debugging;program repair;deep learning;neural networks;code
		  clones;language models},
  doi		= {10.1109/SANER.2019.8668043}
}

@InProceedings{	  widyasari2020bugsinpy,
  author	= {Widyasari, Ratnadira and Sim, Sheng Qin and Lok, Camellia
		  and Qi, Haodi and Phan, Jack and Tay, Qijin and Tan,
		  Constance and Wee, Fiona and Tan, Jodie Ethelda and Yieh,
		  Yuheng and Goh, Brian and Thung, Ferdian and Kang, Hong Jin
		  and Hoang, Thong and Lo, David and Ouh, Eng Lieh},
  title		= {{BugsInPy}: {A} database of existing bugs in {Python}
		  programs to enable controlled testing and debugging
		  studies},
  year		= {2020},
  isbn		= {9781450370431},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3368089.3417943},
  doi		= {10.1145/3368089.3417943},
  abstract	= {The 2019 edition of Stack Overflow developer survey
		  highlights that, for the first time, Python outperformed
		  Java in terms of popularity. The gap between Python and
		  Java further widened in the 2020 edition of the survey.
		  Unfortunately, despite the rapid increase in Python's
		  popularity, there are not many testing and debugging tools
		  that are designed for Python. This is in stark contrast
		  with the abundance of testing and debugging tools for Java.
		  Thus, there is a need to push research on tools that can
		  help Python developers. One factor that contributed to the
		  rapid growth of Java testing and debugging tools is the
		  availability of benchmarks. A popular benchmark is the
		  Defects4J benchmark; its initial version contained 357 real
		  bugs from 5 real-world Java programs. Each bug comes with a
		  test suite that can expose the bug. Defects4J has been used
		  by hundreds of testing and debugging studies and has helped
		  to push the frontier of research in these directions. In
		  this project, inspired by Defects4J, we create another
		  benchmark database and tool that contain 493 real bugs from
		  17 real-world Python programs. We hope our benchmark can
		  help catalyze future work on testing and debugging tools
		  that work on Python programs.},
  booktitle	= {Proceedings of the 28th ACM Joint Meeting on European
		  Software Engineering Conference and Symposium on the
		  Foundations of Software Engineering},
  pages		= {1556–1560},
  numpages	= {5},
  keywords	= {Testing and Debugging, Python, Bug Database},
  location	= {Virtual Event, USA},
  series	= {ESEC/FSE 2020}
}

###InProceedings{ widyasari2020bugsinpy,
  place		= {Virtual Event USA},
  title		= {BugsInPy: a database of existing bugs in Python programs
		  to enable controlled testing and debugging studies},
  isbn		= {978-1-4503-7043-1},
  url		= {https://dl.acm.org/doi/10.1145/3368089.3417943},
  doi		= {10.1145/3368089.3417943},
  abstractnote	= {The 2019 edition of Stack Over�ow developer survey
		  highlights that, for the �rst time, Python outperformed
		  Java in terms of popularity. The gap between Python and
		  Java further widened in the 2020 edition of the survey.
		  Unfortunately, despite the rapid increase in Python’s
		  popularity, there are not many testing and debugging tools
		  that are designed for Python. This is in stark contrast
		  with the abundance of testing and debugging tools for Java.
		  Thus, there is a need to push research on tools that can
		  help Python developers.},
  booktitle	= {Proceedings of the 28th ACM Joint Meeting on European
		  Software Engineering Conference and Symposium on the
		  Foundations of Software Engineering},
  publisher	= {ACM},
  author	= {Widyasari, Ratnadira and Sim, Sheng Qin and Lok, Camellia
		  and Qi, Haodi and Phan, Jack and Tay, Qijin and Tan,
		  Constance and Wee, Fiona and Tan, Jodie Ethelda and Yieh,
		  Yuheng and Goh, Brian and Thung, Ferdian and Kang, Hong Jin
		  and Hoang, Thong and Lo, David and Ouh, Eng Lieh},
  year		= {2020},
  month		= {Nov},
  pages		= {1556–1560}
}

@Article{	  widyasari2022sfl,
  author	= {Widyasari, Ratnadira and Prana, Gede Artha Azriadi and
		  Haryono, Stefanus Agus and Wang, Shaowei and Lo, David},
  title		= {Real world projects, real faults: evaluating spectrum
		  based fault localization techniques on Python projects},
  year		= {2022},
  issue_date	= {Nov 2022},
  publisher	= {Kluwer Academic Publishers},
  address	= {USA},
  volume	= {27},
  number	= {6},
  issn		= {1382-3256},
  url		= {https://doi.org/10.1007/s10664-022-10189-4},
  doi		= {10.1007/s10664-022-10189-4},
  abstract	= {Spectrum Based Fault Localization (SBFL) is a statistical
		  approach to identify faulty code within a program given a
		  program spectra (i.e., records of program elements executed
		  by passing and failing test cases). Several SBFL techniques
		  have been proposed over the years, but most evaluations of
		  those techniques were done only on Java and C programs, and
		  frequently involve artificial faults. Considering the
		  current popularity of Python, indicated by the results of
		  the Stack Overflow survey among developers in 2020, it
		  becomes increasingly important to understand how SBFL
		  techniques perform on Python projects. However, this
		  remains an understudied topic. In this work, our objective
		  is to analyze the effectiveness of popular SBFL techniques
		  in real-world Python projects. We also aim to compare our
		  observed performance on Python to previously-reported
		  performance on Java. Using the recently-built bug benchmark
		  BugsInPy as our fault dataset, we apply five popular SBFL
		  techniques (Tarantula, Ochiai, OP, Barinel, and DStar) and
		  analyze their performances. We subsequently compare our
		  results with results from Java and C projects reported in
		  earlier related works. We find that 1) the real faults in
		  BugsInPy are harder to identify using SBFL techniques
		  compared to the real faults in Defects4J, indicated by the
		  lower performance of the evaluated SBFL techniques on
		  BugsInPy; 2) older techniques such as Tarantula, Barinel,
		  and Ochiai consistently outperform newer techniques (i.e.,
		  OP and DStar) in a variety of metrics and debugging
		  scenarios; 3) claims in preceding studies done on
		  artificial faults in C and Java (such as “OP outperforms
		  Tarantula”) do not hold on Python real faults; 4)
		  lower-performing techniques can outperform
		  higher-performing techniques in some cases, emphasizing the
		  potential benefit of combining SBFL techniques. Our results
		  yield insight into how popular SBFL techniques perform in
		  real Python faults and emphasize the importance of
		  conducting SBFL evaluations on real faults.},
  journal	= {Empirical Softw. Engg.},
  month		= {nov},
  numpages	= {50},
  keywords	= {empirical study, testing and debugging, Python,
		  Spectrum-based fault localization}
}

@InProceedings{	  widyasari2022xai4fl,
  author	= {Widyasari, Ratnadira and Prana, Gede Artha Azriadi and
		  Haryono, Stefanus A. and Tian, Yuan and Zachiary, Hafil
		  Noer and Lo, David},
  title		= {XAI4FL: enhancing spectrum-based fault localization with
		  explainable artificial intelligence},
  year		= {2022},
  isbn		= {9781450392983},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3524610.3527902},
  doi		= {10.1145/3524610.3527902},
  abstract	= {Manually finding the program unit (e.g., class, method, or
		  statement) responsible for a fault is tedious and
		  time-consuming. To mitigate this problem, many fault
		  localization techniques have been proposed. A popular
		  family of such techniques is spectrum-based fault
		  localization (SBFL), which takes program execution traces
		  (spectra) of failed and passed test cases as input and
		  applies a ranking formula to compute a suspiciousness score
		  for each program unit. However, most existing SBFL
		  techniques fail to consider two facts: 1) not all failed
		  test cases contribute equally to a considered fault(s), and
		  2) program units collaboratively contribute to the
		  failure/pass of each test case in different ways.In this
		  study, we propose a novel idea that first models the SBFL
		  task as a classification problem of predicting whether a
		  test case will fail or pass based on spectra information on
		  program units. We subsequently apply eXplainable Artificial
		  Intelligence (XAI) techniques to infer the local importance
		  of each program unit to the prediction of each executed
		  test case. Applying XAI to the failed test case, we
		  retrieve information about which program statements within
		  the test case that are considered the most important (i.e.,
		  have the biggest effect in making the test case failed).
		  Such a design can automatically learn the unique
		  contributions of failed test cases to the suspiciousness of
		  a program unit by learning the different and collaborative
		  contributions of program units to each test case's executed
		  result. As far as we know, this is the first XAI-supported
		  SBFL approach. We evaluate the new approach on the
		  Defects4J benchmark dataset.We compare the performance of
		  our approach against five popular SBFL techniques: DStar,
		  Tarantula, Barinel, Ochiai, and OP. We measure their
		  performance using the Top-K and EXAM scores. In particular,
		  we focus on the result of the Top-1, which importance has
		  been highlighted in automated program repair domain, where
		  the proposed methods often assume perfect fault
		  localization (i.e., the fault must be found at the first
		  rank of the suspiciousness list). Our results show that our
		  approach, named XAI4FL, has a statistically significant and
		  substantially better performance in terms of Top-1 than the
		  SBFL approaches. We also compare our approach with a
		  simpler approach to get feature importance in a tree-based
		  model (i.e., using the Mean Decrease in Impurity method).
		  Our results show that XAI4FL statistically significantly
		  outperforms the MDI method in Top-K and EXAM score. Our
		  results and findings highlight that the utilization of XAI
		  for fault localization can improve the overall results of
		  fault localization techniques.},
  booktitle	= {Proceedings of the 30th IEEE/ACM International Conference
		  on Program Comprehension},
  pages		= {499–510},
  numpages	= {12},
  keywords	= {explainable artificial intelligence (XAI), fault
		  localization, model-agnostic explanation technique,
		  spectrum-based fault localization, testing and debugging},
  location	= {Virtual Event},
  series	= {ICPC '22}
}

@InProceedings{	  wong07qzc,
  author	= {Wong, W. Eric and Qi, Yu and Zhao, Lei and Cai, Kai-Yuan},
  title		= {Effective Fault Localization Using Code Coverage},
  booktitle	= {COMPSAC '07},
  year		= {2007},
  isbn		= {0-7695-2870-8},
  pages		= {449--456},
  numpages	= {8},
  url		= {http://dx.doi.org/10.1109/COMPSAC.2007.109},
  doi		= {10.1109/COMPSAC.2007.109},
  acmid		= {1299726},
  publisher	= {IEEE Computer Society},
  address	= {Washington, DC, USA}
}

@InProceedings{	  wong2007wong,
  author	= {Wong, W. Eric and Qi, Yu and Zhao, Lei and Cai, Kai-Yuan},
  booktitle	= {31st Annual International Computer Software and
		  Applications Conference (COMPSAC 2007)},
  title		= {Effective Fault Localization using Code Coverage},
  year		= {2007},
  volume	= {1},
  number	= {},
  pages		= {449-456},
  doi		= {10.1109/COMPSAC.2007.109}
}

###InProceedings{ wong2007wong,
  author	= {Wong, W. Eric and Qi, Yu and Zhao, Lei and Cai, Kai-Yuan},
  booktitle	= {31st Annual International Computer Software and
		  Applications Conference (COMPSAC 2007)},
  title		= {Effective Fault Localization using Code Coverage},
  year		= {2007},
  volume	= {1},
  number	= {},
  pages		= {449-456},
  doi		= {10.1109/COMPSAC.2007.109}
}

@InProceedings{	  wong2008crosstab,
  author	= {Wong, Eric and Wei, Tingting and Qi, Yu and Zhao, Lei},
  title		= {A Crosstab-based Statistical Method for Effective Fault
		  Localization},
  year		= {2008},
  isbn		= {9780769531274},
  publisher	= {IEEE Computer Society},
  address	= {USA},
  url		= {https://doi.org/10.1109/ICST.2008.65},
  doi		= {10.1109/ICST.2008.65},
  abstract	= {Fault localization is the most expensive activity in
		  program debugging. Traditional ad-hoc methods can be
		  time-consuming and ineffective because they rely on
		  programmers’ intuitive guesswork, which may neither be
		  accurate nor reliable. A better solution is to utilize a
		  systematic and statistically well-defined method to
		  automatically identify suspicious code that should be
		  examined for possible fault locations. We present a
		  crosstab-based statistical method using the coverage
		  information of each executable statement and the execution
		  result (success or failure) with respect to each test case.
		  A crosstab is constructed for each executable statement and
		  a statistic is computed to determine the suspiciousness of
		  the corresponding statement. Statements with a higher
		  suspiciousness are more likely to contain bugs and should
		  be examined before those with a lower suspiciousness. Three
		  case studies using the Siemens suite, the Space program,
		  and the Unix suite, respectively, are conducted. Our
		  results suggest that the crosstab-based method is effective
		  in fault localization and performs better (in terms of a
		  smaller percentage of executable statements that have to be
		  examined until the first statement containing the fault is
		  reached) than other methods such as Tarantula. The
		  difference in efficiency (computational time) between these
		  two methods is very small.},
  booktitle	= {Proceedings of the 2008 International Conference on
		  Software Testing, Verification, and Validation},
  pages		= {42–51},
  numpages	= {10},
  keywords	= {Chi-square test, contingency coefficient, crosstab
		  analysis, fault localization, hypothesis test, program
		  debugging},
  series	= {ICST '08}
}

@Article{	  wong2010,
  author	= {Wong, W Eric and Debroy, Vidroha},
  date-added	= {2015-01-09 14:32:55 +0000},
  date-modified	= {2015-01-09 14:32:55 +0000},
  journal	= {Encyclopedia of Software Engineering},
  pages		= {1147--1156},
  publisher	= {Citeseer},
  title		= {Software Fault Localization.},
  volume	= {1},
  year		= {2010}
}

@Article{	  wong2012crosstab,
  author	= {Wong, W. Eric and Debroy, Vidroha and Xu, Dianxiang},
  journal	= {IEEE Transactions on Systems, Man, and Cybernetics, Part C
		  (Applications and Reviews)},
  title		= {Towards Better Fault Localization: A Crosstab-Based
		  Statistical Approach},
  year		= {2012},
  volume	= {42},
  number	= {3},
  pages		= {378-396},
  doi		= {10.1109/TSMCC.2011.2118751}
}

###Article{	  wong2012crosstab,
  author	= {Wong, W. Eric and Debroy, Vidroha and Xu, Dianxiang},
  journal	= {IEEE Transactions on Systems, Man, and Cybernetics, Part C
		  (Applications and Reviews)},
  title		= {Towards Better Fault Localization: A Crosstab-Based
		  Statistical Approach},
  year		= {2012},
  volume	= {42},
  number	= {3},
  pages		= {378-396},
  doi		= {10.1109/TSMCC.2011.2118751}
}

@InProceedings{	  wong2012dstar,
  author	= {Wong, W. Eric and Debroy, Vidroha and Li, Yihao and Gao,
		  Ruizhi},
  booktitle	= {2012 IEEE Sixth International Conference on Software
		  Security and Reliability},
  title		= {Software Fault Localization Using {DStar} {(D*)}},
  year		= {2012},
  volume	= {},
  number	= {},
  pages		= {21-30},
  doi		= {10.1109/SERE.2012.12}
}

###InProceedings{ wong2012dstar,
  author	= {Wong, W. Eric and Debroy, Vidroha and Li, Yihao and Gao,
		  Ruizhi},
  booktitle	= {2012 IEEE Sixth International Conference on Software
		  Security and Reliability},
  title		= {Software Fault Localization Using DStar (D*)},
  year		= {2012},
  volume	= {},
  number	= {},
  pages		= {21-30},
  doi		= {10.1109/SERE.2012.12}
}

###InProceedings{ wong2012dstar,
  title		= {Software fault localization using DStar (D*)},
  author	= {Wong, W Eric and Debroy, Vidroha and Li, Yihao and Gao,
		  Ruizhi},
  booktitle	= {Software Security and Reliability (SERE), 2012 IEEE Sixth
		  International Conference on},
  pages		= {21--30},
  year		= {2012},
  organization	= {IEEE}
}

@Article{	  wongglaw16,
  author	= {W. Eric Wong and Ruizhi Gao and Yihao Li and Rui Abreu and
		  Franz Wotawa},
  title		= {A Survey on Software Fault Localization},
  journal	= {{IEEE} Trans. Software Eng.},
  volume	= {42},
  number	= {8},
  pages		= {707--740},
  year		= {2016}
}

@InProceedings{	  xiabll16,
  author	= {Xin Xia and Lingfeng Bao and David Lo and Shanping Li},
  title		= {``{A}utomated Debugging Considered Harmful'' Considered
		  Harmful: {A} User Study Revisiting the Usefulness of
		  Spectra-Based Fault Localization Techniques with
		  Professionals Using Real Bugs from Large Systems},
  booktitle	= {2016 {IEEE} International Conference on Software
		  Maintenance and Evolution, {ICSME} 2016},
  pages		= {267--278},
  year		= {2016}
}

@Article{	  xiaglljz16,
  author	= {Xin Xia and Liang Gong and Tien{-}Duy B. Le and David Lo
		  and Lingxiao Jiang and Hongyu Zhang},
  title		= {Diversity maximization speedup for localizing faults in
		  single-fault and multi-fault programs},
  journal	= {Autom. Softw. Eng.},
  volume	= {23},
  number	= {1},
  pages		= {43--75},
  year		= {2016}
}

@Article{	  xie13ckx,
  author	= {Xie, Xiaoyuan and Chen, Tsong Yueh and Kuo, Fei-Ching and
		  Xu, Baowen},
  title		= {A Theoretical Analysis of the Risk Evaluation Formulas for
		  Spectrum-based Fault Localization},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  issue_date	= {2013},
  volume	= {22},
  number	= {4},
  month		= oct,
  year		= {2013},
  issn		= {1049-331X},
  pages		= {1--40},
  articleno	= {31},
  numpages	= {40},
  url		= {http://doi.acm.org/10.1145/2522920.2522924},
  doi		= {10.1145/2522920.2522924},
  acmid		= {2522924},
  publisher	= {ACM},
  address	= {New York, NY, USA},
  keywords	= {Debugging, risk evaluation formulas, spectrum-based fault
		  localization, testing}
}

@InProceedings{	  xie2013gp,
  author	= {Xie, Xiaoyuan and Kuo, Fei-Ching and Chen, Tsong Yueh and
		  Yoo, Shin and Harman, Mark},
  title		= {Provably Optimal and Human-Competitive Results in SBSE for
		  Spectrum Based Fault Localisation},
  year		= {2013},
  isbn		= {9783642397417},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  url		= {https://doi.org/10.1007/978-3-642-39742-4_17},
  doi		= {10.1007/978-3-642-39742-4_17},
  abstract	= {Fault localisation uses so-called risk evaluation
		  formul\ae{} to guide the localisation process. For more
		  than a decade, the design and improvement of these
		  formul\ae{} has been conducted entirely manually through
		  iterative publication in the fault localisation literature.
		  However, recently we demonstrated that SBSE could be used
		  to automatically design such formul\ae{} by recasting this
		  as a problem for Genetic ProgrammingGP. In this paper we
		  prove that our GP has produced four previously unknown
		  globally optimal formul\ae{}. Though other human
		  competitive results have previously been reported in the
		  SBSE literature, this is the first SBSE result, in any
		  application domain, for which human competitiveness has
		  been formally proved. We also show that some of these
		  formul\ae{} exhibit counter-intuitive characteristics,
		  making them less likely to have been found solely by
		  further human effort.},
  booktitle	= {Proceedings of the 5th International Symposium on Search
		  Based Software Engineering - Volume 8084},
  pages		= {224–238},
  numpages	= {15},
  location	= {St. Petersburg, Russia},
  series	= {SSBSE 2013}
}

###InProceedings{ xie2013gp,
  author	= {Xie, Xiaoyuan and Kuo, Fei-Ching and Chen, Tsong Yueh and
		  Yoo, Shin and Harman, Mark},
  title		= {Provably Optimal and Human-Competitive Results in SBSE for
		  Spectrum Based Fault Localisation},
  year		= {2013},
  isbn		= {9783642397417},
  publisher	= {Springer-Verlag},
  address	= {Berlin, Heidelberg},
  url		= {https://doi.org/10.1007/978-3-642-39742-4_17},
  doi		= {10.1007/978-3-642-39742-4_17},
  abstract	= {Fault localisation uses so-called risk evaluation
		  formul\ae{} to guide the localisation process. For more
		  than a decade, the design and improvement of these
		  formul\ae{} has been conducted entirely manually through
		  iterative publication in the fault localisation literature.
		  However, recently we demonstrated that SBSE could be used
		  to automatically design such formul\ae{} by recasting this
		  as a problem for Genetic ProgrammingGP. In this paper we
		  prove that our GP has produced four previously unknown
		  globally optimal formul\ae{}. Though other human
		  competitive results have previously been reported in the
		  SBSE literature, this is the first SBSE result, in any
		  application domain, for which human competitiveness has
		  been formally proved. We also show that some of these
		  formul\ae{} exhibit counter-intuitive characteristics,
		  making them less likely to have been found solely by
		  further human effort.},
  booktitle	= {Proceedings of the 5th International Symposium on Search
		  Based Software Engineering - Volume 8084},
  pages		= {224–238},
  numpages	= {15},
  location	= {St. Petersburg, Russia},
  series	= {SSBSE 2013}
}

@InProceedings{	  xiekcyh13,
  author	= {Xiaoyuan Xie and Fei{-}Ching Kuo and Tsong Yueh Chen and
		  Shin Yoo and Mark Harman},
  editor	= {G{\"{u}}nther Ruhe and Yuanyuan Zhang},
  title		= {Provably Optimal and Human-Competitive Results in {SBSE}
		  for Spectrum Based Fault Localisation},
  booktitle	= {Lecture Notes in Computer Science},
  volume	= {8084},
  pages		= {224--238},
  publisher	= {Springer},
  year		= {2013},
  url		= {https://doi.org/10.1007/978-3-642-39742-4_17},
  doi		= {10.1007/978-3-642-39742-4_17}
}

@Article{	  xiewcx13,
  author	= {Xiaoyuan Xie and W. Eric Wong and Tsong Yueh Chen and
		  Baowen Xu},
  title		= {Metamorphic slice: An application in spectrum-based fault
		  localization},
  journal	= {Information {\&} Software Technology},
  volume	= {55},
  number	= {5},
  pages		= {866--879},
  year		= {2013},
  url		= {https://doi.org/10.1016/j.infsof.2012.08.008},
  doi		= {10.1016/j.infsof.2012.08.008}
}

@InProceedings{	  xuan14m,
  author	= {Jifeng Xuan and Monperrus, Monperrus},
  booktitle	= {ICSME '14},
  title		= {Learning to Combine Multiple Ranking Metrics for Fault
		  Localization},
  publisher	= {IEEE},
  year		= {2014},
  month		= {Sept},
  pages		= {191--200},
  doi		= {10.1109/ICSME.2014.41},
  issn		= {1063-6773}
}

@InProceedings{	  xuan2014test,
  author	= {Xuan, Jifeng and Monperrus, Martin},
  title		= {Test case purification for improving fault localization},
  year		= {2014},
  isbn		= {9781450330565},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2635868.2635906},
  doi		= {10.1145/2635868.2635906},
  abstract	= {Finding and fixing bugs are time-consuming activities in
		  software development. Spectrum-based fault localization
		  aims to identify the faulty position in source code based
		  on the execution trace of test cases. Failing test cases
		  and their assertions form test oracles for the failing
		  behavior of the system under analysis. In this paper, we
		  propose a novel concept of spectrum driven test case
		  purification for improving fault localization. The goal of
		  test case purification is to separate existing test cases
		  into small fractions (called purified test cases) and to
		  enhance the test oracles to further localize faults.
		  Combining with an original fault localization technique
		  (e.g., Tarantula), test case purification results in better
		  ranking the program statements. Our experiments on 1800
		  faults in six open-source Java programs show that test case
		  purification can effectively improve existing fault
		  localization techniques.},
  booktitle	= {Proceedings of the 22nd ACM SIGSOFT International
		  Symposium on Foundations of Software Engineering},
  pages		= {52–63},
  numpages	= {12},
  keywords	= {Test case purification, dynamic program slicing,
		  spectrum-based fault localization, test case atomization},
  location	= {Hong Kong, China},
  series	= {FSE 2014}
}

@InProceedings{	  xuanm14b,
  author	= {Jifeng Xuan and Martin Monperrus},
  editor	= {Shing{-}Chi Cheung and Alessandro Orso and Margaret{-}Anne
		  D. Storey},
  title		= {Test case purification for improving fault localization},
  booktitle	= {Proceedings of the 22nd {ACM} {SIGSOFT} International
		  Symposium on Foundations of Software Engineering, (FSE-22),
		  Hong Kong, China, November 16 - 22, 2014},
  pages		= {52--63},
  publisher	= {{ACM}},
  year		= {2014},
  url		= {http://doi.acm.org/10.1145/2635868.2635906},
  doi		= {10.1145/2635868.2635906},
  timestamp	= {Thu, 15 Jun 2017 21:43:16 +0200},
  biburl	= {https://dblp.org/rec/bib/conf/sigsoft/XuanM14},
  bibsource	= {dblp computer science bibliography, https://dblp.org}
}

@Article{	  yan2023context,
  author	= {Yan, Yue and Jiang, Shujuan and Zhang, Yanmei and Zhang,
		  Shenggang and Zhang, Cheng},
  title		= {A fault localization approach based on fault propagation
		  context},
  year		= {2023},
  issue_date	= {Aug 2023},
  publisher	= {Butterworth-Heinemann},
  address	= {USA},
  volume	= {160},
  number	= {C},
  issn		= {0950-5849},
  url		= {https://doi.org/10.1016/j.infsof.2023.107245},
  doi		= {10.1016/j.infsof.2023.107245},
  journal	= {Inf. Softw. Technol.},
  month		= {aug},
  numpages	= {11},
  keywords	= {Fault propagation context, Program analysis,
		  Spectrum-based fault localization, Software fault
		  localization}
}

@Article{	  yang2024multilingual,
  author	= {Yang, Haoran and Nong, Yu and Zhang, Tao and Luo, Xiapu
		  and Cai, Haipeng},
  title		= {Learning to Detect and Localize Multilingual Bugs},
  year		= {2024},
  issue_date	= {July 2024},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {1},
  number	= {FSE},
  url		= {https://doi.org/10.1145/3660804},
  doi		= {10.1145/3660804},
  abstract	= {Increasing studies have shown bugs in multi-language
		  software as a critical loophole in modern software quality
		  assurance, especially those induced by language
		  interactions (i.e., multilingual bugs). Yet existing tool
		  support for bug detection/localization remains largely
		  limited to single-language software, despite the
		  long-standing prevalence of multi-language systems in
		  various real-world software domains. Extant static/dynamic
		  analysis and deep learning (DL) based approaches all face
		  major challenges in addressing multilingual bugs. In this
		  paper, we present xLoc, a DL-based technique/tool for
		  detecting and localizing multilingual bugs. Motivated by
		  results of our bug-characteristics study on top locations
		  of multilingual bugs, xLoc first learns the general
		  knowledge relevant to differentiating various multilingual
		  control-flow structures. This is achieved by pre-training a
		  Transformer model with customized position encoding against
		  novel objectives. Then, xLoc learns task-specific knowledge
		  for the task of multilingual bug detection/localization,
		  through another new position encoding scheme (based on
		  cross-language API vicinity) that allows for the model to
		  attend particularly to control-flow constructs that bear
		  most multilingual bugs during fine-tuning. We have
		  implemented xLoc for Python-C software and curated a
		  dataset of 3,770 buggy and 15,884 non-buggy Python-C
		  samples, which enabled our extensive evaluation of xLoc
		  against two state-of-the-art baselines: fine-tuned CodeT5
		  and zero-shot ChatGPT. Our results show that xLoc achieved
		  94.98\% F1 and 87.24\%@Top-1 accuracy, which are
		  significantly (up to 162.88\% and 511.75\%) higher than the
		  baselines. Ablation studies further confirmed significant
		  contributions of each of the novel design elements in xLoc.
		  With respective bug-location characteristics and labeled
		  bug datasets for fine-tuning, our design may be applied to
		  other language combinations beyond Python-C.},
  journal	= {Proc. ACM Softw. Eng.},
  month		= {jul},
  articleno	= {97},
  numpages	= {24},
  keywords	= {Multi-language software, bug detection, fault
		  localization, multilingual bugs}
}

@InProceedings{	  yangqm17,
  author	= {Deheng Yang and Yuhua Qi and Xiaoguang Mao},
  title		= {An Empirical Study on the Usage of Fault Localization in
		  Automated Program Repair},
  booktitle	= {2017 {IEEE} International Conference on Software
		  Maintenance and Evolution, {ICSME} 2017},
  pages		= {504--508},
  publisher	= {{IEEE} Computer Society},
  year		= {2017},
  url		= {http://doi.ieeecomputersociety.org/10.1109/ICSME.2017.37},
  doi		= {10.1109/ICSME.2017.37},
  timestamp	= {Thu, 16 Nov 2017 16:30:18 +0100},
  biburl	= {http://dblp.org/rec/bib/conf/icsm/YangQM17},
  bibsource	= {dblp computer science bibliography, http://dblp.org}
}

@Article{	  yi2017,
  author	= "Yi, Jooyong and Tan, Shin Hwei and Mechtaev, Sergey and
		  B{\"o}hme, Marcel and Roychoudhury, Abhik",
  title		= "A correlation study between automated program repair and
		  test-suite metrics",
  journal	= "Empirical Software Engineering",
  year		= "2017",
  month		= "Sep",
  day		= "30",
  abstract	= "Automated program repair is increasingly gaining traction,
		  due to its potential to reduce debugging cost greatly. The
		  feasibility of automated program repair has been shown in a
		  number of works, and the research focus is gradually
		  shifting toward the quality of generated patches. One
		  promising direction is to control the quality of generated
		  patches by controlling the quality of test-suites used for
		  automated program repair. In this paper, we ask the
		  following research question: ``Can traditional test-suite
		  metrics proposed for the purpose of software testing also
		  be used for the purpose of automated program repair?'' We
		  empirically investigate whether traditional test-suite
		  metrics such as statement/branch coverage and mutation
		  score are effective in controlling the reliability of
		  generated repairs (the likelihood that repairs cause
		  regression errors). We conduct the largest-scale
		  experiments of this kind to date with real-world software,
		  and for the first time perform a correlation study between
		  various test-suite metrics and the reliability of generated
		  repairs. Our results show that in general, with the
		  increase of traditional test suite metrics, the reliability
		  of repairs tend to increase. In particular, such a trend is
		  most strongly observed in statement coverage. Our results
		  imply that the traditional test suite metrics proposed for
		  software testing can also be used for automated program
		  repair to improve the reliability of repairs."
}

@InProceedings{	  yoo12,
  year		= {2012},
  isbn		= {978-3-642-33118-3},
  booktitle	= {LNCS},
  volume	= {7515},
  editor	= {Fraser, Gordon and Teixeira de Souza, Jerffeson},
  doi		= {10.1007/978-3-642-33119-0_18},
  title		= {Evolving Human Competitive Spectra-Based Fault
		  Localisation Techniques},
  url		= {http://dx.doi.org/10.1007/978-3-642-33119-0_18},
  publisher	= {Springer},
  author	= {Yoo, Shin},
  pages		= {244--258}
}

@Article{	  yoo2013priorization,
  author	= {Yoo, Shin and Harman, Mark and Clark, David},
  title		= {Fault Localization Prioritization: Comparing
		  Information-Theoretic and Coverage-Based Approaches},
  year		= {2013},
  issue_date	= {July 2013},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {22},
  number	= {3},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/2491509.2491513},
  doi		= {10.1145/2491509.2491513},
  abstract	= {Test case prioritization techniques seek to maximize early
		  fault detection. Fault localization seeks to use test cases
		  already executed to help find the fault location. There is
		  a natural interplay between the two techniques; once a
		  fault is detected, we often switch focus to fault fixing,
		  for which localization may be a first step. In this article
		  we introduce the Fault Localization Prioritization (FLP)
		  problem, which combines prioritization and localization. We
		  evaluate three techniques: a novel FLP technique based on
		  information theory, FLINT (Fault Localization using
		  INformation Theory), that we introduce in this article, a
		  standard Test Case Prioritization (TCP) technique, and a
		  “test similarity technique” used in previous work. Our
		  evaluation uses five different releases of four software
		  systems. The results indicate that FLP and TCP can
		  statistically significantly reduce fault localization costs
		  for 73\% and 76\% of cases, respectively, and that FLINT
		  significantly outperforms similarity-based localization
		  techniques in 52\% of the cases considered in the study.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {jul},
  articleno	= {19},
  numpages	= {29},
  keywords	= {fault localization, information theory, Test case
		  prioritization}
}

###Article{	  yoo2013priorization,
  author	= {Yoo, Shin and Harman, Mark and Clark, David},
  title		= {Fault Localization Prioritization: Comparing
		  Information-Theoretic and Coverage-Based Approaches},
  year		= {2013},
  issue_date	= {July 2013},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {22},
  number	= {3},
  issn		= {1049-331X},
  url		= {https://doi.org/10.1145/2491509.2491513},
  doi		= {10.1145/2491509.2491513},
  abstract	= {Test case prioritization techniques seek to maximize early
		  fault detection. Fault localization seeks to use test cases
		  already executed to help find the fault location. There is
		  a natural interplay between the two techniques; once a
		  fault is detected, we often switch focus to fault fixing,
		  for which localization may be a first step. In this article
		  we introduce the Fault Localization Prioritization (FLP)
		  problem, which combines prioritization and localization. We
		  evaluate three techniques: a novel FLP technique based on
		  information theory, FLINT (Fault Localization using
		  INformation Theory), that we introduce in this article, a
		  standard Test Case Prioritization (TCP) technique, and a
		  “test similarity technique” used in previous work. Our
		  evaluation uses five different releases of four software
		  systems. The results indicate that FLP and TCP can
		  statistically significantly reduce fault localization costs
		  for 73\% and 76\% of cases, respectively, and that FLINT
		  significantly outperforms similarity-based localization
		  techniques in 52\% of the cases considered in the study.},
  journal	= {ACM Trans. Softw. Eng. Methodol.},
  month		= {jul},
  articleno	= {19},
  numpages	= {29},
  keywords	= {fault localization, information theory, Test case
		  prioritization}
}

@Article{	  yooxkch17,
  author	= {Shin Yoo and Xiaoyuan Xie and Fei{-}Ching Kuo and Tsong
		  Yueh Chen and Mark Harman},
  title		= {Human Competitiveness of Genetic Programming in
		  Spectrum-Based Fault Localisation: Theoretical and
		  Empirical Analysis},
  journal	= {{ACM} Trans. Softw. Eng. Methodol.},
  volume	= {26},
  number	= {1},
  pages		= {4:1--4:30},
  year		= {2017},
  url		= {http://doi.acm.org/10.1145/3078840},
  doi		= {10.1145/3078840},
  timestamp	= {Mon, 31 Jul 2017 13:11:39 +0200},
  biburl	= {http://dblp.org/rec/bib/journals/tosem/YooXKCH17},
  bibsource	= {dblp computer science bibliography, http://dblp.org}
}

@InProceedings{	  yu2011models,
  author	= {Yu, Kai and Lin, Mengxiang and Gao, Qing and Zhang, Hui
		  and Zhang, Xiangyu},
  title		= {Locating faults using multiple spectra-specific models},
  year		= {2011},
  isbn		= {9781450301138},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1982185.1982490},
  doi		= {10.1145/1982185.1982490},
  abstract	= {Spectra-based fault localization (SFL) techniques have
		  brought encouraging results and a variety of program
		  spectra have been proposed to locate faults. Different
		  types of abnormal behaviors may be revealed by different
		  kinds of spectra. Compared to techniques using single
		  spectra type, techniques combining multiple types of
		  spectra try to leverage the strengths of the constituent
		  types. However, in the presence of multiple kinds of
		  spectra, how to select adequate spectra type and build
		  appropriate models need further investigation.In this
		  paper, we propose an SFL technique LOUPE, which uses
		  multiple spectra-specific models. Both control and data
		  dependences are introduced to capture unusual behaviors of
		  faults. In the stage of suspiciousness modeling, in
		  contrast with previous studies, we build different models
		  to evaluate the suspiciousness of statements for each
		  spectra type respectively. Finally, since the fault type is
		  unknown in advance, suspiciousness scores are calculated
		  based on the two models. We evaluate LOUPE on the Siemens
		  benchmark and experimental results show that our technique
		  is promising.},
  booktitle	= {Proceedings of the 2011 ACM Symposium on Applied
		  Computing},
  pages		= {1404–1410},
  numpages	= {7},
  keywords	= {fault localization, multiple models, multiple spectra
		  types, spectra selection, spectra-specific model},
  location	= {TaiChung, Taiwan},
  series	= {SAC '11}
}

@InProceedings{	  yulsr00l0w22,
  author	= {Hao Yu and Yiling Lou and Ke Sun and Dezhi Ran and Tao Xie
		  and Dan Hao and Ying Li and Ge Li and Qianxiang Wang},
  title		= {Automated Assertion Generation via Information Retrieval
		  and Its Integration with Deep learning},
  booktitle	= {44th {IEEE/ACM} 44th International Conference on Software
		  Engineering, {ICSE} 2022},
  pages		= {163--174},
  publisher	= {{ACM}},
  year		= {2022},
  url		= {https://doi.org/10.1145/3510003.3510149},
  doi		= {10.1145/3510003.3510149}
}

@Misc{		  zalewski2013afl,
  author	= {Micha\l{} Zalewski},
  url		= {https://lcamtuf.coredump.cx/afl/},
  title		= {American fuzzy lop (afl)},
  year		= {2013},
  note		= {Accessed on 13.09.2023}
}

###Misc{	  zalewski2013afl,
  author	= {Micha\l{} Zalewski},
  url		= {https://lcamtuf.coredump.cx/afl/},
  title		= {American fuzzy lop (afl)},
  year		= {2013},
  note		= {Accessed on 13.09.2023}
}

@InProceedings{	  zhang2009capturing,
  author	= {Zhang, Zhenyu and Chan, W. K. and Tse, T. H. and Jiang, Bo
		  and Wang, Xinming},
  title		= {Capturing propagation of infected program states},
  year		= {2009},
  isbn		= {9781605580012},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/1595696.1595705},
  doi		= {10.1145/1595696.1595705},
  abstract	= {Coverage-based fault-localization techniques find the
		  fault-related positions in programs by comparing the
		  execution statistics of passed executions and failed
		  executions. They assess the fault suspiciousness of
		  individual program entities and rank the statements in
		  descending order of their suspiciousness scores to help
		  identify faults in programs. However, many such techniques
		  focus on assessing the suspiciousness of individual program
		  entities but ignore the propagation of infected program
		  states among them. In this paper, we use edge profiles to
		  represent passed executions and failed executions, contrast
		  them to model how each basic block contributes to failures
		  by abstractly propagating infected program states to its
		  adjacent basic blocks through control flow edges. We assess
		  the suspiciousness of the infected program states
		  propagated through each edge, associate basic blocks with
		  edges via such propagation of infected program states,
		  calculate suspiciousness scores for each basic block, and
		  finally synthesize a ranked list of statements to
		  facilitate the identification of program faults. We conduct
		  a controlled experiment to compare the effectiveness of
		  existing representative techniques with ours using standard
		  bench-marks. The results are promising.},
  booktitle	= {Proceedings of the 7th Joint Meeting of the European
		  Software Engineering Conference and the ACM SIGSOFT
		  Symposium on The Foundations of Software Engineering},
  pages		= {43–52},
  numpages	= {10},
  keywords	= {basic block, control-flow edge, edge profile, fault
		  localization},
  location	= {Amsterdam, The Netherlands},
  series	= {ESEC/FSE '09}
}

@InProceedings{	  zhang2013injecting,
  title		= {Injecting mechanical faults to localize developer faults
		  for evolving software},
  author	= {Zhang, Lingming and Zhang, Lu and Khurshid, Sarfraz},
  booktitle	= {ACM SIGPLAN Notices},
  volume	= {48},
  number	= {10},
  pages		= {765--784},
  year		= {2013},
  organization	= {ACM}
}

@InProceedings{	  zhanglzk17,
  author	= {Mengshi Zhang and Xia Li and Lingming Zhang and Sarfraz
		  Khurshid},
  editor	= {Tevfik Bultan and Koushik Sen},
  title		= {Boosting spectrum-based fault localization using
		  PageRank},
  booktitle	= {Proceedings of the 26th {ACM} {SIGSOFT} International
		  Symposium on Software Testing and Analysis},
  pages		= {261--272},
  publisher	= {{ACM}},
  year		= {2017},
  url		= {http://doi.acm.org/10.1145/3092703.3092731},
  doi		= {10.1145/3092703.3092731}
}

@InProceedings{	  zhangm15,
  author	= {Yucheng Zhang and Ali Mesbah},
  editor	= {Elisabetta Di Nitto and Mark Harman and Patrick Heymans},
  title		= {Assertions are strongly correlated with test suite
		  effectiveness},
  booktitle	= {Proceedings of the 2015 10th Joint Meeting on Foundations
		  of Software Engineering, {ESEC/FSE} 2015},
  pages		= {214--224},
  publisher	= {{ACM}},
  year		= {2015},
  url		= {https://doi.org/10.1145/2786805.2786858},
  doi		= {10.1145/2786805.2786858}
}

@InProceedings{	  zhangyrpk14,
  author	= {Lingming Zhang and Guowei Yang and Neha Rungta and Suzette
		  Person and Sarfraz Khurshid},
  editor	= {Corina S. Pasareanu and Darko Marinov},
  title		= {Feedback-driven dynamic invariant discovery},
  booktitle	= {International Symposium on Software Testing and Analysis,
		  {ISSTA} '14},
  pages		= {362--372},
  publisher	= {{ACM}},
  year		= {2014},
  url		= {https://doi.org/10.1145/2610384.2610389},
  doi		= {10.1145/2610384.2610389}
}

@InProceedings{	  zhao11zwy,
  author	= {Lei Zhao and Zhenyu Zhang and Lina Wang and Xiaodan Yin},
  title		= {{PAFL:} Fault Localization via Noise Reduction on Coverage
		  Vector},
  booktitle	= {SEKE '11},
  pages		= {203--206},
  year		= {2011}
}

@Article{	  zhaowy11,
  author	= {Lei Zhao and Lina Wang and Xiaodan Yin},
  title		= {Context-Aware Fault Localization via Control Flow
		  Analysis},
  journal	= {{JSW}},
  volume	= {6},
  number	= {10},
  pages		= {1977--1984},
  year		= {2011},
  url		= {https://doi.org/10.4304/jsw.6.10.1977-1984},
  doi		= {10.4304/jsw.6.10.1977-1984},
  timestamp	= {Thu, 18 May 2017 09:52:00 +0200},
  biburl	= {http://dblp.org/rec/bib/journals/jsw/ZhaoWY11},
  bibsource	= {dblp computer science bibliography, http://dblp.org}
}

@Article{	  zoulxet18,
  author	= {Daming Zou and Jingjing Liang and Yingfei Xiong and
		  Michael D. Ernst and Lu Zhang},
  title		= {An Empirical Study of Fault Localization Families and
		  Their Combinations},
  journal	= {CoRR},
  volume	= {abs/1803.09939},
  year		= {2018},
  url		= {http://arxiv.org/abs/1803.09939},
  archiveprefix	= {arXiv},
  eprint	= {1803.09939},
  timestamp	= {Wed, 11 Apr 2018 17:54:17 +0200},
  biburl	= {https://dblp.org/rec/bib/journals/corr/abs-1803-09939},
  bibsource	= {dblp computer sc ience bibliography, https://dblp.org}
}
