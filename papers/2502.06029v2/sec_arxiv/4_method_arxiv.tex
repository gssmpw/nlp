\section{\ourmethod: Diffeomorphic Multi-Task Adaptation}
\label{sec:method}

We introduce \ourmethod\ (Diffeomorphic Multi-Task Adaptation), a novel approach for efficient multi-task fine-tuning. Our method is grounded in a fundamental analysis of how neural networks process information through their weight matrices. We draw insights from linear algebra to the workings of a linear layer of neural network in \Cref{subsec:motivation} relating it to SVD. In \Cref{subsec:ditask}, we formally introduce \ourmethod\ and elaborate on its properties that motivate our design choices in \Cref{subsec:theory}.

\subsection{Understanding Weight Matrices}
\label{subsec:motivation}
We now show that by considering the SVD of weight matrices, we can gain insights on the course of action of linear layers, that later, in Section \ref{subsec:ditask}, serves as a mathematically grounded motivation for the design of our \ourmethod. Specifically, we note that  a linear layer with weight matrix $\mathbf{W} \in \mathbb{R}^{c_2 \times c_1}$, and its SVD decomposition $\bf W = \bf U \bf \Sigma \bf V^\top$, can be viewed as a linear map $g: \mathbb{R}^{c_1} \rightarrow \mathbb{R}^{c_2}$, such that the following equality holds:
\begin{equation}
    g(\rvx) = \mathbf{W} \mathbf{x} = \sum\limits_{i=1}^{p} \sigma_i \, \langle \rvx, \rvv_i \rangle \rvu_i,
\end{equation}
where $\rmU = [\rvu_1, \ldots, \rvu_{c_2}]$, $\rmV = [\rvv_1, \ldots, \rvv_{c_1}]$, and $\mathbf{\Sigma} = diag([\sigma_1, \sigma_2, \ldots, \sigma_{p}])$, $p = \min(c_1, c_2)$. The basis vectors in $\rmU$ are the left singular vectors, $\bf V$ are right singular vectors, and $\mathbf{\Sigma}$ are the singular values of $\rmW$.

\noindent Specifically, the orientations encoded by the left and right singular vectors represent features present in the output and input spaces of the linear transformation $g$, respectively. Multi-task learning requires adapting these orientations \emph{jointly} for all tasks, while minimizing task interference to prevent performance degradation. Below, we describe how to achieve effective multi-task adaptation using diffeomorphisms, by preserving the singular vectors $\bf U, \ \bf V$ and modifying $\bf W$ in a principled manner.


\subsection{Adaptation with \ourmethod}
\label{subsec:ditask}
Given a learned weight matrix $\mathbf W = \mathbf{U} \mathbf{\Sigma} \mathbf{V}^\top \in \mathbb{R}^{c_2 \times c_1}$ from a ViT, we transform the singular values $\mathbf{\Sigma}$ by a learned neural diffeomorphism $f^{\vtheta}$ described in \Cref{eq:cpab}, to get the adapted weight matrix $\rmW_A$ as follows:
\small
\begin{equation}
\label{eq:cpab_ditask}
% \small
     \rmW_A = \rmU \, \begin{bmatrix}
        f^{\vtheta}(\sigma_1) & 0 & \ldots & 0 \\
    0 & f^{\vtheta}(\sigma_2) & \ldots & 0 \\
     \vdots & \vdots & \ddots & \vdots \\
     0 & 0 & \ldots & f^{\vtheta}(\sigma_p)
    \end{bmatrix} \, \rmV^\top.
\end{equation}


\noindent During fine-tuning, we freeze $\rmW$ and learn only the parameters $\vtheta$ of the CPA velocity field. This allows \ourmethod\ to adapt to multiple tasks using $\gO(\gN_\gP)$ additional parameters (where typically  $\gN_\gP \leq 128$), which is significantly smaller than  methods with low-rank $r$ using $\gO(r(c_1 + c_2))$. We describe this process in the \Cref{fig:left}, and compare the computational cost of \ourmethod{} with other fine-tuning methods in the supplementary material.
\\
\noindent\textbf{Multi-Task Adaptation with \ourmethod.}  
To enable both multi and task-specific adaptation, we learn two sets of neural diffeomorphic transformations in every pre-trained weight matrix $\rmW$, shown in   \Cref{fig:overview_right}, that include: (i) \textit{Joint Adaptation} parameters, denoted by $\vtheta_j$, to allow task synergies which are crucial for MTL \citep{Huang_2024_CVPR,mtl_survey}; and (ii) \textit{Task-wise Adaptation} parameters, denoted by $\{\vtheta_k\}_{k=1}^K$ to enable learning nuances for each task.


\subsection{Properties of \ourmethod}
\label{subsec:theory}
In this section, we motivate our design choices and discuss the properties that make \ourmethod\ an effective and parameter-efficient fine-tuning method for MTL.
\\
\noindent\textbf{Feature Space Preservation.} As discussed in \Cref{subsec:motivation}, pre-trained weight matrices encode feature transformations through their singular vectors, where $\mathbf{U}$ and $\mathbf{V}$ form orthonormal bases for output and input spaces, respectively. These bases capture the orientation of patterns learned during pre-training, each weighted by its corresponding singular value. In contrast to traditional low-rank methods like LoRA, which constrain adaptations to fixed low-dimensional subspaces, potentially losing important features, our \ourmethod\ preserves these learned bases entirely. This preservation allows us to achieve superior multi-task performance with fewer parameters, as shown in \Cref{fig:teaser}. Specifically, while low-rank methods require increasing their rank (and thus parameters and departure from being low-rank) to match single-task performance, our \ourmethod\ maintains the learned feature space of pre-trained ViTs through a targeted and mathematically-ground singular value modulation.
\\
\noindent\textbf{Feature Relativity Preservation.} The order of singular values $\sigma_1 \geq \sigma_2 \geq \ldots \geq \sigma_p$ in weight matrices of ViTs encode the relative importance of features learned during pre-training on large-scale datasets like ImageNet-21k. By utilizing diffeomorphisms, which are smooth, invertible, and monotone, by definition, we preserve this ordering. That is, if $f^{\vtheta}$ is a diffeomorphism, then $f^{\vtheta}(\sigma_1) \geq f^{\vtheta}(\sigma_2) \geq ... \geq f^{\vtheta}(\sigma_p)$ in \Cref{eq:cpab_ditask}. Our choice of CPAB transformations implements this with only $\gN_\gP \leq 128$ parameters per weight matrix, compared to the $\gO(r(c_1 + c_2))$ parameters required by low-rank adaptation methods. Our experiments in \Cref{sec:exp} demonstrate that preserving feature hierarchy through diffeomorphic transformations enables effective multi-task generalization while maintaining parameter efficiency.
