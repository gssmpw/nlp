
\section{Conclusions}

When developers have created a test scenario for a unit test they may
need help to select appropriate assertions to validate the resulting
program behaviour. One approach proposed in the literature is to
predict likely assertions using deep learning methods. While prior
results were already promising, open questions remained regarding the
influence of identifier abstraction, the context to include, the
benefits of using large pre-trained models of code, and the
effectiveness of assertions predicted for developer written tests at
revealing faults. To answer these questions, we introduce \assertfive,
a new model based on the pre-trained \codetfive model, and empirically
study assertion generation. In our experiments the \assertfive model
clearly outperforms prior models, and benefits from token abstraction
as well as additional context in the form of the method under test or
pre-existing assertions.

Our study also revealed several limitations adherent to deep
learning-based assertion generation techniques. In particular, even
though standard machine learning metrics suggest the predicted
assertions are accurate, they often nevertheless result in
uncompilable test code, or assert incorrect behaviour. While we
assumed a regression testing scenario in which assertions failing on
the code for which they are generated are problematic, there may be
potential for future research on using predicted assertions to find
faults already in the code.

The results of our study also confirm the importance of the inclusion
of a focal method in the context. This is an aspect that distinguishes
assertion prediction from related techniques that aim to predict
entire test cases: When the aim is to generate new tests, for example
using an \llm, then the user specifies the target method to be tested.
When adding assertions to existing test code, the focal method needs
to be determined automatically. Our experiments suggest that basic
heuristics are insufficient in practice, reinforcing the need for
research on focal method detection~\cite{Parizi2014,White2022,He2024}.




We provide implementations, training data and checkpoints for the
models, the raw data obtained during inference, and the evaluation
scripts at \url{https://doi.org/10.5281/zenodo.14703162}.

