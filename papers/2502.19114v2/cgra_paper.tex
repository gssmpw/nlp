\documentclass[conference,hidelinks]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{fontawesome5}

\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{hhline}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\usepackage{balance}

\usepackage[table,dvipsnames]{xcolor}
\usepackage[shrink=25]{microtype}
\usepackage{tikz}
\usetikzlibrary[shadows]
\usepackage{ifthen}
\usetikzlibrary{calc}
\usetikzlibrary{arrows.meta}
\usetikzlibrary{external}
\usetikzlibrary{positioning,fit,calc}
\usepackage[mathscr]{eucal}
\usepackage{dsfont}
\usepackage{scalefnt}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{listings}
\input{code_style.tex}
\lstset{basicstyle=\ttfamily}
\usepackage{multirow}
\usepackage{pgfplotstable}
\usepackage{pgfplots}
\usepackage{marvosym}
\usepackage[english]{babel}
\usepackage{upgreek}
\usepackage{makecell}
\usepackage{framed}
\usepackage{fp}
\usepackage{setspace}
\usepackage{pifont}
\usepackage[nolist]{acronym}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\usepackage[hidelinks]{hyperref}
\usepackage[backend=biber, style=numeric, hyperref, maxnames=3, minnames=1, giveninits=true, maxcitenames=2, mincitenames=1,bibencoding=utf8, isbn=true,sorting=none]{biblatex}
\usepackage{cleveref}
\addbibresource{new_references.bib}

\usepackage{siunitx}
\sisetup{detect-all}

\usepackage{xspace}
\usepackage{xargs}
\usepackage{todonotes}
\marginparsep 0.5em
\marginparwidth 3.5pc
\newcommand{\fh}[1]{\todo[color=ProcessBlue!40,size=\scriptsize]{\textsf{#1}}}% Frank
\newcommand{\ch}[1]{\todo[color=ProcessBlue!40,size=\scriptsize]{\textsf{#1}}}% Frank


\usepackage{csquotes}

\newcommand{\II}{\textit{II}\xspace}

\DeclareSIUnit\flops{FLOPS}
\DeclareSIUnit\flop{FLOP}

\DeclareSIUnit\ops{OPS}
\DeclareSIUnit\op{OP}

\pgfplotsset{compat=1.18}

\graphicspath{{figures/}}

\input{tcpa_formulas.tex}

\DeclareSIUnit\flops{FLOPS}
\DeclareSIUnit\flop{FLOP}

\DeclareSIUnit\ops{OPS}
\DeclareSIUnit\op{OP}

\newcommand{\lineSegmentConnectPass}{%
  \begin{tikzpicture}
    \draw (0,0) -- (0,-8pt);
    \draw (0,-4pt) -- (8pt, -4pt);
  \end{tikzpicture}
}
\newcommand{\lineSegmentConnect}{%
  \begin{tikzpicture}
    \draw (0,0) -- (0,-4pt);
    \draw (0,-4pt) -- (8pt, -4pt);
  \end{tikzpicture}
}
\newcommand{\lineSegmentPass}{%
  \begin{tikzpicture}
    \draw (0,0) -- (0,-8pt);
  \end{tikzpicture}
}

\begin{document}

\newcommand{\tikzpic}[3]{
    \tikzset{pics/#1/.style n args={#2}{code={#3}}}
}
\input{figure_magic.tex}
\newcommand{\eg}{e.\,g.}
\newcommand{\ie}{i.\,e.}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=1pt] (char) {#1};}}
\definecolor{cmark_green}{HTML}{00A64F}
\newcommand{\cmark}{\textcolor{cmark_green}{\ding{51}}}
\definecolor{xmark_red}{HTML}{ED1B23}
\newcommand{\xmark}{\textcolor{xmark_red}{\ding{55}}}
\definecolor{mmark_yellow}{HTML}{ED7A1B}
\newcommand{\mmark}{\textcolor{mmark_yellow}{\ding{51}}}

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\newcommand{\secRef}[1]{Section~\ref{#1}}
\newcommand{\codeRef}[1]{Listing~\ref{#1}}
\newcommand{\figRef}[1]{Figure~\ref{#1}}
\newcommand{\tableRef}[1]{Table~\ref{#1}}
\setlength\arraycolsep{1pt}

\newcommand{\factor}[1]{\qty{#1}{\times}}



\title{Evaluation of CGRA Toolchains}
\author{
	\IEEEauthorblockN{Dominik Walter, Marita Halm, Daniel Seidel, Indrayudh Ghosh, \\Christian Heidorn, Frank Hannig, J\"urgen Teich}
	\IEEEauthorblockA{cs12-alpaca@fau.de\\
	Hardware/Software Co-Design, Department of Computer Science\\
	Friedrich-Alexander-Universit\"at Erlangen-N\"urnberg (FAU), Germany
			}
}

\maketitle

\begin{abstract}
    Increasing demands for computing power also propel the need for energy-efficient SoC accelerator architectures.
    One class for such accelerators are so-called processor arrays, which typically integrate a two-dimensional mesh of interconnected processing elements~(PEs).
    Such arrays are specifically designed to accelerate the execution of multidimensional nested loops by exploiting the intrinsic parallelism of such loops.
    Coarse-grained reconfigurable arrays~(CGRAs) belong to this class of accelerator architectures.
    In this work, we analyze four toolchains for mapping loop programs onto CGRAs and compare the resulting mappings wrt. performance, \ie, latency.
    While most toolchains succeed in simpler kernels like general matrix multiplication, some struggle to find valid mappings for more complex loops like a triangular solver.
    Furthermore, we observe that the considered CGRA mappers generally tend to underutilize the available PEs.
\end{abstract}

% \begin{IEEEkeywords}
%     Loop accelerators, Coarse-grained reconfigurable arrays
% \end{IEEEkeywords}

\section{Introduction}
    Coarse-grained reconfigurable arrays~(CGRAs) were first presented in the 1990s, and since then, many CGRA architectures have been developed by both industry and academia, see, \eg,~\cite{26_CGRA_Overview,24_CGRA_Taxonomy}.
    In this study, we evaluate and compare the mapping quality of four publicly available CGRA toolchains in terms of performance, \ie, the achieved latency on a set of selected loop benchmarks.
    More specifically, we introduce the fundamentals of CGRAs and mapping of data flow graphs in Sections~\ref{sec:cgra} and \ref{sec:cgra:mapping}, followed by discussing available toolchains in \secRef{sec:tools}.
    Afterward, we evaluate the mapping tolls in terms of achieved latency in \secRef{sec:evaluation} and summarize our study in \secRef{sec:summary}.
%
\section{Coarse-Grained Reconfigurable Arrays}
\label{sec:cgra}
    According to~\cite{19_CGRA}, a typical CGRA architecture consists of a network of interconnected PEs arranged in a two-dimensional grid, as shown in Figure \ref{fig:mainFigCgra}~(right).
    To keep the hardware simple and modular, each PE contains one functional unit~(FU), a set of local registers potentially arranged in a register file, a crossbar switch, and an instruction memory.
    The FU usually supports different arithmetic, logic, and memory operations at the word level.
    The local registers are used as temporary data storage for intermediate results.
    The crossbar connects the PE with its adjacent neighbors, enabling data transfer between neighboring PEs in a single cycle.
    The operation performed by the FU and the routing for the crossbar can be configured at the granularity of clock cycles.
    The instruction memory can store a sequence of predetermined per-cycle configurations to execute one loop iteration.
    Most CGRAs also support conditional execution by predication, \ie, the execution of some instructions is masked by a predication bit that was set by a conditional instruction.
    According to \figRef{fig:mainFigCgra}, typically a subset of PEs have a direct access to an accompanying on-chip scratchpad memory (SPM) that can buffer input and output locally.
    Moreover, because only neighboring PEs can read or write data within one clock cycle, transferring data to a PE further away usually requires a propagation taking multiple cycles, while the intermediate PEs are then occupied for communication.
    HyCUBE~\cite{2_HyCUBE,WangKMMP19} alleviates these issues by a reconfigurable interconnect with single-cycle multi-hop connections.%, \ie, PEs further away can communicate within a single cycle.

\section{Data Flow Graph Mapping}
\label{sec:cgra:mapping}
        CGRAs are designed to accelerate nested loops.
        Common to mapping tools for CGRAs is a loop representation in the form of a data flow graph (DFG) that is extracted from a given C/C++ program.
        The DFG is then statically mapped and scheduled on the PEs, aiming to achieve the lowest possible \emph{initiation interval}~\II, such that each node is repeatedly executed by the same PE every \II cycles.
        Consider \figRef{fig:mainFigCgra}.
        It shows a simplified but representative DFG of a typical 3-dimensional loop nest for computing a matrix-matrix multiplication.
        Each node denotes one operation, and the edges show the dependencies between the operations.
        %
        For the execution of each loop iteration $(i, j, k)$, four types of computations are involved:
        {(a)} Determination of the current loop indices---the corresponding operations are shown in \figRef{fig:mainFigCgra} on the left.
        Each loop index computation requires three operations, \eg, to compute the innermost loop (index $i$), a \texttt{Sel}, \texttt{Add}, and \texttt{Cmp} operation is needed.
        \texttt{Sel} is a multiplex operation that uses the result of the \texttt{Cmp} instruction to either forward the output of the \texttt{Add} operation or zero.
        The \texttt{Cmp} compares the result of the \texttt{Add} operation, which increments the current loop index, against a predefined constant, here, the loop bound.
        Note that the data dependencies towards the \texttt{Sel} operations are inter-iteration dependencies.
        This effectively implements a cyclic accumulator.
        Furthermore, the result of the \texttt{Cmp} operation can also be used as an addend for the \texttt{Add} operation of the next loop index.
        Therefore, the second level (index $j$) is only incremented once the first one reaches its loop bound, implementing a two-dimensional loop counter.
        This can be repeated for a third outer dimension (index $k$) as shown in \figRef{fig:mainFigCgra}.
        {(b)} Then, once the loop indices have been properly determined for the current iteration, the addresses of the matrix elements that are to be accessed in this iteration must be computed.
        This is done by multiplying the loop indices with fixed strides and adding the results together.
        {(c)} Afterward, the computed addresses are used to load the inputs and store the output~(see the memory access section in \figRef{fig:mainFigCgra}.
        A restriction here is that in contrast to the other operations, the corresponding \texttt{Load} and \texttt{Store} operations cannot be executed on all PEs, but only on those PEs that have access to the SPM, which are, as shown in \figRef{fig:mainFigCgra}, only the border PEs.
        {(d)} Only then can the \texttt{Mul} and \texttt{Add} operations, forming the only computational part of the loop nest, \ie, one partial product, be computed before the result is written back by a \texttt{Store} operation.
        Note also that the DFG contains multiple performance-constraining cycles, \eg, \texttt{Sel}$\,\to\,$\texttt{Add}$\,\to\,$\texttt{Cmp}$\,\to\,$\texttt{Sel}, inside the indices computation.
        As a consequence, the \texttt{Sel} operation of the next iteration cannot be started before the \texttt{Cmp} and \texttt{Add} operations of the previous iteration are completed.
        Thus, the cycle length determines a minimal possible \II, called the \emph{recurrence minimum initiation interval}~(RecMII).
        Also, the minimal possible \II may be further limited by a \emph{resource minimum initiation interval}~(ResMII).
        For example, given a CGRA with 9~PEs, the actual minimal possible \II is 3, because with $\II = 2$, each iteration would only allow for $9 \cdot 2 = 18$ nodes to be scheduled.

        \begin{figure*}
            \centering
            \begin{minipage}[c]{0.5\textwidth}%
            \resizebox{1.0\textwidth}{!}{
                \begin{tikzpicture}
                    \definecolor{darkPurple}{RGB}{96, 25, 134}
                    \definecolor{darkBlue}{RGB}{0, 59, 111}
                    \definecolor{darkBrown}{RGB}{102, 51, 0}
                    \definecolor{darkGray}{RGB}{71, 79, 82}
                    \definecolor{darkRed}{RGB}{177, 0, 18}
                    \definecolor{darkGreen}{RGB}{0, 147, 146}
                    \definecolor{darkOrange}{RGB}{111, 59, 0}

                    \pic at (0cm, 0cm) {nodeGrid={1.25cm}{1.05cm}{0.4cm}{
                        {{Sel/s0/white/darkBlue},{},{},{},{Mul/ls0/white/darkOrange},{},{},{Load/load0/white/darkPurple},{},{},{}},
                        {{},{Add/a0/white/darkBlue},{},{},{},{Add/addr0/white/darkOrange},{},{},{},{},{Add/mac0/white/darkRed}},
                        {{Cmp/c0/white/darkBlue},{},{Sel/s1/white/darkBlue},{},{Mul/ls1/white/darkOrange},{},{},{Store/store/white/darkPurple},{},{},{}},
                        {{},{Add/a1/white/darkBlue},{},{},{},{Add/addr1/white/darkOrange},{},{Load/load1/white/darkPurple},{},{},{}},
                        {{},{},{Cmp/c1/white/darkBlue},{},{Mul/ls2/white/darkOrange},{},{},{},{},{},{Mul/mac1/white/darkRed}},
                        {{},{Add/a2/white/darkBlue},{},{},{},{Add/addr2/white/darkOrange}, {}, {Load/load2/white/darkPurple},{},{},{}},
                        {{Cmp/c2/white/darkBlue},{},{Sel/s2/white/darkBlue},{},{Mul/ls3/white/darkOrange},{},{},{},{},{},{}}%
                    }{0.07cm}{
                        {s0/a0/darkBlue//-22.5/115.5/1/{}},
                        {a0/s0/darkBlue//160.5/-67.5/1/{dashed}},
                        {a0/c0/darkBlue//{}},
                        {c0/s0/darkBlue///{dashed}},
                        {s1/a1/darkBlue//-22.5-90/115.5-90/1/{}},
                        {a1/s1/darkBlue//160.5-90/-67.5-90/1/{dashed}},
                        {a1/c1/darkBlue//{}},
                        {c1/s1/darkBlue///{dashed}},
                        {a2/s2/darkBlue//-22.5/115.5/1/{dashed}},
                        {s2/a2/darkBlue//160.5/-67.5/1/{}},
                        {a2/c2/darkBlue//{}},
                        {c2/s2/darkBlue///{dashed}},
                        {c0/a1/darkBlue//{}},
                        {c1/a2/darkBlue//{}},
                        {s0/ls0/darkBlue/i//{}},
                        {s1/ls1/darkBlue/j//{}},
                        {s2/ls2/darkBlue/k//{}},
                        {s2/ls3/darkBlue/k//{}},
                        {ls0/addr0/darkOrange///{}},
                        {ls0/addr1/darkOrange///{}},
                        {ls1/addr0/darkOrange///{}},
                        {ls1/addr2/darkOrange///{}},
                        {ls2/addr1/darkOrange///{}},
                        {ls3/addr2/darkOrange///{}},
                        {addr0/load0/darkOrange///{}},
                        {addr0/store/darkOrange///{}},
                        {addr1/load1/darkOrange///{}},
                        {addr2/load2/darkOrange///{}},
                        {load0/mac0/darkPurple/{C[i, j]}//{}},
                        {load1/mac1/darkPurple/{A[i, k]}//{}},
                        {load2/mac1/darkPurple/{B[k, j]}//{}},
                        {mac0/store/darkRed/{C[i, j]}//{}},
                        {mac1/mac0/darkRed///{}},
                    }{%
                        {4/0/4/8/{dashed}},
                        {7/0/7/8/{dashed}},
                        {10/0/10/8/{dashed}},
                    }{%
                        {0/7/4/8/{Indices\\ Computation}/},
                        {4/7/7/8/{Address\\ Computation}/},
                        {7/7/10/8/{Memory\\ Access}/},
                        {9.5/7/12.5/8/{MAC\\ Operations}/},
                    }};
                \end{tikzpicture}
            }%
            \end{minipage}%
            \begin{minipage}[c]{0.5\textwidth}%
            \resizebox{1.0\textwidth}{!}{
                \begin{tikzpicture}
                    \definecolor{darkPurple}{RGB}{96, 25, 134}
                    \definecolor{darkBlue}{RGB}{0, 59, 111}
                    \definecolor{darkBrown}{RGB}{102, 51, 0}
                    \definecolor{darkGray}{RGB}{71, 79, 82}
                    \definecolor{darkRed}{RGB}{177, 0, 18}
                    \definecolor{darkGreen}{RGB}{0, 147, 146}
                    \definecolor{darkOrange}{RGB}{111, 59, 0}

                    \pic at (0cm, -0.5cm-5*2.00cm) {cgra={4}{4}{1.5cm}{0.5cm}};
                    \pic at (1.5cm, -0.5cm) {nodeGrid={0.5cm}{0.4cm}{0.3cm}{
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        %
                        {{},{L/load0/white/darkPurple},{},{},{},{},{},{},{},{S/s0/white/darkBlue},{},{A/a0/white/darkBlue}},
                        {{},{},{},{},{},{},{},{},{},{},{},{}},
                        {{},{S/store/white/darkPurple},{},{},{},{A/addr0/white/darkOrange},{},{},{},{},{C/c0/white/darkBlue},{},{}},
                        %
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        %
                        {{},{},{},{A/mac0/white/darkRed},{},{},{},{M/ls0/white/darkOrange},{},{S/s1/white/darkBlue},{},{A/a1/white/darkBlue}},
                        {{},{},{},{},{},{},{},{M/ls1/white/darkOrange},{},{},{}},
                        {{},{},{},{M/mac1/white/darkRed},{},{},{},{M/ls2/white/darkOrange},{},{},{C/c1/white/darkBlue},{}},
                        %
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        %
                        {{},{L/load1/white/darkPurple},{},{},{},{A/addr1/white/darkOrange},{},{},{},{S/s2/white/darkBlue},{},{A/a2/white/darkBlue}},
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        {{},{L/load2/white/darkPurple},{},{},{},{A/addr2/white/darkOrange},{},{M/ls3/white/darkOrange},{},{},{C/c2/white/darkBlue},{}},
                        %
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        %
                        {{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}},
                        {{},{},{},{},{},{},{},{},{},{},{}},
                        {{},{},{},{},{},{},{},{},{},{},{},{},{},{}}%
                    }{0.05cm}{
                        {s0/a0/darkBlue//45/135/1/{}},
                        {a0/s0/darkBlue//225/-45/1/{dashed}},
                        {a0/c0/darkBlue//{}},
                        {c0/s0/darkBlue///{dashed}},
                        {s1/a1/darkBlue//45/135/1/{}},
                        {a1/s1/darkBlue//225/-45/1/{dashed}},
                        {a1/c1/darkBlue//{}},
                        {c1/s1/darkBlue///{dashed}},
                        {s2/a2/darkBlue//45/135/1/{}},
                        {a2/s2/darkBlue//225/-45/1/{dashed}},
                        {a2/c2/darkBlue//{}},
                        {c2/s2/darkBlue///{dashed}},
                        {c0/a1/darkBlue//{}},
                        {c1/a2/darkBlue//{}},
                        {s0/ls0/darkBlue///{}},
                        {s1/ls1/darkBlue///{}},
                        {s2/ls2/darkBlue///{}},
                        {s2/ls3/darkBlue///{}},
                        {ls0/addr0/darkOrange///{}},
                        {ls0/addr1/darkOrange///{}},
                        {ls1/addr0/darkOrange///{}},
                        {ls1/addr2/darkOrange///{}},
                        {ls2/addr1/darkOrange///{}},
                        {ls3/addr2/darkOrange///{}},
                        {addr0/load0/darkOrange///{}},
                        {addr0/store/darkOrange///{}},
                        {addr1/load1/darkOrange///{}},
                        {addr2/load2/darkOrange///{}},
                        {load0/mac0/darkPurple///{}},
                        {load1/mac1/darkPurple///{}},
                        {load2/mac1/darkPurple///{}},
                        {mac0/store/darkRed///{}},
                        {mac1/mac0/darkRed///{}},
                    }{}{}};
                \end{tikzpicture}
            }%
            \end{minipage}
            \caption{%
                A simplified data flow graph~(DFG) of a matrix multiplication~(shown left) is mapped onto a 4$\times 4$ CGRA architecture~(shown right).
            }
            \label{fig:mainFigCgra}
            \vspace{-.7em}
        \end{figure*}
\section{Mapping Tools}
\label{sec:tools}
        Many different CGRA architectures have been proposed over the years, and some related toolchains are also publicly available.
        This study selects four representative toolchains for analysis, briefly introduced in the following.
        \subsubsection{CGRA-Flow} \label{sec:cgra:tools:cgraflow}
            CGRA-Flow~\cite{4_OpenCGRA}, also known as Open\-CGRA, is a toolchain for the compilation, exploration, synthesis, and development of CGRA architectures~\cite{4_OpenCGRA}.
            It is open-source and available on GitHub\footnote{\url{https://github.com/tancheng/CGRA-Flow}}.
            CGRA-Flow has a GUI for visualizing input, output, and intermediate results.
            As input, users describe or select a loop program written in C/C++.
            CGRA-Flow supports up to two innermost loop nests with control flow in the loop body or up to three innermost loop nests without control flow in the loop body onto the user-specified CGRA.
            Within the GUI, users can configure a CGRA architecture instance by selecting the number of PEs, the number of operations mapped to one PE, the size of the memory buffer, the operation types that the PE can execute, the connections to neighboring PEs, and the disablement of entire PEs.
            Compiling the user-given loop and generating the corresponding DFG is performed using LLVM's~\cite{LLVM} intermediate representation to extract the operations and the dependency between operations.
            The user can select between two mapping algorithms, called \emph{exhaustive} and \emph{heuristic}.
            While the exhaustive algorithm checks all possible mappings for one given initiation interval \II, the heuristic approach starts with a minimal initiation interval and iteratively increments it until a mapping with the lowest cost (based on a heuristic function) for the current initiation interval \II has been found.
            Both the generated DFG and the resulting mapping are visualized in the GUI.
            After mapping, the user can generate Verilog via PyMTL to run various tests on the architecture~\cite{4_OpenCGRA} and to estimate the area and power of PEs and on-chip memory.
        \subsubsection{Morpher}\label{sec:cgra:tools:morpher}
            Morpher is an integrated compilation and simulation toolchain~\cite{6_MorpherWOSET} available on GitHub\footnote{\url{https://github.com/ecolab-nus/morpher}}.
            As input, the user provides a description of the target CGRA architecture and a loop program written in C/C++ that should be mapped onto the target architecture.
            The DFG generator begins by extracting the innermost loop of the program and generating the corresponding DFG using LLVM~\cite{LLVM}.
            It offers three schemes for handling loop control flow in a CGRA, influencing DFG generation: \emph{partial predication}, \emph{full predication}, and \emph{dual-issue}~\cite{6_MorpherWOSET}, described in detail in~\cite{8_Branch_aware_loop_mapping}.
            Partial predication maps the if-part and else-part operations to different PEs, adding a \emph{select} node if both parts update the same variable.
            Full predication schedules both parts using the same variable to the same PE, with one operation executed per cycle, avoiding the need for a select node.
            Dual-issue merges both operations into one DFG node, scheduling them simultaneously but only executing one at run-time.
            In this work, we only consider partial predication because it was the most reliably supported mapping.
            The resulting DFG and data layout for input/output variables on the SPM are then used by the CGRA mapper to find a valid mapping using three algorithms: PathFinder~\cite{McMurchieE95}, Simulated Annealing~\cite{32_SA}, and LISA~\cite{LiMitra2022HPCA}.
            The mapping can then be verified by simulating the execution using a simulator that models a CGRA with FUs, registers, multiplexers, and memory banks~\cite{6_MorpherWOSET}, supporting variations of HyCUBE.
            Here, the test data is automatically created by Morpher’s data generator~\cite{3_MorpherCODAI}.
            After simulation, memory values are compared to the test data.
        \subsubsection{Pillars}\label{sec:cgra:tools:pillars}
            Pillars is an open-source CGRA design toolchain based on Scala and Chisel~\cite{guo-pillars-woset2020}.
            The toolchain is publicly available on GitHub\footnote{\url{https://github.com/pku-dasys/pillars}}.
            It has been designed as a tool for conducting design space explorations and further hardware optimizations of CGRAs.
            The user must provide a Scala-based architecture description of the CGRA, which is then systematically converted by Chisel into a synthesizable Verilog description of the CGRA.
            The design can be synthesized for FPGAs to determine the performance, area and power consumption of the CGRA.
            In contrast to the other toolchains, the Pillars toolchain does not support any automated DFG generation from source code.
            Thus, the user must already provide the application as a DFG.
            Pillars offers two mapping algorithms, an ILP mapper and a Heuristic Search mapper.
            The ILP mapper is slow but succeeds more frequently than the Heuristic Search mapper.
            Therefore, the ILP mapper is used for all loop kernels in this work.
            The resulting mapping can then be either simulated on the RTL by Verilator, or used to determine the performance, area and power estimate for the execution on the actual hardware.
        \subsubsection{CGRA-ME}\label{sec:cgra:tools:cgrame}
            CGRA-ME is an open-source toolchain for modeling and exploration of CGRAs~\cite{RaghebWWBRYA24}.
            It is currently available in its second version~(first release~\cite{17_CGRA-ME}) and supports end-to-end CGRA compilation and simulation with RTL code generation.
            The toolchain is open-source and can be downloaded from the project's website\footnote{\url{https://cgra-me.ece.utoronto.ca/download/}}.
            It uses LLVM to extract a DFG from a given C/C++ source code.
            However, it does not support any nested loops as inputs, but although it supports partial predication, no support for conditional code was available.
            CGRA-ME maps the extracted DFG onto a target CGRA, which is specified by a provided architecture description.
            It offers to choose between three different mapping approaches.
            First, CGRA-ME supports an ILP-based mapping that finds an optimal mapping but is very slow.
            Additionally, a heuristic approach reduces the search space of the ILP.
            Finally, CGRA-ME also includes a clustered mapper that incorporates a simulated-annealing approach~\cite{32_SA} utilizing both QuickRoute~\cite{LiE04} and PathFinder~\cite{McMurchieE95}.
            After the mapping, CGRA-ME produces a Verilog description of the given architecture and a bitstream containing the configuration of the CGRA.
            However, simulation without additional external toolchains is not available.
\section{Comparative Evaluation}
\label{sec:evaluation}
    \input{figures/quant_figs.tex}
    In this section, we evaluate the mapping quality each of the discussed mapping tools achieved.
    For evaluation, we picked five common loop benchmarks (GEMM, ATAX, GESUMMV, MVT, and TRISOLV) from the Polybench suite~\cite{polybench}.
    Each benchmark is a multidimensional loop nest representing a typical workload in the linear algebra domain.
    We observed that several CGRA toolchains do not accept as input a multidimensional loop nest directly, but require flattening, \ie, the multidimensional loop nest is reduced into a single loop by unfolding the iterations of the outer loops.
    Furthermore, no considered CGRA toolchain unrolls a given loop automatically; thus, this transformation was done manually.
    Then, we mapped each benchmark kernel using the four selected CGRA toolchains: CGRA-Flow~\cite{4_OpenCGRA}, Morpher~\cite{6_MorpherWOSET}, CGRA-ME~\cite{RaghebWWBRYA24}, and Pillars~\cite{guo-pillars-woset2020}.
    \tableRef{table:tcpa_cgra_mapping} summarizes the mapping results.
    Whenever no mapping could be found, the entry is colored red, while an orange row indicates a successful mapping of only the innermost loop.
%     CGRA-Flow is the only one among the CGRA tools that directly supports multidimensional loops.
    CGRA-Flow is the only CGRA tool that directly supports multidimensional loops.
    However, we can observe that flattening should still be applied in all but one benchmark as it favorably reduces the achievable initiation interval.
    Only in the case of TRISOLV, the flattened benchmark could not be mapped by CGRA-Flow.
    In this evaluation, we used two different target architectures for Morpher.
    A classical CGRA without multi-hop connections and HyCube, for which Morpher finds consistently better mappings.
    %
    We targeted an ADRES-like~\cite{MeiVVML03} architecture for Pillars, and since Pillars does not come with its own DFG generator, we utilized the DFG from CGRA-ME.
    However, it could only find a valid mapping for the GEMM kernel, failing for all others.
    %
    Without any direct support for multidimensional loops, the loop must be flattened into a single loop.
    This requires explicitly inserting conditional statements inside the loop body that update the outer loop indices.
    Moreover, CGRA-ME currently does not support any predication; hence, it only maps the innermost loop.
    %
    But this simplification allows this tool to achieve the lowest initiation interval \II among the CGRA toolchains.
    However, as discussed in \secRef{sec:cgra:mapping}, the generation of the loop indices should introduce a RecMII of 3.
    This does not apply to CGRA-ME because it only maps the innermost loop and omits any loop-bound checks.
    Besides the achieved initiation interval, the table also shows the number of PEs that were not utilized and the maximum number of operations mapped to a PE.
%     Of the 16 PEs available, it was rarely possible to use all of them, while the number of operations per PE indicates that even the used PEs are not fully utilized, \eg, with $\II=10$ and a maximum of 4 operations per PE, the most active PE will only execute 4 operations within a window of 10 cycles.
    It was rarely possible to employ all the 16 available PEs.
    Moreover, the number of operations per PE indicates that even the used PEs are underutilized.
    For example, with $\II=10$ and a maximum of 4 operations per PE, the most active PE will only execute 4 operations within 10 cycles.

\section{Summary and Outlook}
\label{sec:summary}
    In this paper, we evaluated and examined several coarse-grained reconfigurable arrays (CGRAs) and related toolchains that directly map operations from a data flow graph (DFG) to processing elements (PEs).
    We mapped four common loop benchmarks using four publicly available CGRA tools and observed that in many resulting mappings, multiple PEs stay inactive, \ie, no operations are mapped to them, while the maximal number of operations mapped on a PE further indicate that those PEs are not fully utilized.
%     Thus, the mapping approach is not able to fully utilize the available array of PEs.
    Thus, these mapping approaches still have headroom to utilize the available array of PEs fully.
    This is likely to be the case because of the limited routing capability of the PEs, which makes it impossible for every PE to execute an operation in every cycle.
    We can also observe that the HyCube architecture, which increases the routing capability by introducing multi-hop connections, consistently outperforms the classic CGRAs with no multi-hop connections.
    Finally, we observed that Morpher beats CGRA-Flow in all but one benchmark.
    Although CGRA-ME shows the lowest \II in all benchmarks, it is important to note that this includes only the innermost loop.
    Pillars, however, fails in almost all benchmarks.
    In further work~\cite{walter2025mappingexecutionnestedloops}, we extend this research to a more comprehensive evaluation of processor arrays, considering both qualitative and quantitative measures.
    This includes not only CGRAs but also another contender for loop acceleration---so-called Tightly-Coupled Processor Arrays~(TCPAs)~\cite{KisslerTeich2006IEEEFPT, HannigReiche2014ACMTECS, TeichWitterauf2022Book}, which differ significantly in their mapping methodology~\cite{TeichT93, WitteraufWHT21}.

\vspace{5pt}
{\small%
\noindent%
\textbf{Acknowledgment:} This work was partly funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) -- Project number 146371743 -- TRR 89: Invasive Computing.%
}


\renewcommand*{\bibfont}{\scalefont{0.925}}
\footnotesize
\printbibliography

\end{document}
