\section{Dataset Curation}
\label{sec:data-curation}


\begin{figure*}[t]
\centering
    \includegraphics[width=0.95\linewidth]{figures/math-perturb-annotation.drawio_.pdf}
\caption{Illustration of the annotation process for \SAME and \HARD. }
\label{fig:annotation}
\end{figure*}


\textbf{Origin of the Dataset.} 
We choose the popular MATH benchmark~\citep{hendrycksmath2021}, which contains challenging mathematical reasoning problems sourced from American high school mathematics competitions such as the AMC 10, AMC 12, and AIME. Each problem belongs to one of the 7 subjects: Prealgebra, Algebra, Number Theory, Counting and Probability, Geometry, Intermediate Algebra, and Precalculus. Besides, each problem is labeled with a difficulty level of 1 (easiest) to 5 (hardest). The problems may contain LaTeX and Asymptote graphics language for describing mathematical concepts and geometric figures.

As the state-of-the-art reasoning models can already solve MATH problems with overall accuracies higher than 90\%~\citep{openaio1, team2024gemini, deepseekai2025deepseekr1incentivizingreasoningcapability}, we opt to focus only on the hardest level-5 problems in our work, and create new benchmarks from these level-5 problems.
We use level-5 problems from both the \texttt{train} split and the \texttt{test} split as the seed problems, so we are able to investigate whether language models behave differently on the two splits. 



\textbf{Annotation Criterion.}
For each problem, we modify the problem to create two variations:

(1) for \SAME, we make \textbf{simple perturbations}, i.e., non-essential modifications to the problem, ensuring that the modified problem can be solved using \textit{the same method} as the original problem. 

(2) for \HARD, we make \textbf{hard perturbations}, i.e., small but fundamental modifications to the problem so that the modified problem \emph{cannot} be solved using \textit{the same method} as the original problem. Instead, it requires deeper math understanding and harder problem-solving skills.

Besides, we ensure the following two additional requirements:

\begin{itemize}[itemsep=1pt, parsep=1pt, topsep=1pt]
\item \textbf{Minimal Edits:} To test the \after{generalization} of the reasoning models and elicit potential memorization behaviors, we ask the annotators to make as minimal modifications as possible. Therefore, the modified problems stay close to the original problems in the text form.  

\item \textbf{Changed Answers:} For both of the modifications, we guarantee that the answers to the modified problems are different from the original answer. Therefore, models cannot cheat by pattern recognition and outputting memorized solutions. %
\end{itemize}




\textbf{Quality Control.}
We recruited 12 annotators (PhD students) with strong mathematical backgrounds for the annotation task. All the annotators hold a bachelor's degree in mathematics, have done researches in theoretical machine learning, and/or competed in mathematical competitions during high school.

To ensure the quality of the benchmark, all the annotators are required to double-check their annotations. Each modified problem is also cross-validated by an independent annotator to make sure the answer is correct.

Additionally, we manually went through all the problems where the o1-mini's answer and the annotated answer differ and confirmed that the annotated answers are correct. %



\textbf{Benchmark Overview and Statistics.}

After removing several annotations that failed the quality checks, we obtained 279 pairs of modifications, where 164 examples are from \texttt{train} split and 115 examples are from \texttt{test} split. The numbers of problems in each 
 of the 7 subjects are listed in \cref{tab:stat}. \cref{fig:hard_perturb} shows one example of our benchmark.

To quantify how similar the original problem and the modified problem are,  first, we calculate the edit distance between the modified problem and the original problem, normalized by the length of the original problem. Besides, we compute the cosine similarities between the embeddings of the two problems, where we use OpenAI's \texttt{text-embedding-3-large} embedding model. The distributions of the normalized edit distance and the cosine similarities are shown in \cref{fig:edit_distance_cos_sim}. 


    \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.48\linewidth]{figures/edit_distance_hist_SAME.pdf}
        \includegraphics[width=0.48\linewidth]{figures/edit_distance_hist_HARD.pdf}
        \includegraphics[width=0.48\linewidth]{figures/cos_sim_SAME.pdf}
        \includegraphics[width=0.48\linewidth]{figures/cos_sim_HARD.pdf}
        \caption{The distributions of edit distances and cosine similarities of embeddings between the perturbed problems and the original problems. The edit distances are normalized by the lengths of the original problems. The embedding model is OpenAI's \texttt{text-embedding-3-large}. 
        }
        \label{fig:edit_distance_cos_sim}
    \end{figure}

We also calculate the Mean Reciprocal Ranks (MRRs) when using the perturbed problem as the query to retrieve the corresponding original problem from the set of all 279 original problems, with the cosine similarities of embeddings being the ranking method. The MRRs of the \SAME problems and \HARD problems are 0.995 and 0.986, respectively, indicating that the corresponding original problem and solution are likely to be retrieved using typical semantic-based retrieval methods.















\textbf{Common Strategies for Perturbations.}




For \SAME, most of the problems are modified numerically without making the problems fundamentally different. Our annotators have checked these numerical modifications are non-essential to the problems, so the modified problems can be solved with the same reasoning patterns. 
Besides, our annotators also adopt other types of changes. For example, asking for a different but related quantity, adding/removing non-essential constraints, and changing a mathematical concept to its contrasting counterpart.






For \HARD, the modification strategies are more diverse and problem-specific. A general strategy is to increase the complexity of the mathematical objects involved. For example, raising the degrees of polynomials will make them harder to solve or factorize. Altering key numbers to large values can make brute-force solutions infeasible. Instead, solving the problem requires deriving general formulas or applying deeper theorems rather than relying on computational shortcuts. Other common strategies include relaxing constraints to cover more general cases, changing essential conditions so the original simplifying properties (e.g. symmetry, reducibility, linearity) no longer hold.











