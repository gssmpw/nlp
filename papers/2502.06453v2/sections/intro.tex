\section{Introduction}

    \begin{figure*}[htbp]
    \centering
        \vspace{-1em}
            \begin{minipage}[c]{0.31\textwidth}  
                \centering
                 \begin{minipage}[b]{\textwidth}  
                    \centering
                        {\textcolor{gray}{\textbf{Overview of MATH-Perturb Benchmark}}}
                    \vspace{0.8em}
                \end{minipage}
                 \begin{minipage}[b]{0.9\textwidth}  
                     \centering
                     \includegraphics[width=\textwidth]{figures/subject_pie_chart.pdf}    
                     \vspace{0.05em}
                 \end{minipage}
                \begin{minipage}[b]{\textwidth}  
                    \centering
                    \resizebox{0.95\textwidth}{!}{
                    \begin{tabular}{l|c|c}
                        \toprule
                        \textbf{Split} & \textbf{Type} & \textbf{Size}   \\ \midrule
                        \SAME   & Simple Perturbation & 279    \\ \midrule
                        \HARD   & Hard Perturbation& 279   \\ \bottomrule
                    \end{tabular} 
                    }
                \end{minipage}
            \end{minipage}
        \hfill
        \begin{minipage}[c]{0.68\textwidth}  
            \centering
            \includegraphics[width=\textwidth]{figures/2025_math_perturb_fig_.pdf}
        \end{minipage}
        \vspace{-1em}
    \caption{ \textbf{Left:} The overview of MATH-Perturb Benchmark. \textbf{Right:} An example of the original problem, its \textbf{simple} perturbation, its \textbf{hard} perturbation, and the corresponding model responses that \red{overfit} the short-cut solution. The simple perturbation to the problem is non-essential, so the modified problem can be solved using the same method as the original problem. The hard perturbation changes the problem fundamentally and it requires more difficult problem-solving skills. The shortcut solution can solve the original problem and its simple perturbation but fails on the hard perturbation.  } %
    \label{fig:hard_perturb}
    \end{figure*}

Large language models (LLMs) have achieved remarkable progress in solving many previously challenging tasks and demonstrating signs of general intelligence~\citep{bubeck2023sparks}. As LLMs become more intelligent, the research community responds by developing and adopting new benchmarks to guide the development of better  models~\citep{wang2024mmlu, zhou2023instruction, liu2024your, rein2023gpqa, berkeley-function-calling-leaderboard}. 

In mathematical reasoning, the field has progressed from simpler datasets like SVAMP~\citep{patel-etal-2021-nlp} and GSM8K~\citep{cobbe2021gsm8k} to more challenging benchmarks such as MATH~\citep{hendrycksmath2021}, OlympiadBench~\citep{he2024olympiadbench}, and AIME problems. Models continue to strike higher performance on these advanced benchmarks through stronger architectures, novel training approaches, and better training data~\citep{openaio1, yang2024qwen25, shao2024deepseekmath, deepseekai2025deepseekr1incentivizingreasoningcapability}. \nocite{qwq-32b-preview}

Nevertheless, concerns about data contamination and out-of-distribution generalization remain. Model performance can be artificially high if variants of the evaluation set leak into the training datasets or if its distribution is over-represented. In these cases, the model could be merely doing pattern recognition and memorizing the solution steps without understanding the underlying rationale, making it vulnerable to perturbations of the problem formulation~\citep{zhang2024careful, srivastava2024functional}. %



Several works have been proposed to quantify the robustness of reasoning models against such perturbations~\citep{shi2023large, mirzadeh2024gsm, zhang2024careful, srivastava2024functional, gulati2024putnamaxiom, zou2024dynamath}. Notably, \citet{srivastava2024functional} created Functional-MATH by manually rewriting the original problems in the MATH benchmark~\citep{hendrycksmath2021}  into problem templates, where the numerical values in the problem statements and the corresponding answers can be varied automatically to generate infinitely-many versions that use the same math problem-solving skills. They observed performance drops between the modified benchmark and the original benchmark for several state-of-the-art language models, indicating that those models are indeed \textit{biased} towards the original configurations of numerical values due to some form of data contamination. However, most existing work focuses on perturbing non-critical parameters (e.g., numerical values) that do not alter the fundamental reasoning patterns required to solve the problem. We refer to such changes as \textbf{simple perturbations}. While prior studies have shown that LLMs can generalize across a range of problem variants by relying on bag-of-heuristics reasoning~\citep{nikankin2024arithmetic,OthelloGPT}, this form of generalization does not necessarily reflect a true understanding of the underlying principles. As a result, models may still fail when faced with a substantial shift in reasoning patterns.







In this work, we take one step forward beyond simple perturbations. We consider \textbf{hard perturbations}: while at lexical level (e.g. edit distance) the modification is similar to simple perturbations, we ensure to change the problem formulations fundamentally so that the original solution paths are no longer applicable to the perturbed settings; see \cref{fig:hard_perturb} for a comparison between the two types of perturbations. 
A genuinely robust reasoning model that understands the underlying rationales should \textit{not only} solve the modified problems under simple perturbations \textit{but also} be able to judge whether the problem formulations change in a way that fundamentally alters the problems and respond accordingly, instead of applying the learned skills indiscriminately.




As the capabilities of large language models continue to advance and the average-case performance continue to improve, the \after{generalization abilities against} hard perturbations may soon become the primary bottleneck in their real-world usages. Addressing this challenge will be critical for advancing the robustness and reliability of future LLMs.

We summarize our contributions and key findings below:
\begin{itemize}[itemsep=1pt, parsep=1pt, topsep=1pt]
    \item We design and construct \SAME (simple perturbation) and \HARD (hard perturbation), each consisting of 279 perturbed math problems that originate from the level-5 (hardest) problems of the MATH dataset~\citep{hendrycksmath2021}.  The datasets are curated by 12 graduate-level experts with rigorous rubrics and cross-checking workflow for quality control (\cref{sec:data-curation}).
    \item We benchmark the math reasoning abilities of 18 LLMs (\cref{sec:benchmarking}), and show that all the models, including o1-mini and gemini-2.0-flash-thinking, suffer significant performance drops {(10\%-25\%)} on \HARD. This indicates these models are biased towards the original distribution of reasoning patterns and suffer from \textit{out-of-distribution effect} when facing problems with hard perturbations. 
    \item We conduct in-depth failure mode analysis (\cref{sec:failure:mode}) and identify a new form of memorization, where the model memorizes the problem-solving techniques from the training set and blindly applies them without judging whether the modified settings are still suitable.
    \item We investigate the influences of in-context learning (ICL) with the corresponding original unmodified problem and solution (\cref{sec:icl}), and demonstrate that ICL with original example may hurt the model on \HARD, as the models may fail to recognize the subtle differences and get misled by the demonstration.
\end{itemize}





 

    \begin{figure*}[ht]
    \centering
        \includegraphics[width=0.98\linewidth]{figures/performance.pdf}
        \vspace{-5mm}
    \caption{Performance on \SAME, \HARD, and the corresponding \Original problems. We observe performance degradations across all models on \HARD. 
    }
    \label{fig:performance}
    \end{figure*}

