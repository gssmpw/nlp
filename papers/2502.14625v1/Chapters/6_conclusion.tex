\section{Conclusion}

In this paper, we propose a new large-scale dataset consisting of over 13,000 web pages from Russian news sources, which was specifically designed to address the problem of extracting information from multi-record web pages. This dataset is the first dataset in the Russian language for information extraction from multi-record pages task. It is significantly larger than existing datasets, and includes pages with optional and multi-valued atributes. We make it openly available to provide a valuable resource for researchers of extraction methods.

We have applied and validated multi-stage methods for information extraction. In this methods we fine-tuned a state-of-the-art MarkupLM, which was designed to understand and process markup-language-based documents. Our experiments demonstrated the effectiveness of MarkupLM in handling the multi-record pages. So we set a robust base for further advancements in this area. Moreover, our research goes beyond Russian news websites and provides a valuable contribution to development of other forms of semi-structured web content extraction. 

The internet continues to expand and the ability to efficiently process multi-record web pages becomes increasingly vital too. Our research provides as a powerful tool for current applications, as a strong basis for future development.

In future work, we are going to study the extraction of additional attributes from our dataset, such as short\_text, short\_title, author, and time. These attributes, while not the focus of the current article, represent further opportunities to enhance the richness and utility of information extracted from multi-record pages. We are also going to expand our dataset with examples from other languages, for example, English.
