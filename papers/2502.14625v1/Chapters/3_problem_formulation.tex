\section{Problem definition}
Given a set $W$ of n websites. Each website $W_i$, where $1 \leq i \leq$ n, is represented by a certain number of pages $m_i$, a website may consist of just one page, i.e. $m_i = 1$. 
Each page $W_i^j$ on website $W_i$, where $j$ is the page number, with $1 \leq j \leq m_i$, is a multi-record page, meaning it contains $k$ records where $2 \leq k$. 
We defined a record as an entity with a predefined set of characteristics, e.g. in the news domain these characteristics might include date, author, title, tag, etc. So the set of record's characteristics is a vector $H = \{h_0, h_1, ..., h_t\}$, where $t$ the number of characteristics in a given record. It is important to note that a record can have multiple characteristics of the same type, such as multiple tags.

We formulate the task of extracting information from multi-record pages as identifying all vectors $H$ within the given set $W$, with the following constraints:
\begin{enumerate}
  \item The proposed methods must not rely on visual information based on page rendering.
  \item The proposed methods must be applicable to all multi-record pages in the domain, even if the website was not included in the training dataset.
  \item The proposed methods should generalize beyond the news domain to other fields.
\end{enumerate}

The output of each method should be a structured representation of the records for each page, for example in JSON format.
