\section{Related work}

There are several datasets for the task of extracting attributes from web pages with many records. They all have their own unique features, since each was collected to test a specific method of solving this problem. However, there is a certain set of characteristics by which we can compare them:
\begin{itemize}
    \item Number of pages for each subject area
    \item Number of sites for each subject area
    \item Number of records for each subject area
    \item Number of pages in total
    \item Year of dataset release
    \item Language of dataset
\end{itemize}

One of the first datasets was announced in the article ``Simultaneous Record Detection and Attribute Labeling in Web Data Extraction``\cite{zhu_simultaneous_2006} in 2006 and was named LDST -- ListDataSeT. In this dataset, the authors included 771 pages which contained lists of records.

The first large dataset aimed at studying the problem of extracting information from pages with many records was proposed in the paper ``AMBER: Automatic Supervision for Multi-Attribute Extraction``\cite{furche_amber_2012} in 2012. The authors of the article focused on 150 real sites that contained pages with many records. The resulting dataset contained more than 2,000 pages with a total number of records more than 20,000.

In 2020, a team of researchers from Amazon published the article ``PLAtE: A Large-scale Dataset for List Page Web Extraction``\cite{san_plate_2023} in which they presented a new dataset PLATE -- Pages of Lists Attribute Extraction which contains pages of online stores. The authors focused on preparing high-quality data, they conducted a multi-stage preparation of data, which included:
\begin{enumerate}
 \item Filtration of pages that did not contain lists of records.
 \item Among other pages, the most ``popular`` websites were selected based on data published in the ``Tranco List``.
 \item Also, preference was given to sites that contained as many pages with lists as possible.
 \item Pages with obscene content were filtered.
\end{enumerate}
Thus, the dataset was based on 43 sites and more than 6,600 pages, which together contains more than 52,000 records. Based on this, main feature of this dataset is the high quality of the data.

One of the problems related to web page extraction is web page segmentation. This task involves finding the boundaries of each record on the page. There are several approaches to the segmentation problem. Some of them assume the presence of visual information. For example, such algorithms are discussed in the article \cite{kiesel2021empirical}. However, in this work, we assume that visual information is unavailable and we will use other methods.

One of the first solutions of finding record boundaries on the page is the algorithm proposed in the article ``Web data extraction based on partial tree alignment``\cite{zhai_web_2005}. The authors developed algorithm called MDR, this algorithm finds ``similar`` fragments on the page. It is assumed that "similar" fragments records have the same attributes. After finding these fragments, the process of ``alignment`` occurs, this process compares each node of the fragment to the node in the remaining fragments. By this algorithm we can present information in a structured form.

It is also worth mentioning the article ``Finding and Extracting Data Records from Web Pages``\cite{alvarez_finding_2010}, in which an algorithm for generating partition candidates and selecting the best one was proposed. In our article we consider using this algorithm from a practical point of view.

\begin{figure}
    \centering
    \includegraphics[width=0.45\textwidth]{attach/markuplm_architecture.jpg}
    \caption{MarkupLM architecture*}
    \small* This picture is taken from the \cite{li_markuplm_2022}.
    \label{fig:markuplm_architecture}
\end{figure}

According to our research, there are information extraction methods designed to extract from detailed pages, which might be generalized for the task of extracting information from list pages. One of these methods is the MarkupLM, which was designed in 2022 by Microsoft\cite{li_markuplm_2022}. MarkupLM is BERT-like model, which is used for processing markup-language-based documents such as HTML or XML. The main feature of this model is encoding text and location of node together. The authors propose to use this model as a tool for working with detailed pages. More detailed description of architecture of this model is given in the \autoref{fig:markuplm_architecture}.

\begin{table*}[!ht]
\caption{Dataset comparison}
\begin{center}
    \begin{tabular}{ccccccc}
        \toprule
        Dataset & Pages/Vert. & Sites/Vert. & Records/Vert & Total Pages & Year & Language\\
        \midrule
        LDST & 771 & --- & 8600 & 771 & 2011 & English\\
        AMBER & 200 & 150 & 2000 & 431 & 2012 & English\\
        PLATE & 6694 & 43 & 52900 & 6694 & 2020 & English\\
        \midrule
        Our dataset & \textbf{13120} & \textbf{278} & \textbf{257595} & \textbf{13120} & 2023 & Russian\\
        \bottomrule
    \end{tabular}
    \label{tab:dataset_compare}
\end{center}
\end{table*}