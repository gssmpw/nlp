
\section{Discussion}
\RR{
Our study utilizes an intuitive flower-based visual design and evidence-based collaborative programming process analysis to provide instructors with a clear perspective for evaluating group and individual performance in collaborative programming. In this section, we discuss the lessons learned, the factors contributing to the research outcomes, and how these findings relate to existing works.

\subsection{Flower-Based Visual Design for Intuitive and Useful by Participants}
In large-scale learning analytics, intuitive visualization and interactive features prove to be valuable in assisting instructors with evaluations while reducing their workload~\cite{martinez2020data,fernandez2024data}.
Our study shows that the flower-based visual design effectively helps instructors summarize the performance of students and groups in collaborative programming.
Participants using \textit{CPVis} typically report starting by observing the flower visualization to gain an overview of the group's overall performance and the engagement levels of individual members during collaboration. Our design enables them to make quick assessment judgments and uncover valuable educational insights. 
For instance, students playing the Driver role often exhibit higher engagement levels.
\RA{Previous works use dynamic natural metaphors~\cite{tausch2014groupgarden,tausch2016comparison}, such as blooming flowers, falling leaves, and weather changes, to represent the quality and state of group discussions. However, these metaphors primarily convey overall trends or atmospheres rather than offering a precise and structured representation of multidimensional data, making it difficult for users to extract specific and accurate information efficiently. Moreover, the strong symbolic and emotional nature of their metaphors often leads to subjective interpretations.}
The effectiveness of our design lies in its ability to translate multiple dimensions of process-based learning analytics into visual elements such as colored petals and flower stamens, enabling instructors to quickly interpret multidimensional data and assess both group and individual performance during collaboration.
Furthermore, the flower-based visualization supports hierarchical analysis at both the group and individual levels, allowing instructors to efficiently analyze and compare the performance of multiple groups and students on a large scale.

\subsection{\textit{CPVis} Enhanced Instructors' Confidence in Evaluating Groups and Students}
The study demonstrates that \textit{CPVis} enhances participants' confidence in evaluation outcomes and improves the accuracy of their assessments. In Baseline System 1, participants report that accessing data requires significant time, and evaluating a specific group's performance often necessitates finding similar groups for a relatively fair comparison. 
Such a process demands additional time, causing participants to lose patience and avoid thoroughly examining all the details.
In baseline system 2, participants have to manually browse and process large amounts of student behavior and interaction data, which significantly increases cognitive load and reduces efficiency as they rely on memory to evaluate the performance of different groups.
In comparison, \textit{CPVis} offers significant convenience to participants \RA{by visualizing multidimensional learning analytics data}, allowing them to effortlessly access key information required for evaluations and compare similar groups. By providing both an overall view of multiple groups and detailed comparisons into individual groups, \textit{CPVis} substantially boosts participants' confidence in their evaluation outcomes, as demonstrated in the ratings. 
%This finding aligns with previous research results~\cite{sato2023groupnamics}.
\RA{Clear and intuitive visual analytics systems contribute to improved confidence and efficiency among participants. For instance, Groupnamics helps participants identify groups requiring intervention by visualizing each group's recent vocal activities and discussion statuses in a one-page view, thereby boosting their confidence in decision-making~\cite{sato2023groupnamics}.}
While it is ideal for \textit{CPVis} to support comparisons across an unlimited number of groups, practical limitations related to cognitive load and visual design make this challenging. Future efforts focus on optimizing the evaluation process through visual design, striking a balance between cognitive load and evaluation efficiency, thereby providing effective support for teaching.



\subsection{Theory-driven and LLM-powered Automation Evaluation for Quantifying Collaborative Learning}
Our study utilizes data collection, analysis, and visualization techniques to extract key insights from students' collaborative behaviors and outcomes, providing a deeper understanding of the learning process in collaborative programming. We focus on quantifying complex collaborative learning processes by leveraging LLMs and theoretical frameworks, introducing innovative methods to evaluate collaboration efficiency. 
While collaborative problem-solving is clearly defined in prior research~\cite{rosen2020towards}, achieving a quantitative balance between task performance and team effectiveness remains a significant challenge. To address this, we employ the coefficient of variation as a balancing metric and validate its efficacy using real-world datasets.
By integrating LLMs, \textit{CPVis} automates the annotation of collaborative programming performance, significantly reducing the workload associated with manually labeling large-scale classroom data and offering a novel perspective for automated learning analytics. 
Combining theory-driven metrics and LLM-powered automation provides instructors with robust, multidimensional evidence, enabling them to process and compare extensive student data systematically. 
This empowers instructors to effectively evaluate group and individual behaviors in collaborative programming, identify collaboration patterns, and support evidence-based decision-making. Previous research demonstrates that data-driven analysis helps educational decision-makers~\cite{hou2024codetailor}, such as instructors, uncover hidden learning patterns and deliver personalized guidance. Building on this foundation, \textit{CPVis} further enhances the potential for personalized feedback, enabling instructors to provide precise, data-driven guidance to students.


}


\section{Limitations and Future Work}

\RR{
In this section, we discuss the limitations of the current study and potential future work.
\subsection{Limitation}
Our study has three main limitations.
First, our current analysis is limited to data from a single real-world classroom's collaborative programming discussions, restricting the generalizability of our findings to other contexts. Similarly, our evaluation of \textit{CPVis} relies on a sampled dataset, limiting the study's scope. We hypothesize that participants working with smaller datasets and visualized learning analytics experience reduced cognitive load and find it easier to identify collaboration patterns due to fewer visual elements to process. However, in large-scale collaborative programming classrooms, instructors face the challenge of evaluating more groups and students, which may increase memory load and visual complexity.
Second, the data collected in our study are obtained from real classroom environments, maintaining ecological validity by capturing natural behaviors such as group silence or requests for instructor assistance. However, due to the limitations of non-intrusive equipment, our data lack details such as facial expressions and non-verbal cues. While participants report the comprehensiveness and richness of the learning analytics in the experiment, the absence of these data poses challenges for deeper analysis of emotional expressions and social engagement during collaborative programming. This limitation hinders the provision of a more holistic learning analysis for evaluation purposes.
Additionally, the recorded data are independent and exclude audio information, making it difficult to align screen interactions with dialogue streams. This limitation constrains the exploration of the relationship between collaborative behavior patterns and collaborative problem-solving processes.
Finally, in large-scale collaborative programming classrooms, generating analytics using LLMs requires significant computational time and cost. While feasible for institutions with robust computational resources, this remains a limitation for deploying such tools in real teaching scenarios. Furthermore, in real classrooms, noise from multiple group discussions introduces significant data noise, complicating the automation of learning analytics generation and limiting the accuracy of evaluations for groups and individual students.


\subsection{Future Work}
Without well-structured visualizations, simply presenting multiple data streams poses significant challenges for instructors attempting to interpret these large-scale datasets~\cite{fernandez2024data}.
In this study, we explore the integration and analysis of multimodal data. However, \textit{CPVis} has the potential to further enhance the visualization and perception of multimodal data, enabling instructors to evaluate group and student performance with greater accuracy and reduced cognitive load~\cite{martinez2020data}. 
Our target audience consists of instructors teaching large introductory collaborative programming courses, who require more efficient and intuitive visualizations to understand student performance during collaboration.  
While our use of static 2D visualizations, such as high-dimensional flower glyphs, has been highly regarded by participants for boosting confidence and helping instructors quickly identify key features, we believe there is room for improvement in organizing visualization formats to enhance information transmission efficiency and the users cognitive experience.
For instance, incorporating narrative visualizations further streamlines the process by allowing instructors to generate composite evaluations based on their weighting of different collaboration performance dimensions~\cite{gratzl2013lineup}. 
Narrative visualizations enable instructors to delve into data details, organize learning analytics results along logical paths such as timelines, causality, or categories, and highlight key information~\cite{chen2019designing}. 
This approach mitigates visual overload caused by excessive data, significantly reduces the time and cognitive effort required for evaluation, and ultimately supports instructors in making better decisions and assessments.

\textit{CPVis} requires instructors to spend additional time after class to evaluate collaborative performance. In our study, most participants indicate during follow-up interviews that the extra time spent on evaluating students' collaborative performance is highly valuable for producing comprehensive assessments. They note that providing immediate evaluations during the collaboration process is unrealistic, as final assessments typically need a holistic consideration of task completion and group dynamics after class. However, there is a significant demand for real-time analysis tools to deliver timely, personalized feedback to students and offer appropriate instructional scaffolding during the collaborative process~\cite{tang2024sphere}.
Instructors frequently find themselves overwhelmed by the immediate needs of some students~\cite{yang2023pair}, unintentionally neglecting others. To address this issue, future work could explore the integration of LLMs to enable real-time monitoring and analysis of students' behavioral data—such as code submissions, error logs, and engagement levels. LLMs could automatically detect learning bottlenecks or collaboration issues, providing instant feedback on common problems to students. This would effectively reduce instructors' workload, allowing them to focus on complex or critical issues, and simplify classroom management tasks.
For instance, LLMs could summarize patterns in students' code submissions and generate a ``hotspot report'' identifying recurring issues across the class. They could also provide real-time collaborative performance analytics for different groups, enabling instructors to quickly gain a comprehensive understanding of overall class dynamics. Additionally, LLMs could assist in role allocation within groups, suggest strategies to improve team interactions, and identify potential conflicts or disengagement within collaborative teams.
LLM-powered tools automate evaluations and enable personalized feedback, bridging post-class assessments with in-class scaffolding to enhance teaching and learning in collaborative programming.}