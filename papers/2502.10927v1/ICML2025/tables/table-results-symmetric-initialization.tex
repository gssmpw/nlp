\begin{table}[t]
\caption{The final loss at the end of training and the speed-up for the 4 and 12-layer models trained on the Jigsaw dataset \citep{jigsaw_challenge}, Wikipedia \citep{wikidump}, and Red Pajama \citep{together2023redpajama}, with and without symmetry initialization (see Appendix~\ref{sec:exp_bertmodels_models}).
%
Speed-up (\%) is calculated by subtracting the epoch at which the symmetrically initialized model reaches the non-symmetric modelâ€™s final loss from the total number of epochs, and then dividing by the total number of epochs.
%
For example, a 50\% speed-up means that the model with symmetric initialization achieves the final loss of the non-symmetric model in half the number of training epochs.
%
}
\label{table:symmetric-initialization}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lcccr}
\toprule
Model & Loss & Speed-up \\
\midrule\midrule
4-layer model & & \\
\midrule\midrule
Jigsaw & 2.782 & \\
Jigsaw (+ symm) & \textbf{2.758} & 26 \% \\
\midrule
Wikipedia & 0.984& \\
Wikipedia (+ symm) & \textbf{0.812} & 73 \%\\
\midrule
Red Pajama & 1.106 &\\
Red Pajama (+ symm) & \textbf{0.907} & 69 \%\\
\midrule\midrule
12-layer model & & \\
\midrule\midrule
Jigsaw & 1.419 & \\
Jigsaw (+ symm) & 1.430 & 0 \%\\
\midrule
Wikipedia & 0.256 & \\
Wikipedia (+ symm) & \textbf{0.247} & 20 \%\\
\midrule
Red Pajama & 0.297&\\
Red Pajama (+ symm) & \textbf{0.274} & 35 \%\\
\bottomrule
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}