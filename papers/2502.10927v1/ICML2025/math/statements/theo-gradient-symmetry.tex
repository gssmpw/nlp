\begin{theorem}
\label{theo-gradients-symmetry}
%
(\textbf{Bidirectional training induces symmetry})
%
Let $U$ be an ordered sequence of $N$ tokens $U = [t_1, \dots, t_N]$.
%
Let $\Delta \bm{W}_{qk}$ be derived from a bidirectional objective function as in Definition \ref{def-objective-functions}.
%
It follows that the weight update of $\bm{W}_{qk}^l$ is given by
%
\begin{equation}
    \Delta \bm{W}_{qk}^l = \sum_{i = 1}^N \sum_{j = 1}^N \beta^l_{ij} \bm{K}^{l-1}_{ij} \,,
\end{equation}
%
and that every pair $(i,j)$ with $i \neq j$ contributes to the weight update with a term
%
\begin{equation}
    \Delta \bm{W}_{qk}^l\big|_{\bm{t}_i \leftrightarrow \bm{t}_j} = \beta_{ij}^l\bm{K}^{l-1}_{ij} + \beta_{ji}^l{\bm{K}^{l-1}_{ij}}^T \,,
\end{equation}
%
that is approximately symmetric,
%
\begin{equation}
    \Delta \bm{W}_{qk}^l\big|_{\bm{t}_i \leftrightarrow \bm{t}_j} \approx \Delta \bm{W}_{qk}^l\big|^\top_{\bm{t}_i \leftrightarrow \bm{t}_j} \,.
\end{equation}
% %
% \begin{equation}
%     \Delta \bm{W}_{qk}^l\Big|_{\bm{t}_i \leftarrow \bm{t}_j} + \Delta \bm{W}_{qk}^l\Big|_{\bm{t}_j \leftarrow \bm{t}_i} \, \simeq \, [(1+\alpha)\beta_{ij} + \epsilon_{ij}]\bm{S}^{l-1}_{ij} \, , 
% \end{equation}
% %
% where $\alpha$ is a constant factor proportional to the correlation between $\beta_{ij}$ and $\beta_{ji}$, $\epsilon_{ij}$ is random variable uncorrelated with $\beta_{ij}$, and where $\bm{S}^{l-1}_{ij}$ is the symmetric component of  $\bm{K}^{l-1}_{ij}$.
%
\end{theorem}