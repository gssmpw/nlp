%
In this work, we demonstrate how bidirectional and autoregressive objective functions influence the structure of the query-key matrix $\bm{W}_{qk}$ in self-attention, enhancing our understanding of Transformer models.
%
Our mathematical framework shows that bidirectional training induces symmetric structures in $\bm{W}_{qk}$, whereas autoregressive training results in matrices characterized by directionality and column dominance.
%
To empirically validate our analysis, we develop and apply symmetry and directionality scores to various Transformer encoder and decoder models across multiple modalities, including text, audio, and images. 
%
Our results reveal that bidirectionally trained encoder models exhibit high symmetry, while autoregressively trained decoder models demonstrate strong directionality, thereby supporting the predictions of our mathematical framework.
%
%To validate our analysis empirically we define a symmetry and directionality score, showing consistent results across different Transformer architectures, input modalities, and layers within a model.
%
This suggests that self-attention inherently reflects these structural properties, contributing to the mechanistic interpretability of Transformer models.
%
%Our results thus indicate fundamental characteristics of the self-attention mechanism, contributing to a deeper mechanistic interpretability of Transformer models.
%
Finally, we leverage our findings to improve convergence speed during bidirectional training by initializing $\bm{W}_q$ and  $\bm{W}_k$ matrices such that $\bm{W}_{qk}$ is symmetric.
%
%This result shows a practical consequence of our findings beyond their implications for interpretability.
%

While our findings mark an initial step toward leveraging symmetry for more efficient Transformer training, further research is required to assess the scalability of symmetric initialization in large-scale models and across diverse domains.
%
% Future research should validate our initialization strategy across diverse models and test its scalability in larger architectures.
%
Furthermore, it is important to explore strategies for leveraging the directionality structures of decoder-only models.
%
For instance, incorporating structural constraints into the objective function or weight regularization could enhance training efficiency and stability in autoregressive settings.
%
By bridging theoretical insights with practical improvements, our work not only advances the interpretability of self-attention but also provides a foundation for optimizing Transformer architectures.
%
Ultimately, these findings contribute to a deeper understanding of the mechanisms governing self-attention, paving the way for more reliable and efficient Transformer-based models.