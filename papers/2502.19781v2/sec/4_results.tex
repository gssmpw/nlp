   % Adjust the thickness


\begin{table*}
\centering    

% \hspace*{-1.3cm}
\begin{tabular}{l|ccc|ccccc}
\hline
                        & Biome & EcoRegions & Country   & Temperature & Elevation & Population & Cali-Housing   \\ \hline
Direct                      & 29.1 & 0.6 & 66.9& 0.381  & 0.025  &  0.053  & 0.238      \\
Cartesian\_3D                      & 30.2 & 1.8 &66.9 & 0.362  & 0.030  &  0.162  & 0.240      \\
Wrap~\cite{Aodha_2019_ICCV}                      & 34.4 & 1.1 & 69.7& 0.861  & 0.085  &  0.328  & 0.239      \\
Theory~\cite{gaolearning}                      & 33.5 & 1.0 &72.5 & 0.849  & 0.093  &  0.330  & 0.254      \\
SphereM~\cite{mai2023sphere2vec}                      & 36.4 & 27.3 & 72.7 & 0.629  & 0.139  &  0.302  & 0.423      \\
SphereM$^{+}$~\cite{mai2023sphere2vec}                      & 58.7 & 50.1 & 76.1 & 0.886  & 0.294  &  0.421  & 0.543      \\
SphereC~\cite{mai2023sphere2vec}                     & 36.3 & 52.9 & 72.9 & 0.461  & 0.185  &  0.335  & 0.496      \\
SphereC$^+$~\cite{mai2023sphere2vec}  & 53.2 & 61.6 & 73.6 & 0.842  & 0.260  &  0.392  & \underline{0.544}      \\

\hline


CSP-INat~\cite{mai2023csp}                      & 61.1 & 57.1 & 75.9 & 0.717  & 0.388  &  0.554  & 0.462      \\
CSP-FMoW~\cite{mai2023csp}                    & 61.4 & 58.0 & 81.3& 0.865  & 0.399  &  0.580  & 0.541      \\
SINR~\cite{cole2023spatial}                    & 67.9 & 54.9 & 88.3 & \textbf{0.942}  & 0.644  & 0.726 & 0.420      \\
GeoCLIP~\cite{vivanco2024geoclip}                & \underline{70.2} & 71.6 & 81.3 & 0.916  &  0.604  &  0.698  & \textbf{0.708}      \\
SatCLIP~\cite{klemmer2023satclip}  & 68.9 & 69.3 & 82.8 & 0.825       & 0.666     & 0.684 & 0.400   \\ \hline


RANGE  & \textbf{83.3} & \textbf{75.7} & \underline{93.7} &0.895 & \underline{0.844} & \underline{0.799} & 0.422  \\ 


RANGE$^+$                      & \textbf{83.3} & \underline{75.3} & \textbf{94.7} &\underline{0.931} & \textbf{0.851} & \textbf{0.811} & 0.336 &    \\ 
\end{tabular}
\caption{Our model shows improvements over a variety of tasks compared to state-of-the-art models. The first 3 columns are classification tasks with accuracy metrics and the last 4 columns are regression tasks with R$^2$ metric. We show improvements with significant margins across many of the tasks. Our model underperforms in the Cali-housing dataset. We further analyze this behavior in our discussions.}
\label{table:main}

\end{table*}

\begin{table*}
\resizebox{\linewidth}{!}{%
\begin{tabular}{l|cc|ccc|cccc}
\hline
                    &type &temp.   & Biome & Eco&Country  & Temperature & Elevation & Population & Cali-Housing   \\ \hline

SatCLIP & base-model &- & 68.9 & 69.3 & 82.8& 0.825       & 0.666     & 0.684 & 0.400   \\ 
\hline
RANGE & top-1&-     & 75.6 & 65.2 & 85.6 & 0.817      & 0.766    & 0.742 & 0.444  \\
&  top-k  &-& 82.8 & 76.8 & 90.6 & 0.884 & 0.810 & 0.771 & \textbf{0.619}  \\

 & soft selection & fixed& 83.3 & 75.7 &93.7 & 0.895 & 0.844 & 0.799 & 0.422  \\ 


& soft selection & per task& \underline{83.5} & \underline{75.8} & 94.5 & 0.922 & \textbf{0.857} & 0.809 & \underline{0.465}  \\ 

\hline


    RANGE$^+$ &       soft selection & fixed           & \underline{83.5} & 75.3 &\underline{94.7}  & \underline{0.931} & 0.851 & \underline{0.811} & 0.336    \\ 
    &       soft selection & per task           & \textbf{83.7} & \textbf{75.9} & \textbf{94.9} & \textbf{0.932} & \underline{0.855} & \textbf{0.813} & 0.460    \\ % 
   \hline
  gain (\%)   &      &     & \color{OliveGreen}{+21.5} & \color{OliveGreen}{+9.5} & \color{OliveGreen}{+14.6} & \color{OliveGreen}{+12.9} & \color{OliveGreen}{+28.37} & \color{OliveGreen}{+18.8} & \color{OliveGreen}{+15.0}    \\ 

\end{tabular}
}
\caption{Ablation of different versions of our model compared with SatCLIP as the base model. Our soft selection using weighted averages over the database performs better than top-k selection. We also find that a single temperature works well for most tasks. Fine-tuning the temperature per task is generally not required as the gain is marginal. The last row shows the difference between the base model and RANGE$^+$.}
\label{table:ablate}
\end{table*}

\begin{table}
\centering

\begin{tabular}{l|cccc}
\hline
                    &top-1 &top-3 &top-5& top-10   \\ \hline

Img & 66.1 & 83.3 & 88.0 & 92.2   \\ 
\hline
Img+CSP & 72.9 & 87.9 & 91.6  & 94.8 \\
Img+GeoCLIP & 72.9 & 88.2 & 91.9 & \underline{95.2}  \\
Img+CSP\_INat$^*$ & 74.4 & 88.8 & 92.2 & 94.9   \\ 
Img+SatCLIP & 75.1 & 88.7 & 91.9 & 94.5   \\ 
\hline
Img+RANGE & \textbf{75.2} & \textbf{89.6} & \textbf{92.9} & \textbf{95.5}   \\ 
Img+RANGE$^+$ & \underline{75.1} & \underline{89.5} & \underline{92.8} & \textbf{95.5} \\
\end{tabular}
\caption{\textbf{Top-k classification accuracy on INat-2018 test split:} Location information acts as a strong prior in fine-grained species classification. Our method shows competitive top-k results against state-of-the-art models.}
\label{table:inat}
\end{table}
\begin{figure}[t]
\begin{center}
\includegraphics[width=\linewidth, scale=0.3]{sec/images/database_ablation_plot_v3.jpeg}
\end{center}
   \caption{Performance of our model with respect to the database size. The results show that compared to RANGE-HAVER, both RANGE and RANGE$^{+}$ are very robust to changes in database size. We can maintain the same performance even when only using 10\% of the samples in the database.} 
\label{fig:database_ablation}
\end{figure}

\begin{figure*}[!ht]
\begin{center}
\includegraphics[width=\linewidth, scale=0.3]{sec/images/ica_plots.png}
\end{center}
   \caption{We visualize the geo-embeddings from different models by projecting them into a 3-dimensional vector using Independent Component Analysis (ICA). The results suggest that by explicitly adding visual features, our method learns more high-frequency information compared to the existing models.} 
\label{fig:ica}
\end{figure*}
\begin{figure*}[!t]
\begin{center}
\includegraphics[width=\linewidth, scale=0.3]{sec/images/beta_interpolation_2.png}
\end{center}
   \caption{Interpolating the $\beta$ parameter in RANGE$^+$ allows us to control the spatial smoothness of our embeddings. The results show that RANGE$^+$ can be used to generate neural fields of geo-embeddings at multiple frequencies.} 
\label{fig:beta}
\end{figure*}

\section{Experiments and Results}
\subsection{Quantitative Evaluation on Downstream Tasks}
\label{sec:quant}
We evaluate the efficacy of RANGE and RANGE$^+$ embeddings on a wide variety of downstream applications. We create our database using the SatCLIP~\cite{klemmer2023satclip} dataset with 82k locations. For RANGE$^+$, we set $\beta$ to $0.5$. We choose 3 classification tasks and 4 regression tasks for this experiment as used by prior work~\cite{klemmer2023satclip}. The classification tasks are biome classification~\cite{dinerstein2017ecoregion}, ecoregion classification~\cite{dinerstein2017ecoregion}, and country classification~\cite{klemmer2023satclip}. The regression tasks are air temperature prediction~\cite{Hooker_Duveiller_Cescatti_2018}, elevation prediction~\cite{rolf2021generalizable}, population density prediction~\cite{rolf2021generalizable}, and housing price prediction~\cite{pace1997sparse}. Results on climate data from ERA5 are shown in Section~\ref{sec:era5} of the supplementary material. The objective is to learn a linear predictive model that solves the underlying task. For fairness, we use the same hyperparameters for all tasks, i.e., the same $\tau$ and $\beta$ parameters for each task. The details of the hyperparameters are listed in the supplementary material. We compare our method with state-of-the-art parametric~\cite{klemmer2023satclip, vivanco2024geoclip, cole2023spatial, mai2023csp, mai2023sphere2vec} and non-parametric~\cite{Aodha_2019_ICCV,gaolearning} representations. The results of this experiment are shown in Table~\ref{table:main}. 

The results show that our method outperforms all state-of-the-art models in the classification tasks with significant margins. In biome, ecoregion, and country classification, we advance the state-of-the-art by 13.1\%, 4,1\%, and 6.4\%, respectively. Among the regression tasks, we achieve SoTA performance for elevation and population density prediction with significant gains and narrowly come second in the air temperature prediction task. Our method, however, underperforms in the housing price prediction task. We suspect this is because the visual features that define housing change dramatically over time. The standard California housing dataset is based on a 1990 census, while our retrieved visual features are extracted from 2020 Sentinel data. 
The results also demonstrate that the hyperparameters for our model are robust and do not need to be tuned for specific tasks to achieve good performance. Furthermore, RANGE$^+$, on average, outperforms RANGE by a small margin, which can be attributed to the spatial smoothness constraint.


\subsection{Using Location Embeddings as Geo-prior}
\label{sec:inat}
We evaluate our model on the task of fine-grained species classification. We use the iNaturalist 2018 dataset~\cite{van2018inaturalist}, which contains data from 8,142 species. Prior works~\cite{Aodha_2019_ICCV,russwurm2023geographic,klemmer2023satclip} have shown that adding location information can improve the performance of pretrained image classification models on iNat as knowing the location of an image can provide a strong prior about its content. For our experiment, we follow a similar setup as~\cite{russwurm2023geographic}. We take a pretrained image classification model, which gives us $P(y \mid I)$. We then train a linear model that takes as input the pre-trained geo-embeddings and predicts the species categories, i.e., $P(y \mid G)$. The final distribution is computed as the product of the two distributions, i.e., $P(y\mid I, G) = P(y\mid I)*P(y\mid G)$. This experiment also aims to show that location representations obtained using self-supervised training can be easily generalized towards tasks like iNat. Hence, we exclude SINR~\cite{cole2023spatial} from this comparison as it is trained in a supervised manner on the iNaturalist data itself.   

The results of this experiment are shown in Table~\ref{table:inat}.   The performance of the pretrained image classifier is 66.1\%. The addition of location information improves the accuracy across all models. We see that RANGE and RANGE$^+$ achieve competitive scores, narrowly outperforming state-of-the-art models. The results from this experiment highlight the benefits of using good location representations as geo-prior to solve fine-grained image classification tasks.

\subsection{Ablation Study}
\label{sec:ablation}
\textbf{Robustness to Database Size: }The RANGE database that we used for our model in Section~\ref{sec:quant} was created using the SatCLIP dataset with 82k locations. However, our method is extremely robust and can be used with much smaller database sizes. We conducted an experiment where we used smaller samples of the SatCLIP data to create our RANGE database. We created a database with 75\%, 50\%, 25\%, and 10\% of the total data. We then trained a linear model for RANGE and RANGE$^+$ using each of these subsets as our retrieval database. We also trained another version of our method where we only use geodesic distance for retrieval,i.e. $\beta=0$, which we call RANGE-HAVER. We used the same tasks described in Section~\ref{sec:quant} to evaluate these models.

Our results from figure~\ref{fig:database_ablation} show that we can obtain similar performance while using only 10\% of the original database size. In terms of storage, this database only occupies 85 Megabytes in disk, which is very efficient. The results also support our initial claim that there is low variance in satellite images; thus, a small number of satellite images can capture many important semantics across the globe. We see that the performance for both RANGE and RANGE$^+$ is stable across different settings and different tasks. The results also show that RANGE-HAVER, which only relies on spatially retrieved information, can be unstable, as seen in figure~\ref{fig:database_ablation}. These results highlight the pitfalls of depending completely on spatial similarity for retrieval. Locations that are spatially close do not necessarily share similar semantics. Therefore, as you change the sample distribution in the database, you can introduce noisy retrievals, which amplify the noise in the estimated visual embedding. Semantic-based retrieval strategy mitigates such issues.
\\

\noindent \textbf{Impact of architectural components: }Table~\ref{table:ablate} shows the impact of different components of our method compared to SatCLIP as the base model. We also compare our method with two other methods of retrieval: top-1 and top-k (where k was set to 100). The results show that our retriever function generally yields better results than the top-k selection approach. This can be attributed to the fact that top-k averaging does not consider the measure of similarity between query location and keys. We also performed a linear search to find the optimal temperature parameters of RANGE for each task separately. Our results show we are able to make marginal improvements by tuning the temperature parameter for individual tasks. The results indicate the temperature parameters of RANGE are robust and do not need to be finetuned for individual tasks in most cases.


\subsection{Qualitative Evaluation of Geo-embeddings}
\label{sec:ica}
\textbf{Visual comparison of geo-embeddings: }We qualitatively compare the RANGE embeddings with other location embeddings. We use Independent Component Analysis (ICA) to project the embeddings to a 3-dimensional vector and use them as RGB channels to visualize them over the globe. Figure~\ref{fig:ica} shows the visualizations for each model. Qualitatively, we see that models like CSP and SINR are extremely smooth, suggesting that they predominantly capture low-frequency information. GeoCLIP and SatCLIP capture relatively high-frequency information. The visualizations further suggest that RANGE and RANGE$^+$ embeddings are able to capture even higher frequency information. 
\\
\noindent \textbf{Visualizing the impact of $\beta$ parameter: }Secondly, we visualize the impact of the $\beta$ parameter in equation~\eqref{eq:rangep}. A quantitative evaluation of the $\beta$ parameter is presented in Section~\ref{sec:beta_quant} of the supplementary material. Setting $\beta=1$ gives us the RANGE embeddings, setting $\beta=0$ gives us RANGE-HAVER embeddings, and setting $\beta=0.5$ gives the RANGE$^+$ embeddings. This parameter controls the contribution of spatially-retrieved visual information to the semantically-retrieved visual information. This additional information acts as a spatial smoothness constraint on the RANGE embeddings. At $\beta=0$, we add the maximum constraint, which gives us low-frequency embeddings similar to CSP and SINR. As we increase the value of $\beta$, we increase the frequency of our embeddings, i.e. locations that are spatially close to each other but are semantically different have different representations. Thus, the $\beta$ parameter allows us to explicitly control the smoothness of the RANGE embeddings and, therefore, allows generating location embeddings at multiple frequencies.   
