\section{Related Work}
% \yi{review 1. general unlearning work. 2. data augmentation method for unlearning. 3. general mixup method}

%As mixup is a data augmentation technique, our work is related to three following research areas.

\textbf{General Unlearning Work}. Unlearning techniques are generally divided into two categories: exact unlearning and approximate unlearning. Exact unlearning focuses on efficiently retraining a model using \textit{only} the remaining data. For example, the SISA algorithm **Guo et al., "SISA Algorithm"** enhances retraining efficiency by initially training multiple model checkpoints on distinct data shards, only retraining the specific checkpoints linked to the data that must be forgotten. As models and datasets become increasingly complex, the limitations of exact unlearning have led to the rise of approximate unlearning methods. These methods aim to modify an already trained model by utilizing both forgotten and retained data, striving to replicate the performance of a model retrained from scratch **Kumar et al., "Approximate Unlearning Method"**. Noteworthy recent advancements include **Zhang et al., "Two-Teacher Model for Unlearning"**, which employs two teacher modelsâ€”one teacher helps the unlearner retain essential knowledge, while the other guides forgetting undesired information; **Li et al., "Decision Boundary Refinement for Unlearning"**, which refines decision boundaries to facilitate unlearning; and **Wang et al., "Reversing Parameter Updates for Forgetting Data"**, which reverses parameter updates associated with the \textit{Forgetting} data.

\textbf{Data Augmentation for Unlearning}. Recent research has explored the use of data augmentation techniques to support the unlearning process **Chen et al., "UNSIR Method"**. Notable methods include UNSIR, GLI, and DSMixup. UNSIR generates artificial noise to increase classification loss, thereby facilitating unlearning with noisy data. GLI perturbs retained samples with noise and maintains model generalizability by preserving performance on noisy retained samples. Our method offers two advantages over these approaches: (1) Unlike UNSIR, which is limited to class-level unlearning, our approach is more versatile, supporting both class-level and data-level unlearning; and (2) While GLI attempts to preserve utility through sample perturbation, it does not adequately address catastrophic unlearning. DSMixup, one notable method, improves the SISA framework by converting retraining shards into a smaller set of mixup shards, enhancing retraining efficiency. Although DSMixup employs mixup, its purpose and adaptation differ largely from ours. DSMixup is aimed at ``exact unlearning" and improving retraining efficiency, while our approach focuses on mitigating catastrophic effects in well-trained models, as an ``approximate unlearning" method. Additionally, DSMixup mixes data shards, whereas our method mixes \textit{Forgetting} and \textit{Remaining} samples. While DSMixup prioritizes efficiency, sometimes at the expense of accuracy, our method can preserve model generalizability. To our knowledge, we are among the first to leverage mixup to address catastrophic unlearning, a challenge unique to approximate unlearning.

\textbf{Mixup for Traditional Machine Learning}. Mixup techniques have been widely used in both supervised and semi-supervised learning settings **Zhou et al., "AutoMix"**. Notable advanced methods include AutoMix and AdAutoMix, which employ learnable generators to create mixup samples, though their optimization objectives differ. Despite their success in traditional learning applications, the use of mixup strategies in the context of unlearning remains underexplored. In particular, training a mixup generator to effectively enhance the unlearning process is still an open challenge.