Our problem can be seen as a variant of the selection problem in robust optimization, which is closely related to the secretary problem and prophet inequalities.

In this problem template, we are interested in maximizing the objective function $c^T x$ over a feasible region $\mathcal{F} \subseteq \mathbb{R}^n$, where only the uncertainty set $\mathcal{U}$ is given. This setup is very flexible, as $\mathcal{F}$ can range from a polytope in the continuous case to the set of $s$-$t$ paths or spanning trees of a graph in the discrete one.

The maxi-min objective can be replaced with regret-inspired variants. The uncertainty set $\mathcal{U}$ can take various shapes, with the two most prominent ones being discrete uncertainty: $\mathcal{U}_D = \{c_1, \dots, c_k\}$ and interval uncertainty: $\mathcal{U}_I = [a_1, b_1] \times \dots \times [a_n, b_n]$.

Interval uncertainty admits a variant in the spirit of byzantine fault-tolerance, introduced in ____: given a threshold $\Gamma$ define $\Gamma$-interval uncertainty $\mathcal{U}_I^\Gamma$ such that $c \in \mathcal{U}_I^\Gamma$ if $c \in \mathcal{U}_I$ and $|\{i : c_i \neq b_i\}| \leq \Gamma$. See ____ for excellent surveys of results and techniques.

One of the basic cases considered in the robust optimization literature concerns $\mathcal{F} = \{x \in \{0, 1\}^n : \sum_{i = 1}^n x_i = \ell\}$, the so-called selection problem ____: see ____ for a compilation of results under various objective and uncertainty set assumptions.

Of particular interest to us is the case with the normal maxi-min objective and $\Gamma=t$-interval uncertainty for $\mathcal{U}_I = [0, v_1] \times \dots \times [0, v_n]$: this corresponds exactly with choosing to open $\ell$ boxes, out of which the adversary can nullify $t$. Note, however, that this only models the deterministic part of our paper (which is straightforward): it cannot model committing to a randomized strategy of which $\ell$ boxes to open to which the adversary replies by nullifying $t$ so as to minimize the expectation. One of the few papers considering such randomized strategies is ____: they show that for discrete and interval uncertainty sets, it is possible to optimize the regret objective in polynomial time as long as (non-robust) optimization over $\mathcal{F}$ is feasible polynomially (which trivially holds for the Selection Problem).

Note that their result does not target $\Gamma$-interval uncertainty and is for the regret objective, hence not applicable to us. The paper ____ also refers to an unpublished (and not publicly available) 2012 manuscript of Bertsimas, Nasrabadi, and Orlin, titled ``On the power of nature in robust discrete optimization,'' claiming a similar result for our maxi-min objective, this time more generally applying to any pair $(\mathcal{F}, \mathcal{U})$ such that (non-robust) optimization over both $\mathcal{F}$ and $\mathcal{U}$ is feasible polynomially (which is the case in our setting). Modulo the fact that their paper cannot be reasonably retrieved, their result implies polynomial solvability for our problem (most likely using continuous optimization techniques like LP, and hence not strongly-polynomial).

Our approach to the problem will be different, leading to a better, linear-time, algorithm.

The selection problem is closely related to the secretary problem, which has been extensively studied in the literature ____: see ____ for surveys of results and techniques. The classical secretary problem concerns an online setting where a stream of $n$ items arrive one by one in an online fashion, and the decision-maker should either commit to that item or discard it permanently.

Each item has a value, and common goals include maximizing the probability of picking a highest-value item or maximizing the expected value of the picked item. A plethora of variations of the problem have been explored, including picking $\ell$ items instead of a single one ____: connecting the problem to our paper.

In the standard secretary model, the adversary picks the values of the items knowing the algorithm, and then the items are presented to the algorithm in an order chosen uniformly at random (the random-order model). Most developed algorithms are not robust to even small adversarial perturbations of the random order assumption. To study this effect, ____ introduces a semi-random model, where all values stay adversarial, but the arrival times of $t$ items are adversarial, chosen before the other $n - t$ items' arrival times are randomly generated.

Like us, inspired by the distributed computing literature, they call this the Byzantine secretary model. We note that the problem in ____ is very different from ours: they consider an online setting where all values are adversarial, but the arrival times of only $t$ are adversarial, while our setting is offline, with all but $t$ of the values being honest.

More subtly, given the values $v_1, \dots, v_n$, we want the best possible solution for a given instance, instead of the best achievable for a worst-case instance as in their setting (making our problem harder in this regard).

The selection problem is also related to prophet inequalities ____: see ____ for surveys of results and techniques. The basic setup considers $n$ random variables with known distributions $X_1, \dots, X_n$. One by one, the realization of these random variables is revealed to the decision-maker, who has the option between committing to the current value or passing to the next round.

The goal is to maximize the expectation of the selected value, and the standard result is that a policy achieving an expectation of at least half of the ex-post maximum value exists. Variants where $\ell$ values are to be selected have been studied, but once again, the combination of the stochastic and online aspects makes this setup very different from ours.

This problem has connections to statistical learning with adversarial noise ____: see ____ for surveys of results and techniques. Learning the underlying distribution or statistics about a dataset is a fundamental problem in statistical learning, and real-world data is often ill-behaved, including a fraction of adversarially corrupted/byzantine data.

It also has connections to adversarial bandits and experts ____: see ____ for surveys of results and techniques. The bandit model concerns a decision-maker who faces a slot machine with $n$ arms with unknown, possibly different, reward distributions.

At each time-step, having observed past behavior, the decision-maker must select an arm to pull, gaining an instantaneous reward sampled from that arm's distribution independently of other time-steps. The standard goal is regret minimization across a (possibly not fixed) time horizon $T$. Adversarial variants of the model have been explored, where instead of independent stochastic rewards, the rewards in each time slot are chosen by an adversary, bringing the setup closer to ours.

Our problem can be seen as a single-shot ($T = 1$) variant of adversarial bandits. Here, each arm gives a known reward of either $0$ or $v_i$, and the number of zeros is limited by $t$ (the number of Byzantine arms), but it is not known which $t$ arms give zeros.

The goal also changes from regret minimization to value maximization. Some work also explored models in-between stochastic and adversarial bandits ____: see ____ for surveys of results and techniques.