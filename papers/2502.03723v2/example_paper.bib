% RLC main.bib Version 2024.1
@inproceedings{NEURIPS2021_7ed2d345,
 author = {Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario  and Hari, Ananth  and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and Williams, Niall  and Lokesh, Yashas  and Ravi , Praveen },
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {15032--15043},
 publisher = {Curran Associates, Inc.},
 title = {PettingZoo: Gym for Multi-Agent Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/7ed2d3454c5eea71148b11d0c25104ff-Paper.pdf},
 volume = {34},
 year = {2021}
}
@article{zhangsimple,
  title={A Simple Framework for Intrinsic Reward-Shaping for RL using LLM Feedback},
  author={Zhang, Alex and Parashar, Ananya and Saha, Dwaipayan}
}
@inproceedings{liu2023lazy,
  title={Lazy agents: a new perspective on solving sparse reward problem in multi-agent reinforcement learning},
  author={Liu, Boyin and Pu, Zhiqiang and Pan, Yi and Yi, Jianqiang and Liang, Yanyan and Zhang, Du},
  booktitle={International Conference on Machine Learning},
  pages={21937--21950},
  year={2023},
  organization={PMLR}
}
@misc{rashid2020monotonicvaluefunctionfactorisation,
      title={Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning}, 
      author={Tabish Rashid and Mikayel Samvelyan and Christian Schroeder de Witt and Gregory Farquhar and Jakob Foerster and Shimon Whiteson},
      year={2020},
      eprint={2003.08839},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2003.08839}, 
}
@misc{wen2022multiagentreinforcementlearningsequence,
      title={Multi-Agent Reinforcement Learning is a Sequence Modeling Problem}, 
      author={Muning Wen and Jakub Grudzien Kuba and Runji Lin and Weinan Zhang and Ying Wen and Jun Wang and Yaodong Yang},
      year={2022},
      eprint={2205.14953},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2205.14953}, 
}
@misc{yu2022surprisingeffectivenessppocooperative,
      title={The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games}, 
      author={Chao Yu and Akash Velu and Eugene Vinitsky and Jiaxuan Gao and Yu Wang and Alexandre Bayen and Yi Wu},
      year={2022},
      eprint={2103.01955},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2103.01955}, 
}
@misc{kapoor2024assigningcreditpartialreward,
      title={Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization}, 
      author={Aditya Kapoor and Benjamin Freed and Howie Choset and Jeff Schneider},
      year={2024},
      eprint={2408.04295},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2408.04295}, 
}
@misc{su2020valuedecompositionmultiagentactorcritics,
      title={Value-Decomposition Multi-Agent Actor-Critics}, 
      author={Jianyu Su and Stephen Adams and Peter A. Beling},
      year={2020},
      eprint={2007.12306},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2007.12306}, 
}
@misc{chan2024denserewardfreereinforcement,
      title={Dense Reward for Free in Reinforcement Learning from Human Feedback}, 
      author={Alex J. Chan and Hao Sun and Samuel Holt and Mihaela van der Schaar},
      year={2024},
      eprint={2402.00782},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.00782}, 
}
@misc{ziegler2020finetuninglanguagemodelshuman,
      title={Fine-Tuning Language Models from Human Preferences}, 
      author={Daniel M. Ziegler and Nisan Stiennon and Jeffrey Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
      year={2020},
      eprint={1909.08593},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1909.08593}, 
}

@inproceedings{leerlaif,
  title={RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Mesnard, Thomas and Ferret, Johan and Lu, Kellie Ren and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav and others},
  booktitle={Forty-first International Conference on Machine Learning}
}

@book{sutton1998introduction,
    title={Reinforcement Learning: {A}n Introduction},
    author={Sutton, Richard S. and Barto, Andrew G.},
	publisher={The MIT Press},
	year={1998},
	address={Cambridge, MA},
}

@article{casper2023open,
  title={Open problems and fundamental limitations of reinforcement learning from human feedback},
  author={Casper, Stephen and Davies, Xander and Shi, Claudia and Gilbert, Thomas Krendl and Scheurer, J{\'e}r{\'e}my and Rando, Javier and Freedman, Rachel and Korbak, Tomasz and Lindner, David and Freire, Pedro and others},
  journal={arXiv preprint arXiv:2307.15217},
  year={2023}
}

@article{biyik2019asking,
  title={Asking easy questions: A user-friendly approach to active reward learning},
  author={B{\i}y{\i}k, Erdem and Palan, Malayandi and Landolfi, Nicholas C and Losey, Dylan P and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:1910.04365},
  year={2019}
}

@article{biyik2022learning,
  title={Learning reward functions from diverse sources of human feedback: Optimally integrating demonstrations and preferences},
  author={B{\i}y{\i}k, Erdem and Losey, Dylan P and Palan, Malayandi and Landolfi, Nicholas C and Shevchuk, Gleb and Sadigh, Dorsa},
  journal={The International Journal of Robotics Research},
  volume={41},
  number={1},
  pages={45--67},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{kim2023variational,
  title={A Variational Approach to Mutual Information-Based Coordination for Multi-Agent Reinforcement Learning},
  author={Kim, Woojun and Jung, Whiyoung and Cho, Myungsik and Sung, Youngchul},
  booktitle={Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages={40--48},
  year={2023}
}

@article{chu2019multi,
  title={Multi-agent deep reinforcement learning for large-scale traffic signal control},
  author={Chu, Tianshu and Wang, Jie and Codec{\`a}, Lara and Li, Zhaojian},
  journal={IEEE transactions on intelligent transportation systems},
  volume={21},
  number={3},
  pages={1086--1095},
  year={2019},
  publisher={IEEE}
}

@inproceedings{wiering2000multi,
  title={Multi-agent reinforcement learning for traffic light control},
  author={Wiering, Marco A and others},
  booktitle={Machine Learning: Proceedings of the Seventeenth International Conference (ICML'2000)},
  pages={1151--1158},
  year={2000}
}

@article{zhang2024multi,
  title={Multi-agent reinforcement learning for autonomous driving: A survey},
  author={Zhang, Ruiqi and Hou, Jing and Walter, Florian and Gu, Shangding and Guan, Jiayi and R{\"o}hrbein, Florian and Du, Yali and Cai, Panpan and Chen, Guang and Knoll, Alois},
  journal={arXiv preprint arXiv:2408.09675},
  year={2024}
}

@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@inproceedings{kim2023adaptive,
  title={An adaptive entropy-regularization framework for multi-agent reinforcement learning},
  author={Kim, Woojun and Sung, Youngchul},
  booktitle={International Conference on Machine Learning},
  pages={16829--16852},
  year={2023},
  organization={PMLR}
}
@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={178},
  pages={1--51},
  year={2020}
}


@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{thomaz2006reinforcement,
  title={Reinforcement learning with human teachers: Evidence of feedback and guidance with implications for learning performance},
  author={Thomaz, Andrea Lockerd and Breazeal, Cynthia and others},
  booktitle={Aaai},
  volume={6},
  pages={1000--1005},
  year={2006},
  organization={Boston, MA}
}
@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@book{sadigh2017active,
  title={Active preference-based learning of reward functions},
  author={Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A},
  year={2017}
}
@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{kwon2023reward,
  title={Reward design with language models},
  author={Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2303.00001},
  year={2023}
}
@article{yu2023language,
  title={Language to rewards for robotic skill synthesis},
  author={Yu, Wenhao and Gileadi, Nimrod and Fu, Chuyuan and Kirmani, Sean and Lee, Kuang-Huei and Arenas, Montse Gonzalez and Chiang, Hao-Tien Lewis and Erez, Tom and Hasenclever, Leonard and Humplik, Jan and others},
  journal={arXiv preprint arXiv:2306.08647},
  year={2023}
}
@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}
@inproceedings{du2023guiding,
  title={Guiding pretraining in reinforcement learning with large language models},
  author={Du, Yuqing and Watkins, Olivia and Wang, Zihan and Colas, C{\'e}dric and Darrell, Trevor and Abbeel, Pieter and Gupta, Abhishek and Andreas, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={8657--8677},
  year={2023},
  organization={PMLR}
}
@article{klissarov2023motif,
  title={Motif: Intrinsic motivation from artificial intelligence feedback},
  author={Klissarov, Martin and D'Oro, Pierluca and Sodhani, Shagun and Raileanu, Roberta and Bacon, Pierre-Luc and Vincent, Pascal and Zhang, Amy and Henaff, Mikael},
  journal={arXiv preprint arXiv:2310.00166},
  year={2023}
}
@article{wang2024rl,
  title={RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback},
  author={Wang, Yufei and Sun, Zhanyi and Zhang, Jesse and Xian, Zhou and Biyik, Erdem and Held, David and Erickson, Zackory},
  journal={arXiv preprint arXiv:2402.03681},
  year={2024}
}
@article{xie2023text2reward,
  title={Text2reward: Automated dense reward function generation for reinforcement learning},
  author={Xie, Tianbao and Zhao, Siheng and Wu, Chen Henry and Liu, Yitao and Luo, Qian and Zhong, Victor and Yang, Yanchao and Yu, Tao},
  journal={arXiv preprint arXiv:2309.11489},
  year={2023}
}


@inproceedings{guo2023explainable,
  title={Explainable action advising for multi-agent reinforcement learning},
  author={Guo, Yue and Campbell, Joseph and Stepputtis, Simon and Li, Ruiyu and Hughes, Dana and Fang, Fei and Sycara, Katia},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5515--5521},
  year={2023},
  organization={IEEE}
}


@inproceedings{campbell2023introspective,
  title={Introspective action advising for interpretable transfer learning},
  author={Campbell, Joseph and Guo, Yue and Xie, Fiona and Stepputtis, Simon and Sycara, Katia},
  booktitle={Conference on Lifelong Learning Agents},
  pages={1072--1090},
  year={2023},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}


@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}

@article{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{lee2021pebble,
  title={Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training},
  author={Lee, Kimin and Smith, Laura and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2106.05091},
  year={2021}
}

@article{lee2021b,
  title={B-pref: Benchmarking preference-based reinforcement learning},
  author={Lee, Kimin and Smith, Laura and Dragan, Anca and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2111.03026},
  year={2021}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@misc{schulman2017proximal,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{skalse2022defining,
  title={Defining and characterizing reward gaming},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9460--9471},
  year={2022}
}


@article{arora2021survey,
  title={A survey of inverse reinforcement learning: Challenges, methods and progress},
  author={Arora, Saurabh and Doshi, Prashant},
  journal={Artificial Intelligence},
  volume={297},
  pages={103500},
  year={2021},
  publisher={Elsevier}
}



@inproceedings{ramachandran2007bayesian,
  title={Bayesian Inverse Reinforcement Learning.},
  author={Ramachandran, Deepak and Amir, Eyal},
  booktitle={IJCAI},
  volume={7},
  pages={2586--2591},
  year={2007}
}

@article{wulfmeier2015maximum,
  title={Maximum entropy deep inverse reinforcement learning},
  author={Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  journal={arXiv preprint arXiv:1507.04888},
  year={2015}
}

@article{zhang2023siren,
  title={Siren's song in the AI ocean: a survey on hallucination in large language models},
  author={Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao, Enbo and Zhang, Yu and Chen, Yulong and others},
  journal={arXiv preprint arXiv:2309.01219},
  year={2023}
}
@inproceedings{el2016score,
  title={Score-based inverse reinforcement learning},
  author={El Asri, Layla and Piot, Bilal and Geist, Matthieu and Laroche, Romain and Pietquin, Olivier},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2016)},
  year={2016}
}

@article{lyu2024calibrating,
  title={Calibrating Large Language Models with Sample Consistency},
  author={Lyu, Qing and Shridhar, Kumar and Malaviya, Chaitanya and Zhang, Li and Elazar, Yanai and Tandon, Niket and Apidianaki, Marianna and Sachan, Mrinmaya and Callison-Burch, Chris},
  journal={arXiv preprint arXiv:2402.13904},
  year={2024}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{kim2023aligning,
  title={Aligning large language models through synthetic feedback},
  author={Kim, Sungdong and Bae, Sanghwan and Shin, Jamin and Kang, Soyoung and Kwak, Donghyun and Yoo, Kang Min and Seo, Minjoon},
  journal={arXiv preprint arXiv:2305.13735},
  year={2023}
}

@article{akyurek2023rl4f,
  title={Rl4f: Generating natural language feedback with reinforcement learning for repairing model outputs},
  author={Aky{\"u}rek, Afra Feyza and Aky{\"u}rek, Ekin and Madaan, Aman and Kalyan, Ashwin and Clark, Peter and Wijaya, Derry and Tandon, Niket},
  journal={arXiv preprint arXiv:2305.08844},
  year={2023}
}

@misc{brockman2016openai,
      title={OpenAI Gym}, 
      author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
      year={2016},
      eprint={1606.01540},
      archivePrefix={arXiv},
      primaryClass={id='cs.LG' full_name='Machine Learning' is_active=True alt_name=None in_archive='cs' is_general=False description='Papers on all aspects of machine learning research (supervised, unsupervised, reinforcement learning, bandit problems, and so on) including also robustness, explanation, fairness, and methodology. cs.LG is also an appropriate primary category for applications of machine learning methods.'}
}

@inproceedings{tanneru2024quantifying,
  title={Quantifying uncertainty in natural language explanations of large language models},
  author={Tanneru, Sree Harsha and Agarwal, Chirag and Lakkaraju, Himabindu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1072--1080},
  year={2024},
  organization={PMLR}
}

@article{wang2024srlm,
  title={SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning},
  author={Wang, Weizheng and Mao, Le and Wang, Ruiqi and Min, Byung-Cheol},
  journal={arXiv preprint arXiv:2403.15648},
  year={2024}
}


@article{shen2024beyond,
  title={Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs},
  author={Shen, Zichao and Zhu, Tianchen and Sun, Qingyun and Gao, Shiqi and Li, Jianxin},
  journal={arXiv preprint arXiv:2406.19644},
  year={2024}
}

@article{swamy2024minimaximalist,
  title={A minimaximalist approach to reinforcement learning from human feedback},
  author={Swamy, Gokul and Dann, Christoph and Kidambi, Rahul and Wu, Zhiwei Steven and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2401.04056},
  year={2024}
}


@article{matignon2012independent,
  title={Independent reinforcement learners in cooperative markov games: a survey regarding coordination problems},
  author={Matignon, Laetitia and Laurent, Guillaume J and Le Fort-Piat, Nadine},
  journal={The Knowledge Engineering Review},
  volume={27},
  number={1},
  pages={1--31},
  year={2012},
  publisher={Cambridge University Press}
}

@article{WoJe95,
  title = {Intelligent Agents: Theory and Practice},
  author = {Wooldridge, Michael J. and Jennings, Nicholas R.},
  journal = {The Knowledge Engineering Review},
  volume = {10},
  number = {2},
  pages = {115--152},
  year = {1995}
}

@article{GrKr96,
  title = {Collaborative Plans for Complex Group Action},
  author = {Grosz, Barbara J. and Kraus, Sarit},
  journal = {Artificial Intelligence},
  volume = {86},
  number = {2},
  pages = {269--357},
  year = {1996}
}

@Techreport{Har78,
  author =       "David Harel",
  year =         "1978",
  title =        "Logics of programs: axiomatics and descriptive power",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         ""
}

@Phdthesis{Cla85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        ""
}

@misc{Oba08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A More Perfect Union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  ""
}

@misc{Sci09,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = ""
}

@ArtifactDataset{AnMC13,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 organization = {University of Massachusetts},
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}

@inproceedings{Hag1993,
title        = {Maintaining Discrete Probability Distributions Optimally},
author       = {Hagerup, Torben and Mehlhorn, Kurt and Munro, J. Ian},
booktitle    = {Proceedings of the 20th International Colloquium on Automata, Languages and Programming},
series       = {Lecture Notes in Computer Science},
volume       = {700},
pages        = {253--264},
year         = {1993},
publisher    = {Springer-Verlag},
address      = {Berlin}
}

@Book{Knu97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms",
  publisher =    "Addison Wesley",
  year =         "1997",
  address =      "Reading, Massachusetts",
  edition =      "3rd",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         ""
}

@MASTERSTHESIS{Ani03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@article{wang2020qplex,
  title={Qplex: Duplex dueling multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2008.01062},
  year={2020}
}

@inproceedings{son2019qtran,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International conference on machine learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@inproceedings{lin2024navigating,
  title={Navigating Noisy Feedback: Enhancing Reinforcement Learning with Error-Prone Language Models},
  author={Lin, Muhan and Shi, Shuyang and Guo, Yue and Chalaki, Behdad and Tadiparthi, Vaishnav and Pari, Ehsan Moradi and Stepputtis, Simon and Campbell, Joseph and Sycara, Katia},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  year={2024}
}

@article{knox2023reward,
  title={Reward (mis) design for autonomous driving},
  author={Knox, W Bradley and Allievi, Alessandro and Banzhaf, Holger and Schmitt, Felix and Stone, Peter},
  journal={Artificial Intelligence},
  volume={316},
  pages={103829},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{booth2023perils,
  title={The perils of trial-and-error reward design: misdesign through overfitting and invalid task specifications},
  author={Booth, Serena and Knox, W Bradley and Shah, Julie and Niekum, Scott and Stone, Peter and Allievi, Alessandro},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={5},
  pages={5920--5929},
  year={2023}
}

@article{du2019liir,
  title={Liir: Learning individual intrinsic reward in multi-agent reinforcement learning},
  author={Du, Yali and Han, Lei and Fang, Meng and Liu, Ji and Dai, Tianhong and Tao, Dacheng},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}
