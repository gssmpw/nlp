@inproceedings{ngiam2011multimodal,
  title={Multimodal deep learning},
  author={Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={689--696},
  year={2011}
}

@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={2},
  pages={423--443},
  year={2018},
  publisher={IEEE}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{girdhar2023imagebind,
  title={Imagebind: One embedding space to bind them all},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15180--15190},
  year={2023}
}

@article{ektefaie2023multimodal,
  title={Multimodal learning with graphs},
  author={Ektefaie, Yasha and Dasoulas, George and Noori, Ayush and Farhat, Maha and Zitnik, Marinka},
  journal={Nature Machine Intelligence},
  volume={5},
  number={4},
  pages={340--350},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{yoon2023multimodal,
  title={Multimodal graph learning for generative tasks},
  author={Yoon, Minji and Koh, Jing Yu and Hooi, Bryan and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2310.07478},
  year={2023}
}

@article{zhu2024multimodal,
  title={Multimodal Graph Benchmark},
  author={Zhu, Jing and Zhou, Yuhang and Qian, Shengyi and He, Zhongmou and Zhao, Tong and Shah, Neil and Koutra, Danai},
  journal={arXiv preprint arXiv:2406.16321},
  year={2024}
}

@misc{he2024unigraphlearningunifiedcrossdomain,
      title={UniGraph: Learning a Unified Cross-Domain Foundation Model for Text-Attributed Graphs}, 
      author={Yufei He and Yuan Sui and Xiaoxin He and Bryan Hooi},
      year={2024},
      eprint={2402.13630},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.13630}, 
}

@inproceedings{heharnessing,
  title={Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning},
  author={He, Xiaoxin and Bresson, Xavier and Laurent, Thomas and Perold, Adam and LeCun, Yann and Hooi, Bryan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{chiennode,
  title={Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction},
  author={Chien, Eli and Chang, Wei-Cheng and Hsieh, Cho-Jui and Yu, Hsiang-Fu and Zhang, Jiong and Milenkovic, Olgica and Dhillon, Inderjit S},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@article{he2024g,
  title={G-retriever: Retrieval-augmented generation for textual graph understanding and question answering},
  author={He, Xiaoxin and Tian, Yijun and Sun, Yifei and Chawla, Nitesh V and Laurent, Thomas and LeCun, Yann and Bresson, Xavier and Hooi, Bryan},
  journal={arXiv preprint arXiv:2402.07630},
  year={2024}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{jaegleperceiver,
  title={Perceiver IO: A General Architecture for Structured Inputs \& Outputs},
  author={Jaegle, Andrew and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Doersch, Carl and Ionescu, Catalin and Ding, David and Koppula, Skanda and Zoran, Daniel and Brock, Andrew and Shelhamer, Evan and others},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@inproceedings{baobeit,
  title={BEiT: BERT Pre-Training of Image Transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{wang2023one,
  title={One-peace: Exploring one general representation model toward unlimited modalities},
  author={Wang, Peng and Wang, Shijie and Lin, Junyang and Bai, Shuai and Zhou, Xiaohuan and Zhou, Jingren and Wang, Xinggang and Zhou, Chang},
  journal={arXiv preprint arXiv:2305.11172},
  year={2023}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{schafer2001commerce,
  title={E-commerce recommendation applications},
  author={Schafer, J Ben and Konstan, Joseph A and Riedl, John},
  journal={Data mining and knowledge discovery},
  volume={5},
  pages={115--153},
  year={2001},
  publisher={Springer}
}

@inproceedings{gao2022graph,
  title={Graph neural networks for recommender system},
  author={Gao, Chen and Wang, Xiang and He, Xiangnan and Li, Yong},
  booktitle={Proceedings of the fifteenth ACM international conference on web search and data mining},
  pages={1623--1625},
  year={2022}
}

@inproceedings{chen2022hybrid,
  title={Hybrid transformer with multi-level fusion for multimodal knowledge graph completion},
  author={Chen, Xiang and Zhang, Ningyu and Li, Lei and Deng, Shumin and Tan, Chuanqi and Xu, Changliang and Huang, Fei and Si, Luo and Chen, Huajun},
  booktitle={Proceedings of the 45th international ACM SIGIR conference on research and development in information retrieval},
  pages={904--915},
  year={2022}
}

@inproceedings{zeng2023multi,
  title={Multi-modal knowledge hypergraph for diverse image retrieval},
  author={Zeng, Yawen and Jin, Qin and Bao, Tengfei and Li, Wenfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={3},
  pages={3376--3383},
  year={2023}
}

@article{wang2023hypergraph,
  title={Hypergraph-regularized multimodal learning by graph diffusion for imaging genetics based alzheimerâ€™s disease diagnosis},
  author={Wang, Meiling and Shao, Wei and Huang, Shuo and Zhang, Daoqiang},
  journal={Medical Image Analysis},
  volume={89},
  pages={102883},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{jinlearning,
  title={Learning Multimodal Graph-to-Graph Translation for Molecule Optimization},
  author={Jin, Wengong and Yang, Kevin and Barzilay, Regina and Jaakkola, Tommi},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{galkin2023towards,
  title={Towards foundation models for knowledge graph reasoning},
  author={Galkin, Mikhail and Yuan, Xinyu and Mostafa, Hesham and Tang, Jian and Zhu, Zhaocheng},
  journal={ICLR},
  year={2024}
}

@inproceedings{xiamole,
  title={Mole-BERT: Rethinking Pre-training Graph Neural Networks for Molecules},
  author={Xia, Jun and Zhao, Chengshuai and Hu, Bozhen and Gao, Zhangyang and Tan, Cheng and Liu, Yue and Li, Siyuan and Li, Stan Z},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{hou2024graphalign,
  title={GraphAlign: Pretraining One Graph Neural Network on Multiple Graphs via Feature Alignment},
  author={Hou, Zhenyu and Li, Haozhan and Cen, Yukuo and Tang, Jie and Dong, Yuxiao},
  journal={arXiv preprint arXiv:2406.02953},
  year={2024}
}

@article{wang2024can,
  title={Can language models solve graph problems in natural language?},
  author={Wang, Heng and Feng, Shangbin and He, Tianxing and Tan, Zhaoxuan and Han, Xiaochuang and Tsvetkov, Yulia},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sui2024fidelis,
  title={FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering},
  author={Sui, Yuan and He, Yufei and Liu, Nian and He, Xiaoxin and Wang, Kun and Hooi, Bryan},
  journal={arXiv preprint arXiv:2405.13873},
  year={2024}
}

@article{zhang2024can,
  title={Can LLM Graph Reasoning Generalize beyond Pattern Memorization?},
  author={Zhang, Yizhuo and Wang, Heng and Feng, Shangbin and Tan, Zhaoxuan and Han, Xiaochuang and He, Tianxing and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2406.15992},
  year={2024}
}

@article{liu2023one,
  title={One for all: Towards training one graph model for all classification tasks},
  author={Liu, Hao and Feng, Jiarui and Kong, Lecheng and Liang, Ningyue and Tao, Dacheng and Chen, Yixin and Zhang, Muhan},
  journal={ICLR},
  year={2024}
}

@article{muennighoff2022mteb,
  title={MTEB: Massive text embedding benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  journal={arXiv preprint arXiv:2210.07316},
  year={2022}
}

@inproceedings{zhaolearning,
  title={Learning on Large-scale Text-attributed Graphs via Variational Inference},
  author={Zhao, Jianan and Qu, Meng and Li, Chaozhuo and Yan, Hao and Liu, Qian and Li, Rui and Xie, Xing and Tang, Jian},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{zhao2024all,
  title={All in one and one for all: A simple yet effective method towards cross-domain graph pretraining},
  author={Zhao, Haihong and Chen, Aochuan and Sun, Xiangguo and Cheng, Hong and Li, Jia},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={4443--4454},
  year={2024}
}

@inproceedings{hou2023graphmae2,
  title={Graphmae2: A decoding-enhanced masked self-supervised graph learner},
  author={Hou, Zhenyu and He, Yufei and Cen, Yukuo and Liu, Xiao and Dong, Yuxiao and Kharlamov, Evgeny and Tang, Jie},
  booktitle={Proceedings of the ACM web conference 2023},
  pages={737--746},
  year={2023}
}

@inproceedings{thakoor2021bootstrapped,
  title={Bootstrapped representation learning on graphs},
  author={Thakoor, Shantanu and Tallec, Corentin and Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Veli{\v{c}}kovi{\'c}, Petar and Valko, Michal},
  booktitle={ICLR 2021 Workshop on Geometrical and Topological Representation Learning},
  year={2021}
}

@inproceedings{velivckovic2018graph,
  title={Graph Attention Networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{huang2024prodigy,
  title={Prodigy: Enabling in-context learning over graphs},
  author={Huang, Qian and Ren, Hongyu and Chen, Peng and Kr{\v{z}}manc, Gregor and Zeng, Daniel and Liang, Percy S and Leskovec, Jure},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{liuone,
  title={One For All: Towards Training One Graph Model For All Classification Tasks},
  author={Liu, Hao and Feng, Jiarui and Kong, Lecheng and Liang, Ningyue and Tao, Dacheng and Chen, Yixin and Zhang, Muhan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{burns2023suite,
  title={A suite of generative tasks for multi-level multimodal webpage understanding},
  author={Burns, Andrea and Srinivasan, Krishna and Ainslie, Joshua and Brown, Geoff and Plummer, Bryan A and Saenko, Kate and Ni, Jianmo and Guo, Mandy},
  journal={arXiv preprint arXiv:2305.03668},
  year={2023}
}

@article{he2024generalizing,
  title={Generalizing Graph Transformers Across Diverse Graphs and Tasks via Pre-Training on Industrial-Scale Data},
  author={He, Yufei and Hou, Zhenyu and Cen, Yukuo and He, Feng and Cheng, Xu and Hooi, Bryan},
  journal={arXiv preprint arXiv:2407.03953},
  year={2024}
}

@inproceedings{qiu2020gcc,
  title={Gcc: Graph contrastive coding for graph neural network pre-training},
  author={Qiu, Jiezhong and Chen, Qibin and Dong, Yuxiao and Zhang, Jing and Yang, Hongxia and Ding, Ming and Wang, Kuansan and Tang, Jie},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={1150--1160},
  year={2020}
}

@article{gasteiger2018predict,
  title={Predict then propagate: Graph neural networks meet personalized pagerank},
  author={Gasteiger, Johannes and Bojchevski, Aleksandar and G{\"u}nnemann, Stephan},
  journal={International Conference on Learning Representations},
  year={2018}
}

@article{bianchini2005inside,
  title={Inside pagerank},
  author={Bianchini, Monica and Gori, Marco and Scarselli, Franco},
  journal={ACM Transactions on Internet Technology (TOIT)},
  volume={5},
  number={1},
  pages={92--128},
  year={2005},
  publisher={ACM New York, NY, USA}
}

@inproceedings{lofgren2016personalized,
  title={Personalized pagerank estimation and search: A bidirectional approach},
  author={Lofgren, Peter and Banerjee, Siddhartha and Goel, Ashish},
  booktitle={Proceedings of the Ninth ACM International Conference on Web Search and Data Mining},
  pages={163--172},
  year={2016}
}

@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22118--22133},
  year={2020}
}

@article{he2023harnessing,
  title={Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning}, 
  author={Xiaoxin He and Xavier Bresson and Thomas Laurent and Adam Perold and Yann LeCun and Bryan Hooi},
  year={2024},
  journal={International Conference on Learning Representations}
}

@article{mernyei2020wiki,
  title={Wiki-cs: A wikipedia-based benchmark for graph neural networks},
  author={Mernyei, P{\'e}ter and Cangea, C{\u{a}}t{\u{a}}lina},
  journal={arXiv preprint arXiv:2007.02901},
  year={2020}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{wang2024graph,
  title={Graph mixture of experts: Learning on large-scale graphs with explicit diversity modeling},
  author={Wang, Haotao and Jiang, Ziyu and You, Yuning and Han, Yan and Liu, Gaowen and Srinivasa, Jayanth and Kompella, Ramana and Wang, Zhangyang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wu2023graphmetro,
  title={Graphmetro: Mitigating complex distribution shifts in gnns via mixture of aligned experts},
  author={Wu, Shirley and Cao, Kaidi and Ribeiro, Bruno and Zou, James and Leskovec, Jure},
  journal={arXiv preprint arXiv:2312.04693},
  year={2023}
}

@inproceedings{hou2022graphmae,
  title={Graphmae: Self-supervised masked graph autoencoders},
  author={Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={594--604},
  year={2022}
}