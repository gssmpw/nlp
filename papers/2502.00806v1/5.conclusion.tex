% \vspace{-3mm}
\section{Conclusion}
\model addresses the limitations of existing foundation models for multimodal graphs by introducing a novel unified embedding space that effectively integrates both multimodal information and graph structures. By employing modality-specific encoders, a graph neural network, and a Mixture of Experts module, UniGraph2 outperforms state-of-the-art models in tasks such as classification, transfer learning, and multimodal generation. Extensive experiments demonstrate the model's generalization capabilities across diverse graph domains and modalities, confirming its potential as a scalable and flexible solution for learning on multimodal graphs.

\vspace{-3mm}

\begin{acks}
    This research is supported by the Ministry of Education, Singapore, under the Academic Research Fund Tier 2 (FY2025) (Award MOE-T2EP20124-0009).
\end{acks}