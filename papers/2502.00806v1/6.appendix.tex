\appendix
\begin{figure}
    \centering
    \includegraphics[width=1.0\linewidth]{figs/fig1.pdf}
    \vskip -0.1in
    \caption{\model binds multimodal graphs from different graph domains to a unified embedding space, enabling diverse downstream tasks.}
    \label{fig:fig1}
    % \vspace{-6mm}
\end{figure}

\begin{table*}[t]
\centering
\caption{\textbf{Statistics of all 14 multimodal graph datasets.}}
% \vskip 0.1in
\label{tab:dataset}
%\renewcommand\tabcolsep{4.3pt}
\begin{tabular}{lrrrrc}
\toprule[1.1pt]
Dataset & Domain & Task & \#Nodes & \#Edges & Raw Features \\
\midrule
Cora & Citation & Node  & 2,708 & 5,429  & Paper Titles and Abstracts \\
PubMed & Citation & Node  & 19,717 & 44,338 & Paper Titles and Abstracts \\
ogbn-Arxiv & Citation & Node  & 169,343 & 1,166,243  & Paper Titles and Abstracts \\
ogbn-Papers100M & Citation & Node  & 111,059,956	& 1,615,685,872	& Paper Titles and Abstracts \\
ogbn-Products & Product  & Node & 2,449,029 & 61,859,140 & Product Descriptions \\
Wiki-CS & Wikipedia & Node & 11,701 & 216,123 & Wikipedia Entry Names and Contents \\
Ele-fashion  & Product & Node &  97,766 & 199,602 & Fashion Titles and Fashion Images\\ 
Goodreads-NC & Book & Node &  685,294 & 7,235,084 & Book Descriptions and Book Images \\ 
FB15K237 & Knowledge & Edge & 14,541 & 310,116 &  Entity Names and Descriptions \\
WN18RR & Knowledge & Edge & 40,943 & 93,003 &  Entity Names and Descriptions \\
Amazon-Sports & Product  & Edge & 50,250 & 356,202 & Product Titles and Product Images\\ 
Amazon-Cloth & Product  & Edge  & 125,839 &951,271& Product Titles and Product Images \\ 
Goodreads-LP & Book  & Edge &  636,502 &3,437,017 & Book Descriptions and Book Images \\ 
WikiWeb2M & Wikipedia & Generative & 600,000 & - & Page Title, Section Titles, Section Text, Images\\

\bottomrule[1.1pt]
\end{tabular}
%\vspace{-4mm}
\end{table*}

\begin{table*}[t]
\centering
\caption{Notation Table}
\begin{tabular}{cl}
\toprule[1.1pt]
\textbf{Symbol} & \textbf{Description} \\ 
\midrule
$\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{M}, \Omega)$ & A Multimodal Graph (MMG). \\ 
$\mathcal{V}$ & Set of nodes in the graph. \\ 
$\mathcal{E}$ & Set of edges in the graph. \\
$\Omega$ & Set of possible modalities (e.g., text, images). \\ 
$\mathcal{M}(v)$ & Function that maps each node $v \in \mathcal{V}$ to a subset of modalities $\Omega_v \subseteq \Omega$. \\ 
$\mathcal{G}_{\text{TAG}} = (\mathcal{V}, \mathcal{E}, \mathcal{M}, \{\text{text}\})$ & Text-attributed graph where each node has an associated text feature. \\ 
$f: \mathcal{V}_k \rightarrow \mathbb{R}^d$ & Pre-trained model for representation learning, mapping nodes to a $d$-dimensional embedding space. \\ 
$\mH_{\text{inf}}$ & Inference embeddings generated by applying the pre-trained model to a new graph. \\ 
$\vx^{(\omega)}_i$ & Feature vector for node $v_i$ from modality $\omega$. \\ 
$\mathcal{G}_{\text{inf}} = (\mathcal{V}_{\text{inf}}, \mathcal{E}_{\text{inf}}, \mathcal{M}_{\text{inf}})$ & Inference graph where the pre-trained model generates embeddings for nodes. \\ 
$\mathcal{L}_{\text{feature}}$ & Feature reconstruction loss for reconstructing masked node features. \\ 
$\mathcal{L}_{\text{SPD}}$ & Shortest path distance reconstruction loss used for structural reconstruction. \\ 
$\lambda$ & Mixing coefficient for combining feature and structure reconstruction losses. \\ 
\bottomrule[1.1pt]
\end{tabular}

\label{tab:preliminaries}
\end{table*}

\section{Datasets}

\vpara{Cora}~\cite{he2023harnessing}. The Cora dataset consists of 2708 scientific publications classified into one of seven classes – case based, genetic algorithms, neural networks, probabilistic methods, reinforcement learning, rule learning, and theory. The citation network consists of 5429 links. We collect raw text from ~\cite{he2023harnessing}.

\vpara{PubMed}~\cite{he2023harnessing}. The Pubmed dataset consists of 19,717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes – Experimental induced diabetes, Type 1 diabetes, and Type 2 diabetes. 
As in~\cite{liu2023one}, we ask ChatGPT to generate a detailed description of each category. The citation network consists of 44,338 links. We collect raw text from ~\cite{he2023harnessing}.

\vpara{ogbn-Arxiv}~\cite{hu2020open}. The ogbn-arxiv dataset is a directed graph, representing the citation network between all Computer Science (CS) arXiv papers. Each node is an arXiv paper and each directed edge indicates that one paper cites another one. The task is to predict the 40 subject areas of arXiv CS papers, e.g.,, cs.AI, cs.LG, and cs.OS. We collect raw text from ~\cite{hu2020open}.

\vpara{ogbn-Papers100M}~\cite{hu2020open}. The ogbn-papers100M dataset is a directed citation graph of 111 million papers. We collect raw text from ~\cite{hu2020open}.

\vpara{ogbn-Products}~\cite{hu2020open}. The ogbn-products dataset is an undirected and unweighted graph, representing an Amazon product co-purchasing network. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. The task is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels. We collect raw text from ~\cite{hu2020open}.

\vpara{Wiki-CS}~\cite{liu2023one}. Wiki-CS is a Internet link network with each node represent a Wikipedia page and each edge represent the reference link. Each node’s label corresponds to the category of the entry. We collect raw text from ~\cite{liu2023one}.

\vpara{FB15K237}~\cite{liu2023one}. FB15K237 is a kowledge graph that contains knowledge base relation triples and textual mentions of Freebase entity pairs. We collect raw text from ~\cite{liu2023one}. Given that we propose a self-supervised learning framework, and the edge text features are the labels to be predicted, we solely utilized node text features and did not employ edge text features.

\vpara{WN18RR}~\cite{liu2023one}. WN18RR is a knowledge graph, which is a subset of WordNet that consists of 11 relations and 40943 entities.
We collect raw text from ~\cite{liu2023one}. Given that we propose a self-supervised learning framework, and the edge text features are the labels to be predicted, we solely utilized node text features and did not employ edge text features.

\vpara{Amazon-Sports}~\cite{zhu2024multimodal}. Amazon-Sports is a link prediction dataset derived from the Amazon-Review dataset. In this dataset, each node represents a product within the sports category on Amazon, and the links signify whether two products are often purchased together. The textual features consist of product titles, while the visual features are raw high-resolution images of the products. We collect raw text and images from ~\cite{zhu2024multimodal}.

\vpara{Amazon-Cloth}~\cite{zhu2024multimodal}. Amazon-Cloth follows a similar structure to Amazon-Sports, but focuses on clothing products. The dataset uses co-purchase information from the clothes category on Amazon. The text features include product titles, such as "Nike Men's Revolution 6 Road Running," and the visual features are the associated product images. We collect raw text and images from ~\cite{zhu2024multimodal}.

\vpara{Goodreads-LP}~\cite{zhu2024multimodal}. Goodreads-LP is based on the Goodreads Book Graph dataset. In this dataset, nodes correspond to books, and the links represent whether users who like one book are likely to enjoy another. Text features describe the books, and the visual features are book cover images. Books without images are excluded from the dataset. We collect raw text and images from ~\cite{zhu2024multimodal}.

\vpara{Goodreads-NC}~\cite{zhu2024multimodal}. Goodreads-NC is a node classification dataset also based on the Goodreads dataset. Here, each node represents a book, and the links signify whether users who liked one book will like another. The textual features describe the books, and the visual features are book cover images. Books lacking images are removed. We collect raw text and images from ~\cite{zhu2024multimodal}.

\vpara{Ele-Fashion}~\cite{zhu2024multimodal}. Ele-Fashion is a node classification dataset derived from the Amazon-Fashion dataset. In this dataset, each node represents a fashion product, and links indicate that users who buy one product are likely to purchase another. The textual features are product titles, and the visual features consist of product images. We collect raw text and images from ~\cite{zhu2024multimodal}.

\vpara{WikiWeb2M}~\cite{burns2023suite}. The WikiWeb2M dataset is designed for multimodal content understanding, using many-to-many text and image relationships from Wikipedia. It includes page titles, section titles, section text, images, and indices for each section.

\section{Implementation Notes}
\label{appendix:imple}
\vpara{Running environment.}
All experiments are conducted on Linux machine with 945G RAM, and 8 NVIDIA A100 with 40GB GPU memory. For software versions, we use Python 3.11, Pytorch 2.0.1, DGL 1.1.2, transformers 4.32.1 and CUDA 11.8. Our code and datasets will be available.

\vpara{Hyper-parameters.}
The detailed pre-training hyper-parameters are listed in Table~\ref{tab:hyper}. 
For linear probing, we train the linear classifier using adam optimizer with lr=0.01 for 5000 epochs, and report the early-stopping results.
\begin{table*}[h] 
    \centering
    \caption{Pre-training hyper-parameters for our framework.}
    % \vskip 0.1in
    \label{tab:hyper}
    \renewcommand\tabcolsep{2.8pt}
    \begin{tabular}{ccccccccccc}
    \toprule[1.1pt]
       mask rate  & hidden\_size & lr & weight\_decay & dropout & optimizer & num\_epochs & num\_gnn\_layers & ppr topk & num\_experts & coefficient $\lambda$\\
    \midrule
      0.8  & 1024 & 1e-3 & 0.01 & 0.4 & adamw & 5 & 4 & 256 & 8 & 0.1\\
    \bottomrule[1.1pt]
    \end{tabular}
\end{table*}


\vpara{Baselines.}
To have a fair comparison, we download the public source code. For methods can not scale, we adapt their code to integrate with sampling algorithms to run on large-scale graphs. The sources of the codes used are as follows:
\begin{itemize}
    \item BRGL: \url{https://github.com/Namkyeong/BGRL\_Pytorch}
    \item GraphMAE2: \url{https://github.com/THUDM/GraphMAE2}
    \item GIANT-XRT: \url{https://github.com/amzn/pecos/tree/mainline/examples/giant-xrt}
    \item Prodigy: \url{https://github.com/snap-stanford/prodigy}
    \item OFA: \url{https://github.com/LechengKong/OneForAll}
    \item UniGraph: \url{https://github.com/yf-he/UniGraph}
    \item CLIP: \url{https://github.com/openai/CLIP}
    \item ImageBind: \url{https://github.com/facebookresearch/ImageBind}
    \item GCOPE: \url{https://github.com/cshhzhao/gcope}
    \item MMGL: \url{https://github.com/minjiyoon/MMGL}
\end{itemize}

\vpara{Datasets splits.}
For Cora and PubMed, we follow commonly used data splits, using 20 labeled nodes per class as the training set, 30 nodes per class as the validation set, and the rest as the test set. We report the average accuracy on test set with 20 random initialization.

For Arxiv and Products, we follow the official splits~\cite{hu2020open}. Following the experimental procedure suggested by OGB, we repeat each experiment for 10 times with random seeds and report the average accuracy.

For Wiki-CS, we follow the official splits~\cite{mernyei2020wiki} with 20 different training splits, we report the average accuracy on the 20 different training splits with 20 random initialization. In each split, 5\% of the nodes in each class are used for training.

For FB15K237 and WN18RR, we follow splits in OFA~\cite{liu2023one}. 
For FB15K237, training set has 272115 edges, validation set has 17535 edges and test set has 20466 edges.
For WN18RR, training set has 86835 edges, validation set has 3034 edges and test set has 3134 edges. We repeat each experiment for 10 times with random seeds and report the average accuracy.

For Amazon-Sports, Amazon-Cloth, Goodreads-LP, Goodreads-NC, and Ele-Fashion, we follow the official splits~\cite{zhu2024multimodal}. We repeat each experiment for 10 times with random seeds and report the average accuracy.

For WikiWeb2M, we follow the split and setting in MMGL~\cite{yoon2023multimodal}.



\vpara{Linear probing.}
The dataset \(\mathcal{D}\) after generating embeddings, comprising embedding-label pairs \((\vh, y)\), is divided into training, validation, and test sets. 
A linear classifier with weight matrix \( \mW \in \mathbb{R}^{d \times |\mathcal{Y}|} \) is trained at top the embeddings from the frozen model, aiming to minimize the loss function \(\mathcal{L}\), typically cross-entropy, over the training set: \(\min_\mW \sum_{(\vh, y) \in \mathcal{D}_{\text{train}}} \mathcal{L}(\mW \cdot \vh, y)\). 
The performance of the model is evaluated based on a performance metric \( \mathcal{M} \), which can be defined generically as \(\mathcal{M}(\mathcal{D}_{\text{eval}}, f_{\theta}, \mW)\), where \(\mathcal{D}_{\text{eval}}\) refers to either the validation or test set. 

\vpara{Few-shot transfer.}
Our method follows in-context learning approach in UniGraph~\cite{he2024unigraphlearningunifiedcrossdomain}, and for baselines we either follow the same approach or use their already proposed in-context learning methods (Prodigy, OFA). We repeat each experiment for 10 times with random seeds and report the average accuracy.
All the other experimental details (pre-training) follow those for the previous experiment (i.e., linear probing). 


\section{Mixture of Experts (MoE) in Graph Learning}
Mixture of Experts (MoE) is a machine learning architecture that distributes the learning task across several specialized expert models. In various implementations of MoE in graph neural networks (GNNs), each expert model is typically responsible for learning specific components of the data or task, and a gating model selects which expert(s) to activate for each input, effectively combining their outputs. As in MoE in NLP, most MoE in graph learning are designed to improve efficiency in inference~\cite{wang2024graph}. Other works also use MoE to handle different challenges like distribution shifts. In GraphMETRO~\cite{wu2023graphmetro}, MoE addresses complex graph distribution shifts by assigning each expert to deal with a specific shift type, while a gating model selects the relevant experts to produce shift-invariant representations. GraphAlign~\cite{hou2024graphalign} uses a feature normalization step and employs MoE at the input layer to assign nodes to experts, ensuring a unified distribution across graphs before GNN training. In this work, UniGraph2 employs MoE to align multimodal features (e.g., text, images) from various graph domains, ensuring coherent embeddings across modalities and domains.


