
\section{Introduction}
\label{sec:intro}

Code search is a task to retrieve code snippets from the given query whose intent is to find implementations of specific functionality. 
This task is important for both human developers' productivity and LLM's hallucination with RAG 
(\cite{BrownBNMJPA20, LewisEAFVNHMWT20, LeiWWZHQWXBT25}). 
Although the scale-up of programming language models boosts performance of this task, 
the models still are vulnerable to diverse types of shifts (\cite{ArakelyanDMR23}), 
which comes from the evolutions that human developers continuously write new codes for debug or performance improvements.
Adaptation to these evolutions relies on generalization, 
a key mechanism of human intelligence that also drives the application of neural networks across wide range of fields.

We can utilize supervised signals as catalysts for the generalization. 
In spite of the effectiveness, 
only insufficient supervised signals are available as guidances to generalization
due to severity of shifts.
Therefore, it is necessary to analyze adaptation itself for effective utilization of these supervised signals.
Adaptation to shifts is formulated as minimum entropy problem in code search.
However, minimum entropy problem cannot help shifted initialization lead to bad solution (shifted initialization cascade phenomenon).
(\cite{OriRYM24}) demonstrates that this phenomenon occurs in entropy minimization~(\cite
{Yvew04}) 
which is the unsupervised instantiation of minimum entropy problem.

\begin{figure}[h]
\centering
\includegraphics[width=1.\columnwidth]{sections/figures/methodology/figure1.png} 
\caption{
Hypothetical Example of Real World Scenario in Figure 2.
URECA simulates Real World Scenario with simulation trick.
}
\label{fig1}
\end{figure}

We break down the minimum entropy problem in the lens of Lebesgue integral 
to analyze the mechanics of this shifted initialization cascade.
In the process of decomposition, we extend the connection of minimum entropy problem 
to minimum set cover problem towards the unknowns. 
As a result, we find out that minimum entropy problem hides the chain of two minimum set cover problems equipped with greedy algorithm.
This allows us to discover internal mechanism of minimum entropy problem, 
which makes lumps of disentangled representations with little regard to relationships between them.
(\cite{LeeJLPSHY24}) supports this result with analysis 
that entropy minimization neglects the influence of these disentangled representations, 
which leads to unreliable predictions in biased scenarios. 
In addition, (\cite{WilesGSRKDC22}) assists that it is important to understand the disentangled representations for adaptation to distribution shift.
In succession to these insights, 
we focus on the ignorance of minimum entropy problem to the relationships between disentangled representations
and demonstrate that this ignorance leads to shifted initialization cascade in Section 2. 

From this analysis,  we introduce a new clustering algorithm, URECA.
URECA clusters disentangled representations based on the relationships between them. 
URECA consists of three steps, initialization, update and recursion as depicted in Figure 1.
In the process of intialization, URECA fragmentizes samples and initializes clusters with those fragments.
(In this paper, evidence refers to fragment and logit is the weight of clusters of evidences. 
In addition, disentangled representation is the encoding for evidence / fragment.)
We apply the analyses of Theorem 2.1 and 2.2 to the scenario of training neral network.
Then, theoretical relevance of logits and conditional probabilities reveals that the forward propagation and dot product do 
the fragmentization of samples.
Then, minimum entropy problem initializes the cluster based on these fragments.
URECA utilizes this mechanism of neural networks to initialize clusters of fragments. 

In update step, URECA efficiently updates the clusters with transport of fragments from source clusters to target clusters.
Simulation trick makes it possible for URECA to simulate this process with simple calculations of weights of evidences 
for clusters~(\cite{Greiff00}). 
In this paper, we use logits as these weights of evidences for this simulation trick due to the excessive regularization of probabilities.
However, the naive use of logits triggers errors in the process of transport.
We treat this problem by introducing Thresholdly-Updatable Stationary Assumption 
for dynamics.
This assumption makes dynamics to more correctly reflect on the relationships between disentangled representations
by filtering out irrelevant disentangled representations. 
The accurate reflection makes the transported logits as unbiased estimator for the logits of transported probabilities,
which clears out the errors from naive replacement about probabilities.
For the next, we determine the codes in reference to the clusters which are constructed by URECA based on 
the relationships between disentangled representations. 
Finally, we introduce an auxiliary loss about the relationships between codes as media to leverage the relationships between disentangled 
representations, since they are estimated based on the relationships between disentangled representations. 

Our extensive evaluations demonstrate that URECA is consistently superior to baselines for few shot adaptation to diverse shifts. 
Few shot adaptation to shifts is a realistic setting since the harshness of shifts makes harder 
to collect sufficient data in limited time.
In addition, we architect experiments to enable comparative analysis 
through coordination of datasets and baselines for diverse types of shifts like task shift, query shift and 
code shift~(Appendix F.1 $\sim$ F.3).  
These intricate designs for experiments effectively highlight that URECA drives model to general patterns 
which reflect on the relationships between disentangled reprensentations.

Our contributions  are as follows: 
\begin{itemize}
    \item As long as we know, we are the first to prove that the chain of two minimum set cover problems 
          exists behind minimum entropy problem in terms of Lebesgue integral.
          We present analysis that this chain ignores relations between disentangled representations.
          We also prove by construction, for the first time, 
          that minimum entropy problem clusters disentangled representations. 
          
    \item For effective adaptation to diverse shifts,
          we propose new clustering algorithm URECA which reflects on the relationship 
          between disentangled representations.
          URECA simulates the process of clustering based on simulation trick and 
          overrides Stationary Assumption with Threshold-Updatable Stationary 
          Assumption for dynamics to correctly reflect on
          the relationships between disentangled representations .           
    \item We carefully design the structure of experiments for comparative analysis across diverse 
          types of shifts. 
          This architecture demonstrates that URECA effectively adapts to diverse types of shifts
          like task shift, query shift and code shift. 
          Especially, URECA achieves State-of-The-Art performance in CoSQA 
          along with consistent performance gains across various programming languages 
          and shifts in CSN. 
\end{itemize}


