\section{Experiments}
\subsection{Taxonomy}

Table~\ref{tbl:taxonomy} presents a taxonomy of shift settings in model evaluation,
categorizing different experimental scenarios based on the presence of task, query, and code shifts.
The columns represent the addition of a new shift, while the rows indicate the existing shift settings.
The entries in the table denote whether a setting is feasible, covered in the extensive experiments including ablation studies.
For instance, when you see the ``\textbf{[No Shift]}'' row with ``\textbf{+ Query Shift}'' column,
CoCoSoDA is evaluated on CSN, without query shift, and CoSQA, with query shift.
This demonstrates the query shift ablation to examine how query variations affect the performance.
``\textbf{IMPOSSIBLE}'' denotes the settings that are infeasible,
such as applying two independent task shifts.
``X'' denotes settings that are theoretically possible but not included in the current experiments.

\begin{table}[h]
    \resizebox{\linewidth}{!}{
    % \renewcommand{\arraystretch}{1.2}
        \setlength{\tabcolsep}{6pt} % Adjust column spacing
        \begin{tabular}{p{4cm} p{3.5cm} p{3.5cm} p{3.5cm}}
            \toprule
            \textbf{Shift Type} & \textbf{+ Task Shift} & \textbf{+ Query Shift} & \textbf{+ Code Shift} \\
            \midrule
            \textbf{[No Shift]} & [CoCoSoDA] vs [UniXCoder] (CSN) & CoCoSoDA for [CSN] vs [CoSQA] & X \\\hline
            \textbf{Task Shift} & \textbf{IMPOSSIBLE} & UniXCoder for [CSN] vs [CoSQA] & [CodeT5+] vs [UniXCoder] (CSN) \\\hline
            \textbf{Query Shift}& [CoCoSoDA] vs [UniXCoder] (CoSQA) & \textbf{IMPOSSIBLE} & X \\\hline
            \textbf{Code Shift} & X & X & \textbf{IMPOSSIBLE} \\\hline
            \textbf{(Task Shift, Query Shift)} & \textbf{IMPOSSIBLE} & \textbf{IMPOSSIBLE} & [CodeT5+] vs [UniXCoder] (CoSQA) \\\hline
            \textbf{(Task Shift, Code Shift)}  & \textbf{IMPOSSIBLE} & CodeT5+ for [CSN] vs [CoSQA] & \textbf{IMPOSSIBLE} \\\hline
            \textbf{(Query Shift, Code Shift)} & X & \textbf{IMPOSSIBLE} & \textbf{IMPOSSIBLE} \\
            \bottomrule
        \end{tabular}
    }
    \caption{The taxonomy of experiments considering shift settings, where ``\textbf{[No Shift]}'' serves as the baseline.
    Each column represents the introduction of an additional shift, enabling ablation studies to analyze its impact.}
    \label{tbl:taxonomy}
\end{table}


\subsection{Dataset}

\textbf{Statistics}
\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
    Dataset & Training & Validation & Test \\\toprule
    Ruby-CSN & 24,927 & 1,400 & 1,261 \\
    JavaScript-CSN & 58,025 & 3,885 & 3,291 \\
    Java-CSN & 164,923 & 5,183 & 10,955 \\
    Go-CSN & 167,288 & 7,325 & 8,122 \\ 
    PHP-CSN & 241,241 & 12,982 & 14,014 \\
    Python-CSN & 251,820 & 13,914 & 14,918 \\\midrule
    CoSQA & 19,604 & 500 & 500 \\\midrule
    CoNaLa-docprompt & 768,777 & 201 & 543 \\\bottomrule
\end{tabular}%
\caption{Dataset statistics.}
\label{datastat}
\end{table}

\textbf{CSN:}                             
CodeSearchNet~(\cite{HusainWGAB19})  includes 2.3M functions of six programming languages 
(Ruby, Javascript, Java, Go, PHP, Python) with natural language documents.
CSN is the filtered version of CodeSearchNet~(\cite{HusainWGAB19}).
The authors of (\cite{HusainWGAB19}) filter low-quality queries by handcrafted rules and 
expand 1000 candidates to the whole code corpus, which is closer to the real-life scenario. 
Since CSN is generally used in the context of code search, we evaluate URECA with this dataset.
Unlike general situation in code search, however, CodeSearchNet/CSN query as summary of corresponding code.
This property of CodeSearchNet/CSN enables us to design experiments to reveal impact of specific shift 
on performance with comparative analysis.
For example, UniXCoder was trained on CSN during the pretraining phase, 
but it was not trained with relevance between queries and code as supervised signals for code search. 
Therefore, by evaluating UniXCoder on CSN, 
we can observe how InfoNCE and URECA behaves in a task shift scenario.
Although the shift related to CodeT5p-220M may involve both query shift and code shift, 
the queries in CSN are essentially summaries of the code, making them dependent on code shift. 
Therefore, by evaluating CodeT5p-220M on CSN, we can examine how each methodology behaves in a scenario 
where code shift and task shift are combined. 
Consequently, by comparing the performance of CodeT5p-220M and UniXCoder, 
we can assess the impact of code shift on performance changes.
% In this paper, we use CoCoSoDA\cite{Shi, Ensheng} which the version to apply a data augmentation technique to UniXCoder. 
In this paper, we use (CoCoSoDA\cite{EnshenYWLHSDH23}) which the version to apply a data augmentation technique to UniXCoder. 
By comparing the performance of CoCoSoDA and UniXCoder on CSN, 
we can understand how the accuracy of dynamics estimation affects the performance of URECA.

\textbf{CoSQA: }
Similar to CSN, CoSQA (\cite{HuangTSG0J0D20}) is also a dataset curated for evaluating code search, 
built based on CodeSearchNet.
In the case of CoSQA, the query pool is constructed from the search logs of Microsoft's Bing search engine.
The code pool is constructed from Python code in CodeSearchNet 
that does not contain non-English documentation or special tokens (e.g., $<$img...$>$ or "http://").
Subsequently, people manually match the queries from the query pool with the code from the code pool.
This process results in a dataset that better reflects real-world scenarios compared to CodeSearchNet/CSN, 
whose queries are simply constructed as summaries of the code.
At first, We can investigate the impact of query shift alone 
by comparing the performance of CoCoSoDA for CSN and CoSQA.
Next, we can compare the performances of UniXCoder for CSN and CoSQA 
to look into the impact of query shift in the existence of task shift. 
In addition, we can compare the performances of UniXCoder and CoCoSoDa to examine the impact of task shift 
in the existence of query shift. 
We also compare the performances of CodeT5+ and UniXCoder for CoSQA to inspect the impact of code shift 
in the existence of task shift and query shift. 
Furthermore, by comparing the performance of CodeT5p-220M on CSN-Python and CoSQA, 
we can analyze the impact of query shift in scenarios where code shift and task shift are present.

\textbf{CoNaLa-docprompt: }
CoNaLa-docprompting (\cite{Zhou0XJN23}) originates from CoNaLa (\cite{PengchenBEBG18}).
CoNaLa is a dataset that recognizes the limitations of heuristic methods in dataset construction. 
It is built by curating high-quality pairs of NL queries and code, 
not only based on handcrafted features obtained through heuristic methods but also using features 
derived from probabilistic models.
CoNaLa-docprompting is a re-split version of CoNaLa, 
designed to reflect distribution shift by including one Python function in each test example 
that is not present in the training distribution.
In addition, CoNaLa-docprompting differs from CoNaLa in that it retrieves documentations 
for all Python library functions available in DevDocs and uses these to construct a documentation pool.
This structure of CoNaLa-docprompting enables the retrieval of NL documentation 
for specific functions with nl query.
In particular, CoNaLa-docprompting ensures this by removing all non-text data during its construction process.
Based on these properties of CoNaLa-docprompting, we design experiments related to GraphCodeBERT's methodology, 
including graph-guided attention and data flow augmentation, 
as well as URECA in terms of the comprehension of semantic structures in natural language.


\subsection{Baselines}
\textbf{GraphCodeBERT: }
GraphCodeBERT (\cite{GuoRLFT0ZDSFTDC21}) learns the semantic structure of code through a structure-aware pretraining task 
by employing graph-guided masked attention, which leverages the relationships 
between the specified code and data flow.
Dataflow is a graph that represents dependency relation between variables 
in which nodes represent variables and edges represent where the value of each variable comes from
in corresponding code.
Such code structure provides crucial code semantic information for code understanding.
Data flow supports the model to consider long-range dependencies induced by using the same variable or 
function in distant locations.
To incorporate the graph structure into Transformer, 
GraphCodeBERT defines a graph-guided masked attention function to filter out irrelevant signals. 
To represent dependency relation between source code tokens and nodes of the data flow, 
they define the set $E'$ of pairs of source code token and node of data flow which is identified 
from the source code token.
Then, graph-guided masked attention masks the attention score for the pairs of source code token and 
node of data flow which are not in $E'$. 
In order to learn code representations from source code and code structure, 
GraphCodeBERT introduces new structure-aware pre-training tasks with data flow and graph-guided masked attention.
One is data flow edges prediction for learning representation from code structure, 
and the other is variable-alignment across source code and dataflow for aligning representation 
between source code and code structure.
The pretraining task based on data flow and graph-guided masked attention enables GraphCodeBERT 
to learn the semantic structure of code.
URECA is similar to GraphCodeBERT in terms of the reflection of semantic structure of fragments.
Therefore, we demonstrate the effectiveness of URECA about development for semantic structures 
about fragments thorugh comparative analysis with GraphCodeBERT.

\textbf{UniXCoder: }
UniXCoder follows (\cite{GuoLDW0022}) to forward the same input with dropout mask as a positive example 
and use other representations in the same batch as negative examples.
For cross-modal generation, URECA generates its comment from the corresponding function.
Since the generation of the comment is conditioned on code, it will force the model 
to fuse semantic information from the comment into the hidden states of of the code.
UniXCoder, pretrained on CSN through Cross-Modal Generation, learns patterns of relationships 
between NL comments and code that are well-suited for generation tasks on CSN.
Therefore, by evaluating UniXCoder on the code search task using CSN, 
we can assess how effectively the patterns of relationships between NL comments and code, 
learned through generation tasks, can be adjusted for retrieval tasks. 
In other words, this evaluation allows us to measure how effectively URECA facilitates adaptation to task shifts.

\textbf{CodeT5+: }
CodeT5+ is a family of encoder-decoder based large language models (LLMs) designed 
for a broad range of code-related understanding and generation tasks.
It addresses limitations in existing code LLMs regrading architecture inflexibility 
and limited pretraining tasks with modular architectures and diverse set of pretraining tasks.
The pretraining of CodeT5+ consists of two steps. 
For the first step, they train the model with GitHub code dataset through span denoising and 
causal language modeling.
For the second step, they train the model with text-code contrastive learning and 
text-code matching with CSN dataset.
Since the bidmodally trained version of CodeT5+ is already trained for CSN with the relevance signals, 
there is no space for shifts unlike UniXCoder. 
(UniXCoder is also pretrained on CSN but there is no matching task in the process of pretraining, 
which makes it possible to train the model for task shift)
So we use the unimodally trained version of CodeT5+ in this paper. 
This unimodal version of CodeT5+ is not trained on CSN dataset unlike bimodal version.
This enables us to evaluate URECA in terms of distribution shift for codes.

\textbf{CoCoSoDA: }
CoCoSoDA (\cite{EnshenYWLHSDH23}) consists of two-stage fine-tunings.
In the first stage of fine-tuning, learning is performed using Multi-modal Contrastive Learning 
based on Soft Data Augmentation. 
In the second stage, the model is trained for the code search task through conventional contrastive learning 
on query and code pairs.
CoCoSoDA augment queries and codes with different utilizations of masking and replacement operations 
for each iteration.
There are 4 augmentation methodologies, Dynamic Masking, Dynamic Replacement and Dynamics Replace.
Except for Dynamic Masking, the others are only applicable to code data 
due to the dependence of type information which is not generally available for natural language.
CoCoSoDA trains model with inter-modal loss function and intra-modal loss function.
Inter-modal loss function is criterion to maximize the semantic similarity of 
(original query, paired code snippet (original code + augmented code)) and 
(paired query (original query + augmented query), original code) minimize the semantic similarity 
of the query and its unpaired code snippets in same mini-batch.
Intra-modal loss function is criterion to learn the better representations of queries/codes, 
where similar queries/codes have closed representations and different queries/codes have distinguishing.
This CoCoSoDA makes the model to learn more accurate dynamics of queries itself, 
codes itself and relationships between queries and codes.
Building on this, CoCoSoDA enables more accurate estimation of the dynamics used for transport in URECA. 
Based on this, we conduct experiments to evaluate how the accuracy of dynamics estimation impacts 
the effective operation of URECA.

\subsection{Metrics}
\textbf{Mean Reciprocal Rank(MRR): } 
Mean Reciprocal Rank (MRR) is a statistical measure widely used in information retrieval 
and recommendation systems to evaluate the effectiveness of a ranking algorithm. 
It is particularly helpful when there is a single correct answer or a relevant result in a ranked list.
MRR calculates the average reciprocal rank of the first relevant result across multiple queries or test cases. The reciprocal rank is the multiplicative inverse of the rank position of the first relevant result 
for a query.
The formal definition of Mean Reciprocal Rank is as follows, when $N$ is the total number of examples
and $rank_i$ is  the rank of the first relevant result for the $i$-th query. 
If there is no relevant result, the reciprocal rank is treated as 0.
\begin{align}
    MRR={1 \over N}\sum_{i=1}^N{1 \over rank_i} 
\end{align}

\textbf{Recall@k: }
Recall@k is a performance metric commonly used in information retrieval, recommendation systems, 
and machine learning to evaluate how effectively a model retrieves relevant results from a ranked list. 
It measures the proportion of relevant items successfully retrieved within the top $k$ results.
The formal definition of Recall@k is as follows, when $R_k$ is the number of relevant items in top $k$
results  and $T$ is the total number of relevant items.
\begin{align}
    Recall@k={R_k\over T}
\end{align}

\newpage
\subsection{Main Result}
In this subsection, we provide the main result of URECA for CSN-Ruby, CSN-Javascript, CSN-Java, CSN-Go and 
CSN-PHP. 



\begin{table}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Method}             & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}               & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CodeT5p-220M}      
& InfoNCE                   & \multicolumn{1}{c}{18.8}                & \multicolumn{1}{c}{28.3}          
                            & \multicolumn{1}{c}{32.8}                & \multicolumn{1}{c}{35.3}          
                            & \multicolumn{1}{c}{35.5}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{19.9(+1.1)}          & \multicolumn{1}{c}{28.4(+0.1)}          
                            & \multicolumn{1}{c}{35.3(+2.5)}          & \multicolumn{1}{c}{36.4(+1.1)}          
                            & \multicolumn{1}{c}{38.2(+2.7)}                  
                            \\ \midrule

\multirow{2}{*}{UniXCoder} 
& InfoNCE                   & \multicolumn{1}{c}{61.2}                & \multicolumn{1}{c}{61.4}          
                            & \multicolumn{1}{c}{63}                  & \multicolumn{1}{c}{62.9}                
                            & \multicolumn{1}{c}{63.8}                  
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{61.5(-0.3)}          & \multicolumn{1}{c}{61.4(+0)}          
                            & \multicolumn{1}{c}{63.4(+0.4)}          & \multicolumn{1}{c}{63.6(+0.7)}          
                            & \multicolumn{1}{c}{64.2(+04)}                   
                            \\ \midrule

\multirow{2}{*}{CoCoSoDA} 
& InfoNCE                   & \multicolumn{1}{c}{75}                  & \multicolumn{1}{c}{75.5}          
                            & \multicolumn{1}{c}{75.7}                & \multicolumn{1}{c}{76.0}          
                            & \multicolumn{1}{c}{76.4}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{76.8(+1.8)}          & \multicolumn{1}{c}{77.8(+2.3)}          
                            & \multicolumn{1}{c}{78.8(+3.1)}          & \multicolumn{1}{c}{79.0(+3)}          
                            & \multicolumn{1}{c}{79.5(+3.1)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{Results of Ruby across different number of few shot examples (MRR).}
\label{CSN_Ruby}
\end{table}

\begin{table}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Method}              & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}                 & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CodeT5p-220M}      
& InfoNCE                   & \multicolumn{1}{c}{15.1}          & \multicolumn{1}{c}{21.6}          
                            & \multicolumn{1}{c}{24}          & \multicolumn{1}{c}{22}          
                            & \multicolumn{1}{c}{25.2}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{14.7(-0.4)}          & \multicolumn{1}{c}{23.2(+1.7)}          
                            & \multicolumn{1}{c}{24(+0.9)}          & \multicolumn{1}{c}{23.2(+1.2)}          
                            & \multicolumn{1}{c}{26.4(+1)}                  
                            \\ \midrule

\multirow{2}{*}{UniXCoder} 
& InfoNCE                   & \multicolumn{1}{c}{48.9}              & \multicolumn{1}{c}{50.5}          
                            & \multicolumn{1}{c}{48.4}              & \multicolumn{1}{c}{51.2}          
                            & \multicolumn{1}{c}{51.4}                  
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{48.9(+0)}          & \multicolumn{1}{c}{51.1(+0.6)}          
                            & \multicolumn{1}{c}{51.7(+3.3)}          & \multicolumn{1}{c}{52.6(+2.4)}          
                            & \multicolumn{1}{c}{54(+2.6)}                   
                            \\ \midrule

\multirow{2}{*}{CoCoSoDA} 
& InfoNCE                   & \multicolumn{1}{c}{61.4}              & \multicolumn{1}{c}{62.5}          
                            & \multicolumn{1}{c}{63.4}              & \multicolumn{1}{c}{63.7}          
                            & \multicolumn{1}{c}{64.3}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{64.4(+3)}          & \multicolumn{1}{c}{65.3(+2.8)}          
                            & \multicolumn{1}{c}{67(+3.6)}          & \multicolumn{1}{c}{68.4(+4.7)}          
                            & \multicolumn{1}{c}{68.8(+4.5)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{Results of Javascript across different number of few shot examples (MRR).}
\label{CSN_Javascript}
\end{table}


\begin{table*}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Method}              & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}               & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CodeT5p-220M}      
& InfoNCE                   & \multicolumn{1}{c}{3.1}               & \multicolumn{1}{c}{9.8}          
                            & \multicolumn{1}{c}{22}                & \multicolumn{1}{c}{22.6}          
                            & \multicolumn{1}{c}{26.9}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{3.1(+0)}         & \multicolumn{1}{c}{11(+1.2)}          
                            & \multicolumn{1}{c}{20.2(-1.8)}        & \multicolumn{1}{c}{25.8(+3.2)}          
                            & \multicolumn{1}{c}{29.4(+2.5)}                
                            \\ \midrule

\multirow{2}{*}{UniXCoder} 
& InfoNCE                   & \multicolumn{1}{c}{52.6}             & \multicolumn{1}{c}{52.7}          
                            & \multicolumn{1}{c}{54.2}             & \multicolumn{1}{c}{55.1}             
                            & \multicolumn{1}{c}{55.5}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{52.4(-0.2)}          & \multicolumn{1}{c}{54(+1.3)}          
                            & \multicolumn{1}{c}{55.4(+0.8)}          & \multicolumn{1}{c}{57.2(+2.1)}          
                            & \multicolumn{1}{c}{58.2(+2.7)}                  
                            \\ \midrule

\multirow{2}{*}{CoCoSoDA} 
& InfoNCE                   & \multicolumn{1}{c}{61.1}          & \multicolumn{1}{c}{61.7}          
                            & \multicolumn{1}{c}{64}          & \multicolumn{1}{c}{64.3}          
                            & \multicolumn{1}{c}{65}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{63(+1.9)}        & \multicolumn{1}{c}{64.6(+2.9)}          
                            & \multicolumn{1}{c}{66.1(+2.1)}          & \multicolumn{1}{c}{68.1(+3.8)}          
                            & \multicolumn{1}{c}{68.4(+3.4)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{Results of Java across different number of few shot examples (MRR).}
\label{CSN_Java}
\end{table*}

\begin{table*}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Method}              & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}               & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CodeT5p-220M}      
& InfoNCE                   & \multicolumn{1}{c}{26.5}                & \multicolumn{1}{c}{43.1}          
                            & \multicolumn{1}{c}{42}                & \multicolumn{1}{c}{65.7}          
                            & \multicolumn{1}{c}{66.8}                  
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{28.8(+2.3)}          & \multicolumn{1}{c}{46.9(+3.8)}          
                            & \multicolumn{1}{c}{59.1(+17.1)}          & \multicolumn{1}{c}{66.9(+1.2)}          
                            & \multicolumn{1}{c}{68.3(+1.5)}                   
                            \\ \midrule

\multirow{2}{*}{UniXCoder} 
& InfoNCE                   & \multicolumn{1}{c}{70.5}               & \multicolumn{1}{c}{73.4}          
                            & \multicolumn{1}{c}{73.8}               & \multicolumn{1}{c}{80.2}          
                            & \multicolumn{1}{c}{80.1}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{70.5(+0)}          & \multicolumn{1}{c}{74.8(+1.4)}          
                            & \multicolumn{1}{c}{74.6(+0.8)}          & \multicolumn{1}{c}{80.2(+0)}          
                            & \multicolumn{1}{c}{81.3(+1.2)}                  
                            \\ \midrule

\multirow{2}{*}{CoCoSoDA} 
& InfoNCE                   & \multicolumn{1}{c}{75.2}             & \multicolumn{1}{c}{77.3}          
                            & \multicolumn{1}{c}{79.1}             & \multicolumn{1}{c}{79.2}          
                            & \multicolumn{1}{c}{78.1}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{82(+6.8)}          & \multicolumn{1}{c}{83.4(+6.1)}          
                            & \multicolumn{1}{c}{83.7(+4.6)}          & \multicolumn{1}{c}{83.3(+4.1)}          
                            & \multicolumn{1}{c}{83.4(+5.3)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{Results of Go across different number of few shot examples (MRR).}
\label{CSN_Go}
\end{table*}

\begin{table*}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Method}              & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}               & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CodeT5p-220M}      
& InfoNCE                   & \multicolumn{1}{c}{1.8}          & \multicolumn{1}{c}{11.4}          
                            & \multicolumn{1}{c}{15.8}          & \multicolumn{1}{c}{20.5}          
                            & \multicolumn{1}{c}{21.9}                  
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{2.6(+0.8)}          & \multicolumn{1}{c}{18(+6.6)}          
                            & \multicolumn{1}{c}{17.5(+1.7)}          & \multicolumn{1}{c}{21.9(+1.3)}          
                            & \multicolumn{1}{c}{23.4(+5.3)}                   
                            \\ \midrule

\multirow{2}{*}{UniXCoder} 
& InfoNCE                   & \multicolumn{1}{c}{40.4}          & \multicolumn{1}{c}{46.3}          
                            & \multicolumn{1}{c}{48.6}          & \multicolumn{1}{c}{48.4}          
                            & \multicolumn{1}{c}{50.4}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{40.5(+0.1)}          & \multicolumn{1}{c}{44.8(-1.5)}          
                            & \multicolumn{1}{c}{47.6(-1.1)}          & \multicolumn{1}{c}{50.4(+2)}          
                            & \multicolumn{1}{c}{51.6(+1.2)}                  
                            \\ \midrule

\multirow{2}{*}{CoCoSoDA} 
& InfoNCE                   & \multicolumn{1}{c}{54.2}          & \multicolumn{1}{c}{55.9}          
                            & \multicolumn{1}{c}{55.9}          & \multicolumn{1}{c}{57.1}          
                            & \multicolumn{1}{c}{56.8}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{57.6(+3.4)}          & \multicolumn{1}{c}{60.2(+5.3)}          
                            & \multicolumn{1}{c}{60.3(+5.4)}          & \multicolumn{1}{c}{61.2(+4.1)}          
                            & \multicolumn{1}{c}{60.3(+3.5)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{Results of PHP across different number of few shot examples (MRR).}
\label{CSN_PHP}
\end{table*}

\newpage
\subsection{Thresholdly-Updatable Stationary Assumption for Dynamics}
\begin{table*}[h]
\def\arraystretch{1.0}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lllcccccc@{}}

\toprule
Model                            & \multicolumn{1}{l}{Dataset}              & \multicolumn{1}{c}{40}           
& \multicolumn{1}{c}{80}         & \multicolumn{1}{c}{120}               & \multicolumn{1}{c}{160}     
& \multicolumn{1}{c}{200}        \\ \midrule

\multirow{2}{*}{CSN-Python} 
& Stationary                & \multicolumn{1}{c}{63.2}          & \multicolumn{1}{c}{63.6}          
                            & \multicolumn{1}{c}{63}          & \multicolumn{1}{c}{63.7}          
                            & \multicolumn{1}{c}{64.7}                   
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{64.9(+1.7)}          & \multicolumn{1}{c}{65.8(+2.2)}          
                            & \multicolumn{1}{c}{66.6(+3.6)}          & \multicolumn{1}{c}{67.2(+3.5)}          
                            & \multicolumn{1}{c}{67.7(+3)}                  
                            \\ \midrule

\multirow{2}{*}{CoSQA} 
& Stationary                & \multicolumn{1}{c}{48.6}          & \multicolumn{1}{c}{49.9}          
                            & \multicolumn{1}{c}{51.6}          & \multicolumn{1}{c}{53.9}          
                            & \multicolumn{1}{c}{54.4}                    
                            \\ \cmidrule(l){2-7} 
& URECA                     & \multicolumn{1}{c}{52(+4)}          & \multicolumn{1}{c}{54.6(+4.7)}          
                            & \multicolumn{1}{c}{54.6(+3)}          & \multicolumn{1}{c}{56.3(+2.2)}          
                            & \multicolumn{1}{c}{55.6(+1.2)}                   
                            \\ \bottomrule 
\end{tabular}
\caption{CoCoSoDA Results of Stationary Assumption and URECA (Thresholdly Updatable Stationary Assumption) 
across different number of few shot examples (MRR).}
\label{Stationary Assumption}
\end{table*}


\subsection{Structure of Disentangled Representation}
The performance improvement of GraphCodeBERT in CSN-Python and CoSQA is not as significant 
as UniXcoder and CodeT5+ in Table 12.
This is because GraphCodeBERT incorporates dataflow into the input based on graph-guided attention,
allowing the model to learn the inherent semantic structure of the code.
Therefore, GraphCodeBERT has already sufficiently learned the inherent semantic structure
that others might not have fully captured.
However, for CoNaLa-docprompting dataset as dataset for pure nl dataset, the effects of GraphCodeBERT 
are limited since CoNaLa-docprompting requires model to retrieve nl-document rather than code, 
which makes dataflow and graph-guided-masked-attention impossible to apply. 

On CoNaLa (used validation split as reported in the original paper (\cite{PengchenBEBG18})), 
URECA achieved a recall@10 of 55.4, outperforming InfoNCE’s 49.1 by +6.3, 
since GraphcodeBERT's methodlogies require sufficient pre-training for the model to become familiar with dataflow and graph-guided attention
which is only usable for code domain. 
This suggests that URECA is more broadly effective across modalities than GraphCodeBERT.
In addition, GraphCodeBERT needs 5 to 6 times more seconds since graph-guided attention is always calculated 
for each iteration.
In contrast, URECA can be more generally applied since it only requires fine-tuning 
without these additional steps with a little time lag in reference to Figure 4.



\begin{table}[h]
\centering
\def\arraystretch{0.8}
\setlength\tabcolsep{8pt} % default value: 6pt
\begin{tabular}{@{}lccc@{}}

\toprule
\multicolumn{1}{l}{Method}              & \multicolumn{1}{c}{CSN}           
& \multicolumn{1}{c}{CoSQA}          & \multicolumn{1}{c}{CoNaLa(R@10)}                \\ \midrule

     
InfoNCE                     & \multicolumn{1}{c}{49.4}          & \multicolumn{1}{c}{8.8}          
                            & \multicolumn{1}{c}{49.1}                          
                            \\ \midrule 
URECA                       & \multicolumn{1}{c}{49.7(+0.3)}          & \multicolumn{1}{c}{9.1(+0.3)}          
                            & \multicolumn{1}{c}{55.4(+6.3)}                             
                            \\ \bottomrule 
\end{tabular}
\caption{Results of GraphCodeBERT}
\label{overall}
\end{table}


\subsection{Implementation Details}
We fix the query and code length to 128 for UniXCoder, CodeT5p-220M, and CoCoSoDA in few-shot learning. 
For GraphCodeBERT, we set the query and data flow length to 64 and the code length to 256.
The batch size is selected from 12 and 24, choosing the value that yields the best performance. 
The learning rate is set to $2e-5$ for CoCoSoDA and $1e-5$ for UniXCoder, CodeT5p-220M, and GraphCodeBERT.
In few-shot scenario, all experiments are conducted on a GeForce RTX 3090 GPU, 
and each experiment is repeated three times using different random seeds for 40, 80, 120, 160, and 200 examples.
For CoNaLa-docprompting, we fix the maximum query and code length to 64 exclusively for URECA. 
In this case, the experiments are conducted on an A6000 GPU.
Our codes is based on SoftInfoNCE (\cite{HaochenXAC23}), and it is available at https://github.com/github\_id/ureca.