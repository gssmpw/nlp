\section{Analysis of the Annealed Importance Sampling}
\label{sec:ais}
In practice, it is not feasible to simulate the ALD precisely, nor is it possible to evaluate the exact value of the work $W(X)$. Therefore, discretization and approximation are required. To address this, we first outline the following annealed importance sampling (AIS) equality akin to JE. 

\begin{theorem}[Annealed importance sampling equality \citep{neal2001annealed}] 
Suppose we have probability distributions $\pi_\l=\frac{1}{Z_\l}f_\l$, $\l\in\sqd{0,M}$ and transition kernels $F_\l(x,\cdot)$, $\l\in\sqd{1,M}$, and assume that each $\pi_\l$ is an invariant distribution of $F_\l$, $\l\in\sqd{1,M}$. Define the path measure
    \begin{equation}
        \Pr(x_{0:M})=\pi_0(x_0)\prod_{\l=1}^MF_\l(x_{\l-1},x_\l).
        \label{eq:ais_pr}
    \end{equation}
    Then the same relation between the work function $W$ and free energy difference $\Delta F$ holds:
    $$\E_{\Pr}\e^{-W}=\e^{-\Delta F},\quad\text{where}~~W(x_{0:M}):=\log\prod_{\l=0}^{M-1}\frac{f_\l(x_\l)}{f_{\l+1}(x_\l)}~~\text{and}~~\Delta F:=-\log\frac{Z_M}{Z_0}.$$
    \label{thm:ais}
\end{theorem}
\vspace{-1em}
\begin{proof}
    Since $\pi_\l$ is invariant for $F_\l$, the following backward transition kernels are well-defined:
    $$B_\l(x,x')=\frac{\pi_\l(x')}{\pi_\l(x)}F_\l(x',x),~\l\in\sqd{1,M}.$$
    By applying these backward transition kernels sequentially, we define the backward path measure
    \begin{equation}
        \Pl(x_{0:M})=\pi_M(x_M)\prod_{\l=1}^MB_\l(x_\l,x_{\l-1}).
        \label{eq:ais_pl}
    \end{equation}
    It can be easily demonstrated, as in \cref{eq:jar_rn}, that $\log\de{\Pr}{\Pl}(x_{0:M})=W(x_{0:M})-\Delta F$. Consequently, the identity $\E_{\Pr}{\de{\Pl}{\Pr}}=1$ implies the desired equality.
\end{proof}

To study non-asymptotic complexity guarantees, we focus on a widely used curve in theoretical analysis \citep{brosse2018normalizing,ge2020estimating}, which we refer to as the \emph{geometric interpolation}\footnote{\cref{eq:pi_theta} differs slightly from a widely used curve in applications \citep{gelman1998simulating,neal2001annealed}: $\pi_\theta\propto\pi^{1-\lambda(\theta)}\phi^{\lambda(\theta)}$, where $\phi$ is a prior distribution (typically Gaussian). We refer to both as \emph{geometric interpolation}.}:
\begin{equation}
    \pi_\theta=\frac{1}{Z_\theta}f_\theta=\frac{1}{Z_\theta}\exp\ro{-V-\frac{\lambda(\theta)}{2}\|\cdot\|^2},~\theta\in[0,1],
    \label{eq:pi_theta}
\end{equation}
where $\lambda(\cdot)$ is a decreasing function with $\lambda(0)=2\beta$ and $\lambda(1)=0$, referred to as the \emph{annealing schedule}. With this choice of $\lambda(0)$, by \cref{assu:pi}, the potential of $\pi_0$ is $\beta$-strongly-convex and $3\beta$-smooth, making sampling and normalizing constant estimation relatively easy. To estimate $Z_0$, we use the TI algorithm from \cite{ge2020estimating}, which requires $\Ot\ro{\frac{d^{\frac32}}{\varepsilon^2}}$ gradient oracle calls. In a nutshell, TI is an equilibrium method that constructs a series of intermediate distributions and estimates adjacent normalizing constant ratios via expectation under these intermediate distributions, realized through MCMC sampling from each intermediate distribution. As TI is peripheral to our primary focus, we defer its full description and complexity analysis to \cref{app:rel_work_ti,lem:ais_est_z0}.

Given the curve \cref{eq:pi_theta}, we introduce discrete time points $0=\theta_0<\theta_1<...<\theta_M=1$ to be specified later, and adopt the framework outlined in \cref{thm:ais} by setting $\pi_\l=\frac{1}{Z_\l}f_\l$ to correspond to $\pi_{\theta_\l}=\frac{1}{Z_{\theta_\l}}f_{\theta_\l}$, albeit with a slight abuse of notation. To estimate the normalizing constant, we need to sample from the forward path measure $\Pr$, and calculate the work function along the trajectory. Since $\pi_{\theta_\l}$ must be an invariant distribution of the transition kernel $F_\l$ in $\Pr$, we define $F_\l$ via running LD targeting $\pi_{\theta_\l}$ for a short time $T_\l$, i.e., $F_\l(x,\cdot)$ is given by the law of $X_{T_\l}$ in the following SDE initialized at $X_0=x$:
\begin{equation}
    \d X_t=\nabla\log\pi_{\theta_\l}(X_t)\d t+\sqrt{2}\d B_t,~t\in[0,T_\l].
    \label{eq:ais_ker_f}
\end{equation}
In this setting, AIS can be interpreted as a discretized version of JE \cite[Remark 4.5]{lelievre2010free}. However, in practice, exact samples from $\pi_0$ are often unavailable, and the simulation of LD cannot be performed perfectly. To capture these practical considerations, we define the following sampling path measure:
\begin{equation}
    \Phr(x_{0:M})=\pih_0(x_0)\prod_{\l=1}^{M}\Fh_\l(x_{\l-1},x_\l),
    \label{eq:ais_phr}
\end{equation}
where $\pih_0$ is the law of an approximate sample from $\pi_0$, and the transition kernel $\Fh_\l$ is a discretization of the LD in $F_\l$, defined as running \emph{one step} of \textbf{annealed Langevin Monte Carlo (ALMC)} using the exponential integrator discretization scheme \citep{zhang2023fast,zhang2023gddim,zhang2023improved} with step size $T_\l$. Formally, $\Fh_\l(x,\cdot)$ is the law of $X_{T_\l}$ in the following SDE initialized at $X_0=x$:
\begin{equation}
    \d X_t=-\ro{\nabla V(X_0)+\lambda\ro{\theta_{\l-1}+\frac{t}{T_\l}(\theta_\l-\theta_{\l-1})}X_t}\d t+\sqrt{2}\d B_t,~t\in[0,T_\l].
    \label{eq:ais_ker_fh}
\end{equation}
Here, instead of simply setting $\Fh_\l$ as one step of LMC targeting $\pi_{\theta_\l}$, the dynamically changing $\lambda(\cdot)$ helps reduce the discretization error, as will be shown in our proof. Furthermore, with a sufficiently small step size, the overall discretization error can also be minimized, motivating us to apply just one update step in each transition kernel.

We refer readers to \cref{alg:ais} for a summary of the detailed implementation of our proposed AIS algorithm, including the TI procedure and the update rules in \cref{eq:ais_ker_fh}. The following theorem delineates the oracle complexity of the algorithm required to obtain an estimate $\Zh$ meeting the desired accuracy criterion (\cref{eq:acc_whp}), whose detailed proof can be located in \cref{prf:thm:ais_complexity}.

\begin{theorem}
    Let $\Zh$ be the AIS estimator described as in \cref{alg:ais}, i.e., $\Zh:=\Zh_0\e^{-W(x_{0:M})}$ where $\Zh_0$ is estimated by TI and $x_{0:M}\sim\Phr$.
    Under \cref{assu:pi,assu:AC}, consider the annealing schedule $\lambda(\theta)=2\beta(1-\theta)^r$ for some $1\le r\lesssim1$. Use $\cA_r$ to denote the action of $(\pi_\theta)_{\theta\in[0,1]}$ to emphasize the dependence on $r$. Then, the oracle complexity for obtaining an estimate $\Zh$ that satisfies the criterion $\prob\ro{\abs{\frac{\Zh}{Z}-1}\le\varepsilon}\ge\frac{3}{4}$ is
    \begin{equation}
        \Ot\ro{
        \frac{d^\frac{3}{2}}{\varepsilon^2}
        \vee
        \frac{m\beta\cA_r^\frac{1}{2}}{\varepsilon^2}
        \vee
        \frac{d\beta^2\cA_r^2}{\varepsilon^4}
        }.
        \label{eq:ais_complexity}
    \end{equation}
            
    \label{thm:ais_complexity}
\end{theorem}

We present a high-level proof sketch using \cref{fig:prf_idea}. The continuous dynamics, comprising the forward path $\Pr$, the backward path $\Pl$, and the reference path $\P$, are depicted as three black curves. To address discretization error, the $\l$-th \red{red} ({\color[RGB]{189,16,224}purple}) arrow proceeding from left to right represents the transition kernel $\Fh_\l$ ($B_\l$), whose composition forms $\Phr$ ($\Pl$).

\begin{figure}[ht]
    \centering
    \input{sections/sec_prf_idea}
    \caption{
    Illustration of the proof idea for \cref{thm:ais_complexity}.}
    \label{fig:prf_idea}
\end{figure}

\begin{enumerate}[wide=0pt,itemsep=0pt, topsep=0pt,parsep=0pt,partopsep=0pt]
    \item Analogously to the analysis of JE (\cref{thm:jar_complexity}), define the reference path measure $\P$ with transition kernels $F^*_\l$ such that $x_\l\sim\pi_{\theta_\l}$.
    Given the sampling path measure $\Phr$, define $\Pbr$ as the version of $\Phr$ without the initialization error, i.e., by replacing $\pih_0$ with $\pi_0$ in \cref{eq:ais_phr}. 
    \item Show that it suffices to obtain an accurate estimate $\Zh_0$ and initialization distribution $\pih_0$, together with sufficiently small KL divergences $\kl(\P\|\Pl)$ and $\kl(\P\|\Pbr)$, which quantify the closeness between the continuous dynamics and the discretization error in implementation, respectively.
    \item Using the chain rule, decompose $\kl(\P\|\Pl)$ into the sum of KL divergences between each pair of transition kernels $F_\l$ and $F^*_\l$ (i.e., the sum of \green{green} ``distances''). As in the proof of the convergence of JE (\cref{thm:jar_complexity}), $F^*_\l$, a transition kernel from $\pi_{\theta_{\l-1}}$ to $\pi_{\theta_\l}$, is realized by ALD with a compensatory vector field, ensuring the SDE exactly follows the trajectory $(\pi_\theta)_{\theta\in[\theta_{\l-1},\theta_\l]}$. 
    Similarly, by applying the chain rule and Girsanov theorem, we can express $\kl(\P\|\Pbr)$ as the sum of the \blue{blue} ``distances'', allowing for a similar analysis.
    \item Finally, derive three necessary conditions on the time steps $\theta_{\l}$ to control both $\kl(\P\|\Pl)$ and $\kl(\P\|\Pbr)$. Choosing a proper schedule yields the desired complexity bound.
\end{enumerate}

Our proposed algorithm consists of two phases: first, estimating $Z_0$ by TI, which is provably efficient for well-conditioned distributions, and second, estimating $Z$ by AIS, which is better suited for handling non-log-concave distributions. 
The three terms in \cref{eq:ais_complexity} arise from (i) ensuring the accuracy of $\Zh_0$, (ii) controlling $\kl(\P\|\Pl)$, and (iii) controlling $\kl(\P\|\Pbr)$, respectively, as discussed in \textbf{2.} above.
Due to the non-log-concavity of $\pi$, the action $\cA$ is typically large, making (iii), the cost for controlling the discretization error, the dominant complexity.
Finally, the $\varepsilon$-dependence can be interpreted as the total duration $T=\Theta\ro{\frac{1}{\varepsilon^2}}$ required for the continuous dynamics to converge (as in \cref{thm:jar_complexity}) divided by the step size $\Thetat(\varepsilon^2)$ to control the discretization error.