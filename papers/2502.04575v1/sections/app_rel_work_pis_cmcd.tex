\subsection{Path Integral Sampler and Controlled Monte Carlo Diffusion}
\label{app:rel_work_pis_cmcd}
In this section, we briefly discuss two learning-based samplers used for normalizing constant estimation and refer readers to the original papers for detailed derivations. The path integral sampler (PIS) shares structural similarities with the RDS framework discussed in \cref{thm:revdif}, using the time-reversal of a universal noising process that transforms any distribution into a prior -- such as the OU process in RDS that converges to the standard normal or the Brownian bridge in PIS that converges to the delta distribution at zero. In contrast, the controlled Monte Carlo diffusion (CMCD) extends the JE framework from \cref{sec:jar}, focusing on learning the compensatory drift term along an arbitrary interpolating curve $(\pi_\theta)_{\theta\in[0,1]}$, as long as the density of each intermediate distribution $\pi_\theta$ is known up to a constant.

\paragraph{Path integral sampler (PIS, \citet{zhang2022path}).} The PIS learns the drift term of a reference SDE that interpolates the delta distribution at $0$ and the target distribution $\pi$, which is closely connected with the Brownian bridge and the F\"ollmer drift \citep{chewi2022log}.

Fix a time horizon $T>0$. For any drift term $(u_t)_{t\in[0,T]}$, let $\cQ^u$ be the path measure of the following SDE:
$$\d X_t=u_t(X_t)\d t+\d B_t,~t\in[0,T];~X_0\aseq0.$$

In particular, when $u\equiv0$, the marginal distribution of $X_T$ under $\cQ^0$ is $\n{0,TI}=:\phi_T$. Define another path measure $\cQ^*$ by
\begin{equation*}
    \cQ^*(\d\xi_{[0,T]}):=\cQ^0(\d\xi_{[0,T)}|\xi_T)\pi(\d\xi_T)=\cQ^0(\d\xi_{[0,T]})\de{\pi}{\phi_T}(\xi_T),~\forall\xi\in C([0,T];\R^d)
    \label{eq:pis_qstar}
\end{equation*}
and consider the problem
$$u^*=\argmin_u\kl(\cQ^u\|\cQ^*)\implies\cQ^{u^*}=\cQ^*.$$ 
One can calculate the KL divergence between these path measures via Girsanov theorem (\cref{lem:rn_path_measure}): 
\begin{align*}
    \log\de{\cQ^u}{\cQ^*}(X)&=W^u(X)+\log Z,~\text{a.s.}~X\sim\cQ^u,~\text{where}\\
    W^u(X)&=\int_0^T\inn{u_t(X_t),\d B_t}+\frac{1}{2}\int_0^T\|u_t(X_t)\|^2\d t-\frac{\|X_T\|^2}{2T}+V(X_T)-\frac{d}{2}\log2\pi T,
\end{align*}
which implies $Z=\E_{\cQ^u}{\e^{-W^u}}$, and $\kl(\cQ^u\|\cQ^*)=\E_{\cQ^u}{W^u}+\log Z$. On the other hand, directly applying \cref{lem:rn_path_measure} gives 
$$\kl(\cQ^u\|\cQ^*)=\frac{1}{2}{\int_0^T\E_{\cQ^u}\|u_t(X_t)-u^*_t(X_t)\|^2\d t}.$$

In \citet[Theorem 3]{zhang2022path}, the authors considered the effective sample size (ESS) defined by $\mathrm{ESS}^{-1}=\E_{\cQ^u}{\ro{\de{\cQ^*}{\cQ^u}}^2}$ as the convergence criterion, and stated that $\mathrm{ESS}\ge1-\varepsilon$ as long as $\sup_{t\in[0,T]}\|u_t-u^*_t\|^2_{L^\infty}\le\frac{\varepsilon}{T}$. However, this condition is generally hard to verify since the closed-form expression of $u^*$ is unknown, and the $L^\infty$ bound might be too strong. Using the criterion (\cref{eq:acc_whp}) and the same methodology in proving the convergence of JE (\cref{thm:jar_complexity}), we can establish an improved result on the convergence guarantee of this estimator, relating the relative error to the training loss of $u$, which is defined as
$$\min_u L(u):=\E_{\cQ^u}\sq{\frac{1}{2}\int_0^T\|u_t(X_t)\|^2\d t-\frac{\|X_T\|^2}{2T}+V(X_T)}=\kl(\cQ^u\|\cQ^*)-\log Z+\frac{d}{2}\log2\pi T$$
\begin{proposition}
    \label{thm:pis_complexity}
    Consider the estimator $\Zh:=\e^{-W^u(X)}$, $X\sim\cQ^u$ for $Z$. To achieve both $\kl(\cQ^u_T\|\pi)\lesssim\varepsilon^2$ (with $\cQ^u_T$ representing the law of $X_T$ in the sampled trajectory $X\sim\cQ^u$) and $\prob\ro{\abs{\frac{\Zh}{Z}-1}\le\varepsilon}\ge\frac{3}{4}$, it suffices to choose $u$ that satisfies
    $$L(u)=-\log Z+\frac{d}{2}\log2\pi T+O(\varepsilon^2).$$
\end{proposition}

\begin{proof}
    \begin{align*}
        \prob\ro{\abs{\frac{\Zh}{Z}-1}\ge\varepsilon}=\cQ^u\ro{\abs{\de{\cQ^*}{\cQ^u}-1}\ge\varepsilon}              \lesssim\frac{\tv(\cQ^u,\cQ^*)}{\varepsilon}\lesssim\frac{\sqrt{\kl(\cQ^u\|\cQ^*)}}{\varepsilon}.
    \end{align*}
    Therefore, ensuring $\kl(\cQ^u\|\cQ^*)\lesssim\varepsilon^2$ up to some sufficiently small constant guarantees that the above probability remains bounded by $\frac{1}{4}$. Furthermore, by the data-processing inequality, $\kl(\cQ^u_T\|\pi)\le\kl(\cQ^u\|\cQ^*)\lesssim\varepsilon^2$.
\end{proof}

\paragraph{Controlled Monte Carlo Diffusion (CMCD, \citet{vargas2024transport}).} We borrow the notations from \cref{sec:jar} due to its similarity with JE.

Given $(\pit_t)_{t\in[0,T]}$ and the ALD (\cref{eq:jar_pr}), we know from the proof of \cref{thm:jar} that to make $X_t\sim\pit_t$ for all $t$, the compensatory drift term $(v_t)_{t\in[0,T]}$ must generate $(\pit_t)_{t\in[0,T}$. 
Now, consider the task of learning such a vector field $(u_t)_{t\in[0,T]}$ by matching the following forward and backward SDEs:
\begin{align*}
    \cPr:~~&\d X_t=(\nabla\log\pit_t+u_t)(X_t)\d t+\sqrt{2}\d B_t,~X_0\sim\pit_0,\\
    \cPl:~~&\d X_t=(-\nabla\log\pit_t+u_t)(X_t)\d t+\sqrt{2}\d\Bl_t,~X_T\sim\pit_T,
\end{align*}
where the loss is $\kl(\cPr\|\cPl)$, discretized in training. Obviously, when trained to optimality, both $\cPr$ and $\cPl$ share the marginal distribution $\pit_t$ at every time $t$. By Girsanov theorem (\cref{lem:rn_path_measure_contd}), one can prove the following identity for a.s. $X\sim\cPr$: $\log\de{\cPr}{\cPl}(X)=W(X)+C^u(X)-\Delta F$, where $\Delta F$ and $W(X)$ are defined as in \cref{thm:jar}, and
$$C^u(X):=-\int_0^T(\inn{u_t(X_t),\nabla\log\pit_t(X_t)}+\nabla\cdot u_t(X_t))\d t.$$
We refer readers to \citet[Prop. 3.3]{vargas2024transport} for the detailed derivation. By $\E_{\cPr}\de{\cPl}{\cPr}=1$, we know that $\E_{\cPr}\e^{-W(X)-C^u(X)}=\e^{-\Delta F}$. 
As the paper has not established inference-time performance guarantee given the training loss, we prove the following result characterizing the relationship between the training loss and the accuracy of the sampled distribution as well as the estimated normalizing constant.

\begin{proposition}
    Let $\Zh=Z_0\e^{-W(X)-C^u(X)}$, $X\sim\cPr$ be an unbiased estimator of $Z=Z_0\e^{-\Delta F}$. Then, to achieve both $\kl(\cPr_T\|\pi)\lesssim\varepsilon^2$ (where $\cPr_T$ is the law of $X_T$ in the sampled trajectory $X\sim\cPr$) and $\prob\ro{\abs{\frac{\Zh}{Z}-1}\le\varepsilon}\ge\frac{3}{4}$, it suffices to choose $u$ that satisfies $\kl(\cPr\|\cPl)\lesssim\varepsilon^2$.
\end{proposition}

\begin{proof}
    The proof of this theorem follows the same reasoning as that of \cref{thm:pis_complexity}. For normalizing constant estimation,
    $$\prob\ro{\abs{\frac{\Zh}{Z}-1}}=\cPr\ro{\abs{\de{\cPl}{\cPr}-1}\ge\varepsilon}\lesssim\frac{\tv(\cPr,\cPl)}{\varepsilon}\lesssim\frac{\sqrt{\kl(\cPr\|\cPl)}}{\varepsilon}\lesssim1.$$
    For sampling, the result is an immediate corollary of the data-processing inequality.
\end{proof}