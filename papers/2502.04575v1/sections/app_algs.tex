\section{Pseudo-codes of the Algorithms}
\label{app:algs}
See \cref{alg:ais,alg:rds} for the detailed implementation of the AIS and RDS algorithms, respectively.

\begin{algorithm}[ht]
    \caption{Normalizing constant estimation via AIS.}
    \SetAlgoLined
    \SetCommentSty{emph}
    \KwIn{The target distribution $\pi\propto\e^{-V}$, smoothness parameter $\beta$, total time $T$; 
    TI annealing schedule $\lambda_0>...>\lambda_K=0$; 
    AIS annealing schedule $\lambda(\cdot)$ with $\lambda(0)=2\beta$, AIS time points $0=\theta_0<...<\theta_M=1$.
    }

    \KwOut{$\Zh$, an estimation of $Z=\int_{\R^d}\e^{-V(x)}\d x$.}

    \tcp{Phase 1: estimate $Z_0$ via TI.}

    Define $V_0:=V+\beta\|\cdot\|^2$, $\rho_k:\propto\exp\ro{-V_0-\frac{\lambda_k}{2}\|\cdot\|^2}$, and $g_k:=\exp\ro{\frac{\lambda_k-\lambda_{k+1}}{2}\|\cdot\|^2}$, for $k\in\sqd{0,K-1}$\;

    Initialize $\Zh_0\gets\exp\ro{-V_0(0)+\frac{\|\nabla V_0(0)\|^2}{2(3\beta+\lambda_0)}}\ro{\frac{2\pi}{3\beta+\lambda_0}}^\frac{d}{2}$\;

    \For{$k=0$ \KwTo $K-1$}{
    Obtain $N$ i.i.d. approximate samples $x_1^{(k)},...,x_N^{(k)}$ from $\rho_k$ (e.g., using LMC or proximal sampler)\;

    Update $\Zh_0\gets\ro{\frac{1}{N}\sum_{n=1}^{N}g_k(X_n^{(k)})}\Zh_0$\;
    }

    \tcp{Phase 2: estimate $Z$ via AIS.}

    Approximately sample $x_0$ from $\pi_0$ (e.g., using LMC or proximal sampler)\;

    Initialize $W\gets-\frac{1}{2}(\lambda(\theta_0)-\lambda(\theta_1))\|x_0\|^2$\;

    \For{$\l=1$ \KwTo $M-1$}{
    Sample an independent $\xi\sim\n{0,I_d}$\;

    Define $\varLambda(t):=\int_0^t\lambda\ro{\theta_{\l-1}+\frac{\tau}{T_\l}(\theta_\l-\theta_{\l-1})}\d\tau$, where $T_\l:=T(\theta_\l-\theta_{\l-1})$\;

    Update $x_{\l}\gets\e^{-\varLambda(T_\l)}x_{\l-1}-\ro{\int_0^{T_\l}\e^{-(\varLambda(T_\l)-\varLambda(t))}\d t}\nabla V(x_{\l-1})+\ro{2\int_0^{T_\l}\e^{-2(\varLambda(T_\l)-\varLambda(t))}\d t}^\frac{1}{2}\xi$\tcp*{see \cref{lem:ais_ker_fh_update} for the derivation}

    Update $W\gets W-\frac{1}{2}(\lambda(\theta_\l)-\lambda(\theta_{\l+1}))\|x_\l\|^2$\;
    }

    \Return{$\Zh=\Zh_0\e^{-W}$}
    
    \label{alg:ais}
\end{algorithm}

\begin{algorithm}[ht]
    \caption{Normalizing constant estimation via RDS.}
    \SetAlgoLined
    \SetCommentSty{emph}
    \KwIn{The target distribution $\pi\propto\e^{-V}$, total time duration $T$, early stopping time $\delta\ge0$, time points $0=t_0<t_1<...<t_N=T-\delta$;
    score estimator $s_\cdot\approx\nabla\log\pib_\cdot$.
    }
    \KwOut{$\Zh$, an estimation of $Z=\int_{\R^d}\e^{-V(x)}\d x$.}

    Sample $X_0\sim\n{0,I}$, and initialize $W:=-\frac{\|X_0\|^2}{2}-\frac{d}{2}\log2\pi$\;

    \For{$k=0$ \KwTo $N-1$}{
    Sample an independent pair of 
    $\begin{pmatrix}\xi_1\\\xi_2\end{pmatrix}\sim\n{0,\begin{pmatrix}1&\rho_k\\\rho_k&1\end{pmatrix}\otimes I}$, where the correlation is $\rho_k=\frac{\sqrt{2}(\e^{t_{k+1}-t_k}-1)}{\sqrt{(\e^{2(t_{k+1}-t_k)}-1)(t_{k+1}-t_k)}}$, and $\otimes$ stands for the Kronecker product\;

    Update $X_{t_{k+1}}\gets\e^{t_{k+1}-t_k}X_{t_k}+2(\e^{t_{k+1}-t_k}-1)s_{T-t_k}(X_{t_k})+\sqrt{\e^{2(t_{k+1}-t_k)}-1}\xi_1$\tcp*{see \cref{lem:rds_update} for the derivation}

    Update $W\gets W+(t_{k+1}-t_k)\|s_{T-t_k}(X_{t_k})\|^2+\sqrt{2(t_{k+1}-t_k)}\inn{s_{T-t_k}(X_{t_k}),\xi_2}$\tcp*{see \cref{lem:rds_update} for the derivation}
    }

    Update $W\gets W+V(X_{t_N})+(T-\delta)d$\;
    
    \Return{$\Zh=\e^{-W}$.}
    
    \label{alg:rds}
\end{algorithm}