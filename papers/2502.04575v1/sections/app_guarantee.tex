\section{Review and Discussion on the Error Guarantee (\cref{eq:acc_whp})}
\label{app:guarantee}
\subsection{Literature Review of Existing Bounds}
\paragraph{Estimation of $Z$.} Traditionally, the statistical properties of an estimator are typically analyzed through its bias and variance. However, deriving closed-form expressions of the variance of $\Zh$ and $\Fh$ in JE remains challenging. Recall that the estimator $\Zh=Z_0\e^{-W(X)}$, $X\sim\Pr$ for $Z=Z_0\e^{-\Delta F}$, and that JE implies $\bias\Zh=0$. For general (sub-optimally) controlled SDEs, \cite{hartmann2024nonasymptotic} established both upper and lower bounds of the relative error of the importance sampling estimator, yet bounds tailored for JE are not well-studied. Inspired by this, we establish an upper bound on the \emph{normalized variance} $\var\frac{\Zh}{Z}$ in \cref{thm:jar_var} at the end of this section using techniques in R\'enyi divergence. However, we remark that connecting this upper bound to the properties of the curve (e.g., action) is non-trivial, which we leave for future work. 

\paragraph{Estimation of $F$.} Turning to the estimator $\Fh=-\log\Zh$ for $F=-\log Z$, we have
$$\bias\Fh=\E_{\Pr}W-\Delta F=\cW-\Delta F=\cW_\mathrm{diss}.$$
Bounding the average dissipated work $\cW_\mathrm{diss}=\kl(\Pr\|\Pl)=-\E_{\Pr}\int_0^T(\partial_t\log\pit_t)(X_t)\d t$ remains challenging as well, as the law of $X_t$ under $\Pr$ is unknown, thus complicating the bounding of the expectation. To the best of our knowledge, \cite{chen2020stochastic} established a lower bound in terms of $W_2(\pi_0,\pi_1)$ via the Wasserstein gradient flow, but an upper bound remains elusive. Furthermore, $\E\Fh^2=\E_{\Pr(X)}\ro{\log Z_0-W(X)}^2$ is similarly intractable to analyze. 

For multiple estimators, i.e., $\Fh_K:=-\log\ro{Z_0\frac{1}{M}\sum_{k=1}^K\e^{-W(X^{(k)})}}$ where $X^{(1)},...,X^{(K)}\iid\Pr$, \cite{zuckerman2002theory,zuckerman2004systematic} (see also \citet[Sec. 4.1.5]{lelievre2010free}) derived approximate asymptotic bounds on $\bias\Fh_K$ and $\var\Fh_K$ via the delta method (or equivalently, the central limit theorem and Taylor expansions). Precise and non-asymptotic bounds remain elusive to date.

\subsection{Equivalence in Complexities for Estimating $Z$ and $F$}
We prove the claim in \cref{rmk:guarantee} that estimating $Z$ with $O(\varepsilon)$ relative error and estimating $F$ with $O(\varepsilon)$ absolute error share the same complexity up to absolute constants. This follows directly from \cref{lem:logat1}: for any $\varepsilon\in\ro{0,\frac{1}{2}}$,
$$\mbox{\cref{eq:acc_whp}}\implies\prob\ro{|\Fh-F|\le2\varepsilon}\ge\frac{3}{4},\quad\text{and}\quad\mbox{\cref{eq:acc_whp}}\impliedby\prob\ro{|\Fh-F|\le\frac{\varepsilon}{2}}\ge\frac{3}{4}.$$

\subsection{\cref{eq:acc_whp} is Weaker than Bias and Variance}
We demonstrate that \cref{eq:acc_whp} is a weaker criterion than controlling bias and variance, which is an immediate result from the Chebyshev inequality:
$$\prob\ro{\abs{\frac{\Zh}{Z}-1}\ge\varepsilon}\le\frac{1}{\varepsilon^2}\E\ro{\frac{\Zh}{Z}-1}^2=\frac{\bias^2\Zh+\var\Zh}{\varepsilon^2Z^2},$$
$$\prob\ro{|\Fh-F|\ge\varepsilon}\le\frac{\E(\Fh-F)^2}{\varepsilon^2}=\frac{\bias^2\Fh+\var\Fh}{\varepsilon^2}.$$

On the other hand, suppose one has established a bound in the following form: 
$$\prob\ro{\abs{\frac{\Zh}{Z}-1}\ge\varepsilon}\le p(\varepsilon),\quad\text{for some}~p:[0,\infty)\to[0,1],$$
and assume that $\Zh$ is unbiased. Then this implies
$$\var\frac{\Zh}{Z}=\E\ro{\frac{\Zh}{Z}-1}^2=\int_0^\infty\prob\ro{\ro{\frac{\Zh}{Z}-1}^2\ge\varepsilon}\d\varepsilon\le\int_0^\infty p(\sqrt\varepsilon)\d\varepsilon.$$

\subsection{An Upper Bound on the Normalized Variance of $\Zh$ in Jarzynski Equality}
\begin{proposition}
    Under the setting of JE (\cref{thm:jar}), let $(v_t)_{t\in[0,T]}$ be any vector field that generates $(\pit_t)_{t\in[0,T]}$, and define $\P$ as the path measure of \cref{eq:jar_p}. Then, 
    $$\var\frac{\Zh}{Z}\le\sq{\E_\P\exp\ro{14\int_0^T\|v_t(X_t)\|^2\d t}}^\frac{1}{2}-1.$$
    \label{thm:jar_var}
\end{proposition}

\begin{proof}
The proof is inspired by \cite{chewi2022analysis}. Note that
$$\var\frac{\Zh}{Z}=\E\ro{\frac{\Zh}{Z}}^2-1=\E_{\Pr}\ro{\e^{-W(X)+\Delta F}}^2-1=\E_{\Pr}\ro{\de{\Pl}{\Pr}}^2-1,$$
which is the $\chi^2$ divergence from $\Pl$ to $\Pr$. Recall the $q(>1)$-R\'enyi divergence defined as $\renyi_q(\mu\|\nu)=\frac{1}{q-1}\log\E_\nu\ro{\de{\mu}{\nu}}^q$, and that $\chi^2(\Pl\|\Pr)=\e^{\renyi_2(\Pl\|\Pr)}-1$. By the weak triangle inequality of R\'enyi divergence \cite[Lem. 6.2.5]{chewi2022log}: 
$$\renyi_2(\Pl\|\Pr)\le\frac{3}{2}\renyi_4(\Pl\|\P)+\renyi_3(\P\|\Pr).$$

We now bound $\E_\P\ro{\de{\Pr}{\P}}^q$ for any $q\in\R$. By Girsanov theorem (\cref{lem:rn_path_measure}),
$$\log\de{\Pr}{\P}(X)=\int_0^T\ro{-\frac{1}{\sqrt{2}}\inn{v_t(X_t),\d B_t}-\frac{1}{4}\|v_t(X_t)\|^2\d t},~\text{a.s.}~X\sim\P.$$

Therefore,
\begin{align*}
    &\E_\P\ro{\de{\Pr}{\P}}^q\\
    &=\E_\P\exp\int_0^T\ro{-\frac{q}{\sqrt{2}}\inn{v_t(X_t),\d B_t}-\frac{q}{4}\|v_t(X_t)\|^2\d t}\\
    &=\E_\P\exp\sq{\int_0^T\ro{-\frac{q}{\sqrt{2}}\inn{v_t(X_t),\d B_t}-\frac{q^2}{2}\|v_t(X_t)\|^2\d t}+\int_0^T\ro{\frac{q^2}{2}-\frac{q}{4}}\|v_t(X_t)\|^2\d t}\\
    &\le\ro{\E_\P\exp\sq{\int_0^T\ro{-\sqrt{2}q\inn{v_t(X_t),\d B_t}-q^2\|v_t(X_t)\|^2\d t}}}^\frac12\\
    &\cdot\ro{\E_\P\exp\sq{\ro{q^2-\frac{q}{2}}\int_0^T\|v_t(X_t)\|^2\d t}}^\frac12,
\end{align*}
where the last line is by the Cauchy-Schwarz inequality. Let $M_t:=-\sqrt{2}q\int_0^t\inn{v_r(X_r),\d B_r}$, $X\sim\P$ be a continuous martingale with quadratic variation $[M]_t=\int_0^t2q^2\|v_r(X_r)\|^2\d r$. By \citet[Chap. 3.5.D]{karatzas1991brownian}, the process $t\mapsto\e^{M_t-\frac{1}{2}[M]_t}$ is a super martingale, and hence $\E\e^{M_T-\frac{1}{2}[M]_T}\le1$. Thus, we have 
$$\E_\P\ro{\de{\Pr}{\P}}^q\le\ro{\E_\P\exp\sq{\ro{q^2-\frac{q}{2}}\int_0^T\|v_t(X_t)\|^2\d t}}^\frac12$$
From Girsanov theorem (\cref{lem:rn_path_measure_contd}), we can similarly obtain the following RN derivative:
$$\log\de{\Pl}{\P}(X)=\int_0^T\ro{-\frac{1}{\sqrt{2}}\inn{v_t(X_t),*\d\Bl_t}-\frac{1}{4}\|v_t(X_t)\|^2\d t},~\text{a.s.}~X\sim\P.$$
and use the same argument to show that $\E_\P\ro{\de{\Pl}{\P}}^q$ has exactly the same upper bound as $\E_\P\ro{\de{\Pr}{\P}}^q$. In particular, we can use the same martingale argument, whereas now the \emph{backward} continuous martingale is defined as $M'_t:=-\sqrt{2}q\int_t^T\inn{v_r(X_r),*\d\Bl_r}$, $X\sim\P$, with quadratic variation $[M']_t=\int_t^T2q^2\|v_r(X_r)\|^2\d r$. Therefore, we conclude that
\begin{align*}
    \renyi_2(\Pl\|\Pr)&\le\frac{1}{4}\log\E_\P\exp\ro{14\int_0^T\|v_t(X_t)\|^2\d t}+\frac{1}{4}\log\E_\P\exp\ro{5\int_0^T\|v_t(X_t)\|^2\d t}\\
    &\le\frac{1}{2}\log\E_\P\exp\ro{14\int_0^T\|v_t(X_t)\|^2\d t}.
\end{align*}
\end{proof}