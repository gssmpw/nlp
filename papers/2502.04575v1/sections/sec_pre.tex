\section{Preliminaries}
\label{sec:pre}
\paragraph{Notations and definitions.}
For $a,b\in\R$, let $\sqd{a,b}:=[a,b]\cap\Z$, $a\wedge b:=\min(a,b)$, and $a\vee b:=\max(a,b)$.
For $a,b>0$, the notations $a\lesssim b$, $b\gtrsim a$, $a=O(b)$, $b=\Omega(a)$ indicate that $a\le Cb$ for some constant $C>0$, and the notations $a\asymp b$, $a=\Theta(b)$ stand for $a\lesssim b\lesssim a$. $\Ot\ro{\cdot},\Thetat\ro{\cdot}$ hide logarithmic dependence in $O(\cdot),\Theta(\cdot)$.
A function $U\in C^2(\R^d)$ is $\alpha(>0)$-strongly-convex if $\nabla^2U\succeq\alpha I$, and is $\beta(>0)$-smooth if $-\beta I\preceq\nabla^2U\preceq\beta I$.
We do not distinguish probability measures on $\R^d$ from their Lebesgue densities.
For two probability measures $\mu,\nu$, the total-variation (TV) distance is $\tv(\mu,\nu)=\sup_{\textrm{measurable}~A}|\mu(A)-\nu(A)|$, and the Kullback-Leibler (KL) divergence is $\kl(\mu\|\nu)=\int\log\de{\mu}{\nu}\d\mu$.
We call $\E_\mu\|\cdot\|^2$ the second-order moment of $\mu$.
Finally, a function $T:\R^d\times\R^d\to[0,\pif)$ is a transition kernel if for any $x$, $T(x,\cdot)$ is a p.d.f.

\subsection{Stochastic Differential Equations and Girsanov Theorem}
Throughout this paper, $(B_t)$ and $(W_t)$ represent standard Brownian motions (BM) on $\R^d$. For a stochastic differential equation (SDE) $X=(X_t)_{t\in[0,T]}$ defined on $\Omega=C([0,T];\R^d)$, the distribution of $X$ over $\Omega$ is called the \textbf{path measure} of $X$, defined by $\P^X$: measurable $A\subset\Omega\mapsto\prob(X\in A)$. 
The following lemma
, as a corollary of the Girsanov theorem \cite[Prop. 2.3.1 \& Cor. 2.3.1]{ustunel2013transformation},
provides a method for computing the Radon-Nikod\'ym (RN) derivative and KL divergence between two path measures, which serves as a key technical tool in our proof.


\begin{lemma}
    \label{lem:rn_path_measure}
    Assume we have the following two SDEs with $t\in[0,T]$:
    $$\d X_t=a_t(X_t)\d t+\sigma\d B_t,~X_0\sim\mu;\quad\d Y_t =b_t(Y_t)\d t+\sigma\d B_t,~Y_0\sim\nu.$$
    Denote the path measures of $X$ and $Y$ as $\P^X$ and $\P^Y$, respectively. Then for any trajectory $\xi\in\Omega$, 
    \begin{align*}
        \log\de{\P^X}{\P^Y}(\xi) & =\log\de{\mu}{\nu}(\xi_0)+\frac{1}{\sigma^2}\int_0^T\inn{a_t(\xi_t)-b_t(\xi_t),\d\xi_t}-\frac{1}{2\sigma^2}\int_0^T(\|a_t(\xi_t)\|^2-\|b_t(\xi_t)\|^2)\d t.
    \end{align*}
    In particular, plugging in $\xi\gets X\sim\P^X$, we can compute the KL divergence:
    $$\kl(\P^X\|\P^Y)=\kl(\mu\|\nu)+\frac{1}{2\sigma^2}\int_0^T\E_{\P^X}\|a_t(X_t)-b_t(X_t)\|^2\d t.$$
\end{lemma}

We now define the \textbf{backward SDE}, which can be perceived as the time-reversal of a forward SDE. Given a BM $(B_t)_{t\in[0,T]}$, let its time-reversal be $(\Bl_t:=B_{T-t})_{t\in[0,T]}$. We say that a process $(\Xl_t)_{t\in[0,T]}$ satisfies the backward SDE
$$\d\Xl_t=a_t(\Xl_t)\d t+\sigma\d\Bl_t,~t\in[0,T];~\Xl_T\sim\nu$$
if its time-reversal $(X_t=\Xl_{T-t})_{t\in[0,T]}$ satisfies the following forward SDE:
$$\d X_t=-a_{T-t}(X_t)\d t+\sigma\d B_t,~t\in[0,T];~X_0\sim\nu.$$

The forward and backward SDEs are related through the Nelson's relation (\cref{lem:nelson}), which also allows us to calculate the RN derivative between path measures of forward and backward SDEs (\cref{lem:rn_path_measure_contd}). We postpone the detailed derivations to \cref{app:pre}.

\subsection{Wasserstein Distance, Metric Derivative, and Action}
We provide a concise overview of essential concepts in optimal transport (OT) that will be used in the paper. See standard textbooks \citep{villani2021topics,villani2008optimal,ambrosio2008gradient,ambrosio2021lectures} for details. 

For two probability measures $\mu,\nu$ on $\R^d$ with finite second-order moments, the \textbf{Wasserstein-2 ($\textbf{W}_\textbf{2}$) distance} between $\mu$ and $\nu$ is defined as $W_2(\mu,\nu)=\inf_{\gamma\in\Pi(\mu,\nu)}\ro{\int\|x-y\|^2\gamma(\d x,\d y)}^{\frac{1}{2}}$, where $\Pi(\mu,\nu)$ is the set of all couplings of $(\mu,\nu)$.
The Brenier's theorem states that when $\mu$ has a Lebesgue density, then there exists a unique coupling $\ro{\id\times T_{\mu\to\nu}}_\sharp\mu$ that reaches the infimum. Here, $\sharp$ stands for the push-forward of a measure ($T_\sharp\mu(\cdot)=\mu(\{\omega:T(\omega)\in\cdot\})$), and $T_{\mu\to\nu}$ is known as the \textbf{OT map} from $\mu$ to $\nu$ and can be written as the gradient of a convex function.

Given a vector field $v=(v_t)_{t\in[a,b]}$ and a curve of probability measures $\rho=(\rho_t)_{t\in[a,b]}$ with finite second-order moment on $\R^d$, we say that $v$ \textbf{generates} $\rho$ if the continuity equation $\partial_t\rho_t+\nabla\cdot(\rho_tv_t)=0$, $t\in[a,b]$ holds in the weak sense. The \textbf{metric derivative} of $\rho$ at $t\in[a,b]$ is defined as
$$|\dot\rho|_t:=\lim_{\delta\to0}\frac{W_2(\rho_{t+\delta},\rho_t)}{|\delta|},$$
which can be interpreted as the speed of this curve. We say $\rho$ is \textbf{absolutely continuous (AC)} if $|\dot\rho|_t$ exists and is finite for Lebesgue-a.e. $t\in[a,b]$. The metric derivative and the continuity equation are related through the following fact \citep[Thm. 8.3.1 \& Prop. 8.4.5]{ambrosio2008gradient}:
\begin{lemma}
    For an AC curve of probability measures $(\rho_t)_{t\in[a,b]}$, any vector field $(v_t)_{t\in[a,b]}$ that generates $(\rho_t)_{t\in[a,b]}$ satisfies $|\dot\rho|_t\le\|v_t\|_{L^2(\rho_t)}$ for Lebesgue-a.e. $t\in[a,b]$. Moreover, there exists an a.s. unique vector field $(v^*_t\in L^2(\rho_t))_{t\in[a,b]}$ that generates $(\rho_t)_{t\in[a,b]}$ and satisfies $|\dot\rho|_t=\|v^*_t\|_{L^2(\rho_t)}$ for Lebesgue-a.e. $t\in[a,b]$, which is $v^*_t=\lim_{\delta\to0}\frac{T_{\rho_t\to\rho_{t+\delta}}-\id}{\delta}$.
    \label{lem:metric}
\end{lemma}

Finally, we define the \textbf{action} of an AC curve of probability measures $(\rho_t)_{t\in[a,b]}$ as $\int_a^b|\dot\rho|_t^2\d t$, which plays a key role in characterizing the efficiency of a curve for normalizing constant estimation. For basic properties of the action and its relation to isoperimetric inequalities such as log-Sobolev and Poincar\'e inequalities, we refer the reader to \citet[Lem. 3 \& Ex. 1]{guo2025provable}.

\subsection{Langevin Diffusion and Langevin Monte Carlo}
The (overdamped) \textbf{Langevin diffusion (LD)} with target distribution $\pi\propto\e^{-V}$ is the solution to
\begin{equation}
    \d X_t=-\nabla V(X_t)\d t+\sqrt{2}\d B_t,~t\in[0,\infty).
    \label{eq:ld}
\end{equation}
Under mild regularity conditions, $\pi$ is the unique stationary distribution of this SDE, and when $\pi$ has good properties such as strong log-concavity, $X_t$ converges to $\pi$ in probability rapidly. In practice, when the closed-form solution of this SDE is unavailable, one usually leverages the Euler-Maruyama scheme to discretize \cref{eq:ld}, leading to the (overdamped) \textbf{Langevin Monte Carlo (LMC)} algorithm: with step size $h>0$, iterate the following update rule for $k=0,1,...$:
\begin{equation}
    X_{(k+1)h}=X_{kh}-h\nabla V(X_{kh})+\sqrt{2}(B_{(k+1)h}-B_{kh}),~\text{where}~B_{(k+1)h}-B_{kh}\iid\n{0,hI}.
    \label{eq:lmc_disc}
\end{equation}

\subsection{Reverse Diffusion Samplers}
Inspired by score-based generative models \citep{song2021scorebased}, recent advancements have led to the development of multimodal samplers based on reversing the Ornstein-Uhlenbeck (OU) process \citep{huang2024reverse,huang2024faster,he2024zeroth,vacher2025polynomial}. In this paper, we collectively refer to these methods as the \textbf{reverse diffusion samplers (RDS)}.

The following OU process transforms any target distribution $\pi$ into $\phi:=\n{0,I}$ as $T\to\infty$:
\begin{equation}
    \d Y_t=-Y_t\d t+\sqrt{2}\d B_t,~t\in[0,T];~Y_0\sim\pi,
    \label{eq:ou}
\end{equation}
We denote the law of $Y_t$ by $\pib_t$. The time-reversal $(\Yl_t:=Y_{T-t}\sim\pib_{T-t})_{t\in[0,T]}$ satisfies the SDE
\begin{equation}
    \d\Yl_t=(\Yl_t+2\nabla\log\pib_{T-t}(\Yl_t))\d t+\sqrt{2}\d W_t,~t\in[0,T];~\Yl_0\sim\pib_T(\approx\phi).
    \label{eq:ou_rev}
\end{equation}
Hence, to draw samples from $\pi$, it suffices to approximate the scores $\nabla\log\pib_t$ and discretize \cref{eq:ou_rev}, which can be implemented in various ways. For example, by Tweedie's formula \citep{robbins1992an}, $\nabla\log\pib_t$ is an affine function of $\E(Y_0|Y_t=\cdot)$ (\cref{eq:rds_score}), while the law of $Y_0|Y_t=\cdot$ is analytically tractable (\cref{eq:rds_post}) and provably easier to sample from than the target $\pi$ \citep{huang2024reverse}.