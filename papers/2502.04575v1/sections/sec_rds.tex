\section{Normalizing Constant Estimation via Reverse Diffusion Sampler}
\label{sec:revdif}
From the analysis of JE and AIS (\cref{thm:jar_complexity,thm:ais_complexity}), the choice of the interpolation curve $(\pi_\theta)_{\theta\in[0,1]}$ is crucial for the complexity of AIS. The geometric interpolation (\cref{eq:pi_theta}) is widely adopted in practice due to the availability of closed-form scores of the intermediate distributions $\pi_\theta$. For certain structured non-log-concave distributions, the associated action is polynomial in the problem parameters, enabling efficient AIS. For instance, \citet[Ex. 2]{guo2025provable} analyzed a Gaussian mixture target distribution with identical covariance, means having the \textit{same} norm, and arbitrary weights. However, for general target distributions, the action of the related curve can grow prohibitively large. To illustrate this, we establish an exponential lower bound on the action of a curve starting from a Gaussian mixture, highlighting the potential inefficiency of AIS under geometric interpolation. Our key technical tool is a closed-form expression of the $\text{W}_\text{2}$ distance in $\R$ expressed by the inverse cumulative distribution functions (c.d.f.s) of the involved distributions. We then lower bound the metric derivative near the target distribution, where the curve changes the most drastically. The proof of this result is detailed in \cref{app:prf:mog_w2_action}.

\begin{proposition}
    Consider the Gaussian mixture target distribution $\pi=\frac{1}{2}\n{0,1}+\frac{1}{2}\n{m,1}$ on $\R$ for some sufficiently large $m\gtrsim1$, whose potential is $\frac{m^2}{2}$-smooth. Under the setting in AIS (\cref{thm:ais_complexity}), define $\pi_\theta(x)\propto\pi(x)\e^{-\frac{\lambda(\theta)}{2}x^2}$, $\theta\in[0,1]$, where $\lambda(\theta)=m^2(1-\theta)^r$ for some $1\le r\lesssim1$. Then, the action of the curve $(\pi_\theta)_{\theta\in[0,1]}$ is lower bounded by $\cA_r\gtrsim m^{4}\e^{\frac{m^2}{40}}$.
    \label{thm:mog_w2_action}
\end{proposition}

Motivated by RDS, we propose leveraging the curve along the OU process in AIS. To support this idea, we first present the following proposition, whose proof is available in \cref{app:prf:action_ou}.

\begin{proposition}
    Let $\pib_t$ be the law of $Y_t$ in the OU process (\cref{eq:ou}) initialized from $Y_0\sim\pi\propto\e^{-V}$, where $V$ is $\beta$-smooth and let $m^2:=\E_\pi\|\cdot\|^2<\infty$. Then, $\int_0^\infty|\dot\pib|^2_t\d t\le d\beta+m^2$.
    \label{thm:action_ou}
\end{proposition}

This proposition shows that under fairly weak conditions on the target distribution, the action of the curve along the OU process, $(\pib_{T-t})_{t\in[0,T]}$, behaves much better than \cref{eq:pi_theta}. Hence, our analysis of JE (\cref{thm:jar_complexity}) suggests that this curve is likely to yield more efficient normalizing constant estimation. Furthermore, recall that in our earlier proof, we introduced a compensatory drift term $v_t$ to eliminate the lag in ALD. The same principle applies here: ensuring $X_t$ precisely following the reference trajectory is advantageous, which results in the time-reversal of OU process (\cref{eq:ou_rev}). Building on this insight, we propose an RDS-based algorithm for normalizing constant estimation, and establish a framework for analyzing its oracle complexity. The proof is in \cref{app:prf:revdif}.

\begin{theorem}
    Assume a total time duration $T$, an early stopping time $\delta\ge0$, and discrete time points $0=t_0<t_1<...<t_N=T-\delta\le T$. For $t\in[0,T-\delta)$, let $t_-$ denote $t_k$ if $t\in[t_k,t_{k+1})$. Let $s_\cdot\approx\nabla\log\pib_\cdot$ be a score estimator, and $\phi=\n{0,I}$. Consider the following two SDEs on $[0,T-\delta]$ representing the sampling trajectory and the time-reversed OU process, respectively:
    \begin{align}
        \Qd:\quad&\d X_t=(X_t+2s_{T-t_-}(X_{t_-}))\d t+\sqrt{2}\d B_t,&X_0\sim\phi;\label{eq:ou_rev_score}\\
        \Q:\quad&\d X_t=(X_t+2\nabla\log\pib_{T-t}(X_t))\d t+\sqrt{2}\d B_t,&X_0\sim\pib_T.\nonumber
    \end{align}
    Let $\Zh:=\e^{-W(X)}$, $X\sim\Qd$ be the estimator of $Z$, where the functional $X\mapsto W(X)$ is defined as
    \begin{align*}
        \log\phi(X_0)+V(X_{T-\delta})+(T-\delta)d+\int_0^{T-\delta}\ro{\|s_{T-t_-}(X_{t_-})\|^2\d t+\sqrt{2}\inn{s_{T-t_-}(X_{t_-}),\d B_t}}.
    \end{align*}
    Then, to ensure $\Zh$ satisfies \cref{eq:acc_whp}, it suffices that $\kl(\Q\|\Qd)\lesssim\varepsilon^2$ and $\tv(\pi,\pib_\delta)\lesssim\varepsilon$.
    \label{thm:revdif}
\end{theorem}

For detailed implementation of this algorithm including the update rule in \cref{eq:ou_rev_score} and the computation of $W(X)$, see \cref{alg:rds}. To determine the overall complexity, we leverage existing results for RDS \citep{huang2024reverse,huang2024faster,he2024zeroth,vacher2025polynomial} to derive the oracle complexity to achieve $\kl(\Q\|\Qd)\lesssim\varepsilon^2$. When early stopping is needed (i.e., $\delta>0$), we establish in \cref{lem:ou_tv} that choosing $\delta\asymp\frac{\varepsilon^2}{\beta^2d^2}$ suffices to ensure $\varepsilon$-closeness in TV distance between $\pib_\delta$ and $\pi$, under weak assumptions similar to \cref{assu:pi}. The detailed complexity analysis is deferred to \cref{app:revdif_overall}.

As discussed, RDS can be viewed as an \emph{optimally compensated} ALD using the OU process as the trajectory. We conclude this section by contrasting these two approaches. On the one hand, analytically-tractable curves such as the geometric interpolation offer closed-form drift terms at all time points, but may exhibit poor action properties (\cref{thm:mog_w2_action}) or bad isoperimetric constants \citep{chehab2025provable}, making annealed sampling challenging. On the other hand, alternative curves like the OU process may have better properties in action and isoperimetric constants, but their drift terms, often related to the scores of the intermediate distributions, lack closed-form expressions, and estimating these terms is also non-trivial. This highlights a fundamental trade-off between the complexity of the drift term estimation and the property of the interpolation curve. 