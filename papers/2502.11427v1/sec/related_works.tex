\section{Related Work}
\label{sec:related-work}
\paragraph{Large Vision-Language Models.}
Large vision-language models~(LVLMs)~\cite{liu2024visual,liu2024improved} are capable of processing visual and textual inputs and tackling a variety of multimodal tasks. 
% The key to building advanced LVLM is enabling LLMs to comprehend images and inherit the LLM's task-solving abilities for multimodal tasks. 
Currently, visual instruction tuning is the predominant framework for training LVLMs. 
By training on a large number of visual instructions, LVLMs can directly learn the task-solving capabilities for the corresponding multimodal tasks. Early studies~\cite{liu2024visual,zhu2023minigpt} leverage LLMs to synthesize image-related GPT-style visual instructions. Subsequent studies leverage more advanced LVLMs~(\eg GPT-4V) for higher-quality instruction synthesis~\cite{du2023makes,chen2024allava} and quantity scaling~\cite{zhao2023svit,chen2025sharegpt4v}. 
In addition to general instruction following, another line of works focus on the LVLM's visual reasoning capability~\cite{zhang2024improve,shi2024math,gao2023g} and the performance in other visual domains~(\eg geometry~\cite{shi2024math,gao2023g}, scientific~\cite{saikh2022scienceqa}, and medical~\cite{zhang2023pmc}). Despite its success, it's costly to synthesize high-quality visual instructions, particularly when adapting to diverse new visual domains and visual tasks. 
% Furthermore, it may not be always helpful to enhance genuine capabilities through the scaling of visual instruction data~\cite{liu2024less}, as it may lead the models to learn superficial response style.

% Despite its success, visual instruction tuning tends to lead models to learn superficial response style, making it difficult to enhance genuine capabilities through the scaling of visual instruction data~\cite{liu2024less}.



\paragraph{Representation Engineering for LLMs.}
Our approach is closely related to studies of the representation engineering for LLMs~\cite{zou2023representation,turner2023activation}, which aims to extract a compact vector from the LLM's intermediate representation~(\eg hidden states). The extracted vector, also referred to as the steering vector~\cite{subramani2022extracting}, can be leveraged to manipulate the LLM's behaviour. An application of steering vectors is vector arithmetic~\cite{ilharco2022editing,turner2023activation}.
Through feature engineering~(\eg addition) of steering vectors, the LLM's behaviour can be effectively controlled.
These vectors are successfully implemented across various tasks, including style transfer~\cite{subramani2022extracting}, knowledge editing~\cite{hernandez2023inspecting}, and sentiment control~\cite{turner2023activation}. Recent researches~\cite{hendel2023context,liu2023context} extend their application to in-context learning, where they are referred to as the task vectors. In our study, we leverage steering vectors to combine the individual abilities for solving multimodal tasks.

% we extract the steering vectors for the model's different individual ability, and fuse these abilities via vector addition to elicit combined multimodal task-solving capability during inference.

% utilize different modality inputs to elicit the model's different individual ability, then extract steering vectors from the model's hidden states. Subsequently, we fuse these abilities via vector arithmetic for eliciting combined multimodal task-solving capability.


% An application of task vectors is task arithmetic~\cite{ilharco2022editing}.
% By conducting feature engineering on these task vectors, the model is capable of assembling or disassembling these individual capabilities. 
% There are mainly two ways to extract task vectors: model-based and activation-based. Model-based approach~\cite{ilharco2022editing,yadav2024ties,yu2024language,stoica2023zipit} leverages the weight difference between fine-tuned model and the original model as the task vector, which represents the capability learned from fine-tuning. The activation-based approach leverages the intermediate activations from the model's hidden states as the task vectors~\cite{turner2023activation,hendel2023context,liu2023context,todd2023function}. The activation-based task vector is first studied for in-context learning~\cite{brown2020language}, where the task vector are extracted from task demonstrations~\cite{hendel2023context}.
% In our studies, we use different modality input to stimulate the model's different capabilities, then extract task vectors from the model's hidden states. Then, we entangle these capabilities by task arithmetic for tackling vision tasks.


% These studies aim to extract a compact representation to steer the model's behaviour on a certain task, denotes as task vector. There are mainly two ways to extract task vectors. The first one leverage the weight difference between the fine-tuned model and the original model as the task vector~\cite{ilharco2022editing,yadav2024ties,yu2024language,stoica2023zipit}. The second one leverages the hidden state vectors~ as task vectors~\cite{turner2023activation,hendel2023context,liu2023context,todd2023function}. Performing arithmetic operations on these task vectors can effectively enable model to learn new task behaviour or unlearn existing task behaviour~\cite{ilharco2022editing}. Our studies also involve extracting a latent vector from hidden states for LVLM's biased behaviour and steer the LVLM's behaviour based on hidden vectors arithmetic. 


