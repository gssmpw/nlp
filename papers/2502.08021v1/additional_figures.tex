

\section{Subgrid Studies and Coverage Experiments}  
\paragraph{Subgrid Studies} 
Figures~\ref{fig:misspec-complete} and \ref{fig:gap-complete} show more complete results for investigating the sensitivity to misspecification and gaps in Section~\ref{sec:subgrid} across 4 settings (good/poor coverage and gravity/noise grid). 

\begin{figure}[H]
    \centering
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/mf_on_policy_gravity_7.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/mf_on_policy_noise_7.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/mf_off_policy_gravity_7.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/mf_off_policy_noise_7.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
    \phantom{\includegraphics[width=\textwidth]{figures/appendix_figures/gap_legend.pdf}}
    \end{minipage}%
    \vspace{0.01pt}
    \begin{minipage}{\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/gap_legend.pdf}
    \end{minipage}%
    \caption{Subgrid studies for gaps. Plot \textbf{MF.N} is identical to Figure~\ref{fig:misc}L.}
    \label{fig:gap-complete}
\end{figure}


\begin{figure}[H]
    \centering
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/on_policy_gravity_misspec.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/on_policy_noise_misspec.pdf}
    \end{minipage}%
    %
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/off_policy_gravity_misspec.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/off_policy_noise_misspec.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
    \phantom{\includegraphics[width=\textwidth]{figures/appendix_figures/misspecification_legend.pdf}}
    \end{minipage}%
    \vspace{0.01pt}
    \begin{minipage}{\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/misspecification_legend.pdf}
    \end{minipage}%
    \caption{Subgrid studies for misspecification. Plot \textbf{MF.N} is identical to Figure~\ref{fig:misc}M.}
    \label{fig:misspec-complete}
\end{figure}



\paragraph{Data Coverage} Figure~\ref{fig:coverage-complete} shows more complete results for the data coverage experiment in Section~\ref{sec:exp-coverage}, including more choices of $M^\star$. 


\begin{figure}[h]
    \centering
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/data_coverage_0_no_legend.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/data_coverage_7_no_legend.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/data_coverage_14_no_legend.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/coverage_legend.pdf}
    \end{minipage}%
    \caption{Data coverage results. Left figure is identical to Figure~\ref{fig:misc}L. \label{fig:coverage-complete}}
\end{figure}

\subsection{Poor Coverage Results} \label{app:poor-coverage}
We now show the counterpart of our model-free main results (Figure~\ref{fig:mainfigure}) under behavior policies that offer poor coverage. This makes the problem very challenging and no single algorithm have strong performance across the board. For example, na\"ive model-based demonstrate strong performance in \textbf{MF.OFF.G} (top row of Figure~\ref{fig:poor-coverage}) and resilience to poor coverage, while still suffers  catastrophic failures in \textbf{MF.OFF.N}. While \lstd generally is more reliable than other methods, it also has worse-than-random performance in one of the environments in \textbf{MF.OFF.G}.

\begin{figure}[h!]
    \centering
    \begin{minipage}{0.75\textwidth}
        \includegraphics[width=\linewidth]{figures/appendix_figures/mf_off_policy_sample_eff.pdf}
    \end{minipage}%
    \begin{minipage}{0.25\textwidth}
%
%
                \includegraphics[width=\linewidth]{figures/appendix_figures/mf_off_policy_sample_eff_legend.pdf}
%
%
%
 %
 %
        \caption{Model-free selection results under behavior policies with poor coverage (\textbf{MF.OFF.G/N}). \label{fig:poor-coverage}}
 %
%
%
    \end{minipage}
\end{figure}

\subsection{LSTDQ Family} \label{app:lstd}
As mentioned at the end of Section~\ref{sec:mf-select}, our \lstd can have several variants depending on how we design and transform the linear features. Here we compare 3 of them in Figure~\ref{fig:lstdq_sample_eff}. The \lstd method in all other figures corresponds to the ``normalized\_diff'' version. 
\begin{itemize}
    \item \textbf{Vanilla:} $\phi_{i,j} = [Q_i, Q_j]$.
    \item \textbf{Normalized:} $\phi_{i,j} = [Q_i/c_i, Q_j/c_j]$, where $c_i = \sqrt{\mathbb{V}_{(s,a)\sim \mu}[Q_i(s,a)]}$ normalizes the discriminators to unit variance on the data distribution. In practice these variance parameters are estimated from data.
    \item \textbf{Normalized\_diff:} $\phi_{i,j} = [Q_i/c_i, (Q_j-Q_i)/c_{j,i}]$, where $c_i$ and $c_{j,i}$ performs normalization in the same way as above. 
\end{itemize}



\clearpage

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/appendix_figures/lstdq_sample_eff.pdf}
    \caption{Comparison of variants of \lstd.}
    \label{fig:lstdq_sample_eff}
\end{figure}

\clearpage 

\subsection{$O(1)$ Rollouts} 
In our experiment design, we use a fairly significant number of rollouts $l=128$ to ensure relatively accurate estimation of the Q-values. However, for the average Bellman error and the \lstd algorithms, they enjoy convergence even when $l$ is a constant. For example, consider the average Bellman error:
$$
\EE_{\Dcal}[Q_i(s,a) - r - \gamma Q_i(s',\pi)],
$$
which is an estimation of 
$\EE_{\mu}[Q_i(s,a) - r - \gamma Q_i(s',\pi)]$. 
Thanks to its linearity in $Q_i$, replacing $Q_i$ with its few-rollout (or even single-rollout) Monte-Carlo estimates will leave the unbiasedness of the estimator intact, and Hoeffding's inequality implies convergence as the sample size $n=|\Dcal|$ increases, even when $l$ stays as a constant, which is an advantage compared to other methods. That said, in practice, having a relatively large $l$ can still  be useful as it reduces the variance of each individual random variable that we average across $\Dcal$, and the effect can be significant when $n$ is relatively small. 

A similar but slightly more subtle version of this property also holds for \lstd. Take the vanilla version in Section~\ref{sec:mf-select} as example, we need to estimate
$$
\EE_{\Dcal}[Q_j(s,a)(Q_i(s,a) - r - \gamma Q_i(s',\pi))].
$$
Again, we can replace $Q_j$ and $Q_i$ with their Monte-Carlo estimates, as long as the Monte-Carlo trajectories for $Q_i$ and $Q_j$ are independent. This naturally holds in our implementation when $j\ne i$, but is violated when $j=i$ since $Q_j(s,a)$ and $Q_i(s,a)$ will share the same set of random rollouts, leading to biases. A straightforward resolution is to divide the Monte-Carlo rolllouts into two sets, and $Q_j(s,a)$ and $Q_i(s,a)$ can use different sets when $j\ne i$. We empirically test this procedure in Figure~\ref{fig:rollouts}, where the OPE errors of average Bellman error and different variants of \lstd are plotted against the number of rollouts in each set (i.e., $l/2$). While a small number of rollouts can sometimes lead to reasonable performance, more rollouts are often useful in providing further variance reduction and hence more accurate estimations.   %


\begin{figure}[H]
    \centering
\includegraphics[width=\linewidth]{figures/appendix_figures/multiple_rollouts.pdf}
    \includegraphics[width=\linewidth]{figures/appendix_figures/multiple_rollouts_loss.pdf}
    \caption{The effect of small rollouts in \lstd methods. Sample size is fixed at $n=3200$ and only $l$ (the number of rollouts) varies. Since the rollouts are divided into two separate sets to ensure independence, each Q-value is estimated using $l/2$ rollouts in this experiment, which is shown on the x-axes. The top row shows the OPE error (i.e., final performance), whereas the bottom row shows the convergence of loss estimates. \label{fig:rollouts}}
\end{figure}

\begin{comment}
\subsection{Linearity Between Bellman Error and J Error}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{figures/appendix_figures/occupancy.pdf}
    \caption{Linearity}
\end{figure}
\end{comment}