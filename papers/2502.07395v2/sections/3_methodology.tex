\section{Methodology}
\label{3_methodology}
In this section, we explain our methodology, detailing the data collection process and our approach to answering the research questions.

\subsection{Overview}
Figure \ref{fig:workflow} shows an overview of the study workflow. To answer research questions, we collect PyPI packages from the security advisories in the GitHub advisory database. Our methodology examines how developers report vulnerabilities as outlined in security policies and compares this with developers' actual practices. We manually categorize the instructions provided in these policies and then identify any security issues that do not conform to them. To highlight the importance of effective security policies, we assess security practices using the OpenSSF Scorecard for both packages with and without a security policy. By comparing the scores, we identify specific practices that show significant improvements when a security policy is implemented.

% \morakot{mention this somewhere here rather than the intro focusing on the PyPi packages available on GitHub\chaiyong{May need some support on why we're interested in the PyPi packages}. Given Python is a widely used programming language in the software development, as indicated in the 2023 Stack-Overflow survey \cite{TopProgrammingLanguage:online}.}




% We investigate the process how developers report the vulnerability outlined in the security policy, with the developer's actual practices toward these policies. By manually categorizing the instructions of this process in the security policies. We then identify any new security issues that do not conform to the policies. To define practical security practices that emphasize the importance of the security policy, we use the OpenSSF Scorecard to assess the security practices of the packages, both with and without a security policy. We then determine the difference score to identify the practices that would significantly differ in score if the packages had implemented a security policy.

% \morakot{add a figure of research methodology} \bee{done}

\subsection{Data collection}
Our study incorporates three data sets: (1) GitHub repositories of the PyPi packages that appear in the GitHub advisory database, (2) security issues from GitHub repositories, and (3) security practice scores from the OpenSSF Scorecard. We gathered GitHub repositories of the PyPi packages with at least one GitHub advisory record from GitHub Advisory Database \cite{GitHubAdvisoryDatabase:online}, which includes vulnerability advisories published before May 2024. The initial dataset contains 2,982 security advisories for PyPi packages. To ensure the accuracy of the collection process, we verified key repository values of the advisory, \texttt{source\_code\_location}, which links to the reported repositories.





% To collect the PyPi packages, We gathered PyPi packages with at least one GitHub advisory record from GitHub Advisory Database \cite{GitHubAdvisoryDatabase:online} to ensure the packages were actively addressing security vulnerabilities. The dataset includes vulnerability advisories published before May 2024. The initial dataset contains 2,982 security advisories of PyPi packages. We identify the affected repositories by identifying a key value \texttt{source\_code\_location} for each advisory. \texttt{source\_code\_location} provide the links to the repository. To ensure that we can access the correct repository, collect the security policy, and their issues, we filtered the advisories with this key value and collected the repository links. \chaiyong{Why do we need to specify this name?} \bee{done-fixed the previous sentence}. The advisories with an accessible repository correspond to 2,311 advisories across 679 different packages.

In the GitHub security-related issues collection, we utilized WordNet \cite{WordNetDoc:online} to identify synonyms and related words based on a core set of terms: [``vulnerability'', ``security'', ``risk'', ``CVE'', ``CWE'']. We collected the issues that have the labels containing these security-related keywords. The dataset of security issues includes the metadata of the issues, which comprises links to the issues, titles, labels with security keywords, submitter information, and submission dates. Lastly, we used the OpenSSF Scorecard tool to assess the security practices of collected repositories. The dataset includes scores for 18 security practices along with an overall security score, with each practice score ranging from -1 to 10.

% Lastly, we utilized the OpenSSF Scorecard tool to assess the security practices score of 679 packages. The dataset includes 18 security practice scores with an overall security score, which each practice score ranges between -1 to 10.

\subsection{Data processing}
We began by performing data filtering to ensure the quality and relevance of the repositories analyzed. First, we excluded the OpenSSF Scorecard criterion rated as -1, as this rating indicates that the tool was unable to generate a score due to insufficient data or an internal error during the assessment process. Additionally, we excluded one repository that contained over 1,000 issue reports, treating it as an outlier due to its atypically high volume of issues. Following this initial filtering, we categorized the repositories into two groups. The first group included repositories with a defined security policy, identified by the presence of \texttt{SECURITY.md}, \texttt{security.md}, or \texttt{security.rst} files in either the top-level directory or the \texttt{.github} folder. 

The second group comprised repositories without any security policy files. This classification allowed us to compare security practices between projects with and without explicit security policies in place. Note that the OpenSSF Scorecard considers the presence of a security policy under the ``Security Policy'' criterion. To ensure a fair comparison, we excluded the ``Security Policy'' score from our analysis, as the existence of a security policy directly impacts the overall OpenSSF score. In conclusion, our dataset comprises 679 repositories, with 303 containing the security policy and 376 without one.


% We then conclude that our dataset contain.....

% classified the collected GitHub PyPi repositories into

% that contain \texttt{SECURITY.md}, \texttt{security.md}, or \texttt{security.rst} files in the top-level directory, or \texttt{.github} of the repository. 

% We excluded one package because its security issue count, exceeding 1,000 issues, was identified as an outlier, lying above the upper quartile of the interquartile range (IQR). \chaiyong{May need to specify a bit more by giving the actual number} \bee{done} After filtering, the dataset includes 302 packages with security policies.

% For the OpenSSF Scorecard practices, the score of each security practice results in a score -1 to 10. A score of -1 indicates that the tool was unable to generate a score due to either insufficient data or an internal error during the measurement process. We exclude the practices if the tool generated the score of any packages as -1. The Security Policy practice is also removed as an the independent variable for this study. The security practices to be analyzed includes 10 practices which are Binary-Artifacts, Branch-Protection, CII-Best-Practices, Contributors, Dependency-Update-Tool, Fuzzing, License, Maintained, SAST, and Vulnerabilities.

% \morakot{Briefly discuss your data analysis approach to answer RQ here} \bee{done}

\subsection{Data Analysis}
To address RQ1, we analyze the content specified in security policies. GitHub security policies typically guide developers on reporting vulnerabilities and security issues, detailing the reporting mechanisms available. The classification process was conducted collaboratively among the authors. We manually classified these mechanisms by examining the content to identify the specific methods or channels provided for issue reporting one by one. When discovering new reporting mechanisms, we expanded the methods and conducted the classification iteratively. To ensure consistency and minimize the influence of individual biases, we calculated Cohenâ€™s Kappa \cite{jacob_cohen:1960} for the reliability of the manual analysis, achieving an agreement score of 0.9. Our analysis revealed four distinct reporting mechanisms: reporting through email, external links (e.g., proprietary issue tracking systems), GitHub advisories, and GitHub Issue creation. The definition and example practices are presented in Table \ref{tab:reporting_mechanism_def}. This classification allowed us to identify the most commonly used reporting methods.

\begin{table}[h!]
\centering
\caption{Reporting Mechanism Definition}
\label{tab:reporting_mechanism_def}
\begin{tabular}{p{1.2cm}p{3.2cm}p{2.7cm}}
\toprule
\textbf{Reporting Mechanism} & \textbf{Definition} & \textbf{Example} \\ \midrule
Email & The project provides the process to report the vulnerabilities through sending an email & If you discover a security vulnerability or would like to report a security issue privately and securely, please email us at \censortext{security@openmicroscopy.org.} \\

GitHub Advisory & The project provides the process to report the vulnerabilities by submitting a GitHub Advisory & To report a vulnerability head over to the Security Advisories page and click on "New draft security advisory". \\

GitHub Issue & The project provides the process to report the vulnerabilities by creating an issue & Please report a vulnerability as an issue; our team will evaluate it and address it in the proper time. \\

External link & The project provides another platform (e.g., bug bounty program) or external links for further information about the security policy & Please report sensitive security issues via \censortext{Spotify's} bug-bounty program by following this instruction, rather than GitHub. \\

Not mentioned & The project did not provide the reporting mechanism in the security policy & \\ \bottomrule

\end{tabular}
\end{table}


% \begin{table*}[h!]
% \centering
% \caption{Reporting Mechanism definition}
% \label{tab:reporting_mechanism_def}
% \begin{tabular}{lll}
% \toprule
% \textbf{Reporting Mechanism} & \textbf{Definition} & \textbf{Example} \\ \midrule
% Email & The project provides the process to report the vulnerabilities through sending an email & If you discover a security vulnerability or would like to report a security issue privately and securely, please email us at \censortext{security@openmicroscopy.org.} \\

% GitHub Advisory & The project provides the process to report the vulnerabilities by submiting GitHub Advisory & To report a vulnerability head over to the Security Advisories page and click on "New draft security advisory".\\

% GitHub Issue & The project provides the process to report the vulnerabilities by creating an issue & please report a vulnerability as an issue, our team will evaluate it and address in the proper time \\

% External link & The project provides an another plaforms (e.g., bug bounty program) or external links for further information about security policy & Please report sensitive security issues via \censortext{Spotify's} bug-bounty program by following this instruction, rather than GitHub. \\

% Not mentioned & The project did not provide the reporting mechanism in the security policy & \\ \bottomrule

% \end{tabular}
% \end{table*}


% The classification process was conducted collaboratively among the authors, however, we recognize that a more robust approach, such as calculating Cohen's kappa \cite{jacob_cohen:1960} for agreement rates, could further validate our findings. We plan to incorporate this improvement in future work.

For RQ2, we examine repositories that specify reporting methods such as Email, External Links, and GitHub Advisory in their security policies. Specifically, we assess whether, after the declaration of these policies, any security-related issues were reported as GitHub Issues, which would be non-compliant with the stated reporting methods. 

To address RQ3, we perform a statistical comparison of OpenSSF Scorecard scores between repositories with a security policy and those without one.


% We define this process as a ``reporting mechanism''. We manually classify the reporting mechanisms in the security policy, by looking into the content and having the discussion among the authors about the process that are defined directly in the security policy. 

% \chaiyong{This is confusing. Please paraphrase. What is ``explore the security policy''? Is it ``reading the security policy''?} \bee{done-fixed the whole sentences}

% Some packages offer external links instead of directly specify the process in the policy. Since the policy did not explicitly define the process directly, we defined the reporting mechanism of this packages as external links. Consequently, we discovered four distinct reporting mechanisms: Emails, External links, GitHub advisory, and Issues. 

% After classifying the reporting mechanism, we identify any new security issues that do not conform to the reporting mechanism defined in their security policy (i.e., the security issues that exist in the packages that provide the reporting mechanism as Emails, External links, or GitHub Advisory).

% To answer RQ3, we perform statistical comparison on the OpenSSF Scorecard between the group of repositories with security policy and without security policy.

% we measure the security practices of the packages using OpenSSF Scorecard. From 18 security practices, we analyzed 10 security practices score. For each practice, we analyzed the minimum, maximum, average scores, along with the \texttt{p-value} for the significant difference. Including comparing the security practice scores of the packages with and without an established security policy to identify the practices that would improved if the packages established the security policy.