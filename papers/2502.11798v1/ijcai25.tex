%%%% ijcai25.tex

% \typeout{BackdoorDM: A Comprehensive Benchmark for Backdooring Learning on Diffusion Model}

% These are the instructions for authors for IJCAI-25.
\pdfoutput=1
\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai25.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai25}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
% \usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage[switch]{lineno}
\usepackage[pdftex]{graphicx}
% Our namespace
\usepackage{xspace}
% \usepackage{xcolor}     
\usepackage[table]{xcolor}
\usepackage{booktabs} 
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2 \end{tabular}}
\usepackage{subfigure}
\usepackage[T1]{fontenc}    % 选择合适的字体编码
\newcommand{\ohorn}{\^{o}}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{multirow}

\usepackage{listings}
% 定义 listings 风格，可以定义多个
\lstdefinestyle{mystyle}{
    % backgroundcolor=\color{backcolour},  % 背景色
    commentstyle= \color{red!50!green!50!blue!50},  % 注释的颜色
    keywordstyle= \color{blue!70},  % 关键字/程序语言中的保留字颜色
    numberstyle=\tiny\color{codegray},  % 左侧行号显示的颜色
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,  % 对过长的代码自动换行
    captionpos=b,
    keepspaces=true,
    % numbers=left,  % 在左侧显示行号
    % numbersep=5pt,
    showspaces=false,
    showstringspaces=false,  % 不显示字符串中的空格
    showtabs=false,
    tabsize=2,
    frame=shadowbox  % [none | single | shadowbox] 显示边框
}
\lstset{style=mystyle}  % 使用 listings 风格

\def\eg{\emph{e.g.}\xspace} 
\def\Eg{\emph{E.g.}\xspace}
\def\ie{\emph{i.e.}\xspace} 
\def\Ie{\emph{I.e.}\xspace}
\def\cf{\emph{c.f.}\xspace} 
\def\Cf{\emph{C.f.}\xspace}
\def\etc{\emph{etc}\xspace} 
\def\vs{\emph{vs}\xspace}
\def\wrt{\emph{w.r.t.}\xspace} 
\def\dof{d.o.f\xspace}
\def\etal{\emph{et al}\xspace}
\newcommand{\vect}[1]{\boldsymbol{#1}}

\definecolor{darkred}{rgb}{0.7,0,0}
\definecolor{darkgreen}{rgb}{0,0.46,0}
\definecolor{purple}{rgb}{0.6,0,0.5}
\definecolor{cholocate}{HTML}{d2691e}
\definecolor{slateblue}{HTML}{6a5acd}
\newcommand{\wl}{\color{darkred}}
\newcommand{\yy}{\color{darkgreen}}
\newcommand{\nj}{\color{cholocate}}
\newcommand{\jl}{\color{purple}}
\newcommand{\liu}{\color{slateblue}}
\newcommand{\fin}{\color{black}}
\newcommand{\todo}{\color{red}$\blacktriangleright$~}
\newcommand{\eqdef}{\stackrel{\sf def}{=}}

% Comment out this line in the camera-ready submission
% \linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2025.0)
}

\title{BackdoorDM: A Comprehensive Benchmark for Backdoor Learning \\in Diffusion Model}


% Single author syntax
% \author{
%     Anonymous submission
%     % \affiliations
%     % Affiliation
%     % \emails
%     % email@example.com
% }
% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
% \iffalse
\author{
Weilin Lin$^1$
\and
Nanjun Zhou$^{1,2}$\and
Yanyun Wang$^{1}$\and
Jianze Li$^{3,4}$\and
Hui Xiong$^1$
\And
Li Liu$^{1}$\thanks{Corresponds to Li Liu (avrillliu@hkust-gz.edu.cn)}\\
\affiliations
$^1$The Hong Kong University of Science and Technology (Guangzhou)\\
$^2$South China University of Technology\\
$^3$Shenzhen Research Institute of Big Data\\
$^4$The Chinese University of Hong Kong, Shenzhen\\
% \emails
% \{first, second\}@example.com,
% third@other.example.com,
% fourth@example.com
}
% \fi

\begin{document}

\maketitle

% \wl weilin's color \fin

% \yy yanyun's color \fin

% \nj nanjun's color \fin

% \jl jianze's color \fin

\input{section/0-abs}
\input{section/1-intro}
\input{section/2-related}
\input{section/3-method}
\input{section/4-experiment}
\input{section/5-conclusion}

% \appendix

% \section*{Ethical Statement}

% \section*{Acknowledgments}


%% The file named.bst is a bibliography style file for BibTeX 0.99c
\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Achiam \bgroup \em et al.\egroup }{2023}]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[\protect\citeauthoryear{Alex}{2009}]{alex2009learning}
Krizhevsky Alex.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em https://www. cs. toronto. edu/kriz/learning-features-2009-TR. pdf}, 2009.

\bibitem[\protect\citeauthoryear{Alexey}{2020}]{alexey2020image}
Dosovitskiy Alexey.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock {\em arXiv preprint arXiv: 2010.11929}, 2020.

\bibitem[\protect\citeauthoryear{An \bgroup \em et al.\egroup }{2024}]{an2024elijah}
Shengwei An, Sheng-Yen Chou, Kaiyuan Zhang, Qiuling Xu, Guanhong Tao, Guangyu Shen, Siyuan Cheng, Shiqing Ma, Pin-Yu Chen, Tsung-Yi Ho, et~al.
\newblock Elijah: Eliminating backdoors injected in diffusion models via distribution shift.
\newblock In {\em AAAI}, 2024.

\bibitem[\protect\citeauthoryear{Bagdasaryan and Shmatikov}{2021}]{bagdasaryan2021blind}
Eugene Bagdasaryan and Vitaly Shmatikov.
\newblock Blind backdoors in deep learning models.
\newblock In {\em USENIX Security}, 2021.

\bibitem[\protect\citeauthoryear{Chavhan \bgroup \em et al.\egroup }{2024}]{chavhan2024conceptprune}
Ruchika Chavhan, Da~Li, and Timothy Hospedales.
\newblock Conceptprune: Concept editing in diffusion models via skilled neuron pruning.
\newblock {\em arXiv preprint arXiv:2405.19237}, 2024.

\bibitem[\protect\citeauthoryear{Chen \bgroup \em et al.\egroup }{2023}]{chen2023trojdiff}
Weixin Chen, Dawn Song, and Bo~Li.
\newblock Trojdiff: Trojan attacks on diffusion models with diverse targets.
\newblock In {\em CVPR}, 2023.

\bibitem[\protect\citeauthoryear{Chew \bgroup \em et al.\egroup }{2024}]{chew2024defending}
Oscar Chew, Po-Yi Lu, Jayden Lin, and Hsuan-Tien Lin.
\newblock Defending text-to-image diffusion models: Surprising efficacy of textual perturbations against backdoor attacks.
\newblock {\em arXiv preprint arXiv:2408.15721}, 2024.

\bibitem[\protect\citeauthoryear{Chou \bgroup \em et al.\egroup }{2023}]{chou2023backdoor}
Sheng-Yen Chou, Pin-Yu Chen, and Tsung-Yi Ho.
\newblock How to backdoor diffusion models?
\newblock In {\em CVPR}, 2023.

\bibitem[\protect\citeauthoryear{Chou \bgroup \em et al.\egroup }{2024}]{chou2024villandiffusion}
Sheng-Yen Chou, Pin-Yu Chen, and Tsung-Yi Ho.
\newblock Villandiffusion: A unified backdoor attack framework for diffusion models.
\newblock {\em NeurIPS}, 2024.

\bibitem[\protect\citeauthoryear{Cui \bgroup \em et al.\egroup }{2022}]{cui2022unified}
Ganqu Cui, Lifan Yuan, Bingxiang He, Yangyi Chen, Zhiyuan Liu, and Maosong Sun.
\newblock A unified evaluation of textual backdoor learning: Frameworks and benchmarks.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Dosovitskiy}{2020}]{dosovitskiy2020image}
Alexey Dosovitskiy.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[\protect\citeauthoryear{Gal \bgroup \em et al.\egroup }{2022}]{gal2022image}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or~Patashnik, Amit~H Bermano, Gal Chechik, and Daniel Cohen-Or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock {\em arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[\protect\citeauthoryear{Gu \bgroup \em et al.\egroup }{2019}]{gu2019badnets}
Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Badnets: Evaluating backdooring attacks on deep neural networks.
\newblock {\em IEEE Access}, 2019.

\bibitem[\protect\citeauthoryear{Guan \bgroup \em et al.\egroup }{2024}]{guan2024ufid}
Zihan Guan, Mengxuan Hu, Sheng Li, and Anil Vullikanti.
\newblock Ufid: A unified framework for input-level backdoor detection on diffusion models.
\newblock {\em arXiv preprint arXiv:2404.01101}, 2024.

\bibitem[\protect\citeauthoryear{Hao \bgroup \em et al.\egroup }{2024}]{hao2024diff}
Jiang Hao, Xiao Jin, Hu~Xiaoguang, Chen Tianyou, and Zhao Jiajia.
\newblock Diff-cleanse: Identifying and mitigating backdoor attacks in diffusion models.
\newblock {\em arXiv preprint arXiv:2407.21316}, 2024.

\bibitem[\protect\citeauthoryear{Hessel \bgroup \em et al.\egroup }{2021}]{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan~Le Bras, and Yejin Choi.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock {\em arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[\protect\citeauthoryear{Ho \bgroup \em et al.\egroup }{2020}]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em NeurIPS}, 2020.

\bibitem[\protect\citeauthoryear{Ho \bgroup \em et al.\egroup }{2022}]{ho2022video}
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David~J Fleet.
\newblock Video diffusion models.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Hu \bgroup \em et al.\egroup }{2023}]{hu2023tifa}
Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, and Noah~A Smith.
\newblock Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering.
\newblock In {\em ICCV}, 2023.

\bibitem[\protect\citeauthoryear{Huang \bgroup \em et al.\egroup }{2024}]{huang2024personalization}
Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Ming Hu, Tianlin Li, Geguang Pu, and Yang Liu.
\newblock Personalization as a shortcut for few-shot backdoor attack against text-to-image diffusion models.
\newblock In {\em AAAI}, 2024.

\bibitem[\protect\citeauthoryear{Jiang \bgroup \em et al.\egroup }{2021}]{jiang2021talk}
Yuming Jiang, Ziqi Huang, Xingang Pan, Chen~Change Loy, and Ziwei Liu.
\newblock Talk-to-edit: Fine-grained facial editing via dialog.
\newblock In {\em ICCV}, 2021.

\bibitem[\protect\citeauthoryear{Karra \bgroup \em et al.\egroup }{2020}]{karra2020trojai}
Kiran Karra, Chace Ashcraft, and Neil Fendley.
\newblock The trojai software framework: An opensource tool for embedding trojans into deep learning models.
\newblock {\em arXiv preprint arXiv:2003.07233}, 2020.

\bibitem[\protect\citeauthoryear{Karras \bgroup \em et al.\egroup }{2022}]{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Li \bgroup \em et al.\egroup }{2022}]{li2022backdoor}
Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia.
\newblock Backdoor learning: A survey.
\newblock {\em TNNLS}, 2022.

\bibitem[\protect\citeauthoryear{Li \bgroup \em et al.\egroup }{2023}]{li2023backdoorbox}
Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, and Shu-Tao Xia.
\newblock Backdoorbox: A python toolbox for backdoor learning.
\newblock {\em arXiv preprint arXiv:2302.01762}, 2023.

\bibitem[\protect\citeauthoryear{Li \bgroup \em et al.\egroup }{2024a}]{li2024invisible}
Sen Li, Junchi Ma, and Minhao Cheng.
\newblock Invisible backdoor attacks on diffusion models.
\newblock {\em arXiv preprint arXiv:2406.00816}, 2024.

\bibitem[\protect\citeauthoryear{Li \bgroup \em et al.\egroup }{2024b}]{li2024backdoorllm}
Yige Li, Hanxun Huang, Yunhan Zhao, Xingjun Ma, and Jun Sun.
\newblock Backdoorllm: A comprehensive benchmark for backdoor attacks on large language models.
\newblock {\em arXiv preprint arXiv:2408.12798}, 2024.

\bibitem[\protect\citeauthoryear{Lin \bgroup \em et al.\egroup }{2014}]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem[\protect\citeauthoryear{Lin \bgroup \em et al.\egroup }{2022}]{lin2022cat}
Hezheng Lin, Xing Cheng, Xiangyu Wu, and Dong Shen.
\newblock Cat: Cross attention in vision transformer.
\newblock In {\em ICME}, 2022.

\bibitem[\protect\citeauthoryear{Liu \bgroup \em et al.\egroup }{2015}]{liu2015deep}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In {\em ICCV}, 2015.

\bibitem[\protect\citeauthoryear{Liu \bgroup \em et al.\egroup }{2018}]{liu2018fine}
Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Fine-pruning: Defending against backdooring attacks on deep neural networks.
\newblock In {\em RAID}, 2018.

\bibitem[\protect\citeauthoryear{Lu \bgroup \em et al.\egroup }{2022}]{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Lu \bgroup \em et al.\egroup }{2024}]{lu2024llmscore}
Yujie Lu, Xianjun Yang, Xiujun Li, Xin~Eric Wang, and William~Yang Wang.
\newblock Llmscore: Unveiling the power of large language models in text-to-image synthesis evaluation.
\newblock {\em NeurIPS}, 2024.

\bibitem[\protect\citeauthoryear{Mo \bgroup \em et al.\egroup }{2024}]{pmlr-v235-mo24a}
Yichuan Mo, Hui Huang, Mingjie Li, Ang Li, and Yisen Wang.
\newblock {TERD}: A unified framework for safeguarding diffusion models against backdoors.
\newblock In {\em ICML}, 2024.

\bibitem[\protect\citeauthoryear{Naseh \bgroup \em et al.\egroup }{2024}]{naseh2024backdooring}
Ali Naseh, Jaechul Roh, Eugene Bagdasaryan, and Amir Houmansadr.
\newblock Backdooring bias into text-to-image models.
\newblock {\em arXiv preprint arXiv:2406.15213}, 2024.

\bibitem[\protect\citeauthoryear{Orgad \bgroup \em et al.\egroup }{2023}]{orgad2023editing}
Hadas Orgad, Bahjat Kawar, and Yonatan Belinkov.
\newblock Editing implicit assumptions in text-to-image diffusion models.
\newblock In {\em ICCV}, pages 7053--7061, 2023.

\bibitem[\protect\citeauthoryear{Pan \bgroup \em et al.\egroup }{2024}]{pan2024from}
Zhuoshi Pan, Yuguang Yao, Gaowen Liu, Bingquan Shen, H.~Vicky Zhao, Ramana~Rao Kompella, and Sijia Liu.
\newblock From trojan horses to castle walls: Unveiling bilateral data poisoning effects in diffusion models.
\newblock In {\em NeurIPS}, 2024.

\bibitem[\protect\citeauthoryear{Pang \bgroup \em et al.\egroup }{2022}]{pang2022trojanzoo}
Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, Xiapu Luo, and Ting Wang.
\newblock Trojanzoo: Towards unified, holistic, and practical evaluation of neural backdoors.
\newblock In {\em EuroS\&P}, 2022.

\bibitem[\protect\citeauthoryear{Popov \bgroup \em et al.\egroup }{2021}]{popov2021grad}
Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, and Mikhail Kudinov.
\newblock Grad-tts: A diffusion probabilistic model for text-to-speech.
\newblock In {\em ICML}, 2021.

\bibitem[\protect\citeauthoryear{Radford \bgroup \em et al.\egroup }{2021}]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em ICML}, 2021.

\bibitem[\protect\citeauthoryear{Rombach \bgroup \em et al.\egroup }{2022}]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em CVPR}, 2022.

\bibitem[\protect\citeauthoryear{Ruiz \bgroup \em et al.\egroup }{2023}]{ruiz2023dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In {\em CVPR}, 2023.

\bibitem[\protect\citeauthoryear{Schuhmann \bgroup \em et al.\egroup }{2022}]{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation image-text models.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Song and Ermon}{2019}]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em NeurIPS}, 2019.

\bibitem[\protect\citeauthoryear{Song \bgroup \em et al.\egroup }{2020a}]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502}, 2020.

\bibitem[\protect\citeauthoryear{Song \bgroup \em et al.\egroup }{2020b}]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock {\em arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[\protect\citeauthoryear{Struppek \bgroup \em et al.\egroup }{2023}]{struppek2023rickrolling}
Lukas Struppek, Dominik Hintersdorf, and Kristian Kersting.
\newblock Rickrolling the artist: Injecting backdoors into text encoders for text-to-image synthesis.
\newblock In {\em ICCV}, 2023.

\bibitem[\protect\citeauthoryear{Sui \bgroup \em et al.\egroup }{2024}]{sui2024disdet}
Yang Sui, Huy Phan, Jinqi Xiao, Tianfang Zhang, Zijie Tang, Cong Shi, Yan Wang, Yingying Chen, and Bo~Yuan.
\newblock Disdet: Exploring detectability of backdoor attack on diffusion models.
\newblock {\em arXiv preprint arXiv:2402.02739}, 2024.

\bibitem[\protect\citeauthoryear{Vice \bgroup \em et al.\egroup }{2024}]{vice2024bagm}
Jordan Vice, Naveed Akhtar, Richard Hartley, and Ajmal Mian.
\newblock Bagm: A backdoor attack for manipulating text-to-image generative models.
\newblock {\em TIFS}, 2024.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2024a}]{wang2024eviledit}
Hao Wang, Shangwei Guo, Jialing He, Kangjie Chen, Shudong Zhang, Tianwei Zhang, and Tao Xiang.
\newblock Eviledit: Backdooring text-to-image diffusion models in one second.
\newblock In {\em MM}, 2024.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2024b}]{wang2024the}
Haonan Wang, Qianli Shen, Yao Tong, Yang Zhang, and Kenji Kawaguchi.
\newblock The stronger the diffusion model, the easier the backdoor: Data poisoning to induce copyright breacheswithout adjusting finetuning pipeline.
\newblock In {\em ICML}, 2024.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup }{2025}]{wang2025t2ishield}
Zhongqi Wang, Jie Zhang, Shiguang Shan, and Xilin Chen.
\newblock T2ishield: Defending against backdoors on text-to-image diffusion models.
\newblock In {\em ECCV}, 2025.

\bibitem[\protect\citeauthoryear{Wu and Wang}{2021}]{wu2021adversarial}
Dongxian Wu and Yisen Wang.
\newblock Adversarial neuron pruning purifies backdoored deep models.
\newblock {\em NeurIPS}, 2021.

\bibitem[\protect\citeauthoryear{Wu \bgroup \em et al.\egroup }{2022}]{wu2022backdoorbench}
Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, and Chao Shen.
\newblock Backdoorbench: A comprehensive benchmark of backdoor learning.
\newblock {\em NeurIPS}, 2022.

\bibitem[\protect\citeauthoryear{Yu \bgroup \em et al.\egroup }{2024}]{yu2024backdoormbti}
Haiyang Yu, Tian Xie, Jiaping Gui, Pengyang Wang, Ping Yi, and Yue Wu.
\newblock Backdoormbti: A backdoor learning multimodal benchmark tool kit for backdoor defense evaluation.
\newblock {\em arXiv preprint arXiv:2411.11006}, 2024.

\bibitem[\protect\citeauthoryear{Zhai \bgroup \em et al.\egroup }{2023}]{zhai2023text}
Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, and Hang Su.
\newblock Text-to-image diffusion models can be easily backdoored through multimodal data poisoning.
\newblock In {\em MM}, 2023.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup }{2018}]{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In {\em CVPR}, 2018.

\bibitem[\protect\citeauthoryear{Zhao \bgroup \em et al.\egroup }{2024}]{zhao2024unipc}
Wenliang Zhao, Lujia Bai, Yongming Rao, Jie Zhou, and Jiwen Lu.
\newblock Unipc: A unified predictor-corrector framework for fast sampling of diffusion models.
\newblock {\em NeurIPS}, 2024.

\bibitem[\protect\citeauthoryear{Zheng \bgroup \em et al.\egroup }{2022}]{zheng2022data}
Runkai Zheng, Rongjun Tang, Jianze Li, and Li~Liu.
\newblock Data-free backdoor removal based on channel lipschitzness.
\newblock In {\em ECCV}, 2022.

\end{thebibliography}


\input{section/6-appendix}


\end{document}

