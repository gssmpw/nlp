@misc{breitenbach2023dont,
  author       = {Mark Breitenbach and Adrian Wood and Win Suen and Po-Ning Tseng},
  title        = {Don't You (Forget NLP): Prompt Injection with Control Characters in ChatGPT},
  year         = {2023},
  howpublished = {\url{https://dropbox.tech/machine-learning/prompt-injection-with-control-characters\_openai-chatgpt-llm}},
}

@article{chen2024struq,
  title={StruQ: Defending against prompt injection with structured queries},
  author={Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David},
  journal={arXiv preprint arXiv:2402.06363},
  year={2024}
}

@misc{deberta-v3-base-prompt-injection-v2,
  author = {ProtectAI.com},
  title = {Fine-Tuned DeBERTa-v3-base for Prompt Injection Detection},
  year = {2024},
  publisher = {HuggingFace},
  url = {https://huggingface.co/ProtectAI/deberta-v3-base-prompt-injection-v2},
}

@misc{gorman2022jailbreaking,
  author       = {Stuart Armstrong, rgorman},
  title        = {Using GPT-Eliezer against ChatGPT Jailbreaking},
  year         = {2022},
  howpublished = {LessWrong},
  url          = {https://www.lesswrong.com/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking},
  note         = {[Accessed 20-09-2024]}
}

@article{hines2024defending,
  title={Defending Against Indirect Prompt Injection Attacks With Spotlighting},
  author={Hines, Keegan and Lopez, Gary and Hall, Matthew and Zarfati, Federico and Zunger, Yonatan and Kiciman, Emre},
  journal={arXiv preprint arXiv:2403.14720},
  year={2024}
}

@article{huang2024semantic,
  title={Semantic-guided Prompt Organization for Universal Goal Hijacking against LLMs},
  author={Huang, Yihao and Wang, Chong and Jia, Xiaojun and Guo, Qing and Juefei-Xu, Felix and Zhang, Jian and Pu, Geguang and Liu, Yang},
  journal={arXiv preprint arXiv:2405.14189},
  year={2024}
}

@article{li2023evaluating,
  title={Evaluating the instruction-following robustness of large language models to prompt injection},
  author={Li, Zekun and Peng, Baolin and He, Pengcheng and Yan, Xifeng},
  year={2023}
}

@article{liu2023prompt,
  title={Prompt Injection attack against LLM-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Wang, Zihao and Wang, Xiaofeng and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and others},
  journal={arXiv preprint arXiv:2306.05499},
  year={2023}
}

@article{liu2024automatic,
  title={Automatic and universal prompt injection attacks against large language models},
  author={Liu, Xiaogeng and Yu, Zhiyuan and Zhang, Yizhe and Zhang, Ning and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2403.04957},
  year={2024}
}

@inproceedings{liu2024formalizing,
  title={Formalizing and benchmarking prompt injection attacks and defenses},
  author={Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  booktitle={USENIX Security Symposium},
  year={2024}
}

@misc{meta2024prompt,
  author       = {Meta},
  title        = {Prompt Guard-86M | Model Cards and Prompt formats},
  year         = {2024},
  howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/prompt-guard/}},
  note         = {Accessed: 2024-11-18}

}

@article{mkadry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={M{\k{a}}dry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={stat},
  volume={1050},
  number={9},
  year={2017}
}

@article{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@article{piet2023jatmo,
  title={Jatmo: Prompt injection defense by task-specific finetuning},
  author={Piet, Julien and Alrashed, Maha and Sitawarin, Chawin and Chen, Sizhe and Wei, Zeming and Sun, Elizabeth and Alomair, Basel and Wagner, David},
  journal={arXiv preprint arXiv:2312.17673},
  year={2023}
}

@misc{sandwich_defense_2023,
  title        = {Sandwich Defense},
  year         = {2023},
  howpublished = {\url{https://learnprompting.org/docs/prompt\_hacking/defensive\_measures/sandwich\_defense}},
}

@article{shafran2024machine,
  title={Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents},
  author={Shafran, Avital and Schuster, Roei and Shmatikov, Vitaly},
  journal={arXiv preprint arXiv:2406.05870},
  year={2024}
}

@article{shi2024optimization,
  title={Optimization-based Prompt Injection Attack to LLM-as-a-Judge},
  author={Shi, Jiawen and Yuan, Zenghui and Liu, Yinuo and Huang, Yue and Zhou, Pan and Sun, Lichao and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2403.17710},
  year={2024}
}

@article{suo2024signed,
  title={Signed-Prompt: A new approach to prevent prompt injection attacks against LLM-integrated applications},
  author={Suo, Xuchen},
  journal={arXiv preprint arXiv:2401.07612},
  year={2024}
}

@article{wallace2024instruction,
  title={The instruction hierarchy: Training llms to prioritize privileged instructions},
  author={Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex},
  journal={arXiv preprint arXiv:2404.13208},
  year={2024}
}

@misc{willison_2023,
  author       = {Simon Willison},
  title        = {Delimiters wonâ€™t save you from prompt injection},
  year         = {2023},
  howpublished = {\url{https://simonwillison.net/2023/May/11/delimiters-wont-save-you}},
}

@article{yi2023benchmarking,
  title={Benchmarking and defending against indirect prompt injection attacks on large language models},
  author={Yi, Jingwei and Xie, Yueqi and Zhu, Bin and Hines, Keegan and Kiciman, Emre and Sun, Guangzhong and Xie, Xing and Wu, Fangzhao},
  journal={arXiv preprint arXiv:2312.14197},
  year={2023}
}

@article{zhan2024injecagent,
  title={Injecagent: Benchmarking indirect prompt injections in tool-integrated large language model agents},
  author={Zhan, Qiusi and Liang, Zhixiang and Ying, Zifan and Kang, Daniel},
  journal={arXiv preprint arXiv:2403.02691},
  year={2024}
}

