\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/pipeline.pdf}
    \caption{The pipeline for the filtering method.}
    \label{fig:pipeline}
   \vspace{-15pt}
\end{figure}
\section{Detect and Remove Indirect Prompt Injection Attacks}
To investigate whether indirect prompt injection attacks can be detected and removed, we evaluate a range of detection models and two intuitive removal methods. An injected document, $d^{\text{inj}}$, is constructed by the attack method $\text{Atk}(\cdot)$ with a clean document  $d$ and an injected instruction  $x$, expressed as  $d^{\text{inj}} = \text{Atk}(d, x, \text{pos})$, where \text{pos} is the injection position and $x$  can be injected at various positions (head, middle, and tail) within  $d$.
For detection, a detection method  $D(\cdot)$  is expected to classify documents accurately, identifying injected documents ($ D(d^{\text{inj}}) = 1 $) and clean ones ($D(d) = 0$).

To mitigate prompt injection, we evaluate two intuitive removal methods: the segmentation removal method and the extraction removal method. After processing, the resulting document  $d^{\text{pro}} = R(d^{\text{inj}})$, where  $R(\cdot)$  denotes the removal method, is expected to be free of the injected instruction $x$.

\subsection{Attack Detection}
To explore the detection of indirect prompt injection attacks, we consider both classification and generative detection models. When a candidate document  $d^c$  is fed into the detection model, the last hidden states are obtained as follows:
\begin{equation}
    [h_1, h_2 \cdots h_n] = f_{\text{det}}(d^{c}) \in  {\mathbb R}^{n \times \text{dim}}
\end{equation}
where  $n$  represents the sequence length and  $\text{dim}$  denotes the hidden size.
For a classification detection model, we use the first hidden state  $h_1$, mapping it to classification logits: $z = W_1^T h_1$, where $W_1 \in \mathbb R^{\text{dim} \times 2}$. For a generative detection model, we utilize the last hidden state  $h_n$, mapping it to vocabulary logits and selecting the logits corresponding to ``no'' and ``yes'': $z = \left[ W_2^T h_n \right]_{\{\text{``no'', ``yes''}\}}$. Here,  $W_2 \in \mathbb{R}^{\text{dim} \times \left|\text{vocab}\right|}$ , where  $\left|\text{vocab}\right|$  is the vocabulary size. The prediction  $\hat{y}$  is determined by selecting the largest logit:

\begin{equation}
    \hat{y} = \arg\max_{i} z_i
\end{equation}


We also train our own models with the crafted data $\mathcal{D}_{\text{det}}$. The training objective is to minimize the cross-entropy loss:
\begin{equation}
% \small
    \mathcal{L}_{\text{det}} = - \frac{1}{N} \sum_{i=1}^{N}   \left[z_{y_i}^{(i)} - \log\left(\sum_{j=1}^C \exp(z_j^{(i)})\right)\right]
\end{equation}

Here,  $z_{y_i}^{(i)}$  is the logit corresponding to the ground truth label  $y_i$  for the  $i$-th sample, and  $z_j^{(i)}$  represents the logit for the  $j$-th class of the  $i$-th sample.  $C$  is the total number of classes, where  $C = 2 $ for classification models and  $C = \left|\text{vocab}\right|$  for generative detection models.

\subsection{Attack Removal}
To remove the injected instruction from the injected document  $d^{\text{inj}}$ , we explore two intuitive methods: \textit{segmentation removal method} and \textit{extraction removal method}.

\paragraph{Segmentation removal method.}
The key idea behind segmentation removal, as shown in Figure \ref{fig:segmetation}, is to divide the injected document into smaller segments, detect whether each segment is clean, and then combine the clean segments into a final document.
Given an injected document  $d^{\text{inj}}$ , it is divided into segments as follows:
\begin{equation}
    [s_1, s_2, \cdots , s_{k-1}, s_k] = \text{Div}(d^{inj})
\end{equation}
Here,  $\text{Div}(\cdot)$  performs the segmentation at the sentence level. Each segment  $s_i$  is then classified by the detection model: $\hat{y}_i = f_{det}(s_i)$.
For convenience, the detection model used for segment classification is the same as the one employed for document-level attack detection.
Then the segments classified as clean ($\hat{y}_i = 1$) are combined to form the processed document:

\begin{equation}
% \small
    d^{\text{pro}} = \text{Combine}\big(\{s_i \mid \hat{y}_{i} = 1, \, i = 1, 2, \dots, k\}\big)
\end{equation}

\paragraph{Extraction removal method.}
For the extraction removal method, as shown in Figure \ref{fig:extraction_removal}, the goal is to train an extraction model capable of identifying and removing the injected instruction from the injected document.
Given  $d^{\text{inj}} =\text{Atk}(d, x, \text{pos})$, where  $x$  is the injected instruction, the extraction model is trained to extract  $x$  completely. This also includes identifying both the start and end positions of the injected instruction within the document. The training loss is defined as:

% \begin{equation}
%     \mathcal{L}_\text{ext} = - \sum_{(d^{\text{inj}},x) \in \mathcal{D}_{ext}} (\log \text{Pr}(x_0 \mid d^{\text{inj}},\theta) + \sum_{t=0}^T \log \text{Pr}(x_t \mid d^{\text{inj}}, x_{<t},\theta) + \log \text{Pr}(x_T \mid d^{\text{inj}}, x_{<T} , \theta)) 
% \end{equation}
\begin{align}
% \small
\mathcal{L}_\text{ext} &= - \sum_{(d^{\text{inj}},x) \in \mathcal{D}_{ext}} \bigg( \log \Pr(x_0 \mid d^{\text{inj}}, \theta) \nonumber \\
&\quad + \frac{1}{T+1}\sum_{t=0}^T \log \Pr(x_t \mid d^{\text{inj}}, x_{<t}, \theta) \nonumber \\ 
    &\quad+ \log \Pr(x_T \mid d^{\text{inj}}, x_{<T}, \theta) \bigg)
\end{align}

where $\theta$ is the parameters of the extraction model $f_{\text{ext}}$.  $\frac{1}{T+1} \sum_{t=0}^T \log \Pr(x_t \mid d^{\text{inj}}, x_{<t}, \theta)$  is the standard language modeling loss,  $\log \Pr(x_0 \mid d^{\text{inj}}, \theta)$ and   $\log \Pr(x_T \mid d^{\text{inj}}, x_{<T}, \theta)$  are additional terms to emphasize accurate identification of the injected instructionâ€™s start and end.


Once trained, the extraction model processes a candidate document  $d^c$  to extract the injected instruction: $x_{\text{ext}} = f_{\text{ext}}(d^c)$. Then the longest common substring  $\text{ss}^*$  between  $x_{\text{ext}}$ and  $d^c$  is identified:  $\text{ss}^* = \arg\max_{\text{ss} \subseteq x_{\text{ext}}, \text{ss} \subseteq d^c} |\text{ss}|$. Finally,  $\text{ss}^*$  is removed from the candidate document:

\begin{equation}
    d^{\text{pro}} =  d^c \setminus \text{ss}^*
\end{equation}
Here,  ``$\setminus$''  represents the deletion operation.


