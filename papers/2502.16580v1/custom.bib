% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{Chen2021EvaluatingLL,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and S. Arun Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374}
}

@inproceedings{
zhou2023leasttomost,
title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
author={Denny Zhou and Nathanael Sch{\"a}rli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc V Le and Ed H. Chi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=WZH7099tgfM}
}

@inproceedings{Kojima2022LargeLM,
 author = {Kojima, Takeshi and Gu, Shixiang (Shane) and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {22199--22213},
 title = {Large Language Models are Zero-Shot Reasoners},
 volume = {35},
 year = {2022}
}

@article{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@misc{willison_2023,
  author       = {Simon Willison},
  title        = {Delimiters won’t save you from prompt injection},
  year         = {2023},
  howpublished = {\url{https://simonwillison.net/2023/May/11/delimiters-wont-save-you}},
}

@article{liu2023prompt,
  title={Prompt Injection attack against LLM-integrated Applications},
  author={Liu, Yi and Deng, Gelei and Li, Yuekang and Wang, Kailong and Wang, Zihao and Wang, Xiaofeng and Zhang, Tianwei and Liu, Yepang and Wang, Haoyu and Zheng, Yan and others},
  journal={arXiv preprint arXiv:2306.05499},
  year={2023}
}

@inproceedings{liu2024formalizing,
  title={Formalizing and benchmarking prompt injection attacks and defenses},
  author={Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  booktitle={USENIX Security Symposium},
  year={2024}
}


@article{huang2024semantic,
  title={Semantic-guided Prompt Organization for Universal Goal Hijacking against LLMs},
  author={Huang, Yihao and Wang, Chong and Jia, Xiaojun and Guo, Qing and Juefei-Xu, Felix and Zhang, Jian and Pu, Geguang and Liu, Yang},
  journal={arXiv preprint arXiv:2405.14189},
  year={2024}
}

@article{liu2024automatic,
  title={Automatic and universal prompt injection attacks against large language models},
  author={Liu, Xiaogeng and Yu, Zhiyuan and Zhang, Yizhe and Zhang, Ning and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2403.04957},
  year={2024}
}

@misc{breitenbach2023dont,
  author       = {Mark Breitenbach and Adrian Wood and Win Suen and Po-Ning Tseng},
  title        = {Don't You (Forget NLP): Prompt Injection with Control Characters in ChatGPT},
  year         = {2023},
  howpublished = {\url{https://dropbox.tech/machine-learning/prompt-injection-with-control-characters\_openai-chatgpt-llm}},
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@misc{sandwich_defense_2023,
  title        = {Sandwich Defense},
  year         = {2023},
  howpublished = {\url{https://learnprompting.org/docs/prompt\_hacking/defensive\_measures/sandwich\_defense}},
}

@article{yi2023benchmarking,
  title={Benchmarking and defending against indirect prompt injection attacks on large language models},
  author={Yi, Jingwei and Xie, Yueqi and Zhu, Bin and Hines, Keegan and Kiciman, Emre and Sun, Guangzhong and Xie, Xing and Wu, Fangzhao},
  journal={arXiv preprint arXiv:2312.14197},
  year={2023}
}

@article{chen2024struq,
  title={StruQ: Defending against prompt injection with structured queries},
  author={Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David},
  journal={arXiv preprint arXiv:2402.06363},
  year={2024}
}

@article{wallace2024instruction,
  title={The instruction hierarchy: Training llms to prioritize privileged instructions},
  author={Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex},
  journal={arXiv preprint arXiv:2404.13208},
  year={2024}
}


@article{shu2023exploitability,
  title={On the exploitability of instruction tuning},
  author={Shu, Manli and Wang, Jiongxiao and Zhu, Chen and Geiping, Jonas and Xiao, Chaowei and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={61836--61856},
  year={2023}
}

@inproceedings{yan2024backdooring,
  title={Backdooring instruction-tuned large language models with virtual prompt injection},
  author={Yan, Jun and Yadav, Vikas and Li, Shiyang and Chen, Lichang and Tang, Zheng and Wang, Hai and Srinivasan, Vijay and Ren, Xiang and Jin, Hongxia},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={6065--6086},
  year={2024}
}

@article{hubinger2024sleeper,
  title={Sleeper agents: Training deceptive llms that persist through safety training},
  author={Hubinger, Evan and Denison, Carson and Mu, Jesse and Lambert, Mike and Tong, Meg and MacDiarmid, Monte and Lanham, Tamera and Ziegler, Daniel M and Maxwell, Tim and Cheng, Newton and others},
  journal={arXiv preprint arXiv:2401.05566},
  year={2024}
}

@article{li2024backdoor,
  title={Backdoor Removal for Generative Large Language Models},
  author={Li, Haoran and Chen, Yulin and Zheng, Zihao and Hu, Qi and Chan, Chunkit and Liu, Heshan and Song, Yangqiu},
  journal={arXiv preprint arXiv:2405.07667},
  year={2024}
}

@article{rando2023universal,
  title={Universal jailbreak backdoors from poisoned human feedback},
  author={Rando, Javier and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2311.14455},
  year={2023}
}

@article{xu2023instructions,
  title={Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models},
  author={Xu, Jiashu and Ma, Mingyu Derek and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2305.14710},
  year={2023}
}

@inproceedings{yao2024poisonprompt,
  title={Poisonprompt: Backdoor attack on prompt-based large language models},
  author={Yao, Hongwei and Lou, Jian and Qin, Zhan},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7745--7749},
  year={2024},
  organization={IEEE}
}

@article{wang2024badagent,
  title={BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents},
  author={Wang, Yifei and Xue, Dizhan and Zhang, Shengjie and Qian, Shengsheng},
  journal={arXiv preprint arXiv:2406.03007},
  year={2024}
}

@article{price2024future,
  title={Future Events as Backdoor Triggers: Investigating Temporal Vulnerabilities in LLMs},
  author={Price, Sara and Panickssery, Arjun and Bowman, Sam and Stickland, Asa Cooper},
  journal={arXiv preprint arXiv:2407.04108},
  year={2024}
}

@article{xiang2024badchain,
  title={Badchain: Backdoor chain-of-thought prompting for large language models},
  author={Xiang, Zhen and Jiang, Fengqing and Xiong, Zidi and Ramasubramanian, Bhaskar and Poovendran, Radha and Li, Bo},
  journal={arXiv preprint arXiv:2401.12242},
  year={2024}
}

@article{shi2023badgpt,
  title={Badgpt: Exploring security vulnerabilities of chatgpt via backdoor attacks to instructgpt},
  author={Shi, Jiawen and Liu, Yixin and Zhou, Pan and Sun, Lichao},
  journal={arXiv preprint arXiv:2304.12298},
  year={2023}
}

@article{cao2023stealthy,
  title={Stealthy and persistent unalignment on large language models via backdoor injections},
  author={Cao, Yuanpu and Cao, Bochuan and Chen, Jinghui},
  journal={arXiv preprint arXiv:2312.00027},
  year={2023}
}
@article{dong2024philosopher,
  title={The philosopher’s stone: Trojaning plugins of large language models},
  author={Dong, Tian and Xue, Minhui and Chen, Guoxing and Holland, Rayne and Li, Shaofeng and Meng, Yan and Liu, Zhen and Zhu, Haojin},
  journal={arXiv preprint arXiv:2312.00374},
  year={2024}
}


@article{li2023evaluating,
  title={Evaluating the instruction-following robustness of large language models to prompt injection},
  author={Li, Zekun and Peng, Baolin and He, Pengcheng and Yan, Xifeng},
  year={2023}
}

@article{zhan2024injecagent,
  title={Injecagent: Benchmarking indirect prompt injections in tool-integrated large language model agents},
  author={Zhan, Qiusi and Liang, Zhixiang and Ying, Zifan and Kang, Daniel},
  journal={arXiv preprint arXiv:2403.02691},
  year={2024}
}

@article{shi2024optimization,
  title={Optimization-based Prompt Injection Attack to LLM-as-a-Judge},
  author={Shi, Jiawen and Yuan, Zenghui and Liu, Yinuo and Huang, Yue and Zhou, Pan and Sun, Lichao and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2403.17710},
  year={2024}
}
@article{shafran2024machine,
  title={Machine Against the RAG: Jamming Retrieval-Augmented Generation with Blocker Documents},
  author={Shafran, Avital and Schuster, Roei and Shmatikov, Vitaly},
  journal={arXiv preprint arXiv:2406.05870},
  year={2024}
}

@article{piet2023jatmo,
  title={Jatmo: Prompt injection defense by task-specific finetuning},
  author={Piet, Julien and Alrashed, Maha and Sitawarin, Chawin and Chen, Sizhe and Wei, Zeming and Sun, Elizabeth and Alomair, Basel and Wagner, David},
  journal={arXiv preprint arXiv:2312.17673},
  year={2023}
}

@article{suo2024signed,
  title={Signed-Prompt: A new approach to prevent prompt injection attacks against LLM-integrated applications},
  author={Suo, Xuchen},
  journal={arXiv preprint arXiv:2401.07612},
  year={2024}
}

@article{hines2024defending,
  title={Defending Against Indirect Prompt Injection Attacks With Spotlighting},
  author={Hines, Keegan and Lopez, Gary and Hall, Matthew and Zarfati, Federico and Zunger, Yonatan and Kiciman, Emre},
  journal={arXiv preprint arXiv:2403.14720},
  year={2024}
}

@article{alon2023detecting,
  title={Detecting language model attacks with perplexity},
  author={Alon, Gabriel and Kamfonas, Michael},
  journal={arXiv preprint arXiv:2308.14132},
  year={2023}
}

@inproceedings{yang2021rethinking,
  title={Rethinking stealthiness of backdoor attack against nlp models},
  author={Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={5543--5557},
  year={2021}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{llama3modelcard,

title={Llama 3 Model Card},

author={AI@Meta},

year={2024},

url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}

@misc{yang2024qwen2technicalreport,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jianxin Yang and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Xuejing Liu and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhifang Guo and Zhihao Fan},
      year={2024},
      eprint={2407.10671},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.10671}, 
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{alkhalil2021phishing,
  title={Phishing attacks: A recent comprehensive study and a new anatomy},
  author={Alkhalil, Zainab and Hewage, Chaminda and Nawaf, Liqaa and Khan, Imtiaz},
  journal={Frontiers in Computer Science},
  volume={3},
  pages={563060},
  year={2021},
  publisher={Frontiers}
}

@article{minaee2021deep,
  title={Deep learning--based text classification: a comprehensive review},
  author={Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={3},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{dubois2024alpacafarm,
  title={Alpacafarm: A simulation framework for methods that learn from human feedback},
  author={Dubois, Yann and Li, Chen Xuechen and Taori, Rohan and Zhang, Tianyi and Gulrajani, Ishaan and Ba, Jimmy and Guestrin, Carlos and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{instruction_defense_2023,
  title        = {Instruction Defense},
  year         = {2023},
  howpublished = {\url{https://learnprompting.org/docs/prompt\_hacking/defensive\_measures/instruction}},
}


@inproceedings{rajbhandari2020zero,
  title={Zero: Memory optimizations toward training trillion parameter models},
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={SC20: International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--16},
  year={2020},
  organization={IEEE}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{OpenOrca,
  title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
  author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
  year = {2023},
  publisher = {HuggingFace},
  journal = {HuggingFace repository},
  howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}


@article{2017arXivtriviaqa,
       author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},
                 Daniel and {Zettlemoyer}, Luke},
        title = "{triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}",
      journal = {arXiv e-prints},
         year = 2017,
          eid = {arXiv:1705.03551},
        pages = {arXiv:1705.03551},
archivePrefix = {arXiv},
       eprint = {1705.03551},
}

@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}


@article{bhatt2023purple,
  title={Purple llama cyberseceval: A secure coding benchmark for language models},
  author={Bhatt, Manish and Chennabasappa, Sahana and Nikolaidis, Cyrus and Wan, Shengye and Evtimov, Ivan and Gabi, Dominik and Song, Daniel and Ahmad, Faizan and Aschermann, Cornelius and Fontana, Lorenzo and others},
  journal={arXiv preprint arXiv:2312.04724},
  year={2023}
}

@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@misc{meta2024prompt,
  author       = {Meta},
  title        = {Prompt Guard-86M | Model Cards and Prompt formats},
  year         = {2024},
  howpublished = {\url{https://www.llama.com/docs/model-cards-and-prompt-formats/prompt-guard/}},
  note         = {Accessed: 2024-11-18}

}

@inproceedings{
he2021deberta,
title={DEBERTA: DECODING-ENHANCED BERT WITH DISENTANGLED ATTENTION},
author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=XPZIaotutsD}
}

@inproceedings{greshake2023not,
  title={Not what you've signed up for: Compromising real-world llm-integrated applications with indirect prompt injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  booktitle={Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
  pages={79--90},
  year={2023}
}

@misc{deberta-v3-base-prompt-injection-v2,
  author = {ProtectAI.com},
  title = {Fine-Tuned DeBERTa-v3-base for Prompt Injection Detection},
  year = {2024},
  publisher = {HuggingFace},
  url = {https://huggingface.co/ProtectAI/deberta-v3-base-prompt-injection-v2},
}

@misc{gorman2022jailbreaking,
  author       = {Stuart Armstrong, rgorman},
  title        = {Using GPT-Eliezer against ChatGPT Jailbreaking},
  year         = {2022},
  howpublished = {LessWrong},
  url          = {https://www.lesswrong.com/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking},
  note         = {[Accessed 20-09-2024]}
}

@article{hung2024attention,
  title={Attention Tracker: Detecting Prompt Injection Attacks in LLMs},
  author={Hung, Kuo-Han and Ko, Ching-Yun and Rawat, Ambrish and Chung, I and Hsu, Winston H and Chen, Pin-Yu and others},
  journal={arXiv preprint arXiv:2411.00348},
  year={2024}
}

@article{ayub2024embedding,
  title={Embedding-based classifiers can detect prompt injection attacks},
  author={Ayub, Md Ahsan and Majumdar, Subhabrata},
  journal={arXiv preprint arXiv:2410.22284},
  year={2024}
}

@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1264",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
    eprint={1606.05250},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
}

@article{zverev2024can,
  title={Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?},
  author={Zverev, Egor and Abdelnabi, Sahar and Tabesh, Soroush and Fritz, Mario and Lampert, Christoph H},
  journal={arXiv preprint arXiv:2403.06833},
  year={2024}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}



@article{mkadry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={M{\k{a}}dry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={stat},
  volume={1050},
  number={9},
  year={2017}
}