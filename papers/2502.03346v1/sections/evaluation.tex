\section{User Study}\label{sec:evaluation}

We conducted an IRB-approved, within-subjects user study (U-M HUM00254044) in which a user collaborates with a robot to jointly transport an object to a designated pose. Each user experienced the same set of conditions, each corresponding to a collaborative algorithm running on the robot: ours, and two baselines. Through mailing lists, we recruited 24 participants (4 female, 18 male, 2 other), aged 18-29 from a university population. On average, participants rated of their familiarity with robotics technology as 4.1 (SD = 0.74) on a scale from 1 (not at all familiar) to 5 (very familiar). The study lasted 45 minutes, and each participant received \$20 of compensation.


\subsection{Experiment Design}

\textbf{Task Description.} The user and the robot hold opposite ends of an object (a wooden stick) and transport it together from an initial pose to a goal pose.
Users collaborate with each algorithm three times to ensure they experience a diverse range of interactions.
At the start of each of the three trials, the user and the robot stand in predetermined configurations (\figref{fig:exp-setup}), following the same fixed order for all algorithms.

\textbf{Algorithms.}
We compare the performance of our framework (\textbf{IC-MPC}) against two baselines:

\begin{itemize}
    \item \emph{Vanilla-MPC}: A purely functional ablation of IC-MPC with no uncertainty-minimizing objective ($w_{ent} = 0$).
    \item \emph{VRNN}~\citep{ng2023takes}: A learning-based path planner based on a Variational Recurrent Neural Network that predicts the most likely future path of the object based on human demonstrations. The robot takes actions to track path predictions as closely as possible.
\end{itemize}

\textbf{Metrics.} We evaluate performance in terms of:

\textit{Objective Metrics}:
\begin{itemize}
    \item \emph{Success rate}, defined as the proportion of successful trials. A trial is successful if the following conditions hold:
    a) any part of the object reaches the goal; b) the object stays within the workspace boundary; c) the object stays parallel to the ground---i.e., not lifted above the obstacle or dropped; d) there are no obstacle collisions.
    \item \emph{Completion time}, measured as the time taken for the object to reach the goal.
    \item \emph{Acceleration}, measured as the average acceleration of the human trajectory similar to prior work~\citep{mavrogiannis2022socialmomentum}.
\end{itemize}

\textit{Subjective Metrics}:
\begin{itemize}
    \item \emph{Warmth}, \emph{Competence}, and \emph{Discomfort}, measured using the RoSAS scale~\citep{carpinella2017robotic}.
    We use the original form of the scale: a single list of 18 items in randomized order and a nine-point response scale from 1 = ``Definitely not associated'' to 9 = ``Definitely associated''.
    \item \emph{Fluency}, measured using the \emph{Fluency in HRI} scale~\citep{hoffman2019evaluating}. To reduce fatigue, we use seven of eight items that were validated with objective measures in the original paper~\citep{hoffman2019evaluating}, with one item removed as recommended.
    The items are presented in randomized order with a seven-point response scale from 1 = ``Strongly disagree'' to 7 = ``Strongly agree''.
\end{itemize}

\textbf{Hypotheses.} Our insight is that implicit communication will have observable implications for the collaboration quality of the human-robot team, at an objective and subjective level. We formalize this insight into the following two hypotheses:

\begin{enumerate}[label=\textbf{H\arabic*}]
    \item IC-MPC is more effective at completing this task in collaboration with a user compared to Vanilla-MPC and VRNN as measured by the objective metrics.
    \item IC-MPC is viewed more favorably as a collaborator compared Vanilla-MPC and VRNN as measured by users' responses to questionnaires containing the subjective metrics.
\end{enumerate}


\subsection{System Development}

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/starting-configurations.jpg}
    \caption{Users experienced three different starting configurations with each robot algorithm. From left to right: the user and the robot stand side-by-side; the user stands directly behind the robot; the user stands directly in front of the robot. For the third configuration, the user faces toward the goal and holds the object behind their back.}
    \label{fig:exp-setup}
\end{figure}

\textbf{Experimental Setup}. We deploy all algorithms on Stretch RE2 from Hello Robot~\citep{kemp2022design}, a mobile manipulator with a differential-drive mobile base and a prismatic arm.
To avoid excessive torque on the robot's end-effector, the transported object is a lightweight stick of $0.914~m$ length and $0.05~kg$ mass.
The robot's wrist motors are turned off to allow free rotation of the end effector. The lift of the robot arm is static throughout the task to constrain the object's movement to $SE(2)$.
Across our experiments, the team operates in a workspace with area $2.8 \times 5.6~m^2$.
To study the coordination of the human-robot team over a discrete decision, a single static obstacle of area $0.15 \times 0.15~m^2$ is placed in the center of the workspace (see~\figref{fig:teaser}). The workspace is fitted with an overhead Optitrack Flex 13 motion-capture (mocap) system that continuously streams poses and velocities of the robot and the user (via a construction-style helmet) at 120 Hz.

\textbf{Human modeling}. Since our study involved an environment with a single obstacle, we set $\Psi = \{\textsc{left}, \textsc{right}\}$, corresponding respectively to $w<0$ and $w>0$.
We instantiated the strategy inference using analytical models of the prior distribution and joint action likelihood distribution~\eqref{eq:inference-bayes}. However, it is possible to approximate this inference using data-driven techniques, e.g., by learning them from datasets of demonstrations~\citep{ng2023takes, freeman2023classification}.

We model the prior distribution over the joint strategy as a function of the winding number $w$. Without loss of generality, when $p_0, o, g$ are collinear, we consider the obstacle to have been passed when $\left|w\right| \ge \frac{1}{4}$:
\begin{equation}
\begin{split}
    \mathbb{P}(\textsc{left} \mid p, c) &= \max\left(0, \min\left(0.5 - 2w, 1\right)\right) \\
    \mathbb{P}(\textsc{right} \mid p, c) &= \max\left(0, \min\left(0.5 + 2w, 1\right)\right)
\end{split}
\end{equation}

Before the obstacle is passed, the action likelihood distribution models the most likely action as the velocity that maximizes change in the winding number $w$. We approximate this as
\begin{equation}
\begin{split}
    \mathbb{P}(a \mid \textsc{left}, p, c) &\propto \exp\left(a \cdot R\left(\frac{\pi}{3}\right) \overrightarrow{po}\right) \\
    \mathbb{P}(a \mid \textsc{right}, p, c) &\propto \exp\left(a \cdot R\left(-\frac{\pi}{3}\right) \overrightarrow{po}\right)
\end{split}
\end{equation}
where $R(\cdot)$ is a 2D rotation matrix.
After the obstacle is passed, the most likely action is instead in the direction of the goal.
We illustrate the prior and action likelihood distributions for $\psi=\textsc{left}$ in \figref{fig:prior-distribution}. The same model of the action likelihood distribution is used for human and robot actions.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/distributions.png}
    \caption{Workspace traversal strategy inference. The prior distribution for $\mathbb{P}(\textsc{left} \mid p, c)$ is shown as a colormap in the background, and the mode of the action likelihood distribution for $\mathbb{P}(a \mid \textsc{left}, p, c)$ is shown using gray arrows in the foreground.}
    \label{fig:prior-distribution}
\end{figure}

Prior to the user study, we evaluated our analytical models using the simulation dataset provided by~\citet{ng2023takes}.
We considered the subset of dataset environments with a single obstacle and annotated each trajectory with a ground truth joint strategy label.
The prior and action likelihood distributions achieved 98.9\% and 72.4\% accuracy in this subset of the dataset, respectively.

\textbf{MPC}.
All algorithms are implemented using an open-source package~\citep{arm-mppi} for Model Predictive Path Integral (MPPI) control~\citep{williams2017mppi}.
The same discount factor $\gamma = 0.95$, planning horizon $15 \times 0.25\,s$, and number of rollout samples $(100)$ is used across all algorithms. IC-MPC and Vanilla-MPC use obstacle clearance threshold $\delta = 0.5$ and weight $w_{obs} = 1.0$. IC-MPC uses entropy weight $w_{ent} = 1.0$.
These parameters were empirically selected to ensure good performance in our environment during pilot hardware trials, and different workspace configurations may require different parameter combinations.
Observations of human velocities are downsampled to 10 Hz from the motion capture, and a constant velocity model is used for the human motion prediction rollouts~\citep{scholler2020constant}.
All algorithms run on an Intel i7-13700 CPU at 15 Hz.

\textbf{VRNN}.
We adapt MPC to track VRNN's prediction of the object's future path as closely as possible as in~\citet{ng2023takes}. However, we found that path predictions occasionally have undefined orientations, e.g., the output of the model contains states for which $\left|\cos \theta\right| > 1$.
Consequently, we use only the translational component of the path predictions.
Since VRNN is designed to avoid obstacles and reach the goal, we use a running cost based on Euclidean distance to the predicted path and no terminal cost.


\subsection{Procedure}

Before the study, participants received information about the purpose of the study and data collection. They provided informed consent, acknowledging that their participation was voluntary and that they would not receive descriptions of the robot algorithms until the end of the study.
They were then brought into the motion capture area and instructed to wear a helmet to be tracked by the mocap system. They were instructed to hold the object with both hands, keeping it parallel to the ground, and to collaborate with the robot in whichever way felt natural to them, including moving around the robot. To get familiarized with the interaction and the task, participants completed three practice rounds in which the robot was teleoperated before the main experiment.

For the main portion of the experiment, participants experienced each condition (a different algorithm embodied on the robot) three consecutive times. After each condition, participants were informed of the number of times they succeeded at the task with the robot and directed to respond to a questionnaire about their latest experience.
To account for ordering effects, we randomized items in both questionnaires every time they were presented.
Additionally, we performed counterbalancing of the conditions by randomly assigning participants to one of six possible orderings of the three conditions.

\begin{table}
\centering
\caption{Summary of objective metrics. Success rate is calculated out of 72 total trials for each algorithm. Mean and standard deviation of Time and Acceleration consider only successful trials.\label{table:h1}}
\resizebox{\linewidth}{!}{
\begin{tabular}{llll}
     \toprule
     Metric                              & IC-MPC        & Vanilla-MPC  & VRNN \\
     \midrule
     Success rate (\%) $\uparrow$        & \textbf{98.6} & 88.9         & 51.4 \\
     Completion time (s) $\downarrow$    & 28.54 (1.26)  & 28.86 (3.68) & \textbf{24.98 (1.67)}  \\
     Acceleration ($m/s^2$) $\downarrow$ & 0.67 (0.15)   & 0.69 (0.17)  & 0.71 (0.14) \\
     \bottomrule
\end{tabular}
}
\end{table}


\subsection{Analysis}

We found that objective and subjective metrics did not uniformly pass the Shapiro-Wilk test of normality. Thus, for consistency, we use the non-parametric Friedman test to detect effects of the robot algorithms on dependent variables and the non-parametric paired Wilcoxon signed-rank test with Holm-Bonferroni corrections~\citep{holm1979simple} for post-hoc pairwise comparison tests. Effect sizes are reported using Kendall's coefficient of concordance (denoted as $W_k$ to disambiguate it from the test statistic of the Wilcoxon signed-rank test) and Cohen's $d$.

\textbf{H1}.
We report a summary of objective metrics for each algorithm in~\tabref{table:h1}.
IC-MPC exhibited substantially higher \emph{success rate} compared to both Vanilla-MPC and VRNN.
We found a significant effect of the robot algorithm on \emph{completion time} ($\chi^2(2)=20.61, p < 0.001, W=0.45$). Post-hoc tests indicated that, of successful trials, IC-MPC completed the task \emph{slower} compared to VRNN ($W=3.0, p<0.001, d=2.4$).
We found no significant difference in \emph{completion time} between IC-MPC and Vanilla-MPC ($W=92.0, p=0.17, d=-0.11$). Finally, of successful trials, we found no significant effect of the robot algorithm on \emph{acceleration} ($\chi^2(2)= 3.73, p=0.15, W=0.08$).
Thus, we find partial support for \textbf{H1}.


\begin{table}
\centering
\caption{Mean and standard deviation of subjective metrics.\newline$^{*}p<.05$, $^{**}p<.01$, $^{***}p<.001$\label{table:h2-pairwise}}
\resizebox{\linewidth}{!}{
\begin{tabular}{llll}
     \toprule
     Metric                   & IC-MPC               & Vanilla-MPC        & VRNN                \\
     \midrule
     Warmth~\citep{carpinella2017robotic}  $\uparrow$      & 3.44 (1.89)          & 3.12 (1.98)        & 2.99 (1.82)         \\
     Competence~\citep{carpinella2017robotic} $\uparrow$   & \textbf{6.06 (1.86)} & 5.15 (1.82)$^{*}$  & 4.02 (1.88)$^{***}$ \\
     Discomfort~\citep{carpinella2017robotic} $\downarrow$ & \textbf{2.15 (1.29)} & 2.86 (1.84)$^{*}$  & 3.22 (1.49)$^{***}$ \\
     \midrule
     Fluency~\citep{hoffman2019evaluating} $\uparrow$      & \textbf{5.73 (1.02)} & 4.64 (1.41)$^{**}$ & 3.67 (1.49)$^{***}$ \\
     \bottomrule
\end{tabular}
}
\end{table}


\textbf{H2}. We report subjective measures in~\tabref{table:h2-pairwise} and related test statistics in Table~\ref{table:h2-friedman}. Prior to testing, we evaluated Cronbach's alpha within each RoSAS subscale (\emph{warmth} $\alpha=0.90$, \emph{competence} $\alpha=0.92$, \emph{discomfort} $\alpha=0.85$) and within the \emph{Fluency} scale ($\alpha=0.95$) and found that all subscales had high internal consistency.
Individual users' responses to items within each subscale were subsequently averaged for analysis.

\begin{table}
\centering
\caption{Friedman test results on subjective measures.\label{table:h2-friedman}}
\resizebox{.7\linewidth}{!}{%
\begin{tabular}{llll}
     \toprule
     Metric         & $\chi^2(2)$ & $p$       & $W_k$ \\
     \midrule
     Warmth~\citep{carpinella2017robotic}       & 3.85        & 0.146     & 0.08   \\
     Competence~\citep{carpinella2017robotic}   & 18.86       & $< 0.001$ & 0.39   \\
     Discomfort~\citep{carpinella2017robotic}   & 15.46       & $< 0.001$ & 0.32   \\ \midrule
     Fluency~\citep{hoffman2019evaluating}      & 28.15       & $< 0.001$ & 0.59   \\
     \bottomrule
\end{tabular}
}
\end{table}

We found a significant effect of the robot algorithm on users' perception of \emph{competence}, \emph{discomfort}, and \emph{fluency}.
Post-hoc tests found that IC-MPC was judged by users as: significantly more \emph{competent} compared to Vanilla-MPC ($W=55, p=0.021, d=0.49$) and VRNN ($W=26, p<0.001, d=1.09$); significantly less \emph{discomforting} compared to Vanilla-MPC ($W=30, p=0.018, d=-0.44$) and VRNN ($W=13.5, p<0.001, d=-0.76$); a significantly more \emph{fluent} collaborator compared to Vanilla-MPC ($W=28, p=0.002, d=0.89$) and VRNN ($W=11, p<0.001, d=1.61$).
No statistically significant effect was found on users' perception of \emph{warmth}.
Thus, we find partial support for \textbf{H2}.


\begin{figure*}
  \includegraphics[width=\textwidth]{figures/heatmap.png}
  \caption{Spatial distribution of object trajectories within the workspace during the user study, including failure cases, itemized per algorithm. IC-MPC exhibits an almost uniform split between right and left, whereas baselines show mixed performance, including undesirable zig-zagging effects, an artifact of increased uncertainty over the unfolding traversal strategy.
  }
  \label{fig:qualitative-results}
\end{figure*}


\subsection{Discussion}

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/entropy.png}
    \caption{Entropy over the workspace traversal strategy as a proxy for strategy uncertainty, averaged across all trials for each algorithm. By directly minimizing the entropy, IC-MPC accelerates consensus on a traversal strategy. This reduces undesirable zig-zagging artifacts, present in the execution of baselines (see~\figref{fig:qualitative-results}).}
    \label{fig:post-hoc-uncertainty}
\end{figure}

Our hypotheses were motivated by a supposition that an absence of communication would create situations in which the two agents attempt to follow contradictory strategies, resulting in longer task duration, sudden movements to avoid collisions, or task failure altogether.
We believed these situations would have a negative impact on users' opinion of the robot as a teammate.
To better understand our findings, we examine motion capture data collected during the study.

The spatial distribution of object trajectories (\figref{fig:qualitative-results}) reveals that teams took \emph{wider} paths around the obstacle when the robot was running IC-MPC compared to Vanilla-MPC and VRNN.
This difference in behavior may explain our findings for \emph{success rate} and \emph{completion time}.
Without implicit communication mechanisms to resolve ambiguity or achieve consensus on traversal strategy, both baselines would often drive straight towards the goal and attempt to pass the obstacle from directions opposite the user, leading to collisions.
By acting \emph{earlier} to take \emph{wider} paths compared to Vanilla-MPC and VRNN, IC-MPC reduced uncertainty about the joint strategy faster than baselines (\figref{fig:post-hoc-uncertainty}), thereby reducing the chance of similar collisions.
As wider paths are longer than more direct paths, teams took more time on average to complete the task when the robot was running IC-MPC compared to VRNN.
Similarity between average \emph{completion time} of IC-MPC and Vanilla-MPC is coincidental: Vanilla-MPC had a tendency to slow to a near stop as it approached close to the obstacle.

We speculated that users would make sudden movements to avoid collisions caused by disagreement in joint strategy, particularly when collaborating with baselines that lack a communicative mechanism. However, in this study, we found no significant difference in the average \emph{acceleration} of the human across robot algorithms. We made two observations that could serve as possible explanations. First, the maximum speed of the Stretch RE2 (0.3 m/s) is well below users' average walking speed, which caused them to consistently alternate between taking a step and pausing to wait for the robot to cover more distance, regardless of the algorithm. Second, the slow speed of the robot gave users a relatively long time to change course to avoid a collision, if they decided to do so. Thus, \emph{sudden} movements were uncommon.

Users noticed qualitative differences among algorithms. In open-ended responses, they described VRNN as ``unpredictable'' and ``indecisive''.
One user described Vanilla-MPC as ``a bad teammate that only does what they think is right''.
Two users who interacted with IC-MPC after one or both baselines whose comments were comparative in nature wrote that IC-MPC ``felt more natural'' and that ``the collaboration on the task was a lot more seamless in this series of attempts''.

In contrast to \emph{competence}, \emph{discomfort}, and \emph{fluency}, we did not find any significant effect of robot algorithm on users' perception of \emph{warmth}.
This is not surprising, as we did not design IC-MPC or the robot to be anthropomorphic or socially expressive.
At the start of each study session, we intentionally provided the vague instruction to ``collaborate in whichever way feels natural''.
However, we received informal feedback from several participants that aspects of the interaction, including communication with the robot, \emph{did not feel natural} or \emph{intuitive}.
Participants expressed confusion about \emph{how} they could communicate with the robot and whether the robot was acknowledging, understanding, or ignoring what they were trying to communicate.
Designing the robot to be expressive may facilitate interactions that are perceived as more natural.
