\section{Balancing Functional and Communicative Actions in Human-Robot Collaborative Transport}

We describe a control framework that leverages implicit communication to support efficient and fluent collaboration in human-robot collaborative transport. By reasoning about its partner's uncertainty over the \emph{way} the task is being executed, the robot balances between communicative, uncertainty-reducing actions, and functional, task-driven actions. This balance is not prescribed, but rather dynamically adaptive to the robot's belief about the uncertainty of its partner.


\subsection{Formalizing Joint Strategies of Workspace Traversal}

Collaborative tasks involving multiple agents working together require consensus on a \emph{joint strategy} $\psi$, i.e., a qualitatively distinct way of completing the task, out of the set of all possible joint strategies, $\Psi$. Often, this consensus is not established \textit{a priori}; rather, it is dynamically negotiated during execution. The abstraction of a joint strategy effectively captures critical domain knowledge at a representation level. While prior work on collaborative transport has emphasized \emph{role} assignment across the team (i.e., whether the robot or the human are leading or following each other)~\citep{mortl2012role, nikolaidis2013human, jarrasse2014slaves}, realistic, obstacle-cluttered environments present additional important challenges, such as the decision over \emph{how to pass through} an obstacle-cluttered workspace.

In this work, we formalize the space of workspace traversal strategies using tools from homotopy theory~\citep{knepper2012equivalence}. The human-robot team is tasked with transporting an object from its initial pose $p_0$ to a final pose $g$, resulting in an object trajectory $\boldsymbol{p}:[0,1]\to\mathcal{W}$, where $\boldsymbol{p}(0)=p_0$ and $\boldsymbol{p}(1)=g$, belonging to an appropriate space of trajectories $\mathcal{P}$.
Obstacles, defined as the connected components of $\mathcal{O}$, naturally partition $\mathcal{P}$ into equivalence classes $\Psi$, where each $\psi\in\Psi$ represents a distinct workspace traversal strategy under which the transported object can travel from $p_0$ to $g$, i.e.,
\begin{equation}
    \begin{split}
    & \mathcal{P} = \underset{\psi \in \Psi}{\bigcup} \psi \\
    & \forall \psi^i, \psi^j \in \Psi : (\psi^i \cap \psi^j \neq \emptyset) \implies (\psi^i = \psi^j) \\
    & \forall \boldsymbol{p}^i, \boldsymbol{p}^j \in \psi : \boldsymbol{p}^i \sim \boldsymbol{p}^j
    \end{split}
    \mbox{.}
\end{equation}

These classes can be identified using a notion of topological invariance. The works of~\citet{vernaza2013winding,kretzschmar2016irl,mavrogiannis2023winding} use winding numbers to describe topological relationships between the robot and obstacles or humans navigating around it. Here, we adapt this idea to collaborative transport by enumerating the set of homotopy classes between the object trajectory and obstacles in the workspace. Specifically, for any object trajectory $\boldsymbol{p}$ embedded in a space with $m$ obstacles $o_1,\dots, o_m$, we can define winding numbers
\begin{equation}
    w_i = \frac{1}{2\pi}\sum_{t} \Delta\theta_t^i, \quad i=1,\dots, m\mbox{,}
\end{equation}
where $\Delta\theta^i_t = \angle \left(p_t - o_i, p_{t-1}-o_i\right)$ denotes an angular displacement corresponding to the transfer of the object from $p_{t-1}$ to $p_t$ (see~\figref{fig:winding}). The sign of $w_i$ represents the passing side between the object and the $i$-th obstacle, and its absolute value represents the number of times the object encircled the $i$-th obstacle.
For a trajectory $\boldsymbol{p}$, the tuple of winding number signs
\begin{equation}
    W=(\sign{w_1},\dots, \sign{w_m})
\end{equation}
represents an equivalence class describing how the human-robot team transported the object past all obstacles in the environment. In this work, we model the space of joint strategies $\Psi$ as set of distinct $W$, i.e., $|\Psi|=2^m$.


\begin{figure}[t]
\begin{subfigure}{\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/winding-intuition.png}
    \caption{
    Identification of workspace traversal strategies based on path homotopy~\citep{kretzschmar2016irl}. By integrating the angle of the vector between the obstacle and the object as it is being transported along a path $\boldsymbol{p}$, we extract a winding number $w(\boldsymbol{p})$ identifying the strategy of workspace traversal. Here, $w(\boldsymbol{p}^2)=w(\boldsymbol{p}^3)$ since both $\boldsymbol{p}^2$, $\boldsymbol{p}^3$ passed on the right of $o_1$.}
    \label{fig:winding}
\end{subfigure}
\begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figures/windings.png}
    \caption{Representing workspace traversal strategies as tuples of winding number signs, $W$. In this scene with two obstacles, there are four possible strategies represented as continuous curves. The red curve highlights a strategy corresponding to passing on the right of $o_1$ ($w_1>0$), and the left of $o_2$ ($w_2<0$). This representation is applicable to any number of obstacles.}
    \label{fig:passing-strategy}
\end{subfigure}
\caption{Illustration of our topological abstraction for representing strategies of workspace traversal.\label{fig:workspace-traversal}}
\end{figure}


\subsection{Inferring Strategies of Workspace Traversal}

We describe an inference mechanism that maps observations of team actions to a belief over a workspace traversal strategy. This mechanism is agnostic to the specific definition of the strategy. At time $t$, we assume that the robot observes the joint action $\alpha = (a, u)$, the object state $p$, and the task context $c = (g, \mathcal{O})$. Given $\alpha$, $p$, and $c$, our goal is to infer the unfolding workspace traversal strategy, $\psi$, i.e.,
\begin{equation}
    \mathbb{P}(\psi \mid \alpha, p, c)\mbox{.}\label{eq:inference}
\end{equation}
Using Bayes' rule, we can expand~\eqref{eq:inference} as
\begin{equation}
    \mathbb{P}(\psi \mid \alpha, p, c) = \frac{1}{\eta} \mathbb{P}(\alpha \mid \psi, p, c)\,\mathbb{P}(\psi \mid p, c)\mbox{,}\label{eq:inference-bayes}
\end{equation}
where the left-hand side expression is the \emph{posterior distribution} of the joint strategy $\psi$, and on the right-hand side, $\eta$ is a normalizer across $\alpha$, $\mathbb{P}(\alpha \mid \psi, p, c)$ is the \emph{joint action likelihood distribution} and $\mathbb{P}(\psi \mid p, c)$ is a \emph{prior distribution} of the joint strategy before observing the joint action. We can rewrite the joint action likelihood distribution as
\begin{equation}
    \mathbb{P}(\alpha \mid \psi, p, c) = \mathbb{P}(a \mid \psi, p, c)\,\mathbb{P}(u \mid \psi, p, c)\mbox{,}
\end{equation}
since the two agents choose their actions independently.

The distribution of \eqref{eq:inference} allows the robot to represent the belief of its partner over the unfolding traversal strategy. A natural measure of uncertainty over the observer's belief regarding that strategy can be acquired by computing the information entropy of $\psi$, conditioned on known $\alpha, p, c$:
\begin{equation}
    H\left(\psi \mid \alpha,p,c\right) = - \sum_{\psi \in \Psi} \mathbb{P}(\psi\mid\alpha,p,c) \log \mathbb{P}(\psi\mid\alpha,p,c)\label{eq:entropy}    \mbox{.}
\end{equation}
Intuitively, the higher $H$ is, the higher the uncertainty of the user over the unfolding $\psi$ is assumed to be.


\subsection{Integrating Human Inferences into Robot Control}\label{sec:control}

We integrate the inference mechanism of \eqref{eq:inference} into a model predictive control (MPC) algorithm by using its entropy \eqref{eq:entropy} as a cost. Given the context $c = (g, \mathcal{O})$ and the object state $p$ at time $t$, the goal of the MPC is to find the sequence of future robot actions $\boldsymbol{u}^*$ that minimizes a cost function $J$ over a horizon $T$. At every control cycle, the MPC solves the following planning problem:

\begin{equation}
\begin{split}
\left(u_{t:t+T}\right)^{*} = \underset{u_{t:t+T}} {\arg\,\min}\; & J(p_{t:t+T}, u_{t:t+T})\\
    s.t.\: & p_{k+1} = f(p_k, a_k, u_k) \\
           & a_k \in \mathcal{A} \\
           & u_k\in\mathcal{U}
   \label{eq:mpc}
\end{split}\mbox{,}
\end{equation}
We split $J$ into a running cost $J_k$ and a terminal cost $J_T$
\begin{equation}
\begin{split}
     J(p_{t:t+T}, u_{t:t+T}) = & \sum_{k=0}^{T} \gamma^k J_k(p_{t+k}, u_{t+k})\\
        &+ J_T(p_{t+T}, u_{t+T})
\end{split}
        \mbox{,}
\end{equation}
where $\gamma$ is a discount factor, and the terminal cost penalizes distance from the object's goal pose $g$:
\begin{equation}
    J_T(p_{t+k}, u_{t+k}) = || p_{t+k} - g ||^2
    \mbox{.}
\end{equation}
The running cost $J_k$ is a weighted sum of two terms, i.e.,
\begin{equation}
    \begin{split}
        J_k(p_{t+k}, u_{t+k}) =\,& w_{obs} J_{obs}(p_{t+k}, u_{t+k})\\ &+ w_{ent} J_{ent}(p_{t+k}, u_{t+k})\mbox{,}
    \end{split}\label{eq:mpc-running-cost}
\end{equation}
where
\begin{equation}
    \begin{split}
    J_{obs}(p_{t+k}, u_{t+k}) &=\\ \max & \left(0, -\log\left(\underset{o \in \mathcal{O}}{\min} \frac{||p_{t+k} - o||}{\delta}\right)\right)
    \end{split}
    \mbox{,}
\end{equation}
is a collision avoidance cost penalizing proximity to obstacles, $\delta$ is a clearance threshold, $J_{ent}$ is a cost proportional to the entropy defined in \eqref{eq:entropy}, and $w_{obs}$, $w_{ent}$ are weights.

We refer to this control framework as \emph{Implicit Communication MPC}, or \textbf{IC-MPC}. At every control cycle, IC-MPC plans a future robot trajectory that balances between functional objectives (collision avoidance, progress to goal) and communicative objectives (minimizing the partner's uncertainty over the upcoming joint strategy). The robot executes the first action $u_t$ from the planned trajectory and then replans. This process is repeated in fixed control cycles until the task is completed.
