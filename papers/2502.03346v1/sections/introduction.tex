\section{Introduction}\label{sec:introduction}

Recently, there has been vivid interest in developing physically capable robot partners that could assist humans in \emph{context}-rich, dynamic and unstructured domains~\citep{selvaggio2021survey} like homes~\citep{homerobotovmmchallenge2023, van2011robocup} and manufacturing sites~\citep{matheson2019human}. An important task in this space involves the \emph{collaborative transport} of objects that might be too large or too heavy to be transported by a single agent. This task is especially challenging as it not only requires efficient and fluent coordination between the two heterogeneous partners but also the simultaneous satisfaction of geometric, kinematic, and physics constraints.

\begin{figure}[t]
  \includegraphics[width=\columnwidth]{figures/figure1.jpg}
  \caption{Footage from our study ($N=24$) involving the collaborative transport of an object (orange stick) by a user and a mobile manipulator in a workspace with an obstacle (red color). The robot runs our controller (IC-MPC), designed to balance functional and communicative actions in collaborative tasks.}
  \label{fig:teaser}
\end{figure}

Humans often tackle physically demanding collaborative tasks like transport by fluently coordinating their physical movements with their partners~\citep{sebanz2006joint} even without a concrete plan, with minimal explicit coordination. This capability relies on sophisticated mechanisms connecting perception and action. A prevalent theory from action understanding, commonly referred to as the ``teleological stance'', highlights that agents' actions can often be explained by an underlying goal~\citep{csibra2007obsessed,gergely1995intentional,baker2009understanding}. This idea has inspired researchers in human-robot interaction (HRI) to develop mechanisms that communicate a robot's intended goal to an observer through its actions~\citep{DraganAuR14,knepper2017implicit}. These mechanisms have produced intent-expressive robot behavior in manipulation~\citep{DraganAuR14}, autonomous driving~\citep{sadigh2016cars}, and social robot navigation~\citep{mavrogiannis2022socialmomentum}.
Likewise, we view communication---especially implicit communication~\citep{knepper2017implicit}, the ability to infer and convey information within physical actions---to be a critical skill of robots working in close physical collaboration with humans. Implicit communication can be low-latency, robust to environmental disturbances (e.g., noise, poor lighting conditions), and require less attention compared to explicit forms. While explicit communication remains highly relevant to team activities, implicit communication serves as an important complement that supports fluent teamwork.

To investigate the implications of implicit communication for physical human-robot teamwork, we instantiate a task of human-robot collaborative transport, where the goal of the human-robot team is to collaboratively move an object to a goal pose while avoiding collisions with static obstacles (see~\figref{fig:teaser}).
In this task, the user is simultaneously an observer of the robot and a \emph{dynamic actor}, persistently influencing and being influenced by the robot while it \emph{physically collaborates} with them.
While prior work in human-robot collaborative transport has emphasized fixed leadership roles for the two agents~\citep{bussy2012transportation,bussy2012proactive,mielke2024comanipulation,lima2023assistive,solanes2018human,nikolaidis2017mutual}, we consider a \emph{dynamic negotiation} over a joint strategy of \emph{workspace traversal}.
We contribute a control framework that leverages \emph{implicit communication}~\citep{knepper2017implicit} through actions influencing the state of the transported object to enable the robot to negotiate an efficient traversal with its human partner. We move beyond past work on implicit communication, where the user is either \emph{not an actor}~\citep{DraganAuR14} or \emph{not physically} collaborating with their robot partner~\citep{mavrogiannis2022socialmomentum,liang2019implicit}.
We demonstrate our framework on a mobile manipulator and evaluate it in a lab study ($N=24$) involving the collaborative transport of an object in a workspace with an obstacle obstruction. We show that our framework outperforms baselines lacking a communicative mechanism in terms of task completion and human impressions.

In summary, we contribute:
\begin{itemize}
  \item A formal mathematical representation of workspace traversal strategies during collaborative object transport.
  \item A human-inspired inference mechanism that probabilistically maps a joint human-robot action to a joint strategy of workspace traversal.
  \item A model predictive control framework that balances efficiency maximization and uncertainty minimization to produce fluent, efficient teamwork in physically collaborative tasks.
  \item Evidence from an extensive lab study ($N=24$) suggesting that our framework results in greater team performance and positively perceived robot behaviors. Videos from the study can be found at \url{https://youtu.be/0NTDrobSifg}.
  \item Code and data from our study that could help the community iterate on our work, publicly available at \url{https://github.com/fluentrobotics/icmpc\_collab\_transport}.
\end{itemize}
