@article{van2017neural,
  title={{Neural Discrete Representation Learning}},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{alayrac2022flamingo,
  title={{Flamingo: A Visual Language Model for Few-Shot Learning}},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@INPROCEEDINGS{gumultisubband,
  author={Gu, Yicheng and Zhang, Xueyao and Xue, Liumeng and Wu, Zhizheng},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={{Multi-Scale Sub-Band Constant-Q Transform Discriminator for High-Fidelity Vocoder}}, 
  year={2024},
  pages={10616-10620},}

@article{kaplan2020scaling,
  title={{Scaling Laws for Neural Language Models}},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{walczyna2023overview,
  title={{Overview of Voice Conversion Methods Based on Deep Learning}},
  author={Walczyna, Tomasz and Piotrowski, Zbigniew},
  journal={Applied Sciences},
  volume={13},
  number={5},
  pages={3100},
  year={2023},
}

@article{vaswani2017attention,
  title={{Attention is All You Need}},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{radford2019language,
  title={{Language Models Are Unsupervised Multitask Learners}},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{wang2024maskgct,
  title={{MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer}},
  author={Wang, Yuancheng and Zhan, Haoyue and Liu, Liwei and Zeng, Ruihong and Guo, Haotian and Zheng, Jiachen and Zhang, Qiang and Zhang, Xueyao and Zhang, Shunsi and Wu, Zhizheng},
  journal={arXiv preprint arXiv:2409.00750},
  year={2024}
}

@article{du2024cosyvoice,
  title={{CosyVoice: A Scalable Multilingual Zero-Shot Text-to-Speech Synthesizer Based on Supervised Semantic Tokens}},
  author={Du, Zhihao and Chen, Qian and Zhang, Shiliang and Hu, Kai and Lu, Heng and Yang, Yexin and Hu, Hangrui and Zheng, Siqi and Gu, Yue and Ma, Ziyang and others},
  journal={arXiv preprint arXiv:2407.05407},
  year={2024}
}

@article{casanova2024xtts,
  title={{XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model}},
  author={Casanova, Edresson and Davis, Kelly and G{\"o}lge, Eren and G{\"o}knar, G{\"o}rkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and others},
  journal={arXiv preprint arXiv:2406.04904},
  year={2024}
}

@inproceedings{mary2006prosodic,
  title={{Prosodic Features for Speaker Verification}},
  author={Mary, Leena and Yegnanarayana, B},
  booktitle={Ninth International Conference on Spoken Language Processing},
  year={2006},
}

@inproceedings{li2024database,
  title={{The Database and Benchmark For the Source Speaker Tracing Challenge 2024}},
  author={Li, Ze and Lin, Yuke and Yao, Tian and Suo, Hongbin and Zhang, Pengyuan and Ren, Yanzhen and Cai, Zexin and Nishizaki, Hiromitsu and Li, Ming},
  booktitle={IEEE Spoken Language Technology Workshop (SLT)},
  pages={1254--1261},
  year={2024},
}

@inproceedings{cai2023identifying,
  title={{Identifying Source Speakers for Voice Conversion based Spoofing Attacks on Speaker Verification Systems}},
  author={Cai, Danwei and Cai, Zexin and Li, Ming},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
}

@article{defossez2024moshi,
  title={{Moshi: A Speech-Text Foundation Model for Real-Time Dialogue}},
  author={D{\'e}fossez, Alexandre and Mazar{\'e}, Laurent and Orsini, Manu and Royer, Am{\'e}lie and P{\'e}rez, Patrick and J{\'e}gou, Herv{\'e} and Grave, Edouard and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2410.00037},
  year={2024}
}

@article{betker2023better,
  title={{Better Speech Synthesis through Scaling}},
  author={Betker, James},
  journal={arXiv preprint arXiv:2305.07243},
  year={2023}
}

@article{cao2024neuralvc,
  title={{NeuralVC: Any-to-Any Voice Conversion Using Neural Networks Decoder For Real-Time Voice Conversion}},
  author={Cao, Danyang and Zhang, Zeyi and Zhang, Jinyuan},
  journal={IEEE Signal Processing Letters},
  year={2024},
}

@inproceedings{li2023freevc,
  title={{FreeVC: Towards High-Quality Text-Free One-Shot Voice Conversion}},
  author={Li, Jingyi and Tu, Weiping and Xiao, Li},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={1--5},
  year={2023},
}

@inproceedings{casanova2022yourtts,
  title={{YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for Everyone}},
  author={Casanova, Edresson and Weber, Julian and Shulby, Christopher D and Junior, Arnaldo Candido and G{\"o}lge, Eren and Ponti, Moacir A},
  booktitle={International Conference on Machine Learning},
  pages={2709--2720},
  year={2022},
}

@inproceedings{
copet2023simple,
title={{Simple and Controllable Music Generation}},
author={Jade Copet and Felix Kreuk and Itai Gat and Tal Remez and David Kant and Gabriel Synnaeve and Yossi Adi and Alexandre D{\'e}fossez},
booktitle={Neural Information Processing Systems},
year={2023},
}

@article{du2024cosyvoice2,
  title={{CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models}},
  author={Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and others},
  journal={arXiv preprint arXiv:2412.10117},
  year={2024}
}

@article{zhang2023speak,
  title={{Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec Language Modeling}},
  author={Zhang, Ziqiang and Zhou, Long and Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2303.03926},
  year={2023}
}

@article{chen2024vall,
  title={{VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers}},
  author={Chen, Sanyuan and Liu, Shujie and Zhou, Long and Liu, Yanqing and Tan, Xu and Li, Jinyu and Zhao, Sheng and Qian, Yao and Wei, Furu},
  journal={arXiv preprint arXiv:2406.05370},
  year={2024}
}

@article{fossez2023high,
title={{High Fidelity Neural Audio Compression}},
author={Alexandre D{\'e}fossez and Jade Copet and Gabriel Synnaeve and Yossi Adi},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
}

@article{peng2024voicecraft,
  title={{Voicecraft: Zero-Shot Speech Editing and Text-to-Speech in The Wild}},
  author={Peng, Puyuan and Huang, Po-Yao and Li, Shang-Wen and Mohamed, Abdelrahman and Harwath, David},
  journal={arXiv preprint arXiv:2403.16973},
  year={2024}
}

@inproceedings{lin21b_interspeech,
  title     = {{S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations}},
  author    = {Jheng-Hao Lin and Yist Y. Lin and Chung-Ming Chien and Hung-yi Lee},
  year      = {2021},
  booktitle = {Interspeech 2021},
  pages     = {836--840},
}

@inproceedings{huang2022s3prl,
  title={{S3PRL-VC: Open-Source Voice Conversion Framework with Self-Supervised Speech Representations}},
  author={Huang, Wen-Chin and Yang, Shu-Wen and Hayashi, Tomoki and Lee, Hung-Yi and Watanabe, Shinji and Toda, Tomoki},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={6552--6556},
  year={2022},
}

@inproceedings{choi24b_interspeech,
  title     = {{Self-Supervised Speech Representations are More Phonetic than Semantic}},
  author    = {Kwanghee Choi and Ankita Pasad and Tomohiko Nakamura and Satoru Fukayama and Karen Livescu and Shinji Watanabe},
  year      = {2024},
  booktitle = {Interspeech 2024},
  pages     = {4578--4582},
}

@InProceedings{qian2019autovc,
  title = 	 {{{A}uto{VC}: Zero-Shot Voice Style Transfer with Only Autoencoder Loss}},
  author =   {Qian, Kaizhi and Zhang, Yang and Chang, Shiyu and Yang, Xuesong and Hasegawa-Johnson, Mark},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {5210--5219},
  year = 	 {2019},
  volume = 	 {97},
}

@INPROCEEDINGS{tan2021zeroshot,
  author={Tan, Zhiyuan and Wei, Jianguo and Xu, Junhai and He, Yuqing and Lu, Wenhuan},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={{Zero-Shot Voice Conversion with Adjusted Speaker Embeddings and Simple Acoustic Features}}, 
  year={2021},
  pages={5964-5968},}

@article{CAI2023101427,
title = {{Cross-Lingual Multi-Speaker Speech Synthesis with Limited Bilingual Training Data}},
journal = {Computer Speech \& Language},
volume = {77},
pages = {101427},
year = {2023},
author = {Zexin Cai and Yaogen Yang and Ming Li},
}

@inproceedings{zheng2016text,
  title={{Text-Independent Voice Conversion Using Deep Neural Network Based Phonetic Level Features}},
  author={Zheng, Huadi and Cai, Weicheng and Zhou, Tianyan and Zhang, Shilei and Li, Ming},
  booktitle={International Conference on Pattern Recognition},
  pages={2872--2877},
  year={2016},
}

@inproceedings{zhang2022sigvc,
  author={Zhang, Haozhe and Cai, Zexin and Qin, Xiaoyi and Li, Ming},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={{SIG-VC: A Speaker Information Guided Zero-Shot Voice Conversion System for Both Human Beings and Machines}}, 
  year={2022},
  pages={6567-65571},}

@inproceedings{zhang20e_interspeech,
  author={Zining Zhang and Bingsheng He and Zhenjie Zhang},
  title={{GAZEV: GAN-Based Zero-Shot Voice Conversion Over Non-Parallel Speech Corpus}},
  booktitle={Interspeech 2020},
  year={2020},
  pages={791--795},
}

@inproceedings{ney04b_interspeech,
  author={Hermann Ney and David Suendermann and Antonio Bonafonte and Harald Hoege},
  title={{A First Step towards Text-Independent Voice Conversion}},
  booktitle={Interspeech 2004},
  year={2004},
  pages={1173--1176},
}

@inproceedings{toda2001voice,
  title={{Voice Conversion Algorithm Based on Gaussian Mixture Model with Dynamic Frequency Warping of STRAIGHT Spectrum}},
  author={Toda, Tomoki and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing},
  volume={2},
  pages={841--844},
  year={2001},
}

@inproceedings{CAI2024privacy,
  title={{Privacy Versus Emotion Preservation Trade-Offs in Emotion-Preserving Speaker Anonymization}},
  author={Cai, Zexin and Xinyuan, Henry Li and Garg, Ashi and Garc{\'\i}a-Perera, Leibny Paola and Duh, Kevin and Khudanpur, Sanjeev and Andrews, Nicholas and Wiesner, Matthew},
  booktitle={IEEE Spoken Language Technology Workshop (SLT)},
  pages={409--414},
  year={2024},
}

@article{sisman2020overview,
  title={{An Overview of Voice Conversion and Its Challenges: From Statistical Modeling to Deep Learning}},
  author={Sisman, Berrak and Yamagishi, Junichi and King, Simon and Li, Haizhou},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={132--157},
  year={2020},
}

@article{kominek2003cmu,
  title={{CMU ARCTIC Databases for Speech Synthesis}},
  author={Kominek, John and Black, Alan W and Ver, Ver},
  year={2003},
}

@inproceedings{pratap20_interspeech,
  title     = {{MLS: A Large-Scale Multilingual Dataset for Speech Research}},
  author    = {Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},
  year      = {2020},
  booktitle = {Interspeech 2020},
  pages     = {2757--2761},
}


@ARTICLE{microvalle,
  author={Chen, Sanyuan and Wang, Chengyi and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and He, Lei and Zhao, Sheng and Wei, Furu},
  journal={IEEE Transactions on Audio, Speech and Language Processing}, 
  title={{Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}}, 
  year={2025},
  pages={1-15},}

@inproceedings{baba2024utmosv2,
  title     = {{The T05 System for The {V}oice{MOS} {C}hallenge 2024: Transfer Learning from Deep Image Classifier to Naturalness {MOS} Prediction of High-Quality Synthetic Speech}},
  author    = {Baba, Kaito and Nakata, Wataru and Saito, Yuki and Saruwatari, Hiroshi},
  booktitle = {IEEE Spoken Language Technology Workshop (SLT)},
  year      = {2024},
}

@article{chen2022wavlm,
  title={{WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing}},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and others},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={16},
  number={6},
  pages={1505--1518},
  year={2022}
}


@inproceedings{qian2022contentvec,
  title={{ContentVec: An Improved Self-Supervised Speech Representation by Disentangling Speakers}},
  author={Qian, Kaizhi and Zhang, Yang and Gao, Heting and Ni, Junrui and Lai, Cheng-I and Cox, David and Hasegawa-Johnson, Mark and Chang, Shiyu},
  booktitle={International Conference on Machine Learning},
  pages={18003--18017},
  year={2022},
}

@article{ardila2019common,
  title={{Common Voice: A Massively-Multilingual Speech Corpus}},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{veaux2016superseded,
  title={{Superseded-CSTR VCTK Corpus: English Multi-Speaker Corpus for CSTR Voice Cloning Toolkit}},
  author={Veaux, Christophe and Yamagishi, Junichi and MacDonald, Kirsten and others},
  journal={University of Edinburgh, The Centre for Speech Technology Research},
  year={2016},
}

@techreport{wester2011emime,
  title={{The EMIME Mandarin Bilingual Database}},
  author={Wester, Mirjam and Liang, Hui},
  year={2011},
  institution={The University of Edinburgh}
}

@inproceedings{nagrani17_interspeech,
  author={Arsha Nagrani and Joon Son Chung and Andrew Zisserman},
  title={{VoxCeleb: A Large-Scale Speaker Identification Dataset}},
  booktitle={Proc. Interspeech 2017},
  year={2017},
  pages={2616--2620},
}

@article{tomashenko2024voiceprivacy,
  title={{The VoicePrivacy 2024 Challenge Evaluation Plan}},
  author={Tomashenko, Natalia and Miao, Xiaoxiao and Champion, Pierre and Meyer, Sarina and Wang, Xin and Vincent, Emmanuel and Panariello, Michele and Evans, Nicholas and Yamagishi, Junichi and Todisco, Massimiliano},
  journal={arXiv preprint arXiv:2404.02677},
  year={2024}
}

@INPROCEEDINGS{librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={{Librispeech: An ASR Corpus Based on Public Domain Audio Books}}, 
  year={2015},
  pages={5206-5210},}

@inproceedings{zen2019libritts,
  author={Heiga Zen and Viet Dang and Rob Clark and Yu Zhang and Ron J. Weiss and Ye Jia and Zhifeng Chen and Yonghui Wu},
  title={{LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech}},
  booktitle={Proc. Interspeech 2019},
  year={2019},
  pages={1526--1530},
}

@article{wang2024streamvoice,
  title={{StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion}},
  author={Wang, Zhichao and Chen, Yuanzhe and Wang, Xinsheng and Chen, Zhuo and Xie, Lei and Wang, Yuping and Wang, Yuxuan},
  journal={arXiv preprint arXiv:2401.11053},
  year={2024}
}

@article{wang2023lm,
  title={{LM-VC: Zero-Shot Voice Conversion via Speech Generation Based on Language Models}},
  author={Wang, Zhichao and Chen, Yuanzhe and Xie, Lei and Tian, Qiao and Wang, Yuping},
  journal={IEEE Signal Processing Letters},
  year={2023},
}

@inproceedings{NEURIPS2020_c5d73680,
 author = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {17022--17033},
 title = {{HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis}},
 volume = {33},
 year = {2020}
}

@article{wang2023neural,
  title={{Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers}},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{kharitonov2023speak,
  title={{Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision}},
  author={Kharitonov, Eugene and Vincent, Damien and Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Girgin, Sertan and Pietquin, Olivier and Sharifi, Matt and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1703--1718},
  year={2023},
}

@inproceedings{
kreuk2023audiogen,
title={{AudioGen: Textually Guided Audio Generation}},
author={Felix Kreuk and Gabriel Synnaeve and Adam Polyak and Uriel Singer and Alexandre D{\'e}fossez and Jade Copet and Devi Parikh and Yaniv Taigman and Yossi Adi},
booktitle={International Conference on Learning Representations },
year={2023},
}

@article{zeghidour2021soundstream,
  title={{SoundStream: An End-to-End Neural Audio Codec}},
  author={Zeghidour, Neil and Luebs, Alejandro and Omran, Ahmed and Skoglund, Jan and Tagliasacchi, Marco},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={495--507},
  year={2021},
}

@article{borsos2023audiolm,
  title={{AudioLM: A Language Modeling Approach to Audio Generation}},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and others},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={31},
  pages={2523--2533},
  year={2023},
}

@article{wu2024towards,
  title={{Towards Audio Language Modeling-An Overview}},
  author={Wu, Haibin and Chen, Xuanjun and Lin, Yi-Cheng and Chang, Kai-wei and Chung, Ho-Lam and Liu, Alexander H and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2402.13236},
  year={2024}
}

@inproceedings{he2016residual,
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition},
  pages = {770--778},
  title = {{Deep Residual Learning for Image Recognition}},
  year = 2016
}