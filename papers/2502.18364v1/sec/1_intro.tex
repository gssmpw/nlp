\section{Introduction}
\label{sec:intro}

Diffusion-based generative models have shown tremendous success in producing high-quality images from given text prompts~\cite{podell2023sdxl,esser2024scaling,betker2023improving,saharia2022photorealistic}. These models are typically limited to producing entire images in a single, unified layer, which restricts the ability to edit or manipulate specific elements independently. This limitation presents significant challenges in fields like graphic design and digital art, where creators frequently rely on layer-by-layer control to construct and refine complex compositions.

\begin{figure}[!t]
\begin{minipage}[!t]{1\linewidth}
\begin{subfigure}[b]{1\textwidth}
\centering
\includegraphics[width=1.0\textwidth]{fig/intro_layout.png}
\vspace{-3mm}
\end{subfigure}
\end{minipage}
\vspace{-3mm}
\caption{\footnotesize{\textbf{Semantic Layout \vs Anonymous Region Layout}. The conventional semantic layout requires specifying what objects to generate in each given region, whereas our anonymous region layout only identifies where the important regions are. 
People can leverage the prior knowledge, activated by the global prompt, to intuitively infer the semantic label of each anonymous region. The generative model also learns to harness this capability and autonomously determine what to generate in each region.
}}
\label{fig:anonymous_layout}
\vspace{-3mm}
\end{figure}

This paper presents Anonymous Region Transformer for multi-layer transparent image generation. The key ingredient of the anonymous region transformer is the anonymous region layout, which solely consists of a set of anonymous rectangular regions without any region-wise prompt annotations, as shown in \Cref{fig:anonymous_layout}. This is unlike the conventional semantic layout for text-to-image generation~\cite{li2023gligen,yang2024mastering,yang2023reco}, which requires clearly specify both the global prompt for the entire image and the location and region-wise prompts for each region\footnote{We use `region' and `layer' interchangeably in this paper.}. The drawback of the conventional layout is that it heavily relies on human labor for creating the layout and this process can be very labor intensive, especially when handling tens or even hundreds of regions on a canvas, a common scenario in graphic design generation. The anonymous region transformer significantly reduces the human labor by allowing the generative model to perform the visual planning task of determining which objects to generate in each anonymous region based on the global prompt.
The core insight behind the anonymous region layout is to \emph{give more control to the generative models, while ensuring that users have great control over manipulating the multi-layered output.}

\begin{figure}[!t]
\begin{minipage}[!t]{1\linewidth}
\begin{subfigure}[b]{0.19\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/attention_analysis/intro/layout_v4.png}
\vspace{-3mm}
\caption*{Layout}
\end{subfigure}
\begin{subfigure}[b]{0.19\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/attention_analysis/intro/case_0_seed_1.png}
\vspace{-3mm}
\caption*{Composed.}
\end{subfigure}
\begin{subfigure}[b]{0.19\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/attention_analysis/intro/layer_2_cb.png}
\vspace{-3mm}
\caption*{Region\#1}
\end{subfigure}
\begin{subfigure}[b]{0.19\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/attention_analysis/intro/layer_3_cb.png}
\vspace{-3mm}
\caption*{Region\#2}
\end{subfigure}
\begin{subfigure}[b]{0.19\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/attention_analysis/intro/layer_4_cb.png}
\vspace{-3mm}
\caption*{Region\#3}
\end{subfigure}
\hfill
\begin{subfigure}[b]{1\textwidth}
\centering
\includegraphics[width=1\textwidth,height=14mm]{fig/attention_analysis/intro/attention_map.png}
\vspace{-4mm}
\caption*{Attention Maps between Anonymous Region and Text}
\end{subfigure}
\end{minipage}
\vspace{-2mm}
\caption{\footnotesize{
\textbf{Visual planning capability of our Anonymous Region Transformer}. We visualize the averaged attention maps of all visual tokens within the same anonymous region (as Query) attending to the entities within the global prompt text tokens (as Key and Value). These attention maps reveal that each anonymous region assigns the majority of attention weights to one of the major objects identified in the given text prompt. }}
\label{fig:attention_analysis}
\vspace{-3mm}
\end{figure}

A natural question arises regarding how the anonymous region layout can function effectively without region-wise prompts, especially given that these prompts are central to conventional semantic layout approaches. This effectiveness can be explained by Schema Theory~\cite{bartlett1995remembering,rumelhart2017schemata,kant1934critique,axelrod1973schema}, a well-established cognitive framework that helps bridge the gap between abstract concepts (such as \emph{plate} or \emph{spoon}) and specific sensory experiences (such as \emph{layout}). It suggests that people can infer each region's semantic label based on their prior knowledge activated by a global prompt. In our case, we find that the effectiveness of the anonymous-region layout for multi-layer image generation tasks stems from the Transformer model’s ability to autonomously identify semantic labels for each layer through interactions between text tokens and visual tokens. The generative model learns to capture the prior knowledge similar to Schema Theory, enabling it to determine which set of visual tokens (from an anonymous region) attends to which text tokens (representing different entities), as shown in \Cref{fig:attention_analysis}. Our experiments further demonstrate that adding additional region-wise prompts for each layer does not necessarily improve the results and can even diminish coherence across layers.

The anonymous region transformer offers several key advantages over the conventional approach for multi-layer transparent image generation. \underline{First}, it ensures better coherence across different layers. We observe that, in the semantic layout, regional visual tokens struggle to balance attention weights between region-wise text tokens (to ensure \emph{prompt following}) and the corresponding global visual tokens located at the same position (ensure \emph{coherence}). This difficulty arises from a semantic gap between the global visual tokens and region-wise visual tokens as they are forced to attend different text tokens. In contrast, our anonymous region layout enables all regional visual tokens and global visual tokens to attend to the same set of global text tokens, thereby closing this gap. \underline{Second}, annotating the anonymous-region layout is more scalable, especially for native multi-layer graphic design images. We can easily generate a large number of high-quality anonymous-region layouts, whereas recaptioning each region is non-trivial and often suffers from significant noise due the semantic gap between captioning a crop conditioned on an entire image and captioning only a small crop. \underline{Third}, by focusing on the anonymous regions within each layer, we can significantly reduce computation costs and enables the efficient generation of images with numerous distinct layers (e.g., 50+).

\begin{figure}[!t]
\begin{minipage}[!t]{1\linewidth}
\begin{subfigure}[b]{1\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/intro/win_rate_results_cole.pdf}
\vspace{-3mm}
\end{subfigure}
\begin{subfigure}[b]{1\textwidth}
\centering
\includegraphics[width=1\textwidth]{fig/intro/win_rate_results_layerdiff.pdf}
\vspace{-3mm}
\end{subfigure}
\end{minipage}
\vspace{-3mm}
\caption{\footnotesize{
\textbf{ART \vs previous SOTA} in multi-layer transparent image generation: user study results across different domains. ART significantly outperforms LayerDiffuse~\cite{zhang2024transparent} in the photorealistic domain and COLE~\cite{jia2023cole} in the graphic-design domain across multiple aspects.
}}
\label{fig:user_study}
\vspace{-3mm}
\end{figure}

Our methodology consists of three key components: the Multi-layer Transparent Image Autoencoder, the Anonymous Region Transformer, and the Anonymous Region Layout Planner. The Multi-layer Transparent Autoencoder encodes and decodes a variable number of transparent layers at different resolutions using a sequence of latent visual tokens. The Anonymous Region Transformer concurrently generates a global reference image, a background image, and multiple cropped transparent foreground layers from Gaussian noise conditioned on the anonymous region layout. The Anonymous Region Layout Planner predicts a set of anonymous bounding boxes based on the user-provided text prompt.
Compared existing methods in multi-layer image generation—such as Text2Layer~\cite{zhang2023text2layer}, LayerDiff~\cite{huang2024layerdiff}, and LayerDiffuse~\cite{zhang2024transparent}-the key difference is that these methods can produce only a limited number of transparent layers at fixed resolutions.
Additionally, unlike the COLE~\cite{jia2023cole} and OpenCOLE~\cite{inoue2024opencole}, which apply a cascade of diffusion models to generate layers sequentially, our method generates all transparent layers and the reference image simultaneously in an \textit{end-to-end} manner, ensuring a better global harmonization across different layers. The experimental results demonstrate the advantages of our approach over previous methods, and we report the user study results in \Cref{fig:user_study}.

In summary, this paper not only proposes a novel approach to multi-layer transparent image generation, but also opens up numerous possibilities for future research and applications. Our main contributions are as follows:
\begin{enumerate}
\item We are the first to propose a novel pipeline for multi-layer transparent image generation that supports generating a variable number of layers at variable resolution.
\item We introduce the anonymous region layout, which offers several key advantages over conventional semantic layout for multi-layer transparent image generation.
\item We empirically validate the effectiveness of our method. Compared to the previous state-of-the-art methods, our algorithm generates multi-layer transparent images with higher quality and a greater number of layers.
\end{enumerate}