\section{Related Work}
\subsection{Retrieval-Augmented Generation}
Early approaches to RAG involved simple retrieval and were developed for the task of question answering ____. Recent advancements have seen more sophisticated integration of retrieval and generation processes, thereby significantly enhancing the quality and relevance of the generated text ____.
%Notable implementations of RAG have demonstrated the ability to dynamically retrieve and incorporate relevant information during the generation process, thereby significantly enhancing the quality and relevance of the generated text ____. 
These advancements have been facilitated by improvements in both the retrieval mechanisms, which have become more efficient and effective at finding relevant information, and the generative models, which have become better at integrating and contextualizing the retrieved information ____.

A recent survey by ____ separates RAG approaches into \textit{naive RAG} and \textit{advanced RAG}. The naive RAG approach follows a traditional process that includes indexing, retrieval, and generation, also called a “Retrieve-then-Read” framework ____. 
On the other hand, advanced RAG introduces specific improvements to enhance the retrieval quality by employing pre-retrieval and post-retrieval strategies. Pre-retrieval strategies include query rewriting with an LLM ____ or query expansion methods like HyDE ____.
%, which generates a hypothetical response to the query first and then uses the responses to search the database. On the other hand, p
Post-retrieval methods focus on selecting essential information from retrieved documents. This includes reranking the retrieved documents with neural models ____ or summarizing the retrieved documents before passing them as context ____. 

%RAG systems can be deployed for a wide variety of NLP tasks involving text generation. The most popular is open-domain question answering ____.

\subsection{Context and Noise in RAG Systems}
%RAG systems can be deployed for a wide variety of NLP tasks involving text generation. The most popular is open-domain question answering ____, where the task is to answer questions with no provided context -- the system has to first search through large knowledge bases in order to find an answer. Beyond QA, RAG can be used for generative tasks like machine translation by retrieving example sentences from a corpus in target language ____, or for dialogue generation by guiding the conversation with retrieved exemplar responses from previous dialogues ____. RAG is also used in content creation, such as creative storytelling ____, 
%image creation ____, 
%and code generation ____.

%Applying AI and NLP methods to help education and students has been widely studied ____. Example use cases of NLP technologies for educational applications include language learning ____, grammatical error correction ____, and automated essay scoring ____. There have also been QA systems, often based on retrieval and generation, developed and evaluated for various domains, including QA for compliance ____ and teaching assistance ____. Still, to the best of our knowledge, our study presents the first evaluation of a QA system explicitly designed for answering university students' questions about their study programs and requirements.

A lot of recent work has explored how to improve RAG and make it more accurate and robust to imperfect context. This includes fact verification ____, self-reflection with critique ____, learning to re-rank the context ____, improved answer attribution ____, adaptive search strategy ____, and relevance modeling ____. 

There have also been studies exploring the size of input context and its influence on the performance of RAG systems. ____ highlight the effect of information being \textit{lost in the middle}, showing how RAG mostly focuses on the beginning and the ending of the provided context. Similarly, ____ examine the influence of the position of the most relevant snippet in the context and the influence of noisy snippets on the performance. Both of these studies work with factoid QA dataset where it is assumed one context snippet is the most important for the answer.

____ analyze the effect of number of context snippets on five multiple-choice biomedical QA tasks, while ____ analyze the impact of the number of snippets as well as context recency and popularity for biomedical QA. ____ evaluated the noise robustness and context integration of different LLMs for RAG. Most similar to our work is the study by ____, where the influence of different RAG components is tested with eight LLMs and it also includes BioASQ as a benchmark dataset.

While these studies have discovered important principles in context inclusion for RAG systems, they predominantly evaluate it on multiple-choice or short-form QA tasks where there is one clear answer and one most important context snippet. Our work evaluates generative question answering where potentially all snippets could be relevant for inclusion in the answer, which is a more challenging setting. Additionally, we provide a comprehensive evaluation of three main RAG components: the influence of the context size, different retrieval techniques, and choice of base LLMs.

%Their study focuses on factoid question-answering, where the model has to detect only one gold context snippet that contains the correct answer, whereas in our study, all context snippets are important for constructing the answer.