\paragraph{Tasks} We evaluate DAB on three distinct controlled-generation tasks: sentiment-guided generation, language detoxification, and keyword-guided generation. These are popular tasks within the field of controlled generation \citep{kumar2022gradient, liu2023bolt, han2023lm}. For all tasks, we produce generations in batches of 20 as done in \citet{liu2023bolt}. For all tasks, we include example generations in Appendix \ref{appndx:senti-details}, \ref{appndx:toxicity-details}, \ref{appndx:keywords-details} for sentiment directed generation, language detoxification, and keyword-guided generation respectively. 

\paragraph{Baselines} We compare to previous generation algorithms that use the EBM framework to perform gradient-based text sampling. Specifically, we compare to MuCOLA \citep{kumar2022gradient}, COLD \citep{qin2022cold}, and BOLT \citep{liu2023bolt}. We also compare against LM-Steer introduced in \citep{han2023lm} to see how our method compares to alternative controlled generation methods. 

\paragraph{Metrics} While the metrics assessing control towards external constraint vary across experiments, we use the same evaluation metrics to measure fluency across experiments. We measure fluency by looking at CoLA score, the number of repeated tri-grams per generation, and perplexity \citep{kumar2022gradient, liu2023bolt}. 
For CoLA score, we use a fine-tuned RoBERTa model to provide a probability as to whether a generation is grammatically correct.
For perplexity, we use GPT-XL to evaluate each generation. 
We show the average of the results across all generations. For more details on these evaluation methods, refer to Appendix \ref{appndx:fluency-metrics}. 