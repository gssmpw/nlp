\paragraph{Task} We measure the ability of our method to produce text that includes a given keyword relevant to a specific topic. As done in prior work, we use 7 topics with 4 keywords each and use the differentiable BLEU \citep{liu-etal-2022-dont} as the constraint function \citep{liu2023bolt}. For baselines, we compare to the same methods as before with the exclusion of LM-Steer as no similar task was discussed in the original work. 

\paragraph{Control Metrics} 
The ideal metric goal for this task should only assign good scores to text where keywords are used in a meaningful way. 
While \citet{liu2023bolt} uses the percentage of generations that include a keyword to measure constraint satisfaction, this metric also assigns good scores to text where the keyword does not add meaning to the sentence.

An alternative approach is to compute a similarity score between the generations and reference texts that use the keywords in a manner relevant to the given topic. 
To accomplish this, we use GPT-4o to produce sentences for each combination of prompt, topic, and keyword. 
We then use BertScore to compute the similarity score between the candidate generations and the reference text, where higher similarity implies increased relevance to the target topic \citep{zhang2020bertscoreevaluatingtextgeneration}. 
For further details, refer to Appendix \ref{appndx:keywords-details}. 

\paragraph{Results}
DAB is able to outperform baselines in terms of both control and fluency, reflecting an improved balance between these two attributes. As shown in Table \ref{table:megatable}, DAB outperforms baselines in terms of relevance towards the target topic as measured by BertScore. While the success rate of our method is not as high as some of the baselines, those methods do not incorporate the keywords in a semantically meaningful manner as indicated by the BertScore. Furthermore, our generations are more fluent than all baselines in terms of all three fluency metrics. These results indicate that our method strikes a superior balance between control and fluency in regards to topic-guided generation.  

