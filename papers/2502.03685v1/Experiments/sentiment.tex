\paragraph{Task} Here we measure the ability to direct generation towards positive sentiment from some initial prompt. Given an initial prompt, we generate sequences of length 12, 20, 50 as done in prior works \citep{kumar2022gradient, liu2023bolt}. We use the same set of prompts as \citet{dathathri2020plugplaylanguagemodels} and include them in Appendix \ref{appndx:senti-details}.

\paragraph{Control Metrics} We evaluate control by measuring the predicted sentiment of the generation using three distinct sentiment classifiers.
For details on the training of the three classifiers, see Appendix \ref{appndx:senti-details}. 
We omit the internal classifier measure for LM-Steer as it does not rely on an internal classifier to guide generation. 

\paragraph{Results}
Table \ref{table:megatable} shows that our method achieves a better balance between control and fluency than baselines. DAB achieves the highest average probability of positive sentiment across all three classifiers, demonstrating its effectiveness at incorporating the external constraint.  Furthermore, DAB achieves fluency scores close to BOLT's performance in regards to CoLA score, repeated trigrams, and perplexity. This shows that DAB produces generations that are both fluent and satisfactory under the constraint. 