\paragraph{Task} We compare our algorithm to various baselines for the task of language detoxification to demonstrate that our method can be used to mitigate potentially toxic LLM generations. 
Following prior work, we use 1,000 prompts sampled from the RealToxicityPrompts introduced and generate continuations of length 20 tokens \citep{gehman2020realtoxicitypromptsevaluatingneuraltoxic, kumar2022gradient, liu2023bolt}.
As in the sentiment-directed generation task, we use a fine-tuned RoBERTa as the constraint function. 
\paragraph{Control Metrics} We evaluate the generations using both the internal discriminator used to guide the various methods, and the score returned by the Perspective API \citep{lees2022newgenerationperspectiveapi}. We use the scores returned from Perspective API to calculate the maximum toxicity per prompt and the overall percentage of text predicted to be toxic. 
\paragraph{Results} As shown in Table \ref{table:megatable}, our method generates less toxic text than baselines without compromising fluency. 
DAB significantly decreases the average maximum toxicity per prompt, demonstrating that our algorithm is more consistent in terms of toxicity reduction. 
Furthermore, our method obtains fluency metrics that are on par with the best baseline. 