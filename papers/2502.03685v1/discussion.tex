In this work, we introduce DAB, the first controlled decoding algorithm based on gradient discrete sampling. 
Our algorithm alternates between biased auto-regressive generation and gradient-based discrete sampling to produce text from pre-trained language models subject to an external constraint function. 
Through various controlled generation experiments, we demonstrate that our algorithm is both more efficient and effective than previous methods. 

\paragraph{Limitations} While our method is more efficient than other gradient-based controlled generation methods, the number of gradient computations increases with queries, which may be undesirable. Furthermore, it has not yet been explored how our method performs when faced with multiple external constraints or compositional generation. 