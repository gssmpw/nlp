Large language models (LLMs) are widely used in real-world applications through chatbots such as ChatGPT, Alpaca, and Llama, making them an important part of everyday life \citep{bender2021parrots, bommasani2021opportunities, weidinger2021ethical}. As a result, there has been growing attention on developing methods to reliably and effectively control LLM-generated outputs to meet user-defined constraints \citep{gehman2020realtoxicitypromptsevaluatingneuraltoxic,  dathathri2020plugplaylanguagemodels, goshvadi2023discs, han2023lm}. 

Previous work has tackled controlled language generation using decoding-time algorithms, which bypass the need for fine-tuning the base language model \citep{liu2023bolt, kumar2022gradient, mireshghallah-etal-2022-mix, dathathri2020plugplaylanguagemodels, qin2022cold}. Among these, energy-based decoding methods define a target distribution through an energy function, combining multiple constraints into a weighted average. This formulation offers significant flexibility, as the energy function can be any arbitrary function. Sampling from this distribution relies on gradient-based MCMC in continuous spaces, followed by conversion back to discrete text tokens.

However, these methods often struggle to achieve a good balance between fluency and constraint satisfaction. Tuning the coefficient for each constraint in the energy function requires exhaustive efforts, and even with careful tuning, the generated outputs may still fail to meet the desired standards.

In this paper, we analyze this issue and show that the suboptimal balance arises from sampling in continuous space rather than the natural discrete space of text tokens. Continuous-space sampling leads to incremental sequence updates, which hinders the exploration of fluent and constrained text.

To address this, we propose \textbf{DAB}: \textbf{D}iscrete \textbf{A}uto-regressive \textbf{B}iasing, a decoding algorithm that efficiently explores the discrete text space, achieving a better balance between fluency and constraint satisfaction with even lower decoding costs than existing decoding-time algorithms. DAB operates entirely in the discrete domain, which allows for more directional and substantial updates to the response sequence at each step. Specifically, our method defines a target distribution as a joint distribution over response sequences $Y$ and an auxiliary bias term $B$. It alternates between sampling from $P(B | Y)$ using gradient-based discrete sampling, ensuring constraint satisfaction, and from $P(Y | B)$ using biased auto-regressive generation, ensuring fluency. Notably, DAB significantly reduces computational overhead due to a simpler gradient computation which is enabled by our discrete sampling framework. We provide a visual summary of our algorithm in Figure \ref{fig:intro_visualization}.
We summarize our main contributions as follows: 

\begin{itemize}
\item We propose a controlled auto-regressive decoding algorithm that leverages gradients while operating entirely in the discrete text domain without continuous relaxation or post-hoc discretization. By remaining in the discrete domain, our method achieves a better balance between fluency and constraint satisfaction, with significantly lower computational costs than existing energy-based decoding algorithms.

\item We introduce a new formulation for controlled text generation by defining a joint distribution over the generated sequence and an auxiliary bias sequence. To sample from this joint distribution, we propose a discrete Langevin-within-Gibbs sampling algorithm. Our algorithm leverages discrete gradient-based MCMC to sample the auxiliary bias sequence, which is then incorporated into the final output via biased auto-regressive generation.

\item We demonstrate that our method consistently produces more satisfactory generations than baseline methods, offering comparable or better fluency with \textbf{2x} faster decoding time. 
This performance holds across a range of constrained generation tasks, including sentiment-controlled generation, toxicity avoidance, and keyword-guided generation. 
\end{itemize}
