\documentclass[10pt,twocolumn,letterpaper]{article}


\usepackage[pagenumbers]{cvpr} 
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}


\usepackage{multirow}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}
%%%%%%%%





\title{Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach
}

\begin{document}
\author{Yunuo Chen$^{1,2}$\quad Junli Cao$^{1,2}$\quad Anil Kag$^{2}$\quad Vidit Goel$^{2}$\\ Sergei Korolev$^{2}$\quad Chenfanfu Jiang$^{1}$\quad Sergey Tulyakov$^{2}$\quad Jian Ren$^{2}$\\
{\small $^{1}$University of California, Los Angeles\quad $^{2}$Snap Inc.}\\
{\tt\small Project Page: \url{https://snap-research.github.io/PointVidGen/}}
% {\small $^*$ Work done during internship at Snap.}
}


\twocolumn[{
\renewcommand\twocolumn[1][]{#1}

\maketitle

\begin{center}
    \centering
    \captionsetup{type=figure}

    \vspace{-1cm}
    \includegraphics[width=\textwidth]{figs/comparison-task-all_compressed}
    \caption{\textbf{Comparison on Task-Oriented Videos.} 
We present videos generated by different baselines (SVD~\cite{blattmann2023stablevideodiffusionscaling}, I2VGen-XL~\cite{zhang2023i2vgen}, and DynamiCrafter~\cite{xing2025dynamicrafter}) and compare them with our method. We use the same input conditions for all methods (except that SVD is conditioned only on the image). It can be observed that existing baselines often exhibit severe distortions of hands or objects during human hand-object interactions. In contrast, our method preserves the shapes of both the hand and object during such interactions and ensures smooth transitions throughout the video.}\label{fig:comparison-task-all}
\end{center}
}]


\input{sec/abstract}    
\input{sec/intro}
\input{sec/related}
\input{sec/method}
\input{sec/experiment}
\input{sec/conclusion}

% \clearpage
{
    \small
    \bibliographystyle{ieeenat_fullname}
    \bibliography{main}
}


\input{sec/supp}

\end{document}
