\begin{abstract}
Recent dense retrievers usually thrive on the emergency capabilities of Large Language Models (LLMs), using them to encode queries and documents into an embedding space for retrieval. These LLM-based dense retrievers have shown promising performance across various retrieval scenarios. However, relying on a single embedding to represent documents proves less effective in capturing different perspectives of documents for matching.
In this paper, we propose \textbf{D}\textbf{e}li\textbf{b}er\textbf{a}te \textbf{T}hinking based Dens\textbf{e} \textbf{R}etriever (\method{}), which enhances these LLM-based retrievers by enabling them to learn more effective document representations through a step-by-step thinking process. \method{} introduces the Chain-of-Deliberation mechanism to iteratively optimize document representations using a continuous chain of thought. To consolidate information from various thinking steps, \method{} also incorporates the Self Distillation mechanism, which identifies the most informative thinking steps and integrates them into a unified text embedding.
Experimental results show that \method{} significantly outperforms existing methods across several retrieval benchmarks, demonstrating superior accuracy and robustness. All codes are available at \url{https://github.com/OpenBMB/DEBATER}.
\end{abstract}
