\section*{Limitation}
\method{} demonstrates its effectiveness in activating the reasoning capabilities of LLMs to enhance document representation. 
However, each thinking embedding requires interaction with the query embedding during the training of \method{}, which introduces additional memory costs for GPU. 
Furthermore, we only employ 2$\times$ NVIDIA A100-40G GPU to train and evaluate our \method{} models. Due to the high embedding dimension of the LLM-based retriever, it takes us over a week to build the index for the BEIR evaluation using \method{}-2.4B, and over 2 weeks on \method{}-4B. 
Thus, we do not further explore larger \method{} models (e.g., \method{}-7B) in this paper due to limitations in computational resources.  
However, our experimental results indicate that the \method{}-4B model outperforms all 7B-scale baseline models, highlighting its effectiveness.