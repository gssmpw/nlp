\section{Related Work}
Dense retrieval~\cite{karpukhin2020dense, xiong2020approximate, su2022one} has proven effective in various NLP downstream tasks~\cite{liu2019fine, chen2024ms, guu2020retrieval}. However, the versatility of dense retrievers remains a challenge that hinders their progress~\cite{luo2024large, lee2024gecko}, particularly their inability to generate task- and domain-specific embeddings and return suitable results~\cite{su2022one, luo2024large, tao2024llms}. To address this limitation, prior work has focused on conducting fine-grained data curation to fine-tune dense retrievers with multi-task instructions~\cite{su2022one, asai2022task}. However, obtaining high-quality relevance labels can be difficult for training dense retrievers~\cite{yu2022coco, gao2022precise, wang2023improving}.

Recent research has shifted towards using LLMs as the backbone for dense retrievers~\cite{tao2024llms}, thriving on their strong emergence capabilities. Some studies attempt to directly prompt LLMs to generate embeddings for retrieval~\cite{zhuang2024promptreps}. However, prompt-based approaches cannot leverage pre-existing retrieval signals, limiting their effectiveness~\cite{zhu2023large}. In contrast, recent efforts have focused on fine-tuning LLMs for dense retrieval tasks~\cite{wang2023improving, ma2024fine, li2024llama2vec}, or designing additional pretraining tasks to transform LLMs into dense retrievers~\cite{behnamghader2024llm2vec}, achieving strong retrieval performance and generalization capabilities. However, existing methods typically extract the last hidden state of the end-of-sequence token as the dense representation~\cite{ma2024fine, luo2024large}, which is not always effective for fully representing documents from different perspectives to match queries~\cite{zhang2022multi, khattab2020colbert}. The exploration of different document representations, such as leveraging the reasoning ability of LLMs, remains an underexplored area.

\input{figure/main}

To enhance the reasoning capability of LLMs, one approach is to generate intermediate reasoning steps using Chain-of-Thought (CoT)~\cite{wei2022chain} or its variants~\cite{chen2022program, zhang2024wrong}. CoT allows LLMs to delay final answers by engaging in reasoning~\cite{kudo2024think}, improving response accuracy~\cite{wei2022chain, chu2023survey}. However, these approaches operate within the language space and often require generating tens or even hundreds of additional tokens, which can hinder their ability to meet the latency requirements of dense retrievers. Current research is exploring the integration of CoT reasoning into a continuous latent space~\cite{hao2024training, xie2024self} to enhance computational efficiency. Building on these advancements, our \method{} focuses on latent reasoning chains, encouraging LLM-based retrievers to think step-by-step to enhance the dense representations of documents.