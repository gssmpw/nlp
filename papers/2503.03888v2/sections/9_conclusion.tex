\section{Conclusion}
\label{sec:conclude}

We have shown that through a unique academic-agency partnership, we were able to prototype, test, and integrate AI to scale the redaction, mapping, and preservation of racial covenants across 5.2 million pages of deed records. Substantively, our approach can empower researchers, governments, and citizens to learn about local histories of discrimination with a level of nuance and specificity that has only been available in a few jurisdictions to date.  For instance, our findings show that while racial covenants in Santa Clara specifically focused on Asian groups, covenants barred Black homeowners at the same rate, even when the Black population was one tenth the Asian population in the county. Consistent with \citep{brooksrose2013saving}, we observe the persistence of racial covenants after 1948. And our finegrained mapping and information extraction enables us to surface specific developers responsible for the bulk of racial covenants, who may have had agency in the construction of Santa Clara County \citep{howell, redford}. 

As over a dozen states have moved to enable the redaction of deed records, a substantial policy choice lies in whether to rely on individual homeowners or government to identify and redact deeds. The main reason for the former has  been the perceived cost. But our collaboration demonstrates that AI systems make more proactive efforts like California's eminently feasible at significantly lower cost than conventionally perceived. The benefits of more proactive efforts are substantial, resulting in a speedier and  much more comprehensive accounting of housing discrimination than piecemeal efforts.    

Our collaboration also paints a promising path for AI in the public sector. 

First, the search challenge for legal reform is pervasive. The U.S.\ Congress struggles with tracking the number of mandated reports strewn about the U.S.\ Code, with many suspected to be obsolete \citep{pray2005congressional}. When California liberalizes approvals for ``accessory dwelling units'' to address the acute housing shortage, harmonization with each county, municipal, and administrative regulation proves taxing. In one municipality, attorneys have referred to the urgent need for ``code cleanup,'' given the many outdated or irrelevant provisions that persist. Herein lies the substantial promise of AI to help in turning what for Los Angeles is an \$8M, 7-year project into a rapid process.

Second, our collaboration also speaks to an increasingly important policy debate around the regulation of open vs.\ closed AI models. Calls for regulation of open models have focused on the potential for risk if developers cannot control their usage via API \citep{pmlr-v235-kapoor24a}. Few projects have provided concrete numbers on the marginal benefits in production use, and our application shows the immense cost savings that can be associated with open models. The cost of an open model is 2\% %
of the comparable cost of a proprietary model.\footnote{This is based on the comparison of costs of the finetuned Mistral model and GPT 3.5 in Table~\ref{tab:cost_comparison}. The cost of the open model is roughly 0.5\% of GPT-4 Turbo.} Given the long history of procurement challenges for government technology \citep{pahlka2023recoding} and the federal government's open source policy\footnote{Office of Management and Budget, Federal Source Code Policy: Achieving Efficiency, Transparency, and Innovation through Reusable and Open Source Software, Aug.\ 8, 2016, \url{https://obamawhitehouse.archives.gov/sites/default/files/omb/memoranda/2016/m_16_21.pdf}.}, this cost finding is of particular significance.  
We release both the fine-tuned language model and the web application to assist in reviewing model outputs to enable jurisdictions to efficiently and effectively explore utilizing these approaches. 

Third, many have called for AI regulation based on a categorical determination of whether AI systems are rights-impacting. The U.S. federal government's response, for instance, triggers a bundle of process-based controls for AI systems that ``serve[] as
a principal basis for a decision or action.''\footnote{Office of Management and Budget, Advancing Governance, Innovation, and Risk Management for Agency Use of Artificial Intelligence, March 28, 2024, \url{https://www.whitehouse.gov/wp-content/uploads/2024/03/M-24-10-Advancing-Governance-Innovation-and-Risk-Management-for-Agency-Use-of-Artificial-Intelligence.pdf}.}  Our project illustrates how the integration of AI models can exist along a spectrum within a government program. AI to improve OCR should be subject to very different safeguards than AI to fully automate racial covenant redaction. Responsible adoption requires identifying the appropriate point of integration, and safeguards must be tailored to risk. If, for instance, any use of AI in OCR triggered the right to opt out of AI systems, government programs will suffer \citep{martin_spectrum_2024}. 

Last, while one of the prevalent anxieties around AI is the potential for irresponsible usage to exacerbate biases -- for which there is an abundance of evidence \citep[e.g.,][]{buolamwini2018gender, liang2021towards} -- our collaboration shows the immense benefits for affirmatively using AI to uncover historical discrimination, promote an improved understanding of pathways for disparities, and reduce the stigmatic and signaling harms from racial covenants. 
