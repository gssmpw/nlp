\clearpage
\appendix
\section{Ethical Statement}

We here discuss our considerations for the use and integration of machine learning in this context. 

First, the AB 1466 setting is one where resource constraints loom large. Purely human review would make implementation of AB 1466 challenging and funding cannot fully support such purely manual efforts (see Section~\ref{sec:background}). Our work helps prioritize available human and attorney resources to documents with high likelihood of racial covenants. This makes the process of redaction faster---meaning that fewer homeowners will have to sign such offensive covenants in transactions or expend their own resources in removing them.

Second, AB 1466 requires human oversight in the form of counsel review of any proposed redaction (see Figure~\ref{fig:integration}). The risk of false positives is hence primarily about the review time required. There is a risk that our system misses racial covenants, but (a) it is not obvious whether human reviewers would fare better given the high recall performance reported in Section~\ref{sec:evaluation}, and (b) AB 1466 provides alternative mechanisms to flag remaining racial covenants.\footnote{For instance, AB 1466 places obligations on a title company, escrow company, real estate broker, real estate agent, or association to notify and assist homeowners with redaction. Cal.\ Gov.\ Code \S~12956.2.}

Third, there are substantial societal benefits from reducing the stigmatic and signaling effects of racial covenants and enabling a systematic historical accounting of racial covenants and understanding of mechanisms of housing discrimination. 

Fourth, the release of the fine-tuned Mistral model does not pose any marginal risk (since Mistral is already an open model), while posing substantial benefits for the many jurisdictions grappling with efforts to identify and redact racial covenants. While we have curated a diverse training dataset from eight counties across the United States, we do caution that application in other jurisdictions should include domain-specific validation efforts. Furthermore, there are no additional privacy risks from releasing this model, we mask the loss on input text (so a model cannot learn to generate anything in its input) and we verified that training data for the covenant itself does not contain private information.

Fifth, we were guided in all elements of this collaboration by the articulated needs from County partners, when government entities have historically faced challenges integrating new technology \citep{kelman1990procurement}. Our approach centered the concrete problem faced by administrators to ensure that machine learning was appropriately prototyped, developed, and integrated (see Section~\ref{ref:integration}). Such an approach requires support and cooperation with the county, but may not be feasible in all counties. As such, community-based volunteer efforts across the country will likely still play an important role, and such efforts may also be enhanced by our model. 

In short, due to minimal risks and substantial benefits, we believe this to be a compelling illustration of machine learning for public good \citep{wagstaff2012machine}. 

\section{Optical Character Recognition (OCR) Experiments}
\label{appendix_ocr}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{images/1908_doc_example_more_redaction.png}
    \caption{Excerpt from a 1908 property deed scan, illustrating challenges for OCR: low resolution, smudged characters, and visual artifacts.}
    \label{fig:ocr-challenges}
    \vspace{0.5em}
\end{figure}


Historical property deeds prior to the late 20th century are typically typewritten and vary widely in text and scan quality. As such, OCR is a non-trivial problem for these documents.

In our experiments, we found that the most popular open-source OCR library, Tesseract, performed very poorly on older deeds, particularly those with low-quality scans. Tesseract transcriptions often omitted entire words, substituted characters, and misordered sections of text. We found that common spell-correction and other off-the-shelf methods were insufficient to mitigate these issues.

However, the DocTR library with the ResNet-50 and VGG-16 models is more effective. The improvements in OCR after switching to DocTR further lead to downstream increases in the performance of our RRC detection models. We qualitatively and quantitatively compare the performance of the outputs of both OCR libraries on our dataset.

\begin{table}[h]
\centering
\begin{tabular}{lll}
\hline
 & \multicolumn{2}{l}{\textbf{F1 Score on Evaluation Set}} \\
\textbf{Detector} & \textbf{Tesseract} & \textbf{DocTR: ResNet-50 / VGG-16} \\
\hline
\textit{Fuzzy Matching}& 0.921 & \textbf{0.943} \\
\textit{Mistral Fine-Tuned}& 0.986 & \textbf{0.997} \\
\hline
\end{tabular}
\caption{Switching from Tesseract to DocTR OCR improved model performance for both the baseline and the language models.}
\end{table}

\textbf{Tesseract Example}
    
; an THIS. 1DENTUE, ‘made ‘ott day of February in the ; year of) ar Lord ‘ane. “| thoamnd nine ‘hundred. and ten, “by and. ve tween [REDACTED] of santa clara. county, state. "of california; the party ‘of the first part, and wre. [REDACTED], ‘of san mec county, | State of ouitornia, the party of the second part; — aa re se ese Mi TsESSETH: THAT the emiaiparty of the fitet ‘part; for and in consideration: : Ms of. tte, ain of: ‘ten (gio) Dollars, eae éoin of the ‘United: ‘Btates ‘to. hin in hand paid. by the os ‘gata party ‘er the second pent, the receipt whereof ie herety scimamtedged, has ‘granted, are - : gained and so1,, conveyed and confirma, and “by these presents dos. (grant,: vargain and sell, “SE

\textbf{DocTR Example}

THIS INDETURE, made the7th day of rebruary in the year of aur Lord thousand nine hundred and ten, by and. be tween [REDACTED] a Santa Clara. County, Stateof califarnia, the. party of the first part, and [REDACTED], of San iteo county,of tlie, sum of Tep (\$10) Dallars, gold coin, of the United Statez to.hin in hand paid. by thebaid party'ar the second pant, the receipt Whereof 10 herehy aeknaledged, has granted, bar-gained and sol4,. conveyed and confirmed, and by these presents dos grant, bargain and sell,convey ad confirn anto the said party of the second. part, and to her beireiand assigna forever

\begin{figure}[!t]
    \centering
    \setlength{\belowcaptionskip}{10pt}
    \includegraphics[width=\linewidth]{images/ScanningArtifacts_1908.pdf}
    \caption[]{Real property deeds from Santa Clara County (from 1908), with several visible scanning artifacts.}
    \label{fig:oct-example}
\end{figure}





\clearpage
\section{Instruction-Finetuning Prompt}
\label{sec:instruction-finetuning-prompt}

\begin{figure}[!h]
    \centering
    \setlength{\belowcaptionskip}{10pt}
    \includegraphics[width=\linewidth]{images/InputPrompt.pdf}
    \caption[]{Input and output template used in the finetuning of our Mistral 7B model.}
    \label{fig:instruction-finetuning-template}
\end{figure}



\section{Annotation App}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{images/labeler_app.png}
    \caption{Screenshot of the app used to label data for training our racial covenant detectors. The interface allows labelers to modify or reverse the initial annotation of the model with respect to the on-page bounding box, text span, and cleaned up quotation.}
    \label{fig:labeler_app}
    \vspace{0.5em}
\end{figure}



\clearpage
\section{Resource Cost Comparison}
\label{sec:resource-cost-comparison}

\textbf{Manual Review.} Manual review was the first -- and most straightforward yet least feasible -- option considered by Santa Clara County for implementing the review of racial covenants in property records. With an estimated review speed of 60 pages per hour, manually reviewing the entire archive of 84 million pages would require approximately 1.4 million staff hours, or about 160 years of continuous work for a single individual. At the current minimum wage in California (\$16 per hour), the total labor cost for reviewing all 84 million pages would amount to \$22.4 million.

For the subset of 5.2 million pages, manual review would require 86,667 staff hours, resulting in a labor cost of approximately \$1.4 million. These estimates, however, do not account for additional costs, such as staff training, workflow management, and handling the physical or digital logistics associated with the records. Moreover, the extended duration of manual review increases the risk of non-compliance with legislative deadlines, such as those set by California's AB 1466, further emphasizing the impracticality of this approach.

\textbf{Off-the-Shelf Language Model (ChatGPT).} A more technologically advanced and reliable alternative to manual review is the use of a commercial off-the-shelf language model, such as OpenAI’s ChatGPT-3.5, to process property deeds. With an estimated processing capacity of 1,000 requests per minute, analyzing the 5.2 million pages would take about 87 hours. However, while obviously way faster than manual review, the financial cost of using a commercial language model is significant. Based on a token usage of 922 tokens per deed page -- accounting for both the task instructions and document content\footnote{This estimate is derived from a random sample of 10,000 pages from Santa Clara County’s real property records.} -- and OpenAI’s current pricing of \$1 per 1 million tokens for ChatGPT-3.5 (viz., \texttt{gpt-3.5-turbo-1106}), the total cost of processing all 5.2 million pages using a zero-shot prompting setup would be approximately \$4,794.


If a few-shot prompting technique is applied to enhance the model’s accuracy—by providing two examples with each request—the cost rises to \$13,634. For more complex and nuanced tasks like this, a more powerful model, such as GPT-4 Turbo, might be required. At \$10 per million tokens, the cost of using GPT-4 Turbo to process the entire dataset would escalate to \$47,944, making it significantly more expensive than our finetuned Mistral model, which achieves the same outcome for just \$258. 

\textbf{Our Finetuned Language Model (Mistral).} The most cost-effective option is our custom finetuned language model approach. Our Mistral model, finetuned specifically on a set of restrictive covenants, can process approximately 1 million pages per day, allowing it to complete the review of 5.2 million pages in just six days. The primary advantage of this approach lies in its cost-efficiency. Rather than relying on a commercial API, the model can be run on rented GPUs, with a rental cost of roughly \$258 for the entire six-day processing period.\footnote{In our case, we made use of Stanford’s own Sherlock compute cluster to conduct our experiments.} Moreover, performing all our experiments and analyses internally eliminates any privacy-related risks, as we retain complete oversight of the data. This means we do not have to rely on external providers, ensuring that sensitive information is handled securely and in compliance with privacy regulations throughout the entire process.

Thus, the total cost for reviewing 5.2 million pages using this custom model would amount to only \$258 -- dramatically lower than the \$1.4 million required for manual review and significantly less than the \$30,000 projected for using an off-the-shelf LLM. While setting up and fine-tuning the model requires some initial effort, this method offers the most scalable, efficient, and cost-effective solution for identifying RRCs in Santa Clara County’s property records.


\clearpage

\section{List of Terms Used by Santa Clara County in Manual Review of Deeds}
\label{sec:scc-keyword-list}

{\color{red} Warning: Due to the nature of the racial covenants, the search terms contain offensive terms.}

The Santa Clara County Clerk-Recorder’s Office initially used the following list of keywords to identify instances of racial covenants in their digitized real property deeds: African, American Asiatic, Aryans, Asian, Asiatic, Black, Blood, Brown, Caucasian, Chauffeurs \emph{(exception: dependent on the context)}, Chinese, Clover, Color, Dago, Domestic Servants, Domiciled, Dyke, Ethiopians, Foreigners, Gandhi, Gardeners (exception: dependent on the context), Gay, Ginzo, Greaser, Hebrews, Hindu, Immigrant, Indian, Interracial, Italian or Italians, Japanese, Jew or Jews, Korean, Lineage, Malays, Master, Mixed race, Mongolian, Native of the Turkish Empire, Negro, Nigga, Nigger, People, Portuguese, Race, Religion, Restricted District, Servants, Turkish, White, Mulatto


\clearpage
\section{Geographic Distribution of Racial Covenants}\label{appendix:full_faceted_map}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{images/tractmap_full_faceted.pdf}
    \caption[]{Density of properties with racial covenants in modern-day Census tracts in 1905, 1920, 1935, and 1950. This figure includes the more rural tracts in the south and east of the County.}
    \label{fig:scc_map_faceted_full}
\end{figure}

\clearpage
\section{Lot Coverage of Racial Covenants}
\label{appendix:lot-coverage}

This section provides additional visualizations of the distribution of racial covenants in Santa Clara County, focusing on the number of \emph{lots} covered by racial covenants rather than the number of deed records. These figures complement the analysis presented in \S~\ref{sec:prevalence}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/map_fig_lot_level.pdf}
    \caption{Distribution of lots covered by racial covenants in Santa Clara County. \textbf{Top:} Overview of the entire county. \textbf{Bottom left:} Racial covenants in south Palo Alto and Mountain View. \textbf{Bottom right:} Racial covenants in downtown San Jose. Dots represent individual subdivisions and are scaled in proportion to the number of lots covered by racial covenants, instead of the number of racial covenants.}
    \label{fig:scc_lot_map}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{images/tractmap_faceted_lot_level.pdf}
    \caption{Density of lots covered by racial covenants in modern-day Census tracts in 1905, 1920, 1935, and 1950. Lots are plotted cumulatively. This figure shows the spread of racial covenants throughout the county between 1905 and 1950, with the number of affected lots as the unit of analysis.}
    \label{fig:scc_map_faceted_lot_level}
\end{figure}