\section{Integration with Santa Clara County: Processing 5.2 Million Pages of Deeds with AI}
\label{ref:integration}

After identifying the fine-tuned Mistral model as the best option, we developed a pipeline for responsibly processing 5.2 million pages of Santa Clara County deeds. Here, we describe the additional engineering and design efforts for processing this magnitude of documents, including additional manual review by our team and the Santa Clara County officials.

\textbf{Processing 5.2 Million Pages of Deeds.} Following the evaluation pipeline, we scan 5.2 million pages of deeds using our OCR pipeline and apply our model. OCR was the most computationally expensive part of our pipeline, taking 215 hours to complete on 4 A100 GPUs.

We then spot check the deeds with identified RRCs. Unlike our evaluation, we found several false positives in the 1960s and 1970s -- our evaluation dataset has docs from many different time periods outside of Santa Clara, but our Santa Clara County evaluation documents were exclusively pre-1940s.

One example of how the temporal shift led to the emergence of false positives are so-called ``fair housing'' covenants. Several false positives from the 1970s stipulated the opposite of a racial covenant: citing the Fair Housing Act of 1968, these provisions explicitly \emph{banned} discrimination on the basis of race. Because our fine-tuned model was never exposed to any similar language in training, it incorrectly flagged the discussion of racial restrictions as a racial covenant.\footnote{\label{note:fp-example}One such covenant read: ``Fair Housing: No owner shall, either directly or indirectly, forbid or restrict the conveyance, encumbrance, leasing, mortgaging, or occupancy of his unit to any person of a specified race, color, religion, ancestry, or national origin.''}

However, we observed that the model was well-calibrated: more than 90\% of these later-period false positives had a prediction confidence score of below 75\%, while no known true positives did. We therefore set a minimum confidence threshold of 75\% in preparing our final results.\footnote{As an additional heuristic, we also filtered any covenant which contained the phrase ``fair housing'' on the assumption that these were likely to be false positives similar to the example in note~\ref{note:fp-example}.}

To ensure that our results were sufficiently precise, we randomly sampled 200 positive predictions from our final results. We observed two false positives; the precision on the full dataset can be estimated with a 95\% confidence interval of 96.4\% to 99.7\%.\footnote{These figures are calculated using the Wilson score interval for binomial proportions.}

Finally, for any specific covenants that we discuss, we manually review to ensure that identification is correct. And over 4,500 of the identified covenants have already received confirmation through attorney review.





\textbf{Responsible Integration with Santa Clara County Workflow.} Our longer-term partnership enabled working closely together to consider responsible integration of machine learning output. 

Figure~\ref{fig:integration} presents the baseline operational workflow for how the County Recorder and the County Counsel offices approached the Restrictive Covenant Modification Program (RECOMP). Our model essentially took the time-consuming search steps 1--3 and automated them. After that, the county recorder reviewed the results and delivered them to the County Counsel for approval of redaction, per statutory requirement under AB 1466. All redacted provisions were retained, as required.  

Government integration of technology -- and AI specifically -- has been challenging \citep{pahlka2023recoding}.  Procuring AI systems or technology from private vendors can be particularly difficult  given the changing nature of technology and contracting process \citep{kelman1990procurement}. On the other hand, civic technology can generate many ideas and prototypes, but public agencies require long-term engagement to integrate, monitor, and evaluate the benefits of technology \citep{engstrom_government_2020}.
Our partnership enabled us to identify the most time-consuming task (search) and test the benefits of AI assistance. The academic team ensured the evaluation of performance, and the County team reconfigured its operational processes to integrate the model output. One key principle is that AI is used solely in aid of the statutorily required human review, ensuring that any redactions meet the county counsel standard for an RRC. 

Put differently, rather than promising an end-to-end solution, our partnership enabled us to identify the biggest pain point that could be addressed by AI, while keeping humans responsibly in the loop. 

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{images/Workflow_Figure_v2.pdf}
    \caption{This workflow diagram depicts the multi-step process undertaken by the Restrictive Covenant Modification Program (RECOMP) in Santa Clara County Clerk Recorder’s Office to identify, review, and remove RRCs from real property deeds. The process begins when CRO locates a deed with potential RRCs and checks for a digital copy. If none exists, the original deed is scanned and uploaded to the County Cloud. CRO highlights unlawful language and submits the document to the County Counsel (CC) for review via DocuSign. Based on CC’s review, the redaction may be approved, corrections may be required, or the request may be rejected. If approved, RECOMP proceeds with the redaction, records, indexes, and verifies the document. The final version is then logged and uploaded for accurate and up-to-date recordkeeping.
}
    \label{fig:integration}
\end{figure}
