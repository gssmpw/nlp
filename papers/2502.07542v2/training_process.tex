
%\section{Training Process and Performance Evaluation}
\section{Evaluation}
\label{sec:model_analysis}

Our evaluation test set consists of light curves from confirmed exoplanet candidates and false positives, such as EBs, and non-transit light curves. Since targets may have been observed across multiple sectors, we ensured that none of the targets in the evaluation set have associated targets in other sectors included in the training or validation sets. This separation guarantees that the model is tested not only on unseen light curves but also on unseen targets, preserving the integrity of the evaluation process. \par

%In this section, we describe the metrics we adopted to evaluate the performance of our model.

%\subsection{Implementation}
%Our model described in this work has been implemented in Pytorch (\citet{paszke2019pytorch}) an open source machine learning framework. 

%\subsection{Training}

%We train our model using the labeled datasets described in Section~\ref{datasets}. 


\subsection{Performance evaluation metrics}
\label{sec:performancemetrics}

%In machine learning, classification is the task of predicting the class to which the input data belongs. In this sense, to evaluate how well the classifier manages to predict, evaluation metrics are typically used to reflect the true performance of the classifier. \par

We evaluate our model using two classes: planet (positive instances) and not planet (negative instances). As we mentioned before, most of our dataset belongs to negative instances, and due to this imbalance, accuracy is not an appropriate metric as it can introduce bias by favouring the majority class. Therefore, we evaluate the performance of our model with metrics for unbalanced datasets and for binary classification. We focused on the Area Under the Receiver Operation Characteristic Curve (AUC-ROC) score metric and F1 score \citep{powers2020evaluation}. The AUC score is used for binary classification, and it provides a single value to summarize the true positive rate and the false positive rate. F1 score is the harmonic mean of the precision (how many identified exoplanet transits are correct) and recall (how many real exoplanet transits were detected).  \par

In our work, the AUC score helps us to evaluate the ability of the model to distinguish between true exoplanet transits and false positive signals like EB or non-transit signals. While the AUC score focuses on the model's overall classification performance, the F1 score provides an evaluation that considers both precision and recall. This helps us know how well the model identifies exoplanet transit while minimizing false positives and missed true transits. For each evaluation in all of the experiments, we perform 10-fold stratified cross-validation, taking the mean as the final result. \par

%\subsection{Model configuration}

%Based on test set performance, our best model uses centroid and background time series. 
%We trained our model using a batch size of 350 epochs. 

\subsection{Results}
\label{sec:results_nn}
Our model was evaluated with samples, which the network has not seen up to this point, which includes light curves from confirmed and known planets, EBs, and non-transit such as IS and V. This evaluation is based on metrics described in Section~\ref{sec:performancemetrics}. In addition, since the majority of light curves are expected to have no planetary transit signals, we evaluated the generalization capability of our model across different sectors of TESS by calculating the percentage of candidates detected by our implemented models. For this evaluation, we randomly selected a sample of light curves from the SPOC dataset and made predictions to determine the percentage containing exoplanet transit signals. As a result, our model identified that approximately 0.1\% of the light curves contain planetary transit signals, demonstrating its generalization ability across multiple sectors and its effectiveness in handling complex stellar variability. The main goal of this work is to improve the exoplanet candidate identification process, not only by increasing the likelihood of detecting potential candidates but also by reducing the false positive rate. This will improve the examination process for human vetting, as there will be fewer signals to analyze, with a higher probability that any given signal will contain an exoplanet. Currently, many DL approaches focus on the examination of pre-selected candidates \citep{valizadegan2022exominer}, as this remains a challenge in the field of exoplanet detection. \par
% auc roc curve

Table~\ref{tab:summary_results} shows the performance results for our model across various experimental configurations, including the use of centroid time series and background time series as input for our model. As a result, we found that incorporating the background time series significantly improves the performance of our model. In comparison, the centroids also contribute to performance improvement, but their impact is slightly less substantial. \par

Regarding the components of the attention mechanism, our default model is trained with four heads, as increasing the number of heads beyond this threshold yielded no significant improvement in performance while also leading to increased computational cost. We varied both the number of layers and the number of dimension embedding. Reducing $l = 2$ results in a 2 percent decrease in the AUC-ROC score, while setting $l = 8$ yields an AUC-ROC score equivalent to that of $l = 4$ and an F1 score with a 1 percent improvement for $l=8$. However, we opted to use $l=4$ as our default model as the reduced computational costs outweighed the increase in predictive performance for our use case. 

Additionally, the Table~\ref{tab:summary_results} highlights the impact of training the model without injected light curves, providing insights into how these injections affect the overall performance. Our results showed an improvement in the AUC-ROC score, and beyond that, we also made predictions to identify new candidates within a randomly selected sample from the SPOC dataset. Consequently, the model without data injection identified that approximately 0.36\% of the light curves contain planetary transit signals. This suggests that the model trained with data injection effectively reduces the number of light curves that need to be examined to determine potential planet candidates. These results suggest that training with injected data and the inclusion of background and centroid time series not only improves the performance but also allows for a more efficient evaluation of light curves. \par



\begin{table}
	\centering
	\vspace{5mm}
	\caption{Summary of the results in terms of AUC-score and F1-score. Default model is: $l = 4$, $d_{emb} = 512$, with centroid and background time series, and with injeted LCs. }
	\label{tab:summary_results}
	\vspace{4mm}
	\begin{tabular}{lcccc} 
		\hline
		Model &  Avg. auc score & Avg. F1-score \\
		\hline
        Default & 0.88 & 0.82  \\
        $l = 2$ & 0.84 & 0.80 \\
        $l = 8$ & 0.88 & 0.83 \\
        Without centroid & 0.87 & 0.80  \\
        Without background & 0.85 & 0.80  \\
        \textnormal{$d_{\textnormal{emb}}$} = 128 & 0.80 & 0.76\\
        \textnormal{$d_{\textnormal{emb}}$} = 256 & 0.84 & 0.79 \\
        Without injected LCs & 0.86 & 0.82 \\
        \hline		
	\end{tabular}
	\vspace{3mm}
\end{table}


