
\section{Evaluation Metrics}


\subsection{Saliency}
\label{appendix:saliency}
\textbf{Saliency} measures a question’s relevance and importance within the document \( D \)~\cite{wu2024questions}.
It is rated on a Likert scale from 1 to 5, where a score of 1 indicates that the question in section \( k \) is unrelated to \( S_{[1:k]} \) and contributes minimally to understanding, while a score of 5 indicates strong relevance to \( S_{[1:k]} \) and essential comprehension support for \( S_k \) by clarifying key concepts or introducing new information.

\begin{tcolorbox}[title=Saliency Prediction, myboxstyle, breakable]
\textbf{Article:} \textit{\{article\}}  \\
\textbf{Question:} \textit{\{question\}}  \\

\textbf{System Instructions}  
Imagine you are a curious reader going through the article. You come across a question and need to determine whether it should be answered within the article or not. Your task is to assign a score based on the relevance and necessity of answering the question. \\

\textbf{Scoring Criteria}  
\begin{itemize}
    \item \textbf{Score = 1:} The question is \textbf{completely unrelated} to the article.
    \item \textbf{Score = 2:} The question is \textbf{related but already answered} in the article.
    \item \textbf{Score = 3:} The question is \textbf{related but answering it is not essential}, as it expands on a \textbf{minor or non-central idea}.
    \item \textbf{Score = 4:} The question is \textbf{related and answering it enhances the reader’s understanding} of the article.
    \item \textbf{Score = 5:} The question is \textbf{related and must be answered}, as it expands on \textbf{central ideas of the article}.
\end{itemize}

\textbf{Scoring Guidelines}  
\begin{itemize}
    \item The score is based on the \textbf{information utility} of the answer.
    \item If a question is related but \textbf{not central or necessary}, \textbf{do NOT} assign it a high score.
    \item Assign \textbf{Score 3} if the question is unanswered but \textbf{not critical}, and \textbf{Score 2} if it has already been answered.
    \item \textbf{Distinguishing Scores 4 and 5:}
    \begin{itemize}
        \item If the article would feel \textbf{incomplete} without the answer, assign \textbf{Score 5}.
        \item Otherwise, assign \textbf{Score 4}.
    \end{itemize}
    \item A \textbf{Score of 4} is useful, but \textbf{other questions may be more important}.
    \item A \textbf{Score of 5} is reserved for \textbf{must-answer, central questions}.
    \item \textbf{Avoid bias toward high scores} and carefully follow the instructions.
\end{itemize}

The score should strictly be an \textbf{integer between 1 and 5}.

\textbf{Score:}

\end{tcolorbox}


\subsection{Expected Information Gain (EIG)}
\label{appendix:eig}
Expected Information Gain (EIG) quantifies the reduction in uncertainty about a student's knowledge state after answering a question.
We estimate EIG using an LLM by computing the entropy of the model’s token probability distribution before and after conditioning on the first token of the correct answer. EIG is computed as:
\[
EIG(Q) = H(X) - H(X | A_1)
\]
where \( H(X) \) is the prior entropy, representing the model’s uncertainty before seeing the answer, and \( H(X | A_1) \) is the posterior entropy after conditioning on the first token \( A_1 \). The entropy is given by:
\[
H(X) = - \sum_{x \in V} P(x) \log P(x), \quad
H(X | A_1) = - \sum_{x \in V} P(x | A_1) \log P(x | A_1)
\]
where \( V \) is the vocabulary, and \( P(x) \), \( P(x | A_1) \) are token probabilities before and after observing \( A_1 \), respectively.
We estimate probability distributions by querying an LLM with the following prompts.
Instead of conditioning on the full answer, we use only the first token, as most uncertainty reduction occurs at the start of an answer.
This aligns with the autoregressive nature of LLMs and ensures EIG captures incremental belief updates rather than full-answer memorization.

\begin{tcolorbox}[title=Prior Entropy Estimation, myboxstyle, breakable]
Imagine you are a reader encountering a question in the article.

\textbf{Article:} \{article\}

\textbf{Question:} \{question\}

\textbf{Answer:} 
\end{tcolorbox}

\begin{tcolorbox}[title=Posterior Entropy Estimation, myboxstyle, breakable]
Imagine you are a reader encountering a question in the article.

\textbf{Article:} \{article\}

\textbf{Question:} \{question\}

\textbf{Answer:} \{$A_1$\}
\end{tcolorbox}


