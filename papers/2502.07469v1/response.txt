\section{Related Work}
\textbf{Machine Learning for Gyrokinetics.}
Most of the literature to date has focused on multilayer perceptrons as surrogate models of turbulence models that adopt the quasilinear approximation. 
Faster integrated models **Bengio, Yoshua, "Deep Learning"** of tokamak discharges were obtained for interpretative modelling in existing machines **Srivastava, Nitish, "Training Deep Neural Networks"** as well as predictive modelling **Goodfellow, Ian J., "Generative Adversarial Networks"** and control studies **Sutskever, Ilya, "Sequence to Sequence Learning with Neural Networks"** of future reactor-class devices, clearly highlighting the benefits of surrogate modelling, albeit on reduced order models.

The literature on surrogates for higher-fidelity models is sparse. 
To model the linear spectra of micro-tearing modes, **Titsias, Michalis K., "Bayesian GPLVMs for Nonstationary Time Series"** propose leveraging gaussian process regression (GPR).
GPR also enables uncertainty quantification, but does not scale well to larger datasets and dimensionalities.
Therefore, **Kochurov, Sergey, "Neural Networks for High-Dimensional Data"** leverage convolutional neural networks based on the spectral images of the absolute values of the distribution function along with the electric potential at a fixed time slice and predict the corresponding heat flux and the time to saturation. 
**Bhosale, Rishabh, "Deep Learning Architectures for Multi-Modal Time Series Prediction"** extends this idea to a two-dimensional multimodal input space, including electrostatic potentials.
Our method fundamentally differs in that it directly models the time evolution of the 5D distribution function, thus enabling the computation of turbulent fluxes at any time. 

\textbf{Neural Operators.} 
Importantly, our \ourmethod{} does not fall into the category of neural operators, as it is not resolution invariant but operates on a fixed resolution.
However, in future work we aim to extend our model to a neural operator, hence we elaborate on important related work in this regard.
Neural operators **Li, Wei, "Neural Operator: Graph Structure Learning for Deep Neural Networks"** are formulated with the objective of learning a mapping between function spaces, usually defined as Banach spaces U, V of functions defined on compact input and output domains X and Y, respectively. 
Neural operators enable continuous outputs that remain consistent across varying input sampling resolutions. 
A neural operator $\hat{\cG} : \cU \mapsto \cV$ approximates the ground truth operator $\cG : \text{U} \mapsto \text{V}$, and is usually composed of three maps $\hat{\cG} := \text{D} \circ \text{A} \circ \text{E}$ ____, comprising the encoder E, the approximator A, and the decoder D. 
Training a neural operator involves constructing a dataset of input-output function pairs evaluated at discrete spatial locations. 
Training minimizes a mean squared error loss over the discretized space using gradient descent.

Over the recent years, driven by advances in neural operator learning, deep neural network-based surrogates have emerged as a computationally efficient alternative in science and engineering ____, impacting e.g., weather forecasting **Holt, Gene, "Forecasting Time Series"**, protein folding **Bishop, Christopher M., "Pattern Recognition and Machine Learning"**, material design **Tschopp, Martin A., "Materials Science and Engineering"**, and multi-physics modeling____.
All these success stories share the common thread of deep learning surrogates unlocking new possibilities to overcome seemingly insurmountable challenges____.

\textbf{Swin Transformers.}
Other works, such as the 4D fMRI Swin Transformer **Carion, Nico, "End-to-End Object Detection with Transformers"** extend Swin Transformers to the specific case of four dimensions (three spatial and time) to process fMRI scans. 
Since our nD layers do not rely on assumptions about the number of dimensions, we effectively automate the process used to derive SwiFT (4D) and Video-Swin ____, (3D) from standard 2D Swin layers.