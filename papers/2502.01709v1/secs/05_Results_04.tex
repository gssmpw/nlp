\section{Results}

\input{secs/00_Table_01_04}

\tablename~\ref{tab:res} provides the results for our models and two benchmark models, AV-HuBERT~\cite{AVSR_robust_ssAVSR_avhubert2_2022} and AV-Fusion~\cite{AVSR_2023_selfsupervised}. All models are divided into two groups according to their model size, with the smaller models in the upper part and the larger models in the lower part. All models are tested on the noise categories Babble, Music, Natural and Sidespeaker across a wide SNR range from -10dB to 20dB, with -10dB representing scenarios with very high background noise levels.
All results are given in Word Error Rate (WER) in [\%].

\subsection{AV-HuBERT vs. AV-Fusion}

To ensure comparability, we trained the AV-Fusion~\cite{AVSR_2023_selfsupervised} models, from the official repo for both model sizes on our data. This was necessary because AV-Fusion does not provide models that were pre-trained on VoxCeleb2 and fine-tuned on 430h LRS3. 
Since AV-HuBERT does not provide a seed definition, our splits are not identical and a test on our data would produce different results.
Consequently, we use the values from the official paper~\cite{AVSR_robust_ssAVSR_avhubert2_2022}. We are limited to the large version, as no values are available for the smaller base version. In contrast to AV-HuBERT, we analyze Music and Natural noise separately, so we report the mean values given by AV-HuBERT for both noise categories.

Comparing the larger AV-Fusion small FFT model to AV-HuBERT large reveals that AV-HuBERT is superior for Babble noise, while AV-Fusion has clear advantages for Sidespeaker noise. We also see a mixed picture for Music and Natural noise. 
Across all SNR values, that AV-HuBERT provides results for (-10dB, -5dB, 0dB, 5dB, 10dB) and all noise categories AV-Fusion achieves an average reduction in WER of 2.1\%, which demonstrates that both approaches have a very similar performance, with a slight advantage for AV-Fusion.
Another AVSR with similar performance is Whisper-Flamingo~\cite{AVSR_2024__WhisperFlamingo}. The official paper only provides one value for SNR 0dB and the noise category Babble with a WER of 5.7, which is also slightly higher than the value of 4.7 achieved by AV-Fusion.

Since all of these approaches show quite similar performance, we will focus on the comparison to AV-Fusion FFT in the subsequent discussion, as results for both model sizes and SNR values from -10 dB to 20 dB are available for this approach.

\subsection{LoRa Adapter}

The LoRa-AVSR base/small - Full noise spectrum models share the same model architecture as all subsequent noise-scenario-specific models, but have been trained simultaneously on all four noise categories and the entire SNR range.

Compared to the AV-Fusion FFT models, which were trained on the same data, the results reveal an average increase of 41.5\% for high noise levels (-10dB) across all noise categories. For the SNR range from 0dB to 20dB, the average increase in WER is reduced to 11.0\%. 
For these models, the number of trainable parameters is 79.3\% to 89.1\% lower than for AV-Fusion and 94.1\% lower than for AV-HuBERT large, which explains the lower performance.


\subsection{Noise-Scenario-Specific Adapter-Sets}

\tablename~\ref{tab:res} provides the results for noise-category and noise-level-specific adapter models for both model sizes and a comparison to AV-Fusion with full fine-tuning and AV-HuBERT large.
The noise-category-spcific adapters were trained on individual noise categories spanning the entire SNR range from -15dB to 30dB. The noise-level-specific adapters were trained on the SNR range greater than or less than 0dB, but received examples from all noise categories. All adapter-sets share the same frozen Whisper models.
The results for the noise scenarios each model was trained for, are highlighted in gray, and show that noise-scenario-specific training leads to significant improvements compared to the LoRa-AVSR - Full noise spectrum models. The noise-level-specific adapter-set models in particular show a clear improvement compared to training over the entire SNR range, demonstrating the benefits of using adapter-sets for specific noise scenarios. 
The WER values are still worse, but relatively close to those of AV-Fusion FFT, which is remarkable since AV-Fusion trains many times more parameters. For the smaller models and the noise category Sidespeaker, we actually achieve an improvement compared to AV-Fusion for an SNR value of -10db.

In general, it is noticeable that the noise-level-specific models perform slightly better than the noise-category-specific models. Especially for high noise levels at -10dB and 0dB, the noise-level-specific models achieve lower WER values across both model sizes and the majority of noise categories. We hypothesize that the noise-level-specific HighNoise models are forced to pay high attention to the visual information during training, as the audio inputs are very noisy. In contrast, the noise-category-specific models receive many examples from the SNR range between 5dB to 30dB and 5\% clean audio inputs, which may have the effect that these models do not require the visual information to generate correct embedding and logits, for the majority of training samples.

The blue/green marked rows represent the results achieved when the noise-category (green) and noise-level (blue) are not known a-priori but estimated with our proposed classifier for adapter-set selection (sec. IV.C).
The noise-category-classifier achieves a recognition rate of 98.1\%. The noise-level-classifier actually performs a SNR regression. We specify a threshold value of 5dB, which is used for the HighNoise/LowNoise selection, leading to a correct classification rate of 94.7\%. 

All noise-scenario-specific models with classifier achieve results that are almost identical to the optimum results for each noise-scenario-specific model, which demonstrates the strength of this approach. The only exception is the noise category Sidespeaker, especially for the noise-level-specific models.

We identified two reasons for the weakness at this noise category: First, for Sidespeaker noise, the gap between the results for the HighNoise and LowNoise models is larger than for any other noise category, especially at -10dB, which leads to a stronger negative influence of misclassifications. We suspect that this gap could be reduced by presenting a few examples from the LowNoise range to the HighNoise models during training, to get them used to these noise scenarios, and reduce the gap.
Second, the noise-level-classifier performs poorer for this noise category compared to other noise categories. (Noise-Level-Classifier - correct classification rate at SNR -10dB: Babble 100.0\% / Music 98.4\% / Natural 93.3\% / Sidespeaker 91.3\%). An explanation might be that this noise category overlaps two equivalent speech signals and the classifier struggles to identify the main signal, leading to incorrect SNR predictions.

All noise-scenario-specific models achieve a significant improvement for both model sizes compared to the LoRa-AVSR - Full noise spectrum models and the results tend to be close to those of the AV-Fusion FFT, but are still slightly poorer. Comparing the number of trainable parameters reveals that the noise-level-specific models in particular have 58.6\% to 78.6\% less trainable parameters than AV-Fusion and 88.5\% less trainable parameters than AV-HUBERT large.

As part of several ablation studies, we tested the AV-Fusion FFT models' ability to handle audio-only information, to simulate the case that no visual information is available, which led to an dramatic increase in WER values even at low noise levels. This demonstrates one of the main advantages of our adapter-based models. If no visual information is available, the underlying unmodified ASR model can be used, which is very capable on audio-only data as it has been trained on huge amounts of speech data. Using the AV-Fusion small FFT model with 257M parameters, an extra Whisper small model with 244M parameters needs to be provided for this case.

Another advantage is the easy expandability, as the underlying Whisper model remains unchanged. This allows the extension by further adapter-sets, for instance additional noise categories or even more specific adapter-sets such as a Babble noise adapter-set explicitly trained on high noise levels to improve the adaptation to this specific scenario. In case of changing noise categories, a fully fine-tuned AV-Fusion or AV-HuBERT model would require a re-training.


\section{Conclusion}

We presented an adapter-based approach to Audio-Visual Speech Recognition that allows to train noise-scenario-specific adapter-sets to cover a large range of noise levels and different noise categories. 
We deploy two classifiers with very high recognition rates to select the optimum adapter-set for each specific noise scenario.
We demonstrate that the AV-Fusion approach, which is related to our approach, achieves a performance comparable to one of the current SOTA AVSR approaches, AV-HuBERT.
Compared to AV-Fusion, our models reveal a slightly higher word error rate on average, which is partly caused by certain weaknesses towards the noise category Sidespeaker. Across large ranges of tested SNR values and noise categories, our models show a performance close to that of AV-Fusion and AV-HuBERT, despite 88.5\% less trainable parameters and smaller overall model size compared to AV-HuBERT. 

The moderate weaknesses in terms of performance are compensated by the advantages such as the expandability with additional noise scenario-specific adapter-sets and the usability of the unchanged underlying powerful Whisper ASR model, in case no visual information is available.
