
\begin{table}[ht]
\footnotesize
\centering
\scalebox{0.8}{
\begin{tabular}{cc|c|cccc}
\textbf{Data} & \textbf{Trained Components} & \textbf{TrP} & {-10} & {0} & {10} & {20} \\
\midrule

All & Full Fine-Tuning~\cite{AVSR_2023_selfsupervised} & 85.8M & 46.7 & 7.1 & 2.9 & 2.5 \\
\\[-0.4em]

All & LoRa - Train Fusion Module & 18.0M & 60.7 & 10.0 & 2.9 & 2.5 \\
\\[-0.4em]


Babble & LoRa - Fusion Module Frozen & 4.8M & 57.2 & 9.6 & 3.0 & 2.6 \\
\\[-0.7em]

Babble & LoRa - Fusion Module Adapter & 5.8M & 56.7 & 9.4 & 3.0 & 2.6 \\
\\[-0.7em]

Babble & LoRa - Fusion Module - Extractor Frozen & 8.7M & 54.3 & 8.9 & 3.0 & 2.5 \\
\\[-0.7em]

Babble & LoRa - Train Fusion Module & 18.0M & 51.5 & 8.3 & 2.8 & 2.6 \\
\\[-0.3em]



HighNoise & LoRa - Fusion Module Frozen & 4.8M & 55.4 & 8.8 & 2.6 & 2.6\\
\\[-0.7em]

HighNoise & LoRa - Fusion Module Adapter & 5.8M & 54.7 & 8.8 & 3.1 & 2.3 \\
\\[-0.7em]

HighNoise & LoRa - Fusion Module - Extractor Frozen & 8.7M & 52.0 & 8.6 & 2.9 & 2.9\\
\\[-0.7em]

HighNoise & LoRa - Train Fusion Module & 18.0M & 48.7 & 7.8 & 3.2 & 2.7 \\
\\


\end{tabular}
}
\caption{
Beschreibung!}
\label{tab:res_babble_detail}
%\label{tab:res1}
\end{table}
