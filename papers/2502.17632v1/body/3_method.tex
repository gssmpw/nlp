\section{Method} \label{sec:method}
In this section, we first explore the placement process from the perspective of graph signal processing and highlight the importance of smoothness for chip placement.
Then we present GiFt, the parameter-free placement acceleration approach, and demonstrate its efficacy via theoretical analysis. Finally, we prove that both the classic eigenvector-based placer~\cite{eigen_placer, eigen_placer2} and recently emerged GCN-based placer~\cite{graphplanner, CY2021} are special cases of the proposed approach, while both of them introduce extra computations and complexity.


\begin{figure*}[htbp]
\includegraphics[width=\textwidth]{figure/workflow.pdf}
\centering  
\vspace{-2.5em}
\caption{The workflow of GiFt-equipped placement process.}\label{fig:workflow}
\vspace{-1.5em}
\end{figure*}

\subsection{Enhancing Placement from GSP Perspective}~\label{sec:method1}
As demonstrated in Eq.~\ref{eq:smoothness} and Eq.~\ref{eq:wire_eq}, the optimization objective in placement, which aims to minimize quadratic wirelength, aligns with the goal of enhancing graph signal smoothness from the perspective of GSP. Inspired by this finding, we reframe the placement problem as an effort to improve the smoothness of graph signals on given circuit graphs.
Next, we will explain how we can improve the smoothness of graph signals across the graph.

The normalized form of the smoothness measurement (as depicted in Eq.~\ref{eq:smoothness}) can be calculated using the Rayleigh quotient, as shown below:
\begin{equation}\label{eq:smoothness_ray}
R(g)=\frac{S(g)}{||g||_2^2}=\frac{\sum_{(v_i,v_j)\in E}w_{i,j}(g_j-g_i)^2}{\sum_{v_i \in V}g_i^2}=\frac{g^TLg}{g^Tg}.
\end{equation}
The smaller value of $R(g)$ indicates higher smoothness of graph. 
Leveraging the GFT, we can transform Eq.~\ref{eq:smoothness_ray} as follows:
\begin{equation}\label{eq:smoothness_ray2}
R(g)=\frac{g^TLg}{g^Tg}=\frac{g^TU\Lambda U^Tg}{g^TUU^Tg}=\frac{\hat{g}^T\Lambda\hat{g}}{\hat{g}^T\hat{g}}=\frac{\sum_{v_i \in V} \lambda_i\hat{g_i}^2}{\sum_{v_i \in V}\hat{g_i}^2}.
\end{equation}
It is evident from Eq.~\ref{eq:smoothness_ray2} that $R(g_i)=\lambda_i$, where $g_i$ denotes the graph signal defined on node $v_i$, and $\lambda_i$ denotes $i$-th eigenvalue of the graph Laplacian. This demonstrates that graph signals associated with lower eigenvalues (i.e., lower frequencies) exhibit a higher degree of smoothness.
Consequently, it becomes essential to filter out undesired frequencies, particularly the high-frequency components in graph signals, to enhance the smoothness of these signals, thereby obtaining optimized placement solutions.

Building on this insight, we present our \textbf{placement framework through the lens of GSP}:

Given the input graph signals $g \in \mathbb{R}^{N \times 2}$, which can represent the initial cell locations, potentially containing unwanted noises, we apply a graph filter $\mathcal{H}$ to $g$ to filter out undesired frequencies and obtain the filtered signals $g^{\prime} \in \mathbb{R}^{N \times 2}$, which represents the cell locations processed by the graph filter. The framework can be expressed as follows:
\begin{equation}\label{eq:unified_framework}
g^{\prime}=\mathcal{H}g=Udiag(h(\lambda_1),h(\lambda_2), \ldots, h(\lambda_n))U^Tg,
\end{equation}
where $h(\cdot)$ is a filter function defined on eigenvalues.
This process can be interpreted from a GSP perspective: Given a graph signal $g$, it is initially transformed from the spatial domain to the spectral domain via the GFT.  
Subsequently, unwanted frequencies within the signal are removed using the filter $h(\cdot)$, and finally, the filtered signal is transformed back into the spatial domain through the inverse GFT.


Since the smoothness of graph signals is closely linked to the minimization of placement wirelength, a straightforward approach is to develop an ideal low-pass filter that directly eliminates all high-frequency signals. This can be formulated as follows,
\begin{equation}\label{eq:ideal_filter}
h(\lambda_i)=\left\{
\begin{aligned}
 1,\ &\text{if} \ \lambda_i<\lambda_t\\
 0,\ &\text{otherwise} \\
\end{aligned}
\right.
\end{equation}
where $\lambda_t$ denotes the cut-off frequency. 
Then the filtered signals $g^{\prime}$ are given by 
\begin{equation}\label{eq:unified_framework}
g^{\prime}=\mathcal{H}g=Udiag(\overbrace{1, \ldots, 1}^t, \overbrace{0,\ldots,0}^{n-t})U^Tg=U_tU_t^Tg.
\end{equation}


Although this approach guarantees the global smoothness of graph signals, it requires eigendecomposition to obtain the eigenvectors corresponding to the first $k$ lowest eigenvalues, which is a computationally expensive task for large-scale circuits.
In addition, it is essential to note that globally smooth signals overlook valuable local information, which can be characterized as globally high-frequency yet locally smooth~\cite{LLG2023}. This oversight may lead to an over-smoothing issue, where neighboring locations become too similar, resulting in high overlap in local areas and violations of density constraints.

% In addition, it is essential to note that globally smooth signals overlooks valuable local information.
% This local information can be characterized as globally high-frequency yet locally smooth. Disregarding these signals may lead to an over-smoothing issue, meaning that neighboring locations become too similar, resulting in high overlap in local areas and violations of density constraints. 

To this end, we need to thoughtfully devise a new graph filter that is computationally efficient while considering multi-resolution smooth signals, thereby yielding optimized cell locations $g^{\prime}$ that have minimized total wirelength (representing smoothness over the graph structure) and reduced overlap (i.e., avoid over-smoothing). 


\subsection{GiFt: An Efficient Placement Speedup Technique}~\label{sec:method2}
This section introduces GiFt, a GSP-based placement acceleration approach. GiFt functions as an efficient graph filter, utilizing multi-frequency graph signals for comprehensive graph structural analysis and the generation of optimized cell locations. It can be seamlessly integrates with analytical placers to produce high-quality placement solutions while significantly reducing placement time. The GiFt-equipped placement process is depicted in Figure~\ref{fig:workflow}.
% Notably, this approach does not have time-consuming training costs associated with recently emerged deep learning-based approach, while also significantly reducing the number of iterations required by classic analytical placers.

\subsubsection{The algorithm of GiFt.}~\label{sec:gift}
This section presents the theoretical underpinnings of GiFt.
From the perspective of GSP, the normalized adjacency matrix $\tilde{A}$ of the given circuit graph corresponds to the filter function $h(\lambda)=1-\lambda$. The theoretical proof is as follows.
\begin{theorem}~\label{proof:adj_filter}
The normalized adjacency matrix $\tilde{A}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$ is a graph filter corresponding to the filter function $h(\lambda)=1-\lambda$.
\end{theorem}
 
\begin{proof}
As the eigendecomposition of the normalized graph Laplacian is given by $\tilde{L}=U\Lambda U^T=Udiag(\lambda_1,\lambda_2, \ldots, \lambda_n)U^T$, $\tilde{L}$ corresponds to the filter function $h(\lambda)=\lambda$.

Since we have $L=D-A$, then
\begin{equation}\label{eq:eq1}
\tilde{L}=D^{-\frac{1}{2}}LD^{-\frac{1}{2}}=D^{-\frac{1}{2}}(D-A)D^{-\frac{1}{2}}=I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}
\end{equation}

Let $u_i$ denote the eigenvector corresponding to the eigenvalue $\lambda_i$, and $Lu_i=\lambda_i u_i$, we have
\begin{equation}\label{eq:eq3}
Lu_i=(I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}})u_i=\lambda_i u_i.
\end{equation}
It can be transformed to 
\begin{equation}\label{eq:eq4}
D^{-\frac{1}{2}}AD^{-\frac{1}{2}}u_i=(1-\lambda_i)u_i
\end{equation}
which indicates that $\tilde{A}$ is a graph filter corresponding to the filter function $h(\lambda)=1-\lambda$, that is, 
\begin{equation}\label{eq:eq4}
\tilde{A}=U\Lambda_A U^T=Udiag(1-\lambda_1,1-\lambda_2, \ldots, 1-\lambda_n)U^T
\end{equation}
\end{proof}

\begin{figure*}[htbp]
\includegraphics[width=0.88\textwidth]{figure/fig1.pdf}
\centering  
\vspace{-0.5em}
\caption{Eigenvalue distributions of normalized Laplacians with different graph filters: (a) under different self-loops. (b) with $\tilde{A}$ filter at various $k$, (c) with augmented $\tilde{A}$ filter at various $k$.}\label{fig:tmp}
% (b) The effect of using $\tilde{A}$ for graph filtering under different $k$. (c) The effect of using augmented $\tilde{A}$ for graph filtering under different $k$.
\vspace{-1em}
\end{figure*}

Since the eigenvalues of the normalized Laplacian fall within the interval of $[0,2]$, $\tilde{A}$ acts as a band-stop filter that attenuates intermediate-frequency components, which is not effective for denoising graph signals. 

To address this problem, we introduce two enhancements to $\tilde{A}$ to boost its denoising ability.
Firstly, we add self-loops to $\tilde{A}$ (called augmented $\tilde{A}$) to shrink high-frequency components (e.g. large eigenvalues)~\cite{sgc}, thereby removing high-frequency noises.
As depicted in Figure~\ref{fig:tmp}(a), by adding self-loops as follows $A=A+\sigma I$ (where $\sigma=0, 1, 2, 3$ in Figure~\ref{fig:tmp}(a)), the large eigenvalues become smaller, leading the augmented $\tilde{A}$ to perform like a low-pass filter. 
It is important to note that if $\sigma$ is too large, most eigenvalues will approach zero, rendering the graph filter less effective in noise removal.
Secondly, we generalize the augmented $\tilde{A}$ to $\tilde{A}^k$. This modification transforms its corresponding filter function from $h(\lambda)=1-\lambda$ to $h_k(\lambda)=(1-\lambda)^k$, where $k$ controls the strength of the graph filter. Figure~\ref{fig:tmp}(b) and Figure~\ref{fig:tmp}(c) show the filter strength associated with $\tilde{A}$ and augmented $\tilde{A}$ for various values of $k$. As $k$ increases, the low-pass filtering effect of the augmented $\tilde{A}$ becomes more pronounced.
The underlying dataset for Figure~\ref{fig:tmp} is mgc\_edit\_dist\_1 benchmark in the ISPD2014 benchmark suite~\cite{ispd2014}. 
To this end, by adjusting the values of $\sigma$ and $k$, we can effectively regulate the extent to which high-frequency signals are filtered out, ultimately achieving smooth signals across multiple resolutions.

Building upon this analysis, we propose \textbf{GiFt, functioning as multi-frequency graph filters}, to generate optimized cell locations as follows, 
\begin{equation}\label{eq:proposed_filter}
g^{\prime}=GiFt(g)=\alpha_0\tilde{A}_2^2g+\alpha_1\tilde{A}_4^2g+\alpha_2\tilde{A}_4^4g.
\end{equation}
Here, $\tilde{A}_1^2$, $\tilde{A}_2^2$ and $\tilde{A}_4^3$ all function as low-pass filters with varying degrees of filtering strength, which are formulated as follows,
\begin{equation}\label{eq:A_formulation}
\begin{aligned}
    \tilde{A}_2^2=&{((D+2I)^{-\frac{1}{2}}(A+2I)(D+2I)^{-\frac{1}{2}})}^2 \\
    \tilde{A}_4^2=&{((D+4I)^{-\frac{1}{2}}(A+4I)(D+4I)^{-\frac{1}{2}})}^2 \\
    \tilde{A}_4^4=&{((D+4I)^{-\frac{1}{2}}(A+4I)(D+4I)^{-\frac{1}{2}})}^4 \\
\end{aligned}
\end{equation}
To differentiate, we refer to $\tilde{A}_2^2$ as a \emph{high-pass filter} that allows some relatively high-frequency signals to pass through to capture local information. $\tilde{A}_4^2$ corresponds to a \emph{medium-pass filter}, and $\tilde{A}_4^4$ represents a \emph{low-pass filter} designed to exclusively preserve low-frequency signals, thereby enhancing global smoothness.
$\alpha_0$, $\alpha_1$ and $\alpha_2$ are weight coefficients that determine the proportion of globally smooth signals and locally smooth signals.
$g$ symbolizes the input signals, representing the initial cell locations.
$g^{\prime}$ denotes denoised graph signals, i.e., cell locations produced by GiFt.

\subsubsection{The beneficial attributes of GiFt for placement.}
The input to GiFt is initial cell locations denoted by $g$ in Eq.~\ref{eq:proposed_filter}. We can simply set the locations of movable cells at the center of the placement region, following a Gaussian distribution $N(0,1)$, while fixed cells are placed at their predetermined locations. 
Next, we prove that GiFt can generate optimized locations that both consider the predetermined fixed locations and ensure smoothness across the graph.

% \begin{proof}~\label{proof:incremental}
% To obtain the optimized cell locations that take into account both the predetermined fixed cell locations and the smoothness over the graph, 
To achieve this goal, the optimization objective can be formulated as follows:
\begin{equation}\label{eq:incremental}
min\{||g-g^{\prime}||_{2}^{2}+tr(g^{\prime T}Lg^{\prime})\},
\end{equation}
where $g$ denotes the initial cell locations containing predetermined fixed cell locations, $g^{\prime}$ denotes the predicted cell locations, and $L$ denotes the graph Laplacian matrix. 
The first term enforces that the predicted cell locations account for the fixed cell locations, while the second term contributes to the smoothness of the graph.

By setting the derivative of Eq.~\ref{eq:incremental} to zero, we arrive at the following expression:
\begin{equation}\label{eq:derivative}
g^{\prime}=(I+L)^{-1}g
\end{equation}
Since $L$ associates with the filter function $\lambda$ as proved in Theorem~\ref{proof:adj_filter}, $(I+L)^{-1}$ can be transformed into the spectral domain. This transformation yields the graph filter:
\begin{equation}\label{eq:spectral}
h(\lambda)=(1+\lambda)^{-1}
\end{equation}
Then we approximate $h(\lambda)$ using its first-order Taylor expansion: 
\begin{equation}\label{eq:taylor}
\hat{h}(\lambda)=1-\lambda.
\end{equation}
By transforming $\hat{h}(\lambda)$ back into the spatial domain, we obtain:
\begin{equation}\label{eq:final}
\hat{h}(L)=I-L=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}=\tilde{A}.
\end{equation}
To further enhance the filtering capability, we can add self-loops $\sigma$ and a scaled coefficient $k$ into Eq.~\ref{eq:final}. 
Finally, the predicted cell locations can be obtained by
\begin{equation}\label{eq:final}
g^{\prime}=\tilde{A}_{\sigma}^kg,
\end{equation}
This forms the basis of GiFt.

To sum up, GiFt can capture smooth signals across multiple resolutions, effectively preventing over-smoothing. Simultaneously, it can take the design-specific predetermined locations of fixed cells into account. As a result, it enables comprehensive exploration of the given circuit graphs to generate optimized placement solutions.



\subsubsection{The workflow of GiFt-equipped placement process.}
Since density constraints are not rigorously enforced in Eq.~\ref{eq:proposed_filter}, the predicted solutions $g^{\prime}$ can undergo further refinement through the subsequent placer. By integrating GiFt with the analytical placer, we develop the ultra-fast placement flow GiFt-Placer. 


% \vspace{-0.5em}
\begin{algorithm}[]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \small \caption{GiFt-Placer Algorithm} \label{alg:gift_placement}
    \footnotesize
    \begin{algorithmic}[1]
        \REQUIRE A circuit netlist modeled by an undirected weighted graph $G = (V, E)$
        \ENSURE  Legalized placement result,
        % \STATE  Transform the netlist to an undirected weighted graph $G = (V, E)$ using clique net model
        \STATE Set initial locations $g$ of cells $v \in V$. Locations of movable cells $g_m \sim N(0,1)$ are placed at the center of the placement region. Fixed cells are set at their predetermined locations.
        \STATE Compute optimized cell locations $g^{\prime}$ using GiFt: $g^{\prime}=\alpha_0\tilde{A}_2^2g+\alpha_1\tilde{A}_4^2g+\alpha_2\tilde{A}_4^4g$
        \STATE Input $g^{\prime}$ to subsequent placer to complete placement task
        \STATE \textbf{return} The legalized placement result
    \end{algorithmic}
\end{algorithm}
% \vspace{-0.5em}


The algorithm of GiFt-Placer is summarized in Alg.~\ref{alg:gift_placement}.
Given a circuit netlist, we use clique net model~\cite{clique} to convert it into a weighted graph $G$. The graph is then processed by GiFt to generate optimized cell locations $g^{\prime}$ (Line 1-2). $g^{\prime}$ is then fed into the analytical placer, serving as the starting point for placement optimization, to complete the placement task with substantially reduced iteration time (Line 3-4).

Next, we elaborate on the power of GiFt as follows.

\textbf{Reduced Iteration Count. }
As GiFt can capture comprehensive graph structures from globally smooth signals to locally smooth ones, it can produce optimized cell locations with reduced overlap. By integrating the predicted locations with analytical placers, the placement process benefits from significantly reduced iterations, as the locations predicted by GiFt provide clear and valuable guidance for the subsequent optimization process.

\textbf{Low Computation Complexity.}
GiFt excels in efficiency through sparse matrix multiplication. Its calculation only involves the normalization of the adjacency matrix, eliminating the need for the time-consuming parameter learning process with back-propagation. Consequently, its computation complexity is $O(e)$, where $e$ represents the number of edges.



% In summary, GF-Placer achieves high-quality placement without incurring training costs, as seen in deep-learning based placers, or the long iterations required by classic optimization-based placers.


\subsection{Analyzing Existing Placers from GSP Perspective}~\label{sec:method3}
This section analyzes the classic eigenvector-based placer and recently emerged GCN-based placer from the GSP perspective. It is proved that both of them are special cases of the proposed approach with different graph filters.


\subsubsection{Eigenvector-based Placer}
The classic eigenvector-based placer~\cite{eigen_placer} assumes that all cells are movable. They use the eigenvectors corresponding to the second and third smallest eigenvalues as cell locations.
From the GSP perspective, it is an ideal low-pass filter that only saves the lowest frequencies. The corresponding filter function can be defined as 

\begin{equation}\label{eq:ideal_filter}
h(\lambda_i)=\left\{
\begin{aligned}
 1,\ &\text{if} \ 1<i <=3\\
 0,\ &\text{otherwise} \\
\end{aligned}
\right.
\end{equation}
As eigenvectors (graph signals in the spectrum domain) are directly employed to represent cell locations, there is no need to transform them into the spatial domain using inverse GFT $U$.
Therefore, the filtered signal can be calculated by 
\begin{equation}
g^{\prime}=diag(0, 1, 1, 0, \ldots, 0)U=[u_2, u_3]
\end{equation}

Although this method achieves signal smoothness, it incurs high computational costs when applied to large-scale circuits due to the necessity of eigendecomposition. Moreover, as demonstrated in Section~\ref{sec:method1}, confining graph signals to merely the lowest-frequency components leads to the loss of valuable information present in higher-frequency components, yielding suboptimal solutions.


\subsubsection{GCN-based Placer}
To enhance the placement process, many recent studies have recruited GCNs~\cite{graphplanner, CY2021} for help. These studies apply GCNs to encode connectivity information and generate node embeddings for subsequent calculations.
Node embeddings (denoted as $g^{\prime}$) are computed through GCNs using the formula $g^{\prime}=\mathcal{F}(D^{-\frac{1}{2}}AD^{-\frac{1}{2}}XW)$, where $\mathcal{F}$ denotes the activation function, and the kernel is the normalized adjacency matrix $\tilde{A}$.
As proved in Theorem~\ref{proof:adj_filter}, $\tilde{A}$ corresponds to the filter function $h(\lambda)=1-\lambda$, which can be considered a special case of GiFt.

However, GCNs introduce the learnable parameter $W$, which requires a time-consuming training process via back-propagation. This training overhead is redundant for efficient chip placement. The underlying reason is that the statistical characteristics of graph structures can vary significantly across different circuit designs, and the presence of fixed cells (e.g., fixed IOs) exacerbates this issue. Consequently, it is challenging to train a set of fixed parameters that would be effective across a range of diverse designs.
On the other hand, by carefully designing the graph filter, it can efficiently remove high-frequency noises and produce optimized cell locations based on multi-resolution smooth signals. As demonstrated in Table~\ref{tab:placement_result}, our proposed approach without the need for model training, achieves competitive or superior performance compared to GCNs, providing further evidence in support of our assertion.
