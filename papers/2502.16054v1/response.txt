\section{Related Work}
Cybersecurity research increasingly employs advanced computational models to address the growing complexity of cyber threats, particularly APTs in cloud environments. Modern SOCs integrate machine learning (ML), automated threat-hunting, and Security Information and Event Management (SIEM) tools to detect and mitigate threats in real-time**Nguyen et al., "A Survey on Deep Reinforcement Learning for Cybersecurity"**. However, challenges such as alert fatigue, vendor dependencies, compliance issues, and the increasing sophistication of AI-driven adversaries necessitate more intelligent, proactive security frameworks.

Recent studies highlight the importance of human-AI collaboration in SOC operations, where AI-powered decision-support systems complement human analysts in managing cyber threats efficiently**Chetouane et al., "Human-in-the-Loop Reinforcement Learning for Cybersecurity"**. This has led to the exploration of Deep Reinforcement Learning (DRL) for adaptive defense, AGs for attack pathway visualization, CHT for adversarial reasoning, and HITL strategies for SOC decision-making. This section reviews key research in these areas, positioning our CHT-driven DRL framework within the existing cybersecurity landscape.

\subsection{Deep Reinforcement Learning for SOCs and APT Defense}
Deep Reinforcement Learning (DRL) has emerged as a powerful approach for cyber threat detection and mitigation in SOCs. DRL enables adaptive defense strategies, where an AI agent continuously learns from adversarial interactions to improve its decision-making.
The survey by **Nguyen et al., "A Survey on Deep Reinforcement Learning for Cybersecurity"** explores DRL’s applicability to cyber-physical systems, intrusion detection, and multi-agent security frameworks, discussing various DRL approaches such as value-based methods (DQN), policy gradients, and actor-critic frameworks. Other studies apply DRL to real-time cloud security, demonstrating its potential for resource allocation and adaptive defense against APTs**Wang et al., "Adversarial Deep Reinforcement Learning for Cloud Security"**. Beyond cybersecurity, DRL has also been explored for optimizing design verification workflows, where RL enables efficient test generation and automated verification of complex hardware and software systems**Rastogi et al., "Deep Reinforcement Learning for Design Verification Workflows"**. These applications highlight DRL’s versatility in optimizing decision-making under uncertainty, reinforcing its suitability for adaptive cyber defense.
More specific to cloud-based SOCs, the work in**Zhang et al., "Distributed Deep Reinforcement Learning for Cloud Storage Security"** introduces a DRL-based CPU allocation model for cloud storage defense, using a Colonel Blotto game framework to counter APT attacks. While effective in storage optimization, it does not consider broader threat adaptation across SOC environments.

Additionally, **Chhetri et al., "Risk-Aware AI for Cloud Cost Optimization"** propose a risk-aware AI model for cloud cost optimization, incorporating dynamic threat assessment mechanisms to manage cloud security risks effectively. This aligns with our work, which enhances SOC defenses by integrating CHT with DRL to model adversarial reasoning and proactive threat mitigation in cloud infrastructures.

\subsection{Attack Graphs in Cybersecurity and Cloud Defense}
AGs can play a crucial role in SOC threat modeling, helping analysts visualize, analyze, and predict the movement of adversaries within cloud infrastructures. AGs provide a structured representation of cyber threats, allowing security teams to prioritize vulnerabilities and allocate resources strategically**Sheyner et al., "Automated Attack Graph Generation for Network Vulnerability Analysis"**.
Several studies explore AG-based threat intelligence. For example, **Wu et al., "Attack Graph Evaluation for Power Communication Networks"** automate AG generation for network vulnerability analysis, while **Sengupta et al., "Markov Game Framework for APT Detection in Cloud Networks"** use AGs to evaluate power communication networks, prioritizing risks based on security metrics. Additionally, **Schmidt et al., "Distributed SOC Architectures with Attack Graph-Based Threat Modeling"** propose an AG-driven Markov game framework for APT detection in cloud networks, leveraging Common Vulnerability Scoring System (CVSS) metrics for dynamic threat modeling.
In multi-cloud landscapes, the work in**Kim et al., "Multi-Cloud Security Architecture with Attack Graph-Based Threat Intelligence"** investigates distributed SOC architectures, emphasizing AG-based threat modeling and adaptive defense planning. However, existing AG-based models focus primarily on reactive threat detection rather than proactive, AI-driven defense mechanisms. Our framework extends AG applications by integrating them with CHT and DRL, enabling real-time SOC decision-making against evolving APTs.

\subsection{Cognitive Models in Cyber Defense}
CHT and behavioral game theory have gained traction in cybersecurity research, providing insights into human-like decision-making in adversarial settings**Aref et al., "Prospect Theory for Defender Decision-Making in Cloud Environments"**. Unlike traditional Nash equilibrium-based models, which assume perfect rationality, CHT recognizes that attackers and defenders operate at different levels of cognitive reasoning, leading to non-equilibrium decision patterns.

In cloud security, the work in**Xiao et al., "APT Detection Game with Cumulative Prospect Theory"** applies Prospect Theory to model defender decision-making, demonstrating that subjective risk perception can enhance defense strategies in resource-constrained cloud environments. Similarly, **Mavridis et al., "Level-k Reasoning for APT Behavior Prediction"** formulate an APT detection game, showing that attackers exhibit risk-seeking behaviors when facing aggressive defense mechanisms.
CHT is also applied in cyber-physical security, where the study by**Sanjab et al., "Cumulative Prospect Theory for UAV Cybersecurity"** uses cumulative Prospect Theory to capture adversarial risk dynamics.

Our research builds upon these models by integrating CHT with DRL in a cloud SOC framework, allowing SOC analysts to predict APT strategies and dynamically adjust defenses based on multi-level adversarial cognition.

\subsection{Human-AI Collaboration and Human-in-the-Loop SOCs}
Human-AI collaboration (HITL) is essential for enhancing SOC efficiency, as AI-driven automation alone cannot fully replace human expertise in cybersecurity operations. AI models must align with human cognitive processes to improve SOC decision-making, reduce false positives, and enhance analyst interpretability**Chetouane et al., "Human-in-the-Loop Reinforcement Learning for Cybersecurity"**.
Several studies highlight HITL in SOCs. **Chhetri et al., "AI-Driven Alert Prioritization System for SOC Analysts"** propose an AI-driven alert prioritization system to reduce cognitive overload in SOC analysts, improving threat response efficiency. Furthermore, **Tariq et al., "Modular AI-Human Decision Framework for SOC Workflow Optimization"** introduce a modular AI-human decision framework that optimizes SOC workflow automation while ensuring human oversight in high-risk decision-making.

Explainable AI (XAI) is another key area in human-AI collaboration. A recent study explores how explainable reinforcement learning models improve SOC analyst trust and decision accuracy in real-time security operations**Zhang et al., "Explainable Reinforcement Learning for SOC Decision Support"**. Collaborative AI learning frameworks, such as the survey by **Kim et al., "Collaborative AI Learning Frameworks for Cybersecurity Applications"**, further emphasize the role of human-AI teaming in security environments.
By integrating HITL with our CHT-DQN model, we enable SOC analysts to interact with AI-driven security tools in real time, leveraging human cognitive intuition alongside machine-learning automation for adaptive cloud defense strategies.