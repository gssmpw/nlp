%%
%% This is file `sample-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx (with options: `authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.

%% Document format
\documentclass[sigconf]{acmart}


% Puts line numbers on the left of each line
% \usepackage{lineno}
% \linenumbers
% \renewcommand\linenumberfont{\normalfont\footnotesize\color{red}}
% % Set line numbers to appear on the left side only
% \setlength{\linenumbersep}{1cm}

\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


% Rights management information.
\copyrightyear{2025}
\acmYear{2025}
\setcopyright{acmcopyright}
\acmConference[CHI '25 Workshop on Tools for Thought]{CHI Conference on Human Factors in Computing Systems}{April 26-May 1, 2025}{Yokohama, Japan}
\acmBooktitle{CHI Conference on Human Factors in Computing Systems (CHI '25), April 26-May 1, 2025, Yokohama, Japan}
% \acmDOI{0000000.0000000}
\acmISBN{978-1-4503-XXXX-X/18/06}



% Submission ID.
% \acmSubmissionID{123-A56-BU3}


% Switches to the "author year" style for citations and references.
% \citestyle{acmauthoryear}

\usepackage{lipsum}
\usepackage{subcaption}
\usepackage{macros}
\usepackage{float}
\usepackage{wrapfig}

\newcommand{\changed}[1]{\textcolor{black}{#1}}

\newcommand{\etal}{et al.}
\newcommand{\subsubsubsection}[1]{\paragraph{\textbf{#1}}}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}


% \title[Feedforward Prompting]{Exploring how to show users what's ahead of the LLM response with Feedforward Prompting}
% Exploring how to show users what to expect from LLM outputs
% \title[Feedforward Prompting]{Feedforward Prompting: Can the interface help users know what to expect from LLM outputs?}
% \title[Feedforward in GenAI]{Feedforward in GenAI Interaction: Opportunities and Challenges}
% \title[Feedforward in GenAI]{Feedforward in GenAI Interaction: Exploring Opportunities for a Design Space}
% \title[Feedforward in GenAI]{The Need for Feedforward in GenAI Interaction: Exploring Opportunities for a Design Space}
% \title[Feedforward in Generative AI]{Feedforward as the Medium for Human-AI Communication}
% \title[Feedforward in Generative AI]{Feedforward as a Shared Abstraction for Human-AI Intent Communication}
% \title[Feedforward for Generative AI]{The Feedforward Challenge of Generative AI}
% \title[Feedforward for Generative AI]{Feedforward for Generative AI: Exploring Opportunities for a Design Space}
% \title[Feedforward for Generative AI]{Feedforward in Generative AI: Toward a Defined Design Space}
% \title[Feedforward for Generative AI]{Feedforward in Generative AI: Opportunities for a Design Space}
\title{Feedforward in Generative AI: Opportunities for a Design Space}



%%
\author{Bryan Min}
\email{bdmin@ucsd.edu}
\affiliation{%
  \institution{University of California San Diego}
  \streetaddress{9500 Gilman Dr}
  \city{La Jolla}
  \state{California}
  \country{USA}
  \postcode{92093}
}

\author{Haijun Xia}
\email{haijunxia@ucsd.edu}
\affiliation{%
  \institution{University of California San Diego}
  \streetaddress{9500 Gilman Dr}
  \city{La Jolla}
  \state{California}
  \country{USA}
  \postcode{92093}
}

%%
\renewcommand{\shortauthors}{Min et al.}

%%
% Abstract.
\begin{abstract}
% GenAI is very capable and is being integrated into many diverse systems
% However, a fundamental challenge in GenAI interaction is that it's difficult to anticipate what AI will actually generate, respond with, and do.
% This is because of feedback leads to ...
% Therefore, this paper aims to advance the perspective that feedforward is important, not just feedback.
% This perspective to advance is to reach a design space, figure out ways to make feedforward effective and se how it can be designed and stuff.
% In order to advnace this investigation, we explored the design of four prototype systems that implement feedforward in GenAI---X, X, X, and X.
% This paper aims to spark discussion on how we can advance this perspective.
% We invite researchers....
% 

% Although research has developed approaches for providing effective feedback and facilitating a high quality experimenting experience to help users gain more experience with GenAI systems, these approaches focus on providing users with feedback, which requires users to see what GenAI produces from their prompt after submitting their prompt.
% While feedback helps users develop an understanding of the GenAI system through exploration and experience, users cannot always anticipate the outcome of their prompts and must rely on iterative trial-and-error. 

% Generative AI (GenAI) models are more than capable than ever at augmenting productivity and cognition in a diverse range of contexts. However, a fundamental challenge is that it is difficult to anticipate exactly what AI will generate.
% As a result, users must repeatedly exchange messages with AI to concretely clarify their intents.
% This process can incur significant cognitive load and time investment, especially for heavy tasks such as generating software interfaces on the fly or automating web tasks with agents.
% If we want users to easily leverage the potential of GenAI systems across diverse contexts seamlessly, they must be able to anticipate AI outputs without learning from feedback, and instead look ahead at what AI will generate.
% This paper aims to advance the perspective that GenAI must not only provide informative feedback, but also informative feedforward in GenAI.
% In other words, we must design GenAI systems that will tell users what the AI will generate before the user submits their prompt.
% To spark the discussion of feedforward in GenAI, we designed diverse instantiations of feedforward in four different GenAI applications---conversational UIs, document editors, malleable interfaces, and automation agents. We discuss how these design explorations can lead to a rigorous investigation of a design space for feedforward in GenAI as well as design guidelines that can be applied to all forms of GenAI applications.

% Instead, they should be able to look ahead and understand what the AI will generate before submitting their prompts.

% Generative AI (GenAI) models have become more capable than ever at augmenting productivity and cognition across diverse contexts.
% However, a fundamental challenge remains for users in that it is difficult to anticipate what AI will generate.
% As a result, users must repeatedly exchange messages with AI to clarify their intent concretely, incurring significant cognitive load and time investment.
% In order for users to seamlessly leverage the full potential of GenAI systems across various contexts, they must be able to anticipate AI outputs without relying solely on feedback.

Generative AI (GenAI) models have become more capable than ever at augmenting productivity and cognition across diverse contexts. However, a fundamental challenge remains as users struggle to anticipate what AI will generate. As a result, they must engage in excessive turn-taking with the AI's feedback to clarify their intent, leading to significant cognitive load and time investment. Our goal is to advance the perspective that in order for users to seamlessly leverage the full potential of GenAI systems across various contexts, we must design GenAI systems that not only provide informative feedback but also informative feedforwardâ€”designs that tell users what AI will generate before the user submits their prompt. To spark discussion on feedforward in GenAI, we designed diverse instantiations of feedforward across four GenAI applications: conversational UIs, document editors, malleable interfaces, and agent automations, and discussed how these designs can contribute to a more rigorous investigation of a design space and a set of guidelines for feedforward in all GenAI systems.

% We discuss how these design implementations can contribute to a rigorous investigation of the design space for feedforward in GenAI and design guidelines applicable across diverse GenAI applications.



% these AI models are challenging to properly prompt for most users.
% Although systems have focused on mitigating these challenges through a variety of solutions/approaches of providing feedback, users must learn this feedback like newcomers for each new generative AI system.
% In addition to feedback, we argue that we must also provide informative feedforward to users. Feedforward will enable newcomers of any generative AI system to be able to anticipate what it will generate, thus helping them prompt more efficiently and reduce frictions and intention-gaps.
% This workshop paper aims to spark discussion on how we can design and implement feedforward for generative AI, and we showcase a few methods for understanding this design space.

\end{abstract}

%%
% ACM Computing Classification System.
% http://dl.acm.org/ccs.cfm
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003120.10003121.10003124</concept_id>
       <concept_desc>Human-centered computing~Interaction paradigms</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003120.10003121.10003126</concept_id>
       <concept_desc>Human-centered computing~HCI theory, concepts and models</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Human-centered computing~Interaction paradigms}
\ccsdesc[500]{Human-centered computing~HCI theory, concepts and models}

%%
% Keywords.
\keywords{Feedforward, Human-AI Interaction, Generative AI}

%%
% \begin{teaserfigure}
%     \includegraphics[trim=0cm 0cm 0cm 0cm, clip=true, width=\textwidth]{figures/teaser.png}
%     \caption{(A) We perform a content analysis of overview-detail interfaces (blue: overview; orange: detail view) to understand its variations in the wild, finding three key dimensions: \textit{content}, \textit{composition}, and \textit{layout}. (B) Based on these dimensions, we provide interactions for end-users to customize the overview-detail interface. Among them, we contribute a novel technique, \textit{Fluid Attributes}, enabling users to (C) surface attributes to the overview that only exist in the detail view and (D) operate on attributes they surface.}
%     \label{fig:teaser}
%     \Description{The figure depicts four images that encompass the primary contributions of this paper. The first image depicts three variations of overview-detail interfaces from our content analysis - highlighting key dimensions of content, compositions, and layout. The second image is taken from our design probe, showing the various interactions for end-users to customize the overview-detail interface to match their own needs and preferences. Among these interactions, we contribute a novel technique, Fluid Attributes, shown in the third and fourth images, enabling users to directly interact with and manipulate content attributes between the overview and the detail view. The third image shows, a user selecting attributes to be surfaced in the overview while the fourth image shows a user sorting the overview via a selected attribute.}
% \end{teaserfigure}


%%
\maketitle{}

%%
\input{sections/1_introduction}
% \input{sections/2_critique}
\input{sections/3_feedforward}
\input{sections/4_discussion}
% \input{sections/99_conclusion}

%%
% Acknowledgments.
% \begin{acks}
% Thanks to the anonymous reviewers for their helpful comments.
% \end{acks}

%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{main}

\appendix
\input{sections/999_appendix}

\end{document}
