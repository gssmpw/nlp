\section{Feedforward in Generative AI}
\label{section:feedforward}


This section aims to explore possible ways to provide feedforward in generative AI systems. We view that effective feedforward in generative AI interfaces should enable users to:
\begin{itemize}
    \item Anticipate what the AI's response or action may be.
    \item Disambiguate their prompt without excessive exchanges in conversation or interaction.
    \item Directly engage with the feedforward content.
    \item  Reflect on their prompting practices with less friction.
\end{itemize}

To explore various ways to design feedforward in GenAI systems, we first explore feedforward in an LLM-powered conversational interface. We then describe scenarios for three other designs of feedforward in GenAI applications.


\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figures/applications.pdf}
    \caption{We explored three different applications for designing feedforward in GenAI systems: (A) document editors, (B) malleable interfaces, and (C) agent automation systems.}
    \label{fig:applications}
    \vspace{6pt}
\end{figure*}


\subsection{Feedforward in Conversational LLM UIs}

\subsubsection{Feedforward Components}

Research has shown that users benefit from multiple representations when interacting with LLMs \cite{graphologue, sensecape}.
Therefore, we developed feedforward components that each aim to provide a specific representation that would help users anticipate the LLM's response. 
As the user types a prompt, the conversational UI generates feedforward content inside two feedforward components: 1) a key topic phrase alongside a high-level outline of the anticipated response (Fig. \ref{fig:feedforward-components}.1a) and 2) a minimap view with paragraph blocks (Fig. \ref{fig:feedforward-components}.1b). These representations help users anticipate the topics and subtopics the LLM will generate, as well as whether its response might be too short or too long.

%  to help users anticipate what kinds of topics and subtopics the LLM will share 
% of the anticipated length of the response to help users know whether the LLM will generate a short snippet of text or a detailed explanation about a topic


\subsubsection{Manipulating Feedforward Content}

We enable users to manipulate feedforward content in two ways.
First, when users edit their prompt, the feedforward content updates to reflect the changes.
This allows users to identify misalignments between their intent and the feedforward content, encouraging them to add details to the prompt before submitting it.
For instance, they can clarify an ambiguous term (Fig. \ref{fig:feedforward-components}.2) or request a shorter response (Fig. \ref{fig:feedforward-components}.3).
These instant updates to the feedforward components may also spark reflection, such as realizing that it may be useful to understand the advantages and limitations of Wizard of Oz Prototyping rather than just its definition.
% Nevertheless, feedforward components give users the anticipatory insights and granular control over what information they will receive from the LLM.


% In addition to revising their prompt to adjust the feedforward content, 
Second, users can directly edit content inside the feedforward components. For example, rather than prompting the LLM to remove subtopics from the outline, users can directly delete the subtopic title in the outline component or delete the paragraph in the minimap (Fig. \ref{fig:feedforward-manipulation}A). Users can also drag the edge of the minimap component to expand the feedforward content's level of details (Fig. \ref{fig:feedforward-manipulation}B). This can allow users control ``how far ahead'' they can look into the LLM's response. Additionally, users can highlight parts of the outline, revealing a tooltip that generates a list of possible actions and outputs based on that selection, such as adding examples about a subtopic or organizing the content in a bullet-point list. Users can either select one of these actions or request their own, which will update the feedforward outline (Fig. \ref{fig:feedforward-manipulation}C).


\subsection{Application Scenarios}

Our goal is to explore opportunities for designing feedforward in all GenAI interfaces---beyond conversational UIs.
% This can include video creation platforms, programming tools, and more.
In this paper, we explore three applications to showcase various feedforward designs across diverse contexts: document editors, malleable interfaces, and agent automations.


\subsubsection{Document Editors}

Developers and researchers have begun to integrate AI into document editors and writing canvases to support various aspects of writing tasks, such as fixing grammar \cite{laban2024inksync}, presenting continuously synchronized outlines \cite{dang2022beyondtextgen}, and providing widgets to adjust the tone of writing along various dimensions \cite{masson2024textoshop, chatgptcanvas2025}.
However, it can be difficult for users to anticipate what the LLM might produce based on their writing and revisions. For instance, moving a slider up to change the tone from ``informal'' to ``formal'' does not indicate exactly how ``formal'' they are making their writing. It is only after submitting the change and reviewing the final result that users realize whether they have achieved the desired outcome. To reduce the amount trial-and-error to achieve the desired result, document editors can provide feedforward that presents example phrases as the user moves the slider up and down, helping the user quickly develop a clear understanding of the level of formality they are adjusting to (Fig. \ref{fig:applications}A). This feedforward mechanism can be expanded to let users control how much detail is shown in each example phrase, allowing them to reveal more or fewer words as needed. This customization helps align the feedforward component with user preferences, reducing cognitive load.
% Additionally, users may have the option to increase the level of detail in the feedforward content, revealing the full sentences from which the phrases are derived.


% it's hard to anticipate what these changes might be, and where they might edit your writing. results in users having to repeatedly switch between writing and revising with AI.
% Feedforward in AI writing tools can support this process by helping users anticipate what and where AI will modify their writing.
% For instance, instead of making a full complete change/rewritten snippet, can instead provide feedforward through example phrases, if user slides to write more formal, then it will show example phrases that represent that level of formality. (Fig. X)
% Other instance is where you edit. it's going to change where the edit is made before you accept the change...

% If you have a slider for tone changes, or a spectrum of tone changes, instead of saying more X or less X, feedforward can provide concrete example phrases it will use.

% Also, requesting and explicit changes will prompt AI to provide feedforward of which paragraphs it will look at. Increasing the level of detail will highlight which sentences, which phrases, and even potentially what AI will replace the content with.


\subsubsection{Malleable Interfaces}

GenAI is additionally enabling software interfaces to become increasingly malleable, enabling users to generate custom functional applications on the fly \cite{litt2025workout, onetwoval2025calculator}, personalized interfaces that blends user activity \cite{cao2025jelly}, and user-defined abstractions in overview-detail interfaces \cite{malleableODI}.
In current generated malleable interfaces, the user prompts for a custom application and provides specifications, and after rounds of clarifying, AI generates and compiles the requested application. However, it can be unclear what kinds of software components the AI might produce based on their prompts alone. For example, if the user asks AI to show only linen-textured couches from a shopping website, the user cannot be sure whether AI will add a filtering operation, perform another search query, or create a brand new list linen-textured couches. Feedforward can present a list of system operations the AI will perform before submitting the prompt, allowing them to quickly assess and revise the operations without unnecessary exchanges with the AI (Fig. \ref{fig:applications}B).

% Ask for generating interface. before you submit your prompt, you get a wireframe? You get attributes about what kind of interface it will generate? You get

% Brief context of overview-detail interfaces
% Asking for details about certain items, Asking for an attribute at a high level. Will it surface attributes? will it generate a new one? Will it combine several attributes?

% What kinds of data will the AI focus on looking at? Will AI look at a set of attributes among all of the data provided? If so, which ones?


\subsubsection{Agent Automations}
% Being able to control the "speed" of generating content, which would be controlling the "depth of thought" on how much the model should break down the task.

The AI community has also presented demonstrations of AI agents that can automate diverse tasks on the web \cite{operator2025, dia2025}. However, there lacks clear communication of exactly what the agent is doing on the screen. For instance, if a user asks an AI agent to look for tickets to a basketball game, the agent will break the task into steps and perform them by opening and navigating a webpage. During this phase, the user may be unaware of which buttons or components the agent plans to click to find the best prices, which portions of the webpage it will scan for context, or where it will navigate next. Agent automation systems can integrate feedforward visualizations by providing area selections to show where the AI agent is focusing on for context and opaque cursors to tell the user where the agent will click next (Fig. \ref{fig:applications}C). These feedforward representations help users anticipate the agent’s future actions and provide visual affordances to intervene in potential errors by adjusting the selection area or dragging the cursor.

% Users can anticipate what an AI agent will do before they perform the task. Chain-of-thought and surrounding implementations instantiate feedforward by visualizing stages of actions the agent plans to perform. During each step, users can then stop and adjust stage by stage, providing steerability.

% AI agents should also present feedforward for various actions they aim to perform before submitting the prompt. For instance, users should see depth of thought AI aims to use from that prompt, which then users can then manually adjust.

% During automation tasks, agents currently show an AI-controlled cursor indicating clicks AI aims to perform. We view that this form of communication can be extended to all forms of selection. AI can place shaded rectangles over areas they are currently taking in as context. AI provides feedforward before performing the action. Because of this, the user is able to confirm that is the action the user wants AI to perform, and if it isn't can adjust the selection to steer AI to use the correct selection.



% \subsection{Implementing Feedforward}

% We should also investigate what is the best way to implement feedofrward.
% We implemented such that the feedforward is generated live, then the feedforward feeds into the context for the real content to generate as a skeleton.


% Preliminary Design Space for Feedforward in Generative AI systems
% Representations
% Levels of Detail
% Prompt Revision and Redirection Mechanisms
% 


% , or reflecting on the minimap feedforward component's information  that they must explicitly ask for ``just the definition'' if they want a shorter response.

% The outline will produce feedforward about content, but for the length of the expected response, feedforward will represent as a box to visualize the length in size.

% \subsubsection{Adjusting the Levels of Feedforward Detail}


% As you type your prompt to an LLM, you will see a short outline of text that preview what the LLM will output. This gives you an idea of what you can anticipate given your prompt. As you adjust your prompt, the preview also updates, allowing you to closer align your prompt to your desired outcome.

% Problem chatgpt, ask a question, don't know what it will respond with. Especially can't gauge if your prompt is ambiguous or concrete enough.
% Sending, responds different topic, or generate too much
% Result is you need to submit your prompt again, tuning it, might miss another aspect, or the prompt might not go in your favor again
% gets repetitive
% Instead feedforward in convo LLMs can provide previews of what might happen.


% Feedforward components do not only serve the purpose of providing information before submitting a prompt, but also enables users to interact with the content inside directly. 

% Users can adjust a slider that would adjust the levels of detail the feedforward content will provide. Users can move this slider to control how far ahead they see into what might be generated as they construct their prompt and also look further ahead into what their prompt might lead to.

% As the user slides to view more details, it adjusts all aspects of information of the feedforward content. For instance, text headers and outlines will expand to show subheaders and more details in the outline, while a label ``table'', previewing that the LLM's response will generate a table, will present a low fidelity table. Upon increasing the level of detail more the table will populate with more details as its column and row titles and text inside the cells.

% You can slide to adjust the levels of detail the feedforward will output. for instance, if anticipated to provide a table, the highest level could be the word "table", then describe number of columns and rows + visualize that table in the feedforward space, then populate content in that table little by little, until you go to the end and it ultimately becomes the fully generated response

% You can interact with feedforward content directly. You can select any content in the feedforward content, ask to expand on it, expanding on that level of detail. Selecting on content will also automatically generate recommended prompts for actions to perform, such as if you select the header ``Examples'' a dropdown menu will generate prompts such as ``Remove this header'', ``More details on examples'', and ``Replace with Application Scenarios''.


% Users can ... 
% When incorporating the slider to adjust the level of detail alongside manipulating the feedforward content, users can for instance select a table preview, increase or reduce the level of detail of that table specifically. If the user feels the table does not represent the contained information adequately, they can hold shift while reducing the level of detail to the term ``table''. Upon changing ``table'' to ``two columns'', the feedforward content updates to provide a preview of the two columns arrangement of the information.

% You can interact with any feedforward representation.

% You can also interact with the feedforward content at any level of detail. For instance, you can grow more detailed, and if you don't like where it's going, you can slide back, adjust some content, and see what that would generate.
% Maybe when you choose to go back and then change, you will see a feedforward of the feedforward, showing what that adjustment you made might look like.

% \begin{figure*}
%     \centering
%     \includegraphics[width=1\linewidth]{figures/feedforward-workflow.png}
%     \caption{Enter Caption}
%     \label{fig:enter-label}
% \end{figure*}
