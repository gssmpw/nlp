\section{Introduction}
\label{section:introduction}



\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figures/components.pdf}
    \caption{(1) When the user stops typing for a brief moment, the conversational UI presents two feedforward components: (a) a list of key topics and an outline, and (b) a visual minimap of the anticipated length of the response. (2) The user anticipates what the LLM will generate and adjusts their prompt to match it. (3) They also ask for less information, in which the feedforward components update to match the request.}
    \label{fig:feedforward-components}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{figures/manipulation.pdf}
    \caption{Users can directly interact and manipulate feedforward components by for instance (A) deleting unneeded paragraphs, (B) expanding details about a section, and (C) transforming the representation of the expected content.}
    \label{fig:feedforward-manipulation}
\end{figure*}


Generative AI (GenAI) models are capable of generating a diverse range of content including stories, videos, code, and more. HCI communities have integrated these models into a diverse range of applications to augment learning and teaching \cite{sensecape, jin2024teachAI}, support academic literature review \cite{elicit2024, kang2023synergi, fok2024qlarify, paperweaver}, generate and customize software on the fly \cite{stylette, cao2025jelly, malleableODI, priyan2024dynavis}, and automate web tasks \cite{operator2025, feng2025cocoa}, showcasing their potential to enhance productivity and cognition on a universal scale.

Despite its potential, users inevitably face challenges in trying to anticipate GenAI's responses and aligning their prompts to match their needs.
Subramonyam \etal{} have labeled this set of challenges as the \textit{gulf of envisioning}, which describes the user's gap in identifying and articulating their desired task, providing effective instructions, and anticipating the model’s response \cite{hari2024gulfenvisioning}.
This gap makes it difficult for novices to formulate effective prompts to AI and understand the cause of misalignment \cite{zamfirescu2023johnnyprompt}.

While researchers have explored various approaches to help users better learn and anticipate AI's responses with dedicated spaces for experimenting with prompts \cite{arawjo2024chainforge, angert2023spellburst}, generating multiple outputs in a single space \cite{luminate, gero2024llmsensemakingscale}, asking clarifying questions \cite{deepresearch2025}, and providing widgets to modify generated outputs post-hoc \cite{priyan2024dynavis, masson2024directGPT, graphologue}, these systems primarily focus on offering \textit{feedback}—helping users understand what happened \textit{after} they submit a prompt.
While feedback helps users develop an understanding of the system through exploration, users cannot always anticipate the outcome of their prompts.
Instead, they must rely on iterative trial-and-error, which can incur significant cognitive load and time investment.
If we want users to easily leverage the potential of GenAI systems across diverse contexts, they must be able to anticipate AI outputs without solely relying on feedback.
% , and instead tune their response in faster increments.

To achieve this, we aim to advance the perspective that GenAI must not only provide informative feedback but also informative \textit{feedforward}---designs that help users anticipate outcomes \textit{before} performing an action \cite{vermeulen2013feedforward}.
Providing such feedforward in GenAI systems can help users understand what to expect from the AI model before submitting their prompt.
This can reduce excessive conversational exchanges, bridge the abstraction gap between users and AI \cite{liu2023groundedabstraction, hari2024gulfenvisioning, priyan2024imaginingafuture}, and encourage meta-cognition when constructing prompts \cite{tankelevitch2024metacogAI}.

The HCI community has extensively explored feedforward design in various domains, such as gestures \cite{bau2008octopocus}, VR/AR \cite{muresan2023feedforwardVR}, widgets \cite{coppers2019fortunettes, terry2002sideviews}, and proactive systems \cite{allen1999mixedinitiative}.
Furthermore, the community has begun exploring feedforward designs for GenAI, examining trade-offs between the level of detail provided and the cognitive load involved in assessing generated code and images \cite{zhutian2024sketchgenerate, dang2022ganslider}.
However, GenAI's expanding capabilities are shaping an increasingly broad design space of GenAI interfaces.
This rapid growth calls for a more systematic approach to designing effective feedforward across diverse domains---uncovering opportunities for novel interaction techniques, assessing user benefits and challenges across design dimensions, and establishing comprehensive design guidelines.

% However, GenAI's capabilities are influencing an increasingly larger design space of GenAI interfaces.
% This rapid growth necessitates a more systematic approach to designing effective feedforward across diverse domains, uncovering opportunities for novel interaction techniques, assessing user benefits and challenges across design dimensions, and establishing comprehensive design guidelines.

% Our investigation of feedforward in HCI is already rich, exploring designs in gestures \cite{bau2008octopocus}, VR/AR \cite{muresan2023feedforwardVR}, widgets and commands \cite{coppers2019fortunettes, terry2002sideviews}, proactive AI systems \cite{allen1999mixedinitiative}, and more.
% Furthermore, the community has also begun exploring feedforward designs for GenAI, examining trade-offs between the amounts of detail provided and cognitive load when assessing generated content \cite{zhutian2024sketchgenerate, dang2022ganslider}.
% However, GenAI's capabilities are influencing an increasing larger design space of GenAI interfaces.
% This rapid expansion necessitates a more systematic approach to designing effective feedforward across diverse domains, exploring opportunities for novel interaction techniques, assessing user benefits and challenges across design dimensions, and establishing comprehensive design guidelines.
%  basically saying people are designing GenAI systems everywhere and it's growing so much more, and this means there will need to be a more systematic way to design good feedforward in diverse domains, explore opportunities for novel interaction techniques, assess user benefits and challenges, and establish design guidelines.
% a more rigorous investigation in diverse GenAI systems, assess user benefits and challenges across design dimensions, and establish comprehensive design guidelines. 
% However, GenAI's ability to quickly produce and find large amounts of knowledge requires a more rigorous investigation in diverse GenAI systems, assess user benefits and challenges across design dimensions, and establish comprehensive design guidelines. 
% may surface new dimensions (what about GenAI? what are its unique properties? produce and find more knowledge faster, and this potentially calls for new methods, we need to be on the lookout for this.
% generate lots of information, wide range of knowledge, spark new methods, faster search for information, 
% trade-offs and design considerations for
% requires rigorous investigation, as the community must systematically study feedforward designs in diverse GenAI systems, assess user benefits and challenges across design dimensions, and establish comprehensive design guidelines. 

This paper aims to spark discussion on how we may achieve these goals, enabling users to effectively engage and interact with all forms of GenAI systems.
To lay the groundwork for this discussion, we designed diverse instantiations of feedforward across four GenAI applications: conversational UIs, document editors, malleable interfaces, and agent automations. We then discussed the designs and implementations needed to further develop a comprehensive design space for informative feedforward GenAI systems.

We invite researchers in this community to critically examine past and present GenAI interfaces through the lens of feedforward, draw from feedforward literature in other domains, explore new interaction techniques and frameworks for delivering informative feedforward, and work toward concrete design and implementation strategies applicable to all GenAI systems.


% , especially for heavy tasks like generating UIs and automating web tasks.
% and must rely on iterative trial-and-error.
% This process can incur significant cognitive load and time investment, especially for heavy tasks like generating UIs and automating web tasks.


% While feedback enables users to develop an understanding of the generative AI system through exploration and experience, users cannot effectively anticipate what their prompt will generate and instead must iteratively refine their prompts through trial-and-error. This can incur cognitive load and time investment,  especially for complex tasks, such as generating user interfaces or automating web tasks.


% the diverse contexts in which these systems are integrated mean that expertise with one generative AI system does not necessarily translate to others.
% For instance, strategies for effectively prompting ChatGPT to support creative writing tasks may involve specific ways of asking for minor grammar fixes and tone changes, but these strategies do not help better guide Claude to generate data schema for an e-commerce website.


% We described in detail key components of feedforward
% present the following:
% \begin{itemize}
%     % \item A critique of three past and existing GenAI systems from our research lab through the lens of feedforward.
    % \item  Prototype systems demonstrating potential feedforward designs in four different contexts for GenAI.
    % \item A discussion on the design and implementation needed to further develop informative feedforward GenAI systems.
% \end{itemize}
% Generative AI models are more than capable than ever of augmenting productivity and cognition in a diverse range of contexts.
% However, these AI models are challenging to properly prompt for most users.
% Although systems have focused on mitigating these challenges through a variety of solutions/approaches of providing feedback, users must learn this feedback like newcomers for each new generative AI system.
% In addition to feedback, we argue that we must also provide informative feedforward to users. Feedforward will enable newcomers of any generative AI system to be able to anticipate what it will generate, thus helping them prompt more efficiently and reduce frictions and intention-gaps.
% This workshop paper aims to spark discussion on how we can design and implement feedforward for generative AI, and we showcase a few methods for understanding this design space.


% This can be sup-
% ported through feedforward design [ 34] (as distinct from feedback
% [191 ]): inviting an action and communicating what exactly the user
% can expect as a result.15 For example, feedforward can be used to
% inform users that a vague, high-level prompt is unlikely to achieve
% their task before they submit it. As Vermeulen et al. [191] argue, “the
% more complex a system or interaction context gets, the larger the need
% will be for elaborate feedforward in order to aid users in achieving
% their goals”. Prompt chaining is an example of a sequential feedforward approach, surfacing inputs, outputs, and the underlying
% prompt structure for users to explore [204]. However, feedforward
% information can also increase cognitive load [ 42 ], so the right bal-
% ance, particularly for complex systems, remains to be explored. The
% Prompt Middleware framework uses feedforward at diferent levels
% of complexity to guide users towards efective prompts and scafold
% domain expertise into the process [113].

% Use Metacognitive Demands paper as a core part of the framing possibly
% We know that feedforward could be useful --> there's a set of work exploring feedforward in GennAI
% We know that feedforward increases cognitive load, even though it's helpful information
% One dimension is providing feedforward at different levels of complexity.
% A complete picture of what feedforward design means for GenAI is yet to be realized.
% What would we other dimensions of feedforward for GenAI?
% This workshop aims to focus the community's discussion on designing feedforward for GenAI, what approaches are out there, and what are the dimensions worth exploring.
% We explore several dimension

% What are the various representations of feedforward suitable for GenAI
% Outline (Markdown)
% Attributes (JSON)
% Outline+Attributes (JSON with Markdown strings)
% Unique visual representations (length is visualized spatially, structure is also visualized spatially)
% Example phrases (kind of like peering through what kinds of content GenAI will mention)

% Other aspects of interactivity in feedforward
% Manipulability and User-Defined Abstraction (this means collaboratively manipulating feedforward to balance Human-AI communication) This feedforward abstraction is the medium in which human and AI communicate their intents
% AI shares which ``speed'' of thinking it will use for the task. User can adjust this ``speed'' to communicate what they want.

% Communicating via you could say essentially a semi-abstract representation, citing Shapes of Abstraction



% In order to achieve this, we aim to advance the perspective that GenAI must not only provide informative feedback, but also informative \textit{feedforward}---designs that tell users what to expect \textit{before} performing an action \cite{vermeulen2013feedforward}.
% Providing such feedforward in GenAI systems can tell users what to expect from the AI model before they submit their prompt, reducing the need for excessive conversational exchanges, reducing the abstraction gap between user and AI \cite{liu2023groundedabstraction, hari2024gulfenvisioning}, and encouraging meta-cognition when constructing prompts \cite{tankelevitch2024metacogAI}.
% Reflecting this need, we have seen the HCI community explore feedforward designs for GenAI and studying trade-offs between detail and cognitive load assessing the generated content \cite{dang2022ganslider}.
% However, fully realizing these trade-offs across diverse modalities and contexts requires the community to rigorously investigate feedforward designs in GenAI systems, study user benefits and challenges across all design dimensions, and establish design guidelines.





% This workshop paper aims to spark discussion on how we can realize these endeavors to enable users to easily approach and interact with all forms of generative AI systems effectively.

% the design space of feedforward for genAI across diverse contexts and build towards a set of guidelines for designing and implementing genAI feedforward interfaces. 
% To achieve this, it is essential to define the full design space of feedforward in generative AI, establish clear design guidelines, and develop effective implementation strategies that integrate seamlessly into diverse AI systems.

% What design guidelines should be followed? How can we effectively implement feedforward in AI models?

% Although some instances of feedforward exist, such as prompt suggestions \cite{} and code auto-completions \cite{}, we need a rigorous investigation into how feedforward should be provided across diverse contexts and systems to 

% What is the full design space of feedforward in generative AI systems? What design guidelines should be followed? How can we effectively implement feedforward in AI models? 

% This workshop paper aims to spark discussion on how we can design and implement feedforward for generative AI, and we showcase a few methods for understanding this design space.



% As a result, when AI responses do not align with users' expectations, most novices eventually give up on refining their prompts to obtain the desired output \cite{zamfirescu2023johnnyprompt}.
% Although we have seen approaches such as providing dedicated spaces to learn and tinker with prompts \cite{arawjo2024chainforge, angert2023spellburst}, producing multiple output variations in a single space \cite{luminate, gero2024llmsensemakingscale}, asking clarifying questions \cite{}, and reducing friction to transform the generated output with direct manipulation \cite{priyan2024dynavis, masson2024directGPT, graphologue}, these systems focus on providing \textit{feedback} to users, telling them what happened \textit{after} submitting their prompt.
% While feedback is effective for allowing users to learn what to expect from generative AI through exploration and gained experience with the system, systems are integrated in so many diverse contexts that experience and understanding of one genAI system will not clearly translate to many others.



% LLM is big, but the big thing is providing the right feedback to facilitate iteration.
% However, there’s another form of support through feedforward.
% Without any feedforward, we go through the painstaking process of prompting, realizing the generated content isn’t right, and going through this again.
% Imagine how much worse it would be given how much more we’re generating at a time, such as generative AI, videos, chain of thought and agent automations, etc. AI interaction is growing heavier each prompt.
% We need to robustly investigate the design space of feedforward in AI interaction in order to reduce the cognitive and mechanical load of users.
% This workshop paper analyzes several existing work on their implementation of feedforward, presents design opportunities for feedforward AI interfaces, and explores application scenarios for feedforward support. Finally, we discuss existing challenges for designing and implementing feedforward in genAI interaction and opportunities exploring how we can further investigate this direction.

% We push that this communicaty should explore the design space of feedforward in generative AI systems.
% This could provide a unified understanding of guidelines for how AI systems should be designed...?
% The feedforward framing provides a scoped "term" to describe the AI-interaction needs



% Outline

% Context of how generative AI is really useful and starting to be used everywhere. With many of our visions set on how we can integrate generative AI into each and every kind of task and workflow to augment our productivity. However, research has revealed many challenges in interacting with AI across various domains in ..., resulting in repeated exchanges in prompting, converging too early on an outcome, ....

% Consider a scenario ... 

% What we're seeing in this scenario is this challenge and that --> cite the studies and theories, saying it's because of that, it's observe to be that, and blah blah.
% To address these challenges, the Human-AI interaction community has presented various lines of work including, A, B, C.

% However, if a user is in these systems, the only way they can anticipate what AI is going to generate is through their experience with the system, by tinkering, reflecting on the results --> trial and error.
% This interaction mechanism is through receiving feedback from AI, telling users what happened after submitting their prompt.
% While feedback is effective for helping users better understand how the genAI system behaves and produces given certain inputs, genAI is integrated in so many diverse contexts and for so many tasks that one understanding about the genAI system in a specific scenario does not easily translate to many others.
% For instance, the strategies for effectively prompting ChatGPT to support creative writing tasks do not directly translate to strategies for guiding Claude to generate a data schema for an e-commerce website.
% In essence, users---regardless of their prior expertise---effectively become novices when interacting with a genAI system in a new context, effectively forcing them to learn what to anticipate from this new genAI system.

% To truly help all users---no matter their expertise---effectively utilize all genAI systems, what we need in addition to feedback is
% What we believe is missing in these genAI systems are proper design strategies for \textit{feedforward}.
% Feedforward tells users what they can anticipate before they perform an action, and for the case of genAI, feedforward should tell users what they can expect AI to generate before they submit their prompt.
% Instead that is what feedforward—definition—is for
% However, we do not have explicit principles or guidelines for designing for feedforward.


% However, the root issue is really that users can't anticipate what AI will genearte to their prompt. We don't think that it's X, Y, or Z that explains this issue, but we believe what explains the issues is that we are not providing sufficient \textit{feedforward} in AI-integrated interfaces.
% We label this issue as "The Feedforward Challenge of Generative AI".

% Feedforward is ...

% This workshop paper aims to spark discussion on 1) How to design feedforward in genAI, 2) How to effectively implement feedforward for AI, 
% - What is the design space
% - How can we improve current designs --> want a critical lens
% - What kinds of contexts

% We urge researchers in this community to critically analyze past and current Human-AI systems through the lens of providing feedforward, explore ways we can redesign and innovate ways to design and implement feedforward in generative AI systems in all relevant contexts and domains, and build towards a design space and a set design guidelines to aid .... 



% Despite this potential, users inevitably face challenges when using genAI across these diverse domains.
% Consider a scenario where an intermediate badminton player wants to learn about custom strings for their badminton racket and asks ChatGPT, ``What should I consider when choosing strings for my racket?''
% The user is not aware that other sports such as tennis and squash also involve custom strings for their rackets and may not proactively disambiguate their prompt.
% Additionally, the user could only speculate what kinds of information, in which representations, and with which generative functionalities ChatGPT would use, whether it would detail a bulleted list of criteria or a step-by-step guide, whether it would search the web for example strings and brands, or whether it would employ chain-of-thought to reason through the prompt.
% % Lastly, the user also cannot anticipate how long ChatGPT's response would be, whether .
% Without the user's knowledge, ChatGPT generates information about tennis strings and a bullet-point list of five criteria\footnote{\href{https://chatgpt.com/share/67a035c6-d9b0-8006-b74f-10030501e369}{https://chatgpt.com/share/67a035c6-d9b0-8006-b74f-10030501e369}. Generated with GPT-4o on February 2025.}, ultimately falling down a rabbit hole of confusion during a long conversational exchange and missing out on other key insights on badminton strings.




% Consider a scenario where a student learning about finance asks ChatGPT, ``What is a bond?"
% The user may assume that ChatGPT would provide the definition of <term> in the context of <topic>. He may also speculate that ChatGPT would generate a relatively concise response.
% To the user's surprise, ChatGPT provides a general definition of feedforward spanning contexts of engineering, neuroscience, and machine learning, rather than scoping its context only to design and HCI. 
% Additionally, they notice ChatGPT generates multiple sections each containing paragraphs and bullet point lists---a response way too long for their needs.
% % , they may not anticipate how long the response will be and what other topics AI would generate, if any.
% Consequently, the user must repeatedly clarify their prompt until they land on a desired result---a seemingly simple request becomes a long conversational exchange.






% In other words, genAI must 
% Consider an intermediate badminton player who wants to learn about custom strings for their racket and asks ChatGPT, "What should I consider when choosing strings for my racket?"
% Unaware that other sports, such as tennis and squash, also involve custom racket strings, the user may not proactively clarify their prompt.
% Furthermore, the user can only speculate about the type of information ChatGPT will provide, the representation it will use, and the generative techniques it will employ. Will it present a bulleted list of criteria or a step-by-step guide? Will it search the web for example strings and brands? Will it use chain-of-thought reasoning to analyze the question?
% Without the user's knowledge, ChatGPT may generate information about tennis strings and provide a five-point bullet list, leading users into a long and confusing exchange. As a result, the user could miss key insights specific to their needs.
% This scenario highlights several key challenges explored in recent Human-AI interaction research.

% To address these challenges, the Human-AI interaction community has presented various lines of work including, A, B, C.

% However, the only way users anticipate what AI is going to generate is through their experience with the system, either through trial-and-error or the system asking clarifying questions.

% However, the only way users can anticipate what AI will generate with these systems are through exchanges and interactions after the prompt.
% These interactions instantiate AI providing \textit{feedback} to users, telling them what happened \textit{after} submitting their prompt \cite{}.
% While feedback is effective for helping users better understand how the genAI system responds to certain inputs, 
% To become fluent and comfortable with diverse generative AI systems across various contexts, users—regardless of their prior experience with feedback-rich AI—must be able to anticipate the outputs of any new generative AI system.
% if we want users to easily leverage the potential of genAI systems across all kinds of contexts, 
% If we want users to easily leverage the potential of generative AI systems across all kinds of contexts regardless of their prior experience, users should be able to anticipate the outputs of any generative AI system without necessarily relying on their learnings from feedback.

% In essence, users---regardless of their prior expertise from feedback-rich genAI systems---revert to becoming novices when interacting with a genAI system in new contexts
% , effectively forcing them to learn what to anticipate from this new genAI system.

% in addition to feedback, 
%  frictions, gulfs of envisioning, and abstraction gaps,
% onboard/accustom/understand/comfort 

% - What is the design space
% - How can we improve current designs --> want a critical lens
% - What kinds of contexts

% We design and developed prototypes the provide feedforward

% and draw from prior literature on feedforward across different domains such as gestures \cite{} and VR/AR \cite{} to help discuss what feedforward means for generative AI.

% and Human-AI systems, frameworks, and architectures to discuss ...
% design which aspects from these settings may or may not translate to feedforward for genAI.

% in different settings such as gestures \cite{} and VR/AR \cite{} and draw from literature on  to help discuss 



% explore ways we can redesign and innovate ways to design and implement feedforward in generative AI systems in all relevant contexts and domains, and build towards a design space and a set design guidelines to aid .... 


% A unique challenge in implementing feedforward in the genAI setting compared to others such as gestures in Octopocus \cite{} and VR/AR \cite{} is that users do not have a clear understanding of the inner-workings of genAI models \cite{gulfenvisioning2024subramonyam}.
% We encourage researchers to draw from prior literature on feedforward in different settings such as gestures \cite{} and VR/AR \cite{} to understand design which aspects from these settings may or may not translate to feedforward for genAI.



% However, many challenges surround how users can effectively prompt AI to get their desired output. One key finding is that users cannot anticipate what the model will generate given their prompt.

% More complex workflows involving text-to-video models, generative UIs, and agent automations can exacerbate this problem as the model generates significantly more information.
% of error-fixing through conversational exchanges with AI 
% The core issue of these workflows is that users do not have a clear mental model of how generative AI models work and as a result are unable to effectively anticipate what the model would generate given their prompt.
% As a result, when users inevitably under-specify their prompt, they face challenges in iterating their prompt, with some even giving up iterating entirely.


% In essence, users do not know what to expect from AI's response given their prompt. That's why there are so many of these challenges and symptoms like having to prompt again, giving up, etc.
% - Johnny: over generalize their prompt, don't iterate their prompt enough, or don't iterate at all.
% Users are unsure what kinds of behaviors they could expect from AI. They also expect human capabilities.
% - Gulf of Envisioning: it's hard to know what to expect because AI is a black box.



% To address these challenges, lots of research has explored ways to support this. 
% Direct guidance, such as prompt recommendations, suggestions, and autocomplete.
% Trial-and-error for users to learn and explore (ChainForge, Hari's LLM system)
% Transforming generated output that's more interactive and modifiable (DirectGPT, Graphologue, Dynaviz, Malleable ODI, <other text editing/writing support systems)
% Multi-output to give users more diverse options and ideas (LLM Sensemaking at Scale, Luminate, Bruce's Inner Thoughts)
% - Grounded Abstraction Matching


% We believe the root cause of this issue is that generative AI systems lack \textit{feedforward} in their designs.
% In contrast to feedback, which describes design solutions that tell users what happened after they performed an action, feedforward describes design solutions that show users what they can expect from an action before performing it. 
% In control systems or control theory, feedforward means blah blah blah... Use the definition of control theory, but also share the background in hci.
% The lack of feedforward is what causes ....
% Again, the goal is to help users better anticipate what the genAI model will output. But that definition is literally the need for \textbf{feedforward} in genAI. We frame this need as \textbf{the need for feedforward in genAI systems}.
% Trying to say, at a bigger picture, we should be aiming for "feedforward" design as the thing we're aiming for. How do we design better feedforward? should be the main goal.
% However, we know in HCI research and UI design, that a core design solution to showing users what they can expect before performing an action is \textbf{feedforward}. 
% We identify that generative AI's challenges stem from the lack feedforward in interfaces.
% (Octopocus, that other feedforward survey paper, feedforward in AR/VR, )
% While systems explore steerability and transparency of AI-integrated interfaces, we believe that strong feedforward design is the way to address these concerns.
% Feedforward cannot possibly be implemented if the AI's output is fully dependent on the input. Since we don't understand how it's going to respond, we instead implement feedforward by generating content as the user types their prompt, before they submit. This lightweight output then serves as the skeleton to generate the real output.

% People frame it as gulf of envisioning, abstraction gap, etc.
% We frame this as the Feedforward Challenge in Generative AI. Through this lens, we aim to explore what is good and controllable feedforward design for genAI, what are opportunities, what are implementation challenges worth discussing, etc.

% This workshop paper aims to consider and discuss the following questions:


% This workshop paper advocates for the communities in Tools for Thought, HCI, and AI to rigorously analyze, explore, and develop ways we can design feedforward in generative AI systems to.
% To catalyze this study, we present design opportunities through prototype systems in five applications scenarios: conversational UIs, document editors, generative UI, and IDEs. Finally, we discuss existing challenges for designing and implementing feedforward in genAI interaction and opportunities exploring how we can further investigate this direction.


% This workshop paper analyzes several existing work on their implementation of feedforward, presents design opportunities for feedforward AI interfaces, and explores application scenarios for feedforward support. Finally, we discuss existing challenges for designing and implementing feedforward in genAI interaction and opportunities exploring how we can further investigate this direction.

% it is extremely difficult for users to uncover what their prompt can and might generate.



% Scenario: if a user asks ChatGPT ``What is feedforward?'', the user may not know what it will output. Likely will output the definition, but doesn't know how long the response will be, what other topics the definition may touch on. In fact, the user may not anticipate that the response would provide a general definition in the context of engineering, control theory, and neuroscience, when really only expecting the definition in the context of HCI. Consequently, when ChatGPT responds, the user must continually clarify their prompt until they find a desired response. Although such conversational exchanges may grow cheap and familiar, the same workflow translates to heavier information task workflows, such as text-to-video models, generative UI, and agent automations. 












% I guess a core consideration for this idea is: why not just show the outline right after you press the button? Like, the button is always going to give you an outline. Just press it. Cocoa CHI25


% A natural Human-AI Interface is one that requires a minimal amount of  conversation.





% Although LLMs are extremely powerful, capable of generating a diverse range and depth of content, it is extremely difficult for users to uncover what their prompt can and might generate. Only after submitting their prompt, receiving the entire AI-generated result, and evaluating the result, can the user understand whether they are satisfied with their prompt. Thus, if they are not satisfied, they must repeat this generation process by iterating. While there are also approaches in generating results in parallel [X, X] and intentionally constraining the output to various dimensions and structures [X, X], users must still ultimately evaluate them post-hoc. Consequently, users perhaps waste quite a significant amount of time trying to converge to an ideal response. 

% The existing designs and techniques in current literature all provide high-quality feedback after prompting to the LLM, enabling users to productively evaluate their result and iterate and improve on it. This bridges the Gulf of Evaluation. However, we haven’t explored the design space for enabling users to anticipate and evaluate what LLMs can and might produce \textit{before} generating the response.


