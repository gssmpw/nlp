\documentclass[conference]{IEEEtran}
\usepackage{multirow}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{stfloats}
\usepackage{etoolbox}
\usepackage{geometry}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\title{Deployment-friendly Lane-changing Intention Prediction Powered by Brain-inspired Spiking Neural Networks
}

\author{
\IEEEauthorblockN{1\textsuperscript{st} Shuqi Shen}
\IEEEauthorblockA{\textit{The Hong Kong University of} \\
\textit{Science and Technology (Guangzhou)}\\
Guangzhou, China \\
u202141021@xs.ustb.edu.cn}
\and
\IEEEauthorblockN{1\textsuperscript{st} Junjie Yang}
\IEEEauthorblockA{\textit{The Hong Kong University of} \\
\textit{Science and Technology (Guangzhou)}\\
Guangzhou, China \\
jyang512@connect.hkust-gz.edu.cn}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Hui Zhong}
\IEEEauthorblockA{\textit{The Hong Kong University of} \\
\textit{Science and Technology (Guangzhou)}\\
Guangzhou, China \\
hzhong638@connect.hkust-gz.edu.cn}
\and
\IEEEauthorblockN{4\textsuperscript{th} Qiming Zhang}
\IEEEauthorblockA{\textit{The Hong Kong University of} \\
\textit{Science and Technology (Guangzhou)}\\
Guangzhou, China \\
qzhang255@connect.hkust-gz.edu.cn}
\and
\IEEEauthorblockN{5\textsuperscript{th} Hongliang Lu*}
\IEEEauthorblockA{\textit{The Hong Kong University of} \\
\textit{Science and Technology (Guangzhou)}\\
Guangzhou, China \\
hlu592@connect.hkust-gz.edu.cn\\
*Corresponding author}
\and
\IEEEauthorblockN{6\textsuperscript{th} Hai Yang*}
\IEEEauthorblockA{
\textit{The Hong Kong University of }\\
\textit{Science and Technology}\\
Hongkong, China \\
cehyang@ust.hk\\
*Corresponding author}

\thanks{Junjie Yang and Shuqi Shen contribute equally to this paper.}
\thanks{Corresponding authors: Hongliang Lu and Hai Yang.}
}
\geometry{paper=letterpaper, top=1in, bottom=0.8in, left=0.75in, right=0.75in}
\begin{document}

\maketitle




\begin{abstract}
Accurate and real-time prediction of surrounding vehicles’ lane-changing intentions is a critical challenge in deploying safe and efficient autonomous driving systems in open-world scenarios. Existing high-performing methods remain hard to deploy due to their high computational cost, long training times, and excessive memory requirements.
Here, we propose an efficient lane-changing intention prediction approach based on brain-inspired Spiking Neural Networks (SNN). By leveraging the event-driven nature of SNN, the proposed approach enables us to encode the vehicle's states in a more efficient manner.
%
Comparison experiments conducted on HighD and NGSIM datasets demonstrate that our method significantly improves training efficiency and reduces deployment costs while maintaining comparable prediction accuracy. Particularly, compared to the baseline, our approach reduces training time by 75\% and memory usage by 99.9\%. These results validate the efficiency and reliability of our method in lane-changing predictions, highlighting its potential for safe and efficient autonomous driving systems while offering significant advantages in deployment, including reduced training time, lower memory usage, and faster inference.
\end{abstract}

\begin{IEEEkeywords}
Lane-changing intention prediction, Spiking Neural Networks (SNN), autonomous driving, real-time prediction, HighD dataset, NGSIM dataset.
\end{IEEEkeywords}

\section{Introduction}
%在自动驾驶领域，快速准确地预测周围车辆驾驶员的变道意图是提升系统安全性和决策效率的关键。精准的意图预测不仅能有效避免潜在碰撞，还能优化路径规划和交通流管理，实现更智能高效的驾驶体验。
%先说一句自动驾驶对于未来交通或者出行的意义，算是一个套话
In the field of autonomous driving, the rapid and accurate prediction of lane-changing intentions of surrounding vehicles is critical for enhancing system safety and decision-making efficiency. Precise intention prediction can not only effectively prevent potential collisions but also optimize path planning and traffic flow management, resulting in a smarter and more efficient driving experience \cite{mozaffari2020deep}.

%近年来，变道预测的研究取得了显著进展。不同于早期采用物理模型的方法[参考文献1][参考文献2]，现代研究大多采用基于学习的方法。例如，反向传播神经网络（BP神经网络）通过学习真实数据可以有效预测换道意图。与此同时，时序模型如LSTM（长短期记忆网络）由于能够捕捉时间依赖性，已被广泛应用于变道预测中。ESN（Echo State Network）作为近年来的新兴时序模型，通过其独特的动态特性，进一步提升了换道预测的效果。尽管上述基于学习的方法能够取得一定的预测准确率，人工神经网络的计算需求仍然对实际应用构成挑战，尤其是在车载设备上。此外，随着海量数据的不断涌现，算法的快速迭代和实时处理能力也面临更高要求。因此，变道预测算法亟需在高效训练、快速部署以及实时性和可靠性之间找到合适的平衡。
% Recent advancements in lane-changing prediction research have been significant. Unlike earlier methods that relied on physical models \cite{kesting2007general, wang2014investigation}, modern research predominantly adopts learning-based approaches. For example, backpropagation neural networks (BP networks) can effectively predict lane change intentions by learning from real-world data \cite{ding2013neural}. Meanwhile, temporal models, such as Long Short-Term Memory (LSTM) networks, have gained widespread application in lane change prediction due to their ability to capture temporal dependencies \cite{shokrolah2019trajectory}. The Echo State Network (ESN), a newer temporal model, further enhances prediction performance with its unique dynamic properties\cite{griesbach2021lane}. Although these learning-based methods achieve a certain level of prediction accuracy, the computational demands of artificial neural networks remain a challenge for practical applications, especially on onboard devices. Additionally, with the continuous influx of massive data, there is an increasing demand for fast algorithm iteration and real-time processing capabilities. As a result, lane change prediction algorithms must strike an appropriate balance between efficient training, rapid deployment, and real-time reliability.
Recent advancements in lane-changing prediction research have been remarkable. Unlike earlier approaches that relied on physical models that simulate vehicle dynamics through predefined mathematical equations \cite{kesting2007general, wang2014investigation}, modern research has shifted toward learning-based methods. For instance, back-propagation neural networks effectively predict lane-changing intentions by learning from real-world data \cite{ding2013neural}. Similarly, temporal models such as Long Short-Term Memory (LSTM) networks have gained popularity for their ability to capture temporal dependencies in lane-changing prediction tasks \cite{shokrolah2019trajectory}. The Echo State Network (ESN), a more recent temporal model, further improves prediction performance through its unique dynamic properties \cite{griesbach2021lane}.
%
Learning-based methods for lane-changing prediction, despite their advancements, face notable limitations. They require extensive training data, involve prolonged training durations, and demand significant hardware resources, posing challenges for real-time deployment on onboard devices. These issues highlight the need for more efficient and lightweight solutions \cite{xie2019data}.
While these learning-based methods achieve commendable levels of prediction accuracy, the computational demands of artificial neural networks pose a significant challenge, particularly for onboard devices. Furthermore, the continuous influx of massive amounts of data amplifies the need for fast algorithm iterations and real-time processing capabilities. As a result, lane-changing prediction algorithms must balance efficient training, rapid deployment, and real-time reliability to meet the demands of practical applications.

% 受大脑启发的方法推动了神经计算领域的重大进步，SNN 就是此类创新的典型例子。 SNN 被认为是第三代神经网络 \cite{ghosh2009third}，通过基于脉冲的事件驱动机制进行操作。这种受生物学启发的方法不仅反映了神经处理的自然稀疏性，而且还展示了高能源效率。这些特性使得 SNN 非常适合资源受限的嵌入式系统，并且能够有效地应对动态交通场景的复杂性，利用其时间动态进行实时决策。
% Brain-inspired methods have spurred significant advancements in neural computation, with SNN standing out as a prime example of such innovation. Recognized as the third-generation neural networks \cite{ghosh2009third}, SNN operate through spike-based event-driven mechanisms. This biologically inspired approach not only mirrors the natural sparsity of neural processing but also demonstrates high energy efficiency. 
% %
% These characteristics render SNN highly suitable for resource-constrained embedded systems and effective in navigating the complexities of dynamic traffic scenarios, leveraging their temporal dynamics for real-time decision-making.
Brain-inspired computational methods have recently made groundbreaking progress. SNN, known as the third-generation neural network \cite{ghosh2009third}, exhibits unique advantages\newgeometry{top=0.75in, bottom=0.8in, left=0.75in, right=0.75in}in intelligent embedded systems due to biological interpretability and deployment efficiency. Unlike traditional Artificial Neural Networks (ANN), SNN is event-driven, relying on a sparse spike timing encoding mechanism to process information. This event-driven feature enhances computational energy efficiency by 12 times, as it only processes information when events occur, reducing unnecessary computation cost 
\cite{kundu2021spike}. Therefore, numerous researchers have shown great interest in SNN.
%
\cite{neftci2019surrogate} introduced the surrogate gradient method into SNN, significantly improving training speed by over threefold, while also enhancing deployment efficiency. \cite{rueckauer2017conversion} developed an ANN-SNN conversion framework, which maintained model accuracy while increasing training efficiency by 75\%, and also reduced resource consumption. %所以呢，罗列完例子应该总结一下
These researches collectively highlight the significant potential of SNN in achieving both high computational and deployment efficiency and reliable performance, making SNN a promising solution for future real-world practical applications.

In this paper, we propose an efficient lane-changing intention prediction method based on brain-inspired SNN. 
Specifically, our approach first utilizes a linear layer to feature the vehicle’s driving state. Then, we employ SNN to understand and predict the vehicle’s lane-changing intention in real-time, categorizing it into no lane-keeping, turn left, or turn right.
To evaluate our approach, several groups of comparison experiments are carried out.
we utilize two open-source naturalistic driving datasets, HighD \cite{krajewski2018highd} and NGSIM \cite{coifman2017critical}, to assess the performance in terms of efficiency and accuracy. 
The advantages of SNN in resource consumption support the development of highly efficient algorithms and seamless hardware deployment, enabling scalable and practical autonomous driving solutions.
Looking ahead, brain-inspired approaches like SNN stand out as a key advantage for autonomous driving, offering a paradigm shift in mimicking the brain’s adaptive and efficient problem-solving capabilities. 

The remainder of this paper is organized as follows. Section II discusses the related work. Section III introduces the proposed methodology in detail. Section IV presents the experimental results and analyzes the findings. Finally, Section V concludes the paper and highlights potential directions for future research.

\section{Related Work}
% 总起讲这一节回顾了什么
This section reviews previous work on lane-changing prediction and SNN. We first discuss the development of lane-changing prediction methods, comparing kinematic or kinetic models and behavioral models with learning-based approaches, and highlight their limitations. Next, we introduce SNN, emphasizing its advantages and applications, particularly in traffic and autonomous vehicle domains.
\subsection{Lane-Changing Intention Prediction}
% 换道预测是指在交通场景中，预测其他车辆是否会进行换道操作以及何时进行换道的任务。
Lane-changing prediction refers to predicting whether and when other vehicles will execute a lane change in a traffic environment.
% 早期的换道预测方法主要基于运动学或动力学模型，通过数学公式进行建模, 例如
% XX使用极坐标多项式对车辆轨迹进行拟合并做出预测，但由于多项式无法充分捕捉复杂的非线性动态，导致无法完全拟合车辆的真实轨迹。
% 非线性动力学模型和模型预测控制的应用确保了纵向安全和横向操控稳定，但这种方法未考虑交通参与者的动态预测，限制了其在复杂交通环境中的实际应用。
Early lane-changing prediction approaches were primarily based on kinematic or kinetic models, typically using mathematical formulas for modeling. For example, \cite{nelson1989continuous} used polar coordinate polynomials to fit vehicle trajectories and predict their motion, demonstrating an effective mathematical approach for trajectory prediction. Nonlinear dynamic models and model predictive control were utilized to ensure longitudinal safety and lateral stability in lane-changing scenarios, showcasing their potential in maintaining vehicle control under various conditions \cite{liu2018dynamic}.
% 此外, 行为模型在换道预测中也得到了广泛验证, 例如  研究重点模拟了驾驶员的行为决策过程，通过明确选择目标车道并评估换道安全性的方法提高了换道预测的准确性，但在复杂的交通场景下的适用性不足。
Besides, behavioral modeling methods were also widely utilized. For example, \cite{treiber2009modeling} modeled the driver’s decision-making process and improved lane-changing prediction accuracy by explicitly selecting target lanes and evaluating lane-change safety.
% 这些模型严重依赖模型的复杂度, 高复杂度模型虽然实现了高预测准确率但在部署实时性上面临严重不足
These models achieve high prediction accuracy by relying heavily on their complexity, however, the computational demands make them unsuitable for resource-constrained onboard deployment in real-time applications.
% 近年来，基于学习的方法逐渐成为换道预测的主流。例如
In recent years, learning-based methods have gradually become the mainstream in lane-changing prediction.
% xx使用了多层感知机 MLP学习驾驶轨迹并进行换道预测, 实现了较高的准确率, 但是无法预测完整路径的换道预测
% 结合双向 RNN和 LSTM 对时间序列驾驶数据进行学习也能够对高速公路换道意图进行准确的预测, 然而模型的复杂使得其部署效率无法满足实时需求
% XX 使用了回声状态网络（Echo State Networks, ESNs）和主成分分析（PCA）对自然驾驶数据进行学习，实现了对换道行为的高精度预测。然而，这种方法依赖于驾驶员相关数据，在预测周围车辆（SV）的换道意图时存在局限性。
% 针对驾驶数据不足的问题，xxx 提出了一种基于在线迁移学习的换道意图预测方法，在数据量有限的情况下成功实现了目标车辆换道意图的检测，但在实际应用中，尤其是右侧换道行为的预测准确性仍有待提升。
For example, \cite{tomar2010prediction} employed a multilayer perceptron to learn driving trajectories and predict lane changes, demonstrating the potential of neural networks for capturing lane-changing patterns. Similarly, the combination of bidirectional RNN and LSTM proved effective for predicting highway lane-changing intentions using time-series driving data, showcasing the strength of temporal models in handling sequential information \cite{xing2020ensemble}.
\cite{griesbach2020prediction} advanced lane-changing prediction by applying ESN and Principal Component Analysis to naturalistic driving data, leveraging driver-specific data for precision. Additionally, \cite{zhang2021target} introduced an online transfer learning approach that efficiently predicted lane-changing intentions even with limited data, expanding the applicability of learning-based methods in diverse scenarios.
% overall, 这些基于学习的方法无法实现高效的训练和部署与高预测准确率之间的有效平衡
Overall, these learning-based methods fail to achieve both efficient training and deployment and high prediction accuracy at the same time.
Therefore, a deployment-friendly approach for efficient lane-changing intention prediction is needed.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.85\textwidth]{framework.png}
    \caption{Schematic of the SNN model for lane-changing intention prediction. The model processes a time-series input of vehicle state features through four main components: (1) Event Data Construction to generate the input matrix, (2) Feature Extraction with a Linear layer to expand feature dimensions, (3) Temporal Modeling using a LIF layer to capture temporal dependencies, and (4) Classification where a Linear layer maps the features to lane-change intention categories, followed by a Softmax activation for prediction.}
    \label{framework}
\end{figure*}

\subsection{Spiking Neural Networks}
% 脉冲神经网络（SNN）是一种高效、低功耗且具有生物可解释性的神经网络，特别适合处理时间序列数据和资源受限的实时应用。
SNN are efficient, low-power, and biologically interpretable neural networks that are particularly suited for processing time-series data and real-time applications in resource-constrained environments.
% 近年来 SNN 在很多领域得到了广泛的应用
% Fang等人在时间序列分类任务中使用脉冲神经网络（SNN），通过设计稀疏时空脉冲编码方案和训练算法，在低功耗的前提下实现了与深度神经网络相当的分类性能。
% Kim等人在动态视觉传感（DVS）任务中使用脉冲神经网络（SNN），实现了深层SNN在多个基准数据集上的最先进优化性能。
% []等人通过使用SNN完成视觉识别任务，在SNN导向的数据集上表现出更优的性能，并显著降低了能耗。
% []在复杂视觉识别任务中提出了一种新的 ANN-SNN 转换机制，在确保识别准确率的同时显著提升了训练效率。
In recent years, SNN have been widely applied in many fields. For example, \cite{fang2020multivariate} utilized SNN for time series classification and designed a sparse spatiotemporal spike encoding scheme and training algorithm, achieving classification performance comparable to deep neural networks under low-power conditions. \cite{kim2021optimizing} utilized SNN for dynamic vision sensing (DVS) optimization tasks, achieving optimal performance for deep SNN across multiple benchmark datasets. \cite{deng2020rethinking} used SNN for visual recognition tasks and demonstrated superior performance on SNN-specific datasets with a significant reduction in energy consumption. \cite{sengupta2019going} proposed a new ANN-SNN conversion mechanism for complex visual recognition tasks that ensured recognition accuracy and significantly improved training efficiency.
% 脉冲神经网络在交通领域的应用
In the field of transportation, SNN have also garnered significant attention.
% 在其他交通参与者的分类任务中，SNN与事件摄像头的结合实现了低功耗和低延迟的高效分类性能。
% []在自动驾驶车辆的车道保持任务中应用SNN，并结合STDP实现了快速学习，展现出更高的定位精度，同时显著降低了计算能耗。
In the classification tasks of other traffic participants, the combination of SNN and event-based cameras demonstrated efficient classification capabilities with low power consumption and low latency \cite{viale2021carsnn}.
\cite{lopez2021spiking} proposed novel SNN for AV radar signal processing, which achieved efficient processing performance and maintained low power consumption in simulated driving scenarios.
\cite{bing2020indirect} applied SNN to lane-keeping tasks to achieve fast learning, which improved positioning accuracy and significantly reduced computational energy consumption.
% 总而言之 xx
In summary, SNN has shown great promise in transportation applications, meeting the critical demands of autonomous driving for fast, energy-efficient deployment.




\section{Methodology}
% 总起
This section introduces the proposed approach for efficient lane-changing intention prediction using SNN, including the network architecture and the training process.

\subsection{Proposed SNN Architecture}

To capture the temporal dynamics in lane-changing processes, we propose a model based on Spiking Neural Networks (SNN), as illustrated in Figure \ref{framework}. The input to the model consists of a time-series matrix representing vehicle state features with dimensions $(12, 5)$. Each row corresponds to a time step, and the five feature dimensions include lateral distance to the lane center($\delta_y$), longitudinal velocity($v_x$), longitudinal acceleration($a_x$), lateral velocity($v_y$), and lateral acceleration($a_y$). These features provide critical spatial and dynamic information required for understanding lane-changing behavior.
During dataset construction, lane-changing initiation is defined as the moment when the vehicle starts deviating from its lane. It is assumed that drivers form clear lane-changing intentions 3 s before this moment \cite{jokhio2023analysis}.

The model architecture integrates three main components to enable efficient and accurate prediction of lane-changing intentions. First, the feature extraction module, implemented as a Linear layer, expands the input feature dimensions, enhancing the representation power of the data. Next, the temporal modeling module, implemented as a Leaky Integrate-and-Fire (LIF) layer, captures the dynamic dependencies in the input data by simulating biological neuron behaviors. Finally, the classification module aggregates the extracted temporal features and maps them into a probabilistic output representing three categories of lane-changing intentions. This architecture ensures that the temporal patterns in the input data are preserved and efficiently processed, enabling accurate predictions while maintaining computational efficiency.


% % 模型的输入为尺寸为 $12 \times 5$ 的车辆的状态特征的时间序列数据。输入特征首先通过 Linear 24 层，该层将输入的特征维度从 5 扩展到 24，生成一个 $12 \times 24$ 的特征表示，从而提升特征的表达能力。随后，特征被送入 LIF 24 层（Leaky Integrate-and-Fire），这是脉冲神经网络的核心模块，用于模拟生物神经元的动态行为。
% Our model takes a time-series input data of vehicle state features with dimensions $[12,5]$. First, the input feature matrix $\mathbf{X} \in \mathbb{R}^{[12, 5]}$ pass through a Linear layer, which expands the feature dimension from 5 to 24 and generates a feature matrix $\mathbf{I} \in \mathbb{R}^{[12, 24]}$, which consists of 12 time-steps (rows) and 24 feature dimensions (columns). This process is expressed as follows:
% \begin{equation}
% \mathbf{I} = \mathbf{X}\mathbf{W} + \mathbf{b}
% \end{equation}
% where $\mathbf{W}$ and $\mathbf{b}$ are the weight matrix and the bias vector of the linear layer.
% This expansion enhances the expressive power of the features. Next, the features enter the LIF layer (Leaky Integrate-and-Fire), the core module of the SNN, which simulates the dynamic behavior of biological neurons.

% % 输入数据经过线性扩展层后生成特征矩阵 $\mathbf{I} \in \mathbb{R}^{12 \times 24}$，包含 12 个时间步（行）和 24 个特征维度（列）。LIF 24 层（Leaky Integrate-and-Fire）进一步处理该特征矩阵，其核心机制在于结合特征维度的并行处理与时间序列的动态累积。每个脉冲神经元专注于输入矩阵中一个特定特征维度的时间序列，独立建模该维度在时间上的动态模式。具体来说，LIF 层包含 24 个脉冲神经元，第 $j$ 个神经元仅处理输入矩阵的第 $j$ 列特征 $\mathbf{I}_{:,j} = [I[1,j], I[2,j], …, I[12,j]]^\top$。这一设计保证了特征维度间的独立性，避免了信息处理中的维度间干扰。
% The LIF layer processes the feature matrix by combining parallel processing across feature dimensions with dynamic accumulation over time. Each spiking neuron focuses on the time-series data of one specific feature dimension and models the temporal patterns independently. Specifically, the LIF layer contains 24 spiking neurons, where the $j^{th}$ neuron processes only the $j^{th}$ column of the feature matrix, $\mathbf{I}_{:,j} = [I[1,j], I[2,j], \dots, I[12,j]]^\top$. This design ensures independence between feature dimensions and prevents interference during information processing.
% % 在时间序列的动态处理过程中，LIF 层的每个神经元依照时间步顺序逐一处理分配到的特征值，并通过迭代累积更新其状态。初始化时，每个神经元的状态值设为零，即 $u_j[0] = 0$。随后，在每个时间步 $t$，神经元根据输入信号 $I[t,j]$ 和其历史状态 $u_j[t-1]$ 更新当前状态，更新规则如下：
% In the dynamic processing of the time series, each neuron in the LIF layer handles the assigned feature values sequentially across time steps. Each neuron updates its state through iterative accumulation. At initialization, the state of each neuron is set to zero, represented as $u_j[0] = 0$. At each time step $t$, the neuron updates the current state based on the input signal $I[t,j]$ and its previous state $u_j[t-1]$. The update rule is as follows:
% \begin{equation}
%     u_j[t] = \beta \cdot u_j[t-1] + I[t,j]
% \end{equation}
% % 其中，$\beta \in (0,1)$ 为衰减系数，用于控制历史状态的保留比例。该更新机制使得神经元能够积累输入特征的历史动态。然而，为了捕捉显著事件并避免状态无限累积，LIF 层引入了脉冲发放机制。当神经元状态 $u_j[t]$ 超过设定的阈值 $V_{\text{th}}$ 时，神经元会发放一个脉冲信号 $s_j[t] = 1$，同时将状态重置为 $u_j[t] = 0$；否则，神经元维持累积状态且不发放脉冲，即 $s_j[t] = 0$。这一机制可以简述为：
% where, $\beta \in (0,1)$ is the decay coefficient that controls the proportion of the historical state retained. This update mechanism allows the neuron to accumulate the historical dynamics of the input features. However, to capture significant events and prevent unlimited state accumulation, the LIF layer introduces a spiking mechanism. When the neuron’s state $u_j[t]$ exceeds a predefined threshold $V_{\text{th}}$, the neuron emits a spike signal $s_j[t] = 1$ and resets its state to $u_j[t] = 0$. Otherwise, the neuron maintains its accumulated state and does not emit a spike, setting $s_j[t] = 0.$ This mechanism is summarized as follows:
% \begin{equation}
%     s_j[t] =
%     \begin{cases}
%     1, & u_j[t] \geq V_{\text{th}} \\
%     0, & \text{otherwise}
%     \end{cases}
% \end{equation}
% %这种设计通过强化输入特征的显著动态变化（如突变或峰值），有效提取时间序列中的关键模式，同时抑制无关或噪声信号的影响。通过状态的自然衰减，未能达到阈值的低幅波动逐渐消失，使得神经元输出对动态模式具有更高的敏感性。
% This design enhances significant dynamic changes in the input features, such as sudden shifts or peaks, to effectively extract key patterns from the time series. At the same time, it suppresses irrelevant or noisy signals. Low amplitude fluctuations that do not reach the threshold gradually decay naturally, allowing the neuron output to become more sensitive to dynamic patterns.

% % LIF 层处理后的输出以脉冲矩阵 $\mathbf{S} \in {0,1}^{12 \times 24}$ 表示，其中 $s_j[t]$ 记录第 $j$ 个神经元在时间步 $t$ 的脉冲状态。虽然神经元独立建模每个特征维度的时间序列，但 LIF 层输出矩阵仍保持了时间步的全局对齐关系，这使得后续网络能够在空间上通过特征维度的整合进一步挖掘时序关联。这一设计在有效降低计算复杂度的同时，保留了输入序列的关键时间动态模式。
% The output of the LIF layer is represented as a spike matrix $\mathbf{S} \in \{0,1\}^{[12, 24]}$, where $s_j[t]$ records the spike state of the $j_{th}$ neuron at time step t. While each neuron models the time series of a specific feature dimension independently, the output matrix maintains global alignment across time steps. This design allows subsequent network layers to integrate spatial features across dimensions and further explore temporal correlations. It effectively reduces computational complexity while preserving the key temporal dynamics of the input sequence.

% % 接下来，为了提取时间序列的整体特征，网络对 LIF 层的输出在时间维度上进行平均操作，将 12 帧的动态信息融合为一个 $1 \times 24$ 的特征向量。这一步骤不仅有效降低了计算复杂度，还保留了输入特征中的关键动态信息。随后，压缩后的 $1 \times 24$ 特征向量被输入到 Linear 3 层，该层将特征映射到 3 维输出空间，对应三种换道意图类别。通过 Softmax 激活函数，网络的输出被转换为概率分布，用于预测当前时刻的换道意图。
% Next, to extract the overall features of the time series, the network averages the output of the LIF layer along the time dimension as follows:
% \begin{equation}
% \bar{S}j = \frac{1}{12} \sum{t=1}^{12} S_j[t], \quad \forall j \in {1,\dots,24}
% \end{equation}

% This operation fuses the dynamic information from 12 frames into a single [1, 24] feature vector. This step effectively reduces computational complexity while retaining the critical dynamic information in the input features. The compressed [1, 24] feature vector is then fed into a Linear 3 layer, which maps the features to a 3-dimensional output space corresponding to the three lane-change intention categories. Finally, the network applies a Softmax activation function to convert the output into a probability distribution, enabling the prediction of lane-change intentions at the current time step. The Softmax function is defined as follows:
% \begin{equation}
% P_i = \frac{\exp(z_i)}{\sum_{k=1}^{3} \exp(z_k)}, \quad i \in \{0, 1, 2\}
% \end{equation}
% where $z_i$ is the $i_{th}$ output of the Linear 3 layer, and $P_i$ represents the probability of the $i_{th}$ lane-change intention category.

% % 在模型训练过程中，我们使用监督学习方法，目标是使预测的意图概率分布与真实的标签分布尽可能接近。为此，模型采用负对数似然损失（NLLLoss）作为损失函数，其定义为：
% During model training, we use a supervised learning approach. The goal is to make the predicted intention probability distribution as close as possible to the true label distribution. To achieve this, the model adopts negative log-likelihood loss (NLLLoss) as the loss function:
% \begin{equation}
%     \mathcal{L} = - \frac{1}{N} \sum_{i=1}^N \log P(a_t^{(i)} | s_t^{(i)})
% \end{equation}
% where \( a_t^{(i)} \) represents the true intention at time step \( t \) for the \( i_{th} \) sample, and \( s_t^{(i)} \) denotes the corresponding input state at time step \( t \). \( P(a_t | s_t) \) is the predicted probability of the true class, and \( N \) denotes the batch size, which is set to 128 in this study. By minimizing this loss function, the model gradually learns the dynamic patterns of vehicle lane-changing behavior, achieving improved performance in lane-change intention prediction tasks.
% % 该模型通过脉冲神经网络的时间动态建模和特征融合，有效捕捉了车辆状态的时间关联性，提升了换道意图预测的准确性。
% The model combines the feature fusion and extraction capabilities of spiking neural networks and linear layers to effectively capture the temporal dependencies in vehicle states. This design improves the accuracy of lane-change intention prediction.

\subsection{Model Training}
The training process involves detailed data transformations and computations within each component of the model. The input to the model is a time-series matrix $\mathbf{X} \in \mathbb{R}^{[12, 5]}$ of vehicle state features, which first undergoes a feature expansion step through a linear layer. This layer transforms the input dimensions from $(12, 5)$ to a $(12, 24)$ matrix $\mathbf{I} \in \mathbb{R}^{[12, 24]}$ by applying a linear transformation:
\begin{equation}
\mathbf{I} = \mathbf{X}\mathbf{W} + \mathbf{b}
\end{equation}
where $\mathbf{W}$ and $\mathbf{b}$ are the weight matrix and bias vector of the linear layer. This expansion improves the expressive power of the features.

The expanded feature matrix is then processed by the LIF layer, which models temporal dependencies using a neuron state update mechanism. Each neuron processes a specific feature dimension independently, with its state updated iteratively across time steps:
\begin{equation}
u_j[t] = \beta \cdot u_j[t-1] + I[t,j]
\end{equation}
where $\beta \in (0,1)$ is the decay coefficient that controls the retention of historical states. When the neuron’s state exceeds a predefined threshold, it emits a spike, resetting its state:
\begin{equation}
    s_j[t] =
    \begin{cases}
    1, & u_j[t] \geq V_{\text{th}} \\
    0, & \text{otherwise}
    \end{cases}
\end{equation}

The output of the LIF layer is a spike matrix $\mathbf{S} \in {0,1}^{[12, 24]}$. To extract global temporal features, the spike matrix is averaged along the time dimension:
\begin{equation}
\bar{S}j = \frac{1}{12} \sum{t=1}^{12} S_j[t], \quad \forall j \in {1, \dots, 24}
\end{equation}
This produces a $(1, 24)$ feature vector, which is then passed through a linear layer that maps the features to a 3-dimensional output corresponding to the three lane-changing intention categories. Finally, a Softmax activation function is applied to convert the outputs into a probability distribution:
\begin{equation}
P_i = \frac{\exp(z_i)}{\sum_{k=1}^{3} \exp(z_k)}, \quad i \in {0, 1, 2}
\end{equation}
where $z_i$ is the $i_{th}$ output, and $P_i$ represents the predicted probability of the $i_{th}$ lane-changing intention.

The model is trained using supervised learning, with the goal of minimizing the difference between the predicted probability distribution and the true labels. Negative log-likelihood loss (NLLLoss) is used as the loss function:
\begin{equation}
\mathcal{L} = - \frac{1}{N} \sum_{i=1}^N \log P(a_t^{(i)} | s_t^{(i)})
\end{equation}
where  $a_t^{(i)}$  represents the true lane-changing intention at time step  $t $ for the  $i_{th}$  sample, and $ s_t^{(i)}$  is the corresponding input state. $ P(a_t | s_t)$  denotes the predicted probability of the true class, and  N  is the batch size, set to 128 in this study.

Through iterative optimization, the model learns to effectively capture the dynamic patterns in vehicle state features, leading to improved performance in lane-changing intention prediction tasks.


\section{Experimental Result}
This section presents the experimental results to evaluate the effectiveness and efficiency of the proposed SNN-based lane-changing intention prediction model in comparison with the ESN method and LSTM method. We train our model on HighD and NGSIM datasets, and the evaluation is conducted from three perspectives: training performance, two sample cases, and overall evaluation. All experiments, including model training and testing, are conducted on an Apple M2 CPU. First, we analyze the model’s training process by comparing the time required per epoch and loss, demonstrating the superior efficiency of our approach. Second, we evaluate the model’s practical application in specific scenarios, showing that our predictions align closely with the ground truth lane-changing moments, outperforming baseline methods in dynamic traffic environments. Finally, an overall evaluation is presented, highlighting the performance of our method compared to ESN and LSTM. 

\subsection{Model Training}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{time.png}
    \caption{Comparison of average training time per epoch for our approach, LSTM, and ESN on the HighD and NGSIM datasets.}
    \label{time}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{loss.png}
    \caption{Loss curves for SNN, ESN, and LSTM on the HighD (a) and NGSIM (b) datasets}
    \label{loss}
\end{figure}
% 在本节中，我们展示了我们方法的训练效果，包括训练时间和 loss 曲线的表现，并与 ESN 和 LSTM 方法进行了对比。
In this section, we present the training performance of our approach, ESN, and LSTM methods, including the training time and the loss curve. We train the models of the three approaches on the full HighD and NGSIM datasets.

% 首先，我们展示了训练时间的表现。我们在 HighD 和 NGSIM 两个数据集上分别进行了 500 个 epoch 的训练，结果如图\ref{time}所示。图中蓝色坐标轴表示 HighD 数据集上的训练时间，红色坐标轴表示 NGSIM 数据集上的训练时间。柱状图展示了 500 个 epoch 中每轮训练时间的平均值，误差条（error bar）则展示了训练时间的最大最小值。在 HighD 数据集中，我们的方法每轮平均训练时间为 0.72 秒，LSTM 方法为 2.38 秒，ESN 方法为 0.84 秒；在 NGSIM 数据集中，我们的方法每轮平均训练时间为 0.016 秒，LSTM 方法为 0.048 秒，ESN 方法为 0.018 秒。实验结果表明，我们的方法在训练效率上显著优于 LSTM 方法，同时略优于 ESN 方法，尤其是在 NGSIM 数据集上表现尤为突出。
First, we present the training time performance. We train the three models on the HighD and NGSIM datasets for 500 epochs and show the training time results, as shown in Figure \ref{time}. The blue axis represents the training time on the HighD dataset, while the red axis represents the training time on the NGSIM dataset. The bar chart illustrates the average training time per epoch across 500 epochs, with the blue bars representing the HighD dataset and the red bars representing the NGSIM dataset. The error bars indicate the maximum and minimum training times. On the HighD dataset, our approach achieves an average training time of 0.72 s per epoch, compared to 2.38 s for LSTM and 0.84 s for ESN. On the NGSIM dataset, our approach achieves 0.211 s per epoch, compared to 0.731 s for LSTM and 0.257 s for ESN. These results demonstrate that our approach significantly outperforms LSTM in training efficiency and slightly outperforms ESN, particularly on the NGSIM dataset.

% 接着，我们展示了模型的 loss 曲线。训练过程中，当 loss 值在 50 轮内不再下降时，我们停止训练。如图\ref{loss}所示，横坐标表示训练轮次，纵坐标表示 loss 值。蓝色曲线代表我们的方法，红色和黄色曲线分别代表 ESN 和 LSTM 方法。图\ref{loss}a 展示了三种方法在 HighD 数据集上的 loss 曲线：我们的方法在 522 轮后收敛于 0.045，ESN 方法在 912 轮后收敛于 0.387，LSTM 方法在 639 轮后收敛于 0.0015。图\ref{loss}b 展示了三种方法在 NGSIM 数据集上的 loss 曲线：我们的方法在 1492 轮后收敛于 0.050，ESN 方法在 852 轮后收敛于 0.225，LSTM 方法在 1489 轮后收敛于 0.0。实验结果表明，我们的方法在 HighD 数据集上收敛速度显著快于 ESN 和 LSTM 方法，而在 NGSIM 数据集上，尽管收敛轮次较长，但最终 loss 值与 LSTM 方法接近，且显著优于 ESN 方法。
Next, we present the loss curves of the models. During training, we stop when the loss value does not decrease within 50 epochs. As shown in Figure \ref{loss}, the horizontal axis represents the number of training epochs, and the vertical axis represents the loss value. The blue curve represents our method, the red curve represents the ESN method, and the yellow curve represents the LSTM method. Figure \ref{loss}a shows the loss curves for the three methods on the HighD dataset. Our method converges at 0.045 after 522 epochs, while the ESN method converges at 0.387 after 912 epochs, and the LSTM method converges at 0.0015 after 639 epochs. Figure \ref{loss}b shows the loss curves on the NGSIM dataset. Our method converges at 0.032 after 945 epochs, the ESN method converges at 0.044 after 1076 epochs, and the LSTM method converges at 0.0 after 1090 epochs. The results indicate that our method achieves significantly faster convergence on the HighD dataset compared to ESN and LSTM. On the NGSIM dataset, although our method requires more epochs to converge than ESN, the final loss value is comparable to LSTM and significantly better than ESN.

% 总而言之，我们的方法在训练效率和模型性能上均表现出色。与 LSTM 方法相比，我们的方法在训练时间上具有显著优势，同时 loss 收敛性能与 LSTM 方法相当；与 ESN 方法相比，我们的方法在 loss 收敛性能和训练时间上明显更优。这证明了我们的方法在兼顾高效训练和优异性能方面的潜力。
In summary, our method performs exceptionally well in training efficiency. Compared to the LSTM method, our method shows a significant advantage in training time while achieving comparable loss convergence performance. Compared to the ESN method, our method demonstrates superior performance in both loss convergence and training time. These results highlight the potential of our method to achieve efficient training and excellent performance simultaneously.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.9\textwidth]{case.png}
    \caption{Comparison of lane-changing intention predictions for SNN, LSTM, and ESN models in the HighD (a) and NGSIM (b) datasets. The blue, red, and yellow curves represent predictions from the SNN, LSTM, and ESN models, respectively. Our method predicts lane-changing accurately, with no false predictions.}
    \label{case}
\end{figure*}


\subsection{Two Sample Cases}

This section illustrates the deployment performance of our SNN model compared to the ESN and LSTM models in the HighD and NGSIM scenarios through two sample cases. The analysis includes scenario visualizations and lane-changing intention prediction curves. In Figure \ref{case}, the selected vehicles are highlighted in yellow, with their trajectories represented by red dashed lines. Other vehicles are marked with different colors, and their trajectories are represented by black dotted lines. The lane-changing intention prediction curves are shown, with black dashed lines indicating the lane-changing moments in the original data. The blue curve represents the predictions of our method, while the red and yellow curves represent the predictions from the LSTM and ESN methods, respectively.

Figure \ref{case}a shows a scenario from the HighD dataset, where a vehicle turns right at time-step 115. Experimental results show that the proposed method predicts the lane-changing intention at time-step 60, the LSTM method at time-step 61, and the ESN method at time-step 59. However, the ESN method makes a false prediction at time-step 170.
Figure \ref{case}b shows a scenario from the NGSIM dataset, where a vehicle turns left at time-step 170. Experimental results show that the proposed method predicts the lane-changing intention at time-step 120, the LSTM method at time-step 121, and the ESN method at time-step 119. However, the ESN method produces a significant false prediction at time-step 50.

In summary, the comparative experiments demonstrate that the proposed method performs exceptionally well in lane-changing intention prediction tasks. Our method produces no false predictions and maintains stable performance across different datasets and scenarios. These results confirm the effectiveness and reliability of the proposed method in practical applications.



\subsection{Overall Evaluation}



\begin{table*}[b]
\centering
\caption{Comparison of Models on HighD and NGSIM Datasets}
\label{tab:comparison}

\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Model} & \textbf{Dataset} & \textbf{Parameters} & \textbf{Memory Usage} & \textbf{Training Time} & \textbf{Accuracy} \\ \midrule
\textbf{SNN}   & HighD            & \textbf{219}                 & \textbf{0.01 MB}              & \textbf{375 s}                 & 0.9828                                 \\
\textbf{ESN}   & HighD            & 1,503               & 0.04 MB              & 766 s                 & 0.8876                                        \\
\textbf{LSTM}  & HighD            & 269,059             & 80.81 MB             & 1520 s                 & \textbf{0.9983}                                        \\ \midrule
\textbf{Model} & \textbf{Dataset} & \textbf{Parameters} & \textbf{Memory Usage} & \textbf{Training Time} & \textbf{Accuracy}  \\ \midrule
\textbf{SNN}   & NGSIM            & \textbf{219}                 & \textbf{0.01 MB}              & \textbf{199 s }               & 0.9426                                   \\
\textbf{ESN}   & NGSIM            & 1,503               & 0.04 MB              & 276 s                & 0.9043                                       \\
\textbf{LSTM}  & NGSIM            & 269,059             & 80.81 MB             & 796 s                &\textbf{ 0.9809 }                                  \\ \bottomrule
\end{tabular}%

\end{table*}
% 本节我们展示了我们的方法的整体表现, 并与 esn 和 LSTM 方法进行对比, 表 1 显示了这三种方法在参数量, 内存占用, 整体训练时间, 准确率上的表现

% 从表中可知, 我们的方法的参数量仅为 xx, 内存占用为xx, 在HighD 数据集上 xxx s 完成收敛, 准确率达到了 xxx, 而在 ngsim 数据集上 xxx s 完成收敛, 准确率达到了 xxx
% ESN方法的参数量仅为 xx, 内存占用为xx, 在HighD 数据集上 xxx s 完成收敛, 准确率达到了 xxx, 而在 ngsim 数据集上 xxx s 完成收敛, 准确率达到了 xxx
% LSTM方法的参数量仅为 xx, 内存占用为xx, 在HighD 数据集上 xxx s 完成收敛, 准确率达到了 xxx, 而在 ngsim 数据集上 xxx s 完成收敛, 准确率达到了 xxx

% 结果表明, 我们的方法在参数量,内存占用和训练时间上远高于另外两种方法, 体现出极高的训练效率和部署优势, 我们的方法在准确率上也远高于ESN 方法, 虽然略低于 LSTM 方法,xxx

This section presents the overall performance of our method compared to ESN and LSTM, including Receiver Operating Characteristic (ROC) curves and a summary table of the overall results. The ROC curves in Figure \ref{roc} illustrate the prediction accuracy \cite{mandrekar2010receiver}. Table \ref{tab:comparison} summarizes the results in terms of parameters, memory usage, training time, and accuracy.



First, Figure \ref{roc} presents the accuracy results of the three methods. The horizontal axis represents the False Positive Rate (FPR), which is the proportion of negative samples incorrectly predicted as positive. The FPR is calculated as:
\begin{equation}
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
\end{equation}
where $\text{FP}$ (False Positive) is the number of negative samples incorrectly predicted as positive, and $\text{TN}$ (True Negative) is the number of negative samples correctly predicted as negative. The vertical axis represents the True Positive Rate (TPR), which is the proportion of positive samples correctly predicted as positive. The TPR is calculated as:
\begin{equation}
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}
where $\text{TP}$ (True Positive) is the number of positive samples correctly predicted as positive, and $\text{FN}$ (False Negative) is the number of positive samples incorrectly predicted as negative.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.49\textwidth]{roc.png}
    \caption{ROC curves for SNN, LSTM, and ESN on the NGSIM (a) and HighD (b) datasets. The blue, red, and yellow curves represent the SNN, LSTM, and ESN methods, respectively.}
    \label{roc}
\end{figure}

The curves in Figure \ref{roc} are the ROC curves, which reflect the model’s performance under different classification thresholds. The ROC curve plots the TPR against the FPR at various classification thresholds, and the area under the curve (AUC) is used to quantify the overall performance. A ROC curve closer to the top-left corner, with a higher AUC value, reflects better classification accuracy \cite{moses1993combining}.
Figure \ref{roc}a shows the ROC curves of the three methods on the NGSIM dataset. The AUC value of our method is 0.9925, the AUC value of the LSTM method is 0.9955, and the AUC value of the ESN method is the lowest at 0.9793. Figure \ref{roc}b shows the results on the HighD dataset. The AUC value of our method is 0.9994, the LSTM method achieves 0.9997, and the ESN method achieves 0.9503.
These results demonstrate that our method performs excellently in prediction accuracy, achieving results comparable to the LSTM method while significantly outperforming the ESN method. Moreover, our method significantly outperforms the LSTM approach in terms of training efficiency, which underscores the advantage of our approach in effectively balancing both high accuracy and efficiency.


Then, as shown in Table \ref{tab:comparison}, our method has only 219 parameters, requires 0.01 MB of memory, converges in 375 s on the HighD dataset with an accuracy of 0.9828, and converges in 199 s on the NGSIM dataset with an accuracy of 0.9426. 
The ESN method has 1,503 parameters, requires 0.04 MB of memory, converges in 766 s on the HighD dataset with an accuracy of 0.8876, and converges in 276 s on the NGSIM dataset with an accuracy of 0.9043. 
The LSTM method, with 269,059 parameters and 80.81 MB of memory usage, achieves convergence in 1520 s on the HighD dataset with an accuracy of 0.9983, and in 796 s on the NGSIM dataset with an accuracy of 0.9809. These results demonstrate that our method significantly outperforms the ESN method in terms of parameters, memory usage, and training time while achieving high accuracy. Compared to the LSTM method, our approach offers substantial advantages in efficiency and resource utilization, with only a slight trade-off in accuracy.

In summary, the proposed method shows a compelling balance between accuracy and deployment efficiency. It not only delivers prediction performance comparable to LSTM but also demonstrates significant advantages in terms of resource consumption, training speed, and ease of deployment. Our approach is particularly well-suited for real-time applications and resource-limited environments, offering substantial benefits in both accuracy and deployment efficiency.


\section{Conclusion}
% 本文提出了一种基于脉冲神经网络（SNN）的高效换道意图预测方法，旨在解决自动驾驶系统中对周围车辆换道行为的实时准确预测问题。通过结合SNN的时间动态特性和特征融合能力，我们的方法在保证高预测准确率的同时，显著提升了训练和部署效率。

% 实验结果表明，与LSTM和ESN方法相比，本文方法在训练效率上分别提高了约67%和66%，同时在预测准确率上与LSTM方法相当，显著优于ESN方法。在场景验证中，我们的方法能够更准确地捕捉换道时机，其预测结果与实际换道时刻的偏差最小，展现了在不同数据集和复杂场景下的稳定性能。

% 未来，我们将进一步优化模型架构，探索更高效的训练算法，并尝试将本文方法集成到实际自动驾驶系统中，验证其在真实道路环境中的性能表现。本文的研究为自动驾驶系统的安全决策提供了可靠的技术支持。
This paper proposes an efficient lane-changing intention prediction approach based on Spiking Neural Networks (SNN), addressing the critical challenge of real-time and accurate prediction of surrounding vehicles' lane-changing behavior in autonomous driving systems. By leveraging the temporal dynamics and feature fusion capabilities of SNN, our method achieves high prediction accuracy while significantly improving training and deployment efficiency. The proposed approach reduces training time by 75\% and memory usage by 99.9\% compared to baseline methods, demonstrating its potential for practical deployment in resource-constrained environments.
Experimental results show that, compared to LSTM and ESN methods, the proposed method achieves prediction accuracy comparable to LSTM and significantly outperforms ESN. In scenario validation, the proposed method accurately captures lane-changing timing, with the smallest deviation from actual lane-changing moments.

Future work will focus on optimizing the model architecture to improve both accuracy and efficiency. We will explore more scenarios to enhance the model’s adaptability. Efforts will also be made to improve prediction performance in diverse conditions. Finally, we aim to test on real-world vehicles to validate the practical effectiveness.

\section*{Acknowledgment}
This study is supported by RGC General Research Fund (GRF) HKUST16205224.

\bibliographystyle{IEEEtran}
\bibliography{main}

\end{document}
