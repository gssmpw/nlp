\section{Introduction}
\label{Introduction}

Anomaly detection is a crucial research problem within the machine learning community. Recently, there has been significant research focused on using machine learning for anomaly detection. Based on the availability of labels, anomaly detection methods can be categorized into three types: unsupervised, supervised, and semi-supervised anomaly detection. Unsupervised anomaly detection is particularly popular because it does not require labeled data, which is often scarce, allowing the algorithm to independently identify anomalies without the need for predefined labels. In contrast, supervised anomaly detection relies on labeled data, which limits the algorithm to detecting only those anomalies that it has encountered during training. Semi-supervised anomaly detection combines elements of both supervised and unsupervised approaches, enabling the handling of some labeled data alongside large amounts of unlabeled data. Among these three categories, unsupervised anomaly detection is particularly valuable because it eliminates the need for costly data labeling.

Based on the requirements for training data, unsupervised anomaly detection methods can be further divided into training-based methods and untrained methods. Training-based unsupervised methods rely on a sufficient number of anomaly-free training samples to learn the intrinsic patterns of the target object's surfaces, which then allows for the detection of anomalies. This type of unsupervised anomaly detection methods have proven effective in addressing data representation issues and managing the diverse nature of anomalies. However, they are limited by their reliance on large amounts of anomaly-free training data, which can be a significant obstacle in scenarios where data samples are scarce such as personalized manufacturing and personalized medicine. These methods are equipped with sophisticated feature extractors that perform well, and they learn from anomaly-free samples without assuming the nature of potential anomalies, theoretically enabling them to detect any anomaly type. Nonetheless, in practical applications, anomalies with sparse characteristics or patterns resembling those of anomaly-free data can result in inaccurate detections.

In contrast, untrained methods do not require any anomaly-free samples for training, meaning that anomaly detection can be performed using just a single sample. Untrained unsupervised anomaly detection is becoming increasingly valuable as it addresses some of the limitations of traditional training-based unsupervised anomaly detection methods. While current untrained methods still require certain assumptions about anomalies, they offer a flexible and resource-efficient alternative, especially in situations where access to extensive anomaly-free datasets is not feasible such as personalized manufacturing and personalized medicine. By not relying on predefined feature extractors or large datasets, untrained methods can adapt to various data and anomaly types. This flexibility allows them to effectively detect anomalies that might be rare, subtle, or closely resemble normal data. Such adaptability is crucial in real-world applications, where the nature of anomalies is often unpredictable and varied. Therefore, untrained unsupervised anomaly detection is essential for advancing the capability and reliability of anomaly detection systems.

Developing untrained machine learning methods for anomaly detection presents three key challenges. First, effectively representing high-dimensional data for anomaly detection is a complex task. High-density 3D point cloud data can encompass millions of unstructured points, making it difficult to represent and creating hurdles for real-time computation. Second, having only one sample for anomaly detection makes it challenging to learn features and build an effective model. This necessitates a comprehensive utilization of prior knowledge, yet integrating this knowledge into the model remains a significant challenge. Finally, anomalies can appear locally, vary greatly, and are often sparse across objects. New anomalies can arise unexpectedly, and even anomalies of the same type can show significant differences, making detection difficult. Moreover, anomalies are typically sparse on object surfaces, constituting only a small part of the anomaly sample area, which makes the task of learning anomaly features even more difficult.

To address these challenges, several initial efforts have been made, including local geometry-based methods \cite{wang2023mvgcn}, sparse learning-based approaches \cite{tao2025pointsgrade}, and statistical methods \cite{tao2023anomaly}. A more detailed review will be provided in the following section. However, many research problems still need to be addressed. To advance the current state of untrained machine learning for anomaly detection, this paper first formally defines the anomaly detection problem via untrained machine learning. Then three potential research methodology frameworks are proposed, along with three specific examples for each framework. Finally, the paper concludes with a discussion of the conclusions and future outlook for untrained machine learning in anomaly detection.

\section{Paper Review}
In the realm of manufacturing, anomaly detection using 3D point cloud data has witnessed a significant shift towards unsupervised methods, primarily due to the scarcity of annotated data. These unsupervised approaches can be broadly categorized into training-based methods and untrained methods, each with its own characteristics and applications \cite{tao2023anomaly,cao_survey_2024,rani_advancements_2024}.
training-based unsupervised methods operate under the assumption that sufficient anomaly-free training samples are available. This enables them to learn the intrinsic patterns of normal surfaces, which are then used to detect anomalies. There are two main techniques within this category: feature embedding and reconstruction \cite{cao_complementary_2024,chu_shape-guided_2023,horwitz_back_2023,wang_multimodal_2023}.
Feature embedding-based methods involve a two-step process. First, latent features are extracted from anomaly-free training data. For example, in memory bank-based methods like Back To the Feature (BTF) \cite{horwitz_back_2023}, traditional descriptors such as FPFH are used to extract features from training point cloud patches, and these features are stored in a memory bank. The memory bank is then downsampled to represent the distribution of normal features. During inference, features that deviate significantly from this distribution are flagged as anomalies. Another approach is to use knowledge distillation (KD). Methods like 3D-ST \cite{bergmann_anomaly_2023} transfer knowledge from a pre-trained teacher network (e.g., RandLA-Net \cite{hu_learning_2022}) to a student network. The student network is trained on anomaly-free data to mimic the teacher's output, and during inference, discrepancies between the two are used to calculate anomaly scores.

Reconstruction-based methods aim to achieve anomaly detection at the point level. Autoencoder-based methods, such as EasyNet \cite{chen_easynet_2023}, use a feature encoder and decoder to reconstruct input 3D point cloud data. Trained only on anomaly-free data, they calculate anomaly scores based on the discrepancies between the input and the reconstructed data. For instance, EasyNet employs a multi-scale, multi-modality feature encoder-decoder for 3D depth map reconstruction, enabling real-time detection. However, some autoencoder-based methods like EasyNet and Cheating Depth \cite{zavrtanik_cheating_2024} require structured depth maps as input and struggle with unstructured point clouds. To address this, Li et al. \cite{li_towards_2023} proposed the self-supervised Iterative Mask Reconstruction Network (IMRNet) for unstructured point cloud reconstruction and anomaly detection. Principal component analysis (PCA)-based methods, like those by Von Enzberg and Al-Hamadi \cite{von_enzberg_multiresolution_2016} and Zhang et al. \cite{zhang_automatic_2018}, identify normal patterns through principal components from training data and use them to reconstruct test samples for anomaly detection.
Despite their effectiveness, training-based methods are limited by the requirement for extensive anomaly-free training data. They also face challenges in accurately detecting anomalies with sparse properties or similar patterns to normal data. Feature embedding-based methods are good at localizing anomalies but have difficulty in obtaining accurate anomaly boundaries, while reconstruction-based methods can get more accurate anomaly boundaries but struggle with complex surface reconstruction, leading to higher false positive rates \cite{masuda_toward_2023,zavrtanik_cheating_2024,li_towards_2023,roth_towards_2022}.


Untrained methods, on the other hand, do not require training on a large dataset. 
They rely on prior knowledge to model the normal surface or possible anomalies \cite{jovancevic_3d_2017}. Local geometry-based methods explore local geometric characteristics to detect anomalies. For example, Jovan\v{c}evi'{c} et al. \cite{jovancevic_3d_2017} used a region-growing segmentation algorithm with local normal and curvature data to segment point cloud airplane surfaces. Wei et al. \cite{wei_microhardness_2021} developed local features to compute anomaly scores, and Miao et al. \cite{miao_pipeline_2022} used FPFH and normal vector aggregation for defect detection on gas turbine blades. 
Global geometry-based methods utilize the global shapes of manufacturing parts. Statistical-based methods, such as the one proposed by Tao et al. \cite{tao2023anomaly}, make assumptions about the shape of the product, like low-rankness and smoothness, and formulate the anomaly detection problem within a probabilistic framework. CAD model-based methods compare the point cloud with CAD models through rigid registration. \cite{zhao_defect_2023} used the standard iterative closest point (ICP) algorithm for 3D printing defect detection, and various improvements have been made to the ICP algorithm, such as the octree-based registration algorithm by \cite{he_octree-based_2023} to accelerate the process. Untrained methods can handle one single sample directly, which is an advantage in scenarios with limited data.

In conclusion, unsupervised anomaly detection methods for 3D point cloud data in manufacturing have made significant progress. training-based methods are suitable for scenarios with abundant anomaly-free data, while untrained methods offer a solution for situations where data is scarce. 