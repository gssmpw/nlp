%Version  5: 11th Jan
%change the first paragraph
\looseness=-1
To address the challenges of designing, testing, and verifying autonomous CPS, we propose a new \textbf{neurosymbolic framework}, \textbf{NeuroStrata}, tailored to the unique requirements of such systems. As shown in Figure \ref{fig:vision}, NeuroStrata combines neural adaptability with symbolic reasoning to enforce formal specifications across hierarchical DSLs that capture underlying safety and liveness properties. The framework structures \textit{Perception} and \textit{Planning \& Control} capabilities into high-level (symbolic-only) and middle- and low-level (neurosymbolic) modules. It ensures runtime reliability and adaptation via a two-phase process: \textit{top-down synthesis}, propagating symbolic specifications to neurosymbolic modules, and \textit{bottom-up adaptation}, where neurosymbolic outputs refine symbolic programs.


% \begin{wrapfigure}[16]{r}{0.75\textwidth}
\begin{figure*}
\centering
% \vspace{-4mm}
\includegraphics[width = 0.75\textwidth]
% \includegraphics[width = \columnwidth]
{figs/FSE25-NeuroStrata.png}
\caption{Proposed Vision for NeuroStrata: Hierarchical Neurosymbolic Programming for Autonomous CPS}
\label{fig:vision}
% \end{wrapfigure}
\end{figure*}

%Version 4: 9th Jan
%To address the challenges of testing and verifying autonomous CPS, we propose a new \textbf{neurosymbolic framework}, \textbf{NeuroStrata}, tailored to the unique requirements of such systems. As shown in Figure \ref{fig:vision}, NeuroStrata integrates scalable frameworks like Scallop~\cite{li2023scallop} with hierarchical DSLs to ensure formal specification enforcement and adaptability at all levels. This framework applies to both \textit{Perception} (context-awareness) and \textit{Planning \& Control}, employing a two-phase process: \textit{top-down synthesis (design-time)} and \textit{bottom-up adaptation (runtime)}.


\textbf{Modules.} 
%At design time, \textit{Spec Mining}, which is built on top of existing neurosymbolic distillation \cite{
%singireddy2023automaton,blazek2024automated,abir2024neuro},to extract formal safety and liveness specifications from training datasets. 
At design time, \textit{Specification Mining}, built on neurosymbolic distillation \cite{singireddy2023automaton,blazek2024automated,abir2024neuro}, extracts formal safety and liveness specifications from training datasets.
To cover more diverse safety and liveness violations and out-of-distribution scenarios beyond existing training data, we leverage recent work using large language models to analyze multi-modal sensor data \cite{zheng2024testing,deng2023target}, such as front-facing cameras in vehicles, to generate additional real-world crashes and unusual cases from various angles.
These specifications are propagated hierarchically across the system. In the perception stack, a high-level \textit{Scene Graph} encodes semantic relationships and interactions between objects (e.g., ``pedestrian crossing road''), represented as differentiable, adaptable programs that can be verified using formal tools like theorem provers. The middle-level \textit{Semantic Map} encodes spatial and semantic information such as road layouts and drivable areas, ensuring consistency with the scene graph via symbolic rules. The low-level \textit{Sensor Fusion and Signal Processing} integrates multi-modal sensor data (e.g., LiDAR, cameras, GPS) while enforcing constraints on accuracy and consistency, leveraging neurosymbolic reasoning for fusion and processing. Similarly, the planning and control stack follows a hierarchical structure. The high-level \textit{Global/Mission Planner} synthesizes deterministic programs to achieve overall system objectives, verified with formal methods such as theorem proving. The middle-level \textit{Local Planner} generates short-term trajectories that align with global plans while adapting to local changes, guided by symbolic reasoning. The low-level \textit{Actuation Control} converts trajectories into control commands (e.g., steering angle, throttle) and ensures compliance with constraints using runtime verification techniques.

\textbf{Specifications.} 
For \textit{perception}, high-level specifications govern system-wide context awareness, such as ensuring that pedestrians and vehicles do not spatially overlap in the scene graph or that all objects adhere to semantic relationships. Middle-level specifications enforce localized consistency, such as aligning lane boundaries with the semantic map and ensuring that detected objects are positioned correctly within the road layout. Low-level specifications address operational constraints, such as maintaining sensor fusion accuracy within a 0.1-meter error margin and ensuring consistent integration of multi-modal sensor data. For \textit{planning/control}, high-level specifications ensure system-wide safety and mission compliance, such as requiring the vehicle to remain within designated route bounds throughout its journey. Middle-level specifications enforce trajectory-level constraints, such as avoiding obstacles within a 2-meter radius or maintaining smooth transitions between trajectory points. Low-level specifications govern detailed actuation control, such as keeping the steering angle within physical limits and ensuring the stability of throttle and braking in response to control inputs. 
These hierarchical specifications for perception and planning/control ensure an integrated and reliable system design.
%Together, these hierarchical specifications for perception and planning/control enable a robust, consistent, and safe system design.

\textbf{Adaptation.} 
During runtime, NeuroStrata dynamically adapts its perception and planning modules to real-time data while maintaining formal specification compliance. For perception, sensor data flows upward through the hierarchy, where outputs from the low-level sensor fusion are validated against middle-level semantic map constraints, and updates propagate to the high-level scene graph. It evolves dynamically using differentiable program induction, compacting, and adapting specifications as needed. For planning and control, high-level mission planners adjust strategies based on changing conditions, while differentiable and adaptable control programs refine global plans and compact themselves in response to system data. Middle- and low-level components, such as local planners and actuation control, remain guided by symbolic reasoning to ensure safety and alignment with global objectives. This integration enables simultaneously adaptable and formally validated behavior throughout the system.

\textbf{Guarantees.} 
NeuroStrata ensures reliability through a hybrid validation framework. High-level deterministic programs, such as scene graphs and mission planners, are validated using formal verification tools like model checking and theorem proving. Middle- and low-level neurosymbolic components, such as semantic maps and sensor fusion, are guided by symbolic constraints and validated using white-box testing, runtime monitors, and error propagation analysis (e.g., approximate reachability verification~\cite{geng_bridging_2024} and conformance checking~\cite{habeeb_approximate_2024}). Together, this framework bridges the gap between deterministic high-level programs and adaptive, data-driven neuro-components, thus providing formal guarantees across all three levels of the hierarchy.



%Version 3: 8th Jan
%\begin{figure*}[tb!]
%\centering
%\includegraphics[width = 0.8\textwidth]
%{figs/FSE25vision.jpg}
%\caption{Proposed Vision for NeuroStrata: Hierarchical Neurosymbolic Programming for Autonomous CPS}
%\label{fig:vision}
%\end{figure*}
%To address the challenges of testing and verifying autonomous CPS, we propose the development of a new \textbf{neurosymbolic framework}, \textbf{NeuroStrata}, tailored to the unique requirements of such systems. As shown in Figure \ref{fig:vision},  NeuroStrata combines scalable frameworks like Scallop~\cite{li2023scallop} with hierarchical domain-specific languages (DSLs) for perception, prediction, and planning. The proposed language integrates the low-level symbolic reasoning capabilities of Scallop with the high-level hierarchical semantics of DSLs, ensuring that specifications propagate throughout all abstraction levels in the system.

%For the autonomous driving systems case study, high-level system safety and liveness properties, typically associated with the control module, are decomposed into corresponding properties for the ego-vehicle's planning, dynamic object trajectories (prediction), and perception outputs (e.g., lanes, traffic lights, obstacles). NeuroStrata enables this hierarchical transformation, ensuring safety-critical properties are verified from control (high-level) to prediction (middle-level) to perception (low-level).

%This hierarchical structure facilitates monitoring and enforcing specifications at every level. Safety and liveness properties described in the DSL guide program induction and enable the synthesis of concrete control programs. These programs are differentiable and adaptable to real-time environments, allowing dynamic adjustment of the control module based on evolving input and ensuring alignment with high-level DSL-related checkers.

%By leveraging NeuroStrata, limitations of traditional hard-coded, rule-based neurosymbolic systems are addressed through dynamic reconfiguration. For instance:
%- Path planning and prediction modules are trained and guided by DSLs to extract features and map concepts, akin to a concept learner~\cite{mao2019neuro}.
%- Trajectory prediction and planning are transformed into concrete programs that guide neural network training via backpropagation, with middle-level DSL checkers ensuring conformance to trajectory-level specifications.
%- The perception module operates similarly, with low-level DSL checkers validating object detection against symbolic specifications.

%By replacing traditional black-box AI components with modular, hierarchical neurosymbolic counterparts, NeuroStrata provides formal guarantees at each level of abstraction. The benefits include:

%\begin{itemize}
  %  \item \textbf{Perception}: Multi-modal sensor data is processed with symbolic reasoning integrated into neural networks. The low-level DSL validates fused data streams through logic-based consistency checks, ensuring reliable object detection that adheres to system specifications.
%    \item \textbf{Prediction and Planning}: Trajectory generation and motion planning use neurosymbolic paradigms validated by DSL checkers, guaranteeing safety and compliance with system requirements.
  %  \item \textbf{Control}: Deterministic yet adaptive, differentiable control programs are generated through program induction, leveraging the symbolic language to adhere to high-level safety and liveness properties.
%\end{itemize}

%NeuroStrata’s hierarchical design with compositional interfaces enables modular verification at each level while preserving system-wide guarantees. Furthermore, its integration of neurosymbolic reasoning allows the \textbf{automatic generation of high-level DSLs} as shown as the \textbf{Spec Mining} in Figure \ref{fig:vision}, overcoming scalability challenges faced by current methods like DreamCoder~\cite{ellis2021dreamcoder} or syntax-guided synthesis~\cite{bjorner2023formal}, which often rely on predefined DSLs and E-Graphs.

%NeuroStrata bridges the gap between stochastic AI components and deterministic safety-critical requirements in autonomous systems. For verification, we propose a hybrid framework combining traditional software verification techniques with symbolic reasoning as shown as \textbf{Neuro-Verifier} in Figure \ref{fig:vision}. This framework includes:
%- Formal methods (e.g., model checking, theorem proving and runtime verification) to validate symbolic layers like knowledge graphs and logical rules.
%- Error propagation analysis to assess the impact of neural network errors on symbolic reasoning, identifying failure points and ensuring robustness.

%Together, NeuroStrata enables the creation of safe, adaptable, and verifiable autonomous CPS that can handle real-world uncertainties while maintaining strict safety standards.




%Version 2: 26th Dec
%To address the challenges of testing and verifying autonomous CPS, we propose the development of a new \textbf{neurosymbolic language} tailored to the unique requirements of such systems. This language combines scalable frameworks like Scallop~\cite{li2023scallop} with domain-specific languages (DSLs) for tasks such as perception, prediction, and planning. The proposed neurosymbolic language integrates the low-logic reasoning capabilities of Scallop with the high-level hierarchical semantics of DSLs. For the autonomous driving systems case study, the high-level system safety and liveness properties, typically associated with the output of control modules, are decomposed into corresponding properties for the ego-vehicle's planning, dynamic object trajectories (prediction), and perception outputs (e.g., lane, traffic light, obstacles). This enables a hierarchical transformation of AI-enabled autonomous systems—from control (high-level) to prediction (middle-level) to perception (low-level).

%This hierarchical structure facilitates the monitoring of high-level specifications throughout the system and ensures safety and liveness properties are adhered to at each level. Safety and liveness descriptions in the DSL help monitor the input and output of the control module, guiding program induction and synthesizing concrete control programs. These control programs are differentiable and adaptable to real-time environments, making the control module incremental by continuously monitoring inputs and outputs, adapting to unknown environments, and aligning the evolving control program with high-level DSL-related checkers to ensure specification conformance.

%Such adaptable control modules solve the limitations of hard-coded, rule-based neurosymbolic systems by enabling dynamic reconfiguration. For instance, path planning and prediction modules are trained and guided by the DSL for feature extraction and concept mapping, similar to the concept learner~\cite{mao2019neuro}. In contrast, trajectory prediction and planning are transformed into concrete programs that guide neural network training (backpropagation), with the DSL-associated checker (middle-level) ensuring conformance to specifications at the trajectory level. Similarly, the perception module is constructed in a similar fashion, with a low-level DSL-associated checker operating at the object detection level. More specifcially, by leveraging the neurosymbolic paradigm, we can replace traditional black-box AI components in perception, prediction, planning, and control with modular, hierarchical alternatives that provide formal guarantees. These neurosymbolic components enable:

%\begin{itemize}
   % \item \textbf{Perception}: Symbolic reasoning is integrated with neural networks to produce interpretable decision-making for multi-modal sensor data, ensuring alignment with specifications defined in the DSL. The low-level DSL will define the relationships and dependencies between sensors, validate fused data streams through consistency checks and logic-based validation, and ensure the correct integration of sensor data for reliable object detection.
  %  \item \textbf{Prediction and Planning}: Neurosymbolic paradigms are employed for trajectory generation and motion planning, with formal guarantees validated by corresponding DSL checkers to ensure compliance with system specifications.
  %  \item \textbf{Control}: Outputs from perception, prediction, and planning modules are used to generate deterministic control programs via program induction, leveraging the proposed symbolic language to ensure adherence to system-level safety and liveness properties.
%\end{itemize}

%This hierarchical design with clear compositional interfaces facilitates modular verification at each level, ensuring system-wide guarantees are preserved. Moreover, the formal specifications extracted using neurosymbolic reasoning can \textbf{automatically generate high-level DSLs}, overcoming limitations in current methods. For example, existing techniques like DreamCoder~\cite{ellis2021dreamcoder} or syntax-guided synthesis~\cite{bjorner2023formal} rely heavily on predefined DSLs to constrain program induction. These methods are often overly simplistic or face scalability challenges due to their reliance on E-Graphs. By integrating neurosymbolic reasoning with Scallop, we can construct robust, scalable DSLs tailored to autonomous CPS, enabling more effective program induction and systematic verification. This integration bridges the gap between stochastic AI components and the deterministic requirements of safety-critical autonomous systems.

%As for the verification of neurosymbolic components challenges, we propose a hybrid verification framework that combines traditional software verification techniques with symbolic reasoning. This approach will leverage formal methods such as model checking and theorem proving to ensure the correctness of the symbolic layers, including knowledge graphs and logical rules. Additionally, we will implement error propagation analysis to trace how errors in neural networks impact the symbolic reasoning process, identifying failure points and ensuring that both the AI and symbolic components of the system function as expected. This framework will provide a more comprehensive and interpretable way to verify the safety and reliability of neurosymbolic autonomous systems. Together, these advancements pave the way for safe, adaptable, and verifiable autonomous CPS that can handle real-world uncertainties while maintaining strict safety standards.


%Version 1: 25th Dec
%To address the challenges of testing and verifying autonomous CPS, we propose the development of a \textbf{new neurosymbolic language} tailored to the unique requirements of such systems. This language combines scalable frameworks like Scallop~\cite{liang2021scallop} with domain-specific languages (DSLs) for tasks such as perception, prediction, and planning. A DSL can abstract domain-specific concepts like traffic rules, map constraints, and vehicle behavior into intuitive high-level constructs, while Scallop, as a declarative reasoning framework, provides probabilistic reasoning to handle complex, multi-modal data. For example, a DSL inspired by OpenScenario or Scenic could define traffic laws and road conditions, while Scallop reasons about these rules to adapt to unseen ``long-tail'' scenarios caused by covariate shifts (e.g., input distributions differing from training datasets). This integration enables reasoning over stochastic components, ensuring adaptability and interpretability by symbolically representing and reasoning about the uncertainties inherent in such systems.

%Building on this foundation, we envision a framework that integrates neurosymbolic paradigms across critical modules of autonomous CPS, enabling systematic and hierarchical improvements in \textbf{testability} and \textbf{verification}:

%First, we aim to \textbf{extract formal specifications} from data-driven components using neurosymbolic reasoning. Often, the difficulty lies in defining accurate specifications, which can have a more significant impact than implementation errors. Symbolic reasoning can capture system invariants and constraints from training data or domain knowledge, providing a formal basis for rigorous testing of AI components such as perception and planning.

%Second, we propose replacing traditional black-box AI components in perception, prediction, planning, and control with neurosymbolic alternatives that are both hierarchical and compositional. 
%\begin{itemize}
 %   \item \textbf{Perception}: Symbolic reasoning is integrated with neural networks to enable interpretable decision-making for multi-modal sensor data, ensuring alignment with underlying specifications defined in the DSL.
 %   \item \textbf{Prediction and Planning}: Neurosymbolic paradigms are employed for trajectory generation and motion planning, with built-in formal guarantees. These components are guided by the proposed DSL and validated by a corresponding checker to align decisions with specifications.
  %  \item \textbf{Control}: Outputs from the perception, prediction, and planning modules are leveraged to generate deterministic control programs through program induction using the proposed symbolic language. This ensures adherence to system-level safety and liveness properties.
%\end{itemize}
%By designing these components hierarchically, with clear compositional interfaces, we facilitate modular verification at each level while preserving system-wide guarantees.

%Moreover, the \textbf{formal specifications extracted} using neurosymbolic paradigms can \textbf{automatically generate high-level DSLs}, overcoming limitations in current approaches. For example, existing methods like DreamCoder~\cite{ellis2021dreamcoder} or syntax-guided synthesis~\cite{gao2022formal} rely heavily on predefined DSLs to constrain program induction. However, these approaches are often too simplistic or face scalability issues due to their underlying structures (e.g., E-Graphs). By integrating neurosymbolic reasoning with Scallop, we can construct robust and scalable DSLs tailored to autonomous CPS, enabling better program induction and systematic verification. This automated DSL generation bridges the gap between stochastic AI components and the deterministic requirements of safety-critical autonomous systems.Together, these advancements pave the way for safe, adaptable, and verifiable autonomous CPS, capable of handling real-world uncertainties while maintaining strict safety standards.


%To address the challenges posed by testing and verifying autonomous CPS, we envision leveraging neurosymbolic paradigms to fundamentally enhance the testability and verifiability of these systems. Neurosymbolic approaches combine the statistical power of neural networks with the expressiveness and interpretability of symbolic reasoning. In this vision, we propose a framework that integrates neurosymbolic paradigms across critical modules of autonomous CPS, enabling systematic and hierarchical improvements in testability and verification.

%First, we aim to \textbf{extract formal specifications} from data-driven components using neurosymbolic reasoning. Often in practice, the issue is that it is unclear what the specification for a component or task should be, and the errors in specifications can be more impactful than implementation issues. This approach enables the creation of precise, interpretable specifications that can facilitate model-based testing. For example, symbolic reasoning can be applied to capture system invariants and constraints derived from training data or domain knowledge, providing a formal basis for rigorous testing of AI components such as perception and planning.

%Second, we propose replacing key components of perception, prediction, planning, and control with \textbf{compositional and hierarchical neurosymbolic alternatives}. For instance, the perception module, traditionally dominated by black-box neural networks, can incorporate symbolic reasoning to handle multi-modal sensor data with interpretable decision-making. Similarly, the prediction and planning modules can utilize neurosymbolic paradigms to enable trajectory generation and motion planning with built-in formal guarantees. The control module can then leverage these neurosymbolic outputs to ensure actuation commands adhere to system-level safety and liveness properties. By designing these components hierarchically, with clear compositional interfaces, we enable modular verification at each level while preserving system-wide guarantees.


%To achieve the above vision, we advocate for the development of a \textbf{new neurosymbolic language} tailored to autonomous CPS. Building on the foundation of scalable frameworks like Scallop~\cite{liang2021scallop}. More specifically, we would like to combine Scallop with high-level Domain specific language (
%DSL) for autnomous CPS. In the context of autonomous driving systems, combining Scallop with a DSL tailored for tasks such as perception, prediction, and planning holds significant promise. A DSL can abstract domain-specific concepts like traffic rules, map constraints, and vehicle behavior into intuitive high-level constructs, while Scallop, as a declarative reasoning framework, provides probabilistic reasoning capabilities to handle complex, multi-modal data. For instance, a DSL based on OpenScenario or Scenic could define traffic laws or specific road conditions, while Scallop reasons about these rules to adapt to unseen ``long-tail'' scenarios caused by covariate shifts (e.g., input distributions differing from training datasets). This integration enables reasoning over stochastic components, such as object detection and prediction modules, to ensure adaptability and interpretability by symbolically representing and reasoning about the uncertainties inherent in such systems. 

%Once again, the formal specifications extracted using neurosymbolic paradigms can automatically generate the corresponding high-level DSL, addressing a key limitation in current approaches. For example, existing approaches such as DreamCoder~\cite{ellis2021dreamcoder}, which uses a wake-sleep library learning framework and E-Graph, and syntax-guided synthesis approaches for formal explainable AI (XAI)~\cite{gao2022formal}, rely on DSLs to constrain the program induction space. However, these approaches are either too simplistic, as in the XAI paper, or face scalability issues, as the underlying structures (e.g., E-Graphs) are not well-suited for handling complex, domain-specific requirements. To overcome these challenges, a neurosymbolic framework integrated with Scallop can enable the automatic construction of domain-specific languages that are robust, expressive, and scalable. This automatic generation of DSLs would allow for better constraints in program induction, enhancing the ability of autonomous driving systems to handle dynamic environments, ensure safety, and support systematic verification. Together, these advancements can bridge the gap between stochastic AI components and the deterministic requirements of safety-critical autonomous CPS. 



%In the context of autonomous driving systems, combining Scallop with a DSL tailored for tasks such as perception, prediction, and planning holds significant promise. A DSL can abstract domain-specific concepts like traffic rules, map constraints, and vehicle behavior into intuitive high-level constructs, while Scallop, as a declarative reasoning framework, provides probabilistic reasoning capabilities to handle complex, multi-modal data. For instance, a DSL based on OpenScenario or Scenic\cite{} \tocheckJZ{my google citations capabilities are constrained in China} could define traffic laws or specific road conditions, while Scallop reasons about these rules to adapt to unseen ``long-tail'' scenarios caused by covariate shifts (e.g., input distributions differing from training datasets). This integration enables reasoning over stochastic components, such as object detection and prediction modules, to ensure adaptability and interpretability by symbolically representing and reasoning about the uncertainties inherent in such systems. Moreover, Scallop’s explainable and modular reasoning engine can address scalability issues by processing these rules hierarchically and supporting efficient decision-making in dynamic real-world environments. Together, this combination can bridge the gap between current stochastic AI models and the deterministic requirements of safety-critical autonomous CPS, offering a pathway for robust, verifiable, and interpretable decision-making in autonomous driving.


%the proposed language would support domain-specific reasoning and learning, enabling efficient integration of neural and symbolic computations across the system. This language would allow for the co-design of neurosymbolic components, ensuring seamless interaction and consistency between modules while facilitating rigorous testing and verification.

%This vision establishes a roadmap for leveraging neurosymbolic paradigms to not only bridge the gap between data-driven learning and formal reasoning but also to create a systematic approach for the design, testing, and verification of autonomous CPS. By integrating these advancements, we aim to address the current limitations of testing and verification efforts, paving the way for safer and more reliable autonomous systems.\tocheckJZ{To Ruzica, Ivan and Ziyang, and the rest: I have outlined a high-level design here, which should be sufficient for drafting the initial results in the next section. Please feel free to review and suggest updates if you notice anything important missing. I plan to add more specific details next week.}