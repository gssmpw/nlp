The integration of machine learning (ML) into CPS has driven innovations in autonomous vehicles~\cite{Waymo, Tesla, Uber}, delivery drones~\cite{AmazonPrimeAir, GoogleWing, Zipline}, and robotic surgeries~\cite{DaVinci, Mazor, Mako}. While ML enhances autonomy and intelligence, its uncertain and brittle nature, as witnessed in softmax-based classifications and regression-based control, undermines traditional formal verification, necessitating novel solutions.
%The integration of machine learning (ML) into cyber-physical systems (CPS) has transformed industries such as transportation, logistics, healthcare, and robotics, with innovations including autonomous vehicles (e.g., Waymo~\cite{Waymo}, Tesla Autopilot~\cite{Tesla}, Uber ATG~\cite{Uber}), delivery drones (e.g., Amazon Prime Air~\cite{AmazonPrimeAir}, Google Wing~\cite{GoogleWing}, Zipline~\cite{Zipline}), and robotic surgeries (e.g., Da Vinci~\cite{DaVinci}, Mazor~\cite{Mazor}, Mako~\cite{Mako}). While adding ML components makes CPS more autonomous and intelligent, it also introduces stochastic behavior, such as softmax-based statistical distributions for perception classifications and regression models for actuation commands like steering and speed in control models. These challenges render decades of formal verification efforts ineffective for ML components, highlighting the need for novel solutions. 

\begin{figure*}[bt!]
\centering
\includegraphics[width = 0.85\textwidth]
{figs/driving-stack.png}
\vspace{-2mm}
\caption{Motivating system: an industrial-strength software stack for autonomous driving \cite{deng2022scenario}.}
\label{fig:ROSADS}
\end{figure*}

\textit{Neurosymbolic approaches} combine symbolic reasoning with neural learning, addressing challenges in autonomous CPSs by enabling co-training of neural components with symbolic logic through probabilistic logic programming and differentiable reasoning~\cite{cohen2017tensorlog,manhaeve2021neural,li2023scallop,lu_surveying_2024}. Advanced methods, such as program synthesis using Domain-Specific Languages (DSLs), demonstrate promise by supporting both deterministic and probabilistic programs~\cite{parisotto2016neuro,bjorner2023formal,ellis2021dreamcoder}. 
%Verion: 16 Jan 2025 JZ
However, significant bottlenecks persist, including unseen data in real-world deployments~\cite{fredrikson_learning_2023}, multi-sensor fusion challenges~\cite{strickland_deep_2018}, and the lack of neural component verification. \textit{Determinism at the decision level} of perception and mission planning is also missing, which can enable the applicability of decades-long formal verification and testing techniques.
Ensuring system-level safety and liveness requires \textit{systematic co-design} of perception, planning, and control — a critical aspect missing in current methods.
%Ensuring system-level safety and liveness demands \textit{systematic co-design} of perception, planning, and control, addressing finer-granularity properties for perception and planning and \textit{high-level guarantees} for control — gaps left by current methods.

%However, significant bottlenecks remain, including unseen data in real-world deployments~\cite{fredrikson_learning_2023}, challenges with multi-sensor fusion~\cite{strickland_deep_2018}, and the lack of verification for neural components. At the decision level of perception and mission planning, \textit{determinism is critical}, making decades-long formal verification and testing techniques applicable. Ensuring system-level safety and liveness requires \textit{systematic co-design} across perception, planning, and control, with finer-granularity properties for perception and planning, and \textit{high-level guarantees} for control — gaps that existing methods fail to address.

%However, significant bottlenecks remain. These include unseen data in real-world deployments~\cite{fredrikson_learning_2023}, difficulties with multi-sensor fusion~\cite{strickland_deep_2018}, and the lack of verification for neural components. Ensuring system-level safety and liveness requires \textit{systematic co-design} of perception, planning, and control, with finer-granularity properties for perception and planning, and \textit{high-level guarantees} for control --- which existing methods fail to provide.

%Neurosymbolic approaches, which combine symbolic reasoning with neural learning, have shown promising progress in addressing the challenges of autonomous CPSs. A dominant paradigm integrates probabilistic logic programming with differentiable reasoning, enabling co-training of neuro components with symbolic logic. Neuro outputs map to inputs to the logic program, producing deterministic results, which are differentiated and back-propagated to compute gradients for neuro components. Recent work enhances this by introducing an intermediate language under Datalog, supporting customized provenance networks for greater expressiveness and extensibility~\cite{cohen2017tensorlog,manhaeve2021neural,li2023scallop}. Another approach leverages program synthesis, utilizing Domain-Specific Languages (DSLs) to constrain and guide program induction by observing a limited number of input-output pairs. This method enables the learned language to encompass both deterministic and probabilistic programs, demonstrating significant promise~\cite{parisotto2016neuro,bjorner2023formal,ellis2021dreamcoder}. However, directly applying existing neurosymbolic paradigms to improve the testability and verifiability of autonomous CPS encounters several major bottlenecks. First, these paradigms often rely on training datasets to adapt, such as learning new concepts through differentiable reasoning~\cite{fredrikson_learning_2023}, but real-world deployments of autonomous CPS face unseen data challenges—for instance, an autonomous vehicle trained in one country may be deployed in a new city with different traffic signs and road objects, where labeled datasets are costly or infeasible to construct. Second, current approaches struggle with multi-sensor modalities or multiple sensors of the same modality~\cite{strickland_deep_2018}, which are common in autonomous driving and unmanned aerial systems. The fusion of these sensors, particularly when they involve heterogeneous data streams, poses significant challenges in maintaining data consistency and reliability. Lastly, the symbolic components generated, whether manually created or learned, are often not verified, and the synthesis process itself requires rigorous validation. Moreover, symbolic components spanning perception, planning, and control need to be systematically and compositionally co-designed to ensure system-level safety and liveness. While control typically reflects high-level system properties, perception and planning require finer-granularity formal properties. Co-designing these layers is essential for ensuring both system safety and reliable performance, a critical aspect currently lacking in existing approaches.

%Neurosymbolic approaches, which combine symbolic reasoning with neural learning, have shown promising progress in addressing these challenges. One dominant paradigm uses a Datalog-like language to formalize symbolic reasoning, enabling the integration of logical rules with neural networks for more interpretable decision-making~\cite{}. Another approach employs program synthesis, utilizing Domain-Specific Languages (DSLs) to guide the induction of programs and facilitate the training of neural networks~\cite{}. 

%However, directly applying existing neurosymbolic paradigms to improve the testability and verifiability of autonomous CPS encounters several major bottlenecks. First, current neurosymbolic paradigms often rely on training datasets to adapt, such as learning new concepts through differentiable reasoning~\cite{fredrikson_learning_2023} \tocheckJZ{add more citations later}. In real-world deployments, autonomous CPS frequently encounter unseen data—for example, autonomous vehicles trained in Country A being deployed in a new city in Country B, where traffic signs and on-road objects differ and labeled datasets are either infeasible or prohibitively expensive to construct.  Second, current approaches struggle with multiple sensor modalities or multiple sensors of the same modality\tocheckJZ{add citations later}, which are prevalent in autonomous driving systems~\cite{strickland_deep_2018} and unmanned drones. Lastly, the generated symbolic components, whether manually created or learned, are often not verified, and the synthesis process itself requires validation. Moreover, symbolic components spanning perception, planning, and control need to be systematically and compositionally co-designed to ensure system-level safety and liveness. Control typically reflects system-level properties, while perception and planning require finer-granularity formal properties. Co-designing these layers is critical to maintaining system safety and achieving reliable performance, which is missing at this stage.\tocheckJZ{to all, please check whether I have reflected what we discussed in the brainstorming session}
%Version 16 Jan 2025
This paper summarizes state-of-the-art neurosymbolic paradigms, using autonomous driving as a case study to highlight gaps in adaptability to unseen environments, multi-sensor complexity, systematic validation of neural components, and \textit{determinism at the decision level}, critical for reliable autonomous CPS.
%This paper summarizes state-of-the-art neurosymbolic paradigms, highlighting gaps in adaptability to unseen environments, multi-sensor complexity, systematic validation of neural components, and \textit{determinism at the decision level}, crucial for reliable autonomous CPS.
%This paper summarizes state-of-the-art neurosymbolic paradigms, emphasizing their potential to address challenges posed by machine learning components in autonomous CPS. Using autonomous driving as a case study, we highlight the key knowledge gaps: limited adaptability to unseen environments, the complexity of multi-sensor modalities, and the lack of systematic validation for neural components across perception, planning, and control layers.  
% \looseness=-1

To address these issues, we put forward \textbf{NeuroStrata} --- a neurosymbolic framework for designing and assuring autonomous CPSs. Our vision integrates neurosymbolic distillation and corner-case test generation using LLMs to enable data-driven specification mining, top-down synthesis of symbolic and neurosymbolic components, and runtime bottom-up adaptation via program induction. This approach evolves symbolic programs dynamically for decision-making in perception and planning/control modules. Building on prior work, we aim to transform the testability and verifiability of autonomous CPSs through the neurosymbolic paradigm.

%This vision paper aims to summarize the state-of-the-art of neurosymbolic paradigms, emphasizing their potential to address the challenges posed by machine learning components in autonomous cyber-physical systems. Specifically, we highlight the obstacles in directly applying these paradigms to enhance the testability and verifiability of such systems. Using autonomous driving as a case study, we identify critical gaps in current approaches, including the inability to adapt to unseen deployment environments, the challenges of handling multi-sensor modalities, and the need for systematic validation of symbolic components across perception, planning, and control layers.

%Building on these insights, we propose a roadmap to bridge the gap by reimagining neurosymbolic paradigms tailored for autonomous CPS. Our vision includes designing adaptable frameworks that address real-world deployment constraints, developing modular and verifiable symbolic representations, and fostering co-design principles across system layers to ensure safety and reliability. By laying the foundation for integrating neurosymbolic approaches into autonomous CPS, we aim to drive a new wave of research and innovation that transforms the testability and verifiability of these critical systems.