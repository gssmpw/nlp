% \tocheckJZ{ZiYang, the SE community would greatly appreciate seeing some earlier results demonstrating how the neurosymbolic paradigm can improve the testability and verifiability of autonomous CPS. Now that the design is clearer, could you provide a quick summary of your LASER work? Specifically, where you used LLMs to extract a customized spatial-temporal specification language from captions, and applied this to weakly supervise the generation of spatial-temporal scene graphs? This could effectively address the question of how neurosymbolic-extracted DSLs can support training scene graphs that align with formal specifications. RQ1 is designed for this purpose, while I will explore answers for RQ2.}

We conducted a preliminary case study to investigate a key \textbf{Research Question (RQ)}: ``can neurosymbolic reasoning complement neural-network training to align with underlying specifications?''. We also outline our future plans, along with the potential challenges and proposed solutions. %detail our future plans along with potential challenges and solutions. %Similarly, an initial exploration was performed for \textbf{Research Question 2 (RQ2)}: ``can program induction enable effective neurosymbolic reasoning?''
%Our preliminary findings are promising, showing how a neurosymbolic approach not only enhances interpretability but also ensures alignment with formal specifications, particularly for tasks such as scene graph generation and spatial-temporal reasoning. These results align well with our roadmap and provide a strong foundation for future exploration.


\subsection{Assessing neurosymbolic reasoning to align neural network training with specifications}
\label{sec:symbolicReasoning}

In this study, we investigate the capability of differentiable neurosymbolic reasoning to align perceptual neural networks with specifications.
We explore the application of a high-level visual perception system trained by aligning its output with specifications.
In this application, the goal is to infer spatio-temporal scene graphs (STSG) from videos (e.g., ones taken by ego-centric cameras), where the scene graphs must align with a given spatio-temporal specification.
Figure~\ref{fig:laser-illus} depicts a specification for a traffic scene which is described in natural language but then formalized into a temporal logic formula.
Notice that the specification consists of logical symbols like \textit{exists} ($\exists$), \textit{and} ($\wedge$), \textit{not} ($\neg$), and \textit{finally} ($\Diamond$).
A neurosymbolic approach to solving this task comprises of a neural model for STSG extraction and a differentiable symbolic component for aligning the predicted STSG with the given specification.
Being differentiable, the loss computed from the alignment process can be used to supervise the neural model.
We evaluated our work on three datasets: OpenPVSG \cite{yang2023panoptic}, 20BN-Something-Something \cite{goyal2017something}, and MUGEN \cite{hayes2022mugen}, each with diverse temporal properties. Our approach outperforms current baselines on downstream tasks while offering explainability\footnote{Reference to the full report was anonymized for the review process.}.
This specification alignment provides high confidence in our top-down synthesis approach and in guiding neural training with our specifications.
%Preliminary results have shown that the approach achieve superior data-efficiency and preciseness, as the approach can leverage widely-available weak labels for videos \cite{huang2024laser}.
%Utilizing the neurosymbolic paradigm, we may eliminate the reliance on low-level annotations which might be noisy and biased.
%Instead, high-level, verifiable, and transparent specifications may be used to train the underlying perception models.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figs/laser-illus.pdf}
    \caption{Aligning STSG with natural language description via temporal logic specifications.}
    \label{fig:laser-illus}
\end{figure}

%Leveraging ChatGpt4.0, we interpreted a Texas traffic rule handbook, creating a DSL (Fig.~\ref{fig:schema}) for transforming these rules into traffic scenarios. This DSL stands out by emphasizing semantic descriptions over exact coordinates, setting it apart from other DSLs like OpenScenario and Scenic~\cite{openScenario, geoscenario, Scenic}.
%Using ChatGpt4.0, we interpreted the Texas traffic rule handbook to create a DSL (Fig.~\ref{fig:schema}) that transforms these rules into traffic scenarios. This DSL, focusing on semantic descriptions rather than precise coordinates, differentiates from others such as OpenScenario and Scenic~\cite{openScenario, geoscenario, Scenic}. %R3 comment about hallucination
%{\color{blue}
%We implemented multi-level validation to ensure the correctness of the DSL specifications, mitigating hallucination issues.
 %}
% We then translated these DSL specifications into test scripts for the CARLA simulation platform~\cite{dosovitskiy2017carla}, uncovering significant bugs in autonomous driving systems. The DSL comprises elements like \textit{Environment}, \textit{Road network}, \textit{Actor}, and \textit{Oracle}, each capturing intricate scenario semantics. This approach enabled us to generate diverse, semantically rich test scenarios that revealed rule violations in real-world autonomous systems, aiding developers in pinpointing specific issues. In our experiments, we observed that the MMFN model~\cite{zhang2022mmfn} failed to stop at the stop sign, Autoware~\cite{kato2018autoware} collided with a front vehicle, and LAV~\cite{chen2022lav} did not respond to a pedestrian crossing the road. We reported these issues, along with detailed log data, to the developers of these widely-used autonomous driving systems. They utilised our logs to pinpoint the root causes of these rule violations.
%{\color{blue}
%Further details about the DSL, including insights, examples, and the methodology for translating DSLs into test scripts, along with replicable artifacts, are provided in~\cite{deng2023target}.
%} %R2 comment about artifacts and more details of test scripts generation
%Further insights and examples are detailed in Figure~\ref{fig:schema} and supplementary material~\footnote{Supplementary material: \url{https://shorturl.at/gFPX3}}.


%Utilizing ChatGpt4.0, we parsed a Texas traffic rule handbook to extract human knowledge through specialized prompts, crafting a DSL for translating rules into traffic scenarios. This DSL, unique in its abstraction from concrete parameters, focuses on semantic descriptions based on traffic rule handbooks, distinguishing it from DSLs like OpenScenario and Scenic~\cite{openScenario, geoscenario, Scenic}. The synthesized test scripts from the rule DSL representation through template-based synthesis for the CARLA simulation platform~\cite{dosovitskiy2017carla} revealed significant bugs in autonomous driving systems. The DSL's components: \textit{Environment}, \textit{Road network}, \textit{Actor}, and \textit{Oracle}, encapsulate complex semantics of traffic scenarios, supported by a rich set of elements drawn from various sources including the traffic rule handbook~\cite{texasDriverHandbook} and OpenXOntology~\cite{openxontology}. This hierarchical structure allows the creation of diverse test scenarios with rich semantic details, avoiding reliance on overly concrete parameters. The
%generated scenarios are able to reveal rule violations for a few real-world autonomous driving systems and produced detailed execution logs are also able to help developers to locate the exact issues leading to rule violations.
%Further details and examples are showcased in Figure~\ref{fig:schema} and supplementary material~\footnote{Supplementary material: \url{https://shorturl.at/gFPX3}}.

%We leveraged ChatGpt4.0 to parse a Texas traffic rule handbook, crafting specialized prompts to guide the Language Model in extracting human knowledge embedded within these rules. We devised a domain-specific language (DSL) that melds syntactic simplicity with semantic richness, facilitating the Language Model in translating the original rules into DSL-specified traffic scenarios. We designed specific prompt template with ChatGpt4.0, propelling the Language Model to embody a test expert role for autonomous driving systems. We elucidated the DSL rules, illustrated examples, and engaged the Language Model to generate traffic scenarios in DSL format. Through a template-based program synthesis approach, we synthesized test scripts for the CARLA simulation platform~\cite{dosovitskiy2017carla}, unveiling intriguing violations acknowledged as genuine bugs by autonomous system developers. %Delve into Figure~\ref{fig:all scenarios} and \cite{deng2023target} for an in-depth exploration.

%This DSL stands apart from existing DSLs such as OpenScenario and Scenic~\cite{openScenario, geoscenario, Scenic} due to its abstraction from concrete parameters like exact coordinates of entities, instead focusing on a higher-level semantic description derived from traffic rule handbooks. The DSL, depicted in a context-free grammar format in Figure~\ref{fig:schema}, encompasses four principal components: \textbf{\textit{Environment}}, illustrating the temporal and weather conditions; \textbf{\textit{Road network}}, portraying the geographical and infrastructural context; \textbf{\textit{Actor}}, describing the dynamic entities involved and their respective states; and \textbf{\textit{Oracle}}, governing the ego vehicle's appropriate behaviors.

%Each of these components is further subdivided to encapsulate specific semantics, with a rich set of optional elements defined for each subcomponent, drawing from sources like the traffic rule handbook~\cite{texasDriverHandbook} and OpenXOntology~\cite{openxontology}. For instance, optional elements under \textit{road type} encapsulate typical road configurations like intersections and roundabouts. This hierarchical structure, demonstrated in Figure~\ref{fig:schema}, and the extensive list of optional elements available in the supplementary material~\footnote{Supplementary material: \url{https://shorturl.at/gFPX3}}, furnish a robust framework capable of capturing a wide spectrum of semantic details in test scenarios derived from traffic rules, thereby enriching the capability to generate meaningful test scenarios without delving into the nitty-gritty details of exact coordinates or overly concrete parameters.


%In our recent study~\cite{deng2023target}, we employed ChatGpt to parse a Texas traffic rule handbook, using specially crafted prompts to guide the LLM in extracting human knowledge from these rules. We created a domain-specific language (DSL) that's syntactically simple yet semantically rich, aiding the LLM in generating DSL-specified traffic scenarios from the original rules. Table~\ref{tab:prompt_knowledge_extraction} illustrates our initial prompt, urging the LLM to act as a test expert for autonomous driving systems. We introduced the DSL rules, demonstrated examples, and had the LLM generate traffic scenarios in DSL format. Through template-based program synthesis, we created test scripts for the CARLA simulation platform~\cite{dosovitskiy2017carla}, uncovering intriguing violations confirmed as real bugs by autonomous system developers. See Figure~\ref{fig:all scenarios} and \cite{deng2023target} for more details.


%In our recent work~\cite{deng2023target}, we utilized ChatGpt to parse an entire traffic rule handbook from Texas. We used specifcialized designed prompt to guide the LLM to extract human knowledge from those traffic rules. We also design a domain-specific-language which is syntactically simple and semantically rich enough for wide range of traffic rules. The LLM is guided to generate DSL-specifcied traffic scenario from the original rule description. In Table~\ref{tab:prompt_knowledge_extraction}, we showed the first-stage prompt where we ask the LLM to take a role as a test expert for autonomous driving systems. We first explain the DSL rules and shows some demostrations.  Then we ask the LLM to directly generate the traffic scenario in our DSL format. We then use some template-based program synthesis approach to generate test scripts for the target simulation platform (CARLA~\cite{dosovitskiy2017carla}}. After running the test scripts, we are able to generate the corresponding driving scenarios for each input rule and find some interesting violations which later confirmed by the corresponding autonomous driving systems developers as real bugs. Some of the examples are shown in
%Figure~\ref{fig:all scenarios} and we refer readers to find more details in~\cite{deng2023target}.


%\begin{table}[h!]
%\begin{tabular}{p{\columnwidth}}
%\hline
%\rowcolor[HTML]{C0C0C0}
%\textbf{Role Setting}                                                                                                                               \\
%\begin{tabular}[c]{@{}l@{}}You are a test expert for autonomous driving systems. Your task is \\to generate specific test  scenario representations from given traffic \\rules.\end{tabular}                                                                                  \\
%\rowcolor[HTML]{C0C0C0}
%\textbf{Prompt}                                                                                                                            \\
%\begin{tabular}[c]{@{}l@{}}Below is the definition of a domain-specific language to represent \\test scenarios for autonomous driving systems:\\ \{\textit{Details of DSL}\}\\ \\ Below are the lists of commonly used elements for each \\subcomponent. When creating the scenario representation, consider \\the following elements first for each subcomponent. If no element can \\ describe the close meaning, create a new element by yourself.\\ \{\textit{Details of element lists}\}\\ \\ Below is an example of an input traffic rule and the corresponding \\scenario representation:\\ Traffic rule: \{\textit{content of the traffic rule}\}\\ Scenario representation: \{\textit{content of the scenario representation}\} \\ \\ Based on the above descriptions and examples, convert the following \\traffic rule to corresponding \\scenario representation: \\ \{\textit{input traffic rule}\} \end{tabular} \\ \hline
%\end{tabular}
%\caption{The prompt template for knowledge extraction}
%\label{tab:prompt_knowledge_extraction}
%\end{table}

%\begin{figure*}


%centering
%\subfloat[Traffic rule violation (Auto model~\cite{carla_auto}): Not Give way to the other vehicle in roundabout]{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/roundabout.jpg}\label{fig:violation_roundabout}}\hfil%
%\subfloat[Traffic rule violation (Auto model~\cite{carla_auto}): Not give way to the other vehicle at an intersection]
%{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/collision.jpg}\label{fig:violation_intersection}}\hfil
%\subfloat[Traffic rule violation (MMFN model~\cite{zhang2022mmfn}): Not stop before the stop sign]
%{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/no_stop_before_sign.jpg}\label{fig:violation_stop}}\hfil
%\subfloat[MMFN model~\cite{zhang2022mmfn} collides on the roadside]{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/mmfn_problem.jpg}\label{fig:violation_mmfn}}\hfil
%\subfloat[Autoware~\cite{kato2018autoware} collides with the front vehicle]{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/autoware_collison.jpg}\label{fig:violation_autoware}}\hfil
%\subfloat[LAV~\cite{chen2022lav} does not move even if the pedestrian has crossed the road]{\includegraphics[height=0.16\textwidth,width=.3\textwidth]{figs/1087.jpg}\label{fig:violation_person}}\hfil

% \vspace{-1em}
%\caption{Examples of detected problems on ADSs and Carla simulator}\label{figure}
% \vspace{-1em}

%\label{fig:all scenarios}
%\end{figure*}

%In one of our current work, we take cues from the prevalent use of front-facing cameras that capture real-world
%traffic accidents for autonomous vehicles. We propose the use of existing video data, chronicling
%various failures in autonomous driving, to train a video-language multi-modal large language model
%(LLM). The purpose is twofold: first, to generate a vast repository of realistic, high-quality data; and second, to extract formal specifications underlying these crash scenarios. Leveraging this enriched data, we aim to apply data-driven learning methodologies to distill these formal specifications. The language model itself can also be programmed to generate these formal conditions directly. This provides the foundation for implementing model-based testing, an approach far more formalized than existing strategies like search-based testing.

\subsection{Future Research Plan}
To advance \textsc{NeuroStrata}, we propose a \textit{six-step future plan} with concrete steps to address challenges at each stage.

\looseness=-1
First, \textit{generating diverse training datasets} will leverage recent advancements in model-based testing that utilize LLMs to analyze multi-modal sensor data~\cite{zheng2024testing,deng2023target}. The multi-faceted challenge lies in ensuring the generated datasets are diverse, representative of real-world scenarios, and capable of addressing edge cases. Solutions can be tailored around prior work by accessing diverse sensor datasets and logs, leveraging advanced multi-modal LLMs, and integrating domain-specific constraints with iterative refinement based on industrial partner feedback.

Second, \textit{designing suitable DSLs} is essential for capturing hierarchical and semantically rich specifications. These DSLs enable experts to encode operational constraints for sensor fusion, signal processing, and physical actuation control. Challenges include ensuring the DSLs are intuitive for domain experts while expressive enough to handle complex requirements. Solutions involve co-designing DSLs with autonomy and robotics specialists, developing language automation, and designing usable visual interfaces. By providing a bridge between formal methods and practical application, these DSLs empower experts to play an active role in system design.

Third, \textit{developing a specification mining module} based on neurosymbolic distillation will extract formal safety and liveness specifications from training datasets and LLM interactions. Aligning mined specifications with real-world requirements and handling noisy/hallucinated data are key challenges. Hybrid approaches that combine symbolic reasoning with neural embeddings, as well as active learning techniques, can iteratively refine the mined specifications to ensure accuracy and physical grounding.

%precision.

%Fourth, at design time, \textsc{NeuroStrata} will \textit{synthesize multi-level specifications} for perception and planning/control modules, perform top-down synthesis of symbolic and neurosymbolic components, and validate these components using formal verification techniques. The challenge of scalability for systems with diverse scenarios and high-dimensional inputs can be addressed through modular architectures that compartmentalize functionalities and parallelized verification methods to reduce computational costs. Adaptive abstraction techniques can further focus verification efforts on critical system components, ensuring scalability without sacrificing precision.

%Fourth, at design time, \textsc{NeuroStrata} will \textit{synthesize multi-level specifications} for perception and planning/control modules, perform top-down synthesis of symbolic and neurosymbolic components, and validate them using formal verification. Scalability challenges with diverse scenarios and high-dimensional inputs can be addressed through modular architectures, parallelized verification, and adaptive abstraction techniques to focus on critical components without compromising

%Fifth, during runtime adaptation and validation, \textit{symbolic programs will be dynamically refined} to adapt to real-world changes while maintaining compliance with specifications. Prior work, such as DreamCoder~\cite{ellis2021dreamcoder}, demonstrates the feasibility of program induction through iterative refinement. Challenges include maintaining computational efficiency for real-time adaptation and ensuring formal guarantees. These challenges can be addressed by optimizing runtime validators, incorporating lightweight symbolic reasoning techniques, and employing just-in-time verification to minimize overhead while ensuring reliability.
%Fourth, for design-time synthesis and verification, we will focus on enforcing \textit{multi-level specifications} and synthesis for perception and planning/control modules. This involves defining a hierarchical structure of specifications, starting from sensor data processing constraints to high-level mission planning objectives. We plan to use modular architectures to separate functionalities, enabling scalable synthesis of symbolic and neurosymbolic components through a top-down approach. Formal verification will validate these components against specifications, with parallelized processes and adaptive abstraction techniques addressing scalability issues. These steps ensure the framework is robust across diverse scenarios and high-dimensional inputs.
%Fourth, for design-time synthesis and verification, we will enforce \textit{multi-level specifications} for perception and planning/control modules. This entails enforcing the hierarchical structure of specifications defined in our DSL, ranging from low-level sensor data processing constraints to high-level mission planning objectives. Modular architectures will be employed to separate functionalities, enabling scalable top-down synthesis of symbolic and neurosymbolic components. Formal verification will ensure these components adhere to specifications, while parallelized processes and adaptive abstraction techniques will address scalability challenges, ensuring robustness across diverse scenarios and high-dimensional inputs.
%Fourth, for design-time synthesis and verification, we will enforce \textit{multi-level specifications} for perception and planning/control modules. This involves utilizing the hierarchical structure of specifications defined in our DSL, spanning from low-level sensor data processing constraints to high-level mission planning objectives. Modular architectures will be used to separate functionalities, enabling scalable top-down synthesis of symbolic and neurosymbolic components. Formal verification will ensure compliance with specifications, while parallelized processes and adaptive abstraction techniques will address scalability challenges, ensuring robustness across diverse scenarios and high-dimensional inputs.
Fourth, for design-time synthesis and verification, we will enforce \textit{multi-level specifications} for perception and planning/control modules, leveraging the hierarchical structure  defined in our DSL. Modular architectures will enable scalable top-down synthesis of symbolic and neurosymbolic components, while formal verification ensures compliance with specifications. Parallelized processes and adaptive abstraction techniques will address scalability challenges, ensuring robustness across diverse scenarios and high-dimensional inputs.

Fifth, for runtime adaptation and validation, we will develop mechanisms to \textit{dynamically refine symbolic programs} for real-world changes while ensuring specification compliance. Inspired by program induction approaches like DreamCoder~\cite{ellis2021dreamcoder}, \textsc{NeuroStrata} will iteratively refine symbolic representations using real-time data. Challenges include maintaining computational efficiency and real-time guarantees. To address these, we will optimize runtime validators, integrate lightweight symbolic reasoning for faster adaptation, and implement efficient runtime verification to ensure reliability and compliance with minimal overhead. These advancements will enable \textsc{NeuroStrata} to adapt to dynamic environments and evolving operational conditions.

%Fifth, for runtime adaptation and validation, we aim to develop mechanisms for \textit{dynamically refining symbolic programs} to adapt to real-world changes while ensuring specification compliance. Inspired by program induction approaches such as DreamCoder~\cite{ellis2021dreamcoder}, \textsc{NeuroStrata} will iteratively refine symbolic representations based on real-time data. Challenges include maintaining computational efficiency and ensuring real-time guarantees. To address this, we will optimize runtime validators to efficiently process changes, integrate lightweight symbolic reasoning for faster adaptation, and implement efficient runtime verification to maintain reliability and compliance without introducing significant overhead. These advancements will enable \textsc{NeuroStrata} to handle dynamic environments and evolving operational conditions effectively.


Finally, for \textit{industrial deployment}, \textsc{NeuroStrata} will be applied to autonomous driving systems, delivery drones, cargo drones, and passenger aircraft --- as facilitated by our partners. Key challenges include seamless integration into existing systems, adherence to stringent safety standards, and building trust among stakeholders. Solutions include close collaborative projects, iterative deployment in increasingly open environments, and the creation of comprehensive documentation and training programs to facilitate adoption.

%By addressing these challenges with targeted solutions, \textsc{NeuroStrata} aims to bridge theoretical advancements and practical applications, transforming the testing and verification of autonomous CPS in critical real-world scenarios.

%To advance \textsc{NeuroStrata}, we propose a comprehensive future plan with concrete steps and address the challenges associated with each. First, generating diverse training datasets will leverage LLMs to synthesize edge cases and out-of-distribution scenarios. The main challenge is ensuring dataset relevance and diversity while avoiding overfitting; this can be mitigated by incorporating domain-specific constraints and iterative feedback from industrial partners. Second, developing a specification mining module based on neurosymbolic distillation will enable the extraction of formal safety and liveness specifications. The challenge lies in aligning these specifications with real-world requirements and managing noisy data, which can be addressed through hybrid symbolic-neural approaches and active learning techniques. Third, at design time, we will synthesize multi-level specifications for perception and planning/control, perform top-down synthesis, and validate components using formal methods. Achieving scalability across diverse scenarios remains a challenge but can be tackled by leveraging modular architectures and parallelized verification techniques. Fourth, during runtime adaptation and validation, symbolic programs will be dynamically refined to ensure compliance with observed real-world conditions. Earlier results from DreamCoder \cite{ellis2021dreamcoder}, though not relevant to autonomous systems it shows capability that by looking at some few examples of buildings, the synthesized program can learn the underlying funcitons for building such as arch, bridge and pyramaid, and then in the end through iterative process of combination and compression, create realistic buildings similar to the examples but with more diversiteis,  demonstrate the feasibility of aligning neural outputs with symbolic specifications and adapting programs in real-time to maintain performance under unseen scenarios. The key challenges here are ensuring computational efficiency and maintaining formal guarantees during adaptation, which can be addressed by optimizing runtime validators and using lightweight symbolic reasoning methods. Finally, for industry deployment, \textsc{NeuroStrata} will be applied to autonomous driving systems, delivery drones, cargo drones, and passenger aircraft. Challenges include seamless integration into existing systems, adherence to industry-specific safety standards, and user trust, which can be solved by close collaboration with industry stakeholders and iterative testing in controlled environments. These steps will ensure that \textsc{NeuroStrata} bridges theoretical advancements and practical adoption in critical autonomous CPS applications.

%\begin{figure}
 %   \centering
  %  \includegraphics[width=\linewidth]{figs/DreamCoder-Big.png}
   % \caption{Learning tower building tasks.}
    %\label{fig:dreamcoderexample}
%\end{figure}

%In this study, we eliminated the reliance on specialized DSLs and adopted a learning-to-synthesize paradigm \cite{
%balog2016deepcoder,devlin2017robustfill}.
%This approach trains a neural search policy to efficiently learn a library of reusable components for solving similar problems.
%The learned library is encapsulated in a generative model, which scores candidate programs and samples random tasks to further train the neural search policy.
%The search policy approximates the constraints traditionally defined by DSLs, enabling scalability.
%The developed system can take a collection of synthesized programs and extract a set of components that compactly represent these programs using e-graph matching.
%As shown in the example tasks in the Figure~\ref{fig:dreamcoderexample}, our learned program showcases representative results, demonstrating the ability of our synthesized program to generate an underlying building blocks library from a few provided shape examples.
%Through an iterative incremental learning process involving compaction and filtering, the program can subsequently create buildings that are not only as realistic as the samples but also exhibit greater diversity.
%\tocheckJZ{To Ziyang:As this involves a double-anonymous review process, we are not allowed to reference our existing papers. Instead, we can provide a high-level summary of our research aligned with the research question and include one most convincing figure with an explanation. I am considering from the Dreamcoder paper Figure 9A as the input and Figure 9D as the output; however, we need to redraw the figure to avoid plagiarism. We can also explore a suitable figure from the DreamCoder paper as inspiration such as the one in figure 11A to learn phsyical laws, redraw it, and replace the corresponding description accordingly. Thank you.}
%This system shows significant potential by adaptively learning synthesized programs that are compact, scalable, and closely approximate the oracle solution. This adaptability instills strong confidence in the robustness and adaptability of our high-level components for perception and planning, which we hope to synthesize in a similar learning-based way.% ensuring their robustness and adaptability.

%\begin{figure*}[tb!]
%\centering
%\includegraphics[width = .6\textwidth]
%{figs/Collision-overturn.jpeg}
%\caption{A traffic collision example}
%\label{fig:accident}
%\end{figure*}
%\begin{wrapfigure}{R}{0.25\textwidth}
%\vspace{-1.0cm}
%\begin{center}
%\includegraphics[width=0.25\textwidth]{figs/Collision-overturn.png}
