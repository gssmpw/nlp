State-of-the-art autonomous CPSs, such as autonomous driving systems (ADS), are typically built on middleware frameworks like Robot Operating System (ROS) with proprietary extensions (e.g., Baidu’s CyberRT) to reduce message latency~\cite{zheng2024testing, liang2023rlaga, lou2022testing, deng2021survey, prakash2021multi}. As shown in Figure~\ref{fig:ROSADS}, these systems integrate perception, prediction, planning, and control modules. The perception module processes multi-modal sensor data (e.g., LiDAR, cameras, IMU) for obstacle detection, traffic light recognition, and localization. The prediction module forecasts dynamic object trajectories, while the planning module computes the ego vehicle’s trajectory. The control module generates actuation commands, such as steering and braking. AI components are pervasive across these modules, enabling object detection, trajectory prediction, and real-time control.
%State-of-the-art autonomous CPSs are exemplified by industry-scale autonomous driving systems (ADS), as illustrated in Figure~\ref{fig:ROSADS}. These systems are typically built on middleware frameworks like Robot Operating System (ROS), with proprietary extensions such as Baidu’s CyberRT, which reduce message latency to milliseconds~\cite{zheng2024testing, liang2023rlaga,lou2022testing, deng2021survey,prakash2021multi}. The architecture integrates multiple modules, including perception, prediction, planning, and control. The perception module processes multi-modal sensor data, such as LiDAR, cameras, and IMU, to detect obstacles, recognize traffic lights, and perform localization. The prediction module forecasts the trajectories of dynamic objects, while the planning module determines the ego vehicle’s trajectory based on inputs from perception and prediction. Finally, the control module generates actuation commands, such as steering and braking, to execute the planned trajectory. AI components are pervasive across all these modules, enabling functionalities like object detection, trajectory prediction, and real-time control. 
%Recent advancements in verifying machine learning models and testing learning-enabled CPS, using methods like NNV star sets~\cite{tran2020verification}, Sherlock~\cite{dutta2019sherlock}, Reluplex~\cite{katz2017reluplex}, and Branch-and-Bound~\cite{bunel2018unified}, show promise but struggle with scalability and distribution shifts in real-world, multi-modal CPS. While system-level testing~\cite{deng2022declarative,tian2022mosat,li2020av} and robustness analyses~\cite{tian2018deeptest,deng2020analysis,cai2020real} have advanced, they lack rigorous formal assurances, often relying on probabilistic methods to test probabilistic systems~\cite{badings_probabilities_2023}.

Recent advancements in verifying machine learning models and testing learning-enabled CPS have utilized methods like NNV star sets~\cite{tran2020verification}, Sherlock~\cite{dutta2019sherlock}, Reluplex~\cite{katz2017reluplex}, and Branch-and-Bound~\cite{bunel2018unified}.
While promising, these methods often fall short in providing comprehensive safety and liveness guarantees, particularly when dealing with the complexity and scale of the real-world, multi-modal CPS as shown in the motivating system above. System-level testing~\cite{deng2022declarative,tian2022mosat,li2020av} and robustness analyses~\cite{tian2018deeptest,deng2020analysis,cai2020real} offer progress but still rely on probabilistic methods to assure probabilistic systems~\cite{cleaveland_monotonic_2022,badithela_evaluation_2023}, which can weaken the guarantees~\cite{badings_probabilities_2023}.

%Recent advancements in the formal verification of machine learning models and the testing of learning-enabled CPS have leveraged techniques such as NNV star sets~\cite{tran2020verification}, Sherlock~\cite{dutta2019sherlock}, Reluplex~\cite{katz2017reluplex}, and Branch-and-Bound approaches~\cite{bunel2018unified}. While these methods have shown promise, they often fall short in providing comprehensive safety guarantees, particularly when dealing with the complexity and scale of in the real-world, multi-modal CPS as shown in the case study before. The critical issues include scaling to rich sensor data and dealing with inevitable distribution shifts. Moreover, recent work on system-level testing for properties~\cite{deng2022declarative,tian2022mosat,li2020av} and robustness~\cite{tian2018deeptest,deng2020analysis,cai2020real} has advanced the field --- but it still lacks the ability to deliver rigorous formal assurances for autonomous CPS, which is essentially using probabilistic methods to test probabilistic systems~\cite{badings_probabilities_2023}. 


%In parallel, the neurosymbolic paradigm, which combines neural networks with symbolic reasoning, has emerged as a promising approach to address these gaps. For example, Scallop~\cite{li2023scallop} introduces a declarative reasoning framework that effectively integrates neural and symbolic computations, while DiffLog~\cite{raghothamandifflog} offers differentiable logic programming for explainable predictions. These approaches demonstrate significant progress but face challenges when directly applied to autonomous CPS due to the complexity of multi-modal sensor integration and dynamic real-world constraints. Similarly, efforts such as DreamCoder~\cite{ellis2021dreamcoder} and neurosymbolic Program Synthesis using incrementally expanding partial programs~\cite{parisotto2016neuro,bjorner2023formal}  explore symbolic learning frameworks but encounter scalability issues, as demonstrated in industrial CPS case studies. 

%Though neurosymbolic paradigms aim to combine neural and symbolic approaches—either through differentiable logic programming to produce differentiable yet deterministic outputs or through program induction to synthesize deterministic programs by observing limited input-output pairs—they face notable limitations. The differentiable logic programming paradigm struggles with hard-coded mappings between neural component outputs and logic program inputs, as well as the complexity of implementing differentiable logic programming capabilities. These constraints limit its ability to support multi-modal sensors and the sophisticated logics required for autonomous systems, which demand more automated and expressive guidance. Similarly, the program induction paradigm relies on Domain-Specific Languages (DSLs) for guidance, which are often hard-coded and lack the complexity needed for multi-modal sensor integration and advanced reasoning. Furthermore, program induction may not be sufficient to replace all pure AI components in such systems.

%In parallel, the neurosymbolic paradigm, which integrates neural networks with symbolic reasoning, offers a promising direction to address these gaps. For instance, Scallop~\cite{li2023scallop} introduces a declarative reasoning framework that integrates neural and symbolic computations, and DiffLog~\cite{raghothamandifflog} provides differentiable logic programming for explainable predictions. While these approaches mark significant progress, they face challenges when applied to autonomous cyber-physical systems (CPS), particularly due to the complexities of integrating multi-modal sensors and addressing dynamic real-world constraints. Likewise, symbolic learning frameworks such as DreamCoder~\cite{ellis2021dreamcoder} and neurosymbolic Program Synthesis~\cite{parisotto2016neuro,bjorner2023formal} show promise but encounter scalability issues, as demonstrated in industrial CPS case studies.
In parallel, \textit{neurosymbolic paradigms} aim to combine neural and symbolic approaches --- either through differentiable logic programming to produce differentiable yet deterministic outputs~\cite{li2023scallop,raghothamandifflog} or through program induction to synthesize deterministic programs by observing limited input-output pairs~\cite{parisotto2016neuro,bjorner2023formal,ellis2021dreamcoder}. However, they face notable limitations. The differentiable logic programming paradigm struggles with hard-coded mappings between neural component outputs and logic program inputs, as well as the complexity of implementing differentiable logic programming capabilities. These constraints limit its ability to support multi-modal sensors and the sophisticated logics required for autonomous systems, which demand more automated and expressive guidance. Similarly, the program induction paradigm relies on Domain-Specific Languages (DSLs) for guidance, which are often hard-coded and lack the flexibility needed for multi-modal sensor integration and advanced reasoning~\cite{parisotto2016neuro,ellis2021dreamcoder,bjorner2023formal}. Furthermore, program induction may not be sufficient to replace all pure AI components in such systems.

\looseness=-1
%In parallel, the neurosymbolic paradigm, which integrates neural networks with symbolic reasoning, offers a promising direction to address these gaps. For instance, Scallop~\cite{li2023scallop} introduces a declarative reasoning framework that integrates neural and symbolic computations, and DiffLog~\cite{raghothamandifflog} provides differentiable logic programming for explainable predictions. While these approaches mark significant progress, they face challenges when applied to autonomous cyber-physical systems (CPS), particularly due to the complexities of integrating multi-modal sensors and addressing dynamic real-world constraints. Likewise, symbolic learning frameworks such as DreamCoder~\cite{ellis2021dreamcoder} and neurosymbolic Program Synthesis~\cite{parisotto2016neuro,ellis2021dreamcoder,bjorner2023formal} show promise but encounter scalability issues, as demonstrated in industrial CPS case studies.
% \tocheckJZ{Ivan: Google is banned here in China and my wall-climbing efforts are not fully effective. Please add the reference for the multimodal neurosymbolic approach for explainable deepfake detection}
%Version: 16 Jan 2025 JZ
Recent work on \textit{multimodal neurosymbolic systems} integrates visual and auditory signals but relies on simplistic symbolic rules, unsuitable for the diverse sensor modalities of autonomous CPS, such as LiDARs, radars, and cameras~\cite{haq_multimodal_2024}. A Neural State Machine (NSM) approach combines vision and language reasoning but suffers from scalability issues, manual scene graph construction, and limited interpretability due to missing source code~\cite{jain2024neuro}. These limitations underscore the need for refined co-design to meet the stringent requirements of autonomous CPS.
%Recent work on \textit{multimodal neurosymbolic systems}, while capable of integrating visual and auditory signals, often relies on simplistic symbolic reasoning rules. These rules are not well-suited to the dynamic and complex requirements of autonomous CPS, which involve diverse sensor modalities, including multiple LiDARs, radars, and cameras~\cite{haq_multimodal_2024}. 
%Another pioneering work integrates vision and language modalities using a Neural State Machine (NSM) for reasoning. However, the underlying scene graph is manually constructed, raising concerns about the generality of the approach. The NSM scalability issues, such as state explosion, and the lack of interpretability due to the absence of concrete source code for reasoning remain significant challenges~\cite{jain2024neuro}. 
%These issues highlight the need for further refinement and co-design to ensure the neurosymbolic paradigm meets the stringent requirements of autonomous CPS.

The above limitations emphasize the pressing need for \textit{deterministic testing and verification approaches} in autonomous CPS, particularly in safety-critical domains like autonomous driving. For instance, perception modules in autonomous vehicles, which rely on uncertain or stochastic processes such as (Bayesian) neural networks for object detection, often fail in ``long tail'' scenarios where the inputs deviate from training data (covariate shift). Predictable and deterministic approaches, incorporating reasoning layers, can adapt to such unseen scenarios by leveraging symbolic logic to ensure robust decision-making and mitigate failures caused by stochastic uncertainties. This adaptability is crucial for guaranteeing safety and reliability across perception, prediction, and planning modules in dynamic and complex real-world environments~\cite{shalev2017formal, seshia2017compositional, zapridou2020runtime}.
%\tocheckJZ{Ivan: Please add the reference for "neurosymbolic reasoning for multimodal referring expression comprehension in HMI systems" as my access is limited}

%In parallel, the neurosymbolic paradigm, combining neural networks with symbolic reasoning, has emerged as a promising approach to address these gaps. For example, Scallop~\cite{liang2021scallop} introduces a declarative reasoning framework to integrate neural and symbolic computations effectively, and DiffLog~\cite{zhu2022difflog} provides differentiable logic programming for explainable predictions. While these works demonstrate significant progress, their direct application to autonomous CPS is challenging due to multi-modal sensor integration and dynamic real-world constraints. Furthermore, efforts such as NeuroSAT~\cite{selsam2018neurosat} and Logic Tensor Networks (LTN)~\cite{badreddine2022logic} explore symbolic learning frameworks, but face scalability issues in industrial CPS applications as shown in the case study. 
%Recent work on multimodal neurosymbolic, though able to interate visual and aural signals, the symbolization reasons are provided as easy and primitive rule equations which are not adaptable as required by autonomous CPS~\cite{}\tocheckjz{Ivan: Google is banned here in China and my wall-climbing effort is not entirely working. The paper is multimodal neurosymbolic approach for explainable deepfake detection, please add it}. Aother pionering work intergraging vision and language multimodal uses Neural State Machine to conduct reasonsing, however the udnerlying scene graph is provided and verifiability of such Neurals statement mahcine interms of scalabiliyt avoidng state explosion and interpretabilty as it is not concrete code is subject to reasoning~\cite{}\tocheckjz{Ivan: Google is banned here in China and my wall-climbing effort is not entirely working. The paper is neurosymbolic reasoning for multimodal referring expression comprehensio in HMI systems, please add it}.


%\tocheckJZ{To ziyang, I have put some recent work on neurosymbolic here, but didn't align very well with the introduction and please modify as needed and make it consistent with the claims in the introduction for neurosymbilic gaps when applying to autonomous CPS for improving testability and veriability}

%These limitations emphasize the pressing need for innovative compositional and deterministic testing and verification approaches that are capable of bridging the gap between theoretical guarantees and practical deployments, particularly for safety-critical autonomous CPS
 %\tocheckJZ{to Ivan， do you think this paragraph is suitable? Ivan: It's ok but needs more motivating of the deterministic approaches, per my comment. JZ: I gave a case study to prove the deterministic nature is needed.}