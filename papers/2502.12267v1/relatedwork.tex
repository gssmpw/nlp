\section{Related Work}
\label{sec:related}

We take an overview of related works in software vulnerabilities detection from three different categories: 
traditional rule-based approach, deep learning-based approach, and graph learning-based approach. 

For the traditional approach, early works on vulnerability detection are heavily reliant on human-crafted rules from domain experts. 
The work in~\cite{engler2001bugs} is the first of this kind to implement rules to identify software bugs and vulnerabilities automatically. 
Following that, many static analysis tools~\cite{ferschke2012flawfinder,viega2001static,kremenek2008finding, bader2019getafix, caitlin2015tricorder} 
are developed to cover some well-known security issues, all of which share the same principle 
that if the scanned code base fails to conform to the re-defined rules, 
relevant vulnerabilities could occur. 
It is infeasible to craft rules that cover all possible code vulnerabilities, 
not to mention the required efforts to cope with the ever-changing code bases.

The rapid development of machine learning, especially deep learning techniques, 
unleashes the great potential in enabling the automated learning of implicit vulnerable programming patterns. 
Many early works focus on extracting the features from lines of codes to 
facilitate vulnerability detection/prediction~\cite{chowdhury2011using,shin2010evaluating,chernis2018machine}. 
For instance, 
VulDeePecker~\cite{li2018vuldeepecker} is the first deep learning-based binary vulnerability detector, 
which slices the program into code gadgets and utilizes BiLSTM to capture the semantic relations in the data dependence within the code gadgets. 
%
Similarly, $\mu$VulDeePecker~\cite{zou2019mu} uses both BiLSTM and code attentions to capture more ``localized'' information within a code statement, 
and control dependence among method calls. 
%
LIN \textit{et al.}~\cite{lin} designs a framework that uses data sources of different types for learning unified high-level representations of code snippets. 
It also uses BiLSTM as the core component of the learning process. 
%
DeepBugs~\cite{pradel2018deepbugs} uses a feedforward network as the classifier for name-based bug detection, 
which reasons about names based on semantic representations. 
However, only the natural code sequences are considered in these works, 
and the intra-program flow logic and dependency information are omitted. 


Neural networks on graphs have drawn increasing attention in recent years, 
which focus on learning the model based on graph-structured input~\cite{li2015gated,kipf2016semi,zhang2021gps}. 
Researchers have put efforts into exploring the feasibility of using code graph representations such as 
Abstract Syntax Trees (AST), Program Dependency Graphs (PDG), and Control Flow Graphs (CFG) for vulnerability detection tasks. 
The work in~\cite{allamanis2018learning} first presents how to construct graphs from source code using AST and additional control and data flows, 
and then uses Gated Graph Neural Networks (GGNN) to detect variable misuse bugs. 
Afterwards, Devign~\cite{devign} starts to apply GNN on CPG. It extracts AST, 
program control and data dependency from CPG to create the joint graph as the composite code representation, 
from which a GGNN is designed to learn the graph-level embeddings for the downstream vulnerability detection task. 
%
FUNDED~\cite{funded} integrates data and control flow into the AST 
as the code graph representation and starts to distinguish multiple code relationships when training the GGNN, 
which is achieved by representing the input program as multiple relation graphs. 
%
DeepWukong~\cite{deepwukong} combines the CFG and PDG to generate a refined subgraph called XFG for the program, 
and adopts three different GNNs to test the performance for bug prediction. 
Existing research mainly relies on adopting homogeneous graph learning techniques, 
from which types of nodes and edges are discarded, making it infeasible to represent heterogeneous structures. 
However, we argue that the graph representations of codes convey rich semantic and logical information reflected 
in a variety of node/edge types and are intrinsic to the characteristics of heterogeneous graphs~\cite{wang2022survey}. 
This motivates us to conduct this pioneering study of heterogeneous graph learning which is shown later to improve over these state-of-the-art.