[
  {
    "index": 0,
    "papers": [
      {
        "key": "rajpurkar-etal-2016-squad",
        "author": "Rajpurkar, Pranav  and\nZhang, Jian  and\nLopyrev, Konstantin  and\nLiang, Percy",
        "title": "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wang-etal-2018-glue",
        "author": "Wang, Alex  and\nSingh, Amanpreet  and\nMichael, Julian  and\nHill, Felix  and\nLevy, Omer  and\nBowman, Samuel",
        "title": "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2019superglue",
        "author": "Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel",
        "title": "Superglue: A stickier benchmark for general-purpose language understanding systems"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "hendrycks2021mmlu",
        "author": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt",
        "title": "Measuring Massive Multitask Language Understanding"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "wang-etal-2018-glue",
        "author": "Wang, Alex  and\nSingh, Amanpreet  and\nMichael, Julian  and\nHill, Felix  and\nLevy, Omer  and\nBowman, Samuel",
        "title": "{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "allenai:arc",
        "author": "Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and\nAshish Sabharwal and Carissa Schoenick and Oyvind Tafjord",
        "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wang2019superglue",
        "author": "Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel",
        "title": "Superglue: A stickier benchmark for general-purpose language understanding systems"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "sakaguchi2019winogrande",
        "author": "Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin",
        "title": "WinoGrande: An Adversarial Winograd Schema Challenge at Scale"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zellers2019hellaswag",
        "author": "Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin",
        "title": "HellaSwag: Can a Machine Really Finish Your Sentence?"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hendryckstest2021",
        "author": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt",
        "title": "Measuring Massive Multitask Language Understanding"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "anil2023palm",
        "author": "Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others",
        "title": "Palm 2 technical report"
      },
      {
        "key": "le2023bloom",
        "author": "Le Scao, Teven and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\\'c}, Suzana and Hesslow, Daniel and Castagn{\\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\\c{c}}ois and Gall{\\'e}, Matthias and others",
        "title": "Bloom: A 176b-parameter open-access multilingual language model"
      },
      {
        "key": "dettmers2023qlora",
        "author": "Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke",
        "title": "QLoRA: Efficient Finetuning of Quantized LLMs"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "zheng2023judging",
        "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "dubois2024length",
        "author": "Dubois, Yann and Galambosi, Bal{\\'a}zs and Liang, Percy and Hashimoto, Tatsunori B",
        "title": "Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "li2024crowdsourced",
        "author": "Li, Tianle and Chiang, Wei-Lin and Frick, Evan and Dunlap, Lisa and Wu, Tianhao and Zhu, Banghua and Gonzalez, Joseph E and Stoica, Ion",
        "title": "From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "qin-etal-2024-infobench",
        "author": "Qin, Yiwei  and\nSong, Kaiqiang  and\nHu, Yebowen  and\nYao, Wenlin  and\nCho, Sangwoo  and\nWang, Xiaoyang  and\nWu, Xuansheng  and\nLiu, Fei  and\nLiu, Pengfei  and\nYu, Dong",
        "title": "{I}n{F}o{B}ench: Evaluating Instruction Following Ability in Large Language Models"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "xu-etal-2024-pride",
        "author": "Xu, Wenda  and\nZhu, Guanglei  and\nZhao, Xuandong  and\nPan, Liangming  and\nLi, Lei  and\nWang, William",
        "title": "Pride and Prejudice: {LLM} Amplifies Self-Bias in Self-Refinement"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zheng2023judging",
        "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "zhou2023instruction",
        "author": "Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le",
        "title": "Instruction-following evaluation for large language models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "Instruction-Following Evaluation for Large Language Models",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "qwen2.5",
        "author": "An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu",
        "title": "Qwen2.5 Technical Report"
      }
    ]
  }
]