@article{lee2024holistic,
  title={Holistic evaluation of text-to-image models},
  author={Lee, Tony and Yasunaga, Michihiro and Meng, Chenlin and Mai, Yifan and Park, Joon Sung and Gupta, Agrim and Zhang, Yunzhi and Narayanan, Deepak and Teufel, Hannah and Bellagente, Marco and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wenzek-etal-2020-ccnet,
    title = "{CCN}et: Extracting High Quality Monolingual Datasets from Web Crawl Data",
    author = "Wenzek, Guillaume  and
      Lachaux, Marie-Anne  and
      Conneau, Alexis  and
      Chaudhary, Vishrav  and
      Guzm{\'a}n, Francisco  and
      Joulin, Armand  and
      Grave, Edouard",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.494",
    pages = "4003--4012",
    abstract = "Pre-training text representations have led to significant improvements in many areas of natural language processing. The quality of these models benefits greatly from the size of the pretraining corpora as long as its quality is preserved. In this paper, we describe an automatic pipeline to extract massive high-quality monolingual datasets from Common Crawl for a variety of languages. Our pipeline follows the data processing introduced in fastText (Mikolov et al., 2017; Grave et al., 2018), that deduplicates documents and identifies their language. We augment this pipeline with a filtering step to select documents that are close to high quality corpora like Wikipedia.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@inproceedings{field_survey_2021,
	address = {Online},
	title = {A {Survey} of {Race}, {Racism}, and {Anti}-{Racism} in {NLP}},
	url = {https://aclanthology.org/2021.acl-long.149},
	doi = {10.18653/v1/2021.acl-long.149},
	abstract = {Despite inextricable ties between race and language, little work has considered race in NLP research and development. In this work, we survey 79 papers from the ACL anthology that mention race. These papers reveal various types of race-related bias in all stages of NLP model development, highlighting the need for proactive consideration of how NLP systems can uphold racial hierarchies. However, persistent gaps in research on race and NLP remain: race has been siloed as a niche topic and remains ignored in many NLP tasks; most work operationalizes race as a fixed single-dimensional variable with a ground-truth label, which risks reinforcing differences produced by historical racism; and the voices of historically marginalized people are nearly absent in NLP literature. By identifying where and how NLP literature has and has not considered race, especially in comparison to related fields, our work calls for inclusion and racial justice in NLP research practices.},
	urldate = {2023-05-08},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Field, Anjalie and Blodgett, Su Lin and Waseem, Zeerak and Tsvetkov, Yulia},
	month = aug,
	year = {2021},
	pages = {1905--1925},
}

@article{Cohen1968WeightedKN,
  title={Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit.},
  author={Jacob Cohen},
  journal={Psychological Bulletin},
  year={1968},
  volume={70},
  pages={213-220},
  url={https://api.semanticscholar.org/CorpusID:29694079}
}

@article{bai2024power,
  title={The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning},
  author={Bai, Longju and Borah, Angana and Ignat, Oana and Mihalcea, Rada},
  journal={arXiv preprint arXiv:2411.11758},
  year={2024}
}

@inproceedings{hershcovich-etal-2022-challenges,
    title = "Challenges and Strategies in Cross-Cultural {NLP}",
    author = "Hershcovich, Daniel  and
      Frank, Stella  and
      Lent, Heather  and
      de Lhoneux, Miryam  and
      Abdou, Mostafa  and
      Brandl, Stephanie  and
      Bugliarello, Emanuele  and
      Cabello Piqueras, Laura  and
      Chalkidis, Ilias  and
      Cui, Ruixiang  and
      Fierro, Constanza  and
      Margatina, Katerina  and
      Rust, Phillip  and
      S{\o}gaard, Anders",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.482",
    doi = "10.18653/v1/2022.acl-long.482",
    pages = "6997--7013",
    abstract = "Various efforts in the Natural Language Processing (NLP) community have been made to accommodate linguistic diversity and serve speakers of many different languages. However, it is important to acknowledge that speakers and the content they produce and require, vary not just by language, but also by culture. Although language and culture are tightly linked, there are important differences. Analogous to cross-lingual and multilingual NLP, cross-cultural and multicultural NLP considers these differences in order to better serve users of NLP systems. We propose a principled framework to frame these efforts, and survey existing and potential strategies.",
}

@article{hershcovich2022challenges,
  title={Challenges and strategies in cross-cultural NLP},
  author={Hershcovich, Daniel and Frank, Stella and Lent, Heather and de Lhoneux, Miryam and Abdou, Mostafa and Brandl, Stephanie and Bugliarello, Emanuele and Piqueras, Laura Cabello and Chalkidis, Ilias and Cui, Ruixiang and others},
  journal={arXiv preprint arXiv:2203.10020},
  year={2022}
}

@article{mihalcea2024ai,
  title={Why ai is weird and should not be this way: Towards ai for everyone, with everyone, by everyone},
  author={Mihalcea, Rada and Ignat, Oana and Bai, Longju and Borah, Angana and Chiruzzo, Luis and Jin, Zhijing and Kwizera, Claude and Nwatu, Joan and Poria, Soujanya and Solorio, Thamar},
  journal={arXiv preprint arXiv:2410.16315},
  year={2024}
}

@misc{flux2023,
    author={Black Forest Labs},
    title={FLUX},
    year={2023},
    howpublished={\url{https://github.com/black-forest-labs/flux}},
}

@article{flux1-lite,
  title={Flux.1 Lite: Distilling Flux1.dev for Efficient Text-to-Image Generation},
  author={Daniel Verdú, Javier Martín},
  email={dverdu@freepik.com, javier.martin@freepik.com},
  year={2024},
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@article{betker2023improving,
  title={Improving image generation with better captions},
  author={Betker, James and Goh, Gabriel and Jing, Li and Brooks, Tim and Wang, Jianfeng and Li, Linjie and Ouyang, Long and Zhuang, Juntang and Lee, Joyce and Guo, Yufei and others},
  journal={Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf},
  volume={2},
  number={3},
  pages={8},
  year={2023}
}

@article{podell2023sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}

@inproceedings{lin2025evaluating,
  title={Evaluating text-to-visual generation with image-to-text generation},
  author={Lin, Zhiqiu and Pathak, Deepak and Li, Baiqi and Li, Jiayao and Xia, Xide and Neubig, Graham and Zhang, Pengchuan and Ramanan, Deva},
  booktitle={European Conference on Computer Vision},
  pages={366--384},
  year={2025},
  organization={Springer}
}

@article{ghosh2024geneval,
  title={Geneval: An object-focused framework for evaluating text-to-image alignment},
  author={Ghosh, Dhruba and Hajishirzi, Hannaneh and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{hu2023tifa,
  title={Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering},
  author={Hu, Yushi and Liu, Benlin and Kasai, Jungo and Wang, Yizhong and Ostendorf, Mari and Krishna, Ranjay and Smith, Noah A},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20406--20417},
  year={2023}
}

@inproceedings{ye2024altdiffusion,
  title={Altdiffusion: A multilingual text-to-image diffusion model},
  author={Ye, Fulong and Liu, Guang and Wu, Xinya and Wu, Ledell},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={6648--6656},
  year={2024}
}

@article{wu2024taiyi,
  title={Taiyi-Diffusion-XL: advancing bilingual text-to-image generation with large vision-language model support},
  author={Wu, Xiaojun and Zhang, Dixiang and Gan, Ruyi and Lu, Junyu and Wu, Ziwei and Sun, Renliang and Zhang, Jiaxing and Zhang, Pingjian and Song, Yan},
  journal={arXiv preprint arXiv:2401.14688},
  year={2024}
}

@article{han2024llm,
  title={LLM multi-agent systems: Challenges and open problems},
  author={Han, Shanshan and Zhang, Qifan and Yao, Yuhang and Jin, Weizhao and Xu, Zhaozhuo and He, Chaoyang},
  journal={arXiv preprint arXiv:2402.03578},
  year={2024}
}

@article{guo2024large,
  title={Large language model based multi-agents: A survey of progress and challenges},
  author={Guo, Taicheng and Chen, Xiuying and Wang, Yaqi and Chang, Ruidi and Pei, Shichao and Chawla, Nitesh V and Wiest, Olaf and Zhang, Xiangliang},
  journal={arXiv preprint arXiv:2402.01680},
  year={2024}
}

@book{migration,
  title = {The Age of Migration: International Population Movements in the Modern World},
  author = {Castles, Stephen and Hein de Haas and Mark J, Miller},
  journal = {Red Globe Press},
  year = {2103}
}

@article{naous2023having,
  title={Having beer after prayer? measuring cultural bias in large language models},
  author={Naous, Tarek and Ryan, Michael J and Ritter, Alan and Xu, Wei},
  journal={arXiv preprint arXiv:2305.14456},
  year={2023}
}

@incollection{liu2024cultural,
  title={On the cultural gap in text-to-image generation},
  author={Liu, Bingshuai and Wang, Longyue and Lyu, Chenyang and Zhang, Yong and Su, Jinsong and Shi, Shuming and Tu, Zhaopeng},
  booktitle={ECAI 2024},
  pages={930--937},
  year={2024},
  publisher={IOS Press}
}

@article{pawar2024survey,
  title={Survey of cultural awareness in language models: Text and beyond},
  author={Pawar, Siddhesh and Park, Junyeong and Jin, Jiho and Arora, Arnav and Myung, Junho and Yadav, Srishti and Haznitrama, Faiz Ghifari and Song, Inhwa and Oh, Alice and Augenstein, Isabelle},
  journal={arXiv preprint arXiv:2411.00860},
  year={2024}
}

@article{singh2024global,
  title={Global mmlu: Understanding and addressing cultural and linguistic biases in multilingual evaluation},
  author={Singh, Shivalika and Romanou, Angelika and Fourrier, Cl{\'e}mentine and Adelani, David I and Ngui, Jian Gang and Vila-Suero, Daniel and Limkonchotiwat, Peerat and Marchisio, Kelly and Leong, Wei Qi and Susanto, Yosephine and others},
  journal={arXiv preprint arXiv:2412.03304},
  year={2024}
}

@article{hartwig2024evaluating,
  title={Evaluating Text to Image Synthesis: Survey and Taxonomy of Image Quality Metrics},
  author={Hartwig, Sebastian and Engel, Dominik and Sick, Leon and Kniesel, Hannah and Payer, Tristan and Ropinski, Timo and others},
  journal={arXiv preprint arXiv:2403.11821},
  year={2024}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@inproceedings{nguyen2023extracting,
  title={Extracting cultural commonsense knowledge at scale},
  author={Nguyen, Tuan-Phong and Razniewski, Simon and Varde, Aparna and Weikum, Gerhard},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={1907--1917},
  year={2023}
}

@inproceedings{adilazuarda-etal-2024-towards,
    title = "Towards Measuring and Modeling {\textquotedblleft}Culture{\textquotedblright} in {LLM}s: A Survey",
    author = "Adilazuarda, Muhammad Farid  and
      Mukherjee, Sagnik  and
      Lavania, Pradhyumna  and
      Singh, Siddhant Shivdutt  and
      Aji, Alham Fikri  and
      O{'}Neill, Jacki  and
      Modi, Ashutosh  and
      Choudhury, Monojit",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.882/",
    doi = "10.18653/v1/2024.emnlp-main.882",
    pages = "15763--15784",
    abstract = "We present a survey of more than 90 recent papers that aim to study cultural representation and inclusion in large language models (LLMs). We observe that none of the studies explicitly define {\textquotedblleft}culture, which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of {\textquotedblleft}culture{\textquotedblright}. We call these aspects the proxies of culture, and organize them across two dimensions of demographic and semantic proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of {\textquotedblleft}culture,{\textquotedblright} such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness of probing techniques and situated studies on the impact of cultural mis- and under-representation in LLM-based applications."
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, A},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{salimans2016improved,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{kannen2024beyond,
  title={Beyond aesthetics: Cultural competence in text-to-image models},
  author={Kannen, Nithish and Ahmad, Arif and Andreetto, Marco and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi},
  journal={arXiv preprint arXiv:2407.06863},
  year={2024}
}

@inproceedings{bhatia-etal-2024-local,
    title = "From Local Concepts to Universals: Evaluating the Multicultural Understanding of Vision-Language Models",
    author = "Bhatia, Mehar  and
      Ravi, Sahithya  and
      Chinchure, Aditya  and
      Hwang, EunJeong  and
      Shwartz, Vered",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.385/",
    doi = "10.18653/v1/2024.emnlp-main.385",
    pages = "6763--6782",
    abstract = "Despite recent advancements in vision-language models, their performance remains suboptimal on images from non-western cultures due to underrepresentation in training datasets. Various benchmarks have been proposed to test models' cultural inclusivity. Still, they have limited coverage of cultures and do not adequately assess cultural diversity across universal and culture-specific local concepts. To address these limitations, we introduce the GlobalRG benchmark, comprising two challenging tasks: retrieval across universals and cultural visual grounding. The former task entails retrieving culturally diverse images for universal concepts from 50 countries, while the latter aims at grounding culture-specific concepts within images from 15 countries. Our evaluation across a wide range of models reveals that the performance varies significantly across cultures {--} underscoring the necessity for enhancing multicultural understanding in vision-language models."
}

@article{romanou2024include,
  title={INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge},
  author={Romanou, Angelika and Foroutan, Negar and Sotnikova, Anna and Chen, Zeming and Nelaturu, Sree Harsha and Singh, Shivalika and Maheshwary, Rishabh and Altomare, Micol and Haggag, Mohamed A and Amayuelas, Alfonso and others},
  journal={arXiv preprint arXiv:2411.19799},
  year={2024}
}

@misc{romero2024cvqaculturallydiversemultilingualvisual,
      title={CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark}, 
      author={David Romero and Chenyang Lyu and Haryo Akbarianto Wibowo and Teresa Lynn and Injy Hamed and Aditya Nanda Kishore and Aishik Mandal and Alina Dragonetti and Artem Abzaliev and Atnafu Lambebo Tonja and Bontu Fufa Balcha and Chenxi Whitehouse and Christian Salamea and Dan John Velasco and David Ifeoluwa Adelani and David Le Meur and Emilio Villa-Cueva and Fajri Koto and Fauzan Farooqui and Frederico Belcavello and Ganzorig Batnasan and Gisela Vallejo and Grainne Caulfield and Guido Ivetta and Haiyue Song and Henok Biadglign Ademtew and Hernán Maina and Holy Lovenia and Israel Abebe Azime and Jan Christian Blaise Cruz and Jay Gala and Jiahui Geng and Jesus-German Ortiz-Barajas and Jinheon Baek and Jocelyn Dunstan and Laura Alonso Alemany and Kumaranage Ravindu Yasas Nagasinghe and Luciana Benotti and Luis Fernando D'Haro and Marcelo Viridiano and Marcos Estecha-Garitagoitia and Maria Camila Buitrago Cabrera and Mario Rodríguez-Cantelar and Mélanie Jouitteau and Mihail Mihaylov and Mohamed Fazli Mohamed Imam and Muhammad Farid Adilazuarda and Munkhjargal Gochoo and Munkh-Erdene Otgonbold and Naome Etori and Olivier Niyomugisha and Paula Mónica Silva and Pranjal Chitale and Raj Dabre and Rendi Chevi and Ruochen Zhang and Ryandito Diandaru and Samuel Cahyawijaya and Santiago Góngora and Soyeong Jeong and Sukannya Purkayastha and Tatsuki Kuribayashi and Thanmay Jayakumar and Tiago Timponi Torrent and Toqeer Ehsan and Vladimir Araujo and Yova Kementchedjhieva and Zara Burzo and Zheng Wei Lim and Zheng Xin Yong and Oana Ignat and Joan Nwatu and Rada Mihalcea and Thamar Solorio and Alham Fikri Aji},
      year={2024},
      eprint={2406.05967},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2406.05967}, 
}