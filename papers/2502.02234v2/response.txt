\section{Related Work}
\label{sec:sec2}

\subsection{Incomplete Multi-view Clustering}

Existing IMvC approaches can be generally grouped into: traditional IMvC methods **Zhang, "A Survey on Incomplete Multi-View Clustering"** and deep IMvC algorithms **Kim et al., "Deep Incomplete Multi-View Clustering"**. 

Traditional IMvC methods commonly build upon matrix factorization, kernel learning, and graph learning technologies. Matrix factorization-based approaches derive a view-shared representation across diverse views via the matrix factorization techniques **Li et al., "Matrix Factorization for Incomplete Multi-View Data"**. For instance, an adaptive feature weighting manner is inserted into matrix factorization to mitigate the effects of redundant and noisy features on the learned view-shared representation, which is also regularized with a graph-embedded consensus constraint to preserve the structural information inherent in incomplete multi-view data. Kernel-based methods **Wang et al., "Kernel-Based Incomplete Multi-View Clustering"** utilizes a set of per-computed kernels to measure diverse views, tending to formulate a unified kernel through linear or non-linear combinations of predefined kernels to capture the clustering results. Liu et al., **Liu et al., "Incomplete Kernel Matrices Imputation and Alignment for Clustering"** jointly conduct incomplete kernel matrices imputation and alignment to capture an advanced clustering representation. Graph-based methods **Zhang, "Graph-Based Incomplete Multi-View Clustering"** integrate graph similarities captured from various views via either self-representation  or adaptive neighbor graph learning  manner, ultimately obtaining the clustering results through spectral clustering. Li et al., **Li et al., "Cross-View Information Refinement for Graph Structure Learning"** explored the cross-view information to refine the graph structure by leveraging the tensor nuclear norm. Deep learning-based methods **Chen et al., "Deep Incomplete Multi-View Clustering with Contrastive Learning"** leverage the powerful representation capabilities of deep neural networks to derive consensus clustering results from multi-view data. For example, Lin et al., **Lin et al., "Contrastive Learning for Incomplete Multi-View Data"** learned the consensus representation across diverse views by contrastive learning and recovered the missing views by cross-view prediction. Xue et al., **Xue et al., "Multi-Graph Contrastive Regularization for Clustering"** developed a multi-graph contrastive regularization to reduce abundant correlations
across multiple views and learn discriminative representations for clustering. 

Previous IMvC methods have made significant strides in improving clustering performance following the main pipeline that imputes missing views and conducts clustering. However, the imputation procedure without the true data distributions inevitably causes inaccurate imputed missing views, which in turn degrade clustering performance. Different from them, we learn a view-common representation only from the observed parts of incomplete multi-view without the imputation procedure. To this end, we propose a mask-informed deep contrastive incomplete multi-view clustering method that reduces the impacts of missing values among different views on formulating a view-common representation from multiple views for clustering.

\subsection{Contrastive Learning}

Contrastive learning is a novel self-supervised learning paradigm that has achieved significant success across various computer vision and machine learning tasks **Chen et al., "Survey on Contrastive Learning"**. Its core principle involves pushing samples away from their negative anchors while pulling samples closer to their positive anchors, thereby creating a discriminative representation for downstream tasks  . Over the past few years, different contrastive learning approaches have emerged, including MoCo **He et al., "Momentum Contrast"**, SimCLR **Chen et al., "Simple Framework for Contrastive Learning"**, and SwAV **Caron et al., "SwAV: Self-Learning with a Single Sample"**. For a comprehensive overview of additional methods, we refer to the survey in . 

Recently, inspired by the robust feature learning capabilities of self-supervised learning, contrastive loss has been extensively applied in MvC. For instance, Xu et al., **Xu et al., "Multi-View Contrastive Learning for Clustering"** aligned multi-view information from both high-level semantics and low-level features through contrastive learning, effectively capturing common semantics for clustering. Additionally, the work in  explored the effectiveness of self-supervision and contrastive alignment within the multi-view clustering task. Luo et al., **Luo et al., "Contrastive Learning with Data Augmentation for Multi-View Clustering"** first fused multi-view information at the data level and then applied data augmentation for the fused data, making a shared feature extractor with a simple contrastive learning paradigm to capture robust features for clustering. However, previous methods typically treat the same samples from different views as positive pairs, while diverse samples across multiple views are considered negative pairs. This manner lacks the flexibility to leverage sample connection probabilities to enhance feature representation learning. Thus, we propose prior knowledge-assisted contrastive learning to inject the sample connection probabilities from diverse views into the view-common feature representation with a carefully designed re-weighted contrastive loss. In such a manner, the view-common feature representation full of structural information is beneficial for recovering the underlying cluster structure of data.


%------------------------------------------------------------------------
\begin{figure*}[!htbp]
	\centering
	\includegraphics[width = 0.8\linewidth]{IMvC.jpg}
	\caption{Illustration of mask-informed deep contrastive incomplete multi-view clustering (Mask-IMvC). The view-complete parts of IMvC data are first processed through their encoders to extract view-specific latent features. Next, a mask-informed fusion module aggregates the representations into a unified view-common one, which is then used to reconstruct the view complete parts of IMvC data via view-specific decoders. Finally, the prior knowledge from different views is fused via the mask-informed fusion strategy to assist the contrastive learning on the view-common representation.}
	\label{fig:IMvC}