\section{Related Work}

\subsection{FlavorGraph}

FlavorGraph \cite{Park2019} is a heterogeneous graph \( G = (V, E) \) integrating ingredient co-occurrence and molecular profiling to model food-chemical interactions. By leveraging metapath-based learning \cite{Dong2017}, it enables systematic ingredient discovery and predictive food pairing through shared molecular properties.

\subsubsection{Metapath2Vec}

To learn chemically meaningful embeddings, we employ \textbf{Metapath2Vec}, which captures high-order relations via structured random walks. Ingredients are classified into hub ingredients (\( H \)), which directly connect to chemical compounds, and non-hub ingredients (\( N \)), which lack direct chemical links and rely on hub ingredients to acquire chemical insights.

The metapath sampling strategy follows:

\begin{equation*}
    N \rightarrow H \rightarrow C \rightarrow H \rightarrow N
\end{equation*}

where \( C \) represents chemical compounds. This structured propagation ensures that non-hub ingredients inherit chemical relevance, enhancing embedding robustness and interpretability.

\subsubsection{Architecture}

The network, parameterized by \( \theta \), takes node pairs \( (i, j) \) as input and outputs an edge score \( s_{\theta}(i, j) \), normalized across all embeddings:

\begin{equation*}
    s_{\theta}(i, j) = \sigma(\mathbf{u}_i^T \mathbf{u}_j)
\end{equation*}

where \( \mathbf{u}_i \) and \( \mathbf{u}_j \) are the learned embeddings for nodes \( i \) and \( j \), ensuring consistency across culinary co-occurrence and chemical similarity.

\subsubsection{Loss Function}

Embeddings are optimized using Skip-Gram with Negative Sampling (SGNS):

\begin{equation*}
    J_{\theta} = \sum_{(i, j) \in D} \log \sigma(\mathbf{u}_i^T \mathbf{u}_j) + \sum_{(i, j') \in D'} \log \sigma(-\mathbf{u}_i^T \mathbf{u}_{j'})
\end{equation*}

where \( D \) and \( D' \) are positive and negative sample pairs. To enforce chemical relevance, an additional \textbf{Chemical Structure Prediction (CSP)} loss is introduced:

\begin{equation*}
    L_{\text{CSP}, \theta} = \sum_{d=1}^{D} y_d \log f_{\theta, d}(i) + (1 - y_d) \log (1 - f_{\theta, d}(i))
\end{equation*}

where \( f_{\theta, d}(i) \) predicts the presence of the \( d \)-th molecular substructure \( y_d \), refining embeddings with molecular fingerprints.

\subsection{DIFUSCO}

Graph-based diffusion models have recently emerged as powerful frameworks for solving combinatorial optimization problems by leveraging probabilistic generative processes. In our work, we leverage the fundamental principles of graph-based diffusion models, particularly the Gaussian diffusion framework, to reconstruct structured graph representations. By incorporating diffusion-driven embeddings into our heterogeneous network, we enhance the predictive accuracy of food-chemical interactions while maintaining interpretability. This approach allows for the seamless integration of molecular-level insights into ingredient pairing research, further advancing computational gastronomy.
