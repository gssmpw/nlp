@article{adlam2020cold,
      title={Cold Posteriors and Aleatoric Uncertainty}, 
      author={Ben Adlam and Jasper Snoek and Samuel L. Smith},
      year={2020},
    journal={arXiv preprint arXiv:2008.00029}
}

@article{wenzel2020good,
    title={How Good is the {Bayes} Posterior in Deep Neural Networks Really?},
author={Florian Wenzel and Kevin Roth and Bastiaan S. Veeling and Jakub Swiatkowski and Linh Tran and Stephan Mandt and Jasper Snoek and Tim Salimans and Rodolphe Jenatton and Sebastian Nowozin},
year={2020},
journal={International Conference on Machine Learning (ICML)}
}

@article{kobyzev2020normalizing,
  title={Normalizing flows: An introduction and review of current methods},
  author={Kobyzev, Ivan and Prince, Simon JD and Brubaker, Marcus A},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={3964--3979},
  year={2020},
  publisher={IEEE}
}

@article{papamakarios2021normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={57},
  pages={1--64},
  year={2021},
}

@article{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  year={2015},
journal={International Conference on Machine Learning (ICML)}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  year={2021},
  journal={International Conference on Learning Representations (ICLR)}
}

@article{song2020improved,
  title={Improved techniques for training score-based generative models},
  author={Song, Yang and Ermon, Stefano},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020},
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020},
}

@article{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  year={2021},
  journal={International Conference on Machine Learning (ICML)}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  year={2021},
  journal={International Conference on Learning Representations (ICLR)}
}

@article{anderson1982reverse,
  title={Reverse-time diffusion equation models},
  author={Anderson, Brian DO},
  journal={Stochastic Processes and their Applications},
  volume={12},
  number={3},
  pages={313--326},
  year={1982},
  publisher={Elsevier}
}

@book{sarkka2019applied,
  title={Applied stochastic differential equations},
  author={S{\"a}rkk{\"a}, Simo and Solin, Arno},
  volume={10},
  year={2019},
  publisher={Cambridge University Press}
}

@article{akhound2024iterated,
  title={Iterated denoising energy matching for sampling from Boltzmann densities},
  author={Akhound-Sadegh, Tara and Rector-Brooks, Jarrid and Bose, Avishek Joey and Mittal, Sarthak and Lemos, Pablo and Liu, Cheng-Hao and Sendera, Marcin and Ravanbakhsh, Siamak and Gidel, Gauthier and Bengio, Yoshua and others},
  year={2024},
  journal={International Conference on Machine Learning (ICML)}
}

@article{de2024target,
  title={Target Score Matching},
  author={De Bortoli, Valentin and Hutchinson, Michael and Wirnsberger, Peter and Doucet, Arnaud},
  journal={arXiv preprint arXiv:2402.08667},
  year={2024},
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  year={2023},
  journal={International Conference on Learning Representations (ICLR)}
}

@article{tong2023improving,
  title={Improving and generalizing flow-based generative models with minibatch optimal transport},
  author={Tong, Alexander and Fatras, Kilian and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and Rector-Brooks, Jarrid and Wolf, Guy and Bengio, Yoshua},
  journal={Transactions on Machine Learning Research},
  year={2024},
}

@article{albergo2023stochastic,
  title={Stochastic interpolants: A unifying framework for flows and diffusions},
  author={Albergo, Michael S and Boffi, Nicholas M and Vanden-Eijnden, Eric},
  journal={arXiv preprint arXiv:2303.08797},
  year={2023},
}

@article{albergo2023dependent,
  title={Stochastic interpolants with data-dependent couplings},
  author={Albergo, Michael S and Goldstein, Mark and Boffi, Nicholas M and Ranganath, Rajesh and Vanden-Eijnden, Eric},
  year={2024},
  journal={International Conference on Machine Learning (ICML)}
}

@article{kingma2016improved,
  title={Improved variational inference with inverse autoregressive flow},
  author={Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  journal={Neural Information Processing Systems (NIPS)},
  year={2016}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={International Conference on Learning Representations (ICLR)},
  year={2014}
}

@article{rezende2014stochastic,
  title={Stochastic backpropagation and variational inference in deep latent {Gaussian} models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  journal={International Conference on Machine Learning (ICML)},
  year={2014}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{hoffman2013stochastic,
  title={Stochastic variational inference},
  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
  journal={Journal of Machine Learning Research},
  year={2013},
  volume={14},
  pages={1303--1347}
}

@article{hoffman2014no,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  author={Hoffman, Matthew D and Gelman, Andrew},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1593--1623},
  year={2014}
}

@article{neal2012mcmc,
title={{MCMC} using {Hamiltonian} dynamics},
author={Neal, Radford M},
journal={Handbook of Markov Chain Monte Carlo},
volume={2},
number={11},
pages={2},
year={2011},
publisher={Chapman and Hall/CRC}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@techreport{more1982newton,
  title={Newton's method},
  author={Mor{\'e}, Jorge J and Sorensen, Danny C},
  year={1982},
  institution={Argonne National Lab.(ANL), Argonne, IL (United States)}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Ma, Jingyuan and Li, Rui and Xia, Heming and Xu, Jingjing and Wu, Zhiyong and Liu, Tianyu and others},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022},
}

@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2022},
}

@article{von2023transformers,
  title={Transformers learn in-context by gradient descent},
  author={Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max},
  journal={International Conference on Machine Learning (ICML)},
  year={2023},
}

@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? Investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023},
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit {Bayesian} inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={International Conference on Learning Representations (ICLR)},
  year={2022},
}

@article{mittal2024does,
  title={Does learning the right latent variables necessarily improve in-context learning?},
  author={Mittal, Sarthak and Elmoznino, Eric and Gagnon, Leo and Bhardwaj, Sangnie and Sridhar, Dhanya and Lajoie, Guillaume},
  journal={arXiv preprint arXiv:2405.19162},
  year={2024},
}

@article{elmoznino2024context,
  title={In-context learning and Occam's razor},
  author={Elmoznino, Eric and Marty, Tom and Kasetty, Tejas and Gagnon, Leo and Mittal, Sarthak and Fathi, Mahan and Sridhar, Dhanya and Lajoie, Guillaume},
  journal={arXiv preprint arXiv:2410.14086},
  year={2024},
}


@article{hendel2023context,
  title={In-context learning creates task vectors},
  author={Hendel, Roee and Geva, Mor and Globerson, Amir},
  journal={Findings of Empirical Methods in Natural Language Processing (EMNLP)},
  year={2023},
}

@article{bischl2019openmlcc18,
      title={OpenML Benchmarking Suites}, 
      author={Bernd Bischl and Giuseppe Casalicchio and Matthias Feurer and Frank Hutter and Michel Lang and Rafael G. Mantovani and Jan N. van Rijn and Joaquin Vanschoren},
      year={2021},
      journal={Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track}
}

@inproceedings{mittal2023exploring,
  title={Exploring Exchangeable Dataset Amortization for Bayesian Posterior Inference},
  author={Mittal, Sarthak and Bracher, Niels Leif and Lajoie, Guillaume and Jaini, Priyank and Brubaker, Marcus A},
  booktitle={ICML 2023 Workshop on Structured Probabilistic Inference $\{$$\backslash$\&$\}$ Generative Modeling},
  year={2023},
}

@inproceedings{fischer2023openmlctr23,
title={Open{ML}-{CTR}23 {\textendash} A curated tabular regression benchmarking suite},
author={Sebastian Felix Fischer and Matthias Feurer and Bernd Bischl},
booktitle={AutoML Conference 2023 (Workshop)},
year={2023},
url={https://openreview.net/forum?id=HebAOoMm94}
}

@article{radev2020bayesflow,
  title={BayesFlow: Learning complex stochastic models with invertible neural networks},
  author={Radev, Stefan T and Mertens, Ulf K and Voss, Andreas and Ardizzone, Lynton and K{\"o}the, Ullrich},
  journal={IEEE transactions on neural networks and learning systems},
  volume={33},
  number={4},
  pages={1452--1466},
  year={2020},
  publisher={IEEE}
}

@article{pearson1936method,
  title={Method of moments and method of maximum likelihood},
  author={Pearson, Karl},
  journal={Biometrika},
  volume={28},
  number={1/2},
  pages={34--59},
  year={1936},
  publisher={JSTOR}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M and Nasrabadi, Nasser M},
  volume={4},
  number={4},
  year={2006},
  publisher={Springer}
}

@article{zhang2021path,
  title={Path integral sampler: a stochastic control approach for sampling},
  author={Zhang, Qinsheng and Chen, Yongxin},
  journal={International Conference on Learning Representations (ICLR)},
  year={2022},
}

@article{vargas2023denoising,
  title={Denoising diffusion samplers},
  author={Vargas, Francisco and Grathwohl, Will and Doucet, Arnaud},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023},
}

@article{sendera2024improved,
  title={Improved off-policy training of diffusion samplers},
  author={Sendera, Marcin and Kim, Minsu and Mittal, Sarthak and Lemos, Pablo and Scimeca, Luca and Rector-Brooks, Jarrid and Adam, Alexandre and Bengio, Yoshua and Malkin, Nikolay},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2024},
}

@article{venkatraman2024amortizing,
  title={Amortizing intractable inference in diffusion models for vision, language, and control},
  author={Venkatraman, Siddarth and Jain, Moksh and Scimeca, Luca and Kim, Minsu and Sendera, Marcin and Hasan, Mohsin and Rowe, Luke and Mittal, Sarthak and Lemos, Pablo and Bengio, Emmanuel and others},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2024},
}

@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{welling2011bayesian,
  title={Bayesian learning via stochastic gradient {Langevin} dynamics},
  author={Welling, Max and Teh, Yee W},
  journal={International Conference on Machine Learning (ICML)},
  year={2011},
}

@article{chen2014stochastic,
  title={Stochastic gradient {Hamiltonian Monte Carlo}},
  author={Chen, Tianqi and Fox, Emily and Guestrin, Carlos},
  journal={International Conference on Machine Learning (ICML)},
  year={2014},
}

@article{doob1949,
    title={Application of the theory of martingales},
    author={Doob, J.L.},
    journal={Colloque International Centre Nat. Rech. Sci.},
    pages={22--28},
    year={1949}
}

@article{miller2018detailed,
    title={A detailed treatment of {Doob’s} theorem},
    author = {Miller, Jeffrey W.},
    journal={arXiv preprint arXiv:1801.03122},
    year={2018}
}

@article{miller2021asymptotic,
    author = {Miller, Jeffrey W.},
    title = {Asymptotic normality, concentration, and coverage of generalized posteriors},
    year = {2021},
    volume = {22},
    number  = {168},
    pages   = {1--53},
    journal = {Journal of Machine Learning Research},
}

@article{garnelo2018neural,
  title={Neural processes},
  author={Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J and Eslami, SM and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1807.01622},
  year={2018}
}

@book{neal1996bayesian,
  title={Bayesian learning for neural networks},
  author={Neal, Radford M},
  year={1996},
  publisher={Springer}
}

@article{hernandez2015probabilistic,
  title={Probabilistic backpropagation for scalable learning of {Bayesian} neural networks},
  author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Adams, Ryan},
  journal={International Conference on Machine Learning (ICML)},
  year={2015},
}

@article{muller2021transformers,
  title={Transformers can do {Bayesian} inference},
  author={M{\"u}ller, Samuel and Hollmann, Noah and Arango, Sebastian Pineda and Grabocka, Josif and Hutter, Frank},
  journal={International Conference on Learning Representations (ICLR)},
  year={2022},
}

@article{hollmann2022tabpfn,
  title={{TabPFN}: A transformer that solves small tabular classification problems in a second},
  author={Hollmann, Noah and M{\"u}ller, Samuel and Eggensperger, Katharina and Hutter, Frank},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023},
}

@article{blessing2024beyond,
  title={Beyond {ELBOs}: A Large-Scale Evaluation of Variational Methods for Sampling},
  author={Blessing, Denis and Jia, Xiaogang and Esslinger, Johannes and Vargas, Francisco and Neumann, Gerhard},
  journal={International Conference on Machine Learning (ICML)},
  year={2024},
}

@article{rainforth2018tighter,
  title={Tighter variational bounds are not necessarily better},
  author={Rainforth, Tom and Kosiorek, Adam and Le, Tuan Anh and Maddison, Chris and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},
  year={2018},
  journal={International Conference on Machine Learning (ICML)}
}

@article{hinton1995wake,
  title={The ``wake-sleep'' algorithm for unsupervised neural networks.},
  author={Geoffrey E. Hinton and Peter Dayan and Brendan J. Frey and R M Neal},
  journal={Science},
  year={1995},
  volume={268 5214},
  pages={
          1158-61
        }
}

@article{cremer2018inference,
    title={Inference Suboptimality in Variational Autoencoders},
    author={Chris Cremer and Xuechen Li and David Duvenaud},
    journal={International Conference on Machine Learning (ICML)},
    year={2018}
}

@book{devroye1996probabilistic,
    title={A Probabilistic Theory of Pattern Recognition},
    author={Devroye, Luc and Gy{\"o}rfi, L{\'a}szl{\'o} and Lugosi, G{\'a}bor},
    publisher={Springer},
    year={1996}
}

@article{falck2024incontext,
    title={Is In-Context Learning in Large Language Models {Bayesian}? A Martingale Perspective},
    author={Fabian Falck and Ziyu Wang and Chris Holmes},
    journal={International Conference on Machine Learning (ICML)},
    year={2024},
}

@article{andrieu2003introduction,
  title={An introduction to {MCMC} for machine learning},
  author={Andrieu, Christophe and De Freitas, Nando and Doucet, Arnaud and Jordan, Michael I},
  journal={Machine learning},
  volume={50},
  pages={5--43},
  year={2003},
  publisher={Springer}
}

@article{ritter2018scalable,
  title={A scalable laplace approximation for neural networks},
  author={Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  year={2018},
  journal={International Conference on Representation Learning (ICLR)}
}

@article{gilks1996strategies,
  title={Strategies for improving {MCMC}},
  author={Gilks, Walter R and Roberts, Gareth O},
  journal={Markov chain Monte Carlo in practice},
  volume={6},
  pages={89--114},
  year={1996}
}


@article{ferbach2024proving,
  author={Damien Ferbach and Baptiste Goujaud and Gauthier Gidel and Aymeric Dieuleveut},
  title={Proving Linear Mode Connectivity of Neural Networks via Optimal Transport},
  year={2024},
  journal={Artificial Intelligence and Statistics (AISTATS)}
}

@article{gelberg2024variational,
    title={Variational Inference Failures Under Model Symmetries: Permutation Invariant Posteriors for {Bayesian} Neural Networks}, 
      author={Yoav Gelberg and Tycho F. A. van der Ouderaa and Mark van der Wilk and Yarin Gal},
      year={2024},
      journal={arXiv preprint arXiv:2408.05496}
}

@article{draxler2019essentially,
      title={Essentially No Barriers in Neural Network Energy Landscape}, 
      author={Felix Draxler and Kambis Veschgini and Manfred Salmhofer and Fred A. Hamprecht},
      year={2018},
      journal={International Conference on Machine Learning (ICML)}
}

@article{sharma2023bayesian,
      title={Do {Bayesian} Neural Networks Need To Be Fully Stochastic?}, 
      author={Mrinank Sharma and Sebastian Farquhar and Eric Nalisnick and Tom Rainforth},
      year={2023},
      journal={Artificial Intelligence and Statistics (AISTATS)}
}

@article{daxberger2022bayesian,
      title={Bayesian Deep Learning via Subnetwork Inference}, 
      author={Erik Daxberger and Eric Nalisnick and James Urquhart Allingham and Javier Antorán and José Miguel Hernández-Lobato},
      year={2021},
    journal={International Conference on Machine Learning (ICML)}
}
@article{doan2025bayesian,
      title={Bayesian Low-Rank LeArning (Bella): A Practical Approach to {Bayesian} Neural Networks}, 
      author={Bao Gia Doan and Afshar Shamsi and Xiao-Yu Guo and Arash Mohammadi and Hamid Alinejad-Rokny and Dino Sejdinovic and Damien Teney and Damith C. Ranasinghe and Ehsan Abbasnejad},
      year={2025},
      journal={Association for the Advancement of Artificial Intelligence (AAAI)}
}

@article{teicher1963identifiability,
  title={Identifiability of finite mixtures},
  author={Teicher, Henry},
  journal={The Annals of Mathematical statistics},
  pages={1265--1269},
  year={1963},
  publisher={JSTOR}
}

@article{yakowitz1968identifiability,
  title={On the identifiability of finite mixtures},
  author={Yakowitz, Sidney J and Spragins, John D},
  journal={The Annals of Mathematical Statistics},
  volume={39},
  number={1},
  pages={209--214},
  year={1968},
  publisher={Institute of Mathematical Statistics}
}