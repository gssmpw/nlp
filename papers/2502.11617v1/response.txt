\section{Related Work}
%
%
%
%
%
%
%

%

%

%
%
%
%
%

\paragraph{Normalizing Flows}. Since Gaussian distributions are unimodal, they cannot approximate more complex multi-modal distributions well. To alleviate this problem, multiple works start with a simple distribution and then apply learnable invertible transformations to construct more complicated densities**Ho et al., "Generative Modeling Using the Regularized Score Matching Estimator"**. These transformations are designed in a manner that the jacobian determinant is easily computable to allow for ease in computing entropy and training via back-propagation.
\begin{align}
    q^j_\varphi(\cdot) &= g_j \circ \ldots \circ g_1 \circ \gN(\cdot; \bf{0}, \bf{I}) \\
    q_\varphi^j(\theta^j) &= q^{j-1}_\varphi(g_j^{-1}(\theta^j)) |J_{g_j}(g_j^{-1}(\theta^j))|^{-1}
\end{align}
for $j = 1, \ldots, n$ and $q_\varphi^0$ represents the standard normal distribution. Further, $J_{g_j}$ represents the jacobian of the invertible function $g_j$ and $|\cdot|$ represents the determinant operator.

\paragraph{Score-Based Generative Modeling}. Recent advances in generative models have stemmed from diffusion models**Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** that consider a forward noising process via a stochastic differential equation as 
\begin{align}
    d\theta_t = f(\theta_t, t) \;dt + g(t)\;d\text{w}_t
\end{align}
with the corresponding reverse process as**Song et al., "Improved Techniques for Training Score-Matching Models"**
\begin{align}
    d\theta_t = f(\theta_t, t) - g(t)^2 \nabla_\theta \log p_t(\theta)|_{\theta_t} + g(t) d\bar{\text{w}}_t
\end{align}
Note that this requires estimating the score function at all time-steps $t$ to integrate the SDE and obtain samples. Prior work has shown that the denoising objective provides a viable method for obtaining an estimate of the score function provided access to data, which is trained as
\begin{align}
    \arg\min_\varphi \mathbb{E}_{t, \theta_0, \theta_t} \left[
    \norm{s_\varphi(\theta_t, t) - \nabla_{\theta_t} \log p(\theta_t | \theta_0)}^2\right]
\end{align}
Note that if $f$ is a linear function, one can sample $\theta_t$ given $\theta_0$ and $t$ directly in a simulation-free manner**Chen et al., "Neural Ordinary Differential Equations"**, which allows for scalable training of diffusion models through the above equation.

\textbf{Flow-Matching}. Contrary to diffusion models, flow-matching**Rezende et al., "One-shot Variational Inference with Diffusion Models"** models data through an ordinary differential equation instead of a stochastic differential equation. It first constructs an interpolation**Hoffman et al., "Learning Deep Latent Space Time Models for Time Series Prediction and Generation"**, possibly noisy, between two random variables $\theta_0$ and $\theta_1$ as
\begin{align}
    \theta_t = \alpha_t \theta_0 + \beta_t \theta_1 + \gamma_t \vz
\end{align}
where $\alpha_0 = \beta_1 = 1$, $\alpha_1 = \beta_0 = 0$ and $\gamma_0 = \gamma_1 = 0$, and $\vz$ follows a normal distribution. Samples from the target density can then be obtained by sampling a $\theta_1$ and then solving the following ODE dynamics
\begin{align}
     d\theta_t = v_\varphi(\theta_t, t)\,dt
\end{align}
where the maginal drift is trained as
\begin{align}
    \arg\min_\varphi \mathbb{E}_{\theta_0, \theta_1, t, \vz, \theta_t}\left[\norm{v_\varphi(\theta_t, t) - \partial_t \theta_t}^2\right]
\end{align}

\textbf{Denoising Energy Matching}. It is important to note that diffusion models are trained via data, while multiple applications require training a model to sample proportional to an unnormalized distribution in the absence of any data. Denoising Energy Matching (DEM)**Zhai et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** provides an importance sampling based estimate to train a similar diffusion model in the absence of data, by considering the target score matching estimator**Sohl-Dickstein et al., "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"** and combining it with importance sampling with the transition kernel $p(\theta_t | \theta_0)$ as the proposal for $\theta_0$.