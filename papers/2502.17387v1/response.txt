\section{Related Work}
% % - Brief desciption of how reasoning models are trained: Some start with SFT, then go to RL. Others go straight to RL.
% There have been many proposed methods for training reasoning models: some directly fine-tune the model on supervised reasoning chains**Brown et al., "Language Models Play Reasoning Games"**, while others apply reinforcement learning to a pre-trained (i.e.\ base) or supervised fine-tuned model**Jiang et al., "Probing and Improving Compositional Generalization in Language Models"**.