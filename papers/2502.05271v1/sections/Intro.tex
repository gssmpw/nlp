\section{Introduction}
\label{sec:introduction}

Moving large objects such as furniture is a common challenge in human spaces. Whether it is rearranging a living room or organizing a workspace, these tasks often require significant effort. While people have traditionally handled these tasks independently, there is an increasing interest in developing autonomous robots that can help. The ability for robots to assist in moving large objects would not only reduce physical strain on humans, but also enable greater efficiency in various settings, ranging from households to industrial logistics.   



While there has been significant progress in enabling robots to rearrange small items~\citep{SayCan, chi2023diffusion, black2024pi_0, team2024octo}, manipulating large objects presents a unique set of challenges. These challenges arise in two areas, as illustrated in Figure~\ref{fig:challenge}. First, when objects are large enough, they impose non-negligible spatial constraints. Without advanced control policies, the object may collide with the robot or its surroundings, potentially causing damage to both the system and the object. Second, large objects typically exceed the lifting capacity of most robots, requiring robots to manage the object's momentum and overcome the ground friction during movement. These challenges require developing dynamic control policies that can synchronize the movements of the manipulator and the object, and address the under-actuated nature of large object manipulation tasks. 



Several approaches have been proposed to address these challenges. Model-based methods rely on accurately modeling the dynamics of the robot, the object, and their interactions. 
However, modeling a wide range of object interactions and dynamics is challenging, limiting the generalizability of these methods across different scenarios. 
Reinforcement learning allows robots to learn through trial and error, but requires designing reward functions that can generalize effectively across diverse objects. While imitation learning through teleoperation has shown success in various applications~\citep{RoboImitationPeng20, MobileAloha, lu2024mobile}, this approach is limited by its reliance on skilled operators and the significant time required to collect demonstration data, particularly when manipulating large and heavy objects. These limitations highlight the need for more efficient and scalable solutions to enable robots to handle large objects effectively.



In this work, we propose \method, a generalizable learning framework for robots to manipulate large objects by leveraging demonstrations of humans interacting with objects. Our framework uses human and object movements as a reference to generate an imitation reward. Using this reward, we train a control policy in a simulation environment with domain randomization, enabling zero-shot transfer to the real world.  A key aspect of this approach is to overcome the morphological differences between humans and robots, which makes it infeasible to directly copy the joint angles for imitation. To resolve this, we introduce the Dynamic Chain, a novel representation for describing human-object interactions. The Dynamic Chain is a chain structure connecting every joint from the human’s root to the object’s root, with each joint serving as a vertex on the chain. The movement of the Dynamic Chain captures how humans transmit force from their ``core'' into the object. Compared to whole-body movements, the Dynamic Chain provides an abstract representation that can be easily retargeted to the robot's morphology. We use the Dynamic Chain as the imitation reference to train the robot's policy, enabling it to effectively manipulate large objects.





To evaluate the effectiveness of our method, we conduct a series of experiments in both simulated and real-world environments. In simulation, we test the Dynamic Chain framework against reinforcement learning, end-effector tracking, and inverse kinematics (IK) methods. Our results indicate that the Dynamic Chain outperforms these baselines tracking target object trajectories. On hardware, we deploy policies trained using the Dynamic Chain on a Spot robot and compare them against two learning-based baselines and two types of teleoperation. We propose six metrics to evaluate the robot's behavior in terms of robustness, capability, and controllability. RobotMover outperforms baselines in all aspects, showcasing its adaptability and effectiveness in handling diverse large objects. Finally, by combining our learned policy with a motion planner, we demonstrate our framework in two real-world applications: trash cart transporation and chair rearrangement, highlighting the practical utility of our approach.

In summary, this paper makes three main contributions:
\begin{itemize}
    \item A new robot task: We propose an important and challenging robot task: \emph{large object manipulation}, with challenges not typically encountered when manipulating small objects, such as synchronizing the robot's whole-body movement and learning a dynamical control strategy to overcome the shape and momentum of the target objects.
    \item A generalizable learning framework: We introduce a generalizable learning framework for robots to manipulate large objects by imitating the Dynamic Chain derived from human-object interaction demonstrations.
    \item We conduct several experiments to evaluate our approach in simulation and hardware, demonstrating that our framework enables robots to reliably move diverse objects and can be used for real-world applications.
\end{itemize}

\setcounter{figure}{1}
\begin{figure}[t]
\centering
\includegraphics[width=.995\linewidth]{figures/challenge.png}
\caption{Challenges of moving large objects include but not limit to object colliding with the robot and object falls off from the robot's gripper due to high momentum.}
\label{fig:challenge}
\vspace{-0.5cm}
\end{figure}
