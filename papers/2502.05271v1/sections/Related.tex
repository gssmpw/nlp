\section{Related Works}


\subsection{Mobile Manipulation}

Mobile manipulation tasks that involve robot locomotion and interaction capabilities have been a prominent topic in robotics research~\citep{MobileAloha, TidyBot, Naoki_ASC, Behavior, Habitat, mittal2022articulated, DeepWholeBody, RT1, SayCan}. Many mobile manipulation approaches rely on model-based control, which generally requires domain expertise to design a model tailored to a system and task
~\citep{krotkov2018darpa, wyrobek2008towards, khatib1996force, garrett2021integrated}. 
Recently, learning-based approaches have been applied to mobile manipulation, alleviating much of the heavy engineering effort. These methods have addressed a variety of challenging real-world tasks, such as mobile pick-and-place~\citep{Naoki_ASC, sun2022fully, Homerobot, ha2024umi}, manipulation of articulated objects~\citep{xiong2024adaptive, shafiullah2023bringing, yang2023moma}, and long-horizon cooking tasks~\citep{MobileAloha}. There has also been an interest in creating more interactive and user-friendly robotic systems by integrating primitive mobile manipulation skills with Large Language Models~\citep{TidyBot, RT1, SayCan}. However, most prior work has focused on robots interacting with objects that are small and light, where the dynamic effects of these objects are usually negligible for manipulation. In this work, we study robot learning for rearranging large and heavy objects, such as furniture or a trash truck, where it is necessary to account for these effects.



\subsection{Large Object Manipulation}

While robots that can manipulate large objects are common in industrial applications, they operate in controlled environments, where the objects are known and the dynamics more easily predictable. More recently, some efforts have been made to allow robots to move large objects in more uncontrolled environments, either by training them to imitate teleoperation demonstrations~\citep{MobileAloha} or via curiosity-driven methods~\citep{mendonca2024continuously}. However, collecting teleoperation data is known to be time-consuming, and the collected data can only be used on the same robot platform. Curiosity-driven methods are challenging to control for real-world applications. \citet{ravan2024combining} addresses the problem of manipulating a wheeled chair without simulation. In this work, we introduce a generalizable learning framework that enables robots to manipulate large objects from human demonstrations.







\subsection{Imitation Learning for Robotics}

Imitation learning approaches aim to train robot policies by leveraging expert demonstrations. A common method is behavioral cloning, which learns a policy by mimicking the demonstration's actions and has shown promising results in a wide range of robot tasks~\citep{MobileAloha, chi2023diffusion, jang2022bc, li2019using, shafiullah2022behavior}. For more dynamic tasks, such as agile locomotion, demonstrations provide reference poses that be used as an imitation reward~\citep{RoboImitationPeng20, whirl} or an adversarial reward~\citep{Escontrela22arXiv_AMP_in_real} to train policies in simulation through reinforcement learning. However, to use demonstrations as reference pose targets, the demonstrations must have the same morphology as the robot. 

In settings where robots have significantly different embodiments compared to the demonstrator, such as in 
legged manipulators, the correspondence between the demonstrator and the robot must be properly established to transfer knowledge. This can be achieved through unsupervised learning~\citep{li2023crossloco, li2023ace} or data augmentation~\citep{hirose2023exaug}. Our work is closely related to \citep{InteractionGraph}, which introduces Interaction Graph as a representation for training object interactions in humanoid robots using human demonstrations.
However, the Interaction Graph is a high-dimensional representation that only works between similar morphologies. In our work, we propose the Dynamic Chain, a representation that leverages human whole-body motion data to train policies for robots with different morphologies.






