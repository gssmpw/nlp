\section{Limitations}
Although our method achieves promising results, we recognize several limitations that we aim to address in the future.

The first limitation lies in our treatment of the object-grasping process. In this work, our focus is on how the robot dynamically manipulates the object after grasping, which led to less emphasis on the grasping phase itself. In simulation, we initialize the robot's pose such that the gripper is close to the object, allowing it to make contact blindly. On hardware, the robot is manually initialized to grasp the object. Additionally, to ensure the control frequency as well as since the camera is blocked by the object after grasping, our control policy does not incorporate any camera input. In future work, we plan to develop a vision-based policy that enables the robot to navigate to the target object, grasp it at the correct contact location, to automatically provide initial contact conditions for the object moving policy.

Another limitation concerns the capability of the trained policies. While the proposed imitation method generalizes well to different objects and demonstrations, in this work, we train separate policies for different types of objects. Consequently, each policy is limited to handling objects with similar dynamic properties. In our future work, we aim to develop a single policy that can manage a wide variety of objects and execute diverse manipulation strategies, even for the same object. To achieve this, we intend to explore advanced techniques, such as diffusion policies, to enhance generalization and adaptability.




