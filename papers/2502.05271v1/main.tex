 \documentclass[conference]{IEEEtran}
\usepackage{times}

\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}

\input{preamble}
\input{defs}



\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

\begin{document}

\title{RobotMover: Learning to Move \\ Large Objects by Imitating the Dynamic Chain}


\author{\authorblockN{Tianyu Li$^{1,*}$, Joanne Truong$^{2}$, Jimmy Yang$^{2}$, Alexander Clegg$^{2}$, Akshara Rai$^{2}$, Sehoon Ha$^{1}$, Xavier Puig$^{2}$}
\authorblockA{
$^{1}$Georgia Institute of Technology, $^{2}$FAIR, Meta  \\
$^{*}$Work done during an internship at FAIR, Meta. \\
Email: tli471@gatech.edu
}
}









\makeatletter
\let\@oldmaketitle\@maketitle%
\renewcommand{\@maketitle}{\@oldmaketitle%
    \centering
    \includegraphics[width=0.9\linewidth]{figures/front_page.png}
    \captionof{figure}{\method \  enables robots to move a variety of large objects. }
    \label{fig:teaser}
}
\makeatother

\maketitle


\begin{abstract}
Moving large objects, such as furniture, is a critical capability for robots operating in human environments. This task presents significant challenges due to two key factors: the need to synchronize whole-body movements to prevent collisions between the robot and the object, and the under-actuated dynamics arising from the substantial size and weight of the objects. 
These challenges also complicate performing these tasks via teleoperation. 
In this work, we introduce \method, a generalizable learning framework that leverages human-object interaction demonstrations to enable robots to perform large object manipulation tasks. Central to our approach is the Dynamic Chain, a novel representation that abstracts human-object interactions so that they can be retargeted to robotic morphologies. 
The Dynamic Chain is a spatial descriptor connecting the human and object root position via a chain of nodes, which encode the position and velocity of different interaction keypoints.
We train policies in simulation using Dynamic-Chain-based imitation rewards and domain randomization, enabling zero-shot transfer to real-world settings without fine-tuning. 
Our approach outperforms both learning-based methods and teleoperation baselines across six evaluation metrics when tested on three distinct object types, both in simulation and on physical hardware. Furthermore, we successfully apply the learned policies to real-world tasks, such as moving a trash cart and rearranging chairs.


\end{abstract}

\IEEEpeerreviewmaketitle

\input{sections/Intro}
\input{sections/Related}
\input{sections/Method}
\input{sections/Model_representation}
\input{sections/Experiments}
\input{sections/Limitation}
\input{sections/Conclusion}



\bibliographystyle{plainnat}
\bibliography{references}


\input{sections/Appendix}

\end{document}
