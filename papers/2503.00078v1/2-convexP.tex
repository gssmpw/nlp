
\section{Convex program to compute the final sizes}
We present a convex program to compute the final sizes of the 2-group interacting SIR process. We first define the following functions using the equation system $(\ref{eq:finalsystem})$ in Section \ref{sec:FinalSizes}.

\begin{align*}
    &f_1(s_1,s_2)=s_1-(1-\epsilon)\phi_1\cdot
    exp(\frac{\beta}{\gamma}(s_1-\phi_1)+\frac{\kappa\beta}{\gamma}(s_2-\phi_2))\\
    &f_2(s_1,s_2)=s_2-(1-\epsilon)\phi_2\cdot
    exp(\frac{\kappa\beta}{\gamma}(s_1-\phi_1)+\frac{\kappa^2\beta}{\gamma}(s_2-\phi_2))
\end{align*}
It's easy to see that $f_1(S_1,S_2)=0,f_2(S_1,S_2)=0$ where $S_1,S_2$ are the final sizes. We now define a convex program and show that its optimum solution is the final sizes.

\begin{align*}
    \min_{s_1,s_2}\quad &s_1+s_2\\
    \mathrm{s.t.}\quad &f_1(s_1,s_2)\geq 0\\
    &f_2(s_1,s_2)\geq 0\\
    &0\leq s_1\leq(1-\epsilon)\phi_1\\
    &0\leq s_2\leq(1-\epsilon)\phi_2
\end{align*}
Given a point $p(s_1,s_2)$, we say $p$ is $f_1$-feasible and $f_2$-feasible if $f_1(s_1,s_2)\geq 0$ and $f_2(s_1,s_2)\geq 0$, respectively.
The program is convex because $f_1,f_2$ are concave functions, and $f_1\geq 0,f_2\geq 0$ define convex regions.

\begin{lemma}
$f_1(s_1,s_2),f_2(s_1,s_2)$ are concave.
\end{lemma}
\begin{proof}
    We prove by providing the Hessian matrices.
    \begin{align*}
        H_{f_1}&=
        \begin{bmatrix}
        -(1-\epsilon)\phi_1\frac{\beta^2}{\gamma^2}e^X & -(1-\epsilon)\phi_1\kappa\frac{\beta^2}{\gamma^2}e^X\\
        -(1-\epsilon)\phi_1\kappa\frac{\beta^2}{\gamma^2}e^X & -(1-\epsilon)\phi_1\kappa^2\frac{\beta^2}{\gamma^2}e^X
        \end{bmatrix}\\
        &=-(1-\epsilon)\phi_1\frac{\beta^2}{\gamma^2}e^X \cdot
        \begin{bmatrix}
            1 & \kappa\\
            \kappa & \kappa^2
        \end{bmatrix}\\
        &=-(1-\epsilon)\phi_1\frac{\beta^2}{\gamma^2}e^X \cdot
        \begin{bmatrix}
            1\\
            \kappa
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
            1&\kappa
        \end{bmatrix}\\
    \end{align*}
    \todo{The above suffices}
    $\forall x\in \mathbb{R}^2$,
    \begin{align*}
        x^T H_{f_1} x =
        -(1-\epsilon)\phi_1\frac{\beta^2}{\gamma^2}e^X\cdot
        \Big(x^T 
        \begin{bmatrix}
            1\\
            \kappa
        \end{bmatrix}
        \Big)\cdot\Big(
        \begin{bmatrix}
            1&\kappa
        \end{bmatrix}
        x\Big)
        \leq 0
    \end{align*}
    Therefore $H_{f_1}$ is negative semi-definite, $f_1$ is concave. Similarly,
    \begin{align*}
        H_{f_2}&=
        \begin{bmatrix}
        -(1-\epsilon)\phi_2\kappa^2\frac{\beta^2}{\gamma^2}e^Y & -(1-\epsilon)\phi_2\kappa^3\frac{\beta^2}{\gamma^2}e^Y\\
        -(1-\epsilon)\phi_2\kappa^3\frac{\beta^2}{\gamma^2}e^Y & -(1-\epsilon)\phi_2\kappa^4\frac{\beta^2}{\gamma^2}e^Y
        \end{bmatrix}\\
        &=-(1-\epsilon)\phi_2\kappa^2\frac{\beta^2}{\gamma^2}e^Y \cdot
        \begin{bmatrix}
            1\\
            \kappa
        \end{bmatrix}
        \cdot
        \begin{bmatrix}
            1&\kappa
        \end{bmatrix}\\
    \end{align*}
    It's easy to see $f_2$ is also concave.
\end{proof}
We observe the final sizes point $p^*=(S_1,S_2)$ is feasible to this program. In fact, it is a vertex that minimizes the program, illustrated in Figure \ref{fig:convex}.

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{convex.png}
    \caption{Illustration of feasible regions of the convex program with $\phi_1=0.6,\beta=\frac{2}{14},\kappa=0.8,\gamma=\frac{1}{14},\epsilon=0.0001$. Vector lengths are adjusted for clarity.}
    \label{fig:convex}
\end{figure}

\subsection{Optimality of point $p^*$}
We first show that at point $p^*$, the optimum objective value, $S_1+S_2$, of this program is achieved. We show that any point that further reduces the objective function is infeasible. 

At point $p^*$, on the curve $f_1=0$ we get
\begin{align*}
    s_1 &= (1-\epsilon)\phi_1\cdot 
    exp\Big(\frac{\beta}{\gamma}(s_1-\phi_1)
    +\frac{\kappa\beta}{\gamma}(s_2-\phi_2)\Big)\implies\\
    \frac{\mathrm{d}s_1}{\mathrm{d}s_2} &=
    (1-\epsilon)\phi_1 \cdot e^X
    (\frac{\beta}{\gamma}\frac{\mathrm{d}s_1}{\mathrm{d}s_2}
    +\frac{\kappa\beta}{\gamma})
    =S_1(\frac{\beta}{\gamma}\frac{\mathrm{d}s_1}{\mathrm{d}s_2}
    +\frac{\kappa\beta}{\gamma})\implies\\
    \frac{\mathrm{d}s_1}{\mathrm{d}s_2} &=
    \frac{\frac{\kappa\beta}{\gamma}S_1}
    {1 - \frac{\beta}{\gamma}S_1}\implies\\
    \frac{\mathrm{d}s_2}{\mathrm{d}s_1} &=
    \frac{1 - \frac{\beta}{\gamma}S_1}
    {\frac{\kappa\beta}{\gamma}S_1}
    >0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
\end{align*}
Let $l_1$ be the tangent of $f_1$ at $p^*$, its slope is  $\frac{\mathrm{d}s_2}{\mathrm{d}s_1}$, the normals of $l_1$ are in the 2nd and 4th quadrants. 
Let $\vec{V_1}$ be a normal vector of $l_1$ pointing towards the infeasible half-space. Observe that point $((1-\epsilon)\phi_1,0)$ is in the 4th quadrant of $p^*$ and is $f_1$-feasible since
\begin{align*}
    f_1\Big((1-\epsilon)\phi_1,0\Big)=(1-\epsilon)\phi_1
    \Big(1-exp(\frac{\kappa\beta}{\gamma}(\epsilon-1)\phi_2)
    \Big)>0
\end{align*}
Therefore $\vec{V_1}$ must be in the 2nd quadrant. Let $\vec{V_1}$ be
\[
    \vec{V_1}=\Big[
    \frac{\frac{\beta}{\gamma}S_1 - 1}
    {\frac{\kappa\beta}{\gamma}S_1}
    ,1
    \Big]^T
\]

At point $p^*$, on the curve $f_2=0$ we get
\begin{align*}
    s_2 &= (1-\epsilon)\phi_2\cdot 
    exp\Big(\frac{\kappa\beta}{\gamma}(s_1-\phi_1)
    +\frac{\kappa^2\beta}{\gamma}(s_2-\phi_2)\Big)\implies\\
    \frac{\mathrm{d}s_2}{\mathrm{d}s_1} &=
    (1-\epsilon)\phi_2 \cdot e^Y
    (\frac{\kappa\beta}{\gamma}
    +\frac{\kappa^2\beta}{\gamma}\frac{\mathrm{d}s_2}{\mathrm{d}s_1})
    =S_2(\frac{\kappa\beta}{\gamma}
    +\frac{\kappa^2\beta}{\gamma}\frac{\mathrm{d}s_2}{\mathrm{d}s_1})\implies\\
    \frac{\mathrm{d}s_2}{\mathrm{d}s_1} &=
    \frac{\frac{\kappa\beta}{\gamma}S_2}
    {1 - \frac{\kappa^2\beta}{\gamma}S_2}
    >0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
\end{align*}

Let $l_2$ be the tangent of $f_2$ at $p^*$, its slope is  $\frac{\mathrm{d}s_2}{\mathrm{d}s_1}$, the normals of $l_2$ are in the 2nd and 4th quadrants. 
Let $\vec{V_2}$ be a normal vector of $l_2$ pointing towards the infeasible half-space. Observe that point $(0,(1-\epsilon)\phi_2)$ is in the 2nd quadrant of $p^*$ and is $f_2$-feasible since
\begin{align*}
    f_2\Big(0,(1-\epsilon)\phi_1\Big)=(1-\epsilon)\phi_2
    \Big(1-exp(\frac{\kappa\beta}{\gamma}(\epsilon-1)\phi_1)
    \Big)>0
\end{align*}
Therefore $\vec{V_2}$ must be in the 4th quadrant. Let $\vec{V_2}$ be
\[
    \vec{V_2}=\Big[
    \frac{\frac{\kappa\beta}{\gamma}S_2}
    {1 - \frac{\kappa^2\beta}{\gamma}S_2}
    ,-1
    \Big]^T
\]
We already have the slopes of $l_1,l_2$. We define vectors $\vec{T_1}$ on $l_1$ and $\vec{T_2}$ on $l_2$.
\begin{align*}
    \vec{T_1}=
    \Big[1,
    \frac{1 - \frac{\beta}{\gamma}S_1}
    {\frac{\kappa\beta}{\gamma}S_1}
    \Big]^T,\ \ 
    \vec{T_2}=
    \Big[1,
    \frac{\frac{\kappa\beta}{\gamma}S_2}
    {1 - \frac{\kappa^2\beta}{\gamma}S_2}
    \Big]^T
\end{align*}

We show that $\vec{T_1}$ and $\vec{T_2}$ define the feasible cone of the convex program at point $p^*$.
\begin{align*}
    \vec{T_1}\cdot\vec{V_2} &=
    \frac{\frac{\kappa\beta}{\gamma}S_2}
    {1 - \frac{\kappa^2\beta}{\gamma}S_2} -
    \frac{1 - \frac{\beta}{\gamma}S_1}
    {\frac{\kappa\beta}{\gamma}S_1}\\
    &=\frac{\frac{\beta}{\gamma}(S_1 + \kappa^2 S_2) - 1}
    {(1 - \frac{\kappa^2\beta}{\gamma}S_2)
    (\frac{\kappa\beta}{\gamma}S_1)}
    <0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
\end{align*}
Thus, $\vec{T_1}$ points towards the half-space containing $f_2$-feasibility.
\begin{align*}
    \vec{T_2}\cdot\vec{V_1} &=
    \frac{\frac{\beta}{\gamma}S_1 - 1}
    {\frac{\kappa\beta}{\gamma}S_1} +
    \frac{\frac{\kappa\beta}{\gamma}S_2}
    {1 - \frac{\kappa^2\beta}{\gamma}S_2}\\
    &=\frac{\frac{\beta}{\gamma}(S_1 + \kappa^2 S_2) - 1}
    {(\frac{\kappa\beta}{\gamma}S_1)
    (1 - \frac{\kappa^2\beta}{\gamma}S_2)}
    <0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
\end{align*}
Similarly, $\vec{T_2}$ points towards the half-space containing $f_1$-feasibility. Therefore $\vec{T_1}$ and $\vec{T_2}$ define a feasible cone. Any point outside the cone is infeasible. Now we are ready to apply \textbf{Farkas' lemma} to show that $p^*$ gives the optimum value of the program. We first state the lemma.
\begin{lemma}
\textbf{Farkas' lemma.} Let $\mathbf{A}\in \mathbb{R}^{m\times n}$ and $\mathbf{b}\in \mathbb{R}^m$, then exactly one of the following two assertions is true:
\begin{enumerate}
    \item There exists an $\mathbf{x}\in \mathbb{R}^n$ such that $\mathbf{Ax}=\mathbf{b}$ and $\mathbf{x}\geq 0$.
    
    \item There exists a $\mathbf{y}\in \mathbb{R}^m$ such that $\mathbf{A}^T \mathbf{y}\geq 0$ and $\mathbf{b}^T \mathbf{y} < 0$.
\end{enumerate}
\end{lemma}
The geometric intuition of \textbf{Farkas' lemma} is that a vector $\mathbf{b}$ can either be inside a cone defined by columns of $\mathbf{A}$, or outside of it, in which case there exists a hyperplane separating $\mathbf{b}$ and the cone. 

In our convex program, $\mathbf{b}$ is any vector in the half-space $s_1+s_2<0$, such that the point $(p^*+\mathbf{b})$ reduces the objective function value beyond $p^*$. $\mathbf{A} = [T_1,T_2]$ defines the feasible cone. Let $\mathbf{y}=[1,1]^T$. We show that the 2nd case is true.
\begin{enumerate}[label=(\roman*)]
    \item $\mathbf{A}^T\mathbf{y}\geq 0$
    \begin{align*}
        &\mathbf{A}^T\mathbf{y}\geq 0 \iff
        \begin{cases}
            T_1\cdot \mathbf{y} \geq 0,\\
            T_2\cdot \mathbf{y} \geq 0.
        \end{cases}\\
        &T_1\cdot \mathbf{y} = 1 + 
        \frac{1 - \frac{\beta}{\gamma}S_1}
        {\frac{\kappa\beta}{\gamma}S_1} >0\\
        &T_2\cdot \mathbf{y} = 1 + 
        \frac{\frac{\kappa\beta}{\gamma}S_2}
        {1 - \frac{\kappa^2\beta}{\gamma}S_2} >0
    \end{align*}
    \item $\mathbf{b}^T \mathbf{y} < 0$
    \[
        \mathbf{b}^T \mathbf{y} = s_1+s_2<0
    \]
\end{enumerate}
Thus, $\nexists\mathbf{x}\in \mathbb{R}^n$ such that $\mathbf{Ax}=\mathbf{b}$ and $\mathbf{x}\geq 0$, i.e., $\mathbf{b}$ is not inside the feasible cone, any point $(p^*+\mathbf{b})$ that reduces the objective function is infeasible.

\subsection{Uniqueness of optimum point}
We have already established that $p^*$ gives the optimum value. Now we show that it is the only optimum point.

Let $p'=(S_1+c, S_2-c),c\neq 0$ be a different point from $p^*$ with the same objective value. 
\begin{lemma}
    $p'$ is infeasible to the convex program.
\end{lemma}
\begin{proof}
Let vector $\vec{V_c}=p'-p^*=[c,-c]^T$.
\begin{enumerate}[label=(\roman*)]
    \item When $c>0$,
    \begin{align*}
        \vec{V_c}\cdot\vec{V_2} & =c\cdot 
        \frac{\frac{\kappa\beta}{\gamma}S_2}
        {1 - \frac{\kappa^2\beta}{\gamma}S_2}
        +c\\
        & =c\Big(
        \frac{\frac{\kappa\beta}{\gamma}S_2}
        {1 - \frac{\kappa^2\beta}{\gamma}S_2}
        +1
        \Big)
        >0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
    \end{align*}
    Thus $p'$ is $f_2$-infeasible.
    
    \item When $c<0$,
    \begin{align*}
        \vec{V_c}\cdot\vec{V_1} & =c\cdot 
        \frac{\frac{\beta}{\gamma}S_1 - 1}
        {\frac{\kappa\beta}{\gamma}S_1}
        -c\\
        & =c\Big(
        \frac{\frac{\beta}{\gamma}S_1 - 1}
        {\frac{\kappa\beta}{\gamma}S_1}
        -1
        \Big)
        >0\text{, by \textbf{Lemma \ref{lm:FinalUpper}}}
    \end{align*}
    Thus $p'$ is $f_1$-infeasible.
\end{enumerate}
\end{proof}
This completes the proof of computing the final sizes $S_1,S_2$ by solving the convex program.

