\section{Conclusion}

We have demonstrated how regular DiTs can be converted into \emph{flexible} ones, that can process samples with different patch sizes after minimal fine-tuning. Adjusting the compute for some denoising steps in the diffusion process readily allows accelerating inference without compromising. Notably, the efficiency benefits of our approach are independent of the chosen solver or the number of denoising steps. We have displayed how our approach is generic and can be straightforwardly applied to class-conditioned image generation, low and high-resolution text-conditioned image generation, and text-conditioned video generation. Looking ahead, we anticipate further applications of our flexible DiT framework across various modalities, such as audio and $3$D modeling. As computational resources become increasingly in demand, developing efficient and adaptable models like ours will be crucial for enabling generative capabilities that are of high-quality, but also more scalable.
