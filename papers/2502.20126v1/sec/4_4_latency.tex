\subsection{FLOPs vs Latency}
\label{sec:latency}

High-resolution image/video generation is predominantly compute-bound. To verify, we propagate sequences of different lengths through a fixed size DiT and measure performance --- FLOPs and latency --- on a \textit{NVIDIA H100 SXM5} with a batch size of $2$, simulating inference with CFG\footnote{In all cases, we compile using \textit{torch.compile} with \textit{fullgraph=True} and \textit{mode = 'reduce-overhead'}.}. In Fig.~\ref{fig:latency} we show that the weak~\emu~and~\moviegen~models are also compute-bound, for the setup (generated image/video resolution) that we presented in the paper. Indeed, for T2V, FLOPs utilization is higher for our weak models, due to inefficiencies of the self-attention operation for large sequence lengths when using the powerful model. This effect can be expected to be even more predominant for multi-GPU inference. Consequently, \emph{latency benefits are even higher than FLOPs benefits} presented so far.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/emu/roofline-bfloat16.pdf}
    \caption{GPU utilization for one denoising step, when propagating sequences with different overall number of tokens, corresponding to different patch sizes $(\patchsizef, \patchsizeh, \patchsizew)$. Our T2I model has no temporal dimension, but we overload notation and set $\patchsizef = 1$. For simplicity, we use a DiT of similar configuration (width and depth) for both the T2I and T2V reported in this plot numbers, but results generalize across model shapes.}
    \label{fig:latency}
\end{figure}