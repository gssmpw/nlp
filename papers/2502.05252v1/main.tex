\documentclass[]{fairmeta}
% Option "twocolumn" available, but please prioritize single-column
\usepackage{microtype}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{algpseudocode}
\usepackage[linesnumbered,lined,boxed,commentsnumbered,ruled,longend]{algorithm2e}
\usepackage[capitalize,noabbrev]{cleveref}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\usepackage{enumitem}
\usepackage[subtle, mathdisplays=tight, charwidths=tight, leading=normal]{savetrees}
% \usepackage[margin=1in]{geometry} 
% \usepackage{subfigure} 
\usepackage{subcaption} % Recommended alternative 
\usepackage{booktabs} % for professional tables
\usepackage{longtable} 
\usepackage{textcomp} 
% \usepackage{unicode-math} % Add this in your preamble 
\newcommand{\sysb}{\textsc{GSM}-{\large{$\infty$}}\xspace} 

\usepackage{tikz} % include in your preamble if not present

\usepackage{tikz} % Include in your preamble if not already there

\newcommand{\GSMmouse}{%
\begin{tikzpicture}[scale=0.25, line join=round, thick]
    % Body
    \draw (0,0) ellipse (1.5 and 1.2);
    
    % Ears
    \draw (-1.2,1.1) circle (0.6);
    \draw (1.2,1.1) circle (0.6);
    
    % Inner ears (optional pink ring)
    \draw[very thick, color=pink!60] (-1.2,1.1) circle (0.4);
    \draw[very thick, color=pink!60] (1.2,1.1) circle (0.4);
    
    % Eyes: white + black pupils
    \fill[white] (-0.5,0.3) circle (0.25);
    \fill[white] (0.5,0.3) circle (0.25);
    \fill[black] (-0.5,0.3) circle (0.1);
    \fill[black] (0.5,0.3) circle (0.1);
    % Eye highlights
    \fill[white] (-0.52,0.33) circle (0.03);
    \fill[white] (0.48,0.33) circle (0.03);
    
    % Infinity-symbol nose: bold red outlines, no fill
    \draw[line width=1.2pt, red!90] (-0.2,-0.1) circle (0.2);
    \draw[line width=1.2pt, red!90] (0.2,-0.1) circle (0.2);

    % \draw (-0.1,-0.1) -- (-0.5,0.1);
    % \draw (0.1,-0.1) -- (0.5,0.1); 
    
    \draw (-0.1,-0.1) -- (-1.0,-0.3);
    \draw (-0.1,-0.2) -- (-1.0,-0.5);
    \draw (0.1,-0.1) -- (1.0,-0.3);
    \draw (0.1,-0.2) -- (1.0,-0.5); 
    
    % Upward-curving smile
    \draw[line width=1.2pt, red!60] (-0.6,-0.2) .. controls (-0.2, -0.6) and (0.2, -0.6) .. (0.6,-0.2);

    % (Optional) silly tongue
    \fill[red!40] (0,-0.4) ellipse (0.2 and 0.1);

    % Tail removed!
\end{tikzpicture}%
} 

\newcommand{\PokerShadesLogo}{%
  \begin{tikzpicture}[scale=0.8]

  % Top petal (center at (0,0.3)), rotated 90° around (0,0.3)
  \fill[black, fill opacity=0.5, rotate around={90:(0,0.2)}]
    (0, 0.2) ellipse (0.25 and 0.2);

  % Bottom petal (center at (0,-0.3)), rotated 90° around (0,-0.3)
  \fill[black, fill opacity=0.5, rotate around={90:(0,-0.2)}]
    (0,-0.2) ellipse (0.25 and 0.2);

  % Left petal (center at (-0.3,0)), rotated 90° around (-0.3,0)
  \fill[black, fill opacity=0.5, rotate around={90:(-0.2,0)}]
    (-0.2,0) ellipse (0.2 and 0.25);

  % Right petal (center at (0.3,0)), rotated 90° around (0.3,0)
  \fill[black, fill opacity=0.5, rotate around={90:(0.2,0)}]
    (0.2,0) ellipse (0.2 and 0.25);

\end{tikzpicture}
} 

% \title{GSM-{\Huge$\infty$}: How Do Your LLMs Behave over \\
% Infinitely Increasing Reasoning Complexity and Context Length?} 
% \title{GSM--{\Huge\textinfty}: How Do Your LLMs Behave over \\
% Infinitely Increasing Reasoning Complexity and Context Length?} 
\title{\GSMmouse\ 
{\fontsize{16pt}{10pt}\selectfont 
    GSM-{\textnormal{\scalebox{0.8}{\Huge$\infty$}}}: How Do Your LLMs Behave over
    Infinitely Increasing Context Length and Reasoning Complexity? 
} 
} 

\newcommand{\matthijs}[1]{{\color{RedViolet} [\textbf{Matthijs}: #1]}}

\definecolor{skyblue}{RGB}{135, 206, 235} 
\definecolor{palegreen}{RGB}{152, 251, 152}

\author{Yang Zhou$^{1*}$, Hongyi Liu$^{1*}\dag$, Zhuoming Chen$^{1}$, Yuandong Tian$^{2}$, Beidi Chen$^{1}$\\
$^1$Carnegie Mellon Univeristy\\
$^2$Meta AI\\
\texttt{\{yangzho6, zhuominc, beidic\}@andrew.cmu.edu} \\
\texttt{liuhongy21@gmail.com},
\texttt{yuandong@meta.com} \\ 
\textsuperscript{$^*$ Equal contributions. A coin flip decides the order.} \\
\vspace{-1mm} 
\textsuperscript{$\dag$ Work done during an internship at Carnegie Mellon University.} 
} 

\abstract{
 % \input{arXiv-2410.16179v4/ICLR_2025_Template/abstract} 
 Long-context large language models (LLMs) have recently shown strong performance in information retrieval and long-document QA. However, to tackle the most challenging intellectual problems, LLMs must reason effectively in long and complex contexts (e.g., frontier mathematical research). Studying how LLMs handle increasing reasoning complexity and context length is essential, yet existing benchmarks lack a solid basis for quantitative evaluation. Inspired by the abstraction of GSM-8K problems as computational graphs—and the ability to introduce noise by adding unnecessary nodes and edges—we develop a grade-school math problem generator capable of producing arithmetic problems with infinite difficulty and context length under fine-grained control. Using our newly synthesized \sysb benchmark, we comprehensively evaluate existing LLMs. We find a consistent sigmoid decline in reasoning performance as complexity increases, along with a systematic inference scaling trend: exponentially increasing inference computation yields only linear performance gains. These findings underscore the fundamental limitations of current long-context LLMs and the key challenges in scaling reasoning capabilities. Our \sysb benchmark provides a scalable and controllable testbed for systematically studying and advancing LLM reasoning in long and complex contexts.
}


%\date{\today}
% You can add additional metadata fields as follows 
\metadata[Github]{\url{https://github.com/Infini-AI-Lab/gsm_infinite/}}
\metadata[Website]{\url{https://infini-ai-lab.github.io/gsm_infinite/}} 

\begin{document}

\maketitle
\input{arXiv-2410.16179v4/ICLR_2025_Template/introduction} 
\input{arXiv-2410.16179v4/ICLR_2025_Template/problemstatement} 
\input{arXiv-2410.16179v4/ICLR_2025_Template/rewriteobservation} 
\input{arXiv-2410.16179v4/ICLR_2025_Template/gsminfinite} 
% \input{arXiv-2410.16179v4/ICLR_2025_Template/benchmarksandresults} 
\input{arXiv-2410.16179v4/ICLR_2025_Template/analysis} 
\input{arXiv-2410.16179v4/ICLR_2025_Template/conclusion} 

\clearpage
\newpage
\bibliographystyle{assets/plainnat}
\bibliography{paper}

\clearpage
\newpage
% \beginappendix 
\input{arXiv-2410.16179v4/ICLR_2025_Template/appendix} 

\end{document}