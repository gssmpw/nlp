%should be around 2.5 pages. 
\section{Evaluation of Surrogate Models}
\label{sec:eval}

We evaluate our approach by varying the complexity of the data used for model assessment and comparing the predicted results with the ones obtained with DCSim. 
%
In the first evaluation scenario, referred to as homogeneous jobs (Section~\ref{sec:eval:homogeneous}), we use jobs generated from a single workload description executed on a fixed platform with minimal complexity. 
%
This controlled setup allows us to establish a baseline for the model's performance under simple conditions. 
%
The second scenario covers heterogeneous jobs (Section~\ref{sec:eval:heterogeneous}), introducing increased complexity by predicting results for jobs derived from multiple workload distributions on a more complex platform. 
%
This setting provides insight into the model's capabilities to handle diverse workloads. 

We show the evaluation results for the observables \textit{compute\_time} and \textit{input\_files\_transfer\_time} for both scenarios. The results for other observables can be found in~\cite{Zhyla2024}. 

We evaluate the models' predictions using the coefficient of determination (R-squared) and Kernel Density Estimate (KDE) plots. 
%
R-squared represents the proportion of variance in the target variable explained by the model. Its values range from zero to one, with one indicating a perfect fit. %Its values typically range from zero to one, with one indicating a perfect fit. The values can sometimes be negative if the model performs worse than a naive baseline. 
%
KDE plots provide a visual assessment of the distribution of the respective observable, revealing patterns or systematic bias regarding under- or overprediction that R-squared cannot capture. 

\subsection{Homogeneous Jobs} \label{sec:eval:homogeneous}

In the homogeneous jobs scenario, we use 10,000 simulations for training, organized into 10 batches of 1,000 simulations each. 
%
These simulations include 1, 10, 20, 50, 100, 250, 500, 1,000, 1,500, and 2,000 jobs per simulation. 
%
To assess extrapolation capabilities, we use an additional dataset of 10 simulations with 10,000 jobs each that are not used in training. 
%
The resource demands of all jobs remain identical throughout the training and evaluation phases.
%
%
As input features, we use \textit{index}, \textit{flops}, \textit{input\_files\_size}, and \textit{output\_files\_size}. 
%
%
The platform configuration contains three worker nodes, two with 24 CPU cores each, one with 12 CPU cores, and one scheduler node. 
%
All nodes are connected following a star topology. 
%
The datasets processed by the jobs are stored on a separate storage server. 
%
%

We show a comparison of the prediction results with the simulation for the extrapolation task in \autoref{tab:eval} and \autoref{fig:eval-1}. 
%
\begin{figure}%
    \begin{subfigure}{.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-1/trimmed/GRU-extrapolation-kde-compute_time.png}%
    \vspace{-0.5em}%
    \caption{BiGRU model, \textit{compute\_time}.}%
    \label{fig:eval-1-gru-extrapolation-compute}%
    \end{subfigure}%
    \hfill%
    \begin{subfigure}{0.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-1/trimmed/LSTM-extrapolation-kde-compute_time.png}%
    %\vspace{-0.5em}%
    \caption{BiLSTM model, \textit{compute\_time}.}%
    \label{fig:eval-1-lstm-extrapolation-compute}%
    \end{subfigure}%
    \hfill%
    \vspace{-0.5em}
    \begin{subfigure}{.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-1/trimmed/Transformer-extrapolation-kde-compute_time.png}%
    \vspace{-0.5em}%
    \caption{Transformer model, \textit{compute\_time}.}%
    \label{fig:eval-1-transformer-extrapolation-compute}%
    \end{subfigure}%
    \hfill%
    \begin{subfigure}{.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-1/trimmed/Transformer-extrapolation-kde-input_files_transfer_time.png}%
    \vspace{-0.5em}%
    \caption{Transformer model, \textit{input\_files\_transfer\_time}.}%
    \label{fig:eval-1-transformer-extrapolation-input_files_transfer_time}%
    \end{subfigure}%
    \caption{Predictions for extrapolation of trained models in the homogenous jobs setup. The \textit{input\_files\_transfer\_time} is similar for the other models.}%
    \label{fig:eval-1}%
\end{figure}%
%
%The results for other observables and the interpolation task can be found in the Master thesis~\cite{Zhyla2024}.
%
All models exhibit a negative R-squared value for \textit{compute\_time}, indicating a worse fit than a naive baseline. 
%
The KDE plots show that the target distribution exhibits two prominent spikes for the \textit{compute\_time}. While the BiGRU and BiLSTM models successfully capture the general structure of the distribution, they fail to emphasize these two spikes sufficiently. 
%
The transformer model, however, predicts mainly the mean values for \textit{compute time}, failing to capture the actual distribution. 
%
While the R-squared value for \textit{input\_files\_transfer\_time} is positive, it is close to zero for all models, indicating only a slightly better fit than the naive baseline. 
%
The KDE plots show that the models capture some distribution features again but fail to emphasize the actual form. 
%
In summary, all models failed to predict the observables beyond the first statistical moment, potentially due to the lack of input features providing additional context constraining the job execution, particularly information about the platform architecture.
%
Although the size of the modelled infrastructure is rather minimal in this example, the surrogate ansatz already leads to improvements in the execution time of minimum two orders of magnitude on our test systems ($\mathcal{O}(10\,\mathrm{s}) \to \mathcal{O}(100\,\mathrm{ms})$).


\subsection{Heterogeneous Jobs} \label{sec:eval:heterogeneous}

Our second evaluation scenario introduces jobs from multiple distributions and a more complex platform configuration.
%
We train the models and evaluate their extrapolation capabilities using the same strategy as for the homogeneous jobs.
%
The workload comprises five distinct job classes, each with its own distribution for all resource demands.
Each job's \textit{submission\_time} differs in this scenario and is therefore added as an input feature.
%
The platform configuration describes an interconnected network of two data centers. 
%
The first consists of a local network of ten identical worker nodes and a storage node. 
%
The second has a single but more powerful worker node. 
%
All datasets are stored in the first data center. 
%
The first data center features 420 CPU cores, while the second has 200 CPU cores.
%


We present the prediction results %for the observables \textit{compute time} and \textit{input files transfer time} 
in \autoref{tab:eval} and \autoref{fig:eval-3}.
We omit the KDE plots for the BiGRU model since they show the same features as the BiLSTM.
%
\begin{figure}%
    \begin{subfigure}{0.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-3/trimmed/LSTM-extrapolation-kde-compute_time.png}%
    \vspace{-0.5em}%
    \caption{BiLSTM model, \textit{compute\_time}}%
    \label{fig:eval-3-LSTM-extrapolation-compute}%
    \end{subfigure}%
    \hfill%
    \begin{subfigure}{0.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-3/trimmed/LSTM-extrapolation-kde-input_files_transfer_time.png}%
    \vspace{-0.5em}
    \caption{BiLSTM model, \textit{input\_files\_transfer\_time}}%
    \label{fig:eval-3-LSTM-extrapolation-input}%
    \end{subfigure}%
    %\vspace{-0.5em}%
    \label{fig:eval-3-lstm}%
    \hfill
    \begin{subfigure}{0.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-3/trimmed/Transformer-extrapolation-kde-compute_time.png}%
    \vspace{-0.5em}%
    \caption{Transformer model, \textit{compute\_time}}%
    \label{fig:eval-3-transformer-extrapolation-compute}  %  
    \end{subfigure}%
    \hfill%
    \begin{subfigure}{0.49\linewidth}%
    \centering%
    \includegraphics[width=\linewidth]{figs/eval/scenario-3/trimmed/Transformer-extrapolation-kde-input_files_transfer_time.png}%
    \vspace{-0.5em}%
    \caption{Transformer model, \textit{input\_files\_transfer\_time}}%
    \label{fig:eval-3-transformer-extrapolation-input}% 
    \end{subfigure}%
    %\caption{Predictions of the \textit{compute\_time} and \textit{input\_files\_transfer\_time} for extrapolation of trained LSTM and Transformer models in the heterogeneous jobs setup.}%
    \vspace{-1em}
    \caption{Predictions for extrapolation of trained models in the heterogeneous jobs setup.}%
    \label{fig:eval-3}%
\end{figure}%
%
All models achieve an R-squared value close to one for \textit{compute\_time}, indicating near-optimal predictions. 
%
The KDE plots reveal smaller errors in matching the exact distribution but show a good fit overall despite the same lack of platform context as in the previous example. 
%
However, the R-squared value for \textit{input\_files\_transfer\_time} is negative across all three models, indicating that the models cannot predict the observable effectively. 
%
Looking at the KDE plots, we can see that the models accurately predict the spikes in the distribution. 
%
However, all models fail to predict the long tail of large values, deteriorating the overall prediction quality.


Overall, all models achieve similar results, with the Transformer model achieving slightly less accurate predictions. 
%
While \textit{compute\_time} can be predicted accurately, the behavior of \textit{input\_files\_transfer\_time} cannot be predicted accurately. 
%
This behavior may be influenced by complex interactions within the platform, such as the existence of various routes from the node storing the dataset to the worker node that processes the job. Since information about the platform's configuration is not explicitly included in the model inputs, it cannot be utilized to make predictions.
For the \textit{compute\_time}, however, the presence of multiple workloads, including jobs with different compute requirements and subsequently different execution times also depending on the worker they have been executed on, presents implicit platform information providing additional context about the platform.
For the \textit{transfer\_time}, however, the effect of the platform on the job execution is more convoluted and complex than what can be captured implicitly in the training data.
%
Nonetheless, the benefit of the surrogate in terms of execution times becomes more pronounced with a respective speed-up of multiple orders of magnitude ($\mathcal{O}(100\,\mathrm{s}) \to \mathcal{O}(100\,\mathrm{ms})$).
%
\begin{table}
    \centering%
    \caption{R-squared metric for different models and evaluation scenarios.}%
    \begin{adjustbox}{width=\linewidth}%
    %\small
    \begin{tabular}{l|rrr|rrr}
    & \multicolumn{3}{c}{Homogeneous Jobs} & \multicolumn{3}{c}{Heterogeneous Jobs} \\
    Observable & BiGRU & BiLSTM & Transformer & BiGRU & BiLSTM & Transformer\\ \toprule
    \textit{compute\_time} & -1.20 & -1.08 & -0.14 & 0.99 & 0.99 & 0.96 \\
    \textit{input\_files\_transfer\_time} & 0.06 & 0.18 & 0.07 & -0.27 & -0.14 & -0.46 \\ \bottomrule
    \end{tabular}%
    \end{adjustbox}%
    \label{tab:eval}%
\end{table}%
%