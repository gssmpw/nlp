\section{Introduction}

What constitutes a solution to a game? Descriptive and perscriptive theories in economics brought together in response to such questions chiefly revolve around \emph{equilibria}---strategically stable outcomes. The underpinning of strategic stability can be naturally conceived in more ways than one, but none is more standard than the one pregnant in Nash's theorem~\citep{Nash51:Non}, which single-handedly propelled the rapid development of noncooperative game theory in the last century. This is reflected in, for example, the exulting words of the Nobel prize-winning economist Roger Myerson, who juxtaposed the ``fundamental and pervasive impact of Nash equilibrium'' in economics and the social sciences to ``the discovery of the DNA double helix in the biological sciences~\citep{Myerson99:Nash}.'' This profound influence nonwithstanding, the concept of Nash equilibrium has also been subjected to fierce criticism. Some of the most vocal critiques have been articulated in the computer science community, vehemently objecting to its apparent intractability~\citep{Daskalakis08:Complexity,Chen09:Settling,Rubinstein16:Settling,Rubinstein15:Inapproximability,Etessami07:Complexity}.

Aumann's pathbreaking \emph{correlated equilibrium} concept~\citep{Aumann74:Subjectivity} offers a compelling alternative that promises to alleviate such concerns: unlike Nash equilibria, which amount to fixed points of general functions, correlated equilibria can be expressed as linear programs. This, in turn, enables their efficient computation, or at least so the common narrative goes. The reality is more nuanced, and is dictated by the underlying \emph{game representation}. In particular, strategic interactions encountered in practice often unfold sequentially. Such settings do not lend themselves to the usual one-shot (aka. normal-form) representation---not without blowing up the description of the game, that is. Instead, sequential games are usually represented in \emph{extensive form} (or other pertinent paradigms~\citep{Littman94:Markov}). In stark contrast to normal-form games, wherein polynomial-time algorithms have long been established~\citep{Papadimitriou08:Computing,Jiang11:Polynomial}, the complexity of computing correlated equilibria in extensive-form games remains an enigmatic open problem.

\citet{Daskalakis24:Lower} recently provided evidence in the negative through the prism of the \emph{no-regret} framework. In particular, there is an intimate nexus between correlated equilibria and online learning: learners minimizing \emph{swap regret}---a powerful notion of hindsight rationality---converge to the set of correlated equilibria~\citep{Blum07:From,Stoltz05:Internal}. In this context, \citet{Daskalakis24:Lower} established an exponential lower bound for the number of iterations needed so that a learner incurs at most $\epsilon$ average swap regret when facing an adversary; more precisely, that result applies in the regime where $\epsilon$ is inversely polynomial (\emph{cf.} \citet{Dagan24:From,Peng24:Fast}). While this result does not rule out the existence of efficient algorithms beyond the adversarial regime, it does immediately bring to the fore a well-studied but pressing question: \emph{what notions of hindsight rationality are efficiently learnable?}

Hindsight rationality in online learning can be understood through a set of functions, $\Phi$, so that no deviation according to a function in $\Phi$ can retrospectively improve the cumulative utility; such a learner is said to be consistent with minimizing \emph{$\Phi$-regret}~\citep{Greenwald03:General,Stoltz07:Learning,Gordon08:No}. The broader the set of deviations $\Phi$, the more appealing the ensuing concept of hindsight rationality. The usual notion of external regret is an instantiation of that framework for which $\Phi$ contains solely constant functions---referred to as \emph{coarse} deviations. On the other end of the spectrum, when $\Phi$ contains all possible deviations, one finds the powerful notion of swap regret---associated with (normal-form) correlated equilibria. The fundamental question thus is to characterize the structure of $\Phi$ that enables efficient learnability---and, indeed, computation.

Much of the recent research in the context of learning in extensive-form games has focused on this exact problem. This can be traced back to the influential work of~\citet{Zinkevich07:Regret}, who introduced \emph{counterfactual regret minimization (CFR)}---an algorithm that was at the heart of recent landmark results in AI benchmarks such as poker~\citep{Brown17:Superhuman,Brown19:Superhuman,Bowling15:Heads,Moravvcik17:DeepStack}. CFR is an online algorithm for minimizing external regret---associated with (normal-form) coarse correlated equilibria. Moving forward, efficient algorithms eventually emerged for \emph{extensive-form correlated equilibria (EFCE)}~\citep{Huang08:Computing,Farina22:Simple,Dudik09:SamplingBased,Bai22:Efficient} (\emph{cf.}~\citet{Morrill21:Efficient,Morrill21:Hindsight}), and more broadly, when $\Phi$ contains solely \emph{linear} functions~\citep{Farina24:Polynomial,Farina23:Polynomial}---corresponding to \emph{linear correlated equilibria (LCE)}. \citet{Daskalakis24:Efficient} recently took a step even further by strengthening those results whenever the underlying constraint set $\cX \subseteq \R^d$ admits a membership oracle. \Cref{fig:taxonomy} summarizes the landscape that has emerged.

\input{figs/taxonomy}

\subsection{Our results: \texorpdfstring{$\Phi$}{Phi}-equilibria at the frontier of tractability}
\label{sec:results}

\begin{table}[htbp]
\centering
\small
\caption{Our main results for the $k$-dimensional set $\Phi^m$ of~\Cref{assumption:kernel}; $k \gg d$.}
\vspace{.3cm}
\label{tab:bounds}
\begin{tabular}{lcc}
\toprule
 & Upper bound & Lower bound \\
\midrule
\multirow{2}{*}{\textbf{Learning}} & $\poly(k)/\epsilon^2$ & $\min \{ \sqrt{k}/4, \text{exp}(\Omega(\epsilon^{-1/6})) \}$ \\
 & (\Cref{theorem:main1}) & (\Cref{theorem:mainlower}) \\
\midrule
\multirow{2}{*}{\textbf{Computation}} & $\poly(k, \log(1/\epsilon))$ & \multirow{2}{*}{Open question} \\
 & (\Cref{theorem:main-eah}) & \\
\bottomrule
\end{tabular}
\end{table}

\iffalse
\begin{table}[htbp]
\centering
\caption{Our main results for the $k$-dimensional set $\Phi$ of~\Cref{assumption:kernel}.}
\label{tab:bounds}
\begin{tabular}{lcc}
\toprule
 & Upper bound & Lower bound \\
\midrule
\textbf{Learning} & $\poly(d,k)/\epsilon^2$ (\Cref{theorem:main1}) & $\min \{ \sqrt{k}/4, \text{exp}(\Omega(\epsilon^{-1/6})) \}$ (\Cref{theorem:mainlower}) \\
\textbf{Computation} & $\poly(d, k, \log(1/\epsilon))$ (\Cref{theorem:main-eah}) & Open question \\
\bottomrule
\end{tabular}
\end{table}
\fi

The primary focus of this paper is to expand the scope of that prior research beyond linear-swap regret---associated with linear correlated equilibria---toward the frontier of tractability. While handling all swap deviations is impossible in light of the recent lower bound of~\citet{Daskalakis24:Lower}, discussed above, we are able to cope with the broad class of functions introduced below.


\begin{definition}\label{assumption:kernel}
    Given a map $m : \cX \to \R^{k'}$, the set of deviations $\Phi^m$ is defined as the set of all maps $\phi : \cX \to \cX$ that can be can be expressed by the matrix-vector product $\mK(\phi ) m(\vx) + \cons(\phi)$ for some $\mK(\phi) \in \R^{d \times k'}$ and $\cons(\phi) \in \R^d$. 
The set of functions $\Phi^m$ has dimension at most $k \defeq k' \cdot d + d$.
\end{definition}

We think of $k$ as a measure of the complexity of $\Phi^m$; in what follows, one may imagine $k \leq \poly(d)$. There is a clear sense in which going beyond~\Cref{assumption:kernel} is daunting: even representing such functions becomes prohibitive. Indeed, we also establish lower bounds that preclude going beyond the set of deviations in~\Cref{assumption:kernel}, showing that our results cannot be significantly improved.

As a canonical example, one can capture degree-$\ell$ polynomials by taking $m(\vx)$ to be the function that outputs all $\ell$-wise (and lower) products of entries in $\vx$ (hence $k = d^{O(\ell)}$), and $\mK$ the matrix of coefficients of the polynomial. (For technical reasons, we actually consider a certain orthonormal basis for polynomials introduced formally in~\Cref{def:polys}.)

\subsubsection{Learning}

We begin by stating our results in the usual no-regret framework in online learning, and we then proceed with the centralized model of computation. A key reference point here is the recent paper of~\citet{Zhang24:Efficient}, who provided online algorithms in extensive-form games when $\Phi$ contains low-degree polynomials. However, the complexity of their algorithm---both the per-iteration running time and the total number of rounds---depends on the depth of the game tree; in particular, for general extensive-form games, their bounds become vacuous even for constant-degree polynomials (for example, when the game tree is lopsided). Our first main result addresses that limitation. What is more, it encompasses a more general class than extensive-form decision problems, while at the same time going beyond low-degree swap deviations.

\begin{theorem}[Online learning; precise version in~\Cref{theorem:main-prec}]
    \label{theorem:main1}
    Suppose that $\cX \subseteq \R^d$ admits a membership oracle and $\Phi^m$ is $k$-dimensional per~\Cref{assumption:kernel}. There is an online algorithm that guarantees at most $\epsilon$ average $\Phi^m$-regret after $\poly(k) / \epsilon^2$ rounds with $\poly(k, 1/\epsilon)$ running time.
\end{theorem}

\subsubsection{Computation}

The result above holds even when the learner is facing an adversary, thereby being readily applicable when learning in $n$-player \emph{mutlilinear games}. In such games, each player $i \in \range{n}$ has a convex and compact strategy set $\cX_i \subseteq \R^{d_i}$ and utility function $u_i : \cX_1 \times \dots \times \cX_n \to \R$ that is linear in $\cX_i$, so that $u_i(\vx) = \langle \vec{g}_i, \vx_i \rangle$ for some $\vec{g}_i = \vec{g}_i(\vx_{-i}) \in \R^{d_i}$. (Extensive-form games constitute a canonical example of this framework.) In this context, \Cref{theorem:main1} implies a fully polynomial-time algorithm ($\FPTAS$) for computing $\epsilon$-approximate $\Phi^m$-equilibria in convex games. Our next result establishes a polynomial-time algorithm---that is, with running time growing polynomially in $\log(1/\epsilon)$ as opposed to $1/\epsilon$---for that problem.

\begin{theorem}[Computation; precise version in~\Cref{theorem:main-eah-prec}]
    \label{theorem:main-eah}
    Consider an $n$-player multilinear game $\Gamma$ such that, for each player $i \in [n]$, we are given $\poly(n, k)$-time algorithms for the following:
\begin{itemize}
\item an oracle to compute the gradient, that is, the vector $\vec{g}_i = \vec{g}_i(\vx_{-i}) \in \R^{d_i}$ for which $\ip{\vg_i(\vx_{-i}), \vx_i} = u_i(\vx)$ for all $\vx \in \cX_1 \times \dots \times \cX_n$ (polynomial expectation property); and
\item a membership oracle for the strategy set $\cX_i$.
\end{itemize}
Suppose further that each $\Phi^{m_i}$ is $k_i$-dimensional per~\Cref{assumption:kernel} and $\|\vec{g}_i \| \leq B$. Then, an $\eps$-approximate $\Phi^m$-equilibrium of $\Gamma$ can be computed in $\poly\qty(n, k, \log(B/\eps))$ time.
\end{theorem}

\subsection{Technical approach}

\Cref{theorem:main1,theorem:main-eah} build on and extend certain recent developments due to~\citet{Daskalakis24:Efficient} and~\citet{Zhang24:Efficient}. Below, we outline our key technical contributions.

\paragraph{Expected fixed points} Our approach crucially hinges on the notion of an \emph{expected fixed point}: a distribution $\mu \in \Delta(\cX)$ such that $\E_{\vx \sim \mu} [ \phi(\vx) - \vx] \approx 0$. Taking a step back, earlier approaches for minimizing $\Phi$-regret were based on computing an actual fixed point of a function $\phi \in \Phi$~\citep{Gordon08:No,Blum07:From,Stoltz05:Internal}. For normal-form games, computing a fixed point of such a function boils down to determining the stationary distribution of a certain Markov chain, which is directly amenable to linear programming---this holds more generally when $\Phi$ contains linear functions. However, when considering nonlinear functions, this standard approach immediately becomes prohibitive since fixed points are hard to compute. \citet{Zhang24:Efficient} bypass this obstacle by showing that a fixed point \emph{in expectation}, as introduced earlier, is actually sufficient for minimizing $\Phi$-regret. In fact, building on an earlier result due to~\citet{Hazan07:Computational}, \citet{Zhang24:Efficient} observed that approximating expected fixed points also reduces to minimizing $\Phi$-regret, establishing a certain equivalence between the two. Crucially, there is a simple, $O(1/\epsilon)$-time algorithm for computing an $\epsilon$-expected fixed point of any $\phi \in \Phi$ by taking the uniform distribution over the sequence $\vx, \phi(\vx), \phi(\phi(\vx)), \dots$; the claimed guarantee follows by a telescopic summation. In this context, an important question left open by~\citet{Zhang24:Efficient}---which, as we shall see, is the crux in proving~\Cref{theorem:main-eah}---concerns the complexity of computing expected fixed points in the regime where $\epsilon$ is exponentially small. We address this question by showing that expected fixed points can be computed in time polynomial in the dimension and $\log(1/\epsilon)$.

\begin{theorem}[Expected fixed points]
    \label{theorem:efps}
    Given oracle access to $\cX$ and $\phi : \cX \to \cX$, there is a $\poly(d, \log(1/\epsilon))$-time algorithm that computes an $\epsilon$-expected fixed point of $\phi$.
\end{theorem}

We have described so far the role of expected fixed points when learning in an online environment (\emph{cf.}~\Cref{theorem:main1}). Going back to~\Cref{theorem:main-eah}, expected fixed points also serve a crucial purpose in that context. Namely, \Cref{theorem:main-eah} relies on the \emph{ellipsoid against hope (\eah)} algorithm of~\citet{Papadimitriou08:Computing}, which in turn is based on running the ellipsoid algorithm on an infeasible program---the rationale being that a correlated equilibrium can be extracted from the certificate of infeasibility of that program. Now, to execute ellipsoid, one needs a separation oracle. For normal-form games, this amounts to a fixed point oracle: for any $\phi$, compute $\vx \in \cX$ such that $\phi(\vx) = \vx$. And, as we saw earlier, $\phi$ is a just a stochastic matrix, and so it suffices to identify a stationary distribution of the corresponding Markov chain.

However, there are two main obstacles, which manifest themselves in each iteration of the ellipsoid, when $\cX$ is a general convex set and $\Phi$ is allowed to contain nonlinear endomorphisms:

\begin{enumerate}
    \item computing a fixed point of a nonlinear $\phi$ is intractable; and\label{item:first}
    \item separating over the set $\Phi$ is also intractable even with respect to linear endomorphisms~\citep{Daskalakis24:Efficient}, let alone under~\Cref{assumption:kernel}.\label{item:second}
\end{enumerate}

With regard to~\Cref{item:first}, we show that, during the execution of the ellipsoid, one might as well use \emph{expected} fixed points, which are tractable by virtue of~\Cref{theorem:efps} we described earlier. What is intriguing is that our proof of~\Cref{theorem:efps} also relies on (a different instantiation of) $\eah$, and so the overall algorithm that we develop uses $\eah$ in a nested fashion---each separation oracle as part of the execution of $\eah$ is internally implemented via $\eah$!

For~\Cref{item:second}, we build on the framework of~\citet{Daskalakis24:Efficient}. In light of the inability to efficiently separate over linear endomorphisms, they observed that one can still execute $\eah$ with access to a weaker oracle, which they refer to as a \emph{semi-separation oracle}. Moreover, they developed a polynomial-time semi-separation oracle with respect to the set of linear endomorphisms. Building on~\Cref{theorem:efps}, we significantly extend their result, establishing a semi-separation oracle for general functions, not just linear ones.

\begin{theorem}[Semi-separation oracle for general functions]
    Given oracle access to $\cX$ and $\phi : \cX \to \R^d$, there is a $\poly(d, \log(1/\epsilon))$-time algorithm that either computes an $\epsilon$-expected fixed point of $\phi$, or identifies a point $\vx \in \cX$ such that $\phi(\vx) \notin \cX$.
\end{theorem}

(In particular, in the usual case where $\phi$ maps to $\cX$, the algorithm above always returns an $\epsilon$-expected fixed point of $\phi$.)

We now turn to~\Cref{theorem:main1}, which revolves around the online learning setting. Equipped with our semi-separation oracle for general functions, we show that the framework of~\citet{Daskalakis24:Efficient} can be extended from linear endomorphisms to ones satisfying~\Cref{assumption:kernel}. The technical pieces underpinning~\Cref{theorem:main1} are exposed in depth in~\Cref{sec:reg}. Importantly, the dimension of $\Phi$ turns out to be a fundamental barrier for no-regret learning in the following sense.

\begin{restatable}{theorem}{lowerbound}
    \label{theorem:mainlower}
    For any $k$ and any $d \ge \Theta(\log^{14} k)$, there is an online decision problem with dimension $d$ and an adversary such that the $\Phi$-regret of the learner with respect to a $k$-dimensional $\Phi$ is at least $\epsilon$ when $T < \min \{ \sqrt{k}/4, \exp(\Omega(\epsilon^{-1/6})) \}$.
\end{restatable}

This is a straightforward refinement of recent lower bounds~\citep{Daskalakis24:Lower,Dagan24:From,Peng24:Fast}. What is important is that, up to constant factors in the exponent of $k$, \Cref{theorem:mainlower} matches the upper bound of~\Cref{theorem:main1}. In doing so, we establish for the first time a class of deviations that characterizes---in the previous sense---no-$\Phi$-regret learning in the adversarial setting.

Finally, we remark that we did not attempt to optimize the polynomial dependencies on $d$ and $k$ throughout this paper; improving the overall complexity is an interesting direction for future work.

\subsection{Further related work}
\label{sec:related}

The existence of no-regret algorithms goes back to the pioneering work of~\citet{Blackwell56:analog}; the stronger notion of swap regret was crystallized and analyzed more recently~\citep{Blum07:From,Stoltz05:Internal,Hart00:Simple}. Part of the impetus of that line of work revolves around the connection to correlated equilibria, highlighted earlier. Unfortunately, beyond online decision problems on the simplex, such no-swap-regret algorithms become inefficient when the number of pure strategies is exponential in the natural parameters of the problem---as is the case, for example, in Bayesian games, wherein $\cX \defeq [0, 1]^d$. Recent breakthrough results by~\citet{Dagan24:From} and~\citet{Peng24:Fast} establish a new algorithmic paradigm for minimizing swap regret, applicable even when the number of pure strategies is exponential. However, that comes at the expense of introducing an exponential dependence on $1/\epsilon$, which is unavoidable in the adversarial regime~\citep{Daskalakis24:Lower}. Our main interest here is in online algorithms with complexity scaling polynomially in both the dimension and $1/\epsilon$.

Besides the game-theoretic implications concerning convergence to correlated equilibria, swap regret is a fundamental concept in its own right, being intimately tied to the notion of \emph{calibration}; namely, it has been known since the foundational work of~\citet{Foster97:Calibrated} that best-responding to calibrated forecasters guarantees no-swap-regret (\emph{cf.}\  \citet{Foster18:Smooth}); in relation to that connection, it is worth noting an important, recent body of work that bypasses the intractability of calibration in high dimensions~\citep{Noarov23:High,Roth24:Forecasting,Hu24:Predict}. Swap regret is also more robust against exploitation, in a sense formalized in a series of recent papers~\citep{Assos24:Maximizing,Mansour22:Strategizing,Deng19:Strategizing,Guruganesh24:Contracting}. 

In particular, within that line of work, \citet{Mansour22:Strategizing} introduced the notion of \emph{polytope swap regret}, which comprises deviations that allow the vertices of the underlying polytope to be swapped with each other---points inside the polytope are mapped in accordance with the (worst-case) convex combination of vertices. It is currently unknown whether there is an efficient algorithm for minimizing polytope swap regret.

The more flexible framework of $\Phi$-regret, which has been gaining considerable traction in recent years, allows one to circumvent the recent lower bound of~\citet{Daskalakis24:Lower} by restricting the set of deviations. In addition to the research highlighted above, chiefly in the context of extensive-form games, we now provide some further pointers for the interested reader. \citet{Bernasconi23:Constrained} considered the more challenging setting of so-called ``pseudo-games,'' wherein players have joint constraint sets. $\Phi$-equilibria in such settings have certain counterintuitive properties; for example, they are not necessarily convex. $\Phi$-equilibria have also garnered attention in the context of Markov (aka.\ stochastic) games, going back to the work of~\citet{Greenwald03:Correlated}; for more recent research, we refer to~\citet{Jin24:Vlearning,Erez23:Regret,Cai24:Near}, and references therein. Even more broadly, we refer to~\citet{Cai24:Tractable,Ahunbay25:First} for efficient solution concepts in nonconcave games~\citep{Daskalakis22:Non}.

Finally, we remark that the hardness result of~\citet{Daskalakis24:Efficient} for separating over linear endomorphisms does not apply to polytopes represented with a polynomial number of constraints. Indeed, it is relatively straightforward to implement a membership oracle for such polytopes~\citep{Daskalakis24:Efficient}. In contrast, it is computationally hard to decide membership for low-degree polynomials~\citep{Zhang24:Efficient}.