\section{Related Work}
% Our approach, Collaborative Auxiliary Modality Learning (CAML), integrates insights from multi-agent collaboration, multimodal learning, and knowledge distillation. Below, we discuss how existing methods in these areas relate to our work, their limitations, and how CAML advances the state of the art.

\paragraph{Multi-Agent Collaboration.}
% \vspace{-5pt}
Collaboration in multi-agent systems has been widely studied across fields such as autonomous driving and robotics. In autonomous driving, prior research has explored various strategies, including spatio-temporal graph neural networks ____, LiDAR-based end-to-end systems ____, decentralized cooperative lane-changing ____ and game-theoretic models ____. In robotics, ____ presented a hierarchical multi-robot collaboration approach using large language models, while ____ proposed a perception framework for multi-robot systems built on graph neural networks. A review of multi-robot systems in search and rescue operations was provided by ____, and ____ developed a reinforcement learning (RL) method for multi-robot path planning. Additionally, various communication mechanisms, such as Who2com ____, When2com ____, and Where2comm ____, have been created to optimize agent interactions.

Despite these advancements, existing multi-agent collaboration frameworks remain limited by their focus on specific tasks and the assumption that agents will have consistent access to the same data modalities during both training and testing, an assumption that may not hold in real-world applications. To address these gaps, our framework, \ours, enables agents to collaborate during training by sharing multimodal data, but at test time, each agent performs inference using reduced modality. This reduces the dependency on certain modalities for deployment, while still allowing agents to leverage additional data during training to enhance overall performance and robustness.
\vspace{-6pt}
\paragraph{Auxiliary Modality Learning.}
Auxiliary Modality Learning (AML) ____ has emerged as an effective solution to reduce computational costs and the amount of input data required for inference. By utilizing auxiliary modalities during training, AML minimizes reliance on those modalities at inference time. For example, ____ introduced a method that incorporates depth images during training to enhance test-time RGB-only detection models. Similarly, ____ proposed PM-GANs to learn a full-modal representation using data from partial modalities, while ____ developed approaches that use depth and RGB videos during training but rely solely on RGB data for testing. ____ created a localization system that predicts depth maps from RGB query images at test time. Building on these works, ____ formalized the AML framework, systematically classifying auxiliary modality types and AML architectures.

However, existing AML frameworks are typically designed for single-agent settings, failing to exploit the potential benefits of multi-agent collaboration for improving multimodal learning. \ours~allows agents to collaboratively learn richer multimodal representations during training. This approach mitigates the loss of information when modalities are reduced during inference, as the learned features are reinforced by data shared across agents.

% \vspace{-25pt}
\paragraph{Knowledge Distillation.}
Knowledge distillation (KD) ____ is a widely used technique in many domains to reduce computation by transferring knowledge from a large, complex model (teacher) to a simpler model (student). In computer vision, ____ provided a comprehensive survey of KD applications, while ____ conducted an empirical investigation to develop a robust and effective recipe for making State-of-the-Art (SOTA) large-scale models more practical. Additionally, ____ introduced a KD loss function that aligns the training of a student network with input pairs producing similar activation in the teacher network. In natural language processing, ____ reviewed the applications of KD in LLMs, while ____ proposed a Patient KD method to compress larger models into lightweight counterparts that maintain effectiveness. ____ also suggested a KD approach that leverages the soft target probabilities of the training model to train other neural networks. In autonomous driving, ____ presented an approach for visual detection, ____ used KD for 3D object detection.

Notice that existing KD mostly distills knowledge from a larger model to a smaller one to reduce computation, ____ aimed to design a cross-modality learning approach using KD to utilize the hidden information from auxiliary modalities within the AML framework. But AML is limited by the scope of a single-agent paradigm, missing opportunities for collaborative knowledge sharing across agents. In contrast, we leverage KD within multi-agent settings, where the teacher models are trained with access to shared multimodal data (e.g., RGB and LiDAR) from multiple agents. By distilling this collaborative knowledge into each agent’s reduced modality (e.g., RGB), \ours~enables robust inference during deployment, even with fewer modalities. This collaborative distillation process enhances each agent’s performance by providing richer, complementary knowledge from the collaborative training phase.

\vspace{-5pt}