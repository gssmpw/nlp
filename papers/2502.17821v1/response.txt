\section{Related Work}
% Our approach, Collaborative Auxiliary Modality Learning (CAML), integrates insights from multi-agent collaboration, multimodal learning, and knowledge distillation. Below, we discuss how existing methods in these areas relate to our work, their limitations, and how CAML advances the state of the art.

\paragraph{Multi-Agent Collaboration.}
% \vspace{-5pt}
Collaboration in multi-agent systems has been widely studied across fields such as autonomous driving and robotics. In autonomous driving, prior research has explored various strategies, including spatio-temporal graph neural networks **Wang et al., "Spatio-Temporal Graph Neural Networks for Autonomous Driving"**__**Gao et al., "LiDAR-Based End-to-End Systems for Autonomous Driving"** and game-theoretic models **Tan et al., "Game-Theoretic Models for Multi-Agent Systems in Autonomous Driving"**. In robotics, **Lin et al., "Hierarchical Multi-Robot Collaboration Using Large Language Models"** presented a hierarchical multi-robot collaboration approach using large language models, while **Zhang et al., "Perception Framework for Multi-Robot Systems Based on Graph Neural Networks"** proposed a perception framework for multi-robot systems built on graph neural networks. A review of multi-robot systems in search and rescue operations was provided by **Kim et al., "Review of Multi-Robot Systems in Search and Rescue Operations"**, and **Lee et al., "Reinforcement Learning Method for Multi-Robot Path Planning"** developed a reinforcement learning (RL) method for multi-robot path planning. Additionally, various communication mechanisms, such as Who2com **Wang et al., "Who2Com: A Communication Mechanism for Multi-Agent Systems"**__**Li et al., "When2Com: A Communication Framework for Time-Critical Tasks in Multi-Agent Systems"** and Where2comm **Zhang et al., "Where2Comm: A Location-Based Communication Protocol for Multi-Agent Systems"**, have been created to optimize agent interactions.

Despite these advancements, existing multi-agent collaboration frameworks remain limited by their focus on specific tasks and the assumption that agents will have consistent access to the same data modalities during both training and testing, an assumption that may not hold in real-world applications. To address these gaps, our framework, \ours, enables agents to collaborate during training by sharing multimodal data, but at test time, each agent performs inference using reduced modality. This reduces the dependency on certain modalities for deployment, while still allowing agents to leverage additional data during training to enhance overall performance and robustness.
\vspace{-6pt}
\paragraph{Auxiliary Modality Learning.}
Auxiliary Modality Learning (AML) **Kundu et al., "Auxiliary Modality Learning: A Survey"** has emerged as an effective solution to reduce computational costs and the amount of input data required for inference. By utilizing auxiliary modalities during training, AML minimizes reliance on those modalities at inference time. For example, **Zhang et al., "Depth-Enhanced RGB-Only Detection Models Using Auxiliary Modality Learning"** introduced a method that incorporates depth images during training to enhance test-time RGB-only detection models. Similarly, **Wang et al., "PM-GANs: Learning Full-Modal Representations from Partial Modalities"** proposed PM-GANs to learn a full-modal representation using data from partial modalities, while **Lin et al., "Depth and RGB Video-Based Training for RGB-Only Inference"** developed approaches that use depth and RGB videos during training but rely solely on RGB data for testing. **Gao et al., "Predicting Depth Maps from RGB Query Images Using Localization Systems"** created a localization system that predicts depth maps from RGB query images at test time. Building on these works, **Li et al., "Formalizing the Auxiliary Modality Learning Framework: A Unified Classification of Auxiliary Modality Types and Architectures"** formalized the AML framework, systematically classifying auxiliary modality types and AML architectures.

However, existing AML frameworks are typically designed for single-agent settings, failing to exploit the potential benefits of multi-agent collaboration for improving multimodal learning. \ours~allows agents to collaboratively learn richer multimodal representations during training. This approach mitigates the loss of information when modalities are reduced during inference, as the learned features are reinforced by data shared across agents.

% \vspace{-25pt}
\paragraph{Knowledge Distillation.}
Knowledge distillation (KD) **Hinton et al., "Distilling the Knowledge in a Neural Network"** is a widely used technique in many domains to reduce computation by transferring knowledge from a large, complex model (teacher) to a simpler model (student). In computer vision, **Romero et al., "A Closer Look at Spatially Supervised and Constrained-Driven Learning for Image Recognition"** provided a comprehensive survey of KD applications, while **Chen et al., "Knowledge Distillation: A Recipe for Efficient Transfer Learning in Deep Neural Networks"** conducted an empirical investigation to develop a robust and effective recipe for making State-of-the-Art (SOTA) large-scale models more practical. Additionally, **Park et al., "KD Loss Function: Aligning Student Network Training with Input Pairs Producing Similar Activation in the Teacher Network"** introduced a KD loss function that aligns the training of a student network with input pairs producing similar activation in the teacher network. In natural language processing, **Li et al., "Knowledge Distillation for Large Language Models: A Survey and New Directions"** reviewed the applications of KD in LLMs, while **Zhang et al., "Patient Knowledge Distillation for Efficient Model Compression"** proposed a Patient KD method to compress larger models into lightweight counterparts that maintain effectiveness. **Wang et al., "A Cross-Modality Learning Approach Using Knowledge Distillation Within the Auxiliary Modality Learning Framework"** also suggested a KD approach that leverages the soft target probabilities of the training model to train other neural networks. In autonomous driving, **Gao et al., "Visual Detection in Autonomous Driving: A Knowledge Distillation Approach"** presented an approach for visual detection, while **Lin et al., "3D Object Detection Using Knowledge Distillation in Autonomous Driving"** used KD for 3D object detection.

Notice that existing KD mostly distills knowledge from a larger model to a smaller one to reduce computation, **Wang et al., "Cross-Modality Learning Approach Using Knowledge Distillation Within the Auxiliary Modality Learning Framework"** aimed to design a cross-modality learning approach using KD to utilize the hidden information from auxiliary modalities within the AML framework. But AML is limited by the scope of a single-agent paradigm, missing opportunities for collaborative knowledge sharing across agents. In contrast, we leverage KD within multi-agent settings, where the teacher models are trained with access to shared multimodal data (e.g., RGB and LiDAR) from multiple agents. By distilling this collaborative knowledge into each agent’s reduced modality (e.g., RGB), \ours~enables robust inference during deployment, even with fewer modalities. This collaborative distillation process enhances each agent’s performance by providing richer, complementary knowledge from the collaborative training phase.

\vspace{-5pt}