\section{Related Work}
% Our approach, Collaborative Auxiliary Modality Learning (CAML), integrates insights from multi-agent collaboration, multimodal learning, and knowledge distillation. Below, we discuss how existing methods in these areas relate to our work, their limitations, and how CAML advances the state of the art.

\paragraph{Multi-Agent Collaboration.}
% \vspace{-5pt}
Collaboration in multi-agent systems has been widely studied across fields such as autonomous driving and robotics. In autonomous driving, prior research has explored various strategies, including spatio-temporal graph neural networks \citep{gao2024collaborative}, LiDAR-based end-to-end systems \citep{cui2022coopernaut}, decentralized cooperative lane-changing \citep{nie2016decentralized} and game-theoretic models \citep{hang2021decision}. In robotics, \citet{mandi2024roco} presented a hierarchical multi-robot collaboration approach using large language models, while \citet{zhou2022multi} proposed a perception framework for multi-robot systems built on graph neural networks. A review of multi-robot systems in search and rescue operations was provided by \cite{queralta2020collaborative}, and \citet{bae2019multi} developed a reinforcement learning (RL) method for multi-robot path planning. Additionally, various communication mechanisms, such as Who2com \citep{liu2020who2com}, When2com \citep{liu2020when2com}, and Where2comm \citep{hu2022where2comm}, have been created to optimize agent interactions.

Despite these advancements, existing multi-agent collaboration frameworks remain limited by their focus on specific tasks and the assumption that agents will have consistent access to the same data modalities during both training and testing, an assumption that may not hold in real-world applications. To address these gaps, our framework, \ours, enables agents to collaborate during training by sharing multimodal data, but at test time, each agent performs inference using reduced modality. This reduces the dependency on certain modalities for deployment, while still allowing agents to leverage additional data during training to enhance overall performance and robustness.
\vspace{-6pt}
\paragraph{Auxiliary Modality Learning.}
Auxiliary Modality Learning (AML) \cite{shen2023auxiliary} has emerged as an effective solution to reduce computational costs and the amount of input data required for inference. By utilizing auxiliary modalities during training, AML minimizes reliance on those modalities at inference time. For example, \citet{hoffman2016learning} introduced a method that incorporates depth images during training to enhance test-time RGB-only detection models. Similarly, \citet{wang2018pm} proposed PM-GANs to learn a full-modal representation using data from partial modalities, while \citet{garcia2018modality, garcia2019learning} developed approaches that use depth and RGB videos during training but rely solely on RGB data for testing. \citet{piasco2021improving} created a localization system that predicts depth maps from RGB query images at test time. Building on these works, \citet{shen2023auxiliary} formalized the AML framework, systematically classifying auxiliary modality types and AML architectures.

However, existing AML frameworks are typically designed for single-agent settings, failing to exploit the potential benefits of multi-agent collaboration for improving multimodal learning. \ours~allows agents to collaboratively learn richer multimodal representations during training. This approach mitigates the loss of information when modalities are reduced during inference, as the learned features are reinforced by data shared across agents.

% \vspace{-25pt}
\paragraph{Knowledge Distillation.}
Knowledge distillation (KD) \citep{hinton2015distilling} is a widely used technique in many domains to reduce computation by transferring knowledge from a large, complex model (teacher) to a simpler model (student). In computer vision, \citet{gou2021knowledge} provided a comprehensive survey of KD applications, while \citet{beyer2022knowledge} conducted an empirical investigation to develop a robust and effective recipe for making State-of-the-Art (SOTA) large-scale models more practical. Additionally, \citet{tung2019similarity} introduced a KD loss function that aligns the training of a student network with input pairs producing similar activation in the teacher network. In natural language processing, \citet{xu2024survey} reviewed the applications of KD in LLMs, while \citet{sun2019patient} proposed a Patient KD method to compress larger models into lightweight counterparts that maintain effectiveness. \citet{hahn2019self} also suggested a KD approach that leverages the soft target probabilities of the training model to train other neural networks. In autonomous driving, \citet{lan2022instance} presented an approach for visual detection, \citet{cho2023itkd, sautier2022image} used KD for 3D object detection.

Notice that existing KD mostly distills knowledge from a larger model to a smaller one to reduce computation, \citet{shen2023auxiliary} aimed to design a cross-modality learning approach using KD to utilize the hidden information from auxiliary modalities within the AML framework. But AML is limited by the scope of a single-agent paradigm, missing opportunities for collaborative knowledge sharing across agents. In contrast, we leverage KD within multi-agent settings, where the teacher models are trained with access to shared multimodal data (e.g., RGB and LiDAR) from multiple agents. By distilling this collaborative knowledge into each agent’s reduced modality (e.g., RGB), \ours~enables robust inference during deployment, even with fewer modalities. This collaborative distillation process enhances each agent’s performance by providing richer, complementary knowledge from the collaborative training phase.

\vspace{-5pt}