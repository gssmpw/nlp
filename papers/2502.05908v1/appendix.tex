\appendix
%\twocolumn[
%\icmltitle{Appendix of Bayesian Uncertainty for Gradient Combination in Multi-Task Learning}]

\onecolumn
\section{Full Experimental Details}
\label{sec:full_exp_details}
The experiments were mainly carried out using an NVIDIA A100 having 40GB and 80GB memory. 
In all experiments, we used the DDIM formulation \cite{SongME21}, although \MN{} can be applied with other sampling procedures. For all methods, we performed a hyperparameter search on $\eta \in \{0.05, 0.5, 1.0\}$. For DPS and TDS we examined several scaling coefficients for the prior mean update, including the ones proposed in each corresponding paper, and found that our proposed update works better for both. For all three methods (\MN{}, DPS, and TDS) we searched for $\nu_1 \in \{0, 1\}$ and $\kappa_1 \in \{0.4, 0.5, 1.0, 2.0\}$. For our method, we also performed a grid search over the timestep for the switch between the two terms in the proposal distribution $s \in \{0, 250, 333\}$. For PSLD, in most cases, the default hyper-parameters suggested in the paper and code didn't yield good results. Hence,
we performed a grid search over PSLD's hyper-parameters $\gamma_t \in \{1e-4, 1e-3, 1e-2, 0.1, 0.2\}$ and $\eta_t \in \{0.05, 0.1, 0.2, 0.9\}$. For Resample, we found that using $\eta = 0.0$, the default value in the code, usually performs the best. Also, we performed a grid search over $\gamma$, the scaling coefficient of the resampling step std in $\{4, 8, 16, 40, 80, 200, 400\}$. For each method, we evaluated visually and using the FID on a sample of images and then picked the best hyperparameter configuration. Then, we sampled $1024$ images using the best configuration. Similarly to Resample, we found that applying an optimization process at the end of the sampling process in the latent space can sometimes improve visibility and metric values. We evaluated all models with and without the final optimization process and picked the best one according to the FID. The optimization procedure was not applied to the inpainting task since it created non-smooth changes at the boundaries of the box, making the images look non-natural.

\begin{figure*}[!t]
    \centering
    \includegraphics[height=1.8\textwidth, width=0.9\textwidth, keepaspectratio]{figures/forward_process_degradation.jpg}
\caption{Evolution of $\rvy_t$ over time for different tasks according to forward process of DDIM.}
\label{fig:in_forward_process}
\end{figure*}

\section{Proposal Distribution Scaling Coefficients}
\label{sec:scaling_coefs}
Recall that our proposal distribution (\Eqref{eq:proposal} in the main text) is made of two elements. These elements are scaled by two coefficients, $\gamma_t$ and $\lambda_t$. Here, we provide an explicit formula for these coefficients. We found that our proposed scaling works better than common procedures used in the literature. For consistency with baseline methods, we also used our proposed scaling approach for DPS and TDS, since these methods apply a similar update rule. We tried to use it for PSLD and Resample but it didn't work well for these baselines.

Let $\rvg_t^1 \coloneqq \nabla_{\rvz_t}||\rvy_0 -\gA(\gD(\bar{\rvz}_0(\rvz_t)))||_2^2$, and $\rvg_t^2 \coloneqq \nabla_{\rvmu_\theta(\hat{\rvz}_t, t)}||\rvy_t - \gA(\gD(\rvmu_\theta(\hat{\rvz}_t, t)))||_2^2$.
We set the scaling coefficients $\gamma_t$ and $\lambda_t$ the same and according to the following scheme: $\gamma_t = \kappa_1 \cdot (1 - \bar{\alpha}_t)^{\nu_1} \cdot \frac{1}{max(||\rvg_t^1||_2^2, 1)}$, and similarly $\lambda_t = \kappa_2 \cdot (1 - \bar{\alpha}_t)^{\nu_2} \cdot \frac{1}{max(||\rvg_t^2||_2^2, 1)}$. Here $\{\nu_1, \nu_2\}$ are hyperparameters that controls the effect of the variance scaling, and $\{\kappa_1, \kappa_2\}$ scale the entire term. In practice, since we use either $\rvg_t^1$ or $\rvg_t^2$, but not both, we have only one set of hyperparameters which is used for both $\gamma_t$ and $\lambda_t$. That is, $\nu_1 \coloneqq \nu_2$ and $\kappa_1 \coloneqq \kappa_2$.

% \section{Run Time}
% \label{sec:run_time}

\section{Forward Process}
In \Figref{fig:in_forward_process} we present the evolution of the auxiliary labels $\rvy_t$ over time as part of the forward process according to our proposed sampling procedure in \Secref{sec:sampling_procedure}, steps (a) \& (b). From the figure, we observe a gradual cleaning of noise in the auxiliary labels when advancing from time $t=999$ to time $t=0$. 


\section{Full Results}
\label{sec:full_results}

\begin{table*}[!h]
%\small
\centering
\caption{\textit{ImageNet}. Box in-painting on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 65.45 & 7.918 && 19.19 & 0.623 & 0.407\\
    Latent TDS && 65.03 & 7.872 && 19.21 & 0.623 & 0.406\\
    Resample && 90.32 & 8.464 && 18.16 & 0.695 & 0.318\\
    PSLD && 79.90 & 9.268 && 17.48 & 0.583 & 0.410\\ 
    \midrule
    \MN{} (Ours) && 51.81 & 5.103 && 18.87 & 0.599 & 0.355\\
    \bottomrule
    \end{tabular}
\label{tab:ib_imagenet}
\end{table*}


\begin{table*}[!h]
%\small
\centering
\caption{\textit{ImageNet}. Gaussian debluring on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 52.48 & 6.855 && 23.61 & 0.615 & 0.383\\
    Latent TDS && 50.82 & 6.695 && 23.57 & 0.614 & 0.379\\
    Resample && 46.45 & 7.411 && 24.36 & 0.639 & 0.353\\
    PSLD && 79.31 & 7.972 && 21.38 & 0.483 & 0.474\\ 
    \midrule
    \MN{} (Ours) && 52.17 & 6.789 && 23.60 & 0.614 & 0.382\\ 
    \bottomrule
    \end{tabular}
\label{tab:gd_imagenet}
\end{table*}

\begin{table*}[!h]
%\small
\centering
\caption{\textit{ImageNet}. Super Resolution ($8\times$) on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 61.02 & 6.514 && 21.65 & 0.523 & 0.439\\
    Latent TDS && 58.73 & 7.157 && 21.45 & 0.515 & 0.454\\
    Resample && 87.65 & 8.290 && 22.05 & 0.532 & 0.491\\
    PSLD && 78.56 & 7.000 && 21.54 & 0.516 & 0.467\\ 
    \midrule
    \MN{} (Ours) && 59.27 & 6.423 && 21.64 & 0.521 & 0.437\\ 
    \bottomrule
    \end{tabular}
\label{tab:sr_imagenet}
\end{table*}

\begin{table*}[!h]
%\small
\centering
\caption{\textit{FFHQ}. Box in-painting on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 39.81 & 7.592 && 24.15 & 0.814 & 0.236\\
    Latent TDS && 39.57 & 7.602 && 24.24 & 0.814 & 0.236\\
    Resample && 86.79 & 7.142 && 19.75 & 0.815 & 0.230\\
    PSLD && 47.51 & 7.480 && 22.70 & 0.722 & 0.312\\ 
    \midrule
    \MN{} (Ours) && 37.14 & 7.520 && 24.08 & 0.817 & 0.224\\ 
    \bottomrule
    \end{tabular}
\label{tab:ib_ffhq}
\end{table*}

\begin{table*}[!h]
%\small
\centering
\caption{\textit{FFHQ}. Gaussian debluring on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 31.81 & 6.813 && 26.25 & 0.709 & 0.285\\
    Latent TDS && 33.19 & 6.879 && 26.13 & 0.705 & 0.288\\
    Resample && 39.80 & 7.441 && 28.45 & 0.763 & 0.275\\
    PSLD && 36.31 & 6.802 && 24.02 & 0.633 & 0.341\\ 
    \midrule
    \MN{} (Ours) && 32.18 & 6.566 && 26.60 & 0.721 & 0.280\\ 
    \bottomrule
    \end{tabular}
\label{tab:gd_ffhq}
\end{table*}


\begin{table*}[!h]
%\small
\centering
\caption{\textit{FFHQ}. Super resolution ($8 \times$) on $1024$ test examples.}
\begin{tabular}{l c cc c ccc}
    \toprule
    && \multicolumn{2}{c}{Perceptual Quality} && \multicolumn{3}{c}{Distortion}\\
    \cmidrule(l){3-4}  \cmidrule(l){6-8}
    && FID ($\downarrow$) & NIQE ($\downarrow$) && PSNR ($\uparrow$) & SSIM ($\uparrow$) & LPIPS ($\downarrow$) \\
    \midrule
    Latent DPS && 29.64 & 6.412 && 25.48 & 0.701 & 0.282\\
    Latent TDS && 30.45 & 6.412 && 25.38 & 0.698 & 0.284\\
    Resample && 59.23 & 7.307 && 25.55 & 0.661 & 0.356\\
    PSLD && 40.33 & 6.803 && 23.66 & 0.615 & 0.347\\ 
    \midrule
    \MN{} (Ours) && 30.37 & 6.456 && 25.42 & 0.698 & 0.284\\ 
    \bottomrule
    \end{tabular}
\label{tab:sr_ffhq}
\end{table*}

\newpage
\section{Image Reconstructions}
\label{sec:img_rec}

\begin{figure*}[!t]
    \centering
    \includegraphics[height=1.8\textwidth, width=0.9\textwidth, keepaspectratio]{figures/ffhq_inpainting_reconstractions.jpg}
\caption{Comparison between \MN{} and baseline methods on inpainting of images from the FFHQ dataset.}
\label{fig:ffhq_ib_recon}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/LD-SMC_GD_recon.jpg}
\caption{\textit{Gaussian debluring}. \MN{} reconstruction of images from FFHQ (left) and ImageNet (right).}
\label{fig:gd_recon}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/LD-SMC_SR_recon.jpg}
\caption{\textit{Super resolution}. \MN{} reconstruction of images from FFHQ (left) and ImageNet (right).}
\label{fig:sr_recon}
\end{figure*}


% \begin{figure*}[!t]
%     \centering
%     \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/ffhq_debluring.jpg}
% \caption{\textit{Gaussian debluring}. FFHQ image reconstructions by \MN{}.}
% \label{fig:ffhq_gd_recon}
% \end{figure*}

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/ffhq_super_res.jpg}
% \caption{\textit{Super resolution}. FFHQ image reconstructions by \MN{}.}
% \label{fig:ffhq_sr_recon}
% \end{figure*}

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/imagenet_debluring.jpg}
% \caption{\textit{Gaussian debluring}. ImageNet image reconstructions by \MN{}.}
% \label{fig:in_gd_recon}
% \end{figure*}

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[height=1.1\textwidth, keepaspectratio]{figures/imagenet_super_res.jpg}
% \caption{\textit{Super resolution}. ImageNet image reconstructions by \MN{}.}
% \label{fig:in_sr_recon}
% \end{figure*}