

\section{Novel Objectives for Time Score Estimation}
\label{sec:estimating_time_score}

In this section, we propose novel methods to estimate the time score.

\subsection{Basic Method}

\paragraph{Augmenting the state space}
First,  we rewrite~\eqref{eq:l2_loss} so that it is tractable. The idea is to further augment the state space to $(\bx, t, \bz)$ by introducing a \textit{conditioning variable} $\bz$, as in related literature. Thus, we extend the model from~\eqref{eq:joint_model_two_variables} into 
\begin{align}
    \label{eq:joint_model_three_variables}
    p(\bx, t, \bz) = p(t) p(\bz) p(\bx | t, \bz),
\end{align}
such that the intermediate distributions $p(\bx | t, \bz)$ --- now conditioned on $\bz$ --- can be sampled from \textit{and} evaluated. We remark that this insight is shared by previous research in score matching \citet{vincent2011denoisingscorematching} and flow matching \citep{lipman2023conditionalflowmatching,pooladian2023conditionalflowmatching,tong2024conditionalflowmatching}.

Consider for example~\eqref{eq:vp_path_simulation}. By choosing to condition on $\bz = \bx_1$, we get a closed-form $p(\bx | t, \bz) = \mathcal{N}(\bx; \alpha_t \bz, (1-\alpha_t^2) \mI)$. In this example, $\bz$ is a sample of ``raw" data (for example, real observed data) while $\bx$ is a corrupted version of data, and $t$ controls the corruption level, ranging from $0$ (full corruption) to $1$ (no corruption), as in~\citet{vincent2011denoisingscorematching}. In the following, we explain how to relate the descriptions of the \textit{intractable} marginal probability path $p_t(\bx)$ to descriptions of the \textit{tractable} conditional probability path $p_t(\bx | \bz)$.


\paragraph{Tractable objective for learning the time score}
As a result of~\eqref{eq:joint_model_three_variables}, we relate the time scores, obtained with and without conditioning on $\bz$ (derivations are in Appendix~\ref{app:sec:mixture_score})
\begin{equation}
    \label{eq:mixture_score}
    \partial_{t}\log p_{t}(\bx) 
    = 
    \E_{p_t(\bz | \bx)} \left[
    \partial_{t}\log p_{t}(\bx|\bz) 
    \right]
\end{equation}
and exploit this identity to learn the time score, 
by plugging~\eqref{eq:mixture_score} into the original loss in~\eqref{eq:l2_loss}. 
This way,  
we can reformulate the intractable objective in~\eqref{eq:l2_loss} into a tractable objective which we call the \textit{Conditional Time Score Matching (CTSM)} objective
    \begin{align}
        \label{eq:l2_loss_conditional}
        \mathcal{L}_{\text{CTSM}}(\btheta) 
        &= 
        \E_{p(\bx, \bz, t)} \big[
        \lambda(t) \big( \partial_{t}\log p_{t}(\bx|\bz) - s_{\btheta}(\bx, t) \big)^2 
        \big].
    \end{align}
Note that the regression target is given by the time score of the conditional distribution, $\partial_t \log p_t(\bx | \bz)$. The reformulation is justified by the following theorem:
\begin{theorem}[Regressing the time score]
    \label{theorem:ctsm_objective}
    The TSM loss~\eqref{eq:l2_loss} 
    and CTSM loss~\eqref{eq:l2_loss_conditional} are equal, up to an additive constant.
\end{theorem}
The proof can be found in Appendix~\ref{app:sec:theorem3_proof}. This new objective is useful, as it requires evaluating the time score of the tractable distribution $p_t(\bx | \bz)$ instead of the intractable distribution $p_t(\bx)$. By minimizing this objective, the model $s_{\btheta}(\bx,t)$ learns to output $\partial_{t} \log p_{t}(\bx)$. A similar observation was made in~\citet[Appendix L.3.]{deBortoli2022}, however they did not translate this observation into the CTSM objective and use it for learning. Furthermore, their setting was more restrictive, as the conditioning variable was specifically chosen to be $\bx_1$.

\subsection{Vectorized Variant}

We propose a further objective for learning the time score, called \textit{Vectorized Conditional Time Score Matching (CTSM-v)}. The idea is that we can easily vectorize the learning task, by forming a joint objective over the $D$ dimensions. The intuition is that the time score can be written as a sum of autoregressive terms, and that we learn each term of the sum instead of the final result only. We verify in section~\ref{sec:experiments} that this approach empirically leads to better performance.
Formally, define the vectorization of the conditional time score as the result of stacking its components as
\begin{equation}
\text{vec}(\partial_t \log p_t(\bx | \bz)) = [\partial_t \log p_t(x^i | \bx^{<i}, \bz)]_{i \in \llbracket 1, D \rrbracket}^\top.
\end{equation}
The time score is then obtained by summing these components. Our vectorized objective is given by

\begin{align}
\mathcal{L}_{\text{CTSM-v}}(\btheta)
= 
\E_{p(t, \bz, \bx)}
\left[\lambda(t)\norm{\text{vec}(\partial_{t}\log p_{t}(\bx|\bz)) - \bs^{\text{vec}}_{\btheta}(\bx,t)}^2\right].
\label{eq:full-conditional-time-score}
\end{align}

\begin{theorem}[Regressing the vectorized time score]
    \label{theorem:ctsm_v_objective}
    The CTSM-v objective~\eqref{eq:full-conditional-time-score} is minimized when the sum of the entries of the score network equals the time score.
\end{theorem}
This is proven in Appendix~\ref{app:sec:theorem3_proof}. By minimizing this objective, the model $s_{\btheta}^{\text{vec}}(\bx, t)$ learns to output $[\E_{p_t(\bz | \bx)}[\partial_t \log p_t(x^i | \bx^{<i} | \bz)]]_{i \in \llbracket1, D \rrbracket}^\top$; this is further justified in the next     Theorem~\ref{theorem:marginal_vs_condition_regression}. The original time score can be obtained from the learnt $s_{\btheta}^{\text{vec}}(\bx, t)$ by summing all the entries. Further, while the components of the regression target are formally given by $[\partial_t \log p_t(x^i | \bx^{<i}, \bz)]_{i \in \llbracket 1, D \rrbracket}^\top$, for commonly used probability paths like the VP path, the dependency on $\bx^{<i}$ is dropped.

\subsection{General Framework}

We next show that our learning objectives, i.e., both the conditional time score matching one and the vectorized variant, are actually special cases of a more general framework.

Just as we related the marginal and conditional time scores, $\partial_t \log p_t(\bx)$ and $\partial_t \log p_t(\bx | \bz)$ in~\eqref{eq:mixture_score}, let us now consider the same identity for general, vector or scalar valued functions $\bg(\bx, t)$ and $\bbf(\bx, t, \bz)$, where $t\in [0,1]$
\begin{align}
    \label{eq:mixture_vector_field}
    \bg(\bx,t) 
    = 
    \E_{ p_{t}(\bz|\bx)}[
    \bbf(\bx,t, \bz)
    ].
\end{align}
By analogy to previous paragraphs, we call the functions $\bg$ and $\bbf$, ``marginal" and ``conditional". We consider the scenario where $\bg(\bx,t)$ is intractable, yet $\bbf(\bx,t,\bz)$ is tractable. Similarly, we obtain a theorem that states that a regression problem over the ``marginal" function $\bg(\bx,t)$ can be reformulated as a regression problem over the ``conditional" function $\bbf(\bx,t|\bz)$, thus resulting in a tractable training objective.
\begin{theorem}[Regressing a function]
    \label{theorem:marginal_vs_condition_regression}
    Consider vector or scalar valued functions $\bbf(\bx,t|\bz)$ and $\bg(\bx,t) = \E_{ p_{t}(\bz|\bx)}[\bbf(\bx,t|\bz)]$. Then, the following two loss functions are equal up to an additive constant that does not depend on $\btheta$:
    \begin{align}
    \mathcal{L}_{\bbf}(\btheta) 
    &= 
    \E_{p(t, \bz, \bx)}\left[\lambda(t)\norm{\bbf(\bx,t|\bz) - \bs_{\btheta}(\bx,t)}^2\right],
    \\
    \mathcal{L}_{\bg}(\btheta) 
    &= 
    \E_{p(t, \bx)}\left[\lambda(t)\norm{\bg(\bx,t) - \bs_{\btheta}(\bx,t)}^2\right].
    \end{align}
\end{theorem}
We prove this result in Appendix~\ref{app:sec:theorem3_proof}. 
Our Theorem~\ref{theorem:ctsm_objective} is a special case when $\bbf(\bx,t|\bz) = \partial_{t}\log p_{t}(\bx|\bz)$ and $\bg(\bx,t)= \partial_{t}\log p_{t}(\bx)$. Similarly, our Theorem~\ref{theorem:ctsm_v_objective} is a special case when $\bbf(\bx,t|\bz)=\vec(\partial_{t}\log p_{t}(\bx|\bz))$ and $\bg(\bx,t)=\E_{p_{t}(\bz|\bx)}\left[\bbf(\bx,t)\right]$. 

Versions of Theorem~\ref{theorem:marginal_vs_condition_regression} appear multiple times in the literature, yet they have always been stated for specific functions $\bg$ that are Stein scores $\partial_{\bx} \log p_t(\bx)$~\citep{vincent2011denoisingscorematching,song2021sde} or velocities that generate the probability path~\citep{lipman2023conditionalflowmatching, pooladian2023conditionalflowmatching, tong2024conditionalflowmatching}.
For example, in \citet{vincent2011denoisingscorematching}, $\bbf(\bx, t | \bz) = \partial_{\bx} \log p_t(\bx | \bz)$ and $p(t)$ is a Dirac. 
In \citet{tong2024conditionalflowmatching}, $\bbf(\bx, t | \bz) = v_t(\bx | \bz)$ which is a velocity  such that the solution to the ordinary differential equation $\dot{\bx}_t = \bbv_t(\bx | \bz)$ has marginals $p_t(\bx | \bz)$. To our knowledge, it has not been stated for general functions, whose output may have any dimensionality, nor has it been applied to time scores or vectorized time scores, as we do. 

\section{Design Choices}
\label{sec:design_choices}

In the previous section, we derived two novel and tractable learning objectives for the density ratio of two distributions, CTSM~\eqref{eq:l2_loss_conditional} and CTSM-v~\eqref{eq:full-conditional-time-score}. In this section, we consider two design choices for both of these learning objectives --- the conditional probability path $p_t(\bx | \bz)$ and the weighting function $\lambda(t)$.  

\paragraph{Choice of probability path}
Our regression objectives require computing the time score and its vectorization of a conditional density that is analytically known. It is common to choose a Gaussian $p_{t}(\bx|\bz) = \mathcal{N}(\bx ; \bmu_{t}(\bz),k_{t}\bI)$~\citep{lipman2023conditionalflowmatching}, so that the conditional time score is obtained in closed form. We specify popular choices of $\bz$, $\bmu_t(\bz)$, $k_t$ in Appendix~\ref{app:sec:mixture}. 

In particular, previous works on density ratio estimation~\citet{Rhodes2020,choi2022densityratio} focused on the VP probability path~\eqref{eq:vp_path_simulation}, which is also popular in the literature of diffusion models~\citep{sohl-dickstein2015deep,ho2020ddpm,song2021sde}. By conditioning~\eqref{eq:vp_path_simulation} on $\bz=\bx_{1}$, we obtain the conditional densities
\begin{align}
    p_{t}(\bx|\bz) 
    = 
    \mathcal{N} \left(\bx;\alpha_{t}\bx_{1},(1-\alpha_{t}^{2}) \bI\right).
\end{align}
The conditional time score is
\begin{align}
    \partial_{t}\log p_{t}(\bx|\bz) 
    = 
    D\frac{\alpha_{t}\alpha'_{t}}{1-\alpha_{t}^{2}} - \frac{\alpha_{t}\alpha'_{t}}{1-\alpha_{t}^{2}}\norm{\bepsilon}^{2}
    + \frac{1}{\sqrt{1-\alpha_{t}^{2}}}\bepsilon^{\top}\alpha'_{t}\bx_{1},
\end{align}
where $\bepsilon = \frac{\bx-\alpha_{t}\bx_{1}}{\sqrt{1-\alpha_{t}^{2}}}$. Finally, the vectorized conditional time score is
\begin{align}
    \vec\left(\partial_{t}\log p_{t}(\bx|\bz)\right) 
    = 
    \frac{\alpha_{t}\alpha'_{t}}{1-\alpha_{t}^{2}} - \frac{\alpha_{t}\alpha'_{t}}{1-\alpha_{t}^{2}}\bepsilon^{2}
    + \frac{1}{\sqrt{1-\alpha_{t}^{2}}}\bepsilon\alpha'_{t}\bx_{1}.
\end{align}
where the square and the product are element-wise operations. This is shown in Appendix~\ref{app:ssec:vp_path}. 







\paragraph{Choice of weighting function}

The cost function in~\ref{eq:l2_loss_conditional} combines multiple regression tasks, indexed by $t$, into a single objective, representing a multi-task learning problem. A practical challenge is determining how to weigh the different tasks~\citep{ruder2017multitask,Rhodes2020}.

Some approaches estimate a weighting function during training~\citep{kendall2017multitaskweights,nichol2021diffusion,choi2022densityratio,kingma2023diffusion}, 
while others use an approximation which does not depend on the parameter~\citep{song2021sde,tong2024schrodingerbridge}. We follow the latter approach and draw inspiration from the diffusion models literature \citep{ho2020ddpm,song2021sde}, where it is common to choose as weighting function 
\begin{align}
    \label{eq:path_var}
    \lambda(t)
    \propto \frac{1}{\E_{p(\bx, \bz)}\left[ \norm{\partial_{\bx}\log p_{t}(\bx|\bz)}^2 \right]},
\end{align}
which is also the default weighting scheme from~\citet{choi2022densityratio}. It was derived for estimating the Stein score $\partial_{\vx} \log p_t(\bx | \bz)$ \citep{song2021sde}, and we refer to this weighting scheme as \textit{Stein score normalization}. We show in Appendix~\ref{app:sec:mixture} that it simplifies to $\lambda(t) \propto k_t$.

However, as the name and the equation itself suggest, Stein score normalization is derived based on Stein score, thus not directly relating to the time score. One benefit of Stein score normalization is that its scaling essentially results in the regression targets having unit variances \citep{ho2020ddpm}.
However, the variance of the time score does not equal to the variance of the Stein score. We instead consider 
\begin{align}
    \label{eq:time_score_normalization}
    \lambda(t) 
    \propto \frac{1}{\E_{p(\bx, \bz)}\left[\partial_{t}\log p_{t}(\bx|\bz)^2 \right]}
\end{align}
for CTSM and CTSM-v. This new weighting, which we call \textit{time score normalization}, 
keep the regressands roughly equal in magnitude. We explicitly compute this novel weighting function in Appendix~\ref{app:sec:mixture}: its formula depends on a quantity $c$ that is a function of the data distribution's mean and variance. A natural choice for $c$ is to compute these statistics from the data, but in our experiments, setting $c=1$ often yields better results. In our initial experiments, we found that using the time score normalization was important to achieve stable training. We remark that it is possible to apply time score normalization~\eqref{eq:time_score_normalization} to CTSM-v as well: upon assuming each dimensionality having equal scales, one can calculate the variances of the objective in each individual dimension and employ the same weighting scheme.

For the specific case of the VP path~\eqref{eq:vp_path_simulation}, the time score normalization can be defined as
\begin{align}
\hat{\lambda}(t) 
&= 
\frac{\left(1-\alpha_{t}^{2}\right)^{2}}{2\alpha_{t}^{2}\left(\alpha'_{t}\right)^{2}+\left(\alpha'_{t}\right)^{2}\left(1-\alpha_{t}^{2}\right)c}.
\end{align}


We remark that, using importance sampling as done in \citet{Song2021mle}, it is possible to benefit from both the stability of time score normaliziation and the flexibility of different weighting schemes.

\paragraph{Importance sampling} 

While time score normalization yields stable training in general, we empirically observe that it may not always yield the best results. Specifically, when the variance of the time score is large, for instance, when $\alpha_{t}\rightarrow 1$, time score normalization results in heavy down weighting. In certain cases it is beneficial to employ a weighting scheme that implies approximately uniform reweightings.

Inspired by diffusion models literature \citep{Song2021mle}, we employ importance sampling. Specifically, samples of $t$ are drawn from another distribution $\tilde{p}(t)$,
\begin{equation}
\mathcal{L}(\btheta) 
= 
\E_{p(\bx, \bz), \tilde{p}(t)} \bigg[
\frac{\bar{\lambda}(t)}{\tilde{p}(t)} \big( \partial_{t}\log p_{t}(\bx|\bz) - s_{\btheta}(\bx, t) \big)^2 
\bigg],
\end{equation}
with the goal being that, ideally, $\frac{\bar{\lambda}(t)}{\tilde{p}(t)} = \lambda(t)$ and $\bar{\lambda}(t) \approx 1$. Further details on the employed importance sampling scheme can be found in Section~\ref{app:sec:importance-sampling}.

\section{Theoretical Guarantees}
\label{sec:theoretical_guarantees}

In this section, we provide theoretical guarantees on the density estimated by CTSM or CTSM-v. All proofs are included in Appendix~\ref{app:sec:theory}. 

In practice, we can approximate~\eqref{eq:main_identity} as
\begin{align}
    \label{eq:main_identity_approx}
    \log \hat{p}_1(\bx)
    = 
    \frac{1}{K} \sum_{i=1}^K \hat{s}(\bx, t_i)
    + 
    \log p_0(\bx),
\end{align}
introducing two sources of error, namely the error due to discretizing the integral with $K$ steps and the error due to using the approximate time score $\hat{s}(\bx, t)$. We quantify these errors in the following theorem.
\begin{theorem}[General error bound]
\label{theorem:error_bound}
Denote by $p_1$ and $\hat{p}_1$ the densities obtained from~\eqref{eq:main_identity} and~\eqref{eq:main_identity_approx}, using the true and approximate time scores, $s(\bx, t):=\partial_t \log p_t(\bx)$ and $\hat{s}(\bx, t)$ respectively. 
Assume that the correct time score evolves smoothly with time, specifically $t \mapsto s(\bx, t)$ is $L(\bx)$-Lipschitz. Denote as follows the time-discretized distribution $p_K(t) = \frac{1}{K} \sum_{i=1}^K \delta_{t_i}(t)$. The error between the two distributions $p_1$ and $\hat{p}_1$ is bounded as
\begin{align}
\label{eq:generic_error_bound}
    \mathrm{KL}(p_1, \hat{p}_1)^2
    \leq
    \frac{1}{2 K^2}
    \E_{p_1(\bx)} [L(\bx)^2]
    +
    2
    \E_{p_1(\bx), p_K(t)}
    [
    \left( s(\bx, t) - \hat{s}(\bx, t) \right)^2
    ].
\end{align}
\end{theorem}
The first term quantifies a discretization error of the integral: it is null when using discretization steps $K \rightarrow \infty$, or when using paths whose time-evolution $t \rightarrow p(\bx, t)$ is smooth, even stationary $L(\bx) \rightarrow 0$ for any point $\bx \in \R^d$ where the density is evaluated. Comparing the constants $L(\bx)$ of different probability paths is left for future work. 

The second term in~\eqref{eq:generic_error_bound} quantifies the estimation error of the time score, collected over the times $t_i$ where it is evaluated.
While such an estimation error is assumed to be constant in related works~\citep{deBortoli2022}, we specify it for both CTSM and CTSM-v in our next result.
\begin{proposition}[Error bound for CTSM and CTSM-v]
\label{proposition:error_bound_scores}
Now consider a parametric model for the time score, $s_{\vtheta}(\bx, t)$. Denote by $\btheta*$ the parameter for the actual time score $\partial_t \log p_t(\bx)$, obtained by minimizing the loss from~\eqref{eq:l2_loss_conditional}. Denote by $\hat{\btheta}$ the parameter obtained from minimizing that same loss when the expectation is approximated using a finite sample $(\bx_i, \bz_i, t_i)_{i \in \llbracket 1, N \rrbracket}$. Then, the expected error over all estimates $\hat{p_1}$, obtained by integrating the estimated score $s_{\hat{\btheta}}(\bx, t)$ over time, is
\begin{align}
    \E_{\hat{p}_1}[\mathrm{KL}(p_1, \hat{p}_1)^2]
    \leq
    \frac{1}{2 K^2}
    \E_{p_1(\bx)} [L(\bx)^2]
    +
    \frac{2}{N} e(\btheta^*, \lambda, p)
    + 
    o\Big( \frac{1}{N} \Big),
\end{align}
Note that the expectation of the $\mathrm{KL}$ is taken over all estimates $\hat{p_1}$. The error function $e(\cdot)$ is specified in Appendix~\ref{app:sec:theory}, specifically~\eqref{eq:expected_squared_score_error}, with the matrices for CTSM specified in~\eqref{eq:ctsm_matrices} and the matrices for CTSM-v specified in~\eqref{eq:ctsm_v_matrices}. 
\end{proposition}
Again, note that the final error decreases with the sample size $N$ and discretization steps $K$. Moreover, the estimation error of the time score depends on three design choices: the parameterization of the model $\btheta \rightarrow s_{\btheta}(\bx, t)$, the chosen probability path $p_t(\bx | \bz)$, and the weighting function $\lambda(t)$. Interestingly, there is an edge case that is \textit{independent of the parameterization of the score} (and therefore of the choice of neural network architecture) where the error is zero. That is when the conditional and marginal scores are equal for CTSM, $\partial_t \log p_t(\bx | \bz) = \partial_t \log p_t(\bx)$, and when the vectorized version of that statement 
$\partial_t \log p_t(x^i | \bx^{<i}, \bz) = \E_{p_{t}(\bz|\bx)}\left[\partial_t \log p_t(x^i | \bx^{<i}, \bz)\right]$ holds true for CTSM-v. Choosing paths that approximately verify these condition could reduce the estimation error and would be interesting future work. 

