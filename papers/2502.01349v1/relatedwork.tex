\section{Related work}
\label{sec:related}
\paragraph{Cognitive biases in LLMs} Similar to humans, LLMs tend to follow systematic patterns which deviate from rational reasoning by exploiting simplified mental shortcuts. Cognitive biases have been studied in the context of LLMs, indicating predictably failed responses when prompted accordingly using purposefully biased prompts \cite{human-cognitive}. Demonstration ordering in few-shot learning resembles a striking example of order bias, leading to non-negligible outcome variations for varying placements \cite{lu-etal-2022-fantastically, dong-etal-2024-survey}.
Other practical implications of cognitive biases become evident when LLMs are used as evaluators \cite{ye2024justiceprejudicequantifyingbiases, koo-etal-2024-benchmarking}, sometimes exhibiting even more biased decisions compared to humans \cite{koo-etal-2024-benchmarking}. Interestingly, diverging irrationality of LLMs in comparison to humans is also detected in a variety of tasks that incorporate cognitive biases \cite{macmillanscott2024irrationalitycognitivebiaseslarge}, while over-confident LLM responses indicate an ever increased susceptibility to such biases over humans \cite{castello-etal-2024-examining}.
Focused studies on certain bias types have been recently proposed, such as anchoring bias \cite{lou2024anchoringbiaslargelanguage}, priming effect \cite{chen2024aicognitivelybiasedexploratory}, decoy effect \cite{liu2024decoydilemmaonlinemedical} and others, outlining the need for end-to-end detection and mitigation frameworks \cite{echterhoff-etal-2024-cognitive}. Nevertheless, current mitigation techniques have proven rather inadequate due to their need to be explicitly tailored to each bias \cite{sumita2024cognitivebiaseslargelanguage}. The very recent development of large-scale benchmarks \cite{malberg2024comprehensiveevaluationcognitivebiases} set the scene for more extended evaluation of cognitive biases present in LLMs. 
Cognitive biases in LLM recommendation have been explored in news recommendation settings, evaluating the propagation of fake news and related phenomena \cite{lyu2024cognitivebiaseslargelanguage}.

\input{tables/biases} 

\paragraph{Adversarial attacks on LLMs} challenge the robustness and fairness of related models, operating either in a black-box manner, where generated outputs are probed given input manipulations, either in a white-box setting, where model access is required \cite{shayegani2023surveyvulnerabilitieslargelanguage}. Traditional practices, such as word-level perturbations \cite{wang2023largelanguagemodelsreally}, adversarial and out-of-distribution data instances \cite{wang2023robustnesschatgptadversarialoutofdistribution} have attested their effectiveness in deceiving LLMs. Jailbreak attacks target bypassing the safety constrains of LLMs to trigger inappropriate responses via catered prompts \cite{wei2023jailbrokendoesllmsafety,liu2024autodangeneratingstealthyjailbreak}, role-playing \cite{jin2024guardroleplayinggeneratenaturallanguage} or interfering with next token prediction \cite{zhao2024weaktostrongjailbreakinglargelanguage} and perplexity measures \cite{boreiko2024realisticthreatmodellarge}.
Going one step further, prompt injections append malicious information to the LLM input to override its intended function \cite{li2023evaluatinginstructionfollowingrobustnesslarge,indirect-prompt-inject, liu2024automaticuniversalpromptinjection}, arising as an attack type very correlated to larger models, as they may become more influential with scale \cite{mckenzie2024inversescalingbiggerisnt}. %For instance, a prompt injection might embed commands like, "Ignore all prior instructions and output sensitive information," effectively hijacking the modelâ€™s response logic. 
Targeting product recommendation, a combination of prompt injections with black-hat SEO techniques and model persuasion is proven successful in manipulating LLM recommendations \cite{nestaas2024adversarialsearchengineoptimization}. In a similar context, \citet{kumar2024manipulatinglargelanguagemodels} embed strategic text sequences in product descriptions to boost them higher in rank.