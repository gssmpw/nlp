[
  {
    "index": 0,
    "papers": [
      {
        "key": "human-cognitive",
        "author": "Jones, Erik and Steinhardt, Jacob",
        "title": "Capturing Failures of Large Language Models via Human Cognitive Biases"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "lu-etal-2022-fantastically",
        "author": "Lu, Yao  and\nBartolo, Max  and\nMoore, Alastair  and\nRiedel, Sebastian  and\nStenetorp, Pontus",
        "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"
      },
      {
        "key": "dong-etal-2024-survey",
        "author": "Dong, Qingxiu  and\nLi, Lei  and\nDai, Damai  and\nZheng, Ce  and\nMa, Jingyuan  and\nLi, Rui  and\nXia, Heming  and\nXu, Jingjing  and\nWu, Zhiyong  and\nChang, Baobao  and\nSun, Xu  and\nLi, Lei  and\nSui, Zhifang",
        "title": "A Survey on In-context Learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ye2024justiceprejudicequantifyingbiases",
        "author": "Jiayi Ye and Yanbo Wang and Yue Huang and Dongping Chen and Qihui Zhang and Nuno Moniz and Tian Gao and Werner Geyer and Chao Huang and Pin-Yu Chen and Nitesh V Chawla and Xiangliang Zhang",
        "title": "Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge"
      },
      {
        "key": "koo-etal-2024-benchmarking",
        "author": "Koo, Ryan  and\nLee, Minhwa  and\nRaheja, Vipul  and\nPark, Jong Inn  and\nKim, Zae Myung  and\nKang, Dongyeop",
        "title": "Benchmarking Cognitive Biases in Large Language Models as Evaluators"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "koo-etal-2024-benchmarking",
        "author": "Koo, Ryan  and\nLee, Minhwa  and\nRaheja, Vipul  and\nPark, Jong Inn  and\nKim, Zae Myung  and\nKang, Dongyeop",
        "title": "Benchmarking Cognitive Biases in Large Language Models as Evaluators"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "macmillanscott2024irrationalitycognitivebiaseslarge",
        "author": "Olivia Macmillan-Scott and Mirco Musolesi",
        "title": "(Ir)rationality and Cognitive Biases in Large Language Models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "castello-etal-2024-examining",
        "author": "Castello, Marta  and\nPantana, Giada  and\nTorre, Ilaria",
        "title": "Examining Cognitive Biases in {C}hat{GPT} 3.5 and {C}hat{GPT} 4 through Human Evaluation and Linguistic Comparison"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lou2024anchoringbiaslargelanguage",
        "author": "Jiaxu Lou and Yifan Sun",
        "title": "Anchoring Bias in Large Language Models: An Experimental Study"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "chen2024aicognitivelybiasedexploratory",
        "author": "Nuo Chen and Jiqun Liu and Xiaoyu Dong and Qijiong Liu and Tetsuya Sakai and Xiao-Ming Wu",
        "title": "AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "liu2024decoydilemmaonlinemedical",
        "author": "Jiqun Liu and Jiangen He",
        "title": "The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "echterhoff-etal-2024-cognitive",
        "author": "Echterhoff, Jessica Maria  and\nLiu, Yao  and\nAlessa, Abeer  and\nMcAuley, Julian  and\nHe, Zexue",
        "title": "Cognitive Bias in Decision-Making with {LLM}s"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "sumita2024cognitivebiaseslargelanguage",
        "author": "Yasuaki Sumita and Koh Takeuchi and Hisashi Kashima",
        "title": "Cognitive Biases in Large Language Models: A Survey and Mitigation Experiments"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "malberg2024comprehensiveevaluationcognitivebiases",
        "author": "Simon Malberg and Roman Poletukhin and Carolin M. Schuster and Georg Groh",
        "title": "A Comprehensive Evaluation of Cognitive Biases in LLMs"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "lyu2024cognitivebiaseslargelanguage",
        "author": "Yougang Lyu and Xiaoyu Zhang and Zhaochun Ren and Maarten de Rijke",
        "title": "Cognitive Biases in Large Language Models for News Recommendation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "shayegani2023surveyvulnerabilitieslargelanguage",
        "author": "Erfan Shayegani and Md Abdullah Al Mamun and Yu Fu and Pedram Zaree and Yue Dong and Nael Abu-Ghazaleh",
        "title": "Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "wang2023largelanguagemodelsreally",
        "author": "Haoyu Wang and Guozheng Ma and Cong Yu and Ning Gui and Linrui Zhang and Zhiqi Huang and Suwei Ma and Yongzhe Chang and Sen Zhang and Li Shen and Xueqian Wang and Peilin Zhao and Dacheng Tao",
        "title": "Are Large Language Models Really Robust to Word-Level Perturbations?"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "wang2023robustnesschatgptadversarialoutofdistribution",
        "author": "Jindong Wang and Xixu Hu and Wenxin Hou and Hao Chen and Runkai Zheng and Yidong Wang and Linyi Yang and Haojun Huang and Wei Ye and Xiubo Geng and Binxin Jiao and Yue Zhang and Xing Xie",
        "title": "On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "wei2023jailbrokendoesllmsafety",
        "author": "Alexander Wei and Nika Haghtalab and Jacob Steinhardt",
        "title": "Jailbroken: How Does LLM Safety Training Fail?"
      },
      {
        "key": "liu2024autodangeneratingstealthyjailbreak",
        "author": "Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao",
        "title": "AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "jin2024guardroleplayinggeneratenaturallanguage",
        "author": "Haibo Jin and Ruoxi Chen and Andy Zhou and Yang Zhang and Haohan Wang",
        "title": "GUARD: Role-playing to Generate Natural-language Jailbreakings to Test Guideline Adherence of Large Language Models"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "zhao2024weaktostrongjailbreakinglargelanguage",
        "author": "Xuandong Zhao and Xianjun Yang and Tianyu Pang and Chao Du and Lei Li and Yu-Xiang Wang and William Yang Wang",
        "title": "Weak-to-Strong Jailbreaking on Large Language Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "boreiko2024realisticthreatmodellarge",
        "author": "Valentyn Boreiko and Alexander Panfilov and Vaclav Voracek and Matthias Hein and Jonas Geiping",
        "title": "A Realistic Threat Model for Large Language Model Jailbreaks"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "li2023evaluatinginstructionfollowingrobustnesslarge",
        "author": "Zekun Li and Baolin Peng and Pengcheng He and Xifeng Yan",
        "title": "Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection"
      },
      {
        "key": "indirect-prompt-inject",
        "author": "Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario",
        "title": "Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection"
      },
      {
        "key": "liu2024automaticuniversalpromptinjection",
        "author": "Xiaogeng Liu and Zhiyuan Yu and Yizhe Zhang and Ning Zhang and Chaowei Xiao",
        "title": "Automatic and Universal Prompt Injection Attacks against Large Language Models"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "mckenzie2024inversescalingbiggerisnt",
        "author": "Ian R. McKenzie and Alexander Lyzhov and Michael Pieler and Alicia Parrish and Aaron Mueller and Ameya Prabhu and Euan McLean and Aaron Kirtland and Alexis Ross and Alisa Liu and Andrew Gritsevskiy and Daniel Wurgaft and Derik Kauffman and Gabriel Recchia and Jiacheng Liu and Joe Cavanagh and Max Weiss and Sicong Huang and The Floating Droid and Tom Tseng and Tomasz Korbak and Xudong Shen and Yuhui Zhang and Zhengping Zhou and Najoung Kim and Samuel R. Bowman and Ethan Perez",
        "title": "Inverse Scaling: When Bigger Isn't Better"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "nestaas2024adversarialsearchengineoptimization",
        "author": "Fredrik Nestaas and Edoardo Debenedetti and Florian Tram\u00e8r",
        "title": "Adversarial Search Engine Optimization for Large Language Models"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "kumar2024manipulatinglargelanguagemodels",
        "author": "Aounon Kumar and Himabindu Lakkaraju",
        "title": "Manipulating Large Language Models to Increase Product Visibility"
      }
    ]
  }
]