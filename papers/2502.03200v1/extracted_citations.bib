@article{Anchors, 
title={Anchors: High-Precision Model-Agnostic Explanations},
volume={32}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/11491}, 
DOI={10.1609/aaai.v32i1.11491},  
number={1}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos}, 
year={2018}, 
month={Apr.} }

@article{Araucana,
title = {Why did AI get this one wrong? — Tree-based explanations of machine learning model predictions},
journal = {Artificial Intelligence in Medicine},
volume = {135},
pages = {102471},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102471},
url = {https://www.sciencedirect.com/science/article/pii/S0933365722002238},
author = {Enea Parimbelli and Tommaso Mario Buonocore and Giovanna Nicora and Wojtek Michalowski and Szymon Wilk and Riccardo Bellazzi},
keywords = {XAI, Black-box, Explanation, Local explanation, Interpretable, Explainable, Fidelity, Reliability, Post-hoc, Model agnostic, Surrogate model},
}

@book{CART,
    author = {Breiman, Leo and Friedman, Jerome and Olshen, R.A. and Stone Charles J.},
    title = {Classification and Regression Trees},
    publisher = {1st Edition, Chapman and Hall/CRC},
    year = {1984},
doi = {https://doi.org/10.1201/9781315139470}
}

@inproceedings{DT_surrogate,
author = {Mekonnen, Ephrem and Dondio, Pierpaolo and Longo, Luca},
year = {2023},
month = {11},
pages = {},
title = {Explaining Deep Learning Time Series Classification Models using a Decision Tree-Based Post-Hoc XAI Method},
note = "Publisher Copyright: {\textcopyright} 2023 CEUR-WS. All rights reserved.; Joint 1st World Conference on eXplainable Artificial Intelligence: Late-Breaking Work, Demos and Doctoral Consortium, xAI-2023: LB-D-DC ; Conference date: 26-07-2023 Through 28-07-2023",
year = "2023",
language = "English",
volume = "3554",
pages = "71--76",
journal = "CEUR Workshop Proceedings",
issn = "1613-0073",
publisher = "CEUR-WS",
doi = {https://doi.org/10.21427/9YKT-WZ47}
}

@article{Dablain2023,
author = {Dablain, Damien and Bellinger, Colin and Krawczyk, Bartosz and Aha, W. and Chawla, Nitesh},
year = {2024},
month = {01},
pages = {1-19},
title = {Understanding imbalanced data: XAI & interpretable ML framework},
volume = {113},
journal = {Machine Learning},
doi = {10.1007/s10994-023-06414-w}
}

@article{Guidotti2019,
author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
title = {A Survey of Methods for Explaining Black Box Models},
year = {2018},
issue_date = {September 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3236009},
doi = {10.1145/3236009},
abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
journal = {ACM Comput. Surv.},
month = aug,
articleno = {93},
numpages = {42},
keywords = {Open the black box, explanations, interpretability, transparent models}
}

@article{Huysmans_2011,
title = {An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models},
journal = {Decision Support Systems},
volume = {51},
number = {1},
pages = {141-154},
year = {2011},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2010.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167923610002368},
author = {Johan Huysmans and Karel Dejaeger and Christophe Mues and Jan Vanthienen and Bart Baesens},
keywords = {Data mining, Classification, Knowledge representation, Comprehensibility, Decision tables},
}

@Article{Lopes_2022,
AUTHOR = {Lopes, Pedro and Silva, Eduardo and Braga, Cristiana and Oliveira, Tiago and Rosado, Luís},
TITLE = {XAI Systems Evaluation: A Review of Human and Computer-Centred Methods},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {19},
ARTICLE-NUMBER = {9423},
URL = {https://www.mdpi.com/2076-3417/12/19/9423},
ISSN = {2076-3417},
DOI = {10.3390/app12199423}
}

@ARTICLE{Maouche2023,
  author={Maouche, Ikram and Terrissa, Labib Sadek and Benmohammed, Karima and Zerhouni, Noureddine},
  journal={IEEE Transactions on Biomedical Engineering}, 
  title={An Explainable AI Approach for Breast Cancer Metastasis Prediction Based on Clinicopathological Data}, 
  year={2023},
  volume={70},
  number={12},
  pages={3321-3329},
  keywords={Metastasis;Breast cancer;Prognostics and health management;Predictive models;Data models;Prediction algorithms;Sensitivity;Clinical diagnosis;Pathological processes;Costs;Artificial intelligence;Breast cancer;metastasis;clinicopathological;machine learning;cost sensitive;explainable artificial intelligence;Lime},
  doi={10.1109/TBME.2023.3282840}}

@INPROCEEDINGS{Mustari2023,
  author={Mustari, Ashfiqun and Ahmed, Rushmia and Tasnim, Afsara and Juthi, Jakia Sultana and Shahariar, G. M.},
  booktitle={2023 26th International Conference on Computer and Information Technology (ICCIT)}, 
  title={Explainable Contrastive and Cost-Sensitive Learning for Cervical Cancer Classification}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Visualization;Costs;Sensitivity;System performance;Self-supervised learning;Cervical cancer;Testing;Cervical Cancer;Cost-Sensitive Learning;Contrastive Learning;SIPaKMeD;XAI;LIME;GradCAM},
  doi={10.1109/ICCIT60459.2023.10441352}}

@article{RF,
author = {Breiman, Leo},
title = {Random Forests},
year = {2001},
issue_date = {October 1 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1010933404324},
doi = {10.1023/A:1010933404324},
journal = {Mach. Learn.},
month = oct,
pages = {5–32},
numpages = {28},
keywords = {regression, ensemble, classification}
}

@article{Rivera2024,
  author={Rivera-López, Rafael and Ceballos, Hector G.},
  journal={IEEE Access}, 
  title={A Differential-Evolution-Based Approach to Extract Univariate Decision Trees From Black-Box Models Using Tabular Data}, 
  year={2024},
  volume={12},
  number={},
  pages={169850-169868},
  keywords={Computational modeling;Closed box;Focusing;Artificial neural networks;Data models;Robustness;Decision trees;Data mining;Random forests;Overfitting;Agnostic model;explainable artificial intelligence;evolutionary computation;decision trees},
  doi={10.1109/ACCESS.2024.3498907}}

@inproceedings{RizzoL18Explainability, author = {Lucas Rizzo and Luca Longo}, title = {A Qualitative Investigation of the Explainability of Defeasible Argumentation and Non-Monotonic Fuzzy Reasoning}, booktitle = {Proceedings for the 26th {AIAI} Irish Conference on Artificial Intelligence and Cognitive Science Trinity College Dublin, Dublin, Ireland, December 6-7th, 2018.}, pages = {138--149}, year = {2018} }

@article{Savic2022,
title = {Tax evasion risk management using a Hybrid Unsupervised Outlier
Detection method},
journal = {Expert Systems with Applications},
volume = {193},
pages = {116409},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116409},
url =
{https://www.sciencedirect.com/science/article/pii/S0957417421016973},
author = {Miloš Savić and Jasna Atanasijević and Dušan Jakovetić and
Nataša Krejić}
}

@article{TreeSHAP,
  title={From local explanations to global understanding with explainable AI for trees},
  author={Lundberg, S.M. and Erion, G. and Chen, H. and DeGrave, A. and Prutkin, J.M. and Nair, B. and Katz, R. and Himmelfarb, J. and Bansal, N. and Lee, S.},
  journal={Nature Machine Intelligence},
  volume={2},
  number={1},
  pages={2522-5839},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{ali,
title = {Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence},
journal = {Information Fusion},
volume = {99},
pages = {101805},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101805},
author = {Sajid Ali and Tamer Abuhmed and Shaker El-Sappagh and Khan Muhammad and Jose M. Alonso-Moral and Roberto Confalonieri and Riccardo Guidotti and Javier {Del Ser} and Natalia Díaz-Rodríguez and Francisco Herrera}}

@InProceedings{alime,
author="Shankaranarayana, Sharath M.
and Runje, Davor",
editor="Yin, Hujun
and Camacho, David
and Tino, Peter
and Tall{\'o}n-Ballesteros, Antonio J.
and Menezes, Ronaldo
and Allmendinger, Richard",
title="ALIME: Autoencoder Based Approach for Local Interpretability",
booktitle="Intelligent Data Engineering and Automated Learning -- IDEAL 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="454--463",
isbn="978-3-030-33607-3",
url={https://api.semanticscholar.org/CorpusID:202539758}
}

@article{c45,
author = {Zhou, Zhi-Hua and Jiang, Yuan},
year = {2003},
month = {04},
pages = {37-42},
title = {Medical Diagnosis with C4.5 Rule Preceded by Artificial Neural Network Ensemble},
volume = {7},
journal = {IEEE transactions on information technology in biomedicine : a publication of the IEEE Engineering in Medicine and Biology Society},
doi = {10.1109/TITB.2003.808498}
}

@article{darpa, 
title={DARPA’s Explainable Artificial Intelligence (XAI) Program}, 
volume={40}, 
url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2850}, 
DOI={10.1609/aimag.v40i2.2850},
number={2}, 
journal={AI Magazine}, 
author={Gunning, David and Aha, David}, 
year={2019}, 
month={Jun.}, 
pages={44-58} }

@article{dragoni_2020,
title = {Explainable AI meets persuasiveness: Translating reasoning results into behavioral change advice},
journal = {Artificial Intelligence in Medicine},
volume = {105},
pages = {101840},
year = {2020},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2020.101840},
url = {https://www.sciencedirect.com/science/article/pii/S0933365719310140},
author = {Mauro Dragoni and Ivan Donadello and Claudio Eccher},
keywords = {Explainable AI, Explainable reasoning, Natural Language Generation, MHealth, Ontologies}
}

@article{freitas,
author = {Freitas, Alex A.},
title = {Comprehensible classification models: a position paper},
year = {2014},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/2594473.2594475},
doi = {10.1145/2594473.2594475},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {1–10},
numpages = {10}
}

@article{giulia_2020,
author = {Vilone, Giulia and Rizzo, Lucas and Longo, Luca},
year = {2020},
month = {12},
pages = {},
title = {A comparative analysis of rule-based, model-agnostic methods for explainable artificial intelligence},
journal = {Proceedings for the 28th AIAI Irish Conference on Artificial Intelligence and Cognitive Science, Dublin, Ireland},
pages = {85-96},
volume = {2771},
year = {2020},
month = {December},
doi = {10.21427/z4x3-3f86}
}

@ARTICLE{giulia_2021,
AUTHOR={Vilone, Giulia  and Longo, Luca },
TITLE={A Quantitative Evaluation of Global, Rule-Based Explanations of Post-Hoc, Model Agnostic Methods},
JOURNAL={Frontiers in Artificial Intelligence},
VOLUME={4},
YEAR={2021},
DOI={10.3389/frai.2021.717899},
ISSN={2624-8212}}

@inproceedings{giulia_test,
title = "Development of a Human-Centred Psychometric Test for the Evaluation of Explanations Produced by XAI Methods",
keywords = "Explainable Artificial Intelligence, Human-centred evaluation, Psychometrics",
author = "Giulia Vilone and Luca Longo",
year = "2023",
doi = "10.1007/978-3-031-44070-0_11",
language = "English",
isbn = "9783031440694",
series = "Communications in Computer and Information Science",
publisher = "Springer Science and Business Media Deutschland GmbH",
pages = "205--232",
editor = "Luca Longo",
booktitle = "Explainable Artificial Intelligence - 1st World Conference, xAI 2023, Proceedings",
address = "Germany",
}

@article{kopanja,
author = {Kopanja, Marija and Hačko, Stefan and Brdar, Sanja and Savić, Miloš},
title = {Cost-sensitive tree SHAP for explaining cost-sensitive tree-based models},
journal = {Computational Intelligence},
volume = {40},
number = {3},
pages = {e12651},
keywords = {cost-sensitive learning, ensemble learning, explainable artificial intelligence, tree-based models, tree SHAP},
doi = {https://doi.org/10.1111/coin.12651},
year = {2024}
}

@inproceedings{kopanja2023,
  title={Uncovering Decision-making Process of Cost-sensitive Tree-based Classifiers using the Adaptation of TreeSHAP.},
  author={Kopanja, Marija and Brdar, Sanja and Hacko, Stefan},
  booktitle={"Joint Proceedings of the xAI-2023 Late-breaking Work, Demos and Doctoral Consortium
co-located with the 1st World Conference on eXplainable Artificial Intelligence (xAI-2023)"},
  pages={95--100},
  year={2023},
journal = "CEUR Workshop Proceedings",
}

@inproceedings{lime,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/2939672.2939778},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {interpretable machine learning, interpretability, explaining machine learning, black box classifier},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{refne,
author = {Zhou, Zhi-Hua and Jiang, Yuan and Chen, Shi-Fu},
title = {Extracting symbolic rules from trained neural network ensembles},
year = {2003},
issue_date = {January 2003},
publisher = {IOS Press},
address = {NLD},
volume = {16},
number = {1},
issn = {0921-7126},
journal = {AI Commun.},
month = jan,
pages = {3–15},
numpages = {13},
keywords = {rule extraction, neural network ensembles, machine learning, comprehensibility, Neural networks}
}

@misc{ribeiro2016,
      title={Model-Agnostic Interpretability of Machine Learning}, 
      author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
      year={2016},
      eprint={1606.05386},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1606.05386}, 
}

@article{rxren,
author = {Augasta, M.Gethsiyal and Kathirvalavakumar, T.},
year = {2011},
month = {04},
pages = {},
title = {Reverse Engineering the Neural Networks for Rule Extraction in Classification Problems},
journal = {Neural Processing Letters},
doi = {10.1007/s11063-011-9207-8}
}

@incollection{shap,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, S.M. and Lee, S.},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@article{svm_rules,
title = {Comprehensible credit scoring models using rule extraction from support vector machines},
journal = {European Journal of Operational Research},
volume = {183},
number = {3},
pages = {1466-1476},
year = {2007},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2006.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S0377221706011878},
author = {David Martens and Bart Baesens and Tony {Van Gestel} and Jan Vanthienen},
keywords = {Credit scoring, Classification, Support vector machine, Rule extraction},
}

@misc{tree_alime,
      title={Using Decision Tree as Local Interpretable Model in Autoencoder-based LIME}, 
      author={Niloofar Ranjbar and Reza Safabakhsh},
      year={2022},
      eprint={2204.03321},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
url={https://arxiv.org/abs/2204.03321}
}

@incollection{trepan,
title = {Using Sampling and Queries to Extract Rules from Trained Neural Networks},
editor = {William W. Cohen and Haym Hirsh},
booktitle = {Machine Learning Proceedings 1994},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {37-45},
year = {1994},
isbn = {978-1-55860-335-6},
doi = {https://doi.org/10.1016/B978-1-55860-335-6.50013-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558603356500131},
author = {Mark W. Craven and Jude W. Shavlik},
}

@misc{vilone_review,
      title={Explainable Artificial Intelligence: a Systematic Review}, 
      author={Giulia Vilone and Luca Longo},
      year={2020},
      eprint={2006.00093},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2006.00093}, 
}

