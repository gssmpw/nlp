%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{flushend}
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{tikz,xcolor}
\definecolor{darkgreen}{rgb}{0.0, 0.5, 0.0} % Define a custom dark green

\usetikzlibrary{arrows.meta, positioning}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

\input{math_commands.tex}


% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

\usepackage{bbm}
\usepackage{mathrsfs} 

\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{graphbox}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{comment}

%\usepackage{minted}
%\usepackage{subfigure}
\usepackage{enumitem}


\DeclareMathOperator{\diag}{diag}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

% Macros
\newcommand{\mself}{\mP^{\text{self}}}
\newcommand{\mcross}{\mP^{\text{cross}}}

\newcommand{\sself}{s^{\text{self}}}
\newcommand{\scross}{s^{\text{cross}}}

\newcommand{\kle}{\text{KLE}}
\newcommand{\se}{\text{SE}}
\newcommand{\mpd}{\text{MPD}}
\newcommand{\eigv}{\text{EigV}}
\newcommand{\ecc}{\text{Ecc}}

\newcommand{\entailm}{\texttt{EntailmentMatrix}}

\newcommand{\tar}{\text{t}}
\newcommand{\ver}{\text{v}}

\newcommand{\llamatwothirteen}{\texttt{Llama-2-13b-chat}}
\newcommand{\llamathreeseventy}{\texttt{Llama-3-70B-Instruct}}
\newcommand{\llamatwoseventy}{\texttt{Llama-2-70b-chat-hf}}
\newcommand{\merlinite}{\texttt{merlinite-7b}}
\newcommand{\mixtral}{\texttt{Mixtral-8x7B-Instruct-v0.1}}


\newcommand{\todoblue}[1]{{{\textcolor{blue}{[TODO: #1]}}}}

\newcommand{\yx}[1]{{{\textcolor{blue}{[YX: #1]}}}}
\newcommand{\kg}[1]{{{\textcolor{teal}{[KG: #1]}}}}
\newcommand{\ym}[1]{{{\textcolor{red}{[YM: #1]}}}}
% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\onecolumn
%\icmltitle{Beyond Self-Consistency: Black-box Hallucination Detection with Weak Verifiers}
\icmltitle{Verify when Uncertain: Beyond Self-Consistency\\ in Black Box Hallucination Detection}
% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.

\begin{icmlauthorlist}
\icmlauthor{Yihao Xue}{ucla,intern}
\icmlauthor{Kristjan Greenewald}{mitibm}
\icmlauthor{Youssef Mroueh}{ibm}
\icmlauthor{Baharan Mirzasoleiman}{ucla}
\end{icmlauthorlist}

\icmlaffiliation{ucla}{Department of Computer Science, University of California, Los Angeles}
\icmlaffiliation{ibm}{IBM Research}
\icmlaffiliation{mitibm}{MIT-IBM Watson AI Lab}
\icmlaffiliation{intern}{Work performed while interning at MIT-IBM Watson AI Lab}

\icmlcorrespondingauthor{Yihao Xue}{yihaoxue@g.ucla.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Large Language Models (LLMs) suffer from hallucination problems, which hinder their reliability in sensitive applications. In the black-box setting, several self-consistency-based techniques have been proposed for hallucination detection. We empirically study these techniques and show that they achieve performance close to that of a supervised (still black-box) oracle, suggesting little room for improvement within this paradigm. To address this limitation, we explore cross-model consistency checking between the target model and an additional verifier LLM. With this extra information, we observe improved oracle performance compared to purely self-consistency-based methods. We then propose a budget-friendly, two-stage detection algorithm that calls the verifier model only for a subset of cases. It dynamically switches between self-consistency and cross-consistency based on an uncertainty interval of the self-consistency classifier. We provide a geometric interpretation of consistency-based hallucination detection methods through the lens of kernel mean embeddings, offering deeper theoretical insights. Extensive experiments show that this approach maintains high detection performance while significantly reducing computational cost.
\looseness=-1

% Large Language Models (LLMs) suffer from hallucination problems which hinder their reliability in sensitive applications. In the black-box setting, several techniques based on self-consistency of the LLM have been proposed for hallucination detection. We empirically study in this paper those unsupervised  techniques and show that they reach the performance of a supervised (still black-box) oracle consisting of a graph neural network trained on the entailment data. Motivated by this observation, we explore the oracle performance of a hallucination detector that uses, in addition to the self-consistency, the cross-consistency of the LLM with a verifier model. With this extra information, we observe improved hallucination detection as compared to purely self-consistency based methods. We then propose a budget friendly unsupervised two stage detection algorithm that only calls the verifier model a percentage of the time, otherwise saving the associated computation. It achieves this by switching between relying on self-consistency only and cross-consistency, depending upon an uncertainty interval of the self-consistency based classifier. The two stage algorithm maintains high detection performance while reducing substantially the computational complexity. We finally give a geometrical interpretation of consistency methods for hallucination detection based on \emph{kernel mean embeddings}. This point of view  allows us to derive a simple analysis for the proposed method. 
       

%The abstract paragraph should be indented 1/2~inch (3~picas) on both left and
%right-hand margins. Use 10~point type, with a vertical spacing of 11~points.
%The word \textsc{Abstract} must be centered, in small caps, and in point size 12. Two
%line spaces precede the abstract. The abstract must be limited to one
%paragraph.
\end{abstract}

\input{method}
\input{theory}
\input{experiment}
\input{conclusion}






% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\bibliography{reference}
\bibliographystyle{icml2025}

\flushcolsend
\newpage

\onecolumn
\appendix
\section{Proof of Theorem \ref{thm:ROC}}
\label{app:ROC}
%Setup: 
% \begin{itemize}
%     \item $n_{neg}$ i.i.d. samples from the non-hallucinating distribution and $n_{pos}$ i.i.d. samples from the hallucinating distribution. 
%     \item Sets of thresholds $\mathcal{T}_1 = \{t^1_j\}$ and $\mathcal{T}_2 = \{t^2_k\}$ for stages 1 and 2 respectively. 
% \end{itemize}
A classifier $C$ maps points to binary predictions. The $p_D(C)$ is the probability that positive samples are mapped to 1, and $p_{FA}(C)$ is the probability that negative samples are mapped to 1. Hence
\[
\hat{p}_D = \frac{1}{n_{neg}} \sum_{i} X^{neg}_i
\]
\[
\hat{p}_{FA} = \frac{1}{n_{pos}} \sum_{i} X^{pos}_i
\]
where $X^{neg}_i$, $X^{pos}_i$ are the labels of the positive and negative samples, respectively. These are each i.i.d. Bernoulli random variables. 

The Hoeffding inequality can be directly applied: %(see wikipedia):
\[
Pr(|\hat{p}_D - p_D| \geq \epsilon) \leq 2 \exp\left(-2{\epsilon^2}{n_{neg}}\right)
\]
and similarly for $p_{FA}$. Now, we want a uniform bound that holds simultaneously for all possible threshold combinations. The number of these are $|\mathcal{T}_1| |\mathcal{T}_2|$.

Define events $\mathcal{E}^D_{j,k}$ and $\mathcal{E}^{FA}_{j,k}$ to be the events that the estimated probabilities under the $j$th, $k$th threshold are within $\epsilon$, i.e.
\begin{align*}
\mathcal{E}^D_{j,k}&:= |\hat{p}_D(t^1_j,t^2_k) - p_D(t^1_j,t^2_k)| \leq \epsilon\\
\mathcal{E}^{FA}_{j,k}&:= |\hat{p}_{FA}(t^1_j,t^2_k) - p_{FA}(t^1_j,t^2_k)| \leq \epsilon.
\end{align*}
Let's use the union bound across the $j,k$, we don't need it across FA/D, since these are independent. 

\begin{align*}
&Pr\left(\cap_{j=1}^{|\mathcal{T}_1|}\cap_{k=1}^{|\mathcal{T}_2|} (\mathcal{E}^D_{j,k}\cap \mathcal{E}^{FA}_{j,k})\right) 
\geq \left(1 - 2|\mathcal{T}_1||\mathcal{T}_2| \exp\left(-{2\epsilon^2}{n_{neg}}\right)\right)\left(1 - 2|\mathcal{T}_1||\mathcal{T}_2| \exp\left(-{2\epsilon^2}{n_{pos}}\right)\right) \\
%\geq 1 - 2|\mathcal{T}_1| |\mathcal{T}_2|\left(\exp\left(-{2\epsilon^2}{n_{neg}}\right) + \exp\left(-{2\epsilon^2}{n_{pos}}\right)\right)\\
%&=1 - 2 \left(\exp\left(\log(|\mathcal{T}_1|) + \log(|\mathcal{T}_2|)-{2\epsilon^2}{n_{neg}}\right) + \exp\left(\log(|\mathcal{T}_1|) + \log(|\mathcal{T}_2|)-{2\epsilon^2}{n_{pos}}\right)\right)
\end{align*}
In other words, 
\[
\max_{j,k} \max(|\hat{p}_D(t^1_j,t^2_k) - p_D(t^1_j,t^2_k)|, |\hat{p}_{FA}(t^1_j,t^2_k) - p_{FA}(t^1_j,t^2_k)|) \leq \sqrt{\frac{\log(|\mathcal{T}_1|) + \log(|\mathcal{T}_2|)}{\min(n_{neg}, n_{pos})}},
\]
with probability at least $\left(1 - \frac{2}{|\mathcal{T}_1| |\mathcal{T}_2|}\right)^2$. Since this holds simultaneously for all threshold combinations, if we take the training-convex-hull area, the test AUC from using the frontier of that hull will be at most $2\epsilon $ smaller. 


\section{Kernel Mean Embedding View of Consistency Methods for Hallucination Detection}

In what follows, we suppose that we have also access to  the ground the truth $\pi^*(y|x)$ and observe $\frac{1}{n^*}\sum_{i=1}^{n^*} \delta_{y^*_i}, y^*_i \sim \pi^*(.|x)$.

\begin{proposition}
The optimal weight $\lambda$ for combining self and cross consistencies to approximates the consistency of the target with the ground truth satisfies:
\[ \min_{\lambda \in [0,1]}| \langle\mu_t, \lambda \mu_t + (1-\lambda) \mu_v\rangle - \langle\mu_t,\mu^*\rangle | \leq \min_{\lambda \in [0,1]} \sqrt{2(1-\langle\mu_*, \lambda \mu_t + (1-\lambda) \mu_v\rangle )}, \]
Hence it is enough to solve:
$ \max_{\lambda \in [0,1]} \langle\mu_*, \lambda \mu_t + (1-\lambda) \mu_v\rangle$. Using an entropic regularization of this objective \[ \max_{\omega_t,\omega_v \in [0,1],\omega_t+\omega_v=1} \langle\mu_*, \omega_t \mu_t + \omega_v \mu_v\rangle - \varepsilon (\sum_{j\in \{t,v\}} \omega_j (\log \omega_j-1) ,\] we obtain $\lambda^*= \frac{\exp(\frac{\langle \mu_t, \mu^*\rangle}{\varepsilon})}{\exp(\frac{\langle \mu_t, \mu^*\rangle}{\varepsilon})+ \exp(\frac{\langle \mu_v, \mu^*\rangle}{\varepsilon}) }.$ 
\end{proposition}

\begin{align*}
| \langle\mu_t, \lambda \mu_t + (1-\lambda) \mu_v\rangle - \langle\mu_t,\mu^*\rangle | & = |\langle \mu_t, \mu^*-\left(\lambda\mu_t + (1-\lambda) \mu_v\right) \rangle|\\
& \leq \| \mu_t\| \|\mu^*- (\lambda \mu_t + (1-\lambda) \mu_v ) \|\\
& \leq \sqrt{2(1-\langle\mu_*, \lambda \mu_t + (1-\lambda) \mu_v\rangle )},
\end{align*}
last inequality follows from $\|\mu^*\|\leq 1$, $\|\mu_t\|\leq 1$, $\|\mu_v\|\leq 1$
and $\| \lambda \mu_t + (1-\lambda) \mu_v\rangle )\| \leq 1$ (since the kernel $\mathcal{E}$ is bounded by 1). 

Hence to minimize this inequality it is enough to solve for :
\[ \max_{\lambda \in [0,1]} \langle\mu_*, \lambda \mu_t + (1-\lambda) \mu_v\rangle  \]
we can add to this an entropy regularizer 
\[ \max_{\omega_t,\omega_v \in [0,1],\omega_t+\omega_v=1} \langle\mu_*, \omega_t \mu_t + \omega_v \mu_v\rangle - \varepsilon (\sum_{j\in \{t,v\}} \omega_j (\log \omega_j-1) \]
which gives us that:
$\lambda= \omega_t = \frac{\exp(\frac{\langle \mu_t, \mu^*\rangle}{\varepsilon})}{\exp(\frac{\langle \mu_t, \mu^*\rangle}{\varepsilon})+ \exp(\frac{\langle \mu_v, \mu^*\rangle}{\varepsilon}) }$ and $\omega_v=1-\lambda =\frac{\exp(\frac{\langle \mu_v, \mu^*\rangle}{\varepsilon})}{\exp(\frac{\langle \mu_t, \mu^*\rangle}{\varepsilon})+ \exp(\frac{\langle \mu_v, \mu^*\rangle}{\varepsilon}) } $.


\iffalse

Let $f^*$ be the optimal hallucination detector for a actor model $\pi_a$ and we are given $\pi_{v}$ the verifier. We assume we are given the dataset $( \mu^a_{\ell},\mu^v_{\ell}, h_{\ell})$, corresponding to different prompts $x_{\ell},\ell=1\dots N$, and $h_{\ell} \in \{\pm 1\}$ corresponds to hallucination and not hallucination. 
Note the distribution $\nu= \frac{1}{N} \sum_{i=1}^N \delta_{( \mu^a_{\ell},\mu^v_{\ell}, h_{\ell})}$.

We propose to use the following kernel on the space of distribution between mean embeddings: 

\begin{align*}
 \mathcal{K} ((\mu_a,\mu_v), (\nu_a,\nu_v)) &= \langle m_{\mu_a} , m_{\nu_a}  \rangle_{\mathcal{H}_{k}} + \langle \mu_a \otimes \nu_a ,\mu_v\otimes \nu_v \rangle_{\mathcal{H}_{k}}\\
 &= s(\mu_a,\nu_a) + s(\mu_a,\mu_v)s(\nu_a,\nu_v)
 \end{align*}

In particular we have: 
\[\mathcal{K} ((\mu_a,\mu_v), (\mu_a,\mu_v)) = s(\mu_a,\mu_a) + s(\mu_a,\mu_v)^2\]

Using the distributional kernel regression in mean embedding spaces we can state the problem as follows: 

\[ \min_{f \in \mathcal{H}_{\mathcal{K}}}  \mathbb{E}_{(\mu_a,\mu_v,h)\sim\nu} (\left( 1- hf(m_{\mu_a},m_{\mu_v}) \right)_+ + \lambda ||f||^2_{\mathcal{H}_{K}},\]
By the representer theorem we have: 
\begin{align*}
f^*((m_{\mu_a},m_{\mu_v}))& = \sum_{i=1}^N \alpha_{\ell} h_{\ell} \mathcal{K} ((m_{\mu_a},m_{\mu_v}) , (
m_{\mu^a_{\ell}},m_{\mu^v_{\ell}}))\\
&= \sum_{i=1}^N \alpha_{\ell} h_{\ell} \left(s(\mu^a,\mu^a_{\ell}) + s(\mu^a,\mu^v )s(\mu^a_{\ell},\mu^v_{\ell}) \right)
\end{align*}
where $\alpha_i$ are positive and bounded. 


Can we bound using the self consistency and cross consistency with thresholds by the performance of the best supervised learning $f^*$ and other terms? 

\[ \mathbb{P}(h \text{sign}(\mathcal{K}((\mu_a,\mu_v)),(\mu_a,\mu_v) - \tau) <0) \leq \mathbb{P}( hf^*(m_{\mu_a},m_{\mu_v}) <0) + \mathbb{P} ((h \text{sign}(\mathcal{K}((\mu_a,\mu_v)),(\mu_a,\mu_v) - \tau) < hf^*(m_{\mu_a},m_{\mu_v})) \]

TBC

Assumptions
\subsection{Correctness of Algorithm }


\textbf{potential formalization 1:}

assume $\sself+\scross+\xi=\hat{h}$; 

or $ \hat{h} = B(p), p=f(\sself,\scross) $

write down $corr(\hat{h}, \sself)$ and see under what assumption we can show that $corr(\hat{h}, \sself)$ is guaranteed to be high when $\sself$ is in a certain range

similar for $corr(\hat{h}, \scross)$

\textbf{potential formalization 2:}

1. high $\sself$. assume unique correct answer

2. intermediate $\sself$. assume the verifier is not too bad

3. low $\sself$. assume the probability of confident incorrect answer is very low.

% \yx{Still not sure exactly what kind of theory we can develop. It seems quite challenging to find a theoretical concept that can be connected to the exact algorithm we are using. }

% \yx{However, something that might help illustrate why cross-model consistency can potentially be beneficial is this: when model A is hallucinating, the probability that it has high self-consistency and that model B happens to agree with it (i.e., high cross-model consistency) is low. However, we need to find a good way to formalize it and connect it to some existing concept so that we can establish a natural assumption that leads to such a conclusion. If this can be done, then at least we can provide some insights, although it may not directly lead to a statement about our algorithm. }







\subsection{Statistical Analysis: ROC generalization}
\paragraph{Opportunities for theory}
\begin{itemize}
\item Simple generalization bound on how much PFA/PD can shift from picking thresholds for the hatPFA/hatPD from a validation set of size $n$. (Sec 3.1 below)
\item KL divergence between cross/self distributions - think what this may be useful for?
%\item Intuition-building assumption set for distributions on semantic space, leading to propositions saying that the jump in entropy/mean entailment/whatever by going from self-only to self-cross is larger when at least one model is hallucinating. Perhaps saying that if $X\%$ of the mass is on the true semantic atom, then the entropy increase is bounded by something. 
\end{itemize}

\kristjan{multistage version:
Presumably $s_{self}$ and $s_{cross}$ are pretty dependent
So while the weights you have make sense, you could imagine that the weights could be massaged (if want to talk about partial linear dependence then this is easy) so that you get
an w weight that is as large as possible without changing the result (much). I.e.
$max w s.t. (w s_{self} + (1-w) s_{cross}) \approx (\omega s_{self} + (1-\omega) s_{cross})$
Now, imagine that this $w > (1-w)$. We also know that $0<= s_
{self}, s_{cross} <=1$.
Suppose your current analysis implies a threshold $\tau$, i.e. you say "hallucinating" if $\omega s_{self} + (1-\omega) s_{cross}$. Then,
if $w s_{self} < \tau - (1-w)$, we can declare "no hallucination" without checking s_{cross}, and
if $w s_{self} > \tau$ , we can declare "hallucination" without checking s_{cross}.
This can be viewed as the first stage of our algorithm.
The second stage would most naturally be checking if $(w s_{self} + (1-w) s_{cross}) >< \tau$.
We only look at $s_{cross}$, but this is mostly laziness on our part (don't want to optimize $w$). We can just say this, or further consider that if we are passed to the second stage, then $s_{self}$ is "range-bound" and probably won't vary much. Doing the reverse process of the w above (via approximate linear dependence again), can do
$min v s.t. (v s_{self} + (1-v) s_{cross}) \approx (\omega s_{self} + (1-\omega) s_{cross})$
Now, you have this $v s_{self} + (1-v) s_{cross} <> \tau$ thing where $v$ is small and $s_{self} \approx  \tau/w$ where w is closish to 1. Pretending this approximation is equality yields
$(1-v) s_{cross} <> \tau - v \tau/ w$,
which matches our second stage.

}

\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
% \appendix
% \onecolumn
\input{appendix}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
