[
  {
    "index": 0,
    "papers": [
      {
        "key": "duan2024shifting",
        "author": "Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Zavalny, Alex and Wang, Chenan and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi",
        "title": "Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models"
      },
      {
        "key": "varshney2023stitch",
        "author": "Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong",
        "title": "A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "yin2024characterizing",
        "author": "Yin, Fan and Srinivasa, Jayanth and Chang, Kai-Wei",
        "title": "Characterizing truthfulness in large language model generations with local intrinsic dimension"
      },
      {
        "key": "zou2023representation",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others",
        "title": "Representation engineering: A top-down approach to ai transparency"
      },
      {
        "key": "agrawal2023language",
        "author": "Agrawal, Ayush and Suzgun, Mirac and Mackey, Lester and Kalai, Adam Tauman",
        "title": "Do Language Models Know When They're Hallucinating References?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "manakul2023selfcheckgpt",
        "author": "Manakul, Potsawee and Liusie, Adian and Gales, Mark JF",
        "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"
      },
      {
        "key": "farquhar2024detecting",
        "author": "Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin",
        "title": "Detecting hallucinations in large language models using semantic entropy"
      },
      {
        "key": "kuhn2023semantic",
        "author": "Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation"
      },
      {
        "key": "lin2023generating",
        "author": "Lin, Zhen and Trivedi, Shubhendu and Sun, Jimeng",
        "title": "Generating with confidence: Uncertainty quantification for black-box large language models"
      },
      {
        "key": "nikitin2024kernel",
        "author": "Nikitin, Alexander and Kossen, Jannik and Gal, Yarin and Marttinen, Pekka",
        "title": "Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "manakul2023selfcheckgpt",
        "author": "Manakul, Potsawee and Liusie, Adian and Gales, Mark JF",
        "title": "Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models"
      },
      {
        "key": "kuhn2023semantic",
        "author": "Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian",
        "title": "Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "SAC3_hallucination_detection_black_box_lms",
        "author": "Zhang, Jiaxin and Li, Zhuohang and Das, Kamalika and Malin, Bradley and Kumar, Sricharan",
        "title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "SAC3_hallucination_detection_black_box_lms",
        "author": "Zhang, Jiaxin and Li, Zhuohang and Das, Kamalika and Malin, Bradley and Kumar, Sricharan",
        "title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mielke2022reducing",
        "author": "Mielke, Sabrina J and Szlam, Arthur and Dinan, Emily and Boureau, Y-Lan",
        "title": "Reducing conversational agents\u2019 overconfidence through linguistic calibration"
      },
      {
        "key": "tian2023just",
        "author": "Tian, Katherine and Mitchell, Eric and Zhou, Allan and Sharma, Archit and Rafailov, Rafael and Yao, Huaxiu and Finn, Chelsea and Manning, Christopher D",
        "title": "Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback"
      },
      {
        "key": "kadavath2022language",
        "author": "Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others",
        "title": "Language models (mostly) know what they know"
      },
      {
        "key": "lin2022teaching",
        "author": "Lin, Stephanie and Hilton, Jacob and Evans, Owain",
        "title": "Teaching models to express their uncertainty in words"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "xiong2023can",
        "author": "Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and Li, Yifei and Fu, Jie and He, Junxian and Hooi, Bryan",
        "title": "Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "calibrated_language_models_must_hallucinate",
        "author": "Kalai, Adam Tauman and Vempala, Santosh S.",
        "title": "Calibrated Language Models Must Hallucinate"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "asai2023self",
        "author": "Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh",
        "title": "Self-rag: Learning to retrieve, generate, and critique through self-reflection"
      },
      {
        "key": "gao2022rarr",
        "author": "Gao, Luyu and Dai, Zhuyun and Pasupat, Panupong and Chen, Anthony and Chaganty, Arun Tejasvi and Fan, Yicheng and Zhao, Vincent Y and Lao, Ni and Lee, Hongrae and Juan, Da-Cheng and others",
        "title": "Rarr: Researching and revising what language models say, using language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "li2024inference",
        "author": "Li, Kenneth and Patel, Oam and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Inference-time intervention: Eliciting truthful answers from a language model"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "lee2022factuality",
        "author": "Lee, Nayeon and Ping, Wei and Xu, Peng and Patwary, Mostofa and Fung, Pascale N and Shoeybi, Mohammad and Catanzaro, Bryan",
        "title": "Factuality enhanced language models for open-ended text generation"
      },
      {
        "key": "tian2023fine",
        "author": "Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea",
        "title": "Fine-tuning language models for factuality"
      }
    ]
  }
]