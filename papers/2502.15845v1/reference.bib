@article{Muandet_2017,
   title={Kernel Mean Embedding of Distributions: A Review and Beyond},
   volume={10},
   ISSN={1935-8245},
   url={http://dx.doi.org/10.1561/2200000060},
   DOI={10.1561/2200000060},
   number={1–2},
   journal={Foundations and Trends® in Machine Learning},
   publisher={Now Publishers},
   author={Muandet, Krikamol and Fukumizu, Kenji and Sriperumbudur, Bharath and Schölkopf, Bernhard},
   year={2017},
   pages={1–141} }

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}
@article{kossen2024semantic,
  title={Semantic entropy probes: Robust and cheap hallucination detection in llms},
  author={Kossen, Jannik and Han, Jiatong and Razzak, Muhammed and Schut, Lisa and Malik, Shreshth and Gal, Yarin},
  journal={arXiv preprint arXiv:2406.15927},
  year={2024}
}

@article{farquhar2024detecting,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  number={8017},
  pages={625--630},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{lin2023generating,
  title={Generating with confidence: Uncertainty quantification for black-box large language models},
  author={Lin, Zhen and Trivedi, Shubhendu and Sun, Jimeng},
  journal={arXiv preprint arXiv:2305.19187},
  year={2023}
}

@article{nikitin2024kernel,
  title={Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities},
  author={Nikitin, Alexander and Kossen, Jannik and Gal, Yarin and Marttinen, Pekka},
  journal={arXiv preprint arXiv:2405.20003},
  year={2024}
}

@article{sansford2024grapheval,
  title={GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework},
  author={Sansford, Hannah and Richardson, Nicholas and Maretic, Hermina Petric and Saada, Juba Nait},
  journal={arXiv preprint arXiv:2407.10793},
  year={2024}
}



@article{manakul2023selfcheckgpt,
  title={Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models},
  author={Manakul, Potsawee and Liusie, Adian and Gales, Mark JF},
  journal={arXiv preprint arXiv:2303.08896},
  year={2023}
}

@article{kuhn2023semantic,
  title={Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation},
  author={Kuhn, Lorenz and Gal, Yarin and Farquhar, Sebastian},
  journal={arXiv preprint arXiv:2302.09664},
  year={2023}
}


@article{rethinking_uncertainty_estimation_nlg,
  title={Rethinking Uncertainty Estimation in Natural Language Generation},
  author={Aichberger, Lukas and Schweighofer, Kajetan and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2412.15176},
  year={2024},
  url={https://arxiv.org/abs/2412.15176}
}

@article{mitigating_llm_hallucinations_conformal_abstention,
  title={Mitigating LLM Hallucinations via Conformal Abstention},
  author={Lin, Zhen and Trivedi, Shubhendu and Sun, Jimeng},
  journal={arXiv preprint arXiv:2405.01563},
  year={2024},
  url={https://arxiv.org/abs/2405.01563}
}

@article{SAC3_hallucination_detection_black_box_lms,
  title={SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency},
  author={Zhang, Jiaxin and Li, Zhuohang and Das, Kamalika and Malin, Bradley and Kumar, Sricharan},
  journal={arXiv preprint arXiv:2311.01740},
  year={2023},
  url={https://arxiv.org/abs/2311.01740}
}

@article{limits_language_generation_hallucination_mode_collapse,
  title={On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse},
  author={Nikitin, Alexander and Kossen, Jannik and Gal, Yarin and Marttinen, Pekka},
  journal={arXiv preprint arXiv:2405.20003},
  year={2024},
  url={https://arxiv.org/abs/2405.20003}
}

@article{kernel_language_entropy_llms_semantic_similarities,
  title={Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities},
  author={Nikitin, Alexander and Kossen, Jannik and Gal, Yarin and Marttinen, Pekka},
  journal={arXiv preprint arXiv:2305.19187},
  year={2023},
  url={https://arxiv.org/abs/2305.19187}
}

@article{generating_with_confidence_uncertainty_black_box_llms,
  title={Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models},
  author={Lin, Zhen and Trivedi, Shubhendu and Sun, Jimeng},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023},
  url={https://arxiv.org/abs/2310.01405}
}

@article{fine_tuning_llms_new_knowledge_hallucinations,
  title={Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?},
  author={Gekhman, Zorik and Yona, Gal and Aharoni, Roee and Eyal, Matan and Feder, Amir and Reichart, Roi and Herzig, Jonathan},
  journal={arXiv preprint arXiv:2405.05904},
  year={2024},
  note={Accepted as a long paper at EMNLP 2024},
  url={https://arxiv.org/abs/2405.05904}
}

@article{calibrated_language_models_must_hallucinate,
  title={Calibrated Language Models Must Hallucinate},
  author={Kalai, Adam Tauman and Vempala, Santosh S.},
  journal={Proceedings of the 56th Annual ACM Symposium on Theory of Computing (STOC)},
  year={2024},
  url={https://arxiv.org/abs/2311.14648}
}

@article{detecting_hallucinations_llms_semantic_entropy,
  title={Detecting hallucinations in large language models using semantic entropy},
  author={Farquhar, Sebastian and Kossen, Jannik and Kuhn, Lorenz and Gal, Yarin},
  journal={Nature},
  volume={630},
  pages={123--130},
  year={2024},
  doi={10.1038/s41586-024-07421-0},
  url={https://www.nature.com/articles/s41586-024-07421-0}
}



@article{2017arXivtriviaqa,
       author = {{Joshi}, Mandar and {Choi}, Eunsol and {Weld},
                 Daniel and {Zettlemoyer}, Luke},
        title = "{triviaqa: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}",
      journal = {arXiv e-prints},
         year = 2017,
          eid = {arXiv:1705.03551},
        pages = {arXiv:1705.03551},
archivePrefix = {arXiv},
       eprint = {1705.03551},
}

@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    editor = "Su, Jian  and
      Duh, Kevin  and
      Carreras, Xavier",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D16-1264",
    doi = "10.18653/v1/D16-1264",
    pages = "2383--2392",
    eprint={1606.05250},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
}


@article{47761,
title	= {Natural Questions: a Benchmark for Question Answering Research},
author	= {Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Matthew Kelcey and Jacob Devlin and Kenton Lee and Kristina N. Toutanova and Llion Jones and Ming-Wei Chang and Andrew Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov},
year	= {2019},
journal	= {Transactions of the Association of Computational Linguistics}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{mundler2023self,
  title={Self-contradictory hallucinations of large language models: Evaluation, detection and mitigation},
  author={M{\"u}ndler, Niels and He, Jingxuan and Jenko, Slobodan and Vechev, Martin},
  journal={arXiv preprint arXiv:2305.15852},
  year={2023}
}

@article{yin2024characterizing,
  title={Characterizing truthfulness in large language model generations with local intrinsic dimension},
  author={Yin, Fan and Srinivasa, Jayanth and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2402.18048},
  year={2024}
}

@inproceedings{duan2024shifting,
  title={Shifting attention to relevance: Towards the predictive uncertainty quantification of free-form large language models},
  author={Duan, Jinhao and Cheng, Hao and Wang, Shiqi and Zavalny, Alex and Wang, Chenan and Xu, Renjing and Kailkhura, Bhavya and Xu, Kaidi},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={5050--5063},
  year={2024}
}

@article{zou2023representation,
  title={Representation engineering: A top-down approach to ai transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

@article{agrawal2023language,
  title={Do Language Models Know When They're Hallucinating References?},
  author={Agrawal, Ayush and Suzgun, Mirac and Mackey, Lester and Kalai, Adam Tauman},
  journal={arXiv preprint arXiv:2305.18248},
  year={2023}
}

@article{varshney2023stitch,
  title={A stitch in time saves nine: Detecting and mitigating hallucinations of llms by validating low-confidence generation},
  author={Varshney, Neeraj and Yao, Wenlin and Zhang, Hongming and Chen, Jianshu and Yu, Dong},
  journal={arXiv preprint arXiv:2307.03987},
  year={2023}
}

% mitigation

@article{gao2022rarr,
  title={Rarr: Researching and revising what language models say, using language models},
  author={Gao, Luyu and Dai, Zhuyun and Pasupat, Panupong and Chen, Anthony and Chaganty, Arun Tejasvi and Fan, Yicheng and Zhao, Vincent Y and Lao, Ni and Lee, Hongrae and Juan, Da-Cheng and others},
  journal={arXiv preprint arXiv:2210.08726},
  year={2022}
}

@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lee2022factuality,
  title={Factuality enhanced language models for open-ended text generation},
  author={Lee, Nayeon and Ping, Wei and Xu, Peng and Patwary, Mostofa and Fung, Pascale N and Shoeybi, Mohammad and Catanzaro, Bryan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34586--34599},
  year={2022}
}

@article{tian2023fine,
  title={Fine-tuning language models for factuality},
  author={Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2311.08401},
  year={2023}
}

%%%
@article{xiong2023can,
  title={Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms},
  author={Xiong, Miao and Hu, Zhiyuan and Lu, Xinyang and Li, Yifei and Fu, Jie and He, Junxian and Hooi, Bryan},
  journal={arXiv preprint arXiv:2306.13063},
  year={2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@article{tian2023just,
  title={Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback},
  author={Tian, Katherine and Mitchell, Eric and Zhou, Allan and Sharma, Archit and Rafailov, Rafael and Yao, Huaxiu and Finn, Chelsea and Manning, Christopher D},
  journal={arXiv preprint arXiv:2305.14975},
  year={2023}
}

@article{mielke2022reducing,
  title={Reducing conversational agents’ overconfidence through linguistic calibration},
  author={Mielke, Sabrina J and Szlam, Arthur and Dinan, Emily and Boureau, Y-Lan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={857--872},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{lin2022teaching,
  title={Teaching models to express their uncertainty in words},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2205.14334},
  year={2022}
}