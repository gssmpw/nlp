\section{Related Work}
\textbf{Diffusion Models for Perception Tasks.}
Diffusion models \cite{D1,D2,D3,D4}, known for their powerful denoising capabilities, have attracted considerable interest in domains such as natural language processing, text transformation, and multimodal data production. Recently, an increasing number of researchers have started investigating the use of diffusion models in perception tasks. DDPM-Segmentation \cite{DDPMSegmentation} is the initial study that uses diffusion models for semantic segmentation. On the other hand, DiffusionDet \cite{DiffusionDet} considers object detection as a noise-to-box task, aiming to provide accurate object bounding boxes by progressively denoising randomly generated proposals. Diffusion-SS3D \cite{Diffusion-SS3D} utilises the powerful properties of diffusion models in a semi-supervised 3D object detection framework, with the goal of generating more dependable pseudo-labels. Expanding upon this, Diff3DETR \cite{diff3detr} extends the approach of Diffusion-SS3D by proposing the first diffusion-based DETR framework.
In addition, DifFUSER \cite{diffbev} utilises the noise reduction capabilities of diffusion models to address noise for multimodal fusion (such as image, text, video).
In this work, we are motivated to further explore the potential of employing
the diffusion model to generate a high-quality representation, proposing the first diffusion-based multi-agent cooperative perception 3D detection method.

\textbf{Collaborative 3D Object Detection.}
Collaborative 3D object detection \cite{syncnet,CoAlign,cobevt,v2x-vit,opv2v} is a particular application in multi-agent systems that allows multiple agents to share information to overcome the inherent limitations of single-agent perception.
Many researchers have designed various methods to enhance the perception performance and robustness of collaborative perception systems. 
In terms of perception performance, the study in the literature  \cite{cobevt,v2x-vit,opv2v,where2comm} implemented a transformer architecture to aggregate information from different agents.
In terms of robustness, CoBEVFlow\cite{CoBEVFlow} creates a synchrony-robust collaborative system that aligns asynchronous collaboration messages sent by various agents using motion compensation. HEAL\cite{HEAL} smoothly integrates  emerging heterogeneous agent types into collaborative perception tasks. CoAlign \cite{CoAlign} uses an agent-object pose graph to address pose inaccuracies, and RoCo \cite{roco} tackles  pose errors with object matching and graph optimization techniques.
However, we observe that these methods tend to address only a single aspect of the problem and fail to ensure both perceptual performance and robustness of the model under multiple noise conditions. In contrast, our CoDiff can simultaneously address the effects of various types of noise, such as time delays and pose errors, thereby further improving the accuracy of collaborative 3D object detection.



\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{img/CoDiffusion.png} 
\caption{ 
Overview of the proposed  CoDiff framework. Single-agent features are transmitted to the ego vehicle. These features are concatenated and sent into the compression model $\mathcal E$, before entering the latent diffusion model. 
The diffusion model generates denoised features in latent space, which are then decompressed to obtain the denoised multi-agent fused features.
}
\label{fig:all}
\end{figure*}