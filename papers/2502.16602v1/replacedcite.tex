\section{Related Work}
\noindent \textbf{Language Bias in VQA.} Language bias has long been recognized as a challenging problem for conventional visual question answering (VQA). Previous methods in alleviating this problem can be roughly categorized into three groups: ensemble learning, contrastive learning, and loss re-scaling. Approaches in the first group____ introduce an additional bias branch which is trained with the original input in an ensemble manner. Contrastive learning-based debiasing methods____ first generate positive and negative samples using data augmentation techniques. These samples are then utilized to jointly optimize the model with a contrastive learning loss alongside the original classification loss. The last group methods____ address this problem with inspiration from class-imbalance mechanisms. To this end, each instance-aware loss is re-weighted based on training data statistics to achieve fair training. 

\noindent \textbf{Hallucination in LVLMs.}
Hallucination in LVLMs often refers that the generated textual responses are plausible but contradictory to the associated visual content____. Some initial efforts have been devoted to building benchmarks to probe the hallucinatory level of LVLMs. For instance, CHAIR____ and GAVIE____ instruct models to generate a free-form caption to reveal their exposure to errors, POPE____, HallusionBench____ and AutoHallusion____ query models in terms of visual reasoning aspects with binary questions. Besides, hallucination mitigation has also attracted extensive interest recently. Some data augmentation methods like LRV-Instruction____ and HalluciDoctor____ introduce additional negative and counterfactual data to fine-tune LVLMs. Other approaches propose to leverage contrastive decoding____ or reinforcement learning from human feedback____ to address this problem.
Overall, hallucination in LVLMs often manifests with multiple dimensions, wherein language bias contributes a significant factor.
As a result, performing language debiasing greatly assists the reduction in hallucination, therefore improving the reliability of LVLMs.

\noindent \textbf{Benchmarks for Video-Involved LVLMs.} The pervasiveness of LVLMs is accompanied by continual development in video-involved benchmarks. SEEDBench____ and Video-Bench____ cover a wide variety of video-centric tasks and aim to provide a comprehensive evaluation for video understanding capabilities. However, some studies find that these general benchmarks suffer from the static spatial bias from single frames____. To approach this, MVBench____ and Tempcompass____ curate video instances covering more temporal aspects such as speed, moving direction, attribute change, and event order. Besides, Video-MME____ collects long videos that last up to one hour in duration. Unlike these benchmarks, we propose to evaluate LVLMs from the dimension of language bias, which we believe, constitutes an essential component for video understanding yet received no attention in the existing literature.

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{filtering_all_v3.pdf}
\caption{VidLBEval quality control pipeline. i) We first filter out questions that can be answered correctly without referring to the associated video by utilizing several LLMs such as Qwen2. ii) External tools, i.e., Perspective API and GPT-4o/4V, are then employed for further safety checks. iii) Finally, we conduct human verification to review the results, leading to 1,695 high-quality samples for our VidLBEval dataset.}
\label{fig:filtering_all}
\end{figure*}