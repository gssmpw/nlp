\section{Related work}
\label{sec:related}


\paragraph{Strategic classification.}
The field of strategic classification **Hardt, "Strategic Classification"**
has gained much recent interest.
\extended{This has led to many advances both in theory **Hardt, Dwork, and Mullainathan, "Mitigating Unwanted Bias via Data Preprocessing"**__**Kearns et al., "Adversarial Saliency Maps for Explaining Inferences from Deep Neural Networks"**.}%
% Strategic classification succinctly captures a natural tension that exists between learning systems and their users, but this requires making
The original formulation includes several strong assumptions, in particular regarding costs, which subsequent works have challenged or relaxed.
% In response, several works have attempted to challenge these assumptions.% and extend beyond them.
One line of research considers learning under unknown (but nonetheless fixed) costs,
including in the online **Zemel et al., "You Shouldnâ€™t Share Your Data with Everyone: Privacy Beyond k-Anonymity"**,
multi-round batch **Hardt, Dwork, and Mullainathan, "Mitigating Unwanted Bias via Data Preprocessing"**,
and one-shot **Kearns et al., "Adversarial Saliency Maps for Explaining Inferences from Deep Neural Networks"** settings;
under personalized costs **Ding and Hardt, "Sufficient Conditions for Learning under Unfair Class Balances with a Fixed Budget"**
and for general manipulation graphs
**Hardt and Price, "Equality of Opportunity in Supervised Learning"** %; %,ahmadi2024strategic},
\extended{or in a field experiment **Hanna et al., "Fairness Beyond the Point Score: A Study on Fair Classification with Real-World Data"**.}%
A related thread relaxes assumptions on user-side information,
but focuses on uncertainty regarding the classifier rather than costs
**Hardt and Price, "Equality of Opportunity in Supervised Learning"**.
Another assumption is that users respond independently;
% ---in part since costs apply per user.
this has been relaxed by injecting dependencies through the utility function in a ranking task **Bachrach et al., "Robust Ranking from Pairwise Preferences with Adversarial Guarantees"**
or through the model class by making use of a network structure over users 
**Mansour, Singh, and Zhang, "Learning to be Fair from Data: Effective Equalization Strategies Using Regularized Models"**.
In a recent work, **Zhou et al., "Scalable and Robust Bayesian Optimization for Nonconvex Optimization with Unknown Constraints"** augment the cost function to include externalities, which entail dependencies.
%  as a Stacklberg-Nash game ____.Our work proposes that user behavior becomes dependent through a market mechanism
in which demand, and therefore prices, derive from the classifier.

\extended{scext - update to iclr}

% which coordinates supply and demand as is determined by the classifier.


% (un)known:
% darksc etc
% scuc - robustness, sensitive to misestimation
% infer costsindic costs

% decompose:
% stratgnn
% externalities
% stack-nash [haifeng]

% predetermined:
% - ..?
% - ours - c depends on h



\paragraph{Learning and markets.}
% Recent work has considered the role of learning in distinct market settings, such as recommendation systems and digital marketplaces,
% % Here users seek items that match their preferences,
% in which service providers compete over users by better learning their preferences.
% This leads to interesting questions regarding the role of learning and data in determining market outcomes.
% For example,
% **Kullolainen et al., "A Simple Framework for Fairness in Online Advertising"**
% study online learning algorithms that enable efficient and fair competitive equilibrium.
% Conversely,
% **Tao, Zhang, and Zhou, "Differentially Private Stochastic Gradient Descent with Momentum"**
% show that market outcomes under competition 
% do not necessarily align with user utility at equilibrium.
% Our setting is quite distinct:
% competition is between sellers (rather than platforms),
% users seek positive predictions (rather than useful recommendations),
% % have simple homogeneous preferences,
% and learning \emph{forms} a market (rather than supports it).
A large literature considers markets for data
**Gupta et al., "Differential Privacy Goes Wild: Bounding the Impact of Randomized Mechanisms"**
or trained models **Duchi et al., "Regularization in Differential Privacy"**.
A recent line of work studies competition between platforms or service providers
**Babak and Daskalakis, "Competitive Mechanism Design for Social Welfare"**.
Here learning is used to elicit user preferences, e.g. towards making useful recommendations.
\extended{**Mansour, Singh, and Zhang, "Learning to be Fair from Data: Effective Equalization Strategies Using Regularized Models"**}%
In contrast, our setting considers how learning \emph{creates} a market, where the commodity is features.
% the formation of markets for features.
\extended{The idea that features can be a scare resource has been suggested in
**Hardt and Price, "Equality of Opportunity in Supervised Learning"**, 
but in a very different setting in which the learner controls features to decongest a conventional market.}%
% but in an explicit market setting and for very different reasons.
Closer to ours in spirit, 
**Dai et al., "Adversarially Robust Streaming Algorithms via Online Learning"**
measure the power of learning to shape outcomes through predictions
that cause a distribution shift.
However, they target a general performative setting in which neither a market nor user incentives are explicitly modeled.
**Gao et al., "Learning and Inference in Combinatorial Auctions"**
study data-driven algorithms for mechanism design (e.g., auctions)
in which rational agents can misreport information (e.g., bid untruthfully).
Interestingly, they conclude that learning a mechanism is possible if misreporting bears a cost to users---as in strategic classification.

\extended{%
\red{%
- fairness: \\
--- social burden \\
--- interaction between strategic behavior and fairness constraints
[Fairness Interventions as (Dis)Incentives for Strategic Manipulation] \\
--- ours is monetary \\
- [AN ECONOMIC APPROACH TO REGULATING ALGORITHMS] - propose to study algorithmic bias from welfare econ perspective to reduce and regulate discrimination. \\
- Computing equilibrium prices;
ours is unique in that utility is not strongly increasing, but is binary prediction \\
- differentiable objective; ref our sc papers?
}
}