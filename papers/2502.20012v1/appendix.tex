\section{Market prices -- additional results}

\subsection{Expected prices} \label{appx:empirical}
In Sec.~\ref{sec:fixed_h} we have empirically shown that for many `natural' distributions over demand, there is: (i) a unique revenue-maximizing point $u^*$,
and (ii) this point tends to materialize at extreme quantiles of the distribution.
Here we show that this phenomenon holds more broadly.
%  and attempt to provide a theoretical underpinning for it.
% \paragraph{Empirical results.}
Fig.~\ref{fig:beta_dists-all} shows pdf-s, revenue curves, and price setters for a wide range of parameterizations of the $\Betadist$ distribution. These include symmetric, left-skewed, right-skewed, concave, bell-shaped, and uniform distributions.
For all distributions considered, the price setter is at least in the 80-th percentile, and typically much more extreme.

%========================================================================
\begin{figure}[h!]
\centering
\includegraphics[width=0.7\textwidth]{beta_dists-all-crop.pdf}
\caption{%
Price setters are extreme across a wide range of $\Betadist$ distributions.
}
\label{fig:beta_dists-all}
\end{figure}
%========================================================================

\extended{%
\todo{revenue-setting z-score for normal distributions}
}


\subsection{Theoretical insight} \label{appx:theory}

To complement the observations above,
this section aims to provide a theoretical underpinning for the questions of (i) when do unique revenue-maximizing prices exists,
(ii) why is this prevalent across many natural distributions,
and (iii) how extreme are price setters (e.g., in terms of quantiles).
We begin with some general claims and sufficient conditions,
and then present some examples of particular distribution classes which we analyze in depth.

\subsubsection{Analyzing revenue}
% Recall that we are tasked with finding the expected revenue that a user $u$ achieves when drawn from a 
Consider a continuous distribution over (univariate) revenue 
defined by a pdf $f(u)$.
We assume that $f$ has support on $[0,t]$ for $t \in \R_+ \cup \{\infty\}$,
and consider uniform budgets $b=1$ for all users. 
This is made w.l.o.g.---see below.
Recall that expected revenue $r(u;f)$ is defined as the sum of demands of 
all users $u' \leq u$, divided by $u$.
% depends on the summation of contributions from 
% The summation can be written in terms of the expected value of $u'$, conditional on $u' \leq u$.
% We can write the \textbf{expected} revenue of $u$ over the entire distribution as
This can be rewritten as:
\begin{equation*}
r(u;f) = \frac{1}{u} \expect{u}{u' | u' \leq u} = \frac{1}{u} \int_{0} ^ {t} {f(u') \cdot \mathds{1} \{ u' \leq u \} \cdot u' du'} = \frac{1}{u} \int_{0}^{u} {f(u') \cdot u' du'}
\end{equation*}

To determine whether the expected revenue has a maximum, we compute the derivative of $r(u; f)$ with respect to $u$:
\begin{equation*}
r'(u; f) = \frac{d}{du} r(u; f) = \frac{1}{u} f(u) \cdot u - \frac{1}{u^2} \int_0^u f(u') \cdot u' \, du' = f(u) - \frac{1}{u^2} \int_0^u f(u') \cdot u' \, du'
\end{equation*}

Denote by $u^*$ the revenue maximizer w.r.t. $f$ (if such exists). That is, $u^*=argmax_u r(u; f)$.
The following observations will be useful:
\begin{observation}
\label{obs:r' always positive}
If $ r'(u; f) > 0 $ through $0 \leq u \leq t$, then $u^*$ is unique and is attained at $t$.
\end{observation}

\begin{observation}
\label{obs:r' always negative}
If $ r'(u; f) < 0 $ through $0 \leq u \leq t$, then $u^*$ is unique and is attained at $0$.
\end{observation}

Setting $r'(u; f) = 0$, we find:
\begin{align*}
f(u) &= \frac{1}{u^2} \int_{0}^{u}{f(u') \cdot u' du'} \\
f(u) u^2 &= \int_{0}^{u}{f(u') \cdot u' du'}
\end{align*}


\subsubsection{Proof of Theorem~\ref{thm:unique_rev_argmax}}
Theorem~\ref{thm:unique_rev_argmax} states that sufficient conditions for the existent of a unique argmax for expected revenue are that $f(u)u$
is either strictly increasing, strictly decreasing, or strictly unimodal.
We now turn to its proof.


\begin{proof}
Denote by $D(u)$ the function $D(u)=f(u)u$. We split the proof to two distinct cases:

\textbf{Case I: $D(u)$ contains one maxima point.} Let $\hat{u}$ denote the maxima point of $D(u)$, meaning that $\uhat = \argmax_{u}D(u)$. For $u \in [0, \hat{u}]$, $D(u)$ is increasing, and for $u \in [\hat{u}, t]$, $D(u)$ is decreasing. Therefore, for $0<u_1<u_2<\uhat$, it holds that $D(u_1) = f(u_1)u_1 < f(u_2)u_2 = D(u_2)$. Thus, for all $u < \hat{u}$:
\begin{equation*}
D(u)u = f(u)u^2 > \int_{0}^{u} f(u')u' , du'
\end{equation*}

This implies:
\begin{equation*}
r'(u; f) = f(u) - \frac{1}{u^2} \int_0^u f(u')u' , du' > 0
\end{equation*}

If $f(u)$ is continuous on $[0, t]$, then $r'(u; f)$ is also continuous on $[0, t]$. Therefore, if no $u$ satisfies $f(u)u^2 = \int_{0}^{u} f(u')u'\, du'$, then $r'(u; f) > 0$ throughout $[0, t]$. By observation \ref{obs:r' always positive}, $u^* = t$ maximizes the revenue of the distribution.

Suppose there exists a point $u^*$ such that:
\[
f(u^*){u^*}^2 = \int_{0}^{u^*} f(u') \cdot u' \, du'.
\] 
First, it follows directly that $u^* \geq \uhat$,
since for $u<\uhat$, it holds that $r'(u; f) > 0$.
Second, referring to Figure \ref{fig:proof of maxima}, for each $\epsilon > 0$, moving to $u^* + \epsilon$ increases area 1 and decreases area 3. Area 2 changes as well but is mutual to both terms.
Therefore, in the range $(u^*, t]$, the following inequality holds:
\[
f(u)u^2 < \int_{0}^{u} f(u') \cdot u' \, du'
\]
This implies that within the range $(u^*, t]$, the derivative $r'(u; f) < 0$. Consequently, $u^*$ is the unique revenue maximizer by definition.

\textbf{Case II: $D(u)$ contains no maximum point.}  
If $D(u)$ is strictly increasing over $[0,t]$, it follows that $f(u)u^2 > \int_{0}^{u} f(u')u' \, du'$ for all $u \in [0,t]$. Consequently, $r'(u; f) > 0$ for all $u$, which, by Observation \ref{obs:r' always positive}, indicates that the unique revenue maximizer is $u^* = t$. Moreover, in this case $\argmax_u D(u) = t$, meaning that $u^* = \argmax_u D(u)$

Conversely, if $D(u)$ is strictly decreasing over $[0,t]$, it follows that $f(u)u^2 < \int_{0}^{u} f(u')u' \, du'$ for all $u \in [0,t]$. Consequently, $r'(u; f) < 0$ for all $u$, which, by Observation \ref{obs:r' always negative}, indicates that the unique revenue maximizer is $u^* = 0$. Moreover, in this case $\argmax_u D(u) = 0$, meaning that $u^* = \argmax_u D(u)$.
\end{proof}


% \FloatBarrier
\begin{figure}[t!]
\centering
\includegraphics[width=0.4\textwidth]{unique_revenue_maximizer.png}
\caption{Areas 1 and 2 contribute to $\int_{0}^{u^*} f(u')u' \, du'$, while areas 2 and 3 yield $f(u^*) {u^*}^2$. At $u = u^*$, we have  
$\int_{0}^{u^*} f(u')u' \, du' = f(u^*) {u^*}^2$, which implies that area 1 equals area 3. Furthermore, for each $\epsilon > 0$, shifting to $u^* + \epsilon$ increases area 1 and decreases area 3. Area 2 also changes but remains common to both terms. Thus, for each $\epsilon > 0$, at $u_{\epsilon} = u^* + \epsilon$, it follows that $\int_{0}^{u_{\epsilon}} f(u')u' \, du' > f(u_{\epsilon}) u_{\epsilon}^2$.}
\label{fig:proof of maxima}
\end{figure}
    

We note that the proof can be easily extended to distribution in the range $[a,t]$, for $a>0$. The changes to the original proof are minor, and include modifying the lower limit of the integration. For distributions in range $[a,\infty]$, the proof is valid too, as long as $D(u)$ is strictly increasing, decreasing, or unimodal.

The proof also give a lower bound on $u^*$ in terms of $f$:
\begin{corollary}
Under all conditions of Thm.~\ref{thm:unique_rev_argmax},
it holds that $u^* \ge \uhat$.
\end{corollary}

The following examples show this relation explicitly for two classes of distributions: Beta, and uniform.

\subsubsection{Example: Beta distribution}

% We now analyze two types of distributions - Beta and Uniform, and show that both contain a unique revenue maximizer.

% \textbf{Beta distribution:}
Based on Theorem \ref{thm:unique_rev_argmax}, we establish the following result about Beta distributions:

\begin{theorem}
    For every $a, b > 0$, let $f(u)$ denote the probability density function (PDF) of the Beta distribution $\text{Beta}(a, b)$, defined on the interval $[0,1]$. Then, the function $D(u) = f(u) \cdot u$ is either strictly increasing or strictly unimodal.
\end{theorem}

The following theorem implies that every Beta distribution has a unique revenue maximizer, which is confirmed empirically over different Beta distributions in Figure \ref{fig:beta_dists-all}.

\begin{proof}
    The PDF of $\text{Beta}(a, b)$ is given by:
    \[
    f(u) = K_{a,b} u^{a-1} (1-u)^{b-1},
    \]
    where $K_{a,b} > 0$ is a normalization constant that depends only on $a$ and $b$.
%
    Thus, $D(u) = f(u) \cdot u = K_{a,b} u^a (1-u)^{b-1}$. We will show that $D(u)$ is either strictly increasing, or strictly unimodal.
%
    First, compute the derivative of $D(u)$ with respect to $u$:
    \[
    \frac{d}{du} D(u) = K_{a,b} \left[ a u^{a-1} (1-u)^{b-1} - u^a (b-1) (1-u)^{b-2} \right]
    \]
    Simplifying the expression gives:
    \[
    \frac{d}{du} D(u) = K_{a,b} u^{a-1} (1-u)^{b-2} \left[ a(1-u) - u(b-1) \right]
    \]
    and setting $\frac{d}{du} D(u) = 0$, we solve:
    \[
    K_{a,b} u^{a-1} (1-u)^{b-2} \left[ a(1-u) - u(b-1) \right] = 0
    \]
    The solutions are:
    \[
    u_1 = 0, \quad u_2 = 1, \quad u_3 = \frac{a}{a+b-1}
    \]

    Here, $u_1$ exists if $a > 1$, and $u_2$ exists if $b > 2$ (otherwise, they are undefined due to the powers of $u^{a-1}$ and $(1-u)^{b-2}$). Since the Beta distribution is defined on $[0,1]$ and $D(u_1)=D(u_2)=0$, we focus on $u_3$. For $u_3 \in [0,1]$, it must hold that $b > 1$.
    
    Next, observe that for all $u < u_3$, the term $a(1-u) - u(b-1) > 0$. Therefore, $D'(u) > 0$ and $D(u)$ increases in this range. The proof now splits into two cases:

    \textbf{Case 1: $u_3 \notin [0,1]$.}  
    In this case, $D(u)$ is strictly increasing over the interval $[0,1]$, because $D'(u) > 0$ throughout $[0,1]$ and the proof is complete.

    \textbf{Case 2: $u_3 \in [0,1]$.}  
    For $u_3 < u < 1$, the term $a(1-u) - u(b-1) < 0$. Therefore, $D'(u) < 0$ and $D(u)$ decreases in this range. Thus, $u_3$ is the sole maximum point of $D(u)$, which implies that $D(u)$ is strictly unimodal, as required.
\end{proof}

As shown in the proof of Theorem \ref{thm:unique_rev_argmax}, if \( D(u) \) is strictly increasing, the revenue maximizer occurs at the right edge of the distribution, which in this case is at \( u = 1 \). If \( D(u) \) is strictly unimodal, we know that the revenue maximizer is greater than the maximum point of \( D(u) \). In this case, the maximum point is \( \frac{a}{a+b-1} \) (noting that \( b > 1 \) in this scenario).  

Moreover, the maximum point of a Beta distribution with parameters \( a, b \) is given by \( \argmax_u f(u) = \frac{a-1}{a+b-2} \). For \( b > 1 \), we obtain:
\[
\frac{a}{a+b-1} > \frac{a-1}{a+b-2},
\]

which implies that the percentile of \( \arg\max_u D(u) \) is greater than the percentile of \( \arg\max_u f(u) \), and both are smaller than the percentile of \( u^* \).  

This analysis provides an intuition for the unequivocal empirical results shown in Figure \ref{fig:beta_dists-all}, which demonstrate that the revenue maximizer is at least in the 80th percentile (and typically even higher). To conclude, under this family of distributions, when they induce individual demands for a feature under a uniform budget, a large percentage of users will be able to afford purchasing the amount of the feature they need.

\subsubsection{Example: Uniform distribution}
% \textbf{Uniform distribution:} 
We now perform a similar analysis for the uniform distribution over the range $[0, t]$, where $t > 0$. The PDF of this distribution is constant for all $u$: $f(u) = \frac{1}{t}$. Consequently, $D(u) = f(u)u = \frac{1}{t}u$ is a strictly increasing function of $u$. By Theorem \ref{thm:unique_rev_argmax}, the revenue maximizer for this distribution is the right edge of the range, which is $t$.

We can extend this result to the uniform distribution over the range $[a, b]$.

\begin{theorem}
    For any $a, b > 0$, let $f(u)$ denote the probability density function (PDF) of the uniform distribution over $[a, b]$. Then, the revenue maximizer is unique and occurs at $b$.
\end{theorem}

\begin{proof}
    The PDF of the uniform distribution is constant for all $u$: $f(u) = \frac{1}{b-a}$. The function $r(u; f)$ is therefore given by:
    \[
    r(u; f) = \frac{1}{u} \int_{a}^{u} f(u') \cdot u' \, du' = \frac{1}{u} \int_{a}^{u} \frac{1}{b-a} \cdot u' \, du' = \frac{1}{u(b-a)} \int_{a}^{u} u' \, du'
    \]
    Evaluating the integral:
    \[
    r(u; f) = \frac{1}{u(b-a)} \left[ \frac{u^2}{2} - \frac{a^2}{2} \right] = \frac{1}{2(b-a)} u - \frac{a^2}{2(b-a)} \frac{1}{u}
    \]

    Next, compute the derivative of $r(u; f)$ with respect to $u$:
    \[
    r'(u; f) = \frac{1}{2(b-a)} - \frac{a^2}{2(b-a)} \cdot \left(-\frac{1}{u^2}\right) = \frac{1}{2(b-a)} + \frac{a^2}{2(b-a)} \frac{1}{u^2}
    \]
    Since both terms are positive for all $u \in [a, b]$, it follows that $r'(u; f) > 0$ for all $u \in [a, b]$

    By Observation \ref{obs:r' always positive}, the revenue maximizer is unique and occurs at the right edge of the range, which is $b$.
\end{proof}

% \todo{new condition that bounds $E$ with $u^2$}

% \todo{give concrete examples: \\
% - uniform \\
% - Beta(2,2)
% }

% \todo{add figure for the Beta distribution example, plot $f,g$, enumerator, denominator, denominator $\times 2$, etc. PLOT WITH MATPLOTLIB! (not desmos)}

% \yellow{
% \yellow{\rule{\linewidth}{0.5em}}

\subsection{Empirical prices}

% \todo{take text and figures from main file (currently commented out)}

% - example on three small samples plot \\
% - recursive formula \\
% - argmax jumping plot \\
% - convergence of empirical to expected prices as $m$ grows

Our analysis above considers expected prices defined over a demand distribution.
But in practice, learning must work with finite samples,
and therefore with empirical markets.
We begin by investigation some features of empirical markets, revenue, and prices,
and then make the connection to population markets with expected revenue and prices.

%==================================


\subsubsection{The price-revenue landscape}
Thm.~\ref{thm:price_is_point} states that the revenue-maximizing price $\rhohat$ is always some $u_i^{-1}$;
hence, we can instead think of revenue as a function of inverse prices $\frac{1}{\rho}=u$,
measured in demand units.
This is useful since we can now consider directly how changes in the demand set affect
revenue, and through it, the optimal price.

Fig.~\ref{fig:rev_samples} plots empirical revenue $\rhat(\smplst)$ for three different samples $\smplst_j$ of size $m=10$ with units $u_i$ scaled to span $[1,10]$:

%========================================================================
\begin{figure}[h!]
\centering
% \vspace{-1em}
\includegraphics[width=0.5\linewidth]{rev_samples.v3-crop.pdf}
\caption{%
Empirical revenue curves for different samples.
}
\label{fig:rev_samples}
\end{figure}
%========================================================================
Note that revenue always begins at $\frac{1}{m}$ for the smallest $u_i$
since only one unit is sold (to one user) at price $\rho=1$.
From here, however, outcomes can differ considerably across samples,
in terms of the shape of the revenue curve,
the location and index of the price setter $i^*$,
and the optimal price $\rhohat$.
% This shows how prices can be sensitive to the \emph{composition} of demand.
% \squeeze

% \paragraph{Sensitivity.}
% Next, we examine the sensitivity of optimal prices to changes in demand.
This raises the question: how sensitive are market prices to variation in demand?
% We will measure changes when modifying a single point:
For this, we take a sample $u_1,\dots,u_m$,
and measure how prices change due to adding a single new point $u_0$.
Fig.~\ref{fig:sensitivity} shows the outcome of this process for a fixed select demand set of size $m=5$ and for an increasing value of an additional point $u_0 \in [1,10]$ (x-axis):

%========================================================================
\begin{figure}[h!]
\centering
\includegraphics[width=0.5\linewidth]{sensitivity.v3-crop.pdf}
\caption{%
The effect on price of adding a single point.
\todo{add legend for $s_i$}
}
\label{fig:sensitivity}
\end{figure}
%========================================================================
The $u_i$ are shown in color and positioned on the x-axis.
The revenue curve includes segments colored according to the matching price setter, with turquioise (and yellow highlight) indicating that the price setter is $u_0$.
As can be seen, the value of $u_0$ has a stark effect on market prices:
even though it is increased gradually,
prices jump at discrete points whenever the price-setter $i^*$ changes.
Generally, prices are down-trending, and $i^*$ appear in increasing order of $u_i$---but this is not necessary, as prices can also jump up,
and some $s_i$ can be price-setters more than once.


\subsubsection{Why prices jump}
One reason for this behavior is that optimal prices
% One challenge with market prices is that they
may not be unique.
The following is an extreme construction in which \emph{all}
points are revenue-maximizing.
% \squeeze
% W.l.o.g. assume budget are uniform, $b_i=1 \, \forall i$.
\begin{proposition}
\label{prop:all_points_max_revenue}
Let $m \ge 3$, and
w.l.o.g. assume uniform budgets.
Define $u_1,\dots,u_m$ recursively as:
\[
u_i = u_2 \cdot \sum\nolimits_{j < i} u_j,
\quad u_2=2,
\quad u_1=1
\]
Then for all $i>1$, prices $\rho_i=u_i^{-1}$ attain the same revenue.
% then revenue $\rhat(\rho)$ is the same at all $\rho_i=u_i^{-1}$ for $i>1$.
\end{proposition}
Together with Thm.~\ref{thm:price_is_point}, this implies that $\rhat$ 
is also maximized under all $\rho_i$.
To see how this lends to price jumps,
consider the minimal case of $m=3$.
If we slightly decrease $u_2$, then it becomes the unique price-setter;
% since \todo{...}.
in contrast, if we slightly increase $u_2$,
then $u_3$ becomes the price setter.
%  since \todo{...}.
Thus, small perturbations in $u_2$ can cause prices to jump between
$\rho_2$ and $\rho_3$.
% More generally, we can expect that adding another $u$ to the set will
% contribute mostly \todo{...}

\extended{%
\blue{Of course another set with all maximizers is the set with $u_i=u$ for all $i>1$.
Interestingly, one attains the minimum revenue achievable with $m$ points, and the other attains the maximum.}

\blue{
Prop.~\ref{prop:all_points_max_revenue} is also suggestive of a more general structure.
For convenience, assume that for each $m$, the sequence $u_1,\dots,u_m$ is 
scaled (after its construction) to be in $[0,1]$.
This new sequence has an interesting limiting behavior:
%  by applying $u_i \gets 2(u_i-1)/(u_m-1)$.
as $m$ grows, we get that $u_{m-k} \to 1/3^k$.
}

\todo{is this also the minimal max-revenue set? can we prove it? is having all $u_i$-s be equal the max max-revenue set?}

\todo{add result on effect of outliers?}
} 

% \paragraph{The role of budgets.}
% By Thm.~\ref{thm:price_is_point}, 


\subsubsection{Revenue for large samples}
Our examples above considered mostly very small market sizes.
Fortunately, prices tend to be more well-behaved
when the number of samples grows
as long as the underlying demand distribution is well-behaved.
For example, for $u \sim \Betadist(0.5,4)$,
(and scaled to $[1,10]$),
Fig.~\ref{fig:increasing_sample_size} presents
revenue curves (left) as well as maximal revenue (top right),and empirical market prices (bottom right)
for samples of increasing size $m$:
\squeeze

%========================================================================
\begin{figure}[h!]
\centering
\includegraphics[width=0.55\linewidth]{increasing_sample_size-crop}
\caption{
Revenue and prices for increasing sample size.
}
\label{fig:increasing_sample_size}
\end{figure}
%========================================================================
As can be seen, despite significant variation under small $m$,
results stabilize as $m$ grows in terms of 
the revenue curve (left), its maximum value (top right),
and optimal prices (bottom right).
% The above shows results for $u \sim \Betadist(0.5,4)$ (and scaled to $[1,10]$).

\extended{
\todo{the clustering hypothesis}
}

%================================================

% \yellow{\rule{\linewidth}{0.5em}}

% \yellow{%
\section{Additional experimental results} \label{appx:additional_experiments}
% \todo{b corr y, gap increases}

Our results in Sec.~\ref{sec:market-aware_clsfr} revealed a surprising result:
that induced markets can make unseparable data become perfectly separable.
Here we show that this effect can be even more extreme and unintuitive.
Consider a univariate mixture distribution with
class-conditional distributions $p(x\,|\,y) = \N(\mu_y,\sigma)$.
We set $\sigma=0.15$ and will be interested in the effects of varying $\mu$.
We will examine both balanced data ($p_1 = p(y=1)$) 
and class-imbalanced data with $p_1 = p(y=1) = 0.3$.
For budgets, we set $b=b_1 y$ and show results for $b_1 \in \{1,1.5,2,2.5\}$.
Our model class will consist of threshold functions $h_\tau(x)=\one{x>\tau}$.
Note that we intentionally consider only thresholds that are oriented to 
classify larger $x$ as positive
(i.e., the class does not include `reverse' thresholds $\one{x < \tau}$).

Fig.~\ref{fig:b_corr_y} shows accuracies for the optimal threshold classifier
across increasing gaps between class-conditional means $\mu_1 - \mu_0$.
Note that a negative gap means that the positive distribution 
generates values that are mostly \emph{smaller} than the negative distribution.
The plot shows results for the range of budget scales $b_1$,
and plot the performance of a non-strategic benchmark (dashed grey).
As expected, the benchmark attains reasonable accuracy when the gap is large,
provides $p_1$ accuracy when the gap is zero (and the two distributions are superimposed),
and deteriorates quickly as the gap becomes more negative.
But for market-aware classifiers, this is not the case.
For $p_1=0.5$ (left), we see that for the larger budgets,
accuracy can be 1 \emph{even when the gap is negative}.
For smaller budgets, outcomes under a negative gap can be \emph{better}
than under a positive!
This latter behavior is much more distinct for $p_1=0.3$ (right),
where for all budget considered, a positive gap enables significantly lower accuracy
than moderate negative gaps allow.


%========================================================================
\begin{figure}[h!]
\centering
\includegraphics[width=0.55\linewidth]{b_corr_y-crop.pdf}
\caption{
Accuracy of threshold classifiers on `inverted' data.
}
\label{fig:b_corr_y}
\end{figure}
%========================================================================

% }

%This yields the condition for finding \(u\) that maximizes the revenue:

%\begin{itemize}
    %\item If $ r'(u; f) > 0$ through $0 \leq u < m$, the revenue maximizer $u^*$ is unique and given in the right edge of the distribution.

    %\item Else if $ r'(u; f) < 0$ through $0 \leq u < m$, the revenue maximizer $u^*$ is unique and given in the left edge of the distribution.

    %\item Otherwise, if there exists a point $u^*$ such that $r'(u; f) = 0$, and it holds that $r'(u; f) \geq 0, ~ \forall ~ 0 \leq u < u^*$ and $\forall ~ u^* \leq u < m$ it holds that $r'(u; f) \leq 0$, then $u^*$ is a unique revenue maximizer point of the distribution.
%\end{itemize}

%Another way to interpret the results, is when $g(u) = 2$ it holds that
%\expect{u' \sim f}{u' \,|\, u' \le u} = f(u) u^2


% \section{Market prices}

% \blue{%

% \paragraph{How prices adjust to demand.}
% Given the above, we next consider how sellers should set prices
% when facing a collection of users.
% In principle, different users can have very different demand sets.
% % \blue{
% % Consider a collection of users with aggregate demand $\Gamma=\{\Gamma_x\}$.
% % Since users are rational (and hence minimize costs),
% % the demand set for user $x$ is given by:
% % \squeeze
% % \begin{equation}
% % \label{eq:demand_set}
% % % \delta^h 
% % % = \delta^h(x;p) 
% % % \in 
% % \Gamma_x(p,h) = 
% % \{ \delta \,:\, w^\top (x+\delta) + a = 0
% % \, \wedge \,
% % \delta^\top p \le b \}
% % \end{equation}
% % which satisfies budget constraints.
% % Overall demand $\Gamma$ is then obtained by aggregating over all $\Gamma_x$,
% % and prices are determined according to this set.
% % }
% However, notice that by Eq.~\eqref{eq:br_lp_normalized},
% users differ in practice only by the constant $\kappa$, since only this depends on $x$.
% This results from users preferences being homogeneous.
% The implication is that users differ only in the \emph{quantity} they seek,
% and so demand sets differ only in scale.
% % Hence, while users may seek different quantities,
% % they have homogeneous preferences, and should therefore behave similarly.
% Hence, what matters to sellers are only the 
% % This means that the object of interest for sellers is the
% ratios $p_i/w_i$,
% % whose effect is global,
% where each seller $i$ controls its own $p_i$, and depends on all others.
% Since users will buy only the most cost-effective features,
% any $s_i$ whose ratio is \emph{not} minimal will receive zero market share.
% Hence, equilibrium is possible only if $p_i/w_i=\rho$ for some $\rho \in \R$ and for all $i$.
% % \squeeze

% Consider such $\rho$, and assume all ratio equalities hold.
% % Since users are agnostic to which combination of features they acquire,
% % for simplicity we
% Clearly, no seller has incentive to raise her price, since this can only reduce her market share.
% However, each seller has incentive to slightly lower the price,
% since this would undercut all competitors and capture the entire market.
% Since sellers in our setting have no capacity constraints or production costs,
% one possible outcome is that prices spiral down towards zero---essentially Bertrand's paradox. To circumvent this, we will invoke the Folk Theorem, and assume sellers have foresight and so coordinate to prevent price collapse and maintain prices at the cooperative equilibrium:
% \begin{equation}
% \label{eq:equilibrium_ratio}
% \forall \, i \in [d], \qquad
% \frac{p_i}{w_i} =  \rho^* >0
% \end{equation}
% for $\rho^*$ that admits maximal total revenue, $\rev = \sum_i \rev_i$.
% This implies a tight connection between the classifier and prices:
% \begin{proposition}
% Let $h(x)=\sign(w^\top x + \thresh)$ be a linear classifier,
% then market prices $\p^*$ are proportional to $w$, namely:
% \begin{equation}
% \label{eq:scalar_equilibrium_price}
% \p^*(h;D) = \rho^* \cdot w % (w_1, \dots, w_d)
% % \p^h = \rho^h \cdot w % (w_1, \dots, w_d)
% \end{equation}
% for some $\rho^* \in \R_+$ which also depends on $h$ and $\dist$.
% \end{proposition}
% % Eq.~\eqref{eq:scalar_equilibrium_price} 
% For a particular $h$, we will use $\rho^h = \rho^*$. \todo{used?}
% % For clarity we will use $\rho^* = \rho^*(h;\dist)$.


% \subsection{Computing empirical market prices} \label{sec:exact_algo}
% Given a classifier $h$ and sample set $\smplst =\{(x_i,\budget_i,y_i)\}_{i=1}^m$,
% we will be interested in computing revenue-maximizing market prices.
% Because we only have a sample at hand,
% our goal will be to compute \emph{empirical market prices} $\phatvec$.
% Applying Eq.~\eqref{eq:scalar_equilibrium_price} to 
% the empirical distribution over $\smplst$,
% we get that $\phatvec = \rhohat w$ for the scalar $\rhohat$ 
% % (which depends on $h$ and $\smplst$).
% which maximizes empirical revenue, denoted $\rhat$.
% % = \rhohat(h;\dist)$.
% % \begin{equation}
% % \label{eq:revenue_emp}
% % \rhat_i(\p) = p_i \frac{1}{m} \sum_{j=1}^m \delta_i(x_j;\p)
% % \end{equation}
% This is highly useful,
% since the problem of computing equilibrium for the empirical market 
% for a given $h$ reduces to optimizing over scalars $\rho \in \R$.
% This will form the basis of our learning approach in Sec.~\toref.
% \blue{The connection between $\phatvec$ and $\p^*$ is discussed in Sec.~\toref.}

% % Since $\rhohat$ depends on $h$ (and $\smplst$)
% % with slight abuse of notation we will use $\p^h$ and $\rho^h$ to mean $\phatvec$ and $\rhohat$, respectively.
% % Our goal is now to compute the revenue-maximizing $\rho$.
% Intuitively, the challenge in finding the optimal $\rhohat$ is that if we set $\rho$ too high,
% then some users will not buy at all, and revenue will be lost;
% whereas if $\rho$ is too low, then many users will buy---but at suboptimal profit.
% The trick is therefore to balance \emph{who} buys with \emph{how much} they will pay;
% the first step to which is understanding what users actually want.
% % We now show how to obtain this.
% % \squeeze

% \paragraph{Interpreting demand.}
% Recall that users seek $\delta$ which allow them to cross the decision boundary (Eq.~\eqref{eq:br_lp}).
% Since market prices align with the direction of $w$ (Eq.~\eqref{eq:scalar_equilibrium_price}),
% it will suffice to consider demand as projected onto $w$.
% Since users are rational (and hence minimize costs),
% this has a simple interpretation:
% the demand of user $x$ is precisely her (directional) distance from the decision boundary of $h$.
% \squeeze
% \begin{observation}
% Let $h$ and $\smplst$, then for a given user $x$, 
% and for any $\rho \in \R$,
% her demand under prices $\p = \rho w$ is:
% \begin{equation}
% \label{eq:demand_as_distance}
% u = \distance^+(x;h) = \max\left\{0, \frac{w^\top x + \thresh}{\|w\|} \right\}
% % u = \distance^+(x;h) = \max\left\{0,(w^\top x + \thresh) \|w\|^{-1} \right\}
% \end{equation}
% \end{observation}
% \todo{is this the right direction? or do we needs $-$ inside?}
% \yonatan{I think we need -}

% We refer to $u \in \R$ as the amount of \emph{units} that user $x$ demands.
% Here the max over 0 ensures that demand is considered only for relevant users, i.e., for which $h(x)=-1$.

% % Note also that prices are insensitive to scale (i.e., change of currency);
% % thus, we can consider the pricing problem for normalized $w$,
% % where demand per user is measured scale-free \emph{units}:


% % Note this implies $\p^*=\rho^* \cdot w$, which we will use henceforth.

% % \footnote{
% % Because our setting includes substitute goods with no capacity constraints or production costs, 
% % it is susceptible to Bertrand's paradox:
% % sellers always gain by undercutting competitors,
% % which causes all prices to spiral down towards marginal costs.
% % To circumvent this, %we assume
% % for simplicity we will invoke the Folk Theorem and assume
% % sellers have foresight and so coordinate to prevent price collapse and maintain prices at the cooperative equilibrium.
% % }



% % \begin{lemma}
% % Let $h$ and $\smplst$, and define the \textbf{projected demand set} as
% % $\Gamma = \{(u_i,\budget_i)\}_{i=1}^m$.
% % %  where $u_i$ are given by Eq.~\eqref{eq:demand_as_distance}.
% % Let $\phat$ be the market price for $\Gamma$,
% % then the empirical market price vector for $(h,\smplst)$ is
% % $\phatvec = \phat w \red{/\|w\|?}$.
% % \squeeze
% % \end{lemma}
% % % \begin{lemma}
% % % Let $h$ and $\smplst$, then there exists $\alpha \in \R_+$
% % % for which
% % % the empirical market price vector is of the form $\phatvec = \alpha w$. 
% % % \end{lemma}
% % % Together with Eq.~\eqref{eq:demand_as_distance},
% % \blue{
% % This implies that $\br$ can be rewritten as: \todo{necessary/useful? if not - remove}
% % \begin{equation}
% % \br_h^\phatvec(x_i;\budget_i) = \begin{cases}
% %     x_i + u_i w & \text{if } \,  u_i>0 \,\text{ and }\, \phat u_i \le \budget_i \\
% %     x_i & \text{o.w.}
% %  \end{cases}
% % \end{equation}
% % }



% % %=====================
% % \input{algo_exact.tex}
% % %=====================



% \paragraph{Interpreting prices.}
% Our observation above suggests that to compute the optimal $\rhohat$,
% and in terms of demand,
% it suffices to consider as input the set of pairs
% % $\{(u_i,b_i)\}_{i=1}^m$.
% $(u_i,b_i)$ for all $i \in [m]$.
% We can therefore frame the task as that of a single seller of `units' aiming to maximize its revenue by setting the optimal price $\rhohat$.
% Nonetheless, this is still challenging,
% since revenue remains a complex function even for a single item.
% % (see Fig.~\ref{fig:rev_vs_price}).
% % \squeeze

% Our next observation is that from this single seller's perspective,
% what matters is not only the amount of units each user needs,
% but also how much they are willing to pay for them.
% For revenue considerations, this means we can replace each pair $(u,b)$ with
% the ratio $\ubar = u/\budget$,
% which we refer to as \emph{units-per-budget}.%
% \footnote{To see this, consider for example that gains are the same if a user buys 10 units at price 1, or 5 units at price 2.}
% % can be captured by replacing each pair $(u,b)$ with
% % a normalized \emph{units-per-budget} quantity,
% % denoted $\ubar_i = u_i/\budget_i$,
% % which encodes the amount of units a user can buy given her budget.
% The final step is to notice that a user will purchase at a given price $\rho$
% if $u \rho \le b$, or alternatively, if $\rho \le \ubar^{-1}$.
% % $\ubar^{-1}=b/u$ is smaller or larger than the given price $\rho$.
% This forms the basis of our main result:
% % This gives us a handle on optimize 
% \squeeze
% \begin{theorem}
% \label{thm:price_is_point}
% Given (uni-dimensional) demand $\{(u_i,b_i)\}_{i=1}^m$,
% the revenue-maximizing price is
% $\rhohat = \ubar_{i^*}^{-1}$
% % $\phat = \frac{1}{\ubar_i}$
% % $\phat = 1 / \ubar_i$
% for some $i^* \in [m]$.
% \end{theorem}

% \yonatan{The proof of Thm.~\ref{thm:price_is_point} is that all local minima of revenue (as a function of $\rho$) are characterized exactly by the set of points $\{\ubar_i^{-1}\}_{i=1}^m$.  The revenue term can be written as $r = \rhohat \sum_{i | \ubar_{i^*}^{-1} >= \rhohat} \ubar_{i^*}^{-1}$.  If $\rhohat$ is not one of the set of points  $\{\ubar_i^{-1}\}_{i=1}^m$, increasing $\rhohat$ to the nearest point above increases the revenue since the sum remains the same and (if $\rhohat$ is higher then all points the revenue is 0).}

% The proof of Thm.~\ref{thm:price_is_point} relies on showing that
% all local minima of revenue (as a function of $\rho$) are characterized exactly by the set of points $\{\ubar_i^{-1}\}_{i=1}^m$.
% Intuitively, this is since for any $i$,
% revenue increases when prices grow beyond $\ubar_i^{-1}$
% (since the same amount of units is sold for a higher price),
% but drops abruptly when it crosses $\ubar_{i+1}^{-1}$
% (since user $i+1$ can no longer afford to buy her units, $u_i$).
% The global optimum is therefore one of these points, 
% and we refer to the user $i^*$ as the \emph{price setter}.
% This idea is illustrated for a simple example in Fig.~\ref{fig:rev_vs_price}.

% % %========================================================================
% % \begin{figure}[t!]
% % \centering
% % \includegraphics[width=0.9\columnwidth]{rev_vs_price-crop.pdf}
% % \caption{
% % \textbf{Empirical revenue as a function of price.}
% % Revenue increases before each $\ubar_i^{-1}$
% % and drops immediately after,
% % implying the argmax is attained at some $i^* \in [m]$
% % % Local minima correspond to budget-per-unit points $\ubar_i^{-1}$
% % (Thm.~\ref{thm:price_is_point}).
% % \squeeze
% % }
% % \label{fig:rev_vs_price}
% % \end{figure}
% % %========================================================================

% \paragraph{Exact aglorithm.}
% Algorithm~\ref{algo:exact_market_prices} provides pseudocode for an algorithm that efficiently computes the optimal prices $\phatvec$ for given $h$ and $\smplst$.
% Correctness is due to  Thm.~\ref{thm:price_is_point},
% and runtime is $O(m \log m)$.
% The first steps are to project demand onto $w$,
% obtain all $u_i$, and normalize by $\budget_i$ to get $\ubar_i$.
% % denoted $\ubar = u/\budget$,
% % \blue{and which we refer to as `units per budget' (UPB).}
% % \todo{similar to knapsack?}
% % \blue{This depicts demand from the perspective of the seller,
% % who cares about how many units can be purchased (rather than how many are wanted).}
% % Correctness then follows from the next result.
% Since Thm.~\ref{thm:price_is_point} states that $\phat$ is obtained from \emph{some} $\ubar_i$,
% it suffices to compute revenue at prices $p_i=1 / \ubar_i$ for all $i \in [m]$, choose the maximizing $i^*$, and set $\phat = p_{i^*}$.
% Sorting by $\ubar_i$ makes this process efficient:
% at price $p_i$, the set of point who purchase are precisely $j$ for which $\ubar_j \le \ubar_i$,
% and since revenue at $i$ is  $\rev = p_i U = p_i \sum_{\ubar_j \le \ubar_i} \ubar_j$,
% we can update $U$ on the fly as a cumulative count of total units bought,
% and multiply by price.
% \squeeze
% }


%==================================================


\section{Differentiable market prices} \label{appx:learning_algorithm}

Our market-aware learning approach makes replaces exact market prices with a smooth surrogate to enable differentiation.
This is achieved by modifying the exact pricing scheme in 
Algorithm~\ref{algo:exact_market_prices} to be differentiable.

One useful property of Algorithm~\ref{algo:exact_market_prices} is that each of its steps can be easily vectorized,
and each atomic operation is either already differentiable,
or can be made differentiable using existing smoothing methods.
In particular, note that:
(i) $\distance^+$ is a differentiable operator;
(ii) $\sort$ can be implemented as a linear operator $\Pi$ with $\Pi_{ij}=1$ if item $i$ is in position $j$ and 0 otherwise; and
(iii) $U$ can be computed using a cumulative sum,
implemented as linear operator $C$ with entries $C_{ij}=\one{i \le j}$.
The remaining non-differentiable operations are $\Pi$ and the argmax for choosing the revenue-maximizing point $i^*$.
Thus, if we replace $\Pi$ with a differentiable softsort operator $\Pitilde$ 
(e.g., using \citet{prillo2020softsort})
and the argmax with a softmax,
then the entire algorithm becomes differentiable.
These steps comprise Algorithm~\ref{algo:smooth_market_prices},
which returns smoothed market prices $\rhotilde$ as an approximation to $\rhohat$.
The final differentiable market price vector can be obtained as $\ptildevec = \rhotilde w$, but is unnecessary to compute when using our market hinge loss, which requires only $\rhotilde$.
Note both softsort and softmax operators require setting appropriate temperature parameters.

%=====================
\input{algo_diff.tex}
%=====================


\paragraph{Normalization.}
In practice, we found it useful to normalize $\ubarvec$ 
so that its smallest entry is 1.
This is possible since market prices are insensitive to scale:
if $\rhohat$ is optimal for $\ubarvec$, then for a scaled $\alpha \ubarvec$,
the solution is $\frac{1}{\alpha} \rhohat$.
Normalizing ensures that all temperature parameters (e.g., in softsort and softmax)
operate at the same scale across all batches,
which is important since the relation $\rho = b/u$ suggests that even mild perturbations to small $u$-s can cause large variation in computed prices.
% \squeeze

\paragraph{Truncated demand.}
Recall that demand is determined by the distances of all points the lie on the negative side of $h$. In principle, since points on the positive side are assigned $u=0$,
their presence does not affect prices.
However, when using soft prices, this does have a mild effect.
To see this, consider that softsort employs row-wise softmax operations that replace the argmax used to indicate the sorting position.
Since scores for all entries are exponentiated, points with $u=0$ now contribute $e^0=1$ to the denominator. This biases outcomes, and becomes significant when there are many positively classified points.
% We found that positively-classified examples with negative $u$'s distort the softsort matrix entries by changing the sum of the softmax performed on each row.  
We circumvent this problem by simply
% zeroing those values minimizes the problem, but it was more effective
truncating all points with $u=0$ completely from the calculation.
% as they don't have an effect on the real price anyway. 



% \blue{%
% \paragraph{Approach.}
% Our solution will be to replace $\brmrkt_h$ with a differentiable approximate mapping,
% denoted $\brapx_h$, which will permit gradient-based optimization.
% This will require us to also replace exact market prices $\phatvec$ 
% with a `smooth' surrogate, denoted $\ptildevec$, that is also differentiable in the parameters of $h$.
% A useful property of our $\brapx_h$ will be that \emph{conditioned on prices},
% user responses decouple over training examples.
% Thus, we can treat the computation of prices as a black box,
% and adapt standard techniques from strategic learning to our purposes.
% Combining the above with appropriate choices of loss and regularization terms
% will give our final differentiable learning objective.
% We now turn to presenting each of the above components and discussing how they relate.
% % and how they operate jointly.
% % \squeeze

% % \todo{solution: (1) solve hard prices, (2) make differentiable; loss - extend s-hinge}

% \subsection{Differentiable market prices}
% Our first step is to make prices differentiable.
% One useful property of Algorithm~\ref{algo:exact_market_prices} is that each of its steps can be easily vectorized,
% and each atomic operation is either already differentiable,
% or can be made differentiable using existing smoothing methods.
% In particular, note that:
% (i) $\distance^+$ is a differentiable operator;
% (ii) $\sort$ can be implemented as a linear operator $\Pi$ with $\Pi_{ij}=1$ if item $i$ is in position $j$ and 0 otherwise; and
% (iii) $U$ can be computed using a cumulative sum,
% implemented as linear operator $C$ with entries $C_{ij}=\one{i \le j}$.
% The remaining non-differentiable operations are $\Pi$ and the argmax for choosing the revenue-maximizing point $i^*$.
% Thus, if we replace $\Pi$ with a differentiable softsort operator $\Pitilde$ 
% (e.g., using \citep{DBLP:journals/corr/abs-2006-16038})
% and the argmax with a softmax,
% then the entire algorithm becomes differentiable.
% These steps comprise Algorithm~\ref{algo:smooth_market_prices},
% which returns smoothed market prices $\ptildevec$ as an approximation to $\phatvec$.
% % The final differentiable market price vector is given by $\ptildevec = \ptilde w$.

% \todo{how we treat $u_i=0$ entries}

% In practice, we found it useful to normalize $\ubarvec$ 
% so that its smallest entry is 1.
% This is possible since market prices are insensitive to scale:
% if $\rhohat$ is optimal for $\ubarvec$, then for a scaled $\alpha \ubarvec$,
% the solution is $\frac{1}{\alpha} \rhohat$.
% Normalizing ensures that all temperature parameters (e.g., in softsort and softmax)
% operate at the same scale across all batches,
% which is important since the relation $\rho = b/u$ suggests that even mild perturbations to small $u$-s can cause large variation in computed prices.
% \yonatan{moved to appendix}
% % \squeeze

% \todo{implications of softsort and softmax; as expectations?}

% \todo{challenges (=why its actually not straightforward), and what we do about it}



% %=====================
% \input{algo_diff.tex}
% %=====================



% \subsection{Differentiable learning objective}

% Given our differentiable algorithm for computing $\rhotilde$,
% a straightforward next step would be to obtain $\brapx_h$ by plugging $\ptildevec=\rhotilde \cdot w / \|w\|$
% into a standard best-response mapping with linear costs, $\br_h^\ptildevec$.
% % replace $\phatvec$ with $\ptildevec$ in the objective, which would mean solving Eq.~\eqref{eq:empirical_objective} with $\br_h^\ptildevec$.
% While possible, the drawback is that $\br$ itself is non-differentiable.
% Luckily, this can be circumvented by adapting the \emph{strategic hinge loss} \citep{levanon2022generalized} to our purposes.
% For standard strategic classification with 2-norms costs,
% the strategic hinge loss is given by:
% \begin{equation}
% \label{eq:s-hinge}
% \shinge(x,y;h) = \max\{0, 1 - y(w^\top x + \thresh + 2\|w\|)\}
% \end{equation}
% Note $\shinge$ does not include $\br$ explicitly.
% Instead, it penalizes \emph{all} points according to the maximal moving distance, which is $2\|w\|$:
% this is the maximal admissible cost
% (for modifications $x \mapsto x'$ in which $h(x)=-1$ and $h(x')=1$),
% converted to margin units by (un)normalizing w.r.t. $\|w\|$.

% Eq.~\eqref{eq:s-hinge} assumes all points share the same maximal cost (i.e., 2).
% To extend $\shinge$ to our setting, the key observation is that budgets $\budget_i$ are by definition maximal costs, but \emph{individualized}.
% At price $\rho$, a user with budget $\budget_i$ can purchase at most $b_i/\rho$ units,
% where units are in terms of distance to the decision boundary.
% Hence, our \emph{market hinge loss} (or \emph{m-hinge}) is:
% \squeeze
% \begin{equation}
% \label{eq:m-hinge}
% \mhinge(x,y;h,\rho) = \max\{0, 1 - y(w^\top x + \thresh + \frac{b}{\rho}\|w\|)\}
% \end{equation}
% Note this requires only the scalar market price $\rho$,
% since the direction of movement $w$ is already implicit in the construction.
% Given $\rho$, Eq.~\eqref{eq:m-hinge} is applied to each example independently.
% Our final objective is obtained by plugging $\mhinge$,
% defined w.r.t. smooth market prices $\rhotilde$, 
% into Eq.~\eqref{eq:empirical_objective}.
% % This gives us our final learning objective.

% \todo{this works only because we know $p^h$ will be in the direction of $w$. 
% non-trivial! in fact, this doesn't work for a fixed $\p$, since then it would wrongly assume users move in an $\ell_2$ ball of radius $b/\rho$, whereas the actual $\Delta$ is linear in $\p$. }

% % \red{
% % - what should we be diff to? delta, prices, new points... ? \\
% % - answer: if we use s-hinge, then 1/p is like individualized cost or distance; don't need Delta explicitly
% % }

% \subsection{Optimization.}
% \todo{ \\%
%  -- SGD - mini-batches as stabilizing \\
%  -- regions with "traps" - how to overcome (TBD) \\
%  -- alternating between $w$ and $a$? \\
%  -- treating $a$ aggressively/pessimistically? \\ 
%  -- smooth prices actually help smooth objective too! \\
%  -- against jumpy prices: keep weighted average with decaying weights over previous prices
% }


% \todo{regularization?}
% }



%=======================================================



\section{Experimental details} \label{appx:exp_details}

\subsection{Data and preprocessing} \label{appx:data}

\paragraph{Data description.}
Our experiments make use of the \adult\ dataset.
This dataset contains features based on census data from the 1994 census database that describe demographic and financial data. There are \lotanadd{14 features,  8 of which are categorical and the others numerical}. 
The binary label is whether a person's income exceeds \$50k.
The dataset includes a total of 48,842 entries,
76\% of which are labeled as negative.
The data is publicly available at \url{https://archive.ics.uci.edu/dataset/2/adult}.

\paragraph{Preprocessing.}
To make the data appropriate to our strategic market setting,
we took the following steps.
First, all rows with missing values were removed (7.4\%).
Two features were excluded: \texttt{native\_country},
and \texttt{education}, which had perfect correlation with the numerical feature \texttt{education\_num}.
The feature \texttt{capital\_gain} was not used as input to the classifier,
but rather as the basis of determining budgets.
Second, to maintain class balance, 25\% of negative examples were randomly removed.
Finally, because behavior in strategic classification applies to continuous features, for our main experiment we dropped all categorical features.
These however were still used for constructing budgets (see below).
The remaining numerical features were normalized.

% \lotanadd{The preprocessing pipeline consists of the following steps:}
% \lotanadd{\begin{enumerate}
%     \item Rows with missing values (7.4\%) were removed.
%     % \item The target variable was encoded as follows: <50k to -1 and >=50k to 1.
%     \item The features \texttt{native\_country} and \texttt{education} were excluded. The latter was dropped due to a perfect correlation with the numerical feature \texttt{education\_num}.
%     \item The categorical feature occupation was grouped into five broader categories: \textit{Professional Managerial}, \textit{Skilled Technical}, \textit{Sales Administrative}, \textit{Service Care}, and \textit{Unclassified Occupations}.
%     \item Categorical features: \texttt{work\_class}, \texttt{marital\_status}, \texttt{occupation}, \texttt{relationship}, \texttt{race}, \texttt{sex}) were transformed using one-hot encoding.
%     \item Numerical features: (texttt{age}, \texttt{final\_weight}, \texttt{education\_num}, \texttt{capitol\_loss}, \texttt{hours\_per\_week}) were scaled using min-max normalization.
%     \item For training, only numerical features were used, and a subsample consisting of 25\% of the negative examples was selected to balance the labels.
% \end{enumerate}}

\paragraph{Budgets.}
\lotanadd{For budgets $b$, we chose to use the \texttt{capital\_gain} feature; of all features, this most closely related to an indication of wealth.
Unfortunately, only 8.5\% (3,561) of the entries in the data contained values that were not 0, 99999, or NaN.
As such, we decided to replace such missing or extreme entries with imputed values, for which we trained two random forest models (one per class) on the valid subset of the data.
Hyper-parameters for this process were chosen using a grid search with the following parameters:
\texttt{n\_estimators} $\in$ \{50, 100, 200\}, 
\texttt{max\_depth} $\in$ \{None, 10, 20, 30\},
\texttt{min\_samples\_split} $\in$ \{2, 5, 10\},
\texttt{min\_samples\_leaf} $\in$ \{1, 2, 4\},
5 folds, and $R^2$ scoring.
}
% \lotanadd{
% \begin{itemize}[leftmargin=2em,topsep=0.3em,itemsep=0.5em]
%     \item \texttt{n\_estimators} $\in$ \{50, 100, 200\}
%     \item \texttt{max\_depth} $\in$ \{None, 10, 20, 30\}
%     \item \texttt{min\_samples\_split} $\in$ \{2, 5, 10\}
%     \item \texttt{min\_samples\_leaf} $\in$ \{1, 2, 4\}
%     \item 5 folds
%     \item $R^2$ scoring
% \end{itemize}
% }
\lotanadd{All features were used during imputation.}
% \niradd{The final test accuracies were \todo{XXX} and \todo{XXX}.}
% \lotanadd{The $R^2$ scores were 0.19 for the positive examples and -0.05 for the negative examples.}
%rmse: pos - 3722.96, neg - 2433.53; range ~ 0-40k (negs?)
The normalized RMSE was $0.366$ for positives and $0.679$ for negatives.

\paragraph{Data splits.}
\lotanadd{ We used a train-validation-test split of 70:10:20 and averaged the results over 10 random data splits.
% The train set was shuffled after each epoch.
}

\subsection{Evaluation}

\yellow{
\paragraph{Baselines.}
\begin{itemize}
    \item
    \naivemthd: 
    \lotanadd{
    Conventional non-strategic model, trained using standard logistic regression model with scikit-learn.
    We used this both as a baseline (by testing on strategic market data)
    and as a benchmark (by testing on non-strategic data).
    }

    
    \item
    \strat: 
    \lotanadd{
    Strategic market-unaware model. The model determines a fixed price based on the validation set. It then optimizes the bias within the range $[\tau_{min}, \tau_{max}]$ using the training set and minimizing the market hinge loss. Finally, the model's accuracy is evaluated on the test set using the fixed price and adjusted bias.
    }

\end{itemize}
}


\paragraph{Metrics.}
% We consider several measures of performance and metrics:
In addition to accuracy, we measure the following metrics:

\begin{itemize}
\item
\textbf{Welfare:} Measures the profit (utility minus cost) for all users of the system as:
\begin{equation}
\label{eq:welfare}
\welfare(h) = \frac{1}{B}\sum_i \budget_i \one{h(x_i^h) = 1} - \cost(x_i,x_i^h)
\end{equation}

\item
\textbf{Social burden:} Measures the overall cost required to ensure that all deserving users (i.e., with $y=1$) rightfully obtain positive predictions ($\yhat=1$):
% \lotan{Burden was normalized using $\frac{1}{B}$, not $\frac{1}{P}$}
% \begin{equation}
% \label{eq:burden}
% \burden(h) = \frac{1}{B} \sum_{i:y_i=1} \min_{x':h(x')=1} \cost(x_i,x')
% \end{equation}
\lotanadd{
\begin{equation}
\label{eq:burden}
\burden(h) = \frac{1}{B_+} \sum_{i:y_i=1} \min_{x':h(x')=1} \cost(x_i,x')
\end{equation}
}
% with normalizing constant $P=|\{i\,:\,y_i=1\}|$.

\end{itemize}
Here $B=\sum_i b_i$ is the total budgets,
\lotanadd{and $B_+=\sum_{i:y_i=1} b_i$ is the total budget of the positive examples.}
Since the different experimental settings vary considerably in the distribution of budgets as well as its total,
normalizing by $B$ and $B_+$ permits meaningful comparisons across conditions.


\subsection{Training, tuning, and optimization} \label{appx:optimization}

\paragraph{Implementation.}
All code was implemented in python,
and the learning framework was implemented using Pytorch.

\paragraph{Optimization.}
Our overall approach is to optimize the objective in Eq.~\eqref{eq:empirical_objective} using gradient methods. In particular, we use \lotanadd{ADAM} with mini-batch updates ---see details below.
Additional decisions and considerations:
\begin{itemize}
\extended{%
\item \lotan{This was not implemented}
Since prices can change dramatically at the beginning of training, and since this can have a pronounced effect on the loss (since typically many points can cross),
we found it useful to use at each iteration prices that average between the current price and the price at the previous step, $\rho^t = \frac{\rhotilde+\rho^{t-1}}{2}$.
In effect, this means that at each step we use prices that are a weighted average over all previous time steps with exponentially decaying weights:
$\rho^t = \sum_{k<t}\frac{1}{2^k} \rho^{t-k}$.
}

\item
The softsort and softmax hyper-parameters are intended to facilitate differentiable prices. In general, tuning their parameters should seek to optimally trade off between how well they approximate `hard' sort and argmax, and the effectiveness of gradients.
However, particular to our market settings, we observed that they also contribute to smoothing out discontinuities that result from sharp transitions between market states,
i.e., cases where a mild change in prices causes a large change in the number of points that move and cross---which can significantly affect the loss.

\item 
Similarly, we observed that mini-batches also have a smoothing effect on the market.
This however related to a different aspect:
Since market prices $\rhohat$ correspond to the normalized demand of one of the data points $\ubar_i^{-1}$, prices in general can be sensitive to the particular sample on which they are computed. Another concern if a small change in learned parameters move some points $x$ from being slightly above the decision boundary to slightly below it. If this occurs, then this new point has $u$ that is positive but very small,
which can affect soft prices (despite our normalization step in Algorithm~\ref{algo:smooth_market_prices}) through the choice of hyperparameters.
Mini-batches help in this regard because they average out the effect that any single data point may have. They are also helpful in cases when several points `compete' over setting the price (i.e., entail similarly large revenue) by permitting $\rhotilde$ to express their (weighted) averaged.

\extended{%
\item \lotan{This was also not implemented}
In some experiments we observed that market-aware learning tends to favor solutions in which $\|w\|$ shrinks towards zero. This is enabled by our use of $L_2$ regularization,
but is nonetheless an undesirable outcome. The reason is that shrinking $\|w\|$ (while keeping $\thresh$ fixed) is in effect a means to increase the number of units required to cross the boundary without limit; this can be seen through Eq.~\eqref{eq:demand_as_distance}.%
\footnote{An alternative equivalent strategy would be to fix $\|w\|$ and increase $\thresh$, but this is not encouraged by regularization, and so is less likely.}
This solution works in cases where budgets are sufficiently correlated with labels so that increasing the number of required units to be exceedingly high enables only positive points to cross, and prevents this from negatives. This is possible when prices are driven to be sufficiently low (indeed, in practice we observed $\rhohat \to 0$).
To prevent this undesired artifact from materializing, we can impose the restriction that prices cannot go below a certain point (i.e., items cannot be sold for less than \$0.01), which is reasonable. An alternative is to assume that no user can purchase more than $K$ units of any item. But can be enforced by lower bounding $\|w\|$.
One way to achieve this is by stopping training before $\|w\|$ becomes too small.
Another is to replace the conventional $L_2$ regularizer with
$R(w)=\|w-\frac{\gamma}{\thresh}\|_2^2$ for some choice of $\gamma>0$.
}

\end{itemize}

% In order to reduce variance in the model's prices between iterations, we averaged each price calculated in the current epoch with the previously calculated price.

% -- against jumpy prices: keep weighted average with decaying weights over previous prices

% -- regularizing against small $\|w\|$

% -- minibatches as stabalizing
% -- smooth prices actually help smooth objective too! \\


\paragraph{Initialization.}
The model was initialized with the weights and bias term of the \naivemthd\ model. Notably, initializing it with randomly generated weights from a normal distribution had minimal impact on the results.


\paragraph{Hyperparameters.}
We used the following hyperparameters:
\begin{itemize}[leftmargin=1em,topsep=0em,itemsep=0.1em]
\item 
Temperature $\tau_\mathrm{softsort}$  for the softsort operator: \lotanadd{0.001}

\item 
Temperature $\tau_\mathrm{softmax}$  for the softmax operator: \lotanadd{0.01}

\item 
Batch size: \lotanadd{500}

\item Learning rate: \lotanadd{
    \begin{itemize}
    \item 0.001 for \texttt{budget\_scale} $\in$ [1, 32]
    \item 0.01 for \texttt{budget\_scale} $\in$ [64, 1024]
    \end{itemize}
}

\item Regularization and coefficient: \lotanadd{0.1}

\item \lotanadd{Epochs: 100}

\end{itemize}

Hyperparameters were chosen by standard hyperparameter search over a grid of possible combinations and were chosen based on performance on a \lotanadd{validation} set along with considerations for reasonable convergance times.

