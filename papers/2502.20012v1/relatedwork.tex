\section{Related work}
\label{sec:related}


\paragraph{Strategic classification.}
The field of strategic classification \citep{bruckner2012static,hardt2016strategic}
has gained much recent interest.
\extended{This has led to many advances both in theory \citep{sundaram2021pac,zhang2021incentive}
and in practice \citep{levanon2021strategic}.}%
% Strategic classification succinctly captures a natural tension that exists between learning systems and their users, but this requires making
The original formulation includes several strong assumptions, in particular regarding costs, which subsequent works have challenged or relaxed.
% In response, several works have attempted to challenge these assumptions.% and extend beyond them.
One line of research considers learning under unknown (but nonetheless fixed) costs,
including in the online \citep{dong2018strategic,ahmadi2021strategic},
multi-round batch \citep{lechner2023strategic},
and one-shot \citep{rosenfeld2024oneshot} settings;
under personalized costs \citep{lechner2023strategic,shao2024strategic}
and for general manipulation graphs
\citep{ahmadi2023fundamental,cohen2024learnability}. %; %,ahmadi2024strategic},
\extended{or in a field experiment \citep{bjorkegren2020manipulation}.}%
A related thread relaxes assumptions on user-side information,
but focuses on uncertainty regarding the classifier rather than costs
\citep{ghalme2021strategic,bechavod2022information,barsotti2022transparency}.
Another assumption is that users respond independently;
% ---in part since costs apply per user.
this has been relaxed by injecting dependencies through the utility function in a ranking task \citep{liu2022strategic},
or through the model class by making use of a network structure over users 
\citep{eilat2023strategic}.
In a recent work, \citet{chen2024strategic} augment the cost function to include externalities, which entail dependencies.
%  as a Stacklberg-Nash game \citep{xu2016methodology}.
Our work proposes that user behavior becomes dependent through a market mechanism
in which demand, and therefore prices, derive from the classifier.

\extended{scext - update to iclr}

% which coordinates supply and demand as is determined by the classifier.


% (un)known:
% darksc etc
% scuc - robustness, sensitive to misestimation
% infer costsindic costs

% decompose:
% stratgnn
% externalities
% stack-nash [haifeng]

% predetermined:
% - ..?
% - ours - c depends on h



\paragraph{Learning and markets.}
% Recent work has considered the role of learning in distinct market settings, such as recommendation systems and digital marketplaces,
% % Here users seek items that match their preferences,
% in which service providers compete over users by better learning their preferences.
% This leads to interesting questions regarding the role of learning and data in determining market outcomes.
% For example,
% \citet{guo2022learning}
% study online learning algorithms that enable efficient and fair competitive equilibrium.
% Conversely,
% \citet{jagadeesan2023competition}
% show that market outcomes under competition 
% do not necessarily align with user utility at equilibrium.
% Our setting is quite distinct:
% competition is between sellers (rather than platforms),
% users seek positive predictions (rather than useful recommendations),
% % have simple homogeneous preferences,
% and learning \emph{forms} a market (rather than supports it).
A large literature considers markets for data
\citep[e.g.,][]{agarwal2019marketplace,ghorbani2019data,chen2022selling}
or trained models \citep[e.g.,][]{chen2019towards,huang2023train}.
A recent line of work studies competition between platforms or service providers
\citep{ben2017best,ben2019regression,guo2022learning,jagadeesan2023competition,jagadeesan2024improved,shekhtman2024strategic}.
Here learning is used to elicit user preferences, e.g. towards making useful recommendations.
\extended{\citep{hron2023modeling,eilat2023performative}}%
In contrast, our setting considers how learning \emph{creates} a market, where the commodity is features.
% the formation of markets for features.
\extended{The idea that features can be a scare resource has been suggested in
\citet{nahum2024decongestion}, 
but in a very different setting in which the learner controls features to decongest a conventional market.}%
% but in an explicit market setting and for very different reasons.
Closer to ours in spirit, 
\citet{hardt2022performative} measure the power of learning to shape outcomes through predictions
that cause a distribution shift.
However, they target a general performative setting in which neither a market nor user incentives are explicitly modeled.
\citet{epasto2018incentive}
study data-driven algorithms for mechanism design (e.g., auctions)
in which rational agents can misreport information (e.g., bid untruthfully).
Interestingly, they conclude that learning a mechanism is possible if misreporting bears a cost to users---as in strategic classification.

\extended{%
\red{%
- fairness: \\
--- social burden \\
--- interaction between strategic behavior and fairness constraints
[Fairness Interventions as (Dis)Incentives for Strategic Manipulation] \\
--- ours is monetary \\
- [AN ECONOMIC APPROACH TO REGULATING ALGORITHMS] - propose to study algorithmic bias from welfare econ perspective to reduce and regulate discrimination. \\
- Computing equilibrium prices;
ours is unique in that utility is not strongly increasing, but is binary prediction \\
- differentiable objective; ref our sc papers?
}
}