@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{tang2023video,
  title={Video understanding with large language models: A survey},
  author={Tang, Yunlong and Bi, Jing and Xu, Siting and Song, Luchuan and Liang, Susan and Wang, Teng and Zhang, Daoan and An, Jie and Lin, Jingyang and Zhu, Rongyi and others},
  journal={arXiv preprint arXiv:2312.17432},
  year={2023}
}

@article{wang2023cogvlm,
  title={Cogvlm: Visual expert for pretrained language models},
  author={Wang, Weihan and Lv, Qingsong and Yu, Wenmeng and Hong, Wenyi and Qi, Ji and Wang, Yan and Ji, Junhui and Yang, Zhuoyi and Zhao, Lei and Song, Xixuan and others},
  journal={arXiv preprint arXiv:2311.03079},
  year={2023}
}

@article{thoppilan2022lamda,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}


@article{mishra2021cross,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2104.08773},
  year={2021}
}
@article{conover2023free,
  title={Free dolly: Introducing the worldâ€™s first truly open instruction-tuned llm},
  author={Conover, Mike and Hayes, Matt and Mathur, Ankit and Xie, Jianwei and Wan, Jun and Shah, Sam and Ghodsi, Ali and Wendell, Patrick and Zaharia, Matei and Xin, Reynold},
  journal={Company Blog of Databricks},
  year={2023}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@inproceedings{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  booktitle={International Conference on Machine Learning},
  pages={22631--22648},
  year={2023},
  organization={PMLR}
}

@article{aw2023instruction,
  title={Instruction-tuning Aligns LLMs to the Human Brain},
  author={Aw, Khai Loong and Montariol, Syrielle and AlKhamissi, Badr and Schrimpf, Martin and Bosselut, Antoine},
  journal={arXiv preprint arXiv:2312.00575},
  year={2023}
}

@article{zhang2023instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}


@inproceedings{han2024onellm,
  title={Onellm: One framework to align all modalities with language},
  author={Han, Jiaming and Gong, Kaixiong and Zhang, Yiyuan and Wang, Jiaqi and Zhang, Kaipeng and Lin, Dahua and Qiao, Yu and Gao, Peng and Yue, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26584--26595},
  year={2024}
}


@inproceedings{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={19730--19742},
  year={2023},
  organization={PMLR}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}


@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@article{xu2023pointllm,
  title={Pointllm: Empowering large language models to understand point clouds},
  author={Xu, Runsen and Wang, Xiaolong and Wang, Tai and Chen, Yilun and Pang, Jiangmiao and Lin, Dahua},
  journal={arXiv preprint arXiv:2308.16911},
  year={2023}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}


@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{yu2022coca,
  title={Coca: Contrastive captioners are image-text foundation models},
  author={Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  journal={arXiv preprint arXiv:2205.01917},
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{huang2024brainchat,
  title={BrainChat: Decoding Semantic Information from {fMRI} using Vision-language Pretrained Models},
  author={Huang, Wanaiu},
  journal={arXiv preprint arXiv:2406.07584},
  year={2024}
}



@inproceedings{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andy and Vinyals, Oriol and Zisserman, Andrew and Carreira, Joao},
  booktitle={International conference on machine learning},
  pages={4651--4664},
  year={2021},
  organization={PMLR}
}


@article{xia2024umbrae,
  title={UMBRAE: Unified Multimodal Decoding of Brain Signals},
  author={Xia, Weihao and de Charette, Raoul and {\"O}ztireli, Cengiz and Xue, Jing-Hao},
  journal={arXiv preprint arXiv:2404.07202},
  year={2024}
}

@article{ren2015exploring,
  title={Exploring models and data for image question answering},
  author={Ren, Mengye and Kiros, Ryan and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={International journal of computer vision},
  volume={123},
  pages={32--73},
  year={2017},
  publisher={Springer}
}


@article{chen2023mindgpt,
  title={Mindgpt: Interpreting what you see with non-invasive brain recordings},
  author={Chen, Jiaxuan and Qi, Yu and Wang, Yueming and Pan, Gang},
  journal={arXiv preprint arXiv:2309.15729},
  year={2023}
}


@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{marino2019ok,
  title={Ok-vqa: A visual question answering benchmark requiring external knowledge},
  author={Marino, Kenneth and Rastegari, Mohammad and Farhadi, Ali and Mottaghi, Roozbeh},
  booktitle={Proceedings of the IEEE/cvf conference on computer vision and pattern recognition},
  pages={3195--3204},
  year={2019}
}

@inproceedings{biten2019scene,
  title={Scene text visual question answering},
  author={Biten, Ali Furkan and Tito, Ruben and Mafla, Andres and Gomez, Lluis and Rusinol, Mar{\c{c}}al and Valveny, Ernest and Jawahar, CV and Karatzas, Dimosthenis},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={4291--4301},
  year={2019}
}

@inproceedings{acharya2019tallyqa,
  title={TallyQA: Answering complex counting questions},
  author={Acharya, Manoj and Kafle, Kushal and Kanan, Christopher},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={8076--8084},
  year={2019}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@inproceedings{li2018vqa,
  title={Vqa-e: Explaining, elaborating, and enhancing your answers for visual questions},
  author={Li, Qing and Tao, Qingyi and Joty, Shafiq and Cai, Jianfei and Luo, Jiebo},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={552--567},
  year={2018}
}

@article{liu2023visual,
  title={Visual spatial reasoning},
  author={Liu, Fangyu and Emerson, Guy and Collier, Nigel},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={635--651},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}

@inproceedings{schwenk2022okvqa,
  title={A-okvqa: A benchmark for visual question answering using world knowledge},
  author={Schwenk, Dustin and Khandelwal, Apoorv and Clark, Christopher and Marino, Kenneth and Mottaghi, Roozbeh},
  booktitle={European conference on computer vision},
  pages={146--162},
  year={2022},
  organization={Springer}
}

@article{chen2015microsoft,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}

@article{allen2022massive,
  title={A massive 7T {fMRI} dataset to bridge cognitive neuroscience and artificial intelligence},
  author={Allen, Emily J and St-Yves, Ghislain and Wu, Yihan and Breedlove, Jesse L and Prince, Jacob S and Dowdle, Logan T and Nau, Matthias and Caron, Brad and Pestilli, Franco and Charest, Ian and others},
  journal={Nature neuroscience},
  volume={25},
  number={1},
  pages={116--126},
  year={2022},
  publisher={Nature Publishing Group US New York}
}

@article{scotti2024reconstructing,
  title={Reconstructing the mind's eye: {fMRI}-to-image with contrastive learning and diffusion priors},
  author={Scotti, Paul and Banerjee, Atmadeep and Goode, Jimmie and Shabalin, Stepan and Nguyen, Alex and Dempster, Aidan and Verlinde, Nathalie and Yundler, Elad and Weisberg, David and Norman, Kenneth and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{scotti2024mindeye2,
  title={MindEye2: Shared-Subject Models Enable {fMRI}-To-Image With 1 Hour of Data},
  author={Scotti, Paul S and Tripathy, Mihir and Villanueva, Cesar Kadir Torrico and Kneeland, Reese and Chen, Tong and Narang, Ashutosh and Santhirasegaran, Charan and Xu, Jonathan and Naselaris, Thomas and Norman, Kenneth A and others},
  journal={arXiv preprint arXiv:2403.11207},
  year={2024}
}

@article{wang2024unibrain,
  title={UniBrain: A Unified Model for Cross-Subject Brain Decoding},
  author={Wang, Zicheng and Zhao, Zhen and Zhou, Luping and Nachev, Parashkev},
  journal={arXiv preprint arXiv:2412.19487},
  year={2024}
}

@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}

@inproceedings{qiu2023learning,
  title={Learning High-Order Relationships of Brain Regions},
  author={Qiu, Weikang and Chu, Huangrui and Wang, Selena and Zuo, Haolan and Li, Xiaoxiao and Zhao, Yize and Ying, Rex},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2023}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{shin2016color,
  title={The color of the cat is gray: 1 million full-sentences visual question answering (fsvqa)},
  author={Shin, Andrew and Ushiku, Yoshitaka and Harada, Tatsuya},
  journal={arXiv preprint arXiv:1609.06657},
  year={2016}
}

@article{murahari2019improving,
  title={Improving generative visual dialog by answering diverse questions},
  author={Murahari, Vishvak and Chattopadhyay, Prithvijit and Batra, Dhruv and Parikh, Devi and Das, Abhishek},
  journal={arXiv preprint arXiv:1909.10470},
  year={2019}
}

@article{wang2023see,
  title={To see is to believe: Prompting gpt-4v for better visual instruction tuning},
  author={Wang, Junke and Meng, Lingchen and Weng, Zejia and He, Bo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.07574},
  year={2023}
}
@inproceedings{krause2017hierarchical,
  title={A hierarchical approach for generating descriptive image paragraphs},
  author={Krause, Jonathan and Johnson, Justin and Krishna, Ranjay and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={317--325},
  year={2017}
}

@article{graham2019artificial,
  title={Artificial intelligence for mental health and mental illnesses: an overview},
  author={Graham, Sarah and Depp, Colin and Lee, Ellen E and Nebeker, Camille and Tu, Xin and Kim, Ho-Cheol and Jeste, Dilip V},
  journal={Current psychiatry reports},
  volume={21},
  pages={1--18},
  year={2019},
  publisher={Springer}
}

@inproceedings{takagi2023high,
  title={High-resolution image reconstruction with latent diffusion models from human brain activity},
  author={Takagi, Yu and Nishimoto, Shinji},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14453--14463},
  year={2023}
}

@article{mai2023unibrain,
  title={Unibrain: Unify image reconstruction and captioning all in one diffusion model from human brain activity},
  author={Mai, Weijian and Zhang, Zhijun},
  journal={arXiv preprint arXiv:2308.07428},
  year={2023}
}

@article{ferrante2023brain,
  title={Brain Captioning: Decoding human brain activity into images and text},
  author={Ferrante, Matteo and Ozcelik, Furkan and Boccato, Tommaso and VanRullen, Rufin and Toschi, Nicola},
  journal={arXiv preprint arXiv:2305.11560},
  year={2023}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}

@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14},
  pages={382--398},
  year={2016},
  organization={Springer}
}

@inproceedings{banerjee2005meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@article{chen2023shikra,
  title={Shikra: Unleashing multimodal llm's referential dialogue magic},
  author={Chen, Keqin and Zhang, Zhao and Zeng, Weili and Zhang, Richong and Zhu, Feng and Zhao, Rui},
  journal={arXiv preprint arXiv:2306.15195},
  year={2023}
}

@book{lacan2001ecrits,
  title={Ecrits: A selection},
  author={Lacan, Jacques},
  year={2001},
  publisher={Routledge}
}

@inproceedings{wang2024mindbridge,
  title={Mindbridge: A cross-subject brain decoding framework},
  author={Wang, Shizun and Liu, Songhua and Tan, Zhenxiong and Wang, Xinchao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11333--11342},
  year={2024}
}

@article{de2004course,
  title={Course in general linguistics},
  author={De Saussure, Ferdinand},
  journal={Literary theory: An anthology},
  volume={2},
  pages={59--71},
  year={2004},
  publisher={Singapore: Blackwell Publishing}
}

@book{miller2018four,
  title={The four fundamental concepts of psycho-analysis},
  author={Miller, Jacques Alain and Lacan, Jacques},
  year={2018},
  publisher={Routledge}
}

@book{lacan1988seminar,
  title={The Seminar of Jacques Lacan},
  author={Lacan, Jacques},
  year={1988},
  publisher={WW Norton \& Company}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@article{zhang2023video,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}

@article{cheng2024videollama,
  title={VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs},
  author={Cheng, Zesen and Leng, Sicong and Zhang, Hang and Xin, Yifei and Li, Xin and Chen, Guanzheng and Zhu, Yongxin and Zhang, Wenqi and Luo, Ziyang and Zhao, Deli and others},
  journal={arXiv preprint arXiv:2406.07476},
  year={2024}
}

@article{kondratyuk2023videopoet,
  title={Videopoet: A large language model for zero-shot video generation},
  author={Kondratyuk, Dan and Yu, Lijun and Gu, Xiuye and Lezama, Jos{\'e} and Huang, Jonathan and Schindler, Grant and Hornung, Rachel and Birodkar, Vighnesh and Yan, Jimmy and Chiu, Ming-Chang and others},
  journal={arXiv preprint arXiv:2312.14125},
  year={2023}
}

@inproceedings{chen2024spatialvlm,
  title={Spatialvlm: Endowing vision-language models with spatial reasoning capabilities},
  author={Chen, Boyuan and Xu, Zhuo and Kirmani, Sean and Ichter, Brain and Sadigh, Dorsa and Guibas, Leonidas and Xia, Fei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14455--14465},
  year={2024}
}

@article{zhang2023internlm,
  title={Internlm-xcomposer: A vision-language large model for advanced text-image comprehension and composition},
  author={Zhang, Pan and Dong, Xiaoyi and Wang, Bin and Cao, Yuhang and Xu, Chao and Ouyang, Linke and Zhao, Zhiyuan and Duan, Haodong and Zhang, Songyang and Ding, Shuangrui and others},
  journal={arXiv preprint arXiv:2309.15112},
  year={2023}
}

@inproceedings{qi2025shapellm,
  title={Shapellm: Universal 3d object understanding for embodied interaction},
  author={Qi, Zekun and Dong, Runpei and Zhang, Shaochen and Geng, Haoran and Han, Chunrui and Ge, Zheng and Yi, Li and Ma, Kaisheng},
  booktitle={European Conference on Computer Vision},
  pages={214--238},
  year={2025},
  organization={Springer}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya O and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={24261--24272},
  year={2021}
}

@article{wang2022git,
  title={Git: A generative image-to-text transformer for vision and language},
  author={Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan},
  journal={arXiv preprint arXiv:2205.14100},
  year={2022}
}

@article{card2024accurate,
  title={An accurate and rapidly calibrating speech neuroprosthesis},
  author={Card, Nicholas S and Wairagkar, Maitreyee and Iacobacci, Carrina and Hou, Xianda and Singer-Clark, Tyler and Willett, Francis R and Kunz, Erin M and Fan, Chaofei and Vahdati Nia, Maryam and Deo, Darrel R and others},
  journal={New England Journal of Medicine},
  volume={391},
  number={7},
  pages={609--618},
  year={2024},
  publisher={Mass Medical Soc}
}

@article{bernal2022brain,
  title={When brain-computer interfaces meet the metaverse: Landscape, demonstrator, trends, challenges, and concerns},
  author={Bernal, Sergio L{\'o}pez and P{\'e}rez, Mario Quiles and Beltr{\'a}n, Enrique Tom{\'a}s Mart{\'\i}nez and P{\'e}rez, Gregorio Mart{\'\i}nez and Celdr{\'a}n, Alberto Huertas},
  journal={arXiv preprint arXiv:2212.03169},
  year={2022}
}

@article{rolls2020automated,
  title={Automated anatomical labelling atlas 3},
  author={Rolls, Edmund T and Huang, Chu-Chung and Lin, Ching-Po and Feng, Jianfeng and Joliot, Marc},
  journal={Neuroimage},
  volume={206},
  pages={116189},
  year={2020},
  publisher={Elsevier}
}

@article{glasser2016multi,
  title={A multi-modal parcellation of human cerebral cortex},
  author={Glasser, Matthew F and Coalson, Timothy S and Robinson, Emma C and Hacker, Carl D and Harwell, John and Yacoub, Essa and Ugurbil, Kamil and Andersson, Jesper and Beckmann, Christian F and Jenkinson, Mark and others},
  journal={Nature},
  volume={536},
  number={7615},
  pages={171--178},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{li2021braingnn,
  title={Braingnn: Interpretable brain graph neural network for {fMRI} analysis},
  author={Li, Xiaoxiao and Zhou, Yuan and Dvornek, Nicha and Zhang, Muhan and Gao, Siyuan and Zhuang, Juntang and Scheinost, Dustin and Staib, Lawrence H and Ventola, Pamela and Duncan, James S},
  journal={Medical Image Analysis},
  volume={74},
  pages={102233},
  year={2021},
  publisher={Elsevier}
}

@article{kan2022brain,
  title={Brain network transformer},
  author={Kan, Xuan and Dai, Wei and Cui, Hejie and Zhang, Zilong and Guo, Ying and Yang, Carl},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25586--25599},
  year={2022}
}

@article{du2022fmri,
  title={{fMRI} brain decoding and its applications in brain--computer interface: A survey},
  author={Du, Bing and Cheng, Xiaomu and Duan, Yiping and Ning, Huansheng},
  journal={Brain Sciences},
  volume={12},
  number={2},
  pages={228},
  year={2022},
  publisher={MDPI}
}

@article{luo2023brainscuba,
  title={BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity},
  author={Luo, Andrew F and Henderson, Margaret M and Tarr, Michael J and Wehbe, Leila},
  journal={arXiv preprint arXiv:2310.04420},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}

@inproceedings{kafle2017analysis,
  title={An Analysis of Visual Question Answering Algorithms},
  author={Kafle, Kushal and Kanan, Christopher},
  booktitle={ICCV},
  year={2017}
}

@article{han2024coco,
  title={COCO is" ALL''You Need for Visual Instruction Fine-tuning},
  author={Han, Xiaotian and Wang, Yiqi and Zhai, Bohan and You, Quanzeng and Yang, Hongxia},
  journal={arXiv preprint arXiv:2401.08968},
  year={2024}
}

@article{fellous2019explainable,
  title={Explainable artificial intelligence for neuroscience: behavioral neurostimulation},
  author={Fellous, Jean-Marc and Sapiro, Guillermo and Rossi, Andrew and Mayberg, Helen and Ferrante, Michele},
  journal={Frontiers in neuroscience},
  volume={13},
  pages={1346},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{farahani2022explainable,
  title={Explainable AI: A review of applications to neuroimaging data},
  author={Farahani, Farzad V and Fiok, Krzysztof and Lahijanian, Behshad and Karwowski, Waldemar and Douglas, Pamela K},
  journal={Frontiers in neuroscience},
  volume={16},
  pages={906290},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{epstein1999parahippocampal,
  title={The parahippocampal place area: recognition, navigation, or encoding?},
  author={Epstein, Russell and Harris, Alison and Stanley, Damian and Kanwisher, Nancy},
  journal={Neuron},
  volume={23},
  number={1},
  pages={115--125},
  year={1999},
  publisher={Elsevier}
}

@article{kohler2002differential,
  title={Differential contributions of the parahippocampal place area and the anterior hippocampus to human memory for scenes},
  author={K{\"o}hler, Stefan and Crane, Joelle and Milner, Brenda},
  journal={Hippocampus},
  volume={12},
  number={6},
  pages={718--723},
  year={2002},
  publisher={Wiley Online Library}
}

@article{bar2008scenes,
  title={Scenes unseen: the parahippocampal cortex intrinsically subserves contextual associations, not scenes or places per se},
  author={Bar, Moshe and Aminoff, Elissa and Schacter, Daniel L},
  journal={Journal of Neuroscience},
  volume={28},
  number={34},
  pages={8539--8544},
  year={2008},
  publisher={Soc Neuroscience}
}

@article{epstein2010reliable,
  title={How reliable are visual context effects in the parahippocampal place area?},
  author={Epstein, Russell A and Ward, Emily J},
  journal={Cerebral Cortex},
  volume={20},
  number={2},
  pages={294--303},
  year={2010},
  publisher={Oxford University Press}
}

@article{schultz2003role,
  title={The role of the fusiform face area in social cognition: implications for the pathobiology of autism},
  author={Schultz, Robert T and Grelotti, David J and Klin, Ami and Kleinman, Jamie and Van der Gaag, Christiaan and Marois, Ren{\'e} and Skudlarski, Pawel},
  journal={Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
  volume={358},
  number={1430},
  pages={415--427},
  year={2003},
  publisher={The Royal Society}
}

@article{tsantani2021ffa,
  title={FFA and OFA encode distinct types of face identity information},
  author={Tsantani, Maria and Kriegeskorte, Nikolaus and Storrs, Katherine and Williams, Adrian Lloyd and McGettigan, Carolyn and Garrido, L{\'u}cia},
  journal={Journal of Neuroscience},
  volume={41},
  number={9},
  pages={1952--1969},
  year={2021},
  publisher={Soc Neuroscience}
}

@article{xu2005revisiting,
  title={Revisiting the role of the fusiform face area in visual expertise},
  author={Xu, Yaoda},
  journal={Cerebral Cortex},
  volume={15},
  number={8},
  pages={1234--1242},
  year={2005},
  publisher={Oxford University Press}
}

@article{urgesi2007representation,
  title={Representation of body identity and body actions in extrastriate body area and ventral premotor cortex},
  author={Urgesi, Cosimo and Candidi, Matteo and Ionta, Silvio and Aglioti, Salvatore M},
  journal={Nature neuroscience},
  volume={10},
  number={1},
  pages={30--31},
  year={2007},
  publisher={Nature Publishing Group US New York}
}

@article{amoruso2011beyond,
  title={Beyond Extrastriate Body Area (EBA) and Fusiform Body Area (FBA): context integration in the meaning of actions},
  author={Amoruso, Luc{\'\i}a and Couto, Blas and Ibanez, Agustin},
  journal={Frontiers in Human Neuroscience},
  volume={5},
  pages={124},
  year={2011},
  publisher={Frontiers Research Foundation}
}

@article{carey2019distinct,
  title={Distinct neural response to visual perspective and body size in the extrastriate body area},
  author={Carey, Mark and Knight, Ruth and Preston, Catherine},
  journal={Behavioural Brain Research},
  volume={372},
  pages={112063},
  year={2019},
  publisher={Elsevier}
}

@article{connolly2016coding,
  title={Coding of attention across the human intraparietal sulcus},
  author={Connolly, Jason D and Kentridge, Robert W and Cavina-Pratesi, Cristiana},
  journal={Experimental brain research},
  volume={234},
  pages={917--930},
  year={2016},
  publisher={Springer}
}

@article{golarai2007differential,
  title={Differential development of high-level visual cortex correlates with category-specific recognition memory},
  author={Golarai, Golijeh and Ghahremani, Dara G and Whitfield-Gabrieli, Susan and Reiss, Allan and Eberhardt, Jennifer L and Gabrieli, John DE and Grill-Spector, Kalanit},
  journal={Nature neuroscience},
  volume={10},
  number={4},
  pages={512--522},
  year={2007},
  publisher={Nature Publishing Group US New York}
}

@article{ranganath2004category,
  title={Category-specific modulation of inferior temporal activity during working memory encoding and maintenance},
  author={Ranganath, Charan and DeGutis, Joe and D'Esposito, Mark},
  journal={Cognitive Brain Research},
  volume={20},
  number={1},
  pages={37--45},
  year={2004},
  publisher={Elsevier}
}

@article{brewer1998making,
  title={Making memories: brain activity that predicts how well visual experience will be remembered},
  author={Brewer, James B and Zhao, Zuo and Desmond, John E and Glover, Gary H and Gabrieli, John DE},
  journal={Science},
  volume={281},
  number={5380},
  pages={1185--1187},
  year={1998},
  publisher={American Association for the Advancement of Science}
}

@article{tunik2007beyond,
  title={Beyond grasping: representation of action in human anterior intraparietal sulcus},
  author={Tunik, Eugene and Rice, Nichola J and Hamilton, Antonia and Grafton, Scott T},
  journal={Neuroimage},
  volume={36},
  pages={T77--T86},
  year={2007},
  publisher={Elsevier}
}

@article{jiang2024mindshot,
  title={MindShot: Brain Decoding Framework Using Only One Image},
  author={Jiang, Shuai and Meng, Zhu and Liu, Delong and Li, Haiwen and Su, Fei and Zhao, Zhicheng},
  journal={arXiv preprint arXiv:2405.15278},
  year={2024}
}

@article{robertson2002memory,
  title={Memory and the brain},
  author={Robertson, Lee T},
  journal={Journal of dental education},
  volume={66},
  number={1},
  pages={30--42},
  year={2002},
  publisher={Wiley Online Library}
}

@book{stenning2012human,
  title={Human reasoning and cognitive science},
  author={Stenning, Keith and Van Lambalgen, Michiel},
  year={2012},
  publisher={MIT Press}
}

@book{friederici2017language,
  title={Language in our brain: The origins of a uniquely human capacity},
  author={Friederici, Angela D},
  year={2017},
  publisher={MIT Press}
}

@book{wade2013visual,
  title={Visual perception: An introduction},
  author={Wade, Nicholas and Swanston, Mike},
  year={2013},
  publisher={Psychology Press}
}

@article{hmamouche2024multimodal,
  title={A multimodal LLM for the non-invasive decoding of spoken text from brain recordings},
  author={Hmamouche, Youssef and Chihab, Ismail and Kdouri, Lahoucine and Seghrouchni, Amal El Fallah},
  journal={arXiv preprint arXiv:2409.19710},
  year={2024}
}