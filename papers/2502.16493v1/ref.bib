@inproceedings{Tran2014LearningSF,
  title={Learning Spatiotemporal Features with 3D Convolutional Networks},
  author={Du Tran and Lubomir D. Bourdev and Rob Fergus and Lorenzo Torresani and Manohar Paluri},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2014},
  pages={4489-4497}
}

@inproceedings{Carreira2017QuoVA,
  title={Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset},
  author={Jo{\~a}o Carreira and Andrew Zisserman},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2017},
  pages={4724-4733}
}
@ARTICLE{Cheng2022,
  author={Cheng, Jun and Ren, Ziliang and Zhang, Qieshi and Gao, Xiangyang and Hao, Fusheng},
  journal={IEEE Trans. Circuits Syst. Video Technol.}, 
  title={Cross-Modality Compensation Convolutional Neural Networks for RGB-D Action Recognition}, 
  year={2022},
  volume={32},
  number={3},
  pages={1498-1509},
  %doi={10.1109/TCSVT.2021.3076165}}
  
@article{Ma2024MultiViewTH,
  title={Multi-View Time-Series Hypergraph Neural Network for Action Recognition},
  author={Nan Ma and Zhixuan Wu and Yifan Feng and Cheng Wang and Yue Gao},
  journal={IEEE Trans. lmage Process.},
  year={2024},
  volume={33},
  pages={3301-3313},
  %doi={10.1109/TIP.2024.3391913}
}
@article{Gao2024HypergraphBasedMA,
  title={Hypergraph-Based Multi-View Action Recognition Using Event Cameras},
  author={Yue Gao and Jiaxuan Lu and Siqi Li and Yipeng Li and Shaoyi Du},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2024},
  volume={46},
  pages={6610-6622},
}
@article{LIU2024Temporal,
    title = {Temporal cues enhanced multimodal learning for action recognition in RGB-D videos},
    journal = {Neurocomputing},
    volume = {594},
    pages = {127882},
    year = {2024},
    author = {Dan Liu and Fanrong Meng and Qing Xia and Zhiyuan Ma and Jinpeng Mi and Yan Gan and Mao Ye and Jianwei Zhang},
    }
@article{Zou2022SnipperAS,
  title={Snipper: A Spatiotemporal Transformer for Simultaneous Multi-Person 3D Pose Estimation Tracking and Forecasting on a Video Snippet},
  author={Shihao Zou and Yuanlu Xu and Chao Li and Lingni Ma and Li Cheng and Minh Vo},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  year={2023},
  volume={33},
  number={9},
  pages={4921-4933},
}
@article{Zhang2024VideoCM,
  title={Video Corpus Moment Retrieval via Deformable Multigranularity Feature Fusion and Adversarial Training},
  author={Xuemei Zhang and Peng Zhao and Jinsheng Ji and Xiankai Lu and Yilong Yin},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  year={2024},
  volume={34},
    number={8},
  pages={6686-6698},
}
@ARTICLE{Shao2021Learning,
  author={Shao, Zhanpeng and Li, Youfu and Zhang, Hong},
  journal={IEEE Trans. Circuits Syst. Video Technol.}, 
  title={Learning Representations From Skeletal Self-Similarities for Cross-View Action Recognition}, 
  year={2021},
  volume={31},
  number={1},
  pages={160-174},
  }
 
@article{Wu2024MotionCA,
  title={Motion Complement and Temporal Multifocusing for Skeleton-Based Action Recognition},
  author={Cong Wu and Xiaojun Wu and Tianyang Xu and Zhongwei Shen and Josef Kittler},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  year={2024},
  volume={34},
  pages={34-45},
}
@article{Li2024ScaleAwareGC,
      title={Scale-Aware Graph Convolutional Network With Part-Level Refinement for Skeleton-Based Human Action Recognition},
      author={Chang Li and Yingchi Mao and Qian Huang and Xiaowei Zhu and Jie Wu},
      journal={IEEE Trans. Circuits Syst. Video Technol.},
      year={2024},
      volume={34},
      number={6},
      pages={4311-4324}
      }
@article{Zhang2024SiTMLP,
      title={SiT-MLP: A Simple MLP With Point-Wise Topology Feature Learning for Skeleton-Based Action Recognition},
      author={Shaojie Zhang and Jianqin Yin and Yonghao Dang and Jiajun Fu},
      journal={IEEE Trans. Circuits Syst. Video Technol.},
      year={2024},
      volume={34},
      pages={8122-8134}
      }
@article{Pan2023ViewNormalized,
      title={View-Normalized and Subject-Independent Skeleton Generation for Action Recognition},
      author={Qingzhe Pan and Zhifu Zhao and Xuemei Xie and Jianan Li and Yuhan Cao and Guangming Shi},
      journal={IEEE Trans. Circuits Syst. Video Technol.},
      year={2023},
      volume={33},
       number={12},
      pages={7398-7412},
      %doi={10.1109/TCSVT.2022.3219864}
      }
@ARTICLE{Rahmani2018Learning,
  author={Rahmani, Hossein and Mian, Ajmal and Shah, Mubarak},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.}, 
  title={Learning a Deep Model for Human Action Recognition from Novel Viewpoints}, 
  year={2018},
  volume={40},
  number={3},
  pages={667-681},
  }

@ARTICLE{Ke2018Learning,
  author={Ke, Qiuhong and Bennamoun, Mohammed and An, Senjian and Sohel, Ferdous and Boussaid, Farid},
  journal={IEEE Trans. lmage Process.}, 
  title={Learning Clip Representations for Skeleton-Based 3D Action Recognition}, 
  year={2018},
  volume={27},
  number={6},
  pages={2842-2855},
  }



@InProceedings{kalantidis2020hard,
  author = {Kalantidis, Yannis and Sariyildiz, Mert Bulent and Pion, Noe and Weinzaepfel, Philippe and Larlus, Diane},
  title = {Hard Negative Mixing for Contrastive Learning},
  booktitle = {Proc. Adv. Neural Inf. Process. Syst.},
  year = {2020},
  pages = {21798--21809}, volume = {33},
  %doi={10.5555/3495724.3497553}
}  
@INPROCEEDINGS{Chuang2022RobustCL,
  title={Robust Contrastive Learning against Noisy Views},
  author={Ching-Yao Chuang and R. Devon Hjelm and Xin Wang and Vibhav Vineet and Neel Joshi and Antonio Torralba and Stefanie Jegelka and Ya-heng Song},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={16649-16660},
}

@INPROCEEDINGS{Li20213D,
  author={Li, Linguo and Wang, Minsi and Ni, Bingbing and Wang, Hang and Yang, Jiancheng and Zhang, Wenjun},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 
  title={3D Human Action Representation Learning via Cross-View Consistency Pursuit}, 
  year={2021},
  pages={4739-4748}
 }
@ARTICLE{Wu2023Neighbor,
  author={Wu, Jianlong and Sun, Wei and Gan, Tian and Ding, Ning and Jiang, Feijun and Shen, Jialie and Nie, Liqiang},
  journal={IEEE Trans. lmage Process.}, 
  title={Neighbor-Guided Consistent and Contrastive Learning for Semi-Supervised Action Recognition}, 
  year={2023},
  volume={32},
  pages={2215-2227},
  %doi={10.1109/TIP.2023.3265261}
 }
@INPROCEEDINGS{Piergiovanni2021Recognizing,
  author={Piergiovanni, AJ and Ryoo, Michael S.},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.}, 
  title={Recognizing Actions in Videos from Unseen Viewpoints}, 
  year={2021},
  pages={4122-4130},}
  
@article{He2024STADetST,
  title={STADet: Streaming Timing-Aware Video Lane Detection},
  author={Kaijie He and Jun Xie and Xinguang Dai and Kenglun Chang and Feng Chen and Zhepeng Wang},
  journal={IEEE Trans. Circuits Syst. Video Technol.},
  year={2024},
  volume={34},
  number={9},
  pages={8644-8656},
}

@ARTICLE{Wang2024LIDAR,
  author={Wang, Jian and Li, Fan and An, Yi and Zhang, Xuchong and Sun, Hongbin},
  journal={IEEE Trans. Circuits Syst. Video Technol.}, 
  title={Toward Robust LiDAR-Camera Fusion in BEV Space via Mutual Deformable Attention and Temporal Aggregation}, 
  year={2024},
  volume={34},
  number={7},
  pages={5753-5764},
  }
  
@inproceedings{hou2021multiview,
  title={Multiview detection with shadow transformer (and view-coherent data augmentation)},
  author={Hou, Yunzhong and Zheng, Liang},
  booktitle={Proc. ACM Int. Conf. Multimedia},
  pages={1673--1682},
  year={2021},
  %doi={10.1145/3474085.3475310}}
}
@inproceedings{Srivastav2024SelfPose3dSM,
  title={SelfPose3d: Self-Supervised Multi-Person Multi-View 3d Pose Estimation},
  author={Vinkle Kumar Srivastav and Keqi Chen and Nicolas Padoy},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2024},
  pages={2502-2512},
}
@inproceedings{Liu2024MultiViewAC,
  title={Multi-View Attentive Contextualization for Multi-View 3D Object Detection},
  author={Xianpeng Liu and Ce Zheng and Ming Qian and Nan Xue and Chen Chen and Zhebin Zhang and Chen Li and Tianfu Wu},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2024},
  pages={16688-16698},
  %doi={10.1109/CVPR52733.2024.01579}}
}

@inproceedings{li2022bevformer,
  title={Bevformer: Learning birdâ€™s-eye-view representation from multi-camera images via spatiotemporal transformers},
  author={Li, Zhiqi and Wang, Wenhai and Li, Hongyang and Xie, Enze and Sima, Chonghao and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={1--18},
  year={2022},
}
  
@inproceedings{Qiu2017LearningSR,
  title={Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks},
  author={Zhaofan Qiu and Ting Yao and Tao Mei},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2017},
  pages={5534-5542}
}
@inproceedings{Tran2017ACL,
  title={A Closer Look at Spatiotemporal Convolutions for Action Recognition},
  author={Du Tran and Heng Wang and Lorenzo Torresani and Jamie Ray and Yann LeCun and Manohar Paluri},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2017},
  pages={6450-6459}
}

@inproceedings{Feichtenhofer2020X3DEA,
  title={X3D: Expanding Architectures for Efficient Video Recognition},
  author={Christoph Feichtenhofer},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2020},
  pages={200-210}
}
@inproceedings{Wang2017NonlocalNN,
  title={Non-local Neural Networks},
  author={X. Wang and Ross B. Girshick and Abhinav Kumar Gupta and Kaiming He},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2017},
  pages={7794-7803}
}

@inproceedings{Feichtenhofer2018SlowFastNF,
  title={SlowFast Networks for Video Recognition},
  author={Christoph Feichtenhofer and Haoqi Fan and Jitendra Malik and Kaiming He},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2018},
  pages={6201-6210},
  %doi={}
}%url={https://api.semanticscholar.org/CorpusID:54463801},

@inproceedings{Wang2016TemporalSN,
  title={Temporal Segment Networks: Towards Good Practices for Deep Action Recognition},
  author={Limin Wang and Yuanjun Xiong and Zhe Wang and Yu Qiao and Dahua Lin and Xiaoou Tang and Luc Van Gool},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  year={2016},
  pages={20-36}
}
@inproceedings{reilly2024just,
  title={Just Add $\pi$ Pose Induced Video Transformers for Understanding Activities of Daily Living},
  author={Reilly, Dominick and Das, Srijan},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={18340--18350},
  year={2024},
  %doi={10.1109/CVPR52733.2024.01736}
}

@inproceedings{Lin2018TSMTS,
  title={TSM: Temporal Shift Module for Efficient Video Understanding},
  author={Ji Lin and Chuang Gan and Song Han},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2018},
  pages={7082-7092}
}
@inproceedings{Yang2020TemporalPN,
  title={Temporal Pyramid Network for Action Recognition},
  author={Ceyuan Yang and Yinghao Xu and Jianping Shi and Bo Dai and Bolei Zhou},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2020},
  pages={588-597}
}

@article{Dosovitskiy2020AnII,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  journal={arXiv preprint},
  year={2020},
  volume={arXiv:2010.11929}
}

@inproceedings{Arnab2021ViViTAV,
  title={ViViT: A Video Vision Transformer},
  author={Anurag Arnab and Mostafa Dehghani and Georg Heigold and Chen Sun and Mario Lucic and Cordelia Schmid},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2021},
  pages={6816-6826}
}
@inproceedings{Liu2021VideoST,
  title={Video Swin Transformer},
  author={Ze Liu and Jia Ning and Yue Cao and Yixuan Wei and Zheng Zhang and Stephen Lin and Han Hu},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2021},
  pages={3192-3201}
}
@inproceedings{Girdhar2018VideoAT,
  title={Video Action Transformer Network},
  author={Rohit Girdhar and Jo{\~a}o Carreira and Carl Doersch and Andrew Zisserman},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2018},
  pages={244-253}
}

@article{Kong2017Deeply,
  title={Deeply Learned View-Invariant Features for Cross-View Action Recognition},
  author={Kong, Yu  and  Ding, Zhengming  and  Li, Jun  and  Fu, Yun },
  journal={IEEE Trans. lmage Process.},
  pages={3028-3037},
  volume={26},
  number={6},
  year={2017},
}

@inproceedings{Chen2021DPT,
    author = {Chen, Zhiyang and Zhu, Yousong and Zhao, Chaoyang and Hu, Guosheng and Zeng, Wei and Wang, Jinqiao and Tang, Ming},
    title = {DPT: Deformable Patch-based Transformer for Visual Recognition},
    year = {2021},
    booktitle = {Proc. ACM Int. Conf. Multimedia},
    pages = {2899â€“2907},
    }

@inproceedings{zhu2019deformable,
  title={Deformable convnets v2: More deformable, better results},
  author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={9308-9316},
  year={2019},
  %doi={10.1109/CVPR.2019.00953}
}
@inproceedings{wang2023internimage,
  title={Internimage: Exploring large-scale vision foundation models with deformable convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={14408--14419},
  year={2023}
}

@INPROCEEDINGS{Yarram2022DeVisTR,
  author={Yarram, Sudhir and Wu, Jialian and Ji, Pan and Xu, Yi and Yuan, Junsong},
  booktitle={IEEE Int. Conf. Acoust., Speech Signal Process.}, 
  title={Deformable VisTR: Spatio Temporal Deformable Attention for Video Instance Segmentation}, 
  year={2022},
  pages={3303-3307}
  }
 
  
@inproceedings{Yan2022MultiviewTF,
  title={Multiview Transformers for Video Recognition},
  author={Shen Yan and Xuehan Xiong and Anurag Arnab and Zhichao Lu and Mi Zhang and Chen Sun and Cordelia Schmid},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={3323-3333}
}
@inproceedings{xu2021long,
  title={Long short-term transformer for online action detection},
  author={Xu, Mingze and Xiong, Yuanjun and Chen, Hao and Li, Xinyu and Xia, Wei and Tu, Zhuowen and Soatto, Stefano},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={34},
  pages={1086--1099},
  year={2021}
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={4},
  year={2021}
}


@inproceedings{Chen2021MMViTMV,
  title={MM-ViT: Multi-Modal Video Transformer for Compressed Video Action Recognition},
  author={Jiawei Chen and Chiu Man Ho},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  year={2021},
  pages={786-797}
}


@ARTICLE{MMNet2023,
  author={Yu, Bruce X.B. and Liu, Yan and Zhang, Xiang and Zhong, Sheng-hua and Chan, Keith C.C.},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.}, 
  title={MMNet: A Model-Based Multimodal Network for Human Action Recognition in RGB-D Videos}, 
  year={2023},
  volume={45},
  number={3},
  pages={3522-3538},
  %doi={10.1109/TPAMI.2022.3177813}
  }
  
@inproceedings{Kim2022CrossModalLW,
   title={Cross-modal learning with 3D deformable attention for action recognition},
  author={Kim, Sangwon and Ahn, Dasom and Ko, Byoung Chul},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  pages={10265--10275},
  year={2023},
  %doi={10.1109/ICCV51070.2023.00942}}
}
@inproceedings{Zhu2023STMTAS,
  title={STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition},
  author={Xiaoyu Zhu and Po-Yao (Bernie) Huang and Junwei Liang and Celso M. de Melo and Alexander G. Hauptmann},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2023},
  pages={1526-1536}
}
@inproceedings{Ahn2022STARTransformerAS,
  title={STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition},
  author={Dasom Ahn and Sangwon Kim and Hyun Wook Hong and ByoungChul Ko},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  year={2022},
  pages={3319-3328},
  %doi={10.1109/WACV56688.2023.00333}
}

@article{liu2019ntu,
  title={NTU RGB+D 120: A large-scale benchmark for 3d human activity understanding},
  author={Liu, Jun and Shahroudy, Amir and Perez, Mauricio and Wang, Gang and Duan, Ling-Yu and Kot, Alex C},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  volume={42},
  number={10},
  pages={2684--2701},
  year={2019},
  %doi={10.1109/TPAMI.2019.2916873}
}
@inproceedings{shahroudy2016ntu,
  title={Ntu rgb+ d: A large scale dataset for 3d human activity analysis},
  author={Shahroudy, Amir and Liu, Jun and Ng, Tian-Tsong and Wang, Gang},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={1010--1019},
  year={2016},
  %doi={10.1109/CVPR.2016.115}
}
@article{liu2017pku,
  title={Pku-mmd: A large scale benchmark for continuous multi-modal human action understanding},
  author={Liu, Chunhui and Hu, Yueyu and Li, Yanghao and Song, Sijie and Liu, Jiaying},
  journal={arXiv preprint},
  volume={1703.07475},
  year={2017};
  %doi={10.48550/arXiv.1703.07475}
}
@ARTICLE{Miao2024AP,
  author={Miao, Qiguang and Xin, Wentian and Liu, Ruyi and Liu, Yi and Wu, Mengyao and Shi, Cheng and Pun, Chi-Man},
  journal={IEEE Trans. Multimedia}, 
  title={Adaptive Pitfall: Exploring the Effectiveness of Adaptation in Skeleton-Based Action Recognition}, 
  year={2025},
  volume={27},
  number={},
  pages={56-71},}
@ARTICLE{Geng2024HA,
  author={Geng, Pei and Lu, Xuequan and Li, Wanqing and Lyu, Lei},
  journal={IEEE Trans. Multimedia}, 
  title={Hierarchical Aggregated Graph Neural Network for Skeleton-Based Action Recognition}, 
  year={2024},
  volume={26},
  number={},
  pages={11003-11017},
  }

@inproceedings{Wang2014CrossViewAM,
  title={Cross-View Action Modeling, Learning, and Recognition},
  author={Jiang Wang and Xiaohan Nie and Yin Xia and Ying Wu and Song-Chun Zhu},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2014},
  pages={2649-2656},
  %doi={10.1109/CVPR.2014.339}
}
@inproceedings{cheng2020skeleton,
  title={Skeleton-based action recognition with shift graph convolutional network},
  author={Cheng, Ke and Zhang, Yifan and He, Xiangyu and Chen, Weihan and Cheng, Jian and Lu, Hanqing},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={183--192},
  year={2020}
}
@article{song2022constructing,
  title={Constructing stronger and faster baselines for skeleton-based action recognition},
  author={Song, Yi-Fan and Zhang, Zhang and Shan, Caifeng and Wang, Liang},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  volume={45},
  number={2},
  pages={1474--1488},
  year={2022}
}
@inproceedings{chi2022infogcn,
  title={Infogcn: Representation learning for human skeleton-based action recognition},
  author={Chi, Hyung-gun and Ha, Myoung Hoon and Chi, Seunggeun and Lee, Sang Wan and Huang, Qixing and Ramani, Karthik},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={20186--20196},
  year={2022},
  %doi={10.1109/CVPR52688.2022.01955}
}
@inproceedings{shi2021adasgn,
  title={AdaSGN: Adapting joint number and model size for efficient skeleton-based action recognition},
  author={Shi, Lei and Zhang, Yifan and Cheng, Jian and Lu, Hanqing},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  pages={13413--13422},
  year={2021}
}
@inproceedings{chen2021channel,
  title={Channel-wise topology refinement graph convolution for skeleton-based action recognition},
  author={Chen, Yuxin and Zhang, Ziqi and Yuan, Chunfeng and Li, Bing and Deng, Ying and Hu, Weiming},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  pages={13359--13368},
  year={2021}
}

@inproceedings{hamdi2021mvtn,
  title={Mvtn: Multi-view transformation network for 3d shape recognition},
  author={Hamdi, Abdullah and Giancola, Silvio and Ghanem, Bernard},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  pages={1--11},
  year={2021}
}

@article{Zhang2018ViewAN,
  title={View Adaptive Neural Networks for High Performance Skeleton-Based Human Action Recognition},
  author={Pengfei Zhang and Cuiling Lan and Junliang Xing and Wenjun Zeng and Jianru Xue and Nanning Zheng},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  year={2018},
  volume={41},
  pages={1963-1978}
}


@inproceedings{hou2022shifting,
  title={Shifting perspective to see difference: A novel multi-view method for skeleton based action recognition},
  author={Hou, Ruijie and Li, Yanran and Zhang, Ningyu and Zhou, Yulin and Yang, Xiaosong and Wang, Zhao},
  booktitle={Proc. ACM Int. Conf. Multimedia},
  pages={4987--4995},
  year={2022}
}
@article{Gao2022ViewInvariantHA,
  title={View-Invariant Human Action Recognition Via View Transformation Network (VTN)},
  author={Lingling Gao and Yanli Ji and Kumie Gedamu and Xiaofeng Zhu and Xing Xu and Heng Tao Shen},
  journal={IEEE Trans. Multimedia},
  year={2022},
  volume={24},
  pages={4493-4503},
}
@inproceedings{yang2020gated,
  title={Gated channel transformation for visual recognition},
  author={Yang, Zongxin and Zhu, Linchao and Wu, Yu and Yang, Yi},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={11794--11803},
  year={2020}
}
@inproceedings{hara2018can,
  title={Can spatiotemporal 3d cnns retrace the history of 2d cnns and imagenet?},
  author={Hara, Kensho and Kataoka, Hirokatsu and Satoh, Yutaka},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={6546--6555},
  year={2018},
  %doi={10.1109/CVPR.2018.00685}
}
@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={3--19},
  year={2018}
}
@inproceedings{wang2018dividing,
  title={Dividing and aggregating network for multi-view action recognition},
  author={Wang, Dongang and Ouyang, Wanli and Li, Wen and Xu, Dong},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={457--467},
  year={2018},
  %doi={10.1007/978-3-030-01240-3\_28}
}% url={https://api.semanticscholar.org/CorpusID:211542460},

@inproceedings{vyas2020multi,
  title={Multi-view action recognition using cross-view video prediction},
  author={Vyas, Shruti and Rawat, Yogesh S and Shah, Mubarak},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={427--444},
  year={2020},
  %doi={10.1007/978-3-030-58583-9\_26}
}%url={https://api.semanticscholar.org/CorpusID:220827170},

@article{ULLAH2021321,
title = {Conflux LSTMs Network: A Novel Approach for Multi-View Action Recognition},
journal = {Neurocomputing},
volume = {435},
pages = {321-329},
year = {2021},
issn = {0925-2312},
author = {Amin Ullah and Khan Muhammad and Tanveer Hussain and Sung Wook Baik},
%doi={10.1016/j.neucom.2019.12.151.}
}

@inproceedings{gao2022global,
  title={Global-local cross-view fisher discrimination for view-invariant action recognition},
  author={Gao, Lingling and Ji, Yanli and Yang, Yang and Shen, HengTao},
  booktitle={Proc. ACM Int. Conf. Multimedia},
  pages={5255--5264},
  year={2022}
}
@article{Wu2024STHB,
      title={Spatialâ€“temporal hypergraph based on dual-stage attention network for multi-view data lightweight action recognition},
      author={Zhixuan Wu and Nan Ma and Cheng Wang and Cheng Xu and Genbao Xu and Mingxing Li},
      journal={Pattern Recognit.},
      year={2024},
      volume={151},
      pages={110427},
      %doi={10.1016/j.patcog.2024.110427}
      }
@inproceedings{das2023viewclr,
  title={Viewclr: Learning self-supervised video representation for unseen viewpoints},
  author={Das, Srijan and Ryoo, Michael S},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages={5573--5583},
  year={2023},
  %doi={10.1109/WACV56688.2023.00553}
}

@inproceedings{siddiqui2024dvanet,
  title={DVANet: Disentangling View and Action Features for Multi-View Action Recognition},
  author={Siddiqui, Nyle and Tirupattur, Praveen and Shah, Mubarak},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  pages={4873--4881},
  year={2023},
  %doi={10.1609/aaai.v38i5.28290},
}%url={https://ojs.aaai.org/index.php/AAAI/article/view/28290},



@article{liu2023dual,
  title={Dual-recommendation disentanglement network for view fuzz in action recognition},
  author={Liu, Wenxuan and Zhong, Xian and Zhou, Zhuo and Jiang, Kui and Wang, Zheng and Lin, Chia-Wen},
  journal={IEEE Trans. lmage Process.},
  year={2023},
  volume={32},
  pages={2719-2733},
  %doi={10.1109/TIP.2023.3273459}
}

@article{xu2021cross,
  title={Cross-modality online distillation for multi-view action recognition},
  author={Xu, Chao and Wu, Xia and Li, Yachun and Jin, Yining and Wang, Mengmeng and Liu, Yong},
  journal={Neurocomputing},
  volume={456},
  pages={384--393},
  year={2021},
  %doi={10.1016/j.neucom.2021.05.077}
}

@article{Dhiman2020,
  author={Dhiman, Chhavi and Vishwakarma, Dinesh Kumar},
  journal={IEEE Trans. lmage Process.}, 
  title={View-Invariant Deep Architecture for Human Action Recognition Using Two-Stream Motion and Shape Temporal Dynamics}, 
  year={2020},
  volume={29},
  pages={3835-3844},
}
@article{Zhang2018,
  author={Zhang, Jingtian and Shum, Hubert P. H. and Han, Jungong and Shao, Ling},
  journal={IEEE Trans. lmage Process.}, 
  title={Action Recognition From Arbitrary Views Using Transferable Dictionary Learning}, 
  year={2018},
  volume={27},
  number={10},
  pages={4709-4723},
  }

@article{Oord2018RepresentationLW,
  title={Representation Learning with Contrastive Predictive Coding},
  author={A{\"a}ron van den Oord and Yazhe Li and Oriol Vinyals},
  journal={arXiv preprint},
  year={2018},
  volume={arXiv:1807.03748}
}
@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  volume={33},
  pages={21271--21284},
  year={2020}
}
@inproceedings{Chen2020ExploringSS,
  title={Exploring Simple Siamese Representation Learning},
  author={Xinlei Chen and Kaiming He},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2020},
  pages={15745-15753}
}

@inproceedings{He2019MomentumCF,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},
  author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross B. Girshick},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2019},
  pages={9726-9735}
}
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={Proc. Int. Conf. Mach. Learn.},
  pages={1597--1607},
  year={2020}
}
@inproceedings{Zhu2022BalancedCL,
  title={Balanced Contrastive Learning for Long-Tailed Visual Recognition},
  author={Jianggang Zhu and Z. Wang and Jingjing Chen and Yi-Ping Phoebe Chen and Yueping Jiang},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={6898-6907},
  %doi={10.1109/CVPR52688.2022.00678}}
}

@inproceedings{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
  booktitle={Proc. Adv. Neural Inf. Process. Syst.},
  pages={18661--18673},
  year={2020},
  %doi={10.5555/3495724.3497291}
}%url={https://api.semanticscholar.org/CorpusID:216080787},

@article{Gunel2020SupervisedCL,
  title={Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning},
  author={Beliz Gunel and Jingfei Du and Alexis Conneau and Ves Stoyanov},
  journal={arXiv preprint},
  year={2020},
  volume={arXiv:2011.01403}
}

@inproceedings{Cha2021Co2LCC,
  title={Co2L: Contrastive Continual Learning},
  author={Hyuntak Cha and Jaeho Lee and Jinwoo Shin},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2021},
  pages={9496-9505}
}
@inproceedings{Wang2021ContrastiveLB,
  title={Contrastive Learning based Hybrid Networks for Long-Tailed Image Classification},
  author={Peng Wang and K. Han and Xiu-Shen Wei and Lei Zhang and Lei Wang},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2021},
  pages={943-952}
}

@inproceedings{Gao2022FinegrainedTC,
  title={Fine-grained Temporal Contrastive Learning for Weakly-supervised Temporal Action Localization},
  author={Junyu Gao and Mengyuan Chen and Changsheng Xu},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={19967-19977}
}
@inproceedings{Chen2020RSPNetRS,
  title={RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning},
  author={Peihao Chen and Deng Huang and Dongliang He and Xiang Long and Runhao Zeng and Shilei Wen and Mingkui Tan and Chuang Gan},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  year={2020}
}
@inproceedings{Ding2021MotionawareCV,
  title={Motion-aware Contrastive Video Representation Learning via Foreground-background Merging},
  author={Shuangrui Ding and Maomao Li and Tianyu Yang and Rui Qian and Haohang Xu and Qingyi Chen and Jue Wang},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
    number={1},
  year={2021},
  pages={9706-9716}
}
@inproceedings{Qian2020SpatiotemporalCV,
  title={Spatiotemporal Contrastive Video Representation Learning},
  author={Rui Qian and Tianjian Meng and Boqing Gong and Ming-Hsuan Yang and H. Wang and Serge J. Belongie and Yin Cui},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2020},
  pages={6960-6970}
}
@inproceedings{shah2023multi,
  title={Multi-view action recognition using contrastive learning},
  author={Shah, Ketul and Shah, Anshul and Lau, Chun Pong and de Melo, Celso M and Chellappa, Rama},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages={3381--3391},
  year={2023},
  %doi={10.1109/WACV56688.2023.00338}
}
@inproceedings{tian2020contrastive,
  title={Contrastive Multiview Coding},
  author={Tian, Yuandong and Krishnan, Dilip and Isola, Phillip},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={776--794},
  year={2020},
  %doi={10.1007/978-3-030-58621-8\_45}
}
@inproceedings{Liu2021SwinTH,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Ze Liu and Yutong Lin and Yue Cao and Han Hu and Yixuan Wei and Zheng Zhang and Stephen Lin and Baining Guo},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  year={2021},
  pages={9992-10002},
  %doi={10.1109/ICCV48922.2021.00986}
}

@inproceedings{duan2022pyskl,
  title={Pyskl: Towards good practices for skeleton action recognition},
  author={Duan, Haodong and Wang, Jiaqi and Chen, Kai and Lin, Dahua},
  booktitle={Proc. ACM Int. Conf. Multimedia},
  pages={7351--7354},
  year={2022}
}
@inproceedings{zhang2023hierarchical,
  title={Hierarchical consistent contrastive learning for skeleton-based action recognition with growing augmentations},
  author={Zhang, Jiahang and Lin, Lilang and Liu, Jiaying},
  booktitle={Proc. AAAI Conf. Artif. Intell.},
  pages={3427--3435},
  year={2023}
}
@inproceedings{liu2020disentangling,
  title={Disentangling and unifying graph convolutions for skeleton-based action recognition},
  author={Liu, Ziyu and Zhang, Hongwen and Chen, Zhenghao and Wang, Zhiyong and Ouyang, Wanli},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={143--152},
  year={2020}
}
@inproceedings{pie2021recognizing,
  title={Recognizing actions in videos from unseen viewpoints},
  author={Piergiovanni, AJ and Ryoo, Michael S},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={4124--4132},
  year={2021}
}
@article{das2021vpn++,
  title={Vpn++: Rethinking video-pose embeddings for understanding activities of daily living},
  author={Das, Srijan and Dai, Rui and Yang, Di and Bremond, Francois},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  volume={44},
  number={12},
  pages={9703--9717},
  year={2021},
}
@inproceedings{duan2022revisiting,
  title={Revisiting skeleton-based action recognition},
  author={Duan, Haodong and Zhao, Yue and Chen, Kai and Lin, Dahua and Dai, Bo},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={2969--2978},
  year={2022},
  %doi={10.1109/CVPR52688.2022.00298}}
}
@inproceedings{wang20233mformer,
  title={3mformer: Multi-order multi-mode transformer for skeletal action recognition},
  author={Wang, Lei and Koniusz, Piotr},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  pages={5620--5631},
  year={2023},
  %doi={10.1109/CVPR52729.2023.00544}
}
@inproceedings{das2020vpn,
  title={Vpn: Learning video-pose embedding for activities of daily living},
  author={Das, Srijan and Sharma, Saurav and Dai, Rui and Bremond, Francois and Thonnat, Monique},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={72--90},
  year={2020},
}
@inproceedings{ahn2023star,
  title={Star-transformer: A spatio-temporal cross attention transformer for human action recognition},
  author={Ahn, Dasom and Kim, Sangwon and Hong, Hyunsu and Ko, Byoung Chul},
  booktitle={Proc. IEEE/CVF Winter Conf. Appl. Comput. Vis.},
  pages={3330--3339},
  year={2023},
  %%doi={10.1109/WACV56688.2023.00333}
  
}
@INPROCEEDINGS{Dai2017Def,
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={Proc. IEEE/CVF Int. Conf. Comput. Vis.},
  title={Deformable Convolutional Networks}, 
  year={2017},
  pages={764-773}}

@INPROCEEDINGS{Xia2022VisionTW,
  title={Vision Transformer with Deformable Attention},
  author={Zhuofan Xia and Xuran Pan and Shiji Song and Li Erran Li and Gao Huang},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={4784-4793},
  %doi={10.48550/arXiv.2201.00520}
}

@article{Zhu2020DeformableDD,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Xizhou Zhu and Weijie Su and Lewei Lu and Bin Li and Xiaogang Wang and Jifeng Dai},
  journal={arXiv preprint},
  year={2020},
  volume={arXiv:2010.04159}
}

@INPROCEEDINGS{Liang2022RecurrentVR,
  title={Recurrent Video Restoration Transformer with Guided Deformable Attention},
  author={Jingyun Liang and Yuchen Fan and Xiaoyu Xiang and Rakesh Ranjan and Eddy Ilg and Simon Green and Jiezhang Cao and K. Zhang and Radu Timofte and Luc Van Gool},
  booktitle = {Proc. Adv. Neural Inf. Process. Syst.},
  pages = {378--393},
  volume = {35},
  year = {2022}
}
@INPROCEEDINGS{Wang2022DeformableVT,
  title={Deformable Video Transformer},
  author={Jue Wang and Lorenzo Torresani},
  booktitle={Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit.},
  year={2022},
  pages={14033-14042}
}
@INPROCEEDINGS{Yu_Liu_Chan_2021, 
title={Multimodal Fusion via Teacher-Student Network for Indoor Action Recognition}, booktitle={Proc. AAAI Conf. Artif. Intell.}, author={Yu, Bruce X.B. and Liu, Yan and Chan, Keith C.C.}, year={2021}, pages={3199-3207} }


@ARTICLE{Cheng2022Spatial-Temporal,
  author={Cheng, Qin and Liu, Zhen and Ren, Ziliang and Cheng, Jun and Liu, Jianming},
  journal={IEEE Access}, 
  title={Spatial-Temporal Information Aggregation and Cross-Modality Interactive Learning for RGB-D-Based Human Action Recognition}, 
  year={2022},
  volume={10},
  number={},
  pages={104190-104201},
  %doi = {10.1109/ACCESS.2022.3201227}

@article{Ren2020Seg,
  title={Segment spatial-temporal representation and cooperative learning of Convolution Neural Networks for multimodal-based action recognition},
  author={Ren, Ziliang  and  Zhang, Qieshi  and  Cheng, Jun  and  Hao, Fusheng  and  Gao, Xiangyang},
  journal={Neurocomputing},
  volume={433},
  number={2},
  pages = {142-153},
  year={2020},
  %doi = {10.1016/j.neucom.2020.12.020}
}

@ARTICLE{Cheng2022Cross,
  author={Cheng, Jun and Ren, Ziliang and Zhang, Qieshi and Gao, Xiangyang and Hao, Fusheng},
  journal={IEEE Trans. Circuits Syst. Video Technol.}, 
  title={Cross-Modality Compensation Convolutional Neural Networks for RGB-D Action Recognition}, 
  year={2022},
  volume={32},
  number={3},
  pages={1498-1509}}
@article{wang2018temporal,
  title={Temporal segment networks for action recognition in videos},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={11},
  pages={2740--2755},
  year={2018},
}


@article{Yin2024SpatiotemporalPI,
      title={Spatiotemporal Progressive Inward-Outward Aggregation Network for skeleton-based action recognition},
      author={Xinpeng Yin and Jianqi Zhong and Deliang Lian and Wenming Cao},
      journal={Pattern Recognit.},
      year={2024},
      volume={150},
      pages={110262},
      %doi = {10.1016/j.patcog.2024.110262},
      } %url = {https://www.sciencedirect.com/science/article/pii/S003132032400013X},
      
@article{Wu2025LocalAG,
      title={Local and global self-attention enhanced graph convolutional network for skeleton-based action recognition},
      author={Zhize Wu and Yue Ding and Long Wan and Teng Li and Fudong Nian},
      journal={Pattern Recognit.},
      year={2025},
      volume={159},
      pages={111106},
      %doi={10.1016/j.patcog.2024.111106}
      }
