\section{Related Work}
\subsection{In-Context Learning}
    It was discovered that pre-trained LLMs have remarkable capabilities in adapting to new tasks by providing a related context or several demonstrations alongside the test input**Brown et al., "How Much Train Data Does an NLP Model Require?"**, which is typically referred to as the in-context learning ability of LLMs. However, it's evident that the selection and order of demonstrations can largely affect the final performance**Bertels et al., "Improving In-Context Learning with Multi-Demonstration Alignment"**.
    % Apart from the empirical discovery of ICL, researchers also make an effort to find a proper theoretical explanation behind this paradigm. **Dodge et al., "Show Your Work: Incremental Reasoning in Vision-and-Language Navigation"** first bridges the theoretical gap between in-context learning and gradient descent. Subsequent works**Pang et al., "Can In-Context Learning Learn? A Theoretical Analysis"** further demonstrate how transformers learn in context by implicitly performing gradient descent.

    \subsection{Demonstration Selection in ICL}
     While early corpus-level methods relied on a fixed set of demonstrations**Gao et al., "On the Importance of Demonstration Order in In-Context Learning"**, recent studies emphasize dynamically selecting the most suitable demonstrations for each test input**Kim et al., "Adaptive Demonstration Selection for In-Context Learning"**, which can be categorized into two groups: data-dependent strategies and self-adaptive strategies.

    \begin{figure*}[h]
        \centering
        \includegraphics[width=0.93\textwidth]{figs/main_fig.pdf}
        \caption{The main framework of \textbf{D.Va}. We first retrieve the nearest demonstration as the validation example and a demonstration candidate set of size $K-1$. Then use our proposed metric to re-rank all the candidates and concatenate the top $n$ candidates as the final context at the inference stage.}
        \label{fig:main}
    \end{figure*}

    As for data-dependent strategies, previous work always relies on the textual or semantical similarity between the test input and the demonstrations to select the most suitable demonstrations, namely retrieval-based ICL (Ret-ICL). In this circumstance, BM25**Robertson et al., "The Probabilistic Relevance Framework: BM25"** and Sentence-BERT**Reimers et al., "Sentence-BERT: Pre-training of Bidirectional Encoder Representations for Sentence Pair Classification"** are commonly used to retrieve the most similar demonstrations for each test input. Besides, many researchers also focus on extracting high-quality training data and further optimizing the ability of retrievers**Joulin et al., "FastSPAA: Fast Exact Substring Matching in Suffix Trees"**.

    In the realm of self-adaptive strategies, **Kumar et al., "Self-Adaptive Demonstration Selection for In-Context Learning"** pioneered this area by introducing a self-adaptive method for selecting effective demonstrations for classification tasks.
    Subsequently, **Huang et al., "Self-Adaptive ICL with Perplexity Minimization"** leveraged the language models' understanding of test inputs together with candidate examples to identify demonstrations that effectively minimize the perplexity of the test inputs.