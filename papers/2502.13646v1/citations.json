[
  {
    "index": 0,
    "papers": [
      {
        "key": "gpt3",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario",
        "title": "Language Models are Few-Shot Learners"
      },
      {
        "key": "dong-etal-2024-survey",
        "author": "Dong, Qingxiu  and\nLi, Lei  and\nDai, Damai  and\nZheng, Ce  and\nMa, Jingyuan  and\nLi, Rui  and\nXia, Heming  and\nXu, Jingjing  and\nWu, Zhiyong  and\nChang, Baobao  and\nSun, Xu  and\nLi, Lei  and\nSui, Zhifang",
        "title": "A Survey on In-context Learning"
      },
      {
        "key": "luo2024incontext",
        "author": "Man Luo and Xin Xu and Yue Liu and Panupong Pasupat and Mehran Kazemi",
        "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liu-etal-2022-makes",
        "author": "Liu, Jiachang  and\nShen, Dinghan  and\nZhang, Yizhe  and\nDolan, Bill  and\nCarin, Lawrence  and\nChen, Weizhu",
        "title": "What Makes Good In-Context Examples for {GPT}-3?"
      },
      {
        "key": "lu-etal-2022-fantastically",
        "author": "Lu, Yao  and\nBartolo, Max  and\nMoore, Alastair  and\nRiedel, Sebastian  and\nStenetorp, Pontus",
        "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "dai-etal-2023-gpt",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "pmlr-v202-von-oswald23a",
        "author": "Von Oswald, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Joao and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max",
        "title": "Transformers Learn In-Context by Gradient Descent"
      },
      {
        "key": "deutch-etal-2024-context",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "gpt3",
        "author": "Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario",
        "title": "Language Models are Few-Shot Learners"
      },
      {
        "key": "shin-etal-2020-autoprompt",
        "author": "Shin, Taylor  and\nRazeghi, Yasaman  and\nLogan IV, Robert L.  and\nWallace, Eric  and\nSingh, Sameer",
        "title": "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts"
      },
      {
        "key": "gao-etal-2021-making",
        "author": "Gao, Tianyu  and\nFisch, Adam  and\nChen, Danqi",
        "title": "Making Pre-trained Language Models Better Few-shot Learners"
      },
      {
        "key": "jiang-etal-2021-know",
        "author": "Jiang, Zhengbao  and\nAraki, Jun  and\nDing, Haibo  and\nNeubig, Graham",
        "title": "How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering"
      },
      {
        "key": "sorensen-etal-2022-information",
        "author": "Sorensen, Taylor  and\nRobinson, Joshua  and\nRytting, Christopher  and\nShaw, Alexander  and\nRogers, Kyle  and\nDelorey, Alexia  and\nKhalil, Mahmoud  and\nFulda, Nancy  and\nWingate, David",
        "title": "An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "luo2024incontext",
        "author": "Man Luo and Xin Xu and Yue Liu and Panupong Pasupat and Mehran Kazemi",
        "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "bm25",
        "author": "Robertson, Stephen and Zaragoza, Hugo",
        "title": "The Probabilistic Relevance Framework: BM25 and Beyond"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "reimers-gurevych-2019-sentence",
        "author": "Reimers, Nils  and\nGurevych, Iryna",
        "title": "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "ceil",
        "author": "Ye, Jiacheng and Wu, Zhiyong and Feng, Jiangtao and Yu, Tao and Kong, Lingpeng",
        "title": "Compositional exemplars for in-context learning"
      },
      {
        "key": "li-etal-2023-unified",
        "author": "Li, Xiaonan  and\nLv, Kai  and\nYan, Hang  and\nLin, Tianyang  and\nZhu, Wei  and\nNi, Yuan  and\nXie, Guotong  and\nWang, Xiaoling  and\nQiu, Xipeng",
        "title": "Unified Demonstration Retriever for In-Context Learning"
      },
      {
        "key": "luo2023dricldemonstrationretrievedincontextlearning",
        "author": "Man Luo and Xin Xu and Zhuyun Dai and Panupong Pasupat and Mehran Kazemi and Chitta Baral and Vaiva Imbrasaite and Vincent Y Zhao",
        "title": "Dr.ICL: Demonstration-Retrieved In-context Learning"
      },
      {
        "key": "wang-etal-2024-learning",
        "author": "Wang, Liang  and\nYang, Nan  and\nWei, Furu",
        "title": "Learning to Retrieve In-Context Examples for Large Language Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wu-etal-2023-self",
        "author": "Wu, Zhiyong  and\nWang, Yaoxiang  and\nYe, Jiacheng  and\nKong, Lingpeng",
        "title": "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "peng-etal-2024-revisiting",
        "author": "Peng, Keqin  and\nDing, Liang  and\nYuan, Yancheng  and\nLiu, Xuebo  and\nZhang, Min  and\nOuyang, Yuanxin  and\nTao, Dacheng",
        "title": "Revisiting Demonstration Selection Strategies in In-Context Learning"
      }
    ]
  }
]