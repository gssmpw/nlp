\begin{table}[!t]
\centering
\small
\resizebox{0.40\textwidth}{!}{%
\begin{tabular}{l|cc|c}
\toprule
\textbf{Model} & \textbf{\textit{colloquial}} & \textbf{\textit{standard}} & \textbf{Avg.} \\
\midrule
\multicolumn{4}{@{}l@{}}{\textit{\textbf{Baselines}}} \\
mGPT & 54.56 & 53.49 & 54.03 \\
BLOOM & 55.10 & 54.38 & 54.74 \\
Llama3.2 & 52.42 & 52.59 & 52.51 \\
Qwen2.5 & 52.59 & 54.03 & 53.31 \\
Gemma & 54.03 & 55.99 & 55.01 \\
Sailor$^{*}$ & 57.60 & 65.47 & 61.54 \\
Sailor2$^{*}$ & 58.86 & 66.37 & 62.62 \\
\hline
\multicolumn{4}{@{}l@{}}{\textit{\textbf{Ours}}} \\
TransWebLLM & 48.12 & 49.55 & 48.84 \\
TransWebLLM-web & 55.46 & 59.75 & 57.61 \\
TransWebLLM-cool & 55.99 & 61.90 & 58.95 \\
\bottomrule
\end{tabular}}
\caption{COPAL-ID evaluation for \themodelcool{}, measured in accuracy. The last column reports task average score. Models with $^{*}$ denote regional models trained with support for Indonesian.}
\label{tab:local_culture_reasoning_final}
\end{table}