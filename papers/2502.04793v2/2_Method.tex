
\section{Problem Statement \& Methodology}
\subsection{Estimating a confidence interval for the ATE}
Our aim is to leverage online controlled experiments to assess the ATE of an intervention on some outcome of interest $Y$.
Without loss of generality, we assume that this random variable indicates a logged user-level event (e.g. a user opens the app, clicks, converts, renews, churns, et cetera).
We denote the intervention by superscript, for treatment $Y^{\rm T}$ and control $Y^{\rm C}$.
Our estimand is then, with an expectation over experiment randomisation units (i.e. users):
\begin{equation}
    \mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}(Y) = \mathbb{E}[Y^{\rm T}-Y^{\rm  C}].
\end{equation}

A straightforward estimator for the ATE is given by the difference in sample means.
For a set of users belonging to a \emph{group} (i.e. control C, treatment T, or a general A/B-testing group A) and their observed outcomes $Y$, we have:
\begin{equation}
    \mu_{\rm A}(Y) = \frac{1}{|\mathcal{U}_{\rm A}|} \sum_{i \in \mathcal{U}_{\rm A}} Y_i,\, \, \, \, \enskip \text{and} \, \, \, \, \enskip \widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y)  =  \mu_{\rm T}(Y) - \mu_{\rm C}(Y).
\end{equation}

To quantify the uncertainty in the estimate, we wish to construct a confidence interval.
The CLT tells us that the distribution of $\mathbb{E}[Y]$ converges to a normal distribution, and hence, so does the distribution for the ATE.
This implies that we can compute:
\begin{align}
    \sigma^{2}_{\rm A}(Y) &= \frac{1}{|\mathcal{U}_{\rm A}|}\sum_{i \in \mathcal{U}_{\rm A}}(Y_i - \mu_{\rm A}(Y))^{2}, \\
   \text{SE}\left(\widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y)\right) &= \sqrt{\frac{\sigma^{2}_{\rm C}(Y)}{|\mathcal{U}_{\rm C}|} + \frac{\sigma^{2}_{\rm T}(\rm Y)}{|\mathcal{U}_{\rm T}|}}.
\end{align}
A $100\cdot(1-\alpha)\%$ confidence interval can then be obtained as:
\begin{equation}
    \widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y) \pm  \Phi^{-1}\left(1-\frac{\alpha}{2}\right)\cdot\text{SE}\left(\widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y)\right),
\end{equation}
where the inverse cumulative distribution function for the standard normal distribution $\Phi^{-1}$ gives the critical value for confidence level $\alpha$.
It should include the ground truth ATE in $100\cdot(1-\alpha)\%$ of cases.
A confidence interval around the ATE is a crucial component to consider when properly interpreting A/B-testing results.

In  a statistical hypothesis testing framework, when zero is not contained by this interval, the null hypothesis is rejected and the result is deemed significant at level $\alpha$.
Alternatively, we can construct a two-tailed $p$-value as:
\begin{equation}\label{eq:pvalue}
    p = 2 \left(1- \Phi\left( \left| \underbrace{\frac{\widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y)}{\text{SE}\left(\widehat{\mathop{\rm ATE}\limits_{{\rm C} \to {\rm T}}}(Y)\right)}}_{z\text{-score}} \right| \right)\right),
\end{equation}
and reject the null hypothesis when $p < \alpha$.
The $p$-value can be described as the probability of observing results at least as extreme as what is observed, given that the null hypothesis holds true.

The meaning that is ascribed to both confidence intervals and $p$-values relies heavily on the assumption that the distribution of the estimand has approached normality. 
Whilst the CLT guarantees this property to hold asymptotically, finite sample scenarios require us to empirically validate that the above procedure is appropriate. 

\subsection{Empirically validating confidence intervals}
Naturally, directly validating whether the obtained CI includes the true ATE would require knowledge of the latter, which is prohibitive.
Alternatively, A/A-tests allow us to emulate experiments where we know the true ATE by design (i.e. $0$, as the null hypothesis holds).
This enables us to estimate the empirical coverage of the obtained CIs, through repeated resampling of A/A-groups.
When the distribution of the ATE has approached normality, the distribution of the $p$-values that we obtain over resampled A/A-tests should resemble a uniform distribution.
The Kolmogorov-Smirnov test provides a rigorous statistical framework to flag cases where it does not.
This allows us to, for a set of users $\mathcal{U}$ and outcomes $Y$, assess how amenable the data is to reliable estimation of CIs on ATE($Y$) using the above-mentioned standard methods.

As such, we repeatedly resample groups ${\rm A}_{i}$,${\rm A}_{i}^\prime$ for $n$ iterations, obtain $n$ confidence intervals for $\widehat{\mathop{\rm ATE}\limits_{{\rm A}_i \to {\rm A}_{i}^{\prime}}}(Y)$ and obtain a set of $p$-values $\{p_{1},\ldots,p_{n}\}$.
Given the empirical Cumulative Distribution Function (eCDF) of $p$-values $F_{\rm emp}(p)$, we wish to assess how it deviates from the uniform distribution with CDF $F_{\rm uni}(p)=p$ for $p\in[0,1]$.
The test statistic leveraged by Kolmogorov-Smirnov, known as the $D$-statistic, measures the $\infty$-norm over the observed differences between the two CDFs as:
\begin{equation}
    D = \sup_{p\in[0,1]} \left|F_{\rm emp}(p) - F_{\rm uni}(p)\right|.
\end{equation}
Under the null hypothesis that the distributions are equivalent, $D$ follows a Kolmogorov distribution.
As such, we can obtain a $p$-value that is used to reject the null hypothesis that the $p$-values obtained from the A/A-tests are uniformly distributed, or, that we have sufficient samples to reliably estimate treatment effects on $Y$.
Note that this is equivalent to testing whether the $z$-scores in Equation~\ref{eq:pvalue} follow a standard normal distribution.
Arguments against the statistical hypothesis testing framework apply here as well.
We suggest to pay special attention to cases where the $D$-statistic is high, or conversely, the Kolmogorov Smirnov $p$-value is low, rather than assigning binary (non-)significant labels to metrics.

In cases where an outcome $Y$ is flagged through this procedure, CIs and $p$-values obtained through the $t$- or $z$-test should be considered unreliable.
We can rely on alternative non-parametric methods to estimate CIs on ATE($Y$) in those situations, e.g. based on permutation sampling or bootstrapping.
We note that other commonly used methods like the Mann-Whitney U-test formulate a different null hypothesis, and cannot be used as a drop-in replacement without careful consideration~\cite{Fay2010}.
Furthermore, as the above-mentioned alternatives typically come with a considerable computational cost and specialised engineering solutions, they are significantly less desirable as a default approach.
A deeper exploration of their applicability falls outside of the scope for this work, but provides an interesting avenue for future research.