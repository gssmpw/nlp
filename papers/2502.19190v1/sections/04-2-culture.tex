Several years after the release of generative AI models to the public, we have ample evidence of how the text and images that they produce do not perform well in the context of non-dominant cultures, and at times actively harm them (e.g. \cite{Bender_Gebru_McMillan-Major_Shmitchell_2021,Prabhakaran_Qadri_Hutchinson_2022,cetinic_myth_2022,Cao_Zhou_Lee_Cabello_Chen_Hershcovich_2023}). Admirably, the technical community has recognized the problem and has proposed solutions such as improved training data \cite{Pawar_Park_Jin_Arora_Myung_Yadav_Haznitrama_Song_Oh_Augenstein_2024}, additional fine-tuning processes \cite{Masoud_Liu_Ferianc_Treleaven_Rodrigues_2024}, enhanced prompting strategies \cite{AlKhamissi_ElNokrashy_Alkhamissi_Diab_2024}, and new benchmarks \cite{Santurkar_Durmus_Ladhak_Lee_Liang_Hashimoto_2023}. These interventions are framed under the broader category of systems that improve users' acceptance of AI output: ``cultural alignment'' \cite{AlKhamissi_ElNokrashy_Alkhamissi_Diab_2024} or ``cultural inclusion'' \cite{Karamolegkou_Rust_Cui_Cao_Søgaard_Hershcovich_2024, Wadern}.

And yet much of the work on these topics does not ask what "culture" is, or seek involvement from the many humanities fields that are defined by that question. (There is increasingly involvement from the social sciences, especially anthropology \cite{Pawar_Park_Jin_Arora_Myung_Yadav_Haznitrama_Song_Oh_Augenstein_2024,hershcovich_challenges_2022,Adilazuarda_Mukherjee_Lavania_Singh_Aji_O’Neill_Modi_Choudhury_2024}. The result is a narrow definition of culture that rests on the terms of European modernity–e.g. a geographic region or a unifying nationality, language, or racial/ethnic/religious identity. This definition is far more rigid than how humanities scholars understand the term. In the humanities, ``culture'' may be used to refer to ``the way of life of a people, group, or humanity in general,'' but it can also be employed to describe ``the works and practices of intellectual and artistic activity'' that emerge from a particular community or group \citep{Williams_1976, Culture_2014}. These complementary yet distinct definitions are important to keep in mind, since it is not only that, for example, a model’s training data might be produced by people from different cultures, in the first sense of the word, but are that the training data is itself an expressions of culture, as in the second sense of the word, as is the model itself. 

The distinction between people as cultures and objects or expressions of culture, and our awareness of how both definitions are engaged by genAI models, is crucial for our understanding of their development and their output. Understanding how training data both reflects cultures, and consists of expressions of those cultures, can lead to more intentional data curation practices. In the commercial arena, we have seen how EleutherAI has developed the Pile with heightened attention to scientific cultures, as evidenced by their inclusion of data from PubMed and arXiv, among others \cite{gao_pile_2020}, and how Pleias recently focused its Common Corpus on cultural heritage (e.g., newspapers, monographs) and under-resourced languages \cite{noauthor_releasing_nodate}. This expanded definition of culture can also lead to new ideas for model development, as in recent works that treat pretraining datasets as curations worthy of examination and have studied the spread of books, poetry, and other creative content in these datasets \cite{Chang_Cramer_Soni_Bamman_2023,D’Souza_Mimno,walsh_sonnet_2024}, in work that considers the creative outputs of large models \cite{Lucy_Bamman_2021}, or in work that trains models with capabilities tuned for historical languages \cite{Yamshchikov_Tikhonov_Pantis_Schubert_Jost_2022}.

This expanded definition of culture also opens up the possibility for understanding cultural objects as expressions of larger structures of power, or as active challenges to those structures. In fact, when humanities scholars study culture, we analyze each of these dimensions of culture and more. Carried over to the context of AI, we can not only better understand for example how and why certain perspectives end up captured in training data and others do not, but how and why the models themselves must be understood as cultural objects and analyzed accordingly, meaningful both for the text and other media that they produce, and as expressions of contemporary tech culture in and of themselves.  