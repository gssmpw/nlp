\section{Related Work}
There is a rich history of work illustrating how various aspects of symbol processing might be implemented in neural networks. Work on the tensor product representation~\cite{smolensky1990tensor} and binding-by-synchrony~\cite{hummel2003symbolic} illustrated how dynamic variable-binding can be performed in neural networks. Kriete et al.~\yrcite{kriete2013indirection} demonstrated how indirection, the use of one variable to refer to another, can be implemented in a biologically plausible neural network. More recently, a series of studies illustrated how a \textit{relational bottleneck}~\cite{webb2024relational}--a strong inductive bias to perform relational processing--can enable data-efficient learning of abstract reasoning capabilities in deep learning systems~\cite{webb2020emergent,kerg2022neural,altabaa2023abstractors}. The primary contribution of our work, relative to these previous studies, is to demonstrate empirically that symbolic mechanisms can emerge in a large-scale neural network, and to illustrate how they operate to support abstract reasoning. Notably, the symbol abstraction heads identified in this work implement an emergent version of the abstractor architecture that was previously proposed to support relational learning~\cite{altabaa2023abstractors}

There has also been much recent work investigating the internal mechanisms that support various forms of abstract and structured task processing in language models. This work has identified key primitives such as induction heads~\cite{olsson2022context}, function vectors~\cite{todd2023function}, binding IDs~\cite{feng2023language}, and other mechanisms that play a role in relational processing~\cite{merullo2023mechanism}. We build on this previous work by identifying an integrated architecture that brings together multiple mechanisms. These include newly identified mechanisms -- symbol abstraction and symbolic induction heads -- that, respectively, carry out the processes of abstraction and rule induction needed to implement an emergent form of symbol processing that supports abstract reasoning in a neural network.