\section{Code and Hardware}

All code was written in Python using the TransformerLens and HuggingFace libraries. Experiments were conducted on two NVIDIA 80G H100 GPUs.

All code and data will be made publicly available upon acceptance.

\section{Implementation Details}

\subsection{Task Performance Evaluation}

We randomly selected English tokens from LLaMa-3 vocabulary to form 2000 prompts to evaluate the generation accuracy. The prompt format used in experiments (2-shot) is: 
\vspace{-10pt}
\begin{center}
${A_1}$\textasciicircum${B_1}$\textasciicircum${A_1}$$\backslash n$${A_2}$\textasciicircum${B_2}$\textasciicircum${A_2}$$\backslash n$
${A_3}$\textasciicircum${B_3}$\textasciicircum
\end{center}

\subsection{Causal Mediation Analysis}

\begin{algorithm}
\begin{algorithmic}[1]
\caption{Causal Mediation}
\label{alg:causal_mediation}
\STATE {\bf Input:} context pair ($c_{1}$,$c_{2}$), language model $f(c)\in{R^A}$: outputs the logits for all possible next tokens at the last position of prompt $c$, vocabulary size $A$, the $i$-th value of vector $f(c)$: $f(c)[i]$, the correct answer for $c_{1}$: $y_{c_{1}}$, the expected answer for the patched
context $c_1^*$: $y_{c_{1}^{*}}$.

\STATE For $c_{1}$, measure the difference between the output logit for $y_{c_{1}^{*}}$ and $y_{c_{1}}$, i.e.,
$\Delta{f_{c_{1}}} = f(c_{1})[y_{c_{1}^{*}}] - f({c_{1}})[y_{c_{1}}].$

\STATE Cache the inner activations after feeding $c_{2}$ into the model.

\STATE Replace the activations of the entire attention block or individual attention head in certain layer with the activations from $c_{2}$ at specific token positions to intervene on processing of $c_{1}$, and retrieve the logit difference:

\begin{equation}
    \Delta{f_{c_{1}^*}}=f(c_{1}^{*})[y_{c_{1}^{*}}] - f(c_{1}^{*})[y_{c_{1}}]
\end{equation}

The change in the logit difference is a measure of the causal mediation effect:
\begin{equation}
    s 
    = \Delta{f_{c_{1}^*}} -  \Delta{f_{c_{1}}}= (f(c_{1}^{*})[y_{c_{1}^{*}}] - f(c_{1}^{*})[y_{c_{1}}]) - (f({c_{1}})[y_{c_{1}^{*}}] - f({c_{1}})[y_{c_{1}}]),
\end{equation}
\STATE {\bf Output}: Causal Mediation Score $s$
\end{algorithmic}
\end{algorithm}

Algorithm \ref{alg:causal_mediation} explains the causal mediation procedure on one context pair $(c_1, c_2)$. We randomly selected 20 prompts, restricting the analysis to prompts that the model answered correctly, and calculated the average score over both ABA and ABB tasks.

\textbf{Contexts.}
For
($c_{1}^{abstract}$, $c_{2}^{abstract}$),  $y_{c_{1}} = A_N$ (Eq. \ref{eq:c1_abs} and Eq.\ref{eq:c2_abs}). After activation patching,  $y_{c_{1}^*}$ should be $B_N$ based on our hypothesis that the output embeddings of symbol abstraction heads and symbolic induction heads represent abstract variables. 
For ($c_{1}^{token}$, $c_{2}^{token}$), $y_{c_{1}^*}$ should be $B_N$ according to the hypothesis that the output of retrieval heads represent the actual token.

\textbf{Activations.} We focus on two types of activations, the output of the entire attention block and the output embeddings of the individual attention head. The attention block includes attention heads followed by an MLP. The output embedding of the attention heads is the average of the value embeddings weighted by the attention scores. 

\textbf{Positions.} We replaced the activations at the final items of the in-context examples ($A_n$ or $B_N$) or the final token right before the generated tokens (the final separation token). 

\subsection{Attention Analyses}

For each individual head, the attention map was averaged over 1378 prompts each for ABA and ABB tasks, again limiting the analysis to prompts that the model answered correctly.


\subsection{Representational Similarity Analyses}
For one set of tokens $[(A_n, B_n)]_{N}$, there are four different contexts, i.e.,

\begin{align}
  A_{1}, B_{1}, A_{1}, ..., A_{N}, B_{N} \\ \notag
  A_{1}, B_{1}, A_{1}, ..., B_{N}, A_{N} \\ \notag
    B_{1}, A_{1}, A_{1}, ..., B_{N}, A_{N} \\ \notag
    B_{1}, A_{1}, A_{1}, ..., A_{N}, B_{N} \notag
\end{align}

We randomly selected 40 token sets formed in different contexts to measure the similarity of the activations at certain positions.

\subsection{Cumulative Ablation Analyses}

We randomly selected another set of 20 prompts, which do not overlap with the prompts used in causal mediation analyses. Starting from the heads with highest causal mediation scores, we gradually increase the number of ablated heads, and evaluate the effect on the probability of the correct answer. As a control, we performed the same analysis, but replaced each ablated head with the ablation of the head in the same layer with the lowest causal mediation score. The curves in Fig. \ref{ablation} are averaged over both ABA and ABB tasks.

\subsection{Induction Heads}

Following \cite{olsson2022context}, we used the prefix matching score as a measure for induction heads. We created a prompt involving a repeated sequence of 50 random tokens. The prefix matching score is defined as the average attention score from each token to the tokens that directly follow the previous instance of the same token. We averaged results over 4 random seeds.

\subsection{Function Vectors}

As described in \cite{todd2023function}, function vectors are aggregated over heads with a high causal mediation score. The answers for each in-context example are shuffled to form a corrupted prompt and the causal indirect effect (CIE) is defined as the recovery of the probability for correct answers. The average indirect effect (AIE) was taken over 50 prompts each for ABA and ABB tasks. 

\section{Additional Experimental Results}

\subsection{Comparison of Symbol Abstraction Heads, Symbolic Induction Heads, and Retrieval Heads}

\begin{figure*}[ht] % Regular figure environment for a single-column layout
    \centering
    \subfigure[]{
    \begin{minipage}[c]{0.3\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/head_comparison/symbolic_induction_abstraction.pdf}
    \end{minipage}
    \label{abs_symb_scatterplot}
    }
    \subfigure[]{
    \begin{minipage}[c]{0.3\linewidth}
        \centering \includegraphics[width=\linewidth]{figures/head_comparison/retrieval_abstraction.pdf} 
    \end{minipage}
    \label{retr_abs_scatterplot}
    }
    \subfigure[]{
    \begin{minipage}[c]{0.3\linewidth}
        \centering \includegraphics[width=\linewidth]{figures/head_comparison/retrieval_symbolic_induction.pdf} 
    \end{minipage}
    \label{symb_retr_scatterplot}
    }
\caption{\textbf{(a)} Comparison of symbol abstraction heads and symbolic induction heads. \textbf{(b)} Comparison of symbol abstraction heads and retrieval heads. \textbf{(c)} Comparison of symbolic induction heads and retrieval heads. The scores for each type of attention head are largely orthogonal to eachother, indicating that they form disjoint sets of attention heads.}
\end{figure*}

\raggedbottom
\pagebreak

\subsection{Comparison with Induction heads and Function Vectors}

\begin{figure*}[ht] % Regular figure environment for a single-column layout
    \centering
    \subfigure[]{
    \begin{minipage}[c]{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/symb_ind_prefix_matching.pdf}
    \end{minipage}
    \label{induction_head_scatterplot}
    }
    \subfigure[]{
    \begin{minipage}[c]{0.45\linewidth}
        \centering \includegraphics[width=\linewidth]{figures/symb_ind_avg_indirect_effect.pdf} 
    \end{minipage}
    \label{function_vector_scatterplot}
    }
\caption{\textbf{(a)} Comparison of symbolic induction heads and standard induction heads. \textbf{(b)} Comparison of symbolic induction heads and function vector attention heads.}
\end{figure*}


