\section{Omitted proofs from~\texorpdfstring{\Cref{sec:generalized-mean}}{}}
\label{app:gm}

\pmeanapproximation*
\begin{proof}

    We begin with the case where $p \geq 1$.
    It is well known that the $\ell_p$-norm is convex, and we observe that all of the constraints in the
    in Program~(\ref{eq:p-mean-ecc}) are linear. Thus, we may in polynomial time obtain optimal fractional variables $\{d_v^c\}, \{\gamma_e\}, \{m_c\}$
    for the relaxation of Program~(\ref{eq:p-mean-ecc}).

    We observe that for each vertex $v$, there is at most one color $c$ with the property that $d_v^c < \frac{1}{2}$.
    Otherwise, there are two colors $c_1, c_2$ with $d_v^{c_1}, d_v^{c_2} < \frac{1}{2}$, but then
    \[
        \sum_{c=1}^k d_v^c < 2\cdot\frac{1}{2} + (k - 2) = k - 1,
    \]
    contradicting the first constraint of Program~(\ref{eq:p-mean-ecc}).

    We now propose a coloring $\lambda$ as follows. For each color $c$ and vertex $v$, we assign $\lambda(v) = c$ if $d_v^c < \frac{1}{2}$.
    By the preceding observation, this procedure assigns at most one color to each vertex.
    If for any $v$ we have that $d_v^c \geq \frac{1}{2}$ for all colors $c$, then we set $\lambda(v)$ arbitrarily.

    Now, for each hyperedge $e$ let $\hat{\gamma}_e$ be equal to $0$ if $\lambda(v) = \ell(e)$ for all $v \in e$, or $1$ otherwise.
    We claim that if $\hat{\gamma}_e = 1$, then $\gamma_e \geq \frac{1}{2}$.
    Otherwise, letting $c = \ell(e)$, the second constraint of Program~(\ref{eq:p-mean-ecc}) implies that $d_v^c < \frac{1}{2}$ for all $v \in e$.
    Then $\lambda(v) = c$ for all $v \in e$, implying that $\hat{\gamma}_e = 0$, a contradiction.
    We conclude that for every hyperedge $e$, $\hat{\gamma}_e \leq 2\gamma_e$.

    For each color $c$, we write $\hat{m}_c$ for the number of hyperedges of color $c$ which are unsatisfied by $\lambda$.
    Equivalently,
    \[
        \hat{m}_c = \sum_{e \in E_c} \hat{\gamma}_e \leq 2\sum_{e \in E_c} \gamma_e = 2m_c,
    \]
    where the last equality comes from the third constraint of Program~\ref{eq:p-mean-ecc}.

    It follows that for every $c$, $\hat{m}_c^p \leq 2^pm_c^p$, and thus
    \[
        \sum_{c=1}^k \hat{m}_c^p \leq 2^p \cdot \sum_{c=1}^k m_c^p,
    \]

    which in turn implies that

    \[
        \left(\sum_{c=1}^k \hat{m}_c^p\right)^{1/p} \leq 2 \cdot \left(\sum_{c=1}^k m_c^p\right)^{1/p},
    \]

    so $\lambda$ is $2$-approximate.

    We now consider the case where $0 < p < 1$.
    We begin by defining, for each $c \in [k]$, a non-negative, monotone, and submodular function $f_c\colon 2^E \rightarrow \mathbb{Z}$ given by $f_c(S) = |E_c \cap S|$.
    If $\lambda$ is a vertex coloring of $H$ and $S_\lambda \subseteq E$ is the set of edges unsatisfied by $\lambda$, then $f_c(S_\lambda)$ measures the number of edges of color $c$ unsatisfied by $\lambda$.
    Because the composition of a concave function with a submodular function results in a submodular function and $0 < p < 1$, $f_c^p$ is non-negative, monotone, and submodular.
    Then the function $f\colon 2^E \rightarrow \mathbb{R}$ given by the sum
    \[
        f(S) = \sum_{c=1}^{k} f_c^p(S)
    \]
    has these same properties.

    Now, let $\lambda^*$ be an optimal vertex coloring of $H$ and let $S_{\lambda^*}$ be the set of hyperedges unsatisfied by $\lambda^*$.
    Our goal will be to compute a coloring $\lambda$ with $f(S_\lambda) \leq 2f(S_{\lambda^*})$.
    This would complete the proof, since then we have
    \[
        (f(S_\lambda))^{1/p} \leq (2f(S_{\lambda^*}))^{1/p} = 2^{1/p}f^{1/p}(S_{\lambda^*}),
    \]
    and $f^{1/p}(S_{\lambda}), f^{1/p}(S_{\lambda^*})$ are precisely the objective values attained by $\lambda$ and $\lambda^*$, respectively, according to Program~(\ref{eq:p-mean-ecc}).

    We give a classic analysis based on the Lov{\'a}sz extension~\cite{lovasz1983submodular}.
    %     but we note that in practice more recent, faster methods are preferable.
    %    In particular, since each $f_c$ measures the cardinality of a set, very fast optimization techniques based on reductions to sparse graph cut problems are available~\cite{veldt2021approximate}.
    Some readers may find it helpful to observe that the following is conceptually equivalent to the textbook $2$-approximation for \textsc{Submodular Vertex Cover}\footnote{Given a graph $G$ and a submodular function $f$, find a vertex cover $C$ minimizing $f(C)$.}, where the graph in question is the \emph{conflict graph} $G$ of our edge-colored hypergraph $H$, as defined in~\Cref{sec:color-fair}.
    The connection between vertex colorings of edge-colored hypergraphs and vertex covers of their associated conflict graphs has been observed several times in the literature~\cite{angel2016clustering,cai2018alternating,kellerhals2023parameterized,veldt2023optimal}, and also appears elsewhere in the present work, e.g., in the proofs of~\Cref{thm:cfminecc-reduce-sparse-vc,thm-combinatorial-k-approx,thm:pc-multiple-classes-NP-hard}.

    Impose an arbitrary order on the edges of $E$ and for each vector $\boldsymbol{\gamma} \in [0, 1]^{|E|}$ map edges to components of $\boldsymbol{\gamma}$ according to this order.
    Henceforth, for a hyperedge $e$ we write $\gamma_e$ for the component of $\boldsymbol{\gamma}$ corresponding to $e$. Moreover, for a
    value $\rho$ selected uniformly at random from $[0, 1]$, we write $T_\rho(\boldsymbol{\gamma}) = \{e \colon \gamma_e \geq \rho\}$.
    Then the Lov{\'a}sz extension $\hat{f}\colon [0, 1]^{|E|} \rightarrow \mathbb{R}$ of $f$ is given by
    \[
        \hat{f}(\boldsymbol{\gamma}) = \mathbb{E}[f(T_\rho(\boldsymbol{\gamma}))].
    \]
    This $\hat{f}$ is convex~\cite{lovasz1983submodular}, so we may efficiently optimize the following program:
    %
    \begin{align}
        \label{eq:lovasz}
        \begin{aligned}
            \text{min} \quad  & \hat{f}(\gamma)                 \\
            \text{s.t.} \quad & \gamma_e + \gamma_f \geq 1\quad \\
                              & \gamma_e \geq 0                 \\
        \end{aligned}
        \begin{aligned}
             &                                                                                                         \\
             & \text{for all } e, f \in E \text{ such that } e \cap f \neq \emptyset \text{ and } \ell(e) \neq \ell(f) \\
             & \text{for all } e \in E.
        \end{aligned}
    \end{align}
    Consider the binary vector given by $\gamma_e = 1$ if $e \in S_{\lambda_*}$ or $0$ otherwise; note that this vector satisfies the constraints of Program~(\ref{eq:lovasz}). Hence, we can see that the minimum value for Program~(\ref{eq:lovasz}) provides a lower bound on $f(S_{\lambda_*})$.

    Let $\boldsymbol{\gamma}$ be a minimizer of Program~(\ref{eq:lovasz}), and let
    \[
        S = \left\{e \in E \colon \gamma_e \geq \frac{1}{2}\right\}.
    \]
    The first constraint of Program~\ref{eq:lovasz} ensures that $S$ contains at least one member of every pair of overlapping and distinctly colored hyperedges.
    Thus, it is trivial to compute a coloring $\lambda$ with $S_\lambda \subseteq S$.
    It follows from monotonicity that $f(S_\lambda) \leq f(S)$, and that for each $\rho \leq \frac{1}{2}$, $f(S) \leq f(T_\rho(\boldsymbol{\gamma}))$.
    Putting it all together, we have

    \[
        \frac{f(S_\lambda)}{2} \leq \frac{f(S)}{2} = \int_{0}^{\frac{1}{2}} f(S) \ \mathrm{d}\rho \leq \int_{0}^{\frac{1}{2}} f(T_\rho(\boldsymbol{\gamma})) \ \mathrm{d}\rho \leq \int_{0}^{1} f(T_\rho(\boldsymbol{\gamma})) \ \mathrm{d}\rho = \hat{f}(\boldsymbol{\gamma}) \leq f(S_{\lambda^*}),
    \]
    which completes the proof.

\end{proof}
