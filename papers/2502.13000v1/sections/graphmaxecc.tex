\begin{algorithm}[t]
	\caption{An approximation algorithm for \maxecc{}}
	\label{alg:graph_max_ecc}
	\begin{algorithmic}
		\STATE Obtain optimal LP variables $\{z_e; x_v^c\}$ for the relaxation
		\STATE $\pi \leftarrow \text{uniform random ordering of colors } [k]$
		% \FOR{$c \in [k]$}
		%     \STATE $\alpha_c \leftarrow \text{ a uniform random value in } [0, 1]$
		% \ENDFOR
		\STATE For $c \in [k]$, $\alpha_c \leftarrow $ uniform random threshold in $[0,1]$
		\FOR{$v \in V$}
		\STATE $S_v \leftarrow \left\{c \in [k] \mid x_v^c \geq 2/3 \right\}$; $W_v \leftarrow [k] \setminus S_v$
		% \STATE
		\STATE $W'_v = \left\{ c \in W_v \mid \alpha_c < x_v^c \right\}$
		% \STATE
		\IF{$|W'_v| > 0$}
		\STATE $\lambda(v) \leftarrow \argmax_{i \in W'_v} \pi(i)$
		\ELSIF{$\exists c \text{ s.t. } S_v = \left\{ c \right\}$}
		\STATE $\lambda(v) \leftarrow c$
		\ELSE
		\STATE $\lambda(v) \leftarrow \text{ arbitrary color}$
		\ENDIF
		\ENDFOR
	\end{algorithmic}
\end{algorithm}
Algorithm \ref{alg:graph_max_ecc} is our refined algorithm for \maxecc{} in graphs ($r = 2$). It solves the LP relaxation, generates color thresholds $\{\alpha_i \colon i \in [k]\}$, and generates a uniform random color permutation $\pi$ in the same way as Algorithm~\ref{alg:hyper_maxecc}. However, it differs in that it partitions colors for each $v$ into colors that $v$ wants \emph{strongly} or \emph{weakly}, given respectively by the sets:
\begin{align*}
	S_v = \{ i \in [k] \colon x_v^i \geq 2/3\} \text{ and } W_v &= [k] - S_v.
\end{align*}
The LP constraint $\sum_{i = 1}^k x_v^i = 1$ implies that $S_v$ can contain at most one color. It is also possible that $S_v = \varnothing$. We say color $i$ is \textit{strong for $v$} if $S_v = \{i\}$, otherwise $i$ \textit{weak for $v$}.

As a slight variation on our hypergraph algorithm, Algorithm~\ref{alg:graph_max_ecc} first checks if $v$ specifically wants any \emph{weak} colors (as determined by color thresholds $\{\alpha_c \colon c \in [k]\}$. If so, it gives $v$ the weak color with highest priority (as defined by $\pi$). If $v$ wants to weak colors but has a strong color, then $v$ is assigned the strong color. If neither happens, $v$ is given an arbitrary color. 
%
Prioritizing weak colors in this way appears counterintuitive, since if $v$ has a strong color it is a strong indication that $v$ should be color $c$. To explain the rationale: note that $x_v^c \geq 2/3$ still implies $v$ will be given color $c$ with high probability, since a large value for $x_v^c$ makes it less likely $v$ will want other colors. Meanwhile, prioritizing other colors will make it possible to lower bound the probability that an edge $e = (u,v)$ is satisfied even if $\ell(e)$ is not strong for $u$ or $v$.
Concretely, we are able to prove the following result for an arbitrary edge $e$, which proves our approximation guarantee.
\begin{theorem}
	\label{thm:graphecc}
	For every $e \in E$, $\prob[\text{$e$ is satisfied}] \geq p z_e$ where $p = \frac{154}{405} > 0.38$ when running Algorithm~\ref{alg:graph_max_ecc}.
\end{theorem}
To prove this result, we fix $e = (u,v)$ with color $c = \ell(e)$ and set $C = [k] \backslash \{c\}$. As before, $X_v^i$ is the event that $v$ wants color $i$. We furthermore use $Y_v^i$ to denote the event that $v$ is \emph{actually assigned} color $i$ by Algorithm~\ref{alg:graph_max_ecc}. We define $N_v$ to be the event that $v$ wants \emph{no} colors in $C$. If $c$ is strong for $v$, the event $N_v$ is equivalent to the event that $v$ wants no weak colors and is therefore assigned color $c$. Events $X_u^i$, $Y_u^i$, and $N_u$ are defined analogously for u. Our proof of Theorem~\ref{thm:graphecc} relies on the following supporting lemma.
% some of which are purely algebraic that are independent of ECC, and some of which directly use our notation four our LP rounding techniques. 
\begin{lemma}
	\label{lem:dependent_y_n_x}
	Given an edge $e = (u,v)$ of color $c$ {with \color{blue} $S_v = \{c\}$, and $c \in W_u$,} we have
	\[
	\prob\left[Y_u^c \mid N_v \cap X_u^c\right] \geq \prob\left[Y_u^c \mid X_u^c\right].
	\]
\end{lemma}
We also require the following definition and Lemmas~\ref{lem:sum_to_prod}-\ref{lem:bounding_constraints}, which are purely algebraic but will be used at various points to bound certain probabilities. 

For intuition, if we consider a set of $m$ mutually independent events $\mathcal{E} = \{E_1, E_2, \cdots, E_m\}$, whose probabilities are encoded in a vector $\vx$ where the $i$th entry is $x_i = \prob[E_i]$, the function $P$ in Definition~\ref{def:prob} is the probability that exactly $t$ of the events in $\mathcal{E}$ happen. In practice, we will apply this with $\mathcal{E}$ representing a subset of colors in the ECC instance, and the vector $\vx$ encoding LP variables for some node $u$ and that set of colors (which by Observation~\ref{obs:cv} are probabilities for wanting those colors). Lemmas~\ref{lem:bounding} and \ref{lem:bounding_constraints} will then aid in bounding the probability that a node is assigned a certain color, conditioned on how many other colors it wants. 

\begin{definition}
	\label{def:prob}
	Let $m$ be a nonnegative integer and $t$ be an integer. Given a vector $\vx \in \mathbb{R}^m$, if $m \geq t > 0$, we define the function $P(\vx, t)$ as follows:
	\[
	P(\vx, t) = \sum_{I \in {[m] \choose t}} \left( \prod_{i \in I} x_i \prod_{j\in [m] \setminus I} (1 - x_j) \right),
	\]
	and for other choices of $t$ and $m$ we define
	\begin{equation*}
		P(\vx, t) = \begin{cases}
			0 & \text{ if $m < t$ or $t < 0$} \\
%			0 & \text{ if $t < 0$} \\
			1 & \text{ if $0 = m = t$} \\
			\prod_{i = 1}^m (1 - x_i) & \text{ if $0 = t < m$.}
		\end{cases} 
	\end{equation*}
\end{definition}

\begin{lemma}
	\label{lem:sum_to_prod}
	Let $\beta \in [0,1]$ be a constant and $\mathbf{x} \in \mathbb{R}^m_{\geq 0}$ be a length $m$ nonnegative vector satisfying $\sum_{t=1}^m x_t \leq \beta$, then we have $\prod_{t=1}^m (1 - x_t) \geq 1 - \beta$.
\end{lemma}

\begin{lemma}
	\label{lem:bounding}
	Let $m \geq 2$ be an integer and
	$a_0, a_1, \hdots, a_m$ be values such that for every $t \in [0, m-2]$, $a_{t+1} \leq a_t$ and $2 a_{t+1} \leq a_t + a_{t+2}$.
	Let $\mathcal{D} = \{ \vx \in [0,2/3]^m \colon \sum_{i = 1}^m x_i \leq 1 \}$ be the domain of a function
	$f : \mathcal{D} \rightarrow \mathbb{R}$ defined as
	\[
	f(\vx) = \sum_{t=0}^m a_t P(\vx, t).
	\]
	Then $f$ is minimized (over domain $\mathcal{D}$) by any vector $\vx^*$ with one entry set to $2/3$, one entry to $1/3$, and every other entry to $0$. Furthermore we have
	\begin{equation}
		\label{eq:minval}
		f(\vx^*) = \frac{2}{9}(a_0 + a_2) + \frac{5}{9}a_1.
	\end{equation}
\end{lemma}
The following lemma shows two choices for the sequence $\{a_t\}$ for which the conditions in Lemma \ref{lem:bounding} hold.
\begin{lemma}
	\label{lem:bounding_constraints}
	The inequalities $a_t \geq a_{t+1}$ and $a_t + a_{t+2} \geq 2 a_{t+1}$ hold for sequence $a_t = \frac{1}{1+g+t}$ where $g \geq 0$ is an arbitrary fixed integer. These inequalities also hold for the sequence
	\begin{align*}
		a_t &= \frac{2}{9}\left( \frac{1}{t+1} + \frac{1}{t+3} \right) + \frac{5}{9} \left( \frac{1}{t+2} \right).
	\end{align*}
\end{lemma}
\begin{proof}[Proof of Theorem~\ref{thm:graphecc}]
	
	We break the proof up into three cases, which depend on whether 2, 1, or neither of the nodes in $e = (u,v)$ have $c = \ell(e)$ as a strong color.
	
	\textbf{Case 1:} $c$ is strong for both $u$ and $v$, i.e., $S_u = S_v = \{c\}$.\\
	Since $c$ is the strong color for both $u$ and $v$, $e$ is satisfied if and only if $W'_u = W'_v = \emptyset$. Additionally, because nodes can only have a single strong color and we know $c$ is strong for both $u$ and $v$ we know that all other colors must be weak for both $u$ and $v$. Using the property that probabilities regarding separate colors are independent we have
	\begin{align*}
		\prob\left[e \text{ is satisfied}\right] & = \prob\left[W'_u = W'_v = \emptyset\right] \\
		& = \prod_{i \in C}\prob\left[ i \notin W'_u \cup W'_v \right]
	\end{align*}
	Consider a color $i \in C_v$, which by definition means $x_v^i \geq x_u^i$. There are three options for the random threshold $\alpha_i$:
	\begin{itemize}
		\item $\alpha_i < x_u^i \leq x_v^i$, which happens with probability $x_u^i$ and implies that $i \in W'_u \cap W'_v$,
		\item $x_u^i < \alpha_i \leq x_v^i$, which happens with probability $x_v^i - x_u^i$ and implies $i \in W'_v$, $i \notin W'_u$, and
		\item $x_u^i \leq x_v^i < \alpha_i$, which happens with probability $1 - x_v^i$ and implies $i \notin W_u' \cup W_v'$.
	\end{itemize}
	Thus, for $i \in C_v$ we have $\prob\left[i \notin W'_u \cup W'_v\right] = (1 - x_v^i)$ and similarly for $i \in C_u$ we have $\prob\left[i \notin W'_u \cup W'_v\right] = (1 - x_u^i)$. This gives
	\begin{align*}
		\prod_{i \in C}\prob\left[ i \notin W'_u \cup W'_v \right] & = \prod_{i \in C_v}(1 - x_v^i)\prod_{i \in C_u}(1 - x_u^i).
	\end{align*}
	The fact that $c$ is strong for both $u$ and $v$ means $x_v^i \geq 2/3$ and $x_u^i \geq 2/3$. From the equality constraint in the LP we see that for $w\in\{u,v\}$ we have $\sum_{i \in C}x_w^i \leq 1 - 2/3 = 1/3$. Applying Lemma \ref{lem:sum_to_prod} gives
	\begin{align*}
		\prod_{i \in C_v}(1 - x_v^i)\prod_{i \in C_u}(1 - x_u^i) & \geq \frac{2}{3}\frac{2}{3} = \frac{4}{9} \geq \frac{4}{9}z_e.
	\end{align*}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\textbf{Case 2:} $c$ is strong for one of $u$ or $v$. \\
	Without loss of generality we say $S_v = \{c\}$ and $c \in W_u$. 
	Edge $e$ is satisfied if and only if $Y_u^c \cap Y_v^c$ holds. 
	Because $c$ is strong for $v$, event $Y_v^c$ holds if and only if $N_v$ holds. Using the fact that $Y_u^c = Y_u^c \cap X_u^c$, we can write
	\[
	\prob\left[e \text{ is satisfied}\right] = \prob\left[Y_u^c \cap X_u^c \cap N_v\right].
	\]
	Using Bayes' Theorm, the fact that $X_u^c$ and $N_v$ are independent\footnote{Independence follows from the fact that $X_u^c$ is concerned with color $c$, while $N_v$ is concerned with a disjoint color set $C = [k]\backslash \{c\}$.}, Observation~\ref{obs:cv}, and Lemma~\ref{lem:dependent_y_n_x}, we see that
	\begin{align*}
		\prob\left[Y_u^c \cap X_u^c \cap N_v\right] & = \prob\left[ Y_u^c \mid N_v \cap X_u^c \right] \prob\left[ N_v \cap X_u^c \right] \\
		& = \prob\left[ Y_u^c \mid N_v \cap X_u^c \right] \prob\left[ N_v \right] \prob\left[ X_u^c \right] \\
		& = \prob\left[ Y_u^c \mid N_v \cap X_u^c \right] \prob\left[ N_v \right] x_u^c \\
		& \geq \prob\left[ Y_u^c \mid N_v \cap X_u^c \right] \prob\left[ N_v \right] z_e \\
		& \geq \prob\left[ Y_u^c \mid X_u^c \right] \prob\left[ N_v \right] z_e.
	\end{align*}
	Lemma \ref{lem:dependent_y_n_x} then gives
	\begin{align*}
		\prob\left[ Y_u^c \mid N_v \cap X_u^c \right] \prob\left[ N_v \right] z_e & \geq \prob\left[ Y_u^c \mid X_u^c \right] \prob\left[ N_v \right].
	\end{align*}
	Using $\overline{X}_v^i$ to indicate $v$ \emph{does not} want $i$, we get
	\[
	\prob\left[ N_v \right] = \prob\left[ \bigcap_{i \in C} \overline{X}_v^i \right] = \prod_{i \in C}(1 - x_v^i).
	\]
	As in Case 1, because $c$ is strong for $v$, we know that $\sum_{i \in C} x_v^i \leq 1/3$ and applying Lemma \ref{lem:sum_to_prod} gives us that $\prob\left[ N_v \right] \geq 2/3$. 
	
	
	Finally we must bound $\prob\left[ Y_u^c \mid X_u^c \right]$. Since 
	$c$ is weak for $u$ (i.e., $c \in W_u$), it will be convenient to consider all weak colors for $u$ other than $c$, which we will denote by $\hat{W}_u = W_u \backslash \{c\}$. We will then use $\hat{W}_u' = \{ i \in \hat{W}_u \colon \alpha_i < x_u^i\}$ to denote the set of colors in $\hat{W}_u$ that $u$ wants. Note that $X_u^c$ is independent of the number of colors in $\hat{W}_u$ that $u$ wants. 
	
	Because of the global ordering of colors, conditioned on $u$ wanting $c$ and wanting exactly $t$ colors in $\hat{W}_u$, there is a $1/(t+1)$ chance that $c$ is chosen first by the permutation $\pi$, and is therefore assigned to $u$. Formally:
	\begin{equation*}
		\prob\left[ Y_u^c \mid X_u^c  \cap (|\hat{W}'_u| = t)\right] = \frac{1}{t+1}.
	\end{equation*}
	We define $p_t = \prob[ |\hat{W}'_u| = t]$, that is the probability that exactly $t$ colors from $\hat{W}_u$ are wanted. Using the vector $\vx_v[\hat{W}_u]$ to encode LP variables for node $v$ for the colors in $\hat{W}_u$ we see that $p_i = P(\vx_v[\hat{W}_u], i)$. Therefore, the law of total probability implies
	\begin{equation}
		\label{eq:mainprob}
		\prob\left[ Y_u^c \mid X_u^c \right] 
		% = p_0 + \frac{1}{2}p_1 + \cdots + \frac{1}{|\hat{W}_u| + 1}p_{|\hat{W}_u|}.
		= \sum_{t = 0}^{|\hat{W}_u|} \frac{1}{1+t} p_t.
	\end{equation}
	Eq.~\eqref{eq:mainprob} is exactly of the form in Lemma \ref{lem:bounding} with $a_t = 1/(t+1)$. From Lemma \ref{lem:bounding_constraints}, we know this sequence $\{a_t\}$ satisfies the constraints needed by Lemma \ref{lem:bounding}. Combining this with the bound established earlier on $\prob\left[ N_v \right]$ gives
	\begin{align*}
		\prob\left[e \text{ is satisfied}\right] & \geq \prob\left[ Y_u^c \mid X_u^c \right] \prob\left[ N_v \right] z_e \\
		& \geq \frac{31}{54} \cdot \frac{2}{3} z_e = \frac{31}{81}z_e > 0.3827 z_e.
	\end{align*}

	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\textbf{Case 3:} $c$ is weak for both $u$ and $v$, i.e., $c \in W_u \cap W_v$.\\
	First we condition the probability of satisfying $e$ on the event $X_u^c \cap X_v^c$. If one of $X_u^c$ or $X_v^c$ does not happen, then $e$ cannot be satisfied, so we have
	\begin{align*}
		\prob\left[ \text{$e$ is satisfied} \right]&= \prob\left[ \text{$e$ is satisfied} \mid X_u^c \cap X_v^c \right] \prob\left[ X_v^c \cap X_u^c \right] \\
		&= \prob\left[ \text{$e$ is satisfied} \mid X_u^c \cap X_v^c \right] z_e.
	\end{align*}
	Define $D = (W_u \cup W_v) \backslash \{c\}$ to be the set of weak colors (excluding $c$) that want at least one of $\{u,v\}$. If we condition on $u$ and $v$ both wanting $c$, it is still possible that $e$ will not be satisfied because a weak color $i \in D$ wants either $u$ or $v$, and the permutation $\pi$ will prioritize color $i$ over $c$. We bound the probability of satisfying $e$ by conditioning on the number of such colors in $D$ that end up being wanted. 
	
	Using the same logic as in Observation~\ref{obs:cv}, we can present a simpler way to characterize whether a color $i \in D$ wants at least one of $\{u,v\}$. Formally, we partition $D$ into the sets:
	\begin{align*}
		D_u &= \{i \in D \colon x_u^i \geq x_v^i \} \\
		D_v &= D - D_v.
	\end{align*}
	Note that a color $i \in D_u$ wants one or both nodes in $e$ if and only if $i$ wants $u$, and color $i \in D_v$ wants one or both nodes in $e$ if and only if $i$ wants $v$.  
	Mirroring our previous notation, let $D_u'$ denote the set of colors in $D_u$ that want node $u$ (based on the random color thresholds) and define $D_v'$ analogously. The set $D_u' \cup D_v'$ is then the set of weak colors that want one or more node in $e$. Thus, conditioned on $|D_u' \cup D_v'| = t$ and conditioned on $u$ and $v$ wanting $c$, in order for $e$ to be satisfied $c$ must come before all $t$ colors in $|D_u' \cup D_v'|$ in the random permutation $\pi$. Formally, this means
	\[
	\prob\left[ \text{$e$ is satisfied} \mid X_u^c \cap X_v^c \cap (|D'_u \cup D'_v| = t) \right] = \frac{1}{1 + t}.
	\]
	
	Again using the law of total probability and the fact that $X_u^c \cap X_v^c$ is independent from the size of $D_u' \cup D_v'$, we see
	\begin{align}
		\label{eq:dupdvp}
		\prob[ e &\text{ is satisfied} \mid X_u^c \cap X_v^c ]
		= \sum_{t = 0}^{|D|} \frac{1}{1+t} \prob\left[ |D'_u \cup D'_v| = t \right].
	\end{align}
	
	Observe now that $D_u$ and $D_v$ are disjoint color sets, which implies that $|D_u'|$ and $|D_v'|$ are independent random variables. This allows us to decouple $D_u'$ and $D_v'$ in the above expression since $\prob\left[ |D'_u \cup D'_v| = t \right] = \prob\left[ |D'_u| + |D'_v| = t \right]$. We define 
	\[
	p_i = \prob\left[ |D'_u| = i \right] \text{ and } q_i = \prob\left[ |D'_v| = i \right],
	\] 
	so that we can write
	\[
	\prob\left[ |D'_u| + |D'_v| = t \right] = \sum_{\substack{i, j \in [0, t] \\ i + j = t}} p_i q_j = \sum_{i = 0}^{|D_u|} p_i q_{t-i} .
	\]
	This allows us to re-write Eq.~\eqref{eq:dupdvp} as follows:
	\begin{align}
		\label{eq:decoupled}
		\prob[ e \text{ is satisfied} \mid X_u^c \cap X_v^c ] &= \sum_{i = 0}^{|D_u|} \sum_{j = 0}^{|D_v|} \frac{1}{1+i+j} p_i q_j.
	\end{align}
	
	Without loss of generality we now assume $|D_u| \leq |D_v|$. We now proceed case by case depending on the sizes of $D_u$ and $D_v$. As a shorthand we use $\rho = \prob[ e \text{ is satisfied} \mid X_u^c \cap X_v^c ]$. Our goal is to show $\rho \geq 154/405$. In the cases below, we use the vector $\vx_u[D_u]$ to encode LP variables for node $u$ and colors in $D_u$ so that $p_i = P(\vx_u[D_u], i)$, and likewise $q_i = P(\vx_v[D_v], i)$, to match with notation in Definition~\ref{def:prob} and Lemma~\ref{lem:bounding}.
	
	\textbf{Case 3a.} $|D_u| = |D_v| = 0$. \\
	No weak colors other than $c$ want $u$ or $v$, so $\rho = 1$.
	
	\textbf{Case 3b.} $|D_u| = 0$ and $|D_v| = 1$. \\
	Letting $a$ be the single color in $D_v$,
	\begin{align*}
		\rho & = p_0 q_0 + \frac{1}{2} p_0 q_1 = q_0 + \frac{1}{2} q_1 = (1 - x_v^a) + \frac{1}{2} x_v^a.
	\end{align*}
	Because $a$ is a weak color for $v$, we know $x_v^a \in [0, \frac{2}{3}]$, and the minimum value the probability can obtain is $\frac{2}{3} > \frac{154}{405}$.
	
	
	\textbf{Case 3c.} $|D_u| = |D_v| = 1$. \\
	Letting $a$ be the color in $D_v$ and $b$ be the color in $D_u$,
	\begin{align*}
		\rho & = p_0 q_0 + \frac{1}{2}(p_0 q_1 + p_1 q_0) + \frac{1}{3} p_1 q_1 \\
		& = (1 - x_u^b)(1 - x_v^a) \\ & ~~~~~~~~~~+ \frac{1}{2}((1 - x_u^b)x_v^a + x_u^b(1 - x_v^a)) + \frac{1}{3} x_u^b x_v^a.
	\end{align*}
	Because $a$ is weak for $v$ and $b$ is weak for $u$, we know $x_v^a, x_u^b \in [0, \frac{2}{3}]$. This gives a minimum value for the probability of $\frac{13}{27} > \frac{154}{405}$. 
	
	\textbf{Case 3d.} $|D_u| = 0$ and $|D_v| > 1$. \\
	In this case $p_0 = 1$, and Eq.~\eqref{eq:decoupled} simplifies to
	\begin{equation*}
		\rho = \sum_{j = 0}^{|D_v|} \frac{1}{j+1} q_j \geq \frac{31}{54},
	\end{equation*}
	where we have applied Lemma \ref{lem:bounding} with $a_j = \frac{1}{j+1}$.
	
	\textbf{Case 3e.} $|D_u| = 1$ and $|D_v| > 1$. \\
	Eq.~\eqref{eq:decoupled} simplifies to
	\begin{align*}
		\rho &= p_0 \sum_{j = 0}^{|D_v|} \frac{q_j}{j+1}  + p_1 \sum_{j = 0}^{|D_v|} \frac{q_j}{j+2} \geq p_0 \frac{31}{54} + p_1 \frac{19}{54},
	\end{align*}
	where we applied Lemma \ref{lem:bounding} twice, once with $a_j = \frac{1}{j+1}$ and once with $a_j = \frac{1}{j+2}$. The right hand side of the above bound has a minium value of $\frac{23}{54}$.
	
	\textbf{Case 3f.} $|D_u| > 1$ and $|D_v| > 1$.
	From Eq.~\eqref{eq:decoupled} we know
	\begin{align*}
		\rho &= \sum_{i = 0}^{|D_u|}  p_i \left(\sum_{j = 0}^{|D_v|} \frac{1}{1+i+j}  q_j \right).
	\end{align*}
	We then apply Lemma~\ref{lem:bounding} $|D_v|$ times, where the $i$th time we apply it we use $a_j = \frac{1}{1+i+j}$. 
	which yields the bound
	\begin{align}
		\label{eq:lemdvtimes}
		\sum_{j = 0}^{|D_v|} \frac{1}{1+i+j}  q_j \geq \frac{2}{9}\left( \frac{1}{i+1} + \frac{1}{i+3} \right) + \frac{5}{9} \left( \frac{1}{i+2} \right).
	\end{align}
	The right hand of~\eqref{eq:lemdvtimes} defines a new sequence
	\begin{equation}
		\label{eq:uglyai}
		a_i = \left( \frac{1}{i+1} + \frac{1}{i+3} \right) + \frac{5}{9} \left( \frac{1}{i+2} \right).
	\end{equation}
	We know from Lemma~\ref{lem:bounding_constraints} that this sequence $a_i$ in~\eqref{eq:uglyai} satisfies the conditions from Lemma~\ref{lem:bounding}, so applyign Lemma~\ref{lem:bounding} one more time and combining all steps gives
	\begin{align*}
		\rho &= \sum_{i = 0}^{|D_u|}  p_i \left(\sum_{j = 0}^{|D_v|} \frac{1}{1+i+j}  q_j \right)\\
		& \geq \sum_{i = 0}^{|D_u|}  p_i \left( \frac{2}{9}\left( \frac{1}{i+1} + \frac{1}{i+3} \right) + \frac{5}{9} \left( \frac{1}{i+2} \right) \right) \\
		&\geq \frac{154}{405}.
	\end{align*}
	
	Therefore, we have shown in all possible subcases of Case 3 that $\prob\left[ \text{$e$ is satisfied} \mid X_u^c \cap X_v^c \right] \geq \frac{154}{405}$. 
	
	Cases 1,2, and 3 all together show that for every $e \in E$ we have
	\[
	\prob\left[ \text{$e$ is satisfied} \right] \geq \frac{154}{405} z_e.
	\]
\end{proof}