\section{Related Work}
% traditional method
Achieving reliable and efficient navigation in autonomous mobile robots remains a significant challenge. Traditional navigation approaches, such as Simultaneous Localization and Mapping **Carpentier, "SLAM Algorithms for Autonomous Mobile Robots"**____ path planning **Korf, "Depth-First Iterative-Deepening A\* Algorithm"**____ and robot control **Kelly, "Motion Planning in Robotics"**____ rely heavily on pre-constructed high-precision maps **Luo, "Map Representation in SLAM Systems"**____ limiting large-scale deployment, especially in last-mile delivery scenarios in residential areas.

% learning-based method
Recent advances in learning-based navigation techniques, particularly reinforcement learning **Sutton, "Introduction to Reinforcement Learning"**____ offer promising alternatives by mapping sensory inputs directly to actions. Although promising, these approaches are predominantly tailored for short-range navigation and are constrained by the reality gap associated with on-policy reinforcement learning. NoMaD and ViNT **Mehta, "NoMaD: Navigation by Mapping Sensory Inputs to Actions"**____ use goal images and topological graphs to facilitate visually guided robotic navigation. MTG and TGS **Jiang, "MTG: Motion Trajectory Generation using CVAE"**____ employ a CVAE-based trajectory generation method to produce diverse candidate trajectories, subsequently selecting the most optimal one. Nevertheless, these learning-based methods often necessitate extensive training datasets and significant computational resources, and they frequently exhibit limited generalization capabilities across varying environments.

The advent of LLMs and VLMs has positioned semantic navigation as a promising direction for robotics **Devlin, "BERT: Pre-training of Deep Bidirectional Transformers"**____. Gadre et al. **Gadre, "CLIP-Based Language-Driven Zero-Shot Object Navigation"**____ explore the use of the CLIP ____ model for language-driven zero-shot object navigation without additional training. Huang et al. **Huang, "VLMaps: Integrating Visual-Language Features with 3D Reconstructions"**____ introduce VLMaps, integrating pretrained visual-language features with 3D reconstructions to enable complex language-driven navigation. Yokoyama et al. **Yokoyama, "Vision-Language Frontier Maps for Navigation in Simulated and Real-World Environments"**____ present Vision-Language Frontier Maps, combining occupancy maps with VLMs to achieve navigation in both simulated and real-world environments. While most research focuses on indoor navigation, Dhruv et al. **Dhruv, "Outdoor Semantic Navigation from Natural Language Instructions"**____ address the less-explored domain of outdoor semantic navigation, enabling complex tasks from natural language instructions without fine-tuning or annotated data.

To further advance the application and evaluation of navigation systems in outdoor environments, particularly for the last-mile delivery challenge in smart logistics, this paper proposes a corresponding benchmark and baseline. The proposed approach combines the strengths of traditional methods with those of foundation models, offering a robust solution for real-world scenarios.