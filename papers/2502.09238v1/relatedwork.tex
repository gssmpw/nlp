\section{Related Work}
% traditional method
Achieving reliable and efficient navigation in autonomous mobile robots remains a significant challenge. Traditional navigation approaches, such as Simultaneous Localization and Mapping \cite{Cadena2016}, path planning \cite{SnchezIbez2021}, and robot control \cite{Tzafestas2018}, rely heavily on pre-constructed high-precision maps \cite{Skog2009}, limiting large-scale deployment, especially in last-mile delivery scenarios in residential areas.

% learning-based method
Recent advances in learning-based navigation techniques, particularly reinforcement learning \cite{Hao2024,Liang2020}, offer promising alternatives by mapping sensory inputs directly to actions. Although promising, these approaches are predominantly tailored for short-range navigation and are constrained by the reality gap associated with on-policy reinforcement learning. NoMaD and ViNT \cite{sridhar2023nomad,shah2023vint} use goal images and topological graphs to facilitate visually guided robotic navigation. MTG and TGS \cite{Liang2024,tgs2024} employ a CVAE-based trajectory generation method to produce diverse candidate trajectories, subsequently selecting the most optimal one. Nevertheless, these learning-based methods often necessitate extensive training datasets and significant computational resources, and they frequently exhibit limited generalization capabilities across varying environments.

The advent of LLMs and VLMs has positioned semantic navigation as a promising direction for robotics \cite{VLA2024,Wang2024}. Gadre et al. \cite{cows} explore the use of the CLIP \cite{pmlr-v139-radford21a} model for language-driven zero-shot object navigation without additional training. Huang et al. \cite{Huang2023} introduce VLMaps, integrating pretrained visual-language features with 3D reconstructions to enable complex language-driven navigation. Yokoyama et al. \cite{Yokoyama2024} present Vision-Language Frontier Maps, combining occupancy maps with VLMs to achieve navigation in both simulated and real-world environments. While most research focuses on indoor navigation, Dhruv et al. \cite{shah2023lm} address the less-explored domain of outdoor semantic navigation, enabling complex tasks from natural language instructions without fine-tuning or annotated data.

To further advance the application and evaluation of navigation systems in outdoor environments, particularly for the last-mile delivery challenge in smart logistics, this paper proposes a corresponding benchmark and baseline. The proposed approach combines the strengths of traditional methods with those of foundation models, offering a robust solution for real-world scenarios.