\paragraph{Summary}
Our findings provide significant insights into the influence of correctness, explanations, and refinement on evaluation accuracy and user trust in AI-based planners. 
In particular, the findings are three-fold: 
(1) The \textbf{correctness} of the generated plans is the most significant factor that impacts the evaluation accuracy and user trust in the planners. As the PDDL solver is more capable of generating correct plans, it achieves the highest evaluation accuracy and trust. 
(2) The \textbf{explanation} component of the LLM planner improves evaluation accuracy, as LLM+Expl achieves higher accuracy than LLM alone. Despite this improvement, LLM+Expl minimally impacts user trust. However, alternative explanation methods may influence user trust differently from the manually generated explanations used in our approach.
% On the other hand, explanations may help refine the trust of the planner to a more appropriate level by indicating planner shortcomings.
(3) The \textbf{refinement} procedure in the LLM planner does not lead to a significant improvement in evaluation accuracy; however, it exhibits a positive influence on user trust that may indicate an overtrust in some situations.
% This finding is aligned with prior works showing that iterative refinements based on user feedback would increase user trust~\cite{kunkel2019let, sebo2019don}.
Finally, the propensity-to-trust analysis identifies correctness as the primary determinant of user trust, whereas explanations provided limited improvement in scenarios where the planner's accuracy is diminished.

% In conclusion, our results indicate that the planner's correctness is the dominant factor for both evaluation accuracy and user trust. Therefore, selecting high-quality training data and optimizing the training procedure of AI-based planners to improve planning correctness is the top priority. Once the AI planner achieves a similar correctness level to traditional graph-search planners, strengthening its capability to explain and refine plans will further improve user trust compared to traditional planners.

\paragraph{Future Research} Future steps in this research include expanding user studies with larger sample sizes to improve generalizability and including additional planning problems per session for a more comprehensive evaluation. Next, we will explore alternative methods for generating plan explanations beyond manual creation to identify approaches that more effectively enhance user trust. 
Additionally, we will examine user trust by employing multiple LLM-based planners with varying levels of planning accuracy to better understand the interplay between planning correctness and user trust. 
Furthermore, we aim to enable real-time user-planner interaction, allowing users to provide feedback and refine plans collaboratively, thereby fostering a more dynamic and user-centric planning process.
