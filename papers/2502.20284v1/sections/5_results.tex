This section presents findings from our user study on evaluation accuracy, user trust, and the propensity to trust scale.

\begin{figure}
    \centering
    % Group the first three figures with a common caption
    \begin{minipage}[b]{0.72\textwidth} % Adjust width to fit all subfigures
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figures/trust_bar_pddl_llm.pdf}
            \caption{PDDL vs. LLM.}
            \label{fig:trust_bar_pddl_llm}
        \end{subfigure}%
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figures/trust_bar_expl.pdf}
            \caption{LLM vs. LLM+Expl.}
            \label{fig:trust_bar_expl}
        \end{subfigure}%
        \hfill
        \begin{subfigure}[b]{0.32\textwidth}
            \centering
            \includegraphics[width=\linewidth]{figures/trust_bar_repair.pdf}
            \caption{LLM vs. LLM+Refine.}
            \label{fig:trust_bar_repair}
        \end{subfigure}
        \caption{Trust scores on a 7-point Likert scale before and after.}
        \label{fig:trust_bars}
    \end{minipage}%
    \hfill
    % Add the fourth figure
    \begin{minipage}[b]{0.23\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/correctness_bar.pdf}
        \caption{Evaluation accuracy measured by the number of correctly evaluated tasks.}
        \label{fig:correctness_bar}
    \end{minipage}
\end{figure}


\subsection{On Evaluation Accuracy}
\Cref{fig:correctness_bar} presents the average number of correctly evaluated tasks for each planner, with error bars indicating standard deviations. We used the Wilcoxon signed-rank test to evaluate our hypotheses H1-H3.

For \textbf{H1}, participants achieved an average accuracy of $1.76 \pm 0.50$ with the PDDL solver, compared to $1.52 \pm 0.56$ for the LLM planner. This result supports our hypothesis that correctness is a key determinant of evaluation accuracy. However, the difference was not statistically significant ($W=18, Z=-4.31, p=0.071, r=-0.801$). We suspect that increasing the sample size could reduce this uncertainty and strengthen the observed trend.

For \textbf{H2}, evaluation accuracy improved for the LLM planner when explanations were provided (LLM+Expl), reaching $1.76 \pm 0.43$. This difference was statistically significant ($W=5, Z=-4.59, p=0.020, r=-0.853$), supporting our hypothesis that planners with explanations increase evaluation accuracy.

For \textbf{H3}, the results for the LLM planner with refinement (LLM+Refine) did not align with our hypothesis. 
Participants achieved an average accuracy of $1.38 \pm 0.61$ with the LLM+Refine planner, compared to $1.52 \pm 0.56$ for the basic LLM planner. Although this result deviates from our hypothesis that refinement would improve evaluation accuracy, the difference is not statistically significant ($W=22, Z=-4.23, p=0.285, r=-0.785$). As a result, we cannot conclusively confirm or refute H3. One possible explanation for this deviation is overtrust: Participants may assume that the opportunity to revise the plan ensures the planner would correct itself, leading them to evaluate the revised plan less critically and, consequently, with lower accuracy.

\emph{Thus, the data suggests support for H1, confirms H2, and suggests rejection of H3.}

\subsection{On Trust}
\Cref{fig:trust_bars} shows participants' average self-reported trust levels before and after each intervention, measured on a 7-point Likert scale, with error bars representing standard deviations. We used the Wilcoxon signed-rank test to evaluate our hypotheses H4-H6.

For \textbf{H4}, \Cref{fig:trust_bar_pddl_llm} shows that PDDL achieved statistically significantly higher trust levels than LLM both \textbf{before} the intervention ($W=134.5, Z=-5.75, p<0.001, r=-0.742$) and \textbf{after} ($W=19, Z=-6.60, p<0.001, r=-0.852$). In terms of trust dynamics, participants' trust in PDDL significantly increased from $5.68 \pm 1.66$ to $6.27 \pm 1.02$ ($W=10, Z=-6.66, p=0.001, r=-0.860$). In contrast, trust in LLM showed a slight decrease from $3.97 \pm 2.22$ to $3.85 \pm 2.30$, though this change was not statistically significant ($W=215.50, Z=-5.15, p=0.722, r=-0.665$). These findings support the hypothesis that the correctness of planners is a key factor influencing human trust.

For \textbf{H5}, \Cref{fig:trust_bar_expl} shows no statistically significant difference in trust levels between LLM and LLM+Expl, both before and after the intervention. This result challenges our hypothesis that providing explanations would increase trust when correctness is controlled. 
One possible interpretation is that participants primarily value the objective correctness of the plans, with explanations offering little benefit unless correctness improves.
Alternatively, explanations may help participants calibrate their trust by revealing the planner's limitations, allowing them to adjust their trust to appropriate levels. This insight suggests that improving trust in LLMs for planning tasks may require prioritizing the objective correctness of the plans over supplementary explanations.

For \textbf{H6}, \Cref{fig:trust_bar_repair} shows a slight increase in trust levels with LLM+Refine. On average, trust rose from $3.97 \pm 2.22$ to $4.12 \pm 2.25$ before the intervention and from $3.85 \pm 2.30$ to $4.45 \pm 2.00$ after. While this trend is not statistically significant, it suggests a potential positive effect of refinement on human trust with the LLM planner.

\emph{Thus, the data supports H4, suggests rejection of H5, and suggests support of H6.}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/trust_propensity_stacked_ratio_bar.pdf}
    \caption{Propensity to Trust Scale: 4 out of 6 Questions with Statistically Significant Differences Highlighted (*$p<0.05$, **$p<0.01$).}
    \label{fig:propensity_to_trust_scale}
\end{figure}
\subsection{Propensity to Trust Scale}
The \emph{propensity to trust} scale consists of six questions used to assess an individual's tendency to trust machines based on their current behaviors~\cite{merritt2013trust}.
While we did not have specific hypotheses tied to this scale, we included it to gather initial insights for future exploration. 
We found that four questions showed statistically significant differences between planners using the Wilcoxon signed-rank test and are displayed in \Cref{fig:propensity_to_trust_scale}. Full results are provided in the appendix.

For \textbf{Q1} and \textbf{Q6}, we observe a clear shift toward agreement after the PDDL condition compared to the initial baseline. This suggests that participants were more inclined to trust AI planners following the PDDL session, likely due to the 100\% correctness of PDDL plans, which appears to boost trust.
In contrast, for \textbf{Q1}, \textbf{Q4}, and \textbf{Q5}, we see a notable reduction in agreement after interacting with the LLM planner compared to the PDDL solver. This decrease aligns with the reduced correctness of the LLM plans (50\%), highlighting the importance of correctness in maintaining trust in AI planners.
Interestingly, \textbf{Q4} reveals that providing explanations (LLM+Expl) helps recover participants' agreement levels compared to the basic LLM condition. However, this positive effect of explanations on trust propensity is limited, as it is only observed in one of the six questions.

These results underscore that correctness remains the dominant factor influencing participants' general trust attitude towards AI planners, with explanations offering only minimal benefit when correctness is suboptimal.
