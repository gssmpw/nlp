% context on planning
Planning is the process of determining a sequence of actions to transit from an initial state to a desired goal state. Planners---systems designed to generate such action sequences under given constraints---play a critical role in automating decision-making processes in domains such as robotic navigation, logistics optimization, and medical scheduling.

% limitation of traditional planners that led to LLM-based planners
Traditional planners, while effective in structured and predictable environments, often struggle with rigidity and lack of explainability. In contrast, Large Language Models (LLMs) have recently demonstrated strong performance in various domains, including text generation~\cite{li2024pre}, question answering~\cite{puri2020training,ram2021few}, and code completion~\cite{liu2020multi}. Unlike traditional planners, 
% LLMs support rapid generation of alternative plans, dynamic adjustments to new information, and intuitive interface with humans through natural language. 
LLMs support multi-plan generation (i.e., return multiple plans to enable users to choose), dynamic adjustments based on externally given information, and understandable communication with humans via natural language.
These strengths have sparked growing interest in using LLMs as planners across diverse domains, including robotics~\cite{ren2023robots,singh2023progprompt,verifiable-SDM,huang2022language}, healthcare~\cite{cascella2023evaluating,sallam2023chatgpt}, and law~\cite{wu2023precedent,cheong2024not}.

% concerns around LLM-based planners, especially around trust
However, the increasing use of LLM-based planners raises concerns, particularly regarding trust. Trust, defined as the willingness to rely on automated systems~\cite{lee2004trust}, is vital for the adoption of planning systems. Without trust, even systems with superior technical capabilities may struggle to gain acceptance in practical settings~\cite{vorm2022integrating}. 
Planning tasks are uniquely challenging due to their reliance on high correctness, sequential reasoning, and the need for robust adaptation to dynamic environments~\cite{allmendinger2017planning}.
These factors amplify the importance of trust, as both over-trust and under-trust can introduce errors or inefficiencies in planning and can have cascading effects on task success~\cite{talvitie2012problem,laurian2009trust}. Thus, fostering appropriate trust levels in LLM-based planners is essential for maximizing their potential while minimizing risks.

% Specific gap
While prior research has explored factors influencing trust in LLM-based systems, such as anthropomorphic cues~\cite{cohn2024believing}, the framing and presence of explanations~\cite{sharma2024would}, and user interface design~\cite{sun2024trust}, factors influencing human trust in LLMs in the context of planning tasks remain underexplored. 
As the Planning Domain Definition Language (PDDL) has become a common benchmark for evaluating the planning capabilities of LLMs~\cite{silver2022pddl, silver2024generalized}, existing work primarily focuses on technical performance metrics, such as plan correctness and efficiency. 
To the best of our knowledge, no prior studies have empirically investigated human trust in LLM-based planners compared to classical PDDL solvers in a PDDL domain.
\emph{This work bridges this gap by conducting an exploratory user study that evaluates trust in a PDDL domain}.
% Existing work of human trust in LLMs
% Recent studies have identified several factors that influence trust in LLM-based systems, including anthropomorphic cues, the framing and presence of explanations, and user interface design. For instance, research has shown that anthropomorphic cues, such as the use of first-person pronouns and speech-based interactions, can enhance user trust in LLMs by making them appear more human-like~\cite{cohn2024believing}. Additionally, providing explanations for LLM-generated responses has been found to significantly increase user trust, especially when users can compare various responses~\cite{sharma2024would}. The design of user interfaces also plays a crucial role; different interfaces can shape how users perceive and trust health information delivered by LLMs~\cite{sun2024trust}.

% pros and cons of LLM vs classical planner -> 3 independent variables
Specifically, LLMs possess unique capabilities and limitations compared to classical PDDL planners~\cite{mcdermott20001998, ghallab2004automated} that may affect trust levels.
For instance, LLMs can generate natural language explanations to clarify why specific decisions were made~\cite{DBLP:conf/nips/WangCCLML23,dobhal2024using} and iteratively refine their outputs based on user feedback~\cite{RLHF,Christiano2017RLHF,Ouyang2022FollowInstructions,DBLP:conf/mlsys/YangBIWCWT24}. These capabilities have been shown in other contexts to enhance user trust by making the planning process more transparent and interactive~\cite{kunkel2019let, sebo2019don}. However, LLMs also exhibit significant limitations, such as their inability to reliably generate or validate plans independently, even for relatively simple tasks~\cite{kambhampati2024llms, valmeekam2022large, silver2022pddl, valmeekam2023planning}.
These capabilities and limitations highlight the need for a deeper understanding of the interplay among correctness, explanation, and refinement.

% Dependent measures: how to measure trust
Trust can be evaluated using Likert-scale user questionnaires~\cite{martelaro2016tell,xu2015optimo,choi2015investigating} and broader instruments like the Propensity to Trust scale~\cite{merritt2013trust}, which assesses general attitudes toward machines. This study combines 7-point Likert scale trust scores as a subjective metric with users' evaluation accuracy of generated plans as an objective metric.

% Key findings
Key findings of our study reveal correctness as the dominant factor influencing both evaluation accuracy and trust, with the PDDL solver achieving the highest scores in both metrics. While explanations provided by the LLM planner enhanced evaluation accuracy, they had minimal effect on trust. Conversely, plan refinement showed potential to increase trust without improving evaluation accuracy. Notably, the results on refinement suggest that LLMs can gain user trust without genuine improvements in their planning capabilities, as the refined plan is generated using the same underlying model. This phenomenon underscores a critical implication: as most LLMs are fine-tuned via subjective human feedback~\cite{RLHF, Christiano2017RLHF}, the fine-tuned models tend to generate outputs that comply with human preferences, i.e., humans perceive as appealing or trustworthy, instead of objective correctness. Such tendencies could be exploited, intentionally or inadvertently, to potentially foster overtrust. Overall, the study results offer practical insights for designing human-centered AI planning systems.