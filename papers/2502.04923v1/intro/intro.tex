\section{Introduction}
\vspace{-0.3em}
In the realm of generative text-to-image models~\citep{dalle,imagen, sdxl,sd3,sd1.5, clip}, the integration of Low-Rank Adaptation (LoRA)~\citep{lora} in image generation stands out for its ability to fine-tune image synthesis with precision and minimal computational cost. 
LoRA stands out in its capability for controllable generation, it enables the creation of specific characters, particular types of clothing, unique styles, or other distinctive visual features, and can be trained and later used to produce varied and precise representations of these elements in the generated images.
However, existing image generation methodologies utilizing LoRAs encounter limitations in effectively combining multiple LoRAs, particularly as the quantity of LoRAs to be amalgamated increases, thus hindering the composition of complex images.
Given this limitation, a critical question emerges: How can we effectively composite multiple trained LoRAs in a training-free manner, while still retaining their unique individual attributes in image generation?

% \begin{wrapfigure}{r}{0.5\textwidth}
%   \begin{center}
%     \includegraphics[width=\textwidth]{image/mot.jpg}
%   \end{center}
%   \caption{The denoising process with a Character LoRA and a Background LoRA. The plot illustrates the difference in amplitude of high-frequency components $\Delta\mathcal{H}_{0.2}\left(\overline{\mathbf{x}}_{t};40\right)$ generated by the Character LoRA and Background LoRA after the inverse Fourier Transform, matching each step. The change rate of high-frequency components between $40$-step interval at step $t$.}
%   \label{fig:motivation}
% \end{wrapfigure}
\begin{figure}[ht]
    \centering
    \setlength{\abovecaptionskip}{2pt}
    \setlength{\belowcaptionskip}{-18pt}
    \begin{minipage}[b]{0.36\textwidth}
        \centering
        \includegraphics[width=\linewidth]{image/smot.jpg}
        \caption{The denoising process with a Character LoRA and a Background LoRA. The plot illustrates the difference in amplitude of high-frequency components $\Delta\mathcal{H}_{0.2}\left(\overline{\mathbf{x}}_{t};40\right)$ between $40$-step interval generated by the Character LoRA and Background LoRA after the inverse Fourier Transform, matching each step $t$.}
        \label{fig:motivation}
    \end{minipage}\hfill
    \begin{minipage}[b]{0.62\textwidth}
        \centering
        \includegraphics[width=\linewidth]{image/smot2.jpg}
        \caption{\textbf{Observation:} Prompt-only generation (Naive) and existing LoRA combination methods (Merge and Switch) often lead to semantic conflicts. This failure primarily arises because independent LoRAs are integrated to contribute equally to image generation during the denoising process. CMLoRA employs a frequency-domain-based LoRA scheduling mechanism to integrate multiple concept LoRAs, effectively addressing semantic conflicts.}
        \label{fig:smot2}
    \end{minipage}
\end{figure}

As shown in \Cref{fig:smot2}, we find that directly applying pre-trained LoRA modules to compose the image often leads to semantic conflicts. This failure primarily arises because independent LoRAs are integrated to contribute equally to image generation during the denoising process. We hypothesize that the difficulty in scaling multiple LoRA modules comes from the ``semantic conflicts" among them, as LoRAs are typically trained independently and fuse features with varying amplitudes across different frequency domains to the generated image. When these independent LoRAs are integrated to contribute equally to image generation, inherent conflicts may arise. To investigate LoRA behavior during the denoising process, we shift the perspective to the Fourier domain, a research area that has received limited prior investigation, because of its advantages: 1) efficient image feature detection 2) robustness to noise in the spatial domain~\citep{freq1}. \Cref{fig:motivation} exhibits a disparity in how Character and Background LoRAs function differently during the denoising process, indicating that their fusion of semantic information with varying amplitudes across different frequency spectra into the generated image. It is evident that the Character LoRA fuses a higher proportion of high-frequency components, resulting in greater variation in edges and textures compared to the Background LoRA, during the inference. This finding suggests that certain LoRAs introduce more pronounced high-frequency modifications during denoising, whereas others primarily influence low-frequency elements. This can be explained as follows: (1) Some LoRAs enhance high-frequency components, corresponding to rapid changes like edges and textures. (2) Others target low-frequency components, representing broader structures and smooth color transitions. Furthermore, high-frequency components are predominantly fused during the early stages of inference, aligning with the observation made in prior work: \textit{high-frequency components vary more significantly than low-frequency ones throughout the denoising process}~\citep{freeu}. Consequently, improper integration of various LoRAs may result in visual artifacts or semantic inconsistencies in the generated images.

\vspace{-3pt}

In light of the phenomenon found in \Cref{fig:motivation}, we propose a Fourier-based method to classify LoRAs with different frequency responses and group them into distinct sets. Through our profiling approach, we categorize LoRAs into high-frequency and low-frequency sets. During inference, high-frequency LoRAs are employed predominantly in the early denoising stages, while low-frequency LoRAs are applied dominantly later. Building upon these insights, we introduce Cached Multi-LoRA (CMLoRA), a novel framework for multi-LoRA composition. During inference, CMLoRA employs a flexible multi-LoRA injection backbone: denoising the noisy image with the predominant contributions of dominant LoRAs, while incorporating supplementary contributions from cached non-dominant LoRAs. Guided by an effective frequency-domain-based scheduling mechanism, CMLoRA selects a dominant LoRA from the high-frequency set in the early stages of denoising, transitioning to a dominant LoRA from the low-frequency set in the later stages. Additionally, we introduce a specialized modulation factor as a hyperparameter, which scales the contribution of the dominant LoRA during inference, providing precise control over its influence on the overall composition. As a result, CMLoRA effectively resolves the semantic conflicts that frequently occur during multi-LoRA composition, enhancing the quality of generated images and computational efficiency.

Our findings, encompassing both qualitative and quantitative results, demonstrate that CMLoRA outperforms existing LoRA composition approaches, and we make the following contributions:

\begin{itemize}[noitemsep, topsep=-8pt, leftmargin=*]
    \item We introduce a Fourier-based approach for LoRA partition that leverages frequency characteristics. Our method is grounded in frequency-domain profiling of LoRAs during the inference stage of the diffusion model, enabling us to classify LoRAs into high- and low-frequency sets. This classification allows for more effective LoRA fusion by grouping LoRAs with similar frequency behaviors, reducing potential semantic conflicts and improving the coherence of generated images.
    
    \item We propose a flexible LoRA composition framework: Cached Multi-LoRA, designed to optimize LoRA integration without requiring additional training. Our method overcomes existing constraints on the number of LoRAs that can be integrated, offering enhanced flexibility, improved image quality, compared to state-of-the-art LoRA integration methods.

    % \item  Based on the similarity analysis of latent feature maps, we introduce a dynamic and non-uniform caching strategy tailored to individual LoRAs, which can be applied across diverse LoRA composition methods, potentially mitigate the issue of semantic conflicts while improving computational efficiency.

    \item We address the problem of the lack of evaluation methodologies and metrics in multi-LoRA image generation by introducing an improved evaluator built upon MiniCPM-V. We set a new comprehensive benchmark for assessing four aspects of multi-LoRA composition: 1) element integration, 2) spatial consistency, 3) semantic accuracy, and 4) aesthetic quality.

    % \item We conducted several experiments to show that our proposed Cached Multi-LoRA can outperform current LoRA integration methods.

\end{itemize}

