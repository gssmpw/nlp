@inproceedings{HendrycksD17,
  author = {Dan Hendrycks and Kevin Gimpel},
  title = {A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks},
  booktitle = "The Fifth " # ICLR,
  year = 2017,
}

@inproceedings{HendrycksD19,
  author    = {Dan Hendrycks and
               Mantas Mazeika and
               Thomas G. Dietterich},
  title     = {Deep Anomaly Detection with Outlier Exposure},
  booktitle = "The Seventh " # ICLR,
  year      = 2019,
}

@inproceedings{HuangR21,
  author = {Rui Huang and Yixuan Li},
  title = {{MOS:} {T}owards scaling out-of-distribution detection for large semantic space},
  booktitle = CVPR,
  pages = {8710--8719},
  year = 2021
}

@article{Kim2024UnsupervisedOD,
title = {Unsupervised outlier detection using random subspace and subsampling ensembles of Dirichlet process mixtures},
journal = PR,
volume = {156},
pages = {110846},
year = {2024},
author = {Dongwook Kim and Juyeon Park and Hee Cheol Chung and Seonghyun Jeong},
abstract = {Probabilistic mixture models are recognized as effective tools for unsupervised outlier detection owing to their interpretability and global characteristics. Among these, Dirichlet process mixture models stand out as a strong alternative to conventional finite mixture models for both clustering and outlier detection tasks. Unlike finite mixture models, Dirichlet process mixtures are infinite mixture models that automatically determine the number of mixture components based on the data. Despite their advantages, the adoption of Dirichlet process mixture models for unsupervised outlier detection has been limited by challenges related to computational inefficiency and sensitivity to outliers in the construction of outlier detectors. Additionally, Dirichlet process Gaussian mixtures struggle to effectively model non-Gaussian data with discrete or binary features. To address these challenges, we propose a novel outlier detection method that utilizes ensembles of Dirichlet process Gaussian mixtures. This unsupervised algorithm employs random subspace and subsampling ensembles to ensure efficient computation and improve the robustness of the outlier detector. The ensemble approach further improves the suitability of the proposed method for detecting outliers in non-Gaussian data. Furthermore, our method uses variational inference for Dirichlet process mixtures, which ensures both efficient and rapid computation. Empirical analyses using benchmark datasets demonstrate that our method outperforms existing approaches in unsupervised outlier detection.}
}

@inproceedings{LiangS18,
  author = {Shiyu Liang and Yixuan Li and R. Srikant},
  title={Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks},
  booktitle = "The Sixth " # ICLR,
  year = 2018
}

@inproceedings{LiuW20,
  author    = {Weitang Liu and
               Xiaoyun Wang and
               John D. Owens and
               Yixuan Li},
  title     = {Energy-based Out-of-distribution Detection},
  booktitle = NeurIPS,
  year      = 2020,
  volume    = {33},
  pages = {21464--21475},
  publisher = {Curran Associates, Inc.},
}

@inproceedings{TackJ20,
 author = {Tack, Jihoon and Mo, Sangwoo and Jeong, Jongheon and Shin, Jinwoo},
 booktitle = NeurIPS,
 pages = {11839--11852},
 publisher = {Curran Associates, Inc.},
 title = {{CSI}: {N}ovelty Detection via Contrastive Learning on Distributionally Shifted Instances},
 volume = {33},
 year = {2020}
}

@inproceedings{guo17tempscale,
  title = 	 {On Calibration of Modern Neural Networks},
  author =       {Chuan Guo and Geoff Pleiss and Yu Sun and Kilian Q. Weinberger},
  booktitle =  "Proceedings of the 34th " # ICML,
  pages = 	 {1321--1330},
  year = 	 {2017},
  volume = 	 {70},
  publisher =    {PMLR},
}

@inproceedings{lee18mds,
	author = {Lee, Kimin and Lee, Kibok and Lee, Honglak and Shin, Jinwoo},
	booktitle = NeurIPS,
	publisher = {Curran Associates, Inc.},
	title = {A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks},
	volume = {31},
	year = {2018},
    pages = {},
}

@inproceedings{linderman23,
  title = 	 {Fine-grain Inference on Out-of-Distribution Data with Hierarchical Classification},
  author =       {Linderman, Randolph and Zhang, Jingyang and Inkawhich, Nathan and Li, Hai and Chen, Yiran},
  booktitle = 	 {Proceedings of The 2nd Conference on Lifelong Learning Agents (CoLLAs)},
  pages = 	 {162--183},
  year = 	 {2023},
  volume = 	 {232},
  publisher =    {PMLR},
  abstract = 	 {Machine learning methods must be trusted to make appropriate decisions in real-world environments, even when faced with out-of-distribution (OOD) samples. Many current approaches simply aim to detect OOD examples and alert the user when an unrecognized input is given. However, when the OOD sample significantly overlaps with the training data, a binary anomaly detection is not interpretable or explainable, and provides little information to the user. We propose a new model for OOD detection that makes predictions at varying levels of granularity—as the inputs become more ambiguous, the model predictions become coarser and more conservative. Consider an animal classifier that encounters an unknown bird species and a car. Both cases are OOD, but the user gains more information if the classifier recognizes that its uncertainty over the particular species is too large and predicts “bird” instead of detecting it as OOD. Furthermore, we diagnose the classifier’s performance at each level of the hierarchy improving the explainability and interpretability of the model’s predictions. We demonstrate the effectiveness of hierarchical classifiers for both fine- and coarse-grained OOD tasks.}
}

@inproceedings{malinin2018predictive,
  title={Predictive uncertainty estimation via prior networks},
  author={Malinin, Andrey and Gales, Mark},
  booktitle=NeurIPS,
  volume={31},
  year={2018},
  publisher = {Curran Associates, Inc.},
}

@inproceedings{malinin2019reverse,
  title={Reverse {KL}-divergence training of prior networks: {I}mproved uncertainty and adversarial robustness},
  author={Malinin, Andrey and Gales, Mark},
  booktitle=NeurIPS,
  volume={32},
  year={2019},
  publisher = {Curran Associates, Inc.},
}

@inproceedings{ren2019likelihood,
 author = {Ren, Jie and Liu, Peter J. and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
 booktitle = NeurIPS,
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Likelihood Ratios for Out-of-Distribution Detection},
 volume = {32},
 year = {2019}
}

@inproceedings{ren21rmds,
      title={A Simple Fix to {M}ahalanobis Distance for Improving Near-{OOD} Detection},
      author={Jie Ren and Stanislav Fort and Jeremiah Liu and Abhijit Guha Roy and Shreyas Padhy and Balaji Lakshminarayanan},
      year={2021},
      booktitle=ICMLW,
      series={Uncertainty \& Robustness in Deep Learning}
}

@article{shotwell2011,
	author = {Matthew S. Shotwell and Elizabeth H. Slate},
	journal = {Bayesian Analysis},
	number = {4},
	pages = {665 -- 690},
	publisher = {International Society for Bayesian Analysis},
	title = {Bayesian Outlier Detection with {D}irichlet Process Mixtures},
	volume = {6},
	year = {2011},
}

@inproceedings{sun2022out,
  title = 	 {Out-of-Distribution Detection with Deep Nearest Neighbors},
  author =       {Sun, Yiyou and Ming, Yifei and Zhu, Xiaojin and Li, Yixuan},
  booktitle = "Proceedings of the 39th " # ICML,
  pages = 	 {20827--20840},
  year = 	 {2022},
  volume = 	 {162},
  publisher =    {PMLR}

@inproceedings{varadarajan17,
  author={Varadarajan, Jagannadan and Subramanian, Ramanathan and Ahuja, Narendra and Moulin, Pierre and Odobez, Jean-Marc},
  booktitle=WACV,
  title={Active Online Anomaly Detection Using {D}irichlet Process Mixture Model and {G}aussian Process Classification},
  year={2017},
  pages={615-623},
}

@inproceedings{wei2022mitigating,
  title={Mitigating neural network overconfidence with logit normalization},
  author={Wei, Hongxin and Xie, Renchunzi and Cheng, Hao and Feng, Lei and An, Bo and Li, Yixuan},
  booktitle="Proceedings of the 39th " # ICML,
  pages={23631--23644},
  year={2022},
  organization={PMLR}
}

@inproceedings{zhang2021mixture,
  author       = {Jingyang Zhang and
                  Nathan Inkawhich and
                  Randolph Linderman and
                  Yiran Chen and
                  Hai Li},
  title        = {Mixture Outlier Exposure: Towards Out-of-Distribution Detection in
                  Fine-grained Environments},
  booktitle    = WACV,
  pages        = {5520--5529},
  publisher    = {{IEEE}},
  year         = {2023},
}

