\section{Related Works}
\vspace{-2pt}
\label{sec:Related_works}
%-------------------------------------------------------------------------
\noindent\textbf{Frame-based Video Frame Interpolation.} can be classified into three categories: motion-based approaches____, kernel-based approaches____ and phase-based approaches____.
Thanks to the progress of optical flow algorithms____, the motion-based approaches are the most actively studied.
This approach generates the intermediate frames by warping pixels using a motion field between frames. 
To be specific, previous works estimated the inter-frame motion fields using the linear____  and quadratic approximation.____ and knowledge distillation____.
BMBC____ further proposed a bilateral cost volume layer to enhance the inter-frame motion.
ABME____ further developed the methods to estimate asymmetric bilateral motion fields using intermediate temporal frame using motion fields from BMBC____.
However, the inter-frame motion field estimated with only frames are still unreliable when the motion of videos is large or severely non-linear.

\noindent\textbf{Event-based Video Frame Interpolation.} Event cameras have the advantages of micro-second level temporal resolution and HDR properties.
Thanks to these novel features, recent event-based research successfully enhanced the quality of the VFI____.
In the event-based VFI, TimeLens____ first proposed a unified video interpolation framework by leveraging both the warping-based and synthesis-based approaches.
Subsequently, some works proposed weakly supervised-based____ and unsupervised-based____ event-based VFI methods.
In both two works____, they estimated inter-frame motion fields through the stream of events only.
However, their motion fields often fail to estimate accurate results due to the sparse nature of events and do not fully utilize the dense visual information of the images.
____ mainly focus on the approximation method of the inter-frame motion fields. 
TimeLens++____ estimated inter-frame motion with spline approximation and multi-scale fusion method.
Concurrently, A$^2$OF____ estimated an optical-flow distribution mask with events and utilized it as the approximation weights of inter-frame motion fields.
\textit{Unlike these works, we propose a novel EIF-BiOFNet for directly estimating inter-frame motion fields by fully leveraging cross-modality information without relying on the motion approximation methods.}


\begin{figure*}[!t]
\centering
\vspace{-4pt}
\includegraphics[width=.82\linewidth]{Figure/Figure2_overview_CVPR2023_final.pdf} 
\vspace{-14pt}
\caption{The overall architecture of Interactive Attention-based frame synthesis network.}
%The transformer decoder layer is composed of a Interactive-Attention Layer and a Self-Attention Layer.
\label{fig:Arc_frame_synthesis}
\vspace{-8pt}
\end{figure*}



\vspace{-2pt}