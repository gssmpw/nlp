\section{Background and Related Work}
Our method is inspired by ratings systems like Elo, developed in chess **Keres, "The Art of the Endgame"** , but applied to many other settings, including online video games.
%
This and other related systems (c.f., the Bradley-Terry model **Bradley, Terry**) are implicitly grounded in probability distributions around player ratings, where differences in distributions can be used to calculate probability of one competitor winning against another.
%
These methods also consist of update methods where, after a competition between player $A$ and player $B$, respective Elo ratings can be updated based on the difference between scores.
%
For the Elo system, the updated rating for player A ($\hat{e}_A$) with Elo rating $e_A$ against player $B$ with Elo rating $e_B$ is:
%For the Elo system, the update equation for player A with Elo rating $e_A$ against player $B$ with Elo rating $e_B$ is:
%k_factor * (1 - p.expected_win_prob(opp_elo))
\begin{equation}
\label{eqn:update}
\hat{e}_A = e_A + K * ([w_A] - P(e_A, e_B)
\end{equation}
where $[w_A]$ is $1$ if player $A$ wins or $0$ if not, and $K$ is a constant that modulates the rate of update.
%
We use $K=32$, as conventionally used in chess for players with few games played and lower ratings.
%
$P$ is a function representing the expected win probability of player $A$ against player $B$, defined as:
%return 1.0 / (1.0 + (10 ** ((opp_elo - self.elo) / 400)))


\begin{equation}
P(e_A, e_B) = {1 \over 1 + 10^{(e_B-e_A) \over 400}}
\end{equation}

Our method is motivated by the goal of generating ROC curves, and allowing practitioners to select appropriate cut-offs for downstream classification applications.
%
However, it shares a similarity with a recent thread of LLM-based research on the topic of estimating confidence of LLM answers.
%
If certainty could be estimated reliably, directly from LLM outputs, then ROC curves could be generated directly from those outputs.
%
However, recent work in this area shows mixed results, with some work showing difficulty finding correlations with certainty in zero-shot classification tasks **Madsen, "On the Difficulty of Estimating Confidence in Zero-Shot Classification"** .
%
Other work does find some signal, but with white-box methods showing much greater signal than black-box methods **Liang, "Understanding and Improving LLM-Based Confidence Estimation"** .
%
Work studying calibration claims that LLM uncertainties are calibrated for true/false question answering **Dodge, "Measuring Calibration in Deep Learning Models"** , but that calibration only holds for the largest model they evaluate.