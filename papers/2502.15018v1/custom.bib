% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
@software{UK_AI_Safety_Institute_Inspect_AI_Framework_2024,
  author = {AI Safety Institute, UK},
  title = {Inspect {AI:} {Framework} for {Large} {Language} {Model}
    {Evaluations}},
  date = {2024-05},
  url = {https://github.com/UKGovernmentBEIS/inspect_ai},
  langid = {en}
}

@InProceedings{SciPyProceedings_11,
  author =       {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
  title =        {Exploring Network Structure, Dynamics, and Function using NetworkX},
  booktitle =   {Proceedings of the 7th Python in Science Conference},
  pages =     {11 - 15},
  address = {Pasadena, CA USA},
  year =      {2008},
  editor =    {Ga\"el Varoquaux and Travis Vaught and Jarrod Millman},
}


@misc{noauthor_how_nodate,
	title = {How are {Players} {Paired} in {Most} {Chess} {Tournaments}?},
	url = {https://www.thesprucecrafts.com/the-swiss-system-611537},
	abstract = {The Swiss system is the most popular tournament structure in chess and therefore governs how players are ranked and paired in a tournament.},
	language = {en},
	urldate = {2025-02-14},
	journal = {The Spruce Crafts},
	note = {Section: The Spruce},
	file = {Snapshot:/Users/tmill/Zotero/storage/DPUBCCTA/the-swiss-system-611537.html:text/html},
}


@article{zhang2025dataset,
  title={A dataset for evaluating clinical research claims in large language models},
  author={Zhang, Boya and Bornet, Alban and Yazdani, Anthony and Khlebnikov, Philipp and Milutinovic, Marija and Rouhizadeh, Hossein and Amini, Poorya and Teodoro, Douglas},
  journal={Scientific Data},
  volume={12},
  number={1},
  pages={86},
  year={2025},
  publisher={Nature Publishing Group UK London}
}


@book{elo_rating_2008,
	title = {The {Rating} of {Chessplayers}: {Past} and {Present}},
	isbn = {978-0-923891-27-5},
	shorttitle = {The {Rating} of {Chessplayers}},
	abstract = {One of the most extraordinary books ever written about chess and chessplayers, this authoritative study goes well beyond a lucid explanation of how todays chessmasters and tournament players are rated. Twenty years' research and practice produce a wealth of thought-provoking and hitherto unpublished material on the nature and development of high-level talent: Just what constitutes an "exceptional performance" at the chessboard? Can you really profit from chess lessons? What is the lifetime pattern of Grandmaster development? Where are the masters born? Does your child have master potential? The step-by-step rating system exposition should enable any reader to become an expert on it. For some it may suggest fresh approaches to performance measurement and handicapping in bowling, bridge, golf and elsewhere. 43 charts, diagrams and maps supplement the text. How and why are chessmasters statistically remarkable? How much will your rating rise if you work with the devotion of a Steinitz? At what age should study begin? What toll does age take, and when does it begin? Development of the performance data, covering hundreds of years and thousands of players, has revealed a fresh and exciting version of chess history. One of the many tables identifies 500 all-time chess greatpersonal data and top lifetime performance ratings. Just what does government assistance do for chess? What is the Soviet secret? What can we learn from the Icelanders? Why did the small city of Plovdiv produce three Grandmasters in only ten years? Who are the untitled dead? Did Euwe take the championship from Alekhine on a fluke? How would Fischer fare against Morphy in a ten-wins match? 1t was inevitable that this fascinating story be written, ' asserts FIDE President Max Euwe, who introduces the book and recognizes the major part played by ratings in today's burgeoning international activity. Although this is the definitive ratings work, with statistics alone sufficient to place it in every reference library, it was written by a gentle scientist for pleasurable reading -for the enjoyment of the truths, the questions, and the opportunities it reveals.},
	language = {en},
	publisher = {Ishi Press International},
	author = {Elo, Arpad E.},
	year = {2008},
	note = {Google-Books-ID: syjcPQAACAAJ},
	keywords = {Games \& Activities / Chess, Mathematics / Game Theory, Mathematics / Probability \& Statistics / General},
}

@book{elo1978rating,
series = {Batsford chess books},
publisher = {Batsford},
isbn = {0713418605},
year = {1978},
title = {The rating of chessplayers, past and present},
language = {eng},
address = {London},
author = {Elo, Arpad E.},
keywords = {Chess players -- Rating of},
lccn = {^^^78057214^},
}

@article{bradley_rank_1952,
	title = {Rank analysis of incomplete block designs: {I}. {The} method of paired comparisons},
	volume = {39},
	shorttitle = {Rank analysis of incomplete block designs},
	url = {https://www.jstor.org/stable/2334029},
	number = {3/4},
	urldate = {2025-02-14},
	journal = {Biometrika},
	author = {Bradley, Ralph Allan and Terry, Milton E.},
	year = {1952},
	note = {Publisher: JSTOR},
	pages = {324--345},
}

@inproceedings{gao_position_2024,
	title = {Position {Paper} {On} {Diagnostic} {Uncertainty} {Estimation} from {Large} {Language} {Models}: {Next}-{Word} {Probability} {Is} {Not} {Pre}-test {Probability}},
	shorttitle = {Position {Paper} {On} {Diagnostic} {Uncertainty} {Estimation} from {Large} {Language} {Models}},
	url = {https://openreview.net/forum?id=vMSnp12jRx},
	abstract = {Large language models (LLMs) are being explored for diagnostic decision support, yet their ability to estimate pre-test probabilities, vital for clinical decision-making, remains limited. This study evaluates two LLMs, Mistral-7B and Llama3-70B, using structured electronic health record data on three diagnosis tasks. We examined three current methods of extracting LLM probability estimations and revealed their limitations. We aim to highlight the need for improved techniques in LLM confidence estimation.},
	language = {en},
	urldate = {2025-01-04},
	author = {Gao, Yanjun and Myers, Skatje and Chen, Shan and Dligach, Dmitriy and Miller, Timothy A. and Bitterman, Danielle and Chen, Guanhua and Mayampurath, Anoop and Churpek, Matthew and Afshar, Majid},
	month = nov,
	year = {2024},
	file = {Full Text PDF:/Users/tmill/Zotero/storage/6ATC7Y2Z/Gao et al. - 2024 - Position Paper On Diagnostic Uncertainty Estimation from Large Language Models Next-Word Probabilit.pdf:application/pdf},
}


@article{savage_large_2024,
	title = {Large language model uncertainty proxies: discrimination and calibration for medical diagnosis and treatment},
	issn = {1527-974X},
	shorttitle = {Large language model uncertainty proxies},
	url = {https://doi.org/10.1093/jamia/ocae254},
	doi = {10.1093/jamia/ocae254},
	abstract = {The inability of large language models (LLMs) to communicate uncertainty is a significant barrier to their use in medicine. Before LLMs can be integrated into patient care, the field must assess methods to estimate uncertainty in ways that are useful to physician-users.Evaluate the ability for uncertainty proxies to quantify LLM confidence when performing diagnosis and treatment selection tasks by assessing the properties of discrimination and calibration.We examined confidence elicitation (CE), token-level probability (TLP), and sample consistency (SC) proxies across GPT3.5, GPT4, Llama2, and Llama3. Uncertainty proxies were evaluated against 3 datasets of open-ended patient scenarios.SC discrimination outperformed TLP and CE methods. SC by sentence embedding achieved the highest discriminative performance (ROC AUC 0.68-0.79), yet with poor calibration. SC by GPT annotation achieved the second-best discrimination (ROC AUC 0.66-0.74) with accurate calibration. Verbalized confidence (CE) was found to consistently overestimate model confidence.SC is the most effective method for estimating LLM uncertainty of the proxies evaluated. SC by sentence embedding can effectively estimate uncertainty if the user has a set of reference cases with which to re-calibrate their results, while SC by GPT annotation is the more effective method if the user does not have reference cases and requires accurate raw calibration. Our results confirm LLMs are consistently over-confident when verbalizing their confidence (CE).},
	urldate = {2024-12-12},
	journal = {Journal of the American Medical Informatics Association},
	author = {Savage, Thomas and Wang, John and Gallo, Robert and Boukil, Abdessalem and Patel, Vishwesh and Safavi-Naini, Seyed Amir Ahmad and Soroush, Ali and Chen, Jonathan H},
	month = oct,
	year = {2024},
	pages = {ocae254},
	file = {Snapshot:/Users/tmill/Zotero/storage/U9KG39DC/7819854.html:text/html},
}

@misc{kadavath_language_2022,
	title = {Language {Models} ({Mostly}) {Know} {What} {They} {Know}},
	url = {http://arxiv.org/abs/2207.05221},
	doi = {10.48550/arXiv.2207.05221},
	abstract = {We study whether language models can evaluate the validity of their own claims and predict which questions they will be able to answer correctly. We first show that larger models are well-calibrated on diverse multiple choice and true/false questions when they are provided in the right format. Thus we can approach self-evaluation on open-ended sampling tasks by asking models to first propose answers, and then to evaluate the probability "P(True)" that their answers are correct. We find encouraging performance, calibration, and scaling for P(True) on a diverse array of tasks. Performance at self-evaluation further improves when we allow models to consider many of their own samples before predicting the validity of one specific possibility. Next, we investigate whether models can be trained to predict "P(IK)", the probability that "I know" the answer to a question, without reference to any particular proposed answer. Models perform well at predicting P(IK) and partially generalize across tasks, though they struggle with calibration of P(IK) on new tasks. The predicted P(IK) probabilities also increase appropriately in the presence of relevant source materials in the context, and in the presence of hints towards the solution of mathematical word problems. We hope these observations lay the groundwork for training more honest models, and for investigating how honesty generalizes to cases where models are trained on objectives other than the imitation of human writing.},
	urldate = {2025-01-10},
	publisher = {arXiv},
	author = {Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and Johnston, Scott and El-Showk, Sheer and Jones, Andy and Elhage, Nelson and Hume, Tristan and Chen, Anna and Bai, Yuntao and Bowman, Sam and Fort, Stanislav and Ganguli, Deep and Hernandez, Danny and Jacobson, Josh and Kernion, Jackson and Kravec, Shauna and Lovitt, Liane and Ndousse, Kamal and Olsson, Catherine and Ringer, Sam and Amodei, Dario and Brown, Tom and Clark, Jack and Joseph, Nicholas and Mann, Ben and McCandlish, Sam and Olah, Chris and Kaplan, Jared},
	month = nov,
	year = {2022},
	note = {arXiv:2207.05221 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 23+17 pages; refs added, typos fixed},
	file = {Preprint PDF:/Users/tmill/Zotero/storage/VCJCKC2J/Kadavath et al. - 2022 - Language Models (Mostly) Know What They Know.pdf:application/pdf;Snapshot:/Users/tmill/Zotero/storage/KL2TN2JD/2207.html:text/html},
}
@article{warstadt2018neural,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}

@article{zhang_dataset_2025,
	title = {A dataset for evaluating clinical research claims in large language models},
	volume = {12},
	copyright = {2025 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/s41597-025-04417-x},
	doi = {10.1038/s41597-025-04417-x},
	abstract = {Large language models (LLMs) have the potential to enhance the verification of health claims. However, issues with hallucination and comprehension of logical statements require these models to be closely scrutinized in healthcare applications. We introduce CliniFact, a scientific claim dataset created from hypothesis testing results in clinical research, covering 992 unique interventions for 22 disease categories. The dataset used study arms and interventions, primary outcome measures, and results from clinical trials to derive and label clinical research claims. These claims were then linked to supporting information describing clinical trial results in scientific publications. CliniFact contains 1,970 instances from 992 unique clinical trials related to 1,540 unique publications. When evaluating LLMs against CliniFact, discriminative models, such as BioBERT with an accuracy of 80.2\%, outperformed generative counterparts, such as Llama3-70B, which reached 53.6\% accuracy (p-value {\textless} 0.001). Our results demonstrate the potential of CliniFact as a benchmark for evaluating LLM performance in clinical research claim verification.},
	language = {en},
	number = {1},
	urldate = {2025-02-14},
	journal = {Scientific Data},
	author = {Zhang, Boya and Bornet, Alban and Yazdani, Anthony and Khlebnikov, Philipp and Milutinovic, Marija and Rouhizadeh, Hossein and Amini, Poorya and Teodoro, Douglas},
	month = jan,
	year = {2025},
	note = {Publisher: Nature Publishing Group},
	keywords = {Outcomes research, Randomized controlled trials},
	pages = {86},
	file = {Full Text PDF:/Users/tmill/Zotero/storage/PXSTLNBT/Zhang et al. - 2025 - A dataset for evaluating clinical research claims in large language models.pdf:application/pdf},
}

@misc{noauthor_what_nodate,
        author = {Chess.com},
	title = {What is a {Swiss} tournament? {\textbar} {Chess}.com {Help} {Center}},
	shorttitle = {What is a {Swiss} tournament?},
	url = {https://support.chess.com/en/articles/8558054-what-is-a-swiss-tournament},
	language = {en},
	urldate = {2025-02-15},
	file = {Snapshot:/Users/tmill/Zotero/storage/RX8W6VAJ/8558054-what-is-a-swiss-tournament.html:text/html},
}

@article{sziklai_efficacy_2022,
	title = {The efficacy of tournament designs},
	volume = {144},
	issn = {0305-0548},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054822001022},
	doi = {10.1016/j.cor.2022.105821},
	abstract = {Tournaments are a widely used mechanism to rank alternatives in a noisy environment. This paper investigates a fundamental issue of economics in tournament design: what is the best usage of limited resources, that is, how should the alternatives be compared pairwise to best approximate their true but latent ranking. We consider various formats including knockout tournaments, multi-stage championships consisting of round-robin groups followed by single elimination, and the Swiss-system. They are evaluated via Monte-Carlo simulations under six different assumptions on winning probabilities. Comparing the same pair of alternatives multiple times turns out to be an inefficacious policy. While seeding can increase the efficacy of the knockout and group-based designs, its influence remains marginal unless one has an unrealistically good estimation on the true ranking of the players. The Swiss-system is found to be the most accurate among all these tournament formats, especially in its ability to rank all participants. A possible explanation is that it does not eliminate a player after a single loss, while it takes the history of the comparisons into account. The results can be especially interesting for emerging esports, where the tournament designs are not yet solidified.},
	urldate = {2025-02-15},
	journal = {Computers \& Operations Research},
	author = {Sziklai, Balázs R. and Biró, Péter and Csató, László},
	month = aug,
	year = {2022},
	keywords = {Competitive balance, OR in sports, Ranking, Simulation, Tournament design},
	pages = {105821},
	file = {ScienceDirect Snapshot:/Users/tmill/Zotero/storage/P7XX2ZS5/S0305054822001022.html:text/html},
}

@inproceedings{wolf_transformers_2020,
	address = {Online},
	title = {Transformers: {State}-of-the-{Art} {Natural} {Language} {Processing}},
	shorttitle = {Transformers},
	url = {https://aclanthology.org/2020.emnlp-demos.6/},
	doi = {10.18653/v1/2020.emnlp-demos.6},
	abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.},
	urldate = {2025-02-15},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}: {System} {Demonstrations}},
	publisher = {Association for Computational Linguistics},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Remi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander},
	editor = {Liu, Qun and Schlangen, David},
	month = oct,
	year = {2020},
	pages = {38--45},
	file = {Full Text PDF:/Users/tmill/Zotero/storage/LNR2D4K3/Wolf et al. - 2020 - Transformers State-of-the-Art Natural Language Processing.pdf:application/pdf},
}
