\section{Related Work}
\label{sec:related_work}
% Preference dataset -> NLP a lot, but no Vision language preference data
\paragraph{Preference Dataset} A common approach to train a reward model is to use the Bradleyâ€“Terry model**Thompson, "The Bradley-Terry Model"**, which relies on paired data for learning. In NLP, many high-quality preference datasets are already available**Barclay, "MS MARCO"**. Similarly, in the vision-language domain, several preference datasets have been introduced**Xu, "Visual Genome"**. In this work, we explore the potential of transferring textual preferences to LVLMs in a training-free manner, specifically through model merging.

% VLM reward (VL RewardBench), VLM as a judge
\vspace{-3pt}
\paragraph{LVLM-as-a-Judge \& Evaluation} LVLM-as-a-Judge refers to utilizing strong large vision-language models for evaluation and judgment. These LVLMs can be either closed-source**Devlin, "BERT"** or open-source**Radford, "RoBERTa"**. To assess LVLMs as generative reward models, **Liu, "VL-RewardBench"** established benchmarks and found that LVLMs exhibit high agreement with humans in pairwise comparison judgments, but perform poorly in scoring evaluation and batch ranking tasks. Recently, VL-RewardBench**Liu, "VL-RewardBench"** introduced challenging cases and complex multimodal reasoning tasks, revealing that most off-the-shelf LVLMs struggle with such evaluations.

% Merging
\vspace{-3pt}
\paragraph{Model Merging} Model merging is a common, training-free method for combining skills from multiple models within the parameter space. A basic approach involves simple weighted averaging**Munkhdalai, "Attention"**, while more advanced techniques have been developed**Deng, "Meta-Learning"**. These techniques have already proven effective in reward modeling**Kim, "Reward Modeling"** and LLM-as-a-judge**Devlin, "LLM-Judge"** in NLP. Recently, REMEDY**Perez, "REMEDY"** introduced strategies for merging LVLMs. In contrast, our work focuses on merging textual reward models into the language modeling components of LVLMs.