\documentclass[12pt]{article}
\usepackage{amsmath,amssymb}
\usepackage{authblk}
%\documentclass[fp,twocolumn]{jpsj3}
%\documentclass[letter,twocolumn]{jpsj3}
%\documentclass[letterpaper,twocolumn]{jpsj3}
% \usepackage{tabularx,moreverb,fancybox,ascmac,amsmath,amsthm,float,bm,braket,txfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{amsmath}
\usepackage{txfonts}
% \usepackage[luatex]{graphicx}  
% \usepackage[dvips]{graphics}
% \usepackage[dvipdfmx]{graphicx}
\usepackage{color}
\usepackage{graphicx}  
\usepackage{here}
\usepackage{braket}
\usepackage{bm}
\usepackage[OT1]{fontenc} 
\usepackage[version=3]{mhchem}
\newcommand{\BiggParen}[1]{\Biggl(#1\Biggr)}
% \usepackage[allcommands]{overarrows}
% \usepackage{color}
% \れnewcommand{\color{red}}{\color{black}}

\title{Sequential Exchange Monte Carlo: Sampling Method for Multimodal Distribution without Parameter Tuning}

\author[1]{Tomohiro Nabika}
\author[2]{Kenji Nagata}
\author[1]{Shun Katakami}
\author[3]{Masaichiro Mizumaki}
\author[1]{Masato Okada}

\affil[1]{Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa, Chiba 277-8561, Japan}
\affil[2]{Research and Services Division of Materials Data and Integrated System, National Institute for Materials Science, Tsukuba, Ibaraki 305-0047, Japan}
\affil[3]{Faculty of Science, Course for Physical Sciences, Kumamoto University, Kumamoto, Kumamoto 860-8555, Japan}

\begin{document}
% \affiliation{$^1$Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa, Chiba 277-8561, Japan, \\
% $^2$Research and Services Division of Materials Data and Integrated System, National Institute for Materials Science,Tsukuba, Ibaraki 305-0047, Japan,\\
% $^3$Faculty of Science, Course for Physical Sciences, Kumamoto University, Kumamoto, Kumamoto 860-8555, Japan.} %\\

\maketitle
\begin{abstract}
    The Replica Exchange Monte Carlo (REMC) method, a Markov Chain Monte Carlo (MCMC) algorithm for sampling multimodal distributions, is typically employed in Bayesian inference for complex models.
    Using the REMC method, multiple probability distributions with different temperatures are defined to enhance sampling efficiency and allow for the high-precision computation of Bayesian free energy.
    However, the REMC method requires the tuning of many parameters, including the number of distributions, temperature, and step size, which makes it difficult for nonexperts to effectively use. 
    Thus, we propose the Sequential Exchange Monte Carlo (SEMC) method, which automates the tuning of parameters by sequentially determining the temperature and step size.
    Numerical experiments showed that SEMC is as efficient as parameter-tuned REMC and parameter-tuned Sequential Monte Carlo Samplers (SMCS), which is also effective for the Bayesian inference of complex models. 
    Using the SEMC method, nonexperts can perform Bayesian inference for complex models, thereby accelerating the spread of Bayesian inference.
\end{abstract}


\section{Introduction}

% This sample helps you to create a properly formatted \LaTeXe\ manuscript.
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %% `\ ' is used here because TeX ignores    %%
% %% spaces after text commands.              %%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Prepare your paper in the same style as used in this sample .pdf file.
% Try to avoid excessive use of italics and bold face.
% Please do not use any \LaTeXe\ or \TeX\ commands that affect the layout
% or formatting of your document (i.e., commands like \verb|\textheight|,
% \verb|\textwidth|, etc.).

Bayesian inference has been widely used in data analysis in various fields.
Bayesian inference requires the computation of posterior probabilities, which are generally difficult to analytically calculate.
Thus, two major methods have been employed to obtain the approximate posterior distribution.
The first method involves deterministic approximation algorithms \cite{sun2013review}, which can efficiently derive approximate solutions for the posterior distribution but have limited applicability and high approximation errors.
The other method employs Markov Chain Monte Carlo (MCMC) techniques to sample from the posterior distribution.
MCMC methods are attractive because of their broad applicability and the potential to asymptotically reduce errors by increasing the sample size.
Various libraries for Bayesian inference using MCMC, such as Stan \cite{carpenter2017stan}, PyMC \cite{patil2010pymc}, and Numpyro \cite{phan2019composable}, have been developed; thus, users without specialized MCMC knowledge can employ MCMC techniques. \par

The Bayesian posterior probability is frequently multimodal in many problem settings. 
For instance, in the spectral data analyses, minimizing the error can result in numerous local minima, suggesting that the posterior probability is multimodal \cite{Nagata2012}.
However, commonly used MCMC methods, such as the Metropolis algorithm \cite{metropolis1953equation} and Hamiltonian Monte Carlo (HMC) \cite{neal2011mcmc} struggle to transition between local minima once they become trapped in a local minimum, making it challenging to sample from multimodal distributions.
In addition, when the posterior distribution peak is sharp, it is difficult to compute the Bayesian free energy, which is a statistic in Bayesian model selection. \par

Many studies have attempted to sample from multimodal distributions and compute the Bayesian free energy.
Among these studies, the Replica Exchange Monte Carlo (REMC) and Sequential Monte Carlo Samplers (SMCS) methods have been widely used.
The REMC method (also known as parallel tempering) prepares multiple probability distributions at different temperatures between the prior and posterior distributions \cite{geyer1991markov, Hukushima1996}. 
By sampling from each distribution using the Metropolis algorithm and performing ``exchanges'' between distributions, the REMC method facilitates transitions between local minima, enabling sampling from multimodal distributions. 
The REMC method was initially developed for physical simulations such as the Ising model and has since been applied to various Bayesian inference problem settings \cite{von2011bayesian,sambridge2014parallel}.

To achieve efficient sampling using the REMC method, it is necessary to tune many parameters, including the number of distributions, temperature, and step size.
Although many methods can be employed for automatic tuning, they often require initial values for step sizes \cite{andrieu2008tutorial} and the number of temperatures \cite{vousden2016dynamic}, thus, full automation becomes a challenging process.
Such manual parameter tuning hinders the use of the REMC method by non-experts. 
As HMC has been widely used by the No U-Turn Sampler \cite{hoffman2014no}, which is the HMC with the automatic tuning of HMC parameters, an algorithm with an automatic tuning of REMC parameters is required.

The SMCS method can achieve high-precision sampling from multimodal distributions by simultaneously handling numerous samples \cite{neal2001annealed, chopin2002sequential, del2006sequential}.
Firstly, many samples that follow the prior distribution are prepared and the distribution is set as the distribution with the highest temperature. 
From these samples, the process of proposing the next temperature, resampling for the proposed distribution, and updating with the MCMC method is repeated.
Various automatic tuning methods for step sizes and temperatures have been proposed \cite{fearnhead2013adaptive,schafer2013sequential,beskos2016convergence}, making the SMCS method accessible for non-experts and being implemented in tools like PyMC.
However, the SMCS method sometimes requires a large number of MCMC steps for each sample to update.
Waste-free Sequential Monte Carlo (SMC) \cite{dau2022waste} is proposed to utilize these intermediate MCMC steps, but it still requires the tuning of the number of MCMC steps.

To eliminate the need for parameter tuning, this paper proposes the Sequential Exchange Monte Carlo (SEMC) method, which incorporates the SMCS concept into the REMC method.
This algorithm begins by preparing numerous samples according to the highest temperature, similar to the SMCS method.
After that, it repeatedly proposes the next temperature, performs exchanges between the distributions, and updates the parameters using the MCMC method.
The algorithm can automatically tune the step size and temperature. \par

This study evaluated the SEMC performance through numerical experiments. 
We used three problem settings: sampling from an artificial multimodal distribution, spectral deconvolution \cite{Nagata2012}, and exhaustive search, which requires the sampling of discrete variables \cite{nagata2015exhaustive,igarashi2018exhaustive}.
The SEMC method was observed to be as efficient as parameter-tuned REMC and parameter-tuned SMCS in all problem settings.
This algorithm is expected to enable practitioners in various fields to perform Bayesian inference for complex models, thereby accelerating the spread of Bayesian inference.\par

The rest of this paper is as follows.
Section 2 describes the background of data analysis by Bayesian inference and sampling methods of REMC and SMCS.
Section 3 explains the proposed SEMC method.
Section 4 presents a comparison between the performances of SEMC, REMC, and SMCS through numerical experiments and verifies the effectiveness of SEMC.
Finally, Section 5 concludes the paper and discusses future works.

\section{Background}
This section describes data analysis by Bayesian inference with REMC and SMCS.

\subsection{Bayesian Inference}
Let $M$ be a model with parameter $\theta_M$ and data $D = \{X_i, y_i\}_{i=1}^N$.
Suppose that the likelihood function, $p(D|\theta_M, M)$, is given.
The error function, $E(\theta_M, M)$, which represents the error between data $D$ and the output of parameter $\theta_M$, is defined as follows:
\begin{align}
  \label{eq:likelihood}
  p(D|\theta_M, M) = \frac{\exp(-NE(\theta_M, M))}{C},
\end{align}
where, $C$ is the normalization constant.
The goal of data analysis is to estimate model $M$ and model parameter $\theta_M$ from $D$. \par

Let $\theta_M$ follow the prior probability, $p(\theta_M|M)$.
In Bayesian inference, the posterior probability, $p(\theta_M|D, M)$, is calculated as follows:
\begin{align}
  \label{eq:posterior}
  p(\theta_M|D, M) &= \frac{p(D|\theta_M, M)p(\theta_M|M)}{p(D|M)} \\
  &= \frac{\exp(-NE(\theta_M, M))p(\theta_M|M)}{\int \exp(-NE(\theta_M, M))p(\theta_M|M)d\theta_M}.
\end{align}
Let $\mathcal{M}$ be the set of candidate models, and let $p(M)$ be the prior probability of model $M \in \mathcal{M}$.
The posterior probability of model $M$ is given by
\begin{align}
  \label{eq:model_posterior}
  p(M|D) &= \frac{p(D|M)p(M)}{p(D)} \\
         &= \frac{p(M)}{\overline{Z}} \exp(-F(M)) \\
  F(M) &= -\log\int \exp(-NE(\theta_M, M))p(\theta_M|M)\textup{d}\theta_M + \log C, \\
  \overline{Z} &= \sum_{M' \in \mathcal{M}} p(M')\exp(-F(M')),
\end{align}
where $F(M)$ is the Bayesian free energy, which represents the goodness of model $M$ for $D$. \par
By calculating the posterior probability, $p(\theta_M|D, M)$ and $p(M|D)$,  $M$ and $\theta_M$ can be estimated.
In general, since it is difficult to analytically calculate the posterior probability, MCMC methods are commonly employed to calculate these probabilities.
Next, this paper describes two conventional algorithms of MCMC methods: REMC and SMCS.

\subsection{Replica Exchange Monte Carlo}
\subsubsection{Algorithm}
In the analysis of complex models, $p(\theta_M|D, M)$ is frequently a multimodal distribution, which makes it easy to be trapped in local solutions and difficult to accurately sample.
REMC can avoid being trapped in local minima by preparing multiple probability distributions at different temperatures \cite{Hukushima1996}.
If $E(\theta_M, M)$ is the error function, we define the distribution at an inverse temperature $(\beta)$ as follows:
\begin{align}
  \label{eq:temperature}
  p_\beta(\theta_M|D, M) &\propto p(\theta_M|D,M)^{\beta}p(\theta_M|M)^{1-\beta} \\
  &\propto  \exp(-\beta N E(\theta_M, M))p(\theta_M|M).
\end{align}
Let $L$ be the number of distributions, and let $\{\beta_l\}_{l=1}^L$ be the set of inverse temperatures. (Here, $0 = \beta_1 < \cdots < \beta_L = 1$.)
In the REMC method, the following two parameter update procedures are repeatedly performed to sample from $\{p_\beta(\theta_M|D, M)\}_{l = 1}^L$.
\begin{enumerate}
  \item Update parameter $\theta_M^l$ according to $p_{\beta_l}(\theta_M|D, M)$ using the Metropolis algorithm.
  \item Exchange parameters $\theta_M^l$ and $\theta_M^{l+1}$ between $p_{\beta_{l}}$ and $p_{\beta_{l+1}}$ with a probability of $u$.
  \begin{align}
    u = \min\left(1, \frac{p_{\beta_{l}}(\theta_M^{l+1}|D,M)p_{\beta_{l+1}}(\theta_M^{l}|D,M)}{p_{\beta_{l}}(\theta_M^{l}|D,M)p_{\beta_{l+1}}(\theta_M^{l+1}|D,M)}\right).
  \end{align}
\end{enumerate}
For each distribution $p_{\beta_l}(\theta_M|D, M)$, parameter updates using the Metropolis algorithm can be performed in parallel.
The specific algorithm is provided in Algorithm \ref{EMC}. \par
  \begin{algorithm}[H]
    \caption{Replica Exchange Monte Carlo}
    \label{EMC}
    \begin{algorithmic}[1]
    \REQUIRE Data $D$, model $M$, prior distribution $p(\theta_M|M)$, set of inverse temperatures $\{\beta_l\}_{l = 1}^L$, burn-in size $T_1$, sample size $T_2$, step size $\{\epsilon_l\}_{l = 2}^L$
    \ENSURE Parameter set $\Theta_M^{T_2}$ = $\left\{\{\theta_M^{l,t}\}_{t = 1}^{T_2} \mid \theta_M^{l,t} \textup{ follows } p_{\beta_l}(\theta_M|D, M)\right\}_{l = 1}^L$
    \STATE Parameter set $\Theta_M^{T_2}$ = \{\}
    \FOR{$l \in \{1,...,L\}$}
        \STATE Generate $\theta_M^{l}$ according to the prior distribution $p(\theta_M|M)$.
    \ENDFOR
    \FOR{$t \in \{1,...,T_1 + T_2\}$}
      \STATE Generate $\theta_M^{1}$ according to the prior distribution $p(\theta_M|M)$.
      \FOR{$l \in \{2,...,L\}$}
        % \FOR{$\theta_{M,i}^{l} \in \theta_M^{l}$}
        %   \STATE Generate $\delta$ uniformly from $[-\epsilon_{l,i}, \epsilon_{l,i}]$.
        %   \STATE Set the new candidate as $\theta_{M}^{new} = \theta_{M}^{l}$, $\theta_{M,i}^{new} \leftarrow \theta_{M,i}^{new} + \delta$.
        %   \STATE Calculate $v = \frac{p_{\beta_{l}}(\theta_M^{new}|D,M)}{p_{\beta_{l}}(\theta_M^{l}|D,M)}$.
        %   \STATE Update $\theta_{M}^{l}$ to $\theta_M^{new}$ with probability $\min(1,v)$.
        % \ENDFOR
        \STATE Update $\theta_M^{l}$ according to $p_{\beta_l}(\theta_M|D, M)$ using Metropolis algorithm with step size $\epsilon_l$.
      \ENDFOR
      \FOR{$l \in \{1,...,L-1\}$}
        \STATE Calculate $v = \frac{p_{\beta_{l}}(\theta_M^{l+1}|D,M)p_{\beta_{l+1}}(\theta_M^{l}|D,M)}{p_{\beta_{l}}(\theta_M^{l}|D,M)p_{\beta_{l+1}}(\theta_M^{l+1}|D,M)}$.
        \STATE Exchange $\theta_M^l$ and $\theta_M^{l+1}$ with probability $\min(1,v)$.
      \ENDFOR
      \IF{$t > T_1$}
        \STATE Add $\{\theta_M^l\}_{l=1}^L$ to $\Theta_M$.
      \ENDIF
    \ENDFOR
    \end{algorithmic}
  \end{algorithm}

By sampling from the distribution with inverse temperature $\beta_L = 1$, the samples following the posterior distribution $p(\theta_M|D, M)$ were obtained.
Using a histogram or kernel density estimation \cite{PRML}, the posterior distribution, $p(\theta_M|D, M)$, can be approximated. \par
The calculation of the Bayesian free energy, $F(M)$, is required for the model posterior distribution.
The calculation is efficiently performed using all samples from all distributions \cite{neal1993probabilistic}.
Let $z(\beta)$ be defined as follows:
\begin{align}
  z(\beta) = \int \exp(-\beta NE(\theta_M, M))p(\theta_M|M)d\theta_M.
\end{align}
Thus, the Bayesian free energy, $F(M)$, was calculated as follows:
\begin{align}
  F(M) &= -\log z(1) + \log C, \\
  z(1)  &= \frac{z(\beta_L)}{z(\beta_{L-1})} \times \cdots \times \frac{z(\beta_2)}{z(\beta_1)} = \prod_{l=1}^{L-1} \frac{z(\beta_{l+1})}{z(\beta_l)} \\
       &= \prod_{l=1}^{L-1} \frac{\int \exp(-\beta_{l+1} NE(\theta_M, M))p(\theta_M|M)}{\int \exp(-\beta_l NE(\theta_M, M))p(\theta_M|M)} \\
       &= \prod_{l=1}^{L-1} \langle\exp(-N(\beta_{l+1} - \beta_{l})E(\theta_M,M))\rangle_{p_{\beta_l}(\theta_M|D,M)},
\end{align}
where $\langle \cdot \rangle_{p_{\beta_l}(\theta_M|D,M)}$ denotes the expectation value with probability $p_{\beta_l}(\theta_M|D,M)$.

\subsubsection{Parameter Tuning}
In REMC, the number of distributions, $L$, and inverse temperatures, $\{\beta_l\}_{l=2}^L$, as well as their step sizes, must be tuned as parameters.
To achieve this, the inverse temperatures were set exponentially to render the symmetric Kullback-Leibler divergence between $p_{\beta_l}$ and $p_{\beta_{l-1}}$ constant assuming that the number of distributions was infinite \cite{nagata2008asymptotic}.
The inverse temperatures were set as follows:
\begin{align}
  \beta_l = \begin{cases}
      0 & (l = 1), \\
      \gamma^{l - L} & (\textup{otherwise}).
  \end{cases}    
  \label{eq:temperature_setting}
\end{align}
Here, $\gamma, L$ were set such that the exchange probability between the distributions was not too low. \par
The step size should be set appropriately because a large and small step size will result in a low acceptance rate and low sampling efficiency, respectively.
One method for setting the step size is to use the Robbins-Monro algorithm \cite{robbins1951stochastic, garthwaite2016adaptive}.
% Garthwaite et al. proposed an automatic step size tuning method using the Robbins-Monro algorithm \cite{garthwaite2016adaptive}.
This algorithm adjusts the step size, $\epsilon$, using the following update equation to make the current acceptance rate, $p_{\textup{accept}}$, converge to $p^*$ during the burn-in period:
\begin{align}
  \epsilon^{\textup{new}} = \epsilon^{\textup{old}} + \epsilon^{\textup{old}} \times c \times \frac{p_{\textup{accept}} - p^*}{N_0 + N}.
\end{align}
Here, $c, N_0$ were set to appropriate values. This study updated the step size every $M = 20$ samples, and set $c = 4, N_0 = 15$, and $p^* = 0.5$ for all distributions and parameters. \par
In this algorithm, $p_{\textup{accept}}$ was confirmed to have converged to $p^*$; however, the convergence was slow when the initial step size was extremely large or small.
In practice, the initial step size should be manually set to an appropriate value to improve the convergence rate for all distributions. \par

\subsection{Sequential Monte Carlo Samplers}
\subsubsection{Algorithm}
The SMCS method \cite{neal2001annealed, chopin2002sequential, del2006sequential} achieves sampling from multimodal distributions by simultaneously handling numerous samples.
Similar methods to SMCS are proposed, such as Transitional Markov Chain Monte Carlo (TMCMC) \cite{ching2007transitional} and population annealing \cite{hukushima2003population}, and they are applied to various fields \cite{lye2021sampling,weigel2021understanding}.
In this study, we focus on the SMCS method with MCMC kernel, although the method can be applied to invariant kernel \cite{del2006sequential}. \par
In the SMCS method, the samples following the probability distributions at inverse temperatures, $\{\beta_l\}_{l=1}^L$, can be obtained, by performing the following parameter updates. 
\begin{enumerate}
  \item Let $T$ be the number of samples and $l = 1, \beta_1 = 0$. Generate samples $\{\theta_M^{1,i}\}_{i=1}^T$ according to the prior distribution.
  \item Repeat the following until $\beta_l = 1$.
  \begin{enumerate}
    \item Update $l = l + 1$.
    \item Resample all the samples according to the weight $\{W^{l,i}\}_{i = 1}^T$. For all $i$, select $j$ such that $\theta_M^{l,i} = \theta_M^{l-1,j}$ with probability $\frac{W^{l,j}}{\sum_j W^{l,j}}$.
    \item Update $\theta_M^{l,i}$ using the MCMC algorithm with step size $\epsilon_l$. Repeat this step $n$ times.
    \item Set the next inverse temperature $\beta_{l + 1}$.
  \end{enumerate}
\end{enumerate}

Here, we defined $W^{l,i} = \exp(-(\beta_{l} - \beta_{l-1})NE(\theta_M^{l-1,i}))$. \par
For each sample, resampling and parameter updates can be performed in parallel. Thus, large-scale parallel computing is possible. The specific algorithm is provided in Algorithm \ref{SMCS}. \par
\begin{algorithm}[h]
\caption{Sequential Monte Carlo Samplers}
\label{SMCS}
\begin{algorithmic}[1]
    \REQUIRE Data $D$, prior distribution $p(\theta_M|M)$, sample size $T$, number of steps $n$, step size matrix $\{\epsilon_l\}_{l = 2}^L$
    \ENSURE Parameter set $\Theta_M$ = $\left\{\{\theta_M^{l,t}\}_{l = 1}^L \mid \theta_M^{l,t} \textup{ follows } p_{\beta_l}(\theta_M|D,M)\right\}_{t = 1}^{T}$
    \STATE Parameter set $\Theta_M$ = \{\}
    \FOR{$i \in \{1,...,T\}$}
        \STATE Generate $\theta_M^{1,i}$ according to the prior distribution $p(\theta_M|M)$.
    \ENDFOR
    \STATE Add $\{\theta_M^{1,i}\}_{i=1}^T$ to $\Theta_M$.
    \STATE Set $l = 1, \beta_1 = 0$.
    \WHILE{$\beta_l < 1$}
        \STATE Set the next temperature $\beta_{l+1}$ and $l = l + 1$.
        \STATE Calculate $W^l = \{ \exp(-(\beta_{l} - \beta_{l-1})NE(\theta_M^{l-1,i}))\}_{i=1}^T$.
        \FOR{$i \in \{1,...,T\}$}
            \STATE Select $j$ randomly such that $\theta_M^{l,i} = \theta_M^{l-1,j}$ with probability $\frac{W^{l,j}}{\sum_j W^{l,j}}$.
        \ENDFOR
        \FOR{$j \in \{1,...,n\}$}
            \FOR{$i \in \{1,...,T\}$}
                \STATE Update $\theta_M^{l,i}$ using the MCMC algorithm with step size $\epsilon_l$.
            \ENDFOR
        \ENDFOR
        \STATE Add $\{\theta_M^{l,i}\}_{i=1}^T$ to $\Theta_M$.
    \ENDWHILE
\end{algorithmic}
\end{algorithm}

  % 温度, ステップサイズ(MCMC カーネル)のパラメータは, 一つ上の温度のパラメータを使って自動調整することができ, 様々な手法が提案されて, 応用されている.
% サンプルの多様性を保つためには, MCMCステップを十分な回数行う必要がある一方で, ステップ数が多いと計算コストが高くなる.

Similar to the REMC method, the number of distributions, $L$, and inverse temperatures, $\{\beta_l\}_{l=2}^L$, and their step sizes must be carefully tuned as key parameters.
To address this, automatic tuning methods have been developed by leveraging samples and parameters from the previous temperature. 
Several approaches have been proposed and successfully applied to optimize these parameters. \cite{del2006sequential, ching2007transitional, fearnhead2013adaptive,schafer2013sequential,beskos2016convergence}.
% Tuning the number of MCMC steps for each sample is also required to maintain the diversity of samples.
% Although several methods have been proposed to tune the number of MCMC steps, the tuning of the number of MCMC steps is still a challenging process \cite{dau2022waste}.

\subsubsection{Waste-free SMC algorithm}
In the SMCS method, the number of MCMC steps for each sample must be large enough to preserve the diversity of samples.
However, increasing the number of MCMC steps also leads to higher computational costs.
To address this issue, the waste-free SMC method \cite{dau2022waste} was introduced, which effectively utilizes the intermediate MCMC steps to improve efficiency.\par

Waste-free SMC reduces inefficiency by resampling only $S$ samples ($T = S\times n$) and updating each sample $n-1$ times using the MCMC method.
This process generates $S$ chains, each of length $n$, which are combined to create a new particle sample of size $T = S \times n$. The detailed algorithm is presented in Algorithm \ref{Waste-free SMC}. \par
\begin{algorithm}[h]
  \caption{Waste-free Sequential Monte Carlo Samplers}
  \label{Waste-free SMC}
  \begin{algorithmic}[1]
    \REQUIRE Data $D$, prior distribution $p(\theta_M|M)$, sample size $T$, number of steps $n$, number of samples $S = T/n$, step size matrix $\{\epsilon_l\}_{l = 2}^L$
    \ENSURE Parameter set $\Theta_M$ = $\left\{\{\theta_M^{l,t}\}_{l = 1}^L \mid \theta_M^{l,t} \textup{ follows } p_{\beta_l}(\theta_M|D,M)\right\}_{t = 1}^{T}$
    \STATE Parameter set $\Theta_M$ = \{\}
    \FOR{$i \in \{1,...,T\}$}
        \STATE Generate $\theta_M^{1,i}$ according to the prior distribution $p(\theta_M|M)$.
    \ENDFOR
    \STATE Add $\{\theta_M^{1,i}\}_{i=1}^T$ to $\Theta_M$.
    \STATE Set $l = 1, \beta_1 = 0$.
    \WHILE{$\beta_l < 1$}
        \STATE Set the next temperature $\beta_{l+1}$ and $l = l + 1$.
        \STATE Calculate $W^l = \{ \exp(-(\beta_{l} - \beta_{l-1})NE(\theta_M^{l-1,i}))\}_{i=1}^T$.
        \FOR{$i \in \{1,...,S\}$}
            \STATE Select $j$ randomly such that $\theta_M^{l,i} = \theta_M^{l-1,j}$ with probability $\frac{W^{l,j}}{\sum_j W^{l,j}}$.
        \ENDFOR
        \FOR{$j \in \{1,...,n-1\}$}
            \FOR{$i \in \{1,...,S\}$}
                \STATE Set $\theta_M^{l,S\times j+i} = \theta_M^{l-1,S\times (j-1)+i}$. 
                \STATE Update $\theta_M^{l,S\times j+i}$ using the MCMC algorithm with step size $\epsilon_l$.
            \ENDFOR
        \ENDFOR
        \STATE Add $\{\theta_M^{l,i}\}_{i=1}^{T}$ to $\Theta_M$.
    \ENDWHILE
  \end{algorithmic}
\end{algorithm}

% このアルゴリズムによって, ステップ数を増やしても計算コストは増えず, 効率化が実現される.
% しかし, Sが小さい場合, リサンプリングによってサンプルにバイアスが生じる. 特に, 第5章で見るような多峰性分布の場合, サンプリングの精度を保つためには, Sを大きくする必要がある.
% よって, 実際には, Sを調整する必要がある.
This algorithm enables an increase in the number of steps without incurring additional computational cost, thereby enhancing efficiency.
However, if $S$ is small, resampling may introduce bias into the samples, particularly when dealing with multimodal distributions, as demonstrated in Section 4.
Consequently, adjusting $S$ appropriately is essential in practical applications.

\section{Sequential Exchange Monte Carlo}
This section describes the proposed SEMC method that combines the REMC and SMCS methods.

\subsection{Algorithm}
By performing the following parameter updates, samples were obtained from the probability distributions with inverse temperatures $\{\beta_l\}_{l=1}^L$. \par
\begin{enumerate}
  \item Let $l = 1$ and $\beta_1 = 0$. Generate samples $\{\theta_M^{l,i}\}_{i=1}^T$ according to the prior distribution.
  \item Repeat the following until $\beta_l = 1$.
  \begin{enumerate}
    \item Update $l = l + 1$. Set the initial sample, $\theta_M^{l,1} = \theta_M^{l-1,j}$, with probability $\frac{W^{l,j}}{\sum_j W^{l,j}}$.
    \item Repeat the following update for sampling.
    \begin{enumerate}
      \item Update $\theta_M^{l,i}$ according to $p_{\beta_l}(\theta_M|D)$ using the MCMC method.
      \item Select sample $\theta_M^{l-1,j}$ randomly. Exchange $\theta_M^{l-1,j}$ and $\theta_M^{l,i}$ with probability $u$.
      \begin{align}
          u = \min\left(1, \dfrac{p_{\beta_{l}}(\theta_M^{l-1,j}|D,M)p_{\beta_{l-1}}(\theta_M^{l,i}|D,M)}{p_{\beta_{l}}(\theta_M^{l,i}|D,M)p_{\beta_{l-1}}(\theta_M^{l-1,j}|D,M)}\right).
      \end{align}
    \end{enumerate}
  \end{enumerate}
\end{enumerate}
The specific algorithm is provided in the Algorithm \ref{SEMC}. Here, we assumed that the burn-in size was the same as the sample size. \par
\begin{algorithm}[h]
  \caption{Sequential Exchange Monte Carlo}
  \label{SEMC}
  \begin{algorithmic}[1]
    \REQUIRE Data $D$, prior distribution $p(\theta_M|M)$, set of inverse temperatures $\{\beta_l\}_{l = 1}^L$, sample size $T$, step size $\{\epsilon_l\}_{l = 2}^L$
    \ENSURE Parameter set $\Theta_M$ = $\left\{\{\theta_M^{l,t}\}_{l = 1}^L \mid \theta_M^{l,t} \sim p_{\beta_l}(\theta_M|D,M)\right\}_{t = 1}^{T}$
    \STATE Parameter set $\Theta_M$ = \{\}
    \FOR{$i \in \{1,...,T\}$}
        \STATE Generate $\theta_M^{1,i}$ from the prior distribution $p(\theta_M|M)$.
    \ENDFOR
    \STATE Add $\{\theta_M^{1,i}\}_{i=1}^T$ to $\Theta_M$.
    \FOR{$l \in \{2,...,L\}$}
        \STATE $I_1, I_2 = \{1,...,T\}$ and shuffle $I_1, I_2$ and combine $I = I_1 \cup I_2$.
        \FOR{$i \in \{1,...,2T\}$}
            \IF{$i = 1$}
                \STATE Calculate $W^l = \{ \exp(-(\beta_{l} - \beta_{l-1})NE(\theta_M^{l-1,i}))\}_{i=1}^{T}$.
                \STATE Select $j$ such that $\theta_M^{l,1} = \theta_M^{l-1,j}$ with probability $\frac{W^{l,j}}{\sum_j W^{l,j}}$.
            \ELSE
                \STATE Set $\theta_M^{l,i} = \theta_M^{l,i-1}$.
            \ENDIF
            \STATE Update $\theta_M^{l,i}$ using the MCMC method with step size $\epsilon_l$.
            \STATE Set $j = I^i$.
            \STATE Calculate $v = \dfrac{p_{\beta_{l}}(\theta_M^{l-1,j}|D,M)p_{\beta_{l-1}}(\theta_M^{l,i}|D,M)}{p_{\beta_{l}}(\theta_M^{l,i}|D,M)p_{\beta_{l-1}}(\theta_M^{l-1,j}|D,M)}$.
            \STATE Exchange $\theta_M^{l-1,j}$ and $\theta_M^{l,i}$ with probability $\min(1,v)$.
        \ENDFOR
        \STATE Add $\{\theta_M^{l,i}\}_{i=T}^{2T}$ to $\Theta_M$.
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

\subsection{Parameter Tuning}
In the SEMC method, the inverse temperature $(\beta_l)$ and the step size $(\epsilon_l)$ must be tuned.
We considered tuning $\beta_l$ from the samples, $\{\theta_M^{l-1,i}\}_{i=1}^T$.
Let $p_1$ and $p_2$ be the probability distributions of $\beta_{l-1}$ and $\beta_l$.
The exchange rate, $J$, between $p_1$ and $p_2$ was defined as
\begin{align}
    J &= \int \int u p_1(\theta_1)p_2(\theta_2)\textup{d}\theta_1 \textup{d}\theta_2. \\
    u &= \min\left(1, r\right). \\
    r &= \dfrac{p_2(\theta_1)p_1(\theta_2)}{p_2(\theta_2)p_1(\theta_1)}.
\end{align}
$J$ can be transformed as follows:
\begin{align}
    J &= \int\int_{E(\theta_2) < E(\theta_1)} r p_2(\theta_2)p_1(\theta_1)\textup{d}\theta_1 \textup{d}\theta_2  + \int\int_{E(\theta_2) \geq E(\theta_1)} p_2(\theta_2)p_1(\theta_1)\textup{d}\theta_1 \textup{d}\theta_2 \\ 
    &= 2\int\int_{E(\theta_2) \geq E(\theta_1)} p_2(\theta_2)p_1(\theta_1)\textup{d}\theta_1 \textup{d}\theta_2 \\
    &= 2\frac{C_1}{C_2}\int\int_{E(\theta_2) \geq E(\theta_1)} \exp(-(\beta_l - \beta_{l-1})NE(\theta_1))p_1(\theta_2)p_1(\theta_1)\textup{d}\theta_1 \textup{d}\theta_2.
    \label{eq:exchange_rate}
\end{align}
$C_1$ and $C_2$ are the normalization constants of $p_1$ and $p_2$, respectively, and $\frac{C_2}{C_1}$ can be transformed as follows:
\begin{align}
    \frac{C_2}{C_1} &= \frac{\int \exp(-\beta_{l}NE(\theta))p(\theta)\textup{d}\theta}{\int \exp(-\beta_{l-1}NE(\theta))p(\theta)\textup{d}\theta}. \\
    &= \int \exp(-(\beta_{l} - \beta_{l-1})NE(\theta))p_1(\theta)\textup{d}\theta.
    \label{eq:ratio}
\end{align}
Equations (\ref{eq:exchange_rate}) and (\ref{eq:ratio}) show that $J$ can be approximated from the samples of inverse temperature $\beta_{l-1}$.
Thus, the inverse temperature parameter, $\beta_l$, can be set such that $J$ is constant. \par

We considered tuning the initial step size of $\epsilon_l$ according to the step size $\epsilon_{l-1}, \epsilon_{l-2}$ and adjusted it using the Robbins-Monro algorithm.
We assumed that the optimal step size was proportional to the temperature, $\frac{1}{\beta_l}$, as follows:
\begin{align}
    \epsilon_{l-2}: \epsilon_{l-1}: \epsilon_{l} = \frac{1}{\beta_{l-2}^d}:\frac{1}{\beta_{l-1}^d}:\frac{1}{\beta_{l}^d},
\end{align}
where $d$ is a constant. \par
From this assumption, the initial step size, $\epsilon_l$, was set as follows:
\begin{align}
    \epsilon_{l} &= \epsilon_{l-1}\left(\frac{\beta_{l-1}}{\beta_{l}}\right)^{d} \\
    \label{eq:initial_epsilon}
    d &= \frac{\log(\epsilon_{l-1}/\epsilon_{l-2})}{\log(\beta_{l-1}/\beta_{l-2})}.
\end{align}
For $\epsilon_1$ and $\epsilon_2$ are set to make the acceptance rate of the Metropolis algorithm approximately 0.5.
% Details of the initial step size are provided in the Section 1 of the Supplementary Materials \cite{nabikasupplementary}. \par
%  we set $b-a$ when the prior distribution was uniform, $U(a,b)$. Otherwise, we set it to 2.94 times the standard deviation of the prior distribution. 
% Owing to these step sizes, the acceptance rate of the Metropolis algorithm was approximately 0.5, as shown in the supplementary materials.
\par
The initial step size can be adjusted to the optimal value using the Robbins-Monro algorithm.
Here, we updated the step size every $M = 50$ samples and set $c = 4, N_0 = 15$, and $p^* = 0.5$ for all distributions and parameters. \par

\subsection{Parallelization}
The computation of the SEMC method can be parallelized on a small scale. 
For this, multiple initial samples ($S$ samples) are selected, and each sample is updated independently and in parallel using the exchange and Metropolis algorithm. 
The step size is automatically tuned via the Robbins-Monro algorithm, utilizing the average acceptance rates of the parallelized samples. 
In this study, we fixed $S=50$ for all experiments. \par

\subsection{Comparison of the SEMC and waste-free SMC methods}
% SEMCアルゴリズムは, Waste-free SMCアルゴリズムに交換を導入したものということができる.
% アルゴリズムの16行目から18行目までを削除したものが,  Waste-free SMCアルゴリズムのS=1の場合と等価であり, 
% 上のparallelizationで述べたように, Sを自由に変更することができる.

% Waste-free SMCアルゴリズムは, Sを小さくした場合に, リサンプリングの精度が下がる.
% 例えば, 二つの離れたピークを持つ分布の場合, Sが小さいと, リサンプリングによってサンプルに偏りが生じ, 片方のピークのサンプルが少なくなる可能性がある.
% 一方で, SEMCアルゴリズムは, 交換を随時行うため, リサンプリングによる偏りが生じにくい. 
% see Figure 1 for the sketch of the difference between the two algorithms.

The SEMC algorithm can be viewed as an extension of the waste-free SMC algorithm incorporating exchange steps.
The SEMC algorithm is equivalent to the waste-free SMC algorithm with $S = 1$ when lines 16 to 18 are omitted in Algorithm \ref{SEMC}.
As discussed in the parallelization section, the value of $S$ in the SEMC algorithm can be freely adjusted. \par

In the waste-free SMC algorithm, the accuracy of resampling decreases when $S$ is small.
For example, when the distribution has two distant peaks, using a small $S$ in resampling may introduce a bias, resulting in fewer samples from one of the peaks.
In contrast, the SEMC algorithm incorporates exchange steps, reducing the likelihood of bias caused by resampling.
Figure \ref{fig:sketch} shows a sketch of the difference between the two algorithms. \par

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{sketch.png}
  \caption{Sketch illustrating the difference between the SEMC and waste-free SMC algorithms.
  Left: waste-free SMC algorithm when $S = 2, n = 3$. Right: SEMC algorithm with $S = 1$.
  The SEMC algorithm incorporates exchange steps, which mitigate the likelihood of bias caused by resampling when $S$ is small.}
  \label{fig:sketch}
\end{figure}

\section{Numerical Experiments}
We compared the performances of SEMC, REMC and waste-free SMC through numerical experiments.
Section 4.1 describes the problem settings, and section 4.2 presents the experimental results.
\subsection{Problem Settings}
This subsection describes three problem settings.
In all the problem settings, a computer with 10 cores and 32-GB memory (Apple M1 Pro) was used, and the algorithm was implemented in C++.
The compiler option was set to -O3, and OpenMP was employed for parallelization. \par
This study considered problem settings where $\log C$ is a constant that is not dependent on the model.
Thus, we defined $F'(M) = F(M) - \log C$ and calculated $F'(M)$ instead of $F(M)$.
\subsubsection{Sampling from Artificial Multimodal Distribution}
In this setting, we considered sampling from a two-dimensional multimodal distribution. Let $r = 1.001, N = 30{,}000$.
We defined the prior distribution as a uniform distribution on $[0,1]$ and the error function $E(\theta)$ as follows:
\begin{align}
  E(\theta = \{\theta_1, \theta_2\} ) = \begin{cases}
      r(\theta_1 - 0.25)^2 + (\theta_2 - 0.5)^2 & (\theta_1 < 0.5) \\
      (\theta_1 - 0.75)^2 + (\theta_2 - 0.5)^2 + (r-1)/16 & (\theta_1 > 0.5). \\ 
  \end{cases}           
\end{align}
Therefore, the posterior distribution was $p(\theta) \propto \exp(-NE(\theta))$.
Figure \ref{fig:multimodal} shows the theoretical values of the posterior distribution and histogram of $\theta_1$ with a bin width of 0.001. 
\begin{figure}[H]
  \centering
  \includegraphics[width=6cm]{multimodal.png}
  \includegraphics*[width = 6cm]{multimodal_hist.png}
  \caption{Two-dimensional multimodal distribution for sampling (left) and histogram of $\theta_1$ (right).}
  \label{fig:multimodal}
\end{figure}
The Bayesian free energy $(F')$ was calculated as $F' \simeq 9.022$. \par

% パラメータによって分散が異なるため, TMCMCで提案されているような高次元の提案分布を用いることが難しい.
% そのため, この問題設定では, 一次元の一様分布を提案分布とし, パラメータを一つずつ更新することで, MCMCステップを行った.

In this setting, using a high-dimensional proposal distribution, as suggested in TMCMC \cite{ching2007transitional}, is difficult because the variance of the proposal distribution depends on the parameters. 
To address this, we employed a one-dimensional uniform distribution as the proposal distribution and updated the parameters sequentially during the MCMC steps. \par


\subsubsection{Spectral Deconvolution}
In this setting, we considered spectral deconvolution \cite{Nagata2012}.
In spectral deconvolution, the spectral data are modeled as a sum of multiple peak functions, and the number of peak functions and their parameters are estimated.
Let $\theta_K = \{a_k, \mu_k, b_k\}_{k=1}^K$ be the parameters. The model of the spectral function, $f_K(x;\theta_K)$, was defined as follows:
\begin{align}
  f_K(x;\theta_K) = \sum_{k=1}^K a_k\exp\left(-\frac{b_k}{2}(x - \mu_k)^2\right).
\end{align}
Let $y_i$ be the output, which follows a Gaussian noise with mean $f_K(x_i;\theta_K)$ and variance $\sigma^2$.
The probability of obtaining the observed data, $D = \{x_i, y_i\}_{i=1}^N$, was as follows:
\begin{align}
  p(D|\theta_K) = \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(y_i - f_K(x_i;\theta_K))^2}{2\sigma^2}\right).
\end{align}
In this setting, we considered $K = 3$ and $K = 10$. 
% We show the true values of parameters and prior distributions for each $K$ in the Section 3 of the Supplementary Materials \cite{nabikasupplementary}.
% \begin{align}
%   \begin{pmatrix}
%       a_1^*\\
%       a_2^*\\
%       a_3^*\\
%   \end{pmatrix} 
%   = 
%   \begin{pmatrix}
%       0. 587\\
%       1.522\\
%       1.183\\
%   \end{pmatrix}  ,\ 
%   \begin{pmatrix}
%       \mu_1^*\\
%       \mu_2^*\\
%       \mu_3^*\\
%   \end{pmatrix}
%   = 
%   \begin{pmatrix}
%       1.210\\
%       1.455\\
%       1.703\\
%   \end{pmatrix} ,\ 
%   \begin{pmatrix}
%      b_1^*\\
%      b_2^*\\
%      b_3^*\\
%   \end{pmatrix}
%   = 
%   \begin{pmatrix}
%       95.689\\
%       146.837\\
%       164.469\\
%   \end{pmatrix},\ 
%   \sigma^2 = 0.01.
% \end{align}
% The number of data points was $N = 301$, and the set of inputs $X$ was $\{0.01(i-1)\}_{i=1}^N$.
% Let $\eta_a = 5.0, \lambda_a = 5.0, \nu_0 = 1.5, \xi_0 = 5.0, \eta_\sigma = 5.0, \lambda_\sigma = 0.04$. The prior distribution was defined as follows:
% \begin{align}
%   \varphi(a_k) &= \textup{Gamma} \left(a_k;\eta_a,\lambda_a\right) \\
%   &= \frac{1}{\Gamma(\eta_a)}(\lambda_a)^{\eta_a}(a_k)^{\eta_a-1}\exp\left(-\lambda_a a_k\right) \\
%   \varphi(\mu_k) &= N(\nu_0, (\xi_0)^{-1}) \\
%   &= \sqrt{\frac{\xi_0}{2\pi}}\exp\left(-\frac{\xi_0}{2}(\mu_k-\nu_0)^2\right)\\
%   \varphi(\sigma_k) &= \textup{Gamma} \left(\frac{1}{\sigma_k^2};\eta_{\sigma},\lambda_{\sigma}\right).
% \end{align}
The posterior distribution and Bayesian free energy can be formulated using the Bayesian theorem.
In this case, the theoretical values are unknown; thus, we employed the REMC method with a sufficient number of samples and distributions to obtain values to compare with those of other methods
($T_1 = 1{,}000{,}000$, $T_2 = 1{,}000{,}000$, and $L = 50$ for $K = 3$, $T_1 = 500{,}000$, $T_2 = 500{,}000$, and $L = 50$ for $K = 10$). \par
Figure \ref{fig:spectral_K_3} shows the $D = \{x_i,y_i\}_{i=1}^{301}$ and the histogram of the posterior distribution of $\mu_1, \mu_2, \mu_3 (\mu_1< \mu_2< \mu_3)$ for $K = 3$ with a bin width of 0.005.
Figure \ref{fig:spectral_K_10} shows the $D = \{x_i,y_i\}_{i=1}^{301}$ and histogram of the posterior distribution of $\mu_1, \mu_2, \cdots, \mu_{10} (\mu_1< \mu_2< \cdots < \mu_{10})$ for $K = 10$ with a bin width of 0.005. \par
The Bayesian free energy was calculated to be $F' = 170.881, 224.364$ for $K = 3, 10$, respectively. \par
\begin{figure}[h]
  \centering
  \includegraphics[width=6cm]{spectral_deconvolution_data.png}
  \includegraphics[width=6cm]{spectral_deconvolution_hist.png}
  \caption{Observed data for spectral deconvolution (left) and histogram of posterior distribution of $\mu_1, \mu_2, \mu_3$ (right) for $K = 3$.}
  \label{fig:spectral_K_3}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=6cm]{spectral_deconvolution_data_K_10.png}
  \includegraphics[width=6cm]{spectral_deconvolution_hist_K_10.png}
  \caption{Observed data for spectral deconvolution (left) and histogram of posterior distribution of $\mu_1, \mu_2, ..., \mu_{10}$ (right) for $K = 10$.}
  \label{fig:spectral_K_10}
\end{figure}

% In this setting, we used a one-dimensional uniform distribution as the proposal distribution and updated the parameters one by one to perform the MCMC steps 
As in the previous setting, we employed a one-dimensional uniform distribution as the proposal distribution and updated the parameters sequentially during the MCMC steps. \par

\subsubsection{Exhaustive Search}
In this setting, we considered the exhaustive search problem in which the optimal subset of explanatory variables was selected \cite{igarashi2018exhaustive}.
Let $X \in \mathbb{R}^{N \times p}$ be the input, $\boldsymbol{\beta} \in \mathbb{R}^{p}$ be the coefficient, and $\boldsymbol{c} \in [0,1]^p$ be the indicator that determines whether or not to use the coefficient.
The output, $\boldsymbol{y} \in \mathbb{R}^{N}$, was represented by the following linear regression model with noise $\boldsymbol{\epsilon} \in \mathbb{R}^{N}$:
\begin{align}
  \boldsymbol{y} = X(\boldsymbol{\beta} \odot \boldsymbol{c}) + \boldsymbol{\epsilon}.
\end{align}
Here, $\odot$ is the Hadamard product, namely $(\boldsymbol{\beta} \odot \boldsymbol{c})_i = \beta_i c_i$. \par
Assuming that each element of $\boldsymbol{\beta}$ followed an independent normal distribution with mean $0$ and variance $s$, and $\boldsymbol{\epsilon}$ followed a normal distribution with mean $\boldsymbol{0}$ and covariance matrix $\Sigma$, the negative log likelihood, $-\log(p(\boldsymbol{y}|\boldsymbol{c},X))$, was calculated as follows:
\begin{align}
  -\log(p(\boldsymbol{y}|\boldsymbol{c},X)) = K\log s + \frac{1}{2} \log\det(2\pi\Sigma) + \frac{1}{2}\log\det \Lambda - \frac{1}{2}\boldsymbol{\mu}^\top\Lambda^{-1}\boldsymbol{\mu} + \frac{1}{2}\boldsymbol{y}^\top\Sigma^{-1}\boldsymbol{y}.
  \label{eq:exhaustive}
\end{align}
Here, $K$ is the number of elements in $\boldsymbol{c}$ that are $1$, $\Lambda = (X_I^\top \Sigma^{-1} X_I + \frac{1}{s^2}I)^{-1}$, $\boldsymbol{\mu} = \Lambda X_I^\top \Sigma^{-1} \boldsymbol{y}$, and $X_I$ is a matrix comprising explanatory variables whose elements are nonzero in $\boldsymbol{c}$.
By minimizing the negative log likelihood, the optimal subset of explanatory variables was selected.
When $K$ and $N$ are large, it is difficult to calculate Equation (\ref{eq:exhaustive}) for all combinations.
Thus, we defined $E(\boldsymbol{c}) = -\log(p(\boldsymbol{y}|\boldsymbol{c},X))/N$ and employed the REMC method to find the optimal $\boldsymbol{c}$. \par
Here, we consider a case in which $N = 700, p = 200, s = 1, \Sigma = 0.1I$, $K = 4$, and $c_1 = 1, c_2 = 1, c_3 = 1, c_4 = 1$.
The theoretical values were unknown; thus, we employed the REMC method with a sufficient number of samples and distributions to obtain values to compare with those of other methods
($T_1 = 1{,}000{,}000$, $T_2 = 1{,}000{,}000$, and $L = 100$).
The Bayesian free energy was calculated to be $F' = 208.956$. \par
In this setting, the parameter update was performed by randomly selecting an element of $\boldsymbol{c}$ and flipping it. \par

\subsection{Results}
We evaluated the performance of the SEMC method in the three aforementioned problem settings by comparing it with the REMC and SMCS methods.
In this study, we used waste-free SMC as the SMCS method because the SEMC method can be viewed as a special case of the waste-free SMC method. \par
For the REMC method, the initial step size was manually set to acheive a final acceptance rate of approximately 0.5.
The parameter $\gamma$, which determines the inverse temperatures, was selected using the approach described in Section 3.2, and the inverse temperatures were set according to Equation (\ref{eq:temperature_setting}). \par
In the waste-free SMC method, both the step size and the inverse temperatures were updated in the same manner as in the SEMC method to enable a direct comparison. \par
In this section, we describe the evaluation of the automatic parameter tuning, the comparison of the performance of the REMC and SEMC methods, and the comparison of the performance of the waste-free SMC and SEMC methods. \par
% Section 4.2.1 describes the evaluation of the automatic parameter tuning, and section 4.2.2 describes the comparison of the performance of the REMC and SEMC methods. Section 4.2.3 presents the comparison of the performance of the SMCS and SEMC methods. \par

\subsubsection{Automatic Parameter Tuning}
First, we evaluated the automatic tuning of the inverse temperature and the step size of the SEMC method.
Figure \ref{fig:temperature_setting} shows the relationship between the inverse temperature and the exchange rate of the SEMC and REMC method
($T_1 = 10{,}000$ and $T_2 = 10{,}000$).
In the SEMC method, the inverse temperature was set to $J = 0.1, 0.3, 0.5, 0.7, 0.9$. 
In the REMC method, the number of temperatures was set to $ L = 10, 30, 100$, and the inverse temperature, $\beta_2$, was set such that the exchange rate between $\beta_1$ and $\beta_2$ was $J = 0.5$, and the other inverse temperatures were set according to Equation (\ref{eq:temperature_setting}). \par
\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{exchange_rate.png}
  \caption{Inverse temperature, $\{\beta_l\}_{l=2}^L$, and exchange rate between the $p_{\beta_l}, p_{\beta_{l-1}}$ of the SEMC and REMC methods with 10, 30, and 100 temperatures. (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$), (II-(b)) Spectral deconvolution ($K=10$), (III) Exhaustive search. (a) SEMC method, (b) REMC method with 10 temperatures, (c) REMC method with 30 temperatures, (d) REMC method with 100 temperatures. The vertical and horizontal axes represent the exchange rate and inverse temperature, respectively.}
  \label{fig:temperature_setting}
\end{figure}
In the SEMC method, the exchange rate was close to the $J$ in each problem setting.
The exchange rate of the lowest temperatures is frequently high because the proposed temperature was set to 1 when it exceeded 1.
In the REMC method, the exchange rate was approximately $0.5$ at the highest temperature.
Oppositely, at other temperatures, the exchange rate was high at a large $L$ and low at a small $L$. \par
Here, we set $J = 0.5$ because the performance did not considerably change when $J$ changed. \par
Next, we evaluated the convergence of the automatic tuning of the step size.
Let $\epsilon^{final}$ be the final step size.
We examined the transition of $\epsilon/\epsilon^{final}$, during the burn-in period for the SEMC method.
Figure \ref{fig:step_size} shows the transition of $\epsilon/\epsilon^{final}$ during the burn-in period at a high temperature $(l = 2)$, an intermediate temperature $(l = \lfloor (L+2)/2 \rfloor)$, and a low temperature $(l = L)$ in the continuous variable problem setting.
Here, we showed the average values of all the parameters.
\begin{figure}[H]
  \centering
  \includegraphics[width=11cm]{step_size.png}
  \caption{Transition of step size during the burn-in period of the SEMC method. (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$), (II-(b)) Spectral deconvolution ($K=10$). 
  The high, intermediate, and low temperatures are indicated by round, cross, and square markers, respectively. 
  The vertical and horizontal axes represent the ratio of the step size to the final step size, $\epsilon/\epsilon^{final}$, and the number of iterations, respectively.}
  \label{fig:step_size}
\end{figure}
In all the problem settings, the $\epsilon/\epsilon^{final}$ during the burn-in period converged to a constant value.
In addition, the initial step size, $\epsilon/\epsilon^{final}$, at the intermediate and low temperature was approximately 1, indicating that the initial step size tuning was successful. \par
Finally, we evaluated the step size of the converged parameters obtained via the SEMC method.
Figure \ref{fig:final_step_size} shows the relationship between the adjusted step size and inverse temperature.
Here, we showed the average value for each temperature for the spectral deconvolution problem setting.
For all parameters, the distribution width at the low temperature was proportional to $\beta^{-\frac{1}{2}}$.  
This was consistent with the fact that the distribution width was proportional to $\beta^{-\frac{1}{2}}$ in the low temperature limit \cite{iwamitsu2021replica}. 
\begin{figure}[H]
  \centering
  \includegraphics[width=11cm]{adjustedstep.png}
  \caption{Relationship between adjusted step size and inverse temperature in the SEMC method. (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$) and (II-(b)) Spectral deconvolution ($K=10$). The vertical axis represents the ratio of the adjusted step size for each temperature, $\epsilon_l^{final}$, to the adjusted step size for the lowest temperature, $\epsilon_2^{final}$, and the horizontal axis represents the inverse temperature.}
  \label{fig:final_step_size}
\end{figure}

\subsubsection{Comparison with REMC}
Next, we compared the performances of the SEMC and REMC methods.
Figure \ref{fig:hist_EMC} and \ref{fig:free_energy_EMC} show the results of the comparison of the posterior distribution and the Bayesian free energy.
In the SEMC method, the burn-in size was the same as the number of samples, and the number of samples was $\{10{,}000,30{,}000,100{,}000\}$ for spectral deconvolution with $K=10$, and $\{10{,}000,30{,}000,100{,}000,300{,}000\}$ for the other problem settings. \par
In the REMC method, the number of temperatures $L$ was $\{10,30,100,300\}$. Let $N_{10} = 1000,N_{30} = 300, N_{100} = 100, N_{3000} = 30$.
For spectral deconvolution with $K=10$, the number of samples was $\{N_L,3N_L,10N_L\}$ for $L = 10,100$ and $\{N_L,\frac{10}{3}N_L,10N_L\}$ for $L = 30,300$.
For the other settings, the number of samples was $\{N_L,3N_L,10N_L,30N_L\}$ for $L=10,100$ and $\{N_L,\frac{10}{3}N_L,10N_L, \frac{100}{3}N_L\}$ for $L=30,300$. \par
The bin size of the histogram of $\theta_1$ was set to 0.001 for the multimodal distribution and that of $\mu$ was set to 0.005 for the spectral deconvolution.
For each sample, we performed 10 trials and took the average for comparison. \par
First, we compared the results of the posterior distribution.
Figure \ref{fig:hist_EMC} shows the Wasserstein distance between the histogram in Section 4.1 and those of the SEMC and REMC methods.
In all the problem settings, the sampling accuracy of the SEMC method is equivalent to or higher than that of the REMC method.
Especially, the REMC method showed a low accuracy when $L = 300$, because the number of samples was insufficient. \par
\begin{figure}[h]
  \centering
  \includegraphics[width=9cm]{EMC_distribution.png}
  \caption{Comparison of sampling accuracy between the SEMC and REMC methods. The vertical and horizontal axes represent the Wasserstein distance and computation time, respectively. 
  The average of 10 trials is shown. 
  (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$), and (II-(b)) Spectral deconvolution ($K=10$). 
  SEMC, REMC with $L=10$, $L=30$, $L=100$ and $L=300$ are indicated by round, cross, square, inverted triangle, and triangle markers, respectively. }
  \label{fig:hist_EMC}
\end{figure}
Next, we compared the results of the Bayesian free energy.
Figure \ref{fig:free_energy_EMC} shows the absolute difference between the Bayesian free energy in Section 4.1 and those of the SEMC and REMC methods.
In all the problem settings, the SEMC method exhibited highly accurate Bayesian free energy compared with the REMC method. \par
\begin{figure}[H]
  \centering
  \includegraphics[width=12cm]{EMC_freeenergy.png}
  \caption{Comparison of accuracy of the Bayesian free energy between the SEMC and REMC methods. 
  The vertical and horizontal axes represent the absolute difference and the computation time, respectively. 
  The average of 10 trials is shown. 
  (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$), (II-(b)) Spectral deconvolution ($K=10$), and (III) Exhaustive search. 
  SEMC, REMC with $L=10$, $L=30$, $L=100$ and $L=300$ are indicated by round, cross, square, inverted triangle, and triangle markers, respectively. }
  \label{fig:free_energy_EMC}
\end{figure}


\subsubsection{Comparison with waste-free SMC}

Finally, we compared the performances of the SEMC and waste-free SMC methods. 
In the SEMC method, the burn-in size and the number of samples were identical to those used in the comparison with the REMC method. \par

For the waste-free SMC method, both the number of samples and the burn-in size were set to match those of the SEMC method to enable a fair comparison.
The number of steps was configured as $n = 1,10,100$.
We note that when $n = 1$, the waste-free SMC method is equivalent to the SMCS method.
For each sample, we performed 10 trials and took the average for comparison. \par
First, we compared the results of the posterior distribution.
Figure \ref{fig:hist_TMCMC} shows the Wasserstein distance between the histogram in Section 4.1 and those of the SEMC and waste-free SMC methods. \par
For sampling from the multimodal distribution and the spectral deconvolution problem with $K = 3$, the sampling accuracy of the waste-free SMCS method is highest when $n = 1$.
Conversely, for the spectral deconvolution problem with $K = 10$, the sampling accuracy of the waste-free SMCS method is highest when $n = 10$.
This behavior arises because a large $n$ introduces bias during resampling, while a small $n$ results in insufficient convergence for each sample, especially when the parameter dimensions are high.
Therefore, the waste-free SMC method requires a tuning of $n$ for each specific problem setting. 
On the other hand, the SEMC method exhibited the same or higher accuracy than the waste-free SMC method for all problem settings, eliminating the need for parameter tuning $n$. \par

\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{SMCS_distribution.png}
  \caption{Comparison of sampling accuracy between the SEMC and waste-free SMC methods.
  The vertical and horizontal axes represent the Wasserstein distance and computation time, respectively. 
  The average of 10 trials is shown. 
  (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$) and (II-(b)) Spectral deconvolution ($K=10$). 
  SEMC, waste-free SMC methods with $n=1$, $n=10$ and $n=100$ are indicated by round, cross, square, and inverted triangle markers, respectively. }
  \label{fig:hist_TMCMC}
\end{figure}


% and higher accuracy than the waste-free SMC method with $n = 1$ and $n = 100$.
% The reason for this is that the number of steps are required to converge to the target distribution as the dimension of the parameter increases. \par
% As the dimension of the parameter increased, the number of steps are required to converge to the target distribution.

Next, we compared the results of the Bayesian free energy.
Figure \ref{fig:free_energy_TMCMC} shows the absolute difference between the Bayesian free energy in Section 4.1 and those of the SEMC and waste-free SMC methods.
As observed in the comparison of the posterior distribution, the waste-free SMC method required tuning of $n$ for each problem setting. 
This was particularly evident in exhaustive search, where discrete variables are sampled, as a large $n$ was necessary to achieve accurate results. 
In contrast, the SEMC method consistently demonstrated the same or higher accuracy compared to the waste-free SMC method across all problem settings. \par 

\begin{figure}[h]
  \centering
  \includegraphics[width=12cm]{SMCS_freeenergy.png}
  \caption{Comparison of accuracy of the Bayesian free energy between the SEMC and TMCMC methods. 
  The vertical and horizontal axes represent the absolute difference and computation time, respectively. 
  The average of 10 trials is shown. 
  (I) Sampling from a multimodal distribution, (II-(a)) Spectral deconvolution ($K=3$) and (II-(b)) Spectral deconvolution ($K=10$). 
  SEMC, waste-free SMC with $n=1$, $n=10$ and $n=100$ are indicated by round, cross, square, and inverted triangle markers, respectively. }
  \label{fig:free_energy_TMCMC}
\end{figure}

\section{Conclusion}
This paper proposes the SEMC method, an efficient approach for performing Bayesian inference on complex models without requiring parameter tuning.
Numerical experiments demonstrated that the SEMC method is more efficient than the parameter-tuned REMC method and the parameter-tuned SMCS method.
Owing to the SEMC method, MCMC nonexperts can perform the Bayesian inference of complex models. 
The method is expected to contribute to the spread of Bayesian inference in various fields.
By enabling MCMC nonexperts to perform Bayesian inference on complex models, the SEMC method is expected to contribute to the broader adoption of Bayesian inference across various fields. 
Additionally, the SEMC method is particularly useful in sequential experimental designs \cite{nabika2024bayesian}, where Bayesian inference must be conducted without human intervention. \par
The theoretical foundation of the SEMC method lies in the “exchange” process, which satisfies the detailed balance condition under the assumption of an infinite number of samples. 
However, in practical applications, the number of samples is finite. 
Future work will explore the validity and convergence of the SEMC method with a finite sample size and compare its convergence properties with those of the REMC and SMCS methods \cite{woodard2009sufficient,mathews2024finite}.\par

Additionally, we plan to enhance the SEMC method by combining it with gradient-based Monte Carlo algorithms, such as the Hamiltonian Monte Carlo (HMC) method \cite{neal2011mcmc} and Langevin dynamics \cite{roberts2002langevin}. 
This integration is expected to significantly improve the performance of the SEMC method, similar to how Langevin dynamics and HMC methods have been shown to boost the efficiency of the SMCS method \cite{arampatzis2018langevin,gunawan2020subsampling}.
  
\begin{thebibliography}{10}

    \bibitem{andrieu2008tutorial}
    C.~Andrieu and J.~Thoms.
    \newblock A tutorial on adaptive {MCMC}.
    \newblock {\em Statistics and Computing}, 18:343--373, 2008.
    
    \bibitem{arampatzis2018langevin}
    G.~Arampatzis, D.~Walchli, P.~Angelikopoulos, S.~Wu, P.~Hadjidoukas, and
      P.~Koumoutsakos.
    \newblock Langevin diffusion for population based sampling with an application
      in bayesian inference for pharmacodynamics.
    \newblock {\em SIAM Journal on Scientific Computing}, 40(3):B788--B811, 2018.
    
    \bibitem{beskos2016convergence}
    A.~Beskos, A.~Jasra, N.~Kantas, and A.~Thiery.
    \newblock {On the convergence of adaptive sequential Monte Carlo methods}.
    \newblock {\em The Annals of Applied Probability}, 26(2):1111 -- 1146, 2016.
    
    \bibitem{PRML}
    C.~M. Bishop and N.~M. Nasrabadi.
    \newblock {\em Pattern recognition and machine learning}, chapter~2.
    \newblock Springer, 2006.
    
    \bibitem{carpenter2017stan}
    B.~Carpenter, A.~Gelman, M.~D. Hoffman, D.~Lee, B.~Goodrich, M.~Betancourt,
      M.~A. Brubaker, J.~Guo, P.~Li, and A.~Riddell.
    \newblock Stan: A probabilistic programming language.
    \newblock {\em J. Stat. Softw.}, 76, 2017.
    
    \bibitem{ching2007transitional}
    J.~Ching and Y.-C. Chen.
    \newblock Transitional {M}arkov {C}hain {M}onte {C}arlo method for {B}ayesian
      model updating, model class selection, and model averaging.
    \newblock {\em Journal of Engineering Mechanics}, 133(7):816--832, 2007.
    
    \bibitem{chopin2002sequential}
    N.~Chopin.
    \newblock A sequential particle filter method for static models.
    \newblock {\em Biometrika}, 89(3):539--552, 2002.
    
    \bibitem{dau2022waste}
    H.-D. Dau and N.~Chopin.
    \newblock Waste-free sequential monte carlo.
    \newblock {\em Journal of the Royal Statistical Society Series B: Statistical
      Methodology}, 84(1):114--148, 2022.
    
    \bibitem{del2006sequential}
    P.~Del~Moral, A.~Doucet, and A.~Jasra.
    \newblock Sequential {M}onte {C}arlo samplers.
    \newblock {\em Journal of the Royal Statistical Society Series B: Statistical
      Methodology}, 68(3):411--436, 2006.
    
    \bibitem{fearnhead2013adaptive}
    P.~Fearnhead and B.~M. Taylor.
    \newblock {An Adaptive Sequential {M}onte {C}arlo Sampler}.
    \newblock {\em Bayesian Analysis}, 8(2):411 -- 438, 2013.
    
    \bibitem{garthwaite2016adaptive}
    P.~H. Garthwaite, Y.~Fan, and S.~A. Sisson.
    \newblock Adaptive optimal scaling of {metropolis}--{h}astings algorithms using
      the {R}obbins--{M}onro process.
    \newblock {\em Communications in Statistics-Theory and Methods},
      45(17):5098--5111, 2016.
    
    \bibitem{geyer1991markov}
    C.~J. Geyer.
    \newblock Markov chain monte carlo maximum likelihood.
    \newblock {\em Retrieved from the University Digital Conservancy,
      https://hdl.handle.net/11299/58440}, 1991.
    
    \bibitem{gunawan2020subsampling}
    D.~Gunawan, K.-D. Dang, M.~Quiroz, R.~Kohn, and M.-N. Tran.
    \newblock Subsampling sequential monte carlo for static bayesian models.
    \newblock {\em Statistics and Computing}, 30:1741--1758, 2020.
    
    \bibitem{hoffman2014no}
    M.~D. Hoffman, A.~Gelman, et~al.
    \newblock The {N}o-{U}-turn sampler: Adaptively setting path lengths in
      {H}amiltonian {M}onte {C}arlo.
    \newblock {\em Journal of Machine Learning Research}, 15(1):1593--1623, 2014.
    
    \bibitem{hukushima2003population}
    K.~Hukushima and Y.~Iba.
    \newblock Population annealing and its application to a spin glass.
    \newblock In {\em AIP Conference Proceedings}, volume 690, pages 200--206.
      American Institute of Physics, 2003.
    
    \bibitem{Hukushima1996}
    K.~Hukushima and K.~Nemoto.
    \newblock {Exchange {M}onte {C}arlo method and application to spin glass
      simulations}.
    \newblock {\em Journal of the Physical Society of Japan}, 65(6):1604--1608,
      1996.
    
    \bibitem{igarashi2018exhaustive}
    Y.~Igarashi, H.~Takenaka, Y.~Nakanishi-Ohno, M.~Uemura, S.~Ikeda, and M.~Okada.
    \newblock Exhaustive search for sparse variable selection in linear regression.
    \newblock {\em Journal of the Physical Society of Japan}, 87(4):044802, 2018.
    
    \bibitem{iwamitsu2021replica}
    K.~Iwamitsu, Y.~Nishi, T.~Yamasaki, M.~Kamezaki, K.~Higashiyama, S.~Yakura,
      H.~Kumazoe, S.~Aihara, K.~Nagata, M.~Okada, et~al.
    \newblock Replica-exchange monte carlo method incorporating auto-tuning
      algorithm based on acceptance ratios for effective bayesian spectroscopy.
    \newblock {\em Journal of the Physical Society of Japan}, 90(10):104004, 2021.
    
    \bibitem{lye2021sampling}
    A.~Lye, A.~Cicirello, and E.~Patelli.
    \newblock Sampling methods for solving bayesian model updating problems: A
      tutorial.
    \newblock {\em Mechanical Systems and Signal Processing}, 159:107760, 2021.
    
    \bibitem{mathews2024finite}
    J.~Mathews and S.~C. Schmidler.
    \newblock Finite sample complexity of sequential monte carlo estimators on
      multimodal target distributions.
    \newblock {\em The Annals of Applied Probability}, 34(1B):1199--1223, 2024.
    
    \bibitem{metropolis1953equation}
    N.~{Metropolis}, A.~W. Rosenbluth, M.~N. Rosenbluth, A.~H. Teller, and
      E.~Teller.
    \newblock Equation of state calculations by fast computing machines.
    \newblock {\em Journal of Chemical Physics}, 21(6):1087--1092, 1953.
    
    \bibitem{nabika2024bayesian}
    T.~Nabika, K.~Nagata, M.~Mizumaki, S.~Katakami, and M.~Okada.
    \newblock Bayesian active learning with model selection for spectral
      experiments.
    \newblock {\em Scientific Reports}, 14(1):3680, 2024.
    
    \bibitem{nagata2015exhaustive}
    K.~Nagata, J.~Kitazono, S.~Nakajima, S.~Eifuku, R.~Tamura, and M.~Okada.
    \newblock An exhaustive search and stability of sparse estimation for feature
      selection problem.
    \newblock {\em Information Processing Society of Japan Online Transactions},
      8:25--32, 2015.
    
    \bibitem{Nagata2012}
    K.~Nagata, S.~Sugita, and M.~Okada.
    \newblock {Bayesian spectral deconvolution with the exchange {M}onte {C}arlo
      method}.
    \newblock {\em Neural Networks}, 28:82--89, 2012.
    
    \bibitem{nagata2008asymptotic}
    K.~Nagata and S.~Watanabe.
    \newblock Asymptotic behavior of exchange ratio in exchange {M}onte {C}arlo
      method.
    \newblock {\em Neural Networks}, 21(7):980--988, 2008.
    
    \bibitem{neal1993probabilistic}
    R.~M. Neal.
    \newblock Probabilistic inference using {M}arkov {C}hain {M}onte {C}arlo
      methods.
    \newblock {\em Department of Computer Science, University of Toronto Toronto,
      ON, Canada}, 1993.
    
    \bibitem{neal2001annealed}
    R.~M. Neal.
    \newblock Annealed importance sampling.
    \newblock {\em Statistics and computing}, 11:125--139, 2001.
    
    \bibitem{neal2011mcmc}
    R.~M. Neal et~al.
    \newblock {MCMC} using {H}amiltonian dynamics.
    \newblock {\em Handbook of {M}arkov {C}hain {M}onte {C}arlo}, 2(11):2, 2011.
    
    \bibitem{patil2010pymc}
    A.~Patil, D.~Huard, and C.~J. Fonnesbeck.
    \newblock Pymc: {B}ayesian stochastic modelling in python.
    \newblock {\em Journal of Statistical Software}, 35(4):1--81, 2010.
    
    \bibitem{phan2019composable}
    D.~Phan, N.~Pradhan, and M.~Jankowiak.
    \newblock Composable effects for flexible and accelerated probabilistic
      programming in numpyro.
    \newblock {\em arXiv preprint arXiv:1912.11554}, 2019.
    
    \bibitem{robbins1951stochastic}
    H.~Robbins and S.~Monro.
    \newblock A stochastic approximation method.
    \newblock {\em The annals of mathematical statistics}, pages 400--407, 1951.
    
    \bibitem{roberts2002langevin}
    G.~O. Roberts and O.~Stramer.
    \newblock Langevin diffusions and metropolis-hastings algorithms.
    \newblock {\em Methodology and Computing in Applied Probability}, 4:337--357,
      2002.
    
    \bibitem{sambridge2014parallel}
    M.~Sambridge.
    \newblock A parallel tempering algorithm for probabilistic sampling and
      multimodal optimization.
    \newblock {\em Geophysical Journal International}, 196(1):357--374, 2014.
    
    \bibitem{schafer2013sequential}
    C.~Sch{\"a}fer and N.~Chopin.
    \newblock Sequential monte carlo on large binary sampling spaces.
    \newblock {\em Statistics and Computing}, 23:163--184, 2013.
    
    \bibitem{sun2013review}
    S.~Sun.
    \newblock A review of deterministic approximate inference techniques for
      {B}ayesian machine learning.
    \newblock {\em Neural Computing and Applications}, 23:2039--2050, 2013.
    
    \bibitem{von2011bayesian}
    U.~Von~Toussaint.
    \newblock Bayesian inference in physics.
    \newblock {\em Reviews of Modern Physics}, 83(3):943, 2011.
    
    \bibitem{vousden2016dynamic}
    W.~Vousden, W.~M. Farr, and I.~Mandel.
    \newblock Dynamic temperature selection for parallel tempering in {M}arkov
      {C}hain {M}onte {C}arlo simulations.
    \newblock {\em Monthly Notices of the Royal Astronomical Society},
      455(2):1919--1937, 2016.
    
    \bibitem{weigel2021understanding}
    M.~Weigel, L.~Barash, L.~Shchur, and W.~Janke.
    \newblock Understanding population annealing monte carlo simulations.
    \newblock {\em Physical Review E}, 103(5):053301, 2021.
    
    \bibitem{woodard2009sufficient}
    D.~Woodard, S.~Schmidler, and M.~Huber.
    \newblock {Sufficient Conditions for Torpid Mixing of Parallel and Simulated
      Tempering}.
    \newblock {\em Electronic Journal of Probability}, 14:780 -- 804, 2009.
    
    \end{thebibliography}
    
    
\end{document}