\section{KnowPath}
\subsection{Preliminary}
\textbf{Topic Entities} represent the main entities in a query $Q$, denoted as $e_0$. 
Each $Q$ contains $N$ topic entities $\{e_0^1, ...,  e_0^N\}$.


 
% 推理路径
\noindent\textbf{Inference Paths} are a set of paths $P = {p_1, ..., p_L}$ generated by the LLM's own knowledge, where $L \in [1, N]$ is dynamically determined by the LLM agent. Each path $p$ starts from the topic entity $e_0 \in \{e_0^1,..., e_0^N\}$ and can be represented as $p = e_0 \to r_1 \to e_1 \to ... \to r_n \to e_n$, where $e_i$ and $r_i$ represent entities and relationships, respectively.


\noindent\textbf{Knowledge Graph(KG)} is composed of many structured knowledge triples: $K=\{(e_h,r,e_t),r\in R,e_h,e_t\in E\}$, where $E$ represents all entities in the knowledge graph, and $R$ represents all relationships, and 
$e_h$ and $e_t$ represent the head and tail entities, respectively.

\noindent\textbf{KG Subgraph} refers to a connected subgraph extracted from the knowledge graph $K$, where the entities and relationships are entirely derived from $K$, i.e., $K_s\subseteq K$.

\subsection{Inference Paths Generation}
\label{sec:ipg}

Due to the extensive world knowledge stored within its parameters, LLMs can be considered as a complementary representation of KGs.
To fully excavate the internal knowledge of LLMs and guide the exploration of KGs, we propose a prompt-driven method to extract the internal knowledge of LLMs effectively.
It can retrieve reasoning paths of the model's internal knowledge and clearly display the reasoning process, and also is particularly effective in zero-shot scenarios.
Specifically, given a query $Q$, we first guide the LLM to extract the most relevant topic entities $\{e_0^1, ..., e_0^N\}$ through a specially designed prompt.
Then, based on these topic entities, the large model is instructed to generate a set of knowledge triples associated with them. The number of triples $n$ is variable.
Finally, the LLM attempts to answer based on the previously generated knowledge triples and provides a specific reasoning path from entities and relations to the answer. Each path is in the form of $P=e_0^1 \to r_1 \to e_1 \to ... \to r_n \to e_n$. The details of the Inference Paths Generation process are presented in the Appendix A.1.

\subsection{Subgraph Exploration}
% 子图探索算法

\textbf{Exploration Initialization.} 
KnowPath performs subgraph exploration for a maximum of $D$ rounds.
Each round corresponds to an additional hop in knowledge graph $K$ and the $j$-th contains $N$ subgraphs $\{K_{s,j}^1,...,K_{s,j}^N \}$.
Each subgraph $K_{s,j}^i$ is composed of a set of knowledge graph reasoning paths, i.e. $K_{s,j}^i=\{p_{1,j}^i\cup \cdots \cup p_{l,j}^i,i \in [1,N]\}$.
The number of reasoning paths $l$ is flexibly determined by the LLM agent.
Taking the $D$-th round and the $z$-th path as an example, it starts exploration from one topic entity $e_{0}^i$ and ultimately forms a connected subgraph of the KG, denoted as ${p_{z,D}^i=\{e_{0}^i, e_{1,z}^i,r_{1,z}^i, e_{2,z}^i, r_{2,z}^i, ..., r_{D,z}^i, e_{D,z}^i\}}$.
The start of the first round of subgraph exploration ($D$=0), each path $p_i$ corresponds to the current topic entity, i.e.${p_{z,0}^0=\{e_{0}^1\}}$.
% Similar to other works in the field, the topic entities in $Q$ are already aligned with the dataset.




\textbf{Relation Exploration.}
Relation exploration aims to expand the subgraphs obtained in each round of exploration, enabling deep reasoning. Specifically, for the $i$-th subgraph and the $j$-th round of subgraph exploration, the candidate entities is denoted as $E_{j}^{i}=\{e_{j-1,1}^i,...,e_{j-1,l}^i\}$, where $e_{j-1,1}^i$ is the tail entity of the reasoning path $p_{1,j-1}^i$.
Based on these candidates $E_{j}^{i}$, we search for all coresponding single-hop relations in knowledge graph $K$, denoted as $R_{a,j}^{i}=\{r_1,...,r_M\}$, where $M$ is determined by the specific knowledge graph $K$.
Finally, the LLM agent will rely on the query $Q$, the inference path $P$ generated through the LLM’s internal knowledge (Section \ref{sec:ipg}), and all topic entities $e_{0}$ to select the most relevant candidate relations from $R_{a,j}^{i}$, denoted as $R_{j}^{i} \subseteq R_{a,j}^{i} $, which is dynamically determined by the LLM agent.



\textbf{Entity Exploration.}
Entity exploration depends on the already determined candidate entities and candidate relations.
Taking the $i$-th subgraph and the $j$-th round of subgraph exploration as an example, relying on $E_{j}^{i}$ and $R_{j}^{i}$, we perform queries like $(e, r, ?)$ or $(?, r, e)$ on the knowledge graph $K$ to retrieve the corresponding entities $E_{a,j}^{i} = \{e_1, ..., e_N\}$, where $N$ varies depending on the knowledge graph $K$.
Then, the agent also considers the query $Q$, the inference path $P$ in Section \ref{sec:ipg}, the topic entity $e_{0}^i$, and the candidate relation set $R_{j}^{i}$ from $E_{a,j}^{i}$ to generate the most relevant entity set $E_{j+1}^{i} = \{e_{j,1}^i, ..., e_{j,l}^i\} \subseteq E_{a,j}^{i}$. Note that $e_{j,1}^i$ is the tail entity of the reasoning path $p_{1,j}^i$.
\begin{algorithm}[t]
\caption{Subgraph Exploration}
\begin{algorithmic}[1]
\REQUIRE $entityDict$, $entityName$, $question$, \\ $maxWidth$, $depth$, $path$

\STATE Set $originalPath$ as $path$

\IF{$depth = 0$}
    \STATE Initialize $path$ as $[ \;]*maxWidth$
\ENDIF

\FOR{$eid$ in $entityDict$}
    \STATE Find $relevantRelations$
    \FOR{$relation$ in $relevantRelations$}
        \STATE Find entities linked by $relation$
    \ENDFOR
\ENDFOR

\STATE \textbf{Extract} $relevantEntities$ using candidate entities
\STATE \textbf{Update} $path$ and $entityDict$ based on relevance

\STATE $extraPath \leftarrow (path - originalPath)$

\RETURN $extraPath$, $entityDict$

\end{algorithmic}
\end{algorithm}
% % 路径更新算法
\begin{algorithm}[t]
    \caption{Update Reasoning Path in Subgraph}\label{alg:update_path}
    
    \begin{algorithmic}[1]
    \REQUIRE $path$, $pathIsHead$, $isHead$, $r$, $e$
    
    \IF{\textbf{not} $pathIsHead$} 
        \IF{\textbf{not} $isHead$}
            \STATE $newPath \gets path + [\leftarrow, r, \leftarrow, e]$.
        \ELSE
            \STATE $newPath \gets path + [\rightarrow, r, \rightarrow, e]$.
        \ENDIF
    \ELSE
        \IF{\textbf{not} $isHead$}
            \STATE $newPath \gets [e, \rightarrow, r, \rightarrow] + path$.
        \ELSE
            \STATE $newPath \gets [e, \leftarrow, r, \leftarrow] + path$.
        \ENDIF
    \ENDIF
    
    \STATE Append $newPath$ to $path$
    \RETURN $path$
    
    \end{algorithmic}
\end{algorithm}


\textbf{Subgraph Update.}
Relation exploration determines entity exploration, and we update the subgraph only after completing the entity exploration.
Specifically, for the $i$-th subgraph and the $j$-th round of subgraph exploration, we append the result of the exploration $( , r, e_{j,1}^i)$ to the path $p_{1,j}^i$ in the subgraph $K_{s,j}^i$.
This path update algorithm not only considers the directionality of entities and relations, but also automatically determines and updates the paths.
Its detailed process is described in Algorithm~\ref{alg:update_path}.
The final subgraph can be flexibly expanded due to the variable number of paths $l$.




\subsection{Evaluation-based Answering}

After completing the subgraph update for each round, the agent attempts to answer the query through the subgraph $\{K_{s,j}^1, ..., K_{s,j}^N \}$.
If it determines that the current subgraph is insufficient to answer the question, the next round of subgraph exploration will be executed, until the maximum exploration depth $D$ is reached.
Otherwise, it will output the final answer along with the corresponding interpretable directed subgraph.
Unlike previous work \cite{pog}, even if no answer is found at the maximum exploration depth, our KnowPath will rely on the inference path $P$ to response.
The framework of KnowPath is shown in Figure~\ref{fig:workflow}.
% generated through the LLM’s internal knowledge (Section \ref{sec:ipg}) to answer the query.
