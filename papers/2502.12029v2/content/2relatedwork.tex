\section{Related Work}

\textbf{Prompt-driven LLM inference.}

CoT\cite{cot} (Chain of Thought) effectively improves the reasoning ability of large models, enhancing performance on complex tasks with minimal contextual prompts. Self-Consistency (SC)\cite{sc} samples multiple reasoning paths to select the most consistent answer, with further improvements seen in DIVERSE\cite{cot-more-1} and Vote Complex\cite{cot-more-2}. Other methods have explored CoT enhancements in zero-shot scenarios\cite{zero1,zero2}. However, reasoning solely based on the model's knowledge still faces significant hallucination issues, which remain unresolved.

\textbf{KG-enhanced LLM inference.}

"Early works enhanced model knowledge understanding by injecting KGs into model parameters through fine-tuning or retraining\cite{re-kbqa,unikgqa,givefact}. ChatKBQA\cite{chatkbqa} and RoG\cite{rog} utilize fine-tuned LLMs to generate logical forms. StructGPT\cite{structgpt}, based on the RAG approach, retrieves information from KGs for question answering. ToG\cite{tog} and PoG\cite{pog} involve LLMs in knowledge graph reasoning, using them as agents to assist in selecting entities and relationships during exploration. Despite achieving strong performance, these methods still face challenges like insufficient internal knowledge mining and the inability to generate trustworthy reasoning paths.
