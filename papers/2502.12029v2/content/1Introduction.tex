\section{Introduction}

Large language models (LLMs) are increasingly being applied in various fields of Natural Language Processing (NLP) tasks, such as text generation\cite{text1,text2}, knowledge-based question answering\cite{chatkbqa,qa1}, and over specific domains\cite{special1,special2}. In most scenarios, LLMs serve as intermediary agents for implementing various functions\cite{agent1,agent2,agent3}. However, due to the characteristics of generative models, LLMs still suffer from hallucination issues, often generating incorrect answers that can lead to uncontrollable and severe consequences\cite{hallucinations1}. 
Introducing knowledge graphs (KGs) to mitigate this phenomenon is promising\cite{survey}. This is because knowledge graphs store a large amount of structured factual knowledge, which can provide large models with accurate knowledge dependencies. At the same time, correcting the knowledge in large models often requires fine-tuning their model parameters, which inevitably incurs high computational costs\cite{tog}. In contrast, updating knowledge graphs is relatively simple and incurs minimal overhead.


\begin{figure}[t]
  \centering
    \includegraphics[width=\linewidth]{figure/Intro.pdf}
  \caption{(a.) The LLMs-only approach suffers from severe hallucinations. (b.) The LLMs with KGs approach provides insufficient information, and their graph-based reasoning with KGs is often inaccurate. (c.) We first mine the internal knowledge of LLMs, offering more information for external KG reasoning and achieving better integration of internal and external knowledge in LLMs.}
  \label{fig:Insight}
\end{figure}
\begin{figure*}[t]
  \centering
    \includegraphics[width=0.98\linewidth]{figure/workflow.pdf}
  % \hspace{0.01\linewidth}
  \caption{The workflow of KnowPath. It contains: (a) Inference Paths Generation to exploit the internal knowledge of LLMs, (b)
  Subgraph Exploration to generate a trustworthy directed subgraph, (c) Evaluation-based Answering to integrate internal and external knowledge.}
  \label{fig:workflow}
\end{figure*}

The paradigms of combining LLMs with KGs can be classified into three main categories. The first one is knowledge injection during pre-training or fine-tuning\cite{rog,re-kbqa,unikgqa,givefact}. While the model's ability to grasp knowledge improves, these methods introduce high computational costs and catastrophic forgetting. 
The second one entails using LLMs as agents to reason through knowledge retrieved from the KGs. This approach does not require fine-tuning or retraining, significantly reducing overhead\cite{structgpt,rag1}. However, It heavily relies on the completeness of external KGs and underutilizes the internal knowledge of the LLMs.
The third one enables LLMs to participate in the process of knowledge exploration within external KGs\cite{tog2}. In this case, the LLMs can engage in the selection of knowledge nodes at each step\cite{tog,pog,gog}, thereby leveraging the advantages of the internal knowledge of the LLMs to some extent.



The effective patterns of LLMs introducing KGs still have limitations.
1) Insufficient exploration of internal knowledge in LLMs.
When exploring KGs, most approaches primarily treat LLMs as agents to select relevant relationships and entities, overlooking the potential of the internal knowledge.
2) Constrained generation of trustworthy reasoning paths. Some methods have attempted to generate highly interpretable reasoning paths, but they limit the scale of path exploration, require additional memory. The generated paths also lack intuitive visual interpretability.
3) Ambiguous fusion of internal and external knowledge. How to better integrate the internal knowledge of LLMs with the external knowledge in KGs still requires further exploration.


To overcome the above limitations, we propose KnowPath, a knowledge-enhanced large model framework driven by the collaboration of internal and external knowledge. 
Specifically, KnowPath consists of three stages.
1) Inference paths generation. To entirely exploit the internal knowledge of LLMs and adept in zero-shot scenario, this stage employs a prompt-driven approach to extract the knowledge triples most relevant to the topic entities, and then generates reasoning paths based on these knowledge triples to attempt answering the question. 
2) Trustworthy directed subgraph exploration. It refers to the process where the LLM combines the previously generated knowledge reasoning paths to select entities and relationships, and then responses based on the subgraph formed by these selections. This stage enables the LLMs to fully participate in the effective construction of external knowledge, while providing a clear process for constructing subgraphs.
3) Evaluation-based answering. At this stage, external knowledge primarily guides the KnowPath, while internal knowledge assists in generating the answer.
Our contributions can be summarized as follows:
\begin{itemize}
    \item We focus on a new view, emphasizing the importance of the LLMs' powerful internal knowledge in knowledge question answering, via a prompt-based internal knowledge reasoning path generation method for LLMs.
    \item We build a knowledge-enhanced large model framework driven by the collaboration of internal and external knowledge. It not only integrates both the internal and external knowledge of the LLMs better, but also provides clearer and more trustworthy reasoning paths.
    \item Extensive experiments conducted on multiple knowledge question answering datasets demonstrate that our KnowPath significantly mitigates the hallucination problem in LLMs and outperforms the existing best.
\end{itemize}




