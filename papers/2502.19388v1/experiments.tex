\section{Implementation and Case Studies}
\label{sec:case_studies}
%
%
We have automated our techniques using a modern deductive verifier for probabilistic programs. We first describe how to integrate our techniques within that verifier in \Cref{sec:case_studies:implementation}. We then describe our case studies, i.e., programs and specifications we have verified, in \Cref{sec:case_studies:case_studies}. Finally, we evaluate our approach empirically on these case studies in \Cref{sec:empirical_eval}.
%
%
\subsection{Implementation}
\label{sec:case_studies:implementation}
%
%
\toolcaesar\footnote{\url{https://www.caesarverifier.org/}} \cite{DBLP:journals/pacmpl/SchroerBKKM23} is a recent expectation-based automated deductive verifier targeting \emph{discrete} and possibly \emph{nondeterministic\footnote{Here we refer to pure nondeterminism which is to be resolved angelically or demonically.}} probabilistic programs. As input, \toolcaesar takes programs written in an intermediate verification language called $\heyVL$ --- a quantitative analogue of \toolboogie \cite{leinoThisBoogie2008}. $\heyVL$ provides a programmatic means to describe verification conditions such as the validity of quantitative loop invariants. These verification conditions are offloaded to an SMT solver, which enables the semi-automated verification of said discrete probabilistic programs. 
%
\toolcaesar does \emph{not} support continuous sampling instructions. We will, however, now demonstrate that with our approach based on Riemann sums, \toolcaesar \emph{can} readily be used to verify bounds on expected outcomes of continuous probabilistic programs in a semi-automated fashion.

Our key insight is that our Riemann expectation transformers can be expressed as expectation transformers denoted by \emph{discrete} probabilistic programs featuring angelic (resp.\ demonic) \emph{nondeterministic choices} for $\nonNegReals$-valued intervals. The latter features \emph{are} supported by \toolcaesar: $\heyVL$ supports the discrete fragment of $\pWhile$ and, amongst others, the two statements

%
\begin{enumerate}
	\item  $\NONDETASSIGN{\pVar}{\aExp_1}{\aExp_2}$, which, on program state $\pState$, assigns a nondeterministically chosen value from the $\nonNegReals$-valued interval $[\aExp_1(\pState), \aExp_2(\pState)]$ to the variable $\pVar$, and
	%
	\item $\DISCRETEUNIFASSIGN{\pVar}{\N}$, which, given a (constant) natural number $\N\geq 1$, samples a value from the  set $\{0,\ldots,\N-1\}$ uniformly at random and assigns the result to the variable $\pVar$.
\end{enumerate}
%
Notice that the latter statement is syntactic sugar for $\pWhile$ as it can be simulated by binary probabilistic choices. The statement $\NONDETASSIGN{\pVar}{\aExp_1}{\aExp_2}$, on the other hand, is not syntactic sugar as nondeterminism is not supported in $\pWhile$. 
%

Now, given a (discrete but possibly nondeterministic) program $\prog$, \toolcaesar employs a transformer $\vcTrans{\prog} \colon \exps \to \exps$, which is defined\footnote{We do not need to require $\ex$ to be measurable since $\prog$ is does not contain continuous sampling.
    Moreover, as is standard for deductive verifiers, loops need to be annotated with quantitative loop invariants; see \Cref{ex:caesar_loop} on page \pageref{ex:caesar_loop}.} as in \Cref{tab:original} and where for the additional statements, we have
%
\begin{align*}
	\vc{\NONDETASSIGN{\pVar}{\aExp_1}{\aExp_2}}{\ex}
	\eeq& \lam{\pState}{\sup_{\xi \in [\aExp_1(\pState), \aExp_2(\pState)]} \ex(\pStUpdate{\st}{\lvar}{\xi})} \\
	%
	%
	\vc{\DISCRETEUNIFASSIGN{\pVar}{\N}}{\ex} \eeq & \frac{1}{\N} \cdot \sum\limits_{i=0}^{\N-1} \exSubs{\ex}{\pVar}{i}~.
\end{align*}
%
Notice that $\vc{\NONDETASSIGN{\pVar}{\aExp_1}{\aExp_2}}{\ex}$ resolves the nondeterministic choice of $\pVar$ \emph{angelically} by returning the \emph{supremum} of all values obtained from evaluating $\ex$ at $\pState$ where $\pVar$ is set to some value from $[\aExp_1(\pState), \aExp_2(\pState)]$. The demonic counterpart is obtained from replacing $\sup$ by $\inf$.
Now let $\pVarj$ be a fresh program variable and observe that for all $\N \geq 1$ and all $\ex \in \exps$, we have
%
\[
	\underbrace{\uwp{\N}{\UNIFASSIGN{\pVar}}{\ex}}_{\text{defined in this paper}}
	\eeq
	\underbrace{\vc{\SEQ{\DISCRETEUNIFASSIGN{\pVarj}{\N}}{\NONDETASSIGN{\pVar}{\tfrac{\pVarj}{\N}}{\tfrac{\pVarj + 1}{\N}}}}{\ex}}_{\text{expressible in $\heyVL$ and thus supported by \toolcaesar}}~.
\]
%
Hence, the upper Riemann pre-expectation of $\UNIFASSIGN{\pVar}$ w.r.t.\ $\ex$ corresponds to the maximal --- under all possible resolutions of the nondeterminism --- expected final value of $\ex$ obtained from (i) sampling one of the $\N$ intervals occurring in the Riemann sums uniformly at random and (ii) assigning to $\pVar$ a nondeterministically chosen value from that sampled interval. \emph{Lower} Riemann pre-expectations can be expressed analogously by resolving the nondeterminism \emph{demonically}.
%
\begin{example}
	\label{ex:caesar_loop}
	%
	Reconsider the Monte Carlo $\pi$-approximator $\prog$ and the superinvariant $\exI$ of $\prog$ w.r.t.\ $\pVarcount$ from \Cref{ex:invariant_monte_carlo}. We can provide \toolcaesar with the following annotated loop:
	%
	\input{case_studies_programs/monte_carlo_pi_annotated}
	%
	We can then instruct \toolcaesar to check whether $\exI$ is a superinvariant of this loop w.r.t.\ $\pVarcount$. Since the loop body encodes appropriate upper Riemann pre-expectations, \toolcaesar offloads the quantitative entailments corresponding to \Cref{thm:verificationInvariants} to an SMT solver to check them automatically.
	For lower Riemann pre-expectations and subinvariants (for $\wlpSymb$), \toolcaesar can be used analogously.
	%
\end{example}


\subsection{Case Studies}
\label{sec:case_studies:case_studies}

In what follows, we describe the programs and specifications we have verified using \toolcaesar with the SMT solver \toolzt \cite{DBLP:conf/tacas/MouraB08} as back-end. All case studies (including \Cref{ex:caesar_loop}) have been verified within $12$ seconds on an Apple M2. The precise inputs to \toolcaesar are provided in\iftoggle{arxiv}{ \Cref{app:caesar_inputs}}{~\cite{arxiv}}. Both the verified bounds and the required parition sizes $\N$ where determined manually by guessing the respective weakest pre-expectations and increasing $\N$ until \toolcaesar reports success.


\subsubsection{The Irwin-Hall Distribution}
%
%
\begin{figure}[t]
    \small
	\begin{subfigure}[b]{0.4\textwidth}
		\input{case_studies_programs/irwin_hall_standard}
	\end{subfigure}
	%
	\begin{subfigure}[b]{0.58\textwidth}
		\input{case_studies_programs/irwin_hall_conditioning}
	\end{subfigure}
	%
	\caption{Generating the standard Irwin-Hall distribution (left) and a variant with conditioning (right).}
	\label{fig:irwin_hall}
\end{figure}
%
%
%
The Irwin-Hall distribution (parameterized in $\pVarm$) \cite{johnson1995continuous} is the sum of $\pVarm$ independent and identically distributed random variables, each of which is distributed uniformly over $[0,1]$. The loop $\prog$ depicted in \Cref{fig:irwin_hall} (left) models this family of distributions: On each iteration, $\prog$ samples a value for $\pVarb$ uniformly at random and adds the result to the variable $\pVar$. Hence, if initially $\pVari= 1$, $\pVar= 0$, and $\pVarm \in \nats$, then the final distribution of $\pVar$ indeed corresponds to the Irwin-Hall distribution with parameter $\pVarm$.

We now aim to upper-bound the expected final value of $\pVar$, i.e., the expectation of the Irwin-Hall distribution, for \emph{arbitrary} values of $\pVarm$. Towards this end, we employ our encoding from \Cref{sec:case_studies:implementation} and use \toolcaesar to automatically verify that the expectation 
%
$\exI =  \pVar + \iv{\pVari \leq \pVarm}\cdot \big(1.1 \cdot \tfrac{(\pVarm \monus \pVari) + 1}{2} \big) $
%
is a $\uwpSymb{10}$-superinvariant of $\prog$ w.r.t.\ $\pVar$. Hence, by \Cref{thm:invariant_cont}, we get $\wp{\prog}{\pVar} \eleq \exI$ and thus
%
\[
	\text{for initial $\pState$ with $\pState(\pVari) = 1$, $\pState(\pVar) = 0$, $\pState(\pVarm)\in \nats$ with $\pState(\pVarm) \geq 1$:}~
	\wp{\prog}{\pVar}(\pState) \leq  1.1\cdot \frac{\pState(\pVarm)}{2}~.
\]
%
%
Now consider a variant of the Irwin-Hall distribution where we condition each of the $\pVarm$ random variables to take a value in $[0,\nicefrac{1}{2}]$.
This situation is modeled by the loop $\prog$ depicted in \Cref{fig:irwin_hall} (right), where we employ conditioning inside of the loop. We aim to upper-bound $\cwp{\prog}{\pVar}$, i.e., the \emph{conditional expected final value of $\pVar$}.
For that, we use \toolcaesar to verify that the following expectation is a $\uwpSymb{19}$-superinvariant of $\prog$ w.r.t.\ $\pVarcount$ (resp.\ $\lwlpSymb{2}$-subinvariant of $\prog$ w.r.t.\ $1$):
%
\begin{align*}
	\exI \eeq  \pVar + \iv{\pVari \leq \pVarm}\cdot \big(1.5 \cdot \frac{(\pVarm \monus \pVari) + 1}{8} \big)  
	 %
	 \qquad \text{and}\qquad 
	 \exJ \eeq  \iv{\pVari \leq \pVarm} \cdot 0.5^{ (\pVarm \monus \pVari) +1 } + \iv{\pVari > \pVarm}\cdot 1~.
\end{align*}
%
Hence, we get by \Cref{thm:invariant_cont} that $\cwp{\prog}{\pVar}(\pState)$ is well-defined for all $\pState \in \pStates$ and
%
\[
    \text{for initial $\pState$ with $\pState(\pVari) = 1$, $\pState(\pVar) = 0$, $\pState(\pVarm)\in \nats$ with $\pState(\pVarm) \geq 1$:}~
    \cwp{\prog}{\pVar}(\pState) \leq  \frac{1.5\cdot\pState(\pVarm)}{8 \cdot 0.5^{\pState(\pVarm)}}~.
\]
%
Notice that, even though exponential functions like $0.5^\pVarm$ are not supported by our decidable language of syntactic expectations from \Cref{sec:syntax}, we can use \toolcaesar to reason about it by means of standard user-defined domain declaration for exponentials (see \cite[Section 5.1]{DBLP:journals/pacmpl/SchroerBKKM23} for details). Decidability of the corresponding entailments involving such domains is, however, not guaranteed.


\subsubsection{Reasoning about Diverging Programs}
%
%
\begin{figure}[t]
    \small
    \begin{subfigure}[t]{0.3\textwidth}
        \input{case_studies_programs/diverging}
    \end{subfigure}
    %
    %
    \begin{subfigure}[t]{0.53\textwidth}
        \input{case_studies_programs/tortoise_hare}
    \end{subfigure}
    %
    \caption{A probably diverging loop (left) and a race between tortoise and hare (right) \cite{DBLP:conf/sas/ChakarovS14}.}
    \label{fig:div_and_race}
\end{figure}
%
%
%
Weakest \emph{liberal} pre-expectations enable us to lower-bound divergence probabilities of programs involving continuous sampling. 
Consider the loop $\prog$ depicted in \Cref{fig:div_and_race} (left).
In each iteration, we sample uniformly from the interval $[\pVaraa, \pVarbb]$ (notice that $\pVaraa$, $\pVarbb$ are uninitialized variables and hence correspond to parameters) and assign the result to $\pVarb$.
Whenever we sample a value in $[0, \tfrac{\pVaraa + \pVarbb}{2}]$, the program diverges.
Using \toolcaesar, we verify that 
%
\[
    \exI \eeq \iv{\pVaraa \leq \pVarbb}\cdot (1 \monus 0.5^{\pVar})
\]
%
is a $\lwlpSymb{2}$-subinvariant of $\prog$ w.r.t.\ $0$. Hence, we have $\exI \eeleq \wlp{\prog}{0}$ by \Cref{thm:invariant_cont}, i.e., whenever $\pVaraa \leq \pVarbb$, then $\prog$ diverges on initial state $\pState$ with probability at least $1 - 0.5^{\pState(\pVar)}$.


\subsubsection{Race between Tortoise and Hare}
%
%
The loop $\prog$ depicted in \Cref{fig:div_and_race} (right) is adapted from \cite{DBLP:conf/sas/ChakarovS14} and models a race between a tortoise ($\pVart$) and a hare ($\pVarh$).
As long as the hare did not overtake the tortoise, the hare flips a fair coin to decide whether to move or not. If the hare decides to move, it samples a distance uniformly at random from $[0,10]$.
The tortoise always moves exactly one step.

We now upper-bound the expected final value of variable $\pVarcount$. Towards this end, we use \toolcaesar to verify that the expectation
%
$\exI = \pVarcount + \iv{\pVarh \leq \pVart} \cdot 3.012\cdot\big((\pVart \monus \pVarh) +2\big)$
%
is a $\uwpSymb{16}$-superinvariant of $\prog$ w.r.t.\ $\pVarcount$. Hence, we get $\wp{\prog}{\pVarcount} \eleq \exI$ by \Cref{thm:invariant_cont}, i.e., if $\prog$ is executed on an initial state $\pState$ with $\pState(\pVarcount) = 0$ and $\pState(\pVarh) \leq \pState(\pVart)$, then the expected final value of $\pVarcount$ is at most $3.012 \cdot (\pState(\pVart) - \pState(\pVarh) + 2)$.


\subsection{Experimental Evaluation}
\label{sec:empirical_eval}
%
%
\begin{table}
	\caption{Experimental results. Time in seconds. TO = \SI{180}{s}, MO = \SI{8}{GB}.}
	\label{tab:experiments}
	%
    \renewcommand{\arraystretch}{1.0}
	\begin{tabular}{l | c r@{\quad}@{\quad} r@{\quad}@{\quad} c r}%
		\toprule
		\colprog & \coln & \colt & \colformsize & \colpost & \colbound \\
		\midrule
		\input{oopsla_revision_experiments/timings.rows}\\
        \bottomrule
	\end{tabular}
\end{table}
%
%
In this section, we empirically evaluate the scalability of our approach based on the programs from the previous sections, i.e., our case studies and the Monte-Carlo approximator from \Cref{fig:intro}.
For each of these programs and post-expectations, we verify the tightest upper bound (up to a precision of $3$ decimal places) on the respective weakest pre-expectation for increasing values of $N$ (except for \progdiverging~where $N=2$ already yields the precise weakest pre-expectation).

Our empirical results are depicted in \Cref{tab:experiments}.
Column \colprog~depicts the respective program, \coln~denotes the partition size for the Riemann pre-expectation, \colt~denotes the verification time in seconds (i.e., verification condition generation and time for SMT solving) required by \toolcaesar, \colformsize~denotes the size of the formula offloaded to the SMT solver \toolzt (i.e., the number of nodes in the formula's abstract syntax tree), \colpost~denotes the post-expectation, and \colbound~depicts the upper (lower) bound on the (liberal) weakest pre-expectation. For the \progdiverging~benchmark, we lower-bound a liberal weakest pre-expectation.
All other benchmarks upper-bound a non-liberal weakest pre-expectation.
The bounds were inferred manually in a binary search-like fashion.

With our encoding of Riemann pre-expectations described in \Cref{sec:case_studies:implementation}, \toolcaesar allows verifying increasingly sharper bounds when increasing the partition size $N$
The size of the generated formula for the verification conditions mostly increases moderately when increasing $N$.
This is to be expected since the formula size grows polynomially in $N$ for a fixed program and a fixed post-expectation (see \Cref{sec:verify_loop_free}).
The time required for verification, however, can increase drastically when doubling the value of $N$ (see entries of \Cref{tab:experiments} where $N=32$).
