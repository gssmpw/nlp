@article{ahasanuzzaman2020studying,
  title={Studying ad library integration strategies of top free-to-download apps},
  author={Ahasanuzzaman, Md and Hassan, Safwat and Hassan, Ahmed E},
  journal={IEEE Transactions on Software Engineering},
  volume={48},
  number={1},
  pages={209--224},
  year={2020},
  publisher={IEEE}
}

@article{carreira2023revolutionizing,
  title={Revolutionizing Mobile Interaction: Enabling a 3 Billion Parameter GPT LLM on Mobile},
  author={Carreira, Samuel and Marques, Tom{\'a}s and Ribeiro, Jos{\'e} and Grilo, Carlos},
  journal={arXiv preprint arXiv:2310.01434},
  year={2023}
}

%\bibitem{b4}

@article{chen2023chatgpt,
  title={How is ChatGPT's behavior changing over time?},
  author={Chen, Lingjiao and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2307.09009},
  year={2023}
}
\bibitem{b21}

@inproceedings{erhan2010does,
  title={Why does unsupervised pre-training help deep learning?},
  author={Erhan, Dumitru and Courville, Aaron and Bengio, Yoshua and Vincent, Pascal},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={201--208},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}
%\bibitem{b10}

@inproceedings{fan2023large,
  title={Large language models for software engineering: Survey and open problems},
  author={Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M},
  booktitle={2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)},
  pages={31--53},
  year={2023},
  organization={IEEE}
}

@inproceedings{hendrycks2019using,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={International conference on machine learning},
  pages={2712--2721},
  year={2019},
  organization={PMLR}
}

%\bibitem{b9}

@article{jiang2020mnn,
  title={MNN: A universal and efficient inference engine},
  author={Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={2},
  pages={1--13},
  year={2020}
}
\bibitem{b15}

@article{kaddour2023challenges,
  title={Challenges and applications of large language models},
  author={Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  journal={arXiv preprint arXiv:2307.10169},
  year={2023}
}
%\bibitem{b12}

@misc{langchain,
    author= {{LangChain}},
    year  = {2024},
    title = {LangChain},
    note  = {\url{https://www.langchain.com/}, 
             Last accessed on 2024-11-05},
}
%\bibitem{b19}

@article{li2024transformer,
  title={Transformer-lite: High-efficiency deployment of large language models on mobile phone gpus},
  author={Li, Luchang and Qian, Sheng and Lu, Jie and Yuan, Lunxi and Wang, Rui and Xie, Qin},
  journal={arXiv preprint arXiv:2403.20041},
  year={2024}
}
\bibitem{b13}

@misc{llamacpp,
    author= {{ggerganov}},
    year  = {2024},
    title = {llama.cpp},
    note  = {\url{https://github.com/ggerganov/llama.cpp}, 
             Last accessed on 2024-11-05},
}
\bibitem{b17}

@article{meyer2023chatgpt,
  title={ChatGPT and large language models in academia: opportunities and challenges},
  author={Meyer, Jesse G and Urbanowicz, Ryan J and Martin, Patrick CN and Oâ€™Connor, Karen and Li, Ruowang and Peng, Pei-Chen and Bright, Tiffani J and Tatonetti, Nicholas and Won, Kyoung Jae and Gonzalez-Hernandez, Graciela and others},
  journal={BioData Mining},
  volume={16},
  number={1},
  pages={20},
  year={2023},
  publisher={Springer}
}

@article{minaee2024large,
  title={Large language models: A survey},
  author={Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024}
}

@misc{mlcllm,
    author= {{MLC-AI}},
    year  = {2024},
    title = {MLC-LLM},
    note  = {\url{https://github.com/mlc-ai/mlc-llm}, 
             Last accessed on 2024-11-05},
}
\bibitem{b18}

@inproceedings{nahar2023dataset,
  title={The Product Beyond the Model--An Empirical Study of Repositories of Open-Source ML Products},
  author={Nahar, Nadia and Zhang, Haoran and Lewis, Grace and Zhou, Shurui and K{\"a}stner, Christian},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE)},
  pages={63--75},
  year={2024},
  organization={IEEE Computer Society}
}

@article{naveed2023comprehensive,
  title={A comprehensive overview of large language models},
  author={Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
  journal={arXiv preprint arXiv:2307.06435},
  year={2023}
}

\bibitem{b3}

@misc{ncnn,
    author= {{Tencent}},
    year  = {2024},
    title = {ncnn},
    note  = {\url{https://github.com/Tencent/ncnn}, 
             Last accessed on 2024-11-05},
}
\bibitem{b16}

@article{paguthaniyaintegration,
  title={Integration Of Machine Learning Models Into Backend Systems: Challenges And Opportunities},
  author={Paguthaniya, Sajid Ali and Patel, Faruk Yusuf and Aminu, Emmanuel and Adeleye, Abdulbasit}
}

@article{palomba2019impact,
  title={On the impact of code smells on the energy consumption of mobile applications},
  author={Palomba, Fabio and Di Nucci, Dario and Panichella, Annibale and Zaidman, Andy and De Lucia, Andrea},
  journal={Information and Software Technology},
  volume={105},
  pages={43--55},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{polese2022adoption,
  title={Adoption of third-party libraries in mobile apps: a case study on open-source Android applications},
  author={Polese, Aidan and Hassan, Safwat and Tian, Yuan},
  booktitle={Proceedings of the 9th IEEE/ACM International Conference on Mobile Software Engineering and Systems},
  pages={125--135},
  year={2022}
}

%\bibitem{b8}

@article{salza2020third,
  title={Third-party libraries in mobile apps: When, how, and why developers update them},
  author={Salza, Pasquale and Palomba, Fabio and Di Nucci, Dario and De Lucia, Andrea and Ferrucci, Filomena},
  journal={Empirical Software Engineering},
  volume={25},
  pages={2341--2377},
  year={2020},
  publisher={Springer}
}

@article{sens2024large,
  title={A Large-Scale Study of Model Integration in ML-Enabled Software Systems},
  author={Sens, Yorick and Knopp, Henriette and Peldszus, Sven and Berger, Thorsten},
  journal={arXiv preprint arXiv:2408.06226},
  year={2024}
}
%\bibitem{b7}

@misc{tflite,
    author= {{Google AI}},
    year  = {2024},
    title = {LiteRT overview},
    note  = {\url{https://ai.google.dev/edge/litert}, 
             Last accessed on 2024-11-05},
}
%\bibitem{b14}

@inproceedings{topsakal2023creating,
  title={Creating large language model applications utilizing langchain: A primer on developing llm apps fast},
  author={Topsakal, Oguzhan and Akinci, Tahir Cetin},
  booktitle={International Conference on Applied Engineering and Natural Sciences},
  volume={1},
  number={1},
  pages={1050--1056},
  year={2023}
}
%\bibitem{b20}

@inproceedings{viennot2014measurement,
  title={A measurement study of google play},
  author={Viennot, Nicolas and Garcia, Edward and Nieh, Jason},
  booktitle={The 2014 ACM international conference on Measurement and modeling of computer systems},
  pages={221--233},
  year={2014}
}

@inproceedings{wang2017understanding,
  title={Understanding third-party libraries in mobile app analysis},
  author={Wang, Haoyu and Guo, Yao},
  booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C)},
  pages={515--516},
  year={2017},
  organization={IEEE}
}

@inproceedings{wang2020empirical,
  title={An empirical study of usages, updates and risks of third-party libraries in java projects},
  author={Wang, Ying and Chen, Bihuan and Huang, Kaifeng and Shi, Bowen and Xu, Congying and Peng, Xin and Wu, Yijian and Liu, Yang},
  booktitle={2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  pages={35--45},
  year={2020},
  organization={IEEE}
}

@article{yang2024if,
  title={If llm is the wizard, then code is the wand: A survey on how code empowers large language models to serve as intelligent agents},
  author={Yang, Ke and Liu, Jiateng and Wu, John and Yang, Chaoqi and Fung, Yi R and Li, Sha and Huang, Zixuan and Cao, Xu and Wang, Xingyao and Wang, Yiquan and others},
  journal={arXiv preprint arXiv:2401.00812},
  year={2024}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

