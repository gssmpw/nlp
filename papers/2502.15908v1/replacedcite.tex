\section{Related Work}
\label{related-work}

\subsection{Studies on ML-enabled Systems}
%\shurui{@Kimberly, cite the papers you mentioned in the introduction and more. The current section only has 2 papers, which is not a good sign.}

With the popularity of machine learning (ML) increasing over recent years, there has been an increasing number of products incorporating ML models into their products____. However, adding ML models to existing systems require additional infrastructure and consideration of system architecture____. As well, developers must consider system requirements and user concerns and experience, which poses challenges on how to best embed the ML model____. The most commonly named problems include data quality, meshing ML models with traditional software parts, tool support for managing ML products, and quality assurance____. Overall, we still know very little about how ML models are embedded and integrated into ML-enabled systems____. 

As a new subset of ML models, there is a similar mystery surrounding how LLM models are being integrated into LLM-enabled systems. Also, the findings from prior work focussing on general systems may not be directly applicable to mobile apps, as mobile apps are subject to more continuous, user-motivated, maintenance____, and different non-functional constraints (e.g. energy consumption)____. We aim to focus on a subset of LLM-enabled systems by presenting an empirical study on 149 LLM-enabled Android apps and the strategies used to integrate LLMs. 
%\shurui{@Kimberlt, Need a sentence to summarize the difference between mobile apps and other types and then say the findings from prior work focusing on software in general might not be directly apply to the mobild app scenario.}

%The qualities of LLMs exacerbate some of the common issues, such as quality assurance surrounding reusing pre-trained models. We aim to focus on a subset of LLM-enabled systems by presenting an empirical study on 149 LLM-enabled Android apps, and the strategies used to integrate LLMs. 



%Quality assurance is hard to establish as reusing pre-trained ML models has become common in developing ML-enabled systems, allowing for larger models trained on more data while reducing costs____, but does not fit with current software engineering practices____. Given that a defining characteristic of  LLMs is that they are pre-trained on large datasets, this presents a major problem for developers____. As the size of pre-training datasets are larger than can be manually verified, data collection relies on heuristics to ensure quality data____. This opens up the dataset to issues such as near-duplicates, benchmark data contamination, and personally identifiable information, all of which present issues to model performance, testing, and security____.


 

\subsection{On-Device LLM Deployment}

One method to integrate LLMs into a system is to deploy them on-device. Deploying LLMs on device is becoming a research hotspot as it increases the potential applications and eliminates the costs of cloud deployment, such as security and internet connection____. However, there are restrictions on  limited hardware performance, memory bandwidth, and storage capacity. LLMs have many parameters and have large memory requirements to store the model parameters, the model activations, and the gradients and corresponding statistics____.

%Currently, there are two methods for deploying LLMs on device____; the first method is using generic mobile inference engines such as TFLite____, MNN____, or NCNN____. A restriction with this method is that those engines are primarily optimised for static shape CV models, which are dissimilar to LLMs____. As a result, highly efficient LLM deployment based on device GPUs is usually not supported. 

To facilitate on-device deployment, LLM-specific inference engines have been developed, such as  Llama.cpp____, MLC-LLM____, or Langchain____. These engines are specifically designed for transformer-based LLM deployment on CPUs and GPUs. 
%For example, Langchain is an open-source framework that provides walkthroughs of common end-to-end use cases on the topics such as autonomous agents, chatbots, code understanding agents, extraction, question answering over documents, summarization, and analysing structured data____. 
%However, these engines complicate support for new model architectures due to requiring the re-descriptions of model structures via C++ or TVM script____.
In this study, we aim to investigate the use of these engines in implementing LLMs in mobile apps, and how they are incorporated into the rest of the system.

%As such, both methods for deploying LLMs on-device have issues and there is no one best method. In this study we aim to investigate the use and prevalence of these methods in implementing LLMs in mobile apps.


%\hl{How is this related to our study?}

\subsection{Third-Party Libraries in Mobile Apps}
A large number of companies develop software by way of Application Programming Interfaces (APIs), also known as third-party libraries, which allow the reuse of existing code components____. These libraries are widely used in mobile apps, accounting for, on average, over 60\% of Android app code as well as being used in almost every popular open-source Android app project____. When these companies issue updates to these libraries, app developers have the choice to adopt these implementations, but may be deterred due to the effort or effects of upgrading these libraries ____. %While the propagation of these updates have been investigated, particularly in web applications, it is still unclear how updates to third-party libraries are treated in mobile apps ____. 
Salza et al. conducted an empirical investigation into the when, why, and how mobile app developers update third-party libraries in code and found that only 15.52\% of library uses are constantly updated by developers, most of the updates are done with the aim of avoiding bug propagation or making an app compatible with the Android releases, and some app developers do not update libraries due to low payoff or to not break existing code____. We aim to investigate the particular usage of LLM-related APIs, and whether they are a large factor in-app updates and new releases.


%\subsection{LLM API Issues}

%While pre-training LLMs on massive sets of diverse data allows for great generalisation, developers looking to use LLMs in their product may want those LLMs to be able to address app-specific tasks. Therefore fine-tuning may be needed to adapt the LLM for downstream tasks. This can be achieved by either directly fine-tuning pre-trained models using a standard language modelling objective, or adding individual learnable layers to the output representations of a pre-trained language model____. However, LLMs have many parameters and have large memory requirements to store the model parameters, the model activations, and the gradients and corresponding statistics____. Thus, it is only feasible for those with large computational resources. Additionally, individual copies of fine-tuned LLMs need to be stored and loaded for individual tasks, resulting in large overhead____. These barriers to fine-tuning limit the specificity of LLMs towards app-specific tasks and may discourage developers from incorporating them into their product. 


%The general computational and memory demand of LLMs may restrict feasibility of incorporation to commercial LLMs via APIs. While APIs offer faster inference capabilities, they render the application susceptible to latency issues and the potential of security risks during transmission ____. As well, API use leaves app developers vulnerable to the whims of the LLM provider, who can make unannounced changes to the model, or depreciate or remove access to specific versions of the LLM, forcing updates to the app. It has been seen that commercial LLMs may have large differences in output and performance over time. For example, it was found that GPT-3.5 and GPT-4 performances on four diverse tasks varied vastly within three months____. GPT-4’s initial accuracy in identifying prime numbers was 97.6\%, but  dropped to 2.4\%, while for GPT-3.5, the trend is reversed. This unreliability may serve as a deterrent to developers against using LLMs in their products, or require them to implement additional infrastructure to accommodate these changes.


Considering the numerous factors contributing to the uncertainty and challenges associated with implementing LLMs—including the requisite architectures, infrastructures, and best practices—we aim to address key research gaps through an analysis of Android apps that have integrated LLMs. This study seeks to identify prevalent use cases, challenges, and integration strategies related to incorporating LLMs, as well as to characterize the features of such apps. By leveraging these findings and metrics, we endeavor to answer critical research questions regarding the implementation of LLMs in Android apps, ultimately offering insights to inform and facilitate the integration of LLMs in mobile apps.