% \vspace{-0.7em}
\section{Evaluation}


% \begin{table}[t] \small
% \caption{
% \label{table:benchmark}
% $|S^{all}|$ is total size of collected summaries. \texttt{Redu} is the number of redundant summaries that occur. 
% \texttt{Redu ratio} represents the percentage of \texttt{Redun} in relation to $|S^{all}|$.
% }
% \resizebox{\columnwidth}{!}{
% \begin{tabular}{ccccccc}
% \hline
% Category & ID & Program  & KLoC & $|S^{all}|$  & Redu   & Redu ratio \\ \hline
% \multirow{14}{*}{\begin{tabular}[c]{@{}c@{}}SPEC \\ 2017\end{tabular}} & 1                    & leela                & 21                   & 47245   & 12382   & 26\%  \\
%                                                                        & 2                    & nab                  & 24                   & 34584   & 5165    & 15\%  \\
%                                                                        & 3                    & x264                 & 96                   & 94165   & 24030   & 26\%  \\
%                                                                        & 4                    & wrf                  & 130                  & 51084   & 10183   & 20\%   \\
%                                                                        & 5                    & omnetpp              & 134                  & 405555  & 78088   & 19\%  \\
%                                                                        & 6                    & povray               & 170                  & 231450  & 45761   & 20\%   \\
%                                                                        & 7                    & cactusBSSN           & 257                  & 1058938 & 307732  & 29\%  \\
%                                                                        & 8                    & imagick              & 259                  & 381408  & 30321   & 8\%  \\
%                                                                        & 9                    & perlbench            & 362                  & 1420966 & 217823  & 15\%  \\
%                                                                        & 10                   & cam4                 & 407                  & 46667   & 10070   & 22\%  \\
%                                                                        & 11                   & parest               & 427                  & 3640557 & 658347  & 18\%  \\
%                                                                        & 12                   & xalanbmk             & 520                  & 1433309 & 294420  & 21\%  \\
%                                                                        & 13                   & gcc                  & 1,304                & 3536374 & 382315  & 11\%  \\
%                                                                        & 14                   & blender              & 1,577                & 3224282 & 605656  & 19\%  \\ \hline
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Open \\ Source\end{tabular}} & 15                   & libicu               & 537                  & 1131504 & 190370  & 17\%  \\
%                                                                        & 16                   & ffmpeg               & 1,346                & 2083049 & 393581  & 19\%  \\
%                                                                        & 17                   & mysqld               & 2,030                & 3830630 & 723576  & 19\%  \\ \hline
% Avg                                                                    & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{1}{l}{} & 1332457 & 234695 & 19\%  \\ \hline
% \end{tabular} 
% }
% \vspace{-1.0em}
% \end{table}





We have implemented the contribution identification (CI) algorithm in Algorithm~\ref{alg:main} to identify the path and condition contribution in the state-of-the-art value flow analysis tool Fusion~\cite{shi2021path} for detecting NPD in C/C++ code.
We denote Fusion with CI enabled as Light-Fusion, which serves as the performance-boosted client powered by our technique.
We investigate the following three questions:
\begin{itemize}
    \item (\textbf{RQ1}): How effective and efficient is CI in identifying the summary contribution?
    \item (\textbf{RQ2}): How much can CI boost the performance of existing value-flow analysis?
    \item (\textbf{RQ3}): Can CI enhance the path-sensitive analyzer's performance to be comparable with the top-down approach?
\end{itemize}

% Following the Fusion, Light-Fusion also uses the \textit{no-caching} strategy for the path conditions $\Phi$, which has shown its effectiveness in accelerating path-sensitive analysis, preventing redundant computations, and mitigating potential memory-intensive problems~\cite{shi2021path}.

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\textwidth]{figs/perf-light-fusion.pdf}
%     \caption{(a) illustrates the percentage of identified redundancy.
% (b) and (c) display the performance boost on benchmarks. The green bars represent the percentages of Light-Fusion's performance compared to that of Fusion's, with the exact percentages being annotated.
% The red bars indicate the percentages of performance that have been reduced. }
%     \label{fig:booting-result}
%     \vspace{-0.4cm}
% \end{figure*}


% \vspace{-0.5em}
\subsection{Experimental Setup}






\begin{table}[t]\small
\caption{
\label{table:benchmark}
$|S^{all}|$ is total size of collected summaries. 
\texttt{\#Redun} is the number of redundant summaries that occur, with the percentage relative to $|S^{all}|$ shown in parentheses.
\texttt{\#Identified} is the number of identified summaries by CI, with the percentage relative to \texttt{\#Redun} shown in parentheses.
\texttt{\#Src} and \texttt{\#Sink} represent the number of sources and sinks.
}
\resizebox{\columnwidth}{!}{
\begin{tabular}{r|lr|rrr|rr}
\hline
ID  & Program    & KLoC & $|S^{all}|$ & \multicolumn{1}{c}{\#Redun}   & \#Identified & \#Src                    & \#Sink \\ \hline
1   & leela      & 21   & 47.2K  & 12.4K(\textbf{26\%})  & 9.3K(\textbf{75\%})  & 15                        & 3.2K    \\
2   & nab        & 24   & 34.6K  & 5.2K(\textbf{15\%})   & 3.7K(\textbf{73\%})  & 88                        & 3.6K    \\
3   & x264       & 96   & 94.2K  & 24K(\textbf{26\%})    & 19K(\textbf{79\%})  & 58                        & 7.7K    \\
4   & wrf        & 130  & 51.1K  & 10.1K(\textbf{20\%})  & 8.4K(\textbf{83\%})  & 123                       & 4.3K    \\
5   & omnetpp    & 134  & 405.6K & 78.1K(\textbf{19\%})  & 66.1K(\textbf{85\%})  & 146                       & 27.5K   \\
6   & povray     & 170  & 231.5K & 45.8K(\textbf{20\%})  & 33.5K(\textbf{73\%})  & 24                        & 14.5K   \\
7   & cactus     & 257  & 1.1M   & 307.7K(\textbf{29\%}) & 257.5K(\textbf{84\%}) & 38                        & 49.8K   \\
8   & imagick    & 259  & 381.4K & 30.3K(\textbf{8\%})  & 22.5K(\textbf{74\%})   & 154                       & 12.2K   \\
9   & perlbmk    & 362  & 1.4M   & 217.8K(\textbf{15\%}) & 197.7K(\textbf{91\%}) & 232                       & 40.9K   \\
10  & cam4       & 407  & 46.7K  & 10.1K(\textbf{22\%})  & 7.2K(\textbf{72\%})  & 53                        & 3.4K    \\
11  & parest     & 427  & 3.6M   & 658.3K(\textbf{18\%}) & 555.9K(\textbf{84\%}) & 62                        & 215.7K  \\
12  & xalanbmk   & 520  & 1.4M   & 294.4K(\textbf{21\%}) & 258.9K(\textbf{88\%})  & 23                        & 77.7K   \\
13  & gcc        & 1304 & 3.5M   & 382.3K(\textbf{11\%}) & 287.4K(\textbf{75\%})  & 181                       & 146.2K  \\
14  & blender    & 1577 & 3.2M   & 605.7K(\textbf{19\%}) & 505.6K(\textbf{83\%})  & 127                       & 182.6K  \\ \hline
15  & libicu     & 537  & 1.1M   & 190.4K(\textbf{17\%}) & 165.8K(\textbf{87\%})  & 307                       & 76.7K   \\
16  & ffmpeg     & 1346 & 2.1M   & 393.6K(\textbf{19\%}) & 244.7K(\textbf{62\%})  & 491                       & 146.3K  \\
17  & mysqld     & 2030 & 3.8M   & 723.6K(\textbf{19\%}) & 519.2K(\textbf{72\%})  & 141                       & 215.4K  \\ \hline
avg &            &      & 1.3M   & 234.7K(\textbf{19\%}) & 186K(\textbf{79\%})  &                           &         \\ \hline
\end{tabular}

% \begin{tabular}{rlrrrrrr}
% \hline
% ID  & Program    & KLoC & $|S^{all}|$ & \#Redun   & Ratio & \#Src                    & \#Sink \\ \hline
% 1   & leela      & 21   & 47.2K  & 12.4K(26\%)  & 26\%  & 15                        & 3.2K    \\
% 2   & nab        & 24   & 34.6K  & 5.2K(15\%)   & 15\%  & 88                        & 3.6K    \\
% 3   & x264       & 96   & 94.2K  & 24K(26\%)    & 26\%  & 58                        & 7.7K    \\
% 4   & wrf        & 130  & 51.1K  & 10.1K(20\%)  & 20\%  & 123                       & 4.3K    \\
% 5   & omnetpp    & 134  & 405.6K & 78.1K(19\%)  & 19\%  & 146                       & 27.5K   \\
% 6   & povray     & 170  & 231.5K & 45.8K(20\%)  & 20\%  & 24                        & 14.5K   \\
% 7   & cactusBSSN & 257  & 1.1M   & 307.7K & 29\%  & 38                        & 49.8K   \\
% 8   & imagick    & 259  & 381.4K & 30.3K  & 8\%   & 154                       & 12.2K   \\
% 9   & perlbench  & 362  & 1.4M   & 217.8K & 15\%  & 232                       & 40.9K   \\
% 10  & cam4       & 407  & 46.7K  & 10.1K  & 22\%  & 53                        & 3.4K    \\
% 11  & parest     & 427  & 3.6M   & 658.3K & 18\%  & 62                        & 215.7K  \\
% 12  & xalanbmk   & 520  & 1.4M   & 294.4K & 21\%  & 23                        & 77.7K   \\
% 13  & gcc        & 1304 & 3.5M   & 382.3K & 11\%  & 181                       & 146.2K  \\
% 14  & blender    & 1577 & 3.2M   & 605.7K & 19\%  & 127                       & 182.6K  \\ \hline
% 15  & libicu     & 537  & 1.1M   & 190.4K & 17\%  & 307                       & 76.7K   \\
% 16  & ffmpeg     & 1346 & 2.1M   & 393.6K & 19\%  & 491                       & 146.3K  \\
% 17  & mysqld     & 2030 & 3.8M   & 723.6K & 19\%  & 141                       & 215.4K  \\ \hline
% Avg &            &      & 1.3M   & 234.7K & 19\%  &                           &         \\ \hline
% \end{tabular}
}
% \vspace{-1.0em}
\end{table}

\textbf{Baselines.}
Fusion collects the summaries in a parallel way, i.e., parallelizing functions located within the same level of the call graph, and uses the graph representation of summary conditions~\cite{shi2021path}.
First, we compare Light-Fusion with Fusion. 
We did not compare to~\cite{shi2020pipelining}\cite{tang2023Scaling} as their methodologies involve generating redundant summaries to enable parallelism, which contradicts the principles and objectives of our approach.
In addition, we have developed a variant of Light-Fusion~(denoted as CFL-Light-Fusion) that uses a more precise identification algorithm achieved through CFL reachability.
Specifically, we adopted the open-source implementation of the state-of-the-art CFL reachability algorithm~\cite{lei2022taming} provided by \cite{pocr} and replaced the \texttt{bfs} used in Algorithm~\ref{alg:main}.
Lastly, we compare the Light-Fusion to \textit{PhASAR}~\cite{10.1007/978-3-030-17465-1_22}, an open-sourced implementation of top-down approaches~\cite{reps1995precise, reps1994speeding, murphy1999program, sagiv1996precise}. 
To mitigate the impact of the execution environment, we ran experiments three times and calculated the average performance and performance gains.


\textbf{Subjects.}
We have included all the large programs from the SPEC CPU@2017 benchmark~\cite{bucek2018spec} that consist of more than 10 KLoC. 
Additionally, we have selected three large programs, namely \textit{libicu}, \textit{ffmpeg}, and \textit{mysqld}, which are widely-used software systems in their respective domains.

\textbf{Sources and Sinks.}
For checking NPD, 
NULL pointers are selected as sources.
% As the target program is in SSA form,
% NULL pointers that are not strongly updated~\cite{lhotak2011points} are selected as sources. 
% For example, in Figure~\ref{fig:motivation_ex} (a), the NULL value assigned to $e$ in Line 4 is strongly updated by the assignment in the function call to \textit{baz} in Line 6, and thus is not considered a source in our case.
The dereference operations are selected as sinks.
Table~\ref{table:benchmark} lists the evaluation subjects with statistics of sources and sinks. 

\textbf{Environment.}
All experiments were run on a server with eighty “Intel Xeon CPU E5-2698 v4@2.20GHz” processors and 512 GB of memory running Ubuntu-18.04.
Each program is analyzed with a limit of 12 hours and 256 GB of memory.
Fifteen threads are used to analyze the functions in the same layer when running both Fusion and Light-Fusion.
The solver used to verify constraints is \textit{Z3}\cite{de2008z3}.
%a mature theorem prover widely used in industry
% Following previous works~\cite{shi2018pinpoint, xie2005scalable, shi2021path}, each call of the solver is run with a limit of 10 seconds.

% In Fusion, the summary collection of functions that lie in the same layer of the call graph is parallelized by default.
% Fairly, we maintain this default parallelization setting, fifteen threads, when running both Fusion and Light Fusion.
% The number of nested levels of calling context is set to six~\cite{shi2018pinpoint}.



% \vspace{-0.5em}
\subsection{RQ1: Effectiveness and Efficiency}

To study the effectiveness of CI, we run two experiments for each benchmark.
In the first experiment, we execute Fusion to produce the results $S(V_{\text{src}}, V_{\text{sink}})$ and collect all potential summaries that could be generated during analysis, denoted as $S^{all}$.
Note that $S^{all}$ contains the non-contributing summaries, which is a superset of $S(V_{\text{src}}, V_{\text{sink}})$.  
The summary size of each benchmark is recorded in the $|S^{all}|$ column of Table ~\ref{table:benchmark}.
Second, we count non-contributing summaries from $S^{all}$ based on the definition of contributing summaries (Definition~\ref{def:contributing_summary}). 
The relative number of non-contributing summaries is reported in the ``\#Redun'' column of Table ~\ref{table:benchmark}.



\begin{table}[]\small
\caption{ 
The running time and memory usage of Fusion (F), Light-Fusion (L-F), and building of PDG are presented, along with CI's running time and performance gains (Gains).}
\label{table:compare}
\resizebox{\columnwidth}{!} {
\begin{tabular}{c|rrr|rrrr|r}
\hline
    & \multicolumn{3}{c|}{Memory(GB)} & \multicolumn{4}{c|}{Time(s)}                       &         \\
ID  & F         & \multicolumn{1}{c}{L-F}       & PDG     & F       & \multicolumn{1}{c}{L-F}     & PDG    & CI & Gains   \\ \hline
1   & 18.42     & 13.13(\textbf{29\%})     & 1.1     & 185     & 61(\textbf{67\%})      & 6      & 0.11                  & 1127.27 \\
2   & 5.67      & 4.77(\textbf{16\%})      & 0.9     & 380     & 315(\textbf{17\%})     & 5      & 0.08                  & 812.5   \\
3   & 2.12      & 0.94(\textbf{56\%})      & 1.1     & 362     & 290(\textbf{20\%})     & 23     & 0.23                  & 311.69  \\
4   & 3.1       & 2.98(\textbf{4\%})      & 0.9     & 231     & 126(\textbf{45\%})     & 6      & 0.13                  & 807.69  \\
5   & 3.52      & 2.63(\textbf{25\%})      & 3.6     & 627     & 187(\textbf{70\%})     & 39     & 1.11                  & 395.33  \\
6   & 44.78     & 13.23(\textbf{70\%})     & 2.2     & 2087    & 869(\textbf{58\%})     & 35     & 0.67                  & 1828.83 \\
7   & 17.17     & 12.95(\textbf{25\%})     & 8.8     & 1435    & 524(\textbf{63\%})     & 423    & 3.34                  & 272.67  \\
8   & 79.98     & 74.89(\textbf{6\%})     & 7.9     & 3795    & 3485(\textbf{8\%})    & 118    & 2.23                  & 139.14  \\
9   & 102.7     & 77.9(\textbf{24\%})      & 19.7    & 8075    & 5641(\textbf{30\%})    & 312    & 8.67                  & 280.9   \\
10  & 2.52      & 2.08(\textbf{17\%})      & 11      & 409     & 343(\textbf{16\%})     & 65     & 0.14                  & 471.43  \\
11  & 18        & 7.32(\textbf{59\%})      & 32.6    & 10281   & 3450(\textbf{66\%})    & 497    & 14.22                 & 480.48  \\
12  & 32.06     & 18.83(\textbf{41\%})     & 10.6    & 5172    & 1689(\textbf{67\%})    & 114    & 4.91                  & 709.95  \\
13  & 215.11    & 178.11(\textbf{17\%})    & 35.7    & 19484   & 16569(\textbf{15\%})   & 515    & 15.75                 & 185.07  \\
14  & 336.37     & 234.88(\textbf{30\%})     & 21.9    & 10848   & 4454(\textbf{59\%})    & 536    & 12.11                 & 527.91  \\ \hline
15  & 131.92     & 83.77(\textbf{36\%})     & 12.4    & 8261    & 3660(\textbf{56\%})    & 124    & 4.01                  & 1147.95 \\
16  & 144.93     & 97.82(\textbf{33\%})     & 22.7    & 11018   & 4710(\textbf{57\%})    & 348    & 8.1                   & 778.48  \\
17  & 393.99     & 269.69(\textbf{32\%})     & 36.3    & 16157   & 8050(\textbf{50\%})    & 471    & 17.31                 & 468.48  \\ \hline
avg & 91.31     & 66.65(\textbf{27\%})     & 13.5    & 5812.18 & 3201.35(\textbf{45\%}) & 213.94 & 5.48                  & 632.1   \\ \hline
\end{tabular}
}
% \vspace{-0.2cm}
% \vspace{-1.0em}
\end{table}

In the second experiment, we run Light-Fusion using the same configuration as Fusion to produce $S(V_{\text{src}}, V_{\text{sink}})$. 
Light-Fusion, however, incorporates an additional identification algorithm, CI, to filter out non-contributing summaries before the summary collection and cloning.
We count the number of identified non-contributing summaries and then compare it with the total number of non-contributing summaries in the first experiment to determine the identification ratio.
The findings are listed in the ``\#Identified'' column of Table~\ref{table:benchmark}.


Throughout both experiments, 
the PDG of each benchmark is pre-built once and persisted to disk.
Both Fusion and Light-Fusion read the same PDG as input when analyzing a benchmark.
We monitor the execution time, the memory consumption, and the analysis results, $S(V_{\text{src}}, V_{\text{sink}})$. 
The performance data for the two runnings and the building of PDG are listed in Table~\ref{table:compare}. 
% The time and memory comparison outcomes are presented in Table
In the second set, we specifically record the time consumed by CI, as the memory usage generally stays low, below 200 MB in 15 benchmarks, with the exceptions of \textit{blender} at 265 MB and \textit{mysqld} at 252 MB.
The running time of CI is listed in the ``CI'' column of Table~\ref{table:compare}.

\textbf{Soundness.}
We compare the analysis results $S(V_{\text{src}}, V_{\text{sink}})$ across both sets and the unsafe sinks reported by Fusion and Light-Fusion in Section~\ref{sec:rq3}. 
They remain the same, demonstrating the preservation of the precision of our approach.

\textbf{Effectiveness.}
While using normal graph reachability (\texttt{bfs}) to collect necessary vertices $V^{N}$, CI soundly approximates the summary contribution without considering context sensitivity. 
Thus, some redundant summaries could be incorrectly classified as contributing ones. 
Column ``\#Identified'' in Table~\ref{table:benchmark} lists the number of redundant summaries that can be identified and the percentage relative to redundant summaries that occur for each benchmark.
We observe that CI can precisely identify redundant summaries, reaching the high ratio from 62\% (in \textit{ffmpeg}) to 91\% (in \textit{perlbench}). 
On average, CI correctly identifies 79\% of redundant summaries.
One could reject the bogus $V^{N}$ by reaching context sensitivity.
However, handling context sensitivity may be more costly. 
We examine this aspect in Section~\ref{sec:rq2}. 
The high rate of identification achieved by CI in most projects shows that there is limited room for improvement with a context-sensitive identification algorithm.


\textbf{Efficiency.}
Table~\ref{table:compare} presents the running performance of Fusion, Light-Fusion, CI, and the performance gains when applying CI.
Light-Fusion, using our CI to prune redundant summaries, includes CI's running time in its performance metrics.
For all benchmarks, CI's running time for collecting $V^{N}$ remains below a minute.
% This low time consumption aligns well with the complexity analysis, indicating that the collection process involves several graph traversals.
Specifically, using CI significantly improves the running time and memory of Light-Fusion, as evidenced by the data in the ``Time'' and ``Memory'' columns of the table.
Without computing and maintaining the redundant summaries captured by CI, 
the average running time of Fusion is reduced from 5812.18 seconds to 3201.35 seconds, saving over 40 minutes (or 2,610.83 seconds).
Also, the average memory usage for Fusion drops from 44.26 GB to 33.88 GB.


\begin{table}[] \small
\caption{
\texttt{\#Solver} is the number of saved solver calls, which is equal to the number of identified redundant summaries (\texttt{\#Identified} column in Table~\ref{table:benchmark}).
The total (\texttt{T}) reduction in performance,
performance of calling the solver (\texttt{S}), with the percentage of each with respect to the total reduction in performance shown in parentheses.
}
\label{table:breakdown}
\centering

\resizebox{0.8\columnwidth}{!} {
% \begin{tabular}{c|rr|rrr}
% \hline
% ID  & \#Removed & \#Solver              & Total Time(s) & Solver Time(s) & Collection Time(s) \\ \hline
% 1   & 9308      & 9308   & 124                   & 110(\textbf{89\%})      & 14(11\%)           \\
% 2   & 3774      & \multicolumn{1}{r|}{3774}   & 65                    & 59(\textbf{91\%})       & 6(9\%)             \\
% 3   & 19000     & \multicolumn{1}{r|}{19000}  & 72                    & 66(\textbf{92\%})       & 6(8\%)             \\
% 4   & 8437      & \multicolumn{1}{r|}{8437}   & 105                   & 95(\textbf{90\%})       & 10(10\%)           \\
% 5   & 66160     & \multicolumn{1}{r|}{66160}  & 440                   & 403(\textbf{92\%})      & 37(8\%)            \\
% 6   & 33589     & \multicolumn{1}{r|}{33589}  & 1218                  & 1121(\textbf{92\%})     & 97(8\%)            \\
% 7   & 257480    & \multicolumn{1}{r|}{257480} & 911                   & 840(\textbf{92\%})      & 71(8\%)            \\
% 8   & 22482     & \multicolumn{1}{r|}{22482}  & 310                   & 280(\textbf{90\%})      & 30(10\%)           \\
% 9   & 197731    & \multicolumn{1}{r|}{197731} & 2434                  & 2222(\textbf{91\%})     & 212(9\%)           \\
% 10  & 7236      & \multicolumn{1}{r|}{7236}   & 66                    & 59(\textbf{89\%})       & 7(11\%)            \\
% 11  & 555963    & \multicolumn{1}{r|}{555963} & 6831                  & 6403(\textbf{94\%})     & 428(6\%)           \\
% 12  & 258872    & \multicolumn{1}{r|}{258872} & 3483                  & 3320(\textbf{95\%})     & 163(5\%)           \\
% 13  & 287394    & \multicolumn{1}{r|}{287394} & 2915                  & 2817(\textbf{97\%})     & 98(3\%)            \\
% 14  & 505645    & \multicolumn{1}{r|}{505645} & 6394                  & 6188(\textbf{97\%})     & 206(3\%)           \\ \hline
% 15  & 165757    & \multicolumn{1}{r|}{165757} & 4601                  & 4403(\textbf{96\%})     & 198(4\%)           \\
% 16  & 244650    & \multicolumn{1}{r|}{244650} & 6308                  & 6099(\textbf{97\%})     & 209(3\%)           \\
% 17  & 519224    & \multicolumn{1}{r|}{519224} & 8107                  & 7803(\textbf{96\%})     & 304(4\%)           \\ \hline
% avg & 268656    & \multicolumn{1}{r|}{268656} & 2610                  & 2487(\textbf{95\%})     & 123(5\%)           \\ \hline
% \end{tabular}}
% \begin{tabular}{crr|rrr|rrr}
% \hline
% \multicolumn{1}{l}{\multirow{2}{*}{ID}} & \multicolumn{1}{l}{\multirow{2}{*}{\#Removed}} & \multicolumn{1}{l|}{\multirow{2}{*}{\#Solver}} & \multicolumn{3}{c|}{Time(s)}             & \multicolumn{3}{c}{Memory(GB)} \\
% \multicolumn{1}{l}{}                    & \multicolumn{1}{l}{}                           & \multicolumn{1}{l|}{}                          & \multicolumn{1}{c}{T} & \multicolumn{1}{c}{S}              & \multicolumn{1}{c}{C} & \multicolumn{1}{c}{T}   & \multicolumn{1}{c}{S}  & \multicolumn{1}{c}{C} \\ \hline
% \multicolumn{1}{c|}{1}                  & 9.3K                                           & 9.3K                                           & 124   & 110(\textbf{89\%})  & 14(11\%)   & 5.29    & 1.3(\textbf{25\%})     & 3.99(75\%)       \\
% \multicolumn{1}{c|}{2}                  & 3.7K                                           & 3.7K                                           & 65    & 59(\textbf{91\%})   & 6(9\%)     & 0.9     & 0.1(\textbf{11\%})     & 0.8(89\%)        \\
% \multicolumn{1}{c|}{3}                  & 19.0K                                          & 19.0K                                          & 72    & 66(\textbf{92\%})   & 6(8\%)     & 1.18    & 0.26(\textbf{22\%})    & 0.92(78\%)       \\
% \multicolumn{1}{c|}{4}                  & 8.4K                                           & 8.4K                                           & 105   & 95(\textbf{90\%})   & 10(10\%)   & 0.12    & 0.01(\textbf{8\%})    & 0.11(92\%)       \\
% \multicolumn{1}{c|}{5}                  & 66.2K                                          & 66.2K                                          & 440   & 403(\textbf{92\%})  & 37(8\%)    & 0.89    & 0.18(\textbf{20\%})    & 0.71(80\%)       \\
% \multicolumn{1}{c|}{7}                  & 257.5K                                         & 257.5K                                         & 911   & 840(\textbf{92\%})  & 71(8\%)    & 4.22    & 1(\textbf{24\%})       & 3.22(76\%)       \\
% \multicolumn{1}{c|}{8}                  & 22.5K                                          & 22.5K                                          & 310   & 280(\textbf{90\%})  & 30(10\%)   & 5.09    & 1.4(\textbf{28\%})     & 3.69(72\%)       \\
% \multicolumn{1}{c|}{9}                  & 197.7K                                         & 197.7K                                         & 2434  & 2222(\textbf{91\%}) & 212(9\%)   & 24.8    & 5.6(\textbf{23\%})     & 19.2(77\%)       \\
% \multicolumn{1}{c|}{10}                 & 7.2K                                           & 7.2K                                           & 66    & 59(\textbf{89\%})   & 7(11\%)    & 0.44    & 0.1(\textbf{23\%})     & 0.34(77\%)       \\
% \multicolumn{1}{c|}{11}                 & 555.9K                                         & 555.9K                                         & 6831  & 6403(\textbf{94\%}) & 428(6\%)   & 10.68   & 3.3(\textbf{31\%})     & 7.38(69\%)       \\
% \multicolumn{1}{c|}{12}                 & 258.9K                                         & 258.9K                                         & 3483  & 3320(\textbf{95\%}) & 163(5\%)   & 13.23   & 4.3(\textbf{33\%})     & 8.93(67\%)       \\
% \multicolumn{1}{c|}{13}                 & 287.4K                                         & 287.4K                                         & 2915  & 2817(\textbf{97\%}) & 98(3\%)    & 37      & 8.9(\textbf{24\%})     & 28.1(76\%)       \\
% \multicolumn{1}{c|}{14}                 & 505.6K                                         & 505.6K                                         & 6394  & 6188(\textbf{97\%}) & 206(3\%)   & 101.49  & 37.1(\textbf{37\%})    & 64.39(63)      \\ \hline
% \multicolumn{1}{c|}{15}                 & 165.8K                                         & 165.8K                                         & 4601  & 4403(\textbf{96\%}) & 198(4\%)   & 48.15   & 12(\textbf{25\%})      & 36.15(75\%)      \\
% \multicolumn{1}{c|}{16}                 & 244.7K                                         & 244.7K                                         & 6308  & 6099(\textbf{97\%}) & 209(3\%)   & 47.11   & 8.8(\textbf{19\%})     & 38.31(81\%)      \\
% \multicolumn{1}{c|}{17}                 & 519.2K                                         & 519.2K                                         & 8107  & 7803(\textbf{96\%}) & 304(4\%)   & 124.3   & 26.8(\textbf{22\%})    & 97.5(78\%)       \\ \hline
% \multicolumn{1}{c|}{avg}                & 268.7K                                         & 268.7K                                         & 2610  & 2487(\textbf{95\%}) & 123(5\%)   & 24.7        &  6.66(\textbf{27\%})       &  18.0({73\%})          \\ \hline
% \end{tabular}
% \begin{tabular}{crr|rr|rr}
% \hline
% \multicolumn{1}{l}{\multirow{2}{*}{ID}} & \multicolumn{1}{l}{\multirow{2}{*}{\#Removed}} & \multicolumn{1}{l|}{\multirow{2}{*}{\#Solver}} & \multicolumn{2}{c|}{Time(s)}                   & \multicolumn{2}{c}{Memory(GB)}                \\
% \multicolumn{1}{l}{}                    & \multicolumn{1}{l}{}                           & \multicolumn{1}{l|}{}                          & \multicolumn{1}{c}{T} & \multicolumn{1}{c|}{S} & \multicolumn{1}{c}{T} & \multicolumn{1}{c}{S} \\ \hline
% \multicolumn{1}{c|}{1}                  & 9.3K                                           & 9.3K                                           & 124                   & 110(\textbf{89\%})     & 5.29                  & 1.3(\textbf{25\%})    \\
% \multicolumn{1}{c|}{2}                  & 3.7K                                           & 3.7K                                           & 65                    & 59(\textbf{91\%})      & 0.9                   & 0.1(\textbf{11\%})    \\
% \multicolumn{1}{c|}{3}                  & 19.0K                                          & 19.0K                                          & 72                    & 66(\textbf{92\%})      & 1.18                  & 0.26(\textbf{22\%})   \\
% \multicolumn{1}{c|}{4}                  & 8.4K                                           & 8.4K                                           & 105                   & 95(\textbf{90\%})      & 0.12                  & 0.01(\textbf{8\%})    \\
% \multicolumn{1}{c|}{5}                  & 66.2K                                          & 66.2K                                          & 440                   & 403(\textbf{92\%})     & 0.89                  & 0.18(\textbf{20\%})   \\
% \multicolumn{1}{c|}{7}                  & 257.5K                                         & 257.5K                                         & 911                   & 840(\textbf{92\%})     & 4.22                  & 1(\textbf{24\%})      \\
% \multicolumn{1}{c|}{8}                  & 22.5K                                          & 22.5K                                          & 310                   & 280(\textbf{90\%})     & 5.09                  & 1.4(\textbf{28\%})    \\
% \multicolumn{1}{c|}{9}                  & 197.7K                                         & 197.7K                                         & 2434                  & 2222(\textbf{91\%})    & 24.8                  & 5.6(\textbf{23\%})    \\
% \multicolumn{1}{c|}{10}                 & 7.2K                                           & 7.2K                                           & 66                    & 59(\textbf{89\%})      & 0.44                  & 0.1(\textbf{23\%})    \\
% \multicolumn{1}{c|}{11}                 & 555.9K                                         & 555.9K                                         & 6831                  & 6403(\textbf{94\%})    & 10.68                 & 3.3(\textbf{31\%})    \\
% \multicolumn{1}{c|}{12}                 & 258.9K                                         & 258.9K                                         & 3483                  & 3320(\textbf{95\%})    & 13.23                 & 4.3(\textbf{33\%})    \\
% \multicolumn{1}{c|}{13}                 & 287.4K                                         & 287.4K                                         & 2915                  & 2817(\textbf{97\%})    & 37                    & 8.9(\textbf{24\%})    \\
% \multicolumn{1}{c|}{14}                 & 505.6K                                         & 505.6K                                         & 6394                  & 6188(\textbf{97\%})    & 101.49                & 37.1(\textbf{37\%})   \\ \hline
% \multicolumn{1}{c|}{15}                 & 165.8K                                         & 165.8K                                         & 4601                  & 4403(\textbf{96\%})    & 48.15                 & 12(\textbf{25\%})     \\
% \multicolumn{1}{c|}{16}                 & 244.7K                                         & 244.7K                                         & 6308                  & 6099(\textbf{97\%})    & 47.11                 & 8.8(\textbf{19\%})    \\
% \multicolumn{1}{c|}{17}                 & 519.2K                                         & 519.2K                                         & 8107                  & 7803(\textbf{96\%})    & 124.3                 & 26.8(\textbf{22\%})   \\ \hline
% \multicolumn{1}{c|}{avg}                & 268.7K                                         & 268.7K                                         & 2610                  & 2487(\textbf{95\%})    & 24.7                  & 6.66(\textbf{27\%})   \\ \hline
% \end{tabular}

\begin{tabular}{cr|rr|rr}
\hline
\multicolumn{1}{l}{\multirow{2}{*}{ID}} & \multicolumn{1}{l|}{\multirow{2}{*}{\#Solver}} & \multicolumn{2}{c|}{Time(s)}                   & \multicolumn{2}{c}{Memory(GB)}                \\
\multicolumn{1}{l}{}                    & \multicolumn{1}{l|}{}                          & \multicolumn{1}{c}{T} & \multicolumn{1}{c|}{S} & \multicolumn{1}{c}{T} & \multicolumn{1}{c}{S} \\ \hline
\multicolumn{1}{c|}{1}                  & 9.3K                                           & 124                   & 110(\textbf{89\%})     & 5.29                  & 1.3(\textbf{25\%})    \\
\multicolumn{1}{c|}{2}                  & 3.7K                                           & 65                    & 59(\textbf{91\%})      & 0.9                   & 0.1(\textbf{11\%})    \\
\multicolumn{1}{c|}{3}                  & 19.0K                                          & 72                    & 66(\textbf{92\%})      & 1.18                  & 0.26(\textbf{22\%})   \\
\multicolumn{1}{c|}{4}                  & 8.4K                                           & 105                   & 95(\textbf{90\%})      & 0.12                  & 0.01(\textbf{8\%})    \\
\multicolumn{1}{c|}{5}                  & 66.2K                                          & 440                   & 403(\textbf{92\%})     & 0.89                  & 0.18(\textbf{20\%})   \\
\multicolumn{1}{c|}{7}                  & 257.5K                                         & 911                   & 840(\textbf{92\%})     & 4.22                  & 1(\textbf{24\%})      \\
\multicolumn{1}{c|}{8}                  & 22.5K                                          & 310                   & 280(\textbf{90\%})     & 5.09                  & 1.4(\textbf{28\%})    \\
\multicolumn{1}{c|}{9}                  & 197.7K                                         & 2434                  & 2222(\textbf{91\%})    & 24.8                  & 5.6(\textbf{23\%})    \\
\multicolumn{1}{c|}{10}                 & 7.2K                                           & 66                    & 59(\textbf{89\%})      & 0.44                  & 0.1(\textbf{23\%})    \\
\multicolumn{1}{c|}{11}                 & 555.9K                                         & 6831                  & 6403(\textbf{94\%})    & 10.68                 & 3.3(\textbf{31\%})    \\
\multicolumn{1}{c|}{12}                 & 258.9K                                         & 3483                  & 3320(\textbf{95\%})    & 13.23                 & 4.3(\textbf{33\%})    \\
\multicolumn{1}{c|}{13}                 & 287.4K                                         & 2915                  & 2817(\textbf{97\%})    & 37                    & 8.9(\textbf{24\%})    \\
\multicolumn{1}{c|}{14}                 & 505.6K                                         & 6394                  & 6188(\textbf{97\%})    & 101.49                & 37.1(\textbf{37\%})   \\ \hline
\multicolumn{1}{c|}{15}                 & 165.8K                                         & 4601                  & 4403(\textbf{96\%})    & 48.15                 & 12(\textbf{25\%})     \\
\multicolumn{1}{c|}{16}                 & 244.7K                                         & 6308                  & 6099(\textbf{97\%})    & 47.11                 & 8.8(\textbf{19\%})    \\
\multicolumn{1}{c|}{17}                 & 519.2K                                         & 8107                  & 7803(\textbf{96\%})    & 124.3                 & 26.8(\textbf{22\%})   \\ \hline
\multicolumn{1}{c|}{avg}                & 268.7K                                         & 2610                  & 2487(\textbf{95\%})    & 24.7                  & 6.66(\textbf{27\%})   \\ \hline
\end{tabular}

}
\vspace{-0.4cm}
\end{table}




\textbf{Breakdown.}
To investigate how much resource is spent collecting redundant summaries and how much resource is spent on calling the constraint solver to verify the conditions of redundant summaries, we break down the reduced performance in Table~\ref{table:compare}. 
This is obtained by computing the difference in running time and memory between Fusion and Light-Fusion, as shown in Table~\ref{table:compare}. 
Additionally, we present the number of solver calls avoided in Table~\ref{table:breakdown}.
Once the summary path is collected, the constraint solver is called; thus, the avoided calls of the constraint solver equal the number of redundant summaries identified, 
as shown in the data in the columns ``\#Identified'' in Table~\ref{table:benchmark} and ``\#Solver'' in Table~\ref{table:breakdown}.
For the total reduced running time, almost 90\% is spent on verifying the conditions of redundant summaries across the benchmarks. 
As the size of the program grows, the complexity of the summary conditions tends to increase as well. 
This results in longer summary paths and more time required to solve these conditions. 
Therefore, the proportion of time spent on the solver increases from 89\% to 97\%.
On the other hand, for the total reduced memory, almost 73\% is consumed by storing the collected summaries.


\textbf{Performance Gains.}
It is noted that the running time of CI does not hurt the performance of Light-Fusion. 
The ``Gains'' column in the table illustrates the performance gains achieved by using CI, which is the ratio of the time saved by Light-Fusion to the overhead incurred by CI. 
In the \textit{povray} (ID 6) case, CI achieves the highest performance gain of 1828.83 $\times$ by reducing 1218 seconds with only 0.67 seconds of overhead.
In the \textit{mysqld} (ID 17) case, CI reduces the most time, saving 8107 seconds (2.25 hours), which is nearly half of the original Fusion running time, with only 17.31 seconds of overhead.
On average, CI achieves a performance gain of 632.1$\times$.

% Therefore, \tool~ empowers state-of-the-art value-flow analyzers to trade minimal computational resources for significant performance gains, all without compromising precision or sacrificing path sensitivity like Top-down approaches~\cite{reps1995precise, reps1994speeding, arzt2014flowdroid}.
% Top-down approaches usually have better scalability. They only determine if a source-sink pair is reachable but typically fail to ascertain the conditions and path in which they are connected. 

% Thus, CI enables state-of-the-art value-flow analyzers to achieve substantial performance improvements by using minimal computational resources.
% Specifically, unlike top-down approaches~\cite{reps1995precise, reps1994speeding, arzt2014flowdroid}, Light-Fusion does not sacrifice path sensitivity. 
% Top-down approaches, although possibly more scalable, generally only determine the reachability of a source-sink pair without precisely identifying the conditions and exact path through which they are connected.
% In section~\ref{sec:rq3}, we would further compare the performance and analysis results of Light-Fusion with the top-down approaches.


% \vspace{-0.5em}
\subsection{RQ2: Performance Boosting}
\label{sec:rq2}




% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\textwidth]{figs/tm.pdf}
%     \caption{(a). The percentage of identified redundancy. (b) and (c) is the boosted performance on benchmarks.}
%     \label{fig:booting-result}
%     \vspace{-0.3cm}
% \end{figure*}


% \vspace{-0.2em}
\textbf{Fusion vs. Light-Fusion.}
% The performance comparison between Fusion and Light-Fusion is depicted in Fig.~\ref{fig:booting-result}(b) and Fig.~\ref{fig:booting-result}(c).
The performance comparison between Fusion and Light-Fusion is listed in Table~\ref{table:compare}.
The percentage numbers in parentheses represent the extra performance requirements of Fusion against Light-Fusion.
On average, both the time and memory could be reduced by 45\% and by 27\% by using CI.
The time reduction is more significant than the memory reduction since analyzers allocate considerable CPU resources to summary collection and solving path conditions, which can be NP-hard~\cite{fan2019smoke, cook2023complexity}. 
Thus, pruning redundant summaries can save significant time by conserving CPU resources.
The memory reduction percentages are constrained by the number of redundant summaries in the benchmarks, as indicated by the ``\#Redun'' column in Table~\ref{table:benchmark}, which shows an average redundancy ratio of 19\% closely corresponding to the average memory reduction percentages.




\textbf{Light-Fusion vs. CFL-Light-Fusion.}
To explore the impact of enhancing the CI precision, such as by using the CFL reachability~\cite{kodumal2004set, chaudhuri2008subcubic, yannakakis1990graph, melski2000interconvertibility} to reach context sensitivity and identify more redundant summaries compared to \textit{bfs}, we replaced \textit{bfs} in CI with the state-of-the-art CFL reachability algorithm~\cite{lei2022taming}. 
The modified algorithm was executed as the CFL-Light-Fusion instance compared with Fusion and Light-Fusion.
We monitored the running time on all three instances.

% Then, the modified algorithm was executed as the CFL-Light-Fusion instance alongside the two previous sets of benchmark programs.
% We monitored the running time across all three experiment sets.~\cai{fix this}.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figs/cfl.pdf}
    \caption{Light-Fusion vs. its variants}
    \label{fig:cfl-light-fusion}
    \vspace{-0.2cm}
\end{figure}


The results presented in Fig.~\ref{fig:cfl-light-fusion} demonstrated that CFL-Light-Fusion did not yield performance improvements; instead, it significantly slowed down the process, particularly as the program size increased. 
Notably, CFL-Light-Fusion failed to analyze benchmarks beyond \textit{cam4} (ID 10) within a six-hour timeframe. 
This decrease in performance can be attributed mainly to the cubic complexity of CFL-based approaches~\cite{kodumal2004set, chaudhuri2008subcubic, yannakakis1990graph, melski2000interconvertibility}, which introduce substantial overhead that outweighs the precision benefits. 
As a result, trading efficiency for precision becomes impractical. 
% Although some studies~\cite{lei2022taming, shi2022indexing} have proposed methods like ordering reachability computation and building additional reachability indexing to expedite CFL-reachability, they have not been able to overcome its inherent theoretical limitations.



% \vspace{-0.5em}
\subsection{RQ3: Comparing to Top-down Approaches}

\label{sec:rq3}


To evaluate the performance improvements of the path-sensitive analyzer compared to top-down approaches~\cite{reps1995precise, reps1994speeding, arzt2014flowdroid, murphy1999program, sagiv1996precise}, we conducted a comparative analysis between Light-Fusion and \textit{PhASAR}~\cite{10.1007/978-3-030-17465-1_22}. 
Using the latest release~\cite{phasar} of \textit{PhASAR} at the time of writing, we configured it to analyze the same source-sink pairs as Light-Fusion to ensure a fair comparison. 

\textbf{Performance.}
The results shown in Fig.~\ref{fig:td-comparsion} show the running time and memory usage of Fusion, Light-Fusion, and \textit{PhASAR}, which are represented by blue, green, and red bars, respectively. 
In general, both Fusion and Light-Fusion require more resources compared to \textit{PhASAR}, as indicated by the taller blue and green bars compared to the red bars. 
However, the green bars (representing Light-Fusion) are closer in height to the red bars (\textit{PhASAR}) than the blue bars (representing Fusion). 
In some benchmarks, the green bars are even lower than the red bars. 
For example, the running time of Light-Fusion for \textit{cactus} (ID 7) and \textit{xalanbmk} (ID 12), as well as the memory usage for \textit{x264} (ID 3), are lower than those of \textit{PhASAR}.

% The comparison results are displayed in Fig.~\ref{fig:td-comparsion}. The required running time and memory for Fusion, Light-Fusion, and \textit{PhASAR} are represented by blue, green, and red bars, respectively. 
% Generally, both Fusion and Light-Fusion need more resources than \textit{PhASAR}, as indicated by the blue and green bars being taller than the red ones. However, the green bars (Light-Fusion) are closer to the red ones (\textit{PhASAR}) than the blue ones (Fusion); they are even lower than the red bars in some of the benchmarks. For instance, Light-Fusion's running time for cactusBSSN (with ID 7) and xalanbmk (with ID 12) and the running memory for x264 (with ID 3) are lower than those of \textit{PhASAR}.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figs/td-comparsion.pdf}
    % \caption{Performance comparison: Fusion, Light-Fusion, and \textit{PhASAR}.}
    \caption{Performance: Fusion vs. Light-Fusion vs. \textit{PhASAR}.}
    \label{fig:td-comparsion}
    % \vspace{-0.4cm}
\end{figure}

Next, we quantify the amount of running time and memory among Fusion, Light-Fusion, and \textit{PhASAR}. 
% These magnification values are annotated atop the blue and green bars for each respective benchmark.
The results show that Fusion requires 3.35$\times$ the time and 9.75$\times$ the memory consumed by \textit{PhASAR} on average.
However, Light-Fusion can reduce the requirements to just 1.4$\times$ the time and 6.95$\times$ the memory.
Additionally, Light-Fusion has performance comparable with \textit{PhASAR} on benchmarks such as \textit{leea} (ID 1), x264 (ID 3), \textit{omnetpp} (ID 5), \textit{cactus} (ID 7), \textit{xalanbmk} (ID 12), and \textit{ffmpeg} (ID 16), requiring only an additional 0.5$\times$ of \textit{PhASAR}'s execution time. 
However, Fusion could only complete \textit{x264} (ID 3) within the same threshold.

% \begin{table}[] \small
% \caption{Classification of unsafe sinks (US) and safe sinks (S) reported by Fusion (F), Light-Fusion (LF), and Phasar (P).
% }
% \label{table:report}
% \resizebox{\columnwidth}{!} {
% \begin{tabular}{r|rrrl|llll}
% \hline
% ID & \multicolumn{1}{c}{\#Sinks} & \multicolumn{1}{c}{F-US} & LF-US & \multicolumn{1}{c|}{P-US} & \multicolumn{1}{c}{F-US$\wedge$P-US} & \multicolumn{1}{c}{F-S$\wedge$P-S} & \multicolumn{1}{c}{F-S$\wedge$P-US} & \multicolumn{1}{r}{F-US$\wedge$P-S} \\ \hline
% 1  & 3184                        & 2                        & 2     & 11                        & 2                                    & 3173                               & 9                                   & 0                                   \\
% 2  & 3581                        & 9                        & 9     & 86                        & 9                                    & 3,495                              & 77                                  & 0                                   \\
% 3  & 7657                        & 0                        & 0     & 5                         & 0                                    & 7652                               & 5                                   & 0                                   \\
% 4  & 4273                        & 1                        & 1     & 261                       & 1                                    & 4012                               & 261                                 & 1                                   \\
% 5  & 27489                       & 28                       & 28    & 207                       & 28                                   & 27282                              & 186                                 & 7                                   \\
% 6  & 14490                       & 31                       & 31    & 93                        & 31                                   & 14397                              & 69                                  & 7                                   \\
% 7  & 49769                       & 26                       & 26    & 378                       & 26                                   & 49391                              & 354                                 & 2                                   \\
% 8  & 12156                       & 12                       & 12    & 111                       & 12                                   & 12045                              & 101                                 & 2                                   \\
% 9  & 40888                       & 19                       & 19    & 669                       & 19                                   & 40219                              & 653                                 & 3                                   \\
% 10 & 3418                        & 8                        & 8     & 217                       & 8                                    & 3201                               & 213                                 & 4                                   \\
% 11 & 215747                      & 35                       & 35    & 103                       & 35                                   & 215644                             & 68                                  & 0                                   \\
% 12 & 77705                       & 28                       & 28    & 281                       & 28                                   & 77424                              & 257                                 & 4                                   \\
% 13 & 146208                      & 79                       & 79    & 3592                      & 79                                   & 142616                             & 3516                                & 3                                   \\
% 14 & 182621                      & 65                       & 65    & 3902                      & 65                                   & 178719                             & 3839                                & 2                                   \\ \hline
% 15 & 76727                       & 103                      & 103   & 2382                      & 103                                  & 74345                              & 2289                                & 10                                  \\
% 16 & 146284                      & 92                       & 92    & 1102                      & 92                                   & 145182                             & 1018                                & 8                                   \\
% 17 & 215431                      & 168                      & 168   & 2007                      & 168                                  & 213424                             & 1845                                & 6                                   \\ \hline
% \end{tabular}
% }
% \vspace{-0.4cm}
% \end{table}

\textbf{Analysis Results.}
We record the unsafe sinks reported by Fusion, Light-Fusion, and \textit{PhASAR} for each benchmark. 
A sink is considered unsafe if there is a feasible path from a source to the sink.
Note that top-down approaches, such as \textit{PhASAR}, usually sacrifice path sensitivity for better scalability. As a result, they may misclassify safe sinks as unsafe ones. 
% In Figure~\ref{fig:motivation_ex}, \textit{PhASAR} will report both the sink $printf(*a_9)$ led by summary $\pi_{5}$ and the sink $printf(*p_{13})$ led by summary $\pi_{4}$ as unsafe. However, the latter is actually safe because its summary condition is infeasible, which Light-Fusion correctly identifies.


First, the results show that the unsafe sinks reported by Light-Fusion are the same as those reported by Fusion, demonstrating our approach's precision-preserving nature. 
Next, we examine the unsafe sinks reported by Light-Fusion and \textit{PhASAR}. 
Light-Fusion identifies 90\% of the sinks, which are reported as unsafe by \textit{PhASAR}, as actually being safe, indicating a high false-positive rate for \textit{PhASAR}. 

Additionally, nearly 92\% of unsafe sinks identified by Light-Fusion are also identified by \textit{PhASAR}. 
However, \textit{PhASAR} fails to report some unsafe sinks identified by Light-Fusion due to not modeling the value flow of library functions after manual verification.
% We provide the complete comparison data in a longer version of this paper\cite{toappear}.
We provide the complete comparison data in Appendix Section~\ref{app:comparison}.

In conclusion, our method incorporates path-sensitive analyses without compromising precision and still achieves good performance. 
This aligns with common industrial requirements~\cite{bessey2010few, mcpeak2013scalable} of maintaining both high performance and low false positive rates.

% \section{Discussion}
% This section discusses the usability and potential threats to validity.

% \textbf{Problem Scope.}
% \tool~ is specifically designed to improve value flow analysis, which serves as a foundation for various applications and clients.
% Specifically, it could be applied to many value flow analysis scenarios by selecting appropriate sources and sinks.
% However, our technique cannot be directly applied to other domains without involving value flow, such as type-state analysis, lockset analysis, and may-happen-in-parallel analysis.
% However, in the spirit, \tool~ focuses on performing the computations on the partial program (against the whole functions and their summaries) related to the analysis scope, i.e., bug finding in our paper.
% We believe that the idea of making the analysis more targeted can be applied to other domains. 
% For instance, type-state analyses that focus on the progression of type states following a specific sequence of operations provide a different modeling perspective diverging from the value flow paradigm. 
% One can make type-state analysis more targeted by selecting only the necessary statements or functions involved in the targeting states.

% \textbf{Threats to Validity.}
% We discuss two main limitations in our approach.
% First, \tool~ cannot identify all non-contributing summaries. 
% While our tool effectively identifies 79\% of redundancies across various benchmarks, approximately 21\% of redundancies remain unidentified, indicating potential for further enhancement. 
% However, identifying more redundancies would require more computationally intensive methods, which could hurt overall performance as illustrated in Fig.~\ref{fig:cfl-light-fusion}.
% Second, the choice of checkers and subjects for evaluation poses a potential threat to the validity of our work. 
% Currently, we have focused on evaluating \tool\ using the NPD checker, as the checker is representative and has been derived from prior works~\cite{shi2020pipelining, tang2023Scaling, shi2018pinpoint}.
% The overall performance and potential speed-up may differ when using different checkers. 
% However, our approach, as described, is applicable to any source-sink problem, regardless of the specific selection of nodes as sources and sinks.
% The subjects chosen for evaluation consist of representative real-world programs sourced from the SPEC CPU@2017 benchmark~\cite{bucek2018spec} and open-source repositories. Nevertheless, we acknowledge that the performance may vary when analyzing different subjects.
