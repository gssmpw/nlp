\documentclass{article}

\usepackage{algorithm} 
\usepackage{algorithmic}  
\usepackage[algo2e]{algorithm2e} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[font=small,skip=0pt]{caption} 
\setlength{\textfloatsep}{5pt}
\setlength{\floatsep}{5pt}     
\setlength{\intextsep}{5pt}  

\everymath{\displaystyle\small} % Change font size of equations
\everydisplay{\small}   
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{listings}
\usepackage{mdframed}
%\usepackage{minted}
\usepackage{xcolor}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  keepspaces=true,
  escapeinside={(*@}{@*)}
}
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numberstyle=\scriptsize,
    stepnumber=1,
    showstringspaces=false,
    breaklines=true,
    numbers=none,
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

\theoremstyle{plain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
%\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{lipsum}
\usepackage{mwe}
\usepackage{lipsum} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xurl} % Fixes bib line overflow

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2021} with \usepackage[nohyperref]{icml2021} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
%\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage[accepted]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2021}

% The \icmltitle you define below is probably too long as a header.
\icmltitlerunning{Adaptive Semantic Prompt Caching with \textit{VectorQ}}

\begin{document}

\twocolumn[
\icmltitle{Adaptive Semantic Prompt Caching with \textit{VectorQ}}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2021
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Luis Gaspar Schroeder}{ucb,tum}
\icmlauthor{Shu Liu}{ucb}
\icmlauthor{Alejandro Cuadron}{ucb,eth}
\icmlauthor{Mark Zhao}{stf}
\icmlauthor{Stephan Krusche}{tum}
\icmlauthor{Alfons Kemper}{tum}
\icmlauthor{Matei Zaharia}{ucb}
\icmlauthor{Joseph E. Gonzalez}{ucb}
\end{icmlauthorlist}

\icmlaffiliation{tum}{Technical University of Munich}
\icmlaffiliation{ucb}{University of California, Berkeley}
\icmlaffiliation{eth}{ETH Zurich}
\icmlaffiliation{stf}{Stanford University}

\icmlcorrespondingauthor{Luis Gaspar Schroeder}{luisgasparschroeder[at]berkeley.edu}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Semantic prompt caches reduce the latency and cost of large language model (LLM) inference by reusing cached LLM-generated responses for semantically similar prompts. Vector similarity metrics assign a numerical score to quantify the similarity between an embedded prompt and its nearest neighbor in the cache. Existing systems rely on a static threshold to classify whether the similarity score is sufficiently high to result in a cache hit. We show that this one-size-fits-all threshold is insufficient across different embeddings. We propose \textit{VectorQ}, an online framework with a threshold convergence guarantee to learn embedding-specific threshold regions that adapt to the uncertainty of an embedding. Through evaluations on a combination of three diverse datasets, we show that \textit{VectorQ} consistently outperforms state-of-the-art systems across all static thresholds, achieving up to 26Ã— increases in cache hit rate and error rate reductions up to 74\%.
\end{abstract}

\input{chapters/1_introduction}
\input{chapters/2_related_work}
\input{chapters/3_methodology}
\input{chapters/4_experiments}
\input{chapters/5_conclusion}

\section*{Impact Statement}
This paper presents work whose goal is to advance the field of Machine Learning. By reducing the computational cost and latency of inference systems, our approach makes LLM-based technologies more accessible to a broader audience, lowering the barrier to entry for organizations and individuals who may otherwise lack the resources for large-scale LLM usage. 
Furthermore, by reducing the need to invoke the full LLM generation process, this work reduces the demand for compute associated with LLMs and as a consequence the potential broader carbon footprint associated with building and running additional AI data-centers.  

\bibliography{main}
\bibliographystyle{icml2025}
\input{chapters/appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DO NOT PLACE CONTENT AFTER THE REFERENCES!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

