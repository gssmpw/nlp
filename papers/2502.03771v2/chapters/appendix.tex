\appendix
\onecolumn

% <+=================================+>
% <+=================================+>

\section{Semantic Prompt Cache Architecture}
\label{app:semantic-prompt-cache-architecture}
The semantic prompt cache architecture in Figure \ref{fig:vectorq-architecture} integrates \textit{VectorQ} to optimize cache hit or cache miss decisions.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth]{images/SemanticPromptCacheArchitecture.pdf}
    \caption{Semantic prompt cache architecture where \textit{VectorQ} replaces the static similarity threshold.}
    
    \label{fig:vectorq-architecture}
\end{figure}

Upon receiving a request, the system transforms it into a vector embedding, which the similar answer extractor uses to query the vector database for the nearest neighbor—representing the most semantically similar previously processed prompt. Users can select metrics such as cosine similarity, Euclidean distance, or other available similarity measures to compute this similarity. \textit{VectorQ} evaluates the retrieved neighbor using its dynamic threshold mechanism, which adapts based on embedding-specific threshold regions. If the similarity surpasses the threshold, the cached response linked to the neighbor is reused; otherwise, the request is forwarded to the inference server to generate a new response.

% <+=================================+>
% <+=================================+>
\section{Datasets and Prompt Construction}
\label{app:datasets}
Semantic prompt caching requires the dataset to consist of clusters where the entries in each cluster map to the same LLM response. Otherwise, if all entries in a dataset have distinct responses, it is impossible to reuse them. We identified three task categories that satisfy this requirement.

\textbf{1) Classification.} Classification tasks often involve mapping a variable amount of input data to a finite set of categories. For this experiment, we use the E-Commerce Text Classification dataset \cite{saurabh-2023}, which assigns product descriptions to one of four categories: Books, Electronics, Household, and Clothing \& Accessories. To ensure a balanced representation, we shuffle the dataset to distribute all categories evenly. The prompt for classification is structured as follows:

\begin{lstlisting}[language=json]
{
   "prompt": "Which category does the text belong to?",
   "output_format": "Answer with 'Books', 'Electronics', 'Household', or 'Clothing & Accessories' only",
   "sentence": "{row}"
}
\end{lstlisting}

Response distribution in the Ecommerce Dataset:
\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
Response & Count \\
\midrule
Books & 6,000 \\
Clothing & 6,000 \\
Electronics & 6,000 \\
Household & 2,000 \\
\bottomrule
\end{tabular}
\caption{Response distribution in the Ecommerce Dataset, generated using the Llama-3.1-70B model. All entries are randomly shuffled.}
\end{table}

Additionally, we use the CommonsenseQA \cite{talmor2018commonsenseqa} dataset, which assigns questions to question categories. To ensure a balanced representation, we shuffle the dataset to distribute all categories evenly. The prompt for CommonsenseQA is structured as follows:

\begin{lstlisting}[language=json]
{
   "prompt": "What is the main subject of the following question?",
   "output_format": "Answer with only one of the words of this set: ['people', 'potato', 'competing', , 'snake', 'lizard', 'food', 'car', 'water', 'student', 'crab', 'children', 'killing', 'animals', 'ficus', 'horse', 'fox', 'cat', 'weasel', 'shark', 'person', 'human']",
   "sentence": "{row}"
}
\end{lstlisting}

Response distribution in the Commonsense QA Dataset:
\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
Response & Count \\
\midrule
person & 2,806 \\
people & 625 \\
human & 400 \\
competing & 272 \\
animals & 225 \\
food & 202 \\
car & 125 \\
water & 100 \\
student & 79 \\
children & 32 \\
killing & 27 \\
horse & 24 \\
potato & 13 \\
lizard & 13 \\
fox & 11 \\
ficus & 10 \\
cat & 10 \\
weasel & 8 \\
shark & 8 \\
crab & 7 \\
snake & 3 \\
\bottomrule
\end{tabular}
\caption{Response distribution in the Commonsense QA Dataset, generated using the Llama-3.1-70B model. All entries are randomly shuffled.}
\end{table}

\textbf{2) Sentiment.} Sentiment classification maps a variable amount of input data to a finite set of possible sentiments. While NLP-based methods, such as those proposed by \cite{dang2020sentiment}, outperform LLM-based sentiment analysis in terms of latency, this remains a relevant scenario, as sentiment analysis is used in semantic prompt caches within Retrieval-Augmented Generation (RAG) systems \cite{zhang2023enhancing}. For this experiment, we use the Amazon Instant Video Review dataset \cite{ni2019justifying} and prompt the question: "Is this review friendly?". To ensure unbiased results, we shuffle the dataset to create an even distribution of friendly and unfriendly reviews. The sentiment prompt is structured as follows:

\begin{lstlisting}[language=json]
{
   "prompt": "Is this review friendly?",
   "output_format": "Answer with 'yes' or 'no' only",
   "sentence": "{row}"
}
\end{lstlisting}

Response distribution in the Amazon Instant Video Dataset:
\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
Response & Count \\
\midrule
yes & 10,000 \\
no & 10,000 \\
\bottomrule
\end{tabular}
\caption{Response distribution in the Amazon Instant Video Dataset}
\end{table}


% <+=================================+>
% <+=================================+>
\section{Semantic Prompt Caching Benchmark}
\label{app:semantic-prompt-cache-benchmark}
Semantic prompt caching aims to enhance the efficiency of large language model (LLM) inference by reusing responses for semantically similar prompts. We construct a comprehensive semantic prompt caching benchmark using datasets across sentiment analysis and classification queries. Each entry in the benchmark is designed to test the ability of caching systems to distinguish between reusable and non-reusable responses. An example entry from the benchmark is shown below:

The benchmark integrates 20,000 rows from the E-Commerce dataset \cite{saurabh-2023}, 5,000 rows from the CommonsenseQA dataset \cite{talmor2018commonsenseqa}, and 20,000 rows from the Amazon Instant Video Review dataset \cite{ni2019justifying}. Each dataset is balanced to ensure fairness and unbiased evaluation, with an equal occurrence of distinct responses. Additionally, the datasets are shuffled to simulate alternating context changes.

Response distribution in the Semantic Prompt Cache Benchmark:
\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
Response & Count \\
\midrule
no & 10,000 \\
yes & 10,000 \\
Books & 6,000 \\
Electronics & 6,000 \\
Clothing & 6,000 \\
person & 2,806 \\
Household & 2,000 \\
people & 625 \\
human & 400 \\
competing & 272 \\
animals & 225 \\
food & 202 \\
car & 125 \\
water & 100 \\
student & 79 \\
children & 32 \\
killing & 27 \\
horse & 24 \\
lizard & 13 \\
potato & 13 \\
fox & 11 \\
cat & 10 \\
ficus & 10 \\
weasel & 8 \\
shark & 8 \\
crab & 7 \\
snake & 3 \\
\bottomrule
\end{tabular}
\caption{Response distribution in the Semantic Prompt Cache Benchmark, generated using the Llama-3.1-70B model. Semantic Prompt Cache Benchmark contains 45,000 responses, combining entries from the Commonsense QA, E-commerce, and Amazon Instant Video datasets, with all entries randomly shuffled.}
\end{table}

% <+=================================+>
% <+=================================+>

\section{Benchmarking Results}
\label{app:benchmarking-results}
We evaluate VectorQ's dynamic, embedding-specific thresholds against a semantic prompt cache with a static threshold across three datasets (Section \ref{experiments}). To ensure generalizability and real-world applicability, we test both a smaller embedding model (Alibaba-NLP/gte-large-en-v1.5, dimension 1024) and a larger model (intfloat/e5-mistral-7b-instruct, dimension 4096), combined with two large language models (Meta-Llama-3.1-8B-Instruct and Meta-Llama-3.1-70B-Instruct). We host an E2 VM on Google Cloud Platform with e2-standard-4 CPU (4 vCPU, 2 core, 16 GB memory). We use the vLLM inference engine configured for 0.8 GPU memory utilization, running on NVIDIA A100-SXM4-80GB GPUs—one GPU for Llama-3.1-8B and three GPUs for Llama-3.1-70B.

Each blue dot in a plot represents a static threshold evaluation, using values from the set {0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96}. Red triangle triangles in plots correspond to evaluations of VectorQ with different uncertainty gate settings, specifically {0.1, 0.2, 0.4, 0.6, 0.8, 1.0}. We exclude the uncertainty gate value of 0.0, as it disables all cache hits. We compute confidence intervals for VectorQ by evaluating each uncertainty gate configuration three times.

\subsection{Dataset: Semantic Prompt Cache Benchmark}
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Duration vs. Error Rate. 45,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Cache Hit Rate vs. Error Rate. 45,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Precision vs. Recall. 45,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dataset: Amazon Product Review}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Duration vs. Error Rate. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Cache Hit Rate vs. Error Rate. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/amazon_instant_video/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Precision vs. Recall. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dataset: E-Commerce}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Duration vs. Error Rate. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Cache Hit Rate vs. Error Rate. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_precision_vs_recall.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Precision vs. Recall. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:threepdfs}
\end{figure}

% <+=================================+>
% <+=================================+>

\section{Ablation Study: Correctness Sampling}
This study investigates the necessity of correctness sampling in comparison to a simpler uniform sampling approach. The sampling leverages correctness posteriors to prioritize re-evaluations of cache hits with higher uncertainty and their corresponding similarity value location in Region 3, allowing localized certainty regions to guide adaptive reuse decisions. In contrast, uniform sampling treats all similarity values in Region 3 equally, ignoring threshold-specific uncertainty. While correctness sampling may seem excessive, this ablation study demonstrates its important role in enabling reliable and adaptive threshold re-evaluations.

\begin{figure*}[h]
    \centering
    % First row
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{images/error_vs_hitrate_benchmark1_ablation.pdf}
        \caption{Amazon Product Review Dataset}
        \label{fig:vectorq-vs-static-ablation-1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{images/error_vs_hitrate_benchmark3_ablation.pdf}
        \caption{E-Commerce Dataset}
        \label{fig:vectorq-vs-static-ablation-2}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.33\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{images/error_vs_hitrate_benchmark5_ablation.pdf}
        \caption{Semantic Prompt Cache Benchmark}
        \label{fig:vectorq-vs-static-ablation-3}
    \end{subfigure}

    \caption{Performance comparison of \textit{VectorQ} with correctness sampling, \textit{VectorQ} with uniform sampling, and static-threshold approaches across two datasets and the Semantic Prompt Caching benchmark. Figures (a), (b), and (c) plot the error rates against cache hit rates, demonstrating that \textit{VectorQ} is more robust across diverse datasets, reliably handling varying prompts from different contexts. Uniform sampling exhibits inconsistent behavior, sometimes outperforming the static threshold or correctness sampling approach and other times underperforming both. These results emphasize the advantages of correctness sampling for reliable semantic prompt caching.}
    \label{fig:vectorq-vs-static-ablation-all}
\end{figure*}

As shown in Figure \ref{fig:vectorq-vs-static-ablation-all}, correctness sampling exhibits greater robustness across datasets, achieving lower error rates or higher cache hit rates compared to both uniform sampling and static thresholds. Uniform sampling, while occasionally matching or slightly outperforming the static threshold approach, exhibits inconsistent performance. These results emphasize the importance of incorporating localized threshold certainty measures, as enabled by the correctness posterior. 

