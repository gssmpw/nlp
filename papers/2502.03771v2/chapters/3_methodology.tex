% <+=================================+>
% <+=================================+>

\newcommand{\alex}[1]{{\color{brown}{\bf\sf [alex: #1]}}}

\section{Problem Setup}
The cache maintains a vector database $\mathcal{D}$ containing a set of embedded prompts and their metadata \[
\mathcal{D} = \{(p_i, r_i, R_i^{1}, R_i^{2}, R_i^{3}, \pi_i) \mid i \in \mathbb{N}\},
\]
where:
\begin{itemize}
    \item $p_i \in \mathbb{R}^d$: The $d$-dimensional vector embedding of a prompt.
    \item $r_i$: The LLM-generated response for the prompt.
    \item $R_i^{1}, R_i^{2}, R_i^{3}$: The threshold regions (Section \ref{threshold-regions}).
    \item $\pi_i(s)$: The correctness posterior function (Section \ref{correctness-sampling}).
\end{itemize}

For a new prompt $p$ (referred to as the \textit{candidate}), let $p' \in \mathbb{R}^d$ represent its vector embedding. The system identifies the \textit{nearest neighbor} $nn$ in $\mathcal{D}$ given a similarity metric:
\[
nn = \arg \max_{p_{nn} \in \mathcal{D}} \text{sim}(p', p_{nn}),
\]
and
\[
nn = (p_{nn}, r_{nn}, R_{nn}^{1}, R_{nn}^{2}, R_{nn}^{3}, \pi_{nn}),
\]
where $\text{sim}(p', p_{nn}) \in [0.0, 1.0]$ is the embedding similarity score, with $0.0$ indicating no similarity and $1.0$ indicating identical embeddings. 

A \textbf{cache miss} occurs if the similarity score $s = \text{sim}(p', p_{nn})$ falls below a threshold $\theta$: $s < \theta$. \textit{VectorQ} uses threshold regions instead of one threshold (see Section \ref{threshold-regions}). The system generates a new response $r'$ using the LLM and updates the cache:
\[
\mathcal{D} \gets \mathcal{D} \cup \{(p', r', R'^{1}, R'^{2}, R'^{3}, \pi')\}.
\]
A \textbf{cache hit} occurs if the similarity score exceeds a threshold $\theta$: $s \geq \theta$. The cached response $r_{nn}$ associated with $nn$ is returned in this case. A cache hit is correct if the cached response $r_{nn}$ matches the LLM-generated response $r'$ that would have been produced for the prompt ($r_{nn} = r'$). A cache hit is incorrect if the cached response $r_{nn}$ deviates from the LLM-generated response ($r_{nn} \neq r'$).


% <+=================================+>
% <+=================================+>

\begin{figure}[t]
    \centering
    \includegraphics[width=0.485\textwidth]{images/thresholds_benchmark1.pdf}
    \caption{Kernel Density Functions (KDFs) of correct (green) and incorrect (red) cache hits for two embeddings from the Semantic Prompt Cache Benchmark, showing that similarity distributions vary across embeddings and require different thresholds.}
    \label{fig:one-threshold-problem}
\end{figure}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.99\textwidth]{images/VectorQThresholdRegions.pdf}
    \caption{The figure illustrates the evolution of the three threshold regions ($R_{0}^1, R_{0}^2, R_{0}^3$) for the prompt “Name a paper about human Biology”. Six candidates use this embedding as their nearest neighbor and attempt to reuse its cached response (i.e., the name of a paper about human Biology). Steps 3 and 6.1 demonstrate how correctness sampling re-evaluations either increase certainty in $R_0^3$ or reduce its size, respectively. Further details are provided in Sections \ref{threshold-regions} and \ref{correctness-sampling}.}
    \label{fig:vectorq-threshold-regions}
\end{figure*}

\section{The Problem of Static Similarity Thresholds}
\label{static-similarity-threshold}
This section examines the limitations of using a static similarity threshold in semantic prompt caches, highlighting why a single threshold cannot generalize across different prompts. State-of-the-art semantic prompt caches rely on a static threshold to determine whether a cached response should be reused or if a new response should be generated for a candidate \cite{bang2023gptcache, microsoft, aws, dasgupta2025wallmartcache, li2024scalm}. A single threshold assumes that all candidates and their nearest neighbors share a uniform similarity value that can reliably distinguish between correct and incorrect cache hits.

\textbf{Experiment.} To analyze the relationship between similarity values and cache hit correctness, we designed an experiment with the following setup: Every processed candidate is added to the vector database, ensuring the database contains all previously seen prompts. For each new candidate, we identify its nearest neighbor in the vector database using cosine similarity \cite{rahutomo2012semantic}. We evaluate whether the cached response for the nearest neighbor character matches the response that would have been generated for the candidate. This allows us to classify cache hits as either correct or incorrect. For each prompt, we record the similarity value between the new prompt and its nearest neighbor, along with a label indicating whether the cache hit was correct or incorrect. We generate distributions of similarity values for both correct and incorrect cache hits on an embedding level. These distributions are visualized as kernel density functions (KDFs) in Figure \ref{fig:one-threshold-problem}, which is based on an evaluation of 45,000 samples from the Semantic Prompt Cache Benchmark (Appendix \ref{app:semantic-prompt-cache-benchmark}), using the e5-mistral-7b-instruct embedding model and Llama-3.1-70B-Instruct.

\textbf{Analysis.} In embedding 201 (top), incorrect cache hits occur at similarity values below 0.72, while correct hits are concentrated above this value—suggesting that a threshold of 0.72 would effectively separate correct from incorrect hits. However, embedding 371 (bottom) reveals a different pattern: even similarity values as high as 0.98 still produce incorrect cache hits, meaning a much higher threshold would be needed to ensure correctness. The vertical dashed line marks a static threshold selected based on the distribution of embedding 201 alone, which fails when applied to embedding 371. This inconsistency highlights that a fixed similarity threshold cannot generalize across embeddings and motivates the need for embedding-specific thresholding. 

% <+=================================+>
% <+=================================+>

\section{\textit{VectorQ}}
This section describes how the online \textit{VectorQ} framework overcomes the limitations of the static similarity threshold in semantic prompt caches. 
We introduce embedding-specific threshold regions accompanied by an illustrative example (Section~\ref{threshold-regions}), explain how correctness sampling enables the refinement of these regions (Section~\ref{correctness-sampling}), proof threshold convergence (Section~\ref{threshold-convergence-proof}), and how to adjust the accuracy-latency trade-off (Section~\ref{user-defined-parameter}). 

\subsection{Threshold Regions}
\label{threshold-regions}
Each cached embedded prompt $p$ maintains three threshold regions in its metadata: Incorrect Region ($R_p^1$), Uncertain Region ($R_p^2$), and Correct Region ($R_p^3$). The system decides between a cache hit or a cache miss based on the region to which the similarity score between the candidate and its nearest neighbor belongs. The regions expand and contract based on the correctness of cache hits and their associated embedding similarity scores, where all possible similarity thresholds are in the range $[0.0, 1.0]$. Region 1 ($R_p^1$) spans from $0.0$ to the largest similarity value which resulted in a wrong cache hit. Region 3 ($R_p^3$) spans from the smallest similarity value, which resulted in a correct cache hit to $0.0$. Region 2 ($R_p^2$) is the uncertainty region that spans all values between $R_p^1$ and $R_p^3$. The three regions of an embedding are non-overlapping, with $R_p^1$ expanding monotonically toward higher similarity values. We describe the algorithm used to construct the threshold regions with an illustrative example where a user prompts an LLM to name relevant paper titles. This explanation is accompanied by the visualization in Figure \ref{fig:vectorq-threshold-regions} and references Algorithm \ref{alg:vectorq-regions}.

\textbf{Construction of Threshold Regions.} The cache starts with an empty vector database.\\
\textbf{Step \hyperref[fig:vectorq-threshold-regions]{0})} When the first candidate \textit{``Name a paper about human Biology''} is processed, no nearest neighbor exists. The LLM generates a response for the candidate, which gets stored in the embedding metadata. The embedding is added to the vector database with Region 2 ($R_0^2$) initially spanning the full threshold range. For the rest of the examples, this embedding is the nearest neighbor for all candidates.

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{1})} For the next candidate \textit{"Name a paper about Biology"}, the cache retrieves the nearest neighbor and computes the similarity between the two (Line 1 in Algorithm \ref{alg:vectorq-regions}). The similarity falls within $R_0^2$, which initially spans the entire range. Since $R_0^2$ represents the uncertainty region, the system uses the LLM to generate a ground truth response for the candidate (Line 7 in Algorithm \ref{alg:vectorq-regions}). The candidate and the nearest neighbor share the same response, so the similarity value is considered valid and added to Region 3 ($R_0^3$), the correct region (Line 9 in Algorithm  \ref{alg:vectorq-regions}).

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{2})} For the next candidate \textit{"Name a paper about Architecture"} the cache retrieves the nearest neighbor and computes the similarity, which again falls in $R_0^2$. The system uses the LLM to generate a ground truth response. However, the candidate requires an Architecture paper, whereas the cached response corresponds to the name of a Biology paper, which would result in an incorrect cache hit. The similarity value is classified as incorrect and added to $R_0^2$. Thus, the candidate is not represented in the vector database, it stores the ground truth (computed in Line 7 in Algorithm \ref{alg:vectorq-regions}) and gets added to the vector database (Line 11 in Algorithm \ref{alg:vectorq-regions}). 

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{3})} For the next candidate \textit{"Name a homo sapiens Biology paper"}, the cache retrieves the nearest neighbor and computes the similarity, which falls in $R_0^3$. The correctness sampling (details in Section \ref{correctness-sampling}) triggers a re-evaluation of the cache hit's correctness. The LLM generates a ground truth response for the candidate, and the result matches the cached response. Their similarity value is added to $R_0^3$ as it classifies as correct (Line 20 in Algorithm \ref{alg:vectorq-regions}).

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{4})} For the next candidate \textit{"Name a paper about animal Biology"}, the cache retrieves the nearest neighbor and computes the similarity, which falls in $R_0^2$. As $R_0^2$ represents the uncertainty region, the system invokes the LLM to generate a ground truth response. The cached response does not match the expected response for the candidate, so their similarity value is classified as incorrect and added to $R_0^1$ (Line 11 in Algorithm \ref{alg:vectorq-regions}).

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{5})} For the next candidate \textit{"Name a paper that covers Biology"}, the cache retrieves the nearest neighbor and computes the similarity, which falls in $R_0^3$. The correctness sampling classifies the similarity value as certain enough and allows a cache hit (Line 28 in Algorithm \ref{alg:vectorq-regions}). 

\textbf{Step \hyperref[fig:vectorq-threshold-regions]{6})} For the next candidate \textit{"Name a paper about plant and human Biology"}, the cache computes the similarity, which falls in $R_0^3$. The correctness sampling triggers a re-evaluation of the cached response (Line 17 in Algorithm \ref{alg:vectorq-regions}). The LLM generates a ground truth response for the candidate, which does not match the nearest neighbor's cached response. This indicates that all similarity values smaller than the current value are insufficient, as they fail to ensure correctness. Consequently, all similarity values less than or equal to this similarity value are reclassified as incorrect and moved to $R_0^1$ (Lines 22–23 in Algorithm \ref{alg:vectorq-regions}).\\

\begin{algorithm}[t]
\caption{\textit{VectorQ} Algorithm}
\label{alg:vectorq-regions}
\begin{algorithmic}[1]
\REQUIRE Prompt $p$, Embedded prompt $p'$, nearest neighbor $nn = (p_{nn}, r_{nn}, R_{nn}^{1}, R_{nn}^{2}, R_{nn}^{3}, \pi_{nn})$, user-defined \textit{uncertainty gate} $ug$ ($1.0$ by default. See Section \ref{user-defined-parameter})
\ENSURE Reuse cached response or do LLM inference

\STATE Compute similarity $s = \text{sim}(p', p_{nn})$
\IF{$s \in R_{nn}^1$}
    \STATE Generate ground truth $gt$ for $p$ via LLM inference
    \STATE Add $s$ to $R_{nn}^1$ and add $p'$ to the vector database
    \STATE \textbf{return} $gt$
\ELSIF{$s \in R_{nn}^2$}
    \STATE Generate ground truth $gt$ for $p$ via LLM inference
    \IF{$r_{nn} == gt$}
        \STATE Add $s$ to $R_{nn}^3$
    \ELSE
        \STATE Add $s$ to $R_{nn}^1$ and add $p'$ to the vector database
    \ENDIF
    \STATE Update $\pi_{nn}$
    \STATE \textbf{return} $gt$
\ELSIF{$s \in R_{nn}^3$}
    \STATE Draw a random number $r \sim \mathcal{U}(0.0, ug)$
    \IF{$r < \pi_{nn}(s)$}
        \STATE Generate ground truth $gt$ for $p$ via LLM inference
        \IF{$r_{nn} == gt$}
            \STATE Add $s$ to $R_{nn}^3$
        \ELSE
            \STATE Add $s$ to $R_{nn}^1$ and add $p'$ to the vector database
            \STATE Transfer all similarity values less than or equal to $s$ to $R_{nn}^1$, and remove them from $R_{nn}^3$
        \ENDIF
        \STATE Update $\pi_{nn}$
        \STATE \textbf{return} $gt$
    \ELSE
        \STATE \textbf{return} $r_{nn}$
    \ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}

% <+=================================+>
% <+=================================+>

\subsection{Uncertainty Sampling}
\label{correctness-sampling}
As shown in Figure \ref{fig:one-threshold-problem}, a similarity threshold cannot reliably differentiate between correct and incorrect cache hits. We propose \textit{correctness sampling}, a method to periodically re-evaluate uncertain similarity values between a candidate and its nearest neighbor $nn$ that fall in $R_{nn}^3$. This approach constructs and maintains embedding-specific posterior distributions that model the likelihood of correct and incorrect cache hits, given their corresponding similarity values. By sampling from this posterior, we determine whether to re-evaluate the correctness of a similarity value in $R_{nn}^3$.

\textbf{Correctness Posterior.} The correctness posterior models the likelihood of an incorrect cache hit rate for a given similarity value, enabling adaptation to an embedding's cache hit rate history. Initially, the prior distribution is uniform, $p_{prior}(s) = 1.0$ for all similarity values $s \in [0.0, 1.0]$, indicating no prior knowledge about the embeddings cache hit rate history and considering all similarity values as insufficient \cite{thompson1933likelihood}. As the correctness of the cache hits is evaluated, the posterior is updated using an exponential likelihood function. The posterior evolves to reflect cache hit patterns specific to their associated similarity values. With increasing sample size, the posterior converges toward $1.0$ in threshold regions associated with frequent incorrect cache hits and toward $0.0$ in regions corresponding to correct cache hits \cite{Bayes1763-BAYAET}. Before evaluating the likelihood for a similarity value (Algorithm \ref{alg:vectorq-regions} Line 17), the posterior is normalized to provide consistent scaling for the \textit{correctness sampling}.

\textbf{Correctness Sampling}. The objective is to minimize re-evaluations within $R_{nn}^3$ by selectively re-evaluating only similarity values associated with high uncertainty. To decide whether to re-evaluate the correctness of a cache hit, we leverage the normalized correctness posterior of an embedding. For a candidate with similarity value $s$ to its nearest neighbor (where s falls in the nearest neighbor's $R_{nn}^3$), we evaluate the posterior $\pi_{nn}(s)$ and draw a random number $r$ from a uniform distribution $r \sim \mathcal{U}(0.0, 1.0)$. If $r \leq \pi_{nn}(s)$, the similarity value is likely to result in an incorrect cache hit. We re-evaluate it and adjust the posterior accordingly (Line 25 in Algorithm \ref{alg:vectorq-regions}). Conversely, if $r > \pi_{nn}(s)$, the similarity value is deemed sufficiently certain, and the system bypasses re-evaluation, resulting in a cache hit (Line 28 in Algorithm \ref{alg:vectorq-regions}). The uniform random sampling ensures probabilistic fairness by occasionally re-evaluating even the similarity values with low posterior likelihoods. This sampling process operates analogously to Thompson Sampling \cite{thompson1933likelihood}, prioritizing correctness re-evaluations for similarity values that are most likely to result in incorrect cache hits. This minimizes the number of expensive LLM calls required to re-evaluate the match between the nearest neighbor's cached response and the expected one for the candidate. Re-evaluated similarity values are classified as cache misses because they require an LLM inference to generate a ground truth response.  

% <+=================================+>
% <+=================================+>

\subsection{Threshold Convergence Proof}
\label{threshold-convergence-proof}
When a cache hit is re-evaluted and classified as incorrect, the associated similarity value $s$ between the candidate and its nearest neighbor $nn$ is added to $R_{nn}^1$. If $s$ is also in the range of $R_{nn}^3$, all similarity values in $R_{nn}^3$ that are less than or equal to $s$ are transferred to $R_{nn}^1$ and removed from $R_{nn}^3$ (Line 23 in Algorithm \ref{alg:vectorq-regions}). Because similarity values are never removed from $R_{nn}^1$, and the three threshold regions remain non-overlapping, $R_{nn}^1$ expands monotonically.

Notation: Let $nn$ be the target embedding under consideration for region computation. Let  $s_1, s_2 \in [0,1]$  be the thresholds on similarity which define regions $R_{nn}^1$($[0,s_1)$), $R_{nn}^2$($[s_1, s_2)$) and $R_{nn}^3$($[s_2, 1]$). 

Let $S(t) = \{(x, c)\}_{1}^t$ be the set of all prompts seen till time $t$ where $nn$ was retreived to be candidate nearest neighbor, where $x\in [0,1]$ is the similarity of prompt embedding with candidate $nn$, and $c \in \{\pm 1 \}$ is correctness based on if cached response of $nn$ is correct for the prompt. Then thresholds as computed by the algorithm can be defined as,
\[
    s_1(t) = \max \{ x | (x, c) \in S(t), c = -1\}, s_1(0) = 0
\]
\[
    s_2(t) = \min \{ x | (x, c) \in S(t), c=1, x > s_1(t)\}, s_2(0) = 1
\]

First, let us show that these thresholds converge. Consider $s_1(t)$. The sequence $\{s_1(t)\}_t$ is monotonically non-decreasing. Also by definition, it is upper bounded by $1$. Thus, the sequence converges as $t\rightarrow \infty$. Let this threshold be $s$.

Note that this threshold $s_1$ defines the similarity, beyond which there can only be positive (correct) samples. Under the assumption that similarities $x$ in S span the entire support $[0,1]$ and assuming an independent sampling mechanism from the distribution over similarities, we can show that $s_2(t)$ also converges to $s$. Given any $\delta > 0$, we will show that there exist a $t$, s.t. $|s_2(t) - s_1| \leq \delta.$

Given a $\delta$,
\begin{itemize}
    \item  there exists a $t_1$, such that $| s_1(t) - s | < \delta$ for all $t > t_1$, since $s_1(t)$ converges.
    \item With a very high probability $\rightarrow 1$, there exist a $t_2 > t_1$, such that $|x_{t_2} - s| < \delta$, due to assumption of continuous support $[0,1]$ and independent sampling.
    \item At $t_2$, $| s_2(t_2) - s | < \delta$. Also, it is easy to see that for all $t > t_2$, $| s_2(t) - s | < \delta$
\end{itemize}

Thus, $s_2(t)$ converges to $s$

Note that this threshold $s$ marks the boundary of correctness for retrieval. i.e. For all $x > s$, the retrieved response would always match the actual response. Now we will show that the exploit-explore probability function $\pi(x)$ converges to a function $\pi^*(x)$ where $\pi^*(x) = 0$ for all $x > s$

We consider the discretized $\pi$ as is used in the actual algorithm. Let the gap between similarity discretization be $\Delta_s$. Additionally, for simplicity of analysis, we assume that the kernel function is the Kronecker delta function ( instead of mirrored exponential kernel ) and the probability updates are of magnitude $\Delta_p$. 

Due to convergence of the thresholds to $s_1$, and discretization of $\pi$, there is a time $t^*$ at which the thresholds have effectively converged to $s_1$ for the purpose of $\pi$ computation. (informal)

After this convergence, only points considered for $\pi$ computation are those that have $x > s$.  

Due to the max-normalization, at any point in time, there can be only two cases, 

\begin{itemize}
    \item \textit{Case 1}: $\pi(x_l) =1$ for some $x_l < s$. In this case,  for all $x > s$, the $\pi(x)$ receive updates $-\Delta$ whereas the point of maximum $\pi(x)$ remains at $x_l$. Thus, eventually, $\pi(x)$ for all $x > s$ converge to $0$ (informal)
    
    \item \textit{Case 2}: $\pi(x_r) =1$ for some $x_r >= s$. In this case, whenever $x_r$ gets an update, the values of $\pi(x), x < s$ increase due to max-normalization. Thus, the values of $\pi(x), x < s, t > t^*$ is a monotonically non-decreasing sequence bounded by $1$. Thus, for some value $x < s$ $\pi(x)$  converge to $1$. Once that happens, we switch to Case 1. (informal)
\end{itemize}
Thus in both cases, $\pi$ converges to $\pi^*$ such that $\pi*(x) = 0, x > s$. 

% <+=================================+>
% <+=================================+>

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/semantic_prompt_cache_benchmark/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_hit_rate_vs_error.pdf}
        \caption{E5 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Cache Hit Rate vs. Error Rate on the Semantic Prompt Caching Benchmark. 45,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:cache-hit-vs-error-rate}
\end{figure*}

\begin{figure*}[t]
    \centering
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_8B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-8B}
        \label{fig:pdf1}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/GteLargeENv1_5/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{GTE 1.5 Large \& \\ LLaMA-3.1-70B}
        \label{fig:pdf2}
    \end{subfigure}\hfill
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-8B}
        \label{fig:pdf3}
    \end{subfigure}
    \begin{subfigure}[b]{0.24\textwidth}
        \centering
        \includegraphics[width=\textwidth]{processed_results/ecommerce_dataset/E5_Mistral_7B_Instruct/Llama_3_70B_Instruct/comparison_duration_vs_error_rate.pdf}
        \caption{E5 Mistral 7B \& \\ LLaMA-3.1-70B}
        \label{fig:pdf3}
    \end{subfigure}
    \caption{Duration vs. Error Rate on the Amazon Instant Video Review dataset. 20,000 samples per static threshold (blue dots, thresholds = \{0.74, 0.76, 0.78, 0.8, 0.825, 0.85, 0.875, 0.9, 0.92, 0.94, 0.96\}) and uncertainty gate (red triangles, uncertainty gates = \{0.1, 0.2, 0.4, 0.6, 0.8, 1.0\}).}
    \label{fig:latency-vs-error-rate}
\end{figure*}

\subsection{Uncertainty Gate: Accuracy-Latency Trade-Off}
\label{user-defined-parameter}
During re-evaluation, \textit{VectorQ} assesses similarity value correctness by generating the candidate's response via LLM inference and comparing it to the cached response of the nearest neighbor. Since LLM inference is computationally expensive, performing this re-evaluation for every similarity value in $R_{nn}^3$ would make the system impractical. To address this, \textit{VectorQ} selectively identifies similarity values as correct without re-evaluation when there is high confidence in their correctness.
To manage the trade-off between accuracy and latency, \textit{VectorQ} introduces the optional, user-configurable uncertainty gate parameter that balances the number of correctness re-evaluations. This trade-off is implemented by modifying the bounds of the uniform distribution used during \textit{correctness sampling} (see Section \ref{correctness-sampling}). By default, random numbers are drawn from a uniform distribution $r \sim \mathcal{U}(0.0, 1.0)$. Users can modify the maximum value of the distribution, $ug$, to redefine the range of randomly drawn numbers as $r \sim \mathcal{U}(0.0, ug)$, where $0.0 \leq ug \leq 1.0$.
Reducing $ug$ lowers the likelihood of drawing a random number greater than the posterior in uncertain regions. For example, setting $ug = 0.3$ ensures that the system classifies cache hits as correct only if the posterior value at the given similarity score is below $0.3$. Since the posterior decreases for similarity scores associated with correct cache hits and increases for those linked to incorrect cache hits, a lower posterior value indicates a similarity score with a stronger history of correct cache hits (see Section \ref{correctness-sampling}).
Reducing $ug$ emphasizes accuracy by increasing LLM re-evaluations for cache hits. Conversely, increasing $ug$ prioritizes lower latency by reducing expensive re-evaluations, possibly leading to more incorrect cache hits.


