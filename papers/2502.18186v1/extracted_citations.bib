@article{CREMA-D,
  author       = {Houwei Cao and
                  David G. Cooper and
                  Michael K. Keutmann and
                  Ruben C. Gur and
                  Ani Nenkova and
                  Ragini Verma},
  title        = {{CREMA-D:} Crowd-Sourced Emotional Multimodal Actors Dataset},
  journal      = {{IEEE} Trans. Affect. Comput.},
  volume       = {5},
  number       = {4},
  pages        = {377--390},
  year         = {2014},
}

@article{Hubert,
  author       = {Wei{-}Ning Hsu and
                  Benjamin Bolte and
                  Yao{-}Hung Hubert Tsai and
                  Kushal Lakhotia and
                  Ruslan Salakhutdinov and
                  Abdelrahman Mohamed},
  title        = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction
                  of Hidden Units},
  journal      = {{IEEE} {ACM} Trans. Audio Speech Lang. Process.},
  volume       = {29},
  pages        = {3451--3460},
  year         = {2021},
}

@article{IEMOCAP,
  author       = {Carlos Busso and
                  Murtaza Bulut and
                  Chi{-}Chun Lee and
                  Abe Kazemzadeh and
                  Emily Mower and
                  Samuel Kim and
                  Jeannette N. Chang and
                  Sungbok Lee and
                  Shrikanth S. Narayanan},
  title        = {{IEMOCAP:} interactive emotional dyadic motion capture database},
  journal      = {Lang. Resour. Evaluation},
  volume       = {42},
  number       = {4},
  pages        = {335--359},
  year         = {2008},
}

@article{LLMsurvey,
  author       = {Wayne Xin Zhao and
                  Kun Zhou and
                  Junyi Li and
                  Tianyi Tang and
                  Xiaolei Wang and
                  Yupeng Hou and
                  Yingqian Min and
                  Beichen Zhang and
                  Junjie Zhang and
                  Zican Dong and
                  Yifan Du and
                  Chen Yang and
                  Yushuo Chen and
                  Zhipeng Chen and
                  Jinhao Jiang and
                  Ruiyang Ren and
                  Yifan Li and
                  Xinyu Tang and
                  Zikang Liu and
                  Peiyu Liu and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen},
  title        = {A Survey of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2303.18223},
  year         = {2023},
}

@article{Qwen2-Audio,
  author       = {Yunfei Chu and
                  Jin Xu and
                  Qian Yang and
                  Haojie Wei and
                  Xipin Wei and
                  Zhifang Guo and
                  Yichong Leng and
                  Yuanjun Lv and
                  Jinzheng He and
                  Junyang Lin and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {Qwen2-Audio Technical Report},
  journal      = {CoRR},
  volume       = {abs/2407.10759},
  year         = {2024},
}

@inproceedings{SALMONN,
  author       = {Changli Tang and
                  Wenyi Yu and
                  Guangzhi Sun and
                  Xianzhao Chen and
                  Tian Tan and
                  Wei Li and
                  Lu Lu and
                  Zejun Ma and
                  Chao Zhang},
  title        = {{SALMONN:} Towards Generic Hearing Abilities for Large Language Models},
  booktitle    = {The Twelfth International Conference on Learning Representations,
                  {ICLR} 2024, Vienna, Austria, May 7-11, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
}

@inproceedings{alm_AIR-Bench,
  author       = {Qian Yang and
                  Jin Xu and
                  Wenrui Liu and
                  Yunfei Chu and
                  Ziyue Jiang and
                  Xiaohuan Zhou and
                  Yichong Leng and
                  Yuanjun Lv and
                  Zhou Zhao and
                  Chang Zhou and
                  Jingren Zhou},
  editor       = {Lun{-}Wei Ku and
                  Andre Martins and
                  Vivek Srikumar},
  title        = {AIR-Bench: Benchmarking Large Audio-Language Models via Generative
                  Comprehension},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (Volume 1: Long Papers), {ACL} 2024, Bangkok, Thailand,
                  August 11-16, 2024},
  pages        = {1979--1998},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
}

@article{alm_AudioBench,
  author       = {Bin Wang and
                  Xunlong Zou and
                  Geyu Lin and
                  Shuo Sun and
                  Zhuohan Liu and
                  Wenyu Zhang and
                  Zhengyuan Liu and
                  AiTi Aw and
                  Nancy F. Chen},
  title        = {AudioBench: {A} Universal Benchmark for Audio Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2406.16020},
  year         = {2024},
}

@article{qwenaudio,
  author       = {Yunfei Chu and
                  Jin Xu and
                  Xiaohuan Zhou and
                  Qian Yang and
                  Shiliang Zhang and
                  Zhijie Yan and
                  Chang Zhou and
                  Jingren Zhou},
  title        = {Qwen-Audio: Advancing Universal Audio Understanding via Unified Large-Scale
                  Audio-Language Models},
  journal      = {CoRR},
  volume       = {abs/2311.07919},
  year         = {2023},
}

@article{review-mer1,
  author       = {Smith K. Khare and
                  Victoria Blanes{-}Vidal and
                  Esmaeil S. Nadimi and
                  U. Rajendra Acharya},
  title        = {Emotion recognition and artificial intelligence: {A} systematic review
                  {(2014-2023)} and research recommendations},
  journal      = {Inf. Fusion},
  volume       = {102},
  pages        = {102019},
  year         = {2024},
}

@inproceedings{ssl_ser,
  author       = {Abinay Reddy Naini and
                  Mary A. Kohler and
                  Elizabeth Richerson and
                  Donita Robinson and
                  Carlos Busso},
  title        = {Generalization of Self-Supervised Learning-Based Representations for
                  Cross-Domain Speech Emotion Recognition},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech and Signal Processing,
                  {ICASSP} 2024, Seoul, Republic of Korea, April 14-19, 2024},
  pages        = {12031--12035},
  publisher    = {{IEEE}},
  year         = {2024},
}

@inproceedings{ssl_ser2,
  author       = {Zhi Zhu and
                  Yoshinao Sato},
  title        = {Deep Investigation of Intermediate Representations in Self-Supervised
                  Learning Models for Speech Emotion Recognition},
  booktitle    = {{IEEE} International Conference on Acoustics, Speech, and Signal Processing,
                  {ICASSP} 2023 - Workshops, Rhodes Island, Greece, June 4-10, 2023},
  pages        = {1--5},
  publisher    = {{IEEE}},
  year         = {2023},
}

@inproceedings{wav2vec2.0,
  author       = {Alexei Baevski and
                  Yuhao Zhou and
                  Abdelrahman Mohamed and
                  Michael Auli},
  editor       = {Hugo Larochelle and
                  Marc'Aurelio Ranzato and
                  Raia Hadsell and
                  Maria{-}Florina Balcan and
                  Hsuan{-}Tien Lin},
  title        = {wav2vec 2.0: {A} Framework for Self-Supervised Learning of Speech
                  Representations},
  booktitle    = {Advances in Neural Information Processing Systems 33: Annual Conference
                  on Neural Information Processing Systems 2020, NeurIPS 2020, December
                  6-12, 2020, virtual},
  year         = {2020},
}

