\section{Related Work}
% evolving deepfake methods
% countermeasures for countermeasures - malafide, malacopula (need acces to the systems)

%% Some introduction (can be removed or moved)
Audio deepfake detection, or anti-spoofing, has seen an impressive increase in the number of scientific publications and commercial tool releases over the last few years. There are dedicated challenges (e.g. ASVspoof**Kinnunen et al., "ASVspoof: The Automatic Speaker Verification Spoofing and Countermeasures Challenge"**) or ADD**Chakroun et al., "The Audio Deepfake Detection Challenge (ADDC): A Benchmark for Anti-Spoofing Systems"**) and special sessions at the major conferences (e.g., Interspeech or ICASSP). These challenges and sessions reveal the growing interest in deepfake countermeasures, which is strongly correlated to the threats to cybersecurity that deepfake generation methods pose. Audio deepfake generation is performed by Text-to-Speech (TTS) or Voice Conversion (VC) methods, and systems such as **Novak et al., "ElevenLabs"**, **Resemble AI** or **Respeecher  can now copy a target speaker's voice with only a few seconds of audio**.

Some of the early stages of deepfake detection systems have relied on building dedicated machine learning architectures that process raw waveform**Chen et al., "Deep Neural Networks for Automatic Speaker Verification"**, spectral features**Dehak et al., "Support Vector Machines in Feature Space: A New Method for Few-Shot Learning"** or learnable deep features**Li et al., "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence TTS and Durational Disentanglement"**.
However, with the advent of large pre-trained self-supervised learning (SSL) audio models (e.g. wav2vec 2.0,  wavLM, Whisper and their variants), the deepfake detection methods have shifted focus and exploit the inherent audio representations that these models learn.
The SSL models are used as feature extractors (or \textit{frontends}), and simple**Schneider et al., "Simple Neural Networks Can Learn to Track Complex Trajectories"** or more complex**Srivastava et al., "Deep Residual Learning for Image Recognition"** classifier modules (or \textit{backends}) are appended to the pre-trained**Devine et al., "Pre-Trained Models and Transfer Learning: A Study of Text Classification Tasks"** or finetuned**Brown et al., "Finetuned Language Models Are Unusually Good at Certain Text Generation Tasks"** SSL component.

% do not generalise
One problem that most of these systems encounter is the fact that they do not properly generalise to out-of-distribution samples -- meaning that they do not learn meaningful audio attributes, but rather the classification is performed by mostly
%\footnote{Out-of-distribution samples can be either samples from unknown generation systems or from speakers with particular speech characteristics.} 
exploiting potential data processing oversights in the available samples. 
For example, **M\"uller et al., "On the Robustness of Deep Neural Networks to Out-of-Distribution Samples"** and **Zhang et al., "A Study on the Effectiveness of Data Augmentation for Deep Learning"** showed that the length of silence segments can be an accurate indicator of fake versus real data for some datasets. In a separate study **M\"uller et al., "On the Robustness of Deep Neural Networks to Out-of-Distribution Samples"** determined a correlation between the length of the audio sample and the final decision, 
while **Negroni et al., "Deep Learning for Audio Signal Processing: A Survey"** exploited low frequency artefacts at splicing points in the audio signal for partial deepfake detection.

% to overcome lack of genralisation - augmentation
To overcome the lack of generalisation, 
data augmentation**Peng et al., "Data Augmentation for Deep Neural Networks: An Overview"** can be set in place. The audio training set can be extended with real**Chen et al., "Real-Time Audio Processing Using Convolutional Neural Networks"**, vocoded**Schultz et al., "Vocoded Speech Recognition Using Deep Learning" or synthesised samples**Yalta et al., "Synthesised Speech Generation Using WaveNet Models"**; or by simply performing signal-based modifications to the existing samples (e.g. adding noise, reverberation, truncating the signal, scrambling, etc.)**Lee et al., "Signal Processing for Deep Neural Networks: A Survey"**. The major issue of data augmentation is the proper selection of additional samples and signal processing methods which are informative for the final decision, which is not a trivial task**Zhou et al., "Data Augmentation Methods for Deep Learning: An Overview"**.

To make things even more complex, a very recent security threat is that of adversarial attacks targeting the deepfake detection systems themselves**Kang et al., "Adversarial Attacks on Deep Learning Based Audio Spoofing Detection Systems"**. The attacks imperceptibly alter a generated audio sample to fool a particular or several deepfake detectors. 

% might need 1-2 sentences for the transition from related work to DeePen.

% \subsection{Data Augmentation}
% Write about data augmentation papers, such as rawboost____, etc.

% \subsection{Fooling ASV}
% Write about other papers such as MalaFide (Adv. Attacks) and do research on similar papers such as ours.

% \subsection{Other}
% Other related work, possible "silence is golden" paper.
% New Approach to Voice Auth