@inproceedings{
hsieh2024ruler,
title={{RULER}: What{\textquoteright}s the Real Context Size of Your Long-Context Language Models?},
author={Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Boris Ginsburg},
booktitle={First Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=kIoBbc76Sy}
}

@misc{vodrahalli2024michelangelolongcontextevaluations,
      title={Michelangelo: Long Context Evaluations Beyond Haystacks via Latent Structure Queries}, 
      author={Kiran Vodrahalli and Santiago Ontanon and Nilesh Tripuraneni and Kelvin Xu and Sanil Jain and Rakesh Shivanna and Jeffrey Hui and Nishanth Dikkala and Mehran Kazemi and Bahare Fatemi and Rohan Anil and Ethan Dyer and Siamak Shakeri and Roopali Vij and Harsh Mehta and Vinay Ramasesh and Quoc Le and Ed Chi and Yifeng Lu and Orhan Firat and Angeliki Lazaridou and Jean-Baptiste Lespiau and Nithya Attaluri and Kate Olszewska},
      year={2024},
      eprint={2409.12640},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.12640}, 
}

@inproceedings{
kuratov2024babilong,
title={{BABIL}ong: Testing the Limits of {LLM}s with Long Context Reasoning-in-a-Haystack},
author={Yuri Kuratov and Aydar Bulatov and Petr Anokhin and Ivan Rodkin and Dmitry Igorevich Sorokin and Artyom Sorokin and Mikhail Burtsev},
booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2024},
url={https://openreview.net/forum?id=u7m2CG84BQ}
}

@article{kamradt2023needle,
  title={Needle in a haystack-pressure testing llms},
  author={Kamradt, Greg},
  journal={Github Repository},
  pages={28},
  year={2023}
}

@article{yen2024helmet,
  title={Helmet: How to evaluate long-context language models effectively and thoroughly},
  author={Yen, Howard and Gao, Tianyu and Hou, Minmin and Ding, Ke and Fleischer, Daniel and Izsak, Peter and Wasserblat, Moshe and Chen, Danqi},
  journal={arXiv preprint arXiv:2410.02694},
  year={2024}
}

@inproceedings{goldman-etal-2024-really,
    title = "Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context {NLP}",
    author = "Goldman, Omer  and
      Jacovi, Alon  and
      Slobodkin, Aviv  and
      Maimon, Aviya  and
      Dagan, Ido  and
      Tsarfaty, Reut",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.924/",
    doi = "10.18653/v1/2024.emnlp-main.924",
    pages = "16576--16586",
    abstract = "Improvements in language models' capabilities have pushed their applications towards longer contexts, making long-context evaluation and development an active research area. However, many disparate use-cases are grouped together under the umbrella term of {\textquotedblleft}long-context{\textquotedblright}, defined simply by the total length of the model`s input, including - for example - Needle-in-a-Haystack tasks, book summarization, and information aggregation. Given their varied difficulty, in this position paper we argue that conflating different tasks by their context length is unproductive. As a community, we require a more precise vocabulary to understand what makes long-context tasks similar or different. We propose to unpack the taxonomy of long-context based on the properties that make them more difficult with longer contexts. We propose two orthogonal axes of difficulty: (I) Diffusion: How hard is it to find the necessary information in the context? (II) Scope: How much necessary information is there to find? We survey the literature on long-context, provide justification for this taxonomy as an informative descriptor, and situate the literature with respect to it. We conclude that the most difficult and interesting settings, whose necessary information is very long and highly diffused within the input, is severely under-explored. By using a descriptive vocabulary and discussing the relevant properties of difficulty in long-context, we can implement more informed research in this area. We call for a careful design of tasks and benchmarks with distinctly long context, taking into account the characteristics that make it qualitatively different from shorter context."
}

@misc{zhang2024inftybenchextendinglongcontext,
      title={$\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens}, 
      author={Xinrong Zhang and Yingfa Chen and Shengding Hu and Zihang Xu and Junhao Chen and Moo Khai Hao and Xu Han and Zhen Leng Thai and Shuo Wang and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2402.13718},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.13718}, 
}

@article{liu-etal-2024-lost,
    title = "Lost in the Middle: How Language Models Use Long Contexts",
    author = "Liu, Nelson F.  and
      Lin, Kevin  and
      Hewitt, John  and
      Paranjape, Ashwin  and
      Bevilacqua, Michele  and
      Petroni, Fabio  and
      Liang, Percy",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "12",
    year = "2024",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2024.tacl-1.9/",
    doi = "10.1162/tacl_a_00638",
    pages = "157--173",
    abstract = "While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models."
}

@inproceedings{arora2024zoology,
title={Zoology: Measuring and Improving  Recall in Efficient Language Models},
author={Simran Arora and Sabri Eyuboglu and Aman Timalsina and Isys Johnson and Michael Poli and James Zou and Atri Rudra and Christopher Re},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=LY3ukUANko}
}

@inproceedings{shaham-etal-2023-zeroscrolls,
    title = "{Z}ero{SCROLLS}: A Zero-Shot Benchmark for Long Text Understanding",
    author = "Shaham, Uri  and
      Ivgi, Maor  and
      Efrat, Avia  and
      Berant, Jonathan  and
      Levy, Omer",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.536/",
    doi = "10.18653/v1/2023.findings-emnlp.536",
    pages = "7977--7989",
    abstract = "We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test and small validation sets, without training data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard."
}

@inproceedings{fu2024data,
title={Data Engineering for Scaling Language Models to 128K Context},
author={Yao Fu and Rameswar Panda and Xinyao Niu and Xiang Yue and Hannaneh Hajishirzi and Yoon Kim and Hao Peng},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=TaAqeo7lUh}
}

@article{hengle2024multilingual,
  title={Multilingual needle in a haystack: Investigating long-context behavior of multilingual large language models},
  author={Hengle, Amey and Bajpai, Prasoon and Dan, Soham and Chakraborty, Tanmoy},
  journal={arXiv preprint arXiv:2408.10151},
  year={2024}
}

@inproceedings{levy-etal-2024-task,
    title = "Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models",
    author = "Levy, Mosh  and
      Jacoby, Alon  and
      Goldberg, Yoav",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.818/",
    doi = "10.18653/v1/2024.acl-long.818",
    pages = "15339--15353",
    abstract = "This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA reasoning framework, specifically designed to assess the impact of input length. We isolate the effect of input length using multiple versions of the same sample, each being extended with padding of different lengths, types and locations. Our findings show a notable degradation in LLMs' reasoning performance at much shorter input lengths than their technical maximum. We show that the degradation trend appears in every version of our dataset, although at different intensities.Additionally, our study reveals that the traditional metric of next word prediction correlates negatively with performance of LLMs' on our reasoning dataset. We analyse our results and identify failure modes that can serve as useful guides for future research, potentially informing strategies to address the limitations observed in LLMs."
}


@misc{li2024needlebenchllmsretrievalreasoning,
      title={NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?}, 
      author={Mo Li and Songyang Zhang and Yunxin Liu and Kai Chen},
      year={2024},
      eprint={2407.11963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.11963}, 
}

@inproceedings{wang-etal-2024-leave,
    title = "Leave No Document Behind: Benchmarking Long-Context {LLM}s with Extended Multi-Doc {QA}",
    author = "Wang, Minzheng  and
      Chen, Longze  and
      Cheng, Fu  and
      Liao, Shengyi  and
      Zhang, Xinghua  and
      Wu, Bingli  and
      Yu, Haiyang  and
      Xu, Nan  and
      Zhang, Lei  and
      Luo, Run  and
      Li, Yunshui  and
      Yang, Min  and
      Huang, Fei  and
      Li, Yongbin",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.322/",
    doi = "10.18653/v1/2024.emnlp-main.322",
    pages = "5627--5646",
    abstract = "Long-context modeling capabilities of Large Language Models (LLMs) have garnered widespread attention, leading to the emergence of LLMs with ultra-context windows. Meanwhile, benchmarks for evaluating long-context language models are gradually catching up. However, existing benchmarks employ irrelevant noise texts to artificially extend the length of test cases, diverging from the real-world scenarios of long-context applications. To bridge this gap, we propose a novel long-context benchmark, Loong, aligning with realistic scenarios through extended multi-document question answering (QA). Unlike typical document QA, in Loong`s test cases, each document is relevant to the final answer, ignoring any document will lead to the failure of the answer. Furthermore, Loong introduces four types of tasks with a range of context lengths: Spotlight Locating, Comparison, Clustering, and Chain of Reasoning, to facilitate a more realistic and comprehensive evaluation of long-context understanding. Extensive experiments indicate that existing long-context language models still exhibit considerable potential for enhancement. Retrieval augmented generation (RAG) achieves poor performance, demonstrating that Loong can reliably assess the model`s long-context modeling capabilities."
}

@inproceedings{maharana-etal-2024-evaluating,
    title = "Evaluating Very Long-Term Conversational Memory of {LLM} Agents",
    author = "Maharana, Adyasha  and
      Lee, Dong-Ho  and
      Tulyakov, Sergey  and
      Bansal, Mohit  and
      Barbieri, Francesco  and
      Fang, Yuwei",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.747/",
    doi = "10.18653/v1/2024.acl-long.747",
    pages = "13851--13870",
    abstract = "Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LoCoMo, a dataset of very long-term conversations, each encompassing 600 turns and 16K tokens on avg., over up to 32 sessions. Based on LoCoMo, we present a comprehensive evaluation benchmark to measure long-term memory in models, encompassing question answering, event summarization, and multi-modal dialogue generation tasks. Our experimental results indicate that LLMs exhibit challenges in understanding lengthy conversations and comprehending long-range temporal and causal dynamics within dialogues. Employing strategies like long-context LLMs or RAG can offer improvements but these models still substantially lag behind human performance."
}

@article{xiong2024artificial,
  title={From artificial needles to real haystacks: Improving retrieval capabilities in llms by finetuning on synthetic data},
  author={Xiong, Zheyang and Papageorgiou, Vasilis and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2406.19292},
  year={2024}
}

@inproceedings{
xu2024stresstesting,
title={Stress-Testing Long-Context Language Models with Lifelong {ICL} and Task Haystack},
author={Xiaoyue Xu and Qinyuan Ye and Xiang Ren},
booktitle={First Workshop on Long-Context Foundation Models @ ICML 2024},
year={2024},
url={https://openreview.net/forum?id=5ltgEKXnZt}
}

@article{an2023eval,
  title={L-eval: Instituting standardized evaluation for long context language models},
  author={An, Chenxin and Gong, Shansan and Zhong, Ming and Zhao, Xingjian and Li, Mukai and Zhang, Jun and Kong, Lingpeng and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2307.11088},
  year={2023}
}

@article{yuan2024lv,
  title={Lv-eval: A balanced long-context benchmark with 5 length levels up to 256k},
  author={Yuan, Tao and Ning, Xuefei and Zhou, Dong and Yang, Zhijie and Li, Shiyao and Zhuang, Minghui and Tan, Zheyue and Yao, Zhuyu and Lin, Dahua and Li, Boxun and others},
  journal={arXiv preprint arXiv:2402.05136},
  year={2024}
}

@inproceedings{
liu2024repoqa,
title={Repo{QA}: Evaluating Long Context Code Understanding},
author={Jiawei Liu and Jia Le Tian and Vijay Daita and Yuxiang Wei and Yifeng Ding and Yuhan Katherine Wang and Jun Yang and LINGMING ZHANG},
booktitle={First Workshop on Long-Context Foundation Models @ ICML 2024},
year={2024},
url={https://openreview.net/forum?id=hK9YSrFuGf}
}

@inproceedings{agarwal2024manyshot,
title={Many-shot In-Context Learning},
author={Rishabh Agarwal and Avi Singh and Lei M Zhang and Bernd Bohnet and Luis Rosias and Stephanie C.Y. Chan and Biao Zhang and Aleksandra Faust and Hugo Larochelle},
booktitle={ICML 2024 Workshop on In-Context Learning},
year={2024},
url={https://openreview.net/forum?id=goi7DFHlqS}
}

@inproceedings{
mohtashami2023randomaccess,
title={Random-Access Infinite Context Length for Transformers},
author={Amirkeivan Mohtashami and Martin Jaggi},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=7eHn64wOVy}
}

@misc{bai2025longbenchv2deeperunderstanding,
      title={LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks}, 
      author={Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},
      year={2025},
      eprint={2412.15204},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15204}, 
}

@inproceedings{bai-etal-2024-longbench,
    title = "{L}ong{B}ench: A Bilingual, Multitask Benchmark for Long Context Understanding",
    author = "Bai, Yushi  and
      Lv, Xin  and
      Zhang, Jiajie  and
      Lyu, Hongchang  and
      Tang, Jiankai  and
      Huang, Zhidian  and
      Du, Zhengxiao  and
      Liu, Xiao  and
      Zeng, Aohan  and
      Hou, Lei  and
      Dong, Yuxiao  and
      Tang, Jie  and
      Li, Juanzi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.172/",
    doi = "10.18653/v1/2024.acl-long.172",
    pages = "3119--3137",
    abstract = "Although large language models (LLMs) demonstrate impressive performance for many language tasks, most of them can only handle texts a few thousand tokens long, limiting their applications on longer sequence inputs, such as books, reports, and codebases. Recent works have proposed methods to improve LLMs' long context capabilities by extending context windows and more sophisticated memory mechanisms. However, comprehensive benchmarks tailored for evaluating long context understanding are lacking. In this paper, we introduce LongBench, the first bilingual, multi-task benchmark for long context understanding, enabling a more rigorous evaluation of long context understanding. LongBench comprises 21 datasets across 6 task categories in both English and Chinese, with an average length of 6,711 words (English) and 13,386 characters (Chinese). These tasks cover key long-text application areas including single-doc QA, multi-doc QA, summarization, few-shot learning, synthetic tasks, and code completion. All datasets in LongBench are standardized into a unified format, allowing for effortless automatic evaluation of LLMs. Upon comprehensive evaluation of 8 LLMs on LongBench, we find that: (1) Commercial model (GPT-3.5-Turbo-16k) outperforms other open-sourced models, but still struggles on longer contexts. (2) Scaled position embedding and fine-tuning on longer sequences lead to substantial improvement on long context understanding. (3) Context compression technique such as retrieval brings improvement for model with weak ability on long contexts, but the performance still lags behind models that have strong long context understanding capability."
}

@inproceedings{dong-etal-2024-bamboo,
    title = "{BAMBOO}: A Comprehensive Benchmark for Evaluating Long Text Modeling Capacities of Large Language Models",
    author = "Dong, Zican  and
      Tang, Tianyi  and
      Li, Junyi  and
      Zhao, Wayne Xin  and
      Wen, Ji-Rong",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.188/",
    pages = "2086--2099",
    abstract = "Large language models (LLMs) have achieved dramatic proficiency over NLP tasks with normal length. Recently, multiple studies have committed to extending the context length and enhancing the long text modeling capabilities of LLMs. To comprehensively evaluate the long context ability of LLMs, we propose BAMBOO, a multi-task long context benchmark. BAMBOO has been designed with four principles: comprehensive capacity evaluation, avoidance of data contamination, accurate automatic evaluation, and different length levels. It consists of 10 datasets from 5 different long text understanding tasks, i.e., question answering, hallucination detection, text sorting, language modeling, and code completion, to cover various domains and core capacities of LLMs. We conduct experiments with five widely-used long-context models and further discuss five key questions for long text research. In the end, we discuss problems of current long-context models and point out future directions for enhancing long text modeling capacities. We release our data, prompts, and code at https://anonymous.4open.science/r/BAMBOO/."
}

@inproceedings{li-etal-2024-loogle,
    title = "{L}oo{GLE}: Can Long-Context Language Models Understand Long Contexts?",
    author = "Li, Jiaqi  and
      Wang, Mengmeng  and
      Zheng, Zilong  and
      Zhang, Muhan",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.859/",
    doi = "10.18653/v1/2024.acl-long.859",
    pages = "16304--16333",
    abstract = "Large language models (LLMs) are typically limited to processing texts within context window size, which has spurred significant research efforts into enhancing LLMs' long-context understanding as well as developing high-quality benchmarks to evaluate the ability. However, prior datasets suffer from short comings like short length compared to the context window of modern LLMs; outdated documents that might have data leakage problems; and an emphasis on short dependency tasks only. In this paper, we present LooGLE , a Long Context Generic Language Evaluation benchmark. It features documents post-2022, with over 24,000 tokens per document and 6,000 newly generated questions spanning varying dependency ranges in diverse domains. Human annotators meticulously crafted over 1,100 high-quality question-answer (QA) pairs with thorough cross-validation for a most precise assessment of LLMs' long dependency capabilities. We conduct a comprehensive evaluation of representative LLMs on LooGLE . The results indicate that most LLMs have shockingly bad long context ability and fail to capture long dependencies in the context, even when their context window size is enough to fit the entire document. Our results shed light on enhancing the {\textquotedblleft}true long-context understanding{\textquotedblright} ability of LLMs instead of merely enlarging their context window."
}