[
  {
    "index": 0,
    "papers": [
      {
        "key": "kamradt2023needle",
        "author": "Kamradt, Greg",
        "title": "Needle in a haystack-pressure testing llms"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "hsieh2024ruler",
        "author": "Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Boris Ginsburg",
        "title": "{RULER}: What{\\textquoteright}s the Real Context Size of Your Long-Context Language Models?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "levy-etal-2024-task",
        "author": "Levy, Mosh  and\nJacoby, Alon  and\nGoldberg, Yoav",
        "title": "Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models"
      },
      {
        "key": "arorazoology",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zhang-etal-2024-bench",
        "author": "Unknown",
        "title": "Unknown"
      },
      {
        "key": "li2024needlebench",
        "author": "Unknown",
        "title": "Unknown"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "kuratov2024babilong",
        "author": "Yuri Kuratov and Aydar Bulatov and Petr Anokhin and Ivan Rodkin and Dmitry Igorevich Sorokin and Artyom Sorokin and Mikhail Burtsev",
        "title": "{BABIL}ong: Testing the Limits of {LLM}s with Long Context Reasoning-in-a-Haystack"
      },
      {
        "key": "li2024needlebenchllmsretrievalreasoning",
        "author": "Mo Li and Songyang Zhang and Yunxin Liu and Kai Chen",
        "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "xiong2024artificial",
        "author": "Xiong, Zheyang and Papageorgiou, Vasilis and Lee, Kangwook and Papailiopoulos, Dimitris",
        "title": "From artificial needles to real haystacks: Improving retrieval capabilities in llms by finetuning on synthetic data"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "xu2024stresstesting",
        "author": "Xiaoyue Xu and Qinyuan Ye and Xiang Ren",
        "title": "Stress-Testing Long-Context Language Models with Lifelong {ICL} and Task Haystack"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "an2023eval",
        "author": "An, Chenxin and Gong, Shansan and Zhong, Ming and Zhao, Xingjian and Li, Mukai and Zhang, Jun and Kong, Lingpeng and Qiu, Xipeng",
        "title": "L-eval: Instituting standardized evaluation for long context language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yuan2024lv",
        "author": "Yuan, Tao and Ning, Xuefei and Zhou, Dong and Yang, Zhijie and Li, Shiyao and Zhuang, Minghui and Tan, Zheyue and Yao, Zhuyu and Lin, Dahua and Li, Boxun and others",
        "title": "Lv-eval: A balanced long-context benchmark with 5 length levels up to 256k"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "liu2024repoqa",
        "author": "Jiawei Liu and Jia Le Tian and Vijay Daita and Yuxiang Wei and Yifeng Ding and Yuhan Katherine Wang and Jun Yang and LINGMING ZHANG",
        "title": "Repo{QA}: Evaluating Long Context Code Understanding"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mohtashami2023randomaccess",
        "author": "Amirkeivan Mohtashami and Martin Jaggi",
        "title": "Random-Access Infinite Context Length for Transformers"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bai2025longbenchv2deeperunderstanding",
        "author": "Yushi Bai and Shangqing Tu and Jiajie Zhang and Hao Peng and Xiaozhi Wang and Xin Lv and Shulin Cao and Jiazheng Xu and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li",
        "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "li-etal-2024-loogle",
        "author": "Li, Jiaqi  and\nWang, Mengmeng  and\nZheng, Zilong  and\nZhang, Muhan",
        "title": "{L}oo{GLE}: Can Long-Context Language Models Understand Long Contexts?"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "mohtashami2023randomaccess",
        "author": "Amirkeivan Mohtashami and Martin Jaggi",
        "title": "Random-Access Infinite Context Length for Transformers"
      },
      {
        "key": "kamradt2023needle",
        "author": "Kamradt, Greg",
        "title": "Needle in a haystack-pressure testing llms"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "kamradt2023needle",
        "author": "Kamradt, Greg",
        "title": "Needle in a haystack-pressure testing llms"
      },
      {
        "key": "hsieh2024ruler",
        "author": "Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Boris Ginsburg",
        "title": "{RULER}: What{\\textquoteright}s the Real Context Size of Your Long-Context Language Models?"
      },
      {
        "key": "levy-etal-2024-task",
        "author": "Levy, Mosh  and\nJacoby, Alon  and\nGoldberg, Yoav",
        "title": "Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models"
      },
      {
        "key": "kuratov2024babilong",
        "author": "Yuri Kuratov and Aydar Bulatov and Petr Anokhin and Ivan Rodkin and Dmitry Igorevich Sorokin and Artyom Sorokin and Mikhail Burtsev",
        "title": "{BABIL}ong: Testing the Limits of {LLM}s with Long Context Reasoning-in-a-Haystack"
      },
      {
        "key": "hengle2024multilingual",
        "author": "Hengle, Amey and Bajpai, Prasoon and Dan, Soham and Chakraborty, Tanmoy",
        "title": "Multilingual needle in a haystack: Investigating long-context behavior of multilingual large language models"
      },
      {
        "key": "zhang2024inftybenchextendinglongcontext",
        "author": "Xinrong Zhang and Yingfa Chen and Shengding Hu and Zihang Xu and Junhao Chen and Moo Khai Hao and Xu Han and Zhen Leng Thai and Shuo Wang and Zhiyuan Liu and Maosong Sun",
        "title": "$\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens"
      },
      {
        "key": "vodrahalli2024michelangelolongcontextevaluations",
        "author": "Kiran Vodrahalli and Santiago Ontanon and Nilesh Tripuraneni and Kelvin Xu and Sanil Jain and Rakesh Shivanna and Jeffrey Hui and Nishanth Dikkala and Mehran Kazemi and Bahare Fatemi and Rohan Anil and Ethan Dyer and Siamak Shakeri and Roopali Vij and Harsh Mehta and Vinay Ramasesh and Quoc Le and Ed Chi and Yifeng Lu and Orhan Firat and Angeliki Lazaridou and Jean-Baptiste Lespiau and Nithya Attaluri and Kate Olszewska",
        "title": "Michelangelo: Long Context Evaluations Beyond Haystacks via Latent Structure Queries"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "kuratov2024babilong",
        "author": "Yuri Kuratov and Aydar Bulatov and Petr Anokhin and Ivan Rodkin and Dmitry Igorevich Sorokin and Artyom Sorokin and Mikhail Burtsev",
        "title": "{BABIL}ong: Testing the Limits of {LLM}s with Long Context Reasoning-in-a-Haystack"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "li2024needlebenchllmsretrievalreasoning",
        "author": "Mo Li and Songyang Zhang and Yunxin Liu and Kai Chen",
        "title": "NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "hsieh2024ruler",
        "author": "Cheng-Ping Hsieh and Simeng Sun and Samuel Kriman and Shantanu Acharya and Dima Rekesh and Fei Jia and Boris Ginsburg",
        "title": "{RULER}: What{\\textquoteright}s the Real Context Size of Your Long-Context Language Models?"
      },
      {
        "key": "liu-etal-2024-lost",
        "author": "Liu, Nelson F.  and\nLin, Kevin  and\nHewitt, John  and\nParanjape, Ashwin  and\nBevilacqua, Michele  and\nPetroni, Fabio  and\nLiang, Percy",
        "title": "Lost in the Middle: How Language Models Use Long Contexts"
      },
      {
        "key": "zhang2024inftybenchextendinglongcontext",
        "author": "Xinrong Zhang and Yingfa Chen and Shengding Hu and Zihang Xu and Junhao Chen and Moo Khai Hao and Xu Han and Zhen Leng Thai and Shuo Wang and Zhiyuan Liu and Maosong Sun",
        "title": "$\\infty$Bench: Extending Long Context Evaluation Beyond 100K Tokens"
      },
      {
        "key": "bai-etal-2024-longbench",
        "author": "Bai, Yushi  and\nLv, Xin  and\nZhang, Jiajie  and\nLyu, Hongchang  and\nTang, Jiankai  and\nHuang, Zhidian  and\nDu, Zhengxiao  and\nLiu, Xiao  and\nZeng, Aohan  and\nHou, Lei  and\nDong, Yuxiao  and\nTang, Jie  and\nLi, Juanzi",
        "title": "{L}ong{B}ench: A Bilingual, Multitask Benchmark for Long Context Understanding"
      },
      {
        "key": "yen2024helmet",
        "author": "Yen, Howard and Gao, Tianyu and Hou, Minmin and Ding, Ke and Fleischer, Daniel and Izsak, Peter and Wasserblat, Moshe and Chen, Danqi",
        "title": "Helmet: How to evaluate long-context language models effectively and thoroughly"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "olsson2022incontextlearninginductionheads",
        "author": "Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah",
        "title": "In-context Learning and Induction Heads"
      },
      {
        "key": "arora2024zoology",
        "author": "Simran Arora and Sabri Eyuboglu and Aman Timalsina and Isys Johnson and Michael Poli and James Zou and Atri Rudra and Christopher Re",
        "title": "Zoology: Measuring and Improving  Recall in Efficient Language Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "lin-2004-rouge",
        "author": "Lin, Chin-Yew",
        "title": "{ROUGE}: A Package for Automatic Evaluation of Summaries"
      }
    ]
  }
]