\begin{table*}[ht!]
        \small
	\setlength\tabcolsep{5pt}
	\centering
	\begin{tabular}{l|cc|ccccccc}
		\toprule
        \multirow{2}{*}{\textbf{Models}} & \textbf{Claimed} & \textbf{Effective} & \textbf{Base Score} & \multirow{2}{*}{\textbf{1K}} & \multirow{2}{*}{\textbf{2K}} & \multirow{2}{*}{\textbf{4K}} & \multirow{2}{*}{\textbf{8K}} & \multirow{2}{*}{\textbf{16K}} & \multirow{2}{*}{\textbf{32K}} \\
        & \textbf{Length} & \textbf{Length} & ($\times$0.85: \textbf{Thr.}) &&&&&& \\
        \midrule
        GPT-4o              & 128K & 8K & 99.3 (84.4) & \underline{98.1} & \underline{98.0} & \underline{95.7} & \underline{89.2} & 81.6 & 69.7 \\
        Llama 3.3 70B       & 128K & 2K & 97.3 (82.7) & \underline{94.2} & \underline{87.4} & 81.5 & 72.1 & 59.5 & \cellcolor[HTML]{faa7a7}42.7 \\
        Llama 3.1 405B      & 128K & 2K & 94.7 (80.5) & \underline{89.0} & \underline{85.0} & 74.5 & 60.1 & 48.4 & \cellcolor[HTML]{faa7a7}38.0 \\
        Llama 3.1 70B       & 128K & 2K & 94.5 (80.3) & \underline{91.0} & \underline{81.8} & 71.2 & 62.7 & 51.8 & \cellcolor[HTML]{faa7a7}43.2 \\
        Gemini 1.5 Pro      & 2M   & 2K & 92.6 (78.7) & \underline{86.4} & \underline{82.7} & 75.4 & 63.9 & 55.5 & 48.2 \\
        Jamba 1.5 Mini      & 256K & $<$1K & 92.4 (78.6) & 76.3 & 74.1 & 70.8 & 62.2 & 52.7 & \cellcolor[HTML]{faa7a7}43.6 \\
        Command R+          & 128K & $<$1K & 90.9 (77.3) & 77.0 & 73.5 & 66.3 & \cellcolor[HTML]{faa7a7}39.5 & \cellcolor[HTML]{faa7a7}21.3 & \cellcolor[HTML]{faa7a7}7.4 \\
        Mistral Large 2     & 128K & 2K & 87.9 (74.7) & \underline{86.1} & \underline{85.5} & 73.3 & 51.5 & \cellcolor[HTML]{faa7a7}32.6 & \cellcolor[HTML]{faa7a7}18.7 \\
        Claude 3.5 Sonnet   & 200K & 4K & 87.6 (74.4) & \underline{85.4} & \underline{84.0} & \underline{77.6} & 61.7 & 45.7 & \cellcolor[HTML]{faa7a7}29.8 \\
        Gemini 1.5 Flash    & 1M   & $<$1K & 84.7 (72.0) & 68.6 & 61.6 & 51.0 & 44.4 & \cellcolor[HTML]{faa7a7}35.5 & \cellcolor[HTML]{faa7a7}28.6 \\
        GPT-4o mini         & 128K & $<$1K & 84.9 (72.2) & 67.7 & 58.2 & 44.1 & \cellcolor[HTML]{faa7a7}32.6 & \cellcolor[HTML]{faa7a7}20.6 & \cellcolor[HTML]{faa7a7}13.7 \\
        Llama 3.1 8B        & 128K & 1K  & 76.7 (65.2) & \underline{65.7} & 54.4 & 44.1 & \cellcolor[HTML]{faa7a7}31.9 & \cellcolor[HTML]{faa7a7}22.6 & \cellcolor[HTML]{faa7a7}14.2 \\
		\bottomrule
	\end{tabular}
	\caption{\framework benchmark results on the selected models. Following \citet{hsieh2024ruler}, we report the effective length alongside the claimed supported context length for each model. However, we define the effective length as the maximum length at which the score remains above a threshold set at 85\% of the model's base score (shown in parentheses). Scores exceeding this threshold are \underline{underlined}. Scores that are below 50\% of the base score are shaded in \colorbox{shadedRed}{red}.}
	\label{tab:models_performance}
\end{table*}

