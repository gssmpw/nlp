\onecolumn

\section{Data preprocessing details}
\label{appendix_dataset}
\subsection{Medical Codes Dataset Creation}
The medical codes dataset consists of medical codes, their descriptions, and associated knowledge subgraphs, encompassing eight commonly used health coding systems: ICD-9-CM (procedures and diagnoses), ICD-10-CM, ICD-10-PCS, NDC (National Drug Codes), SNOMED CT, ATC (Anatomical Therapeutic Chemical Classification), CPT (Current Procedural Terminology), and RxNorm. All code lists were obtained from official sources. Specifically, ICD-9 and ICD-10 (CM and PCS) were sourced from the CMS website; NDC codes from the U.S. Food and Drug Administration (FDA) database; and CPT (Level I HCPCS) from the Physician Fee Schedule (PFS) Relative Value Files at CMS. SNOMED CT, RxNorm (active codes only), and ATC were downloaded via the National Library of Medicine (NLM), part of the National Institutes of Health (NIH).

\subsubsection{Medical Codes Knowledge Graphs Creation}
In the final dataset, each medical code is linked to a knowledge graph capturing relevant medical insights and relationships. We constructed these subgraphs in two steps: mapping each code to one or more nodes in the PrimeKG knowledge graph; and extracting node-centered subgraphs to represent the code’s associated knowledge and connections.
To facilitate mapping, we leveraged several external resources, notably the UMLS database and MONDO Disease Ontology files. Medical codes were first mapped to Concept Unique Identifiers (CUIs) in the UMLS database, then linked to PrimeKG nodes via a custom UMLS-to-PrimeKG file. Because PrimeKG includes MONDO annotations, we also aligned medical codes to MONDO terms using the mondo.owl file, thus achieving direct integration with PrimeKG nodes. Additionally, a custom entity linker was employed to enhance coverage by translating medical codes into descriptive text (via PyHealth’s MedCode InnerMap) and matching these descriptions to PrimeKG node names. When exact matches were unavailable, we resorted to an NLP-based linker (SciSpacy with UMLS) to measure semantic similarity. For drug codes, the rxnav.nlm.nih.gov API was used to map RxNorm codes to ATC identifiers, which were then associated with DrugBank entities through a predefined ATC-to-DrugBank mapping.

\subsubsection{Medical Codes Textual Definition Creation}
Initially, each medical code’s description was taken from its official source. For medication codes (e.g., NDC) where the original text was sparse, additional details were derived from attributes such as trade name, proprietary name, and pharmacological classification. These preliminary definitions were then refined and enriched using ChatGPT-4 (turbo), with prompts tailored to each coding system but sharing a common goal of elaborating on clinical uses (for drugs), procedural steps (for procedures), or mechanistic and clinical context (for diagnoses).

\section{Implementation details}\label{appendix_implementation}

\subsection{Experimental environments}
\xhdr{Hardware} \model is training on a machine equipped with 4 NVIDIA H100. All experiments were conducted with 1 NVIDIA H100.

\paragraph{Software.} We implement \model using Python 3.9.19, PyTorch 2.3.1, Transformers 4.43.1, and Tokenizers 0.19.1. All LMs and LLMs adopted in this study are downloaded from Hugging Face, except for OpenAI models.

\subsection{Details in \model training}
\model is trained on 4 NVIDIA H100 GPUs by using the loss defined in the Section 3.2. During the training stage, we set the training step as 3000 with a global batch size of 1024, the dimension of quantized vectors is 64. In terms of the models' weights, we freeze the text encoder in \model and the graph encoder is trainable during the training stage. 

\subsection{Implementation details of baseline models}
All results presented in this study were obtained using the same machine on which the \model was trained.

ETHOS experiments were conducted using the authors’ original repository. For each experimental setting, three models were trained on the MIMIC-IV dataset with different random seeds, and their predictions were averaged during inference to ensure robustness. In the "\model + ETHOS" configuration, the original vocabulary was extended to incorporate \model's tokens for diagnoses, procedures, and prescriptions. The lab measurements were excluded from the analysis.
Training and dataset splitting on MIMIC-IV adhered to the methodology outlined in the ETHOS paper \cite{ethos}. During inference, the number of generated tokens was limited to 2048, and the timeline duration was adjusted based on the specific task: fifteen days for readmission, two weeks for mortality, and up to six months for other tasks. Each model was executed five times, and the resulting predictions were averaged to produce a continuous output, as described in the ETHOS study.
Inference on the MIMIC-III dataset was performed on the entire dataset, excluding BMI, ICU stay tables, blood pressure, and lab data. For the EHRShot dataset, inference was conducted on the full dataset for mortality and disease-related tasks, and on randomly selected, stratified samples of ten thousand instances for other tasks.

As for the other baselines adopted in this work, we first downloaded their code and deploy these models on our working machine. For BEHRT and GT-BEHRT, we re-trained it in an end-to-end way and integrates the tokens for time, visit, and patient's info as that in their original work. For MulT-EHR, we first pre-train it on MIMIC-III, MIMIC-IV, and EHRShot, respectively, to get the embedding of medical codes, and next fine-tune it on multi-task learning. For the \model+, we use our token embeddings to initialize the nodes or tokens the original work adopted and then train or pre-train the model. It should be noted that we adopt a unified epoch number for all baselines, which is 50.

\section{Task definitions and data preparation under in-patient setting}\label{appendix_task_definitions}

\subsection{Mortality prediction}
\xhdr{Task definition}
Mortality (MT) prediction estimates the mortality label of the 
\emph{subsequent} visit for each sample, with the last sample dropped.
Formally,
\[
    f : (v_1, v_2, \ldots, v_{t-1}) \;\to\; y[v_t],
\]
where \(y[v_t] \in \{0, 1\}\) is a binary label indicating the patient’s 
survival status recorded in visit \(v_t\).

\subsection{Readmission prediction}
\xhdr{Task definition}
Readmission prediction checks if the patient will be readmitted
to the hospital within \(\sigma\) days. Formally, $f : (v_1, v_2, \ldots, v_{t-1}) \;\to\; y\bigl[\tau(v_t) - \tau(v_{t-1})\bigr]$,
where \(y \in \{0, 1\}\) and \(\tau(v_t)\) denotes the encounter time of visit
\(v_t\). Specifically,
\[
    y\bigl[\tau(v_t) - \tau(v_{t-1})\bigr] \;=\;
    \begin{cases}
        1 & \text{if } \tau(v_t) - \tau(v_{t-1}) \le \sigma,\\
        0 & \text{otherwise}.
    \end{cases}
\]
In our study, we set \(\sigma = 15\) days.

\subsection{Length-of-Stay (LOS) prediction}

\xhdr{Task definition}
Length-of-Stay (LOS) prediction follows the formulation of Harutyunyan et al., estimating ICU stay length for each visit. Formally, $f : (v_1, v_2, \ldots, v_t) \to y[v_t]$, where $y[v_t] \in \mathbb{R}^{1 \times C}$ is a one-hot vector indicating its class among $C$ possible categories. We define 10 classes, $\{0,1,\ldots,7,8,9\}$, representing the following durations: 0 for one day or less, 1-7 for within one week, 8 for one to two weeks, and 9 for at least two weeks.

\subsection{Phenotype prediction}
\xhdr{Task definition}
Phenotype prediction aims to classify which acute care conditions are present in a given patient record: $f: (v_1, v_2, ..., v_t) \rightarrow y[v_t]$, where $y[v_t] \in \mathbb{R}^{1 \times C}$ is a one-hot vector indicating its class among $C$ possible categories. This task is a multilable classification problem with macro-averaged AUC-ROC being the main metric.

\subsection{Drug recommendation}
\xhdr{Task definition}
Drug recommendation aims to recommend drugs for a patient according to the patient's visit history and diagnosis in current visit: $f: (v_1, v_2, ..., v_t) \rightarrow y[v_t]$, where $y[v_t] \in \mathbb{R}^{1 \times C}$ is a one-hot vector indicating its class among $C$ possible categories. This task is a multilable classification problem with macro-averaged AUC-ROC being the main metric.

\xhdr{Data preprocessing}
In this study, we adopted a data preprocessing approach similar to that used in previous research (https://doi.org/10.1038/s41597-019-0103-9), which defined 25 acute care conditions.  Each diagnosis code was mapped to one of these 25 phenotype categories. Since ICD-9 codes in MIMIC-III are associated with hospital visits rather than specific ICU stays, we linked diagnoses to ICU stays using the hospital admission identifier. To reduce ambiguity, we excluded hospital admissions involving multiple ICU stays, ensuring that each diagnosis corresponded to a single ICU stay per admission. It's important to note that our phenotype classification was retrospective; we analyzed the complete ICU stay before predicting the presence of specific diseases. 
In this study, we adopted a data preprocessing approach similar to that used in previous research (https://doi.org/10.1038/s41597-019-0103-9), which defined 25 acute care conditions.  Each diagnosis code was mapped to one of these 25 phenotype categories. Since ICD-9 codes in MIMIC-III are associated with hospital visits rather than specific ICU stays, we linked diagnoses to ICU stays using the hospital admission identifier. To reduce ambiguity, we excluded hospital admissions involving multiple ICU stays, ensuring that each diagnosis corresponded to a single ICU stay per admission. It's important to note that our phenotype classification was retrospective; we analyzed the complete ICU stay before predicting the presence of specific diseases. 

\subsection{Out-patient Setting}
Under this setting, we adopt two types of tasks in EHRShot, including operational outcomes prediction and assignment of new diagnosis. In the field of operational outcomes, we follow the same task definitions in long length of stay prediction, which only consider if a patient stay in the hospital less than 7 days or more than 7 days. In terms of readmission task, we set the time window as 15 days, which is the same as that under in-patient setting. We also add another operational outcome tash, which is mortality prediction. The definition of mortality prediction is the same as that under the in-patient setting.

