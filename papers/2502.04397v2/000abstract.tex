
Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning.  
%
We introduce \model, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. \model processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information.  
%
We integrate \model into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with \model improves AUPRC across all EHR models, by 4.10\% on MIMIC-III, 4.78\% on MIMIC-IV, and 11.30\% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using \model tokenizer with medical QA systems. 
%
Our results demonstrate the potential of \model as a unified tokenizer for medical codes, improving tokenization for medical foundation models.