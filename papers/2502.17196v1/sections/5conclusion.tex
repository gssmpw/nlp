\section{Conclusions}



This paper proposed a novel interpretable transformer-like architecture: Hindered Transformer. HiT enhances interpretability by decoupling contributions from individual image patches, enabling the extraction of saliency maps without external tools. 
Extensive experiments across multiple datasets demonstrated the improved interpretability benefits from HiT with a reasonable drop in performance. HiT presents a promising approach, offering favorable trade-offs for applications where interpretability is critical. 

Even though our proposed architecture has many advantages in the terms of interpretability, HiT has limiting factors: slow convergence and the potential challenges in capturing complex dependencies. Regarding the former, we believe that a more comprehensive hyperparameter search, which we were unable to conduct due to limited computational resources, could significantly reduce the training time. Regarding the latter, HiT has some token interactions during the self-attention mechanism, yet, it is indeed weaker than standard ViTs. This is troublesome for spatial tasks and would require substantial modifications, opening opportunities for future research.

