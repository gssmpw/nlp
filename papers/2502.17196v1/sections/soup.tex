
\section{Datasets}

As for the dataset, we evaluated HiT on six diverse image classification datasets: 
i) ImageNet~\cite{deng2009imagenet}:  A large-scale dataset with 1.2 million images and 1,000 classes, often used as a benchmark. 
ii) CUB-2011~\cite{WahCUB_200_2011}: A challenging dataset containing 200 bird classes with only 30 training samples per class on average.
iii) Stanford Dogs~\cite{KhoslaYaoJayadevaprakashFeiFei_FGVC2011}:  A dataset with 120 dog classes and 10,000 training and test images.
iv) Stanford Cars~\cite{krause20133d}:  A dataset featuring 196 car classes with 8,100 training and validation examples.
v) FGVC-Aircraft~\cite{maji13fine-grained}: A dataset of 100 airplance classes with 10,000 images.
vi) Oxford-IIIT Pets~\cite{parkhi12a}: a 37 category dataset with roughly 200 images per class.


\section{Insertion-Deletion Curves}

In Fig.~\ref{fig:soup:posthoc-curves}, we present the curves from the post-hoc comparison experiment detailed in \S~4.3 of the main document. HiT consistently outperforms both GradCAM~\cite{8237336} and Rollout Matrix~\cite{abnar2020quantifying} across all datasets. Interestigly, GradCAM achieves performance comparable to our method on all datasets except ImageNet~\cite{deng2009imagenet}. We hypothesize that this correlation stems from GradCAM being computed on the final layer tokens, which our analysis shows are the most important (Fig.~5 in the manuscript), except for ImageNet. %

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{soup-images/hit-id-posthoc.pdf}
    \caption{\textbf{Comparing HiT and alternative post-hoc methods.} This experiments reflects the interpretable advantages with respect to traditional post-hoc methods.}
    \label{fig:soup:posthoc-curves}
\end{figure}

\section{Evaluating HiT without Pooling Layers}

We conducted experiments similar to those in the main manuscript to analyze the positive and negative impact of removing pooling layers. As demonstrated in \S~4.7 of the paper, pooling layers are essential for improving top-1 accuracy performance. However, their inclusion increases the size of the explanations. First, we explore this phenomenon quantitatively in sections \ref{sec:soup:tradeoff} and \S~\ref{sec:soup:layer-contr}. Later, we will explore the qualitative differences in \S~\ref{sec:soup:qual}.


\subsection{Interpretability Trade-off} \label{sec:soup:tradeoff}

First, we explore the interpretability gains of HiT without pooling layers. We compare both HiT versions using the normalized insertion-deletion curves on all tested datasets, illustrated in Fig.~\ref{fig:soup:id-pool}. From a quantitative point of view, HiT without any pooling layer is even more interpretable than our proposed architecture. Interestingly, both curves behave similarly, showing a decrease in the insertion probability curve and an increase in the deletion probability curve during their final steps. This is due to the insertion (or deletion) of tokens that adversely affect the model's prediction. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{soup-images/id-hit-vs-pool.pdf}
    \caption{Caption}
    \label{fig:soup:id-pool}
\end{figure}

We also tested GradCAM~\cite{8237336} and the Rollout~\cite{abnar2020quantifying} Matrix directly on our pooling-free HiT architecture, with results shown in Table~\ref{tab:soup:interpretability}. The interpretability gap between post-hoc methods and HiT saliency maps is more pronounced compared to our standard HiT architecture.

\begin{table}[h]
    \centering
    \small
    \begin{tabular}{C{2.2cm}|C{1.25cm}C{1.25cm}|C{1.25cm}C{1.25cm}|C{1.25cm}C{1.25cm}|C{1.25cm}C{1.25cm}}\toprule
        \multirow{2}{*}{Method}       & \multicolumn{2}{c|}{ImageNet} & \multicolumn{2}{c|}{CUB 2011} & \multicolumn{2}{c|}{Stanford Cars} & \multicolumn{2}{c}{Stanford Dogs} \\ \cmidrule{2-9}
                     & Ins-Z (\ua) & Del-Z (\da) & Ins-Z (\ua) & Del-Z (\da) & Ins-Z (\ua) & Del-Z (\da) & Ins-Z (\ua) & Del-Z (\da) \\ \midrule
        HiT           & \textbf{0.65}  &\textbf{ 0.08}  & \textbf{0.56}  & \textbf{0.04}  & \textbf{0.72}  & \textbf{0.05}  & \textbf{0.64}  & \textbf{0.07} \\
        HiT + Rollout & 0.39  & 0.21  & 0.43  & 0.09  & 0.49  & 0.12  & 0.47  & 0.19 \\
        HiT + GradCAM & 0.36  & 0.15  & 0.40  & 0.09  & 0.34  & 0.11  & 0.40  & 0.15 \\ \midrule
                      & Ins-B (\ua) & Del-B (\da) & Ins-B (\ua) & Del-B (\da) & Ins-B (\ua) & Del-B (\da) & Ins-B (\ua) & Del-B (\da) \\ \midrule
        HiT           &  \textbf{0.67} & \textbf{0.16}  & \textbf{0.59}  & \textbf{0.11}  & \textbf{0.65}  & \textbf{0.15}  & \textbf{0.62}  & \textbf{0.18} \\
        HiT + Rollout & 0.47  & 0.31  & 0.50  & 0.22  & 0.50  & 0.29  & 0.50  & 0.32 \\
        HiT + GradCAM & 0.48  & 0.29  & 0.52  & 0.21  & 0.51  & 0.29  & 0.52  & 0.31 \\ \bottomrule
    \end{tabular}
    \caption{\textbf{HiT and Explainability methods:} We quantitatively compare HiT maps and those created by GradCAM and the modified rollout matrix (mean attention). The assessment shows that HiT maps are in fact more faithful to those generated by GradCAM and the rollout matrix. Higher insertion is better, while lower deletion is better. Ins and Del refers to the Insertion and Deletion metrics, respectively. Z is the zero-corrupted image, while B is the blurred corruption strategy.}
    \label{tab:soup:interpretability}
\end{table}


Finally, in Tab.~\ref{tab:soup:accuracy}, we show the performance on the tested datasets. Without any surprise, the loss in performance is major, making it a less appealing option in contrast to our original architecture when computation power is needed. 

\begin{table}[h]
    \centering
    \begin{tabular}{C{0.1\textwidth}|C{0.12\textwidth}|C{0.12\textwidth}C{0.12\textwidth}C{0.12\textwidth}C{0.12\textwidth}}\toprule
        \textbf{Model}   & \textbf{Pooling?} & \textbf{ImageNet} & \textbf{CUB}     & \textbf{Dogs} & \textbf{Cars} \\ \midrule
        \multirow{2}{*}{HiT-S} & $\chi$       & 67.3     & 76.1    & 77.1 & 83.9\\
                               & $\checkmark$ & 71.4     & 76.1    & 80.3 & 85.2 \\ \midrule
        \multirow{2}{*}{HiT-B} & $\chi$       & 71.5     & 76.3    & 80.2 & 84.7\\
                               & $\checkmark$ & 75.0     & 79.0    & 86.8 & 86.2 \\ \bottomrule
    \end{tabular}
    \caption{\textbf{Top1 Accuracy.} Including pooling layers provides a clear advantage in terms of raw performance. However, this performance gain comes at the cost of reduced interpretability.}  %
    \label{tab:soup:accuracy}
\end{table}


\subsection{Layer-wise Contributions} \label{sec:soup:layer-contr}

Next, we investigate the ability of the pooling-free HiT to analyze layer-wise contributions. Fig.~\ref{fig:soup:layer-saliency} illustrates the layer contribution per dataset, while Fig.~\ref{fig:soup:layer-saliency-exps} plots the ablation results on ImageNet~\cite{deng2009imagenet}. Similar to HiT with layer pooling, the most significant contributions come from the final layers. However, unlike the HiT version with pooling layers, all trained models appear to weight their final predictions equally across the last three layers.

\begin{figure}[h]
    \centering
        \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/saliency-layer-dset.pdf}
        \caption{Layer Saliency.}
        \label{fig:soup:layer-saliency}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{images/saliency-layer-exps.pdf}
        \caption{Empirical validation of layer-wise saliency.}
        \label{fig:soup:layer-saliency-exps}
    \end{subfigure}
    \caption{As in the main manuscript, we assess our pooling-free HiT layer contribution. Effectively, HiT can discover the contributions for each layer.}
    \label{fig:my_label}
\end{figure}

\subsection{Qualitative Comparison} \label{sec:soup:qual}

Finally, we qualitatively show the difference between the pool-free HiT and our original version saliency maps in Fig.~\ref{fig:soup:qualitative} in ImageNet~\cite{deng2009imagenet}. As expected, removing the pooling layers produces finer saliency maps.

\begin{figure*}[h]
    \centering
    \includegraphics[width=\linewidth]{soup-images/qual-hit.pdf}
    \caption{\textbf{Qualitative Examples:} we visually show the difference between HiT saliency maps with and without pooling layers on some correctly classified images from the ImageNet dataset.}
    \label{fig:soup:qualitative}
\end{figure*}
