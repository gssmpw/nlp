\section{Related Work}
In this section, we briefly review three key categories of research relevant to the current work: traditional CL methods, ER-based methods, and output correction methods. The strengths and weaknesses of each method are briefly discussed.
\subsection{CL Methods}

Contemporary CL methodologies predominantly fall into three categories **Li et al., "Deep Transfer Learning"**. Regularization-based approaches penalize parameter updates to enforce convergence within a shared representation space across diverse tasks **Ioffe et al., "Batch Normalization"**. These approaches tackle the problem of catastrophic forgetting by constraining the parameter update methods. However, they faces challenges in balancing between stability and plasticity, often resulting in suboptimal performance and high computational cost. Memory-based strategies integrate prior task knowledge through sample or representation-based memory adjustments during training **Kemker et al., "Measuring Catastrophic Forgetting"**. While these methods effectively retain valuable knowledge across tasks, they require storing a subset of training samples and may introduce prediction bias to some extent due to issues with the training data distribution. Dynamic structures-based approaches adapt network architectures to ensure task-specific parameter isolation, accommodating the integration of novel tasks **Srivastava et al., "Dropout: A Simple Way"**.  These approaches address the issue of interference by isolating task-specific knowledge, but they struggle with computational efficiency and spatial scalability as the number of tasks increases. Thus, methods in OCL often combine with memory-based strategies. However, challenges remain in striking a balance between memory usage, computational efficiency, and maintaining performance on non-stationary data streams.


\subsection{ER-based Methods}

Existing effective approaches in OCL typically adopt strategies that involve replaying samples or representations. To mitigate catastrophic forgetting caused by task changes, ICaRL **Rebuffi et al., "iCaRL: Incremental Classifier and Representation Learning"** combines distillation loss with binary cross-entropy, classifying samples based on nearest-class prototypes computed from buffered data representations, which is suitable for class incremental learning scenarios where each task is sufficiently trained. However, in OCL scenarios, iCaRL often underperforms due to insufficient training on newer tasks. ER **Chen et al., "Improved Deep Learning with Conditional Channel Attention"** employs a fixed-size replay buffer, randomly replaying a subset of samples. Despite its simplicity, ER faces challenges in maintaining performance when learning from both replayed samples and data stream samples simultaneously. To address this issue, GDumb **Louizos et al., "Learning to Balance"** maintains a class-balanced memory pool and trains the model exclusively on these samples, although the size of the memory pool often constrains its effectiveness. MIR **Van et al., "Mining Inductive Bias from Powerfully Generalized Representations"** introduces an alternative improvement to ER by selecting samples that maximize the increase in loss during replay. This method further reduces prediction bias, albeit at the cost of increased computational burden. For loss calculation, DER++ **Liu et al., "DER++: Online Learning via Re-rehearsal for Deep Neural Networks"** employs distillation loss on logits to enforce consistency over time, while ACE **Parascandolo et al., "Task-Free Progressive Neural Tuning"** mitigates sudden representation changes using an asymmetric update rule. Although DER++ and ACE are promising in stabilizing learned knowledge, they fail to resolve the issue of spatially or structurally imbalanced parameter updates across the network, which can lead to significant prediction bias. 

\subsection{Output Correction Methods}
In OCL scenarios, prediction bias is closely related to rapid updates of the output classifier during backpropagation **Jang et al., "CWR*++: A Novel Class-Wise Rehearsal Strategy for Class-Incremental Learning"**. OBC **Golkar et al., "Output-based Calibration in Neural Networks"** independently optimizes output classifier to correct significant prediction bias during training. AR1* ____ combines latent replay methods with optimized output classifier updates from CWR* to enhance performance. The CWR* method aligns the parameters in the output classifier with individual categories. It adjusts the update magnitude of these parameters based on the ratio of the frequency of data from a particular class in past occurrences to its frequency in a single training iteration, thereby correcting prediction bias. These strategies address the bias in the output classifier but do not simultaneously correct the bias in other parameters, leaving room for further improvement. 

Although the three types of methods discussed above do not directly address the issue of parameter variation imbalance, they provide foundational ideas that have informed our approach to solving this problem. ER effectively mitigates catastrophic forgetting caused by non-IID data distributions in streaming tasks, while asymmetric cross entropy (ACE) helps achieve more accurate and balanced gradient updates. These strategies contribute to balancing parameter variations during OCL training to some extent, and thus, we integrate these concepts into our proposed framework. Furthermore, previous work on special handling of the output classifier has inspired our approach to addressing the issue of layer-wise imbalance.