\section{Related Work}
In this section, we briefly review three key categories of research relevant to the current work: traditional CL methods, ER-based methods, and output correction methods. The strengths and weaknesses of each method are briefly discussed.
\subsection{CL Methods}

Contemporary CL methodologies predominantly fall into three categories ____. Regularization-based approaches penalize parameter updates to enforce convergence within a shared representation space across diverse tasks ____. These approaches tackle the problem of catastrophic forgetting by constraining the parameter update methods. However, they faces challenges in balancing between stability and plasticity, often resulting in suboptimal performance and high computational cost. Memory-based strategies integrate prior task knowledge through sample or representation-based memory adjustments during training ____. While these methods effectively retain valuable knowledge across tasks, they require storing a subset of training samples and may introduce prediction bias to some extent due to issues with the training data distribution. Dynamic structures-based approaches adapt network architectures to ensure task-specific parameter isolation, accommodating the integration of novel tasks ____.  These approaches address the issue of interference by isolating task-specific knowledge, but they struggle with computational efficiency and spatial scalability as the number of tasks increases. Thus, methods in OCL often combine with memory-based strategies. However, challenges remain in striking a balance between memory usage, computational efficiency, and maintaining performance on non-stationary data streams.


\subsection{ER-based Methods}

Existing effective approaches in OCL typically adopt strategies that involve replaying samples or representations. To mitigate catastrophic forgetting caused by task changes, ICaRL ____ combines distillation loss with binary cross-entropy, classifying samples based on nearest-class prototypes computed from buffered data representations, which is suitable for class incremental learning scenarios where each task is sufficiently trained. However, in OCL scenarios, iCaRL often underperforms due to insufficient training on newer tasks. ER ____ employs a fixed-size replay buffer, randomly replaying a subset of samples. Despite its simplicity, ER faces challenges in maintaining performance when learning from both replayed samples and data stream samples simultaneously. To address this issue, GDumb ____ maintains a class-balanced memory pool and trains the model exclusively on these samples, although the size of the memory pool often constrains its effectiveness. MIR ____ introduces an alternative improvement to ER by selecting samples that maximize the increase in loss during replay. This method further reduces prediction bias, albeit at the cost of increased computational burden. For loss calculation, DER++ ____ employs distillation loss on logits to enforce consistency over time, while ACE ____ mitigates sudden representation changes using an asymmetric update rule. Although DER++ and ACE are promising in stabilizing learned knowledge, they fail to resolve the issue of spatially or structurally imbalanced parameter updates across the network, which can lead to significant prediction bias. 

\subsection{Output Correction Methods}
In OCL scenarios, prediction bias is closely related to rapid updates of the output classifier during backpropagation ____. OBC ____ independently optimizes output classifier to correct significant prediction bias during training. AR1* ____ combines latent replay methods with optimized output classifier updates from CWR* to enhance performance. The CWR* method aligns the parameters in the output classifier with individual categories. It adjusts the update magnitude of these parameters based on the ratio of the frequency of data from a particular class in past occurrences to its frequency in a single training iteration, thereby correcting prediction bias. These strategies address the bias in the output classifier but do not simultaneously correct the bias in other parameters, leaving room for further improvement. 

Although the three types of methods discussed above do not directly address the issue of parameter variation imbalance, they provide foundational ideas that have informed our approach to solving this problem. ER effectively mitigates catastrophic forgetting caused by non-IID data distributions in streaming tasks, while asymmetric cross entropy (ACE) helps achieve more accurate and balanced gradient updates. These strategies contribute to balancing parameter variations during OCL training to some extent, and thus, we integrate these concepts into our proposed framework. Furthermore, previous work on special handling of the output classifier has inspired our approach to addressing the issue of layer-wise imbalance.
\iffalse
\begin{table*}[htbp]
    \label{tab:labels}
	\caption{Symbol list of our work}
    \centering
	\begin{tabularx}{\textwidth}{p{0.08\textwidth}X}
		\toprule	
		\underline{\textbf{\emph{Indices}}} \\
		$K$ & number of task identifiers $(k \in \{1,...,K\})$  \\ 
		$T$ & number of time steps $(t \in \{1,...,T\})$ \\
        $M$ & number of network parameters $(m \in \{1,...,M\})$ \\
		\underline{\textbf{\emph{Notations}}} \\  
		$\boldsymbol{\Theta}$  & the neural network parameters \\
		$\mathbf{D}_{k}$      & training samples for task $k$ \\
		$\mathbf{X}_{k}$    & training input data (images) of task $k$  \\
        $\mathbf{Y}_{k}$    & labels of task $k$  \\
		$\mathbf{X}^{in}_t$     & coming input data (images) at time step $t$\\
        $\mathbf{Y}^{in}_t$     & coming labels at time step $t$\\
        $\mathbf{X}^{bf}_t$     & coming rehearsal data (images) at time step $t$\\
        $\mathbf{Y}^{old}_t$ & the classes encountered up to time step $t$ \\
        $\mathbf{Y}^{curr}_t $ & current classes of training samples in input stream at time step t\\
        $\theta_{m,k}$     & the parameter ranked $m$ after optimized through task $k$   \\
		$\delta_{m,k}$     & the variation in parameter ranked $m$ between task \( k \) and \( k-1 \)\\
        $\Bar{\delta}_{k}$ & the mean value of the parameter variations of task $k$ \\

        $\delta'_{m,k}$     &  the relative change in parameter ranked $m$ between task \( k \) and \( k-1 \) \\
		$\boldsymbol{V}_k$   & $\{\delta_{1,k}^{'}, \ldots, \delta^{'}_{M,k}\}$, the set of relative changes\\
		$C_{m,k}$ &  the correlation of parameter $m$ with the memory of task $k$\\
		$C_m$   &  the correlation of parameter $m$ with all previously experienced tasks\\
		$g_{m,t}$ & the gradient obtained by neuron $m$ through gradient descent at time step $t$\\
		$g_{m,t}^{'}$   & the adjusted gradient for neuron $m$ at time step $t$\\
		$\omega_{j,t}$  & the $j$-th parameter of the output classifier\\
		$S_t$   & the set of sample labels input to the model, at time step $t$  \\
		$M^s_{j,t}$   & the sensory memory of the model for class $j$ at time time step $t$  \\
		$M^c_{j,t}$ & short-term memory for class $j$ at time step $t$ \\
		$\eta^c_{j,t}$   &  the short-term memory retention coefficient for class $j$ at time step $t$\\
  	$\eta^l_{j,t}$   &  the long-term memory retention coefficient for class $j$ at time step $t$\\
		$M^l_{j,t}$   &  the model's long-term memory for class $j$ at time step $t$ \\
        $P_{j,t}$   &  the number of times class $j$ has appeared during the model training process at time step $t$ \\
        $U_{j,t}$   &  the number of occurrences of class $j$ in the label set $S_t$ \\
		\bottomrule
	\end{tabularx}
\end{table*}
\fi