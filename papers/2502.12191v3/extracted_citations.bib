@inproceedings{cao2023learn,
  title={Learn from Incomplete Tactile Data: Tactile Representation Learning with Masked Autoencoders},
  author={Cao, Guanqun and Jiang, Jiaqi and Bollegala, Danushka and Luo, Shan},
  booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={10800--10805},
  year={2023},
  organization={IEEE}
}

@article{cheng2024tlv,
  title={Towards Comprehensive Multimodal Perception: Introducing the Touch-Language-Vision Dataset},
  author={Cheng, Ning and Li, You and Gao, Jing and Fang, Bin and Xu, Jinan and Han, Wenjuan},
  journal={arXiv preprint arXiv:2403.09813},
  year={2024}
}

@article{cheng2024touch100k,
  title={Touch100k: A Large-Scale Touch-Language-Vision Dataset for Touch-Centric Multimodal Representation},
  author={Cheng, Ning and Guan, Changhao and Gao, Jing and Wang, Weihao and Li, You and Meng, Fandong and Zhou, Jie and Fang, Bin and Xu, Jinan and Han, Wenjuan},
  journal={arXiv preprint arXiv:2406.03813},
  year={2024}
}

@inproceedings{dave2024multimodal,
  title={Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training},
  author={Dave, Vedant and Lygerakis, Fotios and R{\"u}ckert, Elmar},
  booktitle={Proceedings/IEEE International Conference on Robotics and Automation},
  year={2024},
  organization={Institute of Electrical and Electronics Engineers}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{donlon2018gelslim,
  title={Gelslim: A high-resolution, compact, robust, and calibrated tactile-sensing finger},
  author={Donlon, Elliott and Dong, Siyuan and Liu, Melody and Li, Jianhua and Adelson, Edward and Rodriguez, Alberto},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1927--1934},
  year={2018},
  organization={IEEE}
}

@article{feng2024play,
  title={Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic Manipulation},
  author={Feng, Ruoxuan and Hu, Di and Ma, Wenke and Li, Xuelong},
  journal={arXiv preprint arXiv:2408.01366},
  year={2024}
}

@inproceedings{gao2022objectfolder2,
  title={Objectfolder 2.0: A multisensory object dataset for sim2real transfer},
  author={Gao, Ruohan and Si, Zilin and Chang, Yen-Yu and Clarke, Samuel and Bohg, Jeannette and Fei-Fei, Li and Yuan, Wenzhen and Wu, Jiajun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10598--10608},
  year={2022}
}

@article{george2024visuo,
  title={Visuo-Tactile Pretraining for Cable Plugging},
  author={George, Abraham and Gano, Selam and Katragadda, Pranav and Farimani, Amir Barati},
  journal={arXiv preprint arXiv:2403.11898},
  year={2024}
}

@inproceedings{glorot2011domain,
  title={Domain adaptation for large-scale sentiment classification: A deep learning approach},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={513--520},
  year={2011}
}

@misc{gupta2025sensorinvarianttactilerepresentation,
      title={Sensor-Invariant Tactile Representation}, 
      author={Harsh Gupta and Yuchen Mo and Shengmiao Jin and Wenzhen Yuan},
      year={2025},
      eprint={2502.19638},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2502.19638}, 
}

@inproceedings{guzhov2022audioclip,
  title={Audioclip: Extending clip to image, text and audio},
  author={Guzhov, Andrey and Raue, Federico and Hees, J{\"o}rn and Dengel, Andreas},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={976--980},
  year={2022},
  organization={IEEE}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

@inproceedings{higuerasparsh,
  title={Sparsh: Self-supervised touch representations for vision-based tactile sensing},
  author={Higuera, Carolina and Sharma, Akash and Bodduluri, Chaithanya Krishna and Fan, Taosha and Lancaster, Patrick and Kalakrishnan, Mrinal and Kaess, Michael and Boots, Byron and Lambeta, Mike and Wu, Tingfan and others},
  booktitle={8th Annual Conference on Robot Learning},
year={2024}
}

@article{kerr2022ssvtp,
  title={Self-supervised visuo-tactile pretraining to locate and follow garment features},
  author={Kerr, Justin and Huang, Huang and Wilcox, Albert and Hoque, Ryan and Ichnowski, Jeffrey and Calandra, Roberto and Goldberg, Ken},
  journal={arXiv preprint arXiv:2209.13042},
  year={2022}
}

@inproceedings{kim2022style,
  title={A style-aware discriminator for controllable image translation},
  author={Kim, Kunhee and Park, Sanghun and Jeon, Eunyeong and Kim, Taehun and Kim, Daijin},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18239--18248},
  year={2022}
}

@article{lambeta2020digit,
  title={Digit: A novel design for a low-cost compact high-resolution tactile sensor with application to in-hand manipulation},
  author={Lambeta, Mike and Chou, Po-Wei and Tian, Stephen and Yang, Brian and Maloon, Benjamin and Most, Victoria Rose and Stroud, Dave and Santos, Raymond and Byagowi, Ahmad and Kammerer, Gregg and others},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={3},
  pages={3838--3845},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lei2024vitlen,
  title={Vit-lens: Towards omni-modal representations},
  author={Lei, Weixian and Ge, Yixiao and Yi, Kun and Zhang, Jianfeng and Gao, Difei and Sun, Dylan and Ge, Yuying and Shan, Ying and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26647--26657},
  year={2024}
}

@inproceedings{li2014localization,
  title={Localization and manipulation of small parts using gelsight tactile sensing},
  author={Li, Rui and Platt, Robert and Yuan, Wenzhen and Ten Pas, Andreas and Roscup, Nathan and Srinivasan, Mandayam A and Adelson, Edward},
  booktitle={2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3988--3993},
  year={2014},
  organization={IEEE}
}

@article{li2022see,
  title={See, hear, and feel: Smart sensory fusion for robotic manipulation},
  author={Li, Hao and Zhang, Yizhi and Zhu, Junzhe and Wang, Shaoxiong and Lee, Michelle A and Xu, Huazhe and Adelson, Edward and Fei-Fei, Li and Gao, Ruohan and Wu, Jiajun},
  journal={arXiv preprint arXiv:2212.03858},
  year={2022}
}

@inproceedings{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{rodriguez2024touch2touch,
  title={Touch2Touch: Cross-Modal Tactile Generation for Object Manipulation},
  author={Rodriguez, Samanta and Dou, Yiming and Oller, Miquel and Owens, Andrew and Fazeli, Nima},
  journal={arXiv preprint arXiv:2409.08269},
  year={2024}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{wang2022english,
  title={English contrastive learning can learn universal cross-lingual sentence embeddings},
  author={Wang, Yau-Shian and Wu, Ashley and Neubig, Graham},
  journal={arXiv preprint arXiv:2211.06127},
  year={2022}
}

@article{xu2024unit,
  title={UniT: Unified Tactile Representation for Robot Learning},
  author={Xu, Zhengtong and Uppuluri, Raghava and Zhang, Xinwei and Fitch, Cael and Crandall, Philip Glen and Shou, Wan and Wang, Dongyi and She, Yu},
  journal={arXiv preprint arXiv:2408.06481},
  year={2024}
}

@inproceedings{xue2023ulip,
  title={Ulip: Learning a unified representation of language, images, and point clouds for 3d understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1179--1189},
  year={2023}
}

@article{yang2022touch,
  title={Touch and go: Learning from human-collected vision and touch},
  author={Yang, Fengyu and Ma, Chenyang and Zhang, Jiacheng and Zhu, Jing and Yuan, Wenzhen and Owens, Andrew},
  journal={arXiv preprint arXiv:2211.12498},
  year={2022}
}

@inproceedings{yang2024binding,
  title={Binding touch to everything: Learning unified multimodal tactile representations},
  author={Yang, Fengyu and Feng, Chao and Chen, Ziyang and Park, Hyoungseob and Wang, Daniel and Dou, Yiming and Zeng, Ziyao and Chen, Xien and Gangopadhyay, Rit and Owens, Andrew and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={26340--26353},
  year={2024}
}

@article{yu2024octopi,
  title={Octopi: Object Property Reasoning with Large Tactile-Language Models},
  author={Yu, Samson and Lin, Kelvin and Xiao, Anxing and Duan, Jiafei and Soh, Harold},
  journal={arXiv preprint arXiv:2405.02794},
  year={2024}
}

@article{yuan2017gelsight,
  title={Gelsight: High-resolution robot tactile sensors for estimating geometry and force},
  author={Yuan, Wenzhen and Dong, Siyuan and Adelson, Edward H},
  journal={Sensors},
  volume={17},
  number={12},
  pages={2762},
  year={2017},
  publisher={MDPI}
}

@article{zhang2022tac3d,
  title={Tac3D: A novel vision-based tactile sensor for measuring forces distribution and estimating friction coefficient distribution},
  author={Zhang, Lunwei and Wang, Yue and Jiang, Yao},
  journal={arXiv preprint arXiv:2202.06211},
  year={2022}
}

@article{zhang2024duragel,
  title={A compact visuo-tactile robotic skin for micron-level tactile perception},
  author={Zhang, Shixin and Yang, Yiyong and Sun, Fuchun and Bao, Lei and Shan, Jianhua and Gao, Yuan and Fang, Bin},
  journal={IEEE Sensors Journal},
  year={2024},
  publisher={IEEE}
}

@article{zhang2025artificial,
  title={Artificial Skin Based on Visuo-Tactile Sensing for 3D Shape Reconstruction: Material, Method, and Evaluation},
  author={Zhang, Shixin and Yang, Yiyong and Sun, Yuhao and Liu, Nailong and Sun, Fuchun and Fang, Bin},
  journal={Advanced Functional Materials},
  volume={35},
  number={1},
  pages={2411686},
  year={2025},
  publisher={Wiley Online Library}
}

@inproceedings{zhao2019learning,
  title={On learning invariant representations for domain adaptation},
  author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
  booktitle={International conference on machine learning},
  pages={7523--7532},
  year={2019},
  organization={PMLR}
}

@article{zhao2023leveraging,
  title={Leveraging multi-lingual positive instances in contrastive learning to improve sentence embedding},
  author={Zhao, Kaiyan and Wu, Qiyu and Cai, Xin-Qiang and Tsuruoka, Yoshimasa},
  journal={arXiv preprint arXiv:2309.08929},
  year={2023}
}

@article{zhao2024transferable,
  title={Transferable Tactile Transformers for Representation Learning Across Diverse Sensors and Tasks},
  author={Zhao, Jialiang and Ma, Yuxiang and Wang, Lirui and Adelson, Edward H},
  journal={arXiv preprint arXiv:2406.13640},
  year={2024}
}

@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2223--2232},
  year={2017}
}

