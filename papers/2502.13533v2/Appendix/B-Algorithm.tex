\begin{algorithm}[ht]
\small
\caption{\method (Memory-Efficient LoRA Training)}
\label{algo:loram}
\begin{algorithmic}[1]
\Require 
original full-rank pre-trained weight $\mathbf{W}_0$, 
alignment corpus $\mathcal{D}_\mathtt{A}$, 
and flags $\mathcal{F}^\mathtt{P}, \mathcal{F}^\mathtt{A}$, $\mathcal{F}^\mathtt{Q}, \mathcal{F}^\mathtt{R}$.

\State \mydarkcolor{\textbf{Offline $\mathbf{W}_{0}^{*}$ Process Stage:}}
\If{$\mathcal{F}^\mathtt{P}$}
    \State $\mathbf{W}_{0}^\mathtt{P} = \mathtt{P}(\mathbf{W}_{0}) =  \mathbf{W}_0 \circ \mathbf{M}^\mathtt{P}$  \Comment{\mydarkcolor{Pruned Full-Rank Weight Generation.}}
    \If{$\mathcal{F}^\mathtt{A}$} 
        \State $\mathbf{W}_{0}^\mathtt{P,A} \gets \text{argmin} {\ } \mathcal{L}_{\mathtt{A}}(\mathcal{D}_\mathtt{A};\mathbf{W}_{0}^\mathtt{P})$ 
        \Comment{\mydarkcolor{Pruned Full-Rank Weight Alignment.}}
        \If{$\mathcal{F}^\mathtt{Q}$}
        \State $\mathbf{W}_{0}^\mathtt{P,A,Q} = \mathtt{Q}(\mathbf{W}_{0}^\mathtt{P,A})$
        \Comment{\mydarkcolor{Pruned Full-Rank Weight Quantization.}}
        \EndIf
        \ElsIf{$\mathcal{F}^\mathtt{Q}$}
        \State $\mathbf{W}_{0}^\mathtt{P,Q} = \mathtt{Q}(\mathbf{W}_{0}^\mathtt{P})$
    \EndIf
    \ElsIf{$\mathcal{F}^\mathtt{Q}$} 
    \State $\mathbf{W}_{0}^\mathtt{Q} = \mathtt{Q}(\mathbf{W}_{0})$ \Comment{\mydarkcolor{Standard Quantization for LoRA}}
\EndIf

\State{Record the processing result of $\mathbf{W}_{0}$ as $\mathbf{W}_{0}^{*}$, $* \in \{\mathtt{NULL},\mathtt{P},\mathtt{Q},\mathtt{(P,Q)},\mathtt{(P,A)},\mathtt{(P,A,Q)}\}$.}
\\
\State \mydarkcolor{\textbf{Online $\mathbf{W}_{\Delta}^{*}$ Training Stage:}} 

\If{$\mathcal{F}^\mathtt{P}$} \Comment{\mydarkcolor{Pruned Low-Rank Matrix Generation.}}
    \State $\mathbf{W}_{\Delta}^\mathtt{P} = \
    \mathbf{B}^\mathtt{P}\mathbf{A}^\mathtt{P} = \
    \mathtt{P}(\mathbf{W}_{\Delta}) =  \ 
    \mathbf{W}_{\Delta} \circ \mathbf{M}^\mathtt{P} = \
    \mathbf{B}\mathbf{A} \circ \mathbf{M}^\mathtt{P}$
    \While  {$\textsc{Training}$} \Comment{\mydarkcolor{Pruned Low-Rank Matrix Training.}}
    \State Update low-rank matrix via objective $\mathcal{L}_{\mathtt{SFT}}$ with the forward pass $\mathbf{h} = \mathbf{x} \mathbf{W}_{0}^\mathtt{*} + \mathbf{x}\mathbf{W}_{\Delta}^\mathtt{P}$.
    \State Return trained low-rank matrix $\mathbf{W}_{\Delta}^{\mathtt{P}^{\star}}=\mathbf{B}^{\mathtt{P}^{\star}}\mathbf{A}^{\mathtt{P}^{\star}}$.
    \EndWhile
    \If{$\mathcal{F}^\mathtt{R}$} \Comment{\mydarkcolor{Recovered Low-Rank Matrix Generation.}}
    \State $\mathbf{W}_{\Delta}^{\mathtt{R}^{\star}} = \ 
    \mathbf{B}^{\mathtt{R}^{\star}}\mathbf{A}^{\mathtt{R}^{\star}} = \ 
    \mathtt{R}(\mathbf{W}_{\Delta}^{\mathtt{P}^{\star}}) = \ 
    \mathbf{W}_{\Delta}^{\mathtt{P}^{\star}} \circ (1-\mathbf{M}^\mathtt{P})$
    \Comment{\mydarkcolor{Structured \method}}
    \Else
    \State $\mathbf{W}_{\Delta}^{\mathtt{R}^{\star}} = \ 
    \mathbf{B}^{\mathtt{R}^{\star}}\mathbf{A}^{\mathtt{R}^{\star}} = \ 
    \mathbf{B}^{\mathtt{P}^{\star}}\mathbf{A}^{\mathtt{P}^{\star}}$
    \Comment{\mydarkcolor{Non-structured \method}}
    \EndIf
\Else
    \While  {$\textsc{Training}$} \Comment{\mydarkcolor{Standard LoRA Training.}}
    \State Update low-rank matrix via objective $\mathcal{L}_{\mathtt{SFT}}$ with the forward pass $\mathbf{h} = \mathbf{x} \mathbf{W}_{0}^\mathtt{*} + \mathbf{x}\mathbf{W}_{\Delta}$.
    \State Return trained low-rank matrix $\mathbf{W}_{\Delta}^{\star}=\mathbf{B}^{\star}\mathbf{A}^{\star}$.
    \EndWhile
\EndIf

\State{Record the trained low-rank matrix as $\mathbf{W}_{\Delta}^{*}$, $* \in \{{\mathtt{R}^{\star},\star}\}$.}
\\
\State \mydarkcolor{\textbf{Online $\mathbf{W}_{0},\mathbf{W}_{\Delta}^{*}$ Inference Stage:}} 
\While {$\textsc{Inference}$ with {$*$ is $\mathtt{R}^{\star}$}} \Comment{\mydarkcolor{Recovered Low-Rank Matrix Inference.}}
\State Perform inference with the forward pass $\mathbf{h} 
= \mathbf{x} (\mathbf{W}_0 + \mathbf{W}_{\Delta}^{\mathtt{R}^{\star}}) = \mathbf{x} (\mathbf{W}_0 + \mathbf{B}^{\mathtt{R}^{\star}}\mathbf{A}^{\mathtt{R}^{\star}})$.
\EndWhile

\While {$\textsc{Inference}$ with {$*$ is ${\star}$}} \Comment{\mydarkcolor{Standard LoRA Inference.}}
\State Perform Inference with the forward pass $\mathbf{h} 
= \mathbf{x} (\mathbf{W}_0 + \mathbf{W}_{\Delta}^{\star}) = \mathbf{x} (\mathbf{W}_0 + \mathbf{B}^{\star}\mathbf{A}^{\star})$.
\EndWhile

\end{algorithmic}
\end{algorithm}



