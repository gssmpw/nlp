@inproceedings{sohn2024streaming,
    title={Streaming Tensor Programs: A Programming Abstraction for Streaming Dataflow Accelerators},
    author={Sohn, Gina and Gyurgyik, Christophe and Zhang, Genghan and Velury, Suguna and Mure, Paul and Zhang, Nathan and Olukotun, Kunle},
    booktitle={ASPLOS Young Architect Workshop (YArch)},
    year={2024},
    location={San Diego, CA, USA}
}
@inproceedings{prabhakar2024sambanova,
  title={Sambanova sn40l: Scaling the ai memory wall with dataflow and composition of experts},
  author={Prabhakar, Raghu and Sivaramakrishnan, Ram and Gandhi, Darshan and Du, Yun and Wang, Mingran and Song, Xiangyu and Zhang, Kejie and Gao, Tianren and Wang, Angela and Li, Xiaoyan and others},
  booktitle={2024 57th IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={1353--1366},
  year={2024},
  organization={IEEE}
}
@inproceedings{prabhakar2017plasticine,
  title={Plasticine: A Reconfigurable Architecture For Parallel Paterns},
  author={Prabhakar, Raghu and Zhang, Yaqi and Koeplinger, David and Feldman, Matt and Zhao, Tian and Hadjis, Stefan and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
  booktitle={Proceedings of the 44th Annual International Symposium on Computer Architecture},
  pages={389--402},
  year={2017}
}
@inproceedings{prabhakar2021sambanova,
  title={SambaNova SN10 RDU: Accelerating software 2.0 with dataflow},
  author={Prabhakar, Raghu and Jairath, Sumti},
  booktitle={2021 IEEE Hot Chips 33 Symposium (HCS)},
  pages={1--37},
  year={2021},
  organization={IEEE}
}
@inproceedings{chen2023ai,
  title={AI SoC Design Challenges in the Foundation Model Era},
  author={Chen, Zhengyu and Huang, Dawei and Wang, Mingran and Yang, Bowen and Shin, Jinuk Luke and Hu, Changran and Li, Bo and Prabhakar, Raghu and Deng, Gao and Sheng, Yongning and others},
  booktitle={2023 IEEE Custom Integrated Circuits Conference (CICC)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}
@article{sujeeth2014delite,
  title={Delite: A compiler architecture for performance-oriented embedded domain-specific languages},
  author={Sujeeth, Arvind K and Brown, Kevin J and Lee, Hyoukjoong and Rompf, Tiark and Chafi, Hassan and Odersky, Martin and Olukotun, Kunle},
  journal={ACM Transactions on Embedded Computing Systems (TECS)},
  volume={13},
  number={4s},
  pages={1--25},
  year={2014},
  publisher={ACM New York, NY, USA}
}
@article{mora2024synthetic,
  title={Synthetic Programming Elicitation and Repair for Text-to-Code in Very Low-Resource Programming Languages},
  author={Mora, Federico and Wong, Justin and Lepe, Haley and Bhatia, Sahil and Elmaaroufi, Karim and Varghese, George and Gonzalez, Joseph E and Polgreen, Elizabeth and Seshia, Sanjit A},
  journal={arXiv preprint arXiv:2406.03636},
  year={2024}
}
@misc{ouyang2024kernelbench,
      title={KernelBench: Can LLMs Write GPU Kernels?}, 
      author={Anne Ouyang and Simon Guo and Azalia Mirhoseini},
      year={2024},
      url={https://scalingintelligence.stanford.edu/blogs/kernelbench/}, 
}
@inproceedings{polgreen2022uclid5,
  title={UCLID5: multi-modal formal modeling, verification, and synthesis},
  author={Polgreen, Elizabeth and Cheang, Kevin and Gaddamadugu, Pranav and Godbole, Adwait and Laeufer, Kevin and Lin, Shaokai and Manerkar, Yatin A and Mora, Federico and Seshia, Sanjit A},
  booktitle={International Conference on Computer Aided Verification},
  pages={538--551},
  year={2022},
  organization={Springer}
}
@article{bhatia2024verified,
  title={Verified Code Transpilation with LLMs},
  author={Bhatia, Sahil and Qiu, Jie and Hasabnis, Niranjan and Seshia, Sanjit A and Cheung, Alvin},
  journal={arXiv preprint arXiv:2406.03003},
  year={2024}
}
@misc{wiki:affinetype,
    author = "{Wikipedia}",
    title = "Substructural type system --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2024",
    url = "https://en.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems",
    note = "Accessed: 2025-01-12",
}
@misc{cuda,
    author = "NVIDIA",
    title = "CUDA C++ Programming Guide",
    year = "2025",
    url = "https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html",
    note = "Accessed: 2025-01-12",

}
@misc{hip,
    author = "AMD",
    title = "AMD HIP documentation",
    year = "2025",
    url = "https://rocm.docs.amd.com/projects/HIP/en/latest/",
    note = "Accessed: 2025-01-12",

}
@misc{pallas,
    author = "Google",
    title = "Pallas: a JAX kernel language",
    year = "2025",
    url = "https://jax.readthedocs.io/en/latest/pallas/tpu/index.html",
    note = "Accessed: 2025-01-12",

}

@article{chetlur2014cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}
@misc{chipmap,
    author = "SIA",
    title = "U.S. Semiconductor Ecosystem Map",
    year = "2024",
    url = "https://www.semiconductors.org/ecosystem/",
    note = "Accessed: 2025-01-12",

}

@misc{anthropic:agent,
    author = "Anthropic",
    title = "Building effective agents",
    year = "2024",
    url = "https://www.anthropic.com/research/building-effective-agents",
}

@misc{sn:record,
    author = "SambaNova",
    title = "RDU: The GPU Alternative",
    year = "2024",
    url = "https://sambanova.ai/technology/sn40l-rdu-ai-chip"
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}
@article{su2024roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}
@article{zhou2022mixture,
  title={Mixture-of-experts with expert choice routing},
  author={Zhou, Yanqi and Lei, Tao and Liu, Hanxiao and Du, Nan and Huang, Yanping and Zhao, Vincent and Dai, Andrew M and Le, Quoc V and Laudon, James and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7103--7114},
  year={2022}
}
@article{raposo2024mixture,
  title={Mixture-of-Depths: Dynamically allocating compute in transformer-based language models},
  author={Raposo, David and Ritter, Sam and Richards, Blake and Lillicrap, Timothy and Humphreys, Peter Conway and Santoro, Adam},
  journal={arXiv preprint arXiv:2404.02258},
  year={2024}
}
@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}
@misc{vllm2023rotary,
    title = {Rotary Embedding Implementation},
    author = {vLLM},
    year = {2023},
    publisher = {GitHub},
    journal = {GitHub Repository},
    howpublished = {\url{https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/layers/rotary_embedding.py}},
    note = {Accessed: 2025-01-12}
}

@article{sohn2024implementing,
  title={Implementing and Optimizing the Scaled Dot-Product Attention on Streaming Dataflow},
  author={Sohn, Gina and Zhang, Nathan and Olukotun, Kunle},
  journal={arXiv preprint arXiv:2404.16629},
  year={2024}
}
@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{dao2023flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}
@article{he2024does,
  title={Does Prompt Formatting Have Any Impact on LLM Performance?},
  author={He, Jia and Rungta, Mukund and Koleczek, David and Sekhon, Arshdeep and Wang, Franklin X and Hasan, Sadid},
  journal={arXiv preprint arXiv:2411.10541},
  year={2024}
}
@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}
@inproceedings{lattner2021mlir,
  title={MLIR: Scaling compiler infrastructure for domain specific computation},
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  pages={2--14},
  year={2021},
  organization={IEEE}
}

@inproceedings{newell1959report,
  title={Report on a general problem solving program},
  author={Newell, Allen and Shaw, John C and Simon, Herbert A},
  booktitle={IFIP congress},
  volume={256},
  pages={64},
  year={1959},
  organization={Pittsburgh, PA}
}

@article{mccarthy1962towards,
  title={Towards a Mathematical Science of Computation},
  author={Mccarthy, J and Popplewell, Cicely M and Mccarthy, John and Kalenich, Wayne A},
  journal={Journal of Symbolic Logic},
  volume={36},
  number={2},
  year={1962}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{hennessy2019new,
  title={A new golden age for computer architecture},
  author={Hennessy, John L and Patterson, David A},
  journal={Communications of the ACM},
  volume={62},
  number={2},
  pages={48--60},
  year={2019},
  publisher={ACM New York, NY, USA}
}
@article{choquette2023nvidia,
  title={Nvidia hopper h100 gpu: Scaling performance},
  author={Choquette, Jack},
  journal={IEEE Micro},
  volume={43},
  number={3},
  pages={9--17},
  year={2023},
  publisher={IEEE}
}

@inbook{liskov2008,
author = {Liskov, Barbara},
title = {The Power of Abstraction},
year = {2011},
isbn = {9781450310499},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1283920.1962421},
booktitle = {ACM Turing Award Lectures},
pages = {2008}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{spector2024thunderkittens,
  title={ThunderKittens: Simple, Fast, and Adorable AI Kernels},
  author={Spector, Benjamin F and Arora, Simran and Singhal, Aaryan and Fu, Daniel Y and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2410.20399},
  year={2024}
}
@article{ye2025flashinfer,
  title={FlashInfer: Efficient and Customizable Attention Engine for LLM Inference Serving},
  author={Ye, Zihao and Chen, Lequn and Lai, Ruihang and Lin, Wuwei and Zhang, Yineng and Wang, Stephanie and Chen, Tianqi and Kasikci, Baris and Grover, Vinod and Krishnamurthy, Arvind and others},
  journal={arXiv preprint arXiv:2501.01005},
  year={2025}
}
@article{chu2006map,
  title={Map-reduce for machine learning on multicore},
  author={Chu, Cheng-Tao and Kim, Sang and Lin, Yi-An and Yu, YuanYuan and Bradski, Gary and Olukotun, Kunle and Ng, Andrew},
  journal={Advances in neural information processing systems},
  volume={19},
  year={2006}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}
@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@inproceedings{zhang2024dataflow,
  title={The Dataflow Abstract Machine Simulator Framework},
  author={Zhang, Nathan and Lacouture, Rubens and Sohn, Gina and Mure, Paul and Zhang, Qizheng and Kjolstad, Fredrik and Olukotun, Kunle},
  booktitle={2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA)},
  pages={532--547},
  year={2024},
  organization={IEEE}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@inproceedings{hsu2023sparse,
  title={The sparse abstract machine},
  author={Hsu, Olivia and Strange, Maxwell and Sharma, Ritvik and Won, Jaeyeon and Olukotun, Kunle and Emer, Joel S and Horowitz, Mark A and Kj{\o}lstad, Fredrik},
  booktitle={Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={710--726},
  year={2023}
}
@inproceedings{rucker2024revet,
  title={Revet: A language and compiler for dataflow threads},
  author={Rucker, Alexander C and Sundram, Shiv and Smith, Coleman and Vilim, Matthew and Prabhakar, Raghu and Kj{\o}lstad, Fredrik and Olukotun, Kunle},
  booktitle={2024 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  pages={1--14},
  year={2024},
  organization={IEEE}
}
@article{agarwal2024many,
  title={Many-shot in-context learning},
  author={Agarwal, Rishabh and Singh, Avi and Zhang, Lei M and Bohnet, Bernd and Rosias, Luis and Chan, Stephanie and Zhang, Biao and Anand, Ankesh and Abbas, Zaheer and Nova, Azade and others},
  journal={arXiv preprint arXiv:2404.11018},
  year={2024}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}
@article{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}
@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}
@article{yang2024swe,
  title={Swe-agent: Agent-computer interfaces enable automated software engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Lieret, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}
@inproceedings{jia2019taso,
  title={TASO: optimizing deep learning computation with automatic generation of graph substitutions},
  author={Jia, Zhihao and Padon, Oded and Thomas, James and Warszawski, Todd and Zaharia, Matei and Aiken, Alex},
  booktitle={Proceedings of the 27th ACM Symposium on Operating Systems Principles},
  pages={47--62},
  year={2019}
}
@inproceedings{gulwani2003discovering,
  title={Discovering affine equalities using random interpretation},
  author={Gulwani, Sumit and Necula, George C},
  booktitle={Proceedings of the 30th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
  pages={74--84},
  year={2003}
}
@article{hooker2021hardware,
  title={The hardware lottery},
  author={Hooker, Sara},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={58--65},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@misc{cutlass2023,
  title = {CUTLASS},
  author = {Thakkar, Vijay and Ramani, Pradeep and Cecka, Cris and Shivam, Aniket and Lu, Honghao and Yan, Ethan and Kosaian, Jack and Hoemmen, Mark and Wu, Haicheng and Kerr, Andrew and Nicely, Matt and Merrill, Duane and Blasig, Dustyn and Qiao, Fengqi and Majcher, Piotr and Springer, Paul and Hohnerbach, Markus and Wang, Jin and Gupta, Manish},
  year = {2023},
  month = {1},
  url = {https://github.com/NVIDIA/cutlass},
  howpublished = {\url{https://github.com/NVIDIA/cutlass}}
}

@misc{miopen,
    author = "AMD",
    title = "AMD MIOpen documentation",
    year = "2025",
    url = "https://rocm.docs.amd.com/projects/MIOpen/en/latest/index.html",
    note = "Accessed: 2025-01-12",

}

@inproceedings{hagedorn2023graphene,
  title={Graphene: An ir for optimized tensor computations on gpus},
  author={Hagedorn, Bastian and Fan, Bin and Chen, Hanfeng and Cecka, Cris and Garland, Michael and Grover, Vinod},
  booktitle={Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
  pages={302--313},
  year={2023}
}
@article{wei2024improving,
  title={Improving Parallel Program Performance Through DSL-Driven Code Generation with LLM Optimizers},
  author={Wei, Anjiang and Nie, Allen and Teixeira, Thiago SFX and Yadav, Rohan and Lee, Wonchan and Wang, Ke and Aiken, Alex},
  journal={arXiv preprint arXiv:2410.15625},
  year={2024}
}
@article{liu2024deliberation,
  title={Deliberation in Latent Space via Differentiable Cache Augmentation},
  author={Liu, Luyang and Pfeiffer, Jonas and Wu, Jiaxing and Xie, Jun and Szlam, Arthur},
  journal={arXiv preprint arXiv:2412.17747},
  year={2024}
}
@inproceedings{tillet2019triton,
  title={Triton: an intermediate language and compiler for tiled neural network computations},
  author={Tillet, Philippe and Kung, Hsiang-Tsung and Cox, David},
  booktitle={Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
  pages={10--19},
  year={2019}
}
@article{shah2024flashattention,
  title={Flashattention-3: Fast and accurate attention with asynchrony and low-precision},
  author={Shah, Jay and Bikshandi, Ganesh and Zhang, Ying and Thakkar, Vijay and Ramani, Pradeep and Dao, Tri},
  journal={arXiv preprint arXiv:2407.08608},
  year={2024}
}
@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}
@article{sun2024learning,
  title={Learning to (learn at test time): Rnns with expressive hidden states},
  author={Sun, Yu and Li, Xinhao and Dalal, Karan and Xu, Jiarui and Vikram, Arjun and Zhang, Genghan and Dubois, Yann and Chen, Xinlei and Wang, Xiaolong and Koyejo, Sanmi and others},
  journal={arXiv preprint arXiv:2407.04620},
  year={2024}
}
@inproceedings{lattner2004llvm,
  title={LLVM: A compilation framework for lifelong program analysis \& transformation},
  author={Lattner, Chris and Adve, Vikram},
  booktitle={International symposium on code generation and optimization, 2004. CGO 2004.},
  pages={75--86},
  year={2004},
  organization={IEEE}
}
@article{asanovic2014instruction,
  title={Instruction sets should be free: The case for risc-v},
  author={Asanovi{\'c}, Krste and Patterson, David A},
  journal={EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2014-146},
  year={2014}
}
@inproceedings{villa2021need,
  title={Need for speed: Experiences building a trustworthy system-level gpu simulator},
  author={Villa, Oreste and Lustig, Daniel and Yan, Zi and Bolotin, Evgeny and Fu, Yaosheng and Chatterjee, Niladrish and Jiang, Nan and Nellans, David},
  booktitle={2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  pages={868--880},
  year={2021},
  organization={IEEE}
}
@article{dwaracherla2024efficient,
  title={Efficient exploration for llms},
  author={Dwaracherla, Vikranth and Asghari, Seyed Mohammad and Hao, Botao and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2402.00396},
  year={2024}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}
@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}
@inproceedings{wang2024math,
  title={Math-shepherd: Verify and reinforce llms step-by-step without human annotations},
  author={Wang, Peiyi and Li, Lei and Shao, Zhihong and Xu, Runxin and Dai, Damai and Li, Yifei and Chen, Deli and Wu, Yu and Sui, Zhifang},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9426--9439},
  year={2024}
}
@inproceedings{zhao2024expel,
  title={Expel: Llm agents are experiential learners},
  author={Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={19632--19642},
  year={2024}
}
@article{singh2023beyond,
  title={Beyond human data: Scaling self-training for problem-solving with language models},
  author={Singh, Avi and Co-Reyes, John D and Agarwal, Rishabh and Anand, Ankesh and Patil, Piyush and Garcia, Xavier and Liu, Peter J and Harrison, James and Lee, Jaehoon and Xu, Kelvin and others},
  journal={arXiv preprint arXiv:2312.06585},
  year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}

@article{li2022competition,
  title={Competition-level code generation with alphacode},
  author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},
  journal={Science},
  volume={378},
  number={6624},
  pages={1092--1097},
  year={2022},
  publisher={American Association for the Advancement of Science}
}
@techreport{leblond2023alphacode2,
    title={AlphaCode 2 Technical Report},
    author={Leblond, R\'{e}mi and others},
    year={2023},
    url={https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf},
    institution={DeepMind}
}
@article{yan2023gpt,
  title={Gpt-4v in wonderland: Large multimodal models for zero-shot smartphone gui navigation},
  author={Yan, An and Yang, Zhengyuan and Zhu, Wanrong and Lin, Kevin and Li, Linjie and Wang, Jianfeng and Yang, Jianwei and Zhong, Yiwu and McAuley, Julian and Gao, Jianfeng and others},
  journal={arXiv preprint arXiv:2311.07562},
  year={2023}
}
@article{wu2023autogen,
  title={Autogen: Enabling next-gen llm applications via multi-agent conversation framework},
  author={Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
  journal={arXiv preprint arXiv:2308.08155},
  year={2023}
}
@article{milakov2018online,
  title={Online normalizer calculation for softmax},
  author={Milakov, Maxim and Gimelshein, Natalia},
  journal={arXiv preprint arXiv:1805.02867},
  year={2018}
}
@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Elsevier}
}
@article{knuth1968semantics,
  title={Semantics of context-free languages},
  author={Knuth, Donald E},
  journal={Mathematical systems theory},
  volume={2},
  number={2},
  pages={127--145},
  year={1968},
  publisher={Springer}
}
@misc{nvidia:v100,
  title        = {Nvidia Tesla V100 GPU Architecture, The World’s Most Advanced Data Center GPU},
  author       = {{NVIDIA}},
  year         = {2017},
  note         = {Whitepaper},
  url          = {https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf}
}
@inproceedings{zhang2021high,
  title={High performance lattice regression on FPGAs via a high level hardware description language},
  author={Zhang, Nathan and Feldman, Matthew and Olukotun, Kunle},
  booktitle={2021 International Conference on Field-Programmable Technology (ICFPT)},
  pages={1--10},
  year={2021},
  organization={IEEE}
}

@misc{python:ast,
  title = {Python ast module},
  author = {Armin Ronacher},
  year = {2008},
  URL = {https://docs.python.org/3/library/ast.html}
}

@article{opsahl2024optimizing,
  title={Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs},
  author={Opsahl-Ong, Krista and Ryan, Michael J and Purtell, Josh and Broman, David and Potts, Christopher and Zaharia, Matei and Khattab, Omar},
  journal={arXiv preprint arXiv:2406.11695},
  year={2024}
}
@article{liu2023reflect,
  title={Reflect: Summarizing robot experiences for failure explanation and correction},
  author={Liu, Zeyi and Bahety, Arpit and Song, Shuran},
  journal={arXiv preprint arXiv:2306.15724},
  year={2023}
}
@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th annual acm symposium on user interface software and technology},
  pages={1--22},
  year={2023}
}
@article{fernando2023promptbreeder,
  title={Promptbreeder: Self-referential self-improvement via prompt evolution},
  author={Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2309.16797},
  year={2023}
}
@inproceedings{elmaaroufi2024scenicnl,
  title={ScenicNL: generating probabilistic scenario programs from natural language},
  author={Elmaaroufi, Karim and Shanker, Devan and Cismaru, Ana and Vazquez-Chanlatte, Marcell and Sangiovanni-Vincentelli, Alberto and Zaharia, Matei and Seshia, Sanjit A},
  booktitle={First Conference on Language Modeling},
  year={2024}
}
@article{barke2024hysynth,
  title={HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis},
  author={Barke, Shraddha and Gonzalez, Emmanuel Anaya and Kasibatla, Saketh Ram and Berg-Kirkpatrick, Taylor and Polikarpova, Nadia},
  journal={arXiv preprint arXiv:2405.15880},
  year={2024}
}
@inproceedings{batten2024pyhdl,
  title={PyHDL-Eval: An LLM Evaluation Framework for Hardware Design Using Python-Embedded DSLs},
  author={Batten, Christopher and Pinckney, Nathaniel and Liu, Mingjie and Ren, Haoxing and Khailany, Brucek},
  booktitle={Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
  pages={1--17},
  year={2024}
}

@inproceedings {zhang2024caravan,
author = {Qizheng Zhang and Ali Imran and Enkeleda Bardhi and Tushar Swamy and Nathan Zhang and Muhammad Shahbaz and Kunle Olukotun},
title = {Caravan: Practical Online Learning of {In-Network} {ML} Models with Labeling Agents},
booktitle = {18th USENIX Symposium on Operating Systems Design and Implementation (OSDI 24)},
year = {2024},
isbn = {978-1-939133-40-3},
address = {Santa Clara, CA},
pages = {325--345},
url = {https://www.usenix.org/conference/osdi24/presentation/zhang-qizheng},
publisher = {USENIX Association},
month = jul
}

@inproceedings{fang2024assertllm,
  title={AssertLLM: Generating Hardware Verification Assertions from Design Specifications via Multi-LLMs},
  author={Fang, Wenji and Li, Mengming and Li, Min and Yan, Zhiyuan and Liu, Shang and Zhang, Hongce and Xie, Zhiyao},
  booktitle={2024 IEEE LLM Aided Design Workshop (LAD)},
  pages={1--1},
  year={2024},
  organization={IEEE}
}
@inproceedings{guan2024intelligent,
  title={Intelligent agents with llm-based process automation},
  author={Guan, Yanchu and Wang, Dong and Chu, Zhixuan and Wang, Shiyu and Ni, Feiyue and Song, Ruihua and Zhuang, Chenyi},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={5018--5027},
  year={2024}
}
@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}
@article{hu2024automated,
  title={Automated design of agentic systems},
  author={Hu, Shengran and Lu, Cong and Clune, Jeff},
  journal={arXiv preprint arXiv:2408.08435},
  year={2024}
}
@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}
@article{chaturvedi2024hpc,
  title={HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages},
  author={Chaturvedi, Aman and Nichols, Daniel and Singh, Siddharth and Bhatele, Abhinav},
  journal={arXiv preprint arXiv:2412.15178},
  year={2024}
}
@article{liu2024lost,
  title={Lost in the middle: How language models use long contexts},
  author={Liu, Nelson F and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={12},
  pages={157--173},
  year={2024},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}
@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}
@book{kolb2014experiential,
  title={Experiential learning: Experience as the source of learning and development},
  author={Kolb, David A},
  year={2014},
  publisher={FT press}
}
@article{tian2024toward,
  title={Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing},
  author={Tian, Ye and Peng, Baolin and Song, Linfeng and Jin, Lifeng and Yu, Dian and Mi, Haitao and Yu, Dong},
  journal={arXiv preprint arXiv:2404.12253},
  year={2024}
}
@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}
@article{yu2023metamath,
  title={Metamath: Bootstrap your own mathematical questions for large language models},
  author={Yu, Longhui and Jiang, Weisen and Shi, Han and Yu, Jincheng and Liu, Zhengying and Zhang, Yu and Kwok, James T and Li, Zhenguo and Weller, Adrian and Liu, Weiyang},
  journal={arXiv preprint arXiv:2309.12284},
  year={2023}
}
@article{chen2024self,
  title={Self-play fine-tuning converts weak language models to strong language models},
  author={Chen, Zixiang and Deng, Yihe and Yuan, Huizhuo and Ji, Kaixuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2401.01335},
  year={2024}
}
@article{huang2023large,
  title={Large language models cannot self-correct reasoning yet},
  author={Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  journal={arXiv preprint arXiv:2310.01798},
  year={2023}
}
@article{dong2024flex,
  title={Flex Attention: A Programming Model for Generating Optimized Attention Kernels},
  author={Dong, Juechu and Feng, Boyuan and Guessous, Driss and Liang, Yanbo and He, Horace},
  journal={arXiv preprint arXiv:2412.05496},
  year={2024}
}
@article{jiang2024mixtral,
  title={Mixtral of experts},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and others},
  journal={arXiv preprint arXiv:2401.04088},
  year={2024}
}