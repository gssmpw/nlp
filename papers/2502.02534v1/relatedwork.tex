\section{Related Work}
% \todo{Weixin: Consider enhancing Figure 7 by opening with a clear topic sentence that captures the key finding. his would help readers quickly grasp the main relationship you're demonstrating between xxx and yyy.}
% \subsection{DSL for LLM}
% DSL has been used to define the interface between users and LLM agents. ~\cite{wei2024improving} designs a mapper DSL as an interface, enabling an existing prompt optimizer to optimize a parallel computing system problem. Differently, their DSL has their own syntax, while ours is embedded in existing language.
\subsection{Self-improvement learning for LLMs}
Self-improvement learning for LLMs typically involves two stages: scoring generated samples (trajectories) and incorporating those samples to enhance the model. Scoring can be achieved through human labeling~\cite{cobbe2021training,lightman2023let} or through automated methods such as verifiers and heuristics~\cite{wang2024math,singh2023beyond}. Our method stands out in this context by utilizing AST analysis, offering a more interpretable approach to scoring. When it comes to incorporating samples, models may rely on retrieval~\cite{zhao2024expel,park2023generative}, reflection~\cite{shinn2024reflexion,liu2023reflect}, or reward feedback~\cite{opsahl2024optimizing,fernando2023promptbreeder}. Our method introduces a new mechanism in this stage by adaptively extending and prioritizing high-scoring samples. 

Our method shares similar reinforcement principles with self-improvement learning at the post-training stage~\cite{bai2022constitutional,gulcehre2023reinforced,tian2024toward} but is rewarded at a task-level granularity instead of token-level. Specifically, each action is a program implementation instead of token prediction and the state is defined by earned experiences rather than generated sequences.

\subsection{Agentic system organization for specialized tasks}
Task-specific organization has proven effective in enhancing the performance of agentic systems across diverse coding tasks~\cite{zhang2024caravan,fang2024assertllm,guan2024intelligent}. We adopt an agentic system organization specifically for ML library development using an ASPL. Such domain knowledge can be further augmented with automatic agentic system design tools~\cite{khattab2023dspy,hu2024automated}. Furthermore, well-designed interfaces between agents, tools, and other agents have been shown to improve performance~\cite{schick2023toolformer,yang2024swe,wu2023autogen}, and a structural IR enables these interfaces to be highly task-aligned in our system.

% LLM agents have been developed for text-to-code~\cite{batten2024pyhdl,elmaaroufi2024scenicnl}, lifting~\cite{bhatia2024verified}, task completion~\cite{barke2024hysynth,wei2024improving} using low-resource programming languages. The solutions include: using external tools to correct, guided with formal methods, and embedding into common languages.