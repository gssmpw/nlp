\documentclass[11pt]{article}

\def\papertitle{SCU: An Efficient Machine Unlearning Scheme for Deep Learning Enabled Semantic Communications}
\def\authors{Weiqi~Wang, Zhiyi~Tian, Chenhan~Zhang, and Shui~Yu}
\def\journal{Transactions on Information Forensics \& Security}
\def\manuscriptid{T-IFS-18024-2024}

\usepackage[numbers]{natbib}



\renewcommand{\thetable}{\Roman{table}} % Change table numbering to Roman numerals

\input{response_config.tex}

  \newtheorem{lemma}{Lemma}
 \newtheorem{theorem}{Theorem}
\newtheorem*{prob_state}{\textbf{Problem Statement}}

\begin{document}

\preamble

\vspace{2em}
Dear editor in chief, associate editor, and anonymous reviewers,
\\[2em]
We sincerely express our heartfelt gratitude for handling the review of our manuscript. Your insightful comments, constructive suggestions, and investment of time have been truly appreciated. 


In the last round of review, this paper was required to undergo a \textbf{Major Revision (RQ)}. Specifically, the reviewers' recommendations included two \textbf{Major Revision}s. We have thoroughly revised the paper according to the reviewer's constructive suggestions. We summarize our revision as below: 
\begin{itemize}[itemsep=0pt, parsep=0pt, leftmargin=*]
	\item We revised our research challenges introduction to elucidate the unlearning challenges in semantic communication, and we streamlined the problem statement part. This makes the context more compact and aligned with our research objectives.
	\item We collected and analyzed the latest unlearning methods and supplemented the experiments compared with these new methods.
	\item We reorganized the introduction about the evaluation metrics, focusing on the explanation of evaluation design for unlearning the unsupervised semantic communication models, reducing the confusion.
	\item We carefully reviewed the entire paper to enhance its clarity and readability by thoroughly polishing the writing, correcting typos, and reorganizing some structures. Moreover, we invited a number of experts in this area to help proofread the revised manuscript, ensuring the clarity and readability of the paper. 
\end{itemize}


 


We worked diligently to address all the concerns raised by reviewers. We provide our detailed response to the reviewers' comments below, and we have highlighted the main changes of the revised manuscript by coloring the modified text in {\color{blue} blue} in this response.

%\\[2em]
Best regards,\\
\authors


\clearpage
\newpage

\section{Reviewer 1: Review Again After Major Changes}

\RC 1. It is unclear why the proposed SCU is designed for semantic communication. What is the feature of the semantic communication what makes the proposed method suitable for it?

\AR We thank the reviewer for this comment. One feature of semantic communication is it usually employs joint-training models. Existing semantic communication (SC) usually employs a deep learning encoder and decoder to jointly train the SC codecs, which are connected with a physical noise channel. Moreover, across various applications of semantic communication, unsupervised learning techniques are frequently utilized for tasks such as feature extraction, dimensionality reduction, and data reconstruction. Although existing unlearning methods focus on supervised learning scenarios, unlearning for DL-enabled semantic models should consider the unsupervised or self-supervised learning tasks as another feature. 

Based on these features of semantic communication, firstly, the proposed method unlearns a jointly trained encoder and decoder based on the unsupervised information bottleneck structure, which is one of the most popular model structures for semantic communication. Secondly, a contrastive compensation method is proposed to mitigate the huge utility degradation caused by unlearning such unsupervised SC models. Thirdly, we propose two evaluation metrics, reconstruction MSE and downstream task detection, to evaluate the unlearning effect of unsupervised SC models. To reduce the confusion and improve the clarity, we revised the corresponding parts, which are presented as follows.

\begin{change}
\emph{I. Introduction}
\newline
...
\newline
\rev{However, there are three key challenges when unlearning semantic communication models. First, semantic communications are usually implemented by jointly trained DL encoder and decoder [2, 4]. Most existing machine unlearning methods mainly focus on unlearning single model structure scenarios [9, 10]. It is challenging to maintain semantic knowledge consistency between jointly trained encoders and decoders during and after unlearning. Second, unlike conventional unlearning targeting supervised learning scenarios [11], unlearning for DL-enabled semantic models should consider the unsupervised or self-supervised learning tasks, as the semantic communications are the basic tasks, which usually include the upstream unsupervised learning tasks [12, 13]. Third, it lacks an effective evaluation for the semantic communication unlearning methods. Existing evaluation methods [14] for the unlearning supervised models are infeasible to the semantic models with an unsupervised recovery task [12, 13]. 
}
\newline
...

\rev{To effectively evaluate unlearning of semantic communications, two evaluation metrics are proposed: the reconstruction mean squared error (MSE) comparison and the downstream task detection.} Specifically, we mixed the prepared backdoored samples into the full training dataset to train the semantic codecs. Then, we train a downstream classification model to identify the backdoor information of the decoder's outputs. The goal of the unlearning methods is to erase the impact of the backdoored data points from trained semantic models. \rev{The effectiveness of unlearning can be measured via the backdoor detection accuracy of the downstream classification model. A low backdoor accuracy of the downstream model means a high unlearning effect.} We also compare the MSE between the reconstructed and original samples to check whether the recovered data contains the backdoor. Comprehensive experimental results show that SCU greatly improves effectiveness and efficiency over the baselines by directly applying state-of-the-art unlearning methods in semantic communications.
\newline
...
\end{change}


\RC 2. The writing is quite redundant. For example, the problem statement is repeated for several times. The authors should proofread the paper to make it simplified.


\AR We are grateful for the reviewer's comment. We have carefully proofread and streamlined the writing of the paper. We removed the repeat introduction in the problem statement section and reorganized the preliminary and problem statement structure. For example, we removed the introduction of traditional machine unlearning in the problem statement, and we reorganized the problem statement as a subsection of the Preliminary section to make the structure clear. We summarize the revision as follows. 

\begin{change}
\emph{III.B. Unsupervised Variational Information Bottleneck}

 
\rev{The variational information bottleneck (VIB) in an unsupervised form [15] is an important implementation to build semantic communications. It was proved that the unsupervised form VIB could be transformed into the same mathematical form as VAE [33]. Both methods are commonly used in training semantic models [3, 13, 34].} Since unsupervised VIB and VAE are easy to transform into each other and are easy to extend to normal encoder/decoder training, we choose to introduce our method based on the unsupervised VIB framework. 


The VIB objective in an unsupervised version can be described and expanded below
\begin{equation} \label{eq:total_loss_q}
	\small
	\begin{aligned} 
		\mathcal{L}_{\mathcal{IB}}^{unsup}& =   \mathcal{L}_{enc} + \mathcal{L}_{dec} \\
		& =  \beta I(Z;i) - I(Z;X) \\
		&\simeq  \beta \text{KL}[p_{f_\theta}(Z|\text{x}_i)||  \prod_{i}^{|Z|} q_i( \text{z}_i)] +\\
		&+\frac{1}{N} \sum_{i=1}^{N} \mathbb{E}_{ \text{z} \backsim p_{f_\theta}(Z| \text{x}_i)}[-\log \ p_{g_\theta}( \text{x}| \text{z})],
	\end{aligned}
\end{equation} 
\rev{where $I(Z;i)$ is the mutual information (MI) between the semantic representation $Z$ and input sample $i$, which is optimized by the encoder $f_{\theta}$. $I(Z;X)$ is the mutual information between the representation and the original data $X$, which is optimized by the decoder $g_\theta$.} The corresponding encoding loss function is $\mathcal{L}_{enc}=\beta I_{f_\theta}(Z;i)$ and decoding loss function is $\mathcal{L}_{dec}=-I_{g_{\theta}}(Z;X)$. To optimize them in DL, existing work [15] proposes a variational distribution $q(Z)$ and minimizes the corresponding upper bound of \Cref{eq:total_loss_q}. The per-sample optimization form is shown as the approximate equation in \Cref{eq:total_loss_q}. In [15], Alemi et al. proved that the unsupervised VIB takes the same form as VAE [33], except with the weight $\beta$ for encoder. 

...

\emph{III.D. Problem Statement} \label{ps}


\rev{
	In a semantic communication framework, assuming implemented using the VIB method, the difference between the traditional unlearning scenarios is that there are two DL models, one encoder $f_{\theta}(\cdot)$ and one decoder $g_{\theta}(\cdot)$.} The encoder is designed to extract semantic information from source inputs, while the decoder focuses on reconstructing the transmitted data from received signals. Both models undergo joint training prior to their deployment in communication. 
For convenience to understand, we assume the trained semantic communication models as a big model $\mathcal{M}(f_{\theta}, g_{\theta})$ using the unsupervised VIB method based on the whole dataset $D$. When the unlearning request about the erased dataset $D_e$ comes, the problem of semantic communication unlearning can be stated as:
\rev{
	\begin{prob_state}(Semantic Communication Unlearning)  
		Suppose there is an already-trained semantic communication system $\mathcal{M}(f_{\theta}, g_{\theta})$ based on the entire collected data $D$ using the unsupervised VIB algorithm $\mathcal{IB}$.
		Let $D_e=X_e$ be the erased dataset of an unlearned user and $D_e \subseteq D$, and we use $D_r$ to denote the remaining dataset except $D_e$. 
		The goal of the semantic communication unlearning is to design an unlearning method $\mathcal{U}$ that simultaneously unlearns both encoder $f_\theta$ and decoder  $g_\theta$ and makes the unlearned semantic model equal to the retrained model:
		\begin{equation} \small
			P(\mathcal{M}_u(f_{\theta}, g_{\theta})\!= \!\mathcal{IB}(D_r) )\!=\!P(\mathcal{M}_u(f_{\theta}, g_{\theta})\!=\!\mathcal{U}(D_e, \mathcal{IB}(D))  ).
		\end{equation}
	\end{prob_state}
	
	
The key challenge of the problem lies in designing unlearning methods customized for both encoder $f_\theta$ and decoder $g_\theta$ jointly, which is much different from unlearning the normal supervised ML scenarios. During unlearning semantic models, we need to maintain the former learned semantic knowledge consistent in both codecs and eliminate the information of the erased samples from the IB-based semantic systems.}

\end{change}


 
\RC 3. In Equations (4) and (5), the loss is evaluated by KLD between a trained encoder (resp. decoder) and a fixed encoder (decoder). However, it is unclear how we can set a fixed encoder or decoder for evaluation.


\AR We thank the reviewer's comment. To calculate Equations (4) and (5), in our experiments, we keep two models: one is the fixed model that is duplicated using the original trained encoder and decoder, and another one is the unlearned model that is initialized using the original trained encoder and decoder too. During the unlearning process, we feed data into both fixed and unlearned models to calculate the KLD. However, we only update the unlearned model, while the fixed model is always maintained. For clarity, we revise the corresponding part as follows.

\begin{change}
	\emph{IV. Semantic Communication Unlearning}
	\newline
	...
	\newline
where $f_{\theta}^{fix}$ and $g_{\theta}^{fix}$ represent the trained encoder and decoder that are fixed to compute the KLD limitation term. 
\rev{ 
	To calculate the KLD, in experiments, we keep two models: the fixed model $\mathcal{M}(f_{\theta}^{fix}, g_{\theta}^{fix})$ and the unlearned model $\mathcal{M}_u(f_{\theta}, g_{\theta})$. Both are initialized using the original trained model. During the unlearning process, we feed the same data into both fixed and unlearned models to calculate the KLD, and we only update the unlearned model.
} 
This ensures the unlearned models are not too different from the original encoder and decoder. 
\newline
...
\end{change}

 
 

\RC 4. In experimental evaluation, the erased data ratio (EDR) is set from $2\%$ to $10\%$. The authors should also test a larger EDR, such as $20\%$ and $30\%$.

\AR We thank the reviewer for the insightful suggestion. More training data usually increases the model's utility. If we unlearn lots of data, such as $20\%$ and $30\%$, the model utility will also drop a lot. Our setting of EDR from $2\%$ to $10\%$ is reasonable based on two factors. First, in most existing unlearning studies, the unlearning data rate is usually set at less than $10\%$ [1,2,3]. In [3], the percentage of unlearned samples is even set at less than $5\%$. Second, it is also practical because [4] presents that 3.2 million requests for deleting URLs have been issued to Google from 2014 to 2019, constituting less than 1\% of the total URLs Google indexes in the 5 years. We revised the corresponding parts as follows. 

[1]. Kurmanji, Meghdad, et al. "Towards unbounded machine unlearning." Advances in neural information processing systems 36 (2024).
\newline
[2]. Tarun, Ayush K., et al. "Fast yet effective machine unlearning." IEEE Transactions on Neural Networks and Learning Systems (2023).
\newline
[3]. Chen, Min, et al. "When machine unlearning jeopardizes privacy." Proceedings of the 2021 ACM SIGSAC conference on computer and communications security. 2021.
\newline
[4]. Bertram, Theo, et al. "Five years of the right to be forgotten." Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 2019.

 
\begin{change}
	\emph{VI.C. Impact of the Erased Data Ratio}
	\newline
	...
	\newline
	With a fixed ${\it SNR}$ value and using AWGN channels, we explore the effects of varying ${\it EDR}$ values. The results of this exploration on the MNIST, CIFAR10, and CIFAR100 datasets are presented in Figure 3, \rev{where ${\it EDR}$ is ranged from $2\%$ to $10\%$. In practice, we believe even $2\%$ data might be very large for unlearning. The results in [40] present that 3.2 million requests for deleting URLs have been issued to Google from 2014 to 2019, constituting less than $2\%$ of the total URLs Google indexes in the 5 years.} The evaluations of effectiveness are measured by the accuracy of the downstream model on the decoded clean samples in Figures 3(a), 3(f) and 3(k), the backdoor accuracy of the downstream model on the decoded erased samples in Figures 3(b), 3(g) and 3(l). We also demonstrate the decoding MSE on the clean and erased samples in Figures 3(c), 3(d), 3(h), 3(i), 3(m) and 3(n). The last column of Figure 3 shows the running time of all methods on MNIST, CIFAR10, and CIFAR100.
	\newline
	...
\end{change} 

 
 \RC 5. In Fig. 3, compared to SCU, the baselines fluctuate a lot along with the increasing EDR. Please explain the reason.

\AR We thank the reviewer for the constructive comment. When EDR increases, the downstream models' model accuracy and backdoor accuracy also decrease, which is reflected in the results of all methods on the three datasets. The baseline, specifically the Hessian-based unlearning (HBU), fluctuates the most in the MSE metrics on CIFAR10 and CIFAR100, which means it is easy to cause catastrophic unlearning for the unsupervised semantic models, significantly increasing the reconstruction MSE. The reason that we infer is that the HBU is updated based on the Hessian matrix, which calculates the data influence based on the entire remaining dataset but only updates the unlearned model in one step. It is easy to make the update overlarge, hence causing catastrophic unlearning. This is also why most Hessian matrix-based unlearning methods need an update threshold to limit model updates and avoid utility degradation. In our experiments, we also set a fixed threshold for HBU. However, the fixed threshold is still easy to cause catastrophic unlearning. By contrast, we proposed the contrastive compensation to mitigate model utility degradation caused by unlearning, which can effectively avoid catastrophic unlearning. For clarity, we revised the corresponding part as follows.

%Another baseline, the VBU, achieves an acceptable performance, as the VBU (VAE-based) is similar to our VIB-based method (without contrastive compensation), which is demonstrated in the ablation studies in Figure 6.


\begin{change}
	
	\setcounter{figure}{2}
	
	\begin{figure*}[h]
		\centering
		\vspace{-4mm}
		\hspace{-4mm}
		\subfloat[\footnotesize Accuracy on clean data ]{ \label{fig_mnistaccercurve} \rotatebox{90}{ \hspace{5mm}	\scriptsize{ On MNIST} }
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Server_acc/mnist_acc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Bac. acc. on erased data]{ \label{fig_mnistbackaccercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Server_backAcc/mnist_backacc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on clean data]{\label{fig_mnistmsecleanercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Server_MSE_clean/mnist_mse_clean_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on erased data]{	\label{fig_mnistmseerasedercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Server_MSE_erased/mnist_mse_erased_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Running time]{  	\label{fig_mnistrterbar}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Server_runtime/mnist_rt_er_bar}
		}\vspace{-2mm}
		\\
		\hspace{-4mm}
		\subfloat[\footnotesize Accuracy on clean data]{ 	\label{fig_cifaraccercurve} \rotatebox{90}{ \hspace{3mm}	\scriptsize{ On CIFAR10} }
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR/Server_acc/cifar_acc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Bac. acc. on erased data]{ \label{fig_cifarbackaccercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR/Server_backAcc/cifar_backacc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on clean data]{ \label{fig_cifarmsecleanercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR/Server_MSE_clean/cifar_mse_clean_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on erased data]{\label{fig_cifarmseerasedercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR/Server_MSE_erased/cifar_mse_erased_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Running time]{  \label{fig_cifarrterbar}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR/Server_runtime/cifar_rt_er_bar}
		}\vspace{-2mm}
		\\
		\hspace{-4mm}
		\subfloat[\footnotesize Acc. on clean data]{ 	\label{fig_cifar100accercurve} \rotatebox{90}{ \hspace{3mm}	\scriptsize{ On CIFAR100} }
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR100/Server_acc/cifar100_acc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Bac. acc. on erased data]{ \label{fig_cifar100backaccercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR100/Server_backAcc/cifar100_backacc_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on clean data]{ \label{fig_cifar100msecleanercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR100/Server_MSE_clean/cifar100_mse_clean_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize MSE on erased data]{\label{fig_cifar100mseerasedercurve}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR100/Server_MSE_erased/cifar100_mse_erased_er_curve}
		}\hspace{-2mm}
		\subfloat[\footnotesize Running time on]{  \label{fig_cifar100rterbar}
			\includegraphics[scale=0.14]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_CIFAR100/Server_runtime/cifar100_rt_er_bar}
		}
		\caption{Evaluations of the impact of different ${\it EDR}$. Model accuracy and backdoor accuracy of downstream models in SCU and VBU decrease as the ${\it EDR}$ increases. HBU easily causes catastrophic unlearning, reflected in huge model accuracy degradation and the highest decoding MSE. Especially in CIFAR10 and CIFAR100, the decoding MSE of HBU is higher than the vertical axis.} 
		%	\vspace{-4mm}
		\label{evaluation_of_edr} 
	\end{figure*}
	
	
	\emph{VI.C. Impact of the Erased Data Ratio}
	\newline
	...
	\newline
	From the evaluation of decoding MSE, both HBU and VBU cause catastrophic unlearning, reflected in the much increased decoding MSE shown in Figure 3(c), 3(d), 3(h), 3(i), 3(m) and 3(n). \rev{On CIFAR10 and CIFAR100, the decoding MSE of HBU increases too much, higher than the maximum value on the y-axis. We infer that the reason is HBU uses the Hessian matrix to calculate the data influence based on the remaining dataset but only updates the unlearned model in one step. It is easy to make the update overlarge, hence causing catastrophic unlearning. Most Hessian matrix-based unlearning methods need an update threshold to limit model updates and avoid utility degradation. In our experiments, we also set a fixed threshold for HBU. However, the fixed threshold is still easy to cause catastrophic unlearning.} We show the decoding MSE of SCU on clean and erased samples in the third and fourth columns in Figure 3. The MSE on erased samples is all higher than that on clean samples. It proves that SCU achieves unlearning effectiveness from another aspect besides the backdoor accuracy.
	\newline
	...
\end{change} 


 \RC 6. The first occurrence of SNR is without any explanation. The definition is in Sec. VII.C. Please put it forward.

\AR We thank the reviewer for the suggestion. We have put it forward at the beginning of the performance evaluation section, which is demonstrated as follows. We also proofread the entire paper to avoid this kind of issues.

 \begin{change}
 	\emph{VI. Performance Evaluation}
 	\newline
 	...
 	\newline
\rev{We first introduce the experimental setup. Then, we conduct experiments to evaluate the impact of the Erased Data Ratio during semantic communication models' unlearning in subsection VI-C and assess the influence of the channels and Signal-to-Noise Ratio (${\it SNR}$) on semantic communication model performance in subsection VI-D. Finally, an ablation study is conducted to demonstrate the impact of the CC loss within the proposed SCU method.
}
 	\newline
 	...
 \end{change} 

%\newpage
 

\section{Reviewer 2: Review Again After Major Changes}

\RC 1. The experiments in this paper use too few baselines, only two, and they are not new enough. In fact, there has been recent works proposing better supervised unlearning algorithms, e.g. [1-4]. The use of underpowered algorithms from a few year ago as a comparison is not very convincing.

[1] Fan, C., Liu, J., Zhang, Y., Wong, E., Wei, D., \& Liu, S. (2024). SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation (arXiv:2310.12508). arXiv.http://arxiv.org/abs/2310.12508

[2] Jia, J., Liu, J., Ram, P., Yao, Y., Liu, G., Liu, Y., Sharma, P., \& Liu, S. (2023). Model Sparsity Can Simplify Machine Unlearning (arXiv:2304.04934). arXiv.http://arxiv.org/abs/2304.04934

[3] Chundawat, V. S., Tarun, A. K., Mandal, M., \& Kankanhalli, M. (2023). Can Bad Teaching Induce Forgetting?Unlearning in Deep Networks Using an Incompetent Teacher. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7210–7217.https://doi.org/10.1609/aaai.v37i6.25879

[4] Kurmanji, M., Triantafillou, P., Hayes, J., \& Triantafillou, E. (2023). Towards Unbounded Machine Unlearning(arXiv:2302.09880). arXiv.http://arxiv.org/abs/2302.09880 

\AR We sincerely thank the reviewer's comment. We have cited and discussed all the mentioned references. We find that the baselines that we used are also popularly used in these studies. The Hessian matrix-based unlearning (HBU) is similar to the unlearning method based on influence functions. And the VBU is another popular approximate unlearning method. For example, although [1] and [2] find that model sparsity improves unlearning effectiveness without too much model utility loss, model sparsity still needs these unlearning methods to implement the fundamental unlearning effectiveness. To reduce the concerns, we supplement a baseline that considers the model sparsity factor [2]. We extended the VBU baseline with the 95\% sparsity, and the additional experimental results are represented in the ablation study section. The results show that the model sparsity does improve the unlearning effectiveness but has a slight model utility degradation. Compared with considering model sparsity, our contrastive compensation significantly preserves the model utility while slightly mitigating the unlearning effect. We summarize the revision as follows.

 
\begin{change}
	\emph{II. Related Work}
	\newline
	...
	\newline
To minimize the decrease in utility, a fixed threshold is typically employed to regulate the extent of unlearning [9, 24]. \rev{Moreover, Fan et al. and Liu et al. [28, 29] find that considering model sparsity based on existing unlearning methods can effectively enhance the unlearning effect while not significantly decreasing model utility. Other methods, such as [30, 31, 32], considered both the unlearning effect and model utility during the unlearning process and proposed corresponding methods to achieve the optimal balance.} 
\newline
...

\setcounter{figure}{5}
\begin{figure}[h]
	\centering
	\hspace{-4mm}
	\subfloat[\footnotesize Accuracy ]{ 	\label{fig:mnistaccercurveablation}
		\includegraphics[scale=0.25]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Ablation_study/mnist_acc_er_curve_ablation}
	}	\hspace{-4mm}
	\subfloat[\footnotesize Bac. Acc.]{ 	\label{fig:mnistbackaccercurveablation} 
		\includegraphics[scale=0.25]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Ablation_study/mnist_backacc_er_curve_ablation}
	}	\hspace{-4mm}
	\subfloat[\footnotesize MSE]{	\label{fig:mnistmsecleanercurveablation}
		\includegraphics[scale=0.25]{../../../../../../PycharmProjects/Semantic_unlearning/Experiments_results/On_MNIST/Ablation_study/mnist_mse_clean_er_curve_ablation}
	}
	\caption{Ablation study when SCU without (abbreviated as w/o) the CC loss on MNIST. It performs similarly to VBU, much worse than the entire SCU.} 
	\label{ablation_study} 
\end{figure}
\emph{VII.F. Ablation Study}
We evaluate the impact of the CC loss on SCU. Specifically, we compare the performance of SCU and the performance of the SCU without the CC loss, denoted as ``SCU w/o CC''.
\rev{For comparison, we also conduct experiments on VBU and an extended VBU that considers the model sparsity as [29], denoted as ``VBU w Sparsity''.} We present the experimental results on MNIST in \Cref{ablation_study}. 

In Figures \subref{fig:mnistaccercurveablation} and \subref{fig:mnistbackaccercurveablation}, we can see that the ``SCU w/o CC'' performs similarly to VBU. \rev{Without the contrastive compensation, the only joint unlearning is similar to VBU. Since both VIB and VAE have the same expansion mathematic form for optimization, the corresponding unlearning methods perform similarly without the CC compensation. The results of ``VBU w Sparsity'' show that the model sparsity does improve the unlearning effectiveness but has a slight model utility degradation. Compared with considering model sparsity, our method with contrastive compensation, SCU,  significantly preserves the model utility while slightly mitigating the unlearning effect.} And all three subfigures in \Cref{ablation_study} demonstrate that the improvement of SCU with the constructive compensation.

	
\end{change}

%\newpage
\RC 2. On Metrics, why an increase in MSE can be taken as a reflection of good performance of unlearning algorithms. In fact, even if we don't use any unlearning algorithm and just change the model initialization parameters during the model training process, the MSE of the model decoding results versus the original model results is greater than 0 and varies, but a large MSE doesn't mean anything.

\AR We appreciate the reviewer's insightful comments. As you said, simply an MSE increase cannot be treated as a good performance of unlearning algorithms as it ignores the model utility. We compare the decoding MSE on the clean and erased datasets together to evaluate the unlearning effectiveness. Good unlearning methods for an unsupervised model should keep the small MSE on the clean dataset (preserving model utility) and increase the MSE on the erased dataset (achieving the unlearning effect) after unlearning. For clarity, we revised the corresponding parts as follows.

\begin{change}
	\emph{VI.A Experimental Setup}
	\newline
	...
	\newline
\textbf{MSE.} We use mean square error (MSE) to evaluate the decoding effectiveness. \rev{Good unlearning methods for an unsupervised model should (1) keep a small decoding MSE on the clean dataset (preserving model utility) and (2) increase the MSE on the erased dataset (achieving the unlearning effect) after unlearning.} 
\newline
...
\end{change}

 
\RC 3. In Metrics, why use Backdoor Accuracy instead of the more general Membership Inference Attack (MIA) accuracy [1,2,4]?


\AR We thank the reviewer for this comment. We choose the backdoor accuracy because it is relatively straightforward to evaluate if the sample is unlearned from the model, referring to [5]. The backdoor accuracy is usually higher than $90\%$ for a backdoored model and less than $10\%$ for a model without backdoors. Compared with backdoor accuracy, membership inference attack accuracy is reported to be highly correlated to model’s overfitting or generalization gap [6, 7] because an overfitted model should perhaps behave even more confident towards training samples. In this situation, when unlearning a few samples, especially for normal robust models, the change of MIA is usually not obvious enough [8]. By contrast, the change of backdoor accuracy will be remarkable, which usually drops from $90\%$ to lower than $10\%$, which is more straightforward than the MIA metric. To reduce confusion, we revised the corresponding part as follows.



[5]. Hu, Hongsheng, et al. "Membership inference via backdooring." (IJCAI 2022).
\newline
[6]. Salem, Ahmed, et al. "Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models." (NDSS 2019).
\newline
[7]. Rezaei, Shahbaz, and Xin Liu. "On the difficulty of membership inference attacks." Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.
\newline
[8]. Chen, Min, et al. "When machine unlearning jeopardizes privacy." Proceedings of the 2021 ACM SIGSAC conference on computer and communications security. 2021.

\begin{change}
	\emph{VI.A Experimental Setup}
	\newline
	...
	\newline
\textbf{Evaluation Method for SCU.} 
To effectively evaluate SCU and the compared methods, we conduct experiments to unlearn the backdoored semantic communication encoder and decoder, i.e., the models are trained based on backdoored samples, and the purpose of unlearning is to erase the backdoor from the trained models. Our evaluation method is inspired by a commonly used traditional unlearning evaluation method~[14]. \rev{We choose the backdoor-based evaluation method rather than membership inference attack (MIA) methods because backdoor accuracy is more oblivious than MIA to evaluate if the sample is unlearned from the model [39].}
\newline
...
\end{change}


\RC 4. What kind of Accuracy is meant by ``Acc. on clean'' and ``Acc. on erased'' in TABLE II, Model Accuracy or Backdoor Accuracy? Why is there a big difference between the two values on CIFAR10, CIFAR100 datasets but not on MNIST?



\AR We thank the reviewer's insightful comments. The ``Acc. on clean'' and ``Acc. on erased'' in TABLE II are the model accuracy on the clean test dataset and the backdoor accuracy on the erased backdoored dataset. For clarity, we changed ``Acc. on erased'' to ``Bac. Acc. on erased''. The clean test dataset is the dataset prepared for testing and not in the training dataset. The erased dataset is in the original training dataset but needs to be unlearned later. On MNIST, since the dataset is simple and most test data are similar to the training data, the ``Acc. on clean'' and ``Bac. Acc. on erased'' are similar. On CIFAR10 and CIFAR100, as the datasets are considerably complex, the model will commonly have a higher accuracy on the training dataset (``Bac. Acc on erased'') than on the unseen test clean dataset (``Acc. on clean''). For clarity, we revised the corresponding part as follows.


\begin{change}
	
	\setcounter{table}{1}
	\begin{table*}[h]
		% \tiny
		\scriptsize
		\caption{Overview Evaluations on MNIST, CIFAR10 and CIFAR100. }
	%	\vspace{-2mm}
		\label{tab_total}
		\resizebox{\linewidth}{!}{
			\begin{tabular}{ccccccccccccc}
				\toprule[1pt]
				\multirow{2}{*} {Evaluation Metrics} & \multicolumn{4}{c} {MNIST, ${\it EDR}=6\%$, ${\it SNR}=5$, AWGN}& \multicolumn{4}{c} {CIFAR10, ${\it EDR}=6\%$, ${\it SNR}=20$, AWGN} & \multicolumn{4}{c} {CIFAR100, ${\it EDR}=6\%$, ${\it SNR}=20$, AWGN}  \\
				\cmidrule(r){2-5}   \cmidrule(r){6-9} \cmidrule(r){10-13}
				& Origin  		& HBU   &VBU		 	& SCU		& Origin 		& HBU 		&VBU  		& SCU & Origin 		& HBU 		&VBU  		& SCU \\
				\midrule %\thinmidrule
				\rev{Bac. Acc. on erased} 	& 97.72\%  & \textbf{0.06\%}   &2.11\%      & 7.28\%      & 98.53\%	  & \textbf{2.40\%}    &7.27\%	&4.17\% & 94.64\% & \textbf{0.08\%}	&0.80\% 		& 7.12\%\\
				Acc. on clean  	 & 97.17\%   &0.01\% &68.19\%    & \textbf{97.56\%}    & 67.23\%	 & 42.90\%  &47.13\% &\textbf{55.00\%}& 43.84\% & 6.68\%		&15.04\%  		& \textbf{27.84\%} \\
				%Acc on test  	  & 97.05\%  &75.20\% &52.19\%    & 94.47\%    & 55.40\%	 & 30.85\%  &40.21\% &43.01\%\\
				MSE on erased  & 2.92 		 & 83.33   & 77.50       & \textbf{6.13 }   		  & 39.42	      & 56.76      &61.27     &\textbf{45.18}& 26.87		& 467.58 &55.61  		& \textbf{35.41} \\
				MSE on clean    & 2.79 		  & 74.90    &71.94        & \textbf{2.80 }  		& 39.24	       & 54.21       &58.08     &\textbf{43.31}& 27.09 & 443.23 		&51.29 & \textbf{33.45} \\
				%MI on erased     & -   			 & -   			&-       		& -          		& -       			& -     			& -        & -   \\
				%MI on clean       & -    		  & -   		 &-          	  & -     			 & -    			 & -  				 & -    & -\\
				Running time (s)  & 275       &13.80 &\textbf{0.31}  & 2.1         & 2120       & 106.07     & \textbf{1.60}         &2.23& 2120 		& 106.07 		&\textbf{1.88 } 		& 3.08 \\
				\bottomrule[1pt]
		\end{tabular}}
		\vspace{-4mm}
		\begin{tabbing}
			\rev{Bac. Acc. on erased: Backdoor accuracy on erased dataset; Acc. on clean: Model accuracy on test clean dataset.}
		\end{tabbing}
	\end{table*}
	
	\emph{VI.B Evaluation Overview}
	\newline
	...
	\newline
\textbf{Setup.} 
In these experiments, conducted across MNIST, CIFAR10, and CIFAR100 datasets, the erased data ratio (${\it EDR}$) is set at 6\% of the full original dataset, with the addition of AWGN channels. On MNIST, we set the ${\it SNR}=5$, while, on CIFAR10 and CIFAR100, we set the ${\it SNR}=20$. We set a higher ${\it SNR}$ for CIFAR10 and CIFAR100 because these two datasets are more complex than MNIST. More noise, such as ${\it SNR}=5$, decreases the semantic communication model utility worse. We assess the unlearning effect from four aspects: accuracy of the downstream model on the decoded clean data, backdoor accuracy on the decoded erased data and decoding MSE on the clean and the erased data. \rev{The clean test dataset is the dataset prepared for testing and not in the training dataset. The backdoored erased dataset is in the original training dataset but needs to be unlearned later.} We evaluate the efficiency by the running time of the methods. 
	\newline
	...
\end{change}

\RC 5. In Ablation Study section, SCU w/o CC section has no advantage over VBU algorithm, does it indicate that VBU+CC may be a better algorithm?


% We thank the reviewer for this suggestion.
\AR We thank the reviewer for this insightful comment. It is true that ``SCU w/o CC'' performs similarly to the VBU. The main reason could be that VIB and VAE have the same expansion mathematic form for optimization, which is already proven in [9]. Hence, the corresponding VBU unlearning methods perform similarly to SCU without the CC compensation. As you suggested, if we use VBU+CC, it should also achieve similar performance as SCU. It also indicates that the CC component is effective to improve the model utility preservation in machine unlearning. We revised the corresponding part as follows.

[9]. Alemi, Alexander A., et al. "Deep variational information bottleneck." arXiv preprint arXiv:1612.00410 (2016, citation:1860).

 
 

\begin{change}
\emph{VII.F. Ablation Study}
\newline
...
\newline
In Figures \subref{fig:mnistaccercurveablation} and \subref{fig:mnistbackaccercurveablation}, we can see that the ``SCU w/o CC'' performs similarly to VBU. \rev{Without the contrastive compensation, the only joint unlearning is similar to VBU. Since both VIB and VAE have the same expansion mathematic form for optimization, the corresponding unlearning methods perform similarly without the CC compensation. The results of ``VBU w Sparsity'' show that the model sparsity does improve the unlearning effectiveness but has a slight model utility degradation. Compared with considering model sparsity, our method with contrastive compensation, SCU,  significantly preserves the model utility while slightly mitigating the unlearning effect.} And all three subfigures in \Cref{ablation_study} demonstrate that the improvement of SCU with the constructive compensation.

\end{change}





\RC 6. The meaning of $\mathbf{z}_e'$ in Fig.2 is not clear.
%We thank the reviewer for this suggestion.

\AR We thank the reviewer for pointing out this. $\mathbf{z}_e'$ is the erased representation with the channel signal noise. During semantic communication, the transfered representation between encoder and decoder should be dealed through physical channel, i.e., $\mathbf{z'} = \text{H}\mathbf{z} + \mathbf{n}$, where $\text{H} \in \mathbb{C}^{N_r \times N_t}$ denotes the channel matrix and $\mathbf{n} \in \mathbb{C}^{N_r \times 1} \sim \mathcal{CN}(0,\sigma^2\text{I})$ is the additive white Gaussian noise (AWGN). Hence, $z_e'$ can also be represented as $\mathbf{z}_e' = \text{H}\mathbf{z}_e + \mathbf{n}$. We revised the corresponding part as follows.

\setcounter{figure}{1}

\begin{figure*}[h]
	\centering
	\includegraphics[width=0.95\linewidth]{../../../../../绘图/2023/INFOCOM_semantic_unl/two_step_semantic_unl}
	\caption{The overall procedure of SCU. First, we remove the influence of erased data from both semantic encoder $f_\theta$ and decoder $g_\theta$ via minimizing the mutual information between the semantic extracted representation $z_e$ and the specified sample ($i_e$); \rev{we name the process as joint unlearning, as shown in red arrows, where $\mathbf{z}_e'$ and $\mathbf{z}_r'$ mean the representations with simulated channel noise.} Second, we retrain the unlearned models based on the remaining dataset using contrastive compensation to achieve semantic consistency, as shown in green arrows.
	}
	\label{fig_twostagesemanticunlprocess}
\end{figure*}

\begin{change}
	\emph{III.C. Building Semantic Communication with Unsupervised VIB}
 
We implement the semantic communication models following the mainstream semantic communication framework, JSCC [35], where the transmitter owns the encoder $f_\theta$ and the receiver has the decoder $g_\theta$. They communicate through a physical channel. For easy to introduce, we assume that the system has $N_t$ transmitting antennas and $N_r$ receiving antennas. Then, the encoding symbol stream of the transmitter can be described as $\mathbf{z} = f_\theta(x), \mathbf{z} \in \mathbb{C}^{N_t \times 1}$, and $f_{\theta}$ is the encoder of VIB models that we introduce above. \rev{Subsequently, the received signal can be described as $\mathbf{z'} = \text{H}\mathbf{z} + \mathbf{n}$, where $\text{H} \in \mathbb{C}^{N_r \times N_t}$ denotes the channel matrix and $\mathbf{n} \in \mathbb{C}^{N_r \times 1} \sim \mathcal{CN}(0,\sigma^2\text{I})$ is the additive white Gaussian noise (AWGN).} The notation $\text{I}$ denotes an identity matrix. Correspondingly, the decoding stream of the receiver can be represented as $\hat{ \text{x} } = g_\theta(\mathbf{z'})$. The procedure to train a semantic communication system is similar to the joint training process as illustrated in the upper half of \Cref{fig_twostagesemanticunlprocess}, but with an unsupervised VIB loss function \Cref{eq:total_loss_q}. 




\end{change}


\pagebreak


%\small
%\footnotesize
%\bibliographystyle{IEEEtranN}
%\bibliographystyle{IEEEtranN}
%\bibliography{../CFDPD}

\end{document}
