\begin{abstract}
% We present \method, a feed-forward and differentiable system that infers high-quality camera poses and 3D geometry from uncalibrated sparse-view images, enabling photo-realistic novel view synthesis via Gaussian Splatting.
% %
% In 3D reconstruction, camera poses provide crucial geometric constraints that connect 2D images with 3D geometry, significantly simplifying the reconstruction process, particularly with sparse-view images.
% %
% Inspired by the insight, we introduce a novel cascaded learning paradigm that first estimates camera poses from sparse views and then leverages the estimates to guide the subsequent geometry and appearance learning, effectively decomposing the complex joint optimization into manageable sub-tasks and achieving superior performance in camera pose estimation, geometry reconstruction, and novel view synthesis.
% %
% In geometry reconstruction, we propose a two-stage approach that utilizes the estimated poses: first predicting camera-centric pointmaps, then unifying them into a coherent global structure through a neural scene projector.
% %
% Our method further learns 3D Gaussians based on the predicted geometry to enable novel view synthesis.
% %
% Trained on large-scale public datasets, our model achieves state-of-the-art performance in pose estimation, geometry reconstruction, and novel view synthesis with an inference time less than 0.5 seconds, substantially faster than previous optimization-based methods.
% %
% Extensive experiments demonstrate that our approach can effectively reconstruct 3D scenes from as few as 2-8 input images, making it suitable for real-world applications with uncalibrated sparse views.
We present \method, a feed-forward model designed to infer high-quality camera poses and 3D geometry from uncalibrated sparse-view images (\textit{i.e.}, as few as 2-8 inputs), which is a challenging yet practical setting in real-world applications.
%
Our solution features a cascaded learning paradigm with camera pose serving as the critical bridge, recognizing its essential role in mapping 3D structures onto 2D image planes.
%
Concretely, \method starts with camera pose estimation, whose results condition the subsequent learning of geometric structure and appearance, optimized through the objectives of geometry reconstruction and novel-view synthesis.
%
Utilizing large-scale public datasets for training, our method delivers state-of-the-art performance in the tasks of pose estimation, geometry reconstruction, and novel view synthesis, while maintaining the inference efficiency (\textit{i.e.}, less than 0.5 seconds). The project page and code can be found at: \url{https://zhanghe3z.github.io/FLARE/}


% This paper studies the problem of 3D reconstruction from uncalibrated sparse-view images and presents \method, a feed-forward approach that infer high-quality 3D scene geometry and camera poses, and enable photorealistic novel view synthesis even from casually captured images.
% %
% Our proposed \method explores the relationship between camera poses and scene geometry in learnable 3D reconstruction, forming a novel cascaded learning paradigm to decompose the challenging problem into manageable sub-tasks and thus achieves superior performance.
% % camera pose regression, camera-centric pointmap prediction and scene geometry unification, as well as 3D Gaussian-based novel view synthesis. 
% Trained on large-scale public datasets, our model achieves state-of-the-art performance in camera pose estimation, geometry reconstruction, and novel view synthesis with an inference time less than 0.5 seconds, substantially faster than previous optimization-based methods. Extensive experiments demonstrate that our approach can effectively reconstruct 3D scenes from as few as 2-8 input images, making it suitable for real-world applications with uncalibrated sparse views.
\end{abstract}