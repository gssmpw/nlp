\section{Related Work}
\label{section:ads}

In recent years, autonomous driving technology has grown rapidly. With quick advancements and new solutions, various ADS have emerged and continue to evolve \citep{zhao2024autonomous}. As these systems become more complex, the methods for testing them are also changing \citep{li2024choose}. To create a simulation platform that meets developing needs, we have studied the main ADS technical pipelines, especially from the validation perspective, and explored effective ways to test and improve their performance.

\begin{figure*}
    \centering
    \includegraphics[width=0.85 \linewidth]{ads_system.pdf}
    \caption{\textrm{Multiple technology pipelines for autonomous driving systems.}}
    \label{fig:ads_system}
\end{figure*}

\subsection{ADS Pipelines}

As shown in Figure~\ref{fig:ads_system}, mainstream ADS  can be categorized into three types of technical pipelines: Modular ADS, End-to-end ADS, and Knowledge-driven ADS \citep{chen2024end}. The following is a detailed introduction.

\subsubsection{Modular ADS}


The development of ADS has been significantly influenced by machine learning \citep{huang2020autonomous}. In the early stages, limitations in computing power, neural network size, and the scale of training data prevented a single model from handling the entirety of autonomous driving tasks. To address these constraints, researchers divided the overarching task into multiple sequential sub-tasks, enabling focused development on specific aspects of the system \citep{chen2015deepdriving,maddern20171,bachute2021autonomous}. This modular approach facilitated rapid industrial adoption of ADS technologies, which in turn attracted substantial investment and accelerated progress in the field.

As depicted in Figure~\ref{fig:ads_system}, modular ADS consists of multiple interconnected modules, typically categorized into perception, prediction, and planning \citep{mozaffari2020deep,kiran2021deep}. Some designs integrate prediction and planning into a single module and add a separate control module \citep{zhu2021survey}. Each module operates independently and is trained with its own task-specific loss function \citep{grigorescu2020survey}. This design simplifies practical implementation by isolating tasks, but it also introduces challenges. Fragmentation makes error tracing difficult and can lead to error accumulation across modules. Furthermore, requiring different models for each task reduces computational efficiency and increases the risk of local optima \citep{chib2023recent}.

Another key challenge is evaluation. Testing platforms must provide appropriate inputs for each sub-model and establish an evaluation system capable of attributing responsibility for errors accurately \citep{chao2020survey}. Despite these challenges, modular ADS remains widely used in industry due to its robustness and adaptability. Many modular algorithms and models are expected to persist as redundant components in future systems, serving as safety-enhancing fallbacks \citep{yurtsever2020survey}.

\subsubsection{End-to-End ADS}


Attempts at end-to-end ADS began as early as 1988 with ALVINN, a system that employed a shallow neural network to drive a vehicle \citep{pomerleau1988alvinn}. However, early systems faced severe limitations in generalization and were ineffective in complex traffic scenarios. Over time, advances in computational power and algorithmic sophistication enabled significant progress in end-to-end approaches. Modern end-to-end ADS leverages a single integrated model to perform all driving tasks \citep{zeng2019end,tampuu2020survey,chitta2021neat}. While it may still employ a modular structure, the entire model is trained jointly, optimizing for the ultimate driving task \citep{le2022survey}. This integrated approach offers several advantages. By reducing system complexity and improving computational and training efficiency, end-to-end ADS can adapt more readily to complex traffic conditions\citep{hu2023planning}. Joint training also mitigates issues of error propagation between modules, a common problem in modular systems \citep{casas2021mp3,chib2023recent}.

Nevertheless, end-to-end ADS faces unique challenges, particularly in testing. Open-loop testing often fails to capture real-world complexities, as predictions on test datasets closely match ground truth, resulting in high scores \citep{caesar2021nuplan,jia2024bench2drive}. In contrast, real-world driving involves continuous decision-making, where small errors accumulate over time and unanticipated events challenge the system's robustness \citep{zhang2022rethinking,chen2024end}. Consequently, realistic, interactive, and editable closed-loop testing environments are crucial for accurately evaluating the performance of end-to-end ADS.

\subsubsection{Knowledge-Driven ADS}



Despite significant advancements in autonomous driving, the diversity and complexity of road environments continue to create endless corner cases \citep{bolte2019towards}. A common strategy to address this issue is collecting more data for training \citep{li2022coda}. However, the sheer variability of driving scenarios renders data collection an unending task. The root of the problem lies in the separation of model training and deployment. Unlike human drivers, whose skills improve with experience, traditional ADS models lack mechanisms for continuous learning \citep{lan2022instance,wen2023dilu}.

Knowledge-driven ADS seeks to bridge this gap by adopting a design that enables continuous learning during operation \citep{mao2023gpt,li2023towards,xu2024drivegpt4,tang2024grounded}. This approach draws inspiration from human drivers, who not only learn vehicle operation and traffic rules but also refine their skills through real-world experience. Leveraging pre-trained models with advanced knowledge and reasoning capabilities, such as large language models (LLMs), knowledge-driven ADS systems can explore environments, respond to unexpected situations, and accumulate experience through reflective learning \citep{sha2023languagempc,cui2023drivellm,wen2023dilu,mei2024continuously}.

So far, the effectiveness of knowledge-driven ADS has primarily been demonstrated in simulation environments \citep{jin2023surrealdriver,chen2024driving,cui2024drive}. This design paradigm, however, introduces promising insights for future ADS development. Like end-to-end systems, knowledge-driven ADS requires high-quality closed-loop testing environments to support interaction and the accumulation of driving experience. Additionally, pre-trained models often rely on generic data, which can lead to format mismatches with autonomous driving-specific datasets \citep{cui2024survey}. Testing platforms must therefore provide robust tools for format conversion, control interfaces, and auxiliary functionalities to fully realize the potential of knowledge-driven ADS.

The distinct advantages and unique challenges of modular, end-to-end, and knowledge-driven ADS methodologies highlight the critical need for robust simulation and testing platforms, which remain pivotal for advancing ADS toward widespread adoption.

\subsection{Validation and Enhancement of ADS}

To accurately assess performance at various stages of ADS development, testing methods are adjusted accordingly. In this section, we survey and compare widely used testing methods and summarize the requirements for building a closed-loop autonomous driving testing platform.

\subsubsection{Dataset and Benchmark}


Creating datasets and benchmarks is a fundamental approach for training and evaluating autonomous driving models. These datasets are typically constructed by collecting data from vehicle-mounted or roadside sensors, which are then labeled according to the specific requirements of the task. Well-known autonomous driving datasets include KITTI \citep{geiger2013vision}, BDDV \citep{xu2017end}, HDD \citep{ramanishka2018toward}, nuScenes \citep{caesar2020nuscenes}, and Waymo Open Dataset \citep{sun2020scalability}. These datasets are gathered using a variety of sensors, such as cameras, LiDAR, radar, and GPS, which capture data on traffic participants and their behaviors. The labeled data serves as the foundation for training models, enabling the advancement of cutting-edge algorithms in the field of autonomous driving \citep{li2024ego,wang2024driving,zheng2025genad}. Due to the significant cost and labor involved in the collection of real-world data, many research teams rely on these widely used, open-source datasets, which help establish baseline standards for model performance \citep{feng2020deep,liu2024survey}. Additionally, these datasets often come with predefined evaluation metrics and benchmarks, which are critical for comparing the performance of different models across a variety of tasks \citep{guo2019safe}.

Open-loop datasets, which are directly sourced from real-world driving environments, provide authentic training samples and create a shared platform for models to compete on. This has been a significant advancement in autonomous driving research, enabling researchers to test their models against the same set of real-world data. However, while these datasets offer valuable insights, they have limitations. Specifically, open-loop datasets do not provide feedback on model outputs; they simply measure the discrepancy between model predictions and the ground-truth labels \citep{codevilla2019exploring,caesar2021nuplan}. This creates a gap in fully assessing the modelâ€™s actual performance in real-world conditions. The issue is twofold: first, a small gap between model output and labels indicates that the model is feasible but does not necessarily imply optimal performance. Second, task-specific evaluation metrics do not always correlate with the broader success of an ADS \citep{zhang2022rethinking,ljungbergh2025neuroncap,yang2024drivearena}. A model may perform well on a specific task but still fail to operate effectively in the context of a fully integrated ADS.

Moreover, the high cost of real-world data collection limits the scalability of datasets, preventing researchers from capturing rare or complex driving scenarios \citep{chitta2022transfuser,shao2023safety}. This limitation slows the development of more robust ADS technologies. In conclusion, while open-loop datasets and benchmarks are critical for advancing research, their static nature and the challenges of real-world data collection highlight the need for new approaches, such as simulation-based data generation, to overcome these barriers and improve the generalization of autonomous systems \citep{hu2023simulation,tian2024robust}.

\subsubsection{Simulation}

Autonomous driving simulators can be roughly categorized into flow-based, vehicle-based, and data-based \citep{wenl2023limsim}.

Flow-based simulation systems have been developed over the years to assist urban planners and traffic managers. Notable examples include PARAMICS \citep{cameron1996paramics}, a commercial software released in 1998, which integrates traffic simulation, visualization, road network design, and adaptive signal control. Vissim \citep{fellendorf2010microscopic}, another commercial tool, offers high-level visualizations of traffic scenarios using realistic models. CORSIM \citep{halati1997corsim}, supported by the Federal Highway Administration, specializes in road geometry, traffic control, and large-scale simulations. Aimsun \citep{barcelo2005dynamic} is a widely used software for traffic planning and demand analysis, while SUMO is an open-source tool for modeling urban traffic and intermodal transportation systems, offering features like route planning and emission calculations. Despite their strength in simulating large-scale traffic networks, flow-based simulators use simple car-following models, limiting their ability to accurately capture detailed vehicle behavior and microscopic movements \citep{kotusevski2009review}.

Vehicle-based simulators provide more dynamic and realistic simulations by focusing on vehicle-specific behaviors \citep{gog2021pylot,xu2023opencda,bockman2024aark}. Early autonomous driving simulators, such as USARSim \citep{carpin2007usarsim} and Webots \citep{michel2004cyberbotics}, utilized modified game engines to simulate physical interactions. Today, simulators like Gazebo \citep{koenig2004design}, AirSim, LGSVL \citep{rong2020lgsvl}, and CARLA offer advanced features. Gazebo is a flexible 3D simulator often used with ROS \citep{quigley2009ros} for dynamic rendering and object interaction. AirSim, based on Unreal Engine \citep{sanders2016introduction}, provides high-fidelity vehicle simulations and a variety of urban scenarios. LGSVL, built on Unity \citep{haas2014history}, supports detailed sensor simulations like LiDAR and radar. CARLA, also open-source, offers customizable environments and sensor suites for autonomous driving research. Vehicle-based simulators allow for precise vehicle motion modeling and decision-making algorithm testing. However, they fall short in simulating realistic background traffic flow, as they lack the capacity for dynamic vehicle interaction on a larger scale \citep{wenl2023limsim}.

Data-based simulators leverage traffic flow data to simulate realistic driving scenarios \citep{hallyburton2023avstack}. These systems generate vehicle behavior based on historical data, making it challenging to model interactions between the ego vehicle and other road users. SimNet, the first machine learning-based simulator, generates realistic driving episodes from historical data and improves as more data is used. InterSim \citep{sun2022intersim} and TrafficGen \citep{feng2023trafficgen}, both data-driven systems, simulate vehicle interactions and generate diverse traffic scenarios. Data-based simulators are effective at learning multi-vehicle interactions from real-world data, but they are highly dependent on the available dataset, which limits their ability to create new, diverse scenarios and can lead to fragmented simulations \citep{mutsch2023model}.

In general, a simulation platform that can efficiently generate detailed scenarios while balancing real-time performance and simulation fidelity, and readily support the creation of long-term dynamic traffic data and convenient in-depth evaluation, is crucial for advancing autonomous driving development.