\documentclass{article}



\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
% \usepackage{lipsum}		% Can be removed after putting your text content
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}


% \documentclass[a4paper,fleqn]{cas-sc}
% \definecolor{mycolor}{RGB}{0,128,174}
% \usepackage{color, xcolor}
% \usepackage{soul}
% \hypersetup{colorlinks=true,
%             linkcolor=mycolor,
%             filecolor=gray,      
%             urlcolor=mycolor,
%             citecolor=mycolor,}
% \usepackage[authoryear, comma, colon]{natbib}
% \usepackage{ulem}
\usepackage{booktabs}
\usepackage[title]{appendix}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage{subcaption}

\usepackage{booktabs}  
\usepackage{multirow}  
\usepackage{makecell}
\usepackage{fancyhdr}

% \sethlcolor{yellow}
% \soulregister{\cite}7
% \soulregister{\citep}7
% \soulregister{\citet}7
% \soulregister{\ref}7
% \soulregister{\pageref}7


% \newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}

% \def\tsc#1{\csdef{#1}{\textsc{\lowercase{#1}}\xspace}}
% \tsc{WGM}
% \tsc{QE}
% \tsc{EP}
% \tsc{PMS}
% \tsc{BEC}
% \tsc{DE}

% \flushbottom

% \begin{document}
% \captionsetup[figure]{labelfont={bf},labelformat={default},labelsep=period,name={\textrm{Figure}}}
% \captionsetup[table]{labelfont={bf},labelformat={default},labelsep=period,name={\textrm{Table}}}
% \let\WriteBookmarks\relax
% \def\floatpagepagefraction{1}
% \def\textpagefraction{.001}

% \shorttitle{\textrm{LimSim Series}}
% \shortauthors{\textrm{Fu D., Zhong N., Han X.,  et~al.}}
% \title [mode = title]{LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement}                         
% \let\printorcid\relax
% \author[1]{\textcolor{black}{Daocheng Fu}}
% \ead{fudaocheng@pjlab.org.cn}
% \fnmark[1]

% \author[2,1]{\textcolor{black}{Naiting Zhong}}
% \ead{zhongnaiting@pjlab.org.cn}
% \fnmark[1,2]

% \author[3,1]{\textcolor{black}{Xu Han}}
% \ead{xhanab@connect.ust.hk}
% \fnmark[1,2]

% \author[1]{\textcolor{black}{Pinlong Cai}}
% \ead{caipinlong@pjlab.org.cn}
% \cormark[1]

% \author[1]{\textcolor{black}{Licheng Wen}}
% \ead{wenlicheng@pjlab.org.cn}

% \author[1]{\textcolor{black}{Song Mao}}
% \ead{maosong@pjlab.org.cn}

% \author[1]{\textcolor{black}{Botian Shi}}
% \ead{shibotian@pjlab.org.cn}

% \author[1]{\textcolor{black}{Yu Qiao}}
% \ead{qiaoyu@pjlab.org.cn}

% \cortext[cor1]{Corresponding author: Pinlong Cai}
% \fntext[cor1]{These authors contributed equally: Daocheng Fu, Naiting Zhong, Xu Han.}
% \fntext[2]{This work was done during the internships of Naiting Zhong and Xu Han
% at Shanghai Artificial Intelligence Laboratory.}

% \affiliation[1]{organization={Shanghai Artificial Intelligence Laboratory},
%     city={Shanghai},
%     postcode={200232}, 
%     country={China}}

% \affiliation[2]{organization={Tongji University},
%     city={Shanghai},
%     postcode={200070}, 
%     country={China}}

% \affiliation[3]{organization={The Hong Kong University of Science and Technology (Guangzhou)},
%     city={Guangzhou},
%     postcode={511453}, 
%     country={China}}


\title{LimSim Series: An Autonomous Driving Simulation Platform for Validation and Enhancement}

%\date{September 9, 1985}	% Here you can change the date presented in the paper title
\date{} 					% Or removing it

% \author{ \href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}David S.~Hippocampus}\thanks{Use footnote for providing further
% 		information about author (webpage, alternative
% 		address)---\emph{not} for acknowledging funding agencies.} \\
% 	Department of Computer Science\\
% 	Cranberry-Lemon University\\
% 	Pittsburgh, PA 15213 \\
% 	\texttt{hippo@cs.cranberry-lemon.edu} \\
% 	%% examples of more authors
% 	\And
% 	\href{https://orcid.org/0000-0000-0000-0000}{\includegraphics[scale=0.06]{orcid.pdf}\hspace{1mm}Elias D.~Striatum} \\
% 	Department of Electrical Engineering\\
% 	Mount-Sheikh University\\
% 	Santa Narimana, Levand \\
% 	\texttt{stariate@ee.mount-sheikh.edu} \\
% 	%% \AND
% 	%% Coauthor \\
% 	%% Affiliation \\
% 	%% Address \\
% 	%% \texttt{email} \\
% 	%% \And
% 	%% Coauthor \\
% 	%% Affiliation \\
% 	%% Address \\
% 	%% \texttt{email} \\
% 	%% \And
% 	%% Coauthor \\
% 	%% Affiliation \\
% 	%% Address \\
% 	%% \texttt{email} \\
% }

\author{
{\bf Daocheng Fu$^{1\dagger}$, Naiting Zhong$^{2,1\dagger}$, Xu Han$^{3,1\dagger}$, Pinlong Cai$^{1\spadesuit}$, Licheng Wen$^{1}$,  Song Mao$^{1}$, } \\ \\
{\bf Botian Shi$^{1}$, Yu Qiao$^{1}$} \\ \\
$^\dagger$~Equal Contributors \; 
$^{\spadesuit}$~Corresponding Author ( \texttt{caipinlong@pjlab.org.cn})\\ \\
$^{1}$~Shanghai Artificial Intelligence Laboratory, Shanghai, China  \; 
$^{2}$~Tongji University, Shanghai, China  \\ \\ 
$^{3}$~The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China
}


% \begin{keywords}
%     Autonomous Driving \sep Simulation \sep Evaluation \sep Multi-Modal LLM \\ End-to-end System \\ Knowledge-driven System
% \end{keywords}


\begin{document}
\maketitle
\begin{abstract}
	
Closed-loop simulation environments play a crucial role in the validation and enhancement of autonomous driving systems (ADS). However, certain challenges warrant significant attention, including balancing simulation accuracy with duration, reconciling functionality with practicality, and establishing comprehensive evaluation mechanisms. This paper addresses these challenges by introducing the LimSim Series, a comprehensive simulation platform designed to support the rapid deployment and efficient iteration of ADS. The LimSim Series integrates multi-type information from road networks, employs human-like decision-making and planning algorithms for background vehicles, and introduces the concept of the Area of Interest (AoI) to optimize computational resources. The platform offers a variety of baseline algorithms and user-friendly interfaces, facilitating flexible validation of multiple technical pipelines. Additionally, the LimSim Series incorporates multi-dimensional evaluation metrics, delivering thorough insights into system performance, thus enabling researchers to promptly identify issues for further improvements. Experiments demonstrate that the LimSim Series is compatible with modular, end-to-end, and VLM-based knowledge-driven systems. It can assist in the iteration and updating of ADS by evaluating performance across various scenarios. The code of the LimSim Series is released at: \href{https://github.com/PJLab-ADG/LimSim}{https://github.com/PJLab-ADG/LimSim}.
\end{abstract}


% keywords can be removed
\keywords{    Autonomous Driving \and Simulation \and Multi-Modal LLM \and End-to-End System \and Knowledge-Driven System}


\section{Introduction}

Validating and enhancing autonomous driving systems (ADS) within closed-loop simulation environments has become a critical focus of recent intelligent transportation research \citep{gulino2024waymax,ljungbergh2025neuroncap,yang2024drivearena}. Such environments offer a continuous cycle of data collection, model training, and performance evaluation, expanding the capabilities of ADS by providing invaluable feedback loops \citep{codevilla2019exploring}. From a temporal perspective, closed-loop environments enable the exploration of long-term performance of decision-making and planning. Spatially, they offer diverse and dynamic scenarios that help uncover corner cases. In terms of control continuity, closed-loop simulation evaluates the interaction of different system modules, thereby revealing potential weaknesses. This makes closed-loop simulation indispensable in the development and refinement of ADS \citep{zhang2022rethinking}. However, building an effective closed-loop autonomous driving simulation must strike a balance between realism, system requirements, and performance \citep{fu2024limsim++}. Achieving this requires not only designing realistic driving scenarios but also meeting the diverse and evolving needs of ADS technologies. Current autonomous driving simulation platforms still face several key challenges.

First, \textbf{Difficulty in Balancing Simulation Accuracy and Duration.} Although existing simulators 
% such as CARLA , AirSim \citep{shah2018airsim}, SimNet , and TrafficGen \citep{feng2023trafficgen}, 
have made significant strides in realism, providing diverse and complex driving scenarios, these simulators often face the challenge of balancing simulation accuracy with duration. Real-time performance constraints require compromises in accuracy, which can undermine the effectiveness of the simulation \citep{gog2021pylot}. For example, vehicle-based simulators like CARLA \citep{dosovitskiy2017carla} and AirSim \citep{shah2018airsim} typically provide rigid control over background vehicles, limiting the realism of traffic interactions. On the other hand, data-driven simulators such as SimNet \citep{bergamini2021simnet} and TrafficGen \citep{feng2023trafficgen}, which rely on real-world driving data, struggle to scale for large-scale, long-duration simulations. This trade-off between accuracy and simulation efficiency diminishes the reliability of the validation process, making it difficult to simulate real-world scenarios that call for both precision and long-term performance assessment.
    

Second, \textbf{Conflict between Functionality and Practicality.} As autonomous driving research progresses, ADS architectures undergo multiple iterations, resulting in modular \citep{zhu2021survey}, end-to-end \citep{chen2024end}, and knowledge-driven technical pipelines \citep{li2023towards}. These pipelines often have specific and varied requirements for inputs and outputs during the validation process. When developers aim to test and refine their systems using existing simulators,
%like CARLA or SUMO (\cite{lopez2018microscopic})
they frequently encounter challenges related to these simulators' inflexibility. For example, these platforms may struggle to adapt algorithms and manage upstream and downstream data in ways that align with different pipeline architectures. This often necessitates considerable time and effort to configure the environment, which can be especially cumbersome when testing individual modules like decision-making algorithms that may not independently control a vehicle \citep{fu2024limsim++}. To address this issue, providing baseline algorithms that can serve as placeholders or default solutions for missing components can streamline testing. While platforms like Apollo and Autoware offer comprehensive baseline algorithms and modular designs, they are often too complex for general researchers due to steep learning curves and high access barriers \citep{hallyburton2023avstack,ochs2024one}. Thus, these platforms slow down the iteration process, which delays the advancement of ADS development.


Third, \textbf{Lack of a Comprehensive and Reasonable Evaluation System.} Traditional open-loop evaluation systems assess individual tasks in the autonomous driving pipeline, such as measuring perception accuracy using metrics like Average Precision with Heading (APH) and Intersection over Union (IoU) \citep{feng2020deep}, or evaluating trajectory prediction with Average Displacement Error (ADE) and Final Displacement Error (FDE) \citep{huang2022survey}. While these metrics are valuable for assessing specific modules, they fail to offer a holistic evaluation of the entire ADS. In contrast, closed-loop simulation enables continuous sampling in a data space, which requires a corresponding evaluation system capable of handling continuous data inputs. Most current closed-loop systems evaluate performance using metrics such as human-driving similarity, traffic rule violations, and goal achievement \citep{caesar2021nuplan}. However, these metrics have notable limitations. For instance, they may fail to capture the root causes of issues, such as errors in earlier stages of decision-making that lead to collisions later in the simulation. A robust evaluation system must be able to identify key moments and scenes where performance deviates from expectations, enabling developers to pinpoint problematic modules \citep{li2023survey}. Furthermore, for systems with multiple interacting components, the evaluation system should be capable of assigning responsibility to the correct module to ensure accurate performance metrics \citep{li2024data}. Thus, a comprehensive evaluation framework is essential for the continuous improvement of ADS, ensuring that all modules are properly tested and refined.

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{intro.pdf}
    \caption{\textrm{The LimSim Series is all you need for agile and effective autonomous driving simulation.}}
    \label{fig:intro}
\end{figure*}

To address these challenges and further the validation and enhancement of ADS in closed-loop environments, we developed the LimSim Series, a comprehensive simulation platform. As illustrated in Figure~\ref{fig:intro}, through the integration of multi-type information from road network, the LimSim Series controls background vehicles through human-like decision-making and planning algorithms, creating realistic driving scenarios for algorithm testing. This approach balances simulation efficiency with quality by introducing the concept of the Area of Interest (AoI), which optimizes computational resources and enables macro-micro interactive simulation. The LimSim Series also offers a variety of baseline algorithms and user-friendly interfaces, facilitating the rapid deployment of diverse ADS and algorithms. These features support flexible validation of multiple technical pipelines, allowing researchers to efficiently test different modules and configurations. Moreover, the LimSim Series incorporates multi-dimensional evaluation metrics, which provide detailed insights into system performance, helping researchers quickly identify issues and areas for improvement. 

The contributions of this paper are summarized as follows:

\begin{itemize}
% [itemsep=0pt,topsep=0pt,parsep=0pt]
    \item Integrated framework for ADS pipelines and closed-Loop simulation: We delve into an in-depth analysis of the key challenges in the development of closed-loop simulation environments, highlighting the importance of an ADS simulation platform that supports multi-source inputs and diverse technological pipelines, thereby proposing a comprehensive simulation framework.

    \item Development of the LimSim Series: We introduce the open-source autonomous driving simulation platform designed to support rapid deployment and efficient iteration. With its modular architecture and built-in baseline algorithms, the LimSim Series enables flexible validation of multiple ADS pipelines. The platform’s comprehensive evaluation system further aids in the continuous improvement of autonomous driving solutions.

    \item Extensive experimental validation: We conduct extensive experiments to test different technical pipelines with multi-modal inputs, demonstrating how the LimSim Series can effectively validate and enhance ADS performance and highlighting its potential to accelerate the development of reliable and efficient ADS.
\end{itemize}

\section{Related Work}


\label{section:ads}

In recent years, autonomous driving technology has grown rapidly. With quick advancements and new solutions, various ADS have emerged and continue to evolve \citep{zhao2024autonomous}. As these systems become more complex, the methods for testing them are also changing \citep{li2024choose}. To create a simulation platform that meets developing needs, we have studied the main ADS technical pipelines, especially from the validation perspective, and explored effective ways to test and improve their performance.

\begin{figure*}
    \centering
    \includegraphics[width=0.85 \linewidth]{ads_system.pdf}
    \caption{\textrm{Multiple technology pipelines for autonomous driving systems.}}
    \label{fig:ads_system}
\end{figure*}

\subsection{ADS Pipelines}

As shown in Figure~\ref{fig:ads_system}, mainstream ADS  can be categorized into three types of technical pipelines: Modular ADS, End-to-end ADS, and Knowledge-driven ADS \citep{chen2024end}. The following is a detailed introduction.

\subsubsection{Modular ADS}


The development of ADS has been significantly influenced by machine learning \citep{huang2020autonomous}. In the early stages, limitations in computing power, neural network size, and the scale of training data prevented a single model from handling the entirety of autonomous driving tasks. To address these constraints, researchers divided the overarching task into multiple sequential sub-tasks, enabling focused development on specific aspects of the system \citep{chen2015deepdriving,maddern20171,bachute2021autonomous}. This modular approach facilitated rapid industrial adoption of ADS technologies, which in turn attracted substantial investment and accelerated progress in the field.

As depicted in Figure~\ref{fig:ads_system}, modular ADS consists of multiple interconnected modules, typically categorized into perception, prediction, and planning \citep{mozaffari2020deep,kiran2021deep}. Some designs integrate prediction and planning into a single module and add a separate control module \citep{zhu2021survey}. Each module operates independently and is trained with its own task-specific loss function \citep{grigorescu2020survey}. This design simplifies practical implementation by isolating tasks, but it also introduces challenges. Fragmentation makes error tracing difficult and can lead to error accumulation across modules. Furthermore, requiring different models for each task reduces computational efficiency and increases the risk of local optima \citep{chib2023recent}.

Another key challenge is evaluation. Testing platforms must provide appropriate inputs for each sub-model and establish an evaluation system capable of attributing responsibility for errors accurately \citep{chao2020survey}. Despite these challenges, modular ADS remains widely used in industry due to its robustness and adaptability. Many modular algorithms and models are expected to persist as redundant components in future systems, serving as safety-enhancing fallbacks \citep{yurtsever2020survey}.

\subsubsection{End-to-End ADS}


Attempts at end-to-end ADS began as early as 1988 with ALVINN, a system that employed a shallow neural network to drive a vehicle \citep{pomerleau1988alvinn}. However, early systems faced severe limitations in generalization and were ineffective in complex traffic scenarios. Over time, advances in computational power and algorithmic sophistication enabled significant progress in end-to-end approaches. Modern end-to-end ADS leverages a single integrated model to perform all driving tasks \citep{zeng2019end,tampuu2020survey,chitta2021neat}. While it may still employ a modular structure, the entire model is trained jointly, optimizing for the ultimate driving task \citep{le2022survey}. This integrated approach offers several advantages. By reducing system complexity and improving computational and training efficiency, end-to-end ADS can adapt more readily to complex traffic conditions\citep{hu2023planning}. Joint training also mitigates issues of error propagation between modules, a common problem in modular systems \citep{casas2021mp3,chib2023recent}.

Nevertheless, end-to-end ADS faces unique challenges, particularly in testing. Open-loop testing often fails to capture real-world complexities, as predictions on test datasets closely match ground truth, resulting in high scores \citep{caesar2021nuplan,jia2024bench2drive}. In contrast, real-world driving involves continuous decision-making, where small errors accumulate over time and unanticipated events challenge the system's robustness \citep{zhang2022rethinking,chen2024end}. Consequently, realistic, interactive, and editable closed-loop testing environments are crucial for accurately evaluating the performance of end-to-end ADS.

\subsubsection{Knowledge-Driven ADS}



Despite significant advancements in autonomous driving, the diversity and complexity of road environments continue to create endless corner cases \citep{bolte2019towards}. A common strategy to address this issue is collecting more data for training \citep{li2022coda}. However, the sheer variability of driving scenarios renders data collection an unending task. The root of the problem lies in the separation of model training and deployment. Unlike human drivers, whose skills improve with experience, traditional ADS models lack mechanisms for continuous learning \citep{lan2022instance,wen2023dilu}.

Knowledge-driven ADS seeks to bridge this gap by adopting a design that enables continuous learning during operation \citep{mao2023gpt,li2023towards,xu2024drivegpt4,tang2024grounded}. This approach draws inspiration from human drivers, who not only learn vehicle operation and traffic rules but also refine their skills through real-world experience. Leveraging pre-trained models with advanced knowledge and reasoning capabilities, such as large language models (LLMs), knowledge-driven ADS systems can explore environments, respond to unexpected situations, and accumulate experience through reflective learning \citep{sha2023languagempc,cui2023drivellm,wen2023dilu,mei2024continuously}.

So far, the effectiveness of knowledge-driven ADS has primarily been demonstrated in simulation environments \citep{jin2023surrealdriver,chen2024driving,cui2024drive}. This design paradigm, however, introduces promising insights for future ADS development. Like end-to-end systems, knowledge-driven ADS requires high-quality closed-loop testing environments to support interaction and the accumulation of driving experience. Additionally, pre-trained models often rely on generic data, which can lead to format mismatches with autonomous driving-specific datasets \citep{cui2024survey}. Testing platforms must therefore provide robust tools for format conversion, control interfaces, and auxiliary functionalities to fully realize the potential of knowledge-driven ADS.

The distinct advantages and unique challenges of modular, end-to-end, and knowledge-driven ADS methodologies highlight the critical need for robust simulation and testing platforms, which remain pivotal for advancing ADS toward widespread adoption.

\subsection{Validation and Enhancement of ADS}

To accurately assess performance at various stages of ADS development, testing methods are adjusted accordingly. In this section, we survey and compare widely used testing methods and summarize the requirements for building a closed-loop autonomous driving testing platform.

\subsubsection{Dataset and Benchmark}


Creating datasets and benchmarks is a fundamental approach for training and evaluating autonomous driving models. These datasets are typically constructed by collecting data from vehicle-mounted or roadside sensors, which are then labeled according to the specific requirements of the task. Well-known autonomous driving datasets include KITTI \citep{geiger2013vision}, BDDV \citep{xu2017end}, HDD \citep{ramanishka2018toward}, nuScenes \citep{caesar2020nuscenes}, and Waymo Open Dataset \citep{sun2020scalability}. These datasets are gathered using a variety of sensors, such as cameras, LiDAR, radar, and GPS, which capture data on traffic participants and their behaviors. The labeled data serves as the foundation for training models, enabling the advancement of cutting-edge algorithms in the field of autonomous driving \citep{li2024ego,wang2024driving,zheng2025genad}. Due to the significant cost and labor involved in the collection of real-world data, many research teams rely on these widely used, open-source datasets, which help establish baseline standards for model performance \citep{feng2020deep,liu2024survey}. Additionally, these datasets often come with predefined evaluation metrics and benchmarks, which are critical for comparing the performance of different models across a variety of tasks \citep{guo2019safe}.

Open-loop datasets, which are directly sourced from real-world driving environments, provide authentic training samples and create a shared platform for models to compete on. This has been a significant advancement in autonomous driving research, enabling researchers to test their models against the same set of real-world data. However, while these datasets offer valuable insights, they have limitations. Specifically, open-loop datasets do not provide feedback on model outputs; they simply measure the discrepancy between model predictions and the ground-truth labels \citep{codevilla2019exploring,caesar2021nuplan}. This creates a gap in fully assessing the model’s actual performance in real-world conditions. The issue is twofold: first, a small gap between model output and labels indicates that the model is feasible but does not necessarily imply optimal performance. Second, task-specific evaluation metrics do not always correlate with the broader success of an ADS \citep{zhang2022rethinking,ljungbergh2025neuroncap,yang2024drivearena}. A model may perform well on a specific task but still fail to operate effectively in the context of a fully integrated ADS.

Moreover, the high cost of real-world data collection limits the scalability of datasets, preventing researchers from capturing rare or complex driving scenarios \citep{chitta2022transfuser,shao2023safety}. This limitation slows the development of more robust ADS technologies. In conclusion, while open-loop datasets and benchmarks are critical for advancing research, their static nature and the challenges of real-world data collection highlight the need for new approaches, such as simulation-based data generation, to overcome these barriers and improve the generalization of autonomous systems \citep{hu2023simulation,tian2024robust}.

\subsubsection{Simulation}

Autonomous driving simulators can be roughly categorized into flow-based, vehicle-based, and data-based \citep{wenl2023limsim}.

Flow-based simulation systems have been developed over the years to assist urban planners and traffic managers. Notable examples include PARAMICS \citep{cameron1996paramics}, a commercial software released in 1998, which integrates traffic simulation, visualization, road network design, and adaptive signal control. Vissim \citep{fellendorf2010microscopic}, another commercial tool, offers high-level visualizations of traffic scenarios using realistic models. CORSIM \citep{halati1997corsim}, supported by the Federal Highway Administration, specializes in road geometry, traffic control, and large-scale simulations. Aimsun \citep{barcelo2005dynamic} is a widely used software for traffic planning and demand analysis, while SUMO is an open-source tool for modeling urban traffic and intermodal transportation systems, offering features like route planning and emission calculations. Despite their strength in simulating large-scale traffic networks, flow-based simulators use simple car-following models, limiting their ability to accurately capture detailed vehicle behavior and microscopic movements \citep{kotusevski2009review}.

Vehicle-based simulators provide more dynamic and realistic simulations by focusing on vehicle-specific behaviors \citep{gog2021pylot,xu2023opencda,bockman2024aark}. Early autonomous driving simulators, such as USARSim \citep{carpin2007usarsim} and Webots \citep{michel2004cyberbotics}, utilized modified game engines to simulate physical interactions. Today, simulators like Gazebo \citep{koenig2004design}, AirSim, LGSVL \citep{rong2020lgsvl}, and CARLA offer advanced features. Gazebo is a flexible 3D simulator often used with ROS \citep{quigley2009ros} for dynamic rendering and object interaction. AirSim, based on Unreal Engine \citep{sanders2016introduction}, provides high-fidelity vehicle simulations and a variety of urban scenarios. LGSVL, built on Unity \citep{haas2014history}, supports detailed sensor simulations like LiDAR and radar. CARLA, also open-source, offers customizable environments and sensor suites for autonomous driving research. Vehicle-based simulators allow for precise vehicle motion modeling and decision-making algorithm testing. However, they fall short in simulating realistic background traffic flow, as they lack the capacity for dynamic vehicle interaction on a larger scale \citep{wenl2023limsim}.

Data-based simulators leverage traffic flow data to simulate realistic driving scenarios \citep{hallyburton2023avstack}. These systems generate vehicle behavior based on historical data, making it challenging to model interactions between the ego vehicle and other road users. SimNet, the first machine learning-based simulator, generates realistic driving episodes from historical data and improves as more data is used. InterSim \citep{sun2022intersim} and TrafficGen \citep{feng2023trafficgen}, both data-driven systems, simulate vehicle interactions and generate diverse traffic scenarios. Data-based simulators are effective at learning multi-vehicle interactions from real-world data, but they are highly dependent on the available dataset, which limits their ability to create new, diverse scenarios and can lead to fragmented simulations \citep{mutsch2023model}.

In general, a simulation platform that can efficiently generate detailed scenarios while balancing real-time performance and simulation fidelity, and readily support the creation of long-term dynamic traffic data and convenient in-depth evaluation, is crucial for advancing autonomous driving development.

\section{Comprehensive Simulation Framework}
This paper provides a comprehensive framework for autonomous driving simulation, which includes multiple necessary modules as shown in Figure~\ref{fig:framework}, to support the deployment of different technology pipelines. We then share some considerations and insights from designing this framework.

\begin{figure*}
    \centering
    \includegraphics[width=0.85\linewidth]{framework.pdf}
    \caption{
    \textrm{(1) \textbf{Driving Engine} emphasizes independence and compatibility, allowing for full deployment and testing of algorithms while interfacing with open-source engines like SUMO and CARLA for cross-platform development. (2) \textbf{Map construction} involves importing OpenDrive-formatted files or obtaining data through cross-platform communication, utilizing Cartesian and Frenet coordinate systems for accurate vehicle positioning and trajectory planning. (3)\textbf{ Scene understanding }is enhanced through 3D scene information from CARLA, enabling the use of sensor data for traffic participant identification and motion state estimation, which can be applied to perception algorithms or integrated into end-to-end architectures. (4)\textbf{Decision and planning} include traditional models and advanced joint decision planning models that leverage MCTS for behavior decisions and parallel trajectory planning for trajectory generation. (5) \textbf{Performance evaluation} is facilitated through a series of indicators focusing on vehicle operation status, with the ability to calibrate model parameters to align with real-world data for enhanced simulation realism.}
}
    \label{fig:framework}
\end{figure*}

\subsection{Simulation Modules}
\subsubsection{Driving Engine}
In the LimSim Series, we have paid great attention to the issues of independence and compatibility with existing simulation engines. An independent simulation engine is crucial because it allows users to fully deploy and test algorithms based on this platform, effectively obtaining all dynamic and static information of the simulation process. This complete access is essential for evaluating ADS in a controlled setting. Moreover, the LimSim Series is designed to seamlessly integrate with widely used open-source simulation engines such as SUMO and CARLA, enhancing its versatility. By offering cross-platform communication capabilities, the LimSim Series allows for joint development, enabling users to leverage the strengths of each platform. For instance, SUMO is known for its high-speed traffic flow simulation, which is ideal for large-scale traffic management studies, while CARLA excels in realistic 3D rendering, making it perfect for visualizing complex urban environments. Through the integration of these platforms, the LimSim Series can support a wide variety of autonomous driving technology pipelines, enabling users to test and validate their algorithms under diverse simulation scenarios.


\subsubsection{Map Construction}

Traffic network map construction in the LimSim Series is designed to be flexible and user-friendly, with support for importing map files in formats such as the  ASAM OpenDRIVE format. Additionally, users can obtain map information through cross-platform communication, which ensures the adaptability of the platform to various data sources. The geometric information and topological relationships of the network are fundamental in the simulation process, helping to establish effective relationships between vehicles and roads, thereby indirectly constructing relationships between vehicles and their surrounding traffic participants. Moreover, to accurately locate vehicle positions, the LimSim Series incorporates a dual-coordinate system, consisting of the Cartesian and Frenet coordinate systems. The Cartesian coordinate system provides the absolute positioning of vehicles, which is essential for analyzing vehicle conflicts and assessing driving performance. For example, by using Cartesian coordinates, users can track how a vehicle responds when changing lanes or approaching an intersection. On the other hand, the Frenet coordinate system is particularly useful for local trajectory planning. It simplifies the generation of trajectories close to the road centerline, without the need for detailed road geometry. This dual approach ensures precise localization and effective path planning, even in complex environments.


\subsubsection{Scene Understanding}
Traffic scenes can be defined as the road areas surrounding the target vehicle or target road points, including all traffic participants within a specified range. By exchanging information with 3D scene simulators such as CARLA, the LimSim Series provides detailed 3D road scene data, which includes raw sensor data from multiple perspectives—such as images and point clouds from cameras and LiDAR sensors. These data can be used with traditional perception algorithms to identify and tag traffic participants in the scene, as well as estimate their motion states (e.g., speed and direction). Furthermore, this sensor data can also be fed into end-to-end deep learning architectures for implicit encoding of the scene, or into multimodal large models for general context understanding, enabling more sophisticated scene interpretation.


\subsubsection{Decision and Planning}
The LimSim Series offers a range of trajectory planning methods, catering to both simple and advanced use cases. The baseline methods, including traditional following and lane-changing models, serve as a starting point for users new to autonomous driving simulation. For instance, the combination of the Intelligent Driver Model \citep{treiber2000congested} and the MOBIL model \citep{kesting2007general} provides a simple yet effective approach for simulating vehicle movement in traffic. These models help users understand the fundamental mechanics of vehicle behavior, such as maintaining safe following distances and executing smooth lane changes. Although the control mode is straightforward, these models also serve as a baseline for evaluating traffic flow simulation performance. For more complex scenarios, LimSim includes a joint decision planning model that employs a two-layer logic structure. The upper layer utilizes Monte Carlo Tree Search (MCTS) \citep{browne2012survey} for decision-making, which helps to model the vehicle's high-level behavior, such as determining whether to overtake another vehicle or stop at an intersection. The lower layer performs trajectory planning, generating specific trajectory points using parallel processing to ensure real-time responsiveness. Additionally, advanced techniques such as LLMs can be integrated to output decision meta-actions based on scene analysis. For example, an LLM could interpret the surrounding traffic conditions and decide whether the vehicle should accelerate, decelerate, or change lanes.


\subsubsection{Performance Evaluation}
To evaluate the performance of algorithms, the LimSim Series introduces a comprehensive set of performance indicators. For individual vehicles, closed-loop simulation indicators mainly focus on the vehicle's operating status, including efficiency, comfort, and safety indicators. For example, efficiency could be measured by the completion time of the driving task, comfort could be assessed through the smoothness of the vehicle’s ride, and safety could be evaluated by the frequency of collisions or near-misses. The quantification of these indicators can help users identify algorithmic failures in certain scenarios, thereby identifying corner cases and supporting algorithm iteration and optimization. For instance, a scenario where a vehicle repeatedly fails to make safe lane changes might highlight the need for improving the vehicle’s decision-making or perception models. In addition, to further enhance the realism of the simulation, users can calibrate model parameters to match the statistical characteristics of real-world datasets, such as average speed, headway (the time gap between two vehicles), and saturation flow (the maximum number of vehicles that can pass through an intersection in a given time). This ensures that the simulation results are representative of real-world traffic conditions, enhancing the validity of the testing environment.

\subsection{Design Considerations and Insights}

\subsubsection{Trade-off Between Efficiency and Scale}

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{scenario.pdf}
    \caption{\textrm{Differentiated decision-making planning strategies for other vehicles inside and outside the AoI.}}
    \label{fig:AoI}
\end{figure*}

As the number of vehicles operating on the platform increases, the computational load required to simulate their interactions also grows exponentially. With limited computing resources, a common challenge faced by simulation platforms is the trade-off between efficiency and scale. In simpler terms, the more vehicles and detailed interactions you want to simulate, the more computational power is needed. In existing simulators, this trade-off is often addressed by reducing simulation granularity—this can include lowering the rendering frame rate or decreasing the frequency of trajectory updates. However, such simplifications may sacrifice realism and accuracy, especially in critical scenarios where vehicle behavior is key.

To balance these conflicting demands, we introduce the concept of the Area of Interest (AoI) in the LimSim Series, as illustrated in Figure~\ref{fig:AoI}. The AoI focuses computational resources on a localized region around the vehicle of interest, ensuring that the simulation remains highly detailed where necessary, and more computationally efficient in less critical areas. Inside the AoI, vehicle behavior is simulated with high granularity, using complex control strategies that mimic real-world decision-making. For example, when a vehicle is about to merge into another lane, it will apply a nuanced control strategy to assess and react to nearby traffic. Outside the AoI, simulation granularity is reduced, and vehicles default to simple, high-efficiency behaviors such as lane-following or basic speed control. This approach allows for a scalable solution where the simulator can handle a large number of vehicles without overwhelming the system. In the future, we also plan to explore distributed simulation strategies, where the control of vehicles could be decentralized and managed by a network of distributed centers. This would allow for greater flexibility and scalability, while maintaining a unified scene rendering interface to ensure consistent visual representation across all simulation modules.

\subsubsection{Integration of Real Data with Simulation Platform}


One of the critical challenges in simulation-based research is integrating real-world data to improve the realism of the simulated environment. Importing real traffic data, such as road network layouts and historical traffic flow, enhances the accuracy of the simulated traffic conditions. However, this integration can lead to the loss of dynamic interaction between vehicles, which is essential for simulating realistic behavior.

To address this issue, we have developed interactive simulation strategies as a core feature of the LimSim Series. These strategies help determine when vehicles should be controlled by the simulator and when they should follow real-world data. This dynamic approach enhances both realism and interactivity, allowing the simulation to adapt to the complexities of traffic dynamics. For example, as shown in Figure~\ref{fig:control}, when a vehicle enters the AoI and may potentially conflict with others (such as causing a rear-end collision), the simulator will override the vehicle's trajectory with a default control strategy to prevent accidents or unnatural behavior. Once the conflict is resolved or the vehicle exits the AoI, the simulator will restore the vehicle's trajectory to align with real-world data. This ensures that while the vehicle's actions are dynamically adjusted to avoid collisions, they remain grounded in the real-world traffic patterns outside the AoI. In our previous work, we also explored the integration of 3D scene reconstruction with the LimSim Series \citep{yan2024oasim}. This combination allows us to replicate real-world traffic environments in greater detail and provides the flexibility to edit vehicle trajectories arbitrarily. Such an integration opens up new possibilities for simulating complex urban driving scenarios.

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{control.pdf}
    \caption{\textrm{Interactive simulation strategy combines virtual simulation and real traffic data.}}
    \label{fig:control}
\end{figure*}



\section{Experiments}
\label{section:experiments}



\subsection{Experiment setting}


The LimSim Series provides a variety of baseline modules and algorithms, along with user-friendly APIs, enabling seamless integration with mainstream autonomous driving systems. It offers convenient simulation and validation functionalities for different autonomous driving systems, helping to explore their performance boundaries. Additionally, the LimSim Series fully supports high-definition map parsing, allowing for simulation experiments across various road types and scenarios.

In this section, we conducted simulation experiments on different types of autonomous driving systems in diverse scenarios. The systems evaluated include: (1) \textit{PDM} \citep{Dauner2023CORL}, representing modular autonomous driving systems; (2) \textit{Interfuser} \citep{shao2022interfuser}, representing end-to-end autonomous driving systems; (3) \textit{VLM-Agent} \citep{wen2023dilu, fu2024limsim++}, representing knowledge-driven autonomous driving systems; and (4) \textit{LimSim-TM} \citep{wenl2023limsim}, the baseline traffic controller provided by the LimSim Series. PDM includes several modules such as agent forecast, trajectory proposal, and trajectory refinement to provide appropriate trajectories for vehicles. It uses a rule-based predictive planner to obtain a trajectory proposal, and a learned ego-forecasting module to refine the trajectory. InterFuser is a security-enhanced autonomous driving strategy based on multi-sensors and integrated with the transformer-based method, using interpretable features to increase the safety of autonomous driving. VLM-Agent utilizes the GPT-4o for autonomous driving decision-making with the zero-shot approach. The model performs scenario analysis, behavior prediction, and action decision based on surround-view images provided by the LimSim Series. The decision results of the model will be parsed by the LimSim Series and ultimately applied to the ego car. LimSim-TM uses several different modules to achieve the functions of prediction, decision-making, and planning through search. The decision-making module introduces social value orientation (SVO) grouped decision-making, making vehicle behavior closer to real-world situations.

We selected several representative scenarios for these experiments: a multi-lane highway, a ramp, an intersection, a roundabout, and a custom-designed long route that integrates multiple complex situations. The bird's-eye views of these scenarios, as depicted in Figure \ref{fig:test_scenario}, were captured using CARLA.

\begin{figure*}
    \centering
    \includegraphics[width=1.0\linewidth]{test_scenario.pdf}
    \caption{\textrm{Several representative scenarios for performance evaluation of various autonomous driving models.}}
    \label{fig:test_scenario}
\end{figure*}


\subsection{Performance Evaluation of Various Autonomous Driving Models}



To comprehensively evaluate the performance of autonomous driving systems in the aforementioned scenarios, we assess the simulation results from four metrics: route completion (\%), driving score, average decision time (s), and success rate. The driving score is a holistic measure that takes into account ride comfort, driving efficiency, and safety. For detailed definitions and parameter values, please refer to our previous work \citep{fu2024limsim++}. In each scenario, we generate 10 random background traffic flows to validate the models' performance under various traffic conditions. The success rate is calculated as the number of successful tests out of these 10 experiments. The mean and standard deviation of the experimental results are presented in Table \ref{tab:comparison}.

As the driving scores reflect the comprehensive performance evaluation, LimSim-TM demonstrated the most consistent and superior performance overall. PDM and VLM-Agent showed competitive performance across different scenarios, whereas Interfuser consistently underperformed, especially in roundabout scenarios. The model often drives the vehicle into the middle of the roundabout, causing unsatisfying performance in the roundabout scenario. In contrast, both modular methods and knowledge-driven approaches demonstrated correct decision-making capabilities. This does not imply that end-to-end autonomous driving systems are inherently inferior but rather highlights the sensitivity of data-driven methods to the training data distribution. Since Interfuser was not trained in the selected environment, it could not fully demonstrate its potential. 
In contrast, PDM and LimSim-TM, which rely on rule-based decision-making, can produce relatively strong decisions even in unfamiliar scenarios by employing search-based methods. 

Notably, the zero-shot VLM-Agent has strong generalization abilities even without prior exposure to these scenarios, leveraging its strong commonsense reasoning abilities. However, VLM-Agent suffers from limitations in reasoning speed due to the inference latency of VLM. Its average decision time across various scenarios was approximately 10 seconds, which makes it challenging to meet real-time requirements. Future research could focus on improving the model's inference speed or reducing the number of tokens in the output to bridge the gap between data-driven methods and practical applications.

The experiments demonstrate that the LimSim Series provides a rich simulation environment for different types of autonomous driving systems, enabling diverse interactions and multi-dimensional evaluation of simulation outcomes. The experimental results indicate that the LimSim Series offers evaluations well-suited to the characteristics of various models. Its real-time recoding system also facilitates the identification of corner cases, aiding in model iteration and improvement.


\begin{table}[htbp]
\centering
\rmfamily 
\caption{\textrm{Performance comparison of different models across various scenarios.}}
\begin{tabular}{p{2cm}p{2cm}p{1.8cm}p{1.8cm}p{1.8cm}p{1.8cm}p{1.8cm}}
\toprule
\multirow{2}{*}{Metric} & \multirow{2}{*}{ADS} & \multicolumn{5}{c}{Scenario} \\ \cmidrule{3-7}
& & Highway & Ramp & Intersection  & Roundabout & Long Route \\ 
\midrule
\multirow{4}{*}{\textbf{\makecell{Route \\ Completion \\(\%) $\uparrow$}}} 
& PDM        & 100.00$\pm$0.00 & 94.13$\pm$17.61 & 100.00$\pm$0.00 & 100.00$\pm$0.00 & 84.62$\pm$24.58 \\
& InterFuser & 100.00$\pm$0.00 & 93.18$\pm$20.44 & 100.00$\pm$0.00 & 13.17$\pm$4.90 & 88.14$\pm$25.86 \\
& VLM-Agent & 97.22$\pm$8.33 & 97.82$\pm$6.55 & 100.00$\pm$0.00  & 100.00$\pm$0.00 & 87.90$\pm$19.81 \\
& LimSim-TM & 97.78$\pm$6.67 & 96.98$\pm$9.06 & 100.00$\pm$0.00 & 100.00$\pm$0.00 & 86.15$\pm$28.45 \\
\midrule
\multirow{4}{*}{\textbf{\makecell{Driving \\ Score $\uparrow$}}} 
& PDM        & 40.73$\pm$1.98 & 68.25$\pm$14.01 & 76.30$\pm$2.68 & 27.40$\pm$0.41 & 65.22$\pm$15.04 \\
& InterFuser & 50.99$\pm$4.30 & 54.20$\pm$4.45 & 65.23$\pm$3.85  & 28.00$\pm$16.82 & 37.63$\pm$7.95 \\
& VLM-Agent & 52.98$\pm$9.84 & 47.31$\pm$6.59 & 75.67$\pm$2.14  & 65.40$\pm$9.36 & 30.54$\pm$7.89 \\
& LimSim-TM & 76.28$\pm$18.91 & 64.62$\pm$16.30 & 86.28$\pm$0.51 & 72.08$\pm$14.08 & 78.76$\pm$15.43 \\
\midrule
\multirow{4}{*}{\textbf{\makecell{Avg. \\ Decision \\ Time (s) $\downarrow$}}} 
& PDM        & 0.02$\pm$0.00 & 0.01$\pm$0.00 & 0.01$\pm$0.00 & 0.02$\pm$0.00 & 0.02$\pm$0.00 \\
& InterFuser & 0.11$\pm$0.01 & 0.12$\pm$0.02 & 0.11$\pm$0.00  & 0.12$\pm$0.00 & 0.11$\pm$0.01 \\
& VLM-Agent & 9.68$\pm$1.38  & 10.53$\pm$3.25 & 11.24$\pm$3.36 &  11.70$\pm$3.36 & 11.42$\pm$2.16 \\
& LimSim-TM & 0.09$\pm$0.03  & 0.13$\pm$0.04 & 0.03$\pm$0.00 & 0.05$\pm$0.01 & 0.08$\pm$0.01 \\
\midrule
\multirow{4}{*}{\textbf{\makecell{Success \\Rate $\uparrow$}}} 
& PDM        & 1.00$\pm$0.00 & 0.90$\pm$0.30 & 1.00$\pm$0.00  & 1.00$\pm$0.00 & 0.70$\pm$0.46 \\
& InterFuser & 1.00$\pm$0.00 & 0.90$\pm$0.30 & 1.00$\pm$0.00  & 0.00$\pm$0.00 & 0.80$\pm$0.40 \\
& VLM-Agent & 0.90$\pm$0.30 & 0.90$\pm$0.30 & 1.00$\pm$0.00 & 1.00$\pm$0.00 & 0.70$\pm$0.46 \\
& LimSim-TM & 0.90$\pm$0.30 & 0.90$\pm$0.30 & 1.00$\pm$0.00 & 1.00$\pm$0.00 & 0.80$\pm$0.40 \\
\bottomrule
\end{tabular}
\label{tab:comparison}
\end{table}

\section{Conclusion and Future Work}
\label{section:discussion}

This paper explores the development and validation of ADS, categorizing them into modular, end-to-end, and knowledge-driven approaches. It then introduces the LimSim Series, a comprehensive simulation framework supporting various ADS types through modules like driving engine, map construction, scene understanding, decision and planning, and performance evaluation. Experiments across diverse scenarios demonstrate the ability of the proposed platform to evaluate ADS performance effectively. 

In the future, simulation systems for ADS will need to achieve breakthroughs in the following key areas to meet practical demands.
\begin{itemize} 
\item Support for high-fidelity sensor simulation: Future simulation frameworks could incorporate 3D Gaussian sputtering and diffusion techniques to achieve accurate 3D scene reconstruction, providing more realistic and diverse sensor signal inputs for model testing. Emphasis should be placed on ensuring high rendering efficiency to optimize simulation performance.

\item Simulation of heterogeneous traffic flows: The scenarios involving mixed human-vehicle traffic are common in the road networks, where the interactions between pedestrians and vehicles are simulated. Additionally, the system should accommodate special-purpose vehicles, such as buses, taxis, and ambulances, capturing their unique travel trajectories and behaviors.

\item Comprehensive testing scenario library: A robust simulation platform should offer a diverse and comprehensive set of test scenarios. In addition to scenarios based on log case editing, future research should focus on AI-driven generation methods guided by specific instructions. This approach would be particularly valuable for generating rare and hard-to-collect corner cases, facilitating more thorough testing in complex and edge conditions.
\end{itemize}
 

% \section{Acknowledgments}
% The research was supported by Shanghai Artificial Intelligence Laboratory, the National Key R\&D Program of China (Grant No. 2022ZD0160104), the Science and Technology Commission of Shanghai Municipality (Grant No. 22DZ1100102). 

%\balance
\bibliographystyle{cas-model2-names}
\bibliography{references}  

\end{document}

