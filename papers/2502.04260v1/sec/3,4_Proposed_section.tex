\section{Preliminaries}
\label{sec:prelims}

%\subsection{Gradient Ascent}

%Gradient ascent (GA) is an optimization technique aimed at maximizing a given loss function for a specified set of examples. This approach is particularly useful for unlearning, as it allows for the approximate removal of specific samples by adjusting the model weights in the direction that maximizes the loss on the target samples \cite{tarun2023fast}. Let $\theta$ represent the model weight, $\eta$ be the learning rate and $L$ be the loss function, then GA iteratively updates the model weights in the following manner.
%\begin{equation}
%    \theta_{t+1} = \theta_t + \eta\frac{\delta L}{\delta \theta_t}
%\end{equation}

\subsection{Out-Of-Distribution data}

Out-of-distribution (OOD) data refers to the inputs that fall outside the range or characteristics of the data used to train a machine learning model. Such inputs can differ significantly from the training dataset, often causing the model to produce inaccurate or unreliable predictions. Detecting OOD data can be framed as a binary classification task, as discussed by Sun et al. (2022). In this context, a sample is classified as OOD if it lies at least a distance of $\lambda$ away from the in-distribution data, where $\lambda$ represents a predefined threshold for OOD detection.

\subsection{Machine Unlearning in I2I models}

The typical I2I models i.e., AutoEncoders (AEs), Variational AutoEncoders (VAEs), and Diffusion models, employ an encoder-decoder architecture. The encoder part $E_\gamma$ of the model transforms the input image to a latent vector. The decoder $D_\phi$ takes the latent vector as input and decodes it into an output image i.e., for an input image $x$, the output of an I2I model can be written as follows.
\begin{equation}
    \theta_{\gamma, \phi} = D_\phi \circ E_\gamma 
\end{equation}
\text{Therefore, for any input image } $x, \; \theta_{\gamma, \phi} (\tau(x)) = D_\phi (E(\tau(x)))$, where $\tau(x)$ is some operation which results in cropped or masked image $x$; $\circ$ is the composition operator; $\gamma$ and $\phi$ are the trainable model parameters of encoder and decoder respectively.

For a given dataset $\mathcal{D}$, the goal of machine unlearning in image-to-image (I2I) generative models is to effectively remove the influence of a specific subset, known as the forget set $\mathbb{D}_f$, from the model parameters with an unlearning algorithm $A_f$, such that the updated parameters $\gamma, \phi = A_f(\gamma^0, \phi^0)$ no longer retain any information about $\mathbb{D}_f$. Crucially, the model must preserve its performance on the retain set $\mathbb{D}_r$, ($\mathbb{D}_r = \mathcal{D} \setminus \mathbb{D}_f$). In the literature of machine unlearning \cite{li2024machine, feng2024controllable}, the following complementary objectives have been considered.
\begin{enumerate}
    \item On the retain set $\mathbb{D}_r$, the generated images from $\theta_{\gamma, \phi}$ should have the same distribution as in $\theta_{\gamma^0, \phi^0}$ (after unlearning).
    \item On the forget set $\mathbb{D}_f$, the distribution of the generated images from $\theta_{\gamma, \phi}$ should be \textit{as far as possible} from the distribution of images from $\theta_{\gamma^0, \phi^0}$ (after unlearning).
\end{enumerate}

From a probabilistic distribution perspective, the unlearning methodology in \cite{li2024machine} considers the following combined objectives:
\begin{equation}
    \begin{split}
        \argmin_{\gamma, \phi} D \left( P_{\theta_{\gamma_0, \phi_0} (\tau(\mathbb{D}_r))} || P_{\theta_{\gamma, \phi} (\tau(\mathbb{D}_r))} \right ) \text{, and } & \\
        \argmax_{\gamma, \phi} D \left ( P_{\theta_{\gamma_0, \phi_0} (\tau(\mathbb{D}_f))} || P_{\theta_{\gamma, \phi} (\tau(\mathbb{D}_f))} \right )
    \end{split}
\end{equation}

An approach to solve the second objective function is to push the model weights to generate Gaussian noise and, thus to forget the set $\mathbb{D}_f$. That is to solve $\argmin_{\gamma, \phi} D \left ( N(0, \Sigma) || P_{\theta_{\gamma, \phi} (\tau(\mathbb{D}_f))} \right )$. The unlearning methodology in \cite{feng2024controllable} introduces a $\varepsilon$-constrained optimization for this objective, where $\varepsilon$ controls the degree of unlearning. 

\section{Proposed Approach} \label{sec:proposed approach}

\begin{figure}[t]
  \centering
  %\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=\linewidth]{fig/I2I_ours_flowchart.png}
   \caption{Overview of our proposed approach. We maximize the loss on the forget samples ($D_f$) to get unlearned model. We get the updated I2I model by further fine-tuning the unlearned model on the retain samples to maintain the performance.}
   \label{fig:our framework}
\end{figure}

In this work, we aim to realistically address the problem of machine unlearning in Image-to-Image (I2I) generative models which reconstruct the image from its partial or noisy counterpart. Recall that the objective of unlearning is to modify the model parameters in such a way that the model's weights, after unlearning specific data, closely match the weights the model would have if it were retrained from scratch without that data. Because of that, we consider that minimizing the distance between gaussian noise and the output of decoder is \textit{not} equivalent to the model which we will get from a retrained model. As an alternative, in our approach we consider that the forget set should be an out-of-distribution (OOD) after unlearning. Mathematically, we define the unlearning objective using the following expression:
\begin{equation} \label{unlearn_obj}
    \arg_{\gamma, \phi} \| \theta_{\gamma_0, \phi_0} (\tau(\mathbb{D}_f)) - \theta_{\gamma, \phi} (\tau(\mathbb{D}_f)) \| \geq \lambda 
\end{equation}
where $\| .\|$ is a distance measure, and $\lambda$ is a threshold which is used to determine out-of-distribution data. In summary, we consider the following combined objective.
\begin{enumerate}
    \item On the retain set $\mathbb{D}_r$, the generated images from $\theta_{\gamma, \phi}$ should have the same distribution as the images generated from $\theta_{\gamma^0, \phi^0}$ after unlearning.
    \item On the forget set $\mathbb{D}_f$, the distribution of the generated images from $\theta_{\gamma, \phi}$ should be atleast some $\lambda$ distance apart from the distribution of images from $\theta_{\gamma^0, \phi^0}$ after unlearning.
\end{enumerate}

Let $\mathcal{L}$ be the loss function for I2I model $f(x, \gamma, \phi): \mathbb{R}^d \rightarrow \mathbb{R}^d$ $\forall x \in $ $\mathcal{D} \; (\mathcal{D} = \mathbb{D}_r \cup \mathbb{D}_f)$, where $\gamma, \phi$ are the model parameters. The typical objective of a machine learning model is to minimize $\mathcal{L}$ i.e., $\argmin_{\gamma, \phi} \mathcal{L}(\gamma, \phi, \mathcal{D})$. The typical update rule for machine learning model can be written as:
\begin{equation}
    \theta_{\gamma^{t+1}, \phi^{t+1}} = \theta_{\gamma^t, \phi^t} - \eta\nabla f(\gamma^t, \phi^t)
\end{equation}
where $\eta$ is the learning rate. Let $\gamma^*, \phi^*$ be the optimal parameters which have perfect generation i.e.,
\begin{equation}
    \theta_{\gamma^*, \phi^*}(\tau(x)) = x
\end{equation}
Under the assumption that SGD converges for the loss function $\mathcal{L}$, we can say that the expected value of $\theta_{\gamma^*, \phi^*} (\tau(x)) - \theta_{\gamma, \phi}(\tau(x))$ decreases over time across training epochs, although it may not be strictly monotonically decreasing in every epoch. 

\subsection{Decoupling via Gradient Ascent}

Gradient ascent is an approach whose objective is to maximize the model loss on a given set. It is a reverse of gradient descent where the model update is written as:
\begin{equation}
    \theta_{\gamma^{t+1}, \phi^{t+1}} = \theta_{\gamma^t, \phi^t} + \eta \nabla f(\gamma^t, \phi^t)
\end{equation}
In our work, we use gradient ascent to forget the influence of $\mathbb{D}_f$ on the model $\theta_{\gamma_0, \phi_0}$. In gradient ascent, we expect that the loss function $\mathcal{L}(\theta_{\gamma, \phi}) $ is an increasing function in $t$ (the loss increases with training) in contrast to the decreasing function in gradient descent. In the next steps, we prove that the output on $\mathbb{D}_f$ with updated model parameters $\theta_{\gamma, \phi}$ after $T$ iterations of gradient ascent is out-of-distribution from the output with $\theta_{\gamma^0, \phi^0}$. We have the following assumption in our work.

%(x, \gamma, \phi)
\textbf{Assumption 1.} $f: \mathbb{R}^d \rightarrow \mathbb{R}^d$ is convex and differentiable. 
\begin{equation} \label{ass1}
    \forall a,b \in \mathbb{R}^d, f(a) \geq f(b) + \langle \nabla f(a), a-b \rangle
\end{equation}

\textbf{Assumption 2.} During all the training epochs, the expected norm of gradient is lower and upper bounded i.e., $g\leq\mathbb{E}\|\nabla f\| \leq G$, where $g, G>0$.

%\textbf{Assumption 3.} Observe that the stochastic gradient is the sum of $S$ independent, uniformly sampled contributions. With central limit theorem, we assume that the gradient noise is Gaussian with covariance $\frac{1}{S}\Sigma(\theta)$.

The convexity assumption is typically invoked in machine unlearning literature to ensure that the model is well-trained and to quantify the influence of data removal on model parameters \cite{guo2019certified}. Although I2I models are usually formulated as non-convex optimization problems, several studies have adopted the convexity assumption to derive theoretical guarantees \cite{sahiner2021hidden, de2022convergence, zhang2024analyzing}. The lower bound in Assumption 2 is needed to make sure the model before unlearning is not at the optimum (i.e., $\theta_{\gamma^0\phi^0} \neq \theta_{\gamma^*\phi^*}$), while the upper bound is considered to prove $(\epsilon, \delta)$-unlearning. We know that for gradient ascent we have,

\begin{equation} \label{GA}
    \theta_{\gamma^{t+1}, \phi^{t+1}} = \theta_{\gamma^t, \phi^t} + \eta \nabla f(\gamma^t, \phi^t)
\end{equation}

Let us consider Assumption 1 for $\gamma^{t+1}, \phi^{t+1}$ and $\gamma^{t}, \phi^{t}$.
\begin{equation}
    \begin{split}
        f(\theta_{\gamma^{t+1}, \phi^{t+1}}) &\geq f(\theta_{\gamma^{t}, \phi^{t}}) \\
        &\;\;\;\; + \langle \nabla f(\theta_{\gamma^{t+1}, \phi^{t+1}}), \theta_{\gamma^{t+1}, \phi^{t+1}} - \theta_{\gamma^{t}, \phi^{t}} \rangle \\
        &\!\!\!\! \geq f(\theta_{\gamma^{t}, \phi^{t}}) + \eta \| \nabla f(\theta_{\gamma^{t+1}, \phi^{t+1}})\| \|\nabla f(\theta_{\gamma^{t}, \phi^{t}}) \| \\
        %&\geq f(\theta_{\gamma^{t-1}, \phi^{t-1}}) + \eta \| \nabla f(\theta_{\gamma^{t}, \phi^{t}})\| \|\nabla f(\theta_{\gamma^{t-1}, \phi^{t-1}}) \| + \eta \| \nabla f(\theta_{\gamma^{t+1}, \phi^{t+1}})\| \|\nabla f(\theta_{\gamma^{t}, \phi^{t}}) \| \\
        &\!\!\!\! \geq f(\theta_{\gamma^{0}, \phi^{0}}) \\
        &\;\;\;\;\; + \eta \sum_{t=0}^{T-1} \|\nabla f(\theta_{\gamma^{t+1}, \phi^{t+1}}) \| \| \nabla f(\theta_{\gamma^{t}, \phi^{t}})\| 
    \end{split}
\end{equation}

Using Assumption 2, we have $\|\nabla f(\theta_{\gamma^{t+1}, \phi^{t+1}}) \|, \| \nabla f(\theta_{\gamma^{t}, \phi^{t}})\| \geq g$. Then we can rewrite Eq. (9) as:
\begin{equation} \label{lower bound}
    \|f(\theta_{\gamma^{T}, \phi^{T}}) - f(\theta_{\gamma^{0}, \phi^{0}}) \| \geq \eta Tg^2 
\end{equation}

Let us consider Assumption 1 again to get an upper bound for $\gamma^{t+1}, \phi^{t+1}$ and $\gamma^{t}, \phi^{t}$ in the opposite order.
\begin{equation}
    \begin{split}
        f(\theta_{\gamma^{t}, \phi^{t}}) &\geq f(\theta_{\gamma^{t+1}, \phi^{t+1}}) \\
        &\;\;\;\; + \langle \nabla f(\theta_{\gamma^{t}, \phi^{t}}), \theta_{\gamma^{t}, \phi^{t}} - \theta_{\gamma^{t+1}, \phi^{t+1}} \rangle \\
        f(\theta_{\gamma^{t+1}, \phi^{t+1}}) &\leq f(\theta_{\gamma^{t}, \phi^{t}}) \\
        &\;\;\;\; + \langle \nabla f(\theta_{\gamma^{t}, \phi^{t}}), \theta_{\gamma^{t+1}, \phi^{t+1}} - \theta_{\gamma^{t}, \phi^{t}} \rangle \\
        %&\leq f(\theta_{\gamma^{t-1}, \phi^{t-1}}) + \langle \nabla f(\theta_{\gamma^{t-1}, \phi^{t-1}}), \theta_{\gamma^{t}, \phi^{t}} - \theta_{\gamma^{t-1}, \phi^{t-1}} \rangle \\ 
        %&+ f(\theta_{\gamma^{t}, \phi^{t}}) + \| \nabla f(\theta_{\gamma^{t}, \phi^{t}}), \theta_{\gamma^{t+1}, \phi^{t+1}} - \theta_{\gamma^{t}, \phi^{t}} \| \\
        &\leq f(\theta_{\gamma^{0}, \phi^{0}}) + \eta \sum_{t=0}^{T} \| \nabla f(\theta_{\gamma^{t}, \phi^{t}}) \|^2
    \end{split}
\end{equation}
Again using Assumption 2, i.e., $\| \nabla f(\theta_{\gamma^{t}, \phi^{t}}) \| \leq G$. Then we get,
\begin{equation} \label{upper bound}
    f(\theta_{\gamma^{T}, \phi^{T}}) \leq  f(\theta_{\gamma^{0}, \phi^{0}}) + \eta (T+1) G^2 
\end{equation}

\mycomment{
\begin{equation} \label{increasing step_GA}
    \| \theta_{\gamma^{t+1}, \phi^{t+1}} - \theta_{\gamma^t, \phi^t} \| ^2 = \eta^2\|\nabla f(\gamma^t, \phi^t)\|^2
\end{equation}
i.e., $\| \theta_{\gamma^{t+1}, \phi^{t+1}} - \theta_{\gamma^0, \phi^0} \| ^2$ is an increasing sequence in $t$. Thus, for $T$ iteration we have,
\begin{equation}
    \| \theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^0, \phi^0} \| ^2 = \eta^2 \sum_{t=1}^T \|\nabla f(\gamma^t, \phi^t)\|^2
\end{equation}
Taking expectation both sides and using Assumption 2, we get,
\begin{equation}\label{bounding model_Weights}
    T\eta^2g^2 \leq \mathbb{E}\| \theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^0, \phi^0} \| ^2 \leq T \eta^2 G^2
\end{equation}


Considering the left hand side of the inequality and by using the Assumption 1, we get:
\begin{gather*}
    f(\theta_{\gamma^{T}, \phi^{T}}) \geq f(\theta_{\gamma^{0}, \phi^{0}}) + \langle \nabla f(\theta_{\gamma^{0}, \phi^{0}}), \theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^{0}, \phi^{0}}\rangle
\end{gather*}
We can rewrite it as:
\begin{gather*}
    f(\theta_{\gamma^{T}, \phi^{T}}) - f(\theta_{\gamma^{0}, \phi^{0}}) \geq \| \nabla f(\theta_{\gamma^{0}, \phi^{0}}) \| \|\theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^{0}, \phi^{0}}\|
\end{gather*}
Taking expectation on both sides, and then using Eq. (\ref{bounding model_Weights}) we get:
\begin{equation} \label{Th1}
    \begin{split}
        \mathbb{E}\|f(\theta_{\gamma^{T}, \phi^{T}}) - f(\theta_{\gamma^{0}, \phi^{0}})\| & \geq \mathbb{E}\| \nabla f(\theta_{\gamma^{0}, \phi^{0}}) \| \mathbb{E}\|\theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^{0}, \phi^{0}}\| \\
        & \geq T\eta^2g^3
    \end{split}
\end{equation}
On the similar lines, with Assumption 1 we have:
\begin{equation}
    f(\theta_{\gamma^{T}, \phi^{T}}) \leq f(\theta_{\gamma^{0}, \phi^{0}}) + \nabla f(\theta_{\gamma^{T}, \phi^{T}}) \langle \theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^{0}, \phi^{0}}\rangle 
\end{equation}
Taking expectation both sides and using right hand side of the inequality from Eq. (\ref{bounding model_Weights}), we get:
\begin{equation} \label{upper bound}
    \begin{split}
        \mathbb{E}\|f(\theta_{\gamma^{T}, \phi^{T}})\| & \leq \mathbb{E} \|f(\theta_{\gamma^{0}, \phi^{0}}) \| + \mathbb{E}\| \nabla f(\theta_{\gamma^{T}, \phi^{T}}) \| \mathbb{E}\|\theta_{\gamma^{T}, \phi^{T}} - \theta_{\gamma^{0}, \phi^{0}}\| \\
        & \leq \mathbb{E} \|f(\theta_{\gamma^{0}, \phi^{0}}) \| + T\eta^2G^3
    \end{split}
\end{equation}
}

Based on this result, we establish the following theorems.

\textbf{Theorem 1.} Under the Assumption 1, 2, the model weights $(\theta_{\gamma, \phi})$ trained with gradient ascent for $T$ iterations are out-of-distribution for the initial trained model $\theta_{\gamma^0, \phi^0}$ on forget set iff
\begin{equation*}
    \lambda \leq \eta Tg^2
\end{equation*}
where $\lambda$ is the predefined out-of-distribution threshold.

\textbf{Theorem 2.} Under Assumption 1, 2, the gradient ascent provides $(\epsilon = 0, \delta = \eta (T+1) G^2)$-unlearning guarantee for model weight $(\theta_{\gamma, \phi})$ after $T$ iterations.

\subsection{Knowledge Retention}

As shown in Fig. \ref{fig:our framework}, the unlearned model is then fine-tuned with retain samples ($\mathbb{D}_r$) with the following objective,
\begin{equation}
    \argmin_{\gamma, \phi} D \left( P_{\theta_{\gamma_0, \phi_0} (\tau(\mathbb{D}_r))} || P_{\theta_{\gamma, \phi} (\tau(\mathbb{D}_r))} \right )
\end{equation}
in order to preserve its performance.

\subsection{Auditing Unlearning} \label{data poisoning attack}

Auditing effective unlearning is crucial to make sure that the model has truly forgotten the forget samples. In this paper, we introduce a novel auditing mechanism based on a data poisoning attack to verify whether unlearning has occurred. Specifically, we fine-tune the model on poisoned versions of the forget samples, embedding a distinct pattern that is recognizable during inference. The aim of this approach is to introduce a recognizable trace into the model's responses that can later serve as an indicator. After the unlearning process, an effective unlearning mechanism should prevent the model from replicating this pattern. If the model, after unlearning, no longer produces outputs associated with the poisoned pattern, it provides strong evidence that the forget samples have been thoroughly erased. This method ensures a more robust validation of the unlearning process by focusing not only on performance metrics but also on detecting residual data influence, thus confirming the removal/unlearning of the impact of the poisoned data.

\begin{table}[h]
    \centering
    \begin{tabular}{ccccc}
      \toprule
      \multirow{2}{*}{Approach} & \multicolumn{2}{c}{FID} & \multicolumn{2}{c}{IS} \\ \cline{2-5}
      & $\mathbb{D}_f\downarrow$ & $\mathbb{D}_r\downarrow$ & $\mathbb{D}_f$ & $\mathbb{D}_r$ \\
      \hline
      GA model & 237.7 & 210.1 & 1.08 & 1.05 \\
      Fine-tuned model & 46.85 & \textbf{3.79} & 1.09 & \textbf{1.13} \\
      SOTA I2I model & 123.6 & 74.2 & 1.09 & 1.12\\
      Merged obj model & 202.1 & 127.7 & 1.08 & 1.08 \\
      Realistic-I2I model & \textbf{16.22} & \textbf{6.10} & 1.10 & \textbf{1.13} \\
      \bottomrule
    \end{tabular}
    \caption{Results of cropping $8 \times 8$ patch at the center of the image where forget samples were poisoned with the '$+$' sign in the CIFAR-10 dataset. $\mathbb{D}_f$ and $\mathbb{D}_r$ account for the forget samples and retain samples respectively. FID scores are compute with respect to retrained model, hence $\downarrow$ is better. Overall, the results highlight that our approach effectively unlearns forget samples and is closer to the retrained model.}
    \label{tab:CIFAR10_res}
\end{table}