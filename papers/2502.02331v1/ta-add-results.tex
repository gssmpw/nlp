\section{Additional Results}
\label{sec:add-res}

This section presents additional results that were not included in the main
text.

\subsection{Perfect Information}

This section contain additional results in the perfect information setting.

\subsubsection{One-Period Slow Deployment, Perfect Information}

Here, we present additional results for \cref{sec:one-slow}.

\paragraph{Comparison with Naive Path in Symmetric Case}

In the symmetric case, we assume that the equilibrium probability is
symmetric, $\pi = 0$. Then,
\[
    \begin{aligned}
        \loss^n_0 &= 1/4 + (1 - 2 \alpha - 2 \beta) p_0^2,
        & \loss^*_0 &= 1/4 - \frac{\beta^2}{1 - 2 \alpha} p_0^2,\\
        \bias^n_0 &= (1 - \alpha - \beta) p_0,
        & \bias^*_0 &= \frac{\alpha \beta}{1 - 2 \alpha} p_0,\\
        \shift^n_1 &= (\alpha - \abs{\alpha} \lambda) p_0,
        & \shift^*_1 &= \frac{(\alpha - \abs{\alpha} + \alpha \abs{\alpha})
        \lambda}{1 - 2 \alpha} p_0.
    \end{aligned}
\]
If $\alpha > 0$, we get
\[
    \frac{\abs{\bias^*_0}}{\abs{\bias^n_0}} = \frac{\alpha \lambda}{(1
    - 2 \alpha) (1 - \lambda)}.
\]
If the performativity, $\alpha$, or the inertia, $\lambda$, is big then the
naive prediction is preferable in terms of bias. Otherwise, the optimal
prediction is preferable. (The same analysis holds for the shift of
estimator.)

If $\alpha \le 0$, we get
\[
    \frac{\abs{\bias^*_0}}{\abs{\bias^n_0}} = \frac{\abs{\alpha} (1 -
    \abs{\alpha}) \lambda}{(1 + 2 \abs{\alpha}) (1 - \lambda + \abs{\alpha} +
    \abs{\alpha} \lambda)} < 1.
\]
Thus, the optimal prediction is preferable in terms of bias. (The same is true
for the shift.)

Finally, if $1 - 2 \alpha > 0$, the loss penalty equals to
\[
    \Par*{1 - 2 \alpha - 2 \beta + \frac{\beta^2}{1 - 2 \alpha}} p_0^2.
\]
To analyze it consider two cases: $\lambda = 0$ and $\lambda = 1$. If $\lambda
= 0$, we get that the following penalty
\[
    \loss^n_0 - \loss^*_0 = (1 - 2 \alpha) p_0^2.
\]
This penalty is bigger than the penalty in the equilibrium case for small
$\alpha$. If $\lambda = 1$, we get that $p_0 = s_1$. So, we get the same answer
as in the equilibrium case.

\subsubsection{Two-Period Slow Deployment, Perfect Information}

Here, extend \cref{sec:one-slow} by solving the two-period case and comparing
with it.

\begin{proposition}[Proof in \cref{sec:proof-two-slow-sol}]
    \label{thm:two-slow-sol}
    Assume that $1 - 2 \alpha > \sqrt{\gamma} \abs{\alpha} \beta$. Then, the
    solution to the problem (\ref{eq:opt-cont-prob}) in $T=2$ slow case
    satisfies
    \[
        \prm^*_0 = \clip\Par*{\frac{(1  -  \abs{\alpha}) ((1  -  2
        \alpha  +  \gamma \alpha \beta^2) s_1 + \gamma \alpha \beta (1 -
        \lambda) \pi)}{(1 - 2 \alpha)^2 - \gamma \alpha^2 \beta^2},
        -\frac{1}{2}, \frac{1}{2}},
    \]
    if $2 (1 - \abs{\alpha}) \abs{s^*_2} \le 1 - 2 \alpha$ (which always holds
    for $\alpha \le 0$).
\end{proposition}

We visualize whole solution on \cref{fig:fin-sols}, bottom row. Notice that on
the left part of the picture we operate in regime $1 - 2 \alpha < \sqrt{\gamma}
\abs{\alpha} \beta$. In this situation, the optimal prediction depends
non-continuously on $p_0$ because of the incentive to push the mean to the
extremes. Additionally notice that the left plot has a kink on its right side.
This kink corresponds to the transition between the cases $2 (1 - \abs{\alpha})
\abs{s^*_2} \le 1 - 2 \alpha$ and $2 (1 - \abs{\alpha}) \abs{s^*_2} > 1 - 2
\alpha$.

If $\abs{\prm^*_0} < 1/2$ in the setting of \cref{thm:two-slow-sol}, we get
\[
    p^*_1 = \frac{(1 - \abs{\alpha}) ((1 - 2 \alpha) (1 - \alpha) s_1 +
    \gamma \alpha^2 \beta (1 - \lambda) \pi)}{(1 - 2 \alpha)^2 - \gamma
    \alpha^2 \beta^2}.
\]
For the rest of the subsubsection we assume $\prm^*_0 < 1/2$.

\paragraph{Bias of $\prm^*_0$}

We get
\[
    \prm^*_0 - p^*_1 = \frac{\alpha (1 - \abs{\alpha}) ((1 - 2 \alpha + \gamma
    \beta^2) s_1 + \gamma (1 - \alpha) \beta (1 - \lambda) \pi)}{(1 - 2
    \alpha)^2 - \gamma \alpha^2 \beta^2}.
\]
For equilibrium and symmetric $\pi$, the bias of prediction becomes more
pronounced because
\[
    \frac{1 - 2 \alpha + \gamma \beta^2}{(1 - 2 \alpha)^2 - \gamma \lambda^2
    \beta^2} \ge \frac{1}{1 - 2 \alpha}.
\]

\paragraph{Shift of $\prm^*_0$}

We get
\[
    p^*_1 - s_1 = \frac{((1 - 2 \alpha) (\alpha - \abs{\alpha} + \alpha
    \abs{\alpha}) + \gamma \alpha^2 \beta^2) s_1 + \gamma \alpha^2 (1 -
    \abs{\alpha}) \beta (1 - \lambda) \pi}{(1 - 2 \alpha)^2 - \gamma \alpha^2
    \beta^2}.
\]

\paragraph{Discussion}

We can see that generally the bias of the optimal prediction is exacerbated in
the two-period model. It happens because the motivation of the model provider
to skew the distribution becomes stronger due to longer horizon.

\paragraph{Comparison with Naive Path}

In equilibrium case $\pi = p_0$, given that the impact and bias of the naive
path is the same as for the one-period model and our results above, we get that
the naive path is even more preferable to the optimal path if $\alpha > 0$ in
terms of bias and shift. For the case of $\alpha < 0$, we get
\[
    \begin{split}
        -\frac{\bias^*_0}{\abs{\alpha} s_1} &= -\frac{(1 \! - \!
        \abs{\alpha}) (1 + 2 \abs{\alpha} + \gamma \beta (1 + \abs{\alpha} - 2
        \abs{\alpha} \lambda))}{(1 + 2 \abs{\alpha})^2 - \gamma \abs{\alpha}^2
        \beta^2},\\
        \frac{\shift^*_1}{\abs{\alpha} s_1} &= \frac{-(1 + 2 \abs{\alpha}) (2
        + \abs{\alpha}) + \gamma \abs{\alpha} (1 - \abs{\alpha}) \beta}{(1 + 2
        \abs{\alpha})^2 - \gamma \abs{\alpha}^2 \beta^2},\\
        \frac{\shift^n_1}{\abs{\alpha} s_1} &= -\frac{\bias^n_0}{\abs{\alpha}
        s_1} = -2.
    \end{split}
\]
By direct calculation, the bias and shift of the naive path is always higher
than those of the optimal path.

In the symmetric case $\pi = 0$, if $\alpha > 0$, we get
\[
    \frac{\abs{\bias^*_0}}{\abs{\bias^n_0}} = \frac{\alpha \lambda (1 + \gamma
    \beta^2 / (1 - 2 \alpha))}{((1 - 2 \alpha) - \gamma \alpha^2 \beta^2 / (1 -
    2 \alpha)) (1 - \lambda)}
\]
Notice that ratio $\beta^2 / (1 - 2 \alpha) = \lambda^2 (1 + \alpha^2 / (1 - 2
\alpha))$ is increasing in $\alpha$. Thus, the ratio of biases is increasing in
$\alpha$ and $\lambda$. So, similarly, to the one-period case, the optimal path
is preferable to the naive path in terms of bias if $\alpha$ and $\lambda$ are
small enough. (Same analysis holds for the shift.)

If $\alpha < 0$, we get
\[
    \frac{\abs{\shift^*_1}}{\abs{\shift^n_1}} = \frac{\abs{\alpha} \lambda (1
    + 2 \abs{\alpha} + \gamma \beta^2)}{((1 + 2 \abs{\alpha})^2 - \gamma
    \alpha^2 \beta^2) (1 + \abs{\alpha} - \lambda + \abs{\alpha} \lambda)}.
\]
This ratio is increasing in $\lambda$ and $\gamma$. Hence,
\[
    \frac{\abs{\shift^*_1}}{\abs{\shift^n_1}} \le \frac{2 + \alpha^2}{2 + 8
    \abs{\alpha} + 3 \alpha^2} \le 1.
\]
So, the bias of the optimal path is smaller than the bias of the naive path.
Similarly, the shift of the optimal path is smaller than the impact of the
naive path.

\paragraph{Discussion}

Similarly to the one-period case, the naive path might be preferable in terms
of bias and impact to the optimal path for $\alpha \ge 0$. However, for $\alpha
< 0$, the optimal path is superior to the naive path in terms of bias and
shift.

\subsubsection{Infinite Horizon Slow Deployment, Perfect Information}

This section contains additional results for \cref{sec:inf-slow}.

\paragraph{Bias of $\prm^*_0$}

We get
\[
    \bias^*_0 = \frac{(1 - \xi) (1 - \abs{\alpha})}{1 - 2 \alpha +
    \xi} s_1.
\]
Notice that, if $1 - 2 \alpha \ge \sqrt{\gamma} \beta$, then this bias is
bigger than in the two-period case. Thus, as previously, the longer time
horizon incentivizes the model provider to give more biased predictions.

\paragraph{Shift of $\prm^*_0$}

We get
\[
    \shift^*_1 = \frac{2 \alpha - \abs{\alpha} - \abs{\alpha} \xi}{1 - 2
    \alpha + \xi} s_1.
\]
Similarly to the bias of $\prm^*_0$, the impact of $\prm^*_0$ increases
compared to the two-period case if $\alpha > 0$. However, if $\alpha < 0$, the
impact becomes smaller than the two-period impact.

\paragraph{Bias and Shift of $\prm^n_0$}

The bias and impact of the naive path in the symmetric case follows
\[
    \begin{split}
        \bias^n_0 &= (1 - \alpha - \beta) p_0,\\
        \shift^n_1 &= (\alpha - \abs{\alpha} \lambda) p_0.
    \end{split}
\]

The bias of the naive path is smaller if
\[
    2 \alpha + \beta (1 + \gamma (\alpha + \beta) (1 - \alpha - \beta)) \ge 1,
\]
which happens only if $\alpha > 0$ and $\alpha$ is sufficiently big. (The same
inequality holds for the shift.)

\subsubsection{Infinite Horizon Rapid Deployment, Perfect Information}

This section contains additional results for \cref{sec:inf-rapid}.

\paragraph{Bias of $\prm^*_0$}

We get
\[
    \prm^*_0 - p_0 = \frac{1 - \chi}{1 + \chi} p_0.
\]
Assuming that $p_0 > 0$, we get the following classification of the model
provider actions. In the case of $\alpha > 0$, we get that $\prm^*_0 > p_0$. If
$\alpha < 0$ and $\alpha + \beta > 0$, $\prm^*_0 < p_0$. Finally, if $\alpha +
\beta < 0$, $\prm^*_0 > p_0$ again.

\paragraph{Shift of $\prm^*_0$}

We get
\[
    p^*_1 - s_1 = \kappa p_0 - \lambda p_0 = \Par*{-\abs{\alpha} \lambda +
    \frac{2 \alpha}{1 + \chi}} p_0.
\]
Since $\kappa$ increases in $\alpha$ and $\kappa|_{\alpha=0} = \lambda$,
the shift increases in $\abs{\alpha}$.

\subsubsection{Additional Visualizations}

We visualize the solutions for $T=1$ rapid case, $T=2$ rapid case, and $T=2$
slow case in \cref{fig:fin-sols}. As we can see, if $\alpha > 0$, the
prediction and the resulting next-period mean shift to more extreme values.
Otherwise, the prediction and mean shift to $0$ (the effect is more pronounced
for the mean).

\begin{figure}[ht]
    \input{fig6-fin-sols.pgf}
    \caption{The plots depict the dependence of $\prm^*_0$ (blue), $p^*_1$
    (orange), and $s_1$ (green) on $p_0$ for $\lambda = 0.8$, $\pi = 0.2$, and
    $\gamma=0.5$. Columns correspond to the different values of $\alpha$; the
    top row corresponds to the $T=1$ rapid case; the middle row corresponds to
    $T=2$ rapid case; the bottom row corresponds to the $T=2$ slow case.}
    \label{fig:fin-sols}
\end{figure}

\subsection{Imperfect Information, \texorpdfstring{$T=1$}{T=1} Slow Deployment}

Here, we present additional results for \cref{sec:imperf-one-slow}.

\subsubsection{Bias and Mean Shift Theoretical Results}

The bias for the naive estimator $\hat{\theta}_0^n$ is given by
\begin{equation*}
    \bias_0^n = p_0(|\alpha| - \alpha).
\end{equation*}
For the performative estimator $\hat{\theta}_0^\ast$, the bias is 
\begin{equation*}
    \bias_0^\ast= (1 - \alpha) \mathbb{E}[\hat{\theta}_0^\ast] - (1 - |\alpha|) p_0.
\end{equation*}

For the naive estimator $\hat{\theta}_0^n$ the mean shift is  
\begin{equation*}
    \shift_1^n = p_0(\alpha - |\alpha|) = - \bias_0^n,
\end{equation*}
and for the performative estimator $\hat{\theta}_0^\ast$, we have
\begin{equation*}
    \shift_1^\ast = \alpha \E[\hat{\theta}_0^\ast] - |\alpha|p_0.
\end{equation*}

\subsubsection{General Version of Theorem \ref{theorem: expected_loss}}

Here, we present a result that generalizes \cref{theorem: expected_loss},
offering theoretical insights for all possible values of $\alpha \in (-1,1)$.
\begin{theorem}
    \label{theorem: expected_loss_full}
    For the naive estimator $\hat{\theta}_0^n$ the expected loss is 
    \begin{equation*}
        \E_{z \sim D_1^{test}}[(\hat{\theta}_0^n - z)^2] = p_0^2 (2 |\alpha| -
        2\alpha - 1) + (2\alpha - 1)\frac{4p_0^2 - 1}{4m} + \frac14,
    \end{equation*}
    and for the performative estimator $\hat{\theta}_0^\ast$, we have 
    \begin{align*}
        \E&[(\hat{\theta}_0^\ast - z)^2] =\\
        &\begin{cases}
            \frac{(1 - |\alpha|)^2}{1-2\alpha} \bigg( \frac{\frac14 - p_0^2}{m}
            - p_0^2 \bigg) + \frac14 & \alpha \in (-1, 0]\\
            p_0 (1 - |\alpha|) \big(2F_{m, p_0 + \frac12}(\frac{m}{2}) - 1\big)
            + \frac{1-\alpha}{2} & \alpha \in [0.5, 1)\\
            \sum_{x \in I}((1 - 2\alpha)g(x)^2 - 2(1 - |\alpha|)p_0 g(x)) p(x) +
            (p_0(1-|\alpha|) - \frac{1-2\alpha}{4})F_{m, p_0 +
            \frac{1}{2}}\bigl(\frac{2 - 3\alpha}{2 - 2\alpha}m \bigr) & \\
            + (p_0(1-|\alpha|) + \frac{1-2\alpha}{4})F_{m, p_0 +
            \frac{1}{2}}\bigl( \frac{\alpha m}{2 - 2\alpha} \bigr) - p_0
            (1-|\alpha|) + \frac{1-\alpha}{2}, & \alpha \in (0, 0.5),
        \end{cases}
    \end{align*}
    where $I$ is the set of integers in $\big(\frac{\alpha m}{2-2\alpha},
    \frac{(2-3\alpha)m}{2-2\alpha} \big]$, $g(x) \defeq (\frac{1-\alpha}{1-2\alpha})(\frac{x}{m} -
    \frac{1}{2})$, $F_{m, p_0 + \frac12} (x) :=
    \sum_{k=0}^{\lfloor x \rfloor} p(x),$ and
    \begin{equation*}
        p(x) := \binom{m}{x} \bigg(\frac12 + p_0\bigg)^x \bigg(\frac12 -
        p_0\bigg)^{m-x}
    \end{equation*}

    Asymptotically, we have that as $m \to \infty$
    \begin{equation*}
        \E[(\hat{\theta}_0^\ast - z)^2] \to \verb|loss|_0^\ast
    \end{equation*}
    i.e. as $m$ goes to infinity, $\hat{\theta}_0^\ast$ approaches the optimal
    estimator for the risk minimisation problem.
\end{theorem}

\clearpage
