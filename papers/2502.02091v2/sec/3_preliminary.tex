\vspace{-4mm}
\section{Preliminary}
\vspace{-1mm}
For efficient dynamic scene editing, we leverage 4D Gaussian Splatting (4DGS)~\cite{ref_10_4dgs} which represents scenes by separating static and dynamic information. In this section, we briefly review 4DGS, highlighting its Hexplane~\cite{ref_16_hexplane, ref_15_kplanes}-based Gaussian deformation field, and introduce our proposed method in Sec.~\ref{sec::method}.


\vspace{-4mm}
\paragraph{4D Gaussian Splatting.}
4DGS consists of a canonical 3D Gaussians~\cite{ref_8_gs} $\mathcal{G}_{\text{canon}}$ that represents static information and a Gaussian deformation field that represents dynamic information and produces each Gaussian’s deformation $\Delta  \mathcal{G}_t$ (where $t$ is a normalized value from 0 to 1, denoting the timestep within the dynamic scene), as illustrated in Fig.~\ref{fig:4dgs}. The 3D Gaussians $\mathcal{G}_{\text{canon}}$ representing the undeformed static canonical 3D scene consist of $N$ Gaussian primitives (in our case, $N=100k$–$200k$), denoted as $\mathcal{G}_{\text{canon}} = \left\{(p_i, s_i, r_i, o_i, C_i)\right\}_{i=1}^N$, where each primitive is defined by a position $p \in \mathbb{R}^3$ , a scaling vector $s\in \mathbb{R}^3$, a rotation quaternion $r\in \mathbb{R}^4$, an opacity $o\in \mathbb{R}$, and a spherical harmonics color $C\in \mathbb{R}^k$, with $k$ determined by the SH degree. The Gaussian deformation field $\left\{\mathcal{E}(\mathcal{G}_{\text{canon}}, t), \mathcal{D}\right\}$ consists of an encoder part $\mathcal{E}(\mathcal{G}_{\text{canon}}, t)$, which outputs an embedding voxel feature $f_d$ based on spatio-temporal input coordinates $p$ and $t$, and a decoder part $\mathcal{D}$, which decodes the voxel feature into each Gaussian’s deformation $\Delta \mathcal{G}_t$. Note that, to ensure Gaussian deformations resemble real-world physical motion, 4DGS computes deformation values only for Gaussian position $p$, scale $s$, and rotation $r$. Therefore, $\Delta \mathcal{G}_t$ can be expressed as $\left\{ \Delta p_{t,i}, \Delta s_{t,i}, \Delta r_{t,i} \right\}_{i=1}^N$. By repeatedly adding the outputs of the deformation field $\Delta \mathcal{G}_t = \mathcal{D}(\mathcal{E}(\mathcal{G}_{\text{canon}},t))$ to the canonical 3D Gaussians $\mathcal{G}_{\text{canon}}$ at each timestep $t$, we can render an image $\hat{I}_{M, t}$ from deformed 3D Gaussians $\mathcal{G}_{\text{def},t} = \mathcal{G}_{\text{canon}} + \Delta \mathcal{G}_t$ as: $\hat{I}_{M, t} = S(M, \mathcal{G}_{\text{def},t})$, where $M$ denotes the camera matrix, and $S$ represents the rendering (differential splatting) process of the 3DGS. 

\vspace{-4mm}
\paragraph{Encoder for Gaussian Deformation Field.}
4DGS incorporates Hexplane~\cite{ref_15_kplanes,ref_16_hexplane}, as a core component in the structure of the encoder $\mathcal{E}(\mathcal{G}_{\text{canon}}, t)$ within its Gaussian deformation field. The Hexplane is a spatio-temporal structure encoder and can be viewed as a generalization of Triplane ~\cite{ref_24_eg3d}, which was originally designed to embed spatial information in 3D space.

Hexplane-based encoder $\mathcal{E}(\mathcal{G}_{\text{canon}}, t)$ can be parametrized by six multi-resolution voxel grids $R_l$ across the four dimensions $(x, y, z, t)$ and simple MLP encoder $\phi_d$ as $
 \mathcal{E}(\mathcal{G}_{\text{canon}},t)=\{R_l(i,j), \phi_d | (i,j) \in \{(x,y),(y,z),(x,z),(x,t),(y,t),(z,t)\}, l \in \{1,2\}\}$, where $l$ represents the multi-resolution level (the multi-resolution technique is relevant to Instant-NGP ~\cite{ref_23_instantNGP}, enabling fast optimization and rendering).

The spatio-temporal embedding voxel feature $f_d$ is obtained from the Hexplane as $f_d = \phi_d(f_h)$, where $f_h = \bigcup_l \prod \text{interp}(R_l(i,j))$, and $(i,j) \in \{(x,y),(x,z),(y,z),(x,t),(y,t),(z,t)\}$. In 4DGS, the $x, y$, and $z$ coordinates of the Gaussian position $p$ and timestep $t$ is used to query voxel features across six planes. The six voxel features obtained from each plane through bilinear interpolation are then combined via the Hadamard product (channel-wise product). This queried voxel feature $f_h$ is subsequently passed through $\phi_d$ to yield the final embedding voxel feature $f_d$ as shown in Fig.~\ref{fig:4dgs}.


\begin{figure*}[h]
\centering
    \includegraphics[width=\linewidth]{fig/figure_3_method_cr.jpg}
    \caption{\textbf{Overall pipeline of our proposed dynamic scene editing method (Instruct-4DGS)}: To obtain the target dynamic scene for editing, we first optimize the 4D Gaussians using a multi-camera captured video dataset (Sec.~\ref{subsec::4.1}). We then perform 3D Gaussian editing on the static canonical 3D Gaussians by editing only the multiview images corresponding to the first timestep (Sec.~\ref{subsec::4.2}). We apply score-based temporal refinement to mitigate motion artifacts without additional image editing (Sec.~\ref{subsec::4.3}).}
    \label{fig:method}
    \vspace{-1mm}
\end{figure*}

\vspace{-4mm}
\paragraph{Decoder for Gaussian Deformation Field.}
 The spatio-temporal voxel feature $f_d$ passes through a multi-head simple MLP decoder $\mathcal{D}=\{\phi_p, \phi_s, \phi_r\}$, which decodes it into the deformation values of the Gaussian feature $p$, $s$ and $r$ as $\Delta p=\phi_p(f_d), \Delta s=\phi_s(f_d)$, and $\Delta r=\phi_r(f_d)$.
 
 Since the deformation field $\left\{\mathcal{E}(\mathcal{G}_{\text{canon}}, t), \mathcal{D}\right\}$ is designed with a compact Hexplane and a simple MLP, 4DGS achieves real-time rendering speed. This provides a significant advantage for editing tasks, where rendering is performed frequently. To leverage this efficiency and the static-dynamic separability, we applied 4DGS to our primary representation for 4D dynamic scenes.
