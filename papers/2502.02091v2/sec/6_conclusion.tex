\section{Conclusion and Limitations}
\vspace{-2mm}
\paragraph{Conclusion.} We proposed Instruct-4DGS, an efficient 4D dynamic scene editing framework leveraging 4D Gaussian Splatting (4DGS) and a score distillation mechanism. Exploiting the static-dynamic separability of 4DGS, our approach edits only static canonical components and refines motion artifacts, significantly enhancing editing speed and efficiency. Score distillation effectively transfers generative priors into 4D space, offering an efficient alternative to the conventional RGB loss, which requires updating additional 2D images. Experimental results demonstrated superior visual quality and editing efficiency compared to the baseline.

\vspace{-4mm}
\paragraph{Limitations.} Our method relies on IP2P's capabilities, cannot directly edit motion, requires segmentation for partial edits, and may show motion artifacts due to limitations of the 4D representation, even after temporal refinement.

\vspace{-4mm}
\paragraph{Acknowledgements.} This work was supported by Institute of Information \& Communications Technology Planning \& Evaluation (IITP) grant funded by the Korea government (MSIT) (RS-2024-00439020, Developing Sustainable, Real-Time Generative AI for Multimodal Interaction, SW Starlab).