\section{Related Works}
\subsection{Grammatical Error Correction}
% \cite{junczys-dowmunt-etal-2018-approaching, katsumata-komachi-2020-stronger}
% \cite{omelianchuk-etal-2020-gector, lai-etal-2022-type}
% \cite{lewis-etal-2020-bart}
% \cite{devlin-etal-2019-bert}
% \cite{zhang-etal-2022-syngec}
% \cite{zhang-etal-2023-bidirectional, zhou-etal-2023-improving-seq2seq}
% \cite{li-etal-2023-templategec, li-wang-2024-detection}

% \cite{brown2020language}
% \cite{li2024pre}

% \cite{davis-etal-2024-prompting}
% \cite{fan2023grammargpt, raheja-etal-2024-medit}

% \cite{coyne2023analyzing}
% \cite{penteado2023evaluating, maeng-etal-2023-effectiveness}

% \cite{loem-etal-2023-exploring, zeng-etal-2024-evaluating}

% \cite{coyne2023analyzing}

Methods in the GEC field have been dominated by sequence-to-sequence generation models \cite{junczys-dowmunt-etal-2018-approaching, katsumata-komachi-2020-stronger} and sequence-to-edit tagging models \cite{omelianchuk-etal-2020-gector, lai-etal-2022-type} since introduction of the Transformer architecture \cite{vaswani2017attention}. The former generally adopt the encoder-decoder architecture \cite{lewis-etal-2020-bart}, while the latter use the encoder-only architecture \cite{devlin-etal-2019-bert}. Many state-of-the-art (SOTA) improvements are based on these two architectures, such as incorporating syntactic information into the input \cite{zhang-etal-2022-syngec} or reranking during the output process \cite{zhang-etal-2023-bidirectional, zhou-etal-2023-decoding-interventions}. Additionally, there are works that split the task into error detection and error correction phases  \cite{li-etal-2023-templategec, li-wang-2024-detection}.

Since the advent of ChatGPT \cite{brown2020gpt3}, LLMs have seen extensive application in natural language processing, particularly in text generation tasks \cite{li2024pre}. Some studies have explored the application of LLMs in GEC, such as constructing prompts for direct inference \cite{davis-etal-2024-prompting} and using parallel data for instruction tuning \cite{fan2023grammargpt, raheja-etal-2024-medit}. Research has also analyzed the performance of LLMs in the GEC task \cite{coyne2023analyzing}, including scenarios involving low-resource languages \cite{penteado2023evaluating, maeng-etal-2023-effectiveness}. The prompting strategies significantly impact performance, and there is a tendency for over-correction by LLMs \cite{loem-etal-2023-exploring, zeng-etal-2024-evaluating}. However, studies indicate that human evaluations rate the modifications made by LLMs highest \cite{coyne2023analyzing}. Our work extends the use of LLMs in multilingual GEC through an easy-to-use in-context learning approach.

\subsection{Grammatical Error Explanation}

% \cite{liang-etal-2023-chatback}

% \cite{fei-etal-2023-enhancing, ye2024excgec}

% \citet{kaneko-etal-2022-interpretability}

% \cite{kaneko-okazaki-2024-controlled, song-etal-2024-gee}

Grammatical error explanation (GEE) refers to the elucidation of the reasons for grammatical errors in sentences and the corresponding grammatical knowledge. This requirement stems from language teaching, where providing explanations alongside error corrections is essential \cite{liang-etal-2023-chatback}. To promote the development of interpretable GEC systems, some GEC benchmarks incorporate error types, evidence words, and natural language explanations as forms of grammatical error explanation \cite{fei-etal-2023-enhancing, ye2024excgec}. \citet{kaneko-etal-2022-interpretability} utilized example-based methods to construct interpretable GEC systems. With the emergence of more LLMs with stronger linguistic capability, some works have used LLMs to generate explanations for each error in the text, and further refine the task definition and evaluation methods for GEE \cite{kaneko-okazaki-2024-controlled, song-etal-2024-gee}. Our work leverages the natural language explanations to improve the example-based GEC system.


\subsection{Demonstrations Selection}
% \cite{brown2020gpt3}

% \cite{NEURIPS2022_18abbeef}

% \cite{fu2022complexity, li2023finding}

% \cite{luo2023dricl}

% \cite{lewis2020rag}

% \cite{reimers2019sentencebert, hongjin2022selective,robertson2009probabilistic}

In-context learning (ICL) is a simple and efficient method for utilizing large language models \cite{brown2020gpt3}. By using examples as demonstrations to form few-shot inference, ICL can avoid the costly optimization of large parameters. The demonstrations can be hand-crafted \cite{brown2020gpt3} or selected from labeled datasets \cite{NEURIPS2022_18abbeef}. The choice of demonstrations impacts the final performance of LLMs; therefore, some works design the selection process based on criteria such as complexity and diversity \cite{fu2022complexity, li2023finding}. Furthermore, through retrieval mechanisms, each test data can be matched with different demonstrations to enhance model performance \cite{luo2023dricl}. This process is similar to retrieval-augmented generation (RAG), where relevant information is retrieved to improve LLMs performance \cite{lewis2020rag}. Common retrieval methods involve matching inputs to inputs of the labeled data, with frequently used similarity measures including SBERT and BM25 \cite{reimers2019sentencebert, hongjin2022selective, robertson2009probabilistic}. Our work attempts to use matching between explanations as a novel retrieval method.