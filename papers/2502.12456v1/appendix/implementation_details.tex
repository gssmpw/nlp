
\section{Implementation Details}
\label{sec:implementation_details}

\para{Training Details.}
We implement our networks using PyTorch~\cite{paszke2019pytorch} and run all experiments on a GPU cluster with four A100 GPUs.
%
We employ the Adam optimizer~\cite{kingma2014adam} to train our model with a learning rate of $2 \times 10^{-4}$ and an exponential decay of 0.998 every 1,000 iterations.
%
Following LION~\cite{zeng2022lion}, we use an exponential moving average (EMA) 
% \phil{TODO: no need to define EMA, if you will not use it later on in this paper}  \ed{This is a technique for training diffusion model so I mention here as implementation details}
of our model with a decay of 0.9999.
%
Specifically, we train our unconditional generative model for approximately 600,000 iterations with a batch size of 256, taking about four days to complete.
%
% \ed{Our method generally can produce reasonable results starting from 10 inference steps, which takes around XX seconds.}
% \phil{TODO: Try to make this sentenfce more specific and clear} \ednote{TODO: measure the inference time in A100.}
\rebuttal{It is noted that we use larger batch sizes and more training iterations compared to existing work, including~\cite{zhou2021pvd,wu2023psf}, to effectively compare various training paradigms (Figures~\ref{fig:main_quantitative_comp} \&~\ref{fig:main_qualitative_comp}). This choice ensures our training procedure has higher stability and converges properly.
% 
Additionally, we want to highlight that the online subsampling procedure introduces negligible overhead in the training process (merely requiring additional indexing of a cached array).}

\para{Network Architecture.}
For the network architecture, we adopt the same structure as PVD~\cite{zhou2021pvd} and employ PVCNN~\cite{liu2019point} as our vector field network for the unconditional generation task.
%
In the shape completion task, we use an additional 256-dimensional latent vector to represent the input partial point cloud, which is then injected into PVCNN.
%
% For image-conditioned generation, we extract this vector using the Dino-V2 (ViT-L/14)~\cite{oquab2023dinov2} 
% \phil{TODO: citation?} 
% image encoder followed by MLP layers.
%
To do so, we use another PVCNN follow LION~\cite{zeng2022lion} to extract the latent vector from the partial point cloud.
%
% \ednote{Yes. We should mention it!}
% \CL{Are we going to talk more about the inference (e.g. how long it takes for generating one point cloud with $N$ points; We should note we don't need the OT precomputation for inference since that is also a large overhead if needed. }

\para{Generated Shape Normalization.}
To ensure a fair evaluation among different baselines in the unconditional task, we convert the inference results of various generative methods into a common coordinate domain.
%
For all baseline methods, including PVD~\cite{zhou2021pvd}, DiT-3D~\cite{mo2023dit3d}, LION~\cite{zeng2022lion}, and PSF~\cite{wu2023psf}, we respect the original normalization adopted in their training procedures.
%
Since all these methods compute a global mean coordinate and global scale ratio across all training shapes, we use these two quantities to reverse the normalization on the generated shape, based on the values obtained from the training set.
%
This procedure aligns with existing baselines, such as~\cite{yang2019pointflow,zeng2022lion}.
