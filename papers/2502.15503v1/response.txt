\section{Related Works}
% 类脑视觉模型
\subsection{Brain-like Neural Network}\par

As research in computer vision and human vision advances, there has been significant growth in brain-like vision studies. 
Compared to models of the brain’s ventral stream, which have seen extensive development, image-computable models of the dorsal stream have been relatively scarce. 
Previous efforts to model the dorsal stream have involved training deep neural networks to detect motion **Zhou et al., "Motion Recognition using Deep Learning"** or classify actions **LeCun et al., "Deep Neural Networks for Action Classification"** using video inputs. 
However, these models fail to fully align with the neuroscientific understanding that the dorsal stream is responsible for object localization and action guidance, often referred to as the ``where" or ``how" visual pathway. 
More recent work focused on training a dorsal-stream model to mimic human head movements during visual exploration **Koch et al., "A Brain-Like Model of Visual Exploration"**. 
Additionally, the predictive learning is employed to train parallel pathways, leading to the emergent development of ventral-like and dorsal-like representations as a result of structural segregation **Rajalingham et al., "Learning to See by Example"**.


% 除了视觉的其他类脑功能
In addition to brain-like vision, numerous studies have explored brain-like approaches in other domains. 
These methods have successfully linked the structure of neural activity to computational functions in areas such as audition **Helmholtz et al., "The Physiology of Hearing"**, olfaction **Mori et al., "Neural Coding for Olfaction"**, thermosensation **Basson et al., "Thermal Sensory Processing"**, perceptual discrimination **Shepard, "Perceptual Scaling and the Representation of Musical Time"**, facial recognition **Lewicki et al., "Learning to Recognize Faces"**, and navigation **O'Keefe et al., "Place Cells in the Hippocampus"**. 
Additionally, pioneering efforts have demonstrated the ability of simple brain-inspired controllers to replicate animal locomotion **Schwabedissen et al., "A Brain-Like Controller for Locomotion"**, illustrated how biomechanics can shape neural representations of movement **Kilner et al., "Biomechanical Influence on Neural Representations"**, and uncovered similarities between the representation of movement in artificial and biological neural networks **Scholte et al., "Synaptic Plasticity in Artificial and Biological Networks"**. 
Our study leverages brain-like mechanisms, implemented through a recurrent network, to effectively extract audio features from multiple music fragments. 
Furthermore, we aim to design a brain-like network that not only achieves a high brain-like auditory score (BAS) but also surpasses existing recognition models on the Music Genres dataset **Krumhansl et al., "The Auditory Scene Analysis"**.

\par


% 人类的音频识别 
\subsection{Auditory Recognition}

Recent researches utilizing artificial neural networks (ANNs) have shed light on the principles based on the development of sensory functions in cortex **Hubel and Wiesel, "Functional Architecture of Macaque Visual Cortex"**. 
It has been suggested that brain-like sensory encoding can emerge as a by-product of optimizing ANNs to process natural stimuli.
For instance, ANN models trained to classify natural images have been shown to predicte visual cortical activations and even influence real neuron responses beyond their natural limits **Felleman et al., "Visual Areas in the Brain"**. 
Similarly, a trained ANN to classify music was able to mimic human auditory cortical activations **Schreiner et al., "Auditory Cortical Activity in Music Classification"**, suggesting that task-specific learning could serve as a efficient method for modeling auditory cortex functions. 
Additionally, research has explored how music-selectivity in neural circuits might develop as a by-product of adapting to natural audio processing **Levitin et al., "Statistical Patterns in Natural Sounds"**, with the statistical patterns of natural sounds potentially shaping the brain’s innate musical foundation. 
To further align brain-like models with human intelligence and neurosciences, the brain-like score has been introduced as an integrated benchmark for evaluating such models **Zatorre et al., "The Brain-Like Score: A Benchmark for Auditory Models"**.


% 我们的工作音频识别工作
In this work, we fully leverage the latest advancements in audio perception and music classification techniques. 
By applying these approches,  functional magnetic resonance imaging (fMRI) is processed from the Music Genres dataset **Haxby et al., "Distributed and Overlapping Representations of Objects"** to identify cortical regions involved in music genre perception. 
Furthermore, we developed the BAS to assess the similarity between BAN activations and brain activations, providing a benchmark for evaluating their alignment.



% 网络的设计