\begin{abstract}
    % This paper addresses large-scale sparse generalized linear problems by proposing a first-order proximal method for the continuous relaxation within the branch-and-bound framework.
    % The proximal operator is computed in linear time using a customized pooled-adjacent-violation algorithm.
    % Our method achieves fast convergence, low computational complexity, and easy GPU parallelization.
    % We demonstrate significant speedups in computing dual bounds and certifying optimal solutions for large-scale problems using synthetic and real-world datasets.
    
% This paper tackles the fundamental challenge of certifying optimal $k$-sparse solutions for generalized linear models (GLMs), a critical task in high-dimensional statistics, feature selection, and interpretable machine learning.
% While branch-and-bound (BnB) frameworks theoretically enable exact certification via dual bounds, existing methods for computing these bounds suffer from prohibitive computational costs or slow convergence, limiting scalability to large-scale problems.
% We propose a novel first-order proximal gradient algorithm designed for the continuous relaxation of the $k$-sparse GLM problem within a BnB framework.
% A key technical contribution lies in our efficient evaluation of the proximal operator, which circumvents the need to solve a computationally intensive quadratically-constrained quadratic program (QCQP).
% By exploiting the problem’s inherent structure, we derive a procedure to compute this operator \textit{exactly} in $\mathcal{O}(p \log p)$ time, a dramatic improvement over using off-the-shelf solvers.
% Further, we introduce acceleration techniques that exploit problem-specific geometry, yielding an overall fast convergent algorithm with low per-iteration complexity.
% Extensive experiments on synthetic and real-world datasets demonstrate that our approach significantly speeds up dual bound computations and provides effective certification of optimal solutions for large-scale problems.


% This paper tackles the fundamental challenge of certifying optimal $k$-sparse solutions for generalized linear models (GLMs).
% While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes via dual bounds, existing methods for computing these bounds suffer from prohibitive computational costs or slow convergence, limiting scalability to large-scale problems.
% To address this, we propose a novel first-order proximal gradient algorithm designed for solving the perspective relaxation of the problem within a BnB framework.
% A key technical contribution lies in our efficient evaluation of the proximal operator, which circumvents the need to solve a computationally intensive quadratically-constrained quadratic program (QCQP).
% By exploiting the problem’s inherent structure, we derive a procedure to compute this operator \textit{exactly} at time complexity $\tilde{O}(p)$, a dramatic improvement over the general-purpose conic solvers.
% Further, by taking advantage of the additional property of this proximal operator, we introduce an efficient function-value based acceleration technique, yielding an overall fast-converging algorithm with low per-iteration complexity.
% Extensive experiments on synthetic and real-world datasets demonstrate that our approach significantly speeds up dual bound computations and is highly effective in providing optimal certificates for solutions of large-scale problems.


This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\ell_0$ cardinality constraint.
While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems.
To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework.
Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program.
Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity.
Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems.
\end{abstract}

