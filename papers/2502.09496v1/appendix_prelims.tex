\section{Preliminaries for Proof}\label{sec:preliminariesproof}
In this section we give the preliminaries for the proof. For the reader's convenience, we restate \cref{alg:splitting27if}.
\setcounter{algocf}{1}
\begin{algorithm}
    \caption{Splitting algorithm $\cS$}
    \KwIn{Training sequences $S, T \in (\cX \times \cY)^{*}$, where $|S| = 3^{k}$ for $k \in \mathbb{N}$.}
    \KwOut{Family of training sequences.}
    \If{$k \geq 6$}{
        Partition $S$ into $S_{1}, \ldots, S_{27}$, with $S_i$ being the $(i-1)|S|/27+1$ to the $i|S|/27$ training examples of $S$. Set for each $ i $ 
        \newline 
        \textcolor{white}{halloooooooooooooo}   $
             S_{i,\sqcup} = S_{i}[1:3^{k-6}],\quad \quad
            S_{i,\sqcap} = S_{i}[3^{k-6}+1:3^{k-3}], $
            \newline 
        \Return{$[\cS(S_{1,\sqcup}; S_{1,\sqcap} \sqcup T), \ldots, \cS(S_{27,\sqcup}; S_{27,\sqcap} \sqcup T)]$}
    }
    \Else{
        \Return{$S \sqcup T$}
    }
\end{algorithm}  

We first observe that for an input training sequence $ m=|S|=3^{k} $,  the above algorithm makes $ l$ recursive calls where $ l\in\mathbb{N} $ satisfies $ k-6(l-1)\geq 6 $ and $ k-6l<6 $, that is, $ l $ is the largest number such that  $ k/6\geq l$. 
As $ l $ is a natural number, we get that $ l=\lfloor k/6\rfloor $. 
Furthermore, since $k=\log_{3}(m)  $ we get that $ l=\lfloor \log_{3}(m)/6\rfloor $. 
For each of the $ l $ recursive calls 27 recursions are made. Thus, the total number of training sequences created in $ \cS $ is $ 27^{l}\leq  3^{3\log_{3}(m)/(2\cdot6)}=m^{1/(4\ln(3))}\geq m^{0.22}$.
In what follows, we will use the quantity $ s_{\sqcap}$, which we define as $ \frac{|S|}{|S_{1,\sqcap}|}$ when running $ \cS(S;T) $ with $ S;T\in (\cX\times \cY)^{*} $ such that $ |S|=3^{k} $ and $ k\geq6 $. We notice that  
\begin{align}\label{lem:ratios}
    s_{\sqcap}\coloneqq\frac{|S|}{|S_{1,\sqcap}|}=\frac{3^{k}}{3^{k-3}-3^{k-6}}=\frac{3^{k}}{3^{k-3}(1-\frac{1}{3^{3}})}=\frac{27}{1-\frac{1}{27}}.
\end{align}
This ratio $ s_{\sqcap} $ will later in the proof show up as a constant, $ |S_{i}|/(|S|s_{{\sqcap}})=(|S_{i,\sqcup}|+|S_{i,\sqcap}|)/|S_{i,\sqcap}|=1/(1-1/27) $,  multiplied onto $ \tau.$ Thus, from this relation we see that if the split of $S_{i}$ is imbalanced so that $|S_{i,\sqcap}| $ is larger than $ |S_{i,\sqcup}| $ the constant multiplied on to $ \tau $ become smaller.      

Furthermore, in what follows, for the set of training sequences generated by $ \cS(S;T) $ and a $ \cerm $-algorithm $ \cA $, we  write $ \erm(S;T) $ for the set of classifiers the $ \cerm $-algorithm outputs when run on the training sequences in $ \cS(S;T) $, i.e., $ \erm(S;T)=\{ \erm(S') \}_{S'\in\cS(S;T)}  $, where this is understood as a multiset if the output of the $ \cerm $-algorithm is the same for different training sequences in $ \cS(S;T).$ 
Furthermore for an example $ (x,y) $ , we define $ \avg(\erm(S;T))(x,y)=\sum_{h\in \erm(S;T)}\ind\{ h(x)\not=y \}/|\erm(S;T)| $, i.e., the average number of incorrect hypotheses in $ \erm(S;T) .$  
We notice that by the above comment about $ \cS(S;T) $ having size at least $ m^{0.22},$ we have that $ \erm(S;T) $ contains just as many hypothesis, each of which is the output of an $ \cerm $ run on a training sequence of $ \cS(S;T).$ Thus as allotted to earlier our algorithm do not run on all the sub training sequences created by $ \cS(S;T),$ as it calls the $ \erm $ algorithm $ O(\ln{\left(m/(\delta(d+\ln{\left(1/\delta \right)})) \right)}) $-times. Which leads us considering the following classifier.

For a natural number $ t,$ we let $ \widehat{\erm}_{\rt}(S;T),$ be the random collection of $ t $ hypotheses drawn uniformly with replacement from $ \erm(S;T),$ with the draws being independent, where we see $ \widehat{\erm}_{\rt}(S;T) $ as a multiset so allowing for repetitions. 
We remark here that we will overload notation and use $ \rt $ (so $ t $ in bold font) to denote the randomness used to draw the $ t $ hypotheses from $ \erm(S;T)$ in the following analysis of $ \widehat{\erm}_{\rt}(S;T).$ 
Intuitively one can think of $ \widehat{\erm}_{\rt} $ as a bagging algorithm where the subsampled training sequences are restricted to subsets of $ \cS(S;T) $ rather than sampling with replacement from the training examples of $ S $ and $ T.$ In what follows we will consider this algorithm parametrized by $ t=O(\ln{\left(m/(\delta(d+\ln{\left(1/\delta \right)})) \right)}) $ leading to a classifier with the same order of call to the $ \cerm $ as stated in. Similarly to $ \cA(S;T) $ we also define $ \avg(\widehat{\erm}_{\rt}(S;T))(x,y)=\sum_{h\in \widehat{\erm}_{\rt}(S;T)}\ind\{ h(x)\not=y \}/|\widehat{\erm}_{\rt}(S;T)| $

Now, for a distribution $ \cD $ over $ \cX\times \{ -1,1\},$ training sequences $ S;T\in \left(\cX\times\{  -1,1\} \right)^{*},$ and $ \alpha\in[0,1] $  we will use $ \ls_{\cD}^{\alpha}(\erm(S;T))=\p_{(\rx,\ry)\sim \cD}\left[\avg(\erm(S;T))(\rx,\ry) \geq \alpha\right],$ i.e., the probability of at least a $ \alpha $-fraction of the hypotheses in $ \erm(S;T) $ erroring on a new example drawn according to $ \cD $. As above we also define $ \ls_{\cD}^{\alpha}(\widehat{\erm}_{\rt}(S;T))=\p_{(\rx,\ry)\sim \cD}\left[\avg(\widehat{\erm}_{\rt}(S;T))(\rx,\ry) \geq \alpha\right],$ for $ \widehat{\erm}_{\rt}(S;T). $ In the following we will for the case where $ T $ is the empty training sequence $ \emptyset $   us $ \widehat{\cA}_{\rt}(S)=\widehat{\cA}_{\rt}(S;\emptyset). $   
