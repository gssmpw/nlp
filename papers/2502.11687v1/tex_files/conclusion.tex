This paper presents \methodname, a novel concealed backdoor attack targeting the data collection phase of the ML pipeline. Unlike existing methods, \methodname~requires no interaction with the target model or access to auxiliary data, enhancing its practicality. Experiments on four datasets and four trigger patterns show \methodname~significantly reduces ASR during pre-deployment and evades three popular backdoor detection methods. Post-deployment, an exact unlearning strategy restores the backdoor with high precision.

\vspace{0.15cm}
% \noindent{\textbf{Commitment to Open Science:}} We will open-source the implementation of \methodname.
\noindent \textbf{Acknowledgements:} This work has been supported by the NYUAD Center for Cyber Security under RRC Grant No. G1104.