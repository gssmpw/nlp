\section{Related Works}

\noindent \textbf{Generative Models.}
Generative models based on score matching~\cite{ho2020denoising,Song2021a} and flow matching~\cite{lipman2023flow,tong2024improving} have significantly advanced machine learning, 
achieving state-of-the-art results in areas such as image generation~\cite{rombach2022high}, text generation~\cite{gat2024discrete}, and video generation~\cite{Ho2022video,polyak2024moviegencastmedia}. 
However, most of these models operate in finite-dimensional spaces and rely on fixed discretizations of data. 
Such formulations hinder transferability across discretizations and ignore function-level constraints (e.g., continuity, smoothness), 
motivating the need for function-space generative modeling.

\noindent \textbf{Neural Architecture for Functions space}
Designing neural architectures to handle function spaces remains a major research challenge. 
Standard networks typically assume fixed-size inputs, making them unsuitable for arbitrary resolutions. 
Implicit Neural Representations like SIREN~\cite{sitzmann2020implicit} harness random Fourier features~\cite{rahimi2007random} to represent continuous and differentiable objects through position embeddings. 
Similarly, NeRF~\cite{mildenhall2021nerf} treats input coordinates as continuous variables, offering flexible resolution for function outputs. 
Neural operators~\cite{anandkumar2019neural,li2021fourier,Kovachki2023,azizzadenesheli2024neural} and Galerkin transformers~\cite{cao2021choose} further generalize neural architectures to process sets of points as functional inputs, enabling function-space learning.

\noindent \textbf{Generative Models in Function Space.}
In generative modeling, early Neural Processes~\cite{garnelo2018neuralprocesses,pmlr-v80-garnelo18a} drew on Gaussian Processes~\cite{rasmussen2003gaussian}, and later methods such as GASP~\cite{pmlr-v151-dupont22a}, Functa~\cite{pmlr-v162-dupont22a}, and GANO~\cite{rahman2022generative} treat data as function evaluations to enable discretization-independent learning. Energy-based and diffusion models~\cite{pmlr-v206-lim23a,pmlr-v206-kerrigan23a,lim2025scorebaseddiffusionmodelsfunction,pidstrigach2023infinitedimensionaldiffusionmodels,franzese2024continuous} along with flow-based approaches like FFM~\cite{pmlr-v238-kerrigan24a} and OpFlow~\cite{shi2024universal} further extend these ideas. Ultimately, creating comprehensive generative models in function space requires defining suitable stochastic processes, score operators, and consistent neural mappings with specialized training for numerical stability—challenges that remain largely unresolved.

\begin{figure*}[t]
    \small
    \centering
    \includegraphics[width=0.95\linewidth]{assets/framework.pdf}
    % \vspace{-15pt}
    \caption{Overview of \textbf{FuncGenFoil}'s neural network.  
    The model is a Fourier Neural Operator, but any other neural operator capable of general-purpose function-space approximation may be used.  
    The model takes as input a function $u_t$ (at any resolution $d$), design condition variables $c$, and the generation time $t$. It then processes these as an operator and outputs the current velocity operator $v_{\theta}(u_t, c, t)$ of the ODE for generation.}
    \label{fig:velocity}
\end{figure*}

    
\noindent \textbf{Airfoil Design and Optimization.}
Airfoil design is critical for aerodynamic performance in systems such as aircraft, race cars, and wind turbines. Geometric parameterization enables efficient modeling and optimization of airfoil shapes. Free-Form Deformation (FFD)~\cite{mortenson1999mathematics}, B-splines~\cite{farin2002curves}, or NURBS~\cite{schoenberg1964spline}—and is used in CAD/CAE tools like ESP~\cite{dannenhoffer2024overview} and OpenVSP~\cite{hahn2010vehicle}—but its independent control points can lead to local optima, instability, and high dimensionality. Modal parameterization methods, including Proper Orthogonal Decomposition~\cite{berkooz1993proper}, global modal~\cite{bruls2007global}, and compact modal approaches~\cite{li2021adjoint}, address dimensionality by capturing global features with fewer variables, yet their linear reduction struggles with large deformations and detailed edits. In contrast, the Class-Shape Transformation (CST)~\cite{kulfan2008universal} offers intuitive physical interpretation and differentiability but is limited in handling significant deformations and is sensitive to parameter selection. Thus, a high-degree-of-freedom geometric representation is needed to support arbitrary shape modifications while accurately capturing highly nonlinear deformations with stability and robustness.

Recently, with the rise of generative models in the AI field, airfoil design has increasingly adopted generative models such as VAE, GAN and diffusion models~\cite{chen2021bezierganautomaticgenerationsmooth,li2022machine,xie2024parametric,yangaobo,zhenweidiffAirfoil,liu2024afbench}, as well as CFD meshes~\cite{weizhen2023,ZhenWeiDeepGeo2024}, to enhance the representation of airfoil shapes in a generative manner. These models establish an effective transformation from a latent space to the airfoil space. Previous works have primarily focused on modeling the discrete points of airfoils, which limits their flexibility for downstream tasks.








