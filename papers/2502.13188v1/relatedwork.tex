\section{Related work}
\label{sec:related_work}

MARL has been applied in many real-world applications such as finance, transportation, manufacturing \cite{Zhou_2024} as well as chemistry and biology \cite{NING202473}. For instance, \citet{mi2024taxaidynamiceconomicsimulator} introduced a simulation environment to model dynamic interactions among governments, households, firms, and financial intermediaries. \citet{Ma2020FeudalMD} utilized a cooperative MARL approach to control the traffic signals in different road networks. 


MARL has also been used to solve the route choice problems considering different aspects of the problem. \citet{AgentRewardShaping} explored Q-learning for route selection, emphasizing reward-shaping techniques aiming to eliminate traffic congestion. Another study approached route choice as a congestion game aiming for a collective equilibrium in the traffic network \cite{ZHOU2020124895}. \citet{regret_route_choice} proposed a regret-minimization approach \cite{Blum_Mansour_2007} that relies on external traffic data, which may limit its applicability in scenarios where such information is incomplete or inaccurate. In a different vein, \citet{Thomasini+2023} addressed route choice in a centralized multi-agent setting using a macroscopic traffic simulation. \citet{lazar2021learningdynamicallyrouteautonomous} address the route assignment problem to develop policies for CAVs that prevent unbounded delays in traffic networks. \citet{akman2024impact} introduced AV-specific behavioral reward formulations in mixed-traffic environments.




%%% Why RL is a natural thing to use here.