\section{Conclusion}
\label{sec:conclu}
In conclusion, this study introduces a novel constrained mask modeling paradigm, MGVGA, for circuit representation learning. 
This method integrates MGM and VGA to extract fine-grained structural information and abstract functions of circuits. 
MGM operates by masking gates in the latent space rather than in the original circuits, subsequently reconstructing the attributes of these masked gates. 
This approach preserves the logical equivalence of circuits, overcoming the limitations of traditional masked gate modeling strategies. 
Moreover, we developed VGA, which performs masking operations on the original circuits and reconstructs them under the constraints of equivalent Verilog codes. 
This enables GNNs to learn circuit functions from LLMs. 
Our comprehensive evaluations demonstrate that MGVGA performs better than previous SOTA methods in QoR prediction and logic equivalent identification tasks. 
This represents a significant advancement in applying the constrained masked modeling paradigm to general circuit representation learning. 
