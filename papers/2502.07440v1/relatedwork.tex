\section{Related Work}
Our project relates to previous methods and techniques for object recognition in visual material and the design of visualizations to analyze cultural heritage collections. Some related works combine both areas, inspiring the development of our dashboard for artwork exploration.

\subsection{Object Detection}
Focusing on the advancements in applying deep learning methods with visual arts, Castellano and Vessio \cite{castellano2021} highlight the new opportunities for analyzing and understanding art. These new opportunities enable the development of automatic tools that can make art more accessible. The authors focus on different models for recognizing and localizing objects in artwork, such as R-CNN, Fast R-CNN, Faster RCNN, and YOLO. They define The R-CNN models as region proposal-based methods and the YOLO framework as a regression-based method. These two kinds of methods differ in performance, as region proposal-based methods usually perform better, whereas regression-based methods are faster - but with a lower accuracy. However, cross-depiction remains a problem for all object detection models, as models trained on real photographs need to generalize across different visual representations. The cross-depiction problem refers to the significant drop in performance that object detection models experience when applied to datasets of different visual representations, as presented in ”Cross-depiction problem: Recognition and synthesis of photographs and artwork” by Hall et al. \cite{hall2015}. In practice, this means that object detection models are challenged when attempting to recognize objects across different depictive styles, as the style that the model has been trained on is very realistic. When tasked with detecting, the model might easily detect a cat in a photograph, but it might not be able to do so in a painting. As a way to address this problem, the authors suggest incorporating spatial and structural information when training object detection models.

\subsection{Visualization}
In recent years, the development of visualizations of cultural heritage, particularly through interactive digital museums, has increased due to the continuous digitization of cultural heritage artifacts \cite{windhager2019}. These visualizations enhance public engagement and educational opportunities within the arts. The following works described may not directly address the visualization of Holocaust artwork - or Holocaust-related themes. However, they provide a good foundation for making considerations and decisions during the design process of our interface.
To accommodate users’ complex information needs, Whitelaw \cite{whitelaw2015} proposes “generous interfaces” designed to promote exploration and engagement by providing rich and easy-to-navigate representations of digital collections. These interfaces often use components like graphs, grids, dynamic filters, and color palettes to offer multiple perspectives.
Bludau et al. \cite{bludau2021} focus on visualizations that highlight the relationships between individual items in cultural collections. They developed an interface that provides both an overview of the collection and detailed relational perspectives, such as a vertical timeline, genre-based organization, and a social relations diagram. This approach to visualization allows users to explore items based on metadata, content, and temporal context, which enhances engagement through diverse perspectives.
Crissaff et al. \cite{crissaff2018} developed ARiES (ARt Image Exploration Space), which is a user-centered interface designed to help art historians explore, analyze, and organize large image collections. It includes tools for image manipulation, annotation, grouping, comparison, and metadata exploration, which was designed based on feedback from domain experts. 
Dumas et al. \cite{dumas2014} explored a tangible user interface for interacting with ArtVis, a visualization tool for exploring around 28,000 European artworks. ArtVis offers three components - Explore, Analyze, and Browse. It uses various visualization techniques like map-based views, time sliders, stacked area charts, and fisheye distortion to promote user engagement. 
A recent survey on storytelling for heritage on Nazi persecution \cite{meffert2024} gives an overview of narrative visualizations that have been developed to support users in exploring and understanding complex themes like the Holocaust. One of the reviewed projects is the ARt-tool project “ARt. Dachau Concentration Camp in Drawings and Paintings” \cite{fink2024}. It combines augmented reality and digital art visualization to enhance holocaust remembrance. It links historical drawings and paintings to their actual locations at the Dachau memorial site through an app and a web tour with a 3D model providing a virtual exploration of the site’s history.
All of these projects demonstrate the potential of innovative interfaces to enhance user engagement and exploration in digital cultural collections by integrating diverse perspectives and interaction techniques.

\subsection{Object detection, visualization and Artworks}
Meinecke et al. (2022) \cite{meinecke2022}  present a virtual museum experience that uses interactive visualizations and machine learning to analyze and explore digitized artworks from the extensive WikiArt dataset, containing over 200k images with diverse metadata. By detecting objects within the images, the system establishes relationships and comparisons across artworks, which enables users to filter by artist style and detected objects. This approach enriches user engagement by revealing underlying connections and enhancing understanding of historical and cultural contexts.
The SMKExplorer \cite{meyer2024} is a visualization interface developed by the IT University of Denmark and the SMK - National Gallery of Denmark. It addresses the cross-depiction problem in art exploration using machine learning models like Contrastive language-image pretraining (CLIP) and grounded language-image pretraining (>GLIP). With customized labels from IconClass, the tool allows users to explore over 109,145 detected objects in 6,477 paintings, offering thematic browsing, metadata exploration, and generative AI (DALL-E 2) for creating new images. While users found the interface intuitive and engaging, challenges with mislabeling were noted, emphasizing the need for careful label selection.
Applying state-of-the-art models for object detection may lead to insufficient results when dealing with collections of paintings in styles and themes that deviate from the models’ training materials. To label a collection of medieval art, Meinecke et al. \cite{meinecke2024} developed a semi-automated annotation framework that combines machine learning with human input to increase the quality of object detection results.
The above-mentioned projects illustrate how digital cultural heritage is still evolving as technology evolves to foster a deeper understanding of the arts. They encourage the users to gain insight, understand, and learn more about the artwork in question. Drawing from these experiences, our project aims to create an interactive visualization interface for exploring Holocaust artwork, encouraging learning and reflection on this historical context.