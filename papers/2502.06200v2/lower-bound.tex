\section{The lower bound}\label{sec:lb}
In this section, we provide a sample complexity lower bound proof with regard to the error tolerance $\eps$. In fact, we prove \Cref{thm:main}, which is a formal version of \Cref{thm:main-lb}. %All distributions constructed in this section will satisfy \Cref{assump:moment} and \Cref{assump:smooth}.

% A sampling algorithm here is a procedure with query access to $f$, $\grad f$ or $\grad^2 f$, which outputs a sample point based on a series of queries. We aim to prove the following theorem in this note.
% \htodo{Here $c$ is the constant in \Cref{lem:disjointcap}.}

Recall that we use $\@D_{L,M}$ to denote the collection of distributions which are $L$-log-smooth and have second moment at most $M$. 
\begin{theorem}\label{thm:main}
    % There exist a universal constant $C>0$ such that 
    For any $L,M>0$ satisfying $LM\ge d$ and for any $\eps\in(0,1/32)$, $d\geq 5$, if a sampling algorithm $\+A$ always terminates within 
\[
    \frac{\eps (d-2)^{\frac{3}{2}}}{8}\cdot \tp{\frac{9}{256} \cdot \frac{LM}{d\eps} \cdot \frac{1}{\log \frac{LM}{d\eps}}}^{\frac{d-1}{2}}
    % \frac{\eps}{4}\cdot \tp{\frac{C\cdot LM}{2 d\eps} \cdot \frac{1}{\log \frac{LM}{d\eps}}}^{\frac{d-1}{2}}% \approx \frac{\eps}{4}\exp\set{\frac{d}{2}\cdot \Omega\tp{\log \frac{LM}{d\eps}}}
\]
queries on every input instance in $\@D_{L,M}$, then there must exist some distribution $\mu\in \@D_{L,M}$ such that when the underlying instance is $\mu$, the distribution of $\+A$'s output, denoted as $\tilde \mu$, is $\eps$ away from $\mu$ in total variation distance, i.e., $\DTV(\mu,\tilde \mu)\geq \eps$.
\end{theorem}
%\htodo{Actually we consider those distributions with second moment $O(M)$ and $O(L)$-smooth. Not exactly $M$ and $L$.}

%\mn{When $d$ is even, $\Gamma\tp{\frac{d}{2}+1} = \tp{\frac{d}{2}}!$. When $d$ is odd, $\Gamma\tp{\frac{d}{2}+1} = \frac{\sqrt{\pi}}{2^d}\cdot \frac{d!}{\tp{\frac{d-1}{2}}!}$.}

\subsection{The base instance}

We first construct a base distribution $\mu_0$. Let $R= \tp{\frac{M}{\eps}}^{\frac{1}{2}}$, and let
\[
    \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x)=q_{\!{mol}}\tp{\frac{ \|x\|^2- \frac{R^2}{16}}{\frac{R^2}{4} - \frac{R^2}{16}}} \quad \mbox{and} \quad \mathfrak{g}_{[R,2R]}(x)=q_{\!{mol}}\tp{\frac{\|x\|^2-R^2}{4R^2-R^2}},
\]
% Let $\alpha\in (0,2)$ be a constant to be determined later.
With constant function $h_1 \equiv \log \tp{\!{vol}(\+B_{3 R})} + \log \frac{1}{\eps}$ and function $h_0(x)=\frac{d\|x\|^2}{2M} + \frac{d}{2}\log \frac{2\pi M}{d}$, define the function $f_0$ as
\[
    \forall x\in \bb R^d, f_0(x) = \begin{cases} h_0(x), & \|x\|\leq \frac{R}{4} \\
    \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x)\cdot h_1 + \tp{1-\mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x)}\cdot h_0(x), & \frac{R}{4}<\|x\| \leq \frac{R}{2}\\
    h_1, & \frac{R}{2} <\|x\|\leq R\\
    \mathfrak{g}_{[R,2R]}(x)\cdot h_0(x) + \tp{1-\mathfrak{g}_{[R,2R]}(x)}\cdot h_1, & R<\|x\|\leq 2R \\
    h_0(x), & \|x\|>2R
    \end{cases}.
\]

%\mn{Here we use a constant function $h_1$ rather than using Gaussian directly. This is crucial.}
Consider the distribution $\mu_0$ with density $p_{\mu_0} \propto \exp\tp{-f_0(x)}$ and its normalizing factor $Z_0 = \int_{\bb R^d} \exp\tp{-f_0(x)} \d x$.
\begin{lemma}\label{lem:Z_0}
    The normalizing constant $1-16\eps \leq Z_0 \leq  1+\eps$. 
\end{lemma}
\begin{proof}
    On one hand, from Markov's inequality,
    $$
        Z_0\geq \int_{\+B_{\frac{R}{4}}} e^{-f_0(x)} \dd x = \int_{\+B_{\frac{R}{4}}} e^{-h_0(x)} \dd x = 1- \Pr[X\sim \+N\tp{0,\frac{M}{d}\cdot \!{Id}_d}]{\|X\|^2\geq \frac{R^2}{16}} \geq 1-16\eps.
    $$
    On the other hand, 
    $$
        Z_0\leq \int_{\bb R^d} e^{-h_0(x)} \dd x + \vol (\+B_{2R})\cdot e^{-h_1} \leq 1 + \eps\cdot \frac{\vol (\+B_{2R})}{\vol(\+B_{3R})}\leq 1+\eps.
    $$
    
    % Note that $h_1=\log \frac{1}{\eps} + \frac{d}{2}\log\tp{\pi \alpha^2 R^2} - \log \Gamma\tp{\frac{d}{2}+1}$.
    
    % Note that for each fixed $x\in \bb R^d$, $f_0$ is a non-decreasing function wrt $\alpha$. So $Z_0$ is decreasing as $\alpha$ increases. When $\alpha=1$,
\end{proof}

% We fixed the value of $\alpha$ to be the one in \Cref{lem:Z_0}.
\begin{lemma}\label{lem:propertymu0}
    The distribution $\mu_0$ is $\+O(L)$-log-smooth and has second moment $\+O(M)$.
\end{lemma}
%\htodo{$O(M)$ and $O(L)$, not exactly $M$ and $L$} 
\begin{proof}
    We first calculate the second moment of $\mu_0$. We have
    $$
        \E[\mu_0]{\|X\|^2} \leq \frac{\E[X\sim \+N\tp{0,\frac{M}{d}\cdot \!{Id}_d}]{\|X\|^2} + \vol (\+B_{2R})\cdot e^{-h_1}\cdot 4R^2}{Z_0} \leq \frac{M + \eps\cdot \frac{\vol (\+B_{2R})}{\vol (\+B_{3R})}\cdot 4R^2}{Z_0} \leq \frac{3M}{Z_0}\leq 6M,
    $$
    where the last inequality is due to \Cref{lem:Z_0} and the fact that $\eps<\frac{1}{32}$.
    % \htodo{We may need $\eps<\frac{1}{32}$.}

    For the smoothness, we only need to check $\|\grad^2 f_0(x)\|$ for those $x$ with $\|x\|\in (\frac{R}{4},\frac{R}{2}]$ and $\|x\|\in (R,2R]$ since clearly $f_0\in C^2(\bb R^d)$. %\ctodo{need $f_0\in C^2$ here.}

    First, for $\|x\|\in (\frac{R}{4},\frac{R}{2}]$,
    \[
        \grad f_0(x) = \grad \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x) \cdot (h_1 - h_0(x) ) + (1-\mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x))\cdot \grad h_0(x), 
    \]
    and
    \begin{align*}
        \grad^2 f_0(x) &= \underbrace{\grad^2 \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x) \cdot (h_1 - h_0(x))}_{\mbox{(a)}} - \underbrace{\tp{\grad \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x) \cdot \grad h_0(x)^{\top} +  \grad h_0(x)\cdot \grad \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x)^{\top}}}_{\mbox{(b)}}\\
        &\quad + \underbrace{ \tp{1-\mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x)}\cdot \grad^2 h_0(x)}_{\mbox{(c)}}.
        \end{align*}
    Recall that $LM\geq d$, so it is easy to get $0\preceq \mbox{(c)}\preceq L\cdot \!{Id}_d$. Since 
    \[
        \grad \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x) = \frac{2x}{\frac{R^2}{4} - \frac{R^2}{16}} \cdot q_{\!{mol}}'\tp{\frac{ \|x\|^2- \frac{R^2}{16}}{\frac{R^2}{4} - \frac{R^2}{16}}},
    \]
    we have
    \[
        \mbox{(b)} = \frac{4d \cdot xx^{\top}}{M\tp{\frac{R^2}{4} - \frac{R^2}{16}}} \cdot q_{\!{mol}}'\tp{\frac{ \|x\|^2- \frac{R^2}{16}}{\frac{R^2}{4} - \frac{R^2}{16}}}.
    \]
    % \mn{For $x,y\in \bb R^d$, we can show that $\|x\|\|y\|\!{Id}_d - xy^T\succeq 0$: for any $z\in \bb R^d$,
    % \begin{align*}
    %     &\phantom{{}={}}z^T\tp{\|x\|\|y\|\!{Id}_d - xy^T}z \\
    %     & =\|x\|\|y\|\|z\|^2 - (z^Tx)(y^Tz)\\
    %     &\geq \|x\|\|y\|\|z\|^2 - \|x\|\|y\|\|z\|^2\\
    %     &= 0.
    % \end{align*}}
    Therefore, $-\+O(L)\cdot\!{Id}_d \preceq \mbox{(b)} \preceq \+O(L)\cdot\!{Id}_d$.
    By direct calculation,
    \[
        \grad^2 \mathfrak{g}_{[\frac{R}{4},\frac{R}{2}]}(x) = \frac{4xx^{\top}}{\tp{\frac{R^2}{4} - \frac{R^2}{16}}^2} \cdot q''_{\!{mol}}\tp{\frac{ \|x\|^2- \frac{R^2}{16}}{\frac{R^2}{4} - \frac{R^2}{16}}} + \frac{2\!{Id}_d}{\frac{R^2}{4} - \frac{R^2}{16}} \cdot q'_{\!{mol}}\tp{\frac{ \|x\|^2- \frac{R^2}{16}}{\frac{R^2}{4} - \frac{R^2}{16}}}
    \]
    and 
    \begin{align}
        \abs{h_1 - h_0(x)} &= \abs{\log \frac{1}{\eps} + \frac{d}{2}\log\tp{9\pi R^2} - \log \Gamma\tp{\frac{d}{2}+1} - \frac{d\|x\|^2}{2M} - \frac{d}{2}\log \frac{2\pi M}{d}} \notag\\
        &= \abs{\log \frac{1}{\eps} + \frac{d}{2}\log\frac{9d}{2\eps} - \log \Gamma\tp{\frac{d}{2}+1} - \frac{d\|x\|^2}{2M}} \label{eq:1}
        % &\leq \log \frac{1}{\eps} + \frac{d}{2}\log\tp{9\pi R^2} - \log \Gamma\tp{\frac{d}{2}+1} + \frac{R^2 d}{8M} + \frac{d}{2}\log \frac{2\pi M}{d}.
    \end{align}
    % \htodo{Here we need $R^2=\frac{M}{\eps}\log \frac{M}{\eps}$?}
    From Stirling's formula, we know that for any $d>0$,
    \[
        \log\sqrt{\pi d} + \frac{d}{2}\log \frac{d}{2e} \leq \log \Gamma\tp{\frac{d}{2}+1}\leq \log\sqrt{\pi d} + \frac{d}{2}\log \frac{d}{2e} + 1.
    \]
    % \[
    %     \log \Gamma\tp{\frac{d}{2}+1} \leq \begin{cases}
    %         \log\sqrt{\pi d} + \frac{d}{2}\log \frac{d}{2e} + 1, & d \mbox{ is even}\\
    %         \log \sqrt{\frac{2\pi d}{d-1}} + \frac{d+1}{2}\log \frac{d}{2e} + 1, & d \mbox{ is odd}
    %     \end{cases},
    % \]
    % and 
    % \[
    %     \log \Gamma\tp{\frac{d}{2}+1} \geq \begin{cases}
    %         \log\sqrt{\pi d} + \frac{d}{2}\log \frac{d}{2e} , & d \mbox{ is even}\\
    %         \log \sqrt{\frac{2\pi d}{d-1}} + \frac{d+1}{2}\log \frac{d}{2e} , & d \mbox{ is odd}
    %     \end{cases}.
    % \]
    Back to \Cref{eq:1}, we have
    \begin{align*}
        \abs{h_1 - h_0(x)}&\leq \abs{\log \frac{1}{\eps} + \frac{d}{2}\log\frac{9e}{\eps} - \frac{d\|x\|^2}{2M} -\log\sqrt{\pi d}} + 1 \\
        &\leq \log \frac{1}{\eps} + \frac{d}{2}\log\frac{9e}{\eps} + \frac{dR^2}{8M} + \log\sqrt{\pi d} +1.
    \end{align*}
    Since $LM\geq d$, we have $-\+O(L)\cdot\!{Id}_d \preceq \mbox{(a)}\preceq \+O(L)\cdot\!{Id}_d$.
    
    For $\|x\|\in (R,2R]$, 
    \[
        \grad^2 f_0(x) = \grad^2 \mathfrak{g}_{[R,2R]}(x)(h_0(x)-h_1) + 2\grad \mathfrak{g}_{[R,2R]}(x) \grad h_0(x)^{\top} + \mathfrak{g}_{[R,2R]}(x) \cdot \grad^2 h_0(x).
    \]
    The remaining calculations are similar. %\ctodo{Maybe say more here.}
\end{proof}


\subsection{Perturb the base instance}\label{sec:hardinstance}
We then construct instances via perturbing $\mu_0$. Let $r_1= \sqrt{\frac{d}{L}\log \frac{LM}{d\eps}}$, $r_2=\sqrt{2}r_1$. Let $h_2\defeq h_1 - \gamma$, where $\gamma$ is a value to be determined later.
% \htodo{Assume the value of $\eps,L,M,d$ satisfy $4r_2\leq R$ and $r_1=\Omega(1)$.}

Note that when $\eps<1/32$, we have $4r_2\leq R$. For a point $v\in \bb R^d$ with $\|v\|=\frac{3R}{4}$, let $\mathfrak{g}_v(x) = q_{\!{mol}}\tp{\frac{\|x-v\|^2-r_1^2}{r_2^2-r_1^2}}$ and $f_v(x)=\mathfrak{g}_v(x)f_0(x)+(1-\mathfrak{g}_v(x))h_2$. This means that, outside the ball $\+B_{r_2}(v)$, $f_v\equiv f_0$, and inside the ball $\+B_{r_1}(v)$, $f_v\equiv h_2$. Define density of the distribution $\mu_v$ over $\bb R^d$ as $p_{\mu_v}\propto e^{-f_v}$. Let $Z_v = \int_{\bb R^d} e^{-f_v(x)} \dd x$.

\begin{lemma}\label{lem:gamma}
    There exists a $\gamma>0$ such that the following holds at the same time:
    \begin{itemize}
        \item  $\int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}}  \dd x = 9\eps$;
        %\item $9 \tp{\frac{3R}{r_2}}^d \leq e^{\gamma}\leq 18\tp{\frac{3R}{r_1}}^d $;
        % \item $\eps \leq \DTV(\mu_0,\mu_v)\leq 10\eps$;
        \item $\frac{9\eps e^{h_1}}{\!{vol}(\+B_{r_2})}\le e^\gamma-1 \le \frac{9\eps e^{h_1}}{\!{vol}(\+B_{r_1})}$.
        \item $Z_0\leq Z_v\leq 1+10\eps$.
    \end{itemize}
    % There exists a $\gamma$ with $\eps\abs{h_1-\gamma} \leq ()$, such that $\eps \leq \DTV(\mu_0,\mu_v)\leq 10\eps$ for each $\|v\| = \frac{3R}{4}$. This $\gamma$ also satisfies that $Z_0\leq Z_v\leq 1+10\eps$
\end{lemma}

Before proving the lemma, let us examine the information it brings. Recall that $f_0(x)\equiv h_1$ when $x\in \+B_{r_2}(v)$ and we would like to perturb $h_1$ by amount of $\gamma$ to obtain $f_v$ so that there will be $\Theta(\eps)$ more probability mass in $\+B_{r_2}(v)$. For fixed $r_1$ and $r_2$, the lemma says that the order of $\gamma$ is roughly proportional to $h_1$. 

\begin{proof}[Proof of \Cref{lem:gamma}]
    Consider the value $\int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}}\dd x$. It is continuous and increasing in $\gamma$ when $\gamma\ge 0$. When $\gamma = 0$, $\int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}}\dd x = 0$. When $\gamma \to \infty $, this value goes to $\infty$. So we can find a $\gamma$ such that $\int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}}\dd x = 9\eps$ holds exactly.

    For such a $\gamma$, we have
    \[
        Z_v = \int_{\bb R^d} e^{-f_v(x)} \dd x \leq \int_{\bb R^d} e^{-f_0(x)} \dd x + \int_{\+B_{r_2}(v)} \tp{ e^{-f_v(x)} - e^{-h_1}}\dd x = Z_0+9\eps \leq 1+10\eps.
    \]
    Also
    $$
        Z_v = \int_{\bb R^d} e^{-f_v(x)} \dd x \geq \int_{\bb R^d} e^{-f_0(x)} \dd x = Z_0.
    $$
    
    % Then we caculate $\DTV(\mu_0,\mu_v)$. On one hand, since $\+B(v,r_1)\subseteq \+B(v,r_2)\subseteq \set{x\in \bb R^d:\ \|x\| \in (\frac{R}{2},R]}$,
    % \begin{align*}
    %     \DTV(\mu_0,\mu_v) &= \frac{1}{2}\int_{\bb R^d} \abs{\frac{e^{-f_0(x)}}{Z_0} - \frac{e^{-f_v(x)}}{Z_v}} \dd x \\ 
    %     &\geq \frac{1}{2}\int_{\+B(v,r_2)} \abs{\frac{e^{-f_0(x)}}{Z_0} - \frac{e^{-f_v(x)}}{Z_v}} \dd x \\
    %     &=  \frac{1}{2}\int_{\+B(v,r_2)}  \abs{\frac{e^{-f_0(x)}}{Z_v} - \frac{e^{-f_v(x)}}{Z_v}} - \abs{\frac{e^{-f_0(x)}}{Z_0} -  \frac{e^{-f_0(x)}}{Z_v}}  \dd x  \\
    %     &= \frac{1}{2}\tp{\frac{9\eps}{Z_v} - e^{-h_1}\cdot \abs{\frac{1}{Z_0} - \frac{1}{Z_v}} \cdot \vol\tp{\+B(v,r_2)}} \\
    %     &\geq \eps.
    % \end{align*}

    % On the other hand, \begin{align*}
    %     \DTV(\mu_0,\mu_v) &= \frac{1}{2}\int_{\bb R^d} \abs{\frac{e^{-f_0(x)}}{Z_0} - \frac{e^{-f_v(x)}}{Z_v}} \dd x \\ 
    %     &\leq \frac{1}{2}\int_{\bb R^d }  \abs{\frac{e^{-f_0(x)}}{Z_v} - \frac{e^{-f_v(x)}}{Z_v}} + \abs{\frac{e^{-f_0(x)}}{Z_0} -  \frac{e^{-f_0(x)}}{Z_v}}  \dd x \\
    %     &\leq \frac{1}{2}\tp{\frac{9\eps}{Z_v} + Z_0\cdot \abs{\frac{1}{Z_0} - \frac{1}{Z_v}}}\\
    %     &\leq 10\eps.
    % \end{align*}
    
    It remains to calculate $e^\gamma$. We have that
    \[
        \vol\tp{\+B_{r_1}(v)} \cdot e^{-h_1} \tp{e^\gamma - 1}\leq \int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}}  \dd x =9\eps \leq \vol\tp{\+B_{r_2}(v)} \cdot e^{-h_1} \tp{e^\gamma - 1}.
    \]
\end{proof}

\begin{corollary}\label{cor:gamma-bound}
    For our choice of $h_1$, $r_1$ and $r_2$, it holds that
    \[
        9\tp{\frac{3R}{r_2}}^d \leq e^{\gamma}\leq 18\tp{\frac{3R}{r_1}}^d.
    \]
\end{corollary}
\begin{proof}
    Recall that $e^{h_1}=\eps^{-1}\vol\tp{\+B_{3R}}$ and $\vol\tp{\+B_r} = \frac{\tp{\pi R^2}^{\frac{d}{2}}}{\Gamma\tp{\frac{d}{2}+1}}$. We have
    \[
        e^\gamma-1 \leq  9\tp{\frac{3R}{r_1}}^d \mbox{ and } e^\gamma-1 \geq 9 \tp{\frac{3R}{r_2}}^d.
    \]
    Therefore
    \[
        18\tp{\frac{3R}{r_1}}^d \geq e^\gamma\geq 9 \tp{\frac{3R}{r_2}}^d.
    \]
\end{proof}

\subsection{Properties of the perturbed distributions}
For every $v$ with $\|v\|= \frac{3R}{4}$, we first analyze the smoothness and second moment of the distribution $\mu_v$.

\begin{lemma}\label{lem:moment}
    For $\|v\|=\frac{3R}{4}$, $\E[\mu_v]{\|X\|^2}= \+O\tp{M}$.
\end{lemma}
\begin{proof}
    Direct calculation gives
    \begin{align*}
        \E[\mu_v]{\|X\|^2} & \leq \frac{\E[X\sim \+N\tp{0,\frac{M}{d}\cdot \!{Id}_d}]{\|X\|^2} + \vol (B_{2R})\cdot e^{-h_1}\cdot 4R^2 + \int_{\+B_{r_2}(v)} \tp{e^{-f_v(x)} - e^{-h_1}} \|X\|^2 \dd x}{Z_v} \\
        &\leq \frac{3M + R^2\cdot 9\eps}{Z_v} \leq 24 M.
    \end{align*}
    % \htodo{Here only $\tilde O(M)$. It seems that we cannot guarantee the $O(L)$-smooth of $f_0$ and $O(M)$ second moment of $\mu_v$. Or equivalently, we can choose $M=\frac{M_0}{\log \frac{M_0}{\eps}}$. We require $LM_0\geq d\log\frac{M_0}{\eps}$.}
\end{proof}

\begin{lemma}\label{smooth}
  For $\|v\|=\frac{3R}{4}$, the function $f_v$ is $\+O(L)$-smooth. 
\end{lemma}
\begin{proof}
    We only need to consider those $x\in \+B_{r_2}(v)\setminus \+B_{r_1}(v)$. For such $x$, $f_0(x)=h_1$. Therefore,
    \[
        \grad^2 f_v(x) = \gamma\cdot \grad^2 g_v(x).
    \]
    Note that
    \[
        \grad g_v(x) = \frac{2(x-v)}{r_2^2-r_1^2}\cdot q_{\!{mol}}'\tp{\frac{\|x-v\|^2-r_1^2}{r_2^2-r_1^2}}
    \]
    and
    \[
        \grad^2 g_v(x) = \frac{4(x-v)(x-v)^{\top}}{\tp{r_2^2-r_1^2}^2}\cdot q''_{\!{mol}}\tp{y=\frac{\|x-v\|^2-r_1^2}{r_2^2-r_1^2}} + \frac{2\!{Id}_d}{r_2^2-r_1^2}\cdot q'_{\!{mol}}\tp{\frac{\|x-v\|^2-r_1^2}{r_2^2-r_1^2}}.
    \]
    From \Cref{cor:gamma-bound}, 
    \[
        \gamma \leq \log 18 + \frac{d}{2}\log\frac{9LM}{\eps d} - \frac{d}{2}\log\log \frac{LM}{d\eps}.
    \]
    Therefore, $-\+O(L)\cdot\!{Id}_d \preceq \grad^2 f_v(x) \preceq \+O(L)\cdot\!{Id}_d $.
\end{proof}

We remark that the constants hidden in the $\+O(\cdot)$ in the above two lemmas are universal constants and do not depend on $d$ and $\eps$. 


\begin{lemma}\label{lem:TV}
    For $u,v\in \bb R^d$ such that $\|v\|=\|u\|=\frac{3R}{4}$ and $\+B_{r_2}(u)\cap \+B_{r_2}(v)=\emptyset$, $\DTV\tp{\mu_u,\mu_v}> 4\eps$.
\end{lemma}
\begin{proof}
    By the definition of total variation distance, 
    \begin{align*}
        \DTV(\mu_u,\mu_v) & = \frac{1}{2}\int_{\bb R^d} \abs{\frac{e^{-f_u(x)}}{Z_u} - \frac{e^{-f_v(x)}}{Z_v}} \dd x \\
        \mr{$Z_u=Z_v$} & =\frac{1}{2Z_v} \tp{\int_{\+B_{r_2}(u)}\abs{e^{-f_u(x)} - e^{-h_1}} \dd x + \int_{\+B_{r_2}(v)}\abs{e^{-f_v(x) }- e^{-h_1}} \dd x} \\
        &= \frac{9\eps}{Z_v} > 4\eps.
    \end{align*}
\end{proof}

\subsection{The number of disjoint $\+B_{r_2}(v)$'s}

\begin{lemma}\label{lem:disjointcap}
    Suppose $d\geq 5$. There exist $n=\frac{(d-1)\sqrt{d-2}}{2}\cdot \tp{\frac{3R}{8\sqrt{2}r_2}}^{d-1}$ vectors $v_1,v_2,\dots,v_n \in \bb R^d$ such that
    \begin{itemize}
        \item for each $i\in[n]$, $\|v_i\| = \frac{3R}{4}$;
        \item for each $i,j\in [n]$, if $i\ne j$, then $\+B_{r_2}(v_i)\cap \+B_{r_2}(v_j)=\emptyset$.
    \end{itemize}
\end{lemma}
\begin{proof}
    Let $S$ be the sphere $\set{x\in \bb R^d: \|x\| = \frac{3R}{4}}$. For two vectors $x,y\in \bb R^d$, let $\theta(x,y)$ represent the angle between $x$ and $y$. We first try to find $n$ disjoint caps $C_1,C_2,\dots,C_n$ on $S$. Denoting $v_i$ as the central vector of cap $C_i$, $C_i=\set{x\in \bb R^d: \|x\|=\frac{3R}{4}, \cos(\theta(x,v_i))\geq \ell}$ with $\ell=\frac{\sqrt{(\tp{\frac{3R}{4}}^2-2r_2^2)}}{\frac{3R}{4}}$. 
    
    In contrast, suppose we can only find $n'<\frac{(d-2)^{\frac{3}{2}}}{2}\cdot \tp{\frac{3R}{8\sqrt{2}r_2}}^{d-1}$ such disjoint caps $\set{C_i}_{1\leq i\leq n'}$ with central vectors $\set{v_i}_{1\leq i\leq n'}$. Then for any $w\in S$, there exist $i\in[n']$ and $x\in S$ such that $\cos(\theta(x,v_i))\geq \ell$ and $\cos(\theta(x,w))\geq \ell$. Otherwise we can find a new cap with center $w$.
    
    Via \Cref{lem:cos}, we know that $\cos(\theta(w,v_i))\geq \ell^2 - \tp{1-\ell^2}  \ell'$ with $\ell'=\frac{\tp{\frac{3R}{4}}^2-4r_2^2}{\tp{\frac{3R}{4}}^2}$. 
    This means we can find $n'$ larger caps with central vectors $\set{v_i}_{1\leq i\leq n'}$ and angle $\arccos(\ell')$ to cover the sphere.
    From \cite{L11}, however, the area of a cap with angle $\theta = \arccos(\ell')$ is $\frac{\Gamma\tp{\frac{d-1}{2}}}{\sqrt{\pi}\Gamma\tp{\frac{d}{2}}} \int_{0}^{\theta} \sin^{d-2}(\phi)\d \phi$ times of the total sphere. We have
    % \ctodo{Find the constant $c$.}
    \[
         \int_{0}^{\theta} \sin^{d-2}(\phi)\d \phi \leq \frac{1}{\ell'} \int_{0}^{\theta} \sin^{d-2}(\phi)\cos (\phi)\d \phi = \frac{1}{\ell'} \int_0^{\sin(\theta)} s^{d-2} \d s = \frac{1}{\ell'} \frac{\tp{\sin \theta}^{d-1}}{d-1}.
    \]
    Since $\sin \theta = \sqrt{1-\tp{\ell'}^2}\leq \frac{2\sqrt{2}r_2}{\frac{3R}{4}}$, the ratio between the area of this larger cap and the sphere can be bounded by
    \begin{align*}
        \frac{\Gamma\tp{\frac{d-1}{2}}}{\sqrt{\pi}\Gamma\tp{\frac{d}{2}}} \int_{0}^{\theta} \sin^{d-2}(\phi)\d \phi & \leq \frac{1}{\ell' (d-1)}\cdot \frac{\Gamma\tp{\frac{d-1}{2}}}{\sqrt{\pi}\Gamma\tp{\frac{d}{2}}}\cdot \tp{\frac{2\sqrt{2}r_2}{\frac{3R}{4}}}^{d-1} \\
        \mr{$R\geq 4r_2$}
        &\leq \frac{9}{5\sqrt{\pi}(d-1)} \cdot \frac{\Gamma\tp{\frac{d-1}{2}}}{\Gamma\tp{\frac{d}{2}}} \cdot \tp{\frac{8\sqrt{2}r_2}{3R}}^{d-1} \\
        \mr{Gautschi's inequality}
        &\leq \frac{9\sqrt{2}}{5\sqrt{\pi}}\cdot \frac{1}{(d-1)\sqrt{d-2}}\cdot \tp{\frac{8\sqrt{2}r_2}{3R}}^{d-1}\\
        &\leq \frac{2}{(d-1)\sqrt{d-2}} \tp{\frac{8\sqrt{2}r_2}{3R}}^{d-1}.
    \end{align*}
    
    % So there exists some universal constant $c'$ such that the ratio between the area of this larger cap and the sphere is no larger than $\tp{\frac{c' r_2}{R}}^{d-1}$. 
    % By choosing $c= \frac{1}{c'}$, 
    This will lead to a conflict since $n'$ such caps cannot cover the sphere. Therefore, we can find $n= \frac{(d-1)\sqrt{d-2}}{2}\cdot \tp{\frac{3R}{8\sqrt{2}r_2}}^{d-1}$ such $C_i$'s.
    
    Furthermore, from \Cref{lem:cosinBall}, $\+B_{r_2}(v_i)\cap \+B_{r_2}(v_j)=\emptyset$.
\end{proof}

\subsection{Proof of the lower bound}
\begin{theorem}[\Cref{thm:main} restated]
    % There exist a universal constant $C>0$ such that 
    For any $L,M>0$ satisfying $LM\ge d$ and for any $\eps\in(0,1/32)$, $d\geq 5$, if a sampling algorithm $\+A$ always terminates within 
    \[
        \frac{\eps (d-2)^{\frac{3}{2}}}{8}\cdot \tp{\frac{9}{256} \cdot \frac{LM}{d\eps} \cdot \frac{1}{\log \frac{LM}{d\eps}}}^{\frac{d-1}{2}}
        % \frac{\eps}{4}\cdot \tp{\frac{C\cdot LM}{2 d\eps} \cdot \frac{1}{\log \frac{LM}{d\eps}}}^{\frac{d-1}{2}}
        % % \approx \frac{\eps}{4}\exp\set{\frac{d}{2}\cdot \Omega\tp{\log \frac{LM}{d\eps}}}
    \]
    queries on every input instance in $\@D_{L,M}$, then there must exist some distribution $\mu\in \@D_{L,M}$ such that when the underlying instance is $\mu$, the distribution of $\+A$'s output, denoted as $\tilde \mu$, is $\eps$ away from $\mu$ in total variation distance, i.e., $\DTV(\mu,\tilde \mu)\geq \eps$.
\end{theorem}
\begin{proof}
    Let $v_1,v_2,\dots,v_n$ be the $n$ vectors in \Cref{lem:disjointcap}. For each $i\in [n]$, construct a distribution $\mu_{v_i}$ with density $p_i \propto e^{-f_{v_i}}$ as described in \Cref{sec:hardinstance}. From the discussion in previous sections, we can assume that every $\mu_{v_i}$ as well as the base instance are $L$-log-smooth and have second moment at most $M$. For simplicity, we write $\mu_{v_i}$ as $\mu_i$.

    We use $\Pr[\mu]{\cdot}$ and $\E[\mu]{\cdot}$ to denote the probability and expectation when the underlying instance is some distribution $\mu$. Let $\+E_{k,i}$ be the event that the algorithm $\+A$ queries a value in zone $\+B_{r_2}(v_i)$ in the $k$-th query and it is the first time that $\+A$ queries the points in $\+B_{r_2}(v_i)$. If the algorithm terminates before the $k$-th query, we regard $\+E_{k,i}$ as an impossible event.

    Assume $\+A$ always terminates in $N$ queries for some 
    $$
        N< \frac{\eps (d-2)^{\frac{3}{2}}}{8}\cdot \tp{\frac{9}{256}\cdot \frac{LM}{d\eps} \cdot \frac{1}{\log \frac{LM}{d\eps}}}^{\frac{d-1}{2}} < \frac{\eps}{4}\cdot \frac{(d-1)\sqrt{d-2}}{2}\cdot \tp{\frac{3R}{8\sqrt{2}r_2}}^{d-1} = \frac{\eps n}{4}.
    $$ 
    Let $\+E_{i}$ be the event that $\+A$ queries the points in $\+B_{r_2}(v_i)$ at least once. Then
    \begin{align*}
        \sum_{i=1}^n \Pr[\mu_0]{\+E_i}& = \sum_{i=1}^n \sum_{k=1}^N \Pr[\mu_0]{\+E_{k,i}} = \sum_{k=1}^N \sum_{i=1}^n \Pr[\mu_0]{\+E_{k,i}} \leq N<\frac{\eps n}{4}.
    \end{align*}
    So there exists some $i_0,j_0\in[n]$ and $i_0\neq j_0$ such that $\Pr[\mu_0]{\+E_{i_0}}<\frac{\eps}{3}$ and $\Pr[\mu_0]{\+E_{j_0}}<\frac{\eps}{3}$. Otherwise $\sum_{i=1}^n \Pr[\mu_0]{\+E_i}\geq \frac{\eps(n-1)}{3}\geq \frac{\eps n}{4}$ since $n\geq 4$ when $d\geq 5$. From union bound, $\Pr[\mu_0]{\ol{\+E_{i_0}}\cap \ol{\+E_{j_0}}}> 1-\frac{2\eps}{3}$. 
    
    We know that on $\bb R^d\setminus \+B_{r_2}(v_i)$, $f_{v_i}(x)=f_0(x)$ for each $i\in[n]$. Therefore, via coupling arguments,
    \[
        \Pr[\mu_{i_0}]{\ol{\+E_{i_0}}\cap \ol{\+E_{j_0}}} = \Pr[\mu_{j_0}]{\ol{\+E_{i_0}}\cap \ol{\+E_{j_0}}} = \Pr[\mu_0]{\ol{\+E_{i_0}}\cap \ol{\+E_{j_0}}}> 1-\frac{2\eps}{3}.
    \]

    Let $\+E=\+E_{i_0}\cup \+E_{j_0}$. Let $\tilde \mu_0^{\ol{\+E}}$ be the output distribution of $\+A$ with input distribution $\mu_0$ when $\ol{\+E}$ happens. 
    Since
    \begin{align*}
        4\eps\leq \DTV(\mu_{i_0},\mu_{j_0}) \leq \DTV(\mu_{i_0},\tilde \mu_0^{\ol{\+E}}) + \DTV(\mu_{j_0},\tilde \mu_0^{\ol{\+E}}),
    \end{align*}
    we have either $\DTV(\mu_{i_0},\tilde \mu_0^{\ol{\+E}})>2\eps$ or $\DTV(\mu_{j_0},\tilde \mu_0^{\ol{\+E}})>2\eps$. W.l.o.g., assume $\DTV(\mu_{i_0},\tilde \mu_0^{\ol{\+E}})>2\eps$. Assume the output distribution of $\+A$ is $\tilde \mu_{i_0}$ when the input is $\mu_{i_0}$. Let $\tilde \mu_{i_0}^{\+E}$ and $\tilde \mu_{i_0}^{\ol{\+E}}$ be $\tilde \mu_{i_0}$ conditioned on $\+E$ and $\ol{\+E}$ respectively and denote their density functions as $\tilde p_{i_0}^{\+E}$, $\tilde p_{i_0}^{\ol{\+E}}$ and $\tilde p_{i_0}$. Then $\tilde \mu_{i_0}^{\ol{\+E}}=\tilde \mu_0^{\ol{\+E}}$. 
    Then we have
    \begin{align*}
        \DTV(\mu_{i_0},\tilde \mu_{i_0}) &= \frac{1}{2}\int_{\bb R^d} \abs{p_{i_0}(x) - \tilde p_{i_0} (x)} \dd x\\
        &=\frac{1}{2}\int_{\bb R^d} \abs{p_{i_0}(x) - \Pr[\mu_{i_0}]{\+E}\tilde p_{i_0}^{\+E}(x) - \Pr[\mu_{i_0}]{\ol{\+E}}\tilde p_{i_0}^{\ol{\+E}}(x)} \dd x \\
        &\geq \Pr[\mu_{i_0}]{\ol{\+E}}\cdot \frac{1}{2} \int_{\bb R^d}\abs{p_{i_0}(x) - \tilde p_{i_0}^{\ol{\+E}}(x)} \dd x  - \Pr[\mu_{i_0}]{\+E}\cdot \frac{1}{2} \int_{\bb R^d}\abs{p_{i_0}(x) - \tilde p_{i_0}^{\+E}(x)} \dd x \\
        & = \Pr[\mu_{i_0}]{\ol{\+E}}\cdot \DTV(\mu_{i_0}, \tilde \mu_{i_0}^{\ol{\+E}}) - \Pr[\mu_{i_0}]{\+E}\cdot \DTV(\mu_{i_0}, \tilde \mu_{i_0}^{\+E}) \\
        & = \Pr[\mu_{i_0}]{\ol{\+E}}\cdot \DTV(\mu_{i_0}, \tilde \mu^{\ol{\+E}}_0) - \Pr[\mu_{i_0}]{\+E}\cdot \DTV(\mu_{i_0}, \tilde \mu_{i_0}^{\+E}) \\
        &\geq \tp{1-\frac{2\eps}{3}}\cdot 2\eps - \frac{2\eps}{3}\cdot 1\\
        &>\eps.
    \end{align*}
    This means, on instance $\mu_{i_0}$, the algorithm $\+A$ will fail to output a distribution which is $\eps$-close to $\mu_{i_0}$ in total variation distance.
\end{proof}


