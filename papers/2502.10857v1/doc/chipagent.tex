\section{ChipLlama-powered Agent}

\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.96\linewidth]{figs/figure2.pdf} 
    \caption{Overview of the ChipLlama-powered agent for task planning and EDA script generation. 
    } 
    \label{fig:ChipAgent}
\end{figure}

For an autonomous agent for EDA flow automation, users can provide the EDA task in natural language, and the agent will generate executable scripts to complete the EDA task via an LLM.
To guarantee the performance and reliability of the overall flow, we introduce the expert LLM, ChipLlama, as the ``brain'' of the single-agent system.  
Furthermore, we apply few-shot CoT prompts to the single-agent system to enhance the reasoning ability for EDA flow automation as shown in \Cref{fig:ChipAgent}.

\subsection{ChipLlama for EDA Flow Automation}

ChipLlama models are expert LLMs fine-tuned based on Llama3~\cite{dubey2024llama3} via the hybrid instruction tuning.
The capability of the ChipLlama models determines the performance of EDA task-resolving.
Previous expert LLMs for EDA flow automation (e.g. AutoMage2~\cite{wu2024chateda}) only show reliable performance on a single platform.
However, there are various EDA platforms in real industrial scenarios.
To address this challenge, we enhance the generalization ability of LLMs by broadening their understanding of the entire EDA flow, beyond mere simple tool usage.

The invocation of EDA tools is dependent on maintaining the correct logical order in contrast to other fields where tool usage may not require a strict logical sequence. 
This dependency arises from the nature of EDA processes, which consist of interconnected stages such as logic synthesis, floorplanning, placement, and routing. 
Each stage must be executed sequentially, relying on precise inputs from preceding steps.
Therefore, besides domain-specific knowledge for EDA tool usage, LLMs must exhibit advanced logical reasoning and tool manipulation (via code) skills.

Instruction tuning is founded on the principle that by engaging in supervised learning driven by task-specific instructions, LLMs can acquire the skill to adhere to directives for tasks they have not previously encountered. 
This facilitates the application of LLMs to EDA tasks utilizing datasets from domains beyond EDA. 
Instruction datasets from various fields provide a wealth of directives, promoting the ability of models to develop versatile problem-solving strategies by correlating inputs with outputs.
Consequently, as illustrated in \Cref{fig:hit}, we utilize hybrid instruction tuning for ChipLlama models, which integrates three specially curated datasets including MathInstruct~\cite{yu2023metamath}, CodeInstruct~\cite{wei2023magicoder}, and EDAInstruct~\cite{wu2024chateda}.  
Hybrid instruction tuning fosters LLMs' deep understanding of sophisticated EDA flow automation, which can be generalized to various EDA platforms and enhance the performance and reliability applying to a single EDA platform.
We show more details of hybrid instruction tuning in \Cref{sec:appendix1}.

\subsection{Few-shot CoT Prompting}
\label{sec:ChipAgent-CoT}

\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.96\linewidth]{figs/figure3.pdf} 
    \caption{Overview of hybrid instruction tuning.}
    \label{fig:hit}
\end{figure}

Backend design involves complex procedures to interact with various EDA tools.
For example, achieving timing closure has to optimize cell placement, clock trees, and signal routing iteratively until satisfying performance is obtained.
In this sense, it is difficult for LLMs to generate a script that finishes the job directly~\cite{wu2024chateda}.
The enhancement for LLMs in such script generation can be achieved through the application of CoT prompting~\cite{wei2022cot}.
As illustrated in \Cref{fig:ChipAgent}, after receiving user instruction and API document, ChipLlama models start to plan how to complete the task in several steps following the CoT prompt and then generate the corresponding script according to the planning steps. 

Let's first focus on the standard prompt for EDA task-solving without the task planning phase. 
For standard prompting, the objective is to maximize the probability of the script $\mathcal{A}$ given an EDA task $\mathcal{Q}$, a prompt $\mathcal{T}$, and the probabilistic LLM $p_{\mathcal{L}}$ representing the utilized ChipLlama model. The probability is expressed as:
\begin{equation}
    p(\mathcal{A}|\mathcal{Q},\mathcal{T}) = \prod \limits_{i=0}^{|\mathcal{A}|} p_{\mathcal{L}}(a_{i}|\mathcal{Q},\mathcal{T},\mathcal{A}_{<i}),
    \label{Eq:standard_prompt}
\end{equation}
where $\mathcal{A}_{<i} = \{a_1, a_2, \cdots a_{i-1}\}$, $a_{i}$ represents the $i$-th token and $|\mathcal{A}|$ denotes the length of the EDA script $\mathcal{A}$. 

\begin{figure}[tb!]
    \centering
    \includegraphics[width=0.96\linewidth]{figs/figure4.pdf} 
    \caption{Few-shot CoT prompt template utilized in ChipLlama-powered agent.}
    \label{fig:cot_prompt}
\end{figure}

\begin{figure*}[tb!]
    \centering
    \includegraphics[width=0.98\linewidth]{figs/figure1.pdf} 
    \caption{Overview of EDAid, the multi-agent collaboration system. Given an EDA task, multiple agents (including divergent-thoughts agents (role $R_{0}$) and a decision-making agent (role $R_{1}$)) collaborate to generate the EDA script. Finally, the generated EDA script will automate the EDA flow interfacing the EDA tools via APIs.}
% Description
    \label{fig:multi_agent_cosys}
\end{figure*}

Zero-shot CoT prompting is a straightforward concept that incorporates a sequence of task planning steps into the initial prompt.
In this scenario, $p_{L_{0}}$ processes $\mathcal{Q}$ and $\mathcal{T}$ to generate a models of planning steps $\mathcal{C}$ and then generate the EDA script $\mathcal{A}$. 
In addressing $\mathcal{Q}$, articulated in natural language, the expert LLM from the ChipLlama models dissects it into a sequential set of steps using $\mathcal{V}$ as per the guidelines outlined in the API document within $\mathcal{T}$. 
This decomposition facilitates streamlined handling through the utilization of EDA tools. 
Furthermore, meticulous determination of parameters required at each step occurs during the task planning phase, minimizing the potential for erroneous parameter usage in EDA script generation. 
Following the task planning phase, structured steps $\mathcal{C}$ are formulated, enhancing the efficient orchestration of the intricate EDA task. 
Each step is executable through the corresponding APIs of the EDA tools.
Subsequently, LLMs can formulate the script $\mathcal{A}$ to invoke these APIs for automating the EDA flow.
Therefore, \Cref{Eq:standard_prompt} can be modified to: 
\begin{equation}
    p(\mathcal{A}\mid\mathcal{Q},\mathcal{T}) = p(\mathcal{A}\mid\mathcal{Q},\mathcal{T},\mathcal{C})p(\mathcal{C}\mid\mathcal{Q},\mathcal{T}),
    \label{Eq:zero-shot_CoT}
\end{equation}
where $p(\mathcal{A}\mid\mathcal{Q},\mathcal{T},\mathcal{C})$ and  $p(\mathcal{C}\mid\mathcal{Q},\mathcal{T})$ are defined as follows:
\begin{align}
    p(\mathcal{C}\mid\mathcal{Q},\mathcal{T}) &= \prod \limits_{i=0}^{|\mathcal{C}|} p_{\mathcal{L}}(c_{i}\mid\mathcal{Q},\mathcal{T},\mathcal{C}_{<i}),
    \label{Eq:zero-shot_CoT_step1} \\
    p(\mathcal{A}\mid\mathcal{Q},\mathcal{T},\mathcal{C}) &= \prod \limits_{i=0}^{|\mathcal{A}|} p_{\mathcal{L}}(a_{i}\mid\mathcal{Q},\mathcal{T},\mathcal{C},\mathcal{A}_{<i}).
    \label{Eq:zero-shot_CoT_step2}
\end{align}
Here, $\mathcal{C}_{<i} = \{c_1, c_2, \cdots c_{i-1}\}$.
$c_{i}$ and $|\mathcal{C}|$ indicate the $i$-th token and the length of the task planning steps, respectively. 
Zero-shot CoT prompt is provided to guide LLMs in generating task planning steps $\mathcal{C}$ before generating the EDA script $\mathcal{A}$.

Few-shot CoT prompting merges the paradigms of in-context learning with zero-shot CoT prompting to enhance performance on complex EDA tasks that necessitate planning guidelines for resolution. 
In few-shot CoT scenario, $\mathcal{T} = {(\mathcal{Q}_{i}, \mathcal{C}_{i}, \mathcal{A}_{i})}^{\mathcal{N}}_{i=1}$, which consists of $\mathcal{N}$ instances of $(\mathcal{Q}, \mathcal{C}, \mathcal{A})$ tuple. 
For an instance $(\mathcal{Q}, \mathcal{C}, \mathcal{A})$, this instance serves as a guide for resolving the EDA task.
Initially, it directs LLMs to decompose the EDA task $\mathcal{Q}$ according to the API document.
Following the decomposition steps, encompassing logic synthesis, floorplan creation, placement, clock tree synthesis (CTS), routing, and other relevant processes, is generated within the context of $\mathcal{C}$.
Ultimately, the instance guides LLMs on generating the EDA script $\mathcal{A}$ based on the decomposed steps $\mathcal{C}$.
As shown in \Cref{fig:cot_prompt}, a few-shot CoT prompt is provided to guide LLMs on how to generate task planning steps $\mathcal{C}$ and the EDA script $\mathcal{A}$ following previous EDA tool usage demos.

LLMs can acquire the skills to plan for an EDA task and generate the corresponding script by learning from a set of $\mathcal{N}$ instances in a few-shot CoT prompt $\mathcal{T}$. 
Moreover, consider the scenario where a design team has acquired a brand new EDA tool.
By providing ChipLlama models with brand new EDA APIs, they can still draw knowledge for EDA flow automation from few-shot CoT prompts.
