\section{Related Work}
\subsection{Cross-Modal Retrieval}
% with representatives like cross-attention **Vaswani et al., "Attention Is All You Need"** and similarity graph **Kipf et al., "Variational Autoencoders for Non-Linear Dimensionality Reduction"**,
Cross-modal retrieval (CMR) aims to search the most relevant items across different modalities in response to query modality. The core of CMR is to minimize the semantic discrepancies by projecting different modalities into a common comparable space, wherein the matched items manifest higher similarity or closer feature distance and vice versa. Current efforts, from the perspective of similarity calculation, can be roughly classified into two categories: 1) Coarse-grained measurement **Wang et al., "Deep Learning for Content-Based Image Retrieval"** ____, which represents an efficient solution with the key idea of associating the correspondence holistically among features extracted by distinct modality-specific encoders. 2) Fine-grained measurement **Koch et al., "Siamese Neural Networks for One-Shot Image Recognition"** ____, which focuses on assessing the semantic relationships at a more granular level to learn and reason latent alignments between fragments. Unfortunately, the promising performance of all these methods relies heavily on an implicit assumption that all training data pairs are correctly matched while neglecting the presence of NC. Such NC inevitably undermines the alignments and complicates the accurate measurement of similarity, ultimately leading to inferior performance.

% by well-designed consistency interactions, 
%, which is often introduced due to the extensive data collection and annotation expenses
\subsection{Noisy Correspondence Learning}
% , which, recent years, has been widely explored in multi-modal tasks, including image-text matching **Andreas et al., "Deep Compositional Question Answering"**, multi-view clustering **Dong et al., "Joint Unsupervised Domain Adaptation for Multi-Modal Learning"**, image captioning **Rennie et al., "Self-Critical Sequence Training for Image Captioning"**, and infrared re-identification ____.
Noisy correspondence learning refers to noise-tolerant approaches well-designed to effectively mitigate the adverse impacts caused by mismatches among dataset. Unlike traditional category-level mistaken annotations, this instance-level semantic inconsistency, first recognized as a new paradigm of noisy labels in **Batra et al., "What Matters in Unsupervised Face Image Alignment"**, significantly affects the performance of retrieval models. Thus, some prior attempts ____ employ the small-loss criterion ____, to identify matched pairs from the corrupted datasets and subsequently rectify soft correspondence labels for those mismatches. Following this, several works ____ introduce novel criteria to enable more fine-grained data division, such as inconsistent predictions **Kato et al., "Unsupervised Cross-Modal Retrieval through Contrastive Learning"** and uncertainty ____. To avoid inaccurate label predictions, some approaches ____ aim to refine alignments through alternative strategies like rematched mismatches **Kim et al., "Learning Robust Representations via Adversarial Training with Multiple Forms of Corruptions"** and pseudo captions ____. Besides these methods based data sanitized, other efforts ____ retort to robust loss functions to adaptively downweight the contributions of mismatches, e.g., evidential loss **Jiang et al., "Evidential Deep Learning for Noisy Correspondence Learning"**, complementary contrast loss **Wang et al., "Complementary Contrastive Learning for Multi-Modal Retrieval"**, and active complementary loss _____. Recently, some works ____ utilize the intrinsic properties observed within data to estimate accurate soft correspondence labels. However, they all neglect the intra-modal relations, which is significantly crucial for accurately identify true correspondences.