\section{Related Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Encoder-Decoder Architectures}

The encoder-decoder paradigm has been pivotal in advancing image segmentation tasks. UNet++ ____ enhanced this framework by introducing nested and dense skip pathways, effectively bridging semantic gaps between encoder and decoder features and improving segmentation accuracy through deep supervision. This indicates an improved feature flow among the different stages of the model compared to the original UNet ____. Additionally, UNet++ incorporates a pruned decoder to reduce the number of parameters, enhancing computational efficiency.

Expanding upon traditional encoder-decoder frameworks, ERFNet ____ is designed to deliver high accuracy with reduced computational complexity. ERFNet utilizes factorized convolutions and residual connections to streamline the network, making it suitable for applications such as autonomous driving and robotics where real-time processing is essential. Similarly, DFANet ____ introduces a dual attention mechanism that captures both spatial and channel-wise dependencies, enhancing feature representation and improving performance in semantic segmentation and object detection tasks. DFANet achieves a balance between speed and segmentation performance by aggregating discriminative features through a lightweight backbone and multi-scale feature propagation.

Inspired by enhanced feature learning, Deep Smoke Segmentation (DSS) ____ employs a dual-path encoder-decoder structure based on fully convolutional networks, specifically designed for smoke segmentation. This architecture achieves good performance; however, the parameter count remains relatively high. Similarly, Frizzi et al. ____ developed a convolutional neural network using VGG architectures with multiple kernel sizes to capture both global context and fine spatial details. This approach enhances segmentation performance across diverse datasets by effectively handling the dynamic and amorphous nature of smoke plumes, though it results in significant parameter counts.

To comprehensively extract global context features, attention-based mechanisms have been integrated into encoder-decoder architectures. Attention UNet ____ incorporates attention gates into the UNet architecture, enabling the model to focus on relevant target structures and thereby improve segmentation accuracy. This selective focus helps in better delineating smoke regions from complex backgrounds. Additionally, CGNet ____ introduces attention modules within a Context Guided Network framework, prioritizing salient features for efficient semantic segmentation on mobile devices. These attention mechanisms enhance the model's ability to discern important features, thereby improving overall segmentation performance.

More recently, MobileViTv2 ____ introduces a hybrid approach that combines convolutions with Vision Transformers to enhance feature representation for semantic segmentation tasks. By addressing the latency issues commonly associated with multi-headed self-attention (MHA) mechanisms, MobileViTv2 employs a separable self-attention mechanism with linear complexity. This improvement makes the model more practical for resource-constrained environments while maintaining competitive segmentation performance.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Lightweight Segmentation Models}

Segmentation in GPU-constrained environments necessitates lightweight models that balance accuracy with computational efficiency. Several architectures have been developed to optimize computational resources through innovative techniques. MobileNet ____, for instance, employs depthwise separable convolutions to reduce the number of parameters and computational load, making it suitable for mobile and embedded applications. Similarly, ShuffleNet ____ introduces pointwise group convolutions and channel shuffle operations to achieve high efficiency without significant accuracy loss. EfficientNet ____ utilizes a compound scaling method that uniformly scales network depth, width, and resolution, providing a family of models that offer a balance between performance and efficiency.

Building upon these lightweight foundations, UNeXt-S ____ is another lightweight model that has shown promise in medical image segmentation by incorporating efficient convolutional operations and attention mechanisms. Although these models were not initially designed specifically for smoke segmentation, their emphasis on computational efficiency makes them suitable candidates for efficient applications in this domain.

MALUNet ____ and LEDNet ____ exemplify the advancement of lightweight segmentation models tailored for specific tasks. MALUNet introduces a lightweight architecture designed for skin lesion segmentation by integrating four specialized modules: Dilated Gated Attention (DGA), External Attention (IEA), Channel Attention Block (CAB), and Spatial Attention Block (SAB). These modules collectively enable the network to efficiently extract and fuse both global and local features while significantly reducing the number of parameters and computational complexity. By adopting a U-shape architecture, MALUNet achieves competitive segmentation performance with minimal resource requirements, making it suitable for deployment in resource-constrained clinical environments.

LEDNet further refines lightweight segmentation by employing an asymmetric encoder-decoder architecture. It utilizes channel split and shuffle operations within residual blocks to minimize computational costs. Additionally, an Attention Pyramid Network (APN) is integrated into the decoder to enhance segmentation accuracy without increasing model complexity. This design ensures that LEDNet remains highly efficient, making it ideal for real-time applications on mobile devices where computational resources are limited.

Recent advancements have specifically targeted the smoke segmentation task with a focus on enhancing parameter efficiency. Yuan et al. ____ introduced a refined lightweight model optimized for efficient smoke segmentation. This model integrates attention mechanisms to efficiently extract salient features while minimizing computational demands, effectively leveraging the strengths of both lightweight architectures and attention mechanisms to improve performance on smoke-related tasks.

Despite advances in efficient models, evaluating their performance is limited by the scarcity of diverse smoke segmentation datasets. Many studies report good results on synthetic data or specific scenarios like fire-smoke segmentation, but the limited diversity and size of current datasets impede comprehensive assessment of model generalizability. Expanding and diversifying smoke-related datasets to include complex environments such as quarry smoke is essential. This will enable the development and validation of models that can generalize across varied environments, enhancing the robustness and applicability of smoke segmentation techniques in practical applications.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[htbp]
    \centering
    % Left Column: Model Architecture (Subplot a)
    \begin{minipage}{0.45\linewidth}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\linewidth]{fig/architecture_overview.eps}
            \caption{Model Architecture}
            \label{fig:arch_overview}
        \end{subfigure}
    \end{minipage}
    \hfill
    % Right Column: Multiview Module (Subplot b) and Multiscale Module (Subplot c)
    \begin{minipage}{0.50\linewidth}
        \centering
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\linewidth]{fig/multiscale_module.eps}
            \caption{Multiscale Module}
            \label{fig:multiscale_module}
        \end{subfigure}
        
        \vspace{0.5cm} % Adjust vertical space between subplots
        
        \begin{subfigure}[b]{\linewidth}
            \centering
            \includegraphics[width=\linewidth]{fig/multiview_module.eps}
            \caption{Multiview Module}
            \label{fig:multiview_module}
        \end{subfigure}
    \end{minipage}
    
    \caption{Overview of SmokeNet's Architecture. (a) The overall model architecture integrating multiscale convolutions and multiview attention mechanisms.  (b) The Multiscale Module capturing spatial information at various scales for accurate smoke segmentation.  (c) The Multiview Module enhancing feature refinement through attention mechanisms.}
    \label{fig:combined_architecture}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%