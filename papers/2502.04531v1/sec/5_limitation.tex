\section{Limitations}

Our primary focus in this work is on predicting placement poses. However, challenges remain in executing the full pick-and-place task with the same level of generality. Not every stable grasp of an object can be used to place it at a specific pose, and performing rejection sampling in real-world scenarios can be both difficult and time-consuming. Nonetheless, we believe our synthetic dataset and evaluation pipeline provide a strong foundation for advancing in this direction by enabling the generation of training data for an end-to-end pick-and-place model applicable to a wide range of real-world placement tasks.

While our approach improves precision in placement pose prediction, it is still limited by the accuracy of the point clouds it receives as input. Completing placement tasks that require high precision can be challenging with imperfect point cloud data. Recent advances in depth estimation from RGB images show promise in addressing this issue, as does continued progress in sensor quality. Another promising approach is implementing a policy that uses force/torque feedback to refine the final stage of placement. Similarly to the previous point, we believe our dataset and simulation pipeline provides a strong foundation for tackling this challenge by generating data for training reactive placement-execution policies.


The approach we propose does not include language conditioning in the low-level pose prediction model. As a result, we cannot distinguish between different types of placements at the same location. However, given the architecture of the low-level model, adding a language-conditioning input is straightforward. Our synthetic data generation pipeline is well-suited for this scenario, as it allows for the automatic addition of language conditioning to different placement types. Additionally, an LLM can be used to enhance diversity in language-conditioning data.
