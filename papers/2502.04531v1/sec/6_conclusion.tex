\section{Conclusion}

In this work, we presented a general pipeline for performing a wide range of object placement tasks using a robotic arm. We proposed a two-part framework consisting of a high-level module that determines potential placement locations and a low-level module that predicts fine placement poses. The core idea of our approach is to leverage a VLM to propose placement locations, allowing the low-level pose prediction model to focus only on the local region of interest in the objectâ€™s pointcloud. This effectively reduces complexity and enhances generalization. To train our model, we created a synthetic dataset containing thousands of randomly generated objects and placement poses. We demonstrated the effectiveness of the entire pipeline in both simulation and real-world experiments. In simulation, we showed that \ourmethod outperforms baseline methods in terms of success rate, coverage, and precision. We then validated its robustness and generalization in real-world settings, where, given a single RGB-D image, \ourmethod predicts diverse placement configurations in a zero-shot manner and successfully generalizes to unseen objects.
