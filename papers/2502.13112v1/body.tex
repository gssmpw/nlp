

\title{Constrained Online Convex Optimization with Polyak Feasibility Steps}
\date{}
\author{Spencer Hutchinson and Mahnoosh Alizadeh\\
\small University of California, Santa Barbara}

 \maketitle


 \begin{abstract}
    In this work, we study online convex optimization with a fixed constraint function $g : \Rb^d \rightarrow \Rb$.
    Prior work on this problem has shown $\Oc(\sqrt{T})$ regret and \emph{cumulative} constraint satisfaction $\sum_{t=1}^{T} g(\bx_t) \leq 0$, while only accessing the constraint value and subgradient at the played actions $g(\bx_t), \partial g(\bx_t)$.
    Using the same constraint information, we show a stronger guarantee of \emph{anytime} constraint satisfaction $g(\bx_t) \leq 0 \ \forall t \in [T]$, and matching $\Oc(\sqrt{T})$ regret guarantees.
    These contributions are thanks to our approach of using \emph{Polyak feasibility steps} to ensure constraint satisfaction, without sacrificing regret.
    Specifically, after each step of online gradient descent, our algorithm applies a subgradient descent step on the constraint function where the step-size is chosen according to the celebrated Polyak step-size.
    We further validate this approach with numerical experiments.
\end{abstract}

\section{Introduction}

We study the problem of online convex optimization (OCO) where, in each round $t = 1,2,...,T$, a player chooses an action $\bx_t$ from an action set $\Xc \subseteq \Rb^d$ and then suffers the cost $f_t(\bx_t)$ according to an adversarially-chosen convex function $f_t$ \citep{zinkevich2003online}.
The player's goal is to minimize the regret with respect to the best single action in hindsight,
\begin{equation*}
    \reg_T := \sum_{t=1}^{T} f_t (\bx_t) - \min_{\bx \in \Xc}\sum_{t=1}^{T} f_t (\bx).
\end{equation*}
% Following \cite{mahdavi2012trading}, we study the common setting where the action set is described by the sublevel set of a constraint function, i.e. $\Xc := \{ x \in \Rb^d : g(x) \leq 0 \}$ for convex $g:\Rb^d \rightarrow \Rb$.

The OCO problem has emerged as a fundamental setting for various machine learning domains, such as stochastic optimization \cite{cesa2004generalization},  non-convex optimization \cite{cutkosky2023optimal}, and online control \cite{agarwal2019online}.
Furthermore, the OCO problem is directly relevant to various real-world settings, including online advertising \cite{mcmahan2013ad}, internet of things \cite{chen2018bandit}, and healthcare \cite{tewari2017ads}.

Despite the significance of the OCO problem, classical methods for OCO, such as online gradient descent (OGD) \citep{zinkevich2003online} and regularized follow the leader (RFTL) \citep{shalev2007primal}, require orthogonal projections (or similarly costly operations) to ensure that the chosen actions are feasible.
Such operations are prohibitively expensive in many applications, particularly when the action set $\Xc$ has a complicated structure.
Motivated by the high computation cost of classical methods, \citet{mahdavi2012trading} introduced the problem of \emph{OCO with long-term constraints}, where the player is \emph{not} required to ensure that the actions are feasible, but instead aims to satisfy the constraints \emph{cumulatively}.


\begin{table*}[t!]
    \caption{State-of-the-art algorithms for OCO with a non-smooth functional constraint $\Xc = \{ \bx \in \Rb^d : g(\bx) \leq 0 \}$ and first-order feedback $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$. Our results are highlighted with \colorbox{Gainsboro}{gray}. The results marked with * have been extended with Assumption 1 and Theorem 7 in \citet{mahdavi2012trading} as we show in Appendix \ref{apx:ext}. The column ``Known Strictly-Feasible Point?'' is marked ``Yes'' if the algorithm requires knowledge of an $\bx \in \Rb^d$ such that $g(\bx) < 0$, and ``No'' if not.}
    \label{tbl:comp}
\centering
% \vspace{0.1in}
\begin{tabular}{c c c c}
\toprule
\textbf{Reference} & \textbf{Regret} & \textbf{Constraint Guarantee} & \begin{tabular}{@{}c@{}}\textbf{Known Strictly-} \\ \textbf{Feasible Point?}\end{tabular}
\\
    \midrule
    \citet{mahdavi2012trading} & $\Oc(T^{3/4})$ & $\sum_{t=1}^T g (x_t) \leq 0$ & No \\
    \citet{jenatton2016adaptive} & $\Oc(T^{2/3})$ & $\sum_{t=1}^T g (x_t) \leq 0$ & No \\
    \citet{yuan2018online}* & $\Oc(T^{2/3})$ & $\sum_{t=1}^T g (x_t) \leq 0$ & No \\
    \citet{yu2017online}* & $\Oc(\sqrt{T})$ & $\sum_{t=1}^T g (x_t) \leq 0$ & No \\
    \rowcolor{Gainsboro}
    Theorem \ref{thm:ogd_pfs} & $\Oc(\sqrt{T})$ & $g (x_t) \leq 0,\ \forall t \in [T]$ & Yes \\
    \rowcolor{Gainsboro}
    Corollary \ref{cor:late_sat} & $\Oc(\sqrt{T})$ & $g (x_t) \leq 0,\ \forall t \geq t_0 = \Oc(\log(T))$ & No \\
    \rowcolor{Gainsboro}
    Corollary \ref{cor:late_sat} & $\Oc(\sqrt{T})$ & $\sum_{t=1}^{T} g (x_t) \leq 0$ & No \\
    \bottomrule
\end{tabular}
\end{table*}

In particular, \citet{mahdavi2012trading} considered the action set to be represented by the sub-level set of a constraint function, i.e. $\Xc = \{ \bx \in \Rb^d : g(\bx) \leq 0 \}$ for convex\footnote{Since the constraint function $g : \Rb^d \rightarrow \Rb$ is \emph{not} assumed to be differentiable, this can setting can handle multiple constraints $g_1,...,g_n$ by defining $g(\bx) := \max_{i \in [n]} g_i (\bx)$.} $g:\Rb^d \rightarrow \Rb$.
In this setting, \citet{mahdavi2012trading} gave an algorithm that enjoys $\Oc(T^{3/4})$ regret and ensures cumulative constraint satisfaction $\sum_{t=1}^{T} g(\bx_t) \leq 0$, while only observing a subgradient and function value at the played actions, i.e. $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$.
This algorithm uses a \emph{primal-dual} approach, in which it updates sequences of actions (primal variables) and constraint penalties (dual variables) to simultaneously minimize the regret and the cumulative constraint value. 
Primal-dual approaches have continued to be successful for this problem, as more recent algorithms of this type have been shown to enjoy $\Oc(\sqrt{T})$ regret with the same constraint guarantees and constraint feedback \cite{yu2017online}.

In this work, we take a new approach to this problem by using what we call \emph{Polyak feasibility steps}, which are subgradient descent steps that are taken with respect to the constraint function and use the Polyak stepsize.
This approach is motivated by the fact that the Polyak stepsize is known to be effective in unconstrained convex optimization \cite{polyak1969minimization}.
As such, we expect it to be similarly effective when applied to the constraint function in OCO.
Accordingly, we design an algorithm that alternates between gradient descent steps with respect to the cost function, and Polyak feasibility steps.
This algorithm differs from primal-dual approaches in that it maintains a \textit{single} sequence of iterates (versus the \textit{two} sequences used by primal-dual algorithms).

We find that our approach enjoys $\Oc(\sqrt{T})$ regret and \emph{anytime constraint satisfaction} $g(\bx_t) \leq 0 \ \forall t$, while still only observing a subgradient and function value of the constraint at the played actions.
Unlike prior methods for constrained OCO, which often trade feasibility for efficiency, our approach enjoys both feasibility \emph{and} efficiency.
Indeed, our algorithm maintains constraint satisfaction in all rounds, while using the same constraint feedback as prior work and avoiding the use of projections.
Furthermore, our approach is relevant to safety-critical applications, in which constraint satisfaction is paramount and there is often only limited constraint information available.

Our complete results are shown alongside prior work in Table \ref{tbl:comp}.
As presented in this table, prior work has shown \emph{cumulative} constraint satisfaction $\sum_{t=1}^{T} g(\bx_t) \leq 0$ and regret bounds as tight as $\Oc(\sqrt{T})$ \cite{mahdavi2012trading,jenatton2016adaptive,yuan2018online,yu2017online}.
We show stronger \emph{anytime} constraint satisfaction $g(\bx_t) \leq 0\ \forall t \in [T]$, while also guaranteeing $\Oc(\sqrt{T})$ regret.
However, unlike prior work, these guarantees require that there is a known point $\bx \in \Rb^d$ that is strictly-feasible $g(\bx) < 0$.
Nonetheless, we show that when a strictly-feasible point is \emph{not} known, then we can guarantee constraint satisfaction after $\Oc(\log(T))$ rounds, as well as cumulative constraint satisfaction.

Also, note that Table \ref{tbl:comp} only includes algorithms that access the constraint function via the constraint value and subgradient at the played actions $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$.
Therefore, it does not include the line of literature in constrained OCO that solves a convex optimization problem with the constraint function in each round, e.g. \cite{yu2020low,yi2021regret,guo2022online}.
We discuss these related works in more detail in the following section.

\subsection{Related Work}
\label{sec:rel_work}

In this section, we discuss related work on constrained OCO, projection-free OCO, and constrained optimization.

\subsubsection{Constrained OCO}

\citet{mahdavi2012trading} studied OCO with a fixed convex constraint function $g$, and gave an algorithm with $\Oc(\sqrt{T})$ regret and $\Oc(T^{3/4})$ cumulative violation $\sum_{t=1}^T g(\bx_t)$ that used only first-order constraint feedback, $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$.
This result was then generalized to $\Oc(T^{\max(\beta,1-\beta)})$ regret and $\Oc(T^{1 - \beta/2})$ cumulative violation for any $\beta \in (0,1)$ by \citet{jenatton2016adaptive}.
The same bounds were shown for a stronger notion of constraint violation $\sum_{t=1}^T [g(x_t)]_+$ by \citet{yuan2018online}, who also guaranteed that $\sum_{t=1}^T ([g(x_t)]_+)^2 = \Oc(T^{1 - \beta})$.
Finally, \citet{yu2017online} showed $\Oc(\sqrt{T})$ regret and $\Oc(\sqrt{T})$ cumulative violation in the same setting.
With the additional assumption that the constraint gradient is lower bounded near the constraint boundary (Assumption 1 in \citet{mahdavi2012trading}), the aforementioned results can be extended to guarantee no cumulative violation $\sum_{t=1}^T g(\bx_t) \leq 0$ as stated in Table \ref{tbl:comp}.
We use the same assumption to show constraint satisfaction for all rounds $g(x_t) \leq 0\ \forall t$ provided that there is a known strictly-feasible point.
Furthermore, the aforementioned works use primal-dual algorithms, which are fundamentally different from our approach of Polyak feasibility steps.
In particular, our approach uses the Polyak step-size and a \emph{single} sequence of iterates, while primal-dual algorithms use two iterate sequences that are linked via the cost and constraint functions.

There is also a line of literature on OCO with constraints that solves an optimization problem involving the constraint function in each round, e.g. \cite{yu2020low,yi2021regret,yi2022regret,guo2022online}.
This differs from our algorithm and those compared in Table \ref{tbl:comp}, which only access the constraint with first-order feedback at the played actions.
We note that solving an optimization problem with the constraint function in each round can introduce significant computational cost.

Lastly, we point out that a related line of literature considers OCO with time-varying constraints, e.g. \citep{neely2017online,yu2017online,liakopoulos2019cautious,castiglioni2022unifying,guo2022online,kolev2023online}.
This generalizes the fixed constraints that we consider.
Nonetheless, to our knowledge, none of these works improve on the guarantees shown in Table \ref{tbl:comp} for the case of non-smooth constraints, and first-order feedback.
We also point out that \citet{kolev2023online} gives an algorithm that uses first-order feedback and enjoys bounds on the violation in each round, i.e. $g(x_t) \leq \Oc(\frac{1}{\sqrt{t}}$).
However, this work requires that constraint functions are smooth (i.e. have Lipschitz gradients), making it distinct from our work and those considered in Table \ref{tbl:comp}.
Furthermore, \citet{kolev2023online} uses a projection on to a polytope in each round, which introduces additional computational cost.

\subsubsection{Projection-free OCO}

In parallel to the literature on constrained OCO, there is a line of literature that considers projection-free OCO where the feasible set is not treated as the sub-level set of a function, but rather defined as an arbitrary convex set.
\citet{hazan2012projection} initiated this literature by giving an algorithm that accesses the feasible set via a linear optimization oracle (LOO) instead of using projections.
This is advantageous because the LOO is often computationally cheaper than the projection.
LOO-based algorithms have received a significant amount of attention, e.g. \citep{hazan2012projection,chen2019projection,garber2020improved,garber2022new,wang2024non,garberprojection}.
The state-of-the-art for LOO-based algorithms with general convex costs and general convex feasible sets is $\Oc(T^{3/4})$ regret and $1$ oracle call per a round \cite{hazan2012projection}.
Although our methods give smaller $\Oc(\sqrt{T})$ regret, we note that the first-order feedback that we use is generally incomparable to the LOO oracle in terms of computationally complexity.
Indeed, the first-order feedback is cheaper to compute for some constraint functions, while the LOO is cheaper to compute for other constraint functions.\footnote{An example of this, pointed out by \citet{garber2022new}, is the difference in computational complexity for first-order information and LOO for the nuclear norm ball $\Bb_*$ and spectral norm ball $\Bb_2$ in the space of matrices. Computing first-order information for $\Bb_*$ and $\Bb_2$ is at worst a full-rank SVD (which is expensive) and rank-one SVD (which is cheap), respectively. For the LOO, the opposite is true in that $\Bb_*$ requires a rank-one SVD and $\Bb_2$ a full-rank SVD.}

There is also a growing body of literature that uses the membership oracle (MO) or separation oracle (SO) to access the feasible set, e.g. \citep{levy2019projection,garber2022new,mhammedi2022efficient,lu2023projection,hu2024riemannian,mhammedi2024online}.
The MO and SO are defined as follows.
Given a query point $\bx \in \Rb^d$, the MO specifies whether or not $\bx$ is in the feasible set, while the SO returns a hyperplane that separates $\bx$ from the feasible set (if $\bx$ is not in the feasible set).
If the feasible set is the sub-level set of a constraint function $g$ (as we consider), then the MO can be constructed by checking if $g(\bx) > 0$, and the SO can be constructed using the first-order information at $\bx$, i.e. $g(\bx),\partial g(\bx)$.\footnote{Given the query point $\bx$ and first-order information at this point $g = g(\bx),\bs \in \partial g(\bx)$, it follows from convexity that $\{ \by \in \Rb^d : g + \bs^\top(\by - \bx) \leq 0\}$ is a separating hyperplane w.r.t. $\Xc = \{ \bx \in \Rb^d : g(\bx) \leq 0 \}$.}
We use first-order information only at the played actions, which can therefore only be used to construct a separation oracle and membership oracle \emph{at the played action}.
This is distinct from existing MO and SO-based algorithms, which query the SO and MO at arbitrary points (not just the played actions).
Furthermore, existing MO-based and SO-based algorithms require \emph{multiple} oracle calls per a round.
Specifically, existing MO-based algorithms use $\Oc(d \log(T))$ oracle calls per a round \cite{lu2023projection,mhammedi2022efficient}, and existing SO-based algorithms use $\Oc(\log(T))$ oracle calls per a round \cite{mhammedi2022efficient,mhammedi2024online} or $\Oc(\kappa)$ oracle calls per a round \cite{garber2022new}.
Note that we state these bounds for unrestricted $T$ and use $\kappa$ to refer to the eccentricity of the feasible set, i.e. $\kappa = R/r$ with $r \Bb \subseteq \Xc \subseteq R \Bb$, which can be arbitrarily large.
The fact that our algorithm only requires $1$ oracle call per a round can result in significant performance advantages over these methods, particularly when the constraint is costly to evaluate.
Furthermore, our approach is applicable to settings where there is only \emph{local} constraint information available.

\subsubsection{Constrained Optimization}

Our approach is inspired by a line of literature in constrained (offline) optimization that uses the Polyak step-size to ensure convergence to the feasible set, e.g. \cite{polyak2001random,nedic2011random,nedic2019random,necoara2022stochastic}.
However, we point out two key difficulties that arise in the OCO setting: (a) the suboptimality gap of the iterates $f_t(\bx_t) - f_t(\bx^\star)$ is \emph{not} guaranteed to be non-negative, and (b) the constraint feedback is at the played action $\bx_t$ and not at the ``intermediate'' iterate (labeled $\by_t$ in Algorithm \ref{alg:ogd_pfs}).
Challenge (a) is particularly difficult to handle because the analysis approach used by \citet{nedic2011random} (and following works) relies on the suboptimality gap of the iterates being non-negative.
As a result, we require a new analysis approach.
However, our approach does suffer a larger dependence on the problem parameters (such as the subgradient bound $G_g$), which can be seen as the ``cost'' of the adversarial online setting.
To handle challenge (b), we use the first-order approximation of the cost function $g_t + \bs_t^\top (\by_t - \bx_t)$ in the Polyak step-size instead of the true cost function $g(\by_t)$.
This first-order approximation avoids the need for constraint information at the intermediate iterate $\by_t$, while maintaining the advantageous properties of the Polyak step-size (see Section \ref{sec:feas_anal} for the details).
Overall, we believe that these analysis techniques will be of interest to the constrained optimization literature, beyond just OCO.

\subsection{Notation}

We use $\Oc(\cdot)$ for big-O notation and $\Octil(\cdot)$ for the same ignoring log factors.
The 2-norm is denoted by $\| \cdot \|$ and the 2-norm ball is denoted by $\Bb = \{ \bx \in \Rb^d : \| \bx \| \leq 1 \}$.
Given a natural number $n$, we use the notation $[n] := \{1, 2, ..., n \}$.
The transpose of a matrix $M$ is denoted $M^\top$.
A vector of ones and zeros is denoted by $\bone$ and $\bzero$, respectively.
Lastly, for a given $x \in \Rb$, we use the notation $[x]_+ = \max(x,0)$.

\subsection{Overview}

We specify the problem of OCO with constraints in Section \ref{sec:prob}.
Then, in Section \ref{sec:alg}, we give an algorithm for this problem that uses our approach of \emph{Polyak feasibility steps}.
In particular, Section \ref{sec:desc} gives the description of this algorithm, Section \ref{sec:guar} gives the guarantees of $\Oc(\sqrt{T})$ regret and \emph{anytime} constraint satisfaction $g(\bx_t) \leq 0$, and Section \ref{sec:reg_anal} and \ref{sec:feas_anal} give the regret analysis and feasibility analysis, respectively.
Lastly, we give simulation results in Section \ref{sec:num_exp} that demonstrate the functionality of our algorithm.

\section{Problem Setup}

We study the problem of online convex optimization with functional constraints.
In the following, we first describe online convex optimization generally and then specify the functional constraints.

\paragraph{Online Convex Optimization}

\label{sec:prob}

Online convex optimization (OCO) is a repeated game between a player and an adversary that is played over $T$ rounds.
In each round $t \in [T]$, the player chooses an action $\bx_t$ from a convex action set $\Xc \subseteq \Rb^d$, and then the adversary chooses a convex function $f_t : \Rb^d \rightarrow \Rb$.
The player aims to minimize the cumulative regret,
\begin{equation*}
    \reg_T := \sum_{t=1}^{T} f_t (\bx_t) - \min_{\bx \in \Xc}\sum_{t=1}^{T} f_t (\bx),
\end{equation*}
We will use the standard assumptions that the cost functions have bounded gradients and that the action set is bounded. These are stated precisely in the following.

\begin{assumption}
    \label{ass:feas}
    There exists positive real $R$ such that $\Xc~\subseteq~R \Bb$.
\end{assumption}

\begin{assumption}
    \label{ass:stand}
    There exists positive real $G_f$ such that $\| \nabla f_t(\bx) \| \leq G_f$ for all $\bx \in R \Bb$ and $t \in [T]$.
\end{assumption}

\paragraph{Functional Constraints}
\label{sec:func}

Following \citet{mahdavi2012trading}, we study the setting where the action set is defined by a functional inequality constraint $\Xc = \{ \bx \in \Rb^d : g(\bx) \leq 0 \}$, with $g : \Rb^d \rightarrow \Rb$ being non-smooth and convex.
In the following, we assume that the constraint function has bounded subgradients (Assumption \ref{ass:bound_cons}) and that the subgradient norm is lower-bounded near the boundary (Assumption \ref{ass:curve}).
These assumptions are also used by \citet{mahdavi2012trading} and \citet{jenatton2016adaptive}.
Since the constraint function is non-smooth, this setting can be extended to multiple constraints $g_1,..,g_m$ by taking $g(\bx) = \max_{i \in [m]} g_i (\bx)$.

\begin{assumption}
    \label{ass:bound_cons}
    There exists a positive real $G_g$ such that, for all $\bx \in R \Bb$, it holds that $\| \partial g(\bx) \| \leq G_g$.
\end{assumption}

\begin{assumption}
    \label{ass:curve}
    There exists positive reals $\sigma, \epsilon$ such that $\| \partial g(\bx) \| \geq \sigma$ for all $\bx \in \Rb^d$ where $g(\bx) = -\epsilon$.
\end{assumption}

\section{Algorithm}

\label{sec:alg}



In this section, we give Algorithm \ref{alg:ogd_pfs}, which tackles OCO with functional constraints using our approach of Polyak feasibility steps.
Notably, Algorithm \ref{alg:ogd_pfs} only uses \emph{one} constraint query in each round, at the played action $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$, and therefore uses the \emph{exact same} feedback as \citet{mahdavi2012trading}.
Despite this limited feedback, we will show that Algorithm \ref{alg:ogd_pfs} ensures constraint satisfaction for all rounds, i.e. $g(\bx_t) \leq 0$ for all $t \in [T]$.


\begin{algorithm}[t]
    \caption{OGD with Polyak Feasibility Steps}
    \label{alg:ogd_pfs}
\begin{algorithmic}[1]
    \INPUT initial action $\bx_1 \in \Rb^d$, step size $\eta \in \Rb$, tightening~$\rho \in \Rb$.
    \FOR{$t = 1,2,...,T$}
        \STATE Play $\bx_t$ and receive $f_t$.
        \STATE Query constraint: $g_t = g(\bx_t), \bs_t \in \partial g(\bx_t)$.
        \STATE Gradient descent: $\by_{t} = \bx_t - \eta \nabla f_t(\bx_t)$.\alglabel{lne:grad}
        \STATE Polyak feasibility step:\footnotemark\\ $\bx_{t+1} = \Pi_{R \Bb} \left( \by_{t} - \frac{[g_t + \bs_t^\top (\by_{t} - \bx_t) + \rho]_+}{\| \bs_t \|^2} \bs_t \right)$. \alglabel{lne:poly}
    \ENDFOR
\end{algorithmic}
\end{algorithm}



\subsection{Description}
\label{sec:desc}

At a high-level, Algorithm \ref{alg:ogd_pfs} operates by alternating between gradient descent steps (line \ref{lne:grad}) and Polyak feasibility steps (line \ref{lne:poly}).
We discuss the key ingredients of our Polyak feasibility steps in the following.

\paragraph{Polyak Step-size}

The design of our Polyak feasibility step is motivated by the classical Polyak step-size \cite{polyak1969minimization}.
In unconstrained convex optimization, using subgradient descent with the Polyak step-size is known to be optimal \cite{boyd2003subgradient}, and therefore it is a natural choice to ensure strong feasibility guarantees when applied to the constraint function.
This classical step-size uses the function value and subgradient at the current iterate to approximate the optimal step-size in each update.
In our setting, this would require the constraint function value at the ``intermediate iterate'' $\by_t$, which is not available.
We address this next.

\footnotetext{The projection on to the ball can be implemented by scaling the point according to its norm. Specifically, for $\bx \in \Rb^d$, it holds that $\Pi_{R\Bb}(\bx) = \min\left(1, \frac{R}{\| \bx \|} \right) \bx$.}

\paragraph{First-order Approximation}

As discussed previously, the classical Polyak step-size cannot immediately be applied to our setting because it would require the constraint function value at the intermediate iterate $\by_t$.
Although this is not known in our setting, we do have constraint information at the played action $\bx_t$, which should not be too far from the intermediate iterate $\by_t$. 
Therefore, we use the constraint information at $\bx_t$ to construct a first-order approximation of the constraint at $\by_t$,
\begin{equation}
    \label{eqn:first_ord}
    g(\by_t) \approx g_t + \bs_t^\top (\by_{t} - \bx_t) \in g(\bx_t) + \partial g(\bx_t)^\top (\by_{t} - \bx_t).
\end{equation}
As we will show in the analysis, this first-order approximation is sufficient to maintain the advantageous properties of the Polyak step-size.

\paragraph{Constraint Tightening}

Another difficulty that arises in our setting is that the gradient descent step in line \ref{lne:grad} might push the sequences of actions out of the feasible set.
Indeed, the cost functions are chosen adversarially and therefore we have no guarantees about the direction of the gradient in each round.
Therefore, to ensure that the actions are feasible, we use a tightened version of the constraint function $g(\bx) + \rho$ where $\rho > 0$ is a tightening parameter that is to be chosen appropriately.
Given that the constraint function is Lipschitz (via Assumption \ref{ass:bound_cons}), this ensures that there is a ``buffer zone'' between the points that satisfy the tightened constraint $g(\bx) + \rho \leq 0$ and the boundary of the true feasible set defined by $g(\bx) \leq 0$.
Therefore, by choosing $\rho$ proportional to the cost step-size $\eta$, we can ensure that the actions are feasible despite the adversarially-chosen cost gradients.
Note that tightening the constraint in this manner is a common technique in the constrained OCO literature, e.g. \cite{mahdavi2012trading,jenatton2016adaptive}.

\paragraph{Polyak Feasibility Steps}

Using the ingredients discussed previously, we can put everything together to get our Polyak feasibility steps.
Indeed, the step-size in line \ref{lne:poly} is,
\begin{equation}
    \label{eqn:pfs}
    \frac{[g_t + \bs_t^\top (\by_{t} - \bx_t) + \rho]_+}{\| \bs_t \|^2},
\end{equation}
where the numerator uses the first-order approximation in \eqref{eqn:first_ord} and the tightening parameter $\rho$. 
As such \eqref{eqn:pfs} can be viewed as the Polyak step-size that uses a first-order approximation of the tightened constraint value $g(\by_t) + \rho$.
In the analysis, we will see that this step-size ensures that the constraint value is greatly reduced in each step.

\subsection{Guarantees}
\label{sec:guar}

The following theorem shows that, with appropriate choice of algorithm parameters, Algorithm \ref{alg:ogd_pfs} enjoys $\Oc(\sqrt{T})$ regret in terms of the horizon $T$, and anytime constraint satisfaction.


\begin{theorem}[Main Result]
    \label{thm:ogd_pfs}
    Let Assumptions \ref{ass:feas}, \ref{ass:stand}, \ref{ass:bound_cons} and \ref{ass:curve} hold.
    Then, playing Algorithm \ref{alg:ogd_pfs} with $g(\bx_1) \leq -\rho$,
    \begin{equation*}
        \eta = \frac{\xi \epsilon}{G_f G_g \sqrt{T}} \qquad \text{and} \qquad \rho = \frac{\epsilon}{\sqrt{T}},
    \end{equation*}
    ensures that,
    \begin{align*}
        \reg_T & \leq \left(\frac{G_f G_g R^2}{2 \xi \epsilon} + \frac{G_f \xi \epsilon}{2 G_g} + \frac{G_f \epsilon}{\sigma} \right) \sqrt{T},\\
        g(\bx_t) & \leq 0 \quad \forall t \in [T],
    \end{align*}
    where, $\xi = 1 - \sqrt{1 - \frac{\sigma^2}{G_g^2}}$.
\end{theorem}

One drawback of the guarantee in Theorem \ref{thm:ogd_pfs} is that it requires the knowledge of a strictly feasible point as the initial action, i.e. $g(\bx_1) \leq - \rho$.
To address this, we give Corollary \ref{cor:late_sat} below that only requires $\bx_1 \in R \Bb$ and ensures that $g(\bx_t) \leq 0$ for all $t \geq t_0$ where $t_0 = \Oc(\log(T))$.
Note that $\bx_1 \in R \Bb$ can always be satisfied given an arbitrary $\bx \in \Rb^d$, by taking $\bx_1 = \min\left( \frac{R}{\| \bx \|}, 1 \right) \bx$.
Corollary \ref{cor:late_sat} also shows that when $T$ is sufficiently large, then the algorithm ensures that there is cumulative constraint satisfaction $\sum_{t=1}^{T} g(\bx_t) \leq 0$.
Note that the requirement that $T$ is sufficiently large is also used by prior work that shows cumulative constraint satisfaction \cite{mahdavi2012trading,jenatton2016adaptive}.

\begin{corollary}
    \label{cor:late_sat}
    Assume the same as Theorem \ref{thm:ogd_pfs}.
    Consider Algorithm \ref{alg:ogd_pfs} with $\bx_1 \in R \Bb$, $\eta = \frac{\xi \epsilon}{2 G_f G_g \sqrt{T}}$ and $\rho = \frac{\epsilon}{\sqrt{T}}$.
    Then, it holds that,
    \begin{align*}
        \reg_T & \leq \left(\frac{G_f G_g R^2}{\xi \epsilon} + \frac{G_f \xi \epsilon}{4 G_g} + \frac{G_f \epsilon}{\sigma} \right) \sqrt{T},\\
        g(\bx_t) & \leq 0 \quad \forall t \geq 1 + \frac{2 G_g^2}{\sigma^2} \log\left( \frac{2 G_g R \sqrt{T}}{\epsilon} \right).
    \end{align*}
    Furthermore, when $\sqrt{T} \geq \frac{2 R G_g}{\epsilon \xi}$ it additionally holds that,
    \begin{equation*}
        \sum_{t=1}^{T} g(\bx_t) \leq 0.
    \end{equation*}
\end{corollary}

Lastly, we give another corollary below (Corollary \ref{cor:some_viol}) that allows a small amount of violation in each round, while eliminating the dependence on $G_g$ in the regret bound.
In this case, the regret bound is $R G_f \sqrt{T}$, which matches what is attained by online gradient descent using a full projection on to the action set in each round \cite{zinkevich2003online}.
At the same time, the constraint violation satisfies $g(x_t) = \Oc(\frac{1}{\sqrt{T}})$.

\begin{corollary}
    \label{cor:some_viol}
    Assume the same as in Theorem \ref{thm:ogd_pfs}.
    Consider Algorithm \ref{alg:ogd_pfs} with $\bx_1 \in R \Bb$, $\eta = \frac{G_f}{R \sqrt{T}}$ and $\rho = 0$.
    Then, it holds that,
    \begin{align*}
        \reg_T & \leq R G_f \sqrt{T},\\
        g(\bx_t) & \leq \exp \left( -\frac{\sigma^2}{2 G_g^2} t \right) R G_g + \frac{G^2_f G_g}{\xi R \sqrt{T}} \quad \forall t \in [T]
    \end{align*}
\end{corollary}

\subsection{Regret Analysis}
\label{sec:reg_anal}

In this section, we give the regret analysis.
We separate the regret in to (I) the regret with respect to the tightened feasible set, and (II) the cost of tightening the feasible set,
\begin{equation}
    \label{eqn:reg_decomp}
        \reg_T = \underbrace{\sum_{t=1}^{T} (f_t(\bx_t) - f_t(\bx_\rho^\star))}_{\tone} + \underbrace{\sum_{t=1}^{T} (f_t(\bx_\rho^\star) - f_t(\bx^\star)),}_{\ttwo}
\end{equation}
where $\bx_\rho^\star \in \argmin_{\bx \in \Xc_\rho} \sum_{t=1}^{T} f_t(\bx)$, and the tightened feasible set is,
\begin{equation}
    \label{eqn:tight}
    \Xc_\rho := \{ \bx \in \Rb^d : g(\bx) \leq -\rho \}.
\end{equation}

We start with Term I.
The key observation is that the Polyak feasibility step (line \ref{lne:poly}) can be equivalently defined as the projection on to the halfspace $\Hc_t$ in \eqref{eqn:half} (with the additional projection on to the ball).
In fact, this halfspace $\Hc_t$ contains the tightened feasible set $\Xc_\rho$ and therefore projecting on to it will not increase the distance to any point in $\Xc_\rho$.
This is stated precisely in Fact~\ref{fact:half}.

\begin{fact}
    \label{fact:half}
    The update for $\bx_{t+1}$ in line \ref{lne:poly} of Algorithm \ref{alg:ogd_pfs} is equivalent to $\bx_{t+1} = \Pi_{R \Bb} (\Pi_{\Hc_t} (\by_{t+1}))$ where,
    \begin{equation}
        \label{eqn:half}
        \Hc_t = \{ \bx \in \Rb^d : g_t + \bs_t^\top(\bx - \bx_t) + \rho \leq 0 \}.
    \end{equation}
    Furthermore, it holds that $\Hc_t \supseteq \Xc_\rho$, and therefore that for all $\bx \in \Xc_\rho$ and $\bv \in \Rb^d$,
    \begin{equation}
        \label{eqn:non_expan}
        \| \Pi_{\Hc_t} (\bv) - \bx \| \leq \| \bv - \bx \|.
    \end{equation}
\end{fact}

In fact, the classical analysis of OGD (from \citet{zinkevich2003online}) only requires that the projection does not increase the distance to the optimal action, which is ensured by \eqref{eqn:non_expan} in Fact \ref{fact:half}.
Therefore, it follows from \eqref{eqn:non_expan} and the standard analysis of OGD that we have a regret bound with respect to the tightened feasible set, and thus,
\begin{equation}
    \label{eqn:tone}
    \tone \leq \frac{R^2}{2 \eta} + \frac{\eta}{2} G_f^2 T.
\end{equation}
We defer the complete proof of \eqref{eqn:tone} to Appendix \ref{apx:tone}.

Now, we look at Term II.
We use Lemma \ref{lem:error_bound} below, which provides a bound on the distance to $\Xc_\rho$ in terms of $g$.
This lemma is conceptually similar to Theorem 7 in \citet{mahdavi2012trading}.
However, it is more general in the sense that it is a general error bound on the constraint function, whereas Theorem 7 in \citet{mahdavi2012trading} only provides a bound on the difference in costs between a point in the tightened feasible set and the original feasible set. 
The proof of Lemma \ref{lem:error_bound} is given in Appendix \ref{apx:err_bound}.

\begin{lemma}
    \label{lem:error_bound}
    Let Assumptions \ref{ass:bound_cons} and \ref{ass:curve} hold, and suppose that $\rho \in [0,\epsilon]$.
    Then, we have for all $\bx \in R \Bb$ that,
    \begin{equation}
        \label{eqn:error_bound}
        \dist(\bx, \Xc_\rho) \leq \frac{1}{\sigma} [g(\bx) + \rho]_+
    \end{equation}
\end{lemma}

It follows from Lemma \ref{lem:error_bound} and the cost gradient bound (Assumption \ref{ass:stand}) that,
\begin{align*}
    \ttwo & = \sum_{t=1}^{T} (f_t(\bx_\rho^\star) - f_t(\bx^\star)) \\
    & \leq \sum_{t=1}^{T} (f_t(\Pi_{\Xc_\rho}(\bx^\star)) - f_t(\bx^\star)) \tag{a} \label{eqn:lne_a}\\
    & \leq G_f T \dist(\bx^\star, \Xc_\rho)  \tag{b} \label{eqn:lne_b}\\
    & \leq \frac{G_f T}{\sigma} [g(\bx^\star) + \rho]_+ \leq \frac{G_f \rho}{\sigma} T, \tag{c} \label{eqn:lne_c}
\end{align*}
where \eqref{eqn:lne_a} uses the minimality of $\bx_\rho^\star$, \eqref{eqn:lne_b} uses the cost gradient bound, and \eqref{eqn:lne_c} uses Lemma \ref{lem:error_bound} and that $g(\bx^\star) \leq 0$.

Combining the bounds on Term I and Term II and using the choice of $\eta, \alpha$ give the complete regret bound in Theorem \ref{thm:ogd_pfs}.

\subsection{Feasibility Analysis}
\label{sec:feas_anal}

In this section, we give the feasibility analysis.
The central result in this section is Lemma \ref{lem:polyak_feas} below, which shows that the Polyak step-size shrinks the distance to a sub-level set of $g$.
This lemma combines the classical analysis of the Polyak step-size from \citet{polyak1969minimization} with Lemma~\ref{lem:error_bound}.

\begin{lemma}[Polyak Step-size]
    \label{lem:polyak_feas}
    Let Assumption \ref{ass:bound_cons} and \ref{ass:curve} hold, and suppose that $\rho \in [0,\epsilon]$.
    Furthermore, consider the $\rho$-sublevel set of $g$, $\Xc_\rho := \{ \bx \in \Rb^d : g(\bx ) + \rho \leq 0 \}$.
    Consider any $\bx \in R \Bb$ and $\bs \in \partial g(\bx)$, and let,
    \begin{equation}
        \label{eqn:poly_feas}
        \bx^+ = \Pi_{R \Bb} \left(\bx - \frac{[g(\bx) + \rho]_+}{\| \bs \|^2} \bs \right).
    \end{equation}
    Then, it holds that,
    \begin{equation}
        \label{eqn:dists}
        \dist^2(\bx^+, \Xc_\rho) \leq \left(1 - \frac{\sigma^2}{G_g^2} \right) \ \dist^2(\bx, \Xc_\rho).
    \end{equation}
\end{lemma}
\begin{proof}
    Let $\bv = \Pi_{\Xc_\rho} (\bx)$ and denote $g_\rho (\bx) := g(\bx) + \rho$.
    First, note that if $g_\rho (\bx) \leq 0$, then \eqref{eqn:poly_feas} becomes $\bx^+ = \bx$ and therefore $g_\rho(\bx^+) = g_\rho (\bx) \leq 0$ and \eqref{eqn:dists} is satisfied with both sides $0$.
    Therefore, we take $g_\rho(\bx) > 0$ for the remainder (which ensures that $[g_\rho (\bx)]_+ = g_\rho (\bx)$).
    Then, it follows that,
    \begin{align*}
        \dist^2(\bx^+, \Xc_\rho) & \leq \| \bx^+ - \bv \|^2 \\
        & \leq \| \bx - \frac{g_\rho(\bx)}{\| \bs \|^2} \bs - \bv \|^2 \tag{a} \label{eqn:a}\\
        & \begin{aligned}
            =\ & \dist^2(\bx, \Xc_\rho) - 2 \frac{g_\rho(\bx)}{\| \bs \|^2} \bs^\top (\bx - \bv)\\
            & + \frac{g_\rho(\bx)^2}{\| \bs \|^2}
        \end{aligned}  \\
        & \leq \dist^2(\bx, \Xc_\rho) - \frac{g_\rho(\bx)^2}{\| \bs \|^2} \tag{b} \label{eqn:b} \\
        & \leq \dist^2(\bx, \Xc_\rho) - \frac{g_\rho(\bx)^2}{G_g^2} \tag{c} \label{eqn:c}\\
        & \leq \left(1 - \frac{\sigma^2}{G_g^2} \right) \dist^2(\bx, \Xc_\rho), \tag{d} \label{eqn:d}
    \end{align*}
    where \eqref{eqn:a} uses the Pythagorean theorem of the projection, \eqref{eqn:b} uses that $\bs^\top (\bx - \bv) \geq g_\rho(\bx) - g_\rho(\bv) \geq g_\rho(\bx)$ due to convexity of $g_\rho$ and the fact that $\bv \in \Xc_\rho$, \eqref{eqn:c} uses that $\| \bs \| \leq G_g$ due to Assumption \ref{ass:bound_cons}, and \eqref{eqn:d} uses Lemma~\ref{lem:error_bound}.
\end{proof}

Note that Lemma \ref{lem:polyak_feas} uses the ``exact'' Polyak step-size in the sense that the numerator of \eqref{eqn:poly_feas} uses the exact constraint function value at the previous iterate $g(\bx)$.
This differs from the update in line \ref{lne:poly} in Algorithm \ref{alg:ogd_pfs}, which uses the first-order approximation of the function value at $\by_t$ because the algorithm does not have access to the exact function value at $\by_t$.
In order to handle this disparity, we introduce the ``fictitious'' iterate $\bz_{t+1}$,
\begin{equation*}
    \bz_{t+1} = \Pi_{R \Bb} \left(\bx_t - \frac{[g_t + \rho]_+}{\| \bs_t \|^2} \bs_t \right).
\end{equation*}
Importantly, the update for $\bz_{t+1}$ matches the form in \eqref{eqn:poly_feas} and therefore we can directly apply Lemma \ref{lem:polyak_feas} analyze $\bz_{t+1}$.

Using $\bz_{t+1}$, we study the distance between $\bx_{t+1}$ and~$\Xc_\rho$,
\begin{align*}
    \dist(\bx_{t+1}, \Xc_\rho) & \leq \| \bx_{t+1} - \Pi_{\Xc_\rho}(\bz_{t+1}) \|\\
    & \leq \underbrace{\| \bx_{t+1} - \bz_{t+1} \|}_{\tone} + \underbrace{\dist(\bz_{t+1}, \Xc_\rho)}_{\ttwo},
\end{align*}

We start with Term I.
Using the ``halfspace representation'' of the Polyak feasibility step (as in Fact \ref{fact:half}), we can write $\bx_{t+1} = \Pi_{R \Bb}(\Pi_{\Hc_t} (\by_t))$ and $\bz_{t+1} = \Pi_{R \Bb}(\Pi_{\Hc_t} (\bx_t))$ where $\Hc_t$ is defined in \eqref{eqn:half}.
Therefore, it follows that,
\begin{align*}
    \tone & = \| \Pi_{R \Bb}(\Pi_{\Hc_t} (\by_t)) - \Pi_{R \Bb}(\Pi_{\Hc_t} (\bx_t)) \|\\
    & \leq \| \Pi_{\Hc_t} (\by_t) - \Pi_{\Hc_t} (\bx_t) \|\\
    & \leq \| \by_t - \bx_t \| \\
    & \leq \eta G_f,
\end{align*}
where the first two lines use the non-expansiveness of the projection, and the last line uses the cost gradient bound. 

Next, we look at Term II.
Applying Lemma \ref{lem:polyak_feas} yields,
\begin{align*}
    (\ttwo)^2 \leq \gamma\ \dist^2(\bx_t, \Xc_\rho),
\end{align*}
where $\gamma = 1 - \frac{\sigma^2}{G_g^2}$.

Combining Term I and Term II yields,
\begin{align*}
    \dist(\bx_{t+1}, \Xc_\rho) & \leq \sqrt{\gamma} \dist(\bx_{t}, \Xc_\rho) + \eta G_f\\
    & \leq \gamma^{t/2} \dist(\bx_{1}, \Xc_\rho) + \frac{\eta G_f}{1 - \sqrt{\gamma}},     
\end{align*}
where we apply the bound recursively in the second line.
Then, applying the the subgradient bound (Assumption \ref{ass:bound_cons}),
\begin{equation}
    \label{eqn:feas_decomp}
    \begin{split}
        g(\bx_t) & = g(\bx_t) - g(\Pi_{\Xc_\rho} (\bx_t)) + g(\Pi_{\Xc_\rho} (\bx_t))\\
        & \leq G_g \dist(\bx_t, \Xc_\rho) - \rho \\
        & \leq G_g \gamma^{(t-1)/2} \dist(\bx_{1}, \Xc_\rho) + \frac{\eta G_g  G_f}{1 - \sqrt{\gamma}} - \rho,
    \end{split}
\end{equation}
The guarantees in Theorem \ref{thm:ogd_pfs} follows from \eqref{eqn:feas_decomp} by applying the choice of $\bx_1$, $\eta$ and $\rho$, as this ensures that $\dist(\bx_{1}, \Xc_\rho) = 0$ and that $\frac{\eta G_g  G_f}{1 - \sqrt{\gamma}} = \rho$.
Also, the guarantees in Corollary~\ref{cor:late_sat} follow by applying the bound $\dist(\bx_{1}, \Xc_\rho) \leq R$ and then finding when the right-hand side is less than $0$ (with the specified choice of $\eta$ and $\rho$).
Lastly, the guarantees in Corollary \ref{cor:some_viol} follow by simply taking $\rho = 0$.

\section{Numerical Experiments}
\label{sec:num_exp}


Although our primary contribution is our theoretical results, we also give numerical experiments to demonstrate the functionality of the algorithm and provide some empirical verification of the theoretical results.
In these experiments, we benchmark the performance of our algorithm with the algorithm from \citet{yu2017online} as it has the best regret bound among those in Table \ref{tbl:comp}.


We consider a $2$-dimensional toy setting with quadratic cost functions $f_t(\bx) = 3 \| \bx - \bv_t \|^2$ and linear constraints $A \bx \leq \bb$.
We generate $\bv_t$ by sampling uniformly from $[0,1]^2$, and take $A = [I\ -I]^\top$ and $\bb = 0.5 \bone$, where we use $I$ to denote the $2 \times 2$ identify matrix.
Therefore, we can define the constraint function as $g(\bx) = \max_{i \in [4]} \ba_i^\top \bx - b_i$, where $\ba_i$ and $b_i$ are the $i$th row of $A$ and $\bb$ respectively.\footnote{Note that the constraint can also be written with the infinity-norm: $g(\bx) = \| x \|_{\infty} - b$.}
Accordingly, we take $G_f = \sqrt{2}$, $R = 1$, $G_g = 1$, $\epsilon = 0.25$ and $\sigma = \frac{1}{\sqrt{2}}$.

In this setting, we implement Algorithm \ref{alg:ogd_pfs} (labeled \texttt{PFS}) with the algorithm parameters chosen according to Theorem~\ref{thm:ogd_pfs}, as well as the algorithm in \citet{yu2017online} (labeled \texttt{DPP}) with the algorithm parameters chosen according to their Theorem 1, i.e. $\alpha = T, V = \sqrt{T}$.
We also implement the algorithm from \citet{yu2017online} with a tightened constraint $g_\rho(\bx) := g(\bx) + \rho$ for $\rho \in [0,\epsilon]$, as is used in our algorithm and that in \citet{mahdavi2012trading} and \citet{jenatton2016adaptive}.
Same as the aforementioned algorithms, we use a decreasing $\rho = \min(\epsilon, \frac{c}{\sqrt{T}})$, where $c>0$ is a parameter that we tune to reduce the violation.
We choose $c = 20$ to ensure that there is a small amount of constraint violation.
The tightened version of \texttt{DPP} is labeled \texttt{DPP-T}.


\begin{figure*}[t]
    \centering
    % \hfill
    \begin{subfigure}[t]{0.28\textwidth}
        \centering    
        % \vspace{-0.1in}
        \includegraphics[width=\columnwidth]{plot1a.pdf}
        \vspace{-0.2in}
        \caption{}
        \label{fig:expers:a}
    \end{subfigure}
    \hspace{0.04\textwidth}
    \begin{subfigure}[t]{0.28\textwidth}
        \centering    
        % \vspace{-0.1in}
        \includegraphics[width=\columnwidth]{plot1b.pdf}
        \vspace{-0.2in}
        \caption{}
        \label{fig:expers:b}
    \end{subfigure}
    \hspace{0.04\textwidth}
    % ~
    \begin{subfigure}[t]{0.28\textwidth}
        \centering    
        % \vspace{-0.1in}
        \includegraphics[width=\columnwidth]{plot1c.pdf}
        \vspace{-0.2in}
        \caption{}
        \label{fig:expers:c}
    \end{subfigure}
    % \
    % \vspace{-0.1in}
   \caption{Simulation results for our algorithm (labeled \texttt{PFS}), alongside the algorithm from \citet{yu2017online} (labeled \texttt{DPP}). We also include a version of the algorithm in \citet{yu2017online} where the constraint is tightened (labeled \texttt{DPP-T}). The points indicate the average over 30 trials and the error bars and shading are $\pm 1$ standard deviation.}
   \label{fig:expers}
%    \vspace{-0.1in}
\end{figure*}

The results are shown in Figure \ref{fig:expers}.
Precisely, Figure \ref{fig:expers:a} and Figure \ref{fig:expers:b} show the regret and cumulative violation for $T = 2 \times 10^3,4 \times 10^3,...,2 \times 10^4$, where the marker indicates the mean over the $30$ trials and the errorbar indicates the standard deviation.
Figure \ref{fig:expers:c} shows the instantaneous violation $[g(\bx_t)]_+$ at each round for a fixed $T = 2 \times 10^4$, where the line shows the mean over $30$ trials and the shading indicates the standard deviation.
In these results, \texttt{DPP} enjoys smaller regret than \texttt{PFS}.
However, \texttt{DPP} incurs constraint violation, while \texttt{PFS} does not incur constraint violation.
By augmenting \texttt{DPP} with a tightened constraint, the constraint violation can be substantially reduced as shown for \texttt{DPP-T}.
However, this also results in a larger regret.

To provide intuition on the operation of our algorithm, we also include Figure~\ref{fig:examp}, which shows every $300$th action chosen by the algorithms in one simulation trial.
In this plot, it can be seen that \texttt{PFS} takes a conservative approach in gradually approaching the constraint boundary, which ensures constraint satisfaction at the cost of larger regret.


\begin{figure}[t]
    \centering    
    % \vspace{-0.1in}
    \includegraphics[width=0.5\columnwidth]{plot2.pdf}
    \vspace{-0.2in}
   \caption{Actions chosen by our algorithm and the one from \citet{yu2017online} in a simulation.}
   \label{fig:examp}
   \vspace{-0.1in}
\end{figure}

\section{Conclusion}

In this work, we give an algorithm for constrained OCO that uses Polyak feasibility steps to ensure anytime constraint satisfaction $g(\bx_t) \leq 0\ \forall t$ and $\Oc(\sqrt{T})$ regret, while only receiving feedback on the function value and subgradient at the played actions.
We foresee this approach being relevant to safety-critical applications, where constraints must be satisfied despite having only limited constraint information.

\bibliographystyle{plainnat}
\bibliography{references}
