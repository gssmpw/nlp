\section{Introduction}

Machine learning is increasingly used in high-stakes settings to decide who receives a loan \citep{hurley2016credit}, a job interview~\citep{bogen2018help}, or even an organ transplant~\citep{murgia2023algorithms}. Models predict outcomes using features about individuals, without considering how individuals can change them~\citep[][]{liu2024actionability}. Consequently, models may assign an individual a \emph{fixed prediction} which is not \emph{responsive} to the individual's actions. 

The responsiveness of a model is integral to its safety in settings where predictions map to people. In lending and hiring, fixed predictions may preclude individuals from access to credit and employment. In content moderation, a fixed prediction can ensure that malicious actors are unable to evade detection by manipulating their features. There has been little work that mentions this effect, let alone studies it. In spite of this, fixed predictions arise in practice. Recently, a predictive model used to allocate livers in the United Kingdom was found to discriminate on the basis of age, precluding all young patients, no matter how ill, from receiving a liver transplant~\cite{murgia2023algorithms}. Despite the gravity of this problem, no existing methods can characterize the set of individuals who receive fixed predictions under a model.

The difficulties in detecting fixed predictions stem from challenges in optimization, interpretability, and data collection. Verifying recourse for a \emph{single individual} is a non-trivial combinatorial problem that requires performing exhaustive search over a subset of the feature space that captures both the model as well as actionability constraints \cite{ustun2019actionable, kothari2023prediction}. Characterizing all fixed predictions represents an even more intensive setting that requires searching over any plausible individual. Moreover, even when individuals without recourse can be identified, it is hard to determine the cause of these fixed predictions \citep{rawal2020algorithmic}. The standard point-wise approach to check model responsiveness \citep[see][]{kothari2023prediction} can only verify recourse for available data, and does not provide guarantees on model responsiveness out-of-sample. In practice, this means that critical issues can only be identified \emph{after} a model has been deployed and it is too late to prevent harms.  %The utility of these point-wise approaches is dependent on access to comprehensive data sets that cover potential model users. However, this is an onerous requirement for external audits where gaining access to a model is easy but getting a representative sample of the population is difficult. For instance, many interpretable medical and criminal justice scoring systems are available publicly~\citep[see e.g.,][]{morrison2022optimized, yamga2023optimized, ribeiro2023use, PennSentence}, but gaining access to a representative dataset is difficult due to privacy concerns. 

%Point-wise approaches to recourse verification also require access to a representative dataset of individuals affected by the model. This requirement is impossible in settings with distribution shift after deployment, and demanding for external audits where gaining access to a model is easy but getting a representative sample of the population is difficult. For instance, many interpretable medical and criminal justice scoring systems are available publicly~\citep[see e.g.,][]{morrison2022optimized, yamga2023optimized, ribeiro2023use, PennSentence}, but gaining access to a representative dataset is difficult due to privacy concerns. Moreover, even when individuals without recourse can be identified during model development, determining the root cause of fixed predictions can be challenging!\citep{rawal2020algorithmic}. 

This work studies a new paradigm in algorithmic recourse that characterizes fixed predictions by verifying recourse over an \emph{entire region} of the feature space (e.g., all plausible job applicants). 
We introduce the first approach to accomplish this task by leveraging tools from Mixed-Integer Quadratically Constrained Programming (MIQCP). Our approach can identify \emph{confined regions} (i.e., where all individuals are assigned a fixed prediction) within the feature space, or provide a formal certification of model responsiveness over the entire region. Our approach is robust to distribution shifts, interpretable, and runs in seconds on real-world datasets.  Moreover, our tool can be used without the need for available datasets. This enables practitioners to audit model responsiveness in settings with only model access and a description of the population on which it is being deployed. For instance, many interpretable medical and criminal justice scoring systems are available publicly~\citep[see e.g.,][]{morrison2022optimized, yamga2023optimized, ribeiro2023use, PennSentence}, but gaining access to a representative dataset is difficult due to privacy concerns. 

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{figures/overview_figure.pdf}
    \vspace{-2em}
    \caption{Sample recourse verification task. The feature space (1) defines all possible feature vectors $\mathbf{x}$. The region of interest (2) is a subset of the feature space representing individuals on which to audit recourse. The action set (3) defines a set of constraints on what actions $\mathbf{a}$ individuals can take to change their prediction under a classifier (4). A confined region (5) is a subset of the region of interest in which all individuals are assigned a fixed prediction. Confined regions depend on both the classifier and the action set.}
    \label{fig:summary}
    \vspace{-1em}
\end{figure*}

The main contributions of this work include:
%
\begin{enumerate}[leftmargin=*,itemsep=0pt]
    % Conceptual Contributions
    \item We introduce a new approach to formally verify recourse %for linear classifiers 
    over entire regions of the feature space. This tool can be used certify the responsiveness of classifiers beyond data present in a training dataset and can provide stronger guarantees for out-of-sample data. We also present tools to find (or enumerate all) confined regions in the feature space, providing an intuitive tool for model developers to audit and correct problems with model responsiveness.

    % Method Constribution
    \item We develop fast methods that are able to find confined regions via MIQCP. Our approach handles a broad class of actionability constraints, and can verify recourse within seconds on real-world datasets.
    
    % Empirical Contribution
    \item We evaluate our approach on applications in consumer finance, content moderation, and criminal justice. Our results show that point-wise verification approaches fail to verify model responsiveness over regions, emphasizing the need for tools that audit recourse beyond individual data points. We also showcase the ability of our approach to audit model responsiveness in settings with no public datasets via a case-study on the Pennsylvania criminal justice sentencing risk assessment instrument.

    % Software
    %\item We include a Python implementation of our approach that builds upon existing APIs for actionable recourse, allowing practitioners to easily specify complex actionability constraints and audit recourse.
    
\end{enumerate}


