\paragraph{Related Work}

% Recourser verification Literature
Our work introduces a new direction for algorithmic recourse (also known as counterfactual explanations) \cite{venkatasubramanian2020philosophical, karimi2020survey}. We build on a line of work that has focused on generating \emph{actionable} recourse under hard constraints on what actions can be made \cite{ustun2019actionable, russell2019efficient, mahajan2019preserving, mothilal2020explaining, kanamori2021ordered, karimi2020model}. Recent work has highlighted that under \emph{inherent} actionability constraints, ML models may assign fixed predictions that preclude access for individuals \cite{kothari2023prediction, dominguez2022adversarial, karimi2021algorithmic}. While these works have highlighted the problem of fixed predictions, no existing work has attempted to characterize regions in which this phenomenon occurs for a given classifier.

Most of the existing work on algorithmic recourse has focused on providing or verifying recourse for individuals. These approaches fail to provide a high level understanding of recourse (i.e., what actions are needed for what types of individuals) which can be used by stakeholders to interpret and calibrate their trust in the underlying ML model. Motivated by this shortcoming, recent work has studied the problem of generating a global summary of recourse via either mapping individuals to a fixed number of possible actions \cite{lodi2024one, ley2023globe, warren2024explaining}, limiting the number of features that can be used in recourse across all instances \cite{carrizosa2024generating}, or providing an interpretable summary of potential recourse options for different sub-groups \cite{rawal2020beyond}. Our work is fundamentally different from these approaches in that we aim to find and characterize confined regions (i.e., interpretable regions in the feature population without recourse) instead of global actions (i.e., interpretable regions in the action space). Our approach also formally certifies recourse over an entire region, whereas existing approaches provide no out-of-sample guarantees.

More broadly, our work builds on a line of research that has focused on algorithmic recourse as a tool to safeguard access in applications such as hiring and lending. Towards this aim, other work has studied how to generate recourse that is robust to model updates \cite{upadhyay2021towards, forel2024don}, distributional shifts \cite{altmeyer2023endogenous, guo2022rocoursenet, hardt2023algorithmic, o2022toward, rawal2020algorithmic}, imperfect adherence to the prescribed recourse \cite{pawelczyk2022algorithmic, virgolin2023robustness, maragno2024finding}, and causal effects \cite{mahajan2019preserving, karimi2020algorithmic, kleinberg2020classifiers}. 
