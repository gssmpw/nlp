\section{Problem Statement}
\begin{table*}[t]
    \centering
    \resizebox{\linewidth}{!}{
    \input{tables/constraint_table}
    }
    \caption{Examples of deterministic actionability constraints. Each constraint can be expressed in natural language and modeled using standard tools from mathematical programming~\citep[see e.g.,][]{wolsey2020integer}.} \label{Table::ActionabilityConstraintsCatalog}
    \vspace{-1em}
\end{table*}


We consider a classification task of predicting a label $y \in \{0,1\}$ from a set of $d$ features $\mathbf{x} = [x_1, x_2, \dots, x_d ] \in {\cal X}$ in a bounded set feature set ${\cal X}$. We study linear classification models, a broad function class encompassing popular methods such as logistic regression, linearizable rule-based models (e.g., rule sets, decision lists), and concept-bottleneck models \cite{koh2020concept, sun2024concept}. We assume access to the linear classifier $f(\mathbf{x}) = \text{sign}(\mathbf{w}^\top\mathbf{x} + b)$ where $\mathbf{w} \in \mathbb{R}^d$ is the vector of coefficients and $b \in \mathbb{R}$ is the intercept of the classifier. Without loss of generality, we assume $f(\mathbf{x}) = 1$ is the desired outcome (e.g., receiving a loan). We use boldface variables (e.g., $\mathbf{x}$) to denote vectors, and standard text with subscripts (e.g., $x_d$) to denote a specific element of a vector. 

\paragraph{Actionability Constraints}
The recourse verification problem \citep{kothari2023prediction} tests whether an individual $\mathbf{x} \in \mathbb{R}^d$ can obtain the desired outcome of a model by \emph{actions} on their features. Each action is a vector $\mathbf{a} \in \mathbb{R}^{d}$ that shifts the features of the individual to $\mathbf{x} + \mathbf{a} = \mathbf{x}' \in {\cal X}$. We refer to the set of all actions an individual $\mathbf{x}$ can take as the \emph{action set} $A(\mathbf{x})$. In practice, an action set is represented by a set of constraints. \cref{Table::ActionabilityConstraintsCatalog} %\citep[originally presented in][]{kothari2023prediction} 
%
shows sample deterministic actionability constraints represented in both natural language and mathematical formulae that can be embedded into an optimization problem. Actionability constraints can capture inherent limitations on how semantically meaningful features can change (e.g., \textds{age} can only increase) and how those changes impact other features (e.g., increasing \textds{years of account history} also increase \textds{age}).

We summarize all feasible actions that lead to the desirable outcome for an individual in the recourse set.
\begin{definition}
The \emph{recourse set} consists of all feasible actions for an individual $x$ that lead to the desired outcome:%
$$\mathtt{Recourse}(\mathbf{x}, f, A) = \{a: f(\mathbf{x} + \mathbf{a}) = 1, \mathbf{a} \in A(\mathbf{x})\}$$
\end{definition}

We say an individual receives a fixed prediction under a classifier $f$ and action set $A$ if $\mathtt{Recourse}(\mathbf{x}, f, A) = \emptyset$, and has recourse if $|\mathtt{Recourse}(\mathbf{x}, f, A)| \geq 1$

%Note that in our setting, the region of potential individuals after taking an action ${\cal R}'$ may be different than the original region. For instance, we may want to verify recourse for individuals coming from a sub-population within a larger dataset (e.g., job applicants under 18 years old), but only want to constrain that the resulting feature vector is within the original population (e.g., resembles a realistic job application). 

\paragraph{Verification with Regions} This paper studies the problem of verifying recourse over an entire region of the feature space ${\cal R} \subseteq {\cal X}$. This region could represent plausible characteristics of decision subjects (e.g., any loan applicants), or a sub-group of interest (e.g., all Black female loan applicants). 

We start by generalizing the notions of recourse and fixed predictions to regions instead of individual data points.

\begin{definition}
A region ${\cal R}$ is \emph{responsive} under a classifier $f$ and action set $A$ if all individuals within the region have recourse. A region ${\cal R}$ is \emph{confined} if all individuals within the region have a fixed prediction. %Formally, $\forall x \in {\cal R}$: $\mathtt{Recourse}(x, f, A) \neq \emptyset$.
%Formally, $\forall x \in {\cal R}$: $\mathtt{Recourse}(x, f, A) \neq \emptyset$.
\end{definition}
%\begin{definition}
%A region ${\cal R}$ is \emph{confined} under a classifier $f$ and action set $A$ if all individuals within the region have a fixed prediction. Formally, $\forall x \in {\cal R}$: $\mathtt{Recourse}(x, f, A) = \emptyset$.
%\end{definition}
Note that a region is responsive if \emph{all} individuals within the region have recourse. Similarly, a region is only confined if all individuals are assigned fixed predictions.  If the region contains a mix of individuals with recourse and fixed predictions, the region is neither confined nor fixed.

The goal of the \emph{Region Recourse Verification Problem (RVP)} is to certify whether a given region ${\cal R}$ is confined, responsive, or neither. This task can be cast as an optimization problem that finds the largest confined area ${\cal S}(f, A)$ within the region ${\cal S} \subseteq {\cal R}$. For simplicity, we drop the explicit dependence of ${\cal S}$ on $(f, A)$. Let $\text{Size}({\cal S})$ be a function that quantifies the size of the confined area ${\cal S}$. Given a region ${\cal R}$, a classifier $f$, and an action set $A$, the RVP can be modeled as the following optimization problem:
\begin{align*}
\begin{split}
        \maximize_{{\cal S}}\quad& \text{Size}({\cal S})\\
        \st\quad & \forall x \in {\cal S}: \mathtt{Recourse}(x, f, A)= \emptyset\\
        & {\cal S} \subseteq {\cal R}
\end{split}
\end{align*}

An optimal solution to this optimization problem, ${\cal S}^*$, can be used to directly verify whether the entire region ${\cal R}$ is confined, responsive, or neither:
\begin{align*}
    \Verify{{\cal S}^*}{{\cal R}} = \begin{cases}
        \flagyes, & \textrm{if ${\cal S}^* = \emptyset$} \\
        \flagno,  & \textrm{if ${\cal S}^* = {\cal R}$} \\
        \flagidk{}, & \textrm{otherwise}
    \end{cases}%
\end{align*}


\textbf{Use Cases} Verifying recourse over regions is a powerful tool that can be used to catch potential harms that arise from fixed predictions \emph{before} deploying a model, characterize confined regions, and audit discrimination.

% Case should cover responsive + confined
\emph{Detecting Harms before Deployment.} Existing approaches that verify recourse for individual data points may fail to find confined regions before deploying a model, especially in settings with large distribution shifts. This failure can result in tangible harms such as precluding individuals from receiving loans or allowing malicious actors to bypass content filters. Verifying recourse over regions can catch these harms during model development and allow model developers to adjust the model before deployment. 

\emph{Characterizing Confined Regions.} The RVP can be run sequentially to enumerate all confined boxes in a region for a classifier. These boxes are simple to understand and can be used to help model developers debug ML models or provide a high-level summary of confined regions for stakeholders. These confined boxes can also be used to construct a valid (lower) bound on the fraction of the region that is confined. This can be used by model developers as a metric to compare two potential ML models before deployment.

\emph{Data-Free Auditing.} Recourse verification over regions can be used as a tool to find sources of potential discrimination in a model (e.g., individuals that are assigned fixed predictions in a lending application). This approach only requires access to a classifier and a description of the region to audit (which can be as simple as bounds on each feature). This allows external auditors to evaluate the responsiveness of a classifier with \emph{no access to the underlying data}. This is especially powerful in applications where models are publicly available but associated data is not (e.g., criminal justice \cite{PennSentence} and medicine \cite{yamga2023optimized}). 

\paragraph{Pitfalls of Auditing by Observation}
Existing methods for recourse verification \citep[e.g.,][]{kothari2023prediction} can only verify recourse for observed data (e.g., individuals in a training dataset). These point-wise approaches can be used to audit the responsiveness of a region by verifying whether any observed data points are assigned a fixed predictions. However, these approaches may fail to correctly output whether a region is responsive or confined. We outline two kinds of failures:

\begin{definition}
Given a recourse verification task for a region ${\cal R}$, a model $f$, and action set $A$, we say that a method returns a \emph{blindspot} if it outputs that a region is responsive but there exists an individual in the region that is assigned a fixed prediction.
\end{definition}
%
\begin{definition}
Given a recourse verification task for a region ${\cal R}$, a model $f$, and action set $A$, we say that a method returns a \emph{loophole} if it outputs that a region is confined but there exists an individual in the region with recourse.
\end{definition}

These failure modes can arise when an audit over observed data does not reveal all potential individuals within the region. In Section \ref{sec:exp} we show that this can occur with a variety of different strategies to select data to test within a region.

