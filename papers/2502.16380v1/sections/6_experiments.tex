\section{Experiments} \label{sec:exp}


%We present experiments to show that approaches that verify recourse over individual data points fail to guarantee responsiveness over entire regions. 
We present experiments showing that point-wise approaches fail to correctly find confined regions,
while our methods to audit recourse over regions accurately find such regions when they exist. 
Hence our methods can help decision-makers avoid harms from deploying models with fixed predictions.
We include code to reproduce our results at \url{\repourl} and provide additional details and results in \cref{app:experiments}.
%https://github.com/conlaw/confined_regions
%https://anonymous.4open.science/r/confined_regions-6A8D

\paragraph{Setup}

We evaluate our approach on three real-world datasets in consumer finance (\textds{heloc} \cite{fico}, \textds{givemecredit}\cite{data2018givemecredit}) and content moderation (\textds{twitterbot} \cite{twitterbot}). %For the consumer finance applications, data points without recourse represent individuals that are precluded from credit access. For the content moderation application data points without recourse represent users that cannot pass a bot filter (i.e., will always be marked as bots). 
%
%Each dataset includes a set of features that admit actionability constraints encompassing both separable constraints (i.e., constraints that only act on a single feature) and non-separable constraints (i.e., constraints that act over a set of features). 
Each dataset include features that admit \emph{inherent} actionability constraints that apply to all individuals (e.g., preserving feature encoding) which we use to construct the action set (see \cref{app:experiments} for details). %Note that across all three datasets, we find only two constraints, both on the \textds{heloc} dataset, that do not meet the linear recourse criteria outlined in Section \ref{sec:scaling}. For the \textds{heloc} dataset, this requires considering 4 continuous restrictions in the FCP (i.e., $|{\cal C}| = 4$). 
%
We encode all categorical features using a one-hot encoding and discretize all continuous features. We split the processed dataset into a training sample (50\% used to train the model), and an audit sample (used to evaluate responsiveness in deployment). 

We use the training dataset to fit a $\ell_1$-regularized logistic regression model and tune its parameters via cross-validation.
%
%We audit a set of regions which represent sub-populations of interest within the dataset. 
We use the auditing dataset to verify recourse over a set of regions $\Omega$ that represent different sub-groups of interest for the classification task. We generate these regions ${\cal R} \in \Omega$ by restricting the feature space to fixed combinations of immutable characteristics  (e.g., all individuals with a specified age and gender). 
We remove all regions from $\Omega$ that do not have at least 5 data points in the training dataset. The fraction of data points with fixed predictions ($p$) in the each dataset varies between $10-55\%$. We represent the feature space ${\cal X}$ for each dataset as the smallest box containing all available data.

% Actionability constraints 
%Note that the size of the reachability set generated by Reach \cite{kothari2023prediction} scales with the number of possible values a data point can take. Consequently many of the continuous features are encoded via a thermometer encoding. These encodings can improve the predictive performance of the model when there is a non-linear relationship between the input feature and target. We experimented with encoding continuous features with either thermometer encodings or integer values and use the encoding with the best predictive performance. \connor{Add table (maybe to appendix) that shows fraction of each dataset without recourse.}

% Benchmark Algorithms
% - IP to find recourse
% - AR with additional non-separable constraints
% - Synthetic extreme points
% - all data points
%We benchmark against a procedure that audits recourse for a given data point. To audit recourse for a single data point we solve the PREP for a fixed data point $\mathbf{x}$ (i.e., set $\mathbf{u} = \mathbf{l} = \mathbf{x}$). This can be viewed as an extension of AR \cite{ustun2019actionable} that incorporates additional non-separable constraints and uses a constant cost function. We denote this procedure \textit{AR}$_+$. We leverage AR$_+$ to audit recourse over a population of individuals by running it on every data point $x \in {\cal D}$ that is in the negative class. Note that if the goal is to find a single data point without recourse, this provides an upper bound on the worst-case time to audit on the dataset which is tight in settings where every data point has recourse. In settings where the dataset may be censored or missing data from regions without recourse simply auditing recourse on ${\cal D}$ is insufficient to certify recourse on the broader population. We use synthetic data to augment the dataset to include all possible data points in ${\cal X}$ - note that there are up to $\prod_d |{\cal F}_d|$ such data points. In settings that meet our linear recourse criteria we can further relax this to look only at extreme points of ${\cal X}$ (i.e., data points where $x_d = l_d$ or $x_d = u_d$).
%While there are currently no existing methods that are able to audit recourse over a given region, 
%
\paragraph{Methods} We compare our method to pointwise baselines that audit recourse over a sample of individual data points to generate outputs for the entire region. Given a sample of individual data points, these point-wise approaches output that a region is responsive (confined) if all data points have recourse (no recourse). We generate different baselines by using different strategies to select which individual data points to include in the sample.
\begin{itemize}[leftmargin=*, itemsep=0pt]
    \item \baseline{Data}: We use all data points from the training dataset that fall within the region.
    \item \baseline{Region}: We sample 100 data points uniformly at random from the region being audited.
    \item \baseline{Score}: We evaluate the data points within the region with the highest and lowest classifier score (i.e. $\argmax_{x} w^T x$ and  $\argmin_{x} w^T x$). %This heuristic is motivated by the intuition that data points with the smallest (largest) classifier score are more likely to have a fixed prediction (recourse).
    \item \us{}: We implement our approach, \textbf{Re}gion \textbf{Ver}ification (\us{}), in Python using Gurobi \cite{achterberg2019gurobi} to solve all MIQCPs. 
\end{itemize} 



%To audit recourse for a single data point we solve a MILP (detailed in Appendix \ref{app:rep_form}) that checks whether the individual has feasible recourse. This can be viewed as an extension of AR \cite{ustun2019actionable} that incorporates additional non-separable constraints and uses a constant cost function. Given a sample of individual data points, these individualized approaches output that a region is responsive (confined) if all data points have recourse (no recourse). These baselines abstain from making an output if the sample contains a mix of data points with and without recourse. We generate different baselines by using different strategies to select which individual data points to sample:



\paragraph{Results}
\iftoggle{icml}{
\begin{table}[t!]
    \centering
    %\resizebox{0.9\textwidth}{!}{\input{tables/results_table}}
    \resizebox{\linewidth}{!}{\input{tables/results_table_new}}
    \caption{Overview of results for all datasets, regions, and methods. For each dataset, we include the number of regions we audit ($|\Omega|$), and the fraction of data points with fixed predictions ($p$). }
    \label{tab:experimental_results}
\end{table}
}
\iftoggle{arxiv}{
%\begin{wraptable}[23]{r}{0.5\textwidth}
\begin{table}[t!]
    \centering
    %\resizebox{0.9\textwidth}{!}{\input{tables/results_table}}
    \resizebox{0.7\linewidth}{!}{\input{tables/results_table_new}}
    \caption{Overview of results for all datasets, regions, and methods. For each dataset, we include the number of regions we audit ($|\Omega|$), and the fraction of data points with fixed predictions ($p$). }
    \label{tab:experimental_results}
%\end{wraptable}
\end{table}
}

We summarize our results in Table \ref{tab:experimental_results} for all datasets and methods. We use \us{} to certify whether each region is responsive, confined, or neither. We use these results to evaluate the reliability of baseline methods. We evaluate each method in terms of the percentage of regions where it: \emph{certifies responsive}, \emph{outputs responsive}, outputs a \emph{blindspot} (i.e., misses individuals in the region with fixed predictions), \emph{certifies confined}, \emph{outputs confined}, and outputs a \emph{loophole} (i.e., misses individuals in the region with recourse). Additional metrics are reported in Appendix \ref{app:experiments}.

\paragraph{On Preempting Harms during Model Development} Our results demonstrate that individualized recourse verification approaches fail to properly predict whether a region is responsive or confined. All baseline approaches result in blindspots, ranging from 2.8\% to 37.4\% of regions, and loopholes, ranging from 0.6\% to 20\% of regions. The baseline approaches incorporate both separable and non-separable actionability constraints. Consequently, these blindspots and loopholes arise from focusing on individual data points instead of the region as a whole and highlight the importance of region-specific methods. In Appendix \ref{app:distribution_shift} we show that these failures are exacerbated in settings whether there is a distribution shift in the test dataset.

Blindspots and loopholes represent failure cases that undermine the benefits of algorithmic recourse and lead to tangible harms if left undetected in model development. Consider a content moderation setting where a machine learning model is used to remove sensitive content. A loophole could represent malicious content (e.g., discriminatory or offensive content) that is able to bypass the filter by changing superficial features of the post. In a consumer finance application, a blindspot represents unanticipated individuals that receive fixed predictions and are precluded from ever getting access to a loan. In both these settings, rectifying the problem after deployment would involve training a new machine learning model (e.g., by dropping features that lead to fixed predictions, or adding new features that promote actionability) which can be time-consuming, costly, and continues to inflict harm while the existing model operates. This highlights the importance of auditing recourse over regions --- it foresees potential harms that occur when deployed models assign fixed predictions.

\iftoggle{icml}{
\begin{figure}
      \centering
      \includegraphics[width=0.49\textwidth]{figures/coverage.pdf}
      \vspace{-1cm}
  \caption {\label{fig:coverage_curve} Percentage of feasible points in the region with a fixed prediction as a function of the number of confined boxes generated. Note that any point is a valid lower bound on the percentage of points with fixed predictions across the entire region. }
\end{figure}
}
\iftoggle{arxiv}{
%\begin{wrapfigure}[19]{r}{0.45\textwidth}
\begin{figure}
      \centering
      \includegraphics[width=0.5\textwidth]{figures/coverage.pdf}
  \caption {\label{fig:coverage_curve} Percentage of feasible points in the region with a fixed prediction as a function of the number of confined boxes generated. Note that any point is a valid lower bound on the percentage of points with fixed predictions across the entire region. }
\end{figure}
%\end{wrapfigure}
}

\paragraph{On Characterizing Fixed Predictions}
In \cref{subsec:case} we show sample regions that our algorithm certifies as confined. These regions are represented by simple decision rules (e.g., `Age 21-25 and Maleâ€™) and can help model developers debug the sources of fixed predictions.  For instance, the latter example may prompt a model developer to remove features related to age and gender from the dataset.

In some settings, fixed predictions are rare and can be represented by a small number of regions (see e.g., the case study in Section \ref{subsec:case}). However, in complicated settings there may be a large a number of confined regions.
To demonstrate this phenomenon, we run our approach sequentially to enumerate up to 100 confined regions within our benchmark datasets. For each dataset, we audit a region encompassing any plausible individual (i.e., any individual satisfying indisputable conditions on each feature). Figure \ref{fig:coverage_curve} shows the fraction of the entire region covered after generating up to 100 confined regions using our approach. Note that any point on this curve represents a valid lower bound on the total fraction of the region that is assigned a fixed prediction. These lower bounds can be used by model developers to decide between alternative ML models for a given application. More broadly, our results highlight the scale and difficulty of fully characterizing confined regions. Although each dataset has fewer than 50 features, at least 100  regions are confined. Our results highlight that fixed predictions
arise in complex ways from immutable features. As such, they create an insidious new kind of discrimination: unlike traditional forms of discrimination based on protected characteristics (e.g., race and gender), this form of discrimination is much harder to identify, requires looking at combinations of features, and depends on the classifier.

\paragraph{On Computation}
Remarkably, \us{} runs in \emph{under 5 seconds} on average across all datasets (see Appendix \ref{app:experiments}). This shows that although region verification is more computationally challenging than individual verification, our approach can certify region verification extremely quickly. On two thirds of the datasets, our approach is even faster than the \baseline{Region} baseline which audits 100 individual data points.

\section{Demonstration} 
\label{subsec:case}

\paragraph{Setup} We showcase the potential of \us{} as a tool for auditing potential discrimination via a case study of the Pennsylvania Criminal Justice Sentencing Risk Assessment Instrument (SRAI) \cite{PennSentence}. The SRAI is a simple linear scoring system that uses 37 features, including age and gender, to predict the risk of an offender committing a re-offense (i.e., criminal recidivism). The guidelines state that an offender is deemed low-risk if the SRAI risk score is under 5 points. %Note that while the SRAI is publically available (and included directly in the Pennsylvania code), to the best of our knowledge there are no readily available public datasets of previous offenders associated with the tool. 

We use \us{} as a tool to audit whether there are any protected groups that are precluded from being predicted as low-risk. To that end, we specify an action set that does not allow changes to protected characteristics (i.e., age and gender), and enforces logical constraints on the features (e.g., to have a prior conviction for violent crime the number of previous convictions needs to be at least one). Full details of the actionability constraints are included in Appendix \ref{app:case_study}. Note that we allow every \emph{unprotected} characteristic (i.e., criminal history) to be mutable. This choice allows us to answer whether any protected group, based solely on protected characteristics, is never predicted to be low risk. 

\paragraph{Results} %The results of our audit are included in Figure \ref{fig:sample_regions}. 
\us{} finds two confined regions:

\begin{figure}[!h]
    \centering
    \begin{subfigure}
      \centering
      \includegraphics[width=0.4\textwidth]{figures/sample_regions_small.pdf}
    \end{subfigure}
  %\caption {All confined boxes for the Pennsylvania SRAI. A confined region represented a protected group that will never be predicted as low risk for recidivism. \label{fig:sample_regions}}
\end{figure}

 %(1) Anyone with age under 21, and (2) Men with age 21-25. 
 Our results highlight that the SRAI discriminates against individuals on the basis of gender and age by precluding those groups from ever receiving a desirable outcome. 
 Our tool is able to find these forms of discrimination and present an interpretable summary of the results to stakeholders, who must then gauge whether this form of discrimination should be allowed in the criminal justice context. 
 Notably, our audit required no access to the data that was used to develop the SRAI: \us{} is easy for external auditors to run when models are publicly available but data is not, as in contexts like criminal justice and medicine. %Our results also highlight the importance of considering actionability constraints that affect multiple features. Running \us{} for the same model but with only constraints on the actionability of protected characteristics (i.e., no logical constraints on features), outputs only on region with fixed predictions: Men with age under 21. 

%\begin{figure}[t]
%\centering
%\resizebox{0.8\linewidth}{!}{
%\begin{tabular}{ll}
%\textbf{Rule} & \textbf{Coverage} \\
%\toprule
%\texttt{Age $<$ 21} & 16.7\% \\
%\texttt{Age 21-25} $\land$ \texttt{Male} & 8.7\% \\
%\end{tabular}
%}
%\caption {All confined regions for the Pennsylvania SRAI.}
%\end{figure}