Machine learning models are designed to predict outcomes using \emph{features} about an individual, but fail to take into account how individuals can change them. Consequently, models can assign \emph{fixed predictions} that deny individuals \emph{recourse} to change their outcome. This work develops a new paradigm to identify fixed predictions by finding \emph{confined regions} in which all individuals receive fixed predictions. We introduce the first method,
\us{}, for this task, using tools from mixed-integer quadratically constrained programming. Our approach certifies recourse for out-of-sample data, provides interpretable descriptions of confined regions, and runs in seconds on real world datasets. We conduct a comprehensive empirical study of confined regions across diverse applications. Our results highlight that existing point-wise verification methods fail to discover confined regions, while \us{} provably succeeds.



