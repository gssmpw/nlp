\section{RELATED WORK}
\subsection{Humanoid Locomotion}

Research on humanoid locomotion can be traced back to the 1970s \cite{Kato1974InformationPower}. The fundamental idea for a locomotion controller is to decompose it into planning and tracking modules, where the planning module is responsible for generating desired trajectories and the tracking module ensures that the robot follows these trajectories accurately \cite{grandia2023perceptive,meduri2023biconmp}. Methods such as Whole-Body Control (WBC) and Model Predictive Control (MPC) have achieved significant success in this domain \cite{li2023multi,sentis2006whole,sleiman2021unified}. However, these methods typically require precise modeling of the dynamics \cite{koenemann2015whole,schultz2009modeling}, which poses substantial challenges for complex robot structures. In recent years, learning-based algorithms have emerged as a promising alternative to legged locomotion \cite{HumanGym1,ha2024learning} with efficient parallel simulation \cite{Learning-to-walk}, significantly reducing the cost of interaction between the robot and the environment. Policies trained extensively in simulation environments can then be transferred to real robots \cite{he2024bridging}. In the field of quadrupedal locomotion, RL algorithms have demonstrated excellent performance in complex tasks such as complex-terrain walking \cite{levy2024learning,shi2024robust}, gait control \cite{han2024lifelike,huang2024diffuseloco}, and even parkour \cite{zhuang2023robot,cheng2024extreme}. 

For RL-based humanoid locomotion, things become more difficult due to their limited support areas and high center of gravity. Meanwhile, classical control algorithms are also limited by the inaccurate modeling of the complex dynamical system. Recent approaches have proposed using RL algorithms for phase-based gait learning \cite{HumanGym2,HugWBC}, motor skill control \cite{decentralized,hilo}, and motion imitation \cite{AMP,embrace}. However, these methods still lags far behind that of humans in terms of dynamic balance under complex terrain (e.g., narrow paths) and extreme conditions (e.g., sudden disturbance). In our work, we address this problem by measuring the relationship between the ZMP and the humanoid support polygon in an RL framework. 
We note that a concurrent work uses foothold rewards to pass through narrow areas, while it relies on a LiDAR-based elevation map for real-world deployment \cite{wang2024beamdojo}. In contrast, our method can traverse complex terrains only using proprioception without vision or LiDAR perception.
% \cite{legged-vision,hoeller2024anymal}.


\subsection{Zero Moment Point}

ZMP became a crucial tool in classical humanoid locomotion a few decades ago \cite{ZMP-1}, which provides a framework for ensuring dynamic stability in bipedal robots. Formally, ZMP is defined as the point on the ground at which the net moment of the inertial forces and the gravity forces has no component along the horizontal axes \cite{ZMP-2}. In subsequent research, the ZMP concept has been instrumental in gait synthesis and has been integrated with advanced sensors to facilitate real-time balance adjustments \cite{ZIP-35}. In addition, it has inspired the exploration of innovative materials and foot designs to enhance the interaction of robots \cite{ZMP-book}. 
% Further, the definition of ZMP has been used for gain synthesis, and has also been integrated with advanced sensors for real-time balance adjustment . 
In our work, we extend the ZMP as a reward function to measure the relationship between the line of ZMPs and the support polygon, which enables the humanoid to maintain dynamic balance in complex terrains without relying on external perception.