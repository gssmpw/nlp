\section{Background and Related work
\draftStatus{barring audits, R+R DONE}
}

\revised{%
Understanding privacy policies is crucial for empowering users to make informed decisions about their personal data.
This section explores the challenges users face with privacy policies, the role of social media and data collection practices in shaping attitudes, and the psychological and behavioral factors that influence engagement.
It also highlights innovative approaches that aim to enhance user comprehension and trust, such as annotated policies and visual aids.

\boldify{How comfortable are folks with data collection/sales/etc?}

Websites profit from people's trust by selling, sharing, or analyzing personal information~\cite{torbert2021because}.
Goldfarb and Que~\cite{goldfarb2023economics} explore the significant economic value of digital privacy, demonstrating how consumer privacy preferences shape business strategies and market dynamics.
They also examine the impact of privacy regulations on competition and innovation, highlighting the role of policy in fostering privacy-preserving technologies and balancing consumer protection with economic growth.
Melicher et al.~\cite{melicher2016preferences} discovered that slightly over half of the participants (51\%) felt that information about their general searching activities significantly impacted their feelings about tracking.
This finding underscores the importance of addressing user concerns in privacy policy design to enhance trust and compliance.
} % end revised
Another study has found that websites' failure to protect consumers' personal information has harmed their trust in the company~\cite{pilton2021evaluating}.
Americans have varied attitudes about companies using their personal information to build new products: 50\% of people are at least somewhat comfortable, while 49\% are extremely uncomfortable~\cite{lippi2019claudette}.
The general public is more comfortable with companies using their personal information for some purposes than for others.
As an example, some people are extremely or somewhat comfortable with businesses using their personal information to help them improve their fraud protection systems~\cite{auxier2019americans}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The role of social media apps}

\boldify{Social Media is popular, but a big data vacuuming system}

Facebook, Instagram, Twitter, and TikTok are now common tools for communication, information retrieval, and entertainment, 
\revised{%
which exerts a strong pull on attitudes about data collection.
} % end revised
Statista~\cite{statista} noted that as of 2022, the global user base of social media platforms exceeded 4.26 billion individuals, emphasizing their widespread presence.
The fundamental impetus for using social media is the desire for social interaction.
According to Ellison et al.~\cite{ellison2007benefits}, social networking sites (SNS) offer users the chance to preserve current relationships, establish new connections, and develop social capital.
Hermida et al.~\cite{hermida2012share} observed that Twitter has a substantial impact on spreading news and enabling immediate conversations about current events.
Social media's ability to quickly and widely disseminate information is the core added value, but it also raises questions about the authenticity and dependability of the shared content.

\boldify{Ad targeting is a big factor in the social media profit model}

The monetization of social media applications also has a crucial impact on users' experience.
These platforms specifically target consumers with customized advertisements based on their online behavior and preferences.
Social media marketing has become an essential element of corporate strategies, enabling organizations to directly interact with consumers and cultivate brand loyalty~\cite{kaplan2010users}.
Although targeted ads can improve the user's experience by offering appropriate material, they also give rise to privacy concerns about the data collection that informs targeting.
Golbeck and Mauriello~\cite{golbeck2016} conducted a study on the privacy concerns of Facebook users to gauge how informed they are about the use of their data.
The study revealed that initially, users were not aware of how platforms use their data, and once that information surfaced, their concern about data privacy increased---with differences in the educational value of their treatments:
reading the document (worst results), interacting with an app, and a film with horror stylings (best results).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{User's knowledge and attitudes about data collection practices}

\boldify{What factors seem to make people more or less willing to opt in?}

\revised{%
According to Earp et al.~\cite{earp2005examining}, people are more likely to read and understand privacy regulations when they perceive a significant risk to their personal data.
This conclusion flows from their examination of user attitudes toward privacy policies, which revealed that individuals' involvement with these policies increases when they feel that their data is under threat.
Additionally, Earp et al.\ found that users' trust in the organizations responsible for the policies plays a critical role, as higher trust often correlates with lower scrutiny of the policy details.
} % end revised
Bansal et al.~\cite{bansal2010impact} emphasize that implementing transparent and unambiguous privacy practices can establish confidence.
In contrast, confidence decreases when people think that the organization lacks openness or has a poor track record.
Those authors demonstrate that perceived reliability and trustworthiness play a crucial role in shaping user attitudes toward data collection, ultimately affecting their inclination to share personal information~\cite{bansal2010impact}.
Occasionally, trust can override privacy concerns, resulting in a misleading perception of safety.
For example, researchers examined the Facebook-Cambridge Analytica scandal, emphasizing its impact on user data privacy and the critical need for enhanced privacy protection measures~\cite{isaak2018user}.

A multitude of other hacks and data breaches demonstrate that even well-regarded institutions can mishandle or inadequately safeguard user data.
We will provide a few famous and large-scale examples
In 2017, Equifax, a prominent credit reporting agency, suffered a security breach that compromised the confidentiality of sensitive personal data, such as Social Security numbers, addresses, and birth dates, belonging to more than 147 million individuals~\cite{bernard2017equifax}.
In the same year, Sony had a massive security breach on its PlayStation Network, resulting in the exposure of personal information, including credit card data, of 77 million customers~\cite{wilton2017sony}. 

\boldify{So if a barrier is actually reading/knowledge, why don't they do that?}

Many users are frequently oblivious to the full scope of data collection conducted by different platforms and services.
Milne et al.~\cite{milne2004consumers} indicates that a substantial proportion of users lack awareness or comprehension of data-gathering processes.
Prior work indicates that a substantial number of users fail to read privacy policies because they find them too complicated and lengthy~\cite{acquisti2015privacy}.
An empirical analysis found that only a few participants read all or almost all of the terms' main reason for not reading being, boring and tedious to read~\cite{maronick2014consumers}.
According to a study from Smith et al.~\cite{smith1996information}, individuals who know the methods of collecting data typically experience a feeling of intrusion and a lack of control over their personal information.
Further, users may provide personal information impulsively, without considering the long-term privacy risks.
Taddicken~\cite{taddicken2014privacy} discovered that the convenience and incentives provided by these platforms frequently surpass privacy worries, resulting in a greater probability of users revealing personal information.
Heuristic cues such as mental shortcuts in the online world may subconsciously lead users to give personal information despite privacy concerns~\cite{sundar2013unlocking}.
Last, users frequently imitate the actions of their peers, particularly in social networking settings, where the sharing of personal information is widespread.
According to Debatin et al.~\cite{debatin2009facebook}, the need for social recognition and a sense of belonging can motivate users to participate in activities that compromise their privacy.

\boldify{Attitudes also seem to vary with data type}

The emotional reaction to data gathering is also affected by the perceived sensitivity of the data under consideration.
Users exhibit heightened worry about gathering personal and sensitive data, including financial information, medical records, and location data.
Based on a survey from Pew Research Center~\cite{pew2019privacy}, most users felt uncomfortable about the collection of their sensitive information.
Many of them had concerns about the possibility of data being misused or accessed without authorization.
To counteract this discomfort, incorporating privacy by design principles throughout the construction of digital services can effectively reduce privacy risks and ensure that user behaviors are in line with their stated privacy concerns~\cite{cavoukian2009privacy}.
The ToS has major legal implications, regardless of whether users understand them, as another court case demonstrates~\cite{2012davis}.
This lawsuit pertained to accusations against HSBC and Best Buy for deceiving California customers by failing to adequately disclose an annual fee for credit cards.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Usersâ€™ Opinions on Annotated Policies}

Offering users transparent and succinct information regarding the gathering and utilization of data might enable them to make well-informed choices.
The main objective of these annotations is to improve user understanding and provide informed consent by simplifying complex legal terminology into more accessible portions.
Research suggests that the inclusion of explanatory privacy rules greatly enhances consumers' comprehension and retention of information regarding data practices.
For example, Kelley et al.~\cite{kelley2010standardizing} showed that individuals who interacted with simplified privacy notifications better remembered the privacy practices of the websites they visited.
Further, people broadly misunderstand technical terms in privacy policies, reducing transparency and user comfort, highlighting the need for simpler language to enhance policy acceptance~\cite{Tang2021defining}.
To address these concerns, other research has found annotated privacy rules can enhance comprehension of important information~\cite{reidenberg2015disagreeable}.
However, simplification can have both positive and negative consequences, as it makes policy more accessible, but may also result in the omission of important elements.
For example, Bravo et al.~\cite{bravo2010bridging} discovered that some users held a misguided perception of safety, mistakenly thinking they have a complete understanding of a policy, while they know a portion (the annotated sections).

The level of trust that users have in annotated privacy policies likewise varies considerably.
According to Bansal et al.~\cite{bansal2010impact}, annotations have the potential to enhance trust when users perceive the content as sincere and transparent attempts to convey privacy standards.
On the other hand, if users have suspicions that annotations are deliberately creating a positive image by cherry-picking content, confidence can diminish.
Other researchers showed that the presence of transparency and perceived honesty notably influence consumers' acceptance and trust towards annotated privacy regulations~\cite{schaub2015design}.
\revised{%
One such transparency approach is from Shvartzshnaider et al.~\cite{shvartzshnaider2020beyond}, who proposed a framework for analyzing privacy policies using syntactic and semantic role labeling to extract privacy parameters such as sender, recipient, subject, and information type, grounded in the Contextual Integrity framework.
Their approach, tested on 36 real-world privacy policies, achieved an F1 score of 84\%, demonstrating the effectiveness of incorporating domain-specific knowledge into NLP models for privacy policy analysis.
Some efforts at measuring or increasing user understanding of privacy concepts specifically consider children, for example supporting improving children's comprehension of digital privacy via the same framework~\cite{kumar2020strengthening}.
} % end revised

Prior work observed a user preference for visual aids, such as icons and color-coded sections since they facilitated a rapid understanding of essential information~\cite{balebako2022nudging}.
However, depending on images without adequate explaining text can result in shallow comprehension, so it is important to accommodate various learning styles.
As an example, Milne et al.~\cite{milne2004consumers} emphasized that younger individuals exhibit greater receptiveness towards annotations and perceive them as more beneficial, in contrast to older individuals who often prefer conventional text styles.


