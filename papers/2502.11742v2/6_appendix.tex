\subsection{Data Preprocessing}
Data preprocessing is essential in cross-modal VPR, as it seeks to reduce modality differences and improve the overlap in visual content. Utilizing the methodologies outlined in ModaLink \cite{xie2024modalink} and Lip-Loc \cite{shubodh2024lip}, we perform a cropping of the RGB image along the horizontal direction at a predetermined position. In the KITTI dataset, an RGB image originally sized at (1226, 370) is cropped to (1226, 205). The complete 360° point cloud is cropped according to the camera's horizontal field-of-view, ensuring optimal visual content alignment between the processed images and point clouds. This step minimizes content discrepancies in retrieval processes.

Subsequently, range images are produced from point clouds utilizing established techniques, thereby accurately representing point cloud information in the vertical direction. The range images are subsequently aligned with the RGB images. Unobstructed information is integrated into both modalities by generating BEV representations. The cropped RGB image undergoes processing via a monocular depth prediction model to generate a depth prediction map. The Sobel operator is utilized for edge detection on the depth map to filter out ambiguous depth information along the edges. The refined depth map is subsequently transformed into a pseudo point cloud in the LiDAR coordinate system through the application of camera intrinsics, camera extrinsics, and the extrinsic parameters of LiDAR.

After acquiring the camera point clouds and LiDAR point clouds, ground points are eliminated to reduce noise. The point clouds are subsequently converted into BEV representations from a top-down perspective. In the I2P-Rec's setup \cite{zheng2023i2p}, the LiDAR coordinate system functions as the reference framework, with point clouds confined to defined coordinate ranges: the x-axis spans [0, 51.2m], the y-axis ranges from -25.6m to 25.6m, and the z-axis extends from -5.0m to 5.0m. The voxel size for the BEV image is established at 0.4m, yielding a final BEV image resolution of [128, 128]. This BEV representation effectively conveys orientation and scene topology information, clearly illustrating the spatial distribution of buildings and streets in autonomous driving contexts. The data preprocessing pipeline is displayed on the Fig. \ref{fig:datapreprocessing}.

\begin{figure*}[t]
    \centering
    \includegraphics[scale=0.32]{data_preprocessing_v1.png}
    \caption{The data preprocessing pipeline. (1) Top is the cropping process (2) Bottom displays the BEV image generation process.}
    \label{fig:datapreprocessing}
\end{figure*}


\subsection{Additional Ablation}
Our ablation studies primarily focus on evaluating the effects of several key factors: the base margin of the generalized triplet loss, the threshold for distance similarity in the points average distance method, and the impact of ground removal and noise removal algorithms. Both quantitative results and visualizations are provided to support our analysis.


\begin{table}[!t]
    \centering
    \caption{ABLATION STUDIES ON BASE MARGIN}
    \label{tab:AblationBM}
    \resizebox{6.5cm}{!}{
    \begin{tabular}{c|c|c}
    \hline
        & KITTI-00 & KITTI-02 \\ \hline
        Base Margin & R@1 / R@5 / R@1\% & R@1 / R@5 / R@1\% \\ \hline
        0.4 & 99.10 / 99.93 / 100.0 & 94.79 / 98.03 / 99.61 \\ 
        0.5 & 99.05 / 99.87 / 100.0  & 95.04 / 98.05 / 99.85 \\ 
        0.6 & 99.03 / 99.91 / 100.0 & 95.07 / 98.22 / 99.66 \\ 
        0.7 & 98.77 / 99.82 / 100.0 & 94.70 / 97.88 / 99.68 \\ 
        0.8 & 99.19 / 99.91 / 100.0 & 95.73 / 98.46 / 99.72 \\ \hline
    \end{tabular}}
\end{table}


As shown in Table \ref{tab:AblationBM}, the performance remains consistent despite changes in the base margin, indicating that the absolute scale of the delta value between the relative sample and the anchor sample is not critical—rather, it is the delta value itself that plays a crucial role.

\begin{table}[!t]
    \centering
    \caption{ABLATION STUDIES ON DISTANCE THRESHOLD}
    \label{tab:AblationDT}
    \resizebox{6.5cm}{!}{
    \begin{tabular}{c|c|c}
    \hline
        & KITTI-00 & KITTI-02 \\ \hline
        Dist\_sim\_th(m) & R@1 / R@5 / R@1\% & R@1 / R@5 / R@1\% \\ \hline
        2.5 & 98.00 / 99.96 / 100.0 & 92.86 / 97.66 / 99.61 \\ 
        5 & 98.61 / 99.93 / 100.0 & 95.19 / 98.13 / 99.76  \\ 
        7.5 & 99.03 / 99.91 / 100.0 & 95.07 / 98.22 / 99.66 \\ 
        10 & 98.68 / 99.80 / 100.0 & 94.79 / 97.77 / 99.61 \\ \hline
    \end{tabular}}
\end{table}


Additionally, Table \ref{tab:AblationDT} demonstrates that the optimal performance is achieved when the threshold for distance similarity is set to 7.5m. When this value is too high, it includes samples without any visual content overlap, leading to false positives. Conversely, when the value is too low, it disregards meaningful relationships between samples with actual appearance similarities.

\begin{figure*}[!t]
    \centering
    \includegraphics[scale=0.3]{noise_remove_v1.png}
    \caption{Examples of LiDAR BEV and Camera BEV with different processing.}
    \label{fig:NoiseRemove}
\end{figure*}

\begin{table}[!t]
    \centering
    \caption{ABLATION STUDIES ON GROUND-REMOVAL (RG) AND NOISE-REMOVAL (RN)}
    \label{tab:AblationR}
    \resizebox{7.5cm}{!}{
    \begin{tabular}{c|c|c}
    \hline
        & KITTI-00 & KITTI-02 \\ \hline
        Method & R@1 / R@5 / R@1\% & R@1 / R@5 / R@1\% \\ \hline
        Vanilla & 97.82 / 99.82 / 100.0 & 89.62 / 96.14 / 99.68 \\
        RG & 97.73 / 99.65 / 100.00 & 93.03 / 97.34 / 99.53 \\
        RG + RN (Sober) & 99.03 / 99.91 / 100.00 & 95.07 / 98.22 / 99.66 \\
        RG + RN (Canny) & 98.61 / 99.78 / 100.00 & 94.92 / 98.13 / 99.76 \\ \hline
    \end{tabular}}
\end{table}

At last, we emphasize the importance of the ground and noise removal process. To remove ground points from the point cloud, we employ the Patchwork++ \cite{lee2022patchworkpp} algorithm, while noise in the Camera BEV image, caused by ambiguous depth predictions at object edges, is detected using the Sober calculator provided by OpenCV \cite{bradski2008learning}. This method approximates the noise area and marks it as invalid during back-projection. The Canny edge detection algorithm is also employed to detect object edges and expand them based on depth values. In Table \ref{tab:AblationR}, we observe that removing both the ground points and noise simultaneously significantly improves the re-rank method’s performance, with the Sober calculator yielding the best results. Finally, Fig. \ref{fig:NoiseRemove} demonstrates that after removing the ground, the LiDAR and Camera BEV images become more similar, and using the Sober calculator effectively removes noise while preserving essential visual cues, outperforming the Canny edge detection method.