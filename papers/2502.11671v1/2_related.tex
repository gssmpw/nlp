\section{Related Work}
\vspace{-2mm}
\subsection{Textual Data Augmentation}
\vspace{-1mm}
Textual data augmentation revolves around perturbing the wording and syntax of existing sentences to create more modified samples. 
Some early and simple methods propose to randomly replace, remove, insert, and swap characters or words at certain ratios in a sentence~\cite{belinkov2018synthetic,wei2019eda}. 
Some more sophisticated methods modify sentences by using alternative syntax~\cite{min2020syntactic}. 
Language models can in turn act as effective tools for textual data augmentation. 
For example, Back-translation~\cite{sennrich2015improving} first translates sentences from the source language (e.g. English) to an intermediary (e.g. Chinese) and then translates the intermediary sentence back to the source language. 
Substitute Word using BERT~\cite{kumar2020data} masks certain words in the original sentences and uses a BERT model to predict masked words. 
They utilize the subtle differences made by the translator or the unmasking process and perturb the wording or syntax while keeping the meanings untouched. 
The recent emergence of LLM has given birth to a series of new approaches~\cite{anaby2020not,cai2023resolving,ding2024data,wang2024survey}. 
AugGPT~\cite{dai2025auggpt}, for example, prompts the state-of-the-art ChatGPT model to rewrite sentences in the dataset and preserves dataset coherence after data augmentation. 
Self-LLMDA~\cite{li2024empowering} automatically generates and selects the most suitable instruction to prompt the LLM to generate augmented samples. 
However, these aforementioned methods neglect the impact on dataset diversity, failing to ensure the diversity trait of producing high-quality datasets. 
The effect of LLM augmentation diversity is discussed in \cite{cegin2023chatgpt,cegin2024effects}, where three types of prompt-based diversity incentives are proposed. 


\vspace{-0.2cm}
\subsection{Dataset Diversity Evaluation}
\vspace{-0.1cm}
The evaluation of dataset diversity is increasingly popular as the size of available training data stunningly explodes, which makes it vital to maintain a minimized redundancy in the dataset to avoid repetitive training, saving the cost and time consumption and avoiding overfitting. 
Though its definition is not yet unified, many metrics are used across research. % ~\cite{tevet2020evaluating,lai2020diversity,yu2022can}. 
\cite{tevet2021evaluating} systematically studies the evaluation of text data diversity, which includes token-level metrics, embedding-level metrics, and human evaluations. 
\cite{lai2020diversity} proposes three dataset diversity metrics in the embedding space and investigates how these metrics change in different text datasets. 
\cite{yu2022can} proposes another three diversity metrics and discusses how improving dataset diversity helps enhance learning generalization, even when the total size of the dataset is reduced.
\cite{gontijo2020affinity} jointly investigates the role of data diversity and affinity in data augmentation, demonstrating that model performance benefits from improvements in both measures. 
Diversity has been considered in the design of several data augmentation methods~\cite{malandrakis2019controlled,liu2021divaug}, however, it has not yet been integrated with coherence-ensured and LLM-based data augmentation methods such as AugGPT~\cite{dai2025auggpt}. 
