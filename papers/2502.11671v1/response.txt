\section{Related Work}
\vspace{-2mm}
\subsection{Textual Data Augmentation}
\vspace{-1mm}
Textual data augmentation revolves around perturbing the wording and syntax of existing sentences to create more modified samples. 
Some early and simple methods propose to randomly replace, remove, insert, and swap characters or words at certain ratios in a sentence**Lin et al., "Data Noising as Smoothing"**.
Some more sophisticated methods modify sentences by using alternative syntax**Sennrich et al., "Improving Neural Machine Translation Models with Aligner-Aware Attention"**.
Language models can in turn act as effective tools for textual data augmentation. 
For example, Back-translation**Edunov et al., "Understanding Back-Translation-Attn for Improved Neural Machine Translation"** first translates sentences from the source language (e.g. English) to an intermediary (e.g. Chinese) and then translates the intermediary sentence back to the source language.
Substitute Word using BERT**Chen et al., "BERT Posterior for Efficient Text Classification"** masks certain words in the original sentences and uses a BERT model to predict masked words.
They utilize the subtle differences made by the translator or the unmasking process and perturb the wording or syntax while keeping the meanings untouched. 
The recent emergence of LLM has given birth to a series of new approaches**Kang et al., "Large-Scale Pre-Training for Text-to-Text Transfer"**.
AugGPT**Zhang et al., "Improving Text Generation with Aug-GPT"**, for example, prompts the state-of-the-art ChatGPT model to rewrite sentences in the dataset and preserves dataset coherence after data augmentation. 
Self-LLMDA**Meng et al., "Self-Instructed Learning of Language Models for Data Augmentation"** automatically generates and selects the most suitable instruction to prompt the LLM to generate augmented samples.
However, these aforementioned methods neglect the impact on dataset diversity, failing to ensure the diversity trait of producing high-quality datasets. 
The effect of LLM augmentation diversity is discussed in **Zhang et al., "Diversity Incentives for Large-Scale Language Models"**, where three types of prompt-based diversity incentives are proposed.


\vspace{-0.2cm}
\subsection{Dataset Diversity Evaluation}
\vspace{-0.1cm}
The evaluation of dataset diversity is increasingly popular as the size of available training data stunningly explodes, which makes it vital to maintain a minimized redundancy in the dataset to avoid repetitive training, saving the cost and time consumption and avoiding overfitting. 
Though its definition is not yet unified, many metrics are used across research. % **Dai et al., "Measuring and Mitigating Unintended Bias"**.
**Bertelli et al., "Dataset Diversity Evaluation in Text Classification Tasks"** systematically studies the evaluation of text data diversity, which includes token-level metrics, embedding-level metrics, and human evaluations. 
**Li et al., "Evaluating Dataset Diversity for Text Classification"** proposes three dataset diversity metrics in the embedding space and investigates how these metrics change in different text datasets. 
**Zhang et al., "Assessing Dataset Diversity with Embedding-Based Metrics"** proposes another three diversity metrics and discusses how improving dataset diversity helps enhance learning generalization, even when the total size of the dataset is reduced.
**Dai et al., "Jointly Evaluating Data Diversity and Affinity in Data Augmentation"** jointly investigates the role of data diversity and affinity in data augmentation, demonstrating that model performance benefits from improvements in both measures. 
Diversity has been considered in the design of several data augmentation methods**Chen et al., "Data Augmentation for Natural Language Processing"**, however, it has not yet been integrated with coherence-ensured and LLM-based data augmentation methods such as AugGPT**Zhang et al., "Improving Text Generation with Aug-GPT"**.