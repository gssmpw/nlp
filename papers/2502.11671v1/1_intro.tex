\section{Introduction}


AI methods have demonstrated immense capabilities, often surpassing human abilities and traditional techniques across various natural language processing (NLP) tasks. 
This success largely hinges on the availability of high-quality datasets, which enable AI models to uncover intrinsic patterns and drive their effectiveness in real-world applications. 
However, training on inferior datasets can significantly degrade model performance, particularly when applied to test data or real-world scenarios~\cite{wang2024comprehensive}. 
As AI technology advances, especially with large language models (LLMs), the demand for high-quality datasets has become more pronounced. 
To effectively train NLP models, a high-quality dataset should be (1) \textit{Large}: 
a sufficient number of samples is crucial to reflect the diversity and complexity of human language.  
Large datasets help prevent overfitting, ensuring the trained AI model generalizes well to unseen data. 
With more data points, the model can learn various patterns and relationships, which enhances its robustness and reliability; 
(2) \textit{Coherent}: the mapping between data and labels must be accurate and consistent. 
Coherent datasets ensure that each data point is correctly labeled, providing the model with reliable information for learning. 
Incoherent datasets, with mislabeled or inconsistent data, can confuse the model and degrade its performance. 
Consistency in labeling also aids in the reproducibility of results and the interpretability of the model's predictions; 
(3) \textit{Diverse}: a diverse dataset ensures NLP models learn a broad spectrum of linguistic patterns, enhancing robustness across real-world conditions. 
This includes variations such as dialects, tones, formality, or domain-specific terms.
Exposure to such diversity helps models generalize better, avoiding over-reliance on narrow language subsets. 
Additionally, it improves adaptability to unexpected inputs while reducing biases tied to certain language styles.

Data augmentation is an efficient technique for increasing the number of training samples by modifying existing dataset samples~\cite{wang2024comprehensive}. 
It allows for the rapid generation of large-scale datasets without the need for additional data collection and has been successfully applied in various domains, including textual data. 
Data augmentation for textual data often changes the wording or reshapes the structure of a sentence. 
Many early and simple methods achieve this by randomly perturbing the textual samples at the word level~\cite{wei2019eda,karimi2021aeda}. 
While certain operations prove effective, some introduce noise that compromises label integrity (e.g. deleting a ``not'') or generates almost redundant samples, ultimately failing to improve dataset quality or promote diversity. 
Recent advances in LLMs have demonstrated unprecedented power in text understanding and generation~\cite{radford2018improving}. 
The capacity of these state-of-the-art (SOTA) generative language models establishes a new and promising paradigm of textual data augmentation~\cite{anaby2020not}. 
Generative models enable large-scale acquisition of textual data while preserving the coherence of augmented datasets by generating texts with similar meanings to the original sentences~\cite{dai2025auggpt}.
However, most existing generative methods focus primarily on enlarging dataset size, with limited consideration of how the augmentation process affects dataset diversity. 
Adequate attention to maintaining and enhancing dataset diversity is vital for developing AI-ready, high-quality datasets, making it a crucial challenge in textual data augmentation. 

Along this line, we propose a \textbf{\underline{D}}iversity-\textbf{\underline{o}}riented data \textbf{\underline{Aug}}mentation approach (\textbf{DoAug}) using an LLM to paraphrase sentences. 
The LLM is first fine-tuned on a paraphrase dataset and taught to rewrite sentences. 
By instructing the LLM to function as a paraphraser, we can use it to alter sentence expressions while preserving their essential meaning. 
In this way, we ensure the affinity between the original and augmented samples, minimizing the influence of data augmentation on dataset coherence. 
To enhance the dataset diversity through data augmentation, we further proposed a diversity-oriented fine-tuning method.  
We construct a preference dataset that chooses the more diverse paraphrases while rejecting repetitive ones. 
Then the LLM paraphraser is fine-tuned on the preference dataset with the DPO algorithm~\cite{rafailov2024direct} to encourage greater diversity in its generated samples. 
We also adopt a coreset selection method to focus on only the most important samples from the dataset to reduce the computational overhead and costs of running LLMs. 
Finally, we conduct extensive experiments on 12 textual benchmark datasets to verify the effectiveness of \Methodnamec. 
Experimental results show that our proposed method can remarkably enhance the diversity of the augmented dataset on 5 measurements while maintaining high affinity compared with the original dataset. 
We also investigate the implications of this increased diversity on model performance in downstream tasks and observe significant improvements in model performance when trained on the augmented datasets. 

In summary, the contributions are as follows: 
    
    \textbf{(1)} We propose a data augmentation framework, \Methodname, that incorporates and explicitly encourages diversity, an important yet often neglected factor in high-quality datasets; 
    
    \textbf{(2)} The framework trains and employs an LLM as a paraphraser to generate synthetic data with high affinity, ensuring the coherence of the augmented datasets; 
    
    \textbf{(3)} We introduce a diversity-oriented fine-tuning method that trains the LLM augmenter on a preference dataset with the DPO algorithm the boost generation diversity of the LLM;
    
    \textbf{(4)} Extensive experiments conducted on 12 datasets demonstrate that \Methodnamec~significantly benefits learning performance by increasing dataset diversity while maintaining coherence. 
