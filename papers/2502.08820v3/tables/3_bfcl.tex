\begin{table*}[!t]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{l c c c c c c c }
\toprule
\textbf{Model}                  & \textbf{Overall Acc}   & \textbf{Non-Live AST Acc} &  \textbf{Non-Live Exec Acc} & \textbf{Live Acc}    & \textbf{Multi Turn Acc}  & \textbf{Relevance Detection} & \textbf{Irrelevance Detection}  \\ \midrule

Mistral-7B-Instruct-v0.3        & 38.35\%                & 56.33\%                   & 63.77\%                     & 57.31\%              & 0.25\%                   & 77.78\%                      & 41.84\%                         \\
Llama-3.1-8B-Instruct           & 49.84\%                & 84.25\%                   & 79.75\%                     & 60.33\%              & 10.25\%                  & 75.61\%                      & 47.92\%                         \\
Llama-3.3-70B-Instruct          & 51.36\%                & 84.85\%                   & \underline{90.05\%}         & 62.51\%              & 7.25\%                   & \underline{95.12\%}          & 48.33\%                         \\
ToolAce                         & 52.55\%                & 82.19\%                   & 86.98\%                     & 71.08\%              & 0.88\%                   & 70.73\%                      & 87.29\%                        \\
Hammer2.0-7b                    & 52.13\%                & 86.94\%                   & 83.66\%                     & 71.17\%              & 0.38\%                   & 95.12\%                      & 73.20\%                         \\
Llama-3.1-405B-Instruct         & 56.38\%                & \underline{89.71\%}       & 84.70\%                     & 70.77\%              & 11.75\%                  & 88.89\%                      & 70.86\%                        \\
GPT-4o-mini (2024-07-18)        & 59.40\%                & 86.52\%                   & \textbf{85.05\%}            & 73.26\%              & 19.00\%                  & 78.05\%                      & 76.97\%                         \\
GPT-4o (2024-08-06)             & 59.83\%                & 70.08\%                   & 60.79\%                     & \textbf{76.41\%}     & \textbf{34.62\%}         & 51.22\%                      & \textbf{87.34\%}                \\ \midrule

CoALM 8B (ours)                  & 54.11\%                & 85.17\%                   & 78.61\%                     & 72.59\%              & 7.00\%                   & 77.78\%                      & 83.00\%                        \\ 
CoALM 70B (ours)                 & \underline{60.49\%}    & 82.94\%                   & 81.36\%                     & 72.19\%              & 26.25\%                  & 72.22\%                      & \underline{85.36\%}            \\ 
CoALM 405B (ours)\textbf{$^*$}                & \textbf{63.34\%}       & \textbf{90.46\%}          & 84.75\%                     & \underline{74.59\%}  & \underline{28.25\%}      & \textbf{100.00\%}            & 72.26\%                        \\ 
 \bottomrule
\end{tabular}
}
\caption{\textbf{BFCL V3 Benchmark Results.} Performance comparison on the BFCL V3 function-calling benchmark. The best results are highlighted in \textbf{bold}, while the second-best results are \underline{underlined}. The asterisk (*) on CoALM 405B denotes one completed epoch, as the model continues training.}
\label{tab:bfcl}
\end{table*}


% \begin{table*}[!t]
% \centering
% \resizebox{1.0\linewidth}{!}{
% \begin{tabular}{l c c c c c c c }
% \toprule
% \textbf{Model}                  & \textbf{Overall Acc}   & \textbf{Non-Live AST Acc} &  \textbf{Non-Live Exec Acc} & \textbf{Live Acc}    & \textbf{Multi Turn Acc}  & \textbf{Relevance Detection} & \textbf{Irrelevance Detection}  \\ \midrule
% GPT-4o (2024-08-06)             & 59.83\%                & 70.08\%                   & 60.79\%                     & 76.41\%              & 34.62\%                   & 51.22\%                      & 87.34\%                         \\
% GPT-4o-mini (2024-07-18)        & 86.52\%                & 85.05\%                   & 60.79\%                     & 73.26\%              & 19.00\%                   & 78.05\%                      & 76.97\%                         \\
% ToolACE-8B (checkpoint)         & 56.17\%                & 86.94\%                   & 83.02\%                     & 75.79\%              & 6.87\%                   & 82.93\%                      & 84.06\%                         \\
% Hammer2.0-7b (checkpoint)       & 54.57\%                & 90.31\%                   & 86.93\%                     & 70.95\%              & 5.25\%                   & 97.56\%                      & 68.52\%                        \\ \midrule
% CoALM 8B (ours)                  & 53.67\%                & 79.88\%                   & 81.55\%                     & 71.12\%              & 7.62\%                   & 75.61\%                      & 85.18\%                        \\
% ToolAce (trained)               & 52.55\%                & 82.19\%                   & 86.98\%                     & 71.08\%              & 0.88\%                   & 70.73\%                      & 87.29\%                        \\
% Hammer2.0-7b (trained)          & 52.13\%                & 86.94\%                   & 83.66\%                     & 71.17\%              & 0.38\%                   & 95.12\%                      & 73.20\%                         \\
% Llama-3.1-8B-Instruct           & 49.84\%                & 84.25\%                   & 79.75\%                     & 60.33\%              & 10.25\%                  & 75.61\%                      & 47.92\%                         \\ \bottomrule
% %Hammer2.0-1.5b (FC)             & 48.92\%                & 83.94\%                   & 82.75\%                     & 63.93\%              & 1.25\%                   & 92.68\%                      & 60.21\%                         \\
% % experiment0-DST                 & 44.35\%                & 76.90\%                   & 82.21\%                     & 52.82\%              & 4.00\%                   & 87.80\%                      & 46.51\%                         \\
% %experiment3-Mwoz-DST-Hammer     & 39.42\%                & 70.33\%                   & 76.71\%                     & 45.76\%              & 3.88\%                   & 73.17\%                      & 29.82\%                         \\  \bottomrule
% \end{tabular}
% }
% \caption{Evaluation Results of Various Models on BFCL-ver3}
% \vspace{-5mm}
% \label{tab:evaluation_results}
% \end{table*}


