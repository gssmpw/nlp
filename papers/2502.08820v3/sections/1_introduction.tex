\section{Introduction}

% \begin{quote}
% \emph{You don't understand anything until you learn it more than one way...}
% \end{quote}

% \begin{flushright}
% - \citet{Minsky1986-MINTSO}
% \end{flushright}


The concept of intelligent agents has been the cornerstone of artificial intelligence research for a long time \cite{Minsky1986-MINTSO}, developing in parallel with the field of human-to-machine conversation \cite{young02_icslp}. The advent of LLMs \cite{Achiam2023GPT4TR, Dubey2024TheL3-llama3} has revolutionized both fields and enabled powerful Language Agents (LA) \cite{schick2024toolformer} while transforming modular dialogue systems into end-to-end solutions \cite{hudecek-dusek-2023-large}. Despite sharing LLM foundations, they are typically focused and analyzed separately from each other; dialogue models focused on tasks such as multi-turn interactions, delivering relevant information to users, and dialogue management with state-tracking, on the other hand LAs concentrated exclusively on tool calling skills.

\begin{figure}[t!]
\includegraphics[width=\linewidth]{figures/fig1-ver8.pdf}
\caption{\textbf{Unifying Capabilities of TOD Systems and LAs.} TOD systems excel in multi-turn conversations and task completion but lack advanced API capabilities, while LA handle APIs well but struggle with coherent multi-turn dialogue.}
\vspace{-5mm}
\label{fig:conv-agent}
\end{figure}

\begin{figure*}[t!]
\includegraphics[width=\linewidth]{figures/fig3-data-ver9.pdf}
\caption{\textbf{Overview of the CoALM Pipeline.} This figure illustrates our dataset generation and fine-tuning framework. The top three rows depict the data transformation processes, along with a corresponding sample shown on the right. In each training sample, \textbf{\textcolor{darkgreen}{green}} text highlights the input components of the instruction sample, while \textbf{\textcolor{mypurple}{purple}} text indicates the target outputs optimized during fine-tuning. For detailed examples, refer to Figures \ref{tab:snips-dst} - \ref{tab:sgd-sft-response}.}
\vspace{-2.0ex}
\label{fig:summary}
\end{figure*}


\textit{What if a single model could master both conversational and agentic tasks at the same time?}
The narrative of our paper aims to address the vision of a unified \textit{conversational agent}. 
Such an agent must excel not only in handling multi-turn conversations and TOD tasks but also in leveraging advanced LA capabilities, such as compound tool usage.
Previous research has focused on training dialogue agents in controlled scenarios (e.g., booking and reservation tasks) \cite{li2024largelanguagemodelszeroshot} with limited set of functions coming from dialogue actions (e.g., find\_attraction, book\_hotel), or, relied on hand-crafted long prompts tied to a small set of predefined APIs \cite{xu-etal-2024-rethinking} leveraged by propriety models like GPT-4. However, these approaches face limitations in real-world applications. Specifically, existing systems cannot easily adapt to new services without expensive fine-tuning or prompt engineering, yet real-world users often need access to a diverse range of APIs and functionalities according to their needs. 
Moreover, previous work shown a notable performance gap reported in TOD tasks between closed-source and open-source models \cite{hudecek-dusek-2023-large, xu-etal-2024-rethinking, li2024largelanguagemodelszeroshot}.
This tension underscores the need for an integrated open-source framework that supports both long-term dialogue state tracking and complex function calling from wide variety of APIs\footnote{In this work, words such as "tool use", "function calling", and "API calling" are used interchangeably.}.


We propose \textbf{CoALM} (Conversational Agentic Language Model), a unified approach that integrates TOD strengths (e.g., multi-turn state tracking) with LA capabilities (e.g., dynamic tool use). To achieve this, we develop \textbf{CoALM-IT}, a dataset spanning three dimensions: dialogue state tracking, complex function calling, and multi-turn conversations in ReAct style where the agent integrates its reasoning process with actions before providing the final response \cite{yao2023reactsynergizingreasoningacting-react}. The novelty of CoALM-IT comes from its Conversational ReAct API (CRA) instances, which makes it the first multi-turn TOD dataset explicitly incorporating ReAct-style reasoning with multiple think steps inside, generated using GPT-4o. The first think steps are responsible for deciding to call an API or not and second think step is to decide whether to response to user or not. Leveraging CoALM-IT, we trained CoALM model series: \textbf{CoALM 8B}, \textbf{CoALM 70B}, and \textbf{CoALM 405B}, a family of conversational agents demonstrates state-of-the-art performance on both TOD and LA domains. To comprehensively evaluate this, we perform experiments on one TOD benchmark, MultiWOZ 2.4 \cite{ye-etal-2022-multiwoz}, and two popular function calling benchmarks, the Berkeley Function Calling Leaderboard V3 (BFCL) \cite{bfcl} and API-Bank \cite{li-etal-2023-apibank} in completely zero-shot settings\footnote{Here, "zero-shot" refers to none of the evaluation benchmark train-set was used while training the CoALM models with CoALM-IT.}.


Our experiments reveal a stark gap in existing models: while LAs excel at tool calling on BFCL V3, they falter on MultiWOZ 2.4 with poor task completion. Conversely, base LLMs and traditional TOD systems show limited function calling abilities, as evidenced by the low performance on BFCL V3 and API-Bank. In contrast, our CoALM models, excel across both TOD and LA tasks. Our larger-scale open-source variants—CoALM 70B and CoALM 405B—outperform GPT-4o and other domain-specific models on both TOD (MultiWOZ) and function calling benchmarks (BFCL V3 and API-Bank).


In this paper, we study: \textit{How can we craft a single conversational agentic LLM that elegantly interweaves multi-turn dialogue mastery with powerful function calling capabilities?} Our key contributions are as follows:
\begin{itemize}[topsep=2pt, partopsep=-5pt, leftmargin=8pt, itemsep=-4.5pt]
    \item We analyze the gap between two domains: TOD systems and LA through evaluations on MultiWOZ 2.4, BFCL V3, and API-Bank, showing limitations of existing approaches.
    \item We introduce \textbf{CoALM-IT}, a hybrid multi-task dataset for conversational agents that, for the first time, explicitly incorporates ReAct-style reasoning steps in multi-turn TOD scenarios. Notably, to our knowledge, no prior effort has trained ReAct-based models using multi-turn TOD data in this manner.
    \item We propose \textbf{CoALM}, a family of model series trained with CoALM-IT: \textbf{CoALM 8B}, \textbf{CoALM 70B}, and the largest open-source conversational agent \textbf{CoALM 405B}—all unified by multi-turn dialogue skills and advanced function calling capabilities. 
     \item Our larger models, CoALM 70B and CoALM 405B, outperform GPT-4o and GPT-4o-mini on both TOD and LA tasks, narrowing gap between agents using closed-source and open-source models.
\end{itemize}
To foster further research within the open-source community, we publicly release code, all model weights, datasets, intermediate checkpoints, and training configurations.