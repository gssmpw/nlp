\section{Related Work}

\noindent\textbf{Dialogues and the Domain Shift.} Earlier studies work on applying LLMs to dialog applications through supervised fine-tuning \cite{su-etal-2022-multi, gupta-etal-2022-instructdial} or different prompting methods \cite{hu-etal-2022-context, chung-etal-2023-instructtods, zhang-etal-2023-sgp}.
Following these, \citet{hudecek-dusek-2023-large} have examined the dialogue management abilities of instruction-tuned LLMs in handling goal-oriented multi-turn conversations.
More recently, existing work in dialogue agents primarily focuses on leveraging dialogue acts to derive API calls for backend services \cite{li2024largelanguagemodelszeroshot, xu-etal-2024-rethinking, king-flanigan-2024-unsupervised}.
FNCTOD \cite{li2024largelanguagemodelszeroshot} fine-tunes on a small dataset restricted to a limited set of domain-specific APIs for state tracking, whereas AutoTOD \cite{xu-etal-2024-rethinking} uses GPT-4 with hand-crafted prompts that rely on a narrow set of predefined APIs with long instructions for each dialogue domain. However, these approaches are brittle and difficult to scale in real life scenarios, as they require costly re-trainings or extensive prompt engineering to handle new services, unseen domains, and unexpected user requests. Our work aligns with these studies in building such agents, but CoALM can manage thousands of complex APIs at the same time and can generalize to unseen domains without expensive training cycles and time-intensive prompt engineering. %Gokhan: Custom TOD models can only provide a walled garden experience. In this post-GPT era LA TOD will be developed as LA

\vspace{3mm}

\noindent\textbf{Language Agents.} Tool learning with LLMs has evolved from simple simple reasoning \cite{NEURIPS2022_9d560961-cot} to more sophisticated approaches \cite{yao2023reactsynergizingreasoningacting-react, tool_learning}. Early work relied on prompting to enable tool usage \cite{yao2023reactsynergizingreasoningacting-react, paranjape2023art}, but more recent research has focused on specialized fine-tuning approaches for effective function calling accuracy~\cite{schick2024toolformer, patil2023gorilla, wang2024executable, zhang2024xlam}. For example, Toolformer \cite{schick2024toolformer} have explored how LLMs autonomously learn when and how to call APIs, leading to improved performance in task-specific settings. In this direction, recent works \cite{abdelaziz-etal-2024-granite, Liu2024ToolACE, Lin2024Hammer} focus on fine-tuning synthetically generated data to integrate more complex tool calling capabilities, such as nested function calls and irrelevance detection. These approaches shown promising results on LA benchmarks, however they mostly operate on single-turn interactions with the user and fall short of enabling user-driven, multi-domain, and multi-turn task completion which is essential for real-world conversational systems.