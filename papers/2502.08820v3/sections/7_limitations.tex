\section{Limitations}
While CoALM demonstrates improved performance across both conversational TOD and agentic tasks, we conducted all experiments solely using the Llama model family, limiting our insights into other architectures like Mistral and Qwen.
Furthermore, many TOD systems rely on classification-based supervised fine-tuning (DST-only), lacking free-form chat capabilities, so we are not able to integrate them in our chat-based evaluation setup for head-to-head comparisons.
We also did not systematically assess CoALMâ€™s general reasoning abilities after post-training, leaving open the question of potential catastrophic forgetting if any.
Even though we introduced the open source model CoALM 405B, the computational cost of doing inference with CoALM 405B requires 16 H100 GPUs, which may limit accessibility for some researchers. 
Lastly, our current approach still relies on curated fine-tuning data; future work might investigate self-evolving methods that learns complex function calling skills continuously leveraging RL.