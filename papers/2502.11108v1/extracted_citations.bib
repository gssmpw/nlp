@inproceedings{Lewis_NEURIPS2020,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 volume = {33},
 year = {2020}
}

@Article{diagnostics14141468,
AUTHOR = {Muntean, George Adrian and Marginean, Anca and Groza, Adrian and Damian, Ioana and Roman, Sara Alexia and Hapca, Mădălina Claudia and Sere, Anca Mădălina and Mănoiu, Roxana Mihaela and Muntean, Maximilian Vlad and Nicoară, Simona Delia},
TITLE = {A Qualitative Evaluation of ChatGPT4 and PaLMs Response to Patients Questions Regarding Age-Related Macular Degeneration},
JOURNAL = {Diagnostics},
VOLUME = {14},
YEAR = {2024},
NUMBER = {14},
ARTICLE-NUMBER = {1468},

ISSN = {2075-4418},
DOI = {10.3390/diagnostics14141468},
type={journal},
infosite = {10.3390/diagnostics14141468},
durl ={https://www.mdpi.com/2075-4418/14/14/1468},
}

@article{kragen_2024,
    author = {Matsumoto, Nicholas and Moran, Jay and Choi, Hyunjun and Hernandez, Miguel E and Venkatesan, Mythreye and Wang, Paul and Moore, Jason H},
    title = "{KRAGEN: a knowledge graph-enhanced RAG framework for biomedical problem solving using large language models}",
    journal = {Bioinformatics},
    volume = {40},
    number = {6},
    pages = {btae353},
    year = {2024},
    month = {06},
    abstract = "{Answering and solving complex problems using a large language model (LLM) given a certain domain such as biomedicine is a challenging task that requires both factual consistency and logic, and LLMs often suffer from some major limitations, such as hallucinating false or irrelevant information, or being influenced by noisy data. These issues can compromise the trustworthiness, accuracy, and compliance of LLM-generated text and insights.Knowledge Retrieval Augmented Generation ENgine (KRAGEN) is a new tool that combines knowledge graphs, Retrieval Augmented Generation (RAG), and advanced prompting techniques to solve complex problems with natural language. KRAGEN converts knowledge graphs into a vector database and uses RAG to retrieve relevant facts from it. KRAGEN uses advanced prompting techniques: namely graph-of-thoughts (GoT), to dynamically break down a complex problem into smaller subproblems, and proceeds to solve each subproblem by using the relevant knowledge through the RAG framework, which limits the hallucinations, and finally, consolidates the subproblems and provides a solution. KRAGEN’s graph visualization allows the user to interact with and evaluate the quality of the solution’s GoT structure and logic.KRAGEN is deployed by running its custom Docker containers. KRAGEN is available as open-source from GitHub at: https://github.com/EpistasisLab/KRAGEN.}",
    issn = {1367-4811},
}

@article{pub.1182771521,
 abstract = {The capabilities of Large Language Models (LLMs,) such as Mistral 7B, Llama 3, GPT-4, present a significant opportunity for knowledge extraction (KE) from text. However, LLMs’ context-sensitivity can hinder obtaining precise and task-aligned outcomes, thereby requiring prompt engineering. This study explores the efficacy of five prompt methods with different task demonstration strategies across 17 different prompt templates, utilizing a relation extraction dataset (RED-FM) with the aforementioned LLMs. To facilitate evaluation, we introduce a novel framework grounded in Wikidata’s ontology. The findings demonstrate that LLMs are capable of extracting a diverse array of facts from text. Notably, incorporating a simple instruction accompanied by a task demonstration – comprising three examples selected via a retrieval mechanism – significantly enhances performance across Mistral 7B, Llama 3, and GPT-4. The effectiveness of reasoning-oriented prompting methods such as Chain-of-Thought, Reasoning and Acting, while improved with task demonstrations, does not surpass alternative methods. This suggests that framing extraction as a reasoning task may not be necessary for KE. Notably, task demonstrations leveraging examples selected via retrieval mechanisms facilitate effective knowledge extraction across all tested prompting strategies and LLMs.},
 author = {Polat, Fina and Tiddi, Ilaria and Groth, Paul},
 doi = {10.3233/sw-243719},
 journal = {Semantic Web},
 keywords = {},
 number = {},
 pages = {1-34},
 title = {Testing prompt engineering methods for knowledge extraction from text},
 volume = {},
 year = {2024}
}

@article{singhal2023large,
  title={Large language models encode clinical knowledge},
  author={Singhal, K. and Azizi, S. and Tu, T. and Mahdavi, S.S. and Wei, J. and Chung, H.W. and Scales, N. and Tanwani, A. and Cole-Lewis, H. and Pfohl, S. and others},
  journal={Nature},
  volume={620},
  pages={172--180},
  year={2023},
  doi={10.1038/s41586-023-XXXX-X}
}

@article{wei2022chain,
    title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
    author = {Wei, Jason and others},
    journal = {arXiv preprint arXiv:2201.11903},
    year = {2022}
}

@article{yang2024kgllm,
    title = {Enhancing Pretrained Language Models with Knowledge Graphs for Fact-Aware Language Modeling},
    author = {Yang, L. and Chen, H. and Li, Z. and others},
    journal = {IEEE Transactions on Knowledge and Data Engineering},
    pages = {1--20},
    year = {2024},
    doi = {10.1109/TKDE.2024.XXXXXXX}
}

