%%
%% This is file `sample-acmsmall-submission.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall-submission')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall-submission.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,nonacm]{acmart} %,,review, anonymous


\usepackage[ruled,linesnumbered]{algorithm2e} % For algorithms
\usepackage{algpseudocode}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{cc}
\setcctype[4.0]{by}
\copyrightyear{2024}
% \acmYear{2024}
% \acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
% \acmJournal{PACMMOD}
% \acmVolume{3}
% \acmNumber{1}
% \acmArticle{0247 (PODS)}
%\acmMonth{8}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Extending the Applicability of Bloom Filters by Relaxing their Parameter Constraints}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Paul Walther}
\orcid{0000-0002-5101-5793}
\affiliation{%
  \institution{Technical University of Munich}
  \city{Munich}
  \country{Germany}}
\email{paul.walther@tum.de}

\author{Wejdene Mansour}
\orcid{0009-0008-4362-2092}
\affiliation{%
  \institution{Technical University of Munich}
  \city{Munich}
  \country{Germany}}
\email{wejdene.mansour@tum.de}

\author{Martin Werner}
\orcid{0000-0002-6951-8022}
\affiliation{%
  \institution{Technical University of Munich}
  \city{Munich}
  \country{Germany}}
\email{martin.werner@tum.de}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Walther et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
%Thereby, an empty Bloom filter is an all-zero bit array.% To store or retrieve an element, it is mapped with hash functions to a set of indices of slots in the Bloom filter.  
%As they are comparably small they can be hold in memory and therefore reduce disk lookups. This allows for a mutable  (elements can be added) and 
These days, Key-Value Stores are widely used for scalable data storage. In this environment, Bloom filters serve as an efficient probabilistic data structure for the representation of sets of keys as they allow for set membership queries with controllable false positive rates and no false negatives. 
For optimal error rates, the right choice of the main parameters, namely the length of the Bloom filter array, the number of hash functions used to map an element to the array's indices, and the number of elements to be inserted in one filter, is crucial. However, these parameters are constrained: The number of hash functions is bounded to integer values, and the length of a Bloom filter is usually chosen to be a power-of-two to allow for efficient modulo operations using binary arithmetics. These modulo calculations are necessary to map from the output universe of the applied universal hash functions, like Murmur, to the set of indices of the Bloom filter.  
In this paper, we relax these constraints by proposing the Rational Bloom filter, which allows for non-integer numbers of hash functions. This results in optimized fraction-of-zero values for a known number of elements to be inserted. Based on this, we construct the Variably-Sized Block Bloom filters to allow for a flexible filter length, especially for large filters, while keeping computation efficient.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10010070.10010111.10011710</concept_id>
       <concept_desc>Theory of computation~Data structures and algorithms for data management</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10010055.10010056</concept_id>
       <concept_desc>Theory of computation~Bloom filters and hashing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10003752.10003809.10010031</concept_id>
       <concept_desc>Theory of computation~Data structures design and analysis</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[300]{Theory of computation~Data structures and algorithms for data management}
\ccsdesc[500]{Theory of computation~Bloom filters and hashing}
\ccsdesc[500]{Theory of computation~Data structures design and analysis}
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Databases, Set Membership Query, Index Structure, Rational Bloom Filter, Variably-Sized Block Bloom Filter}


\settopmatter{printacmref=false} % Remove in final version TODO

%\received{09 December 2024}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
In big data environments, a typical data life cycle includes data creation, distribution, storage, retrieval, indexing and searching, and visualization \cite{Werner.2015b}. While the type of data being processed can be manifold, Key-Value Stores proved themselves as an efficient storage model to support steps in this data life cycle \cite{DeCandia.2007}. 
They store data as pairs of unique keys and associated values and allow for efficient retrieval and modification of the data elements as the comparably small set of keys can be filtered in memory before an expensive disk lookup for the values is necessary. Consequently, an efficient representation of the keys in memory is necessary to allow the scalability and low-latency handling of large data in Key-Value Stores.

At the same time, large, sparse, low-cardinality data can be modelled as sets. For example, global raster data capturing building footprints may be represented as a set of corresponding raster elements \cite{Werner.2021}. As access to this data type is often random, the requirements for an efficient in-memory representation are similar to those of a Key-Value Store. 

For such set property storages, Bloom filters as probabilistic data structures representing small subsets of a so-called universe were proposed before \cite{Werner.2021, Lu.2012}. They are essentially configured with the three parameters: length $m$ in bits, number of hash functions $k$, and amount of elements to store in the Bloom filter $n$ \cite{Bloom.1970}. As the only error type of this data structure is a false positive, the error is fully characterized by the (expected) false positive rate, which is a consequence of choosing the aforementioned parameters. Thereby, the memory footprint trades against the error probability of the data structure.
 
However, some constraints exist that hinder the optimal choice of parameters in practice. In this context, the main contributions of this paper are
\begin{itemize}
    \item a method allowing to choose any \textbf{rational number} instead of only an integer number \textbf{of hash functions} $k$, which is is very powerful if the set is immutable as it allows for more tailored Bloom filters and, therefore, decreases false positive rates. This is the most common situation when using Bloom filters in the context of databases like Key-Value Stores, where they serve as a lookup index to avoid reading a file on disk. %(if the number of elements is large enough).
    \item a method to choose \textbf{non-power-of-two sizes for the Bloom filter $m$ without performance degradation} (by non-uniformity of access) and still without explicit modulo computations. It has the most impact on large Bloom filters as they have been used already to represent big datasets \cite{Werner.2021}. For these large filters, the constraint of being limited to power-of-two sizes massively constrains available choices. An extreme case would be if we have to choose between filter sizes requiring 32 GB or 64 GB of main memory \cite{Werner.2021, Walther.2024}.
\end{itemize}
The constraints of standard Bloom filters and both proposed methods are visualized in Figure~\ref{fig:teaser}. 
\begin{figure}
  \includegraphics[width=\textwidth, trim=0 11.7cm 16.05cm 0, clip]{Overview_Image.pdf}
  \caption{Overview of the proposed approaches to relax Bloom filter parameter constraints: Rational Bloom filters and Variably-Sized Block Bloom filter}
  \label{fig:teaser}
\end{figure}


% The term \textit{Big Data} gained prominence due to the exponential increase in real-world data driven by improved capturing devices and storage capabilities. Not only do physical sensors capture increasing amounts of data, but virtually created data points like logs and computer program protocols result in more and more data being produced. After data creation, the standard data life cycle continues with distribution, storage, retrieval, indexing and searching, analysis, and visualization \cite{Werner.2015b}. It can be noticed that all of these steps require efficient data access. However, even without the need for analysis, this huge amount of data comprises two challenges: The data needs to be stored efficiently, and retrieval needs to be efficient.

% This means we need efficient data representations and efficient indexing or ordering schemas. While many deterministic approaches exist for both, like, e.g., lossless compression algorithms and classic indexes, these cannot compress the actual data size below a certain threshold and can only order the data along a specific property while requiring relatively large storage overhead for the index. 
% Therefore, probabilistic data structures were developed for both challenges, which are very useful, especially in Big Data Environments \cite{Gupta.2017}. These methods allow data compression ratios beyond lossless limits to save storage space, and they can act as probabilistic indexes, which improve the ability to find data without adding a lot of storage overhead. Many of them use approximations together with hashing techniques to trade complexity and storage footprint advantages against a small error probability \cite{Gupta.2017}. Typical probabilistic data structures include random projections and Bloom filters. In this work, we will focus on the second.

% Bloom filters \cite{Bloom.1970} are simple binary probabilistic data structures commonly used to approximate set membership queries \cite{Kleyko.2020} and find broad application, especially in Big Data settings \cite{Nayak.2019}. For example, they are used in tree-based indexes as an efficient way to store whether an object is part of a subtree. Bloom filters consist of a typically binary filter of length $m$ bits in which a set of $n$ elements is stored by applying $k$ hash functions per element \cite{Broder.2004}. $(m, k, n)$ thereby comprise the set of parameters that need to be optimized to achieve the highest performance, which means the lowest amount of falsely answered set queries.

% In practice, this parameter space is limited by the structure of the Bloom filter, such $m$, $k$, and $n$ are required to be integers, and practical implementation constraints further restrict $m$ to be of size $2^c$ to efficiently map with hash functions from the input space to the length of the Bloom filter \cite{Werner.2021}.
% As the optimal performance, that means the lowest false positive rate with a smaller storage footprint for the largest possible amount of to-be-stored elements is directly dependent on an optimal choice of these parameters, these limits result in non-optimal configurations for many use cases

% In this paper, we first analyze these described restrictions methodologically before proposing to flexibilize these limitations with two new Bloom filter variants, namely a Rational Bloom filter and a Variably-Sized Block Bloom filter.
% Our main contributions are:
% \begin{itemize}
%     \item The analysis of the parameter space restrictions of Bloom filters.
%     \item The proposition of a Bloom filter with a rational amount of hash functions per element, which we call \textit{Rational Bloom filter} and the theoretical evaluation of its improved performance.
%     \item The description of a framework for a Bloom filter of variable size unequal powers of two, based on a blocked internal structure of the filter.
% \end{itemize}
% We show that for some use cases, especially with small amounts of hash functions or very large filter sizes, our proposed approach can optimize error rates or memory usage by only limited computational overhead. All three proposed methods are visualized in Figure~\ref{fig:teaser}.
% \begin{figure}
%   \includegraphics[width=\textwidth, trim=0 11.7cm 16.05cm 0, clip]{Overview_Image.pdf}
%   \caption{Overview of the proposed approaches to extend the Bloom filter theory: Rational Bloom filters and Variably-Sized Block Bloom filter}
%   \Description{Overview of the proposed approaches: Rational Bloom filter and Variably-Sized Block Bloom filter}
%   \label{fig:teaser}
% \end{figure}
% First considerations in this direction were already presented by~\cite{Walther.2024}. Still, we evolve these very basic first ideas to full concepts and, in particular, focus on a detailed evaluation and reasoning of the proposed approaches.

\section{Analysis of Typical Bloom Filter Properties}
\label{sec:properties}
As described, the standard Bloom filter is a data structure for the efficient probabilistic storage of sets \cite{Bloom.1970}. Its simplest form consists of a binary array (the filter) and methods for storage in the filter and querying for set membership. The empty filter, in its simplest version, thereby, is an all-zero bit array of length $m$. 
In general, a Bloom filter trades data footprint against error probability. That means a smaller Bloom filter allows for more errors. Still, due to its structure, it allows only for false positives, which means if an object is inserted in the Bloom filter, we can be sure that when querying it, the Bloom filter responds with \texttt{true}, but if an object is not inserted in the Bloom filter, querying it may still result in a \texttt{true} response \cite{Bruck.2006,Werner.2021}. 

\subsection{Standard Bloom Filter Operations}
Standard operations on a Bloom filter are the \textit{insertion} and the \textit{membership query} \cite{Gupta.2017}. 
To \textit{insert} an element $x$ into a Bloom filter, the element is hashed with $k$ uniformly distributed pairwise independent hash functions $H_i(x)$, with $i \in \{1, \dots, k\}$. The hashing thereby maps from the input space of all elements (universe) to the integer range $\{0, \dots,m-1\}$. The calculated hash values $H_i(x)$ are then treated as indices, and the Bloom filter is set to \texttt{1} at these locations. If the value is already \texttt{1} at one of the indices, it stays \texttt{1} \cite{Gupta.2017}. 
For the \textit{membership query}, that means checking whether an element has been inserted into a Bloom filter before, the $k$ indices representing the element are calculated again by the same $k$ hash functions $H_i(x)$. To decide whether the element is part of the inserted set, the Bloom filter is checked at these $k$ indices: If one of the values is \texttt{0}, we can be sure that the element has not been inserted. Otherwise, if all values are \texttt{1}, the element is part of the inserted set, or it is a false positive error \cite{Gupta.2017}.  
Both standard operations are visualized in Figure \ref{fig:bf-operation}.
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth, trim= 0 13.25cm 25.345cm 0,clip]{BloomFunction.pdf}
    \caption{Visualization of the standard Bloom filter operations, insertion of element $X$ and $Y$, and membership query of elements $X$, $A$ and $B$, visualization based on \cite{Nayak.2019}.}
    \label{fig:bf-operation}
\end{figure}


\subsection{False Positive Rate, the Optimal Number of Hash Functions and Optimal Filter Size}
For a given number of elements $n$ to store in a Bloom filter, a length of the Bloom filter in bits $m$, and $k$ pairwise independent uniformly distributed hash functions, the false positive rate $p_{\text{FP}}$ of the Bloom filter can be calculated.  
The probability that a specific Bloom filter bit remains \texttt{0} after inserting all the elements into the Bloom filter is given as follows \cite{Bruck.2006}:
\begin{equation}
    p=\left(1-\frac{1}{m}\right)^{kn}{\approx} e^{-kn/m}
    \label{eq:probzero}
\end{equation}
The probability for a false positive is therefore \cite{Bruck.2006}:
\begin{equation}
    p_{\text{FP}}=\left(1-\left(1-\frac{1}{m}\right)^{kn}\right)^k \approx \left(1 - e^{-kn/m}\right)^k \approx (1-p)^k
\label{eq:fp_rate}
\end{equation}

For a given $n$, the optimal number of hash functions $k^*$ can be obtained by minimizing $p_{\text{FP}}$ with respect to $k$. According to information theory, for this optimal $k^*$, the fraction of zeros $\mathit{foz}$ in the filter needs to be $\frac{1}{2}$, as the entropy of the filter is maximum and therefore holds the highest information density \cite{Werner.2015b}.
With that, $k^*$ can be derived as follows (refer to Appendix \ref{app:k}):
\begin{equation}
    k^* = \frac{m}{n}\ln{2}
    \label{eq:optimalk}
\end{equation}
Then, the false positive rate for large $m$ reduces to \cite{Bruck.2006, Lumetta.2007}:
\begin{equation}
    p_{\text{FP}}^* = 2^{-\frac{m}{n}\ln{2}}.% \approx 0.6185^\frac{m}{n}.
\end{equation}
For the optimal filter length, this can be rewritten to:
\begin{equation}
    m^* = \frac{n \cdot \ln(p_{\text{FP}}^*)}{\ln\left(1 / 2^{\ln{2}} \right)}.
\end{equation}

\subsection{Constraints of the Bloom filter Parameter Space and the Need for More Variable Bloom filters}
\label{sec:bloom:sub:restrictions}
\citeauthor{Nayak.2019} explain five main challenges with existing Bloom filter approaches \cite{Nayak.2019}, namely: 
\begin{itemize}
    \item to account for the \textit{false positive rate} (reduce it),
    \item the \textit{scalability} of the Bloom filter approach, especially with initially unknown dataset sizes,
    \item the \textit{deletion of elements}, which is not possible with a standard Bloom filter without recalculation of the whole index, 
    \item to implement an \textit{efficient hashing} method, which does not negatively influence the performance of the Bloom filter and
    \item the correct determination of the \textit{number of hash functions} to use. 
\end{itemize}
An approach to these challenges is the relaxation of the constraints for the filter length $m$, the number of hash functions $k$, and the number of elements to store in a Bloom filter $n$.
With that, an unconstrained, optimal choice of the number of hash functions leads to improved false positive rates (compare Equation \ref{eq:fp_rate}), and new approaches to variable filter lengths might improve the scalability of the approach and allow for more efficient hashing as well as more equally distributed false positive rates~\cite{Estebanez.2014, Almeida.2007}.

In the known literature, only integer numbers for the \textit{number of hash functions} $k$ of a Bloom filter are considered. This seems straightforward, as applying, e.g., $0.3$ hash functions to a value is not defined. This reduces flexibility in constructing the optimal filter for given lengths $m$ and number of elements $n$. Especially for small $k$, this constraint may result in a non-optimal false positive rate. For instance, for an optimal number of hash functions $k^*=1.5$, rounding to $k=1$ or $k=2$ entails a relatively large deviation from the optimal value, resulting in a suboptimal false positive rate. This effect is visualized in Figure~\ref{fig:amounthashfunctions}.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{optimal_amount_of_hash_functions.pdf}
    \caption{Dependencies between the optimal number of hash functions $k^*$ and number of samples $n$ (top left) and filter size $m$ (top right). Dependency of the false positive rate for a fixed filter size of $m=8192$ on varying numbers of hash functions $k$ and number of samples (bottom). The calculated optimal configuration for each number of samples is marked with a cross.}
    \label{fig:amounthashfunctions}
\end{figure}
It is further explained that the probability of false positive is not equally distributed over various elements \cite{Almeida.2007}: In Bloom filter settings with multiple hash functions, it's possible for different hash functions applied to the same element to point to the same slot instead of different ones. This increases the chance for false positives for such elements \cite{Almeida.2007}. This effect increases with a larger number of hash functions, and therefore, using only a limited number of hash functions is beneficial. 

Additionally, the \textit{length of the Bloom filter} $m$ is usually chosen to be a power-of-two, $m=2^c, c \in \mathbb{N}_0$ due to efficiency considerations: The results of a general hash function $h_i(x)$ have to be modified to a specific hash function $H_i(x)$ which maps the input space to indices of slots in the Bloom filter $\{0, \dots,m-1\}$. The easiest way to do so is to take the modulo $h_i(x)\%m$, which is efficient for power-of-two filter lengths as in this case, the modulo operation may be performed as a binary $\&$ operation \cite{Estebanez.2014}: 
\begin{equation}
    H_i(x)=h_i(x)\%m =h_i(x) \& (2^c -1)
    \label{eq:modulo}
\end{equation}
Consequently, when high performance is desired, the selectable lengths for the Bloom filter always double from one option to the next. This might not be a problem for small Bloom filters, but for large Bloom filters, the step sizes become huge. 
For example, for a Bloom filter size of 16GB, the neighboring values 8 GB and 32 GB are already very far from each other. Especially in computer systems, which often have memory in the same size intervals, this may become inefficient: Some space is always used, e.g., by the operating system. Therefore, the Bloom filter may have at most half of the available memory size. 

The \textit{number of elements} $n$ to be inserted in the Bloom filter is the third parameter to choose. While in application, it is often determined, it can still be controlled, e.g., by taking several Bloom filters instead of one or applying principles like hierarchical Bloom filters \cite{Mehringer.2023} to reduce the failure rate by subdividing the set of to-be-inserted elements.  


\section{Related Work}
Reviewing all Bloom filter-related publications is beyond the scope of this work as more than 50 years of development resulted in various Bloom filter-based solutions, which are well captured in reviews \cite{Abdennebi.2021, Putze.2009,Patgiri.2018, Gupta.2017}. Still, we want to identify existing work streams in the field of flexibilizing the Bloom filter parameter space.% and evaluate them along the main Bloom filter challenges presented in the previous Section \ref{sec:bloom:sub:restrictions}. 

To the best of the authors' knowledge, there were no previous approaches to rational numbers of hash functions $k$. Still, many publications propose improvements on \textit{hashing methods}.

The most direct way to hash for a Bloom filter application would be to use so-called \textit{perfect hashing} schemes. This means $k$ hash functions which directly map from the input space to exactly $m$ hash buckets uniformly \cite{Gupta.2017}.
In practice, most Bloom filter approaches use popular hash functions, like Murmur Hash \cite{Appleby.2008}, with consecutive modulo operations to do so. While they approach a uniform distribution, true randomness is not achievable in practice \cite{Estebanez.2014}. 
%Algorithms used to create the hash functions in the context of Bloom filters are MurmurHash \cite{Appleby.2008}

Apart from the direct way of calculating $k$ hash functions, techniques like \textit{double hashing} are applied to reduce computational effort in calculating hash values for $k>2$ \cite{Gupta.2017}. It allows the generation of $k$ pseudo hash values by only having two independent hash functions and combining them as defined in \cite{Kirsch.2006}:
\begin{equation}
    h_i(x)=h_1(x)+f(i)h_2(x)
    \label{eq:efficienthash}
\end{equation}
An assumption of this method is the uniform distribution of hash values over the whole range.

Apart from that, \textit{partitioned hashing} is described in \cite{Gupta.2017} where every hash function only gets disconnected ranges of length $m/k$ as target space. They describe that the asymptotic performance stays the same, but due to a higher number of \texttt{1}'s, they might have a higher false positive rate than the standard Bloom filter. 
\citeauthor{Hao.2007} partition the input element set and apply different uniform hash functions for different groups of input elements $x$ \cite{Hao.2007}. The hash functions for each group are thereby independent within groups but can be dependent for different groups. For each group, trials with different hash functions are performed, and the one that results in the highest fraction of zeros in the corresponding Bloom filter is chosen. Alternatively, \citeauthor{Bruck.2006} with their Weighted Bloom filter assign more uniformly distributed hash functions to sets of elements that have a higher probability of being queried \cite{Bruck.2006}.

Other approaches proposed using \textit{non-uniformly distributed hash functions} to allow for improved functionality, especially on hardware like GPUs, where floats can be assumed instead of bits for each Bloom filter slot \cite{Werner.2015b}. Although these approaches propose to add additional functionality, they result in a higher memory footprint and increased complexity and are, therefore, best applicable only in very specific scenarios.

So far, Bloom filters that \textit{do not have a power-of-two filter size} yet still ensure efficiency have not been directly considered in the literature to the best of the author's knowledge. 
However, there is various work on Bloom filters that adopts its size if the number of elements is initially unknown but exceeds the maximum capacity of the initial filter. To do so, the Incremental Bloom filter \cite{Hao.2008} introduces a fill bound, which determines a lower bound to the allowable fraction of zeros $\mathit{foz}$ and incrementally adds an additional Bloom filter as soon as all existing Bloom filters reach this fill bound. Similarly, \cite{Almeida.2007} proposes to make Bloom filters scalable by adding additional plain Bloom filters if existing filters are full and applying a geometric progression on error bounds to keep the false positive rate constant. They consider applying new filters of increasing size $m_i=m_0\cdot s^{l-1}$ to keep the number of elements per filter constant. Further, they use a slicing technique that denotes different areas in the Bloom filter for every hash function \cite{Chang.2004, Almeida.2007}. With that, they try to avoid overlaps of hash values from different hash functions for one element and achieve more uniformly distributed false positive 
rates (compare also \cite{Bose.2008}). Another scaling approach that additionally allows for the deletion of elements from the set adopted from Counting Bloom filters \cite{Fan.1998, Bonomi.2006} is the Dynamic Bloom filter \cite{Guo.2010}. 
An alternative approach is the Block Bloom filter \cite{Putze.2009}, which consists of a set of small cache-line-sized Bloom filters. Each element is then only inserted in one of these subfilters. The selection of the filter is based on the first hash function. 
Furthermore, the Combinatorial Bloom filter (COMB) and Partitioned Combinatorial Bloom filter  (PCOMB) \cite{Hao.2009} were proposed to use a set of Bloom filters to encode situations where one element belongs to several sets. In this approach, they also partition a Bloom filter into smaller ones. However, all sub-Bloom filters are considered to be of similar size. 

Finally, the \textit{learned} Bloom filter as proposed by \citeauthor{Mitzenmacher.2018} is another way to reduce the size of Bloom filters by imitating them with a learned function, which allows for false negatives and using a very small Bloom filter to filter out these false negatives \cite{Mitzenmacher.2018}. 

\section{Methods}
To add more flexibility to Bloom filter applications, we propose the Rational Bloom filter and a Variably-Sized Block Bloom filter in the following. The chapters are structured in a broad description of the approach at the beginning before properties are analyzed systematically and remarks on an efficient implementation are given. 
Finally, the methods are evaluated according to their novelty and advantages compared to the state of the art.


\subsection{Rational Bloom Filter}
\label{sec:methods:sub:rationalbloom}
For Bloom filters, the optimal number of hash functions denoted by Equation \ref{eq:optimalk} is generally not an integer but a small rational number. An example would be a Bloom filter of size $m=10$ and $n=5$ elements to store, resulting in an optimal number of $\approx 1.386$ hash functions. This is not feasible in traditional Bloom filters as they only allow for an integer number of hash functions and, therefore, require an approximation of the optimal number of hash functions with the next integer. However, allowing a non-integer number of hash functions poses advantages compared to the traditional approaches:
\begin{itemize}
    \item For an exactly known number of elements to store and a Bloom Filter length constrained, for example, by hardware, the choice of an optimal number of hash functions actually improves the false positive rate.
    \item A rational number of hash functions allows for more flexibility in selecting other Bloom filter parameters.
\end{itemize}
For this, we define the Rational Bloom filter.
\begin{definition}[Rational Bloom filter]
    A Rational Bloom filter is a Bloom filter constructed by a non-integer number $k\in \mathbb{R}^+$ of hash functions. 
\end{definition}
Practically, this raises the question of how to apply a rational number of hash functions. For this, we propose a probabilistic approach.

\begin{definition}[Probabilistically Activated Hash Functions]
    A probabilistically activated hash function is a hash function that is not applied to every sample to be inserted in a Bloom filter. Instead, it is only activated by a probabilistic protocol. The probability of activation $0\le p_{activation}\le1, p_{activation} \in \mathbb{R}$ is thereby treated similarly to a rational number of hash functions with $p_{activation}=k$.
\end{definition}

While this initially seems to add extra effort, only small additional costs are implied in practice for $k>1$. The always-applied hash functions $H_r(x)$, with $r \in [1,\lfloor k \rfloor]$, give enough pseudo-random information that can be used to decide whether the probabilistically activated hash functions should be used for a specific sample. This gives the additional advantage that for a specific given sample, this random information created from a hash function always consistently denotes whether the additional hash function is activated or not.
Based on this, we develop a rational Bloom filter consisting of standard Bloom filter procedures for $\lfloor k\rfloor$ hash functions while the non-integer part $k-\lfloor k\rfloor$ is represented by a probabilistically activated hash function. This approach is visualized in Figure \ref{fig:rationalbloom}.
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth, trim=0 16.2cm 25.345cm 0, clip ]{RationalBloom.pdf}
    \caption{Visualization of the Rational Bloom filter for $k=2.3$ and $r=1$, with probabilistically activated hash function $H_3(x)$.}
    \label{fig:rationalbloom}
\end{figure}


\subsubsection{Properties}
It can be observed that the proposed Rational Bloom filter does not allow for false negatives:
\begin{lemma}
    \label{lemma:rational_no_fn}
    The Rational Bloom filter has no false negatives.
\end{lemma}
\begin{proof}
    The given Rational Bloom filter $BF_{\text{rational}}$ with $k$ normal hash functions and one probabilistically activated hash function $H_{\lfloor k\rfloor+1}$ has at least as many \texttt{1}-bits in the filter as the normal Bloom filter $BF$ with $\lfloor k\rfloor$  hash functions:
    $BF[i]=1 \implies BF_{\text{rational}}[i]=1 \forall i \in [0,m)$
    as the probabilistically additionally activated hash function $H_{\lfloor k\rfloor+1}(x)$ can only set additional Bloom filter slots to one. The opposite ``$\Longleftarrow$'' is not true. 
    
    A false negative would occur if and only if, during a membership query for an element in the set, the hash values would expect a \texttt{1} in the Bloom filter where there is no actual \texttt{1}. For all hash functions $H_0$ to $H_{\lfloor k\rfloor}$, this cannot be the case, as explained by the standard Bloom filter. For the probabilistically activated hash function $H_{\lfloor k\rfloor+1}$, this would only be true if it was not activated during insertion but is activated during the query. 
    As the activation is deterministic with respect to the input -- due to the creation through a hash of the input -- an activation in the query while it was not activated during insertion is impossible. Therefore, we can state that the Rational Bloom filter has no false negatives.
\end{proof}
\begin{theorem}
    The false positive rate $p_{\text{FP}}^{\text{rational}}$ of the Rational Bloom filter is smaller or equal to the false positive rate of a normal Bloom filter $p_{\text{FP}}^{\text{BF}}$:
    \begin{equation}
        p_{\text{FP}}^{\text{rational}} \leq p_{\text{FP}}^{\text{BF}}
    \end{equation}
\end{theorem}
\begin{proof}
    As described in Equation \ref{eq:optimalk}, the optimal number of hash functions $k$ is solely determined by the number of entries $n$ and the length of the Bloom filter $m$ with the assumption that the highest information can be stored for a fraction of zero $\mathit{foz}_{opt}=\frac{1}{2}$. For two Bloom filters, one standard Bloom filter $BF$ and one Rational Bloom filter $BF_{\text{rational}}$, we further assume that we choose the number of hash functions of the Rational Bloom filter $k_{\text{rational}}$ to be optimal, $k_{\text{rational}}=k^*$.  Then we can differentiate three cases depending on the actual Bloom filter size $k_{\text{BF}}$: \\
    Case a) $k_{\text{BF}}>k_{\text{rational}}$: For the normal Bloom filter, there are more than the optimal $k^*$ hash functions chosen. Therefore, the $\mathit{foz}$ is smaller than the optimal case, e.g., the filter is more full. In this case, the false positive rate will increase as it is more likely to accidentally hit a \texttt{1} in the filter. Therefore, false positives will increase compared to the optimal case $\implies p_{\text{FP}}^{\text{BF}}>p_{\text{FP}}^{\text{rational}}$.\\
    Case b) $k_{\text{BF}}<k_{\text{rational}}$: For a smaller than optimal number of hash functions, the filter will become less full. At the same time, each sample is hashed by less-than-optimal hash functions. In this case, with the exact formula for the false positive rate $p_{\text{FP}}=\left(1-\left(1-\frac{1}{m}\right)^{kn}\right)^{k}$$\implies p_{\text{FP}}^{\text{rational}} \le p_{\text{FP}}^{\text{BF}}$ \\
    Case c) $k_{\text{BF}}=k_{\text{rational}}$: In this case, the optimal $k^*$ is an integer. Therefore, $BF=BF_{\text{rational}}$ and consequently $\implies p_{\text{FP}}^{\text{rational}} = p_{\text{FP}}^{\text{BF}}$.    
\end{proof}
%Considerations on how to choose best other parameters for small Bloom filters with rational number of hash functions

\subsubsection{Efficient Implementation}
A proposed algorithm for applying a rational number of hash functions in Bloom filters is given in Algorithm \ref{alg:rationalbloom}. The integer floor of hash functions  $\{H_1, \dots, H_{\lfloor k \rfloor}\}$ are applied as in a standard Bloom filter.
\begin{algorithm}
\footnotesize
\caption{Application of Hash Functions in the Rational Bloom Filter}
\label{alg:rationalbloom}
\KwData{Element $x$, Bloom filter $BF$ with length $m$, set of always-applied hash functions $\{H_1, \dots, H_{\lfloor k \rfloor}\}$, probabilistically activated hash function $H_{\lfloor k\rfloor+1}$, rational number of hash functions $k$\;}
\KwResult{Set Bloom filter bits for indices denoted by the rational number of hash values of input element x}
\For{each $H_j$ in $\{H_1, \dots, H_{\lfloor k \rfloor}\}$}{
    % Compute the hash $h_j(x)$\;
    Set $BF[H_j(x)] \gets 1$\;
}
Set $p_{activation} = k - \lfloor k \rfloor$\;
Random hash value $H_r(x) \in [0, m]$;  // No additional calculation needed if we, e.g., choose $H_r(x)=H_{\lfloor k\rfloor}(x)$\;
\If{$H_r(x) < (p_{activation}\cdot m)$}{\label{alg:rationalbloom:decision}
    %Compute the hash $H_{k+1}(x)$\;
    Set $BF[H_{\lfloor k\rfloor+1}(x)] \gets 1$\;
}
\end{algorithm}
The rational number of $k$ is represented by a probabilistically activated hash function $H_{\lfloor k\rfloor+1}$. In practice, this probabilistic activation can be achieved efficiently by reusing random information from the last hash function $H_{\lfloor k\rfloor}(x)$.
It is known that this hash function maps uniformly from the input domain to the integer set $\{0, \dots m\}$. Comparing the obtained hash value to the proportion of the maximum value $p \cdot m$ allows for overall probabilistic activation of $H_{\lfloor k\rfloor+1}$ which is still deterministic with regards to the input element $x$ (compare Algorithm \ref{alg:rationalbloom}, Line \ref{alg:rationalbloom:decision}).
%It is important to note that we do not have to calculate additional random information $H_r(x) \in [0, h_{max}]$ to decide whether we apply $H_{\lfloor k\rfloor+1}$ because every previously calculated hash functions $\{H_1, \dots, H_{\lfloor k \rfloor}\}$ already holds enough random information (compare . 
%Therefore no expensive additional hash calculation is necessary to decide on the application of $H_{\lfloor k\rfloor+1}$. 
Furthermore, the Rational Bloom filter proposal actually allows for the hashing trick by \citeauthor{Kirsch.2006} \cite{Kirsch.2006}, which gives additional sufficient independent hash function by only an additional cheap multiplication and addition (compare Equation \ref{eq:efficienthash}).

\subsubsection{Novelty and Comparison to State of the Art} 
Compared to previous approaches, we propose the Rational Bloom filter with a proven lower false positive rate than a same-sized standard Bloom filter due to a more optimal choice of the number of used hash functions $k$. Although it implies only a small improvement of the false positive rate (deviation of false positive rate with respect to $k$ close to zero next to $k^*$), it still is a more optimal solution, especially in database environments where the number of elements to be inserted $n$ and the filter size $m$ is fixed and given by the environment. Furthermore, it is a necessity for the following propositions of more complex Bloom filter structures, which only allow a controllable false positive rate for an optimally chosen $k^*$. Our proposal directly improves on the current state of the art for Bloom filters and incorporates previous improvements in hashing, like double-hashing. 

\subsection{Variably-Sized Block Bloom Filters}
\label{sec:methods:sub:blockedbloom}
As described before, the computation of hash values is efficient for Bloom filters of size $m=2^c, c \in \mathbb{N}_0$ and, therefore, constrains the practically applicable Bloom filter sizes. To extend those, we propose Variably-Sized Bloom filters, which still make use of the easy computation of modulo with the binary \& by restricting the hash values only to subsets of the whole Bloom filter slots. 
This allows for several advantages compared to standard Bloom filters:
\begin{itemize}
    \item The corresponding Bloom filter can easily be adapted to a variable size without compromising hashing speed. 
    \item Sub-parts of the filter can directly be used as compressed versions of the stored set. 
    \item The false positives due to overlapping hash values are more evenly distributed between all elements.
\end{itemize}
We define this data structure as a Variably-Sized Bloom filter. 

\begin{definition}[Variably-Sized Bloom filter]
    We define a Variably-Sized Bloom filter to be a Bloom filter of length $m_{\text{BF}}$, with $2^c<m_{\text{BF}}<2^{c+1}, c\in \mathbb{N}_0$. That means it is a filter with its filter length $m_{\text{BF}}$ being unequal to a power-of-two. 
    \label{def:variable_sized_bf}
\end{definition}

If we number each slot of this Variably-Sized Bloom filter from $0$ to $m_{\text{BF}}-1$ we can also represent this set of indexes $I_{\text{BF}}$ with $J$ not overlapping subsets $I^j_{\text{BF}}$ each having a length $m_j, j\in \{1, \dots, J\}$. We thereby restrict the $m_j$ to be a power-of-two.
\begin{lemma}
    A random length of a Bloom filter $m_{\text{BF}}$ can be decomposed into summands $m_j$ for which $m_j =2^c$ with $c\in \mathbb{N}$ such that $m_{\text{BF}}=\sum_j m_j$, with $m_{\text{BF}}, m_j \in \mathbb{N},  j\in \{1, \dots, J\}$.
\end{lemma}
\begin{proof}
    This follows directly from the fact that every integer can be represented as a binary representation. A visualization of an example for $m_{\text{BF}}=11$ is given in Figure \ref{fig:variablesizedbloom}.
\end{proof}
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth, trim=0 17.65cm 25.345cm 0, clip]{SubsetBloom.pdf}
    \caption{A Bloom filter consisting of a set of indexed slots $I_{\text{BF}}=\{0, ..., 10\}$ and how three subsets can represent it, each having length $2^{c_j}$: $I_{\text{BF}}^1=\{0, 1, 2, 3, 4, 5, 6, 7\}$, $I_{\text{BF}}^2=\{8, 9\}$, $I_{\text{BF}}^3=\{10\}$.}
    \label{fig:variablesizedbloom}
\end{figure}
\begin{definition}[Subset Hash Functions]
    Given a Bloom filter being decomposed into sets of indexed slots $I^j_{\text{BF}}$, we can define hash functions $H_j(x)$, which only map onto their respective subset $I^j_{\text{BF}}$ each. We call those subset hash functions. 
\end{definition}
These subset hash functions can still be calculated efficiently with a modulo and an addition operation for the proposed Variably-Sized Bloom filter as subset lengths $m_j$ are defined to be powers-of-two. 
\begin{equation}
    H_j(x)=h(x)\%m_j+\min\left(I_{\text{BF}}^j\right)
\end{equation}


Based on this, we can implement Bloom filters of arbitrary length by combining variable-sized hash functions, each covering a subset of the filter while not allowing for overlaps in the subsets. 
We call those Variably-Sized Block Bloom filters.
\begin{definition}[Variably-Sized Block Bloom filter]
    The Variably-Sized Block Bloom filter is a specification of the previously defined Variably-Sized Bloom filter (compare Definition \ref{def:variable_sized_bf}) where the actual filter of length $m_{\text{BF}}$ is subdivided into $J$ blocks of sizes $m_j, j\in \{1,\dots,J\}$ with $m_j>m_{j+1}$ and $m_j=2^c, c\in\mathbb{N}$. Each block is denoted by a set of indices $I^j$ and is filled by $k_j$ subset hash functions $H_j^i(x)$, which only map to the corresponding indices $I^j$. $k_j$ is thereby the optimal number of hash functions for the respective filter block and might be rational.
\end{definition}
The idea behind this Variably-Sized Block Bloom filter is visualized in Figure \ref{fig:blockedbloom}. There the Bloom filter of length $m_{\text{BF}}=25$ is subdivided into three subsets of length $m_1=2^4$, $ m_2=2^3$, and $m_3=2^0$.
\begin{figure}
    \centering
    \includegraphics[width=0.5\columnwidth, trim=0 14.26cm 25.345cm 0, clip]{BlockedBloom.pdf}
    \caption{Visualization of a Variably-Sized Block Bloom filter of length $m_{\text{BF}}=25$ with $m_1=2^4=16$, $m_2=2^3=8$ and $m_3=2^0=1$.}
    \label{fig:blockedbloom}
\end{figure}


\subsubsection{Properties}
Based on this general construction of the Variably-Sized Block Bloom filter, we can deduce properties logically.
\begin{lemma}
    The Variably-Sized Block Bloom filter has no false negatives.
\end{lemma}
\begin{proof}
    As using a Variably-Sized Block Bloom filter is equal to using several normal Bloom filters of various sizes for the same set, the proof boils down to none of the filter blocks allowing for false negatives. 
    By definition, the filter blocks are all either normal or Rational Bloom filters, and thus, it follows from Lemma \ref{lemma:rational_no_fn} that the Block Bloom filter has no false negatives.
\end{proof}

The false positive rate of the Variably-Sized Block Bloom filter can then be calculated with the chain rule:
\begin{theorem}
    The false positive rate of the Variably-Sized block Bloom filter is:
    \begin{equation}
        p_{\text{FP}}^{\text{Block}} =\prod_j p_{\text{FP}}^j\approx \prod_j \left(1-e^{-k_jn/m_j}\right)^{k_j}
    \end{equation}
    Where $k_j$ denotes the number of hash functions and $m_j$ is the length of the $j$-th subset Bloom filter. 
\end{theorem}
\begin{proof}
    In general, there are four classes of results for a set query: a true positive or true negative answer denotes the right functioning of the Bloom filter. False negatives are not possible by construction (compare section \ref{sec:properties}), and a false positive happens if a sample is described as being part of the set which was actually not inserted in the Bloom filter. 
    For several Bloom filters representing the same set, which is similar to hash functions only mapping to subsets of the full Bloom filter, deciding whether a queried sample is in the desired set is always a combination of the comparison of values for all applied hash functions. An item can only be wrongly denoted to be in the set if all hash functions for all filters point wrongly to a \texttt{1} element. This is equal to all subset Bloom filters wrongly denoting the element to be in the set. 
    %The probability for a false positive thereby diminishes compared to only using one sub-set, as an element can only be false positive iff it is not in any of the set representations
    %if all $j$ subset Bloom filters denote an item to be in the described set, which was not originall in the set. 
\end{proof}

\begin{corollary}
    For the right choice of $k_j$, the false positive rate of the combined filters of length $m_j=2^{c_j}$ stays the same as the single Bloom filter of size $m_{\text{BF}}$. This means:
    \begin{equation}
        p_{\text{FP}}^{\text{Block}}\approx \prod_j \left(1-e^{-k_jn/m_j}\right)^{k_j}=\left(1-e^{-kn/m_{\text{BF}}}\right)^k \approx p_{\text{FP}}^{\text{BF}}
    \end{equation}
\end{corollary}
\begin{proof}
    With Equation \ref{eq:optimalk} for optimal $k^*_j=\frac{m_j}{n} \ln{2}$ and  $k^*=\frac{m_{\text{BF}}}{n} \ln{2}$:
    %\frac{m}{n}\ln 2
    \begin{equation}
        \prod_j \left(1-e^{-\frac{m_j}{n}\ln 2 \frac{n}{m_j}}\right)^{\frac{m_j}{n}\ln 2}=\left(1-e^{-\frac{m_{\text{BF}}}{n}\ln 2 \frac{n}{m_{\text{BF}}}}\right)^{\frac{m_{\text{BF}}}{n}\ln 2}
    \end{equation}
    \begin{equation}
        \prod_j \left(1-e^{-\ln 2}\right)^{\frac{m_j}{n}\ln 2}=\left(1-e^{-\ln 2 }\right)^{\frac{m_{\text{BF}}}{n}\ln 2}\\
    \end{equation}
        \begin{equation}
        \left(1-e^{-\ln 2}\right)^{\frac{\sum_j m_j}{n}\ln 2}=\left(1-e^{-\ln 2 }\right)^{\frac{m_{\text{BF}}}{n}\ln 2}\\
    \end{equation}
    And as $\sum_j m_j=m_{\text{BF}}$ by construction
    \begin{equation}
        p_{\text{FP}}^{\text{Block}} = p_{\text{FP}}^{\text{BF}}
    \end{equation}
    for the choice of optimal $k_j$. 
\end{proof}
Here, the previous proposition of Rational Bloom filters comes in handy, as a non-optimal choice of the number of hash functions due to integer rounding would introduce additional errors.



\begin{theorem}
    The proposed Block Bloom filter improves the equal distribution of false positives over the to-be-tested elements compared to a standard Bloom filter of the same size. 
\end{theorem}
\begin{proof}
%    As clashes for different hash functions, which means similar hash values for a single item $x$ and different hash functions $H_j(x)$ (compare \cite{Bose.2008}) are reduced by the blocked structure of the newly proposed filter it is less probable, that False positives occur. 
    In general, an element has a higher probability of being false positive if its footprint contains fewer ones, as only the non-zero bits hold information, and it is more probable to have overlaps with an already inserted one then. We denote that different hash functions may produce equal hash indices for one input element as a \textit{clash}. 
    For a fully filled filter with $\mathit{foz}=0.5$, a new item $x_{\text{FP}}$ is denoted false positive if, for all $k$ hash functions, the value is one, although the item was originally not inserted in the filter. The false positive rate is then:
    \begin{equation}
        p_{\text{FP}}=0.5^k.
    \end{equation}
    If hash values of $o$ hash functions clash, the probability of a false positive is increased:
    \begin{equation}
        p_{\text{FP}}^{\text{clash}}=0.5^{(k-o)} > p_{\text{FP}}
    \end{equation}
    Thus, it is desirable to avoid overlaps in hash values of different hash functions for one element. 
    
    For a given Block Bloom filter with blocks of length $m_j$ the optimal number of hash functions for each block is $k^*_j=\frac{m_j}{n} \ln{2}$ (compare Equation \ref{eq:optimalk}). So the sum of applied hash functions is equal to the optimal number of hash functions $k^*$ for a filter of the summed lengths of the blocks $m=\sum_j m_j$:   
    \begin{equation}
        k_{\text{sum}}=\sum_j k^*_j=\sum_j \frac{m_j}{n} \ln{2}= \frac{\ln{2}}{n} \sum_j m_j = \frac{m}{n} \ln{2} \stackrel{\text{Eq.} \ref{eq:optimalk}}{=} k^*
    \end{equation}
    The probability for one element $x$ being inserted into a filter $BF$ with $k^*$ hash functions having less than $k^*$ hash values is equal to the probability of hash functions delivering the same hash values. For two uniformly distributed hash functions, the probability that they have the same value is $\frac{1}{m}$ if $m$ is the length of the Bloom filter.
    For three hash functions, it is $\frac{1}{m}+\frac{2}{m}$. So, for k hash functions, it is 
    \begin{equation}
        p_{\text{clash}}=\sum_{i=1}^{k-1} \frac{i}{m}
        \label{eq:clash}
    \end{equation}
    In comparison, for a Block Bloom filter, the clash probability is:
    \begin{equation}
    \begin{aligned} 
        p_{\text{clash}}^{\text{Block}}&=\sum_j \sum_{i=1}^{k_j-1} \frac{i}{m_j}
    \end{aligned}
    \label{eq:clash_blocked}
    \end{equation}
    With mathematic reformulation and the known properties, we can then show that
    \begin{equation}
    \begin{aligned}
        p_{\text{clash}} &> p_{\text{clash}}^{\text{Block}}
    \end{aligned}
    \end{equation}
    for all $J> 1$ (compare Appendix~\ref{app:clashproof}). 
    
    
\end{proof}

\begin{corollary}
    The proposed solution requires no storage overhead for the description of the block sizes $m_j$ and the number of hash functions $k_j$.
\end{corollary}
\begin{proof}
    Additional information is the block sizes $m_j$ and the number of hash functions being used in each block $k_j$. 
    This information can be easily obtained from the information of the non-blocked representation and some implicit rules applied during construction:
    \begin{itemize}
        \item Blocks are sorted from large to small, $m_{j+1}<m_j$.
        \item The optimal number of hash functions $k_j^*$ is always chosen for each block. If necessary, a Rational Bloom filter, as described in Section \ref{sec:methods:sub:rationalbloom}, is applied for the blocks to keep a controlled false positive rate.
    \end{itemize}
    With these rules, the block sizes $m_j$ are directly encoded in the binary representation of the whole Bloom filter size $m_{\text{BF}}$, and the corresponding number of hash functions can be easily calculated with 
    \begin{equation}
        k_j^*=\frac{m_j}{n}\ln{2}
    \end{equation}

\end{proof}
\begin{conjecture}
    The proposed solution can save on processing time $t$, which means $t(BF)\geq t(BF^{\text{Block}})$ for insertion as well as querying for filter sizes $m_{\text{BF}}\neq 2^c, c \in \mathbb{N}_{0}$ and $\sum_j m_j^{\text{Block}}=m_{\text{BF}}$. 
\end{conjecture}
This is true if the runtime of one modulo calculation by $m_{\text{BF}}\neq 2^c$ is computationally more expensive than the computation of $J$ modulo operations with the binary bit trick (compare Equation~\ref{eq:modulo}).
$J$ thereby denotes the number of blocks in the corresponding Block Bloom filter and can be computed by the hamming weight of the binary representation of the full filter length $(m_{\text{BF}})_2$ \cite{Reed.1954}.

A further advantage of this Block Bloom filter is the easy and meaningful compression by simply taking subsets of the filter, which comprise a certain number of blocks. In tendency, this allows for more compression steps compared to the standard Bloom filter of size $m_{\text{BF}}=2^c$ as not only halving the size is possible but also any combination of block sizes applied in the Bloom filter. Available compression ratios are 
\begin{equation}
    \frac{\sum_i m_i}{m_{\text{BF}}}, \text{ where } i  \subseteq j.
\end{equation}

\subsubsection{Efficient Implementation}
The implementation of the Variably-Sized Block Bloom filter consists of three parts:
\begin{enumerate}
    \item Calculation of optimal BF blocks. This includes the corresponding number of hash functions~$k_j^*$.
    \item Insertion of elements in the proposed data structure.
    \item Query of set property for given elements from the proposed data structure.
\end{enumerate}
For the calculation of the Block sizes $m_j$ 
a simple restructuring of the binary representation of the overall Bloom filter size $m_{\text{BF}}$ is possible: With this representation being denoted as~$(m_{\text{BF}})_2$ with~$m_i, i\in \{\lfloor log_2(m_{\text{BF}})\rfloor,...,0\}$ denoting the binary digits, the desired Bloom filter sizes are $\{2^{m_i}\} \forall i| m_i=1$. The corresponding number of hash functions for each block is then denoted as~$k_j^*=\frac{m_j}{n}\ln{2}$ and can be calculated dynamically.

For inserting an element, an efficient approach using double hashing and the binary modulo trick:
We only hash the input element once with two independent hash functions $h_1(x)$and $h_2(x)$. Additional hash values are created with the hashing trick \cite{Kirsch.2006}. In comparison to the application in only one long Bloom filter, the Block Bloom filter needs to map the hash values to various filter lengths $m_i$.
This can be efficiently done, as all subparts of the filter are still of size $2^c, c\in \mathbb{N}$ and thus we can apply the efficient modulo operation described in Equation~\ref{eq:modulo}.
For a non-integer optimal number of hash functions $k_j$, we apply the principles of Rational Bloom filters as described in Section~\ref{sec:methods:sub:rationalbloom}. The whole algorithm for insertion is given in Algorithm~\ref{alg:blockbloom_insert}. For simplicity, this algorithm does not consider rational numbers of hash functions. 


\begin{algorithm}
\footnotesize
\caption{Inserting an Element in the Variably-Sized Block Bloom Filter}
\label{alg:blockbloom_insert}
\KwData{Element $x$, Total elements to insert $n$, Variably-Sized Block Bloom filter $BF$ of total length $m_{\text{BF}}$, Two uniform, pairwise independent hash functions $h_1(x), h_2(x)$}
\KwResult{Inserted element $x$ into the Variably-Sized Block Bloom filter}
binary $\gets$ BinaryRepresentation($m_{\text{BF}}$)\;
length $\gets$ Length(binary)\;
hash\_values $\gets h_1(x), h_2(x)$\;
offset $\gets 0$\;
\For{j $\gets$ 0 \KwTo length - 1}{
    \If{binary[$j$] == 1}{
        $m_j \gets 2^{\text{length} - j - 1}$\;
        $k_j \gets \frac{m_j}{n} \cdot \ln{2}$\;
        \For{$i \gets 0$ \KwTo $k_j$}{
            $H_i(x) = \left( (hash\_values_1 + (i + m_j) \cdot hash\_values_2) \& (m_j - 1) \right) + \text{offset}$\;
            $BF[H_i(x)] \gets 1$\;
            offset += $m_j$\;
        }
    }
}
\end{algorithm}

Querying an element is similar to insertion, as the lengths of the different blocks are calculated in the same way. Once the hash values are obtained, checking for \texttt{1}s works similarly to a standard BF. 


\subsubsection{Novelty and Comparison to State of the Art} 

With this Variably-Sized Block Bloom filter, we propose a new Bloom filter variant, which allows for variable filter sizes and efficient modulo operation simultaneously. This is only possible as the previously proposed Rational Bloom filter serves as a basis for splitting the variable length Bloom filter into smaller pieces with a power-of-two length. An additional advantage is the better distribution of false positives over all elements in the universe, as a clash of hash functions is less probable. 
Further, the variable size has a special impact for large Bloom filters as they appear if the data structure is used to store large sparse set information for efficient random access (compare \cite{Werner.2021}).

To the best of our knowledge, no similar approach has been proposed in the literature. While there are approaches that split the Bloom filter into smaller pieces \cite{Hao.2009, Hao.2008, Almeida.2007, Putze.2009}, they mainly do this to allow scalability or avoid unnecessary distributed RAM access. To our understanding, all of their approaches still consider Bloom filters, with a size being power-of-two or not taking care of efficient implementation. Additionally, the subparts of the filter are mostly similar in size. 

\section{Implementation Artifacts of the Proposed Approaches}
To verify our theoretical considerations, we implemented the Rational Bloom Filter and Varying-Sized Block Bloom filter in C++. In these implementations, we used a Murmur Hash together with the hashing trick and efficient modulo calculation using binary arithmetic. As a baseline, we also implemented a standard Bloom filter with the same efficiency measures.

Interestingly, implementing the \textit{Rational Bloom filter} showed artifacts that were not expected and need further investigation. The false positive rate has local minima not at the calculated optimal rational value of hash functions but especially at nearby integer values. To observe this, we refer to the results in Figure \ref{fig:rational_bloom_experiment}. For example, the false positive rate for a filter of length $m=131,072$ filled with $60,000$ elements (brown line in the bottom graph) has its global minimum at $k=2$ and another local minimum at $k=1$, although the optimal value lies in between (brown cross).
\begin{figure}
    \centering

    \includegraphics[width=\linewidth]{rational_bloom_fp_with_foz-8192-131072_new.pdf}
    \caption{False positive rate of a Rational Bloom filters with filter sizes 8,192 (top) and 131,072 bit (bottom) for various numbers of hash functions $k$ and number of elements inserted $n$. To obtain the false positive rate, the filter was queried for 10,000 elements that had not been inserted. Experiments with a fraction of zero of 0.5±0.02 are shadowed grey. Theoretically, calculated optimal configurations are denoted by a cross.}
    \label{fig:rational_bloom_experiment}
\end{figure}
This result is counterintuitive to the authors, and we are unable to provide a satisfactory explanation for this issue. We believe that this is likely due to the non-uniform behavior of the hashing algorithm. However, similar artifacts were also observed with other hash functions like SHA256, which should lead to a more uniform distribution of hash values. Additionally, larger filter sizes and numbers of elements inserted did not improve this behavior, although according to logical reasoning, this should reduce the effect of non-uniform hash functions. 
When comparing the fraction of zero $\mathit{foz}$ of the close-to-optimal Rational Bloom filter to that of the Bloom filters with an integer number of hash functions, we observe that the Rational Bloom filter actually achieves better $\mathit{foz}$ rates. 

For the \textit{Variably-Sized Block Bloom filter}, we achieve similar rates of false positives compared to a standard Bloom filter. Improvements in insertion time could not be measured.

Although our practical experiments reveal that the theoretical gains shown by proof could not be fully materialized in the real filters, we still think that the proposed approaches serve as a valuable contribution to Bloom filter theory, as they allow new possibilities for applications. We see special benefits in future explorations of learned Bloom filter approaches and filters with non-similar hash functions for different elements. 


\section{Conclusion}
In this paper, we proposed two new Bloom filter variants allowing for the application of a rational number of hash functions (\textit{Rational Bloom filter}) and variable filter sizes (\textit{Variably-Sized Block Bloom filter}) without performance degradation. With that, we relax existing constraints on Bloom filters, which are theoretically beneficial in scenarios where either small numbers of hash functions are used or large-sized Bloom filters are applied. 
Furthermore, the probabilistic activation of hash functions as proposed by the Rational Bloom filters opens new possible research directions: It needs to be investigated how learned approaches might use rational numbers of hash functions. This extends existing approaches on learned Bloom filters, which only use learned pre-filters to increase Bloom filter efficiency. 

% Along these dimensions: 
% \begin{itemize}
%     \item to account for the \textit{FP-rate}
%     \item the \textit{sacalability} of the Bloom filter approach, especially with initially unknown dataset sizes,
%     \item the \textit{deletion of elements} which is not possible with a standard Bloom filter, 
%     \item to implement an \textit{efficient hashing} method, which does not negatively influence the performance of the Bloom filter, and
%     \item the correct determination of the \textit{number of hash functions} to use. 
% \end{itemize}

% Learn the probabilistic activation of Bloom filters.





%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
This work is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 507196470.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}


%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Deduction of Optimal number of Hash Functions}
\label{app:k}
For completeness, we give the derivation of the formula for the optimal number of hash functions $k^*$ in the following.
Given the probability of false positives with respect to the number of hash functions $k$:
\begin{equation}
    p_{\text{FP}}=\left(1-\left(1-\frac{1}{m}\right)^{kn}\right)^k 
\end{equation}
When $m$ is large, we can expect $\left(1-\frac{1}{m}\right)\approx e^{-1/m}$:
\begin{equation}
    p_{\text{FP}}\approx\left(1-e^{-kn/m}\right)^k 
\end{equation}
With logarithm:
\begin{equation}
\begin{split}
    \ln(p_{\text{FP}})&\approx \ln\left(\left(1-e^{-kn/m}\right)^k \right)\\
    & = k*\ln\left(1-e^{-kn/m}\right)
\end{split}
\end{equation}
Differentiating this with respect to $k$:
\begin{equation}
\frac{\partial}{\partial k}\left(k \ln(1 - e^{-kn/m})\right) = \ln\left(1 - e^{-kn/m}\right) + \frac{k n e^{-kn/m}}{m \left(1 - e^{-k n/m}\right)}
\end{equation}
Substitute with  $x = e^{-k n/m}\in (0,1)$:
\begin{equation}
    \ln(1-x)-\ln(x)\frac{x}{1-x}=\frac{(1-x)\ln(1-x)-x\ln(x)}{1-x}
\end{equation}
With that, we know that the denominator is always $>0$, and it is easy to determine that the numerator is $0$ for $x=1/2$. Based on this, the definition of $x$, and the monotonic increasing of the  $\ln$ function, we can derive the optimum $k^*$:
\begin{equation}
    k^*=\frac{m}{n}\ln(2)
\end{equation}

\section{Comparison of Clashes of Hash Functions for Standard Bloom Filters and the Proposed Block Bloom Filter}
\label{app:clashproof}
In the following, we investigate how the blocking of the Bloom filter, as proposed in this paper, influences the probability of hash functions clashing. A clash is thereby defined as a superposition of output indices of given hash functions in one index of the Bloom filter.

Given the probabilities for a clash of hash functions for a standard Bloom filter 
\begin{equation}
    p_{\text{clash}}=\sum_{i=1}^{k-1} \frac{i}{m}
    \label{eq:clash_app}
\end{equation}
In comparison, for a Variably-Sized Block Bloom filter, the clash probability is:
\begin{equation}
\begin{aligned} 
    p_{\text{clash}}^{\text{Block}}&=\sum_j \sum_{i=1}^{k_j-1} \frac{i}{m_j}
\end{aligned}
\label{eq:clash_blocked_app}
\end{equation}
We start by simplifying equation~\ref{eq:clash_blocked_app} by applying the summation formula:
\begin{equation}
    \begin{aligned} 
        p_{\text{clash}}^{\text{Block}} &=\sum_j \frac{1}{m_j}\frac{k_j(k_j-1)}{2}\\
\end{aligned}
\end{equation}
With the knowledge $k_j=m_j\frac{\ln{2}}{n}$:
\begin{equation}
\begin{aligned}
        p_{\text{clash}}^{\text{Block}}&=\sum_j \frac{\ln{2}(k_j-1)}{2n}\\
        &=\frac{\ln{2}}{2n} \sum_j (k_j -1)\\
        &=\frac{\ln{2}}{2n} (k-J)\\
        %&=\frac{\ln{2}}{2n} (m\frac{\ln{2}}{n}-J)\\
    \end{aligned}
    \label{eq:clash_blocked1}
\end{equation}
We now look at equation~\ref{eq:clash_app}, with the summation formula and the knowledge, that $k=m\frac{\ln{2}}{n}$:
\begin{equation}
    \begin{aligned}
        p_{\text{clash}}&=\sum_{i=1}^{k-1} \frac{i}{m}\\
        &=\frac{k(k-1)}{2m}\\
        &= \frac{\ln{2}}{2n}(k-1)
    \end{aligned}
\end{equation}
We know that $J>1$, as $J\in \mathbb{N}$ and $J=1$ would fall back to the standard case of a Bloom filter of length $2^c, c\in\mathbb{N}_0$. Therefore, it is also true that:
\begin{equation}
    \begin{aligned}
        -J&<-1\\
        k-J&<k-1\\
        \frac{\ln{2}}{2n} (k-J)&< \frac{\ln{2}}{2n}(k-1)\\
        p_{\text{clash}}^{\text{Block}} &<p_{\text{clash}}
    \end{aligned}
\end{equation}

\end{document}
\endinput
%%
%% End of file `sample-acmsmall-submission.tex'.
