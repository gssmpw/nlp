@article{likeradio1,
  title={Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation},
  author={Ma, Jiabo and Guo, Zhengrui and Zhou, Fengtao and Wang, Yihui and Xu, Yingxue and Cai, Yu and Zhu, Zhengjie and Jin, Cheng and Jiang, Yi Lin Xinrui and Han, Anjia and others},
  journal={arXiv preprint arXiv:2407.18449},
  year={2024}
}


@article{likeradio2,
  title={Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders},
  author={Shi, Min and Liu, Fuxiao and Wang, Shihao and Liao, Shijia and Radhakrishnan, Subhashree and Huang, De-An and Yin, Hongxu and Sapra, Karan and Yacoob, Yaser and Shi, Humphrey and others},
  journal={arXiv preprint arXiv:2408.15998},
  year={2024}
}


@article{likeradio3,
  title={UNIC: Universal Classification Models via Multi-teacher Distillation},
  author={Sariyildiz, Mert Bulent and Weinzaepfel, Philippe and Lucas, Thomas and Larlus, Diane and Kalantidis, Yannis},
  journal={arXiv preprint arXiv:2408.05088},
  year={2024}
}

@article{likeradio4,
  title={UNIT: Unifying Image and Text Recognition in One Vision Encoder},
  author={Zhu, Yi and Zhou, Yanpeng and Wang, Chunwei and Cao, Yang and Han, Jianhua and Hou, Lu and Xu, Hang},
  journal={arXiv preprint arXiv:2409.04095},
  year={2024}
}

@misc{wei2022contrastive,
      title={Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation}, 
      author={Yixuan Wei and Han Hu and Zhenda Xie and Zheng Zhang and Yue Cao and Jianmin Bao and Dong Chen and Baining Guo},
      year={2022},
      eprint={2205.14141},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@Article{kessy2018whitening,
  author={Agnan Kessy and Alex Lewin and Korbinian Strimmer},
  title={{Optimal Whitening and Decorrelation}},
  journal={The American Statistician},
  year=2018,
  volume={72},
  number={4},
  pages={309-314},
  month={October},
  keywords={},
  doi={10.1080/00031305.2016.127},
  abstract={ Whitening, or sphering, is a common preprocessing step in statistical analysis to transform random variables to orthogonality. However, due to rotational freedom there are infinitely many possible whitening procedures. Consequently, there is a diverse range of sphering methods in use, for example, based on principal component analysis (PCA), Cholesky matrix decomposition, and zero-phase component analysis (ZCA), among others. Here, we provide an overview of the underlying theory and discuss five natural whitening procedures. Subsequently, we demonstrate that investigating the cross-covariance and the cross-correlation matrix between sphered and original variables allows to break the rotational invariance and to identify optimal whitening transformations. As a result we recommend two particular approaches: ZCA-cor whitening to produce sphered variables that are maximally similar to the original variables, and PCA-cor whitening to obtain sphered variables that maximally compress the original variables.},
  url={https://ideas.repec.org/a/taf/amstat/v72y2018i4p309-314.html}
}

@inproceedings{Bell1997THEI,
  title={THE ``INDEPENDENT COMPONENTS''' OF NATURAL SCENES ARE EDGE FILTERS 3329 recover the causes},
  author={Anthony J. Bell and Terrence J. Sejnowski},
  year={1997},
  url={https://api.semanticscholar.org/CorpusID:18326486}
}

@article{Silvester2000DeterminantsOB,
  title={Determinants of block matrices},
  author={John R. Silvester},
  journal={The Mathematical Gazette},
  year={2000},
  volume={84},
  pages={460 - 467},
  url={https://api.semanticscholar.org/CorpusID:41879675}
}

@ARTICLE{Pratt1969Hadamard,
  author={Pratt, W.K. and Kane, J. and Andrews, H.C.},
  journal={Proceedings of the IEEE}, 
  title={Hadamard transform image coding}, 
  year={1969},
  volume={57},
  number={1},
  pages={58-68},
  keywords={Error correction;Error correction codes;Image coding;Fourier transforms;Fast Fourier transforms;Bandwidth;Image reconstruction;Pulse modulation;Computer errors;Digital images},
  doi={10.1109/PROC.1969.6869}}

@article{Sylvester1867LXTO,
  title={LX. Thoughts on inverse orthogonal matrices, simultaneous signsuccessions, and tessellated pavements in two or more colours, with applications to Newton's rule, ornamental tile-work, and the theory of numbers},
  author={James Sylvester},
  journal={Philosophical Magazine Series 1},
  year={1867},
  volume={34},
  pages={461-475},
  url={https://api.semanticscholar.org/CorpusID:118420043}
}

@article{Paley1933OnOM,
  title={On Orthogonal Matrices},
  author={R E Paley},
  journal={Journal of Mathematics and Physics},
  year={1933},
  volume={12},
  pages={311-320},
  url={https://api.semanticscholar.org/CorpusID:124410493}
}

@INPROCEEDINGS{roy2007effectiverank,
  author={Roy, Olivier and Vetterli, Martin},
  booktitle={2007 15th European Signal Processing Conference}, 
  title={The effective rank: A measure of effective dimensionality}, 
  year={2007},
  volume={},
  number={},
  pages={606-610},
  keywords={Entropy;Signal processing;Covariance matrices;Europe;Random processes;Matrix decomposition;Eigenvalues and eigenfunctions},
  doi={}}


@INPROCEEDINGS{kanj2022whitening,
  author={Kanj, Hind and Trioux, Anthony and Coudoux, François-Xavier and Gharbi, Mohamed and Corlay, Patrick and Kieffer, Michel},
  booktitle={2022 11th International Symposium on Signal, Image, Video and Communications (ISIVC)}, 
  title={A Comparative Study of the Whitening Methods in Linear Video Coding and Transmission Schemes}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Video coding;Wireless communication;Transmitters;Simulation;Packet loss;Transforms;Quality assessment;Wireless Video Transmission;Linear Video Coding and Transmission (LVCT);SoftCast;Hadamard;Packet loss},
  doi={10.1109/ISIVC54825.2022.9800738}}

@InProceedings{ranzinger2023amradio,
    author    = {Ranzinger, Mike and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
    title     = {AM-RADIO: Agglomerative Vision Foundation Model Reduce All Domains Into One},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2024},
    pages     = {12490-12500}
}

@article{kuhn1955hungarian,
author = {Kuhn, H. W.},
title = {The Hungarian method for the assignment problem},
journal = {Naval Research Logistics Quarterly},
volume = {2},
number = {1-2},
pages = {83-97},
year = {1955},
doi = {https://doi.org/10.1002/nav.3800020109},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800020109},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800020109},
abstract = {Abstract Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the “assignment problem” is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@misc{sun2023dimefm,
      title={DIME-FM: DIstilling Multimodal and Efficient Foundation Models}, 
      author={Ximeng Sun and Pengchuan Zhang and Peizhao Zhang and Hardik Shah and Kate Saenko and Xide Xia},
      year={2023},
      eprint={2303.18232},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{kim2018paraphrasing,
author = {Kim, Jangho and Park, SeongUk and Kwak, Nojun},
title = {Paraphrasing Complex Network: Network Compression via Factor Transfer},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Many researchers have sought ways of model compression to reduce the size of a deep neural network (DNN) with minimal performance degradation in order to use DNNs in embedded systems. Among the model compression methods, a method called knowledge transfer is to train a student network with a stronger teacher network. In this paper, we propose a novel knowledge transfer method which uses convolutional operations to paraphrase teacher's knowledge and to translate it for the student. This is done by two convolutional modules, which are called a paraphraser and a translator. The paraphraser is trained in an unsupervised manner to extract the teacher factors which are defined as paraphrased information of the teacher network. The translator located at the student network extracts the student factors and helps to translate the teacher factors by mimicking them. We observed that our student network trained with the proposed factor transfer method outperforms the ones trained with conventional knowledge transfer methods.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {2765–2774},
numpages = {10},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@inproceedings{Mirzadeh2019ImprovedKD,
  title={Improved Knowledge Distillation via Teacher Assistant},
  author={Seyed Iman Mirzadeh and Mehrdad Farajtabar and Ang Li and Nir Levine and Akihiro Matsukawa and Hassan Ghasemzadeh},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:212908749}
}

@INPROCEEDINGS {beyer2022goodteacher,
author = {L. Beyer and X. Zhai and A. Royer and L. Markeeva and R. Anil and A. Kolesnikov},
booktitle = {2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Knowledge distillation: A good teacher is patient and consistent},
year = {2022},
volume = {},
issn = {},
pages = {10915-10924},
abstract = {There is a growing discrepancy in computer vision between large-scale models that achieve state-of-the-art performance and models that are affordable in practical applications. In this paper we address this issue and significantly bridge the gap between these two types of models. Throughout our empirical investigation we do not aim to necessarily propose a new method, but strive to identify a robust and effective recipe for making state-of-the-art large scale models affordable in practice. We demonstrate that, when performed correctly, knowledge distillation can be a powerful tool for reducing the size of large models without compromising their performance. In particular, we uncover that there are certain implicit design choices, which may drastically affect the effectiveness of distillation. Our key contribution is the explicit identification of these design choices, which were not previously articulated in the literature. We back up our findings by a comprehensive empirical study, demonstrate compelling results on a wide range of vision datasets and, in particular, obtain a state-of-the-art ResNet-50 model for ImageNet, which achieves 82.8% top-1 accuracy.},
keywords = {training;manifolds;computer vision;schedules;image coding;computational modeling;data models},
doi = {10.1109/CVPR52688.2022.01065},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR52688.2022.01065},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}
@software{yolov8_ultralytics,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@article{Romero2014FitNetsHF,
  title={FitNets: Hints for Thin Deep Nets},
  author={Adriana Romero and Nicolas Ballas and Samira Ebrahimi Kahou and Antoine Chassang and Carlo Gatta and Yoshua Bengio},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6550},
  url={https://api.semanticscholar.org/CorpusID:2723173}
}

@article{huang2017like,
  author       = {Zehao Huang and
                  Naiyan Wang},
  title        = {Like What You Like: Knowledge Distill via Neuron Selectivity Transfer},
  journal      = {CoRR},
  volume       = {abs/1707.01219},
  year         = {2017},
  url          = {http://arxiv.org/abs/1707.01219},
  eprinttype    = {arXiv},
  eprint       = {1707.01219},
  timestamp    = {Mon, 13 Aug 2018 16:48:41 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HuangW17a.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS {ahn2019variational,
author = {S. Ahn and S. Hu and A. Damianou and N. D. Lawrence and Z. Dai},
booktitle = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Variational Information Distillation for Knowledge Transfer},
year = {2019},
volume = {},
issn = {},
pages = {9155-9163},
abstract = {Transferring knowledge from a teacher neural network pretrained on the same or a similar task to a student neural network can significantly improve the performance of the student neural network. Existing knowledge transfer approaches match the activations or the corresponding hand-crafted features of the teacher and the student networks. We propose an information-theoretic framework for knowledge transfer which formulates knowledge transfer as maximizing the mutual information between the teacher and the student networks. We compare our method with existing knowledge transfer methods on both knowledge distillation and transfer learning tasks and show that our method consistently outperforms existing methods. We further demonstrate the strength of our method on knowledge transfer across heterogeneous network architectures by transferring knowledge from a convolutional neural network (CNN) to a multi-layer perceptron (MLP) on CIFAR-10. The resulting MLP significantly outperforms the-state-of-the-art methods and it achieves similar performance to the CNN with a single convolutional layer.},
keywords = {},
doi = {10.1109/CVPR.2019.00938},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2019.00938},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@misc{sariyildiz2024unic,
      title={UNIC: Universal Classification Models via Multi-teacher Distillation}, 
      author={Mert Bulent Sariyildiz and Philippe Weinzaepfel and Thomas Lucas and Diane Larlus and Yannis Kalantidis},
      year={2024},
      eprint={2408.05088},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.05088}, 
}

@misc{zhu2024unit,
      title={UNIT: Unifying Image and Text Recognition in One Vision Encoder}, 
      author={Yi Zhu and Yanpeng Zhou and Chunwei Wang and Yang Cao and Jianhua Han and Lu Hou and Hang Xu},
      year={2024},
      eprint={2409.04095},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.04095}, 
}

@inproceedings{
shang2024theia,
title={Theia: Distilling Diverse Vision Foundation Models for Robot Learning},
author={Jinghuan Shang and Karl Schmeckpeper and Brandon B. May and Maria Vittoria Minniti and Tarik Kelestemur and David Watkins and Laura Herlant},
booktitle={8th Annual Conference on Robot Learning},
year={2024},
url={https://openreview.net/forum?id=ylZHvlwUcI}
}

@misc{ashkboos2024quarotoutlierfree4bitinference,
      title={QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs}, 
      author={Saleh Ashkboos and Amirkeivan Mohtashami and Maximilian L. Croci and Bo Li and Martin Jaggi and Dan Alistarh and Torsten Hoefler and James Hensman},
      year={2024},
      eprint={2404.00456},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.00456}, 
}

@INPROCEEDINGS {heo2019overhaul,
author = {B. Heo and J. Kim and S. Yun and H. Park and N. Kwak and J. Choi},
booktitle = {2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {A Comprehensive Overhaul of Feature Distillation},
year = {2019},
volume = {},
issn = {},
pages = {1921-1930},
abstract = {We investigate the design aspects of feature distillation methods achieving network compression and propose a novel feature distillation method in which the distillation loss is designed to make a synergy among various aspects: teacher transform, student transform, distillation feature position and distance function. Our proposed distillation loss includes a feature transform with a newly designed margin ReLU, a new distillation feature position, and a partial L2 distance function to skip redundant information giving adverse effects to the compression of student. In ImageNet, our proposed method achieves 21.65% of top-1 error with ResNet50, which outperforms the performance of the teacher network, ResNet152. Our proposed method is evaluated on various tasks such as image classification, object detection and semantic segmentation and achieves a significant performance improvement in all tasks. The code is available at bhheo.github.io/overhaul.},
keywords = {transforms;task analysis;training;jacobian matrices;image coding;neurons;artificial intelligence},
doi = {10.1109/ICCV.2019.00201},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV.2019.00201},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {nov}
}


@inproceedings{edgevit,
  title={EdgeVITs: Competing light-weight CNNs on mobile devices with vision transformers},
  author = {Pan, Junting and Bulat, Adrian and Tan, Fuwen and Zhu, Xiatian and Dudziak, Lukasz and Li, Hongsheng and Tzimiropoulos, Georgios and Martinez, Brais},
  booktitle={ECCV},
  year={2022}
}

@INPROCEEDINGS {sun2021dynamic,
author = {X. Sun and R. Panda and C. Chen and A. Oliva and R. Feris and K. Saenko},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Dynamic Network Quantization for Efficient Video Inference},
year = {2021},
volume = {},
issn = {},
pages = {7355-7365},
abstract = {Deep convolutional networks have recently achieved great success in video recognition, yet their practical realization remains a challenge due to the large amount of computational resources required to achieve robust recognition. Motivated by the effectiveness of quantization for boosting efficiency, in this paper, we propose a dynamic network quantization framework, that selects optimal precision for each frame conditioned on the input for efficient video recognition. Specifically, given a video clip, we train a very lightweight network in parallel with the recognition network, to produce a dynamic policy indicating which numerical precision to be used per frame in recognizing videos. We train both networks effectively using standard backpropagation with a loss to achieve both competitive performance and resource efficiency required for video recognition. Extensive experiments on four challenging diverse benchmark datasets demonstrate that our proposed approach provides significant savings in computation and memory usage while outperforming the existing state-of-the-art methods. Project page: https://cs-people.bu.edu/sunxm/VideoIQ/project.html.},
keywords = {backpropagation;computer vision;quantization (signal);benchmark testing;boosting;standards},
doi = {10.1109/ICCV48922.2021.00728},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00728},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@misc{wei2022featuredistillation,
      title={Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation}, 
      author={Yixuan Wei and Han Hu and Zhenda Xie and Zheng Zhang and Yue Cao and Jianmin Bao and Dong Chen and Baining Guo},
      year={2022},
      eprint={2205.14141},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zuchniak2023multiteacher,
      title={Multi-teacher knowledge distillation as an effective method for compressing ensembles of neural networks}, 
      author={Konrad Zuchniak},
      year={2023},
      eprint={2302.07215},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{liu2020adamultiteachr,
	doi = {10.1016/j.neucom.2020.07.048},
  
	url = {https://doi.org/10.1016%2Fj.neucom.2020.07.048},
  
	year = 2020,
	month = {nov},
  
	publisher = {Elsevier {BV}},
  
	volume = {415},
  
	pages = {106--113},
  
	author = {Yuang Liu and Wei Zhang and Jun Wang},
  
	title = {Adaptive multi-teacher multi-level knowledge distillation},
  
	journal = {Neurocomputing}
}

@misc{yuan2020reinforced,
      title={Reinforced Multi-Teacher Selection for Knowledge Distillation}, 
      author={Fei Yuan and Linjun Shou and Jian Pei and Wutao Lin and Ming Gong and Yan Fu and Daxin Jiang},
      year={2020},
      eprint={2012.06048},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hamidi2024trainteachermodeleffective,
      title={How to Train the Teacher Model for Effective Knowledge Distillation}, 
      author={Shayan Mohajer Hamidi and Xizhen Deng and Renhao Tan and Linfeng Ye and Ahmed Hussein Salamah},
      year={2024},
      eprint={2407.18041},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2407.18041}, 
}

@misc{liu2022normalizedfeaturedistillationsemantic,
      title={Normalized Feature Distillation for Semantic Segmentation}, 
      author={Tao Liu and Xi Yang and Chenshu Chen},
      year={2022},
      eprint={2207.05256},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2207.05256}, 
}

@misc{ruder2017knowledgeadaptationteachingadapt,
      title={Knowledge Adaptation: Teaching to Adapt}, 
      author={Sebastian Ruder and Parsa Ghaffari and John G. Breslin},
      year={2017},
      eprint={1702.02052},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1702.02052}, 
}

@ARTICLE{zhao2022collabteaching,
  author={Zhao, Haoran and Sun, Xin and Dong, Junyu and Chen, Changrui and Dong, Zihe},
  journal={IEEE Transactions on Cybernetics}, 
  title={Highlight Every Step: Knowledge Distillation via Collaborative Teaching}, 
  year={2022},
  volume={52},
  number={4},
  pages={2070-2081},
  doi={10.1109/TCYB.2020.3007506}}

@inproceedings{yang2020modelcompression,
author = {Yang, Ze and Shou, Linjun and Gong, Ming and Lin, Wutao and Jiang, Daxin},
title = {Model Compression with Two-Stage Multi-Teacher Knowledge Distillation for Web Question Answering System},
year = {2020},
isbn = {9781450368223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3336191.3371792},
doi = {10.1145/3336191.3371792},
abstract = {Deep pre-training and fine-tuning models (such as BERT and OpenAI GPT) have demonstrated excellent results in question answering areas. However, due to the sheer amount of model parameters, the inference speed of these models is very slow. How to apply these complex models to real business scenarios becomes a challenging but practical problem. Previous model compression methods usually suffer from information loss during the model compression procedure, leading to inferior models compared with the original one. To tackle this challenge, we propose a Two-stage Multi-teacher Knowledge Distillation (TMKD for short) method for web Question Answering system. We first develop a general Q\&A distillation task for student model pre-training, and further fine-tune this pre-trained student model with multi-teacher knowledge distillation on downstream tasks (like Web Q\&A task, MNLI, SNLI, RTE tasks from GLUE), which effectively reduces the overfitting bias in individual teacher models, and transfers more general knowledge to the student model. The experiment results show that our method can significantly outperform the baseline methods and even achieve comparable results with the original teacher models, along with substantial speedup of model inference.},
booktitle = {Proceedings of the 13th International Conference on Web Search and Data Mining},
pages = {690–698},
numpages = {9},
keywords = {model compression, distillation pre-training, multi-teacher, two-stage, knowledge distillation},
location = {Houston, TX, USA},
series = {WSDM '20}
}

@inproceedings{Park2020FeatureLevelEK,
  title={Feature-Level Ensemble Knowledge Distillation for Aggregating Knowledge from Multiple Networks},
  author={Seonguk Park and Nojun Kwak},
  booktitle={European Conference on Artificial Intelligence},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:220378802}
}

@inproceedings{you2017multiteacher,
author = {You, Shan and Xu, Chang and Xu, Chao and Tao, Dacheng},
title = {Learning from Multiple Teacher Networks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098135},
doi = {10.1145/3097983.3098135},
abstract = {Training thin deep networks following the student-teacher learning paradigm has received intensive attention because of its excellent performance. However, to the best of our knowledge, most existing work mainly considers one single teacher network. In practice, a student may access multiple teachers, and multiple teacher networks together provide comprehensive guidance that is beneficial for training the student network. In this paper, we present a method to train a thin deep network by incorporating multiple teacher networks not only in output layer by averaging the softened outputs (dark knowledge) from different networks, but also in the intermediate layers by imposing a constraint about the dissimilarity among examples. We suggest that the relative dissimilarity between intermediate representations of different examples serves as a more flexible and appropriate guidance from teacher networks. Then triplets are utilized to encourage the consistence of these relative dissimilarity relationships between the student network and teacher networks. Moreover, we leverage a voting strategy to unify multiple relative dissimilarity information provided by multiple teacher networks, which realizes their incorporation in the intermediate layers. Extensive experimental results demonstrated that our method is capable of generating a well-performed student network, with the classification accuracy comparable or even superior to all teacher networks, yet having much fewer parameters and being much faster in running.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1285–1294},
numpages = {10},
keywords = {multiple teacher networks, deep learning, knowledge transfer, triplet loss},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@misc{lan2018knowledge,
      title={Knowledge Distillation by On-the-Fly Native Ensemble}, 
      author={Xu Lan and Xiatian Zhu and Shaogang Gong},
      year={2018},
      eprint={1806.04606},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{Asif2019EnsembleKD,
  title={Ensemble Knowledge Distillation for Learning Improved and Efficient Networks},
  author={Umar Asif and Jianbin Tang and Stefan Harrer},
  booktitle={European Conference on Artificial Intelligence},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:202660953}
}

@inproceedings{Fukuda2017EfficientKD,
  title={Efficient Knowledge Distillation from an Ensemble of Teachers},
  author={Takashi Fukuda and Masayuki Suzuki and Gakuto Kurata and Samuel Thomas and Jia Cui and Bhuvana Ramabhadran},
  booktitle={Interspeech},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:30258763}
}

@misc{oquab2023dinov2,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2023},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{awais2023foundational,
      title={Foundational Models Defining a New Era in Vision: A Survey and Outlook}, 
      author={Muhammad Awais and Muzammal Naseer and Salman Khan and Rao Muhammad Anwer and Hisham Cholakkal and Mubarak Shah and Ming-Hsuan Yang and Fahad Shahbaz Khan},
      year={2023},
      eprint={2307.13721},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@InProceedings{radford2021clip,
  title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
  author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {8748--8763},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
  abstract = 	 {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.}
}

@software{ilharco2021openclip,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@misc{kirillov2023sam,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and Nikhila Ravi and Hanzi Mao and Chloe Rolland and Laura Gustafson and Tete Xiao and Spencer Whitehead and Alexander C. Berg and Wan-Yen Lo and Piotr Dollár and Ross Girshick},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{xie2020noisystudent,
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V.},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Self-Training With Noisy Student Improves ImageNet Classification}, 
  year={2020},
  volume={},
  number={},
  pages={10684-10695},
  doi={10.1109/CVPR42600.2020.01070}}

@INPROCEEDINGS{zhou2017ade20k,
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Scene Parsing through ADE20K Dataset}, 
  year={2017},
  volume={},
  number={},
  pages={5122-5130},
  doi={10.1109/CVPR.2017.544}}

@inproceedings{
shekhar2023objectives,
title={Objectives Matter: Understanding the Impact of Self-Supervised Objectives on Vision Transformer Representations},
author={Shashank Shekhar and Florian Bordes and Pascal Vincent and Ari S. Morcos},
booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
year={2023},
url={https://openreview.net/forum?id=DdqOifSy4q}
}

@inproceedings{
Wu2020Understanding,
title={Understanding and Improving Information Transfer in Multi-Task Learning},
author={Sen Wu and Hongyang R. Zhang and Christopher Ré},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SylzhkBtDB}
}

@misc{liu2023improvedllava,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}

@misc{liu2023llava,
      title={Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      publisher={arXiv:2304.08485},
      year={2023},
}

@misc{hatamizadeh2023fastervit,
      title={FasterViT: Fast Vision Transformers with Hierarchical Attention}, 
      author={Ali Hatamizadeh and Greg Heinrich and Hongxu Yin and Andrew Tao and Jose M. Alvarez and Jan Kautz and Pavlo Molchanov},
      year={2023},
      eprint={2306.06189},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{cai2023efficientvit,
      title={EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction}, 
      author={Han Cai and Junyan Li and Muyan Hu and Chuang Gan and Song Han},
      year={2023},
      eprint={2205.14756},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{schuhmann2021laion400m,
      title={LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs}, 
      author={Christoph Schuhmann and Richard Vencu and Romain Beaumont and Robert Kaczmarczyk and Clayton Mullis and Aarush Katta and Theo Coombes and Jenia Jitsev and Aran Komatsuzaki},
      year={2021},
      eprint={2111.02114},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@INPROCEEDINGS{deng2009imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}

@misc{gadre2023datacomp,
      title={DataComp: In search of the next generation of multimodal datasets}, 
      author={Samir Yitzhak Gadre and Gabriel Ilharco and Alex Fang and Jonathan Hayase and Georgios Smyrnis and Thao Nguyen and Ryan Marten and Mitchell Wortsman and Dhruba Ghosh and Jieyu Zhang and Eyal Orgad and Rahim Entezari and Giannis Daras and Sarah Pratt and Vivek Ramanujan and Yonatan Bitton and Kalyani Marathe and Stephen Mussmann and Richard Vencu and Mehdi Cherti and Ranjay Krishna and Pang Wei Koh and Olga Saukh and Alexander Ratner and Shuran Song and Hannaneh Hajishirzi and Ali Farhadi and Romain Beaumont and Sewoong Oh and Alex Dimakis and Jenia Jitsev and Yair Carmon and Vaishaal Shankar and Ludwig Schmidt},
      year={2023},
      eprint={2304.14108},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kim2023regionaware,
      title={Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers}, 
      author={Dahun Kim and Anelia Angelova and Weicheng Kuo},
      year={2023},
      eprint={2305.07011},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{caron2021dino,
      title={Emerging Properties in Self-Supervised Vision Transformers}, 
      author={Mathilde Caron and Hugo Touvron and Ishan Misra and Hervé Jégou and Julien Mairal and Piotr Bojanowski and Armand Joulin},
      year={2021},
      eprint={2104.14294},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{wu2018knn,
  title={Unsupervised Feature Learning via Non-Parametric Instance Discrimination},
  author={Wu, Zhirong and Xiong, Yuanjun and Stella, X Yu and Lin, Dahua},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@misc{paszke2019pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{EVA02,
  title={EVA-02: A Visual Representation for Neon Genesis},
  author={Fang, Yuxin and Sun, Quan and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.11331},
  year={2023}
}


@INPROCEEDINGS {cipolla2018autobalance,
author = {R. Cipolla and Y. Gal and A. Kendall},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Multi-task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},
year = {2018},
volume = {},
issn = {},
pages = {7482-7491},
abstract = {Numerous deep learning applications benefit from multitask learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task&#x27;s loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.},
keywords = {task analysis;uncertainty;semantics;geometry;image segmentation;computational modeling},
doi = {10.1109/CVPR.2018.00781},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00781},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@inproceedings{
loshchilov2018adamw,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@misc{li2022vitdet,
      title={Exploring Plain Vision Transformer Backbones for Object Detection}, 
      author={Yanghao Li and Hanzi Mao and Ross Girshick and Kaiming He},
      year={2022},
      eprint={2203.16527},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{hu2019adaloss,
author = {Hu, Hanzhang and Dey, Debadeepta and Hebert, Martial and Bagnell, J. Andrew},
title = {Learning Anytime Predictions in Neural Networks via Adaptive Loss Balancing},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v33i01.33013812},
doi = {10.1609/aaai.v33i01.33013812},
abstract = {This work considers the trade-off between accuracy and testtime computational cost of deep neural networks (DNNs) via anytime predictions from auxiliary predictions. Specifically, we optimize auxiliary losses jointly in an adaptive weighted sum, where the weights are inversely proportional to average of each loss. Intuitively, this balances the losses to have the same scale. We demonstrate theoretical considerations that motivate this approach from multiple viewpoints, including connecting it to optimizing the geometric mean of the expectation of each loss, an objective that ignores the scale of losses. Experimentally, the adaptive weights induce more competitive anytime predictions on multiple recognition data-sets and models than non-adaptive approaches including weighing all losses equally. In particular, anytime neural networks (ANNs) can achieve the same accuracy faster using adaptive weights on a small network than using static constant weights on a large one. For problems with high performance saturation, we also show a sequence of exponentially deepening ANNs can achieve near-optimal anytime results at any budget, at the cost of a const fraction of extra computation.},
booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
articleno = {468},
numpages = {10},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inproceedings{xu2023metaclip,
   title={Demystifying CLIP Data},
   author={Hu Xu and Saining Xie and  Xiaoqing Ellen Tan and  Po-Yao Huang and  Russell Howes and Vasu Sharma and Shang-Wen Li and Gargi Ghosh and Luke Zettlemoyer and Christoph Feichtenhofer},
   journal={arXiv preprint arXiv:2309.16671},
   year={2023}
}

@misc{wang2023samclip,
      title={SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding}, 
      author={Haoxiang Wang and Pavan Kumar Anasosalu Vasu and Fartash Faghri and Raviteja Vemulapalli and Mehrdad Farajtabar and Sachin Mehta and Mohammad Rastegari and Oncel Tuzel and Hadi Pouransari},
      year={2023},
      eprint={2310.15308},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{fang2023data,
      title={Data Filtering Networks}, 
      author={Alex Fang and Albin Madappally Jose and Amit Jain and Ludwig Schmidt and Alexander Toshev and Vaishaal Shankar},
      year={2023},
      eprint={2309.17425},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{zhai2023stabilizing,
  title={Stabilizing Transformer Training by Preventing Attention Entropy Collapse},
  author={Zhai, Shuangfei and Likhomanenko, Tatiana and Littwin, Etai and Busbridge, Dan and Ramapuram, Jason and Zhang, Yizhe and Gu, Jiatao and Susskind, Joshua M},
  booktitle={International Conference on Machine Learning},
  pages={40770--40803},
  year={2023},
  organization={PMLR}
}

@misc{paszke2019pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{chen2023internvl,
  title={InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks},
  author={Chen, Zhe and Wu, Jiannan and Wang, Wenhai and Su, Weijie and Chen, Guo and Xing, Sen and Zhong, Muyan and Zhang, Qinglong and Zhu, Xizhou and Lu, Lewei and Li, Bin and Luo, Ping and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  journal={arXiv preprint arXiv:2312.14238},
  year={2023}
}

@article{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  journal={arXiv preprint arXiv:2303.15343},
  year={2023}
}

@inproceedings{Hariharan2014SimultaneousDA,
  title={Simultaneous Detection and Segmentation},
  author={Bharath Hariharan and Pablo Arbel{\'a}ez and Ross B. Girshick and Jitendra Malik},
  booktitle={European Conference on Computer Vision},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:9272368}
}

@inproceedings{Li-hallucination-2023,
  title={Evaluating Object Hallucination in Large Vision-Language Models},
  author={Yifan Li and Yifan Du and Kun Zhou and Jinpeng Wang and Wayne Xin Zhao and Ji-Rong Wen},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://openreview.net/forum?id=xozJw0kZXF}
}

@misc{bolya2023window,
      title={Window Attention is Bugged: How not to Interpolate Position Embeddings}, 
      author={Daniel Bolya and Chaitanya Ryali and Judy Hoffman and Christoph Feichtenhofer},
      year={2023},
      eprint={2311.05613},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{darcet2023vision,
      title={Vision Transformers Need Registers}, 
      author={Timothée Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},
      year={2023},
      eprint={2309.16588},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{bachman2014learning,
	title={Learning with pseudo-ensembles},
	author={Bachman, Philip and Alsharif, Ouais and Precup, Doina},
	booktitle={Advances in Neural Information Processing Systems},
	pages={3365--3373},
	year={2014}
}

@inproceedings{sajjadi2016regularization,
  title={Regularization with stochastic transformations and perturbations for deep semi-supervised learning},
  author={Sajjadi, Mehdi and Javanmardi, Mehran and Tasdizen, Tolga},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1163--1171},
  year={2016}
}

@inproceedings{blum1998combining,
  title={Combining labeled and unlabeled data with co-training},
  author={Blum, Avrim and Mitchell, Tom},
  booktitle={Proceedings of the eleventh annual conference on Computational learning theory},
  pages={92--100},
  year={1998},
  organization={ACM}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{miyato2016adversarial,
  title={Adversarial training methods for semi-supervised text classification},
  author={Miyato, Takeru and Dai, Andrew M and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1605.07725},
  year={2016}
}

@article{wang2018switchout,
  title={Switchout: an efficient data augmentation algorithm for neural machine translation},
  author={Wang, Xinyi and Pham, Hieu and Dai, Zihang and Neubig, Graham},
  journal={arXiv preprint arXiv:1808.07512},
  year={2018}
}

@inproceedings{zhang2019making,
  title={Making convolutional networks shift-invariant again},
  author={Zhang, Richard},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={International Conference on Learning Representations},
  year={2018}
}

@article{berthelot2019mixmatch,
  title={MixMatch: A Holistic Approach to Semi-Supervised Learning},
  author={Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin},
  journal={arXiv preprint arXiv:1905.02249},
  year={2019}
}

@article{shen2019mixture,
  title={Mixture Models for Diverse Machine Translation: Tricks of the Trade},
  author={Shen, Tianxiao and Ott, Myle and Auli, Michael and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.07816},
  year={2019}
}

@article{gilmer2018adversarial,
  title={Adversarial spheres},
  author={Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1801.02774},
  year={2018}
}

@inproceedings{simon2019first,
  title={First-order adversarial vulnerability of neural networks and input dimension},
  author={Simon-Gabriel, Carl-Johann and Ollivier, Yann and Bottou, Leon and Sch{\"o}lkopf, Bernhard and Lopez-Paz, David},
  booktitle={International Conference on Machine Learning},
  pages={5809--5817},
  year={2019}
}


@inproceedings{athiwaratkun2018there,
  title={There are many consistent explanations of unlabeled data: Why you should average},
  author={Athiwaratkun, Ben and Finzi, Marc and Izmailov, Pavel and Wilson, Andrew Gordon},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{devries2017improved,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

@article{sachan2018revisiting,
  title={Revisiting LSTM Networks for Semi-Supervised Text Classification via Mixed Objective Function},
  author={Sachan, Devendra Singh and Zaheer, Manzil and Salakhutdinov, Ruslan},
  year={2018}
}

@article{jackson2019semi,
  title={Semi-Supervised Learning by Label Gradient Alignment},
  author={Jackson, Jacob and Schulman, John},
  journal={arXiv preprint arXiv:1902.02336},
  year={2019}
}

@article{Hataya2019unifying,
  title={UNIFYING SEMI-SUPERVISED AND ROBUST LEARNING BY MIXUP},
  author={Hataya, Ryuichiro and Nakayama, Hideki},
  journal={ICLR The 2nd Learning from Limited Labeled Data (LLD) Workshop},
  year={2019}
}

@inproceedings{verma2019interpolation,
  title={Interpolation Consistency Training for Semi-Supervised Learning},
  author={Verma, Vikas and Lamb, Alex and Kannala, Juho and Bengio, Yoshua and Lopez-Paz, David},
  booktitle={Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)},
  year={2019}
}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}

@inproceedings{park2018adversarial,
  title={Adversarial dropout for supervised and semi-supervised learning},
  author={Park, Sungrae and Park, JunKeon and Shin, Su-Jin and Moon, Il-Chul},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@article{park2019specaugment,
  title={SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
  author={Park, Daniel S and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.08779},
  year={2019}
}

@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  institution={Citeseer}
}


@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{lai2019bridging,
  title={Bridging the domain gap in cross-lingual document classification},
  author={Lai, Guokun and Oguz, Barlas and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1909.07009},
  year={2019}
}

@InProceedings{babenko2014neuralcodes,
author="Babenko, Artem
and Slesarev, Anton
and Chigorin, Alexandr
and Lempitsky, Victor",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Neural Codes for Image Retrieval",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="584--599",
abstract="It has been shown that the activations invoked by an image within the top layers of a large convolutional neural network provide a high-level descriptor of the visual content of the image. In this paper, we investigate the use of such descriptors (neural codes) within the image retrieval application. In the experiments with several standard retrieval benchmarks, we establish that neural codes perform competitively even when the convolutional neural network has been trained for an unrelated classification task (e.g. Image-Net). We also evaluate the improvement in the retrieval performance of neural codes, when the network is retrained on a dataset of images that are similar to images encountered at test time.",
isbn="978-3-319-10590-1"
}

@inproceedings{zhang2024retrieval,
author = {Zhang, Chi and Liu, Jie},
title = {Content Based Deep Learning Image Retrieval: A Survey},
year = {2024},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638884.3638908},
doi = {10.1145/3638884.3638908},
abstract = {With the development of digital technology, various fields generate and share a large amount of visual content. Image retrieval is a hot research direction in the field of computer vision. Efficient and accurate retrieval of query content from massive data is the ultimate form pursued by image retrieval technology. In recent years, the rise of deep learning technology has promoted the rapid development of the field of computer vision. Due to the powerful expressive ability of deep features on image content, image retrieval based on deep learning has become the most cutting-edge research direction in CBIR technology. This paper summarizes the relevant research on the classic deep learning image retrieval technology in recent years, first introduces the form of the CBIR problem, and then lists the classic datasets in this field. Afterwards, content-based deep image retrieval methods are reviewed from the perspectives of network models, deep feature extraction, and retrieval types. Finally, summarize the problems to be solved urgently in the current research, and look forward to the future research direction.},
booktitle = {Proceedings of the 2023 9th International Conference on Communication and Information Processing},
pages = {158–163},
numpages = {6},
keywords = {Content Based Image Retrieval, Convolution Neural Network, Deep Learning},
location = {Lingshui, China},
series = {ICCIP '23}
}

@misc{alayrac2022flamingovisuallanguagemodel,
      title={Flamingo: a Visual Language Model for Few-Shot Learning}, 
      author={Jean-Baptiste Alayrac and Jeff Donahue and Pauline Luc and Antoine Miech and Iain Barr and Yana Hasson and Karel Lenc and Arthur Mensch and Katie Millican and Malcolm Reynolds and Roman Ring and Eliza Rutherford and Serkan Cabi and Tengda Han and Zhitao Gong and Sina Samangooei and Marianne Monteiro and Jacob Menick and Sebastian Borgeaud and Andrew Brock and Aida Nematzadeh and Sahand Sharifzadeh and Mikolaj Binkowski and Ricardo Barreira and Oriol Vinyals and Andrew Zisserman and Karen Simonyan},
      year={2022},
      eprint={2204.14198},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2204.14198}, 
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI et al.},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{liu2024llavanext1p6,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@misc{lin2023vila,
      title={VILA: On Pre-training for Visual Language Models},
      author={Ji Lin and Hongxu Yin and Wei Ping and Yao Lu and Pavlo Molchanov and Andrew Tao and Huizi Mao and Jan Kautz and Mohammad Shoeybi and Song Han},
      year={2023},
      eprint={2312.07533},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{shi2016deconv,
      title={Is the deconvolution layer the same as a convolutional layer?}, 
      author={Wenzhe Shi and Jose Caballero and Lucas Theis and Ferenc Huszar and Andrew Aitken and Christian Ledig and Zehan Wang},
      year={2016},
      eprint={1609.07009},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1609.07009}, 
}

@article{dumoulin2016AGT,
  title={A guide to convolution arithmetic for deep learning},
  author={Vincent Dumoulin and Francesco Visin},
  journal={ArXiv},
  year={2016},
  volume={abs/1603.07285},
  url={https://api.semanticscholar.org/CorpusID:6662846}
}

@INPROCEEDINGS {noh2015deconv,
author = { Noh, Hyeonwoo and Hong, Seunghoon and Han, Bohyung },
booktitle = { 2015 IEEE International Conference on Computer Vision (ICCV) },
title = {{ Learning Deconvolution Network for Semantic Segmentation }},
year = {2015},
volume = {},
ISSN = {2380-7504},
pages = {1520-1528},
keywords = {Deconvolution;Semantics;Image segmentation;Visualization;Feature extraction;Shape;Image reconstruction},
doi = {10.1109/ICCV.2015.178},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV.2015.178},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Dec}

@article{odena2016deconvcheck,
title	= {Deconvolution and Checkerboard Artifacts},
author	= {Augustus Odena and Vincent Dumoulin and Chris Olah},
year	= {2016},
URL	= {http://distill.pub/2016/deconv-checkerboard/},
journal	= {Distill}
}

@article{chen2024internvl1p5,
author = {Chen, Zhe and Wang, Weiyun and Tian, Hao and Ye, Shenglong and Gao, Zhangwei and Cui, Erfei and Tong, Wenwen and Hu, Kongzhi and Luo, Jiapeng and Ma, Zheng and Ma, Ji and Wang, Jiaqi and Dong, Xiaoyi and Yan, Hang and Guo, Hewei and He, Conghui and Shi, Botian and Jin, Zhenjiang and Xu, Chao and Wang, Wenhai},
year = {2024},
month = {12},
pages = {},
title = {How far are we to GPT-4V? Closing the gap to commercial multimodal models with open-source suites},
volume = {67},
journal = {Science China Information Sciences},
doi = {10.1007/s11432-024-4231-5}
}

@inproceedings{silberman2012nyud,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@misc{shi2024eagleexploringdesignspace,
      title={Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders}, 
      author={Min Shi and Fuxiao Liu and Shihao Wang and Shijia Liao and Subhashree Radhakrishnan and De-An Huang and Hongxu Yin and Karan Sapra and Yaser Yacoob and Humphrey Shi and Bryan Catanzaro and Andrew Tao and Jan Kautz and Zhiding Yu and Guilin Liu},
      year={2024},
      eprint={2408.15998},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.15998}, 
}

@inbook{ramachandran2019localattn,
author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
title = {Stand-alone self-attention in vision models},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12\% fewer FLOPS and 29\% fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39\% fewer FLOPS and 34\% fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox. Code for this project is made available.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {7},
numpages = {13}
}

@article{gretton12mmd,
  author  = {Arthur Gretton and Karsten M. Borgwardt and Malte J. Rasch and Bernhard Sch{{\"o}}lkopf and Alexander Smola},
  title   = {A Kernel Two-Sample Test},
  journal = {Journal of Machine Learning Research},
  year    = {2012},
  volume  = {13},
  number  = {25},
  pages   = {723-773},
  url     = {http://jmlr.org/papers/v13/gretton12a.html}
}

@article{Wang2019CARAFECR,
  title={CARAFE: Content-Aware ReAssembly of FEatures},
  author={Jiaqi Wang and Kai Chen and Rui Xu and Ziwei Liu and Chen Change Loy and Dahua Lin},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  pages={3007-3016},
  url={https://api.semanticscholar.org/CorpusID:146120936}
}

@inproceedings{
lu2022sapa,
title={{SAPA}: Similarity-Aware Point Affiliation for Feature Upsampling},
author={Hao Lu and Wenze Liu and Zixuan Ye and Hongtao Fu and Yuliang Liu and Zhiguo Cao},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=hFni381edL}
}

@misc{dai2024nvlm,
      title={NVLM: Open Frontier-Class Multimodal LLMs}, 
      author={Wenliang Dai and Nayeon Lee and Boxin Wang and Zhuolin Yang and Zihan Liu and Jon Barker and Tuomas Rintamaki and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
      year={2024},
      eprint={2409.11402},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.11402}, 
}

@article{rudin1992tvloss,
title = {Nonlinear total variation based noise removal algorithms},
journal = {Physica D: Nonlinear Phenomena},
volume = {60},
number = {1},
pages = {259-268},
year = {1992},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(92)90242-F},
url = {https://www.sciencedirect.com/science/article/pii/016727899290242F},
author = {Leonid I. Rudin and Stanley Osher and Emad Fatemi},
abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t → ∞ the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.}
}

@misc{wang2024qwen2vlenhancingvisionlanguagemodels,
      title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution}, 
      author={Peng Wang and Shuai Bai and Sinan Tan and Shijie Wang and Zhihao Fan and Jinze Bai and Keqin Chen and Xuejing Liu and Jialin Wang and Wenbin Ge and Yang Fan and Kai Dang and Mengfei Du and Xuancheng Ren and Rui Men and Dayiheng Liu and Chang Zhou and Jingren Zhou and Junyang Lin},
      year={2024},
      eprint={2409.12191},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.12191}, 
}

@INPROCEEDINGS {beyer2023flexivit,
author = { Beyer, Lucas and Izmailov, Pavel and Kolesnikov, Alexander and Caron, Mathilde and Kornblith, Simon and Zhai, Xiaohua and Minderer, Matthias and Tschannen, Michael and Alabdulmohsin, Ibrahim and Pavetic, Filip },
booktitle = { 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
title = {{ FlexiViT: One Model for All Patch Sizes }},
year = {2023},
volume = {},
ISSN = {},
pages = {14496-14506},
abstract = { Vision Transformers convert images to sequences by slicing them into patches. The size of these patches controls a speed/accuracy tradeoff, with smaller patches leading to higher accuracy at greater computational cost, but changing the patch size typically requires retraining the model. In this paper, we demonstrate that simply randomizing the patch size at training time leads to a single set of weights that performs well across a wide range of patch sizes, making it possible to tailor the model to different compute budgets at deployment time. We extensively evaluate the resulting model, which we call FlexiViT, on a wide range of tasks, including classification, image-text retrieval, open-world detection, panoptic segmentation, and semantic segmentation, concluding that it usually matches, and sometimes outperforms, standard ViT models trained at a single patch size in an otherwise identical setup. Hence, FlexiViT training is a simple drop-in improvement for ViT that makes it easy to add compute-adaptive capabilities to most models relying on a ViT backbone architecture. Code and pre-trained models are available at github.com/google-research/big_vision. },
keywords = {Training;Costs;Computational modeling;Semantic segmentation;Deep architecture;Predictive models;Transformers},
doi = {10.1109/CVPR52729.2023.01393},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR52729.2023.01393},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Jun}

@inproceedings{kim2023region,
  title={Region-aware pretraining for open-vocabulary object detection with vision transformers},
  author={Kim, Dahun and Angelova, Anelia and Kuo, Weicheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11144--11154},
  year={2023}
}

@article{kopf2007jbu,
author = {Kopf, Johannes and Cohen, Michael F. and Lischinski, Dani and Uyttendaele, Matt},
title = {Joint bilateral upsampling},
year = {2007},
issue_date = {July 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/1276377.1276497},
doi = {10.1145/1276377.1276497},
abstract = {Image analysis and enhancement tasks such as tone mapping, colorization, stereo depth, and photomontage, often require computing a solution (e.g., for exposure, chromaticity, disparity, labels) over the pixel grid. Computational and memory costs often require that a smaller solution be run over a downsampled image. Although general purpose upsampling methods can be used to interpolate the low resolution solution to the full resolution, these methods generally assume a smoothness prior for the interpolation.We demonstrate that in cases, such as those above, the available high resolution input image may be leveraged as a prior in the context of a joint bilateral upsampling procedure to produce a better high resolution solution. We show results for each of the applications above and compare them to traditional upsampling methods.},
journal = {ACM Trans. Graph.},
month = jul,
pages = {96–es},
numpages = {6},
keywords = {bilateral filter, upsampling}
}

@misc{dai2024nvlmopenfrontierclassmultimodal,
      title={NVLM: Open Frontier-Class Multimodal LLMs}, 
      author={Wenliang Dai and Nayeon Lee and Boxin Wang and Zhuolin Yang and Zihan Liu and Jon Barker and Tuomas Rintamaki and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
      year={2024},
      eprint={2409.11402},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.11402}, 
}

@misc{plested2022deeptransferlearningimage,
      title={Deep transfer learning for image classification: a survey}, 
      author={Jo Plested and Tom Gedeon},
      year={2022},
      eprint={2205.09904},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2205.09904}, 
}

@inproceedings{riloff1996automatically,
  title={Automatically generating extraction patterns from untagged text},
  author={Riloff, Ellen},
  booktitle={Proceedings of the national conference on artificial intelligence},
  pages={1044--1049},
  year={1996}
}

@article{thomee2016yfcc100m,
  title={YFCC100M: The new data in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={Communications of the ACM},
  volume={59},
  number={2},
  pages={64--73},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{he2019revisiting,
  title={Revisiting self-training for neural sequence generation},
  author={He, Junxian and Gu, Jiatao and Shen, Jiajun and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1909.13788},
  year={2019}
}


@inproceedings{wu2019exploiting,
  title={Exploiting Monolingual Data at Scale for Neural Machine Translation},
  author={Wu, Lijun and Wang, Yiren and Xia, Yingce and Tao, QIN and Lai, Jianhuang and Liu, Tie-Yan},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={4198--4207},
  year={2019}
}

@article{kolesnikov2019large,
  title={Large Scale Learning of General Visual Representations for Transfer},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  journal={arXiv preprint arXiv:1912.11370},
  year={2019}
}

@article{berthelot2019remixmatch,
  title={ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring},
  author={Berthelot, David and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Sohn, Kihyuk and Zhang, Han and Raffel, Colin},
  journal={arXiv preprint arXiv:1911.09785},
  year={2019}
}

@misc{fang2024vila2vilaaugmentedvila,
      title={$VILA^2$: VILA Augmented VILA}, 
      author={Yunhao Fang and Ligeng Zhu and Yao Lu and Yan Wang and Pavlo Molchanov and Jang Hyun Cho and Marco Pavone and Song Han and Hongxu Yin},
      year={2024},
      eprint={2407.17453},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.17453}, 
}

@misc{li2024llavanextinterleavetacklingmultiimagevideo,
      title={LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models}, 
      author={Feng Li and Renrui Zhang and Hao Zhang and Yuanhan Zhang and Bo Li and Wei Li and Zejun Ma and Chunyuan Li},
      year={2024},
      eprint={2407.07895},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07895}, 
}

@misc{assran2023ijepa,
      title={Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture}, 
      author={Mahmoud Assran and Quentin Duval and Ishan Misra and Piotr Bojanowski and Pascal Vincent and Michael Rabbat and Yann LeCun and Nicolas Ballas},
      year={2023},
      eprint={2301.08243},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2301.08243}, 
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@misc{sariyildiz2024unicuniversalclassificationmodels,
      title={UNIC: Universal Classification Models via Multi-teacher Distillation}, 
      author={Mert Bulent Sariyildiz and Philippe Weinzaepfel and Thomas Lucas and Diane Larlus and Yannis Kalantidis},
      year={2024},
      eprint={2408.05088},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.05088}, 
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@inproceedings{lee2013pseudo,
  title={Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks},
  author={Lee, Dong-Hyun},
  booktitle={Workshop on Challenges in Representation Learning, ICML},
  volume={3},
  pages={2},
  year={2013}
}

@inproceedings{
zhou2022ibot,
title={Image {BERT} Pre-training with Online Tokenizer},
author={Jinghao Zhou and Chen Wei and Huiyu Wang and Wei Shen and Cihang Xie and Alan Yuille and Tao Kong},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=ydopy-e6Dg}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@inproceedings{zagoruyko2017paying,
  author       = {Sergey Zagoruyko and
                  Nikos Komodakis},
  title        = {Paying More Attention to Attention: Improving the Performance of Convolutional
                  Neural Networks via Attention Transfer},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  url          = {https://openreview.net/forum?id=Sks9\_ajex},
  timestamp    = {Thu, 25 Jul 2019 14:25:41 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/ZagoruykoK17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@incollection{weston2012deep,
  title={Deep learning via semi-supervised embedding},
  author={Weston, Jason and Ratle, Fr{\'e}d{\'e}ric and Mobahi, Hossein and Collobert, Ronan},
  booktitle={Neural Networks: Tricks of the Trade},
  pages={639--655},
  year={2012},
  publisher={Springer}
}



@inproceedings{luo2018smooth,
  title={Smooth neighbors on teacher graphs for semi-supervised learning},
  author={Luo, Yucen and Zhu, Jun and Li, Mengxi and Ren, Yong and Zhang, Bo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8896--8905},
  year={2018}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={European conference on computer vision},
  pages={649--666},
  year={2016},
  organization={Springer}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@inproceedings{liang2018learning,
  title={Learning noise-invariant representations for robust speech recognition},
  author={Liang, Davis and Huang, Zhiheng and Lipton, Zachary C},
  booktitle={2018 IEEE Spoken Language Technology Workshop (SLT)},
  pages={56--63},
  year={2018},
  organization={IEEE}
}


@inproceedings{Salazar2018Invariant,
  title={Invariant representation learning for robust deep networks},
  author={Salazar, Julian and Liang, Davis and Huang, Zhiheng and Lipton, Zachary C},
  booktitle={Workshop on Integration of Deep Learning Theories, NeurIPS},
  year={2018}
}

@article{kool2019stochastic,
  title={Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement},
  author={Kool, Wouter and van Hoof, Herke and Welling, Max},
  journal={arXiv preprint arXiv:1903.06059},
  year={2019}
}

@article{he2018sequence,
  title={Sequence to sequence mixture model for diverse machine translation},
  author={He, Xuanli and Haffari, Gholamreza and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1810.07391},
  year={2018}
}

@inproceedings{clark2018semi,
  title={Semi-supervised sequence modeling with cross-view training},
  author={Clark, Kevin and Luong, Minh-Thang and Manning, Christopher D and Le, Quoc V},
  booktitle={Empirical Methods in Natural Language Processing (EMNLP)},
  year={2018}
}


@inproceedings{hu2017learning,
  title={Learning discrete representations via information maximizing self-augmented training},
  author={Hu, Weihua and Miyato, Takeru and Tokui, Seiya and Matsumoto, Eiichi and Sugiyama, Masashi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1558--1567},
  year={2017},
  organization={JMLR. org}
}

@article{hernandez2018data,
  title={Data augmentation instead of explicit regularization},
  author={Hern{\'a}ndez-Garc{\'\i}a, Alex and K{\"o}nig, Peter},
  journal={arXiv preprint arXiv:1806.03852},
  year={2018}
}


@article{gastaldi2017shake,
  title={Shake-shake regularization},
  author={Gastaldi, Xavier},
  journal={arXiv preprint arXiv:1705.07485},
  year={2017}
}

@article{yamada2018shakedrop,
  title={ShakeDrop Regularization for Deep Residual Learning},
  author={Yamada, Yoshihiro and Iwamura, Masakazu and Akiba, Takuya and Kise, Koichi},
  journal={arXiv preprint arXiv:1802.02375},
  year={2018}
}

@article{orhan2019robustness,
  title={Robustness properties of Facebook's ResNeXt WSL models},
  author={Orhan, A Emin},
  journal={arXiv preprint arXiv:1907.07640},
  year={2019}
}

@article{cheng2016semi,
  title={Semi-supervised learning for neural machine translation},
  author={Cheng, Yong and Xu, Wei and He, Zhongjun and He, Wei and Wu, Hua and Sun, Maosong and Liu, Yang},
  journal={arXiv preprint arXiv:1606.04596},
  year={2016}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{edunov2018understanding,
  title={Understanding back-translation at scale},
  author={Edunov, Sergey and Ott, Myle and Auli, Michael and Grangier, David},
  booktitle={Proceedings of the 2018 conference on Empirical methods in natural language processing},
  pages={489--500},
  year={2018}
}

@inproceedings{he2016dual,
  title={Dual learning for machine translation},
  author={He, Di and Xia, Yingce and Qin, Tao and Wang, Liwei and Yu, Nenghai and Liu, Tie-Yan and Ma, Wei-Ying},
  booktitle={Advances in Neural Information Processing Systems},
  pages={820--828},
  year={2016}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}


@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{hinton2012deep,
  title={Deep neural networks for acoustic modeling in speech recognition},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Kingsbury, Brian and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  year={2012}
}

@inproceedings{shi2024s2,
author = {Shi, Baifeng and Wu, Ziyang and Mao, Maolin and Wang, Xin and Darrell, Trevor},
title = {When Do We Not Need Larger Vision Models?},
year = {2024},
isbn = {978-3-031-73241-6},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-031-73242-3_25},
doi = {10.1007/978-3-031-73242-3_25},
abstract = {Scaling up the size of vision models has been the de facto standard to obtain more powerful visual representations. In this work, we discuss the point beyond which larger vision models are not necessary. First, we demonstrate the power of Scaling on Scales (S2), whereby a pre-trained and frozen smaller vision model (e.g., ViT-B or ViT-L), run over multiple image scales, can outperform larger models (e.g., ViT-H or ViT-G) on classification, segmentation, depth estimation, Multimodal LLM (MLLM) benchmarks, and robotic manipulation. Notably, S2 achieves state-of-the-art performance in detailed understanding of MLLM on the V∗ benchmark, surpassing models such as GPT-4V. We examine the conditions under which S2 is a preferred scaling approach compared to scaling on model size. While larger models have the advantage of better generalization on hard examples, we show that features of larger vision models can be well approximated by those of multi-scale smaller models. This suggests most, if not all, of the representations learned by current large pre-trained models can also be obtained from multi-scale smaller models. Our results show that a multi-scale smaller model has comparable learning capacity to a larger model, and pre-training smaller models with S2 can match or even exceed the advantage of larger models. We release a Python package that can apply S2 on any vision model with one line of code: .},
booktitle = {Computer Vision – ECCV 2024: 18th European Conference, Milan, Italy, September 29–October 4, 2024, Proceedings, Part VIII},
pages = {444–462},
numpages = {19},
keywords = {Vision model scaling, Scaling on scales},
location = {Milan, Italy}
}

@inproceedings{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3104--3112},
  year={2014}
}

@inproceedings{zhai2019s,
  title={{S$^\mathbf{4}$L}: Self-Supervised Semi-Supervised Learning},
  author={Zhai, Xiaohua and Oliver, Avital and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  year={2019}
}

@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@inproceedings{laine2016temporal,
	title={Temporal ensembling for semi-supervised learning},
	author={Laine, Samuli and Aila, Timo},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{tarvainen2017mean,
	title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
	author={Tarvainen, Antti and Valpola, Harri},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1195--1204},
	year={2017}
}

@article{chapelle2009semi,
	title={Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]},
	author={Chapelle, Olivier and Scholkopf, Bernhard and Zien, Alexander},
	journal={IEEE Transactions on Neural Networks},
	volume={20},
	number={3},
	pages={542--542},
	year={2009},
	publisher={IEEE}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={181--196},
  year={2018}
}


@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={843--852},
  year={2017}
}


@inproceedings{oliver2018realistic,
  title={Realistic evaluation of deep semi-supervised learning algorithms},
  author={Oliver, Avital and Odena, Augustus and Raffel, Colin A and Cubuk, Ekin Dogus and Goodfellow, Ian},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3235--3246},
  year={2018}
}

@incollection{simard1998transformation,
	title={Transformation invariance in pattern recognition—tangent distance and tangent propagation},
	author={Simard, Patrice Y and LeCun, Yann A and Denker, John S and Victorri, Bernard},
	booktitle={Neural networks: tricks of the trade},
	pages={239--274},
	year={1998},
	publisher={Springer}
}

@inproceedings{mcauley2015image,
  title={Image-based recommendations on styles and substitutes},
  author={McAuley, Julian and Targett, Christopher and Shi, Qinfeng and Van Den Hengel, Anton},
  booktitle={Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={43--52},
  year={2015},
  organization={ACM}
}


@techreport{gray2017gpu,
  title={GPU kernels for block-sparse weights},
  author={Gray, Scott and Radford, Alec and Kingma, Diederik P},
  year={2017},
  institution={Technical report, OpenAI}
}

@inproceedings{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  volume={1},
  pages={328--339},
  year={2018}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{johnson2016supervised,
  title={Supervised and semi-supervised text categorization using LSTM for region embeddings},
  author={Johnson, Rie and Zhang, Tong},
  journal={arXiv preprint arXiv:1602.02373},
  year={2016}
}

@inproceedings{dai2015semi,
  title={Semi-supervised sequence learning},
  author={Dai, Andrew M and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={3079--3087},
  year={2015}
}

@inproceedings{johnson2017deep,
  title={Deep pyramid convolutional neural networks for text categorization},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  volume={1},
  pages={562--570},
  year={2017}
}

@article{johnson2016convolutional,
  title={Convolutional neural networks for text categorization: Shallow word-level vs. deep character-level},
  author={Johnson, Rie and Zhang, Tong},
  journal={arXiv preprint arXiv:1609.00718},
  year={2016}
}


@inproceedings{zhang2015character,
  title={Character-level convolutional networks for text classification},
  author={Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
  booktitle={Advances in neural information processing systems},
  pages={649--657},
  year={2015}
}

@article{miyato2018virtual,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Ishii, Shin and Koyama, Masanori},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2018},
  publisher={IEEE}
}

@article{yu2018qanet,
  title={QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension},
  author={Yu, Adams Wei and Dohan, David and Luong, Minh-Thang and Zhao, Rui and Chen, Kai and Norouzi, Mohammad and Le, Quoc V},
  journal={arXiv preprint arXiv:1804.09541},
  year={2018}
}


@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018}
}


@inproceedings{joachims1999transductive,
  title={Transductive inference for text classification using support vector machines},
  author={Joachims, Thorsten},
  booktitle={ICML},
  volume={99},
  pages={200--209},
  year={1999}
}

@inproceedings{zhu2003semi,
  title={Semi-supervised learning using gaussian fields and harmonic functions},
  author={Zhu, Xiaojin and Ghahramani, Zoubin and Lafferty, John D},
  booktitle={Proceedings of the 20th International conference on Machine learning (ICML-03)},
  pages={912--919},
  year={2003}
}

@inproceedings{collobert2008unified,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008},
  organization={ACM}
}

@inproceedings{balan2015bayesian,
  title={Bayesian dark knowledge},
  author={Balan, Anoop Korattikara and Rathod, Vivek and Murphy, Kevin P and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3438--3446},
  year={2015}
}

@article{zhou2018edf,
  title={EDF: Ensemble, Distill, and Fuse for Easy Video Labeling},
  author={Zhou, Giulio and Dulloor, Subramanya and Andersen, David G and Kaminsky, Michael},
  journal={arXiv preprint arXiv:1812.03626},
  year={2018}
}

@article{cubuk2019randaugment,
  title={RandAugment: Practical data augmentation with no separate search},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  journal={arXiv preprint arXiv:1909.13719},
  year={2019}
}


@inproceedings{cubuk2018autoaugment,
  title={{AutoAugment}: Learning Augmentation Strategies from Data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018}
}

@article{sennrich2015improving,
  title={Improving neural machine translation models with monolingual data},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1511.06709},
  year={2015}
}

@article{goodfellow6572explaining,
  title={Explaining and harnessing adversarial examples (2014)},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572}
}



@article{yang2016revisiting,
  title={Revisiting semi-supervised learning with graph embeddings},
  author={Yang, Zhilin and Cohen, William W and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1603.08861},
  year={2016}
}

@inproceedings{dai2017good,
  title={Good semi-supervised learning that requires a bad gan},
  author={Dai, Zihang and Yang, Zhilin and Yang, Fan and Cohen, William W and Salakhutdinov, Ruslan R},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6510--6520},
  year={2017}
}

@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew L and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1},
  pages={142--150},
  year={2011},
  organization={Association for Computational Linguistics}
}

@inproceedings{hieu2019,
  title={Personal Communication. Will be updated.},
  author={Pham el al., Hieu},
  year={2019},
}

@article{maaloe2016auxiliary,
	title={Auxiliary deep generative models},
	author={Maal{\o}e, Lars and S{\o}nderby, Casper Kaae and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
	journal={arXiv preprint arXiv:1602.05473},
	year={2016}
}

@inproceedings{salimans2016improved,
	title={Improved techniques for training gans},
	author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	booktitle={Advances in neural information processing systems},
	pages={2234--2242},
	year={2016}
}

@article{zhang2017mixup,
	title={mixup: Beyond empirical risk minimization},
	author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
	journal={arXiv preprint arXiv:1710.09412},
	year={2017}
}

@article{radford2018improving,
	title={Improving language understanding by generative pre-training},
	author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	journal={URL https://s3-us-west-2. amazonaws. com/openai-assets/research-covers/languageunsupervised/language understanding paper. pdf},
	year={2018}
}

@inproceedings{mikolov2013distributed,
	title={Distributed representations of words and phrases and their compositionality},
	author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	booktitle={Advances in neural information processing systems},
	pages={3111--3119},
	year={2013}
}

@inproceedings{pennington2014glove,
	title={Glove: Global vectors for word representation},
	author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
	booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
	pages={1532--1543},
	year={2014}
}

@article{yang2017semi,
	title={Semi-supervised qa with generative domain-adaptive nets},
	author={Yang, Zhilin and Hu, Junjie and Salakhutdinov, Ruslan and Cohen, William W},
	journal={arXiv preprint arXiv:1702.02206},
	year={2017}
}

@inproceedings{grandvalet2005semi,
  title={Semi-supervised learning by entropy minimization},
  author={Grandvalet, Yves and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={529--536},
  year={2005}
}

@article{henaff2019data,
  title={Data-efficient image recognition with contrastive predictive coding},
  author={H{\'e}naff, Olivier J and Razavi, Ali and Doersch, Carl and Eslami, SM and Oord, Aaron van den},
  journal={arXiv preprint arXiv:1905.09272},
  year={2019}
}

@article{trinh2019selfie,
  title={Selfie: Self-supervised Pretraining for Image Embedding},
  author={Trinh, Trieu H and Luong, Minh-Thang and Le, Quoc V},
  journal={arXiv preprint arXiv:1906.02940},
  year={2019}
}

@inproceedings{ye2019unsupervised,
  title={Unsupervised Embedding Learning via Invariant and Spreading Instance Feature},
  author={Ye, Mang and Zhang, Xu and Yuen, Pong C and Chang, Shih-Fu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6210--6219},
  year={2019}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@article{galloway2019batch,
  title={Batch Normalization is a Cause of Adversarial Vulnerability},
  author={Galloway, Angus and Golubeva, Anna and Tanay, Thomas and Moussa, Medhat and Taylor, Graham W},
  journal={arXiv preprint arXiv:1905.02161},
  year={2019}
}

@article{zhai2019adversarially,
  title={Adversarially robust generalization just requires more unlabeled data},
  author={Zhai, Runtian and Cai, Tianle and He, Di and Dan, Chen and He, Kun and Hopcroft, John and Wang, Liwei},
  journal={arXiv preprint arXiv:1906.00555},
  year={2019}
}



@article{carmon2019unlabeled,
  title={Unlabeled data improves adversarial robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Liang, Percy and Duchi, John C},
  journal={arXiv preprint arXiv:1905.13736},
  year={2019}
}


@article{stanforth2019labels,
  title={Are Labels Required for Improving Adversarial Robustness?},
  author={Stanforth, Robert and Fawzi, Alhussein and Kohli, Pushmeet and others},
  journal={arXiv preprint arXiv:1905.13725},
  year={2019}
}
@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{confirmation_bias,
  title = {Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning},
  author = {Arazo, Eric and
            Ortego, Diego and
            Albert, Paul and
            O'Connor, Noel E. and
            McGuinness, Kevin},
  journal={Arxiv, 1908.02983},
  year={2019}
}
@inproceedings{ladder_network,
  title     = {Semi-Supervised Learning with Ladder Networks},
  author    = {Rasmus, Antti and
              Valpola, Harri and
              Honkala, Mikko and
              Berglund, Mathias and
              Raiko, Tapani},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
}
@inproceedings{jigsaw_puzzle,
  title={Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018},
}

@inproceedings{predicting_rotation,
  title={Unsupervised Representation Learning by Predicting Image Rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2018},
}
@inproceedings{mixmatch,
  title     = {MixMatch: A Holistic Approach to Semi-Supervised Learning},
  author    = {Berthelot, David and
               Carlini, Nicholas and
               Goodfellow, Ian and
               Papernot, Nicolas and
               Oliver, Avital and
               Raffel, Colin},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2019},
}

@article{uda,
  title={Unsupervised data augmentation for consistency training},
  author={Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V},
  journal={arXiv preprint arXiv:1904.12848},
  year={2019}
}

@inproceedings{inpainting,
  title     = {Context Encoders: Feature Learning by Inpainting},
  author    = {Pathak, Deepak and
               Krahenb\"{u}hl, Philipp and
               Donahue, Jeff and
               Darrell, Trevor and
               Efr\"{o}s, Alexei A. },
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
}

@inproceedings{exemplar_network,
  title     = {Discriminative unsupervised feature learning with convolutional neural networks},
  author    = {Dosovitskiy, Alexey and
               Fischer, Philipp and
               Springenberg, Jost Tobias  and
               Riedmiller, Martin and
               Brox, Thomas},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2014},
}

@inproceedings{denoising_auto_encoder,
  title = {Extracting and Composing Robust Features with Denoising Autoencoders},
  author = {Vincent, Pascal and
            Larochelle, Hugo and
            Bengio, Yoshua and
            Manzagol, Pierre-Antoine},
  booktitle={International Conference on Machine Learning},
  year={2008}
}

@misc{yang2024denoising,
      title={Denoising Vision Transformers}, 
      author={Jiawei Yang and Katie Z Luo and Jiefeng Li and Kilian Q Weinberger and Yonglong Tian and Yue Wang},
      year={2024},
      eprint={2401.02957},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Fan2024ViTARVT,
  title={ViTAR: Vision Transformer with Any Resolution},
  author={Qihang Fan and Quanzeng You and Xiaotian Han and Yongfei Liu and Yunzhe Tao and Huaibo Huang and Ran He and Hongxia Yang},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.18361},
  url={https://api.semanticscholar.org/CorpusID:268723731}
}

@inproceedings{
dehghani2023navit,
title={Patch n{\textquoteright} Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution},
author={Mostafa Dehghani and Basil Mustafa and Josip Djolonga and Jonathan Heek and Matthias Minderer and Mathilde Caron and Andreas Peter Steiner and Joan Puigcerver and Robert Geirhos and Ibrahim Alabdulmohsin and Avital Oliver and Piotr Padlewski and Alexey A. Gritsenko and Mario Lucic and Neil Houlsby},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=VpGFHmI7e5}
}

@misc{beyer2024paligemmaversatile3bvlm,
      title={PaliGemma: A versatile 3B VLM for transfer}, 
      author={Lucas Beyer and Andreas Steiner and André Susano Pinto and Alexander Kolesnikov and Xiao Wang and Daniel Salz and Maxim Neumann and Ibrahim Alabdulmohsin and Michael Tschannen and Emanuele Bugliarello and Thomas Unterthiner and Daniel Keysers and Skanda Koppula and Fangyu Liu and Adam Grycner and Alexey Gritsenko and Neil Houlsby and Manoj Kumar and Keran Rong and Julian Eisenschlos and Rishabh Kabra and Matthias Bauer and Matko Bošnjak and Xi Chen and Matthias Minderer and Paul Voigtlaender and Ioana Bica and Ivana Balazevic and Joan Puigcerver and Pinelopi Papalampidi and Olivier Henaff and Xi Xiong and Radu Soricut and Jeremiah Harmsen and Xiaohua Zhai},
      year={2024},
      eprint={2407.07726},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2407.07726}, 
}

@misc{yang2023emernerf,
      title={EmerNeRF: Emergent Spatial-Temporal Scene Decomposition via Self-Supervision}, 
      author={Jiawei Yang and Boris Ivanovic and Or Litany and Xinshuo Weng and Seung Wook Kim and Boyi Li and Tong Che and Danfei Xu and Sanja Fidler and Marco Pavone and Yue Wang},
      year={2023},
      eprint={2311.02077},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{stack_auto_encoder,
  title = {Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion},
  author = {Vincent, Pascal and
            Larochelle, Hugo and
            Lajoie, Isabelle and
            Bengio, Yoshua and
            Manzagol, Pierre-Antoine},
  journal={Journal of Machine Learning Research},
  year={2010}
}
@inproceedings{greedy_layerwise,
  title = {Greedy Layer-Wise Training of Deep Networks},
  author = {Bengio, Yoshua and
            Lamblin, Pascal and
            Popovici, and
            Larochelle, Hugo},
  booktitle={Advances in Neural Information Processing Systems},
  year={2008}
}

@inproceedings{cat_paper,
  title = {Building high-level features using large scale unsupervised learning},
  author = {Le, Quoc V. and
            Ranzato, Marc'Aurelio and
            Monga, Rajat and
            Devin, Matthieu and
            Chen, Kai and
            Corrado, Greg S. and
            Dean, Jeff and
            Ng, Andrew Y.},
  booktitle={International Conference on Machine Learning},
  year={2012}
}
@article{billion_large_scale,
  title = {Billion-scale semi-supervised learning for image classification},
  author = {Yalniz, I. Zeki and
            Herv{'e} J{'e}gou and
            Chen, Kan and
            Paluri, Manohar and
            Mahajan, Dhruv},
  journal={Arxiv 1905.00546},
  year={2019}
}
@inproceedings{tan2019efficientnet,
  title={{EfficientNet}: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Tan, Mingxing and Le, Quoc V},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{bucilu2006model,
  title={Model compression},
  author={Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006},
  organization={ACM}
}

@inproceedings{parthasarathi2019lessons,
  title={Lessons from building acoustic models with a million hours of speech},
  author={Parthasarathi, Sree Hari Krishnan and Strom, Nikko},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6670--6674},
  year={2019},
  organization={IEEE}
}


@inproceedings{ba2014deep,
  title={Do deep nets really need to be deep?},
  author={Ba, Jimmy and Caruana, Rich},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2654--2662},
  year={2014}
}

@inproceedings{shi2018transductive,
  title={Transductive semi-supervised deep learning using min-max features},
  author={Shi, Weiwei and Gong, Yihong and Ding, Chris and MaXiaoyu Tao, Zhiheng and Zheng, Nanning},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={299--315},
  year={2018}
}

@inproceedings{riloff2003learning,
  title={Learning extraction patterns for subjective expressions},
  author={Riloff, Ellen and Wiebe, Janyce},
  booktitle={Proceedings of the 2003 conference on Empirical methods in natural language processing},
  pages={105--112},
  year={2003}
}

@techreport{zhu2005semi,
  title={Semi-supervised learning literature survey},
  author={Zhu, Xiaojin Jerry},
  year={2005},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@article{arazo2019pseudo,
  title={Pseudo-Labeling and Confirmation Bias in Deep Semi-Supervised Learning},
  author={Arazo, Eric and Ortego, Diego and Albert, Paul and O'Connor, Noel E and McGuinness, Kevin},
  journal={arXiv preprint arXiv:1908.02983},
  year={2019}
}

@article{li2019certainty,
  title={Certainty-Driven Consistency Loss for Semi-supervised Learning},
  author={Li, Yingting and Liu, Lu and Tan, Robby T},
  journal={arXiv preprint arXiv:1901.05657},
  year={2019}
}

@inproceedings{chen2018semi,
  title={Semi-supervised deep learning with memory},
  author={Chen, Yanbei and Zhu, Xiatian and Gong, Shaogang},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={268--283},
  year={2018}
}

@inproceedings{qiao2018deep,
  title={Deep co-training for semi-supervised image recognition},
  author={Qiao, Siyuan and Shen, Wei and Zhang, Zhishuai and Wang, Bo and Yuille, Alan},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={135--152},
  year={2018}
}

@inproceedings{iscen2019label,
  title={Label propagation for deep semi-supervised learning},
  author={Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ondrej},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5070--5079},
  year={2019}
}


@inproceedings{Chowdhury19,
  author    = {Aruni {Roy Chowdhury} and
               Prithvijit Chakrabarty and
               Ashish Singh and
               SouYoung Jin and
               Huaizu Jiang and
               Liangliang Cao and
               Erik G. Learned{-}Miller},
  title     = {Automatic adaptation of object detectors to new domains using self-training},
  booktitle   = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2019}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}


@inproceedings{najafi2019robustness,
  title={Robustness to adversarial perturbations in learning from incomplete data},
  author={Najafi, Amir and Maeda, Shin-ichi and Koyama, Masanori and Miyato, Takeru},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}
@inproceedings{gpipe18,
  title={{GPipe}: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Yonglong and Chen, Dehao and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Chen, Zhifeng},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}
@inproceedings{zoph2018learning,
  title={Learning transferable architectures for scalable image recognition},
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8697--8710},
  year={2018}
}
@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}

@article{howard2013some,
  title={Some improvements on deep convolutional neural network based image classification},
  author={Howard, Andrew G},
  journal={arXiv preprint arXiv:1312.5402},
  year={2013}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}



@article{babakhin2019semi,
  title={Semi-Supervised Segmentation of Salt Bodies in Seismic Images using an Ensemble of Convolutional Neural Networks},
  author={Babakhin, Yauhen and Sanakoyeu, Artsiom and Kitamura, Hirotoshi},
  journal={arXiv preprint arXiv:1904.04445},
  year={2019}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{liu2018progressive,
  title={Progressive neural architecture search},
  author={Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={19--34},
  year={2018}
}

@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{zhang2017polynet,
  title={Polynet: A pursuit of structural diversity in very deep networks},
  author={Zhang, Xingcheng and Li, Zhizhong and Change Loy, Chen and Lin, Dahua},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={718--726},
  year={2017}
}

@article{touvron2019fixing,
  title={Fixing the train-test resolution discrepancy},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:1906.06423},
  year={2019}
}



@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{wan2013regularization,
  title={Regularization of neural networks using dropconnect},
  author={Wan, Li and Zeiler, Matthew and Zhang, Sixin and Le Cun, Yann and Fergus, Rob},
  booktitle={International conference on machine learning},
  pages={1058--1066},
  year={2013}
}

@article{hendrycks2019natural,
  title={Natural adversarial examples},
  author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
  journal={arXiv preprint arXiv:1907.07174},
  year={2019}
}

@inproceedings{hendrycks2018benchmarking,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas G},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{veit2017learning,
  title={Learning from noisy large-scale datasets with minimal supervision},
  author={Veit, Andreas and Alldrin, Neil and Chechik, Gal and Krasin, Ivan and Gupta, Abhinav and Belongie, Serge},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={839--847},
  year={2017}
}


@article{sun2019learning,
  title={Learning to Self-Train for Semi-Supervised Few-Shot Classification},
  author={Sun, Qianru and Li, Xinzhe and Liu, Yaoyao and Zheng, Shibao and Chua, Tat-Seng and Schiele, Bernt},
  journal={arXiv preprint arXiv:1906.00562},
  year={2019}
}

@article{karamanolakis2019leveraging,
  title={Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through Weakly Supervised Co-Training},
  author={Karamanolakis, Giannis and Hsu, Daniel and Gravano, Luis},
  journal={Empirical Methods in Natural Language Processing (EMNLP)},
  year={2019}
}

@inproceedings{geirhos2018imagenet,
  title={{ImageNet-trained CNNs} are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{yarowsky1995unsupervised,
  title={Unsupervised word sense disambiguation rivaling supervised methods},
  author={Yarowsky, David},
  booktitle={33rd annual meeting of the association for computational linguistics},
  pages={189--196},
  year={1995}
}

@article{recht2019imagenet,
  title={Do ImageNet Classifiers Generalize to ImageNet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  journal={International Conference on Machine Learning},
  year={2019}
}

@article{lopes2019improving,
  title={Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation},
  author={Lopes, Raphael Gontijo and Yin, Dong and Poole, Ben and Gilmer, Justin and Cubuk, Ekin D},
  journal={arXiv preprint arXiv:1906.02611},
  year={2019}
}

@article{ngiam2018domain,
  title={Domain adaptive transfer learning with specialist models},
  author={Ngiam, Jiquan and Peng, Daiyi and Vasudevan, Vijay and Kornblith, Simon and Le, Quoc V and Pang, Ruoming},
  journal={arXiv preprint arXiv:1811.07056},
  year={2018}
}

@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={European conference on computer vision},
  pages={646--661},
  year={2016},
  organization={Springer}
}
@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@inproceedings{gu2019using,
  title={Using videos to evaluate image model robustness},
  author={Gu, Keren and Yang, Brandon and Ngiam, Jiquan and Le, Quoc and Shlens, Jonathan},
  booktitle={ICLR Workshop},
  year={2019}
}
@inproceedings{hendrycks2019using,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{scudder1965probability,
  title={Probability of error of some adaptive pattern-recognition machines},
  author={Scudder, H},
  journal={IEEE Transactions on Information Theory},
  volume={11},
  number={3},
  pages={363--371},
  year={1965},
  publisher={IEEE}
}

@article{zhu2002learning,
  title={Learning from labeled and unlabeled data with label propagation},
  author={Zhu, X and Ghahramani, Z},
  year={2002},
  publisher={Center for Automated Learning and Discovery, CMU}
}


@inproceedings{furlanello2018born,
  title={Born again neural networks},
  author={Furlanello, Tommaso and Lipton, Zachary C and Tschannen, Michael and Itti, Laurent and Anandkumar, Anima},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2661--2671},
  year={2019}
}

@inproceedings{radosavovic2018data,
  title={Data distillation: Towards omni-supervised learning},
  author={Radosavovic, Ilija and Doll{\'a}r, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4119--4128},
  year={2018}
}

@misc{garrido2023rankme,
      title={RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank}, 
      author={Quentin Garrido and Randall Balestriero and Laurent Najman and Yann Lecun},
      year={2023},
      eprint={2210.02885},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
thilak2024lidar,
title={Li{DAR}: Sensing Linear Probing Performance in Joint Embedding {SSL} Architectures},
author={Vimal Thilak and Chen Huang and Omid Saremi and Laurent Dinh and Hanlin Goh and Preetum Nakkiran and Joshua M. Susskind and Etai Littwin},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=f3g5XpL9Kb}
}

@misc{lin2024parrot,
      title={Parrot Captions Teach CLIP to Spot Text}, 
      author={Yiqi Lin and Conghui He and Alex Jinpeng Wang and Bin Wang and Weijia Li and Mike Zheng Shou},
      year={2024},
      eprint={2312.14232},
      archivePrefix={arXiv},
      primaryClass={id='cs.CV' full_name='Computer Vision and Pattern Recognition' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers image processing, computer vision, pattern recognition, and scene understanding. Roughly includes material in ACM Subject Classes I.2.10, I.4, and I.5.'}
}

@inproceedings{
    fu2024featup,
    title={FeatUp: A Model-Agnostic Framework for Features at Any Resolution},
    author={Stephanie Fu and Mark Hamilton and Laura E. Brandt and Axel Feldmann and Zhoutong Zhang and William T. Freeman},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=GkJiNn2QDF}
}

@misc{guo2024videosamopenworldvideosegmentation,
      title={VideoSAM: Open-World Video Segmentation}, 
      author={Pinxue Guo and Zixu Zhao and Jianxiong Gao and Chongruo Wu and Tong He and Zheng Zhang and Tianjun Xiao and Wenqiang Zhang},
      year={2024},
      eprint={2410.08781},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.08781}, 
}

@inproceedings{jiang2024mlore,
  title={Multi-Task Dense Prediction via Mixture of Low-Rank Experts},
  author={Yang, Yuqi and Jiang, Peng-Tao and Hou, Qibin and Zhang, Hao and Chen, Jinwei and Li, Bo},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year={2024}
}

@misc{lu2024swissarmyknifesynergizing,
      title={Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning}, 
      author={Yuxiang Lu and Shengcao Cao and Yu-Xiong Wang},
      year={2024},
      eprint={2410.14633},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.14633}, 
}

@misc{ranzinger2024phisdistributionbalancinglabelfree,
      title={PHI-S: Distribution Balancing for Label-Free Multi-Teacher Distillation}, 
      author={Mike Ranzinger and Jon Barker and Greg Heinrich and Pavlo Molchanov and Bryan Catanzaro and Andrew Tao},
      year={2024},
      eprint={2410.01680},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.01680}, 
}

@misc{heinrich2024radioamplifiedimprovedbaselines,
      title={RADIO Amplified: Improved Baselines for Agglomerative Vision Foundation Models}, 
      author={Greg Heinrich and Mike Ranzinger and Hongxu and Yin and Yao Lu and Jan Kautz and Andrew Tao and Bryan Catanzaro and Pavlo Molchanov},
      year={2024},
      eprint={2412.07679},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.07679}, 
}

@article{Maninis2019AttentiveSO,
  title={Attentive Single-Tasking of Multiple Tasks},
  author={Kevis-Kokitsi Maninis and Ilija Radosavovic and Iasonas Kokkinos},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={1851-1860},
  url={https://api.semanticscholar.org/CorpusID:121100839}
}

@misc{mardiamultivariate,
  title={Multivariate Analysis},
  author={Mardia, K and Kent, JT and Taylor, C},
  publisher={Wiley}
}

@inproceedings{
drozdova2024semisupervised,
title={Semi-Supervised Fine-Tuning of Vision Foundation Models with Content-Style Decomposition},
author={Mariia Drozdova and Vitaliy Kinakh and Yury Belousov and Erica Lastufka and Slava Voloshynovskiy},
booktitle={NeurIPS 2024 Workshop on Fine-Tuning in Modern Machine Learning: Principles and Scalability},
year={2024},
url={https://openreview.net/forum?id=zHljWq2hqH}
}

@article{hotelling1936cca,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2333955},
 author = {Harold Hotelling},
 journal = {Biometrika},
 number = {3/4},
 pages = {321--377},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Relations Between Two Sets of Variates},
 urldate = {2025-01-12},
 volume = {28},
 year = {1936}
}

@inproceedings{krizhevsky2012alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}


@inProceedings{elbanani2024probing,
  title={{Probing the 3D Awareness of Visual Foundation Models}},
  author={
        El Banani, Mohamed and Raj, Amit and Maninis, Kevis-Kokitsi and 
        Kar, Abhishek and Li, Yuanzhen and Rubinstein, Michael and Sun, Deqing and 
        Guibas, Leonidas and Johnson, Justin and Jampani, Varun
        },
  booktitle={CVPR},
  year={2024},
}

@article{zbontar2021barlow,
  title={Barlow Twins: Self-Supervised Learning via Redundancy Reduction},
  author={Zbontar, Jure and Jing, Li and Misra, Ishan and LeCun, Yann and Deny, St{\'e}phane},
  journal={arXiv preprint arXiv:2103.03230},
  year={2021}
}

@inproceedings{
bardes2022vicreg,
title={{VICR}eg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning},
author={Adrien Bardes and Jean Ponce and Yann LeCun},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xm6YD62D1Ub}
}
