\section{Related works}
\label{sec:related-works}



HAR using sensors relies on a network of interconnected devices to monitor daily activities \cite{qiu2022multi}. While this data provides valuable insights into Activities of Daily Living (ADL), it also raises significant privacy concerns \cite{yang2017survey}. Consequently, systems utilizing less intrusive binary sensors and wearables have become widely adopted \cite{abade2018non}.  However, HAR in smart homes presents a considerable challenge. Human activity is inherently complex, varying not only daily but also between individuals with unique habits and abilities.

Smart home environments often house multiple occupants, which presents a significant challenge in accurately identifying individual activities \cite{li2020multi}. Many smart home devices lack the capacity to determine who triggered a sensor, making it difficult to distinguish ADLs in multioccupant settings \cite{bouchabou2021survey}.  This ambiguity hinders research progress in this area, leaving many crucial questions unanswered and slowing the development of effective solutions for multi-occupant HAR.

To overcome limitations of single-sensor approaches in HAR, researchers are exploring indoor technology combined with data fusion methods. Although UWB provides precise localisation \cite{khan2024occupancy, zhan2021mosen}, its sensitivity to obstacles requires the use of heat maps for enhanced spatial representation \cite{naser2020adaptive, yuan2024self, polodMultiOccupantTracking2024}. Integrating UWB with nearby sensors, such as wearables, provides richer contextual information, improving activity recognition accuracy, particularly in multi-occupant settings \cite{zhang2022deep, polodMultiOccupantTracking2024}. Furthermore, incorporating fuzzy logic helps to manage uncertainty and differentiate concurrent activities \cite{yang2021survey, polo2024human}. Advanced hardware and processing techniques further optimise data analysis for improved HAR accuracy \cite{javaid2021sensors}.

While these approaches advance the field of HAR, they often lack the ability to provide personalised and contextually relevant assistance to users to identify and solve specific real-world problems \cite{diraco2023review}. This is where LLM and chatbots offer a significant opportunity \cite{miura2022assisting,valtolina2021charlie}. LLMs can process and understand natural language, allowing the development of chatbots capable of engaging in meaningful conversations with users and fragile people \cite{yaser2024rag}. By integrating LLMs with HAR systems, chatbots take advantage of the activity data collected to provide activity recognition \cite{cleland2024leveraging}, customised support, such as reminders, evaluation of mental status \cite{hristidis2023chatgpt}, loneliness \cite{yangai}, and even emotional support \cite{alessa2023towards} that improves responsible use of social care \cite{emmer2024defining}. For example, a chatbot could remind a user to take their medication according to their daily routine and detected activity, or offer encouragement and motivation if it senses that the user is struggling with a particular task \cite{alessa2023towards}. This combination of LLM and HAR has the potential to revolutionise the way smart environments assist and interact with users, creating truly personalised and supportive living spaces; however, the lack of context generates delusion in real-life deployments \cite{irfan2023between}.

Although existing research explores various aspects of smart environments and activity recognition, this work presents a novel approach by integrating LLM with context-aware real-time HAR and indoor localisation. This fusion of technologies enables the development of context-aware chatbots capable of providing personalised assistance and enhancing user experiences in unprecedented ways. By combining the power of LLMs with granular activity and location data, this architecture paves the way for truly intelligent and supportive smart environments that cater to the unique needs of each individual.