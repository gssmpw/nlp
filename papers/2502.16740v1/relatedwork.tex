\section{Related Work}
\subsection{Task delegation to AI and Trust in AI}
Task delegation refers to giving a system the authority to automatically handle certain tasks. This can happen either without the user fully understanding how it works or with the user supervising the system’s actions \cite{wiener1980flight}. Due to the rapid advancement of AI, discussions around task delegation are more active than ever \cite{lubars2019ask}. For instance, Brian et al. \cite{lubars2019ask} explored how factors such as motivation, task difficulty, risk, and trust in AI, influence humans’ preferences for delegating tasks to AI. They found that trust is the most influential factor. When humans have a high degree of trust in AI, they are more willing to delegate their tasks. Trust, defined as an attitude that an agent will achieve an individual's goals in situations of uncertainty and vulnerability \cite{lee2004trust}, plays a crucial role in effective human-AI collaboration. It is essential for fostering productive human-AI interactions, which not only leverage AI assistance to human but also improve task performance \cite{bansal2021does, salimzadeh2024dealing}. As AI evolves, ensuring users place appropriate trust in the system—avoiding both overtrust and undertrust—remains a key consideration \cite{weisz2024design}. Despite these efforts, there has been limited discussion on the meaning of trusting generative AI in co-creation tasks, where definitive answers do not exist. Furthermore, how authors delegate content creation tasks to AIs remains underexplored, highlighting the need for further research in this area.

%Some of the factors that can impact on AI trust are prior experience with AI \cite{salimzadeh2024dealing}, human control over algorithmic decisions \cite{ahn2024impact}, source of training data \cite{hao2024advancing}. 
%Trust has been suggested to influence reliance; however, it alone is not enough to ensure reliance, as factors like time constraints, perceived risk, and self-confidence \cite{schoeffer2024explanations}. 
%With the rise of human-AI collaboration, escaping from users' overtrust or undertrust, and ensuring users' appropriate trust on AI gets more attention. For example, providing adaptive explanation \cite{bansal2021does} for AI output or encouraging users to review and think critically about the generative model's outputs \cite{weisz2024design} to calibrate trust have been discussed. 
%Trust is a decision by A to delegate to B some aspect of importance to A in achieving a goal \cite{wolf2024generative}. Decision delegation means entrusting others to make a decision on one's behalf \cite{candrian2022rise}.

\subsection{Human-AI Co-Creation (HACC) for Resolving Author’s Needs and Challenges}
With the development of generative AI models, AI has taken part in creative tasks, which were considered as a unique ability of humans. These days, various contents can be generated by generative AIs including text (e.g. novel \cite{yuan2022wordcraft}, advertising phrase \cite{saputra2023impact}), sound (e.g. music \cite{wang2022cps}, sound effects \cite{kang2023fall}), and image (e.g. emoticon \cite{yang2021icon}, character \cite{ruan2022anime}, human face \cite{jadhav2023high}). With the progress of AI capacity, the HACC, which means humans and AI collaborate on a shared creative product as partners \cite{rezwana2022designing}, has been increasingly studied.
For instance, researchers have explored technical gaps in authors' working practice and environment where HACC can solve \cite{inie2023designing,ko2023large,wan2023it}. %Ko et al. \cite {ko2023large} interviewed visual artists to understand how they would adopt large-scale text-to-image models to find new opportunities to support their creative works in the visual art field. 
In addition, based on these findings, HACC tools solving the gaps were suggested \cite{haoran2023magical,wang2023popblends,liu2022opal,ippolito2022creative,dang2022beyond}. Haoran et al. \cite{haoran2023magical} developed a system using AIs to help beginner artists create traditional Chinese paintings.
However, while most HACC-related studies focus on technically assisting authors, it is crucial to examine how authors in practice delegate creation tasks to generative AI to ensure more trustful HACC systems.