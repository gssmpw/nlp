\section{\dcad}
\label{sec:dcad-200}
To overcome the limitations of existing multilingual datasets, we propose \dcad, a large-scale, high-quality multilingual dataset constructed by integrating data from latest version of Common Crawl and existing multilingual datasets (Section~\ref{sec:data_collect}).
This dataset is cleaned using our proposed framework, which treats data cleaning as an anomaly detection problem (Section~\ref{sec:ad_clean}).
The construction of \dcad is supported by robust computational resources, as detailed in Section~\ref{sec:resources}.

\subsection{Data Collection}
\label{sec:data_collect}
To ensure comprehensiveness and robustness in multilingual data representation, \dcad integrates data from four main sources: MaLA, Fineweb, Fineweb-2, and newly extracted Common Crawl data.
Each source is selected based on its unique contribution to multilingual coverage, data quality, and freshness, with careful consideration of dataset complementarity to avoid redundancy.
Specifically, MaLA and Fineweb-2 are prioritized due to their broad language coverage and high-quality curation, which complements other widely used datasets like mC4~\cite{raffel2020exploring} and OSCAR~\cite{abadji2022towards}.
% To minimize overlap, we implement a series of deduplication strategies across datasets, such as utilizing MinHashLSH~\cite{broder1998min} to eliminate near-identical entries and ensure maximal diversity across the data sources.

\textbf{MaLA Corpus~\cite{ji2024emma}.}
The MaLA corpus covers 939 languages, aggregating data from diverse sources including Bloom~\cite{leong-etal-2022-bloom}, CC100~\cite{conneau-etal-2020-unsupervised}, Glot500~\cite{imanigooghari-etal-2023-glot500}, among others.
Deduplication is performed using MinHashLSH~\cite{broder1998min}, which is particularly effective in removing near-duplicate entries that often arise from common web sources.
% This process ensures minimal overlap with other datasets and preserves the linguistic diversity of the corpus.
Language codes are based on ISO 639-3\footnote{\url{https://en.wikipedia.org/wiki/ISO_639-3}} standards, and language-specific scripts are supported by GlotScript\footnote{\url{https://github.com/cisnlp/GlotScript}}.

\textbf{Fineweb Corpus~\cite{penedo2024fineweb}.}
Fineweb is a high-quality English web dataset extracted from Common Crawl, consisting of over 15 trillion tokens and updated monthly.
Data cleaning and deduplication are performed using the Datatrove library.\footnote{\url{https://github.com/huggingface/datatrove}}
For \dcad, we incorporate data from the November 2024 release (\texttt{CC-MAIN-2024-46}) to ensure freshness and up-to-date relevance of the data.

\textbf{Fineweb-2 Corpus~\cite{penedo2024fineweb-2}.}
Fineweb-2 expands Fineweb to include multilingual data, covering 1,915 languages.
It processes 96 Common Crawl dumps from 2013 (\texttt{CC-MAIN-2013-20}) to April 2024 (\texttt{CC-MAIN-2024-20}). 
The deduplication process within Fineweb-2 is similarly handled using the Datatrove library, ensuring the exclusion of redundant entries and maintaining high-quality multilingual coverage.

\textbf{Newly Extracted Common Crawl Data.}
To incorporate the most recent multilingual data, we extract and process Common Crawl dumps from May 2024 (\texttt{CC-MAIN-2024-22}) to November 2024 (\texttt{CC-MAIN-2024-46}).
Using the Fineweb-2 pipeline\footnote{\url{https://github.com/huggingface/fineweb-2}}, we process 21.54TB of multilingual data, ensuring that the data remains fresh and suitable for downstream tasks.
This further extends the multilingual data pool and enhances the coverage across underrepresented languages.

%% scatter plots
\input{figure/anomaly_detection}
%%%

\subsection{Data Cleaning as Anomaly Detection}
\label{sec:ad_clean}
Traditional data cleaning methods rely on fixed thresholds for document-level features, making them less adaptable to the diversity of multilingual data.
To address this, we propose a novel framework that formulates data cleaning as an anomaly detection task, which involves the feature extraction (Section~\ref{sec:feature_extract}) and anomaly detection (Section~\ref{sec:ad}).

\subsubsection{Feature Extraction}
\label{sec:feature_extract}
Inspired by~\citet{laurenccon2022bigscience} and~\citet{nguyen-etal-2024-culturax}, we extract eight statistical features from each document to evaluate text quality.
Each feature is selected for its ability to capture important characteristics of the text, contributing to robust anomaly detection.
Let $t$ represent a document; the extracted features are:
\textbf{(1) Number of Words, $n_w(t)$:} Total token count after tokenization.
\textbf{(2) Character Repetition Ratio, $r_c(t)$:} Fraction of repeated character sequences, highlighting noise or encoding errors.
\textbf{(3) Word Repetition Ratio, $r_w(t)$:} Proportion of repeated words, indicating redundancy or unnatural text.
\textbf{(4) Special Characters Ratio, $r_s(t)$:} Fraction of special characters based on language-specific lists from~\citet{laurenccon2022bigscience}. These lists include emojis, whitespace types, numbers, and punctuation.
\textbf{(5) Stopwords Ratio, $r_{\text{stop}}(t)$:} Proportion of stopwords using Fineweb-2's language-specific stopword lists. High or low ratios may indicate text quality issues.
\textbf{(6) Flagged Words Ratio, $r_{\text{flag}}(t)$:} Fraction of toxic or profane words from \textit{Toxicity-200}~\cite{costa2022no} or public repositories\footnote{\url{https://github.com/thisandagain/washyourmouthoutwithsoap}}.
\textbf{(7) Language Identification (LID) Score, $s_{\text{lid}}(t)$:} Confidence score from GlotLID~\cite{kargaran-etal-2023-glotlid}, supporting over 2,000 languages. Low scores may indicate misclassification or noise.
\textbf{(8) Perplexity Score, $s_{\text{ppl}}(t)$:} Using KenLM~\cite{heafield-2011-kenlm}, we train a language model for each language on multilingual Wikipedia data (November 2023). For unsupported languages, a default perplexity of 500 is used.

The feature vector for each document is defined as:
\begin{equation}
\begin{aligned}
\mathbf{x} &= \left[ n_w(t),\, r_c(t),\, r_w(t),\, r_s(t),\, \right. \\
&\left. r_{\text{stop}}(t),\, r_{\text{flag}}(t),\, s_{\text{lid}}(t),\, s_{\text{ppl}}(t) \right]^\top \in \mathbb{R}^8.\
\end{aligned}
\end{equation}

\subsubsection{Anomaly Detection}
\label{sec:ad}
After extracting feature vectors $\mathbf{x} \in \mathbb{R}^8$, we standardize each feature to handle differences in scale. The standardized value $\tilde{x}_j$ for the $j$-th feature is given by:
\begin{equation}
\tilde{x}_j = \frac{x_j - \mu_j}{\sigma_j}, \quad j = 1, \ldots, 8,
\end{equation}
where $\mu_j$ and $\sigma_j$ are the mean and standard deviation of the $j$-th feature across the dataset. The standardized feature vector is:
\begin{equation}
    \tilde{\mathbf{x}} = \frac{\mathbf{x} - \boldsymbol{\mu}}{\boldsymbol{\sigma}},
\end{equation}
where $\boldsymbol{\mu} = [\mu_1, \mu_2, \ldots, \mu_8]^\top$ and $\boldsymbol{\sigma} = [\sigma_1, \sigma_2, \ldots, \sigma_8]^\top$ are the vectors of means and standard deviations, respectively.

Take Isolation Forest~\cite{liu2008isolation} as an example\footnote{We also evaluate some other algorithms, please refer to Section~\ref{sec:eval} for more details.}, we compute an anomaly score $\phi(\tilde{\mathbf{x}})$ for each document.
The Isolation Forest algorithm assigns anomaly scores based on the average path length required to isolate a data point in a decision tree. Specifically, for a document represented by $\tilde{\mathbf{x}}$, the anomaly score is defined as:
\begin{equation}
\phi(\tilde{\mathbf{x}}) = 2^{-\frac{h(\tilde{\mathbf{x}})}{c(n)}},
\end{equation}
where $h(\tilde{\mathbf{x}})$ is the average path length for $\tilde{\mathbf{x}}$ across all trees in the Isolation Forest, and $c(n)$ is the average path length of a point in a binary tree with $n$ samples, given by:
\begin{equation}
    c(n) = 2H(n-1) - \frac{2(n-1)}{n},
\end{equation}
where $H(i)$ is the $i$-th harmonic number, defined as $H(i) = \sum_{k=1}^i \frac{1}{k}$.

An anomaly score $\phi(\tilde{\mathbf{x}}): \mathbb{R}^8 \to \mathbb{R}$ is defined to quantify how far a document deviates from typical data.
Higher scores indicate a higher likelihood of anomalies.
To classify a document, we use the decision rule:
% \begin{equation}
% f(\tilde{\mathbf{x}}) = \operatorname{sign}(\tau - \phi(\tilde{\mathbf{x}})),
% \end{equation}
% or equivalently,
\begin{equation}
f(\tilde{\mathbf{x}}) =
\begin{cases}
1, & \text{if } \phi(\tilde{\mathbf{x}}) < \tau, \\
-1, & \text{if } \phi(\tilde{\mathbf{x}}) \geq \tau,
\end{cases}
\end{equation}
where $\tau \in \mathbb{R}$ is a hyperparameter determined empirically or through cross-validation.\footnote{We use the default setting of the specific anomaly detection algorithm.}

Once the anomaly scores $\phi(\tilde{\mathbf{x}})$ are computed for all samples in the standardized dataset $\tilde{\mathcal{X}} = \{ \tilde{\mathbf{x}}_1, \ldots, \tilde{\mathbf{x}}_N \}$, we partition the dataset into two subsets:
\begin{align}
\mathcal{X}_{\text{keep}} &= \{ \tilde{\mathbf{x}} \in \tilde{\mathcal{X}} : f(\tilde{\mathbf{x}}) = 1 \}, \\
\mathcal{X}_{\text{remove}} &= \{ \tilde{\mathbf{x}} \in \tilde{\mathcal{X}} : f(\tilde{\mathbf{x}}) = -1 \}.
\end{align}
Following anomaly detection, the dataset is partitioned into a clean subset $\mathcal{X}_{\text{keep}}$ and an anomalous subset $\mathcal{X}_{\text{remove}}$. The former is retained for downstream tasks such as model training, while the latter may be discarded or further examined for potential data quality issues.

\subsubsection{Visualization}
To qualitatively assess the separation achieved by our anomaly detection framework, we generate scatter plots (Figure~\ref{fig:anomaly_detect}) of the $8$ feature values, with data points color-coded according to their anomaly labels.
These visualizations facilitate the interpretation of decision boundaries and highlight the features that contribute most significantly to the detection process.
We observe well-defined clusters separating anomalous and non-anomalous data points, with anomalies exhibiting distinct patterns compared to the majority of the data.
Features such as the language identification score ($s_{\text{lid}}(t)$) and perplexity score ($s_{\text{ppl}}(t)$) are expected to be particularly discriminative in identifying anomalies, as they capture linguistic irregularities and unexpected text patterns. For example, low $lid$ or unusually high $ppl$ scores often indicate problematic text, such as spam, low-quality content, or noise.
The framework effectively identifies and removes such low-quality text samples, which can be easily visualized by the separation of these points in the scatter plots.

\subsection{Computational Resources}
\label{sec:resources}
The construction of the \dcad dataset leveraged clould
% {Ksyun}\footnote{\url{https://k8s.ksyun.com}}
servers to process and clean the multilingual data efficiently.
Each server instance is equipped with 32 CPU cores, 128GB of memory, and 100GB of disk storage, which is utilized for intermediate data handling and memory-intensive operations such as anomaly detection.
The workload is managed using container orchestration tools,
% {Kubernetes}\footnote{\url{https://kubernetes.io}},
with up to 100 parallel tasks running per job to ensure scalability.