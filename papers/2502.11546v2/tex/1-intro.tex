\section{Introduction}
\label{sec:intro}
Large language models (LLMs) have achieved great progress on a variety of NLP tasks by leveraging vast amounts of training data~\cite{minaee2024large}.
However, their performance remains heavily biased towards high-resource languages (e.g., English), while low-resource languages are still left behind~\cite{zhu2024multilingual,huang2024survey}.
To improve the multilingual capabilities of LLMs, a common strategy is to incorporate large amounts of non-English data, either by continue pretraining~\cite{lai-etal-2024-llms} or by instruction tuning in multilingual settings~\cite{ustun-etal-2024-aya}.
Therefore, constructing large-scale, high-quality multilingual datasets is crucial for enhancing the multilingual performance of LLMs.

%% introduciton table--- compare with some famous corpus
\input{table/intro_comp}
%%

%
Recent efforts to construct multilingual datasets have built several notable resources, including CulturaX~\cite{nguyen-etal-2024-culturax}, HPLT~\cite{de-gibert-etal-2024-new}, Madlad-400~\cite{kudugunta2024madlad}, MaLA~\cite{lin2024mala}, and Glotcc~\cite{kargaran2024glotcc}, which cover 167, 191, 419, 939, and 1,331 languages, respectively.
While these datasets have made significant contributions, they exhibit three major limitations, as summarized in Table~\ref{tab:intro_comp}:
\textbf{(1) Outdated data sources:} These datasets primarily rely on older versions of Common Crawl\footnote{\url{https://commoncrawl.org}}, 
which results in outdated knowledge and an elevated risk of hallucination~\cite{huang2023survey}.
\textbf{(2) Limited coverage of high- and medium-resource languages\footnote{We follow the criteria from~\citet{goyal-etal-2022-flores} to categorize languages: High: $>100M$; Medium: $(1M, 100M)$; Low: $(100K, 1M)$; Very Low: $<100K$.}:} For instance, Fineweb-2~\cite{penedo2024fineweb-2}, which supports 1,915 languages, includes data from only 10 high-resource languages and 62 medium-resource languages.
\textbf{(3) Insufficient data cleaning:} Despite being cleaned, recent studies~\cite{dou-etal-2024-sailor,zhang-etal-2024-mc2} indicate that these datasets still contain a significant amount of noise, which makes them difficult to directly employ in training multilingual LLMs. For instance,~\citet{dou-etal-2024-sailor} found that 31.11\% of the data in Madlad-400 could still be further removed by advanced data cleaning.

Traditional data cleaning workflows~\cite{albalak2024survey} often rely on document-level features (e.g., language identification;~\citealp{kargaran-etal-2023-glotlid}) and fixed thresholds to filter out low-quality data.
However, this approach struggles with cross-lingual consistency due to feature distribution differences.
For example\footnote{Please refer to Appendix~\ref{appex:feature_analysis} for more details.}, the variation in average word counts across languages, datasets, and shards demonstrates the limitations of heuristic threshold-based data cleaning methods.
Notably, while Fineweb-2 fine-tunes thresholds for more than 1,000 languages, this process is computationally intensive and time-consuming.

To address these challenges, we introduce~\dcad, a new large-scale, high-quality multilingual dataset that can be directly applied to LLM training. \dcad covers 2282 languages (155 high/medium languages), incorporating the latest Common Crawl data (November 2024;~\texttt{CC-MAIN-2024-46}) and existing multilingual datasets.
Additionally, we propose a novel language-agnostic data cleaning approach that treats data cleaning as an anomaly detection~\cite{su2024large} problem, distinguishing it from traditional threshold-based methods~\cite{laurenccon2022bigscience,penedo2024fineweb-2}.
Our approach extracts eight statistical features from each document to evaluate quality, including metrics like \textit{language identification score}, \textit{word repetition}, \textit{special character ratio}, and \textit{perplexity score}.
Anomaly detection algorithms dynamically identify and remove outliers by recognizing deviations from typical document quality metrics, ensuring consistent and language-agnostic filtering.

We provide a comprehensive analysis of \dcad (Section~\ref{sec:analysis}), highlighting its diverse document distribution, broad geographical and script coverage, as well as resource categorization across languages, with a particular focus on supporting both high-resource and underrepresented languages.
The datasetâ€™s extensive multilingual and cross-script representation is further validated through evaluation on the FineTask benchmark~\cite{penedo2024fineweb-2}, where LLMs trained on \dcad consistently outperform those trained on other multilingual datasets. 
Additionally, our anomaly detection-based data cleaning method demonstrates significant improvements in model performance, ensuring high-quality, noise-reduced data for large-scale multilingual model training.

In summary, we make the following contributions:  
\textbf{(1)} We propose a novel data cleaning framework that frames the task as anomaly detection, offering a language-agnostic and adaptive solution without manual threshold tuning.  
\textbf{(2)} We release \dcad, a comprehensive multilingual dataset covering over 2,282 languages, containing 8.63B of documents, 46.72TB of disk size and 159 writing scripts with metadata annotations, making it suitable for a wide range of downstream NLP tasks.
\textbf{(3)} Extensive evaluation experiments on FineTask benchmark demonstrate that \dcad consistently outperforms existing multilingual corpora, achieving higher normalized accuracy across multiple languages and NLP tasks.