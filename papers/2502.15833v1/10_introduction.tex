\section{Introduction}

Most machine learning algorithms operate under the assumption that training and test data share the same distribution. 
However, this assumption frequently fails in real-world scenarios where models encounter out-of-distribution (OOD) data—samples that deviate from the training distribution, such as those belonging to novel categories.
This mismatch can significantly impair a model's accuracy and reliability. 
As a result, OOD detection has become a critical area of research, aiming to discern when inputs fall outside the scope of the distribution used for training. 
Effective OOD detection not only enhances a model’s robustness by identifying and handling these anomalous inputs but also ensures that the model maintains reliable performance on known, in-distribution data \citep{NEURIPS2022_d201587e}.

OOD detection poses a significant challenge due to the diverse nature of OOD types. 
While many OOD detectors excel when tested against specific OOD datasets, they often struggle to maintain high performance across a broad range of OOD samples. 
As stated by \citet{zhang2023openood} \textit{there is no single winner that always outperforms others across multiple datasets}. 
One reason for this inconsistency is that OOD instances can vary widely, from subtle variations near the distribution boundary to completely dissimilar and far-off examples. 
As a result, developing a universal OOD detection method that performs robustly across multiple datasets, spanning near to far OOD samples, remains challenging.

In this paper, we present a novel OOD detection method using Kolmogorov-Arnold Networks (KANs) \citep{liu2024kankolmogorovarnoldnetworks}.
KANs are neural networks with a unique architecture that enhances interpretability, improves the accuracy-to-parameter ratio, and mitigates catastrophic forgetting compared to multilayer perceptrons (MLPs).
Our approach takes advantage of KANs' distinctive property of local neuroplasticity—a characteristic absent in traditional MLPs due to their reliance on shared, non-trainable activation functions.
In contrast, KANs demonstrate local plasticity owing to their spline-based architecture. 
This characteristic ensures that learning a new task impacts only the regions of the network activated by the training data, thereby preserving the integrity of distant and unrelated regions.

As illustrated in Figure \ref{fig:simplified_model}, our method compares the activation patterns of two identically initialized KANs: one trained on In-Distribution (InD) data and the other left untrained.
OOD samples will predominantly trigger the regions of the trained network that were not adapted during the learning phase, thus the samples will produce a response closer to the untrained network.

\begin{wrapfigure}{r}{0.4\textwidth}
    \vspace{-10pt} % Adjust the value as needed to remove the extra space above
    \begin{center}
        \includegraphics[width=1.0\linewidth]{figures/figure1.png}
    \end{center}
    \vspace{-10pt} % Adjust the value as needed to remove the extra space below
    \caption{Overview of the proposed method: the detector compares the activation function response of a trained KAN model with its untrained counterpart. A difference in the response indicates the sample is InD, a similar response suggests it is OOD.}
    \label{fig:simplified_model}
    \vspace{-10pt} % Adjust the value as needed to remove the extra space above
\end{wrapfigure}

Conversely, InD samples will mostly engage the neurons that have been trained, resulting in a noticeable difference in the activation between the two models. 


We tested our method on seven different benchmarks from two different domains: the OpenOOD CIFAR-10, CIFAR-100, ImageNet-200 full-spectrum (FS), and ImageNet-1K FS \citep{NEURIPS2022_d201587e} for the image domain, and the Ethnicity, Age, and Synthetic OOD benchmarks for the tabular medical data domain \citep{azizmalayeri2023unmasking}. 
Our experiments demonstrate that the KAN detector outperforms current State-Of-The-Art (SOTA) techniques across all seven benchmarks on the overall average AUROC that considers both near and far OOD.
Additionally, in contrast to many other SOTA methods, our approach's performance does not vary significantly based on the number of training samples.
This indicates that leveraging KANs leads to highly effective OOD detection, underscoring the potential of this novel architecture in developing more robust machine learning systems capable of operating reliably in diverse and unpredictable environments.