\section{Related Work}
This section reviews recent advancements in OOD detection, provides an overview of the latest innovations to enhance KAN performance, and explores the diverse sectors where KANs have demonstrated successful applications.

\subsection{Out-Of-Distribution detection}
OOD detection focuses on identifying instances with semantic shifts, a special case of distributional shift.  
OOD detection methods can be broadly classified into the following categories ____. 
\textbf{Classification-based methods} use the output of classification models, such as softmax scores, to distinguish between InD and OOD samples. Examples include Maximum Softmax Probability (MSP) ____, which uses the softmax score of the predicted class as a confidence score, and ODIN ____, which applies temperature scaling and input perturbations to enhance the separability of InD and OOD samples. 
More recent methods that fall in this category are SCALE ____, ASH ____, VIM ____, and KNN ____. 
Gradient-based methods also belong to this category. 
Examples include GradNorm ____ and NAC ____, which use gradients calculated from the KL divergence between the model's output and a uniform probability distribution.
\textbf{Density-based methods} model the probability distribution of the training data to identify deviations. 
This is often achieved using a Gaussian mixture model ____ or normalizing flows ____.
\textbf{Reconstruction-based methods} typically use autoencoders to reconstruct input samples and measure the reconstruction error as a signal for OOD detection ____.
\textbf{Distance-based methods} rely on distance metrics in the feature space to identify OOD samples. 
The Mahalanobis distance-based detector ____ first models the feature distribution with a class-conditional Gaussian distribution and then it derives the InD score using the Mahalanobis distance between the InD centroids and the input sample. 
fDBD ____ measures the distance between the latent feature of the sample and the class decision boundaries. 
Our method also falls into this category, as it computes the InD score by measuring the distance between the network's regions activated during training (InD regions) and those activated by the test sample.


\subsection{Kolmogorov-Arnold Networks}
\label{sec:kan_rel_works}

The recently introduced KAN ____ represents a significant advancement in neural network architectures, offering a potential alternative to traditional MLPs by not only enhancing accuracy but also leading to more interpretable models.
As a result, numerous studies have tried to innovate and refine KANs further. 
For example, many articles replace the spline architecture with more efficient or accurate alternatives such as Chebyshev polynomials ____, wavelet-based structures ____, sinusoidal functions ____, and radial basis functions ____. 
Others try to replicate advanced neural network architectures using KAN's characteristics. 
This includes convolutional neural networks ____ and graph neural networks ____, further demonstrating the versatility and potential of KANs. 
Applications of KANs have rapidly expanded across various domains, including time series analysis ____, solving ordinary and partial differential equations ____, hyperspectral image classification ____, and computer vision ____. 
Additionally, KANs have recently been applied to fields similar to OOD detection, such as abnormality detection ____ and AI-generated image detection ____. 
These studies leverage the superior accuracy and interpretability of KANs ____ to uncover more complex patterns in the data. 
While their work focuses on developing robust models that demonstrate KANs' capacity to generalize effectively to unseen samples, they do not address the detection of these samples. 
In contrast, we present a novel OOD detection method that leverages the unique local plasticity property of KANs, applicable to any backbone architecture.