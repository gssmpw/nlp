[
  {
    "index": 0,
    "papers": [
      {
        "key": "ding2022gpt",
        "author": "Ding, Bosheng and Qin, Chengwei and Liu, Linlin and Chia, Yew Ken and Joty, Shafiq and Li, Boyang and Bing, Lidong",
        "title": "Is gpt-3 a good data annotator?"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ye2022zerogen",
        "author": "Ye, Jiacheng and Gao, Jiahui and Li, Qintong and Xu, Hang and Feng, Jiangtao and Wu, Zhiyong and Yu, Tao and Kong, Lingpeng",
        "title": "Zerogen: Efficient zero-shot learning via dataset generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "dai2023auggpt",
        "author": "Dai, Haixing and Liu, Zhengliang and Liao, Wenxiong and Huang, Xiaoke and Cao, Yihan and Wu, Zihao and Zhao, Lin and Xu, Shaochen and Liu, Wei and Liu, Ninghao and others",
        "title": "Auggpt: Leveraging chatgpt for text data augmentation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "liang2022holistic",
        "author": "Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others",
        "title": "Holistic evaluation of language models"
      },
      {
        "key": "AlpacaEval",
        "author": "tatsu-lab",
        "title": "AlpacaEval : An Automatic Evaluator for Instruction-following Language Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "mishra2020dqi",
        "author": "Mishra, Swaroop and Arunkumar, Anjana and Sachdeva, Bhavdeep and Bryan, Chris and Baral, Chitta",
        "title": "Dqi: Measuring data quality in nlp"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "heusel2017gans",
        "author": "Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp",
        "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lai2020diversity",
        "author": "Lai, Yi-An and Zhu, Xuan and Zhang, Yi and Diab, Mona",
        "title": "Diversity, density, and homogeneity: Quantitative characteristic metrics for text collections"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "yu2024large",
        "author": "Yu, Yue and Zhuang, Yuchen and Zhang, Jieyu and Meng, Yu and Ratner, Alexander J and Krishna, Ranjay and Shen, Jiaming and Zhang, Chao",
        "title": "Large language model as attributed training data generator: A tale of diversity and bias"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "song2024scaling",
        "author": "Song, Feifan and Yu, Bowen and Lang, Hao and Yu, Haiyang and Huang, Fei and Wang, Houfeng and Li, Yongbin",
        "title": "Scaling Data Diversity for Fine-Tuning Language Models in Human Alignment"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "shu2019generating",
        "author": "Shu, Raphael and Nakayama, Hideki and Cho, Kyunghyun",
        "title": "Generating diverse translations with sentence codes"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh",
        "title": "Self-instruct: Aligning language models with self-generated instructions"
      },
      {
        "key": "padmakumar2023does",
        "author": "Padmakumar, Vishakh and He, He",
        "title": "Does Writing with Language Models Reduce Content Diversity?"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "heusel2017gans",
        "author": "Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp",
        "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "pillutla2021mauve",
        "author": "Pillutla, Krishna and Swayamdipta, Swabha and Zellers, Rowan and Thickstun, John and Welleck, Sean and Choi, Yejin and Harchaoui, Zaid",
        "title": "Mauve: Measuring the gap between neural text and human text using divergence frontiers"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "stasaski2022semantic",
        "author": "Stasaski, Katherine and Hearst, Marti A",
        "title": "Semantic diversity in dialogue with natural language inference"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "le2024exploring",
        "author": "Le Bronnec, Florian and V{\\'e}rine, Alexandre and Negrevergne, Benjamin and Chevaleyre, Yann and Allauzen, Alexandre",
        "title": "Exploring Precision and Recall to assess the quality and diversity of LLMs"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "lee2023beyond",
        "author": "Lee, Alycia and Miranda, Brando and Sundar, Sudharsan and Koyejo, Sanmi",
        "title": "Beyond scale: the diversity coefficient as a data quality metric demonstrates llms are pre-trained on formally diverse data"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "dan2023vendi",
        "author": "Dan Friedman, Dan and Dieng, Adji Bousso",
        "title": "The vendi score: A diversity evaluation metric for machine learning"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "du2019boosting",
        "author": "Du, Wenchao and Black, Alan W",
        "title": "Boosting dialog response generation"
      }
    ]
  }
]