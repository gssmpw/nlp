\section{Introduction}
\label{sec:intro}

Language in both speech and writing consists of two essential components: content and style. Broadly speaking, content refers to what is being expressed, while style pertains to how it is expressed. Specifically, style encompasses the variability of linguistic forms in actual language use \cite{inbook}. Historically, "Style" has been explored within the field of Stylisticsâ€”a branch of applied linguistics that examines writing styles in literary criticism as well as tone and accent in discourse analysis. However, the notion of style has gained renewed attention with the advancement of Generative AI technologies. Since the seminal work of \cite{gatys2015neuralalgorithmartisticstyle}, which introduced style transfer technology for images, substantial progress has been made in the field of computer vision \cite{gatys2015neuralalgorithmartisticstyle}. This progress has extended to text-style transfer, leading to novel applications in AI-driven text generation, such as Character AI.

Textual style, however, presents a more subjective and nuanced challenge compared to visual styles due to the complex interplay of various linguistic elements \cite{corpus}. Unlike paraphrasing, which focuses on semantic similarity and lexical variation \cite{shen2022evaluationmetricsparaphrasegeneration}, text-style involves additional dimensions such as syntactic structures (e.g., active vs. passive voice, tense) and thematic elements (e.g., emphasis on certain parts of speech such as verbs or adjectives) \cite{lyu2021styleptbcompositionalbenchmarkfinegrained}. These complexities raise challenges in evaluating text-style transfer. Conventional evaluation metrics like BLEU, ROUGE, BERTScore, and perplexity, often based on n-gram overlaps, fail to capture the stylistic nuances of text and can be ineffective in this context. Although human evaluation offers a more accurate assessment, it is typically impractical due to its time-consuming and costly nature.

One of the strengths of large language models (LLMs) is their ability to represent words as high-dimensional vectors that capture semantic relationships more effectively than traditional n-gram-based models \cite{mikolov-etal-2013-linguistic}. While n-gram models treat words as discrete and unrelated units, LLMs utilize continuous embedding spaces, where vectors for semantically related words are closer together. This allows LLMs to better handle the complexity of style beyond simple lexical variations. The linear representation hypothesis suggests that styles in text can be understood as linear transformations within the embedding space \cite{mikolov2013distributedrepresentationswordsphrases}. 

To address the limitations of current evaluation methods, we propose a geometric approach to evaluating text-style by leveraging the vector representations of texts in embedding spaces. By analyzing the transformations within these spaces, we aim to provide a more precise and automated method for assessing stylistic differences in text. This approach offers the potential for more robust and scalable evaluations of text-style transfer, without relying solely on human judgment.

Our findings indicate that this geometric method not only aligns well with human evaluations but also significantly reduces the overhead involved in the evaluation process. The implications of this work are far-reaching, offering potential applications in automated content creation, personalized writing assistants, and AI-driven literary analysis tools.
