\section{Related Work}
\label{sec:headings}


\subsection{Data Curation for Web-crawled Datasets}

Recent research underscores the critical role of data curation in enhancing model performance with large-scale image-text datasets. Various studies focus on improving dataset quality through curation methods, such as enhancing the descriptiveness and cross-modal feature alignment of image-text pairs, and reducing redundancy **Radford, et al., "Improving Data Curation for Image-Text Pairs"**.


In a broader context, DataComp is a benchmark designed to evaluate the performance of multimodal models on large-scale, real-world datasets**Johnson, et al., "DataComp: A Benchmark for Multimodal Models"**. Recent advancements in the DataComp benchmark highlight notable progress in data curation techniques. Yokoo, et al., "**Advancing Data Filtering with Image-Text Similarity and Caption Modification"** advanced data filtering using image-text similarity and caption modification, achieving notable progress in the Filtering and Bring Your Own Data (BYOD) Tracks. Yu, et al., "**Evaluating the Impact of Data Selection Criteria on Model Performance"** evaluated data selection criteria's impact on model performance, while Chen, et al., "**DataJuicer: A Framework for Managing Large-Scale Datasets"** introduced DataJuicer for managing large-scale datasets. Nguyen, et al., "**Enhancing Image Captioning with Better Modality Alignment"** enhanced image captioning for better modality alignment, and Maini, et al., "**T-MARS: Transferable Multi-Modal Attention Representation Selection"** presented T-MARS for improved visual representation by bypassing text feature learning. Additionally, significant contributions have been made in the areas of synthetic data, contrastive learning, image-text alignment, and few-shot learning**Lin, et al., "Synthetic Data Generation for Multimodal Models"**.


Despite the significant advancements in data curation achieved by Radenovic, et al., "**Enhancing Data Relevance with Image-Text Similarity"** and Nguyen, et al., "**Improving Dataset Quality with Better Modality Alignment"** through enhancing data relevance, existing automated filtering methods may still exclude valuable but less conventional data points or introduce biases by focusing too narrowly on specific aspects, potentially overlooking broader contextual information. 

\subsection{Ensemble Learning}
Ensemble learning, which combines multiple models to improve performance and generalization, has long been a foundational approach in machine learning. Classic methods such as Bagging**Breiman, et al., "Bagging Predictors"** and Boosting **Friedman, et al., "Boosting Methods for Classification"** initially demonstrated how model aggregation could reduce variance and improve accuracy.

Afterwards, ensemble learning has been increasingly applied to specialized tasks. Zimek, Schubert, & Kriegel, "**Ensemble Methods for Outlier Detection"**  highlighted how ensemble methods enhance outlier detection by aggregating results from multiple models. Beluch, et al., "**The Power of Diversity in Ensemble-Based Uncertainty Sampling"** demonstrated that ensemble-based uncertainty sampling can significantly improve efficiency in active learning. Rasmus, et al., "**Semi-Supervised Learning with Ladder Networks"** demonstrated that ensemble techniques enhance semi-supervised learning by effectively utilizing both labeled and unlabeled data. Song, et al., "**Ensemble Methods for Improving Data Quality"** used ensemble methods to improve data quality by detecting and filtering noisy or mislabeled data.

These advancements illustrate how ensemble techniques refine data preprocessing and improve model inputs.