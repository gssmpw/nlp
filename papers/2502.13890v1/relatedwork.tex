\section{Prior work}
\label{sec:prior-work}

There is a massive literature that focuses on deriving
the stationary distribution (or a stationary measure)
of Markov chains with countable
(finite or infinite) state spaces.
In reviewing this literature, we focus on results that
either provide a closed-form expression for the stationary measures
or make structural assumptions on the Markov chain,
or both.

\paragraph*{Reversibility, quasi-reversibility, and partial balance}

A long series of works has derived product-form stationary distributions
by focusing on Markov chains
where a stronger form of the balance equations holds,
thus balancing the probability flow between a state and each set
in a partition of its neighbors.
This is often equivalent to
properties of the time-reversed process \cite{serfozo}.
For example, the Kolmogorov criterion \cite[Theorem~2.8]{serfozo}
is a necessary and sufficient condition for reversibility,
which as a by-product yields a closed-form expression for the stationary distribution
as a product of transition rates.
Another example is quasi-reversibility,
as described in \cite[Chapter~3]{kelly}.
Among these works, many have focused on Markov chains
exhibiting a specific transition diagram,
e.g., multi-class queueing systems with arrivals and departures occurring one at a time,
and have identified necessary and sufficient conditions
on the transition rates
that yield a product-form stationary distribution.
This approach has therefore produced many models
applicable to queueing theory and statistical physics.
Reversible models and their variants involving internal routing include
the celebrated Jackson networks \cite{J57},
the zero-range process \cite{A82},
and Whittle networks \cite{serfozo}.
Quasi-reversibility has also given rise to multiple models,
including order-independent queues \cite{BKK95,BK96}
and pass-and-swap queues \cite{CD21}; see \cite{GR20} for a recent survey.
Other examples of queueing models
that satisfy partial balance equations are
token-based order-independent queues \cite{ABDV22}
and certain saturated multiserver-job queues \cite{RM17,GHS23}.



\paragraph*{Graph-based product form}

To the best of our knowledge,
very few papers exploit the structure
of a Markov chain's transition diagram
(rather than its transition \emph{rates})
to guarantee the existence of a product-form stationary distribution.
One example is \cite{F87}, which introduces
\textit{single-input super-state decomposable Markov chains}:
the Markov chain's state space is partitioned into a finite number of sets,
called superstates,
such that all edges into a superset
have the same node as endpoint.
(All finite-state-space Markov chains satisfy this condition
when the partition is formed by singletons.)
Under this assumption, the process of deriving the Markov chain's stationary distribution
can be divided into two steps,
one that solves the stationary distribution
of a Markov chain defined over the superstates,
and another that solves the stationary distribution
of a Markov chain restricted to each superstate.
While the superstate decomposition has a loose resemblance to our cuts,
there is no deeper similarity between the methods.
In particular,
our approach is nontrivial both for finite and infinite Markov chains.
The superstate decomposition approach can be seen as a different approach to deriving product-forms.

Closer to our work,
\cite{GHS23} considers a multiserver-job (MSJ) model
described by a CTMC
and show that it has a product-form stationary distribution
irrespective of the transition rates.
This result is proven in more detail in a technical report \cite{GHS20}.
This example, which inspired the present work,
is discussed in detail in \Cref{sec:msj-example}.



\paragraph*{Symbolic solutions}

Our graph-based product-form method
can also be seen an algorithmic way to discover a particular
type of product-form relationships in Markov chains, giving a clean symbolic solution for the stationary distribution.
If the Markov chains are structured, as in the examples in \Cref{sec:examples}, these relationships can be found explicitly.
However, if algorithm searching is required, we give an algorithmic approach to discover single-source cuts in the underlying graph in \Cref{algo:cut-graph} in $O(|V|^2 |E|)$ time, if the Markov chain has a finite transition graph $G = (V, E)$, allowing us to discover whether a product-form relationship exists.

Prior to our approach, one could symbolically find the stationary distribution for a general symbolic Markov chain in $O(|V|^2)$ time, by symbolically solving the balance equations. However, there is no guarantee that the resulting symbolic expression would be in a simple form.
Simplifying and factorizing the resulting symbolic expression, which might have $O(|V|^2)$ terms,
does not have a known efficient, deterministic algorithm.
In fact, polynomial factorization is a more complicated version of the polynomial identity testing (PIT) problem,
for which no polynomial-time deterministic algorithm is known \cite{A09};
the two problems were recently proven equivalent, in the sense that a deterministic polynomial-time algorithm for one would imply the same for the other \cite{K15}.
Finding such an algorithm has remained a major open problem.



\paragraph*{Other related methods}

Product-form stationary distributions
for DTMCs or CTMCs
have been studied in many different contexts,
such as Stochastic Petri networks,
which sometimes lead to constructive and algebraic methods
that assume particular structure of the transition rates~\cite{D92,B12}.
Orthogonally, the graph structure of a Markov chain
has also been used for other purpose
than deriving a simple closed-form expression
for the stationary distribution.
For instance, the survey \cite{H87} focuses on iterative methods
to approximate the stationary distribution of a finite
Markov chain with transition matrix~$A$
using updates of the form $\pi_{t+1} = \pi_t A$.
The algorithms described in \cite{H87},
called \textit{aggregation-disaggregation methods},
aim at speeding-up iterative methods
by occasionally replacing $\pi_{t+1}$ with $\tilde\pi_{t+1} = S(\pi_{t+1})$,
where $S$ is a function that exploits
structure in the Markov chain's transition diagram.