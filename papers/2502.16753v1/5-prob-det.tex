.pdfIn this section, we formulate two new problems regarding probabilistic detection of sensor attacks: the verification of $\lambda$-sensor-attack detectability and the optimal $\lambda^*$ for $\lambda$-sensor-attack detectability.
We start by formally describing the detection level of a given string and the detection language of an attack strategy. 
Following these descriptions, we define the notion of $\lambda$-sensor-attack detectability.
Next, we formulate two problems over this definition.
Lastly, we compare the definition of $\lambda$-sensor-attack detectability with the definition of $\varepsilon$-safety as in \citep{meira-goes:2020towards,Fahim2024-wodes}.


% \subsection{Overview}
% \rmg{TALK ABOUT MAP - We are doing a hypothesis test check - see reviewers' note. A figure here to explain it.}

% \textcolor{Brown}{In our system, the sensor attacker can disrupt the normal operations of the nominal system $M_n=R/G$, by inserting fictitious events, deleting actual events, or simply allowing events to proceed as normal. This model uses an attacked plant $G_a$ (see Fig.~\ref{fig:plant_Ga}) and an attacked supervisor $R_a$ (see fig.~\ref{fig:supervisor_Ra}) to represent all possible attack scenarios, creating the system $M_a=R_a/G_a$. The attacked plant $G_a$ is a copy of the original plant but includes extra transitions for these three actions: insertions, deletions, and normal transitions. Insertion actions act as self-loops that don’t alter the state, deletion actions occur with the same probability as legitimate events and normal transitions are carried out as they would in the original system. For a detailed explanation of the definitions and construction of the systems please refer to our previous papers \citep{meira-goes:2020towards, Fahim2024-wodes}.}

% \textcolor{Brown}{In our past studies \citep{meira-goes:2020towards, Fahim2024-wodes}, we utilized a single-attack strategy where the supervisor $R$ and the attacker $A$ were combined using parallel composition to form the system $(R||A)$. The attacker could interfere with the supervisor’s observations by either inserting or deleting events, but it had a fixed mode of operation, allowing it to perform only one of these actions throughout the system’s execution, without dynamically switching between them. In other words, the attacker's actions were predefined and consistent throughout the execution. The strategy did not adapt or change based on the state of the system.}

% \textcolor{Brown}{However, in our current study, the attacker can dynamically choose among three actions: insertion, deletion, and normal transitions. Our model introduces a set of strategies \(\{A_1, A_2, \ldots, A_n\}\), allowing the attacker to flexibly switch between different actions. This means the attacker is no longer limited to a single, static strategy but can adapt its actions based on the system's state. This adaptability allows the attacker to be more stealthy and dynamic, choosing in real-time which action—whether inserting, deleting, or allowing normal transitions—would be most effective for evading detection or causing disruption.
% }

% \textcolor{Brown}{In the study \citep{Fahim2024-wodes}, we introduced the concept of an \textit{intrusion detection value} (\textit{int}) to enhance the robustness of our system against sensor deception attacks. The primary goal of \textit{int} is to quantify the system’s ability to distinguish between legitimate and malicious behavior with a high degree of confidence.
% The \textit{intrusion detection value} is defined as:
% \begin{equation}
%     \text{int} := \inf_{s \in L_{det}} \frac{L_p(M_a)(s)}{L_p(M_n)(\Pi_R(s)) + L_p(M_a)(s)},
%     \label{eq:attack_ratio}
% \end{equation}
% Where:
% \begin{itemize}
%     \item $L_p(M_a)(s)$ is the probability that an observed string $s$ is generated by the attacked system ($M_a$).
%     \item $L_p(M_n)(\Pi_R(s))$ is the probability that the same string originates from the nominal system ($M_n$).
% \end{itemize}
% The core idea behind the \textit{int} metric is to provide a rigorous threshold for detecting whether a system has been compromised. Specifically, a system is considered $\epsilon$-safe if the computed intrusion detection value remains above a pre-defined threshold $\epsilon$. For a given string, a higher \textit{int} value indicates that the string is more likely to come from the attacker rather than the nominal system.
% }

% \textcolor{Brown}{Unlike traditional methods that assume a static attack strategy, our approach, termed \textit{``$\lambda$-sensor-deception-attack-detectable,''} extends the concept of \textit{int} to handle dynamic attackers. These attackers can adapt their strategies in real-time, making detection more challenging. To account for this increased complexity, we define a refined version of the intrusion detection value as:
% \begin{equation}
%     \text{dtc} := \inf_{\text{attackers}} \inf_{s \in L_{det}} \frac{L_p(M_a)(s)}{L_p(M_n)(\Pi_R(s)) + L_p(M_a)(s)}.
%     \label{eq:attack_ratio_sdad}
% \end{equation}}

% \textcolor{Brown}{This formulation introduces a double infimum, ensuring that the system remains resilient even against the most adaptive and stealthy attackers. By considering the worst-case scenario among all potential attack strategies, the system guarantees safety, with $\lambda$ representing the minimum threshold required to confidently detect diverse attack strategies.}

% \textcolor{Brown}{In essence, the new \textit{dtc} metric not only measures the likelihood of detecting an attack but also provides a robust framework for assessing system safety in environments where attackers can dynamically alter their behavior. This adaptability ensures that our system can maintain its integrity even in the presence of highly sophisticated adversaries.}


% Intuitively, the definition of $\lambda$-sensor-deception-attack-detectable, $\lambda$-sdad for short,  compares the probability of executing strings in a nominal system versus a possible set of attacked systems.
% Using the probabilistic information, $\lambda$-sdad informs when strings with the same projection, called \emph{ambiguous strings}, are more likely to have been executed by the attacked system than the nominal system.
% % We use an example to concretely demonstrate the definition of $\epsilon$-safety.

% \begin{example}
% \textcolor{Brown}{In our running example, we have constructed the nominal system $M_n$ in Fig~\ref{Mn} and provided a partial view of the attacked system $M_a$ in Fig.~\ref{fig:M_a}.
% % We investigate if it is possible to detect and prevent the attacker from reaching the critical state $0$ in $M_a$.
% The string $ab_{ins}a$ reaches the critical state in $M_a$.
% Since we want to prevent the system before reaching the critical state, we need to detect the attacker with a prefix of strings that reach the critical states, e.g., string $s = ab_{ins}a$.
% We denote strings such as $s$ as \emph{detection strings}.
% These strings represent the latest time for the ID module to identify the attacker and prevent it by disabling controllable events.}

% \textcolor{Brown}{If string $s$ is executed, the ID observes the projected string $\Pi_R(s) = ab_{ins}$.
% The detection mechanism must decide after observing $\Pi_R(s)$ if it originates from the nominal system $M_n$ or the attacked system $M_a$.
% Note that $\Pi_R(s)$ belongs to the $\lang(M_n)$; thus, traditional ID systems cannot detect the attacker \citep{Carvalho:2018,Lima:2019}.
% In $\epsilon$-safety, we compare the probability of executing $s$ in $M_a$ with the probability of executing $\Pi_R(s)$ in $M_n$.}
% % In other words, when the detection module observes $\Pi_R(s)$, $\epsilon$-safety checks if it is more likely to have been generated by $M_a$ than $M_n$. }
% \end{example}
% %\vspace{-1em}
% %\begin{figure}[thpb]
% %\centering
% %\includegraphics[width=0.55\columnwidth]{det-lang.pdf}
% %\caption{Detection language diagram}
% %\label{fig:detection_language}
% %\end{figure}


% % \begin{figure*}[thpb]
% % \centering
% % \begin{subfigure}[b]{0.75\textwidth}
% %     \includegraphics[width=\textwidth]{Figs/15.png}
% %     \caption{Attacked system $M_a$ with transitions leading to unsafe state.}
% %     \label{fig:M_a}
% % \end{subfigure}
% % \hfill
% % \begin{subfigure}[b]{0.75\textwidth}
% %     \includegraphics[width=\textwidth]{Figs/16.png} % Replace with the second image path
% %     \caption{Attacked system $M_a$ where the attacker uses memory.}
% %     \label{fig:M_a_alt}
% % \end{subfigure}
% % \caption{Comparison of the attacked system $M_a$ with and without attacker memory. (a) Shows the primary path to the unsafe state. (b) The attacker employs memory, resulting in an alternate path to the unsafe state.}
% % \label{fig:attack-str}
% % \end{figure*}


\subsection{Detection Value}

The attack detection problem is to determine if an observed behavior $s\in \lang(G)$ is generated by the nominal system $S/G$ or by an attacked system $S_A/G$.
Usually, a detection problem is described as a hypothesis-testing problem \citep{poor2013introduction}.
In our case, the null hypothesis $H_0$ is defined by the nominal system $S/G$ whereas the alternative hypothesis $H_1$ is described by an attack system $S_A/G$.

To identify from which system an observation is generated, we compare the two systems using their probabilistic language.  
Inspired by the \emph{maximum a posterior probability}, we calculate the likelihood of string $s\in \lang(G)$ by directly comparing the probability between $L_p(S/G)$ and $L_p(S_A/G)$. 
We define the \emph{detection level} of a string.

\begin{definition}[Detection level]
Let $s\in \lang(S_A/G)$, the detection level of $s$ with respect to $G$, $S$, and $A$ is:
\begin{equation}\label{eq:detection_level}
det(s) = 
\frac{L_p(S_A/G)\bigl(s \bigr)}{L_p(S_A/G)\bigl(s \bigr)+L_p(S/G)\bigl(\Pi^S(A(s))\bigr)}
\end{equation}
\end{definition}

Intuitively, $det(s)$ informs a ``detection value" of the attack strategy generating string $s\in S_A/G$.
It characterizes the likelihood of $s$ being generated by $S_A/G$ compared to $\Pi^S(A(s))$ being generated in $S/G$.
% In the numerator, we sum the probabilities of generating string $s$ in $S_A/G$, $L_p(S_A/G)(s)$, with the probability of generating string $\Pi^S(A(s))$ in $S/G$, $L_p(S/G)(\Pi^S(A(s)))$.
To generate $s \in \lang(S_A/G)$, the attack strategy feeds the supervisor with observation $\Pi^S(A(s))$.
For this reason, we compare the probabilities of generating $s$ in $S_A/G$ versus $\Pi^S(A(s))$ in $S/G$.
% In other words, the detector will observe string $\Pi^S(A(s))$ and it has to decide if it was a legitimate string from $S/G$ or if $s$ was generated by attack system $S_A/G$.


Note that if $\Pi^S(A(s))\notin \lang(S/G)$, then the value of $det(s) = 1$, i.e., the attack strategy reveals the attacker when generating $s\in\lang(S_A/G)$.
These are the \emph{only} types of attacks that logical detection systems can detect, e.g., \citep{Carvalho:2018, Lima:2019, lin2024diagnosability}.
On the other hand, the detection value is still useful when $\Pi^S(A(s))\in \lang(S/G)$.
For instance, if the attack strategy $A$ modifies the closed-loop system such that $L_p(S_A/G)(s)>L_p(S/G)(\Pi^S(A(s))$, then $det(s)>0.5$, i.e., it is more likely that the observation is coming from an attacked system instead the nominal.

\begin{example}
Let us characterize the detection value for a string in our running example with attack strategy $A_1$.
We select string $s = ca\in \lang(S_{A_1}/G)$ that has probability $L_p(S_{A_1}/G)(ca) = 0.8\times 0.1 = 0.08$ as shown in Fig.~\ref{fig:SA1/G}.
Attack strategy $A_1$ modifies $s$ to $A_1(s) = cains(b)$ as described by Fig.~\ref{fig:A1}.
The supervisor observes string $\Pi^S(cains(b)) = cab$ that has probability $L_p(S/G)(cab) = 0.8\times 0.1 \times 0.111\dots = 0.0088\cdots$.
The detection value computes the likelihood of generating string $ca$ in $S_{A_1}/G$ versus $cab$ in $S/G$.
In this case, the detection value is $det(ca) = 0.9$.
After observing $cab$, it is $90\%$ more likely that $ca$ was executed in $S_{A_1}/G$ compared to $cab$ being executed in $S/G$.
\end{example}



% Based on this discussion, we define the detection language $L^A_{det}\subseteq \lang(S_A/G)$ as the strings in which the detector must make a decision otherwise it is too late. 
% Recall that we assume that $x_{crit}$ is only reached via controllable events, i.e., $x \in X_Q$ such that $\delta_G(x,e) = x_{crit}$ implies $e\in \Sigma_c$.
% First, we define the \emph{critical language of $A$} by the strings in $\lang(S_A/G)$ that reach the critical state.
% \begin{equation}
% L_{crit}^A = \{s\in \lang(S_A/G)\mid \delta_G(x_{0,G},s) = x_{crit}\}
% \end{equation}
% As mentioned above, it is too late to detect the attack with strings in $L_{crit}^A$, i.e., the critical state has been reached.

% % First, we define $X_{det} = \{x\in X_G\setminus\{x_{crit}\}\mid \exists e\in \Sigma_c.\ \delta_G(x,e) = x_{crit}\}$. 
% % These states define 

\subsection{Detection Language}
Although the detection value is defined for every string in $s\in \lang(S_A/G)$, only some can drive the controlled system to a critical state. 
Recall that an attack strategy is only successful if it generates a string that reaches the critical state $x_{crit}$.
Therefore, these ``successful" strings must be detected by the attack detector.
On top of detecting these strings, the attack detection must identify the attack \emph{before} the system reaches a critical state. 
In other words, we can only mitigate attacks if the attack detection detects them before it is too late, i.e., before the critical state is reached.

Based on this discussion, we define the detection language $L^A_{det}\subseteq \lang(S_A/G)$ as the strings in which the detector must make a decision otherwise it is too late. 
Recall that we assume that $x_{crit}$ is only reached via controllable events, i.e., $x \in X_G$ such that $\delta_G(x,e) = x_{crit}$ implies $e\in \Sigma_c$.
First, we define the \emph{critical language of $A$} by the strings in $\lang(S_A/G)$ that reach the critical state.
\begin{equation}
L_{crit}^A = \{s\in \lang(S_A/G)\mid \delta_G(x_{0,G},s) = x_{crit}\}
\end{equation}
As mentioned above, it is too late to detect the attack with strings in $L_{crit}^A$, i.e., the critical state has been reached.
% Based on this discussion, we define the detection language $L_{det}^A\subseteq \lang(S_A/G)$ of attack strategy $A$. 
Given plant $G$, supervisor $S$, and attack strategy $A$, we define the detection language as 
\begin{equation}\label{eq:det_lang}
L_{det}^A = \{s\in \lang(S_A/G)\mid (\exists e\in \Sigma_c.\ se\in L_{crit}^A)\wedge (\forall \sigma\in \Sigma_c,\ i<|s|.\ s^i\sigma \notin L_{crit}^A)\}
\end{equation}

A string $s$ in $L^A_{det}$ can reach the critical state with a controllable event.
Moreover, no prefix of $s$ can reach the critical state with any controllable event.
In other words, string $s$ is the shortest string to be one controllable event away from a critical state. 

\begin{example}
Let us return to our running example with attack strategy $A_1$ to investigate its detection language.
The detection language is given by $L_{det}^{A_1} = \{a, ca, cca, \dots\}$.
Let $s = a$, then $A(s) = a ins(b)$, i.e., the attack inserts event $b$ immediately after $a$ occurs. 
This insertion makes the supervisor return to state $2$ while the plant remains in state $1$ as in Figs.~\ref{fig:plant_G} and \ref{fig:sup_R}.
Since the supervisor enables event $a$ in state $2$, if the plant executes $a$, then the critical state $0$ is reached.
Therefore, the detection system must decide after observing $\Pi^S(a ins(b)) = ab$ if it should disable event $a$.
Note that since observation $ab$ belongs to $\lang(S/G)$, it cannot be detected by logical detectors.
\end{example}


% To formally define $\epsilon$-safety, we define the detection language $L_{det}\subseteq \lang(M_a)$, i.e., strings in which the ID must decide.
% Figure~\ref{fig:detection_language} provides intuition behind the detection language.
% The unsafe region includes states in $M_a$ that can uncontrollably reach the critical state.
% In other words, these are states where it can be too late to prevent the attacker.
% \begin{align}
% Uns := &\{x \in X_{M_a}\mid \exists s\in \Sigma_m^*\text{ s.t. } \nonumber \\& (\delta_{M_a}(x,s)\in X_{crit,a})\wedge(\Pi_G(s)\in \Sigma_{uc}^*)\label{eq:unsafe-region}\}
% \end{align}
% In the attacked system $M_a$ in Fig.~\ref{fig:M_a}, the set of unsafe states only contains the critical state, $Uns = \{0\}$.
% Detection states can reach the unsafe region $Uns$ with one controllable transition.
% For example, state $1'$ in $M_a$, Fig~\ref{fig:M_a}, is a detection state since it can reach state $0$ via controllable event $m_{ego}$.
% Detection states are the last states where the ID can prevent the attacker from reaching the critical state.
% \begin{align}
% X_{det} := &\{x \in X_{M_a}\setminus Uns\mid \exists e\in (\Sigma_d\cap\Sigma)\text{ s.t. } \nonumber \\& (\delta_{M_a}(x,e)\in Uns) \wedge(\Pi_G(e)\in \Sigma_c)\label{eq:detection-state}\}
% \end{align}

% Finally, the detection language includes the shortest ambiguous strings that reach detection states:
% \begin{align}
% L_{det} := &\{s = e_0\dots e_n \in \lang(M_a)\mid (\Pi_R(s)\in \lang(M_n))\wedge\nonumber\\&(\delta_{M_a}(x_{0,M_a},s)\in X_{det})\wedge\nonumber\\&(\delta_{M_a}(x_{0,M_a},e_0\dots e_i)\notin X_{det},\ i<|s|)\}\label{eq:det-lang}
% \end{align}
% The three conditions in Eq.~\ref{eq:det-lang} specify in order: (1) ambiguous strings; (2) detection state reached; and (3) shortest strings.
% The detection language enforces when the detector must make a decision even though $L_{det}$ contains ambiguous strings.
% This language violates the GF-safe diagnosability as in \citep{Carvalho:2018} because $L_{det}$ only contains ambiguous strings whereas GF-safe diagnosability searches to disambiguate attack strings against nominal behavior.
% The detection language $L_{det}$ for $M_a$ in Fig.~\ref{fig:M_a} is defined by the marked language in the DFA shown in Fig.~\ref{fig:verifier} where a marked state is depicted by the black state edge in Fig.~\ref{fig:verifier}.
% We show how to construct this DFA in Sect.~\ref{sect:solution}.


\subsection{Probabilistic Sensor Detectability}
Based on the definitions of detection value, $det(s)$, and detection language, $L_{det}^A$, we define $\lambda$-sa detectability as follows:
% \begin{figure*}[thpb]
% \centering
% \includegraphics[width=0.6\textwidth]{overview-alg.pdf}
% \caption{Overview of our approach to verify $\epsilon$-safety. 
% }
% \label{fig:overview_solution}
% \end{figure*}

\begin{definition}[$\lambda$-sa detectable]\label{def:lambda-sa-det}
Given plant $G$, supervisor $S$, a set of compromised events $\Sigma_a\subseteq \Sigma$, and value $\lambda \in (0.5,1]$, the controlled system is \emph{$\lambda$-sensor-attack detectable}, or simply $\lambda$-sa, if
% Given a nominal controlled system $M_n$, a set of possibly compromised sensors $E_a\subseteq E_o$, a set of sensor attacker strategies $Att$, and $\lambda\in [0.5,1]$, the nominal system $M_n$ is \emph{$\lambda$-sensor-attack}, $\lambda$-sa detectable with respect to $E_a$, $Att$, and $\lambda$ if
\begin{equation}
dtc:=\inf_{A\in \Psi_A}\ \inf_{s\in L^A_{det}} det(s)\geq \lambda\label{eq:likelihood}
\end{equation}
\end{definition}

Intuitively, the controlled system is $\lambda$-sa if \emph{every} complete, consistent, and successful attack strategy significantly modifies the probability of the nominal controlled system.
The parameter $\lambda$ gives the confidence level of detection strings being more likely to be generated by the attacked systems.
For example, $0.9$-sa detectable means that detection strings for all attack strategies are at least $90\%$ more likely to have been generated in $S_A/G$ compared to their observation in $S/G$.

% Equation~\ref{eq:likelihood} computes the probability of executing a string in $M_a$ divided by the total probability of executing this string in $M_n$ and $M_a$.
% The $\epsilon$ parameter must be above $0.5$ since it provides the confidence of strings being more likely to be generated by the attacked systems.
% For string $s = m_{ego}ins(m_{adv})$ in Fig.~\ref{fig:M_a}, we have that $L_p(M_a)(s) = 0.1$.
% Similarly, we use $M_n$ to compute $L_p(M_n)(\Pi_R(s)) = L_p(M_n)(m_{ego}m_{adv}) = 0.011\dots$.
% Computing the ratio in Eq.~\ref{eq:likelihood}, we have $0.1/0.111\dots = 0.9$.
% When observing $\Pi_R(s)$, it is $90\%$ more likely for $s$ to be executed by $M_a$ than by $M_n$.

% \subsection{Verification and Synthesis problems}

Based on the definition of $\lambda$-sa detectability, we formulate two problems.
First, we define a verification problem to check if a controlled system is $\lambda$-sa detectable.

\begin{problem}[Verification of $\lambda$-sa]\label{prob:ver-lsa}
Given plant $G$, supervisor $R$, a set of compromised events $\Sigma_a\subseteq \Sigma$, and $\lambda \in (0.5,1]$, verify if the controlled system is $\lambda$-sa detectable
\[dtc \geq\lambda\]
\end{problem} 

Problem~\ref{prob:ver-lsa} verifies if the controlled system is $\lambda$-sa detectable for a given $\lambda$ value.
A natural question to ask is if there exists a maximum $\lambda$ value such that the controlled system is $\lambda$-sa detectable.
Formally, the problem is posed as follows.
\begin{problem}[Maximum $\lambda$-sa]\label{prob:optimal-lsa}
Given plant $G$, supervisor $R$, and set of compromised events $\Sigma_a\subseteq \Sigma$, find, if it exists, the maximum $\lambda^*$ such that the controlled system is $\lambda^*$-sa: 
$$\lambda^* := \sup\ \{\lambda\in (0.5,1] \mid S/G \text{ is } \lambda\text{-sa detectable}\}$$
\end{problem}

\begin{remark}
In  \citep{meira-goes:2020towards,Fahim2024-wodes}, the problem of $\varepsilon$-safety is defined.
The main difference between $\varepsilon$-safety and $\lambda$-sa detectability is the $\inf_{A\in \Psi_A}$ in Eq.~\ref{eq:detection_level}.
The $\varepsilon$-safety definition only considers \emph{one} attack strategy whereas $\lambda$-sa considers all possible complete, consistent, and successful attack strategies.
The $\lambda$-sa detectability reduces to $\varepsilon$-safety when $|\Psi_A| = 1$, i.e., a single attack strategy.
\end{remark}
% Problem~\ref{prob:verification_eps_safe} simply verifies if a given nominal system is $\epsilon$-safe with respect to a given attacked system.
% On the other hand, Problem~\ref{prob:optimal_eps_safe} searches for the largest $\epsilon^*$ such that $M_n$ is $\epsilon^*$-safe for a given attacked system.
% We addressed the error in \citep{meira-goes:2020towards} by using the $\max$ function.

