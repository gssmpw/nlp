\section{\att{} Architecture}

Figure~\ref{fig:Architecture_Top} presents the \att{} architecture, where a CXL switch interconnects 32 CXL devices, driven by a host CPU. 
Each CXL device integrates a CXL controller, PNM units, and 16 memory chips, each equipped with two GDDR6-PIM channels (hereafter referred to as PIM channels).
We introduce a CXL-based network architecture, a hierarchical PIM-PNM design and the \att{} ISA in this section.


\begin{figure}[h]
% \vspace{-4mm}
	\centering
  	\includegraphics[width=7.5cm]{Figure/Architecture_Top.pdf}
    \caption{CENT Architecture.}
	\label{fig:Architecture_Top}
% \vspace{-6mm}
\end{figure}

% \begin{figure*}[hb!]
%     \centering
%     \includegraphics[width=0.9\textwidth]{Figure/Architecture_CXL_new.pdf}
%     \caption{CXL Network Architecture.}
%     \label{fig:Architecture_CXL}
% \end{figure*}

\subsection{CXL-based Network Architecture}
\label{sub:CXL-Network}

\att{} integrates the CXL 3.0 protocol, using the PCIe 6.0 physical interface. The CXL switch is connected to the host machine with \texttt{x16} lanes, whereas each CXL device is connected to the switch through \texttt{x4} lanes.
The switch supports the communication between the host and CXL devices, and peer-to-peer communication between CXL devices. 

\textbf{Inter-Device Communication.} 
Figure~\ref{fig:CXL_device} shows the architecture of a CXL device. Communication between CXL devices involves the \rf{} and is orchestrated by the inter-device communication controller in conjunction with the CXL port.
We introduce a \textit{broadcast} primitive, allowing one CXL device to write data to multiple devices through a single request. The standard CXL.mem protocol lacks this support. We implement it by using one of the reserved header codes within the Header slot (H-slot) of the Port Based Routing (PBR) flit. 
The H-slot is decoded by the switch for routing.
Upon identifying a flit encoded with this reserved H-slot code, the switch interprets it as a broadcast request and forwards the flit to designated CXL devices. We also modified the CXL port to (1) incorporate a device ID mask within the header slot of the broadcast message, and (2) expect write acknowledgements from all destination devices.

\begin{figure}[h]
    \centering
    % \includegraphics[width=8cm]{Figure/CXL_device.pdf}
    \includegraphics[width=\columnwidth]{Figure/CXL_device.pdf}
    \caption{CXL Device Architecture.}
    \label{fig:CXL_device}
\end{figure}

Inter-device communication is supported by \texttt{SEND\_CXL}, \texttt{RECV\_CXL} and \texttt{BCAST\_CXL} instructions. The non-blocking
\texttt{SEND\_CXL} specifies the device ID (\texttt{DVid}) and the \rf{} address in source and destination devices. Conversely, \texttt{RECV\_CXL} operates in a blocking manner and does \textit{not} specify a device ID. A pair of send and receive instructions constitutes a CXL write transaction. 
\texttt{BCAST\_CXL} is also non-blocking and uses an 8-bit \texttt{DVcount} parameter to specify the number of subsequent CXL devices to which the data is broadcast.
The \textit{multicast} primitive is supported in a similar manner.
To accomplish \textit{gather}, the receiving device executes multiple \texttt{CXL\_RECV} instructions, while each sender executes one \texttt{SEND\_CXL} instruction. Note that the receive instruction omits any device ID specification, thereby rendering the order of incoming CXL flits inconsequential. 


\textbf{CXL Port} is depicted in Figure~\ref{fig:CXL_port}. 
CXL nodes are classified into three categories: Host (H), representing the host machine; Local (L), the CXL device we are considering; and Remote (R), referring to other CXL devices interconnected via the switch. CXL port is equipped with virtual channels. Requests from the host and remote nodes are unpacked onto the Rx H2L and R2L queues, and responses to the host and remote nodes are allocated to the Tx L2H and L2R queues.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.40\textwidth]{Figure/CXL_port.pdf}
    \caption{CXL Port Architecture.}
    \label{fig:CXL_port}
\end{figure}

Transactions comprise a request and a response. On the transmit (Tx) datapath, the CXL port packs requests into flits, which are unpacked on the receive (Rx) datapath by the destination device.
% it deconstructs each flit back into the individual requests and responses. 
The CXL port supports 2 types of transactions: read transactions, initiated with a \textit{Request} (Req) and concluded with \textit{Data with Response} (DRS); and write transactions that begin with a \textit{Request with Data} (RWD) and finish with \textit{No Data Response} (NDR) acknowledgment. 


\vspace{-3mm}

\subsection{Hierarchical PIM-PNM Architecture}~\label{subsec:pim_pnm_arch}

In Figure~\ref{fig:CXL_device}, \att{} instructions are transmitted from the host to a 2MB instruction buffer in each device. These instructions are further distributed to PIM channels and PNM units.
Standard read/write transactions are dispatched to PIM controllers similar to non-PIM memory modules. \att{} arithmetic instructions are decoded into micro-ops and subsequently directed to PIM controllers and PNM units. 
% \att{} ISA will be further elaborated in Section~\ref{ISA_Summary}. 

\begin{figure*}[htbp]
% \vspace{-4mm}
	\centering
  	\includegraphics[width=0.9\textwidth]{Figure/Architecture_PIM_PNM_new.pdf}
    \caption{Hierarchical PIM-PNM Architecture}
	\label{fig:Architecture_PIM_PNM}
% \vspace{-6mm}
\end{figure*}

\textbf{GDDR6-PIM Channel.}
The CXL device integrates 16 PIM controllers, each managing two PIM channels. These controllers receive micro-ops from the decoder and convert them into DRAM commands.
Figure~\ref{fig:Architecture_PIM_PNM}(a) shows that the PIM channel consists of a \texttt{2KB} Global Buffer shared by four bank groups.
The bank group contains four banks.
Each bank has a 32MB memory capacity coupled with a near-bank PU.
% 
% The CXL device integrates 16 PIM controllers, each managing two PIM channels. These controllers receive micro-ops from the decoder and convert them into DRAM commands.
% Figure~\ref{fig:Architecture_PIM_PNM}(a) shows that a PIM channel consists of four bank groups, with each group consisting of four banks. Every bank possesses a memory capacity of 32MB and is coupled with a near-bank PU. Furthermore, a \texttt{2KB} Global Buffer is interconnected with 16 PUs within the channel.

Within the PU is a 16 MAC reduction tree, operating on Bfloat16 (\texttt{BF16}) data elements. Each multiplier receives 16-bit data directly from its associated local bank, in addition to another 16-bit data from either the Global Buffer or its neighboring bank (such as Bank $0$ and Bank $1$). 
The Global Buffer is capable of broadcasting 256-bit data to all PUs concurrently. 32 accumulation registers are incorporated to hold the MAC results in the PU and are designated by the \att{} ISA. The activation function (AF) leverages lookup tables stored within the DRAM bank and linear interpolation. 

The PU operates at 1GHz, equivalent to $t_{CCDS}$ ($2t_{CK}$) of the PIM bank, yielding a compute throughput of 32 GFLOPS.
PIM channels are optimized to allow 16 near-bank PUs to operate in parallel. To facilitate this, the PIM controller issues an activate-all-banks \texttt{ACTab} command, followed by PIM commands such as \texttt{MACab} and concludes with a precharge-all-banks \texttt{PREab} command. The \texttt{ACTab} command is enabled by the reservoir capacitors introduced in AiM~\cite{aim1, aim2}, and \texttt{PREab} is already supported by the GDDR6 DRAM~\cite{samsung-8gb-gddr6}.


% \subsection{Accelerators and RISC-V cores}
\textbf{PNM Units.}
While near-bank PUs could efficiently support MAC operations, LLMs necessitate a broader set of operations beyond MACs. 
To address this, the CXL device incorporates the following PNM units, as shown in Figure~\ref{fig:Architecture_PIM_PNM}(b):
(1) \textit{32 Accumulators}: each retrieves two values from the \rf{} as inputs and segments the 256-bit inputs into 16 groups for \texttt{BF16} accumulations.
(2) \textit{32 Reduction Trees}: each fetches a single 256-bit value from the \rf{}, reducing 16 \texttt{BF16} input elements to a single \texttt{BF16} value. The result is stored into the first 16-bit element in a 256-bit \rf{} slot.
(3) \textit{32 Exponent Accelerators}, each accesses a 256-bit value from the \rf{}, dividing it into 16 lanes. In each lane, the exponent of a \texttt{BF16} input element is calculated by a 10-order Taylor Series approximation.
(4) \textit{8 BOOM-2wide RISC-V cores}~\cite{BOOM}, facilitating the execution of less common operations (such as square root and inversion), and accommodating future improvements in LLMs. Each RISC-V core is equipped with a \texttt{64KB} instruction buffer, which is initialized by the host through CXL write transactions.

\textbf{Intra-Device Communication} between PIM channels and PNM units is enabled through \att{} data movement instructions and a \texttt{64KB} \rf{}.
The \rf{} is viewed by PIM channels as 256-bit registers. 
\att{} facilitates data transfers between DRAM banks and the \rf{} by \texttt{WR\_SBK} and \texttt{RD\_SBK} instructions. These transfers are conducted by the load/store unit associated with each memory controller. Additionally, \texttt{WR\_ABK} instruction segments a 256-bit register into 16 discrete \texttt{BF16} values and concurrently stores them in the same row and column address of all 16 banks within a channel. Communication among banks in a PIM channel is mediated by the Global Buffer through \texttt{COPY\_BKGB} and \texttt{COPY\_GBBK} instructions. Similar to PIM channels, PNM units interface with the \rf{} at a 256-bit granularity and abstract it as a register file. The RISC-V core views the \rf{} as a byte-addressable memory and interacts with it through 16-bit loads and stores in a designated \texttt{64KB} region of the memory space.


\subsection{ISA Summary} \label{ISA_Summary}

Table~\ref{tab:ISA_ARITHMETIC} shows \att{} arithmetic instructions. The \texttt{CHmask} parameter directs the PIM decoder to broadcast micro-ops to specified PIM channels.
PIM decoder generates \texttt{OPsize} micro-ops from a single instruction, targeting subsequent \rf{} slots and DRAM column addresses.
The \texttt{Regid} parameter identifies the specific accumulation register within the PU, while \texttt{AFid} determines the type of non-linear activation function.
The \texttt{RISCV} instruction is designed to initiate the execution of RISC-V cores at the specific start program counter (PC) address.

\begin{table}[h]
    \footnotesize
    \centering
    \caption{\att{} Arithmetic Instructions}
    \label{tab:ISA_ARITHMETIC}
    \begin{tabular}{|c||c|}
        \hline
        \textbf{Instruction} & \textbf{Assembly} \\
        \hline
        \hline
        \multicolumn{2}{|c|}{\textbf{Near-Bank PUs}} \\
        \hline
        MAC All Bank & \texttt{MAC\_ABK CHmask OPsize RO CO Regid} \\
        \hline
        Element-wise Mult. & \texttt{EW\_MUL CHmask OPsize RO CO} \\
        \hline
        Activation Function & \texttt{AF CHmask AFid Regid} \\
        \hline
        \hline
        \multicolumn{2}{|c|}{\textbf{PNM Units}} \\
        \hline
        Exponent & \texttt{EXP OPsize Rd Rs} \\
        \hline
        Reduction & \texttt{RED OPsize Rd Rs} \\
        \hline
        Accumulation & \texttt{ACC OPsize Rd Rs} \\
        \hline
        RISCV operation & \texttt{RISCV OPsize PC Rd Rs} \\
        \hline
    \end{tabular}
\end{table}

% \begin{table}[h]
%     \footnotesize
%     \centering
%     \caption{\att{} Arithmetic Instructions}
%     \label{tab:ISA_ARITHMETIC}
%     \begin{tabular}{|c|c|}
%         \hline
%         \textbf{Detail} & \textbf{Assembly} \\
%         \hline
%         \multirow{3}{*}{Near-Bank PUs} & \texttt{MAC\_ABK CHmask OPsize RO CO Regid} \\
%         \cline{2-2} 
%         & \texttt{EW\_MUL CHmask OPsize RO CO} \\
%         \cline{2-2} 
%         & \texttt{AF CHmask AFid Regid} \\
%         \hline
%         \multirow{4}{*}{PNM Units} & \texttt{EXP OPsize Rd Rs} \\
%         \cline{2-2}
%         & \texttt{RED OPsize Rd Rs} \\
%         \cline{2-2}
%         & \texttt{ACC OPsize Rd Rs} \\
%         \cline{2-2}
%         & \texttt{RISCV OPsize PC Rd Rs} \\
%         \hline
%     \end{tabular}
% \end{table}

Table~\ref{tab:ISA_MOVE} summarizes \att{} data movement instructions,
specifying DRAM bank locations using channel (\texttt{CHid}), bank (\texttt{BK}), row (\texttt{RO}), and column (\texttt{CO}).
The source and destination \rf{} addresses are specified by \texttt{Rd} and \texttt{Rs}.

\begin{table}[h]
    \footnotesize
    \centering
    \caption{\att{} Data Movement Instructions}
    \label{tab:ISA_MOVE}    
    \begin{tabular}{|c||c|}
        \hline
        \textbf{Instruction} & \textbf{Assembly} \\
        \hline
        \hline
        \multicolumn{2}{|c|}{\textbf{CXL Device $\leftrightarrow$ CXL Device}} \\
        \hline
        Send & \texttt{SEND\_CXL DVid Rs Rd} \\
        \hline
        Receive & \texttt{RECV\_CXL} \\
        \hline
        Broadcast & \texttt{BCAST\_CXL DVcount Rs Rd} \\
        \hline
        \multicolumn{2}{|c|}{\textbf{\rf{} $\leftrightarrow$ DRAM Banks}} \\
        \hline
        Write Single Bank & \texttt{WR\_SBK CHid OPsize BK RO CO Rs} \\
        \hline
        Read Single Bank & \texttt{RD\_SBK CHid OPsize BK RO CO Rd} \\
        \hline
        Write All Banks & \texttt{WR\_ABK CHid RO CO Rs Regid} \\
        \hline
        \multicolumn{2}{|c|}{\textbf{Global Buffer $\leftrightarrow$ DRAM Banks}} \\
        \hline
        Copy Bank $\rightarrow$ Global Buffer & \texttt{COPY\_BKGB CHmask OPsize RO CO} \\
        \hline
        Copy Global Buffer $\rightarrow$ Bank & \texttt{COPY\_GBBK CHmask OPsize RO CO} \\
        \hline
        \multicolumn{2}{|c|}{\textbf{\rf{} $\leftrightarrow$ PUs}} \\
        \hline
        Write bias & \texttt{WR\_BIAS CHmask Rs} \\
        \hline
        Read MAC register & \texttt{RD\_MAC CHmask Rd Regid} \\
        \hline
        \multicolumn{2}{|c|}{\textbf{\rf{} $\rightarrow$ Global Buffer}} \\
        \hline
        Write Global Buffer & \texttt{WR\_GB CHmask OPsize CO Rs} \\
        \hline
    \end{tabular}
\end{table}


% \begin{table}[h]
%     \footnotesize
%     \centering
%     \caption{\att{} Data Movement Instructions}
%     \label{tab:ISA_MOVE}    
%     \begin{tabular}{|c|c|}
%         \hline
%         \textbf{Detail} & \textbf{Assembly} \\
%         \hline
%         \multirow{3}{*}{CXL Device $\leftrightarrow$ CXL Device} 
%         & \texttt{SEND\_CXL DVid Rs Rd} \\
%         \cline{2-2} 
%         & \texttt{RECV\_CXL} \\
%         \cline{2-2}
%         & \texttt{BCAST\_CXL DVcount Rs Rd} \\
%         \hline
%         \multirow{3}{*}{\rf{} $\leftrightarrow$ DRAM Banks} & \texttt{WR\_SBK CHid OPsize BK RO CO Rs} \\
%         \cline{2-2}
%         & \texttt{RD\_SBK CHid OPsize BK RO CO Rd} \\
%         \cline{2-2}
%         & \texttt{WR\_ABK CHid RO CO Rs Regid} \\
%         \hline
%         \multirow{2}{*}{Global Buffer $\leftrightarrow$ DRAM Banks} & \texttt{COPY\_BKGB CHmask OPsize RO CO} \\
%         \cline{2-2}
%         & \texttt{COPY\_GBBK CHmask OPsize RO CO} \\
%         \hline
%         \multirow{2}{*}{\rf{} $\leftrightarrow$ PUs} & \texttt{WR\_BIAS CHmask Rs} \\
%         \cline{2-2}
%         & \texttt{RD\_MAC CHmask Rd Regid} \\
%         \hline
%         \rf{} $\rightarrow$ Global Buffer & \texttt{WR\_GB CHmask OPsize CO Rs} \\
%         \hline
%     \end{tabular}
% \end{table}



