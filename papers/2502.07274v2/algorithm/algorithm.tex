\vspace{-0.2in}
\begin{algorithm}[H] %T
%\ContinuedFloat
\caption{Weight-space consolidation for cost-efficient CL}
\label{alg:ours}\footnotesize
\textbf{Input:} Model parameters $\theta$, training data $D_{1:t}$, memory buffer $\mathcal{M}$, average interval $j$, warming epoch $n_{\mathrm{warm}}$%, mixing weight $\alpha$;
%Model $F$ and its parameter $\theta$, training data $D_{1:t}$, memory buffer $\mathcal{M}$, average interval $j$, warming epoch $n_{\mathrm{warm}}$%, mixing weight $\alpha$;

\textbf{Output:} Trained model parameters $\theta$
% \medskip

\For{$t \gets 1$ \textbf{to} $T$}{
  $\Theta \leftarrow \theta$ \tcp{Init. Averaged Model}
  \If{$t > 1$}{
    $\theta_{\mathrm{prev}} \gets \theta$ %\tcp{Step 0}
  }
  %\BlankLine

  \For{$i=1 : n_{\mathrm{iter}}$}{
    %Sample Minibatch $\mathcal{B} = \{(x^t_i,y^t_i), \cdots\}$ from $\{D_t \cup\ \mathcal{M}_{1:t-1}\}$
    Sample minibatch from $\{D_t \cup\ \mathcal{M}_{1:t-1}\}$
    
    Update $\theta$ using $\ell(\theta;x,y)$ and SGD %\tcp{Step 1}

    \If{($t > 1$ \textsc{and} $i=n_{\mathrm{warm}}$)}{
    $\mathcal{I}_{\mathrm{reset}} \gets \texttt{FindDormantParams}(\theta, \theta_{\mathrm{prev}})$\
    
    \For{$l \in \mathcal{I}_{\mathrm{reset}}$}{
      Reset weights \\ using \Cref{eq:reset-mix}
      %\theta[l] \gets \alpha\cdot\theta_{\mathrm{prev}}[l] +  (1-\alpha)\cdot\theta[l] $ %\tcp{Step 2}
    }
    }

    \If{($t > 1$ \textsc{and} $i>n_{\mathrm{warm}}$ \textsc{and} i\%j=0)}{
    $n_{\mathrm{avg}} \leftarrow i/j$
  
  $\Theta \leftarrow (\Theta\cdot n_{\mathrm{\mathrm{avg}}} + \theta) / (n_{\mathrm{\mathrm{avg}}} +1)$ %\tcp{Step 3}
    
    }
  }
  $\theta \leftarrow \Theta$
}
%\Return F,
\end{algorithm}
\vspace{-0.3in}

    