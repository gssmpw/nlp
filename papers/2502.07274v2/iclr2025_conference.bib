@misc{zhou2023pycil,
  title={Pycil: A python toolbox for class-incremental learning},
  author={Zhou, Da-Wei and Wang, Fu-Yun and Ye, Han-Jia and Zhan, De-Chuan},
  year={2023},
  publisher={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@article{(spdilemma)carpenter87,
  title={ART 2: Self-organization of stable category recognition codes for analog input patterns},
  author={Carpenter, Gail A and Grossberg, Stephen},
  journal={Applied Optics},
  volume={26},
  number={23},
  pages={4919--4930},
  year={1987},
  publisher={Optical Society of America}
}
@article{(spdilemma)mermillod13,
  title={The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects},
  author={Mermillod, Martial and Bugaiska, Aur{\'e}lia and Bonin, Patrick},
  journal={Frontiers in Psychology},
  volume={4},
  pages={504},
  year={2013},
  publisher={Frontiers}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}

@article{cha2020cpr,
  title={CPR: classifier-projection regularization for continual learning},
  author={Cha, Sungmin and Hsu, Hsiang and Hwang, Taebaek and Calmon, Flavio P and Moon, Taesup},
  journal={arXiv preprint arXiv:2006.07326},
  year={2020}
}

@inproceedings{chavan2023towards,
  title={Towards realistic evaluation of industrial continual learning scenarios with an emphasis on energy consumption and computational footprint},
  author={Chavan, Vivek and Koch, Paul and Schl{\"u}ter, Marian and Briese, Clemens},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11506--11518},
  year={2023}
}

@inproceedings{(tbbn)cha2023rebalancing,
  title={Rebalancing batch normalization for exemplar-based class-incremental learning},
  author={Cha, Sungmin and Cho, Sungjun and Hwang, Dasol and Hong, Sunwon and Lee, Moontae and Moon, Taesup},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20127--20136},
  year={2023}
}

@article{masana2022class,
  title={Class-incremental learning: survey and performance evaluation on image classification},
  author={Masana, Marc and Liu, Xialei and Twardowski, Bart{\l}omiej and Menta, Mikel and Bagdanov, Andrew D and Van De Weijer, Joost},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={5},
  pages={5513--5533},
  year={2022},
  publisher={IEEE}
}

@article{wang2024comprehensive,
  title={A comprehensive survey of continual learning: theory, method and application},
  author={Wang, Liyuan and Zhang, Xingxing and Su, Hang and Zhu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2024},
  publisher={IEEE}
}

@inproceedings{prabhu2023computationally,
  title={Computationally budgeted continual learning: What does matter?},
  author={Prabhu, Ameya and Al Kader Hammoud, Hasan Abed and Dokania, Puneet K and Torr, Philip HS and Lim, Ser-Nam and Ghanem, Bernard and Bibi, Adel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3698--3707},
  year={2023}
}

@inproceedings{wen2023optimizing,
  title={Optimizing mode connectivity for class incremental learning},
  author={Wen, Haitao and Cheng, Haoyang and Qiu, Heqian and Wang, Lanxiao and Pan, Lili and Li, Hongliang},
  booktitle={International Conference on Machine Learning},
  pages={36940--36957},
  year={2023},
  organization={PMLR}
}

@inproceedings{marouf2025weighted,
  title={Weighted ensemble models are strong continual learners},
  author={Marouf, Imad Eddine and Roy, Subhankar and Tartaglione, Enzo and Lathuili{\`e}re, St{\'e}phane},
  booktitle={European Conference on Computer Vision},
  pages={306--324},
  year={2025},
  organization={Springer}
}
@inproceedings{(mas)aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={139--154},
  year={2018}
}


@inproceedings{marczak2025magmax,
  title={Magmax: Leveraging model merging for seamless continual learning},
  author={Marczak, Daniel and Twardowski, Bart{\l}omiej and Trzci{\'n}ski, Tomasz and Cygert, Sebastian},
  booktitle={European Conference on Computer Vision},
  pages={379--395},
  year={2025},
  organization={Springer}
}

@inproceedings{kozal2024continual,
  title={Continual Learning with Weight Interpolation},
  author={Kozal, J{\k{e}}drzej and Wasilewski, Jan and Krawczyk, Bartosz and Wo{\'z}niak, Micha{\l}},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4187--4195},
  year={2024}
}

@article{dohare2024loss,
  title={Loss of plasticity in deep continual learning},
  author={Dohare, Shibhansh and Hernandez-Garcia, J Fernando and Lan, Qingfeng and Rahman, Parash and Mahmood, A Rupam and Sutton, Richard S},
  journal={Nature},
  volume={632},
  number={8026},
  pages={768--774},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{bic,
  title={Large scale incremental learning},
  author={Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Fu, Yun},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={374--382},
  year={2019}
}

@inproceedings{der,
  title={Der: Dynamically expandable representation for class incremental learning},
  author={Yan, Shipeng and Xie, Jiangwei and He, Xuming},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3014--3023},
  year={2021}
}

@inproceedings{foster,
  title={Foster: Feature boosting and compression for class-incremental learning},
  author={Wang, Fu-Yun and Zhou, Da-Wei and Ye, Han-Jia and Zhan, De-Chuan},
  booktitle={European conference on computer vision},
  pages={398--414},
  year={2022},
  organization={Springer}
}


@inproceedings{icarl,
  title={Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5533--5542},
  year={2001}
}

@inproceedings{wa,
  title={Maintaining discrimination and fairness in class incremental learning},
  author={Zhao, Bowen and Xiao, Xi and Gan, Guojun and Zhang, Bin and Xia, Shu-Tao},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13208--13217},
  year={2020}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

@inproceedings{liu2022towards,
  title={Towards efficient and scalable sharpness-aware minimization},
  author={Liu, Yong and Mai, Siqi and Chen, Xiangning and Hsieh, Cho-Jui and You, Yang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12360--12370},
  year={2022}
}

@article{yadav2024ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@inproceedings{jang2025model,
  title={Model stock: All we need is just a few fine-tuned models},
  author={Jang, Dong-Hwan and Yun, Sangdoo and Han, Dongyoon},
  booktitle={European Conference on Computer Vision},
  pages={207--223},
  year={2025},
  organization={Springer}
}

@misc{loukas2024generalizingdiversedistributionuniformity,
      title={Generalizing to any diverse distribution: uniformity, gentle finetuning and rebalancing}, 
      author={Andreas Loukas and Karolis Martinkus and Ed Wagstaff and Kyunghyun Cho},
      year={2024},
      eprint={2410.05980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.05980}, 
}

@article{sanyal2023early,
  title={Early weight averaging meets high learning rates for llm pre-training},
  author={Sanyal, Sunny and Neerkaje, Atula and Kaddour, Jean and Kumar, Abhishek and Sanghavi, Sujay},
  journal={arXiv preprint arXiv:2306.03241},
  year={2023}
}

@inproceedings{yu2024language,
  title={Language models are super mario: Absorbing abilities from homologous models as a free lunch},
  author={Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}

@inproceedings{kaur2023maximum,
  title={On the maximum hessian eigenvalue and generalization},
  author={Kaur, Simran and Cohen, Jeremy and Lipton, Zachary Chase},
  booktitle={Proceedings on},
  pages={51--65},
  year={2023},
  organization={PMLR}
}

@article{zhou2023going,
  title={Going beyond linear mode connectivity: The layerwise linear feature connectivity},
  author={Zhou, Zhanpeng and Yang, Yongyi and Yang, Xiaojiang and Yan, Junchi and Hu, Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={60853--60877},
  year={2023}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{merlin2022practical,
  title={Practical recommendations for replay-based continual learning methods},
  author={Merlin, Gabriele and Lomonaco, Vincenzo and Cossu, Andrea and Carta, Antonio and Bacciu, Davide},
  booktitle={International Conference on Image Analysis and Processing},
  pages={548--559},
  year={2022},
  organization={Springer}
}

@inproceedings{brignac2023improving,
  title={Improving replay sample selection and storage for less forgetting in continual learning},
  author={Brignac, Daniel and Lobo, Niels and Mahalanobis, Abhijit},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3540--3549},
  year={2023}
}

@inproceedings{khromov2024some,
  title={Some Fundamental Aspects about Lipschitz Continuity of Neural Networks},
  author={Khromov, Grigory and Singh, Sidak Pal},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{fornasier2021consensus,
  title={Consensus-based optimization on the sphere: Convergence to global minimizers and machine learning},
  author={Fornasier, Massimo and Pareschi, Lorenzo and Huang, Hui and S{\"u}nnen, Philippe},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={237},
  pages={1--55},
  year={2021}
}

%intra-task (class imbalance)
@inproceedings{xu2024defying,
  title={Defying Imbalanced Forgetting in Class Incremental Learning},
  author={Xu, Shixiong and Meng, Gaofeng and Nie, Xing and Ni, Bolin and Fan, Bin and Xiang, Shiming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={14},
  pages={16211--16219},
  year={2024}
}

@article{kaushik2021understanding,
  title={Understanding catastrophic forgetting and remembering in continual learning with optimal relevance mapping},
  author={Kaushik, Prakhar and Gain, Alex and Kortylewski, Adam and Yuille, Alan},
  journal={arXiv preprint arXiv:2102.11343},
  year={2021}
}

@inproceedings{guo2025out,
  title={Out-of-distribution forgetting: vulnerability of continual learning to intra-class distribution shift},
  author={Guo, Liangxuan and Chen, Yang and Yu, Shan},
  booktitle={International Conference on Pattern Recognition},
  pages={111--127},
  year={2025},
  organization={Springer}
}

@article{goldfarb2024joint,
  title={The Joint Effect of Task Similarity and Overparameterization on Catastrophic Forgetting--An Analytical Model},
  author={Goldfarb, Daniel and Evron, Itay and Weinberger, Nir and Soudry, Daniel and Hand, Paul},
  journal={arXiv preprint arXiv:2401.12617},
  year={2024}
}

@inproceedings{doan2021theoretical,
  title={A theoretical analysis of catastrophic forgetting through the ntk overlap matrix},
  author={Doan, Thang and Bennani, Mehdi Abbana and Mazoure, Bogdan and Rabusseau, Guillaume and Alquier, Pierre},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1072--1080},
  year={2021},
  organization={PMLR}
}
@misc{kumar2022finetuningdistortpretrainedfeatures,
      title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution}, 
      author={Ananya Kumar and Aditi Raghunathan and Robbie Jones and Tengyu Ma and Percy Liang},
      year={2022},
      eprint={2202.10054},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2202.10054}, 
}

@article{andriushchenko2023sharpness,
  title={Sharpness-aware minimization leads to low-rank features},
  author={Andriushchenko, Maksym and Bahri, Dara and Mobahi, Hossein and Flammarion, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={47032--47051},
  year={2023}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{yang2024parameter,
  title={Is Parameter Collision Hindering Continual Learning in LLMs?},
  author={Yang, Shuo and Ning, Kun-Peng and Liu, Yu-Yang and Yao, Jia-Yu and Tian, Yong-Hong and Song, Yi-Bing and Yuan, Li},
  journal={arXiv preprint arXiv:2410.10179},
  year={2024}
}

@article{yang2024model,
  title={Model merging in llms, mllms, and beyond: Methods, theories, applications and opportunities},
  author={Yang, Enneng and Shen, Li and Guo, Guibing and Wang, Xingwei and Cao, Xiaochun and Zhang, Jie and Tao, Dacheng},
  journal={arXiv preprint arXiv:2408.07666},
  year={2024}
}


@article{zhou2024class,
    author = {Zhou, Da-Wei and Wang, Qi-Wei and Qi, Zhi-Hong and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei},
    title = {Class-Incremental Learning: A Survey},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume={46},
    number={12},
    pages={9851--9873},
    year = {2024}
}

@inproceedings{zhou2024continual,
    title={Continual learning with pre-trained models: A survey},
    author={Zhou, Da-Wei and Sun, Hai-Long and Ning, Jingyi and Ye, Han-Jia and Zhan, De-Chuan},
    booktitle={IJCAI},
    pages={8363-8371},
    year={2024}
}

@misc{pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas KÃ¶pf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.01703}, 
}

@InProceedings{Harun_2023_CVPR,
    author    = {Harun, Md Yousuf and Gallardo, Jhair and Hayes, Tyler L. and Kanan, Christopher},
    title     = {How Efficient Are Today's Continual Learning Algorithms?},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
    month     = {June},
    year      = {2023},
    pages     = {2431-2436}
}