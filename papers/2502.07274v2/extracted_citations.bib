@article{dohare2024loss,
  title={Loss of plasticity in deep continual learning},
  author={Dohare, Shibhansh and Hernandez-Garcia, J Fernando and Lan, Qingfeng and Rahman, Parash and Mahmood, A Rupam and Sutton, Richard S},
  journal={Nature},
  volume={632},
  number={8026},
  pages={768--774},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{ilharco2022editing,
  title={Editing models with task arithmetic},
  author={Ilharco, Gabriel and Ribeiro, Marco Tulio and Wortsman, Mitchell and Gururangan, Suchin and Schmidt, Ludwig and Hajishirzi, Hannaneh and Farhadi, Ali},
  journal={arXiv preprint arXiv:2212.04089},
  year={2022}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@inproceedings{jang2025model,
  title={Model stock: All we need is just a few fine-tuned models},
  author={Jang, Dong-Hwan and Yun, Sangdoo and Han, Dongyoon},
  booktitle={European Conference on Computer Vision},
  pages={207--223},
  year={2025},
  organization={Springer}
}

@inproceedings{kaur2023maximum,
  title={On the maximum hessian eigenvalue and generalization},
  author={Kaur, Simran and Cohen, Jeremy and Lipton, Zachary Chase},
  booktitle={Proceedings on},
  pages={51--65},
  year={2023},
  organization={PMLR}
}

@inproceedings{kozal2024continual,
  title={Continual Learning with Weight Interpolation},
  author={Kozal, J{\k{e}}drzej and Wasilewski, Jan and Krawczyk, Bartosz and Wo{\'z}niak, Micha{\l}},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4187--4195},
  year={2024}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{marczak2025magmax,
  title={Magmax: Leveraging model merging for seamless continual learning},
  author={Marczak, Daniel and Twardowski, Bart{\l}omiej and Trzci{\'n}ski, Tomasz and Cygert, Sebastian},
  booktitle={European Conference on Computer Vision},
  pages={379--395},
  year={2025},
  organization={Springer}
}

@inproceedings{marouf2025weighted,
  title={Weighted ensemble models are strong continual learners},
  author={Marouf, Imad Eddine and Roy, Subhankar and Tartaglione, Enzo and Lathuili{\`e}re, St{\'e}phane},
  booktitle={European Conference on Computer Vision},
  pages={306--324},
  year={2025},
  organization={Springer}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International conference on machine learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@article{yadav2024ties,
  title={Ties-merging: Resolving interference when merging models},
  author={Yadav, Prateek and Tam, Derek and Choshen, Leshem and Raffel, Colin A and Bansal, Mohit},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{yu2024language,
  title={Language models are super mario: Absorbing abilities from homologous models as a free lunch},
  author={Yu, Le and Yu, Bowen and Yu, Haiyang and Huang, Fei and Li, Yongbin},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

