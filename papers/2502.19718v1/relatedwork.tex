\section{Related Works}
\textbf{Contrastive learning.} Contrastive learning \citep{chen2020simple,he2020momentum,chen2021exploring,grill2020bootstrap,caron2021emerging} stands out as the leading self-supervised representation learning approach in computer vision, achieving invariance by comparing different augmentations of the same image. A notable example is SimCLR \citep{chen2020simple}, which enhances semantic representations by increasing the similarity between various views of the same image in the latent space. MoCo v3 \citep{chen2021empirical} applies contrastive learning techniques to pre-train vision transformers. DINO \citep{caron2021emerging} delves into novel properties of self-supervised vision transformers.

\textbf{Masked image modeling.} Masked image modeling (MIM) has gained significant traction in the field of computer vision as an effective self-supervised learning paradigm. Recently, with the widespread use of vision transformers (ViTs) \citep{dosovitskiy2021an,liu2021swin}, a series of notable methods such as BEiT~\citep{bao2022beit}, MAE~\citep{he2022masked}, and SimMIM~\citep{xie2022simmim} have been proposed to pre-train ViTs following the BERT-style masked modeling paradigm used in natural language processing (NLP) \citep{devlin2019bert,liu2019roberta}. Many follow-up works extend masked pre-training by exploring data augmentations \citep{chen2023mixed,fang2023corrupted}, mask strategies \citep{li2022semmae,wang2023hard,wang2024droppos}, and hierarchical structures \citep{xie2022simmim,huang2022green,woo2023convnext}. Additionally, there is growing interest in understanding MAE and its connection with contrastive learning \citep{zhang2022mask,xie2023revealing,huang2023contrastive,kong2023understanding,pan2023towards}. In this paper, we further investigate MAE from an information bottleneck perspective.

\textbf{Information bottleneck.} Under information theory, any closed system can be quantified by the mutual information between bottleneck and output variables \citep{IB_BASE}. A DNN with a given input can be considered as a closed system that introduces no other information. During the forward propagation, the complexity of the intermediate variables usually decreases in a general prediction model, as does the amount of information they contain. It is possible to measure the goodness of each layer and even the whole prediction network by the mutual information that can be used between the intermediate variables or the outputs and the network's prediction target \citep{IB_NN}.