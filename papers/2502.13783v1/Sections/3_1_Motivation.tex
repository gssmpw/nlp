In today's era of information overload, recommendation systems~\cite{xie2024breaking,xie2024bridging,shen2024exploring,yin2024learning,han2024efficient,wang2025mf,yin2023apgl4sr,han2023guesr,zhang2022clustering,wang2021hypersorec,wang2019mcne,zhang2024unified} have become essential tools for filtering vast amounts of data and delivering personalized content to users based on their historical interactions. Over the past decade, significant advancements have been made in the field, particularly in techniques such as feature interaction~\cite{wang2021dcn,guo2017deepfm} and user behavior modeling~\cite{zhou2018deep,zhou2019deep,xu2024multi}. These innovations have led to substantial improvements in the key processes of recommendation systems, namely recall and ranking, enhancing their ability to accurately predict and present information that aligns with users' interests.

Recently, large language models (LLMs)have achieved remarkable success and show great potential for application in recommendation systems. There are currently two primary approaches to integrating LLMs into these systems. The first approach involves enhancing traditional recommendation systems by utilizing the extensive world knowledge and reasoning capabilities of general LLMs, a method known as \textbf{LLMs-enhanced recommendation}~\cite{xi2024towards,liu2024once,li2023ctrl}. The second approach focuses on developing larger and more sophisticated recommendation models by designing generative recommendation models that adhere to scaling laws, known as \textbf{generative large recommendation models}~\cite{zhang2024wukong,zhang2024scaling,zhai2024actions}. In recent months, there have been groundbreaking advancements in this second path, highlighted by the successful online deployment of trillion-parameter generative recommendation models. These models, comparable in scale to GPT-3 and LLaMa-2, have achieved significant business improvements and demonstrated powerful scalability, attracting considerable attention from both academia and industry. Despite advancements, previous surveys~\cite{lin2023can,wu2024survey} and tutorials~\cite{zhang2024large,liu2023user} on LLMs for recommendation have mainly focused on the first approach, leaving a gap in the systematic exploration of the second path. Therefore, this tutorial aims to offer a comprehensive summary of the first approach and, for the first time, systematically introduce the advancements of the second approach. This dual focus makes the tutorial both necessary and timely.

In addition to an in-depth analysis of the paradigm shift in modeling and the evolution of technical directions within the field of LLMs for  recommendation, this tutorial will also address the key challenges and issues generative large recommendation models face, alongside presenting our preliminary explorations. The tutorial will begin by focusing on the critical issue of data quality, highlighting data-centric research and data regeneration methods for large models. Next, it will examine how data size and model size influence recommendation performance, exploring the scaling laws and performance metrics pertinent to the recommendation domain. Additionally, the tutorial will delve into methods for more effectively mining and utilizing complex user behavior sequences to enhance data usage. Finally, it will address the challenge of improving training and inference efficiency, which is crucial for enabling the scalability of model size.

This tutorial will conclude by exploring future research directions in the field of generative large recommendation models. One promising direction is conducting data engineering tasks, such as data distillation and data selection, to ensure that training data is clean, relevant, and well-structured. At the representation level, employing tokenizer technology and integrating side information can significantly enhance recommendation performance and efficiency. Additionally, addressing incremental updates in practical applications presents a valuable research opportunity. By engaging with this tutorial, participants will gain insights into the latest advancements in LLMs for recommendations, develop an understanding of the current challenges in the field, and identify future research directions. This knowledge will aid participants in applying or further researching generative large recommendation models.

\textbf{Necessity and timely of this tutorial.}  Large models for recommendation have gained significant attention recently, with many publications and tutorials at conferences like WWW'24 \cite{zhang2024large}. However, they focus on LLMs-enhanced recommendations, leaving a gap in exploring generative large recommendation models. With their recent successes, a comprehensive tutorial is crucial to support the field's rapid development, offering valuable insights for practitioners. Therefore, this tutorial is both necessary and timely.