\begin{abstract}
%CONTEXT
Generating a collision-free robot motion is crucial for safe applications in real-world settings.
%PROBLEM STATEMENT
This requires an accurate model of all obstacle shapes within the constrained robot cell, 
which is particularly challenging and time-consuming. 
The difficulty is heightened in flexible production lines,
where the environment model must be updated each time the robot cell is modified.
Furthermore, 
sensor-based methods often necessitate costly hardware and calibration procedures, 
and can be influenced by environmental factors 
(e.g., light conditions or reflections).
%MAIN APPROACH
To address these challenges,
we present a novel data-driven approach to modeling a cluttered workspace, 
leveraging solely the robotâ€™s internal joint encoders to capture exploratory motions.
By computing the corresponding swept volume,
we generate a (conservative) mesh of the environment that is subsequently used for collision checking 
within established path planning and control methods.
Our method significantly reduces the complexity and cost of classical environment modeling
by removing the need for CAD files and external sensors.
%EXPERIMENTS
We validate the approach with the KUKA LBR iisy collaborative robot in a pick-and-place scenario.
In less than three minutes of exploratory robot motions
and less than four additional minutes of computation time, 
we obtain an accurate model that enables collision-free motions. 
%OUTCOME
Our approach is intuitive, 
easy-to-use, 
making it accessible to users without specialized technical knowledge.
It is applicable to all types of industrial robots or cobots. % and additional exploration modes.
\end{abstract}