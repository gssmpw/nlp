\section{Introduction}
% CONTEXT
\IEEEPARstart{A}{n} accurate environment model 
is paramount for successfully deploying and operating robot systems without compromising hardware integrity. 
The process of environment modeling involves creating a (digital) representation of the physical world. 
%which robots use to interact with and perform complex tasks with precision and efficiency. 
Typically, 
it encompasses data acquisition through (expensive) sensors~\cite{campos2021orb} and integrating this data into coherent models~\cite{tateno2017cnn,bloesch2018codeslam}. 
The output of this process may be a dense point cloud, 
a 3D map, 
or 3D meshes~\cite{mildenhall2021nerf,kerbl20233d}.
Alternatively,
objects in the robot cell are modeled separately through Computer-Aided Design (CAD) files,
incorporating shape and position information.
This approach can yield imprecise results due to the sim-to-real gap. 
Moreover, 
necessary data are often unavailable.
The challenge intensifies in robot cells frequently modified to meet changing production needs.
% MOTIVATIONS
Based on our experience, 
currently, 
many enterprises avoid modeling the robot surroundings due to the time-consuming, 
expensive, 
and complex nature of the task. 
However, 
this hinders the implementation of applications involving autonomous robots that generate collision-free paths and adapt motions in real-time. 
%Instead, robot programming is not reactive, 
%namely robots do not adjust their actions based on real-time feedback. 
Instead, 
operators program sub-optimal trajectories offline,
leading to inefficiencies in execution.

\begin{figure}[!t]
	\centering
	\includegraphics[width=0.99\linewidth]{figures/pick_and_place}
	\caption{Swept volume (in orange) of a KUKA LBR iisy robot. The exploration of the free workspace has been performed through hand guidance with a cube-shaped exploration tool.}
	\label{fig:sv_pick_and_place}
\end{figure}

% OUR PROPOSAL
Our main contribution is a novel data-driven approach to modeling a constrained robot cell using exploratory robot motions,
relying solely on the integrated joint encoders and eliminating sim-to-real gaps.
The resulting swept volume is used to compute a (conservative) 3D mesh representation of the obstacles and unexplored areas, 
which is finally employed for automatic collision-free motion planning and control~\cite{osorio2020unilateral, fiore2023general}. 
%No neural network is involved in any step of the proposed method.
Our approach is fast, cost-effective, and straightforward,
supporting flexible production lines with confined spaces in modern Industry~4.0 scenarios.
We validate the effectiveness of our approach in a pick-and-place scenario with the KUKA LBR iisy,
demonstrating the user-friendly interface that does not require 
any advanced technical knowledge in robotics. 
Note that the approach is robot-agnostic, 
making it applicable to both collaborative and industrial robots.

As a secondary contribution, 
we propose integrating an \textit{exploration tool} that simplifies and accelerates the exploration phase, 
while reducing computational load. 
This tool is inexpensive as it contains no electronics. 
When combined with a commercially available tool change system, 
multiple exploration tools with different shapes can be easily used, 
without significantly extending the exploration process.

% ARTICLE STRUCTURE
%This article is organized as follows. 
In the following,
\refSec{sec:background} presents the state of the art related to environment modeling and swept volume computation. 
\refSec{sec:freeWorkspaceExploration} describes our approach to obtaining a representation of the free space within the constrained robot cell. 
Experimental results are reported in \refSec{sec:experiments}, % using a KUKA LBR iisy robot in a pick and place scenario to prove the effectiveness and to evaluate the performance of the proposed pipeline. 
while \refSec{sec:conclusion} concludes. % this article.

