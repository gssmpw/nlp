\section{Related work}
\label{sec:background}
\noindent At its core, 
our approach to \emph{environment modeling} is based on the \emph{swept volume} of an exploratory robot motion. 
This section reviews the current state of the art in these two areas.
%In this section, 
%we describe the current state-of-the-art solutions for modeling the robot's surrounding environment and computing the SV of a rigid body. 
%Typically, environment modeling involves mapping algorithms and costly external sensors. 
%However, 
%our work introduces a new method that differs from traditional sensor-driven approaches. 
%We propose a novel approach for modeling a robot cell through exploratory motions without relying on any sensors.
%This approach is centered around computing the robot's SV, 
%which is then utilized alongside established collision-free motion planning and control algorithms to ensure the safe execution of tasks.

\subsection{Environment Modeling}
%Environment modeling has been a long-standing problem in the field of robotics. 
To ensure autonomous robots can safely execute tasks and avoid unintended collisions with their surroundings, 
an accurate environment model is essential.
%An accurate environment model is vital for autonomous robots to safely perform tasks and avoid any unintended collisions with their surroundings.
\emph{Simultaneous Localization and Mapping} (SLAM) is a well-established paradigm 
that allows navigating through an unknown environment, 
while simultaneously localizing the robot pose thanks to onboard sensors such as
cameras, 
laser scanners, 
GPSs, 
sonars, 
or LiDARs.
The algorithm proposed in~\cite{campos2021orb} has proven to be robust, 
accurate, 
and flexible in many applications with various sensor setups. 
However, it faces challenges maintaining high performance within sparsely textured and dynamic environments. %visual-inertial and multimap SLAM with monocular, stereo, and RGB-D cameras, using pin-hole and fisheye lens models.  
%Also, it faces challenges related to discretized environment representations (e.g., point clouds), such as sparse 3D modeling. 
%With the rapid development and spread of the Neural Network.
Remarkable progress in camera localization and map reconstruction has been achieved by integrating deep learning techniques, 
considerably improving the underlying feature extraction~\cite{tateno2017cnn, bloesch2018codeslam}. 
%they were highly dependent on the training datasets showing generalization capabilities for unseen environments. 
In recent years, 
there has been a growing need for continuous surface modeling and finding solutions for occlusions and sparse observations. 
This has increased research interest in Neural Radiance Fields (NeRF)~\cite{mildenhall2021nerf} and 3D Gaussian Splatting (3DGS)~\cite{kerbl20233d}. 
These methods can produce 3D meshes from dense and compact environment maps. 
However, 
their practical applications may be hindered by limitations in real-time processing, 
hardware demands, 
and training duration.
In addition to these automatic methods, 
CAD models describe the geometry of individual objects in a scene.
They are also used to visualize, 
simulate and optimize large production line processes in 3D,
demanding significant technical expertise.
Although this approach can provide high precision and control when performed accurately,
it may suffer from sim-to-real-gaps and is time-consuming.

\subsection{Swept Volume}
Swept volume (SV) refers to the three-dimensional space encompassing all points that a rigid object motion occupies.
This concept is now widely utilized in several application fields,
including numerically controlled machining verification (e.g., for a milling process), 
modeling of complex solids, 
robot reachable and dexterous workspace analysis, 
collision detection/avoidance, 
and ergonomics.

Abdel-Malek et al.~\cite{abdel2006swept} compared several methods for SV computation.
An \textit{explicit} representation, based on the geometric properties of the moving object, 
is typically obtained via voxel grid approximations 
or by using a triangle mesh to approximate the boundary of the SV. 
This approach struggles to generalize to all motions and object types, 
and the error, 
closely tied to computational power, 
is difficult to control.
Alternatively,
an \textit{implicit} representation describes a mathematical function determining whether a point is inside or outside the SV.
Even though the mathematical formulation is straightforward, 
the SV computation may result in a relevant computational load and provide sub-optimal solutions.
Such numerical issues are avoided by the \textit{stamping} method, which samples the object's motion in space and time.  
The accuracy of the final result heavily depends on the complexity of the object's motion and on the sampling time. 
%Indeed, 
%since some points belonging to the object surface can move faster (slower), 
%a finer (coarser) sampling time for those regions should be employed. 
Moreover, 
it scales poorly with the volume size. 
To the best of our knowledge, 
Sell√°n et al.~\cite{sellan2021swept} describe the current best-performing method for SV computation by combining the implicit representation with a numerical continuation method.

In robotics, swept volumes have been employed for collision detection and collision-free path planning. 
To ensure safe motions,
\cite{taubig2011real} checked pairwise self-collisions for all robot links utilizing swept convex hulls extended by a buffer radius. 
Baxter et al.~\cite{baxter2020deep} introduced a neural network that predicts the SV geometry for a robot moving from a start to goal joint configuration.
The method outputs discretized voxel grids, 
where each voxel indicates either free or swept space. 
In the same scenario,
\cite{joho2024neural} overcame the accuracy limitation given by the voxel discretization 
by learning a neural implicit SV model as a signed distance function, 
requiring large amounts of training data associated with a desired motion type.
This approach, 
however, 
does not apply to hand guidance, 
tele-operation or any other human-guided motions.

We are not aware of any prior work that utilize SV in the context of environment modeling.
