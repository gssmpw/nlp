
\begin{figure*}[t]
    \centering
    \begin{minipage}[t]{0.47\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{figures/method_1.png}
        \vspace{-10pt}
        \caption{Relationship between knowledge format, original output probability, and efficacy when applying advanced editing methods to update triplet-structured and diverse-formatted knowledge. For each category, we randomly sample 200 knowledge instances to conduct experiments. Best viewed in color.}
        \label{fig:method1}
        \vspace{-10pt}
    \end{minipage}%
    \hfill
    \begin{minipage}[t]{0.473\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{figures/method_2.png}
        \vspace{-10pt}
        \caption{Relationship between the number of tokens in to-be-updated knowledge, probability shift under random input perturbations, and editing efficacy. We conduct experiments by truncating the sampled knowledge instances to enable editing across different token lengths. The lighter-colored bands represent variance. Best viewed in color.}
        \label{fig:method2}
        \vspace{-10pt}
    \end{minipage}
\end{figure*}

\section{Preliminary} \label{sec:method:pre}
\textbf{Autoregressive LLMs.}
LLMs learn and store knowledge through autoregressive token prediction.
Formally, let $f$ denote a decoder-only LLM with $L$ layers processing the input sequence $X=(x_0,x_1,\cdots,x_T)$.
At layer $l$, the hidden state for token $x_t$ is computed via the forward propagation:
\begin{equation}
    \begin{aligned}
         \vh_t &= \vh_t^{ - 1} + \va_t + \vm_t, \\
         \va_t &= \text{Attention}(\vh_0^{ - 1}, \vh_1^{ - 1}, \ldots, \vh_t^{ - 1}), \\
         \vm_t &= \text{MLP}(\vh_t^{ - 1} + \va_t),
    \end{aligned}
\end{equation}
where $\vh_t$ and $\vh_t^{ - 1}$ denote the hidden states of token $x_t$ in the current and previous layers, respectively; $\va_t$ and $\vm_t$ are the outputs of the attention and MLP modules, respectively. 

\textbf{Model Editing in LLMs.} To update outdated or incorrect knowledge within $f$, model editing typically follows a locate-then-edit paradigm \cite{ROME}: (1) Locate the key token in the input prompt and the influential layers; (2) Edit the hidden states of the key token within these layers to modify the modelâ€™s output. Formally, let $(X, Y)$ denote the to-be-updated knowledge with the input prompt $X$ (\eg ``Where were the latest Olympics held?'') and the desired output $Y$ (\eg ``Paris.''). 
Suppose the key token is located at position $t$ in $X$.
Current methods typically perturb its hidden state $\vh_t$ by adding a residual term $\bm{\delta}$, which is  obtained via gradient descent to maximize the probability of generating $Y$ given $X$:
\begin{equation}
    \bm{\delta}= \argmin_{\bm{\hat{\delta}}} \left( -\log \mathbb{P}_{f(\vh_t+\bm{\hat{\delta}})} \left[Y \mid X\right] \right),\label{opt}
\end{equation}
where $\mathbb{P}_{f(\vh_t+\bm{\hat{\delta}})}$ represents the output probability when replacing $\vh_t$ with $\vh_t+\bm{\hat{\delta}}$ in the LLM.  Finally, the LLM parameters are updated such that, given the input $X$, the hidden state of the key token is aligned with $\vh_t+\bm{\delta}$. For more details, please refer to Appendix \ref{app:model_edit}. 
% This alignment is achieved using methods such as least squares optimization \cite{MEMIT}, null-space projection \cite{AlphaEdit}, or gradient-based fine-tuning \cite{UnKE} (see Appendix C for details).

\section{Exploring Limitations of Existing Paradigm} \label{sec:lim} 

Although \textbf{single-token editing} methods have been extensively studied in recent years \cite{AlphaEdit,wise,UnKE,RECT,AKEW}, we argue that they are fundamentally limited in updating long-form, diverse formatted knowledge. In this section, we analyze and empirically validate these two limitations.

\subsection{Limitation of Editing Diverse-formatted Knowledge} \label{sec:method:lim:div}

According to \Eqref{opt}, the success of the single-token editing methods hinges on whether the LLM generates $Y$ given $X$ after applying the perturbation $\bm{\delta}$ to $\vh_t$.
In other words, the perturbation must significantly increase the probability of generating $Y$ over any other possible output. However, if the original probability of $Y$ in the unedited LLM is already low --- particularly common in the case of diverse-formatted knowledge, such as code snippets and mathematical derivations --- then $\bm{\delta}$ must induce a large shift to make $Y$ the dominant output. Due to the limited capacity of single-token editing, current methods often struggle with such cases.

This limitation arises because structured knowledge (\eg factual triples) is simpler than diverse-formatted knowledge, which involves intricate dependencies. In triplets, modifying a single token (\eg changing ``Tokyo'' to ``Paris'') is often enough. In contrast, diverse-formatted knowledge like code and math requires consistent updates across multiple tokens due to syntax, variable dependencies, and hierarchical structures. Consider Figure \ref{fig:intro} (f) again. Modifying a function in code may require changes across multiple lines, while altering a symbol in a formula often affects the entire expression. Single-token perturbations fail to capture and propagate such dependencies, leading to ineffective edits.

To empirically validate this, we apply leading single-token editing methods, MEMIT to update triplet-structured and diverse-formatted knowledge in LLaMA3-8B-Instruct. Figure \ref{fig:method1} shows relationships between knowledge format, original probability, and editing efficacy. The results show that diverse-formatted knowledge, which typically has a low original probability, exhibits poor editing efficacy. In a nutshell, \textbf{low original probability} may be the fundamental limitation in updating \textbf{diverse-formatted} knowledge.

\subsection{Limitation of Editing Long-form Knowledge} \label{sec:method:lim:lon}

Recent studies suggest that although LLMs leverage attention mechanism \cite{gpt-j}, the dependency between distant tokens weakens as their positional distance increases \cite{long_form}. As a result, for long outputs $Y$ (\eg $Y$ exceeding 100 tokens), perturbations applied to input tokens may have a diminishing influence on the later tokens within $Y$. In such cases, the shift of generation probability of $Y$ introduced by the perturbation $\bm{\delta}$ may be too small, making it insufficient to increase the probability of $Y$ above that of any other potential output.

To validate this, we repeat the experiments described in Section \ref{sec:method:lim:div}. Additionally, we use causal tracing \cite{ROME}, a common strategy in model editing, to quantify the shift in the generation probability of $Y$ introduced by the perturbation on $X$ (details of causal tracing can be found in Appendix \ref{app:model_edit}).
Figure \ref{fig:method2} illustrates the relationship between: the number of tokens in $Y$, the probability shift, and editing efficacy.
The results demonstrate that long-form knowledge, which is less affected by single-token edits on the input, shows poor editing efficacy. In other words, the \textbf{low probability shift} introduced by single-token edits emerges as the inherent limitation in effectively updating \textbf{long-form} knowledge.

This limitation, in conjunction with the constraint discussed in Section \ref{sec:method:lim:div}, collectively suggests that the current single-token editing paradigm faces a theoretical efficacy barrier. We formalize this barrier as follows:

\textit{\textbf{Proposition 1} (Efficacy Barrier of Single-token Editing).
Given $N$ pieces of knowledge to be updated, denoted as $(X_i, Y_i)$ for $i \in (1, N)$, and a target LLM $f$, the upper bound on the efficacy of knowledge updates using single-token editing is given by:}
\begin{equation}
\begin{aligned}
\eta= & \frac{1}{N}\sum_{i=1}^N \operatorname{sign}\Big( 
\mathbb{P}_{f(\vh+\bm{\delta})}\left[Y_i\mid X_i\right]-
\\
&
\max _{Y^{\prime}\in \mathbb{Y}/Y_i} \left(\mathbb{P}_{f(\vh+\bm{\delta})} \left[Y' \mid X_i\right]\right)\Big),
\end{aligned}
\end{equation}
\textit{where $\text{sign}(\cdot)$ is the sign function, $\vh$ denotes the hidden state of the perturbed token, $\mathbb{Y}$ represents the set of $f$'s outputs, and $\bm{\delta}$ is defined as:}
\begin{equation}
    \bm{\delta}= \argmin_{\bm{\hat{\delta}}} \left( -\log \mathbb{P}_{f(\vh+\bm{\hat{\delta}})} \left[Y_i \mid X_i\right] \right).
\end{equation}

\section{AnyEdit: Autoregressive Model Editing} \label{sec:anyedit}
The previous section demonstrated that, regardless of how current single-token editing methods are optimized, their editing efficiency is inevitably constrained by an upper bound. Furthermore, as the format and length of the knowledge to be updated become more diverse and longer, this upper bound diminishes, eventually rendering the editing process ineffective.
To address this issue, we introduce AnyEdit, an autoregressive editing paradigm that enables collaborative token updates. The theoretical foundation from an information-theoretic perspective is provided in Section \ref{sec:any_the}, while its instantiation is outlined in Section \ref{sec:any_imp}.

\subsection{Theoretical Foundation} \label{sec:any_the}
We begin by reviewing the editing process from an information-theoretic perspective.
Specifically, existing methods aim to maximize the probability of generating $Y$ by editing hidden states, as formulated in \Eqref{opt}. This objective aligns with maximizing the mutual information (MI) \cite{information} between $X$ and $Y$, given the perturbed hidden state $\vh'$:
\begin{equation}
    \vh' = \argmax_{\hat{\vh'}} I(X; Y \mid \hat{\vh'}), \label{eq:MI_single}
\end{equation}
where $I(\cdot|\cdot)$ denotes MI. A detailed derivation is provided in Appendix \ref{app:proof_cmi}. Extending this framework to perturb the hidden states of $K$ tokens simultaneously, denoted as $\{\vh_1, \vh_2, \cdots, \vh_K\}$, the MI in \Eqref{eq:MI_single} generalizes to:
\begin{equation}
    I(X; Y \mid \vh'_1, \vh'_2, \cdots, \vh'_K) \label{eq:MI_more}.
\end{equation}
However, as discussed in Section \ref{sec:method:lim:lon}, simultaneous perturbation of multiple hidden states introduces interference, reducing editing efficacy. Ideally, the MI term should involve only a single hidden state as a condition, as in \Eqref{eq:MI_single}. %%%
To achieve this, we first decompose $Y$ into $K$ chunks, denoted as $Y = (Y_1, Y_2, ..., Y_K)$, and apply the chain rule of MI to rewrite \Eqref{eq:MI_more}:
\begin{equation}
    \begin{aligned}
        &I(X; Y \mid \vh'_1, \cdots, \vh'_K)=\\ &\sum_{k=1}^K I(X; Y_k \mid Y_1, \cdots, Y_{k-1}, \vh'_1, \cdots, \vh'_K). \label{eq:decom}
    \end{aligned}
\end{equation}
We then select the last token of each chunk as the perturbation target, establishing a one-to-one correspondence between chunk $Y_k$ and hidden state $\vh'_k$. Given that LLMs generate outputs autoregressively, two key properties hold:
\begin{itemize}[leftmargin=*]
    \item Hidden states of later tokens do not influence the generation of earlier outputs, \ie $H(Y_p \mid \vh'_q) = H(Y_p)$ for $p < q$, where $H(\cdot)$ represents the information entropy;
    \item Once $Y_k$ is determined, conditioning on $Y_k$ subsumes conditioning on the hidden state of tokens within $Y_k$, \ie $H(\cdot \mid Y_k) = H(\cdot \mid Y_k, \vh'_k)$.
\end{itemize}
Using these two properties, we can derive that each term in \Eqref{eq:decom} is proportional to:
\begin{equation}
    \begin{aligned}
        I(X, Y_1, \dots, Y_{k-1}; Y_k \mid \vh'_k). \label{eq:final_MI}
    \end{aligned}
\end{equation}
A detailed derivation is provided in Appendix \ref{app:proof_decom}.
\Eqref{eq:final_MI} directly informs our editing strategy: at each step, we take $X$ and previously edited chunks $(Y_1, \dots, Y_{k-1})$ as inputs, iteratively encoding the next chunk $Y_k$ into the LLM's output in an autoregressive manner.
More importantly, \Eqref{eq:final_MI} exhibits two critical advantages:
\begin{itemize}[leftmargin=*]
    \item[1.] \textbf{Elimination of Interference:} Each MI term conditions on a single hidden state $\vh'$, avoiding the interference issue in \Eqref{eq:MI_more}.
    \item[2. ] \textbf{Scalability Across Length and Formats:} Regardless of $Y$'s length or format, each editing step updates only a single chunk, circumventing the efficacy barrier of single-token editing in Proposition 1.
\end{itemize}

In summary, this formulation provides a theoretical foundation for editing long-form diverse-formatted knowledge in LLMs. By leveraging an autoregressive editing paradigm, we move beyond single-token editing, enabling more scalable and efficient model editing. Next, we demonstrate how to instantiate it by providing specific implementation steps.

\subsection{Implementation Details} \label{sec:any_imp}
Building on the above theoretical foundation, we elaborate on the implementation process of AnyEdit in this part. Specifically, AnyEdit follows a four-step process for effective and scalable knowledge editing:

\textbf{Step 1: Chunk Outputs.} 
The first step involves splitting the target output $Y$ into multiple chunks. We propose two chunking strategies: (1) a sliding window with a fixed number of tokens and (2) semantic segmentation based on natural sentence boundaries.
These strategies endow AnyEdit with the ability to automatically adjust the number of edited tokens based on knowledge length, ensuring efficient edits without redundancy.

\textbf{Step 2: Locate Token and Layer.}
We select the last token of each chunk $Y_k$ as the target for editing, and directly apply the causal tracing to locate the influential layers, following the conventional model editing methods \cite{ROME}.

\textbf{Step 3: Edit Hidden States.}
Following \Eqref{eq:final_MI}, we input $X$ and the previous chunks $\{Y_1,Y_2,\cdots,Y_{k-1}\}$ into the LLM. Then, the hidden state $\vh_k$ of the selected token is edited by the gradient descent to maximize the probability of generating $Y_k$. Formally,
\begin{equation}
\begin{aligned}
    \vh'_k=& \vh_k+ \argmin_{\bm{\hat{\delta}}} \\
    & \left( -\log \mathbb{P}_{f(\vh_k+\bm{\hat{\delta}})} \left[Y_k \mid X, Y_1, \cdots, Y_{k-1}\right] \right).
\end{aligned}
\end{equation}
% This autoregressive paradigm enables multi-token collaborative editing while avoiding interference between edits.

\textbf{Step 4: Update Model Parameters.}
Finally, the LLM parameters are updated to align the hidden state of the selected tokens with the edited states, using standard least-squares optimization as employed in current model editing methods \cite{ROME}. Detailed implementation of this step is provided in Appendix \ref{app:model_edit}.

This multi-token collaborative editing process enables AnyEdit to overcome the efficacy barrier of single-token editing. Furthermore, AnyEdit enables seamless integration with existing methods, equipping them with the ability to edit any knowledge within LLMs and broadening the scope and practicality of LLM knowledge editing.