%%%% ijcai24.tex

\typeout{IJCAI--24 Instructions for Authors}

% These are the instructions for authors for IJCAI-24.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% The file ijcai24.sty is a copy from ijcai22.sty
% The file ijcai22.sty is NOT the same as previous years'
\usepackage{ijcai24}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}

\usepackage{amsfonts}
\usepackage{array}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{cite}
\usepackage{subfigure}
%\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[footnotesize]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{color}
\usepackage[switch]{lineno}
\usepackage{graphicx}
\usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\makeatletter

\renewcommand{\maketag@@@}[1]{\hbox{\m@th\footnotesize\normalfont#1}}%

\makeatother


% Comment out this line in the camera-ready submission
%\linenumbers

\urlstyle{same}

% the following package is optional:
%\usepackage{latexsym}

% See https://www.overleaf.com/learn/latex/theorems_and_proofs
% for a nice explanation of how to define new theorems, but keep
% in mind that the amsthm package is already included in this
% template and that you must *not* alter the styling.
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.


% PDF Info Is REQUIRED.

% Please leave this \pdfinfo block untouched both for the submission and
% Camera Ready Copy. Do not include Title and Author information in the pdfinfo section
\pdfinfo{
/TemplateVersion (IJCAI.2024.0)
}

\title{Riemannian Complex Hermit Positive Definite Convolution Network for Polarimetric SAR Image Classification}


% Single author syntax
%\author{
%   Junfei Shi $^{1,2}$*,~\IEEEmembership{IEEE member}, Mengmeng Nie$^{1,2}$, Haiyan Jin $^{1,2}$
%    \affiliations
%
%    \emails
%   shijunfei@xaut.edu.cn
%}

% Multiple author syntax (remove the single-author syntax above and the \iffalse ... \fi here)
%\author{
%Anonymous IJCAI submission
%}


\author{
  Junfei Shi $^{1}$*
%\and
Mengmeng Nie$^{1}$\and
 Yuke Li $^{1}$\and
 Haiyan Jin $^{1}$\and
Weisi Lin$^{2}$\and
\affiliations
$^1$Department of Computer Science and Technology, Shaanxi Key Laboratory for Network Computing and Security Technology, Xi'an University of Technology, Xi'an, China\\
$^2$College of Computing and Data Science, Nanyang Technological University, Singapore, 639798\\
%$^3$Third Affiliation\\
%$^4$Fourth Affiliation\\
\emails
shijunfei@xaut.edu.cn
%2221220007@stu.xaut.edu.cn,2241849685@qq.com, WSLin@ntu.edu.sg, \{jinhaiyan,lijunhuai,xiaozhaolin\}@xaut.edu.cn, mggong@mail.xidian.edu.cn
%third@other.example.com,
%fourth@example.com
 \thanks{ Corresponding author}
}


\begin{document}

\maketitle

\begin{abstract}
Deep learning can learn high-level semantic features in Euclidean space effectively for PolSAR images, while they need to covert the complex covariance matrix into a feature vector or complex-valued vector as the network input. However, the complex covariance matrices are essentially a complex Hermit positive definite (HPD) matrix endowed in Riemannian manifold rather than Euclidean space. The matrix's real and imagery parts are with the same significance, as the imagery part represents the phase information. The matrix vectorization will destroy the geometric structure and manifold characteristics of complex covariance matrices. To learn complex HPD matrices directly, we propose a Riemannian complex HPD convolution network(HPD\_CNN) for PolSAR images. This method consists of a complex HPD unfolding network(HPDnet) and a CV-3DCNN enhanced network. The proposed complex HPDnet defines the HPD mapping, rectifying and the logEig layers to learn geometric features of complex matrices. In addition, a fast eigenvalue decomposition method is designed to reduce computation burden. Finally, a Riemannian-to-Euclidean enhanced network is defined to enhance contextual information for classification. Experimental results on two real PolSSAR datasets demonstrate the proposed method can achieve superior performance than the state-of-the-art methods especially in heterogeneous regions.
\end{abstract}


%\begin{IEEEkeywords}
%PolSAR image classification, Riemannian manifold, the complex HPD unfolding network, fast eigenvalue decomposition method, Riemannian-to-Euclidean enhanced classification
%\end{IEEEkeywords}


\section{Introduction}

During past several decades, polarimetric synthetic aperture radar (PolSAR) has received wide interest in the field of remote image processing, since it can emit and receive electromagnetic echoes in all weathers and all days. With the flourish development of radar imaging techniques, massive high-resolution PolSAR images have been captured. With abundant scattering information, PolSAR images have been widely applied to image classification\cite{9619948}, agricultural supervision\cite{10770247}, target recognition\cite{10747828} and change detection\cite{10456921}. Among them, PolSAR image classification, as a basis procedure for image understanding, has attracted a great deal of attention from researchers.

For decade years, various PolSAR image classification methods have been proposed, including classification methods based on the scattering mechanism\cite{9143461}, target decomposition\cite{10531285}, and statistical distribution\cite{8438543}. These methods can extract the most commonly used features for PolSAR image processing, such as Cloude decomposition\cite{10335659}, Freeman decomposition\cite{8602439}, Wishart distribution\cite{7018953}. However, relying on these traditional methods alone is far from enough, as they are sensitive to speckle noise and lack of high-level semantic information.

Recently, deep learning methods\cite{10599283,10770247} have been widely used in various fields of remote sensing images, due to their advantages of being the end-to-end learning framework and automatically learning high-level features. Taking into account the polarimetric information, many deep learning models have been proposed for PolSAR image classification, including Convolution Neural Network(CNN)\cite{10685476}, Graph Convolution Network(GCN)\cite{10628006}, Generative attack network (GAN)\cite{9524508}, Transformer\cite{10746331}, etc. However, these methods need to convert the complex covariance matrix into a 9-dimensional real vector as the input of the network, which completely ignores the complex phase information. Realizing this shortage, some complex-valued CNN variants\cite{10650936} have been proposed for PolSAR images such as CV-CNN\cite{9323621},CV-3D-CNN\cite{rs9010067}, hybrid CVNet\cite{10693615}, complex countlet-CNN\cite{10415179} etc. Various deep learning models have been expanded to complex data domain to learn PolSAR complex scattering characteristics. These methods transform the complex covariance matrix into a 6-dimensional complex vector as the network input, effectively learning complex scattering information. Converting PolSAR complex matrix into a complex vector has been a great advancement for PolSAR deep learning model by considering scattering information from the imagery part. However, PolSAR original data is a complex covariance matrix, known as the HPD(Hermit Positive Definite) matrix, which endows in Riemann manifold\cite{7947120}. These existing models are still based on Euclidean space by vectoring the complex matrix, destroying the complicated matrix structure, and ignoring manifold geometric characteristics of original PolSAR complex matrix data. So, it is considered whether we can exploit complex HPD matrix-based deep learning model to fully learn both complex scattering information and matrix geometric structure.

It is well known that the PolSAR covariance matrix is complex HPD, following the HPD manifold in Riemann instead of Euclidean space. That is to say, the theory of Riemann manifold should naturally be applied to PolSAR data. In Remain space, some manifold metrics have been proposed, which can learn the geometric distance of two points on the curve plant, such as affine invariant Riemannian metric (AIRM)\cite{9963700}, Jeffrey and log-Euclidean distances\cite{log2015}, etc. For further analysis, experiments using Euclidean and Riemann metrics are performed on a PolSAR image, as shown in Fig.\ref{fig1}. Euclidean and Riemann distances are utilized to verify their classification performance, respectively\cite{10282134}. It can be seen that Euclidean classification cannot discriminate the thin road and small objects and buildings, whereas Riemann-metric-based classification can tell the road and buildings out. Furthermore, the last column shows the feature distribution of three different classes. It illustrates the Riemann metric can learn more discriminating features, while Euclidean metric appears more confusions between different classes due to the unsuitable distance metric. Investigating the reason, some theories have been proved in \cite{minh2017covariances} that the Euclidean metric for covariance matrices is not a complete metric space, which does not satisfy the scale invariance, resulting in inaccurate measurement of two matrices. However, Remianian metric is a complete metric space, which satisfies the scale invariance and invariance under inversion. Therefore, Riemann-metric-based deep learning model is necessary and can better learn complex matrix data.

\begin{figure}
	\centering
	\setlength{\fboxrule}{0.2pt}
	\setlength{\fboxsep}{0.01mm}
	\includegraphics[height=0.15\textheight]{figures/1.png}
	\caption{An example of Euclidean and Riemann metric learning methods.}
	\label{fig1}
\end{figure}

To learn manifold features from covariance matrix, some Riemann manifold networks have been developed for natural images and have demonstrated its advantages in learning manifold geometry characteristic. Among them, the SPD network\cite{Huang2017} is the most fundamental work to learn the SPD matrix in Riemann rather than Euclidean space, which redefines the SPD convolution, ReLu and Pooling operators in manifold space. Based on the SPD network, some variants have been proposed by expanding various network frameworks from Euclidean to Riemann space, such as SPD-Unet\cite{wang2023u}, DMT-net\cite{zhang2020deep}, During expansion, each network module should be redefined and redesigned to ensure the consistency of the manifold. That means they should satisfy the rule that the resulting output is also be endowed in the same Riemann manifold as the input matrix. Therefore, the SPD-based network can maintain the geometric manifold of SPD matrix data effectively. However, these methods are based on SPD matrix, which did not consider the complex information of HPD matrix. Also, these methods are designed for natural images that totally ignore complex scattering information from PolSAR images. Besides, the SPDnet framework ignores to learn the real and complex information simultaneously. The back-propagation of HPD matrix is more computing-difficult with real and imagery parts. Therefore, we should design a new complex HPD unfolding network to better learn complex HPD manifold, which considers the same significant role for both real and imagery part of HPD matrix. This is because the imagery part of complex scattering information can provide various scattering information, such as the scattering angle, for target objects.

To address these disadvantages, we propose a new complex HPD unfolding network to fully understand the complex matrix structure and scattering information. Firstly, we unfold the complex HPD matrix as the real and imagery parts respectively. Then, an HPD unfolding network is designed to learn complex matrix effectively. To utilize classification in Euclidean space, a LogEig layer is designed to convert the complex HPD matrix into a tangent space in which Euclidean operations can be applied. In addition, to accelerate the computation speed, we design the iteration complex HPD matrix square root normalization method (HPD-ISRT), which can replace matrix eigenvalue decomposition by a set of matrix addition and multiplication, thereby completing parallel computing. After converting complex HPD matrix on tangent space, a complex-valued 3DCNN is applied to learn contextual information for classification.


The main contribution of the proposed Riemannian complex HPD convolution network can be summarized as three aspects.
\begin{itemize}
\item[1)] A new complex HPD unfolding network is proposed for PolSAR image in Riemann space for the first time. It redefines the complex HPD unfolding mapping layer, Rectifying layer and LogEig layer. This network ensures that the resulting matrix is still in complex HPD manifold, which can effectively learn intensity and phase information from the PolSAR manifold data and maintain the geometry structure of complex matrix.
\item[2)] To reduce the calculation complexity of the eigenvalue decomposition for complex HPD matrix, a revised complex HPD iteration model is defined to accelerate the network and perform parallel conduction on GPU.
\item[3)] To learn high-level semantic features, a network framework is designed to learn complex HPD matrices from Riemann to Euclidean, which consists of a complex HPDnet and CV-3DCNN, followed by a softmax classifier. This can not only learn geometry information of complex matrix in Riemann space, but also learn contextual high-level semantic in Euclidean space.
%\item[4)] Experiments are conducted on three sets of real PolSAR data, and experimental results demonstrates the effectiveness of the proposed method on discriminating both edges and heterogeneous regions.
\end{itemize}
  This paper is organized as follows. Section 1 is the Introduction. The preliminary is introduced in Section 2. The proposed methodology is given in Section 3. Experimental results and analysis are described in Section 4. Section 5 is the conclusion.

\begin{figure*}
	\centering
	\setlength{\fboxrule}{0.2pt}
	\setlength{\fboxsep}{0.01mm}
	\includegraphics[height=0.17\textheight]{figures/fig2.png}
	\caption{The framework of the proposed Riemannian complex HPD convolution network.}
	\label{fig2}
\end{figure*}

\section{Preliminary}

\iffalse
\subsection{Euclidean Deep learning methods}

Recently, deep learning models have dominated the development of PolSAR image classification and exhibits excellent performance. Amount of deep learning methods have been proposed to learn PolSAR features in Euclidean space. However, for PolSAR data, each resolution unit is a $3\times 3$ covariance matrix. To apply the PolSAR data to Euclidean deep learning framework, the PolSAR covariance matrix is commonly converted into a 9-dimensional real vector as the network input. Commonly used network frameworks include CNN\cite{10538121}, GCN\cite{shi2023cnn}, SAE\cite{10201469}, U-net\cite{wu2023}, Transformer\cite{10422857} and so on. For example, Hua et al.\cite{9172110} proposed three-channel CNN, which can learn different channel features. Ren et al.\cite{10296522} gave increasing learning method to improve the classification performance for unbalanced samples. Dong et al.\cite{10360854} proposed a causal inference-guided feature enhancement framework, which can better learn effective features for PolSAR image classification. Shi et al.\cite{shi2023cnn} gave CNN enhanced fuzzy GCN method to improve edge classification. Wang et al.\cite{10401978} proposed a superpixel-based multi-scale GCN to learn different scale terrain objects, enhancing classification performance. Geng et al.\cite{10422857} gave a hierarchical scattering-spatial interaction transformer method for PolSAR image classification.


 However, these deep learning methods ignore phase information of radar scattering. To better learn phase information, complex-valued CNN model is proposed for PolSAR images. Further, many complex-valued variants are proposed for learning complex-valued information. For example, Tan et al.\cite{8864110} proposed a complex-valued 3D-CNN method to learn 3D image block. Li et al.\cite{2019Complex} further proposed a complex countlet CNN model, simultaneously learning complex frequency domain and spatial texture information. Jiang et al.\cite{jiang2022unsupervised} proposed an unsupervised complex-valued sparse feature learning method, which defined an enforcing population and lifetime sparsity model to learn  non-redundant features for PolSAR image classification. Liu et al.\cite{liu2023unified} gave a uniform framework to joint learn features from multi-polarimtric and dual-frequency SAR to enhance classification. These complex-valued networks can learn complex phase information by converting complex matrix into a complex-valued vector. However, these transformations also destroy the matrix structure and channel correlation, so that they cannot learn the geometric characteristics of complex matrices. Therefore, a complex matrix-based deep network should be exploited for PolSAR data.

\subsection{Remaninian Deep learning methods}

Recently, considering the characteristics of SPD matrix, SPD-based Riemann deep learning theory and methods have been proposed and widely applied in the field of computer vision. For instance, Fiori et al.\cite{fiori2011riemannian} gave the Riemann-gradient-based learning on the complex matrix hypersphere, which provides the fundamental theory of Riemann deep learning. Chakraborty et al.\cite{chakraborty2015recursive} proposed a recursive Frechet mean computation method on Grassmannian manifold, also being applied to tasks of computer vision. Based on these foundations, Huang et al.\cite{huang2017riemannian} proposed a Riemann network for SPD matrix learning for the first time. Then, they further gave deep learning method on Lie groups for skeleton-based action recognition. Chakraborty et al.\cite{chakraborty2018statistical} proposed a statistical recurrent model on SPD matrices. Then, some deep learning variants on SPD matrix in Riemann space are proposed successively. Zhang et al.\cite{zhang2020deep} gave deep manifold-to-manifold transforming network for action recognition. Wang et al.\cite{wang2021symnet} proposed a lightweight SPD manifold learning method for image classification. Sukthanker et al.\cite{sukthanker2021neural} proposed a network structural searching method for SPD manifold. Wang et al.\cite{wang2020multiple} gave a multi-kernel metric learning method to construct manifold-valued descriptors. Chakraborty et al.\cite{chakraborty2020manifoldnet} gave a manifoldnet and found its applications in computer vision. Chen et al.\cite{chen2023riemannian} proposed an optimization method for Riemann manifold network to reduce the matrix computing time. These SPD matrix-based manifold learning methods can learn geometric structures of SPD matrices and gave better representation capability for complicated manifold data. However, these methods are based on SPD matrix, which is not totally suitable for PolSAR HPD matrix, as the HPD matrix, consisting of real and imagery matrices, is a more complex representation and has more complex computation during deep network than the SPD matrix. Besides, the imagery part stands for the essential phase information, which cannot be ignored. So, constructing a novel HPD-based manifold learning network is the necessary for PolSAR image classification.
\fi

This section gives a brief introduction of SPD manifold and SPD network(SPDnet).
SPD manifold is defined as: An $n\times n$ real matrix \textbf{X} is symmetric and positive definite, then a set of $n\times n$ SPD matrices can span an SPD manifold $\mathcal{S^+}$. SPDnet is defined in Riemann manifold, which consists of a set of basic SPD layers to convert the original SPD matrix to another SPD manifold. The main network layers include the Bimap layer (like convolution layer in Euclidean space), ReEig layer(like Relu layer) and LogEig layer. LogEig layer can convert SPD matrix in Riemann space to Euclidean space, so that the Euclidean operations can be employed.
%Let the input is an SPD matrix $\textbf{X_k} \in \mathcal{S^+}$, a transformation matrix is ${W_k} = {\mathcal{S}^{m \times n}}$. $\textbf{X_k}$ can be the decomposition of the eigenvalue as ${\bf{X_k = U_k}}\Lambda_k {\bf{U_k}}$.

\textbf{BiMap layer}: This layer can generate a more compact and discriminating SPD matrix using a translating matrix $W_k$ with a linear transformation. The BiMap operation is defined as:
\begin{equation}
{\bf{X_k} = {\bf{W_k}X_{k-1}{W_k}}}
\end{equation}


To maintain the SPD manifold in the network, the output $X_{k}$ should also be an SPD matrix. It is required $W_k$ to be row full-rank. This mapping can convert original SPD matrix into another SPD manifold space with better discrimination capability.

\textbf{ReEig Layer}: This layer is similar to a nonlinear operation in deep learning, defined as
\begin{equation}
{X_k} = {U_{k - 1}}\max \left( {\varepsilon I,{\Lambda _{k - 1}}} \right)U_{k - 1}^T
\end{equation}
where $\varepsilon $ is a threshold and \textbf{I} is the identity matrix. This nonlinear operation removes eigenvalues with too small or negative values.

\textbf{LogEig layer}: This layer can project the SPD matrix from the Riemann manifold into a tangent space, in which Euclidean metrics and algorithms can be applied. LogEig layer is complemented by matrix logarithm operation, defined as:
\begin{equation}
{X_k} = {U_{k - 1}}\log \left( {{\Lambda _{k - 1}}} \right)U_{k - 1}^T
\end{equation}

\iffalse
\textbf{Differences between SPDnet and the proposed method:}

 There are four key differences between our method and the SPDnet. 1) We propose a complex HPD manifold network for PolSAR images for the first time. PolSAR data itself is a complex HPD matrix endowed in Riemann manifold, while the SPDnet is defined for natural images which needs to convert features to a real SPD matrix. 2) The proposed HDP unfolding network fully consider the real and imagery matrices of the PolSAR covariance matrix, while the SPDnet only learn the real matrix. 3) A fast eigenvalue decomposition method is designed for HPD matrix in the ReEig and LogEig layers, to accelerate the HPD network learning. 4) Our method combines the HPDnet in Riemann space and complex-valued CNN network in Euclidean space together, which can learn both geometry features in manifold space and contextual semantic in Euclidean space. The SPDnet ignores contextual relationship among SPD matrices.
 \fi


\section{Proposed method}
%, of which the framework is shown in Fig.x.
In this paper, we propose a novel complex Hermitian Positive Definite Manifold Network (HPD\_CNN) for Polarimetric SAR image classification, of which the framework is shown in Fig.\ref{fig2}. The proposed method consists of two modules: the complex HPD unfolding network and Riemannian-to-Euclidean CV-3DCNN enhanced network. Firstly, to learn HPD matrix, the HPD covariance matrix is unfolded as the addition of real-part and imagery-part matrices. Then, a complex HPD unfolding network is designed by defining the HPD mapping layer, non-linear HPD Rectifying layer and complex HPD LogEig layer. Thus, the HPD matrix is transferred from Riemann to Euclidean space by tangent space mapping with the LogEig operation. Then, the learned HPD matrix is converted into a complex-valued vector, and a CV-CNN module is followed to learn contextual information to enhance feature representation. Finally, a softmax classifier is utilized to obtain the final result.


\subsection{ PolSAR HPD matrix representation}
PolSAR system is imaging by emitting and receiving electromagnetic waves with four polarimteric mode. So, the scattering matrix is represented by
\begin{equation}
{\bf{S}} = \left[ {\begin{array}{*{20}{c}}
   {{S_{hh}}} & {{S_{hv}}}  \\
   {{S_{vh}}} & {{S_{vv}}}  \\
\end{array}} \right]
\end{equation}
where $S_{hh}$ is the scattering waves from antenna of horizontal emitting and horizontal receiving mode. Under the assumption of reciprocity, $S_{hv}=S_{vh}$. Generally, $\textbf{S}$ can be vectorized as $k = \left[ {{S_{hh}},\sqrt 2 {S_{hv}},{S_{vv}}} \right]$. After multi-look processing, a covariance matrix can be achieved by
\begin{equation}
{\bf{C}} = \left[ {\begin{array}{*{20}{c}}
{{C_{11}}}&{{C_{12}}}&{{C_{13}}}\\
{{C_{21}}}&{{C_{22}}}&{{C_{23}}}\\
{{C_{31}}}&{{C_{32}}}&{{C_{33}}}
\end{array}} \right]
\end{equation}

Since each non-diagonal element is a complex-valued data. Therefore, the covariance matrix $\textbf{C}$ can be unfolded as
\begin{equation}
 \tiny
{\bf{C}} = \left[ {\begin{array}{*{20}{c}}
{{C_{11}}}&{\Re \left( {{C_{12}}} \right)}&{\Re \left( {{C_{13}}} \right)}\\
{\Re \left( {{C_{21}}} \right)}&{{C_{22}}}&{\Re \left( {{C_{23}}} \right)}\\
{\Re \left( {{C_{31}}} \right)}&{\Re \left( {{C_{32}}} \right)}&{{C_{33}}}
\end{array}} \right] + j\cdot\left[ {\begin{array}{*{20}{c}}
0&{\Im \left( {{C_{12}}} \right)}&{\Im \left( {{C_{13}}} \right)}\\
{\Im \left( {{C_{21}}} \right)}&0&{\Im \left( {{C_{23}}} \right)}\\
{\Im \left( {{C_{31}}} \right)}&{\Im \left( {{C_{32}}} \right)}&0
\end{array}} \right]
\end{equation}


\subsection{ Complex HPD unfolding network}
Traditional SPD network in Riemann space only learn the covariance matrix as a real matrix, which did not fully consider complex-matrix structure and characteristics of real part and imagery part. To learn manifold structure of HPD matrix well, we design a complex HPD unfolding network to better learn the real and imagery information of HPD matrix. The HPD unfolding network consists of complex HPD mapping layer, complex HPD Rectifying layer and LogEig layer. In addition, a fast eigenvalue decomposition method is designed for HPD matrices.

\emph{1) Complex HPD mapping layer}

Inspired by SPDnet, the matrix mapping layer can map an HPD matrix from one HPD manifold to another one. However, in order to learn geometry manifold features, it should be ensured that the mapped manifold should also be HPD. Here, considering each covariance matrix is HPD, we unfold an HPD matrix into the addition of real and complex matrices. Given a complex HPD convolution kernel $W_k$, the complex HPD matrix mapping layer can be defined as

\begin{equation}\label{4}
\small
 \begin{array}{l}
{X_k} = {f_m}\left( {{W_k},{X_{k - 1}}} \right) = {W_k}{X_{k - 1}}W_k^H\\
 = \left( {\Re \left( {{W_k}} \right) + j\Im \left( {{W_k}} \right)} \right)\left( {\Re \left( {{X_{k - 1}}} \right) + j\Im \left( {{X_{k - 1}}} \right)} \right){\left( {\Re \left( {{W_k}} \right) - j\Im \left( {{W_k}} \right)} \right)^T}\\
 = \left( {\Re \left( {{W_k}} \right)\Re \left( {{X_{k - 1}}} \right)\Re {{\left( {{W_k}} \right)}^T} - \Im \left( {{W_k}} \right)\Im \left( {{X_{k - 1}}} \right)\Re {{\left( {{W_k}} \right)}^T}} \right.\\
\left. { + \Re \left( {{W_k}} \right)\Im \left( {{X_{k - 1}}} \right)\Im {{\left( {{W_k}} \right)}^T} + \Im \left( {{W_k}} \right)\Re \left( {{X_{k - 1}}} \right)\Im {{\left( {{W_k}} \right)}^T}} \right)\\
 + j\left( { - \Re \left( {{W_k}} \right)\Re \left( {{X_{k - 1}}} \right)\Im {{\left( {{W_k}} \right)}^T} + \Im \left( {{W_k}} \right)\Im \left( {{X_{k - 1}}} \right)\Im {{\left( {{W_k}} \right)}^T}} \right.\\
\left. { + \Re \left( {{W_k}} \right)\Im \left( {{X_{k - 1}}} \right)\Re {{\left( {{W_k}} \right)}^T} + \Im \left( {{W_k}} \right)\Re \left( {{X_{k - 1}}} \right)\Re {{\left( {{W_k}} \right)}^T}} \right)
\end{array}
\end{equation}
where $f_m$ is the mapping function, $\textbf{W}_k$ is a complex convolution kernel. $\textbf{W}_k$ can be unfolded as ${{\bf{W}}_k} = \Re \left( {{{\bf{W}}_k}} \right) + j \cdot \Im \left( {{{\bf{W}}_k}} \right)$. After unfolding mapping, the obtained output $\textbf{W}_k$ should also an HPD matrix. In addition, to ensure $\textbf{X}_k$ is a valid HPD matrix, $\textbf{W}_k$ is required as the row full-rank matrix\cite{wang2021symnet}.%, which can be proved in Theorem 1.

%\textbf{Theorem 1:}

\emph{2)Complex HPD Rectifying layer}

After matrix mapping layer, the original HPD matrix is converted to a new manifold feature space. However, the HPD mapping layer is similar to the linear mapping in SPDnet. A non-linear rectifying is necessary to enhance the discriminating ability of the mapping features. With non-linear rectifying, the original HPD matrix can be mapped to a new space with better separability. Here, we define a nonlinear function $f_r$ to rectify the result from the mapping layer, denoted by
\begin{equation}\label{e8}
\small
\begin{array}{l}
{X_k} = {f_r}\left( {{X_{k - 1}}} \right) = {U_{k - 1}}{f_r}\left( {{\Lambda _{k - 1}}} \right)U_{k - 1}^H\\
 = \left( {\Re \left( {{U_{k - 1}}} \right) + j\Im \left( {{U_{k - 1}}} \right)} \right){f_r}\left( {{\Lambda _{k - 1}}} \right){\left( {\Re \left( {{U_{k - 1}}} \right) - j\Im \left( {{U_{k - 1}}} \right)} \right)^T}\\
 = \left( {\Re \left( {{U_{k - 1}}} \right){f_r}\left( {{\Lambda _{k - 1}}} \right)\Re {{\left( {{U_{k - 1}}} \right)}^T} - \Im \left( {{U_{k - 1}}} \right){f_r}\left( {{\Lambda _{k - 1}}} \right)\Im {{\left( {{U_{k - 1}}} \right)}^T}} \right)\\
 + j\left( {\Im \left( {{U_{k - 1}}} \right){f_r}\left( {{\Lambda _{k - 1}}} \right)\Re {{\left( {{U_{k - 1}}} \right)}^T} + \Re \left( {{U_{k - 1}}} \right){f_r}\left( {{\Lambda _{k - 1}}} \right)\Im {{\left( {{U_{k - 1}}} \right)}^T}} \right)
\end{array}
\end{equation}
$f_r$ is defined based on the eigenvalue decomposition, where eigenvalues are rectified if they are less than a threshold. So, ${f_r}\left( {{\Lambda _{k - 1}}} \right) = {U_{k - 1}}\max \left( {\tau I,{\Lambda _{k - 1}}} \right)U_{k - 1}^H$. ${\Lambda _{k - 1}}$ is the eigenvalues and $\tau $ is the threshold. Then, $\max \left( {\tau I,{\Lambda _{k - 1}}} \right)$ can be written as:
\begin{equation}\label{e9}
\max {\left( {\tau I,{\Lambda _{k - 1}}} \right)_{ii}} = \left\{ {\begin{array}{*{20}{c}}
{{{\left( {{\Lambda _{k - 1}}} \right)}_{ii}},   if{\rm{  }}{{\left( {{\Lambda _{k - 1}}} \right)}_{ii}} > \tau }\\
{{{\left( {{\Lambda _{k - 1}}} \right)}_{ii}},   otherwise.       }
\end{array}} \right.
\end{equation}

Here, we give $\tau$ as a positive number and above the smallest eigenvalue, which ensures the rectifying layer is the nonlinear operation. After rectifying, the resulting matrices are still HPD.

The complex HPD mapping layer and rectifying layer can be considered as the convolution and ReLu layer similar to CNN. However, they transfer complex HPD matrix from one manifold to another. After applying multiple mapping and rectifying layers, a discriminating feature in Riemann space can be achieved, which maintains the geometric structure of PolSAR data and increases the discriminating ability of different classes.

\emph{3)complex HPD LogEig layer}

After multiple layers of nonlinear operations, the manifold HPD features are generated. Then, a fully connected operation is used to integrate all the features for classification. Since the existing classifier, such as the softmax classifier, is utilized in Euclidean space. To flatten the HPD matrices from Riemann to Euclidean space, a logarithm operation is defined to convert the HPD matrix from manifold space into tangent space, in which Euclidean operations can be utilized. Here, we define a complex HPD matrix logarithm function $f_{log}$ to convert manifold data to the flat tangent space, denoted by:
\begin{equation}\label{e10}
\begin{array}{l}
{X_k} = {f_{\log }}\left( {{X_{k - 1}}} \right) = \log m\left( {{X_{k - 1}}} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = {U_{k - 1}}diag\left( {\log\left( {{\Lambda _{k - 1}}} \right)} \right)U_{k - 1}^H
\end{array}
\end{equation}
where ${X_{k - 1}} = {U_{k - 1}}{\Lambda _{k - 1}}U_{k - 1}^H$ is the matrix's eigenvalue decomposition. $diag\left( {\log \left( {{\Lambda_{k - 1}}} \right)} \right)$ is to convert ${\log\left( {{\Lambda_{k - 1}}} \right)}$ to a diagonal matrix.

\emph{4)Fast eigenvalue decomposition}

Generally, SVD decomposition is utilized to obtain the eigenvalues and eigenvector. It can be observed that both the complex HPD Rectifying and LogEig layers need the SVD decomposition of the complex HPD matrix. However, for a complex HPD matrix, SVD decomposition is time-consuming since the complex operation of matrix inversion and trace, especially for back-propagation, is difficult to compute during the reversing process. To address this issue, we utilize an ASQRT method\cite{li2018towards}, which is based on the Newton-Schulz iteration. The ASQRT method can greatly reduce computation time, since it only needs matrix multiplication instead of matrix inversion. These multiplication operations can be effective and fast to be conducted on GPU with parallel implementation. The SVD decomposition of the covariance matrix can be approximately calculated by Newton-Schulz iteration\cite{li2018towards}. To be specific, if we want to compute the square root $X$ of $C$. We can initialize ${X_0}=C$, and ${Z_0}=I$. Then, the coupled iteration can be calculated by :
\begin{equation}\label{e11}
\begin{array}{l}
{X_k} = \frac{1}{2}{X_{k - 1}}\left( {3I - {Z_{k - 1}}{X_{k - 1}}} \right)\\
{Z_k} = \frac{1}{2}\left( {3I - {Z_{k - 1}}{Y_{k - 1}}} \right){Z_{k - 1}}
\end{array}
\end{equation}

This procedure can obtain the approximation solution with a small number of iterations. However, this method is suitable for the real matrix. To expand them into the complex HPD matrix, we proposed a complex matrix-based ASQRT method(CM-ASQRT), which unfolds these equations by defining each matrix as an HPD matrix with real and imagery parts. That is, assume ${\bf{X_{k-1}}} = {\bf{C}} = \Re \left( {\bf{C}} \right) + j\Im \left( {\bf{C}} \right)$, and ${\bf{Z}} = \Re \left( {\bf{I}} \right) + j{\bf{0}}$. Then, the unfolded iteration can be rewritten by Equ.(\ref{e1}).
\begin{figure*}[hb]
\centering
\hrulefill
\vspace{8pt}
\begin{equation}\label{e1}
\tiny
\begin{array}{l}
{{\bf{X}}_k} = \frac{1}{2}{{\bf{X}}_{k - 1}}\left( {3{\bf{I}} - {{\bf{Z}}_{k - 1}}{{\bf{X}}_{k - 1}}} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{1}{2}\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)\left( {3\left( {\Re \left( {\bf{I}} \right) + j{\bf{0}}} \right) - \left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{1}{2}\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right) \times 3\left( {\Re \left( {\bf{I}} \right) + j{\bf{0}}} \right) - \frac{1}{2}\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right) \times \left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{3}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {\bf{I}} \right) + j\left( {3\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {\bf{I}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  - \frac{1}{2}\left( \begin{array}{l}
\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) - \Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) - \Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) - \Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\\
j\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) + \Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) + \Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) - \Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)
\end{array} \right)
\end{array}
\end{equation}

\begin{equation}\label{e2}
\tiny
\begin{array}{l}
\Re \left( {{{\bf{X}}_k}} \right) = \frac{3}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {\bf{I}} \right) - \frac{1}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) + \frac{1}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\\
\Im \left( {{{\bf{X}}_{k - 1}}} \right) = 3\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {\bf{I}} \right) - \frac{1}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) - \frac{1}{2}\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) - \frac{1}{2}\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)
\end{array}
\end{equation}

\end{figure*}
Therefore, the real and imagery part of ${{\bf{X}}_k}$ can be derived by Eq.(\ref{e2}).


Similar,  ${{\bf{Z}}_k}$ can be derived by Equ.(\ref{e3}).

\begin{figure*}
\centering
\begin{equation}\label{e3}
\tiny
\begin{array}{l}
{{\bf{Z}}_k} = \frac{1}{2}\left( {3{\bf{I}} - {{\bf{Z}}_{k - 1}}{{\bf{X}}_{k - 1}}} \right){{\bf{Z}}_{k - 1}}\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{1}{2}\left( {3\left( {\Re \left( {\bf{I}} \right) + j{\bf{0}}} \right) - \left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)} \right)\left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{3}{2}\left( {\Re \left( {\bf{I}} \right) + j{\bf{0}}} \right)\left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right) - \frac{1}{2}\left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\left( {\Re \left( {{{\bf{X}}_{k - 1}}} \right) + j\Im \left( {{{\bf{X}}_{k - 1}}} \right)} \right)\left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + j\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  = \frac{3}{2}\Re \left( {\bf{I}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + \frac{3}{2}j\left( {\Re \left( {\bf{I}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  - \frac{1}{2}\left( \begin{array}{l}
\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) - \Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) - \Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right) - \Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\\
j\left( {\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right) + \Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + \Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) - \Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)} \right)
\end{array} \right)
\end{array}
\end{equation}

\begin{equation}\label{e4}
\tiny
\begin{array}{l}
\Re \left( {{{\bf{X}}_k}} \right) = \frac{3}{2}\Re \left( {\bf{I}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) - \frac{1}{2}\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + \frac{1}{2}\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\\
\Im \left( {{{\bf{X}}_{k - 1}}} \right) = \frac{3}{2}\Re \left( {\bf{I}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right) - \frac{1}{2}\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right) - \frac{1}{2}\Re \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) - \frac{1}{2}\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Re \left( {{{\bf{X}}_{k - 1}}} \right)\Re \left( {{{\bf{Z}}_{k - 1}}} \right) + \frac{1}{2}\Im \left( {{{\bf{Z}}_{k - 1}}} \right)\Im \left( {{{\bf{X}}_{k - 1}}} \right)\Im \left( {{{\bf{Z}}_{k - 1}}} \right)
\end{array}
\end{equation}
\vspace{8pt}
\hrulefill
\end{figure*}

Therefore, the real and imagery part of ${{\bf{Z}}_k}$ can be derived by Eq.(\ref{e4}).


After several iterations, the SVD decomposition can be approximately obtained. It has been demonstrated\cite{li2018towards} that no more than 5 iterations can obtain good performance under deep learning architecture. Here, we select 5 as the iteration number.

%\textcolor{red}{After Newton-Schulz iteration, a corresponding post compensation is performed based on F-norm, defined as:}
%\begin{equation}\label{}
% {X_F} = \frac{1}{{\left\| {{X_7}} \right\|{}_F}}{X_7}\\
% X_7^{\frac{1}{2}} = \sqrt {\left\| {{X_7}} \right\|{}_F} {P_k}
%\end{equation}
% where X7 is a resulting matrix after 3 sets of HPD mapping and ReEig operations and a Log-Eig mapping operation.
\vspace{-10pt}
\subsection{Complex-valued 3D-CNN enhanced classification}
After log-Eig operation, the complex HPD matrix in Riemann space can be projected to the tangent space, in which Euclidean operations can be utilized directly. Thus, the HPD covariance matrix can be learned from Riemann to Euclidean space. Then, a CV-3DCNN network architecture is utilized to learn contextual information about complex-valued data in Euclidean space.
%The framework of CV-3DCNN is illustrated in the right-hand side of Fig.x.
In this model, the HPD matrix in each pixel is converted into a complex-valued vector. An image block can be represented by a complex-valued 3D tensor, noted by $I \in {\mathcal{C}^{N \times N \times 6}}$. $N\times N$ is the image block size and 6 is the scattering channel number of complex matrix. Then, CV-3DCNN can learn both spatial and scattering information simultaneously. It consists of CV-3D convolution, activation and pooling layers.

1)\textit{CV-3D convolution layer}: For the input image block \textbf{I}, for $i$th layer convolution, assuming a set of filter bands is defined as $w \in \mathcal{C}$ and the bias is ${b_i} \in \mathcal{C}$, where the size of filter bands is ${M_i} \times {M_i} \times {R_i} \times {K_i}$. ${M_i} \times {M_i}$ is the kernel size in spatial dimension, and ${R_i}$ is the kernel size in channel dimension. ${K_i}$ is the number of filters. Then, the jth($j \in \left( {0, \ldots ,{K_i}} \right)$) feature map in $i$th layer can be calculated by:
\begin{equation}\label{e}
\begin{array}{l}
{f_{ij}} = \Re \left( {{w_{ij}}} \right) * \Re \left( {{f_{i - 1}}} \right) - \Im \left( {{w_{ij}}} \right) * \Im \left( {{f_{i - 1}}} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  + j \cdot \left( {\Re \left( {{w_{ij}}} \right) * \Im \left( {{f_{i - 1}}} \right) - \Im \left( {{w_{ij}}} \right) * \Re \left( {{f_{i - 1}}} \right)} \right)\\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  + \Re \left( {{b_{ij}}} \right) + j \cdot \left( {\Im \left( {{b_{ij}}} \right)} \right)
\end{array}
\end{equation}

According to CV-3D convolution, the later feature maps are connected to various polarimetric data in the previous layers, thus learning multiple scattering features.

2)\textit{Activation layer}: Each convolutional layer is the linear conversion of complex data, then a nonlinear activation function is needed to learn complex nonlinear transformation. The complex-valued Relu is defined as:
\begin{equation}\label{ex}
{\mathop{\rm Re}\nolimits} {\rm{LU}}\left( f \right) = {\mathop{\rm Re}\nolimits} {\rm{LU}}\left( {\Re \left( f \right)} \right) + j \cdot {\mathop{\rm Re}\nolimits} {\rm{LU}}\left( {\Im \left( f \right)} \right)
\end{equation}

3)\textit{Pooling layer}: Pooling layer can reduce data dimension and fuse data features by down-sampling operation. Similar, the real pooling operation can be expanded to Complex data domain, defined as:
\begin{equation}\label{eb}
Pooling\left( f \right) = Pooling\left( {\Re \left( f \right)} \right) + j \cdot Pooling\left( {\Im \left( f \right)} \right)
\end{equation}

 4) \textit{Fully connection and softmax classification}

Fully connected layer attempt to flatten the CV features and convert the CV feature to real-valued features. Here, we flatten the CV cube as a CV vector. Then, real and imagery parts are extracted respectively and connected together. Then, the real-valued feature maps are fed into a fully connected layer. Finally, a softmax classifier is applied to obtain the final classification result, and the cross entropy loss is developed to learn the network. %The whole algorithm procedure is described in \textcolor{red}{Algorithm 1}.


\section{Experimental results and analysis}

\subsection{Experimental data and settings}
\subsubsection{Experimental data}

In this study, two PolSAR images were utilized, each capturing real-world ground objects from different bands and satellites. The specific details for each dataset are given below.

1)Xi'an Dataset: This is a full-polarization C-band image captured over the Xi'an area using the SIA-C/X-SAR system. The spatial resolution is $8\times 8$ meters, and the image size is $512\times 512$ pixels. The land covers within the image include Water, Buildings, and Grass. The PauliRGB image and its corresponding ground truth map are shown in Figs.\ref{f10} (a) and (b), respectively.

2)Oberpfaffenhofen Dataset: This dataset is acquired from the Oberpfaffenhofen area, featuring L-band mulit-look polarimetric SAR data obtained by the E-SAR system of the German Aerospace Center. The spatial resolution of this image is approximately $3\times 3.2$ meters, and the image size is $1300\times 1200$ pixels. Within this image, the predominant land covers consist of bare ground, forest, buildings, farmland and road. The PauliRGB image and its corresponding label map are shown in Figs.\ref{f11} (a) and (b), respectively.

\subsubsection{Experimental settings}

This paper conducts the experiments using the deep learning framework PyTorch (version 1.6.0). All the experiments are conducted on Windows 10 operating system with Intel Core i7-10700F processor, 64 GB of RAM, and an NVIDIA GeForce RTX 3070 graphics card.

The parameters for the network model are set as follows: the learning rate is 0.005, and the training process consists of 50 iterations. The Adam optimizer is used during training. The data set is divided into 10\% for training and 90\% for testing, with the training samples randomly selected. The experimental results presented in this article are averaged over five repeated runs. Some evaluation indicators are calculated to test the performance of the proposed method, including class precision, overall accuracy (OA), average accuracy (AA), Kappa coefficient, and confusion matrix.

To assess the effectiveness of the proposed method, we compare it with other relevant PolSAR image classification approaches, including CV-CNN\cite{9323621}, 3DCNN\cite{rs9010067}, DFGCN\cite{9274334}, AMS-MESL\cite{10097620}, and PolMPCNN\cite{9424197} methods.


\subsection{Experimental results}

We conduct experiments on Xi’an and Oberpfaffenhofen data sets, and compare the proposed method with five state-of-the-art methods. The quantitative results on two datasets are shown in Tables \ref{t1} and \ref{t2} respectively. Furthermore, we present some representative qualitative
comparison results in Figures \ref{f10} and \ref{f11} respectively.
\begin{tiny}
\begin{table}
\footnotesize
\begin{center}
\caption
{ \label{t1}
 Classification accuracy of different methods on Xi'an Data Set(\%).}
\begin{tabular}{p{0.8cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.9cm}p{0.7cm}}%lcccccc
\hline
class&CVCNN&3DCNN&DFGCN&AMS-MESL&PolMPCNN&proposed\\
\hline
water&94.55&90.27&82.93&88.99&\textbf{95.52}&93.51\\
grass&90.68&93.60&90.89&90.35&90.95&\textbf{95.27}\\
building&93.81&93.91&85.79&90.27&\textbf{97.68}&94.55\\
OA&92.37&93.21&87.90&90.12&94.01&\textbf{94.75}\\
AA&93.01&92.60&86.54&89.87&\textbf{94.71}&94.44\\
Kappa&87.51&88.77&87.75&83.68&90.25&\textbf{91.34}\\
\hline
\end{tabular}
\end{center}
\end{table}
\end{tiny}

\begin{tiny}
\begin{table}
	\footnotesize
	\begin{center}
		\caption
		{ \label{t2}
			Classification accuracy of different methods on Oberpfaffenhofen Data Set(\%).}
		\begin{tabular}{p{0.8cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.7cm}p{0.9cm}p{0.7cm}}%lcccccc
			\hline
			class&CVCNN&3DCNN&DFGCN&AMS-MESL&PolMPCNN&proposed\\
			\hline
			bare ground&68.86&\textbf{91.76}&89.37&89.93&86.92&90.36\\
			forest&81.16&84.59&86.47&85.75&82.51&\textbf{86.12}\\
			buildings&87.52&83.91&68.31&78.81&85.82&\textbf{88.54}\\
			farmland&70.49&65.33&37.70&68.51&65.65&\textbf{83.21}\\
			road&\textbf{76.20}&50.34&40.76&60.36&10.38&73.47\\
			OA&74.88&82.82&76.63&82.68&75.82&\textbf{86.94}\\
			AA&76.85&75.19&64.52&76.67&66.26&\textbf{84.34}\\
			Kappa&65.73&74.28&76.62&74.37&63.49&\textbf{81.00}\\
			\hline
		\end{tabular}
	\end{center}
\end{table}
\end{tiny}

\textbf{Quantitative Results:}
It can be observed from Table \ref{t1} that the proposed approach demonstrates the highest classification accuracies in all the OA, AA, and Kappa coefficient. Our method can achieve higher OA than compared methods by 2.38\%, 1.54\%, 6.85\%, 4.63\% and 0.65\%, respectively. Specifically, CV-CNN performs lower accuracy in the grass category. The AMS-MESL method struggles with lower accuracy in all three categories. In the 3DCNN method, the water class is relatively low. The DFGCN shows poor performance in both water and building due to noisy result. The PolMPCNN exhibits excellent performance in both water and building classes owing to the ability to learn multiple channels, while the grass class is low due to misclassification.
Compared to the other five classification algorithms, the proposed method achieves the highest overall accuracy (94.75\%) and Kappa coefficient (91.34\%).

In addition, more obvious advantages can be found in Table \ref{t2} on Oberpfaffenhofen data set. It is a challenging data set since there are extremely unbalanced samples in road class. Many methods failed to classify it, such as 3DCNN, DFGCN and PolMPCNN methods. Our method can obtain similar accuracy as the CVCNN method, at 73.47\%. However, CVCNN has lower accuracies in both bare ground and farmland classes. On the contrary, the proposed method achieves the highest class accuracies in all metrics, and higher OA by 12.06\%, 4.12\%, 10.31\%, 4.26\%, and 11.1\% compared to other methods.

 \begin{figure}
	\centering
	\setlength{\fboxrule}{0.5pt}
	\setlength{\fboxsep}{0.01mm}
      \subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/PauliRGB_xian.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/xian-label.png}}}
	%\subfigure[]{\fbox{\includegraphics[height=0.16\textheight]{figures/Xian-HPD.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-CV-CNN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-3DCNN.png}}}\\
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-DFGCN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-AMS-MESL.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-MPCNN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Xian-HPD+CNN.png}}}\\	
	\includegraphics[height=0.04\textheight]{figures/xian_color.png}
	\caption{Classification results of different method on Xi'an area; (a)Pauli RGB image; (b) The label map of Xi'an area; (c) CV-CNN; (d) 3D-CNN; (e) DFGCN; (f) AMS-MESL; (g) PolMPCNN;(h)Proposed HPD\_CNN.}
	\label{f10}
\end{figure}

\textbf{Qualitative Results:}
The visual results on Xi'an data set have been presented in Figs.\ref{f10}. It can be seen from Fig.\ref{f10} that the proposed HPD\_CNN method can obtain better result in both region homogeneity and edge preservation than other compared methods. CVCNN, 3DCNN, DFGCN and AMS-MESL methods cause some noisy points in the building and grass areas. The PolMPCNN can improve the classification results, while they lose some edge details in water class.

In addition, the visual results on Oberpfaffenhofen data set have been presented in Fig.\ref{f11}. It can be seen that all the compared methods will cause many noisy classes in heterogeneous regions, including suburban and woodland, except the PolMPCNN method. However, the PolMPCNN almost totally loses the road class, misclassifying them into bare ground. Our method can classify various classes well, and greatly improve the classification performance in road class. This demonstrates that our network achieves better manifold characteristics of PolSAR data by the proposed HPDnet than state-of-the-art approaches.


 \begin{figure}
	\centering
	\setlength{\fboxrule}{0.5pt}
	\setlength{\fboxsep}{0.01mm}
      \subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/PauliRGB_Ob.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob_RGB_label.png}}}
	%\subfigure[]{\fbox{\includegraphics[height=0.16\textheight]{figures/Ob-HPD.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob-CV-CNN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob-3DCNN.png}}} \\
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob_DFGCN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob-AMS-MES.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob_PolMPCNN.png}}}
	\subfigure{\fbox{\includegraphics[height=0.08\textheight]{figures/Ob-hpd+cnn.png}}}\\	
	\includegraphics[height=0.02\textheight]{figures/Ob_color.png}
	\caption{Classification results of different method on Oberpfaffenhofen area; (a)Pauli RGB image; (b)The label map of Oberpfaffenhofen area; (c) CV-CNN;  (d) 3D-CNN; (e) DFGCN; (f) AMS-MESL; (g) PolMPCNN; (h)Proposed HPD\_CNN.}
	\label{f11}
\end{figure}


\subsection{Ablation Study and Parameter Analysis}
Ablation studies are conducted on Xi'an and Oberpfaffenhofen data sets to show the importance of each module in the proposed method. In addition, different parameters are discussed to show their effects on classification accuracy.

\textbf{ Ablation study on each module:} The proposed method comprises two essential modules: the HPDnet and the 3D-CVCNN enhanced modules. Here, we evaluate their importance and effects on the final result with OA and Kappa as evaluation metrics. The final classification accuracy is presented in Table \ref{t5}. It can be seen that the HPDnet with the shallow features has a lower accuracy than the 3D-CVCNN model with the high-level features. However, only the 3D-CVCNN is notably lower than the proposed HPD\_CNN model, which indicates that the HPD-based manifold learning is evidently effective for classification. The proposed HPD\_CNN method obtains superior performance by combining both the advantages of the two modules.

\begin{table}
\footnotesize
\begin{center}
\caption
{ \label{t5}
Classification accuracy of different modules on two Data sets(\%).}
\begin{tabular}{p{1.6cm}|p{1.2cm}p{1.2cm}|p{1.2cm}p{1.2cm}}%lcccccc
\hline
Dataset&\multicolumn{2}{c|}{Xi'an}&\multicolumn{2}{c}{Oberpfaffenhofen}\\
\hline
Accuracy&OA&Kappa&OA&Kappa\\
\hline
HPDnet&85.47&75.99&73.48&61.21\\
3D-CVCNN&93.21&88.77&82.82&74.28\\
HPD\_CNN&\textbf{94.75}&\textbf{91.34}&\textbf{86.94}&\textbf{81.00}\\
\hline
\end{tabular}
\end{center}
\end{table}

\iffalse
\textbf{Effect of the ratio of training samples:}
The ratio of training samples is a crucial parameter for deep learning. In this study, we tested the effect of sample ratio on classification performance by varying the sample ratio from 1\% to 15\% with an interval of 3\%, as shown in Fig.\ref{fig14}. The experiments are conducted on Xi'an dataset. It is observed that, when the ratio of training samples increase from 1\% to 10\%, there is a significant improvement in OA, then it grows slowly. Therefore, we select 10\% as the ratio of training samples.
\begin{figure}[hb]
	\centering
	\setlength{\fboxrule}{0.2pt}
	\setlength{\fboxsep}{0.01mm}
	\includegraphics[height=0.13\textheight]{figures/ratio.png}
	\caption{The effect of ratio of training samples on Xi'an dataset.}
	\label{fig14}
\end{figure}
\fi

\textbf{Effect of the patch size on classification performance:}
The patch size is a crucial parameter of the proposed HPD\_CNN model. A small patch can reduce computing time greatly, while too small patch may lose semantic information. In this experiment, we test different patch sizes with $9\times 9$, $13\times 13$, $17\times 17$,respectively. The effect of different patch size on classification accuracy can be shown in Table \ref{t4} on Xi'an dataset. According to the table, we can see that the OA values grow fast from  $9\times 9$ to $13\times 13$, while $13\times 13$ can achieve a similar accuracy with less computing cost than $17\times 17$. Therefore, we select the patch size as $13\times 13$.
\begin{table}
\footnotesize
\begin{center}
\caption
{ \label{t4}
 The effect of different patch size on Xi'an dataset(\%).}
\begin{tabular}{p{1.5cm}p{1cm}p{1cm}p{1cm}}%lcccccc
\hline
patch size&$9\times 9$&$13\times 13$&$17\times 17$\\
\hline
OA&91.84&94.75&95.35\\
AA&90.89&94.44&94.61\\
Kappa&88.76&90.25&91.15\\
\hline
\end{tabular}
\end{center}
\end{table}

\textbf{Analysis of running time:}
We utilize the Xi'an data set to analyze the running time of compared and proposed methods. Table \ref{t6} presents the training and testing times. In particular, the PolMPCNN exhibits the longest training and test times, which can be attributed to its input feature dimension and large-scale convolution. On the other hand, the 3D-CVCNN demonstrates the shortest training time with 3D calculation. The proposed method can obtain the best classification performance within a relatively short time, demonstrating the effectiveness of the proposed method in terms of both time efficiency and performance.

\vspace{-10pt}
\begin{table}
	\footnotesize
	\begin{center}
		\caption
		{ \label{t6}
			Running time of different methods on Xi'an Data Set ($s$)}
		\begin{tabular}{p{0.8cm}p{0.8cm}p{0.8cm}p{0.8cm}p{1cm}p{0.8cm}p{0.8cm}}%lcccccc
			\hline
			time&CVCNN&3DCNN&DFGCN&AMS-MESL&MPCNN&proposed\\
			\hline
			train&3463.20&121.84&475.62&345.50&26100.35&152.35\\
			test&38.43&22.80&7.85&3.12&327.53&7.98\\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\section{Conclusion}

This paper presents a novel Riemannian complex HPD convolution network(HPD\_CNN) for PolSAR image classification. This is the first time to propose a complex HPD manifold network for PolSAR images in Riemann space. The proposed method consists of two modules: a complex HPD unfolding network in Riemann space and a CV-3DCNN network in Euclidean space. The proposed HPDnet can maintain geometric structures effectively by ensuring each operation in the manifold space. Then, a CV-3DCNN network is followed to learn contextual information to reduce speckle noises and enhance feature representation. Experiments demonstrate the proposed method can achieve excellent quantitative and qualitative results than state-of-the-art methods.

\iffalse
\section*{Acknowledgments}

This work was supported in part by the National Natural Science Foundation of China under Grant 62006186,62272383,62372369, in part by the Youth Innovation Team Research Program Project of Education Department in Shaanxi Province under Grant 23JP111.
\fi

%% The file named.bst is a bibliography style file for BibTeX 0.99c
\bibliographystyle{named}
\bibliography{mybibfile}

\end{document}

