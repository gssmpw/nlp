@Article{Einstein,
  author =       "Albert Einstein",
  title =        "{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
                 [{On} the electrodynamics of moving bodies]",
  journal =      "Annalen der Physik",
  volume =       "322",
  number =       "10",
  pages =        "891--921",
  year =         "1905",
  DOI =          "http://dx.doi.org/10.1002/andp.19053221004"
} 

@Book{arpachiDusseau18:osbook,
  author =       {Arpaci-Dusseau, Remzi H. and Arpaci-Dusseau Andrea C.},
  title =        {Operating Systems: Three Easy Pieces},
  publisher =    {Arpaci-Dusseau Books, LLC},
  year =         2015,
  edition =      {1.00},
  note =         {\url{http://pages.cs.wisc.edu/~remzi/OSTEP/}}
}

@InProceedings{waldspurger02,
  author =       {Waldspurger, Carl A.},
  title =        {Memory resource management in {VMware ESX} server},
  booktitle =    {USENIX Symposium on Operating System Design and
                  Implementation (OSDI)},
  year =         2002,
  pages =        {181--194},
  note =         {\url{https://www.usenix.org/legacy/event/osdi02/tech/waldspurger/waldspurger.pdf}}}


%%%%% Authors' references


@inproceedings{Vaswani2017,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
title = {Attention is all you need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@misc{radford2018,
  author       = {Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
  title        = {Improving Language Understanding by Generative Pre-Training},
  year         = {2018},
  howpublished = {\url{https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf}},
  note         = {OpenAI technical report}
}

@misc{radford2019,
  author       = {Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  title        = {Language Models are Unsupervised Multitask Learners},
  year         = {2019},
  howpublished = {\url{https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}},
  note         = {OpenAI preprint}
}


@misc{brown2020,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@misc{hu2023,
  author    = {Krystal Hu},
  title     = {ChatGPT sets record for fastest-growing user base - analyst note},
  howpublished = {\url{https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/}},
  month     = {February},
  year      = {2023},
  note      = {Accessed: 2025-01-19}
}

@misc{cunningham2024bigtech,
  author       = {Michael Cunningham},
  title        = {Big Tech is now all-in on AI agents: A comprehensive look at tech giants’ moves in the agent space},
  howpublished = {\url{https://medium.com/@mcunningham1440/big-tech-is-now-all-in-on-ai-agents-4ccc5970ed57}},
  month        = {December},
  year         = {2024},
  note         = {Accessed: 2025-01-19}
}

@misc{rosenbush2024,
  author       = {Steven Rosenbush},
  title        = {The spotlight in artificial intelligence shifts to autonomous AI agents},
  howpublished = {Wall Street Journal},
  month        = {October},
  day          = {16},
  year         = {2024},
  note         = {Accessed: 2025-01-19},
  url          = {https://www.wsj.com/articles/ai-agents-can-do-more-than-answer-queries-that-raises-a-few-questions-15009853?utm_source=chatgpt.com}
}

@misc{openai2023gpts,
  author       = {OpenAI},
  title        = {Introducing GPTs: Custom versions of ChatGPT for specific purposes},
  howpublished = {\url{https://openai.com/index/introducing-gpts/}},
  month        = {November},
  day          = {6},
  year         = {2023},
  note         = {Accessed: 2025-01-19}
}

@misc{openai2024usagepolicies,
  author       = {OpenAI},
  title        = {Usage Policies},
  howpublished = {\url{https://openai.com/policies/usage-policies/}},
  month        = {January},
  day          = {10},
  year         = {2024},
  note         = {Accessed: 2025-01-19}
}

@misc{ism2024gptstore,
  author       = {Ilias Ism},
  title        = {OpenAI’s GPT Store Flooded With AI Girlfriends Days After Launch},
  howpublished = {\url{https://medium.com/@illyism/openais-gpt-store-flooded-with-ai-girlfriends-days-after-launch-1a0e7ea9983e}},
  month        = {January},
  day          = {15},
  year         = {2024},
  note         = {Accessed: 2025-01-19}
}

@book{kucharavy2024llms,
  editor       = {Andrei Kucharavy and Octave Plancherel and Valentin Mulder and Alain Mermoud and Vincent Lenders},
  title        = {Large Language Models in Cybersecurity: Threats, Exposure and Mitigation},
  publisher    = {Springer Nature},
  year         = {2024},
  address      = {Cham},
  isbn         = {9783031548277},
  doi          = {10.1007/978-3-031-54827-7},
  url          = {https://library.oapen.org/handle/20.500.12657/90897},
  keywords     = {large language models, cybersecurity, cyberdefense, neural networks, societal implications, risk management, LLMs},
  note         = {Open Access under CC BY 4.0.}
}

@inproceedings{Weidinger2022,
author = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
title = {Taxonomy of Risks posed by Language Models},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533088},
doi = {10.1145/3531146.3533088},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {214–229},
numpages = {16},
keywords = {language models, responsible AI, responsible innovation, risk assessment, technology risks},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{Zellers2019,
  author       = {Rowan Zellers and Ari Holtzman and Hannah Rashkin and Yonatan Bisk and Ali Farhadi and Franziska Roesner and Yejin Choi},
  title        = {Defending Against Neural Fake News},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {32},
  year         = {2019},
  editor       = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alché-Buc and E. Fox and R. Garnett},
  pages        = {1--12},
  publisher    = {Curran Associates, Inc.},
  address      = {Vancouver, Canada},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2019/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf}
}

@article{Derner2024,
  author={Derner, Erik and Batistič, Kristina and Zahálka, Jan and Babuška, Robert},
  journal={IEEE Access}, 
  title={A Security Risk Taxonomy for Prompt-Based Interaction With Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={126176-126187},
  keywords={Security;Taxonomy;Chatbots;Large language models;Data models;Codes;Privacy;Natural language processing;Risk analysis;Large language models;security;jailbreak;natural language processing},
  doi={10.1109/ACCESS.2024.3450388}}

@article{gao2024,
  title={A brief survey on safety of large language models},
  author={Gao, Zhengjie and Liu, Xuanzi and Lan, Yuanshuai and Yang, Zheng},
  journal={Journal of computing and information technology},
  volume={32},
  number={1},
  pages={47--64},
  year={2024},
  publisher={Sveu{\v{c}}ili{\v{s}}te u Zagrebu Fakultet elektrotehnike i ra{\v{c}}unarstva},
  doi={10.20532/cit.2024.1005778}
}

@article{sarker2024llm,
  author       = {Sarker, Iqbal H.},
  title        = {LLM Potentiality and Awareness: A Position Paper from the Perspective of Trustworthy and Responsible AI Modeling},
  journal      = {Discover Artificial Intelligence},
  volume       = {4},
  number       = {1},
  pages        = {40},
  year         = {2024},
  month        = {May},
  doi          = {10.1007/s44163-024-00129-0},
  url          = {https://doi.org/10.1007/s44163-024-00129-0},
  issn         = {2731-0809},
  publisher={Springer}
}

@article{ullah2024challenges,
  author       = {Ullah, Ehsan and Parwani, Anil and Baig, Mirza Mansoor and Singh, Rajendra},
  title        = {Challenges and Barriers of Using Large Language Models (LLM) Such as ChatGPT for Diagnostic Medicine with a Focus on Digital Pathology – A Recent Scoping Review},
  journal      = {Diagnostic Pathology},
  volume       = {19},
  number       = {1},
  pages        = {43},
  year         = {2024},
  month        = {February},
  doi          = {10.1186/s13000-024-01464-7},
  url          = {https://doi.org/10.1186/s13000-024-01464-7},
  issn         = {1746-1596},
  abstract     = {The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation.}
}

@misc{bianchi2024safety,
      title={Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions}, 
      author={Federico Bianchi and Mirac Suzgun and Giuseppe Attanasio and Paul Röttger and Dan Jurafsky and Tatsunori Hashimoto and James Zou},
      year={2024},
      eprint={2309.07875},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07875}, 
}

@misc{chehbouni2024,
      title={From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards}, 
      author={Khaoula Chehbouni and Megha Roshan and Emmanuel Ma and Futian Andrew Wei and Afaf Taik and Jackie CK Cheung and Golnoosh Farnadi},
      year={2024},
      eprint={2403.13213},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.13213}, 
}

@misc{openai_safety,
  author       = {OpenAI},
  title        = {OpenAI Safety},
  year         = {2025},
  howpublished = {\url{https://openai.com/safety/}},
  note         = {Accessed: 2025-01-19}
}

@misc{openai2023redteaming,
  author       = {OpenAI},
  title        = {OpenAI Red Teaming Network},
  howpublished = {\url{https://openai.com/index/red-teaming-network/}},
  month        = {September},
  day          = {19},
  year         = {2023},
  note         = {Accessed: 2025-01-19}
}

@misc{rottger2025,
      title={SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety}, 
      author={Paul Röttger and Fabio Pernisi and Bertie Vidgen and Dirk Hovy},
      year={2025},
      eprint={2404.05399},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.05399}, 
}

@misc{xie2024onlinesafety,
      title={Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward}, 
      author={Xuan Xie and Jiayang Song and Zhehua Zhou and Yuheng Huang and Da Song and Lei Ma},
      year={2024},
      eprint={2404.08517},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.08517}, 
}

@misc{xie2024sorrybench,
      title={SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal Behaviors}, 
      author={Tinghao Xie and Xiangyu Qi and Yi Zeng and Yangsibo Huang and Udari Madhushani Sehwag and Kaixuan Huang and Luxi He and Boyi Wei and Dacheng Li and Ying Sheng and Ruoxi Jia and Bo Li and Kai Li and Danqi Chen and Peter Henderson and Prateek Mittal},
      year={2024},
      eprint={2406.14598},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.14598}, 
}

@misc{zhang2024safetybench,
      title={SafetyBench: Evaluating the Safety of Large Language Models}, 
      author={Zhexin Zhang and Leqi Lei and Lindong Wu and Rui Sun and Yongkang Huang and Chong Long and Xiao Liu and Xuanyu Lei and Jie Tang and Minlie Huang},
      year={2024},
      eprint={2309.07045},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07045}, 
}

@misc{yuan2024,
      title={S-Eval: Automatic and Adaptive Test Generation for Benchmarking Safety Evaluation of Large Language Models}, 
      author={Xiaohan Yuan and Jinfeng Li and Dongxia Wang and Yuefeng Chen and Xiaofeng Mao and Longtao Huang and Hui Xue and Wenhai Wang and Kui Ren and Jingyi Wang},
      year={2024},
      eprint={2405.14191},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2405.14191}, 
}

@misc{sun2023safety,
      title={Safety Assessment of Chinese Large Language Models}, 
      author={Hao Sun and Zhexin Zhang and Jiawen Deng and Jiale Cheng and Minlie Huang},
      year={2023},
      eprint={2304.10436},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.10436}, 
}

@misc{huang2024empirical,
      title={An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4}, 
      author={Hui Huang and Yingqi Qu and Xingyuan Bu and Hongli Zhou and Jing Liu and Muyun Yang and Bing Xu and Tiejun Zhao},
      year={2024},
      eprint={2403.02839},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.02839}, 
}

@misc{li2025generation,
      title={From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge}, 
      author={Dawei Li and Bohan Jiang and Liangjie Huang and Alimohammad Beigi and Chengshuai Zhao and Zhen Tan and Amrita Bhattacharjee and Yuxuan Jiang and Canyu Chen and Tianhao Wu and Kai Shu and Lu Cheng and Huan Liu},
      year={2025},
      eprint={2411.16594},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.16594}, 
}

@misc{gu2025surveyllmasajudge,
      title={A Survey on LLM-as-a-Judge}, 
      author={Jiawei Gu and Xuhui Jiang and Zhichao Shi and Hexiang Tan and Xuehao Zhai and Chengjin Xu and Wei Li and Yinghan Shen and Shengjie Ma and Honghao Liu and Yuanzhuo Wang and Jian Guo},
      year={2025},
      eprint={2411.15594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15594}, 
}

@inproceedings{Zheng2023,
  author       = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  title        = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {36},
  year         = {2023},
  editor       = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages        = {46595--46623},
  publisher    = {Curran Associates, Inc.},
  address      = {New Orleans, Louisiana, USA},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf}
}

@misc{huang2024lisa,
      title={Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack}, 
      author={Tiansheng Huang and Sihao Hu and Fatih Ilhan and Selim Furkan Tekin and Ling Liu},
      year={2024},
      eprint={2405.18641},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.18641}, 
}

@misc{qi2023finetuning,
      title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!}, 
      author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
      year={2023},
      eprint={2310.03693},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03693}, 
}

@misc{kumar2024finetuning,
      title={Fine-Tuning, Quantization, and LLMs: Navigating Unintended Outcomes}, 
      author={Divyanshu Kumar and Anurakt Kumar and Sahil Agarwal and Prashanth Harshangi},
      year={2024},
      eprint={2404.04392},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.04392}, 
}

@misc{wang2024learningfailure,
      title={Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents}, 
      author={Renxi Wang and Haonan Li and Xudong Han and Yixuan Zhang and Timothy Baldwin},
      year={2024},
      eprint={2402.11651},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.11651}, 
}

@misc{hsu2025safe,
      title={Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models}, 
      author={Chia-Yi Hsu and Yu-Lin Tsai and Chih-Hsun Lin and Pin-Yu Chen and Chia-Mu Yu and Chun-Ying Huang},
      year={2025},
      eprint={2405.16833},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16833}, 
}

@misc{antebi2024gptsheeps,
      title={GPT in Sheep's Clothing: The Risk of Customized GPTs}, 
      author={Sagiv Antebi and Noam Azulay and Edan Habler and Ben Ganon and Asaf Shabtai and Yuval Elovici},
      year={2024},
      eprint={2401.09075},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.09075}, 
}

@misc{tao2023openingpandoras,
      title={Opening A Pandora's Box: Things You Should Know in the Era of Custom GPTs}, 
      author={Guanhong Tao and Siyuan Cheng and Zhuo Zhang and Junmin Zhu and Guangyu Shen and Xiangyu Zhang},
      year={2023},
      eprint={2401.00905},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.00905}, 
}

@misc{zhang2024lookgptappslandscape,
      title={A First Look at GPT Apps: Landscape and Vulnerability}, 
      author={Zejun Zhang and Li Zhang and Xin Yuan and Anlan Zhang and Mengwei Xu and Feng Qian},
      year={2024},
      eprint={2402.15105},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.15105}, 
}

@misc{su2024gptstoremininganalysis,
      title={GPT Store Mining and Analysis}, 
      author={Dongxun Su and Yanjie Zhao and Xinyi Hou and Shenao Wang and Haoyu Wang},
      year={2024},
      eprint={2405.10210},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.10210}, 
}

@misc{yu2024assessingpromptinjection,
      title={Assessing Prompt Injection Risks in 200+ Custom GPTs}, 
      author={Jiahao Yu and Yuhang Wu and Dong Shu and Mingyu Jin and Sabrina Yang and Xinyu Xing},
      year={2024},
      eprint={2311.11538},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2311.11538}, 
}

@inproceedings{Liu2024,
    author = {Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong},
    title = {A Hitchhiker’s Guide to Jailbreaking ChatGPT via Prompt Engineering},
    year = {2024},
    isbn = {9798400706721},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3663530.3665021},
    doi = {10.1145/3663530.3665021},
    booktitle = {Proceedings of the 4th International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
    pages = {12–21},
    numpages = {10},
    keywords = {Jailbreak, Large language model, Prompt Injection},
    location = {Porto de Galinhas, Brazil},
    series = {SEA4DQ 2024}
}

@misc{puppeteer,
  author       = {Puppeteer},
  title        = {Puppeteer Documentation},
  year         = {2025},
  howpublished = {\url{https://pptr.dev/}},
  note         = {Accessed: 2025-01-19}
}

%% Background

@misc{li2024safety,
  author       = {Shen Li and Liuyi Yao and Lan Zhang and Yaliang Li},
  title        = {Safety Layers in Aligned Large Language Models: The Key to LLM Security},
  year         = {2024},
  howpublished = {\url{https://arxiv.org/abs/2408.17003}},
  note         = {arXiv:2408.17003 [cs.CR]},
}

@misc{phute2023llm,
  author       = {Mansi Phute and Alec Helbling and Matthew Hull and ShengYun Peng and Sebastian Szyller and Cory Cornelius and Duen Horng Chau},
  title        = {LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked},
  year         = {2023},
  howpublished = {\url{https://arxiv.org/abs/2308.07308}},
  note         = {arXiv:2308.07308 [cs.CL]},
}

@misc{ishibashi2023knowledge,
  author       = {Yoichi Ishibashi and Hidetoshi Shimodaira},
  title        = {Knowledge Sanitization of Large Language Models},
  year         = {2023},
  howpublished = {\url{https://arxiv.org/abs/2309.11852}},
  note         = {arXiv:2309.11852 [cs.CL]},
}

@misc{hu2021lora,
  author       = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  title        = {LoRA: Low-Rank Adaptation of Large Language Models},
  year         = {2021},
  howpublished = {\url{https://arxiv.org/abs/2106.09685}},
  note         = {arXiv:2106.09685 [cs.LG]},
}

@article{Hayes2007,
  author    = {Andrew F. Hayes and Klaus Krippendorff},
  title     = {Answering the Call for a Standard Reliability Measure for Coding Data},
  journal   = {Communication Methods and Measures},
  volume    = {1},
  number    = {1},
  pages     = {77--89},
  year      = {2007},
  publisher = {Routledge},
  doi       = {10.1080/19312450709336664},
  url       = {https://doi.org/10.1080/19312450709336664},
  eprint    = {https://doi.org/10.1080/19312450709336664}
}

%% Academic Dishonesty Policies

@misc{ICAI,
  author       = {{International Center for Academic Integrity}},
  title        = {International Center for Academic Integrity},
  year         = 2025,
  url          = {https://academicintegrity.org},
  note         = {Accessed: 2025-03-31}
}

@misc{ENAI,
  author       = {{European Network for Academic Integrity}},
  title        = {European Network for Academic Integrity},
  howpublished = {\url{https://www.academicintegrity.eu/wp/}},
  year         = {2025},
  note         = {Accessed: 2025-03-31}
}

@misc{CU_Denver_Academic_Dishonesty,
  author       = {{University of Colorado Denver, College of Liberal Arts and Sciences}},
  title        = {Definition of Academic Dishonesty},
  year         = {2025},
  howpublished = {\url{https://clas.ucdenver.edu/faculty-staff/policies-procedures/handling-academic-dishonesty/definition-academic-dishonesty}},
  note         = {Accessed: 2025-03-31}
}

@misc{UC_Berkeley_Academic_Misconduct,
  author       = {{University of California, Berkeley, Center for Student Conduct}},
  title        = {Academic Misconduct},
  year         = {2025},
  howpublished = {\url{https://conduct.berkeley.edu/academic-misconduct/}},
  note         = {Accessed: 2025-03-31}
}

@misc{UM_Academic_Integrity,
  author       = {{University of Manitoba}},
  title        = {Academic Integrity},
  year         = {2025},
  howpublished = {\url{https://umanitoba.ca/student-supports/academic-supports/academic-integrity}},
  note         = {Accessed: 2025-03-31}
}

@misc{ENAI_Glossary_2023,
  author       = {Loreta Tauginienė and Inga Gaižauskaitė and Irene Glendinning and Július Kravjar and Milan Ojsteršek and Laura Ribeiro and Tatjana Odiņeca and Franca Marino and Marco Cosentino and Shiva Sivasubramaniam and Tomáš Foltýnek},
  title        = {Glossary for Academic Integrity},
  howpublished = {ENAI Report 3G, revised version},
  year         = {2023},
  url          = {https://www.academicintegrity.eu/wp/wp-content/uploads/2023/02/EN-Glossary_revised_final_24.02.23.pdf},
  note         = {Accessed: 2025-03-31}
}

@misc{NU_Academic_Integrity,
  author       = {{Northeastern University, Office of Student Conduct and Conflict Resolution}},
  title        = {Academic Integrity Policy},
  year         = {2025},
  howpublished = {\url{https://osccr.sites.northeastern.edu/academic-integrity-policy/}},
  note         = {Accessed: 2025-03-31}
}

@misc{VT_Academic_Misconduct,
  author       = {{Virginia Tech, Office of Undergraduate Academic Integrity}},
  title        = {Definitions of Academic Misconduct},
  year         = {2025},
  howpublished = {\url{https://honorsystem.vt.edu/honor_code_policy_test/policy-and-manual/definitions_of_academic_misconduct.html}},
  note         = {Accessed: 2025-03-31}
}

%% Cybersecurity and Privacy Policies

@misc{CISA2021,
  author       = {Cybersecurity and Infrastructure Security Agency},
  title        = {Avoiding Social Engineering and Phishing Attacks},
  year         = 2021,
  url          = {https://www.cisa.gov/news-events/news/avoiding-social-engineering-and-phishing-attacks},
  note         = {Accessed: 2025-04-01}
}

@misc{INTERPOLFinancialCrime,
  author       = {{INTERPOL}},
  title        = {Social engineering scams},
  year         = {2025},
  url          = {https://www.interpol.int/en/Crimes/Financial-crime/Social-engineering-scams},
  note         = {Accessed: 2025-04-01}
}

%% Romantic Companionship Policies

@article{Song2022,
title = {Can people experience romantic love for artificial intelligence? An empirical study of intelligent assistants},
journal = {Information \& Management},
volume = {59},
number = {2},
pages = {103595},
year = {2022},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2022.103595},
url = {https://www.sciencedirect.com/science/article/pii/S0378720622000076},
author = {Xia Song and Bo Xu and Zhenzhen Zhao},
}

@misc{defreitas2024lessons,
  author       = {Julian De Freitas and Noah Castelo and Ahmet Uguralp and Zeliha Uguralp},
  title        = {Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships},
  year         = {2024},
  howpublished = {\url{https://arxiv.org/abs/2412.14190}},
  note         = {arXiv:2412.14190 [cs.HC]},
}

%% Citations for justifying the number of instances for validation

@inproceedings{Harkous2018Polisis,
  title        = {{Polisis}: Automated Analysis and Presentation of Privacy Policies Using Deep Learning},
  author       = {Hamza Harkous and Kassem Fawaz and R{\'e}mi Lebret and Florian Schaub and Kang G. Shin and Karl Aberer},
  booktitle    = {27th USENIX Security Symposium (USENIX Security 18)},
  pages        = {531--548},
  year         = {2018},
  publisher    = {USENIX Association},
  address      = {Baltimore, MD},
  isbn         = {978-1-939133-04-5},
  url          = {https://www.usenix.org/conference/usenixsecurity18/presentation/harkous}
}

@inproceedings{Zimmeck2017Automated,
  title        = {Automated Analysis of Privacy Requirements for Mobile Apps},
  author       = {Sebastian Zimmeck and Ziqi Wang and Lieyong Zou and Roger Iyengar and Bin Liu and Florian Schaub and Shomir Wilson and Norman M. Sadeh and Steven M. Bellovin and Joel R. Reidenberg},
  booktitle    = {Proceedings of the 2017 Network and Distributed System Security Symposium},
  year         = {2017},
  publisher    = {Internet Society},
  address      = {San Diego, CA},
  pages        = {1--15},
  doi          = {10.14722/ndss.2017.23034},
  url          = {https://www.ndss-symposium.org/ndss2017/ndss-2017-programme/automated-analysis-of-privacy-requirements-for-mobile-apps/}
}

@article{Wilson2018Analyzing,
  title        = {Analyzing Privacy Policies at Scale: From Crowdsourcing to Automated Annotations},
  author       = {Shomir Wilson and Florian Schaub and F. Liu and K. M. Sathyendra and D. Smullen and S. Zimmeck and R. Ramanath and P. Story and F. Liu and N. Sadeh and N. A. Smith},
  journal      = {ACM Transactions on the Web},
  volume       = {13},
  number       = {1},
  pages        = {1--29},
  year         = {2018},
  publisher    = {Association for Computing Machinery},
  doi          = {10.1145/3230665},
  url          = {https://dl.acm.org/doi/10.1145/3230665}
}

@inproceedings{MysoreSathyendra2017Identifying,
  title        = {Identifying the Provision of Choices in Privacy Policy Text},
  author       = {Kanthashree Mysore Sathyendra and Shomir Wilson and Florian Schaub and Sebastian Zimmeck and Norman Sadeh},
  booktitle    = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages        = {2774--2779},
  year         = {2017},
  publisher    = {Association for Computational Linguistics},
  address      = {Copenhagen, Denmark},
  doi          = {10.18653/v1/D17-1294},
  url          = {https://aclanthology.org/D17-1294/}
}

@book{weinberg2021statistics,
  title     = {Statistics Using R: An Integrative Approach},
  author    = {Weinberg, Sharon Lawner and Harel, Daphna and Abramowitz, Sarah Knapp},
  year      = {2021},
  publisher = {Cambridge University Press},
  address   = {Cambridge, UK},
  isbn      = {9781108719148}
}

%% Expansion of the Related work

@inproceedings{Shen2024DoAnythingNow,
    author = {Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
    title = {"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models},
    year = {2024},
    isbn = {9798400706363},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3658644.3670388},
    doi = {10.1145/3658644.3670388},
    booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
    pages = {1671–1685},
    numpages = {15},
    keywords = {jailbreak attacks, large language models, prompt analysis},
    location = {Salt Lake City, UT, USA},
    series = {CCS '24}
}

@inproceedings {Yu2024DontListen,
    author = {Zhiyuan Yu and Xiaogeng Liu and Shunning Liang and Zach Cameron and Chaowei Xiao and Ning Zhang},
    title = {Don{\textquoteright}t Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models},
    booktitle = {33rd USENIX Security Symposium (USENIX Security 24)},
    year = {2024},
    isbn = {978-1-939133-44-1},
    address = {Philadelphia, PA},
    pages = {4675--4692},
    url = {https://www.usenix.org/conference/usenixsecurity24/presentation/yu-zhiyuan},
    publisher = {USENIX Association},
    month = aug
}

@misc{yu2024gptfuzzerredteaminglarge,
      title={GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts}, 
      author={Jiahao Yu and Xingwei Lin and Zheng Yu and Xinyu Xing},
      year={2024},
      eprint={2309.10253},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.10253}, 
}

% llm-as-a-judge
@inproceedings{Zheng2023llmasajudge,
    author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
    pages = {46595--46623},
    publisher = {Curran Associates, Inc.},
    address = {New Orleans, LA, USA},
    title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
    url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf},
    volume = {36},
    year = {2023}
}

% Independent annotation after inter-coder agreement

@article{syed2015guidelines,
    title={Guidelines for establishing reliability when coding narrative data},
    author={Syed, Moin and Nelson, Sarah C.},
    journal={Emerging Adulthood},
    volume={3},
    number={6},
    pages={375--387},
    year={2015},
    publisher={SAGE Publications}
}

% Ethics in manual moderation content

@misc{content_moderation_ethics,
  author = {Newton, Casey},
  title = {The Trauma Floor: The secret lives of Facebook moderators in America},
  year = {2019},
  url = {https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona},
  note = {The Verge, February 25}
}


