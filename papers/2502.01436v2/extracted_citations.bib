@article{Derner2024,
  author={Derner, Erik and Batistič, Kristina and Zahálka, Jan and Babuška, Robert},
  journal={IEEE Access}, 
  title={A Security Risk Taxonomy for Prompt-Based Interaction With Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={126176-126187},
  keywords={Security;Taxonomy;Chatbots;Large language models;Data models;Codes;Privacy;Natural language processing;Risk analysis;Large language models;security;jailbreak;natural language processing},
  doi={10.1109/ACCESS.2024.3450388}}

@inproceedings{Liu2024,
    author = {Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Wang, Kailong},
    title = {A Hitchhiker’s Guide to Jailbreaking ChatGPT via Prompt Engineering},
    year = {2024},
    isbn = {9798400706721},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3663530.3665021},
    doi = {10.1145/3663530.3665021},
    booktitle = {Proceedings of the 4th International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
    pages = {12–21},
    numpages = {10},
    keywords = {Jailbreak, Large language model, Prompt Injection},
    location = {Porto de Galinhas, Brazil},
    series = {SEA4DQ 2024}
}

@inproceedings{Shen2024DoAnythingNow,
    author = {Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
    title = {"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models},
    year = {2024},
    isbn = {9798400706363},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3658644.3670388},
    doi = {10.1145/3658644.3670388},
    booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
    pages = {1671–1685},
    numpages = {15},
    keywords = {jailbreak attacks, large language models, prompt analysis},
    location = {Salt Lake City, UT, USA},
    series = {CCS '24}
}

@inproceedings{Weidinger2022,
author = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
title = {Taxonomy of Risks posed by Language Models},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533088},
doi = {10.1145/3531146.3533088},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {214–229},
numpages = {16},
keywords = {language models, responsible AI, responsible innovation, risk assessment, technology risks},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{Zellers2019,
  author       = {Rowan Zellers and Ari Holtzman and Hannah Rashkin and Yonatan Bisk and Ali Farhadi and Franziska Roesner and Yejin Choi},
  title        = {Defending Against Neural Fake News},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {32},
  year         = {2019},
  editor       = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alché-Buc and E. Fox and R. Garnett},
  pages        = {1--12},
  publisher    = {Curran Associates, Inc.},
  address      = {Vancouver, Canada},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2019/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf}
}

@inproceedings{Zheng2023,
  author       = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  title        = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {36},
  year         = {2023},
  editor       = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
  pages        = {46595--46623},
  publisher    = {Curran Associates, Inc.},
  address      = {New Orleans, Louisiana, USA},
  url          = {https://proceedings.neurips.cc/paper_files/paper/2023/file/91f18a1287b398d378ef22505bf41832-Paper-Datasets_and_Benchmarks.pdf}
}

@misc{antebi2024gptsheeps,
      title={GPT in Sheep's Clothing: The Risk of Customized GPTs}, 
      author={Sagiv Antebi and Noam Azulay and Edan Habler and Ben Ganon and Asaf Shabtai and Yuval Elovici},
      year={2024},
      eprint={2401.09075},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.09075}, 
}

@misc{bianchi2024safety,
      title={Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions}, 
      author={Federico Bianchi and Mirac Suzgun and Giuseppe Attanasio and Paul Röttger and Dan Jurafsky and Tatsunori Hashimoto and James Zou},
      year={2024},
      eprint={2309.07875},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07875}, 
}

@misc{chehbouni2024,
      title={From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards}, 
      author={Khaoula Chehbouni and Megha Roshan and Emmanuel Ma and Futian Andrew Wei and Afaf Taik and Jackie CK Cheung and Golnoosh Farnadi},
      year={2024},
      eprint={2403.13213},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.13213}, 
}

@article{gao2024,
  title={A brief survey on safety of large language models},
  author={Gao, Zhengjie and Liu, Xuanzi and Lan, Yuanshuai and Yang, Zheng},
  journal={Journal of computing and information technology},
  volume={32},
  number={1},
  pages={47--64},
  year={2024},
  publisher={Sveu{\v{c}}ili{\v{s}}te u Zagrebu Fakultet elektrotehnike i ra{\v{c}}unarstva},
  doi={10.20532/cit.2024.1005778}
}

@misc{gu2025surveyllmasajudge,
      title={A Survey on LLM-as-a-Judge}, 
      author={Jiawei Gu and Xuhui Jiang and Zhichao Shi and Hexiang Tan and Xuehao Zhai and Chengjin Xu and Wei Li and Yinghan Shen and Shengjie Ma and Honghao Liu and Yuanzhuo Wang and Jian Guo},
      year={2025},
      eprint={2411.15594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.15594}, 
}

@misc{hsu2025safe,
      title={Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models}, 
      author={Chia-Yi Hsu and Yu-Lin Tsai and Chih-Hsun Lin and Pin-Yu Chen and Chia-Mu Yu and Chun-Ying Huang},
      year={2025},
      eprint={2405.16833},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16833}, 
}

@misc{huang2024empirical,
      title={An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4}, 
      author={Hui Huang and Yingqi Qu and Xingyuan Bu and Hongli Zhou and Jing Liu and Muyun Yang and Bing Xu and Tiejun Zhao},
      year={2024},
      eprint={2403.02839},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.02839}, 
}

@misc{huang2024lisa,
      title={Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack}, 
      author={Tiansheng Huang and Sihao Hu and Fatih Ilhan and Selim Furkan Tekin and Ling Liu},
      year={2024},
      eprint={2405.18641},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.18641}, 
}

@book{kucharavy2024llms,
  editor       = {Andrei Kucharavy and Octave Plancherel and Valentin Mulder and Alain Mermoud and Vincent Lenders},
  title        = {Large Language Models in Cybersecurity: Threats, Exposure and Mitigation},
  publisher    = {Springer Nature},
  year         = {2024},
  address      = {Cham},
  isbn         = {9783031548277},
  doi          = {10.1007/978-3-031-54827-7},
  url          = {https://library.oapen.org/handle/20.500.12657/90897},
  keywords     = {large language models, cybersecurity, cyberdefense, neural networks, societal implications, risk management, LLMs},
  note         = {Open Access under CC BY 4.0.}
}

@misc{kumar2024finetuning,
      title={Fine-Tuning, Quantization, and LLMs: Navigating Unintended Outcomes}, 
      author={Divyanshu Kumar and Anurakt Kumar and Sahil Agarwal and Prashanth Harshangi},
      year={2024},
      eprint={2404.04392},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2404.04392}, 
}

@misc{li2025generation,
      title={From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge}, 
      author={Dawei Li and Bohan Jiang and Liangjie Huang and Alimohammad Beigi and Chengshuai Zhao and Zhen Tan and Amrita Bhattacharjee and Yuxuan Jiang and Canyu Chen and Tianhao Wu and Kai Shu and Lu Cheng and Huan Liu},
      year={2025},
      eprint={2411.16594},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.16594}, 
}

@misc{openai2023redteaming,
  author       = {OpenAI},
  title        = {OpenAI Red Teaming Network},
  howpublished = {\url{https://openai.com/index/red-teaming-network/}},
  month        = {September},
  day          = {19},
  year         = {2023},
  note         = {Accessed: 2025-01-19}
}

@misc{openai_safety,
  author       = {OpenAI},
  title        = {OpenAI Safety},
  year         = {2025},
  howpublished = {\url{https://openai.com/safety/}},
  note         = {Accessed: 2025-01-19}
}

@misc{qi2023finetuning,
      title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!}, 
      author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
      year={2023},
      eprint={2310.03693},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.03693}, 
}

@misc{rottger2025,
      title={SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety}, 
      author={Paul Röttger and Fabio Pernisi and Bertie Vidgen and Dirk Hovy},
      year={2025},
      eprint={2404.05399},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.05399}, 
}

@article{sarker2024llm,
  author       = {Sarker, Iqbal H.},
  title        = {LLM Potentiality and Awareness: A Position Paper from the Perspective of Trustworthy and Responsible AI Modeling},
  journal      = {Discover Artificial Intelligence},
  volume       = {4},
  number       = {1},
  pages        = {40},
  year         = {2024},
  month        = {May},
  doi          = {10.1007/s44163-024-00129-0},
  url          = {https://doi.org/10.1007/s44163-024-00129-0},
  issn         = {2731-0809},
  publisher={Springer}
}

@misc{su2024gptstoremininganalysis,
      title={GPT Store Mining and Analysis}, 
      author={Dongxun Su and Yanjie Zhao and Xinyi Hou and Shenao Wang and Haoyu Wang},
      year={2024},
      eprint={2405.10210},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.10210}, 
}

@misc{sun2023safety,
      title={Safety Assessment of Chinese Large Language Models}, 
      author={Hao Sun and Zhexin Zhang and Jiawen Deng and Jiale Cheng and Minlie Huang},
      year={2023},
      eprint={2304.10436},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.10436}, 
}

@misc{tao2023openingpandoras,
      title={Opening A Pandora's Box: Things You Should Know in the Era of Custom GPTs}, 
      author={Guanhong Tao and Siyuan Cheng and Zhuo Zhang and Junmin Zhu and Guangyu Shen and Xiangyu Zhang},
      year={2023},
      eprint={2401.00905},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2401.00905}, 
}

@article{ullah2024challenges,
  author       = {Ullah, Ehsan and Parwani, Anil and Baig, Mirza Mansoor and Singh, Rajendra},
  title        = {Challenges and Barriers of Using Large Language Models (LLM) Such as ChatGPT for Diagnostic Medicine with a Focus on Digital Pathology – A Recent Scoping Review},
  journal      = {Diagnostic Pathology},
  volume       = {19},
  number       = {1},
  pages        = {43},
  year         = {2024},
  month        = {February},
  doi          = {10.1186/s13000-024-01464-7},
  url          = {https://doi.org/10.1186/s13000-024-01464-7},
  issn         = {1746-1596},
  abstract     = {The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation.}
}

@misc{wang2024learningfailure,
      title={Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents}, 
      author={Renxi Wang and Haonan Li and Xudong Han and Yixuan Zhang and Timothy Baldwin},
      year={2024},
      eprint={2402.11651},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.11651}, 
}

@misc{xie2024onlinesafety,
      title={Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward}, 
      author={Xuan Xie and Jiayang Song and Zhehua Zhou and Yuheng Huang and Da Song and Lei Ma},
      year={2024},
      eprint={2404.08517},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.08517}, 
}

@misc{xie2024sorrybench,
      title={SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal Behaviors}, 
      author={Tinghao Xie and Xiangyu Qi and Yi Zeng and Yangsibo Huang and Udari Madhushani Sehwag and Kaixuan Huang and Luxi He and Boyi Wei and Dacheng Li and Ying Sheng and Ruoxi Jia and Bo Li and Kai Li and Danqi Chen and Peter Henderson and Prateek Mittal},
      year={2024},
      eprint={2406.14598},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.14598}, 
}

@misc{yu2024assessingpromptinjection,
      title={Assessing Prompt Injection Risks in 200+ Custom GPTs}, 
      author={Jiahao Yu and Yuhang Wu and Dong Shu and Mingyu Jin and Sabrina Yang and Xinyu Xing},
      year={2024},
      eprint={2311.11538},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2311.11538}, 
}

@misc{yu2024gptfuzzerredteaminglarge,
      title={GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts}, 
      author={Jiahao Yu and Xingwei Lin and Zheng Yu and Xinyu Xing},
      year={2024},
      eprint={2309.10253},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.10253}, 
}

@misc{yuan2024,
      title={S-Eval: Automatic and Adaptive Test Generation for Benchmarking Safety Evaluation of Large Language Models}, 
      author={Xiaohan Yuan and Jinfeng Li and Dongxia Wang and Yuefeng Chen and Xiaofeng Mao and Longtao Huang and Hui Xue and Wenhai Wang and Kui Ren and Jingyi Wang},
      year={2024},
      eprint={2405.14191},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2405.14191}, 
}

@misc{zhang2024lookgptappslandscape,
      title={A First Look at GPT Apps: Landscape and Vulnerability}, 
      author={Zejun Zhang and Li Zhang and Xin Yuan and Anlan Zhang and Mengwei Xu and Feng Qian},
      year={2024},
      eprint={2402.15105},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.15105}, 
}

@misc{zhang2024safetybench,
      title={SafetyBench: Evaluating the Safety of Large Language Models}, 
      author={Zhexin Zhang and Leqi Lei and Lindong Wu and Rui Sun and Yongkang Huang and Chong Long and Xiao Liu and Xuanyu Lei and Jie Tang and Minlie Huang},
      year={2024},
      eprint={2309.07045},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07045}, 
}

