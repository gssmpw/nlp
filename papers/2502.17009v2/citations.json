[
  {
    "index": 0,
    "papers": [
      {
        "key": "li2017stochastic",
        "author": "Li, Qianxiao and Tai, Cheng and Weinan, E",
        "title": "Stochastic modified equations and adaptive stochastic gradient algorithms"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "li2017stochastic",
        "author": "Li, Qianxiao and Tai, Cheng and Weinan, E",
        "title": "Stochastic modified equations and adaptive stochastic gradient algorithms"
      },
      {
        "key": "li2019stochastic",
        "author": "Li, Qianxiao and Tai, Cheng and Weinan, E",
        "title": "Stochastic modified equations and dynamics of stochastic gradient algorithms i: Mathematical foundations"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zhao2022batch",
        "author": "Jim Zhao and Aurelien Lucchi and Frank Norbert Proske and Antonio Orvieto and Hans Kersting",
        "title": "Batch size selection by stochastic optimal control"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "compagnoni2023sde",
        "author": "Compagnoni, Enea Monzio and Biggio, Luca and Orvieto, Antonio and Proske, Frank Norbert and Kersting, Hans and Lucchi, Aurelien",
        "title": "An sde for modeling sam: Theory and insights"
      },
      {
        "key": "compagnoni2024sde",
        "author": "Compagnoni, Enea Monzio and Orvieto, Antonio and Kersting, Hans and Proske, Frank and Lucchi, Aurelien",
        "title": "SDEs for Minimax Optimization"
      },
      {
        "key": "compagnoni2025adaptive",
        "author": "Enea Monzio Compagnoni and Tianlin Liu and Rustem Islamov and Frank Norbert Proske and Antonio Orvieto and Aurelien Lucchi",
        "title": "Adaptive Methods through the Lens of {SDE}s: Theoretical Insights on the Role of Noise"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "jastrzkebski2017three",
        "author": "Jastrzebski, Stanis{\\l}aw and Kenton, Zachary and Arpit, Devansh and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos",
        "title": "Three Factors Influencing Minima in SGD"
      },
      {
        "key": "Malladi2022AdamSDE",
        "author": "Malladi, Sadhika and Lyu, Kaifeng and Panigrahi, Abhishek and Arora, Sanjeev",
        "title": "On the {SDEs} and Scaling Rules for Adaptive Gradient Algorithms"
      },
      {
        "key": "compagnoni2025adaptive",
        "author": "Enea Monzio Compagnoni and Tianlin Liu and Rustem Islamov and Frank Norbert Proske and Antonio Orvieto and Aurelien Lucchi",
        "title": "Adaptive Methods through the Lens of {SDE}s: Theoretical Insights on the Role of Noise"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "smith2021origin",
        "author": "Samuel L. Smith and Benoit Dherin and David G. T. Barrett and Soham De",
        "title": "On the Origin of Implicit Regularization in Stochastic Gradient Descent"
      },
      {
        "key": "compagnoni2023sde",
        "author": "Compagnoni, Enea Monzio and Biggio, Luca and Orvieto, Antonio and Proske, Frank Norbert and Kersting, Hans and Lucchi, Aurelien",
        "title": "An sde for modeling sam: Theory and insights"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "condat2022ef",
        "author": "Condat, Laurent and Yi, Kai and Richt{\\'a}rik, Peter",
        "title": "{EF-BV}: A unified theory of error feedback and variance reduction mechanisms for biased and unbiased compression in distributed optimization"
      },
      {
        "key": "PD2025",
        "author": "Constantin Philippenko and Aymeric Dieuleveut",
        "title": "Compressed and distributed least-squares regression: convergence rates with applications to federated learning"
      },
      {
        "key": "mishchenko2024distributed",
        "author": "Mishchenko, Konstantin and Gorbunov, Eduard and Tak{\\'a}{\\v{c}}, Martin and Richt{\\'a}rik, Peter",
        "title": "Distributed learning with compressed gradient differences"
      },
      {
        "key": "islamov2021distributed",
        "author": "Islamov, Rustem and Qian, Xun and Richt{\\'a}rik, Peter",
        "title": "Distributed second order methods with fast rates and compressed communication"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "gao2023econtrol",
        "author": "Gao, Yuan and Islamov, Rustem and Stich, Sebastian",
        "title": "{EControl}: Fast Distributed Optimization with Compression and Error Control"
      },
      {
        "key": "fatkhullin2024momentum",
        "author": "Fatkhullin, Ilyas and Tyurin, Alexander and Richt{\\'a}rik, Peter",
        "title": "Momentum provably improves error feedback!"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "seide20141",
        "author": "Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong",
        "title": "1-bit stochastic gradient descent and its application to data-parallel distributed training of speech {DNNs}."
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "simsekli2019tail",
        "author": "Simsekli, Umut and Sagun, Levent and Gurbuzbalaban, Mert",
        "title": "A tail-index analysis of stochastic gradient noise in deep neural networks"
      },
      {
        "key": "zhang2020adaptive",
        "author": "Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit",
        "title": "Why are adaptive methods good for attention models?"
      },
      {
        "key": "gurbuzbalaban2021heavy",
        "author": "Gurbuzbalaban, Mert and Simsekli, Umut and Zhu, Lingjiong",
        "title": "The heavy-tail phenomenon in {SGD}"
      },
      {
        "key": "kunstner2024heavy",
        "author": "Kunstner, Frederik and Yadav, Robin and Milligan, Alan and Schmidt, Mark and Bietti, Alberto",
        "title": "Heavy-tailed class imbalance and why adam outperforms gradient descent on language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "devlin2018bert",
        "author": "Devlin, Jacob",
        "title": "Bert: Pre-training of deep bidirectional transformers for language understanding"
      },
      {
        "key": "sun2023distributed",
        "author": "Sun, Chao",
        "title": "Distributed Stochastic Optimization under Heavy-Tailed Noises"
      },
      {
        "key": "yang2022taming",
        "author": "Yang, Haibo and Qiu, Peiwen and Liu, Jia",
        "title": "Taming Fat-Tailed (\u201cHeavier-Tailed\u201d with Potentially Infinite Variance) Noise in Federated Learning"
      },
      {
        "key": "gorbunov2023high",
        "author": "Gorbunov, Eduard and Sadiev, Abdurakhmon and Danilova, Marina and Horv{\\'a}th, Samuel and Gidel, Gauthier and Dvurechensky, Pavel and Gasnikov, Alexander and Richt{\\'a}rik, Peter",
        "title": "High-probability convergence for composite and distributed stochastic minimization and variational inequalities with heavy-tailed noise"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "khirirat2023clip21",
        "author": "Sarit Khirirat and Eduard Gorbunov and Samuel Horv\u00e1th and Rustem Islamov and Fakhri Karray and Peter Richt\u00e1rik",
        "title": "{Clip21}: Error Feedback for Gradient Clipping"
      },
      {
        "key": "li2023convergenceandprivacy",
        "author": "Li, Boyue and Chi, Yuejie",
        "title": "Convergence and privacy of decentralized nonconvex optimization with gradient clipping and communication compression"
      },
      {
        "key": "yu2023smoothed",
        "author": "Yu, Shuhua and Jakovetic, Dusan and Kar, Soummya",
        "title": "Smoothed Gradient Clipping and Error Feedback for Distributed Optimization under Heavy-Tailed Noise"
      }
    ]
  }
]