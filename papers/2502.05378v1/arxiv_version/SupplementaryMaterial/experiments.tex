\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/dataset.png}
    \caption{\textbf{More maps from our dataset.} Rows from top to bottom represent increasing scene complexity, categorized into four levels: Simple, Normal, Hard, Insane.}
    \label{fig:dataset_full}
\end{figure}
\section{Experiments}
\input{tables/results_mp3d_details}
\noindent \textbf{Detailed quantitative results.} Table~\ref{tab:doom_test_training_1} and Table~\ref{tab:doom_test_training_2} show our superior performance on both the AiMDoom training set and the test set. Furthermore, we offer detailed results for each test scene in MP3D, as illustrated in Table~\ref{tab:comparison-mp3d}.

% Table 1: ExDoom Simple and Normal
\begin{table*}[!t]
\centering
\caption{{Evaluation results on AiMDoom dataset (Simple and Normal)}.}
\small
\setlength{\tabcolsep}{3.5pt}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
& \multicolumn{4}{c}{\textbf{AiMDoom Simple}} & \multicolumn{4}{c}{\textbf{AiMDoom Normal}} \\
\cmidrule(lr){2-5} \cmidrule(l){6-9}
& \multicolumn{2}{c}{Seen} & \multicolumn{2}{c}{Unseen} & \multicolumn{2}{c}{Seen} & \multicolumn{2}{c}{Unseen} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(l){8-9}
& Final Cov. & AUC & Final Cov. & AUC & Final Cov. & AUC & Final Cov. & AUC \\
\midrule
Random Walk & 0.362 & 0.306 & 0.323 & 0.270 & 0.198 & 0.159 & 0.190 & 0.152 \\
 & {\scriptsize ±0.175} & {\scriptsize ±0.156} & {\scriptsize ±0.156} & {\scriptsize ±0.135} & {\scriptsize ±0.125} & {\scriptsize ±0.104} & {\scriptsize ±0.124} & {\scriptsize ±0.103} \\
FBE & 0.770 & 0.628 & 0.760 & 0.605 & 0.564 & 0.423 & 0.565 & 0.415 \\
 & {\scriptsize ±0.163} & {\scriptsize ±0.147} & {\scriptsize ±0.174} & {\scriptsize ±0.171} & {\scriptsize ±0.171} & {\scriptsize ±0.127} & {\scriptsize ±0.139} & {\scriptsize ±0.109} \\
SCONE & 0.597 & 0.482 & 0.577 & 0.483 & 0.421 & 0.315 & 0.412 & 0.313 \\
 & {\scriptsize ±0.177} & {\scriptsize ±0.158} & {\scriptsize ±0.173} & {\scriptsize ±0.138} & {\scriptsize ±0.138} & {\scriptsize ±0.102} & {\scriptsize ±0.114} & {\scriptsize ±0.087} \\
MACARONS & 0.600 & 0.483 & 0.599 & 0.479 & 0.442 & 0.332 & 0.418 & 0.314 \\
 & {\scriptsize ±0.176} & {\scriptsize ±0.145} & {\scriptsize ±0.200} & {\scriptsize ±0.172} & {\scriptsize ±0.135} & {\scriptsize ±0.104} & {\scriptsize ±0.120} & {\scriptsize ±0.088} \\
\textbf{NBP (Ours)} & \textbf{0.870} & \textbf{0.697} & \textbf{0.879} & \textbf{0.692} & \textbf{0.746} & \textbf{0.538} & \textbf{0.734} & \textbf{0.526} \\
 & {\scriptsize {±0.121}} & {\scriptsize {±0.134}} & {\scriptsize {±0.142}} & {\scriptsize {±0.156}} & {\scriptsize {±0.152}} & {\scriptsize {±0.142}} & {\scriptsize {±0.142}} & {\scriptsize {±0.112}} \\
\bottomrule
\end{tabular}
\label{tab:doom_test_training_1}
\end{table*}

% Table 2: ExDoom Hard and Insane
\begin{table*}[!t]
\centering
\caption{{Evaluation results on AiMDoom dataset (Hard and Insane)}.}
\small
\setlength{\tabcolsep}{3.5pt}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
& \multicolumn{4}{c}{\textbf{AiMDoom Hard}} & \multicolumn{4}{c}{\textbf{AiMDoom Insane}} \\
\cmidrule(lr){2-5} \cmidrule(l){6-9}
& \multicolumn{2}{c}{Seen} & \multicolumn{2}{c}{Unseen} & \multicolumn{2}{c}{Seen} & \multicolumn{2}{c}{Unseen} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(l){8-9}
& Final Cov. & AUC & Final Cov. & AUC & Final Cov. & AUC & Final Cov. & AUC \\
\midrule
Random Walk & 0.121 & 0.086 & 0.124 & 0.088 & 0.070 & 0.048 & 0.074 & 0.050 \\
 & {\scriptsize ±0.081} & {\scriptsize ±0.062} & {\scriptsize ±0.082} & {\scriptsize ±0.060} & {\scriptsize ±0.049} & {\scriptsize ±0.038} & {\scriptsize ±0.048} & {\scriptsize ±0.035} \\
FBE & 0.426 & 0.310 & 0.425 & 0.311 & 0.313 & 0.226 & 0.330 & 0.239 \\
 & {\scriptsize ±0.119} & {\scriptsize ±0.091} & {\scriptsize ±0.114} & {\scriptsize ±0.080} & {\scriptsize ±0.082} & {\scriptsize ±0.066} & {\scriptsize ±0.097} & {\scriptsize ±0.079} \\
SCONE & 0.271 & 0.199 & 0.290 & 0.210 & 0.204 & 0.146 & 0.196 & 0.140 \\
 & {\scriptsize ±0.100} & {\scriptsize ±0.172} & {\scriptsize ±0.093} & {\scriptsize ±0.072} & {\scriptsize ±0.069} & {\scriptsize ±0.052} & {\scriptsize ±0.079} & {\scriptsize ±0.060} \\
MACARONS & 0.316 & 0.202 & 0.302 & 0.218 & 0.201 & 0.143 & 0.192 & 0.139 \\
 & {\scriptsize ±0.106} & {\scriptsize ±0.074} & {\scriptsize ±0.097} & {\scriptsize ±0.070} & {\scriptsize ±0.068} & {\scriptsize ±0.051} & {\scriptsize ±0.078} & {\scriptsize ±0.058} \\
\textbf{NBP (Ours)} & \textbf{0.627} & \textbf{0.430} & \textbf{0.618} & \textbf{0.432} & \textbf{0.486} & \textbf{0.315} & \textbf{0.472} & \textbf{0.312} \\
 & {\scriptsize {±0.144}} & {\scriptsize {±0.111}} & {\scriptsize {±0.153}} & {\scriptsize {±0.115}} & {\scriptsize {±0.106}} & {\scriptsize {±0.047}} & {\scriptsize {±0.095}} & {\scriptsize {±0.073}} \\
\bottomrule
\end{tabular}
\label{tab:doom_test_training_2}
\end{table*}

\noindent \textbf{Additional ablation study.} 
We study the impact of different spatial range information used to predict the next best path by training four different models on the AiMDoom Normal level training split. These models processed input crop sizes ranging from $20m \times 20m$ to $50m \times 50m$, with each model tasked with predicting a value map and an obstacle map within a $40m \times 40m$ area. The Table~\ref{tab:abalation_study_crop_size} shows the results.

\begin{table}
    \centering
    \caption{Comparison of different spatial ranges of information used to predict the next best path.}
    \begin{tabular}{lcccc}
        \toprule
        Range & 20m $\times$ 20m & 30m $\times$ 30m & 40m $\times$ 40m & 50m $\times$ 50m \\
        \midrule
        Final Cov. & 0.630~\tiny{±0.151} & 0.691~\tiny{±0.140} & \textbf{0.734}~\tiny{±0.142} & 0.647~\tiny{±0.144} \\
        AUCs & 0.469~\tiny{±0.107} & 0.501~\tiny{±0.106} & \textbf{0.526}~\tiny{±0.112} & 0.457~\tiny{±0.106} \\
        \bottomrule
    \end{tabular}
    \label{tab:abalation_study_crop_size}
\end{table}

The results indicate that optimal performance is achieved when the input crop size corresponds to the crop size of the area being predicted. This is due to the fact that when the input crop size is either smaller or larger than that of the output maps, predictive errors arise. Specifically, if the input crop size is too small, it limits the model’s ability to formulate effective long-term objectives. Conversely, when the input crop size is too large, the predictions for obstacles near the camera become less accurate, negatively impacting both exploration and reconstruction efficiency.

We also investigate the different strategies in inference. We conducted this experiment on the AiMDoom Normal level, extending our previous ablation studies. Table~\ref{tab:strategy_comparison} shows the results, the Original Strategy adheres to the original approach of updating long-term goals upon completing a path, while the New strategy updates goals at each step.

The results indicate that the New Strategy, which frequently updates long-term goals, performs
worse than the Original Strategy. This inferior performance is mainly due to the lack of decision
\begin{wraptable}{r}{0.48\textwidth}
    \centering
    \caption{Comparison of Different Strategies}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Strategy} & \textbf{Final Cov.} & \textbf{AUCs} \\
        \midrule
        Original strategy & \textbf{0.734}~\tiny{±0.142} & \textbf{0.526}~\tiny{±0.112} \\
        New strategy & 0.432~\tiny{±0.168} & 0.367~\tiny{±0.135} \\
        \bottomrule
    \end{tabular}
    \label{tab:strategy_comparison}
\end{wraptable}continuity in the New Strategy, where the agent frequently changes its long-term goals. Such frequent shifts can cause the agent to oscillate between paths, wasting movement steps, particularly as our experiments were conducted with a limited number of steps. Additionally, the predictive accuracy of the value map is not perfect, and forecasting over long distances naturally entails uncertainty. New Strategy accumulates more predictive errors by recalculating predictions at every step, and frequent updates in decision-making can exacerbate these errors.

Despite these challenges, our results still surpassed the performance of previous state-of-the-art next-best-view (NBV) methods, as detailed in Table.~\ref{tab:doom_main_experiments}. This suggests that predicting coverage gains over long distances can indeed benefit efficient active mapping, even when the goal is updated at each step.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{SupplementaryMaterial/fail_gt1.png}
        \caption{Ground truth mesh}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{SupplementaryMaterial/fail_1.png}
        \caption{NBP (Ours)}
    \end{subfigure}
    \caption{\textbf{Failure case 1}: Our method initially prioritizes the exploration of high-value areas, inadvertently neglecting regions of secondary importance. Thus, it results in incomplete reconstruction in the initial area of the beginning trajectory.}
    \label{fig:comparison5}
\end{figure}
\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{SupplementaryMaterial/fail_gt2.png}
        \caption{Ground truth mesh}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{SupplementaryMaterial/fail_2.png}
        \caption{NBP (Ours)}
    \end{subfigure}
    \caption{\textbf{Failure case 2}: This scene contains multiple narrow areas, prompting our method to depend more heavily on our precise prediction of obstacles. Under these challenging conditions, our approach may overlook exploring this area.}
    \label{fig:comparison6}
\end{figure}

\noindent \textbf{Failure cases.} 
As Figure.~\ref{fig:comparison5} and Figure.~\ref{fig:comparison6} illustrated, we also show that in very complex environments, we could only achieve about 65\% coverage. This is because, in complex environments, our method prioritizes the exploration of areas with multiple valuable goals, ignoring places of lesser current value. After the initial exploration is complete, it is likely to explore other regions, overlooking previously encountered areas with higher value. Consequently, developing methods that aim to achieve a global optimum is a promising and valuable direction for future research.