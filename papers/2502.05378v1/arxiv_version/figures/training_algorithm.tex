\begin{wrapfigure}{R}{0.5\textwidth}
\begin{minipage}{0.5\textwidth}
\vspace{-1em}
\begin{algorithm}[H]
\caption{Training procedure.}
\label{alg:training}
\begin{algorithmic}
\State $N$: number of training iterations
\State $N_{e}$: number of iterations using easy data
\State $S_n$: the number of trajectories per scene
% \State $P_{c_i}$: Model input
% \State $M_{c_i}^{\text{GT}}[c_g]$: Ground truth heatmap
% \State $O_{c_i}^{\text{GT}}$: Ground truth obstacle map
% \State $n$ = Number of iterations
% \State $m$ = Number of validation samples
% \State $L$ = Trajectory length (100 steps)
\State Initialize memory $\mathcal{M} \leftarrow \emptyset$
\State Initialize model parameter $\theta$
\For{$n \leftarrow 1$ \textbf{to} $N$}
    \State Initialize training set $\mathcal{T} \leftarrow \emptyset$
    \For{each scene in training set}
        \For{$s \leftarrow 1$ \textbf{to} $S_n$}
            \State Collect training data $\{d_l\}_{l=1}^L$
            \If{$n \leq N_e$}
                \State $\mathcal{T} \leftarrow \mathcal{T} \cup \{d_l: t \geq 10\}_{l=1}^L$
            \Else
                \State $\mathcal{T} \leftarrow \mathcal{T} \cup \{d_l\}_{l=1}^L$
            \EndIf
        \EndFor
    \EndFor
    \State $\mathcal{M} \leftarrow \mathcal{M} \cup \mathcal{T}$
    \State $\mathcal{T} \leftarrow \mathcal{T} \cup \text{RandomSample}(\mathcal{M} \setminus \mathcal{T}, |\mathcal{T}|)$
    % \If{$t > 1$} \Comment{Training starts from the second iteration}
    \For{$e \leftarrow 1$ \textbf{to} $E$}
        \State Update $\theta$ with loss in Eq~\eqref{eqn:training_loss} over $\mathcal{T}$
    \EndFor
\EndFor
\State \Return $\theta$
\end{algorithmic}
\end{algorithm}
\vspace{-3em}
\end{minipage}
\end{wrapfigure}

% \begin{algorithm}
% \caption{Iterative Training Framework with Dynamic Memory and Model-based Data Collection}
% \begin{algorithmic}[1]
% \State $P_{c_i}$: Model input
% \State $M_{c_i}^{\text{GT}}[c_g]$: Ground truth heatmap
% \State $O_{c_i}^{\text{GT}}$: Ground truth obstacle map
% \State $n$ = Number of iterations
% \State $m$ = Number of validation samples
% \State $L$ = Trajectory length (100 steps)
% \State Initialize Memory: $\mathcal{M} = \emptyset$
% \State Initialize Model Parameters: $\theta$
% \For{$t = 1$ \textbf{to} $n$}
%     \State Initialize Training Set: $\mathcal{T} = \emptyset$
%     \For{each scene in training set}
%         \State Collect trajectory: $\{(P_{c_i}, (M_{c_i}^{\text{GT}}[c_g], O_{c_i}^{\text{GT}}))\}_{i=1}^L$ using model
%         \State $\mathcal{T} = \mathcal{T} \cup \{(P_{c_i}, (M_{c_i}^{\text{GT}}[c_g], O_{c_i}^{\text{GT}}))\}_{i=1}^L$
%     \EndFor
%     \State $\mathcal{M} = \mathcal{M} \cup \mathcal{T}$
%     \If{$t = 1$}
%         \State Sample Validation Set: $\mathcal{V} = \text{RandomSample}(\mathcal{M}, m)$
%         \State \textbf{continue} \Comment{Skip training in the first iteration}
%     \ElsIf{$t = 2$}
%         \State Filter $\mathcal{T}$ from $\mathcal{M}$ for $i \geq 10$
%     \Else
%         \State $\mathcal{S} = \text{RandomSample}(\mathcal{M} \setminus \mathcal{T}, |\mathcal{T}|)$
%         \State $\mathcal{T} = \mathcal{T} \cup \mathcal{S}$
%     \EndIf
%     \If{$t > 1$} \Comment{Training starts from the second iteration}
%         \For{$e = 1$ \textbf{to} $5$}
%             \State $\theta = \text{TrainStep}(\theta, \mathcal{T})$ \Comment{Train model to predict $(M_{c_i}^{\text{GT}}[c_g], O_{c_i}^{\text{GT}})$ given $P_{c_i}$}
%         \EndFor
%         \State $\text{val\_loss} = \frac{1}{5} \sum_{e=1}^5 \text{Validate}(\theta, \mathcal{V})$
%         \If{$\text{val\_loss}$ not decreasing}
%             \State \textbf{break}
%         \EndIf
%     \EndIf
% \EndFor
% \State \Return $\theta$
% \end{algorithmic}
% \end{algorithm}
