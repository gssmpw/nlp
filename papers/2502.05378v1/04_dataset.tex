\section{The AiMDoom Dataset}
\label{dataset-sec}

\input{tables/dataset_cmpr}


In this section, we introduce \textbf{AiMDoom}, a new dataset for \textbf{A}ct\textbf{i}ve 3D \textbf{M}apping in complex indoor environments based on the \textbf{Doom} video game~\footnote{\url{https://en.wikipedia.org/wiki/Doom_(franchise)}}.
As Doom features a wide variety of indoor settings, we use its map generator to create four sets of maps of increasing geometric complexity: Simple, Normal, Hard, and Insane. In the following, we first detail how we built these maps and then discuss the key challenges presented in our AiMDoom dataset.

\input{figures/dataset}

\noindent \textbf{Dataset construction.}
%
We used the open-source software Obsidian~\footnote{\url{https://obsidian-level-maker.github.io/}} to automatically generate Doom maps as our indoor environments.
Four sets of hyperparameters are proposed to control architectural complexity and texture styles in Obsidian. By varying these hyperparameters, we produced maps categorized into Simple, Normal, Hard and Insane difficulty levels. Each difficulty level is made of 100 maps with 70 for training and 30 for evaluation.

% \vincentrmk{should we talk about splits between training, validation, test sets?} \shiyaormk{yes, I will add this, we also mentioned it in the experimental section}

The maps include doors and windows, all of which are configured to be open. This allows the agent to see and pass through the doors and windows.
We converted the maps to the widely used OBJ format, and used Blender~\citep{blender} to consolidate the texture images of each map into a single texture image. This makes the maps compatible with Pytorch3D~\citep{pytorch3d} and Open3D~\citep{open3d}. 
Further details are presented in the supplementary material.


\noindent \textbf{Key challenges.}
%
The AiMDoom dataset presents three key challenges for active 3D mapping.
Firstly, the dataset features environments with intricate geometries and layouts as shown in Figure~\ref{fig:dataset}, making it challenging to determine the optimal exploration direction for effective mapping.
Secondly, the maps have small doors and narrow corridors, requiring careful path planning to navigate.
Finally, the map diversity requires the reconstruction system to generalize across different scenes.
Table~\ref{tab:dataset_comparision} compares AiMDoom with existing indoor 3D datasets~\citep{replica19arxiv, RoboTHOR, Matterport3D, dai2017scannet,gibson, ramakrishnan2021hm3d}, highlighting our dataset's strengths in scene area and navigation complexity.

We will release the dataset along with a comprehensive toolkit to generate the data, which enables easy expansion of the dataset for future research.


% To ensure that the map offers full accessibility for various robotic platforms such as unmanned aerial vehicles (UAVs) and wheeled robots, we configure all doors and windows to remain open during map generation. 
% However, we observe that Obsidian does not consistently guarantee accessibility to all areas. To resolve this, we manually edit each scene to ensure the traversability of windows, doors, and hidden passages.
% Additionally, Doom map files are in a specific format that is incompatible with common 3D libraries such as Pytorch3D \cite{pytorch3d} and Open3D \cite{open3d}.
% To address this, we extract mesh files and texture images from these maps. 
% Specifically, we load Doom WAD~\footnote{\url{https://en.wikipedia.org/wiki/Doom_modding}} files to generate widely used OBJ format, and employ Blender~\cite{blender} for texture baking that consolidates multiple texture images of the map into a single texture image for each scene.
% In this way, we generate 100 unique environments for each of the four levels in AiRDoom.


% For the dataset creation, we first generate Doom map files with varying architectural complexities and diverse texture styles by defining 4 different lower and upper bounds for architectural complexity using Obsidian\footnote{https://obsidian-level-maker.github.io/} under the GNU General Public License. 

% Subsequently, we extract mesh files and their corresponding texture image relationships from these maps. However, as with most existing 3D scene datasets \cite{Matterport3D, replica19arxiv, ramakrishnan2021hm3d}, the texture information at this stage is stored as discrete images, which are unable to directly read the texture information of the meshes by the popular 3D libraries such as Pytorch3D \cite{pytorch3d} and Open3D \cite{open3d}. To address this issue, we utilize Blender \cite{blender} to perform texture baking, consolidating the discrete texture images into a single texture image for each scene in our dataset.

% To ensure our dataset offers comprehensive navigational versatility, accommodating various robotic platforms such as unmanned aerial vehicles (UAVs) and wheeled robots, we configured all doors and windows to be open during the map generation process. However, this open-source software, originally designed for the Doom video game, cannot consistently guarantee accessibility to all areas. To address this limitation, we manually edited each scene mesh to ensure the traversability of windows, doors, and hidden passages.

% \noindent \textbf{Key challenges.}
% The AiRDoom dataset presents three key challenges for active 3D reconstruction.
% Firstly, the dataset features environments with intricate geometries and layouts as shown in Figure~\ref{fig:exdoom}, making it challenging to determine the optimal exploration direction for effective reconstruction.
% Secondly, the environments often contain small windows, doors and narrow corridors, requiring careful path planning to navigate.
% Finally, the diversity of environments requires the reconstruction system to generalize across different scenes.
% Table~\ref{tab:doom-comparison} compares AiRDoom with existing indoor 3D datasets, highlighting our dataset's strengths in scene area and navigation complexity.

% We will release the dataset along with a comprehensive toolkit to generate the data, which enables easy expansion of the dataset for future research.


% Compared with existing similar indoor 3D datasets in Tab.~\ref{tab:doom-comparison}, our dataset excels in terms of scene area, exploration complexity, and high practicality.

% Our contribution extends beyond the dataset itself. We will release the comprehensive toolkit used to generate this dataset, including the configuration files for map generation within Obsidian, and the code for mesh extraction and texture baking.





