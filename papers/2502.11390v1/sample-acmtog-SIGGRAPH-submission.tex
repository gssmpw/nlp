% \documentclass[acmtog,anonymous,review,nonacm]{acmart}
\documentclass[acmtog,nonacm]{acmart}
\makeatletter
\let\@authorsaddresses\@empty
\makeatother
\acmSubmissionID{183}

\usepackage{booktabs} % For formal tables

% TOG prefers author-name bib system with square brackets
\citestyle{acmauthoryear}
%\setcitestyle{nosort,square} % nosort to allow for manual chronological ordering



\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}

% Metadata Information
\acmJournal{TOG}
%\acmVolume{38}
%\acmNumber{4}
%\acmArticle{39}
%\acmYear{2019}
%\acmMonth{7}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
%\acmDOI{0000001.0000001_2}

% Paper history
%\received{February 2007}
%\received{March 2009}
%\received[final version]{June 2009}
%\received[accepted]{July 2009}


% Document starts
\begin{document}
% Title portion
\title{\textbf{MARS}: \textbf{M}esh \textbf{A}uto\textbf{R}egressive Model for 3D \textbf{S}hape Detailization}

% DO NOT ENTER AUTHOR INFORMATION FOR ANONYMOUS TECHNICAL PAPER SUBMISSIONS TO SIGGRAPH 2019!
\author{Jingnan Gao}
\affiliation{%
 \institution{Shanghai Jiao Tong University}
 % \streetaddress{104 Jamestown Rd}
 % \city{Williamsburg}
 % \state{VA}
 % \postcode{23185}
 \country{China}
 }
\email{gjn0310@sjtu.edu.cn}
\authornote{The contribution is made during an internship at Tencent XR Vision Labs.} 
\author{Weizhe Liu}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{weizheliu1991@163.com}
 \authornote{Project lead.} 
\author{Weixuan Sun}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{weixuansun7@outlook.com}
\author{Senbo Wang}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{wsb_pro@live.com}
\author{Xibin Song}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{song.sducg@gmail.com}
\author{Taizhang Shang}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{taizhangshang@qq.com}
\author{Shenzhou Chen}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
\email{chenshenzhou@zju.edu.cn}
\author{Hongdong Li}
\affiliation{%
 \institution{Australian National University}
  \country{Australia}
 }
\email{HONGDONG.LI@anu.edu.au}
\author{Xiaokang Yang}
\affiliation{%
 \institution{Shanghai Jiao Tong University}
  \country{China}
 }
 \email{xkyang@sjtu.edu.cn}
\author{Yichao Yan}
\affiliation{%
 \institution{Shanghai Jiao Tong University}
  \country{China}
 }
\email{yanyichao@sjtu.edu.cn}
\authornote{Corresponding author.} 
 \author{Pan Ji}
\affiliation{%
 \institution{Tencent XR Vision Labs}
  \country{China}
 }
 \email{peterji1990@gmail.com}




%\author{Gang Zhou}
%\orcid{1234-5678-9012-3456}
%\affiliation{%
%  \institution{College of William and Mary}
%  \streetaddress{104 Jamestown Rd}
%  \city{Williamsburg}
%  \state{VA}
%  \postcode{23185}
%  \country{USA}}
%\email{gang_zhou@wm.edu}
%\author{Valerie B\'eranger}
%\affiliation{%
%  \institution{Inria Paris-Rocquencourt}
%  \city{Rocquencourt}
%  \country{France}
%}
%\email{beranger@inria.fr}
%\author{Aparna Patel}
%\affiliation{%
% \institution{Rajiv Gandhi University}
% \streetaddress{Rono-Hills}
% \city{Doimukh}
% \state{Arunachal Pradesh}
% \country{India}}
%\email{aprna_patel@rguhs.ac.in}
%\author{Huifen Chan}
%\affiliation{%
%  \institution{Tsinghua University}
%  \streetaddress{30 Shuangqing Rd}
%  \city{Haidian Qu}
%  \state{Beijing Shi}
%  \country{China}
%}
%\email{chan0345@tsinghua.edu.cn}
%\author{Ting Yan}
%\affiliation{%
%  \institution{Eaton Innovation Center}
%  \city{Prague}
%  \country{Czech Republic}}
%\email{yanting02@gmail.com}
%\author{Tian He}
%\affiliation{%
%  \institution{University of Virginia}
%  \department{School of Engineering}
%  \city{Charlottesville}
%  \state{VA}
%  \postcode{22903}
%  \country{USA}
%}
%\affiliation{%
%  \institution{University of Minnesota}
%  \country{USA}}
%\email{tinghe@uva.edu}
%\author{Chengdu Huang}
%\author{John A. Stankovic}
%\author{Tarek F. Abdelzaher}
%\affiliation{%
%  \institution{University of Virginia}
%  \department{School of Engineering}
%  \city{Charlottesville}
%  \state{VA}
%  \postcode{22903}
%  \country{USA}
%}

%\renewcommand\shortauthors{Zhou, G. et al}

\begin{abstract}
State-of-the-art methods for mesh detailization predominantly utilize Generative Adversarial Networks (GANs) to generate detailed meshes from coarse ones. These methods typically learn a specific style code for each category or similar categories without enforcing geometry supervision across different Levels of Detail (LODs). Consequently, such methods often fail to generalize across a broader range of categories and cannot ensure shape consistency throughout the detailization process. In this paper, we introduce MARS, a novel approach for 3D shape detailization. Our method capitalizes on a novel multi-LOD, multi-category mesh representation to learn shape-consistent mesh representations in latent space across different LODs. We further propose a mesh autoregressive model capable of generating such latent representations through next-LOD token prediction. This approach significantly enhances the realism of the generated shapes. Extensive experiments conducted on the challenging 3D Shape Detailization benchmark demonstrate that our proposed MARS model achieves state-of-the-art performance, surpassing existing methods in both qualitative and quantitative assessments. Notably, the model's capability to generate fine-grained details while preserving the overall shape integrity is particularly commendable.
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below.
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies ~ Shape modeling.}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%
% End generated code
%


\keywords{Generative model, geometry detailization, autoregressive model, machine learning.}

\begin{teaserfigure}
    \includegraphics[width=\textwidth]{Figs/teaser.pdf}
        \caption{\textbf{A variety of objects generated by MARS.} The figure exemplifies the capability of MARS to generate intricate geometric patterns while preserving the overall shape integrity. }
\end{teaserfigure}

\maketitle



\input{samplebody-journals}



\end{document}
