\section{Discussion}
\label{sec:discussion}

In this section, we first summarize the conclusion and share some key observations. Then, we reflect on the usability of our method and propose potential applications. In the end, we discuss the limitations and future work.

\subsection{Effectiveness of \name{}}
\label{sec:discuss_effectiveness}
Firstly, based on the results from Section~\ref{sec:experiment}, we can draw the following conclusions:
\begin{itemize}
    \item It is efficient to detect unknown words by combining linguistic characteristics provided by the pre-trained language model (PLM) and gaze trajectory.
    \item The prediction is mainly based on the linguistic features from the textual context captured by PLM.
    \item Gaze locates the region of interest in a timely manner, which is necessary for real-time applications. Gaze also helps improve the model performance, but its contribution is limited compared to PLM.
\end{itemize}

Additionally, it is interesting that while we typically assume that the gaze modality should contribute significantly to the task of unknown word detection, the experimental results show that the contribution of gaze to the model’s improvement is small with the existence of PLM. Based on the previous analysis of line spacing and eye tracker accuracy, a possible reason for this is that under normal reading conditions (single-line spacing, line height 3-5 mm), the eye tracker’s accuracy is insufficient to precisely detect which line the gaze belongs to, thus failing to accurately locate the gaze on the words. Furthermore, changes in user posture during long reading sessions further reduce the accuracy of the eye tracker. In our system, PLM compensates for this issue by providing linguistic information based on the text.

From another perspective, the low contribution of gaze is not necessarily a disadvantage. Our method’s reduced reliance on gaze makes it more tolerant of noise. The model’s good performance on data collected by webcams further supports this conclusion. The reduced dependency on gaze data allows our model to be applied on more affordable and accessible devices, such as webcams.

\subsection{Usability of \name{}}
\label{sec:discuss_usability}
The results from the user evaluation (Section~\ref{sec:user_evaluation}) show that our reading assistance prototype helps users read more fluently and they are more willing to use it compared to traditional click-to-translate methods. In addition to providing real-time translation and explanations during reading, our system can also benefit ESL for long-term learning. For example, based on the unknown word detected by our system, we can generate a vocabulary list for memorizing and offer memory curve tracking. Furthermore, these unknown words can also be used to generate personalized summaries and notes.

The potential issue of generalizability across users, texts and devices can be addressed through fine-tuning and reinforcement learning methods. During the initial phases of usage, the system collects both gaze and text data for fine-tuning and lets users provide feedback on the model's predictions. This allows the model to continuously learn the user's unique gaze patterns and infer their vocabulary proficiency and domain expertise from textual content, thereby improving prediction accuracy.

\subsection{Limitation and Future Works}
\label{sec:discuss_limitation}
The quality of gaze data hinders the improvement model performance. The accuracy of the eye tracker is not enough for word-level detection. Common formatting, such as single-line spacing and 10-point font, results in a line height of approximately 3-5 mm when viewed using the PDF viewer with a sidebar on a 14-inch laptop. This requires an accuracy of about $0.3-0.6^\circ$ at a reading distance of 50-60 cm. However, most eye trackers have a gaze accuracy ranging from $0.2-1.1^\circ$~\cite{gaze_survey_2024}. Combined with additional errors caused by head and upper body movements, this level of accuracy is insufficient for real-world reading scenarios. During data collection and evaluation, some participants reported that even after calibration, the error could span 1-3 lines. This makes it difficult to determine the specific word the user is focusing on based solely on gaze coordinates, explaining why gaze-based baselines performed poorly on our data.

\change{The inaccuracy of the gaze data could also lead to the inaccuracy of data labeling. To mitigate the impact of mouse clicks on gaze behavior, we asked users to label unknown words during their second pass. However, this widely adopted labeling method inherently requires "guessing" which words correspond to a given gaze trajectory. Previous works mapped each gaze coordinate directly to a specific word to establish word-gaze pairs. This method is infeasible for text with normal line spacing, so we establish gaze-word pairs by defining a bounding box based on a segment of gaze to identify the corresponding words instead. While this approach improves robustness, it may also introduce mismatches between gaze and words and thus introduce noise to the dataset. To further improve model performance, more precise labeling methods are needed.}

Additionally, reading time can be longer than several minutes in daily scenarios, so gaze drift can significantly affect data quality. In our experiments, we observed that it is difficult for participants to maintain a fixed posture after calibration, though we required them to do so. The posture shift further increases errors. Therefore, in practical applications, real-time calibration of gaze data based on user posture is crucial to ensure data quality. If the existing eye-tracking technology can combined with user posture detection~\cite{faceori}, it is possible to reduce the impact of user posture on gaze data, thereby improving the quality of gaze data.


