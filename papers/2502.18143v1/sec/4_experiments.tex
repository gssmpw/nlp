\section{Experiments}
\label{sec:experiment}

\input{tables/rgbd_depthtrack}
\input{tables/rgbd_votrgbd2022}

\input{tables/rgbt_gtot_rgbt234_lasher}
\input{tables/rgbs_rgbs50}

\input{tables/rgbe_visevent}


\input{tables/params_flops_speed}

\input{tables/ablation_ecm}
\input{tables/ablation_number_ecm}


\subsection{Implementation Details}
The training set includes DepthTrack~\cite{depthtrack} for RGB-D tracking, LasHeR~\cite{lasher} for RGB-T tracking, and VisEvent~\cite{visevent} for RGB-E tracking. In addition, we follow~\cite{rgbs50} to train our LightFC-S using the LaSOT~\cite{lasot}, GOT10K~\cite{got10k}, TrackingNet~\cite{trackingnet}, COCO~\cite{coco}, and SarDet~\cite{sardet} datasets. The training platform consists of two NVIDIA RTX A6000 GPUs. The training consists of two phases. In the first phase we train the LightFC-X model without the STAM module. The training takes 45 epochs with a global batch size of 64. Each epoch contains 60k pairs of samples. The AdamW~\cite{adamw} optimizer is used with a weight decay of $10^{-4}$. The learning rate is set to $2\times 10^{-4}$ and decreased by 10 times after 10 epochs. In the second phase, we freeze all parameters of LightFC-X and train only the STAM module. The number of epochs is 15. All other training parameters are unchanged. The template update interval and the update confidence threshold of the tracking pipeline are uniformly set to 400 and 0.7 for multimodal tracking benchmarks.




\subsection{Evaluation Datasets and Metrics}
Our test set includes LasHeR~\cite{lasher}, RGBT234~\cite{rgbt234}, and GTOT~\cite{gtot} for RGB-Thermal tracking; DepthTrack~\cite{depthtrack} and VOT-RGBD2022~\cite{vot22} for RGB-Depth tracking; VisEvent~\cite{visevent} for RGB-Event tracking;  RGBS50~\cite{rgbs50} for RGB-Sonar tracking.


We evaluate our trackers using maximum precision rate (MPR) and maximum success rate (MSR) for GTOT~\cite{gtot} and RGBT234~\cite{rgbt234}, precision rate (PR) and success rate (SR) for LasHeR~\cite{lasher} and VisEvent~\cite{visevent}, F1 Score (F-Score), precision (Pr), and recall (Re) for DepthTrack~\cite{depthtrack}, expected average overlap (EAO), accuracy (A), and recall (R) for VOT-RGBD2022~\cite{vot22}, and RGBS50~\cite{rgbs50} with SR, PR, and normalized precision rate (NPR).


\subsection{Comparison with the state-of-the-art}

\

\textbf{DepthTrack.} DepthTrack~\cite{depthtrack} is a large-scale RGB-D tracking benchmark with 50 test sequences. 
As shown in Tab.~\ref{table rgbd depthtrack}, LightFC-D surpasses DDiMP~\cite{vot20} by 1.5\% and 6.8\% in F-Score and Pr, respectively. 
The F-score and Pr of LightFC-D-N3-ST are 53.8\% and 55.7\%, being 0.9\% and 2.1\% higher than OSTrack~\cite{ostrack}, while using 11.9x fewer parameters (7.76 \textit{v.s.} 92.18 M). 
Moreover, it achieves a gain of 9.8\% and 10.7\% in F-Score and Pr over the baseline LightFC~\cite{lightfc}. Overall, LightFC-D, LightFC-D-N3, and LightFC-D-N3-ST achieve state-of-the-art performance in lightweight RGB-D tracking. 

\textbf{VOT-RGBD2022.} VOT-RGBD2022~\cite{vot22} is a challenging short-term benchmark containing 127 test sequences. The results are shown in Tab.~\ref{table rgbd vot2022}. LightFC-D-N3 achieves similar performance to KeepTrack~\cite{keeptrack}. In addition, it outperforms LiteTrack~\cite{litetrack} by 2.9\% and 6.4\% in the EAO and R, respectively. In general, LightFC-D-N3-ST achieves competitive performance.




\textbf{LasHeR.} LasHeR~\cite{lasher} is a large-scale RGB-T tracking benchmark that comprises 245 test sequences. As shown in Tab.~\ref{table rgbt}. LightFC-T achieves superior performance compared to existing efficient RGB-T trackers. For example, LightFC-T outperforms CMD~\cite{cmd} by 3.7\% and 4.8\% in SR and PR, respectively, while using nearly 3x fewer parameters (6.68 \textit{v.s.} 19.90 M) and running 2.7x faster (81 \textit{v.s.} 30 \textit{fps}) respectively. Compared to MANet++ \cite{manetpp}, which has a similar number of parameters, LightFC-T surpasses it by 18.4\% in SR and 17.1\% in PR, while running 5.4x faster (81 \textit{v.s. }15 \textit{fps}). Compared to LightFC~\cite{lightfc}, LightFC-T outperforms it by 12.3\% and 15.2\% in SR and PR, respectively. Overall, LightFC-T and LightFC-T-ST achieve state-of-the-art performance among lightweight trackers for RGB-T tracking. 

\textbf{RGBT234.} RGBT234~\cite{rgbt234} is a large RGB-T tracking benchmark that contains 234 test sequences. As shown in Tab.~\ref{table rgbt}, the MPR and MSR of LightFC-T-ST are 1.0\% and 1.9\% higher than those of CMD~\cite{cmd}, respectively. Additionally, the MSR of LightFC-T-ST is comparable to MFNet~\cite{mfnet}, while using 10.6x fewer parameters (7.61 \textit{v.s.} 81.01 M) and running 4.5x faster (81 \textit{v.s. }18 \textit{fps}). In general, LightFC-T and LightFC-T-ST outperform other lightweight trackers in RGB-T tracking.

\textbf{GTOT.} GTOT~\cite{gtot} is a classic short-term RGB-T tracking benchmark comprising 50 sequences. Tab.~\ref{table rgbt} presents that LightFC-T achieves better MPR (88.2\%) and MSR (71.1\%), being  16.6\% and 11.6\% higher than those of LiteTrack-B4~\cite{litetrack}, while using nearly 4x fewer parameters (6.68 \textit{v.s.} 26.18 M). Overall, LightFC-T and LightFC-T-ST achieve competitive performance.







\textbf{VisEvent.} VisEvent~\cite{visevent} is a large-scale RGB-E tracking benchmark comprising 323 test sequences. As shown in Tab.~\ref{table rgbe}, LightFC-E achieves better SR (52.9\%) and PR (68.7\%), being 3.0\% and 2.8\% higher than those of SiamRCNN~\cite{siamrcnn}. LightFC-E-ST achieves performance close to that of OSTrack~\cite{ostrack}, while using 13.8x fewer parameters (6.68 \textit{v.s.} 92.18 M). Overall, LightFC-E and LightFC-E-ST demonstrate state-of-the-art performance for lightweight RGB-E tracking.

\textbf{RGBS50.} RGBS50~\cite{rgbs50} is a classic RGB-Sonar tracking benchmark comprising 50 sequences. As shown in Tab.~\ref{table rgbs}, for RGB sequences, LightFC-S outperforms LightFC~\cite{lightfc} by 2.4\% and 3.6\% in SR and NPR. For sonar sequences, compared to LightFC~\cite{lightfc}, LightFC-S improves the SR and PR by 17.3\% and 30.2\%, respectively. The results show the effectiveness of our method in spatially misaligned multimodal tracking. Overall, LightFC-S achieves state-of-the-art performance in lightweight RGB-S tracking.

\textbf{Params and FLOPs.} Tab.~\ref{table params and flops and speed} presents the speeds of the proposed trackers. On the resource-constrained GPU GTX1050Ti, LightFC-X, LightFC-D-N3, and LightFC-S run at 34, 27, and 24 \textit{fps}, respectively. Before deployment, LightFC-X runs in real-time on the CPU Intel I9-12900KF at 22 \textit{fps}. After deployment, LightFC-X, LightFC-D-N3, and LightFC-S all achieve real-time speed on the CPU. On the Xavier edge device, LightFC-X, LightFC-D-N3, and LightFC-S run at 51, 46, and 42 \textit{fps}, respectively. Overall, the LightFC-X family shows significant potential for practical deployment.

\subsection{Ablation Studies}

\ 

\textbf{Component Analysis.} We evaluate the contribution of each component of the proposed modules. As shown in Tab.~\ref{table ablation ecm}, each component of the ECAM and STAM modules contributes to the performance improvement. In particular, within the tracking framework, concatenating the original features from the search area with the output features of the ECAM module effectively complements the original semantic features of the target, thereby improving the performance of the prediction head.

\textbf{Number of ECAM Modules.} We evaluate the effect of inserting different numbers of ECAM modules on performance. As shown in Tab.~\ref{table ablation number ecm}, the ECAM module only has 0.08M parameters. LightFC-T and LightFC-E achieve the best performance when one ECAM module is inserted. For RGB-D tracking, performance is optimal when three ECAM modules are inserted. Excessive insertion of ECAM modules leads to a decline in model performance. Therefore, we present two versions for RGB-D tracking. LightFC-D shares the same structure as LightFC-T and LightFC-E. LightFC-D-N3 achieves superior performance with a slight increase in parameters.


\input{figs/variant}
\input{tables/ablation_variant}

\input{tables/ablation_stam}


\textbf{Different Framework Variants.} We explore different framework variants of our LightFC-X. As shown in Fig.~\ref{fig:variant},  variant (a) aims to explore the cross-modal feature integration in the backbone. Variants (b-d) aim to explore cross-modal feature integration before the template-search area interaction. Variants (e-f) and LightFC-X aim to explore cross-modal feature integration after the template-search area interaction. The results are shown in Tab.~\ref{table ablation variant}, LightFC-X achieves state-of-the-art performance among all variants. This shows that cross-modal feature integration after template-search area interaction is more suitable for lightweight multimodal Siamese tracker.



\textbf{Training paradigm of STAM module.} We explore different training paradigms of our STAM module on LightFC-D-N3, LightFC-T, and LightFC-E. As shown in Tab.~\ref{table ablation stam}, freezing the tracking model during the training of the STAM module effectively improves the tracking performance.



\subsection{Visualization}
\input{figs/heatmap}
 To explore how our model works, we visualize the heat maps before and after cross-modal interaction in Fig.~\ref{fig: heatmap}. Our method effectively improves feature discrimination in challenging multimodal tracking scenarios.
