\section{Related Work}
\label{sec:related}


\subsection{Lightweight Visual Object Tracking}
LightTrack~\cite{litetrack} uses Neural Architecture Search (NAS) technology to design a lightweight convolutional tracker. E.T.Track~\cite{ettrack} proposes an exemplar Transformer module for efficient tracking. FEAR~\cite{fear} proposes a hand-designed lightweight convolutional model and introduces a dual template update mechanism. MixFormerV2-S~\cite{mixformerv2s} proposes a one-stream Transformer framework based on knowledge distillation. HiT~\cite{hit} integrates the high-level semantics of the target features into the low-level features level by level in the Transformer model for achieving better features. SMAT~\cite{smat} proposes a separable mixed attention Transformer and an efficient self-attention module for lightweight tracking. LightFC~\cite{lightfc} explores the benefits of feature refinement for template-search area interacted feature and proposes a reparameterized prediction head. LiteTrack~\cite{litetrack} proposes a Transformer-based asynchronous feature extraction and interaction model. Although these methods are efficient, most of them are Transformer-based trackers, which inevitably increases their parameters. In this work, to achieve an optimal balance between parameters, FLOPs, performance, and speed, we adopt a convolutional architecture and we focus on making it more efficient.

\input{figs/framework}

\subsection{Lightweight Multimodal Tracking}
Some MDNet trackers for RGB-T tracking have fewer parameters, such as MANet~\cite{manet} has 7.28M parameters, DAFNet~\cite{dafnet} has 5.50M parameters, and MANet++~\cite{manetpp} has 7.38M parameters. However, shallow feature extraction networks limit the model's use of deep discriminative features. CMD~\cite{cmd} proposes a feature distillation module to facilitate a shallow network to learn multimodal feature representations of targets. TBSI~\cite{tbsi} provides a lightweight version, TBSI-Tiny, which inserts template search area bridging modules into ViT-Tiny. In addition, USTrack~\cite{ustrack} and FTOS~\cite{ftos} achieve high-speed GPU operation through knowledge distillation.
For other multimodal tracking, very few lightweight trackers are currently publicly reported. 
In this work, compared with these efficient multimodal trackers, LightFC-X not only achieves state-of-the-art performance but also achieves the optimal balance between parameters, performance, FLOPs, and speed.

\subsection{Spatiotemporal Template update}

UpdateNet~\cite{updatenet} proposes a convolutional template update network to achieve optimal template estimation for SiamFC~\cite{siamfc}. LTMU~\cite{ltmu} proposes a meta-updater to determine the conditions for template update. TCTrack~\cite{tctrack} proposes temporally adaptive convolution and Transformer modules. Stark-ST~\cite{stark} proposes a dynamic template usage and updating method within the Transformer framework. ODTrack~\cite{odtrack} models spatiotemporal information using continuously propagating trajectory tokens. AQATrack~\cite{aqatrack} uses an auto-regressive query to learn the spatiotemporal features of the target across  successive frames. TATrack~\cite{tatrack} proposes a spatiotemporal two-stream structure and online template-update method. However, these methods are developed for large trackers and are difficult to apply to lightweight trackers. FEAR~\cite{fear} proposes a template update method for lightweight trackers. However, this method utilizes linear interpolation for naive template updates. In this work, we use cross-attention to model the spatial feature associations between fixed and dynamic templates to achieve deep exploitation of temporal appearance features.
