\section{Related Works}
\label{App:RelatedWorks}
\textbf{RL with constraints:} RL problems with cumulative constraints are studied in 
\citet{wu2016conservative, achiam2017constrained, tessler2018reward, yang2019projection, efroni2020exploration, NEURIPS2020_ae95296e, ding2021provably, bai2022achieving, wei2022triple, paternain2022safe, ghosh2022provably, vaswani2022near, ghosh2022achieving, ding2023provably, ghosh2023achieving, huang2023safe, ghosh2024towards}. This line of work focuses on ensuring the expected cumulative cost remains below a threshold, unlike instantaneous constraints that must be satisfied with high probability at each time step.

\textbf{Bandits with instantaneous hard constraints:} Bandits with instantaneous constraints have been studied in \citet{amani2019linear, khezeli2020safe, moradipari2020linear, moradipari2020stage, moradipari2021safe, pacchiano2021stochastic, zhou2022kernelized, deng2022interference, pacchiano2024contextual, hutchinson2024directional, afsharrad2024convex}. Unlike RL, Bandits do not require the estimation of a value function, and therefore the problem of covering number does not arise in this setting. This distinction significantly simplifies the analysis and algorithm design in the context of Bandits compared to RL with instantaneous hard constraints.

\textbf{RL with instantaneous hard constraints:} Problems with unsafe states in a star-convex setting have been studied in \citet{shi2023near}. However, this setting focuses on the linear mixture model, which is fundamentally different from our setting, as explained in Section~\ref{sec:problem_formulation_continuous_action_space}. Lastly, work in \citet{wei2024safe} relaxed the assumption that a prior safe action is given to the algorithm, instead allowing sublinear constraint violation. Thus, none of the above works have studied RL with instantaneous hard constraints for non-star-convex decision spaces.