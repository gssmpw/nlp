%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
%\usepackage{PRIMEarxiv}



\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{xcolor} 
\usepackage{amsmath }
%\usepackage{amssymb}
%\usepackage{algorithm}
%\usepackage{algpseudocode}
%\usepackage{subcaption}
\usepackage{svg}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}


% Recommended, but optional, packages for figures and better typesetting:


% \newtheorem{assumption}{Assumption}
% \newtheorem{theorem}{Theorem}
% \newtheorem{lemma}{Lemma}
% \newtheorem{definition}{Definition}
% %\theoremstyle{remark}
% \newtheorem{remark}{Remark}
% \newtheorem{proposition}{Proposition}


% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Provably Efficient RL for Linear MDPs under Instantaneous Safety Constraints in Non-Convex Feature Spaces}

\begin{document}


\twocolumn[
\icmltitle{Provably Efficient RL for Linear MDPs under\\ Instantaneous Safety Constraints in Non-Convex Feature Spaces}


\begin{icmlauthorlist}
\icmlauthor{Amirhossein Roknilamouki}{yyy}
\icmlauthor{Arnob Ghosh}{xxx}
\icmlauthor{Ming Shi}{comp}
\icmlauthor{Fatemeh Nourzad}{yyy}
\icmlauthor{Eylem Ekici}{yyy}
\icmlauthor{Ness B. Shroff}{yyy,sch}
\end{icmlauthorlist}
\icmlaffiliation{yyy}{Department of Electrical and Computer Engineering, The Ohio State University}
\icmlaffiliation{sch}{Department of Computer Science and Engineering, The Ohio State University}
\icmlaffiliation{xxx}{Department of Electrical and Computer Engineering, New Jersey Institute of Technology}
\icmlaffiliation{comp}{Department of Electrical Engineering
University at Buffalo}
\icmlcorrespondingauthor{Amirhossein Roknilamouki}{roknilamouki.1@osu.edu}
\icmlcorrespondingauthor{Arnob Ghosh}{arnob.ghosh@njit.edu}
\icmlcorrespondingauthor{Ming Shi}{mshi24@buffalo.edu}
\icmlcorrespondingauthor{Fatemeh Nourzad}{nourzad.1@osu.edu}
\icmlcorrespondingauthor{Eylem Ekici}{ekici.2@osu.edu}
\icmlcorrespondingauthor{Ness B. Shroff}{shroff.11@osu.edu}



% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
%\icmlsetsymbol{equal}{*}

% \begin{icmlauthorlist}
% \icmlauthor{Firstname1 Lastname1}{equal,yyy}
% \icmlauthor{Firstname2 Lastname2}{equal,yyy,comp}
% \icmlauthor{Firstname3 Lastname3}{comp}
% \icmlauthor{Firstname4 Lastname4}{sch}
% \icmlauthor{Firstname5 Lastname5}{yyy}
% \icmlauthor{Firstname6 Lastname6}{sch,yyy,comp}
% \icmlauthor{Firstname7 Lastname7}{comp}
% %\icmlauthor{}{sch}
% \icmlauthor{Firstname8 Lastname8}{sch}
% \icmlauthor{Firstname8 Lastname8}{yyy,comp}
% %\icmlauthor{}{sch}
% %\icmlauthor{}{sch}
% \end{icmlauthorlist}

% \icmlaffiliation{yyy}{Department of XXX, University of YYY, Location, Country}
% \icmlaffiliation{comp}{Company Name, Location, Country}
% \icmlaffiliation{sch}{School of ZZZ, Institute of WWW, Location, Country}

% \icmlcorrespondingauthor{Firstname1 Lastname1}{first1.last1@xxx.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
%\icmlkeywords{Machine Learning, ICML}
\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
\begin{abstract}
In Reinforcement Learning (RL), tasks with instantaneous hard constraints present significant challenges, particularly when the decision space is non-convex or non-star-convex. This issue is especially relevant in domains like autonomous vehicles and robotics, where constraints such as collision avoidance often take a non-convex form. In this paper, we establish a regret bound of \(\tilde{\mathcal{O}}\bigl(\bigl(1 + \tfrac{1}{\tau}\bigr)  \sqrt{\log\bigl(\tfrac{1}{\tau}\bigr)  d^3 H^4 K}  \bigr)\), applicable to both star-convex and non-star-convex cases, where \(d\) is the feature dimension, \(H\) the episode length, \(K\) the number of episodes, and \(\tau\) the safety threshold.  Moreover, the violation of safety constraints is zero with high probability throughout the learning process. A key technical challenge in these settings is bounding the covering number of the value-function class, which is essential for achieving value-aware uniform concentration in model-free function approximation. For the star-convex setting, we develop a novel technique called \textit{Objective–Constraint Decomposition} (OCD) to properly bound the covering number. This result also resolves an error in a previous work on constrained RL. In non-star-convex scenarios, where the covering number can become infinitely large, we propose a two-phase algorithm, Non-Convex Safe Least Squares Value Iteration (NCS-LSVI), which first reduces uncertainty about the safe set by playing a known safe policy. After that, it carefully balances exploration and exploitation to achieve the regret bound. Finally, numerical simulations on an autonomous driving scenario demonstrate the effectiveness of NCS-LSVI.

%In non-star-convex scenarios, where the covering number can become prohibitively large, we propose a new two-phase algorithm, Non-Convex Safe Least Squares Value Iteration (NCS-LSVI) to mitigate this effect. The algorithm first plays a known safe policy to reduce uncertainty about the safe set of actions. After that, it carefully balances exploration and exploitation to achieve the regret bound. Notably, this initial safe exploration phase is necessary to bound the covering number during the second phase. We conduct numerical simulations on an autonomous driving scenario, highlighting the effectiveness of NCS-LSVI.

\end{abstract}

\section{Introduction}
% Safe Reinforcement learning (RL) has emerged as a powerful framework for \textit{safe online learning}, enabling agents to \textit{learn autonomously} from the environment through interactions while respecting safety constraints \cite{wu2016conservative, achiam2017constrained, tessler2018reward, ghosh2022provably}. In many safety-critical applications—such as \textit{autonomous driving}, \textit{healthcare}, and \textit{financial planning}—it is imperative that the agent not only maximizes cumulative rewards but also ensures \textit{safety at every step} of the decision-making process \cite{shi2023near, amani2021safe}. These applications often involve \textit{instantaneous hard constraints}, which must be satisfied at all times to prevent \textit{catastrophic outcomes}. This underscores the need for RL methods that can simultaneously explore and exploit without compromising safety.

Safe Reinforcement Learning (RL) has emerged as a powerful framework for safe online learning, enabling agents to learn autonomously from their environments while respecting safety constraints \cite{ tessler2018reward, ghosh2022provably}. In many safety-critical applications—such as autonomous driving, healthcare, and financial planning—it is imperative that the agent not only maximizes cumulative rewards but also maintains safety at every step of the decision-making process \cite{shi2023near, amani2021safe}. These applications often feature instantaneous hard constraints, which must be satisfied at each time step to prevent catastrophic outcomes (e.g., avoiding collisions in autonomous driving). Unlike constraints that allow violations in expectation or across an entire trajectory, instantaneous hard constraints demand adherence strictly at every decision point, highlighting the need for RL methods that can explore and exploit without compromising immediate safety.



%Star-convexity is a geometric property that subsumes purely convex sets (see Section \ref{Sec:Non_ConvexFeratureSpace_IMCL_1} for further details).

\citet{amani2021safe} tackled this challenge by introducing a strategy for Safe RL with instantaneous hard constraints  in star-convex decision spaces within linear MDPs. \citet{amani2021safe} assume that at every state, there exists an initial safe action that is known to the RL agent. The agent begins interacting with the environment using this initial safe action, subsequently constructing and refining an estimated safe set of actions that remain within the actual safe set of actions.  However, as described below, \textit{their analysis to prove sublinear regret is not correct} (with further details provided in Section \ref{Section:StarConvexResults_Problem_ICML_SAFERL_1}). The key issue arises in bounding the covering number for the value function, a crucial step for achieving value-aware uniform concentration in model-free function approximation. Their Theorem 2 relies on results from unconstrained RL (Lemma D.6 in \citet{jin2020provably}), where the value function is obtained by maximizing the Q-function over a fixed action set. In such cases, a covering of the Q-function automatically induces a covering of the value function, thanks to the contraction property of the \(\max\) operator.  However, in the constrained RL framework of \citet{amani2021safe}, the value function is computed by maximizing the Q-function over an estimated safe set that depends on the random historical data. Consequently, even when the Q-function remains the same, differences in the corresponding safe sets can lead to drastically different value functions. This invalidates the direct application of unconstrained RL’s covering-number bounds, and the analysis in \citet{amani2021safe} must be significantly revised to account for the dynamic nature of the safe set.

As our \textbf{first main contribution}, we show how to \emph{correctly bound the covering number} when the feasible action set is updated over time in the star-convex case. Specifically, we identify that star-convexity provides a form of smooth geometry—small variations in the safety parameters do not cause \emph{drastic} changes in the estimated safe set.  Consequently, if two Q-functions are close, the corresponding value functions—obtained by maximizing each Q-function over these slightly different feasible sets—also remain close. Leveraging this property, we introduce the novel OCD (Objective–Constraint Decomposition) technique, which replaces the unconstrained covering-number argument with a refined bound that includes an additional term of the form \(\mathcal{O}\left(\sqrt{\log\bigl(\tfrac{1}{\tau}\bigr)}\right)\), where \(\tau\) is the safety threshold. This factor reflects how tighter safety requirements (\emph{i.e.}, smaller \(\tau\)) make bounding the covering number more challenging, offering a fresh perspective on the cost of satisfying \emph{instantaneous} constraints (See Rmark~\ref{Remark:InsightSafetyCovering}).


While star-convex geometry can be gentle on covering-number bounds, real-world problems such as autonomous driving and robotics often induce non-star-convex or highly irregular safe decision spaces—e.g., disjoint regions due to obstacles or kinematic constraints. In these settings, as detailed in Section~\ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}, the covering number can become arbitrarily large, rendering existing star-convex-based methods insufficient and highlighting the \textit{necessity of developing new methods for non-star-convex environments}.

% In these settings, our toy example (Section~\ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}) shows that the covering number can become \emph{arbitrarily large}, rendering existing star-convex-based methods insufficient. This limitation \emph{highlights the necessity of developing new methods} for non-star-convex environments.


Motivated by these observations, we propose a new two-phase algorithm for non-star-convex scenarios that satisfy our Local Point Assumption (see Section~\ref{Sec:Non_ConvexFeratureSpace_IMCL_1}), which we refer to as Non-Convex Safe Least Squares Value Iteration (NCS-LSVI).  Drawing from our insight in star-convex analysis, we observe that controlling drastic changes in the estimated safe set under small variations in constraint parameters is a key strategy for bounding the covering number. Based on this, NCS-LSVI includes a pure-safe exploration phase, where the agent samples randomly from safe actions in a small neighborhood of the initial safe policy (whose existence is guaranteed by the Local Point Assumption). By the end of this phase, the estimated safe set remains stable with high probability, enabling tighter covering-number bounds.  


% Motivated by these observations, we propose a new approach for \emph{non-star-convex} problems where global connectivity is absent. Specifically, we focus on scenarios with an \emph{initial safe action}, around which we can explore a small neighborhood—an assumption we formalize in our \emph{Local Point Assumption} (Section~\ref{Sec:Non_ConvexFeratureSpace_IMCL_1}). Moreover, near the constraint boundaries, we assume that the decision set has sufficiently smooth structure (akin to local star-convexity). This localized connectivity is realistic in many safety-critical domains—\emph{e.g.}, autonomous vehicles and robotics—where local exploration around a baseline operating point is common in control theory and system identification.


% Drawing from our star-convex analysis, the key insight is that \emph{any} viable safe RL strategy must ensure the estimated safe set does not change \emph{drastically} under small variations in the constraint parameters. In a non-star-convex environment under Local Point Assumption, we address this by running a \emph{pure-safe exploration phase}, during which the agent samples randomly from actions in a neighborhood of the initial safe policy (whose existence is guaranteed by the Local Point Assumption). By the end of this phase, the agent’s \emph{estimated safe set} covers most feasible points away from the constraint boundary, and we show that the estimated safe set remains stable under small variations of safety parameter with a high probability. Consequently, \emph{this} stability allows us to control the covering number of class value functions with high probability.


% Having established a stable safe set, the agent then proceeds to an \emph{exploration–exploitation phase}, where it refines its policy under a bounded covering-number framework. We refer to this two-phase approach as \emph{Non-Convex Safe Least Squares Value Iteration (NCS-LSVI)}, detailed in Section~\ref{sec:OurAPproach_SafeRL_ICML_1}. NCS-LSVI achieves a regret bound of \(\tilde{\mathcal{O}}\left( (1 +  \frac{1}{ \tau}) d^3 H^4 K  + \frac{1}{\epsilon^2 \iota^2} \right)\), with high probability, nearly matching the regret in convex and star-convex cases while also meeting the instantaneous hard constraints. 

Having established this stable safe set, the agent then proceeds to an exploration–exploitation phase, refining its policy under a bounded covering-number framework.  As our second contribution, we show that  NCS-LSVI achieves a regret bound of \(\tilde{\mathcal{O}}(\bigl(1 + \tfrac{1}{\tau}\bigr)  \sqrt{\log\bigl(\tfrac{1}{\tau}\bigr)  d^3 H^4 K}  + \tfrac{1}{\epsilon^2 \iota^2}  )\) with high probability, nearly matching the regret in convex and star-convex cases while also respecting instantaneous hard constraints.  Here, \(d\) represents the feature space dimension, \(H\) the episode length, \(K\) the number of episodes, and \(\tau\) a safety related parameter. The bounded constant parameters \(\epsilon\) and \(\iota\) are related to our Local Point Assumption (\ref{assumption:epsilon_origin_1}). \textit{To the best of our knowledge, this is the first result for non-star-convex settings.}  Additionally, we conduct a numerical experiment on a merging scenario in autonomous driving, where the safe set is non-star-convex due to collision-avoidance constraints. The results demonstrate sublinear regret, consistent with the theoretical upper bound, and highlight the practical potential of our two-phase framework.


Pure exploration has also been studied in the context of safe linear bandits by \citet{amani2019linear}, where it was specifically designed to ensure that the optimal point is included in the estimated safe set at the end of the exploration phase. In comparison, linear bandits are simpler than RL, as they do not involve estimating a value function or managing the covering number. In our work, the safe pure exploration phase serves a different purpose: it is specifically designed to control the covering number in the second phase of our algorithm, enabling near-optimal performance even in non-star-convex spaces.

Altogether, our work highlights the pivotal role of the decision space's geometry in shaping the complexity of safe RL. While this study focuses on linear function approximation and local connectivity, the broader takeaway is that \emph{additional mechanisms} beyond those used in unconstrained RL are crucial for maintaining tight covering numbers under instantaneous hard constraints. This insight opens up promising directions for future research, particularly in \emph{deep} RL, where nonlinear representations often create irregular feature spaces. These complexities further underscore the importance of understanding how the geometry of the feature space impacts overall performance.






% However, the above work made a mistake in \textit{ bounding the covering number} for the value function, a key step to obtain the value-aware uniform concentration, which lies in the heart of the model-free function approximation setting. \cite{amani2021safe} derives the covering number based on the \textit{unconstrained} RL \cite{jin2020provably} results, where the entire action space remains \textit{fixed} over time. However, in their \textit{constrained} setting, the feasible action set \textit{evolves} as the safe set is updated, making the unconstrained bounding technique inapplicable. This oversight inflates the effective covering number and \textbf{undermines the theoretical guarantees of \cite{amani2021safe}}. \emph{In Section~\ref{Sec:CoveringNumber_ProofSteps_ICML_1}, we demonstrate how this dynamic safe set substantially alters the covering number, ultimately affecting the  regret bounds.} As a \textbf{first} contribution, we fixed the issue and derived the correct the covering number for such dynamically varying safe action-space. Based on this, we obtain the first result that achieves the regret bound for instantaneous hard constraint setup. 
% However, a central limitation in their work is that they have made a mistake in \textbf{incomplete bounding of the covering number} for the value-function class. In RL theory, the covering number measures the complexity or “richness” of the function space needed to approximate the true value function. Ensuring a finite covering number is critical for proving uniform convergence results and guaranteeing \textit{sublinear regret}, as it constrains how many hypotheses the agent must consider to achieve accurate value estimates. In \cite{amani2021safe}, the authors rely on covering-number bounds derived for \textit{unconstrained} RL \cite{jin2020provably}, where the entire action space remains \textit{fixed} over time. However, in their \textit{constrained} setting, the feasible action set \textit{evolves} as the safe set is updated, making the unconstrained bounding technique inapplicable. This oversight inflates the effective covering number and \textbf{undermines the theoretical guarantees of \cite{amani2021safe}}. \emph{In Section~\ref{Sec:CoveringNumber_ProofSteps_ICML_1}, we demonstrate how this dynamic safe set substantially alters the covering number, ultimately affecting the sample complexity and regret bounds.}




% Building upon the insights of Amani et al.~\cite{amani2021safe}, our first contribution is to \textbf{properly bound the covering number in the star-convex case}, tightening the theoretical analysis of safe RL under star-convexity. In scenarios where the decision space remains star-convex, this refined analysis confirms that the overall complexity of safe RL can be kept under control. 
% While achieving results in the star-convex cases, is important, some real-world environments do not exhibit star-convex decision spaces; indeed, \textit{non-star-convex settings} can have disjoint or highly irregular safe sets. For example, in domains such as \textit{autonomous driving} and \textit{robotics}, the feature space often takes on non-convex shapes due to traffic rules, collision avoidance requirements, and kinematic constraints. In these cases, the covering number can become \textbf{arbitrarily large}, as we demonstrate through a toy example in Section~\ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}. As a result, the existing approaches \cite{amani2021safe} breaks down, as it critically relies on the ability to bound the covering number. This highlights the necessity of developing new methods tailored to non-star-convex settings.




% Motivated by these observations, we propose a new approach for \textit{non-star-convex} problems in which global connectivity is absent. Specifically, we focus on situations where we have an \textit{initial safe action} and can explore within a small neighborhood around it—a requirement we formalize as the \textit{Local Point Assumption} provided in Section \ref{Sec:Non_ConvexFeratureSpace_IMCL_1}. This localized connectivity is realistic in many safety-critical applications—such as \textit{autonomous vehicles} and \textit{robotics}—where safe actions exist near an initial operating point, and local exploration is common in \textit{control theory} and \textit{system identification}.

% Our algorithm, \textit{Non-Convex Safe Least Squares Value Iteration (NCS-LSVI)}, operates in \textbf{two distinct phases}, as detailed in Section~\ref{sec:OurAPproach_SafeRL_ICML_1}. The first phase, called the \textit{pure exploration phase}, involves systematically exploring the action space near the initial safe action to \textbf{expand the agent's estimated safe set}. \textbf{This phase is critical not only for enabling the agent to discover more safe actions but also for helping us to bound the covering number of the class of value functions, which ensures that the agent can properly estimate the value function in the second phase of the algorithm.} 



% Explore-then-commit is a well-known strategy in unconstrained RL \cite{sutton2018reinforcement}. In the context of safe linear bandits, \citet{amani2019linear} proposed a pure exploration phase specifically to include the optimal point in the safe set. However, our approach fundamentally differs: while \cite{amani2019linear} aimed at ensuring the optimal point was included, we employ the pure exploration phase to manage the covering number in non-star-convex spaces. Importantly, by the end of this phase, we do not guarantee that the optimal point is in the estimated safe set. \emph{Instead, this initial exploration stabilizes the estimated safe set, ensuring that small changes in the constraint parameters no longer result in drastic alterations to the safe set available to the agent.} As a result, once this phase is complete, the log-covering number remains polynomial even in our non-star-convex scenario. Consequently, this structured exploration provides a robust foundation for safely navigating non-star-convex environments, marking a significant advance in safe RL at both practical and theoretical levels.




% The second phase, the \textit{exploration–exploitation phase}, builds on the expanded safe set from the first phase. The agent refines its estimated safe set while optimizing its policy based on an adaptive bonus term, ensuring a balance between exploring new actions and exploiting previously learned safe policies.  


% \textbf{Contributions.}
% In this work, we consider episodic Markov Decision Processes (MDPs) with linear function approximation under \textit{instantaneous hard constraints} in \textit{non-star-convex} action spaces. Our main contributions can be summarized as follows:

%  \textbf{Two-phase algorithm with sub-linear regret.} We propose a novel algorithm, NCS-LSVI, which operates in two distinct phases (\textit{pure exploration} and \textit{exploration–exploitation}). Under the Local Point Assumption (Assumption \ref{assumption:epsilon_origin_1}), we show that our algorithm attains a sub-linear upper bound on the regret of the form \(\widetilde{O}\big( (1+ \frac{1}{\tau \epsilon \iota^2}) \sqrt{d^3 H^4 K}\big)\) with high probability, while respecting instantaneous safety constraints throughout learning.
    

% \textbf{Covering number analysis in non-star-convex settings.} We rigorously bound the covering number for our class of value functions during the pure exploration phase, which enables accurate value-function approximation in non-star-convex environments. Notably, we demonstrate through a toy example that in these settings the covering number can grow arbitrarily large if no structured exploration is employed.
    

% \textbf{Refined results in star-convex spaces.} Under the assumption that the decision space is star-convex (Assumption~\ref{assumption:Star_ConvexAssumption_1}), we establish that the pure exploration phase can be entirely skipped. The global connectivity of star-convex sets guarantees a manageable covering number, enabling our algorithm to achieve a sub-linear upper bound on regret of the form \(\widetilde{O}\big( (1+ \frac{1}{\tau}) \sqrt{d^3 H^4 K} \big)\). This bound improves upon the regret under the Local Point Assumption (Assumption~\ref{assumption:epsilon_origin_1}) by a factor of \(\frac{1}{\epsilon \iota^2}\). Moreover, our analysis corrects a critical oversight in the work of Amani et al.~\cite{amani2021safe}, where the covering number was not properly bounded, leading to gaps in their theoretical guarantees. These results highlight how the geometric properties of star-convex sets can simplify algorithm design and significantly reduce sample complexity.


% \textbf{Empirical validation in safety-critical tasks.} We conduct extensive experiments, including an autonomous driving scenario with non-convex safety constraints, showing that NCS-LSVI outperforms existing baselines in terms of safety, efficiency, and regret. This underscores the practical importance of our two-phase framework in real-world RL applications where ensuring safety at every timestep is paramount.


\textbf{Other related works.}
We have provided a comprehensive literature review on constrained RL in Appendix \ref{App:RelatedWorks}.







\section{Problem formulation}
\label{sec:problem_formulation_continuous_action_space}

In this study, we focus on an episodic constrained MDP, denoted as \( (\mathcal{S}, \mathcal{A}, H, \mathbb{P}, r, c) \), operating in an online setting over \(K \in \mathbb{N}\) episodes. Here, \(\mathcal{S}\) represents the state space, which may contain an infinite number of states; \(\mathcal{A}\) denotes a continuous action space; and \(H \in \mathbb{N} \) determines the number of steps within each episode. Additionally, \(\{\mathbb{P}\}_{h=1}^H\), \(\{r\}_{h=1}^H\), and \(\{c\}_{h=1}^H\) correspond to the state transition probability kernel, reward function, and cost function at each step, respectively.  During episode \(k \in [K]\) and time step \(h \in [H] \), the learner is in state \(s_h^k\in \mathcal{S} \), interacting with the environment by selecting an action \(a_h^k \in \mathcal{A}\). Subsequently, the learner observes a noisy reward \(\hat{r}_h^k(s_h^k, a_h^k) = r_h(s_h^k, a_h^k) + \eta_h^k \), where \(r_h(.): \mathcal{S} \times \mathcal{A} \to [0,1]\) represents an unknown function, and \(\eta_h^k\) denotes a zero-mean \(\sigma\)-sub-Gaussian random variable. In addition, it observes a corresponding noisy cost \(\hat{c}_h^k(s_h^k, a_h^k) = c_h(s_h^k, a_h^k) + \zeta_h^k \), where \(c_h(.): \mathcal{S} \times \mathcal{A} \to [0,1]\) is an unknown cost function, and \(\zeta_h^k \) is a zero-mean \(\sigma\)-sub-Gaussian random variable as well. Finally, the transition to the next state, \(s_{h+1}^k\), under the action \( a_h^k \) at state \(s_h^k\), is determined by an unknown transition probability kernel denoted as \(\mathbb{P}_h(.|s_h^k, a_h^k)\). The episode terminates at step \(H+1\).


\textbf{Instantaneous hard constraint.} 
In each episode \(k \) and at each step \(h\), the learner is required to adhere to a hard constraint: \(c_h(s_h^k, a_h^k) \leq \tau\), where \(\tau\) is a known positive constant that serves as the safety threshold. For each state \(s \in \mathcal{S}\), the corresponding safe set of actions is given by \( \mathcal{A}^{\text{safe}}_{h} (s) = \{ a \in \mathcal{A}:  c_h(s, a) \leq  \tau \}\).


\textbf{Safe policy.} 
A deterministic policy is defined as a mapping \(\pi(s,h): \mathcal{S} \times [H] \to \mathcal{A}\).  Thus, a policy \(\pi\) is called safe, if, for every state \( s \in \mathcal{S}\) and time step \(h \), it satisfies the instantaneous constraint. Therefore, the set of all safe policies is defined by \( \Pi^{\text{safe}} =  \{ \pi(.): \pi(s,h) \in \mathcal{A}^{\text{safe}}_h(s), \, \forall (s,h) \in \mathcal{S}\times [H] \}\).



\textbf{Performance metric.} 
Given a policy \( \pi \), the corresponding \(V\)-value and the \(Q\)-value are defined as follows: \( V^{\pi}_h(s) = E[\Sigma_{h^{'}=h}^H r_{h^{'}}(s_{h^{'}}, \pi(h^{'}, s_{h^{'}}))| s_h = s]\), and \(Q^{\pi}_h(s,a) = r_h(s,a) +  E[\Sigma_{h^{'}=h+1}^H r_{h^{'}}(s_{h^{'}}, \pi(h^{'}, s_{h^{'}}))|s_h = s, a_h = a]\). Assume that each episode starts with a fixed initial state \(s_1 \in \mathcal{S}\). The agent, at each episode \(k\in[K] \), employs the policy \(\pi^k\) to interact with the environment. We then evaluate the performance of the set of policies \(\{\pi^k \}_{k=1}^K\) by the well-studied regret metric, defined as  \( \text{Regret}(K) \triangleq \sum_{k=1}^K [V_1^{\pi^*}(s_1) - V_1^{\pi^k}(s_1)]\).  Note that \(\pi^*\) is the optimal safe policy that maximizes \(V\)-value function, while remaining safe \(\pi^* \in   \Pi^{\text{safe}} \).

\textbf{Linear MDP.} To handle the large and potentially infinite number of states and actions, we concentrate on linear  MDPs. This choice enables us to employ linear function approximation methods to solve our problem effectively.

\begin{assumption} 
\label{assumption:LinearMDP}
    (Linear MDP \cite{ghosh2022provably}, \cite{jin2020provably}) 
    Consider an episodic constrained MDP denoted as \( (\mathcal{S}, \mathcal{A}, H, \mathbb{P}, r, c) \), which is assumed to be a linear MDP with a feature function \(\phi: \mathcal{S} \times \mathcal{A} \to \mathcal{F} \subset \mathbb{R}^d\). Specifically, for each \(h \in [H]\), there exist \(d\) unknown measures \( \mu_h  = \{\mu_h^1, \ldots, \mu_h^d\}\) over the state space \(\mathcal{S}\) and unknown vectors \(\theta^*_h, \gamma^*_h \in \mathbb{R}^d\) such that for any \( (s,a,s') \in \mathcal{S} \times \mathcal{A} \times \mathcal{S}\), the transition probabilities, cost function, and reward function are given by: \( \mathbb{P}_h(s'|s,a) = \langle \phi(s,a), \mu_h(s')\rangle\),  \(r_h(s,a) = \langle \phi(s,a), \theta^*_h\rangle\), and \( c_h(s,a) = \langle \phi(s,a), \gamma^*_h\rangle\), respectively. Additionally, we assume without loss of generality that for all \((s,a) \in \mathcal{S}\times \mathcal{A}\), we have \(\rVert \phi(s,a) \lVert \leq L\) for some \(L \in (0,1]\), and \(\max(\rVert\mu(\mathcal{S})\lVert, \rVert\theta^*_h\lVert, \rVert \gamma^*_h \lVert) \leq \sqrt{d}\), where \(d\) is the dimension of the feature space.
\end{assumption}

Assumption \ref{assumption:LinearMDP} encapsulates the linear relationship of the transition probabilities, costs, and rewards with the feature map. It is important to note that despite the linearity, the feature map \( \phi(.)\) itself may potentially be non-linear or even non-convex.  Note that, the linearity of the transition probabilities, results in the fact that all features points are located on  a \(d-1\) dimensional hyper plane as explained in the following proposition:

\begin{proposition}
\label{Propisition:linearMDP_1} (Proposition~A.1. from \citet{jin2020provably}).
    Let \(\mathcal{F}_s \triangleq \{\phi(s,a) \in \mathbb{R}^d \mid a \in \mathcal{A} \}\), and \(\mathcal{F} \triangleq \{\phi(s,a) \in \mathbb{R}^d \mid (a,s) \in \mathcal{A}\times \mathcal{S} \}\). Then, there exists a vector \(\mu^* \in \mathbb{R}^d\) such that \(\mathcal{F}_s \subset \mathcal{F} \subset \mathcal{H}\), where \(\mathcal{H}\) is a \(d-1\) dimensional hyper plane determined by \(\mathcal{H} \triangleq \{x \in \mathbb{R}^d \mid \langle x, \mu^* \rangle = 1\}\). 
\end{proposition}




\textbf{Initial safe action.}
Designing a safe RL algorithm that achieves sublinear regret requires at least one known safe action per state \(s \in \mathcal{S}\), as shown in Theorem 3 of \cite{shi2023near}. This assumption is often valid in real-world scenarios where a known, albeit suboptimal, safe strategy exists \cite{amani2019linear,amani2021safe, khezeli2020safe}. In this study, we also adopt a similar assumption as stated bellow.

\begin{assumption}
    \label{assumption:startingPoint_1}
    For each state \(s \in \mathcal{S}\), there exists a safe action \(a_s^0\) that incurs a zero cost, i.e., \(\langle \phi(s,a_s^0), \gamma^*_h \rangle = 0\). 
\end{assumption}

\begin{remark}
  We highlight that for problems where the initial action results in a non-zero cost \(\tau_0\), the original problem can be converted to an equivalent one that satisfies Assumption~\ref{assumption:startingPoint_1} through a simple translation. In the new problem, the safety threshold is adjusted to \(\tau - \tau_0\).
\end{remark}
\textbf{Notations.} 
 For any positive semi-define matrix \(A\) and vector \(v\), the operator \(\lVert v \rVert_A\) defines the weighted norm as \(\lVert v \rVert_A \triangleq \sqrt{v^T A v}\). The symbol \(\lVert. \rVert\) denotes the \(l_2\) norm. Also, we define \(
\mathbb{P}_h V_{h+1}^\pi(s, a) \triangleq \mathbb{E}_{s' \sim \mathbb{P}_h(\cdot \mid s, a)} V_{h+1}^\pi(s')
\). The ball \(\mathbb{B}_\epsilon(v)\) represents the set of all points within distance \(\epsilon\) from \(v\).
\section{Non-Convex Feature Spaces}
\label{Sec:Non_ConvexFeratureSpace_IMCL_1}
Non-convexity often occurs in real-world problems due to non-convex constraints such as traffic rules, collision avoidance, and kinematic restrictions in autonomous vehicles, as well as in feature selection and function approximation in modern RL methods.  Here, we define two key assumptions  in the feature space \(\mathcal{F}_s\)—\emph{star-convexity} and the \emph{Local Point Assumption}-commonly found in these applications and will later provide near-optimal solutions for them. To start, we define the notion of star-convexity, introduced in \citet{amani2021safe}:
\begin{figure}[ht]
    \centering
\includegraphics[width=0.92\columnwidth]{LocalPointStarConvex.png} % Replace with your PDF filename
    \caption{An illustrative example of Assumptions   \ref{assumption:epsilon_origin_1} and \ref{assumption:Star_ConvexAssumption_1}. The left figure demonstrates the Local Point Assumption, where a sphere exists around the initial safe point. The right figure depicts a Star-Convex Set, where all points are connected to the initial safe point by a line segment.}
    \label{fig:LocalStar}
\end{figure}
\begin{assumption}
\label{assumption:Star_ConvexAssumption_1}
\textbf{(Star-Convex Sets)} For each \(s \in \mathcal{S}\), the feature space \(\mathcal{F}_s\) is star-convex around \(\phi(s, a_s^0)\). That is, for all \(\mathbf{x} \in \mathcal{F}_s\) and \(\alpha \in [0, 1]\):
\( 
  \alpha\,\mathbf{x} + (1 - \alpha)\,\phi(s,a^0_s) \in \mathcal{F}_s.
\)
\end{assumption}

Although star-convexity simplifies the theoretical analysis, many real-world applications—including autonomous driving—cannot satisfy this assumption as we explain the following example: 
% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.2\textwidth]{First_TikZ_example-8.pdf} % Replace with your PDF filename
%     \caption{Green car (G) wants to turn right at the intersection, however, the orange car (O) is approaching. The green car must decide whether stop at the intersection to let the orange car pass, or increase the speed to pass before the orange car arrives.}
%     \label{fig:AutonomousVehcleMerging_ICML_Jan_1}
% \end{figure}



% \begin{figure}[t]
%     \centering
%     \begin{minipage}{0.45\columnwidth}
%         \centering
%         \includegraphics[width=\textwidth]{DecisionSpace.png}
%         \caption{(a): The decision space consists of Autonomous Vehicle without considering collision avoidance.}
%         \label{fig:first_image}
%     \end{minipage}%
%     \hfill
%     \begin{minipage}{0.45\columnwidth}
%         \centering
%         \includegraphics[width=\textwidth]{DecisionSpaceCollav.png}
%         \caption{(b): The red region becomes inaccessible due to the collision avoidance module.}
%         \label{fig:second_image}
%     \end{minipage}
%     \vspace{-0.5em} % Optional: Adjust spacing
%     %\caption{Illustration of decision spaces.}
%     %\label{fig:DecisionSpaceCollav_ICML_Jan_1}
% \end{figure}








\textbf{Example (Autonomous Driving):}
Consider an autonomous vehicle approaching an intersection and facing a merging decision (Figure~\ref{fig:AutonomousVehcleMerging_ICML_Jan_1}). The car can either (i) drive slowly to let oncoming traffic pass or (ii) accelerate rapidly to merge before other vehicles arrive. These two action modes induce disjoint feasible regions, violating Assumption~\ref{assumption:Star_ConvexAssumption_1} because no straight line connecting the points in the slow mode to the points in high acceleration mode resides entirely in the decision space. Note that these distinct action subsets naturally emerge from collision avoidance constraints and results in a non-convex decision set.


To address the limitations of star-convex spaces, we introduce a new class of non-convex sets, termed the \emph{Local Point Assumption}, which satisfies conditions relevant to autonomous vehicles and robotics. These sets feature localized properties around \( \phi(s,a^0_s) \) and near constraint boundaries within the feature space, while allowing arbitrary structures outside these regions.

\begin{assumption}
\label{assumption:epsilon_origin_1}
\textbf{(Local Point Assumption)} Let \(\mathcal{H}\) be the \((d-1)\)-dimensional hyperplane containing \(\mathcal{F}\). There exists \(\epsilon \in (0,\frac{\tau}{\sqrt{d}})\) such that \(\mathbb{B}_\epsilon(\phi(s,a_s^0)) \cap \mathcal{H} \subset \mathcal{F}_s\) for all \(s \in \mathcal{S}\). Moreover, for any \((s,a,h)\), if \(\tau-\iota \le \langle \phi(s,a),\gamma^*_h\rangle \le \tau\) for some \(\iota<\tau\), then
\( 
\{\nu\,\phi(s,a) + (1-\nu)\,\phi(s,a^0_s) \mid \nu \in [\tfrac{\tau-\iota}{\langle \phi(s,a), \gamma^*_h \rangle},1]\}\;\subset\;\mathcal{F}_s.
\)
\end{assumption}

\textbf{Comparison.}
The key difference between Assumption~\ref{assumption:Star_ConvexAssumption_1} and Assumption~\ref{assumption:epsilon_origin_1} is that star-convexity imposes global requirements on all points in \(\mathcal{F}_s\), whereas the Local Point Assumption focuses solely on local properties. However, the Local Point Assumption is not always less restrictive, as it requires the existence of a hypersphere on the plane \(\mathcal{H}\), a condition not mandated by star-convexity. In practice, though, it is an effective assumption for handling complex decision spaces, particularly in applications such as autonomous vehicles and robotics. For an illustrative example of star-convex sets, see Figure \ref{fig:LocalStar}. Consequently, these structural differences lead to distinct regret bounds under the two assumptions (see Section \ref{Sec:SAFERL_ICML_Jan_Analysis_1}).
\begin{figure}[ht]
    \vskip 0.2in
\begin{center}
    % First subfigure
    \centerline{
    \begin{subfigure}
        \centering
\includegraphics[width=0.45\columnwidth]{First_TikZ_example-8.pdf}
    \end{subfigure}%
    \hfill
    % Second subfigure
    % \begin{subfigure}
    %     \centering
    % \includegraphics[width=0.33\columnwidth]{DecisionSpace.png}
    %     %\caption{}
    %    % \label{fig:first_image}
    % \end{subfigure}%
    % \hfill
    % Third subfigure
    \begin{subfigure}
        \centering
    \includegraphics[width=0.47\columnwidth]{DecisionSpaceCollav.png}
        %\caption{}
        % \label{fig:second_image}
    \end{subfigure}}
    \caption{\textbf{Left figure:} The green car (G) must decide whether to stop at the intersection for the approaching orange car (O) or accelerate to pass before O arrives. \textbf{Right figure:} The green car's decision space, where the red region is inaccessible due to the collision avoidance module.}
     \label{fig:AutonomousVehcleMerging_ICML_Jan_1}
   \end{center}
\vskip -0.2in
\end{figure}






\section{Our Approach}
\label{sec:OurAPproach_SafeRL_ICML_1}

We now describe our proposed algorithm, Non-Convex Safe Least Square Value Iteration (NCS-LSVI), detailed in Algorithm \ref{alg:SafeNonConvex}. This algorithm extends the standard SLUCB-QVI from \cite{amani2021safe} to address safe RL problems in non-star-convex environments. A key feature of our approach is the ability to handle large covering numbers in non-star-convex environments using the pure exploration phase. The algorithm consists of two main phases: \textbf{pure safe exploration} and \textbf{safe exploitation-exploration}, implemented over \(K\) episodes. At a high level, NCS-LSVI ensures safe learning by leveraging a Recursive Least Squares (RLS) framework to construct an estimated safe set \(\mathcal{A}^k_h(s)\). Subsequently, it employs an optimistic \(Q\)-function estimation to guide policy updates.  Detailed explanations of the algorithm's components are provided below.
% \begin{algorithm}[tb]
%    \caption{Bubble Sort}
%    \label{alg:example}
% \begin{algorithmic}
%    \STATE {\bfseries Input:} data $x_i$, size $m$
%    \REPEAT
%    \STATE Initialize $noChange = true$.
%    \FOR{$i=1$ {\bfseries to} $m-1$}
%    \IF{$x_i > x_{i+1}$}
%    \STATE Swap $x_i$ and $x_{i+1}$
%    \STATE $noChange = false$
%    \ENDIF
%    \ENDFOR
%    \UNTIL{$noChange$ is $true$}
% \end{algorithmic}
% \end{algorithm}

\begin{algorithm}[tb]
\caption{Non-Convex Safe Least Square Value Iteration (NCS-LSVI)}
\label{alg:SafeNonConvex}
\begin{algorithmic}[1]
    \REQUIRE \(\epsilon, \,\, K', \,\, K, \,\, \,\, \nu, \,\, s_1 \)
    \STATE \textbf{Pure safe exploration}
     \FOR{\(k = 1, \dots , K'\)}
        \FOR{\(h = 1, \dots, H \)}
            \STATE \(\text{At state } s \text{ take action } a^k_h \text{randomly 
            from  } \mathcal{D}^{\epsilon}(s)\)\\
            \( \text{according to Eq.~(\ref{Eq:Intitial_Safe_RestrcitedHyperSphere}).}\)
        \ENDFOR
     \ENDFOR
    \STATE \textbf{Safe exploitation-exploration}
    \FOR {episode \(k = K'+1, \dots ,K\)}
        \FOR{ step \(h = H, \dots ,1\)}
    \STATE \(\text{Compute } \Lambda^{k,Q}_h, \Lambda^{k, \gamma}_h, \gamma^k_h, w^k_h \) according to \\Eqs.~(\ref{Eq:Alg_Est_W_1_gamma}-\ref{Eq:Alg_Est_Lambda_1})
              \STATE \(\text{Compute estimated safe set,} \forall s\in \mathcal{S}:\) \[\mathcal{A}^k_h(s)\triangleq \{a\in \mathcal{A}: \langle \phi(s,a) - \phi(s,a^0_s), \gamma^k_h \rangle\] \[  + \beta_2 \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{(\Lambda_h^{k, \gamma})^{-1}} \leq \tau \}\]
            \STATE \(\text{Compute } Q^k_h(s,a) : = \langle \phi(s,a), w_h^k \rangle + b^k_h (s,a)\).
             \STATE \(\text{Take action }  a_h^k = argmax_{a \in \mathcal{A}_h^k(s)}  Q^k_h(s,a)  \).
        \ENDFOR
        \FOR{ step \(h = 1\) to \(H\)}
            \STATE \(\text{Play \(a^{k}_h\) and observe its reward \(r_h^k\) and cost \(c_h^k\)}.\)
        \ENDFOR
    \ENDFOR
\end{algorithmic}
\end{algorithm}


\textbf{Lines \(1-6\) (Pure safe exploration).}
In this phase the agent samples uniformly from a set \(\mathcal{D}^{\epsilon}(s)\) defined as follows:
\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere}
         \mathcal{D}^{\epsilon}(s) \triangleq \{a \in \mathcal{A}\mid \lVert \phi(s,a) - \phi(s,a_s^0) \rVert = \epsilon \}.
\end{equation} According to Assumption \ref{assumption:epsilon_origin_1}, \(\mathcal{D}^{\epsilon}(s)\) represents the boundary of \(\mathbb{B}_{\epsilon'}(\phi(s, a_s^0)) \cap \mathcal{H}\). Note that given Assumption \ref{assumption:startingPoint_1} and the linearity of the problem (Assumption \ref{assumption:LinearMDP}), the Cauchy-Schwarz inequality can be applied to confirm that all actions during the pure exploration phase are safe, i.e., \(\mathcal{D}^{\epsilon}(s) \subset \mathcal{A}^{\text{safe}}_h(s)\).

\textbf{Role of pure exploration.}
 In non-convex environments, small changes in constraint parameters can dramatically alter the estimated safe set, leading to large covering numbers (as shown by our toy example in Section \ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}). However, once the pure exploration phase is complete, under the Local Point Assumption (Assumption \ref{assumption:epsilon_origin_1}), the safe set near the constraint boundary becomes smooth and stable. Consequently, minor perturbations no longer cause drastic changes, allowing us to control the covering number effectively. Under Star-Convexity (Assumption \ref{assumption:Star_ConvexAssumption_1}), this global smoothness and stability is inherent,  we prove that the pure exploration phase is not  needed to achieve a bounded covering number (see Section \ref{sec:outlineOfProff_ICML_1}).



\textbf{ Lines 7-14 (Safe exploitation-exploration).} 
Once the pure exploration phase has been finished, we start the safe exploitation-exploration which contains two main stages: Safe set construction and \(Q\)- function estimation.

\textbf{Safe-set estimation.}
We  use Recursive Least Squares (RLS) for safe-set construction, with the modification that we consider the difference in features relative to the initial starting point. In fact, to satisfy the safety condition, it is crucial to determine how far we can deviate from the initial starting point. Therefore, we formulate the following RLS problem: 
\begin{equation}
\label{Eq:Alg_Est_W_1_gamma}
    \begin{aligned}
          & \Lambda^{k, \gamma}_h \triangleq \Sigma_{\tau=1}^{k-1} (x^\tau_h) (x^\tau_h)^\top 
           + \lambda I\\
            & \gamma^k_h = ( \Lambda^{k, \gamma}_h)^{-1} \Sigma_{\tau=1}^{k-1} (x^\tau_h) c_h^{\tau}(s_h^\tau, a_h^\tau)
    \end{aligned}
\end{equation}
where\( x^\tau_h \triangleq \phi(s_h^\tau, a_h^\tau) - \phi(s_h^\tau, a_{s_h}^0)\) Note that Considering Assumption \ref{assumption:startingPoint_1}, then Theorem~2 from \citet{abbasi2011improved} demonstrate that for any \(\delta \in (0,1)\), the choice of \(\beta_2 = \sigma \sqrt{d \log\left(\frac{2+ \frac{2 KH}{\lambda}}{\delta}\right)} + \sqrt{\lambda d}\) ensures that \(\mathcal{A}^k_h(s) \subset \mathcal{A}_h^{\text{safe}}(s) \) holds with probability of at least \(1-\delta\).



\textbf{Q-function estimation:} According to Proposition 2.3 in \citet{jin2020provably}, for a linear MDP, the \(Q\)-value of the optimal policy \(\pi^*\) can be expressed as \( Q^{\pi^*}_h(s,a) = \langle \phi(s,a), w^{\pi^*}_h \rangle\). Thus, in line 12 of Algorithm \ref{alg:SafeNonConvex}, we utilize Regularized Least Squares (RLS) to estimate  \(w^{\pi^*}_h\) as follows:
\begin{equation}
\label{Eq:Alg_Est_Lambda_1}
    \begin{aligned}
       &w^k_h = (\Lambda^{k,Q}_h)^{-1} \Sigma_{\tau=1}^{k-1} \phi(s_h^\tau, a_h^{\tau}) \big( y^{\tau, k}_h\big),
    \end{aligned}
\end{equation}
where \(y^{\tau, k}_h \triangleq r_h^{\tau}(s_h^\tau, a_h^\tau)+ V^{k}_{h+1}(s^\tau_{h+1})\), \( \Lambda^{k,Q}_h =  \Sigma_{\tau=1}^{k-1} \phi(s_h^\tau, a_h^\tau) \phi(s_h^\tau, a_h^\tau)^\top + \lambda I,\) and \(V^{k}_{h+1} \triangleq \min\{ \max_{a \in \mathcal{A}_h^k(s)}  Q^k_h(s,a), H \}\). 


\textbf{Bonus design and geometric assumptions.}  
Following \citet{amani2021safe}, we include a bonus term in Step~5 to encourage exploring unexplored safe actions:  
\( b^k_h(s,a) \triangleq \beta_1 \|\phi(s,a)\|_{(\Lambda^k_h)^{-1}} + g^k_{h,\nu}(s,a) \),  
where the first term is a standard exploration bonus from unconstrained RL \citep{jin2020provably}, and the second term is defined as follows:
\begin{equation}
\label{eq:bonus_term_non_Convex_2}
    g^k_{h,\nu}(s, a) \triangleq 
 \nu \times \left(\beta_2 \|\phi(s,a) - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}\right)  H.
\end{equation} 
\(g^k_{h,\nu}\) accounts for the distance between the optimal action \(\pi^*(s,h)\) and the estimated safe set \(\mathcal{A}^k_h(s)\). Under star-convex sets (Assumption~\ref{assumption:Star_ConvexAssumption_1}), \citet{amani2021safe} show that there exists a scaling factor \(\alpha \geq (1 - \frac{\tau}{\tau + 2 \beta_2 \|\phi(s,\pi^*(s,h)) - \phi(s,a^0_s)\|_{(\Lambda^{k,\gamma}_h)^{-1}}})\) such that \(\alpha \phi(s,\pi^*(s,h)) +  (1-\alpha) \phi(s,a^0_s) \in \phi(s,\mathcal{A}^k_h(s))\).  
In non-star-convex settings satisfying our Local Point Assumption~\ref{assumption:epsilon_origin_1}, we show that this property holds for \(k \geq K'\), i.e., after the pure exploration phase. This ensures that \(g^k_{h,\nu}\) compensates for the remaining distance between \(\alpha \phi(s,\pi^*(s,h)) +  (1-\alpha) \phi(s,a^0_s)\) and \(\phi(s,\pi^*(s,h))\), while encouraging the algorithm to expand the estimated safe set toward the optimal action.



% \textbf{Bonus design.}  
% At step \(5\), we implement an approach to encourage the agent to select unexplored safe actions. The bonus expression is given by 
% %\begin{equation}
%    \(  b^k_h(s, a) \triangleq \beta_1 \rVert \phi(s,a) \lVert_{(\Lambda^k_h)^{-1}} + g_{h,\nu}^k(s, a)\),
% %\end{equation}  
% where the first term is a common exploration term widely used in the unconstrained RL literature, as discussed in \cite{jin2020provably}. However, since the optimal policy \(\pi^*(s,h)\) may not lie within the estimated safe set \(\mathcal{A}^k_h(s)\), we introduce a new bonus term, \(g^k_{h,\nu}(s, a)\), to capture the distance between the optimal point and the estimated safe set. This bonus term is defined as:  
% % \begin{equation}
% % \label{eq:bonus_term_non_Convex_2}
% %     g^k_{h,\nu}(s, a) \triangleq 
% %  \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2 \|\phi(s,a)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) L H.
% % \end{equation}  
 

% \textbf{Star-convex and local point assumptions.}  
% In cases where the safe action sets are either star-convex around a given safe point (Assumption \ref{assumption:Star_ConvexAssumption_1}) or satisfy Local point assumption (Assumption \ref{assumption:epsilon_origin_1}), setting \(\nu = 1\) in \eqref{eq:bonus_term_non_Convex_2} ensures that \(g^k_{h,\nu}(s, a)\) effectively captures the distance between the optimal point \(\pi^*(s,h)\) and the estimated safe set \(\mathcal{A}^k_h(s)\). The reasoning differs slightly under these two assumptions:  


%  \textbf{Star-convex case:}  
%     For star-convex sets, there exists a scaling factor \(\alpha \geq \frac{\tau}{\tau + 2 \beta_2  \|\phi(s,\pi^*(s,h))\|_{(\Lambda^{k,\gamma}_h)^{-1}}}\) such that \(\alpha \phi(s,\pi^*(s,h))\) belongs to \(\phi(s,\mathcal{A}^k_h(s))\). In other words, the distance from \(\phi(s,\pi^*(s,h))\) to \(\phi(s,\mathcal{A}^k_h(s))\) can be upper-bounded by:  
%     \(
%     \big(1 - \frac{\tau}{\tau + 2 \beta_2  \|\phi(s,\pi^*(s,h))\|_{(\Lambda^{k,\gamma}_h)^{-1}}}\big) L.
%     \) 

%     \textbf{Local point assumption:}  
%     Under the local point assumption, this property holds after \(k \geq K'\), i.e., after the end of the pure exploration phase. For \(k \geq K'\), there exists a scaling factor \(\alpha \geq \frac{\tau}{\tau + 2 \beta_2  \|\phi(s,\pi^*(s,h))\|_{(\Lambda^{k,\gamma}_h)^{-1}}}\) such that \(\alpha \phi(s,\pi^*(s,h))\) is within \(\phi(s,\mathcal{A}^k_h(s))\). This ensures that the bonus term \(g^k_{h,\nu}(s, a)\) appropriately reflects the remaining distance to the safe set while satisfying the local point assumption.


\textbf{Lines 15-17 (Environment interaction).} 
Finally, in steps 15-17, the algorithm plays the selected actions and observes their corresponding rewards and costs, which are stored for use in the next round. The steps 8-17 is repeated for \(K-K'\) iterations.


\section{Analysis}
\label{Sec:SAFERL_ICML_Jan_Analysis_1}
In this section, we first present our main theoretical results for star-convex cases. Then, we explain that ( quite interestingly), in contrast to the unconstraned RL, the geometry of the decision set, i.e. \(\mathcal{F}_s\), can affect the covering number of the class of value functions in constrained RL.
\subsection{Star-Convex Results}
\label{Section:StarConvexResults_Problem_ICML_SAFERL_1}
\begin{theorem}
    \label{Theorem: upperbound_StarConvex_1}
    \textbf{Regret in Star-Convex Spaces (Refined version of Theorem~1 in \citet{amani2021safe})}
 Under assumptions \ref{assumption:LinearMDP}, \ref{assumption:startingPoint_1}, and \ref{assumption:Star_ConvexAssumption_1}, let \(K' = 0\) in \ref{alg:SafeNonConvex}. Then, there exists a constant \(c_\beta >0\) such that for any \(\delta \in (0,\frac{1}{3})\), by setting \(\beta_1 = c_{\beta} d H \sqrt{log(\frac{dK}{\tau \delta})}\), \(\nu = \frac{2}{\tau}\) and \(\lambda = 1\), with the probability of at least \(1-3\delta\) Algortihm \ref{alg:SafeNonConvex} remains safe, \(\mathcal{A}^k_h(s) \subset \mathcal{A}^{\text{safe}}_h(s), \quad \forall (h,k) \in [H]\times [K]\). Further, the regret of Algorithm \ref{alg:SafeNonConvex} with a probability of at least \(1- 3 \delta\) satisfies the the following upper bound: \(\text{Regret}(K) \leq  2 H \sqrt{K H \,\, log(\frac{d (K) H}{\delta})} +  2  ( \beta_1 H + \frac{ 3 \beta_2 H^2}{ \, \tau \, L}  )\sqrt{ 2 d (K) \,\, log(1+\frac{K}{d \lambda})}.\)
%  \begin{equation}
%  \label{eq: Regret_upperbound_StarConvex_1}
%     \begin{aligned}
%          &\text{Regret}(K) \leq  2 H \sqrt{K H \,\, log(\frac{d (K) H}{\delta})}\\
%          & \qquad+  2  ( \beta_1 H + \frac{ 3 \beta_2 H^2}{ \, \tau \, L}  )\sqrt{ 2 d (K) \,\, log(1+\frac{K}{d \lambda})}.
%     \end{aligned}
% \end{equation}
\end{theorem}

\textbf{Comparison with Theorem 1 in \citet{amani2021safe}.}
 
Compared to our Theorem~\ref{Theorem: upperbound_StarConvex_1}, the regret bound in Theorem~1 of \citet{amani2021safe} lacks the \(\sqrt{\log\bigl(\tfrac{1}{\tau}\bigr)}\) factor. This omission arises due to a mistake in their Theorem~2, which relies on a covering-number argument designed for unconstrained RL (Lemma D.6 in \citet{jin2020provably}), an approach that is not valid in our setting under instantaneous hard constraints.   To clarify, note that a \(\kappa\)-covering of the value functions ensures that every possible \(V^k_h\) can be approximated to within \(\kappa\). For the unconstrained setting, \citet{jin2020provably} demonstrated that a \(\kappa\)-covering of the \(Q^k_h\)-functions directly induces a \(\kappa\)-covering of the \(V^k_h\)-functions. This is because \(V^k_h\) is obtained by maximizing \(Q^k_h\) over a fixed action set \(\mathcal{A}\), and the contraction property of the \(\max\) operator ensures that small changes in \(Q^k_h\) lead to small changes in \(V^k_h\) \cite{ghosh2022provably}.  In our setting, however, \(V^k_h\) is defined by maximizing \(Q^k_h\) over a \emph{data-dependent} safe set \(\mathcal{A}^k_h\). Consequently, a covering of the \(Q^k_h\)-functions does not directly imply a covering of the \(V^k_h\)-functions, as changes in \(\mathcal{A}^k_h\) can cause significant differences in \(V^k_h\). To resolve this issue, we develop a novel technique called OCD for bounding the covering number in the star-convex setting (see Section~\ref{sec:outlineOfProff_ICML_1}). Specifically, we show that when \(\mathcal{F}_s\) is star-convex, the changes in \(\mathcal{A}^k_h\) can be controlled by variations in the safety parameters \(\gamma^k_h\) and \(\Lambda^{k, \gamma}_h\), enabling an effective bound on the covering number.  Once this bound is established, we provide a corrected version of Theorem~2 in \citet{amani2021safe} for the event \(\mathcal{E}_2\), which now includes the missing \(\sqrt{\log\bigl(\tfrac{1}{\tau}\bigr)}\) term, as detailed below:

% Compared to our Theorem~\ref{Theorem: upperbound_StarConvex_1}, the regret bound in Theorem~1 of \citet{amani2021safe} lacks the \(\log\bigl(\tfrac{1}{\tau}\bigr)\) factor. This omission stems from their Theorem~2, which relies on a covering-number result from  \emph{unconstrained} RL where action space is fixed (See Lemma D.6. from \citet{jin2020provably}). In contrast, constrained RL features an \emph{evolving} feasible set under instantaneous hard constraints, making the unconstrained bounding technique inapplicable. To address this gap, we provide the following theorem, which properly accounts for the dynamically changing action sets in star-convex problems:


\begin{theorem}[Corrected covering-number result]
\label{Theorem: CoveringNumber_Fluctuation_ICML_SAFERL_1}
Under the setting of Theorem~\ref{Theorem: upperbound_StarConvex_1}, for any fixed policy \(\pi\), let the event \(\mathcal{E}_2\) be defined as follows: \( \mathcal{E}_2 \triangleq \{
    \left|
        \langle \mathbf{w}_h^k, \phi(s, a) \rangle - Q_h^\pi(s, a) + \mathbb{P}_h \big(V_{h+1}^\pi - V_{h+1}^k\big)(s, a) \right| \\
    \leq \beta \|\phi(s, a)\|_{(\mathcal{A}_h^{k,Q})^{-1}}, \, \forall (a, s, h, k) \in \mathcal{A} \times \mathcal{S} \times [H] \times [K]\},\)
% \begin{equation*}
%     \begin{aligned}
%         & \mathcal{E}_2 \triangleq \{
%     \left|
%         \langle \mathbf{w}_h^k, \phi(s, a) \rangle - Q_h^\pi(s, a) + \mathbb{P}_h \big(V_{h+1}^\pi - V_{h+1}^k\big)(s, a) \right| \\
%     &\leq \beta \|\phi(s, a)\|_{(\mathcal{A}_h^{k,Q})^{-1}}, \, \forall (a, s, h, k) \in \mathcal{A} \times \mathcal{S} \times [H] \times [K]\},
%     \end{aligned}
% \end{equation*}
where \(\beta_1 = c_{\beta} d H \sqrt{log(\frac{dK}{\tau \delta})}\) for some constant \(c_\beta\). Then, the event \(\mathcal{E}_2\) holds with the probability of at least \(1-\delta\). 
\end{theorem}

\subsection{ The Challenge of Covering Numbers in Non-star-Convex Safe RL}
\label{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}
Now, we can illustrate why a dedicated pure exploration phase is critical for controlling the covering number when \(\mathcal{F}_s\) is not star-convex. Suppose we remove the pure-exploration component from Algorithm~\ref{alg:SafeNonConvex} and start the second phase of the algorithm, \textit{safe-exploration-exploitation}. The immediate issue, in contrast star-convex  settings, is that we would require a large \(\kappa\)-covering of the value functions. The key distinction between these two settings lies in the inability to control changes in \(\mathcal{A}^k_h\) through variations in the safety parameters \(\gamma^k_h\) and \(\Lambda^{k, \gamma}_h\). In non-star-convex settings, even small variations in these safety parameters can drastically alter \(\mathcal{A}^k_h\), leading to substantial shifts in \(V^k_h\). Thus, we cannot bound the covering number in the same way as in star-convex settings. In fact, the following formalizes this phenomenon in a simple one-dimensional example, showing that the covering number can grow at least as large as the number of states, which can be prohibitively large in environments with very large or continuous state spaces. 
\begin{lemma}
\label{Lemma:CoveringNumberLowerBound}
(Covering number in non-star-convex settings) Consider a one-dimensional setting where \(Q(s, a) = a\) for \(a \in \mathbb{R}\), with a finite state space \(\mathbb{S} = \bigcup_{i=1}^{|\mathcal{S}|} \{i\} \subset \mathbb{N}\). Define the class of parameterized functions \( \mathcal{V} \triangleq \{V_{\gamma} \mid \|\gamma\| \leq 1\} \), where \(V_{\gamma}(s) \triangleq \max_{a \in \mathcal{A}_\gamma(s)} Q(s, a)\), and \(\mathcal{A}_\gamma(s) \triangleq \{a \mid a \in [0, \frac{1}{3}] \cup [\frac{2}{3}, 1], \; \gamma \cdot s \cdot a \leq \tau\}\). Now, for an arbitrary positive real number \(\kappa < \frac{1}{6}\), let the set \(\mathcal{V}_\kappa \subset \mathcal{V}\) be a \(\kappa\)-covering for the function class \(\mathcal{V}\). Then, the following inequality holds: \( 
|\mathcal{S}| \leq |\mathcal{V}_\kappa|.
\)
\end{lemma}
Despite the fundamental challenge highlighted in Lemma~\ref{Lemma:CoveringNumberLowerBound}, we show that under the Local Point Assumption~\ref{assumption:epsilon_origin_1}, the pure exploration phase in Algorithm~\ref{alg:SafeNonConvex} enables us to control the covering number during the second phase of Algorithm~\ref{alg:SafeNonConvex}. This is because, by the end of the pure exploration phase, the agent’s estimated safe set remains stable under small variations in the safety parameter with high probability. Below, we present our main result:

\begin{theorem}
    \label{Theorem: upperbound_1}
    \textbf{(Regret under Local Point Assumption)}
 Under assumptions \ref{assumption:LinearMDP}, \ref{assumption:startingPoint_1}, and \ref{assumption:epsilon_origin_1}, there exists a constant \(c_\beta >0\) such that for any \(\delta \in (0,\frac{1}{3})\), by setting \(\beta_1 = c_{\beta} d H \sqrt{log(\frac{dK}{\tau \delta})}\) and \( \nu =\frac{2}{\tau}\) and \(\lambda = 1\), with the probability of at least \(1-3\delta\) Algortihm \ref{alg:SafeNonConvex} remains safe, \(\mathcal{A}^k_h(s) \subset \mathcal{A}^{\text{safe}}_h(s), \quad \forall (h,k) \in [H]\times [K]\). Further, the regret of Algorithm \ref{alg:SafeNonConvex} with a probability of at least \(1- 3 \delta\) satisfies the the following upper bound: \(\text{Regret}(K) \leq K' H +  2 H \sqrt{(K-K') H \,\, log(\frac{d (K-K') H}{\delta})}  +  2 (\beta_1 H + \frac{\beta_2 H^2}{\tau})  H \sqrt{2 (K-K')  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))},\)for all \(K' \geq \max\{\frac{8 d}{\epsilon^2} \log(\frac{d H}{\delta}), \frac{2 d}{\epsilon^2} (\frac{16 \beta_2^2}{\iota^2} - \lambda)\} \), where \(\epsilon\) and \(\iota\) are defined in Assumption~\ref{assumption:epsilon_origin_1}.
\end{theorem}


\section{Outline of the Proof}
\label{sec:outlineOfProff_ICML_1}

The proof steps presented here hold for both Theorem \ref{Theorem: upperbound_1} and Theorem \ref{Theorem: upperbound_StarConvex_1}, albeit with different choices of \(K'\). For Theorem \ref{Theorem: upperbound_1}, \(K'\) corresponds to the termination of the pure exploration phase, while for Theorem \ref{Theorem: upperbound_StarConvex_1}, \(K'\) can be set to \(0\) as no pure exploration phase is needed in the star-convex case. Our proof involves three main steps: (1) decomposing the sum of regret and ensuring the constraint satisfaction, (2) bounding the covering number of the value function class, and (3) applying uniform concentration tools to achieve sublinear regret. The key challenge lies in controlling the covering number of the value function class, which critically depends on how the geometry of the decision space.

\textbf{Step 1: Decomposition.}
Following a similar approach as in \citet{ghosh2022provably}, we first establish a decomposition that upper bounds the sum of regret: \(\text{Regret}(K) \leq K' H + \underbrace{\sum_{k=K'}^K \bigl(V_0^{\pi^*}(s_0) - V_{0}^{k}(s_0)\bigr)}_{\mathcal{T}_1} 
        + \underbrace{\sum_{k=K'}^K \bigl(V_0^{k}(s_0) - V_{0}^{\pi^k}(s_0)\bigr)}_{\mathcal{T}_2}.\) To control \(\mathcal{T}_1\) and \(\mathcal{T}_2\), we need to carefully compare the estimated value functions \(V_h^k\) produced by our algorithm at each episode \(k\) with the corresponding value functions \(V_h^\pi\) induced by a given policy \(\pi\). A critical challenge is dealing with the adaptive nature of the learning process, where the chosen actions depend on previously observed transitions and rewards. This adaptivity can make standard self-normalized concentration inequalities inapplicable, as the future sample distribution depends on the current value estimates. To address this, we rely on value-aware uniform concentration arguments. By fixing a suitable function class \(\mathcal{V}\) of candidate value functions in advance and ensuring that each \(V_h^k\) belongs to \(\mathcal{V}\), we leverage the polynomial log-covering number of \(\mathcal{V}\) to obtain high-probability bounds uniformly over all functions in the class. Concretely, for each \((k,h) \in [K]\times[H]\), we aim to show that, with high probability: 
\begin{equation}
    \begin{aligned}
        &\left\|\sum_{\tau=1}^{k-1}\phi(s_h^\tau,a_h^\tau)\bigl[V_{h+1}^k(s_{h+1}^\tau)-\mathbb{P}_hV_{h+1}^k(s_h^\tau,a_h^\tau)\bigr]\right\|_{(\Lambda_h^k)^{-1}}\\
        & \qquad \leq O(d\sqrt{\log K}),
    \end{aligned}
\end{equation} where \(\mathbb{P}_h\) is the transition operator at stage \(h\). Achieving such a bound ensures that our estimated value functions are stable and close to the true policy-based value functions, facilitating the desired sublinear regret guarantees.

\paragraph{Step 2: Controlling the Covering Number.} We begin by defining our class of value functions \(\mathcal{V}\). Consider parameters \(\theta,\gamma \in \mathbb{R}^d\) and positive semi-definite matrices \(A,A'\), with bounded norms (e.g., \(\|\theta\| \leq \sqrt{d}\), \(\|\gamma\| \leq \sqrt{d}\), \(\|A\|_F \leq \frac{\sqrt{d} B^2}{\lambda}\), and \(\|A'\|_F \leq \frac{\sqrt{d} (B')^2}{\lambda}\)). Given these parameters, the value function can be written as \(V(s) = \min\{V'(s), H\}\), where:
\begin{equation*}
\label{eq:CLassValueFunctDefinition_SAFERLICML_Main_1}
    \begin{aligned}
&V'(s)  = \max_{a \in \mathcal{A}} \langle \phi(s,a), w \rangle + \|\phi(s,a)\|_{A} + g_{A',1}(s,a),\\
&\text{s.t. }  \langle \phi(s,a) - \phi(s,a^0_s), \gamma \rangle + \|\phi(s,a) - \phi(s,a^0_s)\|_{A'} \leq \tau,
  \end{aligned}
\end{equation*}
%The complexity of \(\mathcal{V}\) arises from how variations in the parameters \((\theta, \gamma, A, A')\) influence the value of the function.
 where \( g_{A', 1}(s, a) \triangleq \frac{2}{\tau}   \|\phi(s,a) - \phi(s,a^0_s)\|_{A'}\). We collect all such value functions into the following class: \( \mathcal{V} \triangleq \{ V_{w,\gamma,A,A'} \mid \|w\| \leq L_w, \|\gamma\| \leq \sqrt{d}, \|A\|_F \leq \tfrac{\sqrt{d} B^2}{\lambda}, \|A'\|_F \leq \tfrac{\sqrt{d}(B')^2}{\lambda} \}\).  In contrast to unconstrained RL, where the value function \(V(.)\) is determined  by maximizing the objective over the entire action space \(\mathcal{A}\), our setup in Eq.~(\ref{eq:CLassValueFunctDefinition_SAFERLICML_Main_1}) introduces constraints through the parameters \((\gamma, A')\), which directly affect the feasible decision set. This distinction highlights the need to consider both the objective and the constraints when constructing a log-polynomial-sized covering for \(\mathcal{V}\), as we discuss next.  
%If small changes in \((\gamma, A')\) cause large, discontinuous shifts in these sets, it changes the optimization solution drastically as well. Thus, constructing a log-polynomial-sized covering requires an approach that accounts for both the objective and the constraints, as detailed in the following discussion.


\textbf{OCD: Objective–Constraint Decomposition.} Here we introduce our novel idea for bounding the covering number. Consider two arbitrary value functions \(V_1 = \min\{V'_1(s), H\}\) and \(V_2 = \{V'_2(s), H\}\) from our class \(\mathcal{V}\), where:
\begin{equation}
\begin{aligned}
&  V'_i(s) = \max_{a \in \mathcal{A}} \langle \phi(s,a), w_i \rangle + \|\phi(s,a)\|_{A_i} + g_{A'_i, 1}(s,a) \\
&\text{s.t. } \langle \phi(s,a) - \phi(s,a^0_s), \gamma_i \rangle + \|\phi(s,a) - \phi(s,a^0_s)\|_{A'_i} \leq \tau,
\end{aligned}
\end{equation}
% \begin{equation}
% \begin{aligned}
% &V'_1(s) = \max_{a \in \mathcal{A}} \langle \phi(s,a), w_1 \rangle + \|\phi(s,a)\|_{A_1} + g_{A'_1,1}(s,a) \\
% & \,\text{s.t. } \langle \phi(s,a) - \phi(s,a^0_s), \gamma_1 \rangle + \|\phi(s,a) - \phi(s,a^0_s)\|_{A'_1} \leq \tau,\\\\
% & V_2(s) = \max_{a \in \mathcal{A}} \langle \phi(s,a) , w_2 \rangle + \|\phi(s,a) \|_{A_2} + g_{A'_2,1}(s,a) \\
% & \, \text{s.t. } \langle \phi(s,a) - \phi(s,a^0_s), \gamma_2 \rangle + \|\phi(s,a) - \phi(s,a^0_s)\|_{A'_2} \leq \tau.
% \end{aligned}
% \end{equation}


for all \(i\in \{1,2\}\). To relate \(V_1\) and \(V_2\), we introduce an intermediate value function \(V_3\) with objective parameters from \(V_1\) and constraint parameters from \(V_2\). Specifically, \(V_3(s) = \min\{V'_3(s), H\}\), where:
\begin{equation}
\begin{aligned}
&V'_3(s) = \max_{a \in \mathcal{A}} \langle \phi(s,a), w_1 \rangle + \|\phi(s,a)\|_{A_1} + g_{A'_1,1}(s,a)\\ 
&\text{s.t. }\langle \phi(s,a) - \phi(s,a^0_s), \gamma_2 \rangle + \|\phi(s,a) - \phi(s, a^0_s)\|_{A'_2} \leq \tau.
\end{aligned}
\end{equation}

Now, we have:  \( 
|V_1(s) - V_2(s)| \leq |V_1(s) - V_3(s)| + |V_2(s) - V_3(s)|
\). This inequality represents a \textit{decomposition of the distance between \(V_1\) and \(V_2\) into contributions from differences in objectives and constraints.} Specifically, \(V_1\) and \(V_3\) differ only in their objective parameters, while \(V_2\) and \(V_3\) differ in their constraints. Now, since \(V_2\) and \(V_3\) share the same constraint parameters \((\gamma_2, A'_2)\), they are maximizing over the same feasible action set. Thus, bounding \(|V_2 - V_3|\) reduces to a scenario akin to the unconstrained case, where comparing two linear–quadratic forms over the same domain is straightforward. On the other hand, bounding \(|V_1 - V_3|\) is \textit{more challenging} because \(V_1\) and \(V_3\) have \textit{different feasible decision sets}.
%Small changes in \(\gamma\) or \(A'\) could significantly alter the feasible action set, making \(|V_1 - V_3|\) potentially large.

\textbf{Bounding \(|V_1 - V_3|\) in Star-Convex Setting.} When \(\mathcal{F}_s\) is star-convex, we prove that small perturbations in \(\gamma\) or \(A'\) do not cause large, discontinuous changes in the feasible action set (see Lemma~\ref{Lemma:epsilon_Cover_utils_1StarConvex_1} in the Appendix).  Specifically, we show that if \(a_1\) is feasible for \(V_1\), then there exists a scaler \(\alpha_3 \in \bigl[\tfrac{\tau}{\tau + \Delta}, 1\bigr]\) and an action \(a_3\) feasible for \(V_3\) such that \(  \phi(s,a_3) \;=\; \alpha_3 \,\phi(s,a_1) \;+\; \bigl(1-\alpha_3\bigr)\,\phi(s,a^0_s),
\) where \(\Delta = \|\gamma_2 - \gamma_1\| + \sqrt{\|A'_1 - A'_2\|_F}\). As \(\Delta\) approaches zero, \(\phi(s,a_3)\) converges to \(\phi(s,a_1)\), implying that every feasible feature of \(V_1\) has a close counterpart in \(V_3\), and vice versa, with the difference controlled by \(\Delta\). Consequently, \(\lvert V_1 - V_3 \rvert\) can also be controlled by \(\Delta\).  Hence, constructing a polynomial-size cover of the parameter space induces a corresponding cover for the value function class \(\mathcal{V}\).
\begin{remark}
\label{Remark:InsightSafetyCovering}When \(\tau\) is small, a smaller \(\Delta\) is required to ensure that \( \alpha_3 \in[\tfrac{\tau}{\tau + \Delta}, 1]\) remains close to 1, which in turn ensures that \(\phi(s,a_3)\) stays sufficiently close to \(\phi(s,a_1)\). As a result, a larger covering net is needed to account for smaller variations in the parameter space. This additional complexity is reflected in the \(\sqrt{\log(\frac{1}{\tau})}\) term in Theorem~\ref{Theorem: CoveringNumber_Fluctuation_ICML_SAFERL_1}.
\end{remark}
% Therefore, if \(\gamma_1\) is close to \(\gamma_2\) and \(A'_1\) is close to \(A'_2\), then the feasible sets defined by these parameters are also close. Consequently, \(|V_1 - V_3|\) remains controlled and does not blow up due to small parameter changes. This stability ensures that \(|V_1 - V_2|\) is bounded by distances in their parameters \(\|w_1 - w_2\|\), \(\|\gamma_1 - \gamma_2\|\), \(\|A_1 - A_2\|\), \(\|A'_1 - A'_2\|\). Hence, constructing a polynomial-size cover of the parameter space induces a corresponding cover for the value function class \(\mathcal{V}\).

% \textbf{Non-Star-Convex Setting.} Without star-convexity, the above argument no longer holds, as demonstrated by our toy example in Section \ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}. Small changes in \(\gamma\) or \(A'\) can result in large, erratic shifts in the feasible action sets, causing \(|V_1 - V_3|\) to become large and uncontrollable. Consequently, constructing a log-polynomial-sized covering for \(\mathcal{V}\) becomes infeasible.  However, in the Local point Assumption case, this complexity can be handled by a pure exploration. In fact, after the pure exploration phase in Algorithm \ref{alg:SafeNonConvex}, the safe points outside of the estimated safe set would connect to the estimated safe set through a line. Therefore, the small changes in the constraint's parameter does not significantly change the estimated safe set same as star-convex cases (see Lemma~\ref{Lemma:epsilon_Cover_utils_1} in the Appendix). Consequently, the log-covering number remains polynomial once the pure exploration phase is completed.

\textbf{Non-Star-Convex Setting.} 
In non-star-convex settings, our OCD technique cannot be directly applied without a pure exploration phase, as small changes in the safety parameters \(\gamma\) or \(A'\) can cause drastic shifts in the feasible action sets, leading to significant differences in \(V_1\) and \(V_3\) (see Lemma~\ref{Sect:ToyExampleCoveringNumberNonconvex_ICML_1}). To understand why this occurs in non-star-convex settings, note that when \(\mathcal{F}_s\) is not star-convex, we cannot guarantee that \(\alpha\,\phi(s,a^*_1) + (1-\alpha)\,\phi(s,a^0_s) \in \mathcal{F}_s\) for \(\alpha \in [\frac{\tau}{\tau+\Delta},1]\). This is the main reason why our approach for the star-convex case does not extend directly to the non-star-convex setting. However, once \(V_1 = V^k_h\), where \(V^k_h\) is the value function generated by Algorithm~\ref{alg:SafeNonConvex} after the pure exploration phase, we show that when \(\Delta\) is sufficiently small, with high probability, all actions in  \(\mathcal{A}^{\iota}_h(s) = \{ a \in \mathcal{A} \mid \langle \phi(s,a), \gamma^*_h \rangle \leq \tau - \iota \}\) are feasible for both \(V_1\) and \(V_3\). Moreover, under the Local Point Assumption, any feasible action of \(V_1\) outside \(\mathcal{A}^{\iota}_h(s)\) has a close feasible counterpart in \(V_3\) within a \(\Delta\)-neighborhood, and vice versa (see Lemma~\ref{Lemma:epsilon_Cover_utils_1} in the Appendix).  This closeness of the feasible sets of \(V_1\) and \(V_3\) enables us to reapply the ideas underlying OCD and effectively bound the covering number in the second phase of Algorithm~\ref{alg:SafeNonConvex}.  
\paragraph{Step 3: Final Assembly.} With these log-polynomial bound for the covering number in hand—achieved, we can apply standard self-normalized concentration inequalities. Thus, we can prove the following Lemmas:

\begin{lemma}
\label{Lemma:Optimism_Lemma_SafeRL_ICML_1}
    (Optimism) With probability of at least \(1-\frac{\delta}{2}\), we have: \(\mathcal{T}_1 \leq 0\).
\end{lemma}
\begin{lemma}
\label{Lemma:Bounding_T2_ICML_SAFERL_1}
     (Bounding \(\mathcal{T}_2\)) With the probability of at least \(1-\frac{\delta}{2}\), the regret of Algorithm \ref{alg:SafeNonConvex} is upper bounded as follows: \(\mathcal{T}_2  \leq \sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h +   \sum_{k=K'}^K \sum_{h=1}^H 2 \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + g^k_h(s^k_h, a^k_h),\) where \(\zeta^k_{h+1} \triangleq \mathbb{P}_h (V^{k}_{h+1} - V^{\pi^k}_{h+1} )(s^k_h, a^k_h) - \delta^k_{h+1}\) and \(\delta^k_{h+1} \triangleq V^{k}_h(s^k_h) - V^{\pi^k}_h(s^k_h)\).
\end{lemma}
Now, combining the last two steps and upper bounding the normalized term obtained in step 3, we can apply Lemma~\(11\) from \citet{abbasi2011improved} to derive the final result. Additionally, Theorem~\(2\) from \citet{abbasi2011improved} can be applied to show that our approach ensures high-probability safety.

% \begin{lemma}
%  With probability at least \(1-\frac{\delta}{2}\), the chosen actions by Algorithm \ref{alg:SafeNonConvex} satisfy the safety constraints for all episodes. In other words, for all \((h,k) \in [H]\times[K]\),
% \( 
% \mathcal{A}^k_h(s) \subseteq \mathcal{A}^{\text{safe}}_h(s).
% \)
% \end{lemma}



\section{Experiment}
\label{Sec:Experiment_ICML_Jan_1}



We consider an autonomous-vehicle path-planning task in a merging scenario (Figure~\ref{fig:AutonomousVehcleMerging_ICML_Jan_1}) where the goal is to navigate safely and efficiently (see Section~\ref{Sec:Non_ConvexFeratureSpace_IMCL_1} for details). A trained module (\textbf{Collav}) handles collision avoidance by masking infeasible actions, so the RL agent focuses on satisfying lane-keeping constraints. Given an initial safe policy \(\pi^{\text{safe}}\), the feature space is non-star-convex due to \textbf{Collav} but still satisfies the Local Point Assumption. Our objective is to learn an optimal safe policy with sublinear regret.   We implement \textbf{NCS-LSVI} (Algorithm~\ref{alg:SafeNonConvex}) with different values of \(K'\) and report the resulting regret in Figure~\ref{fig:regret}. For \(K' = 2000\), regret remains sublinear, indicating successful learning of the optimal safe policy after sufficient pure exploration. 
%However, for \(K' = 1\) and \(K' = 300\), regret grows linearly, underscoring the importance of pure exploration.  
Moreover, across all \(K'\), our algorithm never violates the safety constraint, ensuring lane-keeping is always satisfied. See Appendix~\ref{App:expDetails} for further details and more experiments. 
\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.65\columnwidth]{Regret_final.png}}
    \caption{Regret vs. episodes for NCS-LSVI in an autonomous vehicle merging scenario.}
    \label{fig:regret}
    \end{center}
\vskip -0.2in
\end{figure}

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.3\textwidth]{Regret_final.png}
%     \caption{Regret vs. episodes for NCS-LSVI in an autonomous vehicle merging scenario.}
%     \label{fig:regret}
% \end{figure}



\section{Conclusion}
In this paper, we studied Safe RL with instantaneous hard constraints in both star-convex and non-star-convex settings. A key challenge in these settings is bounding the covering number of the value-function class, which is critical for achieving value-aware uniform concentration in model-free function approximation. For the star-convex setting, we introduced a novel technique, OCD, to effectively bound the covering number. This result also resolves an error in previous work on constrained RL. For non-star-convex scenarios, we proposed a new two-phase algorithm, NCS-LSVI, which effectively addresses the challenge of bounding the covering number in these settings.  Numerical simulations on an autonomous driving scenario demonstrated the practical effectiveness of our method.   In future work, we plan to explore Deep Safe RL, where neural networks introduce nonlinearities and non-convex structures, and develop suitable assumptions and algorithms for these settings.


% \section*{Impact Statement}
% This paper contributes to the advancement of Machine Learning and Learning Theory by addressing fundamental technical challenges. While the societal impacts of our work align with those typically associated with progress in these fields, we do not foresee any immediate or unique ethical concerns that require specific attention in this context.

% We studied safe RL with instantaneous hard constraints, emphasizing how the decision-set geometry fundamentally affects the covering number—unlike in unconstrained settings. A toy example illustrated that non-convex decision spaces can make the covering number arbitrarily large, complicating sublinear regret. Addressing gaps in \citet{amani2021safe}, we proposed \emph{Non-Convex Safe Least Squares Value Iteration} (NCS-LSVI), which handles star-convex decision spaces and certain non-star-convex problems under a Local Point Assumption. NCS-LSVI proceeds in a pure exploration phase to expand the estimated safe set, followed by exploration–exploitation to optimize regret while preserving safety, achieving sublinear regret. Notably, for star-convex problems, this pure exploration phase can be bypassed entirely. Experiments in safety-critical tasks (e.g., autonomous driving) highlight NCS-LSVI’s practical relevance. 




% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}


% \printbibliography
\bibliography{example_paper}
\bibliographystyle{icml2025}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DELETE THIS PART. DO NOT PLACE CONTENT AFTER THE REFERENCES!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\onecolumn
The appendix is organized as follows. Appendix~\ref{App:expDetails} contains the simulation details presented in the main part of the paper. Appendix~\ref{App:RelatedWorks} provides the related works to our paper. Appendix~\ref{ProofOFEpsilonCoveringReference} includes the proofs for bounding the covering number in both star-convex and non-star-convex settings, as stated in Theorems~\ref{Theorem: upperbound_1} and~\ref{Theorem: upperbound_StarConvex_1}. Appendix~\ref{App:ProofStepsOFNonStarConvexSafeRLICML_1} contains the detailed proof steps for Theorem~\ref{Theorem: upperbound_1} in the non-star-convex setting. Finally, Appendix~\ref{App:ProofStepsOFStarConvexSafeRLICML_1} provides the proof steps for Theorem~\ref{Theorem: upperbound_StarConvex_1} in the star-convex setting.

\section{Experiment Details and Star-Convex Simulations}
\label{App:expDetails}
\subsection{Detailed Setup for Section~\ref{Sec:Experiment_ICML_Jan_1} Experiments}
\paragraph{Problem Statement}

We consider a merging scenario at an intersection where an autonomous vehicle must navigate safely and efficiently. The intersection consists of a main road with another vehicle already traveling on it and a merging lane where our autonomous vehicle starts. The autonomous vehicle needs to decide whether to wait for the car on the main road to pass or to accelerate and merge into the main road before the other car arrives. Please see Figure~\ref{fig:AutonomousVehcleMerging_ICML_Jan_1} for a sketch of the scenario. The objective of the autonomous vehicle is to maximize the traversed path toward a goal point within a finite time horizon while adhering to the following constraints:
1. Avoid collisions with the car on the main road.
2. Keep the vehicle within the lane boundaries. In our experiment we assume that, the car includes a trained collision avoidance module (referred to as \textbf{Collav}), which identifies infeasible actions that could lead to collisions, threfore the RL agent does not need to learn collision avoidance constraint. However, lane-keeping is a constraint that the RL agent must learn during its interaction with the environment. Please see Figure \ref{fig:AutonomousVehicleDiagram_1} for a brief diagram of our problem.


Accelerating to merge into the main road is the optimal choice in this scenario, as it allows the vehicle to traverse a greater distance toward the goal point within the finite time horizon. However, due to the unknown dynamics of the car, the RL agent must adopt a conservative strategy, denoted as \(\pi^{\text{safe}}\), to avoid losing control when accelerating.





\paragraph{Vehicle Dynamics}

The vehicle's dynamics are governed by the following equations:
\begin{equation}
\begin{bmatrix} 
x_{t+1} \\ 
y_{t+1} \\ 
v^x_{t+1} \\ 
v^y_{t+1} 
\end{bmatrix} =  
\begin{bmatrix} 
x_{t} + v^x_{t+1} \\ 
y_{t} + v^y_{t+1} \\ 
f(v^x_{t} + \alpha_1 u^x_t) \\ 
f(v^y_{t} + \alpha_2 u^y_t) 
\end{bmatrix},
\end{equation}
where \(x_t, y_t\) represent the vehicle's position, and \(v^x_t, v^y_t\) are its velocities. The control inputs \(u^x_t, u^y_t\) affect the velocity through unknown parameters \(\alpha_1, \alpha_2\). The function \(f(\cdot)\) models nonlinear dynamics, which are linear in most regions but saturate at the car's speed limits as illustrated in Figure~\ref{fig:dyn}. For simulation purposes, we set \((\alpha_1, \alpha_2) = (0.5, 0.5)\).


\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.61\columnwidth]{dynamic.png}}
    \caption{Plot of \(f(x)\) showing the dynamics function behavior.}
\label{fig:dyn}
    \end{center}
\vskip -0.2in
\end{figure}



\paragraph{Lane-Keeping Constraint}

The lane-keeping constraint ensures that the vehicle remains within the lane boundaries:
\(
\mathcal{R}^{\text{lanes}} = \{(x, y) \in \mathbb{R}^2 \mid y^{\min} \leq y \leq y^{\max}\},
\)
where \(y^{\min} = -0.3\) and \(y^{\max} = \frac{1}{3}\). This ensures that the vehicle does not drift out of the lane.

\paragraph{Collision Avoidance}
The collision avoidance module \textbf{Collav} restricts unsafe actions at the start of each episode (\(h = 0\)). Specifically, actions that result in a speed within \(\frac{1}{16} \leq |v^x_t + v^y_t| \leq \frac{1}{4}\) are prohibited. For all other timesteps (\(h \in [H]\)), the module does not impose any restrictions. At \(h = 0\), the resulting restricted action space is shown in Figure \ref{fig:AutonomousVehcleMerging_ICML_Jan_1}. The time horizon for the simulation is \(H = 3\).

\paragraph{Initial Safe Policy.}
The initial safe policy, \(\pi^{\text{safe}}\), is defined as:
\( 
\pi^{\text{safe}}(s_t) = \left[\frac{v^{\text{ref}} - v^x_t}{\kappa_1}, \frac{v^{\text{ref}} - v^y_t}{\kappa_2}\right]^\top,
\)
where \(v^{\text{ref}} = 0.001\) is a small conservative reference speed, and \(\kappa_1 = 100000\) and \(\kappa_2 = 0.5\) determine the reaction strength to deviations.

\paragraph{Algorithm Implementation}
We implement Algorithm \ref{alg:SafeNonConvex} for this setup using the feature vector:
\( 
\phi(s, a) = [x, y, v^x, v^y, u^x, u^y]^\top\),
and express the lane-keeping constraint as:
\(
y^{\min} \leq \langle \phi(s, a), \gamma^* \rangle \leq y^{\max}
\), where \(\gamma^*\) is an unknown parameter vector. The total number of episodes is set to \(K = 1000\), with \(\epsilon = 0.1\) chosen to satisfy Assumption \ref{assumption:epsilon_origin_1}. The pure exploration parameter \(K'\) is selected from \(\{1, 300, 2000\}\). We discretize the action space into grids of size \(\frac{1}{8} \times \frac{1}{8}\) to address optimization challenges in the non-convex setup. However, our state space is continueous. Moreover, in order to speed-up our Algorithm, we update the \(Q\)-function's parameter (\(w^k_h\)) every \(2^k\) epochs. 

\paragraph{Results} Figure \ref{fig:regret} demonstrates that after an initial exploration phase, the agent converges to the optimal policy, achieving sublinear regret. Additionally, Figure \ref{fig:regret} shows that the \(y_t\) values remain within the lane boundaries throughout both exploration and exploitation phases.


\begin{figure}[htbp]
    \centering
        \includegraphics[width=\linewidth]{AutonomousVehicle.jpg}
        \caption{The diagram of autonomous vehicle example: Agent interacts with the environment and observe feedbacks on its location and speed. It utilizes the feedback to imporove the estimation of lane keeping. Then, using lane keeping and a trained collav module it provides the safe set of actions. The decision making module uses the feedback to enhance the estimation on \(Q\) function, and then utilizes the saf set to make the next decision. Note that the Collav block is trained a prioir and we are not learning it, but lane keeping and Decision Making are the blocks that RL agent needs to learn.}
\label{fig:AutonomousVehicleDiagram_1}
     \end{figure}


\subsection{Experiment in the Star-Convex Setting}
Based on Lemma~\ref{Lemma:CoveringNumberLowerBound}, we observe that in non-star-convex settings, without a pure exploration phase, the covering number is lower bounded by the cardinality of the state space. However, Theorem~\ref{Theorem: upperbound_StarConvex_1} establishes that in star-convex settings, the covering number can be properly bounded without a pure exploration phase, ensuring sublinear regret. To validate this argument, we conduct numerical experiments in our autonomous vehicle setting, where the state space is continuous and has infinite cardinality.  

We retain the same setup as in the non-star-convex scenario but remove the collision avoidance module, making the decision space star-convex. Specifically, we assume that the red car in Figure~\ref{fig:AutonomousVehcleMerging_ICML_Jan_1} is no longer present. According to Theorem~\ref{Theorem: upperbound_StarConvex_1}, we expect that skipping the pure exploration phase in Algorithm~\ref{alg:SafeNonConvex} (i.e., setting \(K' = 0\)) will still allow the RL agent to achieve sublinear regret. The regret graph in Figure~\ref{fig:regret_starConvex} confirms this expectation, showing that Algorithm~\ref{alg:SafeNonConvex} successfully attains sublinear regret. Moreover, the agent consistently satisfies the safety constraint, never deviating from its lane throughout learning.

\begin{figure}[ht]
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=0.61\columnwidth]{StarConvexRegret.png}}
    \caption{Regret vs. episodes for NCS-LSVI in an star-convex autonomous vehicle merging scenario.}
\label{fig:regret_starConvex}
    \end{center}
\vskip -0.2in
\end{figure}
\pagebreak
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section{Explanation of Amani's work}
% In the unconstrained linear MDP work \cite{jin2020provably}, one needs to bound $(\mathbb{P}_h-\hat{\mathbb{P}}_h)V_{h+1}^k$. One might be tempted to use the uniform concentration bound, however, the issue is that $V_{h+1}^k$ itself depends on the samples $\{x_{h+1}\}_{\tau=1}^{k-1}$, hence, one cannot apply the standard concentration lemma. \cite{jin2020provably} used the value-aware uniform concentration bound to address the issue. In particular, they introduce a value function class 
% $\mathcal{V}=\{V(\cdot)|V(\cdot)=\min\{\max_{a\in A} \phi(\cdot,a)^Tw+\beta \sqrt{\phi(\cdot,a)^T(\Lambda_h)^{-1}\phi(\cdot,a)},H\}$, then they show that the $\epsilon$-covering number of this class $\mathcal{V}$ is small using the contraction operator max. Then they can apply the standard concentration bounds on this fixed $\epsilon$-close points.

% \cite{amani2021safe} extended the above approach for the safe RL work where the action space is bounded by some estimated safe set $a\in \mathcal{A}_{h,safe}^k$. They then argue that the restricted value function class will also have a small covering number which is enough to apply the uniform concentration lemma. However, the problem is that the action space is also now changing over the episodes depending on the data. Hence, one cannot directly apply the result from \cite{jin2020provably} to obtain the $\epsilon$-covering number. Hence, the result in \cite{amani2021safe} is not correct.  %In particular, one now needs to show that 


% In contrast, we define the value function class as 
% \begin{equation}
%     \begin{aligned}
% \mathcal{V}=\{V|V(s) & = \max_{a \in \mathcal{A}} \langle \phi(s,a), \theta \rangle + \|\phi(s,a)\|_{A} + g_{A',1}(s,a)\\
% & \quad \text{subject to} \quad \langle \phi(s,a), \gamma \rangle + \|\phi(s,a)\|_{A'} \leq \tau\}.
%   \end{aligned}
% \end{equation}
% We then obtain the $\epsilon$-covering number of such a value function class which is non-trivial.
% %\textbf{The problem} with the above argument is that the set $\mathcal{A}_{h,safe}^k$ at state $x_h$ is computed from the samples $\{x_{h+1}^k\}_{k=1}^K$ and so on. 

\section{Related Works}
\label{App:RelatedWorks}
\textbf{RL with constraints:} RL problems with cumulative constraints are studied in 
\citet{wu2016conservative, achiam2017constrained, tessler2018reward, yang2019projection, efroni2020exploration, NEURIPS2020_ae95296e, ding2021provably, bai2022achieving, wei2022triple, paternain2022safe, ghosh2022provably, vaswani2022near, ghosh2022achieving, ding2023provably, ghosh2023achieving, huang2023safe, ghosh2024towards}. This line of work focuses on ensuring the expected cumulative cost remains below a threshold, unlike instantaneous constraints that must be satisfied with high probability at each time step.

\textbf{Bandits with instantaneous hard constraints:} Bandits with instantaneous constraints have been studied in \citet{amani2019linear, khezeli2020safe, moradipari2020linear, moradipari2020stage, moradipari2021safe, pacchiano2021stochastic, zhou2022kernelized, deng2022interference, pacchiano2024contextual, hutchinson2024directional, afsharrad2024convex}. Unlike RL, Bandits do not require the estimation of a value function, and therefore the problem of covering number does not arise in this setting. This distinction significantly simplifies the analysis and algorithm design in the context of Bandits compared to RL with instantaneous hard constraints.

\textbf{RL with instantaneous hard constraints:} Problems with unsafe states in a star-convex setting have been studied in \citet{shi2023near}. However, this setting focuses on the linear mixture model, which is fundamentally different from our setting, as explained in Section~\ref{sec:problem_formulation_continuous_action_space}. Lastly, work in \citet{wei2024safe} relaxed the assumption that a prior safe action is given to the algorithm, instead allowing sublinear constraint violation. Thus, none of the above works have studied RL with instantaneous hard constraints for non-star-convex decision spaces.

\section{Bounding Covering Number in Theorems \ref{Theorem: upperbound_1} and \ref{Theorem: upperbound_StarConvex_1}}
\label{ProofOFEpsilonCoveringReference}
In Appendix~\ref{subsection: resultsforepscoveringNumberinSafeRLAppendix_1}, we present our results for bounding the covering number of the function class of individual value functions in the non-star-convex setting defined in Theorem ~\ref{Theorem: upperbound_1}. Similarly, Appendix~\ref{subsection: resultsforepscoveringNumberinSafeRLAppendix_1_StarConvex_1} contains our results for the star-convex setting defined in Theorem~\ref{Theorem: upperbound_StarConvex_1}. Appendix~\ref{App:LemmaProofCoveringNumberLowerBound} provide our proof for Lemma \ref{Lemma:CoveringNumberLowerBound}. Additionally, Appendix~\ref{utils:EpsilonCover} provides proofs for auxiliary lemmas used in the previous sections.


Before presenting the proof, we define the function class of value functions used in our work below.
\begin{definition}   Let \(\mathcal{V}\) denotes a class of functions, \(\min \{V(.), H\} \), where \(V(.)\) is mapping from \(\mathcal{S}\) to \(\mathbb{R}\) with the following parametric form:

\begin{equation}
\label{eq:eps_Covering_Ed}
    \begin{aligned}
        & V(s) \triangleq \min\{ \max_{a\in\mathcal{A}} (\langle \phi(s,a), w \rangle + \beta \lVert \phi(s,a) \rVert_{\Lambda^{-1}}) + g_{\Lambda^{-1}}(s,a),\,\, H\} \\
        & \qquad s.t: \langle \phi(s,a) - \phi(s,a_s^0), \gamma \rangle + \beta' \lVert \phi(s,a) - \phi(s,a_s^0) \rVert_{(\Lambda')^{-1}} \leq \tau,
    \end{aligned}
\end{equation}
where the parameters \((w, \gamma, \beta, \beta', \Lambda)\) satisfy \(\lVert w \rVert \leq L_w\), \(\lVert \gamma \rVert \leq \sqrt{d}\), \(\lambda_{\text{min}}(\Lambda) \geq \lambda\), \(\beta \in [0, B]\), and \(\beta' \in [0, B']\). Also, \( g_{\Lambda^{-1}, \beta'}\) is defined as follows:

% \begin{equation}
% \label{eq:eps_cover_bonus_nonConvex_g}
%     g_{\Lambda^{-1}, \beta'}(s, a) \triangleq (1-\frac{\tau}{\tau + 2 \beta'  \|\phi(s,a)\|_{\Lambda^{-1}}}) H
% \end{equation}. 
% \end{definition}

\begin{equation}
\label{eq:eps_cover_bonus_nonConvex_g}
    g_{\Lambda^{-1}, \beta'}(s, a) \triangleq \frac{2}{\tau} \beta'  \|\phi(s,a) - \phi(s,a^0_s)\|_{\Lambda^{-1}}
\end{equation}. 
\end{definition}


\subsection{Covering Number in Linear MDPs with Instantaneous Hard Constraints under Local Point Assumption}
\label{subsection: resultsforepscoveringNumberinSafeRLAppendix_1}



  Now we state the next Lemma that provide a proper upper bound for \(\mathcal{N}_\kappa\):


\begin{lemma}
\label{Lemma:BoundedCovering_PureExploraion_1}
    \textbf{(Covering number in linear MDPs with instantaneous hard constraints under Local Point Assumption).} Consider the setting of Theorem \ref{Theorem: upperbound_1}, and let  \( \kappa \leq \frac{\iota}{2}\). Then there exists a finite set of functions \(\mathcal{V}_{\kappa} \subset \mathcal{V}\) such that for all  \(k\geq K'\), there exists a \(V\in \mathcal{V}_{\kappa}\) such that \(dist(V, V^k_h) \leq \kappa\). Moreover, let \(\mathcal{N}_{\kappa}\)
   be the cardinality  for \(\mathcal{V}_\kappa\), then with probability of at least \(1-\delta\), we will have the following:
\begin{equation}
\label{eq:epsilon_Covering_UpperBound}
    \begin{aligned}
        & \log(\mathcal{N}_\kappa) \leq d \bigg[\log(1+\frac{4 L_w}{\kappa}) + \log(1+\frac{8  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + H)}{\kappa  \tau}) \bigg] \\
        & \qquad + d^2 \bigg[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} (B')^2  (\frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2})\bigg].
    \end{aligned}
\end{equation}
\end{lemma}
\paragraph{Proof:}
We equivalently define \(A = \beta^2 \Lambda^{-1}\) and \(A' = \beta'^2 \Lambda^{-1}\) and reparameterize the class function \(\mathcal{V}\) as follows:
\begin{equation}
    \begin{aligned}
        & V(.) = \min\{\max_{a\in\mathcal{A}} \langle \phi(.,a), w \rangle +  \lVert \phi(.,a) \rVert_{A} + g_{A',1}(.,a), \,\, H\}\\
        & \qquad s.t: \langle \phi(.,a) - \phi(.,a^0_.), \gamma \rangle + \lVert \phi(.,a) - \phi(.,a^0_s) \rVert_{A'}) \leq \tau,
    \end{aligned}
\end{equation}
where \( \lVert A \rVert \leq \frac{B^2}{\lambda} \) and \( \lVert A' \rVert \leq \frac{(B')^2}{\lambda} \).

Now, for \(k\geq K'\), let \(V_1 = V^k_h\) be the value function generated by Algorithm \ref{alg:SafeNonConvex} during the exploration-exploitation phase (secon phase), and \(V_2\) is an arbitrary function in \(\mathcal{V}\). Then, there exist parameters \((w_1, \gamma_1, A_1, A'_1)\) and \(( w_2, \gamma_2, A_2, A'_2)\) such that:
\begin{equation}
\label{eq:V_1_2_ICML_Appendix_SafeRL_1}
    \begin{aligned}
         & V_1(s) = \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_1 \rangle + \lVert \phi(s,a) \rVert_{A_1} + g_{A'_1,1}(s,a), H\}\\
         & \qquad s.t: \langle \phi(s,a) - \phi(s,a^0_s), \gamma_1 \rangle + \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{A'_1} \leq \tau\\\\
          & V_2(s) = \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_2 \rangle +  \lVert \phi(s,a) \rVert_{A_2}) + g_{A'_2,1}(s,a), H\}\\
         & \qquad s.t: \langle \phi(s,a)  - \phi(s,a^0_s), \gamma_2 \rangle + \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{A'_2} \leq \tau
    \end{aligned}
\end{equation}


Now, define \(V_3\) as follows:
\begin{equation}
\label{eq:V_3_ICML_Appendix_SafeRL_1}
    \begin{aligned}
         & V_3(s) =  \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_1 \rangle + \lVert \phi(s,a) \rVert_{A_1}) + g_{A'_1,1}(s,a), H\}\\
         & \qquad s.t: \langle \phi(s,a)  - \phi(s,a^0_s), \gamma_2 \rangle + \lVert \phi(s,a)   - \phi(s,a^0_s)\rVert_{A'_2}) \leq \tau
    \end{aligned}
\end{equation}


Now, using triangle inequlity, for all \(s\in \mathcal{S}\), we have:

\begin{equation}
    \begin{aligned}
        & |V_1(s) - V_2(s)| \leq |V_1(s) - V_3(s)| + |V_2(s) - V_3(s)|
    \end{aligned}
\end{equation}

Now, applying the triangle inequality for all \(s \in \mathcal{S}\), we have:  
\[
|V_1(s) - V_2(s)| \leq |V_1(s) - V_3(s)| + |V_2(s) - V_3(s)|.
\]  
To bound \(|V_1(s) - V_2(s)|\), it suffices to separately bound \(|V_1(s) - V_3(s)|\) and \(|V_2(s) - V_3(s)|\). Notably, \(V_2\) and \(V_3\) share the same constraint parameters, resulting in identical feasible sets. Therefore, their difference can be bounded by the difference in their objective parameters. On the other hand, \(V_1\) and \(V_3\) have differing constraint parameters, leading to different feasible decision sets. In the following, we provide bounds for each of these terms.  

\paragraph{Bounding \(|V_1(s) - V_3(s)|\)}
Note that \(V_1(s) = V^k_h\) after pure exploration phase of Algorithm \ref{alg:SafeNonConvex}, i.e., \(k\geq K'\). Thus, we show that if the differnce between the constraint parameters of \(V_1\) and \(V_3\) are small enough then their feasible set also does not change drastically as explained in the following Lemma:

\begin{lemma}
\label{Lemma:epsilon_Cover_utils_1}
\textbf{(No dramatic changes in the estimated action set).}
  Let \(\Delta = \lVert \gamma_2 - \gamma_1 \rVert + \sqrt{\lVert A_1' - A_2' \rVert_F}\), where \(\lVert \cdot \rVert_F\) denotes the Frobenius norm for matrices, and assume \(\Delta \leq \frac{\iota}{2}\). For each \(s \in \mathcal{S}\), let \(\phi(s, a_1^*)\) represent the solution of the constrained optimization problem associated with \(V_1 = V^k_h\) for \(k \geq K'\). Then, with probability of at least \(1-\delta\), there exists \(\alpha_3 \in [\frac{\tau}{\tau + \Delta}, 1]\) such that \(\alpha_3 \phi(s, a_1^*) + (1-\alpha_3) \phi(s,a^0_s)\) is feasible for the constrained optimization problem associated with \(V_3\). Specifically, there exists an action \(a_3 \in \mathcal{A}\) such that \(\phi(s, a_3) = \alpha_3 \phi(s, a_1^*) + (1-\alpha_3) \phi(s,a^0_s)\), and the following holds:
    \begin{equation*}
        \begin{aligned}
           \langle (\phi(s,a_3) - \phi(s,a^0_s), \gamma_2 \rangle + \lVert \phi(s,a_3) - \phi(s,a^0_s) \rVert_{A'_2} \leq \tau
        \end{aligned}
    \end{equation*}
\end{lemma}

The proof of the above Lemma is provided in Section \ref{utils:EpsilonCover}.

Using the above lemma, we can immediately derive the following result:

\begin{lemma}
\label{Lemma:eps_cover_relation_ValueFunctions}
\label{Lemma:epsilon_Cover_Value_FunctionsRelations}
    For each \(s \in \mathcal{S}\), with the probability of at least \(1-\delta\), the following inequality is satisfied:
    \begin{equation*}
        \begin{aligned}
            V_1(s) - V_3(s) \leq \frac{\Delta}{\tau + \Delta} (H + \sqrt{\lVert A_1 \rVert_F}) .
        \end{aligned}
    \end{equation*}
\end{lemma}
The proof of this lemma can be found in Section \ref{utils:EpsilonCover}. 

Now, simliar steps can be applied to get \(V_3(s) - V_1(s) \leq  \frac{\Delta}{\tau + \Delta} (H + \sqrt{\lVert A_1 \rVert_F}) \). Thus, we  will have:
\begin{equation}
\label{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_1}
    \begin{aligned}
        & |V_1(s) - V_3(s)| \leq \frac{\Delta}{\tau + \Delta} \left(H + \sqrt{\lVert A_1 \rVert_F} \right) \leq \frac{\Delta}{\tau} \left(H + \sqrt{\lVert A_1 \rVert_F} \right),
    \end{aligned}
\end{equation}
where the last inequality obtained by the fact that \(\frac{\Delta}{\tau + \Delta} \leq \frac{\Delta}{\tau}\). Now, substituiting \(\Delta = \lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert_F}\) in Eq.(\ref{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_1}) we will have:

\begin{equation}
\label{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_2}
    \begin{aligned}
        & |V_1(s) - V_3(s)| \leq \left(H + \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} \right) \frac{\lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert_F}}{\tau} ,
    \end{aligned}
\end{equation}
where we used the fact that \(\lVert A_1 \rVert_F \leq \frac{\sqrt{d} B^2}{\sqrt{\lambda}}\).

\paragraph{Bounding \(|V_2(s) - V_3(s)|\)}   To bound \(|V_2(s) - V_3(s)|\), we follow a similar approach to Lemma \(\mathbf{D.6}\) in \cite{jin2020provably}:  
\begin{equation}
\label{eq:bounding_Values_Difference_SafeRL_ICML}
    \begin{aligned}
        &|V_2(s) - V_3(s)| \\
        &  \leq  \sup_{a\in\mathcal{A}}  \Big | \langle \phi(s,a), w_1 \rangle +  \lVert \phi(s,a)  \rVert_{A_1} + g_{A'_1,1}(s,a)\\
        & \qquad \qquad  \qquad \qquad - \langle \phi(s,a), w_2 \rangle - \lVert \phi(s,a) \rVert_{A_2} - g_{A'_2, 1}(s,a) \Big| \\\\
         & \leq \lVert w_1 - w_2 \rVert + \sqrt{ \lVert A_1 - A_2 \rVert_F} + \sup_{a\in\mathcal{A}} | g_{A'_1,1}(s,a) - g_{A'_2, 1}(s,a) |,
    \end{aligned}
\end{equation}
where the first inequality follows from the fact that \(V_2\) and \(V_3\) are maximized over the same action space (see Equations (\ref{eq:V_1_2_ICML_Appendix_SafeRL_1}) and (\ref{eq:V_3_ICML_Appendix_SafeRL_1})), and the optimal solution to the constrained problem is upper bounded by the optimal solution to the unconstrained problem.

Now, it remained to bound \(\sup_{a\in\mathcal{A}} | g_{A'_1,1}(s,a) - g_{A'_2, 1}(s,a)|\). Thus, we state the following helpful Lemma:

\begin{lemma}
\label{Lemma:boundingDeltaGNew}
Given PSD matrices \(A'_1\) and \(A'_2\), the following inequlity holds:
\begin{equation*}
    \begin{aligned}
        & \sup_{s,a} |g_{A'_1, 1} (s,a) - g_{A'_2, 1}(s,a)| \leq \frac{2 H }{\tau } \sqrt{\lVert A'_1 - A'_2 \rVert_F}
    \end{aligned}
\end{equation*}
\end{lemma}
\textbf{Proof:} The proof of the above Lemma is provided in Section \ref{utils:EpsilonCover}.

Now, by applying Lemma \ref{Lemma:boundingDeltaGNew} to Equation (\ref{eq:bounding_Values_Difference_SafeRL_ICML}), we can bound \(|V_2(s) -V_3(s)|\) as follows:

\begin{equation}
\label{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_3}
    \begin{aligned}
        &|V_2(s) - V_3(s)|  \leq \lVert w_1 - w_2 \rVert +  \sqrt{ \lVert A_1 - A_2 \rVert_F}  + \frac{2 H}{\tau} \sqrt{\rVert A'_1 - A'_2 \lVert_F}
    \end{aligned}
\end{equation}

\paragraph{Bounding \(|V_1(s) - V_2(s)|\):} Combining Eq.~(\ref{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_2}) and Eq.~(\ref{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_3}), with the proability of at least \(1-\delta\), we have:

\begin{equation}
    \begin{aligned}
\label{eq:eps_cover_upperbound_for_V1_V2}
       & |V_1(s) - V_2(s)| \leq |V_1(s) - V_3(s)|+ |V_2(s) - V_3(s)|\\
       & \leq \left(H + \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} \right) \frac{\lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert_F}}{\tau} + \lVert w_1 - w_2 \rVert +  \sqrt{ \lVert A_1 - A_2 \rVert_F}  + \frac{2 H}{\tau} \sqrt{\rVert A'_1 - A'_2 \lVert_F}
    \end{aligned}
\end{equation}

\paragraph{Final step.} 
Let \(\mathcal{C}_w\) be the \(\frac{\kappa}{4}\)-cover for \(\{w \in \mathbb{R}^d|\,\, \lVert w \rVert \leq L_w \}\), and  \(\mathcal{C}_\gamma\) be the \(\frac{\kappa \tau}{4 ( \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} + H)}\)-cover for \(\{\gamma \in \mathbb{R}^d|\,\, \lVert \gamma \rVert \leq \sqrt{d} \}\). Also, let \(\mathcal{C}_A\) be the \(\frac{\kappa^2}{16}\)-cover for  \(\{A \in \mathbb{R}^{d\times d}| \,\, \lVert A \rVert_F \leq \frac{\sqrt{d} B^2}{\lambda}\} \), and   let \(\mathcal{C}_{A'}\) be the \(\frac{\kappa^2 \tau^2}{16 ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3 H)^2}\)-cover for  \(\{A' \in \mathbb{R}^{d\times d}| \,\, \lVert A' \rVert_F \leq \frac{\sqrt{d} B^2}{\lambda}\} \). By Lemma \(\mathbf{D}.5\) in \cite{jin2020provably}, we  have:

\begin{equation}
    \begin{aligned}
        &|\mathcal{C}_{w}| \leq (1+\frac{8 L_w}{\kappa})^d, \qquad |\mathcal{C}_{\gamma}| \leq (1+\frac{8  ( \frac{d^{\frac{1}{4}}  B}{\sqrt{\lambda}} + H)}{\kappa  \tau})^d\\
    & | \mathcal{C}_A | \leq  (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2})^{d^2}, \qquad | \mathcal{C}_{A'} | \leq  (1+\frac{32 \sqrt{d} (B')^2  (\frac{d^{\frac{1}{4}}  B}{\sqrt{\lambda}} + 3 H)^2}{ \lambda \tau^2 \kappa^2})^{d^2}
    \end{aligned}
\end{equation}
Now, by Eq. (\ref{eq:eps_cover_upperbound_for_V1_V2}), for any \(V_1 = V^k_h\) generated by Algorithm \ref{alg:SafeNonConvex} and \(k \geq K'\), there exist \(w_2 \in \mathcal{C}_w\), \(\gamma_2 \in \mathcal{C}_\gamma\), \(A_2 \in \mathcal{C}_A\), and \(A'_2 \in \mathcal{C}_{A'}\) such that:
\begin{equation*}
    \begin{aligned}
        & dist(V_1, V_2) = \sup_s|V_1(s) - V_2(s)| \leq \kappa
    \end{aligned}
\end{equation*}
Hence, it holds that \(\mathcal{N}_\kappa \leq 
|\mathcal{C}_w| \,\, |\mathcal{C}_\gamma| \,\,|\mathcal{C}_A| \,\, |\mathcal{C}_{A'}|
\), which yields:

\begin{equation*}
    \begin{aligned}
        & \log(\mathcal{N}_\kappa) \leq \log(|\mathcal{C}_w|) + \log(|\mathcal{C}_\gamma|) + \log(|\mathcal{C}_A|) + \log(|\mathcal{C}_{A'}|)\\
        & \leq d \bigg[\log(1+\frac{8 L_w}{\kappa}) + \log(1+\frac{8  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + H) }{\kappa  \tau})] \\
        & \qquad + d^2[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} (B')^2  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2}) \bigg]. \quad \square
    \end{aligned}
\end{equation*}

\subsection{Covering Number in Linear MDPs with Instantaneous Hard Constraints under Star-Convexity Assumtion (Theorem \ref{Theorem: upperbound_StarConvex_1})}
\label{subsection: resultsforepscoveringNumberinSafeRLAppendix_1_StarConvex_1}

Here, we bound the covering number for star-convex cases. The main difference from our proof for the Local Point Assumption lies in Lemma \ref{Lemma:epsilon_Cover_utils_1}, where we show that in the star-convex case, even when \(K' = 0\), the estimated safe set remains stable under small variations in the safety parameters.

\begin{lemma}
\label{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1}
    \textbf{(Covering number in linear MDPs with instantaneous hard constraints under Star-Convex Assumption).} Consider the setting of Theorem \ref{Theorem: upperbound_StarConvex_1}. Let  \( \kappa\) be a positive number. Then there exists a finite set of functions \(\mathcal{V}_{\kappa} \subset \mathcal{V}\) such that for all  \(k\in [K]\), there exists a \(V\in \mathcal{V}_{\kappa}\) such that \(dist(V, V^k_h) \leq \kappa\). Moreover, let \(\mathcal{N}_{\kappa}\)
   be the cardinality  for \(\mathcal{V}_\kappa\), then we will have the following:
\begin{equation}
\label{eq:epsilon_Covering_UpperBound_StarConvex_1}
    \begin{aligned}
        & \log(\mathcal{N}_\kappa) \leq d \bigg[\log(1+\frac{4 L_w}{\kappa}) + \log(1+\frac{8  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + H)}{\kappa  \tau}) \bigg] \\
        & \qquad + d^2 \bigg[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} (B')^2  (\frac{ d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2})\bigg].
    \end{aligned}
\end{equation}
\end{lemma}
\paragraph{Proof:}
We equivalently define \(A = \beta^2 \Lambda^{-1}\) and \(A' = \beta'^2 \Lambda^{-1}\) and reparameterize the class function \(\mathcal{V}\) as follows:
\begin{equation}
    \begin{aligned}
        & V(.) = \min\{\max_{a\in\mathcal{A}} \langle \phi(.,a), w \rangle +  \lVert \phi(.,a) \rVert_{A} + g_{A',1}(.,a), H\}\\
        & \qquad s.t: \langle \phi(.,a) - \phi(.,a^0_.), \gamma \rangle + \lVert \phi(.,a) - \phi(.,a^0_.) \rVert_{A'}) \leq \tau,
    \end{aligned}
\end{equation}
where \( \lVert A \rVert \leq \frac{B^2}{\lambda} \) and \( \lVert A' \rVert \leq \frac{(B')^2}{\lambda} \).

Now, let \(V_1 = V^k_h\) be the value function generated by Algorithm \ref{alg:SafeNonConvex} during the exploration-exploitation phase, and \(V_2\) is an arbitrary function in \(\mathcal{V}\). Then, there exist parameters \((w_1, \gamma_1, A_1, A'_1)\) and \(( w_2, \gamma_2, A_2, A'_2)\) such that:
\begin{equation}
\label{eq:V_1_2_ICML_Appendix_SafeRL_1StarConvex_1}
    \begin{aligned}
         & V_1(s) = \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_1 \rangle + \lVert \phi(s,a) \rVert_{A_1} + g_{A'_1,1}(s,a),\,\, H\}\\
         & \qquad s.t: \langle \phi(s,a), \gamma_1 \rangle + \lVert \phi(s,a) \rVert_{A'_1} \leq \tau\\\\
          & V_2(s) = \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_2 \rangle +  \lVert \phi(s,a) \rVert_{A_2}) + g_{A'_2,1}(s,a),\,\, H\}\\
         & \qquad s.t: \langle \phi(s,a), \gamma_2 \rangle + \lVert \phi(s,a) \rVert_{A'_2} \leq \tau
    \end{aligned}
\end{equation}


Now, define \(V_3\) as follows:
\begin{equation}
\label{eq:V_3_ICML_Appendix_SafeRL_1StarConvex_1}
    \begin{aligned}
         & V_3(s) \triangleq \min\{\max_{a\in\mathcal{A}} \langle \phi(s,a), w_1 \rangle + \lVert \phi(s,a) \rVert_{A_1}) + g_{A'_1,1}(s,a), \,\, H\}\\
         & \qquad s.t: \langle \phi(s,a), \gamma_2 \rangle + \lVert \phi(s,a) \rVert_{A'_2}) \leq \tau
    \end{aligned}
\end{equation}

Similar to our Proof for Lemma \ref{Lemma:BoundedCovering_PureExploraion_1}, we can write \(|V_1(s) - V_2(s) \leq |V_1(s) - V_3(s)| + |V_2(s) - V_3(s)|\). Thus, to bound \(|V_1(s) - V_2(s)|\), it suffices to separately bound \(|V_1(s) - V_3(s)|\) and \(|V_2(s) - V_3(s)|\). 

\paragraph{Bounding \(|V_1(s) - V_3(s)|\).}
Now, we provide the counter part of the Lemma~\ref{Lemma:epsilon_Cover_utils_1} for the  Star-Convex setting as stated below:
\begin{lemma}
\label{Lemma:epsilon_Cover_utils_1StarConvex_1}
\textbf{(No dramatic changes in the estimated safe set under Star-Convexity).}
  Let \(\Delta = \lVert \gamma_2 - \gamma_1 \rVert + \sqrt{\lVert A_1' - A_2' \rVert_F}\), where \(\lVert \cdot \rVert_F\) denotes the Frobenius norm for matrices. For each \(s \in \mathcal{S}\), let \(\phi(s, a_1^*)\) represent the solution of the constrained optimization problem associated with \(V_1 = V^k_h\), for \(k \in [K]\). Then, there exists \(\alpha_3 \in [\frac{\tau}{\tau + \Delta}, 1]\) such that \(\alpha_3 \phi(s, a_1^*) + (1-\alpha_3) \phi(s,a^0_s)\) is feasible for the constrained optimization problem associated with \(V_3\). Specifically, there exists an action \(a_3 \in \mathcal{A}\) such that \(\phi(s, a_3) = \alpha_3 \phi(s, a_1^*) + (1-\alpha_3) \phi(s, a^0_s)\), and the following holds:
    \begin{equation}
        \begin{aligned}
           \langle \phi(s,a_3) - \phi(s,a^0_s), \gamma_2 \rangle + \lVert \phi(s,a_3) - \phi(s,a^0_s) \rVert_{A'_2} \leq \tau
        \end{aligned}
    \end{equation}
\end{lemma}

The proof of the above Lemma is provided in Section \ref{App:ProvingNoDrasticChangesinSafeSet_StarConvex_ICML_1}.

\begin{remark}
The key difference between Lemma~\ref{Lemma:epsilon_Cover_utils_1StarConvex_1} and Lemma~\ref{Lemma:epsilon_Cover_utils_1} lies in their applicability: Lemma~\ref{Lemma:epsilon_Cover_utils_1StarConvex_1} holds for all \(k \in [K]\), whereas Lemma~\ref{Lemma:epsilon_Cover_utils_1} is valid only for \(k \geq K'\) with high probability. This distinction is the primary reason why the Pure Exploration phase in Algorithm~\ref{alg:SafeNonConvex} is unnecessary in star-convex settings.
\end{remark}


The remaining steps are identical to the proof steps outlined in Lemma \ref{Lemma:BoundedCovering_PureExploraion_1}.  In fact, using Lemma~\ref{Lemma:eps_cover_relation_ValueFunctions} we will have:

\begin{equation}
\label{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_2_Star_Convex_1}
    \begin{aligned}
        & |V_1(s) - V_3(s)| \leq \left(H + \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} \right) \frac{\lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert_F}}{\tau} ,
    \end{aligned}
\end{equation}


\paragraph{Bounding \(|V_2(s) - V_3(s)|\)}  Now, applying Lemma~\ref{Lemma:boundingDeltaGNew} on Eq.~(\ref{eq:bounding_Values_Difference_SafeRL_ICML}) we get the following:
\begin{equation}
\label{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_3_star_convex}
    \begin{aligned}
        &|V_2(s) - V_3(s)|  \leq \lVert w_1 - w_2 \rVert +  \sqrt{ \lVert A_1 - A_2 \rVert_F}  + \frac{2 H}{\tau} \sqrt{\rVert A'_1 - A'_2 \lVert_F}
    \end{aligned}
\end{equation}

\paragraph{Bounding \(|V_1(s) - V_2(s)|\):} Combining Eq.~(\ref{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_2_Star_Convex_1}) and Eq.~(\ref{Eq:UtilityDrsticChangesResultOnValueFUnction_SAFERL_ICML_3_star_convex}), we have:

\begin{equation}
    \begin{aligned}
\label{eq:eps_cover_upperbound_for_V1_V2_starConvex}
       & |V_1(s) - V_2(s)| \leq |V_1(s) - V_3(s)|+ |V_2(s) - V_3(s)|\\
       & \leq \left(H + \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} \right) \frac{\lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert_F}}{\tau} + \lVert w_1 - w_2 \rVert +  \sqrt{ \lVert A_1 - A_2 \rVert_F}  + \frac{2 H}{\tau} \sqrt{\rVert A'_1 - A'_2 \lVert_F}
    \end{aligned}
\end{equation}

\paragraph{Final step.} 
Let \(\mathcal{C}_w\) be the \(\frac{\kappa}{4}\)-cover for \(\{w \in \mathbb{R}^d|\,\, \lVert w \rVert \leq L_w \}\), and  \(\mathcal{C}_\gamma\) be the \(\frac{\kappa \tau}{4 ( \frac{d^{\frac{1}{4}} B}{\sqrt{\lambda}} + H)}\)-cover for \(\{\gamma \in \mathbb{R}^d|\,\, \lVert \gamma \rVert \leq \sqrt{d} \}\). Also, let \(\mathcal{C}_A\) be the \(\frac{\kappa^2}{16}\)-cover for  \(\{A \in \mathbb{R}^{d\times d}| \,\, \lVert A \rVert_F \leq \frac{\sqrt{d} B^2}{\lambda}\} \), and   let \(\mathcal{C}_{A'}\) be the \(\frac{\kappa^2 \tau^2}{16 ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3 H)^2}\)-cover for  \(\{A' \in \mathbb{R}^{d\times d}| \,\, \lVert A' \rVert_F \leq \frac{\sqrt{d} B^2}{\lambda}\} \). By Lemma \(\mathbf{D}.5\) in \cite{jin2020provably}, we  have:

\begin{equation}
    \begin{aligned}
        &|\mathcal{C}_{w}| \leq (1+\frac{8 L_w}{\kappa})^d, \qquad |\mathcal{C}_{\gamma}| \leq (1+\frac{8  ( \frac{d^{\frac{1}{4}}  B}{\sqrt{\lambda}} + H)}{\kappa  \tau})^d\\
    & | \mathcal{C}_A | \leq  (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2})^{d^2}, \qquad | \mathcal{C}_{A'} | \leq  (1+\frac{32 \sqrt{d} (B')^2  (\frac{d^{\frac{1}{4}}  B}{\sqrt{\lambda}} + 3 H)^2}{ \lambda \tau^2 \kappa^2})^{d^2}
    \end{aligned}
\end{equation}
Now, by Eq. (\ref{eq:eps_cover_upperbound_for_V1_V2_starConvex}), for any \(V_1 = V^k_h\) generated by Algorithm \ref{alg:SafeNonConvex} and \(k \in [K]\), there exist \(w_2 \in \mathcal{C}_w\), \(\gamma_2 \in \mathcal{C}_\gamma\), \(A_2 \in \mathcal{C}_A\), and \(A'_2 \in \mathcal{C}_{A'}\) such that:
\begin{equation*}
    \begin{aligned}
        & dist(V_1, V_2) = \sup_s|V_1(s) - V_2(s)| \leq \kappa
    \end{aligned}
\end{equation*}
Hence, it holds that \(\mathcal{N}_\kappa \leq 
|\mathcal{C}_w| \,\, |\mathcal{C}_\gamma| \,\,|\mathcal{C}_A| \,\, |\mathcal{C}_{A'}|
\), which yields:

\begin{equation*}
    \begin{aligned}
        & \log(\mathcal{N}_\kappa) \leq \log(|\mathcal{C}_w|) + \log(|\mathcal{C}_\gamma|) + \log(|\mathcal{C}_A|) + \log(|\mathcal{C}_{A'}|)\\
        & \leq d \bigg[\log(1+\frac{8 L_w}{\kappa}) + \log(1+\frac{8  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + H) }{\kappa  \tau})] \\
        & \qquad + d^2[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} (B')^2  ( \frac{d^{\frac{1}{4}}B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2}) \bigg]. \quad \square
    \end{aligned}
\end{equation*}
\subsection{Proof of Lemma \ref{Lemma:CoveringNumberLowerBound}}
\label{App:LemmaProofCoveringNumberLowerBound}
\paragraph{Proof:}
Let \(\mathcal{V}'' \triangleq \{v_\gamma \in \mathcal{V}\mid \gamma \in \cup_{i=1}^n\{\frac{1}{i}\} \}\). Firsly, we show that for all \(v''_1, v''_2 \in \mathcal{V}''\) with \(v''_1 \neq v''_2\), we have \(\sup_{s\in\mathcal{S}} |v''_1(s) - v''_2(s)| \geq \frac{1}{3}\). To prove this, note that there exists \(i, j \in \mathbb{N} \) such that \(v''_1 = v_{\frac{1}{i}}\) and \(v''_2 =v_{\frac{1}{j}} \). Now, without loss of generality assume that \(i < j\) Thus, for \(s=j\) we will have: \(v''_1(j) = \frac{1}{3}\) but \(v''_2(j) =\frac{2}{3}\). Thus,

\begin{equation}
\label{eq:DifferenceLowerBound_LemmaCoveringLower}
    \begin{aligned}
        & \forall v''_1, v''_2 \in \mathcal{V}'' \text{ such that } v''_1 \neq v''_2:
        \sup_{s\in\mathbb{S}}|v''_1(s) - v''_2(s)| \geq |\frac{2}{3} - \frac{1}{3}| = \frac{1}{3}.
    \end{aligned}
\end{equation}





Now, to complete our proof, we use a contradiction strategy. Assume that \(\mathcal{V}'\) is a \(\kappa\)-covering for \(\mathcal{V}\) such that \(|\mathcal{V}'| \leq |\mathbb{S}| - 1\) and \(\kappa < \frac{1}{6}\). Since \(\mathcal{V}'\) is a \(\kappa\)-covering, for all \(v'' \in \mathcal{V}''\), there exists a \(v' \in \mathcal{V}'\) such that
\[
\sup_{s \in \mathbb{S}} |v''(s) - v'(s)| < \kappa \leq \frac{1}{6}.
\]
However, since \(\mathcal{V}'\) has one fewer element than \(\mathcal{V}''\), there must exist two functions \(v''_1, v''_2 \in \mathcal{V}''\) and one function \(v'_{1,2} \in \mathcal{V}'\) such that
\[
\sup_{s \in \mathbb{S}} |v''_1(s) - v'_{1,2}(s)| \leq \kappa \quad \text{and} \quad \sup_{s \in \mathbb{S}} |v''_2(s) - v'_{1,2}(s)| \leq \kappa.
\]
However, this implies:


\begin{equation}
\label{eq:DifferenceLowerBound_LemmaCoveringLower_2}
    \begin{aligned}
        &  \sup_{s\in\mathbb{S}} \Big|v''_1(s) - v''_2(s)\Big| =   \sup_{s\in\mathbb{S}} \Big|v''_1(s) - v_{1,2}'(s) + \big(v_{1,2}'(s) - v''_2(s)\big)\Big|\\
        & \leq  \sup_{s\in\mathbb{S}} |v''_1(s) - v_{1,2}'(s)| +  \sup_{s\in\mathbb{S}} |v''_2(s) -v_{1,2}'(s)| \leq 2 \kappa < \frac{1}{3}
    \end{aligned}
\end{equation}

Thus, combining Equations \ref{eq:DifferenceLowerBound_LemmaCoveringLower} and \ref{eq:DifferenceLowerBound_LemmaCoveringLower_2} we will have: 

\[\frac{1}{3} \leq \sup_{s\in\mathbb{S}} \Big|v''_1(s) - v''_2(s)\Big| < \frac{1}{3},\] which is a contraditction and it completes the proof \(\square\)

\subsection{Proof of Lemmas  \ref{Lemma:epsilon_Cover_utils_1} -\ref{Lemma:boundingDeltaGNew}}
\label{utils:EpsilonCover}
Before we delve into the proof we state the following helpful lemma:

\begin{lemma}
\label{Lemma:PureExploration_1}  For any \( \delta \in (0, 1) \), let \( K' \geq \frac{8 d}{\epsilon^2} \log(\frac{H d}{\delta})\). Then, with probability at least \( 1 - \delta \), the following inequality holds for all \((s, a)\), and \(k\geq K'\):

\[
(\phi(s,a) - \phi(s,a_s^0))^T (\Lambda^{k, \gamma}_h)^{-1} (\phi(s,a) - \phi(s,a_s^0)) \leq \frac{1}{\lambda + \frac{\lambda_- k}{2}} \lVert \phi(s,a) - \phi(s,a_s^0) \rVert^2.
\]

\end{lemma}

Using Lemma \ref{Lemma:PureExploration_1} we can immdiately prove the following Lemma as well.
\begin{lemma}
\label{Lemma:SafesetAfter_PureExploration_1}
Let \( K' = \max\{\frac{8 d}{\epsilon^2} \log(\frac{d H}{\delta}), \frac{2 d}{\epsilon^2} (\frac{16 \beta_2^2}{\iota^2} - \lambda)\}\), and define \(\mathcal{A}^{\frac{\iota}{2}}_h(s) \triangleq \{a \in \mathcal{A} \mid \langle \phi(s,a), \gamma^*_h \rangle \leq \tau - \frac{\iota}{2}\}\). For all \( K \geq K' \), with probability at least \( 1 - \delta \), we have \( \mathcal{A}^{\frac{\iota}{2}}_h(s) \subset \mathcal{A}^k_h(s) \).
\end{lemma}
The proof of Lemma \ref{Lemma:SafesetAfter_PureExploration_1} is provided in Appendix \ref{App:ProofOFLemmaPureExploreinLinearMDP}.

Now, we are ready for the main proof:
\paragraph{Proof of Lemma \ref{Lemma:epsilon_Cover_utils_1}}
\paragraph{Bounding difference between safety values}First of all, we want to bound the safety values of \(V_1\) and \(V_3\):



\begin{equation}
\label{Eq:UtilityAftterArnobDisc_SAFERL_ICML_1}
    \begin{aligned}
        & \forall (s,a): | \langle \phi(s,a) - \phi(s,a^0_s) , \gamma_2 \rangle + \lVert \phi(s,a) - \phi(s,a^0_s)  \rVert_{A'_2} - \langle \phi(s,a)  - \phi(s,a^0_s)  , \gamma_1 \rangle + \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_1}| \\
        & \leq | \langle \phi(s,a) - \phi(s,a^0_s) , \gamma_2 - \gamma_1 \rangle | + | \lVert \phi(s,a) - \phi(s,a^0_s)  \rVert_{A'_2} - \lVert \phi(s,a) - \phi(s,a^0_s)  \rVert_{A'_1}|\\
        & \leq \lVert \phi(s,a) - \phi(s,a^0_s) \rVert \, ( \lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert})\\
        & \leq 2 \left( \lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert} \right) = 2 \Delta
    \end{aligned}
\end{equation}
where the last inequality obtained by Assumption \ref{assumption:epsilon_origin_1}  that \(\lVert \phi \rVert \leq 1\). 

\paragraph{Existence of the feasible feature for \(V_3\): }
 Let \(\mathcal{A}^{\iota}_h(s) \triangleq \{a\in \mathcal{A} \mid \langle \phi(s,a), \gamma^*_h \rangle \leq \tau - \iota\}\). Then, we decompose the proof into two sub-cases:



\begin{itemize}
    \item \textbf{Case 1:} If \(a^*_1 \in \mathcal{A}^{\iota}_h(s)\), then we show that \(a^*_1\) is feasible for the optimization problem of \(V_3\). Using Eq.(\ref{Eq:UtilityAftterArnobDisc_SAFERL_ICML_1}) we will have:

    \begin{equation}
    \label{Eq:EpsCoveringLemma9_PureExploration_1}
        \begin{aligned}
            & \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma_2 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s)  \rVert_{A'_2} \leq \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma_1 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s)  \rVert_{A'_1} + \Delta
        \end{aligned}
    \end{equation}
Now, on the event \(\mathcal{E}_1\), since \(V_1\) is the estimated value function computed by Algorithm~\ref{alg:SafeNonConvex} (recall that \(V_1 = V^k_h\)), we have:

   \begin{equation}
        \begin{aligned}
            & \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma_1 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s)  \rVert_{A'_1} + \Delta \leq \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma^*_h \rangle + 2\lVert \phi(s,a^*_1)  - \phi(s,a^0_s) \rVert_{A'_1} + 2 \Delta
        \end{aligned}
    \end{equation}
But by Lemma \ref{Lemma:PureExploration_1}, for all \(K \geq K'\) we will have:
   \begin{equation}
        \begin{aligned}
            & \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma^*_h \rangle + 2\lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_1} + \Delta \leq \langle \phi(s,a^*_1) - \phi(s,a^0_s) , \gamma^*_h \rangle + \frac{\iota}{2} + \Delta 
        \end{aligned}
    \end{equation}
    Now, by the Assumption of Lemma \ref{Lemma:epsilon_Cover_utils_1}, we have \(\Delta \leq \frac{\iota}{2}\), using Assumption \ref{assumption:startingPoint_1}, and  since \(a^*_1 \in \mathcal{A}^{\iota}_h(s)\) we will have:

    \begin{equation}
    \label{Eq:EpsCoveringLemma9_PureExploration_2}
        \begin{aligned}
            & \langle \phi(s,a^*_1)- \phi(s,a^0_s)  , \gamma^*_h \rangle + 2\lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_1} + \Delta \leq \tau - \iota + \frac{\iota}{2} + \frac{\iota}{2} = \tau 
        \end{aligned}
    \end{equation}

    Now, combining Equations (\ref{Eq:EpsCoveringLemma9_PureExploration_1}-\ref{Eq:EpsCoveringLemma9_PureExploration_2}) yields:
    \begin{equation}
    \label{eq:ImpliciationEq_ExistenceSAFERLICML_ARNOB_Edit_1}
        \begin{aligned}
            &  a^*_1  \in \mathcal{A}^{\iota}_h(s) \implies  \langle \phi(s,a^*_1) - \phi(s,a^0_s)  , \gamma_2 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s)  \rVert_{A'_2} \leq \tau
        \end{aligned}
    \end{equation}
    which implies that \( a_3 = a^*_1\) is feasible for the constrained optimization problem for \(V_3\) and completes the proof for case 1. 
\item \textbf{Case 2:} Now, we only need to show the proof for the  case that \(a^*_1\in (\mathcal{A}^\iota_h(s))^C \cap \mathcal{A}^k_h(s)\), where \((\mathcal{A}^\iota_h(s))^C\) is the complement of the set \(\mathcal{A}^\iota_h(s)\), and  \(\mathcal{A}^k_h(s)\) is the feasible set for the optimization problem for \(V_1 \) (recall that \(V_1 = V^k_h\)). Note that \(a^*_1\in (\mathcal{A}^\iota_h(s))^C \cap \mathcal{A}^k_h(s)\) implies that \( \tau - \iota \leq \langle \phi(s,a^*_1), \gamma^*_h \rangle \leq \tau \), which implies \( \langle \frac{\tau - \iota}{\langle \phi(s,a^*_1), \gamma^*_h \rangle} \phi(s,a^*_1), \gamma^*_h \rangle = \tau - \iota\). Then, by Assumption \ref{assumption:epsilon_origin_1} we have  \(\alpha \phi(s,a^*_1) + (1-\alpha) \phi(s,a^0_s) \in \mathcal{F}_s\), where \(\alpha = \frac{\tau - \iota}{\langle \phi(s, a^*_1), \gamma^*_h \rangle}\), i.e., there exists an \(a' \in \mathcal{A}\) such that \(\phi(s,a') = \alpha \phi(s,a^*_1) + (1-\alpha) \phi(s,a^0_s)\). Now, since \(a' \in \mathcal{A}^\iota_h(s)\), from Case 1 (Eq.~(\ref{eq:ImpliciationEq_ExistenceSAFERLICML_ARNOB_Edit_1})) we have that:
\begin{equation}
\label{eq:DrasticLocalPoint_util_ICMLSAFE_1}
    \begin{aligned}
        & \langle \phi(s,a') - \phi(s,a^0_s)  , \gamma_2 \rangle + \lVert \phi(s,a') - \phi(s,a^0_s)  \rVert_{A'_2} \leq \tau,
    \end{aligned}
\end{equation}
 which implies that \(a'\) is feasible for the constrained optimization problem of \(V_3\). 

On the other hand, let \(\alpha' = \frac{\tau}{\tau + \Delta}\), then we will have:

\begin{equation}
\label{eq:DrasticLocalPoint_util_ICMLSAFE_2}
    \begin{aligned}
        &\Big\langle \big(\alpha' \phi(s,a^*_1) + (1-\alpha') \phi(s,a^*_1)\big) - \phi(s,a^*_1) , \gamma_2 \Big\rangle + \Big\lVert \big(\alpha' \phi(s,a^*_1) + (1-\alpha') \phi(s,a^0_s)\big) - \phi(s,a^0_s) \Big\rVert_{A'_2}\\
        & =  \alpha' \left( \langle \phi(s,a^*_1) - \phi(s,a^0_s), \gamma_2 \rangle  + \lVert \phi(s,a^*_1)  - \phi(s,a^0_s) \Big\rVert_{A'_2} \right) 
        \\
        & \qquad\leq \alpha' ( \langle \phi(s,a^*_1) - \phi(s,a^0_s) , \gamma_1 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_1} + \Delta) \leq \tau
    \end{aligned}
\end{equation}
where the last ineuqlity obtained by the fact that \(a^*_1\) is feasible for the constrained problem of \(V_1\), and \(\alpha' = \frac{\tau}{\tau + \Delta}\).

Now, let \(\alpha_3 = \max\{\alpha, \alpha'\}\). Since \( \frac{\tau - \iota}{\langle \phi(s, a^*_1), \gamma^*_h \rangle}  = \alpha \leq \alpha_3 \leq 1\),  we can apply Assumption \ref{assumption:epsilon_origin_1} to find that \( \alpha_3  \phi(s,a^*_1) + (1-\alpha_3) \phi(s,a^0_s) \in \mathcal{F}_s\), i.e. there exists an \(a_3 \in \mathcal{A}\) such that \(\phi(s,a_3) = \alpha_3  \phi(s,a^*_1) + (1-\alpha_3) \phi(s,a^0_s) \). From Eq.(\ref{eq:DrasticLocalPoint_util_ICMLSAFE_1}) and Eq.(\ref{eq:DrasticLocalPoint_util_ICMLSAFE_2}), it follows that \(\phi(s,a_3)\) is feasible for the constrained problem of \(V_3\), i.e. \(\langle \phi(s,a_3) - \phi(s,a^0_s) , \gamma_2 \rangle + \lVert  \phi(s,a_3) - \phi(s,a^0_s) \rVert_{A'_2} \leq \tau\). \(\square\)
\end{itemize}


\paragraph{Proof of Lemma \ref{Lemma:epsilon_Cover_Value_FunctionsRelations}}  Using Lemma \ref{Lemma:epsilon_Cover_utils_1}, there exists an action \(a_3\) which is  feasible for \(V_3(.)\), and \(\phi(s,a_3) = \alpha_3 \phi(s,a^*_1) + (1-\alpha_3) \phi(s,a^0_s)\) for some \(\alpha \in [\frac{\tau}{\tau+\Delta}, 1]\). Thus, we have:


\begin{equation}
    \begin{aligned}
        &  V_3(s) \geq  \min\{\langle \phi(s,a_3), w_1 \rangle +  \lVert \phi(s,a_3) \rVert_{A_1} + g_{A'_1,1}(s,a_3), \,\, H\}\\
        & =  \min\Big\{\langle \alpha_3 \phi(s,a_1^*) + (1-\alpha_3) \phi(s,a^0_s), w_1 \rangle +  \lVert \alpha_3 \phi(s,a_1^*) + (1-\alpha_3) \phi(s,a^0_s) \rVert_{A_1} \\
        & \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad \,\,+ \lVert \big(\alpha_3 \phi(s,a_1^*) + (1-\alpha_3) \phi(s,a^0_s)\big)  - \phi(s,a^0_s)\rVert_{A'_1},\,\, H \Big\} \\
        & \geq \min\Big\{\alpha_3 \big(  \langle  \phi(s,a_1^*), w_1 \rangle + \lVert \phi(s,a_1^*)\rVert_{A_1}  + \phi(s,a_1^*)\rVert_{A'_1} \big) - (1-\alpha_3) \lVert \phi(s,a_1^*)\rVert_{A_1},\,\, H\Big\}  \\
        & \geq   \min\Big\{\alpha_3 \big(  \langle  \phi(s,a_1^*), w_1 \rangle + \lVert \phi(s,a_1^*)\rVert_{A_1}  + \phi(s,a_1^*)\rVert_{A'_1} \big),\,\, H\Big\}  - (1-\alpha_3) \lVert \phi(s,a_1^*)\rVert_{A_1}\\   
        & \geq \alpha_3 V_1(s) - (1-\alpha_3) \lVert \phi(s,a_1^*)\rVert_{A_1},
    \end{aligned}
\end{equation}
where the last inequality obtained by the fact that \(\alpha_3 \leq 1\). Thus:
\begin{equation}
\label{Eq:BoundingV13DifferentConstrint_Util_SafeRL_1}
    \begin{aligned}
        &  V_1(s) - V_3(s) \leq  (1-\alpha_3) \big( V_1(s) + \lVert \phi(s,a_1^*)\rVert_{A_1}\big)
    \end{aligned}
\end{equation}
Now, since \(V_1 \leq H\) we can continue Eq.(\ref{Eq:BoundingV13DifferentConstrint_Util_SafeRL_1}) as follows:
\begin{equation}
\label{Eq:BoundingV13DifferentConstrint_Util_SafeRL_2}
    \begin{aligned}
        &  V_1(s) - V_3(s) \leq  \frac{\Delta}{\tau + \Delta}\big( H + \lVert \phi(s,a_1^*)\rVert_{A_1}\big)  \leq \frac{\Delta}{\tau + \Delta}\big( H + \sqrt{\lVert A_1 \rVert_F}\big),
    \end{aligned}
\end{equation}
where \(\lVert A_1 \rVert_F\) is the Frobenius norm of the matrix \(A_1\). \(\square\)

\paragraph{Proof of Lemma \ref{Lemma:boundingDeltaGNew}:}
Consider an arbitrary pair \((s,a)\), then we have:

    % \begin{equation}
    %     \begin{aligned}
    %         &|g_{A'_1, 1}(s,a) - g_{A'_2, 1}(s,a)| = 2 H \tau \times \frac{|\,\, \lVert \phi(s,a) \rVert_{A'_1} - \lVert \phi(s,a) \rVert_{A'_2} \,\,|}{(\tau + 2 \lVert \phi(s,a) \rVert_{A'_1}) \times (\tau + 2 \lVert \phi(s,a) \rVert_{A'_2})} \\
    %         & \leq 2 H \tau \times \frac{|\,\, \lVert \phi(s,a) \rVert_{A'_1} - \lVert \phi(s,a) \rVert_{A'_2} \,\,|}{\tau^2} =  2 H \frac{|\,\, \lVert \phi(s,a) \rVert_{A'_1} - \lVert \phi(s,a) \rVert_{A'_2} \,\,|}{\tau}\\
    %         & \leq  2 H \frac{|\,\, \lVert \phi(s,a) \rVert_{A'_1} - \lVert \phi(s,a) \rVert_{A'_2} \,\,|}{\tau}
    %         \leq  2 H \frac{\sqrt{\lVert A'_1 - A'_2 \rVert}}{\tau}
    %     \end{aligned}
    % \end{equation}
    \begin{equation}
        \begin{aligned}
            &|g_{A'_1, 1}(s,a) - g_{A'_2, 1}(s,a)| =   2 H \frac{ \Big|\,\, \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_1} - \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_2} \,\, \Big |}{\tau}
            \leq  2 H \frac{\sqrt{\lVert A'_1 - A'_2 \rVert}}{\tau}
        \end{aligned}
    \end{equation}
    where, the last inequality is obtained by the fact that \(|\sqrt{x} - \sqrt{y}| \leq \sqrt{|x - y|}\) for any \(x, y \geq 0\). Now, using the fact that Frobenius norm is larger than matrix-norm we can continue:
    \begin{equation}
        \begin{aligned}
            &|g_{A'_1, 1}(s,a) - g_{A'_2, 1}(s,a)| 
            \leq 2 H \frac{\sqrt{\lVert A'_1 - A'_2 \rVert}}{\tau} 
            & \leq 2 H \frac{\sqrt{\lVert A'_1 - A'_2 \rVert_F}}{\tau}
        \end{aligned}
    \end{equation}
    The last inequality completes the proof. \(\square\)





\subsection{Proof of Lemma \ref{Lemma:epsilon_Cover_utils_1StarConvex_1}}
\label{App:ProvingNoDrasticChangesinSafeSet_StarConvex_ICML_1}
\paragraph{Proof:}
\paragraph{Bounding difference between safety values}First of all, we want to bound the safety values of \(V_1\) and \(V_3\):



\begin{equation}
\label{eq:util_DrasticChange_safeSet_ICML_StarConvex_1}
    \begin{aligned}
        & \forall (s,a): \left| \langle \phi(s,a) - \phi(s,a^0_s) , \gamma_2 \rangle + \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_2} - \langle \phi(s,a) - \phi(s,a^0_s) , \gamma_1 \rangle + \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_1} \right| \\
        & \leq | \langle \phi(s,a) - \phi(s,a^0_s) , \gamma_2 - \gamma_1 \rangle | + | \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_2} - \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{A'_1}|\\
        & \leq \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert \, ( \lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert})\\
        & \leq  2 \lVert \gamma_1 - \gamma_2 \rVert + \sqrt{\lVert A'_1 - A'_2 \rVert} = 2 \Delta
    \end{aligned}
\end{equation}
where the last inequality obtained by Assumption \ref{assumption:epsilon_origin_1}  that \(\lVert \phi \rVert \leq 1\). 

\paragraph{Existence of the feasible feature for \(V_3\): }  By Assumption \ref{assumption:Star_ConvexAssumption_1} we have \(  \alpha \, \phi(s,a^*_1) + (1-\alpha) \phi(s,a^0_s) \in \mathcal{F}_s\), where \(\alpha = \frac{\tau }{\tau + \Delta} \), i.e., there exists an \(a' \in \mathcal{A}\) such that \(\phi(s,a') =  \alpha \phi(s,a^*_1) + (1-\alpha) \phi(s,a^0_s)\). Now, we show that \(a'\) is feasible for the constrained problem \(V_3\). In fact, we have:
\begin{equation}
\label{Eq:UtilSafeICMLStarCOnvexDrastic_2}
    \begin{aligned}
        & \langle \phi(s,a') - \phi(s,a^0_s) , \gamma_2 \rangle + \lVert \phi(s,a') - \phi(s,a^0_s) \rVert_{A'_2} = \alpha \left( \langle \phi(s,a^*_1) - \phi(s,a^0_s) , \gamma_2 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_2} \right)
    \end{aligned}
\end{equation}

Now, using Eq.(\ref{eq:util_DrasticChange_safeSet_ICML_StarConvex_1}) we can continue Eq.(\ref{Eq:UtilSafeICMLStarCOnvexDrastic_2}) as follows:
\begin{equation}
\label{Eq:UtilSafeICMLStarCOnvexDrastic_3}
    \begin{aligned}
         \langle \phi(s,a') , \gamma_2 \rangle +  \lVert \phi(s,a') \rVert_{A'_2} &=  \alpha \left( \langle \phi(s,a^*_1) -\phi(s,a^0_s) , \gamma_2 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_2} \right)   \\
        &   \leq \alpha   \left( \langle \phi(s,a^*_1) - \phi(s,a^0_s) , \gamma_1 \rangle + \lVert \phi(s,a^*_1) - \phi(s,a^0_s) \rVert_{A'_1} + \Delta \right) \\
        & \leq \frac{\tau}{\tau+\Delta} (\tau + \Delta) = \tau,
    \end{aligned}
\end{equation}
where the last ineuqlity obtained by the fact that \(a^*_1\) is feasible for the constrained problem of \(V_1\), and \(\alpha = \frac{\tau}{\tau + \Delta}\). Thus, \(\langle \phi(s,a') , \gamma_2 \rangle + \lVert \phi(s,a') \rVert_{A'_2} \leq \tau\), which implies that \(a'\) is feasible for the constrained problem of \(V_3\). Now, setting \(a_3 = a'\) and \(\alpha_3 = \alpha'\) concludes the proof.  \(\square\)


\section{Proof Steps of Theorem \ref{Theorem: upperbound_1}}
\label{App:ProofStepsOFNonStarConvexSafeRLICML_1}
We start with the following definition:

\begin{definition}
\label{Def:event_E_2}
    For any fixed policy, the event \(\mathcal{E}_2\) is defined as: 
  \begin{equation}
    \label{eq: event_eps_2}
    \begin{aligned}
        & \mathcal{E}_2 \triangleq \{| \langle \phi(s,a), w^k_h \rangle \, - Q^{\pi}_h(s,a) + E_{s^{'}\sim \mathbb{P}_h(.|s,a)}[V^\pi_{h+1}(s^{'}) - V^{k}_{h+1}(s^{'})]| \leq \beta_1 \lVert \phi(s,a) \rVert_{(\Lambda^k_h)^{-1}}, \\
        &\qquad \qquad \forall(a,s,h,k) \in \mathcal{A}\times \mathcal{S}\times[H]\times[K] \},
    \end{aligned}
    \end{equation}
    where \( \beta_1 = c_{\beta} \cdot d H \sqrt{\log(\frac{2 d T }{\delta \tau})}\), and \(c_\beta\) is a constant.
\end{definition}

\begin{lemma}
\label{Lemma:high_prob_events_E2}
   Under the setup defined in Theorem \ref{Theorem: upperbound_1}, for all \(K \geq K'\), there exists a constant \(c_\beta>0\), such that for any fixed \(\delta \in (0,1)\), the event \( \mathcal{E}_2\) holds with probability at least \(1- \delta\).
\end{lemma}
\paragraph{Proof:}
 Similar to the proof steps of Lemma B.4. in \cite{jin2020provably} we will have:

 \begin{equation}
     \begin{aligned}
         & \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) = \langle \phi(s,a), w^k_h - w^\pi_h \rangle = \\
         & \underbrace{\langle \phi (s,a),- \lambda (\Lambda_h^k)^{-1} \mathbf{w}_h^\pi \rangle}_{q_1} 
         + \underbrace{ \langle \phi (s,a), (\Lambda_h^k)^{-1} \sum_{\tau=1}^{k-1} \phi_h^\tau \left[ V_{h+1}^k(s_{h+1}^\tau) - \mathbb{P}_h V_{h+1}^k(s_h^\tau, a_h^\tau) \right] \rangle}_{q_2}\\
         & \underbrace{\langle \phi (s,a), (\Lambda_h^k)^{-1} \sum_{\tau=1}^{k-1} \phi_h^\tau \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s_h^\tau, a_h^\tau) \rangle }_{q_3} .
     \end{aligned}
 \end{equation}
 
We start with bound ing \(|q_2|\), which is the term related to the covering number.
 \paragraph{Bounding \(|q_2|\)}
For our problem,we cannot directly utilize Lemma B.2 from \cite{jin2020provably} to bound \(|q_2|\), since in our case Value function is obtained by optimization over \(\mathcal{A}^k_h(s)\) instead of \(\mathcal{A}\), and \(\mathcal{A}^k_h(s)\) varies over the time. This makes bounding the covering number challenging. Thus, we first utilize Theorem D.4 from \cite{jin2020provably} to bound \(|q_2|\) in terms of the covering number of Value function in our problem, then, we apply Lemma \ref{Lemma:BoundedCovering_PureExploraion_1} to get the counterpart result of Lemma B.2 from \cite{jin2020provably}.

We start by applying Lemma D.4 from \cite{jin2020provably} on \(|q_2|\), to get that  with the probability at least \(1-\frac{\delta}{2}\) we will have:
\begin{equation}
\label{Eq:bound_q2_PureExplore_1}
    \begin{aligned}
        & |q_2| \leq  \lVert \phi(s,a)  (\Lambda_h^k)^{-1} \rVert \,\,  \lVert  \sum_{\tau=1}^{k-1} \phi_h^\tau \left[ V_{h+1}^k(s_{h+1}^\tau) - \mathbb{P}_h V_{h+1}^k(s_h^\tau, a_h^\tau) \right] \rVert \\
        & \leq \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \,\, ( 4H^2 \left[ \frac{d}{2} \log \left( \frac{k + \lambda}{\lambda} \right) + \log \frac{2 \, \mathcal{N}_\kappa}{\delta} \right] + \frac{8k^2 \kappa^2}{\lambda}),
    \end{aligned}
\end{equation}

where, \(\mathcal{N}_\kappa\) is the cardinality of the set of pre-fixed functions \(\mathcal{V}_\kappa \subset \mathcal{V}\) defined in Lemma \ref{Lemma:BoundedCovering_PureExploraion_1}. Now, considering the fact that Lemma B.2 from \cite{jin2020provably} implies that \(\lVert w^k_h\rVert \leq 2H \sqrt{\frac{dk}{\lambda}}\). Thus, using Lemma \ref{Lemma:BoundedCovering_PureExploraion_1} we can continue Eq.(\ref{Eq:bound_q2_PureExplore_1}) as follows:
\begin{equation}
\label{Eq:bound_q2_PureExplore_2}
    \begin{aligned}
        |q_2| &\leq  \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \,\, \Bigg(  4 H^2\bigg( \frac{d}{2} \log(\frac{k + \lambda}{\lambda}) +   d \Big[\log(1+ \frac{8H}{\kappa
        } \sqrt{\frac{dk}{ \lambda}}) + \log(1+\frac{8  ( (2 \sqrt{\frac{dk}{\lambda}} + 1) H + \frac{B}{\sqrt{\lambda}})}{\kappa  \tau})\Big] \\
        &+ d^2 \Big[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} B^2  (2 H \sqrt{\frac{dk}{\lambda}} + \frac{B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2})\Big]  + \log(\frac{2}{\delta}) \bigg) + \frac{8k^2 \kappa^2}{\lambda}  \Bigg)^{\frac{1}{2}},
    \end{aligned}
\end{equation}

where \(k \geq K' \geq \frac{2 d H}{\iota}\). Thus, by choosing \(\kappa = \frac{dH}{k} \leq \frac{\iota}{2}\), and taking \(B = \beta_1 = c_\beta d H \sqrt{\log(\frac{2dT}{\delta \tau})}\), and \(B' = \beta_2 = \mathbf{O}(\log(1+k H)\) we will have:

\begin{equation}
\label{Eq:bound_q2_PureExplore_3}
    \begin{aligned}
        |q_2| & \leq C   d H \log\left[2(c_{\beta} + 1)\frac{d KH}{\delta \tau}\right]  \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)},
    \end{aligned}
\end{equation}

where \(C\) is a constant.

 \paragraph{Bounding \(q_1\) and \(q_3\):}Similar to Lemma B.4 from \cite{jin2020provably} we can bound terms \(q_1\) and \(q_3\) as follows:
  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_withq2_1}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)|\\
         & \quad \leq  (2H \sqrt{d \lambda} + \sqrt{\lambda} \lVert w^\pi_h \rVert ) \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} + | q_2 |.
     \end{aligned}
 \end{equation}
 
 \paragraph{Final step}
  Combining Equations \ref{Eq:bound_q2_PureExplore_3} and \ref{Eq:bounding_CoveringNmber_PureExplore_withq2_1} yields the following:


  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_q_2Completed_1}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)|\\
         & \quad \leq  \bigg(2H \sqrt{d \lambda} + \sqrt{\lambda} \lVert w^\pi_h \rVert + C   d H \sqrt{\log \big(2(c_{\beta} + 1)\frac{d KH}{\delta \tau}} \big)  \bigg) \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)}
     \end{aligned}
 \end{equation}
Now, by Lemma B.1 from \cite{jin2020provably}, we have \(\lVert w^\pi_h \rVert \leq  2 H \sqrt{d}\). Therefore, there exists an absolute constant \(c_\beta\) such that the following holds:
  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_wholeExpression_1}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)| \leq c_{\beta} \cdot d H \sqrt{\log(\frac{2 d T }{\delta \tau})}
         \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \qquad \square
     \end{aligned}
 \end{equation}

Now, we define another important event that ensures safety, i.e., it guarantees with high probability that the estimated safe set by the agent lies within the actual safe set: 

\begin{definition}
\label{Def:event_E_1}
   The event \(\mathcal{E}_1\) is defined as: \(\mathcal{E}_1 := \{\mathcal{A}^k_h(s) \subset \mathcal{A}^{\text{safe}}_h(s) \,\, \forall (h, k) \in [H] \times [K]\}\).
\end{definition}

Our intersts lies in the events that both event \(\mathcal{E}_1\) and \(\mathcal{E}_2\) holds, i.e., the actual safe set and value function are approximed properly. Therefore, we provide the following important Lemma:
\begin{lemma}
\label{Lemma:high_prob_events_E1_E2_1}
   Under Assumption \ref{assumption:LinearMDP}, for all \(K \geq K'\), there exists a constant \(c_\beta>0\), such that for any fixed \(\delta \in (0,\frac{1}{3})\), the event \(\mathcal{E}:=\mathcal{E}_1 \cap \mathcal{E}_2\) holds with probability at least \(1-2 \delta\).
\end{lemma}
\paragraph{Proof:} 
Theorem 2 from \cite{abbasi2011improved} can be directly applied to our case to show that the event \(\mathcal{E}_1\) holds with a probability of at least \(1 - \delta\). Similarly, Lemma \ref{Lemma:high_prob_events_E2} establishes that the event \(\mathcal{E}_2\) holds with a probability of at least \(1 - \delta\). By applying the union bound, the final result follows. \(\square\)

\subsection{ Proof of Lemma \ref{Lemma:Optimism_Lemma_SafeRL_ICML_1} (Optimism)}
\label{sec:optimim_whole}
Having Lemma \ref{Lemma:high_prob_events_E1_E2_1} in hand, we are ready to prove that Algorithm \ref{alg:SafeNonConvex} satisfies the optimism property stated in Lemma \ref{Lemma:Optimism_Lemma_SafeRL_ICML_1}, which is an essential step in the final proof of regret's upper upper bound. We first provide a helpful lemma in \ref{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_1}, then in \ref{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_2} we provide the  main proof.
\subsubsection{Helpful lemmas} 
\label{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_1}

\begin{lemma}
\label{Lemma:Utility_PureExploration_Optimism_Helpful_SafetyOfFeatures_1}
Let \(k \geq K'\), where \(K'\) is specified in Theorem~\ref{Theorem: upperbound_1}. Then, there exists an action \(a' \in \mathcal{A}^k_h(s)\) such that \(\phi(s,a') =  \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\), for some \(\alpha \in [\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert}_{(\Lambda^{k,\gamma}_h)^{-1}}, 1]\).
\end{lemma}
\paragraph{Proof:} Condionted on the event \(\mathcal{E}\), when \(a^*_s \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\), then by Lemma \ref{Lemma:SafesetAfter_PureExploration_1} we find that \(a^* \in \mathcal{A}^{\frac{\iota}{2}}_h(s) \subset \mathcal{A}^k_h(s)\), which completes the proof. Thus, it remains to only prove the case that \(a^* \in (\mathcal{A}^{\frac{\iota}{2}}_h(s))^c \cap \mathcal{A}^{\text{safe}}_h(s)\). Let us assume that  \(a^* \in (\mathcal{A}^{\frac{\iota}{2}}_h(s))^c \cap \mathcal{A}^{\text{safe}}_h(s)\). Then, one can verify that \(\alpha  = \max\{\frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}, \frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} } \} \in 
[\frac{\tau - \iota}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}, 1]
\). Thus,  by Assumption \ref{assumption:epsilon_origin_1} we can argue that there exists an action \(a'\in \mathcal{A}\) such that  \( \phi(s,a') = \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\). Now, we need to show that \(a' \in \mathcal{A}^k_h(s)\) as well. Note that, when \(\alpha = \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}\), then:

\begin{equation}
\label{eq:helpfulLemma_Optimism_pureExploration_1}
    \begin{aligned}
        & \langle \phi(s,a'), \gamma^*_h \rangle =  \alpha 
 \langle \phi(s,a^*_s), \gamma^*_h \rangle + (1-\alpha) \langle \phi(s,a^0_s), \gamma^*_h \rangle \\
 & =   \alpha 
 \langle \phi(s,a^*_s), \gamma^*_h \rangle + 0 =  \tau - \frac{\iota}{2} 
    \end{aligned}
\end{equation}
where in the second equality we used Assumption \ref{assumption:startingPoint_1}, and  the last equality is obtained by substituting   \(\alpha = \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}\). Now, Equation~(\ref{eq:helpfulLemma_Optimism_pureExploration_1}) implies that \(a' \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\), and by Lemma \ref{Lemma:SafesetAfter_PureExploration_1} we have \(a' \in \mathcal{A}^k_h(s)\). Now, for the other case that \(\alpha = \frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} } \), conditioned on the event \(\mathcal{E} = \mathcal{E}_1 \cap \mathcal{E}_2\), we can follow the below steps:


\begin{equation}
\label{Eq:SafetyOfmyChoice_For_Action_Step_1}
    \begin{aligned}
    &   0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
    & = \alpha \big(\langle \phi(s,a^*_s)  - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a^*_s)  - \phi(s,a^0_s)\rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \big)\\
    & \leq 
    \alpha \big(\langle \phi(s,a^*_s)  - \phi(s,a^0_s) , \gamma^*_h \rangle +  2\beta_2 \lVert \phi(s,a^*_s)  - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \big) 
    \end{aligned}
\end{equation} 
where the last inequality is obtained by conditioning on the event \(\mathcal{E}_1 \subset \mathcal{E}\). Now, substituting \(\alpha\) with \(\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k, \gamma}_h)^{-1}} }\) in Eq.(\ref{Eq:SafetyOfmyChoice_For_Action_Step_1}) yields:


\begin{equation}
\label{Eq:SafetyOfmyChoice_For_Action_Step_2}
    \begin{aligned}
     & 0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        &  \leq  \frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s)\rVert_{(\Lambda^{k, \gamma}_h)^{-1}}} ( \langle \phi(s,a^*_{s,h}), \gamma^*_h \rangle + 2\beta_2 \lVert \phi(s,a^*_{s,h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}})
    \end{aligned}
\end{equation} 

  
Now, since \(a^*_{s,h}\) is the optimal safe solution, it should be feasible as well, i.e., \(\langle \phi(s,a^*_{s,h}), \gamma^*_h \rangle \leq \tau\). Thus, we can continue Eq. (\ref{Eq:SafetyOfmyChoice_For_Action_Step_1}) as follows:
\begin{equation}
    \begin{aligned}
           & 0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        & \quad \leq \frac{\tau}{\tau + 2 \beta_2 \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}}} ( \tau + 2 \beta_2 \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}}) \leq \tau
    \end{aligned}
\end{equation} 
The last inequality implies that \(a'\in\mathcal{A}^k_h(s)\). This, completes the proof of this Lemma. \(\square\)




% \begin{lemma}
% \label{Lemma:Utility_PureExploration_Optimism_Helpful_SafetyOfFeatures_1}
% Let \(k \geq K'\), where \(K'\) specified in Theorem \ref{Theorem: upperbound_1}. Then, there exists an action \(a' \in \mathcal{A}^k_h(s)\) such that \(\phi(s,a') =  \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\), for some \(\alpha \in [\frac{\tau - \iota}{\tau}, 1]\).
% \end{lemma}
% \paragraph{Proof:} Condionted on the event \(\mathcal{E}\), when \(a^*_s \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\), then by Lemma \ref{Lemma:SafesetAfter_PureExploration_1} we find that \(a^* \in \mathcal{A}^{\frac{\iota}{2}}_h(s) \subset \mathcal{A}^k_h(s)\), which completes the proof. Thus, it remains to only prove the case that \(a^* \in (\mathcal{A}^{\frac{\iota}{2}}_h(s))^c \cap \mathcal{A}^{\text{safe}}_h(s)\). Let us assume that  \(a^* \in (\mathcal{A}^{\frac{\iota}{2}}_h(s))^c \cap \mathcal{A}^{\text{safe}}_h(s)\). Then, one can verify that \(\alpha  = \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}\). Thus,  by Assumption \ref{assumption:epsilon_origin_1} we can argue that there exists an action \(a'\in \mathcal{A}\) such that  \( \phi(s,a') = \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\). Now, we need to show that \(a' \in \mathcal{A}^k_h(s)\) as well. Note that, when \(\alpha = \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}\), then:

% \begin{equation}
% \label{eq:helpfulLemma_Optimism_pureExploration_1}
%     \begin{aligned}
%         & \langle \phi(s,a'), \gamma^*_h \rangle =  \alpha 
%  \langle \phi(s,a^*_s), \gamma^*_h \rangle + (1-\alpha) \langle \phi(s,a^0_s), \gamma^*_h \rangle \\
%  & =   \alpha 
%  \langle \phi(s,a^*_s), \gamma^*_h \rangle + 0 =  \tau - \frac{\iota}{2} 
%     \end{aligned}
% \end{equation}
% where in the second inequality we used Assumption \ref{assumption:startingPoint_1}, and  the last equality by substituting   \(\alpha = \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle}\). Equation \ref{eq:helpfulLemma_Optimism_pureExploration_1} implies that \(a' \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\), and by Lemma \ref{Lemma:SafesetAfter_PureExploration_1} we have \(a' \in \mathcal{A}^k_h(s)\). Now, to complete the proof note  that since \(a^*_{s,h}\) is the optimal safe solution, it should be feasible as well, i.e., \(\langle \phi(s,a^*_{s,h}), \gamma^*_h \rangle \leq \tau\). Thus:  \( 1\geq  \frac{\tau - \frac{\iota}{2}}{ \langle \phi(s,a^*_s), \gamma^*_h \rangle} \geq \frac{\tau - \iota}{\tau}\), which implies \(\alpha \in [\frac{\tau - \iota}{\tau}, 1]\). \(\square\)



\subsubsection{ Main Proof of Lemma \ref{Lemma:Optimism_Lemma_SafeRL_ICML_1}}
\label{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_2}
\paragraph{Proof:} We employ an induction strategy to establish this lemma. Initially, we define the value functions at time \(H+1\) as \(V^k_{H+1}(s) = V^{\pi^*}_{H+1}(s) = 0\) for any state \(s\in\mathcal{S}\), confirming the optimism for step \(H+1\). Then, by the induction hypothesis, we assume that for an arbitrary \(h\in [H]\), \(V^{\pi^*}_{h+1}(s) \leq V^k_{h+1}(s)\) holds for all states \(s\in \mathcal{S}\). We now need to prove that \(V^{\pi^*}_{h}(s) \leq V^k_{h}(s)\) also holds for all states \(s\in \mathcal{S}\). 


Consider the case where \( H \leq  \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h \rangle + b^k_h(s,a)\). Then, \(V^{\pi^*}_h(s) \leq H = \min\{\langle \phi(s,a), w^k_h \rangle + b^k_h(s,a), H\}  = V^k_h(s) \) holds, which completes the proof for this case.


It remains to prove the result for the case where \( \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h\rangle + b^k_h(s,a) \leq H\), which implies \(V^k_h(s) =  \max_{a \in \mathcal{A}^k_h(s)}  Q^k_h(s,a) =  \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h \rangle + b^k_h(s,a)\). 


This brings us to analyze two sub-cases. First of all recall the definition of \(\mathcal{A}^{\iota}_h(s) \triangleq \{a\in \mathcal{A} \mid \langle \phi(s,a), \gamma^*_h \rangle \leq \tau - \iota\}\), then we will have the following sub-cases: 

 \textbf{Sub-case one: \(a^*_{s,h} \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\)}

For this case, by Lemma \ref{Lemma:SafesetAfter_PureExploration_1}, we will have: \(a^*_{s,h} \in \mathcal{A}^{\frac{\iota}{2}(s)}\subset \mathcal{A}^k_h(s)\), which implies that \(a^*_{s,h} \in \mathcal{A}^k_h(s)\) for all \(k\geq K'\). Now, we have:

\begin{equation}
\label{Eq:Optimism_PureExplore_DefValueFunction_1}
    \begin{aligned}
& V^k_h(s)  = \max_{a \in \mathcal{A}^k_h(s)} Q^k_h(s, a) \geq Q^k_h(s, a^*_{s,h})  =  \langle \phi(s,a^*_{s,h}), w^k_h\rangle + b^k_h(s, a^*_{s,h}). \\
\end{aligned}
\end{equation}

Then, conditioned on the event \(\mathcal{E}_2\) we have:
\begin{equation}
\label{Eq:labelTemp_Optimism_PureExploration_Subcase1_1}
    \begin{aligned}
        & \langle \phi(s,a^*_{s,h}), w^k_h \rangle + b^k_h(s, a^*_{s,h})  \\
        &  \quad \geq  Q^{\pi^*}_h(s,a^*_{s,h}) +  E_{s^{'}\sim \mathbb{P}_h(.|s,a^{s,h})}[V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] - \beta_1 \lVert \phi(s,a^*_{s,h}) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + b^k_h(s, a^*_{s,h}).\\
        & \quad \geq Q^{\pi^*}_h(s,a^*_{s,h}) +  E_{s^{'}\sim \mathbb{P}_h(.|s,a^{s,h})}[V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] 
    \end{aligned}
\end{equation}
where the last inequality obtained by the fact that \(b^k_h(s,a^*_{s,h}) = \beta_1 \lVert \phi(s,a^*_{s,h}) \rVert_{(\Lambda^{k, Q}_h)^{-1}} + g^k_h(s,a^*_{s,h})\)  and \(g \geq 0\). Now, by induction hypothesis, for all \(s\), we have: \(V^k_{h+1}(s) \geq  V^{\pi^*}_{h+1}(s)\). Thus, we can continue Equation(\ref{Eq:labelTemp_Optimism_PureExploration_Subcase1_1}) as follows:
\begin{equation}
\label{Eq:Optimism_PureExploration_Subcase1_Final_1}
    \begin{aligned}
        & \langle \phi(s,a^*_{s,h}), w^k_h \rangle + b^k_h(s, a^*_{s,h})  \\
        &  \quad  \geq Q^{\pi^*}_h(s,a^*_{s,h}) +  E_{s^{'}\sim \mathbb{P}_h(.|s,a^{s,h})}[V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] \geq  Q^{\pi^*}_h(s,a^*_{s,h}) = V^{\pi^*}_h(s)
    \end{aligned}
\end{equation}
. 
Equations \ref{Eq:Optimism_PureExplore_DefValueFunction_1} and \ref{Eq:Optimism_PureExploration_Subcase1_Final_1} together complete the proof for sub-case one.\\



\textbf{Sub-case two: \(a^*_{s,h} \in (\mathcal{A}^{\frac{\iota}{2}}_h(s))^c \cap \mathcal{A}_h^{\text{safe}}(s)\):} In this case by Lemma \ref{Lemma:Utility_PureExploration_Optimism_Helpful_SafetyOfFeatures_1}, there exists an action \(a'\in \mathcal{A}^k_h(s)\) such that \(\phi(s,a') = \alpha \phi(s,a^*_s)\) for some   \(\alpha \in [\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}}}, 1]\). Thus we will have: 


\begin{equation}
\label{Eq:Optimism_PureExplore_DefValueFunction_1_1}
    \begin{aligned}
& V^k_h(s)  = \max_{a \in \mathcal{A}^k_h(s)} Q^k_h(s, a) \geq Q^k_h(s, a')  =  \langle \phi(s,a'), w^k_h\rangle + b^k_h(s, a'). \\
\end{aligned}
\end{equation}

Then, conditioned on the event \(\mathcal{E}_2\) we have:
\begin{equation}
\label{Eq:OptimismLemma_PureExploration_SubcaseTwo_Final_1}
    \begin{aligned}
        & \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \\
        &  \quad \geq  Q^{\pi^*}_h(s,a') +  E_{s^{'}\sim \mathbb{P}_h(.|s,a')}[V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] - \beta_1 \lVert \phi(s,a') \rVert_{(\Lambda^{k, Q}_h)^{-1}} + b^k_h(s, a').\\
        & \quad \geq Q^{\pi^*}_h(s,a') +  E_{s^{'}\sim \mathbb{P}_h(.|s,a')}[ V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] + g^k_h(s,a') \geq   Q^{\pi^*}_h(s,a') +  g^k_h(s,a')
    \end{aligned}
\end{equation}

, where in the last inequality we utilized the induction hypothesis that \(V^k_{h+1}(.) \geq  V^{\pi^*}_{h+1}(.)\). By considering the fact that \(\phi(s,a') = \alpha \phi(s,a^*_s)\) we can continue Equation~(\ref{Eq:OptimismLemma_PureExploration_SubcaseTwo_Final_1}) as follows:

\begin{equation}
\label{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_1}
    \begin{aligned}
        & V^k_h(s) \geq \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \geq \alpha   \langle \phi(s,a^*_s), w^{\pi^*}_h \rangle + g^k_h(s, a'),
    \end{aligned}
\end{equation}

  

Now, according to the Equation (\ref{eq:bonus_term_non_Convex_2}) we will have:
\begin{equation}
\label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId}
    \begin{aligned}
        & g^k_h(s,a') =  
 \nu \times \left(\beta_2  \|\phi(s,a') - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}} \right)  H  =  
 (\alpha \nu) \times  \left(\beta_2  \|\phi(s,a^*_s) - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}} \right)  H
    \end{aligned}
\end{equation}
Now, by setting 
\(\nu = \frac{2}{\tau}\),  we can continue Eq. (\ref{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId}) as follows:
\begin{equation}
\label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1}
    \begin{aligned}
        & g^k_h(s,a') =  
 \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2   \|\phi(s,a^*_s) - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) H \geq (1-\alpha) H 
    \end{aligned}
\end{equation}

% \begin{equation}
% \label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId}
%     \begin{aligned}
%         & g^k_h(s,a') =  
%  \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2  \|\phi(s,a')\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) L H  =  
%  \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2  \alpha \|\phi(s,a^*_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) L H 
%     \end{aligned}
% \end{equation}
% Now, since \(\nu \geq \frac{\tau}{\tau - \iota}\), and noting the fact that \(
% \alpha \geq \frac{\tau - \iota}{\tau}
% \) we can continue Eq. (\ref{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId}) as follows:
% \begin{equation}
% \label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1}
%     \begin{aligned}
%         & g^k_h(s,a') =  
%  \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2  \alpha \|\phi(s,a^*_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) L H \geq \left(1-\frac{\tau}{\tau + 2 \beta_2  \|\phi(s,a^*_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) L H 
%     \end{aligned}
% \end{equation}

 Now, combining Equations (\ref{Eq:Optimism_ICML_SAFE_RL_SubCase2_1}) and (\ref{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_1}), and considering the fact that \(V^{\pi^*} \leq H\), we obtain the following:


\begin{equation}
\label{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_2}
    \begin{aligned}
        &  V^k_h(s) \geq \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \geq \alpha   \langle \phi(s,a^*_s), w^{\pi^*}_h \rangle + (1-\alpha) H \geq V^{\pi^*}_h(s),
    \end{aligned}
\end{equation}
where in the second inequality we used the fact that when rewards are non-negative, then according to Proposition 2.3 from \cite{jin2020provably} we will have: \(0 \leq Q^{\pi^*}_h(s,a^0_s) = \langle \phi(s,a^0_s), w^{\pi^*}_h\rangle \). The Equation~(\ref{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_2}) completes the proof. \(\square\)

\paragraph{Final Step:} Now, according to the sub-case 1 and sub-case 2, we have \(V^{\pi^*}_h \leq V^k_h\) with the probability of at least \(1-\delta\). Therefore, we can say with the probability of at least \(1-\delta\) the following holds:
\[
\mathcal{T}_1  = \sum_{k=K'}^K V^{\pi^*}_0(s_0) - V^k_0(s_0) \leq 0. \qquad \square
\]

\subsection{Proof of Lemma \ref{Lemma:Bounding_T2_ICML_SAFERL_1} (Bounding \(\mathcal{T}_2\)):}
\label{app:decompose}
\begin{lemma}
\label{Lemma: decompose_Bounding_T2_MiddleStep_ICMLSAFERL_1}
    Conditioned on the event \(\mathcal{E}\), the following inequality holds:

    \begin{equation}
        \begin{aligned}
        \label{eq:upperbound_first_result_T1_T2_1}
            &  \mathcal{T}_2 \leq \underbrace{\sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h}_{\mathcal{T}_{2,1}} + \underbrace{2\beta_1 \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}}}_{\mathcal{T}_{2,2}} + \underbrace{\sum_{k=K'}^K \sum_{h=1}^H (g^k_h(s^k_h, a^k_h))}_{\mathcal{T}_{2,3}},
        \end{aligned}
    \end{equation}
    
     where \(\zeta^k_{h+1} := \mathbb{E}_{s^{'}\sim \mathbb{P}_h(.|s^k_h,a^k_h)}[V^k_{h+1}(s^{'}) - V^{\pi^k}_{h+1}(s^{'})] - \delta^k_{h+1}\) and \(\delta^k_{h+1} := V^k_h(s^k_h) - V^{\pi^k}_h(s^k_h)\).
\end{lemma}


\paragraph{Proof:}

First, by the definition of \(V^k_h\) and \(Q^k_h\) we have: 

\begin{equation}
    \begin{aligned}
    \label{eq:upperbound_Proof_1_step_1_delta_zeta_0}
         \delta^k_{h+1} &= V^k_h(s^k_h) - V^{\pi^k}_h(s^k_h) = 
       \min\{Q^k_h(s^k_h,a^k_h), H\} - Q^{\pi^k}_h(s^k_h,a^k_h) \\
       &\leq  Q^k_h(s^k_h, a^k_h)
       -  Q^{\pi^k}_h(s^k_h,a^k_h)\\
       &  = \langle \phi(s^k_h,a^k_h), w^k_h \rangle + \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h) - Q^{\pi^k}_h(s^k_h,a^k_h). \\
    \end{aligned}
\end{equation}

Then, on the event \(\mathcal{E}\), we have:
\begin{equation}
    \begin{aligned}
    \label{eq:upperbound_Proof_1_step_1_delta_zeta_1}
 &  \langle \phi(s^k_h,a^k_h), w^k_h \rangle + \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h) - Q^{\pi^k}_h(s^k_h,a^k_h) \\
          &\leq  \mathbb{E}_{s^{'}\sim \mathbb{P}_h(.|s^k_h,a^k_h)}[V^k_{h+1}(s^{'}) - V^{\pi^k}_{h+1}(s^{'})]\\
         &= \delta^k_{h+1} + \zeta^k_{h+1} +  2 \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h). 
    \end{aligned}
\end{equation}


Now, note that we have:
\begin{equation}
    \begin{aligned}
     \label{eq:upperbound_Proof_1_step_1_delta_zeta_2}
        &\mathcal{T}_2 =  \sum_{k=K'}^K V^{k}_1(s_1^k) - V^{\pi^k}_1(s_1^k) = \sum_{k=K'}^K \delta^k_1.
    \end{aligned}
\end{equation}

Note that Lemma \ref{Lemma:Optimism_Lemma_SafeRL_ICML_1} ensures that on the event \(\mathcal{E}\), \( 0\leq \delta^k_h\) holds. Consequently, by applying Equations (\ref{eq:upperbound_Proof_1_step_1_delta_zeta_1}) and (\ref{eq:upperbound_Proof_1_step_1_delta_zeta_2}),  we can conclude:

    \begin{equation}
         \begin{aligned}
             & \mathcal{T}_2 \leq  \sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h +  2\beta_1 \sum_{k=K'}^K  \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + \sum_{k=K'}^K  \sum_{h=1}^H  g^k_h(s^k_h, a^k_h). \qquad \square
         \end{aligned}
     \end{equation}



% \subsection{Main Proof of Lemma \ref{Lemma:Bounding_T2_ICML_SAFERL_1}.}
% \paragraph{Proof:} Using Lemma \ref{Lemma: decompose_Bounding_T2_MiddleStep_ICMLSAFERL_1} we only need to bound the term \(\mathcal{T}_{2,3} = \sum_{k=1}^K \sum_{h=1}^H g^k_h(s^k_h, a^k_h)\). Using the expression for \(g\) function we have:

%   \begin{equation}
%         \begin{aligned}
%         \label{eq:sublinearly_traverse_upperBound_proof_4}
%            &\sum_{k=1}^K \sum_{h=1}^H g^k_h(s^k_h, a^k_h) = ( \nu H) \times \sum_{k=1}^K \sum_{h=1}^H  (1-\frac{\tau}{\tau + 2 \beta_2  \rVert \phi(s^k_h,a^k_h) \lVert_{(\Lambda^{k}_h)^{-1}}}). 
%         \end{aligned}
%     \end{equation}
    
% Thus, we can continue as follows:

%   \begin{equation}
%         \begin{aligned}
%         \label{eq:sublinearly_traverse_upperBound_proof_5}
%            & (\nu H) \times \sum_{k=1}^K \sum_{h=1}^H  (1-\frac{\tau}{\tau + 2 \beta_2  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}}}) \\
%            & =  (\nu H) \times \sum_{k=1}^K \sum_{h=1}^H  (\frac{2 \beta_2  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}}}{\tau + 2 \beta_2  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}}})\\
%            & \leq \frac{2 \beta_2 \nu  H }{\tau} \Sigma_{k=1}^K \Sigma_{h=1}^H  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}},
%         \end{aligned}
%     \end{equation}
    
% where the last inequality results from the fact that \(\frac{1}{{\tau + 2 \beta_2  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}}}} \leq \frac{1}{\tau}\). Now, by setting \(\nu = \frac{\tau}{\tau-\iota}\), we obtain:
% \begin{equation}
% \label{eq:second_term_upper_bound_1_Proof_Lemma}
%     \begin{aligned}
%           \sum_{k=1}^K \sum_{h=1}^H g^k_h(s^k_h, a^k_h) &\leq \frac{2 \beta_2  H}{\tau - \iota} \,  \sum_{k=1}^K \sum_{h=1}^H  \rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k}_h)^{-1}}
%     \end{aligned}
% \end{equation}
% which concludes the proof \(\square\)

\subsection{Proof of Theorem \ref{Theorem: upperbound_1}}
\label{app:Proof_Theorem1}

\paragraph{Proof of Theorem \ref{Theorem: upperbound_1}}

We start by bounding the term \(\mathcal{T}_2\):
\paragraph{Bounding \(\mathcal{T}_2\)} 
To bound the term  \(\mathcal{T}_2\). Applying Lemma \ref{Lemma:Bounding_T2_ICML_SAFERL_1} we will have:

\begin{equation}
\label{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1}
    \begin{aligned}
        & \mathcal{T}_2 \leq \sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h + 2 \beta_1  \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}}
    \end{aligned}
\end{equation}


In order to bound the first term on the right hand side of Equation (\ref{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1}) note that \(\zeta^k_h\) forms a martingale difference sequence with a bounded norm, \(|\zeta^k_h| \leq H\). Thus, we  can apply Azuma-Hoeffding's inequality: 
\begin{equation}
\label{eq:first_term_upper_bound_1_Proof_Lemma-AzumaHoeffding}
    \begin{aligned}
        &  \mathbb{P}\Big(\sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h \leq 2 H \sqrt{(K-K') H \, log(\frac{d (K - K') H}{\delta})}\, \Big) \geq 1-\delta
    \end{aligned}
\end{equation}
Therefore, with a probability of at least \(1-\delta\) we have:
\begin{equation}
\label{eq:first_term_upper_bound_1_Final_1MinusTwoDelta}
    \begin{aligned}
        & \sum_{k=K'}^K \sum_{h=1}^H \zeta^k_h 
        & \leq 2 H \sqrt{(K-K') H \, log(\frac{d (K-K') H}{\delta})} 
    \end{aligned}
\end{equation}


Now, to bound the rest of the right hand side of Equation(\ref{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1}) we can Follow the steps outlined in the proof of Theorem 3 in \cite{abbasi2011improved}, as follows:
\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_1}
    \begin{aligned}
        & 2 \beta_1  \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h)  - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        &= 2 \beta_1  \sum_{h=1}^H \sum_{k=K'}^K \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{h=1}^H \sum_{k=K'}^K \lVert \phi(s^k_h,a^k_h)  - \phi(s^k_h, a^0_{s^k_h})\rVert_{(\Lambda^{k, \gamma}_h)^{-1}}\\
        & \leq 2 \beta_1 \sum_{h=1}^H \sqrt{(K-K') \sum_{k=K'}^K \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} } +  \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{(K-K') \sum_{k=K'}^K \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} } 
    \end{aligned}
\end{equation}

By Assumption \ref{assumption:LinearMDP}, given that \(L\leq 1\) and \(\lambda = 1\) in Algorithm \ref{alg:SafeNonConvex}, it can be shown that \(\rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k,Q}_h)^{-1}}  \leq 1\), and \(\rVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h})\lVert_{(\Lambda^{k, \gamma}_h)^{-1}}  \leq 2\). Consequently, the following inequality holds:
\begin{equation}
\label{eq:midlevel_upper_bounded_lastmin_1}
    \begin{aligned}
    & \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k, Q}_h)^{-1}}  \leq 2 \log(1+ \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k}_h)^{-1}}),\\
    & \rVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}  \leq 2 \log\left(1+  \rVert \phi(s^k_h,a^k_h)- \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}\right)
    \end{aligned}
\end{equation}

Thus, by Equations(\ref{eq:Upperbound_Method_Abbasi_Yadolkari_1}) and (\ref{eq:midlevel_upper_bounded_lastmin_1}) we have:

\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_2}
    \begin{aligned}
        & 2 \beta_1 \sum_{h=1}^H \sqrt{(K-K') \sum_{k=K'}^K  \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k, Q}_h)^{-1}}}  +    \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{(K-K') \sum_{k=K'}^K \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} } 
        \\
        &\leq  2 \beta_1 \sum_{h=1}^H \sqrt{2 (K-K') \sum_{k=K'}^K  \log(1+\rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k}_h)^{-1}})} \\
        & \qquad+ \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{(K-K') \sum_{k=K'}^K \log\left(1+  \rVert \phi(s^k_h,a^k_h)- \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}\right)} 
        \\
        & = 2 \beta_1 \sum_{h=1}^H \sqrt{2 (K -K')  (\log(\det(\Lambda^{K,Q}_h)) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 (K -K')  (\log(\det(\Lambda^{K,\gamma}_h)) - \log(\lambda^d))}
    \end{aligned}
\end{equation}

where the last inequality is obtained by Lemma \(11\) from \cite{abbasi2011improved}. Now, considering that \(\lVert\phi(s^k_h, a^k_h)\rVert \leq L \), it follows that the trace of   \(\Lambda^{K,Q}_h \)is upper bounded by \( d\lambda + K L^2\), and the trace of   \(\Lambda^{K,\gamma}_h \)is upper bounded by \( d\lambda + 2 K  L^2\) . Since \(\Lambda^{K,Q}_h\) and \(\Lambda^{K,\lambda}_h\) are positive definite matrices, the determinant  of  them can be bounded as follows:
\begin{equation*}
    \begin{aligned}
        &det(\Lambda^{K,Q}_h) \leq (\frac{\text{trace}(\Lambda^{K,Q}_h)}{d})^d \leq (\frac{d\lambda+ (K) L^2 }{d})^d, \\
        &det(\Lambda^{K,\gamma}_h) \leq (\frac{\text{trace}(\Lambda^{K,\gamma}_h)}{d})^d \leq (\frac{d\lambda+ 2 (K) L^2 }{d})^d.
    \end{aligned}
\end{equation*}
Combining all together yields:

\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_3}
    \begin{aligned}
        &  2 \beta_1 \sum_{h=1}^H \sqrt{2 (K -K')  (\log(\det(\Lambda^{K,Q}_h)) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 (K -K')  (\log(\det(\Lambda^{K,\gamma}_h)) - \log(\lambda^d))} \\
        &\leq 2 \beta_1 \sum_{h=1}^H \sqrt{2 (K-K') (  \log((\frac{d\lambda+ K L^2 }{d})^d) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 (K-K') (  \log((\frac{d\lambda+ 2 K L^2 }{d})^d) - \log(\lambda^d))} \\
        & \leq 2 (\beta_1 + \frac{\beta_2 H}{\tau}) \sum_{h=1}^H \sqrt{2 (K-K')   d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}  = 2 (\beta_1 + \frac{\beta_2 H}{\tau})  H \sqrt{2 (K-K')  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}
    \end{aligned}
\end{equation}

Given that \(\lambda = 1\) and utilizing the Equations (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_1}) through 
 (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_3}), we conclude that:
 
\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_4}
    \begin{aligned}
        & 2 \beta_1  \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        & \qquad \leq  2 (\beta_1 + \frac{\beta_2 H}{\tau})  H \sqrt{2 (K-K')  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}
    \end{aligned}
\end{equation}

Now, by integrating the bounds from Eq.(\ref{eq:first_term_upper_bound_1_Final_1MinusTwoDelta}) and Eq. (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_4}), we establish the desired upper bound on \(\mathcal{T}_2\):

\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_5}
    \begin{aligned}
        &  \mathcal{T}_2 \leq   2 H \sqrt{ (K - K') H \, log(\frac{d (K-K') H}{\delta})}  +  2 (\beta_1 + \frac{\beta_2 H}{\tau})  H \sqrt{2 (K-K')  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))} 
    \end{aligned}
\end{equation}

\paragraph{Final step} Note that by Lemma \ref{Lemma:Optimism_Lemma_SafeRL_ICML_1}, we have \(\mathcal{T}_1 \leq 0\). Thus, by applying union bound  we will have the desired result as follows:

\begin{equation*}
    \begin{aligned}
         \text{Regret}(K) &\leq K' H +  \mathcal{T}_1 + \mathcal{T}_2 \leq K' H +   \mathcal{T}_2 \leq \\
         & K' H +   2 H \sqrt{(K-K') H \, log(\frac{d (K-K') H}{\delta})}  + 2 (\beta_1 H + \frac{\beta_2 H^2}{\tau})  \sqrt{2 (K-K')  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}.
    \end{aligned}
\end{equation*}

\paragraph{Safety} The safety of our method is guaranteed by Theorem~2 from \citet{abbasi2011improved}, as stated below:
\begin{lemma} (Theorem~2 in \cite{abbasi2011improved})
 Let \(\delta \in (0,\frac{1}{H})\). Then, with probability at least \(1- H \delta\), the chosen actions by Algorithm \ref{alg:SafeNonConvex} satisfy the safety constraints for all episodes. In other words, for all \((h,k) \in [H]\times[K]\),
\( 
\mathcal{A}^k_h(s) \subseteq \mathcal{A}^{\text{safe}}_h(s).
\)
\end{lemma}

\(\square\)


\subsection{Proof of Lemmas \ref{Lemma:PureExploration_1} and \ref{Lemma:SafesetAfter_PureExploration_1}}
\label{App:ProofOFLemmaPureExploreinLinearMDP}
\begin{definition}
    Let \(\lambda_{-} \triangleq \frac{d}{\epsilon^2}\).
\end{definition}
\paragraph{Proof of Lemma \ref{Lemma:PureExploration_1}:}
Our main strategy is to project the problem into \(\mathbb{R}^{d-1}\) (Recall that \(\mathcal{F}\)) is a \(d-1\) dimensional hyper plane and then we apply Lemma 1 from \cite{amani2019linear} to achieve the final result. 

\paragraph{Reltation of the higher dimensional problem to the lower dimensional space, i.e., \(\mathbb{R}^{d-1}\)}
Recall that in Algortihm \ref{alg:SafeNonConvex} the agent samples uniformly from the set of safe actions \(\mathcal{D}^{\epsilon}(s)\) that we rewrite its definition here for the convenience of the reader:

\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_1}
    \begin{aligned}
        & \mathcal{D}^{\epsilon}(s) \triangleq \{a \in \mathcal{A}\mid \lVert \phi(s,a) - \phi(s,a_s^0) \rVert = \epsilon \}.
    \end{aligned}
\end{equation}

According to Proposition \ref{Propisition:linearMDP_1}, by Assumption \ref{assumption:epsilon_origin_1}, we can define the image of the set \(\mathcal{D}^{\epsilon}(s) \) under the feature transformation \(\phi(s,.)\)as follows:

\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_2}
    \begin{aligned}
        & \phi \big(s,\mathcal{D}^{\epsilon}(s)\big) \triangleq \{ \phi(s,a^0_s) + \epsilon \times \sum_{i = 1}^{d-1} \alpha_i v_i \mid \sum_{i=1}^{d-1} \alpha_i^2, \,\, \alpha_i \in \mathbb{R} \},
    \end{aligned}
\end{equation}
where \(\{v_i\}_{i=1}^{d-1}\) are orthonormal vectors such that \( \mathcal{F}_s = \phi(s,a^0_s) + \text{Span}(\{v_i\}_{i=1}^{d-1})\) (Note that \(\{v_i\}_{i=1}^{d-1}\) are naturaly orthogonal to the vector \(\mu^*\) defined in Proposition \ref{Propisition:linearMDP_1}). Thus, random sampling from \(\mathcal{D}^{\epsilon}(s)\) is equivalent to  random sampling from the following set:

\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_3}
    \begin{aligned}
        & \mathcal{W} \triangleq \{ w \in \mathbb{R}^{d-1}\mid \lVert w \rVert_2 = \epsilon\}
    \end{aligned}
\end{equation}

\paragraph{Equivalency of the result in lower dimensional space}
Considering the Eq.(\ref{Eq:Intitial_Safe_RestrcitedHyperSphere_app_2}), we have: \(\phi(s^k_h,a^k_h) = \phi(s^k_h, a^0_{s^k_h}) +  \epsilon \times \sum_{i=1}^{d-1} \alpha_i^{k,h} v_i \), and  \(\phi(s,a) = \phi(s, a^0_{s}) +  \epsilon \times \sum_{i=1}^{d-1} \alpha_i^{s,a} v_i \). Now, considering the fact that \( \Lambda^{k, \gamma}_h \triangleq \sum_{\tau=1}^{k-1} (\phi(s_h^\tau, a_h^\tau) - \phi(s_h^\tau, a_{s_h}^0)) (\phi(s_h^\tau, a_h^\tau) -   \phi(s_h^\tau, a_{s_h}^0))^\top 
           + \lambda I\), we will have:

\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_4}
    \begin{aligned}
        & (\phi(s,a) - \phi(s,a^0_s))^\top \Lambda^{k, \gamma}_h (\phi(s,a) - \phi(s,a^0_s)) = 
        \\
        & \epsilon^2 \times (\sum_{i=1}^{d-1} \alpha_i^{s,a} v_i )^\top \left( \lambda I + \epsilon^2 \times \sum_{n = 1}^k  (\sum_{i=1}^{d-1} \alpha_i^{n,h} v_i) \, (\sum_{i=1}^{d-1} \alpha_i^{n,h} v_i)^\top \right) (\sum_{i=1}^{d-1} \alpha_i^{s,a} v_i ).
    \end{aligned}
\end{equation}
Now, since \(\{v_i\}_{i=1}^{d-1}\) are orthonormal, we can continue Eq.(\ref{Eq:Intitial_Safe_RestrcitedHyperSphere_app_4}) as follows:
\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_5}
    \begin{aligned}
        & (\phi(s,a) - \phi(s,a^0_s))^\top \Lambda^{k, \gamma}_h (\phi(s,a) - \phi(s,a^0_s))\alpha_i^{s,a} \, \alpha_i^{n,h})^2) = (w^{s,a})^\top \left(  \lambda I_{d-1} + \sum_{n=1}^k (w^n_h)\, (w^n_h)^\top\right) (w^{s,a}),
    \end{aligned}
\end{equation}
where in the last inequality, \(I_{d-1}\) is the identitiy matrix in \(\mathbb{R}^{d-1 \times d-1}\), and  \(w^{a,s} \in \mathbb{R}^{d-1}\), and the \(i\)-th element of it is \(w^{s,a}_i = \epsilon \alpha_i^{s,a}\), and simularly \(w^n_h \in \mathcal{W}\), and its \(i\)-th element is \(w^{n,h}_i = \epsilon \alpha_i^{n,h}\).

\paragraph{Applying Lemma 1 from \cite{amani2019linear}.}
Let \(\Lambda^k_{h, d-1} \triangleq   \lambda I_{d-1} + \sum_{n=1}^k (w^n_h)\, (w^n_h)^\top \), where \(w^n_h\) is picked randomly from \(\mathcal{W}\). Therefore, using Lemma 1 from \cite{amani2019linear} we have:

\[
(w^{s,a})^\top \Lambda^k_{h, d-1}  (w^{s,a}) \geq \left(  \lambda + \frac{\lambda_{-} k}{2} \right) \lVert w^{s,a} \rVert_2^2
\]
Thus, using Eq.(\ref{Eq:Intitial_Safe_RestrcitedHyperSphere_app_5}) we have:
\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_6_1}
    \begin{aligned}
        & (\phi(s,a) - \phi(s,a^0_s))^\top \Lambda^{k, \gamma}_h (\phi(s,a) - \phi(s,a^0_s))  \geq \left(  \lambda + \frac{\lambda_{-} k}{2} \right) \lVert w^{s,a} \rVert_2^2\\
        & =  \left(  \lambda + \frac{\lambda_{-} k}{2} \right) \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_2^2
    \end{aligned}
\end{equation}

\paragraph{Final Step.} Now, note that \(\Lambda^k_h\) is Positive Definite matrix. Also,  \(\mu^*\) (defined in Proposition \ref{Propisition:linearMDP_1}) is an an eigen vector of \(\Lambda^k_h\), and the rest of the eigen vector of \(\Lambda^k_h\) lies on the hyper-plane \(\mathcal{H}\). Thus, using Eq.(\ref{Eq:Intitial_Safe_RestrcitedHyperSphere_app_6_1}) we will have the following:
\begin{equation}
\label{Eq:Intitial_Safe_RestrcitedHyperSphere_app_6}
    \begin{aligned}
        & (\phi(s,a) - \phi(s,a^0_s))^\top  \left( \Lambda^{k, \gamma}_h \right)^{-1} (\phi(s,a) - \phi(s,a^0_s))  \leq \left(\frac{1}{\lambda + \frac{\lambda_{-} k}{2}} \right)  \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_2^2
    \end{aligned}
\end{equation}

\paragraph{Proof of Lemma \ref{Lemma:SafesetAfter_PureExploration_1}}:
Setting \(K' \geq   \max\{\frac{8 d}{\epsilon^2} \log(\frac{d H}{\delta}), \frac{2 d}{\epsilon^2} (\frac{16 \beta_2^2}{\iota^2} - \lambda)\}\), then by applying Lemma \ref{Lemma:PureExploration_1} we will have:

\begin{equation}
    \begin{aligned}
\beta_2 \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{(\Lambda_h^{k, \gamma})^{-1}}  \leq \frac{\iota}{4}
\end{aligned}
\end{equation}
Therefore, conditioned on the event \(\mathcal{E}\) we have:


\begin{equation}
    \begin{aligned}
&\langle \phi(s,a) - \phi(s,a^0_s), \gamma^k_h \rangle   +  \beta_2 \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{(\Lambda_h^{k, \gamma})^{-1}}  \leq \langle \phi(s,a) - \phi(s,a^0_s), \gamma^*_h \rangle   +  2 \beta_2 \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{(\Lambda_h^{k, \gamma})^{-1}} \\
& \leq \langle \phi(s,a) - \phi(s,a^0_s), \gamma^*_h \rangle   +  \frac{\iota}{2},
\end{aligned}
\end{equation}
where the last ineuqality implies that for all \(a \in \mathcal{A}^{\frac{\iota}{2}}_h(s)\), we will have: \(\langle \phi(s,a) - \phi(s,a^0_s), \gamma^k_h \rangle   +   \beta_2 \lVert \phi(s,a)  - \phi(s,a^0_s) \rVert_{(\Lambda_h^{k, \gamma})^{-1}}  \leq \tau
\), which implies that \(a\in \mathcal{A}^k_h(s)\). \(\square\)

\section{Proof of Theorem \ref{Theorem: upperbound_StarConvex_1}}
\label{App:ProofStepsOFStarConvexSafeRLICML_1}
Note that our main contribution in Star-Convex cases is bounding the covering number as provided in Lemma \ref{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1}. Once we have the result of Lemma \ref{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1}, we can apply the proof steps of Theorem 1 in \cite{amani2021safe} to obtain the desired result. However, for sake of completeness we provide the proof steps here as well.



\begin{lemma}
\label{Lemma:high_prob_events_E2_star_convex}
   Under the setup defined in Theorem \ref{Theorem: upperbound_1}, for all \(K \in [K]\), there exists a constant \(c_\beta>0\), such that for any fixed \(\delta \in (0,1)\), the event \( \mathcal{E}_2\) holds with probability at least \(1- \delta\).
\end{lemma}
\paragraph{Proof:}
 Similar to the proof steps of Lemma B.4. in \cite{jin2020provably} we will have:

 \begin{equation}
     \begin{aligned}
         & \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) = \langle \phi(s,a), w^k_h - w^\pi_h \rangle = \\
         & \underbrace{\langle \phi (s,a),- \lambda (\Lambda_h^k)^{-1} \mathbf{w}_h^\pi \rangle}_{q_1} 
         + \underbrace{ \langle \phi (s,a), (\Lambda_h^k)^{-1} \sum_{\tau=1}^{k-1} \phi_h^\tau \left[ V_{h+1}^k(s_{h+1}^\tau) - \mathbb{P}_h V_{h+1}^k(s_h^\tau, a_h^\tau) \right] \rangle}_{q_2}\\
         & \underbrace{\langle \phi (s,a), (\Lambda_h^k)^{-1} \sum_{\tau=1}^{k-1} \phi_h^\tau \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s_h^\tau, a_h^\tau) \rangle }_{q_3} .
     \end{aligned}
 \end{equation}
 
We start with bound ing \(|q_2|\), which is the term related to the covering number.
 \paragraph{Bounding \(|q_2|\)}
For our problem,we cannot directly utilize Lemma B.2 from \cite{jin2020provably} to bound \(|q_2|\), since in our case Value function is obtained by optimization over \(\mathcal{A}^k_h(s)\) instead of \(\mathcal{A}\), and \(\mathcal{A}^k_h(s)\) varies over the time. This makes bounding the covering number challenging. Thus, we first utilize Theorem D.4 from \cite{jin2020provably} to bound \(|q_2|\) in terms of the covering number of Value function in our problem, then, we apply Lemma \ref{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1} to get the counterpart result of Lemma B.2 from \cite{jin2020provably}.

We start by applying Lemma D.4 from \cite{jin2020provably} on \(|q_2|\), to get that  with the probability at least \(1-\frac{\delta}{2}\) we will have:
\begin{equation}
\label{Eq:bound_q2_PureExplore_1_s}
    \begin{aligned}
        & |q_2| \leq  \lVert \phi(s,a)  (\Lambda_h^k)^{-1} \rVert \,\,  \lVert  \sum_{\tau=1}^{k-1} \phi_h^\tau \left[ V_{h+1}^k(s_{h+1}^\tau) - \mathbb{P}_h V_{h+1}^k(s_h^\tau, a_h^\tau) \right] \rVert \\
        & \leq \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \,\, ( 4H^2 \left[ \frac{d}{2} \log \left( \frac{k + \lambda}{\lambda} \right) + \log \frac{2 \, \mathcal{N}_\kappa}{\delta} \right] + \frac{8k^2 \kappa^2}{\lambda}),
    \end{aligned}
\end{equation}

where, \(\mathcal{N}_\kappa\) is the cardinality of the set of pre-fixed functions \(\mathcal{V}_\kappa \subset \mathcal{V}\) defined in Lemma \ref{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1}. Now, considering the fact that Lemma B.2 from \cite{jin2020provably} implies that \(\lVert w^k_h\rVert \leq 2H \sqrt{\frac{dk}{\lambda}}\). Thus, using Lemma \ref{Lemma:BoundedCovering_PureExploraion_1_StarConvex_1} we can continue Eq.(\ref{Eq:bound_q2_PureExplore_1_s}) as follows:
\begin{equation}
\label{Eq:bound_q2_PureExplore_2_s}
    \begin{aligned}
        |q_2| &\leq  \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \,\, \Bigg(  4 H^2\bigg( \frac{d}{2} \log(\frac{k + \lambda}{\lambda}) +   d \Big[\log(1+ \frac{8H}{\kappa
        } \sqrt{\frac{dk}{ \lambda}}) + \log(1+\frac{8  ( (2 \sqrt{\frac{dk}{\lambda}} + 1) H + \frac{B}{\sqrt{\lambda}})}{\kappa  \tau})\Big] \\
        &+ d^2 \Big[\log (1+\frac{32 \sqrt{d} B^2}{\lambda \kappa^2}) + \log (1+\frac{32 \sqrt{d} B^2  (2 H \sqrt{\frac{dk}{\lambda}} + \frac{B}{\sqrt{\lambda}} + 3H)^2}{ \lambda \tau^2 \kappa^2})\Big]  + \log(\frac{2}{\delta}) \bigg) + \frac{8k^2 \kappa^2}{\lambda}  \Bigg)^{\frac{1}{2}}.
    \end{aligned}
\end{equation}

 Thus, by choosing \(\kappa = \frac{dH}{k}\), and setting \(B = \beta_1 = c_\beta d H \sqrt{\log(\frac{2dT}{\delta \tau})}\), and \(B' = \beta_2 = \mathbf{O}(\log(1+k H))\) we will have:

\begin{equation}
\label{Eq:bound_q2_PureExplore_3_s}
    \begin{aligned}
        |q_2| & \leq C   d H \log\left[2(c_{\beta} + 1)\frac{d KH}{\delta \tau}\right]  \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)},
    \end{aligned}
\end{equation}

where \(C\) is a constant.

 \paragraph{Bounding \(q_1\) and \(q_3\):}Similar to Lemma B.4 from \cite{jin2020provably} we can bound terms \(q_1\) and \(q_3\) as follows:
  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_withq2_1_s}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)|\\
         & \quad \leq  (2H \sqrt{d \lambda} + \sqrt{\lambda} \lVert w^\pi_h \rVert ) \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} + | q_2 |.
     \end{aligned}
 \end{equation}
 
 \paragraph{Final step}
  Combining Equations \ref{Eq:bound_q2_PureExplore_3_s} and \ref{Eq:bounding_CoveringNmber_PureExplore_withq2_1_s} yields the following:


  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_q_2Completed_1_s}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)|\\
         & \quad \leq  \bigg(2H \sqrt{d \lambda} + \sqrt{\lambda} \lVert w^\pi_h \rVert + C   d H \sqrt{\log \big(2(c_{\beta} + 1)\frac{d KH}{\delta \tau}} \big)  \bigg) \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)}
     \end{aligned}
 \end{equation}
Now, by Lemma B.1 from \cite{jin2020provably}, we have \(\lVert w^\pi_h \rVert \leq  2 H \sqrt{d}\). Therefore, there exists an absolute constant \(c_\beta\) such that the following holds:
  \begin{equation}
  \label{Eq:bounding_CoveringNmber_PureExplore_wholeExpression_1_s}
     \begin{aligned}
         & | \langle \phi (s,a), w^k_h \rangle - Q^\pi_h(s,a) - \mathbb{P}_h \left( V_{h+1}^k - V_{h+1}^\pi \right)(s, a)| \leq c_{\beta} \cdot d H \sqrt{\log(\frac{2 d T }{\delta \tau})}
         \sqrt{\phi(s, a)^\top (\Lambda_h^k)^{-1} \phi(s, a)} \qquad \square
     \end{aligned}
 \end{equation}


Our intersts lies in the events that both event \(\mathcal{E}_1\) and \(\mathcal{E}_2\) holds, i.e., the actual safe set and value function are approximed properly. Therefore, we provide the following important Lemma:
\begin{lemma}
\label{Lemma:high_prob_events_E1_E2_1_s}
   Under Assumption \ref{assumption:LinearMDP}, there exists a constant \(c_\beta>0\), such that for any fixed \(\delta \in (0,\frac{1}{3})\), the event \(\mathcal{E}:=\mathcal{E}_1 \cap \mathcal{E}_2\) holds with probability at least \(1-2 \delta\).
\end{lemma}
\paragraph{Proof:} 
Theorem 2 from \cite{abbasi2011improved} can be directly applied to our case to show that the event \(\mathcal{E}_1\) holds with a probability of at least \(1 - \delta\). Similarly, Lemma \ref{Lemma:high_prob_events_E2_star_convex} establishes that the event \(\mathcal{E}_2\) holds with a probability of at least \(1 - \delta\). By applying the union bound, the final result follows. \(\square\)

\subsection{Optimism in Star-Convex cases}
\label{sec:optimim_whole_s}
Here we prove that Algorithm \ref{alg:SafeNonConvex} satisfies the optimism property for the setting of Theorem \ref{Theorem: upperbound_StarConvex_1}, which is an essential step in the final proof of regret's upper upper bound. We first provide a helpful lemma in \ref{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_1_s}, then in \ref{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_2_s} we provide the  main proof.
\subsubsection{Helpful lemmas (star-convex)} 
\label{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_1_s}

\begin{lemma}
\label{Lemma:Utility_PureExploration_Optimism_Helpful_SafetyOfFeatures_1_s}
Consider the setting stated in Theorem \ref{Theorem: upperbound_StarConvex_1}. Then, there exists an action \(a' \in \mathcal{A}^k_h(s)\) such that \(\phi(s,a') =  \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\), for some \(\alpha \in [\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}}}, 1]\).
\end{lemma}


\paragraph{Proof:} Let \(\alpha = \frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}} } \). Then, conditioned on the event \(\mathcal{E}\), we can follow the below steps:


\begin{equation}
\label{Eq:SafetyOfmyChoice_For_Action_Step_1_s}
    \begin{aligned}
    &   0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} \\
    & = \alpha \big(\langle \phi(s,a^*_s) - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a^*_s) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} \big)\\
    &\leq 
    \alpha \big(\langle \phi(s,a^*_s) - \phi(s,a^0_s) , \gamma^*_h \rangle +  2\beta_2 \lVert \phi(s,a^*_s) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} \big) 
    \end{aligned}
\end{equation} 
where the last inequality is obtained by conditioning on the event \(\mathcal{E}_1 \subset \mathcal{E}\). Now, substituting \(\alpha\) with \(\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}} }\) in Eq.(\ref{Eq:SafetyOfmyChoice_For_Action_Step_1_s}) yields:


\begin{equation}
\label{Eq:SafetyOfmyChoice_For_Action_Step_2_s}
    \begin{aligned}
     & 0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} \\
        &  \leq  \frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}}} ( \langle \phi(s,a^*_{s,h}) - \phi(s,a^0_s), \gamma^*_h \rangle + 2\beta_2 \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}})
    \end{aligned}
\end{equation} 

  
Now, since \(a^*_{s,h}\) is the optimal safe solution, it should be feasible as well, i.e., \(\langle \phi(s,a^*_{s,h}), \gamma^*_h \rangle \leq \tau\). Thus, using Assumption~\ref{assumption:startingPoint_1}, we can continue Eq. (\ref{Eq:SafetyOfmyChoice_For_Action_Step_2_s}) as follows:
\begin{equation*}
    \begin{aligned}
           & 0 \leq \langle \phi(s,a') - \phi(s,a^0_s) , \gamma^k_h \rangle +  \beta_2 \lVert \phi(s,a) - \phi(s,a^0_s) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} \\
        & \quad \leq \frac{\tau}{\tau + 2 \beta_2 \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}}} ( \tau + 2 \beta_2 \lVert \phi(s,a^*_{s,h}) - \phi(s,a^0_s) \rVert_{(\Lambda^k_h)^{-1}}) \leq \tau
    \end{aligned}
\end{equation*} 
The last inequality implies that \(a'\in\mathcal{A}^k_h(s)\). This, completes the proof of this Lemma. \(\square\)






\subsubsection{ Main Proof of Optimism in Star-Convex cases}
\label{Appendix:helpful_Lemmas_Optimisitmc_PureExploration_localPoint_2_s}
\begin{lemma}
\label{Lemma:Optimism_nonConvex_1_s}
    (Optimism): Under the setting of Theorem \ref{Theorem: upperbound_StarConvex_1},  conditioned on the event \(\mathcal{E}\), the inequality \( V^{\pi^*}_h(s) \leq V^k_h(s), \,\,\, \forall (s,h) \in \mathcal{S} \times [H]\), and \(k \in [K]\) holds.
\end{lemma}

\paragraph{Proof:} We employ an induction strategy to establish this lemma. Initially, we define the value functions at time \(H+1\) as \(V^k_{H+1}(s) = V^{\pi^*}_{H+1}(s) = 0\) for any state \(s\in\mathcal{S}\), confirming the optimism for step \(H+1\). Then, by the induction hypothesis, we assume that for an arbitrary \(h\in [H]\), \(V^{\pi^*}_{h+1}(s) \leq V^k_{h+1}(s)\) holds for all states \(s\in \mathcal{S}\). We now need to prove that \(V^{\pi^*}_{h}(s) \leq V^k_{h}(s)\) also holds for all states \(s\in \mathcal{S}\). 


Consider the case where \( H \leq  \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h \rangle + b^k_h(s,a)\). Then, \(V^{\pi^*}_h(s) \leq H = \min\{\langle \phi(s,a), w^k_h \rangle + b^k_h(s,a), H\}  = V^k_h(s) \) holds, which completes the proof for this case.


It remains to prove the result for the case where \( \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h\rangle + b^k_h(s,a) \leq H\), which implies \(V^k_h(s) =  \max_{a \in \mathcal{A}^k_h(s)}  Q^k_h(s,a) =  \max_{a \in \mathcal{A}^k_h(s)} \langle \phi(s,a), w^k_h \rangle + b^k_h(s,a)\). 



By Lemma\ref{Lemma:Utility_PureExploration_Optimism_Helpful_SafetyOfFeatures_1_s}, there exists an action \(a'\in \mathcal{A}^k_h(s)\) such that \(\phi(s,a') = \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s,a^0_s)\) for some   \(\alpha \in [\frac{\tau}{\tau + 2 \beta_2  \lVert \phi(s,a^*_s) - \phi(s,a^0_s)\rVert_{(\Lambda^{k,\gamma}_h)^{-1}}}, 1]\). Thus we will have: 


\begin{equation}
\label{Eq:Optimism_PureExplore_DefValueFunction_1_s}
    \begin{aligned}
& V^k_h(s)  = \max_{a \in \mathcal{A}^k_h(s)} Q^k_h(s, a) \geq Q^k_h(s, a')  =  \langle \phi(s,a'), w^k_h\rangle + b^k_h(s, a'). \\
\end{aligned}
\end{equation}

Then, conditioned on the event \(\mathcal{E}_2\) we have:
\begin{equation}
\label{Eq:OptimismLemma_PureExploration_SubcaseTwo_Final_1_s}
    \begin{aligned}
        & \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \\
        &  \quad \geq  Q^{\pi^*}_h(s,a') +  E_{s^{'}\sim \mathbb{P}_h(.|s,a')}[V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] - \beta_1 \lVert \phi(s,a') \rVert_{(\Lambda^{k, Q}_h)^{-1}} + b^k_h(s, a').\\
        & \quad \geq Q^{\pi^*}_h(s,a') +  E_{s^{'}\sim \mathbb{P}_h(.|s,a')}[ V^k_{h+1}(s^{'}) - V^{\pi^*}_{h+1}(s^{'})] + g^k_h(s,a') \geq   Q^{\pi^*}_h(s,a') +  g^k_h(s,a')
    \end{aligned}
\end{equation}

, where in the last inequality we utilized the induction hypothesis that \(V^k_{h+1}(.) \geq  V^{\pi^*}_{h+1}(.)\). By considering the fact that \(\phi(s,a') = \alpha \phi(s,a^*_s) + (1-\alpha) \phi(s, a^0_s)\), we can continue Equation \ref{Eq:OptimismLemma_PureExploration_SubcaseTwo_Final_1_s} as follows:

\begin{equation}
\label{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_1_s}
    \begin{aligned}
        & V^k_h(s) \geq \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \geq \alpha   \langle \phi(s,a^*_s), w^{\pi^*}_h \rangle + (1-\alpha)   \langle \phi(s,a^0_s), w^{\pi^*}_h \rangle + g^k_h(s, a'),
    \end{aligned}
\end{equation}

  

Now, according to the Equation (\ref{eq:bonus_term_non_Convex_2}) we will have:
\begin{equation}
\label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId_s}
    \begin{aligned}
        & g^k_h(s,a') =  
 \nu \times \left(\beta_2  \|\phi(s,a') - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}} \right)  H  =  
 (\alpha \nu) \times  \left(\beta_2  \|\phi(s,a^*_s) - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}} \right)  H
    \end{aligned}
\end{equation}
Now, by setting 
\(\nu = \frac{2}{\tau}\),  we can continue Eq. (\ref{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_MId_s}) as follows:
\begin{equation}
\label{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_s}
    \begin{aligned}
        & g^k_h(s,a') =  
 \nu \times \left(1-\frac{\tau}{\tau + 2 \beta_2   \|\phi(s,a^*_s) - \phi(s,a^0_s)\|_{(\Lambda^{k, \gamma}_h)^{-1}}}\right) H \geq (1-\alpha) H 
    \end{aligned}
\end{equation}

 Now, combining Equations (\ref{Eq:Optimism_ICML_SAFE_RL_SubCase2_1_s}) and (\ref{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_1_s}), and considering the fact that \(0 \leq V^{\pi^*} \leq H\), we obtain the following:


\begin{equation}
\label{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_2_s}
    \begin{aligned}
        &  V^k_h(s) \geq \langle \phi(s,a'), w^k_h \rangle + b^k_h(s, a')  \geq \alpha   \langle \phi(s,a^*_s), w^{\pi^*}_h \rangle + (1-\alpha) H \geq V^{\pi^*}_h(s),
    \end{aligned}
\end{equation}
where in the second inequality we used the fact that when rewards are non-negative, then according to Proposition 2.3 from \cite{jin2020provably} we will have: \(0 \leq Q^{\pi^*}_h(s,a^0_s) = \langle \phi(s,a^0_s), w^{\pi^*}_h\rangle \). The Equation~(\ref{Eq:Optimims_SubCase2_ICML_SafeRL_Ineq_2_s}) completes the proof. \(\square\)

\subsection{Regret decomposition in Star-Convex cases}
\label{app:decompose_s}
\begin{lemma}
\label{Lemma: decompose_Bounding_T2_MiddleStep_ICMLSAFERL_1_s}
    Conditioned on the event \(\mathcal{E}\), the following inequality holds:

    \begin{equation}
        \begin{aligned}
        \label{eq:upperbound_first_result_T1_T2}
            &  \text{Regret}(K) \leq \sum_{k=1}^K \sum_{h=1}^H \zeta^k_h + 2\beta_1 \sum_{k=K'}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + \sum_{k=1}^K \sum_{h=1}^H (g^k_h(s^k_h, a^k_h)),
        \end{aligned}
    \end{equation}
    
     where \(\zeta^k_{h+1} := \mathbb{E}_{s^{'}\sim \mathbb{P}_h(.|s^k_h,a^k_h)}[V^k_{h+1}(s^{'}) - V^{\pi^k}_{h+1}(s^{'})] - \delta^k_{h+1}\) and \(\delta^k_{h+1} := V^k_h(s^k_h) - V^{\pi^k}_h(s^k_h)\).
\end{lemma}


\paragraph{Proof:}
First, we can decompose the regret as follows:

\begin{equation}
\label{eq:starConvex_ICMLSAFERL_1}
    \begin{aligned}
        &\text{Regret}(K) = \sum_{k=1}^K \bigl(V_0^{\pi^*}(s_0) - V_{0}^{\pi^k}(s_0)\bigr) =  \sum_{k=1}^K \bigl(V_0^{\pi^*}(s_0) - V_{0}^{k}(s_0)\bigr) 
        +\sum_{k=1}^K \bigl(V_0^{k}(s_0) - V_{0}^{\pi^k}(s_0)\bigr)\\
        & \leq \sum_{k=1}^K \bigl(V_0^{k}(s_0) - V_{0}^{\pi^k}(s_0)\bigr)
    \end{aligned}
\end{equation}
where, the last inequlity obtained by Lemma \ref{Lemma:Optimism_nonConvex_1_s}. Now, by the definition of \(V^k_h\) and \(Q^k_h\) we have: 

\begin{equation}
    \begin{aligned}
    \label{eq:upperbound_Proof_1_step_1_delta_zeta_0_s}
         \delta^k_{h+1} &= V^k_h(s^k_h) - V^{\pi^k}_h(s^k_h) = 
       \min\{Q^k_h(s^k_h,a^k_h), H\} - Q^{\pi^k}_h(s^k_h,a^k_h) \\
       &\leq  Q^k_h(s^k_h, a^k_h)
       -  Q^{\pi^k}_h(s^k_h,a^k_h)\\
       &  = \langle \phi(s^k_h,a^k_h), w^k_h \rangle + \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h) - Q^{\pi^k}_h(s^k_h,a^k_h). \\
    \end{aligned}
\end{equation}

Then, on the event \(\mathcal{E}\), we have:
\begin{equation}
    \begin{aligned}
    \label{eq:upperbound_Proof_1_step_1_delta_zeta_1_s}
 &  \langle \phi(s^k_h,a^k_h), w^k_h \rangle + \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h) - Q^{\pi^k}_h(s^k_h,a^k_h) \\
          &\leq  \mathbb{E}_{s^{'}\sim \mathbb{P}_h(.|s^k_h,a^k_h)}[V^k_{h+1}(s^{'}) - V^{\pi^k}_{h+1}(s^{'})]\\
         &= \delta^k_{h+1} + \zeta^k_{h+1} +  2 \beta_1 \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + g^k_h(s^k_h,a^k_h). 
    \end{aligned}
\end{equation}


Also, one can find that the following holds:
\begin{equation}
    \begin{aligned}
     \label{eq:upperbound_Proof_1_step_1_delta_zeta_2_s}
        & \sum_{k=1}^K V^{k}_1(s_1^k) - V^{\pi^k}_1(s_1^k) = \sum_{k=1}^K \delta^k_1.
    \end{aligned}
\end{equation}

Note that Lemma \ref{Lemma:Optimism_nonConvex_1_s} ensures that on the event \(\mathcal{E}\), \( 0\leq \delta^k_h\) holds. Consequently, by applying Equations (\ref{eq:starConvex_ICMLSAFERL_1}), (\ref{eq:upperbound_Proof_1_step_1_delta_zeta_1_s}) and (\ref{eq:upperbound_Proof_1_step_1_delta_zeta_2_s}),  we can conclude:

    \begin{equation}
         \begin{aligned}
             & \text{Regret}(K) \leq  \sum_{k=1}^K \sum_{h=1}^H \zeta^k_h +  2\beta_1 \sum_{k=1}^K  \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^k_h)^{-1}} + \sum_{k=1}^K  \sum_{h=1}^H  g^k_h(s^k_h, a^k_h). \qquad \square
         \end{aligned}
     \end{equation}





\subsection{Main Proof of Theorem \ref{Theorem: upperbound_StarConvex_1}}
\label{app:Proof_Theorem1_s}

\paragraph{Proof:}

Applying Lemma \ref{Lemma: decompose_Bounding_T2_MiddleStep_ICMLSAFERL_1_s} we will have:

\begin{equation}
\label{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1_s}
    \begin{aligned}
        & \text{Regret}(K) \leq \sum_{k=1}^K \sum_{h=1}^H \zeta^k_h + 2 \beta_1  \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}}
    \end{aligned}
\end{equation}


In order to bound the first term on the right hand side of Equation (\ref{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1_s}) note that \(\zeta^k_h\) forms a martingale difference sequence with a bounded norm, \(|\zeta^k_h| \leq H\). Thus, we  can apply Azuma-Hoeffding's inequality: 
\begin{equation}
\label{eq:first_term_upper_bound_1_Proof_Lemma-AzumaHoeffding_s}
    \begin{aligned}
        &  \mathbb{P}\Big(\sum_{k=1}^K \sum_{h=1}^H \zeta^k_h \leq 2 H \sqrt{(K) H \, log(\frac{d (K) H}{\delta})}\, \Big) \geq 1-\delta
    \end{aligned}
\end{equation}
Therefore, with a probability of at least \(1-\delta\) we have:
\begin{equation}
\label{eq:first_term_upper_bound_1_Final_1MinusTwoDelta_s}
    \begin{aligned}
        & \sum_{k=1}^K \sum_{h=1}^H \zeta^k_h 
        & \leq 2 H \sqrt{(K) H \, log(\frac{d (K) H}{\delta})} 
    \end{aligned}
\end{equation}


Now, to bound the rest of  the right hand side of Equation(\ref{Eq:Proof_ICML_SafeRL_Upper_LocalPoint_1_T2_1_s}) we can Follow the steps outlined in the proof of Theorem 3 in \cite{abbasi2011improved}, as follows:
\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_1_s}
    \begin{aligned}
       & 2 \beta_1  \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h)  - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        &= 2 \beta_1  \sum_{h=1}^H \sum_{k=1}^K \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{h=1}^H \sum_{k=1}^K \lVert \phi(s^k_h,a^k_h)  - \phi(s^k_h, a^0_{s^k_h})\rVert_{(\Lambda^{k, \gamma}_h)^{-1}}\\
        & \leq 2 \beta_1 \sum_{h=1}^H \sqrt{K \sum_{k=1}^K \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} } +  \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{K \sum_{k=1}^K \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} } 
    \end{aligned}
\end{equation}

By Assumption \ref{assumption:LinearMDP}, given that \(L\leq 1\) and \(\lambda = 1\) in Algorithm \ref{alg:SafeNonConvex}, it can be shown that \(\rVert \phi(s^k_h,a^k_h)\lVert_{(\Lambda^{k,Q}_h)^{-1}}  \leq 1\), and \(\rVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h})\lVert_{(\Lambda^{k, \gamma}_h)^{-1}}  \leq 2\). Consequently, the following inequality holds:


\begin{equation}
\label{eq:midlevel_upper_bounded_lastmin_1_s}
    \begin{aligned}
    & \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k, Q}_h)^{-1}}  \leq 2 \log(1+ \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k}_h)^{-1}}),\\
    & \rVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}  \leq 2 \log\left(1+  \rVert \phi(s^k_h,a^k_h)- \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}\right)
    \end{aligned}
\end{equation}




Thus, by Equations~(\ref{eq:Upperbound_Method_Abbasi_Yadolkari_1_s}) and (\ref{eq:midlevel_upper_bounded_lastmin_1_s}) we have:

\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_2_s}
    \begin{aligned}
        & 2 \beta_1 \sum_{h=1}^H \sqrt{K \sum_{k=1}^K  \rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k, Q}_h)^{-1}}}  +    \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{K \sum_{k=1}^K \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k,\gamma}_h)^{-1}} } 
        \\
        &\leq  2 \beta_1 \sum_{h=1}^H \sqrt{2 K \sum_{k=1}^K  \log(1+\rVert \phi(s^k_h,a^k_h)\lVert^2_{(\Lambda^{k}_h)^{-1}})} \\
        & \qquad+ \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{K \sum_{k=1}^K \log\left(1+  \rVert \phi(s^k_h,a^k_h)- \phi(s^k_h, a^0_{s^k_h})\lVert^2_{(\Lambda^{k, \gamma}_h)^{-1}}\right)} 
        \\
        & = 2 \beta_1 \sum_{h=1}^H \sqrt{2 K   (\log(\det(\Lambda^{K,Q}_h)) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 K   (\log(\det(\Lambda^{K,\gamma}_h)) - \log(\lambda^d))}
    \end{aligned}
\end{equation}

where the last inequality is obtained by Lemma \(11\) from \cite{abbasi2011improved}. Now, considering that \(\lVert\phi(s^k_h, a^k_h)\rVert \leq L \), it follows that the trace of   \(\Lambda^{K,Q}_h \) is upper bounded by \( d\lambda + K L^2\), and the trace of \(\lambda^{k,\gamma}_h\) is upper bounded by  \( d\lambda + 2 K L^2\) . Since \(\Lambda^{K,Q}_h\) and \(\Lambda^{K,\gamma}\) are  positive definite matrices, the determinant  of  \(\Lambda^{k,Q}_h\) and \(\Lambda^{k,\gamma}_h\) can be bounded by:
\begin{equation*}
    \begin{aligned}
        &det(\Lambda^{K,Q}_h) \leq (\frac{\text{trace}(\Lambda^{K,Q}_h)}{d})^d \leq (\frac{d\lambda+ (K) L^2 }{d})^d, \\
        &det(\Lambda^{K,\gamma}_h) \leq (\frac{\text{trace}(\Lambda^{K,\gamma}_h)}{d})^d \leq (\frac{d\lambda+ 2 (K) L^2 }{d})^d,
    \end{aligned}
\end{equation*}
 Combining all together yields:

\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_3_s}
    \begin{aligned}
        &  2 \beta_1 \sum_{h=1}^H \sqrt{2 K   (\log(\det(\Lambda^{K,Q}_h)) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 K  (\log(\det(\Lambda^{K,\gamma}_h)) - \log(\lambda^d))} \\
        &\leq 2 \beta_1 \sum_{h=1}^H \sqrt{2 K (  \log((\frac{d\lambda+ K L^2 }{d})^d) - \log(\lambda^d))} + \frac{2 \beta_2 H}{\tau} \sum_{h=1}^H \sqrt{2 K (  \log((\frac{d\lambda+ 2 K L^2 }{d})^d) - \log(\lambda^d))} \\
        & \leq 2 (\beta_1 + \frac{\beta_2 H}{\tau}) \sum_{h=1}^H \sqrt{2 K   d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}  = 2 (\beta_1 + \frac{\beta_2 H}{\tau})  H \sqrt{2 K  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}
    \end{aligned}
\end{equation}

Given that \(\lambda = 1\) and utilizing the Equations (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_1_s}) through 
 (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_3_s}), we conclude that:
 
\begin{equation}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_4_s}
    \begin{aligned}
        & 2 \beta_1  \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) \rVert_{(\Lambda^{k,Q}_h)^{-1}} + (\frac{ 2 \beta_2   H}{ \tau} \big) \sum_{k=1}^K \sum_{h=1}^H \lVert \phi(s^k_h,a^k_h) - \phi(s^k_h, a^0_{s^k_h}) \rVert_{(\Lambda^{k, \gamma}_h)^{-1}} \\
        & \qquad \leq  2 (\beta_1 + \frac{\beta_2 H}{\tau})  H \sqrt{2 K  d\log((\frac{d\lambda+ 2 K L^2 }{\lambda d}))}
    \end{aligned}
\end{equation}

Now, by integrating the bounds from Eq.(\ref{eq:first_term_upper_bound_1_Final_1MinusTwoDelta_s}) and Eq. (\ref{eq:Upperbound_Method_Abbasi_Yadolkari_4_s}), we establish the desired upper bound on \(\mathcal{T}_2\):

\begin{equation*}
\label{eq:Upperbound_Method_Abbasi_Yadolkari_5_s}
    \begin{aligned}
        &  \text{Regret}(K) \leq   2 H \sqrt{ (K) H \, log(\frac{d (K) H}{\delta})}  + (2 \beta_1 + \frac{2 \beta_2  H}{ \tau}) H \sqrt{2 K  d\log\Big((\frac{d\lambda+ 2 K L^2 }{\lambda d})\Big)} 
    \end{aligned}
\end{equation*}

\paragraph{Safety} The safety of our method is guaranteed by Theorem~2 from \citet{abbasi2011improved}, as stated below:
\begin{lemma} (Theorem~2 in \cite{abbasi2011improved})
 Let \(\delta \in (0,\frac{1}{H})\). Then, with probability at least \(1- H \delta\), the chosen actions by Algorithm \ref{alg:SafeNonConvex} satisfy the safety constraints for all episodes. In other words, for all \((h,k) \in [H]\times[K]\),
\( 
\mathcal{A}^k_h(s) \subseteq \mathcal{A}^{\text{safe}}_h(s).
\)
\end{lemma}

\(\square\)


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
