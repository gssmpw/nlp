@article{Bu2022OptimizedPI,
  title={Optimized Potential Initialization for Low-latency Spiking Neural Networks},
  author={Tong Bu and Jianhao Ding and Zhaofei Yu and Tiejun Huang},
  journal={ArXiv},
  year={2022},
  volume={abs/2202.01440},
  url={https://api.semanticscholar.org/CorpusID:246485745}
}

@article{Diehl2015FastclassifyingHS,
  title={Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing},
  author={Peter Udo Diehl and Daniel Neil and Jonathan Binas and Matthew Cook and Shih-Chii Liu and Michael Pfeiffer},
  journal={2015 International Joint Conference on Neural Networks (IJCNN)},
  year={2015},
  pages={1-8},
  url={https://api.semanticscholar.org/CorpusID:2676182}
}

@article{Hao2023BridgingTG,
  title={Bridging the Gap between ANNs and SNNs by Calibrating Offset Spikes},
  author={Zecheng Hao and Jianhao Ding and Tong Bu and Tiejun Huang and Zhaofei Yu},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.10685},
  url={https://api.semanticscholar.org/CorpusID:257050386}
}

@inproceedings{Lv2023SpikingCN,
  title={Spiking Convolutional Neural Networks for Text Classification},
  author={Changze Lv and Jianhan Xu and Xiaoqing Zheng},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://api.semanticscholar.org/CorpusID:259298612}
}

@article{Sengupta2018GoingDI,
  title={Going Deeper in Spiking Neural Networks: VGG and Residual Architectures},
  author={Abhronil Sengupta and Yuting Ye and Robert Y. Wang and Chiao Liu and Kaushik Roy},
  journal={Frontiers in Neuroscience},
  year={2018},
  volume={13},
  url={https://api.semanticscholar.org/CorpusID:3643293}
}

@inproceedings{bal2024spikingbert,
  title={Spikingbert: Distilling bert to train spiking language models using implicit differentiation},
  author={Bal, Malyaban and Sengupta, Abhronil},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={38},
  pages={10998--11006},
  year={2024}
}

@article{cao2015spiking,
  title={Spiking deep convolutional neural networks for energy-efficient object recognition},
  author={Cao, Yongqiang and Chen, Yang and Khosla, Deepak},
  journal={International Journal of Computer Vision},
  volume={113},
  pages={54--66},
  year={2015},
  publisher={Springer}
}

@inproceedings{diehl2016conversion,
  title={Conversion of artificial recurrent neural networks to spiking neural networks for low-power neuromorphic hardware},
  author={Diehl, Peter U and Zarrella, Guido and Cassidy, Andrew and Pedroni, Bruno U and Neftci, Emre},
  booktitle={2016 IEEE International Conference on Rebooting Computing (ICRC)},
  pages={1--8},
  year={2016},
  organization={IEEE}
}

@inproceedings{han2020deep,
  title={Deep spiking neural network: Energy efficiency through time based coding},
  author={Han, Bing and Roy, Kaushik},
  booktitle={European conference on computer vision},
  pages={388--404},
  year={2020},
  organization={Springer}
}

@inproceedings{hao2023reducing,
  title={Reducing ann-snn conversion error through residual membrane potential},
  author={Hao, Zecheng and Bu, Tong and Ding, Jianhao and Huang, Tiejun and Yu, Zhaofei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={11--21},
  year={2023}
}

@article{li2024error,
  title={Error-Aware Conversion from ANN to SNN via Post-training Parameter Calibration},
  author={Li, Yuhang and Deng, Shikuang and Dong, Xin and Gu, Shi},
  journal={International Journal of Computer Vision},
  pages={1--24},
  year={2024},
  publisher={Springer}
}

@misc{lv2024spikebertlanguagespikformerlearned,
      title={SpikeBERT: A Language Spikformer Learned from BERT with Knowledge Distillation}, 
      author={Changze Lv and Tianlong Li and Jianhan Xu and Chenxi Gu and Zixuan Ling and Cenyuan Zhang and Xiaoqing Zheng and Xuanjing Huang},
      year={2024},
      eprint={2308.15122},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.15122}, 
}

@article{rueckauer2016theory,
  title={Theory and tools for the conversion of analog to spiking convolutional neural networks},
  author={Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael},
  journal={arXiv preprint arXiv:1612.04052},
  year={2016}
}

@article{xiao2022towards,
  title={Towards energy-preserving natural language understanding with spiking neural networks},
  author={Xiao, Rong and Wan, Yu and Yang, Baosong and Zhang, Haibo and Tang, Huajin and Wong, Derek F and Chen, Boxing},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={31},
  pages={439--447},
  year={2022},
  publisher={IEEE}
}

@article{xing2024spikelm,
  title={SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms},
  author={Xing, Xingrun and Zhang, Zheng and Ni, Ziyi and Xiao, Shitao and Ju, Yiming and Fan, Siqi and Wang, Yequan and Zhang, Jiajun and Li, Guoqi},
  journal={arXiv preprint arXiv:2406.03287},
  year={2024}
}

@article{yang2022training,
  title={Training spiking neural networks with local tandem learning},
  author={Yang, Qu and Wu, Jibin and Zhang, Malu and Chua, Yansong and Wang, Xinchao and Li, Haizhou},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12662--12676},
  year={2022}
}

@article{zhu2023spikegpt,
  title={Spikegpt: Generative pre-trained language model with spiking neural networks},
  author={Zhu, Rui-Jie and Zhao, Qihang and Li, Guoqi and Eshraghian, Jason K},
  journal={arXiv preprint arXiv:2302.13939},
  year={2023}
}

