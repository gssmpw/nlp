@article{baras2023quantattack,
  title={QuantAttack: Exploiting Dynamic Quantization to Attack Vision Transformers},
  author={Baras, Amit and Zolfi, Alon and Elovici, Yuval and Shabtai, Asaf},
  journal={arXiv preprint arXiv:2312.02220},
  year={2023}
}

@inproceedings{biswas2022geometric,
  title={Geometric Analysis and Metric Learning of Instruction Embeddings},
  author={Biswas, Sajib and Barao, Timothy and Lazzari, John and McCoy, Jeret and Liu, Xiuwen and Kostandarithes, Alexander},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}

@inproceedings{carlini2017adversarialexampleseasilydetected,
author = {Carlini, Nicholas and Wagner, David},
title = {Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
year = {2017},
isbn = {9781450352024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3128572.3140444},
doi = {10.1145/3128572.3140444},
abstract = {Neural networks are known to be vulnerable to adversarial examples: inputs that are close to natural inputs but classified incorrectly. In order to better understand the space of adversarial examples, we survey ten recent proposals that are designed for detection and compare their efficacy. We show that all can be defeated by constructing new loss functions. We conclude that adversarial examples are significantly harder to detect than previously appreciated, and the properties believed to be intrinsic to adversarial examples are in fact not. Finally, we propose several simple guidelines for evaluating future proposed defenses.},
booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
pages = {3â€“14},
numpages = {12},
location = {Dallas, Texas, USA},
series = {AISec '17}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  year={2017},
  organization={Ieee}
}

@article{chacko2024adversarial,
  title={Adversarial Attacks on Large Language Models Using Regularized Relaxation},
  author={Chacko, Samuel Jacob and Biswas, Sajib and Islam, Chashi Mahiul and Liza, Fatema Tabassum and Liu, Xiuwen},
  journal={arXiv preprint arXiv:2410.19160},
  year={2024}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={international conference on machine learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{dong2018speech,
  title={Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition},
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5884--5888},
  year={2018},
  organization={IEEE}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{fu2022patch,
  title={Patch-fool: Are vision transformers always robust against adversarial perturbations?},
  author={Fu, Yonggan and Zhang, Shunyao and Wu, Shang and Wan, Cheng and Lin, Yingyan},
  journal={arXiv preprint arXiv:2203.08392},
  year={2022}
}

@inproceedings{gong2024random,
  title={Random Entangled Tokens for Adversarially Robust Vision Transformer},
  author={Gong, Huihui and Dong, Minjing and Ma, Siqi and Camtepe, Seyit and Nepal, Surya and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24554--24563},
  year={2024}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{islam2024malicious,
  title={Malicious path manipulations via exploitation of representation vulnerabilities of vision-language navigation systems},
  author={Islam, Chashi Mahiul and Salman, Shaeke and Shams, Montasir and Liu, Xiuwen and Kumar, Piyush},
  journal={arXiv preprint arXiv:2407.07392},
  year={2024}
}

@inproceedings{kim2024exploring,
  title={Exploring Adversarial Robustness of Vision Transformers in the Spectral Perspective},
  author={Kim, Gihyun and Kim, Juyeop and Lee, Jong-Seok},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3976--3985},
  year={2024}
}

@incollection{kurakin2018adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
  booktitle={Artificial intelligence safety and security},
  pages={99--112},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@inproceedings{li2023trade,
  title={Trade-off between robustness and accuracy of vision transformers},
  author={Li, Yanxi and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7558--7568},
  year={2023}
}

@inproceedings{li2024harnessing,
  title={Harnessing Edge Information for Improved Robustness in Vision Transformers},
  author={Li, Yanxi and Du, Chengbin and Xu, Chang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  pages={3252--3260},
  year={2024}
}

@article{liu2023context,
  title={In-context vectors: Making in context learning more effective and controllable through latent space steering},
  author={Liu, Sheng and Xing, Lei and Zou, James},
  journal={arXiv preprint arXiv:2311.06668},
  year={2023}
}

@inproceedings{liu2023understanding,
  title={Understanding and defending patched-based adversarial attacks for vision transformer},
  author={Liu, Liang and Guo, Yanan and Zhang, Youtao and Yang, Jun},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={21631--21657},
  year={2023}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@article{mo2022adversarial,
  title={When adversarial training meets vision transformers: Recipes from training to architecture},
  author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={18599--18611},
  year={2022}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{papernot2016limitations,
  title={The limitations of deep learning in adversarial settings},
  author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
  booktitle={2016 IEEE European symposium on security and privacy (EuroS\&P)},
  pages={372--387},
  year={2016},
  organization={IEEE}
}

@inproceedings{papernot2016transferability,
  title={Transferability in Machine Learning: From Phenomena to Black-Box Attacks Using Adversarial Samples},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian J.},
  booktitle={IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={123--138},
  year={2016},
  publisher={IEEE}
}

@article{raghu2021vision,
  title={Do vision transformers see like convolutional neural networks?},
  author={Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12116--12128},
  year={2021}
}

@article{rando2022exploring,
  title={Exploring adversarial attacks and defenses in vision transformers trained with DINO},
  author={Rando, Javier and Naimi, Nasib and Baumann, Thomas and Mathys, Max},
  journal={arXiv preprint arXiv:2206.06761},
  year={2022}
}

@article{salman2024intriguing,
  title={Intriguing Equivalence Structures of the Embedding Space of Vision Transformers},
  author={Salman, Shaeke and Shams, Md Montasir Bin and Liu, Xiuwen},
  journal={arXiv preprint arXiv:2401.15568},
  year={2024}
}

@article{shao2021adversarial,
  title={On the adversarial robustness of vision transformers},
  author={Shao, Rulin and Shi, Zhouxing and Yi, Jinfeng and Chen, Pin-Yu and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2103.15670},
  year={2021}
}

@article{turner2023activation,
  title={Activation addition: Steering language models without optimization},
  author={Turner, Alex and Thiergart, Lisa and Udell, David and Leech, Gavin and Mini, Ulisse and MacDiarmid, Monte},
  journal={arXiv preprint arXiv:2308.10248},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{vilas2024analyzing,
  title={Analyzing Vision Transformers for image classification in class embedding space},
  author={Vilas, Martina G and Schauml{\"o}ffel, Timothy and Roig, Gemma},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{wallace2019universal,
  title={Universal adversarial triggers for attacking and analyzing NLP},
  author={Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  journal={arXiv preprint arXiv:1908.07125},
  year={2019}
}

@inproceedings{wang2022understanding,
  title={Understanding adversarial robustness of vision transformers via cauchy problem},
  author={Wang, Zheng and Ruan, Wenjie},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={562--577},
  year={2022},
  organization={Springer}
}

@article{wang2024dual,
  title={Dual stage black-box adversarial attack against vision transformer},
  author={Wang, Fan and Shao, Mingwen and Meng, Lingzhuang and Liu, Fukang},
  journal={International Journal of Machine Learning and Cybernetics},
  pages={1--12},
  year={2024},
  publisher={Springer}
}

@inproceedings{wei2022towards,
  title={Towards transferable adversarial attacks on vision transformers},
  author={Wei, Zhipeng and Chen, Jingjing and Goldblum, Micah and Wu, Zuxuan and Goldstein, Tom and Jiang, Yu-Gang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={3},
  pages={2668--2676},
  year={2022}
}

@article{wei2024assessing,
  title={Assessing the brittleness of safety alignment via pruning and low-rank modifications},
  author={Wei, Boyi and Huang, Kaixuan and Huang, Yangsibo and Xie, Tinghao and Qi, Xiangyu and Xia, Mengzhou and Mittal, Prateek and Wang, Mengdi and Henderson, Peter},
  journal={arXiv preprint arXiv:2402.05162},
  year={2024}
}

@inproceedings{xiang2021patchguard,
  title={$\{$PatchGuard$\}$: A provably robust defense against adversarial patches via small receptive fields and masking},
  author={Xiang, Chong and Bhagoji, Arjun Nitin and Sehwag, Vikash and Mittal, Prateek},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2237--2254},
  year={2021}
}

@inproceedings{zhang2023transferable,
  title={Transferable adversarial attacks on vision transformers with token gradient regularization},
  author={Zhang, Jianping and Huang, Yizhan and Wu, Weibin and Lyu, Michael R},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16415--16424},
  year={2023}
}

@article{zhang2024towards,
  title={Towards General Conceptual Model Editing via Adversarial Representation Engineering},
  author={Zhang, Yihao and Wei, Zeming and Sun, Jun and Sun, Meng},
  journal={arXiv preprint arXiv:2404.13752},
  year={2024}
}

@article{zou2023representation,
  title={Representation engineering: A top-down approach to ai transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

