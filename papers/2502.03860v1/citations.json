[
  {
    "index": 0,
    "papers": [
      {
        "key": "jaech2024openai",
        "author": "Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others",
        "title": "Openai o1 system card"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "dutta2024think",
        "author": "Dutta, Subhabrata and Singh, Joykirat and Chakrabarti, Soumen and Chakraborty, Tanmoy",
        "title": "How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "kahneman2011thinking",
        "author": "Kahneman, Daniel",
        "title": "Thinking, Fast and Slow"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ackoff1994systems",
        "author": "Ackoff, Russell L",
        "title": "Systems thinking and thinking systems"
      },
      {
        "key": "kahneman2011thinking",
        "author": "Kahneman, Daniel",
        "title": "Thinking, Fast and Slow"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "min2024imitate",
        "author": "Min, Yingqian and Chen, Zhipeng and Jiang, Jinhao and Chen, Jie and Deng, Jia and Hu, Yiwen and Tang, Yiru and Wang, Jiapeng and Cheng, Xiaoxue and Song, Huatong and others",
        "title": "Imitate, explore, and self-improve: A reproduction report on slow-thinking reasoning systems"
      },
      {
        "key": "huang2024o1",
        "author": "Huang, Zhen and Zou, Haoyang and Li, Xuefeng and Liu, Yixiu and Zheng, Yuxiang and Chern, Ethan and Xia, Shijie and Qin, Yiwei and Yuan, Weizhe and Liu, Pengfei",
        "title": "O1 Replication Journey--Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "guo2025deepseek",
        "author": "Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others",
        "title": "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "schulman2017ppo",
        "author": "John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov",
        "title": "Proximal Policy Optimization Algorithms"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zelikman2022star",
        "author": "Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah",
        "title": "Star: Bootstrapping reasoning with reasoning"
      },
      {
        "key": "dong2023raft",
        "author": "Hanze Dong and Wei Xiong and Deepanshu Goyal and Yihan Zhang and Winnie Chow and Rui Pan and Shizhe Diao and Jipeng Zhang and KaShun SHUM and Tong Zhang",
        "title": "{RAFT}: Reward rAnked FineTuning for Generative Foundation Model Alignment"
      },
      {
        "key": "gulcehre2023reinforced",
        "author": "Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others",
        "title": "Reinforced self-training (rest) for language modeling"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "rafailov2023direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      },
      {
        "key": "munos2023nash",
        "author": "Munos, R{\\'e}mi and Valko, Michal and Calandriello, Daniele and Azar, Mohammad Gheshlaghi and Rowland, Mark and Guo, Zhaohan Daniel and Tang, Yunhao and Geist, Matthieu and Mesnard, Thomas and Michi, Andrea and others",
        "title": "Nash Learning from Human Feedback"
      },
      {
        "key": "ethayarajh2024kto",
        "author": "Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe",
        "title": "Kto: Model alignment as prospect theoretic optimization"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "ahmadian2024back",
        "author": "Arash Ahmadian and Chris Cremer and Matthias Gall\u00e9 and Marzieh Fadaee and Julia Kreutzer and Olivier Pietquin and Ahmet \u00dcst\u00fcn and Sara Hooker",
        "title": "Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs"
      },
      {
        "key": "li2023remax",
        "author": "Li, Ziniu and Xu, Tian and Zhang, Yushun and Yu, Yang and Sun, Ruoyu and Luo, Zhi-Quan",
        "title": "ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models"
      },
      {
        "key": "ahmadian2024back",
        "author": "Arash Ahmadian and Chris Cremer and Matthias Gall\u00e9 and Marzieh Fadaee and Julia Kreutzer and Olivier Pietquin and Ahmet \u00dcst\u00fcn and Sara Hooker",
        "title": "Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs"
      },
      {
        "key": "shao2024deepseekmath",
        "author": "Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Yu and Guo, Daya",
        "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "xu2023some",
        "author": "Xu, Jing and Lee, Andrew and Sukhbaatar, Sainbayar and Weston, Jason",
        "title": "Some things are more cringe than others: Preference optimization with the pairwise cringe loss"
      },
      {
        "key": "snorkelai@pair",
        "author": "Hoang Tran, Chris Glaze, Braden Hancock",
        "title": "Snorkel-Mistral-PairRM-DPO"
      },
      {
        "key": "xiong2023iterative",
        "author": "Xiong, Wei and Dong, Hanze and Ye, Chenlu and Wang, Ziqi and Zhong, Han and Ji, Heng and Jiang, Nan and Zhang, Tong",
        "title": "Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-constraint"
      },
      {
        "key": "yuan2024self",
        "author": "Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason",
        "title": "Self-Rewarding Language Models"
      },
      {
        "key": "dong2024rlhf",
        "author": "Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong",
        "title": "Rlhf workflow: From reward modeling to online rlhf"
      },
      {
        "key": "guo2024direct",
        "author": "Guo, Shangmin and Zhang, Biao and Liu, Tianlin and Liu, Tianqi and Khalman, Misha and Llinares, Felipe and Rame, Alexandre and Mesnard, Thomas and Zhao, Yao and Piot, Bilal and others",
        "title": "Direct language model alignment from online ai feedback"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wei2022chain",
        "author": "Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed H. Chi and Quoc V. Le and Denny Zhou",
        "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wang2022self",
        "author": "Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed H and Zhou, Denny",
        "title": "Self-consistency improves chain of thought reasoning in language models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "madaan2023selfrefineiterativerefinementselffeedback",
        "author": "Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      }
    ]
  }
]