% CVPR 2024 Paper Template; see https://github.com/cvpr-org/author-kit

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}              % To produce the CAMERA-READY version
% \usepackage[review]{cvpr}      % To produce the REVIEW version
% \usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version
\usepackage{dsfont}
\usepackage{graphicx} 
\usepackage{float}
% Import additional packages in the preamble file, before hyperref
\input{preamble}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, 
% e.g. with the file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete *.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you should be clear).
\definecolor{cvprblue}{rgb}{0.21,0.49,0.74}
\newcommand{\ptitle}[1]{\noindent\textbf{#1}\hspace{5pt}}
\newcommand{\qy}[1]{\textcolor{black}{#1}}
\usepackage[pagebackref,breaklinks,colorlinks,allcolors=cvprblue]{hyperref}
\newcommand{\indep}{\perp\!\!\!\perp}
\newtheorem{theorem}{\bf Theorem}
\newtheorem{proof}{\bf Proof}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\paperID{3144} % *** Enter the Paper ID here
\def\confName{CVPR}
\def\confYear{2025}

%%%%%%%%% TITLE - PLEASE UPDATE
% \title{Progressive Correspondence Regenerator: Robust 3D Registration with More Inliers
% under Extreme Outlier Ratios}

\title{Progressive Correspondence Regenerator for Robust 3D Registration}

% \title{Progressive Correspondence Regenerator: Robust 3D Registration with Limited Initial Inliers}

%%%%%%%% AUTHORS - PLEASE UPDATE
\author{Guiyu Zhao\textsuperscript{1$\ast$}, 
    Sheng Ao\textsuperscript{2}\thanks{Equal contribution} ,
    Ye Zhang\textsuperscript{2},
    Kai Xu\textsuperscript{3}
    Yulan Guo\textsuperscript{2$\dagger$}
    \\
    \textsuperscript{1}Beijing Institute of Technology 
    \textsuperscript{2}Sun Yat-sen University 
    \textsuperscript{3}National University of Defense Technology
}
% \author{First Author\\
% Institution1\\
% Institution1 address\\
% {\tt\small firstauthor@i1.org}
% % For a paper whose authors are all at the same institution,
% % omit the following lines up until the closing ``}''.
% % Additional authors and addresses can be added with ``\and'',
% % just like the second author.
% % To save space, use either the email address or home page, not both
% \and
% Second Author\\
% Institution2\\
% First line of institution2 address\\
% {\tt\small secondauthor@i2.org}
% }


\begin{document}
\maketitle

\begin{abstract}
    % Obtaining enough high-quality correspondences 
    % is crucial for robust registration. Current correspondences refinement methods mostly rely on
    % outlier removal.
    % These methods either fail to correctly identify the accurate correspondences when 
    % there are many incorrect ones, or they select too few correct correspondences to 
    % support robust registration.
    % To address this challenge, 
    % we introduce a novel approach of correspondence regeneration. Different from outlier removal,
    % we can regenerate a larger number of high-quality correspondences.
    % Overall, our method adheres to a progressive approach, guiding the regeneration 
    % of local correspondences through using prior constraints.
    % In each iteration, we sample a confident set of seed correspondences. Then, leveraging 
    % the spatial constraints of seed correspondences, we perform neighbor searches 
    % to obtain local corresponding regions. In these regions, we conduct rematching to regenerate new correspondences. 
    % We refine the correspondences at both local and global levels using spatial consistency 
    % and then merge them using a hash table to obtain the regenerated correspondences.
    % % Finally, through spatial consistency filtering and hash table merging, we obtain the regenerated global correspondences. 
    % The progressive convergence of our regenerator is achieved by gradually reducing the local search radius. 
    % Finally, we refine the transformation through point-level Correspondence verification.
    % Benefiting from this robust regenerator, our approach can achieve robust registration even with weak features. 
    % On the 3DMatch and KITTI datasets, our method outperforms existing methods, achieving 20 times more 
    % inliers compared to outlier removal methods and 10 times more than the initial correspondences. The code will be released.

    Obtaining enough high-quality correspondences 
    is crucial for robust registration. Existing correspondence refinement methods mostly follow the paradigm of outlier removal, which either fails to correctly identify the accurate correspondences under extreme outlier ratios, or select too few correct correspondences to support robust registration. To address this challenge, we propose a novel approach named Regor, which is a progressive correspondence regenerator that generates higher-quality matches whist sufficiently robust for numerous outliers. In each iteration, we first apply prior-guided local grouping and generalized mutual matching to generate the local region correspondences. A powerful center-aware three-point consistency is then presented to achieve local correspondence correction, instead of removal. Further, we employ global correspondence refinement to obtain accurate correspondences from a global perspective. Through progressive iterations, this process yields a large number of high-quality correspondences. Extensive experiments on both indoor and outdoor datasets demonstrate that the proposed Regor significantly outperforms existing outlier removal techniques. More critically, our approach obtain 10 times more correct correspondences than outlier removal methods. As a result, our method is able to achieve robust registration even with weak features. The code will be released.
\end{abstract}

\section{Introduction}

% \begin{figure}[ht]
%     \centering{\includegraphics[width=1.0\linewidth]{introduction_v3.pdf}}  %0.32
%     \caption{
%         Illustration of the progressive correspondence regenerator.
%         The green and red lines indicate correct and incorrect correspondences at the current stage respectively. The black and purple dots represent the centers of the local region for the current stage and next stage respectively.
%         % The luminous part is the overlapping area. 
%         The dotted circles are the local corresponding regions, and only part of them are visualized.
%         % With each iteration, we regenerate more correct correspondences.
%         }
%     \label{process}
%     \vspace{-5pt}
% \end{figure}


% \begin{figure}[ht]
%     \centering{\includegraphics[width=1.0\linewidth]{introduction_v4.pdf}}  %0.32
%     \caption{
%         Illustration of the progressive correspondence regenerator.
%         The green and red lines indicate correct and incorrect correspondences at the current stage respectively. The black and purple dots represent the centers of the local region for the current stage and next stage respectively.
%         % The luminous part is the overlapping area. 
%         The dotted circles are the local corresponding regions, and only part of them are visualized.
%         % With each iteration, we regenerate more correct correspondences.
%         }
%     \label{process}
%     \vspace{-5pt}
% \end{figure}

\begin{figure}[ht]
    \centering{\includegraphics[width=1.0\linewidth]{introduction_v5.pdf}}  %0.32
    \caption{
        Difference between our method and existing outlier removal techniques. Outlier removal methods perform top-down pruning, producing an optimized set of correspondences that is a subset of the initial correspondences. When the initial inliers are few, this approach can obtain only a limited number of inliers, which is insufficient for robust pose estimation. In contrast, our method takes a bottom-up approach, using a regeneration strategy to generate more inliers, thereby effectively addressing this issue.
        }
    \label{process}
    \vspace{-5pt}
\end{figure}

Point cloud registration~\cite{huang2021comprehensive} is a fundamental and critical task in 3D computer vision, with widespread applications across various domains such as robotic localization~\cite{xiong2023speal, yin2024survey}, object pose estimation~\cite{yu2024learning}, and remote sensing~\cite{huang2021comprehensive}. Given two point clouds scanned from different perspectives, 
point cloud registration aims to estimate a rigid transformation to align these two point clouds. 
With the advancement of deep learning and feature metric learning, feature-based point cloud registration 
methods~\cite{ao2021spinnet,huang2021predator,yu2021cofinet,qin2022geometric} have garnered significant attention and achieved promising results. However, in scenarios characterized by low overlap, high noise, and strong self-similarity, direct feature matching often leads 
to a large number of outliers, which poses a great challenge for point cloud registration.%constraining the further development of point cloud registration.


Currently, the mainstream approach to address the issue of numerous outliers in point cloud registration 
is to filter wrong correspondences. Existing outlier removal methods~\cite{chen2022sc2,PointDSC,lu2021hregnet,zhang20233d,jiang2023robust} can 
be categorized into two types: geometry-based methods and learning-based methods. 
Geometry-based methods~\cite{fischler1981random,olsson2008branch,zhang20233d,chen2022sc2}
typically remove outliers according to whether point correspondences satisfy geometric consistency. %leverage geometrical invariants to identify inlier correspondences that exhibit consistency. 
Learning-based methods~\cite{PointDSC,lu2021hregnet,jiang2023robust} treat this task as a classification problem to distinguish between outliers and inliers. %Additionally, some approaches based on random sample consensus (RANSAC)~\cite{fischler1981random} and branch-and-bound (BnB)~\cite{olsson2008branch,zheng2011deterministically} have been proposed to achieve more robust registration. 
However, in challenging scenarios, these correspondence filtering methods all suffer from a common problem: when initial correspondences only contains few inliers, estimating the correct rigid transformation between two point clouds is extremely difficult even if all inliers are identified.
%where initial correspondences may be  poor and correct correspondences are scarce, accurately filtering correspondences becomes difficult. Even if correct correspondences are identified, estimating the correct global transformation from these rare correspondences is challenging. 
% Cross-PCR proposes a one-to-many correspondence generation approach, which increases the number 
% of correct correspondences but also deteriorates the inlier ratio, making robust registration 
% challenging. 

In this paper, we aim to design a new 3D registration architecture, which is robust to few inliers and is able to estimate precise 6DoF pose.
As shown in Figure~\ref{process},
different from existing outlier removal methods~\cite{chen2022sc2,PointDSC,zhang20233d,chen2023sc2}
that focus on pruning correspondences, our approach clearly regenerate more high-quality correspondences to achieve robust registration. The key insight is to progressively generate correspondences and leverage the positional priors of correspondences from the previous iteration to guide more refined local regeneration, thereby obtaining more high-quality point correspondences.
% This robust correspondence 
% regenerator allows us to achieve robust registration even with weak feature descriptors.

Our method, named Regor, follows a progressive iterative framework composed of three main modules: Local Grouping and Rematching, Local Correspondence Refinement and Global Correspondence Refinement. In each iteration, \textbf{Local Grouping and Rematching} leverages \emph{prior-guided local grouping} to gradually reduce the matching space and \emph{generalized mutual matching} to perform reliable local matching. %thereby generating a large number of dense local correspondences. % by gradually reducing the matching space, using \emph{prior-guided local grouping} and \emph{generalized mutual matching} to generate a large number of dense local correspondences. 
The \textbf{Local Correspondence Refinement} introduces an effective \emph{center-aware three-point consistency} to mine inliers and update local correspondences. The \textbf{Global Correspondence Refinement} is employed to perform further optimization from a global perspective. Note that, each iteration gradually increases the number of inliers, instead of only removing outliers. % we introduce \emph{center-aware three-point consistency} to finish \emph{local and global correspondence correction}, rather than outlier removal. 
%This approach maintains both the quality and quantity of correspondences, resulting in a larger set of high-quality matches. 
Our method achieves state-of-the-art performance on both the 3DMatch~\cite{zeng20173dmatch} and KITTI~\cite{KITTIdataset} datasets. Notably, the proposed Regor demonstrates a strong ability to generate correspondences, yielding up to 10 times more correct matches than existing outlier removal methods~\cite{chen2022sc2,zhang20233d,chen2023sc2}. %As a result, this correspondence regenerator allows us to achieve robust registration even with weak features.
The main contributions of this paper are as follows:
% In this study, we propose a progressive correspondence regenerator for achieving robust registration. 
% A key aspect is our departure from mainstream erroneous correspondence filtering approaches, 
% opting instead for a novel approach of regenerating correct correspondences. Initially, we perform 
% nearest-neighbor matching using feature descriptors, 
% followed by the stochastic spectral sampling~\cite{zhang2024fastmac} to 
% quickly and efficiently select seed correspondences.
% Finally, through a
% progressive correspondence regenerator, we iteratively refine the correspondences. 
% In each iteration, we use the prior correspondences 
% obtained from the previous stage to guide the generation of new correspondences 
% for the current stage in the local region. Then, we refine 
% these correspondences both locally and globally based on spatial consistency.
% In contrast to 
% correspondence filtering methods, which can only identify 
% a limited number of correspondences, 
% our regenerator leverages the sparse set of correct correspondences 
% from the initial set to regenerate a larger number of correct correspondences, enabling 
% more precise and robust registration. Theoretical analysis and 
% experimental validation demonstrate the significant advantages of our 
% regenerator's novel approach in handling correspondences.
\begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parsep}{0pt}
    % \setlength{\topsep}{0pt}
    \setlength{\parskip}{0pt}
    \item[$\bullet$] 
    We propose a novel registration approach named Regor to obtain massive high-quality point correspondences, overcoming the challenge of scarce inliers by progressively generating correspondences.

    \item[$\bullet$] 
    Our method achieves state-of-the-art performance. In particular, the number of correct correspondences is 10 times higher than that of outlier removal methods.

    \item[$\bullet$]
    Benefiting from the proposed regenerator, our approach achieves robust registration even with weak features.
    
 \end{itemize}

\section{Related Work}

\subsection{3D Feature Matching}
Feature matching is a crucial step in 
correspondence-based point cloud registration~\cite{FPFH,zeng20173dmatch,ao2021spinnet,huang2021predator,yu2021cofinet,qin2022geometric,yu2023peal}. 
According to the approach of feature extraction, feature matching methods 
can be categorized into two types: traditional descriptor-based methods~\cite{PFH, FPFH, salti2014shot} and 
learning-based methods~\cite{ao2021spinnet,huang2021predator,yu2021cofinet,qin2022geometric,yu2023peal}. 
Before the widespread adoption of deep learning, features were manually designed descriptors tailored to represent local information. 
They are classified into LRF-based methods~\cite{guo2013rotational, salti2014shot} and LRF-free methods~\cite{PFH, FPFH} 
based on whether a local reference frame (LRF) is needed. With the advancements in deep learning, 
numerous learning-based methods have emerged. Based on the representation strategy, 
they can be further divided into patch-based methods~\cite{gojcic2019perfect,ao2021spinnet,zhao2023spherenet} 
and fragment-based methods~\cite{choy2019fully,huang2021predator,yu2021cofinet,gath1989unsupervised}. 
SpinNet~\cite{ao2021spinnet} and BUFFER~\cite{ao2023buffer} have achieved excellent generalization ability through 3D cylindrical convolution. Additionally, CoFiNet~\cite{yu2021cofinet} and GeoTransformer~\cite{qin2022geometric} propose a coarse-to-fine matching strategy and a Transformer-based framework, which has garnered widespread attention. Subsequent methods~\cite{yang2022one, yu2023rotation, yu2023peal, jin2024multiway} have further 
improved performance by incorporating position encoding and prior information into this framework.
ODIN~\cite{jin2024multiway} achieves the best performance through diffusion strategy and global optimization.

\subsection{Geometry-based Outlier Removal}
Geometry-based outlier removal involves fitting models from noisy correspondences using the geometric properties of 3D scenes to estimate poses. The most classic method is random sampling consensus (RANSAC)~\cite{fischler1981random}, which 
samples correspondences multiple times and validates to 
obtain the best pose, thus mitigating the impact of noisy correspondences. Subsequently, numerous variants of RANSAC~\cite{barath2018graph, barath2022space, chum2008optimal, schnabel2007efficient} have been proposed to address issues 
of time consumption and instability. TEASER~\cite{yang2020teaser} introduces the truncated least squares (TLS) cost to solve for pose and employ rotation invariant measurements to handle outliers. Then, SC$^2$-PCR~\cite{chen2022sc2, chen2023sc2} propose second-order consistency for robust outlier removal. In recent years, methods~\cite{zhang20233d, yang2023mutual} based on 
geometric consistency have been widely applied in point cloud registration, leveraging graph-theoretic approaches~\cite{eppstein2010listing} and geometric consistency to 
remove outliers, thereby achieving robust registration.

\begin{figure*}[t]
    \centering{\includegraphics[width=1.0\textwidth]{new_v2.pdf}}  %0.32
    \caption{
       Overall framework of our method.
       We extract features from the original point cloud, 
       obtaining features $\mathbf{{F} }^{\mathcal{P}}$ and $\mathbf{{F} }^{\mathcal{Q}}$ 
       as input for our method. 
       % Initially, global 
       % feature matching is conducted using these features, followed by simple geometric constraints 
       % for preliminary spatial filtering to obtain initial correspondences $\mathcal{{G}}^{0}$. 
       Subsequently, a progressive 
       process is applied to iteratively regenerate more accurate and denser 
       correspondences $\mathcal{{G}}^{t}$. At each iteration, the output correspondences $\mathcal{{G}}^{t-1}$ from the previous 
       iteration serve as input. Firstly, prior-guided local grouping is employed to sample 
       seed corresponding points and form local correspondence regions 
       $\mathbf{P}^{t}_i$ and $\mathbf{Q}^{t}_i$. Then, for each pair of local correspondence regions, 
       generalized mutual matching is performed to get new correspondences. Next, these correspondences are refined locally and globally using our center-aware three-point consistency, 
       followed by a merging operation $\oplus$ of local correspondences $\mathcal{{G}}^{t}_{i}$ using a hash table.
       % Finally, pose $\mathbf T\{\mathbf R,\mathbf t\}$ is estimated using refined correspondences $\mathcal{{G}}^{T}$ through efficient SVD
       % , and Point-level Correspondence Verification is proposed for further pose refinement.
       Finally, using these refined correspondences,
       we achieve robust and accurate transformation estimation $\mathbf T\{\mathbf R,\mathbf t\}$ only with SVD.
       }
    \label{fig1}
 \end{figure*}

\subsection{Learning-based Outlier Removal}
Recent researches~\cite{3DRegNet, PointDSC, jiang2023robust} have integrated 
deep learning into outlier removal and pose estimation, 
showcasing promising performance through training. 
Inspired by image matching~\cite{CN-Net}, 3DRegNet~\cite{3DRegNet} adapts CN-Net~\cite{CN-Net} to remove outliers in point cloud registration. Subsequently, PointDSC~\cite{PointDSC} embeds the spatial consistency 
into feature maps and employs neural spectral matching to estimate confidence of correspondences, 
achieving robust registration. VBReg~\cite{jiang2023robust} utilizes variational Bayesian inference 
to achieve better outlier removal. Hunter~\cite{yao2023hunter} addresses severe outlier issues 
by introducing higher-order consistency using hypergraphs. However, while both geometry-based 
and learning-based methods have shown effectiveness in outlier removal, 
they inherently rely on the initial correspondences and only trim down on them, 
which poses challenges when initial inliers are scarce.


\section{Method}

\subsection{Problem Formulation}
Point cloud registration is aligning two point clouds $\mathbf{P}$ and $\mathbf{Q}$, captured from different perspectives, by estimating a pose transformation $\mathbf T\{\mathbf R,\mathbf t\}$ where $\mathbf R$ is a rotation matrix and $\mathbf t$ is a translation vector. Feature-based point cloud registration estimates correspondences through feature extraction and matching, then minimizes the average Euclidean distance between these correspondences, as shown in Eq.~\ref{eq1}:
\begin{equation}
    \underset{\mathbf{R}\in SO(3), \mathbf{t}\in \mathbb{R}^3}{\arg \min } \sum_{\left({\mathbf{p}}_{x_i}, {\mathbf{q}}_{y_i}\right) \in \mathcal{I}} \left\|\mathbf{R} \cdot {\mathbf{p}}_{x_i}+\mathbf{t}-{\mathbf{q}}_{y_i}\right\|_2^2.
\label{eq1}
\end{equation}
In this study, unlike outlier removal methods that perform ``subtraction'' filtering on initial correspondences, 
resulting in a subset of initial correspondences highly dependent on them, 
our aim is to generate more higher-quality correspondences $\mathcal{G}^{t}$  where $t=1, 2, ..., m$ represents the current iterative stage. We define the regeneration process as $\mathcal{G}^{t} = \varTheta (\mathcal{G}^{t-1};\mathbf{P}, \mathbf{Q}, \varphi^{t} )$
where $\varTheta$ is the operation of the correspondence regeneration, and $\varphi^{t}$ represents the parameter used in the regeneration of the $t$th stage.

\subsection{Progressive Regeneration: Key Insight}
Existing methods focus on pruning the initial correspondences to remove outliers and retain inliers. %Outlier removal methods filter initial correspondences to identify correct matches. 
%However, when initial correspondences contain consistency ambiguities, this often leads to the selection of incorrect correspondences. 
Due to common problems such as weak feature representation and low overlap, the proportion of correct initial correspondences is typically very small. Even all correct correspondences are identified, achieving accurate registration remains challenging. To this end, we design a novel progressive correspondence regeneration strategy to address the scarcity of initial inliers and the frequent failures of correspondence filtering under extreme outlier ratios.

The key idea of our method is to progressively regenerate better correspondences in a radius-variable local sphere.
We use the positional priors of correspondences generated in the previous stage to guide the creation of the local sphere.
In each local sphere, we regenerate more correspondences with higher quality.
% If the geodesic distance between the centers of the two spheres is within a certain range, 
% the prior-guided local corresponding region is a pair of correct corresponding regions.
Compared to direct global matching, re-matching and refining within these local 
spheres significantly reduce the problem's scale and search space, resulting in more precise matches and 
reduced computational time. As the quality of the correspondence gets higher, we progressively reduce the size of the local spheres to 
achieve exact convergence of the correspondences. This approach not only generates a large number of new dense correspondences but also incrementally enhances their accuracy.


\subsection{Local Grouping and Rematching}\label{Grouping}
In this module, we implement the core of each iteration: local correspondence generation. First, we introduce prior-guided local grouping to leverage priors from the previous iteration. Then, we propose a generalized mutual matching technique to ensure the generation of a sufficient number of inliers even under high outlier rates.

\ptitle{Prior-guided Local Grouping.}
% Through global matching based on nearest neighbor search and spatial filtering, 
% we obtain the initial correspondences $\mathcal{G}^{0}$.  
The input to our method is the correspondence $\mathcal{G}^{t-1}$ of the previous stage.
Efficiency is crucial for our method due to the need for iterative processing. 
Therefore, we sample $\mathcal{G}^{t-1}$ 
using efficient random sampling~\cite{hu2020randla} 
to derive seed correspondences $ \mathcal{\widetilde{G}}^{t-1}$. 
% Therefore, we perform sampling of the input correspondences $\mathcal{G}^{t-1}$ at each iteration. 
% To maintain the quality of the sampled correspondences, 
% we sample $\mathcal{G}^{t-1}$ 
% using efficient random sampling~\cite{hu2020randla} 
% to derive seed correspondences $ \mathcal{\widetilde{G}}^{t-1}$.  
% The effectiveness and robustness of this approach have been thoroughly demonstrated in~\cite{chen2017fast, leordeanu2005spectral}.
We then utilize 
the positional priors of each seed correspondence to guide the construction of local regions.  
Specifically, we conduct a radius $ r^{t}$ nearest neighbor search centered on each seed correspondence $ {\widetilde{g}}^{t-1}_i \in \mathcal{\widetilde{G}}^{t-1}$
to obtain local point clouds  $\mathbf{P}^{t}_i$ and $\mathbf{Q}^{t}_i$, $i=1, 2, ..., n$:
\begin{equation}
    \mathbf{P}^{t}_i = \mathrm{RNN}(\mathbf{p}^{t-1}_i; r^{t}, \mathcal{\widetilde{G}}^{t-1}),   \mathbf{Q}^{t}_i = \mathrm{RNN}(\mathbf{q}^{t-1}_i; r^{t}, \mathcal{\widetilde{G}}^{t-1}),
\end{equation}
where $\mathrm{RNN}(\mathbf{p}; r, \mathcal{{G}})$ is a radius nearest neighbor search on $\mathcal{{G}}$ with $\mathbf{p}$ as the center and $r$ as the radius. 
$\mathbf{p}^{t-1}_i$ and $\mathbf{q}^{t-1}_i$ satisfy $ {\widetilde{g}}^{t-1}_i =(\mathbf{p}^{t-1}_i, \mathbf{q}^{t-1}_i)$.
% $n$ is the number of seed correspondences $\mathcal{G}^{0}$.
We perform the above grouping operation for each pair of seed corresponding points and obtain $n$ pairs of local region
$(\mathbf{P}^{t}_i, \mathbf{Q}^{t}_i)$.

\begin{figure}[tb]
    \centering{\includegraphics[width=1.0\linewidth]{GMM_v5.pdf}}  %0.32
    \caption{
        Illustration of GMM.
        The orange, blue, green, and red lines are the MNN correspondences, NN correspondences, correct correspondences, and wrong correspondences, respectively.
       }
    \label{GMM}
\end{figure}

\ptitle{Generalized Mutual Matching.}
The next step is to generate new point correspondences from each pair of local region by feature matching. %With the proposed prior-guided local grouping, the computational complexity and search space of feature matching are significantly reduced compared to earlier stages. 
However, the features in small local regions are usually similar, which results in traditional nearest-neighbor (NN) matching~\cite{PointSignatures} producing a large number of false correspondences. Unfortunately, mutual NN matching~\cite{spinimage,3D-3D} may even fail to find any correspondence at all. To address this issue, we propose a generalized mutual matching to relax the strict mutual constraint, thereby improving the robustness of the local correspondences.

%However, in small local regions, the distinctiveness of features is often weak, making direct nearest-neighbor matching unreliable and inaccurate for establishing correspondences. To address this issue, we propose a generalized mutual matching (GMM) to improve the robustness of the local correspondences. Due to the double nearest-neighbor constraint, mutual correspondences typically exhibit a high accuracy rate. However, in cases with a high percentage of extreme outliers, traditional mutual matching results in very few or even no correspondences. To mitigate this problem, we introduce the concepts of nearest-neighbor (NN) and multi-nearest-neighbor (MNN) matching to relax the strict mutual constraint.

Given point cloud $\mathbf{Q}^{t}_i$ as the query, the NN matching matrix $\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_1$ and multi-nearest-neighbor (MNN) matching matrix $\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_2$ are obtained by performing a k-nearest-neighbor (KNN) search in feature space, respectively: 
\begin{equation}
    \begin{aligned}
    &\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_1(m,n)=\operatorname{NN}(\mathbf{F}(\mathbf{p}_m), \mathbf{F}(\mathbf{q}_n)), \\ %\forall \mathbf{p}_m \in \mathbf{P}^{t}_i, \mathbf{q}_n \in \mathbf{Q}^{t}_i
    &\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_2(m,n)=\operatorname{MNN}(\mathbf{F}(\mathbf{p}_m), \mathbf{F}(\mathbf{q}_n)),
    \end{aligned}
\end{equation}
where $\forall \mathbf{p}_m \in \mathbf{P}^{t}_i, \mathbf{q}_n \in \mathbf{Q}^{t}_i$ and $\mathbf{F}(\cdot)$ represents the mapping from points to features. $\operatorname{NN}(\cdot)$ and $\operatorname{MNN}(\cdot)$ represent the indicator functions for NN and MNN matching, respectively.  If the matching condition is satisfied, the value is set to 1. 
Then, we conduct mutual matching from 
$\mathbf{P}^{t}_i$ to $\mathbf{Q}^{t}_i$
and from $\mathbf{Q}^{t}_i$ to $\mathbf{P}^{t}_i$, resulting in four matching matrices $\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_1$, $\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_2$, $\mathbf{M}^{\mathcal{Q}\rightarrow\mathcal{P} }_1$, and $\mathbf{M}^{\mathcal{Q}\rightarrow\mathcal{P} }_2$.

By computing the Hadamard product between the NN and MNN matching matrices, we obtain the mutual matching matrices  $\mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_*$, $\mathbf{M}^{\mathcal{Q}\rightarrow\mathcal{P} }_*$. Further, we perform an element-wise logical OR operation to relax the constraint and get the generalized mutual matching matrix:
\begin{equation}
    \mathbf{M}^{*} = \left( \mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_1 \odot \mathbf{M}^{\mathcal{Q}\rightarrow\mathcal{P} }_2  \right) \otimes \left( \mathbf{M}^{\mathcal{Q}\rightarrow\mathcal{P} }_1 \odot \mathbf{M}^{\mathcal{P}\rightarrow\mathcal{Q} }_2  \right),
\end{equation}
where operation $\odot$ and $\otimes$ denote Hadamard product and element-wise logical OR, respectively.
It is important to note that, to avoid a large number of outliers, we discard the strategy of directly applying mutual matching only based on MNN. Finally, using the matching matrix $\mathbf{M}^{*}$, we establish $n$ sets of local correspondences $\mathcal{{G}}^{t}_i$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%  simple and efficient nearest neighbormatching  %%%%%%%%%%%%%%%%%%
% Therefore, here we only employ simple and efficient nearest neighbor 
% matching based on cosine similarity. 
% We conduct the local matching in the feature space and get the matching matrix $\mathbf{M}^t_{i}$
% \begin{equation}
% \mathbf{M}^t_{i}=\mathrm{Norm}(\mathbf{{F} }^{\mathcal{P}^t_i})^\top 
%  \cdot 
%  \mathrm{Norm}({\mathbf{{F} }^{\mathcal{Q}^t_i}})
% \end{equation}
% According to $\mathbf{M}^t_{i}$, $\forall \mathbf{p} \in \mathbf{P}^{t}_i$, $ \mathbf{q} \in \mathbf{Q}^{t}_i$ with the smallest 
% feature distance is found to form the local correspondences $\mathcal{{G}}^{t}_i$.
% Finally, $n$ sets of local correspondences is obtained.


\subsection{Local Correspondence Refinement}

Because some corresponding local regions may not overlap exactly, the rematching in local regions still introduces some erroneous correspondences. Therefore, we further enhance the quality 
of the regenerated correspondences through local correspondence refinement.

%Given the limitation posed by a small number of correct correspondences on robust registration, and the inevitable filtering out of numerous correct correspondences by outlier removal methods using Top-k~\cite{chen2022sc2,zhang20233d}, we introduce a correspondence refinement approach as an alternative to outlier filtering. By initially selecting a precise set of correspondences through spatial consistency, followed by guiding the correction of other correspondences, this method effectively addresses the above challenges.

\begin{figure}[ht]
    \centering{\includegraphics[width=1.0\linewidth]{correction_v5.pdf}}  %0.32
    % \setlength{\abovecaptionskip}{-6pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{
        Illustration of the local correspondence correction.
        Yellow and blue areas represent a pair of local point clouds. 
        The purple line indicates the correct correspondence after correction.
       }
    \label{LGCR}
\end{figure}


\ptitle{Center-aware Three-point Consistency.}
Note that, our seed correspondences $g^{t\!-\!1}_i\!=\!(\mathbf{p}^{t\!-\!1}_i, \mathbf{q}^{t\!-\!1}_i)$ (central points) are derived from the previous stage and exhibit high accuracy. Therefore, they can serve as prior information to guide the optimization of local correspondence refinement.
%Therefore, we avoid the high-complexity approach~\cite{chen2022sc2,zhang20233d}. 
Based on this, we propose an efficient center-aware three-point consistency (CTC) to search inliers. %It reduces computational complexity while maintaining strong recognition ability for outliers in local regions. 
% 这里可以简写
% The consistency score $s_{jk}$ describes whether two points  $(\mathbf{p}_j, \mathbf{q}_j), (\mathbf{p}_k, \mathbf{q}_k) \in \mathcal{{G}}^{t}_i$ simultaneously satisfy the three-point invariant measurement~\cite{yang2020teaser} with respect to the center point $(\mathbf{p}^{t-1}_i, \mathbf{q}^{t-1}_i)$:
% \begin{equation}
%     s_{jk}= \varTheta \left(\mathbf{p}_j \mathbf{q}_j, \mathbf{p}^{t-1}_i, \mathbf{q}^{t-1}_i\right) \cdot \varTheta (\mathbf{p}_k, \mathbf{q}_k, \mathbf{p}^{t-1}_i, \mathbf{q}^{t-1}_i)
% \end{equation}

We first utilize efficient translation and rotation invariants~\cite{yang2020teaser} to describe the consistency $s_{\sigma}(g_i, g_j)$ between two point pairs 
$g_i=(\mathbf{p}_i, \mathbf{q}_i)$ and $g_j=(\mathbf{p}_j, \mathbf{q}_j)$: 
\begin{equation}
    s_{\sigma}(g_i, g_j)= 
    \mathds {1} \left(\Big| ||\mathbf{p}_i-\mathbf{p}_j||_2 
    -||\mathbf{q}_i-\mathbf{q}_j||_2 \Big| \leqslant {\sigma}
    \right).
\end{equation}
Next, we leverage the prior information of accurate center points to compute the center-aware consistency between $g_j$ and $g_k$, denoted as $s_{\sigma}(g_j, g^{t-1}_i) \cdot s_{\sigma}(g^{t-1}_i, g_k)$. Additionally, we account for the possibility that seed correspondences may not always be correct. Relying solely on the aforementioned criterion could allow errors in the seed correspondences to negatively impact the optimization of the entire region. To mitigate this, we introduce a strict point-pair constraint $s_{\frac{\sigma}{2}}(g_j, g_k)$.
CTC is computed as:
\begin{equation}
    s_{\varDelta}(g_j, g_k)
    = \left(s_{\sigma}(g_j, g^{t-1}_i) \cdot s_{\sigma}(g^{t-1}_i, g_k)\right)||s_{\frac{\sigma}{2}}(g_j, g_k),
\end{equation}
where $||$ represents operator OR and it
means if either condition is satisfied, the correspondence is considered correct.
%*********Triangular Consistency*********
% The consistency score $s_{jk}$ describes whether two points $(\mathbf{p}_j, \mathbf{q}_j), (\mathbf{p}_k, \mathbf{q}_k) \in \mathcal{{G}}^{t}_i$, along with the central point $(\mathbf{p}^{t-1}_i, \mathbf{q}^{t-1}_i)$, satisfy the three-point invariant measurement among them:
% \begin{equation}
%     s_{jk}= \mathds {1}\! \left(\big\| \varDelta (\mathbf{p}_j,\mathbf{p}_k,\mathbf{p}^{t\!-\!1}_i)\!-\!\varDelta (\mathbf{q}_j,\mathbf{q}_k,\mathbf{q}^{t\!-\!1}_i) \big\|_2 \!\leqslant\! {\sigma_d}\right)
% \end{equation}
% where symbol $\varDelta$ defines the three-point consistency property, calculated as follows:
% \begin{equation}
% \varDelta (\!\mathbf{p}_1,\!\mathbf{p}_2,\!\mathbf{p}_3\!) = \big[\overrightarrow{\mathbf{p}_1 \mathbf{p}_2}\!\cdot \overrightarrow{\mathbf{p}_1 \mathbf{p}_3}, \overrightarrow{\mathbf{p}_2 \mathbf{p}_1}\!\cdot\overrightarrow{\mathbf{p}_2 \mathbf{p}_3}, \overrightarrow{\mathbf{p}_3 \mathbf{p}_1}\!\cdot \overrightarrow{\mathbf{p}_3 \mathbf{p}_2}\big]
% \end{equation}
% The consistency score $s_j$ for correspondence $g_j \in \mathcal{{G}}^{t}_i$
% is obtained by summing its associated CTCs:
% \begin{equation}
%     s_j = \sum_{g_k \in \mathcal{{G}}^{t}_i}  s_{\varDelta}(g_j, g_k), \  g_j \in \mathcal{{G}}^{t}_i
% \end{equation}
Therefore, we get the score matrix $\mathbf{S}^t_{i}=[s_{\varDelta}(g_j, g_k)]_{jk} \in \mathbb{R}^{N \times N}$ of the local correspondences $\mathcal{{G}}^{t}_i \in \mathbb{R}^{N \times 2}$.
To evaluate the overall quality of the local region,
we define a local overall score:
\begin{equation}
    Score(\mathcal{G}^{t}_i)
    = \frac{|| \mathbf{S}^t_{i}||_1}{a\cdot N},
\end{equation}
where $||\cdot||_1$represents the $L_1$-norm of a matrix and $a \in (0, 1)$ denotes the threshold for the proportion of correct correspondences. 
Essentially, we consider regions where 
the proportion of correct correspondences exceeds $a$ as correct correspondence regions. 
This is Theorem~\textcolor{red}{1}, and then we give its proof in the Appendix.

\ptitle{Local Correspondence Correction.}
Within each correct corresponding region, we identify a set of precise correspondences $\mathcal{\widehat {G}}^{t}_i$ to 
guide the refinement of correspondences across the entire local region.  Specifically, based on the CTC score, we identify precise correspondences $\mathcal{\widehat {G}}^{t}_i$ with high scores.  
Subsequently, using these correspondences, we estimate the local transformation  $\mathbf{T}_i^{t}\{\mathbf{R}_i^{t}, \mathbf{t}_i^{t}\}$:
\begin{equation}
    \mathbf{R}_i^{t}, \mathbf{t}_i^{t}=\min_{\mathbf{R}, \mathbf{t}} \sum\nolimits_{\left({\mathbf{p}}_{j}, {\mathbf{q}}_{j}\right) \in \widehat{\mathcal{ {G}}}_i^{t}} \left\|\mathbf{R} \cdot {\mathbf{p}}_{j}+\mathbf{t}-{\mathbf{q}}_{j}\right\|_2^2.
\end{equation}
Leveraging this local pose $\mathbf{T}_i^{t}\{\mathbf{R}_i^{t}, \mathbf{t}_i^{t}\}$, we search 
for the nearest points $\mathbf{q}^{\prime}$ in the target local point cloud $\mathbf{Q}^{t}_i$ for each point $\mathbf{p}$ in the source local point cloud $\mathbf{P}^{t}_i$:
% \begin{equation}
%     \Omega_l (\mathcal{{G}}^{1}_i) = \left\{ 
%         (\mathbf{p}, \mathbf{q}^{\prime})| (\mathbf{p},\mathbf{q}) \in \mathcal{{G}}^{1}_i, \mathbf{q}^{\prime}= \mathop{\arg\min}\limits_{\mathbf{q}_j \in \mathbf{Q}^{1}_i} ||\mathbf{R}_i^{1}\mathbf{p}+\mathbf{t}_i^{1}-\mathbf{q}_j||_2,
%         s.t. 
%     \right\}
% \end{equation}
\begin{equation}
\begin{aligned}
&\mathbf{q}^{\prime}= \mathop{\arg\min}\limits_{\mathbf{q}_j \in \mathbf{Q}^{t}_i} ||\mathbf{R}_i^{t}\mathbf{p}+\mathbf{t}_i^{t}-\mathbf{q}_j||_2, \\
        s.t. &||\mathbf{R}_i^{t}\mathbf{p}+\mathbf{t}_i^{t}-\mathbf{q}^{\prime}||_2\leqslant {\sigma_d}, \forall(\mathbf{p},\mathbf{q}) \in \mathcal{{G}}^{t}_i.
\end{aligned}
\end{equation}
Through the one-way refinement of $\mathbf{Q}$, we update our local correspondences $\mathcal{{G}}^{t}_i \leftarrow \Omega_l (\mathcal{{G}}^{t}_i)=\{(\mathbf{p}, \mathbf{q}^{\prime})\} $
where $\Omega_l$ represents the operation of local correspondence correction.

% \vspace{2pt}
\ptitle{Theorem 1.} \label{Theorem1}
% \begin{theorem}\label{lemma1}
    \emph{
        Assuming event $\Phi $, where the consistency of correct correspondences is greater than the maximum consistency of incorrect correspondences, 
        has a probability ${P}(\Phi)\approx  1 $,
        if the score of the local correspondences satisfies $Score(\mathcal{G}^{t}_i)\geqslant  1$, then the proportion of correct correspondences $b \geqslant a$.
        Theorem 1 is proved and explained in detail in the appendix.
    }
% \end{theorem}
% \vspace{2pt}
    
% \begin{proof}[Proof of Theorem \ref{lemma1}]
%     For simplicity, we denote the local correspondences and the consistency matrix as $\mathcal{{G}}$
%     and $\mathbf{S}_{\mathrm{SOG}}$, respectively. Thus, we can demonstrate that:
%     \begin{equation}
%        \begin{aligned} 
%         &P(Score(\mathcal{G}^{t}_i)\geqslant 1) = P(\frac{|| \mathbf{S}^t_{\mathrm{SOG},i}||_1}{a\cdot n^2}\geqslant 1)=1 \\
%         =& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1) \\
%         =& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \Phi) P(\Phi)\\
%         +& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \overline\Phi) P(\overline\Phi) \\
%         \overset{(1)}{\approx}& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \Phi) P(\Phi)\\
%         \overset{(2)}{\leqslant }& P(\frac{   (b \cdot n) \cdot n  }{a\cdot n^2}\geqslant1 | \Phi) P(\Phi) \\
%         \overset{(3)}{=}& P(\frac{  (b \cdot n) \cdot n  }{a\cdot n^2}\geqslant 1) P(\Phi) = P(\frac{   b }{a}\geqslant 1) P(\Phi)
%        \end{aligned} 
%     \end{equation}
% where step (1) is based on our assumption that ${P}(\Phi)\approx  1 $. 
% Step (2) follows from the fact $(\frac{   (b \cdot n) \cdot n  }{a\cdot n^2}\geqslant1)  \indep \Phi$.
% Step (3) can be easily derived 
% from the definition of consistency matrix. By definition, the number of 
% correct correspondences is $b\cdot n$. According to the definition of the second-order consistency matrix, 
% the matrix element ${\mathbf{S}_{\mathrm{SOG}}}_{ij}$ represents the number of correspondences 
% that are consistent with both correspondence $i$ and correspondence $j$. Thus, ${\mathbf{S}_{\mathrm{SOG}}}_{ij} \leqslant b \cdot n$. 
% The equality holds if and only if both $i$ and $j$ are correct correspondences. Therefore, we have:
% \begin{equation}
%     \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|= \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{il}| \leqslant (b \cdot n) \cdot n.
% \end{equation}
% Ultimately, we prove that $P(\frac{   b }{a}\geqslant 1) P(\Phi)\geqslant 1 \Rightarrow P(\frac{   b }{a})\geqslant 1$, meaning that the proportion of correct correspondences 
% $b$ exceeds the threshold $a$.
% \end{proof}

\subsection{Global Correspondence Refinement}
Through local refinement, we obtain $n$ sets of refined local correspondences. However, consistency across sets is not fully aligned. Therefore, we need a global merging and refinement step to complete the global correspondence optimization.
Since there is no seed correspondence at the global scale, we use second-order consistency~\cite{chen2022sc2}.

\ptitle{Correspondence Merging.}
After correcting the local correspondences, we merge them into global correspondences $\mathcal{{G}}^{t}$. 
It is worth noting that some local regions overlap with each other. Therefore, we utilize a hash table $\mathbb{H}$ to store the index of the original point cloud, facilitating the merging of local correspondences to prevent point duplication. With this strategy, we further enhance the efficiency of our method and save memory overhead. Ultimately, we obtain the global correspondences $\mathcal{{G}}^{t}=\bigcup_{i=1}^{n} \mathcal{{G}}_{i}^{t}$.

\ptitle{Global Correspondence Correction.}
Although we achieve the correspondence correction in local regions, if the seed correspondences $ \mathcal{\widetilde{G}}^{t-1}$ are significantly incorrect, it may still result in wrong refinement for the entire local region.
Therefore, similar to local correction, we 
refine global correspondences $\mathcal{{G}}^{t} \leftarrow \Omega_g (\mathcal{{G}}^{t})$, where $\Omega_g$ represents the operation of global correspondence correction. The key difference is that, in the global stage, we use second-order consistency~\cite{chen2022sc2} to identify correct correspondences.
By leveraging correspondences that satisfy maximum consistency, 
we rectify anomalous correspondences globally, completing one iteration of correspondence regeneration $\varTheta(\cdot)$.

% \subsection{Point-level Pose Refinement}
% Through the aforementioned progressive correspondence regeneration, we obtained high-quality dense correspondences, 
% enabling the estimation of a more accurate pose. 
% Therefore, we only use SVD to estimate the transformation $\mathbf{T}\{\mathbf{R}, \mathbf{t}\}$.
% To further enhance the registration accuracy, we perform pose refinement.

% % Pose refinement is crucial for achieving accurate pose estimation. 
% One of the main advantages of our approach is the generation of dense and accurate 
% correspondences. However, traditional pose refinement evaluation functions, such 
% as inlier count (IC)~\cite{chen2022sc2}, mean square error (MSE)~\cite{yang2021toward} and truncated chamfer distance (TCD), 
% % and feature and spatial consistency constrained truncated chamfer distance (FS-TCD)~\cite{chen2023sc2}, 
% are all based on initial correspondences. Since initial correct correspondences are few, 
% using these traditional evaluation functions cannot fully exploit the advantages of 
% our dense and accurate correspondences. Therefore, we propose a point-level evaluation 
% function, named point-level optimal truncated chamfer distance (PO-TCD)
% \begin{equation}
%     { \mathbf{R}}^{*}, { \mathbf{t}}^{*}=\max _{\mathbf{R}, \mathbf{t}} 
%     \sum_{\mathbf{{p}}_i \in \mathbf{{P}}} 
%     \mathds {1}\left(
%         \min _{\mathbf{{q}}_j \in \mathbf{{Q}}}
%         \left\|  \mathbf{\mathbf{R} {p}}_i+\mathbf{t}-\mathbf{{q}}_j  \right\|< {\sigma_d}
%         \right).
% \end{equation}
% It discards evaluation based on initial correspondences and instead calculates  
% the optimal truncation distance directly from dense point clouds.
% It takes full advantage of our dense correspondences.


% \begin{table*}[ht]
%     \caption{Quantitative comparison on {3DMatch} dataset with descriptors FPFH~\cite{FPFH} and FCGF~\cite{choy2019fully}.}
%   \centering
%    \vspace{-4pt}% 减少表格与上文之间的距离
% %    \scriptsize
% 	\resizebox{1.0\linewidth}{!}{
% 		\begin{tabular}{l|cccccc|cccccc|c}
% 			\toprule
% 			& \multicolumn{6}{c|}{\textbf{FPFH} (Traditional Descriptor)} & \multicolumn{6}{c|}{\textbf{FCGF} (Learning-based Descriptor)}  & \\
% 			Method & RR($\uparrow$) & RE($\downarrow$) & TE($\downarrow$) & IP($\uparrow$)  & INR($\uparrow$) & NR($\uparrow$) & RR($\uparrow$) & RE($\downarrow$) & TE($\downarrow$) & IP($\uparrow$)  & INR($\uparrow$) & NR($\uparrow$) &   Time(s)      
%             \\ \midrule 
%             % PointNetLK* \cite{aoki2019pointnetlk} & 1.61 & 8.04  & 21.30 & - & - & - & 1.61 & 8.04 & 21.30 & - & - & - & 0.12 \\
%             3DRegNet  & 26.31 & 3.75 & 9.60 & 28.21 &31.90  &5.91  & 77.76 & 2.74 & 8.13 & 67.34 &72.59  &24.44  &\textbf{0.05}\\
%             % DGR  & 32.84 & 2.45 & 7.53 & 29.51 & 16.78 & 21.35 & 88.85 & 2.28 & 7.02 & 68.51 & 79.92 & 73.15 & 1.53\\
%             DHVR  & 67.10 & 2.78 & 7.84 & 60.19 &65.27  &6.90  & 91.93 &{2.25} & 7.08 &{80.20} &86.98  &27.09  & 3.91\\
%             PointDSC  &76.96	&2.25	&6.76	&66.64	&70.16	&6.97	&92.61	&2.10	&6.48	&78.37	&85.88	&27.59   &0.09          \\ 
%             VBReg  &78.01 &2.28 &7.34 &67.23 &70.93 &7.10    &92.77 &2.24 &6.82 &79.92 &86.30 &27.45 &0.42\\ 
%             Hunter  &84.70 &1.80 &6.46 &74.39 &79.27 &7.21  &94.05 &1.72 &6.40 &82.55 &88.01 &27.32 &0.10\\ 
%             \midrule
%             % SM  & 55.88 & 2.94 & 8.15 & 47.96 & 70.69 & 50.70 & 86.57 & 2.29 & 7.07 & 81.44 & 38.36 & 48.21 &{0.03}\\
%             % ICP*  & 5.79 & 7.93 & 17.59 & - & - & - & 5.79 & 7.93 & 17.59 & - & - & - & 0.25\\
%             % FGR  & 40.91 & 4.96 & 10.25 & 6.84 & 38.90 & 11.23 & 78.93 & 2.90 & 8.41 & 25.63 & 53.90 & 33.58 & 0.89 \\
%             TEASER & 75.48 & 2.48 & 7.31 &{73.01} &78.60  &7.22  & 85.77 & 2.73 & 8.66 &{82.43} &87.90  &27.41  & 0.07\\
%             GC-RANSAC & 67.65 & 2.33 & 6.87 & 48.55 &53.41  &6.32  & 92.05 & 2.33 & 7.11 & 64.46 &70.81 &24.39  & 0.55\\
%             %& RANSAC-1k & 40.05 & 5.16 & 13.65 & 51.52 & 34.31 & 39.23 & 86.57 & 3.16 & 9.67 & 76.86 & 77.45 & 76.62 & 0.08\\
%             RANSAC-1M & 64.20 & 4.05 & 11.35  & 63.96  &69.03  &6.84  & 88.42 & 3.05 & 9.42 & 77.96 &83.08  &26.99 & 0.93 \\
%             % RANSAC-2M  & 65.25 & 4.07 & 11.56 & 64.41 & 58.37 & 60.51 & 90.88 & 2.71 & 8.31 & 78.52 & 83.52 & 80.68 & 1.63 \\
%             RANSAC-4M  & 66.10 & 3.95 & 11.03 & 64.27  &69.82   &6.89    & 91.44 & 2.69 & 8.38 & 78.88 &83.91  &27.10 &2.79  \\
%             CG-SAC     & 78.00 & 2.40 & 6.89  & 68.07  &73.45   &7.02    & 87.52 & 2.42 & 7.66 & 75.32 &80.32  &25.78  & 0.27 \\
%             SC$^2$-PCR &83.24	&2.21	&6.70	&73.64	&78.78	&7.35	&93.16	&2.11	&6.44	&80.17	&87.24	&83.25 &0.08\\
%             MAC \\
%             SC$^2$-PCR++ &86.81	&2.13	&6.59	&76.34	&81.43	&7.26	&93.47	&2.1	&6.54	&80.06	&87.15	&27.45 &0.26\\
%             FastMAC \\
%             PCRegen (\emph{ours}) & \textbf{88.54} &\textbf{1.67} &\textbf{5.90}& \textbf{82.91}	&\textbf{1255.48}	&\textbf{61.86} & \textbf{94.21}	&\textbf{1.69}	&\textbf{6.02}	&\textbf{87.92}	&\textbf{267.34} &\textbf{62.84}

%             \\
%             \bottomrule
%     \end{tabular}
%     }
% 	\label{3dmatch2}
% \end{table*}

\begin{table*}[htbp]
    \centering
     \scriptsize
      \resizebox{1.0\linewidth}{!}{
          \begin{tabular}{l|cccccc|cccccc|c}
              \toprule
              & \multicolumn{6}{c|}{\textbf{FPFH} (Traditional Descriptor)} & \multicolumn{6}{c|}{\textbf{FCGF} (Learning-based Descriptor)}  & \\
              Method & RR($\uparrow$) & RE($\downarrow$) & TE($\downarrow$) & IP($\uparrow$)  & INR($\uparrow$) & IN($\uparrow$) 
              & RR($\uparrow$) & RE($\downarrow$) & TE($\downarrow$) & IP($\uparrow$)  & INR($\uparrow$) & IN($\uparrow$) &   Time(s)      
              \\ \midrule 
              % PointNetLK* \cite{aoki2019pointnetlk} & 1.61 & 8.04  & 21.30 & - & - & - & 1.61 & 8.04 & 21.30 & - & - & - & 0.12 \\
              % 3DRegNet  & 26.31 & 3.75 & 9.60 & 28.21 &31.90  &5.91  & 77.76 & 2.74 & 8.13 & 67.34 &72.59  &24.44  &\textbf{0.05}\\
              % DGR  & 32.84 & 2.45 & 7.53 & 29.51 & 16.78 & 21.35 & 88.85 & 2.28 & 7.02 & 68.51 & 79.92 & 73.15 & 1.53\\
              % DHVR  & 67.10 & 2.78 & 7.84 & 60.19 &65.27  &6.90  & 91.93 &{2.25} & 7.08 &{80.20} &86.98  &27.09  & 3.91\\
              PointDSC~\cite{PointDSC}  &76.96	&2.25	&6.76	&66.64	&70.16	&290.23	
              &92.61	&2.10	&6.48	&78.37	&85.88	&1174.62   &0.22          \\ 
              VBReg~\cite{jiang2023robust}  &78.01 &2.28 &7.34 &67.23 &70.93 & 166.56  
              &92.77 &2.24 &6.82 &79.92 &86.30 &690.38 &1.02\\ 
              Hunter~\cite{yao2023hunter}  &\underline{84.70} &\underline{1.80} &\underline{6.46} &\underline{74.39} &\underline{79.27} & \underline{309.28} 
              &\textbf{94.05} &\underline{1.86} &6.54 &\underline{82.55} &\underline{88.01} &\underline{1203.88} &0.59\\ 
              \midrule
              SM~\cite{leordeanu2005spectral}  & 55.88 & 2.94 & 8.15 & 47.96 & 70.69 & 230.03
              & 86.57 & 2.29 & 7.07 & 81.44 & 38.36 &405.10 &\textbf{0.03}\\
              % ICP*  & 5.79 & 7.93 & 17.59 & - & - & - & 5.79 & 7.93 & 17.59 & - & - & - & 0.25\\
              % FGR  & 40.91 & 4.96 & 10.25 & 6.84 & 38.90 & 11.23 & 78.93 & 2.90 & 8.41 & 25.63 & 53.90 & 33.58 & 0.89 \\
              TEASER~\cite{yang2020teaser} & 75.48 & 2.48 & 7.31 &{73.01} &78.60  &270.98
              & 85.77 & 2.73 & 8.66 &{82.43} &87.90  &1182.44  & 0.07\\
              % GC-RANSAC & 67.65 & 2.33 & 6.87 & 48.55 &53.41  &6.32  & 92.05 & 2.33 & 7.11 & 64.46 &70.81 &24.39  & 0.55\\
              %& RANSAC-1k & 40.05 & 5.16 & 13.65 & 51.52 & 34.31 & 39.23 & 86.57 & 3.16 & 9.67 & 76.86 & 77.45 & 76.62 & 0.08\\
              RANSAC-1M~\cite{fischler1981random} & 64.20 & 4.05 & 11.35  & 63.96  &69.03  &264.09 
              & 88.42 & 3.05 & 9.42 & 77.96 &83.08  &672.22 & 0.93 \\
              % RANSAC-2M  & 65.25 & 4.07 & 11.56 & 64.41 & 58.37 & 60.51 & 90.88 & 2.71 & 8.31 & 78.52 & 83.52 & 80.68 & 1.63 \\
              % RANSAC-4M  & 66.10 & 3.95 & 11.03 & 64.27  &69.82   &6.89    & 91.44 & 2.69 & 8.38 & 78.88 &83.91  &27.10 &2.79  \\
              % CG-SAC     & 78.00 & 2.40 & 6.89  & 68.07  &73.45   &7.02    & 87.52 & 2.42 & 7.66 & 75.32 &80.32  &25.78  & 0.27 \\
              SC$^2$-PCR~\cite{chen2022sc2} &83.24	&2.21	&6.70	&73.64	&78.78	&	289.17
              &93.16	&2.11	&\underline{6.44}	&80.17	&87.24	&1140.85 &\underline{0.11}\\
              MAC~\cite{zhang20233d} &83.90 &2.11 &6.80 &- &-&- &93.72 &2.07 &6.52 &- &-&- &0.95\\
              % SC$^2$-PCR++ &86.81	&2.13	&6.59	&76.34	&81.43	&7.26	&93.47	&2.1	&6.54	&80.06	&87.15	&27.45 &0.26\\
              FastMAC~\cite{zhang2024fastmac} &82.87 &2.15 &6.73 &- &-&- &92.67 &2.00 &6.47 &- &-&- &0.27\\
              % Regor (\emph{ours}) & \textbf{88.54} &\textbf{1.67} &\textbf{5.90}& \textbf{82.91}	&\textbf{1255.48}	&\textbf{61.86} & \textbf{94.21}	&\textbf{1.69}	&\textbf{6.02}	&\textbf{87.92}	&\textbf{267.34} &\textbf{62.84} \\
              Regor (\emph{ours})&\textbf{88.48}  &\textbf{1.70} &\textbf{5.94} &\textbf{82.68} &\textbf{1253.74} & \textbf{2532.40}   &\underline{93.96}  &\textbf{1.75} &\textbf{6.14} &\textbf{87.48} &\textbf{263.81} &\textbf{2620.30} &0.36
  
              \\
              \bottomrule
      \end{tabular}
      }
      % \vspace{-5pt}
      \caption{Quantitative comparison on the {3DMatch} dataset with descriptors FPFH~\cite{FPFH} and FCGF~\cite{choy2019fully}.}
      \label{3dmatch2}
  \end{table*}
  

\section{Experiment}
We evaluate our algorithm using 
the indoor 3DMatch dataset~\cite{zeng20173dmatch} and the outdoor KITTI dataset~\cite{KITTIdataset}, 
demonstrating its superior performance. 
Furthermore, we introduce the 3DMatch-EOR benchmark and conduct experiments to demonstrate the effectiveness of our method in scenarios with very few correct initial correspondences.
Additionally, we 
also conduct robustness test experiments to verify that our 
algorithm can achieve robust registration using only weak features, 
thereby demonstrating its robustness across different descriptors. 
% Finally, we conduct runtime analysis and ablation study to illustrate 
% our algorithm's competitive efficiency and to validate the effectiveness of each module.
Finally, we conduct ablation studies to validate the effectiveness of each module.

\ptitle{Evaluation Metric.}
Following~\cite{chen2022sc2,zhang20233d}, 
we use registration recall (RR), rotation error (RE), and translation 
error (TE) to evaluate registration performance. For outdoor scenes, 
we consider a registration successful if the error is within 
(5$^{\circ}$, 60 cm), and for indoor scenes, within (15$^{\circ}$, 30 cm). 
Additionally, we assess the quality of correspondences using feature matching recall (FMR) and inlier precision (IP) 
which represents the proportion of inliers to the total correspondences. 
To further demonstrate our method's ability to generate a higher number of 
accurate correspondences, we define two new metrics: inlier number ratio (INR) 
and inlier numbers (IN). INR represents the ratio of the final number of 
inliers $\mathrm{IN}_{final}$ to the initial number of inliers $\mathrm{IN}_{initial}$,
defined explicitly in Appendix.
% defined as
% $\mathrm{INR} = \frac{\mathrm{IN}_{final}}{\mathrm{IN}_{initial}}$.
% \begin{equation}
% \mathrm{INR} = \frac{\mathrm{IN}_{final}}{\mathrm{IN}_{initial}}, \quad \mathrm{NR} = \frac{\mathrm{N}_{final}}{\mathrm{N}_{initial}}
% \end{equation}

\subsection{Evaluation on Indoor Scenes}\label{Indoor1}

\ptitle{Experimental Setup.}
For indoor scenes, we utilize the 3DMatch dataset. 
Our method is validated on both 3DMatch~\cite{zeng20173dmatch} and 3DLoMatch benchmarks~\cite{huang2021predator}. 
Following~\cite{PointDSC,chen2022sc2}, we perform voxel 
downsampling on the raw point clouds, and use two descriptors, 
FPFH~\cite{FPFH} and FCGF~\cite{choy2020deep}, to extract features as inputs for each method. 
% The comparative methods are configured according to their official settings.

\begin{figure}[t]
    \centering{\includegraphics[width=1.0\linewidth]{corr1_2.pdf}}
    % \setlength{\abovecaptionskip}{-6pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{Correspondences before and after processing.}
    \label{fig:processing}
\end{figure}


\begin{table}[t]
    % \scriptsize
    % \setlength{\tabcolsep}{3.5pt}
    % \renewcommand\tabcolsep{2.8pt}
    \renewcommand{\arraystretch}{0.9}
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|cccccc}
    \toprule
    & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{INR(\%)}  &{IN(/)} \\
    \midrule
    \multicolumn{7}{c}{\textbf{FPFH}}\\
    \midrule

    % DHVR     &23.87 &4.54   &10.63  &22.09  &24.38  &2.11\\
    % DGR&56.19    &4.76    &10.54   &48.92 &57.28 &52.60  \\
    PointDSC~\cite{PointDSC} &27.91	&4.27	&10.45	&23.80	&25.76	&46.52\\
    VBReg~\cite{jiang2023robust} &30.83 &4.38 &10.92 &26.61 &29.70  & 48.41\\ 
    Hunter~\cite{yao2023hunter}  &36.90  &3.89   &10.05  &\underline{31.55}  &\underline{36.17}  &\underline{56.01}\\
    % SM \\
    % CG-SAC   \\
    RANSAC~\cite{fischler1981random} &19.83	&4.67	&10.32	&30.82 &21.20	&37.02 \\
    SC$^2$-PCR~\cite{chen2022sc2}   &35.93	&4.26	&10.86	&30.11	&35.65	&55.23\\
    MAC~\cite{zhang20233d} &\underline{40.88} &\underline{3.66} &\underline{9.45}  &- &-&-\\
    % SC$^2$-PCR++ &41.04	&3.86	&10.20	&34.32	&39.97	&2.31\\
    FastMAC~\cite{zhang2024fastmac} &38.46 &4.04 &10.47 &- &-&-\\
    % PCRegen (\emph{ours})  &\textbf{44.58}	&\textbf{2.99}	&\textbf{9.12}	&\textbf{38.30}	&\textbf{815.79}	&\textbf{39.64}
    PCRegen (\emph{ours})  &\textbf{43.96}  &\textbf{2.89} &\textbf{8.93} &\textbf{37.73} &\textbf{778.35} &\textbf{643.24} 
    \\
    \midrule

    % \multicolumn{7}{c}{\textbf{FCGF}}\\
    % % & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{IR(\%)}  &{F1(\%)} \\
    % \midrule
    % % DHVR &54.41 &4.14 &12.56 &41.96 &51.09 &9.02\\
    % % DGR&56.19    &4.76    &10.54   &48.92 &57.28 &52.60  \\
    % PointDSC~\cite{PointDSC} &55.31	&3.85	&10.44	&43.00  &51.22	&9.19\\
    % VBReg~\cite{jiang2023robust}    &58.21 &3.98   &10.56  &44.21  &52.01  &9.22 \\ 
    % Hunter~\cite{yao2023hunter}   &60.87 &3.42   &9.88   &47.90  &56.88  &9.33\\
    % % SM  \\
    % % CG-SAC  \\
    % RANSAC~\cite{fischler1981random}       &46.38 &5.00 &13.11 &40.70 &51.42 &8.91 \\
    % SC$^2$-PCR~\cite{chen2022sc2}   &58.17	&3.8	&10.65	&45.51	&54.89	&9.35 \\
    % MAC~\cite{zhang20233d}   \\
    % % SC$^2$-PCR++  &60.36	 &3.69	 &10.30	 &47.05	  &56.39   &9.18\\
    % FastMAC~\cite{zhang2024fastmac} \\
    % Regor (\emph{ours}) &\textbf{62.83}	&\textbf{3.11}	&\textbf{9.43}	&\textbf{53.31}	&\textbf{300.58}	&\textbf{40.01} \\
    % \midrule

    \multicolumn{7}{c}{\textbf{Predator}}\\
    % & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{IR(\%)}  &{F1(\%)} \\
    \midrule
    % DHVR &65.41    &4.97    &12.33 & 54.75 &64.98 &23.76     \\
    % DGR&56.19    &4.76    &10.54   &48.92 &57.28 &52.60  \\
    PointDSC~\cite{PointDSC}  &68.30  &\underline{3.45}	&\textbf{9.44}	&56.35	&66.70	&863.40\\
    VBReg~\cite{jiang2023robust}     &69.82  &3.87  &10.07  &56.90  &67.09  &872.05\\ 
    Hunter~\cite{yao2023hunter}    &\underline{71.10}  &3.58  &9.72   &58.90  & \underline{69.06} &\underline{892.07}\\
    RANSAC~\cite{fischler1981random}  &64.85 &4.28 &11.04 &56.44 &66.81 & 869.21\\
    SC$^2$-PCR~\cite{chen2022sc2}    &69.46	&3.48	&9.63	&58.07	&68.63	&883.59\\
    MAC~\cite{zhang20233d} & 70.91 &3.69 &9.81 &- &-&-\\
    % SC$^2$-PCR++ &71.42	&3.47	&9.75	&59.05	&69.47	&24.57\\
    FastMAC~\cite{zhang2024fastmac} &68.77 &3.90 &10.32 &- &-&-\\
    % Regor (\emph{ours}) &\textbf{72.77}	&\textbf{3.13}	&\textbf{9.48}	&\textbf{64.34}	&\textbf{226.76}	&\textbf{61.81}\\
    PCRegen (\emph{ours})  &\textbf{72.04}  &\textbf{3.17} &\underline{9.46} &\textbf{63.95} &\textbf{220.46} &\textbf{2138.47}  \\
    \bottomrule
    \end{tabular}}
    % \vspace{-5pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{
        Quantitative comparison on the 3DLoMatch Dataset.
    }
    \label{table:3DLoMatch}
\end{table}

\begin{figure*}[t]
    \centering{\includegraphics[width=1.0\textwidth]{corr_new.pdf}}  %0.32
    % \setlength{\abovecaptionskip}{-8pt}
    \caption{Correspondences visualization in different stages.}
    \label{fig:corr}
\end{figure*}


%长表
\begin{table*}[htbp]
    \scriptsize
    \renewcommand{\arraystretch}{0.9}
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|ccccccc|ccccccc}
    \toprule
    & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IP(\%)}  &{INR(\%)}  &{IN(/)}   & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IP(\%)}  &{INR(\%)}  &{IN(/)}\\

    \midrule
    &\multicolumn{14}{c}{\emph{Outlier ratio above 90\%}}\\
    \midrule
    & \multicolumn{7}{c|}{{3DMatch}} & \multicolumn{7}{c}{{3DLoMatch}}\\
    \midrule
    PointDSC~\cite{PointDSC} &71.12 &2.52 &7.79 &77.76 &60.05 &63.55 &129.12  
    &23.27 &4.84 &12.94 &39.78 &18.16 &26.57 &31.18\\
    SC$^2$-PCR~\cite{chen2022sc2}   &78.58	&2.49	&7.73	&84.02	&51.91		&{73.73}	&{138.98}  &35.39	&4.29	&10.96	&42.58	&29.6		&{35.14}	&{49.73}\\
    % PCRegen (\emph{ours}) &84.65	&1.86	&6.71	&87.01	&77.95	&\textbf{1453.66}	&\textbf{1819.3}  &43.61	&2.95	&9.26	&46.34	&36.94		&\textbf{788.04}	&\textbf{627.09}\\
    PCRegen (\emph{ours}) &\textbf{84.88} &\textbf{1.86} &\textbf{6.67} &\textbf{86.38} &\textbf{78.14} &\textbf{1457.54} &\textbf{2334.36}   &\textbf{43.50} &\textbf{2.95} &\textbf{9.24} &\textbf{46.34} &\textbf{36.96} &\textbf{780.05} &\textbf{632.62}\\
    
    \midrule
    &\multicolumn{14}{c}{\emph{Outlier ratio above 99\%}}\\
    \midrule
    & \multicolumn{7}{c|}{{3DMatch}} & \multicolumn{7}{c}{{3DLoMatch}}\\
    \midrule
    PointDSC~\cite{PointDSC} &2.56 &5.12 &15.28 &10.90 &3.07 &4.88 &0.17      &0.75 &4.93 &29.34 &0.75 &0.08 &1.46 &0.02\\
    SC$^2$-PCR~\cite{chen2022sc2}   &9.15	&4.94	&12.21	&16.20	&6.08  &{9.61}	&{0.34} &3.28	  &5.94	&19.44	&7.88	&2.47	&{4.96}	&{0.89}\\
    % PCRegen (\emph{ours}) &27.46	&2.15	&8.6	&32.39	&21.98	&\textbf{1594.03}	&\textbf{675}    &9.27	&3.49	&11.84	&11.84	&6.49	&\textbf{298.79}	&\textbf{60.4}\\
    PCRegen (\emph{ours}) &\textbf{26.76} &\textbf{2.17} &\textbf{8.60} & \textbf{28.87} &\textbf{21.54} &\textbf{1545.12} &\textbf{666.94}    &\textbf{9.27} &\textbf{3.36} &\textbf{12.39} &\textbf{11.84} &\textbf{6.30} &\textbf{291.40} &\textbf{118.45}\\
    
    \bottomrule

    \end{tabular}
    }
    % \vspace{-5pt}
    \caption{
        Results on the 3DMatch-EOR benchmark with extreme outlier ratios.
    }
    \label{table:extreme}
\end{table*}

\ptitle{Result on 3DMatch.}
We compare our method against several baselines on the 3DMatch dataset, 
including PointDSC~\cite{PointDSC}, 
VBReg~\cite{jiang2023robust}, Hunter~\cite{yao2023hunter}, SM~\cite{leordeanu2005spectral}
TEASER~\cite{yang2020teaser}, RANSAC~\cite{fischler1981random}, 
SC$^2$-PCR ~\cite{chen2022sc2}, MAC~\cite{zhang20233d}, and 
FastMAC~\cite{zhang2024fastmac}. The first three baselines are learning-based methods, 
while others are geometry-based approaches. 
The results are summarized in Table~\ref{3dmatch2}.
Our method outperforms the previous state-of-the-art~\cite{chen2022sc2, zhang20233d}. 
Using the FPFH~\cite{choy2019fully}, our method outperforms all others across all metrics. Notably, our method 
achieves 88.48\% RR, 
surpassing SC$^2$-PCR~\cite{chen2022sc2} by 5.2 percentage points (pp).
% It indicates that our method can achieve robust registration even with weak features.
It also achieves more accurate registration with the lowest RE and TE. 
One significant advantage 
of our method is obtaining more high-quality correspondences, as reflected in the INR and IN. 
Our Regor achieves a 1253.74\% INR, 
which is much better than 78.78\% of SC2-PCR. 
% This indicates that our regeneration approach results in a final set of correct correspondences that is 1255.48\% times 
% the initial set of correct correspondences, and the final set of correspondences is 61.86\% times the initial set.
% Compared to SC$^2$-PCR++~\cite{chen2023sc2}, our method improved INR and NR by approximately 10 times with FPFH descriptor. 
% It demonstrates that our local regeneration strategy can capture more 
% accurate correspondences, addressing the challenge of achieving 
% robust registration with a limited number of initial inliers.
% This is also why our method can achieve robust registration even with weak features.
% Despite the progressive iterations, our method is also faster than SC$^2$-PCR++ and $2\times$ 
% faster than RANSAC with 4M iterations. Thus, our method ensures 
% efficiency while maintaining robust performance.
Previous methods~\cite{chen2022sc2, zhang2024fastmac, zhang20233d} only perform top-down filtering, which inevitably limits the INR to below 100\%. In contrast, our Regor regenerates more high-quality correspondences, producing around 10 times the original amount. This advantage allows our method to achieve robust registration even when there are few initial correct correspondences. Moreover, despite employing multiple iterations, it still maintains a comparable speed to the baselines~\cite{jiang2023robust, yao2023hunter} due to its simple sampling strategy and efficient consistency computation.



% %
% %长表
% \begin{table*}[h]
%     \caption{
%         Results under extreme outliers above 99\%
%         % (For DHVR, the
%         % training code and  pretraining model
%         % on KITTI dataset are not released, so we report the results in their paper).
%     }
%     \scriptsize
%     % \setlength{\tabcolsep}{3.5pt}
%     % \renewcommand\tabcolsep{2.8pt}
%     \renewcommand{\arraystretch}{0.9}
%     \centering
%     \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|ccccccc|ccccccc}
%     \toprule
%     & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IR(\%)}  &{INR(\%)}  &{IN(/)}   & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IR(\%)}  &{INR(\%)}  &{IN(/)}\\
%     \midrule
%     &\multicolumn{14}{c}{\emph{Outlier ratio above 99\%}}\\
%     \midrule
%     & \multicolumn{7}{c|}{{3DMatch}} & \multicolumn{7}{c}{{3DLoMatch}}\\
%     \midrule
%     PointDSC~\cite{PointDSC}\\
%     SC$^2$-PCR~\cite{chen2022sc2}   &9.15	&4.94	&12.21	&16.2	&6.08  &\textcolor{red}{9.61}	&\textcolor{red}{0.34} &3.28	  &5.94	&19.44	&7.88	&2.47	&\textcolor{red}{4.96}	&\textcolor{red}{0.89}\\
%     PCRegen (\emph{ours}) &27.46	&2.15	&8.6	&32.39	&21.98	&\textbf{1594.03}	&\textbf{675}    &9.27	&3.49	&11.84	&11.84	&6.49	&\textbf{298.79}	&\textbf{60.4}\\

%     \bottomrule

%     \end{tabular}
%     }
%     \label{table:extreme}
 
% \end{table*}



% \begin{table*}[h]
%     \caption{
%         Results under extreme outliers above 90\%
%         % (For DHVR, the
%         % training code and  pretraining model
%         % on KITTI dataset are not released, so we report the results in their paper).
%     }
%     \scriptsize
%     % \setlength{\tabcolsep}{3.5pt}
%     % \renewcommand\tabcolsep{2.8pt}
%     \renewcommand{\arraystretch}{0.9}
%     \centering
%     \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|cccccccc|cccccccc}
%     \toprule
%     & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IR(\%)}   &{IR-R(\%)}  &{IN-R(\%)} &{Inlier number(-)}   & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{FMR(\%)} &{IR(\%)}  &{IR-R(\%)}  &{IN-R(\%)} &{Inlier number(-)}\\
%     \midrule
%     & \multicolumn{8}{c|}{{3DMatch}} & \multicolumn{8}{c}{{3DLoMatch}}\\
%     \midrule
%     SC$^2$-PCR   &78.58	&2.49	&7.73	&84.02	&51.91	&1905.46	&\textcolor{red}{73.73}	&\textcolor{red}{138.98}  &35.39	&4.29	&10.96	&42.58	&29.6	&1387.11	&\textcolor{red}{35.14}	&\textcolor{red}{49.73}\\
%     PCRegen (\emph{ours}) &84.65	&1.86	&6.71	&87.01	&77.95	&2497.67	&\textbf{1453.66}	&\textbf{1819.3}  &43.61	&2.95	&9.26	&46.34	&36.94	&1958.36	&\textbf{788.04}	&\textbf{627.09}\\

%     \bottomrule

%     \end{tabular}
%     }
%     \label{table:extreme2}
 
% \end{table*}


\ptitle{Result on 3DLoMatch.}
% We validate our method's robustness 
% to low overlap using the 3DLoMatch dataset, 
% employing FPFH~\cite{FPFH} and Predator~\cite{huang2021predator} for feature extraction.
Since Predator~\cite{huang2021predator} is specifically designed for scenarios with low overlap, we use Predator~\cite{huang2021predator} and FPFH~\cite{FPFH} to extract features on 3DLoMatch.
The comparative results are presented in Table~\ref{table:3DLoMatch}. 
Our approach achieves the highest RR and RE on 3DLoMatch, regardless of the descriptors used.
Due to the inherent weakness of FPFH, nearly all baselines perform poorly on 3DLoMatch. 
In contrast, our method shows significant performance improvement, 
surpassing MAC~\cite{zhang20233d} by 3.08 pp. 
% Even when compared to learning-based methods~\cite{PointDSC, jiang2023robust,yao2023hunter}, 
% our method still demonstrate notable advantages.

\ptitle{Result on 3DMatch-EOR.}
The key to the effectiveness of our method lies in its ability to generate more accurate correspondences, particularly in scenarios with extremely high outlier ratios. To validate this, we select extreme outlier ratio cases from the 3DMatch/3DLoMatch datasets and propose the 3DMatch-EOR benchmark which is described in Appendix. We establish two benchmarks with outlier rates exceeding 99\% and 90\%, respectively. Our method is compared to SC2-PCR~\cite{chen2022sc2} and PointDSC~\cite{PointDSC}, with results shown in Table~\ref{table:extreme}. In cases with such high outlier rates, achieving robust registration is exceptionally challenging, as the number of initial correct correspondences is minimal. When the outlier rate exceeded 99\%, the average inlier count of SC2-PCR is less than 1, leading to registration failure and achieving only 9.15\%/3.28\% in RR. In contrast, our method achieves an average of 667 inliers, an improvement of nearly 2000 times compared to SC2-PCR~\cite{chen2022sc2}, resulting in a 26.76\% RR. Our Regor enables success in scenarios where failure would otherwise be inevitable,
allowing for relatively robust registration even with few initial inliers.



\subsection{Evaluation on Outdoor Scenes}\label{Outdoor}

\ptitle{Experimental Setup.}
Following~\cite{chen2023sc2,zhang20233d}, 
we validate our method's performance on the outdoor KITTI dataset. 
We select sequences  8 to 10 for testing. Consistent with the settings~\cite{chen2022sc2}, 
we perform downsampling using a 30 cm voxel grid and extract features using FPFH descriptors.


% \begin{table}[h]
%     \scriptsize
%     % \setlength{\tabcolsep}{3.5pt}
%     % \renewcommand\tabcolsep{2.8pt}
%     \renewcommand{\arraystretch}{0.9}
%     \centering
%     \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|cccccc}
%     \toprule
%     & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{INR(\%)}  &{NR(\%)} \\
%     \midrule
%     \multicolumn{7}{c}{\textbf{FPFH}}\\
%     \midrule

%     % DHVR  &- &- &- &- &- &- \\
%     % DGR&77.12    &1.64    & 33.10   &96.90 &0.34 &21.70  \\
%     PointDSC   &99.46	&0.57	&7.22	&91.39	&93.05	&3.31\\
%     VBReg   &98.92 &8.39  &8.41  &90.82 &92.13 &3.38\\
%     Hunter  &99.82 &0.55  &6.29  &92.11 &94.58 &3.26\\
%     % CG-SAC   \\
%     RANSAC   &74.41 &1.55  &30.20  &  &  &\\
%     SC$^2$-PCR   &99.82	&0.61	&8.16	&93.59	&95.94	&3.27\\
%     MAC     \\
%     SC$^2$-PCR++  &99.64   &0.62	&8.17	&93.18	&95.55	&3.02\\
%     FastMAC \\
%     PCRegen (\emph{ours}) &\textbf{99.82}	&\textbf{0.50}	&\textbf{5.36}	&79.57	&\textbf{2486.82}	&\textbf{84.24}\\
%     \midrule

%     \multicolumn{7}{c}{\textbf{FCGF}}\\
%     % & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{IR(\%)}  &{F1(\%)} \\
%     \midrule
%     % DHVR  &99.10 &\\
%     % DGR&56.19    &4.76    &10.54   &48.92 &57.28 &52.60  \\
%     PointDSC &98.56	&0.40	&20.93	&81.62	&90.47	&44.34\\
%     VBReg  &98.20	&0.49	&20.35& 80.76	&89.97	&43.23\\
%     Hunter  &98.20	&0.30	&19.82& 81.10	&90.01	&43.91\\
%     % SM  \\
%     % CG-SAC  \\
%     RANSAC  &80.36 & 0.73  &26.79  &  &  &\\
%     SC$^2$-PCR   &97.84	&0.47	&20.7	&\textbf{81.75}	&90.66	&42.93\\
%     MAC   \\
%     SC$^2$-PCR++ &98.56	&0.51	&20.44	&81.63	&90.42	&39.84\\
%     FastMAC \\
%     PCRegen (\emph{ours}) &\textbf{98.92}	&\textbf{0.47}	&\textbf{7.85}	&{78.51}	&\textbf{411.49}	&\textbf{134.26}\\
%     \bottomrule

%     \end{tabular}
%     }
%     \vspace{-5pt}
%     \caption{
%         Quantitative comparison on KITTI Dataset. 
%     }
%     \label{table:kitti}
    
% \end{table}


\begin{table}[htbp]
    % \scriptsize
    % \setlength{\tabcolsep}{3.5pt}
    % \renewcommand\tabcolsep{2.8pt}
    \renewcommand{\arraystretch}{0.9}
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|cccccc}
    \toprule
    & {RR(\%)} & {RE($^{\circ}$)} & {TE(cm)} &{IP(\%)}  &{INR(\%)}  &{IN(/)} \\
    \midrule
    % DHVR  &- &- &- &- &- &- \\
    % DGR&77.12    &1.64    & 33.10   &96.90 &0.34 &21.70  \\
    PointDSC~\cite{PointDSC}   &99.46	&0.57	&7.22	&91.39	&93.05	&247.11\\
    VBReg~\cite{jiang2023robust}   &98.92 &8.39  &8.41  &90.82 &92.13 &246.09\\
    Hunter~\cite{yao2023hunter}  &\textbf{99.82} &\underline{0.55}  &\underline{6.29}  &\underline{92.11} &94.58 & 247.50\\
    % CG-SAC   \\
    RANSAC~\cite{fischler1981random}   &74.41 &1.55  &30.20  &85.29 &87.20 &189.70 \\
    SC$^2$-PCR~\cite{chen2022sc2}   &\textbf{99.82}	&0.61	&8.16	&\textbf{93.59} &\underline{95.94}	&\underline{248.46}\\
    MAC~\cite{zhang20233d}   &99.46	&0.59	&8.70 &- &- &-   \\
    FastMAC~\cite{zhang2024fastmac} &98.02 &\underline{0.55} &8.24  &- &- &-\\
    Regor (\emph{ours}) &\textbf{99.82}	&\textbf{0.50}	&\textbf{5.36}	&79.57	&\textbf{2486.82}	&\textbf{5353.22}\\
    \bottomrule

    \end{tabular}
    }
    % \vspace{-5pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{
        Quantitative comparison on the KITTI Dataset. 
    }
    \label{table:kitti}
\end{table}
 

\ptitle{Result on KITTI.}
We conduct comparative experiments between our method and
PointDSC~\cite{PointDSC}, VBReg~\cite{jiang2023robust}, Hunter~\cite{yao2023hunter}, 
RANSAC~\cite{fischler1981random}, SC$^2$-PCR~\cite{chen2022sc2}, 
MAC~\cite{zhang20233d}, and FastMAC~\cite{zhang2024fastmac} on the KITTI dataset. 
The results are presented in Table~\ref{table:kitti}. 
Our Regor achieves the best performance with the highest RR, outperforming RANSAC~\cite{fischler1981random} by 25.41 pp. 
It also demonstrates 
lower RE and TE, achieving the most accurate registration. 
Furthermore, our method shows superior performance in generating new correspondences, 
with INR over 25 times higher than those of other baselines~\cite{yao2023hunter,chen2022sc2}.
Despite IP is lower compared to SOTA~\cite{chen2022sc2}, 
our method achieves more accurate pose estimation
due to a larger number of high-quality inliers.
% results in a significantly larger number of high-quality correspondences. 
% This is why our method achieves better registration performance, even with lower IP.


\begin{figure}[t]
    \centering{\includegraphics[width=1.0\linewidth]{1.pdf}}
    % \setlength{\abovecaptionskip}{-7pt}
    \caption{RR under different features.}
    \label{fig:Features}
\end{figure}

% \begin{table}[htbp]
%     \scriptsize
%     \setlength{\tabcolsep}{1.5pt}
%     \centering
%     \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|lll|lll}
%     \toprule
%     & \multicolumn{3}{c|}{{3DMatch}} & \multicolumn{3}{c}{{3DMatch-EOR}}\\
%     Method & RR(\%)$\uparrow$  & IP(\%)$\uparrow$ & IN(/)$\uparrow$ & RR(\%)$\uparrow$  & IP(\%)$\uparrow$ & IN(/)$\uparrow$\\
%     \midrule
%     FPFH &54.34  & 45.74  &228.71  &0    &1.84 &9.19 \\
%     FPFH + Regor &88.48 (+34.14) &82.68 (+36.44) &1253.74 (\times5.48)  &26.76 &21.54 &666.94\\
%     \hline
%     PFH   &69.38 &57.28 &286.38   &0 &1.08 &5.40\\
%     PFH + Regor &89.28 &81.72 &2477.39  &10.26 &6.34 &185.19\\
%     \hline
%     RoPS   &54.16 &42.49 &212.46   &0 &2.23 &11.17\\
%     RoPS + Regor &91.37 &84.29 &2542.32  &33.66 &27.23 &713.02\\
%     \hline
%     SHOT   & 55.33&46.01 &229.50    &0 &0.44 &2.19\\
%     SHOT + Regor &71.90 &66.41 &1981.10 &3.40 &3.02 &72.57\\
%     \hline
%     FCGF &86.32   & 56.85  &405.27  &5.00   &0.32 &1.60\\
%     FCGF + Regor   &93.96 &87.48 &2620.30   &5.56 &0.63 &4.33\\
%     \hline
%     SpinNet &88.60    &47.53  &444.84  &8.33    &1.03& 5.17\\
%     SpinNet + Regor &96.30 &88.24 &2799.74   &30.00 &11.30 &164.90\\
%     \hline
%     Predator &89.00    &58.01  &444.38  &-    &- &-\\
%     Predator + Regor  &91.44 &86.84 &4608.34   &6.25 &4.25 &138.84\\
%     % \hline
%     % CoFiNet &89.30    &49.80  &  &67.50  &24.42 &\\
%     % CoFiNet+Regor & & &   & & &\\
%     \hline
%     GeoTrans  &91.80 &75.20 &449.85   &- &- &-\\
%     GeoTrans + Regor  &97.10 &91.01 &2649.30   &16.67 &0.63 &4.33\\
%     \bottomrule
%     \end{tabular}
%     }
%     \vspace{-5pt}
%     \caption{
%         Enhancement of feature-based methods.
%     }
%     \label{Henhancement}
%  \end{table}


\begin{table}[t]
    % \scriptsize
    \setlength{\tabcolsep}{1.5pt}
    \centering
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|lll}
    \toprule
    Method & RR(\%)$\uparrow$  & IP(\%)$\uparrow$ & IN(/)$\uparrow$ \\
    \midrule
    FPFH~\cite{FPFH} &54.34  & 45.74  &228.71   \\
    FPFH~\cite{FPFH} + Regor &88.48 (+\textbf{34.14}) &82.68 (+\textbf{36.94}) &1253.74 ($\times$\textbf{5.48})  \\
    \hline
    PFH~\cite{PFH}   &69.38 &57.28 &286.38   \\
    PFH~\cite{PFH} + Regor &89.28 (+\textbf{19.90}) &81.72 (+\textbf{24.44}) &2477.39 ($\times$\textbf{8.65}) \\
    \hline
    RoPS~\cite{guo2013rotational}   &54.16 &42.49 &212.46  \\
    RoPS~\cite{guo2013rotational} + Regor &91.37 (+\textbf{37.21}) &84.29 (+\textbf{41.80}) &2542.32 ($\times$\textbf{11.96})  \\
    \hline
    SHOT~\cite{salti2014shot}   & 55.33&46.01 &229.50   \\
    SHOT~\cite{salti2014shot}  + Regor &71.90 (+\textbf{16.57}) &66.41 (+\textbf{20.40}) &1981.10 ($\times$\textbf{8.63}) \\
    \hline
    FCGF~\cite{choy2019fully} &86.32   & 56.85  &405.27  \\
    FCGF~\cite{choy2019fully} + Regor   &93.96 (+\textbf{7.64}) &87.48 (+\textbf{30.63}) &2620.30 ($\times$\textbf{6.46})   \\
    \hline
    SpinNet~\cite{ao2021spinnet} &88.60    &47.53  &444.84  \\
    SpinNet~\cite{ao2021spinnet} + Regor &96.30 (+\textbf{7.70}) &88.24 (+\textbf{40.71}) &2799.74 ($\times$\textbf{6.29})   \\
    \hline
    Predator~\cite{huang2021predator} &89.00    &58.01  &444.38 \\
    Predator~\cite{huang2021predator} + Regor  &91.44 (+\textbf{2.44}) &86.84 (+\textbf{28.83}) &4608.34 ($\times$\textbf{10.37})   \\
    % \hline
    % CoFiNet &89.30    &49.80  &  &67.50  &24.42 &\\
    % CoFiNet+Regor & & &   & & &\\
    \hline
    GeoTrans~\cite{qin2022geometric}  &91.80 &75.20 &449.85   \\
    GeoTrans~\cite{qin2022geometric} + Regor  &\textcolor{red}{97.10} (+\textbf{5.30}) &91.01 (+\textbf{15.81}) &2649.30 ($\times$\textbf{5.88})   \\
    \bottomrule
    \end{tabular}
    }
    % \vspace{-5pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{
        Enhancement of feature-based methods.
    }
    \label{Henhancement}
 \end{table}

\subsection{Robustness to Different Features}
To further assess the robustness of various descriptors, 
we also test with traditional descriptors such as 
FPFH~\cite{FPFH}, SHOT~\cite{salti2014shot}, PFH~\cite{PFH}, and PoRS~\cite{guo2013rotational}, 
as well as learning-based descriptors like SpinNet~\cite{ao2021spinnet}, 
FCGF~\cite{choy2019fully},
Predator~\cite{huang2021predator}, 
and GeoTrans~\cite{qin2022geometric}. As shown in Table~\ref{Henhancement}, 
our Regor consistently improves performance across all features, which demonstrates it is robust to different features.
% Notably, when using previous SpinNet, 
% our method achieves an RR 96.80\%/72.38\% of on the 3DMatch/3DLoMatch datasets, respectively. 
Notably, GeoTrans~\cite{qin2022geometric}+Regor achieves a SOTA RR of 97.10\%.

\ptitle{Good Performance with Weak Features.}
% In the previous section, we evaluate the performance of our method using FPFH and FCGF descriptors. 
Moreover, our method significantly enhance 
the performance of the weak descriptors,
increasing the RR from 54.16\% to 91.37\% with RoPS~\cite{guo2013rotational}.
% As can be seen in Figure~\ref{fig:Features}, our Regor makes traditional descriptors~\cite{PFH, guo2013rotational, FPFH} comparable to learning-based methods~\cite{choy2019fully,ao2021spinnet,huang2021predator}.
As can be seen in Figure~\ref{fig:Features}, with our Regor, the traditional descriptors~\cite{PFH, guo2013rotational, FPFH} achieves 88\%+ RR, surpassing the learning-based baseline~\cite{choy2019fully}.
% For the challenging 3DMatch-EOR benchmark, correct registration cannot be achieved using any traditional descriptor. 
When combined with our Regor, 
RoPS~\cite{guo2013rotational} exhibits performance that exceeds the learning-based methods~\cite{choy2019fully,ao2021spinnet,huang2021predator}, only second to GeoTrans~\cite{qin2022geometric}.
This demonstrates that our method can achieve robust registration even with weak features. 
% Thanks to our regeneration idea, our method significantly enhances the performance of registration based on traditional descriptors, 
% increasing the RR from 70\% to 80\% and the IR from 60\% to 80\%.


% \ptitle{Robustness to low inlier number}
% Our motivation for proposing the progressive regeneration method stems 
% from the observation that point cloud registration methods based 
% on outlier removal struggle when the initial number of correct 
% correspondences is low. 
% To validate the advantages of our method in these scenarios, 
% we set varying levels of registration difficulty 
% based on the initial number of inliers 
% and compare its performance with other methods.
% As shown in Table 5, our method consistently achieves superior 
% performance across different levels of initial inliers. Notably, 
% our method demonstrates great advantages when the initial 
% number of inliers is low. Specifically, our approach shows a 
% 20 pp improvement over other outlier removal 
% methods when the initial number of inliers ranges from 0 to 100, 
% and 20 pp under 100 to 200. Unlike previous outlier removal techniques, 
% our method introduces a novel approach to regeneration, effectively addressing 
% the challenge of achieving accurate registration 
% with a limited number of initial inliers.


% \subsection{Time Profiling}

\subsection{Ablation Study}\label{sec.Ablation}


% \begin{table}[htbp]
%     % \setlength{\tabcolsep}{3.5pt}
%     \centering
%     % \setlength{\tabcolsep}{2pt}
%     % \scriptsize
%     \resizebox{1.0\linewidth}{!}{
%     \begin{tabular}{l|l|ccc|ccc}
%     \toprule
%     & &\multicolumn{3}{c|}{3DMatch} & \multicolumn{3}{c}{3DMatch-EOR} \\
%     No.  &Methods        & RR  & RE& TE& RR & RE & TE \\
%     \midrule
%     1)         &One-stage   &86.81 &2.13 &6.59  &23.94 &4.41 &12.14 \\
%     2)         &Progressive*  &\textbf{88.48} &\textbf{1.70}  &\textbf{5.94}  &\textbf{26.76}  &\textbf{2.17} &\textbf{8.60} \\
%     \midrule
%     3)         &SM  &87.35&\textbf{1.70}&5.97 &25.06 &2.29 &\textbf{8.07}\\
%     4)         &MM  &86.81 &1.74 &6.01 &23.94 &1.94 &7.89              \\
%     5)         &GMM*  &\textbf{88.48} &\textbf{1.70}  &\textbf{5.94}  &\textbf{26.76}  &\textbf{2.17} &{8.60}  \\
%     \midrule
%     6)         &Only Local    &88.35  &1.74  &6.08  &26.06  &2.32  &\textbf{8.07} \\
%     7)         &Only Global  &87.37&1.76 &6.08  &24.65 &2.28 &8.11 \\
%     8)         &Local \& Global*  &\textbf{88.48} &\textbf{1.70}  &\textbf{5.94}  &\textbf{26.76}  &\textbf{2.17} &{8.60} \\
%     \midrule
%     9)         &SC &86.88 &1.74  &6.00    &22.54&2.39&8.97      \\
%     10)         &CTC*   &\textbf{88.48} &\textbf{1.70}  &\textbf{5.94}  &\textbf{26.76}  &\textbf{2.17} &\textbf{8.60}\\
%     \bottomrule
%     \end{tabular}
%     }
%     \vspace{-5pt}
%     \caption{Ablation study on 3DMatch and 3DMatch-EOR. }
%     \label{Ablation}
% \end{table}

\begin{table}[htbp]
    % \setlength{\tabcolsep}{3.5pt}
    \centering
    % \setlength{\tabcolsep}{2pt}
    % \scriptsize
    \resizebox{1.0\linewidth}{!}{
    \begin{tabular}{l|l|ccc|ccc}
    \toprule
    & &\multicolumn{3}{c|}{3DMatch} & \multicolumn{3}{c}{3DMatch-EOR} \\
    No.  &Methods        & RR  & IP& IN& RR & IP & IN \\
    \midrule
    1)         &One-stage   &86.81 &76.34 &290.32  &23.94 &15.88 &9.13 \\
    2)         &Progressive*  &\textbf{88.48} &\textbf{82.68}  &\textbf{2532.40}  &\textbf{26.76}  &\textbf{21.54}  &\textbf{666.94} \\
    \midrule
    3)         &NNM  &87.35&80.90&2487.23 &25.06 &19.82 &643.45\\
    4)         &MM  &86.81 &81.03 &2392.53 &23.94  &20.80 &600.09               \\
    5)         &GMM*  &\textbf{88.48} &\textbf{82.68}  &\textbf{2532.40}  &\textbf{26.76}  &\textbf{21.54}  &\textbf{666.94}  \\
    \midrule
    6)         &Only Local    &87.35  &78.40  &2526.63  &23.06  &17.32 &\textbf{668.08} \\ % maybe Global Have no effect
    7)         &Only Global  &76.37&80.48 &2502.21  &24.65 &16.57 &641.42 \\
    8)         &Local \& Global*  &\textbf{88.48} &\textbf{82.68}  &\textbf{2532.40}  &\textbf{26.76}  &\textbf{21.54}  &{666.94} \\
    \midrule
    9)         &SC &86.88 &81.09  &2491.54   &22.54&18.18&574.74      \\
    10)         &CTC*   &\textbf{88.48} &\textbf{82.68}  &\textbf{2532.40}  &\textbf{26.76}  &\textbf{21.54}  &\textbf{666.94}\\
    \bottomrule
    \end{tabular}
    }
    % \vspace{-5pt}
    % \setlength{\belowcaptionskip}{-6pt}
    \caption{Ablation study on 3DMatch and 3DMatch-EOR. }
    \label{Ablation}
\end{table}

We conduct ablation experiments 
on the 3DMatch and 3DMatch-EOR benchmarks using FPFH descriptor. 
% We verify the effectiveness of each module by removing other modules, 
% and the experimental results are shown in Table~\ref{Ablation}.
% The ablation results are shown in Table~\ref{Ablation}.

\ptitle{Progressive or One-stage.}
We verify the effectiveness of our progressive strategy by only using the one-stage process. The results are
shown in Table~\ref{Ablation} (1) and (2). Our strategy improves RR by 1.65/2.82 pp compared 
to the one-stage approach. 
It is attributed 
to the heuristic setting: 
starting with a larger radius ensures global optimality and robustness, 
and gradually reducing the radius with each iteration 
enhances accuracy.
More importantly, IN drops by 1$\sim$2 orders of magnitude, suggesting that our progressive strategy is key to generating more correspondences.

\ptitle{Matching Strategy.}
We replace our GMM with mutual matching (MM) and nearest neighbor matching (NNM).
Results are shown in Table~\ref{Ablation} (3), (4) and (5).
The model with GMM achieves the highest RR, IP, and IN.
Compared with MM, using GMM results in a significant improvement in IN, which indicates 
our GMM is helpful to generate more inliers
and addresses the issue of few initial inliers.


\ptitle{Local-Global Refinement.}
% Local-global correspondence refinement is crucial for 
% generating dense and high-quality correspondences. 
To demonstrate the importance of our correspondence refinement, 
we compare the complete model with two ablation models. 
The results, shown in Rows 6, 7, and 8 of Table ~\ref{Ablation}, indicate a 
significant performance drop when either local or global refinement is removed, 
with RR falling to 87\% and 86\%. In addition, the IP of the ablation model 
decreases by over 4 pp, which underscores the substantial 
contribution of the local-global refinement to the quality of the correspondences.

% \ptitle{Point-level correspondence verification.}
% Previous evaluation and verification indicators used IC~\cite{chen2022sc2}, MSE~\cite{yang2021toward} and FS-TCD~\cite{chen2023sc2}. 
% In this section, we replace these indicators with our PO-TCD evaluation 
% function to verify the validity of our point-level correspondence 
% verification. Refer to Tables 1 (6), and (7). Using PO-TCD, we obtaine lower RE 
% TE, demonstrating that PO-TCD helps achieve more accurate registration. 
% Additionally, our point-level correspondence verification resulted in a $100\times$ 
% improvement in INR and NR compared to IC. The PO-TCD effectively 
% leverages the regeneration strategy to generate dense correspondences, 
% ensuring that the final correspondences remain at a high quality level.

\ptitle{Spatial Compatibility.}
We compared the SOTA second-order consistency (SC)~\cite{chen2022sc2, chen2023sc2} with our CTC, and the results are shown at the bottom of Table~\ref{Ablation}. Our method with CTC obtains higher IP and IN, which indicates that CTC is more suitable for local refinement and achieves higher-quality correspondences. In addition, our CTC has less computational complexity than SC. Through it, we can implement an efficient iterative process.

\section{Conclusion}
% In this paper, we propose a new correspondence regeneration idea to enhance the point cloud registration effect.
% Unlike traditional outlier removal methods, 
% we introduces a novel progressive correspondence 
% regeneration approach that effectively addresses the issue of failure with very few correct initial correspondences. 
% Our method can generate more high-quality correspondences in order to facilitate more robust and accurate registration. Our method achieves the best performance on all datasets. Thanks to this correspondence, our method has great performance improvement under extreme outlier rates. Moreover, combined with our method, using weak features can achieve superior effects over learning-based features.


In this paper, we introduce a new idea for optimizing correspondences. Unlike previous methods that focus solely on outlier removal, our Regor effectively addresses the challenge of limited correct initial correspondences. By generating more high-quality correspondences, our method enables more robust and accurate registration, achieving state-of-the-art performance across all datasets. Notably, it demonstrates significant improvements even under extreme outlier conditions. When combined with our Regor, using traditional descriptors can also achieve robust registration.

% In each iteration, we determine the local correspondence region based on 
% the seed correspondences. This region reduces the solution space, 
% allowing for more accurate correspondences through re-matching. 
% We then perform local-global correspondence refinement to correct erroneous correspondences 
% both locally and globally. The local correspondences are merged using a hash table. 
% Through this iterative regeneration process, we progressively obtain more accurate correspondences. 
% Finally, we refine the transformation using point-level correspondence verification. 
% Extensive experiments demonstrate that our method achieves s
% uperior registration performance. Additionally, our approach excels in generating 
% correspondences and feature matching, achieving robust registration even when combined with weake features.





{\small
\bibliographystyle{ieeenat_fullname}
\bibliography{cvpr24}
}

% %************Appendx**********************
% \section*{Appendx}
% \subsection{Proof of Theorem 1}
% \ptitle{Theorem 1.}
% \emph{
%         Assuming event $\Phi $, where the geometric consistency of correct correspondences is greater than the maximum consistency of incorrect correspondences, 
%         has a probability ${P}(\Phi)\approx  1 $,
%         if the score of the local correspondences satisfies $Score(\mathcal{G}^{t}_i)\geqslant  1$, then the proportion of correct correspondences $b>=a$.
% }


% \emph{Proof.}
%     For simplicity, we denote the local correspondences and the consistency matrix as $\mathcal{{G}}$
%     and $\mathbf{S}_{\mathrm{SOG}}$, respectively. Thus, we can demonstrate that:
%     \begin{equation}
%        \begin{aligned} 
%         &P(Score(\mathcal{G}^{t}_i)\geqslant1) = P(\frac{|| \mathbf{S}^t_{\mathrm{SOG},i}||_1}{a\cdot n^2}\geqslant 1)=1 \\
%         =& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1) \\
%         =& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \Phi) P(\Phi)\\
%         +& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \overline\Phi) P(\overline\Phi) \\
%         \overset{(1)}{\approx}& P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}\geqslant 1 | \Phi) P(\Phi)\\
%         =& \left[1- P(\frac{  \mathop{\max}\limits_{1\leqslant j \leqslant n} \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{ij}|   }{a\cdot n^2}< 1 | \Phi) \right]P(\Phi)\\
%         =& \left[1- P(\frac{ \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{il}|   }{a\cdot n^2}< 1 | \Phi)^n \right]P(\Phi)\\
%         \overset{(2)}{\leqslant }& \left[1- P(\frac{ (b \cdot n) \cdot n   }{a\cdot n^2}< 1 | \Phi)^n \right]P(\Phi)\\
%         \overset{(3)}{=}& \left[1- P(\frac{ (b \cdot n) \cdot n   }{a\cdot n^2}< 1)^n \right]P(\Phi)\\
%         =& \left[1- P(\frac{b   }{a}< 1)^n \right]P(\Phi)\\
%        \end{aligned} 
%     \label{proof1}
%     \end{equation}
% where step (1) is based on our assumption that ${P}(\Phi)\approx  1 $. 
% Step (2) follows from the fact $(\frac{   (b \cdot n) \cdot n  }{a\cdot n^2}\geqslant1)  \indep \Phi$.
% Step (3) can be easily derived 
% from the definition of consistency matrix. By definition, the number of 
% correct correspondences is $b\cdot n$. According to the definition of the second-order consistency matrix, 
% the matrix element ${\mathbf{S}_{\mathrm{SOG}}}_{ij}$ represents the number of correspondences 
% that are consistent with both correspondence $i$ and correspondence $j$. Thus, ${\mathbf{S}_{\mathrm{SOG}}}_{ij} \leqslant b \cdot n$. 
% The equality holds if and only if both $i$ and $j$ are correct correspondences. Therefore, we have:
% \begin{equation}
%     \sum_{i=1}^{n} |{\mathbf{S}_{\mathrm{SOG}}}_{il}| \leqslant (b \cdot n) \cdot n.
%     \label{proof2}
% \end{equation}
% According to Eq.~\ref{proof2} and~\ref{proof1}, we have already proved that $\left[1- P(\frac{b   }{a}< 1)^n \right]P(\Phi) \geqslant 1$.
% Below is our final derivation:
% \begin{equation}
% \begin{aligned} 
%     &\left[1- P(\frac{b   }{a}< 1)^n \right]P(\Phi) \geqslant 1 \\
%     \Rightarrow & \left[1- P(\frac{b   }{a}< 1)^n \right] \geqslant 1 \\
%     \Rightarrow & P(\frac{b   }{a}< 1)^n \leqslant 0 \\
%     \Rightarrow & P(\frac{b   }{a}< 1) \leqslant 0 \\
%     \Rightarrow & P(\frac{b   }{a}\geqslant  1) =  1
% \end{aligned} 
% \end{equation}
% Thus, we have proved the proportion of correct correspondences 
% $b$ exceeds the threshold $a$.

\input{X_suppl}

\end{document}
