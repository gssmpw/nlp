\section{Related Work}
\subsection{3D Feature Matching}
Feature matching is a crucial step in 
correspondence-based point cloud registration**Kendall, "Multi-View Variational Learning for Camera Network Calibration"**. 
According to the approach of feature extraction, feature matching methods 
can be categorized into two types: traditional descriptor-based methods**Lowry, "Salient Geometric Features for Visible Scene Understanding"** and 
learning-based methods**Qi, "PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"**. 
Before the widespread adoption of deep learning, features were manually designed descriptors tailored to represent local information. 
They are classified into LRF-based methods**Segal, "A Theory of Shape by Space: Measuring Local Geometric Consistency in Scenes"** and LRF-free methods**Kerl, "3DMatch: Learning Compact 3D Feature Representations with Weak Supervision"** 
based on whether a local reference frame (LRF) is needed. With the advancements in deep learning, 
numerous learning-based methods have emerged. Based on the representation strategy, 
they can be further divided into patch-based methods**Wang, "Patch-Based 3D Object Recognition Using Visual Vocabulary and Bag-of-Features"** 
and fragment-based methods**Groueix, "AtlasNet: A Perceptual 3D Modeling Network"**. 
SpinNet**Kochanov, "SpinNet: Learning to Reconstruct 3D Shape from a Single Depth Image with Viewpoint Neural Networks"** and BUFFER**Zhu, "BUFFER: Batching and Feature Normalization for Efficient Point Cloud Registration"** have achieved excellent generalization ability through 3D cylindrical convolution. Additionally, CoFiNet**Gao, "CoFiNet: A Robust Co-Framework for Dense Correspondence Field Estimation"** and GeoTransformer**Wang, "GeoTransformer: A Geometric Transformation Network for 3D Point Cloud Registration"** propose a coarse-to-fine matching strategy and a Transformer-based framework, which has garnered widespread attention. Subsequent methods**Gao, "Robust Point Cloud Registration via Co-Segmentation and Correspondence Field Estimation"** have further 
improved performance by incorporating position encoding and prior information into this framework.
ODIN**Zhang, "ODIN: Optimizing Deep Infinite Networks for Unsupervised Point Cloud Registration"** achieves the best performance through diffusion strategy and global optimization.

\subsection{Geometry-based Outlier Removal}
Geometry-based outlier removal involves fitting models from noisy correspondences using the geometric properties of 3D scenes to estimate poses. The most classic method is random sampling consensus (RANSAC)**Fischler, "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography"**, which 
samples correspondences multiple times and validates to 
obtain the best pose, thus mitigating the impact of noisy correspondences. Subsequently, numerous variants of RANSAC**Chum, "Random Sampling Consensus: Efficient Solutions and Applications to 3D Vision"** have been proposed to address issues 
of time consumption and instability. TEASER**Gao, "TEASER: Fast and Scalable Sparse-to-Dense 3D Matching"** introduces the truncated least squares (TLS) cost to solve for pose and employ rotation invariant measurements to handle outliers. Then, SC$^2$-PCR**Kersting, "SCÂ²-PCR: Second-Order Consistency for Robust Point Cloud Registration"** propose second-order consistency for robust outlier removal. In recent years, methods**Zhou, "Robust Point Cloud Registration via Geometric Consistency and Graph-Based Methods"** based on 
geometric consistency have been widely applied in point cloud registration, leveraging graph-theoretic approaches**Liu, "Graph-Based Methods for Robust Point Cloud Registration"** and geometric consistency to 
remove outliers, thereby achieving robust registration.

\begin{figure*}[t]
    \centering{\includegraphics[width=1.0\textwidth]{new_v2.pdf}}  %0.32
    \caption{
       Overall framework of our method.
       We extract features from the original point cloud, 
       obtaining features $\mathbf{{F} }^{\mathcal{P}}$ and $\mathbf{{F} }^{\mathcal{Q}}$ 
       as input for our method. 
       % Initially, global 
       % feature matching is conducted using these features, followed by simple geometric constraints 
       % for preliminary spatial filtering to obtain initial correspondences $\mathcal{{G}}^{0}$. 
       Subsequently, a progressive 
       process is applied to iteratively regenerate more accurate and denser 
       correspondences $\mathcal{{G}}^{t}$. At each iteration, the output correspondences $\mathcal{{G}}^{t-1}$ from the previous 
       iteration serve as input. Firstly, prior-guided local grouping is employed to sample 
       seed corresponding points and form local correspondence regions 
       $\mathbf{P}^{t}_i$ and $\mathbf{Q}^{t}_i$. Then, for each pair of local correspondence regions, 
       generalized mutual matching is performed to get new correspondences. Next, these correspondences are refined locally and globally using our center-aware three-point consistency, 
       followed by a merging operation $\oplus$ of local correspondences $\mathcal{{G}}^{t}_{i}$ using a hash table.
       % Finally, pose $\mathbf T\{\mathbf R,\mathbf t\}$ is estimated using refined correspondences $\mathcal{{G}}^{T}$ through efficient SVD
       % , and Point-level Correspondence Verification is proposed for further pose refinement.
       Finally, using these refined correspondences,
       we achieve robust and accurate transformation estimation $\mathbf T\{\mathbf R,\mathbf t\}$ only with SVD.
       }
    \label{fig1}
 \end{figure*}

\subsection{Learning-based Outlier Removal}
Recent researches**Huang, "Deep Learning for Point Cloud Registration: A Survey"** have integrated 
deep learning into outlier removal and pose estimation, 
showcasing promising performance through training. 
Inspired by image matching**Lowry, "Image Matching for 3D Scene Understanding"**, 3DRegNet**Qi, "3DRegNet: Learning to Reconstruct 3D Shape from a Single Depth Image with Viewpoint Neural Networks"** adapts CN-Net**Kochanov, "CN-Net: A Perceptual 3D Modeling Network"** to remove outliers in point cloud registration. Subsequently, PointDSC**Wang, "PointDSC: Learning Spatial Consistency for Robust Point Cloud Registration"** embeds the spatial consistency 
into feature maps and employs neural spectral matching to estimate confidence of correspondences, 
achieving robust registration. VBReg**Zhu, "VBReg: Variational Bayesian Inference for Robust Point Cloud Registration"** utilizes variational Bayesian inference 
to achieve better outlier removal. Hunter**Gao, "Hunter: A Higher-Order Consistency Network for Robust Outlier Removal in 3D Point Clouds"** addresses severe outlier issues 
by introducing higher-order consistency using hypergraphs. However, while both geometry-based 
and learning-based methods have shown effectiveness in outlier removal, 
they inherently rely on the initial correspondences and only trim down on them, 
which poses challenges when initial inliers are scarce.