\section{Related Work}
\label{sec:rw}

\subsection{Fabric Defect Detection Algorithms}
Modern fabric defect detection methods are mainly divided into two categories: two-stage and single-stage approaches. The two-stage methods, such as Faster R-CNN____, utilize cascade detection to improve accuracy and speed. However, they may struggle with detecting multiple defects in a single fabric sample. The CNN-based Mobile-Unet____, which replaces U-Netâ€™s encoding block with MobileNetV2, achieves impressive accuracy (99.75\% on YID, 98.80\% on FID), but still faces limitations in handling various defect types.
Single-stage methods, particularly those based on the YOLO framework, have gained popularity. Enhanced YOLOv3____ improves fabric defect detection by adding an attention mechanism and negative sample weighting____. While effective, it still underperforms in detecting complex defects. YOLOv5____ improves feature representation through adaptive pooling and an attention module____, but faces challenges in complex scenarios. To address these issues, we propose an improved YOLOv4-based model with a Strip Perception Module (SPM) that enhances feature extraction for strip defects, retaining the speed advantage of single-stage detection.

\subsection{Attention Mechanism}
The attention mechanism____ enhances model performance by focusing on relevant spatial, channel, or hybrid features. Spatial attention methods like SAM____ and RANet____ prioritize key regions in the spatial domain, improving the capture of spatial dependencies. RANet uses a relation module to model feature interactions, leveraging attention or graph convolutions.
Channel attention, exemplified by SENets____, introduces a squeeze-and-excitation (SE) block that reweights feature channels to highlight important features. This mechanism improves representational power without significantly increasing computational cost. For fabric defect detection, we propose an enhanced spatial pyramid pooling fast (SE-SPPF) that integrates SENetv2____ for better multi-scale feature fusion, addressing the complexity and variation of defect shapes.

\subsection{Loss Function}
In object detection, the loss function quantifies the difference between predicted and ground truth bounding boxes. Intersection over Union (IoU)____ is commonly used to measure this overlap. The IoU loss encourages the model to align predicted boxes with ground truth. The Generalized IoU (GIoU)____ extends IoU by addressing scale and offset mismatches, providing more reliable localization, but it can be ineffective for boxes with significant overlap.
Distance IoU (DIoU)____ refines GIoU by incorporating centroid distance, improving localization accuracy. However, DIoU does not account for size variations between objects. Complete IoU (CIoU)____ incorporates centroid distance, overlap area, and angular difference, making it more effective for rotated boxes. However, for fabric defect detection, where target aspect ratios vary significantly, basic IoU can lead to errors. To address this, we propose an improved version of CIoU (FECIoU), which adjusts for scale differences and enhances detection accuracy for targets with varying aspect ratios.


\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth]{imgs/Strip.pdf}
    \caption{Strip Perception Module}
\label{fig2}
\end{figure*}