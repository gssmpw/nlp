\section{Conclusions and Limitations}

In this work, we present a novel large avatar model for one-shot animatable Gaussian head generation. The core of our framework is the canonical Gaussian avatar generation Transformer. We utilize point-cloud representation to fully leverage the prior shape information resides in FLAME; build stacked cross-attention modules on multi-scale image features for better texture and shape reconstruction; and generate the Gaussian avatar in the unified canonical space with the same expression and pose to mitigate reconstruction complexcities.  Our framework can generate Gaussian avatars that can be seamlessly integrated into the existing rendering pipeline for real-time animation and rendering on a wide range of platforms, including mobile phones. Moreover, we introduce an efficient pipeline for text to animatable Gaussian avatar generation and a user-friendly pipeline for Gaussian avatar style editing given a single image. 

\paragraph{Limitations.} We utilize FLAME parameters to animate our reconstructed 3D Gaussian avatar. It fails to reproduce expressions that FLAME cannot model. For example, LAM is not able to model the tongue movement since FLAME does not model the tongue blend-shapes. Since we eliminate the 2D post-processing network for efficient animation and rendering, some expression-dependent details like dynamic wrinkles cannot be fully modeled. The limitation of FLAME expressiveness and the challenge of single input image also limits the expression neutralization capability. Also, since we utilize algorithms to estimate FLAME from video, the inaccurate estimated FLAME parameters will infect the results. 