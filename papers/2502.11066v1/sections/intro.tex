\section{Introduction}\label{sec:intro}
Compositional generalisation (CG) refers to the ability to systematically combine known expressions to generate novel ones following learned rules \cite{Partee1984}. This capability is essential for advancing language models (LMs) towards robust linguistic understanding beyond mere pattern matching \cite{ram2024makes}. 

Despite their strong performance across various natural language processing tasks, large language models (LLMs) exhibit persistent weaknesses in compositional generalisation \cite{ijcai2020p708, kim2020cogs, aljaafari2024interpreting}. These limitations stem from multiple factors, including training objectives and model architectures. Standard autoregressive training methods, such as next-token prediction, prioritise statistical correlations in token sequences over structured semantic understanding \cite{yin2023consistency, dziri2024faith}. As a result, token representations often lack structured compositionality, leading to fragmented information processing within layers (horizontal misalignment) and across layers (vertical inconsistency). 

Additionally, while self-attention mechanisms in Transformer models effectively capture local dependencies, they frequently fail to maintain coherent compositional representations across multiple layers \cite{murty-etal-2023-pushdown}. This misalignment impairs the model's ability to generalise compositionally, resulting in sensitivity to input order \cite{ismayilzada2024evaluating} and difficulties in handling complex syntactic and morphological structures \cite{aljaafari2024interpreting}. 

\begin{figure*}
    \centering
    \includegraphics[width=.95\linewidth]{figures/CCG_2.pdf}
 \caption{
This diagram depicts the computation of the loss and illustrates the integration of the \textbf{Mutual Information (MI) loss} (\(\mathcal{L}_{\text{MI}}\)) and the \textbf{Stability Loss} (\(\mathcal{L}_{\text{stability}}\)) into the final optimisation process. Tokens \(Tok_1\) and \(Tok_2\) form the \textit{positive set} (\(H_{\text{pos}}\)), while \(Tok_3, Tok_4, Tok_5\) form the \textit{negative set} (\(H_{\text{neg}}\)). The \(\mathcal{L}_{\text{MI}}\) loss is computed \textit{vertically} across layers (\(l\) to \(k\)), maximising the similarity of tokens in \(H_{\text{pos}}\) while contrasting them with tokens in \(H_{\text{neg}}\). The \(\mathcal{L}_{\text{stability}}\) loss is computed \textit{horizontally} between consecutive layers, ensuring consistency in hidden state representations. Both auxiliary losses are combined with the task loss (\(\mathcal{L}_{\text{task}}\)) to form the total loss (\(\mathcal{L}_{\text{total}}\)). This integration improves token representations and enhances the model's overall optimisation.}
    \label{fig:CCG}
\end{figure*}

Several approaches have been proposed to address these limitations, including architectural modifications, enhanced encoding strategies, and targeted regularisation techniques \cite{ontanon-etal-2022-making, murty-etal-2023-pushdown, csordas-etal-2021-devil}. However, these methods often struggle to balance compositional improvements with maintaining performance across diverse downstream tasks. Moreover, their effectiveness is typically confined to specific compositional structures or synthetic benchmarks. Developing a robust and adaptable solution that enables LLMs to achieve consistent CG across diverse tasks remains a major challenge. 



This work introduces \textbf{CARMA}: enhanced \textbf{C}ompositionality in LLMs via \textbf{A}dvanced \textbf{R}egularisation and \textbf{M}utual Information \textbf{A}lignment,  illustrated in Figure~\ref{fig:CCG}. CARMA enhances CG by addressing training challenges that hinder structured compositionality in LLMs. By balancing layer-specific updates and reinforcing token-level dependencies, CARMA provides a scalable and adaptable solution that improves CG without sacrificing downstream task performance. To evaluate CARMA's effectiveness, we investigate the following research questions:  

\begin{itemize}
    \item \textbf{RQ1:} How does regulating mutual information across layers influence compositionality in LLMs? How does it affect sensitivity to input and internal perturbations?  
    \item \textbf{RQ2:} To what extent does layer-specific regularisation improve compositional generalisation across semantic and sentiment analysis tasks, assessing CARMA's adaptability across domains?
\end{itemize}

\noindent The key contributions of this work are as follows:

\begin{itemize}
    \item A novel regularisation method that enhances compositional generalisation without requiring architectural modifications. CARMA leverages mutual information alignment to preserve token dependencies across layers and employs layer-wise stability constraints to reduce representational inconsistencies. 
    
    \item A systematic evaluation of CARMA across compositionally demanding tasks, demonstrating its ability to reinforce systematicity and substitutivity, particularly in models where fine-tuning alone is insufficient.  
    \item A theoretical and empirical analysis of how token dependencies degrade across layers in standard LLMs, revealing that CG limitations are not solely dependent on model size but rather on representational instability. CARMA mitigates this by ensuring consistent information flow, showing that non-intrusive regularisation strategies can significantly improve CG. 
\end{itemize}

The remainder of this paper is structured as follows: Section~\ref{sec:compositionality} reviews compositionality in LLMs and associated challenges. Section~\ref{sec:methodology} introduces the CARMA method. Section~\ref{sec:experiments} describes the experimental setup. Section~\ref{sec:results} presents empirical findings. Section~\ref{sec:related} discusses related work. Section~\ref{sec:conclusion} offers insights and future research directions. Supporting datasets and software are available at a public repository.\footnote{Anonymised for review.}  
