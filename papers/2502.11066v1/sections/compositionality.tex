\section{Compositionality in LLMs}\label{sec:compositionality}
Compositional generalisation (CG) in linguistics encompasses five key principles: systematicity, productivity, substitutivity, localism, and over-generalisation \cite{dankers-etal-2022-paradox}. These principles have been explored in LLMs for various applications, including compositional instruction \cite{yang2024exploring}, semantic parsing \cite{li-etal-2023-learning}, machine translation \cite{li-etal-2021-compositional}, and multi-step inference \cite{zhang2024can}. Empirical studies reveal that standard Transformer-based LLMs exhibit limited CG, even for relatively simple compositional tasks. For instance, models frequently struggle to assemble tokens into words or construct morphemes into coherent structures \cite{aljaafari2024interpreting, ismayilzada2024evaluating}. These limitations are linked to architectural constraints, training objectives, and tokenisation practices, which fragment information and increase sensitivity to input order and contextual noise \cite{murty-etal-2023-pushdown}. 

\textbf{Training Objectives and Information Fragmentation.} Standard training objectives for LLMs typically optimise for next-token prediction, which prioritises surface-level correlations over deeper semantic integration \cite{dziri2024faith}. While this approach is effective for data already seen, it often impedes CG by reducing mutual information between dependent tokens, thereby limiting the model's ability to form coherent compositional representations \cite{aljaafari2024interpreting}.

\textbf{Architectural Mechanisms and Compositional Consistency.} Beyond training objectives, architectural mechanisms such as dropout and self-attention contribute to the dispersion of information across the model. This fragmentation increases sensitivity to input order and context, often resulting in errors that undermine \textbf{compositional consistency} \cite{sajjadi2016regularization, cai2021isotropy}—the model's ability to maintain produce consistent outputs when processing variations of semantically equivalent inputs through transformations like word substitution or paraphrasing.

These challenges impact both high-complexity reasoning tasks and simpler operations that demand consistent morphological and syntactic processing \cite{ismayilzada2024evaluating}.

\textbf{Existing Approaches to Enhance CG in LLMs.} To address CG limitations, research has explored architectural adjustments, regularisation techniques, and task-specific strategies. For instance, \cite{ontanon-etal-2022-making} demonstrated that combining relative positional encoding with embeddings enhances CG, particularly in algorithmic tasks. Their findings suggest that weight sharing and copy decoders help retain input structures, thus improving CG accuracy. Other architectural modifications, such as Pushdown Layers \cite{murty-etal-2023-pushdown} and GroCoT \cite{sikarwar-etal-2022-transformers}, incorporate mechanisms for tracking syntactic depth and spatial relations, which enable recursive processing of compositional structures.\\
Models like RegularGPT \cite{chi-etal-2023-transformer} introduce adaptive depth and memory mechanisms to facilitate CG by constructing complex structures from simpler components. Studies by \cite{csordas-etal-2021-devil} and \cite{petty2024impact} evaluate model depth, parameter configurations, and encoding methods, revealing that architectural choices and training setups—such as avoiding early stopping and prioritising accuracy over loss minimisation—are critical to enhancing CG. In neural machine translation (NMT), \cite{dankers2022paradox} reformulated CG evaluations, finding a positive correlation between data size and compositional performance, underscoring the importance of extensive, real-world benchmarks for capturing the complexities of linguistic compositionality.\\
Frameworks like CompMCTG and Meta-MCTG \cite{zhong2024benchmarking} offer benchmarks for evaluating CG in multi-aspect text generation, suggesting that joint training and meta-learning approaches can improve fluency. However, significant performance drops persist in out-of-distribution tasks. Additionally, synthetic tasks reveal that recursive, step-by-step prompt formats support combinatorial generalisation, although training biases and sequence order constraints remain limiting factors \cite{ramesh2024compositional}.