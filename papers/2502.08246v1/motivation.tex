
\section{Preliminary discussion}
\label{sec:motivation}


\begin{figure*}
   \vspace{-0.2em}
%
    \includegraphics[height=5.5cm]{figs/PCA_projection.pdf}
    \hfill
    \includegraphics[height=5.5cm]{figs/qk_dot_product_hist_2.pdf}
    \hfill
    \includegraphics[height=5.5cm]{figs/kq_assign_probas.pdf}
   %
   %
   \vspace{-0.8em}
    \caption{
    Illustration of the OOD statistics between keys and queries in the attention computation. 
    Left: first two PCA dimensions of the keys and queries (the big dots are the attention sinks for keys and queries). 
    Middle: distribution of dot products between a random subset of keys and queries.     
    Right: after clustering of keys, probability of assignment to each cluster, for  keys (x-axis) and queries (y-axis).
    %
    \label{fig:ood}}
       \vspace{-0.8em}
\end{figure*}


In this section, we review a few key properties of the attention operator in LLMs from a vector search perspective. 
We manipulate query vectors (token query embeddings) and key vectors (token key embeddings), ignoring the value vectors for now. 
In a transformer model, queries are matched to keys from a given attention head.
Therefore, we train and build indexes separately for each head.
%
%
%
%

\subsection{Attention as a vector search application}

Considering the self-attention computation,
the main differences with respect to classical approximate nearest-neighbor (ANN) settings are 
(i) there is not a hard cut-off for relevant results, but a soft weighting of results (softmax); 
(ii) a maximum inner product search problem instead of the more common Euclidean or cosine-similarity search; and
(iii) the keys and queries are produced by different computations and thus reside in different embedding spaces.
%
We approximate exhaustive attention using a hard cut-off on the maximum number of retrieved keys, to speed up the computation. 

%


\subsection{Out-of-distribution setting}

Classical vector search methods are designed to find vectors that are sampled \iid from the same distribution. 
We examine two types of OOD behavior: between keys and queries, and between training and testing. 
Prior work has quantified the difference between key and query distributions by comparing histograms of query-to-key distances v.s. key-to-key distances~\citep{jaiswal2022ood,chen2024roargraph}. 

\OURS is based on a partition of the keys. 
For a query vector, the $\nprobe$ most promising buckets are visited and the dot product between the query and all keys from the visited buckets is computed. 
One important aspect that plays into OOD behavior for \OURS, is the degree to which the buckets of the $N$ key vectors are balanced in terms of membership. 
If the buckets are all of the same size and equally likely to be visited, then the number of dot products to perform is $\nprobe N / \nlist$. 
The search time is proportional to this.

%
%

%



\subsection{Key-query OOD}

%
Keys and queries are computed using distinct linear layers on top of shared vectors.
%
The  distribution mismatch between keys and queries is observed with basic statistics of a random sample of vectors (here head 28 of layer 17 of a Llama 3 model). %
\autoref{fig:ood}(left) shows the first principal components of keys and queries: their embedding spaces are clearly distinct. 
%
%
As the two point clouds are on opposite sides of the origin, the $\langle k,q \rangle$ dot products are almost always negative (\autoref{fig:ood}, middle).
Note, the dot products with the first key (\ie the ``attention sink''~\citep{xiao2024efficientstreaminglanguagemodels}) and the most recent keys, are statistically higher than the other keys. 

From now on, we apply a spherical k-means clustering with $\nlist=1024$ centroids to the keys~\citep{douze2024faiss}. 
%
Figure~\ref{fig:ood} (right) shows that the probability of assignment to a given centroid are very different between keys and queries.
More specifically, some clusters ``capture'' a significant fraction of the queries (up to 10\%). 
%
Motivated by this, we re-design an alternative assignment operator in Section~\ref{sec:method}. 




\begin{figure}
%
    \centering
    %
    \includegraphics[width=\linewidth]{figs/stddev_cluster_sizes.pdf}
%
    \vspace{-1.5em}
    \caption{
Deviation of key bucket sizes when 100K keys are assigned to a trained k-means.
The 100K keys are sampled 10 times, in 4 different ways indicated on the y-axis, and with or without the rope transformation applied.
%
    \label{fig:otherOOD}}
\end{figure}

\subsection{Prompt and temporal ODD}
\label{sec:otherOOD}

OOD problems occur for all ML models that assume \iid training and test data. 
Here we examine the divergence of the distribution at training time compared to at test time when a prompt is used, focusing entirely on the key vector distribution.
We measure the variance of the assignment of 100k vectors sampled in different ways, and repeat the experiment 10 times: higher variance indicates stronger OOD behavior.
Figure~\ref{fig:otherOOD} shows the minimal variance occurs when vectors are sampled uniformly on the training set. 
When we measure it on 100k random uniform vectors from data that is disjoint from the training set, the variance increases.
We sampled 100k vectors from each of 10 different prompts and found that the variance changes significantly depending on the prompt: this is prompt OOD. %
We then sample 100k vectors across prompts, but from 10 narrow timestamp ranges: here the deviation with respect to the training distribution is the highest, showing strong temporal bias.

\paragraph{Removing temporal bias.}
\label{sec:derope}
The rope temporal transformation~\citep{su2023roformerenhancedtransformerrotary}, when applied to all keys and queries, is likely a major contributor to their temporal bias. 
Therefore, we repeated our analysis on keys without the rope transformation and found that, indeed the time bias is reduced (blue dots in Figure~\ref{fig:otherOOD}). 
We then applied the same de-rope operation to queries where the rope component has been removed, yielding the last plot in Figure~\ref{fig:otherOOD}.
Given the positive effect of de-roping, we use it for all models trained for \OURS.

%
%
%
%

\subsection{Per-head attention span}
\label{sec:densepart}

Figure~\ref{fig:ood} (middle) shows that the first key of any sequence, the so-called \emph{attention sink}~\citep{xiao2024efficientstreaminglanguagemodels}, is an outlier in the data distribution and always has a large dot product with the query vectors. 
Similarly, the most recent keys have higher dot products with the queries. 
%
Therefore, it is typical in attention approximations to retrieve these keys exactly. 
Approximate and exact retrieval results are then combined to form a final attention result. 
In our case, we use the ``1+2047'' setting, which means that the first token and the most recent 2047 tokens are attended exhaustively. 
This context is long enough to cover many short-context tasks.

%
Figure~\ref{fig:attention_fraction} shows the fraction of attention that comes from the top 256 keys (out of $10^5$) for each query (excluding the attention sink and recent tokens). 
%
For most heads, the top-256 cover most of the attention weight. 
Layer 0 is an exception, all its heads are more uniformly spread over keys. 
Therefore, in the following, we perform full attention for the layer 0, similarly to \citet{tang2024quest,xiao2024efficientstreaminglanguagemodels}. 


%
%

\begin{figure}
    \centering
    %
    \includegraphics[width=\linewidth]{figs/percentage_attention_topk.pdf}
    \vspace{-2em}
    \caption{Fraction of attention contributed by the top 256 tokens (out of $10^5$), per head, averaged over 10 prompts. 
    %
    \label{fig:attention_fraction}}
\end{figure}


%

%


%

%

%

%


%


%

%


%
