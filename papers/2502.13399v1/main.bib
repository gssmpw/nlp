@misc{usda2019projections,
    title = {{USDA} Long-Term Agricultural Projections},
    year = {2019},
    howpublished = {\url{https://www.usda.gov/oce/commodity/projections/}},
    note = {Accessed: 2020-05-01}
}

@article{wu2020kernelcounting,
    title = {Automatic kernel counting on maize ear using RGB images},
    author = {Wu, D. and Cai, Z. and Han, J. and others},
    journal = {Plant Methods},
    volume = {16},
    pages = {79},
    year = {2020},
    howpublished = {\url{https://doi.org/10.1186/s13007-020-00619-z}},
    note = {Accessed: 2023-07-18}
}

@article{khaki2020corndetection,
    title = {Convolutional Neural Networks for Image-Based Corn Kernel Detection and Counting},
    author = {Khaki, S. and Pham, H. and Han, Y. and Kuhl, A. and Kent, W. and Wang, L.},
    journal = {Sensors},
    volume = {20},
    pages = {2721},
    year = {2020},
    howpublished = {\url{https://doi.org/10.3390/s20092721}},
    note = {Accessed: 2023-07-18}
}

@article{grift2017kernelcounting,
    title = {Semi-automated, machine vision based maize kernel counting on the ear},
    author = {Grift, Tony E. and Zhao, Wei and Momin, Md Abdul and Zhang, Yu and Bohn, Martin O.},
    journal = {Biosystems Engineering},
    volume = {164},
    pages = {171-180},
    year = {2017},
    doi = {10.1186/s13007-020-00619-z},
    note = {Accessed: 2023-07-18}
}

@article{wang2022impacts,
  title={Impacts of Heat Stress around Flowering on Growth and Development Dynamic of Maize (Zea mays L.) Ear and Yield Formation},
  author={Wang, Na and Liu, Qi and Ming, Bo and Shang, Wenxin and Zhao, Xuefeng and Wang, Xuqing and Wang, Jing and Zhang, Junlong and Luo, Zhongkui and Liao, Yong},
  journal={Plants},
  volume={11},
  number={24},
  pages={3515},
  year={2022},
  publisher={MDPI}
}

@article{yang_estimation_2021,
	title = {Estimation of corn yield based on hyperspectral imagery and convolutional neural network},
	volume = {184},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169921001101},
	doi = {10.1016/j.compag.2021.106092},
	urldate = {2024-05-04},
	journal = {Computers and Electronics in Agriculture},
	author = {Yang, Wei and Nigon, Tyler and Hao, Ziyuan and Dias Paiao, Gabriel and Fernández, Fabián G. and Mulla, David and Yang, Ce},
	month = may,
	year = {2021},
	keywords = {CNN, Corn yield, Deep learning theory, Hyperspectral Image},
	pages = {106092},
}

@misc{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	doi = {10.48550/arXiv.2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2024-05-05},
	publisher = {arXiv},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv:2010.11929 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: Fine-tuning code and pre-trained models are available at https://github.com/google-research/vision\_transformer. ICLR camera-ready version with 2 small modifications: 1) Added a discussion of CLS vs GAP classifier in the appendix, 2) Fixed an error in exaFLOPs computation in Figure 5 and Table 6 (relative performance of models is basically not affected)},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhzar\\Zotero\\storage\\IE6GRDVD\\Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhzar\\Zotero\\storage\\NWJ4SMR7\\2010.html:text/html},
}

@misc{kirillov_segment_2023,
	title = {Segment {Anything}},
	url = {http://arxiv.org/abs/2304.02643},
	doi = {10.48550/arXiv.2304.02643},
	abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	urldate = {2024-05-05},
	publisher = {arXiv},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	month = apr,
	year = {2023},
	note = {arXiv:2304.02643 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	annote = {Comment: Project web-page: https://segment-anything.com},
	file = {arXiv Fulltext PDF:C\:\\Users\\mhzar\\Zotero\\storage\\34BEU2WH\\Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\mhzar\\Zotero\\storage\\2X57ZN59\\2304.html:text/html},
}

###################################

@article{Ruiz:2022tz,
author = {Ruiz, Alejo and Archontoulis, Sotirios V and Borr{\'a}s, Lucas},
title = {{Kernel weight relevance in maize grain yield response to nitrogen fertilization}},
journal = {Field Crops Research},
year = {2022},
volume = {286},
pages = {108631}
}

@article{Wang:2019ug,
author = {Wang, Baomei and Liu, Can and Zhang, Dengfeng and He, Chunmei and Zhang, Juren and Li, Zhaoxia},
title = {{Effects of maize organ-specific drought stress response on yields from transcriptome analysis}},
journal = {BMC Plant Biology},
year = {2019},
volume = {19},
number = {1},
pages = {335}
}

@article{Sadras:2012tw,
author = {Sadras, Victor O and Slafer, Gustavo A},
title = {{Environmental modulation of yield components in cereals: Heritabilities reveal a hierarchy of phenotypic plasticities}},
journal = {Field Crops Research},
year = {2012},
volume = {127},
pages = {215--224}
}

@ARTICLE{Niu:2021,
AUTHOR={Niu, Shiduo  and Du, Xiong  and Wei, Dejie  and Liu, Shanshan  and Tang, Qian  and Bian, Dahong  and Zhang, Yarong  and Cui, Yanhong  and Gao, Zhen },
TITLE={Heat Stress After Pollination Reduces Kernel Number in Maize by Insufficient Assimilates},
JOURNAL={Frontiers in Genetics},
VOLUME={12},
YEAR={2021},
DOI={10.3389/fgene.2021.728166},
ISSN={1664-8021},
}

@article{Shewry:1998uz,
author = {Shewry, P R},
title = {{Seed Biology and the Yield of Grain Crops. Dennis B. Egli}},
journal = {Plant Growth Regulation},
year = {1998},
volume = {26},
number = {2},
pages = {140--141}
}

@book{Abendroth:2011,
author = {Abendroth, Lori and Elmore, Roger and Boyer, Matthew and Marlay, Stephanie},
year = {2011},
month = {03},
pages = {},
title = {In Corn Growth and Development}
}

@article{strachan2004corn,
  title={Corn grain yield in relation to stress during ear development},
  author={Strachan, SD},
  journal={Crop Insights},
  volume={14},
  number={1},
  year={2004}
}
@article{khanal2018integration,
  title={Integration of high resolution remotely sensed data and machine learning techniques for spatial prediction of soil properties and corn yield},
  author={Khanal, Sami and Fulton, John and Klopfenstein, Andrew and Douridas, Nathan and Shearer, Scott},
  journal={Computers and electronics in agriculture},
  volume={153},
  pages={213--225},
  year={2018},
  publisher={Elsevier}
}

@article{millet2019genomic,
  title={Genomic prediction of maize yield across European environmental conditions},
  author={Millet, Emilie J and Kruijer, Willem and Coupel-Ledru, Aude and Alvarez Prado, Santiago and Cabrera-Bosquet, Lloren{\c{c}} and Lacube, S{\'e}bastien and Charcosset, Alain and Welcker, Claude and van Eeuwijk, Fred and Tardieu, Fran{\c{c}}ois},
  journal={Nature genetics},
  volume={51},
  number={6},
  pages={952--956},
  year={2019},
  publisher={Nature Publishing Group US New York}
}

@book{cormen2022introduction,
  title={Introduction to Algorithms},
  author={Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
  year={2022},
  publisher={MIT Press}
}

@article{singh2025use,
  title={Use of artificial intelligence in soybean breeding and production},
  author={Singh, Asheesh K and Jones, Sarah E and Van der Laan, Liza and Ayanlade, Timilehin T and Raigne, Joscif and Saleem, Nasla and Joshi, Shambhavi and Arshad, Muhammad Arbab and ZareMehrjerdi, Hossein and Rairdin, Ashlyn and others},
  year={2025},
  publisher={Elsevier}
}