\section{Related Work}
% first work
Wu et al. **Wu, "Automated Kernel Detection and Counting in Maize Ears"** propose a method for estimating the total number of kernels on a maize ear using a single image. The process involves extracting features from the image, followed by the recognition of each kernel in the RGB images of the maize ear. The process employs a variety of algorithms, including the environmentally adaptive segmentation algorithm (EASA) for environmentally adaptive plant segmentation, a median filter and a Wallis filter for pre-processing, an improved Otsu method combined with a multi-threshold and row-by-row gradient-based method (RBGM) for kernel separation, and a segmentation method that integrates a genetic algorithm with an improved pulse coupled neural network. While the method demonstrates promising results, it has challenges. The accurate counting of kernels necessitates the identification and separation of adjacent kernels, a task that can be complex due to factors such as the narrow color gradient between kernels, the presence of simultaneous corner-to-corner, edge-to-corner, and edge-to-edge touching, and the irregular sizes and shapes of kernels on the same maize ear. Despite these challenges, the method offers a cost-effective and adaptable approach for kernel estimation, making it a valuable contribution to the field.
% end of first work

% second work
Khaki et al. **Khaki, "Kernel Detection in Maize Ears Using Sliding Window and Regression"** employed a sliding window approach for kernel detection, where a Convolutional Neural Network (CNN) classifier assesses each window for the presence of a kernel. Post classification, a non-maximum suppression algorithm is applied to eliminate redundant and overlapping detections. Finally,  windows identified as containing a kernel are passed to a regression model, which predicts the (x, y) coordinates of the kernel centers. Grift et al. **Grift, "Automated Kernel Counting in Maize Ears Using Image Segmentation"** propose a method to handle imperfect segmentation, where some kernel areas are connected to two or more other kernel areas. When a bridged kernel is detected based on area discrimination, the image is traced back to the original grey-scale image, to allow applying the de-bridging algorithm. The de-bridging algorithm consists of extraction of the bridged area from the kernel map, retrieving the grey scale bridged area from the original ear image, and segmentation of the grey scale bridged area using Otsu's method with a local threshold.
  
% end third work

% summary of the limitations of the above methods that will be addressed by this method.
%Previous methods in maize ear phenotyping are typically tailored for specific backgrounds or lighting conditions and trained on limited datasets, making them not generalizable across different environments or crop varieties. The semi-automated method for counting maize kernels has several limitations. It relies on manual counting, which can introduce human error. It may struggle with accurately identifying individual kernels in certain situations. The method's effectiveness with ears affected by disease, mold, or field conditions is unclear. Lastly, the method has demonstrated a potential error range in kernel counting, indicating possible inaccuracies. Additionally, these deep learning methods require substantial amounts of annotated data, which is both time-consuming and labor-intensive to collect. Given that we are dealing with new genotypes, encountering unseen kernel shapes in the input data is also challenging. Furthermore, no objective definition for the kernel row structure could be mathematically formulated. Manual counting of kernels per row is a tedious task, begging for automation to enhance efficiency and accuracy.

As described above, existing maize ear phenotyping methods, while valuable, face certain challenges. Wu et al.'s approach encounters difficulties with kernel separation due to color similarities and shape irregularities. Khaki et al.'s sliding window technique, though effective, may have limitations with varying kernel sizes and image resolution. Grift et al.'s method addresses some segmentation issues but involves complex image processing steps. These methods often work best under specific conditions, for example, lighting and background, which can limit their broader applicability. They typically require large annotated datasets and may not perform optimally with unfamiliar kernel shapes from new genotypes. Most importantly, the lack of a standardized definition for \KPR~also presents a challenge for automation. These factors suggest a need for more versatile approaches to maize ear phenotyping that can maintain accuracy across different conditions and varieties.