

\section{Results and Analysis}



%% BabyAI in one table
% \begin{table}[t!]
\begin{table*}[t!]
    \centering
    \setlength\tabcolsep{3.pt}
     \setlength\extrarowheight{-9pt}
    \begin{tabular}{l c c c c c c c c c c c c}
        \toprule[1.5pt]
              & \multicolumn{4}{c}{Zero-Shot} & \multicolumn{6}{c}{Few-Shot}
             \\
             \cmidrule(lr){2-5}
             \cmidrule(lr){6-12}
             \\
             \textbf{Task} & ZeroShot & 0-CoT & LTM & \textbf{\RwR} & CoT & BAG & Alg & ReAct & ReAct-Trv & SayPlan & \makecell{\textbf{\RwR} \\(FS)} & \makecell{\textbf{\RwR} \\ (Alg)} 
             \\
        \midrule[1pt]
             NumQ\&A & 55\% & 48\% & 52\% & \textbf{95\%} &  53\% & 51\% & 65\% & 
             24\% & 24\% &
             35\% & 
             \textbf{94\%} & \textbf{97\%}
             \\
             Trv-1 & 20\% & 23\% & 17\% & \textbf{61\%} & 34\% & 35\% & \textbf{64\%} & 
             13\% & 62\% &
             18\% &
             \textbf{67\%} & \textbf{64\%} 
             \\
             Trv-2 & 11\% & 7\% & 6\% & \textbf{56\%} & 1\% & 1\% & 0\% & 
             0\% & \textbf{56\%} &
             0\% &
             \textbf{61\%} & \textbf{56\%} 
             \\
         \bottomrule[1.5pt]
    \end{tabular}
    \caption{\textbf{Results in BabyAI} \RwR achieves the best performance across all tasks in both zero-shot and few-shot settings, showing that \RwR (1) is effective in solving spatial tasks; (2) can harness the information from in-context examples and extrapolate better to unseen tasks. We highlight the top-1 performance under the zero-shot setting and top-2 performances, including ties, under the few-shot setting.
    }
    \label{tab:BabyAI}
    \vspace{-0.2in}
\end{table*}

\begin{table}[t!]
    \centering
    % \setlength\tabcolsep{2.5 pt}
	\begin{tabular}{l  c c  c }
        \toprule[1.5pt]
        Method & \makecell{Few-Shot \\ Examples} & VH-1 & VH-2 \\
        \hline 
         \textbf{ZeroShot}  &  & 87.5\% & 75\% \\
         \textbf{0-CoT}     &  & 87.5\% & 75\% \\
         \textbf{LTM}       &  & 87.5\% & 62.5\% \\
         \hline
         \textbf{CoT}       & \bluecheck & 87.5\% & 75\% \\
         \textbf{BAG}       & \bluecheck & 87.5\% & 62.5\% \\
         \hline
         \textbf{RwR} &  & \bf{100\%} & \bf{100\%} \\
         % \cmidrule(r){1-2} \cmidrule(lr){3-14} \cmidrule{15-16}
        \bottomrule[1.5pt]
    \end{tabular}
    \caption{
        \textbf{Results in VirtualHome}. The superior performance of \RwR shows that it is capable of grounding its plan to the environmental states.
    }\label{tab:VHResults}
    \vspace{-12pt}
\end{table}


\subsection{Experiment Results}
\paragraph{Numerical Q\&A Resutls} The results are collected in Table \ref{tab:BabyAI}. Zero-shot \RwR outperforms the best baseline by 30 percentage points (pp), even without taking advantage of the few-shot examples. Few-shot methods do not show significant advantage over zero-shot methods, as the reasoning trace for this task is simple. However, they all tend to make mistakes when addressing the substeps such as counting the item or locating the neighboring rooms. The retrieval mechanisms in both ReAct and SayPlan further degrades the performance. SayPlan cannot effectively retrieve information, due to its retrieve-then-reason framework that does not condition the retrieval on intermediate reasoning. ReAct employs the iterative reasoning, but API-calling is less effective for large scene graphs. In contrast, \RwR retrieves information that better facilitate reasoning. %attends to the graph information in the correct order by querying for it based on the reasoning process.


\paragraph{2D Traversal Results} Table \ref{tab:BabyAI} also reports the success rate in the traversal task. In the seen Trv1 environment, our method achieves 38pp and 3pp higher success rate against the best performing baselines under zero-shot and few-shot settings, respectively. While few-shot baselines perform more than 10pp better compared to zero-shot baselines, they perform even worse in the unseen settings, achieving $\leq 1\%$ success rate. This indicates that although few-shot examples is helpful in the seen tasks, LLMs do not \textit{learn} the reasoning process to extrapolate to similar unseen tasks. Rather, LLMs might only \textit{memorize} the heuristic mechanism in the solution, such as always removing the item on the left of the door. On the other hand, by not directly processing scene graphs, the Reasoner in \RwR better learns the reasoning process essential for the task, and can thus extrapolate well to similar problems. SayPlan and ReAct achieve inferior results \RwR, indicating that their heuristic or API-based retrieval methods are less suitable for complex tasks concerning global information.


\paragraph{Household Task Planning Results}
The planning success rate on the 8 tasks in the 2 VH environments are shown in Table \ref{tab:VHResults}. We observe that all baselines consistently fail to address the precondition of the planned action. For example, all of them failed to generate \texttt{\small [open] <garbagecan> (ID)} before \texttt{\small [putin] <plum> (ID) <garbagecan> (ID)}, forgetting that the state of the garbage can is \texttt{\small state:\{CLOSED\}} from the extensive graph input. On the other hand, \RwR doesn't process the entire graph. Instead, it queries for the specific object information, which helps to better determine the action parameter and examine the action preconditions. 
% For qualitatitve demonstration, please refer to Figure \ref{fig:vhQual} for an examplar task and solution by our method.

We also present qualitative results in Appendix~\ref{app:RwRTrvDemo} (BabyAI), Appendix~\ref{app:RwRVHDemo} (VirtualHome), and Appendix~\ref{app:BaselineFailures} (Baseline failure cases). We provide analysis on the compute cost with the iterative design in Appendix~\ref{app:ComputeAnly}.


\begin{table*}[t!]
    \centering
    % \setlength\tabcolsep{2.5 pt}
    \begin{tabular}{l | c c c | c c c}
        \toprule[1.5pt]
        Method & \makecell{Code-Writing \\ \& Tool-Use} & \makecell{Iterative Reason} & Two-Agent & Numerical Q\&A & Trv-1 & Trv-2\\
         \hline
         \textbf{SingleCoder} & \bluecheck &  &  & 80\% & 33\% & 25\%\\
         \textbf{\RwR-T} &  & \bluecheck & \bluecheck & 57\% & 18\% & 8\%\\
         \textbf{\RwR-S} & \bluecheck & \bluecheck & &  90\% & 46\% & 31\%\\
         \textbf{\RwR} & \bluecheck & \bluecheck & \bluecheck & \bf{95\%} & \bf{61\%} &  \textbf{56\%} \\
         % \cmidrule(r){1-2} \cmidrule(lr){3-14} \cmidrule{15-16}
        \bottomrule[1.5pt]
    \end{tabular}
    \caption{
        \textbf{Ablation in BabyAI traversal and numerical Q\&A}. 
        The best result is achieved by combining both Reason-while-Retrieve framework and the code-writing, justifying the key designs in our method.
    }\label{tab:ablate}
    \vspace{-10pt}
\end{table*}


\subsection{Ablation}
\paragraph{Setup} To further validate the designs of \RwR framework, we conduct an ablation study for the key component of our method. To this end, we compare against the following variants of \RwR:
\begin{itemize}
    \item \textbf{SingleCoder}: 
    Single-shot code writing with LLMs to address a given task, without iterative retrieval and reasoning or multiple generation. This variant verifies the benefit of \textbf{the iterative retrieval-generation}.
    % A single LLM that directly writes the entire code to address a given task. It benefits from the accurate numerical reasoning and tool-use capacity from the code-writing, but does not have the opportunity to analyze the intermediate graph information from the iterative retrieving and reasoning (dubbed \textit{Iterative RetRea} in this section). 
    The SingleCoder is prompted with the combination of the information for both the Reasoner and the Retriever in \RwR, including the environment and action space information, scene graph schema, and tool annotations. The self-debugging mechanism is also enabled.

    \item \textbf{\RwR-T}: 
    Language-only two-agent iterative method, without the schema-based code-writing or tool-using mechanism. Both agents cooperate purely in the language space, and the graph is directly prompted to the retriever as texts. This variant validates the \textbf{schema-based code-writing} design. We also use an additional LLM-based action format corrector following \citep{LLMPlanner, groundedDecoding}, as it consistently fails to generate actions in the executable format.
    % The other variant disables the code-writing ability of both the Retriever and Reasoner in \RwR. Instead, both cooperative agents rely purely on language reasoning and communication skill to solve a given task. This design evaluates the performance of the iterative retrieve and reason process without the code-writing.

    \item \textbf{\RwR-S}: 
    An one-agent version of \RwR with both code-writing and iterative mechanism. This variant verifies the benefits of the \textbf{two-agent} design against one-agent. Specifically, the one-agent \RwR-S is fed with the union of the Reasoner and Retriever prompts. At each iteration, it processes the entire reasoning and retrieval history to generate the next step:
    \begin{align}
        \anly_t, \query_t, \code_t &= LLM(\{\anly_0, \query_0, \code_0, \gG^\prime_0\}, \cdots; \gs) \\
        \gG^\prime_{t} &= \code_t(\gG)
        \end{align}
    \end{itemize}
    
    
All variants are tested in BabyAI under the zero-shot setting. 

\paragraph{Results} The ablation study results are demonstrated in Table \ref{tab:ablate}, where all variants are out-performed by the original \RwR, justifying the core designs. Specifically, 
{\em SingleCoder} is capable of solving numerical problems, but is unable to address complex planning tasks without the iterative cooperation.
{\em \RwR-T} can better break the task down with iterative task solving, but cannot consistently obtain the correct solution for each substep without code-writing. For example, queried with \texttt{\small "Find all rooms that contain 5 green balls"}, the non-code-writing Retriever might struggle with the counting problem in the language space.
{\em \RwR-S} performs both iterative reasoning and code-writing, but can be misguided by the redundant historical information when addressing complex tasks.

% \subsection{Two-agent v.s. One-Agent}
% \paragraph{Setup}
% We further demonstrate the importance of the two-agent design of our framework, by 