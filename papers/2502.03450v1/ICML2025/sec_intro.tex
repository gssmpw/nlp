\section{Introduction}
\label{sec:intro}

%%% Why reasoning on scene graphs are meaningful
With the remarkable prowess in language interpretation and reasoning \citep{gpt4, llama2}, Large Language Models (LLMs) have been increasingly adopted in the embodied planning tasks \citep{huang2023embodied, innermono, socratic}, including plan generation \citep{LLMPlanner}, interaction \citep{joublin2024copal}, and action selection \citep{sayplan}.
Despite the progress, the challenge of grounding the LLMs reasoning to situated environments remains unsolved, primarily due to the absence of a environmental representation that LLMs can effectively process \citep{groundedDecoding}. 
While LLMs can interface with external tools to directlyx process perceptual data such as images \citep{CaP, voxposer}, they are unable to comprehend the intermediate, non-textual outputs from those tools, which prohibits generating the grounded reasoning trace.
In contrast, \textbf{scene graphs} represent environments as hierarchical graphs that encapsulate spatial relationships and semantic attributes in a structured and serializable format \cite{hierarchicalSg, hydra}. 
As a result, scene graphs have emerged as a scalable, high-level environment representation for LLM-based spatial reasoning and planning, showing effectiveness in both simulation-based \cite{octopus} and real-world applications \cite{sayplan, conceptgraphs, GRID, spatialrgpt}. 

%%%%% figure %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[t!]
 
  % \vspace*{-0.1in}
  \centering
  \scalebox{0.95}{
    \begin{tikzpicture}
     \node[anchor=north west] at (0in,0in)
      {{\includegraphics[width=1.0\textwidth,clip=true,trim=0
      280 0 0]{figs/intro_method_compare.pdf}}};
%     \node[yshift=-0pt,anchor=north west] at (0.1in,0.0in) {\bf \small (a)};
%     \node[anchor=north west] at (0.92in,-0.05in) {\textbf{(a)}};
%     \node[anchor=north west] at (2.00in,-0.05in) {\textbf{(b)}};
%     \node[anchor=north west] at (3.09in,-0.05in) {\textbf{(c)}};
    \end{tikzpicture}
  }
 \vspace*{-0.1in}
  \caption{\textbf{LLM Graph Processing Framework Comparison}.
  (a) Reason-Only: A Reasoner LLM is directly prompted with a full textualized graph.
  (b) Retrieve-then-Reason: A Retriever LLM filters out a task-related sub-graph for use by another Reasoner LLM as text inputs.
  (c) Reason-while-Retrieve (Ours): A Reasoner and a Retriever collaborate in solving a task by attending to the graph dynamically based on the progress in solving the task. Both Retriever and Reasoner LLMs write code to process information to avoid hallucinations and to enhance numerical and spatial reasoning.
  }
  \vspace*{-0.2in}
 \label{fig:Overview}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Existing approach on LLMs reasoning on graphs.
Leveraging Large Language Models (LLMs) for reasoning with scene graphs remains a challenging and under-explored problem.
%, which requires LLMs to interpret task descriptions, comprehend the relational and semantic information within the graph, and apply their intrinsic knowledge to solve the task by grounding on the graph and in turn the environment.
Recent research explores graphs-as-text as the input for the single generation \cite{talkLikeGraph, conceptgraphs}, categorized as "Reason-only" methods in Fig. \ref{fig:Overview}, showcasing LLMs' preliminary capacity to interpret graph topology. Yet, they are prone to hallucinations or exceed token limits when handling large graphs \citep{NLGraph}. 
 To address the issues, the "Retrieve-then-Reason" strategy is proposed \citep{reasonOnGraph, thinkOnGraph, sayplan}, 
 wherein the LLM first identifies the sub-graph pertinent to a given task before reasoning on the retrieved part.
 %% Do we need to detail the process here?
% The exploration phase employs a heuristic strategy, either by exploring neighborhood nodes and edges of visited parts~\cite{thinkOnGraph} or expanding the sub-tree rooted at nodes at a certain hierarchical level~\cite{sayplan}.
While this strategy is adept at information collection, it struggles with complex tasks requiring comprehensive graph understanding and dynamically shifting focus based on the reasoning process, 
restricting the utility of LLMs in understanding complex scenes from textualized graphs.
% Additionally, LLMsâ€™ inherent limitations in numerical reasoning \citep{AliceInWonderland, llmMathReason} further impede their ability to solve complex spatial reasoning tasks. 
The aforementioned limitations restrict the utility of LLMs in understanding complex scenes from textualized graphs.

% iterative methods, and why they potentially cannot be directly applied here.
Recent advances on iterative retrieve-augmented generation \citep{react, activeRAG, press2022measuring, iterRG} provides promising solutions to this challenge.
By interleaving generation with retrieval, these methods aggregate relevant information throughout the reasoning process, reducing factual inaccuracies and improving task performance.
However, adapting these methods to scene graph reasoning is non-trivial.
Designed primarily for reasoning with text corpora, they retrieve information via API call that returns contents semantically relevant to the past reasoning context \citep{IRCoT, react}.
% or neural embedding analysis \citep{iterRG}. 
For the scene graphs, typical built-in graph APIs only return information satisfying local constraints, such as the attributes or adjacency of a queried node, which might lead to large semantic gap between the retrieved information and reasoning demands.
%. This could results in inefficiencies during iterative retrieval, as complex tasks require an increased number of API calls, leading to higher iteration costs and error propagation.% Consequently, these limitations exacerbate hallucination risks and reduce the effectiveness of iterative reasoning with scene graphs.

% our approach
% In this work, we aim to develop an iterative reasoning approach for scene graphs while addressing the above issue. Leveraging \textit{scene graph schema} and the code-writing ability of LLMs, we propose \textbf{\RwR}, a \textbf{S}cene-\textbf{G}raph-tailored \textbf{R}eason-\textbf{w}hile-\textbf{R}etrieve framework, depicted in Figure~\ref{fig:Overview}.
% This framework interleaves the reasoning and scene graph information retrieval phases, which ensures that LLMs focus only on the information that is selectively aligned with the task solving process, and that the reasoning trace is grounded in the graph by factoring in the retrieved graph information.

In this work, we exploit the \textit{scene graph schema} as the bridge between the reasoning and graph interaction. 
\citet{FOLDatabase} shows the existence of an abstract logical description associated with any database schema, enabling formulating queries based on atomic database operations.
Inspired by the work, we propose \RwR, a \textbf{S}chema-\textbf{G}guided \textbf{R}eason-\textbf{w}hile-\textbf{R}etrieve framework for scene graph reasoning, illustrated in Figure~\ref{fig:Overview}. 
% \RwR interleaves reasoning and scene graph information retrieval, ensuring that LLMs focus on task-relevant information and generate reasoning traces grounded in the graph.
The framework features two cooperative LLM-powered agents: a \textit{Reasoner} that decomposes the task and generates information queries for subsequent steps; and a \textit{Retriever} that processes the queries and retrieves related graph information for the Reasoner. 
Unlike previous approaches that prompt LLMs with the entire graph, both agents are \textbf{prompted only with the graph schema}, which provides meta-information about the graph, including the types and formats of the encoded semantic and spatial relationships.
The Reasoner uses the schema to determine \textit{what} information is needed to solve a task, while the Retriever \textbf{writes code} to dynamically query the graph as a database.
The code-writing retrieval strategy enables dynamic formulation based on atomic graph operations, allowing logical and global attention on the graph information to address free-form queries raised by the Reasoner.
We also equip Reasoner with the code-writing mechanism to conduct precise numerical reasoning \citep{lyu2023faithful} and employ external tools for atomic sub-problems, further enhancing the framework's capability to handle complex scene understanding and planning tasks.
Unlike prior iterative methods, \RwR features a two-agent design, where two agents only exchange task-critical messages without redundant thought process. 
This design ensures seamless coordination between reasoning and retrieval stages, reducing misguidance from irrelevant contents in the conversation history.
% The two-agent design of \RwR, unlike previous single-agent iterative methods, ensures seamless coordination between reasoning and retrieval stages. By exchanging only the task-critical messages without the redundant thought process, \RwR ensures a focused and efficient reasoning process, reducing misguidance by the conversation history.
% To prevent hallucinations when processing excessive information, we prompt both LLMs with only the \textit{graph schema} instead of the entire graph.
% The schema describes the types, format, and semantics of the scene information in the graph. 
% It guides the Reasoner to determine \textit{what} information is helpful to solve a given task, and informs the Retriever to \textit{write code} for accessing the graph as a database to obtain the desired information.
% We also equip the Reasoner with code-writing capabilities to conduct precise numerical reasoning \citep{lyu2023faithful} and employ external tools for well-defined atomic problems, thereby enhancing the framework's ability to tackle complex scene understanding and planning tasks.


% summarize outcomes
We evaluate our method with two simulation environments: BabyAI \citep{babyai}, a 2D grid world environment; and VirtualHome \citep{virtualhome}, a large-scale indoor multi-room environment.
Our experiments on numerical Q\&A and planning tasks show that \RwR greatly improves the reasoning ability of LLMs on scene graphs. 
We also observe that \RwR can effectively leverage end-to-end task-level few-shot examples \textit{without requiring module-level demonstrations}. 
Additionally, compared to direct graph prompting methods, \RwR can better extrapolate from few-shot examples to unseen tasks without suffering from severe performance degradation.
Specifically, on the traversal plan generation task in BabyAI, our method outperforms baselines by 18.5 percentage points (pp) in the zero-shot prompt setting, and by 3pp and 60pp in seen and unseen environments in the few-shot prompt setting.

In summary, our contributions include:
\begin{itemize}
   \item A two-agent Reason-while-Retrieve (\RwR) framework with reasoning-oriented information gathering mechanism for task solving on scene graphs. 
   \item Schema-based grounding and code-writing for graph information retrieval and processing that reduces hallucination and improves the reasoning ability of LLMs on complex tasks. 
   \item We show that \RwR performs competitively in two distinct environments that encompass a wide range of tasks under both zero-shot and few-shot settings.
\end{itemize}
