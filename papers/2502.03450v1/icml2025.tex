%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
\PassOptionsToPackage{prologue,dvipsnames}{xcolor}
\documentclass[dvipsnames]{article}

% Recommended, but optional, packages for figures and better typesetting:
% \usepackage{microtype}
% \usepackage{graphicx}
% \usepackage{subfigure}
% \usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}


%------- My packages and commands
\input{packages.tex}
\input{commands.tex}
%--------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2025}

\begin{document}

\twocolumn[
\icmltitle{A Schema-Guided Reason-while-Retrieve framework for  \\ Reasoning on Scene Graphs with Large-Language-Models (LLMs)}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2025
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Yiye Chen}{gt}
\icmlauthor{Harpreet Sawhney}{ms}
\icmlauthor{Nicholas Gyd\'{e}}{ms}
\icmlauthor{Yanan Jian}{ms}
\icmlauthor{Jack Saunders}{ub}
\icmlauthor{Patricio Vela}{gt}
\icmlauthor{Ben Lundell}{ms}
\end{icmlauthorlist}

\icmlaffiliation{gt}{Georgia Institute of Technology}
\icmlaffiliation{ms}{Microsoft}
\icmlaffiliation{ub}{University of Bath}

\icmlcorrespondingauthor{Yiye Chen}{yychen2019@gatech.edu}
% \icmlcorrespondingauthor{Firstname2 Lastname2}{first2.last2@www.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Large Language Models, Spatial Reasoning, Scene Graphs}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
% \printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
% Situated LLM reasoning is important, and use scene graph is one way.
    % Grounding the reasoning and planning capabilities of Large Language Models (LLMs) in specific environments remains a significant challenge. 
    % Recent advancements have demonstrated the effectiveness of representing environments as scene graphs, which offer a flexible and structured way to encode diverse semantic and spatial information.
    Scene graphs have emerged as a structured and serializable environment representation for grounded spatial reasoning with Large Language Models (LLMs).
% Existing method has drawback
    % However, existing approaches that na√Øvely prompt LLMs with serialized graph representations often suffer from hallucinations when processing large graphs and fail to produce graph-grounded reasoning steps for complex spatial problems.
% What we propose
    % In this work, we propose \textbf{\RwR}, an iterative scene graph reasoning framework that addresses these limitations through \textit{scene graph schema} prompting.
    % In this work, we propose \textbf{\RwR}, an iterative scene graph reasoning framework based on scene graph \textit{schema} prompting and the code-writing capacity of LLMs.
    In this work, we propose \textbf{\RwR}, a \textbf{S}chema-\textbf{G}uided \textbf{R}etrieve-\textbf{w}hile-\textbf{R}eason framework for reasoning and planning with scene graphs.
    Our approach employs two cooperative, code-writing LLM agents: a (1) \textit{Reasoner} for task planning and information queries generation, and a (2) \textit{Retriever} for extracting corresponding graph information following the queries.
    Two agents collaborate iteratively, enabling sequential reasoning and adaptive attention to graph information. 
    Unlike prior works, both agents are prompted only with the \textit{scene graph schema} rather than the full graph data, which reduces the hallucination by limiting input tokens, and drives the Reasoner to generate reasoning trace abstractly.
    % , ensuring close alignment between the reasoning and retrieval processes.
    % facilitates focused attention on task-relevant graph information and enables sequential reasoning on the graph essential for complex tasks.
    Following the trace, the Retriever programmatically query the scene graph data based on the schema understanding, allowing dynamic and global attention on the graph that enhances alignment between reasoning and retrieval. 
    % Additionally, the code-writing design allows tool-using to solve problems beyond the capacity of LLMs, which further enhance its reasoning ability facing complex tasks.
% Summarize results
    Through experiments in multiple simulation environments, we show that our framework surpasses existing LLM-based approaches in numerical Q\&A and planning tasks, and can benefit from task-level few-shot examples, even in the absence of agent-level demonstrations.
% code
    Project code will be released. %upon acceptance.
\end{abstract}

\input{ICML2025/sec_intro}
\input{ICML2025/sec_method}
\input{ICML2025/sec_exp_settings}
\input{ICML2025/sec_exp_results}
\input{ICML2025/sec_lit}
\input{ICML2025/sec_conclusion}

% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% usually should) include acknowledgements.  Such acknowledgements
% should be placed at the end of the section, in an unnumbered section
% that does not count towards the paper page limit. Typically, this will 
% include thanks to reviewers who gave useful comments, to colleagues 
% who contributed to the ideas, and to funding agencies and corporate 
% sponsors that provided financial support.

% Impact Statement does not count towards the page limit
\section*{Impact Statement}

The paper presents a framework that enables Large Language Models to solve spatial tasks with scene graphs. 
Due to the wide usage of scene graphs as the environmental representation in both simulators and real world, the proposed framework can be potentially embedded in numerous applications.  
Such applications involve high-level task planning~\cite{sayplan, conceptgraphs}, data collection~\cite{octopus, spatialrgpt}, and building autonomous agent in the gaming or Virtual Reality (VR) environments~\cite{gameAgentSurvey}.
In summary, the framework has the potential to serve as a key module in autonomous systems, enhancing the ability to reason spatially and interact with the environments.



% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{reference}
\bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn
\input{ICML2025/appendix}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
