\section{RELATED WORK}
Mobile Edge Computing (MEC) and Open Radio Access Network (ORAN) are two promising paradigms shaping the future of wireless communication networks. MEC aims to reduce latency by pushing computational capabilities closer to end-users, thereby supporting real-time applications and services [1]. Several studies have highlighted the role of MEC in enabling low-latency computing, particularly for applications such as augmented reality, vehicular networks, and smart cities [2]. MEC provides opportunities for optimizing wireless resource management, as computation and data processing are conducted closer to the data source, significantly enhancing Quality of Service (QoS). The introduction of AI and ML techniques, specifically deep learning and reinforcement learning, has further optimized MEC operations. AI/ML helps address various challenges such as dynamic task offloading, resource allocation, and real-time optimization of network functions, making MEC a promising enabler for the next-generation wireless systems [3].

In addition to MEC, the concept of Open RAN (ORAN) has revolutionized the traditional closed and vendor-specific radio access networks by introducing openness and programmability into the RAN infrastructure. ORAN allows interoperability among different vendor components, making it a flexible and scalable approach for deploying 5G and future networks [5]. Several studies have focused on the architecture of ORAN, which consists of multiple layers, including the near-real-time and non-real-time Radio Intelligent Controllers (RICs). These RICs allow the integration of xApps and rApps to monitor and control various network functions, enabling intelligent control over RAN operations. Moreover, ORAN's open architecture and standardization promote a multi-vendor ecosystem, fostering innovation and competition in the telecommunications industry [6].

AI and ML are being extensively utilized to enhance the efficiency of both MEC and ORAN systems. In MEC, AI/ML algorithms help optimize computation offloading decisions, manage network resources, and predict user behavior for proactive service provisioning [4]. The use of Deep Reinforcement Learning (DRL) in MEC is of particular interest as it allows the system to learn optimal policies for dynamic task offloading and resource allocation under uncertain conditions. DRL-based approaches can model complex relationships and dependencies in the network, leading to significant improvements in latency, energy consumption, and computational efficiency [7]. In a recent study, DRL was used to develop a task offloading strategy that optimizes the distribution of tasks between mobile devices and edge servers, ensuring efficient use of computational resources [3].

Similarly, the application of AI/ML in ORAN has been a focal point of recent research, as ORAN's programmable nature allows for the integration of intelligent algorithms to manage network operations in real-time. The use of DRL in ORAN has enabled the development of intelligent xApps that can make autonomous decisions, such as optimizing resource allocation, managing interference, and enhancing spectral efficiency [5]. For instance, a DRL-based xApp for ORAN was introduced to manage network slicing, dynamically allocate resources, and adapt to changing network conditions in real time [6]. These xApps are integrated with the near-real-time RIC, allowing closed-loop control of network resources, which leads to improved network performance, reliability, and adaptability. Such intelligent control mechanisms are crucial for meeting the demands of diverse applications in next-generation networks, including ultra-reliable low-latency communications (URLLC) and massive machine-type communications (mMTC).

Furthermore, a notable example of leveraging DRL in ORAN is the development of ColO-RAN, an experimental testbed that integrates ORAN architecture with deep reinforcement learning-based xApps for performance evaluation [8]. ColO-RAN allows the deployment of DRL algorithms to validate their impact on network performance, providing insights into the potential of closed-loop control in RAN environments. The ColO-RAN project demonstrated the effectiveness of DRL-based xApps for network slicing, scheduling, and online training, showcasing the ability of these xApps to dynamically adapt to changing network conditions. This flexibility and adaptability are fundamental to meeting the evolving demands of next-generation networks, making ORAN a key player in the future of wireless communications.

The related works discussed above provide a strong foundation for understanding how MEC and ORAN, powered by AI and ML, are transforming the wireless communications landscape. By exploring and analyzing the role of AI/ML in optimizing the efficiency, scalability, and flexibility of MEC and ORAN, these studies highlight the synergies between these two paradigms in shaping the future of next-generation networks. This reading report builds upon these foundational works, further exploring the practical implications of using DRL in MEC and ORAN and presenting insights from a class project that aims to validate and expand upon the existing research in the field [6].