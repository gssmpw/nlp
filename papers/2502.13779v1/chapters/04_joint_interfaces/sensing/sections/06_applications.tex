\section{Applications}
We implemented a series of applications to showcase Omni's potential in supporting spatial interaction with virtual objects that is supported by strong haptic sensations as shown in Figure~\ref{fig:usecases}. While \textit{Omni} can support traditional desktop interaction with haptic cues (\eg free-form tool-based gesture input), we focus our applications on mixed and virtual reality scenarios that are inherently spatial.

Specifically, we demonstrate scenarios in MR, which benefit most from \textit{Omni}'s walk-up-and-use nature to track and haptically actuate an untethered, small magnet in the space around \textit{Omni}'s base.

We implemented our applications using a video pass-through Mixed Reality device (Varjo XR-1), shown in Figure~\ref{fig:photo_device_ar}.
\textit{Videos and photos were recorded live through Varjo's software.}
\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{\dir/sensing/figures/user-applications-live.pdf}
\caption{We combine \textit{Omni} with a video see-through MR device (Varjo XR-1) to showcase the applications.}
\label{fig:photo_device_ar}
\end{figure}

\begin{figure*}[!t]
\centering
\includegraphics[width=\textwidth]{\dir/sensing/figures/applications-02.jpg}
\caption{We present possible use cases for \textit{Omni}. \textit{Left} shows the possibilities in 3D CAD design, in this case sculpting. \textit{Center} shows a user exploring and manipulating an augmented reality object. For both applications, users can feel the shape of the outer hull of the objects. \textit{Right} shows a racing game. Once the car collides with the wall, the pen gets pushed to the base. \textit{Arrows indicate movement and are drawn on top of the photo to increase clarity}. }
\label{fig:usecases}
\vspace{-1em}
\end{figure*}

\subsection{Sculpting}
Figure~\ref{fig:usecases} illustrates how \textit{Omni} haptically supports 3D sculpting and CAD design.

Here, the user finely selects locations on a 3D base object for extrusion by means of the stylus, which is tracked through \textit{Omni}. When extruding individual bumps from the starting configuration, the user can probe and feel the compliance of the material, rendered through attractive and repulsive forces.
Having extruded several bumps from the original shape, the user may inspect the 3D object visually as well as haptically, as \textit{Omni} renders collisions with the tool through tangential actuation.

Following this 3D interaction scenario, \textit{Omni}'s haptic capabilities could be scaled to common 3D editing techniques such as grid snapping, guided object rotation, and 3D transformation.

\subsection{Non-rigid object exploration}
\textit{Omni}'s tracking and actuation also lends itself to haptically rendering geometric objects that are non-rigid and may have anisotropic material properties, such as geographical surfaces, enlarged microscopic surfaces, or other complex geometries.
We demonstrate how \textit{Omni} generates haptic feedback while touching and poking a virtual dragon that is configured to simulate rubber-like material properties.
Here, the force \textit{Omni} renders increases with the amount of object deformation, which portrays the \textit{physical behavior} more accurately than would be possible to experience through mere visual feedback.

\subsection{Gaming}
Finally, we demonstrate how \textit{Omni} can be used for enhancing the experience of gameplay.
Using the magnet-equipped tool as a joystick, we demonstrate how users can steer a car in an AR racing game.
The combination of \textit{Omni}'s haptic feedback and visual control over the car increases the level of immersion provided by the system, as haptic and visual sensations render a coherent experience.
For example, \textit{Omni} renders car collisions with forces whose magnitude depends on collision speeds.