In the previous chapter, we demonstrated the use of model predictive control to determine the actuation of a haptic feedback device. However, it relied on known system dynamics, including predictive models of user behavior. One way to overcome this limitation is through learned system, task, and user dynamics. In this chapter we investigate model-free reinforcement learning for such purpose. Furthermore, we switch away from haptics as use case and focus on adaptive point-and-click interfaces. This switch allows us to focus on the control, as the actuation and sensing in graphical user interfaces are deterministic.
%
A core challenge in developing adaptive interfaces is inferring user intent and choosing adaptations accordingly. Current methods often depend on tediously hand-crafted rules or extensively gathered user data. Furthermore, heuristics need to be recrafted and data regathered for every new task and interface.
%
To address this issue, we formulate interface adaptation as a multi-agent reinforcement learning problem. Our approach learns adaptation policies without relying on heuristics or real user data, enabling the development of adaptive interfaces across various tasks with minimal adjustments.
%
In our formulation, a \useragent mimics a real user and learns to interact with an interface via point-and-click actions. \del{Simultaneously, an \interfaceagent learns interface adaptations, by observing the \useragent's behavior, to maximize the \useragent's efficiency.} Simultaneously, an \interfaceagent learns interface adaptations, to maximize the \useragent's efficiency, by observing the \useragent's behavior. 
%
For evaluation, we replaced the simulated \useragent with actual users. Our study involved twelve participants and focused on automatic toolbar item assignment. Results demonstrate that the policies developed in simulation effectively apply to real users. These users were able to complete tasks with fewer actions and in similar times compared to methods trained with real data. "Additionally, we showcased the method's efficiency and generalizability across four different interfaces and tasks.