\section{Method}
Our main contributions are models and a control strategy that enables using the MPCC framework \cite{lam2013model} for electromagnetic haptic guidance.
MPCC is a closed-loop \emph{time-independent} control strategy that minimizes a cost function over a fixed receding horizon. 
There are several advantages in using our formulation over open-loop (as used in dePENd~\cite{yamaoka2013depend}) or time-dependent strategies (\eg MPC). 
%
First, closed-loop control allows to react to user-input, whereas open-loop control removes all user agency. 
Both MPC and MPCC are closed-loop control strategies. 
However, MPC tracks a timed reference, requiring a fixed velocity by users. 
MPCC follows a time-free trajectory, which allows the user to progress at their own speed. 
\figref{fig:control} illustrates the expected behavior for the different strategies, given that the user slows down or stops moving the pen. 
The desired behavior here would be that the algorithm essentially ``waits'', \ie provides guidances towards a slowly or no-longer advancing setpoint.
In this situation, open-loop approaches would lead to lost haptic guidance. 
Closed-loop time-dependent approaches would guide the pen towards a constantly advancing setpoint (although users do no longer move), which can lead to problems such as the user being guided backwards (\eg timestep $t=3$ is in front of $t=2$).

\begin{figure}[!t]
    \centering
    \vspace{-.5em}
    \includegraphics[width=\columnwidth]{\dir/figures//control_strategies-02.pdf}
    \caption{
    Overview of different control strategies on a target trajectory (\textit{green}), with constant pen position.
    For open-loop, the position of the electromagnet is identical to the constantly advancing setpoint, leading to loss of haptic guidance.
    For MPC, although the pen is static, the guidance changes at every timestep since the setpoint advances.
    In our approach, the setpoint is also based on the pen position, therefore remains stationary in this case and guides the user towards the target trajectory.}
    \label{fig:control}
    \vspace{-1em}
\end{figure}

Our method is designed to exert a force $\mathbf{F}_\theta$ of desired strength onto the pen to guide the user towards the target trajectory $\mathbf{s}$. 
The path $\mathbf{s}$ of length $L$ is parametrized by $\theta \in[0,L]$. 
Note that we do not prescribe how fast users draw and hence for each given pen position $\posp$ we first need to establish the closest position on the path parameterized by $\mathbf{s}(\theta)$.
The vector between the pen position and $\mathbf{s}(\theta)$ is defined as $\Rtheta$.
We leverage a receding horizon optimization strategy and the global reference can hence be adjusted or replaced entirely at every iteration. 
The path $\mathbf{s}$ is then a local fit to the global reference.
Furthermore, we seek to find optimized values for the electromagnet intensity $\alpha$ and the in-plane electromagnet position $\mathbf{p}_{m}$. 
Solving the error functional given in Eq. (\ref{eq:J_k}) at each timestep yields optimized values for system states $\mathbf{x}$ and inputs $\mathbf{u}$.   
 
As common in MPC(C), the system is initialized from measurements at $t=0$. 
The system state is then propagated over the horizon with the dynamics model $f(\mathbf{x},\mathbf{u})$. 
The system state vector $\mathbf{x}$ contains variables that are controlled by the algorithm (magnet intensity and position, current path progress). 
The first of the optimized inputs ($u_0$) is then applied to the physical system, transitioning the system state to $x_1$, before iteratively repeating the process to allow for correcting modeling errors. 

% ####################################################
% ####################################################
% ####################################################

\begin{figure}[!t]
% \vspace{-1em}
    \centering
    \includegraphics[width=.8\columnwidth]{\dir/figures//cost-force-02.pdf} 
    \caption{Illustration of actuation force $\mathbf{F_a}$, desired force $\mathbf{F_{\theta}}$, and the force cost-term $\Cost_f$ associate with the difference between those two forces. 
    }
    \label{fig:em_model}
% \vspace{-1em}
\end{figure}

\subsection{Haptics model: controlling the force of the electromagnet} \label{sc:em_costs}
The main goals of our approach is that users can move freely in terms of position and speed, and that the actuator continuously pulls them towards an advancing setpoint $\mathbf{s}(\theta)$ on the target trajectory $\mathbf{s}$.
At any time, the magnet exhibits an actuation force $\mathbf{F_a}$ on the pen,  given by our electromagnetic force model (see \nameref{sec:Implementation} section).
Therein lies the challenge, illustrated in \figref{fig:em_model}. 
The setpoint is continuously advancing based on the movement of the pen to ensure progress.
The actuator needs to pull the pen towards the setpoint by exhibiting force $\mathbf{F_\theta}$, but currently exhibits $\mathbf{F_a}$.
The two forces only align if the pen is exactly at the setpoint, which is rarely the case.
To overcome this challenge, we propose modeling this interaction by a spring-like behavior that ``pulls'' $\mathbf{F_a}$ towards  $\mathbf{F_\theta}$.
In this way, the magnet continuously guides the pen towards the setpoint, and the force linearly increases with distance between the pen and the target setpoint denoted as:
\begin{equation}
     \mathbf{F}_{\theta} (\Rtheta) = c \ F_0 \ \mathbf{r_{\theta}} \ \mathbf{e_{r_{\theta}}} \ . \label{eq:Fd}
\end{equation}
Here $\mathbf{e_{r_{\theta}}}$ is a unit vector in the direction of $\mathbf{r_{\theta}}$, $c$ is a scalar that regulates the stiffness of the spring (in our case $c=5/h$), $F_0$ a scaling of the EM force (\ie the force felt by users) and $h$ the distance between dipoles in $z$ (see Fig. \ref{fig:em_model}). 
Although simple, this formulation ensures that the haptic guidance is strong under large deviation from the path while vanishing as the user approaches the target path ($r_{\theta} \to 0$). 
Note that Eq. \ref{eq:Fd} is a design choice. 
Different formulations can be used to achieve different user experiences. 
Furthermore, replacing our hardware prototype and force-model would allow for adaptation of the remainder of the method to different actuation principles.
%Note that the EM force saturates at $F_a^{max}$.

The above haptics model serves as basis for our problem formulation of electromagnetic guidance in the MPCC framework.
Using the vectors of the current actuation force $\mathbf{F_a}$ and desired force $\mathbf{F_\theta}$, we formulate a quadratic cost term to penalize the difference between desired force and actual force as:
\begin{equation}\label{eq:err_F}
    \Cost_f(\posm, \posp, \alpha) = \norm{ \ \mathbf{F}_{\theta}(\Rtheta) \ - \ \mathbf{F_a}(\mathbf{d}) \ }^2. 
    \end{equation}
%
where $\mathbf{d}$ is the in-plane vector between the magnet and the pen.
Since the actuation force $\mathbf{F_a}$ declines rapidly with distance $\mathbf{d}$, the gradient of $\Cost_f$ goes to 0 for large values of $\mathbf{d}$ causing the optimization to become unstable. 
To counterbalance this issue we encourage the electromagnet to stay close to the pen:
\begin{equation}
    \Cost_d(\posm,\posp) = d^2. \label{eq:err_d}
\end{equation}

Finally, we prioritize proximity between the magnet and the pen rather than increasing its force by penalizing excessive use of magnetic intensity $\alpha$:
\begin{equation}
    \Cost_{\alpha}(\alpha) = \alpha^2. \label{eq:err_alpha}
\end{equation}
%
%
\subsection{Controlling the position of the electromagnet} 
We continuously optimize the position of the electromagnet with the goal of keeping the distance between the desired path and the pen minimal. 
To give the user freedom in deciding their drawing speed we first need to find the reference point $\mathbf{s}(\theta)$ on the target trajectory $\mathbf{s}$. 
Finding the closest point on the path is an optimization problem itself and hence can not be used within our optimization. 
Similar to recent work in robot trajectory generation \cite{Naegeli:2017:MultiDroneCine, Gebhardt:2018}, we decompose the distance to the closest point into a contouring and lag error, as shown in Figure~\ref{fig:elc}. 
%
$\Rtheta$ is the vector between the pen $\posp$ and a point $\mathbf{s}(\theta)$ on the spline, and $\mathbf{n}$ as the normalized tangent vector to the spline at that point, which is defined as $\mathbf{n} = \frac{\partial \mathbf{s} (\theta)}{\partial\theta}$.
%
The vector $\Rtheta$ can now be decomposed into a lag error and a contour error (\figref{fig:elc}). 
The lag-error $\Cost_l$ is computed as the projection of $\Rtheta$.
The contour-error $\Cost_c$ is the component of $\Rtheta$ orthogonal to the normal:
%
\begin{equation}
    \begin{aligned}\label{eq:errL_C} 
\Cost_l (\posp, \theta) &= \norm{\langle\Rtheta,\mathbf{n}\rangle}^2 , \\
\Cost_c (\posp, \theta) &= \norm{ \Rtheta - \left( \langle\Rtheta,\mathbf{n}\rangle \right) \mathbf{n} }^2.
\end{aligned}
\end{equation}
%
Separating lag from contouring error allows us, for example, to differentiate how we penalize a deviation from the path ($\Cost_c$), versus encouraging the user to progress ($\Cost_l$). %This also ensures that the $\posst$ is not influenced to a large extent by the cost function and it is at a close position on the desired path. 
We furthermore include cost terms to ensure that the magnet stays ahead of the pen ($\Cost_{\theta}$) and to encourage smooth progress ($\Cost_{\dot{\theta}}$) computed as
% 
\begin{equation} \label{eq:err_theta}
  \begin{aligned}
\Cost_{\theta}(\theta) &= - \theta ,\\
\Cost_{\dot{\theta}}(\dot{\theta}) &= (\dot{\theta}_t-\dot{\theta}_{t-1})^2 .
\end{aligned}  
\end{equation}

\begin{figure}[!t]
    \centering
    \includegraphics[width=.9\columnwidth]{\dir/figures//cost-lag-contour-02.pdf}
    \caption{Illustration of lag- and contouring error decomposition.}
    \label{fig:elc}
    \vspace{-1em}
\end{figure}

% ################################################
% ################################################
\subsection{Dynamics model}
% Standard mass point model
To phrase electromagnetic haptic guidance in the MPCC framework, we contribute a a dynamics model $f(\mathbf{x},\mathbf{u})$ describing the system dynamics given its states $\mathbf{x}$ and inputs $\mathbf{u}$.  
\begin{equation}
\begin{gathered}
\label{eq:model}
    \dot{\mathbf{x}} = f(\mathbf{x}, \mathbf{u}) ~\text{with}\\
    \mathbf{x} = [\mathbf{p}_{m},\dot{\mathbf{p}}_{m}, \alpha, \theta] \in \mathbb{R}^6
    ~\text{and} ~
    \mathbf{u} = [\ddot{\mathbf{p}}_{m}, \dot{\alpha}, \dot{\theta}] \in \mathbb{R}^4.
\end{gathered}
\end{equation}

The system state $\mathbf{x}$ consists of the position of the electromagnet $\mathbf{p}_{m} \in  \mathbb{R}^2$ and its velocity $\dot{\mathbf{p}}_{m}$, the magnet intensity $\alpha$ and the current path progress $\theta$.
The inputs to the system $\mathbf{u}$ consist of the in-plane electromagnet accelerations $\ddot{\mathbf{p}}_{m}$, and velocities $\dot{\alpha}$ and $\dot{\theta}$ for magnet intensity and the spline progress respectively.
Note that we empirically found that magnet accelerations yield smoother motion than using velocities. 
% 
The system model is given by the non-linear ordinary differential equations using first and second derivatives as inputs:
\begin{equation}
  \ddot{\mathbf{p}}_{m} = v_{m}, \quad \dot{\alpha} = v_{\alpha} \quad \text{and} \quad \dot{\theta} = v_{\theta} ,  
\end{equation}
where $v_{\left(\cdot\right)}$ are the external inputs. 
The continuous dynamics model $\dot{\mathbf{x}} = f(\mathbf{x}, \mathbf{u})$ is discretized using a standard forward Euler approach: $\mathbf{x}_{t+1} = f(\mathbf{x}_t, \mathbf{u}_t)$ \cite{gibbs2011advanced}.

In our hardware implementation, we derive the sets of admissible states $\boldsymbol{\chi}$ and inputs $\boldsymbol{\zeta}$ empirically to conform to the physical hardware constraints of the linear stage (\eg max x,y-position) and EM specifications (\eg max voltage). 
These are used in the constrained optimization problem solved in Eq. \ref{eq:mpcc-formulation}.
%
The pen position is propagated via a standard linear Kalman filter \cite{gibbs2011advanced}. 
While not an accurate user model, it works well in practice since the states are recalculated at every timestep. 


% ################################################
% ################################################

\begin{table}[!t]
	\begin{tabular}{clc}
    \toprule
    Term & Description of cost & Eq.\\
    \midrule
     $\Cost_f$  		& Decreases difference in magnetic force		& \ref{eq:err_F}
     \\
    $\Cost_d$ 		& Decreases distance between magnet and pen		& \ref{eq:err_d}
    \\
    $\Cost_{\alpha}$ 		& Encourages close distance over large force		& \ref{eq:err_alpha}
    \\
     $\Cost_l$   				& Decreases lag to path contour		& \ref{eq:errL_C} 
     \\     
     $\Cost_c$  			& Decreases distance to path contour		& \ref{eq:errL_C} 
     \\
     $\Cost_{\theta}$  				& Magnet stays ahead of pen		& \ref{eq:err_theta}
     \\
     $\Cost_{\dot{\theta}}$ 		& Ensures smooth progress		& \ref{eq:err_theta}
    \\
     \bottomrule
\end{tabular}
\caption{Summary of costs terms used in optimization.}
\label{tab:costs}
\end{table}

\subsection{Optimization}
We combine the cost terms (Table \ref{tab:costs}) to control the force and position of the actuator to form the final stage cost:
%
\begin{align}\label{eq:J_k}
J_k= \quad 
     & w_f \Cost_f(\mathbf{p}_{m,k}, \mathbf{p}_{p,k}, \alpha_k, \theta_k) + \nonumber \\
     & w_d \Cost_d(\mathbf{p}_{m,k}, \mathbf{p}_{p,k}) + w_\alpha \Cost_{\alpha}(\alpha_k)+ \nonumber \\
	 &	 w_l \Cost_l(\mathbf{p}_{p,k}, \theta_k) +  w_c \Cost_c(\mathbf{p}_{p,k}, \theta_k) + \nonumber \\
     & w_{\theta} \Cost_{\theta}(\theta_k) +  w_{\dot{\theta}} \Cost_{\dot{\theta}}(\dot{\theta}_k),
\end{align}
%
where the scalar weights $w_l,w_c,w_{\theta},w_{\dot{\theta}},w_f,w_d, w_{\alpha}>0$ control the influence of the different cost terms. 
The values used in our experiments and applications can be found in the \nameref{sec:Implementation} section.
The system states and inputs are computed by solving the $N$-step finite horizon constrained non-linear optimization problem at time instance $t$. 

The final objective therefore is:
\begin{align}
\label{eq:mpcc-formulation}
\underset{\mathbf{x}, \mathbf{u}, \theta}{\text{minimize}}\quad & \sum_{k=0}^{N} w_k\left ( J_k + \mathbf{u}_k^T \mathbf{R} \mathbf{u_k} \right ) && \\
\text{Subject to:}\quad & \mathbf{x} _{k+1} = f(\mathbf{x_k}, \mathbf{u_k}) & \text{(System Model)} \nonumber\\
                        & \mathbf{x}_0 = \hat{\mathbf{x}}(t) & \text{(Initial State)} \nonumber \\
                        & \theta_0 = \hat{\theta}(t) & \text{(Initial Progress)} \nonumber \\
                        & \theta_{k+1} = \theta_k + \dot{\theta}_k dt & \text{(Progress along path)} \nonumber \\
                        & 0 \leq \theta_k \leq L& \text{(Path Length)} \nonumber \\
                        & \mathbf{x}_k \in \boldsymbol{\chi} & \text{(State Constraints)} \nonumber \\
                        & \mathbf{u}_k \in \boldsymbol{\zeta} & \text{(Input Constraints)} \nonumber
\end{align}

Here $k$ indicates the horizon stage and the additional weight $w_k$ reduces over the horizon, so that the current timestep has more importance than later timesteps. 
$\mathbf{R}\in\mathbb{S}_+^{n_u}$ is a positive definite penalty matrix avoiding excessive use of the control inputs. 
In our implementation we use a horizon length of $N=10$. 
Experimentally we found that this is sufficient to yield robust solutions to problem instances and longer horizons did not improve results, yet linearly increases computation time. 

% \input{content/algorithm.tex}