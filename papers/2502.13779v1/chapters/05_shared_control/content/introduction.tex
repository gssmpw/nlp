\chapter{Introduction}
\label{ch:control:introduction}
% Problem --> Naive policy
In the previous part we have seen how haptic \interfaces might have the potential to increase the intuitiveness of interactions. However, our control strategy of the haptic actuators was na\"ive and not intelligent, leading to subpar interactions. Specifically, our control strategy was based around the current tool position and did not take into account user intent, future states of the system, or bounds to the control.  

% Solution --> Predictive
One solution to this problem is to make use of optimal control formulations (see \ref{}). Optimal control is a branch of control theory that deals with finding a control for a dynamical system over a period of time such that an objective function is minimized \cite{ross2015primer}. Although this addresses both the optimization over future states and enables constraints to the system, it does not take the user into account. 

% Our work
In contrast, our work enables explicit and implicit user models in optimal control strategies. To this end, we introduce two projects. First, we introduce \magpen. \magpen introduces an model predictive control method for electromagnetic haptic guidance systems. Our real-time approach assists users in pen-based tasks such as
drawing, sketching or designing. The key to our control method is that it guides users, yet does not take away agency. To achieve this flexible guidance, our optimization iteratively predicts the motion of an input device such as a pen, and adjusts the position and strength of an underlying dynamic electromagnetic actuator accordingly. However, \magpen relies on an explicit described linear system dynamic. This is challenging, as these system dynamic include a user model. We linearlized the user behavioral model through assumptions. However, this is suboptimal and does not generalize to other \interfaces. 

Second we introduce, \marlui. \marlui overcomes \magpen's limitation by learning system dynamics implicitly. In \marlui, we focus on adaptive user interfaces. Specifically, we formulate interface adaptation as a multi-agent reinforcement learning problem. Our approach learns adaptation policies without relying on heuristics or real user data, facilitating the development of adaptive interfaces across various tasks with minimal adjustments needed. In our formulation, a user agent mimics a real user and learns to interact with an interface via point-and-click actions. Simultaneously, an interface agent learns interface adaptations, to maximize the user agent’s efficiency, by observing the user agent’s behavior. 

% Implications
The implications of our research in shared control on \interfaces is two-fold. First, we show how to integrate models of human behavior explicitly and implicitly into optimal control strategies for intelligent systems. This enables the systems to take into account future states and actions, and optimize the system inputs accordingly. Second, we introduce a method that does not require an explicit user model or system dynamics description. This enables the method to generalize across interfaces and tasks. Treating HCI, and specifically the interaction with intelligent systems, as a multi-agent reinforcement problem is intuitive and enables future extensions of our work.  

% Summary
In summary, we introduce two optimal control strategies. First, A model-based predictive control strategy to optimize the input to a haptic system. Second, a model-free multi agent reinforcement learning strategy for adaptive user interfaces. We show that our methods enable an autonomy-automation trade-off, which results in better user performance, in terms of speed, accuracy and number of actions, compared to alternatives. Our research is a starting point to think and investigate the role of predictive user models in control loops. 