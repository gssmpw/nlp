\section{Approach}
\label{sec:Approach}
This dissertation aims to bridge the gap between user agency and system automation through four projects divided into two primary directions. First, we discuss the design of shared variable interfaces. Second, we explore the control strategies for such interfaces.
\subsection{The Design of Shared Variable Interfaces}

In shared variable interfaces, both the user and the system act on a shared variable, which can take many forms, such as the acceleration of a car or a graphical menu in an operating system. A special instance of this shared variable is kinesthetic haptic feedback. Here, not only is the variable itself shared (e.g., the position of a joystick), but the action and perception of the variable are in the same modality from the user's perspective. For example, to change or perceive a joystick's position, the user uses their hands. This singular interaction modality contrasts sharply with, for example, touch interfaces, where users perceive the UI through their eyes but interact with it using their hands. Using an interface with a single interaction modality potentially reduces confounding factors when investigating interactions with shared variable interfaces. This shared domain allows for simultaneous interaction between a user and an intelligent system.

Previous work in kinesthetic haptic feedback generally revolves around complex mechanical contraptions (\eg \cite{Massie94, Stamper1997, VanDerLinde2002, Araujo2016, zoller2019assessment, Sinclair2019Capstan}). Further extensions of such systems include exoskeletons~\cite{Gu2016, Choi2016}, gloves~\cite{Cybergrasp, hinchet2018dextres}, and tilt-platforms~\cite{Prattichizzo2013, Kim2016}. However, these often require user instrumentation and inherently involve system friction, which users will always perceive. This friction leads to a system that, even when off, does not allow for full user agency.

To overcome the limitations of not covering the full spectrum from user agency to system automation and to enable our research, we introduce novel haptic interfaces. These haptic devices sense and actuate a]passive tool. We introduce a novel spherical electromagnet that acts on an embedded permanent magnet, enabling an untethered tool that allows for full user agency without physical constraints while simultaneously providing large grounded forces, which enables system automation.

In Part II, we introduce i) a novel spherical electromagnet (\chapref{ch:shared:contact}, published in \cite{zarate2020contact}), and ii) a gradient-based tool tracking algorithm (\chapref{ch:shared:volumetric}, published in \cite{Langerak:2020:Omni}). This combination allows us to deliver dynamic haptic feedback. We evaluate our system both technically and with users. We find that interacting with a shared variable in the same modality allows for natural interactions that increase user agency. However, our findings also suggest that more intelligent system control is necessary to enable more complex dynamics.

\subsection{The Control of Shared Variable Interfaces}
Previous systems typically use open-loop control \cite{yamaoka2013depend} to control intelligent systems. This approach fails to consider the user, eliminating the capability to trade off user agency with system automation. Alternatively, some systems use heuristics \cite{Lopes16, Browne1990, Smith2010, Stephanidis1997}, which require tediously crafted rules by experts. Furthermore, supervised learning \cite{Maes1995, Lashkari1997, McCreath2006, Faulring2010, Shen2009a, Shen2009b, Berry2011, Pejovic2014, Mehrotra2015} and multi-armed bandits \cite{glowacka2019bandit, lomas2016interface, koch2019may, kangas2022scalable, Koyama2014, Koyama2016} are popular approaches for controlling intelligent systems. However, these approaches optimize for a myopic decision, failing to consider future states of both the system and the user. Optimizing purely for the next timestep limits the system's capabilities to intelligently trade off user agency and system automation. In contrast, our work minimizes a cost function over a receding horizon[,] taking into account expected user and system behavior. This enables an explicitly optimized balance between agency and automation, taking into account possible future states.

In Part III, we first discuss Model Predictive Contour Control (MPCC), an optimization-based control strategy that uses a supplied model of the system dynamics in combination with a cost function (\chapref{ch:control:optimal}, published in \cite{langerak2020magpen}). We apply this in the context of a prototypical pen-based electromagnetic haptic-feedback system. Our approach allows users to easily override the system, adapt their input spontaneously, and draw at their own speed. While beneficial, crafting a system dynamic that includes user behavior is challenging. Secondly, we focus on UI adaptation as a use case of an interface with a shared variable (\chapref{ch:control:multi}, published in \cite{Langerak:2024:MARLUI}). Moving from haptics to a digital-only interface offers several advantages. Adaptive User Interfaces allow us to focus on control strategies, overcoming any sim-to-real gap confounding factors. Furthermore, existing cognitive models (such as Fitts' Law \cite{fitts1954information}) can be utilized in this context. To overcome the challenge of crafting system dynamics that include user behavior, we turn to Reinforcement Learning (RL) as a control strategy and a means to learn both user and system dynamics models that are intertwined. By formulating UI adaptation as a multi-agent reinforcement learning problem, we introduce a user agent that mimics a real user and learns to interact with an interface, while simultaneously introducing an agent that learns a control strategy to maximize the user agent's performance. The control agent learns the task structure from the user agent's behavior and, based on that knowledge, can support the user agent in completing its task.