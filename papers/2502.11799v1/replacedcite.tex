\section{Related Work}
\textbf{Table Reasoning.}
Table reasoning, which requires joint understanding of semi-structured tables and questions, has evolved through several paradigms. Early approaches focused on developing specialized models through fine-tuning____, while recent work has shifted towards leveraging large language models (LLMs) in few-shot learning____. To handle complex reasoning tasks, decomposition-based methods have emerged as a promising direction. These methods break down complex tasks into manageable steps, either through program execution____ or context-aware table partitioning____. However, a critical limitation of existing approaches is their inability to effectively critique and refine intermediate reasoning steps, leading to error propagation.
In contrast, our Table-Critic framework addresses this limitation by introducing systematic critique and refinement mechanisms throughout the reasoning process.

% Table reasoning involves reasoning over semi-structured tables and unstructured questions. Early approaches focused on fine-tuning specialized models____, while recent work leverages LLMs in few-shot settings____. Decomposition-based methods, such as Binder____, Dater____, and Chain-of-Table____, have shown promise by breaking down tasks into manageable steps, such as program execution or context-aware table partitioning. However, these methods lack mechanisms to critique and refine intermediate steps, leading to error propagation. Our method, Table-Critic, addresses this gap by introducing stepwise critique and refinement to improve reasoning accuracy.

\textbf{Self-Reflection.}
Recent studies have revealed that while LLMs possess inherent self-reflection capabilities, they often suffer from reliability and consistency issues____. Simply enforcing self-reflection can be counterproductive, as models tend to either rationalize their errors or excessively critique correct reasoning steps____. To address these limitations, our Table-Critic introduces a structured approach through: (1) a multi-agent framework where specialized agents collaborate to provide targeted critiques, and (2) a self-evolving template tree that systematically accumulates and organizes critique knowledge. This design effectively overcomes the inherent limitations of LLMs' reflection capabilities while maintaining reliable and consistent error identification.


% LLMs possess some self-reflection capabilities, but their critiques often lack reliability and consistency____. Enforcing self-reflection can introduce biases, such as rationalizing errors or over-criticizing correct reasoning____. To tackle these issues, Table-Critic employs a multi-agent framework that iteratively critiques reasoning steps using specialized agents and a self-evolving template tree. This approach systematically refines errors and accumulates critique knowledge, offering a novel solution for robust table reasoning.

% \textbf{Multi-agent Systems.}
% Multi-agent systems have recently demonstrated promising potential in complex reasoning tasks by enabling collaborative problem-solving through specialized agents____. While these systems have been explored in various domains, their application to table reasoning remains unexplored. Our work presents the first attempt to leverage multi-agent collaboration for table reasoning, where specialized agents work together to critique and refine the reasoning process.


% \subsection{Table Reasoning}
% Table reasoning tasks involve reasoning over semi-structured tables and unstructured questions, with research evolving from fine-tuning specialized models ____ to leveraging LLMs in few-shot settings ____. To address the inherent complexity of these tasks, decomposition strategies have gained traction. For example, Binder ____ decompose complex questions into executable sub-programs, such as SQL or Python, enabling finer-grained reasoning. Similarly, Dater ____ and Chain-of-Table ____ dynamically decompose tables using context-aware strategies, enhancing reasoning over intricate tabular data. While these decomposition-based methods have achieved promising results by simplifying reasoning tasks, they lack mechanisms for critically evaluating and refining intermediate steps, leading to error propagation and reduced accuracy. To address this, our method, Table-Critic, introduces a stepwise critic mechanism that dynamically assesses and refines intermediate reasoning steps, mitigating error accumulation and improving overall performance.


% Table reasoning tasks require the ability to reason over both unstructured questions and semi-structured tables. Research in this area has evolved from fine-tuning specialized models ____ to leveraging LLMs in few-shot settings ____, exploiting the growing reasoning capabilities of these models.

% \textbf{Question Decomposition.} A prominent approach to table reasoning is decomposing complex questions into simpler, more manageable sub-questions. Binder ____ generates SQL or Python programs that decompose a primary question into multiple sub-questions and modifies the program statements by calling LLMs as APIs. Similarly, LEVER ____ also decomposes natural language question into runnable SQL programs and trains code LLMs to verify the programs correctness.
% Decomposing questions into smaller sub-questions has proven effective in addressing complex reasoning challenges. However, these methods struggle with difficult cases involving intricate tables, primarily due to the limitations of the single-pass generation process, where LLMs lack the ability to reason over a static table without dynamic adaptation ____.

% \textbf{Table Decomposition.} To address the limitations of processing entire tables, many multi-step reasoning frameworks that transform the tables according to the given question have been proposed ____. Dater ____ decomposes both tables and questions using a "parsing-execution-filling" strategy. Chain-of-Table ____ utilizes a larger set of generic table operations and dynamically generates tables to solve the problems.
% % However, while dynamic decomposition has shown promise, these methods often lack a mechanism for evaluating the intermediate reasoning steps. This limitation may lead to error accumulation or poor generalization.
% While dynamic decomposition enhances the reasoning process, these methods lack mechanisms to evaluate and refine intermediate reasoning steps. Without such evaluation, errors in intermediate steps can accumulate, ultimately undermining the model's overall performance and generalization capabilities.

% Our approach, Table-Critic, introduces a stepwise critic mechanism to the table reasoning tasks, integrating a dynamically updated template tree to critically assess the intermediate steps of reasoning.

% \subsection{Critic}
% Recent studies have investigated the self-reflection capabilities of large language models (LLMs) and their ability to critique their own outputs. While LLMs have demonstrated some potential for self-reflection, it has been observed that their self-assessments often lack reliability and consistency ____. Simply enforcing self-reflection during reasoning tasks can introduce new challenges, such as rationalizing incorrect reasoning or over-criticizing correct steps, particularly in structured tasks like table reasoning ____. These limitations highlight the need for more robust mechanisms to improve reasoning performance.
% To the best of our knowledge, our work is the first to extend the critique framework to table reasoning tasks in a step-by-step manner. By iteratively applying the critique process at each reasoning stage and incorporating multi-turn interactions, our approach enables more granular error detection and more effective evaluation of intermediate reasoning steps, addressing key limitations in prior works.
% LLMs have been proposed as cost-effective alternatives to human critics ____, capable of discriminating and criticizing the model outputs in a text-generation manner ____. These methods often first provide explanations for critiques of the output, then return a discrete score or preference label as the prediction ____. While effective in critiquing text generation, these methods largely focus on evaluating final outputs, without exploring intermediate reasoning steps or handling semi-structured data, such as tables. 

% To the best of our knowledge, we are the first to extend the concept of a step-by-step critic to table reasoning tasks. Our approach iteratively applies the critique process at each reasoning stage and integrates multi-turn interactions. This allows for more granular error detection and effective evaluation of mistakes made during reasoning steps.


% \begin{figure*}[t]
%   \centering
%   \includegraphics[width=\textwidth]{method.pdf}
%   \caption{a) Illustration of the Table-Critic framework: Table-Critic consists of four components—Judge, Template Tree, Critic, and Refiner—that collaboratively refine reasoning steps and predicted answers for table-based questions through error identification and critique generation. b) Dynamic Expansion of Template Tree: The Template Tree undergoes dynamic updates through direct, vertical, and horizontal expansions to enhance the reasoning process.}
%   \label{method}
% \end{figure*}

% Self-critics have emerged as crucial mechanisms for enhancing the textual reasoning capabilities of LLMs, yet their potential for table reasoning with semi-structured data remains largely unexplored. 
% Moreover, existing critics are mainly experience-driven, often critiquing answers directly without relying on a solid theoretical foundation. 

% \begin{algorithm}
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}
% \caption{Table-Critic}
% \label{alg1}
% \begin{algorithmic}[1]
% \REQUIRE \fontsize{10}{15}\selectfont $T, Q, R,P$
% \STATE \fontsize{10}{13}\selectfont $judge \leftarrow \texttt{Judge}(T, Q, P)$
% \WHILE{\fontsize{10}{13}\selectfont $judge$ is incorrect}
% \STATE \fontsize{10}{13}\selectfont $templates \leftarrow \texttt{TemplateTree}(T, Q, R, P)$
% \STATE \fontsize{10}{13}\selectfont $critique, i \leftarrow \texttt{Critic}(templates, T, Q, R, P)$
% \STATE \fontsize{10}{13}\selectfont $R \leftarrow R[1:i-1]$
% \STATE \fontsize{10}{13}\selectfont $R, P \leftarrow \texttt{Refiner}(critique, T, Q, R)$
% \STATE \fontsize{10}{13}\selectfont $judge \leftarrow \texttt{Judge}(T, Q, P)$
% \ENDWHILE
% \STATE \fontsize{10}{13}\selectfont Update \texttt{TemplateTree}
% \ENSURE \fontsize{10}{15}\selectfont $P$
% \end{algorithmic}
% \end{algorithm}





% \begin{algorithm*}
% \renewcommand{\algorithmicrequire}{\textbf{Input:}}
% \renewcommand{\algorithmicensure}{\textbf{Output:}}
% \caption{Table-Critic}
% \label{alg1}
% \begin{algorithmic}[1]
% \REQUIRE $T, Q, R, P$ \hfill {\small $\triangleright$ Table $T$, Question $Q$, Reasoning steps $R$, Predicted answer $P$}
% \STATE $judge \leftarrow \texttt{Judge}(T, Q, P)$ \hfill {\small $\triangleright$ Determine whether the $P$ is correct}
% \WHILE{$judge$ is incorrect}
% \STATE $template \leftarrow \texttt{TemplateTree}(T, Q, R, P)$ \hfill {\small $\triangleright$ Generate critique templates}
% \STATE $critique, i \leftarrow \texttt{Critic}(template, T, Q, R, P)$ \hfill {\small $\triangleright$ Generate stepwise critique and}
% \STATE \hfill {\small the first error step number $i$} 
% % \\ \hfill {\small $\triangleright$ based on the template}
% \STATE $R \leftarrow R[1:i-1]$ \hfill {\small $\triangleright$ Retain the correct steps from the previous $i-1$ steps}
% \STATE $R, P \leftarrow \texttt{Refiner}(critique, T, Q, R)$ \hfill {\small $\triangleright$ Based on the critique, update the reasoning steps $R$ }
% \\ \hfill {\small and the predicted answer $P$ from the first error step}
% \STATE $judge \leftarrow \texttt{Judge}(T, Q, P)$ \hfill {\small $\triangleright$ Determine again whether the updated answer $P$ is correct}
% \ENDWHILE
% \STATE Update \texttt{TemplateTree}
% \ENSURE $P$ \hfill {\small $\triangleright$ Output the refined answer $P$}
% \end{algorithmic}
% \end{algorithm*}