[
  {
    "index": 0,
    "papers": [
      {
        "key": "yin2020tabert",
        "author": "Yin, Pengcheng and Neubig, Graham and Yih, Wen-tau and Riedel, Sebastian",
        "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
      },
      {
        "key": "liu2021tapex",
        "author": "Liu, Qian and Chen, Bei and Guo, Jiaqi and Ziyadi, Morteza and Lin, Zeqi and Chen, Weizhu and Lou, Jian-Guang",
        "title": "TAPEX: Table pre-training via learning a neural SQL executor"
      },
      {
        "key": "gu2022pasta",
        "author": "Zihui Gu and\nJu Fan and\nNan Tang and\nPreslav Nakov and\nXiaoman Zhao and\nXiaoyong Du",
        "title": "{PASTA:} Table-Operations Aware Fact Verification via Sentence-Table\nCloze Pre-training"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "chen2024tablerag",
        "author": "Si{-}An Chen and\nLesly Miculicich and\nJulian Eisenschlos and\nZifeng Wang and\nZilong Wang and\nYanfei Chen and\nYasuhisa Fujii and\nHsuan{-}Tien Lin and\nChen{-}Yu Lee and\nTomas Pfister",
        "title": "TableRAG: Million-Token Table Understanding with Language Models"
      },
      {
        "key": "zhao2024tapera",
        "author": "Yilun Zhao and\nLyuhao Chen and\nArman Cohan and\nChen Zhao",
        "title": "TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table\n{QA} by Content Planning and Execution-based Reasoning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "cheng2022binding",
        "author": "Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others",
        "title": "Binding language models in symbolic languages"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ye2023large",
        "author": "Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin",
        "title": "Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning"
      },
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yin2020tabert",
        "author": "Yin, Pengcheng and Neubig, Graham and Yih, Wen-tau and Riedel, Sebastian",
        "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
      },
      {
        "key": "liu2021tapex",
        "author": "Liu, Qian and Chen, Bei and Guo, Jiaqi and Ziyadi, Morteza and Lin, Zeqi and Chen, Weizhu and Lou, Jian-Guang",
        "title": "TAPEX: Table pre-training via learning a neural SQL executor"
      },
      {
        "key": "gu2022pasta",
        "author": "Zihui Gu and\nJu Fan and\nNan Tang and\nPreslav Nakov and\nXiaoman Zhao and\nXiaoyong Du",
        "title": "{PASTA:} Table-Operations Aware Fact Verification via Sentence-Table\nCloze Pre-training"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chen2024tablerag",
        "author": "Si{-}An Chen and\nLesly Miculicich and\nJulian Eisenschlos and\nZifeng Wang and\nZilong Wang and\nYanfei Chen and\nYasuhisa Fujii and\nHsuan{-}Tien Lin and\nChen{-}Yu Lee and\nTomas Pfister",
        "title": "TableRAG: Million-Token Table Understanding with Language Models"
      },
      {
        "key": "zhao2024tapera",
        "author": "Yilun Zhao and\nLyuhao Chen and\nArman Cohan and\nChen Zhao",
        "title": "TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table\n{QA} by Content Planning and Execution-based Reasoning"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "cheng2022binding",
        "author": "Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others",
        "title": "Binding language models in symbolic languages"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ye2023large",
        "author": "Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin",
        "title": "Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "MadaanTGHGW0DPY23",
        "author": "Aman Madaan and\nNiket Tandon and\nPrakhar Gupta and\nSkyler Hallinan and\nLuyu Gao and\nSarah Wiegreffe and\nUri Alon and\nNouha Dziri and\nShrimai Prabhumoye and\nYiming Yang and\nShashank Gupta and\nBodhisattwa Prasad Majumder and\nKatherine Hermann and\nSean Welleck and\nAmir Yazdanbakhsh and\nPeter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      },
      {
        "key": "abs-2412-19513",
        "author": "Zhe Yang and\nYichang Zhang and\nYudong Wang and\nZiyao Xu and\nJunyang Lin and\nZhifang Sui",
        "title": "Confidence v.s. Critique: {A} Decomposition of Self-Correction Capability\nfor LLMs"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "critic-cot",
        "author": "Xin Zheng and\nJie Lou and\nBoxi Cao and\nXueru Wen and\nYuqiu Ji and\nHongyu Lin and\nYaojie Lu and\nXianpei Han and\nDebing Zhang and\nLe Sun",
        "title": "Critic-CoT: Boosting the reasoning abilities of large language model\nvia Chain-of-thoughts Critic"
      },
      {
        "key": "chen2025learning",
        "author": "Guoxin Chen and Zhong Zhang and Xin Cong and Fangda Guo and Yesai Wu and Yankai Lin and Wenzheng Feng and Yasheng Wang",
        "title": "Learning Evolving Tools for Large Language Models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "MadaanTGHGW0DPY23",
        "author": "Aman Madaan and\nNiket Tandon and\nPrakhar Gupta and\nSkyler Hallinan and\nLuyu Gao and\nSarah Wiegreffe and\nUri Alon and\nNouha Dziri and\nShrimai Prabhumoye and\nYiming Yang and\nShashank Gupta and\nBodhisattwa Prasad Majumder and\nKatherine Hermann and\nSean Welleck and\nAmir Yazdanbakhsh and\nPeter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      },
      {
        "key": "abs-2412-19513",
        "author": "Zhe Yang and\nYichang Zhang and\nYudong Wang and\nZiyao Xu and\nJunyang Lin and\nZhifang Sui",
        "title": "Confidence v.s. Critique: {A} Decomposition of Self-Correction Capability\nfor LLMs"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "critic-cot",
        "author": "Xin Zheng and\nJie Lou and\nBoxi Cao and\nXueru Wen and\nYuqiu Ji and\nHongyu Lin and\nYaojie Lu and\nXianpei Han and\nDebing Zhang and\nLe Sun",
        "title": "Critic-CoT: Boosting the reasoning abilities of large language model\nvia Chain-of-thoughts Critic"
      },
      {
        "key": "chen2025learning",
        "author": "Guoxin Chen and Zhong Zhang and Xin Cong and Fangda Guo and Yesai Wu and Yankai Lin and Wenzheng Feng and Yasheng Wang",
        "title": "Learning Evolving Tools for Large Language Models"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "GuoCWCPCW024",
        "author": "Taicheng Guo and\nXiuying Chen and\nYaqi Wang and\nRuidi Chang and\nShichao Pei and\nNitesh V. Chawla and\nOlaf Wiest and\nXiangliang Zhang",
        "title": "Large Language Model Based Multi-agents: {A} Survey of Progress and\nChallenges"
      },
      {
        "key": "pmlr-v235-zhang24au",
        "author": "Zhang, Bin and Mao, Hangyu and Li, Lijuan and Xu, Zhiwei and Li, Dapeng and Zhao, Rui and Fan, Guoliang",
        "title": "Sequential Asynchronous Action Coordination in Multi-Agent Systems: A Stackelberg Decision Transformer Approach"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "yin2020tabert",
        "author": "Yin, Pengcheng and Neubig, Graham and Yih, Wen-tau and Riedel, Sebastian",
        "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
      },
      {
        "key": "liu2021tapex",
        "author": "Liu, Qian and Chen, Bei and Guo, Jiaqi and Ziyadi, Morteza and Lin, Zeqi and Chen, Weizhu and Lou, Jian-Guang",
        "title": "TAPEX: Table pre-training via learning a neural SQL executor"
      },
      {
        "key": "gu2022pasta",
        "author": "Zihui Gu and\nJu Fan and\nNan Tang and\nPreslav Nakov and\nXiaoman Zhao and\nXiaoyong Du",
        "title": "{PASTA:} Table-Operations Aware Fact Verification via Sentence-Table\nCloze Pre-training"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "chen2022large",
        "author": "Chen, Wenhu",
        "title": "Large language models are few (1)-shot table reasoners"
      },
      {
        "key": "liu2023rethinking",
        "author": "Liu, Tianyang and Wang, Fei and Chen, Muhao",
        "title": "Rethinking Tabular Data Understanding with Large Language Models"
      },
      {
        "key": "chen2024tablerag",
        "author": "Si{-}An Chen and\nLesly Miculicich and\nJulian Eisenschlos and\nZifeng Wang and\nZilong Wang and\nYanfei Chen and\nYasuhisa Fujii and\nHsuan{-}Tien Lin and\nChen{-}Yu Lee and\nTomas Pfister",
        "title": "TableRAG: Million-Token Table Understanding with Language Models"
      },
      {
        "key": "zhao2024tapera",
        "author": "Yilun Zhao and\nLyuhao Chen and\nArman Cohan and\nChen Zhao",
        "title": "TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table\n{QA} by Content Planning and Execution-based Reasoning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "cheng2022binding",
        "author": "Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others",
        "title": "Binding language models in symbolic languages"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "ye2023large",
        "author": "Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin",
        "title": "Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "yin2020tabert",
        "author": "Yin, Pengcheng and Neubig, Graham and Yih, Wen-tau and Riedel, Sebastian",
        "title": "TaBERT: Pretraining for joint understanding of textual and tabular data"
      },
      {
        "key": "liu2021tapex",
        "author": "Liu, Qian and Chen, Bei and Guo, Jiaqi and Ziyadi, Morteza and Lin, Zeqi and Chen, Weizhu and Lou, Jian-Guang",
        "title": "TAPEX: Table pre-training via learning a neural SQL executor"
      },
      {
        "key": "gu2022pasta",
        "author": "Zihui Gu and\nJu Fan and\nNan Tang and\nPreslav Nakov and\nXiaoman Zhao and\nXiaoyong Du",
        "title": "{PASTA:} Table-Operations Aware Fact Verification via Sentence-Table\nCloze Pre-training"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "chen2022large",
        "author": "Chen, Wenhu",
        "title": "Large language models are few (1)-shot table reasoners"
      },
      {
        "key": "liu2023rethinking",
        "author": "Liu, Tianyang and Wang, Fei and Chen, Muhao",
        "title": "Rethinking Tabular Data Understanding with Large Language Models"
      },
      {
        "key": "chen2024tablerag",
        "author": "Si{-}An Chen and\nLesly Miculicich and\nJulian Eisenschlos and\nZifeng Wang and\nZilong Wang and\nYanfei Chen and\nYasuhisa Fujii and\nHsuan{-}Tien Lin and\nChen{-}Yu Lee and\nTomas Pfister",
        "title": "TableRAG: Million-Token Table Understanding with Language Models"
      },
      {
        "key": "zhao2024tapera",
        "author": "Yilun Zhao and\nLyuhao Chen and\nArman Cohan and\nChen Zhao",
        "title": "TaPERA: Enhancing Faithfulness and Interpretability in Long-Form Table\n{QA} by Content Planning and Execution-based Reasoning"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "cheng2022binding",
        "author": "Cheng, Zhoujun and Xie, Tianbao and Shi, Peng and Li, Chengzu and Nadkarni, Rahul and Hu, Yushi and Xiong, Caiming and Radev, Dragomir and Ostendorf, Mari and Zettlemoyer, Luke and others",
        "title": "Binding language models in symbolic languages"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "ni2023lever",
        "author": "Ni, Ansong and Iyer, Srini and Radev, Dragomir and Stoyanov, Veselin and Yih, Wen-tau and Wang, Sida and Lin, Xi Victoria",
        "title": "Lever: Learning to verify language-to-code generation with execution"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "ye2023large",
        "author": "Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin",
        "title": "Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning"
      },
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      },
      {
        "key": "abhyankar2024h",
        "author": "Abhyankar, Nikhil and Gupta, Vivek and Roth, Dan and Reddy, Chandan K",
        "title": "H-STAR: LLM-driven Hybrid SQL-Text Adaptive Reasoning on Tables"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "ye2023large",
        "author": "Ye, Yunhu and Hui, Binyuan and Yang, Min and Li, Binhua and Huang, Fei and Li, Yongbin",
        "title": "Large language models are versatile decomposers: Decomposing evidence and questions for table-based reasoning"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "wang2024chain",
        "author": "Wang, Zilong and Zhang, Hao and Li, Chun-Liang and Eisenschlos, Julian Martin and Perot, Vincent and Wang, Zifeng and Miculicich, Lesly and Fujii, Yasuhisa and Shang, Jingbo and Lee, Chen-Yu and others",
        "title": "Chain-of-table: Evolving tables in the reasoning chain for table understanding"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "MadaanTGHGW0DPY23",
        "author": "Aman Madaan and\nNiket Tandon and\nPrakhar Gupta and\nSkyler Hallinan and\nLuyu Gao and\nSarah Wiegreffe and\nUri Alon and\nNouha Dziri and\nShrimai Prabhumoye and\nYiming Yang and\nShashank Gupta and\nBodhisattwa Prasad Majumder and\nKatherine Hermann and\nSean Welleck and\nAmir Yazdanbakhsh and\nPeter Clark",
        "title": "Self-Refine: Iterative Refinement with Self-Feedback"
      },
      {
        "key": "abs-2412-19513",
        "author": "Zhe Yang and\nYichang Zhang and\nYudong Wang and\nZiyao Xu and\nJunyang Lin and\nZhifang Sui",
        "title": "Confidence v.s. Critique: {A} Decomposition of Self-Correction Capability\nfor LLMs"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "critic-cot",
        "author": "Xin Zheng and\nJie Lou and\nBoxi Cao and\nXueru Wen and\nYuqiu Ji and\nHongyu Lin and\nYaojie Lu and\nXianpei Han and\nDebing Zhang and\nLe Sun",
        "title": "Critic-CoT: Boosting the reasoning abilities of large language model\nvia Chain-of-thoughts Critic"
      },
      {
        "key": "chen2025learning",
        "author": "Guoxin Chen and Zhong Zhang and Xin Cong and Fangda Guo and Yesai Wu and Yankai Lin and Wenzheng Feng and Yasheng Wang",
        "title": "Learning Evolving Tools for Large Language Models"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "scheurer2023training",
        "author": "Scheurer, J{\\'e}r{\\'e}my and Campos, Jon Ander and Korbak, Tomasz and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan",
        "title": "Training language models with language feedback at scale"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "luo2023critique",
        "author": "Luo, Liangchen and Lin, Zi and Liu, Yinxiao and Shu, Lei and Zhu, Yun and Shang, Jingbo and Meng, Lei",
        "title": "Critique ability of large language models"
      },
      {
        "key": "zeng2023challenge",
        "author": "Zeng, Zhongshen and Chen, Pengguang and Jiang, Haiyun and Jia, Jiaya",
        "title": "Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil Cognitive Depth in LLMs"
      },
      {
        "key": "renze2024self",
        "author": "Renze, Matthew and Guven, Erhan",
        "title": "Self-Reflection in LLM Agents: Effects on Problem-Solving Performance"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "zheng2023judging",
        "author": "Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others",
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena"
      },
      {
        "key": "yan2024predicting",
        "author": "Yan, Jing Nathan and Liu, Tianqi and Chiu, Justin and Shen, Jiaming and Qin, Zhen and Yu, Yue and Lakshmanan, Charumathi and Kurzion, Yair and Rush, Alexander M and Liu, Jialu and others",
        "title": "Predicting text preference via structured comparative reasoning"
      },
      {
        "key": "xu2024perfect",
        "author": "Xu, Tengyu and Helenowski, Eryk and Sankararaman, Karthik Abinav and Jin, Di and Peng, Kaiyan and Han, Eric and Nie, Shaoliang and Zhu, Chen and Zhang, Hejia and Zhou, Wenxuan and others",
        "title": "The perfect blend: Redefining RLHF with mixture of judges"
      }
    ]
  }
]