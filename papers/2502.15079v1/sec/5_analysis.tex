\section{Analysis}
\label{sec:analysis}
\looseness=-1

\paragraph{Performance on text-to-video retrieval.} 
\method{} consistently outperforms both the pretrained model and the entailment fine-tuned model, as illustrated in \autoref{fig:ssv2}. This demonstrates \method{}'s ability to effectively capture the rich temporal information present in videos. On the SSv2-Events dataset, while the entailment objective yields performance comparable to the pretrained Video-LLaVA, \method{} achieves better results on this action-intensive dataset, despite being fine-tuned on the same amount of data.
Additional comparisons with other models are provided in \autoref{app:ablation}.

\paragraph{Performance on video-language binding.} 
\autoref{table:velociti} shows that, on average, both Video-LLaVA and VideoChat2 fine-tuned with the \method{} objective outperform the pre-trained models and those fine-tuned with the entailment objective. 
Masking correction further boosts performance through data augmentation.
The \textit{Agent Coref} test evaluates a model's ability to link events to specific agents, a misalignment type absent in the VideoCon dataset, where actions are always tied to one agent. Consequently, the pretrained Video-LLaVA outperforms its fine-tuned versions, with \method{} marginally exceeding the entailment baseline.
The \textit{Chrono} test measures a model's ability to detect reversed event order. While VideoCon includes such data, our results show that models fine-tuned on the entailment objective perform similarly to the pretrained model. Although \method{} slightly underperforms the entailment objective, it excels on SSv2-Events, involving multiple events.


\method{} consistently outperforms baseline models in all \textit{Action} tests: \textit{Action Adv} (replacing an action with one not in the video), \textit{Action Bind} (replacing an action within the same video), and \textit{Action Modif} (replacing the manner with a plausible modifier). 
This highlights \method{}'s robust ability to distinguish actions in videos, requiring understanding of complex spatio-temporal relationships between the video and its description.
\method{} also excels in \textit{Agent Iden}
and \textit{Agent Bind},
showcasing its effectiveness in identifying and binding entities through the right relationship.


\paragraph{Qualitative examples.}
\input{figures/qualitative_main}
\autoref{fig:qualtitative_main} presents an example where \method{} outperforms the entailment baseline on the VELOCITI dataset, and delivers accurate corrections. Additional qualitative examples are provided in \autoref{app:qualitative_analysis}.


\paragraph{\method{} does not hinder question answering.}
To assess whether fine-tuning with the \method{} objective affects the multi-task capabilities of Video-LLMs, we conduct a zero-shot evaluation on the MSRVTT-QA dataset \cite{xu2016msr} using GPT-3.5-turbo. The results, presented in \autoref{tab:msrvtt_vqa}, are based on a subset of 7,000 samples (10\% of the dataset) due to budget constraints. The GPT-evaluated score for the pretrained Video-LLaVA model aligns with previously reported values \cite{lin2023video}.
As shown in the table, the \method{}-finetuned model performs comparably to the pretrained Video-LLaVA model, despite not involving explicit QA-specific finetuning. In contrast, fine-tuning with the entailment objective alone leads to a significant performance drop on MSRVTT-QA. A possible explanation is that optimizing for a single entailment label may impair the language generation capabilities of video-language models.


\begin{table}[h]
    \centering
    \small
    \begin{tabular}{lc}
        \toprule
        \textbf{Model}       & \textbf{GPT Score} \\
        \midrule
        Video-LLaVA & 3.5 \\
        + Entail     & 2.8 \\
        + HACA       & 3.4 \\
        \bottomrule
    \end{tabular}
    \caption{Zero-shot GPT-assessed score on MSRVTT-QA for the model trained with the baseline entailment task, and our proposed \method{} objective. GPT-assessed scores ranges from 0 to 5.}
    \label{tab:msrvtt_vqa}
\end{table}
