\section{Related Work}
\looseness=-1
In addition to the video-language alignment approaches discussed in \autoref{sec:intro}, several methods leverage a contrastive learning objective to learn a shared video-language embedding space \cite{xue2023clipvip, rasheed2023fine, girdhar2023imagebind, zhu2024languagebind}, and \citet{bagad2023test} further introduces a contrastive loss in Video-LLMs to enforce time-order consistency. 
However, most of these models lack robustness to semantically plausible manipulations \cite{park2022exposing}. 
\citet{yuksekgonul2022and} also finds that applying a contrastive objective to video-caption datasets does not promote the modelâ€™s ability to capture fine-grained details. 
In contrast, our approach encourages Video-LLMs to capture more nuanced semantic mismatches by learning to correct hallucinations, extending beyond sentence-level hallucination detection.
More discussion is provided in \autoref{app:related_work}.

