@article{COELHO2020106274,
    title = {{Is this GitHub project maintained? Measuring the level of
             maintenance activity of open-source projects}},
    journal = {Information and Software Technology},
    volume = {122},
    pages = {106274},
    year = {2020},
    issn = {0950-5849},
    doi = {https://doi.org/10.1016/j.infsof.2020.106274},
    url = {https://www.sciencedirect.com/science/article/pii/S0950584920300240},
    author = {Jailton Coelho and Marco Tulio Valente and Luciano Milen and
              Luciana L. Silva},
    keywords = {Unmaintained projects, GitHub, Open source software},
    abstract = {Context GitHub hosts an impressive number of high-quality OSS
                projects. However, selecting “the right tool for the job” is a
                challenging task, because we do not have precise information
                about those high-quality projects. Objective In this paper, we
                propose a data-driven approach to measure the level of
                maintenance activity of GitHub projects. Our goal is to alert
                users about the risks of using unmaintained projects and possibly
                motivate other developers to assume the maintenance of such
                projects. Method We train machine learning models to define a
                metric to express the level of maintenance activity of GitHub
                projects. Next, we analyze the historical evolution of 2927
                active projects in the time frame of one year. Results From 2927
                active projects, 16% become unmaintained in the interval of one
                year. We also found that Objective-C projects tend to have lower
                maintenance activity than projects implemented in other
                languages. Finally, software tools—such as compilers and
                editors—have the highest maintenance activity over time.
                Conclusions A metric about the level of maintenance activity of
                GitHub projects can help developers to select open source
                projects.},
}

@inbook{Gomez2019,
    author = "G{\'o}mez, Sergio",
    editor = "Moscato, Pablo and de Vries, Natalie Jane",
    title = "Centrality in Networks: Finding the Most Important Nodes",
    bookTitle = "Business and Consumer Analytics: New Ideas",
    year = "2019",
    publisher = "Springer International Publishing",
    address = "Cham",
    pages = "401--433",
    abstract = "Real networks are heterogeneous structures, with edges unevenly
                distributed among nodes, presenting community structure, motifs,
                transitivity, rich clubs, and other kinds of topological
                patterns. Consequently, the roles played by nodes in a network
                can differ greatly. For example, some nodes may be connectors
                between parts of the network, others may be central or peripheral
                , etc. The objective of this chapter is to describe how we can
                find the most important nodes in networks. The idea is to define
                a centrality measure for each node in the network, sort the nodes
                according to their centralities, and fix our attention to the
                first ranked nodes, which can be considered as the most relevant
                ones with respect to this centrality measure.",
    isbn = "978-3-030-06222-4",
    doi = "10.1007/978-3-030-06222-4_8",
    url = "https://doi.org/10.1007/978-3-030-06222-4_8",
}


@inproceedings{10.1145/3600160.3605164,
    author = {Tatschner, Stefan and Peters, Sebastian N. and Emeis, David and
              Morris, John and Newe, Thomas},
    title = {{A Quic(k) Security Overview: A Literature Research on Implemented
             Security Recommendations}},
    year = {2023},
    isbn = {9798400707728},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3600160.3605164},
    doi = {10.1145/3600160.3605164},
    abstract = {Built on top of UDP, the relatively new QUIC protocol serves as
                the baseline for modern web protocol stacks. Equipped with a rich
                feature set, the protocol is defined by a 151&nbsp;pages strong
                IETF standard complemented by several additional documents.
                Enabling fast updates and feature iteration, most QUIC
                implementations are implemented as user space libraries leading
                to a large and fragmented ecosystem. This work addresses the
                research question, “if a complex standard with a large number of
                different implementations leads to an insecure ecosystem?”. The
                relevant RFC documents were studied and “Security Consideration”
                items describing conceptional problems were extracted. During the
                research, 13&nbsp;popular production ready QUIC implementations
                were compared by evaluating 10&nbsp;security considerations from
                RFC9000. While related studies mostly focused on the functional
                part of QUIC, this study confirms that available QUIC
                implementations are not yet mature enough from a security point
                of view.},
    booktitle = {Proceedings of the 18th International Conference on
                 Availability, Reliability and Security},
    articleno = {55},
    numpages = {8},
    keywords = {web, security considerations, RFC9000, QUIC},
    location = {<conf-loc>, <city>Benevento</city>, <country>Italy</country>,
                </conf-loc>},
    series = {ARES '23},
}

@inproceedings{7807909,
    author = {Howlader, Prantik and Sudeep, K. S},
    booktitle = {{2016 IEEE International Conference on Recent Trends in
                 Electronics, Information \& Communication Technology (RTEICT)}},
    title = {Degree centrality, eigenvector centrality and the relation between
             them in Twitter},
    year = {2016},
    volume = {},
    number = {},
    pages = {678-682},
    abstract = {In Social Media the directed links formed between the users, are
                used for the transfer of information. Based on previous research,
                the rate of information transfer in a social network depends on
                the strength of connections of the user in the network, which is
                measured by the centrality value. In this paper, based on data
                collected from Twitter, we perform an analysis of eigenvector
                centrality approach of finding the influential users. We
                investigate the variation in indegree and eigenvector centrality
                of users participating in a hashtag in Twitter, with respect to
                change in the amount of interactions. Here interactions are:
                tweets, mentions and replies. We also investigate the
                relationship between indegree and eigenvector centrality in a
                given hashtag. We make the following interesting observations.
                First, in Twitter, users with high eigenvector centrality need
                not be influential users. Second, in a given hashtag, there is an
                increase in users with both high indegree and eigenvector
                centrality when there are more user interactions. Here
                interactions are: tweets, mentions and replies, indicating both
                indegree and eigenvector centrality should be considered when
                finding influential users. Third, there is a positive correlation
                between indegree and eigenvector centrality.},
    keywords = {Twitter;Tagging;Conferences;Market research;Communications
                technology;Correlation coefficient;Twitter;Eigenvector
                Centrality;Degree Centrality},
    doi = {10.1109/RTEICT.2016.7807909},
    ISSN = {},
    month = {May},
}

@inproceedings{7884604,
    author = {Decan, Alexandre and Mens, Tom and Claes, Maëlick},
    booktitle = {2017 IEEE 24th International Conference on Software Analysis,
                 Evolution and Reengineering (SANER)},
    title = {{An empirical comparison of dependency issues in OSS packaging
             ecosystems}},
    year = {2017},
    volume = {},
    number = {},
    pages = {2-12},
    abstract = {Nearly every popular programming language comes with one or more
                open source software packaging ecosystem(s), containing a large
                collection of interdependent software packages developed in that
                programming language. Such packaging ecosystems are extremely
                useful for their respective software development community. We
                present an empirical analysis of how the dependency graphs of
                three large packaging ecosystems (npm, CRAN and RubyGems) evolve
                over time. We study how the existing package dependencies impact
                the resilience of the three ecosystems over time and to which
                extent these ecosystems suffer from issues related to package
                dependency updates. We analyse specific solutions that each
                ecosystem has put into place and argue that none of these
                solutions is perfect, motivating the need for better tools to
                deal with package dependency update problems.},
    keywords = {},
    doi = {10.1109/SANER.2017.7884604},
    ISSN = {},
    month = {Feb},
}

@inproceedings{9054837,
    author = {Abate, Pietro and Di Cosmo, Roberto and Gousios, Georgios and
              Zacchiroli, Stefano},
    booktitle = {2020 IEEE 27th International Conference on Software Analysis,
                 Evolution and Reengineering (SANER)},
    title = {{Dependency Solving Is Still Hard, but We Are Getting Better at It}
             },
    year = {2020},
    volume = {},
    number = {},
    pages = {547-551},
    doi = {10.1109/SANER48275.2020.9054837},
}

@article{Decan2019,
    author = {Decan, Alexandre and Mens, Tom and Grosjean, Philippe},
    title = {{An empirical comparison of dependency network evolution in seven
             software packaging ecosystems}},
    journal = {Empirical Software Engineering},
    year = {2019},
    month = {Feb},
    day = {01},
    volume = {24},
    number = {1},
    pages = {381-416},
    abstract = {Nearly every popular programming language comes with one or more
                package managers. The software packages distributed by such
                package managers form large software ecosystems. These packaging
                ecosystems contain a large number of package releases that are
                updated regularly and that have many dependencies to other
                package releases. While packaging ecosystems are extremely useful
                for their respective communities of developers, they face
                challenges related to their scale, complexity, and rate of
                evolution. Typical problems are backward incompatible package
                updates, and the risk of (transitively) depending on packages
                that have become obsolete or inactive. This manuscript uses the
                libraries.io dataset to carry out a quantitative empirical
                analysis of the similarities and differences between the
                evolution of package dependency networks for seven packaging
                ecosystems of varying sizes and ages: Cargo for Rust, CPAN for
                Perl, CRAN for R, npm for JavaScript, NuGet for the .NET platform
                , Packagist for PHP, and RubyGems for Ruby. We propose novel
                metrics to capture the growth, changeability, reusability and
                fragility of these dependency networks, and use these metrics to
                analyze and compare their evolution. We observe that the
                dependency networks tend to grow over time, both in size and in
                number of package updates, while a minority of packages are
                responsible for most of the package updates. The majority of
                packages depend on other packages, but only a small proportion of
                packages accounts for most of the reverse dependencies. We
                observe a high proportion of ``fragile'' packages due to a high
                and increasing number of transitive dependencies. These findings
                are instrumental for assessing the quality of a package
                dependency network, and improving it through dependency
                management tools and imposed policies.},
    issn = {1573-7616},
    doi = {10.1007/s10664-017-9589-y},
    url = {https://doi.org/10.1007/s10664-017-9589-y},
}

@article{10.1145/1411203.1411255,
    author = {Dolstra, Eelco and L\"{o}h, Andres},
    title = {{NixOS: A Purely Functional Linux Distribution}},
    year = {2008},
    issue_date = {September 2008},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {43},
    number = {9},
    issn = {0362-1340},
    url = {https://doi.org/10.1145/1411203.1411255},
    doi = {10.1145/1411203.1411255},
    abstract = {Existing package and system configuration management tools
                suffer from an imperative model, where system administration
                actions such as upgrading packages or changes to system
                configuration files are stateful: they destructively update the
                state of the system. This leads to many problems, such as the
                inability to roll back changes easily, to run multiple versions
                of a package side-by-side, to reproduce a configuration
                deterministically on another machine, or to reliably upgrade a
                system. In this paper we show that we can overcome these problems
                by moving to a purely functional system configuration model. This
                means that all static parts of a system (such as software
                packages, configuration files and system startup scripts) are
                built by pure functions and are immutable, stored in a way
                analogously to a heap in a purely function language. We have
                implemented this model in NixOS, a non-trivial Linux distribution
                that uses the Nix package manager to build the entire system
                configuration from a purely functional specification.},
    journal = {SIGPLAN Not.},
    month = {sep},
    pages = {367–378},
    numpages = {12},
    keywords = {nix, software deployment, purely functional language, package
                management, purely functional deployment model, system
                configuration management, NixOS},
}

@article{9631870,
    author = {Mujahid, Suhaib and Costa, Diego Elias and Abdalkareem, Rabe and
              Shihab, Emad and Saied, Mohamed Aymen and Adams, Bram},
    journal = {IEEE Transactions on Engineering Management},
    title = {{Toward Using Package Centrality Trend to Identify Packages in
             Decline}},
    year = {2022},
    volume = {69},
    number = {6},
    pages = {3618-3632},
    doi = {10.1109/TEM.2021.3122012},
}

@article{BORGES2018112,
    title = {{What’s in a GitHub Star? Understanding Repository Starring
             Practices in a Social Coding Platform}},
    journal = {Journal of Systems and Software},
    volume = {146},
    pages = {112-129},
    year = {2018},
    issn = {0164-1212},
    doi = {https://doi.org/10.1016/j.jss.2018.09.016},
    url = {https://www.sciencedirect.com/science/article/pii/S0164121218301961},
    author = {Hudson Borges and Marco {Tulio Valente}},
    keywords = {GitHub stars, Software popularity, Social coding},
    abstract = {Besides a git-based version control system, GitHub integrates
                several social coding features. Particularly, GitHub users can
                star a repository, presumably to manifest interest or
                satisfaction with an open source project. However, the real and
                practical meaning of starring a project was never the subject of
                an in-depth and well-founded empirical investigation. Therefore,
                we provide in this paper a throughout study on the meaning,
                characteristics, and dynamic growth of GitHub stars. First, by
                surveying 791 developers, we report that three out of four
                developers consider the number of stars before using or
                contributing to a GitHub project. Then, we report a quantitative
                analysis on the characteristics of the top-5,000 most starred
                GitHub repositories. We propose four patterns to describe stars
                growth, which are derived after clustering the time series
                representing the number of stars of the studied repositories; we
                also reveal the perception of 115 developers about these growth
                patterns. To conclude, we provide a list of recommendations to
                open source project managers (e.g., on the importance of social
                media promotion) and to GitHub users and Software Engineering
                researchers (e.g., on the risks faced when selecting projects by
                GitHub stars).},
}

@inproceedings{Zhang2017/03,
    title = {{Degree Centrality, Betweenness Centrality, and Closeness
             Centrality in Social Network}},
    author = {Junlong Zhang and Yu Luo},
    year = {2017/03},
    booktitle = {Proceedings of the 2017 2nd International Conference on
                 Modelling, Simulation and Applied Mathematics (MSAM2017)},
    pages = {300-303},
    issn = {1951-6851},
    isbn = {978-94-6252-324-1},
    url = {https://doi.org/10.2991/msam-17.2017.68},
    doi = {10.2991/msam-17.2017.68},
    publisher = {Atlantis Press},
}

@article{PLAGA2019596,
    title = {{Securing future decentralised industrial IoT infrastructures:
             Challenges and free open source solutions}},
    journal = {Future Generation Computer Systems},
    volume = {93},
    pages = {596-608},
    year = {2019},
    issn = {0167-739X},
    doi = {https://doi.org/10.1016/j.future.2018.11.008},
    url = {https://www.sciencedirect.com/science/article/pii/S0167739X18314043},
    author = {Sven Plaga and Norbert Wiedermann and Simon Duque Anton and Stefan
              Tatschner and Hans Schotten and Thomas Newe},
    keywords = {Industrial Internet of Things, Cyber security, Decentralisation,
                Smart environments, Secure communications},
    abstract = {The next industrial revolution is said to be paved by the use of
                novel Internet of Things (IoT) technology. One important aspect
                of the modern IoT infrastructures is decentralised communication,
                often called Peer-to-Peer (P2P). In the context of industrial
                communication, P2P contributes to resilience and improved
                stability for industrial components. Current industrial
                facilities, however, still rely on centralised networking schemes
                which are considered to be mandatory to comply with security
                standards. In order to succeed, introduced industrial P2P
                technology must maintain the current level of protection and also
                consider possible new threats. The presented work starts with a
                short analysis of well-established industrial communication
                infrastructures and how these could benefit from decentralised
                structures. Subsequently, previously undefined Information
                Technology (IT) security requirements are derived from the new
                cloud based decentralised industrial automation model
                architecture presented in this paper. To meet those requirements,
                state-of-the-art communication schemes and their open source
                implementations are presented and assessed for their usability in
                the context of industrial IoT. Finally, derived building blocks
                for industrial IoT P2P security are presented which are qualified
                to comply with the stated industrial IoT security requirements.},
}




@inproceedings{heinl2020,
    author = {Heinl, Michael P. and Giehl, Alexander and Graif, Lukas},
    title = {{AntiPatterns Regarding the Application of Cryptographic Primitives
             by the Example of Ransomware}},
    year = {2020},
    isbn = {9781450388337},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3407023.3409182},
    doi = {10.1145/3407023.3409182},
    booktitle = {Proceedings of the 15th International Conference on
                 Availability, Reliability and Security},
    articleno = {64},
    numpages = {10},
    keywords = {Ransomware, AntiPatterns, Cryptography},
    location = {Virtual Event, Ireland},
    series = {ARES '20},
}



@article{s21154969,
    AUTHOR = {Tatschner, Stefan and Jarisch, Ferdinand and Giehl, Alexander and
              Plaga, Sven and Newe, Thomas},
    TITLE = {{The Stream Exchange Protocol: A Secure and Lightweight Tool for
             Decentralized Connection Establishment}},
    JOURNAL = {Sensors},
    VOLUME = {21},
    YEAR = {2021},
    NUMBER = {15},
    ARTICLE-NUMBER = {4969},
    URL = {https://www.mdpi.com/1424-8220/21/15/4969},
    PubMedID = {34372205},
    ISSN = {1424-8220},
    ABSTRACT = {With the growing availability and prevalence of internet-capable
                devices, the complexity of networks and associated connection
                management increases. Depending on the use case, different
                approaches in handling connectivity have emerged over the years,
                tackling diverse challenges in each distinct area. Exposing
                centralized web-services facilitates reachability; distributing
                information in a peer-to-peer fashion offers availability; and
                segregating virtual private sub-networks promotes
                confidentiality. A common challenge herein lies in connection
                establishment, particularly in discovering, and securely
                connecting to peers. However, unifying different aspects,
                including the usability, scalability, and security of this
                process in a single framework, remains a challenge. In this paper
                , we present the Stream Exchange Protocol (SEP) collection, which
                provides a set of building blocks for secure, lightweight, and
                decentralized connection establishment. These building blocks use
                unique identities that enable both the identification and
                authentication of single communication partners. By utilizing
                federated directories as decentralized databases, peers are able
                to reliably share authentic data, such as current network
                locations and available endpoints. Overall, this collection of
                building blocks is universally applicable, easy to use, and
                protected by state-of-the-art security mechanisms by design. We
                demonstrate the capabilities and versatility of the SEP
                collection by providing three tools that utilize our building
                blocks: a decentralized file sharing application, a
                point-to-point network tunnel using the SEP trust model, and an
                application that utilizes our decentralized discovery mechanism
                for authentic and asynchronous data distribution.},
    DOI = {10.3390/s21154969},
}

@inproceedings{7490780,
    author = {Jing Wang and Qingbo Wu and Yusong Tan and Jing Xu and Xiaoli Sun},
    booktitle = {2015 4th International Conference on Computer Science and
                 Network Technology (ICCSNT)},
    title = {{A graph method of package dependency analysis on Linux Operating
             system}},
    year = {2015},
    volume = {01},
    number = {},
    pages = {412-415},
    abstract = {Maintaining package-based Linux operating system distributions
                and addressing their evolution have always been a challenge.
                Since all packages that form a distribution of Linux Operating
                system interact with each other, it leads to complicated
                dependency relationships of each distribution. Current package
                managers only provide a local view of the dependency
                relationship. It is still a lack for distribution releasers to
                obtain a global view of the package dependency relationships. In
                this paper we present our research that target to bridge this
                gap: we propose a graph method to establish entire distribution
                package dependency relationship and analyze the complicated
                relationship graph with relevant properties. We implement our
                method on ubuntu kylin 14.04. The experiments illustrate that our
                graph approach is efficient for understanding of the whole
                distribution and could assist a high-quality maintenance and
                effective evolution.},
    keywords = {},
    doi = {10.1109/ICCSNT.2015.7490780},
    ISSN = {},
    month = {Dec},
}

@inproceedings{SciPyProceedings_11,
    author = {Aric A. Hagberg and Daniel A. Schult and Pieter J. Swart},
    title = {{Exploring Network Structure, Dynamics, and Function using NetworkX
             }},
    booktitle = {Proceedings of the 7th Python in Science Conference},
    pages = {11 - 15},
    address = {Pasadena, CA USA},
    year = {2008},
    editor = {Ga\"el Varoquaux and Travis Vaught and Jarrod Millman},
}


@article{Bonacich1972,
    author = {Bonacich, Phillip},
    title = {{Technique for Analyzing Overlapping Memberships}},
    journal = {Sociological Methodology},
    year = {1972},
    month = {2023/11/13/},
    publisher = {[American Sociological Association, Wiley, Sage Publications,
                 Inc.]},
    volume = {4},
    pages = {176-185},
    note = {Full publication date: 1972},
    doi = {10.2307/270732},
    url = {https://doi.org/10.2307/270732},
    url = {http://www.jstor.org/stable/270732},
}

@article{Freeman1978,
    author = {Freeman, Linton C.},
    title = {{Centrality in social networks conceptual clarification}},
    journal = {Social Networks},
    year = {1978},
    month = {Jan},
    day = {01},
    volume = {1},
    number = {3},
    pages = {215-239},
    abstract = {The intuitive background for measures of structural centrality
                in social networks is reviewed and existing measures are
                evaluated in terms of their consistency with intuitions and their
                interpretability. Three distinct intuitive conceptions of
                centrality are uncovered and existing measures are refined to
                embody these conceptions. Three measures are developed for each
                concept, one absolute and one relative measure of the centrality
                of positions in a network, and one reflecting the degree of
                centralization of the entire network. The implications of these
                measures for the experimental study of small groups is examined.},
    issn = {0378-8733},
    url = {https://www.sciencedirect.com/science/article/pii/0378873378900217},
}

@inbook{Morris2024,
    author = "Morris, John and Tatschner, Stefan and Heinl, Michael P. and Heinl
              , Patrizia and Newe, Thomas and Plaga, Sven",
    editor = "Naseer Qureshi, Kashif and Newe, Thomas and Jeon, Gwanggil and
              Chehri, Abdellah",
    title = "Cybersecurity as a Service",
    bookTitle = "Cybersecurity Vigilance and Security Engineering of Internet of
                 Everything",
    year = "2024",
    publisher = "Springer Nature Switzerland",
    address = "Cham",
    pages = "141--161",
    abstract = "With the increasing sophistication and sheer number of
                cyberattacks, more and more companies come to the conclusion that
                they have to strengthen their cybersecurity posture. At the same
                time, well-educated information technology (IT) security
                personnel are scarce. Cybersecurity as a service (CSaaS) is one
                possible solution to tackle this problem by outsourcing security
                functions to managed security service providers (MSSP). This
                chapter gives on overview of common CSaaS functions and their
                providers. Moreover, it provides guidance especially for small-
                and medium-sized businesses, for asking the appropriate questions
                when it comes to the selection of a specific MSSP.",
    isbn = "978-3-031-45162-1",
    doi = "10.1007/978-3-031-45162-1_9",
    url = "https://doi.org/10.1007/978-3-031-45162-1_9",
}

@software{Tatschner_gallia,
    author = {Tatschner, Stefan and Specht, Tobias and Kügler, Fabian and
              Jarisch, Ferdinand and Obermaier, Johannes and Schuster, Dieter and
              Madl, Tobias and Ehmes, Veronique},
    license = {Apache-2.0},
    title = {{gallia}},
    url = {https://github.com/Fraunhofer-AISEC/gallia},
}

@article{landau1895relativen,
    title = {{Zur relativen Wertbemessung der Turnierresultate}},
    author = {Landau, Edmund},
    journal = {Deutsches Wochenschach},
    volume = {11},
    number = {366-369},
    pages = {3},
    year = {1895},
}

@phdthesis{wei1952algebraic,
    title = {Algebraic foundations of ranking theory.},
    author = {Wei, Teh-Hsing},
    year = {1952},
    school = {University of Cambridge},
}

@article{760e07d1-fd0d-3ce0-afae-f7ab9cd57766,
    ISSN = {0006341X, 15410420},
    URL = {http://www.jstor.org/stable/3001479},
    author = {M. G. Kendall},
    journal = {Biometrics},
    number = {1},
    pages = {43--62},
    publisher = {[Wiley, International Biometric Society]},
    title = {{Further Contributions to the Theory of Paired Comparisons}},
    urldate = {2024-02-28},
    volume = {11},
    year = {1955},
}

@article{claude1966theorie,
    title = {Th{\'e}orie des graphes et ses applications},
    author = {Claude, Berge},
    journal = {French. Dunod, Paris},
    pages = {15},
    year = {1966},
}

@article{35397813-90c1-3806-8d5d-a07b3340ac3d,
    ISSN = {00811750, 14679531},
    URL = {http://www.jstor.org/stable/270732},
    author = {Phillip Bonacich},
    journal = {Sociological Methodology},
    pages = {176--185},
    publisher = {[American Sociological Association, Wiley, Sage Publications,
                 Inc.]},
    title = {{Technique for Analyzing Overlapping Memberships}},
    urldate = {2024-02-28},
    volume = {4},
    year = {1972},
}

@misc{rfc4949,
    series = {Request for Comments},
    number = 4949,
    howpublished = {RFC 4949},
    publisher = {RFC Editor},
    doi = {10.17487/RFC4949},
    url = {https://www.rfc-editor.org/info/rfc4949},
    author = {Robert W. Shirey},
    title = {{Internet Security Glossary, Version 2}},
    pagetotal = 365,
    year = 2007,
    month = aug,
    abstract = {This Glossary provides definitions, abbreviations, and
                explanations of terminology for information system security. The
                334 pages of entries offer recommendations to improve the
                comprehensibility of written material that is generated in the
                Internet Standards Process (RFC 2026). The recommendations follow
                the principles that such writing should (a) use the same term or
                definition whenever the same concept is mentioned; (b) use terms
                in their plainest, dictionary sense; (c) use terms that are
                already well-established in open publications; and (d) avoid
                terms that either favor a particular vendor or favor a particular
                technology or mechanism over other, competing techniques that
                already exist or could be developed. This memo provides
                information for the Internet community.},
}

@article{Katz1953,
    author = {Katz, Leo},
    title = {{A new status index derived from sociometric analysis}},
    journal = {Psychometrika},
    year = {1953},
    month = {Mar},
    day = {01},
    volume = {18},
    number = {1},
    pages = {39-43},
    abstract = {For the purpose of evaluating status in a manner free from the
                deficiencies of popularity contest procedures, this paper
                presents a new method of computation which takes into accountwho
                chooses as well ashow many choose. It is necessary to introduce,
                in this connection, the concept of attenuation in influence
                transmitted through intermediaries.},
    issn = {1860-0980},
    doi = {10.1007/BF02289026},
    url = {https://doi.org/10.1007/BF02289026},
}

@inproceedings{log4j,
    author = {Everson, Douglas and Cheng, Long and Zhang, Zhenkai},
    booktitle = {Proc. Workshop Meas., Attacks, Defenses Web (MADWeb)},
    year = {2022},
    month = {01},
    pages = {},
    title = {{Log4shell: Redefining the Web Attack Surface}},
    doi = {10.14722/madweb.2022.23010},
}

@misc{rfc8446,
    series = {Request for Comments},
    number = 8446,
    howpublished = {RFC 8446},
    publisher = {RFC Editor},
    doi = {10.17487/RFC8446},
    url = {https://www.rfc-editor.org/info/rfc8446},
    author = {Eric Rescorla},
    title = {{The Transport Layer Security (TLS) Protocol Version 1.3}},
    pagetotal = 160,
    year = 2018,
    month = aug,
    abstract = {This document specifies version 1.3 of the Transport Layer
                Security (TLS) protocol. TLS allows client/server applications to
                communicate over the Internet in a way that is designed to
                prevent eavesdropping, tampering, and message forgery. This
                document updates RFCs 5705 and 6066, and obsoletes RFCs 5077,
                5246, and 6961. This document also specifies new requirements for
                TLS 1.2 implementations.},
}

@techreport{ISO5230,
    address = {Geneva, CH},
    type = {Standard},
    title = {{OpenChain Specification}},
    shorttitle = {{ISO/IEC 5230:2020}},
    url = {https://www.iso.org/standard/81039.html},
    language = {en},
    address = {Geneva, CH},
    number = {ISO/IEC 5230:2020},
    institution = {International Organization for Standardization},
    author = {{ISO Central Secretary}},
    year = {2020},
}

@techreport{ISO18974,
    address = {Geneva, CH},
    type = {Standard},
    title = {{OpenChain security assurance specification}},
    shorttitle = {{ISO/IEC 18974:2023}},
    url = {https://www.iso.org/standard/86450.html},
    language = {en},
    address = {Geneva, CH},
    number = {ISO/IEC 18974:2023},
    institution = {International Organization for Standardization},
    author = {{ISO Central Secretary}},
    year = {2023},
}

@techreport{ISO5962,
    address = {Geneva, CH},
    type = {Standard},
    title = {{SPDX® Specification V2.2.1}},
    shorttitle = {{ISO/IEC 5962:2021}},
    url = {https://www.iso.org/standard/81870.html},
    language = {en},
    address = {Geneva, CH},
    number = {ISO/IEC 5962:2021},
    institution = {International Organization for Standardization},
    author = {{ISO Central Secretary}},
    year = {2021},
}

@techreport{iso27005,
    address = {Geneva, CH},
    type = {Standard},
    title = {{Information security, cybersecurity and privacy protection -
             Guidance on managing information security risks}},
    shorttitle = {{ISO/IEC 27005:2022}},
    url = {https://www.iso.org/standard/80585.html},
    language = {en},
    number = {ISO/IEC 27005:2022},
    institution = {International Organization for Standardization},
    author = {{ISO Central Secretary}},
    year = {2022},
}

@inproceedings{pfeiffer,
    author = {Pfeiffer, Rolf-Helge},
    booktitle = {2021 IEEE/ACM 18th International Conference on Mining Software
                 Repositories (MSR)},
    title = {{Identifying Critical Projects via PageRank and Truck Factor}},
    year = {2021},
    volume = {},
    number = {},
    pages = {41-45},
    abstract = {Recently, Google's Open Source team presented the criticality
                score a metric to assess "influence and importance" of a project
                in an ecosystem from project specific signals, e.g., number of
                dependents, commit frequency, etc. The community showed mixed
                reactions towards the score doubting if it can accurately
                identify critical projects. We share the community's doubts and
                we hypothesize, that a combination of PageRank (PR) and Truck
                Factor (TF) can more accurately identify critical projects than
                Google's current Criticality Score (CS). To verify our hypothesis
                , we conduct an experiment in which we compute the PR of
                thousands of projects from various ecosystems, such as, Maven
                (Java), NPM (JavaScript), PyPI (Python), etc., we compute the TFs
                of the projects with the highest PR in the respective ecosystems,
                and we compare these to the scores provided by the Google
                project. Unlike Google's CS, our approach identifies projects,
                such as, six and idna from PyPI, com.typesafe:config from Maven,
                or tap from NPM, as critical projects with high degree of
                transitive dependents (highest PR) and low amount of core
                developers (each of them possessing a TF of one).},
    keywords = {Measurement;Java;Ecosystems;Software;Internet;Data
                mining;Software development management},
    doi = {10.1109/MSR52588.2021.00017},
    ISSN = {2574-3864},
    month = {May},
}


@techreport{pike2020,
    address = {Github},
    type = {Technical Article},
    title = {{Quantifying Criticality}},
    url = {
           https://github.com/ossf/criticality_score/blob/a41e3aa7971a6d1150b22c2c40d7b6ac8df63629/Quantifying_criticality_algorithm.pdf
           },
    language = {en},
    author = {{Rob Pike}},
    year = {2020},
}



@inproceedings{10.1145/3597503.3639582,
    author = {Wu, Susheng and Song, Wenyan and Huang, Kaifeng and Chen, Bihuan
              and Peng, Xin},
    title = {Identifying Affected Libraries and Their Ecosystems for Open Source
             Software Vulnerabilities},
    year = {2024},
    isbn = {9798400702174},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3597503.3639582},
    doi = {10.1145/3597503.3639582},
    abstract = {Software composition analysis (SCA) tools have been widely
                adopted to identify vulnerable libraries used in software
                applications. Such SCA tools depend on a vulnerability database
                to know affected libraries of each vulnerability. However, it is
                labor-intensive and error prone for a security team to manually
                maintain the vulnerability database. While several approaches
                adopt extreme multi-label learning to predict affected libraries
                for vulnerabilities, they are practically ineffective due to the
                limited library labels and the unawareness of ecosystems.To
                address these problems, we first conduct an empirical study to
                assess the quality of two fields, i.e., affected libraries and
                their ecosystems, for four vulnerability databases. Our study
                reveals notable inconsistency and inaccuracy in these two fields.
                Then, we propose Holmes to identify affected libraries and their
                ecosystems for vulnerabilities via a learning-to-rank technique.
                The key idea of Holmes is to gather various evidences about
                affected libraries and their ecosystems from multiple sources,
                and learn to rank a pool of libraries based on their relevance to
                evidences. Our extensive experiments have shown the effectiveness
                , efficiency and usefulness of Holmes.},
    booktitle = {Proceedings of the IEEE/ACM 46th International Conference on
                 Software Engineering},
    articleno = {162},
    numpages = {12},
    keywords = {open source software, vulnerability quality, affected libraries},
    location = {Lisbon, Portugal},
    series = {ICSE '24},
}

@inproceedings{236368,
    author = {Markus Zimmermann and Cristian-Alexandru Staicu and Cam Tenny and
              Michael Pradel},
    title = {Small World with High Risks: A Study of Security Threats in the npm
             Ecosystem},
    booktitle = {28th USENIX Security Symposium (USENIX Security 19)},
    year = {2019},
    isbn = {978-1-939133-06-9},
    address = {Santa Clara, CA},
    pages = {995--1010},
    url = {
           https://www.usenix.org/conference/usenixsecurity19/presentation/zimmerman
           },
    publisher = {USENIX Association},
    month = aug,
}

@inproceedings{10.1145/3551349.3559517,
    author = {Synovic, Nicholas M. and Hyatt, Matt and Sethi, Rohan and Thota,
              Sohini and Shilpika and Miller, Allan J. and Jiang, Wenxin and
              Amobi, Emmanuel S. and Pinderski, Austin and L\"{a}ufer, Konstantin
              and Hayward, Nicholas J. and Klingensmith, Neil and Davis, James C.
              and Thiruvathukal, George K.},
    title = {Snapshot Metrics Are Not Enough: Analyzing Software Repositories
             with Longitudinal Metrics},
    year = {2023},
    isbn = {9781450394758},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3551349.3559517},
    doi = {10.1145/3551349.3559517},
    abstract = {Software metrics capture information about software development
                processes and products. These metrics support decision-making,
                e.g., in team management or dependency selection. However,
                existing metrics tools measure only a snapshot of a software
                project. Little attention has been given to enabling engineers to
                reason about metric trends over time—longitudinal metrics that
                give insight about process, not just product. In this work, we
                present PRIME (PRocess MEtrics), a tool to compute and visualize
                process metrics. The currently-supported metrics include
                productivity, issue density, issue spoilage, and bus factor. We
                illustrate the value of longitudinal data and conclude with a
                research agenda. The tool’s demo video can be watched at
                https://bit.ly/ase2022-prime. Source code can be found at
                https://github.com/SoftwareSystemsLaboratory/prime.},
    booktitle = {Proceedings of the 37th IEEE/ACM International Conference on
                 Automated Software Engineering},
    articleno = {167},
    numpages = {4},
    keywords = {Software metrics, Empirical software engineering},
    location = {Rochester, MI, USA},
    series = {ASE '22},
}

@dataset{tatschner_2024_11276931,
    author = {Tatschner, Stefan},
    title = {{Tracking Down Software Cluster Bombs: A Health State Analysis of
             the Free/Libre Open-source Software (FLOSS) Ecosystem}},
    month = may,
    year = 2024,
    publisher = {Zenodo},
    doi = {10.5281/zenodo.11276931},
    url = {https://doi.org/10.5281/zenodo.11276931},
}

@conference{Alhamdan:Staicu:2025,
    title = {{Welcome to Jurassic Park: A Comprehensive Study of Security Risks
             in Deno and its Ecosystem}},
    author = {Alhamdan, Abdullah and Staicu, Cristian-Alexandru},
    year = 2025,
    month = 2,
    doi = {10.14722/ndss.2025.23284},
}
