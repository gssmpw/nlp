% !TeX root = ../main.tex
%\newpage

\section{Collection Strategy and Result}\label{Section2}

% To systematically review Operating System Fuzzing (OSF) and its related research, \cite{garousi2016systematic} suggest that both a search strategy and result analysis are necessary to assess the quality of the literature and research trends. In this section, we design a search strategy that involves determining how to find relevant literature, assess its quality, and keep updated with the latest publications. In results analysis, we conduct an assessment of the research trends in OSF over the past decade and examine the shifts in research specifics in recent years.

Following \cite{garousi2016systematic}, we use a scientific and effective collection strategy (see Section~\ref{Collection Methodology}) and present~a detailed analysis of the collection result (see Section~\ref{Results Analysis}) to systematically review OSF. 

% We introduce our collection methodology in \S \ref{Collection Methodology} and present the statistics and analysis of the collection results in \S \ref{Results Analysis}.



\subsection{Collection Strategy}\label{Collection Methodology}

Figure~\ref{img:collection_methodology} shows our strategy to collect relevant works, assess their quality, and keep updated with~the latest publications. We both review scientific literature and collect open-source tools for OSF. 

\subsubsection{Scientific Literature Review}

% To conduct a comprehensive review of OSF, we established a repository specifically for the accumulation and categorization of relevant literature. This initiative is aimed at facilitating a systematic review of publications within the OSF field. In addition, a closed-loop search strategy for literature search was designed and executed, ensuring a methodical approach in the assessment of relevant works. The temporal scope of our survey was set to encompass a decade, ranging from January 2013 through December 2024 (i.e. at least 10 years), thereby capturing the most recent and pertinent contributions to the OSF. The principal steps are outlined below:

%We establish a repository of scientific literature for comprehensive review of operating system fuzzing, ensuring a methodical approach in the assessment of relevant publications. We set the temporal scope of our survey to encompass a decade, ranging from January 2013 to December 2024 (i.e. at least 10 years). The detailed steps are as follows:

%We establish a repository of scientific literature for comprehensive review of operating system fuzzing, ensuring a methodical approach in the assessment of relevant publications. 
We set the temporal scope of our survey to cover the period~from the earliest relevant papers or tools in this field to the present, ranging from January 2015~to~August 2024 (\ie around 10 years). The detailed steps are as follows.

% \begin{figure}[!t]
%   \centering
%   \includegraphics[width=0.85\linewidth]{img/Statistic1.png}
%   \caption{Step 1 depicts the count of \textbf{selected papers}. Step 2 demonstrates the refinement and expansion of the paper count through \textbf{filtering and snowballing}. Step 3 adds \textbf{open-source tools} during the paper review.}
%   \label{statistic1}
% \end{figure}

\begin{figure}[!t]
  \includegraphics[width=0.9\linewidth]{img/methodology.pdf}
  % \vspace{-5pt}
  \caption{Our Collection Strategy}
  \label{img:collection_methodology}
\end{figure}

\textbf{Database Search.} 
% Prior to embarking on a literature survey, it is customary to use "OS Fuzzing" as the keyword to select appropriate papers. However, employing "OS Fuzzing" as the sole keyword failed to fully capture all existing literature on open-source OSF. As outlined in the "Introduction" section, it became evident that the keywords should encompass the primary test subjects within open-source operating systems, including: "Kernel/File system/Driver/Hypervisor Fuzzing," "OS Fuzzing," "Fuzzing Survey," and "open-source/Linux/Android/FreeBSD/OpenBSD Fuzzing." Therefore, all keywords were indexed in the well-known computer science databases such as ACM Digital Library, IEEE Xplore, DBLP, and Semantic Scholar. Fig.\ref{statistic1} illustrates the variation in the number of papers across the three stages of the search strategy execution. As shown in Fig.\ref{statistic1}, the final tally from step 1 revealed a total of 46 papers, indicating a sufficient corpus to support this survey effort. It is noteworthy that this stage only provided a preliminary confirmation. Consequently, there may still exist some issues, such as: 1) Some papers may not actually fall within the scope of the survey, leading to issues of paper irrelevance; and 2) there exists a relationship of inclusion and overlap among keywords, resulting in redundancy in the retrieved literature, where multiple keywords may point to the same paper, thereby causing issues with the completeness of the literature search.
This step aims to find the potential relevant papers by searching electronic databases. Specifically, we select ACM Digital Library, IEEE~Xplore, DBLP and Semantic Scholar~as our databases, which are popular bibliography databases containing a comprehensive list of research venues in computer science. 
Initially, employing ``Operating System Fuzzing'' as the sole keyword fails to fully capture the existing literature about OSF. Keywords need to focus on the application~of fuzzing to operating systems (\eg Linux, Android, FreeBSD, \etc).  In addition, keywords should cover the main tested objects in open-source operating systems, such as kernel, file system, driver, \etc We optimize the search keywords in an iterative manner for the purpose of collecting as many related papers as possible. Our final search keywords are reported as follows. Moreover, our search targets titles, abstracts, and keywords of the papers, since these parts often convey the theme of a paper. Finally, we obtain a total of \todo{56} candidate papers during \emph{database search}. 

\begin{tcolorbox}[size=fbox, opacityfill=0.15]
\small
  (``Linux'' OR ``Android'' OR ``FreeBSD'' OR ``OpenBSD'' OR ``Zephyr'' OR ``Open-source Operating System'')\\
 AND  (``Kernel'' OR ``File system'' OR ``Driver'' OR ``Hypervisor'')  AND  (``Fuzzing'' OR ``OSF'')
\end{tcolorbox}

% Note that, some papers may not actually fall within the scope of the survey, leading to issues of paper irrelevance. In addition, keyword coverage may still be insufficient, resulting in the omission of some related work. Next steps are needed to assess the quality of these papers and update the literature repository.

\textbf{Paper Filtering.} 
% To ensure the relevance and completeness of the literature, it is necessary to more precisely filter papers from the repository that fall within the scope of OSF and to continually collect the cited papers as exhaustively as possible. Therefore, the step 2 is divided into filtering and snowballing: 1) Filtering. One is that the venue of the paper originates from \textbf{top conferences or journals} in the computer science field to ensure the literature's high quality, such as USENIX Security Symposium (USEC), the ACM Conference on Computer and Communications Security (CCS), ISOC Network and Distributed System Security Symposium (NDSS), the IEEE Symposium on Security and Privacy (S\&P), \etc 
We perform a manual assessment on the \todo{56} candidate papers obtained from~our \emph{database search} to ensure their relevance and quality. Specifically, to determine whether each~candidate paper is relevant to OSF and has high quality, we analyze the abstracts and introductions of these papers, following the inclusion and exclusion criteria formulated as follows.

\begin{itemize}[leftmargin=*]
  %\setlength{\itemindent}{-6.5mm}
  \item \textbf{Inclusion Criteria}. \textbf{IC1}: papers that introduce the process of OSF; and \textbf{IC2}: papers that propose a technique of OSF.
  \item \textbf{Exclusion Criteria}. \textbf{EC1}: survey papers or summary papers; \textbf{EC2}: papers that do not target fuzzing; \textbf{EC3}: papers that do not focus on fuzzing operating system and its components; and~\textbf{EC4}: papers that have not been published in top-tier conferences or journals.
\end{itemize}

Specifically, for \textbf{EC1}, such survey papers are discussed in Section~\ref{Section3-1} for a comparison with~our survey; % for \textbf{EC3}, papers that do not target testing open-source operating system or its kernel, file system, driver and hypervisor are excluded; 
and for \textbf{EC4}, we discuss these top-tier conferences and journals in Section~\ref{Results Analysis}. Through our manual assessment, we remove \todo{13} papers, resulting in \todo{43} papers.

\textbf{Backward \& Forward Snowballing.} To reduce the risk of missing relevant papers, we perform both backward and forward snowballing \cite{wohlin2014guidelines} on the \todo{43} papers. In backward snowballing,~we~check the references in these papers to obtain candidate papers, while in forward snowballing, we use Google Scholar to locate candidate papers that cite these papers. For these candidate papers obtained by snowballing, we also apply the same inclusion and exclusion criteria to identify relevant papers. Finally, we add \todo{15} new relevant papers, resulting in a final set of \todo{58} papers.

\textbf{Full-Text Analysis.} We download all the resulting \todo{58} papers, and conduct a full-text analysis~to
%We further analysis the Introduction, Conclusion and other parts of the papers to determine whether a center paper is relevant with OSF. Specifically, we need to 
 identify the fuzzing target (\ie the operating system and its components) and the proposed fuzzing technique. After reading all these papers, we classify them to form our survey (see Section~\ref{Section4} and \ref{Section5}). 


\subsubsection{Open-Source Tools Collection} Some open-source tools of OSF have not been published~in~academic papers, and these tools should not be ignored. Therefore, we use the same search keywords to collect open-source tools whose stars are more than 400 stars on GitHub. We eliminate tools that have been published in academic papers, and select \todo{4} additional open-source tools.

% Through the above steps, it is confident that the collection methodology devised in this paper maximally covers OSF papers and open-source tools, with the next subsection presenting statistical results.

\begin{figure*}[!t]
  \centering
  \subfigure[Distribution across Publication Venues]{
    \includegraphics[width=0.42\linewidth]{fig/publication_venues.pdf}\label{fig:publication_venues}}
  \hspace{20pt}
  \subfigure[Distribution Across Publication Years and Layers]{
      \includegraphics[width=0.428\textwidth]{fig/publication_years.pdf}\label{fig:publication_years}}
  \caption{The Analysis Results of Paper Collection}
\end{figure*}


\subsection{Collection Result Analysis}\label{Results Analysis}

We analyze the collected papers from three perspectives, \ie the publication venues, the publication years, and the target OS layers. 

\textbf{Publication Venues.} Figure~\ref{fig:publication_venues} shows the distribution of all the papers across the publication venues. The \todo{58} papers are published across 17 top-tier venues in four domains, \ie security,~software engineering, computer architecture, and computer storage systems. Specifically, (\romannumeral1)~most~of~the papers, up to \todo{79\%}, are published in security venues such as \emph{USENIX Security Symposium}, \emph{ACM~Conference on Computer and Communications Security (CCS)}, \emph{IEEE Symposium on Security and Privacy (S\&P)}, and \emph{Network and Distributed System Security Symposium (NDSS)}; (\romannumeral2)~\todo{12\%} of the papers are published in software engineering venues such as \emph{ACM Symposium on Operating Systems Principles (SOSP)}, \emph{International Symposium on Software Testing and Analysis (ISSTA)}, and \emph{International Conference on Software Engineering (ICSE)}; (\romannumeral3)~there are \todo{4} papers, accounting for \todo{7\%}, published in computer architecture venues, one each in \emph{European Conference on Computer Systems (EuroSys)}, \emph{USENIX Annual Technical Conference (ATC)}, \emph{ACM Transactions on Embedded Computing Systems (TECS)}, and \emph{IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)}; and (\romannumeral4)~since operating system is related to storage system, there is \todo{1} paper published in computer storage system venues (\ie \emph{ACM Transactions on Storage (TOS)}). It can be conclude that~the~application of fuzzing techniques to operating systems spans multiple fields of computer science.

%{fig:publication_years}, we can see that the number of the papers related to operating system fuzzing shows a general ascending trend, from 2013 to 2023. It is evident that interest in OSF has been escalating year by year, which indicates heightened attention in leveraging fuzzing to uncover deeper security vulnerabilities on open-source operating system. In addition, we can also get from the figure that most of these papers focus on the fuzzing of kernel. Particularly, the AFL \cite{AFL} fuzzing framework, launched in 2013, caused a significant stir in kernel testing. The Syzkaller \cite{Syzkaller} fuzzing framework proposed by Google offers researchers a fundamental kernel fuzzing engine. Consequently, researches focused on kernel fuzzing has sprung up since the kernel boundary is broader and related to other layers. Furthermore, the advent of large language models (LLM) has enhanced software testing due to their advanced natural language processing capabilities \cite{yang2023kernelgpt}. Since 2023, notable contributions in the domain of ``LLM for Kernel Fuzzing'' have emerged. However, using kernel fuzzing interfaces (\ie between user and kernel space) fails to uncover deep bugs in other operating system layers (\eg verification chain checks in driver). Thus, an increasing number of researchers realized the necessity of testing other operating system layers such as the file system, drivers, and hypervisors. 


\textbf{Publication Years and Target OS Layers.}  Figure~\ref{fig:publication_years} presents the number of papers published in each year as well as the distribution across the target OS layers in each year. Overall, the~number of OSF papers shows a general ascending trend from 2015 to 2024. It is evident that interest~in~OSF has been escalating year by year, which indicates increased attention in leveraging fuzzing~to~uncover deeper security vulnerabilities in open-source OS. Notice that since the papers from 2024 have not been fully surveyed yet, Figure~\ref{fig:publication_years} only shows the number of OSF publications till~August~2024. Moreover, most papers focus on the fuzzing of kernel. Particularly, Googleâ€™s fuzzing framework Syzkaller~\cite{Syzkaller} launched in 2015. It provides researchers with a foundational kernel fuzzing engine, and has made a substantial impact on kernel fuzzing. However, using kernel fuzzing interfaces~(\ie between user and kernel space) fails to uncover deep security vulnerabilities in other OS layers (\eg verification chain checks in driver). Therefore, an increasing number of papers realized the necessity of fuzzing other OS layers (\ie file systems, drivers, and hypervisors) since 2020.

%Particularly, the AFL \cite{AFL} fuzzing framework, launched in 2013, caused a significant stir in kernel testing. The Syzkaller \cite{Syzkaller} fuzzing framework proposed by Google offers researchers a fundamental kernel fuzzing engine.

%Consequently, researches focused on kernel fuzzing has sprung up since the kernel boundary is broader and related to other layers. Furthermore, the advent of large language models (LLM) has enhanced software testing due to their advanced natural language processing capabilities \cite{yang2023kernelgpt}. Since 2023, notable contributions in the domain of ``LLM for Kernel Fuzzing'' have emerged.

%\newpage