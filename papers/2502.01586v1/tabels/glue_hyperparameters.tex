\begin{table*}[h]
    \caption{\small Hyperparameters of fine-tuning RoBERTa-Base on GLUE tasks.}
    \centering
    \label{tab:ft_hyperparameters}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{l|c|cccccccc}
    \midrule
    \midrule
    & & MNLI   & SST-2 & MRPC    & CoLA    & QNLI    & QQP     & RTE     & STS-B   \\
    \midrule
    \midrule
    % \midrule
    Shared Parameters & Batch Size    & 16     & 16    & 16      & 32      & 16      & 16      & 16      & 16      \\
    & Learning Rate & 1E-05  & 1E-05     & 3E-05   & 3E-05   & 1E-05   & 1E-05   & 1E-05   & 1E-05   \\
    & \# Epochs   &  \multicolumn{8}{c}{30} \\
    & Max Seq. Len. &  \multicolumn{8}{c}{512} \\

    \midrule
    SubTrack-Grad & SubTrack-Grad Step-Size &0.1 &0.001 &5.0 &5.0 &0.01 &1.0 &8.0 &10.0   \\
    \& GaLore, r = 4 & Subspace Update Interval &  \multicolumn{8}{c}{500} \\
    Parameters & \(\alpha\) &  \multicolumn{8}{c}{4} \\
    \midrule
    SubTrack-Grad & SubTrack-Grad Step-Size &0.1 &0.1 &5.0 &13.0 &0.1 &1.0 &5.0 &10.0   \\
    \& GaLore, r = 8 & Subspace Update Interval &  \multicolumn{8}{c}{500} \\
    Parameters & \(\alpha\) &  \multicolumn{8}{c}{2} \\
    \midrule
    BAdam Parameters & Block Switch Interval &  \multicolumn{8}{c}{100} \\
    & Switch Mode &  \multicolumn{8}{c}{Random} \\
    \bottomrule
    \end{tabular}
    }
\end{table*}
