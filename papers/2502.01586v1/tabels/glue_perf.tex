\begin{table*}[t]
\caption{\small Evaluating the performance of SubTrack-Grad and other baselines when fine-tuning RoBERTa-Base on GLUE tasks for different ranks $r$. All hyperparameters are the same for each rank. The performance is measured via Accuracy for QNLI, MNLI, SST-2, and RTE tasks, F1 for QQP and MRPC, Pearson Correlation for STS-B, and Matthews Correlation for COLA, after fine-tuning for 30 epochs.}
\label{tab:glue}
\begin{center}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|cccccccc|c}
\toprule
 & \bf COLA & \bf STS-B & \bf MRPC & \bf RTE & \bf SST-2 & \bf MNLI & \bf QNLI & \bf QQP & \bf Avg \\ 
\midrule
\midrule
{\bf Full-Rank}
                    &62.57      &91.03      &91.32     &77.98
                    &94.27      &87.83      &92.71     &89.21      &85.86 \\
\midrule
% \multicolumn{10}{c}{\textbf{Rank = 4}} \\
\midrule
{\bf BAdam} \citep{luo2024badammemoryefficientparameter}
                    &54.44      &89.01      &91.35     &68.59
                    &94.15      &87.31      &92.49     &87.50      &83.10 \\
\midrule
\midrule
{\bf GaLore, r=4} \citep{zhao2024galorememoryefficientllmtraining}
                    &60.34      &90.58      &92.58      &76.53
                    &94.27      &87.12      &92.20      &87.86      &\bf 85.18 \\
\midrule
{\bf SubTrack-Grad, r=4} (Ours)
                    &61.07      &90.63      &92.83      &76.89  
                    &93.81      &87.20      &91.73      &86.73     &85.11 \\
\midrule
\midrule
{\bf GaLore, r=8} \citep{zhao2024galorememoryefficientllmtraining}
                    &58.54      &90.61      &91.30      &74.37
                    &94.50      &87.34      &92.71      &87.99      &84.67  \\

\midrule
{\bf SubTrack(Last)-Grad, r=8} (Ours)
                    &58.03      &90.76      &91.81      &77.62  
                    &94.38      &87.15      &92.31      &87.26     &\bf84.91 \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table*}
