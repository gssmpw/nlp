\begin{table*}[t]
\caption{\small Evaluating the performance of SubTrack-Grad and other baselines when fine-tuning RoBERTa-Large on SuperGLUE tasks with rank 8. All hyperparameters are consistent across different methods. The performance is measured via Accuracy for COPA, WIC, WSC, BoolQ, and AX$_g$ tasks, F1 for CB, and Matthews Correlation for AX$_b$, after fine-tuning for 30 epochs.}
\label{tab:superglue}
\begin{center}
\resizebox{\textwidth}{!}{%
% \rowcolors{1}{blue}{blue}
\begin{tabular}{l|cccccc|c}
\toprule
 & \bf BoolQ & \bf CB & \bf COPA & \bf WIC & \bf WSC & \bf AX$_g$ & \bf Avg \\ 
\midrule
\midrule
{\bf Full-Rank}   
                    &85.96      &90.33      &76.00      
                    &71.79      &63.46      &96.30      &80.64 \\
\midrule
\midrule
{\bf GaLore} \citep{zhao2024galorememoryefficientllmtraining}
                    &85.44      &88.85      &80.00      
                    &71.47      &63.46      &100.00     &81.54 \\
\midrule
{\bf BAdam} \citep{luo2024badammemoryefficientparameter}
                    &82.51      &53.28      &59.00      
                    &70.38      &60.58      &51.85      &62.93 \\
\midrule
{\bf SubTrack-Grad} (Ours)
                    &85.66      &88.85      &81.00       
                    &72.73      &63.46      &100.00     &81.95 \\
\bottomrule
\end{tabular}
}
\end{center}
\end{table*}
