\begin{table*}[h]
\caption{\small Peak memory consumption comparison when pre-training Llama-based architectures with different sizes on C4 dataset. The last two columns present the average percentage change in memory consumption relative to Full-Rank and GaLore, respectively.}
\label{tab:lama-mem}
\begin{center}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l|ccccc|c|c|c}
\toprule
 & \bf 60M & \bf 130M & \bf 350M & \bf 1B & \bf 3B  & \bf {\small Avg}& \bf {\small w.r.t FR} & \bf {\small w.r.t GaLore} \\
  & r=128 & r=256 & r=256 & r=512 & r=512  & &  &   \\
\midrule
\midrule
{\bf Full-Rank}   
                    &16.86 &25.32 &28.67 &18.83 &34.92 &24.92    & - & - \\  
\midrule
\midrule
{\bf BAdam}
                    &13.34 &20.01 &21.11 &9.70 &15.25 &15.88    &-36.28\%  & - \\   
\midrule
{\bf GaLore}
                    &16.89 &25.51 &27.85 &15.24 &26.03 &22.30    &-10.51\% & - \\  
\midrule
{\bf SubTrack-Grad}
                    &16.89 &25.52 &27.85 &15.24 &26.16 &22.33    &-10.39\% &+0.13\% \\ 
\bottomrule
\end{tabular}
}
\end{center}
\end{table*}
