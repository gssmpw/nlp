\input{images/subtrac_grad}

\section{Introduction}
Large Language Models (LLMs) have demonstrated state-of-the-art performance across a wide range of tasks and are rapidly growing in popularity. However, training and fine-tuning these models require significant resources, including extensive hardware and time, which limits their practicality for many applications and increases their environmental impact due to a larger carbon footprint. \citep{zhao2024galorememoryefficientllmtraining, jaiswal2024galorewelorelowrankweights, muhamed2024grasscomputeefficientlowmemory, miles2024veloramemoryefficienttraining, modoranu2024microadamaccurateadaptiveoptimization, hao2024floralowrankadapterssecretly, li2024owloreoutlierweighedlayerwisesampled}. 
Consequently, there is a pressing need to develop time- and memory-efficient methods to make LLMs more accessible and reduce their environmental impact, while preseving performance. 

Several techniques have been proposed to address memory challenges, including gradient checkpointing \citep{chen2016trainingdeepnetssublinear} and memory offloading \citep{rajbhandari2020zeromemoryoptimizationstraining}. In this context, several approaches aim to reduce memory usage by optimizing a subset of model parameters or operating within a lower-dimensional space \citep{dettmers2024qlora, yaras2024compressible, lialin2023relorahighranktraininglowrank, renduchintala-etal-2024-tied, xia2024chainloraefficientfinetuning, miles2024veloramemoryefficienttraining, hu2021lora}. Notably, the well-known method LoRA \citep{hu2021lora}, addresses memory efficiency by decomposing weight matrices into two low-rank trainable matrices, enabling the optimization of network parameters within a smaller subspace and significantly reducing memory usage. However, LoRA's effectiveness relies on the assumption that parameters reside in a low-dimensional space, which does not always hold true. On the other hand, recent methods including BAdam \citep{luo2024badammemoryefficientparameter} and the one introduced by \citet{ramesh2024blockllmmemoryefficientadaptationllms} leverage the block coordinate descent (BCD) framework and partition the model into different blocks to optimize one block at a time. These methods can effectively reduce memory footprint while avoiding extra computation; however, while these achieve better memory and time efficiency, they suffer from performance degradation due to partial parameter tuning. 

Memory requirements extend beyond trainable parameters, with a significant portion consumed by optimizers for storing element-wise states \citep{zhao2024galorememoryefficientllmtraining}. To address this, recent efforts have focused on reducing the optimizer parameters while still targeting full parameter training \citep{li2023memoryefficientoptimizers4bit, anil2019memoryefficientadaptiveoptimization, lv-etal-2024-full, dettmers20228bitoptimizersblockwisequantization, zhang2024adamminiusefewerlearning, modoranu2024microadamaccurateadaptiveoptimization, zhao2024galorememoryefficientllmtraining, muhamed2024grasscomputeefficientlowmemory}.
Prominantly, GaLore \citep{zhao2024galorememoryefficientllmtraining} reduces the memory consumption of optimizers by projecting gradient matrices into a low-rank subspace and tracking changes through periodic singular value decomposition (SVD) to obtain a rank-\(r\) approximation. Unlike weight parameters, there are many works showing that gradients evolve in a low-dimensional space during gradient descent \citep{gurari2018gradientdescenthappenstiny, schneider2024identifyingpolicygradientsubspaces, yaras2023invariant}; using this fact, GaLore decreases optimizer memory footprint while enabling full and simultaneous parameter updates. 
However, their approach faces several challenges. First, SVD is computationally expensive, and if the gradient does not evolve within a nearly constant subspace, GaLore must increase the frequency of SVD operations, significantly increasing the amount of computation. This is problematic because not all layersâ€™ gradients converge to a stable subspace early in training \citep{jaiswal2024galorewelorelowrankweights}. Moreover, applying SVD to a single gradient matrix is susceptible to data noise \citep{Vaswani_2018}, and GaLore does not leverage 1) information from the orthogonal space as feedback to adjust the subspace \citep{modoranu2024microadamaccurateadaptiveoptimization} or 2) previously computed subspaces to incorporate past knowledge, which could help mitigate noise effects and improve convergence. 

To this end, we propose Gradient Subspace Tracking (SubTrack-Grad), a Grassmannian-based, time- and memory-efficient method that adjusts the subspace using rank-\(1\) updates for full parameter fine-tuning. SubTrack-Grad leverages information from the orthogonal complement of the subspace to enhance subspace estimation through simple linear operations, making it more computationally efficient than GaLore by avoiding periodic SVD on gradient matrices while maintaining the same memory efficiency. Furthermore, its ability to perform simultaneous weight updates provides significant performance improvements over BAdam. Finally, SubTrack-Grad dynamically adapts to the gradient subspace changes, reducing abrupt shifts for faster convergence, in some cases achieving better performance than full-rank finetuning! An overview of SubTrack-Grad is provided in Figure \ref{fig:method}, and our main contributions are as follows:
\begin{itemize}
    \item We introduce SubTrack-Grad, a memory- and time-efficient full-parameter training that maintains performance by tracking the gradient subspace using Grassmannian geometry.
    \item We show that SubTrack-Grad outperforms BAdam, and delivers performance on par with, or superior to GaLore, while significantly reducing runtime with maintaining GaLore's memory gains. 
    \item We show that tracking the gradient subspace helps reduce abrupt changes in the optimization process, thereby accelerating convergence.
    \item We prove that our method aligns with GaLore's convergence guarantees while enabling more frequent subspace updates by exercising greater control over subspace adjustments through the use of prior knowledge and estimation errors.
\end{itemize}


