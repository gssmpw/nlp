\begin{algorithm}[t]
\caption{SubTrack-Grad}
\label{alg:SubTrack}
\begin{algorithmic}
\small
\REQUIRE Sequence of $m \times n$ gradients $G_t$ with $m \leq n$ (w.l.o.g.), step-size $\eta$, rank $r$, subspace update steps k
\STATE {\bf Initialize Subspace via SVD Decomposition:} \\
    $P_0 \gets U[:, :r]$ , where $U, S, V \gets \text{SVD}(G_0)$ \\
    $S_0 \gets P_0$ 
\FOR{$t = 1, \ldots, T$}
    \IF{$t \mod k = 0$}
        \STATE {\bf Update subspace:} \\ 
        $G_{lr} = \arg \min_A \| (S_{t-1} A - G_t) \|^2$  \\ 
        $R = G_t - S_{t-1}G_{lr}$ \\
        $\nabla F = -2RG_{lr}^\top \approx \widehat{U}_F\widehat{\Sigma}_F\widehat{V}^\top_F$ \\
        $
        S_t = (S_{t-1}\widehat{V}_F \quad \widehat{U}_F) \begin{pmatrix} \cos{\widehat{\Sigma}_F \eta} \\ \sin{\widehat{\Sigma}_F \eta} \end{pmatrix} \widehat{V}^\top_F + S_{t-1}(I - \widehat{V}_F\widehat{V}^\top_F)
        $ \\
    \ELSE
        \STATE {\bf Keep using previous subspace:} $S_t = S_{t-1}$
    \ENDIF
    \STATE {\bf Return final projected gradient to the optimizer:} $S_t^{\top} G_t$
\ENDFOR
\end{algorithmic}
\end{algorithm}