\begin{table*}
  \centering
  \begin{tabular}{lccccccc}
    \hline
    \multirow{2}{*}{\textbf{Method}} & \textbf{NQ} & \textbf{HotpotQA} & \textbf{TriviaQA} & \textbf{PopQA} &\textbf{ASQA} &  \textbf{MARCO} &\textbf{Avg.} \\
    &{(acc)} &{(acc)} &{(acc)} &{(acc)} &{(str-em)} &{(rouge)}\\
    \hline
    \multicolumn{8}{l}{\textit{Llama3-8B-Instruct}} \\
    \hdashline
    No Refinement    &{45.68} & {29.43} & {82.85} &{35.60} & {38.79}  & {20.73} &{42.18}\\
    Rerank & {46.18} &{30.30} &{83.51}  &{36.20} &  {39.92} & {20.72} &{42.81}\\
    Summary     &{44.27} & {28.05} & {82.09} &{33.67} & {37.81} &\textbf{22.67} &{41.32}\\
    CoT   &{45.33} & {26.36} & {81.45} &{34.13}  &{40.25}   & {19.52} &{41.17}\\
    % Vanilla query         &{34.93} & {26.83} & {77.61} &{} & {24.03} & {16.87} \\
    %RankCoT w/o SR &\uline{46.70} &\uline{30.59} &\uline{83.82} &\uline{36.63} &{40.04} &{20.72} &\uline{43.03} \\
    RankCoT  & \textbf{47.41} & \textbf{32.21} & \textbf{85.18} &\textbf{41.17} & \textbf{41.02}  &{20.84} &\textbf{44.64}\\
    \hline
    \multicolumn{8}{l}{\textit{MiniCPM3-4B}} \\
    \hdashline
    % Vanilla query         &{19.74} & {18.55} & {47.08} &{} & {22.05} & {15.96} \\
    No Refinement    &{42.51} &{24.93} &{80.91} &{32.53} &{24.31}  & {13.55} &{36.46}\\
    RankCoT  & \textbf{48.78} & \textbf{33.13} & \textbf{85.20} &\textbf{36.87}  &\textbf{35.85} & \textbf{24.59} &\textbf{44.07}\\
    \hline
    \multicolumn{8}{l}{\textit{Qwen2.5-14B-Instruct}} \\
    \hdashline
    % Vanilla query         &{30.38} & {24.30} & {71.02} &{} & {23.37} & {15.59}\\
    No Refinement    &{47.66} & {29.70} & {79.49} &{36.97} &\textbf{44.73} & {18.50} &{42.84}\\
    RankCoT  & \textbf{49.98} & \textbf{33.91} & \textbf{86.68} &\textbf{44.45}  & {41.94} & \textbf{24.62} &\textbf{46.93}\\
    \hline
  \end{tabular}
  \caption{\label{main result}
    Overall Performance of RAG System with Different Knowledge Refinement Models. We use Llama3-8B-Instruct as the backbone model for different knowledge refinement models and apply RankCoT to the RAG system, which is implemented with Llama3-8B-Instruct, MiniCPM3-4B, and Qwen2.5-14B-Instruct. 
  }
\end{table*}