\section{Conclusion}
\label{sec:Conclusion}
We introduce InsightVision, a comprehensive, multi-level Chinese-based benchmark designed to evaluate the understanding of implicit visual semantics in LVLMs. The benchmark comprises over 2,500 carefully curated images, each paired with questions that assess four levels of comprehension: surface-level content understanding, symbolic meaning interpretation, background knowledge comprehension, and implicit meaning comprehension. Our evaluations demonstrate a considerable gap between current LVLMs and human performance, particularly in understanding implicit meanings. We suggest that enhancing model parameters or integrating detailed image descriptions during reasoning may help improve the model's ability to capture and interpret deeper semantic content. This work underscores the need for more advanced multimodal models capable of nuanced visual semantic understanding. We hope InsightVision will serve as a valuable resource for advancing research aimed at bridging the gap between perceptual recognition and cognitive understanding of visual content.

\section*{Limitations}
The InsightVision dataset currently focuses on comic images, which effectively convey implicit meanings but lack visual diversity. Future expansions will include other media, such as photography and video, to enhance diversity and applicability. Additionally, the dataset is based on Chinese cultural contexts, which may limit generalizability; broader cultural inclusion is planned. Lastly, despite using GPT-4o and human review for annotation, biases and errors may still exist, and improvements to the generation pipeline are needed to address these issues.
% The InsightVision dataset currently focuses exclusively on comic images, selected for their ability to convey rich, implicit meanings. While comics are effective for evaluating complex visual semantics, this choice may limit the diversity of visual styles represented. Future work will expand the dataset to include other forms of visual media, such as photography and video, to more fully capture real-world visual scenarios.

% Furthermore, InsightVision is predominantly framed within Chinese cultural contexts, which could restrict its applicability to models trained on or intended for different cultural backgrounds. Expanding the dataset to include a wider array of cultural perspectives is an important avenue for future research.

% Finally, while pre-annotation models like GPT-4o are effective in generating image annotations, they may introduce biases. Despite implementing a dual-review process with human verification, the potential for annotation errors and biases remains. The datasetâ€™s generation pipeline can be further refined to mitigate these issues, ensuring a more robust and unbiased benchmark.

\section*{Acknowledgements}
The authors wish to thank the anonymous reviewers for their helpful comments. This work was supported by Ant Group Research Intern Program.