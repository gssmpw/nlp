\section{Related Works}
% Adversarial attacks on vision models____, text models____, and multimodal systems____ have been studied extensively. Universal perturbations that generalize across inputs____ remain a severe threat to deployed systems. Recent work has demonstrated that multimodal LLMs inherit vulnerabilities from their sub-modules, but universal attacks on aligned systems have not been well-studied. Our work fills this gap by constructing a single image that consistently triggers harmful behavior in a wide range of queries.

\subsection{Adversarial Attacks on Vision Models}
Early work on adversarial examples demonstrated that small pixel-level perturbations can mislead deep convolutional networks____. Subsequent research explored universal perturbations that transfer across multiple inputs____, highlighting the inherent fragility of these models. Gradient-based methods remain central in these studies, including diverse improvements on iterative update rules____ to enhance attack efficacy and transferability.

\subsection{Adversarial Attacks on Text Models}
Textual adversarial attacks typically rely on discrete perturbations such as synonym substitution or character-level changes____. These approaches leverage gradient signals____ or rule-based strategies____ to disrupt language understanding, often requiring careful semantic and syntactic constraints. Despite growing sophistication, text-based attacks must address the discrete nature and lower dimensionality of language data compared to vision.

\subsection{Multimodal and Universal Attacks}
Extending adversarial attacks to multimodal systems reveals novel vulnerabilities, as both image and text components can be targeted____. Some methods combine cross-modal manipulations or exploit attention mechanisms to cause misalignment____. Additionally, universal perturbations retaining effectiveness across multiple prompts and modalities____ pose a significant threat to real-world deployment. Recent attempts have also shown how carefully optimized single images can trigger unsafe responses in aligned models____.


While there have been numerous advances in adversarial attacks on unimodal systems, the multimodal models remains relatively underexplored. Universal and multimodal perturbations are particularly concerning for safety-critical applications, as they can bypass alignment safeguards____. Ongoing research focuses on building robust countermeasures, but the rapid development of Large Language Models and vision-language alignment leaves many open questions regarding reliable and scalable defense strategies.