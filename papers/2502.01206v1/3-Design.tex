\section{PerfSeer DESIGN}
PerfSeer consists of two main parts: representation and prediction, as shown in Figure \ref{fig:overview}.
\begin{enumerate}
\item
\textbf{Representation.} PerfSeer uses Graph Extractor to analyze the computational graph of a model, generating a performance graph (PerfGraph) to represent the model. The PerfGraph encompasses the topology as well as the node, edge, and global features, comprehensively preserving the performance information of models 
(Section \ref{sec:graph extractor}).

\item
\textbf{Prediction.} PerfSeer employs SeerNet and SeerNet-Multi, our designed prediction models. These models effectively leverage the extracted topology and various features. They capture the critical performance information to predict metrics like execution time, memory usage, and SM utilization (Section \ref{sec:seernet}).
\end{enumerate}

Through these two parts, PerfSeer can comprehensively represent the model and fully leverage this representation to predict the model performance accurately.

\subsection{Representation}\label{sec:graph extractor}
We use the Graph Extractor via ONNX to generate a PerfGraph, extracting the topology and as many performance-related features as possible to preserve and represent the performance information of models. 
PerfSeer is compatible with multiple DL frameworks, such as PyTorch, TensorFlow, and MXNet, unlike other predictors that support only a few.
\subsubsection{Definition of PerfGraph.}\label{sec:definition of graph}
PerfGraph is defined as a 3-tuple $G = \left(\uu, V, E\right)$.
% u
The $\uu$ represents the global features, which are the features of the entire model.
% v
The $V = \left\{\vv_i\right\}_{i=1:N^v}$ is the set of nodes ($N^v$ is the number of nodes), where $\vv_i$ represents the features of node $i$ (Node $i$ represents operation node $i$ in the computational graph).
% e
The $E = \left\{\left(\ee_j, s_j, t_j\right)\right\}_{j=1:N^e}$ is the set of edges ($N^e$ is the number of edges), where $s_j$ is the index of the source node and $t_j$ is the index of the target node, indicating a directed edge $j$ from the source node $s_j$ to the target node $t_j$. 
Edge $j$ represents the data flow from operation $s_j$ to operation $t_j$, where operation $t_j$ depends on operation $s_j$, and \(\ee_j\) represents the features of edge $j$.

\subsubsection{Features of PerfGraph.} \label{sec:features of graph}
The features of the PerfGraph consist of the node, edge, and global features, described as follows:

\input{figure/2-seerblock}
\emph{{Node Features.}}
Node features are represented as $\vv = \left(\vv^{hp} \cat \vv^{c} \cat \vv^{m} \cat \vv^{a} \cat \vv^{p} \right)$. $\cat$ represents the concatenation, responsible for concatenating different features.

$\vv^{hp}$ represents the hyper-parameters of the node, such as the kernel size of the convolution, and serves as the fundamental representation of the node, with all other features derived from it.

$\vv^{c}$ denotes the computation information (i.e., FLOPs) of the node, representing the computational requirements of the node.

$\vv^m$ represents the memory access information of the node, including the memory access cost (MAC) and the weight size.
The MAC is the sum of the sizes of the input, weight, and output tensors.
The features symbolize the memory access requirements of the node.

$\vv^{a}$ represents arithmetic intensity, defined as the ratio of FLOPs to MAC. The features can distinguish whether the node is arithmetic-intensive or memory-intensive.

$\vv^{p}$ denotes the proportions of FLOPs, MAC, and weight size relative to the model. The features can indicate the contribution of the node to the computational and memory requirements of the model.

\emph{{Edge Features.}}
Edge features are represented as $\ee = \left( \ee^{sz} \cat \ee^{sp} \right)$. 

$\ee^{sz}$ represents the size of the tensor delivered by the edge. 

$\ee^{sp}$ represents the shape of the tensor delivered by the edge, which includes the batch size, channel, height, and width. 

\emph{{Global Features.}}
Global features are represented as $\uu = \left( \uu^{gp} \cat \uu^{c} \cat \uu^{m} \cat \uu^{a} \cat \uu^{b} \right)$.

     $\uu^{gp}$ includes the number of nodes, edges, and density. The number of nodes ($N^v$) and edges ($N^e$) represent the counts of computations and memory accesses in the model, respectively. Density, defined as \(\frac{N^e}{N^e(N^e-1)}\), reflects the interconnectedness of the nodes in the graph, indicating how densely the nodes are connected. The features provide a topological profile of the entire computational graph of the model.

    $\uu^{c}$ represents FLOP statistics for all nodes in the model, including total, average, median, and maximum FLOPs. The features capture the computational characteristics of the model.
    
    $\uu^{m}$ represents memory access statistics for all nodes, such as total, average, median, and maximum values for MAC and weight size, as well as the average tensor size per edge, reflecting the memory access profile of the model.
    
    $\uu^{a}$ denotes arithmetic intensity, the ratio of FLOPs to MAC, which helps distinguish whether the model is arithmetic-intensive or memory-intensive.
    
    $\uu^{b}$ represents the batch size, which indicates the number of samples processed simultaneously by the model.

\subsection{Prediction}\label{sec:seernet}
SeerNet comprises a SeerBlock and an MLP-based prediction head.
The PerfGraph is input into SeerBlock, which learns a graph embedding that captures the performance information from the node, edge, global features, and the topology of the computational graph. This embedding is then passed to the prediction head, a two-layer MLP with 256 hidden channels, to predict the performance accurately.
\subsubsection{SeerBlock.}\label{sec:seerblock}
SeerBlock, inspired by \cite{gn}, enables each feature to update its own representation by utilizing both its own features and the aggregated information from other features.
The workflow of SeerBlock, shown in Figure \ref{fig:seerblock}, consists of four update functions ($\phi$) and three aggregation functions ($\rho$). 
\input{equation/seerblock}
Where $E'_i = \left\{\left(\ee'_j, s_j, t_j \right)\right\}_{t_j=i,\; j=1:N^e}$, $V'=\left\{\vv'_i\right\}_{i=1:N^v}$, and $\zz$ represents the features of the global node (Section \ref{sec:gnpb}). The details are as follows:

\begin{enumerate}
% edge update
\item $\phi^e$ is applied to per edge, to compute the updated edge features, $\ee'_j$.
The set of resulting per-edge outputs for each node, $i$, is,
$E'_i = \left\{\left(\ee'_j, s_j, t_j \right)\right\}_{t_j=i,\; j=1:N^e}$.
\begin{equation}
  \ee'_j = \phi^e\left(\ee_j, \vv_{s_j}, \vv_{t_j}\right) = \mathrm{MLP}_e\left(\ee_j \cat \vv_{s_j} \cat \vv_{t_j}\right).
\end{equation}

% edge to node
\item $\rho^{e\rightarrow v}$ is applied to $E'_i$, and aggregates the edge updates for the edges that project to node $i$, into $\mathbf{\bar{e}}'_i$, which will be used in node update in the next step. 
\begin{equation}
    \mathbf{\bar{\ee}'}_i = \rho^{e\rightarrow v}\left(E'_i\right) = \frac{1}{|E'_i|}\sum_{e'_j \in E'_i} \ee'_j.
\end{equation}

% node update
\item $\phi^v$ is applied to each node $i$,
to compute the updated node features, $\vv'_i$. 
The set of resulting per-node outputs is, $V'=\left\{\vv'_i\right\}_{i=1:N^v}$.
\begin{equation}
    \vv'_i = \phi^v\left(\mathbf{\bar{e}}'_i, \vv_i, \zz, \uu\right) = \mathrm{MLP}_v \left(\bar{\ee}'_i \cat (\vv_i + \zz) \cat \uu\right).
    \label{eq:node update}
\end{equation}

% node to global node
\item $\rho^{v \rightarrow z}$ is applied to $V'$, and aggregates all node updates, into $\bar{\vv}_z'$, which will then be used to update the global node in the next step (Section \ref{sec:gnpb}). 
\begin{equation}
    \bar{\vv}_z' = \rho^{v\rightarrow z}\left(V'\right) = {\text{softmax}}(V'). 
    \label{eq:aggr v2n}
\end{equation}

% global node update
\item $\phi^z$ is applied once per graph, 
to compute the updated global node features, $z'$. 
\begin{equation}
    z' = \phi^z\left({\bar{\vv}}_z', \zz\right) = \mathrm{MLP}_z\left({\bar{\vv}}_z' + \zz\right).
    \label{eq:global node update}
\end{equation}

% node to global
\item $\rho^{v \rightarrow u}$ is applied to $V'$, and aggregates all node updates, into $\bar{\vv}_u'$, which will then be used in the update of global features in the next step (Section \ref{sec:synmm}). 
\begin{equation}
    \bar{\vv}_u' = \rho^{v\rightarrow u}\left(V'\right) = \text{SynMM}\left(V'\right).
\end{equation}

% global update
\item $\phi^u$ is applied once per graph, 
to compute the updated global features, $\uu'$. $\uu'$ is the output of the SeerBlock.
\begin{equation}
    \uu' = \phi^u\left(\bar{\vv}_u', \mathbf{z'}, \uu\right) = \mathrm{MLP}_u\left(\bar{\vv}_u' \cat \mathbf{z'} \cat \uu\right).
\end{equation}

\end{enumerate}
Each MLP in SeerBlock has one layer with 256 channels, except for $\text{MLP}_z$, which has two layers. Given the PerfGraph $G = \left(\uu, V, E\right)$, SeerBlock produces the updated PerfGraph $G' = \left(\uu', V', E'\right)$, and the graph embedding $\uu'$ is fed into the prediction head.

\input{figure/3-readout}
\subsubsection{Synergistic Max-Mean Aggregation.}\label{sec:synmm}
SynMM is the customized function for the node features aggregation. As shown in Figure \ref{fig:readout}, the node features are first fed into the max and mean aggregation to obtain intermediate results, $\bar{\vv}_1$ and $\bar{\vv}_2$. 
Then, linear aggregation combines these results to generate the final aggregated features, $\bar{\vv}$. 
Max aggregation extracts the most prominent features from crucial nodes, while mean aggregation captures global information and overall model characteristics. 
Linear aggregation consolidates the results from both max and mean aggregation, providing a more comprehensive and robust model representation.

\subsubsection{Global-Node Perspective Boost.}\label{sec:gnpb}
GNPB, based on \cite{virtualnode}, not only introduces a global node connected to each node, with $\zz$ representing its features, but also designs an initialization method, updates its features, and incorporates them into the final graph embedding update.
The process is as follows:
First, the $\zz$ are initialized using ${\text{softmax}}$, aggregating the initial features of all nodes to capture global information.  
During the node update, each node utilizes the $\zz$ to incorporate global information (Equ. \ref{eq:node update}).  
The $\zz$ then updates itself by aggregating information from all updated nodes (Equ. \ref{eq:global node update}).
The global node offers a unique global perspective by aggregating information from all nodes, distinct from the global features based on the inherent characteristics of models. GNPB enables complementary learning between the node and global features, enriching both perspectives.

\subsubsection{SeerNet-Multi.}\label{sec:seernet multi}
SeerNet-Multi extends SeerNet by using multiple MLP-based prediction heads to predict different performance metrics separately.
In addition, PCGrad is employed to mitigate gradient conflicts among different performance metrics prediction tasks during the training of SeerNet-Multi. PCGrad works by adjusting the gradients of each task to minimize conflicts that arise when gradients point in opposing directions.
The core idea is to identify conflicts by calculating the cosine similarity between the gradients of different tasks. When a conflict is detected (cosine similarity is negative, indicating opposing directions), the gradient of the task is adjusted to ensure alignment by projecting it onto the normal plane of the conflicting gradient. If no conflict is found, the gradient remains unchanged.
By resolving these conflicts, PCGrad enables SeerNet-Multi to effectively predict multiple performance metrics simultaneously while maintaining accuracy.
