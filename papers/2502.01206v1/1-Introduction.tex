\section{INTRODUCTION}
%%% background
Deep learning (DL) has achieved significant success across various fields \cite{RNN,cnn}. Understanding the performance of models (e.g., execution time and resource utilization) is crucial for technologies such as Neural Architecture Search (NAS) and DL cluster schedulers, which drive the advancement of deep learning.
NAS relies on performance metrics like execution time \cite{Brp-nas,latencyaware-nas} and memory usage \cite{sas-nas,micronets-nas} to design efficient models that meet hardware constraints. Similarly, efficient DL cluster schedulers use these metrics to reduce job completion time and improve accelerator utilization \cite{Liquid,Horus}.

%%% related work
Acquiring performance metrics through online profiling is both time-consuming and costly. Consequently, various predictors have been proposed to predict the model performance, generally categorized into three main methods.
The first method \cite{Liquid,Horus} treats the model as a whole, representing it with global features like floating point operations (FLOPs). These features are then used in a basic model, such as Multi-Layer Perceptron (MLP) \cite{mlp}, to predict the performance.
The second method \cite{justus,Nn-meter} divides the model into multiple parts (e.g., operations or units), each represented by specific features. These features are then fed into a similar basic model to predict the performance of each part, which is aggregated to estimate the overall performance.
The third method \cite{Brp-nas,dnnperf,DIPPM,PerfSAGE} treats the model as a computational graph, represented by its topology and node features. These features are then input into a GNN-based model. This approach enables more accurate predictions by learning the performance of each operation and their interdependencies.
%%% shortage
Overall, 
performance predictors use machine-readable data to represent models and then feed this data into prediction models to predict the performance.

However, the model representation in these predictors is not comprehensive enough, resulting in the loss of important information related to model performance, leading to suboptimal prediction accuracy.
Specifically, the node, edge, and global features are all crucial for a model. Node features capture the characteristics of each operation. Edge features describe the data flow and dependencies between operations. Global features provide a view of the overall structure and complexity of the model.
Existing predictors have not selected and utilized these features effectively. 

%%% implement
We propose PerfSeer, a novel predictor that can comprehensively represent the model and fully leverage this representation to accurately predict the performance of models.

Initially, 
PerfSeer uses Graph Extractor to parse the computational graph of a model and generate a performance graph (PerfGraph), which can represent the model performance.
This graph, in addition to the topology, also contains the node, edge, and global features, all of which improve the performance prediction accuracy.
Notably, we construct several unique and effective features, such as arithmetic intensity and statistics of computation and memory access, which are not used by any previous predictors and have been empirically proven to enhance prediction accuracy noticeably.

Subsequently, 
the PerfGraph is fed into our proposed prediction model, SeerNet, to predict the performance.
SeerNet, inspired by \cite{gn}, enables each feature to update its own representation by utilizing both its own features and aggregated information from other features.  
This allows SeerNet to not only learn the topology but also fully leverage various features, providing a comprehensive understanding of the model. 
Specifically, it learns computation and memory access from the node features, data flow and dependencies between operations from the edge features, and the structure and complexity of the entire model from the global features.
% Furthermore
To capture the performance information of models more effectively, SeerNet employs Synergistic Max-Mean aggregation (SynMM) and Global-Node Perspective Boost (GNPB).
SynMM can better aggregate the node features, generating a more comprehensive and robust model representation.
GNPB enables complementary learning between the node and global features, mutually enriching their perspectives.

In addition, 
We propose SeerNet-Multi, a multi-metric performance prediction model designed for applications that require simultaneous consideration of multiple metrics (e.g., \cite{Horus,Liquid}). Training and maintaining separate models for each metric is inefficient, so SeerNet-Multi extends SeerNet with multiple prediction heads to predict multiple metrics simultaneously. To address conflicts in parameter updates caused by differing gradient directions across tasks, we integrate Projecting Conflicting Gradients (PCGrad) \cite{pcgrad}, ensuring high accuracy. 
As a result, SeerNet-Multi provides efficient and accurate multi-metric predictions.

%%% datasets and result
We constructed a dataset with over 53k model configurations, covering key performance metrics such as execution time, memory usage, and Streaming Multiprocessor (SM) utilization during both training and inference in Nvidia GeForce RTX 3090. 
The dataset spans various architectures, such as VGG \cite{vggnet}, GoogLeNet \cite{googlenet}, ResNe(X)t \cite{resnet,resnext}, MobileNet \cite{Mobilenets}, and DenseNet \cite{densenet}. It also includes a wide range of FLOPs, from 49M to 22T.
Evaluation results show that SeerNet achieves an average Mean Absolute Percentage Error (MAPE) of 5.14\%, while SeerNet-Multi achieves 7.75\% MAPE, outperforming other predictors.

%%% contributions
We summarize our key contributions as follows:
\begin{itemize}
    \item We propose a novel performance predictor, PerfSeer.
    Experiments show that PerfSeer, with low deployment and usage overhead, predicts multiple performance metrics accurately for models of various architectures and frameworks on different devices during training and inference, enabling broad applicability.

    \item We design the performance prediction models, SeerNet and SeerNet-Multi.
    SeerNet achieves state-of-the-art prediction accuracy. 
    It rigorously selects, novelly constructs, and fully leverages the performance-related node, edge, and global features. Additionally, it enhances performance capture through SynMM and GNPB.
    SeerNet-Multi efficiently predicts multiple performance metrics without significantly affecting accuracy by addressing conflicting gradient issues across tasks using PCGrad.  

    \item We construct a performance dataset\footnote [1]{https://github.com/upuuuuuu/PerfSeer}.
    The dataset, which contains over 53k model configurations, covers key performance metrics across various architectures and FLOPs during both training and inference.
\end{itemize}
