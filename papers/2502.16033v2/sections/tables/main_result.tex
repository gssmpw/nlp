\begin{table*}[t]
% \small
\caption{\textbf{The accuracy of six MLLMs under the two evaluation settings.} Proprietary models demonstrate higher performance as well as larger performance gain in the MCQ setting.}
\begin{center}
\vspace{-10pt}
\resizebox{0.75\linewidth}{!}{
\begin{tabular}{lcccc|cccc}
\toprule

& \multicolumn{4}{c}{\textbf{Open-ended}} & \multicolumn{4}{c}{\textbf{Multiple-choice}} \\
\cmidrule(l){2-5}
\cmidrule(l){6-9}

Models & Web & Office & Poster & Overall & Web & Office & Poster & Overall\\

\midrule
\multicolumn{9}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
o1 (1217)         & 47.91 & 59.19 & 38.73 & 51.40 & 47.91 & 58.52 & 46.47 & 52.15 \\
GPT-4o (1120)     & 25.00 & 42.60 & 30.98 & 33.14 & 37.29 & 58.96 & 47.88 & 47.75 \\
\multicolumn{9}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
Qwen2.5-VL-7B     & 8.54  & 29.14 & 11.97 & 17.60 & 14.37 & 33.18 & 16.90 & 22.56 \\  
LLaVA-NeXT-7B     & 10.20 & 21.97 & 7.04  & 14.70 & 11.45 & 25.33 & 5.63  & 16.47 \\
InternVL2.5-8B    & 7.70  & 24.21 & 4.92  & 14.23 & 9.37  & 23.54 & 11.97 & 15.63 \\
Phi-3.5-Vision-4B & 6.87  & 24.43 & 7.04  & 14.23 & 1.66  & 8.52  & 0.00  & 4.30  \\
\bottomrule
\end{tabular}
}
\end{center}
% \vspace{-10pt}
\label{tab:main_eval_result}
\end{table*}

% \begin{table*}[t]
% % \small
% \caption{\textbf{The accuracy of six MLLMs under the two evaluation settings.} Proprietary models demonstrate higher performance as well as larger performance gain in the MCQ setting.}
% \begin{center}
% \vspace{-10pt}
% \resizebox{0.75\linewidth}{!}{
% \begin{tabular}{lcccc|cccc}
% \toprule

% & \multicolumn{4}{c}{\textbf{Open-ended}} & \multicolumn{4}{c}{\textbf{Multiple-choice}} \\
% \cmidrule(l){2-5}
% \cmidrule(l){6-9}

% Models & Web & Office & Poster & Overall & Web & Office & Poster & Overall\\

% \midrule
% \multicolumn{9}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
% o1 (1217)         & 56.39 & 48.96 & 36.36 & 50.60 & 48.64 & 47.31 & 41.55 & 47.14 \\
% GPT-4o (1120)     & 37.98 & 52.06 & 27.27 & 42.46 & 42.05 & 56.40 & 49.35 & 49.04 \\
% \multicolumn{9}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
% Qwen2.5-VL-7B     & 6.58  & 9.29  & 9.74  & 8.14  & 11.04 & 26.03 & 14.28 & 17.76 \\
% LLaVA-NeXT-7B     & 6.97  & 8.26  & 7.79  & 7.62  & 0.00  & 2.47  & 0.64  & 1.12 \\
% InternVL2.5-8B    & 12.59 & 15.90 & 7.79  & 13.34 & 12.79 & 26.23 & 13.63 & 18.54 \\
% Phi-3.5-Vision-4B & 7.36  & 9.29  & 7.79  & 8.23  & 6.58  & 21.69 & 11.03 & 13.51 \\
% \bottomrule
% \end{tabular}
% }
% \end{center}
% % \vspace{-10pt}
% \label{tab:main_eval_result}
% \end{table*}


% \begin{table}[t]
% % \small
% \caption{\textbf{We present the accuracy of six MLLMs under four different settings, each across three artifact types.}}
% \begin{center}
% \vspace{-10pt}
% \resizebox{\linewidth}{!}{
% \begin{tabular}{clcccc}
% \toprule

% \multicolumn{1}{c}{} & Models & \textbf{Web} & \textbf{Office} & \textbf{Poster} & \textbf{Overall}\\

% \midrule
% \multirow{8}{*}{\rotatebox[origin=c]{90}{Open-ended}} 
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
% & o1 (1217)         & 47.91 & 59.19 & 38.73 & 51.40 \\
% & GPT-4o (1120)     & 25.00 & 42.60 & 30.98 & 33.14 \\
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
% & Qwen2.5-VL-7B     & 8.54  & 29.14 & 11.97 & 17.60 \\   
% & LLaVA-NeXT-7B     & 10.20 & 21.97 & 7.04  & 14.70 \\
% & InternVL2.5-8B    & 7.70  & 24.21 & 4.92  & 14.23 \\
% & Phi-3.5-Vision-4B & 6.87  & 24.43 & 7.04  & 14.23 \\

% \midrule
% \multirow{8}{*}{\rotatebox[origin=c]{90}{SoM-MCQ}} 
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
% & o1 (1217)         & 39.16 & 52.69 & 24.64 & 42.88 \\
% & GPT-4o (1120)     & 23.75 & 54.58 & 21.12 & 36.23 \\
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
% & Qwen2.5-VL-7B     & 2.91  & 28.02 & 4.92  & 13.67 \\   
% & LLaVA-NeXT-7B     & 0.41  & 19.95 & 6.33  & 9.36  \\
% & InternVL2.5-8B    & 2.70  & 21.74 & 4.22  & 10.86 \\
% & Phi-3.5-Vision-4B & 0.83  & 13.67 & 7.04  & 7.02  \\

% \midrule
% \multirow{8}{*}{\rotatebox[origin=c]{90}{Cap-MCQ}} 
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
% & o1 (1217)         & 47.91 & 58.52 & 46.47 & 52.15 \\
% & GPT-4o (1120)     & 37.29 & 58.96 & 47.88 & 47.75 \\
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
% & Qwen2.5-VL-7B     & 14.37 & 33.18 & 16.90 & 22.56 \\   
% & LLaVA-NeXT-7B     & 11.45 & 25.33 & 5.63  & 16.47 \\
% & InternVL2.5-8B    & 9.37  & 23.54 & 11.97 & 15.63 \\
% & Phi-3.5-Vision-4B & 1.66  & 8.52  & 0.00  & 4.30  \\

% \midrule
% \multirow{8}{*}{\rotatebox[origin=c]{90}{Cap-SoM-MCQ}} 
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Proprietary Models}}\\
% & o1 (1217)         & 48.33 & 55.38 & 44.36 & 50.74 \\
% & GPT-4o (1120)     & 39.58 & 56.50 & 47.18 & 47.65 \\
% & \multicolumn{5}{>{\columncolor{gray!15}}l}{\textit{Open-sourced Models}}\\
% & Qwen2.5-VL-7B     & 15.83 & 35.20 & 15.49 & 23.87 \\
% & LLaVA-NeXT-7B     & 11.45 & 24.88 & 7.04  & 16.47 \\
% & InternVL2.5-8B    & 8.33  & 26.23 & 14.78 & 16.66 \\
% & Phi-3.5-Vision-4B & 7.70  & 13.90 & 1.40  & 9.45  \\
% \bottomrule
% \end{tabular}
% }
% \end{center}
% % \vspace{-2em}
% \vspace{-10pt}
% \label{tab:main_eval_result}
% \end{table}
