\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\linewidth]{graphs/greater_than_naive.pdf}
    \vspace{0.5cm}
    \includegraphics[width=0.8\linewidth]{graphs/p1_bottom.png}
    \vspace{-5pt}
    \caption{\textcolor{positional}{Positional} vs.\ \textcolor{nonpositional}{non-positional} circuits. In a \textcolor{nonpositional}{non-positional} circuit, the same edges must be included at all positions. A \textcolor{positional}{positional} circuit can distinguish between the same edge at different positions. This specificity yields better trade-offs between circuit size and faithfulness. It can also increase both precision and recall.}
    \label{fig:p1}
    \vspace{-5pt}
\end{figure}

\section{Introduction}

\looseness=-1
A primary goal of interpretability research is to characterize the internal mechanisms in language models (LMs) and other NLP models. 
A core approach in this area is \textbf{circuit discovery}---identifying the minimal subgraph within the model's computation graph that performs a specific task \citep{olah2021framework,olah-mech}.
Typically, the nodes of a circuit represent model components (e.g., attention heads, neurons, or layers).
While manual circuit discovery methods can yield position-specific insights \citep{wanginterpretability,goldowskydill2023localizingmodelbehaviorpath}, \emph{automatic methods often overlook positional information}, treating components as uniformly relevant across all input token positions \citep{conmytowards,syed2023attribution}. 
For instance, if an attention head is included in a circuit, it is assumed to contribute equally to the computation for every position in the input sequence.
The assumption that circuits are position-invariant ignores the fact that different positions often require distinct computations.
By ignoring positions, current methods limit their ability to capture mechanisms that operate across positions, such as interactions between attention heads across positions.

In this study, we start by demonstrating that positional agnosticism is a significant limitation (\S\ref{sec:motivating}). Then, to address these limitations, we introduce a new approach: position-aware edge attribution patching (PEAP; \S\ref{sec:full_circ_discovery}; Figure~\ref{fig:p1}). Current approaches  assume that if an edge is in a circuit, then the same edge will be in the circuit at all positions, thus leading to low precision. It is also assumed that an edge's importance should be aggregated across positions before deciding whether it should be included in the circuit; this can lead to cancellation effects, and thus low recall. PEAP instead allows us to compute the importance of cross-positional edges, and separately evaluates edge importance at each position. We show that this leads to smaller and more accurate circuits; see Figure~\ref{fig:p1}.

Incorporating positional information into circuit discovery is straightforward when inputs have the same length and structure across examples.

However, realistic datasets are not nearly this templatic.
How, then, can we incorporate positional information into automatic circuit discovery?
To address this challenge, we propose \textbf{schemas} (\S\ref{sec:schema}). 
Schemas assign semantic labels to spans of tokens, enabling information aggregation across examples even when the spans differ in length.

For example, in the input ``The \textcolor{positional}{war} lasted from 1453 to 14\underline{\hspace{1em}},'' the span ``\textcolor{positional}{war}'' could be labeled as ``\emph{Subject}''.
This enables handling spans with varying lengths: the phrase ``\textcolor{positional}{Black Plague}'' in another example can be treated as a single positional span with the same role as ``\textcolor{positional}{war}''.
In experiments with two LMs and three tasks, we find that circuits discovered using schemas achieve a better trade-off between circuit size and faithfulness to the model's behavior than position-agnostic circuits.
Importantly, position-aware circuits offer a more precise representation of the underlying mechanisms, providing a more concise foundation for mechanistic explanations.

We also present a fully automated pipeline for schema generation and application (\S\ref{sec:schema-generation}) using large language models (LLMs). 
We evaluate the quality of the generated schemas and their utility in discovering position-aware circuits (\S\ref{sec:schema-eval}).
Notably, circuits derived using automatically generated and applied schemas achieve comparable faithfulness scores to circuits discovered with human-designed and manually applied schemas.

We summarize our contributions as follows:
\begin{itemize}[noitemsep,leftmargin=*,topsep=1pt,parsep=1pt]
    \item Introduce a position-aware circuit discovery method, which obtains better faithfulness than position-agnostic discovery.  
    \item Introduce dataset schemas,  facilitating positional circuit discovery in more naturalistic settings. 
    \item Develop an automated schema generation and application pipeline with LLMs, yielding schemas that are comparable to manually-annotated ones.
\end{itemize}
