\section{Background and Motivation }\label{sec:motivating}
\begin{figure*}
    \centering
    \includegraphics[width=0.45\linewidth]{graphs/failure_cancellation.pdf}\hspace{1em} 
\includegraphics[width=0.45\linewidth]{graphs/failure_over.pdf}
    \caption{\textbf{Left}: The yellow edge at position 1 has the highest score of 100, indicating it is the most important edge. However, aggregating across positions causes scores of opposite signs to cancel. This causes the yellow edge to be incorrectly ranked as the \emph{least} important. \textbf{Right}: The yellow edge at position 1 has the highest score; the scores of other edges are consistently high (but lower) at many positions. After summing  across positions, the non-yellow edges have higher scores. Thus, the yellow edge is incorrectly ranked as the least important.}
    \label{fig:failure-exp}
\end{figure*}


A circuit is a subgraph of the model's computation graph;
it can be conceptualized as a binary mask $B(V,E,\mathcal{T})$ over all components $V$ and edges $E$ in the graph, selecting the components and edges that have the strongest effect on the model's behavior on a target task $\mathcal{T}$.
There are many methods for computing the influence of a component on the model's behavior on $\mathcal{T}$, including activation patching \citep{vig-2020-gender,finlayson-etal-2021-causal,geiger2021causal}, path patching \citep{wanginterpretability,goldowskydill2023localizingmodelbehaviorpath}, and edge patching \citep{hanna2024have,marks2024sparsefeaturecircuitsdiscovering}, with 
 attribution patching to approximate direct patching \cite{nanda2023attribution,syed2023attribution}.  
We focus  on edge patching, which aims to identify edges in $E$ that are causally important for $\mathcal{T}$.
For each such edge $(u,v)$, the nodes $u$ and $v$ are included in the circuit.

\emph{Manual} circuit discovery methods can distinguish between components at different token positions; examples include the IOI circuit \citep{wanginterpretability}, the Greater-Than circuit \citep{hanna2024does}, and the Attribute-Binding circuit \citep{prakashfine}.
The authors determined connections between attention heads by examining attention patterns and establishing connections if a head at one position strongly attended to a head at another.
However, this approach has three key limitations: (1) it is not scalable, (2) it is prone to human bias, and (3) it is unclear whether strong attention scores reliably indicate the a causal connection to the downstream metric \citep{jain2019attention}.

In contrast, \emph{automatic} approaches \citep{syed2023attribution, hanna2024have} systematically examine every connection and evaluate them \emph{quantitatively} via their causal effect on the downstream metric. However, when using automatic methods it is common to aggregate across token positions,\footnote{Cf.\ \citet{kramar2024atp}, propose a variant of attribution patching and perform position-sensitive node attribution. They do not use it to discover positional circuits.} which causes specific problems that we now define.

\paragraph{Cancellations across positions (low recall).}
If a component has scores with opposite signs across different positions, summing these scores can partially cancel out the component's overall effect, potentially resulting in a near-zero score (Figure~\ref{fig:failure-exp}, left).
\citet{kramar2024atp} note that cancellation can occur when aggregating across examples in the dataset. We observe that the extent of this phenomenon is larger than previously assumed: it can occur \emph{within a single sample} across positions. 
To measure cancellation effects across positions, we compare importance rankings from edge attribution patching (EAP; \citealp{syed2023attribution}) under two positional aggregation methods: (i) summing the absolute scores across both positions and examples (unaffected by cancellation effects); and (ii) summing scores across positions and then summing the absolute scores across different examples (affected by cancellation effects). 
We observe (Table~\ref{tab:intersections}, Top)  that the two rankings differ significantly at the most important components. 

\paragraph{Importance overestimation (low precision).} 
Circuits that do not consider positional information may favor edges that have small impacts at many positions over edges that have large impact in one or few positions (Figure \ref{fig:failure-exp}, Right). To measure overestimation effects we compare importance rankings derived from two aggregation methods: (i) summing the absolute scores across both positions and examples; and (ii) taking the max of the absolute across positions and then summing scores across different examples. Table \ref{tab:intersections} (Bottom) provides evidence for this phenomenon.


These problems motivate a circuit discovery method that takes position into account. We introduce this method in \S\ref{sec:full_circ_discovery}. 


\begin{table}[t!]
\vspace{-10pt}
    \centering   
     \begin{tabular}{lcccc}
    \toprule
    \rowcolor{lightgray} \multicolumn{5}{c}{Cancellation} \\
    $K\%$ & Diff & Diff$_{\text{Control}}$ & $\rho$ & $\rho_{\text{Control}}$ \\
    \midrule
    1 & 17.1\% & 3.9\% & 0.760 & 0.985 \\
    5 & 13.4\% & 2.4\% & 0.831 & 0.991 \\
    10 & 12.1\% & 2.3\% & 0.877 & 0.992 \\
    \midrule
    \rowcolor{lightgray} \multicolumn{5}{c}{Overestimation} \\
    $K\%$ & Diff & Diff$_{\text{Control}}$ & $\rho$ & $\rho_{\text{Control}}$ \\
    \midrule
    1 & 17.5\% & 3.6\% & 0.772 & 0.984 \\
    5 & 14.6\% & 2.1\% & 0.811 & 0.993 \\
    10 & 12.4\% & 2.2\% & 0.864 & 0.993 \\
    \bottomrule
    \end{tabular}
   \caption{Cancellation and overestimation effects when ignoring positions. We rank edges by their importance scores (IOI task, GPT2-small), and take the top $K\%$. We compute the set difference (Diff) and rank correlations ($\rho$) between rankings produced by the two aggregation methods described in \S\ref{sec:motivating}. We define the difference of two ranking lists $R_1$,$R_2$ at length L as $1-\frac{|R_1 \bigcap R_2|}{L}$. As a control, we also compute the mean pairwise set difference (Diff$_\text{Control}$) and rank similarities ($\rho_\text{Control}$) produced by the \emph{same} aggregation method across 3 data subsets. Differences with respect to control are all significant ($p<.01$).
   }
    \label{tab:intersections}
    \vspace{-5pt}
\end{table}

