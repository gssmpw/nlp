\section{Related Works}
\subsection{Diffusion Model and Representation Learning}
Diffusion models are regarded as multi-level DAEs with varied noise scales, which inherently capture meaningful representations within a latent space____. Therefore, leveraging the features learned during the diffusion process to effectively train downstream tasks____, such as segmentation and classification, proves both meaningful and advantageous____. However, while recent studies (See more in Appendix \ref{rw1}) primarily focus on methods for effectively leveraging features from the diffusion denoising process, few delve deeply into what representation learning truly entails or why it is effective.\par   

\subsection{Modality Alignment}
Huh et al. ____ hypothesize the modalities involved in training data are shadows on the \enquote{cave wall}, which is mentioned in Platoâ€™s Allegory of the Cave. Tian et al. ____ try to align the different modalities within the contrastive loss, and believe that the more views of physical-world involved in training, the better representation captured. Zimmermann et al. ____ investigate the connection between contrastive learning, generative modeling, and nonlinear independent component analysis to reveal the alignment of implicit features. Inspired by these findings (see more in Appendix \ref{model-alignment}), we aim to explore the existence of feature embeddings learned from modality alignment and underlying principles, which we refer to as the MetaFE in this study.\par 

\subsection{Endoscopic Monocular Depth Estimation}

In order to overcome the absence of depth annotation, Zhou et al. ____ propose a self-supervised approach that reformulates depth estimation as a view synthesis problem using warping methods. This framework includes both a DepthNet and a separate PoseNet, along with a predictive mask to handle challenging scenarios like object movement and occlusion/disocclusion. This foundation has led to the development of a range of refined optimization strategies____.  Considering the challenge posed by minimally invasive surgical settings, such as inconsistent interframe brightness, limit the direct applicability of these methods to endoscopic images. Shao et al. ____ propose AF-Net in order to rescue the illumination-invariant by introducing optical flow estimation module. Yang et al. ____ introduce the LiteMono framework to enhance computational efficiency in endoscopic depth estimation. Shao et al. ____ employ a diffusion model and knowledge distillation to produce higher-quality depth images, surpassing those generated by the teacher network. Nevertheless, the aforementioned studies primarily focus on network modifications or surface-level issues, lacking a thorough investigation into the core process of features decoding for depth estimation.\par 

Unlike previous studies that treat depth estimation as a mere modality transformation, we posit the existence of a space that represents physical entities in endoscopic surgery. By validating this space and extracting its intrinsic features, depth interpretation can be achieved with greater accuracy in endoscopic image depth estimation.\par