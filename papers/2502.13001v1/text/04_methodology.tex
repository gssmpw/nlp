\label{sec:pipeline}

We propose \pipeline{}, a multi-agent framework inspired by movie production to generate synthetic meeting transcripts from a knowledge source through multi-agent debate (see \Cref{fig:main_figure}).
The basic idea is to summarize the knowledge source to distill its key highlights to be discussed in a multi-agent-LLM setup.
This setup emulates a discussion among participants with distinct personas and their private memory of the knowledge source, including real-world dynamics such as turn-taking, disagreements, clarifications, and topic continuity.
\pipeline{} operates in three phases, i.e., \textit{pre-production}, \textit{production}, and \textit{post-production}, with seven stages overall (splitted 3/2/2 between each phase).
We explain here the methodological background of \pipeline{}, the corresponding prompts, and implementation details are covered in \Cref{sec:appendix_A,sec:appendix_C}.
In \Cref{sec:appendix_B}, we present the result of each stage using an example knowledge source.




\subsection{Pre-Production Phase}
This phase establishes foundational elements, including the meeting’s target summary, participant roles, and an agenda-like outline.

\paragraph{Stage 1: Content Brainstorming.}
Given a source text, we prompt an LLM to extract hierarchical topics and subtopics, following the approach outlined in \citet{Paoli23a}.
An LLM composes an abstractive target summary following \citet{GaoJYZ24}, guided by five human-written QMSum summaries for consistent brevity, style, and structure.
This summary covers the later discussion points and topic flow, acting as a basic outline.



\paragraph{Stage 2: Casting.}
\label{sec:stage_2_casting}


We define participant profiles suited to the meeting context.
Each profile contains a functional role (e.g., project manager, technical expert), background (e.g., experience, qualifications), domain expertise, and a distinct perspective (e.g., favoring practical solutions).
An LLM iteratively creates these profiles, ensuring complementary viewpoints without redundancy.
Next, each profile receives a speaking style, including tone (e.g., formal), language complexity (e.g., jargon), communication style (e.g., assertive), plus filler words (e.g., ``um,'' ``you know'') and catchphrases to align the person's language with their role.

We distributed select knowledge-source paragraphs to each participant based on expertise \cite{LiWXG25}, introducing knowledge imbalances that foster reliance on one another.
Building on \citet{SerapioGarciaSCS23a} research on LLM personality traits, each participant is assigned psychologically grounded behaviors, e.g., evaluator-critic, blocker \cite{BenneS48}, drawn from a curated list (full list given in \Cref{tab:app_role_overview} in \Cref{sec:appendix_C}).
These behaviors can shift according to the meeting format or topic, allowing realistic group dynamics and participant evolution.  % e.g., embodying a 'blocker' personality if a topic is against a participant's own goals)
An LLM also checks for contradictory traits (e.g., proactive yet blocking) to maintain role consistency.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.9\linewidth]{figure/storage/participant.png}
    \caption{Example of a minimal participant definition.}
    \label{fig:participant_figure}
\end{figure}



\paragraph{Stage 3: Scripting.}
An LLM expands the target summary into a flexible outline of thematic scenes, each dedicated to a major subtopic of the knowledge source.
A scene includes a title, an agenda description, and bullet points covering key content.
Scenes also specify relevant aspects of the source material and invite participants to draw on personal experiences, reflecting each persona.
Depending on the meeting type, extra scenes (e.g., a pre-meeting brainstorming phase) may be added for realism, even if they are not part of the target summary.
This outline serves as a roadmap, allowing participants to briefly shift themes or discuss subtopics without straying from the broader structure.

\subsection{Production Phase}
This phase simulates turn-by-turn dialogue among multiple LLMs and validate each scene for quality.


\paragraph{Stage 4: Filming.}
\label{sec:stage_4_filming}

We generate transcripts scene by scene, following the outline from Stage 3: Scripting.
Each participant is an independent LLM instance, contributing one turn at a time.
To emulate real-world scenarios \cite{ZhouSEK24}, we implement a non-omniscient approach where each participant has private memory, seeing only their own profile, relevant source snippets, a summary of prior scenes, the last three turns of the previous scene and all turns so far in the current scene.

Scenes begin with the participant most relevant to the topic, determined by the exact LLM-based matching used during casting \cite{LiWXG25}.

At the end of each turn, the current speaker nominates the next speaker based on roles, current focus, and prior contributions (e.g., previously raised concerns or ideas introduced) \cite{NonomuraM24a}.
Reminding the current speaker about the other participants prevents them from being left out.

To conclude a turn, the speaker can propose a vote to end a scene \cite{WangWST24a}.
The vote can be called after the first turn if the speaker finds that they have stated all the details in their individual knowledge that fit the current discussion topic.
If the majority (more than 50\%) of the participants agree during voting, the scene ends.
To avoid endless loops, a system reminds the group to finalize if no one initiates a vote after 50 turns.
\pipeline{} then proceeds to the next scene or terminates if all scenes are complete.



\paragraph{Stage 5: Quality assuring.}
Inspired by 'Self-Refinement' \cite{MadaanTGH23b} where LLMs iteratively provide feedback and refine their output, we use a ``director'' model to review each scene along three dimensions: \textbf{topical alignment}, i.e., adherence to the target summary \cite{LinC23}, \textbf{conversational naturalness}, i.e., turn-taking quality, dialogue flow \cite{LiuIXW23}, and \textbf{coherence/factual accuracy}, i.e., logical progression, consistency with knowledge source \cite{XieZPJ24}.
The director LLM provides feedback to correct any critical issues identified (e.g., missing subtopics, overly formal language, and contradictions).
We allow up to three ``re-filming'' cycles, considering this feedback.
If a scene remains problematic after three attempts, \pipeline{} proceeds with the best version, deferring residual edits to the post-production phase.
In practice, this fallback was never triggered for \dataset{}.


\subsection{Post-Production Phase}
This phase injects disruptions for realism and polishes transcripts to ensure real-sounding meetings.



\paragraph{Stage 6: Special effects.}
We inject flow-breaking events (e.g., phone calls, technical glitches, side questions) with a 25\% chance per scene\footnote{Chosen empirically to balance realism without overwhelming the meeting.}, permitting multiple disruptions per meeting.
These events lead to adding a few turns from the participants (e.g., acknowledging a ringing phone) before the main discussion resumes.

\paragraph{Stage 7: Editing.}
A two-step linguistic refinement removes repetitive phrases and overly formal speech and adds minor speech markers (e.g., hesitations).
A subsequent detector–revision step targets any remaining synthetic cues (e.g., uniformly polite turns, unrealistic consensus).
If necessary, minor disagreements or paraphrases are introduced to achieve more natural, human-like transcripts.
