[
  {
    "index": 0,
    "papers": [
      {
        "key": "hao2023reasoning",
        "author": "Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting",
        "title": "Reasoning with language model is planning with world model"
      },
      {
        "key": "wang2023promptagent",
        "author": "Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting",
        "title": "Promptagent: Strategic planning with language models enables expert-level prompt optimization"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "wang2024can",
        "author": "Wang, Ruoyao and Todd, Graham and Xiao, Ziang and Yuan, Xingdi and C{\\^o}t{\\'e}, Marc-Alexandre and Clark, Peter and Jansen, Peter",
        "title": "Can Language Models Serve as Text-Based World Simulators?"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ha2018world",
        "author": "Ha, David and Schmidhuber, J{\\\"u}rgen",
        "title": "World models"
      },
      {
        "key": "ha2018recurrent",
        "author": "Ha, David and Schmidhuber, J{\\\"u}rgen",
        "title": "Recurrent world models facilitate policy evolution"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "wu2023daydreamer",
        "author": "Wu, Philipp and Escontrela, Alejandro and Hafner, Danijar and Abbeel, Pieter and Goldberg, Ken",
        "title": "Daydreamer: World models for physical robot learning"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "guan2024world",
        "author": "Guan, Yanchen and Liao, Haicheng and Li, Zhenning and Hu, Jia and Yuan, Runze and Li, Yunjian and Zhang, Guohui and Xu, Chengzhong",
        "title": "World models for autonomous driving: An initial survey"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhao2023survey",
        "author": "Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others",
        "title": "A survey of large language models"
      },
      {
        "key": "qin2024large",
        "author": "Qin, Libo and Chen, Qiguang and Feng, Xiachong and Wu, Yang and Zhang, Yongheng and Li, Yinghui and Li, Min and Che, Wanxiang and Yu, Philip S",
        "title": "Large language models meet nlp: A survey"
      },
      {
        "key": "huang2022language",
        "author": "Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor",
        "title": "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents"
      },
      {
        "key": "hu2024hiagent",
        "author": "Hu, Mengkang and Chen, Tianxing and Chen, Qiguang and Mu, Yao and Shao, Wenqi and Luo, Ping",
        "title": "Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mu2024robocodex",
        "author": "Mu, Yao and Chen, Junting and Zhang, Qinglong and Chen, Shoufa and Yu, Qiaojun and Ge, Chongjian and Chen, Runjian and Liang, Zhixuan and Hu, Mengkang and Tao, Chaofan and others",
        "title": "RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis"
      },
      {
        "key": "chen2024textbfemostextbfembodimentawareheterogeneoustextbfmultirobot",
        "author": "Junting Chen and Checheng Yu and Xunzhe Zhou and Tianqi Xu and Yao Mu and Mengkang Hu and Wenqi Shao and Yikai Wang and Guohao Li and Lin Shao",
        "title": "$\\textbf{EMOS}$: $\\textbf{E}$mbodiment-aware Heterogeneous $\\textbf{M}$ulti-robot $\\textbf{O}$perating $\\textbf{S}$ystem with LLM Agents"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "lai2024analogcoder",
        "author": "Lai, Yao and Lee, Sungyoung and Chen, Guojin and Poddar, Souradip and Hu, Mengkang and Pan, David Z and Luo, Ping",
        "title": "AnalogCoder: Analog Circuit Design via Training-Free Code Generation"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "hao2023reasoning",
        "author": "Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting",
        "title": "Reasoning with language model is planning with world model"
      },
      {
        "key": "wang2024can",
        "author": "Wang, Ruoyao and Todd, Graham and Xiao, Ziang and Yuan, Xingdi and C{\\^o}t{\\'e}, Marc-Alexandre and Clark, Peter and Jansen, Peter",
        "title": "Can Language Models Serve as Text-Based World Simulators?"
      },
      {
        "key": "wang2023promptagent",
        "author": "Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting",
        "title": "Promptagent: Strategic planning with language models enables expert-level prompt optimization"
      },
      {
        "key": "li2022emergent",
        "author": "Li, Kenneth and Hopkins, Aspen K and Bau, David and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Emergent world representations: Exploring a sequence model trained on a synthetic task"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "hao2023reasoning",
        "author": "Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting",
        "title": "Reasoning with language model is planning with world model"
      },
      {
        "key": "wang2024can",
        "author": "Wang, Ruoyao and Todd, Graham and Xiao, Ziang and Yuan, Xingdi and C{\\^o}t{\\'e}, Marc-Alexandre and Clark, Peter and Jansen, Peter",
        "title": "Can Language Models Serve as Text-Based World Simulators?"
      },
      {
        "key": "wang2023promptagent",
        "author": "Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting",
        "title": "Promptagent: Strategic planning with language models enables expert-level prompt optimization"
      },
      {
        "key": "li2022emergent",
        "author": "Li, Kenneth and Hopkins, Aspen K and Bau, David and Vi{\\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin",
        "title": "Emergent world representations: Exploring a sequence model trained on a synthetic task"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "banerjee2020can",
        "author": "Banerjee, Pratyay and Baral, Chitta and Luo, Man and Mitra, Arindam and Pal, Kuntal and Son, Tran C and Varshney, Neeraj",
        "title": "Can Transformers Reason About Effects of Actions?"
      },
      {
        "key": "luo2023towards",
        "author": "Luo, Man and Kumbhar, Shrinidhi and Parmar, Mihir and Varshney, Neeraj and Banerjee, Pratyay and Aditya, Somak and Baral, Chitta and others",
        "title": "Towards logiglue: A brief survey and a benchmark for analyzing logical reasoning capabilities of language models"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "hu2023tree",
        "author": "Hu, Mengkang and Mu, Yao and Yu, Xinmiao and Ding, Mingyu and Wu, Shiguang and Shao, Wenqi and Chen, Qiguang and Wang, Bin and Qiao, Yu and Luo, Ping",
        "title": "Tree-planner: Efficient close-loop task planning with large language models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "oswald2024large",
        "author": "Oswald, James and Srinivas, Kavitha and Kokel, Harsha and Lee, Junkyu and Katz, Michael and Sohrabi, Shirin",
        "title": "Large Language Models as Planning Domain Generators"
      },
      {
        "key": "silver2024generalized",
        "author": "Silver, Tom and Dan, Soham and Srinivas, Kavitha and Tenenbaum, Joshua B and Kaelbling, Leslie and Katz, Michael",
        "title": "Generalized planning in pddl domains with pretrained large language models"
      },
      {
        "key": "smirnov2024generating",
        "author": "Smirnov, Pavel and Joublin, Frank and Ceravola, Antonello and Gienger, Michael",
        "title": "Generating consistent PDDL domains with Large Language Models"
      },
      {
        "key": "zhu2024language",
        "author": "Zhu, Wang and Singh, Ishika and Jia, Robin and Thomason, Jesse",
        "title": "Language Models can Infer Action Semantics for Classical Planners from Environment Feedback"
      },
      {
        "key": "wang2023bytesized32",
        "author": "Wang, Ruoyao and Todd, Graham and Yuan, Eric and Xiao, Ziang and C{\\^o}t{\\'e}, Marc-Alexandre and Jansen, Peter",
        "title": "ByteSized32: A corpus and challenge task for generating task-specific world models expressed as text games"
      },
      {
        "key": "wong2023word",
        "author": "Wong, Lionel and Grand, Gabriel and Lew, Alexander K and Goodman, Noah D and Mansinghka, Vikash K and Andreas, Jacob and Tenenbaum, Joshua B",
        "title": "From word models to world models: Translating from natural language to the probabilistic language of thought"
      },
      {
        "key": "vafa2024evaluating",
        "author": "Vafa, Keyon and Chen, Justin Y and Kleinberg, Jon and Mullainathan, Sendhil and Rambachan, Ashesh",
        "title": "Evaluating the World Model Implicit in a Generative Model"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "guan2023leveraging",
        "author": "Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao",
        "title": "Leveraging pre-trained large language models to construct and utilize world models for model-based task planning"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "hu2024agentgen",
        "author": "Hu, Mengkang and Zhao, Pu and Xu, Can and Sun, Qingfeng and Lou, Jianguang and Lin, Qingwei and Luo, Ping and Rajmohan, Saravan and Zhang, Dongmei",
        "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "xie2024making",
        "author": "Xie, Kaige and Yang, Ian and Gunerli, John and Riedl, Mark",
        "title": "Making large language models into world models with precondition and effect knowledge"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "vafa2024evaluating",
        "author": "Vafa, Keyon and Chen, Justin Y and Kleinberg, Jon and Mullainathan, Sendhil and Rambachan, Ashesh",
        "title": "Evaluating the World Model Implicit in a Generative Model"
      }
    ]
  }
]