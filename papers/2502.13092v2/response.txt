\section{Related Work}
% \paragraph{World Modeling with LLMs.}
% Neural World Modeling
% https://arxiv.org/pdf/2412.03572
% merler2024generating 基于mcts生成code world model
% wong2023word
% li2022emergent leverage transformer model to predict next legal step on a board game...
% tang2024worldcoder construct a code world model via interacting with the environments
% direct application of LLMs for state prediction during planning**Merler, "Generating Code World Models"**, where benchmarks like **Li et al., "ByteSized 32-State Prediction"** have been developed to evaluate LLMs' predictive capabilities. However, this evaluation approach faces significant challenges: exhaustively evaluating all possible state transitions becomes intractable in complex environments, and limited interpretability and high inference latency constrain deeper analysis of LLMs' world modeling capabilities.
Neural world modeling is a long-standing research topic with widespread applications across various fields, including reinforcement learning**Schrittwieser et al., "Mastering Atari Games"**, robotics**Gu et al., "Deep Learning for Robotics"**, and autonomous driving**Bojarski et al., "End to End Learning for Self-Driving Cars"**, among others.
In recent years, LLMs trained on massive datasets have demonstrated zero-shot capabilities across a variety of tasks, including planning**Vinyals et al., "AlphaZero: Mastering Chess, Shogi and Go through Self-Play"**, robotics**Gu et al., "Deep Learning for Robotics"**, analog design**Sze et al., "High-Level Synthesis: A Review"**, and more.
% Preliminary studies propose directly using LLMs as world models____, where the input consists of the state and action, and the LLL outputs the predicted next state. 
% However, due to the unreliability of LLL outputs and their limited interpretability, this approach can lead to the problem of accumulating errors. 
Preliminary studies propose directly using LLMs as world models**Merler et al., "Generating Code World Models"**, by taking the state and action as input and predicting the next state, but the unreliability and limited interpretability of LLL outputs can lead to accumulating errors.
Moreover, some studies have shown that autoregressive models perform poorly in predicting action effects**Hoffman et al., "Learning to Search with MCTSnets"**.
Tree-planner**Gu et al., "Deep Learning for Robotics"** instead proposes constructing the possible action space using LLLs before executing.
Another line of work focuses on leveraging LLLs to construct symbolic world models**Merler et al., "Generating Code World Models"**. 
For example, **Li et al., "AgentGen: Generating Diverse PDDL Domains"** uses LLLs to generate a PDDL domain model and relies on human feedback to correct errors. 
AgentGen**Li et al., "AgentGen: Generating Diverse PDDL Domains"** synthesizes diverse PDDL domains, aiming to create high-quality planning data. 
**Li et al., "FETT: Fine-Tuning LLMs for Predicting Precondition and Effect of Actions"** propose to finetune LLLs for predicting precondition and effect of actions.
% ____ proposes novel evaluation metrics inspired by the Myhill-Nerode theorem to assess the implicit world models within generative models.
% 
Despite the growing interest in this research direction, there is currently a lack of a comprehensive benchmark in this area.