% \begin{table*}
% \centering
% \small
% \begin{tabular}{l|ccccccc}
%     \toprule 
%         \textbf{Model} & \textbf{Exec} & \textbf{Similarity} & \textbf{Distance} & \textbf{Predicate} & \textbf{action\_f1 params} & \textbf{action\_f1 preconds} & \textbf{action\_f1 effect} \\
%     \midrule
%     % Deepseek-V2
%     DeepSeek-V2 & 56.14\% & 93.19\% & 928.34 & 43.20 & 12.87 & 11.64 & 12.42 \\
%     % Deepseek-V3
%     DeepSeek-V3 & 64.33\% & 92.83\% & 1079.14 & 42.99 & 13.78 & 12.07 & 12.59 \\
%     % GPT3.5
%     ChatGPT 3.5 & 55.56\% & 91.98\% & 1257.89 & 37.99 & 10.53 & 9.62 & 9.62 \\
%     % GPT 4
%     ChatGPT 4 & 50.29\% & 93.42\% & 1123.49 & 40.49 & 10.45 & 9.50 & 9.83 \\
%     % GPT 4o
%     ChatGPT 4o & 64.91\% & 93.09\% & 1024.02 & 46.85 & 12.46 & 10.83 & 11.69 \\
%     % GPT 4o-mini
%     ChatGPT 4o-mini & 47.95\% & 94.03\% & 1056.36 & 40.19 & 10.93 & 10.25 & 10.51 \\
%     % OpenAI o1-mini
%     OpenAI o1-mini & 69.59\% & 88.73\% & 1193.15 & 44.77 & 12.61 & 11.24 & 11.83 \\
%     % calude3sonnet
%     Calude3 sonnet & 70.18\% & 89.74\% & 1629.38 & 43.35 & 12.57 & 11.56 & 11.96 \\
%     % mistral-7b
%     Mistral-7B & 5.26\% & 84.17\% & 1639.67 & 3.38 & 1.75 & 1.46 & 1.65 \\
%     % Mixtral-8x22B-Instruct-v0.1
%     Mixtral-8x22B-Instruct-v0.1 & 34.50\% & 93.68\% & 1073.73 & 30.39 & 7.60 & 6.87 & 7.58 \\
%     % Llama-3.1-8B-Instruct
%     Llama-3.1-8B-Instruct & 3.51\% & 85.15\% & 1163.60 & 0.00 & 0.00 & 0.00 & 0.00 \\
%     % Llama-3.1-8B-Instruct-finetuned
%     Llama-3.1-8B-Instruct-finetuned & 60.23\% & 93.01\% & 1104.16 & 44.34 & 12.71 & 10.82 & 10.66 \\
%     % Llama-3.1-70B-Instruct
%     Llama-3.1-70B-Instruct & 14.04\% & 84.39\% & 1267.13 & 2.75 & 0.58 & 0.58 & 0.58 \\
%     % Llama-3.1-70B-Instruct-finetuned
%     Llama-3.1-70B-Instruct-finetuned & 49.71\% & 89.77\% & 1108.97 & 21.81 & 4.15 & 4.10 & 4.02 \\
%     % Llama-3.1-405B-Instruct-Turbo
%     Llama-3.1-405B-Instruct-Turbo & 7.02\% & 92.24\% & 1069.61 & 5.00 & 0.58 & 0.58 & 0.58 \\
%     \bottomrule
% \end{tabular}

% \end{table*}