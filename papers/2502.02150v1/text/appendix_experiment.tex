\section{Experiment Details}
\label{app:exp}

\subsection{Synthetic Dataset Experiment Details}
\label{app:exp_toy}

The training of flow matching models involves sampling $x_0$ from a source distribution of \{Circle,8 Gaussians,Uniform,Gaussian\} and sampling $x_1$ from the target distribution of \{S-Curve,Moons,8 Guassians\}. The model backbone is an MLP of 4 layers with a hidden dimension of 256. The models are trained 1e5 steps. 


To evaluate the asymptotic exactness of $g^{\text{MC}}$, we compute the Wasserstain-2 ($\mathcal{W}_2$) distance of the samples generated under guidance, with the ground truth energy-weighted distribution $p(x_1)e^{-J(x_1)} / Z$. Since the source distribution $p(x_1)$ is learned, the flow matching model itself has a small error $w$, which can also be quantified using the $\mathcal{W}_2$ distance. In principle, this error $w$ characterizes the performance upper bound of the guided distribution: the $\mathcal{W}_2$ distance of the guided distribution will, in principle, not be significantly lower than $w$. The result is shown in Figure \ref{fig:asymptotic}, where $w$ is demonstrated using the dashed line.
\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\linewidth]{image/mc_n.pdf}
    \caption{Error scaling with Monte Carlo sample number. In the synthetic dataset, the guidance performance ($\mathcal{W}_2$ distance between the generated distribution and the ground truth energy weighted distribution $p(x_1)e^{-J(x_1)} / Z$) decreases as the number of Monte Carlo samples increases. The dashed lines denote the $\mathcal{W}_2$ distance between the learned unguided distribution and the original ground truth distribution $p(x_1)$. The reason why the guided generation errors (crosses) do not converge to the dashed lines is that they measure the $\mathcal{W}_2$ distance of $p(x_1)$ and $p(x_1)e^{-J(x_1)} / Z$, respectively.}
    \label{fig:asymptotic}
\end{figure}

\subsection{Planning Experiment Details}
\label{app:exp_rl}
\paragraph{Settings.}
The experiment leverages the D4RL (Datasets for Deep Data-Driven Reinforcement Learning) dataset \citep{d4rl}, specifically the Locomotion datasets, which is a common choice to evaluate offline reinforcement learning methods, as well as offline planning methods \citep{janner_planning_2022,dou_diffusion_2023}. The datasets contain non-expert behaviors from which the model is required to learn the optimal policy, such as a mixture of expert and medium-level experts, or the training replay buffer of an RL agent.


To evaluate the performance of different guidance methods, we conduct experiments on offline RL tasks where generative models have been used as planners \citep{janner_planning_2022,chen_flow_2024}. Our setting is based on that of a classical generative planner called Diffuser \citep{janner_planning_2022}, where a generative model generates a state-action pair sequence of multiple future steps, and another critic model that predicts the future reward\footnote{Formally, it predicts the discounted return-to-go.} of the generated plans. The generative model then optimizes its plans using guidance for higher future rewards. Following the formulation in \citet{levine_reinforcement_2018,janner_planning_2022}, the optimization is realized through sampling from $\frac{1}{Z}p(x_1)e^{R(x_1)}$, where $R$ is the critic model. This aligns with the goal of guidance which we discussed in this paper, so we chose this experiment to evaluate different guidance methods.

\paragraph{Baseline Methods.}
The results of the two baselines are collected from the literature \citep{janner_planning_2022}. 
Behavior cloning refers to using a Gaussian distribution to fit the offline behavior distribution. Diffuser refers to using a diffusion model to learn the offline behavior and then guiding the model to generate plans with higher expected future returns.
Note that the Diffuser also adopts training-based guidance, which requires re-training the guidance model when switching to a new objective function. On the contrary, the training-free guidances $g^{\text{cov-A}}$, $g^{\text{cov-G}}$, $g^{\text{sim-MC}}$, and $g^{\text{MC}}$ has zero-shot generalization ability for \citep{zhou_diffusion_2024} the objective function. In the experiment results, we do not highlight the results of baselines as we focus on the comparison between different guidance methods.

\paragraph{Hyperparameters.}
As we mentioned, a generative model is first trained on the offline dataset as a behavior-cloning method but captures the actual action distribution rather than approximating it with a Gaussian. The generative model we consider here is the CFM or mini-batch optimal transport CFM with affine paths $\alpha_t= t, \beta_t = 1 - t$, and whose backbones are an 8-layer Transformer with a hidden dimension of 256. The models are trained with 1e5 steps, a batch size of 32, a learning rate of 2e-4, and the cosine annealing learning rate scheduler. As for the critic model, it is trained with the same backbone model using the last token as the value output and trained 1e4 steps, batch size of 64, and a learning rate of 2e-4. The value discount factor is set to 0.99 for all 3 datasets. We use a planning horizon of 20 steps and the planning stride 1. We exclude tricks such
as using the inverse dynamics model, planning with stride,
and using sample-and-select methods \citep{What_Making}.
During evaluation, the same base model is utilized for different guidance methods to ensure a fair comparison. We report the normalized score \citep{d4rl} where $100$ is the expert RL agent's return.

For different guidance methods, different hyperparameter combinations are tuned. We elaborate on them here.
\begin{itemize}
    \item $g^{\text{cov-A}}$: We tune $\lambda_t$ in \{constant, cosine decay, exponential decay, linear decay\} with a scaler \{0.01, 0.1, 1.0, 10.0\}, where the schedule functions are normalized to [0, 1].
    \item $g^{\text{cov-G}}$: The same hyperparameters are tuned. 
    \item $g^{\text{MC}}$: We tune the scale of $J$ in \{0.2, 1, 2, 3, 5\}. The Monte Carlo sample number is limited to be smaller than \{128\}. We also include a small number $\epsilon$ to enhance numerical stability. We conduct an ablation study to show the performance is insensitive to $\epsilon$, as shown in Table \ref{tab:app:rl_epsilon}.
    \item $g^{\text{sim-MC}}$: We tune scale before $J$ in \{0.1, 1, 10\} and the assumed standard deviation of $p(x_1|x_t)$ in \{0.1, 0.5, 1, 10\}, and do extra schedule and scale of the estimated guidance with schedule tuned in \{linear decay, constant\} and the scale tuned in \{0.1, 1, 10\}. It is worth noting that if the objective function $J$ is properly normalized, the scale does not require extensive tuning.
    \item $g_\phi$: Training-based methods have many hyperparameters involving model architecture and the training settings. We switch between different model depth and hidden dimensions, and different training losses. The best results for each loss are provided in Table \ref{tab:rl_complete_results_with_std_ot} and \ref{tab:rl_complete_results_with_std_cfm}.
\end{itemize}

\paragraph{Estimation of the ground truth distribution of $J$.}
Suppose the unguided model generates $x\sim p(x)$, and $J(x)$ follows the distribution $p_J(J)$. Then, if $x'\sim \frac{1}{Z}p(x)e^{-J(x)}$, then $J'$ follows 
\begin{equation}
    p'(J) = p'(x)\text{det}\left(\frac{\partial x}{\partial J(x)}\right) = \frac{1}{Z}p(x)e^{-J(x)}\text{det}\left(\frac{\partial x}{\partial J(x)}\right).
\end{equation}
Since for the original distribution 
\begin{equation}
    p(J) = p(x) \text{det}\left(\frac{\partial x}{\partial J(x)}\right),
\end{equation}
so
\begin{equation}
    p'(J) = \frac{1}{Z}e^{-J}p(J).
\end{equation}
Therefore, by sampling from the unguided model and then reweighting the distribution of $J$, we can compute the ground truth distribution $p'(J)$ for the $J$ under ideal guidance. Note that in the planning experiment, $J=-R$.

It should be noted that although gradient-based guidances $g^{\text{cov-A}}$ and $g^{\text{cov-G}}$ result in distributions where the estimated return $R$ is higher, it does not necessarily mean that their performance is better: first, the goal of the guidance is the gray line, what we assume here is that the methods produce a distribution close to the gray line is better; second, practically speaking, the high return is predicted by the critic model, but gradient methods may produce plans that the critic has not seen during training, which is called distribution shift, thus cheating the critic. 
On the contrary, the target guided distribution $p(x_1)e^{R(x_1)} / Z$ regularizes the guided distribution on the support of $p(x_1)$, alleviating the problem of distribution shift.


\paragraph{Additional Results on the Distribution of Generated $R$.}
The additional results of the distribution of $R$ in different environments with different guidance scales (the $\alpha$ in $p'(R)=p(R)e^{-\alpha R} / Z$) are shown in Figure \ref{fig:appendix_rl_complete_distribution_of_R}.
\begin{figure}[!htb]
    \centering
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_halfcheetah-medium-expert-v2_scale_0.001.pdf}
        \captionof{subfigure}{HalfCheetah, scale $0.001$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_walker2d-medium-expert-v2_scale_0.001.pdf}
        \captionof{subfigure}{Walker2d, scale $0.001$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_hopper-medium-expert-v2_scale_0.001.pdf}
        \captionof{subfigure}{Hopper, scale $0.001$.}
    \end{minipage}
    
    \vskip\baselineskip %

    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_halfcheetah-medium-expert-v2_scale_0.01.pdf}
        \captionof{subfigure}{HalfCheetah, scale $0.01$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_walker2d-medium-expert-v2_scale_0.01.pdf}
        \captionof{subfigure}{Walker2d, scale $0.01$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_hopper-medium-expert-v2_scale_0.01.pdf}
        \captionof{subfigure}{Hopper, scale $0.01$.}
    \end{minipage}
    
    \vskip\baselineskip

    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_halfcheetah-medium-expert-v2_scale_0.05.pdf}
        \captionof{subfigure}{HalfCheetah, scale $0.05$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_walker2d-medium-expert-v2_scale_0.05.pdf}
        \captionof{subfigure}{Walker2d, scale $0.05$.}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{image/return_distributions/ablation_generated_return_hopper-medium-expert-v2_scale_0.05.pdf}
        \captionof{subfigure}{Hopper, scale $0.05$.}
    \end{minipage}
    
    \caption{The complete results of the distribution of $R$. The distribution of $J$ under $g^{\text{MC}}$ matches the ground truth value (gray dashed line) very well.}
    \label{fig:appendix_rl_complete_distribution_of_R}
\end{figure}



\paragraph{Additional Results.}
The complete results, including standard deviations, are provided in Table \ref{tab:rl_complete_results_with_std_ot} and \ref{tab:rl_complete_results_with_std_cfm}.

\input{tables/rl_full}


\input{tables/rl_mc_eps}



\subsection{Image Experiment Details}\label{app:exp_image}
We pre-trained a CFM and mini-batch optimal transport CFM model with affine path $\alpha_t=t,\beta_t=1-t$ on CelebA-HQ 256$\times$256 dataset. The flow matching model utilizes the backbone of a U-Net following \citep{pokle_training-free_2024}. The pretraining was conducted with a learning rate of 1e-4 and a batch size of 128 for 500 epochs. The run time was roughly 3 days on two H800 GPUs. For the CelebA dataset, we employed a train-validation-test split of 8:1:1. The test data was subsequently used for three downstream tasks: central box inpainting, superresolution by four times, and Gaussian deblurring which is all common benchmarks.

\textbf{Settings for the experiments.} We evaluated the guidance methods using 3,000 images randomly sampled from the test set across the three inverse problems. Specifically, for deblurring, we apply a 61$\times$61 Gaussian kernel with a standard deviation of $\sigma_b = 1.0$. For super-resolution, we perform 4 $\times$ downsampling on the CelebA images. In the case of box-inpainting, we use a centered 40$\times$40 mask. Furthermore, for all three tasks, we add Gaussian noise after the degradation operation with a standard deviation of $\sigma = 0.05$ to the images.


\textbf{Metrics.} In this paper, we use four commonly adopted metrics for image quality assessment: FID (Fr√©chet Inception Distance), which measures the distance between generated and real image distributions; LPIPS (Learned Perceptual Image Patch Similarity), which evaluates the perceptual similarity between images; and PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural Similarity Index) to quantify image quality in terms of signal preservation and structural consistency, respectively.

\textbf{Why is $g^{\text{MC}}$ bad at image inverse problems?}
As can be seen from Figure  \ref{fig:app_image_visualization_ot} and Figure \ref{fig:app_image_visualization_cfm}, the images generated by $g^{\text{MC}}$ do not respect the reference degraded image. This is largely due to the variance of the MC estimation being too high given the limited number of samples. Specifically, to estimate $g_t$, one needs to obtain samples from regions where $e^{-J}$ is significantly higher than average, which corresponds to the images that already look like the degraded image. Sampling such images requires an infeasibly large number of samples. More advanced MC sampling techniques may help address this shortcoming, such as the control variable method \citep{mcbook}. Combining $g^{\text{MC}}$ and methods that are biased but with lower variance, such as $g^{\text{local}}$ or $g^{\text{sim}}$, may also boost the performance.

However, on tasks such as conditional generation, as long as the condition often appears in the dataset, it will be easier to obtain an accurate estimation of $g_t$ using $g^{\text{MC}}_t$. Such scenarios include property-conditioned molecular structure generation, label-conditioned image generation, and decision-making tasks, which are included in our experiments.


\textbf{Visualizations.}
We provide visualizations of the results of the inverse problems in Figure \ref{fig:app_image_visualization_ot} and \ref{fig:app_image_visualization_cfm}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1.0\linewidth]{image/appendix_image_ot.pdf}
    \caption{The visualization of the image inverse problems with the base flow matching model of mini-batch optimal transport conditional flow matching (OT-CFM). Three rows show the results of Gaussian deblurring, box-inpainting, and super-resolution from top to bottom.}
    \label{fig:app_image_visualization_ot}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1.0\linewidth]{image/appendix_image_cfm.pdf}
    \caption{The visualization of the image inverse problems with the base flow matching model of conditional flow matching (CFM). Three rows show the results of Gaussian deblurring, box-inpainting, and super-resolution from top to bottom.}
    \label{fig:app_image_visualization_cfm}
\end{figure}

