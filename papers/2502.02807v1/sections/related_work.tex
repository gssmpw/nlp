\section{Related Work}
\label{sec:related}
%Motivational Interviewing (MI) is a client-centered counseling approach for eliciting behavior change by helping clients explore and resolve ambivalence~\citep{miller2012motivational,diclemente2002motivational,miller2002motivational,martins2009review}. 
Developing LLM-based agents to support mental health counseling is an emerging research topic. \citet{steenstra2024virtual} developed LLM-based agents for addressing the alcohol use behavior only. The counselor agent in DIIR~\citep{xie2024few} uses high-quality counseling sessions in the AnnoMI dataset~\citep{wu2022anno,wu2023creation} to learn a set of strategies in the form of natural language inductive rules. During counseling, DIIR uses the current session context to retrieve the best-matching strategy which prompts LLM to generate the next response. 
%Some works develop counselor agents using proprietary datasets to learn models for strategy prediction and generate the counselors' responses based on the predicted strategies. For example, 
\citet{sun2024chain} proposed Chain-of-Strategy (CoS), a prompting method, to align counselor response generation with MI strategies. CARE~\citep{hsu2023helping} determines the specific counseling strategy most suitable for a given context and provides example responses for peer counselors. However, the above works focus on modeling MI strategies only and %While strategy application is crucial for effective MI sessions, focusing %on essential counseling skills and adherence to MI principles, 
overlook the need to model the client's state and to evoke change talk based on topic(s) that could match the client's underlying motivation.  We thus propose to perform client's state inference and topic exploration on a topic tree specially constructed for MI counseling. %To the best of our knowledge, our work is the first attempt to consider topic exploration in eliciting change talk.

To compare the performance of counseling agents, the above works rely on evaluation approaches that compare the generated responses against the predefined ``ground truth'' responses.  One such approach computes word overlap or semantic similarity between the generated and ground truth responses.  Another approach requires human judgement comparing the generated responses with the ground truth ones at the turn-level when the counseling agent is given all previous turns following the ground truth session. 
As these approaches assume a single ``ground truth'' counseling session, they somewhat restrict the possibility of multiple high quality sessions thereby rating a competent counselor agent poorly only because it generates good responses very different from the ``ground truth.'' Unlike previous research, we utilize simulated clients representing a diverse range of behavioral issues to engage in motivational interviewing sessions with counselor agents. Using these simulated interactions, we conduct both automated and human evaluations to assess the performance of CAMI and other counselor agents.
%\jjcomment{Human evaluation doesn't assume a ground truth session, right?} they are not natural and may 

%Our evaluation approach follows the recent works~\citep{yosef2024assessing,chiu2024computational,wang2024towards} which involve a client agent interacting with the counselor agent so as to evaluate the counselor agent's performance very much like how a human counselor is evaluated.  Evaluation criteria such as MI competency can then be assessed on the counseling session between the client agent and counselor agent.  However, the client simulators used in these prior works are quite simple. This affects the reliability of the evaluation results.  In this work, we propose to simulate client agents that mimic the human clients closely. To achieve this, we design a more realistic client agent with state tracking, dynamic engagement, and other modules.
%\jjcomment{Maybe either list out all the modules or remove ``other modules'' (which are vague) and state something like ``we design a more realistic client agent featuring state tracking and dynamic engagement.''}

%{\color{red}
%However, strategy annotations in AnnoMI are coarse-grained and simple~\citep{sun2024chain}, making it challenging to generalize to other strategies. \jjcomment{I am a bit confused here. If the strategies are coarse-grained, aren't they supposed to be easier than fine-grained strategies to generalize elsewhere?} To address this, some works have attempted to annotate more detailed and extensive strategies in non-public datasets, e.g., 7 Cups~\citep{shah2022modeling} and BiMISC~\citep{sun2024eliciting}. 
%}
