\section{Related Work}
\subsection{KANs}
After the recent introduction of \acp{kan} by Liu et al. **Liu, "A Novel Approach to Kernel Adaptive Neural Networks"** there has been a great variety of attempts to apply the ideas of \acp{kan} to different fields like image processing **Meng, "Kernel Adaptive Neural Networks for Image Denoising"** ____ and even transformers ____. Hou et al. **Hou, "Survey on Applications of Kernel Adaptive Neural Networks"** give a great overview of the different applications and extensions of \acp{kan}. Their explainability can be of great value in fields where machine learning approaches are strongly regulated like survival analysis in medicine or engineering ____. Multiple works have already benchmarked the performance of \acp{kan} against \acp{mlp} ____ and found \acp{kan} to be a more suitable alternative in some fields. Alter et al. **Alter, "Robustness Analysis of Large-Scale Kernel Adaptive Neural Networks"** found that large-scale \acp{kan} are more robust against adversarial attacks as \acp{mlp} and thus form an interesting direction for further research in multiple fields.


In **Chen, "Partial Differential Equation Forms Based on Kernel Adaptive Neural Networks"** the authors explore different partial differential equation forms based on \ac{kan} instead of \ac{mlp} for solving forward and inverse problems in computational physics. A systematical comparison demonstrates that the \ac{kan} approach significantly outperforms \ac{mlp} regarding accuracy and convergence 
speed. Further successful applications of \ac{kan} can be found for operator learning in computational mechanics ____ and image classification ____.


\subsection{Complex-Valued Neural Networks}
After early introduction of \acp{cvnn} ____ they have lately risen in popularity since the introduction of building blocks for deep learning architectures ____. Since then a lot of theoretical contributions have been made ____ to enable a multitude of applications ____.

The most closely related prior work in the complex domain are deep \acp{crbfn} ____. However, in \acp{crbfn}, the \acp{rbf} are applied to all inputs of a neuron (e.g. vertex of the computational graph) simultaneously, while in \acp{ckan} the \acp{rbf} are applied on the edges of the computational graph to each value individually. Thus \acp{crbfn} are architecturally more similar to classical \acp{mlp} with \acp{rbf} as activations functions, where we aim to adopt the \ac{kan} framework to the complex domain.