\section{Related Works}
Recent advances in neural embedding models have evolved from early distributed word representations such as word2vec ____ to contextual approaches like BERT ____. Subsequent methods, including SentenceBERT ____ and SimCSE ____, further enhanced semantic representation, while multilingual frameworks like InfoXLM ____ extend these benefits to low-resource languages.

Despite these improvements, general-purpose models often fall short in domain-specific applications. For instance, in finance and biomedicine, tailored models such as FinBERT ____ and BioBERT ____ capture specialized terminology and nuances that generic embeddings may overlook. Recent financial NLP studies even report that models like SentenceBERT and Ada embeddings tend to overestimate similarity in reports with minor surface variations ____, highlighting the necessity for domain-specific benchmarks like FinMTEB ____ that can provide more accurate evaluations in specialized contexts.