
\begin{figure*}[htbp]
    \centering
        \centering
        \includegraphics[width=0.69\linewidth]{figures/split_comparisons.pdf}
        \caption{A comparison between the performance of our algorithms and their contemporaries. The lower plots are zoomed-in versions of the upper plots, but with the $x$-axis now being the runtime. SPLIT and LicketySPLIT consistently lie on the bottom left of the test loss-sparsity frontier, with runtimes orders of magnitude faster than many contemporaries. Our algorithms also offer the ideal compromise between runtime and loss. All metrics are averaged over $3$ test-train splits.}
        \label{fig:split_comparisons}

    \label{fig:comparisons}
\end{figure*}

Our experiments provide an evaluation of decision trees, considering aspects of performance, interpretability, and training budget. To this end, our evaluation addresses the following questions:
\begin{enumerate}
    \item How fast are SPLIT and LicketySPLIT compared to unmodified GOSDT?
    \item Are SPLIT and LicketySPLIT able to produce trees that lie on the frontier of sparsity, test loss performance, and training time?
    \item How good is the Rashomon set approximation produced by RESPLIT?
\end{enumerate}
For all experiments below we set the depth budget of our algorithms to $5$. The lookahead depth for Algorithm \ref{alg::lookahead} is set to $2$ since, from Corollary \ref{corollary:depth-runtime}, this produces the lowest runtime for the chosen depth budget. We defer more details of our experimental setup and datasets to Appendix \ref{sec:setup}. Appendix \ref{sec:appendix_evaluation} has additional evaluations of our methods. 
\subsection{How do our algorithms compare to GOSDT?}
Our first experiments support the claim that our method is significantly faster than GOSDT whilst achieving similar regularized test losses. This is shown in Figure \ref{fig:gosdt_vs_lookahead}. Here, we vary the sparsity penalty, $\lambda$, which is a common input to all algorithms in this figure, and compute the regularized test objective from Equation \ref{eqn:obj} for each value of $\lambda$. We set a timeout limit of $1200$ seconds for GOSDT, after which it gives the best solution found so far. We note two regimes:
\begin{itemize}
\item When all methods have lower regularized objective values (left side of each plot), \textbf{our methods are orders of magnitude faster than GOSDT.} For instance, on the Bike dataset, SPLIT has training times of $\sim$10 seconds, while GOSDT runs for $\sim$$10^3$ seconds. LicketySPLIT takes merely a second in most cases. This is the regime most relevant to our algorithms. 

\item When the optimal objective is high and the tree is super-sparse (right side of each plot), SPLIT and Lickety-SPLIT have small overhead costs and can be slower, because we need to train a greedy tree for each subproblem encountered at the lookahead depth in order to initialize bounds via Algorithm \ref{alg::bounds}. However, in this regime, all methods already have runtimes of $\sim$1 second, so the extra overhead cost is insignificant. This is especially seen in the COMPAS and Netherlands datasets. 
\end{itemize}


\subsection{Characterising the Frontier of Test Loss, Sparsity, and Runtime}
Figure \ref{fig:comparisons} characterises the frontier of training time, sparsity, and test loss for several algorithms. Here, we vary hyper-parameters associated with each algorithm to produce trees of varying sparsity levels (where sparsity is the number of leaves). We see that there exists a frontier between test loss and sparsity, and different methods lie on different parts of the frontier. To maximize interpretability and accuracy, we want a tree to lie in the bottom left corner of the frontier, within the highlighted red rectangle. Out of all algorithms tested, ours consistently lie on the frontier and in the red rectangle. Alongside state of the art performance, our algorithms are often \textbf{over 100$\times$ faster} than their contemporaries. For more datasets, see Figure \ref{fig:comparisons_2} in the Appendix. 

\subsection{Rashomon Set Approximation}
We now show that RESPLIT enables fast, accurate approximation of the Rashomon set of near-optimal trees, while scaling much more favorably than state-of-the-art method TreeFARMS \cite{xin2022treefarms}. We demonstrate that variable importance conclusions using RID \cite{donnelly2023the} remain almost identical under RESPLIT, relative to the full Rashomon set. That is, RESPLIT allows accurate summary statistics of the full Rashomon set to be computed at greater depths and over more binary features while enhancing scalability. Table \ref{tab:results} shows computation of RID with and without RESPLIT. RESPLIT enables $10-20\times$ faster variable importance computation. Furthermore, the correlation between variable importances is very close to $1$, suggesting that RESPLIT trees serve as good proxies for estimating importances derived from the complete Rashomon set. Table \ref{tab:recovery_rate} also shows that most of the trees output by RESPLIT lie in the true Rashomon set or very close to it.  


\begin{table}[h]
\centering
\begin{tabular}{c|c|c|c}
{\textbf{Dataset}} & \textbf{Full}\textbf{ (s)} & \textbf{RESPLIT} \textbf{(s)} & $\tau$ \\
\hline
COMPAS & 152 & \textbf{18}  & 1.0 \\
Spambase & 2659 & \textbf{154} & 0.930 \\
Netherlands & 4255 & \textbf{216} & 0.932 \\ 
HELOC & 5564 & \textbf{337} & 0.979 \\
HIV & 9273  & \textbf{388} & 0.959 \\
Bike & 14330 & \textbf{194} & 0.999 \\
\end{tabular}
\caption{Table summarizing the advantages of RESPLIT. The first $2$ columns show the time taken to compute all bootstrapped Rashomon sets for the Rashomon Importance Distribution (RID) \cite{donnelly2023the} with and without RESPLIT. $\#$ of bootstrapped datasets $= 10$, $\lambda = 0.02$, $\epsilon = 0.01$, depth budget $5$, lookahead depth $3$. The last column shows the Pearson correlation between variable importances computed by RID and RID + RESPLIT. There is nearly perfect correlation seen in every case.}
\label{tab:results}
\end{table}

\begin{table}[H]
\centering
\resizebox{0.48\textwidth}{!}{%
\begin{tabular}{c|c|c}
\textbf{Dataset} & \textbf{Precision} & \textbf{Precision (Slack $\mathbf{.01}$)} \\
\hline
Bike        & 0.974 (370/380) & 1.000 \\
COMPAS      & 1.000 (27/27) & 1.000 \\
HELOC       & 0.974 (528/542) & 1.000 \\
HIV         & 0.528 (243/460) & 0.984 \\
Netherlands & 0.911 (102/112) & 1.000 \\
Spambase    & 0.597 (850/1422) & 0.933 \\
\end{tabular}
}
\caption{Proportion of RESPLIT Trees in the true Rashomon set (precision) and within at most $.01$ loss of being in the set. Most of the trees output by RESPLIT end up being in the Rashomon set. Trees which are not in the Rashomon set are almost always very close to being in it. We employ the same parameters as Table \ref{tab:results}.}
\label{tab:recovery_rate}
\end{table}
