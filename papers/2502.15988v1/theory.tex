
We present theoretical results establishing the performance and scalability of our algorithms. All proofs, including additional lemmas not described below, are in Appendix Section \ref{sec:proofs}.
Even without the speedups discussed in Section \ref{subsec:recursive}, Algorithm \ref{alg::lookahead} is quite scalable. Theorem \ref{thm:runtime-lookahead} shows the asymptotic analysis of the algorithm, with and without caching. Note that the default behaviour of Algorithm \ref{alg::lookahead} is to cache repeated sub-problems. 

\begin{restatable}[Runtime Complexity of SPLIT]{theorem}{runtimelookahead}
\label{thm:runtime-lookahead}
    For a dataset $D$ with $k$ features and $n$ samples, depth constraint $d$ such that $d \ll k$, and lookahead depth $0 \leq d_l < d$, Algorithm \ref{alg::lookahead} has runtime $\mathcal{O}\big(n(d-d_l)k^{d_l+1}+ nk^{d-d_l}\big)$. If we cache repeated subproblems, the runtime reduces to $\mathcal{O}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!} + \frac{nk^{d - d_l}}{(d-d_l)!}\Big)$. 
\end{restatable}

This algorithm is linear in sample size and, because $d_l < d$ and $d - d_l < d$, is exponentially faster than a globally optimal approach, which searches through $\mathcal{O}((2k)^d)$ subproblems in the worst case. 

Corollaries \ref{corollary:depth-runtime} and \ref{corollary:savings} show that, compared to globally optimal approaches, we see substantial improvements in runtime when lookahead depth is around half the global search depth.

\begin{restatable}[Optimal Lookahead Depth for Minimal Runtime]{corollary}{optimaldepth}
\label{corollary:depth-runtime}
The optimal lookahead depth that minimizes the asymptotic runtime of Algorithm \ref{alg::lookahead} is $d_l = \frac{(d-1)}{2}$ for large $k$, regardless of whether subproblems are cached. 
\end{restatable}

\begin{restatable}[Runtime Savings of SPLIT Relative to Globally Optimal Approaches]{corollary}{runtimesavings}
\label{corollary:savings}
Asymptotically, under the same conditions as Theorem \ref{thm:runtime-lookahead} and with caching repeated subproblems, Algorithm \ref{alg::lookahead} saves a factor of $\mathcal{O}\Big(k^{\frac{d-1}{2}}\Big(\frac{d}{2}\Big)!\Big)$ in runtime relative to globally optimal approaches (e.g., GOSDT).
\end{restatable}

Theorem \ref{thm:runtime-greedy} describes the runtime complexity of our LicketySPLIT method from Section \ref{subsec:recursive}, showing that it can be even faster than Algorithm \ref{alg::lookahead} (indeed, achieving low-order polynomial runtime). 

\begin{restatable}[Runtime Complexity of LicketySPLIT]{theorem}{runtimegreedylookahead}
\label{thm:runtime-greedy}
    For a dataset $D$ with $k$ features and $n$ samples, and for depth constraint $d$, Algorithm \ref{alg::recursive_lookahead} has runtime $O(nk^2d^2)$.
\end{restatable}

We can thus use Algorithm \ref{alg::recursive_lookahead} to leverage a recursive search while remaining comfortably polynomial. This is a dramatic improvement to asymptotic scalability relative to globally optimal decision tree construction methods, which solve an NP-hard problem. 

\begin{restatable}[SPLIT Can be Arbitrarily Better than Greedy]{theorem}{arbitrarilybetter}
    \label{thm::arbitrarily_better}
    For every $\epsilon > 0$ and depth budget $d$, there exists a data distribution $\mathcal{D}$ and sample size $n$ for which, with high probability over a random sample $S \sim \mathcal{D}^n$, Algorithm \ref{alg::lookahead} with $d_l = \frac{d-1}{2}$ achieves accuracy at least $1-\epsilon$ but a pure greedy approach achieves accuracy at most $\frac{1}{2} + \epsilon$.
\end{restatable}

Theorem \ref{thm::arbitrarily_better} shows that Algorithm \ref{alg::lookahead} can arbitrarily outperform greedy methods in accuracy, even when we choose its minimum runtime configuration of $d_l = \frac{d-1}{2}$. We prove a similar claims for LicketySPLIT and RESPLIT in the appendix (see Theorems \ref{thm::arbitrarily_better_recursive} and \ref{thm::arbitrarily_better_treefarms}). 
