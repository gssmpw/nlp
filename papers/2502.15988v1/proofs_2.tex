\begin{theorem}
\label{thm:relwork}
    Consider $T$, a tree output by LicketySPLIT, and $T^{\prime}$, a tree output by a method which is constrained to only make an information-gain-maximizing split at each node (or not to split at all). Then, considering the training set objective from Equation \ref{eqn:obj} for training set $D$ and given depth constraint $d$, we have:  $L(T, D, \lambda) \leq L(T', D, \lambda)$.
\end{theorem}
\begin{proof}
    The proof will proceed by induction.

\textbf{Base Case}:

When there is insufficient remaining depth to split, or no split improves the objective, then $T^\prime$ and $T$ both return a leaf with equivalent performance.

\textbf{Inductive Step:}

$T$ considers the split that $T^\prime$ would make (a greedy split), and evaluates the resulting performance of a greedy tree after that split. It also considers all other splits, and evaluates the performance of a greedy tree after that split. It either picks the split that $T^\prime$ would make, or it picks one that will correspond to a tree better than $T^\prime$, assuming that the objective after the first split is at least as good as a greedy tree past that first split (which, by the inductive hypothesis, we know is true).

Thus, by induction LicketySPLIT will do at least as well as $T^\prime$.

We can, of course, extend this to SPLIT fairly trivially, since SPLIT is more rigorous than LicketySPLIT. The splits up to the lookahead depth are optimal assuming the continuation past the lookahead depth is at least as good as a greedy method (so SPLIT will either start with greedy splits up to the lookahead, matching $T^\prime$, or it will find some better prefix with respect to the training objective). The post-processing further improves the performance of SPLIT relative to $T^\prime$.
\end{proof}

\subsubsection{Proof of Theorem \ref{thm:runtime-lookahead}}

\runtimelookahead*
\begin{proof}

We divide the computation process into two stages:
\begin{itemize}
    \item \textbf{Stage $1$} involves computing the lookahead tree prefix. There are $k$ choices to split on at each level, yielding $2k$ nodes at the next level and hence $(2k)^{d_l}$ nodes (sub-problems) at level $d_l$. For each of the $(2k)^{d_l}$ sub-problems at depth $d_l$, we will compute a greedy subtree of depth $d-d_l$.  
    Let $S_i$ be the $i^{th}$ sub-problem at depth $d_l$ (with corresponding size $|S_i|$). 
    The runtime of a greedy decision tree algorithm with depth $d_g$ for a sub-problem of size $n$ and $k$ features is $\mathcal{O}(nkd_g)$ (where $d_g = d - d_l$ in our algorithm). The runtime complexity for this phase is therefore: 
    \begin{equation}
        \mathcal{O}\Big(\sum_{i=1}^{(2k)^{d_l}} |S_i|(k-d_l)(d-d_l)\Big) = \mathcal{O} \left((k-d_l)(d-d_l) \sum_{i=1}^{(2k)^{dl}} |S_i|\right)
    \end{equation}
    where we have $(k-d_l)$ features remaining to be split on at the end of lookahead. Now,
    \begin{equation}
        \sum_{i=1}^{(2k)^{d_l}} |S_i| = \mathcal{O}\Big(nk^{d_l}\Big),
    \end{equation}
   because at each level, we split on $\mathcal{O}(k)$ features and route $n$ examples down each path. Thus, the runtime for this stage simplifies to:
   \begin{align}
       \mathcal{O}\Big(\sum_{i=1}^{(2k)^{d_l}} |S_i|(k-d_l)(d-d_l)\Big) &= \mathcal{O}\big(nk^{d_l}(k-d_l)(d-d_l)\big) \\
       &= \mathcal{O}\big(n(d-d_l)k^{d_l+1}\big)
   \end{align}
    where the second equality stems from the fact that $k-d_l = O(k)$, because $d \ll k$ and $d_l < d$. \textit{However}, there is redundancy here, because this expression assumes that all sub-problems at level $d_l$ are unique - this is not the case. Consider a subproblem identified by the sequence of splits $f_1 = 0 \rightarrow f_2 = 1 \rightarrow  f_3 = 0$. The exact order of the splits does not matter in identifying the subproblem. This implies that multiple sequences of splits correspond to the same subproblem, leading to an overestimation of the runtime. At level $d_l$, there are therefore $d_l!$ redundant subproblems (corresponding to the different ways of arranging the sequence of splits). We only need to solve, i.e. compute a greedy tree, for one of them and store the solution for the other identical subproblems. If we cache subproblems in this manner, the final runtime for this stage becomes:
    \begin{equation}
        \mathcal{O}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!}\Big)
    \end{equation}
    \item $\textbf{Stage $2$}$ involves replacing the leaves of the learned prefix tree with an optimal tree of depth $d - d_l$ so that the resulting tree has depth $\leq d$. Let $u$ be a leaf node in this prefix tree and $n_u$ be its corresponding sub-problem size. As before, we will search over all trees of size $d-d_l$, which requires evaluation of $(2k)^{d-d_l}$ nodes in the search tree. This time, however, the evaluation at the last node will be linear in the sub-problem size (as we are not considering any splits beyond depth $d$). By the same argument as Stage $1$, the runtime of this phase is therefore $\mathcal{O}\big(k^{d-d_l}n_u\big)$. Summing this across all subproblems $u$, we get $\sum_{u} \mathcal{O}\big(k^{d-d_l}n_u\big)$. As the total sum of sub-problem sizes across all leaves is equal to the original dataset size, this sum is equal to $\mathcal{O}\big(k^{d-d_l}n\big)$. By the same subproblem redundancy argument as in Stage $1$, the final runtime complexity of this stage upon caching redundant subproblems becomes:
    \begin{equation}
        \mathcal{O}\Big(\frac{nk^{d-d_l}}{(d-d_l)!}\Big)
    \end{equation}
\end{itemize}
Combining Stages $1$ and $2$, we get that the total runtime of SPLIT is: 
\begin{align}
    \begin{cases}
        \mathcal{O}\big(n(d-d_l)k^{d_l+1}+ nk^{d-d_l}\big) & \textrm{Without Caching}\\ 
        \textcolor{white}{hi} & \textcolor{white}{hi} \\
         \mathcal{O}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!} + \frac{nk^{d - d_l}}{(d-d_l)!}\Big) & \textrm{With Caching.}
    \end{cases}
\end{align}

\end{proof}

\subsubsection{Proof of Corollary \ref{corollary:depth-runtime}}
\optimaldepth*
\begin{proof}
We evaluate the optimal lookahead depth in both scenarios, caching and no-caching.
\textcolor{white}{hi}
\section*{Case 1: Lookahead Without Caching}
In this case, the runtime expression is $\mathcal{O}\Big(n(d-d_l)k^{d_l+1} + nk^{d - d_l}\Big)$. We divide the proof into $6$ parts: 
\paragraph{Part 1: Finding the stationary point of the runtime}\leavevmode\leavevmode\\\\
Consider the runtime expression from Theorem \ref{thm:runtime-lookahead}. We now minimize this  with respect to $d_l$: 
\begin{align}
    \frac{\partial}{\partial d_l} &\Big(n(d-d_l)k^{d_l+1} + nk^{d - d_l}\Big) = 0 \\
    \iff \frac{\partial}{\partial d_l} &\Big((d-d_l)k^{d_l+1} + k^{d - d_l}\Big) = 0 \\
    \iff \frac{\partial}{\partial d_l} &\Big(dk^{d_l+1} - d_l k^{d_l+1} + k^{d - d_l}\Big) = 0 \\
    \iff&d (\log k) k^{d_l + 1} - (k^{d_l + 1} + d_l (\log k) k^{d_l + 1}) - (\log k) k^{d-d_l} = 0 \\ 
    \iff&\big((d-d_l)\log k - 1\big) k^{d_l+1} - (\log k) k^{d-d_l} = 0 \\ 
    \label{eqn:optimal_dl} &\implies \Big( (d-d_l) - \frac{1}{\log k}\Big)k^{2d_l + 1} = k^d.  
\end{align}
We can now simplify this equation to analytically express the lookahead depth $d_l$ as a function of $k$. To do so, we define a new variable $u$ such that:
\begin{align}
\label{eqn:d_l_u}
    d_l = \frac{u - 2+2d\log k}{2\log k}.
\end{align}
Under this definition of $d_l$, we can now rewrite Equation \ref{eqn:optimal_dl} in terms of $u$:
\begin{align}
    &\left(\left(d-\frac{u - 2+2d\log k}{2\log k}\right) - \frac{1}{\log k}\right)e^{\log k{\left(2\left(\frac{u - 2+2d\log k}{2\log k}\right) + 1\right)}} = k^d \\
    &\Big(d - \frac{u + 2d \log k}{2 \log k}\Big)e^{u-2+2d\log k + \log k} = k^d\\ 
    & \Rightarrow \frac{-u}{2\log k}e^{-2}k^{2d+1} e^u = k^d\\
    \label{eqn:lambert_u} & ue^u = -2e^2k^{-(d+1)}\log k. 
\end{align}
As the solution to this equation is known to be analytically intractable, we express $u$ in terms of the Lambert $W$ function, which is a well known function that cannot be expressed in terms of elementary functions. Denoted by $W(z)$, this function satisfies the following equation:
\begin{equation}
    \label{eqn:lambert}
    W(z)e^{W(z)} = z.
\end{equation}
From Equation \ref{eqn:lambert_u}, we can express $u$ in terms of $W(.)$, giving us:
\begin{equation}
    u = W(-2e^2k^{-(d+1)}\log k).
\end{equation}
Substituting this back into the expression for $d_l$ in Equation \ref{eqn:d_l_u}, we get:
\begin{equation}
    \label{eqn:d_l_in_lambert_form}
    d_l = \frac{W(-2e^2k^{-(d+1)}\log k) - 2+2d\log k}{2\log k}.
\end{equation}
\paragraph{Part 2: Bounding the Lambert $W$ function}\leavevmode\leavevmode\\\\
Let $z = -2e^2k^{-(d+1)}\log k$. For sufficiently large $k$, $z \in [-\frac{1}{e}, 0]$. In this domain, there are two possible values of $W(z)$, $W_0(z)$ and $W_{-1}(z)$, such that $W_0(z) \geq W_{-1}(z)$. Figure \ref{fig:lambert_w_function} shows these two branches of the $W$ function.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{figures/lambert_w_function.png}
    \caption{The Lambert W function, which has two branches in the real plane, $W_0(z)$ and $W_{-1}(z)$. Figure from \cite{lambert}.}
    \label{fig:lambert_w_function}
\end{figure}
For now, consider the function $W_{-1}(z)$. We will show later that choosing this branch of the $W$ function results in the value of $d_l$ that minimizes the runtime.\\  \cite{lambert_bound} show the following lower bound for $W_{-1}(z)$: 
\begin{align}
    W_{-1}(z) \geq \log\left(-z\right)-\sqrt{2\left(-1-\log\left(-z\right)\right)}.
\end{align}
\cite{lambert} show the following upper bound for $W_{-1}(z)$: 
\begin{align}
    W_{-1}(z) \leq \log\left(-z\right)-\log\left( -\log\left(-z\right)\right).
\end{align}
Denote the lower bound as $W_{-1}^{lb}(z)$ and the upper bound as $W_{-1}^{ub}(z)$. We can now write upper and lower bounds for the optimal $d_l$ (call this $d_l^*$) in Equation \ref{eqn:d_l_in_lambert_form}.
\begin{align}
\label{eqn:bounds_dl}
    \frac{W_{-1}^{lb}(z) - 2+2d\log k}{2\log k} \leq d^*_l \leq \frac{W_{-1}^{ub}(z) - 2+2d\log k}{2\log k}
\end{align}
where $z = -2e^2k^{-(d+1)}\log k$ from above.
\paragraph{Part 3: Lower Bound for $d^*_l$}\leavevmode\leavevmode\\\\
We now evaluate the lower bound for $d_l^*$, substituting $z=-2e^2k^{-(d+1)}\log k$ into the left side of Equation \ref{eqn:bounds_dl}:
\begin{align}
d^*_l &\geq \frac{W_{-1}^{lb}(z) - 2+2d\log k}{2\log k} \\
    &= \frac{W_{-1}^{lb}\left(-2e^2k^{-\left(d+1\right)}\log k\right) - 2+2d\log k}{2\log k} \\
    &= \frac{\log\left(2e^2k^{-\left(d+1\right)}\log k\right)-\sqrt{2\left(-1-\log\left(2e^2k^{-\left(d+1\right)}\log k\right)\right)}-2+2d\log k}{2\log k}\\
    &= \frac{\log 2 -(d+1)\log k + \log \log k + 2d\log k - \sqrt{-6-2\log 2 + 2(d+1)\log k - 2\log \log k}}{2\log k}.
\end{align}
Consider the term: 
\begin{equation}
\sqrt{-6-2\log 2+2(d+1)\log k - 2\log \log k}.
\end{equation}
As $k$ becomes large, we can ignore the constants. Asymptotically, $\log k \gg \log \log k$, and hence this term approaches $\sqrt{2(d+1)\log k}$. Thus, we can write:
\begin{align}
    d^*_l &\geq \frac{\log 2 -(d+1)\log k + \log \log k + 2d\log k - \sqrt{2(d+1) \log k}}{2\log k}\\
    &= d-\frac{d+1}{2} + \frac{\log 2}{2\log k} + \frac{\log\log k}{\log k} - \frac{\sqrt{2(d+1)\log k}}{\log k}\\
    &= \frac{d-1}{2} - \mathcal{O}\Big(\frac{1}{\sqrt{\log k}}\Big)
\end{align}
as $d$ is a constant and $k \gg d$.
\paragraph{Part 4: Upper Bound for $d^*_l$}\leavevmode\leavevmode\\\\
We can similarly evaluate the upper bound for $d_l^*$: 
\begin{align}
    d^*_l &\leq \frac{W_{-1}^{ub}(-2e^2k^{-\left(d+1\right)}\log k) - 2+2d\log k}{2\log k}\\
    &= \frac{\log\left(2e^2k^{-\left(d+1\right)}\log k\right) - \log\Big(-\log\left(-2e^2k^{-\left(d+1\right)}\log k\right)\Big) - 2 + 2d\log k}{2\log k}\\
    \label{eqn:upper_bound_dl_final}
    &= \frac{\log 2 - (d+1)\log k + \log \log k - \log\Big(-\big(\log 2 + 2 - \left(d+1\right)\log k + \log \log k\big)\Big) + 2d \log k}{2\log k}.
\end{align}
Consider the term: 
\begin{equation}
    \log\Big(-\big(\log 2 + 2 - \left(d+1\right)\log k + \log \log k\big)\Big).
\end{equation}
As $k$ becomes large, we can ignore the constants. 
We can also consider the asymptotic lower bound of the subsequent expression:
\begin{equation}
    \log\Big(\left(d+1\right)\log k - \log \log k\Big) \geq 1 - \frac{1}{\left(d+1\right)\log k - \log \log k}
\end{equation}
If we plug in this lower bound in Equation \ref{eqn:upper_bound_dl_final}, the resulting expression is still a valid upper bound. 
\begin{align}
    d_l^* &\leq \frac{\log 2 -(d+1)\log k + \log \log k -1 + \frac{1}{\left(d+1\right)\log k - \log \log k} + 2d\log k}{2\log k}\\
    &=d - \frac{d+1}{2} + \frac{\log 2 - 1}{2\log k} + \frac{\log \log k}{2 \log k} + \frac{1}{2(d+1)\log^2 k - 2\log k \log \log k}\\
    &= \frac{d-1}{2} + \mathcal{O}\Big(\frac{\log \log k}{\log k}\Big).
\end{align}
\paragraph{Part 5: Putting it all together}\leavevmode\leavevmode\\\\
Finally, we get the following lower and upper bounds on the optimal lookahead depth $d_l^*$: 
\begin{equation}
    \frac{d-1}{2} - \mathcal{O}\Big(\frac{1}{\sqrt{\log k}}\Big) \leq d_l^* \leq \frac{d-1}{2} + \mathcal{O}\Big(\frac{\log \log k}{\log k}\Big).
\end{equation}
For large $k$, these bounds will converge, and hence, in this limit, $d_l^* = \frac{d-1}{2}$.
\paragraph{Part 6: Verifying that $d_l^* = \frac{d-1}{2}$ is the minimum}\leavevmode\leavevmode\\\\
We show that the computed value of $d_l^*$ is indeed the minimum by evaluating the second derivative of the runtime, i.e. $\frac{\partial^2}{\partial d_l^2}\Big(n(d-d_l)k^{d_l+1} + nk^{d - d_l}\Big)|_{d_l = d_l^*}$. 
\begin{align}
    &\frac{\partial^2}{\partial d_l^2}\Big(n(d-d_l)k^{d_l+1} + nk^{d - d_l}\Big) = \frac{\partial}{\partial d_l}\Big(n\big((d-d_l)\log k - 1\big) k^{d_l+1} - n(\log k) k^{d-d_l}\Big)
\end{align}
where we use the the derivative expression from Part $1$ of this proof. Simplifying further:
\begin{align}
    &\frac{\partial}{\partial d_l}\Big(n\big((d-d_l)\log k - 1\big) k^{d_l+1} - n(\log k) k^{d-d_l}\Big) \\
    &= \frac{\partial}{\partial d_l}\Big(n d k^{d_l+1}\log k-nd_lk^{d_l+1}\log k -nk^{d_l+1}-nk^{d-d_l}\log k\Big)\\
    &= ndk^{d_l+1}\log^2 k - nk^{d_l+1}\log k - nd_lk^{d_l+1} \log^2 k -nk^{d_1+1} \log k + nk^{d-d_l} \log^2 k.
\end{align}
We now substitute $d_l = \frac{d-1}{2}$ and simplify the result:
\begin{align}
    &\frac{\partial^2}{\partial d_l^2}\Big(n(d-d_l)k^{d_l+1} + nk^{d - d_l}\Big)\eval_{d_l = d_l^*} \\
    &= ndk^{\frac{d+1}{2}}\log^2 k - nk^{\frac{d+1}{2}}\log k - n\Big(\frac{d-1}{2}\Big)k^{\frac{d+1}{2}} \log^2 k -nk^{\frac{d+1}{2}} \log k + nk^{\frac{d+1}{2}} \log^2 k\\
    &= n\Big(\frac{d+1}{2}\Big) k^{\frac{d+1}{2}}\log^2 k + nk^{\frac{d+1}{2}} \log^2 k - 2nk^{\frac{d+1}{2}}\log k \\
    &= n\Big(\frac{d+3}{2}\Big) k^{\frac{d+1}{2}}\log^2 k - 2nk^{\frac{d+1}{2}}\log k .
\end{align}
This is clearly $> 0$ as the $\log^2 k$ terms dominate $\log k$. Thus, the value $d_l^* = \frac{d-1}{2}$ corresponds to the minimum of the runtime. 
\section*{Case 2: Lookahead with Caching}
In this case, the runtime expression is $\mathcal{O}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!} + \frac{nk^{d - d_l}}{(d-d_l)!}\Big)$. We divide the proof into $3$ parts:
\paragraph{Part 1: Finding the stationary point of the runtime}\leavevmode\leavevmode\\\\
We can replace the factorial in the runtime expression with the Gamma function, i.e.:
\begin{equation}
    d_l! = \Gamma(d_l+1) = \int_0^\infty t^{d_l} e^{-t} \, dt
\end{equation} 
as this allows us to apply the derivative operator. Further employing the definition of the Digamma function $\psi(x) = \frac{\Gamma^\prime(x)}{\Gamma(x)}$, we now minimize the runtime with respect to $d_l$:
\begin{align}
    &\frac{\partial}{\partial d_l} \Big(\frac{n(d-d_l)k^{d_l+1}}{\Gamma(d_l+1)} + \frac{nk^{d-d_l}}{\Gamma(d-d_l+1)}\Big) = 0\\
    \Rightarrow &n \frac{\partial}{\partial d_l} \Big(\frac{(d-d_l)k^{d_l+1}}{\Gamma(d_l+1)}\Big) + n \frac{\partial}{\partial d_l} \Big(\frac{k^{d-d_l}}{\Gamma(d-d_l+1)}\Big) = 0\\
    \Rightarrow &n \Bigg[\frac{\partial}{\partial d_l} \Big((d-d_l)k^{d_l+1}\Big) \cdot \frac{1}{\Gamma(d_l+1)} - \frac{(d-d_l)k^{d_l+1}}{\Gamma(d_l+1)^2} \cdot \frac{\partial}{\partial d_l} \Gamma(d_l+1)\Bigg] \ \ + \\
    &n \Bigg[\frac{\partial}{\partial d_l} \Big(k^{d-d_l}\Big) \cdot \frac{1}{\Gamma(d-d_l+1)} - \frac{k^{d-d_l}}{\Gamma(d-d_l+1)^2} \cdot \frac{\partial}{\partial d_l} \Gamma(d-d_l+1)\Bigg] = 0\\
    \Rightarrow &n \Bigg[-k^{d_l+1} + (d-d_l)k^{d_l+1}\log k\Bigg] \cdot \frac{1}{\Gamma(d_l+1)} - n \frac{(d-d_l)k^{d_l+1}}{\Gamma(d_l+1)^2} \cdot \Gamma(d_l+1)\psi(d_l+1) \ \ + \\
    &n \Bigg[-k^{d-d_l}\log k\Bigg] \cdot \frac{1}{\Gamma(d-d_l+1)} - n \frac{k^{d-d_l}}{\Gamma(d-d_l+1)^2} \cdot \Gamma(d-d_l+1)\psi(d-d_l+1) = 0\\
    \Rightarrow &\frac{(-k^{d_l+1} + (d-d_l)k^{d_l+1}\log k)\Gamma(d_l+1) - (d-d_l)k^{d_l+1}\Gamma(d_l+1)\psi(d_l+1)}{\Gamma(d_l+1)^2} \ \ + \\
    &\frac{k^{d-d_l}\big(\Gamma(d-d_l+1)\psi(d-d_l+1) - (\log k)\Gamma(d-d_l+1)\big)}{\Gamma(d-d_l+1)^2} = 0
\end{align}
Simplifying this expression, we get:
\begin{align}
 \Rightarrow &\frac{(-k^{d_l+1}+(d-d_l)k^{d_l+1}\log k) - (d-d_l)k^{d_l+1}\psi(d_l+1)}{\Gamma(d_l+1)} + \frac{k^{d-d_l}\big(\psi(d-d_l+1)-\log k\big)}{\Gamma(d-d_l+1)} = 0\\
&\Rightarrow\frac{k^{d_l+1}\Big(-1+\left(d-d_l\right)\left(\log k - \psi\left(d_l+1\right)\right)\Big)}{\Gamma(d_l+1)} =  \frac{k^{d-d_l}\Big(\log k-\psi(d-d_l+1)\Big)}{\Gamma(d-d_l+1)}\\
&\Rightarrow \frac{k^{2d_l-d+1}\Big(-1+\left(d-d_l\right)\left(\log k - \psi\left(d_l+1\right)\right)\Big)}{\Gamma(d_l+1)} =  \frac{\log k-\psi(d-d_l+1)}{\Gamma(d-d_l+1)}\\
&\Rightarrow k^{2d_l-d+1} =  \frac{\Big(\log k-\psi(d-d_l+1)\Big)\Gamma(d_l+1)}{\Gamma(d-d_l+1)\Big(-1+\left(d-d_l\right)\left(\log k - \psi\left(d_l+1\right)\right)\Big)}.
\end{align}
\paragraph{Part 2: Bounding the Optimal Lookahead Depth}\leavevmode\leavevmode\\\\
Unlike the previous case, it is not possible to derive a closed functional form for the optimal lookahead depth for any given value of $k$ (although we can simulate it numerically). Instead, we need to analyze how this expression behaves as in the limit as $k \rightarrow \infty$. Because $k \gg d, d_l$, $\log k \gg \psi(d-d_l+1)$. Similarly, $\log k \gg \psi(d_l+1)$. Furthermore, we can ignore all expressions which are not functions of $k$ as they are insignificant when $k$ is large. Thus, in this limit: 
\begin{align}
    &k^{2d_l-d+1} \rightarrow \frac{\Gamma(d_l+1) \log k}{\Gamma(d-d_l+1)(d-d_l)\log k} \\
    &\Rightarrow k^{2d_l-d+1} = \frac{\Gamma(d_l+1)}{\Gamma(d-d_l+1)(d-d_l)} \\
    &\Rightarrow (2d_l-d+1)\log k = \log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l)\\
    &\Rightarrow 2d_l-d+1 = \frac{\log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l)}{\log k}.
\end{align}

Observe the term $\log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l)$. 
We can write the factorial form of this expression to understand it better:
\begin{equation}
    \log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l) = \log\Big(\frac{d_l!}{(d-d_l)!(d-d_l)}\Big).
\end{equation}
Notice that for any $d_l$ between $0$ and $\lfloor\frac{d}{2}\rfloor$ (inclusive), the RHS is always less than $0$. Similarly, for $\lfloor\frac{d}{2}\rfloor < d_l \leq d - 1 $, the term is always greater than $0$. Given that these are constant as $k$ increases: 
\begin{align}
    \log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l) =
    \begin{cases}
        -\mathcal{O}(1) & \textrm{$0 \leq d_l \leq \lfloor\frac{d}{2}\rfloor$}\\
        \mathcal{O}(1) & \textrm{$\lfloor\frac{d}{2}\rfloor < d_l \leq d - 1$}.
    \end{cases}
\end{align}
This implies: 
\begin{equation}
     -\mathcal{O}\Big(\frac{1}{\log k}\Big) \leq \frac{\log\Gamma(d_l+1) - \log\Gamma(d-d_l+1) - \log(d-d_l)}{\log k} \leq \mathcal{O}\Big(\frac{1}{\log k}\Big)
\end{equation}
for all $0 \leq d_l \leq d-1$ (which are the constraints in our setup). Hence, we conclude that, for large $k$:
\begin{align}
    &\mathcal{O}\Big(\frac{1}{\log k}\Big) \leq 2d_l - d + 1 \leq -\mathcal{O}\Big(\frac{1}{\log k}\Big)\\
    &\Rightarrow \frac{d-1}{2} - \mathcal{O}\Big(\frac{1}{\log k}\Big) \leq d_l \leq \frac{d-1}{2} + \mathcal{O}\Big(\frac{1}{\log k}\Big)
\end{align}
which approaches $d_l = \frac{d-1}{2}$ as $k \rightarrow \infty$. Henceforth, we denote this asymptotically optimal value as $d_l^*$.
\paragraph{Part 3: Verifying that $d_l^* = \frac{d-1}{2}$ is the minimum for large $k$}\leavevmode\leavevmode\\\\
We show that the computed value of $d_l^*$ is indeed the minimum for large $k$ by evaluating the second derivative of the runtime, i.e. $\frac{\partial^2}{\partial d_l^2}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!} + \frac{nk^{d - d_l}}{(d-d_l)!}\Big)\eval_{d_l = d_l^*}$. 
\begin{align}
    &\frac{\partial^2}{\partial d_l^2}\Big(\frac{n(d-d_l)k^{d_l+1}}{d_l!} + \frac{nk^{d - d_l}}{(d-d_l)!}\Big) \\
    &= n\frac{\partial}{\partial d_l}\Big(\frac{(-k^{d_l+1}+(d-d_l)k^{d_l+1}\log k)\Gamma(d_l+1) - (d-d_l)k^{d_l+1}\Gamma(d_l+1)\psi(d_l+1)}{\Gamma(d_l+1)^2} \ \ +\\& \ \ \ \frac{k^{d-d_l}\big(\Gamma(d-d_l+1)\psi(d-d_l+1)-(\log k)\Gamma(d-d_l+1)\big)}{\Gamma(d-d_l+1)^2}\Big).
\end{align}
We can remove the dataset size $n$ for simplicity as it doesn't affect the sign of the answer. In the limit as $k \rightarrow \infty$, we can simplify this expression and only evaluate terms that grow with $k$: 
\begin{align}
    &\frac{\partial}{\partial d_l} \Bigg(\frac{\log k (d-d_l) k^{d_l+1} \Gamma(d_l+1)}{\Gamma(d_l+1)^2} - \frac{k^{d-d_l} \log k \Gamma(d-d_l+1)}{\Gamma(d-d_l+1)^2}\Bigg)\\
    &= \Bigg[\frac{\partial}{\partial d_l} \Big(\log k (d-d_l) k^{d_l+1}\Big) \cdot \frac{\Gamma(d_l+1)}{\Gamma(d_l+1)^2} - \frac{\log k (d-d_l) k^{d_l+1}}{\Gamma(d_l+1)^2} \cdot \frac{\partial}{\partial d_l} \Gamma(d_l+1)\Bigg] \ \ - \\
    &\quad \Bigg[\frac{\partial}{\partial d_l} \Big(k^{d-d_l} \log k\Big) \cdot \frac{\Gamma(d-d_l+1)}{\Gamma(d-d_l+1)^2} - \frac{k^{d-d_l} \log k}{\Gamma(d-d_l+1)^2} \cdot \frac{\partial}{\partial d_l} \Gamma(d-d_l+1)\Bigg]\\
    &= \Bigg[\Big(-\log k k^{d_l+1} + (d-d_l)k^{d_l+1} (\log k)^2 \Big) \cdot \frac{1}{\Gamma(d_l+1)} - \frac{\log k (d-d_l) k^{d_l+1}}{\Gamma(d_l+1)^2} \cdot \Gamma(d_l+1)\psi(d_l+1)\Bigg] \ \ - \\
    &\quad \Bigg[\Big(-k^{d-d_l} (\log k)^2\Big) \cdot \frac{1}{\Gamma(d-d_l+1)} - \frac{k^{d-d_l} \log k}{\Gamma(d-d_l+1)^2} \cdot \Gamma(d-d_l+1)\psi(d-d_l+1)\Bigg]\\
    &= \Bigg[\frac{\Big(-\log k k^{d_l+1} + (d-d_l) k^{d_l+1} (\log k)^2\Big)}{\Gamma(d_l+1)} - \frac{\log k (d-d_l) k^{d_l+1} \psi(d_l+1)}{\Gamma(d_l+1)}\Bigg] \ \ - \\
    &\quad \Bigg[\frac{-k^{d-d_l} (\log k)^2}{\Gamma(d-d_l+1)} - \frac{k^{d-d_l} \log k \psi(d-d_l+1)}{\Gamma(d-d_l+1)}\Bigg]\\
    &= \Bigg[\frac{\Big(-k^{d_l+1} (\log k)  + (d-d_l) k^{d_l+1} (\log k)^2 - \log k (d-d_l) k^{d_l+1} \psi(d_l+1)\Big)}{\Gamma(d_l+1)}\Bigg] \ \ - \\
    &\quad \Bigg[\frac{-k^{d-d_l} (\log k)^2 + k^{d-d_l} \log k \psi(d-d_l+1)}{\Gamma(d-d_l+1)}\Bigg].
\end{align}
Note that the $(\log k)^2$ terms are dominant in this expression as k $\rightarrow \infty$. Hence, at $d_l^* = \frac{d-1}{2}$, the terms that will affect the sign of the expression are: 
\begin{align}
    k^{\frac{d+1}{2}}\Big(\frac{d+1}{2}\Big)(\log k)^2 - k^{\frac{d+1}{2}}(\log k)^2 + \mathcal{O}(\textrm{$\log k$}).
\end{align}
This is clearly positive for any $d > 1$, hence the value $d_l^* = \frac{d-1}{2}$ corresponds to the minimum of the runtime. Note that in practice, if $d_l^*$ is not an integer, we can choose whichever of $\lceil d_l^*\rceil$ or $\lfloor d_l^* \rfloor$ gives us a lower runtime. 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\linewidth]{figures/runtime_lookahead_caching.pdf}
    \includegraphics[width=0.45\linewidth]{figures/optimal_lookahead_depth_analysis.pdf}
    \caption{(left) The asymptotic runtime expression as a function of the lookahead depth for $k=20$, $d = 5$, and $n=1000$. This also lines up nicely with what we observe in practice, e.g. in Figure \ref{fig:lookahead_depth_runtime}. (right) Exact value for the theoretically optimal lookahead depth as a function of the number of features (with their associated lower and upper bounds). T}
    \label{fig:runtime_vs_lookahead_depth_theory} 
\end{figure}
From Figure \ref{fig:runtime_vs_lookahead_depth_theory}, we see that for a depth budget of $5$, the minimum lookahead depth $d_l^*$ is slightly less than $2$ for both the caching and non-caching case, which is what is predicted by Corollary \ref{corollary:depth-runtime}. This also lines up nicely with what we observe in practice (e.g. in Figure \ref{fig:lookahead_depth_runtime}). Note that our algorithms, which build on the GOSDT codebase, cache subproblems by default.
\end{proof}
\subsubsection{Proof of Corollary \ref{corollary:savings}}
\runtimesavings*
\begin{proof}
    Any branch and bound algorithm for constructing a fully optimal tree will, in the worst case, involve searching through $(2k)^d$ sub-problems at depth $d$ (where we can ignore all sub-problems at shallower depths, because their cost is exponentially lower). By the same arguments as in Theorem \ref{thm:runtime-lookahead}, the runtime of brute force search without any caching is $\mathcal{O}(nk^d)$. Thus, the ratio of runtimes of brute force and Algorithm \ref{alg::lookahead} is $\mathcal{O}\Big(\frac{k^d}{\frac{(d-d_l)k^{d_l+1}}{d_l!} + \frac{k^{d - d_l}}{(d-d_l)!}}\Big)$. From Theorem \ref{thm:runtime-lookahead}, we set $d_l = \frac{d-1}{2}$, as it minimizes the denominator of the above expression and hence gives the maximal runtime savings. Thus, the ratio of runtimes is:
    \begin{align}
        &\mathcal{O}\Big(\frac{k^d}{\frac{(d-d_l)k^{d_l+1}}{d_l!} + \frac{k^{d - d_l}}{(d-d_l)!}}\Big) \\
        &= \mathcal{O}\Big(\frac{k^d\big(\frac{d+1}{2}\big)!}{\frac{d+1}{2}k^{\frac{d+1}{2}} + k^{\frac{d+1}{2}}}\Big) \\
        &= \mathcal{O}\Big(\frac{k^d\big(\frac{d+1}{2}\big)!}{\frac{d+3}{2}k^{\frac{d+1}{2}}}\Big)\\
        &= \mathcal{O}\Big(k^{\frac{d-1}{2}}\Big(\frac{d}{2}\Big)!\Big).
    \end{align}
\end{proof}

\subsubsection{Proof of Theorem \ref{thm:runtime-greedy}}
\runtimegreedylookahead*
\begin{proof}
\textbf{Sketch}: 
Running lookahead for a single step involves $k$ different potential splits, and a full run of a standard greedy algorithm for each sub-problem. Since a greedy algorithm's runtime for a sub-problem of size $n_s$ is $\mathcal{O}(n_skd)$, and each split creates two sub-problems whose sub-problem sizes sum to $n$, we know that each split leads to $\mathcal{O}(nkd)$ runtime, and we have $k$ such splits to evaluate, leading to $\mathcal{O}(nk^2d)$ runtime for the first iteration. \\
In the recursive step, we call lookahead on two sub-problems whose sizes sum to $n$, and each of which has a similar runtime analysis. \\
We run at most $d$ layers of recursion. \\
From this, we have a total runtime bound of $\mathcal{O}(nk^2d^2)$, since we have $d$ levels which each take $\mathcal{O}(nk^2d)$ time. 
\\
\textbf{Proof via recurrence relation: }

For dataset $D$ and remaining depth $d$, and defining $i^*$ as the split selected by LicketySPLIT at the current iteration, 
we have the runtime recurrence relation: 
    $$T(D, d) = \begin{cases}
        T(D(i^*), d-1) + T(D(\bar{i^*}), d-1) + \sum_{i=1}^k \Big(\mathcal{O}(|D|) + \mathcal{O}(|D(i)|kd) + \mathcal{O}(|D(\bar{i})|kd)\Big)  \ \ , & d > 1\\
        |D| & d=1,
    \end{cases}$$
because at each level and each feature, LicketySPLIT needs to compute the split ($\mathcal{O}(|D|)$ time), then run greedy on the left and right subproblems, taking $\mathcal{O}(|D(i)|kd)$ and $\mathcal{O}(|D(\bar{i})|kd)$ time, respectively. Then it needs to recurse on the optimal of those splits. 

Noting that $|D(\bar{i})| + |D({i})| = |D|$, this simplifies to: 
    $$T(D, d) = \begin{cases}
        T(D(i^*), d-1) + T(D(\bar{i^*}), d-1) + \sum_{i=1}^k \Big(\mathcal{O}(|D|) + \mathcal{O}(|D|kd)\Big) \ \ , & d > 1\\
        \mathcal{O}(|D|) & d=1.
    \end{cases}$$

Given this recurrence, we can show $T(D, d) \in \mathcal{O}(nk^2d^2)$ inductively. 

First, define $c_A, n_A$ be values such that the runtime of each $\mathcal{O}(|D|)$ steps in the recurrence above is below $c_A * |D|$ for $k > k_A, |D| > n_A$ (we know such values exist because of the definition of $\mathcal{O}$). Then define $c_B, n_B, d_B, k_B$ be values such that the runtime of each $\mathcal{O}(|D|kd)$ step in the recurrence above is below $c_B * |D|kd$ for $k > k_B, |D| > n_B, d > 1$ (we know such values exist because of the definition of $\mathcal{O}$).
Now set: 
\begin{align*}
    c = \max(c_A, c_B, 1)\\
    n_0 = \max(n_A, n_B, 1)\\
    k_0 = \max(k_B, 1)\\
    d_0 = 1
\end{align*}
So that, for any $k \geq k_0, |D|=n \geq n_0, d \geq d_0$ , we can bound all the $\mathcal{O}(|D|)$ steps as taking less than $c|D|$ time, and all the $\mathcal{O}(|D|kd)$ steps as taking less than $c|D|kd$ time. 

$$T(D, d) \leq \begin{cases}
        T(D(i^*), d-1) + T(D(\bar{i^*}), d-1) + \sum_{i=1}^k \Big(c|D| + c|D|kd \Big) \ \ , & d > 1\\
        c|D| & d=1.
    \end{cases}$$

We now want to show that  for any $k \geq k_0, |D|=n \geq n_0, d \geq d_0$ , we can bound the runtime of the recurrence $T$ as $\leq cnk^2d^2$, where $n = |D|$. 

We show this by induction: 

\textit{Base Case ($d=1$)}: 

Trivially, $T(D, 1) \leq c|D| \leq c |D|k^2d^2$ for any $k \geq k_0, |D|=n \geq n_0$. Note that $k^2d^2 \geq 1$ because each of $k$ and $d$ are at least 1. 

\textit{Inductive Step ($d \geq 2$)}: 

Now, inductively: 
\begin{align}
    &T(D, d) \leq T(D(i^*), d-1) + T(D(\bar{i^*}), d-1) + \sum_{i=1}^k\Big(c|D| + c|D|kd\Big) \\ 
    &T(D, d) = T(D(i^*), d-1) + T(D(\bar{i^*}), d-1) + c|D|k + c|D|k^2d \\ 
&\leq ck^2(d-1)^2(|D(i*)| + c|D(\bar{i*})|) + c|D|k + c|D|k^2d \\ 
&\leq ck^2(d-1)^2(|D|) + c|D|k + c|D|k^2d \\ 
& < c|D|k^2((d-1)^2 + 1 + d )\\ 
& = c|D|k^2(d^2-d+2)\\ 
& \leq c|D|k^2d^2 \textrm{, noting that $d \geq 2$.}
\end{align}
Thus as $|D| = n$, we have the runtime in $\mathcal{O}(nk^2d^2)$.

\end{proof}
\subsubsection{Additional Claims, with Proofs}
We here prove some additional results about how our trees compare to optimal ones. 

\begin{theorem}[Optimality certificate based on lookahead depth]
Algorithm \ref{alg::lookahead} will return a tree with objective no worse than a globally optimal tree with maximum depth $d_\textrm{lookahead}$. 
\end{theorem}
\begin{proof}
    Note that Algorithm \ref{alg::lookahead} considers all possible tree structures up to depth $d_\textrm{lookahead}$, with greedy completions of those structures. Those greedy completions are no worse than leaves with respect to our objective - they only expand beyond a leaf if the regularized objective is better than leaving the tree node as a leaf. So for any tree $t$ of depth at or below $d_\textrm{lookahead}$, there exists an analogous tree in the search space of Algorithm \ref{alg::lookahead}, with objective no worse than that of $t$. 

    Now, note that Algorithm \ref{alg::lookahead} globally optimizes over its search space. So the tree returned by Algorithm \ref{alg::lookahead} has objective no worse than any other element in the algorithm's search space.

    We now have that the tree returned by Algorithm \ref{alg::lookahead} has objective no worse than a globally optimal tree with maximum depth $d_\textrm{lookahead}$. For any globally optimal tree $t^*$ of that depth, we know there exists an analogous tree $t'$ in the search space of Algorithn \ref{alg::lookahead}, with objective no worse than that of $t^*$. And we know that the tree returned by the algorithm is no worse than tree $t'$, and thereby no worse than $t^*$. 

    (Note that postprocessing does not change the above, since it only ever improves the objective of the reported solution).
\end{proof}

\begin{theorem}[Conditions for heuristic optimality]\label{thm:opt}
If any true globally optimal tree uses greedy splits after depth $d_l$, then SPLIT will return a globally optimal tree.
\end{theorem}

\begin{proof}
    We prove Theorem \ref{thm:opt} as follows:
    
    Our algorithm globally optimizes over the set of all trees that use greedy splits after depth $d_{l}$. Thus, if at least one such tree in that set is also in the set of globally optimal trees, we know we will find that tree or another equivalently good tree according to our objective. (Note that postprocessing does not change the above, since it only ever improves the objective of the reported solution). 
\end{proof}

\subsubsection{Proof of Theorem \ref{thm::arbitrarily_better}}
\arbitrarilybetter*
\begin{proof}
    Our proof follows a similar construction as \cite{topk}. They define the function Tribes as follows: 
    \begin{definition}[Tribes: from \cite{topk}]
        For any input length $k$, let $w$ be the largest integer such that $(1 - 2^{-w})^{\ell/w} \leq \frac{1}{2}$. For $\bx \in \{0, 1\}^\ell$, let $\bx^{(1)}$ be the first $w$ coordinates, $\bx^{(2)}$ the second $w$, and so on. \textrm{\rm Tribes}$_\ell$ is defined as:
        \begin{equation}
            \textrm{Tribes}_\ell(\bx) = \left(\bx_1^{(1)}\land ....\land \bx_w^{(1)}\right) \lor .... \lor \left(\bx_1^{(t)}\land ....\land \bx_w^{(t)}\right)
        \end{equation}
        \end{definition}
    where $t = \Big\lfloor \frac{\ell}{w}\Big\rfloor$. \cite{blanc2019top} prove the following properties of Tribes: 
    \begin{itemize}
        \item Tribes$_\ell$ is monotone. 
        \item \textrm{Tribes}$_\ell$ is nearly balanced:\[
        \mathbb{E}_{\bx \sim \{0,1\}^\ell} [\textrm{Tribes}_\ell(\bx)] = \frac{1}{2} \pm o(1)\]
        where the $o(1)$ term goes to 0 as $\ell$ goes to $\infty$.
        \item All variables in \textrm{Tribes}$_\ell$ have small correlation: For each $i \in [\ell]$,
        \[
        \text{Cov}_{\bx \sim \{0,1\}^\ell} [\bx_i, \textrm{Tribes}_\ell(\bx)] = O\left( \frac{\log \ell}{\ell} \right).
        \]
    \end{itemize}
    Further define the majority function as follows: 
    \begin{definition}[Majority]
        The majority function indicated by $\text{Maj} : \{0, 1\}^\ell \to \{0, 1\}$, returns
        \[
        \text{Maj}(x) := \mathbf{1}[\text{at least half of } x\text{'s coordinates are } 1].
        \]
    \end{definition}
    Let the number of features $k = d_l + u - 1$ for lookahead depth $d_l$ and constant $u$. Define the following data distribution over $\{0,1\}^k \times \{0,1\}$:
\begin{itemize}
    \item Sample $\bx \sim \textrm{Uniform}\big(\{0,1\}^k\big)$.
    \item Let $\bx(d_l)$ be the first $d_l$ elements in $\bx$ and $x(\bar{d_l})$ be the remaining elements. Compute: 
    \begin{align}
    \label{eqn:formulation_tribes_majority}
        y = f(\bx) = 
        \begin{cases} 
            \textrm{Tribes}_{d_l}(\bx(d_l)) & \text{with probability } 1-\epsilon, \\
            \textrm{Majority}(\bx_{\bar{d_l}}) & \text{with probability } \epsilon.
        \end{cases}
    \end{align}
\end{itemize}
\paragraph{How does lookahead fare on this data distribution?}\leavevmode\leavevmode\\\\
Consider our lookahead heuristic. If we exhaustively search over all possible features up to depth $d_l$, we are guaranteed to perfectly classify $\textrm{Tribes}_{d_l}(\bx(d_l))$, as it is computed from $d_l$ features. In this scenario, the lookahead prefix tree will be a full binary tree, with $2^{d_l}$ leaves corresponding to every outcome of Tribes. When we extend this tree up to depth $d$ (with or without postprocessing), Algorithm \ref{alg::lookahead} is still guaranteed to achieve at least $1-\epsilon$ accuracy.
\paragraph{How does greedy fare on this data distribution?}\leavevmode\leavevmode\\\\
We now apply Lemma $4.4$ from \cite{topk} in this context, adjusting the notation to suit our case. Let $T$ be the tree of depth $d$ returned by greedy. Consider any root-to-leaf path of $T$ that does not query any of the first $d_l$ features of $\bx$ (i.e. the Tribes block). Only features from the Majority block are therefore queried by $T$ along this path. We can therefore write the probability of error along this path: 
\begin{align*}
    \Pr_{(\bx,y)\sim \mathcal{D}} & [T(\bx) = y \mid \bx \text{ follows this path}]\\
    &= (1 - \epsilon) \Pr_{(\bx,y)\sim \mathcal{D}} [T(\bx) = \text{Tribes}_{d_l}(\bx(d_l)) \mid \bx \text{ follows this path}] \\
    &\quad + \epsilon \cdot \Pr_{(\bx,y)\sim \mathcal{D}} [T(\bx) = \text{Majority}(\bx(\bar{d_l})) \mid \bx \text{ follows this path}] \\
    &\leq (1 - \epsilon) \cdot \left( \frac{1}{2} + o(1) \right) + \epsilon \cdot 1 \\
    &\leq \frac{1 + \epsilon}{2} + o(1)
\end{align*}
where the last line follows, because \textit{Tribes} is nearly balanced. As the distribution over x
is uniform, each leaf is equally likely. \cite{topk} then show that, if only $p$-fraction of root-to-leaf paths of $T$ query at least one of the first $d_l$ coordinates, then: 
\begin{align}
    \Pr_{(\bx,y)\sim \mathcal{D}}[T(\bx) = y &\leq (1-p)\Big(\frac{1 + \epsilon}{2} + o(1)\Big) + p\cdot 1]\\
    &\leq \frac{1}{2} + \frac{\epsilon}{2} + \frac{p}{2} + o(1).
\end{align}
We now want to show that, just like in the case of \cite{topk}, $p$ is small asymptotically. If this is the case, we can claim that a greedy tree is arbitrarily bad. The only difference between \cite{topk} and us is that their greedy tree has depth $d_l$ (adjusting for notation), but we want to construct a tree of depth $d$. \\
\\
We now use Lemma $7.4$ from \cite{blanc2019top}, which proves the following (again, adjusting for our notation): 
A random root-to-leaf path of a greedy tree $T$ satisfies the following with probability at least $1-\mathcal{O}(u^{-2})$: \textit{If the length of this path is less than $\mathcal{O}(u \log u)$, at any point along that path, all coordinates within the majority block that have not already been queried have correlation at least $\frac{1}{100\sqrt{u}}$.}
Now, for a greedy tree of depth $d$: 
\begin{itemize}
    \item We need to set $u \geq \Omega(d\log d)$ so that all root-to-leaf paths have length at most $\mathcal{O}(u \log u)$, so the above lemma applies. 
    \item Remember that the size of our Tribes block is still fixed as the lookahead depth $d_l$, according to Equation \ref{eqn:formulation_tribes_majority}. From the definition of tribes, all variables in this block will have correlation $\mathcal{O}\Big(\frac{\log d_l}{d_l}\Big)$. Because we want the correlations in the majority block to be greater than those in Tribes, we need to set $\frac{1}{100\sqrt{u}} \geq \mathcal{O}\Big(\frac{\log d_l}{d_l}\Big)$, implying that $u \leq \mathcal{O}(d_l^2\log^2d_l)$. 
\end{itemize}
Thus, it follows that $p = \mathcal{O}(u^{-2})$ if the conditions above are satisfied. If we set $d_l =\frac{d-1}{2} =\mathcal{O}(d)$, we can say that, for any $\Omega(d\log d) \leq u \leq \mathcal{O}\Big(\frac{d^2}{\log^2}\Big)$, a greedy tree of depth $d$ will yield accuracy $\leq \frac{1}{2} + \epsilon$, as it almost never selects any variable from the Tribes block.
\end{proof}

\begin{restatable}[All Trees in RESPLIT Can be Arbitrarily Better Than Greedy]{theorem}{arbitrarilybettertreefarms}
    \label{thm::arbitrarily_better_treefarms}
    For every $\epsilon, \epsilon^\prime > 0$, depth budget $d$, and lookahead depth $d_l$, Rashomon set size $R$, there exists a data distribution $\mathcal{D}$ and sample size $n$ for which, with high probability over a random sample $S \sim \mathcal{D}^n$, all $R$ trees output by Algorithm \ref{alg::resplit} with minimum runtime lookahead depth $d_l = \frac{d-1}{2}$ achieve accuracy at least $1-\epsilon - \epsilon^\prime + \mathcal{O}(\epsilon\epsilon^\prime)$ but a pure greedy approach achieves accuracy at most $\frac{1}{2} + \epsilon$.
\end{restatable}
\begin{proof}
We divide the proof as follows:
\paragraph{Part 1: Defining the feature space}\leavevmode\\\\
    Let the number of features $k = R + 2d$ for depth budget $d$ and a constant $R$ that is the size of the Rashomon set we want to generate. We now create a dataset of size $n$ with $k$ features in the following manner:
    \begin{itemize}
        \item Loop over $n$ iterations: 
        \begin{itemize}
            \item Sample $X_1\ldots X_{2d}$ uniformly from $\{0,1\}^{2d}$.
            \item For each $2d < j \leq 2d+R$:
            \begin{itemize}
                \item Choose a random index $idx(j) \sim \textrm{Uniform}\{1,d_l\}$
                \item Define feature $X_j$ in the following manner: 
                \begin{align}
                \label{eqn:x_j}
                    X_j = \begin{cases}
                        X_{idx(j)} & \textrm{With probability $1-\epsilon^\prime$}\\
                        \bar{X}_{idx(j)} & \textrm{otherwise.}
                    \end{cases}
                \end{align}
            \end{itemize}
        \end{itemize}
    \end{itemize}
    Define the reference block of features to be $X_1,\ldots, X_d$. We break this block into $2$ sub-blocks.
    \begin{itemize}
        \item Sub-block $1$ corresponds to the $d_l$ features for which we will compute a parity bit. At a high level, a tree needs to know the parity of the expression in order to 'unlock' a high accuracy. This also serves to 'trick' greedy into not choosing these features, because they will have $0$ correlation with the label. Let $X_{1}\ldots X_{d_l}$ be the features in this sub-block.
        \item Sub-block $2$ corresponds to the set of $d-d_l$ features over which we will take a majority vote. We will only reach this block when the parity bit is $1$. Let $X_{d_l+1}\ldots X_{d}$ be the features in this sub-block.
    \end{itemize}
\paragraph{Part 2: Defining the labels}\leavevmode\\\\
For each example in this dataset, define the label $y$ as:
\begin{align}
\label{eqn:label_rset_parity}
y = \begin{cases}
    (X_1 \oplus \ldots\oplus X_{d_l}) \land \textrm{Majority}(X_{d_l+1} \ldots X_{d} ) & \textrm{with probability $1 - \epsilon$}\\
    \textrm{Majority}(X_{d+1} \ldots X_{2d})  & \textrm{with probability $\epsilon$.}
\end{cases} 
\end{align}
Intuitively, the label is the majority vote of the second block only when parity of the first block is even - otherwise the label is the minority vote.
\paragraph{Part 3: Bounding the Error of the Rashomon Set}\leavevmode\\\\
We can immediately see that the best tree will achieve an error $\geq 1-\epsilon$. The Rashomon set in this case will contain $R-1$ trees (besides the empirical risk minimizer). In particular, each tree $T$ in the Rashomon set will split on one unique feature $X_j \ \forall 2d < j \leq 2d+R$, making a prediction on an instance $\bX = (X_1,...X_k)$ of the following form: 
\begin{align}
T(\bX) = (X_1 \oplus \ldots X_{j} \ldots \oplus X_{d_l}) \land \textrm{Majority}(X_{d_l+1} \ldots X_{d} )
\end{align}
where tree $T$ employs feature $X_j$ in its path (defined in Equation \ref{eqn:x_j}. Whenever $X_j \neq X_{idx(j)}$ the parity of the first block will be different from that corresponding to Equation \ref{eqn:label_rset_parity}. However, this only happens with probability $\epsilon^\prime$. For the $1-\epsilon^\prime$ proportion of cases, the error will be that of the best tree (i.e. at least $1-\epsilon$), giving tree T an expected accuracy of least $(1-\epsilon)(1-\epsilon^\prime) = 1-\epsilon - \epsilon^\prime + \mathcal{O}(\epsilon\epsilon^\prime)$.
\paragraph{Bounding the Performance of a Greedy Tree}\leavevmode\\\\
A greedy tree will seek to split on the feature that has the highest correlation with the label $y$. From the definition of $y$ in Equation \ref{eqn:label_rset_parity}, it follows that $X_{d+1},\ldots, X_{2d}$ are the only variables that will have non $0$ correlation with the label outcome. Thus, the tree will fully split only on these features up to depth $d$. However, this means that the tree does not learn the underlying parity function $(X_1 \oplus \ldots\oplus X_{d_l})$. Thus, $1-\epsilon$ proportion of the time, the tree will achieve $\frac{1}{2}$ accuracy. Thus, the total accuracy is less than $\frac{1}{2}(1-\epsilon) + \epsilon = \frac{1}{2} + \epsilon$. 
\end{proof}

\begin{restatable}[LicketySPLIT Can be Arbitrarily Better than Greedy]{theorem}{arbitrarilybetterrecursive}
    \label{thm::arbitrarily_better_recursive}
    For every $\epsilon > 0$ and depth budget $d$, there exists a data distribution $\mathcal{D}$ and sample size $n$ for which, with high probability over a random sample $S \sim \mathcal{D}^n$, Algorithm \ref{alg::recursive_lookahead} achieves accuracy at least $1-\epsilon$ but a pure greedy approach achieves accuracy at most $\frac{1}{2} + \epsilon$.
\end{restatable}

\begin{proof}

Let 
$x \sim \textrm{Uniform}\big(\{0,1\}^{2d}\big)$ and
$$y = \begin{cases}
    x_1 \oplus \textrm{Majority}(x_2, \ldots x_d) & \textrm{with probability $1 - \epsilon$}\\
    \textrm{Majority}(x_{d+1}, \ldots x_{2d}) & \textrm{with probability $\epsilon$}\\
\end{cases}$$

A purely greedy, information-gain-based splitting approach will only split on features in the $x_{d+1}, \ldots x_{2d}$ block, since all have greater than zero information gain (unlike the other variables). Such a tree can improve to at most $\frac{1}{2} + \epsilon$ accuracy. 
 
However, Algorithm 3 (LicketySPLIT), when deciding on the first split, will pick $x_1$ as the first split, after observing that being greedy from $x_1$ onwards will achieve accuracy at least $1-\epsilon$: because once $x_1$ is known, variables $x_2, \ldots x_d$ have high information gain, and a greedy tree will pick those features for splits over $x_{d+1}, \ldots x_{2d}$. Splitting on all of the first $d$ features, then, affords performance at least $1 - \epsilon$. 

\end{proof}