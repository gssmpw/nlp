		%\documentclass[11pt]{article}

%\documentclass[smallextended,final]{svjour3}
\documentclass[smallextended,final]{svjour3}
\usepackage[letterpaper,top=2in, bottom=1.5in, left=1in, right=1in]{geometry}

\usepackage{epsfig,epsf,fancybox}
\usepackage{amsmath}
\usepackage{tablefootnote}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{color}
\usepackage[linktocpage,pagebackref,colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=blue,urlcolor=blue,hypertexnames=false]{hyperref}
\usepackage{boxedminipage}
\usepackage{stmaryrd}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
%\usepackage{accents}
\usepackage{cite}
\usepackage{float}
%\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{braket,mathdots}
\usepackage{mathtools}
\usepackage[thinlines]{easytable}
\usepackage{array}
\usepackage{bbding}
\usepackage{subcaption}

\allowdisplaybreaks[4]
\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
%\textheight 8.5truein
%\parskip 0.1in
%\topmargin 0.25in
%\headheight 0in
%\headsep 0in
%\textwidth 6.5truein
%\oddsidemargin  0in
%\evensidemargin 0in
%\renewcommand{\baselinestretch}{1.1}
%\parindent0pt
\def\proof{\par\noindent{\em Proof.}}
\def\endproof{\hfill $\Box$ \vskip 0.4cm}

\newcommand{\vgamma}{{\boldsymbol{\gamma}}}
\newcommand{\vxi}{{\boldsymbol{\vx}}}
\newcommand{\vvarphi}{{\boldsymbol{\varphi}}}
\newcommand{\vxeta}{{\boldsymbol{\zeta}}}
\newcommand{\vdelta}{{\boldsymbol{\delta}}}


\def\red#1{\textcolor{red}{#1}}	
\def\blue#1{\textcolor{blue}{#1}}
\usepackage{mathtools}
%\mathtoolsset{showonlyrefs}

%% macros for editing and commenting
\usepackage[normalem]{ulem} % to use \sout
\newcommand{\remove}[1]{{\color{gray}\sout{#1}}}
\newcommand{\revise}[1]{{\color{blue}#1}}
\newcommand{\comm}[1]{{\color{red}(yx: #1)}}
\newcommand{\commwei}[1]{{\color{red}(#1)}}
\newcommand{\commgmb}[1]{{\color{red}(GMB: #1)}}

\newcommand{\bm}[1]{\boldsymbol{#1}}


%% macros for vectors
\newcommand{\lb}{\lambda}
\newcommand{\va}{{\mathbf{a}}}
\newcommand{\vb}{{\mathbf{b}}}
\newcommand{\vc}{{\mathbf{c}}}
\newcommand{\vd}{{\mathbf{d}}}
\newcommand{\ve}{{\mathbf{e}}}
\newcommand{\vf}{{\mathbf{f}}}
\newcommand{\vg}{{\mathbf{g}}}
\newcommand{\vh}{{\mathbf{h}}}
\newcommand{\vi}{{\mathbf{i}}}
\newcommand{\vj}{{\mathbf{j}}}
\newcommand{\vk}{{\mathbf{k}}}
\newcommand{\vl}{{\mathbf{l}}}
\newcommand{\vm}{{\mathbf{m}}}
\newcommand{\vn}{{\mathbf{n}}}
\newcommand{\vo}{{\mathbf{o}}}
\newcommand{\vp}{{\mathbf{p}}}
\newcommand{\vq}{{\mathbf{q}}}
\newcommand{\vr}{{\mathbf{r}}}
\newcommand{\vs}{{\mathbf{s}}}
\newcommand{\vt}{{\mathbf{t}}}
\newcommand{\vu}{{\mathbf{u}}}
\newcommand{\vv}{{\mathbf{v}}}
\newcommand{\vw}{{\mathbf{w}}}
\newcommand{\vx}{{\mathbf{x}}}
\newcommand{\vy}{{\mathbf{y}}}
\newcommand{\vz}{{\mathbf{z}}}

%% macros for matrices
\newcommand{\vA}{{\mathbf{A}}}
\newcommand{\vB}{{\mathbf{B}}}
\newcommand{\vC}{{\mathbf{C}}}
\newcommand{\vD}{{\mathbf{D}}}
\newcommand{\vE}{{\mathbf{E}}}
\newcommand{\vF}{{\mathbf{F}}}
\newcommand{\vG}{{\mathbf{G}}}
\newcommand{\vH}{{\mathbf{H}}}
\newcommand{\vI}{{\mathbf{I}}}
\newcommand{\vJ}{{\mathbf{J}}}
\newcommand{\vK}{{\mathbf{K}}}
\newcommand{\vL}{{\mathbf{L}}}
\newcommand{\vM}{{\mathbf{M}}}
\newcommand{\vN}{{\mathbf{N}}}
\newcommand{\vO}{{\mathbf{O}}}
\newcommand{\vP}{{\mathbf{P}}}
\newcommand{\vQ}{{\mathbf{Q}}}
\newcommand{\vR}{{\mathbf{R}}}
\newcommand{\vS}{{\mathbf{S}}}
\newcommand{\vT}{{\mathbf{T}}}
\newcommand{\vU}{{\mathbf{U}}}
\newcommand{\vV}{{\mathbf{V}}}
\newcommand{\vW}{{\mathbf{W}}}
\newcommand{\vX}{{\mathbf{X}}}
\newcommand{\vY}{{\mathbf{Y}}}
\newcommand{\vZ}{{\mathbf{Z}}}

\newcommand{\vlam}{{\bm{\lambda}}}
\newcommand{\vtheta}{{\bm{\theta}}}
\newcommand{\vell}{{\bm{\ell}}}
\newcommand{\veps}{{\bm{\vareps}}}
\newcommand{\vsigma}{{\bm{\sigma}}}


%% macros for sets
\newcommand{\cA}{{\mathcal{A}}}
\newcommand{\cB}{{\mathcal{B}}}
\newcommand{\cC}{{\mathcal{C}}}
\newcommand{\cD}{{\mathcal{D}}}
\newcommand{\cE}{{\mathcal{E}}}
\newcommand{\cF}{{\mathcal{F}}}
\newcommand{\cG}{{\mathcal{G}}}
\newcommand{\cH}{{\mathcal{H}}}
\newcommand{\cI}{{\mathcal{I}}}
\newcommand{\cJ}{{\mathcal{J}}}
\newcommand{\cK}{{\mathcal{K}}}
\newcommand{\cL}{{\mathcal{L}}}
\newcommand{\cM}{{\mathcal{M}}}
\newcommand{\cN}{{\mathcal{N}}}
\newcommand{\cO}{{\mathcal{O}}}
\newcommand{\cP}{{\mathcal{P}}}
\newcommand{\cQ}{{\mathcal{Q}}}
\newcommand{\cR}{{\mathcal{R}}}
\newcommand{\cS}{{\mathcal{S}}}
\newcommand{\cT}{{\mathcal{T}}}
\newcommand{\cU}{{\mathcal{U}}}
\newcommand{\cV}{{\mathcal{V}}}
\newcommand{\cW}{{\mathcal{W}}}
\newcommand{\cX}{{\mathcal{X}}}
\newcommand{\cY}{{\mathcal{Y}}}
\newcommand{\cZ}{{\mathcal{Z}}}
%$\newcommand{\R}{{\mathbb{R}}}

%
\newcommand{\vareps}{\varepsilon}

%% macros for the real and imaginary parts
\newcommand{\ri}{{\mathrm{i}}}
\newcommand{\rr}{{\mathrm{r}}}

%% macros for math notions and operators
\newcommand{\EE}{\mathbb{E}} % expectation
\newcommand{\RR}{\mathbb{R}} % real
\newcommand{\CC}{\mathbb{C}} % complex
\newcommand{\ZZ}{\mathbb{Z}} % integer
\newcommand{\zz}{^{\top}} % integer
\renewcommand{\SS}{{\mathbb{S}}} % symmetric matrix
\newcommand{\SSp}{\mathbb{S}_{+}} % symmetric positive semi-definite matrix
\newcommand{\SSpp}{\mathbb{S}_{++}} % symmetric positive definite matrix
\newcommand{\sign}{\mathrm{sign}} % sign function
\newcommand{\vzero}{\mathbf{0}} % 0 vector
\newcommand{\vone}{{\mathbf{1}}} % 1 vector

\newcommand{\dist}{\mathrm{dist}}    % distance
\newcommand{\op}{{\mathrm{op}}} % subscript for operator norm
\newcommand{\opt}{{\mathrm{opt}}} % subscript for optimal solution
%\newcommand{\supp}{{\mathrm{supp}}} % support
\newcommand{\Prob}{{\mathrm{Prob}}} % probability
\newcommand{\prox}{{\mathbf{prox}}} % proximal map
\newcommand{\Diag}{{\mathrm{Diag}}} % vector -> diagonal matrix
%\newcommand{\diag}{{\mathrm{diag}}} % matrix diagonal -> vector
\newcommand{\dom}{{\mathrm{dom}}} % domain
%\newcommand{\rank}{\textnormal{rank}}
%\newcommand{\grad}{{\nabla}}    % gradient
\newcommand{\tr}{{\mathrm{tr}}} % trace
\newcommand{\TV}{{\mathrm{TV}}} % total variation
\newcommand{\Proj}{{\mathrm{Proj}}} % projection
\newcommand{\Null}{{\mathrm{Null}}} % null space
\newcommand{\Dim}{{\mathrm{dim}}} % dimension
\newcommand{\etal}{{\textit{et al.}}}
\newcommand{\conj}{{\mathrm{conj}}} % conjugate
\newcommand{\vvec}{{\mathrm{vec}}}
\newcommand{\fold}{{\mathbf{fold}}} % fold into a tensor
\newcommand{\unfold}{{\mathbf{unfold}}} % unfold a tensor
\newcommand{\fit}{{\mathrm{fit}}} % data fitting
\newcommand{\obj}{{\mathrm{obj}}} % data fitting
\newcommand{\round}{{\mathrm{round}}}
\newcommand{\vol}{{\mathrm{vol}}}

% rounding number
\newcommand{\err}{{\mathrm{err}}}
\newcommand{\ST}{\mbox{ subject to }}
\newcommand{\st}{\mbox{ s.t. }}

\newcommand{\ip}[2]{\langle #1 , #2 \rangle}
\newcommand{\by}{{\bf y}}
\newcommand{\bxs}{{\bf x}_{\epsilon,\lambda,q}}
\newcommand{\od}{\frac{d}{dt}}
\newcommand{\pd}{{\partial }}
\newcommand{\rankk}{{\hbox{rank}}}




\newcommand{\prev}{{\mathrm{prev}}} % previous iteration

\DeclareMathOperator{\shrink}{shrink} % shrinkage
\DeclareMathOperator{\hardthr}{hardthr} % hard thresholding
\DeclareMathOperator*{\argmin}{arg\,min} % argmin
\DeclareMathOperator*{\argmax}{arg\,max} % argmax

\DeclareMathOperator*{\Min}{minimize}
\DeclareMathOperator*{\Max}{maximize}



%% macros for environments math equations

\newcommand{\bc}{\begin{center}}
	\newcommand{\ec}{\end{center}}

\newcommand{\bdm}{\begin{displaymath}}
	\newcommand{\edm}{\end{displaymath}}

\newcommand{\beq}{\begin{equation}}
	\newcommand{\eeq}{\end{equation}}

\newcommand{\bfl}{\begin{flushleft}}
	\newcommand{\efl}{\end{flushleft}}

\newcommand{\bt}{\begin{tabbing}}
	\newcommand{\et}{\end{tabbing}}

\newcommand{\beqn}{\begin{eqnarray}}
	\newcommand{\eeqn}{\end{eqnarray}}

\newcommand{\beqs}{\begin{align*}} % no equation numbers
	\newcommand{\eeqs}{\end{align*}}  % no equation numbers

%% macros for theorem-like environments

%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{acknowledgement}{Acknowledgement}[section]
\newtheorem{axiom}{Axiom}[section]
%\newtheorem{algorithm}{Algorithm}[section]
%\newtheorem{case}{Case}[section]
%\newtheorem{claim}{Claim}[section]
\newtheorem{conclusion}{Conclusion}[section]
%\newtheorem{condition}{Condition}[section]
%\newtheorem{conjecture}{Conjecture}[section]
%\newtheorem{corollary}{Corollary}[section]
\newtheorem{criterion}{Criterion}[section]
%\newtheorem{definition}{Definition}[section]
%\newtheorem{example}{Example}[section]
%\%newtheorem{exercise}{Exercise}[section]
%\newtheorem{lemma}{Lemma}[section]
\newtheorem{notation}{Notation}[section]
%\newtheorem{problem}{Problem}[section]
%\newtheorem{proposition}{Proposition}[section]
%\newtheorem{remark}{Remark}[section]
\newtheorem{assumption}{Assumption}
\newtheorem{setting}{Setting}
%\newtheorem{solution}{Solution}[section]
\newtheorem{summary}{Summary}[section]



\newcommand{\hvx}{{\hat{\vx}}}
\DeclarePairedDelimiter{\dotp}{\langle}{\rangle} 
\numberwithin{equation}{section}
\numberwithin{corollary}{section}
\numberwithin{theorem}{section}
\numberwithin{lemma}{section}
\numberwithin{proposition}{section}
\numberwithin{remark}{section}
\begin{document}
\allowdisplaybreaks[4]

    \titlerunning{A stochastic smoothing framework for nonconvex-nonconcave min-sum-max problems}
	\title{A stochastic smoothing framework for nonconvex-nonconcave min-sum-max problems with applications to Wasserstein distributionally robust optimization
    }
	
	\author{Wei Liu \and Muhammad Khan \and Gabriel Mancino-Ball \and Yangyang Xu}
	
	\institute{W. Liu, M. Khan, G. Mancino-Ball, Y. Xu \at Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, NY\\
		\email{\{liuw16, khanm7, xuy21\}@rpi.edu}, gabriel.mancino.ball@gmail.com}
	\date{\today}
	\maketitle

 \begin{abstract}
		Applications such as adversarially robust training and Wasserstein Distributionally Robust Optimization (WDRO) can be naturally formulated as min-sum-max optimization problems. While this formulation can be rewritten as an equivalent min-max problem, the summation of max terms introduces computational challenges, including increased complexity and memory demands, which must be addressed. These challenges are particularly evident in WDRO, where existing tractable algorithms often rely on restrictive assumptions on the objective function, limiting their applicability to state-of-the-art machine learning problems such as the training of deep neural networks.
This study introduces a novel stochastic smoothing framework based on the \mbox{log-sum-exp} function, efficiently approximating the max operator in min-sum-max problems. By leveraging the Clarke regularity of the max operator, we develop an iterative smoothing algorithm that addresses these computational difficulties and guarantees almost surely convergence
to a Clarke/directional stationary point. 
We further 
prove that the proposed algorithm finds an $\epsilon$-scaled Clarke stationary point of the original problem, with a worst-case 
iteration complexity of $\widetilde{O}(\epsilon^{-3})$.
Our numerical experiments demonstrate that our approach outperforms or is competitive with state-of-the-art methods in solving the newsvendor problem, deep learning regression, and adversarially robust deep learning. The results highlight that our method yields more accurate and robust solutions in these challenging problem settings.
 \end{abstract}
	
	\noindent {\bf Keywords}: stochastic method, smoothing method, nonconvex-nonconcave min-sum-max problem, minimax problems, distributionally robust optimization
	
	\noindent {\bf Mathematics Subject Classification} : 49M37, 65K05, 90C06, 90C30, 90C47
	
	
	
%%%%%%%%%%%%%%%%%%%
% Introduction 
%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}
The goal of this paper is to develop a novel algorithmic framework with guaranteed convergence for solving the nonconvex-nonconcave min-sum-max structured problem
\begin{equation}\label{eq:minmax}
	\min_{\vy\in\RR^{m_1}}\left\{g(\vy):=\varphi(\vy)+\EE_{\vx\sim\widehat{\mathbb{P}}_n}\left[\max_{\vz\in\mathcal{Z}} \Psi(\vy,\vz;\vx)\right]\right\}.\tag{P}
\end{equation}
Here, $\cZ\subseteq\RR^{m_2}$ is a finite discrete set or a general continuous compact set. We refer to $g$ as the \emph{primal function} with $\widehat{\mathbb{P}}_n$ as the {uniform (empirical)  distribution} based on data set $\{\vx_1,\vx_2,\ldots,\vx_n\}$.  
For each $i\in[n]$, we define 
\begin{equation}\label{eq:def-Phi-i}
	\Phi_i(\vy):=\max _{\vz\in\mathcal{Z}} \Psi(\vy,\vz;\vx_i).
\end{equation}    Throughout the paper, we make the following assumption on problem~\eqref{eq:minmax}.
\begin{assumption}\label{ass:problemsetup}
	The following statements hold:
	
	$\mathrm{(i)}$ For each $i$, the function $\Psi(\cdot,\cdot;\vx_i): \mathbb{R}^{m_1} \times \mathbb{R}^{m_2} \rightarrow \mathbb{R}$ is continuous on its domain, and its $\vy$-partial gradient mapping $\nabla_{\vy}\Psi(\cdot,\cdot;\vx_i)$ is also continuous. 
	
	$\mathrm{(ii)}$ The function $\varphi:\RR^{m_1}\mapsto\RR$ is 
	proper closed convex,  and its proximal mapping can be easily evaluated.  
	
	$\mathrm{(iii)}$ The sets $\dom(\varphi)$ and $\mathcal{Z}$ are compact.
\end{assumption} 
Based on the above assumption, the functions $\{\Phi_i\}$ in \eqref{eq:def-Phi-i} are well defined and continuous.  
%We will focus on the case  
%where $\mathcal{Z}$ is a finite discrete set or a general continuous compact set.  
The function~$\varphi$ is any proximal-friendly convex function such as the indicator function of a convex set or the $L_1$-norm, often referred to as a \emph{regularizer}. {Notably, we do not assume smoothness of the functions $\{\Phi_i\}$ or %the primal function 
	$g$.  
	\begin{comment}
		Then problem \eqref{eq:minmax2} becomes
		\begin{equation}\label{eq:minmax3}
			\min_{\vy}\max_{\vz\in\mathcal{Z}}\varphi(\vy)+ \frac{1}{n}\sum_{i=1}^n\overline{\Psi}(\vy,\vz;\vx_i)
		\end{equation}
		with $\overline{\Psi}(\vy,\vz;\vx_i) = \Psi(\vy,\vz_i;\vx_i)$ for all $i\in[n]$ 
	\end{comment} 
	The problem \eqref{eq:minmax} encompasses a broad class of modern machine learning applications such as  
	adversarially robust training \cite{goodfellow2014explaining, huang2015learning, madry2017towards, liang2023optimization}  
	and distributionally robust optimization (DRO)~\cite{kuhn2024distributionallyrobustoptimization,rahimian2019distributionally}. 
	Notice that problem~\eqref{eq:minmax} can be equivalently written in the following minimax structured formulation
	\begin{equation}\label{eq:minmax22}
		\min_{\vy}\max_{\{\vz_1,\ldots,\vz_n\}\subset\mathcal{Z}} \varphi(\vy)+\frac{1}{n}\sum_{i=1}^n \Psi(\vy,\vz_i;\vx_i),
	\end{equation}
	where we have used the fact that $\widehat{\mathbb{P}}_n$ is a uniform distribution. 
	When solving problem \eqref{eq:minmax}, researchers~\cite{liang2023implications} often frame it as a minimax problem, as outlined in \eqref{eq:minmax22}. However, directly solving \eqref{eq:minmax22} can result in computational difficulties, especially when $n$ is large in real-world applications, primarily due to the challenges in managing memory storage and tuning the step size during the optimization process\footnote{Roughly speaking, 2x memory will be required to store both $\{\vx_i\}$ and $\{\vz_i\}$ in the case where each $\vz_i$ has the same size as $\vx_i$. Also, tuning step size becomes more challenging for $n$-fold high dimensional problem.}. 
	
	{To address this issue, some researchers~\cite{deng2021local,goodfellow2014explaining} propose using a single $\vz$  variable shared across all data points, and subsequently solve the corresponding problem
		\begin{equation}\label{eq:minmax2}
			\min_{\vy}\max_{\vz\in\mathcal{Z}} \varphi(\vy)+\frac{1}{n}\sum_{i=1}^n \Psi(\vy,\vz;\vx_i).
		\end{equation}
		Nevertheless, this substitution fails to adequately capture the complexity of the original problem, resulting in solutions that deviate significantly from those of the original formulation.}
	
	%\blue{Necessary?
		%		Despite the curse of dimensionality caused by a large \( n \) in~\eqref{eq:minmax22}, existing algorithms for solving min-max problems can still be applied here. In addressing such problems, researchers often aim to develop algorithms that find the so-called \emph{game stationary points} or \textit{Nash equilibrium points}; see~\cite{xu2023unified,nouiehed2019solving,jiang2022optimality,lin2018solving,li2022nonsmooth} for examples.  However, for any game stationary point \( (\bar{\vy}, [\bar{\vz}_i]^n_{i=1}) \), both \( \bar{\vy} \) and \( \bar{\vz}_i \) may be far from any local minimizer of the problems \( \min_{\vy} g(\vy) \) and \( \min_{\vz \in \mathcal{Z}} \Psi(\bar{\vy}, \vz; \vx_i) \), respectively~\cite{jiang2022optimality}. This flaw arises because game stationary points fail to capture the order between the min-problem and the max-problem~\cite{lin2020gradient}.
		%		Notably, in solving convex-concave and nonconvex-concave minimax problems, some researchers have shifted their focus to solving the primal problem and have successfully obtained Clarke stationary points~\cite{lin2020gradient,rahimian2019distributionally,lu2020hybrid,thekumparampil2019efficient}. This raises a direct question: \textbf{can we obtain a Clarke stationary point for nonconvex-nonconcave min-(sum-)max problems}?
		%	}
	
	Instead of maintaining $n$ $\vz$-points in \eqref{eq:minmax22} or solving a deviated formulation in \eqref{eq:minmax2}, we develop a framework to solve problem~\eqref{eq:minmax} by sequentially approximating the inner maximization problem using the Logarithm of the Expectation of Exponentials (log-sum-exp) approximation function~\cite{shapiro2021lectures}. By exploiting properties of this function, 
	we directly solve the primal minimization problem $\min_{\vy} g(\vy)$ with a smoothing technique, {effectively circumventing the computational challenges previously discussed.}
	Our theoretical analysis shows that the proposed framework achieves a Clarke stationary point (see Definition~\ref{def:clarkeregular}), and importantly, we prove that this point is also a directional stationary point for the primal problem $\min_{\vy} g(\vy)$. 
	The directional stationary point is shown to be the sharpest first-order stationary point of a nonconvex optimization problem~\cite{pang2017computing, cui2018composite, cui2021modern}.
	Notably, this is the first time that such a point is rigorously established for the nonconvex-nonconvave min-sum-max problem \eqref{eq:minmax}. %and its equivalent formulation, the minimax problem \eqref{eq:minmax22}. 
	The remainder of this section introduces relevant applications that have the structure of~\eqref{eq:minmax}; we then state our technical contributions, a brief literature review, and finally list relevant notation and definitions.
	
	
	
	\subsection{Applications}\label{sec:appli}
	
	Two relevant applications that have the structure of~\eqref{eq:minmax} %of our interest %\red{that benefit from having coupled $(\vx,\vz)$ pairs} 
	are adversarially robust training and Wasserstein distributionally robust optimization (WDRO).
	In a classification setting, the adversarially robust training \cite{goodfellow2014explaining, huang2015learning, madry2017towards, liang2023optimization} problem takes the form of 
	\begin{equation}\label{eq:adt}\min _{{\vtheta}}\frac{1}{n}\sum_{i=1}^n \max _{\vz \in \Delta({\vx}_i)} \ell\left({\bar{\vx}_i}, f(\vtheta, \vz)\right).\end{equation}
	Here, $\{(\vx_i,{\bar{\vx}}_i)\}_{i=1}^n%,(\vx_2,{\bar{\vx}}_2),\ldots,(\vx_n,{\bar{\vx}}_n)\}
	\subset \RR^{m_2}\times \RR^{m_3}$ are sampled ordered pairs of data points and their corresponding labels (respectively),
	%are the given data samples with labels $\bar{\vx}_i$, %of size $n$ in a uniform distribution $\widehat{\mathbb{P}}_n$,  
	$\Delta({\vx})=\left\{\vz\in\RR^{m_2}\big| d\left({\vx}, \vz\right) \leq \varepsilon\right\}$ represents a set of feasible perturbations applied to a given data point $\vx$ based on some distance function $d$, %\comm{Why $\vz \in [0,1]^{m_2}$} 
	%\red{To ensure that $\vz$ is a valid image.} 
	$f:\RR^{m_1}\times \RR^{m_2}\mapsto \RR^{m_3}$ is a  prediction function, and $\ell: \RR^{m_3}\times \RR^{m_3}\mapsto \RR$ is a loss function. 
	In the context of computer vision, this model seeks to identify the worst-case perturbations for images within a prescribed radius \cite{huang2015learning, madry2017towards}. Let $\widehat{\mathbb{P}}_n$ be a uniform distribution on the data samples. Then $\frac{1}{n}\sum_{i=1}^n \max _{\vz \in \Delta({\vx}_i)} \ell\left({\bar{\vx}_i}, f(\vtheta, \vz)\right) = \EE_{(\vx,\bar\vx)\in \widehat{\mathbb{P}}_n}\max _{\vz \in \Delta({\vx})} \ell\left({\bar{\vx}}, f(\vtheta, \vz)\right)$, and thus \eqref{eq:adt} can be formulated into \eqref{eq:minmax}.
	
	The WDRO problem~\cite{kuhn2024distributionallyrobustoptimization} can be formulated as
	\begin{equation}
		\label{eq:model}
		\min_{\vtheta\in \Theta} \max _{\mathbb{P} \in \mathcal{B}_\delta(\widehat{\mathbb{P}}_n)} \mathbb{E}_{\vx \sim \mathbb{P}}\left[\ell(\vtheta,\vx)\right],
	\end{equation}
	where $\mathbb{P}$ is a probability distribution supported on $\cZ$, $\ell:\RR^{m_1}\times \RR^{m_2}\mapsto \RR$ is a given loss function, $\Theta$ is a closed convex set, $\mathbb{E}_{\vx \sim \mathbb{P}}[\ell(\vtheta,\vx)]=\int_{\mathcal{Z}}\ell(\vtheta,\vx) \mathbb{P}(\mathrm{d}\vx)$, and the ambiguity set %~\cite{mohajerin2018data} 
	$\mathcal{B}_\delta(\widehat{\mathbb{P}}_n)$ is defined as the $\delta$-ball in the $p$-th Wasserstein distance centered at the uniform distribution $\widehat{\mathbb{P}}_n$, i.e., 
	$\mathcal{B}_\delta(\widehat{\mathbb{P}}_n)=\{\mathbb{P} \in \mathcal{P}(\mathcal{Z})\mid d_{\mathcal{W}_p}(\mathbb{P}, \widehat{\mathbb{P}}_n) \leq \delta\}.$ Here, $\mathcal{P}(\mathcal{Z})$ is the space of probability distributions $\mathbb{P}$ supported on $\mathcal{Z}$ with $\mathbb{E}_{\vx \sim \mathbb{P}} [\|\vx\|] <\infty$,  and the $p$-th Wasserstein distance \cite{kantorovich1958space} between distributions $\mathbb{Q}_1, \mathbb{Q}_2 \in \mathcal{P}(\mathcal{Z})$  is defined by %$d_{\mathcal{W}_p}: \mathcal{P}(\mathcal{Z}) \times$ $\mathcal{P}(\mathcal{Z}) \rightarrow \mathbb{R}_{+}$ with an arbitrary norm and 
	$$
	d_{\mathcal{W}_p}\left(\mathbb{Q}_1, \mathbb{Q}_2\right):=\inf \left\{\left(\int_{\mathcal{Z}\times \mathcal{Z}}\left\|\vz_1-\vz_2\right\|_p^p \mathrm{\Pi}\left(\mathrm{d} \vz_1, \mathrm{d} \vz_2\right)\right)^{1/p} \bigg| \begin{array}{l}
		\mathrm{\Pi} \text { is a joint distribution of } \vz_1 \text { and } \vz_2 \text{ with}\\
		\text {marginal distributions } \mathbb{Q}_1 \text { and } \mathbb{Q}_2 \text {, respectively}
	\end{array}\right\}.
	$$  
	%\revise{The presence of the ambiguity set \( \mathcal{B}_\delta(\widehat{\mathbb{P}}_n) \) makes problem \eqref{eq:model} distinct from standard min-max problems. Directly solving this problem requires additional assumptions about the structure of \( f \) and the ambiguity set (see \cite{sheriff2024nonlinear} and references therein). To reduce reliance on such assumptions, researchers turn to consider a dual formulation of problem~\eqref{eq:model}, as introduced in the following.}
	The inner maximization problem of  WDRO gives the worst-case risk 
	\begin{equation}
		\label{eq:worstrisk}
		\max_{\mathbb{P} \in \mathcal{B}_\delta(\widehat{\mathbb{P}}_n)} \mathbb{E}_{\vx \sim \mathbb{P}}\left[\ell(\vtheta,\vx)\right].
	\end{equation}
	Under certain assumptions on the loss function $\ell$, the optimal value of problem \eqref{eq:worstrisk} is finite and attainable~\cite{yue2022linear, gao2023distributionally}, and furthermore,
	strong duality holds. %for problem \eqref{eq:worstrisk}, 
	%where its 
	The dual problem of \eqref{eq:worstrisk} is given by~\cite{rahimian2019distributionally,yue2022linear,gao2023distributionally}
	\begin{equation}
		\label{eq:worstriskdual}
		\min_{\lb \geq 0} \lambda \delta^p+\mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\left[\max _{\vz \in \mathcal{Z}}\{\ell(\vtheta,\vz)-\lambda d(\vx,\vz)\}\right] = \min_{\lb \geq 0} \lambda \delta^p+\frac{1}{n}\sum_{i=1}^n\left[\max _{\vz \in \mathcal{Z}}\{\ell(\vtheta,\vz)-\lambda d(\vx_i,\vz)\}\right].
	\end{equation}
	Here, $d: \RR^{m_2}\times \RR^{m_2}\mapsto \RR$ denotes the transport cost of the Wasserstein metric of order $p\in \mathbb{N}_+$ defined as $d(\vz_1,\vz_2):=\|\vz_1-\vz_2\|_p^p$ and $\lb\in\RR_+$ is the Lagrangian multiplier with respect to the inequality constraint $d_{\mathcal{W}_p}^p(\mathbb{P}, \widehat{\mathbb{P}}_n) \leq \delta^p$. By strongly duality, the optimal value of the aforementioned two models are the same. Therefore, by replacing \eqref{eq:worstrisk} with \eqref{eq:worstriskdual} in problem \eqref{eq:model}, we arrive at the following problem 
	\begin{equation}
		\label{eq:model2}
		\min_{\vtheta\in \Theta, \lb\ge 0} g(\vtheta, \lb):= \lambda \delta^p+\mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\left[\max _{\vz \in \mathcal{Z}}\{\ell(\vtheta,\vz)-\lambda d(\vx,\vz)\}\right],
	\end{equation}
	which is in the form of %structure as that in~
	\eqref{eq:minmax}.
	\subsection{Literature Review}
	\label{sec:liter}
	
	In this section, we briefly review %provides an overview of 
	existing methods for solving minimax problems % 
	and for WDRO. Also, we review the use of the log-sum-exp function. %in the literature.
	
	\subsubsection{Existing Methods for Solving Minimax Problems}
	Regardless of the dimension curse problem caused by a large $n$ in~\eqref{eq:minmax22}, existing algorithms for solving minimax problems can be applied there.
	Since the seminal work in \cite{v1928theorie}, convex-concave minimax problems have been extensively studied based on the concept of saddle points (see e.g. \cite{chen2014optimal,hamedani2021primal,zhao2022accelerated,daskalakis2018limit,lan2023novel, yan2022adaptive, lin2020near} and the references therein). 
	%For the case where~\eqref{eq:minmax22} has 
	Convex-nonconcave/nonconvex-concave minimax problems have also been studied; see~\cite{zhang2024generalization,xu2023unified, lin2020gradient, kong2021accelerated, zhao2024primal, rafique2022weakly, lin2020near, mancino2023variance,zhang2022sapd+,zhang2024jointly,xu2024decentralized} and references therein. For nonconvex-nonconcave minimax structured problems, see~\cite{Wang2020On,li2022nonsmooth,diakonikolas2021efficient,grimmer2022landscape,yang2022faster, adolphs2019local, daskalakis2018limit,liu2021first,fiez2021local,mazumdar2019finding}. 
	
	In cases where the minimax problem has a nonconvex-nonconcave structure, the existence of a saddle point is not guaranteed~\cite{jiang2022optimality}. 
	Hence, researchers have turned to developing algorithms for finding the so-called \emph{game stationary point} or \textit{Nash equilibrium point}; see~\cite{xu2023unified,nouiehed2019solving,jiang2022optimality,liu2021first,li2022nonsmooth} for examples.  
	However, for a game stationary  point $(\bar{\vy}, [\bar{\vz}_i]^n_{i=1})$, $\bar{\vy}$ and $\bar{\vz}_i$ may be far away from any local minimizer of problems $\min_{\vy}g(\vy)$ and $\min_{\vz\in\mathcal{Z}}-\Psi(\bar{ \vy},\vz;\vx_i)$, respectively~\cite{jiang2022optimality}. Such a flaw occurs because a game stationary point fails to capture the order between the min-problem and the max-problem~\cite{lin2020gradient}.  
	
	To address the fundamental limitations of game stationary points, several works focus on minimizing the primal function $g$ to obtain %specific 
	stronger types of stationary points, such as the Clarke stationary point; see Definition \ref{def:sta} below. %~\cite{clarke1990optimization}. 
	The Clarke stationarity  
	has been %extensively 
	studied for convex-concave and nonconvex-concave minimax problems \cite{lin2020gradient,rahimian2019distributionally,lu2020hybrid,thekumparampil2019efficient}. However, for nonconvex-nonconcave min-(sum-)max problems, computing (or even approximating) $\max_{\vz}\Phi_i(\vy,\vz;\vx)$ becomes intractable, making it difficult to verify the stationarity condition. In contrast, through the smoothing technique, our method can produce an iterate sequence converging to a Clarke stationary solution. Further, by establishing a Clarke regularity condition, we are able to show the convergence to a directional stationary point, which is claimed to be the sharpest first-order stationary point for nonconvex optimization problems \cite{pang2017computing, cui2018composite, cui2021modern}.
	
	\subsubsection{Existing Methods for Solving WDRO}
	As introduced in \cite{rahimian2019distributionally}, a broad approach in the DRO literature is to solve problem~\eqref{eq:model2}. Notably, problem~\eqref{eq:model2} exhibits a min-sum-max structure, allowing methods for solving minimax problems to be applied to WDRO.
	As we have mentioned, the nonconcavity of the loss function presents significant challenges in obtaining a stationary point. Moreover, in WDRO, the function $\ell(\vtheta,\cdot) - \lb d(\vx,\cdot)$ is often nonsmooth, further complicating the problem. To overcome these obstacles, researchers have proposed algorithms based on various reformulations of~\eqref{eq:model2} (see e.g. in~\cite{gao2023distributionally,mohajerin2018data,wozabal2012framework,kuhn2019wasserstein,liu2021discrete}),  and the convergence of these methods requires somewhat stringent conditions on the loss function~$\ell$ and the transport cost.
	When the %\remove{uncertainty} 
	{support} set~$\cal{Z}$
	is compact, a common approach to solve WDRO is to approximate $\cal{Z}$ using a finite, discrete grid. This method, though widely used \cite{xu2018distributionally,chen2021decomposition, liu2021discrete, pflug2007ambiguity}, becomes prohibitively expensive as the number of grid points grows. For WDRO with $l_1$ transport cost, a convex reformulation is available when the loss function can be expressed as a pointwise maximum of finitely many concave functions \cite{mohajerin2018data,gao2023distributionally}, or when the log-loss function is applied, such as in robust logistic regression \cite{li2019first,selvi2022wasserstein,shafieezadeh2015distributionally}. Moreover, efficient first-order algorithms have been developed for specific WDRO problems where the function $\ell(\vtheta,\cdot)-\lb d(\cdot,\vx)$ is strongly concave~\cite{blanchet2022optimal, sinha2018certifiable}.  To guarantee the strong concavity, the transport cost must satisfy stringent conditions relative to the loss function. %However, beyond 
	Without these conditions on the loss function or the transport cost, solving WDRO problems poses significant computational challenges. This is especially true when the structure of the problem does not lend itself to the simplifications used in previous work. 
	
	Recognizing the difficulty in solving the WDRO problem, \cite{wang2021sinkhorn} innovatively proposes addressing a dual problem of Sinkhorn DRO (SDRO),  
	which can be written as 
	\begin{equation}
		\label{eq:smoothg}
		\min_{\vtheta\in \Theta, \lb\ge 0}g_{\mathrm{s}}(\vtheta, \lb) :=  \lambda \delta^p+  \lb\eta \mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\left[\log \mathbb{E}_{\vz \sim \zeta}\left[e^{(\ell(\vtheta,\vz) -\lb d(\vx,\vz)) / \lb\eta}\right]\right]
	\end{equation}
	for some $\eta>0$.  
	The objective function in \eqref{eq:smoothg} can be viewed as a smoothing function of \eqref{eq:model2} by Definition~\ref{def:smooth} below with $\eta $ as the smoothing parameter. %; see Lemma \ref{lem:smoothphi}(a).
	Assuming $\ell(\cdot,\vz)$ is convex for all feasible~$\vz$, the authors of \cite{wang2021sinkhorn} develop a convergent triple-loop algorithm by skillfully combining a bisection method, a stochastic mirror descent method, and multilevel Monte-Carlo simulation.
	However, they fix $\eta>0$. In addition, in their complexity result \cite[Theorem 3]{wang2021sinkhorn}, they assume that any optimal solution $(\vtheta^*,\lb^*)$ of problem \eqref{eq:smoothg} satisfies $\lb^*\ge \overline{\lb}$ for some positive scalar $\overline{\lb}$.
	This assumption circumvents significant computational challenges by preventing both the Lipschitz constant and the gradient Lipschitz constant from exploding if %should \red{GMB: Not sure if \textit{should} is right here, but can we guarantee that $\lambda\to0$ would occur for SDRO?}
	$\lb$ approaches~0 as the algorithm progresses, 
	%\revise{This is the theoretical flaw. I do not think we should guarantee that $\lambda\to0$ occurs for SDRO.}
	%, which would otherwise lead to an exponential increase in the sampling complexity of their multilevel Monte-Carlo simulations with respect to $\frac{1}{\lb}$ (see the proof in \cite[Proposition EC.4]{wang2021sinkhorn}). 
	%Should $\lb$ approach~0, 
	in which case, an exponential increase in the sampling complexity of their multilevel Monte-Carlo simulations would occur with respect to $\frac{1}{\lb}$ (see the proof in \cite[Proposition EC.4]{wang2021sinkhorn}). 
	Hence, their algorithm does not solve the WDRO problem but rather addresses a simpler approximation.    
	
	%{
		In contrast, when applied to WDRO, our proposed method for \eqref{eq:minmax} smoothes the function in \eqref{eq:model2} by the log-sum-exp technique and solves 
		\begin{equation}
			\label{eq:smoothg2}
			\min_{\vtheta \in \Theta, \lb \geq 0} \widetilde{g}(\vtheta, \lb, \mu) := \lambda \delta^p + \mu \mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\left[\log \mathbb{E}_{\vz \sim \zeta}\left[e^{(\ell(\vtheta, \vz) -\lb d(\vx, \vz)) / \mu}\right]\right].
		\end{equation}
		Different from \cite{wang2021sinkhorn}, we do not fix $\mu$ at a big number but instead push it to zero and we further treat $\lambda$ as a variable that can reach zero. The formulation in \eqref{eq:smoothg2} 
		replaces \(\lb \eta\) in \eqref{eq:smoothg} with \(\mu\).  However, this subtle difference in the formulation leads to a fundamentally different method  
		from the algorithm in \cite{wang2021sinkhorn} in terms of algorithmic development, methodological foundation, and theoretical analysis.
		First, \cite{wang2021sinkhorn}  
		solves a dual problem of SDRO with a  fixed  \(\eta\). In contrast, we  
		solve WDRO directly, requiring \(\mu \downarrow 0\) in our algorithmic framework. 
		This divergence alters the optimization objectives and methodological considerations.
		Second, the requirement of \(\mu \downarrow 0\)
		introduces unique computational and theoretical challenges. It demands rigorous convergence analysis  %guarantees \red{GMB: To prove? (instead of that)} 
		to prove that solving a sequence of smoothed problems approximates a WDRO solution, while also handling the ill-conditioning and increased computational complexity arising from the vanishing~$\mu$. This necessitates sophisticated  
		analysis and careful design to ensure stability and efficiency.
		Third, \(\lb\) is a primal variable in problem \eqref{eq:smoothg} and appears in the denominator of the exponential term. 
		This results in both the Lipschitz constant and the gradient Lipschitz constant of 
		$g_s$  with respect to~$\lb$ becoming unbounded as 
		$\lambda$ approaches zero, which potentially yields slow convergence and high complexity. %complicate the complexity analysis. %To avoid this issue, Wang et al. \cite{wang2021sinkhorn} propose a convergent triple-loop algorithm under some stringent assumptions, which significantly increases complexity of tuning parameters of their algorithm.  
		In constrast, the Lipschitz constant of $\widetilde{g}$  with respect to \(\lb\) is bounded, and the gradient Lipschitz constant of $\widetilde{g}$   with respect to \(\lb\) can be bounded  by $\frac{C}{\mu}$ for some positive scalar $C$; %\red{GMB: If $\mu\to0$, isn't this bound sort of meaningless?} 
		this enables us to apply our established complexity results of our proposed method to the WDRO problem to obtain a scaled near-stationary solution; see Definition~\ref{def:scaled-stat} below.
		Additionally, 
		our proposed method applied to WDRO is  
		a single-loop algorithm compared to the triple-loop algorithm developed in~\cite{wang2021sinkhorn}.
		
		
		
		\subsubsection{The Log-sum-exp Function}
		When $\mathcal{Z}$ is a finite discrete set, $\mu \log \frac{1}{|\cZ|}\sum_{\vz_i\in\mathcal{Z}} e^{\Phi(\vy,\vz_i)/\mu}$ is the log-sum-exp function of  $\max_{\vz_i\in\mathcal{Z}} \Phi(\vy,\vz_i)$. In the literature, this function is sometimes referred to as the \emph{softmax maximum}~\cite{lecun2015deep} or the \emph{Neural Networks smoothing  function}~\cite{chen2012smoothing, burke2013gradient}. This smoothing function has been used for solving finite minimax problems \cite{polak2003algorithms, pee2011solving}. It is useful in scenarios where a differentiable approximation for the maximum is required~\cite{burke2020subdifferential,boyd2004convex,blanchet2020semi,wang2023stochastic}.
		Its optimization properties, such as convexity and gradient structure, have been studied extensively, highlighting its theoretical importance and practical utility in various fields ranging from statistics to deep learning. Notably, the gradient of the Neural Networks smoothing  function can also be viewed as the softmax function \cite{lecun2015deep}, which is widely used in neural networks.
		The authors in \cite{wang2023stochastic} utilize the Neural Networks smoothing function to solve nonsmooth convex minimization problems.  
		However, 	the log-sum-exp function that we will introduce in \eqref{eq:smoothphi} has not yet been applied as an approximation of the max operator over a continuous compact set within any known smoothing algorithm. %, and its properties have not been fully understood.
		
		\subsection{Contributions}
		\label{sec:contri}
		In this paper, we introduce the nonconvex-nonconcave min-sum-max problem~\eqref{eq:minmax}, which encompasses applications such as adversarially robust training and Wasserstein distributionally robust optimization (WDRO). We design a first-order stochastic framework called \textbf{SSPG} (\textbf{S}tochastic \textbf{S}moothing \textbf{P}roximal \textbf{G}radient) to solve this problem effectively. Our key contributions are four-fold.
		
		\begin{enumerate}
			\item Under the assumptions that $\mathcal{Z}$ is compact and the Lipschitz continuity of $\Psi(\cdot, \cdot; \vx_i)$,  we prove the Clarke regularity of $\Phi_i$ defined in \eqref{eq:def-Phi-i} for each  
			$i\in[n]$. 
			By this property, we establish the equivalence between Clarke stationarity and directional stationarity  for the primal problem in~\eqref{eq:minmax}. 
			This equivalence simplifies the algorithm design for the nonsmooth minimax problem and guarantees that once a Clarke stationary point is obtained, we %simultaneously 
			attain a %its corresponding 
			directional stationary point, %.
			%The directional stationary point 
			which is known to represent the sharpest form of a first-order stationary point in nonsmooth nonconvex optimization problems~\cite{pang2017computing, cui2018composite, cui2021modern}.  
			To the best of our knowledge, no prior work has identified a Clarke stationary point of a general \emph{nonconvex-nonconcave} min-sum-max (or minimax) problem,  even under Polyak-Łojasiewicz (PL) condition or Kurdyka-Łojasiewicz (KL) condition~\cite{li2022nonsmooth,nouiehed2019solving,yang2020global,yang2022faster}.  
			
			\item We use the log-sum-exp function to approximate the inner maximization problem in nonconvex-nonconcave min-sum-max problems. By utilizing the properties of the log-sum-exp function, we show that when 
			$\cal Z$ is a compact set, the resuling approximate function %.
			%	First, we prove that the log-sum-exp function 
			$\widetilde{\Phi}_i$ %of $\Phi_i$ 
			defined in \eqref{eq:smoothphi} below
			is a smoothing function of~$\Phi_i$ and it inherits the Lipschitz continuity of $\Psi(\cdot,\cdot;\vx_i)$ and $\nabla_{\vy}\Psi(\cdot,\vz;\vx_i)$ for any $\vz\in\cZ$. 
			
			\item 
			Using the smoothing technique,	we develop SSPG as an iterative algorithmic framework for solving 
			the nonconvex-nonconcave min-sum-max problem \eqref{eq:minmax}.  
			The SSPG framework  %\remove{offers a theoretically guaranteed stochastic method to} 
			handles the sum part directly, thereby avoiding the potential memory burden associated with reformulating the original problem into~\eqref{eq:minmax22}.  
			We prove that the proposed algorithm almost surely converges to a Clarke stationary point and a directionally stationary point of problem \eqref{eq:minmax}. 
			We %\remove{demonstrate} 
			{also prove} that the proposed algorithm can, in expectation, find an $\epsilon$-scaled Clarke stationary point (see Definition~\ref{def:scaled-stat} below) of the original problem, with a worst-case iteration complexity of \( \widetilde{O}(\epsilon^{-3}) \).   
			
			
			\item  
			Our method can be directly applied to WDRO if a stochastic gradient estimator is available.   
			We conduct extensive numerical experiments to assess the performance and effectiveness
			of our proposed method, yielding impressive results, particularly
			in terms of solution accuracy. Our evaluation encompasses three distinct problems within WDRO:
			newsvendor, regression, and adversarial robust deep learning. %~\red{Is this more like a Adversarial Robust problem?}. 
			In each problem, our framework
			outperforms or is comparable to the state-of-the-art methods, demonstrating superior performance
			and robustness, highlighting the utility of our approach on real-world problems. %This finding highlights the utility of our approach in delivering more reliable and
			%precise solutions compared to existing methods to tackle the real-world applications in this domain. %\comm{May need to reword the 4th contribution after all numerical results are done.}
		\end{enumerate}
		
		
		
		
		\subsection{Definitions and Notations}\label{sec:defi}
		Let $\|\cdot\|$ be the 2-norm of a vector. 
		We use $[M]$ to represent $\{1,2,\ldots,M\}$ for an integer $M$. Given a compact set $\mathcal{Z}$, denote $|\mathcal{Z}|$ as the cardinality of $\cal{Z}$ if it is a finite set and volume of $\cal{Z}$ if it is a continuous set.
		The indicator function is denoted as $\mathbb{I}.$
		The proximal mapping of a closed convex function $h$ %$\operatorname{prox}_{\nu h}$ 
		is defined by
		$\operatorname{prox}_{h}({\vx}) =\argmin_\vz\{h({\vz})+\frac{1}{2}\|{\vz}-{\vx}\|^2\}.$
		We use $h^{\prime}\left(\bar{\vy} ; \vd\right)$ to denote the \textit{directional derivative} of a function~$h$ at $\bar{\vy} $ along the direction $\vd$, i.e.,
		\begin{equation}
			\label{eq:dsta}
			h^{\prime}\left(\bar{\vy} ; \vd \right)=\lim _{ t \downarrow 0} \frac{1}{t}(h(\bar{\vy}+t \vd)-h(\bar{\vy})).
		\end{equation} 
		If the right limit in \eqref{eq:dsta} exists, we say $h$ is directional differentiable at $\bar{\vy} $ along the direction $\vd$. %If $h^{\prime}\left(\bar{\vy} ; \vd\right)$ is well-defined for any unit vector $\vd$, we say $h$ is directional differentiable at $\bar{\vy} $. 
		It is known that if $h$ is piecewise differentiable and Lipschitz continuous, then it is directional differentiable \cite{mifflin}.
		
		Denote $h^{\circ}(\bar{ \vy} ; \vd)$ as the \textit{generalized directional derivative} at $\bar{\vy}$ along the direction~$\vd$~\cite{clarke1990optimization}, by 
		$$h^{\circ}(\bar{ \vy} ; \vd):=\limsup _{{\vy \rightarrow \bar{ \vy}}, {t \downarrow 0}} \frac{1}{t}(h(\vy+t \vd)-h(\vy)).$$ 
		In general, it holds $h^{\circ}(\bar{ \vy} ; \vd)\geq h^{\prime}\left(\bar{\vy} ; \vd \right)$~\cite{clarke1990optimization}.
		If $h$ is differentiable, then $h^{\prime}\left(\bar{\vy} ; \vd \right)=h^{\circ}(\bar{ \vy} ; \vd)=\vd\zz\nabla h(\bar{ \vy})$. 
		We use $\partial h$ to denote the (Clarke) subdifferential~\cite[Section 1.2]{clarke1990optimization} of a continuous function $h$, i.e.,
		$$
		\partial h(\vy):=\left\{\vz \in \mathbb{R}^d:\langle \vz, \vv\rangle \leq h^{\circ}(\vy ; \vv),\,\, \forall \vv \in \mathbb{R}^d\right\}.
		$$
		The \textit{normal cone} of a convex set $\mathcal{Y}$ at $\vy^*$ is defined as 
		$\mathcal{N}_{\mathcal{Y}}(\vy^*)=\{\vgamma:\langle \vgamma, \vy-\vy^*\rangle \leq 0,  \forall \vy \in \mathcal{Y}\}.$  
		%We then introduce the definition of Clarke regular.
		\begin{definition}[Clarke regular {\cite[Definition 2.3.4]{clarke1990optimization}}]
			\label{def:clarkeregular}
			A function $h$ is said to be Clarke regular  at $\bar{\vy}$  %provided that 
			if for any direction $\vd$, the directional derivative $h^{\prime}(\bar{\vy} ; \vd)$ exists, and
			$
			h^{\prime}(\bar{\vy} ; \vd)=h^{\circ}(\bar{\vy} ; \vd)
			$.
		\end{definition}
		From Definition~\ref{def:clarkeregular}, 
		if $h$ is convex or  differentiable, then it is Clarke regular~\cite{clarke1990optimization} and directional differentiable.
		\begin{definition}[Stationary point \cite{cui2021modern}]
			\label{def:sta}
			Let $h$ be a directional differentiable function.
			{We say that $\vy^*$ is a directional stationary point of problem $\min_{\vy } h(\vy)$ if %for all $\vd$, it holds that 
				$h^{\prime}({\vy}^* ; \vd) \geq 0$ for all direction $\vd$,}
			and we say that $\vy^*$ is a Clarke stationary point of problem $\min_{\vy } h(\vy)$ if %it holds that 
			$\vzero\in\partial h(\vy^*)$.
		\end{definition}
		Any directional stationary point of $h$ %problem \eqref{eq:minmax} 
		is also a Clarke stationary point, while it may not hold vice versa.  
		Nevertheless, if $h$ is Clarke regular, then its Clarke stationary solution will also be 
		a directional stationary point.  
		
		\begin{definition}[Smoothing function \cite{chen2012smoothing}]\label{def:smooth}
			Let $h: \mathbb{R}^m \mapsto \mathbb{R}$ be continuous. We call $\widetilde{h}: \mathbb{R}^m \times \mathbb{R}_{+} \mapsto \mathbb{R}$ a smoothing function of $h$, if for any fixed {$\mu>0$}, $\widetilde{h}(\cdot, \mu)$ is continuously differentiable, and for any $\bar{\vy}$, it holds $\lim_{\vy\rightarrow\bar{\vy},\mu\downarrow 0} \widetilde{h}(\vy,\mu) = h(\bar{\vy})$.
		\end{definition}
		
		\subsection{Organization}
		The remainder of the paper is organized as follows.  In Section \ref{sec:algorithm}, 
		we introduce the SSPG framework for solving the problem~\eqref{eq:minmax}. We first construct a smoothing function, then give our proposed algorithmic framework, and finally provide the convergence analysis.  
		Numerical results are presented in Section~\ref{sec:numerical}. The proofs of some lemmas and theorems are given in Section \ref{sec:proof}. Finally, we conclude the paper %with a summary of our findings and list potential directions for future research 
		in Section \ref{sec:conclu}.
	
	

%\subsection{Notations}



%\begin{definition}
%	we call $\vy^*$ an $\epsilon$-scaled first-order  stationary point of problem $\min_{\vy\in \mathcal{Y}} h(\vy)$ if it holds that $\mu= O(\epsilon)$ and
%	$\dist(\vzero,\nabla \widetilde{h}(\vy^*,\mu) + \mathcal{N}_{\mathcal{Y}}(\vy^*))\leq \epsilon$.
%\end{definition}


%We consider the relation between the Clarke subdifferential  $\partial $ defined in Section~\ref{sec:presub} of a locally Lipschitz function $h$ and its smoothing function $\widetilde{h}$, which are defined by
%$$
%G_{\widetilde{h}}(\bar{\vy})=\overline{\textbf{co}}\left\{\vv \mid \nabla_\vy \widetilde{h}\left(\vy, \mu\right) \rightarrow %\vv, \text { for } \vy \rightarrow \bar{\vy}, \mu \downarrow 0\right\}.
%$$
%According to Theorem 9.61 and (b) of Corollary 8.47 in the book of Rockafellar and Wets \cite{roc1998var}, if $h$ is locally Lipschitz, then $G_{\widetilde{h}}(\vy)$ is nonempty and bounded, and $\partial h(\vy) \subseteq G_{\widetilde{h}}(\vy)$. 


%\subsection{A General Smoothing Algorithm Framework}

%In this subsection, we introduce a general smoothing algorithm framework~\cite{chen2012smoothing} for solving problem $\min_{\vy\in \mathcal{Y}} h(\vy)$.

%\begin{algorithm}
%	\caption{A smoothing algorithm framework for solving $\min_{\vy\in \mathcal{Y}} h(\vy)$.}
%	\label{alg:smooth1}
%	\begin{algorithmic}[1]
	%		\State{Initialization: define a parametric smoothing function $\widetilde{h}: R^m \times R_{+} \rightarrow R$ to approximate $h$. Set $k:=0$}.
	%		\While{{a termination criterion is not met,} }
	%		\State Use an algorithm to find an approximate stationary point $\vy^{(k)}$ of the smooth optimization problem
	%		$$
	%		\min _{\vy\in \mathcal{Y}} \widetilde{h}\left(\vy, \mu_k\right)
	%		$$
	%		for a fixed $\mu_k>0$.
	
	%		\State Update $\mu_k\downarrow 0$.
	%		%\STATE{Increment $k$ by one, return to step 2.}
	%		\EndWhile
	%	\end{algorithmic}
%\end{algorithm}

%Based on the definition of gradient consistency, we know that the smoothing algorithm in Algorithm~\ref{alg:smooth1} will find a Clarke stationary point of problem $\min_{\vy\in \mathcal{Y}} h(\vy)$ \cite{chen2012smoothing}. The lemma is formally stated as follows. This lemma can be proved by using a similar method to that of \cite[Theorem 3]{chen2012smoothing}.
%\begin{lemma}

	
	
	
%%%%%%%%%%%%%%%%%%%
% Algorithm 
%%%%%%%%%%%%%%%%%%%
\section{SSPG: A Stochastic Smoothing Proximal Gradient Framework for Solving Problem~\eqref{eq:minmax}}\label{sec:algorithm}

We focus on solving the primal problem $\min_{\vy} g(\vy)$ in \eqref{eq:minmax}. We first show that $ g$ is Clarke regular under a Lipschitz condition in Section~\ref{sec:clarke-reg}. Then we construct a smoothing function $\widetilde{\Phi}_i(\cdot,\mu)$ of $\Phi_i(\cdot)$ for each $i\in[n]$ in Section \ref{sec:smoothingphi}.
With access to a stochastic gradient estimator, we introduce the SSPG method and establish its convergence results in Section~\ref{sec:conver2}. 

\subsection{Clarke Regularity of the Primal Function $g$}\label{sec:clarke-reg}

In this subsection, we prove that the primal function $ g$ is directional differentiable and Clarke regular.  
We begin with a technical assumption. 

\begin{assumption}[Lipschitz]
	\label{ass:compact1}
	%	(\textit{Lipschitz})
	There exists $l_{\Psi}>0$ such that
	$\|\nabla_{\vy}\Psi(\vy,\vz;\vx_i)\|\leq l_{\Psi}$ for all $\vz\in\mathcal{Z}$ and $\vy\in\dom(\varphi)$ and $\Psi(\vy,\cdot;\vx_i) \text{ is } l_{\Psi}\text{-Lipschitz continuous on $\mathcal{Z}$}$ for all $i\in[n]$ and all $\vy\in \dom(\varphi)$. 
\end{assumption}
Before presenting the Clarke regularity result of $g$, we introduce  two auxiliary lemmas.

\begin{lemma}[mean-value theorem {\cite[Proposition 1.1]{correa1990subdifferential}}]	\label{lem:meanvalue}
	Let $h$ be a continuous directional differentiable function from $[a_1,a_2]$ to $\mathbb{R}$. Then, there exists $\bar{a} \in (a_1, a_2)$ such that
	$h^{\prime}(\bar{a}; 1) \geq \frac{h(a_1)-h(a_2)}{a_1-a_2}.$
\end{lemma}

\begin{lemma}[{\cite[Corollary 2.1]{correa1985directional}}]
	\label{lem:direc}
	Suppose Assumptions~\ref{ass:problemsetup}--\ref{ass:compact1} hold. %Let $\Psi^{\prime}_i(\vy, {\vz} ; \vx_i,\vd)$ be the directional derivative of $\Psi(\vy, {\vz} ; \vx_i)$ on $(\vy,\vz)$ at the direction $(\vd,\vzero)$.
	Then for each $i\in[n]$, the directional derivative $\Phi_i^{\prime}(\vy; \vd)$ exists for all $\vy$ and $\vd$, and it satisfies 
	\begin{equation}
		\label{eq:hderiva}
		\Phi_i^{\prime}(\vy; \vd) %= \max\left\{ \Psi^{\prime}_i(\vy, \bar{\vz} ; \vx_i,\vd) \mid \bar{\vz}\in \argmax_{\vz\in\mathcal{Z}}\Psi(\vy, \vz;\vx_i) \right\}
		=\max\left\{ \vd\zz \nabla_{\vy}\Psi(\vy, \bar{\vz} ; \vx_i) \mid \bar{\vz}\in \argmax_{\vz\in\mathcal{Z}}\Psi(\vy, \vz;\vx_i) \right\}.
	\end{equation}
\end{lemma}

Now, we are ready to show the key lemma of this subsection. The proof is given in Section \ref{sec:regularcondi}.



\begin{lemma}[Clarke regularity of the primal function]
	\label{lem:regularcondi}
	%The following statements hold.
	Under Assumptions~\ref{ass:problemsetup}--\ref{ass:compact1}, the function $ g$ in \eqref{eq:minmax} is Clarke regular. 
\end{lemma}
By Lemma~\ref{lem:regularcondi}, we have the following corollary.

\begin{corollary}
	\label{cor:gradientconssforg}
	Under Assumptions \ref{ass:problemsetup}--\ref{ass:compact1}, any Clarke stationary point of problem \eqref{eq:minmax} is also a directional stationary point.
\end{corollary}

\subsection{Constructing a Smoothing Function via the Log-sum-exp Function}\label{sec:smoothingphi}

For each $i\in[n]$, we construct a smoothing function for $\Phi_i$ by
\begin{equation}
	\label{eq:smoothphi}
	\widetilde{\Phi}_i(\vy, \mu) =   \mu \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu}], 
\end{equation}
where $\mu>0$ and the probability measure $\zeta$ satisfies the following assumption.
\begin{assumption}[Measure]
	\label{def:zeta}
	
	$\mathrm{(i)}$ If $\mathcal{Z}$ is a finite discrete set, let $\zeta$ be a uniform distribution on $\cal{Z}$;
	$\mathrm{(ii)}$ If $\mathcal{Z}$ is a continuous compact set, we let $\vz$ be a continuous random variable  
	and $\mathrm{supp}(\zeta) $ be a compact subset in~$\mathcal{Z}$ that contains at least one element in $ \argmax_{\vz\in\mathcal{Z}}\Psi(\vy, \vz;\vx_i) $.
\end{assumption}

We make the following assumption to ensure the smoothness of $\widetilde{\Phi}_i(\cdot,\mu)$. 
\begin{assumption}[{Gradient Lipschitz}]
	\label{ass:lk} 
	There exists $L_\Psi>0$ such that 
	$\nabla_{\vy}{\Psi}(\cdot,\vz;\vx_i)$ is $L_{\Psi}$-Lipschitz continuous on $ \dom(\varphi)$  	for all $\vz\in\mathcal{Z}$ and all $i\in[n]$.
\end{assumption}
The following lemma shows that $\widetilde{\Phi}_i$ is a smoothing function of $\Phi_i$ and
establishes key %smoothness and gradient 
properties of the smoothing function. Its proof is given in Section \ref{sec:smoothphi}.

\begin{lemma}
	\label{lem:smoothphi}
	Under Assumptions~\ref{ass:problemsetup}--\ref{ass:lk}, the following statements hold: %\comm{Put the gradient formula back. It is needed in Remark 2.2.}
	\begin{enumerate}
		\item[\textnormal{(a)}] $\widetilde{\Phi}_i$ is a smoothing function of $\Phi_i$ for each $i\in[n]$.
		\item[\textnormal{(b)}] 
		The $\vy$ and $\mu$ partial gradients of $\widetilde{\Phi}_i$ are %has the following structure:
		\begin{equation*}
			\begin{aligned}
				&\nabla_{\vy} \widetilde{\Phi}_i(\vy,\mu) =  \frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] },\\
				&\nabla_{\mu} \widetilde{\Phi}_i(\vy,\mu) = \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu}] -\frac{1}{\mu} \frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu} \Psi(\vy,\vz;\vx_i)]}{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}]}.\\   
			\end{aligned}
		\end{equation*}
		Moreover, it holds that $\|\nabla_{\vy} \widetilde{\Phi}_i(\vy,\mu)\|\leq l_{\Psi}$ for any $\mu>0$, 
		$\widetilde{\Phi}_i(\vy,\mu_1)\leq \widetilde{\Phi}_i(\vy,\mu_2)$ for any $\mu_1\geq\mu_2>0$, and $\lim_{ \mu \downarrow 0} \mu \nabla_\mu \widetilde{\Phi}_i(\mathbf{y}, \mu) =0$.
		
		\item[\textnormal{(c)}] The $\vy$ partial gradient $\nabla_{\vy} \widetilde{\Phi}_i(\vy,\mu)$ is $(L_{\Psi}+2l^2_{\Psi}/\mu)$-Lipschitz continuous with respect to $\vy$ for any $\mu>0$.
	\end{enumerate}
\end{lemma}

For any $\mu_1,\mu_2>0$ and all $i\in[n]$, we then establish upper bounds on the difference $|\widetilde{\Phi}_i(\vy,\mu_1)-\widetilde{\Phi_i}(\vy,\mu_2)|$ with respect to $|\mu_1-\mu_2|$
in the following two lemmas. Their proofs are given in Sections \ref{sec:distancemufinite} and \ref{sec:distancemu}, respectively.

\begin{lemma}
	\label{lem:distancemufinite}
	Suppose Assumptions \ref{ass:problemsetup}--\ref{ass:lk} hold, and $\mathcal{Z}$ is finite discrete. Then for any $\kappa \geq 2 \log(|\cal Z|)$, $\vy\in~\dom(\varphi)$, $1\ge \mu_1>\mu_2>0$, and all $i\in[n]$, it holds  $|\widetilde{\Phi}_i(\vy,\mu_1)-\widetilde{\Phi}_i(\vy,\mu_2)|\leq \kappa(\mu_1-\mu_2)$.
\end{lemma}


\begin{lemma}
	\label{lem:distancemu} 
	Suppose Assumptions \ref{ass:problemsetup}--\ref{ass:lk} hold,and $\mathcal{Z}$ is continuous compact. There exists $C_0\ge 2 \log(|\cal{Z}|)$ 
	such that  $|\widetilde{\Phi}_i(\vy,\mu_1)-\widetilde{\Phi}_i(\vy,\mu_2)|\leq \frac{C_0}{\mu_2}(\mu_1-\mu_2)$ for any $\vy\in\dom(\varphi)$, $0<\mu_1\le 1$, $\frac{1}{2}\mu_1\leq \mu_2\leq  \mu_1$, and all $i\in[n]$.
\end{lemma}

Based on the smoothing function in \eqref{eq:smoothphi}, we introduce a ``smoothing'' problem of \eqref{eq:minmax} as follows:
\begin{equation}
	\label{eq:smootho}
	\min_{\vy} \left\{\widetilde{g}(\vy, \mu) := \varphi(\vy) + \frac{1}{n} \sum_{i=1}^n \widetilde{\Phi}_i(\vy, \mu)\right\}.
\end{equation}


\begin{definition}[$\epsilon$-scaled stationary point \cite{bian2013worst,bian2015linearly}]\label{def:scaled-stat}
	We call $\vy^*\in\dom(\varphi)$ an $\epsilon$-scaled stationary point of problem \eqref{eq:minmax} in expectation, if it holds $\mathbb{E}[(\dist(0, \partial\widetilde{g}( \vy^*,\mu)))^2]\leq \epsilon^2$, for some $0< \mu \leq \epsilon$.
\end{definition}

Below we give our main theorem in this subsection. Its proof is given in Section \ref{sec:scaled}.

\begin{theorem}[Almost surely convergence to a directional stationary point]
	\label{lem:scaled}
	Suppose Assumptions~\ref{ass:problemsetup}--\ref{ass:lk} hold.
	Let a sequence $\{\epsilon_k\}$ with $\sum_{k=0}^{\infty}\epsilon^2_k<+\infty$ ,
	and $\{\vy^{(k)}\}\subset \dom(\varphi)$ be given, such that $\vy^{(k)}$ is an $\epsilon_k$-scaled stationary point of problem \eqref{eq:minmax} in expectation. 
	There exists $\{\mu_k\}$ such that $0<\mu_k\le \epsilon_k$ for all $k\ge 0$, and
	%\remove{It then holds that} \comm{Restate the results by using $\dist(\vzero, ...)$. $\vgamma$ is not defined here.}
	\begin{equation}
		\label{eq:almost}
		\lim_{k\rightarrow \infty}\dist(0, \partial\widetilde{g}( \vy^{{(k)}},\mu^{{(k)}})) =0, \text{ almost surely}.
		%\remove{\lim_{k\rightarrow \infty}\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{\Phi}_i( \vy^{(k)},\mu_{k})+ \vgamma_{\vy}^{{(k)}}\right\|=0, \text{ almost surely}.}
	\end{equation}
	Moreover, if there is a subsequence $\{\vy^{(j_k)}\}$ almost surely converging to $\vy^*$,     
	then $\vy^{*}$ 
	is a directioanlly stationary point of problem~\eqref{eq:minmax} almost surely.  
\end{theorem}
Based on Theorem \ref{lem:scaled}, we can pursue an 
$\epsilon$-scaled stationary point of problem \eqref{eq:minmax}  in expectation, in order to identify a directionally stationary point.


\subsection{SSPG and Its Convergence Results}
\label{sec:conver2}
In this subsection, we present our proposed stochastic smoothing proximal gradient (SSPG) method for solving \eqref{eq:minmax}. %As stated in Section \ref{sec:intro}, 
When $n$ is large, accessing all 
$n$ samples at each iteration becomes computationally expensive. %\remove{This is a challenge that the existing literature has not addressed.}
To overcome this challenge, %we now adopt an SSPG approach by applying stochastic methods to  the
%$\vx$  part. Specifically, 
at each iteration of SSPG, we choose
$m$ samples $\{\vx_{i_1},\vx_{i_2}, \ldots, \vx_{i_m}\}$ uniformly at random without replacement %, i. i. d., 
from $\{\vx_1,\vx_2,\ldots,\vx_n\}$. 
In addition, %sampled index $i_j$, 
%computing the exact gradient of $\widetilde{\Phi}_i$ may still be computationally intensive. Instead,  
we assume the availability of stochastic gradient estimators $\{\mathcal{G}_i\}$ %(\vy^{(k)},\mu_{k})$ 
that satisfy
\begin{equation}
	\label{eq:gradinetbias2}
	\mathbb{E} \left[\|\mathcal{G}_i(\vy^{(k)},\mu_{k}) - \nabla_{\vy} \widetilde{{\Phi}}_i( \vy^{(k)},\mu_{k})\|^2\right]\leq \widehat{\epsilon}_k^2, \text{ for all }i\in[n],
\end{equation}
for some scalar $\widehat{\epsilon}_k\geq 0$ and all $k\ge 0$.
The $m$ sampled stochastic gradient estimates are then aggregated to form an overall estimator:
\begin{align}
	\label{eq:gradinetg}
	\mathcal{G}(\vy^{(k)},\mu_{k}) = \frac{1}{m} \sum_{j=1}^m\mathcal{G}_{i_j}(\vy^{(k)},\mu_{k}).
\end{align}
We proceed with a proximal gradient update step, followed by updating the value of \( \mu \) according to a predefined nonincreasing rule. The algorithmic framework is given in Algorithm \ref{alg:spg2}. %This strategy reduces the computational cost per iteration while still ensuring convergence. 

\begin{algorithm}[htbp!]
	\caption{A \textbf{s}tochastic \textbf{s}moothing \textbf{p}roximal \textbf{g}radient (SSPG) method for solving \eqref{eq:minmax}
	}
	\label{alg:spg2}
	\begin{algorithmic}[1]
		\State{Initialization: choose $\vy^{(0)}\in\dom(\varphi)$, $\mu_0>0$, a positive sequence $\{\widehat\epsilon_k\}_{\epsilon=0}^K$, and $K>0$}.
		\For{{$k=0,1,\ldots, K$} }
		\State\label{line323}
		Let $\alpha_k>0
		$
		be a stepsize, and $\mathcal{G}(\vy^{(k)},\mu_{k})$ is given in \eqref{eq:gradinetg}.
		Update $\vy$ by 
		\begin{equation}
			\label{eq:updatex2}
			\vy^{(k+1)} = \operatorname{Prox}_{\alpha_k\varphi} \left(\vy^{(k)}- {\alpha_k}{} \mathcal{G}(\vy^{(k)},\mu_{k}) \right).
		\end{equation}
		
		
		\State\label{line423}
		Choose $\mu_{k+1}\le \mu_k$.
		%Update the smoothing parameter $\mu_{k+1}$ according to a predefined nonincreasing rule.
		\EndFor
	\end{algorithmic}
\end{algorithm}



\begin{remark}
	\label{rem:exact}
	We make a few remarks regarding the feasibility of establishing the condition in \eqref{eq:gradinetbias2}. %It can be satisfied for several scenarios. 
	First, if the set \(\mathcal{Z}\) is finite, the exact value of \(\nabla_{\vy} \widetilde{\Phi}_i(\vy^{(k)}, \mu_{k})\) can be calculated, ensuring \(\widehat{\epsilon}_k = 0\).
	This situation is common in Wasserstein distributionally robust optimization (WDRO) where a discrete grid is used to approximate the entire sample space
	\cite{xu2018distributionally,chen2021decomposition,liu2021discrete,pflug2007ambiguity}. 
	Second, if for all $i\in[n]$, the expectation \(\mathbb{E}_{\vz\sim \zeta}e^{\Psi(\vy, \cdot; \vx_i)/\mu}\) can be computed, 
	we can generate samples to approximate the expectation  \(\mathbb{E}_{\vz\sim \zeta}e^{\Psi(\vy, \cdot; \vx_i)/\mu}\nabla_{\vy}\Psi(\vy, \cdot; \vx_i)\). By doing so, we can generate an unbiased stochastic gradient estimator of \(\nabla_{\vy} \widetilde{\Phi}_i(\vy^{(k)}, \mu_{k})\). This approach is feasible in some specific cases, as detailed in Appendix~\ref{appen:piece}. Lastly, 
	if we can obtain an approximate maximizer of problem \(\max_{\vz\in\mathcal{Z}} \Psi(\vy, \vz; \vx_i)\) for all $i\in[n]$, we can efficiently construct such a stochastic gradient estimator, as detailed in Appendix \ref{sec:sample}. Several conditions can ensure the computation of an approximate maximizer, such as (strong) concavity assumed in \cite{lin2020near, thekumparampil2019efficient, nouiehed2019solving, kong2021accelerated}, PL/KL conditions assumed in \cite{yang2020global, yang2022faster, li2022nonsmooth}, and a subdifferential error bound condition. We emphasize that even under these conditions, our algorithm is new and our theoretical results are novel. We do not assume smoothness of \(\Psi(\vy, \cdot; \vx_i)\) which is required in \cite{lin2020near, thekumparampil2019efficient, nouiehed2019solving, yang2020global, yang2022faster, li2022nonsmooth}; also, we guarantee convergence to a directional stationary point, a result that has not been achieved in existing works for solving nonconvex-nonconcave minimax
	problems. 
\end{remark}


The following lemma will be used for establishing the convergence results of Algorithm~\ref{alg:spg2}.  
Its proof is given in Section~\ref{sec:alg3}.  

\begin{lemma}\label{lem:alg3}
	Suppose Assumptions \ref{ass:problemsetup}--\ref{ass:lk} hold.
	Let $\{ \vy^{(k)}\}$ and $\{\mu_k\}$ be the sequences generated by Algorithm~\ref{alg:spg2} with $m= \min \{\lceil 4l_{\Psi}^2 \widehat{\epsilon}_k^{-2}\rceil, n\}$ and $\alpha_k=  \frac{\mu_k}{C_2}$  for all $k\in[K]$, where $C_2=L_{\Psi}\mu_0+2l^2_{\Psi}$.
	Then, {for all $k\in[K-1]$,} %\remove{the following statements hold:}
	\begin{enumerate}
		\item[\textnormal{(a)}] %\revise{$\vy^{(k+1)}\in\dom(\varphi)$}, 
		the sequence \(\left\{ \widetilde{g}( \vy^{(k)},\mu_k)\right\}\) satisfies 
		\begin{equation}
			\label{eq:funcgap2}
			\mathbb{E}\left[\widetilde{g}( \vy^{(k+1)},\mu_k)- \widetilde{g}( \vy^{(k)},\mu_k)\right]   \leq 
			-\frac{L^{(k)}}{4} \mathbb{E} \left[\| \vy^{(k+1)}- \vy^{(k)}\|^2\right] + \frac{4}{ L^{(k)}}\widehat{\epsilon}_k^2;
		\end{equation}
		\item[\textnormal{(b)}] and it holds %\remove{There exists a vector $\vgamma_{\vy}^{(k+1)}\in \partial \varphi(\vy^{k+1})$ such that}
		\begin{equation}\label{eq:kktregu2}		
			\begin{aligned}
				\mathbb{E}\left[\left(\dist\left(\vzero, \partial\widetilde{g}( \vy^{(k+1)},\mu_k)\right)\right)^2\right]  %\remove{\leq}  & \remove{\mathbb{E} \left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k+1)},\mu_k)+  \vgamma_{\vy}^{{(k+1)}}\right\|^2\right]} \\ 
				\leq %&  
				18 L^{(k)} \mathbb{E} \left[\widetilde{g}( \vy^{(k)},\mu_k)- \widetilde{g}( \vy^{(k+1)},\mu_k)\right] +  {112}{}\widehat{\epsilon}_k^2.%= O(\mu_k^{\sigma_2-1/2} ).		
			\end{aligned}
		\end{equation}
	\end{enumerate}
\end{lemma}

Now we are ready to present the main convergence rate result.  
The proof  is given in Section~\ref{sec:scaled2}.

\begin{theorem}[Stationarity violation bound]
	\label{thm:scaled2}
	Suppose Assumptions \ref{ass:problemsetup}--\ref{ass:lk} hold. Let $0<\epsilon<1$,  and $K> k_1 \ge 0$ be given. Set $m= \min \{\lceil 4l_{\Psi}^2 \widehat{\epsilon}_k^{-2}\rceil, n\}$, and  $\alpha_k=  \frac{\mu_k}{C_2}$ for all $k\in[K]$, where $C_2=L_{\Psi}\mu_0+2l^2_{\Psi}$.
	%\remove{Define $\mathbf{x}^{(\tau)}$ with} 
	Let~$\tau$ be randomly sampled from $\{k_1,k_1+1,\ldots,K-1\}$ with probability  $\operatorname{Prob}(\tau=k)=\frac{\mu_k}{\sum_{t=k_1}^{K-1}\mu_t}$. 
	Then, %\remove{the  iterates generated by Algorithm \ref{alg:spg2} satisfy}
	\begin{align}
		\notag
		&%\min_{k\in\{k_1, k_1+1,\ldots, K-1\}} 
		\mathbb{E}\left[\left(\dist\left(0, \partial\widetilde{g}( \vy^{(\tau+1)},\mu_{\tau})\right)\right)^2\right]
		\\\leq &  
		\frac{18 C_2 \mathbb{E} \left[\widetilde{g}( \vy^{(k_1)},\mu_{k_1})- \widetilde{g}( \vy^{(K)},\mu_{K-1}) \right] }{\sum_{k=k_1}^{K-1} {\mu_k}} + \frac{18\sum_{k=k_1}^{K-2}  \frac{C_0C_2}{\mu_{k+1}} \left(\mu_{k}- \mu_{k+1}\right)}{\sum_{k=k_1}^{K-1} {\mu_k}} +  \frac{112\sum_{k=k_1}^{K-1} { \mu_k}{ } \widehat{\epsilon}_k^2}{\sum_{k=k_1}^{K-1} {\mu_k}},
		\label{eq:expectationsta}
	\end{align}
	where $C_0$ is given in Lemma \ref{lem:distancemu}.
\end{theorem}

%\remove{In practical implementations, t}
There are multiple strategies for selecting \(\widehat{\epsilon}_k\) and \(\mu_k\). 
%\commwei{$\Theta$ has been used in (1.5).}
Typically, we set $\widehat{\epsilon}_k$ %=\Theta(\epsilon)$. 
in the same order as $\epsilon$. For~$\mu_k$, it can %\remove{either} 
be kept constant, decay %\remove{ed}
over %\remove{time}
$k$, or be updated based on the difference between the objective function values at two consecutive iterations; see \eqref{eq:munews} in Section~\ref{sec:news}.  
As long as the right-hand side of \eqref{eq:expectationsta} is less than \(\epsilon^2\) {and $\mu_\tau\le \epsilon$}, we %\remove{can achieve} 
{claim that $\vy^{\tau+1}$ is} an \(\epsilon\)-scaled stationary point {in expectation}. Below, we present two corollaries detailing specific choices for \(\widehat{\epsilon}_k\) and \(\mu_k\), along with an analysis of the computational complexity required by %\remove{Algorithm} 
Algorithm~\ref{alg:spg2} to obtain an \(\epsilon\)-scaled stationary point. 
Their proofs are given in Section \ref{sec:cor}.

\begin{corollary}
	\label{cor:main1}
	Under the same assumptions of Theorem \ref{thm:scaled2},
	set $k_1 =0$, $\widehat{\epsilon}_k =  {\epsilon}/16$, and $\mu_k=\epsilon$ for all $k\in[K]$
	with $K=  \left\lceil 
	36C_2 \epsilon^{-3} 
	\widetilde{g}( \vy^{(0)},\epsilon)- \min_{\vy}\widetilde{g}( \vy,\epsilon)   
	\right\rceil$.
	Then, Algorithm \ref{alg:spg2} outputs a point~$\vy^{(k)}$ satisfying 
	$
	\mathbb{E}\left[\left(\dist\left(0,    \partial\widetilde{g}( \vy^{(k+1)},\mu_k)\right)\right)^2\right] \leq \epsilon^2
	$
	with $\mu_{k}= \epsilon$ for some $0\leq k<K$.
	The total number of iterations required is \(O(\epsilon^{-3})\). % and the total sample complexity would be \(O(\min\{n,\epsilon^{-2}\}\epsilon^{-3})\).
\end{corollary}

\begin{corollary}
	\label{cor:main2}
	Under the same assumptions of Theorem \ref{thm:scaled2},
	set $k_1= \lceil \epsilon^{-3} \rceil$, $\widehat{\epsilon}_k =  {\epsilon}/16$,  and $\mu_{k}=(k+1)^{-1/3}$ for all $k\in[K].$  
	Starting from $k=k_1 $, Algorithm \ref{alg:spg2} outputs $\vy^{(k)}$ satisfying 
	$
	\mathbb{E}\left[\left(\dist\left(0,    \partial\widetilde{g}( \vy^{(k+1)},\mu_k)\right)\right)^2\right] \leq \epsilon^2
	$ in no more than \(O(\epsilon^{-3}\log(\epsilon^{-1}))\) iterations. %The total sample complexity would be \(\widetilde{O}(\min\{n,\epsilon^{-2}\}\epsilon^{-3})\).
\end{corollary}


\begin{remark}
	\label{rem:23}
	Let $\Delta = l_{\Psi} D$, where $D$ refers to the diameter of $\dom(\varphi)$. Since  $\|\nabla_{\vy} \widetilde{\Phi}_i(\vy,\mu)\|\leq l_{\Psi}$ for all $\vy\in\dom(\varphi)$ and $\mu>0$, we have $\widetilde{g}( \vy^{(k_1)},\mu_{k_1})- \min_{\vy,\mu\in(0,1]}\widetilde{g}( \vy,\mu) \leq \Delta $.
	By choosing $\widehat\epsilon_k = \mu_k/16$, we iteratively refine our approximations to the stationary point of problem~\eqref{eq:minmax}. 
	We construct a sequence $\{k_t\}$ via $k_1=0$, and $k_{t+1} = k_t + \lceil 
	36C_2 t^3 \Delta\rceil$ for all $t\ge 0$.
	We set $\mu_{k}=\frac{1}{t}$ for all $k_t\leq k < k_{t+1}$.
	According to Corollary~\ref{cor:main1}, we obtain an $\epsilon_t=\frac{1}{t}$-scaled stationary point $\vy^{(t)}$ in expectation between iterations $k_t$ and $k_{t+1}$.
	Since $\sum_{t=0}^{\infty}\epsilon^2_t= \sum_{t=0}^{\infty}\frac{1}{t^2}<+\infty$,
	Theorem \ref{lem:scaled} implies that 
	any accumulation point of the sequence $\{\vy^{(t)}\}$ is almost surely a directionally stationary point of problem~\eqref{eq:minmax}.  
\end{remark}







%\input{WDRO}
	
%%%%%%%%%%%%%%%%%%%
% Wasserstein 
%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%
% NUMERICAL 
%%%%%%%%%%%%%%%%%%%


%Suppose that we have obtained a $\epsilon$ directional stationary point $\vtheta^*$ of problem $\mih_{\vtheta}\max_{\vz\in\mathcal{Z}} \ell(\vtheta,\vz)$, we have 
%\begin{equation}
%	\max_{\vz\in s_1(\vtheta^*)}\left\{d\zz \nabla_{\vtheta} f(\vtheta^*, \vz )\right\}\geq -\epsilon, \forall d \text{ satisfying } \|d\|=1,
%\end{equation}
%where $s_1(\vtheta^*)=\argmax_{\vz\in\mathcal{J}} f(\vtheta^*,\vz)$. Here, $\mathcal{J}$ is an approximate finite set of $\mathcal{Z}$. Specifically, for any $\bar{\vz}\in\mathcal{Z}$, there exists $\vz\in\mathcal{J}$ such that $\|\vz-\bar{\vz}\|\leq \epsilon$.

%Let $\widehat{s}(\vtheta^*):=\max_{\vz\in\mathcal{Z}} f(\vtheta^*,\vz)$. From the above relation, we can obtain that 
%\begin{equation}
%	\max_{\vz\in s_3(\vtheta^*)}\left\{d\zz \nabla_{\vtheta} f(\vtheta^*, \vz )\right\}\geq -\epsilon, \forall d \text{ satisfying } \|d\|=1,
%\end{equation}
%where $s_3(\vtheta^*)=\{\vz: f(\vtheta^*,\vz) \geq \widehat{s}(\vtheta^*) - L\epsilon \}$, where $L$ is the gradient Lipschitz of $f$.

%However, we cannot obtain the following inequality 
%\begin{equation}
%	\max_{\vz\in s_2(\vtheta^*)}\left\{d\zz \nabla_{\vtheta} f(\vtheta^*, \vz )\right\}\geq -O(\epsilon), \forall d \text{ satisfying } \|d\|=1,
%\end{equation}
%where $s_2(\vtheta^*)=\argmax_{\vz\in\mathcal{Z}} f(\vtheta^*,\vz)$.


\section{Numerical Experiments}\label{sec:numerical}

%\commwei{Please check notations}

In this section, we demonstrate the utility and applicability of Algorithm~\ref{alg:spg2} and compare it with two existing methods:  SDRO \cite{wang2021sinkhorn} and Gradient Descent with Maximization Oracle (GDMax) \cite{jin2020local}.
We explore three applications %in the  WDRO
{within the WDRO framework}: the newsvendor problem, the regression problem, and the adversarial deep learning problem. All the numerical experiments are conducted using Python, with  details provided in Table \ref{tab:python-libraries-processor-info}. 
We implement both SSPG and GDMax %and our methods, we 
to solve problem \eqref{eq:model2},
%, i.e., %\comm{no need to rewrite the problem formula}
%\begin{equation}\label{eq:gda}
%	\min_{\lambda \geq 0, \vtheta}  \ \lambda \delta^{p} + \mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}[\max_{\vz \in \mathcal{Z}} \{\ell(\vtheta, \vz) -  \lambda  d(\vx,\vz)\}],
%\end{equation}
%where the code is implemented by us.
%
%\red{SSPG/SSPG:
	%	\begin{equation}\label{eq:spg}
		%		\min_{\lambda \geq 0, \vtheta}   \ \ \widetilde{g}(\vtheta, \lambda) =  \ \lambda \delta^{p} + \mu \mathbb{E}_{\vx \sim \widehat{\mathbb{P}}}\{\text{log}  \mathbb{E}_{\vz}   [ e^{\frac{[\ell(\vtheta,\vz) - \lambda d(\vx,\vz)]}{\mu}}]   \}.
		%\end{equation}}
		%
		%\commwei{Change $\eta$}
		%In 
		{while for SDRO, we build on the code from GitHub\footnote{\url{https://github.com/WalterBabyRudin/SDRO_code}} to solve problem \eqref{eq:smoothg}. 
			%the implementation \red{GMB: should we add ``for solving~\eqref{eq:smoothg}''?}}.
		%i.e., \comm{no need to rewrite the problem formula}
		%\begin{equation}\label{eq:sdro}
		%	\mih_{\vtheta} \ \lambda \delta^{p} + \lambda \eta \mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\{\text{log}  \mathbb{E}_{\vz \sim \zeta}   [ e^{\frac{[\ell(\vtheta,\vz) - \lambda d(\vx,\vz)]}{\lambda \eta}}]   \}.
		%\end{equation}
		% The implementation of SDRO in~\cite{wang2021sinkhorn} can be downloaded from Github\footnote{\url{https://github.com/WalterBabyRudin/SDRO_code}}. 
		The specific parameter values for each method are introduced separately in the following subsections for each application.
		
		\begin{table}[ht]
			\centering
			\renewcommand{\arraystretch}{1.5} % Adjust the vertical spacing here
			\resizebox{\textwidth}{!}{%
				\Large % Adjust font size here
				\begin{tabular}{|>{\centering\arraybackslash}m{1.0\textwidth}|>{\centering\arraybackslash}m{1.0\textwidth}|}
					\hline
					\textbf{Problem Type} & \textbf{Processor Info} \\ \hline
					Newsvendor (Section \ref{sec:news}) and regression problem (Section \ref{sec:regre}) & 12th Gen Intel(R) Core(TM) i5-1240P with 8GB RAM \\ \hline
					Adversarial robust deep learning problem (Section \ref{sec:adversial}) & NVIDIA Ampere A100 GPU with 80 GB RAM\\ \hline
				\end{tabular}%
			}
			\caption{Processor information}
			\label{tab:python-libraries-processor-info}
		\end{table}
		\subsection{Newsvendor Problem}\label{sec:news} 
		The newsvendor problem, which models the expected profit of a retailer under uncertain demand, takes the form of problem \eqref{eq:model}. In this subsection, we consider solving problems \eqref{eq:model2} and \eqref{eq:smoothg} with
		\begin{equation}\label{eq:newsvendor}
			\ell(\theta, x) = v\theta - u\min(\theta,x)\quad\text{and}\quad d(x,z) = \frac{1}{2} (x - z)^{2},
		\end{equation}
		where  $\theta \in \mathbb{R}_+$ {represents the inventory level, $x \in \mathbb{R}$ denotes the demand, $v = 5$ is the underage cost,  and $u = 7$ is the overage cost. To ensure that the inner maximization problem has a finite solution, we set $\lambda \geq 7$, as required in \cite{lee2021data}.
			
			%\red{GMB: I am partial to removing subsection headings such as \textbf{Problem parameters:} since I do not think it fits the style of the rest of the paper, but I leave it up to the rest of you to decide what to do. Whatever is decided here should be followed in the below sections.}
			
			\textbf{Problem parameters:} We synthetically generate five different demand datasets, each consisting of $n=100$ independent samples drawn from an exponential distribution with rate parameter 1.
			We set $\delta = 1$ and $p = 2$.
			For each dataset {$X_{\mathrm{train}}$}, the empirical distribution $\widehat{\mathbb{P}}_{n}$ is constructed from these~$n$ samples for each dataset; the support set is given as $\mathcal{Z}=
			\{x:\min (X_{\mathrm{train}})\le x\le\max(X_{\mathrm{train}})\}$. %\mathcal{Z} = [\min (X_{\mathrm{train}}),\max(X_{\mathrm{train}})]$
			
			
			\textbf{Algorithm parameters:}
			For all the methods, we use the initial $\theta^{(0)}\sim \mathcal{U}(0, 1)$ on all five datasets, where $\cU$ denotes the uniform distribution. %by the uniform distribution on $[0,1]$. %\commwei{How do we initialize $\theta$?}.
			In addition, for GDMax and SSPG, we use the same $\lambda^{(0)}  \sim \mathcal{U}(7, 15)$ on all five datasets. %where \revise{ $\mathcal{U}(7,15)$ denotes the} \commwei{what is $\mathcal{U}$? }.
			For SSPG, we set $\mu_0 = \lambda^{(0)}  \eta$, where $\eta \sim \mathcal{U}(0.1, 1)$. 
			Following \cite{wang2021sinkhorn}, we use a grid search for SDRO to fine-tune the hyperparameters $\lambda$ and~$\eta$ from the sets \{7, 10, 15\} and \{0.1, 0.5, 1\}, respectively.
			Each method is terminated after 1000 iterations.  
			
			
			\textbf{Implementation of the compared methods at the $k$th iteration:}
			For each method, at iteration $k$, we solve several inner maximization problems to obtain $\{z_i^{(k+1)}\}_{i=1}^n\subset \RR $.
			Specifically, for each $i\in\{1,2,\ldots,n\}$, we solve problem $\max_{z \in \cZ} \ell(\theta^{(k)}, z) - \lambda^{(k)} d(x_i, z)$ using the projected gradient ascent with a fixed step size of~$10^{-2}$ for 20 iterations, starting from $\mathrm{Proj}_{{\mathcal{Z}}}(x_i + 10^{-3}s)$ where $s$ follows a standard normal distribution. %\commwei{which $\vz$?}.
			After obtaining $\{z_i^{(k+1)}\}_{i=1}^n$, GDMax  performs a projected gradient descent step on the primal variable $(\theta,\lb)$ using the gradient $\nabla_{(\theta,\lb)}\frac{1}{n}\sum_{i=1}^n\left[\lb^{(k)}\delta^p+\ell(\vtheta^{(k)},z_i^{(k+1)})-\lambda^{(k)} d(x_i,z_i^{(k+1)})\right]$ and a fixed learning rate of $0.1$.
			
			For SSPG and SDRO, for all $i\in\{1,2,\ldots,n\}$, we generate sets $\Omega_i^k$ of size $M=32$, containing samples near~$z_i^{(k+1)}$. For any $\widehat{z}\in\Omega_i^k$, we set \( \widehat{z} = \mathrm{Proj}_{{\mathcal{Z}}}(z_i^{(k+1)} + s^{(k+1)}) \) with \( s^{(k+1)} \sim \mathcal{N}(0, 10^{-1}) \).} 
		SDRO then performs a projected gradient descent step on  $\theta$ with gradient $\nabla_{\theta}{g}_s^k(\theta^{(k)},\lb)$ and a fixed learning rate of~$0.1$, where 
		\begin{align}
			\label{eq:gradientgsk}
			{g}_s^k( \theta,\lb) = \lambda \delta^{p} + \lb\eta \frac{1}{n}\sum_{i=1}^n\left[ \text{log} \left(\frac{1}{M} \sum_{\widehat{z}\in\Omega_i^k}  \left[ e^{\frac{\ell(\theta, \widehat{z}) - \lambda d(x_i, \widehat{z})}{\lb\eta}} \right] \right)\right].
		\end{align}
		Our SSPG method similarly conduct a projected gradient descent step on $(\theta,\lb)$ with $\nabla_{(\theta,\lb)}\widetilde{g}^k( \theta^{(k)},\lb^{(k)} , \mu_k)$ and a fixed learning rate of $0.1$, where 
		\begin{align}
			\label{eq:gradientgtildek}
			\widetilde{g}^k(\theta,\lb,\mu) = \lambda \delta^{p} + \mu \frac{1}{n}\sum_{i=1}^n\left[ \text{log} \left(\frac{1}{M} \sum_{\widehat{z}\in\Omega_i^k}  \left[ e^{\frac{\ell(\theta, \widehat{z}) - \lambda d(x_i, \widehat{z})}{\mu}} \right] \right)\right].
		\end{align}
		We then update $\mu$ by 
		\begin{equation}\label{eq:munews}
			\mu_{k+1} = \left\{
			\begin{aligned}
				& \mu_k, \hspace{2.7cm} \text{ if }  
				\widetilde{g}^k( \theta^{(k+1)},\lb^{(k+1)}, \mu_k) - \widetilde{g}_k( \theta^{(k)}, \lb^{(k)},\mu_k)< -\mu_k^{2\sigma_2}, \\
				&\max\{\sigma_1 \mu_k, 10^{-4}\mu_{0}\}, \,\,\, \text{otherwise},
			\end{aligned}
			\right.
		\end{equation}
		with $\sigma_{1} = 0.99$, $\sigma_{2} = 0.5$. 
		
		
		
		
		
		
		
		
		
		\begin{figure}
			\centering
			\begin{subfigure}{0.4\textwidth}
				\centering
				\includegraphics[width=\linewidth]{./fig/g_theta_lambda.png}
				\caption{$g(\theta, \lambda)$}
				\label{fig:sub2}
			\end{subfigure}
			~~~~
			\begin{subfigure}{0.4\textwidth}
				\centering
				\includegraphics[width=\linewidth]{./fig/lambda_iterates.png}
				\caption{$\lambda$ iterates}
				\label{fig:sub1}
			\end{subfigure}
			%\hfill
			\caption{Comparison of $g(\theta,\lambda)$ and $\lb$  among SSPG, GDMax, and SDRO for solving the newsvendor problem.}
			\label{fig:overall}
		\end{figure}
		
		\textbf{Performance comparisons:} 
		Figure~\ref{fig:overall}(a) presents the mean and standard deviation of \( g(\theta, \lambda) \) over iterations for SSPG, GDMax, and SDRO across the five training sets. This figure demonstrates that SSPG achieves lower values of \( g(\theta, \lambda) \) compared to GDMax and SDRO, illustrating the advantage of employing a smoothing technique and dynamically updating \(\lambda\) and \(\mu\) for solving the newsvendor problem. Figure \ref{fig:overall}(b) shows the mean and standard deviation of \( \lambda \).
		It reveals that SSPG and GDMax quickly converge to values of 7, while SDRO maintains a fixed \(\lambda = 7\).
		This choice arises from a grid search indicating that the pair \(\lambda = 7, \eta=0.1\)  yields the best performance among the tested configurations for  SDRO. 
		%\commwei{It is wield that that Figure \ref{fig:overall}(b) shows the mean and standard deviation of \( \lambda \), since we initialize $\lambda^{(0)}  \sim \mathcal{U}(7, 15)$. Is 15 the deviation?}
		
		
		\subsection{{Regression Problem}}\label{sec:regre}
		The distributionally robust regression problem aims to find a robust solution to the standard regression problem by minimizing the worst-case risk. 
		In this subsection, we consider problems \eqref{eq:model2} and \eqref{eq:smoothg} with
		\begin{equation}\label{eq:ell-d-func}
			\ell(\vtheta,\vx) = (h_{\vtheta}(\va) - b)^{2}, \text{ and }d(\vx,\vz) = d((\va, b), (\overline{\va}, \overline{b})) = \frac{1}{2} \|\va - \overline{\va}\|_{2}^{2} + \infty |b - \overline{b}|,
		\end{equation}
		where $h_{\vtheta}: \mathbb{R}^{m_2-1} \to \mathbb{R}$ is a small {neural network} parameterized by $\vtheta$, $\vx = (\va, b)$, $\vz = (\overline{\va}, \overline{b})$ with $\va, \overline{\va} \in \mathbb{R}^{m_2-1}$ representing a vector of features and  $b, \overline{b} \in \mathbb{R}$ denoting a target. 
		Specifically, 
		we employ a neural network with a single hidden layer containing three neurons, using the ReLU activation function~\cite{goodfellow2016deep}. %{\color{red}GMB: why only 3?}
		The $\infty$ before $|b - b{'}|$ means that there is no uncertainty in the target variable.
		
		
		\textbf{Problem parameters:} 
		We set $\delta = 10$ and $p = 2$.
		For each dataset {$X_{\mathrm{train}}$}, the empirical distribution~$\widehat{\mathbb{P}}_{n}$ is constructed from these~$n$ samples for each dataset; the support set is given as $\mathcal{Z} = \widetilde{\mathcal{Z}} \times \mathbb{R}$ with~$\widetilde{\mathcal{Z}}~=~\prod_{j=1}^{m_2-1} [ \min([X_{\text{train}}]_{\cdot,j}), \max([X_{\text{train}}]_{\cdot,j}) ]$.  %, namely, no uncertainity on the target variable $b$.
		
		\textbf{Datasets:}
		We consider three real-world datasets, \verb|Space GA|, \verb|BodyFat|, and \verb|MG|, from the LIBSVM repository\footnote{\url{https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression.html}}.  
		Each dataset, containing 
		$n$ data points, is randomly partitioned into training (80\%) and testing (20\%) sets using \verb|train_test_split| from \verb|Scikit-learn|\footnote{Documentation available at: \url{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html}}, 
		ensuring that the original data distribution is preserved. The resulting training sets and test sets are 
		$X_{\text{train}} \in \mathbb{R}^{\lfloor 0.8 \times n \rfloor \times (m_2-1)}$ and $ X_{\text{test}} \in \mathbb{R}^{\lceil 0.2 \times n \rceil \times (m_2-1)}$, respectively.
		The testing set is further normalized using  \verb|StandardScaler|\footnote{Documentation available at: \url{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing. StandardScaler.html}}. To ensure fair comparisons, we employ five distinct random seeds for data preparation, including splitting, scaling, and initialization, ensuring identical dataset configurations across all three methods.
		
		%To ensure a fair and unbiased comparison of the algorithms, the experiment employs five distinct random seeds for initializing the data preparation process. This includes splitting and scaling of the training and testing sets. Additionally, these seeds are used to maintain consistent initialization across all three algorithms. By using the same seeds, we ensure that each algorithm is tested on identically prepared and initialized datasets.
		
		
		
		\textbf{Algorithm parameters:} 
		For all the methods, we initialize $\theta^{(0)}$ by the default setting of \verb|pytorch|. %\commwei{How do we initialize $\theta$?}.
		In addition, for GDMax and SSPG, we let $\lambda^{(0)}  \sim \mathcal{U}(1, 10)$.
		For SSPG, we set $\mu_0 = \lambda^{(0)}  \eta$, where $\eta \sim \mathcal{U}(0.1, 1)$. 
		Following \cite{wang2021sinkhorn}, we utilize a grid search for SDRO to fine-tune the hyperparameters $\lambda$ and $\eta$ from the sets \{1, 5,10\} and \{0.1, 0.5, 1\}, respectively.
		For each comparison method, the training is terminated after 500 epochs.
		
		\textbf{Implementation of the compared methods at the $k$th iteration:}
		For each method, at iteration~$k$, we conduct an inner maximization step to obtain 
		$\{\vz_i^{(k+1)}= (\overline{\va}_i^{(k+1)}, \overline{b}_i^{(k+1)})\}_{i=1}^{\lfloor 0.8 \times n \rfloor} \subset  \mathbb{R}^{m_2}$.
		Specifically, for each $i\in\{1,2,\ldots,\lfloor 0.8 \times n \rfloor\}$, we solve problem $\max_{\vz \in \cZ} \ell(\vtheta^{(k)}, \vz) - \lambda^{(k)} d(\vx_i, \vz)$ using the projected gradient ascent with a fixed step size of~$10^{-2}$ for five iterations, starting from $\vx_i + 10^{-3} \vs$ where $\vs$ follows the standard Gaussian distribution. %\commwei{which $\vz$?}.
		%Indeed, we have $\overline{b}_i^{(k+1)} = [\vx_i]_{m_2}$, due to the structure of $d$.
		Notice that by the definition of $d$ in \eqref{eq:ell-d-func}, we actually fix the last component of $\vz_i$ as the label corresponding to $\vx_i$.
		
		After obtaining $\{\vz_i^{(k+1)}\}_{i=1}^{\lfloor 0.8 \times n \rfloor}$, GDMax updates the the primal variable $(\vtheta,\lb)$ via  a projected gradient descent step with the gradient $\nabla_{(\vtheta,\lb)}\mathbb{E}_{\vx \sim \widehat{\mathbb{P}}_n}\left[\lb^{(k)}\delta^p+\ell(\vtheta^{(k)},\vz^{(k+1)})-\lambda^{(k)} d(\vx,\vz^{(k+1)})\right]$ and a fixed learning rate $\alpha>0$.
		For SSPG and SDRO, we generate, for each $i\in\{1,2,\ldots,\lfloor 0.8 \times n \rfloor\}$, a set $\Omega_i^k$ of size $M=32$, containing samples near~$\vz_i^{(k+1)}$. Specifically, for any $\widehat{\vz}\in\Omega_i^k$, we let \( \widehat{\vz} = \mathrm{Proj}_{{\mathcal{Z}}}(\vz_i^{(k+1)} + \vs^{(k+1)}),\) where it holds that $ \vs^{(k+1)} \sim [\mathcal{N}(0, 10^{-1})]^{m_2-1}\times \{0\}.$
		SDRO then performs a projected gradient descent step on  $\vtheta$ with gradient $\nabla_{\vtheta}{g}_s^k(\vtheta^{(k)},\lb)$ and a fixed learning rate of $\alpha$, where ${g}_s^k$ is given in \eqref{eq:gradientgsk} with $\widehat{z}$ replaced by $\widehat{\vz}$.
		Our SSPG method similarly applies a projected gradient descent step on $(\vtheta,\lb)$ with gradient $\nabla_{(\vtheta,\lb)}\widetilde{g}^k( \vtheta^{(k)},\lb^{(k)} , \mu_k)$ and a fixed learning rate $\alpha$, where  $\widetilde{g}^k$ is given in~\eqref{eq:gradientgtildek} with $\widehat{z}$ replaced by~$\widehat{\vz}$. We then update~$\mu$ by %, in the case of this particular problem, 
		\begin{equation}\label{eq:mu2}
			\begin{aligned}
				&\mu_{k+1} := \max\left\{10^{-4}\mu_{0},\left(k+1\right)^{-\frac{1}{3}}\mu_{0}\right\}.
			\end{aligned}
		\end{equation}
		For all compared methods, we select the learning rate $\alpha$ from the set
		$\{10^{-1}, 5 \times 10^{-1}, 10^{-2}, 5 \times 10^{-2}, 10^{-3}\}$. %The neural network is trained using SGD with a fixed learning rate corresponding to each selected value. 
		%{For GDMax, we compute \(\va^{\text{max}} \in \mathbb{R}^{\lfloor 0.8 \times n \rfloor \times (m_2-1)}\) 
			%by performing projected gradient ascent with a fixed step size of $10^{-2}$ for 5 iterations. The $i$-th row of $\va^{\text{max}}$ is obtained as an approximate solution of } {\color{red}GMB: It may be better to include the description at the $t$-th iterate to show which values are fixed here}
		%\textcolor{blue}
		%{\begin{align*}
				%\va^{\text{max}}_{i} &= 
				%\argmax_{\va \in \tilde{Z}} \ell(\vtheta, (\va, b)) - \lambda d(\vx_i, (\va, b))
				%\end{align*}}%\textcolor{blue}
				%{where $b$ is the target variable corresponding to the $i$-th datapoint $\vx_{i}$.
					%For SSPG and SDRO, we first obtain  \(\va^{\text{max}}\) %\( \left\{ z_{\text{max}}^{(k)} \right\}_{k=1}^{100} \) 
					%and then generate a set of samples \( \{ \va^{(t)}\}_{t=1}^{32} \)  %= \{z_{(i)}\}_{i=1}^{32}\) 
					%where \( \va_{i}^{(t)} = \mathrm{Proj}_{\widetilde{\mathcal{Z}}}(\va^{\text{max}}_i + \vs^{(t)}) \) %with \( \vs^{t} \sim \mathcal{N}(0, 10^{-1})^{m_2-1} \) $\forall i \in \{1,2, ..., \lfloor 0.8 \times n \rfloor\}$, to approximate the inner expectation.}
				%For GDMax, we compute \(\va_{\text{max}} = \left\{ \va_{\text{max}}^{(k)} \right\}_{k=1}^{B} \) by performing projected gradient ascent with a fixed learning rate of $10^{-2}$ for 5 iterations. In the case of SSPG and SDRO,to approximate the inner expectation, we first obtain  \( \left\{ \va_{\text{max}}^{(k)} \right\}_{k=1}^{B} \) and then generate a set of samples \( \{\{ \mathbf{a}_{(i)}^{(k)} \}_{k=1}^{\lfloor 0.8 \times N \rfloor}\}_{i=1}^{8}  = \{\va_{(i)}\}_{i=1}^{32}\) \ $\forall k \in \{1,2,..., \lfloor 0.8 \times N \rfloor\}$. Here, \( \mathbf{a}_{(i)}^{(k)} = \mathrm{Proj}_{\widetilde{\mathcal{Z}}}(\mathbf{a}_{\text{max}}^{(k)} + \vs_{(i)}) \), where \( \vs_{i} \sim \mathcal{N}(0, 1)^{q} \) .
				
				%For GDMax,  we numerically obtain \(\va_{\mathrm{max}}\) by solving the inner maximization problem for a fixed number of iterations prior to performing the update for $\vtheta$. For SSPG and SDRO, in order to approximate the inner expectation, we first  solve the inner maximization problem in \eqref{eq:model2} numerically to obtain \(\va_{\mathrm{max}}\) and then 
				%by step 1 of Algorithm \ref{alg:sampling}. 
				% generate $\va_{0} = \mathrm{Proj}_{\widetilde{\mathcal{Z}}}(\va + \vs)$ with $\vs \sim [\mathcal{N}(0, 10^{-3})]^{q}$. 
				%To solve the inner maximization problem, we use SGD with a fixed learning rate of $10^{-2}$ and 5 iterations. 
				
				
				
				
				
				
				\textbf{Performance comparisons:} 
				We measure model performance using the root mean square error (RMSE) and {overall training time.}  %{\color{red}GMB: Define computation time (i.e. only time spent computing gradients and updates, overall running time, etc) - if this value is not fair (meaning it is not measuring gradient computation time and algorithm updates only) we need to change this.}. 
				Each model is evaluated on a modified version of the test set. Specifically, for each data point $\vx=(\va, b)$ in the test set, 
				the feature vector 
				$\va$ is perturbed according to $\va+\upsilon \boldsymbol{\omega}\|\va\|_2$, %as recommended by \cite{wang2021sinkhorn}, 
				where $\upsilon = 2$ and $\boldsymbol{\omega} \sim [\text{Laplace}(0,1)]^{q}$~\cite{goodfellow2016deep}.
				For each random seed, we select the best learning rate $\alpha$ for SSPG and GDMax based on the lowest RMSE. For SDRO, we report results corresponding to the best-performing parameters
				$\alpha$, $\lambda$ and $\eta$.
				Finally, we report the mean value and standard deviation of RMSE and training time across five distinct random seeds for all compared methods, as shown in Table~\ref{tab:algorithms2}.
				From this table, we observe that SSPG achieves the lowest RMSE on two of the three datasets while also exhibiting smaller standard deviations, indicating superior error minimization and robust performance. SDRO, although it achieves the best performance on the \verb|MG| dataset, requires significantly longer runtime, limiting its practical advantage.
				Overall, SSPG is an effective method for minimizing prediction errors and ensuring consistent performance, rendering it a good choice for robust regression tasks across diverse data environments.
				
				%As seen in Table~\ref{tab:algorithms2}, SSPG %consistently
				%delivers the lowest RMSE values with smaller standard deviations across two datasets, demonstrating superior error minimization and enhanced precision.  
				%In contrast, while SDRO achieves better performance on the MG dataset, the higher computation time dampens the benefit. Overall, SSPG stands out as an effective method for minimizing prediction errors and ensuring consistent performance, rendering it a good choice for robust regression tasks across diverse data environments.
				%and computation time for the three algorithms %—SSPG, GDMax, and SDRO— 
				%across three datasets. %: Space GA, MG, and BodyFat. 
				%As seen in Table~\ref{tab:algorithms2}, SSPG consistently achieves the lowest RMSE values with lower standard deviations, across two of the three datasets, indicating both superior error minimization and higher precision in its predictions. This performance highlights SSPG's effectiveness in producing accurate and robust predictions across different data environments. %In comparison, while GDMax and SDRO also deliver good performance, their RMSE values are generally higher than those of SSPG. Overall, SSPG stands out as the most effective algorithm for minimizing prediction errors and ensuring consistent performance. It should be the preferred choice for regression tasks requiring the lowest RMSE and highest precision. While GDMax and SDRO also offer strong performance, they are better suited as secondary options depending on specific needs. %In comparison, while GDMax and SDRO also deliver good performance, their RMSE values are generally higher than those of SSPG. Overall, SSPG stands out as the most effective algorithm for minimizing prediction errors and ensuring consistent performance. It should be the preferred choice for regression tasks requiring the lowest RMSE and highest precision. While GDMax and SDRO also offer strong performance, they are better suited as secondary options depending on specific needs.
				
				
				
				%\begin{table}[htbp]
				%	\centering
				%	\begin{tabular}{l|cc|cc|cc}
					%		\toprule
					%		\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{SSPG}} & \multicolumn{2}{c|}{\textbf{GDMax}} & \multicolumn{2}{c}{\textbf{SDRO}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
					%		& \textbf{RMSE} & \textbf{Time (s)} & \textbf{RMSE} & \textbf{Time (s)} & \textbf{RMSE} & \textbf{Time (s)} \\
					%		\midrule
					%		\textbf{Space GA} & \textbf{0.20 $\pm$ 0.01} & 102.64  & 0.87 $\pm$ 0.84 & \textbf{75.62} & 0.44 $\pm$ 0.22 & 935.03 \\
					%		\textbf{MG} & \textbf{0.23 $\pm$ 0.01} & 53.63 & 0.50 $\pm$ 0.53 & \textbf{33.14} & 0.37 $\pm$ 0.28 & 468.55\\
					%		\textbf{BodyFat} & \textbf{0.02 $\pm$ 0.01} & 19.05 & 0.10 $\pm$ 0.10 & \textbf{10.69 } & 0.05 $\pm$ 0.03 & 166.52  \\
					%		\bottomrule
					%	\end{tabular}
				%	\caption{Comparison on noisy test set of RMSE (mean $\pm$ standard deviation) and time (mean) for the distributionally robust problem.}
				%	\label{tab:algorithms}
				%\end{table}
				
				
				\begin{table}[htbp]
					\centering
					\begin{tabular}{l|cc|cc|cc}
						\toprule
						\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{SSPG}} & \multicolumn{2}{c|}{\textbf{GDMax}} & \multicolumn{2}{c}{\textbf{SDRO}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
						& \textbf{RMSE} & \textbf{Time (s)} & \textbf{RMSE} & \textbf{Time (s)} & \textbf{RMSE} & \textbf{Time (s)} \\
						\midrule
						{\verb|Space GA|} & \textbf{0.41 $\pm$ 0.20} & 79.45  & 0.87 $\pm$ 0.84 & {51.31} & 0.50 $\pm$ 0.26 & 655.66 \\
						{\verb|MG|} & %\commwei{can we use the old one?}
						0.38 $\pm$ 0.28 & 44.56 & 0.50 $\pm$ 0.53 & {21.14} & \textbf{0.24 $\pm$ 0.03} & 370.69  \\
						{\verb|BodyFat|} & \textbf{0.05 $\pm$ 0.03} & 20.02 & 0.10 $\pm$ 0.10 & {6.93} & 0.08 $\pm$ 0.06 & 161.25  \\
						\bottomrule
					\end{tabular}
					\caption{{RMSE (mean $\pm$ standard deviation) and time (mean) for the distributionally robust regression problem on noisy test sets. %{\color{red}GMB: It is better to decide on using a period or no period in figures/captions and then apply it to all instances}
					}}
					\label{tab:algorithms2}
				\end{table}
				
				%\red{In the table below, we present an alternative version of the results based on a new metric referred to as the ``Time-Adjusted RMSE,'' which combines both time and RMSE into a consolidated metric for evaluating the performance of different methods. The metric is defined as follows:}
				
				%\red{\[
					%\text{Time Adjusted RMSE} = \kappa_1 \left( \frac{RMSE_i}{RMSE_{\text{max}}} \right)^{\tau_1} + \kappa_2 \left( \frac{Time_i}{Time_{\text{max}}} \right)^{\tau_2}
					%\]}
				
				%\red{where \(RMSE_i\) and \(Time_i\) represent the RMSE and time values, respectively, corresponding to method \(i\) in Table~\ref{tab:algorithms2}. Without loss of generality (WLOG), we assume that SSPG corresponds to method 1, GDMax corresponds to method 2, and SDRO corresponds to method 3. The parameters \(\kappa_1 \in [0,1]\) and \(\kappa_2 = 1 - \kappa_1\) represent the weights assigned to RMSE and time, respectively. A higher value of \(\kappa_1\) gives greater weight to RMSE. The parameters \(\tau_1 \geq 1\) and \(\tau_2 \geq 1\) are additional weight factors, used to adjust the relative importance of RMSE and time in the metric. Since \(\frac{RMSE_i}{RMSE_{\text{max}}} \leq 1\) and \(\frac{Time_i}{Time_{\text{max}}} \leq 1\), values greater than 1 for \(\tau_1\) and \(\tau_2\) assign greater weight to the respective metric. The overall goal is to minimize the value of the Time-Adjusted RMSE, indicating better performance of the method. Furthermore, the new metric is dimensionless, which eliminates any concerns related to units. For the purposes of the table below, we set \(\kappa_1 = 0.7\), \(\tau_1 = 1.1\), and \(\tau_2 = 1.1\).}
				
				
				
				%\begin{table}[htbp]
				%	\centering
				%	\begin{tabular}{l|cc|cc|cc}
					%		\toprule
					%		\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{SSPG}} & \multicolumn{2}{c|}{\textbf{GDMax}} & \multicolumn{2}{c}{\textbf{SDRO}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
					%		& \textbf{Time Adjusted RMSE} & & \textbf{Time Adjusted RMSE} & & \textbf{Time Adjusted RMSE} & \\
					%		\midrule
					%		\textbf{Space GA} & \textbf{0.34} & & 0.72  & & 0.68   & \\
					%		\textbf{MG} & \textbf{0.55}   & & 0.71   & & 0.61 & \\
					%		\textbf{BodyFat} & \textbf{0.36} & & 0.71  & & 0.85  & \\
					%		\bottomrule
					%	\end{tabular}
				%	\caption{\red{Comparison on noisy test set of Time Adjusted RMSE for the distributionally robust regression problem.}}
				%	\label{tab:algorithms3}
				%\end{table}
				
				\subsection{{Adversarial Robust Deep Learning Problem}}\label{sec:adversial}
				The adversarial deep learning image classification problem aims to develop a model that is robust to adversarial attacks on images \cite{madry2018towards}. Given an image belonging to one of $m_3$ classes,  we use a neural network prediction function $h_{\vtheta}: \mathbb{R}^{l \times w \times h} \to \mathbb{R}^{m_3}$, parameterized by $\vtheta$, to predict the target class. %to predict the most likely class of said image 
				%by minimizing the following loss function
				%We utilize a neural network, parameterized by $\vtheta$, to predict the target class with the categorical cross entropy loss function:%\footnote{Documentation available at: \url{https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html}}:
				The corresponding loss function and distance function in  \eqref{eq:model2} and \eqref{eq:smoothg2} is given by
				\begin{align}
					\ell(\vtheta,\vx) := -\sum_{i=1}^{m_3} y_i \log \left( \frac{e^{\left[h_{\vtheta}\left(\textbf{a}\right)\right]_i}}{\sum_{j=1}^{m_3}e^{[h_{\vtheta}(\textbf{a})]_j}}\right), \text{ and } d(\mathbf{x}, \vz)  = \frac{1}{2} \|\mathbf{a} - \overline{\va}\|_{F}^{2} + \infty \|\vb - \overline{\vb}\|_1,
				\end{align}
				where $\vx = (\va, \vb)$, $\vz = (\overline{\va}, \overline{\vb})$ with $\va, \overline{\va} \in [0,1]^{l \times w \times h}$ representing an image and  $\vb, \overline{\vb} \in \{0,1\}^{m_3}$ denoting their corresponding one-hot encoded label vectors.
				
				\textbf{Problem parameters:} We set \(\delta = 10\), \(p = 2\), and \(\mathcal{Z} = \widetilde{\mathcal{Z}} \times \{0,1\}^{m_3}\) where \(\widetilde{\mathcal{Z}} = [0,1]^{l \times w \times h}\).
				
				\begin{comment}\footnote{In this encoding scheme, if the target class is \( i \), the one-hot encoded vector \( \textbf{y} \) will have a 1 in the \( i \)-th position and 0s in all other positions. Specifically, if the target class is \( i \), then: \[
						\textbf{y}_j = \begin{cases}
							1 & \text{if } j = i, \\
							0 & \text{otherwise}.
						\end{cases}
						\] where \( j \) denotes the position in the vector \( \textbf{y} \).} of $b$. \end{comment}
				%, specifying \texttt{train=True} for training sets and \texttt{train=False} for testing sets. This approach ensured standardized data handling and preprocessing across all experiments, enabling a reliable comparison of algorithm performance.
				
				\textbf{Datasets and neural network architectures:} 
				To evaluate the efficacy of the compared algorithms, we use two benchmark datasets: \verb|Fashion-MNIST| and \verb|CIFAR-10|. These datasets are loaded using \verb|torchvision|\footnote{Documentation available at: \url{https://pytorch.org/vision/main/datasets.html}} with the standard training/test split applied.
				
				For \verb|Fashion-MNIST|, we utilize a convolutional neural network (CNN) architecture\footnote{\url{https://www.kaggle.com/code/rutvikdeshpande/fashion-mnist-cnn-beginner-98}} consisting of three convolutional layers with 32, 64, and 128 filters, each using a $3\times 3$ kernel, followed by ReLU activation and max pooling. The middle convolutional layer also employs dropout \cite{goodfellow2016deep} with a probability of 0.3 and batch normalization \cite{ioffe2015batch}. The output of the convolutional layers is passed through a fully connected network with 512 hidden units, followed by ReLU activation, dropout (probability 0.25), and batch normalization.
				
				For \verb|CIFAR-10|, we adopt the All-CNN architecture \cite{springenberg2014striving}, incorporating batch normalization after each ReLU activation in every convolutional layer.
				
				
				
				\textbf{Algorithm parameters:}  
				For all the methods, we initialize $\theta^{(0)}$ by the default of \verb|pytorch|. %\commwei{How do we initialize $\theta$?}.
				In addition, for GDMax and SSPG, we let $\lambda^{(0)}  \sim \mathcal{U}(1, 10)$.
				For SSPG, we set $\mu_0 = \lambda^{(0)}  \eta$, where $\eta \sim \mathcal{U}(0.1, 1)$. 
				We utilize a grid search for SDRO to fine-tune the hyperparameters $\lambda$ and $\eta$ from the sets \{1, 10\} and \{0.1, 1\}, respectively.
				{For each comparison method, the training is terminated after 100 epochs.}
				
				
				%One should note here that we opted against conducting a grid search for SDRO due to our preference to avoid prolonged computational duration.
				%\comm{Is this statement accurate? We did not do grid search for SDRO?} 
				%
				%\red{Remark: I forgot to remove this line from the old writeup. But since we have done grid search I have removed it.}
				
				
				\textbf{Implementation of the compared methods at the $k$th iteration:}
				At iteration~$k$, we first sample a mini-batch of size 
				$B=100$ from the training set, denoted as $\{\vx_{j_1^k},\vx_{j_2^k},\ldots,\vx_{j_B^k}\}$.
				Next, for each~$i~\in~\{1,2,\ldots,B\}$, we 
				perform an inner maximization step to obtain 
				$\{\vz_{j_i}^{(k+1)}\}_{i=1}^B$.
				Specifically, we solve $B$ problems of the form $\max_{\vz \in \cZ} \ell(\vtheta^{(k)}, \vz) - \lambda^{(k)} d(\vx_{j_i^k}, \vz)$ using the projected gradient ascent with a fixed step size of~$10^{-2}$ for 15 iterations, starting from $\vx_{j_i^k}+10^{-3}\vs$ where $\vs$ follows the standard normal distribution.
				
				
				After obtaining $\{\vz_{j_i}^{(k+1)}\}_{i=1}^B$, GDMax updates the the primal variable $(\theta,\lb)$ via  a projected gradient descent step with the gradient $\nabla_{(\theta,\lb)} \frac{1}{B}\sum_{i=1}^B\left[\lb^{(k)}\delta^p+\ell(\vtheta^{(k)},\vz_{j_i^k}^{(k+1)})-\lambda^{(k)} d(\vx_{j_i^k},\vz_{j_i^k}^{(k+1)})\right]$ and a learning rate $\alpha_k>0$.
				
				For SSPG and SDRO, we generate, for each $i\in\{1,2,\ldots,B\}$, a set~$\Omega_{j_i}^k$ of size $M=8$, containing samples near~$\vz_{j_i}^{(k+1)}$. Specifically, for any $\widehat{\vz}\in\Omega_{j_i}^k$, we let \( \widehat{\vz} = \mathrm{Proj}_{{\mathcal{Z}}}(\vz_{j_i}^{(k+1)} + \vs^{(k+1)}),\) where it holds that $\vs^{(k+1)} \sim [\mathcal{N}(0, 10^{-1})]^{l\times w\times h}\times [0]^{m_3}.$
				For each $j_i$, we retain only the samples that improve upon $\vz_{j_i}^{(k+1)}$, defining the refined set as
				\begin{align*}
					\overline{\Omega}_{j_i}^k:= \{\vz_{j_i}^{(k+1)}\} \cup \left\{\widehat{\vz}\in {\Omega}_{j_i}^k: \ell(\vtheta^{(k)}, \widehat{\vz}) - \lambda^{(k)} d(\vx_{j_i^k}, \widehat{\vz}) > \ell(\vtheta^{(k)}, \vz_{j_i}^{(k+1)}) - \lambda^{(k)} d(\vx_{j_i^k}, \vz_{j_i}^{(k+1)})\right\}.
				\end{align*}
				SDRO then updates  $\vtheta$ via a projected gradient descent step with the gradient $\nabla_{\vtheta}{g}_s^k(\vtheta^{(k)},\lb)$ and the learning rate $\alpha_k$, 
				where 
				\begin{align}
					\label{eq:gradientgsk2}
					{g}_s^k( \vtheta,\lb) = \lambda \delta^{p} + \lb\eta \frac{1}{B}\sum_{i=1}^B\left[ \text{log} \left(\frac{1}{M} \sum_{\widehat{\vz}\in\overline\Omega_{j_i}^k}  \left[ e^{\frac{\ell(\vtheta, \widehat{\vz}) - \lambda d(\vx_{j_i}, \widehat{\vz})}{\lb\eta}} \right] \right)\right].
				\end{align}
				Our SSPG method conducts a projected gradient descent step on $(\vtheta,\lb)$ using  $\nabla_{(\vtheta,\lb)}\widetilde{g}^k( \vtheta^{(k)},\lb^{(k)} , \mu_k)$ and the learning rate $\alpha_k$, where 
				\begin{align}
					\label{eq:gradientgtildek2}
					\widetilde{g}^k(\vtheta,\lb,\mu) = \lambda \delta^{p} + \mu \frac{1}{B}\sum_{i=1}^B\left[ \text{log} \left(\frac{1}{M} \sum_{\widehat{\vz}\in\overline\Omega_{j_i}^k}  \left[ e^{\frac{\ell(\vtheta, \widehat{\vz}) - \lambda d(\vx_{j_i}^k, \widehat{\vz})}{\mu}} \right] \right)\right].
				\end{align}
				We then update~$\mu$ by \eqref{eq:mu2}. 
				For all compared methods, we set $\alpha_k= \alpha \gamma^{\lfloor k/20 \rfloor}$, where $\alpha$ is chosen from the set
				$\{1 \times 10^{-1}, 5 \times 10^{-1}, 5 \times 10^{-2}\}$, and $\gamma$ is  selected from
				$\{0.5,0.9\}$.
				
				%\bigbreak
				%\bigbreak
				%\textcolor{blue}{For GDMax, we compute \(\va_{\text{max}} = \left\{ \va_{\text{max}}^{(k)} \right\}_{k=1}^{B} \) by performing projected gradient ascent with a fixed learning rate of $10^{-2}$ for 15 iterations. In the case of SSPG and SDRO, we first obtain  \( \left\{ \va_{\text{max}}^{(k)} \right\}_{k=1}^{B} \) and then generate a set of samples \( \{\{ \mathbf{a}_{(i)}^{(k)} \}_{k=1}^{B}\}_{i=1}^{8}  = \{\va_{(i)}\}_{i=1}^{8}\) where \( \mathbf{a}_{(i)}^{(k)} = \mathrm{Proj}_{\widetilde{\mathcal{Z}}}(\mathbf{a}_{\text{max}}^{(k)} + \vs_{(i)}) \), with \( \vs_{i} \sim \mathcal{N}(0, 10^{-2})^{l \times w \times h} \) \  $\forall k \in \{1,2,..., B\}$.
					%To approximate the inner expectation in \eqref{eq:smoothg} and \eqref{eq:smoothg2} we utlize \(  \left\{\{\va_{\text{max}}\} \cup \{\va_{(i)}\}_{i\in \tilde{\mathcal{I}} }\right\}\) where:}
				
				%\textcolor{blue}{\begin{align*}
						%\tilde{\mathcal{I}} = \left\{i \ | \ \mathbb{E}_{\mathbf{x} \sim \widehat{\mathbb{P}}_{B}}\left[\ell(\vtheta, \mathbf{z}_{i}) - \lambda d(\mathbf{x}, \mathbf{z}_{i})\right] > \mathbb{E}_{\mathbf{x} \sim \widehat{\mathbb{P}}_{B}}\left[\ell(\vtheta, \mathbf{z}) - \lambda d(\mathbf{x}, \mathbf{z})\right]\right\}
						%\end{align*}}\footnote{ \( \mathbf{z} = (\mathbf{a}_{\text{max}}, b) \), \(\mathbf{z}_{i} = (\mathbf{a}_{(i)}, b) \) \ and b is the label corresponding to $\vx$.}
						
						
						%\commwei{$\va_{\text{max}}$ is different for each iteration. Please check notations.} 
						
						\textbf{Performance comparisons:} 
						We evaluate model performance using accuracy and overall training time. Each model is tested on a modified version of the test set, where each feature vector is perturbed in a manner similar to the distributionally robust regression setting. Specifically, for each data point $\vx=(\va, \vb)$ in the test set, 
						we apply the perturbation $\va+\upsilon \boldsymbol{\omega}\|\va\|_2$, 
						where $\boldsymbol{\omega} \sim [\text{Laplace}(0,1)]^{q}$~\cite{goodfellow2016deep}, $\upsilon = 2 \times 10^{-3}$ for  \verb|Fashion-MNIST|  and $\upsilon= 2 \times 10^{-4} $ for \verb|CIFAR-10|.
						
						To ensure a fair comparison,
						we use five distinct random seeds for initialization across all three methods.
						Given the large dataset sizes and high computational cost, for each random seeds, we first sample 20\% of each training set for hyperparameter tuning, optimizing $\alpha$, $\gamma$, $\lambda$, and $\eta$ from the specified choices. The best learning rate is then selected for SSPG and GDMax based on the lowest accuracy, while for SDRO, we report results using the best-performing hyperparameter values. 
						After selecting the optimal parameters, we apply each method to the full training set. Finally, we aggregate the results across the five seeds and report in Table~\ref{tab:algorithm_comparison_deep_learning} the mean accuracy and training time, along with their standard deviations, for all methods.
						
						For the \verb|Fashion-MNIST|, we observe that SSPG demonstrates competitive performance, outperforming both GDMax and SDRO in terms of accuracy while requiring significantly less computational time than SDRO. Similarly, on CIFAR-10, SSPG achieves strong accuracy and computational efficiency, though SDRO attains a marginally higher accuracy at the cost of considerably longer runtime.
						Overall, SSPG achieves an effective balance between accuracy and computational efficiency, making it a suitable choice for applications requiring reliable and time-efficient performance even in the presence of noisy data.
						
						\begin{table}[htbp]
							\centering
							\begin{tabular}{l|cc|cc|cc}
								\toprule
								\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{SSPG}} & \multicolumn{2}{c|}{\textbf{GDMax}} & \multicolumn{2}{c}{\textbf{SDRO}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
								& \textbf{Accuracy (\%)} & \textbf{Time (hrs)} & \textbf{Accuracy} & \textbf{Time (hrs)} & \textbf{Accuracy} & \textbf{Time (hrs)} \\
								\midrule
								{\verb|Fashion-MNIST|} & \textbf{93.09 $\pm$ 0.13} & 2.52 & 92.64 $\pm$ 0.07 & \textbf{2.04} & 92.85 $\pm$ 0.04 & 10.04  \\
								{\verb|CIFAR-10|} & 86.64 $\pm$ 0.11 & 4.20 & 86.41 $\pm$ 0.36 & \textbf{2.93} & \textbf{86.68 $\pm$ 0.08} & 13.41  \\
								\bottomrule
							\end{tabular}
							\caption{Comparison of accuracy (mean $\pm$ standard deviation) and time (mean) for the adversarial deep learning problem on the noisy test set.}\label{tab:algorithm_comparison_deep_learning}
						\end{table}
						
						
						
						%\begin{table}[t!]
						%	\centering
						%	\begin{tabular}{l|cc|cc|cc}
							%		\toprule
							%		\multirow{2}{*}{\textbf{Dataset}} & \multicolumn{2}{c|}{\textbf{SSPG}} & \multicolumn{2}{c|}{\textbf{GDMax}} & \multicolumn{2}{c}{\textbf{SDRO}} \\ \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
							%		& \textbf{Accuracy (\%)} & \textbf{Time (hrs)} & \textbf{Accuracy} & \textbf{Time (hrs)} & \textbf{Accuracy} & \textbf{Time (hrs)} \\
							%		\midrule
							%\textbf{MNIST} & 96.63 $\pm$ 0.03 & 51.55 $\pm$ 10.00 & 96.21 $\pm$ 0.02 & 42.38 $\pm$ 12.77 & \textbf{96.97 $\pm$ 0.22} & \textbf{21.28 $\pm$ 5.37} \\
							%		\textbf{Fashion-MNIST} & 92.87 $\pm$ 0.15 & 4.40 & 92.79 $\pm$ 0.11 & \textbf{1.83} & \textbf{92.91 $\pm$ 0.10} & 9.06  \\
							%		\textbf{CIFAR-10} & - & - & - & - & - & -  \\
							%\textbf{CIFAR-100} & - & - & - & -  & - \\
							%		\bottomrule
							%	\end{tabular}
						%	\caption{\red{Comparison on the noisy test set of accuracy (mean $\pm$ standard deviation) and time (mean) for the adversarial deep learning problem - New} .}\label{tab:algorithm_comparison_deep_learning}
						%\end{table}
						\section{Proofs of the main results}\label{sec:proof}
						
						In this section we provide proofs of our results presented in Section \ref{sec:algorithm}.
						
						\subsection{Proof of Lemma \ref{lem:regularcondi}}\label{sec:regularcondi}
						\begin{proof}
							Given $ g=\frac{1}{n}\sum_{i=1}^n\Phi_i +\varphi$ and the convexity of $\varphi$, it suffices to verify the Clarke regularity of $\Phi_i$ for each $i\in[n]$.
							We fix $i$ throughout the rest of the proof.
							
							Let $\vy$ and $\vd$ be given. Consider sequences $\{\vy^k\}$ and $\{t^k\}$ such that $\vy^k\rightarrow\vy$,  $t^k\downarrow0$, and 
							\begin{equation}
								\label{eq:phicric}
								\Phi_i^{\circ}(\vy; \vd) =\lim_{k\rightarrow \infty}  \frac{\Phi_i(\vy^k+t^k \vd)-\Phi_i(\vy^k)}{t^k}.
							\end{equation}
							We construct a sequence  $\{{\vz}^k\}$ by 	
							\begin{equation}
								\label{eq:definevzk}
								{\vz}^k \in \argmax_{\vz\in\mathcal{Z}}\Psi(\vy^k+t^k \vd, \vz;\vx_i).
							\end{equation}
							Since $\mathcal{Z}$ is compact, without loss of generality, we assume ${\vz}^k {}{\rightarrow} \bar{\vz}$; otherwise, we can choose a convergent subsequence.
							By Assumption \ref{ass:problemsetup} and the continuity of $\Phi_i$,
							we have $$\Psi(\vy, \bar{\vz} ;\vx_i) = \lim_{k \rightarrow \infty }\Psi(\vy^k+t^k \vd, \vz^k ;\vx_i) =\lim_{ k \rightarrow \infty}\Phi_i(\vy^k+t^k \vd)
							=\Phi_i(\vy)=\max_{\vz\in\mathcal{Z}}\Psi(\vy, \vz;\vx_i) .$$
							This implies $\bar{\vz} \in \argmax_{\vz\in\mathcal{Z}}\Psi(\vy, \vz;\vx_i).$
							In addition, it holds $\Phi_i(\vy^k)\geq \Psi(\vy^k, \vz^k;\vx_i)$ by the definition of $\Phi_i$ in \eqref{eq:def-Phi-i}. Thus, using $\Phi_i(\vy^k+t^k \vd)= \Psi(\vy^k+t^k \vd, \vz^k ;\vx_i)$, we obtain
							\begin{equation}
								\label{eq:clarke1}
								\begin{aligned}
									&\frac{\Phi_i(\vy^k+t^k \vd)-\Phi_i(\vy^k)}{t^k}   \leq  %\frac{\left(\Psi(\vy^k+t^k 	\vd, \vz^k) -\left(\Psi(\vy^k, \vz^k) \\
										\frac{\Psi(\vy^k+t^k \vd, \vz^k;\vx_i) -\Psi(\vy^k, \vz^k;\vx_i) }{t^k}.
									\end{aligned}
								\end{equation}
								By Lemma~\ref{lem:meanvalue} with $h(\cdot) = \Psi(\vy^k+ \cdot \, \vd, \vz^k;\vx_i)$, there exists $0<s^k<t^k$ such that 
								\begin{equation}
									\label{eq:clarke2}
									\begin{aligned}
										\frac{\Psi(\vy^k+t^k \vd, \vz^k;\vx_i) -\Psi(\vy^k, \vz^k;\vx_i) }{t^k-0}\leq %\Psi^{\prime}(\vy^k+s^k \vd, \vz^k; \vx_i, \vd)=
										\vd\zz \nabla_{\vy}\Psi(\vy^k+s^k \vd, \vz^k ;\vx_i).
									\end{aligned}
								\end{equation}
								Combining \eqref{eq:clarke1} and \eqref{eq:clarke2}, we obtain $\left({\Phi_i(\vy^k+t^k \vd)-\Phi_i(\vy^k)}\right)/{t^k}\leq \vd\zz \nabla_{\vy}\Psi(\vy^k+s^k \vd, \vz^k ;\vx_i)$. Taking $k\rightarrow\infty$ in the above inequality, we deduce from~\eqref{eq:phicric} and the continuity of $\nabla_{\vy}\Psi(\cdot,\cdot;\vx_i)$ that  
								\begin{equation}
									\label{eq:limitsup}
									\Phi_i^{\circ}(\vy; \vd)  \leq \lim _{k\rightarrow\infty }\vd\zz \nabla_{\vy}\Psi(\vy^k+s^k \vd, \vz^k ;\vx_i) = 	\vd\zz \nabla_{\vy}\Psi(\vy, \bar{\vz} ;\vx_i).
								\end{equation}
								From~\eqref{eq:hderiva} and the inequality above, we get 
								%\begin{equation*}
								$\Phi_i^{\circ}(\vy ; \vd) \leq 	\Phi_i^{\prime}(\vy; \vd ).$ 
								%\end{equation*}
								This together with 
								$\Phi_i^{\circ}(\vy;\vd)\geq \Phi_i^{\prime}(\vy;\vd)$ 
								yields 
								$
								\Phi_i^{\circ}(\vy;\vd)=\Phi_i^{\prime}(\vy;\vd).
								$
								Hence, $\Phi_i$ is Clarke regular at $\vy$. The proof is then completed.
							\end{proof}
							
							
							
							\subsection{Proof of Lemma \ref{lem:smoothphi}}\label{sec:smoothphi}
							\begin{proof}
								(a) 
								We take $\mu\downarrow 0$ in $\mu \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu}]$ to obtain
								\begin{align}
									\notag
									& \lim _{\mu \downarrow 0} \mu \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu} ]= \lim _{\beta \rightarrow \infty} \frac{1}{\beta} \log \mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i) }]  \stackrel{(i)}{=}\lim_{\beta \rightarrow \infty}  \nabla_\beta \log \mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  }]   \\
									= & {\lim _{\beta \rightarrow \infty} \frac{ \nabla_\beta \mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  } ]}{\mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  }] }   \stackrel{(ii)}{=}
										\lim _{\beta \rightarrow \infty} \frac{  \mathbb{E}_{\vz\sim \zeta}[\nabla_\beta e^{\beta\Psi(\vy,\vz;\vx_i)  } ]}{\mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  }] }   }
									=
									\lim _{\beta \rightarrow \infty} \frac{ \mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  } \Psi(\vy,\vz;\vx_i)]}{\mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i)  }] }  
									\label{eq:limitu}
									\\\notag 
									=
									&\lim _{\beta \rightarrow \infty} \frac{ \mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i) -\beta \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)  } \Psi(\vy,\vz;\vx_i)]}{\mathbb{E}_{\vz\sim \zeta}[e^{\beta\Psi(\vy,\vz;\vx_i) -\beta \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) }] }  
									\stackrel{(iii)}{=}  \max_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) \stackrel{(iv)}{=}\max _{\vz \in \mathcal{Z}}\Psi(\vy,\vz;\vx_i).
								\end{align}
								Here (i) comes from L'Hôpital's rule.
								When $\mathcal{Z}$ is a finite set, (ii) holds directly; and when $\mathcal{Z}$ is a continuous compact  set, (ii) holds by Leibniz integral rule and the continuity of $e^{\beta\Psi(\vy,\vz;\vx_i)  } \Psi(\vy,\vz;\vx_i)$ with respect to~$\beta$.
								(iii) results from the fact that %\remove{the pdf with respect to $\zeta$ is large than 0 for all feasible} 
								$\vz$ {is a continuous random variable}, and 
								\begin{equation*}
									\begin{aligned}
										&\lim _{\beta \rightarrow \infty} e^{\beta\Psi(\vy,\vz;\vx_i) -\beta \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)} = \left\{
										\begin{aligned}
											1, &\text{ if } \vz \in\argmax_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) \\ 
											0, & \text{ otherwise}.
										\end{aligned}
										\right., \\
										&\lim _{\beta \rightarrow \infty} e^{\beta\Psi(\vy,\vz;\vx_i) -\beta \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)} \Psi(\vy,\vz;\vx_i) = \left\{
										\begin{aligned}
											\Psi(\vy,\vz;\vx_i), &\text{ if } \vz \in\argmax_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) \\ 
											0, \quad\quad& \text{ otherwise}.
										\end{aligned}
										\right.,
									\end{aligned}
								\end{equation*}
								In addition, (iv) follows from Assumption \ref{def:zeta}(ii).
								
								Notice that $\mu \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu} ]$ is continuously differentiable with respect to~$\vy$ by Assumption \ref{ass:problemsetup}. We then obtain that  $\widetilde{\Phi}_i$ is a smoothing function of $\Phi_i$ from Definition~\ref{def:smooth}.
								
								(b) The $\vy$ and $\mu$ partial gradients of $\widetilde{\Phi}_i$ are derived by direct calculation. %has the following structure:
								For the $\vy$-partial gradient, we have
								\begin{align*}
									\left\|\nabla_{\vy} 
									\widetilde{\Phi}_i(\vy,\mu)\right\| &=  \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }\right\| 
									\leq \frac{\mathbb{E}_{\vz\sim \zeta}\left[\left\|e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)\right\| \right]  }{\left\|\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}]\right\|  }\\
									&\leq \frac{\mathbb{E}_{\vz\sim \zeta}\left[l_{\Psi}\left\|e^{\Psi(\vy,\vz;\vx_i) / \mu}   \right\| \right]  }{\left\|\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}]\right\|  }= l_{\Psi}.
								\end{align*}
								For the $\mu$-partial gradient, 
								it holds
								$\lim_{ \mu \downarrow 0} \mu \nabla_\mu \widetilde{\Phi}_i(\mathbf{y}, \mu) =0$ by \eqref{eq:limitu}.
								
								Let $\sigma = \frac{\mu_2}{\mu_1}\leq 1$. We then have 
								\begin{equation*}
									\begin{aligned}
										&\mu_1 \log \left(\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu_1} ] \right)  - \mu_2 \log \left(\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu_2} ]\right)  \\ =& \mu_1 \log \left(\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu_1} ]\right)  - \sigma\mu_1 \log \left(\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/(\sigma\mu_1)} ]\right) 
										=\mu_1 \log \frac{\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu_1} ]}{\left(\mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/(\sigma\mu_1)} ]\right)^\sigma} \leq 0,		\end{aligned}
								\end{equation*} 
								where the inequality holds by $\mathbb{E}\left[X^{1/\sigma}\right] \geq (\mathbb{E}[X])^{1/\sigma}$
								with $X=e^{\Psi(\vy,\vz;\vx_i)/\mu_1}$. Thus $\widetilde{\Phi}_i(\vy,\mu_1)\leq \widetilde{\Phi}_i(\vy,\mu_2)$ for any $\mu_1\geq\mu_2>0$.
								
								(c) 
								Given $\vy_1, \vy_2$ and $\vz$, we assume $\Psi(\vy_1,\vz;\vx_i)\geq \Psi(\vy_2,\vz;\vx_i)$, without loss of generality.
								Letting \\$s_1= \Psi(\vy_1,\vz;\vx_i)/\mu$ and $s_2=\Psi(\vy_2,\vz;\vx_i)/\mu$, we have $$|e^{s_1}-e^{s_2}|\leq \max_{s\in[s_2,s_1]}e^s
								|s_1-s_2|= e^{s_1}|s_1-s_2|.$$ We then obtain
								\begin{equation}
									\label{eq:y2}
									\begin{aligned}
										& \left|e^{\Psi(\vy_1,\vz;\vx_i)/\mu}-e^{\Psi(\vy_2,\vz;\vx_i)/\mu}\right| 
										\leq e^{\Psi(\vy_1,\vz;\vx_i)/\mu}\left(\frac{\Psi(\vy_1,\vz;\vx_i)}{\mu}  - \frac{\Psi(\vy_2,\vz;\vx_i)}{\mu}\right)
										\leq  
										\frac{ l_{\Psi}}{\mu} e^{\Psi(\vy_1,\vz;\vx_i)/\mu} \|\vy_1-\vy_2\|,
									\end{aligned}
								\end{equation}
								where %the first inequality uses $\Psi(\vy_1,\vz;\vx_i)\ge \Psi(\vy_2,\vz;\vx_i)$, and 
								the second inequality holds by Assumption \ref{ass:compact1}.
								
								For simplicity of notations, we let 
								\begin{align*}
									&\Psi_1 := \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_1,\vz;\vx_i)] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}], \\&\Psi_2: =\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}],\\
									&\Psi_3:= \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}],\\&\Psi_4:= \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}].
								\end{align*}
								It holds
								\begin{equation}
									\label{eq:philip1}
									\begin{aligned}
										&\left\|\nabla_{\vy} \widetilde{\Phi}_i(\vy_1,\mu)-\nabla_{\vy} \widetilde{\Phi}_i(\vy_2,\mu)\right\| 
										= \left\|\frac{  \Psi_1 - \Psi_2 }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}]}\right\| \\
										\leq &\underbrace{\left\|\frac{ \Psi_1-\Psi_3 }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}]}\right\|}_{\mathrm{term}\,\,(i)}   + \underbrace{\left\|\frac{\Psi_3 -\Psi_4  }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}]}\right\|}_{\mathrm{term}\,\,(ii)} \\
										&+\underbrace{\left\|\frac{\Psi_4- \Psi_2  }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}]}\right\|}_{\mathrm{term}\,\,(iii)}.
									\end{aligned}
								\end{equation}
								
								Notice that $e^{\Psi(\vy,\vz;\vx_i) / \mu}>0$ for all $\vy,\vz$ and $\nabla_{\vy}\Psi(\cdot,\vz;\vx_i)$ is $L_{\Psi}$-Lipschitz continuous for all $\vz\in\mathcal{Z}$. Hence, for term (i) in \eqref{eq:philip1}, we have 
								\begin{equation}
									\label{eq:phiterm1}
									\begin{aligned}
										\mathrm{term}\,\,\text{(i)} &= \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_1,\vz;\vx_i)] -\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)]  }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]}\right\|
										\\
										&\leq \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \|\nabla_{\vy}\Psi(\vy_1,\vz;\vx_i) -  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)]\|  }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]}\right\|
										\\
										&\leq \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  L_{\Psi} \|\vy_1-\vy_2\|]  }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]}\right\|=L_{\Psi} \|\vy_1-\vy_2\|. \\
									\end{aligned}
								\end{equation}
								For term (ii) in \eqref{eq:philip1}, we have 
								\begin{equation}
									\label{eq:phiterm2}
									\begin{aligned}
										\mathrm{term}\,\,\text{(ii)} &= \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] -\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]}\right\| \\
										&\leq \left\|\frac{\mathbb{E}_{\vz\sim \zeta}\left[\frac{l_{\Psi}}{\mu} e^{\Psi(\vy_1,\vz;\vx_i)/\mu} \|\vy_1-\vy_2\|\right]  \cdot l_{\Psi} }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]}\right\|=\frac{l^2_{\Psi}}{\mu} \|\vy_1-\vy_2\|,
									\end{aligned}
								\end{equation}
								where the inequality comes from \eqref{eq:y2} and $\|\nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)\|\leq l_{\Psi}$.
								For term (iii) in \eqref{eq:philip1}, we have 
								\begin{equation}
									\label{eq:phiterm3}
									\begin{aligned}
										\mathrm{term}\,\,\text{(iii)} &\leq  \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] \mathbb{E}_{\vz\sim \zeta} \left[\frac{l_{\Psi}}{\mu} e^{\Psi(\vy_1,\vz;\vx_i)/\mu} \|\vy_1-\vy_2\|\right] }{\mathbb{E}_{\vz\sim \zeta}\left[e^{\Psi(\vy_1,\vz;\vx_i) / \mu}]\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}\right]}\right\| \\
										&= \left\|\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy_2,\vz;\vx_i) / \mu}]}\right\| \frac{l_{\Psi}}{\mu}  \|\vy_1-\vy_2\| \leq \frac{l^2_{\Psi}}{\mu}\|\vy_1-\vy_2\|,
									\end{aligned}
								\end{equation}
								where the first inequality comes from \eqref{eq:y2}, and the second inequality holds by $\|\nabla_{\vy}\Psi(\vy_2,\vz;\vx_i)\|\leq~l_{\Psi}$. 	
								Now	substituting  \eqref{eq:phiterm1}--\eqref{eq:phiterm3} into \eqref{eq:philip1}, we obtain $\left\|\nabla_{\vy} \widetilde{\Phi}(\vy_1,\mu)-\nabla_{\vy} \widetilde{\Phi}(\vy_2,\mu)\right\|\leq (L_{\Psi}+2l^2_{\Psi}/\mu)\|\vy_1-\vy_2\|$. 
								The proof is then completed.
							\end{proof}
							
							\subsection{Proof of Lemma \ref{lem:distancemufinite}}\label{sec:distancemufinite}
							\begin{proof}
								Define $\omega_t:\RR^t \mapsto\RR$ by $\omega_t(\vx):=\log  ( \sum_{i=1}^t e^{x_i} )$ and $\widetilde{b}_t:\RR^t\times \RR \mapsto\RR$ by $\widetilde{b}_t(\vy,\mu):= \mu \log (\sum_{i=1}^t e^{y_i / \mu})$. % and $b_t(\vx):=\max\{x_1,x_2,\ldots, x_t\}$.
								We have
								$
								\widetilde{b}_t(\vy,\mu) 
								= \mu \omega_t\left(\frac{\vy}{\mu}\right)= \max _{\vx\in D_t}\left\{\langle \vx, \vy\rangle -\mu \omega_t^*(\vx)\right\},%=\inf _{x \in \mathbb{R}^q}\left\{b(x)+\mu \omega\left(\frac{y-x}{\mu}\right)\right\},
								$
								where $D_t:=\{\mathbf{x} \in \mathbb{R}^t: \mathbf{x} \geq \mathbf{0}, \textbf{1}_t\zz \mathbf{x}=1\}$, and the second equality follows from that   the conjugate function of $\omega$ over   $D_t$ is $\omega_t^*(\vy)=\sum_{i=1}^t y_i \log y_i$
								(cf. \cite[Theorem 4.2]{beck2012smoothing}). 
								%Here, .
								Then		
								%	 We derive 
								\begin{equation}
									\label{eq:boundbtilde}
									\begin{aligned}
										& \left|\widetilde{b}_t(\vy,\mu_1)-\widetilde{b}_t(\vy,\mu_2)\right|  = \left| \max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_2 \omega_t^*(\vx)\right\}-\max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_1 \omega_t^*(\vx)\right\}\right|  \\ 
										\leq & \max\bigg\{ \max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_2 \omega_t^*(\vx)\right\}-\max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_1 \omega_t^*(\vx)\right\}, \\ &\quad\quad\quad\quad\quad \max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_1 \omega_t^*(\vx)\right\} - \max _{\vx\in D_t }\left\{\langle \vx, \vy\rangle -\mu_2 \omega_t^*(\vx)\right\}\bigg\}
										\\
										\leq & \max\left\{ \max _{\vx\in{D_t}} (\mu_1-\mu_2)\omega_t^*(\vx), \max _{\vx\in{D_t}} (\mu_2-\mu_1)\omega_t^*(\vx)\right\}\\ 
										= &\left(\mu_1-\mu_2\right) \max _{\vx\in{D_t}}-\omega_t^*(\vx)=
										\left(\mu_1-\mu_2\right) \left|\max _{\vx\in{D_t}}[\langle\vzero, \vx\rangle-\omega_t^*(\vx)]\right|
										=\omega_t(\vzero)\left(\mu_1-\mu_2\right) =\log(t)\left(\mu_1-\mu_2\right),
									\end{aligned}
								\end{equation}
								where the third equality uses the fact that the conjugate function of $\omega_t^*$ is $\omega_t$ itself, and the second inequality holds because for any continuous functions $f_1, f_2: \RR^t \rightarrow \mathbb{R}$,
								$$
								\max _{\vu}\left\{f_1(\vu)-f_2(\vu)\right\}+\max _{\vu}\left\{f_2(\vu)\right\} \geq \max _{\vu }\left\{f_1(\vu)-f_2(\vu)+f_2(\vu)\right\}=\max _{\vu}\left\{f_1(\vu)\right\}.
								$$ 
								
								Since $\mathcal{Z}$ is a finite discrete set, we let $t=|\mathcal Z|$ and $r_j =\Psi(\vy,\vz_j;\vx_i)$  for all $j\in[t]$. We have $\widetilde{\Phi}_i(\vy,\mu)=\mu \log \mathbb{E}_{\vz\sim \zeta} [e^{\Psi(\vy,\vz;\vx_i)/\mu}]  = \mu\log \frac{1}{t} + \mu \log \sum_{j=1}^t e^{\Psi(\vy,\vz_j;\vx_i)/\mu} =\widetilde{b}_t(\vr,\mu)+\mu\log\frac{1}{t}$.  Thus it follows from \eqref{eq:boundbtilde} that
								\begin{align*}
									|\widetilde{\Phi}_i(\vy,\mu_1) - \widetilde{\Phi}_i(\vy,\mu_2)| 
									\leq & |\widetilde{b}_t(\vr,\mu_1) - \widetilde{b}_t(\vr,\mu_2)| +  \left|\log\frac{1}{t} \right| \left(\mu_1-\mu_2\right)
									\\
									\leq &(\log(t)+\log({t}))(\mu_1-\mu_2)= 2\log(t)(\mu_1-\mu_2),
								\end{align*}
								which indicates the desired result.
							\end{proof}
							
							\subsection{Proof of Lemma \ref{lem:distancemu}}\label{sec:distancemu}
							\begin{proof}
								Applying the mean-value theorem, it holds 
								$|\widetilde{\Phi}_i(\vy,\mu_1)-\widetilde{\Phi}_i(\vy,\mu_2)|\leq \kappa_{\mu_2}|\mu_1-\mu_2|$ with 
								$$\kappa_{\mu_2} = \max_{\vy\in \dom(\varphi)}\max_{\mu\in[\mu_2,\mu_1]} \|\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\|.$$
								
								Let $\sigma = \frac{\mu_2}{\mu_1}$.  It holds
								\begin{align}
									\label{eq:mukappa}
									\lim_{\mu_2\downarrow 0} \mu_2\kappa_{\mu_2}= &\lim_{\mu_2\downarrow 0} \max_{\vy\in \dom(\varphi)} \max_{\mu\in[\mu_2,\mu_1]} \|\mu_2\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\| 
									\leq
									\lim_{\mu_2\downarrow 0} \max_{\vy\in \dom(\varphi)} 
									\max_{\mu\in[\mu_2,\frac{\mu_2}{\sigma}]}  \|\mu\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\|, 
								\end{align}
								where the inequality uses $\mu_2\leq \mu$.
								According to Lemma \ref{lem:smoothphi}(b),  it holds $\lim_{\mu\downarrow 0} \|\mu\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\| =0$ for all $\vy\in\dom(\varphi)$. This implies 
								$
								\lim_{\mu_2\downarrow 0}\max_{\mu\in[\mu_2,\frac{\mu_2}{\sigma}]} \|\mu_2\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\|=0 
								$
								for each $\vy\in\dom(\varphi)$.
								Because $\dom(\varphi)$ is compact, we can extend this result to $
								\lim_{\mu_2\downarrow 0}\max_{\vy\in\dom(\varphi)}\max_{\mu\in[\mu_2,\frac{\mu_2}{\sigma}]} \|\mu_2\nabla_{\mu}\widetilde{\Phi}_i(\vy,\mu)\|=0 
								$.
								Substituting back into \eqref{eq:mukappa}, we arrive at $\lim_{\mu_2\downarrow 0} \mu_2\kappa_{\mu_2}= 0$ by $\kappa_{\mu_2}\ge 0$. 
								Therefore, there exists $C_0>0$, such that  $ \mu_2\kappa_{\mu_2}\leq C_0$ for any $0<\mu_1\le 1$, and $\mu_2\in [\frac{1}{2}\mu_1, \mu_1]$. This completes the proof.
							\end{proof}
							
							\subsection{Proof of Theorem \ref{lem:scaled}}\label{sec:scaled}
							\begin{proof} 
								From the definition of $\vy^{(k)}$, %we know that $\vy^{(k)}$ is an $\epsilon_k$-scaled stationary point of problem \eqref{eq:smootho} in expectation, with $0<\mu=\mu_k\leq \epsilon_k$. Then, 
								there exist $\vgamma_{\vy}^{(k)} \in \partial \varphi (\vy^{(k)}) \subset\RR^{m_1}$ and $0<\mu_k\leq \epsilon_k$
								{such that}
								\begin{equation}
									\label{eq:kkgamma}
									\mathbb{E}\left[\left(\dist\left(\vzero, \partial\widetilde{g}( \vy^{(k)},\mu_k)\right)\right)^2\right]= \mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k)}}\right\|^2\right] \leq \epsilon^2_k, \text{ for all }k\ge 0.
								\end{equation}
								Define $A_k(\delta): = \left\{\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k)}}\right\|^2 \ge \delta \right\}$ and $A^c_k(\delta): = \left\{\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k)}}\right\|^2 < \delta \right\}$.
								By Markov's inequality and \eqref{eq:kkgamma},  we have for any $\delta>0$,
								\begin{align*}
									\sum_{k=0}^{\infty}\mathrm{Prob}\left(
									A_k(\delta)
									\right) \leq \sum_{k=0}^{\infty}\frac{1}{\delta}
									\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k)}}\right\|^2\right] 
									\leq \frac{1}{\delta}\sum_{k=0}^{\infty}\epsilon^2_k<+\infty.
								\end{align*}
								Setting $\delta=\frac{1}{t}$ for $t\in\mathbb{N}_{++}$, we apply the Borel-Cantelli Lemma to the sequence of events $\left(A_k(\delta): k\ge 0\right)$, and obtain
								$ 
								\mathrm{Prob}(\limsup_{k\rightarrow\infty} A_k(\frac{1}{t}))=0.
								$
								By the definition of the limit operator, $\omega$ belongs to the event $$\Omega:=\left\{\omega: \lim_{k\rightarrow\infty}\left\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(k)}(\omega),\mu_k)+  \vgamma_{\vy}^{{(k)}}(\omega)\right\|=0\right\},$$
								if and only if
								$$\omega\in \bigcap_{t=1}^{\infty}\bigcup_{k=1}^{\infty}\bigcap_{i=k}^{\infty} A_i^c(\frac{1}{t})=\left(\bigcup_{t=1}^{\infty}\limsup_{k\rightarrow\infty}A_k(\frac{1}{t})\right)^c.$$
								It then follows $$\mathrm{Prob}\left( \Omega\right)=1-\mathrm{Prob}\left(\bigcup_{t=1}^{\infty}\limsup_{k\rightarrow\infty}A_k(\frac{1}{t})\right)\geq 1-\sum_{t=1}^{\infty}\mathrm{Prob}\left(\limsup_{k\rightarrow\infty}A_k(\frac{1}{t})\right)=1.$$
								Combining this with $\mathrm{Prob}\left(  
								\Omega\right)\leq 1$, we derive $\mathrm{Prob}(\Omega)=1$. This implies \eqref{eq:almost} by the equation in \eqref{eq:kkgamma}.
								
								Define event $\overline\Omega:= \{\omega: \lim_{k\rightarrow \infty}\vy^{(j_k)}(\omega) = \vy^{*}(\omega)\}$. According to our setting in this theorem, it holds $\mathrm{Prob}(\overline\Omega)=1$, and thus $\mathrm{Prob}(\Omega \cap \overline\Omega)=1$.
								For any $\omega\in \Omega\cap \overline\Omega$, 
								{it holds} $\vy^{(j_k)}(\omega) \to \vy^{*}(\omega)$.
								Recall that $\nabla_{\vy}\widetilde{\Phi}_i(\vy,\mu)
								=\frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }$ in Lemma \ref{lem:smoothphi}(a). 
								From this expression, and given the continuity of both $\Psi$ and $\nabla_{\vy}\Psi$, we conclude that $\nabla_{\vy}\widetilde{\Phi}_i(\cdot,\mu)$ is continuous for a fixed $\mu$.
								To further analyze the dependence on $\mu$, we rewrite the gradient via
								$$
								\nabla_{\vy}\widetilde{\Phi}_i(\vy,\mu)
								= 
								\frac{ \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i)/ \mu - \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)/ \mu  } \nabla_{\vy}\Psi(\vy,\vz;\vx_i)]}{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i)/ \mu - \max_{\vz\in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)/ \mu }] }.
								$$
								By applying Assumption \ref{ass:compact1}, which states that $\|\nabla_{\vy}\Psi(\vy,\vz;\vx_i)\| \leq l_{\Psi}$, we ensure that the numerator and denominator are uniformly bounded. Utilizing a technique similar to that used in establishing (iii) in the proof of Lemma~\ref{lem:smoothphi}(a), we can then demonstrate the continuity of $\nabla_{\vy}\widetilde{\Phi}_i(\vy,\cdot)$ for a fixed $\vy$.
								Then, we obtain that the limit $\lim _{k\rightarrow\infty  } \frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{\Phi}_i( \vy^{(j_k)}(\omega),\mu_{j_k})$ exists, due to the continuity established, $\lim_{ k \rightarrow \infty}\mu_{j_k}=0$, and $\lim_{k\rightarrow \infty}\vy^{(j_k)}(\omega) = \vy^{*}(\omega)$.
								Next, since $g - \varphi$ is Clarke regular at $\vy^*(\omega)$ by Lemma~\ref{lem:regularcondi}, and given that $\lim_{k\to\infty} \mu_{j_k} = 0$, we invoke \cite[Relation (23)]{chen2012smoothing}. This allows us to conclude that
								\begin{equation}\label{eq:gf}
									\lim _{k\rightarrow\infty  } \frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{\Phi}_i( \vy^{(j_k)}(\omega),\mu_{j_k}) \in \partial  (g-\varphi)(\vy^*(\omega)).
								\end{equation}
								%Simultaneously, 
								Meanwhile, we have $\lim_{k\rightarrow\infty}\|\frac{1}{n}\sum_{i=1}^n\nabla\widetilde{{\Phi}}_i( \vy^{(j_k)}(\omega),\mu_{j_k})+  \vgamma_{\vy}^{{(j_k)}}(\omega)\|=0$ for any $\omega\in\Omega \cap \overline{\Omega}$.
								This implies that 
								%the limit
								$\lim_{k \rightarrow \infty} \vgamma_{\vy}^{(j_k)}(\omega)$ exists, which we denote as
								$\vgamma_{\vy}^*(\omega)$.
								The relation 
								$\vgamma_{\vy}^{(j_k)}(\omega) \in \partial \varphi (\vy^{(j_k)}(\omega)) $, the limit
								$\lim_{k \rightarrow \infty} \vy^{(j_k)}(\omega)=\vy^*(\omega)$,
								and the outer semicontinuity of $\partial\varphi$~\cite[Theorem 8.6]{roc1998var} imply 
								$  \vgamma_{\vy}^*(\omega)\in\partial \varphi(\vy^*(\omega))$.
								Combining this and \eqref{eq:gf}, we deduce $$\lim _{k\rightarrow\infty  }\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{\Phi}_i( \vy^{(j_k)}(\omega),\mu_{j_k}) +\vgamma_{\vy}^{(j_k)} (\omega)\in \partial  (g-\varphi)(\vy^*(\omega)) + \partial\varphi(\vy^*(\omega)) = \partial g(\vy^*(\omega)),$$
								where the equality holds due to the properties of the subdifferential and the structure of the functions involved~\cite[Page 40, Corollary 3]{clarke1990optimization}. Specifically, since $\vy^*(\omega) \in \dom(\varphi) \subset \mathbb{R}^{m_1} = \dom(g - \varphi)$, both $g-\varphi$ and $\varphi$ are Clarke regular, and considering the compactness of $\dom(\varphi)$, we can apply the subdifferential sum rule under these conditions.
								To elaborate, the inclusion $\vy^*(\omega) \in \dom(\varphi)$ is ensured by the compactness of $\dom(\varphi)$, $\vy^{(j_k)}(\omega)\in\dom(\varphi)$ for all $k\ge 0$, and $\lim_{k\rightarrow \infty} \vy^{(j_k)}(\omega) = \vy^*(\omega)$.
								Therefore, we obtain that
								$$\dist\left(\vzero, \partial  g(\vy^*(\omega))\right)
								\leq \lim_{k\rightarrow\infty}\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{\Phi}_i( \vy^{(j_k)}(\omega),\mu_{j_k})+ \vgamma_{\vy}^{{(j_k)}}(\omega)\right\| =0%, \text{ almost surely}
								.$$ 
								Hence $\vzero\in \partial  g(\vy^*(\omega))$, and $\vy^*(\omega)$ is a Clarke stationary point of  problem \eqref{eq:minmax}.
								Finally, since the function $g$ is Clarke regular, it follows that $\vy^*(\omega)$ is also a directionally stationary point of problem \eqref{eq:minmax} for all $\omega\in \Omega\cap \overline\Omega$. Since $\mathrm{Prob}(\Omega \cap \overline{\Omega}) = 1$, $\vy^*$ is a directionally stationary point of problem \eqref{eq:minmax} almost surely.
							\end{proof}
							
							
							
							\subsection{Proof of Lemma \ref{lem:alg3}}\label{sec:alg3}
							
							\begin{proof}
								$($a$)$
								From the updating rule~\eqref{eq:updatex2} with $\alpha_k=\frac{1}{L^{(k)}}$, it follows that
								\begin{equation}
									\label{eq:KKT2}
									L^{(k)}\left(\vy^{(k+1)}-\vy^{(k)}\right)+ \mathcal{G}(\vy^{(k)},\mu_{k}) + \vgamma_{\vy}^{(k+1)} =\vzero, 
								\end{equation}
								for some $\vgamma_{\vy}^{(k+1)}\in \partial \varphi(\vy^{k+1}).$
								We derive
								\begin{align}
									\notag
									&\mathbb{E}\left[\widetilde{g}( \vy^{(k+1)},\mu_k)- \widetilde{g}( \vy^{(k)},\mu_k) \right]\\
									\notag	\leq& \mathbb{E}\left[\left\langle\frac{1}{n}\sum_{i=1}^n\nabla_{\vy} \widetilde{{\Phi}}_i( \vy^{(k)},\mu_k), \vy^{(k+1)}- \vy^{(k)}\right\rangle\right]+\mathbb{E}\left[\frac{L^{(k)}}{2}\| \vy^{(k+1)}- \vy^{(k)}\|^2\right] +\mathbb{E}\left[ \varphi(\vy^{(k+1)}) - \varphi(\vy^{(k)})\right] \\
									\notag
									\stackrel{\eqref{eq:KKT2}}{=}& \mathbb{E}\left[\left\langle -\vgamma_{\vy}^{(k+1)}-L^{(k)}( \vy^{(k+1)}- \vy^{(k)}), \vy^{(k+1)}- \vy^{(k)}\right\rangle\right]+ \mathbb{E}\left[\frac{L^{(k)}}{2}\| \vy^{(k+1)}- \vy^{(k)}\|^2\right] \\ \notag&\quad\quad\quad\quad+\mathbb{E}\left[\left\langle\frac{1}{n}\sum_{i=1}^n\nabla_{\vy} \widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k}), \vy^{(k+1)}- \vy^{(k)}\right\rangle\right] + \mathbb{E}\left[\varphi(\vy^{(k+1)}) - \varphi(\vy^{(k)})\right]\\
									\notag\leq & -\frac{L^{(k)}}{2}\mathbb{E} \left[\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]  + \mathbb{E}\left[-\left\langle  \vgamma_{\vy}^{{(k+1)}}, \vy^{(k+1)}- \vy^{(k)}\right\rangle   + \varphi(\vy^{(k+1)}) - \varphi(\vy^{(k)})\right]
									\\\notag&\quad\quad\quad\quad\,\,+ \mathbb{E}\left[\frac{L^{(k)}}{4}\|\vy^{(k+1)}- \vy^{(k)}\|^2 + \frac{1}{L^{(k)}}\left\|\frac{1}{n}\sum_{i=1}^n \nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right] \\
									%\notag= & -\mathbb{E}\left[\frac{L^{(k)}}{2}\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]-
									%\mathbb{E}\left[\left\langle  \vgamma_{\vy}^{{(k+1)}}, \vy^{(k+1)}- \vy^{(k)}\right\rangle   + \varphi(\vy^{(k+1)}) - \varphi(\vy^{(k)})\right]
									%\\\notag&\quad\quad\quad\quad\,\,+ \mathbb{E}\left[\frac{L^{(k)}}{4}\|\vy^{(k+1)}- \vy^{(k)}\|^2 + \frac{1}{L^{(k)}}\left\|\frac{1}{n}\sum_{i=1}^n \nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right]  \\
									\leq &-\frac{L^{(k)}}{4}\mathbb{E}\left[\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]+ \frac{1}{L^{(k)}}\mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right],
									\label{eq:b2}
								\end{align}
								where the first inequality comes from the  $L^{(k)}$-smoothness of $\Phi_i$ for each $i\in[n]$, the second inequality holds by Young inequality, and the last inequality results from %~\eqref{eq:gradinetbias}, 
								the convexity of $\varphi$ and $\vgamma_{\vy}^{(k+1)}\in \partial \varphi(\vy^{k+1})$.
								
								Next, we bound the second term in the right hand side of \eqref{eq:b2}, 
								\begin{align}
									\notag
									& \mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right] 
									= \mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\frac{1}{m}\sum^{m}_{j=1}
									\mathcal{G}_{i_j}(\vy^{(k)},\mu_{k})\right\|^2\right]
									\\
									\notag\leq & 
									2\mathbb{E}\left[\left\| \frac{1}{m} \sum_{j=1}^m\nabla_{\vy}\widetilde{{\Phi}}_{i_j}( \vy^{(k)},\mu_k)-\frac{1}{m}\sum^{m}_{j=1}
									\mathcal{G}_{i_j}(\vy^{(k)},\mu_{k})
									\right\|^2\right]
									\\ & \notag\quad\quad\quad\quad\quad + 
									2\mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\frac{1}{m} \sum_{j=1}^m\nabla_{\vy}\widetilde{{\Phi}}_{i_j}( \vy^{(k)},\mu_k)
									\right\|^2\right] 
									\\\notag
									\leq & 2\widehat{\epsilon}_k^2 + 2\mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\frac{1}{m} \sum_{j=1}^m\nabla_{\vy}\widetilde{{\Phi}}_{i_j}( \vy^{(k)},\mu_k)
									\right\|^2\right]  \\
									= &  {2\widehat{\epsilon}_k^2 + \frac{2}{m}\frac{n-m}{n-1}\mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\nabla_{\vy}\widetilde{{\Phi}}_{i_1}( \vy^{(k)},\mu_k)
										\right\|^2\right]} \leq    2\widehat{\epsilon}_k^2 + \frac{8}{m}l_{\Psi}^2\leq 4\widehat{\epsilon}_k^2,
									% = &  2\widehat{\epsilon}_k^2 + \frac{1}{m}\mathbb{E}\left[\left\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\nabla_{\vy}\widetilde{{\Phi}}_{i_1}( \vy^{(k)},\mu_k)
									% \right\|^2\right] \leq    2\widehat{\epsilon}_k^2 + \frac{4}{m}l_{\Psi}^2\leq 4\widehat{\epsilon}_k^2,
									\label{eq:boundg2}
								\end{align}
								where the first inequality uses triangle inequality, the second one yields from \eqref{eq:gradinetbias2},  the  second equality holds because of sampling without replacement~\cite[Page 267]{mood1950introduction}, the third inequality uses $n-m\leq n-1$, and $\|\nabla_{\vy} \widetilde{\Phi}_i(\vy,\mu)\|\leq l_{\Psi}$ for all $i\in[n]$ from Lemma~\ref{lem:smoothphi}(b), and the last one follows by $m\leq \lceil 4l_{\Psi}^2 \widehat{\epsilon}_k^{-2}\rceil$.
								
								(b)  
								We deduce that
								\begin{align*}
									&\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k+1)},\mu_k)+  \vgamma_{\vy}^{{(k+1)}}\right\|^2\right] \\
									\leq & 2\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k+1)}}\right\|^2\right]  +2 \mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)- \frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k+1)},\mu_k)\right\|^2\right] 
									\\\leq & 2\mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)+  \vgamma_{\vy}^{{(k+1)}}\right\|^2\right]  +2\mathbb{E}\left[(L^{(k)})^2\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]
									\\
									\stackrel{\eqref{eq:KKT2}}{=}&  
									2\mathbb{E} \left[\left\|-L^{(k)}( \vy^{(k+1)}- \vy^{(k)}) + \left(\frac{1}{n}\sum_{i=1}^n \nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)- \mathcal{G}(\vy^{(k)},\mu_{k})\right)\right\|^2\right]+2\mathbb{E}\left[(L^{(k)})^2\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]\notag
									\\ \leq & 
									\frac{5(L^{(k)})^2}{2} \mathbb{E}\left[ \| \vy^{(k+1)}- \vy^{(k)}\|^2\right]
									+10 \mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n \nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)- \mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right] 
									\\ & \quad\quad\quad\quad\quad +2\mathbb{E}\left[(L^{(k)})^2\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]\notag\\
									=&  
									\frac{9 (L^{(k)})^2}{2} \mathbb{E}\left[ \| \vy^{(k+1)}- \vy^{(k)}\|^2\right] 
									+10 \mathbb{E}\left[\left\|\frac{1}{n}\sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)- \mathcal{G}(\vy^{(k)},\mu_{k})\right\|^2\right]
									\\ \le& 18 L^{(k)} \left(\mathbb{E} \left[\widetilde{g}( \vy^{(k)},\mu_k)- \widetilde{g}( \vy^{(k+1)},\mu_k)\right] +  \frac{4}{L^{(k)}}\widehat{\epsilon}_k^2 \right) +40 \widehat{\epsilon}_k^2
									\\ =& 18 L^{(k)} \mathbb{E} \left[\widetilde{g}( \vy^{(k)},\mu_k)- \widetilde{g}( \vy^{(k+1)},\mu_k)\right] +  {112}{}\widehat{\epsilon}_k^2,
								\end{align*}
								where we use triangle inequality in the first inequality, Lemma \ref{lem:smoothphi}(c) in the second one, and  Young's inequality in the third one. To obtain the last inequality, we have used $\mathbb{E}[\| \frac{1}{n} \sum_{i=1}^n\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_k)-\mathcal{G}(\vy^{(k)},\mu_{k})\|^2] \le 4 \widehat{\epsilon}_k^2$ from \eqref{eq:boundg2}, and
								$\frac{L^{(k)}}{4} \mathbb{E} \left[\| \vy^{(k+1)}- \vy^{(k)}\|^2\right]\leq -\mathbb{E}\left[\widetilde{g}( \vy^{(k+1)},\mu_k)- \widetilde{g}( \vy^{(k)},\mu_k)\right]   + \frac{4}{ L^{(k)}}\widehat{\epsilon}_k^2$
								from
								\eqref{eq:funcgap2}.   
								The proof is then completed.
							\end{proof}
							
							
							\subsection{Proof of Theorem \ref{thm:scaled2}}\label{sec:scaled2}
							\begin{proof} 
								Summing up \eqref{eq:kktregu2} for all $k=k_1, k_1+1,\ldots,K-1$, and noticing $L^{(k)}=C_2/\mu_k$, we have %\comm{Correct $\tau$}
								\begin{align}
									\notag
									\sum_{k=k_1}^{K-1} \frac{\mu_k}{C_2}\mathbb{E}\left[\left(\dist\left(\vzero, \partial\widetilde{g}( \vy^{(\tau+1)},\mu_\tau)\right)\right)^2\right]	=	&	\sum_{k=k_1}^{K-1} \frac{\mu_k}{C_2}\mathbb{E}\left[\left(\dist\left(\vzero, \partial\widetilde{g}( \vy^{(k+1)},\mu_k)\right)\right)^2\right]  \\ \leq & 18 \sum_{k=k_1}^{K-1}  \mathbb{E} \left[\widetilde{g}( \vy^{(k)},\mu_k)- \widetilde{g}( \vy^{(k+1)},\mu_k)\right] +  \sum_{k=k_1}^{K-1} \frac{112 \mu_k}{ C_2} \widehat{\epsilon}_k^2.
									\label{eq:sumgradient}
								\end{align}
								For the first term in the right hand side of \eqref{eq:sumgradient}, we have 
								\begin{align}
									\notag
									& \sum_{k=k_1}^{K-1} \mathbb{E} \left[\widetilde{g}( \vy^{(k)},\mu_k)- \widetilde{g}( \vy^{(k+1)},\mu_k)\right]  \\  
									\notag= &   \mathbb{E} \left[\widetilde{g}( \vy^{(k_1)},\mu_{k_1})- \widetilde{g}( \vy^{(K)},\mu_{K-1}) \right] +\sum_{k=k_1}^{K-2} \mathbb{E} \left[\widetilde{g}( \vy^{(k+1)},\mu_{k+1})- \widetilde{g}( \vy^{(k+1)},\mu_{k})\right]   \\
									\leq &   \mathbb{E} \left[\widetilde{g}( \vy^{(k_1)},\mu_{k_1})- \widetilde{g}( \vy^{(K)},\mu_{K-1})\right] +\sum_{k=k_1}^{K-2}  \frac{C_0}{\mu_{k+1}} \left(\mu_{k}- \mu_{k+1}\right), 
									\label{eq:difffunc}
								\end{align}
								where {the inequality follows from Lemma \ref{lem:distancemu}}, and $C_0$ is given therein.
								Substituting \eqref{eq:difffunc} into \eqref{eq:sumgradient} and multiplying each side by $\frac{C_2}{\sum_{k=k_1}^{K-1}{\mu_k}}$ yields 
								\eqref{eq:expectationsta}. 
							\end{proof}
							
							\subsection{Proofs of Corollaries \ref{cor:main1} and \ref{cor:main2}} \label{sec:cor}
							
							\begin{proof}
								(proof of Corollary \ref{cor:main1})
								We look at the three terms in the right hand side of \eqref{eq:expectationsta}. Since $\mu_k = \epsilon$ and $k_1=0$,
								the denominators of these terms are $\sum_{k=k_1}^{K-1} \mu_k = K \epsilon$. The first term satisfies $$\frac{18 C_2 \mathbb{E}\left[ \widetilde{g}(\vy^{(0)}, \epsilon) - \widetilde{g}(\vy^{(K)}, \epsilon) \right] }{K \epsilon} \leq \frac{18 C_2 \left(\widetilde{g}(\vy^{(0)}, \epsilon) - \min_{\vy}\widetilde{g}(\vy, \epsilon)\right)}{K \epsilon}\leq \frac{\epsilon^2}{2},$$ where the last inequality uses the definition of $K$. The second term is zero because $\mu_k = \epsilon$ for all $k\in[K]$. The third term simplifies to $\frac{112 K \epsilon   \widehat{\epsilon}_k^2}{K \epsilon} = {112  \left( \frac{\epsilon}{16} \right)^2}{} \leq \frac{\epsilon^2}{2}$. Summing the three bounds of the three terms, the right hand side of \eqref{eq:expectationsta} is less than $\epsilon^2$. This completes the proof.
							\end{proof}
							
							\begin{proof}
								(proof of Corollary \ref{cor:main2})
								Again, we look at the three terms in the right hand side of \eqref{eq:expectationsta}. Since $\mu_k = (k+1)^{-1/3}$ and $k_1=\lceil \epsilon^{-3}\rceil$,
								it holds $\mu_k \leq \epsilon$ for all $k=k_1,k_1+1,\ldots,K$, and 
								the denominators of these terms satisfy $\sum_{k=k_1}^{K-1} \mu_k \geq \sum_{k=k_1}^{K-1} \mu_{K-1} = (K-k_1) K^{-1/3} \ge \frac{1}{2}K^{2/3}$, when $K\ge 2\lceil \epsilon^{-3}\rceil=2k_1$. The first term satisfies $$\frac{18 C_2 \mathbb{E}\left[ \widetilde{g}(\vy^{(k_1)}, \mu_{k_1}) - \widetilde{g}(\vy^{(K)}, \mu_{K-1}) \right] }{\sum_{k=k_1}^{K-1} {\mu_k}} \leq \frac{36 C_2 \left(\widetilde{g}(\vy^{(k_1)}, \mu_{k_1}) - \min_{\vy,\mu\in(0,1]}\widetilde{g}( \vy,\mu) \right)}{K^{2/3}}\leq 
								\frac{36 C_2 l_{\Psi} D}{K^{2/3}}
								\leq
								\frac{\epsilon^2}{6},$$ where the second inequality uses 
								$\widetilde{g}( \vy^{(k_1)},\mu_{k_1})- \min_{\vy,\mu\in(0,1]}\widetilde{g}( \vy,\mu) \leq   l_{\Psi} D$  in Remark \ref{rem:23}, and the  last inequality holds when %\comm{Put the following condition of $K$ in the corollary.}
								$$K \geq \left(216C_2 l_{\Psi} D\right)^{\frac{3}{2}}\epsilon^{-3}.
								$$
								Here,  $D$ refers to the diameter of $\dom(\varphi)$. 
								The second term satisfies
								\begin{align}
									\notag
									\frac{18 \sum_{k=k_1}^{K-2}  \frac{C_0C_2}{\mu_{k+1}} \left(\mu_{k}- \mu_{k+1}\right)}{\sum_{k=k_1}^{K-1} {\mu_k}} &\leq \frac{36C_0C_2  }{K^{2/3}}\sum_{k=k_1}^{K-2}  \frac{1}{\mu_{k+1}} \left(\mu_{k}- \mu_{k+1}\right) = \frac{36C_0C_2  }{K^{2/3}}\sum_{k=k_1}^{K-2}  \frac{(k+1)^{-1/3} - (k+2)^{-1/3}}{(k+2)^{-1/3}}  \\
									\label{eq:Kupper}
									& = \frac{36C_0C_2  }{K^{2/3}}\sum_{k=k_1}^{K-2}  \left( \left( \frac{k+2}{k+1} \right)^{\frac{1}{3}}-1\right) 
									\leq \frac{36C_0C_2  }{K^{2/3}}\sum_{k=k_1}^{K-2}    \frac{1}{k+1} \leq  \frac{36C_0C_2 (\log(K)+1)  }{K^{2/3}}.
								\end{align}
								We have $  \frac{36C_0C_2    }{K^{2/3}} \leq \frac{\epsilon^2}{6}$ when $K \geq \left(216C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3},
								$
								and $\frac{36C_0C_2 \log(K)}{K^{2/3}} \leq \frac{\epsilon^2}{6}$ when $$K \geq \left(324C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3} \log\left( \left(324C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3}\right).
								$$
								Substituting the above two inequalities into \eqref{eq:Kupper}, we can bound the second term by $\frac{1}{3}\epsilon^2$. 
								The third term simplifies to $ {112  \left( \frac{\epsilon}{16} \right)^2}{} \leq \frac{\epsilon^2}{2}$. Summing the three bounds of the three terms, the right hand side of \eqref{eq:expectationsta} is less than $\epsilon^2$ when $$K= 
								\max\left\{2\lceil \epsilon^{-3}\rceil,  \left(216C_2 l_{\Psi} D\right)^{\frac{3}{2}}\epsilon^{-3}, \left(216C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3}, \left(324C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3} \log\left( \left(324C_0C_2\right)^{\frac{3}{2}}\epsilon^{-3}\right) 
								\right\}
								,$$ which is in the order of $\epsilon^{-3}\log(\epsilon^{-1})$. Since $\mu_k \leq \epsilon$ for all $k=k_1,k_1+1,\ldots,K$, we complete this proof.
							\end{proof}

\section{Conclusion}\label{sec:conclu}
%In this paper, 
We have introduced a stochastic smoothing framework to address the challenges of solving nonconvex-nonconcave min-sum-max problems, with a particular focus on applications in Wasserstein distributionally robust optimization (WDRO). 
We demonstrated a few key contributions that reflect the strength of our approach. First, we establish the Clarke regularity of the primal function, proving the equivalence between Clarke and directional stationary points of the target problem. This result simplifies algorithm design and ensures convergence guarantees. Second, we develop an SSPG algorithm that achieves global convergence to a Clarke stationary point and produces an $\epsilon$-scaled stationary point in $\tilde O(\epsilon^{-3})$ iterations. 
Our method is directly %specifically 
applicable to %solving 
WDRO. %i.e., Problem \eqref{eq:model2}, by iteratively solving the ``smoothed'' problem formulated in Equation \eqref{eq:smoothg2}.
Finally, our extensive numerical experiments confirm the reliability and efficacy of our proposed framework across different WDRO applications. %In the Newsvendor problem, it surpasses SDRO and GDMax in managing inventory levels. In regression tasks, our method achieves a much lower RMSE, demonstrating superior data relationship modeling and variability handling. Additionally, in adversarial deep learning challenges, it consistently outperforms in accuracy and stability against adversarial perturbations. Overall, our results establish our framework as a more effective tool for several optimization challenges within WDRO.



\section*{Acknowledgement}
We would like to thank Professor Xiaojun Chen from The Hong Kong Polytechnic University for the valuable suggestions on our early draft.
We also thank Dr. Jie Wang for sharing the code on SDRO.





%%%%%%%%%%%%%%%%%%%
% Bibliography 
%%%%%%%%%%%%%%%%%%%

\bibliographystyle{plain}
\bibliography{./inner/dro}



%%%%%%%%%%%%%%%%%%%
% Appendix 
%%%%%%%%%%%%%%%%%%%
\appendix
\section{Methods to Generate a Stochastic Gradient Estimator}
In this section, we detail two situation under which the gradient estimation condition \eqref{eq:gradinetbias2} can be satisfied. As noted in Remark \ref{rem:exact},
if, for all $i\in[n]$, the function \(\Psi(\vy, \cdot; \vx_i)\) exhibits certain structures, we can efficiently generate a stochastic gradient estimator.
For simplicity of notations, we fix $i\in[n]$ in this section, and
define $H(\vz):=\Psi(\vy, \vz; \vx_i)$.

\subsection{Computing a Stochastic Gradient Estimator with a Specific Loss Function and Support Set}\label{appen:piece} 
As noted in Remark \ref{rem:exact}, 
if  we can compute 
\(\mathbb{E}_{\vz\sim \zeta}[e^{H(\vz)/\mu}]\)
for all \(\mu > 0\), we can generate a desired stochastic gradient estimator.
We now introduce several situations, under which this expectation can be computed.

First, when \(H(\cdot)\) is a linear function and $\zeta$ is the uniform distribution over its support set, %it is possible to 
we can calculate  \(\mathbb{E}_{\vz\sim \zeta}[e^{H(\vz)/\mu}]\). 
This computation often reduces to evaluating the integrals of \(e^{\va^\top \vz + c}\) over \(\mathcal{Z}\).
Notably, \cite{Barvinok1992ComputingTV} demonstrates that for specific choices of \(\mathcal{Z}\), these integrals can be computed in polynomial time. Specifically, the authors provide efficient methods for the following four cases:
\begin{enumerate}
	\item[(i)] \(\mathcal{Z}\) is a regular simplex, i.e., \(\mathcal{Z}=\left\{\vz\in \mathbb{R}_{+}^{m_2}: \mathbf{1}\zz\vz=1\right\}\);
	\item[(ii)] \(\mathcal{Z} = [0,r]^{m_2}\) is a \(m_2\)-dimensional cube;
	\item[(iii)] \(\mathcal{Z}=\operatorname{conic}\left\{\vu_1, \ldots, \vu_s\right\} \subset \mathbb{R}^{m_2}\), is a   simple convex cone given as the conic hull of its extreme rays \(\vu_1, \ldots, \vu_s \in \RR^{m_2}\);
	\item[(iv)] $\mathcal{Z}$ is an intersection of several half-spaces.
\end{enumerate}




Second, if \(H(\cdot) \) is some specific piecewise linear functions and $\zeta$ is the uniform distribution over its support set, we can also %have the opportunity to 
compute \(\mathbb{E}_{\vz\sim \zeta}[e^{H(\vz)/\mu}]\).
For example, consider the truncated hinge loss function used in binary and multiclass classification~\cite{zhang2018robust},  given by  
$$H(\vz) = \max\{\va^\top \vz, 0\} - \max\{\va^\top \vz - 1, 0\}$$ with $\mathcal{Z} = \RR^{m_2}$ and $\va\in\RR^{m_2}$.
This function is nonconvex and nonconcave, and its graph shown in Figure \ref{fig:hinge}.  
To compute the desired expectation, we partition   $\mathcal{Z}$ into three regions: $\va^\top \vz\le 0$, $0\leq \va^\top \vz\leq 1$, and $\va^\top \vz\ge 1$. Let
$\zeta_1,\zeta_2$, and $\zeta_3$   denote the uniform distributions over these regions, respectively.
We then have
$$
\mathbb{E}_{\vz\sim \zeta}\left[e^{H(\vz)/\mu}\right] = 
\mathbb{E}_{\vz\sim \zeta_1}\left[1\right] + \mathbb{E}_{\vz\sim \zeta_2}\left[e^{\va^\top \vz/\mu}\right]
+\mathbb{E}_{\vz\sim \zeta_3}\left[e^{1/\mu}\right].
$$
Since $\{\vz: \va^\top \vz\le 0\}$
and $\{\vz: \va^\top \vz\ge 1\}$ are half-spaces, and 
$\mathbb{E}_{\vz\sim \zeta_2}\left[e^{\va^\top \vz/\mu}\right]$ can be calculated via a coordinate transformation, we can calculate $\mathbb{E}_{\vz\sim \zeta}\left[e^{H(\vz)/\mu}\right] $  in a polynomial time.

\begin{figure}[H]
	\centering 
	\includegraphics[width=0.4\linewidth]{./fig/hinge.eps}
	\caption{Truncated Hinge-loss with $\va=1$ and $\vz\in\RR$}\label{fig:hinge}
\end{figure}

\subsection{A Sampling Method to Generate a Stochastic Gradient Estimator}
\label{sec:sample}
In this subsection, 
we assume  access to an approximate maximizer of
$\max_{\vz\in\mathcal{Z}} \Phi(\vy^{(k)},\vz;\vx_i)$ for each $i\in[n]$.
Building on this assumption, we construct a specific measure that satisfies Assumption~\ref{def:zeta}, which enables the formulation of a corresponding smoothing function. Subsequently, we demonstrate how to generate a stochastic gradient estimator $\mathcal{G}_i(\vy^{(k)}, \mu_k)$
for the specific smoothing function. This estimator, obtained through sampling, satisfies the bias condition in~\eqref{eq:gradinetbias2}.
%We consider two scenarios: when we ; and when 
%we have a subdifferential error bound condition (see Assumption \ref{ass:errorbound}). 
%The latter is weaker than the former, since the subdifferential error bound condition
%allows us to efficiently find such an approximate maximizer. 
%\comm{The latter is a stronger assumption. No need to consider the two scenarios separately. Only need to consider the first scenario and then mention a few conditions that can ensure the first scenario.}\comm{We need to explain that even if a near maximizer can be found, our method is still new or can have better complexity results. I remember GDMax and GDA both require smoothness on the dual part (i.e., $z$). How about other method when the max part is concave or satisfies an error bound condition?}
Specifically, suppose we can access a point $\vz^{(k)}_i$ such that it is $\frac{\mu_k}{8l_{\Psi}}$-close to a global maximizer of problem $\max_{\vz\in\mathcal{Z}}\Psi(\vy^{(k)},\vz;\vx_i)$.
We construct $\zeta_{i}^{(k)}$ as the uniform distribution over the ball $\mathcal{B}_{\frac{\mu_k}{4l_{\Psi}}}(\vz_i^{(k)})$.  
Consequently,  $\zeta:=\zeta_i^{(k)}$ satisfies the conditions in Assumption~\ref{def:zeta}. By Lemma~\ref{lem:smoothphi}(a), $  \mu_k \log \mathbb{E}_{\vz\sim \zeta_i^{(k)}} [e^{\Psi(\cdot,\vz;\vx_i)/\mu_k}]$ is   a smoothing function of~$\Phi_i$ at $\vy^{(k)}$.
To approximate the gradient $\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_{k})$, we generate 
$M$ i.i.d. samples $\{\vz_j\}_{j=1}^M$ from $\zeta_i^{(k)}$ and approximate
$\widetilde{{\Phi}}_i( \vy^{(k)},\mu_{k})$ as
$$
\overline{\Phi}_i(\vy^{(k)},\mu_{k}) =\mu_{k} \log \left(\frac{1}{M} \sum_{j \in\left[M\right]} e^{(\Psi(\vy^{(k)},\vz_j;\vx_i)) / \mu_{k}}\right).
$$
The stochastic gradient estimator is then defined as 
\begin{equation}
	\label{eq:gradientg}
	\mathcal{G}_i(\vy^{(k)},\mu_k) := \nabla_{\vy}\overline{\Phi}_i(\vy^{(k)},\mu_k).
\end{equation}
Here, $\nabla_{\vy}\overline{\Phi}_i(\vy^{(k)},\mu_k)$ serves as an approximation of the true gradient $\nabla_{\vy}\widetilde{{\Phi}}_i( \vy^{(k)},\mu_{k})$,  with its 
accuracy improving as $M$ increases.  %The detailed algorithmic framework for generating a stochastic estimator is given in Algorithm \ref{alg:sampling}. \comm{No need to state the algorithm.}
%\begin{algorithm}[htbp!]
%	\caption{A sampling method to generate a stochastic gradient estimator  with an approximate maximizer}
%	\label{alg:sampling}
%	\begin{algorithmic}[1]
	%		\State Let $\zeta_{i}^{(k)}$ be the uniform distribution over  the ball $\mathcal{B}_{\frac{\mu_k}{4l_{\Psi}}}(\vz_i^{(k)})$.
	%		\State Generate $M$ point i. i. d. from $\zeta_{i}^{(k)}$, and $\mathcal{G}_i(\vy^{(k)}, \mu_k)$ by \eqref{eq:gradientg}.
	%	\end{algorithmic}
%\end{algorithm}


We establish the following two lemmas, to determine the required sample size 
$M$ for satisfying condition \eqref{eq:gradinetbias2}  with $\zeta = \zeta_i^{(k)}$.  


\begin{lemma}
	\label{lem:sampling1}
	Suppose Assumptions \ref{ass:problemsetup}--\ref{ass:lk} hold, and we have access to a point $\vz^{(k)}_i$ that is $\frac{\mu_k}{8l_{\Psi}}$-close to a global maximizer of problem $\max_{\vz\in\mathcal{Z}}\Psi(\vy^{(k)},\vz;\vx_i)$.
	Let $\vy=\vy^{(k)}$,  $\mu=\mu_k$, and   $\zeta=\zeta^{(k)}_{i}$ be the uniform distribution defined as above. Then ${\mathrm{Var}_{\vz \sim \zeta}\left[e^{\Psi(\vy,\vz;\vx_i) / \mu}\right]}\leq 3 {(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy ,\vz;\vx_i) / \mu}])^2} $,
	and 
	$\left\|{\mathrm{Var}_{\vz \sim \zeta}\left[e^{\Psi(\vy,\vz;\vx_i) / \mu}\nabla_{\vy}\Psi(\vy ,\vz;\vx_i) \right]} \right\|\leq 3l_{\Psi}^2 {(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2} $.
\end{lemma}

\begin{proof} 
	Since $\zeta$ is the uniform distribution over the ball $\mathcal{B}_{\frac{\mu}{4l_{\Psi}}}(\vz_i^{(k)})$, it holds $\|\vz_1-\vz_2\|\leq \frac{\mu}{2l_{\Psi}}$ for all $\vz_1,\vz_2\in \mathrm{supp}(\zeta)$. By 
	the $l_{\Psi}$-Lipschitz continuity of $\Psi$ from Assumption~\ref{ass:compact1}, we obtain that 
	\begin{align*}
		\max_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) - \min_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy ,\vz;\vx_i)  \leq l_{\Psi} \frac{\mu}{2l_{\Psi}} =\frac{\mu}{2}.
	\end{align*}
	Therefore,
	\begin{align*}
		&  \frac{{\mathrm{Var}_{\vz \sim \zeta} \left[e^{\Psi(\vy,\vz;\vx_i) / \mu}\right]}}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2}}   
		\leq    \frac{\mathbb{E}_{\vz\sim \zeta}[e^{2\Psi(\vy,\vz;\vx_i) / \mu}]}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2}}
		\leq    {e^{2\left(\max_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) - \min_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i) \right)/ \mu}}{} \leq e\leq 3,
	\end{align*}b
	where the second inequality uses $$\mathbb{E}_{\vz\sim \zeta}[e^{2\Psi(\vy,\vz;\vx_i) / \mu}]\leq e^{2\max_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)/ \mu}, \text{ and } \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}]\geq e^{\min_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy,\vz;\vx_i)/ \mu}.$$
	Similarly, using $\left\| 
	\nabla_{\vy}\Psi(\vy ,\vz;\vx_i)
	\right\|\leq l_{\Psi}$ from Assumption \ref{ass:compact1}, we have 
	\begin{align*}
		\frac{\left\|{\mathrm{Var}_{\vz \sim \zeta} \left[e^{\Psi(\vy ,\vz;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy ,\vz;\vx_i)\right]}\right\|}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy ,\vz;\vx_i) / \mu}])^2}}   
		\leq  &  \frac{\mathbb{E}_{\vz\sim \zeta}[e^{2\Psi(\vy ,\vz;\vx_i) / \mu} \left\| 
			\nabla_{\vy}\Psi(\vy ,\vz;\vx_i)
			\right\|^2]}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy ,\vz;\vx_i) / \mu}])^2}} \\
		\leq &  l_{\Psi}^2 {e^{2\left(\max_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy ,\vz;\vx_i) - \min_{\vz \in \mathrm{supp}(\zeta)}\Psi(\vy ,\vz;\vx_i) \right)/ \mu}}{} \leq 3l_{\Psi}^2.
	\end{align*}
	The proof is then completed.
\end{proof}

\begin{lemma}
	\label{cor:corvar}
	Under the same assumptions of Lemma \ref{lem:sampling1}, if $M\geq \left\lceil {12 l_{\Psi}^2 \widehat\epsilon^{-2} }\right\rceil$, then   $$\mathbb{E}\left\|\mathcal{G}_i(\vy,\mu) - \nabla_{\vy} \widetilde{{\Phi}}_i( \vy,\mu)\right\|^2 \leq \widehat\epsilon^2.$$
\end{lemma}
\begin{proof}  
	For simplicity of notations, let us denote $\vy=\vy^{(k)}$,  $\mu=\mu_k$, $\zeta=\zeta^{(k)}_{i}$, %as defined earlier,
	\begin{align*}
		&\Psi_1 := \frac{1}{M} \sum_{j \in\left[M\right]} [e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}],\,\, \Psi_2: =\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)],\\
		&\text{and }\Psi_3:= \frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] 
		\frac{1}{M} \sum_{j \in\left[M\right]}
		[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)].
	\end{align*}
	It holds
	\begin{align*}
		& \mathbb{E}\|\mathcal{G}_i(\vy,\mu) - \nabla_{\vy} \widetilde{{\Phi}}_i( \vy,\mu)\|^2\\
		= &\mathbb{E} \left\| \frac{\frac{1}{M} \sum_{j \in\left[M\right]}  [e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)] }{\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] } - \frac{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] }{\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] } \right\|^2 \\
		= & \mathbb{E}\left\| \frac{ \Psi_1 - \Psi_2 }{\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }   \right\|^2 \\
		\leq & 2\mathbb{E}\left\| \frac{\Psi_1  -  \Psi_3 }{\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }   \right\|^2  +  2\mathbb{E}_{\vz\sim \zeta}\left\| \frac{ \Psi_3 - \Psi_2}{\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}]  \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }   \right\|^2 \\
		\leq &2l^2_{\Psi}\mathbb{E}\left\| \frac{ \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] - \frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}] }
		{\mathbb{E}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }   \right\|^2 
		\\ &\quad+ 2\mathbb{E}\left\| \frac{\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)]  - \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] }{ \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] }   \right\|^2\\
		= &2l^2_{\Psi}\frac{ \mathbb{E}_{\vz\sim \zeta}\left\| \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}] - \frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu}]\right\|^2 }
		{ (\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2 }    
		\\ &\quad+ 2 \frac{\mathbb{E}_{\vz\sim \zeta}\left\|\frac{1}{M} \sum_{j \in\left[M\right]}[e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)]  - \mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}  \nabla_{\vy}\Psi(\vy,\vz;\vx_i)] \right\|^2}{ (\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2 }   \\
		= & \frac{2l^2_{\Psi}}{M}  \frac{{\mathrm{Var}_{\vz \sim \zeta} \left[e^{\Psi(\vy,\vz;\vx_i) / \mu}\right]}}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2}}   
		+\frac{2}{M}
		\frac{\left\|{\mathrm{Var}_{\vz \sim \zeta} \left[e^{\Psi(\vy,\vz;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz;\vx_i)\right]}\right\|}{{(\mathbb{E}_{\vz\sim \zeta}[e^{\Psi(\vy,\vz;\vx_i) / \mu}])^2}}  
		\leq    {\frac{12l^2_{\Psi}}{M},}
	\end{align*}
	where the first inequality uses the triangle inequality, the last one uses Lemma \ref{lem:sampling1}, and the second one holds by
	\begin{align*}
		\left\|\frac{1}{M} \sum_{j \in\left[M\right]} [e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)] \right\|^2\leq &
		\left( \frac{1}{M} \sum_{j \in\left[M\right]} \left\| e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \nabla_{\vy}\Psi(\vy,\vz_j;\vx_i)] \right\|\right)^2 \\ 
		\leq &
		\left(\frac{1}{M} \sum_{j \in\left[M\right]} l_{\Psi} \left| e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \right|\right)^2 = l_{\Psi}^2 \left(\frac{1}{M} \sum_{j \in\left[M\right]} e^{\Psi(\vy,\vz_j;\vx_i) / \mu} \right)^2.
	\end{align*} The proof is then completed.
\end{proof}

\begin{remark}
	Consider a convex support set \(\mathcal{Z}\). Below, we outline two scenarios for accessing an approximate maximizer of \(\max_{\vz \in \mathcal{Z}} \Psi(\vy, \vz; \vx_i)\).
	\begin{enumerate}
		\item 
		If \(\Psi(\vy, \cdot; \vx_i)\) is concave over \(\mathcal{Z}\) for all \(\vy \in \operatorname{dom}(\varphi)\), we can directly access a maximizer using a first-order subgradient method~\cite{nesterov2009primal}. This method guarantees convergence to a maximizer of \(\max_{\vz \in \mathcal{Z}} \Psi(\vy, \vz; \vx_i)\), leveraging the concavity of \(\Psi\).
		
		\item  
		When a subdifferential error bound condition~\cite{drusvyatskiy2018error} holds, we can efficiently compute an approximate maximizer. This condition states that, for any \(\vy \in \operatorname{dom}(\varphi)\), there exists a constant \(E_{\Psi} > 0\) such that for all \(i \in [n]\):
		\[
		\operatorname{dist}(\vz, S_{\vz}) \leq E_{\Psi} \cdot \operatorname{dist}(\vzero, \partial_{\vz} \Psi(\vy, \vz; \vx_i)), \quad \forall \vz \in \mathcal{Z},
		\]
		where \(S_{\vz}\) is the set of maximizers of \(\max_{\vz \in \mathcal{Z}} \Psi(\vy, \vz; \vx_i)\). %, and \(\Psi_{\vy}^*\) is the optimal value.  
		Under this condition, at the \(k\)-th iteration, we can employ a subgradient method~\cite{davis2019proximally} to efficiently compute a point \(\vz_i^{(k)} \in \mathcal{Z}\) satisfying
		$
		\|\vz_i^{(k)} - \bar{\vz}_i^{(k)}\| \leq \frac{\mu}{8l_{\Psi}},
		$
		where \(\bar{\vz}_i^{(k)}\) satisfies:
		\[
		\operatorname{dist}\left(0, \partial_{\vz} \Psi(\vy^{(k)}, \bar{\vz}_i^{(k)}; \vx_i) + \mathcal{N}_{\mathcal{Z}}(\bar{\vz}_i^{(k)})\right) \leq \frac{\mu}{8l_{\Psi}E_{\Psi}}.
		\]
		Once \(\vz_i^{(k)}\) is obtained, we construct a small ball \(\mathcal{B}_{\frac{\mu_k}{4l_{\Psi}}}(\vz_i^{(k)})\) that contains a maximizer of \(\max_{\vz \in \mathcal{Z}} \Psi(\vy, \vz; \vx_i)\), as guaranteed by the subdifferential error bound condition.
	\end{enumerate}
\end{remark}





 



 
%\input LBN_cvx2.bbl
\end{document}