\section{Background and Related Work}
\label{background_related_work}

The rapid advancements in artificial intelligence have paved the way for the development of multiagent systems, where multiple autonomous entities interact within shared environments to achieve individual or collective goals. Multiagent Reinforcement Learning (MARL) has emerged as a critical area of research within AI, addressing the unique challenges posed by these systems. These challenges include coordinating behaviors in dynamic and uncertain environments, managing conflicts between agents with competing objectives, and ensuring the scalability of solutions as the number of agents increases. MARL is particularly relevant in domains where complex decision-making and adaptability are required, such as robotics, logistics, and industrial automation.

In parallel, there has been growing interest in Constrained Reinforcement Learning (CRL), which extends traditional reinforcement learning to incorporate safety and performance constraints. This paradigm is crucial for ensuring that AI systems operate within acceptable boundaries, especially in high-stakes applications such as autonomous driving, healthcare, and energy management. Integrating constraints into MARL adds another layer of complexity, requiring innovative approaches to balance local and global requirements across multiple agents.

The maritime and logistics industries stand out as prominent domains where MARL and CRL have significant potential. As global trade and transportation continue to grow, optimizing operations in these sectors has become increasingly critical for reducing costs, improving efficiency, and minimizing environmental impact. However, the dynamic and interconnected nature of maritime logistics presents unique challenges, including the need for hierarchical decision-making and adherence to international regulations on emissions and sustainability.

Fairness in multiagent systems is another critical aspect that has garnered attention, particularly in scenarios where resource allocation or policy decisions affect diverse stakeholders. Ensuring equitable outcomes is essential for fostering cooperation and maintaining trust among participants. This is especially relevant in industrial contexts, where imbalanced policies can disadvantage smaller players, leading to inefficiencies and conflicts.

By exploring the intersections of MARL, CRL, maritime logistics, and fairness, this work aims to address key research gaps and advance the state of the art in these fields. The following sections provide a comprehensive review of existing literature and identify opportunities for future research.

\subsection{Multiagent Reinforcement Learning}
Multiagent Reinforcement Learning (MARL) has gained increasing prominence as a method to coordinate autonomous agents in complex, dynamic environments. MARL settings can be broadly categorized into cooperative and competitive domains. In cooperative scenarios, multiple agents aim to maximize a shared objective, exemplified by tasks such as cooperative robotics or emergency response ____. In contrast, competitive MARL addresses settings where agents have conflicting or opposing goals, including zero-sum games and competitive market models ____.

One core challenge in MARL involves \emph{scalability}: as the number of agents increases, the growth of state and action spaces becomes exponential, making learning computationally intractable ____. Techniques such as decentralized training with centralized execution (DTCE) ____ and parameter sharing ____ have partially mitigated this issue, although these methods often assume relatively homogeneous agent types. Additionally, agents typically operate under \emph{partial observability}, having access only to localized information ____, which can impede learning. Recent approaches that incorporate recurrent architectures ____ and communication protocols ____ show promise, but also increase computational overhead. Finally, \emph{non-stationarity} arises when multiple agents learn in parallel, making convergence to stable policies or equilibria more challenging ____. Mechanisms such as opponent modeling ____ and equilibrium learning ____ are active research areas aimed at alleviating these challenges.

\subsection{Constrained Reinforcement Learning}
Constrained Reinforcement Learning (CRL) introduces explicit constraints—often reflecting safety or performance thresholds—into the learning process. Early work employed Lagrangian relaxation ____, translating constrained optimization into unconstrained forms through penalty functions. More recent research on Constrained Policy Optimization (CPO) ____ uses trust-region methods to ensure constraints remain satisfied, offering theoretical performance guarantees at the cost of higher computational demands.

Alternative methods, such as primal-dual optimization and constraint sampling, propose additional ways of managing constraints. However, these techniques tend to struggle with scalability in multiagent contexts. When applied to MARL, the necessity of balancing both individual-agent constraints and system-wide limitations complicates policy design. Further, real-time constraints in large-scale applications—such as traffic networks or power grids—necessitate efficient CRL approaches that can handle multiagent interactions.

\subsection{MARL for Maritime \& Logistics}
The maritime sector has begun exploring MARL to optimize factors such as vessel routing, port operations, and scheduling. For instance, vessel routing studies show MARL can simultaneously reduce fuel consumption and improve scheduling efficiency. Meanwhile, research on port operations applies MARL to berth allocation, crane dispatch, and container handling.

Despite notable achievements, existing approaches rarely incorporate global emission caps enforced by international regulations like those of the IMO ____. Fairness considerations are also overlooked, potentially disadvantaging smaller shipping lines. While hierarchical coordination can help manage decisions across different levels (e.g., vessel-level, fleet-level), such methods remain relatively underexplored in the maritime domain. These gaps highlight the potential for a more robust and integrated MARL framework that can reconcile emission constraints and fairness goals with overarching operational objectives.

\subsection{Fairness in Multiagent Systems}
Fairness is crucial in multiagent resource-allocation problems, as policy decisions may disproportionately affect certain stakeholders. Foundational concepts like max-min fairness, envy-freeness, and Gini coefficients offer theoretical bases for diagnosing and mitigating inequality ____. In practice, such metrics have been employed in traffic management ____ and cloud computing, among other areas.

In industrial logistics, smaller firms risk systematic disadvantage when competition arises for shared resources,e.g., docking berths or emission budgets. Ensuring equitable outcomes is not only a moral imperative but also fosters cooperation, enhancing the real-world viability of multiagent solutions. Nonetheless, fair allocation is challenging to implement in MARL, where efficiency and equity often compete ____. More research is needed to integrate fairness constraints effectively in systems that also target high performance.

%Collectively, t
The literature indicates a strong need for hierarchical methods that incorporate both global constraints and fairness into MARL, especially in sustainable maritime logistics. Existing work offers only partial solutions, typically addressing isolated aspects like constrained optimization or static fairness scenarios. By bridging these gaps, future MARL frameworks can more effectively guide sustainable decision-making and policy enforcement in real-world maritime contexts.