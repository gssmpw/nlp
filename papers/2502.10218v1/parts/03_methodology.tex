\section{Methodology}\label{sec:Methodology} \label{sec:methodology}
\subsection{Sphinx Simulator}
 The drones provided by Parrot Drone are known for having long flight times and flight range and are equipped with powerful hardware and sensors for different applications as illustrated in \cite{sarabakha2023}, thus making them attractive also for scientific purposes. The publicly available simulator Sphinx \cite{parrot_sphinx}  allows the simulation of the drones \textit{Anafi} \cite{parrot_anafi} and \textit{Anafi Ai} \cite{parrot_anafi_ai} in customizable environments. Sphinx' physics back-end is based on a customized version of Gazebo 11 and the visualization front-end on a customized version of the graphic engine Unreal Engine 4.26  \cite{parrot_unreal_engine}. However, one major drawback of Sphinx is that it cannot simulate more than one drone instance at once \cite{sphinx_one_drone_only}.

Accurate simulation of the drone in Sphinx is achieved in terms of i) realistic flight physics by means of the customized Gazebo-based back-end and ii) realistic drone handling via simulated firmware which includes the flight control, navigation and hardware management stack of the real drone into the simulation. During runtime, the firmware and thus a variety of internal drone parameters can be controlled using a Python-based API called Olympe \cite{parrot_olympe}, for which a ROS wrapper has been introduced in \textit{anafi_ros} \cite{sarabakha2023}. Furthermore, simulated drone telemetry data can be retrieved using a provided website interface or a CLI tool. 

Static actors, i.e. static meshes, can be placed in the Sphinx environment in customizable poses. Furthermore, Parrot provides a set of ready-to-use dynamic actors such as cars and pedestrians for which trajectories can be defined before runtime  \cite{parrot_sphinx_populate_with_actors} using configuration files. User generated actors with customized appearance and motion characteristics can be realized in the modified UE4 editor provided by Parrot Drone. For this purpose  Blueprint functions can be used, a graphical programming approach resembling in its workflow MATLAB / Simulink. However, as outlined in Section \ref{sec:Introduction}, state information of  actors in the scene can neither be updated nor retrieved from outside Sphinx.
Technically, numerous plugins exist for updating actor states from outside UE4-based applications, e.g. also via ROS. Retrieving state information from inside the application could also be realized using C++ code which generally can be included in the UE4 editor.  However, Parrot Drone has blocked the usage of plugins \cite{parrot_unreal_engine_no_plugins}  and custom C++ code \cite{parrot_unreal_engine_no_cpp}, necessitating other  approaches for multi-robot scenarios.

\subsection{Connection between Sphinx and Gazebo}
We propose a framework that uses ROS as central middleware to exchange data between the framework's different components.  These components not only allow to send commands to the drone in the Sphinx simulator but also to retrieve ground truth data of the drone state as well as the drone's state estimate. We use this information to set up a `mirrored' drone instance in Gazebo. This enables us  to leverage the flight behaviour of the Anafi drone simulated by Sphinx in an Gazebo-based, multi-robot environment. Figure \ref{fig:overview} illustrates the components necessary to realize the connection between Sphinx and Gazebo. 
\begin{figure}[thpb]
      \centering
		\includegraphics[scale=0.31]{./pics/dataflow_small.pdf}
\caption{Overview of the dataflow and connection between the components enabling the interface between Sphinx and Gazebo. Simulators are colored orange, components relying on ROS are colored blue. The simulated firmware is a stand alone module provided by Parrot Drone and colored green. The boxes next to the arrows indicate the tool managing the communication with the respective components. }
\label{fig:overview}
 \end{figure}

The \textit{Sphinx} component is an instance of the Sphinx simulator running an empty world in which the Anafi drone is spawned. The drone parameters can be accessed via the simulated firmware implemented as a daemon called Firmwared, as is indicated by the \textit{Simulated Firmware} block. Parrot Drone provides a Python-based API called Olympe to communicate with the firmware. The component \textit{anafi_ros} \cite{sarabakha2023} constitutes a ROS wrapper for Olympe which allows sending and retrieving drone information via ROS topics, a necessity to realize other functionalities that are implemented elsewhere in the ROS system, e.g. controllers.
The \textit{Interface} component accesses the Sphinx simulator via a CLI tool provided by Parrot Drone for the purpose of retrieving ground truth data about the Anafi drone. This ground truth data comprises the following. The pose and the linear and angular velocity vectors in both, world frame (an East-North-Up coordinate system) and the body center reference frame. Furthermore, the linear and angular acceleration is available in the body center reference frame only. The gimbal position and orientation and thus the pose of the camera are provided in world frame.

This information is used to set up two  objects in Gazebo. The first is a robot model consisting only of a mesh  of the Anafi drone for visualization of its pose as retrieved from Sphinx.  The second is a camera plugin whose position and orientation is governed by the gimbal of the Anafi drone in Sphinx. Common to both objects is that the influence of gravity is deactivated. This avoids a jittering behaviour in the model's position which is induced by the influence of gravity in between updates of the pose. Furthermore, collision capabilities are disabled. This is due to the missing possibility to feed collision data back into Sphinx to then have an effect on the flight behaviour of the simulated drone.

A critical issue when  running two interfaced simulations in parallel is timing. Both simulations need to run with the same speed as to prevent data loss during exchanging data. Since it is not possible to update Sphinx and Gazebo on a step-wise basis, we address this issue by reducing the real time factor (RTF) to a value which can be reached by both simulations simultaneously. On our setup (see Section \ref{sec:implementation}) this is the case for $RTF =0.6$.


\subsection{Controller Design}
We implement two types of controllers to address the problem of the Parrot Drone-provided PID-based waypoint controller showing the undesired start-stop behaviour. The first controller is PID-based using cascaded and single loop controller structures, the second is a MPC. Both control frameworks are introduced in the following. Common to both controllers is that they take  a stream of waypoints as input and generate as output setpoint values for the roll and pitch angle as well as for the yaw rate and the vertical velocity which are then sent to the Anafi \textit{Firmware} component via the \textit{anafi_ros} wrapper.
A waypoint is hereby defined as a tuple of values
\begin{equation}
WP = \left\lbrace x_{ref},y_{ref},z_{ref},v_{x,ref},v_{y,ref},v_{z,ref},\psi_{world,ref}\right\rbrace,
\end{equation} 
where $x_{ref},y_{ref},z_{ref}$ denote the desired positions, $v_{x,ref},v_{y,ref},v_{z,ref}$ the desired velocity and $\psi_{world,ref}$ the desired yaw angle in the world frame, an east-north-up (ENU) coordinate system.
\subsection{PID Controller Framework} \label{sec:pid_controller_framework}
Under the assumptions of i) linearization around hover flight, ii) small angles, iii) a rigid, symmetric vehicle body and iv) no aerodynamic effects \cite{wang2016}, the axes of motion are decoupled  allowing to control the longitudinal, lateral, vertical and yaw movement independently using four different controllers, each controlling one direction of motion. Against this background, the first controller framework we propose consists of a set of PID controllers, in a single loop structure for the vertical velocity and yaw angle and in a cascaded structure for the longitudinal and lateral motion, the latter structure illustrated by Figure \ref{fig:cascaded_PI_controller}. In this figure, the reference position $p_{ref}$  denotes the position on the  coordinate axes associated with  the respective controller but transformed into the stability axes. The stability axes are a separate coordinate system moving along with the drone, accordingly its center resides in the drone's center of gravity. The x-axis resides in the symmetry plane of the drone in longitudinal direction and forms along with the y-axis a horizontal plane. The vertical axis points upwards, completing the right-hand system. In the stability frame the pitch angle $\theta_{ref}$ and the roll angle $\phi_{ref}$ are defined, where the pitch angle controls the longitudinal and the roll angle the lateral motion. The desired yaw angle is set via the yaw rate and the vertical motion via the vertical velocity.

\begin{figure}[thpb]
      \centering
		\includegraphics[scale=1]{./pics/cascaded_PID_controller.pdf}
\caption{Cascaded PID controller structure for the longitudinal and lateral motion. }
\label{fig:cascaded_PI_controller}
 \end{figure}

\subsection{Quadratic Model Predictive Controller}\label{sec:mpc}
In order to reduce the tacking error present for PID based tracking controllers, we focus on the reduction of the offset between the moving target waypoint and the drone during the design of the MPC by introducing cumulative error states. In this regard, using a quadratic formulation of the MPC is beneficial as convex quadratic optimization problems are fast to solve and computationally cheap \cite{boyd2004}.

We use the implementation of a constrained linear-quadratic MPC using the solver OSQP \cite{osqp} and define the following finite-horizon optimal control problem to be solved at each time step
\begin{equation}
\begin{split}
\begin{array}{ll}
\mathbf{x}^*_0,\mathbf{x}^*_1, \ldots, \mathbf{x}^*_{N}& ,\mathbf{u}^*_0,\mathbf{u}^*_1, \ldots, \mathbf{u}^*_{N} \\
 = \underset{\mathbf{u}_0,\mathbf{u}_1, \ldots, \mathbf{u}_{N}}{ \mbox{arg min} }  & (\mathbf{x}_N-\mathbf{z}_{N})^T \mathbf{Q}_N (\mathbf{x}_N-\mathbf{z}_{N}) +\\
  					 & \sum_{k=0}^{N-1} (\mathbf{x}_k-\mathbf{z}_{k})^T \mathbf{Q} (\mathbf{x}_k-\mathbf{z}_{k}) + \mathbf{u}_k^T \mathbf{R} \mathbf{u}_k \\
  \mbox{subject to} & \mathbf{x}_{k+1} = \mathbf{A} \mathbf{x}_k + \mathbf{B} \mathbf{u}_k \\
  					 & \mathbf{z}_{k+1} = \mathbf{A}_r \mathbf{z}_{k}  \\
                    & \mathbf{x}_{\rm min} \le \mathbf{x}_k  \le \mathbf{x}_{\rm max} \\
                    & \mathbf{u}_{\rm min} \le \mathbf{u}_k  \le \mathbf{u}_{\rm max} \\
                    & \mathbf{x}_0 = \bar{\mathbf{x}}\\
                    & \mathbf{z}_{0} =\bar{\mathbf{z}},
\end{array}
\end{split}\label{eq:MPC}
\end{equation} 
where $\mathbf{z}_{k}\in\mathbb{R}^{n_x}$ denotes the reference state vector that shall be tracked by the state vector  $\mathbf{x}_k\in\mathbb{R}^{n_x}$, with $n_x\in\mathbb{N}$ states each. The input vector to the dynamic model   $\mathbf{x}_{k+1} = \mathbf{A} \mathbf{x}_k + \mathbf{B} \mathbf{u}_k $ is  $\mathbf{u}_k\in\mathbb{R}^{n_u}$ with $n_u\in\mathbb{N}$ inputs.   $\mathbf{x}_{\rm min}$,  $\mathbf{x}_{\rm max}$, $\mathbf{u}_{\rm min}$ and $\mathbf{u}_{\rm max}$ denote the state and input limits. The initial states  $\mathbf{x}_0 = \bar{\mathbf{x}}$ and $\mathbf{z}_{0}= \bar{\mathbf{z}}$ are updated repeatedly for each execution of the optimization problem. In each execution cycle the MPC computes an optimal trajectory for the controller input, $\mathbf{u}^*_0,\mathbf{u}^*_1,\mathbf{u}^*_2 \ldots \mathbf{u}^*_{N} $ which lead to the optimal state trajectory  $\mathbf{x}^*_0,\mathbf{x}^*_1,\mathbf{x}^*_2 \ldots \mathbf{x}^*_{N} $ that best tracks the reference states $\mathbf{z}_k$. 
We define the reference state vector $\mathbf{z}_k$ and state vector $\mathbf{x}_k$ as follows.
\begin{dmath}
\mathbf{z}_k = \left[x_{ref,k},  x_{ref,k},  y_{ref,k},  y_{ref,k},  z_{ref,k},  z_{ref,k},...\\ v_{x,ref,k},v_{x,ref,k}, v_{y,ref,k}, v_{y,ref,k},  v_{z,ref,k},v_{z,ref,k},...  \\x_{cum,ref,k},  y_{cum,ref,k},  z_{cum,ref,k},...\\ v_{x,cum,ref,k},  v_{y,cum,ref,k}, v_{z,cum,ref,k}\right]^T,
\end{dmath}
\begin{dmath}
\mathbf{x}_k = \left[x_{ref,k},  x_k,  y_{ref,k},  y_k,  z_{ref,k},  z_k,...\\ v_{x,ref,k},v_{x,k}, v_{y,ref,k}, v_{y,k},  v_{z,ref,k},v_{z,k},...  \\x_{cum,k},  y_{cum,k},  z_{cum,k},...\\ v_{x,cum,k},  v_{y,cum,k}, v_{z,cum,k}\right]^T,
\end{dmath}
where $x_{ref,k}$, $y_{ref,k}$, $z_{ref,k}$, $v_{x,ref,k}$, $v_{y,ref,k}$, $v_{z,ref,k}$ denote the waypoint's position and velocity coordinates, $x_k$, $y_k$, $z_k$, $v_{x,k}$, $v_{y,k}$, $v_{z,k}$ the position and velocity coordinates of the drone, and $x_{cum,ref,k}$, $ y_{cum,ref,k}$, $ z_{cum,ref,k}$ as well as $v_{x,cum,ref,k}$, $ v_{y,cum,ref,k}$, $v_{z,cum,ref,k}$ denote the reference values for the cumulative errors $x_{cum,k}$, $y_{cum,k}$, $z_{cum,k}$ and $v_{x,cum,k}$, $v_{y,cum,k}$, $v_{z,cum,k}$, respectively, each at the prediction step $k \in \left\lbrace 0,1,2,\ldots,N \right\rbrace$.
The reason why the reference values are part of the state vector $\mathbf{x}$  is that they need to be included in the formulation of the dynamic model as to be able to build the cumulative error necessary for reducing the tracking offset. This is also why the reference values appear twice in the reference vector $\mathbf{z}_k$.

 
The dynamics model $\mathbf{x}_{k+1} = \mathbf{A} \mathbf{x}_k + \mathbf{B} \mathbf{u}_k $ of the MPC is defined by the matrices $\mathbf{A},\mathbf{B}$ as follows.
\begin{equation}
\mathbf{A} =
\begin{bmatrix}
    \mathbf{I}_6 & \Delta t \mathbf{I}_6 & \mathbf{0}_{6 \times 6} \\
    \mathbf{0}_{6 \times 6} & \mathbf{I}_6 & \mathbf{0}_{6 \times 6} \\
	 &	\begin{bmatrix}
		1 & -1 & 0 & \cdots & 0 \\
		0 & 1 & -1 & \cdots & 0 \\
		0 & 0 & 1 & \cdots & 0 \\
		0 & 0 & 0 & \ddots & 0 \\
		\vdots & \vdots & \vdots & \ddots & 0 \\
		0 & 0 & 0 & \cdots & -1 
	\end{bmatrix}_{6\times 12} & \mathbf{I}_{6 \times 6}
\end{bmatrix}
\end{equation}

The upper part consisting of the first two rows of matrices defines a simple mass point model. The lower $6\times12$ matrix computes the difference in position and velocity between the waypoint and the drone. This offset is added to the existing cumulative error as indicated by the matrix $\mathbf{I}_{6\times6}$ in the lower right corner. 
The input vector to the dynamics model $\mathbf{u}$  is defined as
\begin{dmath}
\mathbf{u} = \left[a_x,a_y,a_z\right]^T.
\end{dmath}
The input matrix $\mathbf{B} = \left[ \mathbf{b}_1,\mathbf{b}_2, \mathbf{b}_3 \right]$  specifies how the control inputs $\mathbf{u}$ influence the states associated with the drone's position and velocity.
\begin{align}
\mathbf{b}_1 & = \left[\mathbf{0}_{1\times1},\Delta t^2/2 , \mathbf{0}_{1\times5},\Delta t ,\mathbf{0}_{1\times10} \right]^T \notag   \\ 
\mathbf{b}_2 & = \left[\mathbf{0}_{1\times3},\Delta t^2/2 , \mathbf{0}_{1\times5},\Delta t ,\mathbf{0}_{1\times8} \right]^T\\
\mathbf{b}_3 & = \left[\mathbf{0}_{1\times5},\Delta t^2/2 , \mathbf{0}_{1\times5},\Delta t ,\mathbf{0}_{1\times6} \right]^T  \notag
\end{align}

The matrix $\mathbf{A}_{r}$ defines a simple constant velocity model which is used to update the reference state $\mathbf{z}_{k}$ over the prediction horizon. In tracking scenarios, it is commonly assumed that each waypoint $WP$ is associated with a velocity vector, which defines the expected motion of the waypoint over time.
\begin{equation}
\mathbf{A}_{r} =
\begin{bmatrix}
\mathbf{I}_{6\times6} & \begin{bmatrix} \Delta t & 0 \\ \Delta t & 0\end{bmatrix} \otimes \mathbf{I}_{3\times3} & \mathbf{0}_{6\times6} \\ 
\mathbf{0}_{6\times6} & \begin{bmatrix} 1 & 0 \\ 1 & 0\end{bmatrix} \otimes \mathbf{I}_{3\times3} & \mathbf{0}_{6\times6} \\ 
&\mathbf{0}_{6\times18}&\\
\end{bmatrix}
\end{equation}
Careful testing has revealed that best tracking capabilities are achieved when $a_{x}, a_{y}$ taken from $\mathbf{u}_0^*$ (see \eqref{eq:MPC})  are published to the drone. For the longitudinal and lateral motion, these  accelerations are translated via the following equations into the required pitch angle $\theta$ and the roll angle $\phi$.

\begin{align}
\theta &= \sin^{-1}(a_{x} / g)\\
\phi &= \sin^{-1}(a_{y} / g)
\end{align}
For the required vertical velocity to set the altitude of the drone the value $v_{z}$ taken from $\mathbf{x}_5^*$ (see \eqref{eq:MPC}) has proven most successful. The yaw angle is not controlled by the MPC but by the same single loop PID controller used in the framework described in Section \ref{sec:pid_controller_framework}.
