\section{Related Works}
% When pretraining language models, a large amount of text corpus is often crawled from the internet. However, several studies \cite{li2023textbooks, zhou2024lima} suggest that high-quality data is more beneficial to the model's performance.

% To select high-quality data, a common strategy involves utilizing rules crafted by human experts \cite{raffel2020exploring, rae2021scaling, laurenccon2022bigscience, together2023redpajama, penedo2024fineweb}, such as removing HTML tags and emoticons \cite{laurenccon2022bigscience} or excluding sentences that are either too short or excessively long \cite{rae2021scaling}. However, these methods often fall short in effectively selecting high-quality data based on semantic content.

% Research has revealed that text corpus often contains numerous duplicate sentences \cite{lee2022deduplicating, sorscher2022beyond, abbas2023semdedup, cerebras2023slimpajama, tirumala2024d4}. SemDeDup \cite{abbas2023semdedup} employs k-means clustering to group similar data and retains only one representative sample from each cluster, while \citeauthor{sorscher2022beyond} (\citeyear{sorscher2022beyond}) use SSL Prototypes to systematically eliminate prototypical data. However, only removing duplicates is insufficient to eliminate all low-quality samples.

% Utilizing a target data source or proxy model is also a common solution \cite{wenzek2020ccnet, xie2023data, marion2023less, thakkar2023self, engstrom2024dsdm, yu2024mates}. DSIR \cite{xie2023data} calculates the distribution difference between the source and target dataset as data sampling weight. Additionally, data influence is also considered as an important metric of data quality \cite{thakkar2023self, engstrom2024dsdm, yu2024mates}. Furthermore, some studies \cite{wenzek2020ccnet, marion2023less} measure the perplexity as a selection criterion.

% Training a classifier is a more straightforward method \cite{du2022glam, gururangan2022whose, zhang2024autonomous, wettig2024qurating, sachdeva2024train}. \citeauthor{du2022glam} (\citeyear{du2022glam}) implemented a logistic regression binary classifier to score the data, while some studies train more complex neural network scorers 
%  \cite{zhang2024autonomous, sachdeva2024train}. Additionally, QuRating \cite{wettig2024qurating} trains multiple raters with a finer-grained approach to analyze the contribution of data to model performance improvement from different dimensions.

% The aforementioned methods primarily focus on selecting data from a single aspect. While QuRating has developed raters across multiple dimensions, it has not thoroughly explored how to effectively integrate these raters, which is meticulously addressed in our research.