\section{Related Work}
\textbf{Anomaly detection models.}
Deep learning models~\cite{pang2021deep} have been widely adopted for anomaly detection due to their powerful capabilities. 
Variational autoencoder (VAE) based models~\cite{zhou2021vae} are utilized to learn latent representations for this task. 
The Anomaly Transformer~\cite{xu2021anomaly} demonstrates significant effectiveness by jointly modeling pointwise representations and pairwise associations. 
Additionally, a diffusion model~\cite{xiao2023imputation} has been proposed to detect anomalies through data imputation. 
However, as these models grow in size and complexity, they become increasingly opaque, providing only binary detection results without insight into the underlying decision-making process. 
% This lack of transparency makes it challenging to understand how the models arrive at their conclusions. 
Moreover, these models typically require large datasets, which may not be feasible in many real-world applications.

\begin{figure*}
\centering
\includegraphics[width=0.81\textwidth]{figures/model_0814.pdf} 
\caption{A 3-variable example dynamical system. 
$\protect\circled{1}$ Train ICODE using data from normal periods to establish the baseline causality relationship $C$.
$\protect\circled{2}$ Apply the trained ICODE to detect anomalies in anomaly period.
$\protect\circled{3}$ Retrain the model using the anomalous data to obtain a new causality relationship $C'$.
$\protect\circled{4}$ Analyze the causality difference $|C-C'|$ to classify the anomaly type; $\protect\circled{5}$ Apply Eq. (\ref{eq:get-root-cause}) or Eq. (\ref{eq:get-root-cause-2}) to identify the root cause.
}.

\label{fig:architecture}
\vspace{-0.27in}
\end{figure*}


\textbf{Root Cause Analysis models.}
Root cause analysis (RCA) using machine learning~\cite{lei2020applications, richens2020improving} has gained increasing popularity in recent years. 
For example, a variational autoencoder model~\cite{han2023root} leverages a known causal graph to identify root causes based on Pearl's structural causal model. 
However, these models often require precise causal relationships and separate models for anomaly detection, which is challenging in practice. 
Obtaining accurate causal graphs is sometimes challenging, and deploying two individual models can be cost-prohibitive. 
Other RCA methods based on causal structures have been proposed~\cite{budhathoki2022causal, wang2023interdependent}, but they typically assume anomalies are outliers, 
which is not always valid, leading to potential inaccuracies in the learned causality architecture.

\textbf{Model Explainability using Neural ODEs.} 
Model-intrinsic-explainable models are designed with inherent transparency, allowing direct interpretation of their decisions and processes from their internal structures~\cite{Lakkaraju2016,Lou2012}. Self-explainable Neural Networks (SENN) employ explainable basis concepts for explicit and faithful predictions and classification~\cite{alvarez2018towards}. 
Building on SENN, the GVAR model learns causal relationships within time series data using an interpretable framework~\cite{marcinkevivcs2021interpretable}. 
Additionally, time series systems often follow differential equations, and Neural ODEs have been proposed to approximate these systems~\cite { jia2019neural, asikis2022neural}. 
However, using model-intrinsic-explainable models enhanced by Neural ODEs to learn patterns in dynamic systems for anomaly detection and RCA remains largely unexplored.
% Self-explaining neural networks (SENN)~\cite{alvarez2018towards} represent a class of intrinsically interpretable models motivated by properties of explicitness, faithfulness, and stability. 
% A SENN with a link function $g(*)$ and interpretable basis concepts $h(x):\mathbb{R}^p \rightarrow \mathbb{R}^k$ follows the form
% \begin{equation}
% \label{eq:senn}
%     f(x) = g(\theta(x)_1h(x)_1, ..., Î¸(x)_kh(x)_k), 
% \end{equation}
% where $x\in \mathbb{R}^p$ are predictors; $\theta(*)$ is a neural network with $k$ outputs.
% In~\cite{marcinkevivcs2021interpretable}, $g(*)$ is set as the sum of the raw inputs, Eq. (\ref{eq:senn}) is simplified as 
% \begin{equation}
%     f(x) = \sum_{j=1}^p \theta(x)_j x_j.
% \end{equation}