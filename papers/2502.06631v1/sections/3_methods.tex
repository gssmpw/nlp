\section{Methods}

\subsection{Experimental settings}\label{sec:datasets}
We conduct our experiments using three video clip datasets: HMDB51 (51 classes) \cite{hmdb51}, UCF101 (101 classes) \cite{soomro2012ucf101} and Kinetics400 (400 classes) \cite{carreira2017quo}. For HMDB51 and UCF101, we use all available samples and split them into a 10-shot calibration set and a testing set. For Kinetics400, we apply the same splitting method to the testing and validation samples from the official split from \cite{carreira2017quo}. The results reported are averaged over 40 random seeds for data splitting.

To compute embeddings for each video clip, we extract 10 frames at uniform intervals throughout the video, and use the average of their corresponding visual embeddings, yielding a single global embedding per video. This approach corresponds to the Global Average Pooling (GAP) method described in~\cite{wang2021actionclip}. For text prompts, we use the template: "a photo of a person doing \{class\}." Unless otherwise specified, we use a CLIP model with a ViT-B/16 image encoder. Using this setup, we achieve base accuracies of 54\% on Kinetics400, 69\% on UCF101 and 48\% on HMDB51.

\subsection{Temperature tuning for tail size reduction}
In the upper part of Figure \ref{fig:intro_set_sizes}, we observe how a Conformal Predictor, when combined with an off-the-shelf VLM significantly reduces the number of classes from which a human expert must choose. However, distribution of set sizes appears long-tailed on the right. This means that, for a small proportion of samples, the number of classes in the conformal set remains relatively large.

Previous research has shown that human decision time increases with the number of available choices \cite{hick1952rate, landauer1985selection}, and many practical scenarios follow \textit{Hick's law}, which describes a logarithmic relationship. More recent studies suggest a sigmoidal model \cite{pavao2016sequence} to capture the dependence of decision time on task uncertainty, for which the number of classes in the conformal sets could serve as a proxy. This highlights the importance of controlling the tail of the set size distribution, especially for applications such as live video monitoring, where the maximum time spent by a human operator to annotate a data point is limited.

As $\tau$, the temperature parameter, affects the predicted soft labels through Equation \ref{eq:softmax_labels}, its variation indirectly influences the distribution of the non-conformity scores derived from the 10-shots calibration sets (Equation \ref{eq:nonconf}). Consequently, $\tau$ also impacts the value of $\hat{q}$, the $1-\alpha$ quantile of these non-conformity scores. The relationship between $\hat{q}$ and $\tau$, shown on Figure \ref{fig:temp_selection} for different $\alpha$, is convex. To minimize the tail of the conformal set sizes distribution, we select the temperature $\tau_* = \arg \min_{\tau \in\mathbb{R}} \hat{q}(\tau)$.

\input{figures/temp_selection}