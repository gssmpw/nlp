@inproceedings{Das24,
  author       = {Abhimanyu Das and
                  Weihao Kong and
                  Rajat Sen and
                  Yichen Zhou},
  title        = {A decoder-only foundation model for time-series forecasting},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=jn2iTJas6h},
  timestamp    = {Mon, 02 Sep 2024 16:55:26 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/DasKSZ24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Dong24,
  author       = {Jiaxiang Dong and
                  Haixu Wu and
                  Yuxuan Wang and
                  Yunzhong Qiu and
                  Li Zhang and
                  Jianmin Wang and
                  Mingsheng Long},
  title        = {TimeSiam: {A} Pre-Training Framework for Siamese Time-Series Modeling},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=wrTzLoqbCg},
  timestamp    = {Mon, 02 Sep 2024 16:55:27 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/DongWWQ00L24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Ekambaram24,
  author       = {Vijay Ekambaram and
                  Arindam Jati and
                  Nam H. Nguyen and
                  Pankaj Dayama and
                  Chandra Reddy and
                  Wesley M. Gifford and
                  Jayant Kalagnanam},
  title        = {Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot
                  Forecasting of Multivariate Time Series},
  journal      = {CoRR},
  volume       = {abs/2401.03955},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.03955},
  doi          = {10.48550/ARXIV.2401.03955},
  eprinttype    = {arXiv},
  eprint       = {2401.03955},
  timestamp    = {Thu, 01 Feb 2024 07:50:10 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2401-03955.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Kamarthi23,
  author       = {Harshavardhan Kamarthi and
                  B. Aditya Prakash},
  title        = {Large Pre-trained time series models for cross-domain Time series
                  analysis tasks},
  journal      = {CoRR},
  volume       = {abs/2311.11413},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2311.11413},
  doi          = {10.48550/ARXIV.2311.11413},
  eprinttype    = {arXiv},
  eprint       = {2311.11413},
  timestamp    = {Thu, 23 Nov 2023 12:06:25 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2311-11413.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Liu24,
  author       = {Yong Liu and
                  Haoran Zhang and
                  Chenyu Li and
                  Xiangdong Huang and
                  Jianmin Wang and
                  Mingsheng Long},
  title        = {Timer: Generative Pre-trained Transformers Are Large Time Series Models},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=bYRYb7DMNo},
  timestamp    = {Mon, 09 Sep 2024 19:07:31 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/LiuZLH0L24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Liuzd24,
  author       = {Zhiding Liu and
                  Jiqian Yang and
                  Mingyue Cheng and
                  Yucong Luo and
                  Zhi Li},
  editor       = {Ricardo Baeza{-}Yates and
                  Francesco Bonchi},
  title        = {Generative Pretrained Hierarchical Transformer for Time Series Forecasting},
  booktitle    = {Proceedings of the 30th {ACM} {SIGKDD} Conference on Knowledge Discovery
                  and Data Mining, {KDD} 2024, Barcelona, Spain, August 25-29, 2024},
  pages        = {2003--2013},
  publisher    = {{ACM}},
  year         = {2024},
  url          = {https://doi.org/10.1145/3637528.3671855},
  doi          = {10.1145/3637528.3671855},
  timestamp    = {Sun, 08 Sep 2024 16:05:53 +0200},
  biburl       = {https://dblp.org/rec/conf/kdd/LiuYCLL24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Ma24,
  author       = {Xiangkai Ma and
                  Xiaobin Hong and
                  Wenzhong Li and
                  Sanglu Lu},
  title        = {{UTSD:} Unified Time Series Diffusion Model},
  journal      = {CoRR},
  volume       = {abs/2412.03068},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2412.03068},
  doi          = {10.48550/ARXIV.2412.03068},
  eprinttype    = {arXiv},
  eprint       = {2412.03068},
  timestamp    = {Mon, 13 Jan 2025 21:28:32 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2412-03068.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Nie23,
  author       = {Yuqi Nie and
                  Nam H. Nguyen and
                  Phanwadee Sinthong and
                  Jayant Kalagnanam},
  title        = {A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=Jbdc0vTOcol},
  timestamp    = {Wed, 24 Jul 2024 16:50:33 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/NieNSK23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Rasul23,
  author       = {Kashif Rasul and
                  Arjun Ashok and
                  Andrew Robert Williams and
                  Arian Khorasani and
                  George Adamopoulos and
                  Rishika Bhagwatkar and
                  Marin Bilos and
                  Hena Ghonia and
                  Nadhir Vincent Hassen and
                  Anderson Schneider and
                  Sahil Garg and
                  Alexandre Drouin and
                  Nicolas Chapados and
                  Yuriy Nevmyvaka and
                  Irina Rish},
  title        = {Lag-Llama: Towards Foundation Models for Time Series Forecasting},
  journal      = {CoRR},
  volume       = {abs/2310.08278},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.08278},
  doi          = {10.48550/ARXIV.2310.08278},
  eprinttype    = {arXiv},
  eprint       = {2310.08278},
  timestamp    = {Tue, 24 Oct 2023 14:46:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2310-08278.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Shi24,
  author       = {Xiaoming Shi and
                  Shiyu Wang and
                  Yuqi Nie and
                  Dianqi Li and
                  Zhou Ye and
                  Qingsong Wen and
                  Ming Jin},
  title        = {Time-MoE: Billion-Scale Time Series Foundation Models with Mixture
                  of Experts},
  journal      = {CoRR},
  volume       = {abs/2409.16040},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2409.16040},
  doi          = {10.48550/ARXIV.2409.16040},
  eprinttype    = {arXiv},
  eprint       = {2409.16040},
  timestamp    = {Wed, 16 Oct 2024 13:28:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2409-16040.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Woo24,
  author       = {Gerald Woo and
                  Chenghao Liu and
                  Akshat Kumar and
                  Caiming Xiong and
                  Silvio Savarese and
                  Doyen Sahoo},
  title        = {Unified Training of Universal Time Series Forecasting Transformers},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=Yd8eHMY1wz},
  timestamp    = {Mon, 02 Sep 2024 16:55:25 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/WooLKXSS24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Wu23,
  author       = {Haixu Wu and
                  Tengge Hu and
                  Yong Liu and
                  Hang Zhou and
                  Jianmin Wang and
                  Mingsheng Long},
  title        = {TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/forum?id=ju\_Uqw384Oq},
  timestamp    = {Wed, 24 Jul 2024 16:50:33 +0200},
  biburl       = {https://dblp.org/rec/conf/iclr/WuHLZ0L23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Yang24,
  author       = {Jiarui Yang and
                  Tao Dai and
                  Naiqi Li and
                  Junxi Wu and
                  Peiyuan Liu and
                  Jinmin Li and
                  Jigang Bao and
                  Haigang Zhang and
                  Shutao Xia},
  title        = {Generative Pre-Trained Diffusion Paradigm for Zero-Shot Time Series
                  Forecasting},
  journal      = {CoRR},
  volume       = {abs/2406.02212},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2406.02212},
  doi          = {10.48550/ARXIV.2406.02212},
  eprinttype    = {arXiv},
  eprint       = {2406.02212},
  timestamp    = {Thu, 01 Aug 2024 07:59:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2406-02212.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Zhang24,
  author       = {Yunhao Zhang and
                  Minghao Liu and
                  Shengyang Zhou and
                  Junchi Yan},
  title        = {{UP2ME:} Univariate Pre-training to Multivariate Fine-tuning as a
                  General-purpose Framework for Multivariate Time Series Analysis},
  booktitle    = {Forty-first International Conference on Machine Learning, {ICML} 2024,
                  Vienna, Austria, July 21-27, 2024},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=aR3uxWlZhX},
  timestamp    = {Mon, 02 Sep 2024 16:55:27 +0200},
  biburl       = {https://dblp.org/rec/conf/icml/ZhangLZY24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{gao24,
  title={UniTS: A unified multi-task time series model},
  author={Gao, Shanghua and Koker, Teddy and Queen, Owen and Hartvigsen, Thomas and Tsiligkaridis, Theodoros and Zitnik, Marinka},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024}
}

