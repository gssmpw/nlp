\section{Method}
\label{sec:method}
We structure this section into two parts. The first describes the dataset, its creation, and corresponding statistics. 
The second explains the order-invariant method we use to generate the results.
\input{content/dataset}
\subsection{Order invariant Method}
We aim to develop a malware detection method independent of the temporal constraints and ordering of API calls. This approach ensures that the detection system remains effective even when the sequence of API calls is altered, which is a common evasion technique used by malware. To achieve this, it is crucial to thoroughly investigate the impact on performance as we progressively increase the sequence length of successive API calls under consideration.

Our proposed solution involves mapping each function call directly to a feature in the feature vector, with the value in each position representing the number of times the sample invoked that particular function. This method allows us to create a robust feature representation that is not influenced by the order of API calls, focusing instead on the frequency of each function's invocation.

We structure our experiments into four distinct parts to evaluate this approach comprehensively and ensure the validity of our findings. In the first part, we examine each API call individually, disregarding the context provided by previous and subsequent API calls. We refer to this as the Unigram model, a concept borrowed from natural language processing (NLP). In NLP, a Unigram model analyzes text by considering each word independently, without accounting for the sequence in which words appear. Similarly, in our Unigram model for API calls, we treat each function call as an independent event, counting its occurrences without considering its position in the sequence.

This initial experiment establishes a baseline understanding of how well individual API call frequencies can distinguish between benign and malicious software. By focusing solely on the count of each function, we can determine the effectiveness of this simple yet powerful feature representation in detecting malware. Subsequent parts of our experiments will build upon this foundation, progressively incorporating more contextual information to explore how the performance varies following different lengths of sequences.

By employing this methodical approach, we ensure a comprehensive analysis of the relationship between API call sequences and malware detection accuracy. Our ultimate goal is to identify the optimal balance between feature complexity and detection performance, ultimately developing a robust and efficient malware detection system that is resilient to common evasion tactics.

For the Unigram approach, we simply map each function call to an array index in the feature vector.
We do this by creating a vector, $V$ of length as in~\autoref{eqn:feature_vector}.
\begin{equation}
    |V| = |{Call_1, Call_2, ..., Call_i, ..., Call_n}|
    \label{eqn:feature_vector}
\end{equation}
Each dimension in $V$ corresponds to a specific API Call, and the value of the dimension is the number of API calls belonging to the specific function in a particular sample as shown in~\autoref{api_eqn:call}.
\begin{equation}
    V_i = |Call_i| 
    \label{api_eqn:call}
\end{equation}

When we consider the Bigram model, we also look at the immediately preceding API call for the second part. 
Furthermore, we do this using a sliding window approach over the entire API call sequence.
The length of the feature vector in theory would be the total number of combinations of two API calls, which is $|V|^2$~($59^2$).

Like the Unigram model, we create a feature vector for every combination of API calls.
The vector would comprise two consecutive calls we concatenate, like $Call_1Call_2$.
The total count will be the value for the feature at index $i$.
\begin{equation}
    V_i = |\theta(Call_{i-1},Call_{i})|
\end{equation}
where,
$\theta$ is a mapping from two consecutive API calls to an index.
For the third part, we consider two previous API calls for the sequence. 
%The feature vector is quite large compared to the feature vectors of the unigram and bigram models.
We follow the same procedure as the Unigram model with the only difference in the length of the feature vector and the number of API calls considered.

And for the Trigram model, we consider three consecutive calls as given in~\autoref{eqn:trigram}. In this case, the size of the feature vector expands to $|V|^3$~($=59^3$)~which is quite large compared to the feature vectors of the Unigram and Bigram models.
\begin{equation}
    V_i = |\theta(Call_{i-2},Call_{i-1},Call_{i})|
    \label{eqn:trigram}
\end{equation}
where,
$\theta$ is a mapping from three consecutive API calls to an index.
The index mapping the unique function sequences to an index is provided as a JSON file in our online code repository.
The final model, which we call the Combined model, consists of creating a feature vector that concatenates the feature vectors of the Unigram, Bigram, and Trigram models. 
We do this in the hope that the~\textit{Combined Model}~exploits the positive aspects of Unigram, Bigram, and Trigram models independently to obtain discriminating information from any of the inputs of the models.
%We observe that there are 59 unique API calls to the ntdll.dll library corresponding to the fifty-nine functions we mapped.
%Using these fifty-nine unique function calls, we find that there are 2540 unique~(where we consider two consecutive API calls)~API calls and 5483 unique trigrams ~(where we consider three consecutive API calls)~API calls using a sliding window approach.
The feature vector length for the Unigram model is $59$ corresponding to the number of traced functions to the ntdll.dll, which is manageable, but the Bigram and Trigram models have theoretical lengths of $3481$ and $205379$. 
Although the Bigram feature vector is manageable, it is still quite large, and a Trigram-based feature vector is only possible for more than $330k$ samples on machines with substantial amounts of memory.
Moreover, such a feature vector could be sparse since most values would be zero. 
Therefore, we efficiently identify all the unique bigram and trigram function calls and create feature vectors using only those present in the dataset.
There are~$2540$~unique bigram calls and~$5483$~unique trigram combinations in the dataset.
Therefore, for practicality and to save memory, we limit the Bigram model and Trigram model feature vectors to a length of~$2540$ and $ 5483$~respectively.
We then train a random forest on these feature vectors and predict whether a given sample from the test set is malware or benign.
The dataset is unbalanced, containing many more malicious samples than benign ones.

