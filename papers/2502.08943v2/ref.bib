@misc{open-llm-leaderboard-v1,
  author = {Edward Beeching and Cl√©mentine Fourrier and Nathan Habib and Sheon Han and Nathan Lambert and Nazneen Rajani and Omar Sanseviero and Lewis Tunstall and Thomas Wolf},
  title = {Open LLM Leaderboard (2023-2024)},
  year = {2023},
  publisher = {Hugging Face},
}

@article{huang2024trustllm,
  title={Trustllm: Trustworthiness in large language models},
  author={Huang, Yue and Sun, Lichao and Wang, Haoran and Wu, Siyuan and Zhang, Qihui and Li, Yuan and Gao, Chujie and Huang, Yixin and Lyu, Wenhan and Zhang, Yixuan and others},
  journal={arXiv preprint arXiv:2401.05561},
  year={2024}
}

@article{wang2024mmlu,
  title={Mmlu-pro: A more robust and challenging multi-task language understanding benchmark},
  author={Wang, Yubo and Ma, Xueguang and Zhang, Ge and Ni, Yuansheng and Chandra, Abhranil and Guo, Shiguang and Ren, Weiming and Arulraj, Aaran and He, Xuan and Jiang, Ziyan and others},
  journal={arXiv preprint arXiv:2406.01574},
  year={2024}
}

@article{song2024good,
  title={The good, the bad, and the greedy: Evaluation of llms should not ignore non-determinism},
  author={Song, Yifan and Wang, Guoyin and Li, Sujian and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2407.10457},
  year={2024}
}

@inproceedings{hendrycks2measuring,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)}
}

@article{rein2023gpqa,
  title={Gpqa: A graduate-level google-proof q\&a benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2311.12022},
  year={2023}
}

@article{ding2024easy2hard,
  title={Easy2Hard-Bench: Standardized Difficulty Labels for Profiling LLM Performance and Generalization},
  author={Ding, Mucong and Deng, Chenghao and Choo, Jocelyn and Wu, Zichu and Agrawal, Aakriti and Schwarzschild, Avi and Zhou, Tianyi and Goldstein, Tom and Langford, John and Anandkumar, Anima and others},
  journal={arXiv preprint arXiv:2409.18433},
  year={2024}
}

@inproceedings{polotinybenchmarks,
  title={tinyBenchmarks: evaluating LLMs with fewer examples},
  author={Polo, Felipe Maia and Weber, Lucas and Choshen, Leshem and Sun, Yuekai and Xu, Gongjun and Yurochkin, Mikhail},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{glickman2012example,
  title={Example of the Glicko-2 system},
  author={Glickman, Mark E},
  journal={Boston University},
  volume={28},
  year={2012}
}

@article{cai2016item,
  title={Item response theory},
  author={Cai, Li and Choi, Kilchan and Hansen, Mark and Harrell, Lauren},
  journal={Annual Review of Statistics and Its Application},
  volume={3},
  number={1},
  pages={297--321},
  year={2016},
  publisher={Annual Reviews}
}

@article{natesan2016bayesian,
  title={Bayesian prior choice in IRT estimation using MCMC and variational Bayes},
  author={Natesan, Prathiba and Nandakumar, Ratna and Minka, Tom and Rubright, Jonathan D},
  journal={Frontiers in psychology},
  volume={7},
  pages={1422},
  year={2016},
  publisher={Frontiers Media SA}
}

@article{desender2017subjective,
  title={Subjective experience of difficulty depends on multiple cues},
  author={Desender, Kobe and Van Opstal, Filip and Van den Bussche, Eva},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={44222},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{liang2022holistic,
  title={Holistic evaluation of language models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv preprint arXiv:2211.09110},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}


@article{zhang2024defining,
  title={Defining Boundaries: A Spectrum of Task Feasibility for Large Language Models},
  author={Zhang, Wenbo and Xu, Zihang and Cai, Hengrui},
  journal={arXiv preprint arXiv:2408.05873},
  year={2024}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{sprague2023musr,
  title={Musr: Testing the limits of chain-of-thought with multistep soft reasoning},
  author={Sprague, Zayne and Ye, Xi and Bostrom, Kaj and Chaudhuri, Swarat and Durrett, Greg},
  journal={arXiv preprint arXiv:2310.16049},
  year={2023}
}

@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}

@article{polo2024tinybenchmarks,
  title={tinyBenchmarks: evaluating LLMs with fewer examples},
  author={Polo, Felipe Maia and Weber, Lucas and Choshen, Leshem and Sun, Yuekai and Xu, Gongjun and Yurochkin, Mikhail},
  journal={arXiv preprint arXiv:2402.14992},
  year={2024}
}

@article{madaan2024quantifying,
  title={Quantifying Variance in Evaluation Benchmarks},
  author={Madaan, Lovish and Singh, Aaditya K and Schaeffer, Rylan and Poulton, Andrew and Koyejo, Sanmi and Stenetorp, Pontus and Narang, Sharan and Hupkes, Dieuwke},
  journal={arXiv preprint arXiv:2406.10229},
  year={2024}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{white2024livebench,
  title={Livebench: A challenging, contamination-free llm benchmark},
  author={White, Colin and Dooley, Samuel and Roberts, Manley and Pal, Arka and Feuer, Ben and Jain, Siddhartha and Shwartz-Ziv, Ravid and Jain, Neel and Saifullah, Khalid and Naidu, Siddartha and others},
  journal={arXiv preprint arXiv:2406.19314},
  year={2024}
}

@article{lin2024wildbench,
  title={WILDBENCH: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild},
  author={Lin, Bill Yuchen and Deng, Yuntian and Chandu, Khyathi and Brahman, Faeze and Ravichander, Abhilasha and Pyatkin, Valentina and Dziri, Nouha and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2406.04770},
  year={2024}
}


@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  month = {5},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{holtzman2019curious,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09751},
  year={2019}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@inproceedings{mitchell2022enhancing,
  title={Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference},
  author={Mitchell, Eric and Noh, Joseph and Li, Siyan and Armstrong, Will and Agarwal, Ananth and Liu, Patrick and Finn, Chelsea and Manning, Christopher D},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1754--1768},
  year={2022}
}

@article{swayamdipta2020dataset,
  title={Dataset cartography: Mapping and diagnosing datasets with training dynamics},
  author={Swayamdipta, Swabha and Schwartz, Roy and Lourie, Nicholas and Wang, Yizhong and Hajishirzi, Hannaneh and Smith, Noah A and Choi, Yejin},
  journal={arXiv preprint arXiv:2009.10795},
  year={2020}
}

@article{miller2024adding,
  title={Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations},
  author={Miller, Evan},
  journal={arXiv preprint arXiv:2411.00640},
  year={2024}
}

@inproceedings{wang2023decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models.},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  booktitle={NeurIPS},
  year={2023}
}

