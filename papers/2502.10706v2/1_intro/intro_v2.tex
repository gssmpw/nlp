Graph Neural Networks (GNNs) have made remarkable advancements in modeling and learning from graph-structured data across various scenarios, including, but not limited to, social networks~\citep{fan2020graph,chang2021sequential}, molecules~\citep{shui2020heterogeneous,liu2024data}, and knowledge graphs~\citep{kg_1,kg_2}. Despite the powerful representational capabilities of GNNs, their success often relies on the assumption that the training and testing data follow the same distribution. Unfortunately, such an assumption rarely holds in most real-world applications, where out-of-distribution (OOD) data from different distributions often occurs~\citep{OODsurvey}. Empirical evidence has shown that GNNs often struggle to maintain performance when tested on OOD data that differ significantly from the training set~\citep{OODbench,li2022ood}. These vulnerabilities underscore the critical need to enhance the OOD generalization capabilities of GNNs, which has become a rapidly growing area of research~\citep{good,drugood}.

Building on the success of invariant learning in addressing OOD generalization challenges in image data~\citep{creager2021environment,ye2022ood}, graph invariant learning~(GIL) has recently emerged as a prominent solution for tackling its counterpart problem in graph data~\citep{li2022learning,fan2022debiasing,miao2022interpretable,wu2022discovering}. The fundamental assumption underlying GIL is that each graph sample can be divided into two distinct components, namely \textit{invariant subgraph} and \textit{environment subgraph}. The former exhibits deterministic and solid predictive relationships with the label of the graph sample, while the latter may show spurious correlations with the labels and can vary significantly in response to distribution shifts~\citep{yang2022learning,chen2024does}. By effectively separating invariant and environment information,  GIL-based approaches can learn invariant representations from the former and make reliable predictions. To achieve accurate separation, existing methods primarily focus on capturing and modeling the environmental subgraphs, employing carefully designed loss functions to minimize the correlations between the predicted environmental subgraphs and the labels~\citep{gui2024joint,piao2024improving}, or utilizing data augmentation strategies to simulate potential environments in wild data~\citep{wu2022handling,jia2024graph}.
\begin{figure}[t!]   

 \centering
 \subfigure[Diversity of environments.]{
   \includegraphics[width=0.21\textwidth]{1_intro/intro1.pdf}
   \label{subfig:intro1}
 } 
 \subfigure[Semantic cliff across classes.]{
   \includegraphics[width=0.21\textwidth]{1_intro/intro2.pdf}
   \label{subfig:intro2}
}
\vspace{-5mm}
\caption{Case examples of two challenges faced by graph out-of-dirstribution generalization}
\vspace{-8mm}
\label{fig:moti}
\end{figure}
Although GIL-based methods are theoretically viable, they underestimate the \textbf{difficulties in capturing environment information} in real-world graph data. These difficulties can be attributed to the \textit{diversity}, \textit{distinguishability}, and \textit{lack of labels} of practical graph environments. 
Specifically, the environments of graph data can exhibit substantial diversity in terms of sizes, shapes, and topological properties. Taking molecular graphs as an example (Fig.~\ref{subfig:intro1}), the invariant subgraph can be a specific functional group, while the environmental subgraphs may display varied patterns, such as different scaffolds, side chains, or bonding configurations that modify the overall structure~\citep{zhuang2023learning}. In this context, even with augmented or reorganized environments during training, GNN models struggle to identify all forms of environment subgraphs in real-world OOD samples. 
Moreover, unlike image data where environments can be clearly segmented at the pixel level, the structural boundaries between invariant and environmental subgraphs in graph data are often ambiguous (see the examples in Fig.~\ref{subfig:intro1}), which leads to poor distinguishability of environments. Moreover, unlike certain visual datasets~\citep{lin2022zin} where environment labels (such as background or image style) are available for model training, the environments in graph data are highly complex, making it difficult to obtain corresponding labels to aid in capturing environmental information. Given the above difficulties, most existing GIL-based approaches demonstrate suboptimal performance in identifying environmental information, particularly in complex graph data, as empirically demonstrated by~\citep{chen2024does}. Consequently, a natural question arises: \textbf{\textit{(RQ1) Can we consider a more feasible way to learn invariant representations on graphs without explicitly modeling the environment information?}}

In addition to the challenges posed by environment capturing, another critical obstacle, referred to as the \textbf{semantic cliff across different classes}~\citep{xia2024understanding}, also hinders current GIL-based approaches from making reliable decisions on OOD graph data. To be more specific, the semantic cliff issue refers to a situation where invariant subgraphs or representations from different classes share significant similarities, making them difficult to distinguish from one another~\citep{van2022exposing}.
For instance, as shown in Fig.~\ref{subfig:intro2}, invariant subgraphs (e.g., functional groups) across different molecular classes often share similar structural characteristics, with distinctions frequently limited to a single atom or bond. In such cases, the decision boundaries between invariant representations can become blurred, exacerbating the challenge of separating classes, particularly when the invariant and environment subgraphs are not distinctly identifiable. Nevertheless, the existing OOD generalization GNNs overemphasize the extraction of invariant information while neglecting the distinction between invariant subgraphs belonging to different classes, which may lead to their sub-optimal performance. Given this shortage, a natural follow-up question arises: \textbf{\textit{(RQ2) How can we develop a more robust OOD generalization approach that better discriminates between invariant representations across different classes?}}

To answer the above research questions, in this paper, we propose a novel \textbf{M}ulti-\textbf{P}rototype \textbf{H}yperspherical \textbf{I}nvariant \textbf{L}earning (\ourmethod for short) method. Building upon and enhancing the theoretical framework of GIL, \ourmethod propose a novel graph OOD generalization framework with two advanced features: 1)~\textbf{invariant learning in hyperspherical space}, which ensures the separability and informativeness of the learned invariant representations, and 2)~\textbf{class prototype as intermediate variable}, which eliminates the need for explicit environment modeling in invariant learning and enables flexible decision boundaries for prediction. 
More specifically, we derive a more practical invariant learning objective based on prototypical learning in hyperspherical space, incorporating two well-crafted loss terms. To address \textbf{\textit{(RQ1)}}, we design an \textit{invariant prototype matching loss} ($\mathcal{L}_{IPM}$) that ensures samples from the same class are assigned to the same class prototype in hyperspherical space. In this way, $\mathcal{L}_{IPM}$ can allow the model to extract robust invariant features across varying environments without explicitly modeling them. To answer \textbf{\textit{(RQ2)}}, we produce a \textit{prototype separation loss} ($\mathcal{L}_{PS}$) that pulls the prototypes belonging to the same class closer together while ensuring those from different classes remain dissimilar. In this way, $\mathcal{L}_{PS}$ enhances the class separability in the context of OOD generalization and mitigates the semantic cliff issue in graph data. Innovatively, we propose to assign multiple prototypes for each class, which ensures adaptable decision boundaries and greater tolerance to environmental changes. To sum up, the main contributions of this paper are as follows:

\begin{itemize}[leftmargin=*]
    \item \textbf{Framework.} Derived from the objective of GIL, we introduce a novel invariant learning framework that leverages hyperspherical space and prototypical learning, ensuring robust invariant representation learning while reducing the need for explicit graph environment modeling. 
    
    \item \textbf{Methodology.} Based on the new GIL framework, we develop a new graph OOD generalization method termed \ourmethod. \ourmethod incorporates two effective loss terms to enhance intra-class invariance and inter-class separability, with a multi-prototype mechanism to handle diverse environments.
    
    \item \textbf{Experiments.}  We conduct extensive experiments to validate the effectiveness of \ourmethod, and the results demonstrate its superior generalization ability compared to state-of-the-art methods across various types of distribution shifts.
\end{itemize}

% \begin{figure*}[h]
% \centering 
% \subfigure[Two molecular graphs with the same functional group but a different scaffold] { 
% \includegraphics[width=0.4\columnwidth]{1_intro/fig1.pdf} 
% }
% \subfigure[K] { 
% \includegraphics[width=0.4\columnwidth]{1_intro/fig2 (2).pdf} 
% }

% \caption{Left, Middle:} 
% \label{t-sne}
% \vspace{-1pt}
% \end{figure*}
% \begin{figure*}[t!] 
% \centering    
% \includegraphics[scale=0.39]{1_intro/sx_fig1(1).png}
% \caption{Upper: molecular graphs with the same functional group but different scaffolds. down:  molecular graphs with the different functional group which is too similar. }  
% \label{fig:intro} 
% \end{figure*}