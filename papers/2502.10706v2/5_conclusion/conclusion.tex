In this work, we introduce a novel graph invariant learning framework integrated with hyperspherical space and prototypical learning, ensuring that the learned representations are both environment-invariant and class-separable without relying on environmental information. Building upon this framework, we present a new graph out-of-distribution generalization method named \ourmethod. \ourmethod achieves inter-class invariance and intra-class separability by optimizing two effective loss functions and leverages class prototypes, defined as the mean feature vectors of each category, to eliminate dependency on individual prototypes. Experimental evaluations on benchmarks demonstrate the effectiveness of \ourmethod.
