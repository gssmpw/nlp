%%
%% This is file `sample-sigconf-authordraft.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,proceedings,bibtex,authordraft')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf-authordraft.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
\documentclass[sigconf]{acmart}
% \documentclass[sigconf,review]{acmart}
%% NOTE that a single column version may required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.

%%
%% \BibTeX command to typeset BibTeX logo in the docs
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}
%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Conference acronym 'XX]{Make sure to enter the correct
  conference title from your rights confirmation emai}{June 03--05,
  2018}{Woodstock, NY}
%%
%%  Uncomment \acmBooktitle if the title of the proceedings is different
%%  from ``Proceedings of ...''!
%%
%%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%%  June 03--05, 2018, Woodstock, NY}
\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
% \usepackage{minipage}

\usepackage{mathrsfs}
\usepackage{amsmath}


\usepackage{bm}
\usepackage{algorithm}
\usepackage{algorithmic}
%\usepackage{algorithmicx}
\usepackage{float}  
\usepackage{lipsum}

\usepackage{xcolor}    % 用于 \colorbox
\usepackage{varwidth}  % 用于 varwidth 环境

\let\Bbbk\relax         %%redefined in newtxmath.sty
\usepackage{amssymb}
\usepackage{pifont}
 \usepackage{enumitem}
\usepackage{multirow}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\usepackage{wrapfig}

% \documentclass{article}
\usepackage{booktabs}  % 提供更好看的横线
\usepackage{array}     % 提供更多的列格式控制
% \usepackage{booktabs}  % 提供更好看的横线
\usepackage{graphicx}  % 允许图片插入
\usepackage{subfigure}
\usepackage{multirow}  % 允许跨行合并
\usepackage{multicol}  % 允许跨列合并

\usepackage{colortbl}
\usepackage{xcolor}
\usepackage{array}
\usepackage{xspace}
\newcommand{\ourmethod}{\textsc{{MPhil}}\xspace}
%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{Raising the Bar in Graph OOD Generalization: \\ Invariant Learning Beyond Explicit Environment Modeling}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Xu Shen }
\authornote{Both authors contributed equally to this research.}

\affiliation{%
  \institution{Jilin University}
 \streetaddress{}
  \city{Changchun}
  \country{China}}
  \email{shenxu23@mails.jlu.edu.cn}

\author{Yixin Liu }
\authornotemark[1]
\affiliation{%
  \institution{Griffith University}
  \streetaddress{}
  \city{Goldcoast}
  \country{Australia}}
\email{yixin.liu@griffith.edu.au}

\author{Yili Wang }

\affiliation{%
  \institution{Jilin University}
  \streetaddress{}
  \city{Changchun}
  \country{China}}
\email{wangyl21@mails.jlu.edu.cn}

\author{Rui Miao}
\affiliation{%
  \institution{Jilin University}
  \streetaddress{}
  \city{Changchun}
  \country{China}}
\email{ruimiao20@mails.jlu.edu.cn}

\author{Yiwei Dai}
\affiliation{%
  \institution{Jilin University}
  \streetaddress{}
  \city{Changchun}
  \country{China}}
\email{daiyw23@mails.jlu.edu.cn}

\author{Shirui Pan }
\affiliation{%
  \institution{Griffith University}
  \streetaddress{}
  \city{Goldcoast}
  \country{Australia}}
\email{s.pan@griffith.edu.au}

\author{Xin Wang}
\authornote{Corresponding author.}
% \authornotemark[1]
\affiliation{%
  \institution{Jilin University}
  \streetaddress{}
  \city{Changchun}
  \country{China}}
\email{xinwang@jlu.edu.cn}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Xu Shen et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.


%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Out-of-distribution (OOD) generalization has emerged as a critical challenge in graph learning, as real-world graph data often exhibit diverse and shifting environments that traditional models fail to generalize across. A promising solution to address this issue is graph invariant learning (GIL), which aims to learn invariant representations by disentangling label-correlated invariant subgraphs from environment-specific subgraphs. However, existing GIL methods face two major challenges: (1) the difficulty of \textbf{capturing and modeling diverse environments} in graph data, and (2) the \textbf{semantic cliff}, where invariant subgraphs from different classes are difficult to distinguish, leading to poor class separability and increased misclassifications. 
To tackle these challenges, we propose a novel method termed \textbf{M}ulti-\textbf{P}rototype \textbf{H}yperspherical \textbf{I}nvariant \textbf{L}earning (\ourmethod), which introduces two key innovations: (1) \textit{hyperspherical invariant representation extraction}, enabling robust and highly discriminative hyperspherical invariant feature extraction, and (2) \textit{multi-prototype hyperspherical classification}, which employs class prototypes as intermediate variables to eliminate the need for explicit environment modeling in GIL and mitigate the semantic cliff issue. Derived from the theoretical framework of GIL, we introduce two novel objective functions: the \textit{invariant prototype matching loss} to ensure samples are matched to the correct class prototypes, and the \textit{prototype separation loss} to increase the distinction between prototypes of different classes in the hyperspherical space.
Extensive experiments on 11 OOD generalization benchmark datasets demonstrate that \ourmethod achieves state-of-the-art performance, significantly outperforming existing methods across graph data from various domains and with different distribution shifts. The source code of \ourmethod is available at \href{https://anonymous.4open.science/r/MPHIL-23C0/}{https://anonymous.4open.science/r/MPHIL-23C0/}.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002950.10003624.10003633.10010917</concept_id>
       <concept_desc>Mathematics of computing~Graph algorithms</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10010147.10010341.10010366.10010367</concept_id>
       <concept_desc>Computing methodologies~Machine learning</concept_desc>
       <concept_significance>500</concept_significance>
   </concept>
   <concept>
       <concept_id>10010405.10010406.10010430.10010431</concept_id>
       <concept_desc>Applied computing</concept_desc>
       <concept_significance>300</concept_significance>
   </concept>
   <concept>
       <concept_id>10002951.10003227.10003241</concept_id>
       <concept_desc>Information systems~Data mining</concept_desc>
       <concept_significance>300</concept_significance>
   </concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Mathematics of computing~Graph algorithms}
\ccsdesc[500]{Computing methodologies~Machine learning}
\ccsdesc[300]{Applied computing}
\ccsdesc[300]{Information systems~Data mining}
%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Graph out-of-distribution generalization, invariant learning, hyperspherical space}
%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.


\received{20 February 2007}
\received[revised]{12 March 2009}
\received[accepted]{5 June 2009}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.

\maketitle

\section{Introduction} \label{sec:intro}
\input{1_intro/intro_v3}
\section{Related Works} \label{appe:rw}
\input{6_appendix/rw}
\section{Preliminaries and Background}
\input{2_preliminary/pre_v2}

\section{Methodology}
\input{3_method/method_v2}

\section{Experiments}
\input{4_exp/exp_v2}
\section{Conclusion}
\input{5_conclusion/conclusion}
\bibliography{iclr2025_conference}
\bibliographystyle{iclr2025_conference}

\clearpage
\appendix

% \section{Related Works} \label{appe:rw}
% \input{6_appendix/rw}
% You may include other additional sections here.




\section{MPHIL Objective Deductions} \label{appe:proof}
\subsection{Proof of the overall objective}\label{appe:deduct}
In this section, we explain how we derived our goal in Eq.~(\ref{eq: target2}) from Eq.~(\ref{eq:soft}). Let's recall that Eq.~(\ref{eq:soft}) is formulated as:
\begin{equation}
   \underset{f_{c}, g}{\min} -I(y; \mathbf{z}_{inv})+\beta I(\mathbf{z}_{inv};e),
\end{equation}
For the first term $-I(y;\mathbf{z}_{inv})$, since we are mapping invariant features to hyperspherical space, we replace $\mathbf{z}_{inv}$ with $\mathbf{\hat{z}}_{inv}$. Then according to the definition of mutual information:
\begin{equation}\label{eq:muinfor}
-I(y;\mathbf{\hat{z}}_{inv}) = - \mathbb{E}_{y, \mathbf{\hat{z}}_{inv}} \left[ \log \frac{p(y,\mathbf{\hat{z}}_{inv})}{p(y) p(\mathbf{\hat{z}}_{inv})} \right].
\end{equation}

We introduce intermediate variables $\boldsymbol{\mu}^{y}$ to rewrite Eq. (\ref{eq:muinfor}) as:
\begin{equation}
    \resizebox{.9\hsize}{!}{
$-I(y; \mathbf{\hat{z}}_{inv}) = -E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log \frac{p(y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y})}{p(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}) p(y)} \right] + E_{y, \mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y}} \left[ \log \frac{p(y,\boldsymbol{\mu}^{y}|\mathbf{\hat{z}}_{inv})}{p(y|\mathbf{\hat{z}}_{inv}) p(\boldsymbol{\mu}^{y})|\mathbf{\hat{z}}_{inv}} \right]. $}
\end{equation}




By the definition of Conditional mutual information, we have the following equation:
\begin{equation}
    \begin{aligned} 
    -I(y;\mathbf{\hat{z}}_{inv})  &= -I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y})+I(y;\boldsymbol{\mu}^{y}|\mathbf{\hat{z}}_{inv}),  \\ 
    -I(y;\boldsymbol{\mu}^{y})  &= -I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y})+I(y;\mathbf{\hat{z}}_{inv}|\boldsymbol{\mu}^{y}). 
\end{aligned}
\end{equation}
% \input{6_appendix/rw}

By merging the same terms, we have:
\begin{equation}
     -I(y;\mathbf{\hat{z}}_{inv})  = -I(y;\boldsymbol{\mu}^{y})+[I(y;\boldsymbol{\mu}^{y}|\mathbf{\hat{z}}_{inv})-I(y;\mathbf{\hat{z}}_{inv}|\boldsymbol{\mu}^{y})]. 
\end{equation}

Since our classification is based on the distance between $\boldsymbol{\mu}^{y}$ and $\mathbf{\hat{z}}_{inv}$, we add $-I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y})$ back into the above equation and obtain a lower bound:
\begin{equation}
\resizebox{.9\hsize}{!}{
$-I(y;\mathbf{\hat{z}}_{inv}) \geq -I(y;\boldsymbol{\mu}^{y})+[I(y;\boldsymbol{\mu}^{y}|\mathbf{\hat{z}}_{inv})-I(y;\mathbf{\hat{z}}_{inv}|\boldsymbol{\mu}^{y})]-I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y}).$}
\end{equation}
Since the $\boldsymbol{\mu}^{y}$ are updated by $\mathbf{\hat{z}}_{inv}$ from the same class, we can approximate $I(y;\boldsymbol{\mu}^{y}|\mathbf{\hat{z}}_{inv})$ equal to $I(y;\mathbf{\hat{z}}_{inv}|\boldsymbol{\mu}^{y})$ and obtain the new lower bound:
\begin{equation}
\label{eq: first part}
    -I(y;\mathbf{\hat{z}}_{inv}) \geq -I(y;\boldsymbol{\mu}^{y})-I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y}).
\end{equation}

For the second term $I(\mathbf{z}_{inv};e)$, we can also rewrite it as:
\begin{equation}
  \begin{aligned}
    I(\mathbf{\hat{z}}_{inv};e)  &= I(\mathbf{\hat{z}}_{inv};e,\boldsymbol{\mu}^{y})-I(\mathbf{\hat{z}}_{inv};\boldsymbol{\mu}^{y}|e).
    \end{aligned}
\end{equation}

Given that the environmental labels  $e$ are unknown, we drop the term $I(\mathbf{\hat{z}}_{inv};e,\boldsymbol{\mu}^{y})$ as it cannot be directly computed. This leads to the following lower bound:
\begin{equation}\label{z_e}
  \begin{aligned}
    I(\mathbf{\hat{z}}_{inv};e)  &\geq-I(\mathbf{\hat{z}}_{inv};\boldsymbol{\mu}^{y}|e).
    \end{aligned}
\end{equation}

We can obtain a achievable target by Eq. (\ref{eq: first part}) and Eq. (\ref{z_e}) as follow:
\begin{equation}\label{uneq_1}
\resizebox{.9\hsize}{!}{$
    -I(y; \mathbf{z}_{inv})+\beta I(\mathbf{z}_{inv};e)\geq-I(y;\boldsymbol{\mu}^{y})-I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y})-\beta I(\mathbf{\hat{z}}_{inv};\boldsymbol{\mu}^{y}|e).$}
\end{equation}

In fact, $p(\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y}|e) \geq p(\mathbf{\hat{z}}_{inv};\boldsymbol{\mu}^{y})$, Eq. (\ref{uneq_1}) can be achieved by:
\begin{equation}\resizebox{.9\hsize}{!}{$
    -I(y; \mathbf{z}_{inv})+\beta I(\mathbf{z}_{inv};e)\geq-I(y;\boldsymbol{\mu}^{y})-I(y;\mathbf{\hat{z}}_{inv},\boldsymbol{\mu}^{y})-\beta I(\mathbf{\hat{z}}_{inv};\boldsymbol{\mu}^{y}). $}
\end{equation}

Finally, optimizing Eq. (\ref{eq:soft}) can be equivalent to optimizing its lower bound and we can obtain the objective without environment $e$ as shown in Eq. (\ref{eq: target2}):
\begin{equation}
\setlength\abovedisplayskip{9pt}
\setlength\belowdisplayskip{9pt}
   \underset{f_{c}, g}{\min} \underbrace{-I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)}) }_{\mathcal{L}_{\mathrm{C}}}\underbrace{-I(y ; \boldsymbol{\mu}^{(y)}) }_{\mathcal{L}_{\mathrm{PS}}}\underbrace{-\beta I(\hat{\mathbf{z}}_{inv};\boldsymbol{\mu}^{(y)})}_{\mathcal{L}_{\mathrm{IPM}}}.
\end{equation}

\subsection{Proof of $\mathcal{L}_{\mathrm{C}}$ } \label{appe:deduct2}
For the term $I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)})$, it can be written as:
\begin{equation}
    I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)}) = E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log \frac{p(y| \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y})}{p(y)} \right],
\end{equation}
according to ~\citep{graphpro}, we have:
\begin{equation}
    I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)}) \geq E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log \frac{q_{\theta}(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))}{p(y)} \right],
\end{equation}
where $\gamma(,)$ is the function to calculate the similarity between $\mathbf{\hat{z}}_{inv}$ and $\boldsymbol{\mu}^{y}$. $q_{\theta}(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))$ is the variational approximation of the $p(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))$. Then we can have:
\begin{align}\nonumber
    I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)}) &\geq E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log \frac{q_{\theta}(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))}{p(y)} \right] \\ \nonumber
    &\geq E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log {q_{\theta}(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))} \right]- E_{y}[\log p(y)]\\ \nonumber
    &\geq E_{y, \mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}} \left[ \log {q_{\theta}(y| \gamma(\mathbf{\hat{z}}_{inv}, \boldsymbol{\mu}^{y}))} \right]\\
    &:= -\mathcal{L}_{\mathrm{C}}.
\end{align}

Finally, we prove that $\min I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)})$ is equivalent to minimizing the classification loss $\mathcal{L}_{\mathrm{C}}$.

\section{Methodology Details}\label{appe:method_detail}

\subsection{Overall Algorithm of \ourmethod} 
The training algorithm of \ourmethod is shown in Algorithm.~\ref{code:train}. After that, we use the well-trained $\mathrm{GNN}_{S}$,$\mathrm{GNN}_{E}$, $\mathrm{Proj}$ and all prototypes $\mathbf{M}^{(c)} = \{ \boldsymbol{\mu}_{k}^{(c)}\}^{K}_{k=1}$ to perform inference on the test set. The pseudo-code for this process is shown in Algorithm.~\ref{code:test}.
\begin{algorithm}[h!]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
  \caption{The training algorithm of \ourmethod.}
  \begin{algorithmic}[1]
    \REQUIRE
      Scoring GNN $\mathrm{GNN}_{S}$;
      Encoding GNN $\mathrm{GNN}_{E}$;
      Projection $\mathrm{Proj}$;
      Number of prototypes for each class $K$;
      The data loader of in-distribution training set $D_{\mathrm{train}}$.
      
    \ENSURE
    Well-trained $\mathrm{GNN}_{S}$, $\mathrm{GNN}_{E}$, $\mathrm{Proj}$
       and all prototypes $\mathbf{M}^{(c)}$.
    \STATE 
For each class $c \in \{1, \cdots, C\}$, assign $K$ prototypes for it which can be denoted by $\mathbf{M}^{(c)} = \{ \boldsymbol{\mu}_{k}^{(c)}\}^{K}_{k=1}$.    
\STATE Initialize each of them by $\boldsymbol{\mu}_{k}^{(c)} \sim \mathcal{N}(\textbf{0}, \textbf{I})$
     \FOR{epoch in epochs}  
    \FOR{each $G_\mathrm{{batch}}$ in $D_{\mathrm{train}}$}
       \STATE Obtain $Z_{inv}$  using $\mathrm{GNN}_{S}$ and $\mathrm{GNN}_{E}$ via Eq. (\ref{eq:score}) and (\ref{eq:readout})
       \STATE Obtain $\hat{Z}_{inv}$ using $\mathrm{Proj}$ via Eq. (\ref{eq: hype_rinv})
       \STATE Compute $W^{(c)}$ using $\boldsymbol{u}^{(c)}$ and $\hat{Z}_{inv}$ via Eq. (\ref{eq: att}).
        \FOR{each prototype $\boldsymbol{u}_{k}^{(c)}$}
        \STATE Update it using $\hat{Z}_{inv}$ and $W^{(c)}$ via Eq. (\ref{eq: update_prototype}).
        
        \ENDFOR
        \STATE Get $p(y = c \mid \hat{\mathbf{z}}_{i}; \{ w^{c},\boldsymbol{u}^{(c)} \}_{c=1}^{(C)})$ using $\hat{Z}_{inv}$, $W^{(c)}$ and $\boldsymbol{\mu}^{(c)}$ via Eq. (\ref{classify})
        \STATE Compute the final loss $\mathcal{L}$ with $\hat{Z}_{inv}$, $\boldsymbol{\mu}^{(c)}$ and $p(y = c \mid \hat{\mathbf{z}}_{i}; \{ w^{c},\boldsymbol{u}^{(c)} \}_{c=1}^{(C)})$ via Eq. (\ref{ipm}), (\ref{ps}) and (\ref{cls})
        % \State Generate $\overline{G}$ and add to $TL$;
        \STATE Update parameters of $\mathrm{GNN}_{S}$, $\mathrm{GNN}_{E}$ and $\mathrm{Proj}$ with the gradient of $\mathcal{L}$.
      \ENDFOR
    \ENDFOR
  \end{algorithmic}\label{code:train}
\end{algorithm}
\vspace{-5mm}
\begin{algorithm}[h!]
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
  \caption{The inference algorithm of \ourmethod.}
  \begin{algorithmic}[1]
    \REQUIRE
      Well-trained $\mathrm{GNN}_{S}$,$\mathrm{GNN}_{E}$, $\mathrm{Proj}$ and all prototypes $\mathbf{M}^{(c)} = \{ \boldsymbol{\mu}_{k}^{(c)}\}^{K}_{k=1}$.
      The data loader of Out-of-distribution testing set $D_{\mathrm{test}}$.
      
    \ENSURE
    Classification probability $p(y = c \mid \hat{\mathbf{z}}_{i}; \{ w^{c},\boldsymbol{\mu}^{(c)} \}_{c=1}^{(C)})$ 
    \FOR{each $G_\mathrm{{batch}}$ in $D_{\mathrm{test}}$}
       \STATE Obtain $Z_{inv}$  using $\mathrm{GNN}_{S}$ and $\mathrm{GNN}_{E}$ via Eq. (\ref{eq:score}) and (\ref{eq:readout})
       \STATE Obtain $\hat{Z}_{inv}$ using $\mathrm{Proj}$ via Eq. (\ref{eq: hype_rinv})
       \STATE Compute $W^{(c)}$ using $\boldsymbol{\mu}^{(c)}$ and $\hat{Z}_{inv}$ via Eq. (\ref{eq: att}).
        
        \STATE Get $p(y = c \mid \hat{\mathbf{z}}_{i}; \{ w^{c},\boldsymbol{\mu}^{(c)} \}_{c=1}^{(C)})$ using $\hat{Z}_{inv}$, $W^{(c)}$ and $\boldsymbol{\mu}^{(c)}$ via Eq. (\ref{classify})
        
        % \State Generate $\overline{G}$ and add to $TL$;
        
      \ENDFOR
  \end{algorithmic}\label{code:test}

\end{algorithm}
\vspace{-6mm}

\subsection{Weight Pruning} \label{appe:pruning}

Directly assigning weights to all prototypes within a class can lead to excessive similarity between prototypes, especially for difficult samples. This could blur decision boundaries and reduce the model's ability to correctly classify hard-to-distinguish samples.

To address this, we apply a \textbf{top-$n$ pruning} strategy, which keeps only the most relevant prototypes for each sample. The max weights are retained, and the rest are pruned as follows:
\begin{equation}
    W_{i,k}^{(c)} = {1}[W_{i,k}^{(c)}>\beta]\ast W_{i,k}^{(c)}, 
\end{equation}
where $\beta$ is the threshold corresponding to the top-$n$ weight, and ${1}[W_{i,k}^{(c)}>\beta]$ is an indicator function that retains only the weights for the top-$n$ prototypes. This pruning mechanism ensures that the prototypes remain distinct and that the decision space for each class is well-defined, allowing for improved classification performance. By applying this attention-based weight calculation and top-$n$ pruning, the model ensures a more accurate and robust matching of samples to prototypes, enhancing classification, especially in OOD scenarios.


\subsection{Complexity Analysis}
The time complexity of \ourmethod is $
\mathcal{O}(|E|d+|V|d^{2})$, where $|V|$ denotes the number of nodes and $|E|$ denotes the number of edges, $d$ is the dimension of the final representation. Specifically, for $\mathrm{GNN}_{S}$ and $\mathrm{GNN}_{E}$, their complexity is denoted as $
\mathcal{O}(|E|d+|V|d^{2})$. The complexity of the projector is $
\mathcal{O}(|V|d^{2})$, while the complexities of calculating weights and updating prototypes are $
\mathcal{O}(|V||K|d)$ where $K$ is the number of prototypes. The complexity of computing the final classification probability also is $
\mathcal{O}(|V|Kd)$. Since $K$ is a very small constant, we can ignore $\mathcal{O}(|V|Kd)$, resulting in a final complexity of $
\mathcal{O}(|E|d+|V|d^{2})$. Theoretically, the time complexity of \ourmethod is on par with the existing methods.

% \begin{figure}[htb]
%  \centering
% \subfigure[CIGA] { 
% \includegraphics[width=0.27\textwidth]{4_exp/imold.pdf} \label{t1}
% }
% \subfigure[Ours] { 
% \includegraphics[width=0.27\textwidth]{4_exp/my.pdf} \label{t2}
% }
% \caption{t-SNE visualization on HIV-Scaffold.}
% \label{fig:tsne}
% \end{figure}
\section{Experimental Details}\label{appe:exp}

\subsection{Datasets}\label{appe:data}
\textbf{Overview of the Dataset.} In this work, we use 11 publicly benchmark datasets, 5 of them are from GOOD~\citep{good} benchmark. They are the combination of 3 datasets (GOOD-HIV, GOOD-Motif and GOOD-CMNIST) with different distribution shift (scaffold, size, basis, color). The rest 6 datasets are from DrugOOD~\citep{drugood} benchmark, including IC50-Assay, IC50-Scaffold, IC50-Size, EC50-Assay, EC50-Scaffold, and EC50-Size. The prefix denotes the measurement and the suffix denotes the distribution-splitting strategies. We use the default dataset split proposed in each benchmark.  Statistics of each dataset are in Table \ref{data_st}.

\begin{table}[t]
\renewcommand{\arraystretch}{1.5}
\setlength\tabcolsep{3pt}
\centering
\caption{Dateset statistics.}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cccccccc}
\toprule
\multicolumn{3}{c|}{Dataset}                                                                            & Task                       & Metric  & Train & Val   & Test  \\ \midrule
\multicolumn{1}{c|}{\multirow{5}{*}{GOOD}}    & \multirow{2}{*}{HIV}   & \multicolumn{1}{c|}{scaffold} & Binary Classification      & ROC-AUC & 24682 & 4133  & 4108  \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{size}     & Binary Classification      & ROC-AUC & 26169 & 4112  & 3961  \\ \cline{2-8} 
\multicolumn{1}{c|}{}                         & \multirow{2}{*}{Motif} & \multicolumn{1}{c|}{basis}    & Multi-label Classification & ACC     & 18000 & 3000  & 3000  \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{size}     & Multi-label Classification & ACC     & 18000 & 3000  & 3000  \\ \cline{2-8} 
\multicolumn{1}{c|}{}                         & CMNIST                 & \multicolumn{1}{c|}{color}    & Multi-label Classification & ACC     & 42000 & 7000  & 7000  \\ \midrule
\multicolumn{1}{c|}{\multirow{6}{*}{DrugOOD}} & \multirow{3}{*}{IC50}  & \multicolumn{1}{c|}{assay}    & Binary Classification      & ROC-AUC & 34953 & 19475 & 19463 \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{scaffold} & Binary Classification      & ROC-AUC & 22025 & 19478 & 19480 \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{size}     & Binary Classification      & ROC-AUC & 37497 & 17987 & 16761 \\ \cline{2-8} 
\multicolumn{1}{c|}{}                         & \multirow{3}{*}{EC50}  & \multicolumn{1}{c|}{assay}    & Binary Classification      & ROC-AUC & 4978  & 2761  & 2725  \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{scaffold} & Binary Classification      & ROC-AUC & 2743  & 2723  & 2762  \\
\multicolumn{1}{c|}{}                         &                        & \multicolumn{1}{c|}{size}     & Binary Classification      & ROC-AUC & 5189  & 2495  & 2505  \\ \bottomrule
\end{tabular}%
}\label{data_st}
\vspace{-4mm}
\end{table}

\textbf{Distribution split.} In this work, we investigate various types of distribution-splitting strategies for different datasets.
\begin{itemize}
    \item \textbf{Scaffold.}  Molecular scaffold is the core structure of a molecule that supports its overall composition, but it only exhibits specific properties when combined with particular functional groups. 
    \item \textbf{Size.} The size of a graph refers to the total number of nodes, and it is also implicitly related to the graph's structural properties.     
    \item \textbf{Assay.} The assay is an experimental technique used to examine or determine molecular characteristics. Due to differences in assay conditions and targets, activity values measured by different assays can vary significantly. 
    \item \textbf{Basis.} The generation of a motif involves combining a base graph (wheel, tree, ladder, star, and path) with a motif (house, cycle, and crane), but only the motif is directly associated with the label. 
    \item \textbf{Color.} CMNIST is a graph dataset constructed from handwritten digit images. Following previous research, we declare a distribution shift when the color of the handwritten digits changes.
\end{itemize}
\subsection{Baselines}\label{appe:baseline}
In our experiments, the methods we compared can be divided into two categories, one is ERM and traditional OOD generalization methods:
\begin{itemize}
    \item \textbf{ERM} is a standard learning approach that minimizes the average training error, assuming the training and test data come from the same distribution.
    \item \textbf{IRM}~\citep{arjovsky2019invariant} aims to learn representations that remain invariant across different environments, by minimizing the maximum error over all environments.
    \item \textbf{VREx}~\citep{krueger2021out} propose a penalty on the variance of training risks which can providing more robustness to changes in the input distribution.  
    \item \textbf{Coral}~\citep{coral} utilize a nonlinear transformation to align the second-order statistical features of the source and target domain distributions
\end{itemize}
Another class of methods is specifically designed for Graph OOD generalization:
\begin{itemize}
    \item \textbf{MoleOOD}~\citep{yang2022learning} learn the environment invariant molecular substructure by a environment inference model and a molecular decomposing model.
    \item \textbf{CIGA}~\citep{chen2022learning} proposes an optimization objective based on mutual information to ensure the learning of invariant subgraphs that are not affected by the environment.
    \item \textbf{GIL}~\citep{li2022learning} performs environment identification and invariant risk loss optimization by separating the invariant subgraph and the environment subgraph.
    \item \textbf{GERA}~\citep{liu2022graph} performs data augmentation by replacing the input graph with the environment subgraph to improve the generalization ability of the model
    \item \textbf{IGM}~\citep{jia2024graph} performs data augmentation by simultaneously performing a hybrid strategy of invariant subgraphs and environment subgraphs.
    \item \textbf{DIR}~\citep{wu2022discovering} identifies causal relation between input graphs and labels by performing counterfactual interventions.
    \item \textbf{DisC}~\citep{fan2022debiasing} learns causal and bias representations through a causal and disentangling based learning strategy separately.
    \item \textbf{GSAT}~\citep{miao2022interpretable} learns the interpretable label-relevant subgraph through an stochasticity attention mechanism.
    \item \textbf{CAL}~\cite{sui2022causal} proposes a causal attention learning strategy to ensure that GNNs learn effective representations instead of optimizing loss through shortcuts.
    \item  \textbf{iMoLD}~\citep{zhuang2023learning} designs two GNNs to directly extract causal features from the encoded graph representation.
    \item { \textbf{GALA}~\citep{gala} designs designs a new loss function to ensure graph OOD generalization without environmental information as much as possible.}
    \item  {\textbf{EQuAD}~\citep{Equad} learns how to effectively remove spurious features by optimizing the self-supervised informax function.}
\end{itemize}
\subsection{Implementation Details}\label{appe:hyperparam}
\textbf{Baselines.} For all traditional OOD methods, we conduct experiments on different datasets using the code provided by GOOD~\citep{good} and DrugOOD~\citep{drugood} benchmark. For graph OOD generalization methods with public code, we perform experiments in the same environments as our method and employ grid search to select hyper-parameters, ensuring fairness in the results.

\begin{table}[t] 
\renewcommand{\arraystretch}{0.9}
\setlength\tabcolsep{2pt}
\centering
\caption{Hyper-parameter configuration.}
% \vspace{-4mm}
% \resizebox{\columnwidth}{!}{%
\begin{tabular}{cccccccc}
\toprule
                                          & \multicolumn{1}{l}{}       &          & $\mathrm{proj\_dim}$ & $\mathrm{att\_dim}$ & $K$ & $lr$ & $\beta$ \\ \midrule
\multirow{6}{*}{DrugOOD}                  & \multirow{3}{*}{IC50}      & Assay    & 300      & 128     & 3   & 0.001     & 0.1     \\
                                          &                            & Scaffold & 300      & 128     & 3   & 0.001      & 0.1     \\
                                          &                            & Size     & 300      & 128     & 3   & 0.001     & 0.1     \\ \cline{2-8} 
                                          & \multirow{3}{*}{EC50}      & Assay    & 300      & 128     & 3   & 0.001      & 0.1     \\
                                          &                            & Scaffold & 300      & 128     & 3   & 0.001      & 0.1     \\
                                          &                            & Size     & 300      & 128     & 3   & 0.001     & 0.1     \\ \midrule
\multicolumn{1}{c}{\multirow{5}{*}{GOOD}} & \multirow{2}{*}{HIV}       & Scaffold & 300      & 128     & 3   & 0.01     & 0.1     \\
\multicolumn{1}{c}{}                      &                            & Size     & 300      & 128     & 3   & 0.01     & 0.1     \\ \cline{2-8} 
\multicolumn{1}{c}{}                      & \multirow{2}{*}{Motif}     & Basis    & 256     & 128     & 6   & 0.01    & 0.2     \\
\multicolumn{1}{c}{}                      &                            & Size     & 256      & 128     & 6   & 0.01    & 0.2     \\ \cline{2-8} 
\multicolumn{1}{c}{}                      & \multicolumn{1}{l}{CMNIST} & Color    & 256      & 128     & 5   & 0.01    & 0.2     \\ \bottomrule
\end{tabular}\label{hyperpater}
% }
% \vspace{-7mm}
\end{table}
\textbf{Our method.} We implement our proposed \ourmethod under the Pytorch~\citep{pytorch} and PyG~\citep{pyg}. For all datasets containing molecular graphs (all datasets from DrugOOD and GOODHIV), we fix the learning rate to $0.001$ and select the hyper-parameters by ranging the $\mathrm{proj\_dim}$ from $\{100,200,300\}$, $\mathrm{att\_dim}$ from $\{64,128,256\}$, $K$ from $\{2,3,4,5\}$ and $\beta$ from $\{0.01,0.1,0.2\}$. For the other datasets, we fix the learning rate to $0.01$ and select the hyper-parameters by ranging the $\mathrm{proj\_dim}$ from $\{64,128,256\}$, $\mathrm{att\_dim}$ from $\{64,128,256\}$, $K$ from $\{3,4,5,6\}$ and $\beta$ from $\{0.01,0.1,0.2\}$. For the top-$n$ pruning, we force $n$ to be half of $K$. We conduct a grid search to select hyper-parameters and refer to Table \ref{hyperpater} for the detailed configuration. For all experiments, we fix the number of epochs to 200 and run the experiment five times with different seeds, select the model to run on the test set based on its performance on validation, and report the mean and standard deviation. 
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}

\subsection{Supplemental Results}\label{appe:more_results}
We report the complete experimental results with means and standard deviations in Tables \ref{tab:main_good} and \ref{tab:main_drugood}
\input{tables/main_good_full}
\input{tables/main_drugood_full}.
\end{document}
\endinput
%%