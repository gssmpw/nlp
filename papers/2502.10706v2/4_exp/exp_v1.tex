In this section, we verify the effectiveness of our methods by conducting comprehensive experiments on two graph OOD benchmarks. 
\subsection{Experiments setup}
\textbf{Datasets.} We utilize two real-world benchmarks with various distribution shifts to evaluate our method. GOOD is a comprehensive graph OOD benchmark, and we selected three datasets: (1) GOOD-HIV, a molecular graph dataset predicting HIV inhibition; (2) GOOD-CMNIST, containing graphs transformed from MNIST using superpixel techniques; and (3) GOOD-Motif, a synthetic dataset where graph motifs determine the label. Additionally, DrugOOD is designed for AI-driven drug discovery with three types of distribution shifts: scaffold, size, and assay, applied to six molecular datasets for predicting drug-target binding affinity.
%We employ two real-world benchmarks containing various distribution shifts for graph OOD generalization to evaluate the effectiveness of our method.
% \begin{itemize}
%     \item \textbf{GOOD} is a systematic and comprehensive graph OOD benchmark, offering detailed distributions partition across various types of graphs. For the graph classification task, we selected three distinct datasets: (1) GOOD-HIV, a molecular graph dataset with the task of binary classification to predict whether a molecule can inhibit HIV; (2) GOOD-CMNIST, which consists of graphs representing hand-written digits transformed from the MNIST database using superpixel techniques; and (3) GOOD-Motif, a synthetic dataset where each graph is formed by connecting a base graph with a motif, where the motif alone determines the label.
%     \item \textbf{DrugOOD} is an OOD benchmark designed specifically for AI-driven drug discovery, where the data consists of molecular graphs. DrugOOD includes three basis of distribution shift: scaffold, size, and assay, and applies these to two measurements (IC50 and EC50). The benchmark contains six datasets, and all of them are tasked with predicting drug-target binding affinity, framed as a binary classification problem.
% \end{itemize}

\textbf{Baselines}.  For a more comprehensive comparison, we evaluate our method against ERM and two categories of OOD baselines: (1) Traditional OOD approaches that can also be applied to Euclidean data, such as Coral, IRM and VREx; and (2) graph-specific OOD generalization methods, including environment-based approaches like MoleOOD, CIGA, GIL, GREA and causal explanations based: Disc and DIR, along with novel model architecture like CAL and GSAT .

\textbf{Implementation Details}. To ensure fairness, we adopt the same experimental setup as iMold across two benchmarks. For molecular datasets with edge features, we use a three-layer GIN with a hidden dimension of 300, while for non-molecular graphs, we employ a four-layer GIN with a hidden dimension of 128. Prototype updating is fixed with a hyperparameter of 0.99, and we use the Adam optimizer for model parameter updates. The projector is a two-layer MLP with a hidden dimension set to half that of the GIN encoder. All baselines use the optimal parameters from their original papers. Additional hyperparameter details can be found in Appendix 2.

\subsection{main results}

\textbf{Q: Whether our methods achieves the best performance on the OOD generalization on these two benchmarks?} 
Yes, our method integrates hyperspherical space and invariant learning by optimizing the proposed objective function, ensuring the invariance of representations without relying on environmental information, while simultaneously enhancing separability

 \noindent$\rhd$ \textsf{State-of-the-art results.}
Table \ref{table_1} and Table \ref{table_2} present the experimental results on GOOD and DrugOOD benchmark. Our method achieves the state-of-the-art performance on 10 out of 11 datasets, securing second place on the remaining dataset. The average improvements against the previous SOTA are $4.87\%$ on GOOD and $1.68\%$ on DrugOOD. Our method consistently outperforms other baselines in terms of average performance across various data shifts, demonstrating its superior ability to achieve environment invariance. Moreover, our model achieves the best results in both binary and multi-class tasks, highlighting the strength of the multi-prototype-based classification approach.

 \noindent$\rhd$ \textsf{Environment-based methods fail.}
Among all baselines, environment-based methods only achieve the best performance on 5 datasets, while other methods perform best on the remaining datasets. Notably, general OOD methods still achieve the best results on three of these datasets. These observations suggest that environment-based methods are limited by the challenge of accurately defining environmental information in graph data, leading to a discrepancy between theoretical expectations and experimental results. In contrast, the performance of general OOD methods suggests that, even without specific environmental information for graphs, OOD generalization can still be achieved under certain conditions. 
\subsection{Ablation Experiment}
\textbf{Q: Whether each module in PGR-MOOD contribute to achieve effective OOD generalization?} Yes, we conduct experiments on three datasets to verify the role of our proposed loss constraint $\mathcal{L}_{\mathrm{inv}}$, $\mathcal{L}_{\mathrm{sep}}$, and the component of our model: projector and weight pruning technique. The results are shown in Table~\ref{ablation}.

\noindent$\rhd$ \textsf{Ablation on $\mathcal{L}_{\mathrm{inv}}$ and $\mathcal{L}_{\mathrm{sep}}$.}
 % \begin{document}
 We remove $\mathcal{L}_{\mathrm{inv}}$ and $\mathcal{L}_{\mathrm{sep}}$ in the Eq. (\ref{eq: target2}) respectively to explore their impacts on the performance of OOD generalization. The experimental results demonstrate a clear fact: merely optimizing  for invariance (w/o $\mathcal{L}_{\mathrm{sep}}$) or separability (w/o $\mathcal{L}_{\mathrm{inv}}$) weakens the OOD generalization ability of our model, especially for the multiclass classification task. This provides strong evidence that ensuring both invariance and separability is a sufficient and necessary condition for effective out-of-distribution generalization in graph learning.

 \noindent$\rhd$ \textsf{Ablation on projector and multi-prototype.}
 % \begin{document}
We conducted ablation studies by removing the projector and setting the number of prototypes to one to assess their impact on performance. The results demonstrate the necessity of both components. For the projector, as it projects the invariant features into the hyperspherical space, and the optimization of Eq. (\ref{eq: target2}) in the hyperspherical space cannot be completed if without it, even leading worse results than ERM. Similarly, the absence of multiple prototypes blurs the decision boundaries between classes, which in turn affects the calculation of the loss function $\mathcal{L}_{\mathrm{sep}}$, preventing the guarantee of inter-class separability.

 \noindent$\rhd$ \textsf{Ablation on updating and weight pruning.}
 % \begin{document}
We removed the prototype-related weight calculations and weight pruning operations separately. Experimental results show that proper weighting is essential for ensuring the correct alignment between representations and their corresponding prototypes. Without these techniques, the prototypes degrade into the average representation of all samples in the class, failing to maintain classification performance in OOD scenarios.

\subsection{Hyperparameter analysis}
 \noindent$\rhd$ \textsf{Analysis of $K$.}
 To investigate the effect of the number of prototypes on model performance, we vary $k$ from 2 to 5 and present the experimental results in Fig. \ref{hyper_p}. We observe that the best performance is achieved when the number of prototypes is approximately twice the number of classes (e.g., 2 or 3 for GOOD-HIV, and 5 or 6 for GOOD-Motif). Deviating from this optimal range, either too many or too few prototypes negatively impacts the final performance.
 
  \noindent$\rhd$ \textsf{Analysis of $\beta$.}
  To investigate the effect of the coefficient $\beta$ for $\mathcal{L}_{\mathrm{inv}}$ on model performance, we vary $\beta$ within {0.01, 0.05, 0.1, 0.2, 0.3} and present the results in Fig. \ref{hyper_a}. We observe that a small $\beta$ (e.g., 0.01, 0.05) hampers the model’s ability to effectively learn invariant features, while selecting a moderate $\beta$ (0.1) leads to the best performance.

\subsection{Analysis of the hyperspherical Space}
\textbf{Q: Whether hyperspherical Spaces are more separable than ordinary latent Spaces} Yes, the visualization shows the advantage of hyperspherical space over traditional latent space.

To further validate the advantage of hyperspherical latent space over traditional latent spaces, we visualized the invariant representation 
$\hat{\vz}_{inv}$ in both the training set (ID) and the test set (OOD) after achieving the best score on the validation set (ID). Using T-SNE, we visualize the representation on GOODHIV-Scaffold using T-sne, as shown in Figure \ref{t1}. For comparison, we also visualized the invariant representations learned by the state-of-the-art method, CIGA, as shown in Figure \ref{t2}. It is evident that our method produces more separable invariant representations, while also exhibiting tighter clustering for samples of the same class, indicating successful capture of environment-invariant features. In contrast, while CIGA also achieves some degree of intra-class compactness, its lower separability hampers its overall performance.

In addition, we reveal the characteristics of prototypes by visualizing samples that exhibit the highest similarity to them. As shown in Figure \ref{v_prototype}, prototypes from different classes capture distinct invariant subgraphs, ensuring a strong correlation with their respective labels. Furthermore, within the same category, different prototypes encapsulate samples with varying environmental subgraphs. This effectively validates the association between multi-prototype learning and environmental adaptability.
\begin{figure*}[t!] \label{v_prototype}
\centering    
\includegraphics[scale=0.39]{3_method/sx_prototype.pdf}
\caption{In the case of the DrugOOD-IC50-assay (binary classification task), we set up three prototypes for each class and visualized the closest example to it. }  
\label{fig:intro} 
\end{figure*}

\begin{table}[ht] \label{table_1}
\centering
\caption{Performance of various methods on IC50 and EC50 tasks.}
\begin{tabular}{l|ccc|ccc}
\hline
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{IC50} $\uparrow$} & \multicolumn{3}{c}{\textbf{EC50} $\uparrow$} \\ 
 & \textbf{Assay} & \textbf{Scaffold} & \textbf{Size} & \textbf{Assay} & \textbf{Scaffold} & \textbf{Size} \\ \hline
ERM & 70.61 (0.75) & 67.54 (0.42) & 66.10 (0.31) & 65.27 (2.39) & 65.02 (1.10) & 65.17 (0.32) \\ 
IRM & 71.15 (0.57) & 67.22 (0.62) & \underline{67.58 (0.58)} & 67.77 (2.71) & 63.86 (1.36) & 59.19 (0.83) \\ 
VREx & 70.98 (0.77) & 68.02 (0.43) & 65.67 (0.19) & 69.84 (1.88) & 62.31 (0.96) & \underline{65.89 (0.83)} \\ 
Coral & 71.28 (0.91) & 68.36 (0.61) & 67.53 (0.32) & 72.08 (2.80) & 64.83 (1.64) & 58.47 (0.43) \\ \hline
MoleOOD & 71.62 (0.50) & 68.58 (1.14) & 67.22 (0.96) & 72.69 (4.16) & 65.78 (1.47) & 64.11 (1.04) \\ 
CIGA & \underline{71.86 (1.37)} & \textbf{69.14 (0.70)} & 66.99 (1.40) & 69.15 (5.79) & \underline{67.32 (1.35)} & 65.60 (0.82) \\ 
GIL & 70.66 (1.75) & 67.81 (1.03) & 66.23 (1.98) & 70.25 (5.79) & 63.95 (1.17) & 64.91 (0.76) \\ 
GREA & 70.23 (1.17) & 67.20 (0.77) & 66.09 (0.56) & 74.17 (1.47) & 65.84 (1.35) & 61.11 (0.46) \\  \hline
DIR & 69.84 (1.41) & 66.33 (0.65) & 62.92 (1.89) & 65.81 (2.93) & 63.76 (3.22) & 61.56 (4.23) \\ 
DisC & 61.40 (2.56) & 62.70 (2.11) & 64.43 (0.60) & 63.71 (5.56) & 60.57 (2.27) & 57.38 (2.48) \\ \hline
GSAT & 70.59 (0.43) & 66.94 (1.43) & 64.53 (0.51) & 73.82 (2.62) & 62.65 (1.79) & 62.65 (1.79) \\ 
CAL & 70.09 (1.03) & 65.90 (1.04) & 64.42 (0.50) & \underline{74.54 (1.48)} & 65.19 (0.87) & 61.21 (1.76) 
\\ \hline
Ours & \textbf{72.96 (1.21)} & \underline{68.62 (0.78)} & \textbf{68.06 (0.55)} & \textbf{78.08 (0.54)} & \textbf{68.34 (0.61)} & \textbf{68.11 (0.58)} \\ \hline
\end{tabular}
\end{table}

% \end{document}
\begin{table}[htbp] \label{table_2}
\centering
\begin{tabular}{l|cc|c|cc}
\toprule
           & \multicolumn{2}{c|}{GOOD-Motif} & \multicolumn{1}{c|}{GOOD-CMNIST} & \multicolumn{2}{c}{GOOD-HIV} \\
           & basis         & size          & color         & scaffold      & size \\
\midrule
ERM        & 60.93(2.11)  & 46.63(7.12)   & 26.64(2.37)   & 69.55(2.39)   & 59.19(2.29)\\
IRM        & 64.94(4.85)   & 54.52(3.27)   & 29.63(2.06)   & 70.17(2.78)   & 59.94(1.59)\\
VREX       & 61.59(6.58)   & \underline{55.85(9.42)}   & 27.13(2.90)   & 69.34(3.54)   & 58.49(2.28)\\
Coral      & 61.95(4.36)  & 55.80(4.05)   & 29.21(6.87)   & 70.69(2.25)   & 59.39(2.90)\\
\midrule
MoleOOD      & -  & -   & -  & 69.39(3.43)   & 58.63(1.78)\\
CIGA       & 67.81(2.42)   & 51.87(5.15)   & 25.06(3.07)   & 69.40(1.97)   & \underline{61.81(1.68)}\\
GIL      & 65.30(3.02)   & 54.65(2.09)   & 31.82(4.24)   & 68.59(2.11)   & 60.97(2.88)\\
GREA      & 59.91(2.74)   & 47.36(3.82)   & 22.12(5.07)   & \underline{71.98(2.87)}   & 60.11(1.07)\\
\midrule
DIR        & 64.39(2.02)   & 43.11(2.78)   & 22.53(2.56)   & 68.44(2.51)   & 57.67(3.75)\\
DisC       & 65.08(5.06)  & 42.23(4.20)   & 23.53(0.67)   & 58.85(7.26)  & 49.33(3.84)         \\ 
\midrule
GSAT       & 62.27(8.79)   & 50.03(5.71)   & \underline{35.02(2.78)}   & 70.07(1.76)   & 60.73(2.39)\\
CAL       & \underline{68.01(3.27)}   & 47.23(3.01)   & 27.15(5.66)   & 69.12(1.10)   & 59.34(2.14)\\
\midrule
Ours     & \textbf{76.23(4.89)} & \textbf{58.43(3.15)} & \textbf{41.29(3.85)} & \textbf{73.94(1.77)} & \textbf{66.84(1.09)}\\ \bottomrule
\end{tabular}
\caption{This is scm}
\end{table}

% \begin{table*}[ht]\tiny
% \centering
% \begin{tabular}{l|ccc|ccc|cc|c|cc}
% \hline
% \multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{IC50} $\uparrow$} & \multicolumn{3}{c}{\textbf{EC50} $\uparrow$} & \multicolumn{2}{c|}{GOOD-Motif} & \multicolumn{1}{c|}{GOOD-CMNIST} & \multicolumn{2}{c}{GOOD-HIV} \\ 
%  & Assay & Scaffold & Size & Assay & Scaffold & Size & basis  & size & color  & scaffold  & size \\ 
% \hline
% ERM & 70.61 (0.75) & 67.54 (0.42) & 66.10 (0.31) & 65.27 (2.39) & 65.02 (1.10) & 65.17 (0.32) & 60.93(2.11)  & 56.63(7.12)   & 26.64(2.37)   & 69.55(2.39)   & 59.19(2.29)\\ 
% IRM & 71.15 (0.57) & 67.22 (0.62) & 67.58 (0.58) & 67.77 (2.71) & 63.86 (1.36) & 59.19 (0.83) & 64.94(4.85)   & 54.52(3.27)   & 29.63(2.06)   & 70.17(2.78)   & 59.94(1.59)\\
% VREx & 70.98 (0.77) & 68.02 (0.43) & 65.67 (0.19) & 69.84 (1.88) & 62.31 (0.96) & 60.19 (0.73) & 61.59(6.58)   & 55.85(9.42)   & 27.13(2.90)   & 69.34(3.54)   & 58.49(2.28)\\ 
% Coral & 71.28 (0.91) & 68.36 (0.61) & 67.53 (0.32) & 72.08 (2.80) & 64.83 (1.64) & 58.47 (0.43) & 61.95(4.36)  & 55.80(4.05)   & 29.21(6.87)   & 70.69(2.25)   & 59.39(2.90)\\
% \hline
% MoleOOD & 71.62 (0.50) & 68.58 (1.14) & 67.22 (0.96) & 72.69 (4.16) & 65.78 (1.47) & 65.51 (1.24) & -    & - & -    & - & -   \\ 
% CIGA & 71.86 (1.37) & \textbf{69.14 (0.70)} & 66.99 (1.40) & 69.15 (5.79) & 67.32 (1.35) & 65.60 (0.82) & 67.81(2.42)   & 51.87(5.15)   & 25.06(3.07)   & 69.40(1.97)   & 61.81(1.68) \\ 
% GIL & 70.66 (1.75) & 67.81 (1.03) & 66.23 (1.98) & 70.25 (5.79) & 63.95 (1.17) & 64.91 (0.76) & -    & - & -    & - & -   \\ 
% GREA & 70.23 (1.17) & 67.20 (0.77) & 66.09 (0.56) & 74.17 (1.47) & 65.84 (1.35) & 61.11 (0.46) & -    & - & -    & - & -    \\  
% \hline
% DIR & 69.84 (1.41) & 66.33 (0.65) & 62.92 (1.89) & 65.81 (2.93) & 63.76 (3.22) & 61.56 (4.23) & 64.39(2.02)   & 43.11(2.78)   & 22.53(2.56)   & 68.44(2.51)   & 57.67(3.75) \\ 
% DisC & 61.40 (2.56) & 62.70 (2.11) & 64.43 (0.60) & 63.71 (5.56) & 60.57 (2.27) & 57.38 (2.48) & -    & - & -    & - & -   \\ 
% \hline
% GSAT & 70.59 (0.43) & 66.94 (1.43) & 64.53 (0.51) & 73.82 (2.62) & 62.65 (1.79) & 62.65 (1.79)    & 62.27(8.79)   & 50.03(5.71)   & 35.02(2.78)   & 70.07(1.76)   & 60.73(2.39) \\ 
% CAL & 70.09 (1.03) & 65.90 (1.04) & 64.42 (0.50) & 74.54 (1.48) & 65.19 (0.87) & 61.21 (1.76) & -    & - & -    & - & -    \\ 
% \hline
% Ours & \textbf{72.96 (1.21)} & 68.62 (0.78) & \textbf{68.06 (0.55)} & \textbf{78.08 (0.54)} & \textbf{68.34 (0.61)} & \textbf{68.11 (0.58)} \\ \hline
% \end{tabular}
% \caption{Performance of various methods on IC50 and EC50 tasks.}
% \end{table*}


\begin{table}[ht]\label{ablation}
\centering
\begin{tabular}{lccc}
\toprule
 Mothod &IC50-size &HIV-scaffold &CMNIST-color \\
\midrule
Ours & \textbf{68.06 (0.55)} & \textbf{73.94 (1.77)} & \textbf{41.29 (3.85)}  \\
ERM & 66.10 (0.31) & 69.55 (2.39) & 26.64 (2.37)  \\
\midrule

w/o $\mathcal{L}_{inv}$ & 67.09 (0.65) & 70.61 (1.52) & 37.86 (3.44)  \\
w/o $\mathcal{L}_{sep}$ & 66.21 (0.37)  & 71.06 (1.56) & 37.53 (2.18) \\
\midrule
w/o projector & 51.96 (2.54) & 65.78 (3.57) & 21.05 (4.89) \\
w/o multi-prototype & 57.64 (1.02) & 62.11 (1.95) & 20.58 (3.78)  \\
\midrule
w/o updating & 54.14 (1.22) & 67.89 (1.84) & 38.95 (3.01)  \\
w/o weight pruning & 67.64 (1.02) & 71.11 (1.95) & 40.58 (3.78) \\
\bottomrule
\end{tabular}
\caption{Experimental results on GOOD-HIV-Scaffold and GOOD-PCBA-Size datasets.}
\end{table}



\begin{figure*}[h]
\centering 
\subfigure { 
\includegraphics[width=0.23\columnwidth]{K_hiv.pdf} 
}
\subfigure{ 
\includegraphics[width=0.23\columnwidth]{K_motif.pdf} 
}
\subfigure { 
\includegraphics[width=0.23\columnwidth]{K_a.pdf}
}
\subfigure { 
\includegraphics[width=0.23\columnwidth]{K_a_motif.pdf}
}
\caption{Left, Middle:} 
\label{hyperparameter}
\vspace{-1pt}
\end{figure*}

\begin{figure*}[h]
\centering 
\subfigure[CIGA] { 
\includegraphics[width=0.4\textwidth]{imold.pdf} \label{t1}
}
\subfigure[Ours] { 
\includegraphics[width=0.4\textwidth]{my(1).pdf} \label{t2}
}

\caption{Left, Middle:} 
\label{t-sne}
\vspace{-1pt}
\end{figure*}

% \begin{figure}[!ht] \label{hyper_p}   
% 					\centering            % 前面说过，图片放置在中间
% 					 % 第一张子图的下标（注意：注释要写在[]中括号内）
% 					{
% 						\label{apha}\includegraphics[width=0.25\textwidth,height=0.13\textheight]{K.pdf}
						
% 					}\hspace{2mm}
				
% 					{
% 						\label{length}\includegraphics[width=0.25\textwidth,height=0.13\textheight]{K_motif.pdf}
% 					}
					
% 					 \vspace{-10pt}
% 					\caption{ Analysis of Hyper-Parameters of our method on two GOOD datasets.}    % 整个图片的说明，注释写在{}内
% 					\label{figinfluence}            % 整个图片的标签编号，注意这里跟
     
% \end{figure}
% \begin{figure}[!ht] \label{hyper_a}   
% 					\centering            % 前面说过，图片放置在中间
% 					 % 第一张子图的下标（注意：注释要写在[]中括号内）
% 					{
% 						\label{apha}\includegraphics[width=0.25\textwidth,height=0.13\textheight]{K_a.pdf}
						
% 					}\hspace{2mm}
				
% 					{
% 						\label{length}\includegraphics[width=0.25\textwidth,height=0.13\textheight]{K_motif_a.pdf}
% 					}
					
% 					 \vspace{-10pt}
% 					\caption{ Analysis of Hyper-Parameters of our method on two GOOD datasets.}    % 整个图片的说明，注释写在{}内
% 					\label{figinfluence}            % 整个图片的标签编号，注意这里跟
     
% \end{figure}