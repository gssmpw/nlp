 \begin{figure*}[t!]    % 常规操作\begin{figure}开头说明插入图片
					% 后面跟着的[htbp]是图片在文档中放置的位置，也称为浮动体的位置，关于这个我们后面的文章会聊聊，现在不管，照写就是了
					\centering    
% 前面说过，图片放置在中间
	\label{fig:subfig5}\includegraphics[scale=0.39]{framework.jpg}
				
					
					\caption{During the training phase, we map the input graph to invariant features using a GNN-based extractor and project them into the hyperspherical space. The invariance of these features with respect to the environment is enforced by minimizing $\mathcal{L}_{\text{inv}}$, while the maximum separability of the categories within the hyperspherical space is ensured by minimizing $\mathcal{L}_{\text{sep}}$}    % 整个图片的说明，注释写在{}内
					\label{framework}            % 整个图片的标签编号，注意这里跟子图是一样的道理，标签不能重复 
				\end{figure*}

As previously mentioned in Eq.(\ref{eq: causal}), the OOD generalization objective seeks to maximize the mutual information between the invariant representation $z_{inv}$ and the label $y$, while ensuring that $z_{inv}$ remains independent of the environment $e$. However, directly optimizing this objective with strict constraints is challenging, especially in the context of graph data where defining and partitioning environments is inherently difficult. Graph structures do not have clear environmental boundaries, making it hard to enforce environment-specific constraints. To make the optimization more tractable, we relax the independence constraint and introduce a soft-constrained formulation: 
\begin{equation}
\label{eq: IB}
   \underset{z_{inv}}{\min} -I(y; z_{inv})+\beta I(z_{inv};e),
\end{equation}
where $e$ represents the environment to which the current graph belongs, but it cannot be directly observed or obtained. The parameter $\beta$ controls the trade-off between the predictive power of $z_{inv}$ and its independence from the environment $e$. This soft constraint allows for a more flexible optimization that still maintains the desired invariance properties in graph-based OOD generalization. Rather than relying on the explicit definition of the environment $e$, which is inherently difficult in graph data, we adopt a more flexible approach by using  prototypes in the hyperspherical space as implicit representations of environmental variations. This enables us to achieve the desired invariance in a more practical manner.


\textbf{Definition 1} (Prototype as Environment Variants). \label{def_1} 
\textit{For each class \( c \), we define its prototype denoted as \( \mu_{c} \). A graph $G_i$ will be classified as the class $i$ only if its hyperspherical representation \( \hat{z}_i \) has the greatest similarity with prototype \( \mu_{i} \). If  two  hyperspherical representations with different classes \( \hat{z}_i \in \mathcal{Y}_a \) and \( \hat{z}_j \in \mathcal{Y}_b \) are mistakenly assigned to the same prototype, i.e.,
\[
\mathrm{argmax}_{i} \, \mathrm{sim}(\hat{z}_i, \mu_{i}) = \mathrm{argmax}_{i} \, \mathrm{sim}(\hat{z}_j, \mu_{i})
\]
this misclassification suggests that the hyperspherical representations \( \hat{z} \) are more influenced by the environment \( e \) than by the actual class labels \( y \). Therefore, we can infer that this misclassification likely arises from the two graphs being in the same environment.}%Therefore, by increasing the number of prototypes, these prototypes can implicitly represent the environmental variations, eliminating the need to explicitly define or separate the environment \( e \).}

Given the introduction of prototypes as implicit variants of environment $e$, we now perform invariant learning in hyperspherical space and reformulate the optimization objective: 
\begin{equation}\label{eq: target2}
   \underset{\hat{z}_{inv}}{\min} \underbrace{-I(y ; \hat{z}_{inv}|\mu_{y}) }_{\mathcal{L}_{\mathrm{cls}}}\underbrace{-I(y ; \mu_{y}|\hat{z}_{inv}) }_{\mathcal{L}_{\mathrm{PS}}}+\underbrace{\beta I\left(\hat{z}_{inv};e|\mu_{y}\right)}_{\mathcal{L}_{\mathrm{IPM}}}.
\end{equation}
where $\hat{z}_{inv}$ represents the hyperspherical invariant representation. By using prototypes to represent environmental variations, we avoid the need for explicitly defining or labeling the environment. In addition, we guarantee the separability of the hyperspherical representation by increasing the distance between prototypes of different classes. Next, we will analyze each component of Eq.(\ref{eq: target2}) to provide a detailed understanding of its meaning. Additionally, the overall framework is illustrated in Figure 1, and the detailed pseudocode for the training process can be found in Appendix 1.

\subsection{hyperspherical invariant representation  extraction model}\label{invariant_model}
The goal of invariant learning is to extract features that are associated only with the label and remain invariant across environments. In the case of graph data, this usually means identifying an invariant subgraph. However, extracting flexible and variable subgraphs from complex, non-Euclidean structures can be time-consuming and often infeasible. Instead, we extract invariant representations in the latent space, which is both efficient and consistent with our loss function in Eq. (\ref{eq: target2}).

We utilize two GNNs: one to encode the input graph $G$ into the latent space, producing the node representation  $\mathbf{H}$, and the other to compute the separation score $S$ for the invariant features: 
\begin{equation}
    \mathbf{H} = \mathrm{GNN}_{I}(G) \in \mathbb{R}^{|\mathcal{V}| \times d}, \mathbf{S} = \sigma(\mathrm{GNN}_{S}(G)) \in \mathbb{R}^{|\mathcal{V}| \times d},
\end{equation}
$\mathrm{GNN}_{I}$ encodes the input graph and $\mathrm{GNN}_{S}$ computes the separation score. $|\mathcal{V}|$ is the number of nodes in the graph $G$, $d$ is the latent space dimension, and $\sigma(\cdot)$ is the Sigmoid function to constrain $\mathbf{S}$ falls into the range of $(0,1)$. The invariant representation $\mathbf{z}_{inv}$ is  obtained through the following operation:
\begin{equation}
    \mathbf{z}_{inv} = \mathrm{READOUT}(\mathbf{H} \odot \mathbf{S}) \in \mathbb{R}^{d},
\end{equation}
where $\odot$ is the element-wise product and $\mathrm{READOUT}$ is an aggregation function (e.g., $\mathrm{mean}$) to generate a graph-level representation. Existing graph invariant learning methods optimize the objective in Eq. (\ref{eq: IB}) using $z_{inv}$, but this often relies on explicit environment information and fails to ensure sufficient class separability. 
Our approach optimizes a more achievable objective Eq. (\ref{eq: target2}) by computing hyperspherical invariant representations $\hat{z}_{inv}$. It can be formulated as follows:
\begin{equation}
\label{eq: hype_rinv}
    \hat{z}_{inv} = \mathrm{Poj}(z_{inv}), \hat{z}_{inv} = \hat{z}_{inv} / \| \hat{z}_{inv}\|_{2}
\end{equation}
where $\mathrm{Poj}$ is a projector, such as an $\mathrm{MLP}$, that maps the representation to a lower-dimensional space.  This method establishes a novel framework by integrating invariant learning with hyperspherical embeddings, laying the groundwork for the introduction of prototypes. By leveraging hyperspherical space, the model mitigates the need for explicit environmental labels and enhances the separability of class representations. Hyperspherical invariant representation strengthens OOD generalization and sets the foundation for incorporating prototypes to refine the learned representations further.

\subsection{Multi prototypes based hypersphere model} 
In the previous section, we established the groundwork for using hyperspherical embeddings to enhance representation separability. While traditional prototype-based models map input directly into hyperspherical space and rely on a single prototype for each class, this approach can result in non-compact representations and unclear decision boundaries. A single prototype often overfits easy-to-classify samples while failing to account for harder cases. To address these limitations, we extend the hyperspherical space by introducing multiple prototypes for each class, allowing the model to better capture the full complexity of the data. This multi-prototype approach ensures that the classification decision space is more adaptable and comprehensive, leading to more accurate coverage of all sample types.

\subsubsection{prototype updating}
To implement this multi-prototype approach effectively, it is essential to maintain up-to-date prototypes for each class throughout the training process. The following section describes the prototype updating mechanism that ensures the prototypes remain representative of their respective classes. 

Specifically, we assign $K$ prototypes for each class $c$ with $\boldsymbol{\mu}^{c} = \{ \boldsymbol{\mu}^{c}_{k}\}^{K}_{k=1}$
 and each prototype can be initialized as follows:
\begin{equation} \label{init}
 \quad \mu^{c}_{k} \sim \mathcal{N}(\textbf{0}, \textbf{I}), \quad 
\end{equation}
where $\mathcal{N}(\textbf{0}, \textbf{I})$ represents a standard multivariate Gaussian distribution, with mean vector $\textbf{0}$ and identity covariance matrix $\textbf{I}$. To ensure that the prototypes remain representative of the majority of samples in their respective classes, we adopt the exponential moving average (EMA) technique, which updates the prototypes asynchronously.

After obtaining the hyperspherical invariant representation $\hat{z}_{inv}$, the corresponding class prototype is updated before applying gradient descent to Eq.(\ref{eq: target2}) to adjust the model parameters. This approach prevents the prototype values from fluctuating too much during training, avoiding suboptimal solutions. The update rule for a batch of $B$ samples is given by:
\begin{equation} \label{eq: update_prototype}
    \boldsymbol{\mu}_k^c := \text{Normalize}\left( \alpha \boldsymbol{\mu}_k^c + (1 - \alpha) \sum_{i=1}^{B} \mathbbm{1}(y_i = c) w_{i,k}^c \hat{\vz}^i_{inv} \right), 
\end{equation}
where $\alpha$ is the EMA update rate, $w_{i,k}^c$ is the weight of sample $i$ for prototype $k$ in class $c$, and $\mathbbm{1}(y_i = c)$ is an indicator function that ensures the update applies only to samples of class $c$.  After each update, the prototype is normalized to maintain its unit norm, ensuring it remains on the hypersphere. The $\text{Normalize}$ function ensures that the prototypes are re-normalized to the unit sphere, allowing distance calculations to take place in the same space as $\hat{\vz}^i_{inv}$. Each representation $\hat{\vz}^i_{inv}$ is associated with multiple prototypes, weighted by the assigned weight vector$w_{i}^c \in \mathbb{R}^{K}$. By updating the prototypes using $\hat{z}_{inv}$, we ensure that the prototypes remain robust to environmental variations. This provides a clear advantage over traditional hyperspherical spaces, making our method particularly well-suited for OOD generalization tasks. 


\subsubsection{weight calculation and pruning}
Once the prototypes have been updated to reflect their respective class centers, it becomes critical to assign appropriate weights to ensure that each sample is matched with the most relevant prototype. In our multi-prototype hypersphere model, we address this through an Attention-based Matching mechanism. This approach computes the attention score between each sample and its corresponding class prototypes to determine the matching probability.
We first compute the attention scores as follows:
\begin{align}\label{eq: att}
    Q = \hat{\vz}_{inv}\mW^{Q}, K = \boldsymbol{\mu}^c\mW^{K}, \vw^{c} = \mathrm{softmax}(\frac{QK^\top}{\sqrt{d'}}),
\end{align}
where $\mW^{Q}, \mW^{K} \in \mathbb{R}^{d \times {d'}}$ are the learnable weight matrices for the samples and the prototypes, respectively. $d'$ is the dimension of the projected space.  The attention mechanism ensures that the prototype $\boldsymbol{\mu}^c$ most similar to $\hat{\vz}_{inv}$ receives the highest weight, which improves classification accuracy and helps the prototype remain aligned with its class center.

However, assigning weights to all prototypes within a class can lead to excessive similarity between prototypes, especially for difficult samples. This could blur decision boundaries and reduce the model's ability to correctly classify hard-to-distinguish samples.

To address this, we apply a \textbf{top-$k$ pruning} strategy, which keeps only the $k$-most relevant prototypes for each sample. The top-$k$ weights are retained, and the rest are pruned as follows:
\begin{equation}
    w_{i,k}^c = \mathbbm{1}[w_{i,k}^c>\beta]\ast w_{i,k}^c, 
\end{equation}
where $\beta$ is the threshold corresponding to the $k$-th largest weight, and $\mathbbm{1}[_{i,k}^c>\beta]$ is an indicator function that retains only the weights for the top-$k$ prototypes. This pruning mechanism ensures that the prototypes remain distinct and that the decision space for each class is well-defined, allowing for improved classification performance. By applying this attention-based weight calculation and top-$k$ pruning, the model ensures a more accurate and robust matching of samples to prototypes, enhancing classification, especially in OOD scenarios.

\subsection{Optimization Objectives for MPHIL}

\subsubsection{Invariant prototype matching loss $\mathcal{L}_{\mathrm{IPM}}$}
The challenge of disentangling invariant features from environmental variations lies at the heart of OOD generalization.   In our formulation, the misalignment of a sample with an incorrect prototype can be seen as a signal of environmental interference, while successful alignment with the correct prototype reflects the capture of stable, invariant features. The $\mathcal{L}_{\mathrm{IPM}}$ operates by reinforcing the proximity of samples to their invariant representations and penalizing the influence of environmental factors, implicitly captured through incorrect prototype associations.
The loss function is expressed as follows:
\begin{align}
   \mathcal{L}_{\mathrm{IPM}} = - \frac{1}{B} \sum_{i=1}^{B} \log \frac{\sum_{c=y_i} \exp \left( \hat{z}_i^\top \boldsymbol{\mu}^c / \tau \right)}{\sum_{c=y_i} \exp \left( \hat{z}_i^\top \boldsymbol{\mu}^c / \tau \right) + \sum_{\hat{c} \neq y_i} \exp \left( \hat{z}_i^\top \boldsymbol{\mu}^{\hat{c}} / \tau \right)},
\end{align}
where $B$ represents the batch size, with $i$ indexing each sample in the batch. $\hat{z}_i$ represents the hyperspherical invariant representation, $\boldsymbol{\mu}^c$ is the correct class prototype, and $\boldsymbol{\mu}^{\hat{c}}$ denotes the prototypes of the incorrect classes $\hat{c} \neq y_i$. $\tau$ is a temperature factor. This formulation reflects the dual objective of pulling samples towards their class-invariant prototypes while ensuring that the influence of prototypes associated with environmental shifts is minimized. The numerator reinforces the similarity between the sample’s invariant representation and its correct prototype, while the denominator introduces competition between correct and incorrect prototypes, implicitly modeling the influence of environmental noise.

\subsubsection{Prototype Separation Loss $\mathcal{L}_{\text{PS}}$}
In hyperspherical space, all invariant $\hat{z}$ representations are compactly clustered around their respective class prototypes. To ensure inter-class separability, prototypes of different classes must be distinguishable.  The Prototype Separation Loss $\mathcal{L}_{\text{PS}}$  is designed to enforce this by maximizing the separation between prototypes of different classes while encouraging the similarity of prototypes within the same class. The loss function is defined as:
\begin{equation}
    \mathcal{L}_{\text{PS}} = -\frac{1}{CK} \sum_{c=1}^{C} \sum_{k=1}^{K} \log \frac{\sum_{i = 1}^{K} \mathbb{I}(i \neq k) \exp \left( {(\mathbf{\mu}_k^c)^\top \mathbf{\mu}_{i}^c}/{\tau} \right)}{\sum_{c' = 1}^{C} \sum_{j = 1}^{K} \mathbb{I}(c' \neq c) \exp \left( {(\mathbf{\mu}_k^c)^\top \mathbf{\mu}_{j}^{c'}}/{\tau} \right)},
\end{equation}
where $C$ represents the total number of classes, and $K$ denotes the number of prototypes assigned to each class. The prototypes $\mathbf{\mu}_k^c$ and $\mathbf{\mu}_i^c$ correspond to different prototypes within the same class $c$, while
$\mathbf{\mu}_k^c$ and $\mathbf{\mu}_j^{c'}$ represent prototypes from different classes.  The indicator function
$\mathbf{\mu}_k^c$ and $\mathbf{\mu}_j^{c'}$ represent prototypes from different classes.  The indicator function ensures that the comparisons are made between distinct prototypes, enhancing intra-class similarity and inter-class separation.


\subsubsection{prediction}
Given the complexity of real-world graph data, a single prototype per class often fails to capture the full diversity of features, especially in cases where graph structures are highly variable. Therefore, we modify Eq. (\ref{eq: prototpye_1}) to accommodate a multi-prototype setting. This multi-prototype strategy allows the invariant representations $\hat{\vz}_{inv}$ to learn more robust features, enhancing the model's ability to handle difficult-to-classify samples and reducing the likelihood of misclassification due to environmental variations.

In this setup, each class is represented by multiple prototypes, and the classification decision is made based on the maximum similarity between the invariant representation $\hat{\vz}_{inv}$ and the set of prototypes $\boldsymbol{\mu}_{k}^{c}$ associated with each class. The prediction probability is defined as:
\begin{equation}\label{classify}
   p(y = c | \hat{\vz}_{inv}; \{ \mathbf{w}^j, \boldsymbol{\mu}^c, \kappa \}_{j=1}^C) = 
\frac{\underset {k=1,\dots,K}{\max} (w_{k}^c \exp \left(  {\boldsymbol{\mu}_k^c}^\top \hat{\vz}_{inv} / \tau \right))}
{\sum_{j=1}^{C} \underset {{k'}=1,\dots,K}{\max} (w_{k'}^j \exp \left(  {\boldsymbol{\mu}_{k'}^j}^\top \hat{\vz}_{inv} / \tau \right))}.
\end{equation}

During training, this classification probability is used to compute the cross-entropy loss ${\mathcal{L}_{\mathrm{cls}}}$ which is defined as:
\begin{equation}
    \mathcal{L}_{\text{cls}} = \text{Cross-entropy}(y, \mathrm{argmax}_{c} p(y = c \mid \hat{\vz}_{inv}; \{ \boldsymbol{\mu}_k^c \}_{j=1}^C)).
\end{equation}

In this chapter, we introduced the Multi-Prototype Hyperspherical Invariant Learning (MPHIL) framework, which leverages hyperspherical embeddings and a multi-prototype strategy to improve OOD generalization in graph data. By utilizing prototypes as implicit representations of environmental variations and optimizing a relaxed objective, our method effectively captures invariant features and enhances class separability. The training procedure, including prototype updating and weight pruning, is detailed in the pseudocode provided in Appendix A.