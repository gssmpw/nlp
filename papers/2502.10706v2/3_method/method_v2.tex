In this section, we present the proposed method, \textbf{M}ulti-\textbf{P}rototype \textbf{H}yperspherical \textbf{I}nvariant \textbf{L}earning (\ourmethod). In Sec.~\ref{subsec:framework}, we first derive our general framework based on the learning objective graph invariant learning (GIL). Then, we describe the specific designs of the components in MPHIL, including hyperspherical invariant representation learning (Sec.~\ref{subsec:invariant_model}), multi-prototype classifier (Sec.~\ref{subsec:proto}), and learning objectives (Sec.~\ref{subsec:objective}). The overall learning pipeline of \ourmethod is shown in Fig.~\ref{fig:framework}.
\begin{figure*}[t!] 
\centering    
% \vspace{-3mm}
\includegraphics[scale=0.5]{3_method/final_framework.pdf}
% \vspace{-2mm}
\caption{The overall framework of \ourmethod. First, a GNN-based model generates the invariant representation and maps it into the hyperspherical space. Then, the classifier makes the prediction based on multiple prototypes. The overall method is trained by a three-term joint objective.}
\label{fig:framework} 
\end{figure*}
\subsection{Hyperspherical Graph Invariant Learning Framework} \label{subsec:framework}
The objective of GIL (i.e., Eq.~(\ref{eq: causal})) aims to maximize the mutual information between the invariant representation $\mathbf{z}_{inv}$ and the label $y$, while ensuring that $\mathbf{z}_{inv}$ remains independent of the environment $e$. However, directly optimizing this objective with such strict constraints is challenging due to the difficulty of modeling environments in graph data. To make the optimization more tractable, we relax the independence constraint and introduce a soft-constrained formulation:
\begin{equation}
\label{eq:soft}
   \underset{f_{c}, g}{\min} -I(y; \mathbf{z}_{inv})+\beta I(\mathbf{z}_{inv};e),
\end{equation}
where $e$ represents the environment to which the current graph belongs, but it cannot be directly observed or accessed. The parameter $\beta$ controls the trade-off between the predictive power of $\mathbf{z}_{inv}$ and its independence from the environment $e$. 

Although the relaxed objective Eq.~(\ref{eq:soft}) is more feasible, the intractable properties of real-world graph data (i.e., \textit{complex environment information} and \textit{inter-class semantic cliff} as discussed in Sec.~\ref{sec:intro}) still hinder us from learning reliable invariant representations and making accurate predictions with this objective. Specifically, the diversity and complexity of environments make it challenging to explicitly model $e$, leading to the difficulties of minimizing $I(\mathbf{z}_{inv};e)$. On the other hand, the semantic cliff issue may cause indistinguishable $\mathbf{z}_{inv}$ of samples belonging to different classes, resulting in the hardness of maximizing $I(y; \mathbf{z}_{inv})$ using a simple cross-entropy loss. 

To deal with the above challenges, we propose a new GIL framework based on hyperspherical space. Concretely, we model the invariant representations in a \textit{hyperspherical space} rather than an arbitrary latent representation space, which enhances the discriminative ability of the learned representations and improves robustness to environmental variations. The desirable properties of hyperspherical space allow us to introduce an intermediate variable, the \textit{class prototype} $\boldsymbol{\mu}$, as a bridge between the hyperspherical invariant representation $\mathbf{z}_{inv}$ and label $y$, which solve the above issues. To be more specific, the class prototypes $\boldsymbol{\mu}$, serving as cluster centers in the class space, directly capture the invariant patterns of each class. By ensuring correct matching between input samples and their corresponding class prototypes, reliable invariant representations can be learned within hyperspherical space, obviating the need for explicit environmental modeling 
$e$. Moreover, the prototype-based classifier is more robust against the semantic cliff issue, since the semantic gaps between classes can be precisely represented by the relative distances between prototypes in the hyperspherical space. Formally, the reformed learning objective is as follows, with detailed deductions from Eq.~(\ref{eq:soft}) to Eq.~(\ref{eq: target2}) provided in Appendix~\ref{appe:deduct}:
\begin{equation}\label{eq: target2}
   \underset{f_{c}, g}{\min} \underbrace{-I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)}) }_{\mathcal{L}_{\mathrm{C}}}\underbrace{-I(y ; \boldsymbol{\mu}^{(y)}) }_{\mathcal{L}_{\mathrm{PS}}}\underbrace{-\beta I(\hat{\mathbf{z}}_{inv};\boldsymbol{\mu}^{(y)})}_{\mathcal{L}_{\mathrm{IPM}}},
\end{equation}
where $\hat{\mathbf{z}}_{inv}$ represents the invariant representation in the hyperspherical space and $\boldsymbol{\mu}^{(y)}$ is the prototype corresponding to class $y$. In the following subsections, we will introduce \ourmethod as a practical implementation of the above framework, including the encoder $f_c$ for representation learning (Sec.~\ref{subsec:invariant_model}), the multi-prototype classifier $g$ (Sec.~\ref{subsec:proto}), and the three learning objective terms (Sec.~\ref{subsec:objective}).

\subsection{Hyperspherical Invariant Representation Extraction} \label{subsec:invariant_model}

\noindent\textbf{Encoder.} 
In GIL, the goal of the encoder $f$ is to extract invariant representations that are highly correlated with the invariant subgraph of each sample. Nevertheless, explicitly identifying the subgraphs via modeling the selecting probabilities of each node and edge may lead to increased overhead and require more complex network architectures~\citep{zhuang2023learning}. To mitigate these costs, we adopt a lightweight GNN-based model for efficient invariant representation learning. To be specific, our model includes two GNNs: $\mathrm{GNN}_{E}$ to encode the input graph $G$ into the latent space, producing the node representation $\mathbf{H}$, and $\mathrm{GNN}_{S}$ to compute the separation score $S$ for the invariant features: 
\begin{equation}\label{eq:score}
    \mathbf{H} = \mathrm{GNN}_{E}(G) \in \mathbb{R}^{|\mathcal{V}| \times d}, \mathbf{S} = \sigma(\mathrm{GNN}_{S}(G)) \in \mathbb{R}^{|\mathcal{V}| \times d},
\end{equation}
\noindent where $|\mathcal{V}|$ is the number of nodes in the graph $G$, $d$ is the latent dimension, and $\sigma(\cdot)$ is the Sigmoid function to constrain $\mathbf{S}$ falls into the range of $(0,1)$. Then, the invariant representation $\mathbf{z}_{inv}$ is obtained through the following operation:
\begin{equation}\label{eq:readout}
    \mathbf{z}_{inv} = \mathrm{READOUT}(\mathbf{H} \odot \mathbf{S}) \in \mathbb{R}^{d},
\end{equation}
where $\odot$ is the element-wise product and $\mathrm{READOUT}(\cdot)$ is an aggregation function (e.g., $\mathrm{mean}$) to generate a graph-level representation. 

\noindent\textbf{Hyperspherical Projection.} 
After obtaining $\mathbf{z}_{inv}$, the key step in \ourmethod is to project it into hyperspherical space. Concretely, the hyperspherical invariant representation $\hat{\mathbf{z}}_{inv}$ can be calculated by: 
\begin{equation}
\label{eq: hype_rinv}
    \tilde{\mathbf{z}}_{inv} = \mathrm{Proj}(\mathbf{z}_{inv}), \hat{\mathbf{z}}_{inv} = \tilde{\mathbf{z}}_{inv} / \| \tilde{\mathbf{z}}_{inv}\|_{2}, 
\end{equation}
where $\mathrm{Proj}(\cdot)$ is a MLP-based projector that maps the representation into another space, and dividing $\tilde{\mathbf{z}}_{inv}$ by its norm constrains the representation vector to unit length. The hyperspherical projection allows invariant learning to occur in a more discriminative space. More importantly, the hyperspherical space provides a foundation for prototypical classification, enabling the extraction of invariant patterns without modeling environments and addressing the semantic cliff issue.

\subsection{Multi-Prototype Hyperspherical Classifier} \label{subsec:proto}
Following hyperspherical projection, the next step is to construct a prototype-based classifier within the hyperspherical space. In conventional hyperspherical learning approaches~\citep{ke2022hyperspherical}, each class is typically assigned a single prototype. Although this is a straightforward solution, its modeling capabilities regarding decision boundaries are limited, as it may not adequately capture the complexity of the data distribution. More specifically, a single prototype often overfits easy-to-classify samples while failing to consider the harder samples. To address this limitation, we propose a multi-prototype hyperspherical classifier in which \textit{each class is represented by multiple prototypes}. This multi-prototype approach ensures that the classification decision space is more flexible and comprehensive, enabling better modeling of intra-class invariance and inter-class separation. In the following paragraphs, we will explain how to initialize, update, and use the prototypes for prediction.

\noindent\textbf{Prototype Initialization.} 
For each class $c \in \{1, \cdots, C\}$, we assign $K$ prototypes for it, and they can be denoted by $\mathbf{M}^{(c)} \in \mathbb{R}^{K \times d} = \{ \boldsymbol{\mu}_{k}^{(c)}\}^{K}_{k=1}$. At the beginning of model training, we initialize each of them by $\boldsymbol{\mu}_{k}^{(c)} \sim \mathcal{N}(\textbf{0}, \textbf{I})$, where $\mathcal{N}(\textbf{0}, \textbf{I})$ represents a standard multivariate Gaussian distribution. Random initialization can help prevent the issue of mode collapse.

\noindent\textbf{Prototype Updating.} 
To ensure that the prototypes can represent the majority of samples in their corresponding classes while preserving  cross-distribution stability, we adopt the exponential moving average (EMA) technique to update the prototypes asynchronously according to invariant representation $\hat{\mathbf{z}}_{inv}$. Specifically, the update rule for a batch of $B$ samples is given by:
\begin{equation} \label{eq: update_prototype}
    \boldsymbol{\mu}_{k}^{(c)} := \text{Norm}\left( \alpha \boldsymbol{\mu}_{k}^{(c)} + (1 - \alpha) \sum_{i=1}^{B} 1(y_i = c) \mathbf{W_{i,k}^{(c)}} \mathbf{\hat{Z}_{inv,i}} \right), 
\end{equation}
where $\alpha$ is the EMA update rate, $\mathbf{W_{i,k}^{(c)}} $ is the weight of the $i$-th sample for prototype $k$ in class $c$, $\mathbf{\hat{Z}_{inv,i}}$ is the representations of the $i$-th sample, and ${1}(y_i = c)$ is an indicator function that ensures the update applies only to samples of class $c$.  After each update, the prototype is normalized to maintain its unit norm, ensuring it remains on the hypersphere and the distance calculations take place in the same unit space as $\mathbf{\hat{Z}_{inv,i}}$. Each representation $\mathbf{\hat{Z}_{inv,i}}$ is associated with multiple prototypes, weighted by the assignment weight vector $\mathbf{W_{i}^{(c)}} \in \mathbb{R}^{K}$. 

\noindent\textbf{Assignment Weight Calculation.} 
To ensure that each sample is matched with the most relevant prototype, we introduce an attention-based matching mechanism. This approach computes the attention score between each sample and its class prototypes to determine the assignment weights:
\begin{equation}\label{eq: att}
    \mathbf{Q} = \mathbf{\hat{Z}_{inv,i}}\mathbf{W}_{Q}, K = \mathbf{M}^{(c)}\mathbf{W}_{K}, \mathbf{W^{(c)}_i} = \mathrm{softmax}(\frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d'}}),
\end{equation}
where $\mathbf{W}_{Q}, \mathbf{W}_{K} \in \mathbb{R}^{d \times {d'}}$ are the learnable weight matrices for the samples and the prototypes, respectively, and $d'$ is the dimension of the projected space. The attention mechanism ensures that the prototype $\boldsymbol{\mu}^{(c)}$ most similar to the current $\mathbf{\hat{Z}_{inv,i}}$ receives the highest weight, which improves classification accuracy and helps the prototype remain aligned with its class center. In practice, to ensure that each sample can only concentrate on a limited number of prototypes, we further introduce a \textbf{top-$n$ pruning} strategy: we only preserve $\mathbf{W_{i,k}^{(c)}}$ with the top-$n$ largest values while setting the rest to be 0. The detailed algorithmic process and discussions are provided in Appendix~\ref{appe:pruning}. 

%%%%%%%%%%%%%
\noindent\textbf{Prototype-Based Prediction.} 
To make classification decisions with the multi-prototype classifier, we can calculate the prediction probability with the similarity between the invariant representation $\hat{\mathbf{z}}_{inv}$ and the set of prototypes $\boldsymbol{\mu}^{(c)}$ associated with each class, which is defined as:
\begin{align}\label{classify}
\resizebox{.9\hsize}{!}{$
p(y = c | \hat{\mathbf{z}}_{inv}; \{ \mathbf{w}^{(c)}, \boldsymbol{\mu}^{(c)}\}_{c=1}^{(C)}) = 
\frac{\underset {k=1,\dots,K}{\max} w_{k}^{(c)} \exp \left(  {\boldsymbol{\mu}_{k}^{(c)}}^\top \hat{\mathbf{z}}_{inv} / \tau \right)}
{\sum_{j=1}^{C} \underset {{k}=1,\dots,K}{\max} w_{k}^{(j)} \exp \left(  {\boldsymbol{\mu}_{k}^{(j)}}^\top \hat{\mathbf{z}}_{inv} / \tau \right)},$}
\end{align}
{where  $w_{k}^{c}$ represents the weight of the $k$-th prototype $\boldsymbol{\mu}_{k}^{(c)}$ assigned to the current sample for class $c$.}
After that, the class prediction can be directly obtained by an $\mathrm{argmax}$ operation. We classify using the prototype most similar to the sample, as it offers the most representative and discriminative information, helping the sample converge faster to the correct class.

\subsection{\ourmethod Learning Objectives} \label{subsec:objective}

In this subsection, we formulate the learning objective terms of \ourmethod in Eq.~(\ref{eq: target2}), including the invariant prototype matching loss $\mathcal{L}_{\mathrm{IPM}}$, prototype separation loss $\mathcal{L}_{\mathrm{PS}}$, and the classification loss $\mathcal{L}_{\mathrm{C}}$. For $\mathcal{L}_{\mathrm{IPM}}$ and $\mathcal{L}_{\mathrm{PS}}$, we formulate them with contrastive learning loss, which is proved to be an effective mutual information estimator~\citep{sordoni2021decomposed,xie2022self,sun2024interdependence}. For the term of $-I(y;\hat{\mathbf{z}}_{inv},\boldsymbol{\mu}^{(y)})$, we show in the Appendix~\ref{appe:deduct2} that it can be implemented with classification loss.

% \subsubsection{Invariant prototype matching loss $\mathcal{L}_{\mathrm{IPM}}$}
\noindent\textbf{Invariant Prototype Matching Loss $\mathcal{L}_{\mathrm{IPM}}$.}
The challenge of disentangling invariant features from environmental variations lies at the heart of OOD generalization. In our formulation, the misalignment of a sample with an incorrect prototype can be seen as {a signal of environmental interference.} In contrast, successful alignment with the correct prototype reflects {the capture of stable and invariant features.} Motivated by this, we design $\mathcal{L}_{\mathrm{IPM}}$ that operates by reinforcing the proximity of samples to their invariant representations and penalizing the influence of environmental factors, implicitly captured through incorrect prototype associations.
The loss function is expressed as follows:
\begin{align}\label{ipm}\resizebox{.9\hsize}{!}{$ \mathcal{L}_{\mathrm{IPM}} = - \frac{1}{B} \sum_{i=1}^{B} \log \frac{\sum_{c=y_i} \exp \left( \hat{\mathbf{z}}_i^\top \boldsymbol{\mu}^{(c)} / \tau \right)}{\sum_{c=y_i} \exp \left( \hat{\mathbf{z}}_i^\top \boldsymbol{\mu}^{(c)} / \tau \right) + \sum_{\hat{c} \neq y_i} \exp \left( \hat{\mathbf{z}}_i^\top \boldsymbol{\mu}^{(\hat{c})} / \tau \right)},$}
\end{align}
where $B$ represents the batch size, with $i$ indexing each sample in the batch. $\hat{\mathbf{z}}_i$ represents the hyperspherical invariant representation, $\boldsymbol{\mu}^{(c)}$ is the correct class prototype, $\boldsymbol{\mu}^{(\hat{c})}$ denotes the prototypes of the incorrect classes $\hat{c} \neq y_i$, and $\tau$ is a temperature factor. This formulation reflects the dual objective of pulling samples towards their class-invariant prototypes while ensuring that the influence of prototypes associated with environmental shifts is minimized. The numerator reinforces the similarity between the sampleâ€™s invariant representation and its correct prototype, while the denominator introduces competition between correct and incorrect prototypes, implicitly modeling the influence of environmental noise.

% \subsubsection{Prototype Separation Loss $\mathcal{L}_{\text{PS}}$}
\noindent\textbf{Prototype Separation Loss $\mathcal{L}_{\mathrm{PS}}$.} 
In hyperspherical space, all invariant $\hat{\mathbf{z}}$ representations are compactly clustered around their respective class prototypes. To ensure inter-class separability, prototypes of different classes must be distinguishable. The prototype separation loss $\mathcal{L}_{\text{PS}}$ is designed to enforce this by maximizing the separation between prototypes of different classes while encouraging the similarity of prototypes within the same class. The loss function is defined as:
\begin{equation}\label{ps}
\resizebox{.9\hsize}{!}{$
    \mathcal{L}_{\text{PS}} = -\frac{1}{CK} \sum_{c=1}^{C} \sum_{k=1}^{K} \log \frac{\sum_{i = 1}^{K} \mathbb{I}(i \neq k) \exp \left( {(\boldsymbol{\mu}_{k}^{(c)})^\top \boldsymbol{\mu}_{i}^{(c)}}/{\tau} \right)}{\sum_{c' = 1}^{C} \sum_{j = 1}^{K} \mathbb{I}(c' \neq c) \exp \left( {(\boldsymbol{\mu}_{k}^{(c)})^\top \boldsymbol{\mu}_{j}^{(c')}}/{\tau} \right)},$}
\end{equation}
where $C$ represents the total number of classes, $K$ denotes the number of prototypes assigned to each class, $\boldsymbol{\mu}_{k}^{(c)}$ and $\boldsymbol{\mu}_i^{(c)}$ correspond to different prototypes within the same class $c$,
$\boldsymbol{\mu}_{k}^{(c)}$ and $\boldsymbol{\mu}_j^{(c')}$ represent prototypes from different classes, and $\boldsymbol{\mu}_{k}^{(c)}$ and $\boldsymbol{\mu}_j^{(c')}$ represent prototypes from different classes. Such an indicator function ensures that the comparisons are made between distinct prototypes, enhancing intra-class similarity and inter-class separation.

% \subsubsection{prediction}
\noindent\textbf{Classification Loss $\mathcal{L}_{\mathrm{C}}$.} 
To calculate the classification loss with the multi-prototype classifier, we update the classification probability in Eq.~(\ref{classify}) to be closed to truth labels with a classification loss. Take multi-class classification as example, we use the cross-entropy loss:
\begin{equation}\label{cls}
    \mathcal{L}_{\mathrm{C}} = - \frac{1}{BC} \sum_{i=1}^{B}\sum_{c=1}^{C}y_{ic}\text{log}(p(y = c \mid \hat{\mathbf{z}}_{i}; \{ w^{c},\boldsymbol{\mu}^{(c)} \}_{c=1}^{(C)})).
\end{equation}
% \begin{equation}
%     \mathcal{L}_{\mathrm{C}} = \text{Cross-entropy}(y, \mathrm{argmax}_{c} p(y = c \mid \hat{\mathbf{z}}_{inv}; \{ \boldsymbol{\mu}_{k}^{(c)} \}_{j=1}^{(c)})).
% \end{equation}
With the above loss terms, the final objective of \ourmethod can be written as $\mathcal{L}=\mathcal{L}_{\mathrm{C}}+\mathcal{L}_{\mathrm{PS}}+\beta\mathcal{L}_{\mathrm{IPM}}$. The pseudo-code algorithm and complexity analysis of \ourmethod is provided in Appendix~\ref{appe:method_detail}. 
% In this chapter, we introduced the Multi-Prototype Hyperspherical Invariant Learning (MPHIL) framework, which leverages hyperspherical embeddings and a multi-prototype strategy to improve OOD generalization in graph data. By utilizing prototypes as implicit representations of environmental variations and optimizing a relaxed objective, our method effectively captures invariant features and enhances class separability. The training procedure, including prototype updating and weight pruning, is detailed in the pseudocode provided in Appendix A.