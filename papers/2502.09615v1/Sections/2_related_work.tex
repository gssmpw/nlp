\section{Related Work}

\subsection{Automatic Rigging}

Rigging is a fundamental technique for animation in computer graphics.
% 
Traditional automatic rigging methods, such as Pinocchio~\cite{pinocchio}, rely on predefined skeletons and optimize their variations to fit a range of characters, with skinning weights determined by analyzing vertex-bone deformation relationships.
% 
However, the optimization process is computationally expensive and diminishes the generalizability.
% 
Recent advances in deep learning have improved the quality and adaptability of rigging.
% 
TARig~\cite{ma2023tarig} utilizes a template with adaptive joints and a boneflow field to generate skeletons and skinning weights for humanoid characters.
% 
Li's \textit{et al.}~\cite{li2021learning} leverages a predefined skeleton template for characters to learn rigging and proposes neural blend shape to enhance deformation quality.
% 
However, these methods are confined to humanoid characters in standard poses and rely heavily on predefined templates, limiting their robustness and generalization to diverse objects, poses, and skeleton topologies.
% 
% 

\begin{figure*}[t]
  \centering
  % \fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
  \includegraphics[width=\linewidth]{Figures/riganything-pipeline.pdf}
  \caption{Pipeline of our method: The input shape and the previously predicted skeleton sequence are tokenized using two separate tokenizers. These tokens are processed through a chain of autoregressive transformer blocks with a hybrid attention mask. Shape tokens perform self-attention to capture global geometric information, while skeleton tokens attend to all shape tokens and use causal attention within themselves to maintain the autoregressive generation process. After the transformer blocks, a skinning module decodes shape tokens into skinning weights, a joint diffusion module samples the next joint position, and a connectivity module predicts the next joint's connection to its preceding joint conditioned on the sampled next joint position from joint diffusion module.}
  % \Description{Temporal pipeline figure}
  \label{fig:main_pipeline}
  \vspace{-3mm}
\end{figure*}

Differently, RigNet~\cite{rignet} use a combination of regression and adaptive clustering to handle the diverse number of joints and employs a deep neural network for connectivity prediction to allow various topologies without templates or assumptions about shape classes and structures.
% 
However, it lacks the robustness and efficiency due to its model design, which is not end-to-end trainable with clustering and Minimum Spanning Tree operations.
% Concurrent works
Make-it-Animatable~\cite{guo2024makeitani} and HumanRig~\cite{chu2024humanrig} are works developed concurrently with ours. They also focus solely on humanoid characters and rely on template skeletons, restricting their adaptability to more diverse data categories. 
% 
In contrast, our method eliminates the need for templates and avoids assumptions about skeleton topology, achieving greater generalizability and robustness for diverse object types in a feed-forward manner.


\subsection{Autoregressive Models for 3D}

Autoregressive models are a powerful class of probabilistic models widely applied across domains such as natural language processing~\cite{brown2020language,achiam2023gpt,radford2019language} and computer vision~\cite{esser2021taming,parmar2018image,chen2020generative,li2024autoregressive}. 
% 
In 3D tasks, autoregressive models have also demonstrated remarkable potential in areas like shape generation~\cite{yan2022shapeformer,mittal2022autosdf,ibing2023octree,cheng2022autoregressive,argus} and motion generation~\cite{t2mgpt,rempe2021humor,han2024amd}.
% 
In 3D shape generation, methods mostly focus on designing effective representations for autoregressive modeling.
% 
ShapeFormer~\cite{yan2022shapeformer} introduces a sparse representation that quantizes non-empty voxel grids in a predefined order.
AutoSDF~\cite{mittal2022autosdf} takes a different approach by modeling the entire space and using randomized sampling orders to enable non-sequential modeling.
Octree Transformer~\cite{ibing2023octree} introduce octree-based hierarchical shape representations with adaptive compression, significantly reducing sequence lengths.
Cheng \textit{et al.}~\cite{cheng2022autoregressive} decompose point clouds into semantically aligned sequences.
% 
Argus3D~\cite{argus} utilizes discrete representation learning on a latent vector and scales up the model to improve the quality and versatility of 3D generation. 
% 
Similarly, autoregressive models have advanced 3D motion generation.
T2M-GPT~\cite{t2mgpt} uses motion VQ-VAE and textural descriptions for human motion generation. 
HuMoR~\cite{rempe2021humor} proposes hierarchical latent variables for realistic motion synthesis.
AMD~\cite{han2024amd} presents an autoregressive model that iteratively generates complex 3D human motions from long textual descriptions.
% 
In this paper, we pioneer the application of autoregressive models to the task of automatic rigging, marking a significant advancement in this domain.
