\definecolor{LightRed}{rgb}{1,0.92,0.92}
\definecolor{LightOrange}{rgb}{1,0.95,0.88}
\definecolor{LightYellow}{rgb}{1.0,1.0,0.84}
\definecolor{LightGreen}{rgb}{0.9,1.0,0.88}
\definecolor{LightCyan}{rgb}{0.9,1,1}
\definecolor{LightBlue}{rgb}{0.9,0.94,1}
\definecolor{LightIndigo}{rgb}{0.92,0.9,1}
\definecolor{LightMagenta}{rgb}{0.96,0.86,1}
\definecolor{DirtyWhite}{rgb}{0.96,0.96,0.96}
\definecolor{Training}{rgb}{0.9568627450980393, 0.7803921568627451, 0.6901960784313725}
\definecolor{Finetuning}{rgb}{0.6274509803921569, 0.8470588235294118, 0.9372549019607843}
\definecolor{Free}{rgb}{0.596078431372549, 0.8509803921568627, 0.5568627450980392}
\definecolor{softblue}{RGB}{100,149,237}
\definecolor{softgreen}{RGB}{144,238,144}
\definecolor{softpurple}{RGB}{230,190,255}
\definecolor{softyellow}{RGB}{255,255,0}
\definecolor{softpink}{RGB}{255,182,193}
\definecolor{softcyan}{RGB}{0,160,255}
\definecolor{majororange}{RGB}{240,145,72}
\definecolor{majoryellow}{RGB}{255,152,150}

\newcommand{\cluterthensample}{clustering-then-sampling}
\newcommand*{\belowrulesepcolor}[1]{% 
  \noalign{% 
    \kern-\belowrulesep 
    \begingroup 
      \color{#1}% 
      \hrule height\belowrulesep 
    \endgroup 
    % \vskip -0.15mm%
    \vspace{-0.03mm}
  }%
} 
\newcommand*{\aboverulesepcolor}[1]{% 
  \noalign{% 
  \vspace{-0.03mm}
    \begingroup 
      \color{#1}% 
    \endgroup 
    \kern-\aboverulesep 
  }%
}

\newcommand{\TrainingColor}{60}
\newcommand{\FinetuningColor}{40}
\newcommand{\FreeColor}{40}

\begin{figure*}[t]
\centering
\tikzset{
        my node/.style={
            draw,
            align=center,
            thin,
            text width=1.2cm, 
            minimum height=1cm, % 节点内文字与边框的距离？
            rounded corners=3,
        },
        my leaf/.style={
            draw,
            align=left,
            thin,
            % minimum width=1cm,
            text width=8.5cm, 
            % text height=1cm, 
            % minimum height=0.5cm,
            rounded corners=3,
        }
}
\forestset{
  every leaf node/.style={
    if n children=0{#1}{}
  },
  every tree node/.style={
    if n children=0{minimum width=1em}{#1}
  },
}
\begin{forest}
     for tree={
        % my node,
        every leaf node={my leaf, font=\small},
        every tree node={my node, font=\small, l sep-=4.5pt, l-=1.pt},
        anchor=west,
        inner sep=3pt, % 文字框与node框之间的距离？
        l sep=10pt, 
        s sep=5pt, % 上下两个node之间的距离 
        fit=tight,
        grow'=east,
        edge={ultra thin},
        parent anchor=east,
        child anchor=west,
        edge path={
            \noexpand\path [draw, \forestoption{edge} ] (!u.parent anchor) 
             -- +(5pt,0)
            |- (.child anchor)\forestoption{edge label};
        },
        if={isodd(n_children())}{
            for children={
                if={equal(n,(n_children("!u")+1)/2)}{calign with current}{}
            }
        }{}
    }
    [\textbf{Diffusion-generated Image Detection},draw=softblue, fill=softblue!15,text width=3cm
          [
         {\textbf{Data-driven} \\ \textbf{Detection} \\ \textbf{(Sec.~\ref{sec:data-driven})}},draw=majororange, fill=majororange!15, text width=2.3cm
        [
        {Advanced \\ Model Architectures},draw=majororange, fill=majororange!15,text width=3cm
        [
        {\cite{ojha2023towards,koutlis2024leveraging,liu2024forgery,liu2024mixture}
        },draw=majororange, fill=majororange!15,text width=6cm
        ]
        ]
        [
        Reduced Dataset Bias,draw=majororange, fill=majororange!15, text width=3cm
        [
        {\cite{doloriel2024frequency,chen2024drct,rajan2025effectiveness,yu2024semgir}},draw=majororange,fill=majororange!15, text width=6cm
        ]
        ]
        [
        {{Improved \\ Training Objectives}},draw=majororange, fill=majororange!15, text width=3cm
        [
        {\cite{khan2024clipping,liu2024forgery,chen2024drct,cozzolino2024zero,zhu2023gendet}}
        ,draw=majororange, fill=majororange!15, text width=6cm
        ]
        ]
    ]
        [
        {\textbf{Feature-driven} \\ \textbf{Detection} \\ \textbf{(Sec. \ref{sec:feature-driven})}},draw=softpurple, fill=softpurple!15, text width=2.3cm
        [
        {{Perceptible \\ Image Features}},draw=softpurple, fill=softpurple!15, text width=3cm
        [
        {\cite{sarkar2024shadows,sha2023fake}
        },draw=softpurple, fill=softpurple!15,text width=6cm
        ]
        ]
        [
        Imperceptible Image Features,draw=softpurple, fill=softpurple!15,text width=3cm
        [
        {\cite{zhang2024leveraging,tan2024rethinking,li2024improving,yan2024sanity,zhong2023rich,chen2024single}
        },draw=softpurple, fill=softpurple!15,text width=6cm
        ]
        ]
        [
        {{Features \\ Beyond Images}},draw=softpurple, fill=softpurple!15,text width=3cm
        [
        {\cite{cazenavette2024fakeinversion,brokman2025manifold,wang2023dire,ricker2024aeroblade,sha2024zerofake,luo2024lare}        },draw=softpurple, fill=softpurple!15,text width=6cm
        ]
        ]
        ]
    ]
\end{forest}
% \caption{Overall structure of this survey. We categorize existing generalizable diffusion-based image detection methods as data-driven detection and feature-driven detection. We also discuss several future directions.}
\caption{A taxonomy of recent diffusion-generated image detection methods.}
\label{fig_overall_structure}
\vspace{-5mm}
\end{figure*}

% A taxonomy of diffusion-generated image detection methods with representative methods.
%[
%    \textbf{Re-purposing\\(Sec.~\ref{subsec:re-purposing})},draw=softpink, fill=softpink!15, text width=2cm
%        [
%        {Re-purposed\\conditional encoders},draw=softpink, fill=softpink!15,text width=2.7cm
%        [
%        {T2I-Adapter~\cite{mou2023t2iadapter}, ControlNet~\cite{zhang2023controlnet}, PITI~\cite{wang2022piti}, BLIP diffusion~\cite{li2023blip}, MGIE~\cite{fu2023guiding}, \cite{kocsis2024lightit,zhang2023paste,goel2023pair, yang2024imagebrush, xu2023prompt, xiao2023fastcomposer, ma2023subject, gal2023encoder, jia2023taming, li2023warpdiffusion, lu2024coarse, shi2024instantbooth, shiohara2024face2diffusion, feng2023ranni, huang2023smartedit, li2023instructany2pix}
%        },draw=softpink, fill=softpink!15, text width=8cm       ]
%        ]
%        [
%        Condition injection,draw=softpink, fill=softpink!15,text width=2.7cm
%        [
%        {IP-adapter~\cite{ye2023ip}, GLIGEN~\cite{li2023GLIGEN}, Dragon-Diffusion~\cite{mou2023dragondiffusion}, \cite{wei2023elite, hoe2023interactdiffusion, wang2024instancediffusion, qi2024deadiff, gu2024mix}},draw=softpink, fill=softpink!15, text width=8cm
%        ]
%        ]
%        [
%        Backbone fine-tuning,draw=softpink, fill=softpink!15,text width=2.7cm
%        [
%        {Instructpix2pix~\cite{brook2023instructpix2pix}, PbE~\cite{yang2023paint}, \cite{yildirim2023inst,wei2023dialogpaint,zhang2024magicbrush, geng2023instructdiffusion, sheynin2023emu, zhang2023hive, wang2023imagen, xie2023smartbrush, xie2023dreaminpainter, song2023objectstitch, kim2023reference, chen2023anydoor, zhang2024text}
%        },draw=softpink, fill=softpink!15, text width=8cm
%        ]
%        ]
%    ]