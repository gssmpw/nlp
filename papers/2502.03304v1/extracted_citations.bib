@inproceedings{chen2017zoo,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM workshop on artificial intelligence and security},
  pages={15--26},
  year={2017}
}

@inproceedings{chen2022visualgpt,
  title={Visualgpt: Data-efficient adaptation of pretrained language models for image captioning},
  author={Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18030--18040},
  year={2022}
}

@article{chen2023deepzero,
  title={Deepzero: Scaling up zeroth-order optimization for deep model training},
  author={Chen, Aochuan and Zhang, Yimeng and Jia, Jinghan and Diffenderfer, James and Liu, Jiancheng and Parasyris, Konstantinos and Zhang, Yihua and Zhang, Zheng and Kailkhura, Bhavya and Liu, Sijia},
  journal={arXiv preprint arXiv:2310.02025},
  year={2023}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{dhurandhar2018explanations,
  title={Explanations based on the missing: Towards contrastive explanations with pertinent negatives},
  author={Dhurandhar, Amit and Chen, Pin-Yu and Luss, Ronny and Tu, Chun-Chen and Ting, Paishun and Shanmugam, Karthikeyan and Das, Payel},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{dhurandhar2019model,
  title={Model agnostic contrastive explanations for structured data},
  author={Dhurandhar, Amit and Pedapati, Tejaswini and Balakrishnan, Avinash and Chen, Pin-Yu and Shanmugam, Karthikeyan and Puri, Ruchir},
  journal={arXiv preprint arXiv:1906.00117},
  year={2019}
}

@article{dong2021should,
  title={How should pre-trained language models be fine-tuned towards adversarial robustness?},
  author={Dong, Xinshuai and Luu, Anh Tuan and Lin, Min and Yan, Shuicheng and Zhang, Hanwang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4356--4369},
  year={2021}
}

@inproceedings{gu2021efficient,
  title={Efficient on-chip learning for optical neural networks through power-aware sparse zeroth-order optimization},
  author={Gu, Jiaqi and Feng, Chenghao and Zhao, Zheng and Ying, Zhoufeng and Chen, Ray T and Pan, David Z},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={9},
  pages={7583--7591},
  year={2021}
}

@article{gururangan2020don,
  title={Don't stop pretraining: Adapt language models to domains and tasks},
  author={Gururangan, Suchin and Marasovi{\'c}, Ana and Swayamdipta, Swabha and Lo, Kyle and Beltagy, Iz and Downey, Doug and Smith, Noah A},
  journal={arXiv preprint arXiv:2004.10964},
  year={2020}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@inproceedings{li2022align,
  title={Align and prompt: Video-and-language pre-training with entity prompts},
  author={Li, Dongxu and Li, Junnan and Li, Hongdong and Niebles, Juan Carlos and Hoi, Steven CH},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4953--4963},
  year={2022}
}

@article{liu2018zeroth,
  title={Zeroth-order stochastic variance reduction for nonconvex optimization},
  author={Liu, Sijia and Kailkhura, Bhavya and Chen, Pin-Yu and Ting, Paishun and Chang, Shiyu and Amini, Lisa},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{liu2019roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692}
}

@article{liu2024sparse,
  title={Sparse mezo: Less parameters for better performance in zeroth-order llm fine-tuning},
  author={Liu, Yong and Zhu, Zirui and Gong, Chaoyu and Cheng, Minhao and Hsieh, Cho-Jui and You, Yang},
  journal={arXiv preprint arXiv:2402.15751},
  year={2024}
}

@article{malladi2023fine,
  title={Fine-tuning language models with just forward passes},
  author={Malladi, Sadhika and Gao, Tianyu and Nichani, Eshaan and Damian, Alex and Lee, Jason D and Chen, Danqi and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={53038--53075},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{sener2020learning,
  title={Learning to guide random search},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2004.12214},
  year={2020}
}

@inproceedings{shu2023zeroth,
  title={Zeroth-order optimization with trajectory-informed derivative estimation},
  author={Shu, Yao and Dai, Zhongxiang and Sng, Weicong and Verma, Arun and Jaillet, Patrick and Low, Bryan Kian Hsiang},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@inproceedings{singh2022revisiting,
  title={Revisiting weakly supervised pre-training of visual perception models},
  author={Singh, Mannat and Gustafson, Laura and Adcock, Aaron and de Freitas Reis, Vinicius and Gedik, Bugra and Kosaraju, Raj Prateek and Mahajan, Dhruv and Girshick, Ross and Doll{\'a}r, Piotr and Van Der Maaten, Laurens},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={804--814},
  year={2022}
}

@inproceedings{vemula2019contrasting,
  title={Contrasting exploration in parameter and action space: A zeroth-order optimization perspective},
  author={Vemula, Anirudh and Sun, Wen and Bagnell, J},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2926--2935},
  year={2019},
  organization={PMLR}
}

@article{verma2023certified,
  title={Certified Zeroth-order Black-Box Defense with Robust UNet Denoiser},
  author={Verma, Astha and Bangar, Siddhesh and Subramanyam, A Venkata and Lal, Naman and Shah, Rajiv Ratn and Satoh, Shin'ichi},
  journal={arXiv preprint arXiv:2304.06430},
  year={2023}
}

@inproceedings{wang2024pre,
  title={Pre-trained model guided fine-tuning for zero-shot adversarial robustness},
  author={Wang, Sibo and Zhang, Jie and Yuan, Zheng and Shan, Shiguang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24502--24511},
  year={2024}
}

@article{ye2018hessian,
  title={Hessian-aware zeroth-order optimization for black-box adversarial attack},
  author={Ye, Haishan and Huang, Zhichao and Fang, Cong and Li, Chris Junchi and Zhang, Tong},
  journal={arXiv preprint arXiv:1812.11377},
  year={2018}
}

@article{zhao2024second,
  title={Second-order fine-tuning without pain for llms: A hessian informed zeroth-order optimizer},
  author={Zhao, Yanjun and Dang, Sizhe and Ye, Haishan and Dai, Guang and Qian, Yi and Tsang, Ivor W},
  journal={arXiv preprint arXiv:2402.15173},
  year={2024}
}

