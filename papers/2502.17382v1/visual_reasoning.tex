% science_template.tex
% See accompanying readme.txt for copyright statement, change log etc.

% Any modification of this template, including writing a paper using it,
% MUST rename the file i.e. use a different file name.

%%%%%%%%%%%%%%%% START OF PREAMBLE %%%%%%%%%%%%%%%

% Basic setup. Authors shouldn't need to adjust these commands.
% It's annoying, but please do NOT strip these into a separate file.
% They need to be included in this .tex for our production software to work.

% Use the basic LaTeX article class, 12pt text
\documentclass[12pt]{article}

% Science uses Times font. If you don't have this installed (most LaTeX installations will be
% fine) or prefer the old Computer Modern fonts, comment out the following line
\usepackage{newtxtext,newtxmath}
% Depending on your LaTeX fonts installation, you might get better results with one or both of these:
%\usepackage{mathptmx}
%\usepackage{txfonts}

% Allow external graphics files
\usepackage{graphicx}

% Use US letter sized paper with 1 inch margins
\usepackage[letterpaper,margin=1in]{geometry}

% Double line spacing, including in captions
\linespread{1.5} % For some reason double spacing is 1.5, not 2.0!

% One space after each sentence
\frenchspacing

% Abstract formatting and spacing - no heading
\renewenvironment{abstract}
	{\quotation}
	{\endquotation}

% No date in the title section
\date{}

% Reference section heading
\renewcommand\refname{References and Notes}

% Figure and Table labels in bold
\makeatletter
\renewcommand{\fnum@figure}{\textbf{Figure \thefigure}}
\renewcommand{\fnum@table}{\textbf{Table \thetable}}
\makeatother

% Call the accompanying scicite.sty package.
% This formats citation numbers in Science style.
\usepackage{scicite}

% Provides the \url command, and fixes a crash if URLs or DOIs contain underscores
\usepackage{url}

%%%%%%%%%%%% CUSTOM COMMANDS AND PACKAGES %%%%%%%%%%%%

% Authors can define simple custom commands e.g. as shortcuts to save on typing
% Use \newcommand (not \def) to avoid overwriting existing commands.
% Keep them as simple as possible and note the warning in the text below.
% Example:
\newcommand{\pcc}{\,cm$^{-3}$}	% per cm-cubed

% Please DO NOT import additional external packages or .sty files.
% Those are unlikely to work with our conversion software and will cause problems later.
% Don't add any more \usepackage{} commands.


%%%%%%%%%%%%%%%% TITLE AND AUTHORS %%%%%%%%%%%%%%%%

% Title of the paper.
% Keep it short and understandable by any reader of Science.
% Avoid acronyms or jargon. Use sentence case.
\def\scititle{
	Unraveling the Geometry of Visual Relational Reasoning
}
% Store the title in a variable for reuse in the supplement (otherwise \maketitle deletes it)
\title{\bfseries \boldmath \scititle}

% Author and institution list.
% Institution numbers etc. should be hard-coded, do *not* use the \footnote command.
\author{
	% You can write out first names or use initials - either way is acceptable, but be consistent
	Jiaqi~Shang$^{1}$,
	Gabriel~Kreiman$^{2,3,4}$,
	Haim~Sompolinsky$^{4,5\ast}$\and
	% Additional lines of authors should be inserted using the \and command (not \\)
	% Institution list, in a slightly smaller font
	\small$^{1}$Program in Neuroscience, Harvard Medical School, Boston, Massachusetts \& 02115, United States.\and
        \small$^{2}$Boston Children’s Hospital, Harvard Medical School, Boston, Massachusetts \& 02115, United States.\and
        \small$^{3}$Center for Brains, Minds, and Machines, Cambridge, Massachusetts \& 02139, United States.\and
        \small$^{4}$Center for Brain Science, Harvard University, Cambridge, Massachusetts \& 02138, United States.\and
	\small$^{5}$Edmond and Lily Safra Center for Brain Sciences, Hebrew University, Jerusalem \& 9190401, Israel.\and
	% Identify at least one corresponding author, with contact email address
	\small$^\ast$Corresponding author. Email: hsompolinsky@mcb.harvard.edu
}

%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%% START OF MAIN TEXT %%%%%%%%%%%%%%%
\begin{document} 

% Insert the title and author list
\maketitle

% Abstract, in bold
% There are strict length limits, and not all formats have abstracts.
% Consult the journal instructions to authors for details.
% Do not cite any references in the abstract.
\begin{abstract} \bfseries \boldmath
Humans and other animals readily generalize abstract relations, such as recognizing \textit{constant} in shape or color, whereas neural networks struggle. To investigate how neural networks generalize abstract relations, we introduce \mbox{\textit{SimplifiedRPM}}, a novel benchmark for systematic evaluation. In parallel, we conduct human experiments to benchmark relational difficulty, enabling direct model-human comparisons. Testing four architectures—ResNet-50, Vision Transformer, Wild Relation Network, and Scattering Compositional Learner (SCL)—we find that SCL best aligns with human behavior and generalizes best. Building on a geometric theory of neural representations, we show representational geometries that predict generalization. Layer-wise analysis reveals distinct relational reasoning strategies across models and suggests a trade-off where unseen rule representations compress into training-shaped subspaces. Guided by our geometric perspective, we propose and evaluate SNRloss, a novel objective balancing representation geometry. Our findings offer geometric insights into how neural networks generalize abstract relations, paving the way for more human-like visual reasoning in AI.


\end{abstract}

% The first paragraph of any Science paper does NOT have a heading
% Nor is it indented
\subsection*{Introduction}
Humans and other animals demonstrate a remarkable ability to identify and generalize abstract relations across diverse contexts. For example, recognizing the relation “constant” allows individuals to flexibly apply it to different attributes, such as a row of objects sharing the same color or shape. Furthermore, one can readily apply the same abstract relation to novel attributes never encountered before. This ability to generalize abstract relations underpins flexible reasoning, supports complex problem-solving, and enables intelligent behavior in novel situations. 

A central challenge in cognitive neuroscience and artificial intelligence is to develop neural network models that can achieve similar abstract relation generalization. The Raven’s Progressive Matrices (RPM) task is a widely used benchmark for assessing abstract relational reasoning ability~\cite{raven1936mental}. In this task, participants view a $3\times3$ grid of images with the bottom-right panel missing. The goal is to identify the relational rules that govern the grid and select the correct missing panel based on these inferred rules. Inspired by this task, researchers have developed large-scale RPM-style datasets, such as Procedurally Generated Matrices (PGM)~\cite{barrett2018measuring} and the Relational and Analogical Visual rEasoNing (RAVEN) dataset~\cite{zhang2019raven, hu2021stratified}, and have trained various neural architectures to solve them~\cite{barrett2018measuring, zhang2019raven, hu2021stratified, wu2020scattering, webb2020emergent, webb2024relational, steenbrugge2018improving, hersche2023neuro, rahaman2021dynamic, zhang2022learning, zhang2019learning, zhang2024human, mondal2024slot}. While many of these models achieve high test accuracy on the relational rules they are trained on, they struggle to generalize to unseen rules~\cite{malkinski2022deep}. The absence of human behavioral data on the same generalization tasks measured in neural networks further complicates the interpretation of existing results. 

This limitation raises a fundamental question: What mechanisms enable or constrain abstract relation generalization in neural networks? While prior studies have documented performance levels, the representational factors shaping generalization remain poorly understood. In particular, it is unclear how learned representations encode relational structure, how these representations differ across neural network architectures, and what geometric constraints govern generalization.

In this work, we introduce a geometric framework to systematically analyze the structure of relational representations in neural networks. To compare quantitatively network generalization performance against humans, we introduce a new benchmark, the Simplified Raven’s Progressive Matrices (\textit{SimplifiedRPM}) task. Using this benchmark, we compare four representative neural networks spanning different reasoning strategies. ResNet-50~\cite{he2016deep}, Vision Transformer~\cite{dosovitskiy2020image}, Wild Relation Network~\cite{barrett2018measuring}, and Scattering Compositional Learner (SCL)~\cite{wu2020scattering}. We conduct human experiments, concluding that SCL aligns most closely with human relational reasoning. 

\textit{SimplifiedRPM} enables applying a geometric theory~\cite{sorscher2022neural} originally developed for generalization in visual object classification tasks to the reasoning domain. Specifically, we propose that the reasoning performance of neural networks can be attributed to the geometry of their emergent “rule manifolds”. We demonstrate that this geometric theory precisely predicts empirical generalization error in neural networks, establishing a direct link between the geometry of rule manifolds for unseen relations and generalization performance. Our analysis highlights two key geometric factors, signal and dimensionality, which interact to determine the generalizability of a network. Importantly, we observe a trade-off between signal and dimensionality, driven by a structured compression mechanism, where networks amplify the signal by constraining all class manifolds—including unseen ones—into a low-dimensional subspace spanned by the principal components of the training rules. Motivated by this theory, we introduce \textit{SNRloss}, a new network training objective explicitly designed to optimize the representation geometry and show that this loss function leads to adequate generalization performance with balanced geometric features. Overall, this work provides new insights into the mechanisms underlying relational reasoning through the lens of representation geometry.

\subsection*{Evaluating Deep Neural Networks in Relational Reasoning}
To systematically assess neural networks’ ability to generalize abstract relations, we developed the Simplified Raven’s Progressive Matrices (\textit{SimplifiedRPM}) task (Fig.~\ref{fig:Fig1_RPMtask_and_perf}A). Inspired by the original RPM task~\cite{raven1936mental}, \textit{SimplifiedRPM} requires models to infer a relational rule from a \textit{sample row} (Fig.~\ref{fig:Fig1_RPMtask_and_perf}A, top) and determine which of two \textit{choice rows} (Fig.~\ref{fig:Fig1_RPMtask_and_perf}A, bottom) follows the same rule. Each row consists of three \textit{panels} with abstract objects, such as triangles or circles, arranged according to a relational rule. For example, the sample row in Fig.~\ref{fig:Fig1_RPMtask_and_perf}A illustrates the ``constant shape'' rule, where all objects share the same shape while other attributes, such as number or position, vary. \textit{SimplifiedRPM} refines the original RPM task~\cite{raven1936mental} by reducing answer choices from eight to two, mitigating selection bias exploitation~\cite{hu2021stratified}, and presenting a single example row instead of two to remove multi-row comparisons. These changes maintain RPM's core challenge while enabling a more focused assessment of relational reasoning.

We construct a dataset for evaluating abstract relation generalization in the \textit{SimplifiedRPM} task, comprising rows governed by 40 distinct relational rules. Each rule applies an abstract relation (e.g., constant) to an object attribute (e.g., shape). The abstract relations and attributes are selected to be consistent with those used in human experiments~\cite{raven1936mental, matzen1994error} while maximizing the number of rules for comprehensive evaluation. Importantly, each row corresponds to a unique rule. We generate many rows per rule, resulting in a dataset of 400k training rows, 40k validation rows, and 40k test rows. To construct a \textit{SimplifiedRPM} task trial, a sample row is selected that follows one rule. A correct choice is drawn from the same rule, while an incorrect choice is drawn from a different rule. Further details are provided in the Methods section.

We assess models' ability to generalize abstract relations using a held-out rule split, where $5$ out of $40$ relational rules are excluded from training. During training, models learn relational structures from the remaining $35$ rules. For instance, a model trained on "constant number" and "OR shape" may never encounter "constant shape." After training, their performance is evaluated on the five withheld rules using the \textit{SimplifiedRPM} task. This design addresses limitations in the existing RPM benchmarks. RAVEN~\cite{zhang2019raven} lacks a split where some test rules are entirely unseen during training. Although PGM's Held-out Triplet split withholds certain rules, test rows still combine seen and unseen rules, allowing models to rely on familiar rules. In contrast, \textit{SimplifiedRPM} enforces a strict separation between training and test rules, ensuring a more rigorous evaluation of relational generalization. By systematically varying which rules are withheld, our benchmark provides a comprehensive assessment of models’ ability to generalize across different types of abstract relations.

We evaluate four representative models on the \textit{SimplifiedRPM} task: ResNet-50~\cite{he2016deep} and ViT~\cite{dosovitskiy2020image}, two benchmark vision models, and WReN~\cite{barrett2018measuring} and SCL~\cite{wu2020scattering}, which are explicitly designed for relational reasoning. These models employ different computational strategies: ResNet-50 applies a series of convolutional layers across all panels simultaneously, WReN computes pairwise panel relationships and aggregates them to infer underlying rules, ViT leverages self-attention to capture relational dependencies, and SCL employs a shared relational module to improve abstract relation recognition across object attributes. Together, these models represent diverse approaches to solving RPM tasks. All models are randomly initialized and trained end-to-end. Further details on the model architecture and hyperparameters are provided in the Methods section.

The models process a row to generate a high-dimensional \textit{relational representation} of its underlying relational rule (Fig.~\ref{fig:Fig1_RPMtask_and_perf}B). To train the models on $35$ relational rules, we appended a linear classification layer to the relational representations and optimized them end-to-end using cross-entropy loss with one-hot rule labels. Fig.~\ref{fig:Fig1_RPMtask_and_perf}C shows test errors across $15$ random training and held-out rules splits. All models successfully learned the relational rules, achieving test errors well below the chance level of $34/35=0.97$. Among them, SCL achieved the lowest test error, followed by ViT, WReN, and ResNet-50.

We assess the trained models’ ability to generalize abstract relations to unseen rules using the \textit{SimplifiedRPM} task. For each pair in the five held-out rules, we generate $500$ trials by randomly selecting a sample row that follows one rule, pairing it with a correct choice from the same rule and an incorrect choice from a different rule. In each trial, the model is sequentially presented with the sample row, followed by the two choice rows. The model computes the Euclidean distance between the relational representation of the sample row and each choice row. A trial is deemed correct if the correct choice row is closer to the sample row than the incorrect one (Fig.~\ref{fig:Fig1_RPMtask_and_perf}D). All models outperformed the chance generalization error of $0.5$ (Fig.~\ref{fig:Fig1_RPMtask_and_perf}E). Among them, SCL achieved the lowest generalization error, followed by ViT, WReN, and ResNet. Notably, SCL also outperformed the other models on the PGM benchmark’s held-out rule split~\cite{malkinski2022deep}, aligning with our observed generalization order.

\subsection*{SCL Captures Human-like Differential Relational Rule Difficulties}
Analyzing only the averaged generalization error is insufficient to fully assess neural networks' ability to generalize abstract relations, as a model may perform well overall but struggle with rules of specific relation types. To gain deeper insight, we analyzed generalization errors separately for trials where the correct rule of the sample row fell into one of three abstract relation types: progression, arithmetic, or logical. We observed distinct error patterns across models (Fig.~\ref{fig:Fig2_perf_per_rule}A-D). ResNet had higher errors for arithmetic than logical rules (Fig.~\ref{fig:Fig2_perf_per_rule}A). WReN showed the highest errors for arithmetic, performing worse than progression and logical rules (Fig.~\ref{fig:Fig2_perf_per_rule}B). ViT struggled most with arithmetic, while logical rules had higher errors than progression (Fig.~\ref{fig:Fig2_perf_per_rule}C). In contrast, SCL showed similarly high errors for arithmetic and logical rules but significantly lower errors for progression (Fig.~\ref{fig:Fig2_perf_per_rule}D). 

Interestingly, while arithmetic rules posed the greatest challenge for models to generalize, this difficulty did not arise from poor learning of the rules. Instead, it highlights the model's inability to generalize the arithmetic relation to new attributes. When evaluating test errors—the classification error on novel rows following the trained rules—arithmetic rules consistently had much lower errors than logical rules, which exhibited the highest errors across models (figure~\ref{fig:SuppFig1_test_err_per_relation}). 

Human performance on the original RPM task~\cite{raven1936mental} follows a hierarchy of difficulty, with progression rules the easiest and logical rules the hardest~\cite{forbes1964item,carpenter1990one,matzen1994error,matzen2010recreating}. Unlike models, humans do not receive explicit training on these rules before taking the task~\cite{te2001practice, flynn1987massive}. To evaluate whether models exhibit human-like reasoning, we compare their ability to generalize to novel rules against human performance.-Among the models examined, only the SCL model replicates the human difficulty pattern across relation types (Fig.~\ref{fig:Fig2_perf_per_rule}D). To more rigorously test this alignment, we conducted additional human studies using the \textit{SimplifiedRPM} task, which allows a direct comparison of abstract relation generalization between humans and models.

To encompass a range of task difficulties, we sampled $130$ trials of the \textit{SimplifiedRPM} task, spanning $13$ relational rule pairs with $10$ questions per pair. We recruited $n=25$ MTurk participants, each of whom answered $60$ randomly selected questions from this pool to minimize sequential learning effects. Participants had unlimited time to respond and were compensated based on accuracy. For each trial, we recorded both accuracy and response time (see Methods for details). Human participants exhibited a mean task error of $0.270\pm0.038$ (mean$\pm$s.e.m.), significantly lower than the chance level of $0.5$ (one-sample t-test, $t(12)=-5.70$, $p = 4.9 \times 10^{-5}$). The detailed $13$ rule pairs included in the human experiment and their corresponding human performance are in table~\ref{tab:human_error}.

We evaluated the generalization errors of the SCL model on the same \textit{SimplifiedRPM} trials used in human experiments. Specifically, we trained ten SCL models for each of the thirteen rule pairs, each using a different split of the forty rules in the dataset while ensuring that the target rule pair was always among the five held-out rules. We then measured the generalization error on the held-out pair using the same trials as those used in the human evaluation. The model achieved an average task error of $0.268\pm0.043$ (mean$\pm$s.e.m.), close to the human performance. Across the thirteen rule pairs, SCL models exhibited error patterns that correlated with those observed in human participants (Spearman’s rank correlation, $\rho=0.62$, $p=0.02$) (Fig.~\ref{fig:Fig2_perf_per_rule}E). 

Besides task errors, human response times—the total duration participants spent on each trial—were also strongly correlated with SCL generalization error across the thirteen rule pairs (Spearman’s rank correlation, $\rho=0.90$, $p=1.8\times10^{-5}$) (Fig.~\ref{fig:Fig2_perf_per_rule}F). This finding suggests that participants allocated more time to solving trials that the model found more challenging. In summary, although trained solely to classify relational rules without explicit human-like guidance, the SCL model successfully captures the human order of difficulty. In contrast, other models deviate from human performance patterns (figure~\ref{fig:SuppFig2_human_model}). This alignment of SCL with human performance motivates further exploration of the mechanisms underlying how neural networks perform relational reasoning. 

\subsection*{Geometric Theory of Rule Manifolds Accurately Predicts Error in the \textit{SimplifiedRPM} Task}
To investigate how neural networks achieve relational reasoning and generalize their learned representations to unseen relational rules, we leveraged a geometrical theory of few-shot learning \cite{sorscher2022neural}. This theory provides a framework for linking errors in the Simplified RPM task to interpretable geometric properties of the relational representations.

We define \textit{rule manifolds} as the set of relational representations for rows that follow a specific rule (Fig.~\ref{fig:Fig3_geometry_theory}A). For a rule pair $(a,b)$, we consider the average generalization error $\varepsilon_{a}$ on the \textit{SimplifiedRPM} task across all trials where the sample and correct choice rows follow rule $a$, while the incorrect choice row follows rule $b$. Geometrically, $\varepsilon_{a}$ corresponds to the probability that a correct choice sampled from the rule a manifold is closer to an incorrect choice from the rule b manifold than to another correct choice from the rule a manifold.

Each rule manifold is defined by its centroid $\mathbf{x}_{0}$ (depicted as blue and green stars in Fig.~\ref{fig:Fig3_geometry_theory}A), which represents the mean position of all representations that follow a given rule. The spread of representations within a manifold is captured by a set of principal axes $\mathbf{u}_{i}$ (illustrated as blue and green dashed arrows in Fig.~\ref{fig:Fig3_geometry_theory}A), along which the variation is quantified by corresponding radii $R_i$. Here, $i=1,..., N$, where $N$ denotes the total dimensionality of the relational representation space. The overall magnitude of this variation is measured by the mean squared radius given by: $R^{2}\equiv\frac{1}{N}\sum_{i=1}^{N}R_{i}^{2}$. 

Although the rule manifolds may have complex shapes, the geometrical theory predicts that generalization error can be accurately estimated using only a few key geometric properties. Specifically, the generalization error, $\varepsilon_{a}$, for a given rule pair ($a$,$b$) is governed by the signal-to-noise ratio $\text{SNR}_{a}$, following: $\varepsilon_{a}=H\left(\text{SNR}_{a}\right)$. Here, $H\left(\cdot\right)$ is the Gaussian tail function defined as $H\left(x\right)=\intop_{x}^{\infty}dte^{-t^{2}/2}/\sqrt{2\pi}$. Higher $\text{SNR}_{a}$ values correspond to lower generalization errors. The dominant terms of $\text{SNR}_{a}$ are given by: 

\begin{equation}	                           
        \text{SNR}_{a}=\frac{\parallel\Delta\mathbf{x}_{0}\parallel^{2}+R_{b}^{2}R_{a}^{2}-1}{\sqrt{D_{a}^{-1}+\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{a}\parallel^{2}+\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{a}\parallel^{2}}}
	\label{eq:SNR} % Use a logical label
\end{equation}

The $\text{SNR}_{a}$ depends on four key interpretable geometric terms. The first is the \textit{signal}: \linebreak${\parallel\Delta\mathbf{x}_{0}\parallel^{2}=\parallel\mathbf{x}_{0}^{a}-\mathbf{x}_{0}^{b}\parallel^{2}/R_{a}^{2}}$, which measures the squared Euclidean distance between the centroids $(\mathbf{x}_{0}^{a}, \mathbf{x}_{0}^{b})$ of the two rule manifolds (depicted as purple line in Fig.~\ref{fig:Fig3_geometry_theory}A), normalized by the mean squared radius $R_{a}^{2}$ of rule $a$. A larger signal indicates greater separation between the rule $a$ and rule $b$ manifold centroids, leading to higher $\text{SNR}_{a}$ and lower generalization error. We denote $\Delta\mathbf{x}_{0}$ as the signal direction. The second term is the \textit{bias}, $R_{b}^{2}R_{a}^{-2}-1$, which captures the relative difference in the sizes of two rule manifolds. When rule manifold $a$ is larger than manifold $b$, the bias term is negative, predicting a lower $\text{SNR}_{a}$ for rule a. The third term, $D_{a}^{-1}$, represents the inverse of the dimensionality $D_a$ of the rule $a$ manifold. $D_a$, known as the ''Participation ratio''~\cite{gao2017theory}, is defined as $D_{a}\equiv\left(R_{a}^{2}\right)^{2}/\sum_{i=1}^{N}\left(R_{i}^{a}\right)^{4}$. $D_a$ quantifies the number of dimensions along which the manifold varies significantly. Higher-dimensional manifolds are preferred for minimizing generalization errors. The last term, \textit{signal-noise overlap}, is given by $\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{a}\parallel^{2}$ and $\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{b}\parallel^{2}$. Here, $\mathbf{U}_{a}\equiv\left[\mathbf{u}_{1}^{a}R_{1}^{a},...,\mathbf{u}_{N}^{a}R_{N}^{a}\right]$ and $\mathbf{U}_{b}\equiv\left[\mathbf{u}_{1}^{b}R_{1}^{b},...,\mathbf{u}_{N}^{b}R_{N}^{b}\right]$ are matrices of the manifold axes of variation. The signal-noise overlap quantifies the alignment between these axes of variation $(\mathbf{U}_{a}, \mathbf{U}_{b})$ and the signal direction $\Delta\mathbf{x}_{0}$. Smaller overlaps result in lower generalization errors. 

We estimate the SNR for each model by first extracting the relational representations of rows associated with each held-out rule, thereby forming the rule manifolds. We then computed the geometric properties of these manifolds and calculated the SNR for each held-out rule pair using Equation~\ref{eq:SNR}. Fig.~\ref{fig:Fig3_geometry_theory}B-E presents the computed SNR along with the empirically measured generalization error on the \textit{SimplifiedRPM} task, highlighting close alignments between theoretical predictions (red lines) and empirical results (individual points) across all four models. This alignment validates the geometrical theory as a principled framework for understanding abstract relation generalization through representation geometry.

The geometrical theory identifies three independent mechanisms that facilitate generalization: increasing signal, expanding dimensionality (D), and reducing signal-noise overlap. These mechanisms provide a structured framework for analyzing differences in generalization performance across models. Fig.~\ref{fig:Fig3_geometry_theory}F-I illustrates the geometry of held-out rule representations before (gray bars) and after (colored bars) training, highlighting key differences between models.

Across all models, training increases the SNR for held-out rules (Fig.~\ref{fig:Fig3_geometry_theory}F). When analyzing individual mechanisms, we observe that all models show an increase in signal, with SCL exhibiting a particularly pronounced rise (Fig.~\ref{fig:Fig3_geometry_theory}G). Model-specific differences emerge in dimensionality: ResNet, WReN, and ViT increase D, whereas SCL exhibits a decrease (Fig.~\ref{fig:Fig3_geometry_theory}H). For signal-noise overlap, we normalize the overlap by signal magnitude: $\frac{\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{a}\parallel^{2}+\parallel\Delta\mathbf{x}_{0}\cdot\mathbf{U}_{b}\parallel^{2}}{\parallel\Delta\mathbf{x}_{0}\parallel^{2}}$. This normalization allows us to distinguish whether a high signal-noise overlap is due to a large signal magnitude or a genuine alignment between the manifold and the signal direction. We observed that ResNet, WReN, and ViT reduce overlap, whereas SCL shows an increase (Fig.~\ref{fig:Fig3_geometry_theory}I). In summary, ResNet, WReN, and ViT leverage all three mechanisms—enhancing signal strength, expanding D, and reducing overlap—to improve generalization. In contrast, SCL primarily relies on increasing signal strength but does so at the cost of reduced dimensionality and increased overlap. 

Previously, we observed that different abstract relations—progression, arithmetic, and logical—exhibited varying levels of generalization error across models (Fig.~\ref{fig:Fig2_perf_per_rule}A-D). To understand these differences, we examined the role of signal, dimensionality, and overlap in shaping generalization performance. 

Across all models, signal strength emerged as the primary driver of generalization performance, with higher signal correlating with lower generalization error. In the SCL model, we observed a human-like generalization pattern where progression rules had significantly lower generalization errors than arithmetic and logical rules (Fig.~\ref{fig:Fig2_perf_per_rule}D). This was explained by progression rules exhibiting the highest signal (Fig.~\ref{fig:Fig4_geometry_per_rule}D). A similar pattern was observed in other models, each exhibiting distinct generalization error trends. In ResNet, arithmetic rules' errors were higher than logical rules due to lower signal (Fig.~\ref{fig:Fig4_geometry_per_rule}A). In WReN, arithmetic rules had the highest error, driven by the lowest signal (Fig.~\ref{fig:Fig4_geometry_per_rule}B). In ViT, progression rules had the lowest error, reflecting their highest signal (Fig.~\ref{fig:Fig4_geometry_per_rule}C).

Beyond signal, dimensionality (D) did not consistently correlate with generalization performance (Fig.~\ref{fig:Fig4_geometry_per_rule}E-H). In ResNet and ViT, progression rules had the lowest D despite their low errors, suggesting that D alone does not determine generalization ability. Signal-noise overlap also showed no significant difference across abstract relations (figure~\ref{fig:SuppFig3_overlap}).

\subsection*{Layer-wise Geometric Analysis Reveals Model-Specific Generalization Strategies}
We observed that models exhibit distinct geometries in their relational representations. A key question is how these geometries emerge: Do they form abruptly at specific layers or gradually across the network? To address these questions, we examined the evolution of representational geometry across layers, aiming to pinpoint where abstract relations are extracted and how architecture shapes representation.

Fig.~\ref{fig:Fig5_layer_geometry}A-D shows each model's generalization error across layers. At the input stage, rows exhibit a generalization error of $0.475\pm0.002$, close to the $0.5$ chance level. This suggests the rules are not yet separated at the row pixel level. Across all four models, generalization errors decrease along the layers, demonstrating progressive refinement of relational representations. Fig.~\ref{fig:Fig5_layer_geometry}E-H shows generalization SNR across layers, highlighting distinct relational development patterns across architectures. ResNet-50 and ViT exhibit a gradual increase in SNR, reflecting a steady accumulation of relational information (Fig.~\ref{fig:Fig5_layer_geometry}E,G). In contrast, WReN plateaus early at the pairwise aggregation layer, with later MLP layers failing to improve further generalization SNR (Fig.~\ref{fig:Fig5_layer_geometry}F). In the SCL model—which achieved the best generalization performance—we observed a sharp increase in generalization SNR at the first MLP layer (Fig.~\ref{fig:Fig5_layer_geometry}H). 

To gain deeper insights into how relational rule separability evolves across network layers, we decompose SNR into the dynamics of its geometric terms at each layer. While signal generally increases across layers, its layerwise trend does not always follow that of SNR. While SNR steadily rises in ResNet, the signal remains relatively stable until a sharp increase in the final average pooling layer (Fig.~\ref{fig:Fig5_layer_geometry}I). In WReN, the signal plateaus at the pairwise aggregation layer and even decreases in the final MLP layer (Fig.~\ref{fig:Fig5_layer_geometry}J). In ViT, the signal progressively increases across layers (Fig.~\ref{fig:Fig5_layer_geometry}K). In SCL, the signal only begins to rise sharply in the first MLP layer, whereas SNR increases earlier in the last convolutional layer. Furthermore, while the signal rises in the second MLP layer, SNR unexpectedly decreases (Fig.~\ref{fig:Fig5_layer_geometry}L).  

The observed misalignment suggests that signal amplification alone is not sufficient to explain rule separation across layers. To further investigate, we examine the evolution of dimensionality (D) (Fig.~\ref{fig:Fig5_layer_geometry}M-P). Interestingly, unlike the signal, D exhibits a non-monotonic trajectory across layers. ResNet-50 initially expands D in early layers before compressing in later layers (Fig.~\ref{fig:Fig5_layer_geometry}M). WReN follows a different pattern, initially compressing D through pairwise aggregation and early MLP layers before expanding it in later MLP layers (Fig.~\ref{fig:Fig5_layer_geometry}N). ViT maintains a consistently low D throughout, with only a slight increase in the final attention block (Fig.~\ref{fig:Fig5_layer_geometry}O). SCL increases D through convolutional layers but then sharply compresses it in MLP layers (Fig.~\ref{fig:Fig5_layer_geometry}P). These variations in D help explain the gaps observed between signal and SNR evolution through layers. In ResNet-50,  the initial expansion of D accounts for the early rise in SNR, which occurs before the signal increases. In SCL, the sharp compression of D in the last MLP layer explains why SNR does not increase alongside the signal. 

Across different models, our findings on layerwise geometry suggest that relational abstraction is not a uniform process; each model employs a distinct strategy. The SCL model achieves the best generalization performance by maximizing signal amplification, especially in MLP1, outperforming all other models. In contrast, ResNet-50 and ViT progressively refine relational representations, whereas WReN reaches an early plateau, indicating a bottleneck in relational generalization. While the previous section showed weaker correlations between D and rule separation across abstract relation types, the layerwise analysis reveals a more dynamic interaction. Specifically, D plays a crucial role in shaping relational representations across model layers by refining the effectiveness of signal amplification in driving their emergence.

\subsection*{Structured Compression Drives the Trade-off Between Generalization Signal and Dimensionality}
The geometrical theory suggests that high signal and dimensionality (D) benefit generalization. However, we observed that in model layers where significant signal increases occur, D tends to decrease (e.g., Fig.~\ref{fig:Fig5_layer_geometry}I, M for ResNet-50; Fig.~\ref{fig:Fig5_layer_geometry}L, P for SCL). This relationship between the generalization signal and D occurs not only across model layers but also throughout training. In all four models, signal and D exhibit a consistent anti-correlation, with signal increases accompanied by decreases in D (Fig.~\ref{fig:Fig6_signalD_tradeoff}A-D). Intuitively, signal and D are two independent geometric properties. For example, the centroids of two rule manifolds can remain fixed, preserving the signal, while their shapes evolve, changing D. This raises a key question: Why does this trade-off between the generalization signal and D consistently emerge?

We propose that the trade-off between the generalization signal and D arises from a structured compression effect. All class manifolds—including those for held-out rules—gradually align with a low-dimensional subspace defined by the principal components of the training rules. Across models, the representations of the 35 training rules consistently occupy a low-dimensional space. Notably, we observe a drop in variance explained by the top principal components (PCs) at exactly $35$, matching the number of training rules (figure~\ref{fig:SuppFig4_test_PC_sig}). We hypothesize that the network amplifies the generalization signal by aligning all representations, including those of held-out classes, within this low-dimensional space. 

To test this hypothesis, we measured the fraction of variance explained by the top $35$ principal components (PCs) of the training rules for each held-out rule manifold. Higher values indicate more substantial alignment with the low-dimensional subspace of training rules. We observed that as the network signal increases, this alignment becomes more pronounced across models (Fig.~\ref{fig:Fig6_signalD_tradeoff}E-H).

Our findings suggest that the observed signal-D trade-off is not incidental but a consequence of structured compression. As networks enhance the generalization signal, they constrain representations into a low-dimensional subspace, prioritizing inter-class signal at the expense of dimensionality. This effect is a general mechanism across different architectures.

\subsection*{Theory-Grounded SNR Loss Yields Geometry-Balanced Representations}
Can the geometry predicted by the theory directly guide neural network training? We hypothesize that enforcing this geometry provides a principled approach to learning relational representations. To test this hypothesis, we introduce the SNR loss—an SNR-based objective function that explicitly enforces the predicted geometry.  

Specifically, the SNR loss maximizes the SNR for the training rule pairs, reinforcing the optimal representation geometry. We sample $P$ rows from $m$ relational rules for each input batch and process them through the model to obtain high-dimensional relational representations. The SNR loss is then formulated as: 
\begin{equation}
	l_{SNR}=\sum_{(a,b)}\exp\left(-SNR_{a}\right)
	\label{eq:SNR_loss} % Use a logical label
\end{equation}
Here, $SNR_{a}$ represents the estimated SNR (~Equation~\ref{eq:SNR}) for the ordered rule pair $(a,b)$, averaged across all possible rule pairs in the batch. 

To assess the effectiveness of the proposed SNR loss, we trained the top-performing SCL model using this objective and evaluated its generalization across the same $15$ rule splits previously used for training with cross-entropy loss. The model effectively optimized the training rule representations, achieving an average SNR of $9.66\pm0.22$ (mean$\pm$s.e.m.) across training rule pairs, as evaluated on novel test rows of the training rules. More importantly, the model effectively separated held-out rules, yielding an averaged generalization error of $0.162\pm0.018$ (mean$\pm$s.e.m.) (Fig.~\ref{fig:Fig7_SNRloss}A). This performance was statistically indistinguishable from models trained with cross-entropy (CE) loss using one-hot rule labels (Wilcoxon signed-rank test: statistic = $48.0$, $p=0.26$, n.s.), confirming that SNR loss achieves competitive generalization while structuring learned representations according to theoretical predictions.

To further evaluate the efficacy of SNR loss, we compared its performance against Prototypical loss, a widely used loss function designed to learn structured representations that generalize to unseen classes \cite{snell2017prototypical}. Prototypical loss operates by embedding inputs into a high-dimensional representation space and forming class prototypes, defined as the centroids of the representations corresponding to each class. The loss function then encourages representations of samples from the same class to cluster around their respective prototypes. Additional details on Prototypical loss are provided in the Supplementary Text. We trained the SCL model using Prototypical loss on the same $15$ rule splits. The resulting model exhibited a generalization error of $0.227\pm0.010$, significantly higher than that obtained with SNR loss (Fig.~\ref{fig:Fig7_SNRloss}A). These findings suggest that while both loss functions promote structured representations, SNR loss is more effective in shaping a geometric representation that enhances generalization.

Notably, the generalization errors of models trained with both SNR loss and Proto loss, similar to our previous observations with cross-entropy loss (Fig.~\ref{fig:Fig3_geometry_theory}E), are also accurately predicted by the geometrical theory (Fig.~\ref{fig:Fig7_SNRloss}B,C). Compared to cross-entropy (CE) and Prototypical loss, SNR loss is uniquely grounded in geometric theory, explicitly accounting for key representation geometries, including signal strength, dimensionality, and signal-noise overlap. This theoretical foundation raises the question of whether SNR loss yields a more advantageous representational geometry relative to other loss functions. To investigate this, we analyzed the representation geometries induced by different loss functions. Our findings show that representations learned with SNR loss have higher dimensionality than those trained with CE loss (Fig.~\ref{fig:Fig7_SNRloss}E), addressing the low-dimensionality issue in CE training while maintaining relatively high signal strength (Fig.~\ref{fig:Fig7_SNRloss}D). Furthermore, SNR loss reduces signal-noise overlap, which is beneficial for generalization (Fig.~\ref{fig:Fig7_SNRloss}F). Although Prototypical loss also encourages high-dimensional representations, it results in the lowest signal, contributing to its worst generalization performance (Fig.~\ref{fig:Fig7_SNRloss}D, E). These findings highlight that SNR loss shapes the representations of held-out rules in a way that explicitly adheres to geometric principles.

\subsection*{Discussion}
We address the fundamental question of how neural networks discover unseen rules when learning abstract relational rules. We hypothesize that networks trained to perform reasoning tasks generate good representations even for unseen rules. The utility of these representations can be quantified by the geometry of the \textit{rule manifolds} defined by all representations associated with a given rule. Extending the geometric theory of object manifold~\cite{sorscher2022neural} to abstract rules, we predicted an explicit relation between the generalization performance in visual reasoning and key geometric properties: manifold radii, dimensionality, the distance between manifold centroids, and the overlap between these distances and their subspaces of variation. 

To test whether the geometric theory developed for object recognition can be applied to visual reasoning tasks, we introduce \textit{SimplifiedRPM}, a subset of Raven’s Progressive Matrices (RPM), whose simpler design allows a systematic study of generalization ability in visual reasoning and direct comparison with the above theory. Using this dataset, we trained state-of-the-art deep network architectures (ResNet~\cite{he2016deep}, WReN~\cite{barrett2018measuring}, ViT~\cite{dosovitskiy2020image}, SCL~\cite{wu2020scattering}). We demonstrated the superiority of the SCL (Scatter Compositional Learner) architecture, consistent with previous reports~\cite{malkinski2022deep}. We then conducted an in-depth comparison between the performance of the SCL network and human participants on the same task. Surprisingly, we found excellent agreement between human and network performance, both in terms of overall performance but also across different abstract rules. 

Leveraging on a geometrical theory of manifolds initially applied to object recognition tasks~\cite{sorscher2022neural}, we show that interpretable representation geometries can explain models’ performance. Further analysis reveals how different architectures balance signal and dimensionality to achieve relational reasoning while identifying bottlenecks limiting their performance. Building on these insights, we propose SNRloss, a theoretically grounded objective function that explicitly optimizes representation geometry. This novel loss function provides adequate training and generalization capabilities. Our work establishes a geometrically informed framework for analyzing neural networks’ capacity to recognize and generalize abstract relations.

A key insight from our study is that neural networks do not generalize equally well across all abstract relations. While prior research has examined abstract relation generalization in neural networks \cite{barrett2018measuring}, our work offers a more fine-grained empirical evaluation. Notably, the top-performing model, SCL, aligns closely with human difficulty rankings, with logical rules being the hardest. In contrast, the other three models struggle to generalize arithmetic rules despite achieving high test accuracy. Furthermore, we find that signal, rather than dimensionality or signal-noise overlap, is the primary factor governing these generalization differences among abstract relations. These insights suggest that future models could benefit from strengthening signals for specific relational types.

The best-performing model, SCL, shows a sharp improvement in relational separability only in the last two MLP layers of the network. The earlier layers exhibit only minor gains despite the network being trained end-to-end. This observation suggests that high-level relational abstractions do not gradually build up over the model’s layers but instead emerge abruptly during the final transformations. Geometrically, the signal rises even later in the last MLP layer, while the dimensionality shows a non-monotonic trend—first expanding and then decreasing. The same geometric trend was previously observed in vision models, including ResNet-50, VGG19, and ResNet-152, trained on the ImageNet object classification task \cite{sorscher2022neural}. The consistency of these geometric trends across models trained on relational reasoning and object classification tasks suggests that they are not merely artifacts of specific architectures or tasks but may reflect a general mechanism of hierarchical abstraction. In contrast, ViTs show a more gradual refinement of relational separation and a steady signal increase across network layers. This indicates that attention mechanisms may support relational learning differently than convolution-based architectures such as SCL and ResNet.

According to the geometrical theory, higher dimensionality should be favorable for generalization. On the other hand, prior studies suggest that low-dimensional manifolds offer advantages for object recognition, enabling the classification of a greater number of objects \cite{cohen2020separability, chung2018classification}. This contrast implies that dimensionality should not be universally maximized or minimized but instead tuned to task demands. Our findings extend this idea by showing that generalization depends not only on dimensionality but mostly on its interaction with pairwise manifold signals. Specifically, we demonstrate that deep networks systematically compress representations into structured, low-dimensional spaces—even for unseen rules. Moreover, this phenomenon is consistently observed across diverse architectures (e.g., ResNet, SCL), indicating that it is a fundamental learning property rather than an artifact of any specific architecture. We observe that late layers play a crucial role in compressing relational representations, a phenomenon consistent with prior work showing that deep networks tend to refine and condense information in later stages of learning~\cite{shwartz2017opening}. These findings open new avenues to explicitly leverage this signal versus dimensionality trade-off to improve generalization.

Among the tested models, SCL best replicates the human-like difficulty ordering across rules. While prior research has relied on explicit relational priors to achieve human alignment \cite{little2012bayesian}, our results demonstrate that SCL, when trained end-to-end on the task, exhibits human-like performance without requiring such priors. Furthermore, SCL's generalization errors closely correlate with human response times. This raises a key question: What insights does SCL offer for understanding the brain’s relational reasoning mechanisms? The SCL network parallels the brain's hierarchy: its CNN-based feature extractor mimics the ventral visual cortex, capturing basic features like shape and color \cite{freedman2003comparison, yamane2006representation,kreiman2021, nayebi2024neural}, while its later reasoning module reflects higher cortical areas supporting relational reasoning \cite{davis2017concrete, chafee2007representing, summerfield2020structure, nelli2023neural}. We propose that the brain encodes rules of input rows through distinct, rule-specific neural manifolds. Our observation of layer-wise changes in the geometry of these rule manifolds offers hypotheses into how neural representations evolve across brain regions~\cite{mcintosh2016deep, genkin2023dynamics}. According to the SCL model, early visual areas exhibit high representational dimensionality (D) but low signal, whereas later regions show larger signals with reduced dimensionality. These predictions can be empirically tested by measuring neural activity during abstract reasoning tasks~\cite{engel2011same, courellis2024abstract, krawczyk2012cognition, langdon2023unifying}. 

This study aimed to study the generalization of abstract relations. While the humans in our experiment were not explicitly trained on the rules, their reasoning abilities could be considered "pre-trained" through life experiences, as they may have previously encountered similar rules. In contrast, neural networks were trained under strictly controlled rule splits, ensuring they had no prior exposure to the rules evaluated for generalization. To address this discrepancy, a crucial next step is to develop a new benchmark for human reasoning that incorporates abstract relations unlikely to have been encountered. Such a benchmark would disentangle relational generalization from prior experience, providing a clearer view of their distinct roles in human abstract reasoning. This approach enables a direct comparison between humans and neural networks, offering deeper insights into their generalization mechanisms.

In summary, our findings not only advance our understanding of relational reasoning in neural networks but also provide testable hypotheses on how geometric principles may underlie abstract reasoning in the brain. Looking forward, our approach opens exciting opportunities for extending geometric analysis to a broader range of cognitive tasks, including real-world visual reasoning benchmarks and cross-modal linguistic challenges. 

% If your text is very short you might need to uncomment the following line to avoid
% layout problems with the figures and tables.
%\newpage


%%%%%%%%%%%%%%%% MAIN TEXT FIGURES %%%%%%%%%%%%%%%

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=0.8\textwidth]{Fig1_RPMtask_and_perf} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{The \textit{SimplifiedRPM} dataset helps evaluate neural networks in relational reasoning and generalization.}
	(\textbf{A}) Example \textit{SimplifiedRPM} trial with ``constant shape`` rule. Choice 1 is correct; Choice 2 follows ``constant number'' and is incorrect.
        (\textbf{B}) We evaluate four representative models on the \textit{SimplifiedRPM} task: ResNet-50 (orange)~\cite{he2016deep}, WReN (green)~\cite{barrett2018measuring}, ViT (purple)~\cite{dosovitskiy2020image}, and SCL (yellow-green)~\cite{wu2020scattering}. Each model encodes relational rules in rows using high-dimensional relational representations (red) and is trained end-to-end. A linear classifier is appended during training to categorize relational rules. See Methods for details.
        (\textbf{C}) Test errors for four models across 15 random splits of training and held-out rules, with error bars denoting s.e.m. All models perform significantly above chance ($0.97$) based on a one-sample t-test: ResNet ($t(14)=-312.77$, $p=1.2\times10^{-28}$), WReN ($t(14)=-343.78$, $p=3.4\times10^{-29}$), ViT ($t(14)=-388.11$, $p=6.2\times10^{-30}$) and SCL ($t(14)=-542.53$, $p=5.7\times10^{-32}$). Pairwise Wilcoxon tests confirm SCL achieves the lowest test error, followed by ViT, WReN, and ResNet ($p$-values: SCL vs. ViT, $3.0\times10^{-5}$; ViT vs. WReN, $1.6\times10^{-3}$; WReN vs. ResNet, $3.0\times10^{-5}$). 
        (\textbf{D}) Schematic illustrating distances (red arrows) between sample and choice row relational representations. The trial is solved correctly if the correct choice row representation is closer to the sample row than the incorrect choice.
        (\textbf{E}) Generalization error of four models on \textit{SimplifiedRPM}, averaged over $15$ random training and held-out rule splits. Error bars denote s.e.m. All models perform significantly above chance ($0.5$) based on a one-sample t-test: ResNet ($t(14)=-8.93$, $p=1.8\times10^{-7}$), WReN ($t(14)=-26.39$, $p=1.2\times10^{-13}$), ViT ($t(14)=-33.45$, $p=4.6\times10^{-15}$), and SCL ($t(14)=-19.35$, $p=8.3\times10^{-12}$). Pairwise Wilcoxon tests confirm SCL achieves the lowest error, followed by ViT, while WReN and ResNet show similarly high errors ($p$-values: SCL vs. ViT, $6.1\times10^{-5}$; ViT vs. WReN, $3.0\times10^{-5}$). Asterisks indicate statistical significance: ** ($p < 0.01$), *** ($p < 0.001$).}
	\label{fig:Fig1_RPMtask_and_perf} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig2_perf_per_rule} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{SCL Captures Human-like Differential Relational Rule Difficulties.}
	(\textbf{A-D}) Generalization errors of four models on the \textit{SimplifiedRPM} task, evaluated across three abstract relation types: Progression (blue), Arithmetic (green), and Logical (red). The chance level is 0.5. Each bar represents the average error for trials where the correct rule of the sample row fell into one of these relation types, with error bars denoting s.e.m.
        (\textbf{A}) ResNet exhibited significantly higher errors for arithmetic rules than logical rules (p = 0.019, Pairwise Wilcoxon test).
        (\textbf{B}) WReN showed significantly higher errors for arithmetic rules than both progression ($p=4.2 \times 10^{-6}$) and logical ($p=9.1 \times 10^{-5}$) rules.
        (\textbf{C}) ViT exhibited higher errors for arithmetic rules compared to both progression ($p=3.8 \times 10^{-17}$) and logical ($p=7.7 \times 10^{-7}$) rules. Additionally, logical rules had significantly higher errors than progression ($p=2.0 \times 10^{-12}$).
        (\textbf{D}) SCL progression was lower than arithmetic ($p=2.1 \times 10^{-17}$) and logical ($p=3.2 \times 10^{-8}$). Statistical significance was assessed using Pairwise Wilcoxon tests. Asterisks indicate statistical significance: * ($p < 0.01$), *** ($p < 0.001$).
        (\textbf{E}) Comparison of the SCL model's generalization errors against human performance on the \textit{SimplifiedRPM} task across 13 selected rule pairs (chance level = 0.5). Each dot represents the average model (x-axis) or human (y-axis) error over 10 questions for a given rule pair, with error bars indicating the s.e.m. The dashed line represents the line of identity.
        (\textbf{F}) Correlation between the SCL model's generalization error (x-axis) and human response times (y-axis) for the 13 selected rule pairs. Each dot represents the average model error and corresponding human response time for a given rule pair, with error bars indicating the s.e.m. }
	\label{fig:Fig2_perf_per_rule} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig3_geometry_theory} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{Geometric Theory of Rule Manifolds Accurately Predicts Error in the \textit{SimplifiedRPM} Tasks.}
	(\textbf{A}) Illustration of rule manifolds in the relational representation space. Orange axes denote representation dimensions. Each rule manifold consists of relational representations for rows that follow a specific rule. Two rule manifolds are shown: blue (rule a) and green (rule b) ellipsoids. The two black dots in rule a manifold represent example rows following rule A (e.g., constant shape). Each manifold is characterized by a centroid ($\mathbf{x}_{0}^{a}$ for rule a, blue star; $\mathbf{x}_{0}^{b}$ for rule b, green star), representing the mean position of all relational representations following that rule. Variation is characterized by principal axes ($\mathbf{u}_{i}^{a}$ for the blue rule manifold a and $\mathbf{u}_{i}^{b}$ for the green manifold b), shown as blue and green dashed arrows. Here, $i=1,.., N$, where $N$ is the relational representation dimension. The extent of variation along each axis is quantified by the corresponding radii $R_i^a$ and $R_i^b$. Purple line represents signal $\Delta\mathbf{x}_{0}$.  
    (\textbf{B-E}) Comparison of theoretical predictions (red lines) and empirical generalization errors (dots) across four models. Each dot represents a held-out rule pair, where the theoretical SNR predictions are computed using geometric measures (Equation~\ref{eq:SNR}), and the empirical generalization errors are averaged over 500 \textit{SimplifiedRPM} trials. Each plot includes rule pairs from 15 distinct held-out rule splits. Each split consists of five held-out rules, resulting in 20 rule pairs per split.
    (\textbf{F-I}) Generalization SNR, signal, D, and signal-noise overlap (normalized by signal magnitude) for model relational representations on the held-out rules. The gray bars represent the untrained models' representation at initialization, while the colored bars correspond to different models: orange for ResNet, green for WReN, purple for ViT, and yellow-green for SCL. Each bar shows the mean value averaged across 15 distinct held-out rule splits, with error bars indicating the s.e.m. Pairwise Wilcoxon tests assess whether the trained model terms differ from the untrained models. Asterisks indicate statistical significance: * ($p < 0.01$), *** ($p < 0.001$).}
	\label{fig:Fig3_geometry_theory} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig4_geometry_per_rule} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{Generalization error differences across abstract relation types were primarily influenced by signal rather than dimensionality.}
		(\textbf{A-D}) Generalization signal and (\textbf{E-H}) dimensionality for different abstract relation types—progression, arithmetic, and logical—across four models. Results are averaged over 15 random splits of training and held-out rules. Each bar represents the average error for trials where the correct rule of the sample row belonged to each relation type, with error bars indicating the s.e.m. Statistical comparisons were conducted using the pairwise Wilcoxon test.}
	\label{fig:Fig4_geometry_per_rule} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig5_layer_geometry} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{Layer-wise Geometric Analysis Reveals Model-Specific Generalization Strategies.}
	(\textbf{A-D}) Generalization error across layers for each model. The plotted values represent 15 distinct held-out rule splits, each containing five held-out rules, leading to 20 rule pairs per split. Error bars denote the s.e.m. across the 15 splits. Representations at each layer are randomly projected to a fixed dimensionality of $N=400$ before computing errors and performing geometric analysis. Generalization errors for each rule pair are evaluated using 500 \textit{SimplifiedRPM} trials.
        (\textbf{E-H}) Generalization signal-to-noise ratio (SNR) across layers.
        (\textbf{I-L}) Generalization signals across layers.
        (\textbf{M-P}) Generalization dimensionality (D) across layers.}
	\label{fig:Fig5_layer_geometry} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig6_signalD_tradeoff} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{Structured Compression Drives the Trade-off Between Generalization Signal and Dimensionality.}
    (\textbf{A-D}) Generalization signal vs. dimensionality (D) across training epochs for all models. Each point shows average signal and D over 15 held-out splits (five rules per split). Dot size and color indicate training epoch; later epochs are larger, brighter. Spearman’s rank correlation between the generalization signal and D reveals a strong negative correlation across the 15 rule splits for each model (ResNet: \( \rho = -0.12\pm0.12 \); WReN: \( \rho = -0.41 \pm 0.11 \); ViT: \( \rho = -0.37 \pm 0.19 \); SCL: \( \rho = -0.77 \pm 0.05 \); mean \( \pm \) s.e.m.).  This effect was statistically significant, as confirmed by Stouffer’s test (ResNet: $Z = 3.41$, $p = 3.2 \times 10^{-4}$; WReN: $Z = 2.38$, $p = 8.5 \times 10^{-3}$; ViT: $Z = 14.76$, $p = 1.1 \times 10^{-49}$; SCL: $Z = 13.04$, $p = 3.5 \times 10^{-39}$). 
    (\textbf{E-H}) Alignment of held-out rule manifolds with the low-dimensional subspace of training rules across training epochs for all four models. Each point shows the variance explained by the top 35 principal components of training rule representations for a held-out rule manifold, averaged over 15 splits. The size and color of the dots indicate the training epoch, with later epochs depicted by larger, brighter dots. Spearman’s rank correlation between the generalization signal and subspace alignment shows a strong positive correlation across the 15 rule splits for each model (ResNet: \( \rho = 0.01 \pm 0.13 \); WReN: \( \rho = 0.29 \pm 0.11 \); ViT: \( \rho = 0.38 \pm 0.19 \); SCL: \( \rho = 0.90 \pm 0.04 \); mean \( \pm \) s.e.m.). This effect was statistically significant in all four models except WReN, as confirmed by Stouffer’s test (ResNet: $Z = 3.35$, $p = 3.9 \times 10^{-4}$; WReN: $Z = 0.37$, $p = 0.35$; ViT: $Z = 12.09$, $p = 6.0 \times 10^{-34}$; SCL: $Z = 19.54$, $p = 2.5 \times 10^{-85}$).We begin plotting from the training epoch, where the structured low-dimensional representation of the training rule first emerges, indicated by the stabilization of its relational representation’s dimensionality. The full trajectory of the generalization signal, D, and alignment is presented in figure~\ref{fig:SuppFig5_score_epoch}.}
	\label{fig:Fig6_signalD_tradeoff} % give each figure a logical label name
\end{figure}

\begin{figure} % Do NOT use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{Fig7_SNRloss} % for an image file named example_figure.*
	% Pick an appropriate width - in print, figures are usually one or two columns wide, which can
	% be approximated by 0.3\textwidth or 0.6\textwidth respectively. Use appropriate label sizes.

	% Captions go below figures
	\caption{\textbf{Theory-Grounded SNR Loss Yields Geometry-Balanced Representations.}
	(\textbf{A}) Generalization error for models trained with SNR loss, cross-entropy (CE) loss, and Prototypical (Proto) loss, averaged over 15 rule splits. Error bars denote s.e.m. Pairwise Wilcoxon tests confirm Prototypical achieves the highest error ($p$-values: SNR Loss vs. Proto Loss, $5.1 \times 10^{-3}$; CE vs. Proto Loss, $1.0 \times 10^{-3}$). 
        (\textbf{B,C}) Comparison of theoretical predictions (red lines) and empirical generalization errors (dots) for the SNR and Prototypical Loss. Each dot represents a held-out rule pair.
        (\textbf{D-F}) Generalization signal, dimensionality (D), and signal-noise overlap (normalized by signal magnitude) for models trained with SNR, CE, and Proto Loss. Each bar represents the mean value across 15 rule splits, with error bars indicating the s.e.m. Pairwise Wilcoxon tests assess the statistical significance of differences between loss functions. Asterisks indicate statistical significance: * ($p < 0.05$), ** ($p < 0.01$), *** ($p < 0.001$).}
	\label{fig:Fig7_SNRloss} % give each figure a logical label name
\end{figure}

%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%

\clearpage % Clear all remaining figures and tables then start a new page

% The list of references goes after the main text and before the acknowledgements
% When preparing an initial submission, we recommend you use BibTeX, like this:
%
\bibliography{visual_reasoning} % for a file named science_template.bib
\bibliographystyle{sciencemag}

% After the paper has completed peer review and been revised ready for acceptance,
% you should comment out the lines above and copy-paste the contents of your .bbl
% file here instead. This will help ensure that our conversion software works correctly.
% Remember to re-run BibTeX first - check the timestamp!
%
% Example of the first three entries copy-pasted from science_template.bbl:
%
%\begin{thebibliography}{1}
%
%\bibitem{example}
%A.~N. {Author}, An example reference. \emph{Journal of Improbable Research}
%  \textbf{1}, 67 (2020).
%
%\bibitem{example2}
%F.~M. {Surname}, S.~{Author}, A second example. \emph{Interesting Research
%  Letters} \textbf{32}, 897 (2019).
%
%\bibitem{example_preprint}
%P.~{One}, P.~{Two}, P.~{Three}, {An unpublished preprint}. \emph{preprint}
%  (2021), arXiv:2101.12345.
%
%\end{thebibliography}


%%%%%%%%%%%%%%%% ACKNOWLEDGEMENTS %%%%%%%%%%%%%%%

\section*{Acknowledgments}

\paragraph*{Funding:} \mbox{}\\
National Institutes of Health grant R01EY026025 (GK) \\
Swartz Foundation (HS) \\
Office of Naval Research grant No. N0014-23-1-2051 (HS) \\
Kempner Institute for the Study of Natural and Artificial Intelligence at Harvard University (HS)

\paragraph*{Author contributions:} \mbox{}\\
Conceptualization: JS, GK, HS \\
Methodology: JS, GK, HS \\
Investigation: JS, GK, HS \\
Visualization: JS \\
Supervision: GK, HS \\
Writing—original draft: JS \\
Writing—review \& editing: JS, GK, HS 


\paragraph*{Competing interests:}
There are no competing interests to declare.

\paragraph*{Data and materials availability:}
The code and dataset used in the study are publically available on Github: https://github.com/ShaneShang/SimplifiedRPM-Visual-Reasoning. 

%%%%%%%%%%%%%%%% SUPPLEMENT LIST %%%%%%%%%%%%%%%

% List the contents of your Supplementary Materials, including the numbers of any
% supplementary figures, tables, external data files etc. and any references that are
% cited only in the supplement. In this example, refs. 7-8 are cited only in the supplement.
% Fill out your numbers accordingly and delete any lines that aren't applicable.
\subsection*{Supplementary materials}
Materials and Methods\\
Supplementary Text\\
Figs. S1 to S8\\
Tables S1 to S2\\

%%%%%%%%%%%%%%%% END OF MAIN TEXT %%%%%%%%%%%%%%%

\newpage

%%%%%%%%%%%%%%%% START OF SUPPLEMENT %%%%%%%%%%%%%%%

% Figures, tables, equations and pages in the supplement are numbered S1, S2 etc.
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thepage}{S\arabic{page}}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{equation}{0}
\setcounter{page}{1} % not 0 as \newpage already started a supplementary page
% References continue the numbering from the main text.


%%%%%%%%%%%%%%%% SUPPLEMENT TITLE PAGE %%%%%%%%%%%%%%%

\begin{center}
\section*{Supplementary Materials for\\ \scititle}

% Author list for the supplement
% Indicate the corresponding authors, but do NOT include institutions here
% It would be nice if the template auto-generated this, but doing so is complicated...
Jiaqi~Shang,
Gabriel~Kreiman,
Haim~Sompolinsky$^\dagger$\\ % we're not in a \author{} environment this time, so use \\ for a new line
\small$^\ast$Corresponding author. Email: hsompolinsky@mcb.harvard.edu\\
\end{center}

% Fill out the numbers for each type of supplementary material,
% and delete any lines that aren't applicable.
% These are just example numbers that don't match the rest of this template.
\subsubsection*{This PDF file includes:}
Materials and Methods\\
Supplementary Text\\
Figures S1 to S8\\
Tables S1 to S2\\

\newpage

%%%%%%%%%%%%%%%% MATERIALS AND METHODS %%%%%%%%%%%%%%%

\subsection*{Materials and Methods}

\subsubsection*{\textit{SimplifiedRPM} Dataset}
The Raven’s Progressive Matrices (RPM) task~\cite{raven1936mental} is a widely used assessment of abstract relational reasoning, commonly applied in fields such as cognitive psychology and AI evaluation. Each RPM trial presents a 3×3 grid with the bottom-right panel missing. The subject must select the correct answer from eight options to complete the missing panel, ensuring that all three rows or columns in the matrix follow a consistent underlying relational rule.

Inspired by the RPM task, the \textit{SimplifiedRPM} dataset was specifically designed to assess a model’s ability to generalize abstract relations across different object attributes (Fig.~\ref{fig:Fig1_RPMtask_and_perf}). Each row in the dataset follows a unique relational rule that determines how an object’s attribute values change across three panels (figure~\ref{fig:SuppFig6_rule_table_example}A). The dataset consists of $40$ relational rules, each derived by applying an abstract relation to a specific object attribute. These abstract relations fall into three categories: progression (constant, progression $\pm2$, progression $\pm1$), arithmetic (addition, subtraction), and logical (AND, OR, XOR). A detailed description of the abstract relations is provided in Table~\ref{tab:simplifiedRPM_rules}.

Each rule was applied to one of four object attributes: shape, size, shade, or number/position (Fig.~\ref{fig:SuppFig6_rule_table_example}). Number and position were grouped as a single attribute to avoid ambiguity. For example, a "constant position" rule inherently fixes the object count, enforcing the constant number rule and conflicting with our requirement that each row in the task follows a unique relational rule. To ensure consistency with prior benchmarks, the dataset adopts the same object definitions and attribute specifications as the PGM dataset \cite{barrett2018measuring}. Shape is selected from seven geometric forms: circle, triangle, square, pentagon, hexagon, octagon, and star. The objects' sizes are represented by their bounding boxes in the panel, with heights ranging from $20$ to $40$ pixels in ten evenly spaced increments. Shade is represented as a grayscale intensity, ranging from $[230, 230, 230]$ (close to white) to $[0, 0, 0]$ (black) in RGB values, with $10$ evenly spaced increments. The number attribute specifies the number of objects per panel, ranging from $1$ to $9$. Position refers to the spatial arrangement of objects. Each panel has a total size of $[160, 160]$, and each object occupies a maximum bounding box of $[40, 40]$. There are nine possible object locations, each defined by its centroid coordinates: $\{(20,20),(20,60),(20,100),(60,20),(60,60),(60,100),(100,20),(100,60),(100,100)\}$. Consequently, each row has dimensions $3\times160\times160$. When presented, the three panels are arranged horizontally. 

Dataset generation followed a structured pipeline to ensure consistency and reproducibility. Each row was constructed to enforce a unique rule from our predefined set, eliminating ambiguity. To achieve this, we first sampled attribute values from valid options that conformed to the designated rule. Next, we randomly assigned values to the remaining attributes and resampled if a sampled value inadvertently conformed to an unintended rule. Once attribute values were finalized, they uniquely defined an input row. The corresponding row input was then generated by placing objects with the specified attributes in their designated positions. To maintain dataset balance, we generated 10,000 training rows, 1,000 validation rows, and 1,000 test rows per rule, yielding a total of 48,000 unique rows across all rules (40 rules $\times$ 1,200 samples). Example rows in the dataset are provided in figure~\ref{fig:SuppFig6_rule_table_example}B-D.

\subsubsection*{Neural Network Training}
To evaluate a model’s ability to generalize abstract relations to unseen object attributes, we implement a rule-splitting strategy in which a subset of rules is withheld during training. Specifically, we randomly select five rules to be held out, ensuring that each abstract relation appears at most once in this set. The remaining $35$ rules are used for model training. After training, the model is evaluated based on its ability to infer the held-out rules. Fig.~\ref{fig:SuppFig6_rule_table_example}A provides an example of this rule split, with held-out rules highlighted in yellow and training rules in blue.

During training, models are optimized using supervised learning with a cross-entropy loss function. The models are trained on 10,000 examples per rule across $35$ training rules. Test error (Fig.~\ref{fig:Fig1_RPMtask_and_perf}C) is assessed based on classification accuracy using $1,000$ test examples per rule. These test examples differ from the $10,000$ training examples used during model training.

After training, we evaluate the model’s ability to infer previously unseen, held-out rules. For each pair of the five held-out rules (20 possible rule pairs), we generate 500 \textit{SimplifiedRPM} trials. Each trial is constructed by randomly sampling two rows from the first rule—one as the sample row and the other as the correct choice. Then, we sample a row from the second rule as the incorrect choice. Finally, we ensure all 500 trials per rule pair are unique. 

To evaluate model performance, we compute the Euclidean distance between the sample row and each of the two choice rows. A trial is considered correct if the correct choice row is closer to the sample row than the incorrect one. The model’s generalization error is then quantified as the proportion of incorrect trials averaged across all $500$ trials for each of the $20$ rule pairs (Fig.~\ref{fig:Fig1_RPMtask_and_perf}E). 

We trained four architectures: ResNet-50, WReN, ViT, and SCL. ResNet-50~\cite{he2016deep} is a convolutional neural network with residual connections. We employed the standard ResNet-50 architecture without modification. WReN~\cite{barrett2018measuring} explicitly models pairwise relations between objects and has been previously used for RPM tasks. We optimized the hyperparameters of its relation module and fully connected layers. ViT~\cite{dosovitskiy2020image} is a transformer-based model that operates on image patches as input tokens and captures global dependencies via self-attention. We split each of the three panels in a row into a $3\times3$ grid, resulting in $27$ patches per row. We optimized key hyperparameters, including the number of layers, attention heads, and hidden dimensions. Finally, SCL~\cite{wu2020scattering} was specifically designed for the RPM task, and we used the original architecture without modifications. Detailed model configurations, including layer-wise specifications and hyperparameter tuning, are provided in Supplementary Text.

Training was conducted using stochastic gradient descent with a learning rate of $0.1$, momentum of $0.9$, and weight decay of $5 \times 10^{-4}$. To facilitate stable convergence, we applied a learning rate warmup for the first two epochs, followed by a plateau-based scheduler that reduced the learning rate by $0.2$ whenever the validation loss plateaued. Training continued until the classification errors across $1,000$ validation rows for each of the $35$ training rules stabilized. The final training durations for each model were: ResNet-50 ($100$ epochs), WReN ($60$ epochs), ViT ($200$ epochs), and SCL ($150$ epochs). All models were trained using a batch size of $512$. 

\subsubsection*{Human Experiment}
Twenty-five participants were recruited via Amazon Mechanical Turk (MTurk) to evaluate performance on the \textit{SimplifiedRPM} dataset. To ensure data reliability, we set strict eligibility criteria, requiring an approval rating above $95\%$ and restricting participation to Masters-qualified workers. All participants provided informed consent, and the study protocol was approved by the Institutional Review Board at Children’s Hospital, Harvard Medical School. Compensation was performance-based, with participants earning more for higher accuracy.

Before the main experiment, participants read written instructions describing the task and completed three practice trials that introduced relational rules different from the $13$ rule pairs used in the main experiment. Participants received feedback and explanations of the underlying rules during these practice trials. In the main experiment, each participant completed 60 trials randomly selected from a larger pool of $130$ trials ($10$ trials per rule pair), encompassing $13$ distinct rule pairs of varying relational complexity (Table~\ref{tab:human_error}). Participants were shown images like those in Fig.~\ref{fig:Fig1_RPMtask_and_perf}A. The images remained on the screen until the participants made a choice. Participants responded by clicking on one of two choice rows and were allowed unlimited time to provide their answers. No performance feedback was given during the main experiment. Additional information, including illustrative example trials, can be found in figure~\ref{fig:SuppFig7_human}.

%%%%%%%%%%%%%%%% SUPPLEMENTARY TEXT %%%%%%%%%%%%%%%

\subsection*{Supplementary Text}
\subsubsection*{Model Architecture and Hyperparameter Tuning}
We used the standard ResNet-50 architecture described by \cite{he2016deep} without any modifications. The architecture comprises residual blocks containing convolutional layers followed by batch normalization and ReLU activation. Specifically, the model begins with an initial convolutional layer, followed by four residual blocks, and concludes with a global average pooling layer and a fully connected layer for classification. To analyze the evolution of layer-wise geometry, we extracted features from the outputs of each residual block (Block 1–4) and the final output of the average pooling layer (avgpool).

The Wild Relation Network (WReN) model captures and integrates pairwise relational information from the three panels in an input row. Each panel is first processed through a shared four-layer convolutional block to generate an individual panel embedding. Then, embeddings from each pair of panels are concatenated and passed through a multi-layer perceptron (MLP). The resulting pairwise features are summed to form an aggregated relational representation, which is further refined through three additional MLP layers. For layer-wise geometric analysis, we extract representations from the convolutional block output (CNN), the aggregated pairwise features (Pairwise), and the three successive MLP layers (MLP1–3).

For hyperparameter tuning of WReN, we performed a grid search over the following parameters: (1) hidden dimension of the pairwise relational module $\{128, 256, 512\}$; (2) number of layers in the pairwise relational module $\{1, 2, 3, 4\}$; (3) hidden dimension of the classification MLP $\{64, 128, 256\}$; and (4) number of layers in the classification MLP $\{1, 2, 3, 4\}$. The optimal configuration, minimizing test error on three held-out rule splits, was found to be a pairwise relational module with $2$ layers of $512$ dimensions and a classification MLP with $3$ layers of $256$ dimensions.

The Vision Transformer (ViT) architecture comprises multiple layers of multi-headed self-attention (MSA). In our implementation, we utilize a four-layer Transformer model, each containing $12$ attention heads and a hidden dimension of $96$. The model processes input row patches, embedding them into token representations with a learnable class token prepended to the sequence. These representations are then sequentially processed through self-attention layers to capture global contextual dependencies. For layer-wise geometric analysis, we extract the outputs from each attention layer (Attn1-4).

For hyperparameter tuning of ViT, we performed a grid search over the following parameters: (1) number of layers $\{4,8,12\}$; (2) number of attention heads $\{4,8,12,16\}$; (3) hidden dimension of the self-attention layers $\{48,96,192,384,768\}$. The optimal configuration, determined by minimizing test error, was found to be $4$ layers, each with $12$ heads and a hidden dimension of $96$.

The Scattering Compositional Learner (SCL) model~\cite{wu2020scattering} is a hierarchical architecture designed explicitly for RPM tasks (figure~\ref{fig:SuppFig8_SCL_architecture}). Each input panel is first processed through a shared convolutional block, producing an individual panel embedding. These embeddings are then processed through three 1-D convolutional layers that operate across the three panels. Crucially, the same filter is applied consistently across the panel-wise feature dimensions, ensuring that abstract relations are detected in an attribute-invariant manner. Finally, the output is further refined using two MLP layers. For layer-wise geometric analysis, we extract representations from the convolutional block (CNN), the three 1-D convolutional layers (conv1-3), and the two MLP layers (MLP1–2). 

For hyperparameter tuning of SCL, we performed a grid search over the following parameters:  (1) the kernel size of the 1-D convolutional layers $\{1, 2, 4, 8\}$; (2) the number of output channels, chosen from $\{16, 32\}$ for the first layer, $\{32, 64\}$ for the second layer, and $\{5, 10\}$ for the final layer; (3) the hidden dimensions of the last two layers of the multi-layer perceptron (MLP) $\{400, 1000\}$. The optimal configuration, determined by minimizing test error, was found to be a kernel size of $1$, output channel sizes of $\{64, 32, 5\}$, and an MLP hidden dimension of $400$.

\subsubsection*{Prototypical loss and SNR loss}
For the SNR loss, we conduct a grid search over batch composition and learning rate. Following the setup used in cross-entropy training, we maintain a total batch size of $512$ and explore three batch compositions: \(\{32\times16, 16\times32, 8\times64\}\) ($m$ classes \(\times\) $P$ samples per class). Additionally, we test three learning rates: $\{0.1, 0.01, 0.001\}$. Model performance is evaluated based on test error across three held-out rule splits, distinct from the $15$ used for training. The optimal configuration is $32\times16$ with a learning rate of $0.01$.

The prototypical loss~\cite{snell2017prototypical} is a distance-based loss function commonly used in few-shot learning. It generates rule prototypes, which act as representative representations for each rule. Like the SNR loss, each input batch consists of $P$ rows drawn from $m$ different relational rules. For each rule $r$, the $P$ rows are randomly split into two disjoint subsets: a support set $S_r$ and a query set $Q_r$. The prototype $z_r$ for rule $r$ is computed as the mean representation of its support set:
\begin{equation}
	z_{r}=\frac{1}{\mid S_{r}\mid}\sum_{x\in S_{r}}x
        \label{eq:Proto_z} % Use a logical label
\end{equation}
where $x$ denotes the relational representation of an input row. 

The prototypical loss encourages rows in the query set $Q_r$ to be closer to their corresponding rule prototype $z_r$ while pushing them away from prototypes of other rules $z_{c'} (c' \neq c)$ in the batch. It is formulated as:
\begin{equation}
	l_{\text{Prototypical}}=\sum_{r}\sum_{x\in Q_{c}}-\log\frac{\exp\left(-\parallel x-z_{c}\parallel^{2}\right)}{\sum_{c' \neq c}\exp\left(-\parallel x-z_{c'}\parallel^{2}\right)}
	\label{eq:Proto_loss} % Use a logical label
\end{equation}

To optimize the Prototypical loss, we conducted a grid search over:  (1) batch size \(\{32\times16, 16\times 32, 8 \times 64\}\) ($m$ classes \(\times\) $P$ samples per class); (2) learning rate {\(\{0.1, 0.01, 0.001\}\)}, and support set size {\(\{1, 5\}\)}. Model performance was assessed using test accuracy on three held-out rule splits, distinct from the 15 used for training. The optimal configuration was found to be \( 32 \) classes \(\times\) \( 16 \) samples per class, with a learning rate of \( 0.01 \) and support set size \( 5 \).

% If your supplement is very short you might need to uncomment the following line to avoid
% layout problems with the figures and tables.
%\newpage

%%%%%%%%%%%%%%%% SUPPLEMENTARY FIGURES %%%%%%%%%%%%%%%
\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{SuppFig1_test_err_per_relation} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Model Test Errors Across Abstract Relation Types.}
		(\textbf{A-D}) Test errors of four models on the $35$ training rules, evaluated across three abstract relation types: Progression (blue), Arithmetic (green), and Logical (red). The chance error is $0.97$. Each bar shows the mean classification error for rows of rules belonging to one of these relation types. Error bars represent the standard error of the mean (s.e.m.). Statistical significance was assessed using pairwise Wilcoxon tests, with asterisks indicating significance levels: *** ($p < 0.001$).}
	\label{fig:SuppFig1_test_err_per_relation} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{SuppFig2_human_model} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Comparison of Model Generalization Errors with Human Performance on the \textit{SimplifiedRPM} Task.}
(\textbf{A-C}) Comparison of the generalization errors of ResNet-50, WReN, and ViT models with human performance on the \textit{SimplifiedRPM} task across 13 selected rule pairs. Each dot represents the average model error (x-axis) and human error (y-axis) over 10 questions for a given rule pair, with error bars indicating the standard error of the mean (s.e.m.). The dashed line represents the line of identity. No significant positive correlation is observed between model and human errors (Spearman’s rank correlation: ResNet-50, $\rho = 0.34$, $p = 0.24$; WReN, $\rho = -0.67$, $p = 0.01$; ViT, $\rho = 0.27$, $p = 0.37$).
    (\textbf{D-F}) Relationship between model generalization error (x-axis) and human response time (y-axis) for the 13 selected rule pairs in ResNet-50, WReN, and ViT models. Each dot represents the average model error and corresponding human response time for a given rule pair, with error bars indicating the s.e.m. No significant correlation is found between model error and human response time (Spearman’s rank correlation: ResNet-50, $\rho = 0.12$, $p = 0.68$; WReN, $\rho = -0.50$, $p = 0.08$; ViT, $\rho = -0.14$, $p = 0.65$).}
	\label{fig:SuppFig2_human_model} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{SuppFig3_overlap} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Generalization signal-noise overlap differences across abstract relation types.}
		(\textbf{A-D}) Generalization signal-noise overlap (normalized by signal magnitude) for different abstract relation types—progression, arithmetic, and logical—across four models. Results are averaged over 15 random splits of training and held-out rules. Each bar represents the average error for trials where the correct rule of the sample row belonged to each relation type, with error bars indicating the s.e.m. Statistical comparisons were conducted using the pairwise Wilcoxon test. Asterisks indicate statistical significance: * ($p < 0.01$).}
	\label{fig:SuppFig3_overlap} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=0.8\textwidth]{SuppFig4_test_PC_sig} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Fraction of variance explained by the principal components (PCs) of the training rule representations.}
		(\textbf{A-D}) We aggregate the relational representations of the 1,000 test rows for each of the 35 training rules and perform principal component analysis (PCA) on these representations. For each of the four neural networks under study, we plot the fraction of variance explained by each principal component (PC), displaying only the top 60 PCs. The red line indicates the 35th PC, corresponding to the number of training rules. A noticeable drop in explained variance at this point suggests that the representations of the 35 training rules are consistently confined to a low-dimensional subspace. The lines represent the average explained variance across 15 random splits of held-out rules, with shading indicating the standard error of the mean (s.e.m.).}
	\label{fig:SuppFig4_test_PC_sig} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{SuppFig5_score_epoch} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Comparison of Model Generalization Errors with Human Performance on the \textit{SimplifiedRPM} Task.}
		Changes in generalization signal (\textbf{A-D}), generalization dimensionality D (\textbf{E-H}), and the variance of held-out rule manifolds explained by the top 35 principal components of training rules (\textbf{I-L}) over training epochs. Results are averaged across 15 different held-out rule splits, with shaded areas representing the standard error of the mean (s.e.m.) for the four models (ResNet, WReN, ViT, and SCL). The red vertical line indicates the starting point of the plot in Fig.~\ref{fig:Fig6_signalD_tradeoff}, marking the epoch at which the relational representation structure for the training rules stabilizes.}
	\label{fig:SuppFig5_score_epoch} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=0.8\textwidth]{SuppFig6_rule_table_example} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Overview of \textit{SimplifiedRPM} dataset rules and example rows.}
	(\textbf{A}) Rules in the \textit{SimplifiedRPM} dataset. Each rule in the \textit{SimplifiedRPM} dataset is defined by an abstract relation (first column) applied to a specific object attribute, resulting in a total of 40 possible rules. During training, we create rule splits by randomly selecting five rules to be held out, ensuring that each abstract relation appears at most once in the held-out set. The table illustrates an example of this split, where yellow cells indicate the five held-out rules, and blue cells represent the remaining 35 rules used for training the models.
         (\textbf{B-D}) Example rows in the \textit{SimplifiedRPM} dataset. 
         (\textbf{B}) Example row illustrating the Progression -1 number relation, where the number of objects in each panel decreases by one across the row (4 objects in the first panel, 3 in the second, and 2 in the last). 
         (\textbf{C}) Example row demonstrating the OR position rule, where objects in the third panel occupy positions in either the first or second panel.
         (\textbf{D}) Example row illustrating the AND shape rule, where the third panel contains shapes (hexagon, star) that appear in both the first and the second panel.}
	\label{fig:SuppFig6_rule_table_example} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=0.5\textwidth]{SuppFig7_human} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Example trials in the human experiment.}
	(\textbf{A}) Instruction and practice trial, where participants are introduced to the task. 
        (\textbf{B}) Explanations are provided to participants after they make a selection in the practice trial. 
        (\textbf{C}) Example trial from the main experiment, where no feedback is given.}
	\label{fig:SuppFig7_human} % give each figure a logical label name
\end{figure}

\begin{figure} % Do not use \begin{figure*}
	\centering
	\includegraphics[width=1.0\textwidth]{SuppFig8_SCL_architecture} % for an image file named example_figure.*
	% Pick an appriopriate width for the size of the image

	% Captions go below figures
	\caption{\textbf{Overview of the SCL architecture.}
	Each input row, consisting of three panels, is processed through three 1-D convolutional layers, followed by two fully connected multilayer perceptron (MLP) layers. The final output is of size 35, compared against the one-hot target vector corresponding to the 35 possible relational rules. The penultimate layer is the relational representation used for the \textit{SimplifiedRPM} task. }
	\label{fig:SuppFig8_SCL_architecture} % give each figure a logical label name
\end{figure}

\clearpage
%%%%%%%%%%%%%%%% SUPPLEMENTARY TABLES %%%%%%%%%%%%%%%

\begin{table} % Do not use \begin{table*}
	\centering
	% Captions go above tables
	\caption{\textbf{Relations in the \textit{SimplifiedRPM} Dataset.}
	The \textit{SimplifiedRPM} dataset includes ten abstract relations organized into progression, arithmetic, and logical types. Each rule defines how attribute index values assigned to objects change across three panels. Each example consists of three lists, each representing a panel and specifying the assigned attribute values. For instance, $\left\{ [1],[1],[1]\right\}$ represents a constant relation, with objects maintaining the attribute value one across all panels. Objects can also have multiple attribute values, as seen in the \textit{AND} relation example $\left\{ [1],[0,1],[1]\right\}$, where the second panel contains objects with attributes 0 and 1.}
	\label{tab:simplifiedRPM_rules} % give each table a logical label name

        \begin{tabular}{lccc}
            \\
            \hline
            \textbf{Relation Type} & \textbf{Relation} & \textbf{Description} & \textbf{Example} \\
            \hline
            \textbf{Progression} & Const & \shortstack{Attribute values are the same \\ across all three panels.} & \{[1], [1], [1]\} \\
            \cline{2-4} & Prog -2  & \shortstack{Attribute values decrease \\ incrementally by 2 across the panels.} & \{[4], [2], [0]\} \\
            \cline{2-4} & Prog -1  & \shortstack{Attribute values decrease \\ incrementally by 1 across the panels.} & \{[2], [1], [0]\} \\
            \cline{2-4} & Prog +1  & \shortstack{Attribute values increase \\ incrementally by 1 across the panels.} & \{[0], [1], [2]\} \\
            \cline{2-4} & Prog +2  & \shortstack{Attribute values increase \\ incrementally by 2 across the panels.} & \{[0], [2], [4]\} \\
            \hline
            \textbf{Arithmetic}  & + & \shortstack{Attribute values in the 3rd panel \\ are the sum of the values \\ in the first two panels.} & \{[0], [1], [1]\}\\
            \cline{2-4} & - & \shortstack{Attribute values in the 3rd panel \\ are the first panel's values \\ minus the second panel's values.} & \{[1], [1], [0]\}\\
            \hline
            \textbf{Logical} & AND & \shortstack{3rd panel contains attribute values \\ present in both the first and second panels.} & \{[0], [0, 1], [0]\}\\
            \cline{2-4} & OR & \shortstack{3rd panel contains attribute values \\ present in either the first or second panel.} & \{[0], [0, 1], [0, 1]\}\\
            \cline{2-4} & XOR       & \shortstack{3rd panel contains attribute values \\ present in only one of the first two panels.} & \{[0], [0, 1], [1]\}\\
            \hline
        \end{tabular}
\end{table}

\begin{table} % Do not use \begin{table*}
	\centering
	% Captions go above tables
	\caption{\textbf{Human Performance on 13 Rule Pairs.}
	Thirteen rule pairs were tested in the human experiment. The correct rule corresponds to the rule governing both the sample row and the correct choice row, while the incorrect rule applies to the incorrect choice row. Human error represents the average error rate across 10 trials for each rule pair, with error bars indicating the standard error of the mean (s.e.m.). We recruited 25 MTurk participants (n=25), each completing a subset of 60 trials from a total of 130 (13 rule pairs $\times$ 10 trials per rule pair). The error for each trial was calculated as the mean response error across 10 participants. Response time denotes the total duration from trial onset (when the stimulus appears on the screen) to the moment the participant selects one of the two choice images. Rule pairs are ordered by average human error.}
	\label{tab:human_error} % give each table a logical label name

	\begin{tabular}{lccccr} % four columns, alignment for each
		\\
		\hline
		\# & Correct Rule & Incorrect Rule & Human Error & Response Time (sec) \\
		\hline
		1  & Prog-1 Number  & AND Shape       & $0.11\pm0.04$  & $10.32\pm1.33$ \\
		2  & Prog+1 Number  & Const Number    & $0.14\pm0.05$  & $7.23\pm1.13$  \\
		3  & OR Shape       & Arith+ Number   & $0.15\pm0.03$  & $13.52\pm1.08$ \\
		4  & Prog+2 Number  & Const Number    & $0.18\pm0.06$  & $10.08\pm1.45$ \\
		5  & Arith- Number  & OR Shape        & $0.18\pm0.06$  & $13.19\pm1.46$ \\
		6  & XOR Shape      & AND Position    & $0.20\pm0.04$  & $18.57\pm1.57$ \\
		7  & Prog-2 Number  & XOR Position    & $0.22\pm0.06$  & $8.87\pm1.23$  \\
		8  & Arith+ Number  & OR Position     & $0.22\pm0.06$  & $12.13\pm2.01$ \\
		9  & Const Number   & Prog+2 Number   & $0.23\pm0.04$  & $6.08\pm0.58$  \\
		10 & AND Position   & Prog-2 Number   & $0.43\pm0.07$  & $14.95\pm1.05$ \\
		11 & AND Shape      & XOR Shape       & $0.47\pm0.06$  & $17.80\pm1.07$ \\
		12 & OR Position    & XOR Position    & $0.48\pm0.07$  & $20.62\pm1.18$ \\
		13 & XOR Position   & Arith- Number   & $0.51\pm0.07$  & $14.71\pm1.02$ \\
		\hline
	\end{tabular}
\end{table}

%%%%%%%%%%%%%%%% SUPPLEMENTARY REFERENCES %%%%%%%%%%%%%%%

% Do NOT include a reference list in the supplement.
% All references must be in a single list at the end of the main text.
% The copyeditors will ensure that the correct reference list appears with each version of the paper
% (print, HTML, PDF, mobile app, metadata for bibliographic databases etc.)

\end{document}
% End of science_template.tex