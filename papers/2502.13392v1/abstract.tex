Pioneering companies such as Waymo have deployed robo-taxi services in several U.S. cities. These robo-taxis are electric vehicles, and their operations require the joint optimization of ride matching, vehicle repositioning, and charging scheduling in a stochastic environment. We model the operations of the ride-hailing system with robo-taxis as a discrete-time, average reward Markov Decision Process with infinite horizon. As the fleet size grows, the dispatching is challenging as the set of system state and the fleet dispatching action set grow exponentially with the number of vehicles. To address this, we introduce a scalable deep reinforcement learning algorithm, called Atomic Proximal Policy Optimization (Atomic-PPO), that reduces the action space using atomic action decomposition. We evaluate our algorithm using real-world NYC for-hire vehicle data and we measure the performance using the long-run average reward achieved by the dispatching policy relative to a fluid-based reward upper bound. Our experiments demonstrate the superior performance of our Atomic-PPO compared to benchmarks. Furthermore, we conduct extensive numerical experiments to analyze the efficient allocation of charging facilities and assess the impact of vehicle range and charger speed on fleet performance.
%In this work, we model the dispatching of a robo-taxi fleet as a Markov decision process with discrete state and action space, infinite horizon, and long-run average reward objective. The dispatching of a robo-taxi fleet in a ride-hailing system is challenging because the state and action space grows exponentially with the number of vehicles. To address this, we introduce a scalable deep reinforcement learning algorithm, referred as Atomic Proximal Policy (Atomic PPO), that employs atomic action decomposition, state aggregation, and neural network function approximation. Additionally, we propose a fluid-based linear program (LP) that provides an upper bound on the optimal objective value achievable by any control policy. We implement our algorithm on the dataset of NYC for-hire vehicle and it demonstrates superior performance against benchmarks. Moreover, we conduct extensive numerical experiments to investigate the efficient allocation of charging facility and the impact of vehicle range and charger speed.