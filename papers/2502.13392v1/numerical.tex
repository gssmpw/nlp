We conduct numerical experiments using the for-hire vehicle trip records in July 2022 from New York City Taxi and Limousine Commissionâ€™s (TLC) \cite{nyctlc}. The dataset contains the individual trip records of for-hire vehicles from Uber, Lyft, Yellow Cab, and Green Cab. Each trip record includes the origin and destination taxi zones, base passenger fares, trip duration, and distance, all of which are used for model calibration.

We consider trip requests from 0:00 to 24:00, Mondays to Thursdays \footnote{Through data exploration, we find that the trip demand across Mondays to Thursdays shares a similar pattern, which is different from the patterns from Fridays to Sundays. Hence, we only use the trip records from Mondays to Thursdays to calibrate the model for workdays.}, where each workday is partitioned into time intervals of 5 minutes. We estimate the mean of trip arrivals $\arrrate{\origin\destination}{\time}$ for each origin $\origin$ and destination $\destination$ at each time $\time$ of a workday by taking the average of the number of trip requests of from $\origin$ to $\destination$ at time $\time$. Ride-hailing trips in NYC show significant demand imbalances during morning (7-10 am) and evening (5-8 pm) rush hours, with zones experiencing more trips flowing in (red) or out (blue), as visualized in Figure \ref{fig:manhattan-demand}.

\begin{figure}[h]
    \centering
    \begin{subfigure}{0.4\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/weekday_morning_rush_tripsupplytime_202207.png}
        \caption{Weekday Morning Rush Hours\\\centering 7-10 am Mondays - Thursdays}
        \label{fig:manhattan-demand-morning-rush}
    \end{subfigure}%
    \begin{subfigure}{0.4\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/weekday_evening_rush_tripsupplytime_202207.png}
        \caption{Weekday Evening Rush Hours\\\centering 5-8 pm Mondays - Thursdays}
        \label{fig:manhattan-demand-evening-rush}
    \end{subfigure}
    \caption{Manhattan Trip Demand Imbalance.}
    \label{fig:manhattan-demand}
\end{figure}

We partition the entire Manhattan into 10 regions (Figure \ref{fig:map}) by aggregating adjacent taxi zones with similar demand patterns in both morning and evening rush hours. Based on the trip request pattern, we identify 3 categories of regions: workplace, restaurant area, and residential area.  Workplaces are marked with red circles and mainly consist of downtown Manhattan and midtown Manhattan. Restaurants are mostly gathered in East Village and West Village circled in orange. Residential area consists of Upper/Midtown East, Upper/Midtown West, and upper Manhattan, and are circled in blue. During morning rush hours, people travel to workplaces (Figure \ref{fig:manhattan-demand-morning-rush}), while in the evening rush hours, they head to restaurants or residential areas (Figure \ref{fig:manhattan-demand-evening-rush}). Without repositioning, vehicles idle in high in-flow regions while abandoning trip requests in high out-flow regions. Therefore, it is critical to incorporate vehicle repositioning to balance the supply of vehicles across different regions in Manhattan.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.3\linewidth]{plots/ManhattanMap.png}
    \caption{Service Regions in Manhattan.}
    \label{fig:map}
\end{figure}

Using the NYC TLC dataset, we build a simulator of trip order generating process. We set the environment parameter for numerical experiments according to Table \ref{tab:env-params}. The reward of a trip $\tripfulfillreward{,\origin \destination}{\time}$ from region $\origin$ to $\destination$ at time $\time$ is calibrated by taking the average of the base\_passenger\_fare column across all trips from $\origin$ to $\destination$ at time $\time$. We estimate the actual fleet size using the maximum number of simultaneous trips across all times. Then, we scale down the mean of trip arrivals for all origin-destination pairs at all times based on the ratio of our chosen fleet size (i.e. 300) to the actual estimated fleet size (i.e. 12.8k). %Currently, Waymo deployed 250 vehicles in San Francisco area \cite{waymo_news}, which is comparable to the fleet size in our experiments for Manhattan.

We calibrate the battery consumption $\batterycost{\origin\destination}$ for each origin $\origin$ and destination $\destination$ using the Chevrolet Bolt EUV model with battery pack size 65 kW. If fully charged, the range $\range$ of the vehicle is 260 miles. For self-driving vehicles, this range is halved because the autonomous driving computation takes around 50\% of the battery. We use 75 kW as the outlet rate of DC fast chargers and 15 kW for Level 2 AC (slow) chargers \cite{afsl, evinfra}. 

We adopt the non-linear charging curve for charging (Table \ref{tab:nonlinear-charging-curve}). Based on the criticality of battery level and the cutoff points of non-linear charging rates, we mark the battery level 0\%-10\% as ``low", 10\%-40\% as ``medium", and 40\%-100\% as ``high"  \footnote{We remark that due to the decay in charging rate and the large volume of trip demand relative to the fleet size, it is inefficient to charge up a vehicle to near full. Therefore, we merge battery levels above 40\% into a single category.}.

\begin{table}[htb]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        Parameter & Value \\
        \hline
        Decision Epoch Length & 5 mins\\
        Number of Time Steps Per Day & 288\\
        Number of Days Per Episode & 8\\
        % Number of Episodes & 30\\
        Fleet Size & 300\\
        Battery Pack Size & 65 kW\\
        Vehicle Range & 130 miles\\
        Initial Vehicle Battery & Half Charged\\
        Charger Outlet Rate & 75 kW\\
        \hline
    \end{tabular}
    \caption{Environment parameters}
    \label{tab:env-params}
\end{table}

\begin{table}[htb]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
        Battery Percentage & 0\%-10\% & 10\%-40\% & 40\%-60\% & 60\%-80\% & 80\%-90\% & 90\%-95\% & 95\%-100\%\\
        \hline
        Charging Time (s) & 47 & 33 & 40 & 60 & 107 & 173 & 533 \\
         \hline
    \end{tabular}
    \caption{Charging time (in sec) for each percentage increase in battery}
    \label{tab:nonlinear-charging-curve}
\end{table}

We present the details about the architecture of neural networks and the hyperparameter settings for all experiments with Atomic-PPO (see Algorithm \ref{algo:ppo}) in the Appendix \ref{sec:appendix-dnn}. For each experiment setting, we monitor the training logs of Atomic-PPO and terminate the training when the policy no longer makes improvements in the average reward across simulated trajectories. For most of the experiment settings, the training curve of Atomic-PPO converges after 10 policy iterations. In the evaluation phase, we roll out the Atomic-PPO policy on 10 consecutive days of operations for 10 different trajectories and compute the average daily reward. With 30 CPUs running the data generation \eqref{eq:ppo-data} part of Atomic-PPO in parallel, each policy iteration takes 15-20 mins, so the entire training of Atomic-PPO on one problem instance takes 2-3 hours to complete.
%Empirically, we observe that Atomic-PPO's policy becomes stationary starting from the 3rd day. We use each individual days from the roll out to update the value function of Atomic-PPO. For most of the experiment settings, the training curve of Atomic-PPO starts to converge after 10 policy iterations. We monitor the training logs of Atomic-PPO and terminate the training when the training curve no longer makes improvements. In the evaluation phase, we roll out the Atomic-PPO policy on 10 consecutive days and compute the total reward.

We use the power-of-k dispatching and the fluid policy as our benchmark algorithms. For each trip request, the power-of-k heuristic selects the closest $k$ vehicles and assigns the one with the highest battery level to the trip request. If there are no vehicle that can reach the origin of the trip request within $L_p$ units of time, or if none of the $k$-closest vehicles have enough battery to complete the trip, then the trip request is abandoned. Upon completion of a trip, the vehicle will be routed to the nearest region with chargers. If, at the current decision epoch, the vehicle is not assigned any new trip requests and there is at least one charger unoccupied, then it will be plugged in at this charger and charge for one charging period. If all chargers are currently occupied or if the vehicle is fully-charged, then it will idle for the current decision epoch. The power-of-k dispatching policy is a very intuitive heuristic and is easy to implement. Under restrictive assumptions where all trip requests and charging facilities are uniformly distributed across the entire service area, \cite{varma2023electric} has demonstrated the effectiveness of power-of-k in achieving a high service level, which is the average fraction of trip demand served in the long-run. %It achieves optimal service level when the fleet size and the charger quantity are in the order of $\lambda + \lambda^{2/3}$ with respect to the trip arrival rate $\lambda$. 
This assumption is not satisfied in our setting.
We experiment $k = 1, \dots, 5$ and we set $k = 2$ because it achieves the highest average reward.

For the fluid policy, we use the LP fluid solution to infer the number of vehicles deployed for each action, at each decision epoch $t$. We use randomized rounding \footnote{As a example, if the LP fluid solution suggests to send 3.6 vehicles from $o$ to $d$ at time $t$, then we send $3$ vehicles with probability $0.4$ and send $4$ vehicles with probability $0.6$.} to obtain a feasible policy from the LP fluid solution. The fluid policy is optimal under fluid limit, but not optimal when the fleet size is finite.

% We remark that the LP fluid solution in section \ref{sec:fluid} gives the passenger-carrying, rerouting, and charging flows on the extended graph that records the discretized time, region, and battery level. In order to reduce the variance from the randomized rounding, we aggregate all the flows along the dimension of the battery level. Additionally, we aggregate the passenger-carrying and rerouting flows for each $o$-$d$ pair be to the traveling flows of $o$-$d$. If the actual trip arrival is smaller than the traveling flow between the corresponding $o$-$d$ pair, we fulfill all these trips and treat the extra flow of vehicles as rerouting. If the actual trip arrival is larger than the traveling flow, then we assign all traveling vehicles as passenger-carrying and abandon the extra trip requests. 

% For each region $o$ at time $t$, we obtain the (fractional) number of vehicles we should send to charge or travel to another region. We first distribute the charging flow to vehicles in the increasing order of battery levels, then we distribute the traveling flows to the remaining vehicles.

In Section \ref{subsec:superior}, we demonstrate the effectiveness of our Atomic-PPO algorithm by comparing against the power-of-k dispatching algorithm and the fluid policy. In Section \ref{subsec:charger-deployment}, we run our Atomic-PPO algorithm on multiple instances with different number of chargers and different locations of chargers. We draw insight on how the quantity and location of charging facility can impact the reward. For all experiments above, we use the DC fast chargers. In Section \ref{subsec:range-outlet}, we study how the vehicle range and outlets rate of chargers will affect the average reward achieved by the algorithm.

\subsection{Experiments with Abundant Chargers} \label{subsec:superior}
For experiments in this section, we assume that there are abundant chargers. In each region, the number of chargers equals to the fleet size (i.e. 300 chargers per region and 3000 chargers in total), so the chargers are available in all regions at all times under all policies. 

\paragraph{Atomic-PPO achieves high percentage of fluid upper bound and significantly beats benchmark algorithms.} Table \ref{tab:payoff} shows the reward achieved by Atomic-PPO outperforms both of the fluid policy and the power-of-k by a large margin. After Atomic-PPO has been trained for 10 policy iterations, the average reward converges to around 91\% of fluid upper bound. On the other hand, the power-of-k policy can achieve around 71\% of fluid upper bound. The fluid policy has the worst performance and it achieves only 43\% of the fluid upper bound. %Among the 10 days of evaluation, we pick the $4^{th}$ day to plot the snapshots of Atomic-PPO, power-of-k, and fluid policies.

% Fluid policy is a policy independent from the passenger arrivals. Additionally, with 300 vehicles operating among 10 regions (i.e. 100 o-d pairs), the fluid policy suffers from a large integrality gap. Since the power-of-k does not have vehicle rerouting, in Manhattan area with strong demand imbalance, it results in a significant number of vehicles idling in over-supply regions while many trip requests are abandoned in under-supply regions. On the other hand, Atomic-PPO jointly optimizes the trip fulfillment, vehicle rerouting, and charging. In a service area that has strong demand imbalanced, Atomic-PPO can effectively send vehicles from regions of over-supply to fulfill trip requests in regions of under-supply. Additionally, as Atomic-PPO interacts with the stochastic environment during training, it can handle the stochasticity of trip arrivals and it is not impacted by the integrality gap from fractional solutions.

\begin{table}[h]
    \centering
    \begin{tabular}{c|c|c}
        % \hline
        Algorithm & Reward/$\bar{R}$ & Avg. Daily Reward \\
        \hline
        Atomic-PPO & 91\% & \$390K\\
        Power of k & 71\% & \$305K\\
        Fluid policy & 43\% & \$185K\\
        % \hline
    \end{tabular}
    \caption{Reward achieved by Atomic-PPO and benchmarks}
    \label{tab:payoff}
\end{table}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.6\linewidth]{plots/payoff.png}
%     \caption{Atomic-PPO training curve}
%     \label{fig:payoff}
% \end{figure}

\paragraph{Atomic-PPO has a higher utilization of fleet for taking trip requests.} Figures \ref{fig:fleet-status-ppo}-\ref{fig:fleet-status-lp-augmented} demonstrate the fleet status of Atomic-PPO, power-of-k dispatching, and fluid policies respectively. Atomic-PPO has the largest fraction of passenger-carrying vehicles among all three policies across almost all time of the day, which illustrates that Atomic-PPO fulfills the highest number of trip requests. From 9 a.m. to 9 p.m., where the trip arrival rate is relatively higher than that of other hours, nearly all vehicles under Atomic-PPO are assigned to take trip requests. 

However, a significant fraction of vehicles remain idle throughout the day under both the power-of-k heuristic and the fluid policy. The power-of-k heuristic does not allow for vehicle repositioning. When there are strong demand imbalance (Figure \ref{fig:manhattan-demand}), the power-of-k heuristic cannot reposition vehicles from oversupply regions to pickup trip requests in undersupply regions. The fluid policy does not adapt to the stochasticity of the trip request arrivals as the policy is state-independent. When the number of trip arrivals $\arrnum{\origin\destination}{\time}$ for a particular trip status is significantly larger than its Poisson arrival mean $\arrrate{\origin\destination}{\time}$, the fluid policy does not adjust its assignment to fulfill the additional trip requests.
%Hence, the distribution of fleet from the fluid policy significantly deviates from the optimal one. the accumulation of rounding errors over time makes the distribution of fleet significantly deviates from the optimal one. 

\begin{figure}[h]
    \centering
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/car_status_ppo_singleday.png}
        \caption{Atomic-PPO}
        \label{fig:fleet-status-ppo}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/car_status_d-closest_singleday.png}
        \caption{Power of K}
        \label{fig:fleet-status-d-closest}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/car_status_lp-augmented_singleday.png}
        \caption{Fluid Policy}
        \label{fig:fleet-status-lp-augmented}
    \end{subfigure}
    \caption{Fleet status of Atomic-PPO, power-of-k, and fluid policy}
    \label{fig:fleet-status}
\end{figure}

\paragraph{Atomic-PPO has higher trip fulfillment across all times of a day.} Figures \ref{fig:trip-status-ppo}-\ref{fig:trip-status-lp-augmented} illustrate the trip fulfillment of Atomic-PPO, power-of-k, and fluid policies, respectively. Atomic-PPO fulfills a higher number of trip requests at all time steps of the day, compared to the power-of-k and fluid-policy. Note that the power-of-k policy can fulfill almost all trip requests during early morning hours (0-6 am) when the trip demand is small, but it fulfills significantly fewer trip requests than Atomic-PPO after 9 am when the trip demand is large. On the other hand, the fluid policy has the smallest number of fulfilled trip requests at all times of the day. It has to abandon some trip requests even during early morning hours, when the trip demand is small. 

\begin{figure}[h]
    \centering
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/trip_status_ppo_singleday.png}
        \caption{Atomic-PPO}
        \label{fig:trip-status-ppo}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/trip_status_d-closest_singleday.png}
        \caption{Power of K}
        \label{fig:trip-status-d-closest}
    \end{subfigure}
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{plots/AbundantChargers/trip_status_lp-augmented_singleday.png}
        \caption{Fluid Policy}
        \label{fig:trip-status-lp-augmented}
    \end{subfigure}
    \caption{Trip fulfillment status of Atomic-PPO, power-of-k, and fluid policy}
    \label{fig:trip-status}
\end{figure}

\subsection{Deployment of Charging Facilities} \label{subsec:charger-deployment}

\begin{table}[htb]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         & \multicolumn{5}{c|}{Workplace} & \multicolumn{1}{c|}{Restaurants} & \multicolumn{4}{c|}{Residential} & \\
        \hline
        Region & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & Avg. Daily Reward\\
        \hline
        Unif. 10 chargers & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \$250K\\ %\$250,614 \\
        Unif. 20 chargers & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & \$375K\\ %\$373,167 \\
        Unif. 30 chargers & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & 3 & \$390K\\ %\$387,596 \\
        Unif. 40 chargers & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & 4 & \$390K\\ %\$390,189 \\
        \hline
        %% 10 chargers
        % Midtown Manhattan. & 0 & 0 & 0 & 10 & 0 & 0 & 0 & 0 & 0 & 0 & \$360K\\ %\$359,926\\ 
        % Upper Manhattan & 2 & 2 & 2 & 0 & 0 & 0 & 2 & 2 & 0 & 0 & \$155K\\ %\$153,258 \\
        % Lower Manhattan & 0 & 0 & 0 & 2 & 2 & 2 & 0 & 0 & 2 & 2 & \$275K\\ %\$274,126\\
        %% 15 chargers
        Midtown Manhattan. & 0 & 0 & 0 & 15 & 0 & 0 & 0 & 0 & 0 & 0 & \$380K\\ %\$379,291\\ 
        Upper Manhattan & 3 & 3 & 3 & 0 & 0 & 0 & 3 & 3 & 0 & 0 & \$225K\\ %\$224,181 \\
        Lower Manhattan & 0 & 0 & 0 & 0 & 3 & 3 & 0 & 0 & 3 & 3 & \$335K\\ %\$335,735\\
        % LP Alloc. & 0 & 0 & 0 & 1 & 3 & 3 & 1 & 3 & 4 & 0 & \$162K\\ %\$162,083 \\
        \hline
        Abundant Chargers & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & \$390K\\ %\$391,649\\
        \hline
        Fluid Upper Bound & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & 300 & \$430K\\
        \hline
    \end{tabular}
    \caption{Deployment of Charging Facilities}
    \label{tab:charging-facility-deployment}
\end{table}

We conduct experiments on different deployments of charging facilities. We first experiment with uniform deployment of chargers across the 10 regions and we run the Atomic-PPO training algorithm. Starting from 1 charger per region (i.e. 10 chargers in total), we keep increasing the number of chargers per region by 1, until the average reward reaches the level as that achieved by Atomic-PPO algorithm in the setting with abundant chargers as in Section \ref{subsec:superior}. Additionally, we investigate the allocation of a limited number of chargers to a subset of regions. We allocate 15 chargers uniformly to all regions in lower Manhattan (regions 4, 5, 8, and 9), upper Manhattan (regions 0, 1, 2, 6, and 7), or midtown Manhattan (region 3). The average reward achieved by Atomic-PPO for each experiment case, along with the number of chargers per region, are summarized in Table \ref{tab:charging-facility-deployment}.

Table \ref{tab:charging-facility-deployment} demonstrates that in order to achieve the same average reward as of the abundant chargers, we need 30 chargers if allocating them uniformly. Uniformly allocating 20 chargers leads to roughly 95\% of reward generated by abundant chargers, and the performance degrades to roughly 65\% when allocating uniformly with only 10 chargers. On the other hand, with only 15 chargers in total, it can achieve 88\% reward of abundant chargers by allocating them uniformly to lower Manhattan, and it can achieve 98\% reward of abundant chargers by allocating all to midtown Manhattan. Recall from Figure \ref{fig:manhattan-demand}, midtown Manhattan region is the most popular destination during morning rush hours and it becomes the most popular origin during evening rush hours. Therefore, deploying all chargers in midtown reduces vehicles' travel time to chargers, as vehicles can charge in midtown after finishing the morning rush-hour trips and before the evening rush-hour trips.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\linewidth]{plots/midtown_cars.png}
%     \caption{Fraction of vehicles with Midtown Manhattan as destination at each time of a workday}
%     \label{fig:midtown-cars}
% \end{figure}

\subsection{Vehicle Range and Charger Outlet Rates} \label{subsec:range-outlet}
In Table \ref{tab:charging-rate-range}, we record average reward of experiments where all chargers are slow (15 kW) or all vehicles have doubled the range. %Table \ref{tab:charging-rate-range} demonstrates that if we replace all fast chargers with slow chargers, then it will lead to 14\% reduction in total reward, even though we have abundant chargers. On the other hand, doubling the vehicle range does not have a significant impact on the long-run total reward. 

\paragraph{The deployment of fast chargers can effectively lead to an increase in reward, while doubling the vehicle range cannot.} Table \ref{tab:charging-rate-range} demonstrates that replacing fast chargers with slow chargers leads to 14\% reduction in average daily reward, while doubling the vehicle range has little impact on reward. The reason is that when a vehicle is charging, it incurs an opportunity cost as the vehicle cannot take trip requests. Fast chargers enable vehicles to recharge more quickly than slow chargers, thereby reducing their opportunity cost. In contrast, doubling the vehicle range does not reduce the charging time required to replenish the same amount of battery, and thus it does not lower the opportunity cost. Moreover, the range does not have a significant impact for trips in Manhattan because most trips have a short distance.


\begin{table}[htb]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Regime & Charger Outlet Rates & Vehicle Range & Avg. Daily Reward\\
        \hline
        Benchmark & 75 kW & 130 miles & \$390K\\ %\$391,649\\
        Slow Chargers & 15 kW & 130 miles & \$335K\\ %\$336,177\\
        Double Range & 75 kW & 260 miles & \$390K \\%\$389,100\\
        \hline
    \end{tabular}
    \caption{Charging Rate \& Vehicle Range}
    \label{tab:charging-rate-range}
\end{table}
