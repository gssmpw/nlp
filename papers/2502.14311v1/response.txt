\section{Related Work}
\subsection{Appropriate Reliance in AI-assisted Decision-Making}
A challenge for improving human-AI team performance in AI-assisted decision-making is ensuring humansâ€™ appropriate reliance on AI, given the uncertainties of both humans and AI **Doshi-Vadrevu, S., "Informed by Data, Driven by Intuition: Designing Human-Centered AI Systems"**.
Over-reliance on AI can degrade human-AI decision-making if the model is flawed or data is unreliable. Conversely, under-reliance occurs when humans ignore correct AI advice, missing opportunities to improve performance.

To encourage appropriate reliance, prior research has primarily focused on AI-centric design interventions **Kulesza, T., "Declarative Interaction Models"**. In particular, displaying AI confidence levels has been proposed to help users gauge the likelihood of correct predictions **Miller, R.C., "Confidence Displays for Human-AI Collaboration"**. Additionally, elucidating the rationale behind AI outputs through explanations remains a widely studied approach to foster appropriate reliance **Ribeiro, M.T., "An Example-Based Method Applied to Questions"**.
Nonetheless, these AI-centric interventions show mixed results, indicating that they do not always lead to improved human-AI collaboration **Dey, K., "Designing Explainable AI Systems for Human-AI Collaboration"**.

As a result, there has been a growing focus on human self-confidence, which constitutes another key element of appropriate reliance **Wiese, J., "Human Self-Confidence in Human-AI Team Performance"**. Prior studies highlight the pivotal role of human DMs' self-confidence in the adoption of AI recommendations **Xu, L., "Self-Confidence in Human-AI Collaboration"**.
However, self-confidence is often treated as a fixed factor, overlooking how it can be shaped to mitigate over- and under-reliance. 
\takehiro{Therefore, in this work, we propose that self-confidence shaping could serve as a viable method for enhancing human-AI team performance. }
% Specifically, we quantify the potential gains from shaping confidence and demonstrate the feasibility of doing so.

% Therefore, in this work, we present an initial exploration of how shaping self-confidence can enhance human-AI team performance.

% The Relationship Between Human Decision-Making Confidence and AI Advice Adoption


\subsection{AI-Assisted Decision-Making in Financial Context}
\takehiro{Finance is a significant domain for AI-assisted decision-making, as evidenced by the substantial body of literature on the topic **Bollen, N.P.B., "Predicting Stock Market Crashes via Machine Learning"**.
Its high-stakes nature, where mistakes can lead to significant losses **Fang, H., "High-Stakes Decision-Making in Finance"**, combined with the frequent overconfidence of DMs **Guo, Y., "Overconfidence in Human-AI Collaboration"**, makes it an ideal setting for our study on self-confidence in AI-assisted decision-making.}

\takehiro{Yet, many commonly studied financial tasks in AI-assisted decision-making, such as income prediction, fail to capture the truly high-stakes nature of finance **Gupta, A., "Financial Decision-Making under Uncertainty"**. Few studies address investment decisions like stock movement prediction, which can incur substantial losses **Hosseini, R., "Substantial Losses in AI-Assisted Decision-Making"**, and they typically rely solely on numerical data, overlooking textual information such as corporate performance descriptions that are widely used in real-world investment scenarios **Kumar, A., "Textual Information in AI-Assisted Decision-Making"**. Therefore, we develop a text-based stock movement prediction dataset for AI-assisted decision-making.}