\section{Related Work}
\subsection{Appropriate Reliance in AI-assisted Decision-Making}
A challenge for improving human-AI team performance in AI-assisted decision-making is ensuring humansâ€™ appropriate reliance on AI, given the uncertainties of both humans and AI~\cite{schemmer2023appropriate,does_the,buccinca2021trust,towards_science}.
Over-reliance on AI can degrade human-AI decision-making if the model is flawed or data is unreliable. Conversely, under-reliance occurs when humans ignore correct AI advice, missing opportunities to improve performance.

To encourage appropriate reliance, prior research has primarily focused on AI-centric design interventions~\cite{effect_of_confidence}. In particular, displaying AI confidence levels has been proposed to help users gauge the likelihood of correct predictions~\cite{effect_of_confidence,vodrahalli2022uncalibrated,who_should}. Additionally, elucidating the rationale behind AI outputs through explanations remains a widely studied approach to foster appropriate reliance~\cite{effect_of_confidence,does_the,Are_explanations,li2024utilizing}.
Nonetheless, these AI-centric interventions show mixed results, indicating that they do not always lead to improved human-AI collaboration~\cite{effect_of_confidence,who_should,visual_uncertainty}.

As a result, there has been a growing focus on human self-confidence, which constitutes another key element of appropriate reliance~\cite{chong2022human,vodrahalli2022humans,are_you_really,mahmood2024designing}. Prior studies highlight the pivotal role of human DMs' self-confidence in the adoption of AI recommendations~\cite{chong2022human}.
However, self-confidence is often treated as a fixed factor, overlooking how it can be shaped to mitigate over- and under-reliance. 
\takehiro{Therefore, in this work, we propose that self-confidence shaping could serve as a viable method for enhancing human-AI team performance. }
% Specifically, we quantify the potential gains from shaping confidence and demonstrate the feasibility of doing so.

% Therefore, in this work, we present an initial exploration of how shaping self-confidence can enhance human-AI team performance.

% The Relationship Between Human Decision-Making Confidence and AI Advice Adoption


\subsection{AI-Assisted Decision-Making in Financial Context}
\takehiro{Finance is a significant domain for AI-assisted decision-making, as evidenced by the substantial body of literature on the topic~\cite{hase-bansal-2020-evaluating,effect_of_confidence,li2024utilizing,vodrahalli2022uncalibrated}.
Its high-stakes nature, where mistakes can lead to significant losses~\cite{towards_science,biran2017human}, combined with the frequent overconfidence of DMs~\cite{barber2001boys,grevzo2021overconfidence}, makes it an ideal setting for our study on self-confidence in AI-assisted decision-making.}

\takehiro{Yet, many commonly studied financial tasks in AI-assisted decision-making, such as income prediction, fail to capture the truly high-stakes nature of finance~\cite{towards_science,li2024utilizing}. Few studies address investment decisions like stock movement prediction, which can incur substantial losses~\cite{biran2017human}, and they typically rely solely on numerical data, overlooking textual information such as corporate performance descriptions that are widely used in real-world investment scenarios~\cite{takayanagi_naacl}. Therefore, we develop a text-based stock movement prediction dataset for AI-assisted decision-making.}