\section{RELATED WORK}
Neural Radiance Fields (NeRF) ____ and 3D Gaussian Splatting (3DGS) ____ have garnered widespread attention in recent years as effective methods for scene reconstruction ____. These approaches have shown exceptional performance, particularly in real-time photorealistic rendering, and their integration with RGB-D SLAM systems has demonstrated impressive results. iMAP ____ was the first SLAM system based on NeRF, but its single MLP model limited its ability to represent complex scenes. However, with the emergence of 3DGS-based SLAM, neural implicit representation faced significant challenges as 3DGS-based SLAM achieved better results in both tracking accuracy and rendering. 3DGS strikes a balance between implicit and explicit representations. For instance, SplaTAM ____ uses frame-to-frame tracking and per-pixel output to represent 3DGS scenes, while MonoGS ____ enables pure RGB scene tracking and reconstruction. Nonetheless, these SLAM systems struggle in dynamic real-world scenarios, as dynamic interferences lead to erroneous feature matching or pixel misalignment, resulting in tracking failures or loss. Furthermore, dynamic noise in the input causes rendering artifacts during mapping, posing a significant challenge to current SLAM systems.

As NeRF-SLAM continues to evolve, researchers are increasingly focusing on handling dynamic scenes. DN-SLAM ____ employs optical flow estimation to remove dynamic feature points from the front-end, correcting tracking errors similarly to traditional methods. However, it overlooks the rendering artifacts caused by noisy inputs in the back end. DDN-SLAM ____ combines deep learning-based detection with depth segmentation and introduces additional rendering penalties. RoDyn-SLAM ____ uses optical flow estimation on keyframes to obtain dynamic masks, removing dynamic rays for updates, but its real-time performance and rendering accuracy are limited. NID-SLAM ____ also utilizes optical flow estimation to generate dynamic masks and background completion to mitigate dynamic noise interference, but its tracking performance is constrained. Our approach integrates the strengths of these methods while addressing the issue of decoupled tracking and mapping. We use a Gaussian pyramid network to apply front-end feature points to Gaussians for densification and directly apply dynamic segmentation for rendering correction on Gaussians, mapping them back to the tracked feature points. This method tightly integrates the system, allowing tracking and mapping to mutually enhance each other, ultimately constructing a static scene map.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\hsize]{images/1.pdf}
  \caption{Frame of GARAD-SLAM. Given a series of RGB-D frames, we simultaneously construct the gaussian map and camera pose via Gaussian pyramid with Photometric-SSIM Loss $\lambda _{p-ssim}$ and dyn Loss $ \lambda _{dyn}$.  }
  \vspace{-15pt}  % 调整这个数值来减少空白
  \label{fig2}
\end{figure*}