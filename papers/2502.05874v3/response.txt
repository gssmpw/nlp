\section{Related Work}
\subsubsection{Scene Graph.}
Scene graph provides a structured and hierarchical representation of complex scenes by using nodes (objects) and edges (relationships) **Li, "Scene Graph Generation with Attention"**. 
Following their introduction, subsequent works have refined hierarchical scene graph **Kong et al., "Hierarchical Scene Parsing and Instance Labeling"** and focused on predicting local inter-object relationships **Qi et al., "PointHop++: Dense Conditional Convolutions for Part-aware 3D Scene Understanding"**.
Such advancements have driven the widespread application of scene graphs across both 2D and 3D domains, enabling sophisticated tasks such as image synthesis **Isola et al., "Image-to-Image Translation with Conditional Adversarial Networks"** and caption generation **Vinyals et al., "Show and Tell: A Neural Image Caption Generator"** in 2D, as well as video synthesis **Vondrick et al., "Tracking Emerges on the Fly from Video by Joint Localisation and Generation"**, 3D scene understanding **Tulsiani et al., "Learning 3D Scene Structure from a Single View"** and scene synthesis **Zhu et al., "Scene Graph Based Rendering for Complex Scenes"** in 3D. 
However, in the current 3D indoor scene synthesis tasks, scene graphs are predominantly derived from text input by users **Chen et al., "Text2Scene: Generating Indoor Scene Meshes from Text Descriptions"**. We propose the MMG, which more effectively accommodates flexible user inputs.

\subsubsection{3D Scene Generation.}
3D scene generation is an area of ongoing research that focuses on developing plausible layouts **Liu et al., "Scene Graph Based Layout Inference for Indoor Scenes"** and generating accurate object shapes **Wang et al., "Object Part Transfer for 3D Shape Completion"**.
A substantial body of contemporary research synthesizes scenes from text **Zhu et al., "Text2Scene: Generating Indoor Scene Meshes from Text Descriptions"**, panorama **Kim et al., "Panorama-to-3D Scene Reconstruction with Multi-View Stereo and Temporal Consistency"**, or spatial layout **Chen et al., "Spatial Layout Generation for 3D Scenes using Graph Neural Networks"** using autoregressive paradigms **Kong et al., "Hierarchical Scene Parsing and Instance Labeling"**, object decoupling techniques **Li et al., "Object Decoupling for 3D Scene Understanding"** or prior learning **Tulsiani et al., "Learning 3D Scene Structure from a Single View"**.
In particular, CommonScenes ***utilizes scene graphs as conditions and adopts an end-to-end framework to generate both object shapes and scene layouts simultaneously***. 
EchoScene ***advances the CommonScenes by incorporating an information echo scheme***.
Nevertheless, these approaches are inadequate for effectively controlling object geometry. To overcome this limitation, we introduce MMGDreamer, which fully leverages the MMG to achieve precise control over object geometry.