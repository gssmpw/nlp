[
  {
    "index": 0,
    "papers": [
      {
        "key": "zugner2018adversarial",
        "author": "Z{\\\"u}gner, Daniel and Akbarnejad, Amir and G{\\\"u}nnemann, Stephan",
        "title": "Adversarial attacks on neural networks for graph data"
      },
      {
        "key": "dai2018adversarial",
        "author": "Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le",
        "title": "Adversarial attack on graph structured data"
      },
      {
        "key": "wu2019adversarial",
        "author": "Wu, Huijun and Wang, Chen and Tyshetskiy, Yuriy and more",
        "title": "Adversarial examples on graph data: Deep insights into attack and defense"
      },
      {
        "key": "wang2019attacking",
        "author": "Wang, Binghui and Gong, Neil Zhenqiang",
        "title": "Attacking graph-based classification via manipulating the graph structure"
      },
      {
        "key": "xu2019topology",
        "author": "Xu, Kaidi and Chen, Hongge and Liu, Sijia and more",
        "title": "Topology attack and defense for graph neural networks: An optimization perspective"
      },
      {
        "key": "sun2020adversarial",
        "author": "Sun, Yiwei and Wang, Suhang and Tang, Xianfeng and Hsieh, Tsung-Yu and Honavar, Vasant",
        "title": "Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach"
      },
      {
        "key": "zhang2021backdoor",
        "author": "Zhang, Zaixi and Jia, Jinyuan and Wang, Binghui and Gong, Neil Zhenqiang",
        "title": "Backdoor attacks to graph neural networks"
      },
      {
        "key": "wan2021adversarial",
        "author": "Wan, Xingchen and Kenlay, Henry and Ru, Robin and Blaas, Arno and Osborne, Michael A and Dong, Xiaowen",
        "title": "Adversarial attacks on graph classifiers via bayesian optimisation"
      },
      {
        "key": "zhang2022projective",
        "author": "Zhang, He and Yuan, Xingliang and Zhou, Chuan and Pan, Shirui",
        "title": "Projective ranking-based gnn evasion attacks"
      },
      {
        "key": "ma2020towards",
        "author": "Ma, Jiaqi and Ding, Shuangrui and Mei, Qiaozhu",
        "title": "Towards more practical adversarial attacks on graph neural networks"
      },
      {
        "key": "mu2021a",
        "author": "Mu, Jiaming and Wang, Binghui and Li, Qi and Sun, Kun and Xu, Mingwei and Liu, Zhuotao",
        "title": "A Hard Label Black-box Adversarial Attack Against Graph Neural Networks"
      },
      {
        "key": "wang2022bandits",
        "author": "Wang, Binghui and Li, Youqi and Zhou, Pan",
        "title": "Bandits for Structure Perturbation-based Black-box Attacks to Graph Neural Networks with Theoretical Guarantees"
      },
      {
        "key": "wang2023turning",
        "author": "Wang, Binghui and Pang, Meng and Dong, Yun",
        "title": "Turning Strengths into Weaknesses: A Certified Robustness Inspired Attack Framework against Graph Neural Networks"
      },
      {
        "key": "chenunderstanding",
        "author": "Chen, Yongqiang and Yang, Han and Zhang, Yonggang and KAILI, MA and Liu, Tongliang and Han, Bo and Cheng, James",
        "title": "Understanding and Improving Graph Injection Attack by Promoting Unnoticeability"
      },
      {
        "key": "ju2023let",
        "author": "Ju, Mingxuan and Fan, Yujie and Zhang, Chuxu and Ye, Yanfang",
        "title": "Let graph be the go board: gradient-free node injection attack for graph neural networks via reinforcement learning"
      },
      {
        "key": "wang2024efficient",
        "author": "Wang, Binghui and Lin, Minhua and Zhou, Tianxiang and more",
        "title": "Efficient, direct, and restricted black-box graph evasion attacks to any-layer graph neural networks via influence function"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "sun2020adversarial",
        "author": "Sun, Yiwei and Wang, Suhang and Tang, Xianfeng and Hsieh, Tsung-Yu and Honavar, Vasant",
        "title": "Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach"
      },
      {
        "key": "ju2023let",
        "author": "Ju, Mingxuan and Fan, Yujie and Zhang, Chuxu and Ye, Yanfang",
        "title": "Let graph be the go board: gradient-free node injection attack for graph neural networks via reinforcement learning"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "zugner2018adversarial",
        "author": "Z{\\\"u}gner, Daniel and Akbarnejad, Amir and G{\\\"u}nnemann, Stephan",
        "title": "Adversarial attacks on neural networks for graph data"
      },
      {
        "key": "dai2018adversarial",
        "author": "Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le",
        "title": "Adversarial attack on graph structured data"
      },
      {
        "key": "xu2019topology",
        "author": "Xu, Kaidi and Chen, Hongge and Liu, Sijia and more",
        "title": "Topology attack and defense for graph neural networks: An optimization perspective"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zugner2018adversarial",
        "author": "Z{\\\"u}gner, Daniel and Akbarnejad, Amir and G{\\\"u}nnemann, Stephan",
        "title": "Adversarial attacks on neural networks for graph data"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "sun2020adversarial",
        "author": "Sun, Yiwei and Wang, Suhang and Tang, Xianfeng and Hsieh, Tsung-Yu and Honavar, Vasant",
        "title": "Adversarial Attacks on Graph Neural Networks via Node Injections: A Hierarchical Reinforcement Learning Approach"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "dai2018adversarial",
        "author": "Dai, Hanjun and Li, Hui and Tian, Tian and Huang, Xin and Wang, Lin and Zhu, Jun and Song, Le",
        "title": "Adversarial attack on graph structured data"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "mu2021a",
        "author": "Mu, Jiaming and Wang, Binghui and Li, Qi and Sun, Kun and Xu, Mingwei and Liu, Zhuotao",
        "title": "A Hard Label Black-box Adversarial Attack Against Graph Neural Networks"
      },
      {
        "key": "wang2022bandits",
        "author": "Wang, Binghui and Li, Youqi and Zhou, Pan",
        "title": "Bandits for Structure Perturbation-based Black-box Attacks to Graph Neural Networks with Theoretical Guarantees"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2022bandits",
        "author": "Wang, Binghui and Li, Youqi and Zhou, Pan",
        "title": "Bandits for Structure Perturbation-based Black-box Attacks to Graph Neural Networks with Theoretical Guarantees"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "wu2019adversarial",
        "author": "Wu, Huijun and Wang, Chen and Tyshetskiy, Yuriy and more",
        "title": "Adversarial examples on graph data: Deep insights into attack and defense"
      },
      {
        "key": "xu2019topology",
        "author": "Xu, Kaidi and Chen, Hongge and Liu, Sijia and more",
        "title": "Topology attack and defense for graph neural networks: An optimization perspective"
      },
      {
        "key": "zhu2019robust",
        "author": "Zhu, Dingyuan and Zhang, Ziwei and Cui, Peng and Zhu, Wenwu",
        "title": "Robust Graph Convolutional Networks Against Adversarial Attacks"
      },
      {
        "key": "entezari2020all",
        "author": "Entezari, Negin and Al-Sayouri, Saba and Darvishzadeh, Amirali and Papalexakis, Evangelos",
        "title": "All you need is low (rank) defending against adversarial attacks on graphs"
      },
      {
        "key": "tao2021adversarial",
        "author": "Tao, Shuchang and Shen, Huawei and Cao, Qi and Hou, Liang and Cheng, Xueqi",
        "title": "Adversarial Immunization for Certifiable Robustness on Graphs"
      },
      {
        "key": "zhao2021expressive",
        "author": "Zhao, Xin and Zhang, Zeru and Zhang, Zijie and Wu, Lingfei and Jin, Jiayin and Zhou, Yang and Dou, Dejing and Yan, Da",
        "title": "Expressive 1-lipschitz neural networks for robust multiple graph learning against adversarial attacks"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "mujkanovic2022defenses",
        "author": "Mujkanovic, Felix and Geisler, Simon and G{\\\"u}nnemann, Stephan and Bojchevski, Aleksandar",
        "title": "Are Defenses for Graph Neural Networks Robust?"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "jin2020certified",
        "author": "Jin, Hongwei and Shi, Zhan and Peruri, Venkata Jaya Shankar Ashish and Zhang, Xinhua",
        "title": "Certified robustness of graph convolution networks for graph classification under topological attacks"
      },
      {
        "key": "jia2020certified",
        "author": "Jia, Jinyuan and Wang, Binghui and Cao, Xiaoyu and Gong, Neil Zhenqiang",
        "title": "Certified robustness of community detection against adversarial structural perturbation via randomized smoothing"
      },
      {
        "key": "bojchevski2020efficient",
        "author": "Bojchevski, Aleksandar and Gasteiger, Johannes and G{\\\"u}nnemann, Stephan",
        "title": "Efficient robustness certificates for discrete data: Sparsity-aware randomized smoothing for graphs, images and more"
      },
      {
        "key": "wang2021certified",
        "author": "Wang, Binghui and Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil",
        "title": "Certified robustness of graph neural networks against adversarial structural perturbation"
      },
      {
        "key": "xia2024gnncert",
        "author": "Zaishuo Xia and Han Yang and Binghui Wang and Jinyuan Jia",
        "title": "Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"
      },
      {
        "key": "lai2023nodeawarebismoothingcertifiedrobustness",
        "author": "Yuni Lai and Yulin Zhu and Bailin Pan and Kai Zhou",
        "title": "Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "bojchevski2020efficient",
        "author": "Bojchevski, Aleksandar and Gasteiger, Johannes and G{\\\"u}nnemann, Stephan",
        "title": "Efficient robustness certificates for discrete data: Sparsity-aware randomized smoothing for graphs, images and more"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "wang2021certified",
        "author": "Wang, Binghui and Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil",
        "title": "Certified robustness of graph neural networks against adversarial structural perturbation"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "lecuyer2019certified",
        "author": "Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman",
        "title": "Certified robustness to adversarial examples with differential privacy"
      },
      {
        "key": "cohen2019certified",
        "author": "Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico",
        "title": "Certified adversarial robustness via randomized smoothing"
      },
      {
        "key": "hong2022unicr",
        "author": "Hong, Hanbin and Wang, Binghui and Hong, Yuan",
        "title": "Unicr: Universally approximated certified robustness via randomized smoothing"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "lai2023nodeawarebismoothingcertifiedrobustness",
        "author": "Yuni Lai and Yulin Zhu and Bailin Pan and Kai Zhou",
        "title": "Node-aware Bi-smoothing: Certified Robustness against Graph Injection Attacks"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "xia2024gnncert",
        "author": "Zaishuo Xia and Han Yang and Binghui Wang and Jinyuan Jia",
        "title": "Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "levine2020robustness",
        "author": "Levine, Alexander and Feizi, Soheil",
        "title": "Robustness certificates for sparse adversarial attacks by randomized ablation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "xia2024gnncert",
        "author": "Zaishuo Xia and Han Yang and Binghui Wang and Jinyuan Jia",
        "title": "Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "xia2024gnncert",
        "author": "Zaishuo Xia and Han Yang and Binghui Wang and Jinyuan Jia",
        "title": "Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "dietterich2000ensemble",
        "author": "Dietterich, Thomas G",
        "title": "Ensemble methods in machine learning"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "levine2020deep",
        "author": "Levine, Alexander and Feizi, Soheil",
        "title": "Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "xia2024gnncert",
        "author": "Zaishuo Xia and Han Yang and Binghui Wang and Jinyuan Jia",
        "title": "Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"
      },
      {
        "key": "yang2024distributed",
        "author": "Yang, Yuxin and Li, Qiang and Jia, Jinyuan and Hong, Yuan and Wang, Binghui",
        "title": "Distributed backdoor attacks on federated graph learning and certified defenses"
      },
      {
        "key": "li2025provably",
        "author": "Li, Jiate and Pang, Meng and Dong, Yun and Jia, Jinyuan and Wang, Binghui",
        "title": "Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "levine2020randomized",
        "author": "Levine, Alexander and Feizi, Soheil",
        "title": "(De) Randomized smoothing for certifiable defense against patch attacks"
      },
      {
        "key": "xiang2021patchguard",
        "author": "Xiang, Chong and Bhagoji, Arjun Nitin and Sehwag, Vikash and Mittal, Prateek",
        "title": "$\\{$PatchGuard$\\}$: A provably robust defense against adversarial patches via small receptive fields and masking"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "pei2023textguard",
        "author": "Pei, Hengzhi and Jia, Jinyuan and Guo, Wenbo and Li, Bo and Song, Dawn",
        "title": "Textguard: Provable defense against backdoor attacks on text classification"
      },
      {
        "key": "zhang2024text",
        "author": "Zhang, Xinyu and Hong, Hanbin and Hong, Yuan and Huang, Peng and Wang, Binghui and Ba, Zhongjie and Ren, Kui",
        "title": "Text-crs: A generalized certified robustness framework against textual adversarial attacks"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "jia2021intrinsic",
        "author": "Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil Zhenqiang",
        "title": "Intrinsic certified robustness of bagging against data poisoning attacks"
      },
      {
        "key": "jia2022certified",
        "author": "Jia, Jinyuan and Liu, Yupei and Cao, Xiaoyu and Gong, Neil Zhenqiang",
        "title": "Certified robustness of nearest neighbors against data poisoning and backdoor attacks"
      }
    ]
  }
]