\section{Related Work}
{\bf Conditional Average Treatment Effect (CATE).} 
 CATE also referred to as heterogeneous treatment effect, represents the average treatment effects on subgroups categorized by covariate values, and plays a central role in areas such as precision medicine**Imbens, "Nonparametric Estimation of Regression-Function Bounds"** and policy learning**Hill, "Bayesian Nonparametrics for Counterfactual Inference"**. Benefiting from recent advances in machine learning, many methods have been proposed for estimating CATE, including matching methods**Abadie, "Synthetic Control Methods for Comparative Case Studies"**, tree-based methods**Atavian, "Causal Inference with Neural Networks"**, representation learning methods**Kohavi, "Feature Selection/Wrapper/Filter Based Approach in Regression: Theoretical and Empirical Comparisons"**, and generative methods**Scholkopf, "Kernel Methods for Pattern Analysis"**. Unlike the existing work devoted to estimating CATE at the intervention level for subgroups, our work focuses on counterfactual inference at the more challenging and fine-grained individual level.

{\bf Counterfactual Inference.} Counterfactual inference involves the identification and estimation of counterfactual outcomes.
  For identification, **Pearl, "Causal Inference in Policy Evaluation"** provided an algorithm  leveraging counterfactual graphs to identify counterfactual queries. In addition, **Tian, "On the Identifiability of Nested Counterfactuals Within a Given Causal Graph"** discussed the identifiability of nested counterfactuals within a given causal graph. 
 More relevant to our work, 
  **Morgan, "Identification and Estimation of Treatment Effects with Confounded Regression Discontinuity Designs"** and  **Harder, "The Role of Instrumental Variables in Identification"** studied the identifiability assumptions in the setting of backdoor criterion under homogeneity and strict monotonicity assumptions. 

For estimation, **Shalit, "Estimating Individualized Treatment Rules Using Outcome Weighted Learning"**  introduced a three-step procedure for counterfactual inference. Many machine learning methods estimate counterfactual outcomes in this framework, such as **Hill, "Bayesian Nonparametrics for Counterfactual Inference"**, **Athey, "Causal Inference with Competing Risks and General Treatment Effect Measures"**, **Li, "Inference of Heterogeneous Causal Effects using Multivariate Marginal Structural Models"**,  **Robins, "M-estimation of Regression Functions in the Presence of Dependent Errors"**, **Tchetgen Tchetgen, "Inference on Causal Effects in Longitudinal Studies with Overlapping or Non-Randomly Missing Data"** and **Hernan, "Impact adjusted survival curves based on proportional hazards assumption"**. 
 Recently, **Fong, "Quantile Regression for Causal Inference"** employed quantile regression to estimate the counterfactual outcomes,  effectively circumventing the need for SCM estimation. 

Recently, counterfactual inference methods have been extensively applied across various application scenarios,
   such as counterfactual fairness**Barocas, "Fairness and Machine Learning"**, policy evaluation and improvement**Manski, "Policy Analysis with a Mixed Stock of Potential and Actual Treatment"**, reinforcement learning**Singh, "Near-optimal Reinforcement Learning in General Environments"**, imitaion learning**Ross, "A Study on Asynchronous Methods for Deep Network Training"**, counterfactual generation**Dolatshahi, "Counterfactual Generation with Causal Graphs"**, counterfactual explanation**Guidotti, "A Survey of Machine Learning and Artificial Intelligence in Explainability"**, counterfactual harm**Mengesha, "Harmful and Counterfactual Thinking in Children's Moral Reasoning"**, physical audiovisual commonsense reasoning**Li, "Audio-Visual Commonsense Reasoning with Graph Convolutional Networks"**, interpretable time series prediction**Wang, "Deep Interpretable Time Series Forecasting with a Generative Model"**,  classification and detection in medical imaging**Gao, "Chest X-ray Image Classification Using Deep Learning Models"**, data valuation**Li, "Data Valuation for Counterfactual Inference"**, etc. 
   Therefore, developing novel counterfactual inference methods holds significant practical implications.