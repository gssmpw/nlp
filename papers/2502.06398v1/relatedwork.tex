\section{Related Work}
{\bf Conditional Average Treatment Effect (CATE).} 
 CATE also referred to as heterogeneous treatment effect, represents the average treatment effects on subgroups categorized by covariate values, and plays a central role in areas such as precision medicine~\cite{Kosorok+Laber:2019} and policy learning~\cite{Dudik2011-ICML}. Benefiting from recent advances in machine learning, many methods have been proposed for estimating CATE, including matching methods~\cite{rosenbaum1983central,schwab2018perfect,yao2018representation}, tree-based methods~\cite{chipman2010bart,wager2018estimation}, representation learning methods~\cite{johansson2016learning,shalit2017estimating,shi2019adapting,wu2022learning,wang2023optimal}, and generative methods~\cite{louizos2017causal,yoon2018ganite}. Unlike the existing work devoted to estimating CATE at the intervention level for subgroups, our work focuses on counterfactual inference at the more challenging and fine-grained individual level.
 % at the intervention level for subgroups
   %However, these efforts focus on identification and do not address the challenges associated with the estimation.
 % leaving the question of how to estimate counterfactuals potentially intractable. 
 % In recent years, 
 %\vskip -0.15cm
 
 
{\bf Counterfactual Inference.} Counterfactual inference involves the identification and estimation of counterfactual outcomes.
  For identification,  \citet{Shpitser2007-UAI} provided an algorithm  leveraging counterfactual graphs to identify counterfactual queries. In addition, \citet{Correa2021-NIPS} discussed the identifiability of nested counterfactuals within a given causal graph. 
 More relevant to our work, 
  \citet{Lu-etal2020-attribution} and  \citet{Xie-etal2023-attribution} studied the identifiability assumptions in the setting of backdoor criterion under homogeneity and
strict monotonicity assumptions. 
% \cite{Nasr-Esfahany-2023-attribution} extended them in the setting of instrument variables. 
% Instead of aim at identifying and estimating counterfactual outcomes directly, 
Several methods focus on determining its bounds with less stringent assumptions, such as  \citet{Bakle-1994-UAI}, \citet{Tian2000}, \citet{pearl2009causality}, \citet{Pearl-etal2016-primer}, \citet{Finkelstein-2020-UAI}, \citet{Zhang-2022-ICML}, and \citet{Melnychuk2023}.  
%Appendix \ref{app-c} provides additional literature on counterfactual inference.
% These methods include works by 
 %\vskip -0.15cm

 
 For estimation, \citet{Pearl-etal2016-primer}  introduced a three-step procedure for counterfactual inference. Many machine learning methods estimate counterfactual outcomes in this framework, such as  \citet{Lu-etal2020-attribution}, \citet{Mesnard2021-ICML}, \citet{Brouwer2022}, \citet{Shah2022}, \citet{Yan2023}, \citet{Nasr-Esfahany-2023-attribution} and \citet{Chao-etal2023}. 
 % However, this framework relies on the availability of SCM or needs to estimate SCM a priori. 
 Recently, \citet{Xie-etal2023-attribution} employed quantile regression to estimate the counterfactual outcomes,  effectively circumventing the need for SCM estimation. 
 % Nonetheless, this method relies on that the conditional quantile functions for different counterfactual outcomes originate from the same model. It also necessitates estimating a distinct quantile value for each individual, which may cause instability in optimization. 
 In our work, we extend the above methods in both identification and estimation. 


Recently, counterfactual inference methods have been extensively applied across various application scenarios,
   %extensive work has applied counterfactual inference methods to a variety of application scenarios, 
   such as counterfactual fairness~\citep{kusner2017counterfactual, Zuo2023, Anthis2023-NIPS, Kavouras2023-NIPS, Chen2023-NIPS}, policy evaluation and improvement~\citep{Tang2023-NIPS, Saveski2023-NIPS, Chen-etal2023-NIPS}, reinforcement learning~\citep{Lu-etal2020-attribution, Tsirtsis2023-NIPS, Liu2023-NIPS, Shao2023-NIPS, Meulemans-etal-NIPS23, Haugh-ICML23, Zenati-ICML23}, imitaion learning~\citep{Sun2023-NIPS}, counterfactual generation~\citep{Yan2023, Prabhu2023-NIPS, Feder2023-NIPS, Ribeiro-ICML23}, counterfactual explanation~\citep{Kenny2023-NIPS, Raman2023-NIPS, Hamman-ICML23, Wu-eatl-ICML23, Ley-ICML23}, counterfactual harm~\citep{2022counterfactualharm, li2023trustworthy}, physical audiovisual commonsense reasoning~\citep{Lv2023-NIPS}, interpretable time series prediction~\citep{Yan-etal-ICML23},  classification and detection in medical imaging~\citep{Fontanella-ICML23}, data valuation~\citep{Liu-ICML23}, etc. 
   Therefore, developing novel counterfactual inference methods holds significant practical implications. 
    % for real-world applications.  
% dispersed across different disciplines and using slightly different terminology
% We also note that 

% 计量经济学还有一些作品.