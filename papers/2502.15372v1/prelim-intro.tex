 \section{Preliminaries}

\subsection*{Exponential Families}
\begin{definition}[Probability Density of Exp. Distributions]\label{def:exp}
    We define an {\it exponential family} of probability distributions as those
distributions whose density (relative to parameter $\boldsymbol{\theta} \in \Theta \subset \bR^D$) have the following general form:
\[
p(\xx|\boldsymbol{\theta}) = \hh(\xx)\cdot \exp\left(\boldsymbol{\theta}^{\top}\boldsymbol{T}(\xx)-A(\boldsymbol{\theta})\right),
\]
for a parameter $\boldsymbol{\theta}$, and functions $\hh$ and $\boldsymbol{T}$. The function $A$ is then automatically determined as the normalizing constant.
\end{definition}

This family captures several widely used probability distributions such as Gaussian, Gamma, Binomial, Bernoulli, and Poisson.


In particular the log density ratio for any two distributions in the exponential family, is an affine function of the reparmetrization $\boldsymbol{T}$
\begin{equation*}
    \ln(p(\xx | \boldsymbol{\theta}_1)/p(\xx | \boldsymbol{\theta}_2)) = \langle \boldsymbol{\theta}_1 - \boldsymbol{\theta}_2, \boldsymbol{T}(x)\rangle - A(\boldsymbol{\theta}_1) + A(\boldsymbol{\theta}_2). 
\end{equation*}
 \paragraph{Notation.} We use {\it high-probability bounds} to refer to sample complexity bounds that are true with probability at least $1-\delta$ with the dependence of $\delta$ on the sample complexity is $\log\frac{1}{\delta}$. We use $d_{TV}(p,q)$ to denote the total variation distance between distributions $p$ and $q$. The notation $\supp(p)$ is used to denote the support of the distribution $p$.
We define for $p \geq 1$, the discrepancy metric between two probability distributions as
\begin{equation*}
    R_{p}(p_1 || p_2) := \E_{\xx \sim p_2} \left(\frac{p_1(\xx)}{p_2(\xx)}\right)^p.
\end{equation*}

Note that this is closely related with the Renyi divergence between $p_1$ and $p_2$, that is $D_{p}(p_1 || p_2) = \frac{1}{p - 1} \exp(R_p(p_1 || p_2)$. The quantity $R_p$ will be more convenient for us.
\input{prelim}
