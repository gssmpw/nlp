\section{Related work}
\label{RL}

\subsection{Medical Image Segmentation} 
%As mentioned earlier, researchers typically apply distinct methods for 2D____ and 3D____ medical images. 2D models are used for planar images or slices, while 3D models are intended to learn volumetric features. % implicitly.
As mentioned earlier, researchers typically apply 2D models____ for planar images or slices, and 3D models____ to learn volumetric features implicitly.
____ introduced a versatile, self-adaptive deep learning framework specifically designed for medical image segmentation tasks, extending the U-Net architecture and its 3D version. 
____ pioneered the combination of Transformer-based architecture with Convolutional Neural Networks (CNNs) for medical image segmentation, applying a slice-by-slice inference on 3D volumes without considering interrelationships among slices. 
Some works____ utilize spatial-temporal cues and ____ introduce report texts as guidance to enhance segmentation performance. However, these models are limited to specific image modalities and tasks.  

\subsection{Medical Vision-Language Models} Medical vision-language models have achieved success across multiple downstream tasks, including diagnosis classification____, lesion detection____, image segmentation____, report generation____, and visual question answering____. 
____ designed auto-generation strategies for medical prompts and transferred large vision language models for medical lesion detection. 
____ incorporated text embedding learned from Contrastive Language-Image Pre-training (CLIP) to segmentation models.
____ proposed BiomedParse, a biomedical foundation model that can jointly conduct segmentation, detection and recognition across nine imaging modalities.
____ built a model based on Segment Anything Model____ for medical scenarios driven by text prompts, but the model focused on 3D medical volume segmentation and did not consider the sequential relationships between scans. 
To the best of our knowledge, we are the first to use medical text prompts to specify segmentation targets across medical image sequences.

% \textbf{Text Promptable Segmentation.} 
% TGANet TextSAM TP-SIS.

\subsection{Referring Video Object Segmentation}
____ were the first to propose inferring segmentation from a natural language input, extending two popular actor and action datasets with natural language descriptions.
____ constructed the first large-scale referring video object segmentation (RVOS) dataset and proposed a unified referring video object segmentation network.
____ and ____ presented Transformer-based RVOS frameworks, enabling end-to-end segmentation of the referred object.
____ designed explicit query propagation for an online model. 
____ aggregated inter- and intra-frame information via a semantic integrated module and introduced a visual-linguistic contrastive loss to apply semantic supervision on video-level object representations.
____ enabled multi-modal references to capture multi-scale visual cues and designed inter-frame feature communication for different object embeddings for tracking along the video.

Inspired by these works, the Referring Medical Image Sequence Segmentation task processes both 2D and 3D medical data into image sequences, enabling in-depth exploration of sequence-level consistency guided by text prompts.