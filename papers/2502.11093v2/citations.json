[
  {
    "index": 0,
    "papers": [
      {
        "key": "ronneberger2015unet",
        "author": "Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
        "title": "U-net: Convolutional networks for biomedical image segmentation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "cciccek20163dunet",
        "author": "{\\c{C}}i{\\c{c}}ek, {\\\"O}zg{\\\"u}n and Abdulkadir, Ahmed and Lienkamp, Soeren S and Brox, Thomas and Ronneberger, Olaf",
        "title": "3D U-Net: learning dense volumetric segmentation from sparse annotation"
      },
      {
        "key": "milletari2016vnet",
        "author": "Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad",
        "title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "ronneberger2015unet",
        "author": "Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas",
        "title": "U-net: Convolutional networks for biomedical image segmentation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "cciccek20163dunet",
        "author": "{\\c{C}}i{\\c{c}}ek, {\\\"O}zg{\\\"u}n and Abdulkadir, Ahmed and Lienkamp, Soeren S and Brox, Thomas and Ronneberger, Olaf",
        "title": "3D U-Net: learning dense volumetric segmentation from sparse annotation"
      },
      {
        "key": "milletari2016vnet",
        "author": "Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad",
        "title": "V-net: Fully convolutional neural networks for volumetric medical image segmentation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "isensee2021nnunet",
        "author": "Isensee, Fabian and Jaeger, Paul F and Kohl, Simon AA and Petersen, Jens and Maier-Hein, Klaus H",
        "title": "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chen2021transunet",
        "author": "Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Xiangde and Adeli, Ehsan and Wang, Yan and Lu, Le and Yuille, Alan L and Zhou, Yuyin",
        "title": "Transunet: Transformers make strong encoders for medical image segmentation"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "ji2021pns",
        "author": "Ji, Ge-Peng and Chou, Yu-Cheng and Fan, Deng-Ping and Chen, Geng and Fu, Huazhu and Jha, Debesh and Shao, Ling",
        "title": "Progressively normalized self-attention network for video polyp segmentation"
      },
      {
        "key": "painchaud2022echocardiography",
        "author": "Painchaud, Nathan and Duchateau, Nicolas and Bernard, Olivier and Jodoin, Pierre-Marc",
        "title": "Echocardiography segmentation with enforced temporal consistency"
      },
      {
        "key": "lin2023shifting",
        "author": "Lin, Junhao and Dai, Qian and Zhu, Lei and Fu, Huazhu and Wang, Qiong and Li, Weibin and Rao, Wenhao and Huang, Xiaoyang and Wang, Liansheng",
        "title": "Shifting more attention to breast lesion segmentation in ultrasound videos"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "li2023lvit",
        "author": "Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi",
        "title": "Lvit: language meets vision transformer in medical image segmentation"
      },
      {
        "key": "zhong2023ariadne",
        "author": "Zhong, Yi and Xu, Mengqiu and Liang, Kongming and Chen, Kaixin and Wu, Ming",
        "title": "Ariadne\u2019s Thread: Using Text Prompts to Improve Segmentation of Infected Areas from Chest X-ray Images"
      },
      {
        "key": "bui2024mmiunet",
        "author": "Bui, Phuoc-Nguyen and Le, Duc-Tai and Choo, Hyunseung",
        "title": "Visual-Textual Matching Attention for Lesion Segmentation in Chest Images"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "moon2022medvill",
        "author": "Moon, Jong Hak and Lee, Hyungyung and Shin, Woncheol and Kim, Young-Hak and Choi, Edward",
        "title": "Multi-modal understanding and generation for medical images and text via vision-language pre-training"
      },
      {
        "key": "medclip",
        "author": "Wang, Zifeng  and\nWu, Zhenbang  and\nAgarwal, Dinesh  and\nSun, Jimeng",
        "title": "{MedCLIP}: Contrastive Learning from Unpaired Medical Images and Text"
      },
      {
        "key": "chexzero",
        "author": "Tiu, Ekin and Talius, Ellie and Patel, Pujan and Langlotz, Curtis P and Ng, Andrew Y and Rajpurkar, Pranav",
        "title": "Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning"
      },
      {
        "key": "lu2023mizero",
        "author": "Lu, Ming Y and Chen, Bowen and Zhang, Andrew and Williamson, Drew FK and Chen, Richard J and Ding, Tong and Le, Long Phi and Chuang, Yung-Sung and Mahmood, Faisal",
        "title": "Visual language pretrained multiple instance zero-shot transfer for histopathology images"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "qin2023mvlm",
        "author": "Ziyuan Qin and Hua Hui Yi and Qicheng Lao and Kang Li",
        "title": "{MEDICAL} {IMAGE} {UNDERSTANDING} {WITH} {PRETRAINED} {VISION} {LANGUAGE} {MODELS}: A {COMPREHENSIVE} {STUDY}"
      },
      {
        "key": "huang2024adapting",
        "author": "Huang, Chaoqin and Jiang, Aofan and Feng, Jinghao and Zhang, Ya and Wang, Xinchao and Wang, Yanfeng",
        "title": "Adapting visual-language models for generalizable anomaly detection in medical images"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "zhao2023one",
        "author": "Zhao, Ziheng and Zhang, Yao and Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi",
        "title": "One model to rule them all: Towards universal segmentation for medical images with text prompts"
      },
      {
        "key": "li2023lvit",
        "author": "Li, Zihan and Li, Yunxiang and Li, Qingde and Wang, Puyang and Guo, Dazhou and Lu, Le and Jin, Dakai and Zhang, You and Hong, Qingqi",
        "title": "Lvit: language meets vision transformer in medical image segmentation"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "yan2022clinical-bert",
        "author": "Yan, Bin and Pei, Mingtao",
        "title": "Clinical-bert: Vision-language pre-training for radiograph diagnosis and reports generation"
      },
      {
        "key": "BioViL-T",
        "author": "Bannur, Shruthi and Hyland, Stephanie and Liu, Qianchu and Perez-Garcia, Fernando and Ilse, Maximilian and Castro, Daniel C and Boecking, Benedikt and Sharma, Harshita and Bouzid, Kenza and Thieme, Anja and others",
        "title": "Learning to exploit temporal structure for biomedical vision-language processing"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "singhal2023med-palm",
        "author": "Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others",
        "title": "Large language models encode clinical knowledge"
      },
      {
        "key": "moor2023med-flamingo",
        "author": "Moor, Michael and Huang, Qian and Wu, Shirley and Yasunaga, Michihiro and Dalmia, Yash and Leskovec, Jure and Zakka, Cyril and Reis, Eduardo Pontes and Rajpurkar, Pranav",
        "title": "Med-flamingo: a multimodal medical few-shot learner"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "qin2023mvlm",
        "author": "Ziyuan Qin and Hua Hui Yi and Qicheng Lao and Kang Li",
        "title": "{MEDICAL} {IMAGE} {UNDERSTANDING} {WITH} {PRETRAINED} {VISION} {LANGUAGE} {MODELS}: A {COMPREHENSIVE} {STUDY}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "liu2023clip-driven",
        "author": "Liu, Jie and Zhang, Yixiao and Chen, Jie-Neng and Xiao, Junfei and Lu, Yongyi and A Landman, Bennett and Yuan, Yixuan and Yuille, Alan and Tang, Yucheng and Zhou, Zongwei",
        "title": "Clip-driven universal model for organ segmentation and tumor detection"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "zhao2024biomedparse",
        "author": "Zhao, Theodore and Gu, Yu and Yang, Jianwei and Usuyama, Naoto and Lee, Ho Hin and Naumann, Tristan and Gao, Jianfeng and Crabtree, Angela and Abel, Jacob and Moung-Wen, Christine and others",
        "title": "BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "zhao2023one",
        "author": "Zhao, Ziheng and Zhang, Yao and Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi",
        "title": "One model to rule them all: Towards universal segmentation for medical images with text prompts"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "kirillov2023sam",
        "author": "Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others",
        "title": "Segment anything"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "gavrilyuk2018actor",
        "author": "Gavrilyuk, Kirill and Ghodrati, Amir and Li, Zhenyang and Snoek, Cees GM",
        "title": "Actor and action video segmentation from a sentence"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "seo2020urvos",
        "author": "Seo, Seonguk and Lee, Joon-Young and Han, Bohyung",
        "title": "Urvos: Unified referring video object segmentation network with a large-scale benchmark"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "wu2022referformer",
        "author": "Wu, Jiannan and Jiang, Yi and Sun, Peize and Yuan, Zehuan and Luo, Ping",
        "title": "Language as queries for referring video object segmentation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "botach2022mttr",
        "author": "Botach, Adam and Zheltonozhskii, Evgenii and Baskin, Chaim",
        "title": "End-to-end referring video object segmentation with multimodal transformers"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "wu2023onlinerefer",
        "author": "Wu, Dongming and Wang, Tiancai and Zhang, Yuang and Zhang, Xiangyu and Shen, Jianbing",
        "title": "Onlinerefer: A simple online baseline for referring video object segmentation"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "luo2024soc",
        "author": "Luo, Zhuoyan and Xiao, Yicheng and Liu, Yong and Li, Shuyan and Wang, Yitong and Tang, Yansong and Li, Xiu and Yang, Yujiu",
        "title": "Soc: Semantic-assisted object cluster for referring video object segmentation"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "yan2024referred",
        "author": "Yan, Shilin and Zhang, Renrui and Guo, Ziyu and Chen, Wenchao and Zhang, Wei and Li, Hongyang and Qiao, Yu and Dong, Hao and He, Zhongjiang and Gao, Peng",
        "title": "Referred by multi-modality: A unified temporal transformer for video object segmentation"
      }
    ]
  }
]