\section{Conclusion}

In this work, we examined how emotional intensity influences perceived convincingness. Using GPT4o to rephrase arguments with varying emotional impact, we developed a dynamic framework inspired by manipulation checks in psychology and social sciences. Our results show that GPT4o reliably generates counterpart arguments, preserving meaning while altering emotional tone.
For both humans and LLMs, convincingness is largely unaffected by emotions. However, when emotions do play a role, they more often enhance rather than weaken convincingness, particularly in political debates, where emotional appeal is frequently used as a persuasive strategy. Additionally, while LLMs broadly mirror human patterns, they struggle to capture emotional nuances.

Future research could explore \textbf{when and how} emotions influence convincingness across argument types. Investigating \textbf{specific emotions} \citep{greschner2024fearfulfalconsangryllamas} or \textbf{justified vs. unjustified emotions} and their persuasive effects may provide deeper insights. Enhancing LLMs' ability to capture emotional nuances through improved prompts or fine-tuning could further strengthen their reliability in evaluating emotional arguments.


\section*{Limitations \& Ethical concerns}
While our study provides insights into the relationship between emotional intensity and argument convincingness, several limitations should be acknowledged:
(1) We rely on a single model, GPT4o, for synthetic argument generation. While GPT4o demonstrates strong capabilities in controlled text modification, exploring multiple models could provide a more comprehensive understanding of how different architectures handle emotional rephrasing.
(2) We focus only on two languages, English and German. Expanding to additional languages, particularly those with different rhetorical traditions or cultural perspectives on emotional persuasion, would offer a broader cross-linguistic perspective.
(3) The topics of arguments differ across text domains, which may introduce variability in how emotional intensity interacts with convincingness. Ensuring more comparable topics across domains would help isolate the individual effects of topic and text domain, leading to a more precise analysis.
(4) We do not distinguish between different types of emotions (e.g., anger, joy, fear) or between justified and unjustified emotions, both of which could have varying impacts on argument convincingness. Future work could explore how different kinds of emotions influence persuasion to gain a more nuanced understanding of their effects. (5) We experiment with only three prompts to evaluate model responses, which may not fully reflect LLM performance. A broader range of prompts could yield more stable results.

A potential ethical concern arises from the possibility of leveraging the dataset to develop politically motivated agendas that rely on emotional appeal rather than factual reasoning. Since emotions can influence perceived convincingness, there is a risk that political actors or interest groups may use this dataset to craft emotionally charged arguments that manipulate public opinion rather than inform it. This could contribute to misinformation, polarization, and biased discourse, particularly in sensitive political debates.

We used ChatGPT solely for text refinement while writing this paper. All annotators provided consent for research use of their annotations via Google Forms.
