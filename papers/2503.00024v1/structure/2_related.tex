\section{Related Work}
This work primarily connects to (1) the interplay between emotions and argument convincingness, while also relating to (2) human-like biases in LLMs.


\paragraph{Emotion vs.\ convincingness}
Emotions have been shown to play a role in argument convincingness in both fields of computational argumentation \citep[e.g.][]{habernal-gurevych-2016-argument,wachsmuth-etal-2017-computational,greschner2024fearfulfalconsangryllamas} and philosophy/psychology \citep[e.g.][]{kennedy1991theory,konat2024pathos,benlamine2015emotions}. 

In NLP, emotional appeal is primarily studied within the context of logical fallacy in arguments \citep{evgrafova-etal-2024-analysing} or as a secondary focus in relation to argument convincingness \citep{greschner2024fearfulfalconsangryllamas}. 
The most relevant works include: \citet{habernal-gurevych-2016-argument} find that human annotators identify emotional aspects as positively contributing to argument convincingness. \citet{habernal2017argumentation} introduce an emotional appeal layer in a modified Toulmin argumentation model, showing that 6\% of arguments are purely emotional. \citet{wachsmuth-etal-2017-computational} analyze arguments across 15 dimensions, finding a weak positive correlation between emotional appeal and convincingness. \citet{lukin-etal-2017-argument} demonstrate that audience-specific factors improve belief change prediction, particularly for emotional arguments. \citet{greschner2024fearfulfalconsangryllamas} examine specific emotions, showing that joy and pride enhance convincingness, whereas anger reduces it.

Previous studies rely on fixed analyses that do not control for confounders. 
In contrast, we adopt a dynamic approach, controlling for confounding factors and examining how perceived convincingness changes with varying emotional intensity. Our methodology aligns with psychological manipulation checks \citep{hoewe2017manipulation,ejelov2020rarely}, treating emotional intensity as the manipulated variable and convincingness as the dependent variable.

Additionally, prior work has largely focused on English, except for \citet{greschner2024fearfulfalconsangryllamas}, who examine German arguments. Since emotional effects may vary across cultures, we study both English and German arguments. We also expand the scope by incorporating diverse text domains, including political debates, online portals, and curated human-written arguments, unlike previous studies limited to a single domain.

\iffalse
The most relevant works %\todo{SE: just one work?} 
to ours include: \citet{habernal-gurevych-2016-argument} manually examine human-written reasons explaining why one argument is considered more convincing than another in web discourse, finding that the emotional aspect as having a positive contribution is pointed out by the annotators. %\todo{SE: as having a positive contribution?} 
\citet{habernal2017argumentation} annotate web arguments using a modified Toulmin argumentation model, which includes an emotional appeal layer (among many others), finding that 6\% of the arguments are purely emotional without any logical reasoning. \citet{wachsmuth-etal-2017-computational} evaluate the arguments from \citet{habernal2017argumentation} across 15 dimensions derived from argumentation theories, including both convincingness (referred to as `effectiveness' in their work) and emotional appeal, finding a weak positive correlation between emotional appeal and convincingness. \citet{lukin-etal-2017-argument} investigate the relationship between the perceived convincingness of different types of arguments and audience variables in social media, demonstrating that incorporating audience-specific factors, such as personal beliefs and personality traits, improves classifier performance in predicting belief change, especially on emotional arguments (versus factual arguments). 
\citet{greschner2024fearfulfalconsangryllamas} inspect the interplay between specific emotions (e.g., joy, anger) and argument convincingness. Their results imply that positive emotions like joy and pride lead to higher convincingness, whereas negative emotions like anger correlate to lower convincingness.

To the best of our knowledge, all previous studies rely on fixed analyses that do not control for confounders, i.e., other factors affecting argument convincingness. Consequently, causal relationships between emotions and convincingness cannot be fully established. In contrast, we adopt a dynamic approach that controls for confounding factors, exploring how perceived convincingness changes with varying levels of emotional intensity for a given argument. Our setup is akin to the manipulation checks commonly used in psychology and social sciences \citep{hoewe2017manipulation,ejelov2020rarely}, where emotional intensity serves as the manipulated variable, and convincingness is the dependent variable being observed.

Besides, except for \citet{greschner2024fearfulfalconsangryllamas}, which focus on German arguments, previous studies are predominantly centered on English; however, the effect of emotions may vary across cultures.
\todo{SE: the effect of emotions may vary across cultures --- I guess you could bring this as a motivation}
In this work, we explore both English and German arguments. Furthermore, we experiment with more diverse text domains, including political debates, online portals, and curated human-written arguments, unlike prior studies that are limited to a single text domain.
\fi

\vspace{-.2cm}
\paragraph{Human-like biases in LLMs}
An array of studies has demonstrated human-like biases in LLMs \citep[e.g.,][]{liang2021towards,echterhoff-etal-2024-cognitive,10.1162/tacl_a_00673}. Social biases, such as sentiment, stereotype, and gender biases, have been extensively investigated \citep[e.g.,][]{huang-etal-2020-reducing,nadeem-etal-2021-stereoset,10.1145/3582269.3615599,viswanath2023fairpytoolkitevaluationsocial}.

Beyond social biases, LLMs also mimic human cognitive biases in reasoning and decision-making \citep{10.1093/pnasnexus/pgae233,hagendorff2023human,talboy2023challengingappearancemachineintelligence,echterhoff-etal-2024-cognitive,10.1162/tacl_a_00673,sumita2024cognitivebiaseslargelanguage,macmillan2024ir}. For instance, \citet{10.1093/pnasnexus/pgae233} show that LLMs, like humans, perform better when task semantics align with logical inference (`content effect’). Similarly, \citet{echterhoff-etal-2024-cognitive} find LLMs exhibit decision-making biases such as anchoring bias \citep{tversky1974judgment}, status quo bias \citep{samuelson1988status}, and framing bias \citep{tversky1974judgment}. Meanwhile, \citet{macmillan2024ir} analyze LLMs’ irrationality across 12 cognitive tasks \citep{kahneman1972subjective,bruckmaier2021tversky}, revealing both human-like errors and distinct deviations.

Although emotional appeal is not inherently a bias or fallacy but a persuasion strategy, it is crucial to examine whether LLMs' preferences align with human judgments, especially given their growing role in argument evaluation \citep[e.g.,][]{wachsmuth2024argument,rescala-etal-2024-language,mirzakhmedova2024large}. Inspired by studies on cognitive biases in LLMs, we investigate whether LLMs exhibit human-like behavior in how emotional intensity influences argument convincingness.

\iffalse
An array of studies has demonstrated the presence of human-like biases in LLMs \citep[e.g.,][]{liang2021towards,echterhoff-etal-2024-cognitive,10.1162/tacl_a_00673}. On the one hand, social biases in LLMs --- including (a.o.) sentiment bias, stereotype bias, and gender bias --- have been extensively investigated in recent years \citep[e.g.,][]{huang-etal-2020-reducing,nadeem-etal-2021-stereoset,10.1145/3582269.3615599,viswanath2023fairpytoolkitevaluationsocial}.

On the other hand, LLMs have been shown to mimic human cognitive biases in reasoning and decision-making tasks \citep{10.1093/pnasnexus/pgae233,hagendorff2023human,talboy2023challengingappearancemachineintelligence,echterhoff-etal-2024-cognitive,10.1162/tacl_a_00673,sumita2024cognitivebiaseslargelanguage,macmillan2024ir}. %particularly in models that are instruction-tuned or use reinforcement learning from human feedback \citep{10.1162/tacl_a_00673}. 
For instance, \citet{10.1093/pnasnexus/pgae233} demonstrate that the logical reasoning abilities of LLMs are influenced by the semantic content of tasks. Specifically, LLMs perform better when the semantic content of a task aligns with its logical inference (the so-called `content effect'), mirroring human behavior.
Similarly, \citet{echterhoff-etal-2024-cognitive} investigate a broad range of cognitive biases in decision-making, such as anchoring bias \citep{tversky1974judgment}, status quo bias \citep{samuelson1988status}, and framing bias \citep{tversky1974judgment}, finding that LLMs exhibit patterns analogous to human biases. Meanwhile, \citet{macmillan2024ir} explore the irrationality of LLMs across 12 cognitive tasks, including those defined by \citet{kahneman1972subjective} and \citet{bruckmaier2021tversky}. Their findings suggest that while LLMs display human-like irrationality on these tasks, their errors often deviate from human patterns.

While emotional appeal is not necessarily a bias or fallacy in arguments but rather a persuasion strategy, it is essential to understand whether LLMs' preferences align with that of humans, particularly given the growing interest in using LLMs for automatically evaluating arguments \citep[e.g.,][]{wachsmuth2024argument,rescala-etal-2024-language,mirzakhmedova2024large}. Inspired by those studies relevant to cognitive biases in LLMs, we explore whether LLMs exhibit human-like behavior in how judgments of argument convincingness are influenced by the perceived emotional intensity of arguments. 
\fi

