\begin{table*}[t]
\centering
\tabcolsep=4pt
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccccccc}
\toprule
\multirow{2}*{Model} & \multicolumn{3}{c}{{SQA}} & \multicolumn{4}{c}{{MQA}} & \multicolumn{2}{c}{{Synthetic}} & \multicolumn{1}{c}{{Code}} & \multirow{2}*{Avg.}\\
\cmidrule(lr){2-4} \cmidrule(lr){5-8} \cmidrule(lr){9-10} \cmidrule(lr){11-11}
 & MFQA-en & MFQA-zh & Qasper & HPQ & 2Wiki & GovRpt & Dur & PassR-en & PassR-zh & LCC & \\
\midrule
H2O & 0.428& 0.429& 0.308& 0.112& 0.101& 0.231& 0.208& 0.704& 0.421& 0.092& 0.303
\\
InfLLM & 0.474& 0.517& 0.356& 0.306& 0.250& 0.277& 0.257& 0.766& 0.486& 0.143& 0.383
\\
Quest & 0.495& 0.561& 0.365& 0.295& 0.245& 0.293& 0.257& 0.792& 0.478& 0.135& 0.392
\\
Exact-Top& 0.502& 0.605& 0.397& 0.321& 0.288& \underline{0.316}& 0.291& 0.810& 0.548& 0.156& 0.423\\
Full Attn & \textbf{0.512} & \underline{0.623}& \underline{0.409}& \underline{0.350} & \underline{0.305}& \textbf{0.324} & \underline{0.294}& \underline{0.830}& \textbf{0.560} & \underline{0.163} & \underline{0.437}\\
\midrule
\method{} & \underline{0.503}& \textbf{0.624} & \textbf{0.432} & \textbf{0.437} & \textbf{0.356}& {0.307}& \textbf{0.341} & \textbf{0.905}& \underline{0.550}& \textbf{0.232}& \textbf{0.469}\\
\bottomrule
\end{tabular}
}
\caption{Performance comparison between our \method{} and baselines on LongBench, including subsets in single document QA, multi-document QA, synthetic and code task categories. \method{} outperformed most of the baselines including Full Attention.}
\label{tab:longbench}

\end{table*}

