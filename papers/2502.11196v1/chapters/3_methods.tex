\section{Methodology}

\subsection{Dataset Construction}
\label{sec:dataset}

Given the challenges of conducting mechanistic interpretability analysis on Internet-scale corpus, we perform controlled experiments on synthetic data, following~\citet{physics3.1,physics3.2,physics3.3}.
We focus on factual knowledge that can be represented as triples of the form $(s, r ,a)$ containing subject $s$, relation $r$, and attribute $a$.
% For example, a piece of factual knowledge such as \textit{"Donald Trump is 78 years old"} can be represented as (\textit{Donald Trump, age, 78}).
We synthesize a pool of fictional knowledge entities based on heuristic rules using ChatGPT, ensuring that these fictional biographical knowledge is unavailable to LLMs in the pre-training phase.
Each knowledge entity is first assigned a unique name as the subject, and then associated with five relationsâ€”\textit{birth date}, \textit{city}, \textit{major}, \textit{university} and \textit{company}-and corresponding attributes.
To convert these entities into textual knowledge for training data, we fill them in predefined templates.
Considering real-world data scenarios and the perspectives of analysis, we further customize the training corpus from two aspects: \textit{knowledge type} and \textit{knowledge frequency}.

\paragraph{Knowledge Type}
We classify the new knowledge that the language model may need to acquire into two categories. 
One involves knowledge that already exists in the model's parameters but requires further learning of specific aspects (e.g., new relations).
This type of knowledge is referred to as \textit{relevant new knowledge} and denoted as $K_\text{rel}$.
The other type of knowledge is absent from the model's parameters, which is referred to as \textit{completely new knowledge} and denoted as $K_\text{compl}$.

\paragraph{Knowledge Frequency}
Considering the long-tail distribution of knowledge in real-world data, we model the frequency of knowledge entities in the corpus to follow an exponential distribution.
This ensures that the corpus for continual pre-training contains both high-frequency knowledge as well as long-tail knowledge.

More details of the pipeline of dataset construction are provided in Appendix \ref{app:dataset}.

\subsection{Model Training}

To conduct the knowledge acquisition experiment, we use three series of typical decoder-only LLMs to yield consistent findings on different architectures: \textit{GPT-2}, \textit{Llama}, and \textit{Phi}.
We continually pre-train the base models using a standard next-token prediction objective on the corpus described in Section~\ref{sec:dataset}.
Further details on the training configuration can be found in Appendix \ref{app:training}.

\subsection{Circuit Discovery}
\label{sec:circuit_discovery}

To facilitate the discovery of circuits over multiple checkpoints throughout continual pre-training, we select EAP-IG~\citep{eap-ig} from a range of circuit discovery techniques ~\citep{acdc,eap,information_flow_routes,eap-ig}, which assigns an importance score to each edge, balancing efficiency and faithfulness.
% we select an attribution-based method from a range of circuit discovery techniques ~\citep{acdc,eap,information_flow_routes,eap-ig}, which assigns an importance score to each edge, balancing efficiency and faithfulness.
% Specifically, we select EAP-IG~\citep{eap-ig}, an approach that leverages the parallels between edge attribute patching~\citep{eap} and gradient-based input attribution methods~\citep{ig}.
Given an edge $e=(u,v)\in{E}$ between nodes $u\in{N}$ and $v\in{N}$ with clean and corrupted activations $z_u$ and $z'_u$, EAP-IG scores the importance of $e$ as:
\begin{equation}
    S(e)=\left(z_u^{\prime}-z_u\right) \frac{1}{m} \sum_{k=1}^m \frac{\partial L\left(z^{\prime}+\frac{k}{m}\left(z-z^{\prime}\right)\right)}{\partial z_v}
    \label{eq:eap-ig}
\end{equation}
where $z$ refers to a sequence of token embeddings for one input, $z'$ refers to the token embeddings of the distinct, baseline input, and $m$ refers to the number of integrated gradient steps; we set $m=5$ as suggested by \citet{eap-ig}.
More details of circuit discovery are provided in Appendix \ref{app:circuit_discovery}.

After scoring all edges within a language model using EAP-IG, we identify a circuit by selecting the top $n$ edges with the highest absolute score as in \citet{eap}, ensuring that the selected edges collectively achieve over 70\% of the whole model's performance on the specific task.
Specifically, we retain 8k, 20k, 50k, and 50k edges for GPT-2 Small, GPT-2 Medium, TinyLlama, and Phi-1.5, respectively.
