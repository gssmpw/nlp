
\section{Hybrid sparsity-aware context parallelism algorithm}\label{appendix:algo}

The algorithm's pesudo code is listed in Algorithm~\ref{algo::cp}.
\begin{algorithm}[h]
\caption{Hybrid sparsity-aware context parallelism}\label{algo::cp}
\begin{algorithmic}[1]
\small
\Statex 

\Function{HybridSparseCP}{${Q}, {K}, {V}, {G_{hcp}}, G_{scp}$,}
\small
\Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Workflow from the perspective of each GPU (for simplicity, only the forward is shown).}}}
\Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {$G_{hcp}$ and $G_{scp}$ are the sparse HCP and SCP communication groups this GPU belongs to. }}}


\If {$|G_{hcp}| >1$}
\State $Q,K,V$ $\gets$ \texttt{LoadBalanceHCP}($Q,K,V,G_{hcp}$)
\EndIf

\If {$|G_{scp}| >1$}
\State $K, V$ $\gets$ \texttt{SelectiveCommSCP}($Q, K, V, G_{scp}$)
\EndIf
\State $Output$ $\gets$ \texttt{SparseAttn}($Q,K,V$)

\Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Redistribute the output if any sparse HCP operations.}}}
\If {$|G_{hcp}| >1$}
\State $Output$ $\gets$ \texttt{UnevenAlltoAll}($output,G_{hcp}$)
\EndIf
\EndFunction

\Function{LoadBalanceHCP}{${Q}, {K}, {V}, Group$}
    \Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Get the balanced head-wise workload allocation for each GPU by solving the optimal allocation problem periodically.}}}
    
    \State $plan \gets \texttt{GetLoadBalancePlan}$(Group,Head\_Sparsity)
    \Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Permute $QKV$ along the head dimension to prepare the comm data layout.}}}
    \State $Q,K,V \gets \texttt{Permute\_and\_Split(Q,K,V,plan)}$

    \State $Q,K,V \gets \texttt{UnevenAlltoAll}(Q,K,V,Group)$
   \State \Return $Q,K,V$
  
        

\EndFunction

\Function{SelectiveCommSCP}{${Q}, {K}, V, Group$}
 \Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Get the global critical KV indices for each GPU with the sparsity predictor}}}
 
\State $Critical\_{KV}\_idx \gets \texttt{Estimate\_with\_Predictor}()$


 \Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Exchange information to decide which local KV pairs to send to other GPUs.}}}

\State $KV\_idx\_to\_send \gets 
\texttt{UnevenAlltoAll}(Critical\_{KV}\_idx)$
 \Statex\quad\ {\textcolor{Maroon}{$\triangleright$ {Prepare local KV to send to other GPUs}}}
\State $KV\_to\_send \gets \texttt{Prepare\_KV\_to\_send}(KV\_idx\_to\_send)$ 
\State $Gathered\_KV  \gets \texttt{UnevenAlltoAll}(KV\_to\_send)$
\State $K,V \gets \texttt{MergeKV}(K,V,Gathered\_KV)$
\State \Return $K,V$

\EndFunction

\end{algorithmic}
\end{algorithm}


\section{Implementation details}\label{appendix:imple}

\noindent\textbf{Asynchronous CPU offloading for large KV indices.} For long video tokens and relatively low sparsity ratios, sparse computation can generate large KV index tensors (e.g., approximately 2GB for a 50K video token length at 80\% sparsity). To mitigate GPU memory limitations, we employ asynchronous CPU offloading to transfer the KV index after attention computation and pre-fetch it during the backward pass of its next block, if necessary.

\noindent\textbf{Estimation kernel.} We perform matrix multiplication on CUDA cores rather than tensor cores due to its memory-bound 'slim' shape. Unlike standard tiling in matrix multiplication, each Streaming Multiprocessor (SM) conducts the multiplication for multiple full rows and selects the \topk indices online by Bitonic Select. However, large \topk sizes (e.g. 10K per query) can burden the SM's shared memory and reduce parallelism. To address this, we split the process into two stages: first, we perform multiplication and determine the \topk threshold for each query; second, we select indices based on the threshold.



\section{Sparsity change over \sys's training on VideoGen}\label{appendix:videogen_sparsity}

Figure~\ref{figure:videogen_sparsity} illustrates the evolution of block-wise sparsity throughout the training process of \sys on the VideoGen dataset. Notably, the low-sparsity outliers are mainly those from the initial and final blocks.

\begin{figure}[]
  \centering
  \includegraphics[width=0.43\textwidth]{figures/videogen_sparsity.pdf} 
    \vspace{-0.1in}
\caption{The block-wise sparsity distribution throughout \sys training on VideoGen. }
  \label{figure:videogen_sparsity} 
\end{figure}







