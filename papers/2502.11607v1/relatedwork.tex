\section{Related Work}
\subsection{LLMs for Graph Combinatorial Optimization}

The integration of Large Language Models (LLMs) into solving Graph Combinatorial Optimization (GCO) problems has garnered significant attention in recent years. Several works have attempted to leverage LLMs for GCO problems from various perspectives. Jin et al.~\cite{jin2024large} provided a comprehensive survey on the application of LLMs on graphs, categorizing potential scenarios into pure graphs, text-attributed graphs, and text-paired graphs. They discussed techniques such as using LLMs as predictors, encoders, and aligners. Chen et al.~\cite{chen2024exploring} explored the potential of LLMs in graph machine learning, especially for node classification tasks, and investigated two pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. Liu et al.~\cite{liu2023towards} introduced the concept of Graph Foundation Models (GFMs) and classified existing work into categories based on their dependence on graph neural networks and LLMs. Ren et al.~\cite{ren2024survey} conducted a survey on LLMs for graphs, proposing a taxonomy to categorize existing methods based on their framework design.

Many studies have focused on using prompt engineering and optimization to extract the intrinsic knowledge of pretrained LLMs in the form of text or code. Wang et al.~\cite{wang2024can} proposed the NLGraph benchmark to evaluate LLMs on graph reasoning tasks and introduced Build-a-Graph and Algorithmic Prompting to enhance their performance. Iklassov et al.~\cite{iklassov2024self} introduced Self-Guiding Exploration (SGE) to improve LLM performance on combinatorial problems. Elhenawy et al.~\cite{elhenawy2024eyeballing, elhenawy2024visual} explored the use of multimodal LLMs to solve the Traveling Salesman Problem (TSP) through visual reasoning. Tang et al.~\cite{tang2024grapharena} introduced GraphArena, a benchmarking tool for evaluating LLMs on graph computational problems. Li et al.~\cite{li2024graphteam} proposed GraphTeam, a multi-agent system based on LLMs for graph analysis. Guo et al.~\cite{guo2023gpt4graph} conducted an empirical evaluation of LLMs on graph-structured data. Fatemi et al.~\cite{fatemi2023talk} explored encoding graph-structured data as text for LLMs. Hu et al.~\cite{hu2024scalable} introduced GraphAgent-Reasoner, a multi-agent collaboration framework for graph reasoning. Perozzi et al.~\cite{perozzi2024let} proposed GraphToken to explicitly represent structured data for LLMs. Cao et al.~\cite{cao2024graphinsight} proposed GraphInsight to improve LLM comprehension of graph structures. Feng et al.~\cite{feng2024beyond} introduced LLM4Hypergraph to evaluate LLMs on hypergraphs. Yuan et al.~\cite{yuan2024gracore} presented GraCoRe, a benchmark for assessing LLMs' graph comprehension and reasoning. Firooz et al.~\cite{firooz2024lost} examined the impact of contextual proximity on LLM performance in graph tasks. Skianis et al.~\cite{skianis2024graph} explored using pseudo-code prompting to improve LLM performance on graph problems. Agrawal et al.~\cite{agrawal2024exploring} designed graph traversal tasks to test LLMs' structured reasoning capabilities. Wang et al.~\cite{wang2024reasoning} investigated the influence of temperature on LLM reasoning performance. Dai et al.~\cite{dai2024revisiting} revisited LLMs' graph reasoning ability through case studies. Zhong et al.~\cite{zhong2024exploring} explored the impact of graph visualizations on LLM performance. Sanford et al.~\cite{sanford2024understanding} analyzed the reasoning capabilities of transformers via graph algorithms.

Other works have focused on training graph foundation models using dense embeddings from LLM pretraining. Drakulic et al.~\cite{drakulic2024goal} proposed GOAL, a generalist model for solving multiple combinatorial optimization problems. Jiang et al.~\cite{jiang2024unco} introduced UNCO, a unified framework for solving various COPs using LLMs. Anonymous~\cite{anonymous2024solving} proposed a unified model for diverse CO problems using a transformer backbone. Chai et al.~\cite{chai2023graphllm} introduced GraphLLM to boost the graph reasoning ability of LLMs. Wei et al.~\cite{wei2024rendering} proposed GITA, a framework integrating visual and textual information for graph reasoning.


\subsection{Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought Methods}
The Chain-of-Thought (CoT) prompting technique, introduced by Wei et al. \cite{wei2022chain}, demonstrates that generating intermediate reasoning steps can significantly improve LLMs' performance on complex reasoning tasks. This method was further extended by Yao et al. \cite{yao2024tree}, who proposed the Tree of Thoughts (ToT) framework, enabling exploration over coherent units of text (thoughts) to enhance problem-solving abilities. The ToT approach allows LMs to consider multiple reasoning paths and self-evaluate choices, significantly improving performance on tasks requiring non-trivial planning or search. Besta et al. \cite{besta2024graph} introduced the Graph of Thoughts (GoT), which advances prompting capabilities by modeling LLM-generated information as an arbitrary graph. This approach enables combining arbitrary LLM thoughts into synergistic outcomes and enhances thoughts using feedback loops. Besta et al. \cite{besta2024demystifying} further demystified the concepts of chains, trees, and graphs of thoughts, providing a taxonomy of structure-enhanced LLM reasoning schemes. These studies highlight the importance of structured reasoning topologies in improving LLMs' problem-solving abilities.

\subsection{Self-Correction, Planning, and Search Strategy Learning}
Huang et al. \cite{huang2024large} examined the role of self-correction in LLMs, finding that intrinsic self-correction without external feedback often fails to improve reasoning accuracy. In contrast, Lehnert et al. \cite{searchformer} proposed the Searchformer model, which predicts the search dynamics of the A* algorithm, significantly outperforming traditional planners on complex decision-making tasks. Gandhi et al. \cite{gandhi2024stream} introduced the Stream of Search (SoS) approach, teaching language models to search by representing the process as a flattened string. This method significantly improved search accuracy and enabled flexible use of different search strategies.