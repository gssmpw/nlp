\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage[small,bf]{caption}
\usepackage{authblk}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{enumitem}

% \usepackage{forest}
% \usepackage{tikz}
% \usepackage{amssymb}
% \usepackage{times}
% \usepackage{soul}
% \usepackage{url}
% \usepackage[hidelinks]{hyperref}
% \usepackage[utf8]{inputenc}
% \usepackage[small]{caption}
% % \usepackage{ragged2e}
% \usepackage[dvipsnames]{xcolor}
% \usepackage{hyperref}
% \usepackage{natbib}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}
% \usepackage{natbib}

%\hypersetup{
%    colorlinks = true,
%    allcolors = {purple},
%    linkbordercolor = {white},
%}

\usepackage{siunitx}
\usepackage{tcolorbox}
\usepackage{listings}

\newcommand{\bbR}{\mathbb{R}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    % numbers=left,                    
    % numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmiccomment}[1]{\hfill $\triangleright$ \textcolor{blue}{\small #1}}
% \usepackage{algpseudocode}

% \usepackage[ruled,boxed]{algorithm2e}
\usepackage{stfloats}
\usepackage{makecell}  %单元格内换行
\usepackage{enumerate} %enumerate的标签类型
\usepackage{color}     %字体颜色
\usepackage{titlesec}
\usepackage{array} % 在导言区添加该包
\newcolumntype{C}{>{\centering\arraybackslash}p{1.5cm}} % 定义固定宽度列，1.2cm 是示例宽度，可调整
\usepackage{threeparttable}  % 表格专用脚注
\usepackage{booktabs}         % 推荐配合使用（非必须）

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\newcounter{template}%        counter for templates
\newcounter{algorithm_saved}% the real counter for algorithms
\makeatletter
\newenvironment{template}[1][htb]{%
	\renewcommand{\ALG@name}{Program Template}% Update algorithm name
	\setcounter{algorithm_saved}{\value{algorithm}} % switch to using the template counter
	\setcounter{algorithm}{\value{template}}% save the current number of algorithms
	\begin{algorithm}[#1]%
	}{\end{algorithm}
	\setcounter{template}{\value{algorithm}}% save the current number of templates
	\setcounter{algorithm}{\value{algorithm_saved}}% restore the algorithm counter
}
\makeatother

\usepackage[toc,header]{appendix}
\usepackage{minitoc}

\renewcommand \thepart{}
\renewcommand \partname{}

%\input defs.tex
\allowdisplaybreaks

% \bibliographystyle{alpha}

\title{GraphThought: Graph Combinatorial Optimization with Thought Generation}
\author[1]{Zixiao Huang}
\author[2,5]{Lifeng Guo}
\author[1]{Junjie Sheng}
\author[1]{Haosheng Chen}
\author[3]{Wenhao Li\thanks{\texttt{whli@tongji.edu.cn}}}
\author[3,4]{Bo Jin}
\author[2,5]{Changhong Lu}
\author[1,2,5]{Xiangfeng Wang\thanks{\texttt{xfwang@cs.ecnu.edu.cn}}}

\affil[1]{School of Computer Science and Technology, East China Normal University}
\affil[2]{School of Mathematical Sciences, East China Normal University}
\affil[3]{School of Computer Science and Technology, Tongji University}
\affil[4]{Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University}
\affil[5]{Key Laboratory of Mathematics and Engineering Applications, MoE, East China Normal University}

\date{}
\begin{document}

\doparttoc % Tell to minitoc to generate a toc for the parts
\faketableofcontents % Run a fake tableofcontents command for the partocs

\maketitle

\begin{abstract}
% Large language models (LLMs) have demonstrated remarkable capabilities in addressing complex natural language tasks. To fully harness these capabilities, prompt optimization has emerged as an essential technique for effectively guiding in specific tasks. One of the primary advantages of prompt optimization is its ability to significantly enhance LLM performance without necessitating retraining, thereby providing an efficient approach to model adaptation. However, designing effective prompts manually can be highly time-consuming and labor-intensive. To address these challenges, various automated prompt optimization techniques have been proposed, garnering considerable research interest. This survey provides a comprehensive overview of these techniques and outlines several future directions for prompt optimization, such as 
Large language models (LLMs) have demonstrated remarkable capabilities across various domains, especially in text processing and generative tasks. 
Recent advancements in the reasoning capabilities of state-of-the-art LLMs, such as OpenAI-o1, have significantly broadened their applicability, particularly in complex problem-solving and logical inference. 
However, most existing LLMs struggle with notable limitations in handling graph combinatorial optimization
(GCO) problems. 
To bridge this gap, we formally define the Optimal Thoughts Design (OTD) problem, including its state and action thought space. 
We then introduce a novel framework, \textbf{GraphThought}, designed to generate high-quality thought datasets for GCO problems. 
Leveraging these datasets, we fine-tune the Llama-3-8B-Instruct model to develop Llama-GT. 
Notably, despite its compact 8B-parameter architecture, Llama-GT matches the performance of state-of-the-art LLMs on the GraphArena benchmark. 
Experimental results show that our approach outperforms both proprietary and open-source models, even rivaling specialized models like o1-mini. 
This work sets a new state-of-the-art benchmark while challenging the prevailing notion that model scale is the primary driver of reasoning capability.
\end{abstract}

\section{Introduction}\label{sec:intro}

Originally designed for textual data, Large Language Models (LLMs) are increasingly being applied to tasks beyond language processing.
For example, in robotics and planning, LLMs help guide agents through structured environments~\cite{huang2022language,andreas2022language}, while in theory-of-mind reasoning, they maintain and update belief graphs for different agents~\cite{adhikari2020learning,ammanabrolu2021learning}. 
Furthermore, LLMs are employed in structured commonsense reasoning, where they generate graph-based action plans to achieve objectives with complex prerequisites~\cite{tandon2019wiqa,madaan2022language}. 
Additionally, in multi-hop question answering, LLMs uncover connections and paths across vast networks of entities and concepts~\cite{creswell2023selectioninference}. 
Collectively, these applications highlight the growing use of LLMs in tasks with underlying graphical structures, achieving promising early results~\cite{wang2024can}.

Building on this initial success, some work has explored the feasibility of applying LLMs to explicit, standard graph tasks~\cite{zhang2024llm4dyg,zi2024prog,li2024glbench,liu2023evaluating}. 
Unlike real-world graph tasks with rich node and/or edge information, this paper focuses on more principled and abstract graph combinatorial optimization (GCO) problems—typically requiring systematic traversal or search algorithms to solve~\cite{grapharena}.
Consider the task of finding the shortest path: the model must understand the entire graph structure, identify relevant nodes, logically deduce multiple steps to trace paths between nodes, and perform calculations to arrive at a correct solution. 
GCO problems have wide-ranging applications, including in medicine, engineering, operations research, and management~\cite{paschos2014applications}, and have driven the development of discrete mathematics and theoretical computer science for a century~\cite{kuhn1955hungarian,kruskal1956shortest,ford1956maximal}.
Moreover, because GCO problems often involve optimizing an objective function subject to discrete constraints in the solution space—frequently NP-hard~\cite{zhang2023let}—enhancing LLMs' ability to solve GCO problems is crucial for advancing their general reasoning and planning capabilities for complex tasks.

In fact, several works have already attempted to leverage LLMs for GCO problems from different perspectives~\cite{jin2024large,chen2024exploring,liu2023towards,ren2024survey}. 
Some approaches use prompt engineering and optimization to extract the intrinsic knowledge of pretrained LLMs in the form of text~\cite{wang2024can,iklassov2024self, elhenawy2024eyeballing, elhenawy2024visual, tang2024grapharena, li2024graphteam, guo2023gpt4graph, fatemi2023talk, hu2024scalable, perozzi2024let, cao2024graphinsight, feng2024beyond, yuan2024gracore, firooz2024lost, skianis2024graph, agrawal2024exploring, wang2024reasoning, dai2024revisiting, zhong2024exploring, sanford2024understanding} or code~\cite{anonymous2024efficient, anonymous2024llmsolver, li2024can, wu2024grapheval2000, borazjanizadeh2024navigating}. 
Some other works have trained graph foundation models in non-text spaces using dense embeddings from LLM pretraining~\cite{drakulic2024goal, jiang2024unco, anonymous2024solving, chai2023graphllm, wei2024rendering}. 
These methods might have variations in efficiency and performance, they still fall significantly short of commercial solvers such as Gurobi, raising questions about their practicality.
We argue that the paradigm of directly mapping problems to solutions using LLMs, as seen in previous work, overlooks the inherent solving patterns of GCO problems, which is the primary reason for limited performance. 
In natural language generation tasks, logical transitions between words, sentences, and even paragraphs are usually smooth.
However, solving GCO problems typically requires long-horizon reasoning, planning, and searching from the problem to the solution. 
This raises an intuitive question: 
\textit{can we incorporate the search principles of classical GCO solvers into the LLM's output process?}

Similar ideas have been applied to improve LLMs' general task-solving ability, such as simulating human thinking processes and generating intermediate thoughts before producing a response.
Methods like chain-~\cite{wei2022chain}, tree-~\cite{yao2024tree} and graph-of-thoughts~\cite{besta2024graph} prompting encourage step-by-step reasoning~\cite{besta2024demystifying}.
While these techniques are often effective, they can sometimes degrade performance due to self-enforcing~\cite{huang2024large}. 
Moreover, techniques that work well on one dataset may not generalize to others due to variations in the type of reasoning involved (e.g., spatial reasoning vs. mathematical reasoning)~\cite{searchformer,wu2024thinking}.
These limitations also apply to works that attempt to solve GCO problems using similar approaches~\cite{luo2024graphinstruct, searchformer, chen2024graphwiz, zhang2024can, ouyang2024gundam, gandhi2024stream}. 
These works construct thoughts in a forward manner by unrolling traditional search algorithms or automatically generating thoughts using LLMs, then injecting them into the generation process through supervised fine-tuning. 
However, thought generation in GCO presents a unique challenge: 
\textit{for NP-hard or NP-complete problems, no efficient traditional (heuristic) search methods exist, rendering forward thought construction infeasible.}

To address this, this paper focuses on using thought generation methods to inject search principles, thereby enhancing LLMs' ability to generate high-quality GCO solutions. 
Specifically, we design a universal thought representation and formally define an Optimal Thoughts Design (OTD) problem tailored for GCO tasks. After that, we propose GraphThought, a novel framework for fine-tuning LLMs with reasoning thought generation. Within this framework, we introduce forward, constructive thought design methods for simpler problems, as well as reverse, backtracking thought design methods for more complex problems.
Applying the GraphThought framework, we fine-tune the Llama-3-8B-Instruct model to
develop Llama-GT, and evaluate it across various different GCO tasks. 
These tasks range from local to global, from polynomial-time solvable to NP-hard, and involve graphs with anywhere from a few to dozens of nodes. 
In some tasks, Llama-GT even gets close to the performance upper bound set by Gurobi.

% 1. 我们定义了优化问题（包括状态空间、动作空间的设计）
% 2. 我们提出了算法框架 
% 3. 有好的效果 我们使用该方法来生成优质推理数据集，微调llama-3-8b-instruct模型，
% 1. 在大部分情况下超过加上和不加few-shot example的现有流行大模型（比如Deep Seek-V3， QWQ-32B）
% 2. 超过code-based approaches；
% 3. 超过直接用答案来微调的模型；
% 4. 性能超过自动化生成thought的框架STaR
% 5. 接近o1-mini和deepseek-r1推理大模型的性能，并在某些任务上（比如mis）展现出超越两个推理大模型的性能
% 6. 在采用Best-of-N策略后，多任务的平均性能有所提升，并能够胜过人工设计的启发式方法。
%\smallskip
%\noindent {\bf Superior Reasoning Performance:} We leverage our method to generate high-quality reasoning datasets and fine-tune the Meta-Llama-3-8B-Instruct model. The fine-tuned model consistently outperforms popular large models such as DeepSeek-V3 and QWQ-32B, surpasses code-based approaches and models fine-tuned directly on answers, and outperforms the automated reasoning dataset generation framework STaR. Our approach achieves results comparable to o1-mini and DeepSeek-R1, even exceeding them in specific tasks like Maximum Independent Set. Furthermore, incorporating a Best-of-N strategy enhances multi-task performance, surpassing human-designed heuristic methods.

Our main contributions are as follows: 1) We formalize the OTD problem with state thought space $\mathbb{S}$ and action thought space $\mathbb{A}$, which facilitates the systematic generation of reasoning thoughts. 2) Within the GraphThought framework, we propose dual thought generation frameworks: a forward (heuristic-guided) one and a backward (solver-guided) one for GCO problems. 3) The state-of-the-art performance of our approach is evidenced by the fine-tuning of Llama-3-8B-Instruct, which achieves superior accuracy on GraphArena, outperforming both
proprietary and open-source LLM by significant margins 
% (e.g., +60\% on MVC) 
and approaching the performance of commercial solver Gurobi.

% \begin{itemize}
%     \item {\bf Enhanced Reasoning Capabilities for Combinatorial Optimization:} We propose a systematic methodology to generate high-quality reasoning trajectories through multi-strategy integration. This framework enables fine-tuning of foundational large language models (LLMs), improving their ability to solve combinatorial optimization problems via enhanced logical inference and stepwise reasoning.
%     \item {\bf Comprehensive Empirical Validation:} We rigorously evaluate our approach on ten classical graph combinatorial optimization problems. Experimental results demonstrate an improvement in LLM reasoning accuracy (e.g., XXXXXXX, +22\% F1-score on average) compared to baseline methods.
%     \item {\bf Automated Reasoning Framework:} We propose a novel dual-layer optimization paradigm: A meta-optimization layer that strategically combines diverse reasoning strategies to improve the quality of prompting thoughts, and a task-execution layer that implements concrete algorithmic programs based on the selected strategies.
% \end{itemize}

\section{Problem Formulation}

This section aims to formalize the key research problems addressed in this work. 
In recent years, we have observed significant advancements in LLMs, which exhibit remarkable capabilities across various scientific and engineering fields. 
However, when tackling more complex mathematical problems that require advanced reasoning and domain-specific expertise, a critical research gap remains in adapting LLMs to these tasks through systematic fine-tuning approaches.

Combinatorial optimization problems are a class of mathematical optimization problems where the goal is to find the best possible solution from a finite or countably infinite set of discrete possibilities. 
Solving such problems typically need carefully designed heuristic algorithms derived from rigorous mathematical analysis. 
These algorithms embody sophisticated strategies to balance solution quality and computational efficiency. 
A fundamental challenge lies in incorporating the search principles of heuristic algorithms into learnable reasoning thoughts for LLMs, enabling knowledge transfer while preserving algorithmic efficiency. 
We focus on GCO problems because graphs naturally model a variety of combinatorial optimization problems, such as the shortest path, maximum independent set (MIS), and traveling salesman problems (TSP). A graph represents discrete entities through nodes and their connections. For a graph $G = (V,E)$, the node set $V = \{v_1, \ldots, v_n\}$ contains $n$ nodes, while the edge set $E = \{e_1,\ldots, e_m\}$ defines $m$ adjacency relationships. An edge $e=(v_i,v_j)$ denotes adjacency of nodes $v_i$ and $v_j$.

Formally, let ${\cal{F}}: ({\rm {LLM}},D) \rightarrow {\rm {LLM}}_D$ denote the supervised fine-tuning process mapping a foundation LLM to its fine-tuned version ${\rm {LLM}}_D$ through the training dataset $D$. The evaluation metric ${\cal{M}}: {\rm {LLM}}_D \rightarrow \bbR^+$ measures model performance.
%over the testing instance dataset $I$.
The core optimization challenge can be formalized as:
\begin{equation}\label{prob:core_problem}
    D^* = \arg \min_{D} {\cal{M}} \big( {\cal{F}} (\text{LLM},D) \big),
\end{equation} where $D^*$ is the optimal training dataset given LLM, ${\cal{F}}$, and ${\cal{M}}$. 
%The formulation \eqref{prob:core_problem} is a large-scale black-box optimization problem, and calculating the optimal solution within a limited time is nearly infeasible.
The formulation \eqref{prob:core_problem} constitutes a combinatorial optimization challenge over the exponentially large space of possible training datasets $D$. Three key difficulties emerge: 1) The discrete solution space prohibits gradient-based optimization; 2) The black-box nature of ${\cal{M}}$ prevents analytical evaluation; 3) The computational cost of evaluating ${\cal{M}}$ grows super-linearly with instance size.
It becomes important to efficiently compute high-quality approximate optimal solutions of the formulation \eqref{prob:core_problem}.

Thoughts of solving specific instances of math problems can be viewed as high-quality training data for fine-tuning LLMs and thus developing enhanced thoughts is critical for the creation of superior training datasets.
In the following, we will propose a series of thought generation methods to establish thoughts as one kind of approximate suboptimal solutions for the formulation \eqref{prob:core_problem}.
 
The representation and design of thoughts are typically a promising research direction in order to enhance the reasoning capabilities of LLMs.
The thought generation process can be modeled as to solve an approximate optimal solution $D' \subset \hat{D}$ for the formulation \eqref{prob:core_problem}, where $\hat{D}$ denotes the set of all training data with thoughts as content. For GCO problems, there are mainly two kinds of thoughts. One kind is to decide the following available action executed on the instance and the other kind is to show the current solving state.
A hierarchical decision problem in generating these kinds of thoughts is govern as: 
\begin{equation}\label{prob:otd}
    \left\{\begin{array}{l}
        {\hbox{Choose optimal}} \ A^*\subset \mathbb{A} , S^* \subset \mathbb{S}, \\
        {\hbox{Constructing program}} \  {\cal{P}}\ {\hbox{by}}\ A^*, S^*.
    \end{array}\right.
\end{equation}
% \begin{gather}
%     (A, S) \leftarrow \mathbb{A} \times \mathbb{S} \\
%    P \leftarrow (A, S)
% \end{gather}
where $\mathbb{A}$ and $\mathbb{S}$ denote the action thought space and state thought space for a GCO problem respectively. 
The first item is to choose optimal $A^*$ from $\mathbb{A}$ and optimal $S^*$ from $\mathbb{S}$ according to the characteristics of the GCO problem, where $A$ encapsulates core algorithmic operations while $S$ maintains dynamic problem-solving states. The second item is to incorporate all chosen thoughts of $A^*$ and $S^*$ into a program template $\cal{P}$, which is used to generate specific thoughts in solving a GCO instance. 

Furthermore, the OTD problem is to generate the optimal thought set $A^*$ and $S^*$ to construct $\cal{P}$ for a GCO problem, which is the key problem that we want to solve in this work. 
To emphasize, the optimal thoughts dataset in OTD  might not be the optimal solution of the formulation \eqref{prob:core_problem}, but it can be considered as a high-quality approximate solution.

\section{The GraphThought Framework}\label{sec:method}

% \subsection{Overall framework}

% The fine-tuning workflow with thoughts generation for LLMs is formalized in Algorithm \ref{algo:g_t_d}.
% Given a task $\tau$, the hierarchical decision system $(HDS_{outer}, HDS_{inner})$ derives $P$ based on characteristics of $\tau$.
% $HDS_{outer}$ is responsible for generating a combination of actions $A$ and states $S$ from given action thought set $\mathbb{A}$ and state thought set $\mathbb{S}$ which we concluded 25 items provided in appendix\ref{app:a_s}. $HDS_{inner}$ is to create the program $P$ with chosen actions and states.

% Next the program template  $P$ produces a set of reasoning thought dataset $T$ for LLM fine-tuning.
% Here $A$ contains some core algorithmic thoughts for solving $\tau$, $S$ includes thoughts to show and update the current solving situations, and $P$ acts as an algorithm to solve $\tau$ and, at the same time, generates the solving thoughts.

% \begin{algorithm}[hbt]
%     \caption{Thought-Enhanced LLM Fine-Tuning Framework}
%     \begin{algorithmic}[1]
%         \label{algo:g_t_d}
%         \REQUIRE A math task $\tau$, the max Iterations $n$, hierarchical decision systems $HDS_{outer}$ and $HDS_{inner}$.
%         \STATE $(A, S) \gets HDS_{outer}(\tau, \mathbb{A}, \mathbb{S})$
%         \STATE $P \gets HDS_{inner}(\tau, A, S)$
%         \STATE Initialize corpus $T \leftarrow \emptyset$
%         \FOR{$i = 1$ \text{ to } $n$}
%             \STATE Sample instance $I_i$
%             \STATE Generate thought $t_i \leftarrow P(I_i)$
%             \STATE $T \leftarrow T \cup\{t_i\}$
%         \ENDFOR
%         \STATE Fine-Tune LLM with $T$
%     \end{algorithmic}
% \end{algorithm}

% Our implementation employs manually designed $HDS_{outer}$ and $HDS_{inner}$ components to do OTD for LLMs in this work, though the framework supports integration with automated program synthesis systems like FunSearch. Section \ref{exp:llm_gen} provides empirical validation of this hybrid approach.

% For the OTD problem, we call the process of generating $A$, $S$, and $P$ the Meta Thoughts Programming (MTP), which is a thought generation process.  This section introduces two complementary methods to do MTP for GCO problems by combining heuristic algorithms or instance solvers.

% The heuristic distillation approach decomposes classical algorithms to extract fundamental thought generation heuristic rules. Conversely, the solution-driven induction method generate thoughts following the instruction of a high quality solution with the purpose of grasping profound, subtle, and undiscovered principles from answers. These methods form a duality: A forward, constructive MTP embodies explicit knowledge through heuristic algorithms and a reverse, backtrack MTP Implements implicit pattern extraction via the high-quality solution. Two applications of combinatorial optimization problems show the details of these two frameworks.


\subsection{The Overall Framework}
\label{subsec:framework}

We present GraphThought, a novel framework for fine-tuning LLMs with reasoning thought generation, as formalized in Algorithm~\ref{algo:g_t_d}. The framework architecture comprises two core modules that collaboratively generate task-specific reasoning programs through state and action thoughts selection and program construction, denoted as $\textbf{Selector}$ and $\textbf{Constructor}$ respectively.

\noindent - {\bf{Selector}}: For a given task $\tau$, this module performs dynamic selection of \textit{action-state pairs} $(A, S)$ from predefined action thought space $\mathbb{A}$ and state thought space $\mathbb{S}$. The selection mechanism adaptively adjusts its strategies to capture the essential characteristics of $\tau$, ensuring context-aware component selection;

\noindent - {\bf{Constructor}}: This module operates as a program synthesis engine that methodically assembles the selected $(A, S)$ into an executable reasoning program ${\cal{P}}$. 

For the predefined action thought space $\mathbb{A}$ and state thought space $\mathbb{S}$, we systematically derive nine state thoughts and sixteen action thoughts through a rigorous analysis of task-solving processes. These elements form the predefined space $\mathbb{A}$ and $\mathbb{S}$, serving as an integral part of our framework. The complete specifications are provided in Appendix \ref{app:a_s}.

The synthesized program ${\cal{P}}$ serves dual objectives: 1) as an algorithmic solver for task $\tau$, and 2) as a structured generator for creating reasoning thoughts. Through iterative execution on instances set $\tilde{\mathcal{D}_\tau}$, where $|\tilde{\mathcal{D}_\tau}|=n$, ${\cal{P}}$ produces structured reasoning thoughts set ${T} = \{{T}_i\}_{i=1}^n$ that form the training corpus for LLM fine-tuning.

\begin{algorithm}[hbt]
    \caption{Thought-Enhanced LLM Fine-Tuning}
    \begin{algorithmic}[1]\label{algo:g_t_d}
        \REQUIRE Target task $\tau$, problem instances $\tilde{\mathcal{D}_\tau}$,  $\mathbb{A}$, $\mathbb{S}$, foundation model $\tilde{\text{LLM}}$;
        \STATE $(A, S) \gets {\textbf{Selector}}(\tau, \mathbb{A}, \mathbb{S})$;\COMMENT{Action/State set selection}
        \STATE ${\cal{P}} \gets {\textbf{Constructor}}(\tau, A, S)$;
        \COMMENT{Program construction}
        \STATE Initialize thought corpus ${T} \leftarrow \emptyset$;
        \FOR{$i = 1$ \text{ to } $|\tilde{\mathcal{D}_\tau}|$}
            \STATE Select an instance ${\cal{I}}_i \gets \tilde{\mathcal{D}_\tau}[i]$; 
            \STATE Generate thought ${T}_i \leftarrow {\cal{P}}({\cal{I}}_i)$;\COMMENT{Program execution}
            \STATE ${T} \leftarrow {T} \cup\{{T}_i\}$;
        \ENDFOR
        \STATE \textbf{return} ${\hbox{{LLM}}}_{\text{fine-tuned}} \leftarrow \mathcal{F}(\tilde{\text{LLM}}, {T})$.
    \end{algorithmic}
\end{algorithm}

For the reason that we currently employ manually designed components for OTD problem, the introduced architecture naturally supports automated program synthesis (which will be empirically validated in Section \ref{exp:llm_gen}).

To achieve the functionalities of {\bf{Selector}} and {\bf{Constructor}}, we propose {\bf Meta-Thought Programming (MTP)}, a systematic methodology for generating $(A, S, {\cal{P}})$ triples through structured knowledge extraction. 
For GCO problems, we develop two complementary MTP frameworks:

\noindent - {\bf{Forward MTP}}: decomposes classical heuristic algorithms to extract fundamental reasoning patterns through constructive forward-chaining;

\noindent - {\bf{Backward MTP}}: discovers implicit principles via backward analysis of high-quality solutions.

These dual approaches constitute a complete knowledge acquisition cycle: 
forward MTP encodes explicit algorithmic knowledge, while backward MTP reveals implicit problem-solving patterns.
The synergy between these frameworks enables comprehensive coverage of both declarative and procedural reasoning aspects in LLM training.


% \paragraph{Implementation Insights} Our MTP implementation demonstrates that manually designed decision systems can effectively bootstrap the thought generation process. The hierarchical architecture allows gradual replacement of manual components with learned modules as the system evolves.


\begin{figure}[htb!]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figs/framework.pdf}}
\caption{The Forward and Backward MTP framework used to construct the two core modules of GraphThought framework—Selector and Constructor—via distinct pathways.}
\label{fig:framework}
\end{center}
% \vskip -0.2in
\end{figure}
The GraphThought framework, designed to address the OTD problem, embodies the dual-process framework in Figure \ref{fig:framework}. The proposed framework consists of two integrated components: the forward framework illustrated in the upper half of the figure, whereas the backward framework is correspondingly demonstrated in the lower half. The architectural components of this framework will be comprehensively discussed in the following two subsections, collectively establishing the OTD solution set.


\subsection{Forward MTP Framework}\label{sec:forward}
\begin{comment}
    \begin{algorithm}[h]
    \caption{Forward MTP via Heuristic Composition}\label{algo:forward}
    \begin{algorithmic}[1]
    \REQUIRE A math problem $\tau$, action thoughts space $\mathbb{A}$, state thoughts space $\mathbb{S}$,.
    \STATE $H \leftarrow \text{ExtractHeuristic}(\tau)$
    \STATE $A \leftarrow \text{CombineHeuristic}(H, \tau, \mathbb{A})$
    \STATE $S \leftarrow \text{DesignStates}(\tau, A, \mathbb{S})$
    \STATE $P \leftarrow \text{Synthesize}(A, S)$
    \end{algorithmic}
    \end{algorithm}
\end{comment}

%The blue-delineated components in Figure \ref{fig:framework} architecturally define the forward MTP framework. Given a mathematical problem $\tau$, this framework exact classical heuristic algorithms $H$ for $\tau \in \{\text{MIS, MVC, TSP}, \ldots\}$. These heuristics are combined to filter fundamental operational rules to construct the action thought set $A$. The relevant state thoughts $S$ are designed according to $\tau$ and $A$.The program $P$ is ultimately synthesised by applying chosen $A$ and $S$. The specific methods to generating $A$ and $S$ are introduced in Appendix \ref{app:a_s_method}.

The \textcolor{black}{blue-highlighted modules} in Figure \ref{fig:framework} formally establish the forward MTP framework. For a given GCO task $\tau$, this framework systematically extracts several classical heuristic algorithms. These algorithms are systematically combined to distill fundamental operational axioms from $\mathbb{A}$, thereby constructing the action thought set $A$. Concurrently, the corresponding state thought set $S$ is axiomatically derived from $\mathbb{S}$ with $A$ and $\tau$. Following this procedural logic, the target program $\mathcal{P}$ is synthesized via categorical composition of selected $A$-$S$ pairs. The complete generation mechanisms of $A$ and $S$ is rigorously detailed in Appendix \ref{app:a_s_method}.


A basic program template of $\mathcal{P}$ is structured in Program Template \ref{algo:template_heuristic}. It sequentially applies action thoughts in $A$ followed by displaying each state of $S$. This template may require domain-specific adaptations depending on the task $\tau$.

\begin{template}[htb!]
\caption{ A Forward MTP Program Template}\label{algo:template_heuristic}
\begin{algorithmic}[1]
\REQUIRE Instance $I$,  state and action thought set $S,A$.
% state thought set $S$.
\STATE Initialize an empty solution $x \leftarrow \emptyset$
\STATE Initialize a solving flag $flag \leftarrow False$
\WHILE{$flag$}
    \FOR{$a \in A$}
        \STATE Update solution $x$ according to $a$; \COMMENT{Action thought application}
        \FOR{$s \in S$}
            \STATE Display state $s$ for $I$; \COMMENT{State thought application}
        \ENDFOR
        \STATE Update instance $I$;
    \ENDFOR
    \STATE Update $flag$; \COMMENT{ Update the iteration condition}
\ENDWHILE
\end{algorithmic}
\end{template}

An application of the forward MTP framework for the connected components problem is introduced in Appendix \ref{sec:forward_c_c}. 

\subsection{Backward MTP Framework}

High-quality GCO solutions often embed intelligent problem solving strategies. Although some established knowledge has guided heuristic and approximation algorithm design, many complex patterns remain undiscovered due to analytical complexity. The Universal Approximation Theorem suggests deep networks can theoretically encode such optimal solutions, making it promising to generate thoughts for LLMs using approximation or optimal slovers' guidance.

\begin{comment}
\begin{algorithm}[htb!]
\caption{ Backward MTP via A Solver}\label{algo:backward}
\begin{algorithmic}[1]
    \REQUIRE A math problem $\tau$, action thoughts space $\mathbb{A}$, state thoughts space $\mathbb{S}$.
    \STATE $\mathcal{X}$ is a solver of $\tau$\COMMENT{Approximate or optimal solver}
    \STATE $A \leftarrow \{\text{AddOne}\}$\COMMENT{A basic action thought}
    \STATE $S \leftarrow \text{DesignStates}(\tau, A, \mathbb{S})$
    \STATE $P \leftarrow \text{Synthesize}(A, S, \mathcal{X})$
\end{algorithmic}
\end{algorithm}
\end{comment}

%The red-delineated components in Figure \ref{fig:framework} architecturally define the backward MTP framework. This framework leverages high-quality solvers (exact or approximation) to derive solution construction patterns. There is only one action thought {\bf AddOne}, which adds one element of the standard solution into the current solution, and thus generates stepwise solution trajectories. The process of designing state is the same to Section \ref{sec:forward}. The program template  $P$ integrates the solver $\mathcal{X}$ of the task$\tau$ to the process of generating thoughts as follows:

The \textcolor{black}{red-highlighted modules} in Figure \ref{fig:framework} structurally define the backward MTP framework. This architecture employs high-quality solvers (including both exact and approximate methods) to obtain high-quality solutions from which we can extract solution construction patterns. The action thought set is constrained to a single operator, AddOne, which incrementally incorporates solution elements into the current partial solution, thereby generating stepwise trajectories. The state design methodology maintains consistency with the forward framework in Section \ref{sec:forward}. The program $\mathcal{P}$ integrates a task-specific solver $\mathcal{X}$ with the thought-generation process through the following Program Template \ref{algo:template_opt}.

\begin{template}[htb!]
\caption{ A Backward MTP Program Template}\label{algo:template_opt}
\begin{algorithmic}[1]
\REQUIRE Instance $I$, action thought set $A$, state thought set $S$, a solver $\mathcal{X}$ of $\tau$.
\STATE Initialize an optimal or suboptimal solution $\hat{x} \leftarrow \mathcal{X}(I)$
\STATE Initialize an empty solution $x \leftarrow \emptyset$
\STATE Initialize a solving flag $flag \leftarrow False$
\WHILE{$flag$}
    \STATE $e \leftarrow \text{AddOne}(\hat{x})$;\COMMENT{Add element from standard solution}
    \STATE $x \leftarrow x \cup \{e\}$;
    %\STATE Update solution $x$;
    \FOR{$s \in S$}
        \STATE Display state $s$ for $I$; \COMMENT{State thought application}
    \ENDFOR
    \STATE Update instance $I$;
    \STATE Update $flag$;\COMMENT{Update the iteration condition}
\ENDWHILE
\end{algorithmic}
\end{template}

An application of the backward MTP framework for the MIS problem is shown in Appendix \ref{sec:backward_mis}. 

\section{Related Work}

\subsection{LLMs for Graph Combinatorial Optimization}

The integration of Large Language Models (LLMs) into solving Graph Combinatorial Optimization (GCO) problems has garnered significant attention in recent years. Several works have attempted to leverage LLMs for GCO problems from various perspectives. Jin et al.~\cite{jin2024large} provided a comprehensive survey on the application of LLMs on graphs, categorizing potential scenarios into pure graphs, text-attributed graphs, and text-paired graphs. They discussed techniques such as using LLMs as predictors, encoders, and aligners. Chen et al.~\cite{chen2024exploring} explored the potential of LLMs in graph machine learning, especially for node classification tasks, and investigated two pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. Liu et al.~\cite{liu2023towards} introduced the concept of Graph Foundation Models (GFMs) and classified existing work into categories based on their dependence on graph neural networks and LLMs. Ren et al.~\cite{ren2024survey} conducted a survey on LLMs for graphs, proposing a taxonomy to categorize existing methods based on their framework design.

Many studies have focused on using prompt engineering and optimization to extract the intrinsic knowledge of pretrained LLMs in the form of text or code. Wang et al.~\cite{wang2024can} proposed the NLGraph benchmark to evaluate LLMs on graph reasoning tasks and introduced Build-a-Graph and Algorithmic Prompting to enhance their performance. Iklassov et al.~\cite{iklassov2024self} introduced Self-Guiding Exploration (SGE) to improve LLM performance on combinatorial problems. Elhenawy et al.~\cite{elhenawy2024eyeballing, elhenawy2024visual} explored the use of multimodal LLMs to solve the Traveling Salesman Problem (TSP) through visual reasoning. Tang et al.~\cite{tang2024grapharena} introduced GraphArena, a benchmarking tool for evaluating LLMs on graph computational problems. Li et al.~\cite{li2024graphteam} proposed GraphTeam, a multi-agent system based on LLMs for graph analysis. Guo et al.~\cite{guo2023gpt4graph} conducted an empirical evaluation of LLMs on graph-structured data. Fatemi et al.~\cite{fatemi2023talk} explored encoding graph-structured data as text for LLMs. Hu et al.~\cite{hu2024scalable} introduced GraphAgent-Reasoner, a multi-agent collaboration framework for graph reasoning. Perozzi et al.~\cite{perozzi2024let} proposed GraphToken to explicitly represent structured data for LLMs. Cao et al.~\cite{cao2024graphinsight} proposed GraphInsight to improve LLM comprehension of graph structures. Feng et al.~\cite{feng2024beyond} introduced LLM4Hypergraph to evaluate LLMs on hypergraphs. Yuan et al.~\cite{yuan2024gracore} presented GraCoRe, a benchmark for assessing LLMs' graph comprehension and reasoning. Firooz et al.~\cite{firooz2024lost} examined the impact of contextual proximity on LLM performance in graph tasks. Skianis et al.~\cite{skianis2024graph} explored using pseudo-code prompting to improve LLM performance on graph problems. Agrawal et al.~\cite{agrawal2024exploring} designed graph traversal tasks to test LLMs' structured reasoning capabilities. Wang et al.~\cite{wang2024reasoning} investigated the influence of temperature on LLM reasoning performance. Dai et al.~\cite{dai2024revisiting} revisited LLMs' graph reasoning ability through case studies. Zhong et al.~\cite{zhong2024exploring} explored the impact of graph visualizations on LLM performance. Sanford et al.~\cite{sanford2024understanding} analyzed the reasoning capabilities of transformers via graph algorithms.

Other works have focused on training graph foundation models using dense embeddings from LLM pretraining. Drakulic et al.~\cite{drakulic2024goal} proposed GOAL, a generalist model for solving multiple combinatorial optimization problems. Jiang et al.~\cite{jiang2024unco} introduced UNCO, a unified framework for solving various COPs using LLMs. Anonymous~\cite{anonymous2024solving} proposed a unified model for diverse CO problems using a transformer backbone. Chai et al.~\cite{chai2023graphllm} introduced GraphLLM to boost the graph reasoning ability of LLMs. Wei et al.~\cite{wei2024rendering} proposed GITA, a framework integrating visual and textual information for graph reasoning.


\subsection{Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought Methods}
The Chain-of-Thought (CoT) prompting technique, introduced by Wei et al. \cite{wei2022chain}, demonstrates that generating intermediate reasoning steps can significantly improve LLMs' performance on complex reasoning tasks. This method was further extended by Yao et al. \cite{yao2024tree}, who proposed the Tree of Thoughts (ToT) framework, enabling exploration over coherent units of text (thoughts) to enhance problem-solving abilities. The ToT approach allows LMs to consider multiple reasoning paths and self-evaluate choices, significantly improving performance on tasks requiring non-trivial planning or search. Besta et al. \cite{besta2024graph} introduced the Graph of Thoughts (GoT), which advances prompting capabilities by modeling LLM-generated information as an arbitrary graph. This approach enables combining arbitrary LLM thoughts into synergistic outcomes and enhances thoughts using feedback loops. Besta et al. \cite{besta2024demystifying} further demystified the concepts of chains, trees, and graphs of thoughts, providing a taxonomy of structure-enhanced LLM reasoning schemes. These studies highlight the importance of structured reasoning topologies in improving LLMs' problem-solving abilities.

\subsection{Self-Correction, Planning, and Search Strategy Learning}
Huang et al. \cite{huang2024large} examined the role of self-correction in LLMs, finding that intrinsic self-correction without external feedback often fails to improve reasoning accuracy. In contrast, Lehnert et al. \cite{searchformer} proposed the Searchformer model, which predicts the search dynamics of the A* algorithm, significantly outperforming traditional planners on complex decision-making tasks. Gandhi et al. \cite{gandhi2024stream} introduced the Stream of Search (SoS) approach, teaching language models to search by representing the process as a flattened string. This method significantly improved search accuracy and enabled flexible use of different search strategies.
    

\section{Experiments}\label{sec:expe}

\subsection{Experiments Settings}

% 对于要训练的模型，我们选择了llama3-8b-instruct模型，并使用lora来方式来进行sft，其中lora_rank设置8， lora_alpha设置为16，lora_dropout设置为0，我们采用了llama-factory来进行微调。更完整的训练参数，我们放在了附录里面。在推理时，设置temperature为0.1来确保性能的可复线性，在推理时，我们采用了vllm推理加速框架来加速大语言模型的推理。评估指标我们沿用了graphArena中的有效性和最优性指标，评估任务为graphArena中的十个任务。

We fine-tuned the \texttt{Meta-Llama-3-8B-Instruct} model using Low-Rank Adaptation (LoRA) via the \texttt{llama-factory} framework\footnote{\url{https://github.com/hiyouga/LLaMA-Factory}}, naming the resulting model {\bf{Llama-GT}} (GT means GraphThought). For inference, we set \texttt{temperature=0.1} and using \texttt{vLLM} library\footnote{\url{https://github.com/vllm-project/vllm}}. Full hyperparameters are placed in Appendix \ref{app:setting}.

For performance evaluation, we adopted the \textit{optimality} metric from the \texttt{GraphArena} benchmark~\cite{tang2024grapharena}. 
Regarding the definitions of small/large graphs, we strictly followed the specifications in \texttt{GraphArena}: 

\noindent - {\bf{Neighbor/Distance Task}}: Small ($4$-$19$ nodes), Large ($20$-$50$ nodes)  

\noindent - {\bf{Connected/Diameter/MCP/MIS/MVC Task}}: Small ($4$-$14$ nodes), Large ($15$-$30$ nodes)  

\noindent - {\bf{MCS/GED/TSP Task}}: Small ($4$-$9$ nodes), Large ($10$-$20$ nodes).   

The evaluation covered all ten predefined tasks in \texttt{GraphArena}, with detailed task descriptions and optimality criteria provided in Appendix \ref{app:setting}.



% \subsection{Optimal Thought Design}
\subsection{Main Result}

% \textbf{Comparison with Original GraphArena Results} Our proposed Llama-GT demonstrates significant improvements over baseline LLMs from GraphArena. For small graphs, Llama-GT achieves near-perfect performance on polynomial-complexity tasks including Neighbor (1.0), Distance (1.0), and Diameter (0.954), substantially outperforming both conventional LLMs and code-assisted approaches. Notably, it shows 60-90\% absolute gains over the best original model (GPT-4o-2024-0513) on NP-hard tasks with large graphs (MVC: 0.744 vs 0.102; MIS: 0.900 vs 0.034). While code-based approaches (DeepSeek-V2-Coder and GPT-4o-Coder) demonstrate intermediate performance on basic tasks, they remain limited on complex challenges like Diameter (0.334) and GED (0.32). Qwen2-7B-SFT exhibits strong performance on basic tasks but completely fails on MCS (0.0) for large graphs, revealing fundamental limitations of direct supervised fine-tuning without our thought-enhanced paradigm.

% \textbf{Comparison with Few-shot Thought Prompting} Though few-shot thought prompting improves base model performance, Llama-GT maintains distinct advantages. While Deepseek-V3 achieves perfect scores on Neighbor (1.0) and Connected (1.0) for small graphs through prompting, it struggles with complex tasks like MVC (0.366). Our method demonstrates more consistent gains across all task categories, particularly excelling on large graphs where Llama-GT outperforms the best few-shot model (DeepSeek-V3) by wide margins on NP-hard tasks: MVC (0.744 vs 0.120) and MIS (0.900 vs 0.304). This performance gap suggests systematic thought integration provides superior reasoning capabilities compared to few-shot exemplars alone.

% \textbf{Comparison with STaR Framework} Our comparison with the STaR\cite{zelikman2022star} framework's self-generated thought approach reveals critical insights. Using STaR with Meta-Llama-3-8B-Instruct under two configurations\footnote{More detailed configuations see appendix \ref{app:setting}.} - (1) few-shot prompting with thought structures generated with our GraphThought framework and (2) \texttt{o1}-generated thoughts - Llama-GT substantially outperforms both variants across all graph sizes. For large graphs, Llama-GT achieves 2-3× improvements over STaR(w/ GT) on key metrics: MVC (0.744 vs 0.360), MIS (0.900 vs 0.216), and Diameter (0.600 vs 0.080). The persistent performance gap even when STaR uses our thought-enhanced examples highlights limitations in iterative self-improvement approaches. Notably, STaR(w/o1) shows catastrophic failures on certain tasks (MCP: 0.030), emphasizing the necessity of our carefully designed thought paradigm over automated example generation.

% \textbf{Ablation: Thought Mechanism Impact} The thought mechanism proves essential for complex reasoning. While Llama-GT(w/o Thought) already shows strong performance on polynomial tasks (Neighbor: 0.988 small, 0.804 large), thought integration brings dramatic improvements for NP-hard problems: MVC increases from 0.930→0.972 (small) and 0.652→0.744 (large), MIS from 0.972→0.994 (small) and 0.652→0.900 (large). However, we observe a performance degradation in GED (small: 0.608→0.460; large: 0.068→0.008). We posit that potential causes underlying this phenomenon will be explored in the later discussion.

% \textbf{Discussion on Challenging Tasks} While Llama-GT demonstrates clear advantages on most tasks, its performance parity in particularly challenging problems (TSP, MCS, and GED) warrants analysis. We hypothesize three contributing factors: (1) These tasks exhibit significantly higher computational complexity than MIS/MVC/MCP problems, pushing the boundaries of current reasoning paradigms; (2) The lack of established human problem-solving heuristics for these tasks limits the effectiveness of manual thought design; (3) Potential over-regularization effects from thought guidance may inadvertently constrain model exploration. Despite these challenges, Llama-GT still maintains measurable improvements over untrained baselines, suggesting our approach provides foundational benefits even for extreme-difficulty tasks. This observation opens promising directions for hybrid methodologies combining systematic thought guidance with adaptive exploration mechanisms.

\textbf{Comparison with Original GraphArena Results}
Llama-GT outperforms baseline LLMs from GraphArena, especially on small graphs. 
It achieves near-perfect performance on polynomial-complexity tasks such as Neighbor ($1.0$), Distance ($1.0$), and Diameter ($0.954$). 
On NP-hard tasks with large graphs, Llama-GT shows $60$-$90$\% improvements over the best original model gpt-4o-2024-0513 (e.g., MVC: $0.744$ vs. $0.102$, MIS: $0.900$ vs. $0.034$). 
While code-based approaches (DeepSeek-V2-Coder and GPT-4o-Coder) demonstrate intermediate performance on basic tasks, they remain limited on complex challenges like Diameter ($0.334$), which Llama-GT can address more effectively ($0.954$). 
Qwen2-7B-SFT excels on basic tasks but fails on MIS for large graphs ($0.054$), highlighting the limitations of supervised fine-tuning without our thought-enhanced paradigm.

\textbf{Comparison with Few-shot Thought Prompting}
While few-shot prompting improves performance, Llama-GT shows greater consistency, especially on large graphs. 
DeepSeek-V3 achieves perfect scores on simple tasks like Neighbor ($1.0$) but struggles with MVC ($0.366$). 
Llama-GT outperforms DeepSeek-V3 on NP-hard tasks like MVC ($0.744$ vs. $0.120$) and MIS ($0.900$ vs $0.304$) with large graphs, demonstrating the superiority of GraphThought over few-shot exemplars.

\textbf{Comparison with STaR Framework}
Our comparison with the STaR~\cite{zelikman2022star} framework's self-generated thought approach reveals critical insights. 
Using STaR with Llama-3-8B-Instruct under two configurations\footnote{More detailed configuations see appendix \ref{app:setting}.} - 
(1) few-shot prompting with thoughts generated with our GraphThought framework and 
(2) \texttt{o1}-generated thoughts - Llama-GT substantially outperforms both variants across all graph sizes, showing $2$-$3$x improvements on large graphs (MVC: $0.744$ vs. $0.360$, MIS: $0.900$ vs $0.216$). 
The gap persists even when STaR uses our thought-enhanced examples, emphasizing the limits of iterative self-improvement approaches. 
In addition, STaR(w/GT) performs better than STaR(w/o1) across nearly all tasks and different graph sizes, further underscoring the importance of our thought paradigm over automated generation for training.

\textbf{Ablation: Thought Mechanism Impact}
The thought mechanism significantly improves performance on NP-hard tasks. 
Llama-GT without thought integration still performs well on polynomial tasks (e.g., Neighbor: $0.988$ small, $0.804$ large). 
With thought integration, MVC increases from $0.930$ to $0.972$ (small) and $0.652$ to $0.744$ (large), MIS from $0.972$ to $0.994$ (small) and $0.652$ to $0.900$ (large). 
However, performance drops on GED (small: $0.608$ to $0.460$; large: $0.068$ to $0.008$). 
We posit that potential causes underlying this phenomenon will be explored later.

\textbf{Discussion on Challenging Tasks}
While Llama-GT excels in most tasks, its performance on TSP, MCS, and GED still requires attention. 
We attribute this to 
(1) the higher computational complexity of these tasks, 
(2) the lack of well-established heuristics for human problem-solving, and 
(3) potential over-regularization effects from thought guidance. 
Despite this, Llama-GT shows improvements over untrained models, suggesting that combining thought guidance with post-training may offer promising avenues for tackling these difficult problems.


\begin{table*}[htb!]
\label{tab:example}
\centering
\caption{Performance comparison of optimal solution rates (\%) across $10$ graph tasks, evaluated on small graphs, each has $500$ instances. Results are shown for: (1) Original inference results of LLMs from GraphArena (Claude3-haiku, GPT-4o, etc.); (2) Code-augmented models (DeepSeek-V2-Coder, GPT-4o-Coder); (3)Supervised Fine-Tuned Model provided by GraphArena (Qwen2-7B-SFT);(4) Few-shot thought prompting variants (Deepseek-V3, Llama-3.3-70B, etc.); (5) STaR framework implementations with different fewshot strategies; and (6) Our Llama-GT model trained with/without thought mechanisms. Metrics include polynomial tasks (Neighbor, Distance, Connected, Diameter), NP-hard tasks (MVC, MIS, MCP, TSP, MCS, GED). $^*$ indicates that the model in the GraphArena paper was trained on fewer data compared to the data used in our model.}
\renewcommand{\arraystretch}{1.2} % Adjust line spacing

\resizebox{0.95\textwidth}{!}{%
% \begin{sc}
\begin{tabular}{lCCCCCCCCCC}

\hline
\multicolumn{11}{c}{Graph Task (Small Graphs)} \\ \hline
Model & Neighbor & Distance & Connected & Diameter & MVC & MIS & MCP & TSP & MCS & GED \\ \hline
Claude3-haiku & 0.768 & 0.580 & 0.260 & 0.116 & 0.336 & 0.450 & 0.482 & 0.242 & 0.282 & 0.216 \\ 
DeepSeek-V2 & 0.540 & 0.814 & 0.474 & 0.226 & 0.376 & 0.360 & 0.400 & 0.368 & 0.236 & 0.282 \\ 
Gemma-7b & 0.410 & 0.496 & 0.014 & 0.086 & 0.128 & 0.212 & 0.254 & 0.134 & 0.020 & 0.028 \\ 
gpt-3.5-turbo-0125 & 0.562 & 0.572 & 0.096 & 0.130 & 0.376 & 0.184 & 0.400 & 0.230 & 0.176 & 0.144 \\ 
gpt-4o-2024-0513 & 0.860 & 0.796 & 0.794 & 0.426 & 0.326 & 0.518 & 0.528 & 0.404 & 0.406 & 0.268 \\ 
Llama3-70b-Instruct & 0.674 & 0.894 & 0.632 & 0.248 & 0.420 & 0.368 & 0.428 & 0.232 & 0.442 & 0.316 \\ 
Llama3-8b-Instruct & 0.368 & 0.412 & 0.248 & 0.114 & 0.318 & 0.282 & 0.280 & 0.162 & 0.096 & 0.072 \\ 
Mixtral-8x7b & 0.530 & 0.566 & 0.286 & 0.130 & 0.130 & 0.116 & 0.278 & 0.188 & 0.098 & 0.124 \\ 
Qwen1.5-72b-Chat & 0.572 & 0.478 & 0.394 & 0.118 & 0.224 & 0.386 & 0.388 & 0.228 & 0.298 & 0.174 \\ 
Qwen1.5-8b-Chat & 0.138 & 0.266 & 0.022 & 0.048 & 0.138 & 0.118 & 0.216 & 0.170 & 0.062 & 0.058 \\ 
DeepSeek-V2-Coder & 0.816 & 0.894 & 0.586 & 0.142 & 0.176 & 0.482 & 0.498 & 0.276 & 0.228 & 0.214 \\ 
GPT-4o-Coder & 0.808 & 0.654 & 0.712 & 0.334 & 0.296 & 0.530 & 0.644 & \textbf{0.490} & 0.508 & 0.320 \\ 
Qwen2-7b-SFT$^*$ & 0.966 & 0.912 & 0.888 & 0.608 & 0.548 & 0.702 & 0.696 & 0.368 & 0.000 & 0.054 \\ 
\hline
+Few-shot Thought & & & & & & & & & & \\ 
Deepseek-V3 & \textbf{1.000} & 0.988 & \textbf{1.000} & 0.850 & 0.366 & 0.642 & 0.754 & 0.370 & \textbf{0.544} & 0.308 \\ 
gpt-4o-mini & 0.980 & 0.902 & 0.760 & 0.336 & 0.100 & 0.710 & 0.578 & 0.312 & 0.360 & 0.280 \\ 
Llama-3.3-70B & 0.970 & 0.970 & 0.954 & 0.674 & 0.206 & 0.648 & 0.554 & 0.292 & 0.484 & 0.326 \\ 
Mixtral-8x7b & 0.580 & 0.536 & 0.378 & 0.156 & 0.148 & 0.326 & 0.490 & 0.168 & 0.196 & 0.262 \\ 
QwQ-32B-Preview & 0.962 & 0.848 & 0.696 & 0.514 & 0.262 & 0.482 & 0.560 & 0.310 & 0.444 & 0.318 \\ 
Llama3-8b-Instruct & 0.700 & 0.480 & 0.502 & 0.070 & 0.108 & 0.248 & 0.258 & 0.190 & 0.222 & 0.450 \\ 
\hline
+SFT & & & & & & & & & & \\ 
STaR(w/ GT) & 0.648 & 0.910 & 0.522 & 0.466 & 0.722 & 0.640 & 0.676 & 0.352 & 0.308 & 0.370 \\ 
STaR(w/ o1) & 0.296 & 0.662 & 0.440 & 0.380 & 0.688 & 0.654 & 0.288 & 0.282 & 0.328 & 0.258 \\ 
\textbf{Llama-GT(w/o Thought)} & 0.988 & 0.990 & 0.906 & 0.820 & 0.930 & 0.972 & 0.906 & 0.366 & 0.538 & \textbf{0.608} \\ 
\textbf{Llama-GT} & \textbf{1.000} & \textbf{1.000} & 0.996 & \textbf{0.954} & \textbf{0.972} & \textbf{0.994} & \textbf{0.952} & 0.392 & 0.496 & 0.460 \\ 
\hline

\end{tabular}
% \end{sc}

}
\end{table*}

\begin{table*}[htb!]
\label{tab:example2}
\centering
\caption{Performance comparison of optimal solution rates (\%) across $10$ graph tasks, evaluated on large graphs, each has $500$ instances. Results are shown for: (1) Original inference results of LLMs from GraphArena (Claude3-haiku, GPT-4o, etc.); (2) Code-augmented models (DeepSeek-V2-Coder, GPT-4o-Coder); (3)Supervised Fine-Tuned Model provided by GraphArena (Qwen2-7B-SFT);(4) Few-shot thought prompting variants (Deepseek-V3, Llama-3.3-70B, etc.); (5) STaR framework implementations with different fewshot strategies; and (6) Our Llama-GT model trained with/without thought mechanisms. Metrics include polynomial tasks (Neighbor, Distance, Connected, Diameter), NP-hard tasks (MVC, MIS, MCP, TSP, MCS, GED). $^*$ indicates that the model in the GraphArena paper was trained on fewer data compared to the data used in our model.}
\renewcommand{\arraystretch}{1.2} % Adjust line spacing

\resizebox{0.95\textwidth}{!}{%
% \begin{sc}
\begin{tabular}{lCCCCCCCCCC}

\hline
\multicolumn{11}{c}{Graph Task (Large Graphs)} \\ \hline
Model & Neighbor & Distance & Connected & Diameter & MVC & MIS & MCP & TSP & MCS & GED \\ \hline
Claude3-haiku & 0.406 & 0.358 & 0.052 & 0.002 & 0.076 & 0.014 & 0.090 & 0.000 & 0.000 & 0.018 \\ 
DeepSeek-V2 & 0.278 & 0.534 & 0.154 & 0.022 & 0.064 & 0.032 & 0.032 & 0.006 & 0.000 & 0.014 \\ 
Gemma-7b & 0.116 & 0.246 & 0.002 & 0.004 & 0.014 & 0.006 & 0.016 & 0.000 & 0.000 & 0.002 \\ 
gpt-3.5-turbo-0125 & 0.412 & 0.322 & 0.012 & 0.008 & 0.082 & 0.008 & 0.052 & 0.000 & 0.000 & 0.006 \\ 
gpt-4o-2024-0513 & 0.674 & 0.550 & 0.370 & 0.032 & 0.102 & 0.034 & 0.102 & 0.004 & 0.000 & 0.018 \\ 
Llama3-70b-Instruct & 0.434 & 0.530 & 0.264 & 0.034 & 0.114 & 0.026 & 0.106 & 0.000 & 0.000 & 0.008 \\ 
Llama3-8b-Instruct & 0.118 & 0.234 & 0.022 & 0.002 & 0.064 & 0.010 & 0.022 & 0.000 & 0.000 & 0.002 \\ 
Mixtral-8x7b & 0.232 & 0.282 & 0.040 & 0.000 & 0.036 & 0.008 & 0.034 & 0.000 & 0.000 & 0.006 \\ 
Qwen1.5-72b-Chat & 0.236 & 0.258 & 0.068 & 0.006 & 0.038 & 0.018 & 0.022 & 0.000 & 0.000 & 0.010 \\ 
Qwen1.5-8b-Chat & 0.026 & 0.156 & 0.002 & 0.000 & 0.002 & 0.000 & 0.016 & 0.000 & 0.000 & 0.006 \\ 
DeepSeek-V2-Coder & 0.672 & 0.632 & 0.206 & 0.008 & 0.080 & 0.028 & 0.072 & 0.000 & 0.022 & 0.014 \\ 
GPT-4o-Coder & 0.868 & 0.684 & 0.378 & 0.112 & 0.110 & 0.072 & 0.222 & 0.028 & \textbf{0.036} & 0.018 \\ 
Qwen2-7b-SFT$^*$ & 0.790 & 0.570 & 0.230 & 0.092 & 0.156 & 0.054 & 0.136 & 0.000 & 0.000 & 0.032 \\ 
\hline
+Few-shot Thought & & & & & & & & & & \\ 
DeepSeek-V3 & \textbf{0.992} & 0.942 & \textbf{0.932} & 0.448 & 0.120 & 0.304 & 0.290 & 0.020 & 0.012 & 0.020 \\ 
gpt-4o-mini & 0.920 & 0.550 & 0.284 & 0.016 & 0.050 & 0.226 & 0.146 & 0.000 & 0.006 & 0.014 \\ 
Llama-3.3-70B & 0.952 & 0.866 & 0.856 & 0.290 & 0.118 & 0.254 & 0.136 & 0.000 & 0.012 & 0.012 \\ 
Mixtral-8x7b & 0.466 & 0.282 & 0.108 & 0.002 & 0.032 & 0.024 & 0.056 & 0.000 & 0.000 & 0.022 \\ 
QwQ-32B-Preview & 0.912 & 0.504 & 0.498 & 0.164 & 0.058 & 0.106 & 0.124 & 0.000 & 0.002 & 0.020 \\ 
Llama3-8b-Instruct & 0.604 & 0.220 & 0.132 & 0.002 & 0.028 & 0.010 & 0.038 & 0.000 & 0.002 & 0.026 \\ 
\hline
+SFT & & & & & & & & & & \\ 
STaR(w/ GT) & 0.374 & 0.618 & 0.124 & 0.080 & 0.360 & 0.216 & 0.134 & 0.018 & 0.006 & 0.026 \\ 
STaR(w/ o1) & 0.320 & 0.332 & 0.090 & 0.038 & 0.126 & 0.124 & 0.030 & 0.002 & 0.004 & 0.024 \\ 
\textbf{Llama-GT(w/o Thought)} & 0.804 & 0.864 & 0.340 & 0.302 & 0.652 & 0.652 & 0.370 & 0.024 & 0.020 & \textbf{0.068} \\ 
\textbf{Llama-GT} & 0.988 & \textbf{0.984} & 0.836 & \textbf{0.600} & \textbf{0.744} & \textbf{0.900} & \textbf{0.634} & \textbf{0.036} & \textbf{0.036} & 0.008 \\ 
\hline

\end{tabular}
% \end{sc}

}
\end{table*}

% \subsection{Practical Thought Generation}
% 我们将llama3-8B-instruct作为测试模型，测试了zero-shot、带有直接答案作为few-shot example、带有构建thought作为few-shot example以及带有o1-mini生成thought作为few-shot example的三种prompt，测试结果如下所示。可以看到，带有thought的prompt都能实现较好的效果，同时，使用我们的方法构建的thought作为few-shot example能够显著优于带有直接答案作为few-shot example和带有o1-mini生成thought作为few-shot example在有效性和最优性维度上，可见使用我们方法构建thought的优越性。

% We used \texttt{llama3-8b-instruct} as the test model and evaluated it under four prompting strategies: 
% (1) zero-shot prompting, 
% (2) few-shot prompting with direct answers as examples, 
% (3) few-shot prompting with constructed thoughts as examples, and 
% (4) few-shot prompting with \texttt{o1-mini}-generated thoughts as examples.

% The results are presented below. It is evident that prompts containing thought annotations achieve better overall performance. Notably, using thoughts constructed by our method as few-shot examples significantly outperforms both the direct-answer few-shot examples and the \texttt{o1-mini}-generated thought examples in terms of \textit{effectiveness} and \textit{optimality}. This demonstrates the superiority of our approach for constructing thought annotations.

% \subsection{Thought-Supervised Finetuning}
% 我们使用上述thought generation方式构建了包含10种graph任务的带有thought数据集和不带thought数据集来进行finetune。其中数据集大小为30K，现已开源到huggingface上。基座模型我们选择了llama3-8b-instruct模型，并使用lora来方式来进行sft，其中lora_rank设置8， lora_alpha设置为16，lora_dropout设置为0，epoch设置为4。我们采用了llama-factory来进行微调。
% Using the thought generation method described above, we constructed two datasets for fine-tuning: one with thought annotations and one without. Both datasets are based on 10 graph-related tasks, with a total size of 30K samples. These datasets have been open-sourced on Hugging Face for public access.

% For the base model, we selected the \texttt{llama3-8b-instruct} model and applied LoRA (Low-Rank Adaptation) for supervised fine-tuning (SFT). The \texttt{lora\_rank} was set to 8, \texttt{lora\_alpha} to 16, \texttt{lora\_dropout} to 0, and the number of epochs was set to 4. The fine-tuning process was implemented using the \texttt{llama-factory} framework.

\subsection{Performance Comparison with OpenAI-o1}
% 我们还对比了以推理能力擅长的OpenAI-o1性能。考虑到o1模型推理速度慢且价格昂贵，所以这里我们选择了o1-mini-2024-09-12模型，且每一个测试任务选择50个instance来进行验证。可以看到，微调后的llama模型，能够在Polynomial和简单的NP-hard问题上逼近甚至在某些任务（比如MVC和MIS）上性能超过o1-mini。但在某些难度更高的任务上（比如TSP），我们训练的模型仍然和o1-mini有一定的差距。但值得注意的是，我们的模型是基于8b模型大小微调出来的，不论是模型参数量和模型训练成本相较于o1-mini有很大的优势。

% Additionally, we compared the performance of several cutting-edge inference models, including OpenAI-o1 and DeepSeek-R1. Considering the slow inference speed and high cost of these two models, we select 50 instances for each task. As shown in figure \ref{fig:vs_o1_combined}, our fine-tuned Llama model (Llama-GT) performs competitively on polynomial and simpler NP-hard problems, even surpassing o1-mini and DeepSeek-R1 in certain tasks, such as MVC on small graphs and MIS on large graphs. However, for more complex tasks, such as TSP and MCS, our trained model still lags behind these inference models significantly. It’s important to note that our model is based on the 8B model size, which offers significant advantages in terms of both model parameters and training cost compared to these larger models.

% We conducted comparative analyses with OpenAI's o1 model series. Given the computational inefficiency and high costs associated with the o1 model, we strategically selected the o1-mini-2024-09-12 variant and evaluated its performance using 50 test instances per task. As shown in figure \ref{fig:vs_o1_combined} , experimental results demonstrate that our fine-tuned Llama model (Llama-GT) achieves comparable or even superior performance to o1-mini on polynomial-time solvable tasks and certain tractable NP-hard tasks, particularly in MVC and MIS. However, a noticeable performance gap persists in more complex combinatorial optimization challenges such as the Traveling Salesman Problem (TSP). Notably, our model architecture derives from parameter-efficient fine-tuning of an 8B-parameter base model, yielding substantial advantages in both parameter efficiency and computational resource requirements during training.

We compared the performance of our fine-tuned Llama model (Llama-GT) with OpenAI’s o1 model series, specifically the o1-mini-2024-09-12 variant, chosen for its computational efficiency and lower cost. 
We tested both models on 50 instances per task. 
Results, shown in figure \ref{fig:vs_o1_combined}, indicate that Llama-GT performs comparably or better than o1-mini on polynomial-time and certain NP-hard tasks, particularly in MVC and MIS. 
However, a performance gap remains in more complex problems like the Traveling Salesman Problem (TSP). 
Notably, our model architecture derives from an 8B-parameter base model, yielding substantial advantages in both parameter efficiency and computational resource requirements during training.

% \begin{figure}[htb!]
% % \vskip 0.1in
% \begin{center}
% \begin{tabular}{c}
%     \includegraphics[width=0.48\columnwidth]{figs/vs_o1_easy.png} \\
%     \textbf{(a)} Small Graph
%     \includegraphics[width=0.48\columnwidth]{figs/vs_o1_hard.png} \\
%     \textbf{(b)} Large Graph \\
% \end{tabular}
% \caption{Comparison of OpenAI-o1-mini and our fine-tuned Llama model (Llama-GT) on ten graph tasks of GraphArena benchmark. (a) Results on small graph instances. (b) Results on large graph instances.}
% \label{fig:vs_o1_combined}
% \end{center}
% % \vskip -0.1in
% \end{figure}

\begin{figure}[htb!]
\begin{center}
    \begin{subfigure}[b]{0.48\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/vs_o1_easy.png}
        \caption{Small Graph}
        \label{fig:vs_o1_easy}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\columnwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/vs_o1_hard.png}
        \caption{Large Graph}
        \label{fig:vs_o1_hard}
    \end{subfigure}
\caption{Comparison of OpenAI-o1-mini and our fine-tuned Llama model (Llama-GT) on ten graph tasks of GraphArena benchmark. (a) Results on small graph instances. (b) Results on large graph instances.}
\label{fig:vs_o1_combined}
\end{center}
\end{figure}


\subsection{Automated Thought Dataset Synthesis via LLM-Driven Code Generation}
\label{exp:llm_gen}
% 除了使用人工设计生成十个任务数据集的代码，我们还构建了使用大语言模型自动化生成构建数据集代码的prompt（见附录），并使用gpt-4o生成了十个任务的有效代码，并生成相同数量数据的数据集，来对llama3-8b-instruct模型进行微调。效果如下所示。其中origin是没有进行微调的llama3模型，w/o thought是使用direct answer来进行微调的模型，llm-design是使用大语言模型生成代码来自动生成数据集进行微调的模型，human-design是使用人工设计的代码生成数据集进行微调的模型。可以看到，llm-design生成的数据集进行训练的模型，能够大幅提升原有模型的推理能力，并在Polynomial Task上超过w/o thought模型。但在NP难的问题上，大模型很难自动构建生成优质thought数据集的代码，导致性能和w/o thought模型持平。另一方面，虽然llm-design模型无法在Polynomial Task或者NP难的问题上超越人工精心设计的数据集，但自动化生成方式不仅在新的问题上构造成本低，而且能够使用优化方法来自动对outer response和inner response做提升，具有很大的潜力。如何使用优化方法，来对生成数据集的代码做进一步提升将留给未来来解决。


% In addition to using manually designed code to generate datasets for ten tasks, we also created a template that automates the generation of dataset-building code using a large language model (see Appendix \ref{app:prompt}). Using GPT-4o, we generated valid code for these ten tasks and created datasets of equivalent size to fine-tune the Meta-Llama-3-8B-Instruct model. We compared four configurations: 1) Origin: The base Meta-Llama-3-8B-Instruct model without fine-tuning, 2) w/o Thought: Fine-tuned with direct-answer supervision, 3) Llama-GT(w/ LLM-Design): Fine-tuned on datasets generated by LLM-synthesized code, and 4) Llama-GT(w/ Human-Design): Fine-tuned on datasets generated by human-designed code.

% As shown in figure \ref{llm-generated}, Llama-GT(w/ LLM-Design) significantly enhances reasoning capabilities compared to the Origin model, achieving superior performance on tasks of both difficulty levels and surpassing w/o Thought on the Polynomial task. However, on NP-hard tasks, the code generated by the LLM struggles to produce high-quality thought sequences, resulting in similar performance to w/o Thought (0.509 vs. 0.508). 
% While Llama-GT(w/ LLM-Design) lags behind Llama-GT(w/ Human-Design) in both task categories, it offers critical advantages. These include low construction costs for novel problems and inherent compatibility with optimization methods that can iteratively refine response generation. Future efforts will focus on developing optimization frameworks to enhance the quality and generality of LLM-synthesized dataset code.
We created a template to automate dataset generation for ten tasks using a LLM (GPT-4). 
This automated approach generated valid code for the tasks, creating datasets of equivalent size to fine-tune the Meta-Llama-3-8B-Instruct model. 
We compared four configurations: 
1) Origin: The base model, 
2) w/o Thought: Fine-tuned with direct-answer supervision, 
3) Llama-GT (w/ LLM-Design): Fine-tuned on datasets generated by LLM-synthesized code, and 
4) Llama-GT (w/ Human-Design): Fine-tuned on datasets generated by human-designed code.

As shown in Figure \ref{llm-generated}, Llama-GT (w/ LLM-Design) significantly improves reasoning capabilities over the Origin model, outperforming w/o Thought on Polynomial tasks. 
However, on NP-hard tasks, the LLM-generated code struggles to produce high-quality thought sequences, resulting in performance similar to w/o Thought ($0.509$ vs. $0.508$). 
While Llama-GT (w/LLM-Design) lags behind Llama-GT (w/Human-Design) in both categories, it offers advantages like lower construction costs for unseen problems and better compatibility with optimization methods. 
Future work will focus on developing frameworks to improve the quality and generality of LLM-generated datasets.

\begin{figure}[htb!]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.8\columnwidth]{figs/llm-design.png}}
\caption{Performance comparison of Meta-Llama-3-8B-Instruct variants on Polynomial and NP-hard tasks: Base model (Origin), fine-tuned with direct-answer datasets (w/o Thought),datasets generated using LLM-synthesized code Llama-GT (w/LLM-Design), and datasets generated using human-designed code Llama-GT (w/Human-Design). The values represent the average ratio of the number of optimal solutions achieved across different tasks.}
\label{llm-generated}
\end{center}
% \vskip -0.2in
\end{figure}

\subsection{BoN-Enhanced Optimality Rates versus Heuristics}
% 我们对比了微调后的模型和启发式方法的性能差异。我们这里选择了贪心算法和随机算法，为每一个任务设计了对应的贪心算法和随机算法。可以看到，微调后的模型能够远远超过随机的性能，同时能够逼近贪心的性能。这里需要注意的是，贪心算法需要对每一个任务进行人工设计代码，所以微调后的模型能够实现更强的通用性。

% We propose a generalized optimality ratio metric for evaluating combinatorial optimization algorithm performance. For each problem instance \( I \), we first obtain the provably optimal solution \( Opt(I) \) using the commercial-grade solver Gurobi, which employs exact methods with mathematically guaranteed optimality certifications. The optimality ratio for algorithm \( A \) on instance \( I \) of graph combinatorial optimization (GCO) problem \( \tau \) is formally defined as:
% \begin{equation}
% \text{Rate}(I,A) = \min \biggl\{ \frac{Opt(I)}{A(I)}, \frac{A(I)}{Opt(I)} \biggr\}
% \end{equation}
% where \( A(I) \) denotes the algorithm's solution value and \( Opt(I) \) represents the optimal value. This symmetric formulation ensures consistent normalization across both maximization and minimization problems. For maximization tasks (e.g., \textit{Maximum Independent Set (MIS)}), where \( A(I) \leq Opt(I) \), the ratio \( \frac{A(I)}{Opt(I)} \) directly measures approximation quality within \([0,1]\). For minimization problems (e.g., \textit{Minimum Vertex Cover (MVC)}), the inverse ratio \( \frac{Opt(I)}{A(I)} \) appropriately penalizes suboptimal solutions while maintaining the same normalized range. This unified metric facilitates cross-problem performance comparisons while preserving interpretability of near-optimal solutions.

We introduce a generalized optimality ratio metric for evaluating the quality of a found solution given an instance. 
For each problem instance \( I \), the optimal solution \( x^* \) is obtained using Gurobi, which guarantees exact optimality. 
% we first obtain the provably optimal solution \( x^* \) using the commercial-grade solver Gurobi, which employs exact methods with mathematically guaranteed optimality certifications. 
The optimality ratio for a solution \( x \) on the instance \( I \) of a GCO problem \( \tau \) is formally defined as:
\begin{equation}
\text{Rate}(I,x) = \min \biggl\{ \frac{\phi(x^*)}{\phi(x)}, \frac{\phi(x)}{\phi(x^*)} \biggr\}
\end{equation}
where \( \phi(\cdot) \) is the evaluation function of the solution of \( \tau \). 
This symmetric ratio works for both maximization and minimization tasks. 
For maximization tasks (e.g., MIS), where \( \phi(x) \leq \phi(x^*) \), the ratio \( \frac{\phi(x)}{\phi(x^*)} \) directly measures approximation quality within \([0,1]\). 
For minimization problems (e.g., MVC), the inverse ratio \( \frac{\phi(x^*)}{\phi(x)} \) appropriately penalizes suboptimal solutions while maintaining the same normalized range. 
This metric enables cross-problem performance comparisons while maintaining interpretability of near-optimal solutions.

Figure \ref{fig:vs_heuristic} demonstrates the average optimality ratio through comprehensive evaluations across $1,000$ graph instances ($500$ small and $500$ large) spanning $6$ NP-Hard tasks: GED, MCP, MCS, MIS, MVC and TSP. 
Our base model (\( n=1 \), without Best-of-\( N \) enhancement) achieves remarkable optimality ratios of $93.9$\% on small graphs and $79.1$\% on large graphs, outperforming random baselines by significant margins of $1.9$\% and $20.7$\% respectively. 
These results demonstrate the inherent effectiveness of our Llama-GT model in generalizing across problem scales and types.

% To further enhance solution quality, we implement the Best-of-N (BoN) strategy - a powerful inference-time computation technique that generates \( n \) candidate solutions per instance and selects the optimal candidate. Scaling the beam size \( n \) yields progressive performance improvements: BoN(n=32) achieves 98.7\% optimality on small graphs, surpassing conventional greedy algorithms (96.3\%). For large graphs, BoN(n=32) reaches 88.4\% optimality compared to the greedy baseline's 87.9\%.

% This integration of BoN significantly narrows the performance gap between data-driven approaches and manual heuristic design. While traditional methods rely on domain-specific rules (e.g., vertex degree prioritization in Maximum Independent Set), our framework leverages parallelized inference-time search through BoN to enhance solution quality. This approach achieves near-optimal performance while eliminating the need for problem-specific heuristic engineering, demonstrating the versatility of our learning-based paradigm.

\begin{figure*}[htb!]
% \vskip 0.2in
\begin{center}
    \includegraphics[width=\textwidth]{figs/vs_greedy.pdf}
    \caption{Visualization of Greedy Algorithm and LLM-Generated Solution for MIS Problem.
    Top: Step-by-step greedy selection (e.g., node 16 with neighbors $21$, $17$ removed), achieving a $11$-node set.
    Bottom: LLM-generated solution with adaptive heuristics (e.g., prioritizing node $18$ and removing neighbors $2$, $15$, $23$), achieving a $12$-node set.
    }
\label{fig:case_study_vs_greedy}
\end{center}
% \vskip -0.2in
\end{figure*}

\begin{figure}[htb!]
% \vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=.8\columnwidth]{figs/graph-size-bon-optimal-rate-average.png}}
\caption{Average performance of LLMs with BoN strategy and classic solvers on $6$ NP-Hard Tasks (GED, MCP, MCS, MIS, MVC, TSP) for small and large graphs. The values represent the average optimality ratio across different tasks.}
\label{fig:vs_heuristic}
\end{center}
% \vskip -0.2in
\end{figure}

We enhance solution quality with the Best-of-N (BoN) strategy, which generates \( n \) candidate solutions per instance and selects the best. 
With BoN(n=32), optimality improves to 98.7\% on small graphs and $88.4$\% on large graphs, surpassing greedy algorithms ($96.3$\% and $87.9$\%, respectively). 
This technique significantly narrows the performance gap between data-driven approaches and manual heuristics, achieving near-optimal results without problem-specific rules.

% We provide an interesting case study demonstrating that our approach surpasses the traditional greedy algorithm in solving the Maximum Independent Set (MIS) problem, as shown in figure \ref{fig:case_study_vs_greedy}. At the fourth step, while the greedy algorithm selects nodes with minimal degrees (e.g., node 16) and removes their neighbors (e.g., nodes 21 and 17), yielding an MIS of 11 nodes, our LLM-based method leverages adaptive heuristics—such as prioritizing high-impact nodes like 18 (which disrupts more connections) and dynamically optimizing selections based on evolving graph structures—to achieve a superior 12-node MIS. By balancing local node attributes (e.g., degree) with global topological insights, the LLM avoids the myopic decisions inherent to the greedy approach, which often prioritizes short-term gains (e.g., low-degree nodes like 16) at the expense of overall solution quality.

A case study in the MIS problem (Figure \ref{fig:case_study_vs_greedy}) highlights our approach’s superiority. 
While the greedy algorithm selects low-degree nodes (node $16$), our method uses adaptive heuristics to prioritize high-impact nodes (node $18$) and optimize selections based on evolving graph structures, achieving a $12$-node MIS compared to the greedy algorithm’s $11$. 
This demonstrates how our framework avoids the myopic decisions of traditional heuristics, leading to higher-quality solutions.

% \begin{table}[h!]
% \vskip 0.15in
% \begin{center}
% \caption{Performance comparison of LLMs and classic solvers on Six NP-Complete Tasks(including GED, MCP, MCS, MIS, MVC, TSP) for both small and large graphs. The table shows the percentage of problems where LLMs wins, ties, or loses against two classic solvers: Random and Greedy.}
% \renewcommand{\arraystretch}{1.2} % 增加行距
% \resizebox{\linewidth}{!}{
% \begin{small}
% \begin{sc}
% \begin{tabular}{clcccc}
% \hline
% \multicolumn{2}{l}{} & BoN(n=1) & BoN(n=16) & random & greedy \\ \hline
% \multicolumn{1}{c|}{\multirow{2}{*}{MIS$\mathbb{\uparrow}$}} & Easy & 4.476 & \textbf{4.502} & \textbf{4.502} & \textbf{4.502} \\ 
% \multicolumn{1}{c|}{} & Hard & 12.218 & 12.566 & 12.55 & \textbf{12.57} \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MVC$\mathbb{\downarrow}$}} & Easy & 3.97 & \textbf{3.93} & 4.83 & 3.94 \\ 
% \multicolumn{1}{c|}{} & Hard & 8.992 & 6.882 & 11.002 & \textbf{6.572} \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MCP$\mathbb{\uparrow}$}} & Easy & 4.234 & 4.282 & \textbf{4.286} & 4.264 \\ 
% \multicolumn{1}{c|}{} & Hard & 6.234 & 6.696 & \textbf{6.754} & 6.514 \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{TSP$\mathbb{\downarrow}$}} & Easy & 44499.36 & \textbf{42604.732} & 45363.19 & 43906.14 \\ 
% \multicolumn{1}{c|}{} & Hard & 76979.438 & \textbf{70912.964} & 109137.4 & 73093.264 \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{GED$\mathbb{\downarrow}$}} & Easy & 6.024 & \textbf{5.0} & 6.286 & 5.07 \\ 
% \multicolumn{1}{c|}{} & Hard & 19.97 & 19.532 & 23.426 & \textbf{13.844} \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MCS$\mathbb{\uparrow}$}} & Easy & 3.626 & 4.014 & \textbf{4.088} & 4.062 \\ 
% \multicolumn{1}{c|}{} & Hard & 6.332 & 8.556 & 8.974 & \textbf{9.35} \\ \hline 

% \end{tabular}
% \end{sc}
% \end{small}
% }
% \end{center}
% \vskip -0.1in
% \end{table}

% \begin{table}[h!]
% \begin{center}
% \renewcommand{\arraystretch}{1.2} % 增加行距
% \resizebox{\linewidth}{!}{
% \begin{small}
% \begin{sc}
% \begin{tabular}{clcccc}
% \hline
% \multicolumn{2}{l}{} & BoN(n=1) & BoN(n=16) & random & greedy \\ \hline
% \multicolumn{1}{c|}{\multirow{2}{*}{MIS$\mathbb{\uparrow}$}} & Easy & 4.476 & \textbf{4.502} & 3.87 & \textbf{4.502} \\ 
% \multicolumn{1}{c|}{} & Hard & 12.218 & \textbf{12.566} & 11.234 & 12.562 \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MVC$\mathbb{\downarrow}$}} & Easy & 3.97 & \textbf{3.93} & 6.824 & 3.946 \\ 
% \multicolumn{1}{c|}{} & Hard & 8.992 & 6.882 & 15.33 & \textbf{6.58} \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MCP$\mathbb{\uparrow}$}} & Easy & 4.234 & \textbf{4.282} & 3.838 & 4.234 \\ 
% \multicolumn{1}{c|}{} & Hard & 6.234 & \textbf{6.696} & 4.996 & 6.44 \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{TSP$\mathbb{\downarrow}$}} & Easy & 44499.36 & \textbf{42604.732} & 54244.988 & 43906.14 \\ 
% \multicolumn{1}{c|}{} & Hard & 76979.438 & \textbf{70912.964} & 133885.366 & 73093.264 \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{GED$\mathbb{\downarrow}$}} & Easy & 6.024 & \textbf{5.0} & 9.558 & 5.49 \\ 
% \multicolumn{1}{c|}{} & Hard & 19.97 & 19.532 & 28.4 & \textbf{15.17} \\ \hline 
% \multicolumn{1}{c|}{\multirow{2}{*}{MCS$\mathbb{\uparrow}$}} & Easy & 3.626 & 4.014 & 3.442 & \textbf{4.032} \\ 
% \multicolumn{1}{c|}{} & Hard & 6.332 & \textbf{8.556} & 7.514 & 8.35 \\ \hline 

% \end{tabular}
% \end{sc}
% \end{small}
% }
% \end{center}
% \vskip -0.1in
% \end{table}

% \begin{figure}[H]

% \begin{center}
% \begin{tabular}{c}
%     \includegraphics[width=\columnwidth]{figs/easy-bon-optimal-rate-average.png} \\
%     \textbf{(a)} Small Graph\\[10pt]
%     \includegraphics[width=\columnwidth]{figs/hard-bon-optimal-rate-average.png} \\
%     \textbf{(b)} Large Graph\\
% \end{tabular}
% \caption{Performance comparison of LLMs and classic solvers on Six NP-Hard Tasks(including GED, MCP, MCS, MIS, MVC, TSP) for both small and large graphs. The values represent the average optimal rates across different tasks.}
% \label{fig:vs_heuristic}
% \end{center}
% \end{figure}





% \begin{figure*}[!t]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\textwidth]{figs/radar.png}}
% \caption{Feasibility and accuracy comparison of five selected LLMs on each individual task. The circles represent performance levels, progressing outward from 20\% to 100\% in increments of 20\%.}
% \label{radar}
% \end{center}
% \vskip -0.2in
% \end{figure*}

% \newpage



\section{Conclusion}
This work tackles the limitations of large language models (LLMs) in graph-based combinatorial optimization by proposing the GraphThought framework, which systematically generates high-quality training data through forward and backward MTP frameworks. 
The resulting Llama-GT model, fine-tuned from Llama-3-8B-Instruct, achieves state-of-the-art performance on the GraphArena benchmark—outperforming most existing LLMs despite its compact 8B parameters. 
Our results challenge the necessity of model scaling for advanced reasoning, demonstrating that high-quality dataset generation can unlock efficient combinatorial reasoning capabilities in smaller LLMs.

%% The file named.bst is a bibliography style file for BibTeX 0.99c
% \bibliographystyle{named}
% \bibliography{ijcai24}
% \bibliography{main}
\bibliographystyle{alpha}
\bibliography{main}

\clearpage
\newpage

\appendix

\addcontentsline{toc}{section}{Appendix}
\part{Supplementary Material}
\parttoc

\section{Experiments Setting}
\label{app:setting}

\subsection{Training Parameter}
% 我们训练框架采用了llama-factory，训练阶段为sft，硬件为H100，base model为Llama-3-8B-Instruct，微调方式为lora，数据量为30k，cutoff len为3000，learning rate设置为0.0008，训练轮次为4轮，gradient_accumulation_steps为8，per_device_train_batch_size为8，lr_sheduler_type设置为cosine，max_grad_norm设置为1.0，optim设置为adamw,warmup_steps设置为0，lora_rank设置为8，lora_alpha设置为16，lora_dropout设置为0，lora_target设置为q_proj,v_proj，val_size设置为0.1

Our framework is implemented based on LLaMA-Factory. We perform supervised fine-tuning (SFT) on the Meta-Llama-3-8B-Instruct model using LoRA adaptation. The training process is conducted on a NVIDIA H800 PCIe 80GB GPU with 30K instruction-following examples. Key hyperparameters include a cosine learning rate scheduler with initial value 8e-4, 4 training epochs, and gradient accumulation over 8 steps. The complete configuration details are presented in Table~\ref{tab:training_config}.

\begin{table}[htb!]
\centering
\caption{Training configurations.}
\label{tab:training_config}
\begin{tabular}{ll}
\toprule
\textbf{Category} & \textbf{Setting} \\
\midrule
\textbf{Model Configuration} & \\
\quad Base Model & Llama-3-8B-Instruct \\
\quad Fine-tuning Method & LoRA \\
\quad Hardware & a NVIDIA H800 PCIe 80GB GPU \\
\quad Dataset Size & 30,000 samples \\
\quad Validation Split & 10\% \\
\quad Max Sequence Length & 3,000 tokens \\
\midrule
\textbf{Training Parameters} & \\
\quad Epochs & 4 \\
\quad Learning Rate & 8e-4 \\
\quad Batch Size (per device) & 8 \\
\quad Gradient Accumulation Steps & 8 \\
\quad Optimizer & AdamW \\
\quad Learning Rate Scheduler & Cosine \\
\quad Warmup Steps & 0 \\
\quad Max Gradient Norm & 1.0 \\
\midrule
\textbf{LoRA Configuration} & \\
\quad LoRA Rank & 8 \\
\quad LoRA Alpha & 16 \\ 
\quad LoRA Dropout & 0 \\
\bottomrule
\end{tabular}
\end{table}

% 我们沿用了STaR原文构建数据集的方式，即使用未训练或者训练后的模型首先进行一次推理，然后对未成功得到最优解的数据进行rationalization，获取数据集后，再对base model进行SFT。这里base model我们同样也使用Llama-3-8B-Instruct，参数与上述参数列表保持一致。共迭代4次。
We follow the dataset construction methodology described in the original STaR\cite{zelikman2022star} paper. Specifically, we first perform inference using either an untrained or partially trained model, then conduct rationalization on unsuccessful cases that failed to reach the optimal solution. After collecting these rationalized examples to construct the training dataset, we subsequently perform supervised fine-tuning (SFT) on the base model. For the base model, we consistently employ Llama-3-8B-Instruct with identical hyperparameter settings as listed in the configuration table\ref{tab:training_config}. The complete STaR process undergoes four iterative cycles to progressively enhance model performance.

\subsection{Inference Setting}

% 在推理阶段，我们使用vllm框架来部署我们的模型，同时除了我们自己训练以外的模型及llama-3-8b-instruct，其余加了few-shot thought或者需要重新推理的模型皆使用了api来进行推理（如Deepseek-V3、DeepSeek-R1\footnote{\url{https://api.deepseek.com}}、gpt-4o-mini、llama-3.3-70b、mixtral-8x7b、QwQ-32B-Preview、o1-mini\footnote{\url{https://api.pandalla.ai/}}）。除了o1-mini和DeepSeek-R1外将temperature设置为1.0外，其余模型在推理时将temperature设置为0.1来提高其可复现性。由于开销大，所以每一个模型只推理一次。
% 但在BoN实验中，为了验证增加inference-time computaion是否能提高大模型的推理性能，我们将batchsize设置为16/32，并设置temperature为1.0来提高回答的多样性。

During the inference phase, we deployed the base untrained and trained model using the vllm framework. For comparative analysis, all baseline models except our custom-trained model and the original Meta-Llama-3-8B-Instruct model utilized API-based inference (including Deepseek-V3,\footnote{\url{https://api.deepseek.com}}, gpt-4o-mini, llama-3.3-70b, mixtral-8x7b, QwQ-32B-Preview, and o1-mini\footnote{\url{https://api.pandalla.ai/}}). To ensure reproducibility, we configured the temperature parameter to 0.1 for all models except o1-mini, which used a temperature of 1.0. Due to computational constraints, each model underwent single-pass inference for each test instance.

For Best-of-N(BoN) experiments investigating whether increased inference-time computation enhances model performance, we adjusted the batch size to 16 or 32 while maintaining a temperature setting of 1.0 to maximize response diversity.

\subsection{Evaluation Dataset}

% 1. 我们沿用了grapharena的10个任务的测试数据和问题难度和大小图的分类标准；2. 我们在此基础上对10个任务的输入进行转换，转换成更加统一的格式，方便对输入输出做解析。详细输入格式可见appendix\ref{app:thought_case}。同时这边我们也给出了转换的prompt，以及后续我们会开源转换后的测试数据集。 3. 介绍10个任务, 及其相关的最优性如何评估。
We conduct evaluations using GraphArena's original test datasets with preserved graph size definitions ("small" vs "large") from their benchmark. The 10 tasks are categorized by time complexity and specified as follows:

\begin{itemize}[leftmargin=*]
    \item \textbf{Common Neighbor (Polynomial)}: For graph $\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}$ and nodes $v_1, v_2$, identify all $u \in \mathcal{V}$ connecting to both. Optimal solution maximizes $|S|$ where $S = \{u \mid (u,v_1),(u,v_2) \in \mathcal{E}\}$. {\bf Neighbor} for short.
    
    \item \textbf{Shortest Distance (Polynomial)}: Find the path between $v_1$ and $v_2$ with minimal hops in $\mathcal{G}$. Optimality requires $\min \ell(p_{v_1 \to v_2})$. {\bf Distance} for short.
    
    \item \textbf{Connected Component (Polynomial)}: Select representative nodes covering all components. Optimality demands full coverage ($|\mathcal{C}| =$ total components). {\bf Connected} for short.
    
    \item \textbf{Graph Diameter (Polynomial)}: Identify the longest shortest path. The optimal solution achieves $\max_{u,v} d(u,v)$. {\bf Diameter} for short.
    
    \item \textbf{Maximum Clique Problem (NP-hard)}: A clique is a complete subgraph where every pair of distinct vertices is connected. The task requires identifying the largest subgraph $\mathcal{C} \subseteq \mathcal{V}$ in $\mathcal{G}$. A solution is optimal if no larger clique exists (i.e., $\nexists \mathcal{C}'$ where $|\mathcal{C}'| > |\mathcal{C}|$). {\bf MCP} for short.
    
    \item \textbf{Maximum Independent Set (NP-hard)}: Select an independent set $\mathcal{S}$. Optimality requires identifying the maximum-size set of mutually non-adjacent nodes. {\bf MIS} for short.
    
    \item \textbf{Minimum Vertex Cover (NP-hard)}: Determine a vertex cover $\mathcal{S}$. Optimal solution satisfies covering all edges with the minimum number of nodes. {\bf MVC} for short.
    
    \item \textbf{Maximum Common Subgraph (NP-hard)}: Identify the largest node-induced subgraph $\mathcal{S}$ common to both $\mathcal{G}$ and $\mathcal{H}$ where edge relationships are preserved, with optimality determined by maximizing $|V(\mathcal{S})|$. {\bf MCS} for short.
    
    \item \textbf{Graph Edit Distance (NP-hard)}: Calculate minimal edit operations (node/edge changes) to align $\mathcal{G}$ with $\mathcal{H}$. Optimal solution minimizes total edit cost. {\bf GED} for short.
    
    \item \textbf{Traveling Salesman Problem (NP-hard)}: In a complete graph, find shortest Hamiltonian cycle. Optimal route minimizes $\sum w(e_i)$. {\bf TSP} for short.
\end{itemize}

In alignment with the original study's framework, we maintain the original node range definitions across task categories: (1) Neighbor/Distance tasks operate with small graphs (4-19 nodes) and large graphs (20-50 nodes); (2) Component/Diameter measurements alongside combinatorial problems (MCP/MIS/MVC) utilize small-scale graphs (4-14 nodes) contrasting with large-scale counterparts (15-30 nodes); (3) MCS/GED/TSP adhere to the established size parameters of small (4-9 nodes) versus large (10-20 nodes) instances. By employing the benchmark's test datasets with unmodified size criteria, we preserve experimental continuity and facilitate meaningful cross-study comparisons.

To address more general graph-theoretic challenges and facilitate algorithmic processing, we systematically convert the input representations of these tasks into a unified and structured schema. Detailed descriptions of the input structures and task specifications for each problem are documented in Appendix \ref{app:thought_case}.

\section{Methods for constructing action thoughts and state thoughts for GCO problem}\label{app:a_s_method}

\subsection{Action thoughts generation methods}
For a GCO problem, there are mainly three classes of methods to construct action thought set $A$ with heuristics.  

\noindent - {\bf Ordinary Generation Rule}: Foundational strategies (e.g., greedy selection, random sampling) provide baseline mechanisms for generating thoughts. These rule-based approaches offer broad applicability across diverse problem domains through their simplicity.

\noindent - {\bf Simple Heuristic Thoughts:} Heuristics of GCO problems leverage structural properties of target problems to enhance operational efficiency. Such methods typically derive from simple reasoning conclusions of the problem.

\noindent - {\bf Complex Heuristic Thoughts:} Complex heuristics involve a broader set of operational primitives, presenting two fundamental challenges. First, their intricate implementation mechanisms lack intuitive interpretability. Second, the expanded solution space necessitates consideration of diverse operational combinations. These characteristics hinder LLMs from effectively discerning the underlying principles learning such heuristics.

\noindent - {\bf Mixed Heuristic Thoughts:} The former strategies possess distinct advantages, hybrid approaches demonstrate superior efficacy in specific problem contexts through strategic combination of complementary strategies.

\subsection{State thoughts generation methods}

In solving a GCO problem, maintaining instance state descriptions is essential for two reasons. First, the GCO instance evolves with each reasoning step, requiring the removal of redundant elements. Second, explicitly tracking instance states prevents hallucinations in LLMs. The following state thought generation methods are defined.
 
\noindent -  {\bf Instance Description:} Recording the current GCO instance information forms the foundational state representation. For example describe the node set $V$ and edge set $E$ of a graph $G$.

\noindent -  {\bf Instance Simplification:} Pruning redundant elements after every reasoning step. For example, in maximum independent set (MIS) problems, removing all neighbors of the current MIS set from the graph $G$.

\noindent -  {\bf Instance Reduction:} Transforming instances into equivalent problem. For instance, solving MIS of $G$ can be reduced to finding minimum vertex cover (MVC) of $G$'s complement graph $\bar{G}$.

\noindent -  {\bf Solution Description:} The solution information not only emphasizes the importance of the solution but also shows the changes of the solution. This prompts the LLM to explicitly track how selected actions influence the current solution.

\noindent -  {\bf Solving flag:} Formal stopping criteria marking solution completion through state indicators.	

\section{Usual action thoughts and state thoughts for GCO problem}
\label{app:a_s}
 
In graph optimization problems, the fundamental heuristic operations primarily comprise four canonical primitives: node addition, node deletion, edge addition, and edge deletion. Formally, let $\mathbb{A}$ denote the action thought space for graph optimization, which includes the following actions:
\begin{itemize}
    \item Add Nodes Based on the Given Optimal Solution ($a_1$): Add one or more nodes to the current solution set based on the given optimal solution.
    \item Add Nodes Based on Rules ($a_2$): Add one or more nodes to the current solution set using rules such as greedy or random selection.
    \item Add Nodes Based on Simple Prior Knowledge ($a_3$): Add one or more nodes to the current solution set using simple prior knowledge.
    \item Add Nodes Based on Complex Prior Knowledge ($a_4$): Add one or more nodes to the current solution set using complex prior knowledge.
    \item Remove Nodes Based on the Given Optimal Solution ($a_5$): Remove one or more nodes from the current solution set based on the given optimal solution.
    \item Remove Nodes Based on Rules ($a_6$): Remove one or more nodes from the current solution set using rules such as greedy or random selection.
    \item Remove Nodes Based on Simple Prior Knowledge ($a_7$): Remove one or more nodes from the current solution set using simple prior knowledge.
    \item Remove Nodes Based on Complex Prior Knowledge ($a_8$): Remove one or more nodes from the current solution set using complex prior knowledge.
    \item Add Edges Based on the Given Optimal Solution ($a_9$): Add one or more edges to the current solution set based on the given optimal solution.
    \item Add Edges Based on Rules ($a_{10}$): Add one or more edges to the current solution set using rules such as greedy or random selection.
    \item Add Edges Based on Simple Prior Knowledge ($a_{11}$): Add one or more edges to the current solution set using simple prior knowledge.
    \item Add Edges Based on Complex Prior Knowledge ($a_{12}$): Add one or more edges to the current solution set using complex prior knowledge.
    \item Remove Edges Based on the Given Optimal Solution ($a_{13}$): Remove one or more edges from the current solution set based on the given optimal solution.
    \item Remove Edges Based on Rules ($a_{14}$): Remove one or more edges from the current solution set using rules such as greedy or random selection.
    \item Remove Edges Based on Simple Prior Knowledge ($a_{15}$): Remove one or more edges from the current solution set using simple prior knowledge.
    \item Remove Edges Based on Complex Prior Knowledge ($a_{16}$): Remove one or more edges from the current solution set using complex prior knowledge.
\end{itemize}

The fundamental state thought space $\mathbb{S}$ for graph optimization problems is defined through node and edge set representations. Formally, the canonical state components are structured as follows:

\begin{itemize}
    \item Solving State ($s_1$): Describes the solving state to determine whether the process is complete.
    \item Add Nodes to the Graph ($s_2$): Describes the operation of adding nodes to the original graph for subsequent solving.
    \item Remove Nodes from the Graph ($s_3$): Describes the operation of removing nodes from the original graph for subsequent solving.
    \item Add Edges to the Graph ($s_4$): Describes the operation of adding edges to the original graph for subsequent solving.
    \item Remove Edges from the Graph ($s_5$): Describes the operation of removing edges from the original graph for subsequent solving.
    \item Graph Node Set ($s_6$): Describes the set of all nodes or partial nodes in the original graph.
    \item Graph Edge Set ($s_7$): Describes the set of all edges or partial edges in the original graph.
    \item Current Solution Set ($s_8$): Describes the set of elements in the current solution.
    \item Final Solution Set ($s_9$): Describes the set of elements in the final solution.
\end{itemize}


% \section{More Related Work}
% @wenhao

\section{Concrete Applications of Forward and Backward MTP Frameworks}

\subsection{A Forward MTP for the Connected Components Problem}\label{sec:forward_c_c}

The Connected Components (CC) problem requires identifying all maximally connected subgraphs in an undirected graph $G$. Formally, given $G=(V,E)$, the goal is to partition $V$ into disjoint subsets $\{C_1,\ldots,C_k\}$ where each $C_i$ forms a connected subgraph.

{\bf Action Thought Generation Methods:}
\begin{itemize}
    \item {\bf A simple heuristic thought: Breadth-First Search (BFS)}, systematically explores node neighborhoods through queue-based traversal (lines 1 and 6 of Algorithm~\ref{algo:template_bfs}).
    \item {\bf An ordinary generation rule: Random Selection}, chooses initial nodes for BFS through random sampling (line 3 of Algorithm \ref{algo:template_cc} ).
\end{itemize}
These action thoughts in the three lines constitute the set $A$.

{\bf State Thought Generation Methods:}
\begin{itemize}
    \item {\bf Instance Simplification}: Add an unvisited node to the queue of nodes to be visited (line 11 of Algorithm~\ref{algo:template_bfs}).
    \item {\bf Solution Description}: Current connected component being explored (line 14 of Algorithm~\ref{algo:template_bfs},  line 9 of Algorithm \ref{algo:template_cc}).
    \item {\bf Solving Flag}: Indicator for algorithm completion (line 16 of Algorithm~\ref{algo:template_bfs} ).
\end{itemize}
These state thoughts in the four lines constitute the set $S$.

A forward MTP for CC is shown as follows. $\text{RandomSelect}(G)$ select randomly a node $u$ of $G$.

\begin{algorithm}[htb!]
\caption{ A Thoughts Template for Connected Component Problem }\label{algo:template_cc}
\begin{algorithmic}[1]
    \REQUIRE Graph $G = (V,E)$
    \STATE $CC \leftarrow \emptyset$;\COMMENT{Initialize connected components}
    \WHILE{$V \ne \emptyset$}
        \STATE Action: choose a node for BFS randomly;
        \STATE $u \leftarrow \text{RandomSelect}(G)$; \COMMENT{Random node selection}
        \STATE $C_u \leftarrow \text{BFS}(G, u)$;\COMMENT{Component discovery}
        \STATE $CC \leftarrow CC \cup \{C_u\}$;
        \STATE $V \leftarrow V \setminus C_u$;\COMMENT{Graph simplification}
    \ENDWHILE
    \STATE State: describe connected components in $CC$;
    \STATE {\bf return} $CC$;
\end{algorithmic}
\end{algorithm}

In BFS, the queue $L$ stores nodes awaiting visitation, while set $C$ maintains all visited nodes. When $L \neq \emptyset$, the algorithm selects a node $v$ of $L$ to visit, then adds $v$'s unvisited neighbors to $L$. PopFrom(L) pops the first node of $L$. Neighbor($G$,$v$) returns all neighbor node of $v$ in $G$. AddTo($w$, $L$) appends $w$ to the end of $L$.
\begin{algorithm}[htb!]
\caption{ Breadth-First Search($G$,$u$)}\label{algo:template_bfs}
\begin{algorithmic}[1]
    \REQUIRE Graph $G$, start node $u$
    \ENSURE Connected component $C$
    \STATE Action: Start BFS at node $u$ of $G$;
    \STATE $L \leftarrow \{u\}$; \COMMENT{ Nodes waiting to be visited}
    \STATE $C \leftarrow \emptyset$; \COMMENT{ Visited nodes }
    \WHILE{$L \ne \emptyset$}
        \STATE $v \leftarrow$ PopFrom(L);\COMMENT{Select unvisited node}
        \STATE Action: add $v$ to the current component;
        \STATE $C \leftarrow C \cup \{v\}$;
        \FOR{$w \in$ Neighbor($G$,$v$)}
            \IF{$w \notin C \land w\notin L$} 
                \STATE \text{AddTo}($w, L$);\COMMENT{Record unvisited nodes}
                \STATE State: add an unvisited neighbor $w$ to $L$;
            \ENDIF
        \ENDFOR
        \STATE State: show the current visited nodes $C$;
    \ENDWHILE
    \STATE State: finished, show the connected component $C$;
    \STATE {\bf return} $C$;
\end{algorithmic}
\end{algorithm}

\subsection{A Backward MTP for the MIS Problem}\label{sec:backward_mis}

The MIS problem identifies the largest subset of non-adjacent nodes. The AddOne thought comprises two specialized operations:
\begin{itemize}
    \item \textbf{AddOne: Add Isolated Nodes}, immediately incorporates all isolated nodes into the current solution $MIS$ (line 4 of Algorithm \ref{algo:template_mis}).
    \item \textbf{AddOne: Add Optimal Nodes}, selectively integrates one node from solver outputs into the current solution $MIS$ (line 6 of Algorithm \ref{algo:template_mis}).
\end{itemize}
The first action atomically adds all isolated nodes to the current solution because all isolated nodes belong to the optimal MIS solution. These action thoughts in the two lines constitute the set $A$.

{\bf State Thought Generation Methods:}
\begin{itemize}
    \item {\bf Instance Description}: Graph $G$'s current structure (line~13 of Algorithm \ref{algo:template_mis})
    \item {\bf Instance Simplification}: Graph simplification operations (line~10 of Algorithm \ref{algo:template_mis}) 
    \item {\bf Solution Description}: Current/final solution candidates (lines~9 \&~15 of Algorithm \ref{algo:template_mis})
    \item {\bf Solving Flag}: Termination conditions (line 15 of Algorithm \ref{algo:template_mis})
\end{itemize}
These state thoughts in the four lines constitute the set $S$.

A backward MTP for MIS  is shown as follows. An integer programming model of MIS problem is put into Gurobi, which serves as an optimal solution solver. Isolated($G$) returns all nodes of $G$ without neighbors.

\begin{algorithm}[htb!]
\caption{ A Thought Template for MIS}\label{algo:template_mis}
\begin{algorithmic}[1]
\REQUIRE Graph $G = (V, E)$, a mis solver $\mathcal{X}$.
\STATE $OPT\leftarrow \mathcal{X}(G)$;\COMMENT{Compute optimal MIS}
\STATE $MIS \leftarrow \emptyset$;\COMMENT{Initialize solution}
\WHILE{$V \ne \emptyset$}
    \STATE Action: add all isolated nodes to $MIS$;
    \STATE $MIS \leftarrow MIS \cup \text{Isolated}(G)$;\COMMENT{Add all isolated nodes}
    \STATE Action: add one node of $OPT$ to  $MIS$;
    \STATE $u \leftarrow \text{AddOne}(OPT)$;\COMMENT{Add optimal node}
    \STATE $MIS \leftarrow MIS \cup\{ u\}$;
    \STATE State: describe the current $MIS$;
    \STATE State: delete all neighbors of $u$ in G;
    \STATE $V \leftarrow V \setminus (\text{Isolated}(G) \cup \text{Neighbor}(G,u)  \cup \{u\})$; \COMMENT{ Remove useless nodes}
    \STATE $OPT \leftarrow OPT \setminus MIS$;
    \STATE State: describe the current $G$;
\ENDWHILE
\STATE State: finished, describe the solution $MIS$;
\STATE {\bf return} $MIS$.
\end{algorithmic}
\end{algorithm}

\section{Automated Thought Dataset Generation Template}
\label{app:prompt}
% 在这里，我们提供外层、内层的prompt，

\subsection{Outer Prompt}
\begin{lstlisting}

You are a professional mathematician and computer scientist. I am working on solving a graph theory problem called {TASK NAME}. {TASK DESCRIPTON} I want to reconstruct the steps involved in solving this graph theory problem starting from the optimal solution. Please help me construct a subset of combinations of states and actions from the following state thought space and action thought space, so that the algorithm using this subset can clearly and step-by-step output the optimal reasoning process for solving {task.task_full_name} in textual form. Please do not use any third-party libraries or known algorithms to simply obtain the final answer. What we need is the reasoning process for solving the problem in as much detail as possible.
The states describe the transformations and intermediate stages of the graph during the solution process. Each element in the state thought space is defined and explained as follows:
1. Solving State: Describes the solving state to determine whether the process is complete.
2. Add Nodes to the Graph: Describes the operation of adding nodes to the original graph for subsequent solving.
3. Remove Nodes from the Graph: Describes the operation of removing nodes from the original graph for subsequent solving.
4. Add Edges to the Graph: Describes the operation of adding edges to the original graph for subsequent solving.
5. Remove Edges from the Graph: Describes the operation of removing edges from the original graph for subsequent solving.
6. Graph Node Set: Describes the set of all nodes or partial nodes in the original graph.
7. Graph Edge Set: Describes the set of all edges or partial edges in the original graph.
8. Current Solution Set: Describes the set of elements in the current solution.
9. Final Solution Set: Describes the set of elements in the final solution.
The actions represent operations performed on the solution set. Each element in the action thought space is defined and explained as follows:
1. Add Nodes Based on the Given Optimal Solution: Add one or more nodes to the current solution set based on the given optimal solution.
2. Add Nodes Based on Rules: Add one or more nodes to the current solution set using rules such as greedy or random selection.
3. Add Nodes Based on Simple Prior Knowledge: Add one or more nodes to the current solution set using simple prior knowledge.
4. Add Nodes Based on Complex Prior Knowledge: Add one or more nodes to the current solution set using complex prior knowledge.
5. Remove Nodes Based on the Given Optimal Solution: Remove one or more nodes from the current solution set based on the given optimal solution.
6. Remove Nodes Based on Rules: Remove one or more nodes from the current solution set using rules such as greedy or random selection.
7. Remove Nodes Based on Simple Prior Knowledge: Remove one or more nodes from the current solution set using simple prior knowledge.
8. Remove Nodes Based on Complex Prior Knowledge: Remove one or more nodes from the current solution set using complex prior knowledge.
9. Add Edges Based on the Given Optimal Solution: Add one or more edges to the current solution set based on the given optimal solution.
10. Add Edges Based on Rules: Add one or more edges to the current solution set using rules such as greedy or random selection.
11. Add Edges Based on Simple Prior Knowledge: Add one or more edges to the current solution set using simple prior knowledge.
12. Add Edges Based on Complex Prior Knowledge: Add one or more edges to the current solution set using complex prior knowledge.
13. Remove Edges Based on the Given Optimal Solution: Remove one or more edges from the current solution set based on the given optimal solution.
14. Remove Edges Based on Rules: Remove one or more edges from the current solution set using rules such as greedy or random selection.
15. Remove Edges Based on Simple Prior Knowledge: Remove one or more edges from the current solution set using simple prior knowledge.
16. Remove Edges Based on Complex Prior Knowledge: Remove one or more edges from the current solution set using complex prior knowledge.
Here, I'll give you two examples about what to output:
Example 1:
{
    "input": "In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the maximum independent set in the graph and list the steps and results for each iteration. The Maximum Independent Set problem is an optimization problem in graph theory that aims to identify the largest set of vertices in a graph, where no two vertices in the set are adjacent."
    "output": {"Solving State":  "Determine whether the current graph is an empty graph.", "Add Nodes Based on Simple Prior Knowledge": "Add isolated nodes: [].", "Add Nodes Based on the Given Optimal Solution": "Add the most appropriate node: [].", "Remove Nodes from the Graph": "Remove the neighboring nodes of the node: [].", "Graph Node Set": "The remaining nodes of the graph are: [].", "Current Solution Set": "The current Independent Set is: [].", "Final Solution Set": "The maximum independent set is []."}
}
Example 2:
{
    "input": "In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph and two nodes, please help me find the common neighbor nodes of the given two nodes in the graph."
    "output": {"Graph Node Set": "The neighboring nodes of the node <chosen node 1>: [].", "Graph Node Set": "The neighboring nodes of the node <chosen node 2>: [].", "Final Solution Set": "The common neighbor nodes of the two nodes are: []."}
}
Please provide the state and action combinations along with their descriptions for {TASK NAME} based on the format of "output" above. {TASK DESCRIPTION} Do not provide any explanations or descriptions related to "output" and there is no need to provide any examples. Since the nodes and edges of the original graph will be provided in the input, in order to keep the output inference text brief, please avoid choosing Graph Node Set and Graph Edge Set to describe the original graph unless necessary. 

\end{lstlisting}

\subsection{Inner Prompt}

\begin{lstlisting}

You are a professional mathematician and computer science expert. I am working on solving a graph theory problem called {task.task_full_name}. {task.task_description()} I would like to reconstruct the steps involved in solving this graph theory problem starting from the optimal solution. Please help me build a Python function using all the provided combinations of states and actions, so that this function can return the reasoning steps to solve the problem. Please do not use any third-party libraries or known algorithms to simply obtain the final answer. What we need is the reasoning process for solving the problem in as much detail as possible.
Here is two examples:
Example 1:
{
	"input": "In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the maximum independent set in the graph and list the steps and results for each iteration. The Maximum Independent Set problem is an optimization problem in graph theory that aims to identify the largest set of vertices in a graph, where no two vertices in the set are adjacent. Here's the combination of states and actions constructed from expert: {{"Solving State":  "Determine whether the current graph is an empty graph.", "Add Nodes Based on Simple Prior Knowledge": "Add isolated nodes: [].", "Add Nodes Based on the Given Optimal Solution": "Add the most appropriate node: [].", "Remove Nodes from the Graph": "Remove the neighboring nodes of the node: [].", "Graph Node Set": "The remaining nodes of the graph are: [].", "Current Solution Set": "The current Independent Set is: [].", "Final Solution Set": "The maximum independent set is []."}}"
    "output": ```python
def mis_optimal_trace(G_: nx.Graph, optimal_solution: List[int]) -> Tuple[str, List[int]]:
    G = G_.copy()
    s = ""
    mis = optimal_solution.copy()
    I = []
    while G: # Solving State
        Isopnts = [u for u in G if len(list(G.neighbors(u))) == 0]
        I.extend(Isopnts)
        s += f"Add isolated nodes: {{list(set(Isopnts))}}.\\n" # Add Nodes Based on Simple Prior Knowledge
        G.remove_nodes_from(Isopnts)
        if not G:
            s += f"The remaining nodes of the graph are: {{list(G.nodes)}}.\\n" # Graph Node Set
            break
        
        mis = [elem for elem in mis if elem not in I]
        chosen_node = random.choice(mis)
        I.append(chosen_node)
        s += f"Add the most appropriate node: {{chosen_node}}.\\n" # Add Nodes Based on the Given Optimal Solution
        s += f"Remove the neighboring nodes of the node {{chosen_node}}: {{list(G.neighbors(chosen_node))}}.\\n" # Remove Nodes from the Graph

        G.remove_nodes_from(list(G.neighbors(chosen_node)))
        G.remove_node(chosen_node)
        s += f"The remaining nodes of the graph are: {{list(G.nodes)}}.\\n" # Graph Node Set
        s += f"The current Independent Set is: {{I}}.\\n" # Current Solution Set
    
    s += "Finished!\\n"
    s += f'The maximum independent set is {{mis}}.' # Final Solution Set
    return s, I
```
}
Example 2:
{
	"input": "In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph and two nodes, please help me find the common neighbor nodes of the given two nodes in the graph. Here's the combination of states and actions constructed from expert: {{"Graph Node Set": "The neighboring nodes of the node <chosen node 1>: [].", "Graph Node Set": "The neighboring nodes of the node <chosen node 2>: [].", "Final Solution Set": "The common neighbor nodes of the two nodes are: []."}}"
    "output": ```python
def neighbor_optimal_trace(G_: nx.Graph, chosen_nodes: List[int], optimal_solution: List[int]) -> Tuple[str, List[int]]:
    G = G_.copy()
    s = ""
    neighbor_node_1 = list(G.neighbors(chosen_nodes[0]))
    neighbor_node_2 = list(G.neighbors(chosen_nodes[1]))
    common_neighbor_nodes = list(set(neighbor_node_1) & set(neighbor_node_2))
    s += f"The neighboring nodes of the node {{chosen_nodes[0]}}: {{neighbor_node_1}}.\\n" # Graph Node Set
    s += f"The neighboring nodes of the node {{chosen_nodes[1]}}: {{neighbor_node_2}}.\\n" # Graph Node Set
    s += f"The common neighbor nodes of the two nodes are: {{common_neighbor_nodes}}.\\n" # Final Solution Set
    return s, common_neighbor_nodes
```
}
Here's the input: "{TASK DESCRIPTION} Here's the combination of states and actions constructed from expert: {OUTER RESPONSE}."
Please provide the python code of solution for {TASK NAME} based on the format of "output" above. Do not provide any explanations or descriptions related to "output," and there is no need to provide any examples. Please use all the provided states and actions set to construct the function. Here's the function definition header: "{TASK FUNCTION HEADER}". Please construct the optimal Python code to solve the problem. Ensure the code is correct, the reasoning steps are complete, and the code is highly readable, while minimizing the length of the reasoning text as much as possible. And you must concatenate '{TASK OUTPUT FORMAT}' at the end of your code, where <final answer> is a python list. Do not modify, add, or delete any words or symbols in the statement, and do not change case.

\end{lstlisting}

\subsection{Example}

% 这里我们以Minimum Vertex Cover问题为例展示使用上述template所生成的Outer output和Inner output，问题描述如下所示。

Here, we use the Minimum Vertex Cover problem as an example to demonstrate the Outer output and Inner output generated using the above-mentioned template. The problem description is as follows.

\begin{lstlisting}
In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the minimum vertex cover in the graph and list the steps and results for each iteration. The Minimum Vertex Cover problem is an optimization problem in graph theory that aims to find the smallest set of vertices in a graph such that every edge in the graph is incident to at least one vertex in the set.
\end{lstlisting}

{\bf{Outer Output}}

\begin{lstlisting}

{'Solving State': 'Determine whether the current graph is an empty graph.', 'Add Nodes Based on Simple Prior Knowledge': 'Add nodes with the highest degree: [].', 'Add Nodes Based on the Given Optimal Solution': 'Add the most appropriate node: [].', 'Remove Nodes from the Graph': 'Remove the selected node and its incident edges: [].', 'Graph Node Set': 'The remaining nodes of the graph are: [].', 'Graph Edge Set': 'The remaining edges of the graph are: [].', 'Current Solution Set': 'The current Vertex Cover is: [].', 'Final Solution Set': 'The minimum vertex cover is [].'}

\end{lstlisting}

{\bf{Inner Output}}

\begin{lstlisting}

def mvc_optimal_trace(G_: nx.Graph, optimal_solution: List[int]) -> str:
    G = G_.copy()
    s = ""
    mvc = optimal_solution.copy()
    C = []
    while G:  # Solving State
        if not G.edges:
            s += "The graph is empty.\n"
            break
        
        # Add Nodes Based on Simple Prior Knowledge
        degrees = dict(G.degree())
        max_degree_node = max(degrees, key=degrees.get)
        C.append(max_degree_node)
        s += f"Add nodes with the highest degree: {max_degree_node}.\n"
        
        # Remove Nodes from the Graph
        neighbors = list(G.neighbors(max_degree_node))
        G.remove_node(max_degree_node)
        s += f"Remove the selected node and its incident edges: {max_degree_node}.\n"
        
        # Graph Node Set and Edge Set
        s += f"The remaining nodes of the graph are: {list(G.nodes)}.\n"
        s += f"The remaining edges of the graph are: {list(G.edges)}.\n"
        
        # Current Solution Set
        s += f"The current Vertex Cover is: {C}.\n"
    
    s += "Finished!\n"
    s += f'The minimum vertex cover is {mvc}.'  # Final Solution Set
    return s
\end{lstlisting}

% \section{Case Study}

% \subsection{LLMs Surpass Greedy Algorithms in MIS}
% \label{app:greedy case}

% % 在这个例子中，我们展示了大语言模型在求解最大独立集问题时，展现出超越贪心算法性能的一个例子。其中在第四步中，贪心算法选择了度最小的节点16

% This case study demonstrates that our approach surpasses the traditional greedy algorithm in solving the Maximum Independent Set (MIS) problem. At the fourth step, while the greedy algorithm selects nodes with minimal degrees (e.g., node 16) and removes their neighbors (e.g., nodes 21 and 17), yielding an MIS of 11 nodes, our LLM-based method leverages adaptive heuristics—such as prioritizing high-impact nodes like 18 (which disrupts more connections) and dynamically optimizing selections based on evolving graph structures—to achieve a superior 12-node MIS. By balancing local node attributes (e.g., degree) with global topological insights, the LLM avoids the myopic decisions inherent to the greedy approach, which often prioritizes short-term gains (e.g., low-degree nodes like 16) at the expense of overall solution quality.

% \begin{figure}[htb!]
% % \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figs/vs greedy.pdf}}
% \caption{Visualization of Greedy Algorithm and LLM-Generated Solution for Maximum Independent Set (MIS) Problem.
% Left: Step-by-step greedy selection (e.g., node 16 with neighbors 21, 17 removed).
% Right: LLM-generated solution with adaptive heuristics (e.g., prioritizing node 18 and removing neighbors 2, 15, 23).
% We visualize the LLM's reasoning process and manually reformat the greedy results to align with the LLM's thought structure.}
% \label{icml-historical}
% \end{center}
% % \vskip -0.2in
% \end{figure}

\section{Detailed Case Studies of Thought Processes}
\label{app:thought_case}
In this section, we present ten concrete task examples accompanied by their corresponding reasoning thoughts to systematically demonstrate the thought construction methodology.

\begin{table*}[htb!]
\centering
\small
\caption{An example of the Connected Component task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, and the task is to identify one representative node from each connected component within the graph. \\\\

\textbf{Input}

The graph has 7 nodes. The nodes are numbered from 0 to 6, and the edges are: [(0, 3), (2, 6), (3, 4), (4, 6)]. \\\\

\textbf{Output}

Choose node 0 as the start point of the current connectivity component.\\
Add node 0 into the connected component list.\\
Add the unvisited neighboring nodes of the node 0 into the search queue: [3].\\
Add node 3 into the connected component list.\\
Add the unvisited neighboring nodes of the node 3 into the search queue: [4].\\
Add node 4 into the connected component list.\\
Add the unvisited neighboring nodes of the node 4 into the search queue: [6].\\
The current connected component is: [0, 3, 4].\\
Add node 6 into the connected component list.\\
Add the unvisited neighboring nodes of the node 6 into the search queue: [2].\\
Add node 2 into the connected component list.\\
Add the unvisited neighboring nodes of the node 2 into the search queue: [].\\
Finished!\\
Connected component 1: Nodes = [0, 3, 4, 6, 2], Representative node = 0.\\
Choose node 1 as the start point of the current connectivity component.\\
Add node 1 into the connected component list.\\
Add the unvisited neighboring nodes of the node 1 into the search queue: [].\\
Finished!\\
Connected component 2: Nodes = [1], Representative node = 1.\\
Choose node 5 as the start point of the current connectivity component.\\
Add node 5 into the connected component list.\\
Add the unvisited neighboring nodes of the node 5 into the search queue: [].\\
Finished!\\
Connected component 3: Nodes = [5], Representative node = 5.\\
The representative nodes for each connected component are: [0, 1, 5]. \\

\bottomrule

\label{table:Connected Component}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Shortest Distance task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the shortest path between two nodes in the graph and list the steps and results for each iteration. The shortest path between two nodes is defined as the path with the fewest edges that connect the source node to the target node. If no path exists, output an empty path. \\\\

\textbf{Input}

The graph has 9 nodes. The nodes are numbered from 0 to 8, and the edges are: [(0, 7), (0, 8), (1, 3), (1, 8), (2, 6), (3, 6), (4, 8), (6, 7), (7, 8)]. The source node is 4, and the target node is 3. \\\\

\textbf{Output}

Current path: [4], the neighboring nodes of the node 4: [8].\\
Current path: [4, 8], the neighboring nodes of the node 8: [0, 1, 4, 7].\\
Current path: [4, 8, 0], the neighboring nodes of the node 0: [7, 8].\\
Current path: [4, 8, 1], the neighboring nodes of the node 1: [3, 8].\\
Found the target node 3.\\
The shortest path is [4, 8, 1, 3]. \\

\bottomrule

\label{table:Shortest Distance}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Common Neighbor task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph and two nodes, please help me find the common neighbor nodes of the given two nodes in the graph. \\\\

\textbf{Input}

The graph has 10 nodes. The nodes are numbered from 0 to 9, and the edges are: [(0, 1), (0, 3), (0, 5), (0, 7), (0, 8), (1, 3), (1, 6), (1, 7), (1, 8), (1, 9), (2, 3), (2, 4), (2, 7), (2, 8), (2, 9), (3, 5), (3, 6), (3, 7), (3, 9), (4, 7), (4, 9), (5, 6), (5, 8), (6, 8), (6, 9), (7, 8), (7, 9), (8, 9)]. The given nodes are [7, 3]. \\\\

\textbf{Output}

The neighboring nodes of the node 7: [0, 1, 2, 3, 4, 8, 9].\\
The neighboring nodes of the node 3: [0, 1, 2, 5, 6, 7, 9].\\
The common neighbor nodes of the two nodes are: [0, 1, 2, 9]. \\

\bottomrule

\label{table:Common Neighbor}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Minimum Vertex Cover task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the minimum vertex cover in the graph and list the steps and results for each iteration. The Minimum Vertex Cover problem is an optimization problem in graph theory that aims to find the smallest set of vertices in a graph such that every edge in the graph is incident to at least one vertex in the set. \\\\

\textbf{Input}

The graph has 10 nodes. The nodes are numbered from 0 to 9, and the edges are: [(1, 5), (1, 6), (2, 7)]. \\\\

\textbf{Output}

Remove isolated nodes: [0, 3, 4, 8, 9].\\
Add the most appropriate node: 1.\\
The current Vertex Cover is: [1].\\
Remove the edges of node 1: [(1, 5), (1, 6)].\\
Remove isolated nodes: [1, 5, 6].\\
Add the most appropriate node: 2.\\
The current Vertex Cover is: [1, 2].\\
Remove the edges of node 2: [(2, 7)].\\
Remove isolated nodes: [2, 7].\\
There is no edge left in the graph.\\
Finished!\\
The minimum vertex cover is [1, 2]. \\

\bottomrule

\label{table:Minimum Vertex Cover}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Maximum Independent Set task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the maximum independent set in the graph and list the steps and results for each iteration. The Maximum Independent Set problem is an optimization problem in graph theory that aims to identify the largest set of vertices in a graph, where no two vertices in the set are adjacent. \\\\

\textbf{Input}

The graph has 8 nodes. The nodes are numbered from 0 to 7, and the edges are: [(3, 4), (5, 6)]. \\\\

\textbf{Output}

Add isolated nodes: [0, 1, 2, 7].\\
Add the most appropriate node: 3.\\
The current Independent Set is: [0, 1, 2, 7, 3].\\
Remove the neighboring nodes of the node 3: [4].\\
The remaining nodes of the graph are: [5, 6].\\
Add isolated nodes: [].\\
Add the most appropriate node: 5.\\
The current Independent Set is: [0, 1, 2, 7, 3, 5].\\
Remove the neighboring nodes of the node 5: [6].\\
The remaining nodes of the graph are: [].\\
Finished!\\
The maximum independent set is [0, 1, 2, 7, 3, 5]. \\

\bottomrule

\label{table:Maximum Independent Set}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Graph Diameter task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the diameter of the graph and list the steps and results for each iteration. The diameter of a graph is the longest shortest path between any two nodes in the graph. \\\\

\textbf{Input}

The graph has 10 nodes. The nodes are numbered from 0 to 9, and the edges are: [(0, 1), (0, 9), (1, 3), (2, 3), (3, 4), (3, 6), (4, 6), (5, 9), (6, 8), (7, 8)]. \\\\

\textbf{Output}

Choose the most appropriate node as source node of the diameter path: 7.\\
Calculating the longest path among all the shortest paths from the graph and source node 7.\\
The neighboring nodes of the node 7: [8].\\
Update the shortest path from source node to node [8] with distance 1.\\
The neighboring nodes of the node 8: [6, 7].\\
Update the shortest path from source node to node [6] with distance 2.\\
The neighboring nodes of the node 6: [3, 4, 8].\\
Update the shortest path from source node to node [3, 4] with distance 3.\\
The neighboring nodes of the node 3: [1, 2, 4, 6].\\
Update the shortest path from source node to node [1, 2] with distance 4.\\
The neighboring nodes of the node 1: [0, 3].\\
Update the shortest path from source node to node [0] with distance 5.\\
The neighboring nodes of the node 0: [1, 9].\\
Update the shortest path from source node to node [9] with distance 6.\\
The neighboring nodes of the node 9: [0, 5].\\
Update the shortest path from source node to node [5] with distance 7.\\
The farthest target from the source 7 is node 5 with distance 7.\\
The diameter path is [7, 8, 6, 3, 1, 0, 9, 5]. \\

\bottomrule

\label{table:Graph Diameter}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Maximum Clique Problem task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge. I'll give an instance of a graph, please help me find the maximum clique in the graph and list the steps and results for each iteration. The Maximum Clique Problem is an optimization problem in graph theory that aims to identify the largest set of vertices in a graph, where every two vertices in the set are adjacent. \\\\

\textbf{Input}

The graph has 9 nodes. The nodes are numbered from 0 to 8, and the edges are: [(2, 8), (3, 6), (4, 5), (5, 7)]. \\\\

\textbf{Output}

Add the most appropriate node: 8.\\
The current clique is: [8].\\
The common neighbors of nodes in the current clique are: [2].\\
Add the most appropriate node: 2.\\
The current clique is: [8, 2].\\
Finished!\\
The maximum clique is [8, 2]. \\

\bottomrule

\label{table:Maximum Clique Problem}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Traveling Salesman Problem task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j,k) means that node i and node j are connected with an undirected edge with weight k. I'll give an instance of a graph, please help me find the solution of the TSP problem in the given graph and list the steps and results for each iteration. The Traveling Salesman Problem (TSP) is a classic combinatorial optimization problem where, given a set of cities(nodes), the goal is to find the shortest possible route that visits each city(node) exactly once and returns to the starting city(node). For each iteration, please select the most appropriate node considering it's distance from the previous node and it's influence of total travel distance. \\\\

\textbf{Input}

The graph has 7 nodes. The nodes are numbered from 0 to 6, and the edges are: [(0, 1, 8309), (0, 2, 3986), (0, 3, 2254), (0, 4, 1983), (0, 5, 396), (0, 6, 2655), (1, 2, 1416), (1, 3, 9346), (1, 4, 3061), (1, 5, 3220), (1, 6, 7309), (2, 3, 8945), (2, 4, 6117), (2, 5, 9132), (2, 6, 4310), (3, 4, 7830), (3, 5, 1095), (3, 6, 3040), (4, 5, 9538), (4, 6, 6771), (5, 6, 1899)]. \\\\

\textbf{Output}

Choose starting node: 0.\\
Choose node 4 after node 0 with weight 1983.\\
The current subtour is [0, 4].\\
Choose node 1 after node 4 with weight 8309.\\
The current subtour is [0, 4, 1].\\
Choose node 2 after node 1 with weight 6117.\\
The current subtour is [0, 4, 1, 2].\\
Choose node 6 after node 2 with weight 7309.\\
The current subtour is [0, 4, 1, 2, 6].\\
Choose node 3 after node 6 with weight 8945.\\
The current subtour is [0, 4, 1, 2, 6, 3].\\
Choose node 5 after node 3 with weight 1899.\\
The current subtour is [0, 4, 1, 2, 6, 3, 5].\\
Choose node 0 after node 5 with weight 2254.\\
The current subtour is [0, 4, 1, 2, 6, 3, 5, 0].\\
Finished!\\
The optimal solution of TSP is: [0, 4, 1, 2, 6, 3, 5, 0]. \\

\bottomrule

\label{table:Traveling Salesman Problem}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Maximum Common Subgraph task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge, we call i and j are neighbors. Please find the maximum common subgraph of two graphs and list the steps and results for each iteration. The maximum common subgraph problem is defined as follows: given two graphs G and H, the task is to find a maximum subgraph sub\_g of G and a subgraph sub\_h of H such that sub\_g and sub\_h are isomorphic. That means some nodes of G and H should be put in the nodes lists sub\_g\_nodes and sub\_h\_nodes respectively satisfying the following 3 simple requirements. Firstly, sub\_g\_nodes and sub\_h\_nodes has the equal length. Secondly, any two nodes in sub\_g\_nodes or sub\_h\_nodes are different. Thirdly, for any available indices i and j, if (sub\_g\_nodes[i], sub\_g\_nodes[j]) is an edge of G, then (sub\_h\_nodes[i], sub\_h\_nodes[j]) must be also an edge of H, and vice versa. The objective is to maximize the length of sub\_g\_nodes. For each iteration, please choose a node u of G and another node v of H such that the indices of u'neighbors in sub\_g\_nodes must be same to the indices of v's neighbors in sub\_h\_nodes. \\\\

\textbf{Input}

The graph G has 5 nodes, the nodes are numbered from 0 to 4, and the edges are: [(0, 4), (1, 2), (1, 3), (1, 4), (3, 4)]. The graph H has 5 nodes, the nodes are numbered from 0 to 4, and the edges are: [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (1, 4), (2, 4)]. \\\\

\textbf{Output}

Choose node 0 of G, and node 3 of H that has a similar neighborhood structure.\\
The current nodes lists of subgraphs are: [0], [3].\\
In sub\_g\_nodes, node 1 does not connect any node.\\
In sub\_h\_nodes, node 2 does not connect any node.\\
So choose node 1 of G, and node 2 of H as indices of their individual neighbors in the corresponding nodes lists are the same.\\
The current nodes lists of subgraphs are: [0, 1], [3, 2].\\
In sub\_g\_nodes, node 3 connects nodes of indices [1] which are [1] in G, and does not connect nodes of indices [0] which are [0] in G.\\
In sub\_h\_nodes, node 4 connects nodes of indices [1] which are [2] in H, and does not connect nodes of indices [0] which are [3] in H.\\
So choose node 3 of G, and node 4 of H as indices of their individual neighbors in the corresponding nodes lists are the same.\\
The current nodes lists of subgraphs are: [0, 1, 3], [3, 2, 4].\\
In sub\_g\_nodes, node 4 connects all nodes which are [0, 1, 3] in G.\\
In sub\_h\_nodes, node 1 connects all nodes which are [2, 3, 4] in H.\\
So choose node 4 of G, and node 1 of H as indices of their individual neighbors in the corresponding nodes lists are the same.\\
The current nodes lists of subgraphs are: [0, 1, 3, 4], [3, 2, 4, 1].\\
Finished!\\
The optimal solution of MCS is: [0, 1, 3, 4], [3, 2, 4, 1]. \\

\bottomrule

\label{table:Maximum Common Subgraph}
\end{tabular}

\vspace{-5mm}
\end{table*}


\begin{table*}[htb!]
\centering
\small
\caption{An example of the Graph Edit Distance task.} 
\begin{tabular}{p{0.95\linewidth}}
\toprule

\textbf{Task Description}

In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge, we call i and j are neighbors. Next, I'll give you two special graphs, where each node has a label. You are required to solve the Graph Edit Distance problem between two graphs. The problem is to establish a one-to-one mapping between nodes from graph G to graph H, ensuring that each node in graph G corresponds to exactly one node in graph H, vice versa. For convenience, the notation i~j denotes one node mapping from node i in graph G to node j in graph H, also abbreviated as map(i)=j. For the node mapping i~j, if labels of node i and node j are the same, then the cost associated with i~j is 0, otherwise the cost is 1. For any two node mapping i~j and p~q from graph G to graph H, if (i,p) is an edge of G and (j,q) is not an edge of H, then i~j and p~q incur an edge deletion cost of 1, else if (i,p) is not an edge of G and (j,q) is an edge of H, then the edge insertion cost is 1, otherwise the edge cost is 0. The total cost is the sum of all node mapping costs and all edge costs. The objective is to minimize the total cost of a node mapping from G to H. You should represent the node mapping with an integer list L, such that node i~L[i] for all i.
 For instance, if node 0 in graph G corresponds to node 1 in graph H, node 1 in graph G corresponds to node 0 in graph H, and node 2 remains unchanged, the mapping would be represented as [1, 0, 2, ...]. \\\\

\textbf{Input}

The graph G has 5 nodes, the nodes are: [(0, 'Si'), (1, 'O'), (2, 'Si'), (3, 'Na'), (4, 'S')], and the edges are: [(0, 2), (0, 4), (1, 2), (1, 3), (1, 4), (2, 4), (3, 4)]. The graph H has 5 nodes, the nodes are: [(0, 'C'), (1, 'Na'), (2, 'N'), (3, 'Mg'), (4, 'N')], and the edges are: [(0, 1), (0, 2), (0, 3), (1, 3), (1, 4), (2, 3), (2, 4)]. \\\\

\textbf{Output}

Mapping node 0 labeled \textless Si\textgreater  of graph G to node 4 labeled \textless N\textgreater  of graph H.\\
As the mapping two nodes 0~4 have different labels, the node mapping cost adds 1.\\
The current mapping is [4] with cost 1.\\
Mapping node 1 labeled \textless O\textgreater  of graph G to node 0 labeled \textless C\textgreater  of graph H.\\
As the mapping two nodes 1~0 have different labels, the node mapping cost adds 1.\\
The current mapping is [4, 0] with cost 2.\\
Mapping node 2 labeled \textless Si\textgreater  of graph G to node 2 labeled \textless N\textgreater  of graph H.\\
As the mapping two nodes 2~2 have different labels, the node mapping cost adds 1.\\
The current mapping is [4, 0, 2] with cost 3.\\
Mapping node 3 labeled \textless Na\textgreater  of graph G to node 1 labeled \textless Na\textgreater  of graph H.\\
As the mapping two nodes 3~1 have the same label, the node mapping cost adds 0.\\
Currently for any index u of [0], node u does not connect node 3 in graph G, but map(u)=L[u] connects to map(3)=1 in graph H, so the new node mapping 3~1 generate edge addition cost 1.\\
The current mapping is [4, 0, 2, 1] with cost 4.\\
Mapping node 4 labeled \textless S\textgreater  of graph G to node 3 labeled \textless Mg\textgreater  of graph H.\\
As the mapping two nodes 4~3 have different labels, the node mapping cost adds 1.\\
Currently for any index u in [0], node u connects node 4 in graph G, but map(u)=L[u] does not connect to map(4)=3 in graph H, so the new node mapping 4~3 generate edge deletion cost 1.\\
The current mapping is [4, 0, 2, 1, 3] with cost 6.\\
Finished!\\
The optimal mapping of GED is: [4, 0, 2, 1, 3]. \\

\bottomrule

\label{table:Graph Edit Distance}
\end{tabular}

\vspace{-5mm}
\end{table*}

\end{document}


