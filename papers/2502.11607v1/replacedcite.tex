\section{Related Work}
\subsection{LLMs for Graph Combinatorial Optimization}

The integration of Large Language Models (LLMs) into solving Graph Combinatorial Optimization (GCO) problems has garnered significant attention in recent years. Several works have attempted to leverage LLMs for GCO problems from various perspectives. Jin et al.____ provided a comprehensive survey on the application of LLMs on graphs, categorizing potential scenarios into pure graphs, text-attributed graphs, and text-paired graphs. They discussed techniques such as using LLMs as predictors, encoders, and aligners. Chen et al.____ explored the potential of LLMs in graph machine learning, especially for node classification tasks, and investigated two pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. Liu et al.____ introduced the concept of Graph Foundation Models (GFMs) and classified existing work into categories based on their dependence on graph neural networks and LLMs. Ren et al.____ conducted a survey on LLMs for graphs, proposing a taxonomy to categorize existing methods based on their framework design.

Many studies have focused on using prompt engineering and optimization to extract the intrinsic knowledge of pretrained LLMs in the form of text or code. Wang et al.____ proposed the NLGraph benchmark to evaluate LLMs on graph reasoning tasks and introduced Build-a-Graph and Algorithmic Prompting to enhance their performance. Iklassov et al.____ introduced Self-Guiding Exploration (SGE) to improve LLM performance on combinatorial problems. Elhenawy et al.____ explored the use of multimodal LLMs to solve the Traveling Salesman Problem (TSP) through visual reasoning. Tang et al.____ introduced GraphArena, a benchmarking tool for evaluating LLMs on graph computational problems. Li et al.____ proposed GraphTeam, a multi-agent system based on LLMs for graph analysis. Guo et al.____ conducted an empirical evaluation of LLMs on graph-structured data. Fatemi et al.____ explored encoding graph-structured data as text for LLMs. Hu et al.____ introduced GraphAgent-Reasoner, a multi-agent collaboration framework for graph reasoning. Perozzi et al.____ proposed GraphToken to explicitly represent structured data for LLMs. Cao et al.____ proposed GraphInsight to improve LLM comprehension of graph structures. Feng et al.____ introduced LLM4Hypergraph to evaluate LLMs on hypergraphs. Yuan et al.____ presented GraCoRe, a benchmark for assessing LLMs' graph comprehension and reasoning. Firooz et al.____ examined the impact of contextual proximity on LLM performance in graph tasks. Skianis et al.____ explored using pseudo-code prompting to improve LLM performance on graph problems. Agrawal et al.____ designed graph traversal tasks to test LLMs' structured reasoning capabilities. Wang et al.____ investigated the influence of temperature on LLM reasoning performance. Dai et al.____ revisited LLMs' graph reasoning ability through case studies. Zhong et al.____ explored the impact of graph visualizations on LLM performance. Sanford et al.____ analyzed the reasoning capabilities of transformers via graph algorithms.

Other works have focused on training graph foundation models using dense embeddings from LLM pretraining. Drakulic et al.____ proposed GOAL, a generalist model for solving multiple combinatorial optimization problems. Jiang et al.____ introduced UNCO, a unified framework for solving various COPs using LLMs. Anonymous____ proposed a unified model for diverse CO problems using a transformer backbone. Chai et al.____ introduced GraphLLM to boost the graph reasoning ability of LLMs. Wei et al.____ proposed GITA, a framework integrating visual and textual information for graph reasoning.


\subsection{Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought Methods}
The Chain-of-Thought (CoT) prompting technique, introduced by Wei et al. ____, demonstrates that generating intermediate reasoning steps can significantly improve LLMs' performance on complex reasoning tasks. This method was further extended by Yao et al. ____, who proposed the Tree of Thoughts (ToT) framework, enabling exploration over coherent units of text (thoughts) to enhance problem-solving abilities. The ToT approach allows LMs to consider multiple reasoning paths and self-evaluate choices, significantly improving performance on tasks requiring non-trivial planning or search. Besta et al. ____ introduced the Graph of Thoughts (GoT), which advances prompting capabilities by modeling LLM-generated information as an arbitrary graph. This approach enables combining arbitrary LLM thoughts into synergistic outcomes and enhances thoughts using feedback loops. Besta et al. ____ further demystified the concepts of chains, trees, and graphs of thoughts, providing a taxonomy of structure-enhanced LLM reasoning schemes. These studies highlight the importance of structured reasoning topologies in improving LLMs' problem-solving abilities.

\subsection{Self-Correction, Planning, and Search Strategy Learning}
Huang et al. ____ examined the role of self-correction in LLMs, finding that intrinsic self-correction without external feedback often fails to improve reasoning accuracy. In contrast, Lehnert et al. ____ proposed the Searchformer model, which predicts the search dynamics of the A* algorithm, significantly outperforming traditional planners on complex decision-making tasks. Gandhi et al. ____ introduced the Stream of Search (SoS) approach, teaching language models to search by representing the process as a flattened string. This method significantly improved search accuracy and enabled flexible use of different search strategies.