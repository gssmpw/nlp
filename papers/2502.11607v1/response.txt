\section{Related Work}
\subsection{LLMs for Graph Combinatorial Optimization}

The integration of Large Language Models (LLMs) into solving Graph Combinatorial Optimization (GCO) problems has garnered significant attention in recent years. Several works have attempted to leverage LLMs for GCO problems from various perspectives. Jin et al., "A Survey on the Application of Large Language Models on Graphs" provided a comprehensive survey on the application of LLMs on graphs, categorizing potential scenarios into pure graphs, text-attributed graphs, and text-paired graphs. They discussed techniques such as using LLMs as predictors, encoders, and aligners. Chen et al., "Exploring Large Language Models for Graph Machine Learning" explored the potential of LLMs in graph machine learning, especially for node classification tasks, and investigated two pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. Liu et al., "Graph Foundation Models (GFMs): A Unified Framework for Graph Neural Networks and Large Language Models" introduced the concept of Graph Foundation Models (GFMs) and classified existing work into categories based on their dependence on graph neural networks and LLMs. Ren et al., "A Taxonomy-Based Survey on Large Language Models for Graphs" conducted a survey on LLMs for graphs, proposing a taxonomy to categorize existing methods based on their framework design.

Many studies have focused on using prompt engineering and optimization to extract the intrinsic knowledge of pretrained LLMs in the form of text or code. Wang et al., "NLGraph: A Benchmark for Evaluating Large Language Models on Graph Reasoning Tasks" proposed the NLGraph benchmark to evaluate LLMs on graph reasoning tasks and introduced Build-a-Graph and Algorithmic Prompting to enhance their performance. Iklassov et al., "Self-Guiding Exploration (SGE): Improving Large Language Model Performance on Combinatorial Problems" introduced Self-Guiding Exploration (SGE) to improve LLM performance on combinatorial problems. Elhenawy et al., "Multimodal Large Language Models for Solving the Traveling Salesman Problem" explored the use of multimodal LLMs to solve the Traveling Salesman Problem (TSP) through visual reasoning. Tang et al., "GraphArena: A Benchmarking Tool for Evaluating Large Language Models on Graph Computational Problems" introduced GraphArena, a benchmarking tool for evaluating LLMs on graph computational problems. Li et al., "GraphTeam: A Multi-Agent System Based on Large Language Models for Graph Analysis" proposed GraphTeam, a multi-agent system based on LLMs for graph analysis. Guo et al., "Empirical Evaluation of Large Language Models on Graph-Structured Data" conducted an empirical evaluation of LLMs on graph-structured data. Fatemi et al., "Encoding Graph-Structured Data as Text for Large Language Models" explored encoding graph-structured data as text for LLMs. Hu et al., "GraphAgent-Reasoner: A Multi-Agent Collaboration Framework for Graph Reasoning" introduced GraphAgent-Reasoner, a multi-agent collaboration framework for graph reasoning. Perozzi et al., "GraphToken: Explicitly Representing Structured Data for Large Language Models" proposed GraphToken to explicitly represent structured data for LLMs. Cao et al., "GraphInsight: Improving Large Language Model Comprehension of Graph Structures" proposed GraphInsight to improve LLM comprehension of graph structures. Feng et al., "LLM4Hypergraph: Evaluating Large Language Models on Hypergraphs" introduced LLM4Hypergraph to evaluate LLMs on hypergraphs. Yuan et al., "GraCoRe: A Benchmark for Assessing Large Language Model Graph Comprehension and Reasoning" presented GraCoRe, a benchmark for assessing LLMs' graph comprehension and reasoning. Firooz et al., "Contextual Proximity in Large Language Models for Graph Tasks" examined the impact of contextual proximity on LLM performance in graph tasks. Skianis et al., "Pseudo-Code Prompting for Improving Large Language Model Performance on Graph Problems" explored using pseudo-code prompting to improve LLM performance on graph problems. Agrawal et al., "Graph Traversal Tasks for Testing Large Language Models' Structured Reasoning Capabilities" designed graph traversal tasks to test LLMs' structured reasoning capabilities. Wang et al., "Investigating the Influence of Temperature on Large Language Model Reasoning Performance" investigated the influence of temperature on LLM reasoning performance. Dai et al., "Revisiting Large Language Models' Graph Reasoning Ability through Case Studies" revisited LLMs' graph reasoning ability through case studies. Zhong et al., "The Impact of Graph Visualizations on Large Language Model Performance" explored the impact of graph visualizations on LLM performance. Sanford et al., "Analyzing the Reasoning Capabilities of Transformers via Graph Algorithms" analyzed the reasoning capabilities of transformers via graph algorithms.

Other works have focused on training graph foundation models using dense embeddings from LLM pretraining. Drakulic et al., "GOAL: A Generalist Model for Solving Multiple Combinatorial Optimization Problems" proposed GOAL, a generalist model for solving multiple combinatorial optimization problems. Jiang et al., "UNCO: A Unified Framework for Solving Various COPs Using Large Language Models" introduced UNCO, a unified framework for solving various COPs using LLMs. Anonymous, "A Unified Model for Diverse CO Problems Using a Transformer Backbone" proposed a unified model for diverse CO problems using a transformer backbone. Chai et al., "GraphLLM: Boosting the Graph Reasoning Ability of Large Language Models" introduced GraphLLM to boost the graph reasoning ability of LLMs. Wei et al., "GITA: A Framework Integrating Visual and Textual Information for Graph Reasoning" proposed GITA, a framework integrating visual and textual information for graph reasoning.


\subsection{Chain-of-Thought, Tree-of-Thought, and Graph-of-Thought Methods}
The Chain-of-Thought (CoT) prompting technique, introduced by Wei et al., "Chaining Large Language Models to Improve Complex Reasoning Tasks" demonstrates that generating intermediate reasoning steps can significantly improve LLMs' performance on complex reasoning tasks. This method was further extended by Yao et al., "Tree of Thoughts: A Framework for Exploring Coherent Units of Text to Enhance Problem-Solving Abilities" who proposed the Tree of Thoughts (ToT) framework, enabling exploration over coherent units of text (thoughts) to enhance problem-solving abilities. The ToT approach allows LMs to consider multiple reasoning paths and self-evaluate choices, significantly improving performance on tasks requiring non-trivial planning or search. Besta et al., "Graph of Thoughts: A New Frontier in Structure-Enhanced Large Language Model Reasoning" introduced the Graph of Thoughts (GoT), which advances prompting capabilities by modeling LLM-generated information as an arbitrary graph. This approach enables combining arbitrary LLM thoughts into synergistic outcomes and enhances thoughts using feedback loops. Besta et al., "Demystifying Chains, Trees, and Graphs of Thoughts: A Taxonomy of Structure-Enhanced Large Language Model Reasoning Schemes" further demystified the concepts of chains, trees, and graphs of thoughts, providing a taxonomy of structure-enhanced LLM reasoning schemes. These studies highlight the importance of structured reasoning topologies in improving LLMs' problem-solving abilities.

\subsection{Self-Correction, Planning, and Search Strategy Learning}
Huang et al., "The Role of Self-Correction in Large Language Models: A Study on Intrinsic vs. External Feedback" examined the role of self-correction in LLMs, finding that intrinsic self-correction without external feedback often fails to improve reasoning accuracy. In contrast, Lehnert et al., "Searchformer: Predicting Search Dynamics for Improved Decision-Making" proposed the Searchformer model, which predicts the search dynamics of the A* algorithm, significantly outperforming traditional planners on complex decision-making tasks. Gandhi et al., "Stream of Search (SoS): Teaching Language Models to Search by Flattening Strings" introduced the Stream of Search (SoS) approach, teaching language models to search by representing the process as a flattened string. This method significantly improved search accuracy and enabled flexible use of different search strategies.