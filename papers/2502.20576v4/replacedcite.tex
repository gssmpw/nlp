\section{Related Work}
% \subsection{LLM Router}
% MF

% CausalLM


\subsection{LLM Generation Length Prediction}
Predicting LLM generation length is crucial for optimizing computational resources. Early attempts like Magnus ____ employed random forest algorithms but achieved limited accuracy. Subsequent research has explored two main directions of prediction models: encoder-only models for classification (DynamoLLM ____, S3 ____, TerriInfer ____, SSJF ____, and $\mu$3 ____) and decoder-only models for generative prediction like Perception-only (PO) ____. ____ reformulated this as a ranking problem and utilized listwise ranking for predictor training. Due to the inherent difficulty in precise output length prediction, several works ____ adopted a bucketing approach for approximate estimation. However, these existing studies primarily emphasize computational efficiency while overlooking a critical aspect: model capability - specifically, whether a model has the capability to answer a given query. Our research addresses this limitation by simultaneously considering both generation length and model capability, aiming to optimize both system effectiveness and efficiency.

% S3 ____

% Perception-only ____

% TerriInfer ____

% DynamoLLM ____

% Magnus ____

% SSJF ____

% $\mu$3 ____

\subsection{General Scheduling}
Scheduling is a fundamental problem in computer systems. First-come-first-serve (FCFS) provides simplicity by processing requests in arrival order, while shortest-job-first (SJF) and its preemptive variant, shortest-remaining-time-first (SRTF), optimize for average latency by prioritizing quick tasks. Though theoretically optimal for minimizing average latency, these approaches can lead to starvation of longer jobs. Multi-level feedback queue (MLFQ) attempts to balance fairness and efficiency through multiple priority queues, but struggles with mixed workloads. In practice, modern Linux systems employ the completely fair scheduler (CFS), which uses a red-black tree to track process runtime and aims to give each process a fair share of CPU time