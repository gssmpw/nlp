\section{Introduction}
\label{sec:intro}
Image deblurring seeks to restore high-quality images from these blur versions. Due to the ill-posed nature, traditional method~\cite{karaali2017edge} attempts to tackle it by imposing various priors to limit the solution space. However, creating such priors is difficult and often lacks generalizability, making them impractical for real-world applications.

In recent years, a variety of Convolutional Neural Networks (CNNs)~\cite{FSNet, SFNet, IRNeXt, Zamir2021MPRNet,alggao2024learning} have been developed for image deblurring. The fundamental component of a CNN is a convolutional layer followed by an activation function. The convolution operation ensures local connectivity and translational invariance, while the activation function adds non-linearity to the network. However, CNNs face inherent limitations, such as local receptive fields and a lack of dependence on input content, which restrict their ability to eliminate long-range blur degradation perturbation. To overcome such limitations, Transformers~\cite{kong2023efficient, potlapalli2023promptir, Zamir2021Restormer, u2former} have been introduced in image deblurring. They leverage the adaptive weights of the self-attention mechanism and excel at capturing global dependencies, demonstrating superior performance compared to CNN-based approaches.

\begin{figure}[tb] % use float package if you want it here
	\centering
	\includegraphics[width=1\linewidth]{que.jpg}
	\caption{Varying degrees of degradation across different regions. The top row is the blurred image and the bottom row is the sharp image.}
	\label{fig:ques}
\end{figure}
While the aforementioned methods have demonstrated strong performance in image deblurring, they have two key drawbacks: (1) they approximate nonlinear function properties by stacking numerous nonlinear activation functions, and (2) they overlook the varying degrees of degradation across different blur regions of the image. As shown in Figure~\ref{fig:ques}, the degradation in a blurred image varies across different regions. The areas highlighted by the \textcolor{green}{green box} are more severely blurred than those marked by the \textcolor{red}{red box}.



To tackle the first drawback, NAFNet~\cite{chen2022simple} argues that high complexity is unnecessary and proposes a simpler baseline that employs element-wise multiplication instead of nonlinear activation functions, achieving better results with lower computational resources. However, this approach inevitably sacrifices the ability to map complex input-output relationships, making it difficult to manage more intricate scenes. To address the second issue, AdaRevD~\cite{AdaRevD} introduces a classifier to assess the degradation degree of image patches. However, this method relies on a limited number of predefined categories and a fixed blur patch size\footnote{AdaRevD groups the patches into six degradation degrees based on the PSNR between the blurred patch and the sharp patch, and then uses a relatively large patch size of 384 x 384 to classify the degradation degree of each blurred patch.} to specify the degree of degradation, which diminishes its effectiveness in adaptively managing different degrees of degradation across various sizes of blurred patches.
\begin{figure}[tb] % use float package if you want it here
	\centering
	\includegraphics[width=1\linewidth]{para.png}
	\caption{Computational cost vs. PSNR of models on the GoPro dataset~\cite{Gopro}. Our DHNet achieve the SOTA performance with up to 48.9\% of cost reduction.}
	\label{fig:param}
\end{figure}



Based on the analyses presented above, a natural question arises: Is it feasible to devise a network that effectively  performs differential processing for different blur regions with less nonlinear activation function? In pursuit of this objective, we propose DHNet for efficient image deblurring, incorporating several key components. 
1)  We design a Volterra block (VBlock) to investigate non-linearity within the network. VBlock avoids using traditional nonlinear activation functions and instead employs Volterra kernel to enhance linear convolution by facilitating interactions between image pixels. This approach approximates non-linearity without the computational overhead associated with stacking numerous nonlinear functions to map complex input-output relationships.
2) To adaptively identify degradation degrees across varying sizes of blur regions, we propose a degradation degree  recognition expert module (DDRE). DDRE first integrates prior knowledge from a well-trained model to estimate the spatially variable blur information. This enables the router to map the learned degradation representation and assign weights to experts based on both the degree of degradation and the size of the regions. 
We conduct extensive experiments to validate the effectiveness of the proposed networks, demonstrating their remarkable performance advantage over state-of-the-art approaches. As illustrated in Figure~\ref{fig:param}, our DHNet model achieves SOTA performance while requiring less computational cost compared to existing methods.

The main contributions are summarized as follows:
\begin{enumerate}
	\item  We propose an efficient and effective framework for image deblurring, called DHNet, which excels at differentially handling various blur regions while maintaining lower computational costs.
 
    \item  We design a Volterra block (VBlock) to investigate non-linearity within the network, avoiding the previous operation of stacking numerous nonlinear functions to map complex input-output relationships. 
    
    \item  We devise a degradation degree recognition expert module (DDRE), enabling the model adaptively deal with the different degradation degrees of the degraded region.
    
    \item Extensive experiments demonstrate that the proposed DHNet achieves promising performance compared to state-of-the-art methods across synthetic and real-world benchmark datasets.
\end{enumerate}