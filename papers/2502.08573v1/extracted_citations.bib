@article{abdullah2021multimodal,
  title={Multimodal emotion recognition using deep learning},
  author={Abdullah, S. M. S. A. and Ameen, S. Y. A. and Sadeeq, M. A. and Zeebaree, S.},
  journal={Journal of Applied Science and Technology Trends},
  volume={2},
  number={1},
  pages={73--79},
  year={2021}
}

@inproceedings{fan2016video,
  title={Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
  author={Fan, Y. and Lu, X. and Li, D. and Liu, Y.},
  booktitle={Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  pages={445--450},
  year={2016}
}

@article{gupta2024visatronic,
  title={Visatronic: A Multimodal Decoder-Only Model for Speech Synthesis},
  author={Gupta, A. and Likhomanenko, T. and Yang, K. D. and Bai, R. H. and Aldeneh, Z. and Jaitly, N.},
  journal={arXiv preprint arXiv:2411.17690},
  year={2024}
}

@article{hu2021mmgcn,
  title={MMGCN: Multimodal fusion via deep graph convolution network for emotion recognition in conversation},
  author={Hu, J. and Liu, Y. and Zhao, J. and Jin, Q.},
  journal={arXiv preprint arXiv:2107.06779},
  year={2021}
}

@article{kugate2024efficient,
  title={Efficient Key Frame Extraction from Videos Using Convolutional Neural Networks and Clustering Techniques},
  author={Kugate, A. H. and Balannanavar, B. Y. and Goudar, R. H. and Rathod, V. N. and Dhananjaya, G. M. and Kulkarni, A. and Kaliwal, R. B.},
  journal={EAI Endorsed Transactions on Context-aware Systems and Applications},
  volume={10},
  year={2024}
}

@article{mai2022hybrid,
  title={Hybrid contrastive learning of tri-modal representation for multimodal sentiment analysis},
  author={Mai, S. and Zeng, Y. and Zheng, S. and Hu, H.},
  journal={IEEE Transactions on Affective Computing},
  volume={14},
  number={3},
  pages={2276--2289},
  year={2022}
}

@article{pang2023caver,
  title={CAVER: Cross-modal view-mixed transformer for bi-modal salient object detection},
  author={Pang, Y. and Zhao, X. and Zhang, L. and Lu, H.},
  journal={IEEE Transactions on Image Processing},
  volume={32},
  pages={892--904},
  year={2023}
}

