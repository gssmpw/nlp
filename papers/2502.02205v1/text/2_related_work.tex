\subsection{Control of PDE Systems}
The development of control methods in physical systems is critical across various scientific and engineering areas, including PID \citep{1580152}, supervised learning (SL) \citep{holl2020learning,hwang2022solving}, reinforcement learning (RL) \citep{farahmand2017deep, pan2018reinforcement, rabault2019artificial}, and physics-informed neural networks (PINNs) \citep{mowlavi2023optimal}. Among these, PID is one of the earliest and most widely used method \citep{johnson2005pid}, known for its simplicity and effectiveness in regulating physical systems; however, it faces challenges in parameter tuning and struggles with highly nonlinear or time-varying systems. Model Predictive Control (MPC) \cite{garcia1989model,findeisen2002introduction,schwenzer2021review} is another well-known control strategy that optimizes a control sequence over a finite time horizon by solving an optimization problem at each time step, using a dynamic model of the system. As it requires solving an optimization problem in real-time at each time step, it may have a high computational cost and struggle to handle high-dimensional, complex systems effectively.
Furthermore, the adjoint method \citep{protas2008adjoint} and PINNs \citep{mowlavi2023optimal} are also incorporated in PDE control, but they require an explicit form of the PDE. Currently, the diffusion model used in physical systems' control \citep{wei2024generative, hu2024wavelet} integrates the learning of entire state trajectories and control sequences, enabling global optimization that incorporates the physical information learned by the model. However, it does not consider the important cases where safety constraints are required. 

In the field of reinforcement learning (RL), several safe offline RL algorithms have emerged in recent years. CPQ \citep{xu2022constraints} is the first practical safe offline RL method that assigns high costs to out-of-distribution (OOD) and unsafe actions and updates the value function as well as the policy only with safe actions. COptiDICE \citep{lee2022coptidice} is a DICE-based method and corrects the stationary distribution. CDT \citep{liu2023constrained} takes the decision transformer to solve safe offline RL problems as multi-objective optimization. More recent methods such as TREBI \citep{lin2023safe} and FISOR \citep{zheng2024safe} address this problem through diffusion model planning, leveraging the capability of diffusion models to model high-dimensional data. However, none of these algorithms take into account the uncertainty of the predicted safety from the perspective of conformal prediction, nor do they address PDE-constrained scenarios.


\subsection{Conformal Prediction}


Conformal prediction \citep{vovk2005algorithmic} is a statistical framework that constructs prediction intervals guaranteed to contain the true label with a specified probability. Its validity could be compromised, however, by the violation of the core assumption of exchangeability due to distribution shifts in real-world scenarios \citep{chernozhukov2018exact, hendrycks2018using}. 
Recent studies \citep{Cauchois2024Robust} have extended conformal prediction to accommodate various distribution shifts. For example, \citet{Tibshirani2019ConformalPU} proposed weighted conformal prediction to handle covariate shift, where training and test data distributions differ. \citet{Podkopaev2021Disfree} introduced reweighted conformal prediction and calibration techniques to address label shift using unlabeled target data. Adaptive conformal inference \citep{gibbs2021adaptive} provides valid prediction sets in online settings with unknown, time-varying distribution shifts without relying on exchangeability. 
Inspired by conformal prediction, we measure uncertainty based on the distribution of data generated by diffusion models for control problems. This is also the first time the perspective of conformal prediction has been applied to address safety control problems.
