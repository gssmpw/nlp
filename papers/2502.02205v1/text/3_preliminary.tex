\begin{figure*}[t]
\begin{center}
    \includegraphics[scale=0.8]{fig/overview2.pdf}
\end{center}
\vspace{-10pt}
\caption{\textbf{Overview of \proj}. First, we pre-train a diffusion model $p_{\theta}$ on the training data. Then, combined with the uncertainty quantile, we post-train the model to steer its distribution to safer regions with better control objectives. Finally, to improve performance and safety for specific control tasks, we conduct inference-time fine-tuning, again incorporating the uncertainty quantile into the process.}
\vspace{-10pt}
\label{fig:overview}
\end{figure*}

\subsection{Problem Setup}
We consider the following safe control problem of PDE-constrained systems:
\begin{equation}
    \w^*=\argmin_\w\J(\u,\w)\quad\text{s.t.}\quad\mathcal{C}(\u,\w)=0,\quad\score(\u)\leq \score_0,
    \label{eq:origion_optimization}
\end{equation}
where $\u(t,\x):[0,T]\times \Omega\mapsto \mathbb{R}^{d_\u}$ is the system's state trajectory with dimension ${d_\u}$ and $\w(t,\x):[0,T]\times \Omega\mapsto \mathbb{R}^{d_\w}$ is the external control signal with dimension ${d_\w}$. They are both defined on the time range $[0,T]\subset\mathbb{R}$ and spatial domain $\Omega\subset \mathbb{R}^{D}$. 
$\J(\u,\w)$ is the objective of the control problem, and $\mathcal{C}(\u,\w)=0$ is the PDE constraint.

As for the safety constraint, $\score(\u)$ is the safety score and $\score_0$ is the bound of the safety score. 
We need to minimize the control objective while satisfying PDE constraints and constraining the safety score to stay below the bound, which requires a careful balance between safety and control performance. Furthermore, it is important to note that safety and control performance are not on equal footing, and the pursuit of a better objective should be built upon ensuring safety \cite{knight2002safety, cheng2019end}.

\subsection{Diffusion Models and Diffusion Control}
\label{sec:ddpm}

Diffusion models \citep{ho2020denoising} learn data distribution from data in a generative way. They present impressive performance in a broad range of generation tasks. Diffusion models involve diffusion/denoising processes: the diffusion process $q(\x^{\t+1}|\x^\t)=\mathcal{N}(\x^{\t+1};\sqrt{\alpha_\t}\x_\t,(1-\alpha_\t)\mathbf{I})$
corrupts the data distribution $p(\x_0)$ to a prior distribution $\mathcal{N}(\mathbf{0}, \mathbf{I})$, and the denoising process $p_{\theta}(\x^{\t-1}|\x^\t)=\mathcal{N}(\x^{\t-1};\mu_\theta(\x^\t,\t),\sigma_\t \mathbf{I})$ makes sampling in a reverse direction. Here $\t$ is the diffusion/denoising step, $\{\alpha_\t\}_{\t=1}^\T$ and $\{\sigma_\t\}_{\t=1}^\T$ are the noise and variance schedules. In practice, a denoising network $\bepsilon_{\theta}$ is trained to estimate the noise to be removed in each step. 
During inference, the iterative removal of $\bepsilon_{\theta}$ from the prior distribution could generate a new sample that follows the data distribution $p(\x)$. 

Recently, diffusion models \citep{wei2024generative, hu2024wavelet} are applied to solve the control problem as in Eq. \ref{eq:origion_optimization} without the safety constraint $\score(\u)\leq \score_0$. For brevity, we only summarize the light version. These methods transform the physical constraint to a parameterized energy-based model (EBM) $E_{\theta}(\u,\w)$ with the correspondence  $p(\u,\w)\propto \exp({-E_{\theta}(\u,\w)})$. Then the problem is converted to an unconstrained optimization over $\u$ and $\w$ for all physical time steps simultaneously:
\vspace{-2pt}
\begin{gather}
\label{eq:joint_optimization}
\u^*, \w^* = \argmin_{\u, \w}\left[E_\theta(\u,\w) + \lambda\cdot \mathcal{J}(\u,\w)\right],
\end{gather}
where $\lambda$ is a hyperparameter. 
To optimize $E_{\theta}$, a denoising network $\bepsilon_\theta$ is trained to approximate $\nabla_{\u,\w} E_\theta(\u,\w)$ by the following loss:
\begin{align}
\label{eq:training_obj}
\mathcal{L}_\textrm{diffusion}&=\mathbb{E}_{\t\sim U(1,\T),(\u,\w)\sim p(\u,\w),\bepsilon\sim \mathcal{N}(\mathbf{0},\mathbf{I})} \notag \\ 
&\quad [\|\mathbf{\bepsilon} - \bepsilon_\theta(\sqrt{\bar{\alpha}_\t}[\u,\w] + \sqrt{1-\bar{\alpha}_\t} \bepsilon,\t)\|_2^2],
\end{align}
where $\Bar{\alpha}_\t:=\prod_{i=1}^\t\alpha_i$. After $\bepsilon_\theta$ is trained, Eq. \ref{eq:joint_optimization} can be optimized by sampling from an initial sample $(\u^\T,\w^\T)\sim\mathcal{N}(\mathbf{0},\mathbf{I})$, and iteratively running the following process\footnote{In this paper, we use $\mathbf{u}$ to represent state trajectory across time, and $\mathbf{w}$ to represent control signal sequence across time. $\mathbf{u}^k$ denotes the full system trajectory across time at denoising step $k$.}
\begin{align}
\label{eq:1ddpm_inference}
 (\u^{\t-1},\w^{\t-1}) = (\u^{\t},\w^{\t}) - \eta_k\cdot\bepsilon_\theta([\u^{\t},\w^{\t}],\t) \notag \\ 
 +\lambda_k\nabla_{\u,\w}\mathcal{G}(\hat{\u}^\t,\hat{\w}^\t) + \xi, \quad \mathbf{\xi} \sim \mathcal{N} \bigl(\mathbf{0}, \sigma^2_\t \mathbf{I} \bigl)
\end{align}
under the guidance of $\G=\J$ for $\t=\T,\T-1,..., 1$. Here 
$[\hat{\u}^\t,\hat{\w}^\t]$ is the noise-free estimation of $[\u^0, \w^0]$, $[\cdot,\cdot]$ denotes vector concatenation, and $\eta_k$ and $\lambda_k$ are denoising schedules. The final sampling step yields the solution $\w^0$ for the optimization problem in Eq. \ref{eq:joint_optimization}.
