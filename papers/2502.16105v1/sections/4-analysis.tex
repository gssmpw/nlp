We perform an extensive empirical study to investigating three aspects, including: optimality of core concept neurons, fidelity of core concept neurons, and fidelity of neuron interaction weights.
Our experiments are performed on ResNet50 \citep{Resnet} and GoogLeNet \cite{Googlenet} using the ILSVRC2012 validation set \citep{Imagenet}. The models are pretrained in Pytorch \citep{Pytorch}, and layer names follow Pytorch's conventions (e.g., \textit{layer4.2} for ResNet50). 
Unless otherwise specified, the input parameters are \( \tau = 16 \), \( N=50 \), and \( k = 50 \), where the top 50 images with the highest activation on the target neuron are considered as its concept. We will release the source code once the paper is published. 

\begin{wrapfigure}{r}{0.55\textwidth}
    \centering
    \vspace{-5mm}
    \includegraphics[width=0.55\textwidth]{figures/Confidence_interval_of_fig_4.png}
    \vspace{-5mm}
    \caption{\textbf{The difference in losses between core concept neurons and random neuron combinations.} The blue-toned bars represent the average losses, while the pink-toned bars indicate instances where random neuron combinations result in smaller losses compared to core concept neurons.}\label{figure2}
    \vspace{-20pt}
\end{wrapfigure}
\noindent \textbf{Optimality of core concept neurons.}
\label{sec:minimization} According to Definition \ref{def:critical neuron}, the core concept neuron set \( \mathbb{S}_a \) for neuron \( a \) is the set that minimizes the objective function \( \left| \mathcal{V}^{\overline{\mathbb{S}_a}}_a \cap \mathcal{V}_a \right| \) without exceeding the cardinality \( \tau \). To evaluate our heuristic solution, we define a loss function \( \mathcal{L}(S, a) := \left| \mathcal{V}^{\overline{S}}_a \cap \mathcal{V}_a \right| / |\mathcal{V}_a| \), balancing these two objectives.
In this experiment, our objective is to demonstrate that the core concept neurons, $\mathbb{S}_a$, identified by our algorithm are near-optimal.
Ideally, a brute-force search over all possible combinations of $\tau$ neurons would be conducted to demonstrate that these combinations yield a higher loss function value compared to $\mathbb{S}_a$. However, such an approach is computationally infeasible due to its prohibitive cost. Consequently, we perform experiments using a large set of randomly selected combinations.
% Specifically, we aim to show that selecting a random subset of neurons $S$ with the same cardinality as $\mathbb{S}_a$ is likely to result in a higher loss function value compared to $\mathbb{S}_a$. 
Specifically, we use three different values of $\tau$, specifically $10, 30, 50$. For each setting, we randomly select $50$ target neurons (denoted by $a_i$) from $10$ distinct classes (five neurons for each class). For each target neuron $a_i$, we determine its core concept neuron set $\mathbb{S}_{a_i}$ using our algorithm and generate 100 random neuron combinations, with the same cardinality as $\mathbb{S}_{a_i}$, from the preceding layer of $a_i$. In total, the experiments are performed over $15,000$ cases per layer for each model.
We compare the loss differences between $\mathbb{S}_{a_i}$ and the random neuron combinations. These average differences along with 99\% the confidence intervals are shown in Figure \ref{figure2}. Additionally, we report cases where the random combinations resulted in a smaller loss than our core concept neurons. As observed, the average differences are positive in all cases, indicating that replacing the core concept neurons identified by our algorithm with random ones generally leads to a significant increase in the loss for both models. Furthermore, only a few cases show a random combination achieving a smaller loss than our core concept neurons, and in those instances, the gap is negligible.

\noindent \textbf{Fidelity of core concept neurons.} 
\label{sec:fidelity}
We evaluate the impact of the identified core concept neurons on the model's performance by comparing two variants: (1) \emph{Retaining version}--all neurons masked except for the core concept neurons, and (2) \emph{Masking version} version--only the core concept neurons are masked. 
%For clarity, we refer to the first as the \emph{Retaining version} and the second as the \emph{Masking version}. 
Intuitively, a higher performance in the \emph{Retaining version} and a lower performance in the \emph{Masking version} would indicate that the core concept neurons play a significant role in the model's performance. We compare the performance of these two versions against models obtained by performing retraining and masking on equal numbers of random neurons.
%Our experiment focuses on the last 10 layers of ResNet50 and GoogLeNet, as the number of core concept neurons increases significantly in these layers. 
We select 50 random classes and apply the retaining and masking operations at two levels: on a single layer or across multiple layers. In the multi-layer scenario, masking or retaining is applied from the linear classifier down to a specified layer.
Figure \ref{figure4} presents the results for $\tau = 4, 8$, and $16$. The $y$-axis indicates changes in model accuracy, where a value of $1$ implies that masking neurons does not affect predictions.
It is evident that masking core concept neurons consistently results in a more pronounced decline in performance compared to masking random neuron combinations. Moreover, the rate of decline in accuracy, moving from higher to lower layers, is considerably steeper for the core concept neurons than for random neurons. 
The most significant discrepancy occurs at layer \emph{5a} of the GoogLeNet model, where masking core concept neurons at this layer reduces model accuracy to nearly $0$, while masking random neurons has a minimal effect on performance. \emph{Retaining version}, preserving only the core concept neurons allows the model to maintain its performance substantially better than when random neurons are retained. 
This experiment also demonstrates that the value of $\tau$ represents a trade-off between the simplicity of the circuit and the comprehensiveness of capturing the core concept neurons.
A smaller $\tau$ results in greater instability in the modelâ€™s performance during the retaining experiment, leading to a more pronounced performance drop. For more discussion on the impacts of $\tau$, please refer to Appendix \ref{sec:choice_of_tau}.
% The most substantial disparity is observed in the multi-layer scenario of ResNet50, where retaining $16$ core concept neurons nearly preserves the model's full accuracy (close to 1), whereas retaining 16 random neurons reduces accuracy to nearly $0$.

\begin{figure}
\vspace{-12mm}
\begin{center}
\includegraphics[width=0.85\textwidth]{figures/fidelity.png} 
\end{center}
\vspace{-12pt}
\caption{\textbf{Effects of neuron groups on model's performance.} Retaining only the core concept (denoted as CC) neurons preserves high accuracy, whereas masking them leads to a significant drop in performance. In contrast, random neuron combinations show the opposite trend.} \label{figure4}
%\vspace{-20pt}
\vspace{-13pt}
\end{figure}
We conduct an experiment to show that adding non-core neurons to the concept core neurons set identified by NeurFlow has minimal impact the model's performance. Specifically, we perform the Fidelity experiment with $\tau = 16$, incorporating $50\%$ more non-core neurons (i.e., those that are not concept core neurons), and evaluated their impact on model accuracy. These neurons were selected greedily, prioritizing those with the highest scores as ranked by NeuronMCT \cite{neuronmct}. The results in Figure \ref{fig:completeness} (Appendix \ref{sec:choice_of_tau}) indicate that for ResNet-50, adding non-core neurons had little to no effect on improving model performance, confirming that when $\tau$ is sufficiently large, our algorithm ensures completeness.

\noindent \textbf{Fidelity of neuron interaction weights.}
\label{sec:edge_verification}
The edge weight representing the interaction between core concept neurons (or groups of core concept neurons) is defined using Integrated Gradients (IG) (Definition \ref{def:critical neuron}). Without the ground truth, we evaluate the fidelity of edge weights based on the following rationale: if the weights assigned by our definition are meaningful, they should accurately rank the importance of neurons in the preceding layer in detecting the concept represented by a target neuron in the subsequent layer.
We demonstrate that our IG-based scores exhibit a strong correlation with the loss, not only for single neuron setup but also for groups of neurons. Specifically, we randomly select $10$ target neurons from $10$ distinct classes (denoted as $a_i$, where $i = 1, \dots, 10$). For each target neuron $a_i$, we generate random combinations of neurons from the preceding layer. We then measure the correlation between the losses caused by these random neuron combinations and the sum of the absolute values of their IG-based importance scores with respect to $a_i$.
The experiments are conducted using $500$ neuron combinations, with cardinality ($\tau$) varying from $1$ to $50$. Figure \ref{figure3} presents the average correlation across all combinations. The results indicate that for $\tau < 50$, IG-based scores maintain a high correlation across all layers. Notably, for $\tau = 1$, the correlation consistently exceeds $0.6$ in both models, and up to almost perfect correlations for several layers in ResNet50.
While the correlation diminishes as $\tau$ increases, our focus is on a small subset of core concept; thus, for a sparse sub-graph of core concept neurons, these results are considered satisfactory. We further compare our defined IG-based score with other attribution methods, including the one used in \citet{NEUCEPT}, in the Appendix \ref{sec:compare_scoring}.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \vspace{-3mm}    \includegraphics[width=0.5\textwidth]{figures/Correlation.png}
    \vspace{-6mm}
    \caption{Correlation between loss and our defined IG-based importance scores.}\label{figure3}
    \vspace{-4mm}
\end{wrapfigure}
\noindent \textbf{Quantitative comparison of NeurFlow with existing approaches.}
While our approach focuses on identifying core concept neurons relative to a specific target neuron, we demonstrate that the neurons identified by our method also significantly influence the model's final output. 
To validate this, we analyzed the overlap between our core concept neurons and the critical neurons identified by \citet{NEUCEPT}, and NeuronMCT \citep{neuronmct}. The $F_1$ scores for these overlaps are presented in Table \ref{tab:overlap} (Appendix \ref{sec:compare_to_model_output}). The results indicate that NeurFlow identifies core concept neurons largely similar to those found by NeuronMCT, even though it does not explicitly find critical neurons to the modelâ€™s output.
Additionally, we compare our approach for identifying core concept neurons for a specific target neuron with the method proposed in \citet{Olah}. 
% In their approach, neurons are ranked based on the top $L_2$ weights connected to the target neuron. 
Details of this experiment can be found in Section \ref{sec:compare_to_target_neuron} (Appendix \ref{sec:compare_to_target_neuron}). The results, summarized in Table \ref{tab:loss-subtraction} (Appendix), show that our method is more effective in identifying core concept neurons.

