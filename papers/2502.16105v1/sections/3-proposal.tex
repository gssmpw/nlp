\subsection{Problem Formulation}
Our goal is to explain the internal mechanisms of deep neural networks (DNNs) by investigating how groups of neurons function and interact to encapsulate concepts, thereby performing a specific task. In particular, we focus on the classification problem, exploring how groups of neurons process visual features to identify a class. Given the exponential number of possible neuron groups, we focus only on core concept neurons. 
In addition, to facilitate human interpretation, we group these neurons through the common visual features they encode.
In essence, we propose a comprehensive framework to address the following questions: 
\textit{(i) Which neurons play a crucial role in each layer? (ii) How can these neurons be clustered, and what visual features does each neuron group encapsulate? (iii) How do groups of neurons in adjacent layers interact?}


Our problem can be formulated as follows:
Given a pretrained classification network \textit{F} and a dataset $\mathcal{D}_c$ composed of exemplars from a specific class $c$, the goal is to construct a hierarchical tree whose vertices represent groups of core concept neurons in each network layer, and the edges capture the relationships between these groups.
Figure \ref{fig:flow} illutrates the workflow of our framework which comprises the following key components: (1) identifying core concept neurons (Section \ref{subsec:identify_node}), (2) determining inter-layer relationships among neurons (Section \ref{sec:indentify_circuit}), (3) clustering the core concept neurons into groups, and analyzing the interactions between these neuron groups (Section \ref{concept_circuit}). 

\begin{figure}[tb] 
\begin{center}
\vspace{-11mm}
\includegraphics[width=0.8\textwidth]{figures/flow3.png} 
\end{center}
\vspace{-15pt} 
\caption{\textbf{Workflow of NeurFlow}, consisting of three main components: identifying core concept neurons in each layer, building the neuron circuit, and constructing the circuit of neuron groups.}
\label{fig:flow}
\vspace{-15pt}
\end{figure}

\subsection{Definitions and Notations}
\label{def_not}
In this paper, the term \emph{neuron} refers to either a unit in a linear layer or a feature map in a convolutional layer. As suggested by \citet{Olah, Invert, Polysemantic}, each neuron is selectively activated by a distinct set of visual features, and by interpreting the neuron as a representation of these features, we can gain insights into the internal representations of a DNN. We refer to these visual features as the concept of the neuron. In the following definitions, let $a$ represent an arbitrary neuron located in layer $l$ of the pretrained network $F$. 
In this study, we do not rely on any predefined concepts. Instead, we enhance the original dataset $\mathcal{D}_c$ by cutting it into smaller patches with varying sizes. These patches serve as visual features for probing the model. We refer to this augmented dataset as $\mathcal{D}$, and denote $v$ as an arbitrary element of $\mathcal{D}$.

\begin{mydef}[Neuron Concept]
\label{def:neuron concept}
    The neuron concept $\mathcal{V}_{a}$ of neuron $a$ is defined as the set of the top-$k$ image patches\footnote{each image patch is a piece cropped from image set.} that most strongly activate neuron $a$. Formally, the neuron concept of $a$ is expressed as $\mathcal{V}_{a} :=\underset{\mathcal{V} \subset \mathcal{D}; |\mathcal{V}| = k}{\arg \max} \sum_{v \in \mathcal{V}} \phi_{a}(v)$, where $\phi_{a}(v): \mathbb{D} \xrightarrow{} \mathbb{R}$ represents the activation of neuron $a$ for a given input $v \in \mathcal{D}$, and $k$ is a hyperparameter.
\end{mydef}
An empirical analysis of the impact of $k$ (Appendix \ref{sec:choice_of_k}) reveals that NeurFlow's performance is relatively insensitive to the selection of $k$.

\begin{mydef}[Neuron Concept with Knockout]
    Let $M$ be the computational graph of the network $F$, $S$ be an arbitrary subset neurons of $M$, and $M \setminus S$ be the sub-graph of $M$ after removing $S$; let $\phi^{\overline{S}}_{a}$ be the activation of neuron $a$ computed from $M \setminus S$. 
    The neuron concept of $a$ when knocking-out $S$ (denoted as $\mathcal{V}^{\overline{S}}_{a}$) is defined as $\mathcal{V}^{\overline{S}}_{a} := \underset{\mathcal{V} \subset \mathcal{D}; |\mathcal{V}| = k}{\arg \max} \sum_{v \in \mathcal{V}} \phi^{\overline{S}}_{a}(v)$. 
\end{mydef}

We hypothesize that for each neuron $a$, only a small subset of neurons from the preceding layer exert the most significant influence on $a$. In particular, knocking out these neurons would lead to a substantial change in the concept associated with $a$. We refer to these neurons as \emph{core concept neurons} and provide a formal definition in the following.

% \mt{How about change ``critical neurons'' to: Core Concept Neurons? Earlier, we have neuron concepts, neuron concepts with knockoff. so core concept neurons is naturally coming...}

\begin{mydef}[Core Concept Neurons]
\label{def:critical neuron} Given a neuron $a$ at layer $l$, core concept neurons of $a$ (denoted as $\mathbb{S}_a$) is the sub-set of neurons at the previous layer $l - 1$ satisfying the following conditions:
    \begin{equation}
    \label{eq:critical neurons}
        \mathbb{S}_a := \underset{S \subseteq \mathbb{S};\left|{S}\right| \leq \tau}{\arg \min} \left| \mathcal{V}^{\overline{{S}}}_a \cap \mathcal{V}_a \right|,
    \end{equation}
    where $\mathbb{S}$ is set of all neurons at layer $l-1$ and $\tau$ is a predefined threshold. 
    Intuitively, the core concept neurons for a target neuron $a$ are those that play an important role in defining the concepts represented by $a$.
    In practice, the value of $\tau$ may vary across the network layers, its impact will be elaborated upon in Sections \ref{sec:analysis}.
\end{mydef}    
% In practice, the value of $\tau$ may vary across the network layers, its impact will be elaborated upon in Sections \ref{sec:analysis}.
In the following, we denote by  $\phi^{1, l-1}(v): \sD \xrightarrow{} \sR^{m\times w \times h}$ the function that maps the input $v$ to the feature maps at the $(l-1)$-th layer of the model, where $m$ represents the number of channels, and $w \times h$ indicates the dimensions of each feature map. Furthermore, we adopt the notation $|.|$ to indicate the cardinality of a set, while $\|.\|$ is employed to represent the absolute value.
We summarize all the notations in Table \ref{fig:notation} (Appendix \ref{sec:appendix_notation}).

\subsection{Identifying core concept Neurons}
\label{subsec:identify_node}
Given a neuron $a$, we describe our algorithm for identifying its core concept neuron set $\mathbb{S}_a$. This process consists of two main steps: determining $a$'s concept $\mathcal{V}_a$ according to Definition \ref{def:neuron concept}, and identifying core concept neurons following Definition \ref{def:critical neuron}. 

Firstly, we generate a set of image patches $\mathcal{D}$ by augmenting the original dataset $\mathcal{D}_c$, which consists of images that the model classifies as class $c$.
%To determine $\mathcal{V}_a$, we create a set of visual features $\mathcal{D}$ by augmenting the original dataset $\mathcal{D}_c$ (images that the model predicts as class $c$). 
Since neurons can detect visual features at different levels of granularity, we divide each image in $\mathcal{D}_c$ into smaller patches using various crop sizes, where smaller patches capture simpler visual features and larger patches represent more complex ones. 
We subsequently evaluate all items in $\mathcal{D}$ to identify the top-$k$ image patches that induce the highest activation in neuron $a$, thereby constructing $\mathcal{V}_a$.

With $\mathcal{V}_a$ identified, one could determine the core concept neurons through a brute-force search over all possible candidates. However, this naive approach is computationally infeasible. 
To this end, we define a metric named \emph{importance score} that quantifies the attribution of a neuron $s_i$ to $a$.
The importance score can be intuitively seen as integrated gradients (\cite{IG}) of $a$ to $s_i$ calculated across all elements of $\mathcal{V}_a$, calculated as follows:
\begin{equation}
     T(a, s_i, \mathcal{V}_a) = \sum_{v\in \mathcal{V}_a} \sum_{ \substack{x \in \phi^{1, l-1}_{s_i}(v); \\ y \in \phi^{l-1,l}_a(\phi^{1,l-1}(v)) }} x \times \frac{1}{N} \left ( \sum_{n=1}^{N} \frac{\partial y(\frac{n}{N}x)}{\partial x} \right ),
\end{equation}
where $\phi^{1,l-1}_{s_i}$ is the element of $\phi^{1,l-1}$ corresponding to neuron $s_i$, $\phi^{l-1,l}_a$ depicts the function mapping from the activation vector of layer \( l-1 \) to the activation of neuron \( a \), and $N$ is the step size. 
Utilizing the \emph{importance scores} of all neurons in the preceding layer, the set of core concept neurons is identified by selecting the top $\tau$ neurons that exhibit the highest absolute scores.
To justify the use of integrated gradients, we empirically show a strong correlation between the absolute values of \( T(a, s_i, \mathcal{V}_a) \) and the change in \( a \)'s concept after knocking out \( s_i \), as demonstrated in Section \ref{sec:analysis}.
Additionally, we compare our method with other attribution techniques in Appendix \ref{sec:compare_scoring}.

\subsection{Constructing core concept Neuron Circuit}
\vspace{-5pt}
\label{sec:indentify_circuit}
For each class of interest \(c\), the neuron circuit $\mathcal{H}_c$ is represented as a \emph{hierarchical hypertree}\footnote{A hypertree is a tree in which each child-parent pair may be connected by multiple edges.}, with the root $a_c$ being the neuron in the logit layer (ouput) associated with class $c$. The nodes in each layer of the tree $\mathcal{H}_c$ are the core concept neurons of those in the layer above, and branches connecting a parent node $a$ and its child $s_i \in \sS_a$ represents the contributions of $s_i$ to $a$'s concept. 

As mentioned in \citep{Olah, Polysemantic}, neurons often exhibit polysemantic behavior, meaning that a single neuron may encode multiple distinct visual features. In other words, the visual features within a concept $\mathcal{V}_a$ of neuron $a$ may not share the same meaning and can be categorized into distinct groups, which we term \emph{semantic groups}.
We hypothesize that each core concept neuron $s_i$ makes a distinct contribution to each semantic group of neuron $a$. To model this relationship, we represent the interaction between $s_i$ and $a$ through multiple connections, where the $j$-th connection reflects $s_i$'s influence on $\mathcal{V}_{a,j}$, the $j$-th semantic group of $a$. 

At a conceptual level, the algorithm for constructing the hypertree $\mathcal{H}_c$ proceeds through the following steps: (1) employing our core concept neuron identification algorithm to determine the children of each node in the tree (Section \ref{subsec:identify_node}), (2) clustering the neuron concept of each parent node into semantic groups, and (3) assigning weights to each branch connecting a child node to the semantic groups of its parent. 
Figure \ref{fig:critical neuron} illustrates our algorithm. 
The complete algorithm for constructing the core concept neuron circuit is presented in Appendix \ref{sec:main_algo}.
We provide a detailed explanation of these steps below.

\textbf{Determining semantic groups.}
 Let the concept $\mathcal{V}_a$ corresponding to $a$ be composed of $k$ elements $\{ v^1_a, \dots, v_a^k \}$.
 For each visual feature $v_a^i$ ($i = 1, \dots, k$), we define its representative vector $r(v_a^i) \in \sR^m$ as:
 \begin{equation}
     r(v_a^i) = \left [ \texttt{mean}\left(\phi^{1, l-1}_1(v_a^i) \right), \dots, \texttt{mean}\left(\phi^{1, l-1}_m(v_a^i) \right) \right ],
 \end{equation}
where $\phi^{1, l-1}_j(v_a^i)$ ($j = 1, \dots, m$) represents the $j$-th feature map and $\texttt{mean}\left(\phi^{1, l-1}_j(v_a^i)\right)$ denotes the average value across its all elements.
Next, we use agglomerative clustering \citep{Agglo_clustering} to divide the set $\{v^1_a, \dots, v_a^k\}$ into clusters, where the distance between two visual features $v^p_a$, $v^q_a$ is defined by the distance between their corresponding representative vectors $r(v^p_a)$, $r(v^q_a)$. 
The Silhouette score \citep{Silhouettes} is employed to ascertain the optimal number of clusters. The complete procedure is detailed in Algorithm \ref{alg:determin_semantic_groups}.

\textbf{Calculating edge weight.} The weight $w(a, s_i, \mathcal{V}_{a,j})$ of the branch connecting a child $s_i$ and its parent $a$'s $j$-th semantic group $\mathcal{V}_{a,j}$ is defined as: 
\begin{equation}\label{equation4}
    w(a, s_i, \mathcal{V}_{a,j}) = \frac{T(a, s_i, \mathcal{V}_{a,j})}{\sum_{s\in \mathbb{S}_a} \|T(a, s, \mathcal{V}_{a,j})\|},
\end{equation}
where $T(a, s_i, \mathcal{V}_{a,j})$ is the importance score of $s_i$ to $a$ calculated over $\mathcal{V}_{a,j}$.

\subsection{Determining Groups of Neurons and Constructing Concept Circuit}
\label{concept_circuit}
\vspace{-5pt}
%Let $\mathbb{S}_a = \{s_1, ..., s_k\}$ be the set of critical neurons of $a$.
This section describes our algorithms to (1) cluster the set of core concept neurons $\mathbb{S}_a = \{s_1, ..., s_k\}$ into distinct groups, (2) identifying the concept associated with each group, and (3) quantifying the interaction between the groups. 

\textbf{Clustering neurons into groups.} 
As mentioned in the previous section, a single neuron can encode multiple distinct visual features, while several neurons may also capture the same visual feature \citet{Olah}. 
We hypothesize that, due to the polysemantic nature of neurons \citep{Olah, Polysemantic}, a model may struggle to accurately determine whether a concept is present in an input image by relying on a single neuron. As a result, the model processes visual features not by considering individual neurons in isolation but rather by operating at the level of neuron groups. 
Intuitively, a group of neurons consists of those that capture similar visual features. This can be interpreted as \emph{two neurons belonging to the same group if they share similar semantic concept groups}. 

Building on this intuition, we develop a neuron clustering algorithm based on the semantic groups of each neuron's concept (Figure \ref{fig:neuron group}). 
Specifically, let $\mathcal{V}_{s_i}$ represent the concept of neuron $s_i$ (i.e., the primary visual features it encodes), which can be decomposed into several semantic groups $\{\mathcal{V}_{s_i, 1}, ..., \mathcal{V}_{s_i, n_i}\}$ (see Section \ref{sec:indentify_circuit}), where $n_i$ is the number of semantic groups encoded by $s_i$. For each semantic group $\mathcal{V}_{s_i, j}$, we calculate its representative activation vector $\overrightarrow{r_{s_i,j}}$ by averaging the feature maps of all its visual features, i.e., $\overrightarrow{r_{s_i,j}}:= \frac{1}{|\mathcal{V}_{s, j}|}\sum_{v_s \in \mathcal{V}_{s, j}} mean(\phi^{1, l-1}(v_s))$.
We then apply the agglomerative clustering algorithm to group the semantic groups $\mathcal{V}_{s_i, j}$ ($i = 1,..., k; j = 1, ..., n_i$), where the distance between any two groups $\mathcal{V}_{s_i, u}$ and $\mathcal{V}_{s_j, w}$ is determined by the distance of their respective representative activation vectors, $\overrightarrow{r_{s_i,u}}$ and $\overrightarrow{r_{s_j,w}}$.
Finally, we assign neurons $s_1, ..., s_k$ to the same groups based on their semantic concept groups. Specifically, neurons $s_i$ and $s_j$ are clustered together if there exists a semantic group $\mathcal{V}_{s_i, u}$ (of $s_i$) and a semantic group $\mathcal{V}_{s_j, w}$ (of $s_j$) belonging to the same group. 

\textbf{Finding neuron group concept automatically.}
We define the concept associated with a group of neurons as the union of all visual features from the corresponding semantic groups. 
Specifically, let $\{\mathcal{V}_{G,1}, \dots, \mathcal{V}_{G,k}\}$ represent the semantic groups categorized into a cluster, with their corresponding neurons $\{s_{G,1}, \dots, s_{G,k}\}$ grouped together in the same set, denoted as $G$. 
The concept of this group, denoted as $\mathbb{V}_G$, is then defined as the union of the sets $\{\mathcal{V}_{G,1}, \dots, \mathcal{V}_{G,k}\}$, i.e., $\mathbb{V}_G := \bigcup_{i=1}^{k}\mathcal{V}_{G,i}$.
We leverage a Multimodal LLM to automatically assign labels to the concept, thereby eliminating the need for a predefined labeled concept dictionary. Further details on the design of the prompts are provided in the Appendix \ref{prompt}.

\begin{figure}
    \centering
    \begin{minipage}{.35\textwidth}
        \vspace{-12mm}
        \includegraphics[width=1\columnwidth]{figures/critical_neuron3.png} 
        \vspace{3mm}
        \caption{The interaction between a neuron $s_i$ and its parent $a$.\label{fig:critical neuron}}   
    \end{minipage}
    \hfill
    \begin{minipage}{0.55\textwidth}
        \vspace{-12mm}
        \includegraphics[width=1\columnwidth]{figures/neuron_group3.png} 
        \vspace{-5mm}
        \caption{Illustration of our algorithm to determine groups of neurons.\label{fig:neuron group}}
    \end{minipage}
\vspace{-12mm}
\end{figure}


\noindent \textbf{Constructing concept circuit.} 
\label{sub_sec:constructing concept circuit}
For a given class $c$, the concept circuit $\mathcal{C}_c$ is a hierarchical tree where each node represents a neuron group concept (\emph{NGC}), and each edge illustrates the contribution of the child neuron group to its parent. 
For a node $G$, we denote by $\sV_{G} = \{\mathcal{V}_{G, 1}, ..., \mathcal{V}_{G, |\sV_{G}|}\}$ the set of semantic groups associated with $G$, and $\sS_{G} = \{ s_{G, 1}, ..., s_{G, |\sS_{G}|}\}$ represent the neurons corresponding to the semantic groups in $\sV_{G}$, i.e., $s_{G, j}$ is the core concept neuron possesses the semantic group $\mathcal{V}_{G, j}$ ($j = 1, ..., |\sV_{G}|$).
Let $G_i$ and $G_j$ be a child-parent pair in the tree, then, the relationship between $G_i$ and $G_j$ (quantified by $W(G_i, G_j))$ is represented by two aspects: the number of edges connecting elements of $G_i$ and $G_j$, and the weights of those connecting edges. The more the edges and the higher the edge weights, the stronger the relationship between $G_i$ and $G_j$. Accordingly, we define
the weight of branch connecting a child $G_i$ to its parent $G_j$ as sum of the attribution of each neuron in $\sS_{G_i}$ with each neuron in $\sS_{G_j}$: $ W(G_i, G_j) := \sum_{\substack{s_{G_i, q} \in \sS_{G_i}; \\ s_{G_j,p} \in \sS_{G_j}}}w(s_{G_j, p}, s_{G_i, q}, \mathcal{V}_{G_j,p})$.

% \begin{equation}\label{equation5}
%      W(G_i, G_j) = \sum_{\substack{s_{G_i, q} \in \sS_{G_i}; \\ s_{G_j,p} \in \sS_{G_j}}}w(s_{G_j, p}, s_{G_i, q}, \mathcal{V}_{G_j,p}).
% \end{equation}
% \begin{equation}\label{equation5}
%      W(G_i, G_j) = \frac{1}{\left | \mathcal{S}_{G_i} \right| \times  \left|\mathcal{S}_{G_j}\right|}\sum_{S^q_{G_i} \in \mathcal{S}_{G_i}; D^p_{G_j} \in \mathcal{D}_{G_j}}^{} w(S^q_{G_i}, D^p_{G_j}).
% \end{equation}
% and $\mathcal{D}^{1}_{G_j}$ the sets of semantic groups associated with $G_i$ and $G_j$, respectively; and $\mathbb{S}_{G_i}$, $\mathbb{S}_{G_j}$ the critical neurons corresponding to semantic groups in $\mathcal{D}^{1}_{G_j}$ and $\mathrm{D}_{G_i}$ re
% Suppose $\mathrm{D}_{G_i} = \{ \mathcal{D}^{1}_{G_i}, ..., \mathcal{D}^{n_i}_{G_i} \}$ is the set of semantic groups associated with $G_i$, and $\mathrm{D}_{G_j} = \{ \mathcal{D}^{1}_{G_j}, ..., \mathcal{D}^{n_j}_{G_j} \}$ are those associated with $G_j$.
% In addition, let us denote by $\mathbb{S}_{G_i} = \{s^1_{G_i}, ..., {s^{n_i}_{G_i}\}$ the for each semantic group $\mathcal{D}^{p}_{G_q}$ ($q \in \{i, j\}, p = 1, ..., n_q$), let us denote by $s^p_q$ the critical neuron possessing $\mathcal{D}^{p}_{G_q}$. 
% representing the way the groups of critical neurons 
% function of neuron groups 
% whose each node represent a semantic group 
% Let $G_1, ..., G_q$ be the groups of critical neurons at layer $l-1$, and 
% We can extend further by taking into account the connection between critical neurons of layer $l+1$ and layer $l$. For a combination $\mathcal{G}_1 = \{s_1^{l+1}, s_2^{l+1}, \dots, s_{g_1}^{l+1} \}$ with the respective semantic groups that share a common concept: $\mathcal{V}_{s_i^{l+1}, j_i}, \: \forall i \in \{1, \dots, g_1\}$ at layer $l+1$ and similar notations for $\mathcal{G}_2$ at layer $l$, we can quantify how strongly $\mathcal{G}_2$ influences $\mathcal{G}_1$ by aggregating the edge weights: $T_{\mathcal{G}_1,\mathcal{G}_2} = \frac{1}{g_1} \frac{1}{g_2} \sum_{i=1}^{g_1} \sum_{t=1}^{g_2} EdgeWeight(s_i^{l+1}, s_t^l, \mathcal{V}_{s_i^{l+1}, j_i})$. This allows us to construct a graph of COC, providing an abstract representation of how the model processes visual features without examining every individual neuron (see Figure \ref{figure1}). We refer to this graph as a \textit{concept circuit}, with applications demonstrated in Section \ref{sec:application}.