@misc{pi_against_gpt3,
  title = {{Prompt injection attacks against GPT-3}},
  howpublished = "\url{https://simonwillison.net/2022/Sep/12/prompt-injection/}",
  author = {Simon Willison},
  year={2022}
}

@misc{delimiters_url,
  title = {{Delimiters won’t save you from prompt injection}},
  howpublished = "\url{https://simonwillison.net/2023/May/11/delimiters-wont-save-you}",
  author = {Simon Willison},
  year={2023}
}

@misc{worst_url,
  title = {{Prompt injection: What’s the worst that can happen?}},
  howpublished = "\url{https://simonwillison.net/2023/Apr/14/worst-that-can-happen/}",
  author = {Simon Willison},
  year={2023}
}

@inproceedings{ignore_previous_prompt,
    author = {Perez, Fábio and Ribeiro, Ian},
    title = {Ignore Previous Prompt: Attack Techniques For Language Models},
    booktitle = {NeurIPS ML Safety Workshop},
    year = {2022}
}

@inproceedings{liu2024formalizing,
  title={Formalizing and benchmarking prompt injection attacks and defenses},
  author={Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  booktitle={33rd USENIX Security Symposium (USENIX Security 24)},
  pages={1831--1847},
  year={2024}
}

@inproceedings{debenedetti2024agentdojo,
  title={AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents},
  author={Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\`e}r, Florian},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}

@inproceedings{greshake2023not,
  title={Not what you've signed up for: Compromising real-world llm-integrated applications with indirect prompt injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  booktitle={Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
  pages={79--90},
  year={2023}
}

@inproceedings{zhong-etal-2023-poisoning,
    title = "Poisoning Retrieval Corpora by Injecting Adversarial Passages",
    author = "Zhong, Zexuan  and
      Huang, Ziqing  and
      Wettig, Alexander  and
      Chen, Danqi",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.849/",
    doi = "10.18653/v1/2023.emnlp-main.849",
    pages = "13764--13775",
}

@article{zou2024poisonedrag,
  title={Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models},
  author={Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan},
  journal={arXiv preprint arXiv:2402.07867},
  year={2024}
}

@article{fu2023misusing,
  title={Misusing tools in large language models with visual adversarial examples},
  author={Fu, Xiaohan and Wang, Zihan and Li, Shuheng and Gupta, Rajesh K and Mireshghallah, Niloofar and Berg-Kirkpatrick, Taylor and Fernandes, Earlence},
  journal={arXiv preprint arXiv:2310.03185},
  year={2023}
}

@article{wu2024agentattack,
  title={Adversarial Attacks on Multimodal Agents},
  author={Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi},
  journal={arXiv preprint arXiv:2406.12814},
  year={2024}
}

@article{kumar2024manipulating,
  title={Manipulating large language models to increase product visibility},
  author={Kumar, Aounon and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2404.07981},
  year={2024}
}

@article{nestaas2024adversarial,
  title={Adversarial search engine optimization for large language models},
  author={Nestaas, Fredrik and Debenedetti, Edoardo and Tram{\`e}r, Florian},
  journal={arXiv preprint arXiv:2406.18382},
  year={2024}
}

@article{liao2024eia,
  title={Eia: Environmental injection attack on generalist web agents for privacy leakage},
  author={Liao, Zeyi and Mo, Lingbo and Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Xiao, Chaowei and Tian, Yuan and Li, Bo and Sun, Huan},
  journal={arXiv preprint arXiv:2409.11295},
  year={2024}
}

@inproceedings{schulhoff2023ignore,
    title = "Ignore This Title and {H}ack{AP}rompt: Exposing Systemic Vulnerabilities of {LLM}s Through a Global Prompt Hacking Competition",
    author = "Schulhoff, Sander  and
      Pinto, Jeremy  and
      Khan, Anaum  and
      Bouchard, Louis-Fran{\c{c}}ois  and
      Si, Chenglei  and
      Anati, Svetlina  and
      Tagliabue, Valen  and
      Kost, Anson  and
      Carnahan, Christopher  and
      Boyd-Graber, Jordan",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.302/",
    doi = "10.18653/v1/2023.emnlp-main.302",
    pages = "4945--4977",
}

@article{xu2024advweb,
  title={Advweb: Controllable black-box attacks on vlm-powered web agents},
  author={Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Liao, Zeyi and Mo, Lingbo and Yuan, Mengqi and Sun, Huan and Li, Bo},
  journal={arXiv preprint arXiv:2410.17401},
  year={2024}
}

@inproceedings{
chen2024agentpoison,
title={AgentPoison: Red-teaming {LLM} Agents via Poisoning Memory or Knowledge Bases},
author={Zhaorun Chen and Zhen Xiang and Chaowei Xiao and Dawn Song and Bo Li},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=Y841BRW9rY}
}

@article{lee2024prompt,
  title={Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems},
  author={Lee, Donghyun and Tiwari, Mo},
  journal={arXiv preprint arXiv:2410.07283},
  year={2024}
}

@inproceedings{
toyer2024tensor,
title={Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game},
author={Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=fsW7wJGLBd}
}

@article{yu2023assessing,
  title={Assessing prompt injection risks in 200+ custom gpts},
  author={Yu, Jiahao and Wu, Yuhang and Shu, Dong and Jin, Mingyu and Xing, Xinyu},
  journal={arXiv preprint arXiv:2311.11538},
  year={2023}
}

@article{chen2024struq,
  title={StruQ: Defending against prompt injection with structured queries},
  author={Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David},
  journal={arXiv preprint arXiv:2402.06363},
  year={2024}
}

@article{chen2024aligning,
  title={Aligning llms to be robust against prompt injection},
  author={Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Guo, Chuan},
  journal={arXiv preprint arXiv:2410.05451},
  year={2024}
}

@article{wallace2024instruction,
  title={The instruction hierarchy: Training llms to prioritize privileged instructions},
  author={Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex},
  journal={arXiv preprint arXiv:2404.13208},
  year={2024}
}

@misc{deberta-v3-base-prompt-injection-v2,
  author = {ProtectAI},
  title = {Fine-Tuned DeBERTa-v3-base for Prompt Injection Detection},
  year = {2024},
  publisher = {HuggingFace},
  url = {https://huggingface.co/ProtectAI/deberta-v3-base-prompt-injection-v2},
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{hung2024attention,
  title={Attention Tracker: Detecting Prompt Injection Attacks in LLMs},
  author={Hung, Kuo-Han and Ko, Ching-Yun and Rawat, Ambrish and Chung, I and Hsu, Winston H and Chen, Pin-Yu and others},
  journal={arXiv preprint arXiv:2411.00348},
  year={2024}
}

@inproceedings{wu2025isolategpt,
  title={{IsolateGPT: An Execution Isolation Architecture for LLM-Based Systems}}, 
  author={Wu, Yuhao and Roesner, Franziska and Kohno, Tadayoshi and Zhang, Ning and Iqbal, Umar},
  booktitle={Network and Distributed System Security Symposium (NDSS)},
  year={2025},
}

@misc{alex2023ultimate,
  title = {{Ultimate ChatGPT prompt engineering guide for general users and developers}},
  howpublished = "\url{https://www.imaginarycloud.com/blog/chatgpt-prompt-engineering}",
  author = {Alexandra Mendes},
  year={2023}
}

@misc{learning_prompt_sandwich_url,
  title = {{Sandwitch defense}},
  howpublished = "\url{https://learnprompting.org/docs/prompt_hacking/defensive_measures/sandwich_defense}",
  year={2023}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{hines2024defending,
  title={Defending Against Indirect Prompt Injection Attacks With Spotlighting},
  author={Hines, Keegan and Lopez, Gary and Hall, Matthew and Zarfati, Federico and Zunger, Yonatan and Kiciman, Emre},
  journal={arXiv preprint arXiv:2403.14720},
  year={2024}
}

@article{koh2024visualwebarena,
  title={VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks},
  author={Koh, Jing Yu and Lo, Robert and Jang, Lawrence and Duvvur, Vikram and Lim, Ming Chong and Huang, Po-Yu and Neubig, Graham and Zhou, Shuyan and Salakhutdinov, Ruslan and Fried, Daniel},
  journal={arXiv preprint arXiv:2401.13649},
  year={2024}
}

@article{zhou2024webarena,
  title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
  journal={ICLR},
  year={2024}
}

@misc{openai2024embedding,
    title = {OpenAI Text Embeddings},
    author = {{OpenAI}},
    year = {2024},
    url = {https://platform.openai.com/docs/guides/embeddings},
    organization = {OpenAI}
}

@inproceedings{
ruan2024identifying,
title={Identifying the Risks of {LM} Agents with an {LM}-Emulated Sandbox},
author={Yangjun Ruan and Honghua Dong and Andrew Wang and Silviu Pitis and Yongchao Zhou and Jimmy Ba and Yann Dubois and Chris J. Maddison and Tatsunori Hashimoto},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=GEcwtMk1uA}
}

@inproceedings{
yuan2024rjudge,
title={R-Judge: Benchmarking Safety Risk Awareness for {LLM} Agents},
author={Tongxin Yuan and Zhiwei He and Lingzhong Dong and Yiming Wang and Ruijie Zhao and Tian Xia and Lizhen Xu and Binglin Zhou and Li Fangqi and Zhuosheng Zhang and Rui Wang and Gongshen Liu},
booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
year={2024},
url={https://openreview.net/forum?id=g6Yy46YXrU}
}

@article{naihin2023testing,
  title={Testing language model agents safely in the wild},
  author={Naihin, Silen and Atkinson, David and Green, Marc and Hamadi, Merwane and Swift, Craig and Schonholtz, Douglas and Kalai, Adam Tauman and Bau, David},
  journal={arXiv preprint arXiv:2311.10538},
  year={2023}
}

@inproceedings{zhan24injecagent,
    title = "{I}njec{A}gent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents",
    author = "Zhan, Qiusi  and
      Liang, Zhixiang  and
      Ying, Zifan  and
      Kang, Daniel",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.624/",
    doi = "10.18653/v1/2024.findings-acl.624",
    pages = "10471--10506",
}


@misc{anthropic_tool_use,
  author       = {Anthropic},
  title        = {Claude 3.5 Models and Computer Use},
  year         = 2024,
  url          = {https://www.anthropic.com/news/3-5-models-and-computer-use},
}

@misc{openai_tool_use,
  author       = {OpenAI},
  title        = {OpenAI Function Calling Guide},
  year         = 2024,
  url          = {https://platform.openai.com/docs/guides/function-calling},
}

@misc{llama_tool_use,
  author       = {Llama},
  title        = {Llama3.3 Model Cards},
  year         = 2024,
  url          = {https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_3/},
}

@article{zhang2024agent,
  title={Agent security bench (asb): Formalizing and benchmarking attacks and defenses in llm-based agents},
  author={Zhang, Hanrong and Huang, Jingyuan and Mei, Kai and Yao, Yifei and Wang, Zhenting and Zhan, Chenlu and Wang, Hongwei and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2410.02644},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={GeminiTeam},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{yao2022webshop,
  title={Webshop: Towards scalable real-world web interaction with grounded language agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{wu2024system,
  title={System-Level Defense against Indirect Prompt Injection Attacks: An Information Flow Control Perspective},
  author={Wu, Fangzhou and Cecchetti, Ethan and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2409.19091},
  year={2024}
}

@article{patil2024goex,
  title={GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications},
  author={Patil, Shishir G and Zhang, Tianjun and Fang, Vivian and Huang, Roy and Hao, Aaron and Casado, Martin and Gonzalez, Joseph E and Popa, Raluca Ada and Stoica, Ion and others},
  journal={arXiv preprint arXiv:2404.06921},
  year={2024}
}

@misc{zhang2024attacking,
    title={Attacking Vision-Language Computer Agents via Pop-ups},
    author={Yanzhe Zhang and Tao Yu and Diyi Yang},
    year={2024},
    eprint={2411.02391},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{wu2024new,
  title={A new era in llm security: Exploring security concerns in real-world llm-based systems},
  author={Wu, Fangzhou and Zhang, Ning and Jha, Somesh and McDaniel, Patrick and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2402.18649},
  year={2024}
}

@misc{deepseek2025,
  author       = {DeepSeek},
  title        = {DeepSeek Function Calling Guide},
  year         = {2025},
  howpublished = {\url{https://api-docs.deepseek.com/guides/function_calling}},
}
