[
  {
    "index": 0,
    "papers": [
      {
        "key": "pi_against_gpt3",
        "author": "Simon Willison",
        "title": "{Prompt injection attacks against GPT-3}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "ignore_previous_prompt",
        "author": "Perez, F\u00e1bio and Ribeiro, Ian",
        "title": "Ignore Previous Prompt: Attack Techniques For Language Models"
      },
      {
        "key": "schulhoff2023ignore",
        "author": "Schulhoff, Sander  and\nPinto, Jeremy  and\nKhan, Anaum  and\nBouchard, Louis-Fran{\\c{c}}ois  and\nSi, Chenglei  and\nAnati, Svetlina  and\nTagliabue, Valen  and\nKost, Anson  and\nCarnahan, Christopher  and\nBoyd-Graber, Jordan",
        "title": "Ignore This Title and {H}ack{AP}rompt: Exposing Systemic Vulnerabilities of {LLM}s Through a Global Prompt Hacking Competition"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "delimiters_url",
        "author": "Simon Willison",
        "title": "{Delimiters won\u2019t save you from prompt injection}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chen2024struq",
        "author": "Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David",
        "title": "StruQ: Defending against prompt injection with structured queries"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      },
      {
        "key": "xu2024advweb",
        "author": "Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Liao, Zeyi and Mo, Lingbo and Yuan, Mengqi and Sun, Huan and Li, Bo",
        "title": "Advweb: Controllable black-box attacks on vlm-powered web agents"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "wu2024agentattack",
        "author": "Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi",
        "title": "Adversarial Attacks on Multimodal Agents"
      },
      {
        "key": "liao2024eia",
        "author": "Liao, Zeyi and Mo, Lingbo and Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Xiao, Chaowei and Tian, Yuan and Li, Bo and Sun, Huan",
        "title": "Eia: Environmental injection attack on generalist web agents for privacy leakage"
      },
      {
        "key": "xu2024advweb",
        "author": "Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Liao, Zeyi and Mo, Lingbo and Yuan, Mengqi and Sun, Huan and Li, Bo",
        "title": "Advweb: Controllable black-box attacks on vlm-powered web agents"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhang2024attacking",
        "author": "Yanzhe Zhang and Tao Yu and Diyi Yang",
        "title": "Attacking Vision-Language Computer Agents via Pop-ups"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "yu2023assessing",
        "author": "Yu, Jiahao and Wu, Yuhang and Shu, Dong and Jin, Mingyu and Xing, Xinyu",
        "title": "Assessing prompt injection risks in 200+ custom gpts"
      },
      {
        "key": "wu2024agentattack",
        "author": "Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi",
        "title": "Adversarial Attacks on Multimodal Agents"
      },
      {
        "key": "wu2024new",
        "author": "Wu, Fangzhou and Zhang, Ning and Jha, Somesh and McDaniel, Patrick and Xiao, Chaowei",
        "title": "A new era in llm security: Exploring security concerns in real-world llm-based systems"
      },
      {
        "key": "toyer2024tensor",
        "author": "Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell",
        "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "wallace2024instruction",
        "author": "Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex",
        "title": "The instruction hierarchy: Training llms to prioritize privileged instructions"
      },
      {
        "key": "chen2024struq",
        "author": "Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David",
        "title": "StruQ: Defending against prompt injection with structured queries"
      },
      {
        "key": "chen2024aligning",
        "author": "Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Guo, Chuan",
        "title": "Aligning llms to be robust against prompt injection"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "deberta-v3-base-prompt-injection-v2",
        "author": "ProtectAI",
        "title": "Fine-Tuned DeBERTa-v3-base for Prompt Injection Detection"
      },
      {
        "key": "inan2023llama",
        "author": "Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others",
        "title": "Llama guard: Llm-based input-output safeguard for human-ai conversations"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "hines2024defending",
        "author": "Hines, Keegan and Lopez, Gary and Hall, Matthew and Zarfati, Federico and Zunger, Yonatan and Kiciman, Emre",
        "title": "Defending Against Indirect Prompt Injection Attacks With Spotlighting"
      },
      {
        "key": "alex2023ultimate",
        "author": "Alexandra Mendes",
        "title": "{Ultimate ChatGPT prompt engineering guide for general users and developers}"
      },
      {
        "key": "delimiters_url",
        "author": "Simon Willison",
        "title": "{Delimiters won\u2019t save you from prompt injection}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "learning_prompt_sandwich_url",
        "author": "Unknown",
        "title": "{Sandwitch defense}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "liu2024formalizing",
        "author": "Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang",
        "title": "Formalizing and benchmarking prompt injection attacks and defenses"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "wu2025isolategpt",
        "author": "Wu, Yuhao and Roesner, Franziska and Kohno, Tadayoshi and Zhang, Ning and Iqbal, Umar",
        "title": "{IsolateGPT: An Execution Isolation Architecture for LLM-Based Systems}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "wu2024system",
        "author": "Wu, Fangzhou and Cecchetti, Ethan and Xiao, Chaowei",
        "title": "System-Level Defense against Indirect Prompt Injection Attacks: An Information Flow Control Perspective"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "patil2024goex",
        "author": "Patil, Shishir G and Zhang, Tianjun and Fang, Vivian and Huang, Roy and Hao, Aaron and Casado, Martin and Gonzalez, Joseph E and Popa, Raluca Ada and Stoica, Ion and others",
        "title": "GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "wu2024agentattack",
        "author": "Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi",
        "title": "Adversarial Attacks on Multimodal Agents"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "liao2024eia",
        "author": "Liao, Zeyi and Mo, Lingbo and Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Xiao, Chaowei and Tian, Yuan and Li, Bo and Sun, Huan",
        "title": "Eia: Environmental injection attack on generalist web agents for privacy leakage"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      },
      {
        "key": "zhang2024attacking",
        "author": "Yanzhe Zhang and Tao Yu and Diyi Yang",
        "title": "Attacking Vision-Language Computer Agents via Pop-ups"
      },
      {
        "key": "xu2024advweb",
        "author": "Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Liao, Zeyi and Mo, Lingbo and Yuan, Mengqi and Sun, Huan and Li, Bo",
        "title": "Advweb: Controllable black-box attacks on vlm-powered web agents"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "pi_against_gpt3",
        "author": "Simon Willison",
        "title": "{Prompt injection attacks against GPT-3}"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "ignore_previous_prompt",
        "author": "Perez, F\u00e1bio and Ribeiro, Ian",
        "title": "Ignore Previous Prompt: Attack Techniques For Language Models"
      },
      {
        "key": "schulhoff2023ignore",
        "author": "Schulhoff, Sander  and\nPinto, Jeremy  and\nKhan, Anaum  and\nBouchard, Louis-Fran{\\c{c}}ois  and\nSi, Chenglei  and\nAnati, Svetlina  and\nTagliabue, Valen  and\nKost, Anson  and\nCarnahan, Christopher  and\nBoyd-Graber, Jordan",
        "title": "Ignore This Title and {H}ack{AP}rompt: Exposing Systemic Vulnerabilities of {LLM}s Through a Global Prompt Hacking Competition"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "delimiters_url",
        "author": "Simon Willison",
        "title": "{Delimiters won\u2019t save you from prompt injection}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "yu2023assessing",
        "author": "Yu, Jiahao and Wu, Yuhang and Shu, Dong and Jin, Mingyu and Xing, Xinyu",
        "title": "Assessing prompt injection risks in 200+ custom gpts"
      },
      {
        "key": "wu2024new",
        "author": "Wu, Fangzhou and Zhang, Ning and Jha, Somesh and McDaniel, Patrick and Xiao, Chaowei",
        "title": "A new era in llm security: Exploring security concerns in real-world llm-based systems"
      },
      {
        "key": "toyer2024tensor",
        "author": "Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell",
        "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "yu2023assessing",
        "author": "Yu, Jiahao and Wu, Yuhang and Shu, Dong and Jin, Mingyu and Xing, Xinyu",
        "title": "Assessing prompt injection risks in 200+ custom gpts"
      },
      {
        "key": "toyer2024tensor",
        "author": "Sam Toyer and Olivia Watkins and Ethan Adrian Mendes and Justin Svegliato and Luke Bailey and Tiffany Wang and Isaac Ong and Karim Elmaaroufi and Pieter Abbeel and Trevor Darrell and Alan Ritter and Stuart Russell",
        "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "zhong-etal-2023-poisoning",
        "author": "Zhong, Zexuan  and\nHuang, Ziqing  and\nWettig, Alexander  and\nChen, Danqi",
        "title": "Poisoning Retrieval Corpora by Injecting Adversarial Passages"
      },
      {
        "key": "zou2024poisonedrag",
        "author": "Zou, Wei and Geng, Runpeng and Wang, Binghui and Jia, Jinyuan",
        "title": "Poisonedrag: Knowledge poisoning attacks to retrieval-augmented generation of large language models"
      },
      {
        "key": "chen2024agentpoison",
        "author": "Zhaorun Chen and Zhen Xiang and Chaowei Xiao and Dawn Song and Bo Li",
        "title": "AgentPoison: Red-teaming {LLM} Agents via Poisoning Memory or Knowledge Bases"
      },
      {
        "key": "lee2024prompt",
        "author": "Lee, Donghyun and Tiwari, Mo",
        "title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "fu2023misusing",
        "author": "Fu, Xiaohan and Wang, Zihan and Li, Shuheng and Gupta, Rajesh K and Mireshghallah, Niloofar and Berg-Kirkpatrick, Taylor and Fernandes, Earlence",
        "title": "Misusing tools in large language models with visual adversarial examples"
      },
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      },
      {
        "key": "wu2024agentattack",
        "author": "Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi",
        "title": "Adversarial Attacks on Multimodal Agents"
      },
      {
        "key": "liao2024eia",
        "author": "Liao, Zeyi and Mo, Lingbo and Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Xiao, Chaowei and Tian, Yuan and Li, Bo and Sun, Huan",
        "title": "Eia: Environmental injection attack on generalist web agents for privacy leakage"
      },
      {
        "key": "xu2024advweb",
        "author": "Xu, Chejian and Kang, Mintong and Zhang, Jiawei and Liao, Zeyi and Mo, Lingbo and Yuan, Mengqi and Sun, Huan and Li, Bo",
        "title": "Advweb: Controllable black-box attacks on vlm-powered web agents"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "kumar2024manipulating",
        "author": "Kumar, Aounon and Lakkaraju, Himabindu",
        "title": "Manipulating large language models to increase product visibility"
      },
      {
        "key": "nestaas2024adversarial",
        "author": "Nestaas, Fredrik and Debenedetti, Edoardo and Tram{\\`e}r, Florian",
        "title": "Adversarial search engine optimization for large language models"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "wu2024agentattack",
        "author": "Wu, Chen Henry and Koh, Jing Yu and Salakhutdinov, Ruslan and Fried, Daniel and Raghunathan, Aditi",
        "title": "Adversarial Attacks on Multimodal Agents"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "pi_against_gpt3",
        "author": "Simon Willison",
        "title": "{Prompt injection attacks against GPT-3}"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "ignore_previous_prompt",
        "author": "Perez, F\u00e1bio and Ribeiro, Ian",
        "title": "Ignore Previous Prompt: Attack Techniques For Language Models"
      },
      {
        "key": "schulhoff2023ignore",
        "author": "Schulhoff, Sander  and\nPinto, Jeremy  and\nKhan, Anaum  and\nBouchard, Louis-Fran{\\c{c}}ois  and\nSi, Chenglei  and\nAnati, Svetlina  and\nTagliabue, Valen  and\nKost, Anson  and\nCarnahan, Christopher  and\nBoyd-Graber, Jordan",
        "title": "Ignore This Title and {H}ack{AP}rompt: Exposing Systemic Vulnerabilities of {LLM}s Through a Global Prompt Hacking Competition"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "delimiters_url",
        "author": "Simon Willison",
        "title": "{Delimiters won\u2019t save you from prompt injection}"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "liu2024formalizing",
        "author": "Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang",
        "title": "Formalizing and benchmarking prompt injection attacks and defenses"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "chen2024struq",
        "author": "Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David",
        "title": "StruQ: Defending against prompt injection with structured queries"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "wallace2024instruction",
        "author": "Wallace, Eric and Xiao, Kai and Leike, Reimar and Weng, Lilian and Heidecke, Johannes and Beutel, Alex",
        "title": "The instruction hierarchy: Training llms to prioritize privileged instructions"
      },
      {
        "key": "chen2024struq",
        "author": "Chen, Sizhe and Piet, Julien and Sitawarin, Chawin and Wagner, David",
        "title": "StruQ: Defending against prompt injection with structured queries"
      },
      {
        "key": "chen2024aligning",
        "author": "Chen, Sizhe and Zharmagambetov, Arman and Mahloujifar, Saeed and Chaudhuri, Kamalika and Guo, Chuan",
        "title": "Aligning llms to be robust against prompt injection"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "hines2024defending",
        "author": "Hines, Keegan and Lopez, Gary and Hall, Matthew and Zarfati, Federico and Zunger, Yonatan and Kiciman, Emre",
        "title": "Defending Against Indirect Prompt Injection Attacks With Spotlighting"
      },
      {
        "key": "alex2023ultimate",
        "author": "Alexandra Mendes",
        "title": "{Ultimate ChatGPT prompt engineering guide for general users and developers}"
      },
      {
        "key": "delimiters_url",
        "author": "Simon Willison",
        "title": "{Delimiters won\u2019t save you from prompt injection}"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "learning_prompt_sandwich_url",
        "author": "Unknown",
        "title": "{Sandwitch defense}"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "debenedetti2024agentdojo",
        "author": "Debenedetti, Edoardo and Zhang, Jie and Balunovic, Mislav and Beurer-Kellner, Luca and Fischer, Marc and Tram{\\`e}r, Florian",
        "title": "AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "wu2025isolategpt",
        "author": "Wu, Yuhao and Roesner, Franziska and Kohno, Tadayoshi and Zhang, Ning and Iqbal, Umar",
        "title": "{IsolateGPT: An Execution Isolation Architecture for LLM-Based Systems}"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "deberta-v3-base-prompt-injection-v2",
        "author": "ProtectAI",
        "title": "Fine-Tuned DeBERTa-v3-base for Prompt Injection Detection"
      },
      {
        "key": "inan2023llama",
        "author": "Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others",
        "title": "Llama guard: Llm-based input-output safeguard for human-ai conversations"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "liu2024formalizing",
        "author": "Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang",
        "title": "Formalizing and benchmarking prompt injection attacks and defenses"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "hung2024attention",
        "author": "Hung, Kuo-Han and Ko, Ching-Yun and Rawat, Ambrish and Chung, I and Hsu, Winston H and Chen, Pin-Yu and others",
        "title": "Attention Tracker: Detecting Prompt Injection Attacks in LLMs"
      }
    ]
  }
]