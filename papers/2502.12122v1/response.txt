\section{Related Work}
\paragraph{PEFT:} As large language models continue to grow, parameter-efficient fine-tuning (PEFT) has become a popular approach to reducing computational and storage costs. Among various methods**Raghu, "To Recycle or Not to Recycle"**, **Wu, "Adversarial Training for Free"**, LoRA**Kaplan, "Finding Order in the Chaos"** has emerged as one of the most widely used. 
Building on its success, several approaches have been proposed to enhance different aspects of PEFT**Zhang, "Improving Parameter Efficiency in Large Language Models"**. One such method, LoRA-XS**Tay, "LoRA-XS: A Framework for Efficient Fine-Tuning"**, further optimizes parameter efficiency by enabling flexible control over the number of trainable parameters per adaptation module. 
\our{} reuses the idea of SVD-based projections to reduce the parameter space dimensionality. 
%, allowing fine-tuning to be tailored to different computational constraints.

\paragraph{Bayesian LoRAs:} Standard LoRA**Kaplan, "Finding Order in the Chaos"** does not account for uncertainty, making fine-tuned models susceptible to miscalibration. Then, Bayesian LoRA approaches integrate Bayesian inference techniques into LoRA to improve uncertainty estimation and generalization.

Several Bayesian LoRA methods have been proposed, each employing different Bayesian techniques to address these challenges.  SWAG-LoRA **Zhang, "SWAG-LoRA: Stochastic Weight Averaging-Gaussian for Efficient Fine-Tuning"** combines Stochastic Weight Averaging-Gaussian (SWAG) with LoRA to enable approximate Bayesian inference, significantly improving model calibration and reducing overconfidence. Laplace-LoRA **Li, "Laplace-LoRA: Efficient Approximation of the Posterior Distribution"** applies a Laplace approximation to the posterior over LoRA parameters. Bella **Tay, "Bella: Reducing the Cost of Bayesian Deep Ensembles"** introduces an approach that reduces the cost of Bayesian deep ensembles by applying multiple low-rank perturbations to a pre-trained model.
%
BLoB (Bayesian Low-Rank Adaptation by Backpropagation) **Kaplan, "BLoB: Efficient Bayesian Fine-Tuning with Backpropagation"** jointly learns both the mean and covariance of model parameters throughout the fine-tuning process using Variational Inference. B-LoRA **Wu, "B-LoRA: A Bayesian Perspective on Quantization and Rank Selection"** introduces a Bayesian perspective to both quantization and rank selection by using a prior distribution over these hyperparameters, optimizing model efficiency and reducing bit operations.

 The key challenge lies in balancing uncertainty modeling with parameter efficiency, as Bayesian inference typically increases both the number of trainable parameters and computational cost.
Despite their advantages, Bayesian LoRA methods face challenges related to increased parameter count and computational cost. One major issue is the higher storage and memory requirements, as Bayesian methods often require additional parameters to model uncertainty, particularly those involving covariance estimation, such as SWAG-LoRA**Zhang, "SWAG-LoRA: Stochastic Weight Averaging-Gaussian for Efficient Fine-Tuning"**. 
Scalability remains a concern for methods that explicitly model uncertainty across a large number of parameters.