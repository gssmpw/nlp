\section{Approach}\label{approach_section}



Dependency analysis forms the basis of our selective information flow mechanism. The \textbf{\dependencydetector} analyzes the history to identify relevant regions before the system proceeds. These screeners operate on a LM’s full history, where parts of the history are divided into non-overlapping regions, each annotated with confidentiality and integrity labels. Regions without explicit labels are treated as having the most permissive label (public and trusted). We first describe the two approaches that we developed to estimate the dependent regions for a particular generation. 


\subsection{LM-Judge Approach}

LMs have demonstrated remarkable abilities in reasoning\cite{wei2023chainofthoughtpromptingelicitsreasoning, zelikman2024quietstarlanguagemodelsteach} and reflection\cite{renze2024selfreflectionllmagentseffects}, making them well-suited for tasks that require judgment or decision-making. This has led to the increasing popularity of using LMs as judges\cite{gu2025surveyllmasajudge}. In our work, we adopt this methodology as one implementation of the \dependencydetector. To achieve this, we tag every region in the TBAS context with easily recognizable markers, such as \texttt{<<REGION\_N>>region content goes here<</REGION\_N>>}, ensuring that the LM can clearly identify and differentiate between regions. We employ prompt sandwiching \cite{learning_prompt_sandwich_url} where we provide instructions in both the system message and the final message in a long context. We also employ GPT-4's capability to enforce a specific tool call to ensure the reflected regions are well-formed. 



\subsection{Attention-Based Approach}\label{sec:attn}

Motivated by the case studies in \S\ref{sec:motivation-attn}, we design a neural network to map the features of attention of the dependency relationship. 

\textbf{Problem Formulation.} We formulate the dependency analysis into a sequential binary classification problem. In particular, every input of a data point has two fields:
\begin{itemize}
    \item $I, O$: the input and output text generated by potentially LMs,
    \item $T = (b_1, e_1), (b2_, e_2), ..., (b_n, e_n)$: a list of regions needed for dependency analysis.
\end{itemize}

A classifier $\mathcal{C}$ maps the input text, output text, and input regions to list of boolean variables on how whether the output is dependent on any input regions. Namely:
$\mathcal{C}(I, O, T) \rightarrow \hat{d_1}, \hat{d_2}, ..., \hat{d_n} \in \{0,\ 1\}.$

\textbf{Classifier Design.} We design our classifier by first extracting the attention features from the input-output text using an open-source LM, and then mapping the features to the dependency predictions by training a neural network. 

In particular, we extract attention features $\textbf{a}_k$ for every region $k$ by adopting common statistical measures: 
\begin{itemize}[noitemsep]
    \item \textbf{Normalized Attention Sum/Mean}: 
    \[
    \frac{\sum_{b_k \leq i \leq e_k} A_i}{\sum_{i} A_{i,o}}, \quad 
    \frac{\sum_{b_k \leq i \leq e_k} A_i}{\sum_{i} A_{i,o}} \times \frac{|I|}{e_k - b_k},
    \]

    \item \textbf{Normalized Attention Quantiles}: 20-th, 50-th, 80-th, 99-th Quantiles of normalized attention scores within the input region.
\end{itemize}

After extraction, every region has a list of attention features; we now map it to dependency scores using a neural network. Since the input regions follow a natural temporal pattern, we deploy a recurrent neural network (RNN) to iteratively generate whether the output depends on the current input region. Namely, for a network $f$ parameterized by $\theta$, the classification performs by 
$\hat{d_i},\ \textbf{s}_k = f_\theta(\textbf{s}_{k-1}, \textbf{a}_k),\ i = 1, 2, ..., n.
$
In practice, we found that a lightweight two-layer LSTM~\cite{hochreiter1997lstm} network suffices to obtain decent performance to uncover the dependency relationship beneath attention features.

\textbf{Implementation and Deployment.} For the experiment, we collect the dataset using 40 well-labeled test cases from AgentDojo. The offline evaluation shows 85\% train accuracy and 81\% test accuracy. When deploying the classifier, the local feature extractor LM and the trained classifier are invoked each time the LM generates an output to track dependencies. As both the local models and the classifier are lightweight, this process introduces minimal runtime overhead to the TBAS.














\subsection{Robust TBAS}
To extend TBAS with taint tracking, we introduce \textbf{\sysnamelong} (\sysname), an extension of traditional \textbf{TBAS} that performs the propagation of security metadata during interactions. We present a simplified view of our mechanism below where we assume that all content within the same message is annotated with uniform security metadata (i.e., each message is a single “region”). However, our implementation supports finer granularity, allowing individual messages, such as user messages or tool responses, to contain multiple regions, each with distinct security labels.

\textbf{Terminologies and Definitions.}
To present \sysname, we extend the symbols and terminologies presented in List~\ref{list:tbas_syms} where we use $\redacted$ to represent redacted content. 
We also modify the definitions presented in List~\ref{list:tbas_defs} as the runtime needs to keep track of security labels on messages. And that some messages are masked or redacted to maintain security guarantees. We detail the masking process later in this section. $m^{(l_i, l_c)}$ refers to messages tagged with the integrity label $l_i$ and confidentiality label $l_c$. 

{
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\begin{equation*}
\begin{array}{l@{\;}rcl}
\textbf{Tagged Messages} & \underline{M} & = & \cdot \mid  \underline{M}, m^{(l_i, l_c)} \\[8pt]
\textbf{Post Redaction Messages} & \mathcal{M}_{\redacted} & = & \cdot \mid \mathcal{M}_{\redacted}, m  \mid  \mathcal{M}_{\redacted}, \redacted 
\end{array}
\end{equation*}
}

As specified in \S\ref{subsec:robust_tbas_assumptions}, we assume a security lattice $L$ where $(l_i, l_c) \in L$, and a Information Flow Policy $P$, defined in Eq.~\ref{eq:security_policy} specifying the label restrictions for a tool call $t^i$.

We change the types of the meta-functions presented in List~\ref{list:tbas_funcs} to account for the Tagged Messages and Post Redaction Messages shown below:

\textbf{Metafunctions}:
{
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\begin{equation*}
\begin{array}{l@{\;}rl}
\textbf{GET\_NEXT\_TOOLCALLs} & : & \mathcal{M}_{\redacted}  \mapsto \textbf{ToolCalls} \\
\textbf{CALL\_API} & : & t^i\times E \mapsto m^{(l_i, l_c)}\times E \\
\textbf{LM\_RESPONSE} & : & \mathcal{M}_{\redacted}  \mapsto m \\
\textbf{USER\_REQUEST} & : & \underline{M} \mapsto m^{(l_i, l_c)} \\
\textbf{USER\_CONTINUE} & : & \underline{M} \mapsto \textbf{TRUE}\mid \textbf{FALSE} 
 \label{list:robust_tbas_funcs}
\end{array}
\end{equation*}
}


\textbf{Security Metadata Propagation.}
Before the LM is permitted to generate the next message for the agent, the 
\dependencydetector identifies the \textbf{regions of interest}. These are the regions deemed relevant to the agent’s next action based on the current context. 

Once the regions of interest are identified, the runtime computes a \textbf{final label} $(l_i^d, l_c^d)$ . This label is derived by aggregating the security labels of all relevant regions using the join operator ($\sqcup$) defined within the developer-provided security lattice. This label, $(l_i^d, l_c^d)$ , represents a conservative upper bound on the restrictions associated with the regions of interest. In other words, $(l_i^d, l_c^d)$ is the least restrictive(more secret and less trusted) label that is at least as restrictive as every relevant region’s label for this final label $(l_i^d, l_c^d)$ serves as the security context for the next phase of computation, ensuring that the LM respects the confidentiality and integrity constraints implied by the relevant regions in the context.


\begin{algorithm}
\caption{Dependency Label SCREENER}
\label{alg:dependency_label_collector}
\begin{algorithmic}[1]
\Require Tagged Messages $\underline{M}$
\Ensure Collected dependency labels $l$
\State $(l_i^d, l_c^d) \gets \bot$ \Comment{Initialize $l$ as the most permissive element in the lattice}
\ForAll{$m^{(l_i, l_c)} \in \underline{M}$}
    \If{\textsc{IS\_RELEVANT}($m$,$\underline{M}$)}
        \State $(l_i^d, l_c^d) \gets (l_i, l_c) \sqcup (l_i^d, l_c^d)$ \Comment{Merge labels for all dependent regions}
    \EndIf
\EndFor
\State \Return $(l_i^d, l_c^d)$ \Comment{Return merged dependency labels where the final label is at least as restrictive as the labels on any relevant region}
\end{algorithmic}
\end{algorithm}
\vspace{-1em}
{
\setlength{\abovedisplayskip}{0pt}
\setlength{\belowdisplayskip}{2pt}
\begin{equation*}
\begin{array}{l@{\;}rcl}
\textbf{SCREENER} & : & \underline{M} &  \mapsto L
\end{array}
\end{equation*}
}
The \dependencydetector is detailed in Algorithm \ref{alg:dependency_label_collector} where the \texttt{IS\_RELEVANT} function is left unspecified and can be instantiated by either the JM-Judge or the Attention-based methods. It's possible that there are nonregion based techniques that could also instantiate such a screener.

\begin{algorithm}[H]
\caption{\textbf{REDACTOR} Algorithm}
\label{alg:redaction}
\begin{algorithmic}[1]
\Require Tagged Message Sequence $\underline{M}$, Redaction Label $(l_i^d, l_c^d)$
\Ensure Redacted Message Sequence $\mathcal{M}_{\redacted}$
\State $\mathcal{M}_{\redacted} \gets \cdot$ \Comment{Initialize the redacted sequence as empty}
\ForAll{$m^{(l_i, l_c)} \in \underline{M}$}
    \If{$(l_i, l_c) \sqsubseteq (l_i^d, l_c^d)$} \Comment{Checking if message label is as permissive as the target label}
        \State $\mathcal{M}_{\redacted} \gets \mathcal{M}_{\redacted}, m$ \Comment{Preserve message $m$}
    \Else
        \State $\mathcal{M}_{\redacted} \gets  \mathcal{M}_{\redacted},\redacted $ \Comment{Replace message with $\redacted$}
    \EndIf
\EndFor
\State \Return $\mathcal{M}_{\redacted} $ \Comment{Return the fully redacted sequence}
\end{algorithmic}
\end{algorithm}


Upon determining a label $l$ , which represents the security restrictions applicable to the message being generated, the system enforces these restrictions to ensure soundness. Specifically, the LM is allowed to observe any content that is less restrictive than $l$ . However, any content that is more restrictive than $l$ must be redacted. This redaction process is shown by Algorithm \ref{alg:redaction}.

{
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\begin{equation}
\begin{array}{l@{\;}rl}
\textbf{REDACTOR} & : & \underline{M} ,L \mapsto \mathcal{M}_{\redacted}
\end{array}
\end{equation}
}

$\texttt{REDACTOR}$ redact all messages that are more restrictive than the label $l$ arrived at by the screener. 

\noindent\textbf{Runtime Behavior.} At runtime, the \dependencydetector first output some label $(l_i^{u}, l_c^{u})$, which serves the role of conservatively bounds the information that can influence the LM’s generation of the next message, similar to that of the label on the program counter in a traditional IFC analysis.

Next, the \textbf{REDACTOR} redacts all messages more restrictive(more secret and less trusted) than the label provided by the screener. The resulting post-redaction messages are then used by the LM to come up with a list of tool calls.
{
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\begin{equation*}
\begin{array}{l@{\;}rl}
\textbf{USER\_CONFIRMATION} & : & t^i\mapsto \textbf{TRUE} \mid \textbf{FALSE}
\end{array}
\end{equation*}
}

The runtime then verifies that each of the tool calls is permitted with label ${(l_i^{u}, l_c^{u}})$ by the information flow policy of the tool call $P(t^i)$ . If ${(l_i^{u}, l_c^{u}})$ is not permitted, the system halts to await user confirmation on whether to proceed tool call.

\begin{algorithm*}[h!]
\caption{Robust Tool-Based Agent System (\textit{Taint Tracking Mechanism shown in Red}) }
\label{alg:robust_TBAS}
\begin{algorithmic}[1]
\footnotesize
\Require Initial Tagged System Message $m_s^{(l_i^s,l_c^s)}$, Environment $E$
\State Initialize $\underline{M} \gets\cdot, m_s^{\textcolor{red}{(l_i^s,l_c^s)}} $ \Comment{Initialize Tagged Messages \underline{M} with the Tagged System Message}
\While{\textsc{user\_continue}()} \Comment{If user continues interaction}
    \State $\underline{M} \gets \underline{M}, \textsc{user\_message}() $ \Comment{Append user message to $\underline{M}$}
    \State \textcolor{red}{$(l_i, l_c) \gets \textsc{screener}(\underline{M})$ \Comment{the screener obtains the label by screening the tagged messages $\underline{M}$ and returns the joined label of all relevant regions}}
    \State \textcolor{red}{$\mathcal{M}_{\redacted} \gets \textsc{redactor}(\underline{M}, (l_i, l_c))$ \Comment{Messages with more restrictive (more secret and less trusted)labels are redacted}}
    \State $\textbf{ToolCalls} \gets \textsc{get\_next\_toolcalls}(\mathcal{M}_{\redacted})$ \Comment{Generate new tool calls based on the redacted $\mathcal{M}_{\redacted}$}
    \ForAll{$t^i \in \textbf{ToolCalls}$}
        \State \textcolor{red}{$(l_i^p, l_c^p) \gets \textsc{P}(t^i)$ \Comment{Obtain the restriction label on this tool call}}
        \textcolor{red}{\If{$(l_i, l_c) \not\sqsubseteq (l_i^p, l_c^p)$ \textbf{and not} \textsc{user\_confirmation}($t^i$)} 
            \State \textbf{continue} \Comment{If the information flow policy is violated, explicit user confirmation is required to continue}
        \EndIf}
        \State $E, m^{\textcolor{red}{(l_i^t, l_c^t)}} \gets \textsc{call\_API}(t^i, E)$ \Comment{Execute tool $t^i$ with environment $E$; update $E$ and return $m$}
        \State \label{line:tainting_tool}$\underline{M} \gets \underline{M}, m^{\textcolor{red}{(l_i^t, l_c^t) \sqcup (l_i, l_c)}}$ \Comment{Append the tainted tool response to $\underline{M}$}
    \EndFor
    \State \textcolor{red}{$(l_i^u, l_c^u) \gets \textsc{screener}(\underline{M})$ \Comment{The response from the LM to the user needs to be similarly tainted based on its dependencies}}
    \State\textcolor{red}{ $ \mathcal{M}_{\redacted} \gets \textsc{redactor}(\underline{M}, (l_i^u, l_c^u))$}
    \State $m_u \gets \textsc{LM\_response}(\underline{M})$
    \State \label{line:tainting_user_response}$\underline{M} \gets  \underline{M},m_u^{\textcolor{red}{(l_i^u, l_c^u)}}$ \Comment{Append response from the LM to the user to $\underline{M}$}
\EndWhile
\end{algorithmic}
\end{algorithm*}

We illustrate the Robust TBAS Algorithm \ref{alg:robust_TBAS}, an extension of the TBAS Algorithm \ref{alg:TBAS}. A worked through example of our algorithm is found in Fig \ref{fig:robust_tbas_example}.

A critical aspect of information flow control is ensuring the proper propagation of security metadata. Every time a new message is generated, its label must reflect both the restrictions of the current context and the label returned by the tool. This ensures the label accurately represents the cumulative restrictions of all contributing factors.  

Such tainting mechanism is represented by lines \ref{line:tainting_tool} and \ref{line:tainting_user_response} from Alg.~\ref{alg:robust_TBAS}. Here, the runtime ensures that the security metadata of generated content aligns with the constraints imposed by both the runtime context and the tool invocation, preventing unauthorized information leakage or policy violations.

We stress that the tool environment must align with the stated information flow policy to prevent scenarios where secret or low-integrity data influences public or high-integrity data through a tool’s side effects. Such situations could effectively create a backdoor, allowing the protections provided by the information flow policy to be bypassed. 

\textbf{Screener Mistakes.}
Importantly, incorrect decisions by our \dependencydetector approaches cannot compromise security due to the selective masking mechanism. However, such errors may degrade performance. This degradation could take the form of over-tainting, where regions are unnecessarily marked as private or low integrity, leading to excessive user confirmations, or under-tainting, where insufficient content remains accessible for completing the task. 

