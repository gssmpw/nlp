\section{Related work}
\begin{table*}
  %\small
  \caption{\coloredtext{red}{Comparison of related work in vRAN }\\
  }
  \label{tab:related}
  \scalebox{1}{
      \begin{tabular}{ccccl}
        \toprule
        %\vtop{\hbox{\strut Approaches}\hbox{\strut (device)}} 
        \vtop{\hbox{\strut Approaches}} 
        &\thead{Offloading}
        &\thead{HARQ prediction}
        &\thead{PreParsing}
        &\thead{Resource pooling}\\\\        
        %&\thead{HARQ prediction}\\      
        %&\vtop{\hbox{\strut HARQ prediction}\hbox{\strut (relative)}}
        %&\vtop{\hbox{\strut distance}\hbox{\strut /latency}}
        %&\vtop{\hbox{\strut band-}}\\
        \midrule
        Li et al., "Deep Learning for Wireless Communication" &Yes  &Proactive(~\ref{early_decoding})      &High accuracy &Yes\\
        Nuberu    &No   &Passive        &No &Yes\\
        RT-opex   &No   &No             &No &Yes\\
        CloudIQ   &No   &No             &No &Yes\\
        \bottomrule
      \end{tabular}}
\end{table*}

The concept of Virtualized RAN (vRAN) has garnered significant interest in recent years Li et al., "Deep Learning for Wireless Communication"__Sun et al., "HARQ-Aware Resource Allocation for vRAN"__. The role and impact of virtualization in RAN systems have been thoroughly explored Kumar et al., "A Survey on Virtualized RAN Architecture"__. A primary challenge in deploying compute-intensive RAN/vRAN processing over cloud-based platforms is meeting the real-time requirements of the PHY layer, especially for computationally demanding tasks like FEC decoding. Various strategies have been developed to manage the allocation of compute resources for these real-time constraints in RAN/vRAN functions.

In the commercial realm, dedicated accelerators are often employed to support RAN functions, notably FEC decoding. Examples include Intel FlexRAN__NVIDIA Aerial__, both of which offer Layer-1 (L1) solutions in commercial vRANs. These systems utilize specialized hardware, such as FPGAs in FlexRAN and GPUs in Aerial, to boost performance. However, implementations details on these platforms are limited as they are not publicly available as open-source.

Academic research has also been active in exploring methods to enhance the efficiency of real-time RAN processing to minimize resource usage. For instance, CloudIQ__adopted a scheduling approach that assigned a set of base stations to a computing platform based on their processing demands to fulfill real-time processing needs. RT-OPEX__dynamically redistributed parallel tasks, including decoding, to idle computing resources in real-time, optimizing the use of edge computing. More recently, vrAIn__introduced machine-learning-based controllers to manage the distribution of radio and compute resources across sliced RAN instances, although it struggled to maintain RAN function reliability during computing resource shortages.

These works typically treat the entire decoding process as constrained by real-time requirements, overlooking the potential benefits of additional decoding time afforded by decoding result predictions (HARQ predictions). Nuberu__, a closely related work focused on LTE, passively used HARQ prediction to prevent deadline misses and limited spectrum assignments to reduce load during edge resource scarcity. However, it still relied entirely on edge resources for decoding, thus restricting its capacity.

\coloredtext{red}{
In contrast, as shown in Table~\ref{tab:related},  introduced an innovative decoding scheduling framework that actively used HARQ prediction and pre-parsing for packet subheaders. It intelligently managed resource allocation between edge and remote servers, enhancing overall system efficiency and capability.
}