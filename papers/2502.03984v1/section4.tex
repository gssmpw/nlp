\begin{algorithm}[h]
\SetNoFillComment
\DontPrintSemicolon
	{
		\caption{\small \textsc{PGB-Linear}}\label{alg:infer}

		\KwIn { $X \triangleq$ input X of $S \times M$,\\ 
  $\widehat{W} \triangleq$ a pruned weight matrix with $G$ diagonal groups, where each group is of $\frac{M}{G}\times \frac{N}{G}$,\\
  $\pi_r, \pi_c \triangleq$  permutation vectors for the rows and columns of each weight matrix $W$ }
        \For {each linear operation $X \widehat{W}^*$ s.t. $\widehat{W}^* \xleftarrow[argsort(\pi_{c})]{argsort(\pi_{r})} \widehat{W}$}
		{
            $\widetilde{X} \xleftarrow[\pi_c]{} X$\;
            
            \For {each group $j \in [1,G]$}
            {
                
                $g^{(j)} \leftarrow \widehat{W}[\frac{M}{G}(j-1):\frac{M}{G}j~,\frac{N}{G}(j-1):\frac{N}{G}j]$\;
                $\widetilde{X}^{(j)} \leftarrow \widetilde{X}[1:S~,~~\frac{M}{G}(j-1):\frac{M}{G}j]$\;
                $o^{(j)} \leftarrow \widetilde{X}^{(j)}g^{(j)}$\;
            }

            $O \leftarrow \textsc{Concat}[o^{(1)},o^{(2)},\dots,o^{(G)}]$\;
            $O^{*} \xleftarrow[]{argsort(\pi_r)} O$\;
            \Return ${O^{*}}$\;
		}
        
    }
\end{algorithm}

\section{Cost Analysis for Inference with PGB} \label{sec:cost}
As mentioned above, we make inference using only $G$ groups of each pruned weight matrix $\widehat{W} \in \mathbb{R}^{M\times N}$ for each linear operation $X \widehat{W}^*$, where $X$ is the $S$-length input sequence. By using this inference module, we ensure $G$ times faster efficiency by reducing the previous time cost $S  \cdot  M \cdot N$ to $S \cdot G  \cdot \frac{M}{G} \cdot \frac{N}{G}$. 

\noindent Algorithm \ref{alg:infer} provides a detailed outline of the linear operation process used at inference time with a pruned model resulting from the \textsc{Group-Weight-Pruning} procedure in Algorithm \ref{alg:prune}. It takes the input sequence $X \in \mathbb{R}^{S \times M}$, the grouped weight matrix $\widehat{W}$ obtained after PGB pruning, and the row and column permutation vectors $\pi_r$ and $\pi_c$ that have been determined during the pruning process. At this point, we take only the groups of remaining weights, $g^{(1)},...,g^{(G)}$ where each $g^{(i)} \in \mathbb{R}^{\frac{M}{G}\times \frac{N}{G}}$. Our inference process first starts with permuting the input $X$ using $\pi_c$ at each linear operation (Line 2). Subsequently, for the pruned weight matrix $\widehat{W}$ and the permuted matrix $\widetilde{X}$, we obtain the output $o^{(j)}$ for each group with its corresponding weight matrix $g^{(j)}$ and permuted input matrix $\widetilde{X}^{(j)}$ (Lines 3--6). Once the outputs $o^{(1)},...,o^{(G)}$ for all groups are obtained, we concatenate them to form the output $O$, and permute the output $O$ with respect to $argsort(\pi_r)$ to obtain the final desired output $O^{*} \in \mathbb{R}^{S \times N}$ (Lines 7--8), where $argsort(\pi_r)$ returns the permutation vector of indices that rearrange the output values back to their original positions. As mentioned in Section \ref{sec:cost}, \textsc{PGB-Linear} incurs $1/G$ times the cost of the original linear operation, i.e., $X \widehat{W}^*$.
