\begin{figure}[]%
\centering
\includegraphics[width=0.4\textwidth]{figs/discussion.pdf}
\caption{Visualization of flame steak compared with 4D-GS.}\label{discussion2}
\end{figure}
\section{Discussion on Real-World Scenario} \label{real-world}
Generating a dynamic scene from input real-world videos is an essential task. In this section, we conduct experiments on three scenes from Neu3Dâ€™s dataset to demonstrate the effectiveness of DSFD and TSSF on complexity real-world dynamic scene. We set 4D-GS \cite{wu20244d} as the baseline, which has shown promising results in this task. To fair comparison, we directly insert our DSFD and TSSF into 4D-GS. More details can be found in supplementary material.

\begin{table}[]
	\centering
	\renewcommand\arraystretch{0.95}
	\scalebox{0.85}{
    \begin{tabular}{c|cccc}
	    \hline
		\multicolumn{1}{c|}{\textbf{\makecell{Method}}} &
		\multicolumn{1}{c}{\textbf{PSNR $\uparrow$}} & \multicolumn{1}{c}{\textbf{SSIM $\uparrow$}} & \multicolumn{1}{c}{\textbf{D-SSIM $\downarrow$}} & \multicolumn{1}{c}{\textbf{LPIPS $\downarrow$}} \\ \hline
		4D-GS \cite{wu20244d} & 32.1598 & 0.9483 & 0.0132 & \textbf{0.1422} \\
		Ours & \textbf{32.3964} & \textbf{0.9494} & \textbf{0.0123} & 0.1434 \\ \hline
	\end{tabular}}
	\caption{Evaluation of the performance on Neu3D's dataset.}
\label{discussion1}
\end{table}




The results are shown in Tab.\ref{discussion1} and Fig.\ref{discussion2}. Our method achieves competitive results, demonstrating significant potential even for intricate real-world scenarios. Due to static nature of a significant portion of the real-world scene, the previous method easily encounters challenges in exploring dynamic regions, consequently impacting the quality of outputs. Hence, it is necessary to decompose dynamic and static regions to mitigate this issue. In essence, significant differences exhibit texture variations and motion trends between frames. Thus it is beneficial to utilize this nature to decouple dynamic-static information at feature-level, which enables us to enhance fine-grained dynamic representations. Indeed, there are additional methods available to decouple effectively. For instance, we can introduce optical flow and utilize 3D-aware foundation model \cite{xu2024depthsplat,yang2024depthv2} to extract depth features used to decouple.

