\section{Related Work}
Previous methods for event relation extraction**Socher, "Recursive Deep Models for Semantic Compositionality"**
primarily utilize multi-class classification, MASK prediction, or prototype matching, focusing on addressing specific sub-tasks such as coreference, temporal, causal, or sub-event relations. In the classification-based approach**Zhang, "Event Extraction and Temporal Awareness with Answer Reckoner"**, event mentions are paired together, and additional features are incorporated, such as prototypes, logical rules, graph convolutional networks, or prompts. MASK prediction-based methods**Li, "Mask-Predict: Boxed Entity Recognition with Masked Predictions"**
train a masked language model to predict the relation. The prototype matching method**Yin, "ProtoMatch: A Prototype-Based Method for Event Relation Extraction"**
manually selects instances to serve as prototypes for each relation, and new instances are then matched against these prototypes. **Zhou, "Multi-Choice Question Answering via Reasoning over Knowledge Graph with Attention Mechanism"**
and **Lin, " Span-based Entity Mention Extraction with Pre-trained Language Model"**
each proposed reading comprehension models based on multi-choice and multi-span, respectively, allowing the model to select the correct answer from candidate options or to generate multiple answers simultaneously. Simultaneously, many entity relation extraction methods based on LLMs**Huang, "Generating Natural Measuring Expressions with Pre-trained Language Models"**
directly prompt large language models to generate relations between pairs of entities. However, these methods have several drawbacks. Therefore, we have designed a series of improvement measures to address these identified deficiencies.