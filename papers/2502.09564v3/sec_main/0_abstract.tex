\begin{abstract}
Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data whenever they are affected by strong spurious correlations between specific attributes and target labels. This results in a form of bias affecting training data, which typically leads to unrecoverable weak generalization in prediction. 
This paper aims at facing this problem by leveraging bias amplification with generated synthetic data: we introduce \textit{Diffusing DeBias} (DDB), a novel approach acting as a plug-in for common methods of unsupervised model debiasing exploiting the inherent bias-learning tendency of diffusion models in data generation.
Specifically, our approach adopts conditional diffusion models to generate synthetic bias-aligned images, which replace the original training set for learning an effective bias amplifier model that we subsequently incorporate into an end-to-end and a two-step unsupervised debiasing approach. 
By tackling the fundamental issue of bias-conflicting training samples memorization in learning auxiliary models, typical of this type of techniques, our proposed method beats current state-of-the-art in multiple benchmark datasets, demonstrating its potential as a versatile and effective tool for tackling bias in deep learning models. 
\end{abstract}



\begin{figure}[ht]
  \centering
  \includegraphics[width=1\linewidth]{figures/pdfs/teaser3.pdf}
  \caption{Comparison of bias amplifier training approaches. (a) Traditional methods that use real biased datasets lead to the memorization of biased-conflicting samples, resulting in suboptimal auxiliary models. (b) Our proposed approach leverages conditional diffusion models to learn class-specific biases and amplify them into synthetic images. Such generations can replace the original training set for learning an effective \textit{Bias Amplifier}, eliminating memorization effects by avoiding exposure to real data.}
  \label{fig:teaser}
\end{figure}

