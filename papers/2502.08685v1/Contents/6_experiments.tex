\section{Experiment}
We compare our framework on four public datasets with various base models to sate-of-the-art baselines from the aspects of accuracy, diversity, and fairness.
\subsection{Datasets}
We use four real-world datasets in our experiments. Table \ref{tab:DataStatistics} provides an overview of the data statistics. \textbf{\textit{Beauty}} and \textbf{\textit{CD}} are both product recommendation datasets adopted from the \textit{Amazon Review Dataset}\cite{he2016ups}. It covers users' purchases over the category of \textit{All Beauty} and \textit{CDs and Vinyl} with rating score. \textbf{\textit{LastFM}} was collected from the \textit{Last.fm} music social platform \cite{Celma:Springer2010}, covering a large amount of users' music listening activities and metadata from the period between 2005 and 2009. \textbf{\textit{Gowalla}} was collected worldwide from the \textit{Gowalla} website \cite{cho2011friendship}, which is a location-based social networking website over the period from February 2009 to October 2010.

When dealing with datasets originally containing explicit ratings, we consider any ratings equal to or greater than four (on a scale of five) as positive feedback and all other ratings as missing entries to maintain consistency within the implicit feedback setting. Furthermore, to ensure data quality and reliability, we follow the common practice used in prior works to filter out users and items with fewer than ten ratings. 

\begin{table}[h]
    \centering
    \small
    \caption{The statistics of four read-world datasets.}
    \label{tab:DataStatistics}
    \begin{tabular}{lllll}
        \toprule
                & \textit{Beauty}  & \textit{CD} & \textit{LastFM}  & \textit{Gowalla} \\ \midrule
       
        \#User    & 8,159    & 11,346    & 23,385   & 29,858   \\ \hline
        \#Item    & 5,862    & 32,705    & 34,186   & 40,981   \\ \hline
        \#Interaction & 98,566   & 466,501  & 982,798  & 1,027,370 \\ \hline
        Density   & 0.206\% & 0.126\%  & 0.123\% & 0.084\% \\ \bottomrule
    \end{tabular}
\end{table}

\subsection{Evaluation Protocols}
We utilize cross-validation to evaluate our proposed model. The user-item interactions are divided into three sets: training set, validation set, and testing set, with a ratio of 8:1:1, respectively. We evaluate our model from three aspects: accuracy, diversity, and fairness. With respect to accuracy, Recall and Normalized Discounted Cumulative Gain (NDCG) are used. Recall@K measures how many target items are retrieved in the recommendation result, while NDCG@K further takes into account their positions in the ranking list \cite{jarvelin2002cumulated}. To evaluate the diversity, we use Category Coverage (CC) and Intra-List Distance (ILD). CC@k computes the proportion of unique categories represented in the top-K recommendation results. ILD@k calculates the average dissimilarity between item pairs within the recommended item list. For fairness, we use the Gini index to calculate the imbalance in the item distribution within the recommendation results. It is worth noting that we consider the ranking list of all items, excluding the training items in the user history, rather than ranking a smaller set of random items alongside the target items, as suggested in recent research \cite{li2020sampling}. All experiments are run five times with the same seed to control the data partition.

\begin{table*}[h]
    \tabcolsep 0.06in
    \centering
    \small
    \caption{The performance comparison of all methods on the backbone of BPR in terms of R@20 (Recall@20) and N@20 (NDCG@20) in percentage (\%).}
    \label{tab:OverallResult}
    \begin{tabular}{c|c|c|c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c|c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}c@{\extracolsep{4pt}}}
    \hline
    \textbf{Datasets}                  & \textbf{backbone}                  & \textbf{Metric} & \textbf{BPR}   &  \begin{tabular}[c]{@{}l@{}}\textbf{AO}\\ \textbf{-BPR}\end{tabular} &  \begin{tabular}[c]{@{}l@{}}\textbf{W}\\ \textbf{-BPR}\end{tabular} & \textbf{PRIS} & \begin{tabular}[c]{@{}l@{}}\textbf{TCE}\\ \textbf{-BPR}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{RCE}\\ \textbf{-BPR}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{TIL}\\ \textbf{-UI}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{TIL}\\ \textbf{-MI}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{DVR}\\ \textbf{-Loss}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{DVR}\\ \textbf{-Recall}\end{tabular} & \begin{tabular}[c]{@{}l@{}}\textbf{DVR}\\ \textbf{-NDCG}\end{tabular}  \\ \hline
    \multirow{8}{*}{Beauty} & \multirow{2}{*}{\textbf{BPRMF}}       & R@20   & 11.33  & 11.36  & 11.35 & 11.64 & 12.20 & 12.84 & 12.96 & \underline{13.47} & 15.82& 15.83& \textbf{15.84}\\
                              &                           & N@20   & 5.47  & 5.51  & 5.49 & 5.65 & 6.41 & 6.98 & 7.32  & \underline{7.51} & \textbf{8.76}& 8.67& 8.70\\
                              & \multirow{2}{*}{\textbf{NeuMF}}    & R@20   & 10.23  & 10.25 & 10.23 & 11.17 & 11.25 & 12.18 & 12.59 & \underline{12.81} & 13.41& 13.47& \textbf{13.50}\\
                              &                           & N@20   & 5.08  & 5.10 & 5.09 & 5.92 & 6.01 & 6.23 & 6.54 & \underline{6.75} & 7.19& 7.40& \textbf{7.48}\\ \cline{2-14} 
                              & \multirow{2}{*}{\textbf{MGCF}}     & R@20   & 11.41 & 11.41 & 11.42 & 11.78 & 12.38 & 12.92 & 13.42 & \underline{14.20} &  15.65&  15.67&   \textbf{15.68}\\
                              &                           & N@20   &  5.59 & 5.63 & 5.64 & 5.72 & 6.60 & 6.88 &  7.51 & \underline{7.83} &   \textbf{8.70}&  8.66&  8.67\\
                              & \multirow{2}{*}{\textbf{LightGCN}} & R@20   & 11.21 & 11.24 & 11.25 & 11.55 & 12.32 & 12.84 & 13.47 & \underline{14.46} &  16.40&  \textbf{16.43}&   16.42\\
                              &                           & N@20   & 5.33  & 5.35 & 5.36 & 5.69 & 6.54 & 6.69 & 7.54 & \underline{8.05}  &   8.94&  8.96&  \textbf{8.97}\\ \hline
    \multirow{8}{*}{CD}   & \multirow{2}{*}{\textbf{BPRMF}}       & R@20   & 9.99 & 10.03  & 10.01 & 10.32 & 9.03 & 9.71 & 10.88   & \underline{12.03}   & 15.02& \textbf{15.16}& 15.08\\
                              &                           & N@20   & 5.81  & 5.83  & 5.92 & 6.04  & 5.36 & 5.73 & 6.30 & \underline{7.11}  & 8.98& \textbf{8.99}& 8.97\\
                              & \multirow{2}{*}{\textbf{NeuMF}}    & R@20   & 11.03 & 11.08  & 11.05 & 11.93 & 11.77 & 11.42 & 11.85   & \underline{13.33}   & 14.10& \textbf{14.12}   & 14.10\\
                              &                           & N@20   & 6.40  & 6.43  & 6.62 & 7.22 & 6.86 & 6.77 & 7.01   & \underline{7.83}   & 8.48& 8.50& \textbf{8.52}\\ \cline{2-14} 
                              & \multirow{2}{*}{\textbf{MGCF}}     & R@20   & 13.80  & 13.86  & 14.01 & 14.24 & 13.82 & 13.94 & 14.30  & \underline{14.67}  &  \textbf{15.21}&  15.20&  15.15\\
                              &                           & N@20   & 8.02  & 8.08  & 8.07 & 8.24  & 8.20 & 8.11 & 8.43   & \underline{8.68}   &  9.20&  9.18&  \textbf{9.21}\\
                              & \multirow{2}{*}{\textbf{LightGCN}} & R@20   & 13.40 & 13.44  & 13.52 & 13.77 & 13.52 & 13.45 & 13.92  & \underline{14.21}   &  \textbf{14.98}&  14.95&  14.96\\
                              &                           & N@20   & 7.90  &  7.95  & 7.96  & 8.15  & 8.12 & 7.98 & 8.34    & \underline{8.61}   &  9.27&  9.26&  \textbf{9.28}\\ \hline
    
    \multirow{8}{*}{LastFM}   & \multirow{2}{*}{\textbf{BPRMF}}       & R@20   & 17.35 & 17.38  & 18.99 & 20.28 & 20.30& 18.50& 20.70   & \underline{21.63}   & 25.86& \textbf{25.96}& 25.92\\
                              &                           & N@20   & 10.47 & 10.52  & 11.43 & 12.07 & 11.91 & 11.46 & 12.48   & \underline{13.22}  & 16.44& \textbf{16.56}& 16.44\\
                              & \multirow{2}{*}{\textbf{NeuMF}}    & R@20   & 19.17 & 19.18  & 20.80 & 21.15 & 21.50 &  21.46 & 22.86   & \underline{23.15}   & 24.91& 25.22& \textbf{25.26}\\
                              &                           & N@20   & 11.63 & 11.67 & 12.15 & 12.26 & 13.07 & 12.99 & 14.10  & \underline{14.21}  & 15.80& \textbf{15.99}& 15.96\\ \cline{2-14} 
                              & \multirow{2}{*}{\textbf{MGCF}}     & R@20   & 21.26 & 21.32  & 21.28 & 21.97 & 21.80 & 21.22 & 23.14   & \underline{23.44}  &  25.53&  \textbf{25.67}&  25.61\\
                              &                       & N@20   & 13.06 & 13.33  & 13.30 & 13.50 & 13.47 & 13.19 & 14.19  & \underline{14.35}   &   16.12&  16.22&     \textbf{16.25}\\
                              & \multirow{2}{*}{\textbf{LightGCN}} & R@20    & 23.31 & 23.33 & 23.35 & 23.92 & 23.82 & 23.30 & 24.14  & \underline{24.85}   &  27.55&  \textbf{27.61}&  27.60\\
                              &                           & N@20   & 14.25 & 14.28  & 14.26 & 14.68 & 14.51 & 14.20 & 14.82   & \underline{15.35}   &  18.03&  18.09&  \textbf{18.10}\\ \hline
    \multirow{8}{*}{Gowalla}  & \multirow{2}{*}{\textbf{BPRMF}}       & R@20   & 12.19 & 12.22  & 13.02  &  14.88 & 13.94 & 13.82 & 15.80  & \underline{16.42}   & \textbf{17.85}& 17.15& 17.16\\
                              &                           & N@20   & 7.76  & 7.80  & 7.92 & 9.49 & 8.53 & 8.25 & 9.77   & \underline{10.09}   & \textbf{13.59}& 13.02& 13.02\\
                              & \multirow{2}{*}{\textbf{NeuMF}}    & R@20   & 13.55 & 13.59  & 14.35 & 15.83 & 14.80 & 14.76 & {16.89}   & \underline{17.32}   & 16.40   & \textbf{16.42}      & 16.41    \\
                              &                           & N@20   & 8.47  & 8.52  & 8.60 & 9.23 & 8.96 & 8.87 & 10.90   & \underline{11.17}   & 12.46   & 12.47      & \textbf{12.48}    \\ \cline{2-14} 
                              & \multirow{2}{*}{\textbf{MGCF}}     & R@20   & 15.75 & 15.84 & 15.83 & 16.35 & 15.93 & 15.80 & 17.33 & \underline{18.25} &  18.47&  18.52&   \textbf{18.53}\\
                              &                           & N@20   & 9.70  & 9.81  & 9.82 & 9.94 & 10.00 & 9.79 & 10.24  & \underline{11.06} &  14.36&    14.38&   \textbf{14.40}\\
                              & \multirow{2}{*}{\textbf{LightGCN}} & R@20   & 17.73 & 17.75  & 17.78 & 18.03 & 17.99 & 17.82 & 18.01   & \underline{18.61}   &  18.62&  18.85&  \textbf{18.87}\\
                              &                           & N@20   & 11.16 & 11.21  & 11.18 & 11.30 & 11.21 & 11.15 & 11.27   & \underline{11.62}    &  14.47&  14.55&  \textbf{14.58}\\ \hline
    \end{tabular}
\end{table*}

\subsection{Methods Studied}
To show the compatibility of our method, we apply the DVR framework on four recommendation backbones, i.e., BRPMF~\cite{koren2009matrix}, NeuMF~\cite{he2017neural}, MGCF~\cite{8970709}, and LightGCN~\cite{he2020lightgcn}.
Based on these backbones, our DVR framework can optimize diverse metrics, where ranking accuracy is denoted as DVR-Loss, DVR-Recall, and DVR-NDCG, diversity and fairness are labeled as DVR-CC, DVR-ILD, and DVR-Gini. Besides, we compare our framework with various data valuation methods for recommendations including BPR~\cite{10.5555/1795114.1795167}, AOBPR \cite{10.1145/2556195.2556248}, WBPR \cite{gantner2012personalized}, PRIS \cite{10.1145/3366423.3380187}, TCE-BPR, RCE-BPR\cite{10.1145/3437963.3441800}, TIL-UI and TIL-MI \cite{wu2022adapting}. 


\subsection{Performance Comparison}
\subsubsection{Comparison of Accuracy}
As shown in Table \ref{tab:OverallResult}, we compare the accuracy performance of DVR-Loss, DVR-Recall, and DVR-NDCG with several baseline approaches. The following is observations about the results: (i) Our framework outperforms most baseline methods across diverse evaluation metrics and consistently maintains this superiority across multiple datasets. This shoes the ability of our data valuator to accurately assess the quality of user behavior data, enhancing the efficacy of the recommendation model.
(ii) Compared to TCE-BPR and RCE-BPR, our framework consistently outperforms them. These approaches assume that noise only comes from positive samples and treat all negative items equally, which is suboptimal. Moreover, relying solely on loss values for weighting positive samples can reinforce errors.
(iii) Our framework outperforms AOBPR, WBPR, and PRIS. One factor is that these methods rely solely on negative samples to assess data quality. They select or adjust the weight of informative negative samples based on manual rules like item popularity or training loss, which may not be comprehensive.
(iv) In comparison to TIL-UI and TIL-MI, our proposed framework can achieve highly competitive performance when applied to both the simple base model (e.g., MF) and complex GNN-based model (e.g., MGCF and LightGCN). This strongly suggests the effectiveness of directly optimizing the accuracy metrics, i.e. Recall and NDCG.
(v) DVR-Loss, DVR-Recall, and DVR-NDCG exhibit similar outcomes, likely because these metrics all focus on accuracy. DVR-Recall and DVR-NDCG generally outperform DVR-Loss, as Recall and NDCG take into account detailed ranking information, while the latter only considers the relationship between the used positive and negative samples.


\subsubsection{Comparison of Diversity}
We compared DVR-CC and DVR-ILD with the BPR model on the Beauty dataset based on BPRMF and MGCF backbones. The performance results are presented in Table \ref{tab:Diversity}. Key observations from the experiments include: (i) DVR-CC and DVR-ILD achieved the best performance for CC@20 and ILD@20 metrics, respectively, as they are directly optimized for diversity metrics. This allows the data valuator to adjust data values for improved training of the recommendation model towards higher diversity. (ii) An interesting finding is that the Recall@20 and NDCG@20 of DVR-CC and DVR-ILD show no significant decrease compared to the BPR model, demonstrating the robustness of our reinforcement learning framework. This is attributed to our approach of enhancing recommendation model optimization by adjusting data values instead of directly incorporating diversity regularizers, which could potentially compromise recommendation performance. (iv) The MGCF outperforms the BPRMF as the backbone for BPR, DVR-CC, and DVR-ILD. This indicates that GCN-based approaches serve as strong backbones suitable for the joint optimization of data valuation and recommendation models.

\begin{table}[t]
\centering
\small
\caption{The performance comparison of BPR and our proposed methods on the Beauty dataset in terms of Recall@20, NDCG@20, CC@20, and ILD@20 in percentage (\%).}
\label{tab:Diversity}
    \begin{tabular}{l|l|l|l|l}
    \hline
    backbone                  & Metric & BPR & DVR-CC & DVR-ILD \\ \hline
    \multirow{2}{*}{BPRMF}       & R@20  & \textbf{11.33}&  11.01&  10.79\\
                               & N@20 & \textbf{5.47}&   5.18&  5.05\\
                               & CC@20 &  69.75&   \textbf{71.11}&   70.04\\
                               & ILD@20 &  90.31&  91.43&  \textbf{91.88}\\ \cline{1-5} 
    \multirow{2}{*}{MGCF} & R@20  & \textbf{11.41}&  11.26&  11.17\\
                               & N@20 & \textbf{5.59}&  5.45&  5.41\\
                               & CC@20  & 71.32&   \textbf{72.85}&  72.83\\
                              & ILD@20 & 91.49&   92.67&  \textbf{92.96}\\ \hline
    \end{tabular}
\end{table}
    
\begin{table}[t]
% \tabcolsep 0.06in
\small
\centering
\caption{The performance comparison of BPR and our proposed methods in terms of Recall@20, NDCG@20, Gini@20 (Gini Index) in percentage (\%).}
\label{tab:ItemFairness}
\begin{tabular}{l|l|l|l|l}
\hline
Datasets                  & backbone                  & Metric & BPR & DVR-Gini \\ \hline
\multirow{4}{*}{LastFM} & \multirow{2}{*}{BPRMF}       & R@20  &  \textbf{17.35}&  17.21\\
                            &                           & N@20 &  \textbf{10.46}&  10.38\\
                            &                           & Gini@20  &  97.94&  \textbf{95.47}\\ \cline{2-5} 
                            & \multirow{2}{*}{LightGCN} & R@20  &  \textbf{23.31}&  22.37\\
                            &                           & N@20 &  \textbf{14.25}&  13.69\\
                            &                           & Gini@20  &  97.86&  \textbf{96.23}\\ \hline
\multirow{4}{*}{Gowalla}   & \multirow{2}{*}{BPRMF}       & R@20  &  \textbf{12.19}&  12.04\\
                            &                           & N@20 &  \textbf{7.76}&  7.62\\
                            &                           & Gini@20  &  98.02&  \textbf{96.31}\\ \cline{2-5} 
                            & \multirow{2}{*}{LightGCN} & R@20  &  \textbf{17.73}&  17.47\\
                            &                           & N@20 &  \textbf{11.16}&  11.01\\
                            &                           & Gini@20  &  98.17&   \textbf{96.48}\\ \hline
\end{tabular}
\end{table}

\subsubsection{Comparison of Fairness}
The performance comparison of item fairness is displayed in Table \ref{tab:ItemFairness}. We compare DVR-Gini with the BPR model based on BPRMF and LightGCN backbones. From the experimental findings, we draw the following conclusions: (i) DVR-Gini consistently outperforms the BPR model in terms of the Gini metric, as DVR-Gini utilizes Gini as the reward in its reinforcement learning-based optimization approach. By leveraging policy gradients learned from the Gini metric, the data valuator improves the fairness performance. (ii) The Recall@20 and NDCG@20 of DVR-Gini exhibit strong performance compared to the BPR model, showcasing the robustness of our reinforcement learning framework. This resilience is similar to the rationale discussed in the preceding section on diversity.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{Figs/cosine_similarity_plot.png}
    \caption{The Cosine Similarity between Negative BPR Loss and Shapley Value.}
    \label{fig:case_study}
\end{figure}

\subsubsection{Case Study of Shapley value}
To verify the interpretability of the assigned Shapley value, we conduct a case study of the BPR-Loss model on the Beauty and LastFM datasets. Figure \ref{fig:case_study} shows the average cosine similarity between the Shapley value and the negative BPR loss of the batch data in every two epochs. Our analysis revealed a progressive increase in cosine similarity throughout the training process. Notably, the Beauty and LastFM datasets exhibited distinct initial values, peak values, and growth rates. These variations could be attributed to differences in dataset size and density, resulting in varying convergence speeds.
