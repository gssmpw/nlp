\section{Introduction}
With the vast amount of online information, Internet users are constantly exposed to an ever-growing number of online products or services. This abundance makes it challenging for individuals to find items that truly align with their interests. To solve the problem of information overload, personalized recommendation systems have emerged, playing a pivotal role in helping users navigate through the vast choices in modern society~\cite{ma2019hierarchical, ma2020memory, 10.1145/3477495.3532043, 10.1145/3626772.3657761}.


Current recommender systems usually prioritize the development of intricate model structures like RNN~\cite{HidasiKBT15}, Attention~\cite{10.1145/3626772.3657748}, Transformer~\cite{10.1145/3357384.3357895}, and GNN~\cite{he2020lightgcn}. With delicate model designs, these methods typically resort to Bayesian Personalized Ranking (BPR) to train their models on users' behavior data. BPR generates training samples by negative sampling~\cite{10.5555/1795114.1795167}, constructing triplets $\{\textit{user, positive item, negative item}\}$ to distinguish the positive items from the negative ones. The quality of these training samples plays a crucial role in the BPR training procedure, directly impacting the effectiveness of the recommendation model. However, most methods overlook data quality as they use the vanilla BPR training procedure, which penalizes all samples equally without accounting for distinguishing the distinct effects of various training instances.

A common case of fluctuating data quality arises from the negative sampling process, where the sampled items may include both true negative items and false negatives. For instance, in a movie recommendation system where a user prefers action movies, sampling true negative items like art films leads to higher-quality data over false ones sampled as war movies. Consequently, treating all training samples equally in this context can lead to sub-optimal representation learning, ultimately undermining the model's performance.
To differentiate high-quality data from low-quality data, some data-valuation methods for recommendation have been proposed~\cite{10.1145/3437963.3441800, 10.1145/2556195.2556248,gantner2012personalized,10.1145/3366423.3380187, wu2022adapting}. These methods typically resort to some pre-defined heuristic rules to identify the data quality, such as the prediction scores, popularity levels, or loss values. While these approaches have demonstrated promising performance, we identify two main limitations:
\begin{itemize}
    \item \textbf{Lacking interpretability}. Current methods employ a black-box design for data valuation, making it difficult to understand how data is evaluated and assigned value. This lack of transparency poses challenges in aligning data valuation with its actual contribution to model performance. For instance, there may be cases where data has a minimal impact on model outcomes, yet receives a high valuation. By incorporating explainability into data valuation, it becomes possible to ensure that the valuation accurately reflects data's real impact on model performance. This alignment would enhance both the transparency and reliability of data valuation processes, offering deeper insights into the data value in improving recommendations. 
    \item \textbf{Limited generality}. Prior works concentrate on enhancing recommendations through tailored model designs on certain metrics like accuracy, limiting the scalability of these approaches. There is a growing need for more versatile and adaptable work that can be applied across various model architectures and metrics. Many metrics utilized in performance evaluation are non-differentiable and hold significance in assessing various facets of the recommender system. For instance, Recall is crucial for measuring accuracy, while Category Coverage is instrumental in evaluating diversity. Enhancing the recommendation system across diverse aspects can lead to an increase in user satisfaction. Therefore, it is significant to handle both the differentiable and non-differentiable metrics.
\end{itemize}

To overcome these issues, we propose an explainable and versatile \textbf{\underline{D}}ata \textbf{\underline{V}}aluation framework for \textbf{\underline{R}}ecommendation (DVR) which can enhance the efficiency of data utilization tailored to any requirements of the model architectures and evaluation metrics. For explainable data valuation, a data valuator is presented to evaluate the data quality by measuring the contribution of data to model performance. The data valuator views the data as player and model performance as the outcome to compute the explainable Shapley value from a game-theoretic perspective, which has good mathematical properties and reliability. To improve the computation efficiency of the Shapley value, the data valuator utilizes Harsanyi interaction to reduce the computational complexity from exponential to constant time. With the aim of accommodating various evaluation metrics, a metric adapter is devised based on reinforcement learning to handle the important non-differentiable metrics that are widely used in many aspects of recommendation evaluation. The metric adapter treats the metric as the reinforcement reward to guide the optimization toward optimal metric performance. To ensure simplicity and efficiency, the framework conducts end-to-end data valuation without complex pre-processing or post-processing. 

The main contributions of this work can be summarized as follows:
\begin{itemize}
    \item We present an explainable and versatile framework to enhance data utilization efficiency across various model architectures and evaluation metrics. To our best knowledge, this work marks the first attempt at handling data valuation in terms of interpretability and generality in the recommendation domain.
    \item 
 We propose the explainable data valuation via calculating Shapley value from the game-theoretic perspective with high efficiency, ensuring understanding and trustworthiness of data values. We achieve metric adaption for both differentiable and non-differentiable metrics by reinforcement learning in an end-to-end manner.
    \item 
 Extensive experiments on various benchmarks show that our framework improves the performance of representative recommendation algorithms on various metrics including ranking accuracy, diversity, and fairness. Specifically, our framework achieves up to 34.7\% improvements in terms of the NDCG metric. Further analysis on explainable data valuation demonstrates the transparency and credibility of our framework.
\end{itemize}
