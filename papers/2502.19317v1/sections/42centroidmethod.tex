\section{The Centroid Method}
In this section, we provide an alternative method that utilize the classic centroid algorithm in convex optimization to obtain a solution that is $\varepsilon$ close to the optimal solution. Recall the bidder's problem is:
\begin{align*}
    \max_{\bid=(\mu_1, \mu_2 \dots, \mu_m)} &\sum_{j \in \platform} v_j(\mu_j) \nonumber\\
    s.t. & \sum_{j \in \platform} c_j(\mu_j) \leq T \cdot \sum_{j \in \platform} v_j(\mu_j). 
\end{align*}
\xtnote{double check the assumptions on the value and cost function} Since each of the value functions are concave, the sum of them is also a concave function. In addition, the feasible range defined by the ROS constraint is a convex region. \agnote{We should add a reason for this convexity.} Let $R$ be convex feasible range, we have $R \subseteq [0,n]^m$. For presentation purpose, we abuse notation and write $v(\bid) = \sum_j v_i(\mu_j)$. We want to approximately maximize the objective function, i.e., we want to output a bidding strategy $\bid'$ such that 
\[ v(\bid') \geq  v(\optf)-\varepsilon.\]
we assume a gradient oracle for the objective function\footnote{\xtnote{discuss why the assumption is reasonable}}.
The centroid \( c \) of a convex range \( R \subseteq \mathbb{R}^n \) can be expressed as:
\[
c = \frac{\int_R x \,dx}{\text{vol}(R)}, 
\]
where \(\text{vol}(R)\) is the volume of the range \( R \). This represents the ``center of mass'' of the range.
The following
result of the centroid is crucial to our analysis. 
\begin{lemma}
[Grünbaum's Lemma]For any compact convex set  $R \subseteq \mathbb{R}^n \text{ with a centroid } c \in \mathbb{R}^n,$ 
and for any halfspace \( H = \{ x \in \mathbb{R}^n \mid a^\top (x - c) \geq 0 \} \) whose supporting hyperplane passes through \( c \), the following holds:
\[
\frac{1}{e} \leq \frac{\text{vol}(K \cap H)}{\text{vol}(K)} \leq 1 - \frac{1}{e}.
\]
\end{lemma} 
In addition, we also utilize the strong separation oracle.
\begin{definition}
[strong seperating orcale]
For a convex set $K \subseteq \mathbb{R}^n$, a strong separation oracle for $K$ is an algorithm that takes a point $z \in \mathbb{R}^n$ and correctly outputs one of:
\begin{itemize}
    \item[(i)] \textbf{Yes} (i.e., $z \in K$), or
    \item[(ii)] \textbf{No} (i.e., $z \notin K$), as well as a separating hyperplane given by $a \in \mathbb{R}^n$, $b \in \mathbb{R}$ such that $K \subseteq \{ x \in \mathbb{R}^n \mid \langle a, x \rangle \leq b \}$ but $\langle a, z \rangle > b$.
\end{itemize}
\end{definition}
With these tools in hand, we present the following algorithm of our problem inspired by the centroid method for convex optimization. The \textsc{CentroidMethod} algorithm iteratively refines a search space by checking the centroid of the current search region in each iteration and queries the oracle to check if the centroid is feasible. If the point is infeasible, the oracle provides a separating hyperplane to update and reduce the search space; if feasible, the region is updated based on the value function's gradient. In particular, we consider the halfspace
of vectors positively correlated with the gradient, and continue. In either case, a constant fraction of the region is removed from the search space. This process repeats for \( T \) iterations, progressively narrowing the search space. After all iterations, the algorithm selects the best feasible point that minimizes the value function among the centroids checked, and returns it as the solution. Please refer to Algorithm~\ref{alg:centroid} for a formal description.

\begin{algorithm}
\SetAlgoRefName{3}
\SetAlgoLined
\KwIn{value function $v$, $T$}
% \KwOut{$\bid$}
\textbf{Initialize:} $K_1 \leftarrow [0,n]^m$\\
\For{$t = 1, \ldots, T$}{
    $\bid_t \leftarrow$ centroid of $K_t$\\
    query strong separation oracle on $\bid_t$\\
    \If{$\bid_t$ is not feasible}{
    $a_t \gets$ direction from strong separation oracle\\
    $K_{t+1} \leftarrow K_t \cap \{ x \mid \langle \nabla a_t, x - \bid_t \rangle\leq 0 \}$}
    \Else{
    $K_{t+1} \leftarrow K_t \cap \{ x \mid \langle \nabla v(c_t), x - \bid_t \rangle \geq 0 \}$}
}
$\bid \leftarrow \arg\min_{t \in \{1, \ldots, T|\ \bid_t \text{ is feasible}\}} v(\bid_t)$\\
\Return $\bid$
\caption{\textsc{CentroidMethod}}
\label{alg:centroid}
\end{algorithm}


% \begin{theorem}
% , the Centroid algorithm finds a (randomized) bidding strategy that achieves a value of at least opt-$\varepsilon$ with at most $O(m^2 \log \frac{G(n+1)}{\varepsilon})$,
% where $G$ is the upper bound of gradient of the objective function.
% \end{theorem}



\begin{theorem}
Given the feasible convex set $R \subseteq \mathbb{R}^m$ with $||x - y|| \leq r$ for any $x,y \in R$, and a convex function $v : R \rightarrow \mathbb{R}$ such that $\|\nabla v(x)\| \leq G$ for all $x \in R$. If $\bid$ is the result of the \textsc{CentroidMethod} algorithm,  $\optf = \arg\max_{x \in R} v(x)$, \xtnote{and  $\gamma = \frac{\text{vol}(R)}{\text{vol}[0,n]^m}$} then
\[
\xtnote{v(\optf) - v(\bid)  \leq \frac{4Gr}{\gamma} \cdot \exp(-T/3n)}.
\]
Hence, for any $\varepsilon \leq 1$, as long as $T \geq 3n \ln \frac{4Gr}{\varepsilon}$, we have
\[
 v(\optf) - v(\bid) \leq \varepsilon.
\]
\end{theorem}

\begin{proof}
For some $\delta \leq 1$, define the body
\[
R^\delta := \{(1 - \delta)\optf + \delta x \mid x \in R\}
\]
as a scaled-down version of $R$ centered at $\optf$. we have that:
\begin{enumerate}
    \item $\text{vol}(R^\delta) = \delta^m \cdot \text{vol}(R)$.
    \item For any points $x, y \in R$, integrating along the path from $x$ to $y$ and using the fact that the gradients are bounded by $G$ gives
    \begin{align*}
        v(x) - v(y)& = \int_{t=0}^1 \langle \nabla v(y + t(x - y)), x - y \rangle  dt\\
         &\leq \int_{t=0}^1 \|\nabla v(y + t(x - y))\| \|x - y\| dt\\
         & \leq G \|x - y\| \leq G \cdot (2r).
    \end{align*}
    \item The value of $v$ on any point $y = (1 - \delta)\optf + \delta x \in R^\delta$ is
    \begin{align*}
        v(y) & = v((1 - \delta)\optf + \delta x) \geq (1 - \delta)v(\optf) + \delta v(x)\\
        & = v(\optf) - \delta (v(\optf) - v(x)) \geq v(\optf) - 2\delta Gr,
    \end{align*}
where the first inequality is by concavity of the value function and the third inequality is by fact (2) above.
\end{enumerate}
Using Grünbaum's lemma, in our algorithm, the volume of the search range (may not necessarily be entirely feasible) falls by a constant factor in each iteration, so $\text{vol}(K_t) \leq \text{vol}(K_1) \cdot \left(1 - \frac{1}{e}\right)^t$, where $K_1 = [0,n]^m$ \xtnote{let $\gamma = \frac{\text{vol}(R)}{\text{vol}(K)}$ be the ratio between the volume of the total search region of the algorithm and the feasible region in it.
Let $\delta := 2/\gamma(1 - 1/e)^{T/m}$, then after $T$ steps the volume of $K_T$ is smaller than that of $R^\delta$}. Therefore, some point of $R^\delta$ must have been cut off.

Consider step $t$ with $R^\delta \subseteq K_t$ but $R^\delta \not\subseteq K_{t+1}$. Let $y \in K^\delta \cap (K_t \setminus K_{t+1})$ be a point that is ``cut off''. By concavity, we have
\[
v(y) \leq v(c_t) + \langle \nabla v(c_t), y - c_t \rangle;
\]
moreover, $\langle \nabla v(c_t), y - c_t \rangle < 0$ since the cut-off point $y \in K_t \setminus K_{t+1}$. 
In addition, since the hyperplane cross $R^\delta \subseteq R$, we also have that $c_t \in R$, since if $c_t \notin R$, the hyperplane defined by the strong separation orcale would not cut-off any feasible ranges.
Hence the corresponding centroid has value $v(c_t) > v(y) \geq v(\optf) - 2\delta Gr$. Since $\bid$ is the centroid with the smallest function value, we get

\[
\xtnote{f(\bid) - f(\optf) \leq 2Gr \cdot \frac{2}{\gamma}\left(1 - \frac{1}{e}\right)^{T/m} \leq \frac{4Gr}{\gamma} \exp(-T/3m).}
\]
The second claim follows by substituting \xtnote{$T \geq 3m \ln \frac{4Gr}{\gamma\varepsilon}$} into the first claim, and simplifying.
\end{proof}

As a corollary of the theorem, we can get the following query bound of the centroid metho of our algorithm:
\begin{corollary}
GIven any instance $M$, $S$, the \textsc{CentroidMethod} algorithm finds a bidding strategy such that
\[v(\bid) \geq v(\optf)-\varepsilon\]
with at most \xtnote{ $O(m^2\log \frac{4G\sqrt{m}n}{\gamma\varepsilon})$ }queries, where  $\|\nabla v(x)\| \leq G$ for all $x$ in the feasible range $R$.
\end{corollary}

\begin{proof}
Since the feasible region $R \subseteq [0,n]^m$, we have that $\|x-y\| < \sqrt{m}(n+1)$ for any $x, y \in R$. In addition, in each iteration, querying the strong separation oracle and obtaining the value of the centroid point requires $m$ queries. Given some $\varepsilon > 0$, we therefore have that the number of queries needed is 
\[
\xtnote{
m \cdot 3n \ln \frac{4GR}{\gamma\varepsilon} = O(m^2 \log \frac{G\sqrt{m}n}{\gamma\varepsilon}).}
\qedhere
\]
\end{proof}


% \begin{lemma}
% Given a fractional optimal solution, there should exist at most one platform such that the bid is not integral
% \end{lemma}

% \xtnote{conjecture: Can we translate the $\varepsilon$-fractional OPT to fractional OPT or discrete OPT 
% 	With some assumption on the minimum difference between adjacent value/marginals}