\section{Choices of the Nudges and Modalities}
\label{sec: section3}
We now outline the design of our interface nudges and the rationale behind the selection of both the nudges and the modalities.

\subsection{Choice of Nudges}
Our goal was to consider nudges that would trigger different types of self-reflection. We identified two types: \textbf{direct reflective nudges} and \textbf{indirect reflective nudges}. \textbf{Direct} reflective nudges typically involve explicit, targeted prompts that encourage individuals to reflect on their own thoughts, experiences or opinions, and are usually shorter, while \textbf{indirect} ones are subtler, often encouraging reflection through external examples or narratives, allowing users to reflect by considering others' viewpoints or scenarios and usually feature more content. This approach allows us to explore how different modalities support varying levels of reflective nudges.

\subsubsection{Direct Reflective Nudge: Persona}
The direct reflective nudge employs a \textit{persona} approach, encouraging reflection through perspective-taking~\cite{galinsky2000perspective, kim2019crowdsourcing, zhang2021nudge}. This approach is grounded in principles from constructivist learning theories~\cite{vygotsky1978mind, piaget1985equilibration}. By guiding users to explicitly examine their own thoughts, the persona approach mirrors Vygotsky's concept of mediated learning~\cite{vygotsky1978mind}, enabling users to internalize insights through active interaction with reflective stimuli. Piaget's theory~\cite{piaget1985equilibration} complements this by focusing on how learners construct knowledge through self-directed exploration. Reflection, as facilitated by the persona, prompts users to critically evaluate their preconceptions, fostering new understandings and alignment with Piaget’s notion of active knowledge construction. Moreover, we specifically chose persona as its ability to reach higher levels of deliberativeness compared to others, have been established in previous work~\cite{yeo2024help}.

\subsubsection{Indirect Reflective Nudge: Storytelling}
The indirect reflective nudge employs a \textit{storytelling} approach, encouraging users to reflect through narratives that present others' perspectives~\cite{batson1997perspective, yeo2024help}. By fostering reflection through vicarious experiences, storytelling provides richer contextual information than the persona-based approach by extending its content with an added storyline. Grounded in narrative-based learning~\cite{bruner1991narrative, green2000role}, storytelling is described by Bruner~\cite{bruner1991narrative} as a fundamental mode of thought, enabling the construction of personal and social meaning through interpretation. Green and Brock~\cite{green2000role} further explore the concept of `transportation' --- the immersive mental absorption into a narrative, characterized by focused attention, emotional engagement and vivid imagery. Their findings highlight the persuasive power of storytelling in shaping beliefs and attitudes. Additionally, prior research demonstrates that storytelling improves deliberativeness by engaging emotional and cognitive processes, ultimately enhancing critical thinking and reflective engagement~\cite{yeo2024help}.

\paragraph{\normalfont{Both nudges leverage self-referential encoding, where individuals process and internalize information by relating it to their own life, enhancing engagement and cognitive retention~\cite{rogers1977self}. These nudges also align with Kahneman's dual-system theories~\cite{kahneman2011thinking} (see section~\ref{sec: dual system thinking}), with the direct persona nudge engaging System 2 (i.e., analytical, reflective thinking) and the indirect storytelling nudge activating System 1 (intuitive, empathetic processing). Together, these nudges provide a multifaceted approach to fostering reflection.}} 

\subsection{Choice and Design of Modalities}
\label{sec: Modalities}
The design of each modality was guided by principles from multimedia learning theory~\cite{mayer2005cambridge, fadel2008multimodal} to enhance reflective engagement. We chose a set of modalities representative of non-interactive multimedia formats identified in prior research~\cite{mayer2005cognitive, de2005multimedia, deimann2006volitional, fadel2008multimodal}, ensuring they were representative of diverse content representations. According to Fadel~\cite{fadel2008multimodal}, non-interactive multimodal learning includes combinations such as text with visuals, audio and video formats. Empirical studies~\cite{mayer2005cognitive, de2005multimedia, deimann2006volitional, fadel2008multimodal} demonstrate that non-interactive, multimodal learning significantly improves learning outcomes compared to traditional single-mode approaches. Interestingly, when these scenarios shift from non-interactive to interactive settings, these gains are not statistically significant. Guided by this evidence, we identified the following non-interactive modalities to support reflection:
\begin{enumerate}
    \item \textbf{Text}: A traditional and widely used medium for reflective prompts. It follows the design principles of Cooper for persona~\cite{cooper1999inmates, cooper2007face, pruitt2010persona} and Freidus et al.~\cite{freidus2002digital} and Bruner~\cite{bruner1991narrative} for storytelling. As text is the most conventional modality, it is structured to optimize engagement without overwhelming users.
    \item \textbf{Image}: This modality integrates visual stimuli to enhance reflection, featuring the same text content, with additional images. It follows the \textit{spatial contiguity principle}, ensuring that images are placed alongside related text to minimize split-attention and enhance understanding~\cite{hegarty1993constructing, ayres2005split, moreno1999cognitive, mayer1989systematic, mayer1995generative, chandler1992split}. 
    \item \textbf{Audio}: Designed to leverage auditory cues, this modality employs the \textit{voice principle}, which suggests that reflections are more effective when delivered in a natural, human voice with a standard accent rather than a machine or foreign-accented narration~\cite{atkinson2005fostering}. This conversational delivery ensures engagement and encourages deeper thought.    
    \item \textbf{Video}: Combining visual and auditory elements, video content leverages its dynamic nature to simulate real-world experiences. This modality adheres to the \textit{temporal contiguity principle}, synchronizing narration with animations to ensure that verbal and visual information are presented together for better cognitive processing~\cite{moreno1999cognitive, mayer1991animations, mayer1992instructive, mousavi1995reducing}. Additionally, Paivio’s \textit{Dual-Coding Theory} supports the use of auditory and visual channels to reinforce reflective thinking~\cite{paivio2013imagery}.
\end{enumerate}

Figure~\ref{fig: modalities} provides examples for each of the modality and their respective reflective nudges. Content across modalities in each nudge type is the same.

\begin{figure*}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{figures/Four_Modalities.png}
  \caption{Example of the Two Reflective Nudges and their Respective Four Modalities.}
  \label{fig: modalities}
  \Description{Example of the two selected reflective nudges and their respective four modalities. An example for the text, persona: Dr Selene, 43 year old oceanographer. Sea levels have been naturally rising for years. It is clear that natural variability has dominated sea level rise, with changes in ocean heat content and changes in precipitation patterns. An example for the image, persona: an image of an oceanographer is shown with the exact same text shown at the bottom of the image. An example for the video, persona: a video is shown with the title - an oceanographer's insight on climate change. An example for the audio, persona: an audio is shown. An example for the text, storytelling: Dr Selene, a 43 year old oceanographer, dedicated her life to studying the oceans. She spent years understanding the natural patterns of the ocean while encountering playful dolphins and curious whales. An example for the image, storytelling: six different images were shown with the exact same text shown at the bottom of the images. Video and audio formats for storytelling is the same for persona except for its duration.} 
\end{figure*}

\subsection{Implementation of the Modalities with LLM and Generative AI}
We used GPT-4.0 to generate a range of 10 textual prompts for the direct reflective nudge. We then instructed the LLM to generate short narratives for each of the same textual prompts for indirect reflective nudge. Following, to generate modalities, we used text-to-image generation tools (Bing Image Creator), text-to-video generation tool (Invideo AI) and text-to-speech generation tool (Narakeet AI). This ensures that the content across \textbf{all modalities is strictly the same}, just presented differently by their own modality, such that we can assess the impacts of the modalities on deliberativeness and not due to the quality of the content presented in each modality.

The utilization of LLMs to promote self-reflection on online deliberation platforms ensures the adaptability and scalability of reflective nudges.
%Using LLMs, we tap into its vast knowledge and language proficiency in enabling reflective nudges to accommodate to a diverse array of topics commonly found in online discussions. 
%This enhances and versatility of the reflective nudges to effectively cater to the varied and dynamic nature of discussions on online deliberation platforms.

\paragraph{\normalfont{\textbf{Generating textual variants for both nudges:} In creating the textual variants for the direct reflective nudge (persona), GPT was tasked with the role of ``\textit{a helpful assistant focusing on supporting users' self-reflection on a given topic}.'' We adhered to scholarly design principles for each reflective nudge, ensuring that the output aligned with the objective of each nudge. Following White et al.~\cite{white2023prompt}, we used a structured prompt template: defining the task, adding constraints, and setting clear expectations. This led us to prompt GPT with, ``\textit{Create ten distinct personas representing different perspectives on the topic. Provide the name, age, and occupation for each persona}.'' Specific constraints were also established: ``\textit{Create three male and three female personas}'' to mitigate gender bias, as prior research has shown that LLMs such as GPT-3 can reinforce gender stereotypes~\cite{brown2020language, lucy2021gender, huang2019reducing, nozza2021honest, johnson2022ghost}.}}

For the textual variants in indirect reflective nudge (storytelling), each persona generated above was then used as input to prompt GPT to create a unique story.

\paragraph{\normalfont{\textbf{Generating image variants for both nudges:}} To generate the image variants, we input GPT's text output into the text-to-image generator, prompting it with, ``\textit{Create a photo-realistic image with realistic textures and lighting of the [persona/story]}.'' For the indirect nudge (storytelling), we prompt the AI to generate individual images representing key moments in the story, which are then combined to create a cohesive visual narrative. A key constraint for images is to exclude any wordings, as AI-generated images often produce distorted or unreadable text~\cite{keyes2023hands}.}

\paragraph{\normalfont{\textbf{Generating video variants for both nudges:}}
For video, similarly, the text output from GPT was input into the text-to-video generator. We prompted it with, ``\textit{Create a photo-realistic video featuring the [persona/story]},'' specifying background details and voice narration. We constrained the model to adhere strictly to the provided script, ensuring that the content remained the same across all modalities.}

\paragraph{\normalfont{\textbf{Generating audio variants for both nudges:}}
For audio, likewise, the text output from GPT was input into the text-to-speech generator. We then manually selected a gender-appropriate voice that matches the gender specified in the text output. Audio prompts were not required for this process as the generator automatically converts the provided text into audio.}

All prompts, along with the rationale behind the constraints and generation tools for each modality, are detailed in Appendix Tables~\ref{tab: prompt engineering} and~\ref{tab: prompt constraint rationale}. The temperature parameter was set at 0.7 to maintain diversity in responses without introducing excessive randomness.