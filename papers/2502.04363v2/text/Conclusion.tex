\section{Conclusion}

% \isu{
% We summarize our results and provide the conclusion in App ?? 
% We summarize and provide the conclusion in App ?? 
We propose On-device Sora, the first training-free solution for generating videos on mobile devices using diffusion-based models. It addresses key challenges in video generation to enable efficient on-device operation. The issue of extensive denoising steps is addressed through Linear Professional Leap, the challenge of handling large tokens is mitigated with Temporal Dimension Token Merging, and memory limitations are overcome through Concurrent Inference with Dynamic Loading. These proposed efficient on-device video generation methodologies are not limited to On-device Sora but are broadly applicable to various applications, providing advancements in on-device video generation without additional model re-training.
% }

%\jjm{
%In this study, we propose On-device Sora, a novel solution for generating videos directly on smartphone-grade devices using diffusion-based models. This approach addresses several critical challenges associated with video generation models to enable efficient on-device operation. The issue of extensive denoising steps is addressed through Linear Professional Leap (LPL), the challenge of handling a large number of tokens is mitigated with Temporal Dimension Token Merging, and memory limitations are overcome through Concurrent Inference with Dynamic Loading. Importantly, the proposed methodologies are not limited to Open-Sora, the base model for On-device Sora, but are broadly applicable to various models, offering significant advancements in on-device video generation without requiring additional training.

%Despite these contributions, this study also has certain limitations. First, while video generation is performed more efficiently with reduced generation time, it remains significantly slower compared to high-end GPUs. Second, this work did not explore methodologies involving additional training, such as model optimization techniques. Lastly, the current approach does not support image-to-video generation, which could provide richer user experiences. Future research will focus on developing faster and lighter models to address these limitations.

%In conclusion, this study represents a significant advancement in AI-based media technology by enabling diffusion-based video generation on smartphone-grade devices. The methodologies presented here are expected to foster innovation in academic and industrial applications, paving the way for the next generation of media technology.
%}