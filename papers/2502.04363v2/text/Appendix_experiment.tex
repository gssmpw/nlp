\section{Appendix - Additional Experiments}
\label{sec:extra_experiment}

\subsection{Video Generation Performance}

{In \Cref{sec:ex_video_generation_performance}, we evaluate the quality of videos generated on an iPhone 15 Pro~\cite{apple2023} and compare them to videos produced by Open-Sora running on NVIDIA A6000 GPUs using VBench~\cite{huang2024vbench} as the evaluation benchmark. \isu{The evaluation is conducted on 68-frame videos at 256×256 resolution, using text prompts provided by VBench~\cite{huang2024vbench}, consisting of 100 examples each across eight categories: animals, architecture, food, humans, lifestyle, plants, scenery, and vehicles. \Cref{tab:appendix-main-experiments} and \Cref{fig:end-to-end-evaluation-2} present the comprehensive comparison of generated videos on all categories.}


\subsection{Concurrent Inference with Dynamic Loading}

% \input{tables/pareto-optimal-model-offloading}
\label{sec:CIDL}
%\note{\parlabel{Concurrent Inference.}}

\Cref{fig:exp_partitioned_stdit}-(b) illustrates the model block loading and inference cycles of STDiT~\cite{opensora} when applying the proposed Concurrent Inference (Sec. \ref{sec:ours3}), whereas \Cref{fig:exp_partitioned_stdit}-(a) depicts the case without its application. It can be observed that, with Concurrent Inference, the GPU executes each model block for inference without almost no idle time in parallel with the model block loading, indicated by the overlap between the red (loading) and black (inference) boxes in \Cref{fig:exp_partitioned_stdit}-(b), resulting in a block inference latency reduction from 29s to 23s. In contrast, without Concurrent Inference, each model block inference is executed only after the corresponding block is fully loaded to memory, indicated by the lack of overlap between the red (loading) and black (inference) boxes in \Cref{fig:exp_partitioned_stdit}-(a). Consequently, the total latency of the full denoising process using multiple executions of STDiT~\cite{opensora} is reduced by approximately 25\%, decreasing from 1,000 to 750 seconds for 30 denoising steps. Given that STDiT is executed multiple times to perform numerous denoising steps, it significantly accelerates the STDiT's overall inference. In addition, when applied with Dynamic Loading (Sec. \ref{sec:ours3}), it achieves an additional average speed improvement of 17 seconds as reloading is not required for certain model blocks that are retained in memory, provided in \Cref{eq:dynamic loading-2}.

\begin{figure} [!htb]
    \centering
    \includegraphics[width=\linewidth]{figures/EXP_Partitioned_STDiT.pdf}
    \caption{The block loading and inference cycles of STDiT \cite{opensora} without (a) and with (b) Concurrent Inference. The red box represents the loading cycle, while the black box indicates the model block inference on the iPhone 15 Pro's GPU.%\jjm{Performance graphs of sequential loading STDiT. The blue lines represent load and prediction, and the green lines represent that GPU is operating each block.}
    }
    \label{fig:exp_partitioned_stdit}
\end{figure}

\begin{figure} [!ht]
    \centering
    \includegraphics[width=\linewidth]{figures/EXP_Partitioned_CI_T5.pdf}
    
    \caption{The block loading and inference cycles of T5~\cite{raffel2020exploring} without (a) and with (b) Concurrent Inference. %The red box represents the loading cycle, while the black box indicates the model block inference on the iPhone 15 Pro's GPU.%\jjm{Performance graphs of sequential loading and Concurrent Inference of T5. The blue lines represent load and prediction, and the green lines represent that GPU is operating each block.}    
    }
    \label{fig:exp_partitioned_ci_t5}
\vspace{-4pt}
\end{figure}

\Cref{fig:exp_partitioned_ci_t5} shows the case of T5~\cite{raffel2020exploring}. Unlike STDiT, which exhibits similar latencies for both block loading and inference execution, T5 exhibits a much longer block loading latency relative to inference latency. Consequently, the overlap between the model loading and inference is minimal, as shown by the small region of overlap between the red (loading) and black (inference) boxes. As a result, the latency improvement is expected to be less substantial, as in \Cref{eq:concurrent_inference}. Nevertheless, the inference latency is reduced from 164 to an average of 137 seconds, achieving a reduction of 16\%. This result implies the effectiveness of concurrent loading and inference, even in cases when there is an imbalance between the latencies of model block loading and inference.

\subsection{Ablation Study of Linear Proportional Leap (LPL) on Other Text-to-Video Models}
% The only constraint for the application of Linear Proportional Leap is the model is flow-matching based model, and it is trained under rectified flow target. Pyramidial Flow~\cite{jin2024pyramidal}, fits for this condition. Therefore We made several experiments on one of the state-of-the-art open-source video generation model, Pyramidial flow.  As a ablation, we show the time required for the similar resolution of video with that CogvideoX~\cite{yang2024cogvideox} model as a reference. Unfortunately, CogVideoX does not utilizes the flow-matching, which does not exhibits the increasing, saturated straightness as the denoising iterations proceed. In contrast, pyramidial flow consistently showed reasonably high straightness during its generation procedure after the initial generation unit, which corresponds to the initial denoising step of other models. As we showed in ~\Cref{tab:LPL_pyramid}, we could successfully reduce nearly quarter of the time as we apply Linear Proportional Leap(LPL) during the generation process, 264.60 -> x, a -> b. Yet, as Pyramidial flow utilizes cascading architectures, the subtle variance that would not be the matter in typical single-model architecture increases more than evicting 1/3 of total steps. We will address this in future works, after making extensive research on compatibility of flow-based models and current Linear Proportional Leap(LPL) algorithm.
\bonote{The primary constraint for applying Linear Proportional Leap (LPL) is that the model must be a flow-matching–based model trained with a rectified flow target~\cite{liu2022flow}. Since} \jjm{Pyramidal} \bonote{Flow~\cite{jin2024pyramidal}, one of the state-of-the-art open-source video generation models, satisfies this condition, we conduct experiments on it.} % For our ablation study, we compared the time required to generate videos at similar resolutions with that of the CogVideoX model~\cite{yang2024cogvideox} as a reference. Unfortunately, CogVideoX does not employ flow matching and, therefore, does not exhibit the increasing, saturated straightness as the denoising iterations progress.

% \begin{figure} [!ht]
% \vspace{-4pt}
%   \centering
%   \begin{minipage}[c]{0.5\columnwidth}
%     \centering    
%     \includegraphics[width=\columnwidth]{figures/cos_sim_first_and_eighth_units_closer.pdf}
%   \end{minipage}%
%   \begin{minipage}[c]{0.48\columnwidth}
%   \caption{Cosine similarities between adjacent drifts estimated by Pyramid Flow~\cite{jin2024pyramidal} at each stage. (a) and (b) show similarities at the first and last units, respectively. Notably, values approach 1.0 at the last unit across all stages, indicating strong alignment between $\boldsymbol{v}(P_{n},t_{n})$ and $\boldsymbol{v}(P_{n-1},t_{n-1})$. Computations follow the experimental settings in~\cite{jin2024pyramidal}, using 20 steps in (a) and 10 in (b).} 
%     \label{fig:cos_siml_pyramid}
%   \end{minipage}
% \end{figure}




\bonote{In a manner similar to Open-Sora with Rectified Flow~\cite{liu2022flow},} \jjm{Pyramidal} \bonote{Flow consistently demonstrates a high degree of straightness in its generation process following the initial generation unit (as illustrated in \Cref{fig:cos_sim_pyramid}). As demonstrated in \Cref{tab:LPL_pyramid}, the application of LPL during generation reduces the overall generation time by nearly 38\%, decreasing from 264.60 seconds to 165.15 seconds. Notably,} \jjm{Pyramidal} \bonote{Flow employs a cascading model procedure in which subtle variances are treated as noise to be subsequently denoised. Since these variances become negligible in the final output, Linear Proportional Leap is particularly well-suited to this architecture. Our experiments involving multiple prompts (as shown in \Cref{fig:lpl_pyramid}) confirmed that removing nearly half of the total denoising steps does not compromise performance while preserving both visual quality and temporal consistency. Furthermore, we observed that additional steps at later units can also be omitted due to the high straightness of} \jjm{Pyramidal} \bonote{Flow. Future work will further investigate this phenomenon by exploring the compatibility of flow-based models with the current LPL algorithm, developing the algorithm to be more compatible to other type of models.}

\begin{table}[!htb]
\setlength{\tabcolsep}{3pt}
\resizebox{\columnwidth}{!}{
\begin{tabular}{c|r|c|c|c}
\hline\hline
\textbf{Models} & \textbf{Time (s)} & \textbf{Resolution} & \textbf{DiT Steps} & \textbf{Speedup} \\ \hline\hline
%CogVideoX1.5-5B & 503.29 & 1360 $\times$ 768 & 50 & X \\ \hline
\jjm{Pyramidal} Flow - 2B & 262.03 & 1280 $\times$ 768 & 270 & 1.00$\times$ \\ \hline
\jjm{Pyramidal} Flow - 2B - LPL (2) & 165.15 & 1280 $\times$ 768 & 159 & 1.59$\times$  \\ \hline
\jjm{Pyramidal} Flow - 2B & 48.88& 640 $\times$ 384 & 270 & 1.00$\times$ \\ \hline
\jjm{Pyramidal} Flow - 2B - LPL (2) & 30.54& 640 $\times$ 384  & 159 &1.60$\times$  \\ \hline
\hline
\end{tabular}
}
\caption{Ablation study conducted on \jjm{Pyramidal} Flow~\cite{jin2024pyramidal} based on the miniFLUX~\cite{flux2024} architecture. `DiT steps' represent the total number of DiT forward computations required for the denoising process. Speedups are measured relative to the corresponding model, with execution time computed as the average of three independent runs. Notably, LPL does not degrade video quality, even when using nearly half of its total steps.}
\label{tab:LPL_pyramid}
\end{table}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{figures/cos_sim_first_and_eighth_units_closer.pdf}
    \caption{Cosine similarities between adjacent drifts estimated by \jjm{Pyramidal} Flow~\cite{jin2024pyramidal} at each stage. (a) and (b) show cosine similarities computed at the first and last units, respectively. The values approach 1.0 at the last unit across all stages. Computations follow the experimental settings in~\cite{jin2024pyramidal}, using 20 denoising steps in (a) and 10 in (b).}
    \vspace{-8pt}
    \label{fig:cos_sim_pyramid}    
\end{figure}


\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/snapshot_movie.pdf}
    \caption*{Prompt: \textit{"A movie trailer featuring the adventures of a 30-year-old spaceman wearing a red wool-knitted motorcycle helmet, blue sky, salt desert, cinematic style, shot on 35mm film, vivid colors."}}
    \includegraphics[width=\linewidth]{figures/snapshot_humanoid.pdf}
    \caption*{Prompt: \textit{"A cybernetic humanoid scans the streets with red eyes as holographic screens flicker around its head, displaying futuristic data."}}
    \includegraphics[width=\linewidth]{figures/snapshot_woman.pdf}
    \caption*{Prompt: \textit{"A green-eyed woman with auburn hair and a mysterious smile, wearing a flowing red dress."}}
\caption{Videos generated using naive \jjm{Pyramidal} Flow~\cite{jin2024pyramidal} (top) and \jjm{Pyramidal} Flow with the proposed Linear Proportional Leap (bottom) under identical prompts. Linear Proportional Leap (LPL) reduces the total number of denoising steps by nearly half \note{(\ie, from 270 to 159)}, while maintaining video generation results that are highly comparable to those achieved using the full set of denoising steps and preserving most details.}
    \label{fig:lpl_pyramid}
\vspace{-8pt}
\end{figure*}