[
  {
    "index": 0,
    "papers": [
      {
        "key": "wu2023human",
        "author": "Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng",
        "title": "Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "huang2023t2i",
        "author": "Huang, Kaiyi and Sun, Kaiyue and Xie, Enze and Li, Zhenguo and Liu, Xihui",
        "title": "T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2024genai",
        "author": "Li, Baiqi and Lin, Zhiqiu and Pathak, Deepak and Li, Jiayao and Fei, Yixin and Wu, Kewen and Ling, Tiffany and Xia, Xide and Zhang, Pengchuan and Neubig, Graham and others",
        "title": "GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "jha2024visage",
        "author": "Jha, Akshita and Prabhakaran, Vinodkumar and Denton, Remi and Laszlo, Sarah and Dave, Shachi and Qadri, Rida and Reddy, Chandan and Dev, Sunipa",
        "title": "ViSAGe: A global-scale analysis of visual stereotypes in text-to-image generation"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "schuhmann2021laion",
        "author": "Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran",
        "title": "Laion-400m: Open dataset of clip-filtered 400 million image-text pairs"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "birhane2021multimodal",
        "author": "Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel",
        "title": "Multimodal datasets: misogyny, pornography, and malignant stereotypes"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liu2021visually",
        "author": "Liu, Fangyu and Bugliarello, Emanuele and Ponti, Edoardo Maria and Reddy, Siva and Collier, Nigel and Elliott, Desmond",
        "title": "Visually Grounded Reasoning across Languages and Cultures"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "jha-etal-2023-seegull",
        "author": "Jha, Akshita  and\nMostafazadeh Davani, Aida  and\nReddy, Chandan K  and\nDave, Shachi  and\nPrabhakaran, Vinodkumar  and\nDev, Sunipa",
        "title": "{S}ee{GULL}: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "myung2024blend",
        "author": "Myung, Junho and Lee, Nayeon and Zhou, Yi and Jin, Jiho and Putri, Rifki Afina and Antypas, Dimosthenis and Borkakoty, Hsuvas and Kim, Eunsu and Perez-Almendros, Carla and Ayele, Abinew Ali and others",
        "title": "BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gaviria2022dollar",
        "author": "Gaviria Rojas, William and Diamos, Sudnya and Kini, Keertan and Kanter, David and Janapa Reddi, Vijay and Coleman, Cody",
        "title": "The Dollar Street dataset: Images representing the geographic and socioeconomic diversity of the world"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "liu2023towards",
        "author": "Liu, Zhixuan and Shin, Youeun and Okogwu, Beverley-Claire and Yun, Youngsik and Coleman, Lia and Schaldenbrand, Peter and Kim, Jihie and Oh, Jean",
        "title": "Towards equitable representation in text-to-image synthesis models with the cross-cultural understanding benchmark (ccub) dataset"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "kannenbeyond",
        "author": "Kannen, Nithish and Ahmad, Arif and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi and others",
        "title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "salimans2016improved",
        "author": "Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi",
        "title": "Improved techniques for training gans"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "heusel2017gans",
        "author": "Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp",
        "title": "Gans trained by a two time-scale update rule converge to a local nash equilibrium"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "chen2023quantifying",
        "author": "Chen, Yunzhuo and Akhtar, Naveed and Haldar, Nur Al Hasan and Mian, Ajmal",
        "title": "On quantifying and improving realism of images generated with diffusion"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "hessel2021clipscore",
        "author": "Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin",
        "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "lin2025evaluating",
        "author": "Lin, Zhiqiu and Pathak, Deepak and Li, Baiqi and Li, Jiayao and Xia, Xide and Neubig, Graham and Zhang, Pengchuan and Ramanan, Deva",
        "title": "Evaluating text-to-visual generation with image-to-text generation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "xu2023imagereward",
        "author": "Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and Tong, Yuxuan and Li, Qinkai and Ding, Ming and Tang, Jie and Dong, Yuxiao",
        "title": "ImageReward: learning and evaluating human preferences for text-to-image generation"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "kannenbeyond",
        "author": "Kannen, Nithish and Ahmad, Arif and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi and others",
        "title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "nguyen2024quality",
        "author": "Nguyen, Quan and Dieng, Adji Bousso",
        "title": "Quality-Weighted Vendi Scores And Their Application To Diverse Experimental Design"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "kannenbeyond",
        "author": "Kannen, Nithish and Ahmad, Arif and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi and others",
        "title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models"
      },
      {
        "key": "nayak2024benchmarking",
        "author": "Nayak, Shravan and Jain, Kanishk and Awal, Rabiul and Reddy, Siva and Steenkiste, Sjoerd and Hendricks, Lisa and Stanczak, Karolina and Agrawal, Aishwarya",
        "title": "Benchmarking Vision Language Models for Cultural Understanding"
      }
    ]
  }
]