\section{Related Works}
\subsection{Cultural-Aware Datasets}
Beginning with the benchmark to evaluate image quality from simpler text prompts using text-to-image (T2I) diffusion models, such as HPDv2  \cite{wu2023human} using human preferences, more recently advanced efforts include creating comprehensive benchmarks such as T2I-CompBench  \cite{huang2023t2i} and GenAI-Bench  \cite{li2024genai}. These prior benchmarks assess the performance of T2I models across various aspects, including realism, fidelity, and compositional text-to-image generation. Although a very recent study \cite{jha2024visage} has started investigating global representation in T2I models, their emphasis has primarily been on regional social stereotypes.

On the other hand, many widely-used datasets for training T2I synthesis models, such as LAION-400M  \cite{schuhmann2021laion}, tend to exhibit Anglo-centric and Euro-centric biases, as noted by  \citet{birhane2021multimodal}. These biases skew the representation of cultures in generated images, often favoring Western perspectives. In response to this, several researchers have worked to create datasets that better represent diverse cultures. For example, the MaRVL dataset  \cite{liu2021visually} was specifically designed to include a broader array of languages and cultural concepts, covering regions such as Indonesia, Swahili-speaking Africa, Tamil-speaking South Asia, Turkey, and Mandarin-speaking China and addressing biases in datasets that predominantly focused on North American and Western European cultures. 

In the Large Language Models (LLMs) domains, SeeGULL dataset  \cite{jha-etal-2023-seegull} broadens stereotype benchmarking to encompass global and regional diversity, and BLEnD benchmark  \cite{myung2024blend} evaluates the cultural knowledge of LLMs across various languages including low-resource ones.
Similarly, the Dollar Street dataset \cite{gaviria2022dollar} sought to capture everyday life across a wide variety of socioeconomic backgrounds, presenting a more globally inclusive view. In addition, \citet{liu2023towards} introduced the CCUB dataset developed to promote cultural inclusivity by collecting images and captions representing the cultural contexts of different countries. Most recently, CUBE \cite{kannenbeyond} is a large-scale dataset of cultural artifacts spanning 8 countries across different geo-cultural regions for evaluating cultural diversity. Our work further contributes to dataset creation by expanding the focus to include low-resource cultures, thereby addressing gaps between overrepresented and underrepresented cultural contexts.

\subsection{Diffusion Model Evaluation}
Several metrics have been developed and widely used to evaluate the quality of images generated by T2I models. These include measures of realism such as the Inception Score (IS) \citep{salimans2016improved}, Fr√©chet Inception Distance (FID) \citep{heusel2017gans}, and Image Realism Score (IRS) \citep{chen2023quantifying}. In particular, IS evaluates image quality and diversity based on classification probabilities, FID quantifies the similarity between generated and real image distributions, and IRS mainly analyzes basic image characteristics to measure the realism of the visual content.
In addition, the alignment between generated images and the corresponding prompts has been evaluated using various metrics, such as CLIPScore \citep{hessel2021clipscore}, VQA Score \citep{lin2025evaluating}, and ImageReward \citep{xu2023imagereward}, which incorporates human feedback to enhance T2I models further. Although \citet{kannenbeyond} has explored cultural diversity in text-to-image model generations using the Vendi Score \citep{nguyen2024quality}, measuring cultural accuracy in generated images has not yet been successfully achieved with existing metrics. As a result, the most reliable approach remains relying on human participants, as demonstrated in several works \citep{kannenbeyond, nayak2024benchmarking}. In our work, we also utilize human annotation; however, due to the time and cost associated with it, there is a pressing need for automatic evaluation. To address this, we present a metric specifically trained on a culture-aware dataset to observe its potential for aligning with human preferences.