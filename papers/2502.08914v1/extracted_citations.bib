@article{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  journal={arXiv preprint arXiv:2110.01963},
  year={2021}
}

@article{chen2023quantifying,
  title={On quantifying and improving realism of images generated with diffusion},
  author={Chen, Yunzhuo and Akhtar, Naveed and Haldar, Nur Al Hasan and Mian, Ajmal},
  journal={arXiv preprint arXiv:2309.14756},
  year={2023}
}

@article{gaviria2022dollar,
  title={The Dollar Street dataset: Images representing the geographic and socioeconomic diversity of the world},
  author={Gaviria Rojas, William and Diamos, Sudnya and Kini, Keertan and Kanter, David and Janapa Reddi, Vijay and Coleman, Cody},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12979--12990},
  year={2022}
}

@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7514--7528},
  year={2021}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{huang2023t2i,
  title={T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation},
  author={Huang, Kaiyi and Sun, Kaiyue and Xie, Enze and Li, Zhenguo and Liu, Xihui},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={78723--78747},
  year={2023}
}

@inproceedings{jha-etal-2023-seegull,
    title = "{S}ee{GULL}: A Stereotype Benchmark with Broad Geo-Cultural Coverage Leveraging Generative Models",
    author = "Jha, Akshita  and
      Mostafazadeh Davani, Aida  and
      Reddy, Chandan K  and
      Dave, Shachi  and
      Prabhakaran, Vinodkumar  and
      Dev, Sunipa",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.548/",
    doi = "10.18653/v1/2023.acl-long.548",
    pages = "9851--9870",
    abstract = "Stereotype benchmark datasets are crucial to detect and mitigate social stereotypes about groups of people in NLP models. However, existing datasets are limited in size and coverage, and are largely restricted to stereotypes prevalent in the Western society. This is especially problematic as language technologies gain hold across the globe. To address this gap, we present SeeGULL, a broad-coverage stereotype dataset, built by utilizing generative capabilities of large language models such as PaLM, and GPT-3, and leveraging a globally diverse rater pool to validate the prevalence of those stereotypes in society. SeeGULL is in English, and contains stereotypes about identity groups spanning 178 countries across 8 different geo-political regions across 6 continents, as well as state-level identities within the US and India. We also include fine-grained offensiveness scores for different stereotypes and demonstrate their global disparities. Furthermore, we include comparative annotations about the same groups by annotators living in the region vs. those that are based in North America, and demonstrate that within-region stereotypes about groups differ from those prevalent in North America."
}

@inproceedings{jha2024visage,
  title={ViSAGe: A global-scale analysis of visual stereotypes in text-to-image generation},
  author={Jha, Akshita and Prabhakaran, Vinodkumar and Denton, Remi and Laszlo, Sarah and Dave, Shachi and Qadri, Rida and Reddy, Chandan and Dev, Sunipa},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12333--12347},
  year={2024}
}

@inproceedings{kannenbeyond,
  title={Beyond Aesthetics: Cultural Competence in Text-to-Image Models},
  author={Kannen, Nithish and Ahmad, Arif and Prabhakaran, Vinodkumar and Prabhu, Utsav and Dieng, Adji Bousso and Bhattacharyya, Pushpak and Dave, Shachi and others},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year      = {2024},
}

@article{li2024genai,
  title={GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation},
  author={Li, Baiqi and Lin, Zhiqiu and Pathak, Deepak and Li, Jiayao and Fei, Yixin and Wu, Kewen and Ling, Tiffany and Xia, Xide and Zhang, Pengchuan and Neubig, Graham and others},
  journal={arXiv preprint arXiv:2406.13743},
  year={2024}
}

@inproceedings{lin2025evaluating,
  title={Evaluating text-to-visual generation with image-to-text generation},
  author={Lin, Zhiqiu and Pathak, Deepak and Li, Baiqi and Li, Jiayao and Xia, Xide and Neubig, Graham and Zhang, Pengchuan and Ramanan, Deva},
  booktitle={European Conference on Computer Vision},
  pages={366--384},
  year={2025},
  organization={Springer}
}

@inproceedings{liu2021visually,
  title={Visually Grounded Reasoning across Languages and Cultures},
  author={Liu, Fangyu and Bugliarello, Emanuele and Ponti, Edoardo Maria and Reddy, Siva and Collier, Nigel and Elliott, Desmond},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={10467--10485},
  year={2021}
}

@article{liu2023towards,
  title={Towards equitable representation in text-to-image synthesis models with the cross-cultural understanding benchmark (ccub) dataset},
  author={Liu, Zhixuan and Shin, Youeun and Okogwu, Beverley-Claire and Yun, Youngsik and Coleman, Lia and Schaldenbrand, Peter and Kim, Jihie and Oh, Jean},
  journal={arXiv preprint arXiv:2301.12073},
  year={2023}
}

@article{myung2024blend,
  title={BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages},
  author={Myung, Junho and Lee, Nayeon and Zhou, Yi and Jin, Jiho and Putri, Rifki Afina and Antypas, Dimosthenis and Borkakoty, Hsuvas and Kim, Eunsu and Perez-Almendros, Carla and Ayele, Abinew Ali and others},
  journal={arXiv preprint arXiv:2406.09948},
  year={2024}
}

@inproceedings{nayak2024benchmarking,
  title={Benchmarking Vision Language Models for Cultural Understanding},
  author={Nayak, Shravan and Jain, Kanishk and Awal, Rabiul and Reddy, Siva and Steenkiste, Sjoerd and Hendricks, Lisa and Stanczak, Karolina and Agrawal, Aishwarya},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={5769--5790},
  year={2024}
}

@article{nguyen2024quality,
  title={Quality-Weighted Vendi Scores And Their Application To Diverse Experimental Design},
  author={Nguyen, Quan and Dieng, Adji Bousso},
  journal={arXiv preprint arXiv:2405.02449},
  year={2024}
}

@article{salimans2016improved,
  title={Improved techniques for training gans},
  author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv preprint arXiv:2111.02114},
  year={2021}
}

@article{wu2023human,
  title={Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis},
  author={Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2306.09341},
  year={2023}
}

@inproceedings{xu2023imagereward,
  title={ImageReward: learning and evaluating human preferences for text-to-image generation},
  author={Xu, Jiazheng and Liu, Xiao and Wu, Yuchen and Tong, Yuxuan and Li, Qinkai and Ding, Ming and Tang, Jie and Dong, Yuxiao},
  booktitle={Proceedings of the 37th International Conference on Neural Information Processing Systems},
  pages={15903--15935},
  year={2023}
}

