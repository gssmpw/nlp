%!TEX root = ../main.tex
\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}

\begin{table*}[t!]
\centering
\vspace{-1em}
\caption{Execution Accuracy on BIRD Development Dataset.}
\label{tab:acc-bird-dev}
\resizebox{\textwidth}{!}{%
\begin{tabular}{cccccccc}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Selection\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Zero-shot \\ Setting\end{tabular}}} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} \\ \cline{5-8} 
 &  &  &  & \textbf{Simple} & \textbf{Moderate} & \textbf{Challenging} & \textbf{All} \\ \hline
SFT CodeS~\cite{codes} & CodeS-7B & - & \markcross & 64.6 & 46.9 & 40.3 & 57.0 \\
SFT CodeS~\cite{codes} & CodeS-15B & - & \markcross & 65.8 & 48.8 & 42.4 & 58.5 \\
Distillery~\cite{Distillery} & GPT-4o & - & \markcross & - & - & - & 67.2 \\
CHESS-SQL~\cite{chesssql} & Deepseek-Coder-33B & GPT-4-Turbo & \markcross & - & - & - & 65.0 \\
CHESS-SQL~\cite{chesssql} & Deepseek-Coder-33B & LLaMA3-70B & \markcross & - & - & - & 61.5 \\
CHASE-SQL~\cite{CHASE} & Gemini-1.5-Pro & Gemini-1.5-Flash & \markcross & - & - & - & 73.0 \\
XiYan-SQL~\cite{XiYan} & ? & ? & \markcross & - & - & - & 73.3 \\
XiYan-SQL~\cite{XiYan} & Qwen2.5-Coder-32B & Qwen2.5-Coder-32B & \markcross & - & - & - & 67.0 \\ \hline
DAIL-SQL~\cite{dailsql} & GPT-4 & SC Selection & \markcheck & 63.0 & 45.6 & 43.1 & 55.9 \\
SuperSQL~\cite{supersql} & GPT-4 & SC Selection & \markcheck & 66.9 & 46.5 & 43.8 & 58.5 \\
MCS-SQL~\cite{MCS-SQL} & GPT-4 & GPT-4 & \markcheck & - & - & - & 64.4 \\
RSL-SQL~\cite{rslsql} & GPT-4o & GPT-4o & \markcheck & 74.4 & 57.1 & 53.8 & 67.2 \\ \hline
\textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{SC Selection} & \markcheck & \textbf{72.6} & \textbf{59.3} & \textbf{53.1} & \textbf{66.8} \\ 
% \textbf{AlphaSQL (Ours)} & Qwen2.5-Coder-7B & Tournament Selection & \markcheck  &  &  &  &  \\ \hline
\textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{SC Selection} & \markcheck & \textbf{74.6} & \textbf{61.0} & \textbf{55.9} & \textbf{68.7} \\
% \textbf{AlphaSQL (Ours)} & Qwen2.5-Coder-14B & Tournament Selection & \markcheck &  &  &  &  \\ \hline
\textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{SC Selection} & \markcheck & \textbf{74.5} & \textbf{64.0} & \textbf{57.2} & \textbf{69.7} \\ \hline
% \textbf{AlphaSQL (Ours)} & Qwen2.5-Coder-32B & Tournament Selection & \markcheck &  &  &  &  \\ \hline
\end{tabular}%
}
\end{table*}

\begin{table*}[t!]
\centering
\vspace{-1em}
\caption{Execution Accuracy on Spider Development Dataset.}
\label{tab:acc-spider-dev}
\resizebox{\textwidth}{!}{%
\begin{tabular}{ccccccccc}
\hline
\multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Selection\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Zero-shot\\ Setting\end{tabular}}} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} \\ \cline{5-9} 
 &  &  &  & \textbf{Easy} & \textbf{Medium} & \textbf{Hard} & \textbf{Extra Hard} & \textbf{All} \\ \hline
SFT CodeS~\cite{codes} & CodeS-7B & - & \markcross & 94.8 & 91.0 & 75.3 & 66.9 & 85.4 \\
SFT CodeS~\cite{codes} & CodeS-15B & - & \markcross & 95.6 & 90.4 & 78.2 & 61.4 & 84.9 \\ \hline
C3-SQL~\cite{c3} & GPT-3.5-Turbo & SC Selection & \markcheck &  92.7 & 85.2 & 77.6 & 62.0 & 82.0 \\
DIN-SQL~\cite{dinsql} & GPT-4 & - & \markcheck &  92.3 & 87.4 & 76.4 & 62.7 & 82.8 \\
DAIL-SQL~\cite{dailsql} & GPT-4 & SC Selection & \markcheck &  91.5 & 90.1 & 75.3 & 62.7 & 83.6 \\
ZeroNL2SQL~\cite{zeronl2sql} & GPT-4 & - & \markcheck & - & - & - & - & 84.0 \\
MAC-SQL~\cite{macsql} & GPT-4 & - & \markcheck & - & - & - & - & 86.8 \\
SuperSQL~\cite{supersql} & GPT-4 & SC Selection & \markcheck & 94.4 & 91.3 & 83.3 & 68.7 & 87.0 \\ \hline
% MCS-SQL~\cite{MCS-SQL} & GPT-4 & GPT-4 & \markcheck & - & - & - & - & 89.5 \\ \hline
\textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{SC Selection} & \markcheck & \textbf{94.0} & \textbf{89.2} & \textbf{76.4} & \textbf{63.3} & \textbf{84.0} \\
% \textbf{AlphaSQL (Ours)} & Qwen2.5-Coder-7B & Tournament Selection & \markcheck & - & - & - & - & - \\ \hline
\textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{SC Selection} & \markcheck & \textbf{94.0} & \textbf{91.0} & \textbf{79.9} & \textbf{72.3} & \textbf{87.0} \\ \hline
% \textbf{AlphaSQL (Ours)} & Qwen2.5-Coder-14B & Tournament Selection & \markcheck & - & - & - & - & - \\ \hline
\end{tabular}%
}
\vspace{-1em}
\end{table*}

\textbf{Datasets.}
We utilize the \textbf{Spider}~\cite{spider} and  \textbf{BIRD}~\cite{bird} development sets for evaluation.
Spider contains 1034 (NL, SQL) pairs, and BIRD includes 1534 pairs, with BIRD queries being more complex and containing domain-specific keywords like \texttt{CASE} and \texttt{IIF}.

To reduce the experimental costs and facilitate additional comparison experiments (Sections~\ref{subsec:exp-scale} to~\ref{subsec:exp-action-space}), we follow CHESS-SQL~\cite{chesssql} and utilize the Subsampled Development Set (\textbf{SDS}), which includes 10\% of the BIRD development set. The SDS contains 147 samples -- 81 simple, 54 moderate, and 12 challenging queries.



% respectively. The SQL queries in BIRD exhibit greater structural complexity and incorporate keywords absent from Spider, such as \texttt{CASE} and \texttt{IIF}, which pose additional challenges for the model's natural language to SQL translation capabilities. Furthermore, the domain-specific knowledge in BIRD introduces challenges in the model's ability to comprehend and apply relevant domain knowledge. 
% To facilitate more comparison experiments while reducing computational costs (Sections~\ref{subsec:exp-scale} to~\ref{subsec:exp-action-space}), we follow CHESS-SQL~\cite{chesssql} and utilize the same Subsampled Development Set (SDS), which comprises 10\% of each database from the BIRD development set. The SDS contains 147 samples, consisting of 81 simple, 54 moderate, and 12 challenging questions.

% \textbf{Models.}
% % 在Spider和BIRD的开发集上的对比实验中（Sec5.2）我们使用Qwen2.5-Coder-7B/14B/32B三个open source model作为Alpha-SQL的inference model。我们设定MCTS的Rollout次数$N_rollout = 24$，每一个动作

% \textbf{Baselines.}


\textbf{Metrics.}
% EX, R-VES? Since we can filter the most efficient SQL query from multiple identical SQLs.
% Following previous work, we use Execution Accuracy (EX) as our evaluation metric, \rev{which is defined as the ratio of queries where the execution results of the predicted SQL queries exactly match those of the ground-truth SQL queries. }
Following prior work~\cite{CHASE}, we use Execution Accuracy (EX) as the metric, defined as the percentage of predicted SQL queries that generate execution results identical to those of the ground-truth queries.


\textbf{Hardware.}
All experiments are run on an Ubuntu 22.04.3 LTS server with 512GB of RAM and dual 40-core Intel(R) Xeon(R) Platinum 8383C CPUs (@ 2.70GHz). Open-source LLMs are deployed locally using 8 GPUs, each with 80GB of memory and 312 TFLOPS with BF16 precision.


\subsection{Main Results on BIRD and Spider Datasets}
\label{subsec:exp-main}
% \vspace{-0.5em}


% 在Spider和BIRD的开发集上的对比实验中（Sec5.2）我们使用Qwen2.5-Coder-7B/14B/32B三个open source model作为Alpha-SQL的inference model。
% 我们设定MCTS的Rollout次数$N_{rollout} = 24$。在扩展子节点时每一个动作执行结果的重复采样次数$N_{expansion} = 3$，采样温度$T_{expansion} = 0.8$。计算Self-supervised reward过程中，我们设定重复采样SQL次数$N_{reward} = 5$，采样温度$T_{reward} = 1.0$。SQL Revision动作中（$A_7$)，我们设定多轮修正的最大次数为$N_{revision} = 3$。

\textbf{Settings.} We employed three open-source models from the Qwen2.5-Coder family - 7B, 14B, and 32B~\cite{qwen2.5} - as inference models for \sys. 
The related hyper-parameters were set as follows: For offline database value retrieval, we set the editing similarity $\epsilon_\text{edit}$ as 0.3 and semantic similarity $\epsilon_\text{semantic}$ as 0.6. For the MCTS rollout process, we set the number of rollouts to $N_{rollout} = 24$. During node expansion, each action was sampled $N_{expansion} = 3$ times with a sampling temperature of $T_{expansion} = 0.8$. In the computation of self-supervised rewards, we set the SQL sampling parameters with $N_{reward} = 5$ repetitions and a temperature of $T_{reward} = 1.0$. For the SQL Revision action ($A_6$), we set a maximum iteration limit of $N_{revision} = 10$ for the multi-round correction process.

% 在Table~\ref{???}中，我们对比了Alpha-SQL与当前主流方法的性能，并将方法根据是否符合Zero-shot场景进行分类。Alpha-SQL基于参数量较小的Qwen2.5-Coder-7B便实现了66.5%的平均准确率，与基于闭源GPT-4o的RSL-SQL方法性能相近，同时也超过了大部分需要数据微调（非Zero-shot场景）的方法。当我们将模型参数量扩大到32B后，我们的Alpha-SQL实现了Zero-shot场景下的最优性能。即使在非Zero-shot场景的方法中，也仅仅次于需要数据微调较强的闭源模型Gemini-1.5-Flash的CHASE-SQL。这都说明了Alpha-SQL作为即插即用的框架，无需数据微调便可实现竞争性的性能。

\textbf{Performance on BIRD Dataset.}
As shown in Table~\ref{tab:acc-bird-dev}, we conducted a comprehensive comparison between Alpha-SQL and current state-of-the-art approaches, categorizing methods based on their zero-shot capabilities. Alpha-SQL, leveraging the relatively lightweight Qwen2.5-Coder-7B model, achieved 66.8\% average accuracy, comparable to the performance of RSL-SQL~\cite{rslsql}, which relies on the proprietary GPT-4o. Notably, this performance surpasses many methods that require data fine-tuning. Upon scaling our inference model to 32B parameters, Alpha-SQL demonstrated superior performance in the zero-shot scenario, with 69.7\% average accuracy. Even when compared to methods with domain data fine-tuning, Alpha-SQL's performance is exceeded only by CHASE-SQL~\cite{CHASE}, which requires fine-tuning the proprietary Gemini-1.5-Flash model, and XiYan-SQL~\cite{XiYan}, which fine-tunes an unknown model. These results confirm Alpha-SQL's effectiveness as a plug-and-play framework that delivers competitive performance without fine-tuning.

\textbf{Performance on Spider Dataset.} We also evaluate Alpha-SQL on the Spider development dataset. As shown in Table~\ref{tab:acc-spider-dev}, Alpha-SQL with Qwen2.5-Coder-14B outperforms existing methods. Notably, it achieves a 2.1\% improvement over SFT Coder-15B, which was specifically fine-tuned for the Spider dataset, demonstrating Alpha-SQL's ability to perform well without fine-tuning on \nlsql datasets.
% This demonstrates Alpha-SQL's capability to achieve strong generalization performance without dataset-specific fine-tuning.


% Further, in Figure~\ref{fig:paretro}, we show the distribution of accuracy versus model parameter size. In comparison to existing Text-to-SQL methods, Alpha-SQL allows weaker models to outperform strong models on the optimal Pareto front of cost-effectiveness. This demonstrates our framework's capacity to improve cost-effectiveness across different model scales.

\begin{figure}[t!]
    \centering
\includegraphics[width=\linewidth]{figures/alpha-pareto.pdf}
\vspace{-2.5em}
    \caption{{Performance vs. Model Size on the BIRD dev. For GPT-4, GPT-4o, and Gemini-1.5-pro, we referenced the parameter descriptions from~\cite{asma2024parameters} for plotting.}}
    \label{fig:paretro}
\vspace{-1.5em}
\end{figure}


\textbf{Performance-Scale Trade-off Analysis.} To explore the performance potential of smaller open-source LLMs, we conducted this experiment to demonstrate that Alpha-SQL can unlock the full potential of smaller models while maintaining cost efficiency.
Figure~\ref{fig:paretro} shows that Alpha-SQL significantly outperforms larger models on the Pareto frontier, enabling smaller models, such as the 7B and 14B versions, to achieve accuracy comparable to or surpassing much larger models, including GPT-4o-based approaches. This demonstrates our framework’s ability to optimize \nlsql performance across varying model scales.
% Figure~\ref{fig:paretro} illustrates the relationship between model size and accuracy. Alpha-SQL enables small open-source LLMs to exceed the performance of larger LLMs on the Pareto frontier of cost-effectiveness, demonstrating our framework's ability to optimize performance across different model scales.



\begin{figure}[t!]
    \centering
    \vspace{-0.5em}
\includegraphics[width=.9\columnwidth]{figures/accuracy-vs-rollouts.pdf}
    \vspace{-1.5em}
    \caption{Accuracy vs. MCTS Rollouts.}
    \label{fig:scaling}
\end{figure}

\subsection{Impact of MCTS Rollouts on Performance}
\label{subsec:exp-scale}

The efficiency of MCTS in exploring large search spaces is a key feature of Alpha-SQL. Based on Table~\ref{tab:action-space}, we calculated that there are over 3000 possible reasoning paths for each text-to-SQL task. Remarkably, Alpha-SQL achieves significant performance improvements with just 24 MCTS rollouts, suggesting that our \sys can efficiently explore significantly larger search spaces.

% 在这一节中，我们验证Alpha-SQL的性能与MCTS Rollouts次数之间的关系，以进一步说明使用MCTS进行多次探索的作用。
To further investigate this efficiency and understand how the number of MCTS rollouts affects performance, we conducted an in-depth analysis.
% 我们使用Qwen2.5-Coder-7B/14B模型，在SDS上进行实验，除了rollout次数（$N_{rollout}$）外，其他参数与BIRD实验相(Section~\ref{})相同。我们report Upper Bound Accuracy以及经过SQL Selection后的最终Accuracy，结果如图~\ref{}所示。
We conducted experiments on the SDS dataset using the Qwen2.5-Coder-7B model, maintaining all hyper-parameters identical to Section~\ref{subsec:exp-main} except for the number of rollouts ($N_{rollout}$). 
% We report both the Upper Bound Accuracy and the final Accuracy after SQL Selection, with results illustrated in Figure~\ref{fig:scaling}. 
We report both the upper bound accuracy and final accuracy. Similar to CHASE-SQL~\cite{CHASE}, the upper bound accuracy represents the percentage of samples where the candidate SQL set contains the correct SQL query before the final SQL selection.
% 我们观察到随着MCTS rollouts次数的提高，Upper Bound准确率和最终准确率都在上升。这说明Alpha-SQL可以在不改变模型参数的情况下，仅仅通过增加推理阶段的计算量提高Text-to-SQL任务性能的有效性。
We observe a positive correlation between the number of MCTS rollouts and both upper bound and final accuracy metrics. This demonstrates Alpha-SQL's capability to enhance Text-to-SQL task performance through more MCTS explorations.

\subsection{Comparison with Baseline LLMs}
\label{subsec:exp-baseline-llm}

% \begin{table}[t!]
% \centering
% \caption{Comparison with Baseline LLMs on the SDS.}
% \label{tab:baseline-llm}
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{ccc}
% \hline
% Method & Model & Accuracy (\%) \\ \hline
% Baseline & Deepseek-V3 & 51.2 \\
% Baseline & GPT-4o & 53.7 \\
% Baseline & Gemini-1.5-Pro & 56.2 \\ \hline
% % Baseline & Qwen2.5-Coder-7B & 47.6 \\
% % Baseline & Qwen2.5-Coder-14B & 52.4 \\
% % Baseline & Qwen2.5-Coder-32B & 55.1 \\ \hline
% Baseline & QwQ-32B-Preview & 38.8 \\  
% Baseline & DeepSeek-R1 & 50.3 \\
% Baseline & Gemini-2.0-Flash-Thinking-Exp & 60.8 \\ \hline
% Baseline & Qwen2.5-Coder-7B & 47.6 \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{64.6 ($\uparrow$ 17.0)} \\ \hline
% Baseline & Phi-4 & 43.5 \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Phi-4} & \textbf{60.0 ($\uparrow$ 16.5)} \\ \hline
% % \textbf{Alpha-SQL (Ours)} & Qwen2.5-Coder-14B & 64.0 \\
% % \textbf{Alpha-SQL (Ours)} & Qwen2.5-Coder-32B & 63.3 \\ \hline
% \end{tabular}
% }
% \end{table}

\begin{table}[t!]
\centering
\vspace{-1em}
\caption{Comparison with Baseline LLMs on the SDS dataset.}
\label{tab:baseline-llm}
\resizebox{0.8\columnwidth}{!}{%
\begin{tabular}{cc}
\hline
Model & Accuracy (\%) \\ \hline
Deepseek-V3 & 51.2 \\
GPT-4o & 53.7 \\
Gemini-1.5-Pro & 56.2 \\ \hline
QwQ-32B-Preview & 38.8 \\  
DeepSeek-R1 & 50.3 \\
Gemini-2.0-Flash-Thinking-Exp & 60.8 \\ \hline
Qwen2.5-Coder-7B & 47.6 \\
\textbf{+ Alpha-SQL (Ours)}  & \textbf{64.6 ($\uparrow$ 17.0)} \\ \hline
Phi-4 & 43.5 \\
\textbf{+ Alpha-SQL (Ours)} & \textbf{60.0 ($\uparrow$ 16.5)} \\ \hline
\end{tabular}
}
\end{table}

% 1. Qwen Base LLMs
% 2. Reasoning Models: QwQ, DeepSeek-R1
% BIRD MiniDev, Table~\ref{tab:baseline-llm}

% Finding: Reasoning LMs is not suitable for Text-to-SQL application directly. And, a good reasoning framework is better than reasoning model.

% 这一节中，我们在SDS上评测了LLMs的baseline性能，并进一步划分为general的LLMs（如GPT-4o）和Reasoning LLMs（如DeepSeek-R1），结果如Table~\ref{}所示。
In this section, we evaluate the baseline performance of LLMs on the SDS dataset, categorizing them into general LLMs (such as GPT-4o) and reasoning LLMs (such as DeepSeek-R1) and using the same Text-to-SQL prompt (Appendix~\ref{sub:baseline-llm-prompt}). 
%with results presented in Table~\ref{tab:baseline-llm}. 
% 我们的Alpha-SQL使用仅7B参数量的模型，超过了所有基座模型。值得注意的是，Alpha-SQL使用较弱的模型超过了Gemini-2.0-Flash-Thinking-Exp，which is一个很强的推理优化模型，说明Text-to-SQL任务需要针对性的推理优化，这正是Alpha-SQL的目标之一。
As shown in Table~\ref{tab:baseline-llm},
our Alpha-SQL, utilizing a model with only 7B parameters, surpasses all baseline models in performance. Notably, Alpha-SQL outperforms Gemini-2.0-Flash-Thinking-Exp, a sophisticated reasoning-optimized model, despite using a weaker model. This shows that the Text-to-SQL task requires targeted reasoning optimization, which is a strength of the Alpha-SQL framework.
% 此外，为了验证Alpha-SQL即插即用的优点，除了Qwen2.5-Coder，我们还使用Phi-4模型作为推理模型进行实验。与直接应用Qwen2.5-Coder和Phi-4相比，Alpha-SQL分别成功提高了17.0%和16.5的准确率，进一步说明了Alpha-SQL对不同推理模型的泛化性和有效性。
Moreover, to validate Alpha-SQL's plug-and-play advantages, we conducted additional experiments using Phi-4~\cite{phi-4} and Qwen2.5-Coder-7B as inference models. Compared to directly prompting these LLMs, Alpha-SQL achieved significant accuracy improvements of 17.0\% and 16.5\% for Qwen2.5-Coder-7B and Phi-4, respectively. These results validate Alpha-SQL's generalizability and effectiveness across different inference models.


% TODO :
% 讨论一下为什么R1/QwQ这么差
% 美化一下table{tab:baseline-llm}，Qwen和alphasql放一块，突出增益；分成LLM和RLM
% 加一个其他开源模型，不然怕被问全用qwen


% \subsection{Comparison with Selection Methods}
% \label{subsec:exp-selection}

% SC Selection~\cite{dailsql, supersql}, SC + Binary Selection~\cite{CHASE},  Our Tournament Selection

% Upper Bound Comparison: CHASE-SQL~\cite{CHASE}, Our \sys.

% Report 1 of N in \sys. Finding: more powerful model will lead to more deterministic candidate SQLs.



\begin{table}[t!]
\centering
\vspace{-1em}
\caption{Ablation Study on Action Space.}
\label{tab:ablation-action}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{cc}
\hline
Action Space & Accuracy (\%) \\ \hline
$A_1, A_2, A_3, A_4, A_5, A_6, A_7$ & 64.6 \\
w/o $A_1$ (Question Rephrasing) & 63.9 ($\downarrow$ 0.7) \\
w/o $A_2$ (Schema Selection) & 63.1 ($\downarrow$ 1.5) \\
w/o $A_3$ (Column Value Identification) & 64.2 ($\downarrow$ 0.4) \\
w/o $A_4$ (Column Function Identification) & 64.0 ($\downarrow 0.6$) \\
w/o $A_6$ (SQL Revision) & 62.8 ($\downarrow 1.8$) \\ \hline
\end{tabular}%
}
\vspace{-.5em}
\end{table}

% 在这一节中，我们对Sec4.1中定义的Action Space在SDS上进行消融实验，以验证每一个Action的有效性。我们使用与Section 5.2相同的参数设置，除了Action空间。结果如Table所示，相对于原本的Action空间，去掉其中相应的Action都对性能产生了负面影响。尤其是SQL Revision，which 通过与外部数据库进行交互，将数据库反馈信息输入LLM以对SQL进行修正，说明了Text-to-SQL任务中使用外部数据库增强推理的重要性。
\subsection{Ablation Study of Action Space}
\label{subsec:exp-action-space}
The purpose of this ablation study is to validate the effectiveness of our proposed Text-to-SQL reasoning action space and the LLM-as-Action-Model approach.
To achieve this, we conducted experiments on the SDS dataset, systematically removing individual actions from the original action space while maintaining the parameter settings from Section~\ref{subsec:exp-main}. Table~\ref{tab:ablation-action} presents the results of these experiments.

Table~\ref{tab:ablation-action} shows that removing any action from the original action space negatively impacts performance. The SQL Revision action demonstrates particular significance, as it leverages database interaction to incorporate feedback into the LLM for SQL correction, highlighting the importance of database execution feedback for Text-to-SQL tasks.

% In this section, we conduct ablation studies on the action space defined in Section~\ref{sub:llmaction} using the SDS dataset to validate the effectiveness of each action. We maintain the parameter settings from Section~\ref{subsec:exp-main}, varying only the action space. As shown in Table~\ref{tab:ablation-action}, removing any action from the original action space negatively impacts performance. The SQL Revision action demonstrates particular significance, as it leverages database interaction to incorporate feedback into the LLM for SQL correction, highlighting the importance of database feedback in Text-to-SQL tasks.
% \rev{These results validate the effectiveness of our defined Text-to-SQL reasoning action space and the proposed LLM-as-Action-Model.}



% \boyan{
% Update tables data.
% Table ~\ref{tab:acc-bird-minidev}, ~\ref{tab:path-selection}
% }

% Report correct possibility in UB for each Model
% Plot a figure for scaling exploaration N vs. UB/Acc, among different models


%%%%%%%%%% Draft %%%%%%%%%%
% Main Exp: Comparison with baselines
% 1. Different models (Qwen / Llama / ...) -> Generalizabilty / Effectiveness
% 2. Different datasets (BIRD / Spider) -> Generalizabilty / Effectiveness
% 3. (Token Cost / Time cost)?
%    High token cost is our limitation, but it could be solved in our future work (in Discussion section)?
%    Synthesize data with reasoning steps -> Train PRM model -> Do not need searching process anymore
% 4. Figures -> Performance vs. Token cost (i.e. Testing-time scale law)
%    a. different simulation steps in MCTS
%    b. different max width of MCTS (i.e. the size of reasoning space)
%
% Ablation Study:
% 1. Path Selection -> Importance of SQL Selection
%%%%%%%%%%%%%%%%%%%%%%%%%%%




































% \begin{table*}[t!]
% \centering
% \caption{Accuracy on BIRD-MiniDev.}
% \label{tab:acc-bird-minidev}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{@{}cccccccc@{}}
% \toprule
% \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{Params}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Fine-Tuning-\\ Free\end{tabular}}} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} \\ \cmidrule(l){5-8} 
%  &  &  &  & \textbf{Simple} & \textbf{Moderate} & \textbf{Challenging} & \textbf{All} \\ \midrule
% SFT CodeS~\cite{codes} & CodeS & $\sim$7B & \markcross & 58.44 & 41.30 & 41.67 & 51.11 \\
% SFT CodeS~\cite{codes} & CodeS & $\sim$15B & \markcross & 57.14 & 50.00 & 41.67 & 53.33 \\ \midrule
% DAIL-SQL~\cite{dailsql} & GPT-4 & Unknown & \markcheck & 67.53 & 34.78 & 41.67 & 54.07 \\
% SuperSQL~\cite{supersql} & GPT-4 & Unknown & \markcheck & 66.23 & 41.30 & 41.67 & 55.56 \\
% CHESS-SQL~\cite{chesssql} & GPT-4o & Unknown & \markcheck & 66.23 & 71.43 & 52.17 & 50.00 \\
% RSL-SQL~\cite{rslsql} & GPT-4o & Unknown & \markcheck & 71.43 & 52.17 & 50.00 & 62.96 \\ \midrule
% \textbf{\textbf{\sys-UB} (Ours)} & \textbf{Qwen2.5-Coder} & \textbf{$\sim$7B} & \markcheck & \textbf{87.01} & \textbf{69.57} & \textbf{58.33} & \textbf{78.52} \\
% \textbf{\textbf{\sys} (Ours)} & \textbf{Qwen2.5-Coder} & \textbf{$\sim$7B} & \markcheck & \textbf{72.73} & \textbf{52.17} & \textbf{41.67} & \textbf{62.96} \\ \midrule
% \textbf{\textbf{\sys-UB} (Ours)} & \textbf{Deepseek} & \textbf{$\sim$671B} & \markcheck & \textbf{87.01} & \textbf{69.57} & \textbf{58.33} & \textbf{78.52} \\
% \end{tabular}%
% }
% \end{table*}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
% \begin{table*}[t!]
% \centering
% \caption{Accuracy on BIRD-MiniDev (147 Samples).}
% \label{tab:acc-bird-minidev}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccccc}
% \hline
% \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Selection\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Fine-Tuning-\\ Free\end{tabular}}} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} \\ \cline{5-8} 
%  &  &  &  & \textbf{Simple} & \textbf{Moderate} & \textbf{Challenging} & \textbf{All} \\ \hline
% SFT CodeS~\cite{codes} & CodeS-7B & - & \markcross & 59.26 & 38.78 & 41.67 & 50.70 \\
% SFT CodeS~\cite{codes} & CodeS-15B & - & \markcross & 58.02 & 44.90 & 50.00 & 52.82 \\ \hline
% DAIL-SQL~\cite{dailsql} & GPT-4 & - & \markcheck & 65.43 & 34.69 & 41.67 & 52.82 \\
% SuperSQL~\cite{supersql} & GPT-4 & - & \markcheck & 64.20 & 36.73 & 41.67 & 52.82 \\
% CHESS-SQL~\cite{chesssql} & GPT-4o & GPT-4o & \markcheck & 64.20 & 57.14 & 50.00 & 60.56 \\
% RSL-SQL~\cite{rslsql} & GPT-4o & GPT-4o & \markcheck & 71.60 & 53.06 & 50.00 & 63.38 \\ \hline
% % \textbf{AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{-} & \markcheck & \textbf{87.01} & \textbf{69.57} & \textbf{58.33} & \textbf{78.52} \\
% % \textbf{AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Self-consistency} & \markcheck & \textbf{72.73} & \textbf{52.17} & \textbf{41.67} & \textbf{60.96} \\ \hline
% % \textbf{AlphaSQL-UB (Ours)} & \textbf{Deepseek-V3} & \textbf{-} & \markcheck & \textbf{83.95} & \textbf{75.51} & \textbf{58.33} & \textbf{78.87} \\
% % \textbf{AlphaSQL (Ours)} & \textbf{Deepseek-V3} & \textbf{Self-consistency} & \markcheck & \textbf{67.90} & \textbf{59.18} & \textbf{41.67} & \textbf{62.68} \\ \hline
% \textbf{*AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{-} & \markcheck & \textbf{90.12} & \textbf{77.78} & \textbf{66.67} & \textbf{83.67} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Self-consistency} & \markcheck & \textbf{72.84} & \textbf{55.56} & \textbf{50.00} & \textbf{64.63} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \textbf{*AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{-} & \markcheck & \textbf{86.42} & \textbf{81.48} & \textbf{75.00} & \textbf{83.67} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{Self-consistency} & \markcheck & \textbf{70.37} & \textbf{62.96} & \textbf{41.67} & \textbf{65.31} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \textbf{*AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{-} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{Self-consistency} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{*AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \end{tabular}%
% }
% \end{table*}

% \begin{table*}[t!]
% \centering
% \caption{Accuracy on BIRD-Dev.}
% \label{tab:acc-bird-dev}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccccc}
% \hline
% \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Selection\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Fine-Tuning-\\ Free\end{tabular}}} & \multicolumn{4}{c}{\textbf{Accuracy (\%)}} \\ \cline{5-8} 
%  &  &  &  & \textbf{Simple} & \textbf{Moderate} & \textbf{Challenging} & \textbf{All} \\ \hline
% SFT CodeS~\cite{codes} & CodeS-7B & - & \markcross & - & - & - & - \\
% SFT CodeS~\cite{codes} & CodeS-15B & - & \markcross & - & - & - & - \\ 
% Distillery~\cite{Distillery} & GPT-4o & - & \markcross & - & - & - & - \\ 
% XiYan-SQL~\cite{XiYan} & Qwen2.5-Coder-32B & Qwen2.5-Coder-32B & \markcross & - & - & - & - \\
% XiYan-SQL~\cite{XiYan} & Qwen2.5-Coder-32B & Qwen2.5-Coder-32B & \markcross & - & - & - & - \\ \hline
% DAIL-SQL~\cite{dailsql} & GPT-4 & - & \markcheck & - & - & - & - \\
% SuperSQL~\cite{supersql} & GPT-4 & - & \markcheck & - & - & - & - \\
% CHESS-SQL~\cite{chesssql} & GPT-4o & GPT-4o & \markcheck & - & - & - & - \\
% RSL-SQL~\cite{rslsql} & GPT-4o & GPT-4o & \markcheck & - & - & - & - \\
% CHASE-SQL~\cite{CHASE} & Gemini 1.5 &  Gemini 1.5 & \markcheck & - & - & - & - \\ \hline
% \textbf{AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{-} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ 
% \textbf{AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{-} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{Hybird} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ 
% \textbf{AlphaSQL-UB (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{-} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{AlphaSQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{Hybird} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \end{tabular}%
% }
% \end{table*}

% \begin{table*}[t!]
% \centering
% \caption{Execution Accuracy on Spider and BIRD Datasets.}
% \label{tab:acc}
% \resizebox{\textwidth}{!}{%
% \begin{tabular}{cccccccc}
% \hline
% \multirow{2}{*}{\textbf{Method}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Inference\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Selection\\ Model\end{tabular}}} & \multirow{2}{*}{\textbf{\begin{tabular}[c]{@{}c@{}}Fine-Tuning-\\ Free\end{tabular}}} & \multicolumn{2}{c}{\textbf{Spider}} & \multicolumn{2}{c}{\textbf{BIRD}} \\ \cline{5-8} 
%  & &  &  & \textbf{Dev} & \textbf{Test} & \textbf{Dev} & \textbf{Test} \\ 
%  \hline
% SFT CodeS~\cite{codes} & CodeS-7B & - & \markcross & 85.40 & - & 57.17 & 59.25 \\
% SFT CodeS~\cite{codes} & CodeS-15B & - & \markcross & 84.90 & - & 58.47 & 60.37 \\ 
% Distillery~\cite{Distillery} & GPT-4o & - & \markcross & - & - & 67.21 & 71.83 \\ 
% CHASE-SQL~\cite{CHASE} & Gemini-1.5-pro & Gemini-1.5-flash & \markcross & - & 87.60 & 73.01 & 73.00 \\
% XiYan-SQL~\cite{XiYan} & Qwen2.5-Coder-32B & Qwen2.5-Coder-32B & \markcross & - & 89.65 & 73.34 & 75.63 \\ \hline
% DAIL-SQL~\cite{dailsql} & GPT-4 & - & \markcheck & 83.60 & 86.60 & 54.76 & 57.41 \\
% SuperSQL~\cite{supersql} & GPT-4 & - & \markcheck & 87.00 & - & 58.50 & 62.66 \\
% MCS-SQL~\cite{MCS-SQL} & GPT-4 & GPT-4 & \markcheck & 89.50 & 89.60 & 63.40 & 65.50 \\
% CHESS-SQL~\cite{chesssql} & GPT-4o & GPT-4o & \markcheck & - & 87.20 & 65.00 & 66.69 \\
% RSL-SQL~\cite{rslsql} & GPT-4o & GPT-4o & \markcheck & - & 87.90 & 67.21 & - \\ \hline
% \textbf{Alpha-SQL-UB (Ours)} & \textbf{Qwen2.5-Coder-7B} & - & \markcheck & \textbf{-} & \textbf{-} & \textbf{83.58} & \textbf{-} \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Self-consistency} & \markcheck & \textbf{-} & \textbf{-} & \textbf{66.84} & \textbf{-} \\ 
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-7B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \textbf{Alpha-SQL-UB (Ours)} & \textbf{Qwen2.5-Coder-14B} & - & \markcheck & \textbf{-} & \textbf{-} & \textbf{83.90} & \textbf{-} \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{Self-consistency} & \markcheck & \textbf{-} & \textbf{-} & \textbf{68.32} & \textbf{-} \\ 
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \textbf{Alpha-SQL-UB (Ours)} & \textbf{Qwen2.5-Coder-32B} & - & \markcheck & \textbf{-} & \textbf{-} & \textbf{82.07} & \textbf{-} \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{Self-consistency} & \markcheck & \textbf{-} & \textbf{-} & \textbf{69.23} & \textbf{-} \\ 
% \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \textbf{Alpha-SQL-UB (Ours)} & \textbf{Deepseek-V3} & - & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% \textbf{Alpha-SQL (Ours)} & \textbf{Deepseek-V3} & \textbf{Self-consistency} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ 
% \textbf{Alpha-SQL (Ours)} & \textbf{Deepseek-V3} & \textbf{Hybrid} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% % \textbf{Alpha-SQL-UB (Ours)} & \textbf{Qwen2.5-Coder-14B} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% % \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-14B} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ 
% % \textbf{Alpha-SQL-UB (Ours)} & \textbf{Qwen2.5-Coder-32B} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\
% % \textbf{Alpha-SQL (Ours)} & \textbf{Qwen2.5-Coder-32B} & \markcheck & \textbf{-} & \textbf{-} & \textbf{-} & \textbf{-} \\ \hline
% \end{tabular}%
% }
% \end{table*}

% \begin{table}[t!]
% \centering
% \caption{Path Selection Comparison.}
% \label{tab:path-selection}
% \resizebox{\columnwidth}{!}{%
% \begin{tabular}{@{}ccccc@{}}
% \toprule
% \multirow{2}{*}{\textbf{Candidate Level}} & \multicolumn{3}{c}{\textbf{Score Combination}} & \multirow{2}{*}{\textbf{Accuracy (\%)}} \\ \cmidrule(lr){2-4}
%  & \textbf{Self-consistency} & \textbf{Path} & \textbf{SQL} &  \\ \midrule
% \multirow{3}{*}{Group-level} & \markcheck & \markcross & \markcross & 63.64 \\
%  & \markcheck & \markcheck & \markcross & 63.64 \\
%  & \markcheck & \markcheck & \markcheck & 62.73 \\ \midrule
% \multirow{3}{*}{Path-level} & \markcheck & \markcross & \markcross & 63.64 \\
%  & \markcheck & \markcheck & \markcross & 64.55 \\
%  & \markcheck & \markcheck & \markcheck & 64.55 \\ \midrule
% Upper Bound & - & - & - & 76.79 \\ \bottomrule
% \end{tabular}%
% }
% \end{table}


