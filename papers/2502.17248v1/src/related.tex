%!TEX root = ../main.tex
\section{Related Work}
\label{sec:related}


% Test-time Compute~\cite{snell2024scalingllmtesttimecompute}

% \citet{snell2024scalingllmtesttimecompute}

\textbf{Text-to-SQL.}
The Natural Language to SQL (Text-to-SQL, a.k.a., NL2SQL) task involves translating natural language questions into SQL queries. 
% Early works~\cite{NaLIR, GraPPa} primarily employed rule-based approaches to parse natural language questions and map them to corresponding SQL queries.
The emergence of Pre-trained Language Models (PLMs) like T5~\cite{t5} subsequently enhanced the performance of \nlsql tasks~\cite{PICARD, RESD-SQL, Graphix-SQL}. 
More recently, the development of LLMs has further advanced Text-to-SQL capabilities. 
However, applying LLMs directly remains challenging due to issues like schema alignment, complex query generation, etc~\cite{nl2sql-survey}.
To address these challenges, recent works~\cite{CHASE, chesssql, supersql, rslsql} have explored decomposing Text-to-SQL into subtasks, such as candidate SQL generation, refinement, and selection. For example, CHASE-SQL~\cite{CHASE} employs a multi-step pipeline to generate and validate SQL candidates, mitigating errors introduced by direct generation.

Building on this direction, we propose \sys, a progressive SQL construction framework that uses MCTS for dynamic query generation. Unlike prior methods relying on static pipelines or fine-tuning, \sys leverages LLMs as action models, guiding the search in a context-aware manner, enabling efficient exploration and improved accuracy without task-specific labeled data.
% Building on this promising direction, we propose \sys, which introduces a progressive SQL construction framework that dynamically builds queries through MCTS~\cite{mcts}. Unlike prior approaches that rely on static reasoning pipelines or expensive fine-tuning, \sys leverages LLMs as action models, guiding search-based SQL construction in a structured and context-aware manner. This allows \sys to efficiently explore the vast SQL query generation space, improving accuracy without requiring task-specific labeled data.
% 
% based on fine-tuning-free open-source models, achieves performance comparable to current state-of-the-art systems solely through enhanced inference-time reasoning. This approach effectively addresses the challenges associated with both categories by eliminating the need for domain-specific fine-tuning while avoiding the limitations of closed-source LLMs.

\textbf{Test-time Computation.}
Recent advances in test-time computation~\cite{snell2024scalingllmtesttimecompute} have significantly improved LLM performance without modifying model parameters. Techniques such as planning, search, and verification during inference have enhanced reasoning across various tasks~\cite{cot, tot, treebon, rap, zhang2024aflow, teng2025atom}. 
% Early methods like Chain-of-Thought (CoT) prompting~\cite{cot} improved performance by explicitly generating intermediate reasoning steps, while 
Recent methods, including tree-based search~\cite{tot} and Best-of-N sampling~\cite{treebon}, further optimized inference through structured search.
Recent work has also explored MCTS-based reasoning to enhance the capabilities of LLMs~\cite{qi2024mutualreasoningmakessmaller}. While effective in general reasoning tasks, these methods do not fully address the unique challenges of Text-to-SQL, such as schema understanding, generating semantically accurate SQL, and refining outputs based on execution feedback.

Alpha-SQL builds on test-time computation principles with a search-based SQL generation framework designed for zero-shot Text-to-SQL. Unlike prior work, it integrates LLM-driven reasoning into the MCTS process for progressive SQL query construction, optimizing the action space and incorporating database feedback to improve accuracy.

% Recent developments in ``test-time computation''~\cite{snell2024scalingllmtesttimecompute} have brought new vitality to the field of LLMs. Several recent approaches~\cite{cot, tot, treebon, rap} have demonstrated improved LLM performance in general benchmarks without modifying the parameters of the base model by incorporating the planning, search, and verification steps during the inference phase. The early Chain-of-Thought~\cite{cot} prompting method compelled models to output their reasoning process before providing answers, leveraging additional token overhead to enhance performance. Subsequent work achieved superior results by further increasing test-time computation through tree-based search~\cite{tot} and Best-of-N sampling strategies~\cite{treebon}. Our \sys explores the application of test-time computation techniques in the Text-to-SQL domain. This investigation extends the growing body of research on computation-intensive inference strategies to address the specific challenges of the Text-to-SQL task.
% rStar~\cite{qi2024mutualreasoningmakessmaller} applies Monte Carlo Tree Search (MCTS) for reasoning using two models: a reasoning LLM and a discriminator LLM for path selection. In contrast, Alpha-SQL introduces a novel approach by using a single LLM for end-to-end reasoning, simplifying the architecture and reducing computational complexity. Furthermore, Alpha-SQL is designed for the Text-to-SQL task, optimizing the action space to handle challenges such as complex table relationships and query ambiguity. Additionally, Alpha-SQL incorporates feedback from external database tools to refine query generation.
