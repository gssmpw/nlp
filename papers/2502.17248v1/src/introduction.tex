%!TEX root = ../main.tex
\section{Introduction}
\label{sec:introduction}




% LLMs for Text-to-SQL have revolutionized this area.
% Fine-tuning LLMs: limitations 
% No fine-tuning, zero-shot: (1) directly prompting (e.g., GPT, ...) (2) piggybacking LLMs for more advanced search, typically by generating candidate SQL queries and select the best.
% Along with new LLMs, zero-shot is promising. However, existing methods suffer from limited search space thus often fail to find the correct SQL queries.
% Our key idea is to have a dynamic exploration mechanism to generate and refine SQL queries adaptively.
% However, this faces two main challenges: (1) the search space for exploring candidate SQL queries is vast, as each reasoning step can branch into multiple possible paths based on the database schema and the natural language query. (2) determining the quality of exploration paths (\ie candidate SQL queries) during the search phase is challenging in the absence of human-annotated data. A robust evaluation mechanism is essential to ensure the generated SQL queries are both correct and diverse.


Text-to-SQL (a.k.a., NL2SQL) converts natural language queries into SQL, simplifying access to relational databases and enabling both lay and expert users to derive insights effectively~\cite{nl2sql-survey, supersql}. 
With the advancement of large language models (LLMs), methods like CHASE-SQL~\cite{CHASE} and XiYan-SQL~\cite{XiYan} have achieved new state-of-the-art results on benchmarks such as BIRD~\cite{bird}. Using LLMs for \nlsql can be generally categorized as trained methods and zero-shot methods.
%These LLM-based Text-to-SQL approaches have demonstrated that as LLMs improve, so does the performance of Text-to-SQL systems. 
 
\textbf{Training LLMs for \nlsql.} 
Pre-training or fine-tuning LLMs on task-specific datasets is a common approach to improving \nlsql performance~\cite{codes, XiYan,chesssql}. While effective, this method requires extensive labeled datasets and significant computational resources for model training. Moreover, as newer and more powerful LLMs emerge, the training process must be repeated to maintain competitive performance, further increasing the cost and effort.

\textbf{Zero-Shot LLMs for \nlsql.}
As an alternative, \textit{zero-shot Text-to-SQL} methods, such as DAIL-SQL~\cite{dailsql} and C3~\cite{c3}, leverage the general knowledge encoded in LLMs to generate SQL queries without requiring task-specific fine-tuning, which eliminates the dependence on labeled datasets and computationally intensive training.
While this approach offers a practical and cost-effective solution, it faces a fundamental challenge.

The key challenge in zero-shot Text-to-SQL is the difficulty of transferring and generalizing knowledge from pre-trained LLMs to the specific task of SQL generation, based on natural language queries and database schemas, without fine-tuning on task-specific annotated data. 
This limitation makes it difficult for the model to handle the complex mapping between natural language queries and diverse database schemas, impeding its ability to accurately interpret schema relationships, construct complex SQL queries, and maintain robustness across various contexts.

% The key challenge in zero-shot Text-to-SQL is the difficulty of knowledge transfer and adaptive generalization without fine-tuning the LLM parameters on task-specific annotated data. 
% This hinders the model’s ability to handle the complex mapping between natural language queries and database schemas, making it difficult for the model to understand diverse schemas, construct complex SQL queries, and maintain robustness across different database domains.


% \textbf{Key Idea.}
% A promising approach is to formulate Text-to-SQL as a process of progressive SQL construction, where queries are built step-by-step. 

% \textbf{Challenges.}
% Although this approach allows for more focused decisions at each step, accurately understanding the query intent and database context becomes increasingly difficult without fine-tuning, especially in complex tasks. %Specifically, challenges arise in understanding relationships between tables, identifying the correct column names, and interpreting ambiguous expressions in natural language queries.
% Furthermore, this multi-step reasoning process leads to an exponentially large search space. Without a structured approach to explore this vast space of potential SQL queries, zero-shot methods may miss optimal or semantically correct solutions.


% Inspired by recent advances in test-time computation~\cite{snell2024scalingllmtesttimecompute}, which improve LLM performance by incorporating reasoning, search, and verification steps during inference, we propose leveraging these techniques to guide LLMs in the SQL query generation process dynamically for \nlsql. 
% However, directly applying test-time computation to Text-to-SQL poses unique \textit{\textbf{challenges}}.




% 
% Second, unlike other tasks where reasoning focuses on relatively static input, Text-to-SQL requires dynamic integration of context, including the natural language question and the database schema. 
% 
% \rev{
% Third, test-time computation often relies on intermediate steps to refine solutions, but evaluating partial SQL queries is challenging in text-to-SQL due to the lack of ground-truth signals or intermediate feedback. Designing a self-supervised evaluation mechanism for these partial queries is critical for guiding the inference process effectively.
% }

% \yuyu{only evaluate the complete and valid SQL}

% Additionally, techniques that involve piggybacking on LLMs for advanced search—where candidate SQL queries are generated and subsequently evaluated—have also been explored. Despite the potential of these zero-shot methods, they often suffer from a limited search space, leading to frequent failures in identifying the correct SQL queries.

% Our key idea is to use a dynamic exploration mechanism that adaptively generates and refines SQL queries. This approach aims to enhance the search process, but it faces two main challenges.

%With the advancement of large language models (LLMs), state-of-the-art methods like XiYan-SQL~\cite{XiYan} and CHASE-SQL~\cite{CHASE} have achieved competitive results on benchmarks such as BIRD~\cite{bird}. These methods primarily rely on generating multiple candidate SQL queries from a given natural language question and database schema and then selecting the most appropriate candidate through a refined selection module. While effective, such approaches heavily depend on supervised fine-tuning and pre-defined strategies, which can hinder their adaptability to diverse real-world scenarios and significantly increase reliance on annotated data. This raises the question of whether more flexible and less data-intensive frameworks can achieve comparable or superior performance.

%\yuyu{I think we should have a motivated figure here.}

% Difference of Alpha-SQL and other methods
% Better generation space

% \paragraph{How do human experts perform the Text-to-SQL task?}
% In real-world scenarios, experts often approach the Text-to-SQL task with a dynamic and iterative reasoning process. Key observations include:

% \begin{itemize}
%     \item Dynamic Exploration and Refinement \yuyu{todo: fix}: Rather than generating a single SQL query outright, experts iteratively construct and refine intermediate queries. They evaluate the logical consistency of each step and revise based on misinterpretations or errors in the query structure.
%     \item Self-Evaluation and Self-Correction \yuyu{todo: fix}: During the process, experts validate SQL queries by checking for logical correctness, adherence to the query intent, and compatibility with the database schema. They iteratively revise the queries to ensure precision and relevance.
% \end{itemize}

%To ..., our \textbf{key idea} is to leverage a dynamic exploration mechanism to generate and refine SQL queries adaptively. This is achieved by modeling SQL generation as a path exploration problem, where each step dynamically adjusts based on the context of the natural language query and the database schema. 
%Unlike existing solutions such as CHASE-SQL~\cite{CHASE} and XiYan-SQL~\cite{XiYan}, which rely on fixed exploration strategies and static candidate SQL generation frameworks, we aim to introduce a flexible and self-adaptive reasoning process. Specifically, our approach dynamically selects the most suitable ``action'' at each reasoning step, forming multiple exploration paths that adapt based on intermediate results and query-specific contexts.
%To further enhance the process, our framework evaluates the quality of each exploration path (\ie candidate SQL) in a self-supervised fashion, ensuring correctness and diversity without relying heavily on annotated data. This approach mimics how experts iteratively evaluate and refine their reasoning paths, leading to more robust and accurate SQL generation.
%\yuyu{revise this part later with more details}

%\paragraph{Challenges.}
%Implementing our key idea presents two major challenges.
%First, the search space for exploring candidate SQL queries is vast, as each reasoning step can branch into multiple possible paths based on the database schema and the natural language query. 
%Second, determining the quality of exploration paths (\ie candidate SQL queries) during the search phase is challenging in the absence of human-annotated data. A robust evaluation mechanism is essential to ensure the generated SQL queries are both correct and diverse.

% 将大任务拆解为多个细粒度的小任务，用action model单独解决每一步推理，

\textbf{Our Methodology and Contributions.}
To address the above challenges, we propose Alpha-SQL, a novel approach that enables zero-shot Text-to-SQL as a process of progressive SQL construction, where queries are progressively built step-by-step. The core idea of Alpha-SQL is to decompose the task into smaller, more manageable sub-tasks, each with contextual guidance, making it easier for the model to handle complexity at each step. To achieve this, we model the progressive construction process as a search problem over a tree-structured space, where nodes represent partial SQL query states, and edges denote SQL construction actions (\eg selecting a table or revising a SQL clause). By iteratively selecting edges (actions) from the root to a leaf node, Alpha-SQL progressively constructs a valid SQL query.

Based on this idea, Alpha-SQL leverages a Monte Carlo Tree Search (MCTS) framework to dynamically generate and explore SQL construction actions. To facilitate efficient and effective search within the MCTS framework, we introduce the following novel techniques.

\begin{figure}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/intro-figure.pdf}
    \vspace{-2em}
    \caption{Alpha-SQL: A plug-in framework boosting small open-source LLMs. Our method significantly improves Qwen2.5's performance by 15\%-20\% across different model sizes (7B-32B) without fine-tuning, surpassing even GPT-4o based zero-shot Text-to-SQL SOTA (RSL-SQL) on the BIRD (Dev) dataset.}
    \label{fig:plugin}
    \vspace{-.5em}
\end{figure}

%%%%%%%%%%%%%%%%%%
% Blocked by Ju
%To address the above challenges, 
%we formulate zero-shot Text-to-SQL as a process of progressive SQL construction, where queries are built step-by-step. This approach breaks the task into smaller, more manageable sub-tasks, each with context available for reference, making it easier for the model to handle each task.
%To systematically navigate this progressive construction process, we model this process as a search problem over a tree-structured space, where nodes represent partial SQL query states and edges correspond to SQL construction actions (\eg selecting a table or SQL revision). The goal is to iteratively select edges (actions) from the root to a leaf node, progressively constructing a valid SQL query.
%
%Building on this formulation, we propose Alpha-SQL, a novel framework that leverages \textit{LLM-as-Action-Model} to dynamically generate SQL construction actions during the Monte Carlo Tree Search (MCTS) process. 
%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%

First, to enhance reasoning capabilities during the search process, we propose the \textit{LLM-as-Action-Model}, which invokes an LLM as the reasoning action model in the MCTS framework to generate step-by-step reasoning (\ie Chain-of-Thought) after each action taken. 
This reasoning is stored in each node alongside the partial SQL query state, enabling Alpha-SQL to maintain context and track the LLM's thought process throughout the SQL construction process.
This ensures that each SQL construction action is both context-aware and aligned with the overall reasoning path, which can guide the search toward more promising SQL queries.

%First, to enhance the reasoning capabilities during the search process, we introduce \textit{LLM-as-Action-Model} that invokes an LLM as the action model to generate step-by-step reasoning (\ie Chain-of-Thought) after each action taken by the MCTS search process. This reasoning is stored within each node, alongside the partial SQL query state, enabling Alpha-SQL to maintain context and track the LLM's thought process at each step. This approach ensures that each SQL construction action is context-aware, informed by prior actions, and aligned with the overall reasoning trajectory. By incorporating the LLM's reasoning into the MCTS process, Alpha-SQL dynamically guides the search towards more promising candidate SQL queries.

Second, to ensure accurate and efficient query generation during the MCTS search process, we introduce a self-supervised reward function to evaluate the quality of candidate SQL queries. Specifically, for each reasoning path, Alpha-SQL generates multiple candidate SQL queries using high-temperature sampling, filters out invalid queries, and computes a self-consistency score by comparing the execution results of the sampled queries with those of the predicted SQL. This helps prioritize promising paths and refines the exploration process.
Finally, Alpha-SQL calculates the self-consistency scores of all candidate SQL queries and selects the SQL with the highest score as the final output.

In summary, \sys is a fine-tuning-free, plug-and-play \nlsql framework that enhances small open-source LLMs for Text-to-SQL tasks.  As shown in Figure~\ref{fig:plugin}, it can integrate and boost existing LLMs without fine-tuning on Text-to-SQL datasets. Extensive experiments show Alpha-SQL's strong performance, achieving 69.7\% execution accuracy on the BIRD development set, significantly outperforming existing zero-shot methods. Ablation studies confirm the effectiveness of our reasoning actions, and performance improves with more MCTS rollouts.
% In summary, \sys leverages the techniques discussed above to create a fine-tuning-free, plug-and-play framework. \rev{As shown in Figure~\ref{fig:plugin}}, it seamlessly integrates existing small open-source LLMs as the core component, enhancing their reasoning capabilities for the Text-to-SQL task without requiring task-specific fine-tuning.
% \rev{Moreover, extensive experiments demonstrate Alpha-SQL's competitive performance, achieving 69.7\% execution accuracy on Spider and 87.0\% on BIRD development sets.
% Through ablation studies on the action space, we validate the effectiveness of our defined reasoning actions for Text-to-SQL tasks.
% Moreover, Alpha-SQL's performance increases with more MCTS rollouts, enabling flexible adaptation to varying computational resources. }

% To address these challenges, we propose \sys, a Monte Carlo Tree Search (MCTS)-based framework designed to explore and evaluate SQL generation paths systematically.

% First, we model SQL generation as a tree search problem, where each node represents a reasoning state and edges correspond to actions such as schema linking, condition generation, or SQL refinement. Using MCTS, \sys dynamically explores multiple reasoning paths by selecting actions based on the query context and intermediate results, efficiently generating \textit{diverse} candidate SQL queries.

% Second, to evaluate the quality of SQL candidates during the exploration phase, we introduce a self-supervised reward function. For the final step of each reasoning path, whether SQL generation or refinement, \sys applies high-temperature sampling to generate multiple SQL candidates. Invalid SQL queries, such as those with syntax errors or empty execution results, are filtered out. A self-consistency score is then computed by comparing the execution results of the sampled SQL queries with those of the predicted SQL. This score, calculated as the proportion of consistent results among the sampled queries, serves as a reward that is back-propagated through the MCTS process to update reward values for all nodes along the path. This mechanism ensures that \sys prioritizes more promising exploration paths, effectively improving the quality of SQL candidates.

% Finally, \sys employs a hybrid voting mechanism to select the best SQL query as the output. Notably, \sys is fine-tuning-free and can seamlessly integrate existing LLMs as the backbone to enhance reasoning capabilities in the Text-to-SQL task.


% \yuyu{We can remove the following part.}
% \paragraph{Contributions.}
% We make the following key contributions:

% \bi 
% \item \textbf{Problem Formulation}: We reformulate Text-to-SQL as a search problem over a tree-structured space.

% \item \textbf{Alpha-SQL}:


% \item \textbf{Extensive Experiments}:

% \ei 

% \begin{itemize}
%     \item \textbf{A Novel Framework for Dynamic SQL Generation.} \sys introduces a Monte Carlo Tree Search (MCTS)-based framework that models SQL generation as a dynamic path exploration problem. This approach enables the adaptive selection of actions at each reasoning step, forming multiple exploration paths tailored to the query context and database schema.
    
%     \item \textbf{Self-Supervised SQL Evaluation.}  \yuyu{revmove...}
%     \sys incorporates a self-supervised reward mechanism to evaluate the quality of candidate SQL queries during exploration. By leveraging high-temperature sampling, filtering invalid queries, and computing self-consistency scores, this mechanism ensures correctness and diversity without relying on annotated data, mimicking the iterative refinement process of human experts.  

%     \item \textbf{Fine-Tuning-Free and Plug-and-Play Integration.} 
% \sys is designed to be fine-tuning-free and can seamlessly integrate with existing LLMs, enhancing their reasoning capabilities for Text-to-SQL tasks. This flexibility minimizes the need for extensive re-training while leveraging state-of-the-art LLM performance.  

%     \item \textbf{Extensive Experiments.} 
%     We conduct extensive experiments on BIRD and Spider benchmarks, \yuyu{summarize the experimental results.}
% \end{itemize}

% \paragraph{Motivation} 

% \begin{itemize} \item Text-to-SQL Translation is inherently a data- and query-dependent task, presenting unique challenges across different natural language queries and database schemas. Specifically, the logic required to synthesize SQL is tightly coupled with the structure and content of the underlying database and the given natural language query.

% \item Traditional methods often rely on static generation strategies (with different prompt designs) or pre-defined workflow with multiple LLM agents, which struggle to adapt to the diverse structures of real-world databases and ambiguous user queries. 

% \item Furthermore, complex queries require dynamic reasoning capabilities, including identifying relevant database values, mapping natural language conditions to schema elements, and constructing precise SQL queries. These tasks demand a flexible, adaptive approach that can dynamically explore and refine reasoning paths. 

% \item Existing approaches often lack mechanisms to self-evaluate and improve query generation accuracy. This gap underscores the need for techniques that incorporate self-supervised optimization and dynamic exploration frameworks. 

% \item Motivated by these challenges, we propose a novel framework that leverages Monte Carlo Tree Search (MCTS) for dynamically optimizing the SQL generation process and self-supervised rewards for enhancing path exploration and final query accuracy. 

% \end{itemize}