\section{Conclusion}
\label{section:conclusion}
%
% With AoS, compute kernels over sequences of structs 
% have to gather and scatter vector register content (shuffling),
% vector parallelism is not blatant to the compiler, 
% and structs for multiple loop iterations might not fit into the cache.
% With SoA, vector registers can be filled with coalesced memory
% accesses, vector computations are exposed explicitly, and data from subsequent
% loop iterations is likely to reside in cache.
% While CPUs improve their gather-scatter efficiently with every new generation,
% the observations remain valid and apply
% GPUs, too~\cite{Strzodka:2011:AbstractionSoA}.
% 
% This is an out-of-place reordering, i.e.~does not alter the original
% data layout
% \cite{Gallard:2020:ExaHyPEVectorisation,Gustavson:2012:InPlaceStorage,Vikram:2014:LLVM}.
% The compiler also alters all corresponding data accesses such that they fit
% to the reordered copy of the data.
% A counterpart annotation ensures that data modifications are copied back at the end of the
% block, i.e.~data are kept consistent.
%
%



\added[id=copy]{
 SoA is not always superior to AoS. 
 Tasks such as boundary data exchange in domain decomposition codes, particle movements over meshes, or, in
 general, any algorithm that has to alter or permute struct sequences or
 access it in a non-continuous way \cite{Strzodka:2011:AbstractionSoA} benefit
 from AoS.
 The size of characteristic sequences \cite{Homann:2018:SoAx} and the memory
 footprint per struct further affect which storage format performs better.
 Finally, any statement on a storage format superiority depends upon how successful the compiler 
 vectorises an algorithm
 \cite{Jubertie:2018:DataLayoutAbstractionLayers,Xu:2014:SemiAutomaticComposition} and what the target architecture looks like.
 The choice of an optimal data structure is context-dependent.
 There is no ``one format rules them all''.
} 
Our approach accommodates this insight as it strictly separates the optimisation over data layouts from the modelling.
By adding, modifying or removing annotations, users can investigate better-suited data layouts.


Our experiments with temporary out-of-place transformations~\cite{Sung:2012:DataLayoutTransformations} and struct peeling~\cite{Hundt:2006:StructureLayoutOptimisation} suggest that annotations bringing data into the right format at the right time has significant performance optimisation potential.
However, our observations also suggest that they do not free developers from manual performance engineering.
Instead, they alter the character of such engineering.
Streamlining all data conversion allows the engineer to focus more on other aspects such as kernel-level vectorisation or the creation of GPU kernels handling larger data sets in one go without small kernel launches.


The observations also challenge the common knowledge that it is important to organise data carefully within large-scale simulation codes.
Instead, there is the potential to work with wildly scattered heap data and to consolidate such data just before the compute-heavy kernels are launched.
It is likely that this observation is not upheld for other codes and can be challenged.
However, it seems to hold for SPH. 


Future work will have to push the notion of on-demand data transformations.
At the moment, our view constructions are strictly temporal and tied to individual loops.
If a force calculation follows a density compute step, we convert data forth and back, which is not necessary: 
We potentially could hold it in SoA, albeit with bigger $\mathbb{A}$ sets and likely not on the call stack anymore.
It will remain subject of future work to study how such considerations can feed into compiler-buided format conversions.
It is also important to continue to explore how annotations can help to performanc engineer modern codes efficiently, what role data conversions can play in this context, and how different aspects such as the conversion and multicore parallelisation or GPU offloading can be brought together.
As C starts to support annotations, too, such conversations generalise beyond the realms of C++ only.

 
