\section{Source code annotations}
\label{section:annotations}

\input{code-snippets/blueprint-annotated.tex}

%
% Predicate remains completely unchanged as well as the actual density function
%
\added[id=copy]{We propose that developers stick to AoS as modelling data structure, and request temporary data transformations into SoA that are executed automatically by the compiler.
For this we introduce new C++ attributes}
(Listing~\ref{algorithm:annotations:example}):

\begin{itemize}
  \item The attribute \texttt{[[clang::soa\_conversion]]} must precede a loop over a C++ container and instructs the translator to construct a view over this container that converts all read (in) and all written data members (out) into a SoA.
  \item The attribute \texttt{[[clang::soa\_conversion\_hoist(n)]]} can be applied to an inner loop. It has the same semantics as a simple conversion yet moves the conversion $n$ levels out of the loop hierarchy.
  \item The attribute \texttt{[[clang::soa\_conversion\_compute\_offload]]} deploys the loop execution, subject to the conversions, onto OpenMP's target offloading.
\end{itemize}


\subsection{Annotation semantics}
%
%
%
Each annotation triggers a temporary, local, automatic rewrite of the container indexed by the loop into SoA.
\added[id=copy]{We instruct the compiler to perform a temporary out-of-place transformation behind the scenes} \cite{Sung:2012:DataLayoutTransformations}:


The annotation makes the compiler analyse all data accesses to the container data within the loop body. 
Let the struct members read be described by a set $\mathbb{A}_{\text{in}}$,
while data members written end up in $\mathbb{A}_{\text{out}}$.
\added[id=copy]{
The \texttt{soa\_conversion} statement then adds a prologue to the loop.
}
This prologue creates one logical (temporary) array per entry in $\mathbb{A}_{\text{in}} \cup \mathbb{A}_{\text{out}}$.
After that, the entries from the container are copied over into the temporary data structures for all entries in $\mathbb{A}_{\text{in}}$.
$\mathbb{A}_{\text{out}} \setminus \mathbb{A}_{\text{in}} $ does not require any preparation.
Next, the compiler ensures that the transformed loop accesses the SoA buffers instead of the original AoS data. 
% A discussion about the implementation details of this step is presented in Section~\ref{section:realisation}.
Finally, we synchronise the temporary data with the origin data structure.
This is achieved through an epilogue following the main computation loop.
The epilogue step loops over the container and moves the temporary data indexed by $\mathbb{A}_{\text{out}}$ back into the original data structure.
Once this epilogue terminates, any changes induced by the loop body on the view are re-synchronised with the original loop container.
Eventually, we free the temporary data, i.e.~we destroy the view.


\subsection{Annotation properties and constraints}

To make the automatic construction of correct views work, the compiler analysis has to track all data accesses of the AoS data inside the loop body, including accesses inside functions called from within the loop body. 
All definitions of the functions called, either directly or indirectly, need to be known. 

We assume that the loop body is atomic, i.e.~free of side effects caused outside of the loop body.
Aliasing effects would fall into this rubric but also accesses to atomic variables through multiple threads:
As we construct the view through an out-of-place transformation, any access to an entry of the loop container from outside the loop, even though correctly declared as atomic, will continue to affect the original container element, while the loop works on its working copy.
The change is not visible to the loop body and will eventually be overwritten.
Concurrent access to a container property within the loop body is not a problem.
In this case, all concurrent access is encapsulated. 


The concurrency statements hold exclusively for data members from $\mathbb{A}_{\text{in}} \cup \mathbb{A}_{\text{out}}$.
The view splits the members of the struct into two categories:
While the loop is running, the data items from $\mathbb{A}_{\text{in}} \cup \mathbb{A}_{\text{out}}$ within the container become temporarily invalid.
The remaining struct members however remain valid as the epilogue's mapping from the transformed SoA data onto the original container is, in general, not surjective.


\subsection{Data replication due to aliasing}

For struct members in $\mathbb{A}_{\text{in}} \cap \mathbb{A}_{\text{out}} \not= \emptyset$, an out-of-place transformation yields only one instance of these data.
We do not create a separate instance for $\mathbb{A}_{\text{in}}$ and one for $\mathbb{A}_{\text{out}}$.
Yet, only those data members in $\mathbb{A}_{\text{out}}$ are eventually picked from the transformed data and copied back.


For nested loops with aliasing, i.e.~nested loops where two containers reference joint data, we have to be more careful.
Let $\mathbb{A}_{\text{in}}^{(outer)},\ \mathbb{A}_{\text{out}}^{(outer)}$ and $\mathbb{A}_{\text{in}}^{(inner)},\ \mathbb{A}_{\text{out}}^{(inner)}$ be the active sets of the outer or inner loop, respectively.
If the underlying containers index distinct sets of objects, no further discussion is required.
However, ambiguity problems can arise if 

\[
\mathbb{A}_{\text{out}}^{(inner)} \cap \left( \mathbb{A}_{\text{out}}^{(outer)} \cup \mathbb{A}_{\text{out}}^{(outer)} \right) \not= \emptyset.
\]


\noindent
In this case, the outer loop's prologue will convert $\mathbb{A}_{\text{out}}^{(outer)} \cup \mathbb{A}_{\text{out}}^{(outer)}$ into a temporary new data set.
The inner loop's prologue will also create a new dataset, effectively duplicating the overlapping data.
As we have a bitwise replica of all data items, the replica are consistent.
The subsequent epilogue of the inner loop now modifies the members identified through $\mathbb{A}_{\text{out}}^{(inner)}$.
However, these modifications are not mirrored in the set $\mathbb{A}_{\text{out}}^{(outer)} \cup \mathbb{A}_{\text{out}}^{(outer)}$, i.e. the two datasets become inconsistent.


We label setups with ambiguous conversion outcomes as undefined or corrupted, i.e.~we do not support them.
Indeed, our SPH code's distinction of active vs.~local sets does yield overlapping data, i.e.~aliasing effects, but it remains well-defined, as we always write exclusively to the local data and furthermore ensure in our implementation that these updated data are never read from the active data.


\subsection{Offloading through OpenMP}

OpenMP's \texttt{target} clause and its offloading infrastructure makes it straightforward to deploy compute kernels to an accelerator.
Offloading however requires a proper mapping of the CPU's memory, i.e.~we have to ensure a correct memory allocation on the device and efficient data transfers between the host and the accelerator.
The existing SoA transformation classifies memory access over the struct members into three types: 
read-only ($\mathbb{A}_{\text{in}} \setminus \mathbb{A}_{\text{out}}$), write-only ($\mathbb{A}_{\text{out}} \setminus \mathbb{A}_{\text{in}}$), and read-write ($\mathbb{A}_{\text{in}} \cap \mathbb{A}_{\text{out}}$). 
They directly define which memory mappings or allocations are required if we work with a distributed memory model:
Read-only data is allocated on the device, and data is transferred from the host to the device before the kernel execution. 
Write-only buffers are allocated on the device, and data is transferred from the device to the host after kernel execution. 
Finally, read-write data is allocated on the device, with two memory transfers taking place---one from the host to the device before execution and another from the device to the host after kernel execution.
In a shared memory model, all memory movements are delegated to the underlying hardware/driver/runtime stack.

Our annotation exclusively relates to the iteration's container. If additional data, such as static variables, need to be mapped to the device, we delegate the responsibility of mapping it correctly to the user.

For the realisation of the loop iteration, we assume that we can directly exploit \texttt{teams distribute parallel for}, i.e.~that the underlying loop iterations are embarassingly parallel.
For an annotation prototype, this is sufficient.
In the long term, a closer integration into OpenMP's syntax---compare the use of attributes in the OpenMP Technical Report 8 \cite{OpenMP:TechnicalReport8}---would be beneficial.

% This is definitely a possibility and it's even something the OpenMP language committee is looking at. Take a look at OpenMP Technical Report 8 (https://www.openmp.org/wp-content/uploads/openmp-TR8.pdf) page 36, where a syntax for using OpenMP via attributes is proposed. Inclusion in TR8 doesn't guarantee its inclusion in version 5.1, but it shows that it's being discussed. This syntax is largely based on the work done in the original proposal for C++ attributes.
