\subsection{Sparsely-gated MoE}
\label{subsec:sparse_moe}

In AVSR systems, the multimodal encoder processes a sequence of audio $\rva = [a_1, a_2, \cdots]$ and video $\rvv = [v_1, v_2, \cdots]$ data into combined audio-visual embeddings $\text{Enc}(\rva, \rvv)$. These embeddings are utilized by the decoder to predict subsequent text tokens, where the predicted token is given by $\textsl{text}_{t+1} = \text{Dec}(\text{Enc}(\rva, \rvv), \textsl{text}_t)$. Within the Transformer layer, $x_t$ is the intermediate representation of the token $\textsl{text}_t$, derived by cross-attending to the combined audio-visual embeddings from $\rva$ and $\rvv$ (see Figure\,\ref{fig:overview}).

The integration of a sparsely-gated MoE framework \citep{shazeer2017outrageously, lepikhin2021gshard} leverages $E$ experts to scale model capacity. Each token representation is routed to a selected subset of these experts through a learned gating mechanism. 
Specifically, the routing function $h(x) = W_r \cdot x$ assigns weights for each token, and the weight for expert $i$ is computed using a softmax function:
\begin{equation}
\label{eq:router_weight}
    p_i(x) = \frac{\exp(h_i(x))}{\sum_{j=1}^{E} \exp(h_j(x))},
\end{equation}
and the output $y$ is the aggregated result of computations from the top-$k$ selected experts:
\begin{equation}
y = \sum_{i \in \text{top}k(E)} \tilde{p}_i(x) E_i(x),
\end{equation}
where $\tilde{p}$ is the normalization of top-$k$ probabilities.
Note that each expert follows the same structure as a feed-forward network\,(FFN) in a Transformer block. Figure\,\ref{fig:overview} presents the overall MoE architecture and its token routing.



%%%%%%%%%%%%%%%%%%%%
\begin{figure}[!t]
    \centering
    \vspace*{-5pt}
    \includegraphics[width=\linewidth]{tex_figure/figure2.pdf}
    \vspace*{-20pt}
    \caption{Overview of sparsely-gated MoE for AVSR. A select subset of experts are activated for each token representation ($x_t$).
    }
    \label{fig:overview}
    \vspace{-5pt}
\end{figure}
%%%%%%%%%%%%%%%%%%%%


\vspace*{-8pt}
\paragraph{Load balancing.}
To mitigate the load imbalance issue commonly observed in the top-$k$ expert selection strategy, a load balancing loss has been implemented to encourage the balanced token load across all experts. Specifically, we use a differentiable load balancing loss~\citep{fedus2022switch}:
\begin{equation}
    L_B = E \cdot \sum_{i=1}^E f_i \cdot P_i,
\end{equation}
where $f_i$ denotes the frequency of expert $i$ being selected as top-1, averaged over all tokens within a batch $\mathcal{B}$,
\begin{equation}
\label{eq:expert_frequency}
    f_i = \frac{1}{T} \sum_{x\in\mathcal{B}} \mathbbm{1} \{\arg\max p(x) = i\}
\end{equation}
and $P_i$ is the average assigned probability for expert $i$,
\begin{equation}
\label{eq:expert_probability}
    P_i = \frac{1}{T} \sum_{x\in\mathcal{B}} p_i(x)
\end{equation}
with $T$ representing the total number of tokens.

An additional router z-loss~\citep{zoph2022st} is employed to stabilize the routing mechanism:
\begin{equation}
    L_Z = \frac{1}{T}\sum_{x\in\mathcal{B}} \Bigg(\log \sum_{i=1}^E \exp(h_i(x)) \Bigg)^2.
\end{equation}
This sparse MoE structure ensures that token processing is efficiently managed across multiple experts, utilizing lower compute relative to its expansive capacity.


%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.95\linewidth]{tex_figure/figure3.pdf}
    \vspace{-5pt}
    \caption{MoE-based routing strategies for AVSR. 
    (a) A conventional MoE approach where a learned router selects the top-2 experts for each token, enforcing the balanced expert load. 
    (b) Experts are explicitly divided into audio and visual groups, with manual activation based on the input modality.
    (c) \ourmodel introduces an inter-modal router that can dynamically assign weights to modality-specific expert groups, followed by intra-modal routers that select the top-1 expert within each group. The inter-modal router is trained by the load biasing loss that guides the expert group specialization.
    }
    \label{fig:routing}
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%