\subsection{Expert Group Specialization}
\label{subsec:hard_routing}


To enhance expert management within the AVSR system, a \textit{hard routing} technique can be used for expert group specialization. This approach is inspired by several practices in visual-language MoE models \citep{zhu2022uni, li2023pace, shen2023scaling, lee2025moai} where the role of experts is strictly defined by the input modality, eliminating the need for a trained router.

\vspace*{-8pt}
\paragraph{Hard routing.}
Our hard routing enforces modality-specific activation of expert groups: audio data activate only audio experts, and video data activate only visual experts.
This segregation encourages the independent development of specialized expert groups. As suggested in V/T-MoE \citep{shen2023scaling}, once the group is activated, we use an intra-modal router for the modality-specific experts.

Figure\,\ref{fig:routing}(b) visualizes the hard routing mechanism with audio and visual expert groups.
During training, audio or video sequence is randomly dropped, leading to subsets $\mathcal{A}$ and $\mathcal{V}$ within a batch $\mathcal{B}$, consisting of audio-only or video-only sequences, respectively. A token representation $x_t \in \mathcal{A}$ indicates that the cross-attention module processes the input $\textsl{text}_t$ with $\text{Enc}(\rva, \vzero)$---where the visual component is zeroed out---and vice versa for $x_t \in \mathcal{V}$.
For these, we utilize two distinct intra-modal routing networks, $W_r^A$ and $W_r^V$:
\begin{align}
\begin{split}
    h^A(x) &= W_r^A \cdot x \quad \text{for } x \in \mathcal{A}, \\
    h^V(x) &= W_r^V \cdot x \quad \text{for } x \in \mathcal{V}.
\end{split}
\end{align}
These routers calculate the weights $p^{\{A,V\}}(x)$ as in Eq.\,(\ref{eq:router_weight}) within their respective expert group, either $\{E^A\}$ for audio or $\{E^V\}$ for visual. The output for each token is then
\begin{equation}
    y = \begin{cases}
        \sum_{\text{top}k(E^A)} \tilde{p}_i^A(x) E^A_i(x) & \text{if } x \in \mathcal{A}, \\
        \sum_{\text{top}k(E^V)} \tilde{p}_i^V(x) E^V_i(x) & \text{if } x \in \mathcal{V}. \\ 
    \end{cases} 
\end{equation}
For audio-visual sequences, outputs from both groups are averaged, with the top-($k/2$) experts from each group contributing to ensure balanced processing.
