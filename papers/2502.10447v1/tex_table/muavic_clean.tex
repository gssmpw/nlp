\begin{table*}[!h]
    \centering
    \small
    \caption{Multilingual audio-visual speech task performance, with non-English speech recognition (WER) and X-En speech-to-text translation (BLEU score), in a clean environment without auditory noise. $^\dagger$Results obtained from \citet{han-etal-2024-xlavs}. $^\ddagger$Re-implemented using the pretrained model from \citet{choi2024av2av}.}
    \label{tab:muavic_clean}
    \vspace{5pt}
    % \addtolength{\tabcolsep}{-1pt}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{llccccccccc}
    \toprule
    && \multicolumn{8}{c}{Source} & \\
    \cmidrule{3-10}
    Model & Pretrain data & Ar & De & El & Es & Fr & It & Pt & Ru & Avg \\
    \midrule
    \multicolumn{11}{c}{\textbf{\textit{Clean Speech Recognition, Test WER $\downarrow$}}} \\
    Whisper large-v2\,\cite{radford2023robust} & \textit{680k hrs, 100+ langs} & 91.5 & \textbf{24.8} & 25.4 & 12.0 & 12.7 & 13.0 & 15.5 & 31.1 & 28.2 \\
    u-HuBERT$^\dagger$\,\cite{hsu2022u} & \textit{1.7k hrs, English} & 89.3 & 52.1 & 46.4 & 17.3 & 20.5 & 21.2 & 21.9 & 44.4 & 39.1 \\
    mAV-HuBERT\,\cite{anwar2023muavic} & \textit{1.7k hrs, English} & 69.3 & 47.2 & 41.2 & 16.2 & 19.0 & 19.8 & 19.9 & 38.0 & 33.8 \\
    XLS-R 300M$^\dagger$\,\cite{babu2022xls} & \textit{1.2k hrs, 9 langs} & 85.6 & 44.0 & 34.4 & 13.2 & 15.1 & 14.3 & 16.2 & 34.4 & 32.2 \\
    XLAVS-R 300M\,\cite{han-etal-2024-xlavs} & \textit{8.3k hrs, 100+ langs} & 80.0 & 38.0 & 28.1 & 11.7 & 15.3 & 13.8 & 14.4 & 31.2 & 29.1 \\
    XLAVS-R 2B\,\cite{han-etal-2024-xlavs} & \textit{1.2k hrs, 9 langs} & 79.3 & 44.4 & \textbf{19.0} & \textbf{9.1} & \textbf{12.3} & \textbf{10.6} & \textbf{11.2} & \textbf{25.0} & \textbf{26.4} \\
    \cdashlinelr{1-11}
    mAV-HuBERT$^\ddagger$ & \textit{7.0k hrs, 100+ langs} & \textbf{78.3} & 41.4 & 25.5 & 11.9 & 16.2 & 14.8 & 14.3 & 31.6 & 29.3 \\
    \ourmodel-\textsc{Large} (\textbf{ours}) & \textit{7.0k hrs, 100+ langs} & 85.1 & 38.9 & 25.9 & 11.2 & 14.6 & 14.0 & 13.8 & 30.0 & 29.2 \\
    \midrule
    \multicolumn{11}{c}{\textbf{\textit{Clean X-En Speech-to-Text Translation, Test BLEU $\uparrow$}}} \\
    Whisper large-v2\,\cite{radford2023robust} & \textit{680k hrs, 100+ langs} & - & - & \textbf{24.2} & \textbf{28.9} & \textbf{34.5} & \textbf{29.2} & \textbf{32.6} & \textbf{16.1} & \textbf{29.9} \\
    mAV-HuBERT\,\cite{anwar2023muavic} & \textit{1.7k hrs, English} & - & - & 7.6 & 20.5 & 25.2 & 20.0 & 24.0 & 8.1 & 17.6 \\
    XLAVS-R 300M\,\cite{han-etal-2024-xlavs} & \textit{8.3k hrs, 100+ langs} & - & - & 18.3 & 23.9 & 29.8 & 25.1 & 28.9 & 12.1 & 23.0 \\
    XLAVS-R 2B\,\cite{han-etal-2024-xlavs} & \textit{1.2k hrs, 9 langs} & - & - & 21.6 & 25.1 & 30.6 & 26.6 & 29.9 & 13.9 & 24.6 \\
    \cdashlinelr{1-11}
    mAV-HuBERT$^\ddagger$ & \textit{7.0k hrs, 100+ langs} & - & - & 11.5 & 24.2 & 29.2 & 23.9 & 28.1 & 10.4 & 21.2 \\
    \ourmodel-\textsc{Large} (\textbf{ours}) & \textit{7.0k hrs, 100+ langs} & - & - & 13.8 & 24.9 & 30.8 & 25.0 & 28.7 & 10.9 & 22.4 \\
    \bottomrule
    \end{tabular}
    }
\end{table*}