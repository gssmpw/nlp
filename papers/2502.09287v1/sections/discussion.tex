\vspace{-5mm}
\section{Conclusion}\label{section discussion}

We demonstrated that the performance of linear models on a simplified copy task, when applied to stationary input sequences, depends on the ratio $\frac{S}{K}$, where $S$ denotes the size of the state space, and $K$ represents the lag of the copy task. This analysis revealed a form of uncertainty principle governing the resolution of our copy task with linear recurrences. To explain this trade-off between memory capacity and filter performance, we introduced a new filter that achieves the same performance on our copy task up to constants. This representation offers fresh insights into the filter's behavior, particularly in the spectral domain. As highlighted by \cite{orvieto2023resurrecting} and further elaborated by \cite{gu2022efficiently}, the initialization of the recurrence matrix's entries plays a crucial role in achieving high performance. Specifically, these studies constrain both the magnitudes and phases of the diagonal entries to depend on $\frac{1}{\Delta}$, where $\Delta$ has an order of magnitude similar to the sequence length. In this paper, we aim to provide an explanation for the efficacy of this specific initialization: it arises from the linear model's endeavor to retain certain elements of the sequence, thereby approximating the shifted Dirac function. 

 
