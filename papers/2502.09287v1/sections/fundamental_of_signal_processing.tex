\section{Some fundamentals of signal processing}\label{section fundamentals} 
\label{review}

In this section, we will recall some fundamentals definitions and results in signal processing. We will only look at discrete-time signals. Throughout this section, we denote $(x_n)_{n\in\mathbb{Z}}$ or $x_n$ a discrete time signal, and $x_k$ the value taken by the signal at time $k$. For example, let us denote $(e_n)$ the impulse signal such that 
\begin{equation}
e_n =
\begin{cases}
    1, n = 0\\
    0, n\neq 0.
\end{cases}  
\label{appendix impulse signal}
\end{equation}
This signal is  useful because the response of a system to a impulse signal gives a lot of insights. In particular it fully describes a linear time-invariant system. For more on signal processing, we refer the reader to \cite{oppenheim1996signals}.

\subsection{Linear Time-invariant systems}

A system is said to be \textit{time-invariant} if its response to a certain input signal does not depend on time. It is said to be \textit{linear} if its output response to a linear combinations of inputs is the same linear combinations of the output responses of the individual inputs. A system is said to be \textit{causal} if the output at a present time depends on the input up the present time only. 

There exist several ways to represent the input-output behavior of LTI system. We will only look at the impulse response representation (convolution). 



\begin{proposition}[Convolution]
    Let $h_n$ be the impulse response of an LTI system $H$ (i.e., the output of system $H$ subject to input $e_n$), and $x_n$ be an input signal. In this case, the output signal of the system $y_n$ writes 
    \begin{equation}
        y_n = \sum_{k=-\infty}^{+\infty}x_kh_{n-k}.
        \label{appendix conv LTI}
    \end{equation}
\end{proposition}


\textit{Causal systems.} The output $y_n$ of a causal system depends only on past or present values of the input. This forces $h_k=0$ for $k<0$ and the convolution sum is rewritten 
\[
y_n = \sum_{k=0}^{+\infty}h_kx_{n-k}.
\]

\textit{Stable systems.} A system is stable if the output is guaranteed to be bounded for every bounded input. 



\subsection{Discrete-Time Fourier Transform}

In this section, we denote $x_n$ a complex-valued discrete-time signal.

\begin{definition}
    The discrete-time Fourier transform of signal $x_n$ is given by
    \[
    X(\omega) = \sum_{n=-\infty}^{+\infty}x_ne^{-i\omega n}.
    \]
    This function takes values in the frequency space.
    The inverse discrete-time Fourier transform is given by 
    \[
    x_n = \frac{1}{2\pi}\int_0^{2\pi}X(\omega)e^{i\omega n}d\omega.
    \]
\end{definition}

The Discrete-Time Fourier transform presents some notable properties that we recall in Table~\ref{table:dtft-properties}.

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|c|c|}
\hline
\textbf{Property} & \textbf{Relation} \\ \hline
Time Shifting & 
$x_{n-k} \overset{DTFT}{\longleftrightarrow} e^{-i\omega k} X(\omega)$ \\ \hline
Convolution in Time & 
$x_n * y_n \overset{DTFT}{\longleftrightarrow} X(\omega) Y(\omega)$ \\ \hline
Frequency Differentiation & 
$j \frac{d}{d\omega} X(\omega) \overset{DTFT}{\longleftrightarrow} -n x_n$ \\ \hline
Differencing in Time & 
$x_n - x{n-1} \overset{DTFT}{\longleftrightarrow} \left(1 - e^{-i\omega}\right) X(\omega)$ \\ \hline
\end{tabular}
\caption{Properties of the Discrete-Time Fourier Transform (DTFT). For each property, assume $x_n\overset{DTFT}{\longleftrightarrow} X(\omega)$ and $y_n\overset{DTFT}{\longleftrightarrow} Y(\omega)$.}
\label{table:dtft-properties}
\end{table}

We recall Parseval's theorem that establishes a fundamental equivalence between the inner product of two signals in the time domain and their corresponding representation in the frequency domain.

\begin{theorem}[Parseval]
    For two complex-valued discrete-time signals \((x_n)\) and \((y_n)\) with discrete-time Fourier transforms \(X(e^{i\omega})\) and \(Y(e^{i\omega})\), Parseval's theorem yields:
    \begin{equation}
        \sum_{n=-\infty}^{+\infty}x_n\overline{y_n} = \frac{1}{2\pi}\int_0^{2\pi}X(e^{i\omega})\overline{Y(e^{i\omega})}d\omega.
        \label{Parseval thm}
    \end{equation}
In particular, Parseval's theorem yields an energy conservation result:
    $$
        \sum_{n=-\infty}^{+\infty}\vert x_n\vert^2 = \frac{1}{2\pi}\int_0^{2\pi}\vert X(e^{i\omega})\vert^2 d\omega.
    $$
\end{theorem}
The following proposition will be useful in our lower bound proof in Appendix~\ref{appendix subsection white noise loss}.
\begin{proposition}\label{proposition semi parseval}
    Let $w_n$ be a causal discrete-time complex-valued signal with Fourier transform $W(\omega)$. We have the following equality:
    \[
    \sum_{L=0}^{+\infty}L\vert w_l\vert^2 = \frac{i}{2\pi}\int_0^{2\pi}\frac{dW(\omega)}{d\omega}\overline{W}(\omega)d\omega.
    \]
\end{proposition}

\begin{proof}
    By definition of the DTFT, $W(\omega) = \sum_{L=0}^{+\infty}w_Le^{-i\omega L}$. Therefore, 
    \begin{align*}
        \sum_{L=0}^{+\infty}L\vert w_L\vert^2 &= \sum_{L=0}^{+\infty}Lw_L\bar{w}_L = \frac{1}{2\pi}\sum_{L=0}^{+\infty}\sum_{L'=0}^{+\infty}Lw_L\bar{w}_{L'}\int_0^{2\pi}e^{-i\omega(L-L')}d\omega\\
        &= \frac{i}{2\pi}\int_0^{2\pi}\sum_{L=0}^{+\infty}-iL\omega_Le^{-iL\omega}\sum_{L'=0}^{+\infty}\bar{w}_{L'}e^{iL'\omega}d\omega.
    \end{align*}
    Provided that the sequence $(Lw_L)_{L\geq 0}$ is summable, $\frac{dW(\omega)}{d\omega}=\sum_{L=0}^{+\infty}-iLw_Le^{-i\omega L}$, which proves the result.
\end{proof}

\subsection{Fourier series}\label{appendix subsection Fourier series}
We recall basics of Fourier Series. For more about Fourier series and their applications, we refer the reader to \cite{serov2017fourier}.

\begin{definition}[Fourier series]
    Let $f: \mathbb{R}\rightarrow \mathbb{R}$ be a piecewise continuous and $2\pi$-periodic function. The Fourier series of $f$ is the series of functions 
    \[
    S(f) = \sum_{n=-\infty}^{+\infty}
c_n(f)e^{int},  
\]
where $c_n(f)$ are the Fourier coefficients of $f$, such that 
\[
c_n(f) = \frac{1}{2\pi}\int_{-\pi}^\pi f(t)e^{-int}dt.
\]
The partial sums of these series write
\[
S_n(f)(t) = \sum_{k=-n}^nc_k(f)e^{ikt}
\]
\end{definition}

\begin{theorem}[Dirichlet]
    Let $f$ be piecewise $\mathcal{C}^1$ and $2\pi$-periodic. Therefore, for every $x\in\mathbb{R}$, $S_n(f)(x)$ converges to 
    \[
    \frac{f(x+0) + f(x-0)}{2},
    \]
    where $f(x+0)$ (resp. $f(x-0)$) denotes the right-hand (resp. left-hand) limit of $f$ at $x$.
\end{theorem}

\paragraph{Remark:}If the function \( f \) is not \( 2\pi \)-periodic, its graph on the interval \([0, 2\pi]\) can be extended periodically over \(\mathbb{R}\). In this case, Dirichlet's theorem is applicable at potential discontinuities at \( 0 \) and \( 2\pi \).

\subsection{A natural pair for autocorrelation}\label{appendix subsection natural pair}

A natural parametrization is to represent autocorrelation with $\gamma(k) = \rho^{\vert k\vert}$ with $\vert\rho\vert < 1$, as done in the main paper. This models exponentially decreasing autocorrelation between data. The natural associated time-frequency pair to represent is 
\[
(\gamma(k), \Gamma(e^{i\omega})) = (\rho^{\vert k\vert}, \frac{1-\rho^2}{\vert 1-\rho e^{-i\omega}\vert^2})
.\]
Indeed, as $\vert\rho\vert<1$, the sequence \((\rho^{\vert k\vert}e^{ik\omega})_{k\in\mathbb{Z}}\) is summable, \(\gamma\) admits a Fourier transform that we denote~$\Gamma$. For $\omega\in\mathbb{R}$.
\begin{align*}
    \Gamma(e^{i\omega}) &= \sum_{k=-\infty}^{+\infty}\rho^{\vert k\vert}e^{-i\omega k} =\sum_{k=1}^{+\infty}\rho^k e^{i\omega k} + \sum_{k=0}^{+\infty}\rho^ke^{-i\omega k}\\
    &= \frac{1}{1-\rho e^{i\omega k}} -1 + \frac{1}{1-\rho e^{-i\omega k}} =\frac{1-\rho^2}{\vert 1-\rho e^{-i\omega}\vert^2}.
\end{align*}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{img/spectral_power_density.pdf}
    \caption{\textit{The autocorrelation factor $\rho$ determines the width of the spectral power density $\Gamma(e^{i\omega})$. The larger $\rho$, the narrower the spectral power density. This means that increasing $\rho$ in $\mathcal{L}_\text{freq}(c, d)$ narrows the bandwidth over which we evaluate the difference $\vert C(e^{i\omega}) - D(e^{i\omega})\vert^2$, leading to improved performance.}}
    \label{figure spectral power density}
\end{figure}
