\section{Upper Bound}\label{section upper bound}

In this section, we complement the previous results, which showed that the lower bound of $\mathcal{L}_\text{time}(c, d)$ for the copy task using linear systems depends on the ratio \(\frac{S}{K}\). We present a closed-form parameterization of the filter that achieves a similar performance differing only by a constant factor. This parameterization serves as an upper bound on the achievable approximation accuracy of linear RNNs on the shift-$K$ task. In particular, we provide explicit expressions for the learnable parameters \(a_s\) and \(b_s\), accompanied by a theoretical analysis of their performance. This formulation establishes a theoretical upper limit for the smallest attainable error and highlights the behavior of a ``good'' filter. Since this upper limit also depends on the ratio \(\frac{S}{K}\), we can infer conclusions about the optimal behavior of the filter, establishing our uncertainty principle and particularly its relation to the spectral width of the data. 
To present our intuitions and results, we convert the time-domain loss $\mathcal{L}_\text{time}$ in Eq.~\eqref{Time domain loss} into its frequency-domain counterpart $\mathcal{L}_\text{freq}$ in Eq.~\eqref{Frequential loss copy task}.



\subsection{Parameterization of the Filter}

Here, we introduce a new filter inspired by the frequency representation of the problem, which achieves promising results on the copy task. $\mathcal{L}_\text{freq}(C, D)$ in Eq.~\eqref{Frequential loss copy task} suggests that a good filter $(c_k)$, denoted by $C(e^{i\omega})$ in the frequency domain, should approximate as best as possible the complex exponential~$e^{-iK\omega}$ for~$\omega~\in~[-\pi,\pi]$.
Additionally, Sec.~\ref{section lower bound} demonstrated that it is not possible to achieve an error smaller than \(1-\frac{S}{K}\) when solving the copy task using linear models on white noise.  Based on these results, we build a greedy approach, where each individual term~\(\frac{b_s}{1-a_se^{-i\omega}}\) of~$C(e^{i\omega})$ captures a single oscillation of the complex exponential. This should result in an error that depends on \(\frac{S}{K}\), and motivates the following representation.

\paragraph{Parameterization of the $\boldsymbol{a_s}$.} 
The parameters \(a_s\) govern the filter's ability to refer to earlier time steps, making them the most critical components of the recurrence. To provide finer control around  the complex unit circle, we employ an exponential parameterization, for $S$ odd:
\begin{equation}
    a_u = \exp\left(-\frac{\alpha}{K}\right)\exp\left(i\frac{\pi s}{K}\right), \quad s \in \llbracket -T, T\rrbracket, \text{ with } S = 2T+1,
    \label{Param_of_the_as}
\end{equation}
where \(0<\alpha\ll K\) so that $\vert a_s\vert<1$ (for stability of the system). The \(a_s\)'s have a constant modulus defined by the parameter \(\alpha\), while their phases are uniformly distributed around the unit circle, separated by an angular distance of \(\frac{\pi}{K}\).

\paragraph{Remark:} This representation in Eq.~\eqref{Param_of_the_as} ensures that the majority of the weight in each individual term \(\frac{b_s}{1-a_se^{-i\omega}}\) is concentrated around the frequency \(\frac{\pi s}{K}\), effectively capturing a single oscillation of the complex exponential. Our goal is to fit \(S\) oscillations of \(e^{-iK\omega}\), which would result in a loss proportional to \(\frac{S}{K}\).



\paragraph{Parameterization of the $\boldsymbol{b_s}$.} We can obtain the $b_s$'s by an approximate minimization as follows:
\begin{lemma}\label{Lemma param of bs}
    Let the parameters $a_s$ of the filter be defined as in Eq.~\eqref{Param_of_the_as}, where $\alpha$ is a positive real number. The asymptotic optimal parameters (when $K\rightarrow+\infty$) $b_s$ that minimize $\mathcal{L}_\text{freq}$ are given by: 
    \begin{equation}
        b_s = \frac{e^{-\alpha}(e^{2\alpha} - e^{-2\alpha})}{2K}(-1)^s, \quad s \in \llbracket -T, T\rrbracket.
        \label{Param_of_the_bs}
    \end{equation}
\end{lemma}

\begin{proof}
As highlighted in Eq.~\eqref{Q}, the approximation error, defined in terms of $a_s$ and $b_s$, is quadratic and convex with respect to $b_s$. Hence, the optimal solution is given by:
\begin{equation}
b = C^{-1}\bar{a}^K,
\label{bs linear system inversion}    
\end{equation}
where the matrix $C$ is defined as $C_{ss'} = \frac{1}{1 - a_s \bar{a}_{s'}}$. Using asymptotic expansions for large $K$, the eigenvector of $C$ corresponds to $z = \left((-1)^s\right)_s \in \mathbb{R}^S$ associated to the eigenvalue $\frac{2}{e^{2\alpha}-e^{-2\alpha}}$, yielding the result, thanks to the asymptotic expansion of $(a_s)$. See full proof in Appendix~\ref{appendix subsection asymptotic bs}.
\end{proof}


Note that $(a_s)$ and $(b_s)$ from complex conjugate pairs; this allows to obtain a real filter.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=1\linewidth]{img/spectral_analysis_2.pdf}

    \vspace*{-.3cm}
    
    \caption{\textit{Poor performance of the filter for white noise data is due to its approximation of the complex exponential over a limited frequency window of size $\frac{\pi S}{K}$. Left: The target filter $\exp(-iK\omega)$ (blue) for $K=450$, and the approximated filter using linear recurrences (green) for $S=90$. The approximation is reasonably accurate within the frequency window of size $\frac{\pi S}{K}$, indicated by the dashed yellow  lines. Outside this window, the filter is zero, demonstrating the inability of filters based on linear recurrences to perfectly memorize long-range data with broad spectra. Right: Contributions from all individual terms $\frac{b_s}{1 - a_s e^{-i\omega}}$ for $s\in\llbracket -45, 45 \rrbracket$. Each individual term captures one oscillation of the complex exponential, making their contributions highly localized. This design reflects the structure of the filter's parameters.}}
    \label{figure spectral analysis}
\end{figure}



\begin{lemma}\label{definition new filter}
    Let $K$ and $S$ be two large integers such that $S \ll K$. Consider the parameters $(a_s)_{s \in \llbracket -T, T \rrbracket}$ from Eq.~\eqref{Param_of_the_as} and $(b_s)_{s \in \llbracket -T, T \rrbracket}$ from Eq.~\eqref{Param_of_the_bs}. Then the spectral representation of the filter is given by
    \begin{equation*}
        C(e^{i \omega}) = \sum_{s=-T}^{T} \frac{b_s}{1 - a_s e^{-i\omega}} = \sum_{s=-T}^{T} \frac{(-1)^s e^{-\alpha}(e^{2\alpha} - e^{-2\alpha})}{2K \big(1 - e^{-\frac{\alpha}{K}} e^{i(\frac{\pi s}{K}-\omega)}\big)}.
    \end{equation*}
\end{lemma}


In the time domain, this filter is approximately equivalent to a shifted sine cardinal, see Fig.~\ref{fig:time domain filter}, highlighting its inherent smoothness and symmetry. The positions of its parameters on the complex plane are strongly influenced by the ratio $S/K$, which corresponds to the horizon of the copy task relative to the order of the linear recurrence. This dependency captures the trade-off between long-term memory and the granularity of the recurrence structure.




\begin{theorem}[Upper bound of the error]\label{thm upper bound}
    Consider $c_k$ the filter defined in Lemma~\ref{definition new filter}, and $(d_k) = (1_{k=K})$ the shift-$K$ filter. Then, for $S,K \to +\infty$ with $S/K \to 0$, we have 
    \begin{equation}
        \mathcal{L}_\text{time}(c, d) \sim 1 - \frac{e^{-2\alpha}(e^{2\alpha} - e^{-2\alpha})}{2} \times \frac{S}{K}.
        \label{Upper bound as and bs}
    \end{equation}
\end{theorem}
\paragraph{Remark:} Note that the relation of $\mathcal{L}_\text{time}$ to $\alpha$ in Theorem~\ref{thm upper bound} incites to take $\alpha$ very large. Nevertheless, this would cause the value of the norm of $b_s$ in Eq.~\eqref{Param_of_the_bs} to explode. In practice, we always chose $\alpha =1$, a choice which also leads to a closer match with HiPPO initialization~(see Section~\ref{sec:hippo}). We further note that our bound on the $b_s$ in Lemma~\ref{Lemma param of bs} is strictly related to the discussion around benefits of complex parametrization in~\citet{ran2024provable}: as $a_s$ become closer to reals~(magnitude increases at equal phase), approximating arbitrary filters requires exploding coefficients~(cf. their Theorem 2). \ \\

When $S \ll K$, the term $\frac{S}{K}$ becomes very small, causing the error in Eq.~\eqref{Upper bound as and bs} to approach 1. We recover the result of Section~\ref{section lower bound}, obtaining a loss that is similar up to a constant factor. This approximation error for our filter serves as an upper bound for the approximation of shift-$K$ filter by linear recurrences.

This behavior can be attributed to the inherent properties of the filter, as illustrated in Fig.~\ref{figure spectral analysis}. The filter approximates reasonably well all the oscillations of $e^{-iK\omega}$ over the frequency window $[\frac{-\pi T}{K}, \frac{\pi T}{K}]$ and vanishes outside this window. Each individual term of the partial fraction decomposition is responsible for capturing a peak of the complex exponential. Therefore, data exhibiting large frequency spectrum like white noise cannot be memorized properly, explaining the poor performance of the filter on our copy task. This is how we designed it, to catch up with the lower bound. This is made precise in the following theorem.

\begin{theorem}\label{convergence to window}
     For $\alpha$ real and positive and $\Omega=\frac{K\omega }{\pi}$, 
     \[C(e^{i\omega}) = 
\sum_{s=-T}^{T} \frac{(-1)^u e^{-\alpha}(e^{2\alpha} - e^{-2\alpha})}{2K \big(1 - e^{-\frac{\alpha}{K}} e^{i(\frac{\pi u}{K}-\frac{\pi\Omega}{K})}\big)} \underset{S/K\rightarrow 0}{\underset{S\rightarrow+\infty}{\sim} }
\begin{cases} 
\frac{e^{-\alpha}(e^{2\alpha}-e^{-2\alpha})}{2}\times\frac{i(-1)^{T+1}\times 2\lfloor\Omega\rfloor}{2\pi(\lfloor\Omega\rfloor-T)(\lfloor\Omega\rfloor+T)} & \text{if } \vert\Omega\vert > T, \\
\frac{e^{-\alpha}(e^{2\alpha}-e^{-2\alpha})}{e^{\alpha}e^{i\pi\Omega}-e^{-\alpha}e^{-i\pi\Omega}} & \text{if } \vert\Omega\vert < T.
\end{cases}
\]
\end{theorem}
In particular, we obtain that $C(e^{i\omega})$ tends to $0$ if $\Omega$ is out of the window $[-T, T]$, while  inside the window, we obtain some oscillations around 1 whose magnitude depends on $\Omega$ (see Fig.~\ref{figure spectral analysis}).


When both $S$ and $K$ tend to infinity, $K$ being significantly larger than $S$, the filter converges to a rectangular window function on the frequency interval $[-\frac{\pi T}{K}, \frac{\pi T}{K}]$, taking the value oscillating around 1 within this interval and 0 outside it. See an illustration in Fig.~\ref{fig:window}. This limitation highlights why the filter performs poorly on white noise, as the uniform spectral density of white noise extends far beyond this narrow frequency window. Conversely, as the frequency window narrows (determined by the autocorrelation $\Gamma(e^{i\omega}))$, the filter becomes better aligned with the target response, leading to improved performance. 

\subsection{Performance in the Autocorrelated case}

The autocorrelation factor \(\Gamma(e^{i\omega})\) exerts a narrowing effect in the frequency domain, reducing the bandwidth of frequencies over which $\mathcal{L}_\text{freq}(C, D)$ is evaluated. See Appendix~\ref{appendix subsection natural pair} for more details. Since our filter is specifically designed to accurately approximate the oscillations of the complex exponential over a frequency window of size \(\frac{\pi S}{K}\), it follows logically that the loss decreases as the autocorrelation factor \(\rho\) approaches 1.

We can compute the loss of the idealized filter in the frequency domain $1_{|\omega| \leqslant \frac{2\pi S}{K}} e^{-i K \omega }$: 
$$
1 - \frac{1}{2\pi}\int_{-\frac{\pi S}{2K}}^\frac{\pi S}{2K} \Gamma(e^{i\omega}) = 
1 - \frac{2}{\pi}
\arctan \Big(
\frac{1+\rho}{1-\rho}\tan  \frac{\pi S}{K}
\Big) \sim 1 -\frac{2}{\pi}
\frac{1+\rho}{1-\rho}  \frac{\pi S}{K},
$$
when $S/K$ goes to zero, which is corresponding to the lower bound in Theorem~\ref{theorem 
autocorrelated lower bound}.


\subsection{Connection with HiPPO Initialization}
\label{sec:hippo}

HiPPO theory~\citep{gu2020hippo} was crucial for the development of modern recurrent models. The main result of this theory is that linear continuous-time ODEs~(linear RNNs, when discretized) can perform online compression of smooth input signals by storing projection onto an $S$-dimensional ~($S$ is the dimension of $x$ in Eq.~\eqref{eq:1}) polynomial basis. Starting from a \textit{dense} HiPPO-inspired $A$ matrix,~\citet{gupta2022diagonal} first proposed to initialize the $A$ matrix in Eq.~\eqref{eq:1} as the diagonal part of its ``diagonal plus low rank'' approximation. \citet{gu2022parameterization} additionally simplified this expression conjecturing~(see their Conjecture 5) a simplified closed-form solution that works well in practice: $a_s = \exp\left(-\frac{\Delta}{2}\right)  \exp\left(i\pi s\Delta\right)$~(S4D-Lin). The parameter~$\Delta$ here is a learnable coefficient resulting from discretization of the approximate HiPPO system. There is no theory indicating how to initialize this coefficient, though further studies~\citep{gu2023how} suggest initializing near $1/K$~($K$ being the sequence length) yields good results. 
Our theory gives grounding to this initialization practice, as well as to the S4D-Lin approximation, using a different viewpoint: our closed-form approximation for the filter $\delta_K$ in Eq.~\eqref{Param_of_the_as} is $a_s = \exp\left(-\frac{\alpha}{K}\right)\exp\left(i\frac{\pi s}{K}\right)$, with $s \in \llbracket -T, T\rrbracket$ and $S = 2T+1$. According to Lemma~\ref{Lemma param of bs}, for numerical stability $\alpha$ should be a small scalar. For $\alpha=1/2$, we get $\exp\left(-\frac{1}{2K}\right)\exp\left(i\frac{\pi s}{K}\right)$, i.e., exactly S4DLin with $\Delta =1/K$. We believe this connection to be a piece of evidence motivating correlation between magnitude and phase in modern variants of S4.
