\begin{definition}[Discrete-Time Fourier Transform]
    For a discrete-time sequence $(u_n)_n$, the discrete-time Fourier transform is, for $\omega\in[0, 2\pi]$,
    \begin{equation}
          U(e^{j\omega})=\sum_{n=-\infty}^\infty u_ne^{-j\omega n}  
    \label{DTFT}
    \end{equation}

    and its inverse Fourier transform 
    \begin{equation}
    u_n = \frac{1}{2\pi}\int_{-\pi}^\pi U(e^{j\omega})e^{j\omega n}d\omega
    \label{inverse DTFT}
    \end{equation}
    
\end{definition}

The \textit{z-Transform} is a generalization of the discrete-time Fourier transform, extending it to complex values of \(z\), whereas the Fourier transform is obtained by evaluating the \textit{z-transform} on the unit circle.


\begin{definition}[z-Transform]
    Given a sequence $(u_n)_n$, for a complex number $z$, the \textit{z-transform} is 
    \begin{equation}
    U(z) = \sum_{n=-\infty}^\infty u_nz^{-n}
    \label{Z-transform}
    \end{equation}
    Comparing \ref{DTFT} and \ref{Z-transform}, the Fourier-transform can be obtained evaluating the \textit{z-Transform} at the unit circle.
\end{definition}
The \textit{z-transform} satisfies the shifting property: if \( (u_n) \) is a discrete-time signal and \( \tau \in \mathbb{Z} \), the shifted signal \( (v_n) = (u_{n-\tau}) \) has the z-transform \( V(z) = z^{-\tau} U(z) \). This property allows to compute the transfer function of a signal defined by difference equations.
\\

We recall Parseval's theorem that establishes a fundamental equivalence between the inner product of two signals in the time domain and their corresponding representation in the frequency domain.

\begin{definition}[Parseval's theorem]
    For two complex-valued discrete-time signals \(x_n\) and \(y_n\) with discrete-time Fourier transforms \(X(e^{j\omega})\) and \(Y(e^{j\omega})\), Parseval's theorem yields:
    \begin{equation}
        \sum_{n=-\infty}^{+\infty}x_n\overline{y_n} = \frac{1}{2\pi}\int_0^{2\pi}X(e^{j\omega})\overline{Y(e^{j\omega})}d\omega
        \label{Parseval thm}
    \end{equation}
In particular, Parseval's theorem yields an energy conservation result:
    \begin{equation*}
        \sum_{n=-\infty}^{+\infty}\vert x_n\vert^2 = \frac{1}{2\pi}\int_0^{2\pi}\vert X(e^{j\omega})\vert^2 d\omega
    \end{equation*}

\end{definition}


Applying the \textit{z-transform} to the difference equation \ref{Difference equation} allows us to compute the transfer function of a linear time-invariant (LTI) system, i.e., the \textit{z-transform} of the impulse response \( (c_n) \) as shown in \ref{LTI convolution filter}. The transfer function \( C(z) \) characterizes the system's input-output relationship and is given by the ratio of the z-transforms of the output and input:
\[
C(z) = \frac{X(z)}{U(z)} = \frac{\sum_{k=0}^S h_k z^{-k}}{\sum_{k=0}^S g_k z^{-k}},
\]
where \( g_0 = 1 \). It can be further decomposed using partial fraction decomposition:
\begin{equation}
C(z) = \sum_{s=-S/2}^{S/2} \frac{b_s}{1 - a_s z^{-1}},
\label{Partial fraction decomposition}
\end{equation}

where \( (a_s) \) are complex numbers with modulus less than 1, and \( (b_s) \) are coefficients. 

The Fourier transform of the impulse response, \( C(e^{j\omega}) \), can be obtained by evaluating the transfer function on the unit circle. This will be of particular relevance later in the paper.

\paragraph{First Case: $\epsilon > 1$} \\
Let us define, for $u \in \mathbb{N}$ and $\alpha > 0$, 
\[
\phi_u(\alpha) = \frac{(-1)^u}{\alpha - i\pi u}.
\]
For any $\alpha > 0$, the series 
\[
\sum_{u=-\infty}^{+\infty} \phi_u(\alpha)
\]
is an alternating series whose general term decreases to 0 in norm. Moreover, the sequence of functions $(\phi_u)_u$ uniformly decreases to 0 on $[0.1, 10]$. Thus, the series of functions $\sum_{u=-\infty}^{+\infty} \phi_u$ converges uniformly on $[0.1, 10]$. 

Now, consider the sum $\sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + \epsilon S)}$ for $\alpha \in [\pi, 10]$. Take $\delta > 0$ and $N \in \mathbb{N}$ such that for any $\alpha$ with $\vert\alpha\vert \in [0.1, 10]$, 
\[
\left| \sum_{u=N}^{+\infty} \phi_u(\alpha) \right| \leq \frac{\delta}{2}.
\]
Decompose $\epsilon$ as $\epsilon = \frac{n}{S} + \frac{\beta}{S}$, where $n = \lfloor \epsilon S \rfloor \in \llbracket S+1, +\infty \rrbracket$ and $\beta \in [0,1]$. We then write:
\begin{align*}
    \sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + \epsilon S)} 
    &= \sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + n + \beta)} \\
    &= \sum_{u=-S+n}^{S+n} \frac{e^{i\pi u}}{\tilde{\alpha} - i\pi u}, \quad \text{with } \tilde{\alpha} = \alpha - i\pi \beta.
\end{align*}
We have $\vert \tilde{\alpha} \vert > 0.1$, and as $S \to +\infty$, $-S+n \to +\infty$. For $S$ such that $-S+n > N$, we find:
\begin{align*}
    \left| \sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + \epsilon S)} \right| 
    &= \left| \sum_{u=-S+n}^{+\infty} \frac{e^{i\pi u}}{\tilde{\alpha} - i\pi u} - \sum_{u=S+n}^{+\infty} \frac{e^{i\pi u}}{\tilde{\alpha} - i\pi u} \right| \\
    &\leq \frac{\delta}{2} + \frac{\delta}{2} = \delta.
\end{align*}

\paragraph{Second Case: $\epsilon < 1$} \\
Consider the sum $\sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + \epsilon S)}$. Decompose $\epsilon$ as $\epsilon = \frac{n}{S} + \frac{\beta}{S}$, where $n = \lfloor \epsilon S \rfloor \in \llbracket -S, S \rrbracket$ and $\beta \in [0,1]$. We then write:
\begin{align*}
    \sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + \epsilon S)} 
    &= \sum_{u=-S}^S \frac{e^{i\pi u}}{\alpha - i\pi(u + n + \beta)} \\
    &= \sum_{u=-S+\lfloor \epsilon S \rfloor}^{S+\lfloor \epsilon S \rfloor} \frac{e^{i\pi u}(-1)^{\lfloor \epsilon S \rfloor}}{\tilde{\alpha} - i\pi u}, \quad \text{with } \tilde{\alpha} = \alpha - i\pi \beta.
\end{align*}
We study the limit as $S \to +\infty$:
\begin{align*}
    \lim_{S \to +\infty} \sum_{u=-S+\lfloor \epsilon S \rfloor}^{S+\lfloor \epsilon S \rfloor} \frac{e^{i\pi u}}{\tilde{\alpha} - i\pi u}
    &= \lim_{S \to +\infty} \left( \sum_{u=-S+n}^{S-n} \frac{(-1)^u}{\tilde{\alpha} - i\pi u} + \sum_{u=S-n+1}^{S+n} \frac{(-1)^u}{\tilde{\alpha} - i\pi u} \right).
\end{align*}
For fixed $\epsilon$, the series $\sum_{u=-\infty}^{+\infty} \frac{(-1)^u}{\alpha - i\pi u}$ converges uniformly with respect to $\alpha$. Thus, even though $\tilde{\alpha}$ depends on $S$, 
\[
\lim_{S \to +\infty} \sum_{u=S-n+1}^{S+n} \frac{(-1)^u}{\tilde{\alpha} - i\pi u} = 0.
\]
We are left with:
\[
\lim_{S \to +\infty} \sum_{u=-S+n}^{S-n} \frac{(-1)^u}{\tilde{\alpha} - i\pi u}.
\]
Since $\tilde{\alpha} = \alpha - i\pi \beta$ does not converge to a fixed value as $S \to +\infty$, for large $S$, we approximate:
\begin{align*}
    \sum_{u=-S+n}^{S-n} \frac{(-1)^u}{\tilde{\alpha} - i\pi u} &\approx \frac{2}{e^{\tilde{\alpha}} - e^{-\tilde{\alpha}}} \\
    &= \frac{2}{e^{\alpha}e^{i\pi \beta} - e^{-\alpha}e^{-i\pi \beta}}, \quad \text{with } \beta = \epsilon S - \lfloor \epsilon S \rfloor.
\end{align*}



\subsection{z-Transforms and Transfer Function}

\paragraph{z-Transform}  
For a complex number \(z = re^{j\phi}\), the z-transform of a discrete-time signal \(x[n]\) is defined as:
\begin{equation}
X(z) = \sum_{n=-\infty}^{+\infty} x[n] z^{-n}, \label{appendix z-transform}
\end{equation}
where \(z\) represents a point in the complex plane. The inverse z-transform is given by:
\[
x[n] = \frac{1}{2\pi \mathrm{i}} \oint X(z) z^{n-1} \, dz,
\]
where the integration is performed along a closed contour within the region of convergence (ROC).  

The relationship between \(x[n]\) and \(X(z)\) is denoted as:
\[
x[n] \overset{z}{\longleftrightarrow} X(z).
\]

The z-transform exists if the infinite sum in \eqref{appendix z-transform} converges. A necessary condition for convergence is the absolute summability of \(x[n]z^{-n}\). Since \(\vert x[n]z^{-n}\vert = \vert x[n]r^{-n} \vert\), the condition becomes:
\[
\sum_{n=-\infty}^{+\infty} \vert x[n] r^{-n} \vert < \infty.
\]
The range of \(r\) for which this condition holds is called the region of convergence (ROC).

Unlike the discrete-time Fourier transform (DTFT), the z-transform exists for certain signals that do not have a DTFT. For any signal \(x[n]\), the DTFT can be obtained by evaluating the z-transform at \(z = e^{j\omega}\).

\paragraph{Properties of the z-Transform}  
The z-transform has several useful properties:
\begin{itemize}
    \item \textit{Time Shift}: \(x[n-n_0] \overset{z}{\longleftrightarrow} z^{-n_0} X(z)\)
    \item \textit{Time Reversal}: \(x[-n] \overset{z}{\longleftrightarrow} X\left(\frac{1}{z}\right)\)
    \item \textit{Convolution}: \(x[n] \ast y[n] \overset{z}{\longleftrightarrow} X(z) Y(z)\)
\end{itemize}

\paragraph{Transfer Function}  
Consider applying the input \(x[n] = z^n\) to a linear time-invariant (LTI) system with impulse response \(h[n]\). The system output \(y[n]\) is given by the convolution of \(h[n]\) and \(x[n]\):
\[
y[n] = h[n] \ast x[n] = \sum_{k=-\infty}^{+\infty} h[k] x[n-k].
\]

Substituting \(x[n] = z^n\) into this expression yields:
\[
y[n] = z^n \left( \sum_{k=-\infty}^{+\infty} h[k] z^{-k} \right).
\]

The transfer function \(H(z)\) is then defined as the z-transform of the system's impulse response \(h[n]\):
\begin{equation}
H(z) = \sum_{k=-\infty}^{+\infty} h[k] z^{-k}. \label{appendix transfer function}
\end{equation}

Thus, the system response to an input \(x[n] = z^n\) is characterized by:
\[
y[n] = H(z) z^n,
\]
where \(H(z)\) encapsulates the system's frequency response in the z-domain.

\paragraph{Transfer Function of an LTI System}  
For a linear time-invariant (LTI) system described by its impulse response \(h[n]\) and input \(x[n]\) via the convolution:
\[
y[n] = h[n] \ast x[n],
\]
the convolution property of the z-transform allows the transformed output \(Y(z)\) to be expressed as the product of the system's transfer function \(H(z)\) and the transformed input \(X(z)\):
\[
Y(z) = H(z) X(z).
\]
This implies that the transfer function can also be defined as the ratio of the z-transform of the output to that of the input:
\[
H(z) = \frac{Y(z)}{X(z)},
\]
where this relationship holds for all \(z\) such that \(X(z) \neq 0\).

The transfer function can be derived directly from the system's difference equation. For an LTI system described by:
\[
\sum_{k=0}^N h_k y[n-k] = \sum_{k=0}^M g_k x[n-k],
\]
applying the time-shift property of the z-transform to \(y[n]\) and \(x[n]\) yields:
\begin{equation}
H(z) = \frac{\sum_{k=0}^M g_k z^{-k}}{\sum_{k=0}^N h_k z^{-k}},
\label{appendix rational TF}
\end{equation}
where \(H(z)\) is a rational transfer function.

The numerator and denominator polynomials in \eqref{appendix rational TF} can be factorized as:
\[
H(z) = \frac{\Tilde{b} z^{-p} \prod_{k=1}^{M-p} (1 - c_k z^{-1})}{z^{-l} \prod_{k=1}^{N-l} (1 - a_k z^{-1})},
\]
where \(\Tilde{b} = b_p / a_l\) is the gain of the system, and \(c_k\) and \(a_k\) are the zeros and poles, respectively. These provide significant insights into the system's characteristics, particularly regarding stability and causality.  

- \textit{Poles and Stability}: A pole located inside the unit circle in the \(z\)-plane (\(\vert a_k \vert < 1\)) contributes an exponentially decaying term to the impulse response, while a pole located outside the unit circle (\(\vert a_k \vert > 1\)) contributes an exponentially growing term. Therefore, for a system to be stable, all its poles must lie strictly inside the unit circle.

The transfer function can also be expressed using partial fraction decomposition:
\begin{equation}
H(z) = \sum_{k=0}^r \frac{b_k}{1 - a_k z^{-1}},
\label{appendix partial fraction decomposition}
\end{equation}
where the poles \(a_k\) determine the system's stability and causality.

In summary, the transfer function encapsulates the system's behavior in the \(z\)-domain, with its poles and zeros providing critical information about the system's dynamic characteristics.




\subsection{A few signal processing tools}

\begin{definition}[Discrete-Time Fourier Transform]
    For a discrete-time sequence $(u_n)$, the discrete-time Fourier transform is, for $\omega\in[0, 2\pi]$,
    \begin{equation}
          U(e^{i\omega})=\sum_{n=-\infty}^\infty u_ne^{-i\omega n}  
    \label{DTFT}
    \end{equation}

    and its inverse Fourier transform 
    \begin{equation}
    u_n = \frac{1}{2\pi}\int_{-\pi}^\pi U(e^{i\omega})e^{i\omega n}d\omega
    \label{inverse DTFT}
    \end{equation}
    
\end{definition}

We recall Parseval's theorem that establishes a fundamental equivalence between the inner product of two signals in the time domain and their corresponding representation in the frequency domain.

\begin{definition}[Parseval's theorem]
    For two complex-valued discrete-time signals \((x_n)\) and \((y_n)\) with discrete-time Fourier transforms \(X(e^{i\omega})\) and \(Y(e^{i\omega})\), Parseval's theorem yields:
    \begin{equation}
        \sum_{n=-\infty}^{+\infty}x_n\overline{y_n} = \frac{1}{2\pi}\int_0^{2\pi}X(e^{i\omega})\overline{Y(e^{i\omega})}d\omega
        \label{Parseval thm}
    \end{equation}
In particular, Parseval's theorem yields an energy conservation result:
    \begin{equation*}
        \sum_{n=-\infty}^{+\infty}\vert x_n\vert^2 = \frac{1}{2\pi}\int_0^{2\pi}\vert X(e^{i\omega})\vert^2 d\omega
    \end{equation*}
\end{definition}

These definitions allow us to transform the time-domain loss \eqref{Time domain loss} into a frequency-domain loss:

\begin{theorem}\label{theorem frequency loss}
    Let \((c_n)=(c_k)_{k \geq 0}\) and \((d_n)=(d_k)_{k \geq 0}\) be discrete-time filters such that \(d_k=1_{k=K}\) and \(c_k=\sum_{s=1}^Sa_s^kb_s\) is its approximation with a linear recurrence of order \(S\). Let \(\gamma : \mathbb{Z} \to \mathbb{R}\) define the autocorrelation such that \(\gamma(k)=\rho^{\vert k\vert}\) for \(\rho > 0\). The approximation error is given by
\begin{equation}
\sum_{k, k'} (c_k - d_k)(c_{k'} - d_{k'}) \gamma(k - k') = \frac{1}{2\pi} \int_{-\pi}^\pi \bigg\vert\sum_{s=1}^{S}\frac{b_s}{1-a_se^{-i\omega}} - e^{-iK\omega}\bigg\vert^2 \Gamma(e^{i\omega}) d\omega
\label{Frequential loss copy task}
\end{equation}
where \(\Gamma(e^{i\omega})\) denotes the discrete-time Fourier transform of the autocorrelation factor \(\gamma\).
\end{theorem}

\begin{proof}
    Denoting \(C(e^{i\omega})\) and \(D(e^{i\omega})\) as the Fourier transforms of \((c_n)\) and \((d_n)\), respectively, Parseval's theorem gives:
    \[
    \sum_{k, k'} (c_k - d_k)(c_{k'} - d_{k'}) \gamma(k - k') = \frac{1}{2\pi} \int_{-\pi}^\pi \bigg\vert C(e^{i\omega}) - D(e^{i\omega})\bigg\vert^2 \Gamma(e^{i\omega}) d\omega.
    \]
    The Fourier transform of \((d_n)\) is \(D(e^{i\omega})=e^{-iK\omega}\). The Fourier transform \(C(e^{i\omega})\) of \((c_n)\) is given by 
    \[
    C(\omega) = \sum_{s=1}^S b_s \sum_{k=-\infty}^\infty \left(a_s e^{-i\omega}\right)^k = \sum_{s=1}^S \frac{b_s}{1 - a_s e^{-i\omega}}.
    \]
\end{proof}

Note that by developing this frequency loss, we come back to \eqref{Time domain loss}. We just transformed the time-domain problem into an complex approximation problem in the frequency space. This representation simply motivates the following parametrization. In a first time, we place ourselves in the white noise case, which is easier to analyze. We extend the results in a second time, showing that they hold in the autocorrelated case.


\begin{proof} \francis{not needed. We are not giving a class, just recalling the basics.}
    Consider the product of a signal $(x_n)$ and the impulse sequence $e_n$, written as 
    \[
    x_ne_n = x_0e_n
    \]
    Generalize this relationship to the product of $(x_n)$ and the time-shifted impulse sequence to obtain 
    \[
    x_ne_{n-k} = x_ke_{n-k}
    \]
    This property allows us to express $(x_n)$ as the following weighted sum of time-shifted impulses:
    \[
    x_n = \sum_{k=-\infty}^{+\infty}x_ke_{n-k}
    \]
    Now use the linearity property to interchange the system operator $H$ with the summation and signal values $x[k]$ to obtain 
    \begin{align*}
        y_n &= \sum_{k=-\infty}^{+\infty}x_kH\{e_{n-k}\}\\
        &=\sum_{k=-\infty}^{+\infty}x_kh_{n-k}
    \end{align*}
\end{proof}

An LTI system is bounded if $\sum_{k=-\infty}^{+\infty}\vert h_k\vert < \infty$ \francis{ is this needed?}

\begin{proof} \francis{ is this needed?}
    Let $x_n$ be a bounded input signal: $\vert x_n \leq M_x < \infty$. The magnitude of the output is given by 
    \begin{align*}
        \vert y_n\vert &= \vert h_n\ast x_n\vert\\
        &=\big\vert \sum_{k=-\infty}^\infty h_kx_{n-k}\big\vert\\
        &\leq \sum_{k=-\infty}^\infty\vert h_k\vert \vert x_{n-k}\vert\\
        &\leq M_x\sum_{k=-\infty}^\infty\vert h_k\vert
    \end{align*}
    Therefore, if $h_n$ is summable, $y_n$ is bounded for every bounded input $x_n$. 
\end{proof}

\subsubsection{Difference equations}
\francis{ is this needed?}
Linear constant-coefficients difference equations provide another way to represent the input-output characteristics of LTI in the time domain. Such an equation has the following form:
\[
\sum_{k=0}^N h_ky_{n-k} = \sum_{k=0}^M g_kx_{n-k}
\]
The integer $N$ is termed the order of the difference equation and corresponds to the maximum memory involving the system output. It represents the number of energy storage devices in the system. 


\begin{align*}
    (b_u) &= (C^{-1}\bar{a}^K)_u\\
    &= \big(\frac{M^{-1}}{K}\bar{a}^K\big)_u + \big[\big( C^{-1} - \frac{M^{-1}}{K}\big)\bar{a}^K\big]_u\\
    &= \big(\frac{M^{-1}_{\infty}}{K}\bar{a}_\infty^K\big)_u + \frac{1}{K}\big[\big(M^{-1}\bar{a}^K\big)_u - \big(M^{-1}_\infty \bar{a}_\infty^K\big)_u\big] + \big[\big( C^{-1} - \frac{M^{-1}}{K}\big)\bar{a}^K\big]_u.
\end{align*}

First, according to Lemma \ref{lemma eigenvector Toeplitz},
\[
\big(\frac{M^{-1}_{\infty}}{K}\bar{a}_\infty^K\big)_s= \frac{e^{-\alpha}(e^{2\alpha} - e^{-2\alpha})}{2K}(-1)^s.
\]

Second, \alex{i cant bound this because I struggle to express $M^{-1}$ wrt $M$}

Third, \begin{align*}
    \big\vert\big[\big( C^{-1} - \frac{M^{-1}}{K}\big)\bar{a}^K\big]_u\big\vert^2    &=\big\vert\big[\big(-C^{-1}(C - KM)\frac{M^{-1}}{K}\big)\bar{a}^K\big]_u\big\vert^2\\
    &\leq e^{-\alpha}\cdot\| C^{-1}\|^2\cdot\|\frac{M^{-1}}{K}\|^2\| C-KM\|^2\\
    &= e^{-\alpha}\frac{\kappa_2(C)}{\| C\|^2}\cdot\frac{\kappa_2(M)}{K\| M\|^2}\cdot\| C - KM\|^2.
\end{align*}

First, we bound $\| C-KM\|^2$.
\begin{align*}
    \| C - KM\|^2 &= \sum_{s, s'}\big\vert\frac{1}{1-e^{-2\alpha/K}e^{i(s-s')\pi/K}} - \frac{K}{2\alpha - i(s-s')\pi}\big\vert^2\\
    &= \sum_{s, s'}\big\vert \frac{2\alpha -i(s-s')\pi - K(1 - e^{-2\alpha/K}e^{i(s-s')\pi/K})}{(1-e^{-2\alpha/K}e^{i(s-s')\pi/K})(2\alpha - i(s-s')\pi)}\big\vert^2\\
    &= \sum_{s, s'}\big\vert\frac{2\alpha - i(s-s')\pi - K\big[\frac{2\alpha}{K} -i\frac{(s-s')\pi}{K} + \frac{1}{2}\big(\frac{4\alpha^2}{K^2} - \frac{(s-s')^2\pi^2}{K^2} -\frac{4i\pi\alpha(s-s')}{K^2} + o(\frac{1}{K^2})\big)\big]}{(1-e^{-2\alpha/K}e^{i(s-s')\pi/K})(2\alpha - i(s-s')\pi)}\big\vert^2\\
    &=\sum_{s, s'}\big\vert\frac{\frac{2\alpha^2}{K} - \frac{\pi^2(s-s')^2}{2K} - \frac{2i\pi\alpha(s-s')}{K} + o(\frac{1}{K})}{(1-e^{-2\alpha/K}e^{i(s-s')\pi/K})(2\alpha - i(s-s')\pi)}\big\vert^2\\
    &=\frac{1}{K^2}\sum_{s, s'}\big\vert\frac{2\alpha^2 - \frac{\pi^2(s-s')^2}{2} - 2i\pi\alpha(s-s') + o(1)}{(1-e^{-2\alpha/K}e^{i(s-s')\pi/K})(2\alpha - i(s-s')\pi)}\big\vert^2\\
    &= O\big(T^2\big). \text{\alex{it is empirically true, is it formally rigorous ?}}
\end{align*}


Now, we bound $\| C\|^2$. We have 
\begin{align*}
    \| C\|^2 &= \sum_{s, s'}\frac{1}{\big\vert1 - e^{-2\alpha/K}e^{i(s-s')\pi/K}\big\vert^2}\\
    &=\sum_{s, s'}\frac{1}{\big(1-e^{-2\alpha/K}\cos(\frac{(s-s')\pi}{K}\big)^2 + e^{-4\alpha/K}\sin^2(\frac{(s-s')\pi}{K})}\\
    &= \sum_{s, s'}\frac{1}{\big(1 + e^{-4\alpha/K} - 2e^{-2\alpha/K}\cos(\frac{(s-s')\pi}{K})\big)}\\
    &=\sum_{s, s'}\frac{1}{1 + e^{-4\alpha/K} - 2e^{-2\alpha/K}\big(1 - \frac{(s-s')^2\pi}{2K^2} + o(\frac{1}{K^2})\big)}\\
    &= \sum_{s, s'}\frac{1}{2 - \frac{4\alpha}{K} + \frac{8\alpha}{K^2} + o(\frac{1}{K^2}) - 2\big[1 - \frac{(s-s')^2\pi^2}{2K^2}-\frac{2\alpha}{K}+\frac{2\alpha^2}{K^2}+o(\frac{1}{K^2})\big]}\\
    &= \sum_{s, s'}\frac{K^2}{4\alpha^2 + (s-s')^2\pi^2 + o(1)}\\
    &= K^2\sum_{\Delta=-2T}^{2T}\frac{2T + 1}{4\alpha^2 + \Delta^2 + o(1)}\\
    &=O(K^2T)
\end{align*}

So $\| C^{-1}\|^2 = O(\frac{1}{K^2T})$. \alex{this is true only if the condition number is bounded}

Now we bound $\| (KM)\|^2$. We recall that $M(s, s') = \frac{1}{2\alpha + i(s-s')\pi}$. So 
\begin{align*}
    \| KM \|^2 &= K^2\sum_{s, s'}\big\vert \frac{1}{2\alpha + i(s-s')\pi}\big\vert^2\\
    &= K^2\sum_{s, s'}\frac{1}{4\alpha^2 + (s-s')^2\pi^2}\\
    &= O(K^2T).
\end{align*}

Therefore, 
\[
 \big\vert\big[\big( C^{-1} - \frac{M^{-1}}{K}\big)\bar{a}^K\big]_u\big\vert = O\big(\frac{1}{K^2}\big).
\]

We can finally conclude that 
\[
b_s= \big(\frac{M^{-1}_{\infty}}{K}\bar{a}_\infty^K\big)_s= \frac{e^{-\alpha}(e^{2\alpha} - e^{-2\alpha})}{2K}(-1)^s + O\big(\frac{1}{K^2}\big).
\]
\end{proof}