\section{Related Work}
\label{sec:related_work}

\textbf{Transformer-Based Video Super-Resolution (VSR) Models:} 
Transformer-based architectures, such as Video Restoration Transformer (VRT) cite{liang2022vrt} and Recurrent Video Restoration Transformer (RVRT)____, leverage global attention to model long-term temporal dependencies, achieving state-of-the-art performance in VSR. However, their high computational cost and memory footprint make them impractical for real-time applications or deployment on resource-constrained devices ____. Progressive Sparse Representation Transformer (PSRT) ____ improves efficiency using a recurrent design but still suffers from high latency. While these transformer-based methods achieve strong reconstruction quality, their computational and memory requirements limit their utility for deployment in low-resource settings.

\textbf{Lightweight VSR Models:} 
Several recent works have focused on reducing model complexity while maintaining competitive performance. Efficient Lightweight Network for Video Super-Resolution (ELNVSR) ____ introduces a bidirectional alignment module and a multi-scale pyramid block to reduce redundancy and improve feature aggregation. Similarly, Information Refinement Network (IRN)____ employs ConvNeXt blocks with residual structures, effectively balancing parameter efficiency and accuracy. However, these models still struggle with motion compensation and temporal coherence, particularly in challenging real-world scenarios.  

A notable contribution in lightweight VSR is WaveMixSR____, which employs wavelet transforms to extract multi-scale representations. By leveraging joint spatial and frequency-domain processing, WaveMixSR enhances texture restoration while reducing redundant spatial computations. However, despite its advantages, it does not integrate effective memory mechanisms for long-term temporal dependencies, leading to frame inconsistencies in videos.

\textbf{Deformable Convolutions for Motion Alignment:}  
Deformable convolutions have proven highly effective in handling motion misalignment in VSR. Enhanced Deformable Video Restoration (EDVR) ____ introduced deformable alignment layers that dynamically predict spatial offsets for better motion compensation. Basic Video Super-Resolution++ (BasicVSR++) ____ further refined this approach by incorporating bidirectional propagation with deformable convolutions, leading to improved performance in dynamic scenes. However, while these methods enhance motion alignment, they often introduce additional parameters, increasing computational complexity.  

%Our work builds on the strengths of deformable convolutions but incorporates residual deformable convolutions, which improve feature reuse and reduce the need for excessive parameterization. [MOVED TO INTRO]

\textbf{Memory-Augmented Architectures for Temporal Consistency:}  
To address temporal inconsistencies in VSR, several models integrate memory-based architectures. RealBasicVSR ____ introduces a dynamic refinement module that progressively reduces artifacts by leveraging long-term dependencies. Similarly, RVRT ____ incorporates memory mechanisms to improve video consistency across frames. However, these methods still rely on high computational budgets, making them less viable for low-resource applications.  

%Our proposed memory tensor module efficiently retains past frame information while avoiding the memory overhead of recurrent-based methods. This approach enhances temporal stability without excessive model complexity. [Moved to intro.]

\textbf{Efficient Upsampling and Multi-Scale Feature Extraction:}  
Efficient upsampling plays a crucial role in lightweight VSR models. Dynamic Context-Guided Upsampling (DCGU) ____ improves detail reconstruction by leveraging non-local sampling, enhancing fine-texture restoration with reduced computational cost. Meanwhile,wavelet-based methods have gained attention due to their ability to capture structural information across different frequency scales.  

We integrate \textbf{wavelet-based multi-scale feature extraction} in our framework to improve detail preservation while reducing redundant computations. Unlike traditional spatial convolutions, wavelet transformations enable a more efficient and parameter-effective method of capturing high-frequency details.

Building upon these advancements, we propose a convolution-based VSR model that achieves state-of-the-art performance while remaining computationally efficient. Unlike transformer-heavy methods, our approach incorporates:
\begin{itemize}
    \item \textbf{Residual Deformable Convolutions} for precise frame alignment with minimal overhead.
    \item \textbf{Memory Tensors} to enhance long-term temporal consistency without the need for excessive memory buffers.
    \item \textbf{Wavelet-Based Feature Extraction} for multi-scale detail enhancement while reducing computational redundancy.
    \item \textbf{Parameter-Efficient Design}, achieving superior performance on REDS4 and other benchmark datasets with only \textbf{2.3M parameters} and significantly fewer FLOPs compared to transformer-based approaches.
\end{itemize}

Our model demonstrates that by strategically integrating \textbf{memory mechanisms, residual networks, and deformable convolutions}, it is possible to \textbf{achieve high-quality VSR while maintaining low computational costs}, making it suitable for real-world applications such as video streaming, surveillance, and mobile devices.