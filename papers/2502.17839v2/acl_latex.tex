% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors

\usepackage{inconsolata}
\usepackage{multicol}
\usepackage{float}
\usepackage{subcaption} % For subfigures
\usepackage{caption}

\usepackage{tabularx}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{amsmath}

\usepackage{paracol}
\usepackage{listings}
\lstset{breaklines=true}

\usepackage{wrapfig}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\newcommand{\edit}[1]{\textcolor{blue}{#1}}
\definecolor{darkgreen}{RGB}{0,100,0}


\title{Say Less, Mean More: \\Leveraging Pragmatics in Retrieval-Augmented Generation}

\author{%
Haris Riaz$^{*}$ \and Ellen Riloff \and Mihai Surdeanu\\
University of Arizona, Tucson, AZ, USA\\
\texttt{\{hriaz,msurdeanu\}@arizona.edu} \quad \texttt{riloff@cs.arizona.edu}
} 

\begin{document}
\maketitle

% Define the star footnote:
\def\thefootnote{*}\footnotetext{Corresponding author.}

% Restore numeric footnotes
\def\thefootnote{\arabic{footnote}}

\begin{abstract}
We propose a simple, unsupervised method that injects pragmatic principles in retrieval-augmented generation (RAG) frameworks such as Dense Passage Retrieval~\cite{karpukhin2020densepassageretrievalopendomain} to enhance the utility of retrieved contexts. 
Our approach first identifies which sentences in a pool of documents retrieved by RAG are most relevant to the question at hand, cover all the topics addressed in the input question and no more, and then highlights these sentences within their context, before they are provided to the LLM, without truncating or altering the context in any other way. We show that this simple idea brings consistent improvements in experiments on three question answering tasks (ARC-Challenge, PubHealth and PopQA) using five different LLMs. It notably enhances relative accuracy by up to 19.7\% on PubHealth and 10\% on ARC-Challenge compared to a conventional RAG system.
\end{abstract}

\section{Introduction}

\label{sec:intro}
Retrieval-augmented generation (RAG)~\cite{lewis2020retrieval} has emerged as a solution to the limited knowledge horizon of large language models (LLMs). RAG combines ``pre-trained parametric and non-parametric memory for language generation,''~\cite{lewis2020retrieval} with the non-parametric memory typically retrieved from large collections of documents. RAG has been shown to dramatically improve the performance of LLMs on various question-answering and reasoning tasks (see section \ref{sec:related-work}). However, we argue that RAG often overwhelms the LLM with too much information, only some of which may be relevant to the task at hand. This contradicts Grice's four maxims of effective communication~\cite{grice1975logic}, which state that the information provided should be ``as much as needed, and no more'' and that it should be ``as clear, as brief'' as possible. The four maxims are enumerated as follows: (1) \textit{Maxim of Quantity}: Provide as much information as needed, but no more; (2) \textit{Maxim of Quality}: Be truthful; avoid giving information that is false or unsupported; (3) \textit{Maxim of Relation}: Be relevant, sharing only information pertinent to the discussion; (4) \textit{Maxim of Manner}: Be clear, brief, and orderly; avoid obscurity and ambiguity. While these maxims were originally formulated in the context of human communication, we argue that they are also applicable in a RAG setting.

We propose a simple, unsupervised method that injects pragmatics in any RAG framework\footnote{Code is available at: \url{https://github.com/hriaz17/SayLessRAG}}. In particular, our method: (a) identifies which sentences in a pool of documents retrieved by RAG are most relevant to the question at hand (maxim of relation), and cover all the topics addressed in the input question and no more (maxim of quantity and manner);\footnote{We envision that the maxim of quality could be considered too by identifying factual statements~\cite{rudinger-etal-2018-neural-models}. We leave this for future work.} and (b) highlights these sentences within their original contexts before they are provided to the LLM. Table~\ref{tab:example} shows an example of our method in action. 

The contributions of our paper are:
{\flushleft {\bf (1)}} We introduce a strategy to introduce pragmatics into any RAG method such as Dense Passage Retrieval~\cite{karpukhin2020densepassageretrievalopendomain}. To our knowledge, we are the first to investigate the impact of pragmatics for RAG.
\vspace{-2mm}
{\flushleft {\bf (2)}} We evaluate the contributions of pragmatics in RAG on three datasets: ARC-Challenge \cite{Clark2018ThinkYH}, PubHealth \cite{kotonya2020explainable} and PopQA \cite{mallen2023llm_memorization} and with five different LLMs ranging from 1B to 7B parameters: Mistral-7B-Instruct-v0.1 \cite{jiang2023mistral7b}, Alpaca-7B \cite{alpaca}, Llama2-7B-chat \cite{touvron2023llama2openfoundation}, Qwen2.5-3B \cite{qwen2.5} and AMD-OLMo-1B-SFT \cite{AMD-OLMo}. Our results indicate that pragmatics helps the most when the QA task primarily involves single-hop or multi-hop logical deduction where the highlighted evidence comprises factual statements that can be sequentially chained to derive the answer. Our post-hoc analysis further shows that this approach fares especially well for queries that benefit from analogical reasoning; with highlighted evidence sentences resembling in-context learning exemplars, proving especially useful for smaller language models with limited reasoning capabilities such as AMD-OLMo-1B-SFT, enabling a 10\% relative improvement on ARC-Challenge for this model.
{\flushleft {\bf (3)}} We find that pragmatics is less effective when the QA task requires arithmetic manipulation, or involves subtleties such as \textit{double negation}. Furthermore, we find that for factoid QA tasks, if a set of ambiguous contexts are first retrieved by DPR for a given query where 
the query lacks disambiguating information and multiple plausible answers could be derived, our method struggles to identify the appropriate evidence sentences for highlighting. In such cases, incorrect evidence highlighting can yield a slight degradation in LLM performance.
{\flushleft {\bf (4)}} Our empirical evidence suggests that our method is complementary when paired with a strong retriever like DPR; in favorable cases it can improve performance by up to 20\%, while exhibiting minimal degradation (approximately 1\%) in less optimal scenarios. Thus, we present it as a low risk and low overhead default augmentation to standard DPR implementations.

\begin{table}
\begin{small}
\begin{tabular}{>{\centering\arraybackslash}m{3mm}|p{0.4\textwidth}}
  \toprule
  \rotatebox[origin=b]{90}{
  %Documents with highlighted evidence
  %~~~~~~} &
  Highlighted evidence
  ~~~~~~~} &
  \vspace{-9mm}
  [\dots] 
  Bats are famous for using echolocation to hunt down their prey, using sonar sounds to capture them in the dark. Another reason for nocturnality is avoiding the heat of the day. \textcolor{blue}{{\bf <evidence>This is especially true in arid biomes like deserts, where nocturnal behavior prevents creatures from losing precious water during the hot, dry daytime.</evidence>}} This is an adaptation that enhances osmoregulation. One of the reasons that (cathemeral) lions prefer to hunt at night is to conserve water.
  \\
  \midrule
  \rotatebox[origin=c]{90}{MCQ~~~~~~~~~~~~~~~~~~~~~} & 
  \vspace{-7mm}
  Question: Many desert animals are only active at night. How does being active only at night most help them survive in a hot desert climate?
  \vspace{2mm}
  
  Choices: 
  \vspace{-2mm}
  \begin{enumerate}
    \renewcommand{\labelenumi}{\Alph{enumi}.}
    \item They can see insects that light up at night.
    \vspace{-2mm}
    \item Their bodies lose less water in the cool night air.
    \vspace{-2mm}
    \item They are able to find more plant food by moonlight.
    \vspace{-2mm}
    \item Their bodies absorb sunlight in the daytime while they sleep.
  \end{enumerate} \\
  \bottomrule
\end{tabular}
\caption{\footnotesize Example of a multiple-choice question (MCQ) from the ARC-C dataset \cite{Clark2018ThinkYH} together with a fragment of a supporting document retrieved, in which the relevant evidence is highlighted with ``$<$evidence$>$'' tokens by our pragmatics-inspired algorithm. This evidence highlighting allows the downstream LLM to identify the correct answer (option B).}
\label{tab:example}
\end{small}
\end{table}

\input{latex/sections/related-work}
\begin{figure*}[t]
    \centering
    \includegraphics[width=\textwidth, height=0.3\textheight, keepaspectratio]
    {./latex/figures/diagram-new.png}
    \caption{\footnotesize Our proposed method. Each query is concatenated with a more abstract \textit{Step-back} version of itself synthesized by a \textit{Step-back} LLM. This new query is used initiate multi-hop retrieval where in each hop the query is aligned with passages retrieved by DPR to select one evidence sentence. These sentences are aggregated across hops with alignment at each hop driven by query reformulation based on \textit{missing information} (maxim of relation) between the current set of selected evidence sentences and current query. After all query keywords are covered by the retrieved evidences (maxim of quantity), our method highlights them within their original contexts and provides them to the LLM.}
    \label{fig:SayLessRAG-diagram}
\end{figure*}

\begin{table*}[h]
  \centering
  \footnotesize
    \resizebox{\linewidth}{!}{
    \setlength{\tabcolsep}{3.5mm}{
    \begin{tabular}{llll}
    \toprule
    \textbf{\footnotesize Settings} & \textbf{\footnotesize ARC-C} & \textbf{\footnotesize PubHealth} & \textbf{\footnotesize PopQA} \\
    \midrule
    \textit{\footnotesize No Retrieval} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 62.39 (\textcolor{darkgreen}{+6.72\%}) & \footnotesize 74.82 (\textcolor{darkgreen}{+0.96\%}) & \footnotesize 32.52 (\textcolor{red}{-49.73\%}) \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 34.02 (\textcolor{red}{-17.43\%}) & \footnotesize 43.25 (\textcolor{red}{-7.78\%}) & \footnotesize 30.24 (\textcolor{red}{-53.04\%}) \\
    \footnotesize \quad Llama2-7B \vspace{1mm} & \footnotesize 40.94 (\textcolor{red}{-9.78\%}) & \footnotesize 68.02 (\textcolor{darkgreen}{+10.57\%}) & \footnotesize 23.73 (\textcolor{red}{-64.07\%}) \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize \textbf{78.12} (\textcolor{darkgreen}{+7.28\%}) & \footnotesize 65.89 (\textcolor{red}{-7.15\%}) & \footnotesize 26.38 (\textcolor{red}{-62.39\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT \vspace{1mm} & \footnotesize 25.81 (\textcolor{red}{-0.17\%}) & \footnotesize 60.81 (\textcolor{darkgreen}{+0.00\%}) & \footnotesize 33.38 (\textcolor{red}{-44.14\%}) \\
    \midrule
    \textit{\footnotesize DPR (No Evidence Highlighting)} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 58.46 & \footnotesize 74.11 & \footnotesize 64.69 \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 41.20 & \footnotesize 46.90 & \footnotesize 64.40 \\
    \footnotesize \quad Llama2-7B-chat \vspace{1mm} & \footnotesize 45.38 & \footnotesize 61.52 & \footnotesize 66.05 \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize 73.33 & \footnotesize 70.96 & \footnotesize 75.48 \\
    \footnotesize \quad AMD-OLMo-1B-SFT \vspace{1mm} & \footnotesize 25.64 & \footnotesize 60.81 & \footnotesize 59.76 \\
    \midrule
    \textit{\footnotesize DPR + Evidence Highlighting + No Step-back} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 59.23 (\textcolor{darkgreen}{+1.32\%}) & \footnotesize 76.04 (\textcolor{darkgreen}{+2.60\%}) & \footnotesize 63.90 (\textcolor{red}{-1.22\%}) \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 41.28 (\textcolor{darkgreen}{+0.19\%}) & \footnotesize 50.56 (\textcolor{darkgreen}{+7.80\%}) & \footnotesize 63.83 (\textcolor{red}{-0.89\%}) \\
    \footnotesize \quad Llama2-7B-chat \vspace{1mm} & \footnotesize 47.44 (\textcolor{darkgreen}{+4.54\%}) & \footnotesize \footnotesize 62.64 (\textcolor{darkgreen}{+1.82\%}) & \footnotesize 65.98 (\textcolor{red}{-0.10\%}) \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize 73.25 (\textcolor{red}{-0.11\%}) & \footnotesize 71.17 (\textcolor{darkgreen}{0.3\%}) & \footnotesize \textbf{77.34} (\textcolor{darkgreen}{+2.46\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT \vspace{1mm} & \footnotesize 28.21 (\textcolor{darkgreen}{+10.02\%}) & \footnotesize 61.02 (\textcolor{darkgreen}{+0.35\%}) & \footnotesize 60.54 (\textcolor{darkgreen}{+1.31\%}) \\
    \midrule
    \textit{\footnotesize DPR + Evidence Highlighting + Step-back} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct & \footnotesize 59.57 (\textcolor{darkgreen}{+1.90\%}) & \footnotesize \textbf{76.14} (\textcolor{darkgreen}{+2.74\%}) & \footnotesize 64.19 (\textcolor{red}{-0.77\%}) \\
    \footnotesize \quad Alpaca-7B & \footnotesize 41.37 (\textcolor{darkgreen}{+0.41\%}) & \footnotesize 56.14 (\textcolor{darkgreen}{+19.70\%}) & \footnotesize 64.05 (\textcolor{red}{-0.54\%}) \\
    \footnotesize \quad Llama2-7B-chat \vspace{1mm} & \footnotesize 47.95 (\textcolor{darkgreen}{+5.66\%}) & \footnotesize 66.40 (\textcolor{darkgreen}{+7.94\%}) & \footnotesize 65.76 (\textcolor{red}{-0.43\%}) \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize 73.08 (\textcolor{red}{-0.34\%}) & \footnotesize 70.15 (\textcolor{red}{-1.14\%}) & \footnotesize 77.48 (\textcolor{darkgreen}{+2.65\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT \vspace{1mm} & \footnotesize 28.21 (\textcolor{darkgreen}{+10.02\%}) & \footnotesize 62.03 (\textcolor{darkgreen}{+2.01\%}) & \footnotesize 60.47 (\textcolor{darkgreen}{+1.19\%}) \\
    \bottomrule
    \end{tabular}%
    }
    }
    \caption{\footnotesize Our pragmatics driven RAG versus a Standard DPR RAG setup. \textbf{Bold} numbers indicate the best performance among all methods and LLMs for a specific dataset.  Percentage changes relative to the \textit{DPR without Evidence Highlighting} setting are shown in parentheses. Positive changes are highlighted in \textcolor{darkgreen}{green}, negative in \textcolor{red}{red}. In the \textit{No Retrieval} setting, we do not retrieve any documents and test the LLM's parametric knowledge. \textit{DPR (No Evidence Highlighting)} refers to the setting where we provide the top-$K$ passages for each query to the LLM without highlighting any evidence sentences within those passages. In the \textit{DPR + Evidence Highlighting + No Step-back} setting, we provide DPR passages annotated with highlighted evidences using ``$<$evidence$>$'' tokens. The \textit{DPR + Evidence Highlighting + Step-back} setting extends the previous setting by introducing reformulated queries and answer choices using Step-back prompting.
    }
  \label{tab:pragmatics_rag}%
\end{table*}
\begin{table*}[h]
\centering
\footnotesize % Reduce font size for a more compact table
\setlength{\tabcolsep}{3pt} % Reduce space between columns
\renewcommand{\arraystretch}{0.9} % Reduce space between rows
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}p{7cm} *{3}{>{\centering\arraybackslash}X}}
\toprule
\textbf{Dataset and Setting} & \textbf{Llama-2â€“7B-chat} & \textbf{Alpaca-7B} & \textbf{Mistral-7B-Instruct} \\
\midrule
ARC-C \textit{(Evidences w/ Context)} & 47.95 & 41.37 & 59.57 \\
ARC-C \textit{(Evidences w/o Context)} & 47.69 (\textcolor{red}{-0.54\%}) & 38.03 (\textcolor{red}{-8.07\%}) & 58.29 (\textcolor{red}{-2.14\%}) \\
PubHealth \textit{(Evidences w/ Context)} & 66.40 & 56.14 & 76.14 \\
PubHealth \textit{(Evidences w/o Context)} & 54.82 (\textcolor{red}{-17.44\%}) & 49.34 (\textcolor{red}{-12.11\%}) & 62.23 (\textcolor{red}{-18.27\%}) \\
\bottomrule
\end{tabularx}
\caption{\footnotesize Performance of various models on ARC-C and PubHealth datasets when using highlighted evidences within their original context versus using highlighted evidences while discarding surrounding context. Percentage changes (decreases) are shown in parentheses relative to the full context setting. Using highlighted evidence without its surrounding context can significantly degrade the LLMs QA performance. }
\label{tab:highlighted_justifications}
\end{table*}
\input{latex/sections/approach}
\begin{table*}[h]
  \centering
  \footnotesize
    \resizebox{\linewidth}{!}{
    \setlength{\tabcolsep}{3.5mm}{
    \begin{tabular}{llll}
    \toprule
    \textbf{\footnotesize Settings} & \textbf{\footnotesize ARC-C} & \textbf{\footnotesize PubHealth} & \textbf{\footnotesize PopQA} \\
    \midrule
    \textit{\footnotesize No Retrieval} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 62.39 (\textcolor{darkgreen}{+9.11\%}) & \footnotesize \textbf{74.82} (\textcolor{darkgreen}{+34.23\%}) & \footnotesize 32.52 (\textcolor{darkgreen}{+18.17\%}) \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 34.02 (\textcolor{red}{-16.02\%}) & \footnotesize 43.25 (\textcolor{darkgreen}{+17.05\%}) & \footnotesize 30.24 (\textcolor{red}{-22.66\%}) \\
    \footnotesize \quad Llama2-7B \vspace{1mm} & \footnotesize 40.94 (\textcolor{darkgreen}{+0.22\%}) & \footnotesize 68.02 (\textcolor{darkgreen}{+0.15\%}) & \footnotesize 23.73 (\textcolor{red}{-0.29\%}) \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize \textbf{78.12} (\textcolor{darkgreen}{+6.30\%}) & \footnotesize 65.89 (\textcolor{darkgreen}{+51.30\%}) & \footnotesize 26.88 (\textcolor{darkgreen}{+0.83\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT \vspace{1mm} & \footnotesize 25.81 (\textcolor{darkgreen}{+0.00\%}) & \footnotesize 60.81 (\textcolor{darkgreen}{+0.00\%}) & \footnotesize 33.38 (\textcolor{darkgreen}{+4.25\%}) \\
    \midrule
    \textit{\footnotesize BM25 (No Evidence Highlighting)} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 57.18 & \footnotesize 55.74 & \footnotesize 27.52 \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 40.51 & \footnotesize 36.95 & \footnotesize \textbf{39.10} \\
    \footnotesize \quad Llama2-7B \vspace{1mm} & \footnotesize 40.85 & \footnotesize 67.92 & \footnotesize 23.80 \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize 73.50 & \footnotesize 43.55 & \footnotesize 32.38 \\
    \footnotesize \quad AMD-OLMo-1B-SFT  \vspace{1mm} & \footnotesize 25.81 & \footnotesize 60.81 & \footnotesize 32.02 \\
    \midrule
    \textit{\footnotesize BM25 + Evidence Highlighting + No Step-back} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct  \vspace{1mm} & \footnotesize 58.38 (\textcolor{darkgreen}{+2.10\%}) & \footnotesize 62.23 (\textcolor{darkgreen}{+11.64\%}) & \footnotesize 29.16 (\textcolor{darkgreen}{+5.96\%}) \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 40.17 (\textcolor{red}{-0.84\%}) & \footnotesize 53.91 (\textcolor{darkgreen}{+45.90\%}) & \footnotesize 37.81 (\textcolor{red}{-3.30\%}) \\
    \footnotesize \quad Llama2-7B \vspace{1mm} & \footnotesize 47.69 (\textcolor{darkgreen}{+16.74\%}) & \footnotesize 62.23 (\textcolor{red}{-8.38\%}) & \footnotesize 33.88 (\textcolor{darkgreen}{+42.35\%}) \\
    \footnotesize \quad Qwen-2.5-3B \vspace{1mm} & \footnotesize 75.13 (\textcolor{darkgreen}{+2.22\%}) & \footnotesize 42.84 (\textcolor{red}{-1.63\%}) & \footnotesize 35.53 (\textcolor{darkgreen}{9.73\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT  \vspace{1mm} & \footnotesize 25.13 (\textcolor{red}{-2.63\%}) & \footnotesize 59.39 (\textcolor{red}{-2.33\%}) & \footnotesize 33.10 (\textcolor{darkgreen}{+3.37\%}) \\
    \midrule
    \textit{\footnotesize BM25 + Evidence Highlighting + Step-back} \vspace{1mm} &       &       &  \\
    \footnotesize \quad Mistral-7B-Instruct \vspace{1mm} & \footnotesize 58.72 (\textcolor{darkgreen}{+2.69\%}) & \footnotesize 62.64 (\textcolor{darkgreen}{+12.38\%}) & \footnotesize 29.24 (\textcolor{darkgreen}{+6.25\%}) \\
    \footnotesize \quad Alpaca-7B \vspace{1mm} & \footnotesize 40.00 (\textcolor{red}{-1.26\%}) & \footnotesize 45.69 (\textcolor{darkgreen}{+23.65\%}) & \footnotesize 38.46 (\textcolor{red}{-1.64\%}) \\
    \footnotesize \quad Llama2-7B \vspace{1mm} & \footnotesize 47.61 (\textcolor{darkgreen}{+16.55\%}) & \footnotesize 61.93 (\textcolor{red}{-8.82\%}) & \footnotesize 34.31 (\textcolor{darkgreen}{+44.16\%}) \\
    \footnotesize \quad Qwen-2.5-3B  \vspace{1mm} & \footnotesize 74.62 (\textcolor{darkgreen}{+1.52\%}) & \footnotesize 43.05 (\textcolor{red}{-1.15\%}) & \footnotesize 34.88  (\textcolor{darkgreen}{7.72\%}) \\
    \footnotesize \quad AMD-OLMo-1B-SFT  \vspace{1mm} & \footnotesize 25.38 (\textcolor{red}{-1.67\%}) & \footnotesize 60.61 (\textcolor{red}{-0.33\%}) & \footnotesize 33.02 (\textcolor{darkgreen}{+3.12\%}) \\
    \bottomrule
    \end{tabular}%
    }
    }
    \caption{\footnotesize Our pragmatics driven RAG versus a BM25 RAG setup. \textbf{Bold} numbers indicate the best performance among all methods and LLMs for a specific dataset. Percentage changes relative to the BM25 \textit{without Evidence Highlighting} setting are shown in parentheses. Positive changes are highlighted in \textcolor{darkgreen}{green}, negative in \textcolor{red}{red}. In the \textit{No Retrieval} setting, we do not retrieve any documents and test the LLM's parametric knowledge. 
    \textit{BM25 (No Evidence Highlighting)} refers to the setting where we provide the top-$K$ passages for each query to the LLM without highlighting any evidence sentences within those passages.
    In the \textit{BM25 + Evidence Highlighting + No Step-back setting}, we provide BM25 passages annotated with highlighted evidences using ``$<$evidence$>$'' tokens.  The \textit{BM25 + Evidence Highlighting + Step-back} setting extends the previous setting by introducing reformulated queries and answer choices using Step-back prompting.}
  \label{tab:bm25_results}%
\end{table*}


\input{latex/sections/results}

\begin{figure}[!htb]
  \centering
  % \includegraphics[width=\columnwidth]{latex/figures/dpr_settings_comparison_subplots.png}
    \includegraphics[width=\columnwidth]{latex/figures/dpr_settings_comparison_subplots_granular.png}
  \caption{Performance of Qwen2.5-3B on: (\textbf{top}) ARC-Challenge, \textbf{(middle)} PopQA, (\textbf{bottom}) PubHealth under different \textit{Evidence Highlighting} settings, with varying top-$k$ where $k$ is the number of DPR contexts retrieved.}
  \label{fig:top-k}
\end{figure}

% \vspace{-2mm}

\begin{table*}[h]
\centering
\footnotesize
\begin{tabular}{lcc}
\toprule
\textbf{Category} & \textbf{Frequency (ARC-Challenge)} & \textbf{Frequency (PubHealth)} \\
\midrule
\textbf{Bad} (0) & 6 & 8 \\
\textbf{Medium} (0.5) & 10 & 4 \\
\textbf{Good} (1) & 4 & 8 \\
\bottomrule \\
\end{tabular}
\caption{\footnotesize Highlighted Evidence Quality Scores for 20 randomly sampled queries from the ARC-Challenge and PubHealth datasets. The frequencies represent the number of instances falling into each quality category for the highlighted evidence in both datasets.}
\label{tab:evidence_quality_scores}
\end{table*}

\input{latex/sections/analysis}

\input{latex/sections/conclusions}

\section*{Limitations}
This study investigates the effectiveness of pragmatics in enhancing Retrieval Augmented Generation (RAG) systems. Our evaluation, however, is limited to a comparison against standard Dense Passage Retriever (DPR) and BM25 baselines. The proposed method has potential for integration with more sophisticated RAG systems, such as those developed by \newcite{asai2024selfrag, xu2024recomp, sarthi2024raptor}. Our assessment encompasses three datasets, but a more comprehensive evaluation would involve a broader range of single-hop and multi-hop tasks. Moreover, there are several scenarios which our approach does not cover, such as handling linguistic phenomena like negation, mathematical reasoning tasks and reconciling retrieved contexts that are ambiguous. Our current approach is also limited by the fact that it is unsupervised and query reformulation is mostly driven by a bag-of-words. One could trivially improve query reformulation by using an LLM, or using a weakly supervised strategy that fine-tunes an LLM to retrieve pragmatic evidence (using supervision from the current retriever) via a joint loss that learns to retrieve evidence sentences while simultaneously answering the query correctly (motivated by the relevance estimator and answer marginalization losses proposed by \newcite{kim2024reragimprovingopendomainqa}). We leave the exploration of supervised pragmatic RAG methods as future work.

While we hypothesize that our retrieved \& highlighted justifications constitute ``shallow chains of thought'' which are faithfully utilized by the Large Language Model in its generations, this assertion remains to be formally validated through rigorous analysis.
% Since December 2023, a "Limitations" section has been required for all papers submitted to ACL Rolling Review (ARR). This section should be placed at the end of the paper, before the references. The "Limitations" section (along with, optionally, a section for ethical considerations) may be up to one page and will not count toward the final page limit. Note that these files may be used by venues that do not rely on ARR so it is recommended to verify the requirement of a "Limitations" section and other criteria with the venue in question.

% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
% ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}
\input{latex/sections/appendix}

\end{document}
