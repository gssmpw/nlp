\section{Related Work}
\label{sec:related-work}
Since it was first proposed~\cite{lewis2020retrieval}, RAG has become an essential arrow in the quiver of LLM tools. However, many of the proposed RAG approaches rely on supervised learning to jointly optimize the retrieval component and the LLM~\citep[inter alia]{lewis2020retrieval,guu2020realmretrievalaugmentedlanguagemodel,xu2024recomp,kim2024reragimprovingopendomainqa} or to decide ``when to retrieve''~\cite{asai2024selfrag}. Instead, our approach is training free: it uses a set of unsupervised heuristics that approximate Grice's maxims (refer to Section~\ref{sec:intro}). 
Part of our method is similar to Active-RAG, which also reformulates the input query \cite{jiang2023activeretrievalaugmentedgeneration}. However, unlike Active-RAG, we use pragmatics to reformulate the input query and retrieve evidence for it,  instead of relying on LLM probabilities.
Our work is also similar to~\cite{xu2024recomp} and \cite{sarthi2024raptor}, which also touch on pragmatics by reducing the quantity of text presented to the LLM through summarization. However, the method used in \cite{xu2024recomp} is supervised. Furthermore, both of these methods exhibit considerably higher overhead compared to our proposed approach, which relies on simple yet robust heuristics. 

Our method adopts a {\em pre-retrieval} reasoning approach that is complementary to post-retrieval reasoning approaches such as \cite{trivedi2023interleavingretrievalchainofthoughtreasoning,kim2023treeclarificationsansweringambiguous},
which reason after document retrieval.
Further, we do not focus on reasoning about whether the retrieval was useful or not \cite{islam2024openrag}.
For example, current approaches that incorporate reasoning into the QA task, such as rStar \cite{qi2024mutualreasoningmakessmaller}, use an LLM to guide MCTS, where each intermediate step in the tree is verified by another LLM. \cite{jiang2024ragstarenhancingdeliberativereasoning} demonstrate that, rather than relying solely on the LLMâ€™s parametric knowledge, retrieved contexts can also enhance tree search.
Another reasoning-based approach, STaR \cite{zelikman2022starbootstrappingreasoningreasoning}, employs an LLM to iteratively generate and refine a training set of rationales. The LLM is then fine-tuned on these rationales, generates a new set of rationales, and repeats the process.
In contrast, our method integrates reasoning directly into retrieval in a more efficient manner; specifically, we first reason about the task and then retrieve using the simple technique described in \cite{zheng2024stepbackevokingreasoning}.

Lastly, our work focuses on improving the utility of retrieved documents, somewhat similar to CRAG \cite{yan2024corrective}. However, we do not improve utility by retrieving more documents (e.g., from a web search) but rather by highlighting useful information already present in the current set of documents through pragmatics. Several previous methods, especially those based on summarization \cite{xu2024recomp} reduce the text by chopping it. Ours does not. The key idea of our work is to extract more utility \textit{while keeping the full text}.