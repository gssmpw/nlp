%%%%%%%% ICML 2025 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

\usepackage[letterpaper]{geometry}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.



% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2025preprint}


\setcounter{tocdepth}{2}
%\usepackage{cleveref}
\usepackage{hyperref}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2025preprint}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \theoremstyle{plain}
% \newtheorem{theorem}{Theorem}[section]
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{corollary}[theorem]{Corollary}
% \theoremstyle{definition}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{assumption}[theorem]{Assumption}
% \theoremstyle{remark}
% \newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
%\icmltitlerunning{Importance Sampling via Score-based Generative Models}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Additional packages added by me
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{tensor}
\usepackage{pifont}

\usepackage[capitalize,noabbrev]{cleveref}
\usepackage{multirow}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}%[section]
%\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{proposition}{Proposition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}{Lemma}%[section]
\newtheorem{corollary}{Corollary}%[section]
\theoremstyle{definition}
%\newtheorem{definition}[theorem]{Definition}
\newtheorem{definition}{Definition}%[section]
%\newtheorem{problem}[theorem]{Problem}
%\newtheorem{problem}{Problem}%[section]
%\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{assumption}{Assumption}%[section]
%\theoremstyle{remark}
\theoremstyle{definition}
%\newtheorem{remark}[theorem]{Remark}
\newtheorem{remark}{Remark}%[section]


\input{math_commands.tex}
\usepackage{titletoc}
\usepackage{wrapfig} % for wrapping text around figures
\newtheorem{problem}{Problem}%[section]
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{algpseudocode}
\algtext*{EndWhile}% Remove "end while" text
\algtext*{EndIf}% Remove "end if" text
\algtext*{EndFor}% Remove "end while" text
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\makeatletter
% start with some helper code
% This is the vertical rule that is inserted
\newcommand*{\algrule}[1][\algorithmicindent]{%
  \hspace*{.2em}% <------------- This is where the rule starts from
  \vrule %height .75\baselineskip depth .25\baselineskip
  \hspace*{\dimexpr#1-.2em-.4pt}%
}

\newcommand{\StatePar}[1]{%
  \State\parbox[t]{\dimexpr\linewidth-\ALG@thistlm}{\strut #1\strut}%
}
\renewcommand{\ALG@beginalgorithmic}{\offinterlineskip}% Remove all interline skips

\newcount\ALG@printindent@tempcnta
\def\ALG@printindent{%
  \ifnum \theALG@nested > 0% is there anything to print
    \ifx\ALG@text\ALG@x@notext% is this an end group without any text?
      % do nothing
    \else
      \unskip
      % draw a rule for each indent level
      \ALG@printindent@tempcnta=1
      \loop
        \algrule[\csname ALG@ind@\the\ALG@printindent@tempcnta\endcsname]%
        \advance \ALG@printindent@tempcnta 1
        \ifnum \ALG@printindent@tempcnta<\numexpr\theALG@nested+1\relax
      \repeat
        \fi
    \fi
}
% the following line injects our new indent handling code in place of the default spacing
\patchcmd{\ALG@doentity}{\noindent\hskip\ALG@tlm}{\ALG@printindent}{}{\errmessage{failed to patch}}
% end vertical rule patch for algorithmicx
\makeatother

% Add \struts to keywords
\algrenewcommand\algorithmicend{\strut\textbf{end}}
\algrenewcommand\algorithmicdo{\strut\textbf{do}}
\algrenewcommand\algorithmicwhile{\strut\textbf{while}}
\algrenewcommand\algorithmicfor{\strut\textbf{for}}
\algrenewcommand\algorithmicforall{\strut\textbf{for all}}
\algrenewcommand\algorithmicloop{\strut\textbf{loop}}
\algrenewcommand\algorithmicrepeat{\strut\textbf{repeat}}
\algrenewcommand\algorithmicuntil{\strut\textbf{until}}
\algrenewcommand\algorithmicprocedure{\strut\textbf{procedure}}
\algrenewcommand\algorithmicfunction{\strut\textbf{function}}
\algrenewcommand\algorithmicif{\strut\textbf{if}}
\algrenewcommand\algorithmicthen{\strut\textbf{then}}
\algrenewcommand\algorithmicelse{\strut\textbf{else}}

\algrenewcommand\algorithmicrequire{\strut\textbf{Input:}}
\algrenewcommand\algorithmicensure{\strut\textbf{Output:}}

\let\oldState\State
\renewcommand{\State}{\oldState\strut}


\def\NoNumber#1{{\def\alglinenumber##1{}\State #1}\addtocounter{ALG@line}{-1}}

\begin{document}


\title{Importance Sampling via Score-based Generative Models}

\author{Heasung Kim, Taekyun Lee, Hyeji Kim, and Gustavo de Veciana}

\date{%
    {Department of Electrical and Computer Engineering\\
    \vspace{1mm}The University of Texas at Austin\\\vspace{1mm} Austin, TX 78712 USA}
    }

\maketitle


\begin{abstract} 
         Importance sampling, which involves sampling from a probability density function (PDF) proportional to the product of an importance weight function and a base PDF, is a powerful technique with applications in variance reduction, biased or customized sampling, data augmentation, and beyond. 
        Inspired by the growing availability of score-based generative models (SGMs), we propose an entirely training-free Importance sampling framework that relies solely on an SGM for the base PDF. 
        Our key innovation is realizing the importance sampling process as a backward diffusion process, expressed in terms of the score function of the base PDF and the specified importance weight function--both readily available--eliminating the need for any additional training.
        We conduct a thorough analysis demonstrating the method's scalability and effectiveness across diverse datasets and tasks, including importance sampling for industrial and natural images with neural importance weight functions. 
        The training-free aspect of our method is particularly compelling in real-world scenarios where a single base distribution underlies multiple biased sampling tasks, each requiring a different importance weight function. To the best of our knowledge our approach is the first importance sampling framework to achieve this.
\end{abstract}

\section{Introduction}


\let\thefootnote\relax\footnotetext{\emph{Preprint.} Correspondence to: Heasung
Kim <heasung.kim@utexas.edu> \\ Source code: \href{https://github.com/Heasung-Kim/importance-sampling-via-score-based-generative-models}{https://github.com/Heasung-Kim/importance-sampling-via-score-based-generative-models}}

Score-based Generative Models (SGMs) have proven to be a very effective tool for sampling from high dimensional distributions~\cite{ho2020ddpm, song2021ddim, song2021score}. Increasingly SGMs are being made available to capture a wide variety of data sets, including images~\cite{dhariwal2021diffusion, pmlr-v139-ramesh21a}, audio~\mbox{\cite{kong2021diffwave, chen2021wavegrad}}, and wireless environments~\cite{lee2024generating, zhang2024denoising}. 
In this work, we consider the following problem: {\em Given an SGM, can we design a strategy for generating samples that satisfy pre-specified characteristics, e.g., samples corresponding to rare events or high losses on a downstream task?} Formally, this might be viewed as a form of importance sampling, where the aim is to generate representative ``important” samples.  


Mathematically, importance sampling is defined as follows: Consider a Probability Density Function (PDF) $p: \mathbb{R}^{d} \mapsto [0,1]$ over the domain $\mathbb{R}^{d}$ of the random vector $\rmX$, and importance weight function $l: \mathbb{R}^{d} \mapsto \mathbb{R}_{+}$ where $\mathbb{R}_{+}$ denotes the set of positive real values. The concept of importance sampling entails drawing samples from a modified PDF $q$, whose PDF is proportional to the product of the importance weight function $l$ and the original PDF $p$. Formally, the importance sampling PDF is given by: 
\begin{definition}
    \label{problem:clustered_federated_learning}
    (Importance Sampling PDF)
    %\vspace{-0.5mm}
    \begin{equation}
    \label{importance sampling_PDF_definition}
        q(\rvx) = \frac{ l(\rvx) p(\rvx) }{\int l(\rvx) p(\rvx) \,\mathrm{d}\rvx}
    \end{equation}
    %\vspace{-4.5mm}
\end{definition}






Importance sampling is a versatile technique with demonstrated effectiveness across various applications, including variance minimization in mean estimation, data augmentation, selective feature analysis, and bias and fairness considerations~\cite{robert2004monte, byrd2019effect, cortes2010learning, kamiran2012data}. %@Taekyun 


In real-world scenarios, given a single base PDF \( p(\rvx) \) or samples drawn from it, we often seek to perform multiple importance sampling with different importance weight functions \( l(\rvx) \). 
% In real-world scenarios, a single base PDF $p(\rvx)$ often supports diverse tasks requiring different importance weight functions $l(\rvx)$. 
For example, $l(\rvx)$ can be designed to prioritize underrepresented classes, refining sampling to meet varying fairness criteria. Alternatively, $l(\rvx)$ can represent a loss function, enabling the sampling of $\rvx$ that induces high loss values. This allows for the identification of inputs associated with poor task model performance. Such flexibility highlights the power of importance sampling in addressing a wide range of practical challenges.


%These variations highlight the need for a flexible and efficient importance sampling framework.



%% \paragraph{Challenges.}  
Despite its advantages, existing importance sampling methods face critical challenges: They typically require training or fine-tuning separate generative models for multiple importance sampling distributions corresponding to each and every weight function $l(\rvx)$, a process that is computationally prohibitive and inefficient, particularly in scenarios involving multiple or dynamic importance weight functions. Therefore, we seek computationally efficient sampling methods that can adapt to multiple importance weight functions. 

%\paragraph{Opportunities and Problem Formulation.}  Recent advancements in Score-based Generative Models (SGMs) \cite{ho2020ddpm, song2021ddim, song2021score} present new opportunities to address these challenges. SGMs have proven successful in generating high-quality samples across domains such as images, audio, and other complex datasets, and they are increasingly trained on large datasets, making the score functions of extensive base distributions more accessible. This progress leads to the following critical question: given access to the score function of a base distribution, can we efficiently generate importance samples for a variety of weight functions? Addressing this question forms the foundation of our proposed approach.


 % Our specific objective is to devise an efficient algorithm that can handle varying weight functions $l(\rvx)$, enabling dynamic external control over the distribution to produce samples with targeted characteristics.

% 
% \paragraph{Problem Formulation.} Motivated by the benefits and challenges, this paper develops an algorithm capable of sampling $\rmX$ from the importance sampling distribution $q(\rvx)$. We consider a scenario where the score function of the original distribution, $\nabla_{\rvx} \log p(\rvx)$, is provided, accessible through score-based generative modeling techniques due to recent significant progress \cite{ho2020ddpm, song2021ddim, song2021score}. Our specific objective is to devise an efficient algorithm that can handle varying $l(\rvx)$, enabling dynamic external control over the distribution to produce samples with targeted characteristics.


% Furthermore, additional practical contexts leverage adaptive importance sampling with varying $l$, such as computing mean estimates under diverse target functions or performing fairness-driven sampling under multiple criteria. Training separate generative models for each instance of $l$ would be computationally prohibitive and inefficient in terms of storage.





\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{fig/main_banner/main_banner_ver3.pdf}
    %\vspace{-5mm}
    \caption{
    \textbf{\emph{Top}}: Sampling process for $\rmX' \sim p(\rvx)$. \textbf{\emph{Bottom}}: Importance sampling process for $\rmX \sim q(\rvx)$. The proposed method utilizes the pretrained $\nabla_{\rvx} \log p_{t}(\rvx)$ and given importance weight function $l(\rvx)$ to compute $\nabla_{\rvx} \log q_{t}(\rvx)$ \textbf{\emph{without necessitating any additional training}}.
    }
    \label{fig:main_banner}
    %\vspace{-6mm}
\end{figure}



\paragraph{Contributions.} The {\em main contribution} of this paper is the development of a novel approach to efficiently generate importance samples from a target distribution $q(\rvx)$ given only the score function of the base distribution $p(\rvx)$, without explicitly learning $q(\rvx)$ or its score function. 
Our key innovation lies in deriving an approximate representation for the time-dependent score function of $q(\rvx)$ %denoted by $\nabla_{\rvx} \log q_{t}(\rvx)$, 
in terms of the score function of $p(\rvx)$ %, denoted by $\nabla_{\rvx} \log p_{t}(\rvx)$, 
and the weight function $l(\rvx)$ (Sec. \ref{section_importance_sampling_via_score_based_generative_models}). This approximation allows us to model the importance sampling process as a backward diffusion process, which \emph{does not require any additional training of generative models}. To the best of our knowledge, this is the first score-based importance sampling framework that does not require direct training of the importance sampling PDF or its score function.

%{\color{blue}[Explain Figure 1 - shrink one peak / or something... qT q0 etc... ] For example, We provide an example in Fig.~\ref{fig:main_banner}.... explain the figure. ..Based on this approximation, we model the importance sampling process as a backward diffusion process that evolves from time $t\!=\!T$ to $t\!=\!0$ as illustrated in Fig.~\ref{fig:main_banner}. }


%Fig. \ref{fig:main_banner} is a conceptual illustration of two backward diffusion processes where the first process (top) initiates from Gaussian noise and transitions to a bimodal distribution (base PDF) using the time-dependent score function $\nabla_{\rvx} \log p_{t}(\rvx)$. The second (bottom) represents an importance sampling process, generating samples following a single-peaked importance sampling PDF (which is single-peaked due to the importance weight $l(\rvx)$). Importance sampling requires  $\nabla_{\rvx} \log q_{t}(\rvx)$ but Instead of learning the score function $\nabla_{\rvx} \log q_{t}(\rvx)$, we utilized Our key innovation lies in deriving an approximate representation for $\nabla_{\rvx} \log q_{t}(\rvx)$ in terms of $\nabla_{\rvx} \log p_{t}(\rvx)$ and $l(\rvx)$, effectively leveraging these accessible and known quantities, intead of training a new score function.

Fig. \ref{fig:main_banner} conceptually illustrates two backward diffusion processes. The first (top) transitions from a Gaussian distribution to a bimodal base PDF using the score function $\nabla_{\rvx} \log p_{t}(\rvx)$. The second (bottom) depicts an importance sampling process targeting a single-peaked PDF (shaped by the importance weight $l(\rvx)$), requiring $\nabla_{\rvx} \log q_{t}(\rvx)$. Instead of learning $\nabla_{\rvx} \log q_{t}(\rvx)$, we approximate it in terms of $\nabla_{\rvx} \log p_{t}(\rvx)$ and $l(\rvx)$, effectively leveraging the accessible and known quantities, making our approach training-free and scalable.

\paragraph{Theoretical Development.} We provide a detailed derivation of how training-free importance sampling is achieved and conduct a technical analysis of the approximation accuracy within the proposed framework (Sec. \ref{section_importance_sampling_via_score_based_generative_models}).

\paragraph{Empirical Validation.} We thoroughly evaluate the sampling accuracy by assessing how well our generated importance samples approximate the target importance sampling distribution across various synthetic scenarios (Sec. \ref{experiments_closed_form}).
\paragraph{Applications.} The versatility of our approach enables importance sampling for \emph{any differentiable importance weight function} $l(\rvx)$, including those modeled as neural networks. This allows us to address several challenging sampling tasks that existing importance sampling methods struggle to handle efficiently, such as: Designing $l(\rvx)$ as a distortion measure computed by a neural autoencoder for a specific downstream task, enabling the targeted sampling of high-distortion-inducing instances (Sec. \ref{experiments_csi}); Utilizing a neural classifier as $l(\rvx)$ to enable training-free, dynamic class-wise bias/uniformity sampling, even in \emph{SGMs that have never been trained with class labels} (Sec. \ref{section:celebA_stablecascade}-1); Defining $l(\rvx)$ based on image characteristics, such as color or frequency emphasis, to sample images with desired attributes—achieving a new level of sampling control beyond traditional prompt conditioning (Sec. \ref{section:celebA_stablecascade}-2) 

    

These results underscore the scalability and adaptability of our method, positioning it as a powerful and generalizable approach for importance sampling in SGMs.



\paragraph{Clarifying the Scope of Work.}  
We state that our work is {\emph{fundamentally distinct}} from conditional sampling with SGMs \cite{nichol2022glide, podell2024sdxl} and methods refining SGMs to improve output quality, such as \cite{kim2023refining}. Conditional sampling typically involves training SGMs with conditions, whereas our approach focuses on training-free importance sampling with an {\emph{externally defined}} importance weight function that operates independently of the original distribution. This also differs from approaches refining diffusion processes using trained discriminators to enhance SGM outputs or solve inverse problems \cite{rout2024beyond, rout2024solving, chungdiffusion}.
Additionally, prior work applied SGMs to annealed importance sampling for variance reduction in distribution estimation \cite{doucet2022score}, whereas we recover the importance sampling for an independently defined importance weight function—tackling an entirely different problem. %For further discussion on related work and distinctions, see Appendix \ref{sec:related}.




%We are aware of prior work exploring the integration of 
%Prior work has explored integrating importance sampling with SGMs to reduce variance in SGM processes \cite{doucet2022score}. However, our objective is distinct: %to recover the importance sampling distribution corresponding to an independently defined importance weight, rather than using importance sampling to improve SGM performance. 
%Rather than using importance sampling to enhance SGM performance, we aim to recover the importance sampling distribution corresponding to an independently defined importance weight. 
%For additional discussion on related work and distinctions, see Appendix \ref{sec:related}.

%Prior work has explored integrating importance sampling with SGMs to reduce variance in distribution estimation \cite{doucet2022score}. However, our objective is fundamentally different: rather than leveraging importance sampling to enhance SGM performance, we focus on recovering the importance sampling distribution associated with an independently defined importance weight function. For further discussion on related work and distinctions, see Appendix \ref{sec:related}.


\section{Background on SGM}
%In order to generate 
The score-based generative modeling approaches aim to learn the score function of the target data distribution, $\nabla_{\rvx} \log q(\rvx)$. This is achieved through a parameterized model, typically implemented as a neural network, to approximate the true score function.  
%
A notable innovation in score-based generative modeling is the use of score functions for noise-perturbed data rather than relying solely on the score function of the original PDF. Learning the score function of noise-perturbed data enables the modeling of data generation as a Stochastic Differential Equation (SDE) and also leads to more robust training of the score function \cite{song2021score}. Specifically, a continuous-time noise perturbation process, or diffusion process, can be represented by the following SDE.
\begin{equation}
\label{true_forward_sde}
    \mathrm{d} \rmX_{t} = f(\rmX_{t}, t) \, \mathrm{d}t + \sigma(t) \, \mathrm{d} \rmW_{t},
\end{equation}
where $\rmX_{0} \sim q(\rvx)$, implying that $\rmX_{t}$ at $t = 0$ follows the target distribution we aim to learn. In this context, $f: \mathbb{R}^{d} \times [0,T] \mapsto \mathbb{R}^{d}$ represents the drift coefficient, $\sigma(t): [0,T]\mapsto \mathbb{R}$ denotes the diffusion coefficient, and $\mathrm{d} \rmW_{t}$ indicates multidimensional Brownian motion. As time $t$ progresses, the distribution of $\rmX_{t}$ evolves, which we denote as $q_t(\rvx)$.

When the score function $\nabla_{\rvx} \log q_t(\rvx)$ is known, this framework enables sampling of $\rmX_{0}$ that follows PDF $q_{0} = q$ via a corresponding backward SDE \cite{anderson1982reverse} which is given by 
\begin{align}
\mathrm{d}\rmX_t &= b_{1}(\rmX_t, t) \,\mathrm{d}t \;+\; \sigma(t)\,\mathrm{d}\tilde{\rmW}_{t}, 
\label{true_backward_sde}\\
\text{where\quad} b_{1}(\rvx, t) &= f(\rvx, t) \;-\; \sigma(t)^2 \nabla_{\rvx} \log q_{t}(\rvx)
\notag
\end{align}
with  $\rmX_{t} \sim q_{t}$ and $\mathrm{d} \tilde{\rmW}_{t}$ denoting the Brownian motion associated with the reverse-time process.
%
For instance, given an initial sample $\rmX_{T} \sim q_{T}(\rvx)$, solving SDE (\ref{true_backward_sde}) yields a sample $\rmX_{0}$ with distribution $q_0$. Typically, for sufficiently large values of $T$, a realization $\rvx_{T}$ can be initialized as Gaussian noise.

Following convention \cite{ho2020ddpm, lugmayr2022repaint, nichol2021improved, choi2021ilvr}, we consider the following drift and diffusion coefficients,
\begin{align*}
f(\rvx,t) = -\frac{1}{2} \beta(t) \rvx  \quad \text{and} \quad  \sigma(t) = \sqrt{\beta(t)}
\end{align*}
where $\beta(t)$ is a predefined scalar-valued continuous function such that $0 \leq \beta(t) \leq 1$. Here, in defining $\sigma(t)$ and $f(\rvx,t)$, we apply a slight abuse of notation: the scalar-vector multiplication in this context represents the elementwise multiplication of the vector by the scalar.

%Despite advances in score-based models, learning $\nabla_{\rvx} \log q_{t}(\rvx)$ to perturb importance sampling remains challenging, limiting its direct application. Existing score-based models require samples from the target distribution (the importance sampling PDF) to learn its score function, but such samples are typically unavailable in practice. Additionally, many applications require importance sampling across different importance weight functions $l$, which would necessitate separate models for each $l$ in current methods—an approach that is computationally prohibitive and inefficient in storage.

%We address these challenges by introducing a novel approach that represents the score function of perturbed importance samples in terms of the score function of $p_{t}$ and $l$, both accessible or known quantities. This framework allows us to learn the score function of $p_{t}$ using existing techniques, thereby enabling direct sampling of $\rvx$ from the target distribution $q_0$.


\paragraph{Notation.} 
The symbol $\mathrm{d}$ denotes an infinitesimal increment. $\Vert \cdot \Vert$ indicates the spectral norm for matrices and the Euclidean ($L_2$) norm for vectors. We denote Gaussian and Uniform distributions by $\mathcal{N}$ and $\mathcal{U}$.
%$\mathbb{N}$ is the set of positive integers. For $k \in \mathbb{N}$, $[k]\coloneqq\{1, 2, \dots, k\}$. 
 %Bold uppercase letters (e.g., $\rmX$) denote random vectors, with their realizations in bold lowercase (e.g., $\rvx$). 



\section{Importance Sampling via SGM (ISSGM)}
\label{section_importance_sampling_via_score_based_generative_models}

\subsection{Problem Formulation}
%\paragraph{Objective.} 
Given an SGM that models a base distribution $p(\rvx)$ and a desired weight function $l(\rvx)$, our ultimate goal is to devise an algorithm that can draw samples from the importance sampling PDF $q(\rvx) = \frac{ l(\rvx) p(\rvx) }{\int l(\rvx) p(\rvx) \,\mathrm{d}\rvx}$, 
where $l$ is a positive function as $l(\rvx) \ge  m$ and $m>0$. We assume that the logarithms of $p,q,l$ are twice continuously differentiable with respect to $\rvx$. %Reflecting a practical scenario, we assume that the data instances sampled from the original distribution $p$ are available, not from $q$. \% or score?



\subsection{Proposed method}
% we wanna handle....
% 1. cannot train q cuz no samples from q
% 2. may not wannt train a score function for q... 

%
%% In this section, we introduce a novel method that addresses key obstacles in existing generative models and importance sampling methods: specifically, (1) the unavailability of samples from the target PDF $q$, and (2) the inefficiency of training separate models for each variation in $l(\rvx)$.

We introduce a novel approach for generating importance samples, following $q(\rvx)$, using an SGM trained on the base distribution $p(\rvx)$. Notably, our method neither requires a single sample from the distribution $q(\rvx)$ (or $p(\rvx)$) nor necessitates any additional retraining.


\paragraph{Key Idea.} %The crux of our approach is establishing a connection between the score function of the target distribution $q$ and that of the base distribution $p$, combined with the weight function $l$. Specifically, %
%
% we propose the use of an approximated time-dependent score function for the importance sampling PDF, denoted as $\nabla_{\rvx} \log \tilde{q}_{t}(\rvx) \approx \nabla_{\rvx} \log q_{t}(\mathbf{x})$ which 
% 
We first show that the time-dependent score function for the importance sampling PDF, denoted as $\nabla_{\rvx} \log \tilde{q}_{t}(\rvx) \approx \nabla_{\rvx} \log q_{t}(\mathbf{x})$, can be approximated in terms of the score function for the base PDF, $\nabla_{\rvx} \log p_t(\mathbf{x})$ and the target weight function $l(\rvx)$, both of which are readily available. Importantly, this approximation is computationally simple and requires no additional training. We further show that the approximation error vanishes as $t\rightarrow 0$ under mild assumptions. 
Next, we perform the backward SDE in (\ref{true_backward_sde}) with the approximated score function as: 
\begin{align}
\label{our_approach_simple_form}
    &\mathrm{d} \rmX_{t} \!=\! {\beta(t)} \! \left[ \frac{\!-\!\rmX_{t}}{2} \!-\!  \nabla_{\rmX_{t}}\! \log \tilde{q}_{t}(\rmX_{t}) \!\right] \!\mathrm{d}t \!+\! \sqrt{\!\beta(t
)}  \mathrm{d} \tilde{\rmW}_{t},
\end{align}
through which we generate importance samples.

% We demonstrate that $\nabla_{\rvx} \log \tilde{q}_{t}(\rvx)$ can be effectively approximated using only the given score function $\nabla_{\rvx} \log p_{t}(\rvx)$ and $\nabla_{\rvx} \log  l(\rvx)$, with the approximation error going to zero as $t\rightarrow 0$ under mild assumptions.

Our approach offers two major advantages: ($a$) it renders the {\emph{importance sampling process training-free}}, thereby eliminating the need to learn the PDF $q$ or score function of $q$, and ($b$) it enhances the {\emph{scalability and adaptability}} of the algorithm, as it relies solely on the inference of readily available quantities, $\nabla_{\rvx} \log p_{t}(\rvx)$ and $l(\rvx)$. %$\nabla_{\rvx} \log l(\rvx)$.



\paragraph{Derivation of the Proposed SDE (\ref{our_approach_simple_form}).}
We aim to represent $\nabla_{\rvx} \log q_{t}(\rvx)$ in terms of $\nabla_{\rvx} \log p_{t}(\rvx)$ and $\nabla_{\rvx} \log l(\rvx)$.
To achieve this, we begin by examining the form of the importance sampling distribution for the noise-perturbed importance samples, $q_{t}(\rvx)$, under the SDE defined in (\ref{true_forward_sde}).
%
Consider the transition probability density function $G: \mathbb{R}^{d} \times \mathbb{R}^{d} \times [0,T] \mapsto \mathbb{R}_{+}$, also referred to as the Green’s function or fundamental solution of the SDE \cite{beck1992heat, duffy2015green, economou2006green}. This function represents the probability density of the process transitioning from the given initial state $\rmX_{0} \! = \! \rvy$ to the state $\rvx$ at time $t$. Specifically, $G(\rvx, \rvy, t)$ denotes the probability density of transitioning from $\rvy$ to $\rvx$ over time $t$. Using this Green’s function, we can express $q_t(\rvx)$ as
\begin{align}
\label{q_t_green_function}
    q_{t}(\rvx) &= \int G(\rvx, \rvy, t) q_{0}(\rvy) \, \mathrm{d} \rvy \\
\label{q_t_green_function_01}
    &= \frac{1}{Z_0} \int G(\rvx, \rvy, t) l(\rvy) p_0(\rvy) \, \mathrm{d} \rvy
\end{align}
where $q_{0} = q$, $p_{0} = p$, and $Z_0$ is the normalization constant, $Z_0 = \int  l(\rvx) p(\rvx) \, \mathrm{d} \rvx$ as given in (\ref{importance sampling_PDF_definition}).

To further investigate the relationship between $q_{t}$ and $p_{t}$, we consider an SDE of $\rmX'_{t} \in \mathbb{R}^{d}$, which shares the same drift and diffusion coefficients as in (\ref{true_forward_sde}), but where the initial distribution is $p_{0} = p$ rather than $q_{0}$:
%
\begin{equation}
\label{true_forward_sde_of_x_prime}
    \mathrm{d} \rmX'_{t} =  -\frac{1}{2} \beta(t) \rmX'_{t} \, \mathrm{d}t + \sqrt{\beta(t
)} \, \mathrm{d} \rmW_{t},
\end{equation}
where $\rmX'_{0} \sim p_{0}$. It should be noted that the corresponding Green’s function for this SDE is also $G$ in (\ref{q_t_green_function}), and the distribution of $\rmX'$ at time $t$, denoted by $p_{t}$, is given as follows
\begin{align}
\label{p_t_green_function}
    p_{t}(\rvx) &= \int G(\rvx, \rvy, t) p_{0}(\rvy) \, \mathrm{d} \rvy.
\end{align}
%
By using (\ref{q_t_green_function_01}) and (\ref{p_t_green_function}), we have 
\begin{align}
% \label{q_t_intermsof_p_t_l}
    q_{t}(\rvx) &= \frac{p_{t}(\rvx)}{Z_0} \int l(\rvy) G(\rvx, \rvy, t) \frac{p_0(\rvy)}{p_{t}(\rvx)} \, \mathrm{d} \rvy 
\label{q_t_intermsof_p_t_l_01}
    = \frac{p_{t}(\rvx)}{Z_0} \mathbb{E}_{\rmX'_{0} \sim p_{\rmX'_{0}|\rmX'_{t}}(\cdot|\rvx)} [l(\rmX'_{0})] 
\end{align}
where $p_{\rmX'_{0}|\rmX'_{t}}(\cdot|\rvx)$ is the conditional PDF of the initial state $\rmX'_{0}$ for a given state $\rmX'_{t}\!=\!\rvx$ at $t$ under the SDE given in (\ref{true_forward_sde_of_x_prime}). 

We can observe that $q_{t}$ can be represented in terms of $p_{t}$ and $l$ as shown in (\ref{q_t_intermsof_p_t_l_01}). Consequently, the score function for importance sampling can be represented as
\begin{align}
    \label{score_qt_original}
    \nabla_{\rvx} \log q_{t}(\rvx) &= \nabla_{\rvx} \log p_{t}(\rvx) +\nabla_{\rvx} \log  \mathbb{E}_{\rmX'_{0} \sim p_{\rmX'_{0}|\rmX'_{t}}(\cdot|\rvx)} [l(\rmX'_{0})]. 
\end{align}
For practical computation of (\ref{score_qt_original}), we consider the first order Taylor approximation of $l(\rmX'_{0})$ at $\bar{\rvx}'_{0}\vert_{\rvx,t} \coloneqq \mathbb{E}[\rmX'_{0} \vert \rmX'_{t}=\rvx]$ which gives us 
\begin{align}
    \label{l_x_taylor_approx}
    l(\rmX'_{0}) &\approx  l(\bar{\rvx}'_{0}\vert_{\rvx,t}) + \nabla l(\bar{\rvx}'_{0}\vert_{\rvx,t})^{\top}(\rmX'_{0} - \bar{\rvx}'_{0}\vert_{\rvx,t}).
    %\nonumber\\  &+ \frac{1}{2}(\rvx_{0} - \mu)^{\top} \nabla^2 l(\mu) (\rvx_{0} - \mu)
\end{align}
Substituting (\ref{l_x_taylor_approx}) to (\ref{score_qt_original}), we have 
\begin{align}
    \label{score_qt_approx_1}
    \nabla_{\rvx} \log q_{t}(\rvx) \approx \nabla_{\rvx} \log p_{t}(\rvx) +\nabla_{\rvx} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t}).
\end{align}
%The gap between (\ref{score_qt_original}) and (\ref{score_qt_approx_1}) can be interpreted as a gap from Jensen's inequality \cite{simic2008global}, which can be effectively bounded under mild assumptions and, as $t\rightarrow 0$, this gap also goes to zero, as we show in Theorem \ref{theorem_1}.  
%
Note that $\bar{\rvx}'_{0}\vert_{\rvx,t}$ is the conditional mean of the initial state for a given $\rvx$ at $t$ and can be obtained through the Tweedie’s approach (\cite{efron2011tweedie, kim2021noise2score,chungdiffusion}) as 
\begin{align}
\label{tweedie_mean}
\bar{\rvx}'_{0}\vert_{\rvx,t}= \frac{1}{\sqrt{\bar{\alpha}(t)}}(\rvx + (1-\bar{\alpha}(t)) \nabla_{\rvx} \log p_{t}(\rvx))
\end{align}
where 
$
\bar{\alpha}(t) = \exp\left( -\int_0^{t} \beta(s) \, ds \right).
$

Given that we now have a tractable form for $\nabla_{\rvx} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})$ by (\ref{tweedie_mean}), we can apply the chain rule to represent $\nabla_{\rvx} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})$ as follows
\begin{align}
    \label{true_derivative_log_x_0}
    &\nabla_{\rvx} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t}) =
 \frac{\left(  \rmI +  (1-\bar{\alpha}(t)) H_{p_{t}}(\rvx) \right)}{\sqrt{\bar{\alpha}(t)}} \nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})
\end{align}
where $H_{p_{t}}(\rvx)$ is the Hessian matrix of $\log p_{t}(\rvx)$. 

To enhance the practicality of the proposed method, we approximate the Hessian matrix-vector multiplication in (\ref{true_derivative_log_x_0}) by the first-order Taylor's approximation with a sufficiently small $\epsilon > 0$ as
\begin{align}
    %\label{hessian_approximation}
     \nabla_{\rvx} \log \ &p_{t}(\rvx) + \epsilon H_{p_{t}}(\rvx)  \nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t}) \notag \\
    \label{hessian_approximation_01}
&\approx {\nabla_{\rvx} \log p_{t}(\rvx + \epsilon \nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})) }.
\end{align}



Combining (\ref{true_backward_sde}), (\ref{score_qt_approx_1}), and (\ref{hessian_approximation_01}), we finally suggest to use the following approximated score function.
\begin{align}
    &\nabla_{\rvx} \log \tilde{q}_{t}(\rvx) \coloneqq \nabla_{\rvx} \log p_{t}(\rvx) + \frac{\nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})}{\sqrt{\bar{\alpha}(t)}} \nonumber \\
    &+ \frac{\nabla_{\rvx} \log p_{t}(\rvx + \epsilon \nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})) - \nabla_{\rvx} \log p_{t}(\rvx)}{\epsilon (1-\bar{\alpha}(t))^{-1} \sqrt{\bar{\alpha}(t)}}  \nonumber
\end{align}
whose corresponding backward SDE to sample $\rmX \sim q_{0}$ is given as
\begin{align}
\label{our_approach}
     &\mathrm{d} \rmX_{t} = -\frac{\beta(t)}{2} \left[  \rmX_{t} +2  \nabla_{\rmX_{t}} \log \tilde{q}_{t}(\rmX_{t}) \right]\, \mathrm{d}t + \sqrt{\beta(t )} \, \mathrm{d} \tilde{\rmW}_{t} \nonumber \\
 &= \left [ -\frac{1}{2} \beta(t) \rmX_{t} \!-\! \beta(t)  \nabla_{\rmX_{t}} \log p_{t}(\rmX_{t}) \right]  \mathrm{d}t  + \sqrt{\beta(t)} \, \mathrm{d} \tilde{\rmW}_{t} \nonumber \\
 &- \beta(t) \bigg[ \frac{\nabla_{\bar{\rvx}'_{0}\vert_{\rmX_{t},t}} \log l(\bar{\rvx}'_{0}\vert_{\rmX_{t},t})  }{\sqrt{\bar{\alpha}(t)}}  - \frac{\nabla_{\rmX_{t}} \log p_{t}(\rmX_{t})}{\epsilon (1-\bar{\alpha}(t))^{-1} \sqrt{\bar{\alpha}(t)}} + \frac{\nabla_{\rmX_{t}} \log p_{t}(\rmX_{t} + \epsilon \nabla_{\bar{\rvx}'_{0}\vert_{\rmX_{t},t}} \log l(\bar{\rvx}'_{0}\vert_{\rmX_{t},t}) }{\epsilon (1-\bar{\alpha}(t))^{-1} \sqrt{\bar{\alpha}(t)}}  \bigg]  \mathrm{d}t.
 \end{align}
%
This proposed SDE (\ref{our_approach}) can be solved by the Euler–Maruyama method \cite{kloeden1992stochastic}, i.e., iterative discretization of the SDE. We reiterate and further elaborate on the key benefits of our approach for generating importance samples as follows. %Our approach provides significant benefits for generating importance samples as follows.
%
% \begin{remark}[Training-Free Importance Sampling]\label{remark:training_free}
% The proposed backward SDE in (\ref{our_approach}) demonstrates that, for a given score function of the original PDF $\nabla_{\rvx} \log p_{t}(\rvx)$ and the importance weight function $l$, \textbf{\emph{importance sampling can be approximated without additional training}}. This presents a substantial advantage over existing methods, which require learning the density of $q$ through individual training for each specific $l$. Furthermore, in modern computer vision research, pre-trained score functions are widely available in the public domain and are frequently utilized, especially for natural image generative models \cite{podell2024sdxl, pernias2024wurstchen, rombach2022high}. Thus, with an appropriate differentiable importance weight function, $l(\rvx)$, these pre-trained models can be directly leveraged, eliminating the need for further training of the importance sampling PDF.
% \end{remark}


\begin{remark}[Training-Free Importance Sampling]\label{remark:training_free}
The proposed backward SDE in (\ref{our_approach}) demonstrates that, for a given score function \( \nabla_{\mathbf{x}} \log p_{t}(\mathbf{x}) \) and importance weight function \( l(\mathbf{x}) \), \textbf{\emph{importance sampling can be approximated without additional training}}. This presents a substantial advantage over existing methods, which require learning the density of $q$ through individual training for each specific $l$.

In modern applications, pre-trained score functions are widely available \cite{podell2024sdxl, pernias2024wurstchen, rombach2022high} and can be directly leveraged. Our approach enables the direct application of importance sampling with any differentiable importance weight function \( l(\mathbf{x}) \),  thereby eliminating the need for further training. \end{remark}


\begin{remark}[High Scalability and Applicability]\label{remark:scalability}
The proposed method requires only the score function of the original PDF and the differentiable function $l$,  enabling diverse advanced importance measures, particularly those implemented via differentiable neural networks. 
For example, in a neural autoencoder designed to compress input instances, the importance weight for each instance could be defined by the compression-induced distortion, thereby prioritizing high-distortion samples.
Applying the proposed algorithm in this context allows for targeted sampling of instances prone to high distortion, aiding in feature analysis focused on the high-distortion cases.

%This approach is readily applicable to a variety of tasks, such as importance sampling for high-quality images by giving greater weight to better-quality samples or sampling images based on stylistic similarity to a reference image by placing more emphasis on samples that align closely with the desired style.

\paragraph{Computational Complexity.} 
%It is important to highlight that the additional computational complexity introduced by this approach, as compared to the original score-based sampling that computes $\nabla_{\rvx} \log p_{t}(\rvx)$, is minimal. The computation of $\bar{\rvx}'_{0}\vert_{\rvx,t}$ involves only a simple linear transformation of the input $\rvx$ and the precomputed score function, as described in (\ref{tweedie_mean}). Aside from this negligible cost, the only other potential overhead is calculating the derivative of the loss function, $\nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})$ and utilizing it to compute the last term in (\ref{our_approach}), which can be efficiently done through a single gradient backpropagation step with respect to the precomputed realization of $\bar{\rvx}'_{0}\vert_{\rvx,t}$ and one step inference of the score function. This additional computation is likely to be \emph{significantly less demanding} than methods that require the estimation of exact importance sampling PDF for each individual $l$. % Heasung? have you seen my slack message? Impact statement has to come after the conclusion & before references. I've put Karl's example on slack.- I sent a message via slack. Thank you!
The additional computational cost introduced by our approach, compared to the base score-based sampling, is minimal. Calculating $\bar{\rvx}'_{0}\vert_{\rvx,t}$ involves only a linear transformation of $\rvx$ and the precomputed score function, as outlined in (\ref{tweedie_mean}). Aside from this negligible cost, the potential overhead is the computation of $\nabla_{\bar{\rvx}'_{0}\vert_{\rvx,t}} \log l(\bar{\rvx}'_{0}\vert_{\rvx,t})$ to evaluate the final term in (\ref{our_approach}). This is efficiently achieved with a single gradient backpropagation step on $l$ with respect to the realization $\bar{\rvx}'_{0}\vert_{\rvx,t}$ and one inference step of the score function. Overall, this additional cost is \emph{significantly less demanding} than methods requiring exact PDF or score function for each individual $l(\rvx)$.
\end{remark}




\subsection{Theoretical Analysis}
In this section, we establish Theorem \ref{theorem_1} providing an upper bound on the Euclidean norm discrepancy between the proposed approximated score function and the true score function. %, with a detailed proof provided in Appendix \ref{appendix_technical_results}.
%
\begin{assumption}
    \label{assumption_bounded_norm}
    (Bounded derivatives of $\log l(\rvx)$)
    For all $\rvx \! \in \! \mathbb{R}^{d}$ and $t \! \in \! [0,T]$, we have $\Vert \nabla_{\rvx} \log l(\rvx) \Vert \le \eta$,     
    $\Vert H_{l}(\bar{\rvx}'_{0}\vert_{\rvx,t}) \Vert \le \eta_{2}$, and $\left\Vert {\partial H_{l}(\bar{\rvx}'_{0}\vert_{\rvx,t})}/{\partial \rvx}  \right\Vert_{F} \le \eta_{F}$, where $H_{l}(\rvx)$ is Hessian matrix of $\log l(\rvx)$.
\end{assumption}
\noindent Assumption \ref{assumption_bounded_norm} implies that the importance weight function’s log-derivatives remain finite. Recall that we consider a strictly positive importance weight function $l(\rvx)>0$, which reasonably supports the assumption of bounded log derivatives, avoiding unbounded behavior.
%
\begin{assumption}
    \label{assumption_lipschitz}
    (Bounded log PDF derivatives)
    For all $\rvx, \rvy \in \mathbb{R}^{d}$ and $t\in[0,T]$, we have $\left\Vert \nabla_{\rvx} \log  p_{\rmX'_{0}|\rmX'_{t}}(\rvy|\rvx) \right\Vert \le \gamma_{t}$,  $\Vert H_{p_{t}}(\rvx)\Vert \le \zeta_{t}$, and $\Vert H_{p_{t}}(\rvx) - H_{p_{t}}(\rvy) \Vert \le L_{t} \Vert \rvx-\rvy\Vert$.
    %
    %There exist $A_{t}\le 0$ and $b_{t} \in \mathbb{N}$ such that $\Vert H_{p_{t}}(\rvx) \Vert \le A_{t}(1+ \Vert \rvx \Vert^{b_{t}}).$ 
\end{assumption}
\noindent The bounded norm of the score function and Hessian of the log-likelihood are standard assumptions in the analysis of SGMs \cite{chen2023improved, de2022convergence, chensampling, de2021diffusion}. The Lipschitz continuity of the Hessian often holds under a bounded Hessian assumption \cite{chensampling}, especially in practical implementations of SGMs where the domain is often compact \cite{ho2020ddpm, song2021ddim} with high probability.

%especially when the domain is compact with high probability which is typically true in practical score-based generative models limiting domain as a bounded space. 

%Note it is assumed for the analysis (\ref{hessian_approximation})
%
%In Appendix \ref{section:discussion_assumptions} we provide additional details regarding assumptions for our technical results in more detail.
%
\begin{theorem}
    \label{theorem_1}
    \text{\normalfont(Score function gap)}
    Suppose that Assumptions \ref{assumption_bounded_norm}–\ref{assumption_lipschitz} hold and for all $\rvx \in \mathbb{R}^{d}$ and $t\in[0,T]$, the importance weight function $l$ is approximately equal to its second-order Taylor expansion at the estimated mean as $l(\rmX'_{0}) \approxeq  l(\bar{\rvx}'_{0}\vert_{\rvx,t}) + \nabla l(\bar{\rvx}'_{0}\vert_{\rvx,t})^{\top}(\rmX'_{0} - \bar{\rvx}'_{0}\vert_{\rvx,t}) + \frac{1}{2} (\rmX'_{0} - \bar{\rvx}'_{0}\vert_{\rvx,t})^{\top} H_{l}(\bar{\rvx}'_{0}\vert_{\rvx,t})(\rmX'_{0} - \bar{\rvx}'_{0}\vert_{\rvx,t})$.

    For a given $\epsilon > 0$, the gap between the true score function of the importance sampling PDF and the approximated score function is upper-bounded as
    \begin{align}
    \label{theorem_1_inequality}
    &\Vert \nabla_{\rvx} \log q_{t}(\rvx) - \nabla_{\rvx} \log \tilde{q}_{t}(\rvx) \Vert \le  \frac{(1-\bar{\alpha}(t))L_{t}\eta^{2}\epsilon}{2\sqrt{\bar{\alpha}(t)}} + \lambda_{t} \mathbb{E} \left[\Vert \rmX'_{0}- \bar{\rvx}'_{0}\vert_{\rvx,t}\Vert^2 \vert \rmX'_{t}=\rvx \right] 
    \end{align}
    where $\lambda_{t}= \frac{1}{2m}(\eta_{F} + \gamma_{t}\eta_{2}) + \frac{ \left({1+(1-\bar{\alpha}(t))\zeta_{t}} \right )\eta\eta_{2} }{2m^2 \sqrt{\bar{\alpha}(t)}} $.
\end{theorem}


\begin{remark}[Bounded score function gap by variance]
The gap between the true score function and the proposed approximation is bounded by $\mathbb{E} \left[\Vert \rmX'_{0}- \bar{\rvx}'_{0}\vert_{\rvx,t}\Vert^2 \vert \rmX'_{t}=\rvx \right]$, which is the \emph{trace of the covariance matrix of $\rmX'_{0}$ whose PDF is conditioned on the observation $\rvx$ at $t$}. As $t \rightarrow 0$, this conditional variance converges to zero resulting the second term on the right-hand side of (\ref{theorem_1_inequality}) vanishes, making the gap negligible. Additionally, the first term, $\frac{(1-\bar{\alpha}(t))L_{t}\eta^{2}\epsilon}{2\sqrt{\bar{\alpha}(t)}}$, also approaches $0$ as $\bar{\alpha}(t)\rightarrow 1$ when $t\rightarrow 0$.

\end{remark}

\section{Experiments}
\label{sec:experiments}







\subsection{Importance Sampling Performance Analysis}
\label{experiments_closed_form}
% Prof. Hyeji's original ver.
%In this section, we evaluate the performance of the proposed method by measuring the `distance' between the ground truth importance sampling distribution and the sample distribution generated by our approach across various distributions and importance weight functions. No prior baselines exist for our setup (i.e., we have access only to an SGM). Nevertheless, establishing a baseline–particularly a generative model-driven approach–would be valuable. To address this, we assume access to a certain number of samples from the base distribution $p$. For baselines, we parameterize the importance sampling distribution using state-of-the-art (SOTA) density-based generative models, which are then optimized via CEM using only samples from the original distribution. For our approach, we train an SGM on these samples and then apply our method, ensuring that both our approach and the baseline utilize the same number of samples, from the same base distribution.

% It is important to highlight that a direct comparison of our method with this baseline is inherently unfair due to fundamental differences in the mechanisms, as the baseline approach relies heavily on extensive neural network training, requiring significant hyperparameter tuning. To the best of our knowledge, our work introduces \textbf{\emph{the first score-based, training-free importance sampling framework}} capable of accommodating a broad range of \emph{externally defined importance weight functions} $l(\rvx)$. Here, the term ``training-free'' signifies that, given the availability of an SGM for the base distribution, our method does not necessitate training a separate generative model tailored to a specific $l(\rvx)$. 


In this section, we evaluate the proposed method by measuring the `distance' between the ground truth importance sampling distribution and the sample distribution generated by our approach across various scenarios. No prior baselines exist for our setup (i.e., we have access only to an SGM). Nevertheless, establishing a baseline–particularly a generative model-driven approach–would be valuable. Thus we parameterize the importance sampling distribution with state-of-the-art (SOTA) density-based generative models, optimized via Cross Entropy Minimization (CEM) method \cite{botev2013cross} using only samples from the base distribution $p$. Our method is applied to the same dataset, ensuring both approaches use an equal number of samples.

It is important to note that a direct comparison with this baseline is inherently unfair due to fundamental differences in mechanism. The baseline requires extensive neural network training with substantial hyperparameter tuning, whereas our approach remains \textbf{\emph{the first score-based, training-free importance sampling framework}} that accommodates a broad range of \emph{externally defined importance weight functions} $l(\rvx)$. Here, ``training-free'' signifies that, given an SGM for the base distribution, our method operates without training an additional generative model specific to $l(\rvx)$.


%Empirical results demonstrate that the proposed training-free method achieves comparable performance to SOTA approaches that necessitate per-$l(\rvx)$ training, thereby validating its efficiency.



%\begin{adjustwidth}{-2.5 cm}{-2.5 cm}\centering\begin{threeparttable}[!htb]...\end{threeparttable}\end{adjustwidth}
\setlength\tabcolsep{3.5pt}
\begin{table}[t]\centering
\label{performance_table}
%\vspace{-3.8mm}
\caption{Performance comparison. 
({\color{green}{\ding{52}}}) represents a training-free algorithm, whereas ({\color{red}{\ding{55}}}) indicates an algorithm requiring training for each $l(\rvx)$. 
Metric: Jensen–Shannon divergence to ground truth importance sampling distribution, with lower values indicating better performance.}
\scriptsize
\begin{tabular}{lrrrrr}\toprule
&Circles, $l_1$ &Circles, $l_2$ &Spiral, $l_1$ &Spiral, $l_2$ \\\midrule
MADE-MAA ({\color{red}{\ding{55}}}) &0.209 ± 1e-3 &0.292 ± 8e-4 &0.154 ± 3e-2 &0.119 ± 2e-1 \\
NIS ({\color{red}{\ding{55}}}) &0.122 ± 4e-4 & 0.123 ± 2e-4 &{0.096 ± 5e-5} &0.227 ± 4e-3 \\
NSF ({\color{red}{\ding{55}}}) &0.121 ± 7e-4 &0.121 ± 1e-3 &0.097 ± 1e-4 &\textbf{0.100 ± 6e-3} \\
CSF ({\color{red}{\ding{55}}}) &0.121 ± 3e-4 &0.121 ± 7e-4 &\textbf{0.094 ± 4e-2} &0.102 ± 1e-3 \\
TNA ({\color{red}{\ding{55}}}) &0.129 ± 3e-4 &0.137 ± 6e-3 &0.201 ± 9e-4 &0.228 ± 5e-3 \\
ISSGM (Ours, {\color{green}{\ding{52}}}) &\textbf{0.117 ± 2e-4} &\textbf{ 0.121 ± 3e-4} &0.107 ± 1e-4 &0.106 ± 5e-3 \\
\bottomrule
\end{tabular}

\setlength\tabcolsep{3.6pt}
\begin{tabular}{lrrrrr}\toprule
&Pinwheel, $l_1$ &Pinwheel, $l_2$ &8-G, $l_1$ &8-G, $l_2$ \\\midrule
MADE-MAA ({\color{red}{\ding{55}}}) &0.174 ± 2e-1 & 0.128 ± 2e-3 &0.215 ± 4e-2 &0.155 ± 2e-3 \\
NIS ({\color{red}{\ding{55}}}) & 0.120 ± 8e-4 &0.106 ± 2e-3 &0.105 ± 2e-3 &0.106 ± 1e-4 \\
NSF ({\color{red}{\ding{55}}}) &\textbf{0.117 ± 1e-3} &0.104 ± 4e-4 &0.108 ± 1e-4 &0.108 ± 3e-4 \\
CSF ({\color{red}{\ding{55}}}) &0.117 ± 2e-3 &0.104 ± 2e-2 &0.108 ± 6e-4 &0.108 ± 3e-2 \\
TNA ({\color{red}{\ding{55}}}) &0.118 ± 4e-3 &0.107 ± 8e-3 &0.156 ± 9e-4 &0.127 ± 2e-2 \\
ISSGM (Ours, {\color{green}{\ding{52}}}) &0.123 ± 1e-2 &\textbf{0.103 ± 6e-4} &\textbf{0.104 ± 6e-4} &\textbf{0.104 ± 1e-4} \\
\bottomrule
\end{tabular}
%\vspace{-5mm}

\end{table}


{\bf Setup.\ } We shall initially consider the Circles, Spiral, Pinwheel, and 8-Gaussians (8-G) %Swiss Roll,  CheckerBoard (CB) 
datasets \cite{grathwohl2019scalable, perugachi2021invertible} with two different importance weight functions $l_1(\rvx) \!=\! \Vert \rvx \Vert^2 $ and $l_2(\rvx) \!=\! \Sigma_{i\in [d]} [\rvx]_{i}+2$, i.e., Euclidean norm square and element summation. 

\paragraph{Evaluation metrics.} The use of these closed-form data distributions and importance weight functions enable us to recover the optimal importance sampling distribution via the accept/reject method, facilitating the evaluation of importance sampling performance based on the Jensen-Shannon Divergence \cite{endres2003new} --  this is a symmetric variant of the Kullback-Leibler divergence, i.e., the distance between estimated samples and the optimal importance sampling distribution. %Additional details regarding these distributions and setups are provided in Appendix \ref{appendix_experiments_details_spiral}.

\paragraph{Our method.} We use Denoising Diffusion Probabilistic Models (DDPM) \cite{ho2020ddpm} to obtain the base score function, and use the SDE discretization method. 
%described in Appendix \ref{appendix_sde_disrectization} to perform importance sampling. Further details of the setup are provided in Appendix \ref{appendix_experiments_details_spiral}.


\paragraph{Baselines.}
We adopt the following representative and SOTA density estimation-based generative models: Masked Autoencoder for Distribution Estimation {\cite{germain2015made}} combined with the Masked Affine Autoregressive technique (MADE-MAA) {\cite{papamakarios2017masked}}, implemented using a density flow model with CEM; leveraging the Piecewise Quadratic Coupling Transform proposed in Neural Importance Sampling (NIS) {\cite{muller2019neural}}; Neural Spline Flows (NSF) {\cite{durkan2019neural}} which utilize spline transformations to model complex distributions; Cubic Spline Flow {\cite{durkan2019cubic}} (CSF); and Transformer Neural Autoregressive density estimation method (TNA), incorporating masked autoregressive multi-head attention {\cite{patacchiola2024transformer}}. %For implementation details of the baselines, refer to Appendix \ref{appendix:baseline_implementation}.


\paragraph{Results.}
In Table \ref{performance_table}, we present the performance evaluation of the proposed importance sampling method. Our approach achieves the best performance in 5 out of 8 scenarios. We stress that for the two given importance weight functions, our method requires only a single base score function training.
Even in cases where the proposed importance sampling does not attain the best performance, the gap remains marginal, with the Jensen-Shannon divergence difference being less than 0.015. This highlights the robustness of our approach. By contrast, some of our baselines exhibit significant performance variation across the considered scenarios. For instance, while TNA achieves performance comparable to the best-performing method in the Pinwheel scenario, its performance deteriorates significantly on the Spiral dataset, where its divergence metric is twice that of the best approach. %Additional results and density visualizations can be found in Appendix \ref{appendix_experiments_details_spiral}.


% Visualization




\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/spiral/estimated_mean_p_and_q_ver2.pdf}
    %\vspace{-7mm}
    \caption{
    \textbf{\emph{Top row}}: sampling process for $\rmX' \sim p(\rvx)$. \textbf{\emph{Bottom row}}: proposed importance sampling process for $\rmX \sim q(\rvx)$. From left to right, each column corresponds to $t=500, 400, \ldots, 0$, showing the distributions of $\mathbb{E}[\rmX'_{0}|\rmX'_{t}]$ and $\mathbb{E}[\rmX_{0}|\rmX_{t}]$. Thus, the rightmost column illustrates the PDFs $p(\rvx)$ (top) and $q(\rvx)$ (bottom). 
    %The proposed method utilizes the pretrained $\nabla_{\rvx} \log p_{t}(\rvx)$, combined with $l(\rvx)$, to compute $\nabla_{\rvx} \log \tilde{q}_{t}(\rvx)$ without necessitating any additional training. 
    The proposed approach enables efficient \textbf{\emph{importance sampling on the correct spiral-shaped manifold without any additional training for $l(\rvx)$}}, selectively emphasizing instances with a high norm with $l(\rvx)=\Vert \rvx \Vert^{2}$.
    }
    \label{fig:spiral_estimated_mean_p_and_q}
    %\vspace{-5mm}
\end{figure}

Fig. \ref{fig:spiral_estimated_mean_p_and_q} exhibits a visualization of a base sampling and the importance sampling processes for the Spiral distribution with the norm squared weight. The top row shows the sampling process for $\rmX' \sim p$ based on depicting the evolution of distribution of $\mathbb{E}[\rmX'_{0}|\rmX'_{t}]$. The bottom row shows our proposed importance sampling method for $\rmX \sim q$ by exhibiting the evolution of the distribution of $\mathbb{E}[\rmX_{0}|\rmX_{t}]$. Note that at $t\!=\!0$ (rightmost column), \emph{the distributions of the conditional means correspond to } $p(\rvx)$ and $q(\rvx)$ respectively.

%Specifically, we generate $10^{5}$ random instances, each initiaged at a centered Gaussian distribution. Then, 
For every $t$, we compute the mean by using Tweedie's formula $\frac{1}{\sqrt{\bar{\alpha}(t)}}(\rvx_{t} + (1-\bar{\alpha}(t)) \nabla_{\rvx_{t}} \log p_{t}(\rvx_{t}))$ for the original sampling process and $\frac{1}{\sqrt{\bar{\alpha}(t)}}(\rvx_{t} + (1-\bar{\alpha}(t)) \nabla_{\rvx_{t}} \log \tilde{q}_{t}(\rvx_{t}))$ for our importance sampling approach. We present 2D histograms for each time step, where reddish pixels indicate high probability density and blue pixels represent lower density. The histograms on the far right, corresponding to $t\!=\!0$, illustrate the PDFs, $p$ (top) and $q$ (bottom), as $\bar{\alpha}(0)\!=\!1$.

The results show that our proposed method performs importance sampling over the \emph{feasible manifold}, i.e., the domain where $p(\rvx)\! \neq \! 0$; and reflects the specified importance weight function $l$, by resulting in higher densities for instances with high $l$ values. Importantly, this approach leverages $\nabla_{\rvx} \log p_{t}(\rvx)$ to approximate $\nabla_{\rvx} \log q_{t}(\rvx)$ without any additional training. 

%Our proposed algorithm demonstrates remarkable versatility, offering the capability to perform sampling without additional training and adaptability to any differentiable importance weight function $l$. This flexibility allows it to be effectively extended to large-scale foundational models and neural importance weight functions, as demonstrated in the following sections.


% We generate spiral shaped dataset which is useful to observe the algorithm behavior as widely used in existing literatures \cite{chen2018neural}. 
\setlength\tabcolsep{4.5pt}
\begin{table}[t]\centering
%\vspace{-3.8mm}
\caption{Importance weight functions and importance values.}
\label{table:average_importance_value}
\scriptsize
%\vspace{-3mm}
\begin{tabular}{lrrr}\toprule
Experiment, $l(\rvx)$ & $\mathbb{E}_{\rmX' \sim p}[l(\rmX')]$ & $\mathbb{E}_{\rmX \sim q}[l(\rmX)]$ (Ours) \\\midrule
Fig. \ref{fig:spiral_estimated_mean_p_and_q}, Spiral, $\Vert \rvx \Vert^2 $ & $6.75\times 10^{-1}$ & $8.55\times 10^{-1}$ \\
%MNIST,  $D_{\text{ce}}( F_{\text{cl}}(\rvx), \rve_{1} )^2$ & $4.58\times 10^{2}$ & $5.77\times 10^{2}$ \\
Fig. \ref{fig:csi_samples_q}, CSI, $D(F_{\text{dec}}(F_{\text{enc}}(\rvx))), \rvx)$ &$3.07\times 10^{-4}$ & $6.09\times 10^{-4}$ \\
Fig. \ref{fig:celeba_generation_process}, CelebA, a classifier &$3.51\times 10^{-1}$ & $5.12\times 10^{-1}$ \\
Fig. \ref{fig:stable_cascade_main_picture}, StableCascade, a frequency analyzer \hspace{-9mm} & $1.36$ &$4.39$ \\
\bottomrule
\end{tabular}
%\vspace{-5mm}
\end{table}




\subsection{Inverse Model Analysis: Sampling Rare Instances Showing High Distortion in Neural Compression
%(Inverse Model Analysis)
}
\label{experiments_csi}
Thus far, we have demonstrated that the proposed method achieves performance comparable to, or often surpassing, SOTA methods, all while remaining training-free. This unique property enables its application to fundamental sampling challenges, such as model analysis under complex importance weight functions $l(\rvx)$ in high-dimensional spaces.
In this section, we apply our training-free importance sampling for \emph{inverse model analysis}, i.e., identifying samples that degrade model performance.

\paragraph{Application Scenarios.} We consider the problem of Channel State Information (CSI) compression, where CSI represents a high-dimensional matrix—often exceeding thousands of dimensions—describing the wireless transmission link conditions between devices. Given the pivotal role of CSI in optimizing communication quality, its efficient compression and transmission have emerged as crucial challenges in wireless communication research and industrial standards \cite{9927255}. Neural compressors, typically implemented as autoencoders comprising an encoder $F_{\text{enc}}$ and a decoder $F_{\text{dec}}$, have been extensively studied for this purpose and continue to be an active area of research~\cite{guo2022overview,jiang2024digital,qin2024ai}.  

\paragraph{Importance Sampling Formulation.} In real-world industrial applications, rigorous analysis of model reliability is essential. A fundamental question in this context is: \emph{\textbf{Under what conditions does our task model, i.e., the autoencoder, fail?}} Importance sampling provides a principled approach to address this. By defining an importance weight function as $l(\rvx) = D(F_{\text{dec}}(F_{\text{enc}}(\rvx)), \rvx),$ where $D$ denotes the distortion measure—specifically, Mean Squared Error (MSE) in this case—we can efficiently giving high importance weight to samples that exhibit high distortion, thereby identifying failure modes of the neural autoencoder model.


\emph{This approach is particularly valuable in scenarios where high-distortion samples are rare.} A brute-force strategy that generates a large volume of samples, computes distortions, and applies an accept/reject procedure would be computationally inefficient. 
Also, traditional importance sampling methods are impractical in this setting, especially when multiple neural autoencoders need to be compared, as they necessitate training a separate generative model for each neural autoencoder under evaluation. In contrast, our training-free importance sampling method enables efficient \emph{inverse model analysis} of neural models. %, providing a scalable and effective solution for identifying failure cases.


% Hyeji: intentionally vague? - yes.
For the experiment, we utilize DDPM to obtain $\nabla_{\rvx} \log p_{t} (\rvx)$ with CSI data from Quasi Deterministic Radio Channel Generator \cite{jaeckel2014quadriga, jaeckel2021quadriga}. The convolutional nueral architecture-based autoencoder comprising $F_{\text{enc}}$ and $F_{\text{dec}}$ is trained through the dataset generated from DDPM in direction of minimizing MSE.

%are provided in Appendix %All implementation details, including the neural autoencoder architectures for $F_{\text{enc}}$ and $F_{\text{dec}}$ are provided in Appendix \ref{appendix_experiments_details_csi}.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{fig/csi/csi_samples_with_histogram.pdf}
    %\vspace{-5mm}
    \caption{
         \textbf{\emph{Left}:} Histogram of $l(\rvx)$ (distortion) from $p(\rvx)$ and \textbf{\emph{Right}:} the importance sampling PDF $q(\rvx)$ which assigns higher weights to instances with high distortion in the neural compressor. This allows rare features to be more readily observed by increasing the likelihood of sampling high-distortion instances.
    }
    \label{fig:csi_samples_q}
    %\vspace{-5mm}
\end{figure}

%{\color{blue} Somewhere in the results section, we can Refer to Table 2}
\paragraph{Results.} We sample $10^{4}$ CSI instances using both the original and importance sampling methods to measure average distortion under the neural compressor. 
In Fig. \ref{fig:csi_samples_q}, we present the distortion histograms from $p(\rvx)$ and $q(\rvx)$. On the left-hand side, we also visualize a sample from $p(\rvx)$ showing relatively small distortion of $10^{\!-4}$ in both domain spatial-frequency and angular-delay domains through inverse Fourier transform. On the right-hand side, we represent a sample from $q(\rvx)$ showing compression distortion more than $10^{\!-3}$.


% LONG VERsion
% The histograms indicate that our proposed method effectively samples rare, high-distortion instances, which were infrequent in the original distribution (e.g., instances with distortion greater than $10^{\!-3}$ occurred in only about 5\% of cases). With importance sampling, these high-distortion cases are observed with a frequency exceeding 16\%. Table \ref{table:average_importance_value} also demonstrates that the average distortion of importance samples in the autoencoder model, $\mathbb{E}_{\rmX \sim q}[l(\rmX)]$, is nearly twice that of samples from the base distribution, $\mathbb{E}_{\rmX' \sim p}[l(\rmX')]$. It enables more accessible feature analysis for selective samples, allowing, for example, the identification of characteristics specific to rare, high-distortion samples—such as dominant scatter patterns in the angular-delay domain (denoted by yellow dotted circles). These patterns are known to be challenging for compression \cite{csinet_ver1, kim2022learning}, contrasting with lower-distortion samples that exhibit less scattering in the delay domain, as shown on the left. Further analysis is presented in Appendix \ref{appendix_experiments_details_csi}. 

The histograms show that our method effectively samples rare, high-distortion instances that are infrequent in the original distribution (e.g., cases with distortion greater than $10^{\!-3}$ occur in only 5\% of samples). With importance sampling, their frequency increases to over 16\%. 
Table \ref{table:average_importance_value} further demonstrates that the average distortion of importance samples in the autoencoder model, $\mathbb{E}_{\rmX \sim q}[l(\rmX)]$, is nearly twice that of samples from the base distribution, $\mathbb{E}_{\rmX' \sim p}[l(\rmX')]$. This facilitates targeted feature analysis, enabling the identification of characteristics unique to rare, high-distortion samples—such as dominant scatter patterns in the angular-delay domain (highlighted by yellow dotted circles), which pose significant challenges for compression \cite{csinet_ver1, kim2022learning}. In contrast, lower-distortion samples exhibit minimal scattering in the delay domain, as shown on the left. %Additional analysis is provided in Appendix \ref{appendix_experiments_details_csi}.


%Table \ref{table:average_importance_value} shows that samples from importance sampling exhibit significantly higher distortion compared to those following the original distribution. 

%Hyeji: I wonder if it'd be good to mention fine-tuning... are importance samples useful? 

% 

%This application illustrates the potential of our proposed method for selective feature analysis across various industrial applications.



\subsection{Versatility and Scalability}
\label{section:celebA_stablecascade}


One of the key advantages of our approach is its {\em versatility} to generate samples with varying characteristics from a given SGM. We illustrate this through the following examples: 
($a$) {{\em Neural classifier-driven sampling} (\textbf{Exp-(a)}) and ($b$) {\em Sampling images with desired frequency properties from a foundation diffusion model} (\textbf{Exp-(b)}). 
% 
Additionally, our experiments highlight the {\em scalability} of our approach, as we apply it to various high-dimensional data, including natural images, image-text pairings, and large-scale diffusion models such as foundational models.%. e.g., StableCascade~\cite{pernias2023wuerstchen}.
%We note that our experiments also demonstrate the scalability of our algorithm as we consider various high-dimensional data, including natural images and image-text pairings, and large-scale diffusion models such as foundational models. %, %model, e.g., StableCascade~\cite{pernias2023wuerstchen} 
% respectively. 
% 

%We describe the setup for \textbf{Exp-1} and \textbf{Exp-3} and present part of the results. Additional details, analysis, and results for \textbf{Exp-2} and \textbf{Exp-4} are available in Appendices \ref{appendix_experiments_details_mnist}--\ref{appendix_experiments_details_stablecascade}.

% We here describe the experimental setup of \textbf{Exp-1} and \textbf{Exp-3}, presenting part of quantitative results for \textbf{Exp-1} and qualitative results for \textbf{Exp-3}. See Appendices \ref{appendix_experiments_details_celeba}, \ref{appendix_experiments_details_mnist}, and \ref{appendix_experiments_details_stablecascade} for further details and analysis and stuff for Exp-2 and Exp-4. 


% {\em Neural classifier-driven sampling} (\textbf{Exp-1}, \textbf{Exp-2} in Appendices \ref{appendix_experiments_details_celeba}, \ref{appendix_experiments_details_mnist}) and Sampling images with {\em desired frequency properties} and {\em color properties} from a foundation diffusion model %model, e.g., StableCascade~\cite{pernias2023wuerstchen} 
%(\textbf{Exp-3} and \textbf{Exp-4} in Appendix \ref{appendix_experiments_details_stablecascade}, respectively). 
%We here describe the experimental setup and present part of quantitative results for \textbf{Exp-1} and qualitative results for \textbf{Exp-3}. See Appendices \ref{appendix_experiments_details_celeba}, \ref{appendix_experiments_details_mnist}, and \ref{appendix_experiments_details_stablecascade} for further details and analysis.






\paragraph{Exp-(a): Neural Classifier-Driven Sampling.}
%\paragraph{Exp-1: Training-Free Sampling for Fairness via Neural Classifiers.}
\label{experiments_celeba}


\begin{figure}[t]
    \centering
    \setlength{\tabcolsep}{0pt}  % Adjust horizontal spacing between images
    \begin{tabular}{c}
        % Red Channel row
        { $\mathrm{d} \rmX'_{t} =(f(\rmX'_{t}, t) - \sigma(t)^2 \textcolor{blue}{\nabla_{\rmX'_{t}} \log p_{t}(\rmX'_{t})}) \, \mathrm{d}t + \sigma(t) \, \mathrm{d} \tilde{\rmW}_{t}$ }\\
        \begin{tabular}{ccccc}
            %\includegraphics[width=0.15\textwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_0_idx_1_1_label_0.pdf} &
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_800_idx_1_1_label_0.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_600_idx_1_1_label_0.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_400_idx_1_1_label_0.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_200_idx_1_1_label_0.pdf} &
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_p_idx_1_1_label_0/noisy_p_t_0_idx_1_1_label_0.pdf} \\
        \end{tabular} \\
        
        % Green Channel row
        
        { $\mathrm{d} \rmX_{t} =(f(\rmX_{t}, t) - \sigma(t)^2 \textcolor{red}{\nabla_{\rmX_{t}} \log \tilde{q}_{t}(\rmX_{t})}) \, \mathrm{d}t + \sigma(t) \, \mathrm{d} \tilde{\rmW}_{t}$}\\
        \begin{tabular}{ccccc}
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_q_idx_1_1_label_1/noisy_q_t_800_idx_1_1_label_1.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_q_idx_1_1_label_1/noisy_q_t_600_idx_1_1_label_1.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_q_idx_1_1_label_1/noisy_q_t_400_idx_1_1_label_1.pdf}&
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_q_idx_1_1_label_1/noisy_q_t_200_idx_1_1_label_1.pdf} &
            \includegraphics[width=0.19\columnwidth]{fig/celeba/appendix_generation_process/noisy_q_idx_1_1_label_1/noisy_q_t_0_idx_1_1_label_1.pdf} \\
        \end{tabular} \\
        
    \end{tabular}
    \vspace{-4mm}
    % Text with arrows and alpha values below
    %\vspace{0.5em}
    %\begin{minipage}{0.9\textwidth}
    %    \centering
    %    $t=T$\(\longrightarrow\) \hspace{10cm} \(\longrightarrow\) $t=0$
    %\end{minipage}
    
    \caption{
        %Example sampling process for original (top) and importance-weighted (bottom) samples: 
        \emph{Can a neural classifier serve as an importance weight in a completely training-free manner for SGM which is never trained with class information? - YES.} Our method can use any external differentiable importance weight function, e.g., a neural gender classifier. %{\color{blue}I like this caption, but it has not much to do with the image?}
        %\textbf{\emph{Top}}: The backward diffusion process for sampling from $p(\rvx)$. \textbf{\emph{Bottom}}: The proposed backward diffusion process for importance sampling from $q(\rvx)$. Both diffusion processes share the \textbf{\emph{same randomness}}, i.e., the same initialization and the Gaussian noises used in the iterative discretized SDE solution. The proposed importance sampling method assigns higher importance weights to samples where the classification logit value for the label ``man'' is high, which leads a distinct backward diffusion process.         From left to right, the columns correspond to $t=800, 600, 400, 200, 0$, with a total of $T=1000$ steps.
        %Having a diagram? SGM no notion of gender / gender classifier / 
    }

    \label{fig:celeba_generation_process}
\end{figure}




\begin{figure}[t]
%\vspace{-3mm}
    \centering
    \includegraphics[width=0.8\linewidth]{fig/stable_cascade/merged_stable_cascade_ver3.pdf}
    % \includegraphics[width=1.0\linewidth]{fig/stable_cascade/merged_stable_cascade_ver3.pdf}
    %\vspace{-3mm}
    \caption{\textbf{\emph{First row}}: Samples from $p(\rvx)$, \textbf{\emph{Second row}}: samples generated from $q(\rvx)$. %with higher importance weight for instances containing elevated high-frequency component, sampling of pen illustration-like images while preserving semantic categories. 
    %Original samples (top) vs. importance samples (bottom): 
    Our approach can generate samples containing elevated high-frequency components via setting $l(\rvx)$ accordingly.% (or as shown in ()). %  and applying our importance sampling approach.
%Hyeji: {\color{blue}Last row is not clear in the caption} 
}
    \label{fig:stable_cascade_main_picture}
    \vspace{-4mm}
\end{figure}
 % Heasung? Have you seen my message? Check Slack
 
% Consider an SGM trained without any awareness of ``class'' concepts, such as gender, yet capable of generating samples from an unknown data distribution—for example, celebrity-like human faces. 
Consider an SGM trained without ``class" awareness, such as gender, yet capable of generating celebrity-like faces (trained on CelebA~\cite{liu2015deep}). 
% Now, assume the availability of an independent neural classifier capable of determining whether a given image belongs to the ``man'' class. 
% 
Now, assume an independent neural classifier can identify whether an image belongs to the ``man'' class. 
While the SGM itself is unaware of class-level information, the classifier reveals that 35\% of the samples generated by the SGM are classified as ``man,'' implying a {\em high bias} in the original image distribution. % We ask: 
\emph{What if we want to efficiently generate more faces of ``man''?} %Our goal is to increase the sampling frequency of the ``man'' class. 

Our method can leverage the external neural classifier as an importance weight function to adjust ``man'' class sampling, even without SGM's class awareness; by setting \( l(\rvx) \) as the classifier's logit for ``man'', the importance sampling distributoin $q(\rvx)$ puts more emphasis on man-like faces. 

% \sim l(\rvx)p(\rvx)$ 

%Our proposed method can leverage the externally defined neural classifier as an  importance weight function to adjust the sampling probabilities of the ``man'' class, even when the SGM lacks inherent class-level awareness. This can be achieved by directly defining $l(\rvx)$ as the classifier's logit output regarding class ``man'', i.e., how likely $\rvx$ represents a man's face; %By exploiting the neural classifier as $l(\rvx)$, 
%Our algorithm assigns higher importance to samples that are more likely going to be a man's face
%with elevated logit values
%, resulting in correcting the bias of gender in the original distribution. %biasing the sampling process toward the desired class.

Fig. \ref{fig:celeba_generation_process} illustrates the difference between the backward diffusion process of base SGM trained over CelebA dataset (top) and the proposed backward diffusion process for importance sampling (bottom) based on the neural classifier importance weight. %Without requiring any additional training, our method utilizes the independent neural classifier to compute ${\nabla_{\rmX_{t}} \log \tilde{q}_{t}(\rmX_{t})}$, which guides the generation process toward samples classified as ``man.''
% 
As shown in Table \ref{table:average_importance_value}, our method successfully increases the sampling probability of the ``man'' class from 35\% to 51\%, achieving this without any retraining of the SGM. % Detailed simulation setups, experimental parameters, and more results are provided in Appendix \ref{appendix_experiments_details_celeba}.

%(Following two paragraphs: Appendix?)
%This method represents a distinct and efficient alternative to density-estimation-based fairness derivation techniques, such as \cite{kim2024training}, which require extensive retraining to achieve fairness adjustments. We anticipate that our training-free importance sampling approach will pave the way for new advancements in fairness—a goal of growing importance in the development of Artificial Intelligence (AI) models \cite{bellamy2019ai, trewin2019considerations, john2022reality}.

%Related to this, in Appendix \ref{appendix_experiments_details_mnist}, we present how our importance sampling method enables selective class downweighting (allowing for intentional exclusion of specific classes during sampling) or transformation of an inherently biased distribution into one that approximates class-wise uniformity.





%We train a ResNet18-based classifier $F_{\text{cl}}$ on the CelebA \cite{liu2015celebafaceattributes} dataset, to distinguish between samples labeled as ``man'' and ``not man,'' with outputs approaching 1 for instances classified as ``man'' and 0 otherwise. To prioritize ``man'' samples, similar to the technique in Sec. \ref{experiments_mnist}, we define $l(\rvx) = D_{\text{bce}}( F_{\text{cl}}(\rvx), 0)$, assigning higher importance to samples classified as ``man.'' 




\paragraph{Exp-(b): Sampling High-Spatial-Frequency Images from %Applications to 
Foundation Diffusion Models.}  
\label{paragraph:stablecascade}
The scalability of our proposed method makes it well-suited for application to large-scale foundation models, such as StableCascade \cite{pernias2024wurstchen}, which utilize pretrained \emph{text-conditional} score functions, $\nabla_{\rvx} \log p_{t}(\rvx \vert \rvc)$, where $\rvc$ represents the conditioning text. Our approach extends this capability to enable text-conditional importance sampling via $\nabla_{\rvx} \log q_{t}(\rvx \vert \rvc)$.

% In particular, we first apply a 2D Fourier transform (FFT) to each RGB channel of a generated image, then define smooth radial masks to distinguish low- and high-frequency regions within the FFT-shifted representation. By summing the masked frequency magnitudes across channels, we obtain a measure of how ``high-frequency'' or ``low-frequency'' an image is. 
%Shorter version


This experiment demonstrates that our importance sampling can control foundation diffusion models by utilizing an externally defined importance function. Specifically, we define an importance weight function $l(\rvx)$ that assigns higher values to images with pronounced high-frequency components, identified via Fourier Transform with radial masks applied to each RGB channel. As shown in Fig.~\ref{fig:stable_cascade_main_picture}, applying this function enables the generation of images with highly emphasized edges (bottom row) compared to general outputs (top row). Notably, this is achieved \emph{without text-conditioning related to the characteristics of the images}. These results highlight the potential of our training-free importance sampling method for \emph{offering a new dimension of control beyond text prompts}. %Further analysis is provided in Appendix~\ref{appendix_experiments_details_stablecascade}.




% "powerful tool" - removed. good to you? ok lets go ahead then. 9 minutes :)  Yes % Added 'novel' instead 

\section{Conclusion}
We proposed a novel training-free score-based importance sampling methodology that models the importance sampling process as a backward diffusion process. By leveraging the score function of the base PDF and the importance weight function, our approach eliminates the need for additional training. This framework offers a scalable and efficient solution, particularly for scenarios where varying importance criteria are required. We anticipate that the proposed method will enable diverse and practical applications of importance sampling in score-based generative models, addressing challenges in adaptive sampling, bias mitigation, and model interpretation.




% Our experiments demonstrate the wide applicability of our approach, ranging from SGMs for synthetic data to large-scale foundation models, employing any differentiable importance weight functions. 

%\paragraph{Discussion} These findings illustrate the method’s adaptability across various tasks, including selective feature analysis, data augmentation, and fairness in AI. While widely applicable, it is essential to clarify where this approach excels and where alternative methods may be more suitable. The method’s expandability and limitations are further discussed in Appendix \ref{appendix_possible_applications}. Additionally, Appendix \ref{appendix_broad_impact_statement} addresses the broader impact of this work and confirms its focus on technical advancements and neutrality, with no political or ethical intentions.








\newpage

\section*{Impact Statement}%  and Discussion}
\label{section:Impact_Statements}
The proposed method facilitates importance sampling with a wide range of existing pretrained score-based models and importance weight functions. % However, it is crucial to acknowledge the potential for this approach to be misused in reinforcing biased sampling practices.
% 
We explicitly clarify that \emph{\textbf{the primary objective of this study is to advance methodological rigor and the field of Machine Learning}}; this work neither intends to advocate nor promote any particular social perspective through the experimental results presented. We do acknowledge the potential for this approach to be misused in reinforcing biased sampling practices, though, and thus strongly encourage careful consideration of the implications associated with its application. %›Additionally, we affirm that this work is entirely devoid of political intentions or any similar motivations. How about this? OK let's submit it!! :) Looks perfect. Thank you for the update. Well noted.

{
    \small
    \bibliographystyle{ieeetr}
    \bibliography{references_sde, references_importance_sampling, references_generative_model, references_csi}
}



% \input{sec/X_suppl}












% WARNING: do not forget to delete the supplementary pages from your submission 
% \input{sec/X_suppl}


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 and 2024 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
