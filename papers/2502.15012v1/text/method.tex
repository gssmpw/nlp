\begin{figure*}[t]
    \centering
    \includegraphics[width=0.99\linewidth]{imgs/overview.pdf}
    \caption{\textbf{Overview of \mymethod.} \mymethod can be summarized into four steps: 1. generate a substitute graph based on the similarity between the node features; 2. train the GNN backbone with the substitute adjacency matrix; 3. freeze the backbone and train the secure recalibration rectifier using real adjacency information; 4. deploy the backbone and substitute graph in untrusted environments (in {\color{brown} brown}) and deploy the real graph and rectifiers on enclaves (in {\color{green!30} green}). }
    \label{fig: overview}
    \vspace{-2mm}
\end{figure*}


\section{Our Approach: \mymethod } \label{sec: method}


\subsection{Threat Model} \label{method: threat model}
Our work aims to protect both GNN model parameters and the edge data during inference, specifically using the TEE of Intel SGX. 
Unless specified, we consider node classification as the primary downstream task.

\noindent\textbf{Attacker's Goal.}
We assume there are ``honest-but-curious'' attackers such as users of local ML systems.
Specifically, these passive attackers are curious about sensitive data but do not intend to corrupt the systemâ€™s integrity and functionality. 
Their objective is to extract confidential graph structural information, represented by the adjacency matrix, and to steal the parameters of highly accurate GNNs present on the device.

\noindent\textbf{Attacker's Capability.}
The attacker has full control over the victim system, enabling them to query the GNN model with any chosen node to obtain the model output results. 
Additionally, they can observe any computation and intermediate results in the untrusted environment, such as the public part of the GNN model or the intermediate node embeddings.
However, any data and operations within the enclaves remain sealed and inaccessible to the attacker. 
Other attacks against TEE, e.g., side-channel attacks, are out of the scope of this work.

\noindent\textbf{Attacker's Knowledge.}
We assume the attacker lacks knowledge of the adjacency matrix, which represents confidential relationships between any two nodes in the graph (e.g., hidden correlations between customers and products in recommender systems or private connections between users in social networks). 
The node features, however, are considered public knowledge such as product attributes or user profiles.

\noindent\textbf{Defender's Goal.}
The defender, a model provider such as Apple or Amazon, is responsible for the design and deployment of the GNN model on the local device, aiming to protect both the highly accurate GNN model and the private adjacency matrix information. This involves designing the GNN structure and establishing the secure deployment of the trained model and graph data on the inference platform.


\subsection{Overview of \mymethod} \label{method: overview}
\mymethod employs the design strategy known as \textit{partition-before-training}~\cite{zhang2024no}, to completely avoid using the private edge data during training of the public backbone. 
To maintain the model performance, a GNN rectifier is designed to use the real adjacency matrix, which is lightweight and securely protected within the TEE. 
Furthermore, to prevent information leakage through intermediate data transfer, \mymethod allows only one-way communication from the untrusted environment to the enclave. 
As illustrated in Fig.~\ref{fig: overview}, \mymethod can be summarized in four steps: (1) generate substitute graph(s); (2) train the public backbone; (3) train the private rectifier;  (4) securely deploy the data and models.

\subsection{Public GNN Backbone} \label{method: backbone}
The backbone is trained with public data, aiming to provide sufficient pre-computation during the inference process. Unlike the backbones for DNNs or LLMs in~\cite{zhang2024no}, which are open-source pre-trained models, GNNs are more dataset-specific and cannot directly leverage such models. Therefore, our \mymethod uses a pre-trained neural network backbone that utilizes public node features. We generate a substitute adjacency matrix based on node similarity and train this backbone for the target tasks (node classification).

\noindent\textbf{Substitute Adjacency Matrix:}
To enable the backbone model to capture message passing between nodes, we design it as a GNN with a substitute adjacency matrix. This substitute adjacency is computed based on the similarity between nodes:

{\footnotesize
\begin{equation}
    A'(i, j) = 
\begin{cases}
1 & \text{if } F(i, j)\geq\tau \text{ for each } j \neq i \\
0 & \text{otherwise}
\end{cases}
\end{equation}}Here, $F(i, j) = \text{sim}(x_i, x_j)$ represents the similarity measure computed between two node features, such as cosine similarity $\frac{x_i \cdot x_j}{|x_i||x_j|}$. Based on this similarity, we determine the connected edges using a threshold $\tau$. Alternatively, connectivity can be computed using the $k$-nearest neighbors, where we connect the top-$k$ similar nodes to construct the adjacency matrix.

\noindent\textbf{Training the Public Backbone:}
The public backbone consists of GCN layers trained with the substitute adjacency matrix $A'$ and the public node features $X$. Each GCN layer $k$ projects the high-dimensional features (embeddings) from $\mathbb{R}^{N \times d^{(k)}}$ to a lower-dimensional space $\mathbb{R}^{N \times d^{(k+1)}}$ through the message passing procedure. However, due to the loss of spatial information from the real adjacency matrix, this public backbone often exhibits lower accuracy. Therefore, the other component, a private rectifier, aims to recalibrate the embeddings in $\mathbb{R}^{N \times d^{(k+1)}}$ with real adjacency to achieve higher accuracy.


\subsection{Secure GNN Rectifier} \label{method: rectifier}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.93\linewidth]{imgs/designs.pdf}
    \caption{\textbf{Backbone and GNN Rectifier Designs:} (a). Public GNN backbone; (b). Parallel rectifier; (c). Cascaded rectifier; (d) Series rectifier.}
    \label{fig: designs}
    \vspace{-3mm}
\end{figure}

With the public backbone trained using the substitute adjacency matrix, the node embeddings
are passed from the backbone to the GNN rectifier to rectify the misinformation from $A'$.
The rectifier is designed with GCN layers that take the outputs of the backbone as inputs, along with the true adjacency matrix for rectification. 
Notably, the embeddings are often in a lower-dimensional latent space compared to the original node features. 
Therefore, a rectifier layer will be smaller than the corresponding backbone layer, so that it can fit into the enclave. 
During the training process of the rectifier, we freeze the pre-trained GNN backbone and adjust the rectifier parameters using cross-entropy loss for node classification.

How to process node embeddings from the backbone will result in various rectifier sizes and rectification performances. We consider three communication schemes (data flows) and the corresponding rectifiers, as shown in 
Fig.~\ref{fig: designs}:

\noindent\textbf{Parallel Rectifier:} Layers of the public backbone and layers of the rectifier run layer-by-layer in parallel. We aim to rectify the node embeddings right after each message-passing with the substitute adjacency matrix. Our experiment shows that the parallel rectifiers have the best accuracy (Sec.~\ref{exp: performance}). 
\ad{Generally, I would consider `performance' include both classifier accuracy and cost (time/memory). This here seems to only meaning accuracy. Should we be more specific in using the term?  }
\rd{revised.}

\noindent\textbf{Cascaded Rectifier:} This design allows the backbone to run first, and then we concatenate all GCN layer outputs from the untrusted environment as input to the rectifier, which provides the rectifier a global view of the node embeddings but introduces additional computational requirements.

\noindent\textbf{Series Rectifier:} In this design, we utilize only the final layer from the backbone as input to the rectifier. This approach uses the smallest input space and results in lower memory consumption and faster response time.

\subsection{Deployment of GNN on TEE} \label{method: deployment}
As shown in Fig.~\ref{fig: overview}, we deploy the public backbone and substitute graph in the untrusted environment, where the model can benefit from acceleration from GPUs.
We safeguard the real adjacency information and GNN rectifiers inside the secure enclaves to prevent edge privacy breaches and model stealing attacks.
The true adjacency matrix will be saved in the Coordinate (COO) format, which maintains only the non-zero elements with their indices for memory efficiency, with the pre-computed degree matrix, to accelerate the normalization process.
During the inference phase, each layer of the rectifier's output will be stored internally within the enclave, preventing intermediate data from leaking to the untrusted environment.
Logits have been shown to contain additional privacy information such as data membership and link connectivity~\cite{he2021stealing, shokri2017membership}.
Therefore, we also require the final output to be label-only, i.e., the logits are kept inside the enclave and only the output class is available to users.
