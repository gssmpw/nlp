\section{Conclusion}

This study presents \our{}, a novel psychologically grounded paradigm that enables automated, scalable, adaptable, and non-reactive value system construction. With \our{}, we introduce the first theoretically and empirically validated five-factor LLM value system, encompassing Social Responsibility, Risk-Taking, Rule-Following, Self-Competence, and Rationality. We accompany the value system with three benchmarking tasks, rooted in both psychological theories and AI priorities. Experimental results confirm the superior validity and utility of the proposed value system compared to the canonical Schwartz's values.

\our{} promises to overcome the key limitations of traditional psycho-lexical paradigms by offering adaptability to evolving contexts and agent-specific needs. The proposed value system enables more effective evaluation, understanding, and alignment of LLM values, thereby contributing to their safe and reliable deployment.


\section*{Limitations}

This study is limited to identifying and measuring values in English. Values are both culturally and linguistically sensitive \cite{schwartz2013culture}, and LLM value orientations can vary across languages \cite{cahyawijaya2024high}. Future work will extend GPLA to multilingual contexts.

In addition, we follow BaseAlign \cite{yao2023value_fulcra} when benchmarking value systems on value alignment. However, the algorithm, like many existing alignment methods, assumes a single, consistent alignment target. Future work should explore distributional and pluralistic alignment \cite{sorensenposition, zhong2024panacea} to more holistically evaluate a value system.