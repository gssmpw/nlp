\section{Introduction}

Personal values are broad, fundamental motivations behind individual and collective actions. They serve as guiding principles that shape perceptions, cognition, and behaviors across situations and over time. As Large Language Models (LLMs) continue to permeate and transform human society, researchers have increasingly sought to evaluate, understand, and align LLM values \citep{ye2025gpv, ren2024valuebench, rao2024normad, meadows2024localvaluebench, kovavc2024stick, jiang2024raising, rozen2024llms, yao2024clave, zhang2023measuring, sorensen2024value, moore2024large, demszky2023using}. Rather than relying solely on specific risk metrics, implicit preference modeling, or atomic ethical principles, framing these studies through the lens of intrinsic values \cite{schwartz2012overview} offers a more comprehensive, adaptable, and transparent approach \cite{yao2023value_fulcra, biedma2024beyond, yao2023alignment_goals}. 

However, value systems used in existing research—primarily Schwartz's values—are designed for humans. A psychologically informed value system specifically tailored for LLMs remains largely unexplored, obscuring a structured and holistic perspective on their values.
A preliminary attempt at constructing LLM value systems \cite{biedma2024beyond} has several limitations that undermine its psychological grounding; we present related discussion and experimental evidence in \cref{sec:human_to_llm_values} and \cref{app:against_bhn}.

To address this gap, we introduce a generative psycho-lexical approach (\our{}), a novel methodology that leverages LLMs to construct a value system grounded in psychological principles. This approach is based on the psycho-lexical hypothesis, which suggests that all salient values are captured in language. \our{} adopts an agentic framework and involves five sequential steps: 1) extracting perceptions from the corpus, 2) identifying values behind perceptions, 3) filtering values, 4) non-reactive value measurements of test subjects, and 5) structuring the value system. In contrast to traditional methods that manually compile value lexicons and design questionnaires to collect self-report data \cite{aavik2002structure, crectu2012psycho, Klages1929-KLATSO-5, saucier2000isms}, \our{} automates the entire process and features two key advantages.

First, \our{} supports \textbf{agent-specific construction}. Rather than relying on value lexicons derived from human-compiled dictionaries, it utilizes LLMs to identify values within free-form agent-generated text. This principled approach facilitates the agent- and context-specific collection of value lexicons and ensures better coverage (\cref{app:comprehensiveness}).
Second, \our{} enables \textbf{nonreactive value measurement}. Traditional methods that rely on forced-choice self-report are demonstrated to be unreliable and biased for humans \cite{ponizovskiy2020development, bardi2008new} and AI \cite{ye2025gpv, rottger2024political, dominguez2023questioning}. Instead, \our{} measures values through analyzing unstructured responses to arbitrary prompts, which mitigates response biases and enables scalable and self-adaptive value measurement \cite{ye2025gpv}.

In applying \our{} to 33 LLMs, each steered with 21 different value-anchoring prompts \cite{rozen2024llms}, we develop a five-factor value system encompassing \textit{Social Responsibility}, \textit{Risk-taking}, \textit{Rule-following}, \textit{Self-competence}, and \textit{Rationality}. We demonstrate the system's reliability and explore its theoretical and practical implications. To benchmark LLM value systems, we propose three tasks based on psychometric principles \cite{devon2007psychometric} and AI priorities \cite{ji2023ai_alignment, anwar2024foundational}: \textit{Confirmatory Factor Analysis} for assessing structural validity, \textit{LLM Safety Prediction} for examining predictive validity, and \textit{LLM Value Alignment} for evaluating representational power. These tasks confirm the validity and utility of our system in evaluating, understanding, and aligning the intrinsic values of LLMs, when compared to canonical Schwartz's values \cite{schwartz2012overview}.

We summarize our contributions as follows. 1) We introduce the Generative Psycho-lexical Approach (\our{}), a novel LLM-driven and data-driven methodology to construct psychologically grounded value systems. 2) With \our{}, we construct a five-factor value system for LLMs. We demonstrate its reliability and explore its theoretical and practical implications. 3) We present three benchmarking tasks for LLM value systems, and establish the superior validity and utility of the proposed system.