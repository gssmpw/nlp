\section{Related Work}
Recent advances in MLLMs \cite{hurst2024gpt,liu2024visual,wang2024qwen2} have 
inspired research to extend these models to intelligent agents in various domains.
Among these, there's significant focus on GUI Agents for task automation on smart devices.
Currently, research in this field is more concentrated on the Mobile~\cite{zhang2023appagent,wang2024mobilev1,hong2024cogagent} and Web~\cite{gur2023real,zheng2024gpt} scenarios. In the PC scenario, Cradle~\cite{tan2024cradle} focuses on employing MLLM's reasoning abilities to realize operations in AAA games, while PC Agent~\cite{he2024pc} aims to enable agents to create and modify PowerPoint presentations.
Despite the notable progress, their versatility remains relatively limited.
% 
To handle cross-app tasks, UFO~\cite{ufo} designs a dual-agent framework, where one agent is responsible for application selection, and the other agent handles the specific control interactions.
To inject PC task knowledge into decision-making, 
Agent-S~\cite{agashe2024agent} combines online search and local memory for experience-augmented planning.
% 
Compared to previous methods, our PC-Agent focuses on complex PC tasks.
We achieve more refined perception and operation (\textit{e.g.}, editing Word documents) via the devised APM.
And the proposed hierarchical framework realizes a divide-and-conquer pipeline for complex instructions, which effectively addresses the inter-subtask dependencies and significantly improves performance on complex tasks.