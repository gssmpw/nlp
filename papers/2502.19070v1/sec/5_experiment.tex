\section{Experiments}
\label{sec:exp}
\subsection{Experimental Setup}
\noindent
\textbf{Datasets.}\quad
We conduct experiments\footnote{https://github.com/haoyangliASTAPLE/DDCS\_MI.git} on four high-resolution image datasets for two image classification tasks, namely, face recognition and dog breed classification.
For face recognition, we use UMDFaces~\cite{umdfaces} face dataset for training victim models and CelebA-HQ~\cite{pgan18iclr,celeba} dataset as the attacker's auxiliary dataset.
For dog breed classification, Stanford Dogs~\cite{stanforddogs} dataset is selected as the training dataset of victim models and Tsinghua Dogs~\cite{tsinghuadogs20} for the auxiliary datasets.
Similar to previous works~\cite{kedmi21iccv, gmi20cvpr}, we take a subset of 1000 identities from UMDFaces that contains 50981 training samples and 3000 test samples as $\mathcal{D}_{tar}$ to train the victim models.
Following~\cite{ppa22icml}, we use all labels for Stanford Dogs and split them into 18780 training samples and 1800 test samples.
To prevent strong assumptions about attacks, we limit the attacker's sample size in the auxiliary dataset to 30000 for both tasks.

\noindent
\textbf{Models.}\quad
We train 4 types of victim models: (1) VGG16~\cite{vgg} with Batch Normalization~\cite{bn} (VGG16BN), (2) ResNet50~\cite{resnet}, (3) Improved ResNet50 with Squeeze-and-Excitation~\cite{se18cvpr} blocks (IR50-SE), and (4) AlexNet~\cite{alexnet}.
We resume pre-trained StyleGAN2~\cite{stylegan2_20cvpr} of resolution 256 $\times$ 256 trained on two datasets, CelebA-HQ for face identification task and LSUN-Dogs~\cite{lsun} for dog breed classification task.



\noindent
\textbf{Competing MI Attacks.}\quad
Our GAN augmentation framework (Ours) is compared against two leading MI attack strategies: the algorithms of Plug \& Play Attack~\cite{ppa22icml} (PPA) and training with entropy loss of KEDMI~\cite{kedmi21iccv} (HLoss).
Given that KEDMI's algorithms, aside from HLoss, are tailored specifically for DCGAN~\cite{ppa22icml}, and PPA is recognized as a versatile, open-source framework for incorporating StyleGAN in MI attacks~\cite{ppa22icml,mi23mm}, we adopt PPA's StyleGAN-based architecture to implement both HLoss and our proposed approach.
Note that while several MI studies~\cite{gmi20cvpr,mirror22ndss,vmi21nips,rethink23cvpr,mi23mm} focus on the latter phase of MI attacks (i.e., fine-tuning GAN latent codes), our approach primarily enhances the GAN transfer learning phase of MI Attacks.
Thus, our approach is compatible with these works, as well as future MI attack strategies centered on latent code optimization.

\noindent
\textbf{Competing Evaluation metrics.}\quad
We evaluate the attacks in terms of DDCS$_{\text{avg}}$ and DDCS$_{\text{best}}$ as introduced in Algorithm~\ref{alg:ddcs}, as well as other standard metrics including accuracy, feature distance, FID, and coverage from~\cite{densitycoverage,vmi21nips}.
Additionally, an Inception-v3~\cite{inceptionv3} model is trained on the target dataset as the evaluator on top-1 accuracy (Acc@1), top-5 accuracy (Acc@5) and feature distance (Dist).
A publicly available pre-trained Inception-v3 model is used to calculate the coverage and FID between the reconstructed samples and target samples.
Furthermore, to measure LPIPS distance, a default VGG network setting is adopted.

\subsection{DDCS Reveals Per-example Vulnerability Against MI Attacks}
\label{sec:exp:per_examples}



Previous works fail to pinpoint which sample from $\mathcal{D}_{tar}$ is the most similar to a given reconstructed sample.
As a result, in the visualization, one must manually select the most similar sample from $\mathcal{D}_{tar}$, which is not only best guaranteed but also hard to interpret.
On the other hand, \textbf{DDCS can indicate how vulnerable each sample is under the MI attack in an unsupervised manner}.
Specifically, recall that each sample from $\mathcal{D}_{tar}$ is assigned a reconstruction distance to indicate its degree of restoration by $\mathcal{D}_{rec}$ in either worst case or average case.
Therefore, we can easily build the reconstruction pairs between $\mathcal{D}_{tar}$ and $\mathcal{D}_{rec}$ by searching for samples in $\mathcal{D}_{rec}$ that can achieve the smallest reconstruction distance to a given sample in $\mathcal{D}_{tar}$.

In Figure~\ref{fig:eye_test}, we present several samples from $\mathcal{D}_{tar}$ that are successfully matched by samples from $\mathcal{D}_{rec}$ together with their reconstruction distance. Samples that are not matched by any samples from $\mathcal{D}_{rec}$ are shown in the rightmost column.
Results are averaged from 10 independent runs to account for randomness.
These matched samples can be regarded as samples that are vulnerable to MI attacks and are more likely to leak their private information.
The data or model owner can thus focus on protecting these samples, by perturbing their values or removing them from the training.
Besides, we find that most samples in $\mathcal{D}_{tar}$ are unmatched, and these samples usually have more complex features than paired samples.
As such, future works could target at those difficult-to-attack samples to achieve a better coverage of MI attacks.

\begin{figure}[htbp]%[htbp]
%\vspace{-0.2in}
	\centering
	%\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
	\includegraphics[width=0.7\linewidth]{figs/exp_eyetest.jpg}
 \vspace{-0.1in}
	\caption{Visualization of reconstruction pairs between target (left) and reconstructed (right) samples for VGG16BN-UMDFaces with reconstruction distance attached on their bottom right corner. Samples on the right most column have no reconstruction pairs.}
	\label{fig:eye_test}
 %\vspace{-0.2in}
\end{figure}



\begin{table*}[htb]
	\centering
    \resizebox{0.8\textwidth}{!}{
	\begin{tabular}{ | c | c | c c c c c | c c | }
		\hline
		Model & Attack & $\uparrow$ Acc@1 & $\uparrow$ Acc@5 & $\downarrow$ Dist & $\downarrow$ FID & $\uparrow$ Coverage & $\uparrow$ DDCS$_{\text{avg}}$ & $\uparrow$ DDCS$_{\text{best}}$\\
		\hline
		\multirow{3}{*}{VGG16BN} & HLoss & 49.64\% & 69.10\% & 15978.52 & 64.00 & 0.1601 & 0.4162 & 0.4308 \\
        & PPA & \bf 97.67\% & \bf 99.89\% & \bf 7044.45 & 48.35 & 0.3213 & 0.5046 & 0.5240 \\
		& Ours & \bf 97.67\% & 99.86\% & 7065.28 & \bf 47.64 & \bf 0.3907 & \bf 0.6772 & \bf 0.7114 \\
		\hline
		\multirow{3}{*}{ResNet50} & HLoss & 35.15\% & 57.01\% & 18086.90 & 51.48 & 0.1727 & 0.4118 & 0.4243 \\
        & PPA & \bf 81.77\% & 94.84\% & \bf 10605.46 & 47.10 & 0.3234 & 0.4901 & 0.5088 \\
		& Ours & 81.65\% & \bf 95.01\% & 10642.02 & \bf 45.83 & \bf 0.3951 & \bf 0.6632 & \bf 0.6961 \\
		\hline
		\multirow{3}{*}{IR50-SE} & HLoss & 31.58\% & 49.47\% & 18323.38 & 79.28 & 0.1303 & 0.4238 & 0.4364 \\
        & PPA & 85.65\% & 95.64\% & 9728.30 & 47.55 & 0.3186 & 0.5146 & 0.5339 \\
		& Ours & \bf 86.12\% & \bf 95.92\% & \bf 9668.79 & \bf 46.18 & \bf 0.3901 & \bf 0.7017 & \bf 0.7367 \\
		\hline
		\multirow{3}{*}{AlexNet} & HLoss & 16.68\% & 36.07\% & 19990.63 & 62.06 & 0.1543 & 0.3901 & 0.4031 \\
        & PPA & 53.96\% & \bf 78.54\% & \bf 13710.45 & 45.62 & 0.2979 & 0.4600 & 0.4762 \\
		& Ours & \bf 53.97\% & 78.43\% & 13751.00 & \bf 44.11 & \bf 0.3696 & \bf 0.6193 & \bf 0.6481 \\
		%\hline
		%\multirow{3}{*}{ResNet50} & PPA & - & - & - & - & - & - & - & - \\
		%& HLoss & - & - & - & - & - & - & - & - \\
		%& Ours & - & - & - & - & - & - & - & - \\
		\hline
	\end{tabular}
    }
	\caption{Comparison on UMDFaces dataset between our approach (Ours), HLoss and PPA accross different metrics. $\uparrow$ and $\downarrow$ mean the higher the better and the lower the better, respectively. The best values for each metric and each model are in bold.}
	\label{exp:result:umdfaces}
\end{table*}


\subsection{Comparison of Various Evaluation Metrics}
In this subsection, we experimentally study the evaluation and robustness of DDCS against limitations discussed previously.
Specifically, we build a customized $\mathcal{D}_{rec}$ to simulate an MI attack that are very close to the ideal MI attack and can reconstruct $\mathcal{D}_{tar}$ very well.
As such, we can then observe how DDCS successfully evaluates this customized attack and how existing metrics fail to achieve it.
Two customized datasets, denoted as D1 and D2, are constructed based on UMDFaces and the settings as follows:

\noindent
D1. \quad
This dataset represents a $\mathcal{D}_{rec}$ of perfect distance to $\mathcal{D}_{tar}$ but poor diversity. To construct D1, we sub-sample a fixed number of images for every label, so that those samples have their identical matches in original $\mathcal{D}_{tar}$ and the diversity of D1 can be manually controlled.

\noindent
D2.\quad
This dataset represents a $\mathcal{D}_{rec}$ of perfect distance and diversity to $\mathcal{D}_{tar}$ but with a modified sample distribution different from $\mathcal{D}_{tar}$. To construct D2, we create a fixed number of redundant samples from $\mathcal{D}_{tar}$ to result in different distribution between $\mathcal{D}_{tar}$ and $\mathcal{D}_{rec}$.

In D1, we simulate the condition of varied diversity in $\mathcal{D}_{rec}$, and thus DDCS is compared with accuracy in this case.
As for D2, we test the metrics' robustness against distribution change of $\mathcal{D}_{rec}$, a common phenomenon in MI attacks, where we choose FID as the competing metric for DDCS.
Since both customized datasets can achieve perfect distance to $\mathcal{D}_{tar}$, we regularize the range of DDCS by setting $c$ in Algorithm~\ref{alg:ddcs} to 1.0.

Figure~\ref{fig:rich_poor} and~\ref{fig:eval_redundant} are the results for D1 and D2 respectively.
In Figure~\ref{fig:rich_poor}, as more images are sampled, DDCS successfully captures the increasing diversity of $\mathcal{D}_{rec}$ and thus increases. On the other hand, since $\mathcal{D}_{rec}$ has a very small distance from the samples of $\mathcal{D}_{tar}$, the accuracy approaches 100\% but it ignores the diversity of $\mathcal{D}_{rec}$.
In Figure~\ref{fig:eval_redundant}, since FID is sensitive to the changes of sample distribution, it always grows with the addition of additional redundant samples. Thanks to the $\mathcal{D}_{rec}$-oriented evaluation, DDCS is robust against the varied distribution and stays in a high and stable range.

\begin{figure}[htb]%[htbp]
	\centering
	\includegraphics[width=0.7\linewidth]{figs/rich_poor_cropped.pdf}
 \vspace{-0.1in}
	\caption{Evaluation results for various metrics on a customized UMDFaces dataset, in which the diversity is controlled with different number of samples per label. }
	\label{fig:rich_poor}
 \vspace{-0.2in}
\end{figure}

\begin{figure}[htb]%[htbp]
	\centering
	\includegraphics[width=0.7\linewidth]{figs/eval_redundant_cropped.pdf}
 \vspace{-0.1in}
	\caption{Evaluation results for various metrics on a customized UMDFaces dataset, in which the distribution is controlled with different number of redundant samples per label. }
	\label{fig:eval_redundant}
 %\vspace{-0.2in}
\end{figure}


\subsection{Comparison Results of MI Attacks}

Table~\ref{exp:result:umdfaces} shows the comparison results on UMDFaces between Ours, HLoss and PPA. %Table~\ref{exp:result:stanforddogs} in the Appendix shows the result of Stanford Dogs.
We keep two decimal places for numbers greater than 10, and four decimal places for the rest. %Their detailed explanations are attached in the Appendix.

\subsection{Per-label Reconstruction of MI Attacks}
In this subsection, we study the reconstruction degree of MI attacks in a label-wise manner through visualizing the reconstruction distance from DDCS.
Among three attacks discussed in UMDFaces dataset and VGG16BN model scenario, Figure~\ref{fig:ddcs_coverage} plots the proportion of target samples that have at least one matching to $\mathcal{D}_{rec}$, and Figure~\ref{fig:ddcs_distance} illustrates the per-label reconstruction distance by averaging the cumulative distance of these matched target samples.
We observe that our method significantly enhances the proportion of those samples that are reconstructed by $\mathcal{D}_{rec}$, while achieving a similar reconstruction distance to PPA, thereby improving DDCS.
On the other hand, suffering from entropy loss with soft-constraint that deteriorates both the image quality and generative power, HLoss achieves a much higher average reconstruction distance and thus a lower DDCS, though it can cover some labels in Figure~\ref{fig:ddcs_coverage}.

\begin{figure}[htb]%[htbp]
%\vspace{-0.1in}
	\centering
	%\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
	\includegraphics[width=0.9\linewidth]{figs/ddcs_distance.pdf}
 %\vspace{-0.1in}
	\caption{Average reconstruction distance for matched samples in each label with VGG16BN-UMDFaces and three attacks (PPA, HLoss and Ours).}
	\label{fig:ddcs_distance}
 \vspace{-0.1in}
\end{figure}




%As the reconstruction distance of a sample decreases, there is an increasing risk of leakage of the privacy information it contains.







%\subsection{Improvements on DDCS for Previous Techniques}
%Another interesting question is how the previous attacks perform on DDCS?
%To begin with, starting from GMI, there have been several significant improvements in MI attacks, including the use of poincare distance, initial selection and final selection.
%We measure the improvement of these methods on DDCS$_\text{avg}$ and DDCS$_\text{best}$ and present the result in Table.
%Since DDCS comprehensively measures multiple characteristics of MI attacks, these techniques also achieves descent improvements DDCS.

%\subsection{Limitation of A Single GAN}
%To further illustrate the limitations of a single GAN for MI attacks, we study whether similar performance to GAN Augmentation can be achieved by increasing the number of generated samples for baseline.

%\subsection{More Augmented GANs}

%\subsection{HVP of Image Manifold}

%\subsection{Indenpence of $\lambda_h$} 