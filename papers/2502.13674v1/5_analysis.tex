In this section, we propose to analyze the effect of undesired responses generated by our unfaithful sampling method on the overall performances of \scope. By varying the value of $\alpha$ in the noisy data generation process (\Cref{alg:preferencedatasetgen}), we can simulate different degrees of hallucinations due to the influence of $\plm$. In this analysis, we examine the impact of negative samples on preference learning.

%\hil{
%\subsection{Effect of number of samples used for fine-tuning phase}
%TODO: Ablation 0.25 / 0.5 / 0.75 / 1.0 -> 0.25 / 0.5 / 0.75 / 1.0 sur ToTTo
%}

%\hil{
%\subsection{Effect of preference tuning method}
%Although we experimented with DPO, the generation of the noisy samples does not depend on the choice of the preference tuning framework. We considered the ORPO framework and report the results in Table.
%TODO: Insert ORPO results.
%}

%\hil{\subsection{Effect of preference tuning without targets $y$}
%TODO: Use self-generated samples from $\psft$ instead of  provided targets $y$ from the dataset in \scope.
%}

\paragraph{How does the value of $\alpha$ affect the training dynamics?}
\label{sec:alpha-effect}
%As shown above, increasing $\alpha$ introduces both intrinsic and extrinsic hallucinations due to the effect of the unconditional model. 
The choice of $\alpha$ is critical. When $\alpha$ is low, the negative samples are too close to the model's own approximation of the underlying data distribution. During the preference-tuning stage, the model struggles to maximize the gap between the likelihood of the clean and noisy samples while maintaining the high likelihood of the clean ones. This causes the model to downweight the likelihood of both samples, leading to degeneracies, see \Cref{fig:train_a01}.
Conversely, when $\alpha$ is high, the generated noisy samples are barely grounded in the input context, making it easy to distinguish between $y$ and $\ylose$ under $p_\theta(\cdot \mid c)$. In this case, the model learns very little compared to its fine-tuned counterpart, see \Cref{fig:train_a07}. Therefore, $\alpha$ should be chosen to balance the noisy generation between being too similar to the reference texts and too easy to discriminate. This scenario is illustrated on \Cref{fig:train_a05} for $\alpha=0.5$. The likelihood of the references does not decrease, and the likelihood of the noisy samples diverges less abruptly than in \Cref{fig:train_a07}, providing a more effective learning signal.

\begin{figure*}
  \centering
  \subfloat[Training with $\alpha = 0.1$.]{\includegraphics[width=0.25\textwidth]{images/logprobs_a0.1_totto.pdf}\label{fig:train_a01}}\hspace{1em}
  \subfloat[Training with $\alpha = 0.5$.]{\includegraphics[width=0.25\textwidth]{images/logprobs_a0.5_totto.pdf}\label{fig:train_a05}}\hspace{1em}
\subfloat[Training with $\alpha = 0.7$.]{\includegraphics[width=0.25\textwidth]{images/logprobs_a0.7_totto.pdf}\label{fig:train_a07}}
  \caption{Preference training dynamics with \textsc{Llama-2-7b} as noise level $\alpha$ increases on ToTTo dataset. Illustration of the three different regimes during preference training. Blue (resp.\ red) curve corresponds the log probability of the reference labels (resp.\ of the synthetic unfaithful samples).}
  
  \label{fig:train_alpha}
\end{figure*}

\paragraph{How does the negative samples construction affect generation quality?}
For low values of $\alpha$, we observe noticeable degeneracies, evidenced by text repetitions. This is shown in \Cref{fig:bleu_alpha}, where BLEU scores decrease abruptly with lower values of $\alpha$. As dicussed in \Cref{sec:results}, in the $[0.4, 0.6]$ interval, the decrease in BLEU appears to be more closely related to the generated outputs diverging from standard fine-tuning patterns, rather than a noticeable decline in fluency.
Regarding optimization efficiency, the three regimes observed in \Cref{fig:train_alpha} can also be identified in \Cref{fig:nli_alpha}, that describes the evolution of the NLI score as a function of $\alpha$. Below a certain level of noise, degeneracies also impact the NLI score. Increasing $\alpha$ beyond a certain point yields no further improvement, as both BLEU and NLI scores converge to the results of standard fine-tuning. As a result, searching for $\alpha$ in the interval $[0.4, 0.6]$ seems to yield the best performances. We observe similar patterns in text summarization tasks, see \Cref{app:scope-analysis}. A quantitative and qualitative analysis of the noisy samples can be found in \Cref{app:noisy-samples}.
%In the extreme case where $\alpha = 0$, \scope is equivalent to one iteration of SPIN \citep{spin}, a method designed to enhance instruction-tuned models for chat. Within the specific context of data-to-text generation and text summarization, we found that this approach is ineffective. We hypothesize that this ineffectiveness is due to the distinct requirements of data-to-text generation, which may not align well with the mechanisms that SPIN leverages for instruction tuning.

% \red{where the model exhibits the greatest boost in faithfulness without showing degeneracies. The hyperparameter $\alpha$.  $\alpha$ is tuned for each dataset based on the NLI score on the validation set after preference-tuning. Since the NLI score does not penalize non-fluent behavior that appears when $\alpha$ is low, we select ranges of $\alpha$ on which values of BLEU do not decrease significantly. In practice, we found that for $\alpha \in \{0.4, 0.5, 0.6\}$, the model exhibits the greatest boost  More details on the effect of $\alpha$ can be found in \Cref{sec:analysis}.}

\begin{figure*}
  \centering
  \subfloat[]{\includegraphics[width=0.30\textwidth]{images/nli_score_totto.pdf}\label{fig:nli_alpha}}\hspace{2em}
  \subfloat[]{\includegraphics[width=0.30\textwidth]{images/bleu_totto.pdf}\label{fig:bleu_alpha}}
  \caption{Evolution of NLI Score and BLEU with $\alpha$ on ToTTo validation set with \textsc{Llama-2-7b}.}
  \vspace{-0.5cm}
\end{figure*}

%\begin{figure}
%  \centering
%
%  \includegraphics[width=0.35\columnwidth]{images/nli_score_totto.pdf}
%\caption{Evolution of NLI Score on ToTTo validation set as a function of $\alpha$ %with \textsc{Llama-2-7b}.}
%  \label{fig:nli_alpha}
%\end{figure}
% \subsection{Noisy samples when varying $\alpha$}
%\red{Hallucinations happen when the generation is not enough grounded in the input context. To simulate hallucinated content, we perturb the decoding process using the pre-trained model without context $\plm(\cdot)$ and varying its effect with a scaling factor $\alpha$. Samples with different values of $\alpha$ can be visualized in \red{Table}. As highlighted, our noisy generation procedure incorporates both intrinsic ( in \red{red}) and extrinsic (in blue) hallucinations.}
