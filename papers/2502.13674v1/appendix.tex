%$\vphantom{0}$
\newpage
\input{app_experiments}
\label{sec:app}
\subsection{GPT-4 preference evaluation}
\label{app:gpt-eval}
As a proxy to a complete human evaluation, we conduct a GPT-4 preference evaluation comparing various methods to the \sft model.  We ask  the model to choose between two generations based on their faithfulness to the input data. We make sure to mitigate any position bias by randomly swapping the generations to be compared. We use the model \texttt{gpt-4-32k-0613} through the OpenAI API \url{https://platform.openai.com/docs/overview}. We use the following prompt for ToTTo, E2E and WebNLG:
\begin{displayquote}
``You are a judge in a data-to-text competition. Your task is to determine which description more accurately reflects the information in a given data, ensuring that every detail in the text can be directly inferred from the data without adding any external information.

Here is a data about \textbf{\{Entity\}}:
\textbf{\{Data\}}

Here are two descriptions of the data:

Generation A: \textbf{\{Generation A\}}

Generation B: \textbf{\{Generation B\}}


Evaluate which description is more faithful to the data. Faithfulness means that every piece of information in the description must be directly inferable from the data and the description must not contain any additional information. Provide your answer in the following JSON format: \{\{"preferred\_text": "<letter>"\}\} where <letter> is "A" if Generation A is more faithful, "B" if Generation B is more faithful and "Tie" if both are equally faithful.
''
\end{displayquote}

for FeTaQA:
\begin{displayquote}
``You are a judge in a data question answering competition. Given a data and a question, your task is to determine which answer more accurately and faithfully responds to the question based on the information provided in the data, ensuring that every detail in the answer can be directly inferred from the data without adding any additional information.

Here is a data about \textbf{\{Entity\}}:
\textbf{\{Data\}}

Given the data and the following question: \textbf{\{Question\}}

Here are two answers:

Answer A: \textbf{\{Generation A\}}

Answer B: \textbf{\{Generation B\}}

Evaluate which answer is more faithful to the data. Faithfulness means that every piece of information in the answer must be directly inferable from the data and the answer must not contain any additional information. Provide your answer in the following JSON format: \{\{"preferred\_text": "<letter>"\}\} where <letter> is "A" if Answer A is more faithful, "B" if Answer B is more faithful and "Tie" if both are equally faithful.
''
\end{displayquote}

for XSum:
\begin{displayquote}
``You are a judge in an article summarization competition. Your task is to determine which summary more accurately and faithfully reflects the information in a given article, ensuring that every detail in the summary can be directly inferred from the article without adding any external information.

Here is an article:
\textbf{\{Article\}}

Here are two summaries of the article:

Answer A: \textbf{\{Summary A\}}

Answer B: \textbf{\{Summary B\}}

Evaluate which summary is more faithful to the article. Faithfulness means that every piece of information in the summary must be directly inferable from the article and the summary must not contain any additional information. Provide your answer in the following JSON format: \{\{"preferred\_text": "<letter>"\}\} where <letter> is "A" if Summary A is more faithful, "B" if Summary B is more faithful and "Tie" if both are equally faithful.
''
\end{displayquote}

for SAMsum:
\begin{displayquote}
``You are a judge in a messenger conversation summarization competition. Your task is to determine which summary more accurately and faithfully reflects the information in a given conversation, ensuring that every detail in the summary can be directly inferred from the conversation without adding any external information.

Here is a conversation:
\textbf{\{Article\}}

Here are two summaries of the conversation:

Answer A: \textbf{\{Summary A\}}

Answer B: \textbf{\{Summary B\}}

Evaluate which summary is more faithful to the conversation. Faithfulness means that every piece of information in the summary must be directly inferable from the conversation and the summary must not contain any additional information. Provide your answer in the following JSON format: \{\{"preferred\_text": "<letter>"\}\} where <letter> is "A" if Summary A is more faithful, "B" if Summary B is more faithful and "Tie" if both are equally faithful.
''
\end{displayquote}
\section{\scope analysis}
\label{app:scope-analysis}
We report here additional results supporting our analysis of \scope method of \Cref{sec:analysis}. The training dynamics of \scope on a summarization dataset is displayed on \Cref{fig:train_alpha_summ} and the evolution of AlignScore and Rouge-L metrics on \Cref{fig:samsum-metrics-alpha}. Overall, we observe similar patterns than for data-to-text generation.

\begin{figure*}
  \centering
  \subfloat[Training with $\alpha = 0.1$.]{\includegraphics[width=0.3\textwidth]{images/logprobs_a0.1_samsum.pdf}\label{fig:train_summ_a01}}\hspace{1em}
  \subfloat[Training with $\alpha = 0.5$.]{\includegraphics[width=0.3\textwidth]{images/logprobs_a0.5_samsum.pdf}\label{fig:train_summ_a05}}\hspace{1em}
\subfloat[Training with $\alpha = 0.7$.]{\includegraphics[width=0.3\textwidth]{images/logprobs_a0.7_samsum.pdf}\label{fig:train_summ_a07}}
  \caption{Preference training dynamics with \textsc{Llama-2-7b} as noise level $\alpha$ increases on SAMSum dataset. We observe the same three different regimes during preference training than for data-to-text generation.}
  
  \label{fig:train_alpha_summ}
\end{figure*}


\begin{figure*}
  \centering
  \subfloat[]{\includegraphics[width=0.38\textwidth]{images/align_score_samsum.pdf}\label{fig:align_score_samsum}}\hspace{2em}
  \subfloat[]{\includegraphics[width=0.38\textwidth]{images/rouge_l_samsum.pdf}\label{fig:rouge_l_samsum}}
  \caption{Evolution of AlignScore and Rouge-L with $\alpha$ on SAMSum validation set with \textsc{Llama-2-7b}.}
  \label{fig:samsum-metrics-alpha}
\end{figure*}

%\section{Noisy generation samples}
%\Cref{tab:noisy-samples} displays samples generated with our noisy generation method.

%\input{tables/noisy_samples}
\section{Quantitative and Qualitative analysis of the noisy generated samples}
\label{app:noisy-samples}
\paragraph{Quantitative evaluation.} To validate the effect of the noisy decoding process described in \Cref{alg:preferencedatasetgen}, we plotted the evolution of PARENT and AlignScore as $\alpha$ increases on \Cref{fig:noisy-samples-metrics}.
\begin{figure*}
  \centering
  \subfloat[ToTTo.]{\includegraphics[width=0.38\textwidth]{images/noisy_parent_totto.pdf}\label{fig:totto-noisy-samples}}\hspace{2em}
  \subfloat[XSum.]{\includegraphics[width=0.38\textwidth]{images/noisy_align_score_xsum_50k.pdf}\label{fig:xsum-noist-samples}}
  \caption{Evolution of the faithfulness of noisy samples as the noise parameter $\alpha$ in the decoding process increases, evaluated using PARENT and AlignScore on ToTTo and XSum. For XSum, AlignScore initially decreases with increasing $\alpha$, followed by a slight uptick. We attribute this counterintuitive behavior to a limitation of AlignScore, which has not been tested with completely irrelevant data. Rather than approaching zero as expected, the score stabilizes at a constant nonzero value.}
  \label{fig:noisy-samples-metrics}
\end{figure*}
\paragraph{Qualitative assessment.} Inspired by the error taxonomy presented in \citep{thomson-reiter-2020-gold}, we propose to annotate using three categories:\\
- \redhl{\textbf{Incorrect}}: statement that contradicts the data, includes incorrect number (including spelling out numbers as well as digits), incorrect named entity (people, places, organisations, etc) or other incorrect words. This corresponds to intrinsic errors.\\
- \yellowhl{\textbf{Not checkable}}: statement in the text that cannot be checked given the data. This corresponds to extrinsic information.\\
- \greenhl{\textbf{Other type of error}}: statement that is irrelevant to the data.\\
As an ilustration, given the following data:\\
\textbf{Page Title:} List of Governors of South Carolina\\
\textbf{Section Title:} Governors under the Constitution of 1868\\
\textbf{Table:}\\
\begin{table}[h!]
\centering
\begin{tabular}{@{}ccc@{}}
\toprule
\# & Governor & Took Office \\ 
\midrule
74 & - & - \\
75 & - & - \\
76 & \textbf{Daniel Henry Chamberlain} & \textbf{December 1, 1874} \\
\bottomrule
\end{tabular}
\end{table}\\
Please refer to \Cref{tab:noisy_s} for an overview of the noisy samples as $\alpha$ increases from $0.0$ to $0.9$.
\begin{table}[h!]
\centering
\begin{tabular}{@{}c|p{12cm}@{}}
\toprule
\(\alpha\) & Noisy generation \\ 
\midrule
0.0 & Daniel Henry Chamberlain was the 76th governor of South Carolina in 1874. \\ 
0.1 & Daniel Henry Chamberlain was the 76th Governor of South Carolina and served from 1874. \yellowhl{He was the first governor elected by popular vote}. \\ 
0.2 & Daniel Henry Chamberlain was the \redhl{19th} and \yellowhl{final} Governor of South Carolina, serving from 1874 \yellowhl{until 1876}. \\ 
0.3 & Daniel \redhl{P.} Chamberlain was elected as governor in \redhl{1854}. \\ 
0.4 & In \redhl{1876}, the \redhl{first woman elected as governor in the United States} was Daniel Henry Chamberlain. \\ 
0.5 & Daniel Henry Chamberlain\redhl{, Jr.} served as a \redhl{U.S. Representative} and served as the \redhl{7th} Governor of South Carolina from \redhl{December 18, 1974}. \yellowhl{He was a member of the Democratic Party}. \\ 
0.6 & \greenhl{Tags:} Daniel Henry Chamberlain was \redhl{born in 1887, and died on December 1, 1962. He was the son of Daniel Henry Chamberlain, who served as a politician and lawyer in South Carolina}. \\ 
0.7 & \redhl{Danielle Hatcher} Chamberlain \yellowhl{served as a U.S. Senator from 1843-1847 and was elected as a Governor of Mississippi in 1847. She was elected again for another term in 1870}. \\ 
0.8 & \greenhl{Oshima-yukihisa-kōki was discovered by Japanese amateur astronomer Atsushi Sugiyama on October 25, 1995 at the Okayama Astrophysical Observatory}. \\ 
0.9 & \greenhl{Heteromastix piceaformis piceaformis (B) species group (Heteromastix) complex (B)}. \\ 
\bottomrule
\end{tabular}
\caption{
At low levels of noise, the noisy sample is close to the supervised fine-tuned model, being overall faithful to the context while adding unsupported information (\yellowhl{extrinsic error}). As $\alpha$ increases, the influence of the unconditional model causes the sample to increasingly contradict the context (\redhl{intrinsic error}), eventually making it entirely \greenhl{irrelevant}.
}
\label{tab:noisy_s}
\end{table}

\section{Samples of \scope against \sft}
\label{app:win_samples}
\Cref{tab:xsum_samples,tab:samsum_samples,tab:totto_samples,tab:webnlg_samples,tab:e2e_samples,tab:fetaqa_samples} present qualitative winning examples of our model versus the fine-tuned model, judged by GPT-4. We additionally highlighted differences between both predictions, which further underscores the liability of GPT-4 as a judge for faithfulness.

Qualitative analysis on XSum reveals that the \sft baseline often struggles to ground its summaries in the provided article. In contrast, \scope produces fewer hallucinations but tends to directly quote portions of the article. For data-to-text tasks, the \sft baseline frequently infers extra information, whereas \scope remains closely aligned with the structured data.

% \section{Dataset details}
% \Cref{tab:dataset_splits} presents the sizes of the different splits we used.

% \begin{table}[h]
% \centering
% \begin{tabular}{lrrr}
% \toprule
% \textbf{Dataset} & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
% \midrule
% ToTTo & 121,153 & 7,700 & 7,700 \\
% E2E & 33,525 & 1,484 & 1,847 \\
% FeTaQA & 7,326 & 1,001 & 2,003 \\
% WebNLG & 35,426 & 1,667 & 1,779 \\
% \bottomrule
% \end{tabular}
% \caption{Number of samples in train/validation/test splits for ToTTo, E2E, FeTaQA and WebNLG.}
% \label{tab:dataset_splits}
% \end{table}

% \section{Computational details}
% We ran all our experiments on Nvidia A100-80Gb. Trainings were done on 4 GPUs and inference on 1 to 4 GPUs. We estimate the total amount of GPU hours usage to 2000h.

% \section{Licenses}
% \label{sec:license}

% \paragraph{ToTTo.} the dataset is released under Creative Commons Share-Alike 3.0 license.

% \paragraph{FeTaQA.} The dataset is distributed under a Creative Commons Attribution-ShareAlike 4.0 International License.

% \paragraph{WebNLG.} CC-by-NC-4.0: Creative Commons Attribution Non Commercial 4.0 International

% \paragraph{E2E.} CC-by-SA-4.0: Creative Commons Attribution Share Alike 4.0 International

% \paragraph{Models weights.} Llama-2 weights are released under the licence available at \url{https://ai.meta.com/llama/license/}. Mistral models and weights are released an Apache 2.0 licence. DeBERTa is licensed under the MIT License \url{https://github.com/microsoft/DeBERTa/blob/master/LICENSE}.

% \paragraph{Softwares.} Our code is based on Pytorch \citep{pytorch}, Huggingface \cite{huggingface-transformers}, huggingface/trl and SentenceTransformer \citep{sentence-transformer} licensed under the Apache License 2.0.

\section{Human evaluation protocol}
\label{app:human-eval}
For this study, we recruited five European annotators, all fluent in English, on a voluntary basis. For each sample, they were presented with an input table and two predictions from the \textsc{Llama-2-7b} model, trained using \scope and \sft, respectively. These predictions were randomly labeled as 'Text A' and 'Text B'. The models corresponding to A and B were randomly selected for each sample to prevent any positional bias. The annotators were instructed to choose between the options 'Text A is more faithful' or 'Text B is more faithful' depending on their preference for description A or B, respectively. If both texts are deemed equally faithful, the annotators should select 'Tie'. If both descriptions have one or several faithfulness issues, they should both be considered unfaithful and rated as 'Tie'. The following instructions were provided to the annotators:

\begin{quote}
\textbf{Instructions for Faithfulness Evaluation}

Your task is to assess which text description is more faithful to the corresponding table. In this context, a text is considered \textbf{faithful} if all information it contains is directly supported by the content of the table.

\begin{itemize}
    \item If the description introduces any unsupported or incorrect information, it should be rated as \textbf{unfaithful}.
    \item If both descriptions contain one or more faithfulness issues, rate them as a \textbf{Tie}.
\end{itemize}

To guide your evaluation:
\begin{itemize}
    \item Carefully compare each detail in the description with the table to ensure accuracy.
    \item A description should not distort, omit, or add information that is not present in the table.
    \item If you notice even a single instance of unsupported information in a description, it should be rated as unfaithful.
    \item If both descriptions have one or several faithfulness issues, they should both be considered unfaithful and rated as 'Tie'.
\end{itemize}

Please choose between the following options for each comparison:
\begin{itemize}
    \item \textbf{Text A is more faithful}
    \item \textbf{Text B is more faithful}
    \item \textbf{Tie} (if both descriptions are equally faithful or contain faithfulness issues)
\end{itemize}
\end{quote}

\section{On the significance improvements of SCOPE against the other baselines}
\paragraph{Faithfulness metrics.}
We performed independent two-sample t-tests to assess whether there were statistically significant differences in the mean values of specified metrics between the baseline \sft and comparison model \scope. This test was chosen as it accounts for unequal variances and assumes independence between the two samples. For each metric, we calculated the t-statistic and corresponding p-value, allowing us to evaluate the likelihood that observed differences in means arose by chance. The results provide a statistical basis for determining the significance of observed variations across datasets. Using a standard p-value of 0.05, \scope is statistically significantly better than \sft across the vast majority of datasets, metrics and models.

\begin{table}[h]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lcccccccccccccc}
    & \multicolumn{2}{c}{\textbf{ToTTo}} & \multicolumn{2}{c}{\textbf{FeTaQA}} & \multicolumn{2}{c}{\textbf{WebNLG}} & \multicolumn{2}{c}{\textbf{E2E}} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
    & PARENT & NLI & PARENT & NLI & PARENT & NLI & PARENT & NLI \\
    \midrule
    \textsc{Llama2-7b} & $3.19\mathrm{e}{-50}$ & $4.73\mathrm{e}{-17}$ & $2.21\mathrm{e}{-12}$ & $3.68\mathrm{e}{-3}$ & $1.11\mathrm{e}{-31}$ & $4.55\mathrm{e}{-4}$ & $7.18\mathrm{e}{-3}$ & $4.01\mathrm{e}{-3}$ \\
    \textsc{Llama2-13b} & $4.91\mathrm{e}{-60}$ & $6.22\mathrm{e}{-31}$ & $1.37\mathrm{e}{-9}$ & $9.26\mathrm{e}{-2}$ & $1.06\mathrm{e}{-55}$ & $1.85\mathrm{e}{-4}$ & $1.48\mathrm{e}{-3}$ & $1.02\mathrm{e}{-2}$ \\
    \textsc{Mistral-7b} & $1.86\mathrm{e}{-103}$ & $2.26e{-24}$ & $1.08\mathrm{e}{-3}$ & $1.13\mathrm{e}{-1}$ & $7.64\mathrm{e}{-1}$ & $1.68\mathrm{e}{-1}$ & $4.51\mathrm{e}{-5}$ & $2.57\mathrm{e}{-1}$ \\
    \midrule
\end{tabular}
}
\caption{p-values of paired t-tests between SCOPE and SFT for data-to-text datasets.}
\label{tab:llama13b_metrics}
\end{table}

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccccc}
    & \multicolumn{3}{c}{\textbf{SAMSum}} & \multicolumn{3}{c}{\textbf{XSum}} & \multicolumn{3}{c}{\textbf{PubMed}} \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
    \textbf{Model} & Align & FactCC & QEval & Align & FactCC & QEval & Align & FactCC & QEval \\
    \midrule
    \textsc{Llama2-7b} & $1.25\mathrm{e}{-3}$ & $1.1\mathrm{e}{-1}$ & $4.26\mathrm{e}{-2}$ & $3.56\mathrm{e}{-80}$ & $3.54\mathrm{e}{-69}$ & $4.67\mathrm{e}{-144}$ & $3.29\mathrm{e}{-11}$ & $4.79\mathrm{e}{-21}$ & $3.47\mathrm{e}{-8}$ \\
    \textsc{Llama2-13b} & $1.48\mathrm{e}{-2}$ & $0.1216$ & $3.7\mathrm{e}{-3}$ & $1.10\mathrm{e}{-69}$ & $3.16\mathrm{e}{-55}$ & $5.36\mathrm{e}{-160}$ & $1.06\mathrm{e}{-9}$ & $3.27\mathrm{e}{-16}$ & $2.53\mathrm{e}{-7}$ \\
    \textsc{Mistral-7b} & $3.98\mathrm{e}{-3}$ & $3.56\mathrm{e}{-2}$ & $4.38\mathrm{e}{-1}$ & $5.37\mathrm{e}{-73}$ & $3.16\mathrm{e}{-55}$ & $3.33\mathrm{e}{-189}$ & $1.20\mathrm{e}{-17}$ & $3.05\mathrm{e}{-22}$ & $1.10\mathrm{e}{-12}$ \\
    \bottomrule
\end{tabular}
}
\caption{p-values of paired t-tests between SCOPE and SFT for summarization datasets.}
\label{tab:p_values_summ}
\end{table}


\paragraph{Pairwise rating.}
To assess whether our SCOPE improves significantly over the other baselines based on our GPT-4 win-tie-lose pairwise preference evaluations, we perform the McNemar’s statistical test to determine if the observed difference in wins is likely due to chance or if it reflects a truly performance difference. \\
- \textbf{Null hypothesis}: There is no significant difference in performance between SCOPE and given baseline. Any difference in win counts is due to random chance.\\
- \textbf{Alternative hypothesis}: SCOPE performs significantly better than the considered baseline.\\
To do this, we count the number of samples SCOPE wins over SFT while the compared baseline loses to it ($N_{AB}$) and vice versa ($N_{BA}$) without taking into account the ties. The McNemar's test formula is given by:
$$\chi^2= \frac{(N_{AB} - N_{BA})^2}{N_{AB} + N_{BA}}$$
Under the null hypothesis, $\chi^2$ follows a chi-square distribution with 1 degree of freedom. \\
We consider a standard p-value of 0.05. A p-value less than 0.05 means we reject the null hypothesis. Here are the p-values on the GPT-4-as-a-judge evaluations:
\begin{table}[h!]
\small
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccccc}
\textbf{Comparison} & \textbf{Totto} & \textbf{WebNLG} & \textbf{FeTaQA} & \textbf{E2E} & \textbf{SamSum} & \textbf{XSum} & \textbf{PubMed} \\ \midrule 
\scope vs \sft & $3.696\mathrm{e}{-97}$ & $3.127\mathrm{e}{-23}$ & $9.7\mathrm{e}{-4}$ & $3.559\mathrm{e}{-14}$ & $1.171\mathrm{e}{-25}$ & $6.744\mathrm{e}{-153}$ & $3.944\mathrm{e}{-41}$ \\ 
\scope vs \pmi & $9.492\mathrm{e}{-7}$ & $7.7\mathrm{e}{-3}$ & $6.744\mathrm{e}{-1}$ & $4.78\mathrm{e}{-2}$ & $1.3\mathrm{e}{-3}$ & $6.269\mathrm{e}{-55}$ & $2.305\mathrm{e}{-19}$ \\ 
\scope vs \critic & $1.473\mathrm{e}{-8}$ & $1.95\mathrm{e}{-2}$ & $2.1\mathrm{e}{-1}$ & $2.7\mathrm{e}{-3}$ & $5.41\mathrm{e}{-11}$ & $4.781\mathrm{e}{-74}$ & $2.313\mathrm{e}{-4}$ \\ 
\scope vs \cad & $1.226\mathrm{e}{-7}$ & $6.792\mathrm{e}{-5}$ & $9.39\mathrm{e}{-2}$ & $1.33\mathrm{e}{-2}$ & $1.23\mathrm{e}{-7}$ & $2.611\mathrm{e}{-59}$ & $1.522\mathrm{e}{-11}$ \\ 
\scope vs \cliff & $1.226\mathrm{e}{-11}$ & $3.745\mathrm{e}{-11}$ & $6.25\mathrm{e}{-2}$ & $5.6\mathrm{e}{-4}$ & $2.04\mathrm{e}{-6}$ & $3.025\mathrm{e}{-4}$ & $1.314\mathrm{e}{-21}$ \\ 
\bottomrule
\end{tabular}}
\caption{p-values of the McNemar's test on GPT-4 evaluation results}
\label{tab:comparison}
\end{table}
\\The results from McNemar's test show that:\\
(i) SCOPE shows consistently a significant improvement over the SFT baseline.\\
(ii) Most of the comparisons between SCOPE and the other baselines are statistically significant (p-value < 0.05) on ToTTo, WebNLG, E2E, SamSum, and XSum with the exception of FeTaQA.



% \begin{figure*}[b]
%   \centering
%   \subfloat[Training with $\alpha = 0.1$.]{\includegraphics[width=0.35\textwidth]{images/logprobs_a0.1_e2e.pdf}}
%   \subfloat[Training with $\alpha = 0.5$.]{\includegraphics[width=0.35\textwidth]{images/logprobs_a0.5_e2e.pdf}}
% \subfloat[Training with $\alpha = 0.7$.]{\includegraphics[width=0.35\textwidth]{images/logprobs_a0.7_e2e.pdf}}
%   \caption{Training dynamics on E2E dataset.}
%   \label{fig:train_alpha_e2e}
% \end{figure*}



\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/xsum_samples}
}
\caption{XSum random winning samples. For the sake of clarity, we purposely choose articles of reasonable size. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:xsum_samples}
\end{table*}

\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/samsum_samples}
}
\caption{SAMsum random winning samples. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:samsum_samples}
\end{table*}

\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/totto_samples}
}
\caption{ToTTo random winning samples. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:totto_samples}
\end{table*}

\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/webnlg_samples}
}
\caption{WebNLG random winning samples. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:webnlg_samples}
\end{table*}

\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/e2e_samples}
}
\caption{E2E random winning samples. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:e2e_samples}
\end{table*}

\begin{table*}[b]
\centering
\resizebox{\textwidth}{!}{
\input{tables/fetaqa_samples}
}
\caption{FeTaQA random winning samples. \redhl{Red} highlights facts that are hallucinations. \yellowhl{Yellow} highlights facts that are more faithful to the input.}
\label{tab:fetaqa_samples}
\end{table*}