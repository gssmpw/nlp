\section{Related Works}
Advanced Driver Assistance Systems (ADAS) improve road safety and driving efficiency, but their adoption is influenced by multiple factors, including user acceptance, awareness, and trust in the technology. This section reviews existing research on ADAS adoption, identifying key gaps related to driver acceptance, education and awareness, and trust in ADAS transparency.

% \subsection{Driver Acceptance and Demographic Influences}
Research shows that demographic factors significantly affect ADAS adoption. Studies by Ebecken et al., "Human Factors in the Design of Advanced Driver Assistance Systems" and Lee et al., "Older Adults' Perception of and Acceptance for Driver Assistance Systems" indicate that older drivers generally perceive ADAS favorably due to its ability to extend independent mobility. Features such as lane-keeping assistance and forward collision warnings are particularly beneficial when adapted for sensory impairments. However, findings suggest that while older drivers recognize ADAS benefits, concerns about system complexity and interface usability hinder long-term adoption. Additionally, acceptance levels among younger drivers remain underexplored, with studies producing mixed findings on the influence of age, gender, and driving experience. Further research is needed to clarify how different demographic factors shape ADAS perceptions and long-term usage patterns.

% \subsection{Awareness, Learning Methods, and User Misuse}
Understanding how drivers learn and interact with ADAS is crucial for effective adoption. A study in Australia by Kim et al., "Exploring Driver Adoption of Advanced Driver Assistance Systems: An Australian Perspective" found that most drivers acquire ADAS-equipped vehicles primarily for safety but receive minimal structured training on their functionalities. Many rely on trial-and-error learning or inconsistent point-of-sale education from salespersons, leading to potential misuse, over-reliance, or disengagement. This aligns with broader concerns that inadequate awareness of ADAS capabilities contributes to risky behaviors, such as failing to override automation when necessary or misinterpreting system limitations. While some studies propose improved Human-Machine Interfaces (HMI) to enhance learning by Gao et al., "Human-Machine Interface Design for Advanced Driver Assistance Systems", research on structured ADAS education remains limited, highlighting a need for more comprehensive user training strategies.

% \subsection{Trust, Explainable AI, and System Transparency}
Trust in ADAS is a critical determinant of adoption, yet skepticism about system reliability persists due to the opaque, black-box nature of machine learning models. While research has examined ADAS acceptance factors, few studies have explored how AI transparency influences trust. One notable study by Kim et al., "Analyzing Driver Acceptance Factors for Advanced Driver Assistance Systems Using Random Forest Algorithm" used a random forest algorithm to analyze ADAS acceptance, identifying speed, warning duration, and driver age as key factors. However, this study did not assess trust-related concerns arising from model interpretability. Research on XAI suggests that techniques like SHAP could improve driver trust by offering more transparent explanations of system decisions, yet their application to ADAS remains underexplored. Bridging this gap is crucial for enhancing driver confidence and addressing concerns about reliability and decision-making transparency.

% \subsection{Research Gap and Justification}
Despite extensive research on ADAS adoption, significant gaps remain. Many studies focus on isolated ADAS features, such as lane departure warnings or forward collision systems, without considering the interplay between multiple functionalities. Additionally, existing research is often limited to specific driver populations, restricting the generalizability of findings. More critically, the role of XAI in ADAS acceptance remains underexplored, leaving a crucial gap in understanding the relationship between explainability and user perception.