\section{Related work}
\textbf{Classifier guards.} Markov et al.____ proposed an active learning strategy that identifies relevant samples for labeling, balances between uncertainty and diversity, and leverages redundancy to capture rare events. Rebedea et al.____ developed guardrails control LLM output, preventing harmful topics, following dialogue paths, and maintaining language styles. Chi et al.____ introduced multimodal LLM-based safeguard that classifies content as safe or unsafe based on user-provided guidelines, conversation context, and output formats. Kim et al.____ highlight the necessity of developing better definitions for unsafe outputs. Wang et al.____ point to challenges in jailbreak defense even in narrow contexts, suggests future directions involving classifier calibration and human feedback integration, suggesting future directions involving classifier calibration and human feedback integration. Sharma et al.____ proposed "Constitutional Classifiers", which use natural-language rules to train classifier safeguards defining what constitutes permitted and restricted content.

\textbf{Jailbreaking} Lapid et al.____ developed a black-box Genetic Algorithm (GA) to manipulate LLMs. Huang et al.____ show that manipulation of generation strategies, such as removing system prompts and altering decoding parameters, can easily disrupt model alignment. Samvelyan et al.____ introduced "Rainbow Teaming" methodology that sefines features like risk category and attack style to diversify prompts and rank them based on their effectiveness. Doumbouya et al.____ developed an open-source automated red-teaming platform for generating and analyzing jailbreak attacks. Andriushchenko et al.____ applied prompt templates, random suffix search, self transfer from easier tasks, transfer and prefilling attacks and showed that adaptive attacks are necessary to accurately assess LLM robustness. Hughes et al.____ proposed "Best-of-N (BoN) Jailbreaking," a black-box algorithm and demonstrated its effectiveness across text, vision, and audio language models, achieving high Attack Success Rates (ASR).