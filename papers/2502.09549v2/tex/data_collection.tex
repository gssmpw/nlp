\section{Dataset Collection}
\label{sec:datacollection}

\begin{table}[t]
\caption{Overview of Our Collected Dataset from July 2021 to October 2024 (39 months). We collect a total of 2.3M phishing URLs and 765K domains.}
\vspace{-10px}
\label{tab:dataset}
\resizebox{0.9\linewidth}{!}{ 
\begin{NiceTabular}{l r r r}
\toprule
\multicolumn{1}{c}{\textbf{Type}} & \multicolumn{1}{c}{\textbf{\# URLs}} & \multicolumn{1}{c}{\textbf{\# Domains}} & \multicolumn{1}{c}{\textbf{\# TLD}}\\
\midrule
APWG~\cite{APWGTheA83:online} & 2,184,835 & 697,237 & 1,203\\
phishunt.io~\cite{phishunt94:online} & 262,755 & 66,743 & 598\\
PhishStats~\cite{PhishSta46:online} & 221,331 & 57,299 & 541\\
OpenPhish~\cite{OpenPhis99:online} & 115,804 & 26,127 & 480\\
Malware-filter~\cite{curbengh9:online} & 76,465 & 24,300 & 470 \\
PhishTank~\cite{PhishTan96:online} & 5,579 & 1,695 & 195\\
Phishing.Database~\cite{mitchell17:online} & 393 & 236 & 51\\
\midrule
Total (Distinct) &2,294,267  & 765,910 & 1,258 \\
\bottomrule
\multicolumn{4}{l}{-- APWG: collected from Jul. 15, 2021 to Oct. 31, 2024.}\\
% \multicolumn{4}{l}{and Oct. 31, 2024 (1204 days).}\\
\multicolumn{4}{l}{-- Others: collected from May 31, 2024 to Oct. 31, 2024.}\\
% \multicolumn{4}{l}{and Oct. 31, 2024 (153 days).}
\end{NiceTabular}
}
\vspace{-10px}
\end{table}

To address our research questions, we collect a dataset comprising phishing URLs (\autoref{sec:collection:phishing:domain}), DNS records using a custom-built crawler (\autoref{sec:dns_record_collection}), and registration timestamps of phishing domains to analyze their characteristics and lifespans (\autoref{sec:domain_registration_collection}).
% define maliciously registered domains (\autoref{sec:def_mal_registered_domains}),
% \DK{data collection section}
% analyzing domain characteristics (\autoref{sec:mal-reg-char}),
% domain registration/deregistration histories (\autoref{sec:lifespan}).
% , and DNS records (\DK{section ref}). 


% We collect a dataset of phishing webisites




\subsection{Phishing URL and Domain Collection}
\label{sec:collection:phishing:domain}
As shown in~\autoref{tab:dataset}, we first collect 2.3M phishing URLs and their associated 765K distinct domains (1,258 TLDs) across a 39-month period spanning July 2021 to October 2024 
% To ensure comprehensive data collection, we aggregate phishing URLs 
from multiple prominent phishing blocklists including APWG (Anti-Phishing Working Group)~\cite{APWGTheA83:online}, Malware-filter~\cite{curbengh9:online}, 
OpenPhish~\cite{OpenPhis99:online}, 
Phishing-Database~\cite{mitchell17:online}, 
phishunt.io~\cite{phishunt94:online},
PhishStats~\cite{PhishSta46:online},
and PhishTank~\cite{PhishTan96:online}.
% Other blocklists have unique URLs of 115,805 and unique domains of 84,600 with 664 unique TLDs.
These sources have been used to better understand the phishing ecosystem~\cite{oest2020phishtime,oest2019phishfarm,kim2021security,lim2024phishing,oest2020sunrise,8376206}.
Particularly, APWG is a global industry association of anti-phishing entities, including banks and financial services companies, Internet service providers, law enforcement agencies, and security vendors.
APWG maintains an extensive database of phishing URLs gathered from multiple sources. 





% our study leverages a comprehensive dataset of phishing websites collected over a three-year period from July 2021, to September 2024 (39 months). 
% We collect phishing URLs from multiple reputable blocklists including  APWG, Malware-filter~\cite{curbengh9:online}, 
% OpenPhish~\cite{OpenPhis99:online}, 
% Phishing.Database~\cite{mitchell17:online}, 
% phishunt.io~\cite{phishunt94:online},
% PhishStats~\cite{PhishSta46:online},
% and PhishTank~\cite{PhishTan96:online}.
% These URLs serve as a blocklist for the public to some extent (APWG requires an API key).
% In total we collect \KL{XX} URLs and \KL{XX} domains as shown in~\autoref{tab:dataset}.

% Our collection of URLs serves as a trusted resource, aggregating information about active phishing campaigns reported by various members and communities. 
% To ensure comprehensive coverage, we collect real-time feeds from multiple blocklists, each with varying update frequencies. 
% For instance, the \texttt{APWG} feed updates approximately every 120 seconds, offering near real-time data. 
% Other blocklists provide updates at longer intervals, ranging from 90 minutes to 24 hours. 
% Specifically, \texttt{PhishStats} updates every 90 minutes, while \texttt{OpenPhish} refreshes every 12 hours. 
% Similarly, \texttt{PhishTank} and \texttt{phishunt.io} update hourly, and \texttt{Phishing.Database} updates every 24 hours. 
% The total number of URLs and domains collected are shown in~\autoref{tab:dataset}.
% This diverse set of sources ensures a robust and dynamic dataset for analyzing phishing activity.
% URLs from our collection are a trusted resource that aggregates information about active phishing campaigns reported by members and communities.
% We collect real-time feed from each of the blocklists.
% From APWG, the feed is updated on an average of 120 seconds.
% Other blocklists provide updates every 90 minutes to 24 hours.
% (OpenPhish: 12 hours, Phishing.Database: 24 hours, phishunt: 1 hour, PhishStats: 90 minutes, PhishTank: 1 hour)


% Access to this feed was secured through a research partnership with APWG, allowing us to collect data on a large scale while adhering to ethical research practices. 




\subsection{DNS Record Collection}
\label{sec:dns_record_collection}
% \DK{Summarize the purpose of this dataset collection in one sentence.}
To answer our research question 
(\textbf{RQ1:} \textit{What are the characteristics of maliciously registered domains, and how can we find maliciously registered domains?}),
% (\textbf{RQ2:} \textit{What are the characteristics of maliciously registered domains?}), 
we develop a comprehensive DNS data collection system to monitor and analyze how phishing attackers configure and modify their DNS settings across different geographic locations. 
Our system periodically collects DNS records types of our collected phishing domains 
(\ie, \cc{A}, \cc{AAAA}, \cc{NS}, \cc{MX}, \cc{TXT})
% (\eg, \cc{A}, \cc{AAAA}, \cc{NS}, \cc{MX}, \cc{TXT}, \cc{RRSIG}, \cc{DNSKEY}, \cc{DS}, \cc{NSEC}) 
to provide detailed insights into their behavior.
% \MJ{Why such a long "e.g." list? Which RRtype is not included in this list? I would either reduce the example to a few records, or go the "i.e." route and list all.}\KL{Updated}
% Our longitudinal data collection spans 39 months, capturing the complete DNS configuration lifecycle of phishing domains.


\PP{DNS Crawler Design}
\autoref{fig:overview} illustrates our data collection process. 
% \RM{Fig. 1 needs to have a word `crawler'}\KL{added crawler icon}
We implement a multi-threaded crawler designed for scalability and reliability, using concurrent processing to efficiently handle thousands of domain queries. The crawler maintains a connection pool for database access and implements file-locking mechanisms to prevent data corruption during parallel operations.
The crawler collects detailed DNS information using the \cc{dig} command with comprehensive parameters. 
This approach enables the recursive collection of DNS records, capturing all possible types. For reliability, our system implements a retry mechanism with exponential backoff, attempting each query up to 5 times before marking it as failed.

% \PP{Temporal Resolution}
Our crawler operates at 30-minute intervals, enabling us to capture both gradual changes and modifications in DNS configurations. This high-frequency polling is crucial for detecting dynamic DNS behaviors that phishing attackers might employ to evade detection, such as fast-flux DNS or rapid record updates.
The system stores DNS responses in a structured JSON format, organized by domain, timestamp, and vantage point.

Our data collection period spanned from June 6, 2024, to October 31, 2024. 
We gathered URLs from blocklist feeds and extracted their domains and subdomains to perform DNS queries during this period. 
Using our crawler, we collected a total of 94,798 domains, including subdomains, with 11,932 being unique domains.
% \RM{A bit confused here. How can DNS crawler collect URLs? i assume URLs are phishing URLs? but 4.1 said you collected 2.3M URLs. } \KL{clarified}

% An SQLite database tracks each domain-resolver pair's query status, retry attempts, and failure timestamps. This database helps maintain collection continuity and enables systematic analysis of DNS record evolution over time.
% This helps us to collect over 211 million DNS records.




\PP{Vantage Points}
Moreover, to detect location-based DNS configurations, we query DNS records from 10 geographically diverse DNS resolvers. These include global providers (Google, Cloudflare, Quad9, OpenDNS) and regional servers across six continents (Brazil, South Africa, UK, Australia, South Korea, US). This distributed approach reveals if phishing domains serve different DNS responses based on geographic locationâ€”a technique attackers might use to evade detection or target specific regions.
\vspace{-10px}
% To investigate this tactic, our crawler queries DNS records from multiple vantage points worldwide (\eg, Cloudflare, OpenDNS, and locations such as BR, ZA, UK, AU, and KR). 
% The vantage points used include IP addresses such as 143.110.169.182, 160.36.0.66, 170.64.147.31, 200.150.97.226, 208.67.222.222, 222.97.189.7, 41.23.216.150, 8.8.8.8, and 9.9.9.9. \KH{This sentence is too verbose, listing IPs. }
% This approach allows us to determine whether phishing attackers adapt their DNS settings based on the geographic location of potential victims, revealing evasion strategies that target specific vantage points.\KH{This seems unfounded. Please add more technical elements.}


\subsection{Domain Registration Collection}
\label{sec:domain_registration_collection}
To investigate the lifecycle of maliciously registered domains (\textbf{RQ2:} ``\textit{What is the lifecycle of a maliciously registered domain?}''), we collect registration information (including timestamps and registrars) of our collected phishing domains.
We first utilize WHOIS and the Registration Data Access Protocol (RDAP)~\cite{RDAPORG31:online} from registrars and registries as WHOIS and RDAP provides basic information, such as registrar names and domain registration/expiration dates.

% whois: 25,987 
% rdap: 436,176
% ctlog: 71,156
% domaintools: 27,929
% DNS Coffee: 526,867 (DZDB is inclusive in this data)

\PP{GDPR Restriction}
However, due to the European General Data Protection Regulation (GDPR), the registration timestamp and the registrant's information (such as their name, address, and phone number) can be unavailable to the public.
% From our collection of WHOIS, we have seen that domains can
To this end, we leverage the methodology of COMAR~\cite{maroofi2020comar} to obtain registration timestamps of the domains whose information is hidden.
% Specifically, by using CT logs, we can utilize the first timestamp of when the certificate was issued to a domain.
% Previous study~\cite{kim2021security} shows that TLS certificates are used for phishing attacks.\DK{<- does not make sense for the reason why we use CT for collecting timestamps.}
% We also leverage DNSDB, a passive DNS (pDNS) dataset provided by DomainTools~\cite{Introduc45:online}, to obtain the first-seen timestamps of domains in the pDNS collection.
Furthermore, we also utilize DNS Zone files from DNS Coffee~\cite{homeDNSC2:online} and DZDB~\cite{homeDZDB83:online} for more comprehensive registration timing analysis. 
These services daily collect and archive TLD Zone files from ICANN~\cite{AboutZon71:online}.
The Zone file data provides 
first-appearance and last-seen timestamps of domains; the last-seen timestamp indicates when a domain has been deregistered and is no longer active. 
We also utilize passive DNS (pDNS) data through DomainTools' Farsight DNSDB~\cite{Introduc45:online}. 
This dataset includes a first-seen timestamp, indicating the earliest recorded observation of a domain in the passive DNS.

% By comparing this timestamp with blocklist detection times, we determine whether a domain is deregistered before or after being flagged, providing critical insights into domain lifecycles and detection timelines.

\PP{Our Collected Registration Data}
Our dataset includes domain registration timestamps collected from various sources: WHOIS (25,987 domains), RDAP (436,176 domains), CT logs (71,156 domains), DomainTools (27,929 domains), and DNS Coffee (526,867 domains, inclusive of DZDB data).
In total, we have 526,954 registration timestamps for unique domains. 
% \RM{We have the registration timestamps of 526,954 unique domains?}\KL{yes}
% Specifically, we determine registration timestamps by analyzing multiple data sources: the Registration Data Access Protocol (RDAP)~\cite{RDAPORG31:online}, TLS certificates (CT Logs)\DK{cite}, and passive DNS first-seen timestamps~\cite{Introduc45:online}.
% Furthermore, we enhance this approach by 
% 
% More specifically, we begin by collecting timestamps from WHOIS and RDAP, both of which provide domain registration timestamps and associated information, such as the registrar. Additionally, we utilize zone files to extract both the first-appearance and last-seen timestamps of domains. The last seen timestamp indicates when a domain has been deregistered and is no longer active. By comparing this timestamp with blocklist detection times, we determine whether a domain was deregistered before or after being flagged, providing critical insights into domain lifecycles and detection timelines.
% 
In sum, our approach enables us to achieve 76.3\% (526,954 out of 690,502) coverage of our collected domains. While relying solely on registration timestamps from WHOIS and RDAP provides 62.4\% (431,011 domains) coverage, incorporating additional data sources such as zone files, pDNS data, and CT logs significantly improves the completeness of our timestamp data.

% \DK{more detail here (summary of our collected dataset). Specifically, out of XXX distinct domains, we collect the registration information (timestamps) of XXX distinct phishing domains.}
% Using COMAR method~\cite{maroofi2020comar} and improving upon the current method, we use WHOIS, CT Log for the first appeared time, first appeared time from pDNS~\cite{Introduc45:online}, Registration Data Access Protocol (RDAP)~\cite{RDAPORG31:online}, and Zone file from DZDB~\cite{homeDZDB83:online} and DNS Coffee~\cite{homeDNSC2:online}.
% We first collect a timestamp from WHOIS, RDAP since both provide a timestamp of registration of a domain, a registration information (\ie, registrar).
% We also leverage the zone file to get the first appeared timestamp and also last seen timestamp in the zone file.
% The last seen timestamp shows that the domain is deregistered and no longer alive. 
% We use this timestamp to measure when a domain is deregistered whether before or after detected by blocklist.

% \subsubsection{Zone File Collection}
% DZDB, DNS Coffee, DomainTools
% \subsection{Retry Mechanism for Inaccessible Domains}
% Our crawler accesses phishing domains every 30 minutes to collect period data.
% This can help us with seeing any changes in DNS records.
% To reduce network load and eliminate infinite storage increase, we stop accessing phishing domains after 3 inaccessible trials.
% We heuristically measure that 3 trials are suitable to determine whether the phishing domain is active.

% We improve upon the method shown in~\cite{maroofi2020comar} by adding Zone file information.
% details about the registrant, such as their name, address, and phone number, are often hidden and unavailable to the public due to the European General Data Protection Regulation (GDPR).




% \PP{Registration Timestamp}
% uilding on the COMAR method~\cite{maroofi2020comar} and improving upon existing approaches, we incorporate multiple data sources to analyze domain registration and activity. These include WHOIS, CT Logs for first appearance timestamps, passive DNS (pDNS) data~\cite{Introduc45:online}, the Registration Data Access Protocol (RDAP)~\cite{RDAPORG31:online}, and Zone file from DZDB~\cite{homeDZDB83:online} and DNS Coffee~\cite{homeDNSC2:online}.

% We begin by collecting timestamps from WHOIS and RDAP, both of which provide domain registration timestamps and associated information, such as the registrar. Additionally, we utilize zone files to extract both the first-appearance and last-seen timestamps of domains. The last seen timestamp indicates when a domain has been deregistered and is no longer active. By comparing this timestamp with blocklist detection times, we determine whether a domain was deregistered before or after being flagged, providing critical insights into domain lifecycles and detection timelines.
% Using COMAR method~\cite{maroofi2020comar} and improving upon the current method, we use WHOIS, CT Log for the first appeared time, first appeared time from pDNS~\cite{Introduc45:online}, Registration Data Access Protocol (RDAP)~\cite{RDAPORG31:online}, and Zone file from DZDB~\cite{homeDZDB83:online} and DNS Coffee~\cite{homeDNSC2:online}.
% We first collect a timestamp from WHOIS, RDAP since both provide a timestamp of registration of a domain, a registration information (\ie, registrar).
% We also leverage the zone file to get the first appeared timestamp and also last seen timestamp in the zone file.
% The last seen timestamp shows that the domain is deregistered and no longer alive. 
% We use this timestamp to measure when a domain is deregistered whether before or after detected by blocklist.

% \subsubsection{Zone File Collection}
% DZDB, DNS Coffee, DomainTools
% \subsection{Retry Mechanism for Inaccessible Domains}
% Our crawler accesses phishing domains every 30 minutes to collect period data.
% This can help us with seeing any changes in DNS records.
% To reduce network load and eliminate infinite storage increase, we stop accessing phishing domains after 3 inaccessible trials.
% We heuristically measure that 3 trials are suitable to determine whether the phishing domain is active.


