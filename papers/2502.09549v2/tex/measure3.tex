\section{Lifespan of Phishing Domains}


\label{sec:lifespan}

% For phishing attackers to maximize their monetization, keeping their phishing websites active for as long as possible is essential. To understand this, we analyze how phishing attackers register their domains and examine the timelines from registration to detection by blocklists (\eg, APWG) and eventual deregistration.
This section examines the lifecycle of phishing domains, focusing on two critical phases: (1) the time from registration to detection, (2) the time from detection to deactivation, and (3) the comparison of detection time between blocklists. 
These phases provide insights into how phishing attackers sustain their domains to maximize monetization and evade timely countermeasures. 
By analyzing detection delays and post-detection persistence across different domain types, brands, and registration strategies, we uncover characteristics in the lifespan of phishing domains (\ie, maliciously registered). 
Our findings highlight the need for improved detection mechanisms to reduce delays and more robust enforcement measures to ensure rapid domain takedown, thereby limiting attackers' ability to exploit these domains.
% \KH{Missing statistical significance tests for lifespan differences.}\KH{analysis mixes registration-to-detection and detection-to-deregistration metrics without clear delineation.}

% \subsection{Trend of Phishing Domain}

% \begin{figure}[!t]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/tld_by_year.pdf}
%     \caption{TLD by Year.\KL{need a better color and sizing}}
%     \label{fig:tld_by_year}
% \end{figure}

% We first measure how phishing attackers deploy phishing domains and which TLDs are widely used.
% \KL{Add phishing domain over time graph}
% \KL{Add top TLD}

% \rtbox{
% \textbf{Takeaway:} 
% Even when a domain is maliciously registered, detection systems often fail to identify it significantly earlier than other types of domains.
% }


% \begin{table}[t]
% \caption{TLD by Year (Top 10).}
% \label{tab:dataset}
% \resizebox{0.98\linewidth}{!}{ 
% \begin{NiceTabular}{r r r r r r r r r r r}
% \toprule
% \multicolumn{1}{c}{\textbf{Year}} & \multicolumn{1}{c}{\textbf{.com}} & \multicolumn{1}{c}{\textbf{.top}} & \multicolumn{1}{c}{\textbf{.xyz}} & \multicolumn{1}{c}{\textbf{.shop}} & \multicolumn{1}{c}{\textbf{.tk}} & \multicolumn{1}{c}{\textbf{.cn}} & \multicolumn{1}{c}{\textbf{.ml}} & \multicolumn{1}{c}{\textbf{.online}} & \multicolumn{1}{c}{\textbf{.net}} & \multicolumn{1}{c}{\textbf{.info}} \\
% \midrule
% Total & 211,494 & 75,272 & 35,901 & 26,150 & 22,453 & 20,460 & 14,153 & 13,951 & 12,607 & 9,584 \\
% \midrule
% 2021 & 31,121 & 5,742 & 6,531 & 1,392 & 992 & 2,111 & 977 & 935 & 2,132 & 1,264 \\
% 2022 & 84,705 & 23,406 & 18,835 & 4,323 & 17,932 & 10,034 & 12,256 & 6,734 & 5,343 & 3,832 \\
% 2023 & 63,995 & 33,241 & 8,136 & 8,457 & 3,425 & 3,641 & 916 & 4,829 & 3,646 & 3,036 \\
% 2024 & 31,673 & 12,883 & 2,399 & 11,978 & 104 & 4,674 & 4 & 1,453 & 1,486 & 1,452 \\
% \bottomrule
% \end{NiceTabular}
% }
% \end{table}


\begin{figure*}[!t]
    \centering
    \includegraphics[width=.98\linewidth]{fig/apwg_vs_others.pdf}
    \vspace{-15px}
    \caption{Days Between APWG Detection and Other Blocklists.
    Other than Phishunt, all 5 blocklists show similar median delays (2.3 to 4.4 days except the Phishunt).
    }
    \label{fig:blocklist_compare}
    \vspace{-10px}
\end{figure*}

\subsection{Time Taken between Registration to Detection (Detection Delay)}
\label{sec:registration_detection}
In this section, we analyze how phishing domains are detected by blocklist after registration.

\PP{Motivation}
Maliciously registered domains can be blocked in advance when compared to compromised domains.
Phishing domains exhibit significant variation in the time it takes to be detected after registration, influenced by the type of domain and the targeted brand. As shown in ~\autoref{fig:registration_timediff}, these differences highlight both quicker detection for some brands and prolonged delays for others. 

\PP{Result: Overview of Detection Delay}
Across all domains, the overall median detection time is 42.4 days, with an average of 286.2 days.
For the top 10 most targeted brands, the detection times have a slight improvement over these values, with an average of 286.2 days and a significantly shorter median of 11.7 days. This suggests that well-known brands tend to benefit from quicker median detection times compared to less prominent brands, likely due to more active monitoring and stronger anti-phishing measures.
% 
% takeaway: popular brand gets detected sooner than other brands
% 
% Phishing domains demonstrate significant variation in the time it takes for phishing domains to be detected after registration, depending on the type of domain and the targeted brand. 
% As shown in ~\autoref{fig:registration_timediff}, these differences highlight both quicker detection for certain brands and prolonged delays for others. 
% The overall median value is 42.4 days, and average is 277.3 days.
% However, for the top 10 most targeted brands, the average detection time is 286.2 days, while the median detection time is significantly shorter at 11.7 days
% This indicates that well known brands have shorter median detection time when compare to other brands.
% illustrates these differences, highlighting both quicker detection for certain brands and prolonged delays for others. 

% USPS (United States Postal Service)~\cite{WelcomeU93:online}, a U.S. federal agency providing postal services, and \cc{OZON}~\cite{OZON}, a Russian e-commerce platform founded in 1998, stand out with the fastest average detection times among targeted brands. 
% \cc{USPS} has a median of 1.4 days (average of 59 days), and \cc{OZON} has a median of 1.3 days (average of 42.9 days).
% % , likely due to active monitoring or simpler phishing tactics that are easier to detect.
% % \KH{Same statistics repeated \color{red}(A)}
% \DK{highlight the median value rather than average value}
% % USPS and OZON (\DK{cite and explain what brand is for}) stand out with the fastest average detection times of 59 and 42.9 days, respectively. 
% These quicker detections may result from more active monitoring systems or simpler phishing tactics that are easier to identify. 
% \DK{same sentence and same results. we need to highlight other findings.}\KL{Remove?}
% % Previous research~\cite{affinito2022domain} shows that registrars (\ie, Freenom) provide an API to takedown phishing domains immediately when a sign of abuse is discovered.
% In contrast, domains impersonating \cc{Microsoft} take the longest to be detected, with an average detection time of 719 days.
% \cc{Facebook}, despite being the most impersonated brand, has a moderate detection time of 275 days.
% \DK{put the general median values.} \KL{added in the beginning of this subsection}
% \DK{No you didn't add all median values for the numbers.}



\PP{Detection Time between Targeted Brands}
\cc{USPS} (United States Postal Service)~\cite{WelcomeU93:online}, a U.S. federal agency providing postal services, and \cc{OZON}~\cite{OZON}, a Russian e-commerce platform founded in 1998, stand out with the fastest average detection times among targeted brands. 
\cc{USPS} has a median of 1.4 days (average of 59 days), and \cc{OZON} has a median of 1.3 days (average of 42.9 days).
These quicker detections may result from more active monitoring systems or simpler phishing tactics that are easier to identify. 

Both brands are targeted using non-original TLDs (\autoref{sec:tld_characteristics}), which are often cheaper to register. 
Also, the detection as shown in~\autoref{fig:registration_by_brand}, detection time of \cc{USPS} and \cc{OZON} is quickest with a median of 1.4 days and 1.3 days respectively.
Some registrars, such as Freenom, provide APIs for the immediate takedown of phishing domains upon detecting signs of abuse ~\cite{affinito2022domain}. 
This suggests that attackers' choice of cost-effective TLDs may have inadvertently backfired, as these domains could be removed quickly.
%are detected more quickly than others.
% USPS and OZON are detected the fastest, with average detection times of 59 and 42.9 days, respectively. 
% Interestingly both brands are using non-original TLD. 
% Previous research~\cite{affinito2022domain} highlights that some registrars, such as Freenom, offer APIs to facilitate the immediate takedown of phishing domains upon detecting signs of abuse.

Domains targeting \cc{Microsoft} take the longest to be detected, with an average detection time of 719 days (median of 440.4 days).
\cc{Facebook}, despite being the most impersonated brand, has a moderate detection time of 275 days (median of 52.5 days).
% \DK{put the general median values.} \KL{added in the beginning of this subsection}
% \DK{No you didn't add all median values for the numbers.}
% Microsoft experiences the longest detection delays, with an average of 719 days, reflecting either more sophisticated evasion tactics or less stringent monitoring for its targeted domains. 
% Although Facebook is the most frequently impersonated brand, it does not benefit from rapid detection either, with an average detection time of 275 days. 
These findings highlight significant disparities in detection efficiency across brands and TLDs, emphasizing the impact of attackers' TLD choices on detection timelines.\looseness=-1
% \vspace{-2px}
% This shows that attackers may have chosen to use a cheaper TLD to register a domain, however that backfired on their domain since those domains gets detected sooner than others.
% In contrast, Microsoft experiences the longest detection delay, averaging 719 days. 
% Although Facebook is the most frequently impersonated brand, it does not benefit from quick detection, with an average detection time of 275 days.



% We utilize the Levenshtein distance to find similar domain names.
% From previous work~\cite{maroofi2020comar}, having a Levenshtein distance less than 1 can be considered a similar domain.
% We find that 7.9\% (54,787/689,492) of domains have Levenshtein distance of 1 or less.
% From there, we also look at the registration timestamp and registrars.
% We find that 20.1\% (11,016/54,787) domains are registered within a same time (same time between more than two domains) and also registered through the same registrars.



\PP{Maliciously-registered Vs. Compromised}
As shown in~\autoref{fig:registration_timediff}, the detection times vary across different categories of maliciously registered domains. 
Overall, compromised domains consistently have slower detection times compared to maliciously registered domains, though the difference is not substantial. 
Specifically, the median detection time for maliciously registered domains is 16.3 days, with an average of 206.4 days, while compromised domains have a median detection time of 86 days and an average of 332.1 days. 
This indicates that current detection methods do not perform significantly better at identifying maliciously registered domains compared to compromised domains. We will discuss potential future directions in~\autoref{sec:discussion}.
% mal median: 16.3
% mal avg: 206.4
% comp median: 86
% comp avg: 332.1

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[width=.98\linewidth]{fig/apwg_vs_others.pdf}
%     \vspace{-15px}
%     \caption{Days Between APWG Detection and Other Blocklists.
%     Other than Phishunt, all 5 blocklists show similar median delays (2.3 to 4.4 days except the Phishunt).
%     }
%     \label{fig:blocklist_compare}
%     \vspace{-10px}
% \end{figure*}

\rtbox{
\textbf{Takeaway:} 
Detection delays for phishing domains vary, with maliciously registered domains detected faster (median 16.3 days) than compromised ones (median 86 days). 
Brands like \cc{USPS} and \cc{OZON} see rapid detection (medians of 1.4 and 1.3 days), while others, like \cc{Microsoft}, face significant delays (median 440.4 days and 52.5 days, respectively). 
% Phishing domains from our dataset often use TLDs different from the original brand’s TLD, such as \cc{USPS} being targeted primarily with \cc{.top} instead of \cc{.com}, and \cc{OZON} with \cc{.tk} instead of \cc{.ru}. 
% Detection times also vary significantly by targeted brand; \cc{USPS} and \cc{OZON} are detected the fastest, while Microsoft experiences the longest detection delays.
}

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/last_seen_wide_02.pdf}
%     \vspace{-20px}
%     \caption{Days Between Detection and Last Seen. Vertical bars show the last seen timestamp from the zone file by each type of maliciously registered domain.}
%     \label{fig:registration_timediff_last_seen}
% \end{figure*}

% \PP{Maliciously-registered vs. Compromised}
% We observe that maliciously registered domains exhibit slower detection rates than compromised domains. 
% \DK{no number is mentioned and where is the table or figure? You just draw the conclusion without any experiment and analysis}
% \KL{Add analysis and result}
% % For instance, compromised domains targeting USPS are detected in just 11.9 days on average, whereas maliciously registered domains have an average detection time of 86 days. 
% This discrepancy highlights the challenges associated with detecting domains that are specifically crafted for malicious purposes. 

% The prolonged detection times for maliciously registered domains and high-profile brands such as Microsoft highlight critical vulnerabilities in current blocklisting systems. 
% Improving detection mechanisms to prioritize domains with high-risk characteristics, such as those impersonating popular brands or leveraging evasive DNS configurations, could significantly reduce attackers’ ability to exploit victims. 
% Enhanced monitoring of TLDs frequently associated with phishing could also address this gap, ensuring quicker identification and mitigation of malicious domains.

% \rtbox{
% \textbf{Takeaway:} 
% Maliciously registered domains and domains targeting high-profile brands, such as Microsoft, experience significant detection delays, emphasizing the need for improved monitoring and prioritization of high-risk domains.
% }

\begin{figure*}[!t]
    \centering
    \includegraphics[width=.98\linewidth]{fig/last_seen_wide_02.pdf}
    \vspace{-15px}
    \caption{Days Between Detection and Last Seen. Vertical bars show the last seen timestamp from the zone file by each type of maliciously registered domain.}
    \label{fig:registration_timediff_last_seen}
    \vspace{-10px}
\end{figure*}

% \subsection{Takendown Domains}
\subsection{Time Taken between Registration and Deregistration (Takedown Delay)}
\label{sec:registration_deregistration}
% \DK{between registration and deregstration? or between detection and deregistration?}
% \KL{Add Deregistration result}
% If domain is still alive after detection, it can still be accessed from victims. Once domain is determined as a malicious, it is important to deregister as soon as possible. 
% \KL{Previous work defined maliciously-registered domain based on lifetimem of phishing domain such as less than 30 days or 60 days. However our finding show that maliciously-registered domain can live up to years.}
\autoref{fig:registration_timediff_last_seen} highlights the significant variation in the time it takes for phishing domains to be deregistered after detection. 
Across all phishing domains, the average time between detection and deregistration is 11.5 days on average, reflecting a relatively short-lived post-detection activity. 
However, specific domain categories reveal notable discrepancies. 
Squatted domains
%, which mimic well-known brands through minor alterations, 
persist significantly longer, with an average lifespan of 23 days post-detection.
Random-looking domains and impersonating specific branded domains exhibit average post-detection duration of 14.8 days and 19.9 days, respectively.
\looseness=-1
% indicating that attackers use different tactics to maintain availability.\KH{This looks slightly overclaimed.}

This prolonged availability of squatted and brand-targeted domains underscores their continued risk in phishing campaigns, as these domains remain accessible to victims even after being blocklisted. The observed differences in deregistration times between maliciously registered domain categories, such as brand-targeted (19.9 days), random-looking (14.8 days), and squatted domains (23 days), may reflect variations in the policies or practices of registrars and hosting providers. 
These differences could also indicate that attackers exploit specific domain types for their perceived resilience or due to differences in enforcement or takedown mechanisms. 
% Further investigation is needed to understand the factors influencing these variations in deregistration times.
These findings reveal critical gaps in enforcement mechanisms, particularly for squatted domains, which outlast other categories by a wide margin. 
% The persistence of these domains highlights the need for more robust takedown processes that prioritize high-risk categories.
% such as squatted domains.
% Strengthening cooperation between registrars, hosting providers, and blocklists could significantly reduce the post-detection window, limiting attackers' ability to exploit these domains further.
% Even after detection by blocklists, phishing domains often remain active for a significant period, allowing attackers to continue exploiting victims. 
% ~\autoref{fig:registration_timediff_last_seen} shows that squatted domains persist, on average, for 23 days post-detection, compared to 11.5 days for all phishing domains. 
% This extended post-detection activity reflects attackers’ ability to prolong domain availability, particularly when targeting specific brands. 
% For instance, domains impersonating Facebook or Microsoft tend to have longer lifespans post-detection.

% The persistence of phishing domains after detection highlights inefficiencies in current enforcement mechanisms. 
% Strengthening coordination between blocklists, registrars, and hosting providers is crucial to ensure the timely takedown of flagged domains.

\rtbox{
\textbf{Takeaway:} 
Maliciously registered domains, especially squatted domains, are key in phishing domains but are deregistered more slowly, averaging 23 days compared to 11.5 days for all phishing domains.
}
\vspace{-5px}

% \KL{Stats of Interisle (Domain and TLD trend, \# of Domain, Top registrars)}
% 1. Top TLD
% 2. Top Domain
% 3. Top Brand with TLD, count of TLD
% 4. bulk registration domains with count



% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle1.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle3.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle4.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle6.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle8.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle9.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle13.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle14.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle15.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/placeholder/interisle16.png}
%     \caption{Placeholder: I want like this figure..}
%     \label{fig:enter-label}
% \end{figure}

% \begin{figure*}[!t]
%     \centering
%     \includegraphics[width=1\linewidth]{fig/apwg_vs_others.pdf}
%     \vspace{-20px}
%     \caption{Days Between APWG Detection and Other Blocklists.
%     Other than Phishunt, all 5 blocklists show similar median delays (2.3 to 4.4 days except the Phishunt).
%     }
%     \label{fig:blocklist_compare}
% \end{figure*}

\subsection{Comparison Between Blocklists}
As shown in~\autoref{fig:blocklist_compare}, detection times vary significantly between APWG and other blocklists, illustrating how quickly each blocklist identifies phishing domains after they have already been detected by APWG. 
APWG plays a critical role in identifying phishing domains, with domains on its blocklist having an average detection time of 277.3 days and a median detection time of 42.4 days.

In contrast, other blocklists show considerable delays in detecting these same domains. 
For instance, \cc{Phishunt.io} has an average detection delay of 676.1 days and a median of 930.8 days after APWG's detection, indicating significant lag. 
Conversely, blocklists like \cc{PhishTank} and \cc{OpenPhish} demonstrate faster detection times, with \cc{PhishTank} averaging 167.7 days and a median of 4.4 days, while \cc{OpenPhish} averages 257.9 days and a median of 4.1 days after APWG detection. 
\cc{Malware-filter} and \cc{PhishStats} also detect domains relatively quickly, with median delays of 3.7 and 2.3 days, respectively, despite higher average delays of 255.6 and 141.9 days.
\looseness=-1

\cc{Phishing.Database} shows mixed results, with an average detection delay of 388.5 days but a stronger median delay of 64.4 days. 
These findings demonstrate that APWG consistently detects phishing domains earlier than all other blocklists in our dataset. 
However, the variability in detection delays across blocklists highlights the need for improved synchronization and data sharing to reduce detection gaps and enhance phishing defense coverage. APWG’s early detection could be further leveraged to accelerate response times across the ecosystem.

\rtbox{
\textbf{Takeaway:} 
APWG consistently detects phishing domains earlier than other blocklists, but significant variability in detection delays across blocklists underscores the need for improved synchronization and data sharing to enhance timely phishing defense and reduce attacker impact.
}
\vspace{-5px}
% apwg vs others
% apwg avg: 277.3
% apwg median: 42.4
% phishunt avg: 676.1
% phishunt median: 930.8
% phishtank avg: 167.7
% phishtank median: 4.4
% openphish avg: 257.9
% openphish median: 4.1
% phishtank avg: 167.7
% phishtank median: 4.43
% malware-filter avg: 255.6
% malware-filter median: 3.7
% phishing-db avg: 388.5
% phishing-db median: 64.4
% phishstats avg: 141.9
% phishstats median: 2.3

% \section{Evade Detection in Phishing Domains}
% \label{sec:measurement3}
% We aim to see if phishing domains evade detection by modifying DNS records.
% We first look at any changes in DNS records.
% Then we compare the detection point with the DNS record change to determine whether phishing domains change the DNS record to evade detection.

% \KL{Add trend graph with detection point}

% We also want to see if phishing attackers set different DNS records based on different vantage points around the globe.
% We leverage different DNS servers to assess any inconsistent DNS records between same phishing domain.
% \KL{Add ipinfo map figure}