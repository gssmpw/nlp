\section{Certificate Synthesis}
\label{sec:training}

In this section, we propose a mechanism to synthesize a certificate from sampled trajectories, thus offering a constructive approach for algorithm $\mathcal{A}$ in Theorem \ref{thm:Guarantees}.

% \subsection{Neural Networks}
In order to learn a certificate from samples, we consider a neural network, a well-studied class of function approximators that generalize well to a given task.

% \begin{defn}[Neural Network]
%     We denote a neural network by an input layer $z_0 \in \mathbb{R}^n$ (same dimension with the system state vector), a number of hidden layers $z_1 \in \mathbb{R}^{h_1}, \dots, z_k \in \mathbb{R}^{h_k}$, and an output layer $z_{k+1} \in \mathbb{R}$.
%     Each layer, except the input, has an associated set of weights and biases $W_i \in \mathbb{R}^{h_{i-1}\times h_i}, b_i \in \mathbb{R}^{h_i}$, as well as an activation function $\sigma_i \colon \mathbb{R} \rightarrow \mathbb{R}$.

%     The layers are related by the following equations,
%     \begin{align}
%         z_{i} &= \sigma_i(W_i z_{i-1}+b_i),~ i =1,\dots,k,\\
%         z_{k+1} &= W_{k+1} z_k+b_{k+1},
%     \end{align}
%     where the activation function is applied element-wise to its argument. 
% \end{defn}

Such a neural network acts as a ``template'' for our certificate $V_N$. 
Denote all tunable neural network parameters by a vector $\theta$. 
We then have that our certificate $V_N$ depends on $\theta$. 
For the results of this section, we simply write $V_\theta$ and drop the dependency on $N$ to ease notation. 

\newcounter{figure_store}
\setcounter{figure_store}{\arabic{figure}}
\setcounter{figure}{0}

\makeatletter
\renewcommand{\fnum@figure}{\textbf{Algorithm \thefigure}}
\makeatother
\begin{figure*}
\caption{Certificate Synthesis and Compression Set Computation}
\vspace{0.2cm}
\label{algo:sub}
\hrule \vspace{0.05cm} \hrule 
    \begin{algorithmic}[1]
    \Function{}{}$\mathcal{A}(\theta,\mathcal{D})$
    \State Set $k \gets 1$ \Comment{Initialize iteration index}
            \State Set $\mathcal{C}\leftarrow \emptyset$ 
            \Comment{Initialize compression set}
            \State Fix $L_1 < L_0$ with $|L_1-L_0|>\eta$ \Comment{$\eta$ is any fixed tolerance}
            \While{$l^s(\theta)>0$} \Comment{While sample-independent state loss is non-zero}
                \State  $g \gets \nabla_\theta l^s(\theta)$  \Comment{Gradient of loss function} \label{line:state_grad}
                \State $\theta \leftarrow \theta-\alpha g$ \Comment{Step in the direction of sample-independent gradient} \label{line:state_step}
            \EndWhile
            \Statex \vspace{-0.35cm}\hrulefill
             \While{$|L_k-L_{k-1}|>\eta $} \Comment{Iterate until tolerance is met} \label{line:while}
            \State $\mathcal{M} \gets \{\tilde{\xi} \in \mathcal{D} \colon L(\theta,\tilde{\xi}) \geq \max_{\tilde{\xi} \in \mathcal{C}} L(\theta,\tilde{\xi}) \}$ \Comment{Find samples with loss greater than compression set loss} \label{line:max_D}
            \State  $\overline{g}_\mathcal{M} \gets \{\nabla_\theta L(\theta,\tilde{\xi})\}_{\tilde{\xi} \in \mathcal{M}}$  \Comment{ Subgradients of loss function for $\tilde{\xi} \in  \mathcal{M}$} \label{line:subgrad_D}
            \State $\overline{\xi}_{\mathcal{C}} \in \argmax_{\tilde{\xi} \in \mathcal{C}} L(\theta,\tilde{\xi})$ \Comment{Find a sample with maximum loss from $\mathcal{C}$} \label{line:max_C}
            \State $\overline{g}_{\mathcal{C}}  \gets \nabla_\theta L(\theta,\overline{\xi}_{\mathcal{C}})$ \Comment{Approximate subgradient of loss function for $\tilde{\xi} = \overline{\xi}_{\mathcal{C}}$} \label{line:subgrad_C}
            \Statex \vspace{-0.25cm}\hrulefill
             \If{$\exists \overline{g} \in \overline{g}_\mathcal{M} \colon \langle \overline{g},\overline{g}_{\mathcal{C}} \rangle \leq 0 \wedge \overline{g} \neq 0$ \label{line:inner}} \Comment{If there is a misaligned subgradient (take the maximum if multiple)}
                \State $\theta \leftarrow \theta-\alpha\overline{g}$ \Comment{Step in the direction of misaligned subgradient} \label{line:true_step}
                \State $\mathcal{C} \leftarrow \mathcal{C} \cup \{\overline{\xi}\}$ \Comment{Update compression set with sample corresponding to $\overline{g}$} \label{line:update_C}
            \Else
                \State $\theta \leftarrow \theta-\alpha\overline{g}_{\mathcal{C}}$ \Comment{Step in the direction of approximate subgradient} \label{line:approx_step}
            \EndIf \label{line:endif}
	    % \While{$|L_k-L_{k-1}|>\eta $} \Comment{Iterate until tolerance is met} \label{line:while}

     %        \State $\overline{\xi}_\mathcal{D} \in \argmax_{\xi \in \mathcal{D}} L(\theta,\xi)$\Comment{Find a sample with maximum loss from $\mathcal{D}$} \label{line:max_D}
     %        \State  $\overline{g}_\mathcal{D} \gets \nabla_\theta L(\theta,\overline{\xi}_\mathcal{D})$  \Comment{ Subgradient of loss function for $\xi = \overline{\xi}_D$} \label{line:subgrad_D}
     %        \State $\overline{\xi}_{\mathcal{C}} \in \argmax_{\xi \in \mathcal{C}} L(\theta,\xi)$ \Comment{Find a sample with maximum loss from $\mathcal{C}$} \label{line:max_C}
     %        \State $\overline{g}_{\mathcal{C}}  \gets \nabla_\theta L(\theta,\overline{\xi}_{\mathcal{C}})$ \Comment{Approximate subgradient of loss function for $\xi = \overline{\xi}_{\mathcal{C}}$} \label{line:subgrad_C}
     %        \Statex \vspace{-0.25cm}\hrulefill
     %         \If{$\langle \overline{g}_D,\overline{g}_{\mathcal{C}} \rangle \leq 0$} \label{line:inner}
     %         \If{$\overline{g}_D \neq 0$}
     %            \State $\theta \leftarrow \theta-\alpha\overline{g}_\mathcal{D}$ \Comment{Step in the direction of exact subgradient} \label{line:true_step}
     %            \State $\mathcal{C} \leftarrow \mathcal{C} \cup \{\overline{\xi}_D\}$ \Comment{Update compression set with $\xi = \overline{\xi}_D$} \label{line:update_C}
     %            \EndIf
     %        \Else
     %            \State $\theta \leftarrow \theta-\alpha\overline{g}_{\mathcal{C}}$ \Comment{Step in the direction of approximate subgradient} \label{line:approx_step}
     %        \EndIf \label{line:endif}
            \Statex \vspace{-0.35cm}\hrulefill
	    \State $L_k \gets \min\left\{ L_{k-1}, \max_{\xi \in \mathcal{D}} L(\theta,\xi)\right\}$ \Comment{Update ``running'' loss value} \label{line:update_L}
        \State $k \gets k+1$ \Comment{Update iteration index} \label{line:update_k}
            \EndWhile
            \State \Return $\theta, \mathcal{C}$
            \EndFunction
    \end{algorithmic}
               \vspace{0.1cm} \hrule \vspace{0.05cm} \hrule
\end{figure*}
\makeatletter
\renewcommand{\fnum@figure}{Fig. \thefigure}
\makeatother

\setcounter{figure}{\arabic{figure_store}}
\setcounter{algorithm}{1}


\subsection{Certificate and Compression Set Computation}

We provide an algorithm that seeks to optimize the neural network parameters so that it results in a certificate $V_{\theta^\star}$. 
To this end, for a $\xi \in \Xi$ and parameter vector $\theta$, let \begin{equation}
    L(\theta,\xi)=l^\Delta(\theta,\xi)+ l^s(\theta),\label{eq:opt_prob}
\end{equation} represent an associated loss function consisting of a sample-dependent loss $l^\Delta$, and a sample-independent loss $l^s$. 
Without loss of generality, we assume that we can drive the sample-independent loss to be zero (see further discussions later). 
We impose the next mild assumption, needed to prove termination of our algorithm.
\begin{assum}[Minimizers' Existence] \label{ass:exist}
For any $\{\xi\}_{i=1}^N$, and any non-empty $\mathcal{D} \subseteq \{\xi\}_{i=1}^N$, the set of minimizers of $\max_{\xi \in \mathcal{D}} L(\theta,\xi),$ is non-empty.
\end{assum}
We aim at approximating a minimizer $\theta^\star$ of $\max_{\xi \in \mathcal{D}} L(\theta,\xi)$ when $\mathcal{D}=\{\xi\}_{i=1}^N$, which exists due to Assumption \ref{ass:exist}. 
We can then use that minimizer to construct $V_{\theta^\star}$. 
To achieve this, we employ Algorithm~\ref{algo:sub}. 

We provide a graphical representation of the algorithm in Figure~\ref{fig:algorithm}, the loss evaluated only on the support samples is shown as a blue dot, whilst the true loss is shown with a green cross.

Algorithm \ref{algo:sub} takes as inputs some initial (arbitrary) parameter vector $\theta$ and a set of samples $\mathcal{D} \subseteq \{\xi\}_{i=1}^N$. 
First, in steps~\ref{line:state_grad}--\ref{line:state_step}, we optimize for the sample-independent loss until this loss is non-positive, which serves as a form of warm starting.
In step~\ref{line:max_D}, the maximizing samples $\mathcal{M}$ that achieve loss greater than the loss on the compression set is identified, while in step~\ref{line:subgrad_D} the subgradients of the maximizing samples $\nabla_\theta L(\theta,\tilde{\xi}), \tilde{\xi} \in \mathcal{M}$ are computed.  
Steps~\ref{line:max_C}--\ref{line:subgrad_C} perform similar computations but with the set $\mathcal{C}$ maintained throughout the algorithm, in place of $\mathcal{D}$. 
As such, the subgradient in step~\ref{line:subgrad_C} is termed approximate, as the samples in $\mathcal{C}$ may not achieve the worst-case loss value. 
It is to be understood that if $\mathcal{C}$ is empty (as per initialization) steps~\ref{line:max_C}-\ref{line:subgrad_C} are not performed.

Steps~\ref{line:inner}--\ref{line:endif} of Algorithm \ref{algo:sub} involve taking a descent step.  
If the inner product in step~\ref{line:inner} is non-positive (i.e., if the approximate subgradient ``steers'' against a maximizing subgradient) and the maximizing subgradient is non-zero, then we proceed to step~\ref{line:true_step} and follow the maximizing subgradient (with stepsize $\alpha$) to explore the new direction (this can be thought of as an exploration step, and is seen at label $5$ in the Figure); otherwise, we move to step~\ref{line:approx_step} and follow the direction of the approximate subgradient (seen at the ``blue'' dot labelled by $3$) which in this case would point towards a similar direction with the exact one. This logic prevents us from unnecessarily appending to $\mathcal{C}$ more samples.
If the maximizing subgradient is followed, we add the associated sample $\overline{\xi}$ to the set $\mathcal{C}$ (step~\ref{line:update_C}). 
We then iterate till the loss value meets a given tolerance $\eta$ (see steps~\ref{line:while} and~\ref{line:update_L}).

\begin{figure}[b]
    \centering
    \includegraphics[width=0.75\linewidth]{Figures/Algorithm.eps}
    \caption{Graphical Representation of Algorithm~\ref{algo:sub}.}
    \label{fig:algorithm}
\end{figure}

We view Algorithm \ref{algo:sub} as a specific choice for the mapping $\mathcal{A}$ introduced in Section \ref{sec:learn_certs} when fed with $\mathcal{D} = \{\xi_i\}_{i=1}^N$, and some initial choice for $\theta$. 
It terminates returning an updated $\theta$, and a set $\mathcal{C}$ which forms a compression set for this algorithm. 
These are formalized below.

\begin{prop}[Algorithm \ref{algo:sub} Properties] \label{prop:converge}
Consider Assumption \ref{ass:non-conc_mass}, Assumption  \ref{ass:exist} and Algorithm \ref{algo:sub} with $\mathcal{D} = \{\xi_i\}_{i=1}^N$ and a fixed (sample independent) initialization for the parameter $\theta$. We then have:
\begin{enumerate}[wide, labelwidth=!, labelindent=0pt]
\item Algorithm \ref{algo:sub} terminates, returning a parameter vector $\theta^\star$ and a set $\mathcal{C}_N$.
\item The set $\mathcal{C}_N$ with cardinality $C_N = |\mathcal{C}_N|$ forms a compression set for Algorithm \ref{algo:sub}.
\item Algorithm \ref{algo:sub} satisfies Assumption \ref{ass:alg_prop}.
\end{enumerate}
\end{prop}

The proof can be found in Appendix \ref{app:proofs}.

Proposition \ref{prop:converge} implies that we can construct a certificate $V_N = V_{\theta^\star}$, while the algorithm that returns this certificate satisfies Assumption \ref{ass:alg_prop} and admits a compression set $\mathcal{C}_N$ with cardinality $C_N$. 
As such, Algorithm \ref{algo:sub} offers a constructive mechanism to synthesize a certificate, and can be accompanied by the probabilistic guarantees of Theorem \ref{thm:Guarantees}. 
Moreover, Assumptions \ref{ass:non-conc_mass} \& \ref{ass:exist} under which Algorithm \ref{algo:sub} exhibits these properties are rather mild.

Our way of computing a compression set serves as an efficient alternative to existing methodologies, as we construct it iteratively. 
At the same time the constructed compression set is non-trivial as we avoid adding uninformative samples to it, and only add one sample per iteration in the worst case, however, the one that maximizes the loss (see step 12).
This algorithm could be thought of as a constructive procedure for the general methodology proposed recently in \cite{DBLP:conf/nips/PaccagnanCG23}.

Proposition \ref{prop:converge} shows that Algorithm \ref{algo:sub} terminates and produces parameter iterates that yield a non-increasing sequence of loss functions. As such, the algorithm moves towards the direction of the optimum, but we have no guarantees that it indeed reaches some (local) optimum.
We conjecture the approximate subgradient used in our algorithm constitutes a descent direction~\cite{doi:10.1137/1.9781611971309}, and hence if the step size is chosen appropriately the algorithm should converge to a stationary point. Current work focuses on formalizing this claim.


% \end{rem}

In some cases, the parameter returned by Algorithm \ref{algo:sub} may result in a value of the loss function that is considered as undesirable (and as a result the constructed certificate might be far from meeting the desired conditions). 
To achieve a lower loss, we make use of a sample-and-discarding procedure \cite{DBLP:journals/jota/CampiG11,DBLP:journals/tac/RomaoPM23}.
To this end, consider Algorithm \ref{algo:main}. At each iteration of this algorithm, the compression set returned by Algorithm \ref{algo:sub} (step~\ref{line:subgrad}) is appended to a ``running'' set $\widetilde{\mathcal{C}}$ (see step~\ref{line:update_outer_C}). 
We then discard all elements of the compression set from $\mathcal{D}$, and repeat the process till the worst case loss $\max_{\xi \in \mathcal{D}} L(\theta, \xi)\geq0$ is sufficiently small and ideally zero. 
This implies that Algorithm \ref{algo:sub} is invoked each time with fewer samples as its input, while the set $\widetilde{\mathcal{C}}$ progressively increases.
The set $\widetilde{\mathcal{C}}$ is a compression set that includes all samples that lead to a worst case loss, plus all
samples that are removed along the process of Algorithm \ref{algo:main}.
However, it has higher cardinality compared to the original compression set, implying that improving the loss comes at the price of an increased risk level $\varepsilon$ as the cardinality of the compression set increases.

\begin{algorithm}[ht]
\caption{Compression Set Update with Discarding}
\vspace{0.2cm}
\label{algo:main}
\hrule \vspace{0.05cm} \hrule \vspace{0.1cm}
\begin{algorithmic}[1]
\State Fix $ \{\xi^i\}_{i=1}^N$
    \State Set $\widetilde{\mathcal{C}}\gets \emptyset$\Comment{Initialize compression set}
    \State Set $\mathcal{D} \gets \{\xi^i\}_{i=1}^N$ \Comment{Initialize ``running'' samples}
    %\State $\rhd$ While loss is positive
    \While{$\max_{\xi \in \mathcal{D}} L(\theta, \xi)>0$}
            \State $\theta, \mathcal{C} \gets$ $\mathcal{A}(\theta,\mathcal{D})$ \Comment{Call Algorithm \ref{algo:sub}} \label{line:subgrad}
        \State $\widetilde{\mathcal{C}} \gets \widetilde{\mathcal{C}} \cup \mathcal{C}$ \Comment{{Update $\widetilde{\mathcal{C}}$}} \label{line:update_outer_C}
        \State  $\mathcal{D} \gets \mathcal{D} \setminus \widetilde{\mathcal{C}}$ \Comment{Discard $\widetilde{\mathcal{C}}$ from $\mathcal{D}$} \label{line:discard}
    \EndWhile
        \State \Return $\theta$, $\widetilde{\mathcal{C}}$
\end{algorithmic}
\vspace{0.1cm}
\hrule \vspace{0.05cm} \hrule 
\end{algorithm}

\subsection{Choices of Loss Function}
We now provide some choices of the loss function $L(\theta,\xi)=l^\Delta(V_\theta, \xi) + l^s(V_\theta)$ so that minimizing that function we obtain a parameter vector $\theta^\star$, and hence also a certificate $V_{\theta^\star}$, which satisfies the conditions of the property under consideration, namely, reachability, safety, or RWA.
Note that when calculating subgradients to these functions, which as we will see below are non-convex, we effectively have the so-called Clarke subdifferential~\cite{doi:10.1137/1.9781611971309}.

We provide some expressions for $l^s$ and $l^\Delta$ for the reachability property in Property \ref{prop:reach}. 
For the other properties, the loss functions can be defined in an analogous manner. 
To this end, we define
\begin{align}
    &l^s(V_\theta) \defeq \int_{X \setminus X_G}\max\{0,-\delta-V_\theta(x)\} ~\mathrm{d}x \\ &+\int_{X_I}\max\{0,V_\theta(x)\}   ~\mathrm{d}x+\int_{\mathbb{R}^N \setminus X} \max\{0,-V_\theta(x)\}  ~\mathrm{d}x.\nonumber
\end{align}
Focusing on the first of these integrals, if $V(x) > -\delta$ then $\max\{0, -\delta-V_\theta(x)\}=0$, i.e., no loss is incurred, implying satisfaction of \eqref{eq:reach_goal}, \eqref{eq:reach_else}. 
Under a similar reasoning, the other integrals account for \eqref{eq:reach_init} and \eqref{eq:reach_dom_border}, respectively. 
Note that, for a sufficiently expressive neural network, we can find a certificate $V$ which satisfies the state constraints and hence has a sample-independent loss of zero.

In practice, we replace integrals with a summation over points generated deterministically within the relevant domains. 
These points are generated densely enough across the domain of interest, and hence offer an accurate approximation. 
This generation may happen through gridding the relevant domain, or sampling according to a fixed synthetic distribution.
For the last term, we only enforce the positivity condition on the border of the domain $X$.
Thus, we take a deterministically generated discrete set of points on each domain $\mathcal{X}_{\overline{G}}$ for points in the domain but outside the goal region, $\mathcal{X}_I$ from the initial set, and $\mathcal{X}_\partial$ for the border of the domain $X$.
Since these samples do not require access to the dynamics we consider them separate to the sample-set $\{\xi_i\}_{i=1}^N$, and references to the size of the sample set only refer to the trajectory samples (since these are the ``costly'' samples).
Our practical loss function is then of the following form: 
\begin{align}
    &\hat{l^s}(V_\theta) \defeq  \frac{1}{|\mathcal{X}_{\overline{G}}|}\sum_{x \in \mathcal{X}_{\overline{G}}} \max\{0, -\delta-V_\theta(x)\} \\ &+\frac{1}{|\mathcal{X}_I|}\sum_{x \in \mathcal{X}_I}\max\{0,V_\theta(x)\}+\frac{1}{|\mathcal{X}_\partial|}\sum_{x \in \mathcal{X}_\partial} \max\{0,-V_\theta(x)\}.\nonumber
    \end{align}

We define $l^\Delta$ by
\begin{equation}
\label{eq:c_deriv}
        \begin{aligned}            
        l^\Delta&(V_\theta, \xi) \defeq \max \Big \{ 0, \frac{1}{T} \Big (\sup_{x\in \mathcal{X}_I} V_\theta(x) + \delta \Big )\\&-\max_{k=0,\dots,k_G-1} \Big ( V_\theta(x(k+1))-V_\theta(x(k)) \Big ) \Big \}.
        \end{aligned}
\end{equation}
The value of $l^\Delta$ encodes a loss if the condition in \eqref{eq:reach_deriv} is violated.
If both $l^s$ and $l^\Delta$ evaluate to zero for all $\{\xi\}_{i=1}^N$, then we have that 
\begin{equation}
\begin{aligned}
        l^s(V_\theta) + \max_{i = 1, \dots, N} l^\Delta(V_\theta, \xi^i) = 0,
\end{aligned}
\end{equation}
which by Certificate \ref{cert:reach} implies that the constructed certificate $V_\theta$ is such that
\begin{equation}
\begin{aligned}
        V_\theta \models \psi^s_\text{reach} \wedge (i=1,\dots,N) V_\theta \models\psi^\Delta_\text{reach}(\xi^i).
\end{aligned}
\end{equation}
Analogous conclusions hold for all other certificates.