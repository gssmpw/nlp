\documentclass[twocolumn]{autart}    % Enable this line and disable the 

\newif\ifappendix
\global\appendixtrue

\input{Ancillary/packages}

\begin{document}

\begin{frontmatter}

\title{Data-Driven Neural Certificate Synthesis}

\author[Oxford]{Luke Rickard}\ead{rickard@robots.ox.ac.uk}
\author[OxfordCS]{Alessandro Abate}
\author[Oxford]{Kostas Margellos}
\address[Oxford]{Department of Engineering Science, University of Oxford}
\address[OxfordCS]{Department of Computer Science, University of Oxford}

\begin{keyword}
    Verification of Dynamical Systems, Safety, Reachability, Statistical Learning, Scenario Approach.
\end{keyword}

\begin{abstract}
    We investigate the problem of verifying different properties of discrete time dynamical systems, namely, reachability, safety and reach-while-avoid. To achieve this, we adopt a data driven perspective and using past systems' trajectories as data, we aim at learning a specific function termed \emph{certificate} for each property we wish to verify. The certificate construction problem is treated as a safety informed neural network training process, where we use a neural network to learn the parameterization of each certificate, while the loss function we seek to minimize is designed to encompass conditions on the certificate to be learned that encode the satisfaction of the associated property. Besides learning a certificate, we quantify probabilistically its generalization properties, namely, how likely it is for a certificate to be valid (and hence for the associated property to be satisfied) when it comes to a new system trajectory not included in the training data set.
    We view this problem under the realm of probably approximately correct (PAC) learning under the notion of compression, and use recent advancements of the so-called scenario approach to obtain scalable generalization bounds on the learned certificates. To achieve this, we design a novel algorithm that minimizes the loss function and hence constructs a certificate, and at the same time determines a quantity termed compression, which is instrumental in obtaining meaningful probabilistic guarantees. This process is novel per se and provides a constructive mechanism for compression set calculation, thus opening the road for its use to more general non-convex optimization problems. We verify the efficacy of our methodology on several numerical case studies, and compare it (both theoretically and numerically) with closely related results on data-driven property verification.
\end{abstract}

\end{frontmatter}

\input{Sections/1-Introduction}
\input{Sections/2-Certificates}
\input{Sections/3-Data-Driven_Certificates}
\input{Sections/4-Certificate_synth}
\input{Sections/5-Related_Work}
\input{Sections/6-Experiments}
\input{Sections/7-Conclusion}

\bibliographystyle{plain}
\bibliography{neural_certs_paper}


\ifappendix
\appendix   
\input{Sections/A-proofs}
\fi

\end{document}
