\section{Related Work}
\label{section:related_work}

\subsection{Large-scale Pre-trained Models for Pathology}
Recent advancements in large-scale pre-trained models for pathology can be broadly classified into two categories. \textit{Vision models}, such as 
\texttt{Virchow} ____, 
\texttt{Hibou} ____, \texttt{UNI} ____, and \texttt{Prov-GigaPath} ____ leverage massive pathology image datasets to learn robust visual representations. Among these, \texttt{Prov-GigaPath} stands out as the largest model, trained on 1.3 billion pathology image patches, and excels in resolving complex tissue patterns at high resolution. On the other hand, \textit{vision-language models} (VLMs) like \texttt{PLIP} ____ (trained 200K image-text pairs), \texttt{CONCH} ____ (1.17M), or \texttt{QUILTNET}____ (1M), integrate visual and textual information to enhance contextual understanding and improve pathology slide interpretation. In contrast,  our \texttt{\textsc{MGPath}} combines the strengths of both approaches by using a \textit{parameter-efficient adaptor} to link \texttt{Prov-GigaPath} (the largest pre-trained vision encoder) with a text encoder from VLMs like \texttt{PLIP} or \texttt{CONCH}, leveraging both rich visual features and semantic textual embeddings. Although we use the \texttt{PLIP} text encoder in our experiments due to its common use in baselines, the method can be extended to other larger pre-trained text models.


\subsection{Few-shot learning in WSI}
MIL treats a WSI as a bag of patches and aggregates these instances into a bag of features, with early methods using non-parametric techniques like mean or max pooling. However, since disease-related patches are rare, these methods can overwhelm useful information with irrelevant data. To address this, attention-based methods, graph neural Networks (GNNs), and Transformer-based methods have been introduced ____. In contrast, VLMs have gained popularity through contrastive learning, aligning image-text pairs to enhance performance on a variety of tasks. While collecting large-scale pathology image-text pairs remains challenging, models like MI-Zero, \texttt{PLIP}, and \texttt{CONCH} have been trained on hundreds of thousands to over a million pathology image-text pairs ____.  Some approaches also integrate multi-magnification images and multi-scale text to mimic pathologistsâ€™ diagnostic processes, especially for detecting subtle abnormalities ____. Our \texttt{\textsc{MGPath}} extends on the VLMs strategy by further \textit{amplifying the benefits of using a large pre-trained pathology} VLM model and introducing a new \textit{parameter-efficient multi-granular prompt learning} to adapt these models to few-shot settings.

\subsection{Prompt Learning for Vision-Language Adaptations}
Prompt tuning is proposed to transfer large pre-trained model task-specific downstream tasks and has shown strong results in multimodal models like CLIP. Rather than design a heuristic template, several methods like \texttt{CoOp} ____, \texttt{CoCoOp} ____, or \texttt{MaPLe} ____ among others ____ have allowed models to determine optimal prompts from multiple perspectives, such as domain generalization ____, knowledge prototype ____, or diversity ____. However, these approaches focus on natural images and do not address the unique challenges of whole-slide pathology images, which require multi-scale and structural contextual information. While a few current methods typically integrate prompts with frozen visual features via self-attention ____, these approaches might struggle with the complex relationships in WSIs. Our solution introduces multi-granular prompt learning, bridging \textit{attention} on both \textit{individual image patches} and \textit{spatial groups} to better align with the hierarchical structure of WSI data.