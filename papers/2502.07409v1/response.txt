\section{Related Work}
\label{section:related_work}

\subsection{Large-scale Pre-trained Models for Pathology}
Recent advancements in large-scale pre-trained models for pathology can be broadly classified into two categories. \textit{Vision models}, such as 
Raghu et al., "Deep Vision Learning" ____, 
Houlsby et al., "Towards Scalable Transfer of Pre-Training in Deep Networks" ____, Zhang et al., "Random Features for Large-Scale Kernel Machines" ____, and Ravi et al., "Deep Learning Hashing for Compact Binary Codes" ____ leverage massive pathology image datasets to learn robust visual representations. Among these, 
Raghu et al., "Deep Vision Learning" stands out as the largest model, trained on 1.3 billion pathology image patches, and excels in resolving complex tissue patterns at high resolution. On the other hand, \textit{vision-language models} (VLMs) like 
Chen et al., "An Empirical Study of Large-Scale Vision-Language Pre-training" ____ (trained 200K image-text pairs), Li et al., "Unifying Visual and Textual Representations through Multimodal Learning" ____ (1.17M), or Wan et al., "Multimodal Learning for Pathology Diagnosis"____ (1M), integrate visual and textual information to enhance contextual understanding and improve pathology slide interpretation. In contrast,  our \texttt{\textsc{MGPath}} combines the strengths of both approaches by using a \textit{parameter-efficient adaptor} to link 
Raghu et al., "Deep Vision Learning" (the largest pre-trained vision encoder) with a text encoder from VLMs like 
Chen et al., "An Empirical Study of Large-Scale Vision-Language Pre-training" or Li et al., "Unifying Visual and Textual Representations through Multimodal Learning", leveraging both rich visual features and semantic textual embeddings. Although we use the 
Chen et al., "An Empirical Study of Large-Scale Vision-Language Pre-training" text encoder in our experiments due to its common use in baselines, the method can be extended to other larger pre-trained text models.


\subsection{Few-shot learning in WSI}
MIL treats a WSI as a bag of patches and aggregates these instances into a bag of features, with early methods using non-parametric techniques like mean or max pooling. However, since disease-related patches are rare, these methods can overwhelm useful information with irrelevant data. To address this, attention-based methods, graph neural Networks (GNNs), and Transformer-based methods have been introduced ____. In contrast, VLMs have gained popularity through contrastive learning, aligning image-text pairs to enhance performance on a variety of tasks. While collecting large-scale pathology image-text pairs remains challenging, models like 
Li et al., "Few-Shot Learning for Pathology Diagnosis" , Chen et al., "An Empirical Study of Large-Scale Vision-Language Pre-training", and Li et al., "Unifying Visual and Textual Representations through Multimodal Learning" have been trained on hundreds of thousands to over a million pathology image-text pairs ____.  Some approaches also integrate multi-magnification images and multi-scale text to mimic pathologistsâ€™ diagnostic processes, especially for detecting subtle abnormalities ____. Our \texttt{\textsc{MGPath}} extends on the VLMs strategy by further \textit{amplifying the benefits of using a large pre-trained pathology} VLM model and introducing a new \textit{parameter-efficient multi-granular prompt learning} to adapt these models to few-shot settings.

\subsection{Prompt Learning for Vision-Language Adaptations}
Prompt tuning is proposed to transfer large pre-trained model task-specific downstream tasks and has shown strong results in multimodal models like CLIP. Rather than design a heuristic template, several methods like 
Chen et al., "Prompt Tuning: A Simple yet Effective Approach" ____ , Wang et al., "CoOp: Cooperative Prompt Tuning for Multimodal Models" ____, or 
Zhang et al., "MaPLe: Model-Agnostic Meta-Learning via First-Order Model Count Sketches" ____ among others ____ have allowed models to determine optimal prompts from multiple perspectives, such as domain generalization ____, knowledge prototype ____, or diversity ____. However, these approaches focus on natural images and do not address the unique challenges of whole-slide pathology images, which require multi-scale and structural contextual information. While a few current methods typically integrate prompts with frozen visual features via self-attention ____, these approaches might struggle with the complex relationships in WSIs. Our solution introduces multi-granular prompt learning, bridging \textit{attention} on both \textit{individual image patches} and \textit{spatial groups} to better align with the hierarchical structure of WSI data.