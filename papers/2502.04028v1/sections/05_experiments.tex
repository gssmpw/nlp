
In this section, we present the empirical evaluation of our proposed approach, \algoabb, in various MARL tasks. 

\subsection{Evaluation domains} 

We evaluate \algoabb\ in the Multi-Agent Coordination (MACO) benchmark \cite{wang2022contextaware} and SMACv2 \cite{ellis2023smacv}. Below, we provide a brief description of the tasks (more details with reward function definitions can be found in the appendix). 

\paragraph{Gather} (Figure \ref{fig:envs}a) extends the Climb Game \cite{wei2016lenient} by adding temporal complexity and stochastic elements. Agents must coordinate and navigate to one of three goal states (\( g_1 \), \( g_2 \), or \( g_3 \)), with one goal randomly chosen as optimal at the start of each episode. 

\paragraph{Disperse} (Figure \ref{fig:envs}b) involves twelve agents selecting one of four hospitals each timestep, where only one hospital needs a specific number of agents. Agents are penalized for understaffing, testing their ability to efficiently distribute themselves according to dynamic needs.

\paragraph{Pursuit} (Figure \ref{fig:envs}c) features ten predator agents on a $10 \times 10$ grid who must coordinate to capture prey. The challenge lies in requiring simultaneous actions by at least two predators, with penalties for failed capture attempts.

\paragraph{Hallway} (extends hallway by \cite{wang2019learning}; Figure \ref{fig:envs}d), is multi-chain Dec-POMDP where agents must synchronize their movements through a hallway to reach a goal state simultaneously. The environment tests agents' coordination under limited observability and potential conflicts.

\paragraph{SMACv2} (Figure \ref{fig:envs}e) is a MARL benchmark with high-dimensional, partially observable environments, diverse unit types, and dynamic elements \cite{ellis2023smacv}. It introduces procedurally generated scenarios that require agents to generalize to unseen settings, addressing limitations of the original SMAC \cite{samvelyan2019starcraft}. 

\begin{figure*}[!htp]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/results/maco_sota.png} 
    \caption{Performance comparison of \algoabb\ against other algorithms in the Gather, Disperse, Pursuit, and Hallway. The results highlight \algoabb's significant outperformance in Gather and Hallway, achieving near-perfect win rates and demonstrating superior sample efficiency. In Disperse, \algoabb\ outperforms all methods while moderately surpassing DCG as well. In the more challenging Pursuit and Hallway tasks, \algoabb\ effectively addresses issues like relative overgeneralization and miscoordination, proving its robustness in environments with partial observability and stochastic dynamics.} 
    \label{fig:res:maco_sota}
\end{figure*}


\subsection{Learning Algorithms and Training} 

To assess the effectiveness of \algoabb, we compare it against a range of methods that represent different strategies for managing coordination in MARL. IQL provides a baseline that illustrates how well agents perform without explicit coordination mechanisms. VDN, QMIX, QTRAN, QPLEX, and weighted variants of QMIX (OW-QMIX and CW-QMIX) represent most of the recent state-of-the-art value function factorization approaches. \algoabb\ directly competes with these methods by aiming to improve the way interactions and contributions are modeled. We select DCG as a representative approach that emphasizes modeling of only pairwise interactions between agents. Comparing \algoabb\ to DCG will highlight the need for capturing more nuanced and powerful multi-agent interactions in cooperative MARL tasks. 

By selecting these algorithms for comparison, we aim to position \algoabb\ within the broader landscape of MARL research, providing a clear assessment of its performance relative to other relevant methods. To ensure statistical significance in our experiments, we conducted four independent runs for each MARL algorithm in each domain and report the average (domain-specific) performance along with standard deviations in the next section. More details on the training setup and experiments are specified in the appendix. 

\begin{figure*}[!htp]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/results/smacv2_sota.png} 
    \caption{Scaling \algoabb\ to SMACv2, highlighting key metrics such as test win rate, returns, and number of dead allies and enemies. \edits{The results suggest that \algoabb\ adopts a cautious and strategic approach, prioritizing survival and long-term returns over immediate aggression}.}
    \label{fig:res:smacv2}
\end{figure*} 
