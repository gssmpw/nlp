
MARL has recently made significant progress in several complex domains including robotics, game playing, and autonomous systems \cite{oroojlooy2023review,vinyals2019grandmaster}. 

In recent years, many approaches have relied on representing the joint value function as a function of the individual value functions of all agents \cite{rashid2018qmix,rashid2020weighted,foerster2018counterfactual,son2019qtran,wang2021qplex,sunehag2018value}. This approach is good at capturing the value of coordination and mitigates the non-stationarity problem common in independent MARL \cite{tan1993multi,laurent2011world,matignon2012independent}. However, there are notable limitations. Relying exclusively on local observations and actions for local utility functions can suffer from miscoordination problems \cite{wang2021qplex,wang2022contextaware,lyu2023centralized} and \textit{relative overgeneralization} \cite{panait2006biasing,bohmer2020deep}, which occurs when agents fail to learn optimal policies if they are unable to distinguish between coordinated and uncoordinated actions in a task. \algoabb\ directly addresses these issues by using a higher-order value decomposition approach instead of agent-wise factorizations. We also demonstrate that it solves relative overgeneralization through the experiments discussed later. 

% \edits{In addition to value-based methods, there are other classes of factorized MARL algorithms too, such as decomposed actor-critic approaches \cite{peng2021facmac,wang2021dop,foerster2018counterfactual}. However, our focus in this work is on classic value-based algorithms, which remain foundational and state-of-the-art in cooperative MARL. This choice allows for a thorough comparison within a well-established paradigm, showcasing the strengths of our coordination graph-based approach. Notably, actor-critic methods often operate under different assumptions and paradigms, making direct comparisons challenging without forfeiting decentralizability or requiring significant algorithmic modifications. Moreover, such methods typically do not address the modeling of indirect and higher-order dependencies, which our approach explicitly captures. Investigating the adaptation of these methods to incorporate such dependencies represents an exciting avenue, and can be explored in the future.} 

\edits{Other classes of factorized MARL algorithms, such as decomposed actor-critic approaches \cite{peng2021facmac,wang2021dop,foerster2018counterfactual} also exist, however, our focus is on value-based algorithms, which are foundational in cooperative MARL. This choice enables a thorough comparison within a well-established paradigm, highlighting the strengths of our coordination graph-based approach. Actor-critic methods often operate under different assumptions, making direct comparisons difficult without sacrificing decentralizability or requiring major modifications. Additionally, they generally do not model indirect and higher-order dependencies, which our approach explicitly captures. Adapting such methods to address these dependencies is a promising direction for future work.} 

Several works have shown that coordination graph formulations can offer a promising solution to the aforementioned miscoordination challenges \cite{guestrin2002coordinated,guestrin2001multiagent,kok2006collaborative,rogers2011bounded}. They represent agents as vertices and define edges as payoff functions over joint action-observation spaces, facilitating a higher-order value decomposition among agents. \cite{kok2004sparse} explored their use in the context of tabular MARL. \cite{bohmer2020deep} extended coordination graphs to large state-action spaces through deep learning and also solved the problem of relative overgeneralization. Further research has been proposed since then to address different challenges such as inference of coordination graphs \cite{li2021deep}, learning sparse coordination graphs \cite{wang2022contextaware,castellini2021analysing}, and non-linear coordination graphs \cite{kang2022non} to name a few. All of these formulations focus on pairwise or direct interactions between agents to learn local value functions. Some recent works have motivated a shift of focus from individual agents to group development to foster efficient collaborations \cite{phan2021vast,shao2022self,duan2024group,zang2024automatic}. 

These works, however, do not explore higher-order and indirect multi-agent relationships, which can significantly enhance the learning process by capturing complex dependencies and interactions that go beyond simple pairwise connections. \edits{Some graph-based communication models \cite{kortvelesy2022qgnn,liu2020multi,hu2024learning} encode relationships through edge weights; however, they are still inherently limited to representing pairwise interactions. Some works formulate hyper-edges that explicitly connect multiple agents in a single edge \cite{castellini2021analysing}. Our approach models higher-order interactions by representing different relationships as unique edge types within the graph. In comparison, indirect interactions, as modeled in \algoabb, are arguably closer to the definition of hyper-edges since they represent the propagation of effects across intermediary agents, effectively capturing multi-step, emergent relationships. However, \algoabb\ distinguishes itself by incorporating both higher-order relationships, which represent multifactor dependencies, and indirect interactions, where the effects of one agent’s actions propagate through intermediaries to influence others. This enables it to dynamically model complex, multi-step dependencies, offering a more nuanced and adaptive representation essential for capturing the broader spectrum of coordination in MARL.} In many real-world scenarios, the outcome of an agent’s action is influenced not only by its immediate neighbors but also by more distant agents through chains of interactions. \algoabb\ allows the system to account for cascading effects where the action of one agent indirectly influences others across the coordination graph, leading to more coordinated and globally optimal behavior. Moreover, it captures and models the various types of multi-agent interactions that can potentially occur in cooperative MARL tasks. 

