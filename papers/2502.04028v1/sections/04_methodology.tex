
This section introduces \algosmall\ (\algoabb), a novel approach for learning cooperative policies in MARL. The primary motivation for developing \algoabb\ is to capture the richness of interactions in complex environments. \edits{By modeling diverse multi-agent dependencies, higher-order relationships, and indirect interactions, \algoabb\ enables more expressive representations, leading to improved coordination among agents. The workflow of \algoabb, as illustrated in Figure~\ref{fig:methodology}, consists of several key steps: starting from input observations and predefined interaction types represented by adjacency matrices, the approach dynamically models interactions, generates meta coordination graphs, and uses graph convolutions to learn cooperative policies.} 

\begin{figure*}[!ht]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/diagrams/dmcg.png} 
    \caption{\edits{Illustration} of \algotitle\ (\algoabb) for learning cooperative policies in MARL. The diagram shows how the approach captures and adapts to multiple types of interactions among agents, including higher-order and indirect relationships, and generates new graph structures by exploring dynamic interactions, even among initially unconnected agents.} 
    \label{fig:methodology}
\end{figure*} 

\paragraph{Modeling \edits{higher-order} interactions.} Multi-agent interactions often involve diverse and complex relationships. To address this, \edits{we model interactions using a set of adjacency matrices \( \{A_k\}_{k=1}^K \), where each \( A_k \) represents a specific interaction type. Each adjacency matrix encodes the dependencies between agents, where \( A_k[i, j] \neq 0 \) indicates the presence of a \( k \)-th type edge from agent \( j \) to agent \( i \). Notably, an agent can have different types of interactions with different agents, resulting in multiple edges going out of and coming into a single node. This is captured by having \( K \) individual adjacency matrices, each of size \( n \times n \), corresponding to the same \( n \) agents but encoding different interaction types. The graph representation can be expressed as a tensor \( \bm{A} \in \mathbb{R}^{n \times n \times K} \), where \( n \) is the number of agents and \( K \) is the total number of interaction types. This representation allows the model to incorporate multiple interaction types simultaneously, enabling it to capture higher-order relationships.} Additionally, each agent's local observations are represented in a feature matrix \( X \in \mathbb{R}^{n \times d} \), where \( d \) is the dimensionality of the features. \edits{Figure~\ref{fig:methodology} (left block) depicts this initial setup, where multiple adjacency matrices \( \{A_k\}_{k=1}^K \) represent diverse interaction types, forming the input for downstream MCG generation.} 

\paragraph{\edits{Modeling} indirect interactions.} Indirect interactions \edits{arise when the effects of one agent's actions propagate through intermediary agents, creating cascading influences. For example, in a search-and-rescue mission, the actions of one drone may influence others operating far away by altering paths, redistributing tasks, or sharing critical information. Such relationships can be modeled as sequences of interactions \( M \)}, defined as:
\[
v_1 \xrightarrow{e_1} v_2 \xrightarrow{e_2} \dots \xrightarrow{e_l} v_{l+1},
\]
where \( l \) is the length of \( M \). \edits{The composite relationship \( c = e_1 \circ e_2 \circ \dots \circ e_l \) can then represent the combined effect of interactions. This formulation also inherently captures multi-hop connections.} 

\paragraph{Generating meta coordination graphs.} We now \edits{introduce meta coordination graphs (MCGs) which extend traditional coordination graphs by incorporating multiple types of edges, enabling the representation of diverse and dynamic interactions among agents. Formally, an MCG can be defined as \( \mathcal{G}_M = (\mathcal{V}, \mathcal{E}) \), where \( \mathcal{V} \) represents agents as vertices, and \( \mathcal{E} \) represents edges of \( K \) types. Each edge type \( e_k \in \mathcal{E} \) captures a specific kind of interaction or dependency between two agents. Note here that, when \( |K| = 1 \), it becomes a standard coordination graph. For dynamic tasks, edges evolve over time and can be represented as \( e^t_k \in \mathcal{E}_t \), where \( \mathcal{E}_t \) is the set of edges at timestep \( t \). This temporal flexibility allows MCGs to adapt to the changing dynamics of multi-agent environments. As illustrated in Figure~\ref{fig:methodology} (middle block), to dynamically generate MCGs, \algoabb\ starts with the input adjacency matrices \( \{A_k\}_{k=1}^K \), where each \( A_k \) corresponds to a specific interaction type, as discussed previously. Using a softmax-based weighting mechanism, \algoabb\ combines the adjacency matrices to prioritize the most relevant interactions for the task. Specifically, it softly selects \( l \) graph structures from the set of \( K \) candidate adjacency matrices in \( \bm{A} \) by applying a \( 1 \times 1 \) convolution operation. This can be represented as \( \phi(\bm{A}; \text{softmax}(W_\phi)) \), where \( \phi \) is the convolution layer and \( W_\phi \in \mathbb{R}^{1 \times 1 \times K} \) is its parameter. This approach is inspired by channel attention pooling techniques from research in computer vision and pattern recognition \cite{chen20182}. Meta coordination graphs are then generated by multiplying selected adjacency matrices, capturing composite and higher-order dependencies. For instance, given a sequence of interactions \( M \), the resulting adjacency matrix \( A_M \) (corresponding to the MCG \( \mathcal{G}_M\)) is computed as \[ A_M = A_{e_l} \cdots A_{e_2} A_{e_1}, \] where \( l \) is the sequence length. This process allows \algoabb\ to dynamically refine and adapt the graph structure as learning progresses. The generated meta coordination graphs provide a flexible and expressive representation of agent interactions, capturing both direct and indirect relationships. This enables \algoabb\ to model emergent multi-agent behaviors and discover non-obvious interaction patterns, leading to improved coordination in complex MARL environments (discussed further with experiments and results in Section \ref{sec:results}).} \algoabb\ can be regarded as the MARL counterpart to methodologies like Graph Transformer Networks \cite{yun2019graph} for graph neural network-based tasks and Spatial Transformer Networks \cite{jaderberg2015spatial} for computer vision. Both aim to dynamically learn and adapt the underlying structure (graph-based relationships and spatial configurations, respectively) just as \algoabb\ learns and encodes emergent interactions among agents in the MARL context. 

\begin{figure*}[!htp]
    \centering
    \captionsetup[subfigure]{justification=centering}
    \subfloat[Gather]{\includegraphics[width=0.12\linewidth]{figures/envs/gather.png}} \hfill 
    \subfloat[Disperse]{\includegraphics[width=0.25\linewidth]{figures/envs/disperse.png}} \hfill  
    \subfloat[Pursuit]{\includegraphics[width=0.12\linewidth]{figures/envs/pursuit.png}} \hfill 
    \subfloat[Hallway]{\includegraphics[width=0.25\linewidth]{figures/envs/hallway.png}} \hfill
    \subfloat[SMACv2]{\includegraphics[width=0.2\linewidth]{figures/envs/smacv2.jpeg}} 
    \caption{Evaluation environments. The figure shows an example of (a) Gather with $g_1$ as the optimal goal and \{$g_2$, $g_3$\} as suboptimal goals, (b) Disperse illustrating a need for 6 agents at Hospital 1 at time $t$, (c) Pursuit where at least 2 predator agents (purple) must coordinate to capture a prey (yellow), (d) Hallway with 2 groups of agents, and (e) a SMACv2 scenario.} 
    \label{fig:envs}
\end{figure*}

\paragraph{Modeling arbitrary lengths of indirect interactions.} To encode \edits{relationships of arbitrary lengths $l$,} the adjacency matrix \( A_M \) \edits{can be generalized} as  \[ A_M = \prod_{i=1}^{l} \left( \sum_{e_i \in \mathcal{E}} \alpha^{(i)} A_{e_i} \right) \] where \( \alpha^{(i)} \) is the weight for the adjacency matrix \( A_{e_i} \) associated with the \( e_i \)-th interaction type. When \( \alpha \) is not a one-hot vector, \( A_M \) can be seen as the weighted sum of adjacency matrices for all length-\( l \) connections. We also append the identity matrix \( I \) in \( \bm{A} \), i.e., \( A_0 = I \). 

\paragraph{Generating multiple meta coordination graphs.} We can capture and represent a variety of interaction patterns and dependencies among agents in a flexible and scalable manner by generating multiple meta coordination graphs simultaneously in \algoabb. To do so, the output channels of \(1 \times 1\) convolution can be set to a desired value \(o\). Then, the soft selection will render adjacency tensors of size $n\times n\times o$, and their multiplication will give us an adjacency tensor for $\mathbb{A}_M \in \mathbb{R}^{n\times n\times o}$. 

\paragraph{\edits{Graph Convolution.}} We then compute a concatenation of node representations from each output channel using a graph convolutional layer \cite{kipf2017semisupervised} as follows \[ Z = \bigg\|_{i=1}^{o} \sigma(\tilde{D}_i^{-1} \tilde{\mathbb{A}}_M^{(i)} XW), \] where \(\| \) is the concatenation operator, \(o\) denotes the number of channels, \( \tilde{\mathbb{A}}_M^{(i)} = \mathbb{A}_M^{(i)} + I\) is the adjacency matrix from the \(i\)-th channel of \( \mathbb{A}_M \), \(\tilde{D}_i\) is the degree matrix of \(\tilde{\mathbb{A}}_M^{(i)}\), \(W \in \mathbb{R}^{d \times d}\) is a trainable weight matrix shared across channels and \(X \in \mathbb{R}^{n \times d}\) is a feature matrix. \(Z\) contains the node representations from \(o\) different meta coordination graphs. 

\paragraph{Learning cooperative policies.} Then, on the newly generated meta coordination graphs, our approach models coordination relations upon the graph-based value factorization specified by deep coordination graphs \cite{bohmer2020deep}, in which the global value function is factorized into the summation of individual utility functions \( Q_i \) and payoff functions \( Q_{ij} \) \edits{(Figure~\ref{fig:methodology}; right block)} as follows: 
\begin{equation*}
    \begin{split}
        Q&(\tau^t, a; \mathcal{G}_M)= \frac{1}{|\mathcal{V}|} \sum_{i \in I} Q_i(a_i \mid \tau_i) \quad + \\
        & \frac{1}{2|\mathcal{E}|} \sum_{(i,j) \in \mathcal{E}}\left[Q_{ij}(a_i, a_j \mid \tau^t_i, \tau^t_j) + Q_{ji}(a_j, a_i \mid \tau^t_j, \tau^t_i) \right].
    \end{split}
\end{equation*} 

\noindent The primary advantage of \algoabb\ lies in its capability to discover, learn, and leverage complex multi-agent interactions for improving coordination. Higher-order and indirect relationships are often far more intricate and emergent in nature, involving subtle dependencies and influences that cannot be explicitly specified during the initial setup of a task or environment. These interactions must be uncovered and modeled through careful analysis of the agents’ behaviors and the underlying structure of the coordination graph. \edits{\algoabb\ requires an initial set of coordination graphs (CGs) and edge types ( K ) as input. If the environment does not provide such input, the initialization of CGs and edge types becomes a tunable hyperparameter. In such cases, we investigate the performance of various topologies defined in DCG, such as fully connected, cyclic, linear, and star structures, to determine their suitability for different tasks. Through its attention mechanism, \algoabb\ dynamically learns and refines these edge types, prioritizing the most relevant interactions during training. This adaptive mechanism ensures the model evolves beyond the initial CG structure to align with task-specific requirements. By dynamically combining and refining initial edge types, \algoabb\ captures both higher-order and indirect relationships,} enabling the generation of novel graph structures that reflect nuanced, dynamic interactions, potentially among initially unconnected agents. As we will see in the following sections, this design results in significant performance enhancements across a range of challenging multi-agent scenarios. 

