\section{Introduction}
\label{sec:introduction}

Humans can recognize new objects after seeing them just a few times, a remarkable ability that is simulated and studied in few-shot object detection (FSOD). In an FSOD setup, there are two distinct datasets: the base dataset and the novel dataset. The base dataset is extensive and comprises numerous classes with abundant training instances. This dataset helps the model learn a wide variety of object features and characteristics, forming a general knowledge for detection tasks. In contrast, the novel dataset is limited, with only a few samples per novel class, posing a significant challenge for object detection. This constraint makes FSOD a critical research area~\citep{meta-rcnn, yolo-reweighting, rpn-attention, TFA, max-margin, trans-int, meta-detr, han2022few, bulat2023fs}, with potential applications in fields such as robotics, autonomous driving, and medical imaging, where models need to handle critical but rare scenarios. 

Earlier FSOD approaches~\citep{TFA, defrcn, meta-rcnn, meta-detr} firstly train a model on the base dataset to establish a generalized detector. This detector is then fine-tuned on the novel dataset to recognize and detect new objects. Still, this approach %can easily lead 
could lead to overfitting due to the limited amount of data available. Other methods~\citep{zhu2021semantic, li2023disentangle} leverage the general knowledge of the large language models (LLMs) to alleviate this issue. A simply yet effective approach for FSOD is data augmentation. Recent works~\citep{zhang2021hallucination, vu2023few} utilize the prior knowledge to create hallucinations in feature space to fine-tune classifiers. However, these synthetic samples often lack essential information for object detection, such as low level details, spatial information. Meanwhile, other methods~\citep{li2021transformation, demirel2023meta} rely solely on traditional geometric transformations (e.g., flipping, cropping, rotating) to create variations of given samples from novel classes, which limits the diversity of synthesized datasets.



Recently, diffusion models have achieved remarkable strides in producing high-quality and diverse  datasets~\citep{nichol2021glide, rombach2022high, ramesh2022hierarchical, saharia2022photorealistic}. Furthermore, large-scale text-to-image diffusion models have shown significant flexibility and scalability in image editing tasks by incorporating lightweight adapter modules for additional conditions (e.g., bounding box, semantic map, depth map, human pose)~\citep{zhang2023adding, li2023gligen, zhuang2023task}. Consequently, several FSOD methods~\citep{lin2023explore, fang2024data, wang2024snida} leverage controllable diffusion but often reply on simple prompts to generate synthetic objects, without exploring attributes  such as colors, shapes, details, sizes, types of objects. As a result, most synthesized novel samples are typical objects.

\begin{wrapfigure}{r}{0.49\textwidth}
    \centering
\includegraphics[width=0.5\textwidth]{fig/teaser.pdf}
    \caption{T-SNE visualization of novel synthetic samples and base real samples in Novel Set 1 of PASCAL VOC. \blue{We only generate synthetic samples for three novel classes (``bird", ``bus", ``cow") and use real samples for three base classes (``aeroplane", ``train", ``horse")}. Typical and hard samples in novel classes are created by using \blue{ICOS} and HPAS, respectively. \blue{Base real samples are considered as typical samples}.
    }
     \label{fig:teaser}
\end{wrapfigure}

To address the above problem, we propose In-Context learning for Object Synthesis (ICOS). ICOS leverages general knowledge from LLMs to deeply explore the attributes of novel classes and diversify prompt inputs. Additionally, the diversity of a class is derived from both \textbf{\textit{typical} }and \textbf{\textit{hard}} samples, as illustrated in Figure \ref{fig:teaser}. Inspired by the large margin principle (e.g. SVM~\citep{cortes1995support}), support vectors play a crucial role in learning a generalized model. These samples, considered hard samples, often exhibit characteristics not only of the main class but also of neighboring ones. In other words, in this paper, we define typical samples as those that contain features of a single class, whereas hard samples exhibit features of two classes. Leveraging this aspect, we aim to blend the characteristics of two classes during the data generation process. Unlike image classification, where only the foreground-foreground relations are considered and the main objects are roughly centered, object detection must take into account the foreground-background relations. To our knowledge, this is the first work to use ChatGPT to diversify prompts and embed the foreground-background relations when synthesizing diverse datasets in few-shot object detection.

In terms of the \textit{foreground-foreground} relation, we propose a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in the diffusion model. This approach guides the diffusion model to synthesize objects with high-level features (e.g., object parts) of the main class and low-level features (e.g., shape, color, size) of a selected base class. By mixing the low-level features of the base class, we leverage the prior knowledge acquired during the base training stage.
Regarding \textit{foreground-background} relation, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds from the base dataset. For typical backgrounds, we select the most cluttered backgrounds based on an entropy metric. For hard backgrounds, we select those with the highest similarity to foreground objects in the embedding space. During the base training stage, the model learns to classify novel objects as backgrounds when trained on base classes. This phenomenon creates ambiguities in learning and detecting novel classes. Therefore, in the novel training stage, we guide the model to distinguish novel classes from similar base backgrounds, utilizing the knowledge gained from base training.

In summary, our contributions can be summarized as follows: 
\begin{itemize}
    \item We propose a Multi-Perspective Data Augmentation (MPAD) framework for synthesizing data which better prevents the overfitting problem for FSOD.
    \item We introduce ICOS, HPAS, and BAP methods to enhance synthesis by considering foreground-background relation. Specifically, ICOS diversifies prompts using fine-grained attributes from the general knowledge of LLMs. HPAS supports the controllable diffusion model to create hard samples containing characteristics of two foregrounds, while BAP proposes typical and hard backgrounds in relation to the foreground.
    \item We conduct comprehensive experiments on FSOD benchmarks to demonstrate the effectiveness of our method. The results show that our method outperforms the baseline model by a large margin and achieves state-of-the-art performance on few-shot object detection.
\end{itemize}