% \newpage

\newpage
We provide more detailed information about our work in this Appendix. The structure includes ICOS outputs (Appendix~\ref{secA:ICOS-output}), visualizations of our synthesis dataset  (Appendix~\ref{secA:synthesis-vis}),  detailed studies for the foreground-foreground approach (Appendix~\ref{secA:ab_foreground-foreground}), \orange{ablations about the number of generated images (Appendix~\ref{secA:no_images}) and comparisons with different fine-tuning schemes (Appendix~\ref{secA:training_schemes})}.

\section{The responses in \blue{ICOS}}
\label{secA:ICOS-output}

We provide ChatGPT responses in \blue{ICOS} for exploring class attributes and fine-grained classes in Novel Set 1 of PASCAL VOC, as shown in Figure~\ref{fig:ICOS_output2} and Figure~\ref{fig:ICOS_output1}, respectively.


\begin{figure}[!hbt]
    \centering
    \includegraphics[width=0.99\linewidth]{fig/synthetic_dataset.pdf}
    \caption{\blue{In-context learning} results for exploring fine-grained classes in Novel Set 1 on the PASCAL VOC dataset.}
    \label{fig:ICOS_output2}
\end{figure}
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\linewidth]{fig/ICOS_01.pdf}
    \caption{\blue{In-context learning} results for exploring class attributes in Novel Set 1 on the PASCAL VOC dataset.}
    \label{fig:ICOS_output1}
\end{figure}


\newpage
\section{Synthesis images visualization}
\label{secA:synthesis-vis}

We provide visualization for synthesis images in Figure~\ref{fig:synthetic-dataset}. They are created separately for each method. We visualize synthetic samples for five novel classes in Novel Set 1 on PASCAL VOC. 
% In practice, these methods can be combined with each other. For example, a typical background image can be combined with a typical foreground.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\linewidth]{fig/synthetic_dataset.pdf}
    \caption{visualization for synthesis images. Each row represent a type of augmentation.}
    \label{fig:synthetic-dataset}
\end{figure}

\section{Detailed studies for the foreground-foreground approach}
\label{secA:ab_foreground-foreground}

\begin{table}[!h]
% \adjustbox{width=0.99\linewidth}{
\centering
\begin{tabular}{c|ccc}
\toprule
N.o. fine-grained classes & nAP   & nAP50 & nAP75 \\\midrule
1 & 40.0 & 66.8 & 42.3 \\
2 & 39.6 & 66.3 & 40.7 \\
3 & 39.9 & 65.4 & 43.3\\
\rowcolor{YellowOrange!30}
4 & 41.2 & 68.5 & 42.6 \\
5 & 40.5 & 67.1 & 42.9 \\
6 & 38.8 & 64.8 & 39.3 \\
\bottomrule
\end{tabular}
% } % end adjust box
\caption{Ablations about the number of  fine-grained classes in MPAD. nAP, nAP50, nAP75 metrics on Novel Set 1 of PASCAL VOC are reported.}
\label{tab:abs_fine-grained}
\end{table}


% As shown in the table, using the multi-scale method improves nAP50 from xx.x\% to xxx.x\% . Moreover, by employing both multi-scale and fine-grained techniques, detectors can be improved by 3.2\% compared to the baseline. These results shows a potentially way to improve FSOD models by cracking existing conditional diffusion methods. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.5\linewidth]{fig/ablation_fg_fg.pdf}
    \caption{Ablations about momentum $m$ and starting value $w$ in Eq. (\ref{eq:mix-prompt}). The average value of nAP, nAP50, nAP75 metrics on Novel Set 1 of PASCAL VOC are reported.}
    \label{fig:ab_fg_sim}
\end{figure}

As shown in Table~\ref{tab:abs_fine-grained} and Figure~\ref{fig:ab_fg_sim}, we provide ablation studies in our foreground generation method. We use nAP, nAP50 and nAP75 for Table~\ref{tab:abs_fine-grained}, and the average of these three metrics for Figure~\ref{fig:ab_fg_sim}. 

Firstly, we evaluate the impact of the number of fine-grained classes in Table~\ref{tab:abs_fine-grained}. An upward trend is experienced when the number of fine-grained classes increases up to 4. These experiments reveal that models cannot capture datasets with very high diversity. The reason for this is that models are optimized with default training hyper-parameters (e.g., training iterations, learning rate, batch size, etc.) for FSOD. As a result, detectors are  unable to converge on such datasets.

In Figure~\ref{fig:ab_fg_sim}, we test the hyper-parameters of the HPAS method.  It shows that when momentum is applied, overall performance improves. Specifically, when $m$ increases from $0.7$ to $0.9$, the model performance improves by about 1 to 2\%. However, when $m$ increases to $0.99$ with a low $w$, the base class features are retained over time steps, which will generate objects too similar to the base class and reduce the model performance. Similarly, when $w$ is too low, the generated objects may retain many of the base's features. \blue{More visualization of generated samples with different $w$ and $m$ is shown in Figure~\ref{fig:ab_m_w_hpas}}.

\blue{
\section{Ablations about the number of generated images}
\label{secA:no_images}

We also provide an ablation study on the number of generated images in Table~\ref{tab:abs_no_images}. These results show an upward trend in performance as the number of images increases, achieving the best performance at $300$ images.}

\begin{table}[hbt]
\centering
\begin{tabular}{c|ccccc}
\toprule
N.o. images & 50   & 100  & 200  & \textbf{300}  & 400  \\ \midrule
nAP75       & 42.0 & 41.0 & 43.7 & \textbf{42.8} & 43.8 \\
nAP50       & 67.6 & 66.9 & 68.8 & \textbf{69.1} & 68.0 \\ \bottomrule
\end{tabular}
\caption{Ablations about the number of generated images per class.}
\label{tab:abs_no_images}
\end{table}

\section{Comparisons with different fine-tuning schemes}
\label{secA:training_schemes}

\orange{To analyze the impact of different training schemes, we conducted experiments comparing our augmentation framework (MPAD) with alternative approaches, such as using simple prompting with ChatGPT and the diffusion model for generating training samples and fine-tuning strategies, as shown in Table~\ref{tab:training_schemes}. Specifically, we present training scheme (1), where base models are only trained on the synthetic dataset, and training scheme (2), where models are pre-trained with generated data before being fine-tuned with the original few-shot data. All models are evaluated under the 1-shot setting of Novel Set 1 of PASCAL VOC.}

\begin{table}[h]
    \centering
    \begin{tabular}{c|cccccccccc}
        \hline
        \#images & 5 & 10 & 50 & 100 & 200 & 300 & 400 & 600 & 800 & 1000 \\
        \hline
        (1) & 49.5 & 56.7 & 62.3 & 62.4 & 63.8 & 63.1 & 64.5 & 65.1 & 65.4 & 64.5 \\
        (2) & 62.3 & 60.5 & 60.4 & 61.7 & 61.0 & 61.6 & 62.1 & 62.1 & 62.3 & 62.5 \\
        \hline
    \end{tabular}
    \caption{Performance comparison between directly training on generated data (1) and fine-tuning in real data (2) using different numbers of generated samples.}
    \label{tab:training_schemes}
\end{table}

\orange{The results indicate that performance saturates at 600 samples, and additional samples do not improve results. Compared to the best performance obtained in this experiment, MPAD still outperforms simple prompting by 3.7, even when using only 300 samples, as shown in Table~\ref{tab:abs_no_images}.}

\orange{Our training scheme is also superior to alternative pre-training and fine-tuning approaches. Specifically, MPAD effectively leverages both real high-quality few-shot samples and diverse generated samples within a single fine-tuning phase, avoiding potential overfitting issues. When pre-training with a large number of training data and fine-tuning with too few samples, the model risks "forgetting" knowledge from the pre-training phase. Moreover, MPAD is computationally efficient, requiring a simpler training process compared to alternative approaches that involve separate pre-training and fine-tuning steps.}

\orange{These ablations demonstrate the effectiveness of MPAD in leveraging generated data while maintaining robustness and efficiency in training.}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{fig/detailed_visualization_HPAS.pdf}
    \caption{Visualization of generated samples with different of momentum ($m$) and $w$.}
    \label{fig:ab_m_w_hpas}
\end{figure}




