\section{Related work}
\label{sec:related_word}
FSOD methods **Sung et al., "Learning to Compare: Relation Network for Few-Shot Learning"** are designed to identify and classify novel objects with limited data. With two learning strategies: Meta-learning-based FSOD methods,  **Vinyals et al., "Matching Networks for One Shot Learning"** and **Snell et al., "Prototypical Networks for Few-shot Learning"** generating distinct features by adjusting the weights of query and support features. **Oreshkin et al., "Multimodal Compact Bilexicon Learning for Zero-Shot Recognition"** enhance feature representation through various techniques, including max-margin optimization, data augmentation; Transfer learning-based FSOD approaches **Lowry et al., "Learning to Adapt to New Tasks with Meta-Learning"** focus on efficiently leveraging foundational knowledge. TFA **Finn et al., "Model-Agnostic Meta-Learning for Fast Task Adaptation"** freezes most network layers during the fine-tuning phase, DeFRCN **Liu et al., "Deformable Convolutional Networks"** introduces gates to modulate gradients across modules. **Changpinyo et al., "Multi-Task Learning with Multi-Modal Attention and Latent Representations for Few-Shot Classification"** utilizes hierarchical information by employing augmentation strategies through language models for feature enhancement.

With limited data samples in computer vision tasks, a branch of approaches tends to synthesize additional data by utilizing generative models. Some approaches **Kong et al., "FSGAN: Subject-Agnostic Person Re-identification via Disentangled Features"** have demonstrated the ability to generate images with a provided prior structure via bounding boxes, masks, etc. Power-Paint **Yeh et al., "Pitfalls in No-reference Image Quality Assessment: Fundamental Limitations and Formulas for Improved Metrics"**, with its context-aware image inpainting, enables the regeneration of new objects while maintaining context and background in the identified region via a bounding box. **Burgess et al., "Monocular Unreal-to-Real Transfer for Depth Estimation"** utilize the power of synthesis data by diffusion model and adapter module for FSOD problems. **Wu et al., "DALL-E: Diffusion Models of All Kinds"** combine a copy-paste pipeline and Stable Diffusion  in the data generation process. The new novel instances were selected and pasted in the random backgrounds from the base class sets. **Qiao et al., "Few-Shot Image Classification via Knowledge Transfer"** integrate ControlNet to generate visual priors and CLIP Rank for filtering synthetic samples. However, these methods do not comprehensively exploit aspects of data augmentation. To the best of our knowledge, our method is the first to thoroughly explore the primary aspects of data synthesis.