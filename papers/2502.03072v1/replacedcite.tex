\section{Related Works}
Recent advancements in robot policy planning have facilitated the democratization of Behavior Cloning (BC), extending its reach beyond specialized research labs ____. These approaches typically involve models that map sensor observations into trajectories of future robot poses. In this context, diffusion models have emerged as a powerful tool to address critical limitations of Behavior Cloning, such as covariate shift ____, where robots fail to generalize beyond their training data ____. Diffusion-based policies, exemplified by Diffusion Policy (DP) ____, overcome these challenges by generating diverse and multi-modal action trajectories, significantly improving robustness in dynamic and unpredictable environments.

Recent large-scale robotic expert demonstration datasets ____ have fueled efforts to scale BC architectures. Works like Robotics Diffusion Transformer (RDT) ____, Octo ____, and $\pi_0$ ____ demonstrate that skills learned from diverse datasets can transfer to novel tasks, with some models achieving zero-shot generalization to grasping new objects. However, training large-scale models remains computationally expensive, limiting accessibility for resource-constrained settings.

Recent efforts have investigated point-based affordance representations ____, where keypoints are used to identify task-relevant objects and guide the policy with structured information, often leveraging pre-trained vision models. While scalable, these approaches primarily convey object locations but lack actionable information on how to grasp or manipulate them effectively.

Grasping-based affordance representations offer a more comprehensive solution by encoding feasible grasping strategies ____, providing both spatial and actionable information. Datasets like Grasp Anything ____ highlight the potential for scalable data collection in this domain. However, integrating grasping affordances with diffusion-based policies remains underexplored. Existing works such as GQCNN ____ provide initial steps, but further research is needed to unlock the full potential of affordance-driven planning.

Our work bridges this gap by integrating grasping-based affordance representations with diffusion-based policies. By providing richer conditional inputs, we aim to improve the efficiency and generalization of robot planning models, particularly in resource-constrained settings.