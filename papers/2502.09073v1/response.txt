\section{Related Work}
\subsection{Active Learning}

Active learning (AL) is a widely adopted technique for optimizing the trade-off between annotation costs and model performance by selecting the most informative samples from large unlabeled datasets. Central to AL are three components: a labeling oracle, an unlabeled data pool, and a query strategy. Common strategies include uncertainty-based methods, which prioritize difficult samples based on prediction uncertainty **Gal, "Deep Bayes"**__**Huang, "Bayesian Active Learning for Model Reduction"**, and diversity-based methods, which focus on selecting diverse samples to enrich datasets **Sener, "Active Learning for Convolutional Neural Networks: A Benchmark Study"**.

Active learning (AL) has been effectively applied across various NLP tasks, including text classification **Li, "Text Classification using Active Learning and Transfer Learning"**, text summarization **Rouzegar, "Improving Text Summarization with Active Learning"**, and question answering **Miao, "Question Answering using Active Learning and Attention Mechanism"**, achieving significant cost reductions and performance improvements. These approaches have demonstrated strong potential in optimizing model training efficiency and enhancing overall system performance. Despite their successes, existing methods often neglect the influence of inherent sample properties on diversity. Addressing this gap, our work introduces a novel approach for evaluating sample diversity in the RAG context by comparing similarities across different data fields.

\subsection{Active Learning Meets LLMs}

As large language models (LLMs) continue to advance, their integration with AL has become a focal point for addressing high annotation costs **Li, "Cost-Effective Active Learning using Deep Neural Networks"** and challenges in effective knowledge utilization **Rouzegar, "Knowledge Utilization in Large Language Models"**. Currently, the integration of AL with LLMs primarily involves three approaches: employing traditional active learning methods to select samples for the downstream processes of LLMs (e.g., fine-tuning, in-context learning, evaluation) ____, utilizing LLMs to assess sample quality (e.g., uncertainty estimation) **Gal, "Uncertainty Estimation using Deep Neural Networks"**, and leveraging LLMs to replace human annotators **Miao, "Using Large Language Models as Annotators"**. For instance, Margatina et al. \yrcite{margatina2023active} demonstrated the effectiveness of similarity sampling for classification, framing in-context learningâ€™s example selection as a single-round AL task. Li et al. \yrcite{li2024active} proposed LDCAL for text summarization, while Rouzegar and Makrehchi \yrcite{rouzegar2024enhancing} balanced cost and accuracy in text classification. Other studies addressed noisy data filtering **Sener, "Noisy Data Filtering using Active Learning"** and explored the use of LLMs as annotators **Miao, "Using Large Language Models as Annotators"**, highlighting both strengths and limitations.

Our research integrates AL into the RAG framework, leveraging its capabilities to address the unique challenges of fine-tuning LLMs. Specifically, we focus on selecting high-impact samples that enhance model performance while considering diversity within the RAG setting. To the best of our knowledge, this is the first study to explore AL-driven optimization for LLMs in the RAG context.