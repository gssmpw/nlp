@article{jones2024ai,
  title={The AI revolution is running out of data. What can researchers do?},
  author={Jones, Nicola},
  journal={Nature},
  volume={636},
  number={8042},
  pages={290--292},
  year={2024},
  publisher={Nature}
}

@article{khaki2024rs,
  title={Rs-dpo: A hybrid rejection sampling and direct preference optimization method for alignment of large language models},
  author={Khaki, Saeed and Li, JinJin and Ma, Lan and Yang, Liu and Ramachandra, Prathap},
  journal={arXiv preprint arXiv:2402.10038},
  year={2024}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{villalobos2024will,
  title={Will we run out of data? Limits of LLM scaling based on human-generated data},
  author={Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
  journal={arXiv preprint arXiv:2211.04325},
  pages={13--29},
  year={2024}
}

@article{zhuang2023toolqa,
  title={Toolqa: A dataset for llm question answering with external tools},
  author={Zhuang, Yuchen and Yu, Yue and Wang, Kuan and Sun, Haotian and Zhang, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={50117--50143},
  year={2023}
}

@article{abburi2023generative,
  title={Generative ai text classification using ensemble llm approaches},
  author={Abburi, Harika and Suesserman, Michael and Pudota, Nirmala and Veeramani, Balaji and Bowen, Edward and Bhattacharya, Sanmitra},
  journal={arXiv preprint arXiv:2309.07755},
  year={2023}
}

@article{jin2024comprehensive,
  title={A comprehensive survey on process-oriented automatic text summarization with exploration of llm-based methods},
  author={Jin, Hanlei and Zhang, Yang and Meng, Dan and Wang, Jun and Tan, Jinghua},
  journal={arXiv preprint arXiv:2403.02901},
  year={2024}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2023},
  publisher={ACM New York, NY}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@article{anthropic2024claude,
  title={Claude 3.5 sonnet model card addendum},
  author={Anthropic, AI},
  journal={Claude-3.5 Model Card},
  volume={2},
  year={2024}
}

@article{settles1995active,
  title={Active Learning Literature Survey},
  author={Settles, Burr},
  journal={Science},
  volume={10},
  number={3},
  pages={237--304},
  year={1995},
  publisher={University of Wisconsin--Madison}
}

@inproceedings{beluch2018power,
  title={The power of ensembles for active learning in image classification},
  author={Beluch, William H and Genewein, Tim and N{\"u}rnberger, Andreas and K{\"o}hler, Jan M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9368--9377},
  year={2018}
}

@inproceedings{liu2021influence,
  title={Influence selection for active learning},
  author={Liu, Zhuoming and Ding, Hao and Zhong, Huaping and Li, Weijia and Dai, Jifeng and He, Conghui},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9274--9283},
  year={2021}
}

@article{schroder2021revisiting,
  title={Revisiting uncertainty-based query strategies for active learning with transformers},
  author={Schr{\"o}der, Christopher and Niekler, Andreas and Potthast, Martin},
  journal={arXiv preprint arXiv:2107.05687},
  year={2021}
}

@inproceedings{xie2023active,
  title={Active finetuning: Exploiting annotation budget in the pretraining-finetuning paradigm},
  author={Xie, Yichen and Lu, Han and Yan, Junchi and Yang, Xiaokang and Tomizuka, Masayoshi and Zhan, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23715--23724},
  year={2023}
}

@inproceedings{sinha2019variational,
  title={Variational adversarial active learning},
  author={Sinha, Samarth and Ebrahimi, Sayna and Darrell, Trevor},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5972--5981},
  year={2019}
}

@inproceedings{agarwal2020contextual,
  title={Contextual diversity for active learning},
  author={Agarwal, Sharat and Arora, Himanshu and Anand, Saket and Arora, Chetan},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XVI 16},
  pages={137--153},
  year={2020},
  organization={Springer}
}

@inproceedings{yan2020active,
  title={Active learning with query generation for cost-effective text classification},
  author={Yan, Yi-Fan and Huang, Sheng-Jun and Chen, Shaoyi and Liao, Meng and Xu, Jin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={6583--6590},
  year={2020}
}

@inproceedings{gidiotis2022should,
  title={Should We Trust This Summary? Bayesian Abstractive Summarization to The Rescue},
  author={Gidiotis, Alexios and Tsoumakas, Grigorios},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={4119--4131},
  year={2022}
}

@article{hasan2018context,
  title={Context-aware query selection for active learning in event recognition},
  author={Hasan, Mahmudul and Paul, Sujoy and Mourikis, Anastasios I and Roy-Chowdhury, Amit K},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={42},
  number={3},
  pages={554--567},
  year={2018},
  publisher={IEEE}
}

@inproceedings{karamcheti2021mind,
  title={Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering},
  author={Karamcheti, Siddharth and Krishna, Ranjay and Fei-Fei, Li and Manning, Christopher D},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={7265--7281},
  year={2021}
}

@inproceedings{padmakumar2021dialog,
  title={Dialog policy learning for joint clarification and active learning queries},
  author={Padmakumar, Aishwarya and Mooney, Raymond J},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13604--13612},
  year={2021}
}

@article{niu2023ragtruth,
  title={Ragtruth: A hallucination corpus for developing trustworthy retrieval-augmented language models},
  author={Niu, Cheng and Wu, Yuanhao and Zhu, Juno and Xu, Siliang and Shum, Kashun and Zhong, Randy and Song, Juntong and Zhang, Tong},
  journal={arXiv preprint arXiv:2401.00396},
  year={2023}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{tsvigun2022active,
  title={Active Learning for Abstractive Text Summarization},
  author={Tsvigun, Akim and Lysenko, Ivan and Sedashov, Danila and Lazichny, Ivan and Damirov, Eldar and Karlov, Vladimir and Belousov, Artemy and Sanochkin, Leonid and Panov, Maxim and Panchenko, Alexander and others},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={5128--5152},
  year={2022}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9459--9474},
  year={2020}
}

@inproceedings{margatina2023active,
  title={Active Learning Principles for In-Context Learning with Large Language Models},
  author={Margatina, Katerina and Schick, Timo and Aletras, Nikolaos and Dwivedi-Yu, Jane},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={5011--5034},
  year={2023}
}

@inproceedings{maekawa2022low,
  title={Low-resource interactive active labeling for fine-tuning language models},
  author={Maekawa, Seiji and Zhang, Dan and Kim, Hannah and Rahman, Sajjadur and Hruschka, Estevam},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={3230--3242},
  year={2022}
}

@inproceedings{snijders2023investigating,
  title={Investigating Multi-source Active Learning for Natural Language Inference},
  author={Snijders, Ard and Kiela, Douwe and Margatina, Katerina},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={2187--2209},
  year={2023}
}

@inproceedings{rouzegar2024enhancing,
  title={Enhancing Text Classification through LLM-Driven Active Learning and Human Annotation},
  author={Rouzegar, Hamidreza and Makrehchi, Masoud},
  booktitle={Proceedings of The 18th Linguistic Annotation Workshop (LAW-XVIII)},
  pages={98--111},
  year={2024}
}

@inproceedings{taneja2024can,
  title={Can Active Label Correction Improve LLM-based Modular AI Systems?},
  author={Taneja, Karan and Goel, Ashok},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={9019--9031},
  year={2024}
}

@inproceedings{kholodna2024llms,
  title={Llms in the loop: Leveraging large language model annotations for active learning in low-resource languages},
  author={Kholodna, Nataliia and Julka, Sahib and Khodadadi, Mohammad and Gumus, Muhammed Nurullah and Granitzer, Michael},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={397--412},
  year={2024},
  organization={Springer}
}

@inproceedings{rauch2023activeglae,
  title={Activeglae: A benchmark for deep active learning with transformers},
  author={Rauch, Lukas and A{\ss}enmacher, Matthias and Huseljic, Denis and Wirth, Moritz and Bischl, Bernd and Sick, Bernhard},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={55--74},
  year={2023},
  organization={Springer}
}

@article{tan2024large,
  title={Large language models for data annotation: A survey},
  author={Tan, Zhen and Li, Dawei and Wang, Song and Beigi, Alimohammad and Jiang, Bohan and Bhattacharjee, Amrita and Karami, Mansooreh and Li, Jundong and Cheng, Lu and Liu, Huan},
  journal={arXiv preprint arXiv:2402.13446},
  year={2024}
}

@inproceedings{xiao2023freeal,
  title={FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models},
  author={Xiao, Ruixuan and Dong, Yiwen and Zhao, Junbo and Wu, Runze and Lin, Minmin and Chen, Gang and Wang, Haobo},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={14520--14535},
  year={2023}
}

@article{xu2024activerag,
  title={Activerag: Revealing the treasures of knowledge via active learning},
  author={Xu, Zhipeng and Liu, Zhenghao and Liu, Yibin and Xiong, Chenyan and Yan, Yukun and Wang, Shuo and Yu, Shi and Liu, Zhiyuan and Yu, Ge},
  journal={arXiv preprint arXiv:2402.13547},
  year={2024}
}

@inproceedings{li2024active,
  title={Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization},
  author={Li, Dongyuan and Zhang, Ying and Wang, Zhen and Tan, Shiyin and Kosugi, Satoshi and Okumura, Manabu},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={8959--8971},
  year={2024}
}

@inproceedings{zhang2023llmaaa,
  title={LLMaAA: Making Large Language Models as Active Annotators},
  author={Zhang, Ruoyu and Li, Yanzeng and Ma, Yongliang and Zhou, Ming and Zou, Lei},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={13088--13103},
  year={2023}
}

@inproceedings{zhang2022survey,
  title={A Survey of Active Learning for Natural Language Processing},
  author={Zhang, Zhisong and Strubell, Emma and Hovy, Eduard},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={6166--6190},
  year={2022}
}

@article{wang2023comprehensive,
  title={A comprehensive survey on deep active learning and its applications in medical image analysis},
  author={Wang, Haoran and Jin, Qiuye and Li, Shiman and Liu, Siyu and Wang, Manning and Song, Zhijian},
  journal={arXiv preprint arXiv:2310.14230},
  year={2023}
}

@article{tuia2021survey,
  title={A survey of active learning algorithms for supervised remote sensing image classification},
  author={Tuia, Devis and Volpi, Michele and Copa, Loris and Kanevski, Mikhail and Munoz-Mari, Jordi},
  journal={arXiv preprint arXiv:2104.07784},
  year={2021}
}

@article{budd2021survey,
  title={A survey on active learning and human-in-the-loop deep learning for medical image analysis},
  author={Budd, Samuel and Robinson, Emma C and Kainz, Bernhard},
  journal={Medical image analysis},
  volume={71},
  pages={102062},
  year={2021},
  publisher={Elsevier}
}

@article{bayer2024activellm,
  title={ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios},
  author={Bayer, Markus and Reuter, Christian},
  journal={arXiv preprint arXiv:2405.10808},
  year={2024}
}

@article{li2024active2,
  title={Active Evaluation Acquisition for Efficient LLM Benchmarking},
  author={Li, Yang and Ma, Jie and Ballesteros, Miguel and Benajiba, Yassine and Horwood, Graham},
  journal={arXiv preprint arXiv:2410.05952},
  year={2024}
}

@inproceedings{kim2021task,
  title={Task-aware variational adversarial active learning},
  author={Kim, Kwanyoung and Park, Dongwon and Kim, Kwang In and Chun, Se Young},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8166--8175},
  year={2021}
}

@article{jin2022one,
  title={One-shot active learning for image segmentation via contrastive learning and diversity-based sampling},
  author={Jin, Qiuye and Yuan, Mingzhi and Qiao, Qin and Song, Zhijian},
  journal={Knowledge-Based Systems},
  volume={241},
  pages={108278},
  year={2022},
  publisher={Elsevier}
}

@article{siriwardhana2023improving,
  title={Improving the domain adaptation of retrieval augmented generation (RAG) models for open domain question answering},
  author={Siriwardhana, Shamane and Weerasekera, Rivindu and Wen, Elliott and Kaluarachchi, Tharindu and Rana, Rajib and Nanayakkara, Suranga},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1--17},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{rangan2024fine,
  title={A fine-tuning enhanced RAG system with quantized influence measure as AI judge},
  author={Rangan, Keshav and Yin, Yiqiao},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={27446},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{fleischer2024rag,
  title={RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation},
  author={Fleischer, Daniel and Berchansky, Moshe and Wasserblat, Moshe and Izsak, Peter},
  journal={arXiv preprint arXiv:2408.02545},
  year={2024}
}

@article{asai2023self,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2310.11511},
  year={2023}
}

@inproceedings{leedpo2024,
  title={DPO-Finetuned Large Multi-Modal Planner with Retrieval-Augmented Generation@ EgoPlan Challenge ICML 2024},
  author={Lee, Kwanghyeon and Kang, Mina and Na, Hyungho and Bae, HeeSun and Na, Byeonghu and Kwon, Doyun and Shin, Seungjae and Kim, Yeongmin and Yun, Seungmin and Moon, Il-chul and others},
  booktitle={Multi-modal Foundation Model meets Embodied AI Workshop@ ICML2024},
  year={2024}
}

@inproceedings{leerlaif2024,
  title={RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Mesnard, Thomas and Ferret, Johan and Lu, Kellie Ren and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav and others},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{song2024rag,
  title={RAG-HAT: A Hallucination-Aware Tuning Pipeline for LLM in Retrieval-Augmented Generation},
  author={Song, Juntong and Wang, Xingguang and Zhu, Juno and Wu, Yuanhao and Cheng, Xuxin and Zhong, Randy and Niu, Cheng},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track},
  pages={1548--1558},
  year={2024}
}

@article{li2022batch,
  title={Batch multi-fidelity active learning with budget constraints},
  author={Li, Shibo and Phillips, Jeff M and Yu, Xin and Kirby, Robert and Zhe, Shandian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={995--1007},
  year={2022}
}

@inproceedings{shi2021diversity,
  title={Diversity-Aware Batch Active Learning for Dependency Parsing},
  author={Shi, Tianze and Benton, Adrian and Malioutov, Igor and {\.I}rsoy, Ozan},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2616--2626},
  year={2021}
}

@inproceedings{li2023best,
  title={The Best of Both Worlds: Combining Human and Machine Translations for Multilingual Semantic Parsing with Active Learning},
  author={Li, Zhuang and Qu, Lizhen and Cohen, Philip R and Tumuluri, Raj and Haffari, Gholamreza},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={9511--9528},
  year={2023}
}

@article{tan2021diversity,
  title={Diversity enhanced active learning with strictly proper scoring rules},
  author={Tan, Wei and Du, Lan and Buntine, Wray},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10906--10918},
  year={2021}
}

@article{duan2024research,
  title={Research on Relation Extraction Method Based on Active Learning},
  author={Duan, Lianzhai},
  journal={International Journal of Computer and Information System (IJCIS)},
  volume={5},
  number={2},
  pages={92--101},
  year={2024}
}

@inproceedings{chen2024benchmarking,
  title={Benchmarking large language models in retrieval-augmented generation},
  author={Chen, Jiawei and Lin, Hongyu and Han, Xianpei and Sun, Le},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17754--17762},
  year={2024}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{muennighoff2022mteb,
  title={MTEB: Massive text embedding benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"\i}c and Reimers, Nils},
  journal={arXiv preprint arXiv:2210.07316},
  year={2022}
}

@inproceedings{wang2014new,
  title={A new active labeling method for deep learning},
  author={Wang, Dan and Shang, Yi},
  booktitle={2014 International joint conference on neural networks (IJCNN)},
  pages={112--119},
  year={2014},
  organization={IEEE}
}

@article{sener2017active,
  title={Active learning for convolutional neural networks: A core-set approach},
  author={Sener, Ozan and Savarese, Silvio},
  journal={arXiv preprint arXiv:1708.00489},
  year={2017}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{xiao2020wat,
  title={Wat zei je? detecting out-of-distribution translations with variational transformers},
  author={Xiao, Tim Z and Gomez, Aidan N and Gal, Yarin},
  journal={arXiv preprint arXiv:2006.08344},
  year={2020}
}

@article{wood2024100,
  title={100\% Hallucination Elimination Using Acurai},
  author={Wood, Michael C and Forbes, Adam A},
  journal={arXiv preprint arXiv:2412.05223},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{DBLP:conf/kdd/WangZH00024,
author = {Haozhao Wang and Peirong Zheng and Xingshuo Han and Wenchao Xu and Ruixuan Li and Tianwei Zhang},
title = {FedNLR: Federated Learning with Neuron-wise Learning Rates},
booktitle = {Proceedings of the 30th {ACM} {SIGKDD} Conference on Knowledge Discovery
and Data Mining, {KDD} 2024, Barcelona, Spain, August 25-29, 2024},
pages = {3069--3080},
publisher = {{ACM}},
year = {2024},
}

@inproceedings{DBLP:conf/www/WangJZHR00024,
author = {Haozhao Wang and Yabo Jia and Meng Zhang and Qinghao Hu and Hao Ren and Peng Sun and Yonggang Wen and Tianwei Zhang},
title = {FedDSE: Distribution-aware Sub-model Extraction for Federated Learning
over Resource-constrained Devices},
booktitle = {Proceedings of the {ACM} on Web Conference 2024, {WWW} 2024, Singapore,
May 13-17, 2024},
pages = {2902--2913},
publisher = {{ACM}},
year = {2024}
}

@inproceedings{DBLP:conf/iclr/WangXLX0024,
author = {Haozhao Wang and Haoran Xu and Yichen Li and Yuan Xu and Ruixuan Li and Tianwei Zhang},
title = {FedCDA: Federated Learning with Cross-rounds Divergence-aware Aggregation},
booktitle = {The Twelfth International Conference on Learning Representations,
{ICLR} 2024, Vienna, Austria, May 7-11, 2024}
}

@article{DBLP:journals/corr/abs-2412-13840,
author = {Yichen Li and
Haozhao Wang and
Wenchao Xu and
Tianzhe Xiao and
Hong Liu and
Minzhu Tu and
Yuying Wang and
Xin Yang and
Rui Zhang and
Shui Yu and
Song Guo and
Ruixuan Li},
title = {Unleashing the Power of Continual Learning on Non-Centralized Devices:
{A} Survey},
journal = {CoRR},
volume = {abs/2412.13840},
year = {2024},
eprinttype = {arXiv},
eprint = {2412.13840}
}

@article{DBLP:journals/corr/abs-2412-13437,
author = {Wenchao Xu and
Jinyu Chen and
Peirong Zheng and
Xiaoquan Yi and
Tianyi Tian and
Wenhui Zhu and
Quan Wan and
Haozhao Wang and
Yunfeng Fan and
Qinliang Su and
Xuemin Shen},
title = {Deploying Foundation Model Powered Agent Services: {A} Survey},
journal = {CoRR},
volume = {abs/2412.13437},
year = {2024},
eprinttype = {arXiv}
}