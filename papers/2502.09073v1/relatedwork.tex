\section{Related Work}
\subsection{Active Learning}

Active learning (AL) is a widely adopted technique for optimizing the trade-off between annotation costs and model performance by selecting the most informative samples from large unlabeled datasets. Central to AL are three components: a labeling oracle, an unlabeled data pool, and a query strategy. Common strategies include uncertainty-based methods, which prioritize difficult samples based on prediction uncertainty \cite{beluch2018power,liu2021influence,schroder2021revisiting,maekawa2022low,rouzegar2024enhancing}, and diversity-based methods, which focus on selecting diverse samples to enrich datasets \cite{hasan2018context,sinha2019variational,agarwal2020contextual,maekawa2022low,xie2023active}. 

Active learning (AL) has been effectively applied across various NLP tasks, including text classification \cite{yan2020active,schroder2021revisiting}, text summarization \cite{gidiotis2022should,tsvigun2022active}, and question answering \cite{karamcheti2021mind,padmakumar2021dialog}, achieving significant cost reductions and performance improvements. These approaches have demonstrated strong potential in optimizing model training efficiency and enhancing overall system performance. Despite their successes, existing methods often neglect the influence of inherent sample properties on diversity. Addressing this gap, our work introduces a novel approach for evaluating sample diversity in the RAG context by comparing similarities across different data fields.

\subsection{Active Learning Meets LLMs}

As large language models (LLMs) continue to advance, their integration with AL has become a focal point for addressing high annotation costs \cite{tan2024large} and challenges in effective knowledge utilization \cite{xu2024activerag}. Currently, the integration of AL with LLMs primarily involves three approaches: employing traditional active learning methods to select samples for the downstream processes of LLMs (e.g., fine-tuning, in-context learning, evaluation) \cite{xie2023active,margatina2023active,bayer2024activellm}, utilizing LLMs to assess sample quality (e.g., uncertainty estimation) \cite{li2024active}, and leveraging LLMs to replace human annotators \cite{xiao2023freeal,kholodna2024llms}. For instance, Margatina et al. \yrcite{margatina2023active} demonstrated the effectiveness of similarity sampling for classification, framing in-context learningâ€™s example selection as a single-round AL task. Li et al. \yrcite{li2024active} proposed LDCAL for text summarization, while Rouzegar and Makrehchi \yrcite{rouzegar2024enhancing} balanced cost and accuracy in text classification. Other studies addressed noisy data filtering \cite{taneja2024can} and explored the use of LLMs as annotators \cite{zhang2023llmaaa}, highlighting both strengths and limitations.

Our research integrates AL into the RAG framework, leveraging its capabilities to address the unique challenges of fine-tuning LLMs. Specifically, we focus on selecting high-impact samples that enhance model performance while considering diversity within the RAG setting. To the best of our knowledge, this is the first study to explore AL-driven optimization for LLMs in the RAG context.