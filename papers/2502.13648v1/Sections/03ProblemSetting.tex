\section{Problem Setting}

\subsection{Presence of Parametric Knowledge}
\label{dataset:parametric-knowledge}


The assessment of whether LLMs possess the knowledge to answer a specific question is based on two key criteria: factual \textit{correctness}  \citep{zhang-etal-2024-r, zhang-etal-2024-self, wang-etal-2024-factuality} and the model's \textit{confidence} in its knowledge \citep{kuhn2023semantic, 10820047, amayuelas-etal-2024-knowledge}.
Since knowledge varies across models, for each model, we classify a question as \textbf{known} if both criteria are met and \textbf{unknown} otherwise, forming the basis of our problem setting.


To ensure precise knowledge estimation, we assess whether the model consistently generates correct responses rather than producing correct answers by chance.
For each question, we sample $n$ ($n = 10$) responses using the question alone.
Then, if the proportion of correct responses meets or exceeds the threshold $\tau$ ($\tau = 0.7$), the question is determined to be \textit{known}.
If none of the generated answers are correct, the question is determined to be \textit{unknown}.
Questions that fall between these conditions are classified as \textit{undefined} and excluded from scenario analysis.
The correctness is measured by Exact Match.




\subsection{Informativeness of External Knowledge}
\label{section:externalKnowledge}


The informativeness of external knowledge determines whether it should be utilized or disregarded.
\textbf{Informative knowledge} provides essential details that enable the model to refine its understanding even when it lacks direct knowledge of the question and, in some cases, update its existing knowledge.


We cover diverse forms of \textbf{uninformative knowledge} which may be entirely unrelated to the query, loosely related but lacking the necessary details to answer it (Figure \ref{figure:front_image} (c)), or thematically similar yet misleading, creating a false sense of relevance (Figure \ref{figure:front_image} (d)) \citep{wu2024how}.


To comprehensively cover informativeness, we incorporate four context types: original context paired with the question, conflicting context, randomly sampled uninformative context, and retrieved-uninformative context.


\subsection{Knowledge-Handling Scenarios}


The presence of parametric knowledge and the informativeness of external knowledge define four distinct knowledge-handling scenarios.
\textbf{Known-Informative (\KI)} refers to the scenario where the model possesses parametric knowledge and is provided with informative external knowledge.
In contrast, \textbf{Unknown-Informative (\UI)} occurs when the model lacks the knowledge to answer correctly and needs to incorporate informative external knowledge to refine its understanding.


In the \KI\ scenario, we exclude cases where external knowledge aligns with the model's known parametric knowledge, as no refinement is needed.
Instead, we focus on situations where the model's knowledge conflicts with external knowledge, creating a contextual-parametric conflict \citep{xu-etal-2024-knowledge-conflicts}.




For LLMs to be reliable, they need to appropriately handle cases where external knowledge is uninformative, adapting their response based on the presence of parametric knowledge.
In \textbf{Known-Uninformative (\KU)} scenario, the model should rely on its known parametric knowledge without being distracted by uninformative context.
In \textbf{Unknown-Uninformative (\UU)}, the question should be treated as unanswerable \citep{wen2025knowlimitssurveyabstention}.
The key challenge lies in the model's ability to recognize its unknown state and determine when to abstain.



