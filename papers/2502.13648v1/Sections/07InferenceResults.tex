

\section{Analysis on Inference-time Approach}

\input{Assets/Tables/reliability_train}


\subsection{Reliability of LLMs}
\label{section:model_reliability}

Figure \ref{figure:eval_v2_avg_base} presents Rely and Acc of models across different sizes.
Note that for \naive, Rely and Acc are identical because the model provides an answer in most cases instead of abstaining.


\textbf{Trade-off between Acc and Rely is evident across all model sizes and types under \absinst.}
For \absinst, Acc is always lower than \naive, indicating an abstention bias where LLMs tend to provide incorrect answers or abstain even when they have the necessary knowledge.


\textbf{Reliability increases as model scales.}
Most LLMs with different sizes exhibit similar Acc for \absinst, except for Llama-2 70B.
However, Rely shows a clear upward trend, suggesting that scaling enhances the model's reliability despite false abstention limiting Acc gains.


Overall, instructing LLMs to abstain appropriately lowers Acc while improving Rely, highlighting the challenge of balancing these two goals.
Minimizing this trade-off is essential to avoid incorrect responses or excessive abstention.



\subsection{Analysis on Knowledge-Handling Scenarios}
\label{section:modelErrorAnalysis}

A reliability score alone is insufficient for precisely identifying the specific capabilities the model lacks.
For an in-depth analysis, we assess model responses based on several key criteria beyond Acc under the four knowledge-handling scenarios.


Incorrect responses are categorized into three types.
Contextual errors (C) occur when the model incorrectly responds using non-answer information from external knowledge.
Parametric errors (P) arise when the model generates a response relying on its incorrect parametric knowledge.
Errors that do not fit into either of the above categories are classified as Other errors (O).
Abstention (Abs) is considered an error in the three scenarios other than \UU.
Figure \ref{figure:eval_v6_models_both} presents the error distribution for Llama 3 70B in each knowledge-handling scenario.


\textbf{Abstention depends on external cues, even when parametric knowledge is sufficient.}
In \absinst\ approach, abstention occurs far more frequently in uninformative scenarios.
The instruction is effective in encouraging the model to recognize when it lacks sufficient external information to produce a reliable answer.
However, in the \KU\ scenario, abstention error occurs at a high rate (43.3\%), despite the model possessing the necessary parametric knowledge to provide a valid response.


The model is not able to reliably assess whether it possesses the required knowledge, leading to an over-reliance on external cues.
Thus, its abstention behavior appears to depend more on external information, highlighting a fundamental limitation in its self-assessment capability.



\textbf{Over-reliance on parametric knowledge depends on its known state.}
The results indicate that in both \naive\ and \absinst\ approaches, the \KI\ scenario exhibits a significantly higher proportion of P error compared to other error types.
This suggests that when external knowledge conflicts with the model's parametric knowledge, the model tends to prioritize its known knowledge, even when the external knowledge is informative.
This behavior implies that the model is not fully receptive to conflicting external knowledge if it already possesses knowledge confidently.


Conversely, in the \UI\ scenario, parametric errors constitute the smallest proportion of errors.
It implies that when the required knowledge is not present in the model's parametric memory, it does not exhibit the same bias toward its own knowledge.



\textbf{In the uninformative scenarios, the most frequent error type is C error.}
This suggests that when the given context lacks informativeness, the model struggles to determine an appropriate response, leading to distraction from irrelevant information.
The absence of an effective abstention mechanism in \naive\ approach further exacerbates this issue, as the model attempts to generate a response despite the lack of meaningful knowledge.

\input{Assets/Figures/eval_v2_ID_base_rely}

