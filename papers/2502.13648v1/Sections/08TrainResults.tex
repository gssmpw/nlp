

\section{Analysis on Training-based Approach}

\subsection{Overall Performance}
\label{section:overallPerformance}


Table \ref{table:reli_train} presents the performance on the in-domain (ID) and out-of-domain (OOD) datasets.
For OOD datasets, we include HotpotQA, a multi-hop QA dataset, and BioASQ, which belongs to the biomedical scientific domain.


In most cases, \ours\ achieves the highest Rely, while its Acc remains comparable to \naive.
This suggests that through alignment, the model effectively minimizes incorrect responses via abstention while developing adaptability to various context types.
Additionally, \ours\ demonstrates strong generalization to OOD datasets, exhibiting similar trends to ID datasets, except in the case of Qwen 2.5.


\baseline, which is trained without considering abstention, achieves the highest Acc but does not perform as well in terms of Rely.
In some cases, \absinst\ exhibits a lower Rely than \baseline, implying that an approach that generates abstention words does not necessarily guarantee a higher Rely than one that always provides answers.



Figure \ref{figure:eval_v2_ID_base_rely} visualizes the performance gains achieved by \ours\ in terms of Rely and Acc.
\ours, trained with diverse context types based on parametric knowledge awareness, demonstrates a well-balanced improvement in both Acc and Rely, even outperforming larger models of the same type.


\subsection{Analysis on Knowledge-Handling Scenarios}

\input{Assets/Figures/analysis_v6-ID_OOD}


Using the same setup as Section \ref{section:modelErrorAnalysis}, we analyze three different approaches---\absinst, \baseline, and \ours---across four knowledge-handling scenarios.
We mainly assess the impact of abstention learning and knowledge utilization.
Figure \ref{figure:eval_v6_ID_OOD} shows the performance averaged separately over ID and OOD datasets.


\textbf{\ours\ demonstrates the most balanced performance across all knowledge-handling scenarios.}
\ours\ outperforms \absinst\ in both Acc and Abs across all scenarios within the ID datasets.
It also shows a significant improvement in informative scenarios, alleviating Abs error.
In terms of Acc, \baseline\ achieves the highest performance.
However, since \baseline\ does not learn to handle \UU\ scenario, it fails to abstain when necessary.
In the \UU\ scenario, \baseline\ instead generates incorrect responses, either by relying on incorrect parametric knowledge or by producing incorrect answers in most error cases.


\textbf{\ours\ matches \baseline\ in accuracy for informative scenarios, despite being trained for abstention.}
It remains unbiased toward parametric knowledge or abstention, effectively leveraging external knowledge to answer questions.
Notably, when external knowledge is informative, \ours\ rarely makes abstention errors, outperforming \absinst.


\textbf{While P errors dominate in the \KI\ scenario for inference-based approach, training has significantly reduced them.} 
This does not imply that the models are trained to disregard parametric knowledge entirely, as evidenced by their accuracy in the \KU\ scenario.
This suggests that they learn to moderate their reliance on parametric knowledge, leveraging it when necessary while incorporating external knowledge in informative scenarios.




\textbf{In \UU, \ours\ achieves superior performance by effectively handling uninformative context without being misled by it.}
It learns to determine whether the information is known or unknown, aligning more effectively with comprehensive knowledge handling.
However, \ours\ experiences an accuracy drop in \KU, especially in OOD datasets.
This occurs because its ability to robustly generate parametric responses in \KU\ does not generalize well.
The decline in Acc is directly offset by a proportional increase in Abs errors. 
This suggests that when the knowledge domain shifts, the model struggles to assess the presence of its parametric knowledge effectively.



