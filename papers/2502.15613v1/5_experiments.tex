\section{Experiments} 
To evaluate our proposed method, we designed experiments to (i) evaluate the stability of grasping probability maps under different object and robot pose conditions, (ii) validate different policy's generalization for pick-and-place tasks across diverse two-finger grippers without retraining the policy, and (iii) assess the generated trajectory's safety and task completion issues across different policies.


\subsection{Experiment Setup}
The experimental setup employs a Franka Emika Panda robotic arm equipped with interchangeable end-effectors, including a native parallel gripper augmented with custom 3D-printed fingertips and a Robotiq 2F-85 adaptive gripper, as shown in Fig. \ref{fig:grippers}. Real-time control is managed via a workstation running Ubuntu 20.04 with a real-time kernel to ensure deterministic low-latency operation, while Diffusion Policy framework is trained and executed on another workstation with a NVIDIA RTX-4090 GPU and an AMD 7950x CPU. Perception integrates an egocentric Azure Kinect DK camera and a fixed Intel RealSense D455 camera. Sensor data synchronizations are facilitated through ROS noetic. 


\subsection{Data Collection and Training}
\textit{1) Data Collection:} Our dataset comprises 59 expert demonstration trajectories of pick-and-place tasks with the gripper $\mathbb{G}_0$ in Fig. \ref{fig:grippers}. Multimodal observations are captured through three synchronized modalities: (1) Proprioceptive states: including the 6-DoF end-effector pose and continuous gripper width measurements obtained via the Franky API\footnote{\href{https://github.com/TimSchneider42/franky}{https://github.com/TimSchneider42/franky}}; (2) 3D point clouds are acquired via the D455 camera and are processed with farthest point sampling. To estimate the gripper-agnostic \textit{grasping probability map} $\mathcal{G}^*_{\text{prob}}$, we adapt the grasping probability representation from \cite{10582538} to process the Kinect camera's depth and RGB images; (3) Kinesthetic demonstration signals: recorded via a joystick controller operating at 2Hz, encoding relative Cartesian displacements alongside a one-hot encoded gripper action (open/closed).

\textit{2) Training:}  We select the Simple DP3 implementation \cite{Ze2024DP3} as our policy's backbone for efficiency. To integrate the \textit{grasping probability map} $\mathcal{G}^*_{\text{prob}}$ into the policy framework, we adapt Simple DP3 to Simple DP3 MM (Multi-Modal Simple Diffusion Policy 3D). This architecture concatenates three encoded inputs: Proprioceptive states and point cloud features processed identically to Simple DP3; $\mathcal{G}^*_{\text{prob}}$ encoded through a ResNet-18 network. The model retains the same pruned UNet backbone as Simple DP3. Training follows the original Simple DP3 procedure but extends the duration to 8,000 epochs to accommodate the additional modality.

\input{exp-figure-gmap}

\subsection{Real-world Experiment}
\textbf{1) Evaluation of Grasping Probability Map}: 
We evaluate the stability of grasping probability maps under three perturbation scenarios, including graspable object variation, gripper morphology, and viewpoint changes (i.g. end-effector heights). We define stability as the extent to which the probability distribution of these maps remains consistent across the different scenarios. If the variance in distribution is large, the resulting shift can adversely affect the policyâ€™s trajectory generation from training to inference. Fig.~\ref{fig:gmap} visualizes raw GG-CNN outputs $\mathcal{G}_{\text{prob}}$ versus our processed maps $\mathcal{G}^*_{\text{prob}}$ across these conditions. Fig. \ref{fig:exp-gmap} presents the difference between $\mathcal{G}_{\text{prob}}$ and $\mathcal{G}^*_{\text{prob}}$ through normalized probability histograms, here only shows high-probability parts ($>$ 0.4). The baseline $\mathcal{G}_{\text{prob}}$ demonstrates multimodal distributions versus our unimodal concentration. Moreover, Tab. \ref{tab:kl} quantifies the distribution difference across conditions via KL divergence, indicating $\mathcal{G}^*_{\text{prob}}$ provides stable grasping information against perturbations. The stabilized grasp cues enable the policy to generate spatially consistent approach trajectories despite sensory perturbations, which is critical for reliable manipulation across grippers. 

\textbf{2) Policy Performance Comparison across Grippers}:

(a) \textbf{Setup}: Our policy and baselines are evaluated in different pick-and-place task setting, including utilizing different grippers and manipulating different objects. Notably, all training demonstrations included only one type of gripper ($\mathbb{G}_0$) and graspable object (a pink block).

(b) \textbf{Success Rate Definition}: Picking the object from the tabletop and placing it on a box is a successful trial. All other outcomes are deemed failures, including failure to grasp the object or dropping it during manipulation.

(c) \textbf{Baseline and Ablation Study Setting}: 
\begin{itemize}
  \item Diffusion Policy (DP)~\cite{chi2023diffusion}:  Implements a baseline framework for temporal action sequence generation through diffusion modeling. DP receives two viewpoint RGB images from the Realsense and Kinect cameras.
  \item Diffusion Policy 3D (DP 3D)~\cite{Ze2024DP3}: Extends the Diffusion Policy paradigm by incorporating 3D spatial reasoning. It receives point clouds from the Realsense camera as visual observations.
  \item Ours w/o Projection: The trajectory optimization strategy in \ref{sec:optimization} is not activated in the online inference phase, including gripper mapping and safety-constrained trajectory projection.
  \item Ours w/o $\mathcal{G}^*_{\text{prob}}$: Utilizing RGB images from the Kinect camera to train policy, instead of gripper-agnostic grasping knowledge $\mathcal{G}^*_{\text{prob}}$.
\end{itemize}

\input{table-exp-success-rate-block}

(e) \textbf{Quantitative results}:
Our method demonstrates generalization across diverse gripper geometries relative to baselines. As shown in Table~\ref{tab:comparison}, our method achieves an average success rate of \textbf{93.3\%} on all gripper configurations for the seen graspable object (block). In contrast, for the original gripper \(\mathbb{G}_0\), both DP and DP 3D exhibit notably lower success rates (e.g., DP succeeds only 20\%, while DP 3D fails entirely), primarily due to their imprecise motion generation, resulting in collisions with the table. When transitioning to shorter grippers (\(\mathbb{G}_2\) and \(\mathbb{G}_3\)), DP and DP 3D can complete the task, as the reduced gripper length diminishes the likelihood of collisions. Notably, our policy without the Projection (``Ours w/o Projection'') is capable of successfully completing the task for the original gripper \(\mathbb{G}_0\); however, it fails for grippers that deviate more significantly from \(\mathbb{G}_0\) (specifically, \(\mathbb{G}_1\), \(\mathbb{G}_4\), and \(\mathbb{G}_5\)). Furthermore, for the ablation setting with ``Ours w/o $\mathcal{G}^*_{\text{prob}}$'', the performance on \(\mathbb{G}_0\), \(\mathbb{G}_3\), and \(\mathbb{G}_4\) is comparable to, or slightly worse than, that of our full policy. However, when evaluated on grippers that appear different from \(\mathbb{G}_0\) from the perspective of the Kinect camera (namely, \(\mathbb{G}_1\) and \(\mathbb{G}_5\)), its performance degrades (the success rate ranging from 0 to 20\%). These results underscore the critical roles of both the Projection and gripper-agnostic grasping knowledge \(\mathcal{G}^*_{\text{prob}}\) in ensuring robust generalization across varying gripper geometries. Our method demonstrates robust generalization to unseen object geometries compared to baseline approaches, as evidenced by experiments with objects such as bananas. Our method achieves an average success rate of 70\%, outperforming baseline policies. While DP and DP 3D occasionally succeed (30\% and 20\%, respectively) when the unseen object is placed identically to training demonstrations, their reliance on position-specific motion primitives limits adaptability. For instance, DP's rigid trajectory generation fails to adjust to novel object shapes, often resulting in misaligned grasps (e.g., sliding off the curved surface of a banana). 

\input{figure-exp-safety}

\input{figure-exp-horizon}


When object positions are randomized, both DP and DP 3D collapse entirely (success rate is 0). Notably, our projection module plays a pivotal role in handling unseen geometries. Compared to the ablation without gripper-agnostic grasping knowledge ``Ours w/o \( \mathcal{G}^*_{\text{prob}} \)'', our policy exhibits a better understanding of grasping unseen objects by leveraging gripper-agnostic grasping knowledge. Similarly, our policy without the Projection module (``Ours w/o Projection'') is still able to locate the grasping point. However, it fails for grippers that deviate more significantly from \( \mathbb{G}_0 \) (specifically, \( \mathbb{G}_2 \), \( \mathbb{G}_4 \), and \( \mathbb{G}_5 \)). These results highlight the limitations of baseline methods in disentangling object geometry from positional priors. This capability is critical for real-world applications where object and experiment setup diversity are inherent.


\textbf{3) Safety Analysis}:
We analyze how \textbf{gripper mapping} and \textbf{safety-constrained trajectory projection} ensure safe trajectory generation and successful task completion across different grippers. As shown in Fig.~\ref{fig:safety}, for Gripper \( \mathbb{G}_0 \), as mentioned in quantitative results, DP and DP 3D often result in collisions. After introducing the \textbf{safety-constrained trajectory projection} to DP and DP 3D on the inference phase, the generated motions are projected within the defined safety constraints, enabling both policies to successfully complete the task without collisions, as shown in Fig. \ref{fig:safe-a}. When testing on gripper \( \mathbb{G}_1 \), which is longer than gripper \( \mathbb{G}_0 \) with TCP's shift +3.5cm, as shown in Fig. \ref{fig:safe-b}, DP, DP 3D, and our policy without the projection module consistently lead to table collisions. In contrast, our policy ensures collision-free execution by correctly adjusting the motion to the extended gripper length. For the shorter gripper \( \mathbb{G}_4 \), our policy without \textbf{gripper mapping} fails to adapt the motion to the shorter gripper compared to \( \mathbb{G}_0 \), where TCP's shift -4cm, resulting in a grasping point that is too high above the object. However, our full policy successfully generates adaptive motions that account for the shorter gripper length, ensuring accurate and stable object grasping. Fig. \ref{fig:real-world-horizon} displays our method's rollout of pick-and-place tasks with different grippers.



