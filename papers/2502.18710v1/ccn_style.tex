\documentclass[10pt,letterpaper]{article}

\usepackage{ccn}
\usepackage{apacite}
\usepackage[bookmarks=false]{hyperref} 
\usepackage{natbib}
\usepackage{bm}
\usepackage{xcolor}
\usepackage{array}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{amsmath, amsfonts}
\usepackage{dblfloatfix}

\definecolor{mplblue}{rgb}{0.0, 0.447, 0.741}
\definecolor{mplgreen}{rgb}{0.0, 0.621, 0.451}
\definecolor{mplorange}{rgb}{0.850, 0.325, 0.098}





\title{Bridging Critical Gaps in Convergent Learning: How Representational Alignment Evolves Across Layers, Training, and Distribution Shifts}
 
\author{{\large \bf Chaitanya Kapoor, Sudhanshu Srivastava, Meenakshi Khosla} \\~\\
Department of Cognitive Science, UC San Diego, \texttt{\{chkapoor, sus021, mkhosla\}@ucsd.edu}}
%   A Department, 1234 Example Street\\
% A City, State 12345 A country
%   \AND {\large \bf Another Person (AnotherPerson@this.planet.edu)} \\
%   A Department, 1234 Example Street\\
% A City, State 12345 A country}


\begin{document}
\maketitle


\section{Abstract}
{
\bf
Understanding convergent learning---the extent to which artificial and biological neural networks develop similar representations---is crucial for neuroscience and AI, as it reveals shared learning principles and guides brain-like model design. While several studies have noted convergence in early and late layers of vision networks, key gaps remain. First, much existing work relies on a limited set of metrics, overlooking transformation invariances required for proper alignment. We compare three metrics that ignore specific irrelevant transformations: linear regression (ignoring affine transformations), Procrustes (ignoring rotations and reflections), and permutation/soft-matching (ignoring unit order). Notably, orthogonal transformations align representations nearly as effectively as more flexible linear ones, and although permutation scores are lower, they significantly exceed chance, indicating a robust representational basis. A second critical gap lies in understanding when alignment emerges during training. Contrary to expectations that convergence builds gradually with task-specific learning, our findings reveal that nearly all convergence occurs within the first epoch---long before networks achieve optimal performance. This suggests that shared input statistics, architectural biases, or early training dynamics drive convergence rather than the final task solution. Finally, prior studies have not systematically examined how changes in input statistics affect alignment. Our work shows that out-of-distribution (OOD) inputs consistently amplify differences in later layers, while early layers remain aligned for both in-distribution and OOD inputs, suggesting that this alignment is driven by generalizable features stable across distribution shifts. These findings fill critical gaps in our understanding of representational convergence, with implications for neuroscience and AI.
%Understanding convergent learning---the extent to which different artificial and biological neural networks learn similar representations---is crucial for both neuroscience and AI, as it can reveal shared principles of learning and guide the design of brain-like models. While several studies have noted convergence in early and late layers of vision networks, important gaps remain. First, most existing work has relied on a limited set of metrics, often overlooking the role of specific transformation invariances needed to properly align representations across layers. We address this by comparing three metrics, each designed to ignore specific types of irrelevant transformations: linear regression (ignoring affine transformations), Procrustes (ignoring rotations and reflections), and permutation or soft-matching (ignoring the order of units). Strikingly, orthogonal transformations align representations almost as effectively as more flexible linear transformations, and permutation scores, though lower than the other metrics, significantly exceed chance levels, indicating that the representational basis is meaningfully distinguished. A second, critical gap in the literature is the lack of understanding of when representational alignment emerges during training. Contrary to the expectation that convergence builds gradually with task-specific learning, our findings reveal that nearly all convergence occurs within the first epoch---long before networks reach optimal performance. This surprising result suggests that shared input statistics, common architectural biases, or the early dynamics of training drive convergence instead of the final task solution. Finally, prior studies have not systematically examined how changes in input statistics affect representational alignment. Our work shows that out-of-distribution (OOD) inputs consistently amplify differences in later layers, reflecting sensitivity to input statistics, while early layers maintain alignment for both in-distribution and OOD inputs, suggesting that this alignment is driven by generalizable features stable across distribution shifts. These findings fill critical gaps in our understanding of representational convergence with significant implications for both neuroscience and AI. 	
}
\begin{quote}
\small
\textbf{Keywords: Artificial Intelligence, Machine Learning, Representational Convergence} 
\end{quote}

\section{Introduction}
\input{./intro}
\input{./figures-code/network-hierarchy}

\section{Problem Statement}
We consider two representations, 
\[
\bm{X}_i\in \mathbb{R}^{M\times N_x} \quad \text{and} \quad \bm{X}_j\in \mathbb{R}^{M\times N_y},
\]
obtained from different models over \(M\) unique stimuli, where \(N_x\) and \(N_y\) denote the number of neurons (or units) in each representation, respectively. To systematically identify the minimal transformations needed for alignment, we use three metrics that quantify similarities between networks while ignoring nuisance transformations. These metrics are ordered to reflect progressively more permissive mapping functions (from strict to flexible):

\begin{enumerate}
    \item \textbf{Permutation Score (and its extension, the Soft-Matching Score):}  
    This metric treats the order of units as arbitrary, reflecting similarity in representational form---i.e., how the representations are assigned at the level of individual neurons. In this case, we seek a mapping matrix \(\bm{M}\) that minimizes
    \[
    \min_{\bm{M}} \|\bm{X}_j - \bm{M}\bm{X}_i\|_2^2.
    \]
    For the permutation score, when \(N_x = N_y\), \(\bm{M}\) is constrained to be a permutation matrix:
    \[
    \bm{M} \in \mathcal{P}(N).
    \]
    This is computed using the linear sum assignment algorithm~\citep{burkard2012assignment}. When \(N_x \neq N_y\), we use a generalized version called the soft-matching score~\citep{khosla2024soft}. Here, the mapping matrix \(\bm{M} \in \mathbb{R}^{N_x \times N_y}\) is constrained such that its entries are nonnegative and satisfy
    \[
    \sum_{j=1}^{N_y} M_{ij} = \frac{1}{N_x} \quad \text{for all } i = 1, \dots, N_x,
    \]
    \[
    \sum_{i=1}^{N_x} M_{ij} = \frac{1}{N_y} \quad \text{for all } j = 1, \dots, N_y.
    \]
    These constraints place \(\bm{M}\) in the transportation polytope \(\mathcal{T}(N_x, N_y)\). The optimal soft-matching mapping is obtained by solving
    \[
    \min_{\bm{M} \in \mathcal{T}(N_x, N_y)} \|\bm{X}_j - \bm{M}\bm{X}_i\|_2^2,
    \]
    using the network simplex algorithm. In the special case when \(N_x = N_y\), the soft-matching score reduces to the permutation score.

    \item \textbf{Procrustes Score:}  
    The Procrustes metric discounts rotations and reflections, capturing similarity in the overall geometric shape of the representation. When \(N_x \neq N_y\), we first zero-pad the lower-dimensional representation so that both representations become square. Then, we seek an orthogonal mapping matrix \(\bm{M}\) by solving
    \[
    \min_{\bm{M} \in \mathcal{O}(N)} \|\bm{X}_j - \bm{M}\bm{X}_i\|_2^2,
    \]
    where
    \[
    \mathcal{O}(N) = \{\bm{M} \in \mathbb{R}^{N \times N} \mid \bm{M}^\top \bm{M} = \bm{I}\}.
    \]

    \item \textbf{Linear Regression Score:}  
    The linear regression approach imposes no constraints on the mapping matrix, thereby discounting only affine transformations. Here, \(\bm{M}\) is allowed to be any matrix in \(\mathbb{R}^{N_y \times N_x}\), and we solve
    \[
    \min_{\bm{M} \in \mathbb{R}^{N_y \times N_x}} \|\bm{X}_j - \bm{M}\bm{X}_i\|_2^2.
    \]
\end{enumerate}

Once the optimal mapping matrix \(\bm{M}\) is computed for each metric, we report the alignment using the pairwise correlation:
\[
\texttt{Alignment} = \texttt{corr}\left(\bm{X}_j,\ \bm{M}\bm{X}_i\right)
\]
Since the metric is asymmetric, we report the average alignment score computed in both directions: \texttt{corr}$\left(\bm{X}_j,\  \bm{M}_1\bm{X}_{i}\right)$ and \texttt{corr}$\left(\bm{X}_i,\ \bm{M}_2\bm{X}_{j}\right)$, where $\bm{M}_1$ and $\bm{M}_2$ are the respective transformation matrices.

\noindent
By leveraging these three metrics---which progressively relax the mapping constraints from strict (soft-matching / permutation) to flexible (linear regression)---we can dissect the nature of representational alignment across networks, distinguishing between similarity in representational form (captured by the soft-matching score, which reduces to the permutation score when \(N_x = N_y\)), overall geometric shape (captured by the Procrustes score), and information content (captured by the linear regression score).

\section{Method}
Below, we outline the general framework for evaluating alignment between different vision models (ResNet18, ResNet50~\citep{he2016deep}, VGG16, VGG19~\citep{simonyan2014very}).
\subsection{Network Training}
Consider a model type denoted by $M$. We train a pair of models, $\{M_1, M_2\}$ initialized with two different random seeds. We initialize the models using a uniform Xavier distribution~\citep{glorot2010understanding}. This controlled setup ensures that the two models are identical in architecture and achieve comparable task performance, allowing us to isolate the effects of stochastic variations in the SGD process (such as initialization differences and input order). By comparing the representations from these models, we can quantify the minimal set of transformations required to align them. All models are trained from scratch on CIFAR100 and ImageNet for $100$ and $80$ epochs respectively. We save model weights at every epoch and additionally store the best-performing weights based on test-set performance for each dataset.

\subsection{Comparing Convolutional Layers}
For a given convolutional layer, let the activations be represented by $\bm{X} \in \mathbb{R}^{m \times h \times w \times c}$, where \(m\) is the number of stimuli, \(h\) and \(w\) denote the spatial height and width, and \(c\) is the number of channels (i.e., convolutional filters). In theory, each convolutional layer produces a feature map whose spatial dimensions are equivariant to translations. That is, a circular shift along the spatial dimensions yields an equivalent representation (up to a shift). As a result, one could compare the full spatial activation patterns between networks by considering an equivalence relation that allows for spatial shifts. However, evaluating an alignment that optimizes over all possible shifts together with another alignment (\emph{e.g.}, Procrustes) is computationally costly.

Previous work has demonstrated that in many convolutional layers the optimal spatial shift parameters tend to be close to zero~\citep{williams2021generalized}. This observation motivates our simpler approach: rather than collapsing the spatial dimensions by flattening the entire feature map (which would yield an activation matrix of size \(m \times (h \cdot w \cdot c)\), we instead extract a single representative value from each channel. In our experiments, we choose the value at the center pixel of each channel. This reduces the activation tensor \(\bm{X}\) to a two-dimensional matrix $\bm{X}^{\prime} \in \mathbb{R}^{m \times c}$,
where each row corresponds to a stimulus and each column to a channel. This strategy drastically reduces the computational complexity of computing the optimal mapping. For instance, aligning the full spatially flattened representations would incur a runtime of \(\mathcal{O}(m h^2w^2c + h^3w^3c^3)\), whereas our center-pixel approach reduces the problem to aligning an \(m \times c\) matrix, resulting in a more tractable complexity.

%By using this simplified comparison strategy, we exploit the translation equivariance of convolutional layers while avoiding the heavy computational burden associated with exhaustively searching over spatial shifts.


\subsection{Computing Alignment}
Alignment scores for all networks trained on CIFAR100 and ImageNet are evaluated on their respective test sets. We compute alignment between corresponding layers of networks with the same architecture (Sec.~\nameref{sec: convergence-evolution}) and between all pairs of layers for networks with different architectures (Sec.~\nameref{par: inter-network}). All scores are reported as the mean across $k$-fold cross-validation, with $k = 5$ in our case. This helps prevent overfitting when computing the optimal transformation. 

\section{Results}

\input{./acrosslayers}


\input{./acrosstraining}


\input{./acrossdistribution}



\section{Discussion}
This study fills critical gaps in our understanding of convergent learning, offering a comprehensive analysis of how representational alignment between independently trained networks varies across network depth, training, and distribution shifts. We systematically explored how different alignment metricsâ€”with varying levels of transformation invariance---capture representational similarities, providing a more nuanced view of convergent learning than previous work.

Despite these insights, the study has important limitations. While we show that alignment emerges early during training, we do not quantify precisely when within the first epoch this convergence occurs. Further, different networks may learn at varying rates---so epoch one for one network may not reflect an analogous state for another network. Comparing networks epoch-wise may overlook this difference in learning speeds. Nonetheless, since alignment at the end of the first epoch already matches the alignment seen at convergence, the broader conclusions about early representational alignment remain robust.

Another limitation stems from the alignment metrics themselves. Although our metrics reveal that alignment stabilizes quickly and does not improve significantly over training, this could reflect the limitations of the metrics rather than the absence of representational changes. Prior work~\citep{bo2024evaluating} has demonstrated that certain alignment metrics may fail to capture subtle shifts in representations that are critical for task performance. It remains possible that more sensitive or alternative metrics could reveal gradual representational alignments over training that are invisible to the methods employed here.

Finally, our method for computing alignment focuses on the center pixel of each feature map, enforcing a strict spatial correspondence between representations.  This approach may underestimate alignment, especially in cases where two filters detect the same feature at slightly shifted spatial locations. While more flexible approaches---such as incorporating spatial shifts into alignment computations---could offer a more accurate view, they are computationally intensive and were beyond the scope of this work. However, prior research has shown that optimal spatial shifts in many convolutional layers are typically close to zero~\citep{williams2021generalized}, supporting the validity of this approximation. Developing scalable methods that account for such spatial variability remains an important direction for future research.

\bibliographystyle{ccn_style}
\bibliography{ccn_style}

\appendix
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{figure}{0}  
\setcounter{table}{0}
\newpage
\section{Appendix}

\subsection{Out-Of-Distribution Dataset}
\label{sec: ood-dataset-details}
All OOD datasets were directly taken from~\citep{geirhos2018imagenet}, which share the same $16$ coarse labels as ImageNet. Concretely, this set consists of the following classes: Airplane, Bear, Bicycle, Bird, Boat, Bottle, Car, Cat, Chair, Clock, Dog, Elephant, Keyboard, Knife, Oven, Truck.\\

\noindent
Each of the $17$ stylized datasets are described below:
\begin{itemize}
    \item \textbf{Color:} Half of the images are randomly converted to grayscale, and the rest kept in their original colormap. 
    \item \textbf{Stylized:} Textures from one class are transferred to the shapes of another, ensuring that object shapes remain preserved.
    \item \textbf{Sketch:} Cartoon-style sketches of objects representing each class.  
    \item \textbf{Edges:} Generated from the original ImageNet dataset using the Canny edge detector to produce edge-based representations.
    \item \textbf{Silhouette:} Black objects on a white background generated from the original dataset.
    \item \textbf{Cue Conflict:} Images with textures that conflict with shape categories, generated using iterative style transfer~\citep{gatys2015neural}, where \textbf{Texture} dataset images serve as the style and \textbf{Original} dataset images as the content.
    \item \textbf{Contrast:} Image variants modified to different contrast levels.
    \item \textbf{High-Pass / Low-Pass:} Images processed with Gaussian filters to emphasize either high-frequency or low-frequency components.
    \item \textbf{Phase-Scrambling:} Images with phase noise added to frequency components, introducing varying levels of distortion from $0^\circ$ to $180^\circ$.
    \item \textbf{Power-Equalization:} The images were processed to normalize the power spectra across the dataset by adjusting all amplitude spectra to match the mean value.
    \item \textbf{False-Color:} The colors of the images were inverted to their opponent colors while maintaining constant luminance, using the DKL color space.
    \item \textbf{Rotation:} Rotated images ($0^\circ$, $90^\circ$, $180^\circ$, or $270^\circ$) to test rotational invariance.
    \item \textbf{Eidolon I, II, III:} The images were distorted using the Eidolon toolbox, with variations in the coherence and reach parameters to manipulate both local and global image structures for each intensity level.
    \item \textbf{Uniform Noise:} White uniform noise was added to the images in a varying range to assess robustness, with pixel values exceeding the bounds clipped to the range $[0, 255]$.
\end{itemize}

\subsection{Additional Results}
In this section, we compute Procrustes alignment for the remainder of vision networks at the first convolutional and penultimate layer to assess whether a similar phenomenon holds as described in Sec.~\nameref{sec:ood-results}. Indeed, in Fig.~\ref{fig:ood-convergence-appendix}, we observe a similar trend that was observed earlier, i.e., alignment mirrors task performance at higher network depths. 

\input{./figures-code/ood-imagenet}


\end{document}
