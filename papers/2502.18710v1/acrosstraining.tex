\subsection{Evolution of convergence over training}
We next explore how representational convergence evolves during the training process. Specifically, we compute Procrustes alignment scores between pairs of networks over the first $10$ epochs of training for both CIFAR100 and ImageNet.

% ood amplification
\input{./figures-code/ood-amplification}

As shown in Fig.~\ref{fig:training-evo}, a striking pattern emerges: the majority of representational convergence happens within the first epoch---long before networks approach optimal task performance. This rapid early convergence suggests that factors independent of task optimization drive much of the representational alignment. Shared input statistics, architectural biases, and early training dynamics seem to play a dominant role in shaping the learned representations, overshadowing the influence of the final task-specific solution.

This observation challenges prevailing hypotheses that attribute convergence to constraints imposed by the task, such as the \emph{contravariance principle}~\citep{cao2021explanatory} or the \emph{convergence via task generality} hypothesis~\citep{huh2024platonic}. These theories propose that networks converge because they are steered toward a limited subspace of solutions capable of achieving high task performance. However, the early emergence of representational alignment---well before networks achieve such performance---implies that convergence is not primarily driven by task-related pressures but is instead rooted in the networkâ€™s inductive biases, statistical properties of the input data and early training dynamics.

Interestingly, this result aligns with findings from another study on the early phase of training~\citep{frankle2020early}, which demonstrated that substantial changes in network representations occur within the first few hundred iterations, even before meaningful task learning begins. Their work showed that perturbations to network weights in this early phase---such as re-initialization or weight shuffling---can significantly degrade performance, suggesting that early representations are already highly structured and data-dependent. Moreover, they found that pre-training using only the input distribution \emph{p(x)} (\emph{e.g.,} through self-supervised tasks) could approximate the changes seen in early supervised training, albeit requiring substantially longer pre-training. This also lends credence to the idea that shared input statistics, rather than task-specific labels, play a critical role in early convergence.


For the earliest convolutional layers, we find that training has minimal impact on representational similarity and can even reduce it in some cases. This phenomenon arises because early layers compute a largely linear function of the input, even in untrained networks, allowing them to align well with simple linear transformations. As training progresses, these layers may undergo minor adjustments that slightly disrupt this initial alignment, though they remain highly similar overall. This result highlights that the convergence of early-layer representations is not driven by the specifics of the training process.

\input{./figures-code/pearson-ood}