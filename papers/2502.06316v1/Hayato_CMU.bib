% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}
@article{krestel2021survey,
  title={A survey on deep learning for patent analysis},
  author={Krestel, Ralf and Chikkamath, Renukswamy and Hewel, Christoph and Risch, Julian},
  journal={World Patent Information},
  volume={65},
  pages={102035},
  year={2021},
  publisher={Elsevier}
}
@article{koreeda2021contractnli,
  title={ContractNLI: A dataset for document-level natural language inference for contracts},
  author={Koreeda, Yuta and Manning, Christopher D},
  journal={arXiv preprint arXiv:2110.01799},
  year={2021}
}
@article{lee2019patentbert,
  title={Patentbert: Patent classification with fine-tuning a pre-trained bert model},
  author={Lee, Jieh-Sheng and Hsiang, Jieh},
  journal={arXiv preprint arXiv:1906.02124},
  year={2019}
}
@inproceedings{poliak-etal-2018-hypothesis,
    title = "Hypothesis Only Baselines in Natural Language Inference",
    author = "Poliak, Adam  and
      Naradowsky, Jason  and
      Haldar, Aparajita  and
      Rudinger, Rachel  and
      Van Durme, Benjamin",
    editor = "Nissim, Malvina  and
      Berant, Jonathan  and
      Lenci, Alessandro",
    booktitle = "Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S18-2023",
    doi = "10.18653/v1/S18-2023",
    pages = "180--191",
    abstract = "We propose a hypothesis only baseline for diagnosing Natural Language Inference (NLI). Especially when an NLI dataset assumes inference is occurring based purely on the relationship between a context and a hypothesis, it follows that assessing entailment relations while ignoring the provided context is a degenerate solution. Yet, through experiments on 10 distinct NLI datasets, we find that this approach, which we refer to as a hypothesis-only model, is able to significantly outperform a majority-class baseline across a number of NLI datasets. Our analysis suggests that statistical irregularities may allow a model to perform NLI in some datasets beyond what should be achievable without access to the context.",
}
@inproceedings{kaushik-lipton-2018-much,
    title = "How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks",
    author = "Kaushik, Divyansh  and
      Lipton, Zachary C.",
    editor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1546",
    doi = "10.18653/v1/D18-1546",
    pages = "5010--5015",
    abstract = "Many recent papers address reading comprehension, where examples consist of (question, passage, answer) tuples. Presumably, a model must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50{\%} accuracy, sometimes matching the full model. Interestingly, while CBT provides 20-sentence passages, only the last is needed for accurate prediction. By comparison, SQuAD and CNN appear better-constructed.",
}
@misc{googleGPPD,
  title="Google Patents Public Datasets",
  author = "Google",
  note = "\url{https://console.cloud.google.com/marketplace/product/google_patents_public_datasets/google-patents-public-data}, Retrieved [Jun. 17, 2024]",
}
@article{suzgun2024harvard,
  title={The harvard uspto patent dataset: A large-scale, well-structured, and multi-purpose corpus of patent applications},
  author={Suzgun, Mirac and Melas-Kyriazi, Luke and Sarkar, Suproteem and Kominers, Scott D and Shieber, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{gao2022towards,
  title={Towards comprehensive patent approval predictions: Beyond traditional document classification},
  author={Gao, Xiaochen and Hou, Zhaoyi and Ning, Yifei and Zhao, Kewen and He, Beilei and Shang, Jingbo and Krishnan, Vish},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2022}
}
@article{Beltagy2020Longformer,
  title={Longformer: The Long-Document Transformer},
  author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
  journal={arXiv:2004.05150},
  year={2020},
}
@misc{MetaLlama3,
  title="Introducing Meta Llama 3: The most capable openly available LLM to date.",
  year="2024",
  author = "Meta",
  note = "\url{https://ai.meta.com/blog/meta-llama-3/}, Retrieved [Jun. 17, 2024]",
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@misc{openAIGPT4o,
  title="Hello GPT-4o",
  year="2024",
  author = "openAI",
  note = "\url{https://openai.com/index/hello-gpt-4o/}",
}
@article{dettmers2024qlora,
  title={Qlora: Efficient finetuning of quantized llms},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@misc{hgllama2,
  title="Llama2",
  author = "HuggingFace",
  note = "\url{https://huggingface.co/docs/transformers/main/en/model_doc/llama2}, Retrieved [Jun. 17, 2024]",
}
@article{huang2023can,
  title={Can large language models explain themselves? a study of llm-generated self-explanations},
  author={Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H},
  journal={arXiv preprint arXiv:2310.11207},
  year={2023}
}
@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}
@article{lampinen2022can,
  title={Can language models learn from explanations in context?},
  author={Lampinen, Andrew K and Dasgupta, Ishita and Chan, Stephanie CY and Matthewson, Kory and Tessler, Michael Henry and Creswell, Antonia and McClelland, James L and Wang, Jane X and Hill, Felix},
  journal={arXiv preprint arXiv:2204.02329},
  year={2022}
}
@article{li2023label,
  title={Label supervised llama finetuning},
  author={Li, Zongxi and Li, Xianming and Liu, Yuzhang and Xie, Haoran and Li, Jing and Wang, Fu-lee and Li, Qing and Zhong, Xiaoqin},
  journal={arXiv preprint arXiv:2310.01208},
  year={2023}
}
@article{risch2020patentmatch,
  title={Patentmatch: a dataset for matching patent claims \& prior art},
  author={Risch, Julian and Alder, Nicolas and Hewel, Christoph and Krestel, Ralf},
  journal={arXiv preprint arXiv:2012.13919},
  year={2020}
}
@article{schmitt2023assessment,
  title={Assessment of patentability by means of semantic patent analysis--A mathematical-logical approach},
  author={Schmitt, Valentin J and Walter, Lothar and Schnittker, Frank C},
  journal={World Patent Information},
  volume={73},
  pages={102182},
  year={2023},
  publisher={Elsevier}
}
@inproceedings{hashimoto2023hunt,
  title={Hunt for Buried Treasures: Extracting Unclaimed Embodiments from Patent Specifications},
  author={Hashimoto, Chikara and Kumar, Gautam and Hashimoto, Shuichiro and Suzuki, Jun},
  booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)},
  pages={25--36},
  year={2023}
}
@manual{mpepe131,
    author = {USPTO},
    title = {Manual of PATENT EXAMINING PROCEDURE},
    chapter = {2131},
    edition = {Ninth},
    organization = {USPTO},
    year = {2014},
    note = {The latest revise in Feb. 2023}
}
@misc{OECD_stat,
  title="OECD stat",
  author = "OECD",
  note = "\url{https://stats.oecd.org/index.aspx?queryid=22014#},Retrieved [Jun. 27, 2024]",
}}