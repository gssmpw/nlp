

\begin{table*}[ht!] \small
    \centering
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Model} & \textbf{Size} & \textbf{Call Accuracy} & \textbf{Execution Accuracy} & \textbf{Speed Up} \\ 
        \midrule
        \multicolumn{5}{c}{\textit{Domain-Specific Models}} \\
        Qwen2.5-Coder           & $7$B        & $0.00$~/~$0.00$                     & $0.00$~/~$0.00$                       & $0.00$~/~$0.00$     \\
        DeepSeek-Coder          & $6.7$B      & $0.00$~/~$1.81$                     & $0.00$~/~$1.81$                       & $0.00$~/~$\mathbf{0.94}$     \\
        Qwen2.5-Coder-sft      & $7$B        & $17.47$~/~$16.27$                    & $17.47$~/~$15.67$                     & $\mathbf{0.98}$~/~$0.92$     \\
        DeepSeek-Coder-sft     & $6.7$B      & $\mathbf{19.28}$~/~$\mathbf{18.67}$  & $\mathbf{19.28}$~/~$\mathbf{16.26}$   & $0.91$~/~$0.85$     \\

        \midrule
        \multicolumn{5}{c}{\textit{General-Purpose Models}} \\
        % \midrule

        GPT-4o                      & -      &$36.75$~/~$32.53$                     &$36.75$~/~$32.53$                      & $0.98$~/~$0.94$     \\
        Claude-3.5-Sonnet           & -      &$29.52$~/~$37.95$                     &$29.52$~/~$33.70$                      & $0.93$~/~$0.89$     \\
        Qwen2.5-72B                 & 72B    &$30.12$~/~$22.89$                     &$30.12$~/~$16.30$                      & $1.07$~/~$0.92$     \\
        DeepSeek-R1                 &$685$B  &$\mathbf{53.01}$~/~$\mathbf{45.78}$   &$\mathbf{53.01}$~/~$\mathbf{45.78}$    & $1.03$~/~$\mathbf{1.91}$     \\
        GPT-o1                      & -      &$32.53$~/~$43.37$                     &$32.53$~/~$43.37$                      & $\mathbf{1.21}$~/~$1.10$     \\

        \bottomrule
    \end{tabular}
    % }
    \caption{Main results of \benchtwo across baseline models, where the left side of ``/'' represents the zero-shot results and the right side represents the one-shot results.}
    \label{tab:torch_res}
\end{table*}

