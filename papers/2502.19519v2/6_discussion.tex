\section{Discussion} \label{sec:discussion}



% Surprises
% Cool that v2 is dominant
% Some players preferred the yap of v1
% We as devs did not expect players to be very good at telling the DMs apart, but they were very different to the players

The rise and potential of LLM-based agents is recognized~\cite{xi2025rise} and can take different roles within the field of gaming, from being the player~\cite{tsai2023largelanguagemodelsplay}, assisting human players~\cite{Rist_2024}, acting as NPCs~\cite{xu2024llms} or commentators~\cite{ranella2023towards}, to being a game analyst~\cite{Ra2024} or, as in our case, being the game master. Arguably, the game master role is the most complex and challenging, requiring a variety of agent tools and agent flexibility. In this paper, we presented our research journey and insights gained throughout realizing and evaluating ChatRPG to better facilitate solo role-playing experiences.

Our comparative analysis of ChatRPG v1 and v2 reveals that v2 significantly outperforms its predecessor in both qualitative and quantitative metrics. Participants consistently highlighted v2’s enhanced responsiveness, adaptability, and narrative coherence, which resulted in more meaningful interactions and a gameplay experience more akin to that of a human game master. The system's ability to generate dynamic quests and interpret player intentions contributed to deeper immersion and a heightened sense of agency. However, a subset of participants—particularly those favoring less interactive engagement—expressed a preference for v1, appreciating its detailed environmental descriptions and a narrative style that supported passive consumption of content. Contrary to our initial expectations that users might struggle to differentiate between the two versions, participants immediately noted distinct improvements in v2’s response quality and quest delivery.

We now reflect on the technology choices and implications for the continued research on conversational user interfaces for facilitating role-playing game experiences. We discuss the ReAct pattern and highlight the implications for refinement of the agent design and limitations of the LLM API. We then discuss the limitations of the study and sketch out important future work. 


% Implications of design
% Prompt engineering
% Tool descriptions (especially with complex tools)
\subsection{ReAct Pattern Design Discoveries}
The ReAct framework requires an extensive system prompt in addition to descriptions of available tools to function successfully. In this project, we employed the ReAct framework to simulate a human GM. The primary challenge lies in the sensitivity of prompts and tool descriptions, where even the wording of a specific example in a prompt can significantly alter the system's functionality. Ensuring humanlike behavior required the development of complex prompts that emulate the capabilities of a real GM during gameplay.

A key example is the Battle tool utilized by the Narrator agent to resolve combat between characters. In the game, a battle may involve multiple participants simultaneously, requiring the Narrator agent to employ the Battle tool repeatedly with different characters. While this is straightforward for a human GM, it poses a significant challenge for an AI GM. It is crucial to use the Battle tool an appropriate number of times---neither too few nor too many. In this and similar scenarios, we found that incorporating few-shot prompting in both prompts and tool descriptions assisted in maintaining consistency and ensuring appropriate tool usage. This point is also echoed in \citep{verma_brittle_2024}, which analyses ReAct prompting for agentic LLMs and concludes that the benefits attributed to ReAct prompting are not primarily due to its interleaving of reasoning with actions or the content of the generated reasoning trace. Instead, the key advantage comes from using few-shot prompting.
Despite this, ReAct's interleaved structure was instrumental in our system development. The clear separation of reasoning and action allowed us to trace intermediate decisions and rapidly identify issues during debugging. This modular design enabled us to iteratively refine our prompts. Ultimately, while few-shot prompting may have been the primary performance driver, the interleaved reasoning provided a crucial scaffold for building a robust system.

Another key finding is the benefit of utilizing multiple agents within the system. Initially, our design employed a single agent that combined the functionalities of the Narrator and Archivist agents. This approach proved inefficient, as the agent needed to complete game state updates before generating a narrative response, resulting in slower response times.

Additionally, the single-agent model placed excessive responsibility on one entity, which could be better distributed among multiple agents.
Recognizing that generating narrative responses and updating the game state are largely independent tasks, we decided to divide the logic into two specialized agents. This decision aligned with our design philosophy of mimicking the behavior of a human GM. In human gameplay, the narrative interaction—where character actions lead to outcomes—is typically distinct from the administrative task of recording those outcomes for future reference.

In the current version of the game, we do not see room for further splitting the logic into additional agents, as the existing tasks are mapped directly to the responsibilities of the Narrator and Archivist agents. This design ensures that the system can be extended by integrating new tools without requiring changes to the agent structure. However, as discussed in Section~\ref{subsec:future_work}, future extensions of the system may warrant introducing new agents to manage additional responsibilities, such as implementing multimedia content. For instance, an agent could be developed to control the game’s ambiance if audio features were added. This agent could analyze the tone of the narrative to adjust ambient background music or trigger sound effects, such as clashing swords. Such an agent would logically reside between the Narrator and Archivist, as it would benefit from the persistent storage of ambiance-related information.

State-of-the-art models like DeepSeek leverage Mixture of Experts (MoE)~\citep{fedus_switch_2022} architectures, which dynamically activate specialized sub-models to process different inputs, optimizing computational efficiency while maintaining high performance~\citep{alford_deepseek_2025,deepseek-ai_deepseek-v2_2024, dai_deepseekmoe_2024}. This approach allows for selective utilization of model parameters, reducing resource consumption without compromising on output quality. Incorporating ReAct frameworks with such MoE-based models could further enhance system performance by strategically interleaving reasoning and actions across specialized experts. This combination might allow for more efficient tool usage and complex decision-making, particularly in multi-agent systems where distinct roles can be mapped to specific experts within the model.

Beyond leveraging MoE architectures, fine-tuning models on domain-specific data presents another viable approach for enhancing AI-driven game mastering. For instance, fine-tuning on transcripts from RPG sessions, such as Critical Role~\citep{rameshkumar_storytelling_2020}, could enable models to better capture narrative flow, character interactions, and improvisational storytelling styles~\citep{sakellaridis_exploring_2024}. Additionally, models fine-tuned specifically for the ReAct framework could internalize the reasoning-action structure, reducing prompt sensitivity and improving tool usage consistency in agentic systems~\citep{jadhav_finetuning_2024,parthasarathy_ultimate_2024}. Combining these strategies—whether through MoE, targeted fine-tuning, or both—could lead to more robust and immersive AI Dungeon Masters.


\subsection{Limitations due to Restrictive API}
Content filtering in LLMs can pose challenges when generating creative content in genres like fantasy, where themes such as battles or fictional conflicts are prevalent. Overzealous moderation may inadvertently censor benign content, limiting artistic expression. For instance, researchers have identified that content moderation systems can be so restrictive that even some PG-rated scripts are censored, potentially limiting artistic expression~\citep{scheffler_censored_2024}.

Similarly, platforms like AI Dungeon have experienced issues where content filters, designed to prevent harmful outputs, inadvertently restricted common fantasy elements, impacting the user experience~\citep{ai_dungeon_openai_nodate}.

During the user tests, the OpenAI API's content filters significantly impacted some players' experience, particularly in combat scenarios, as they often involved intense or violent descriptions. While there will soon be relaxed policies and support for more `intellectual freedom' when using the API~\footnote{\url{https://openai.com/index/sharing-the-latest-model-spec/}}, the current filters inadvertently restrict the player's actions or responses, leading to interruptions in the gameplay flow and a diminished sense of agency. This limitation can create frustration, as players are unable to explore all possible actions within the game's logic and context. To address this issue, a private, self-hosted LLM without a restrictive content filter could be utilized, allowing for greater creative freedom while ensuring the narrative remains consistent and engaging. This approach would enable developers to implement customized safeguards tailored to the game's themes and audience, maintaining ethical content boundaries without sacrificing the richness of player interactions.

Balancing the need for content safety with the preservation of creative freedom remains a complex issue in the deployment of LLMs for imaginative applications.

\subsection{Comparative Study Limitations}
The t-tests conducted in this study were useful for assessing differences across the various constructs. Still, their effectiveness may have been limited by the relatively low sample size of 12 participants. With such a small sample, the statistical power to detect significant effects is reduced, increasing the likelihood of Type II errors—failing to detect true differences when they exist. While 9 out of the 14 total constructs were deemed statistically significant, which is a promising outcome, the relatively small sample size may have constrained the ability to detect additional significant effects. Interestingly, the p-values for most of the constructs that were not deemed statistically significant were around 0.10, suggesting that these differences could potentially become significant with a larger sample.

Therefore, while the findings provide valuable insights, the limited power of the t-tests calls for caution in generalizing the results. Future research with a larger sample size would offer more robust conclusions and improve the reliability of the statistical analyses.


% Forced choice
During the qualitative data gathering, the interview questions asked participants to select a version of the game they preferred across different dimensions and aspects, but some participants deemed both versions to be equivalent in regard to the given dimension, resulting in a tie. While allowing ties offered flexibility and captured nuanced preferences, it can introduce complexity in interpreting the data. Tied responses may reflect genuine ambivalence or equal preference, but they could also arise from a lack of clarity in the options or difficulty in making a definitive choice. This ambiguity complicates the analysis, as ties do not lend themselves easily to statistical comparisons and may dilute the strength of observed patterns. Furthermore, allowing ties may have inadvertently reduced the pressure on participants to make a distinct choice, potentially obscuring subtle differences in preferences. On the other hand, a forced-choice approach may cause participants to answer randomly if they genuinely do not have a preference. 

Future research could address this issue by refining the question design, such as by encouraging participants to prioritize one option when possible or using follow-up questions to explore the reasons behind tied responses.

\subsection{Future Work} \label{subsec:future_work}

%Narrative adherence

Future work will focus on four key areas: enhancing narrative adherence, integrating user accessibility features, incorporating affective computing, and enriching multimedia content. To ensure coherent plot development and prevent the LLM from uncritically accepting user inputs, we plan to develop a dedicated narrative adherence tool that enforces pivotal events. Additionally, implementing speech-to-text and text-to-speech functionalities will address accessibility concerns, enabling smoother interactions and differentiated character voices. We also aim to integrate affect analysis---using tools such as the AffectToolbox~\citep{mertes_affecttoolbox_2024}---to dynamically tailor narrative developments based on players' emotional cues. Finally, by developing AI-driven image and music generation tools within the ReAct framework, we seek to augment the text-based narrative with adaptive visual and auditory elements, thereby deepening player engagement.




