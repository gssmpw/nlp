
\section{Background} \label{sec:bacground}


Interactive Fiction (IF), including Choose Your Own Adventure (CYOA) games, originated as a genre of non-digital entertainment. The concept of exploratory, decision-based storytelling can be traced back to the Song dynasty~\citep{yidong_compilation_1127}, where classical Chinese divination manuals were used to guide individuals in decision-making, particularly in religious contexts~\citep{adler_introduction_2004}. These techniques were initially reserved for ritualistic practices and remained so for centuries. However, in the twentieth century, the IF genre was formalized through gamebooks~\citep{katz_consider_1998,dickens_great_1861,lodge_chooseco_2007}, where readers would navigate the narrative by making choices that directed them to specific sections of the text. With the advent of digital technologies, IF evolved, with early digital games like \textit{Zork}~\citep{blank_zork_1984,mobygames_zork_2024} on the PDP-10 and more contemporary media, such as Black Mirror: Bandersnatch~\citep{rubin_how_2018}, reinvigorating the genre and contributing to its mainstream popularity.

Dungeons \& Dragons (D\&D) is a tabletop role-playing game (TTRPG) that enables collaborative storytelling, where players assume the roles of fictional characters in a shared narrative. Central to the game is the Dungeon Master (DM), a Game Master (GM) who serves as both the storyteller and referee. The DM crafts the world, controls non-player characters (NPCs), and presents the challenges that players face while the players, as a group, navigate this environment through their characters' actions and decisions~\citep{hanju_kim_introduction_2008}. This dynamic interaction allows for highly flexible, emergent narratives that can diverge significantly based on player choices. However, the requirement of a DM and a group of players to drive the story limits the game's accessibility for solo play.
With the advancement of generative AI, the role of the DM can now be simulated, allowing D\&D-style gameplay to be experienced by a single player. By leveraging AI-driven systems that generate content dynamically, such as branching storylines and responsive NPC behavior, players can engage in narrative experiences similar to CYOA games but with vastly enhanced capabilities. Unlike traditional CYOA games like \textit{Zork}, where narrative branches are predetermined, AI can generate endless replayability with unbounded story branching, adapting in real-time to player choices. This development mirrors the flexibility and depth of traditional D\&D, making it possible to offer a personalized, interactive narrative without the need for human participants.




%% Outline:
%% Interactive fiction - From books and "hardcoded paths" to dynamic story branching
%% D&D and the absence of hardcoded paths: CALYPSO - D&D DM tool for interactive fiction
%% ChatRPG - Previous work and its shortcomings


%IA: We may want to look into and reference this survey paper: https://arxiv.org/pdf/2402.18659 "Large Language Models and Games: A Survey and Roadmap"   from December 2024
% section 3.6 is about game masters and LLM


A common characteristic of IF titles is that, although narrative branches diverge based on user-driven decision-making, the possible story paths are predetermined. This approach stems from the constraints of early media, such as books, where fixed narratives were necessary, and even in more recent cinematic adaptations, the plot must be pre-scripted to accommodate filming requirements. However, with the advent of computers, it has become feasible to dynamically alter story paths based on various factors, such as randomness, game states determined by prior player actions, or the possession of specific items required to unlock certain narrative branches.
Several tools have emerged to facilitate the creation of text-based IF on computers. For instance, Adrift~\citep{campbell_wild_adrift_2013} provides a graphical user interface (GUI) to assist creators in designing complex story worlds, allowing them to define objects and rooms with unique properties. Similarly, Twine~\citep{interactive_fiction_technology_foundation_twine_2024} offers a fully graphical interface for crafting text-based narratives, where small written passages are represented as boxes on a canvas, resembling a flowchart. The user can implement multiple-choice mechanics by linking these boxes together, offering decisions such as [[Touch the cursed mirror]] or [[Back away carefully]]. More mature tools, such as Inform~\citep{nelson_inform_2022}, use a natural language approach to allow creators to script stories, which are then compiled into text-based adventure games. This approach is distinct from traditional programming; for example, a passage might be written as: \textit{'The old metal tin is hidden in the basement. The tin is a container. It contains an old pirate map and a sextant.'}
Other tools, such as Ink~\citep{inkle_ltd_ink_2024}, require actual programming, though they also offer a GUI through their inklewriter software~\citep{inkle_ltd_inklewriter_2024}. Developers of popular titles like The Banner Saga have disclosed that their games were initially prototyped using inklewriter before transferring the story content to their proprietary visual novel engine once the narrative had been fully developed~\citep{stoic_update_2018}.

The role of a GM in TTRPGs is multifaceted, involving world-building, guiding players through a dynamic narrative, and resolving in-game events. While digital games often rely on pre-scripted narratives, TTRPGs demand improvisational storytelling, making the potential of LLMs as GMs an intriguing area of study~\citep{gallotta2024large}. One of the earliest explorations of AI-driven GM experiences was AI Dungeon, which employed a fine-tuned GPT-2 model to generate interactive text-based adventures~\citep{gallotta2024large}. However, AI Dungeon was a pure text-based conversational user interface (CUI) with no world state tracking or other mechanics, such as structured combat or health tracking. Since then, research has expanded to explore LLMs' capacity to generate encounters, moderate in-game interactions, and assist GMs in real-time. More broadly, LLMs in games can serve a variety of roles beyond just the GM. They have been explored as autonomous players, capable of making strategic decisions in both turn-based and text-based games, and as NPCs that can engage in dynamic, contextually relevant dialogue~\citep{gallotta2024large}. NPCs powered by LLMs hold particular promise in role-playing games, as they can react to player actions with unscripted, emergent behavior, adding depth to world-building and player immersion.

Rather than replacing human GMs, recent efforts have focused on augmenting their capabilities through AI-powered tools. CALYPSO~\citep{zhu_calypso_2023} is one such example, designed as a Discord-based assistant that helps GMs with encounter generation and narrative brainstorming. By processing monster stat blocks, CALYPSO can provide concise and engaging descriptions, reducing the improvisational burden on GMs. Additionally, its interactive brainstorming capabilities enable dynamic expansion of in-game details in response to player actions. However, like many LLM-powered tools, CALYPSO also exhibits challenges, such as occasional hallucinations, which can generate both creative and erroneous details. The broader potential of LLMs in games, as highlighted in \citep{gallotta2024large}, suggests that similar AI-driven tools could extend beyond encounter descriptions by dynamically controlling NPCs or generating responsive narrative elements in real-time.

Integrating generative AI tools into the GM role offers significant potential to streamline game preparation and enhance real-time gameplay. By leveraging models such as those used in CALYPSO, AI-driven assistants can empower GMs to focus on storytelling and player engagement rather than administrative tasks. The development of LLM-powered GM tools thus represents a promising direction for enhancing the TTRPG experience while maintaining the creative agency of human GMs.

However, \citep{gallotta2024large} highlights several challenges in replacing human GMs with LLMs. One major limitation is their difficulty in accurately capturing user intent, particularly when dealing with sarcasm or ambiguous phrasing. This can lead to misunderstandings, often requiring players to rephrase their input multiple times to clarify their intent. Another issue is the over-compliance of LLMs, which, in the role of a GM, may result in the game veering drastically from the intended narrative, potentially causing irreparable disruptions. Additionally, an effective LLM GM requires a comprehensive understanding of the game world, which must be provided through prompt engineering. For complex and long-running campaigns, this information can exceed the LLMâ€™s context window, leading to the loss of earlier details due to the necessity of summarization. These limitations underscore the importance of a well-designed AI GM system, ensuring that generative AI enhances, rather than undermines, the tabletop role-playing experience.



To the best of our knowledge, \citet{roy_exploring_2024} conducted the first empirical study on the application of the ReAct framework in leveraging LLMs for root-cause analysis during cloud incident management. Their research explored the capabilities of ReAct in an out-of-domain, zero-shot setting, comparing its performance against strong baselines such as retrieval-augmented generation and Chain of Thought reasoning. The results demonstrated that ReAct performed competitively, with the additional advantage of significantly reducing factual inaccuracies. Furthermore, the study's case analysis underscored the potential of LLM agents to autonomously execute root-cause analysis in real-world scenarios when integrated with the appropriate tools. 




\subsection{Technical Preliminaries}

%This section covers the fundamentals of LLMs and how they can be used to construct complex applications.


\subsubsection{Large Language Models}
A Language Model (LM) is a machine learning model utilized in Natural Language Processing (NLP) to replicate natural language. When given a query, these LMs will predict a sequence of words based on the input's context. The user's query is often accompanied by a prompt written in natural language instructing the LM to answer the query appropriately. LLMs refer to LMs containing hundreds or billions of parameters trained on massive textual data. Therefore, LLMs have some abilities not present in smaller models such as \textit{in-context learning} and \textit{instruction following}. The former refers to how LLMs can generate the expected output to a query without additional training, assuming that a natural language instruction and/or several examples are provided. The latter refers to how LLMs are shown through fine-tuning to be able to follow task instructions for unseen tasks without using explicit examples of how similar tasks should be solved, thus having an improved generalization ability. Overall, LLMs are general and capable learners that can accurately replicate natural language and solve a variety of tasks. However, as they are trained as text generators over massive plain text corpora, their performance on tasks not best expressed in the form of text (e.g., numerical computation) can be lacking. Furthermore, their knowledge is also limited to the pre-training data that they are exposed to, making them unable to capture up-to-date information~\citep{zhao_survey_2023}.

Prompt engineering is designing input prompts to guide LLMs in generating accurate and relevant outputs. By carefully structuring the prompt, users can influence the model's behavior and improve task performance. Three common prompting strategies are zero-shot, one-shot, and few-shot prompting. Zero-shot prompting involves giving the model a task instruction without any examples, leveraging its generalization capabilities to produce the desired output. One-shot prompting includes a single example to illustrate the task, which can help the model better understand the context. Few-shot prompting provides several examples to guide the model's output by demonstrating patterns or formats relevant to the task. These strategies utilize LLMs' in-context learning abilities to perform tasks without requiring additional training, enhancing adaptability and effectiveness across diverse applications~\citep{brown_language_2020,touvron_llama_2023,dairai_few-shot_2025}.

\subsubsection{LangChain}
LangChain is a framework designed to develop applications utilizing LLMs. It facilitates the integration of various components, such as data retrieval and computation units, into LLMs, enabling developers to conveniently build more complex LMM-based applications that avoid the deficiencies of LLMs mentioned earlier. In LangChain these components are called tools.
One of the key features of LangChain that enable this is \textit{chains}. A chain usually combines an LLM with a prompt, but tools can also be used. These chains can be linked together, causing the output of one chain to be used as the input to the following chain. This allows for a complex application structure wherein a chain is linked to multiple other chains. Here, the LLM or tool within the chain would be responsible for determining which of its links should be invoked~\citep{topsakal_creating_2023}. This capability for complex structure allows for the implementation of various LLM prompting methods, such as ReAct, which the following section will describe. 




\begin{figure}[h!]
    \centering
    \begin{tcolorbox}[colframe=black!35!white, colback=black!5!white, coltitle=black, title=\textbf{ReAct Trajectory Example}, halign title=flush center, width=0.49\textwidth]
        \textbf{Question:} How fast is the third fastest sea animal in km/h? \\
        
        \textbf{Thought:} To answer this question, I first need to identify the fastest sea animals and their speeds. \\
        \textbf{Action:} \texttt{Search}["fastest sea animals"] \\
        \textbf{Observation:} \begin{itemize}
            \item Black Marlin: $\sim$82 mph
            \item Sailfish: $\sim$68 mph
            \item Swordfish: $\sim$60 mph
            \item Yellowfin Tuna: $\sim$50 mph
        \end{itemize}
    
        \textbf{Thought:} Now that I have the speed in mph, I need to convert it to km/h. The third fastest sea animal appears to be the swordfish, which has a speed of 60 mph. \\
        \textbf{Action:} \texttt{Convert}[60 mph to km/h] \\
        \textbf{Observation:} 60 mph is approximately 96.56 km/h. \\
    
        \textbf{Thought:} The third fastest sea animal is the swordfish, and after converting its speed from mph to km/h, it can swim at approximately 96.56 km/h. \\
        \textbf{Final Answer:} The third fastest sea animal is the swordfish, and it swims at approximately 96.56 km/h.
    \end{tcolorbox}
    \caption{An example of a ReAct reasoning trajectory.}
    \Description{A textual representation of a ReAct trajectory demonstrating the thought-action-observation steps upon receiving a question.}
    \label{fig:react_example}
\end{figure}


\subsubsection{ReAct}
ReAct, as described in ~\citep{yao_react_2022}, is a general paradigm that utilizes LLMs to solve diverse language reasoning and decision-making tasks. To accomplish this, ReAct combines two concepts used when interacting with language models: Reasoning and acting. 

%ReAct combines these two concepts 
React achieves this by prompting LLMs to generate both verbal reasoning traces and actions pertaining to a task in an interleaved manner, enabling the model to perform dynamic reasoning to create and adjust high-level plans for acting while also interacting with the external environments to incorporate additional information into reasoning~\citep{yao_react_2022}. Due to these capabilities, LLMs prompted following the ReAct pattern can be classified as Augmented Language Models (ALMs), also known as LLM agents~\citep{roy_exploring_2024}. 

Reasoning and complex decision-making are accomplished by generating a sequence of Thought-Action-Observation steps that end when the language model deems it has reached its final answer. The Thought substep contains the LLM's reasoning based on the current context, such as the key takeaway from the previous step's Observation substep and what information it needs to find to get the final answer. The Action substep describes which action should be performed based on the aforementioned reasoning in the Thought substep. Lastly, the Observation substep contains the result of the action. A sequence of Thought-Action-Observation steps is called a trajectory. Actions are often also referred to as tools. When prompting an LLM using ReAct, it can be beneficial to include some in-context manually generated trajectory examples~\citep{yao_react_2022}.

Figure \ref{fig:react_example} contains a manually generated example of a ReAct trajectory, wherein the LLM is asked a question. First, the LLM reasons that it needs to gather information and therefore invokes the \textit{Search} action. In this example, the \textit{Search} action can take as input a query and search the internet for an answer. After collecting the required information, the LLM reasons that the data needs to be converted into the correct measurement unit and, therefore, uses the \textit{Convert} action, which can convert a value to different measurement units. Lastly, as the LLM deems it has reached the final answer, it uses the \textit{Final Answer} tag to indicate this. 

