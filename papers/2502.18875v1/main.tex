
\documentclass[pdflatex,sn-mathphys-num]{sn-jnl}


\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
\usepackage{changes}
\setaddedmarkup{\textcolor{black}{#1}}
\setdeletedmarkup{\textcolor{black}{\sout{#1}}}
\usepackage{xspace}
\usepackage{geometry}
\geometry{top=2cm, bottom=2cm, left=3cm, right=3cm}



\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
\newtheorem{proposition}[theorem]{Proposition}%

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom


\def\modelName{DeepTernary}
\input{math_commands.tex}


\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}
\makeatother

\providecommand{\added}[1]{#1}
\providecommand{\deleted}[1]{}
\providecommand{\replaced}[2]{#1}

\begin{document}

\title[Article Title]{SE(3)-Equivariant Ternary Complex Prediction Towards Target Protein Degradation}


\author[1]{\fnm{Fanglei} \sur{Xue}}\email{faxue@uw.edu}
\author[2]{\fnm{Meihan} \sur{Zhang}}\email{zmh1023@126.com}
\author[3]{\fnm{Shuqi} \sur{Li}}\email{shuqili@ruc.edu.cn}
\author[4]{\fnm{Xinyu} \sur{Gao}}\email{gzgaoxinyu@163.com}
\author[6]{\fnm{James A.} \sur{Wohlschlegel}}\email{jwohl@mednet.ucla.edu}
\author*[3]{\fnm{Wenbing} \sur{Huang}}\email{hwenbing@ruc.edu.cn}
\author*[5]{\fnm{Yi} \sur{Yang}}\email{yangyics@zju.edu.cn}
\author*[6]{\fnm{Weixian} \sur{Deng}}\email{weixiandeng@ucla.edu}

\affil[1]{\orgdiv{ReLER Lab, AAII}, \orgname{University of Technology Sydney}, \orgaddress{\city{Sydney}, \state{NSW}, \postcode{2007}, \country{Australia}}}
\affil[2]{\orgdiv{College of Life Sciences}, \orgname{Nankai University}, \orgaddress{\city{Tianjin}, \country{China}}}
\affil[3]{\orgdiv{Gaoling School of Artificial Intelligence}, \orgname{Renmin University of China}, \orgaddress{\city{Beijing}, \country{China}}}
\affil[4]{\orgname{University of Chinese Academy of Sciences}, \orgaddress{\city{Beijing}, \country{China}}}
\affil[5]{\orgdiv{ReLER Lab, CCAI}, \orgname{Zhejiang University}, \orgaddress{\city{Hangzhou}, \country{China}}}
\affil[6]{\orgdiv{Department of Biological Chemistry at David Geffen School of Medicine}, \orgname{University of California, Los Angeles}, \orgaddress{\city{Los Angeles}, \state{CA}, \postcode{90095}, \country{U.S.A.}}}





\abstract{
Targeted protein degradation (TPD) induced by small molecules has emerged as a rapidly evolving modality in drug discovery, targeting proteins traditionally considered "undruggable." This strategy induces the degradation of target proteins rather than inhibiting their activity, achieving desirable therapeutic outcomes. Proteolysis-targeting chimeras (PROTACs) and molecular glue degraders (MGDs) are the primary small molecules that induce TPD. Both types of molecules form a ternary complex linking an E3 ubiquitin ligase with a target protein, a crucial step for drug discovery. While significant advances have been made in in-silico binary structure prediction for proteins and small molecules, ternary structure prediction remains challenging due to obscure interaction mechanisms and insufficient training data. Traditional methods relying on manually assigned rules perform poorly and are computationally demanding due to extensive random sampling. In this work, we introduce DeepTernary, a novel deep learning-based approach that directly predicts ternary structures in an end-to-end manner using an encoder-decoder architecture. DeepTernary leverages an SE(3)-equivariant graph neural network (GNN) with both intra-graph and ternary inter-graph attention mechanisms to capture intricate ternary interactions from our collected high-quality training dataset, TernaryDB. The proposed query-based Pocket Points Decoder extracts the 3D structure of the final binding ternary complex from learned ternary embeddings, demonstrating state-of-the-art accuracy and speed in existing PROTAC benchmarks without prior knowledge from known PROTACs. It also achieves notable accuracy on the more challenging MGD benchmark under the blind docking protocol. Remarkably, our experiments reveal that the buried surface area calculated from DeepTernary-predicted structures correlates with experimentally obtained degradation potency-related metrics. Consequently, DeepTernary shows potential in effectively assisting and accelerating the development of TPDs for previously undruggable targets.}






\maketitle


\section{Introduction}

\begin{figure}
\centering
\includegraphics[width=\linewidth]{imgs/introduction.pdf}
\caption{
\textbf{\modelName{} is a deep learning model for predicting the structure of the ternary complex induced by PROTACs and MG(D)s.}
\textbf{a,} The MOA of PROTACs and MGDs. The protein of interest (POI) and the E3 ligase are recruited to proximity by PROTACs or MGDs to form a ternary complex, which then the Ubiquitin-Proteasome System (UPS) is employed to transfer the ubiquitin and degrade the POI.
\textbf{b,} To mitigate the scarcity of known PROTACs and MG(D)s structures, a large-scale ternary complex dataset (named TernaryDB) was collected by searching and cleaning complexes from the Protein Data Bank (PDB) archive. The collected samples were then grouped into clusters by similarity. Any complex that is similar to known PROTAC and MG(D) induced complexes was excluded from the training set. \modelName{} was trained on this filtered database by predicting the original complex structure using dissembled monomers.
\textbf{c,} \modelName{} is an SE(3)-equivalent graph neural network equipped with attention blocks to facilitate efficient information exchange. It begins by representing two proteins and a small molecule as three graphs, encoding node coordinates, diverse amino acid or atom characteristics as node features, edge types and distances as edge features. The three graphs are fed into an encoder consisting of a series of SE(3)-equivariant blocks, enabling both intra- and inter-graph learning to capture interactions effectively. The encoder will predict the conformation of the small molecule and output the refined node features/coordinates of the two proteins. Subsequently, a decoder comprising several attention-based blocks employs these refined features/coordinates to generate \added{two pairs of pocket points} and a predicted aligned error (PAE). The pocket points are then used to align the small molecule and protein 2 to protein 1. * For PROTAC, the pocket points are taken from unbound structures, \added{don't need to predict}. ** For MG(D), the ligand and protein 2 are simultaneously aligned to protein 1.
}
\label{fig:overall}
\end{figure}


Targeted protein degradation (TPD) is a rapidly evolving field in drug discovery, representing a promising therapeutic approach to degrade target proteins via harnessing the ubiquitin-proteasome system and autophagy-lysosome system~\cite{sakamoto2001protacs,buckley2012targeting,kronke2014lenalidomide, banik2020lysosome}.  Traditional drug discovery mainly focuses on inhibiting the activity of target proteins, which may not always be effective, especially in cases where the target protein is `undruggable' by occupancy-driven inhibitors like small molecules~\cite{hammoudeh2009multiple}.
These `undruggable' proteins include oncology targets in the  SWI/SNF complex~\cite{mittal2020swi,willis2012functional} and many kinases~\cite{huang2018chemoproteomic} which share high homology active domain with their essential non-disease related family members, and transcriptional factors~\cite{vairy2020ikzf1} that are highly unstructured until they form active conformations.
TPD presents an alternative strategy, which is to induce the degradation of target proteins rather than inhibit their activity to achieve desirable therapeutic outcomes. The mode of action (MOA) for TPD offers several advantages: Firstly, TPD molecules do not require targeting `active site', allowing them to selectively target disease-driver proteins without affecting other essential homologous proteins that often share conserved active sites, and exert potential to engage highly-unstructured transcriptional factors~\cite{henley2021advances} and other scaffolding targets that do not depend on active sites~\cite{henley2021advances}. Secondly, its transient protein interaction via event-driven mechanism reduces the reliance on strong binding affinity, in contrast to inhibitor drugs~\cite{teng2023rise}. Furthermore, its catalytic nature mitigates the requirement for high dosages and the subsequent challenges associated with off-target effects~\cite{bondeson2015catalytic}. Lastly, even for existing targetable proteins by inhibitors, it still offers alternative therapeutic options to fight against drug resistance caused by active site mutations~\cite{barouch2011mechanisms}.

Proteolysis-targeting chimeras (PROTACs) and molecular glue degraders (MGDs) are two main modes of TPD~\cite{teng2023rise}. As shown in Fig.~\ref{fig:overall}a,
PROTACs are hetero-bifunctional small molecules consisting of three moieties, including a warhead, which is the ligand of the protein of interest (POI), an anchor, which is the ligand of an E3 ubiquitin ligase being employed, and a linker linking the warhead and anchor. With the hetero-bifunctional structure, PROTACs recruit the POI to an E3 ubiquitin ligase, leading to the ubiquitination of the POI and its subsequent degradation process by UPS~\cite{buckley2012targeting,li2022protacs}. As of January 2023, there have been 18 PROTACs under evaluation by regulatory authorities, targeting different malignant cancer diseases~\cite{chirnomas2023protein}.
MGDs, in contrast, are small molecules that facilitate the interaction between the POI and an E3 ubiquitin ligase, enabling the ubiquitination and degradation processes of the POI~\cite{schreiber2021rise}. Unlike PROTACs, they do not require a bifunctional structure but act by stabilizing existing protein-protein interactions or inducing new interactions~\cite{rui2023protein}. Despite their distinct modes of action, both PROTACs and MG(D)s share a common feature: the induction of a ternary complex structure that is crucial for their respective mechanisms.

Understanding the ternary structure induced by PROTACs or MGDs provides crucial insights into the molecular basis of induced protein degradation. In the context of PROTACs, the ternary structure elucidates how the PROTAC molecule facilitates the connection between the POI and the E3 ligase, demonstrating the interacting poses, properties of the contact interface, and solvent-exposed amino acid residues essential for efficient ubiquitination. For instance,  the buried surface area (BSA) of the ternary structure~\cite{yamamoto2022discovery} is a critical parameter indicating the extent of interaction surface between the PROTAC, the POI, and the E3 ligase, directly correlating with the stability and efficacy of the induced degradation~\cite{wurzAffinityCooperativityModulate2023,rui2023protein}.
The ternary structure can also suggest possible modifications in terms of the length and the composition of the PROTAC linker in order to improve selectivity and reduce off-target effects~\cite{wurzAffinityCooperativityModulate2023}. Similar to PROTACs, the BSA of the MGD-induced ternary structure is a crucial determinant of their functional impact, influencing both the strength and specificity of the interaction between the POI and the E3 ligase~\cite{rui2023protein}, which can also provide clues about the molecular features that are crucial for the molecular glue's activity~\cite{oleinikovasThalidomideRationalMolecular2024}.


Existing experimental approaches to obtain the PROTAC- or MGD-induced ternary structures, such as X-ray crystallography and cryo-EM, often depend on costly instrumentation and intricate reagents and remain a formidable challenge for seasoned structural biologists due to the necessity of high-purity proteins and precise buffer conditions. Instead, in silico approaches have been proposed to predict ternary structures that primarily using various docking methods (such as PatchDock~\cite{duhovny2002PatchDock,zaidmanPRosettaC2020}, FRODock~\cite{Garzon2009FRODOCK,wengIntegrativeModelingPROTACMediated2021}, RosettaDock~\cite{Lyskov2008RosettaDock,zaidmanPRosettaC2020,wengIntegrativeModelingPROTACMediated2021}, and PIPER~\cite{Kozakov2006PIPER,ignatovHighAccuracyPrediction2023,wurzAffinityCooperativityModulate2023}) to generate big pools of structures and then to rank, filter, and refine the docked ternary structures by minimizing free energy~\cite{zaidmanPRosettaC2020, wurzAffinityCooperativityModulate2023,ignatovHighAccuracyPrediction2023}, atom clash~\cite{drummondInSilicoModelingofPROTAC-MediatedTernaryComplexes2019,drummondImprovedAccuracyModeling2020, ignatovHighAccuracyPrediction2023}, constraining distance to E2 ligase~\cite{ignatovHighAccuracyPrediction2023}, and molecular dynamics simulations~\cite{wurzAffinityCooperativityModulate2023}. In spite of the encouraging progress, the structures predicted by existing docking methods still deviate greatly from experimentally determined ones, and the docking process is usually time-consuming. Recently, deep learning technologies such as AlphaFold2~\cite{jumperAlphaFold22021} and RosettaFold~\cite{baekRoseTTAFold2021} have shown promising prediction accuracy for protein structure prediction by making use of deep and sophisticated neural networks to distill crucial features from extensive training datasets.
These remarkable achievements have attracted significant scientific interest in extending deep learning to other related tasks, including protein-protein~\cite{ganeaEquiDock2022,evansAF-Multimer2021} and protein-ligand complex structure prediction~\cite{starkEquiBind2022,corsoDiffDock2022}. However, to our best knowledge, there were no reported research on predicting PROTAC- or MGD-induced ternary structures by using deep learning approaches. This can be attributed to the heightened complexity of modeling ternary structures compared to the unitary or binary structures tackled in prior studies. Additionally, the scarcity of training data presents a significant obstacle to training deep learning models, as there are only a few resolved ternary structures for both PROTACs and MGDs~\cite{raoBayesianOptimizationTernary2023,rui2023protein}, making it impractical to train such models with such limited data.

In this work, we introduce a novel deep learning-based framework for predicting ternary complexes induced by PROTACs and MG(D)s\footnote{We use the term MG(D) to denote both degraders and non-degraders, as the formation of MGD ternary complexes can be generalized to non-degraders.}. This represents the first attempt to apply deep learning to PROTAC structure prediction and the first in silico approach for MG(D) structure prediction. To achieve this, we curated TernaryDB, a large-scale dataset comprising over 20,000 ternary complexes from the Protein Data Bank (PDB). The dataset focuses on high-quality complexes that include a small molecule and two proteins while deliberately excluding known PROTACs and MG(D)s from the training list. Fig.~\ref{fig:overall}b outlines the construction process of the dataset. Leveraging TernaryDB, we trained \modelName{}, an SE(3)-equivariant graph neural network specifically designed for ternary structure prediction (Fig.~\ref{fig:overall}c). In this model, the ternary complexes were disassembled into three components—p1 (protein1), lig (ligand), and p2 (protein2)—each modeled as a graph. Graph neural networks(GNN)~\cite{wuComprehensiveSurveyGraph2021} offer a powerful framework for processing graph-structured data through message passing between nodes and edges. To improve data efficiency, we employed an SE(3)-equivariant GNN, leveraging the symmetry properties of SE(3) to ensure invariance to the translation and rotation of 3D structures. Additionally, we introduced a novel ternary inter-graph attention mechanism to capture the intricate relationships between ternary components, along with a query-based pocket points decoder to predict the final complex structure. With these innovations, \modelName{} effectively predicts both the conformation of the small molecule and the docking poses of the ternary complex. \modelName{} was evaluated against existing PROTAC and MG(D) benchmarks, achieving state-of-the-art performance with DockQ scores of 0.65 and 0.21, with average inference times of approximately 7 seconds and 1 second, respectively. The model’s ability to generalize from a non-PROTAC/MG(D) PDB dataset to PROTAC/MG(D) ternary structures highlights its capacity to capture the fundamental interaction patterns governing ternary complex formation, rather than relying on memorization. Moreover, the predicted buried surface area (BSA) of the PROTAC complexes aligns closely with values reported in existing literature, with BSA ranging from 1100 to 1500, indicating high degradation potential. These results demonstrate \modelName{}'s potential to advance our understanding and manipulation of protein degradation mechanisms.


\section{Results}

\subsection*{The construction of TernaryDB}


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth,page=1]{imgs/Figures.pdf}
\caption{
\textbf{TernaryDB construction and visualization.}
\textbf{a,} The process of collecting and cleaning the ternary complexes dataset. Initially, a search of ternary structures from the PDB yielded 46,797 PDB IDs, each of which contains at least two proteins and one small molecule. High-quality PDB IDs were retained based on criteria such as X-ray crystallography data, resolution, and R-free value. From this subset, 42,441 complexes were extracted, each comprising just two proteins and one small molecule. These complexes underwent further refinement based on peptide chain length and the number of contacts. Ultimately, 22,303 complexes met our stringent criteria and were used to train our model.
\textbf{b,} Histogram of the ligand atom number (excluding hydrogens) within the dataset.
\textbf{c,} Histogram of cluster sizes within the dataset according to the protein sequence similarity.
\textbf{d,} The distribution of protein source organisms in the dataset.
\textbf{e,} Proteome-wide view of the collected dataset. ESM-1b~\cite{rivesESM1b2021} sequence embeddings for the two proteins in each complex are calculated and concatenated. This is followed by two-dimensional (2D) Uniform Manifold Approximation and Projection (UMAP). Similar complexes to PROTACs- and MG(D)s-involved ternary structures are denoted as red and green square points, respectively.
\textbf{f,} Chemical space covered by the dataset. Morgan fingerprints are converted to 1024-length vectors and visualized through a 2D UMAP. The points on the map are differentiated and colored by molecular weight (hydrogen excluded). PROTACs- and MG(D)s-like molecules are highlighted as red and green square points, respectively.
}
\label{fig:dataset}
\end{figure}

There are only a few dozen experimentally determined PROTAC- and MG(D)-involved ternary complexes in the PDB~\cite{bermanProteinDataBank2000}. Despite the remarkable success of deep learning in protein structure prediction~\cite{jumperAlphaFold22021,baekRoseTTAFold2021}, protein-protein docking~\cite{ganeaEquiDock2022}, and protein-ligand interactions~\cite{starkEquiBind2022,luDynamicBind2024}, its application to targeted protein degradation (TPD) remains underdeveloped, primarily due to the scarcity of training data. We hypothesized that TPD complexes adhere to the same fundamental atom-interaction principles as other tripartite complexes. To test this hypothesis and enable deep learning-based prediction of TPD complex structures, we curated a comprehensive dataset of ternary complexes from the PDB. After stringent data filtering (\added{details are provided in Methods~\ref{sec:method:data_collection}}), the final dataset comprised 22,303 complexes, with their key attributes illustrated in Fig.~\ref{fig:dataset}. The distribution of ligand atom counts, excluding hydrogens, is shown in Fig.~\ref{fig:dataset}b, revealing that the majority of ligands contain fewer than 60 heavy atoms, with only a small subset exceeding 100. The chemical diversity of these ligands, represented by Morgan fingerprints (Fig.~\ref{fig:dataset}f), highlights the broad chemical space and drug-like properties of the dataset. Proteins from 363 species, ranging from bacteria to humans, are included in the dataset (Fig.~\ref{fig:dataset}d). Although the protein space is relatively sparse, it adequately covers PROTAC- and MG(D)-induced proteins (Fig.~\ref{fig:dataset}e).

To rigorously assess our method, we integrated known PROTAC and MG(D) ternary complexes into the test sets. To prevent data leakage, we utilized MMseqs2~\cite{steineggerMMseqs22017} to cluster the dataset based on protein sequence similarity. Clusters containing known PROTAC or MG(D) complexes were excluded from the training set and served as a validation set, ensuring no overlap between training and test data. This clustering approach yielded 16,203 complexes distributed across 1,398 clusters for PROTACs and 22,046 complexes across 1,982 clusters for MG(D)s. The distribution of cluster sizes is shown in Fig.~\ref{fig:dataset}c, where most clusters are small, although a few contain over 100 complexes.

To mitigate potential biases during training, we adopted a cluster-wise sampling strategy. Traditional uniform sampling within batches could result in the selection of highly similar complexes, thereby skewing the training process. Instead, we first randomly sampled a cluster with equal probability and then selected the representative complex with a 20\% likelihood; otherwise, a random complex from the cluster was chosen. The representative complex was determined using the MMseqs2 toolkit during clustering. This approach ensures a diverse and representative sampling of the training data, enhancing the model's ability to generalize across complex structures.



\subsection*{The architecture of \modelName{}}
DeepTernary is designed to predict the structures of small molecule-induced ternary complexes, such as those formed by PROTACs and MG(D)s-induced E3 ligase with POI complexes. Unlike existing methods that rely on standard protein-protein docking programs to approximate the interaction between two proteins—often neglecting the presence of small molecules, DeepTernary employs a deep neural network to directly learn the intricate dynamics of protein-protein and protein-ligand interactions within ternary complexes. For predicting PROTAC-induced complexes, DeepTernary takes as inputs the respective mono forms of the two protein structures (E3 ligase and target protein) along with docked warheads and anchors from other PDB entries (unbound structures), in addition to the PROTAC Simplified Molecular Input Line Entry System (SMILES) strings. In the case of MG(D)-induced complexes, since the unbound structures are hard to find, we adopt the respective in-complex form of the two protein structures (randomly rotated and transformed) and the corresponding MG(D) SMILES strings as input.

In general, \modelName{} consists of an encoder and a decoder.
The process begins by generating a random conformation of the small molecule using RDKiT~\cite{landrum2013rdkit} and randomly displacing the small molecule and protein 2 (p2) away from protein 1 (p1). This serves as the starting point for learning the interactions between the two proteins and the ligand. As illustrated in Fig.~\ref{fig:overall}c, these three monomers are encoded as graphs and processed through an SE(3)-equivariant encoder. This encoder facilitates the interaction of the encoded entities in a geometrically consistent manner. Multiple blocks of alternating intra- and inter-graph message passing are employed to update the coordinates and latent features of the three monomers. To efficiently capture the symmetry in their interactions, the parameters in the encoders for p1 and p2 are weight-shared (\added{Methods~\ref{sec:method:architecture}}). Following the encoding stage, the conformation of the small molecule is utilized as the final conformation. \added{The final ternary structure is generated based on this predicted conformation and pocket points. For PROTACs, the pocket points are derived from unbound structures, while for MG(D)s, these points are predicted by the proposed query-based pocket points decoder (PPPD). With these information, we can rigid align the ligand and p2 back to p1 for form the final structure. The PPPD will also predict an alignment error for this predicted structure. Notably, benefiting from the Transformer architecture’s inherent ability to handle variable numbers of input queries without architectural modifications, the proposed PPPD architecture is unified for both PROTAC and MG(D). This simplifies the model design and implementation. For PROTACs, only PAE queries are input to the decoder, while for MG(D)s, both pocket point and PAE queries are used.}





\subsection*{Effectiveness of model designs}


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth,page=5]{imgs/Figures.pdf}
\caption{
\textbf{Effectiveness of \modelName{} designs on PROTAC and MG(D) test benchmarks.} \added{All results are based on test sets comprising 22 PROTAC complexes or 94 MG(D) complexes. Statistical significance was determined using an independent t-test: * p $\leq$ 0.05, ** p $\leq$ 0.01, and ***p $\leq$ 0.001, similarly hereinafter.}
\textbf{a,} Comparison of decoder types: our proposed Pocket Points Decoder outperforms IEGMN in predicting medium- to high-quality binding poses (DockQ \textgreater{} 0.49).
\textbf{b,} Impact of multi-head attention on coordination prediction: increasing the number of heads results in a slight decrease in DockQ scores.
\textbf{c,} Effect of latent embedding dimension on model performance: larger dimensions yield improved learning, especially for MG(D) complexes.
\textbf{d,} Influence of noise level on model robustness: elevating the noise level from 1 to 2 enhances performance on both PROTAC and MG(D) benchmarks.
\textbf{e,} Effect of \added{number of sampled random conformations}: more sampled conformations lead to higher DockQ scores and acceptance rates (DockQ \textgreater{} 0.23) for PROTACs, while MG(D) remains largely unaffected.
}
\label{fig:ablation}
\end{figure}

\added{Based on the binary interaction prediction model~\cite{starkEquiBind2022,ganeaEquiDock2022}, we had explored various choices of model designs and hyper-parameters for \modelName{}. To ensure robust model selection, we employed a validation set consisting of curated structures that are dissimilar to the training set and also not in the test set. Model performance on this validation set was assessed using a simple score calculated as the average of the DockQ scores for the top-ranked prediction and the best overall prediction (detailed information is provided in Supplementary Section~\ref{sec:supp-model-selection}). We now present the results obtained on the test set.
}


First, \modelName{} incorporates a ternary inter-graph attention mechanism in the encoder, enabling it to capture more complex ternary interactions. However, the initial decoder design, denoted as IEGMN, struggled to effectively translate the encoded information into accurate binding poses (Fig.~\ref{fig:ablation}a). By introducing the newly developed Prompt-based Pocket Points Decoder (PPPD) (\added{detailed in Methods~\ref{sec:method:architecture}}), we significantly enhanced performance, with many samples achieving medium to high quality (DockQ \textgreater{} 0.49). Additionally, we found that, while multi-head attention is beneficial in natural language processing, it is less effective for predicting pocket point coordinates in this context. Specifically, as the number of attention heads increases, the DockQ score decreases slightly (Fig.~\ref{fig:ablation}b). Consequently, we employed single-head attention in the PPPD to extract coordinates accurately. Transitioning from binary to ternary interaction prediction posed additional challenges. We discovered that increasing the latent embedding space improved the model's capacity to learn complex triplet interactions, particularly for MG(D) complexes, which exhibit greater structural complexity (Fig.~\ref{fig:ablation}c).
Besides, to avoid the risk of overfitting, we increased the noise added to both the coordinates and latent features, from 1 to 2, which improved performance across both PROTAC and MG(D) benchmarks (Fig.~\ref{fig:ablation}d). Nevertheless, adding too much noise (noise level from 2 to 3) will hinder the performance.

In line with previous studies~\cite{wengIntegrativeModelingPROTACMediated2021,ignatovHighAccuracyPrediction2023,raoBayesianOptimizationTernary2023}, \modelName{} utilizes RDKit~\cite{landrum2013rdkit} to generate initial conformations for small molecules, sampling multiple conformations with different seed numbers during inference. Our ablation studies (Fig.~\ref{fig:ablation}e) demonstrated that both the DockQ score and accept rate (DockQ \textgreater{} 0.23) increased as the number of sampled conformations for PROTAC grew. Conversely, MG(D) complexes showed little change. This discrepancy can be attributed to the fact that PROTACs have more atoms and exhibit greater structural flexibility, while MG(D)s have a smaller conformation space. Based on these findings, we sample 40 initial random conformations for each PROTAC and rank the predicted results using the PAE score. For MG(D) predictions, we use a single initial conformation to conserve computational resources.






\subsection*{\modelName{} achieves the highest accuracy in PROTACs-induced ternary structure prediction}

\begin{figure}
\centering
\includegraphics[width=\linewidth,page=2]{imgs/Figures.pdf}
\caption{
\textbf{\modelName{} achieves the highest accuracy in PROTACs-induced ternary structure prediction.}
\textbf{a,} \modelName{} outperforms existing methods in predicting 22 existing PROTAC-induced ternary structures regarding the metrics of the DockQ score (top panel) and the first acceptable rank containing at least one prediction with $\text{DockQ}\geq0.23$ (middle panel). For those that failed to generate a acceptable result, we manually set the rank value to 41 for a fair comparison. Besides, \modelName{} achieves better DockQ performance on most complexes compared to the current best model, the RosettaDock-Based model (bottom panel).
\textbf{b,} \modelName{} outperforms existing methods on the percentage of High/Medium/Acceptable.
\textbf{c,} \modelName{} has a higher potential to generate decent (RMSD \textless{} 10 \AA{}) results.
\textbf{d,} DockQ performance comparison among different E3 ligases.
\textbf{e,} Surface illustration of the predicted structure of PDB ID 5T35.
\textbf{f,} Three examples of predicted ternary structures (teal and orange for the protein and ligand, respectively) overlaid with the experimental structures (gray and green for the protein and ligand). The receptor protein is colored in red, and the chemical structure diagrams of PROTAC molecules are illustrated at the bottom.
}
\label{fig:protac}
\end{figure}


To evaluate our method, we utilized the PROTAC benchmark compiled by Rao \etal \cite{raoBayesianOptimizationTernary2023}, which consists of 22 known PROTAC-induced ternary structures serving as the test set. The unbound protocol adopted in this benchmark emulates the real-world scenario encountered during drug discovery, where the experimental structure of the ternary complex is often unavailable. In this protocol, an unbound complex refers to a protein with a bounded ligand similar to the warhead or anchor of the PROTAC, but not co-crystallized with the entire PROTAC molecule. To align with the rational design process of PROTACs, we followed this unbound protocol to evaluate \modelName{}.

To mitigate data leakage, we excluded any similar protein pairs from the dataset used to train our model. Unlike previous methods, which rely on human-defined heuristics -- such as manually set thresholds for free energy~\cite{zaidmanPRosettaC2020, wurzAffinityCooperativityModulate2023,ignatovHighAccuracyPrediction2023}, atom clashes~\cite{drummondInSilicoModelingofPROTAC-MediatedTernaryComplexes2019,drummondImprovedAccuracyModeling2020, ignatovHighAccuracyPrediction2023}, or linker ends distances~\cite{ignatovHighAccuracyPrediction2023} -- to filter ternary conformations, we leveraged deep learning to automatically capture high-dimensional interactions between PROTACs and proteins. Furthermore, in contrast to Drummond \etal~\cite{drummondInSilicoModelingofPROTAC-MediatedTernaryComplexes2019,drummondImprovedAccuracyModeling2020}, our model was trained without any PROTAC-involved structures and directly evaluated on the PROTAC benchmark, using a zero-shot protocol. This approach tests the model's ability to learn general interaction rules applicable to any ternary structure, not just those induced by PROTACs, offering a stringent measure of how well the model generalizes from non-PROTAC to PROTAC data.

For a comprehensive comparison, we employed several evaluation metrics, including DockQ scores, rank of the first prediction achieving a DockQ score greater than 0.23, the percentage of CAPRI high/medium/acceptable predictions, and the percentage of predictions with RMSD \textless{} 10 \AA{} (metrics detailed in \hyperref[sec:metrics]{Evaluation metrics}). As shown in Fig.~\ref{fig:protac}a, b, and c, \modelName{} consistently produces higher DockQ scores and higher rates of acceptable predictions (both in terms of High/Medium/Acceptable predictions and \textless{} 10 \AA) compared to other published methods, \added{including FRODock- and RosettaDock-Based methods~\cite{wengIntegrativeModelingPROTACMediated2021}, BOTCP~\cite{raoBayesianOptimizationTernary2023}, Method 4~\cite{drummondInSilicoModelingofPROTAC-MediatedTernaryComplexes2019}, Method 4B~\cite{drummondImprovedAccuracyModeling2020}, PRosettaC~\cite{zaidmanPRosettaC2020}, and most recently published AlphaFold 3~\cite{abramsonAF32024} and Chai-1~\cite{discoveryChai-12024}}. Specifically, it achieved an average DockQ score of 0.65 across the test set, significantly outperforming the recently proposed BOTCP~\cite{raoBayesianOptimizationTernary2023}, which scored 0.44. Although other methods were only evaluated on subsets of the benchmark, \modelName{} demonstrated superior performance across overlapping tested structures. Notably, as illustrated in the lower portion of Fig.~\ref{fig:protac}a, \modelName{} surpasses the top-performing RosettaDock-based method~\cite{wengIntegrativeModelingPROTACMediated2021} for most testing structures.

PROTAC molecules, with their larger atom counts compared to natural small molecules, exhibit diverse conformations due to their significant degrees of freedom. To model this flexibility, we employed the RDKit toolkit to generate multiple initial conformations of the ligand using different random seeds, each of which was input into our model. To estimate the prediction quality, we introduced a predicted aligned error (PAE), allowing us to rank the predicted results and select the most confident output. With an average rank of 4.06 under 40 seeds (Fig.~\ref{fig:protac}a, middle panel), \modelName{} reliably generated acceptable predictions (DockQ \textgreater{} 0.23).
\added{
In another words, there is generally at least one acceptable prediction within the top four results. To compare with existing methods, we also calculate the prediction success rate for each complex based on another two criteria: CAPRI criteria and RMSD \textless{} 10 \AA{} (Fig.~\ref{fig:protac}b and c). As we can see, DeepTernary significantly improve the success rate to around 50\%, which means for most of the test complexes, more than half of the predictions are above acceptable quality.
}
Since the ground-truth structure is typically unavailable in practice, distinguishing between higher- and lower-quality output structures remains challenging without of a reliable scoring or ranking system. Our \modelName{} addresses this challenge by incorporating a PAE predictor, where lower PAE values indicate higher confidence in predictions (Fig.~\ref{sup:fig:paevsdockq}). The mean Top-1 DockQ based on PAE reaches up to 0.4 (Tab.~\ref{tab:supp:top1_dockq}), surpassing the acceptable cutoff of 0.23, which enhances its utility in real-world drug discovery applications.


Finally, we examined the performance of \modelName{} across the three distinct E3 ligases present in the 22 benchmark complexes. As shown in Fig.~\ref{fig:protac}d, \modelName{} consistently achieved desirable DockQ scores across all ligases, highlighting its robustness and generalizability. Visual comparisons of the predicted and experimentally determined structures (Fig.~\ref{fig:protac}e–f) demonstrate that our model can generate high-quality predictions, with DockQ values exceeding 0.9. Notably, for PDB IDs 6W7O and 6W8I, which share the same E3 ligase and POI pair but differ in their PROTACs, \modelName{} accurately captured the structural differences, producing predictions aligned with experimental expectations.


\subsection*{\modelName{} reaches acceptable accuracy in MG(D)-induced ternary complex structure prediction}

\begin{figure}
\centering
\includegraphics[width=\linewidth,page=3]{imgs/Figures.pdf}
\caption{
\textbf{\modelName{} reaches acceptable accuracy for MG(D)-induced ternary complex structure prediction.}
\textbf{a,} Since no MG(D)-induced complex prediction method exists, we compared \modelName{} with the traditional protein-protein interaction (PPI) prediction method EquiDock. \modelName{} significantly outperforms EquiDock by precisely modeling ternary interactions.
\textbf{b,} Comparison with EquiDock and the recently realeased AlphaFold3 (AF3) on PDB ID 7BQU. The predicted aligned error (PAE) matrix from AF3 is shown in the top right corner. AF3 predicts the structure with plDDT values between 50 and 90 but shows low confidence for docking, with PAE values exceeding 20 between p1 and p2.
\textbf{c,} Visualization of the predicted ternary structure for PDB ID 4JDD (Group 2), displayed using both cartoon and surface illustrations.
\textbf{d,} Two predicted results from Group 1.
\textbf{e,} Performance comparison across different interaction modes: domain-domain (Group 1) and sequence motif-domain (Group 2).}
\label{fig:MGD}
\end{figure}

Molecular glue degraders (MGDs) represent a novel class of TPD drugs, distinct from PROTACs due to their lower molecular weight and alternative MOA. These characteristics often result in an advantageous starting point for medicinal chemistry optimization, as well as enhanced drug-like physicochemical properties~\cite{tsai2024targeted}. Their simplicity in structure further facilitates later-stage drug development. The rising interest in MGDs has prompted significant research efforts and corporate investments focused on this new modality. In particular, structure-based rational design plays a crucial role in maximizing the chances of successful drug discovery. For instance, the crystal structure of the $\beta$-TrCP, $\beta$-catenin, and NRX-1933 ternary complex has been instrumental in developing MGDs with improved mutant selectivity~\cite{simonettaProspectiveDiscoverySmall2019}. Similarly, the discovery of ALV2, a mutant-specific Ikaros degrader, relied on known crystal structures for guidance~\cite{matyskielaNovelCereblonModulator2016,wangAcutePharmacologicalDegradation2021}.


MG(D)s can either stabilize endogenous protein-protein interactions or induce non-native ones~\cite{deweyMolecularGlueDiscovery2023}. However,  predicting MG(D)-induced ternary complex structures poses a challenge due to the often weak binding affinity between the small molecule and one of the proteins. With no existing in silico method specifically designed for  MG(D)-induced complexes, we employed EquiDock~\cite{ganeaEquiDock2022}, a protein-protein docking approach, to test whether weak interactions between two proteins could approximate MG(D)-induced binding features. Using MG(D)-induced complexes collected by Rui et al.\cite{rui2023protein} as a test set, we evaluated the models’ performance using DockQ scores, similar to our approach with PROTAC experiments. The results, shown in Fig.~\ref{fig:MGD}a, reveal that EquiDock achieves an average DockQ score of only 0.04. In contrast, \modelName{} significantly improves the score to 0.21, demonstrating the advantage of incorporating small molecule information and modeling ternary interactions within the model architecture.

Recently, DeepMind introduced AlphaFold3 (AF3)~\cite{abramsonAF32024}, which is able to predict complexes involving nearly all molecular types in the PDB, including proteins and small molecules. However, since the code has not yet been released and the AlphaFold Server does not currently allow customization of small molecules, we used AF3 solely for protein-protein binding predictions, as we did with EquiDock. Fig.~\ref{fig:MGD}b illustrates a prediction for PDB ID 7BQU, where AF3, thought better than EquiDock, performs significantly worse than \modelName{}, which predicts a structure closest to the co-crystallized ground truth (green vs. gray). \added{We show the PAE matrix in the top right corner. The PAE in AlphaFold, measured in Ångströms (Å), represents the expected positional error between two residues in the predicted structure. Typically, an AF PAE value exceeding 15 Å is considered indicative of a less confident prediction. In this prediction, the PAE values are approximately 20 Å, highlights AF3's lower confidence in this predicted interaction.}

Rui \etal categorized the collected MG(D)-induced complexes into two groups based on the nature of their protein-protein interface: Group 1 involves domain-domain interactions, where two proteins bind through well-structured domains (as shown in Fig.~\ref{fig:MGD}d), and Group 2 involves sequence motif-domain interactions, where a protein sequence motif binds to a structured domain (illustrated in Fig.~\ref{fig:MGD}c). Our results indicate that both EquiDock and \modelName{} perform better on Group 2 complexes than on Group 1, as shown in Fig.~\ref{fig:MGD}e. This suggests that the large, well-folded domains in Group 1 complexes involve more complex binding rules, which may not be adequately covered by the training set (Supplementary Fig.~\ref{sup:fig:MGD_seq_length}). In contrast, the interactions involving small recognition motifs in Group 2 are better captured, leading to improved predictions.


\subsection*{The total buried surface area (BSA) from our predicted structures strongly correlates with degradation potency}


\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth,page=4]{imgs/Figures.pdf}
\caption{
\textbf{The buried surface area (BSA) based on our predicted structures correlates with degradation potency.}
\textbf{a,} The BSA of 22 known PROTAC-induced ternary complexes from experimental structures.
\textbf{b,} Correlation analyses between BSA and $ln(K_{LPT})$ for the predicted BRD4-VHL ternary complex with various PROTACs. The quantity $ln(K_{LPT})$ has been proven in previous work~\cite{wurzAffinityCooperativityModulate2023} to have a positive relationship with $ln(DC_{50})$. The red line represents a linear regression of the points.
\textbf{c,} Correlation analyses between BSA and linker length for predicted CRBN-BTK complexes induced by 11 different PROTACs. As PROTAC ID increases, linker length increases. The red line shows a second-order polynomial regression. Notably, PROTACs (6-11) are associated with significant cellular knockdown, while shorter PROTACs(1-4) exhibit weak/no degradation capability.
\textbf{d,} Predicted ternary structures for CRBN-BTK complexes induced by PROTAC (1) and PROTAC (10), illustrating severe atom clashes PROTAC (1) and increased flexibility to avoid clashes in PROTAC (10).
\textbf{e,} \modelName{} predicts ternary structures approximately 100 times faster than existing methods.
}
\label{fig:bsa}
\end{figure}


Experimental work by Wurz \etal~\cite{wurzAffinityCooperativityModulate2023} has demonstrated a strong correlation between the total buried surface area (BSA) of PROTAC-mediated ternary complexes and the \added{equilibrium dissociation constant ($K_{LPT}$) for VHL-PROTAC-SMARCA2. Their findings revealed that BSA has a negative correlation with $ln(K_{LPT})$, while a lower  $K_{LPT}$ corresponds to higher degradation potency. In other words, a higher BSA corresponds to higher degradation potency.} To test whether our predicted ternary structures could reflect this relationship, we calculated the total BSA for the predicted VHL-PROTAC-SMARCA2 complexes ( Fig.~\ref{fig:bsa}b). Consistent with the experimental data, our predictions also show a generally negative correlation between total BSA and $ln(K_{LPT})$, supporting the findings of Wurz \etal.

In a separate study, Zorba \etal~\cite{zorbaDelineatingRoleCooperativity2018} investigated the effect of PROTAC linker length on degradation potency, using cereblon (CRBN) as the E3 ligase to induce degradation of Bruton’s tyrosine kinase (BTK). They synthesized 11 PROTACs with varying linker lengths (PROTACs 1-11) and found that longer PROTACs (6-11) yield detectable ternary complex formation via fluorescence resonance energy transfer (FRET) and demonstrated potent cellular BTK degradation. In contrast, shorter PROTACs (1-4) showed weak or no FRET signals and were ineffective in cells. PROTAC (5) displayed intermediate behavior.

To further explore the relationship between degradation potency and ternary structure, we use  \modelName{} to predict the ternary structures induced by these 11 PROTACs and computed their total BSA. The results, illustrated in Fig.~\ref{fig:bsa}c, indicate that as linker length increases, total BSA decreases sharply at first before plateauing. This trend correlates negatively with degradation potency, consistent with the findings from Zorba \etal. For the predicted structures of PROTACs (1-4),  severe atom clashes between proteins lead to higher BSAs (left side of Fig.~\ref{fig:bsa}d), which explains their inability to form stable ternary complexes and induce degradation. In contrast, for PROTACs (5-11), the increased linker length allows for more flexibility, reducing atomic clashes (right side of Fig.~\ref{fig:bsa}d) and facilitating productive protein-protein interactions, which correlate with effective degradation.


Although both Wurz \etal and Zorba \etal demonstrated strong correlations between PROTAC degradation potency and factors like BSA and linker length, it remained unclear whether the observed relationships for VHL-SMARCA2 PROTACs could be generalized to CRBN-BTK PROTACs. By employing \modelName{} to model the ternary structures and calculate BSA for all PROTACs whose degradation potency was experimentally validated, we were able to compare their results and examine these conclusions more thoroughly. In the VHL-SMARCA2 system (Fig.~\ref{fig:bsa}b), higher BSA correlates with higher degradation potency (lower $log(K_{LPT})$), whereas in the CRBN-BTK system (Fig.~\ref{fig:bsa}c), higher BSA--indicative of shorter linker lengths-- is associated with lower degradation potency, highlighting conflicting trends (Supplementary Fig.~\ref{sup:fig:bsa}).


By synthesizing the findings from both studies (Fig.~\ref{fig:bsa}b and c), we conclude that their conclusions do not inherently conflict. This is because the correlation between BSA and degradation potency appears to be more nuanced than a simple linear correlation. In Fig.~\ref{fig:bsa}a, we analyzed the BSA range for 22 known PROTAC-induced complexes with experimentally determined structures, highlighting a range of 1,175 to 1,422 \AA$^2$ (shaded gray). When comparing the BSA values of PROTAC-induced complexes in Fig.~\ref{fig:bsa}b and c, we found that PROTACs tend to exhibit higher degradation potency when their total BSA falls within the 1,100 to 1,500 \AA$^2$ range. This suggests that BSA could be a useful metric for virtual screening and inform future PROTAC design.



\subsection*{\modelName{} is significantly faster than existing methods}


Existing methods for predicting ternary structures often require generating numerous candidate structures and applying multiple filtering criteria to identify the most viable options. For instance, Weng \etal utilized a multi-step protocol involving FRODOCK for local docking, followed by energy scoring with Open Babel Obenergy and AutoDock Vina, and further refinement using RosettaDock~\cite{wengIntegrativeModelingPROTACMediated2021}. This approach, while effective, is time-consuming, taking approximately one hour on an 18-core CPU for the FRODOCK-based process alone, with RosettaDock-based refinement adding another nine hours. More recent methods like BOTCP, which employ Bayesian optimization to expedite candidate sampling, have reduced the process to around two hours~\cite{raoBayesianOptimizationTernary2023}.

In contrast, \modelName{} introduces a substantial leap in efficiency by leveraging an end-to-end neural network that embeds learned knowledge directly into its parameters. Unlike traditional docking-based techniques that rely on iterative candidate generation and refinement, \modelName{} predicts PROTAC ternary structures in a fraction of the time. Using 40 seeds, it can predict a ternary complex in just 12.37 seconds on a 15-core CPU, and as little as 6.48 seconds with GPU acceleration. For MG(D) complexes, the process is even faster, requiring only a single forward pass of the embedded graphs, yielding results in under 1 second (Fig.~\ref{fig:bsa}e). \added{It is worth noting that this time includes both the model's forward time and the data preprocessing time (such as using RDKit to generate initial conformations and file operations), making it instructive for real-world applications. The model-only forward time is reported in Supplementary Table~\ref{tab-supp-forward-time}. }


This dramatic improvement in prediction speed has the potential to revolutionize drug discovery by facilitating the rapid in-silico screening of a significantly large number of candidates, making it feasible to explore a broader range of compounds in less time.


\section{Discussion}

In this study, we introduced \modelName{}, a novel deep learning framework consisting of an SE(3)-equivariant graph neural network and a pocket point decoder to predict ternary complex structures induced by PROTACs and MG(D)s. \modelName{} offers a powerful tool for drug discovery by modeling complex interactions within ternary complexes, enabling the optimization of key drug characteristics such as selectivity and potency. Unlike traditional docking methods, which rely on predefined strategies, \modelName{} learns the underlying physical-chemical rules governing ternary complex formation, resulting in both improved prediction accuracy and significant reductions in computational time. This allows for rapid screening of PROTAC libraries across different E3 ligases and protein targets, providing structure-guided insights for drug development. The model’s ability to correlate buried surface area (BSA) with degradation potency further enhances its utility in designing more potent degraders. Additionally, \modelName{} excels in predicting low-affinity, transient interactions for MG(D)s, overcoming limitations of traditional methods and supporting the growing interest in MG(D)s as therapeutics with distinct mechanisms of action.

While \modelName{} is a significant advance, it shares a common limitation with data-driven approaches: a dependence on large datasets and a susceptibility to biases from the training set. Despite we have collected a broad dataset from the PDB, there remain room for improvement. Expanding the training data and incorporating lower-resolution experimental datasets could further enhance the model’s accuracy and applicability. Future developments in this direction will likely extend \modelName{}'s impact, enabling broader application in drug discovery.

In conclusion, \modelName{} offers a fast and accurate approach for predicting ternary complexes, representing a valuable tool in the development of TPD therapeutics. In addition, the BSA calculated from generated complexes by \modelName{} may offer valuable insights into the degraded potency, potentially facilitating the structure-guided TPD design. By refining this framework and integrating additional structural data, we anticipate even greater contributions to the field of targeted protein degradation.



\section{Methods}
\label{sec:method}

\subsection*{Data collection and filtering}
\label{sec:method:data_collection}

In our quest to identify potential ternary complexes, We searched the Protein Data Bank (PDB) to extract potential ternary complexes, applying filters to select structures with at least two proteins and more than one small molecule. This initial filtration process yielded 46,797 potential PDB entries. Subsequently, the filtered candidates were further refined by selecting only X-ray structures that met our high-quality standards—specifically, those with a resolution of 3.5 Å or better and an R-free value of 0.26 or lower—thereby refining our dataset to 22,221 PDB IDs.

From these entries, we extracted 42,441 ternary complexes, some of which included multiple complexes within a single entry, such as assemblies (e.g., 5T35\_D\_A\_759 and 5T35\_H\_E\_759) and instances where different ligands interacted with the same protein pair (e.g., 6ZO8\_B\_C\_LPX and 6ZO8\_B\_C\_PTY). To ensure meaningful protein-small molecule interactions, we imposed additional criteria: the small molecule must share a chain ID with one of the proteins, and the protein components must meet a minimum length requirement—seven amino acids for PROTACs and three for MG(D)s. This was exemplified by the TRAP motif in PDB ID 4TR9~\cite{nemetski2015PDB4TR9}. Such stringent criteria effectively pruned nearly half of the initial complexes, leaving us with 25,756 viable candidates for further analysis.

In our final step to validate meaningful protein-ligand interactions, \added{we implemented a two-tiered filtering approach. First, we excluded complexes where the ligand established fewer than three contacts with the protein, defined as ligand atoms positioned within 4 \AA{} of any protein atom. Second, we removed complexes exhibiting steric clashes, identified as any heavy atom pair (one from the ligand and one from the protein) separated by less than 2 \AA{}.  While this stringent criteria led to the exclusion of some well-characterized PROTACs and MG(D)s, such as PDB ID 6HAX~\cite{Farnaby2019PDB6HAX} (Rfree = 0.268), which marginally exceeded our 0.26 threshold, and PDB ID 6BN7~\cite{nowak2018PDB6BN7} (chain B ligand clash of 1.97 \AA{}), these structures were manually curated and retained in our database due to their established significance.
} \added{Additionally, many ligands in the PDB are crystallization buffers that frequently appear across numerous PDB entries and are not functionally relevant. To address this, we manually exclude commonly occurring ligands such as ACT, GOL, PEG, SO4, TRS, XYP, BME, EDO, PG4, and PG5 from the dataset.} The culmination of our efforts resulted in a comprehensive structure collection dataset comprising 22,303 complexes.




\subsection*{Similarity-based dataset splitting}
To mitigate the risk of test data leakage and to prevent model overfitting, we adopted a similarity-based dataset splitting strategy. This approach was designed to rigorously evaluate the model’s generalization capabilities by ensuring that training complexes were not similar to those in the test set.

We utilized MMseqs2~\cite{steineggerMMseqs22017}, a highly efficient toolkit for sequence clustering, to group proteins based on a minimum sequence identity threshold of 50\%. This involved clustering proteins with similar sequences. Any cluster containing a test set complex was designated as a test cluster.

\added{
To maintain the integrity of our training set, we excluded all complexes within the test clusters from the training set. Specifically, any protein complex with a sequence similarity exceeding 50\% to any complex in the test set was removed from the training data and treated as a validation sample. For PROTACs, the 22 known-structure test complexes were clustered into 7 groups, resulting in the exclusion of 16 test-similar complexes from the training set, all of which were PROTAC-induced, ensuring the validation set's relevance.}

\added{
For MG(D)s, the 94 test complexes clustered into 44 groups, resulting in 182 excluded training set complexes forming the validation set. This rigorous approach ensured the test set's novelty and provided a robust evaluation of the model's generalization ability. The performance of \modelName{} on the corresponding validation and test set is detailed in Supplementary Table~\ref{sec:supp-model-selection}.
}


\subsection*{Featurization}

Following the EquiBind approach~\cite{starkEquiBind2022}, both the ligand and proteins were encoded as geometric graphs using the k-nearest neighbor method. In the ligand graph $\gG_{\mathrm{lig}} = (\gV_{\mathrm{lig}}, \gE_{\mathrm{lig}})$, each node (representing an atom) $v_i \in \gV_{\mathrm{lig}}$ was characterized by atom attributes $\vf_i$ (a list feature of atomic number, chirality, total degree, formal charge, number of implicit hydrogens, number of hydrogen, radical electrons, hybridization state, aromaticity, and ring participation) and a 3D position vector $\vx_i \in \R^3$. Edges $\gE_{\mathrm{lig}}$ were defined between atoms within a distance of less than 4 \AA{}, determined by relative Euclidean distances and bond angles. For the protein graphs $\gG_{\mathrm{p1}} = (\gV_{\mathrm{p1}}, \gE_{\mathrm{p1}})$ and $\gG_{\mathrm{p2}} = (\gV_{\mathrm{p2}}, \gE_{\mathrm{p2}})$, nodes were defined as amino acid type and edges were defined similarly as ligand.

For PROTACs, we utilized the known-pocket unbound evaluation protocol from previous studies~\cite{drummondInSilicoModelingofPROTAC-MediatedTernaryComplexes2019,drummondImprovedAccuracyModeling2020,wengIntegrativeModelingPROTACMediated2021,ignatovHighAccuracyPrediction2023,raoBayesianOptimizationTernary2023}.  This protocol requires prior knowledge of the unbound structures of both anchor-E3 ligase and warhead-POI binary complexes during inference—a standard practice in PROTAC discovery. To integrate pocket information into DeepTernary, we introduced pocket embeddings for graph nodes associated with pockets. These embeddings were integrated into the node features by summation. During training, pocket node coordinates were replaced with their actual values (after random rotation and transformation), while during inference, pocket coordinates from unbound pockets were used. Note that we had ensured that the atom indexes of the unbound pockets and the candidate complexes were well aligned beforehand.

\subsection*{Model architecture}
\label{sec:method:architecture}


\modelName{} leverages an SE(3)-equivariant graph neural network along with the attention mechanism, allowing invariant message passing regarding the atom attributes and equivariant message passing regarding the atom coordinates. The model accepts inputs in various formats: the structures of two proteins (E3 ligase and PoI) in PDB or CIF format and the 2D geometry of the small molecule derived from SMILES strings or files in PDB, mol2, or structure-data file (SDF) format. Initially, the RDKit tool was employed to generate possible coordinates of the small molecule. Subsequently, the proteins and the ligand were represented as geometric graphs. The model is fundamentally composed of two primary components: the encoder and the decoder. The encoder learns SE(3)-invariant semantic features and SE(3)-equivariant coordinates, while the decoder outputs pocket points and predicted aligned errors. The comprehensive network architecture of \modelName{} was already depicted in Fig.~\ref{fig:overall}c.

\textbf{Encoder.} After obtaining the graph representations of the proteins and the ligand, we employed the Independent E(3)-Equivariant Graph Matching Network (IEGMN)~\cite{ganeaEquiDock2022} by extending its input from binary complex to ternary complex, in order to facilitate interactions among triplets. This extension involves a series of layers where node coordinates and feature embeddings were updated through both in-graph and cross-graph message passing. Unlike the original IEGMN, our extension allowed for feature updates in a triplet-wise fashion, enabling each monomer to update its features with the awareness of the other two monomers. The update of the coordinates maintains E(3)-equivariance, ensuring that the output faithfully mirrors any independent rotations and translations applied to the input.
Formally, there are totally $M$ encoder layers and the latent embedding $\vh_i^{l+1}$ and node coordinate $\vx_i^{l+1}$ at the ($l+1$)-th layer were computed as follows:

(1) Intra-graph message passing, which updates edge and node latent embeddings:
\begin{equation}
    \vm_{j\to i} = \phi^e(\vh_i^{(l)},\vh_j^{(l)},||\vx_i^{(l)}-\vx_j^{(l)}||^2,\vf_{j\to i}), \forall (i,j)\in\gE_{\mathrm{lig}}\cup\gE_{\mathrm{p1}}\cup\gE_{\mathrm{p2}},
\end{equation}

\begin{equation}
    \vm_i = \frac{1}{|\mathcal{N}(i)|} \sum_{j \in \mathcal{N}(i)}\vm_{j\to i}, \forall i \in \gV_{\mathrm{lig}}\cup\gV_{\mathrm{p1}}\cup\gV_{\mathrm{p2}},
\end{equation}

(2) Ternary inter-graph message passing: For the nodes of the ligand, the message from the nodes of the other two graphs $\gV_{\mathrm{p1}}\cup\gV_{\mathrm{p2}}$ was computed by
\begin{equation}
    a_{j\to i} = \frac{\mathrm{exp}(<\phi^q(\vh_i^{(l)}), \phi^k(\vh_j^{(l)})>)}{\sum_{j'\in \gV_{\mathrm{p1}}\cup\gV_{\mathrm{p2}}}\mathrm{exp}(<\phi^q(\vh_i^{(l)}), \phi^k(\vh_{j'}^{(l)})>)}, \forall i\in\gV_{\mathrm{lig}},
    \label{eq:attn_coef}
\end{equation}
\begin{equation}
    \mu_{j\to i} = a_{j\to i} \mW \vh_{j}^{(l)}, \mu_{i} =  \sum_{j\in \gV_{\mathrm{p1}}\cup\gV_{\mathrm{p2}}}\mu_{j\to i}, \forall i\in\gV_{\mathrm{lig}},
\end{equation}
We also derived cross-graph message $\mu_{i}$ for the nodes $\gV_{\mathrm{p1}}$ and $\gV_{\mathrm{p2}}$ similar to the above processes.

(3) Calculation of the new node coordinates and embeddings:
\begin{equation}
    \vx_i^{(l+1)} = \Psi\left(\vx_i^{(l)} + \sum_{j\in\gN(i)}\frac{\vx_i^{(l)}-\vx_j^{(l)}}{\|\vx_i^{(l)}-\vx_j^{(l)} \|}\phi^x(\vm_{j\to i})\right),
\end{equation}
\begin{equation}
    \vh_i^{(l+1)} = (1 - \beta) \cdot \vh_i^{(l)} + \beta \cdot \phi^h(\vh_i^{(l)},\vm_i,\mu_{i}, \vf_i), \forall i\in
    \gV_{\mathrm{lig}}\cup\gV_{\mathrm{p1}}\cup\gV_{\mathrm{p2}}.
\end{equation}
Here, $\phi^e, \phi^x, \phi^h, \phi^q, \phi^k$ denote multi-layer perceptrons (MLPs), $\vf_{j \to i}$ and $\vf_i$ represents the initial edge and node features (prior to processing through the IEGMN layers), separately, $\gN(i)$ collects all the neighbors of node $i$, $a_{j \to i}$ indicates the SE(3)-invariant cross-attention coefficient ($a_{i \to i}$ indicates the self-attention coefficient), $<\cdot>$ computes the inner product of two vectors, $\mW$ is a learnable matrix that transforms latent embeddings according to the cross-attention coefficients, $\Psi$ is a function that imposes distance geometric constraints~\cite{starkEquiBind2022}, and $\beta$ is a trade-off parameter. After the encoder process, the latent embeddings and coordinates of all nodes across the three graphs were updated to reflect the intricate interactions among the triple molecules. The predicted coordinates of the ligand ($\vx^l_i, \forall i \in \mathcal{V}_{lig}$) were assumed to represent the ligand's final conformation within the predicted ternary complex.


\added{Given a ternary complex composed of protein1, a ligand, and protein 2 (p1-lig-p2), the predicted structure should be invariant to the order of the proteins. In other words, the predicted structure should be the same regardless of whether the input is (p1-lig-p2) or (p2-lig-p1). To learn this symmetry, the two protein encoders are share parameters to learn generalize protein features. During training, the p1 and p2 were randomly swapped for data augmentation.}

\textbf{Decoder.} For the prediction of ternary structures, we use the ligand conformation derived from IEGMN and require two pairs of pocket points to rigidly align the second protein (protein2) and the ligand with the first protein (protein1), forming a complex. Additionally, the model must predict the predicted alignment error (PAE) for protein2 to assess the quality of the prediction. To this end, we designed a Transformer-based decoder to extract necessary information from graph embeddings. We designed two different decoders for MG(D)s and PROTACs owing to their different MOAs.

Specifically, for MG(D)s, we defined \added{two pairs of pocket points}: ( $\gP_{\mathrm{lig}}, \gP_{\mathrm{p1\rightarrow lig}}$) and ($\gP_{\mathrm{p2}}, \gP_{\mathrm{p1\rightarrow p2}}$). The first pair represents the pocket points between the ligand and protein1, where $\gP_{\mathrm{lig}}$ denotes the ligand pocket bound to protein1, and $\gP_{\mathrm{p1\rightarrow lig}}$ denotes the protein1 pocket bound to the ligand. Similarly, the second pair represents the pocket points between protein2 and protein1, with $\gP_{\mathrm{p2}}$ denoting the protein2 pocket bond to protein1, and $\gP_{\mathrm{p1\rightarrow p2}}$ denoting the protein1 pocket bond to protein2.
Their corresponding queries are matrices $\mQ_{\mathrm{lig}}, \mQ_{\mathrm{p1\rightarrow lig}}, \mQ_{\mathrm{p2}}, \mQ_{\mathrm{p1\rightarrow p2}}$, each row of which denotes the query of each node. In addition, we denote the PAE query as $\vq_{\mathrm{PAE}}$. All these values were initialized randomly and processed through an $N$-layer decoder. Each layer requires to compute the attention function, represented as $\mathrm{Attn}(\mQ, \mK, \mV)$:
\begin{equation}
    \mathrm{Attn}(\mQ, \mK, \mV) = a(\mQ,\mK)\mW\mV,
\end{equation}
where $\mQ, \mK$ and $\mV$ represent the querie, key, and value matrices, respectively; $a(\mQ, \mK)$ returns the attention matrix, and its element of the $i$-th row and $j$-th column was given by the attention coefficient $a_{j \to i}$ defined in Eq.~\ref{eq:attn_coef}. When $\mQ, \mK$ and $\mV$ become the same, we call it self-attention, otherwise, we call it cross-attention.

We now introduce how to process the queries $\mQ_{\mathrm{lig}}, \mQ_{\mathrm{p1\rightarrow lig}}, \mQ_{\mathrm{p2}}, \mQ_{\mathrm{p1\rightarrow p2}}$ and $\vq_{\mathrm{PAE}}$, with the information of the hidden embeddings obtained from the encoder before. We first conducted column-wise concatenation:
\begin{equation}
    \mQ =
    \mQ_{\mathrm{lig}} \|
    \mQ_{\mathrm{p1\rightarrow lig}} \|
    \mQ_{\mathrm{p2}} \|
    \mQ_{\mathrm{p1\rightarrow p2}} \|
    \vq_\mathrm{PAE},
\end{equation}
where $\|$ denotes column-wise concatenation. For conciseness, we collect the updated coordinates and embeddings of the final layer in the encoder over all nodes as $\mX$ and $\mH$ henceforth. Specifically for $\mH$ we further involved the graph embedding features $\ve$ in order to distinguish the graph identity:
\begin{equation}
    \mH =
    \left(\|_{i\in \gV_{\mathrm{lig}}}(\vh_i + \ve_{\mathrm{lig}})\right) \|
    \left(\|_{j\in \gV_{\mathrm{p1}}}(\vh_j + \ve_{\mathrm{p1}}) \right)\|
    \left(\|_{k\in \gV_{\mathrm{p2}}}(\vh_k + \ve_{\mathrm{p2}})\right),
\end{equation}
Then the pocket queries $\mQ$ were updates with the following attention layer:
\begin{equation}   % self-attention
\label{eq:Q-first}
    \mQ = \mathrm{Attn}(\mQ,\  \mQ,\  \mQ),
\end{equation}
\begin{equation}    % cross-attention
    \mQ' = \phi(\mathrm{Attn}(\mQ,\  \mH,\  \mH)),
\end{equation}
\begin{equation}    % cross-attention
    \mH' = \mathrm{Attn}(\mH,\  \mQ',\  \mQ').
\end{equation}
where $\phi$ is a learnable MLP. We repeated the above attention layer several times. The final queries and embeddings were unfolded as:
\begin{equation}
\label{eq:Q-final}
    \mQ'' = \phi(\mathrm{Attn}(\mQ',\  \mH', \ \mH')).
\end{equation}
\begin{equation}
    \mQ_{\mathrm{lig}},
    \mQ_{\mathrm{p1\rightarrow lig}},
    \mQ_{\mathrm{p2}},
    \mQ_{\mathrm{p1\rightarrow p2}},
    \vq_\mathrm{PAE} = \mathrm{unfold}(\mQ''),
\end{equation}
\begin{equation}
    \mH_\mathrm{lig}, \ \mH_\mathrm{p1}, \ \mH_\mathrm{p2} = \mathrm{unfold}(\mH').
\end{equation}

For the pocket coordinates, we first computed the attention values between the queries of each local pocket and the embeddings of the corresponding global graph. We then derived the coordinate of each pocket atom as a weighted sum of the coordinates of the entire graph. Specifically, we computed:
\begin{align}
  \mP_{\mathrm{lig}} &= a(\mQ_{\mathrm{lig}}, \mH_{\mathrm{lig}}) \mX_{\mathrm{lig}}, \\
  \mP_{\mathrm{p1}\rightarrow\mathrm{lig}} &= a(\mQ_{\mathrm{p1}\rightarrow\mathrm{lig}}, \mH_{\mathrm{p1}}) \mX_{\mathrm{p1}}, \\
    \mP_{\mathrm{p2}} &= a(\mQ_{\mathrm{p2}}, \mH_{\mathrm{p2}})\mX_{\mathrm{p2}}, \\
    \mP_{\mathrm{p1}\rightarrow\mathrm{p2}} &= a(\mQ_{\mathrm{p1}\rightarrow\mathrm{p2}}, \mH_{\mathrm{p1}}) \mX_{\mathrm{p1}},
\end{align}
where the matrices $\mP$ denote the predicted pocket point coordinates.

The PAE $\vq_{\mathrm{PAE}}$ was estimated using an MLP, reflecting the prediction confidence. Given the computational intensity of real-time DockQ score calculations, we use the Root-Mean-Square Deviation (RMSD) between predicted and actual coordinates of protein2 as a training surrogate for PAE. With predicted pocket points and the ligand conformation, the final ternary complex structure is assembled, which will be detailed in the next subsection.

For PROTACs, we directly bound the two proteins at their two ends, and designed two protein-ligand pocket coordinates: ( $\mP_{\mathrm{p1}}, \mP_{\mathrm{lig\rightarrow p1}}$) and ($\mP_{\mathrm{p2}}, \mP_{\mathrm{lig\rightarrow p2}}$), representing pockets of (E3, anchor) and (POI, warhead), respectively. Different from MG(D)s, these pocket points are already known from the unbound structures. Thus, without the need of the computations above derived for MG(D)s,
$\mP_{\mathrm{p1}}$ and $\mP_{\mathrm{p2}}$ were directly taken from the unbound protein structures, $\mP_{\mathrm{lig\rightarrow p1}}$ and $\mP_{\mathrm{lig\rightarrow p2}}$ were taken from the predicted ligand coordinates $\mX$ from the encoder according to unbounded pocket masks.
The decoder predicts the PAE for PROTACs using the same architecture but with only the PAE query reserved. In other words, we conducted \autoref{eq:Q-first} - \autoref{eq:Q-final} by setting $ \mQ = \vq_{\mathrm{PAE}}$.



\subsection*{Transformation to generate the final output}
\label{sec:transform_final_output}
Considering the different modes of action of PROTAC and MGD, we adopted two slightly different ways to construct the final complex structure. PROTAC molecules comprise three elements: the anchor, warhead, and connecting linker. The anchor and warhead are typically selected from known bounded ligands to E3 ligase and the POI, respectively. This selection facilitates rational design, leveraging existing unbound binding data between the anchor and E3, as well as the warhead and PoI, to construct the complex structure. Following this process, the PROTAC was first aligned with the unbound pocket of E3 (protein1) based on the predicted pocket points for the anchor. The linker and warhead coordinates were determined according to the conformation of the PROTAC. Subsequently, the coordinates of POI (protein2) were determined by aligning its unbound structures to the aligned warhead positions according to predicted protein2 pocket points:

\begin{align}
    \mR_{\mathrm{lig}}, \vt_{\mathrm{lig}} &= \mathrm{kabsch}(\mP_\mathrm{lig \rightarrow p1}, \mP_\mathrm{p1}), \\
    \vx_\mathrm{lig} &= (\mR_{\mathrm{lig}} \ \vx_\mathrm{lig}^\top)^\top + \vt_{\mathrm{lig}}, \\
    \mP^{'}_\mathrm{lig\rightarrow p2} &= (\mR \ \mP_\mathrm{lig\rightarrow p2}^\top)^\top + \vt, \\
    \mR_{\mathrm{p2}}, \vt_{\mathrm{p2}} &= \mathrm{kabsch}(\mP_\mathrm{p2}, \mP^{'}_\mathrm{lig\rightarrow p2}), \\
    \vx_\mathrm{p2} &= (\mR_{\mathrm{p2}} \ \vx_\mathrm{p2}^\top)^\top + \vt_{\mathrm{p2}},
\end{align}
where $\mathrm{kabsch}$ denotes the Kabsch algorithm~\cite{kabsch1976solution}, $^\top$ denotes matrix transpose.

A more direct alignment approach was employed for MG(D)s. Both the ligand and protein2 were aligned directly to protein1. This was achieved by predicting the pocket points of interaction between protein1 and the ligand, as well as between protein1 and protein2. The decoder's predicted pocket points facilitated the alignment of the ligand and protein2 to protein1, resulting in the final ternary complex structure:
\begin{align}
\mR_{\mathrm{lig}}, \vt_{\mathrm{lig}} &= \mathrm{kabsch}(\mP_\mathrm{lig}, \mP_\mathrm{p1 \rightarrow lig}), \\
\vx_\mathrm{lig} &= (\mR_{\mathrm{lig}} \ \vx_\mathrm{lig}^\top)^\top + \vt_{\mathrm{lig}},  \\
\mR_{\mathrm{p2}}, \vt_{\mathrm{p2}} &= \mathrm{kabsch}(\mP_\mathrm{p2}, \mP_\mathrm{p1 \rightarrow p2}),  \\
\vx_\mathrm{p2} &= (\mR_{\mathrm{p2}} \ \vx_\mathrm{p2}^\top)^\top + \vt_{\mathrm{p2}}.
\end{align}


\subsection*{Training and inference}
During the training process, protein structures were derived from bound structures and ligand conformations generated by the RDKit toolkit~\cite{landrum2013rdkit}. \added{For each training ligand, we pre-generated a pool of 50 random conformations.} In each training iteration, protein1 or protein2 was randomly fixed, while the other protein and \added{a randomly selected conformation from the ligand's 50-conformation pool} were subjected to random rotations and translations from their original positions.  Coordinates were normalized before being input into the model to stabilize the training process, with random noise added to graph features and coordinates to avoid overfitting.

The model was trained with six losses to guide it towards generating accurate outputs. The total loss is formulated as follows:

\begin{equation}
    \Ls = \Ls_{\mathrm{lig}} + \Ls_{\mathrm{kabsch\_lig}} + \Ls_{\mathrm{ot1}} + \Ls_{\mathrm{ot2}} + \Ls_{\mathrm{intersection}} + \Ls_\mathrm{PAE}.
\end{equation}
where $\Ls_\mathrm{lig}$ indicated the mean squared error (MSE) loss between the predicted and ground-truth ligand coordinates, and $\Ls_\mathrm{kabsch\_lig}$ denoted the MSE loss after rigid alignment of the predicted ligand to the ground truth using Kabsch algorithm~\cite{kabsch1976solution}. $\Ls_\mathrm{ot1}$ and $\Ls_\mathrm{ot2}$ corresponded to the optimal transport loss~\cite{flamary2021pot} between the predicted pocket points and target pocket coordinates.  $\Ls_\mathrm{intersection}$ represented intersection punishment between proteins and the ligand, and $\Ls_\mathrm{PAE}$ indicated the predicted aligned error of protein2, calculated using the L1 loss between the predicted and ground-truth RMSD of protein2.

During inference, unbound structures were used for PROTACs and bound structures for MG(D)s. The initial ligand conformations were randomly generated by RDKit using different seeds. For each PROTAC, we performed 40 samplings and ranked results based on predicted PAEs. For molecule glues, only one sampling was performed due to their limited atom numbers and conformational flexibility.

\modelName{} contains 16.73 million parameters and was trained for about five hours on four Nvidia V100 GPUs.


\subsection*{Calculation of buried surface area (BSA)}

The buried surface area (BSA) was calculated using ChimeraX \cite{chimerax}. Ligands were assigned unique sequence IDs separate from proteins, and the "interfaces" command computed solvent-accessible surface area (SASA) for each interacting chain pair within the complexes.
The total BSA was determined by summing the SASA values across all protein-protein and protein-ligand interactions. The BSA represented in Fig.~\ref{fig:bsa} is the average BSA of the top five most confident (lower PAE) predictions from DeepTernary.


\subsection*{Evaluation metrics}
\label{sec:metrics}

Following recent studies~\cite{wengIntegrativeModelingPROTACMediated2021,raoBayesianOptimizationTernary2023}, we adopted the \textbf{DockQ score}~\cite{basuDockQ2016} as a quantitative measure to evaluate prediction quality. The DockQ score is a continuous metric ranging from 0 to 1, calculated based on three components: F\textsubscript{nat}, LRMS, and iRMS. F\textsubscript{nat} represents the fraction of native contacts maintained in the predicted complexes. LRMS is the root mean square deviation (RMSD) between backbone atoms after aligning the predicted structure to the native one. iRMS is the RMSD of backbone atoms of the interface residues. By integrating these three criteria, the DockQ score provides a comprehensive measure of prediction quality, with higher values indicating higher-quality predictions.

To compare our methods with previously published approaches, we also calculated the fraction of acceptable predictions and compared them with other methods. It is worth noting that the criteria for an ``acceptable" prediction vary across different studies. We categorize these criteria as follows:

\textbf{DockQ \textgreater{} 0.23}: This threshold indicates a quality prediction based on the DockQ scoring system.

\textbf{CAPRI criterion}: Derived from the Critical Assessment of Predicted Interaction (CAPRI)~\cite{Méndez_CAPRI_2005}), predictions are classified into  High, Medium, or Acceptable. This criterion has been employed to assess the quality of PROTAC-induced complex predictions, as used by Drummond \etal~\cite{drummondImprovedAccuracyModeling2020}.

\textbf{RMSD \textless{} 10 \AA{}}: This criterion involves calculating the C$\alpha$ RMSD and is commonly used as the upper limit for an "acceptable" pose in protein-protein docking contexts. It is straightforward and easy to compute.



\added{
For PROTACs, given the model's generation of multiple predictions from varying initial conformations, we employ the \textbf{Acceptable Rank} metric, following existing methods. This metric is determined by sorting predictions based on their predicted alignment error (PAE) and identifying the rank of the first prediction achieving a DockQ score greater than 0.23.}

By applying these metrics, we ensure a robust evaluation of our model's performance in predicting ternary complex structures.




\section*{Declarations}

\bmhead{Data Available}
The TernaryDB complex list and cluster results of the training dataset, training log, pre-trained model weights and unbound structures for PROTAC testing are available at \url{https://github.com/youqingxiaozhua/DeepTernary}. The complex crystal structures are downloaded from the Protein Data Bank at \url{https://www.rcsb.org/}. Source Data are provided with this paper.


\bmhead{Code Available}
Codes for running DeepTernary have been released on GitHub and are free for academic, personal, and commercial use at \url{https://github.com/youqingxiaozhua/DeepTernary}.


\bmhead{Acknowledgements}
We thank Yaoyukun Jiang and Yifan Sun for their helpful discussions. W.H. was jointly supported by the following projects: the National Science and Technology Major Project under Grant 2020AAA0107300, the National Natural Science Foundation of China (No. 62376276); Beijing Nova Program (No. 20230484278); Beijing Outstanding Young Scientist Program (No. BJJWZYJH012019100020098); the Fundamental Research Funds for the Central Universities, and the Research Funds of Renmin University of China (23XNKJ19); Public Computing Cloud, Renmin University of China.
W.D. was supported by the Whitcome fellowship and the Molecular Biology Interdepartmental graduate program at UCLA. J.A.W. was supported by National Institutes of Health grant R01 GM089778 and GM112763 and the David Geffen School of Medicine at UCLA. Computational facilities were provided by the UTS Interactive High-Performance Computer Cluster.


\bmhead{Author contributions statement}
F.X., W.H., and W.D. conceived the study. F.X. wrote the code and trained the model. F.X. and M.Z. collected and processed training data. All authors contributed to the analysis of the results. F.X., M.Z., W.H., and W.D. wrote the manuscript. W.H., Y.Y., and W.D. offered supervision throughout the project. All authors revised the manuscript.




\bibliography{bibliography}





\newpage


\begin{appendices}

\renewcommand{\tablename}{Supplementary Table}
\renewcommand{\figurename}{Supplementary Figure}
\setcounter{table}{0}
\setcounter{figure}{0}

\section{Supplementary Materials}


\subsection{Model selection on the validation set}
\label{sec:supp-model-selection}
\added{
For model selection during training, we evaluated model performance on a validation set comprising curated structures dissimilar to the training set but also not in the test set. After training, a single scalar Validation Performance Score (VPS) is calculated via a arithmetic mean of the DockQ scores for the top-ranked prediction based on PAE ($D_{\mathrm{top\text{-}1}}$) and the best overall prediction ($D_{\mathrm{best}}$):
}
\begin{equation}
\mathrm{VPS} = (D_{\mathrm{top\text{-}1}} + D_{\mathrm{best}}) / 2
\end{equation}

\added{where $D$ represents the DockQ score between the predicted and ground-truth crystal structures. Despite its simple definition, VPS assesses both structure and confidence accuracy.
}

\added{
The model's performance on the validation set is summarized in Supplementary Tab.~\ref{tab:supp-validation}. Unlike the PROTAC, the performance on MG(D) plateaued with increasing seed numbers. To balance performance and computational cost, we used a single seed for MG(D) evaluation, resulting in $\mathrm{VPS} = D_{\mathrm{top\text{-}1}} = D_\mathrm{best} $.
}

\begin{table}[h]
\centering
\label{tab:supp-validation}
\caption{\added{Results on the validation set for model selection. The highest VPS for each hyper-parameter is marked in bold.  `=' denotes $D_\mathrm{best} = D_{\mathrm{top\text{-}1}}$ for MG(D)s, because only one seed is used for evaluation.}}
\begin{tabular}{cccccccc}
\toprule
    & \multicolumn{3}{c}{PROTAC}                                                             & \multicolumn{3}{c}{MG(D)}       & \multicolumn{1}{c}{\multirow{2}{*}{Mean VPS}}      \\ \cmidrule(lr){2-4} \cmidrule(lr){5-7}
    & \multicolumn{1}{c}{$D_{\mathrm{top\text{-}1}}$} & \multicolumn{1}{c}{$D_{\mathrm{best}}$} & \multicolumn{1}{c}{VPS}   & \multicolumn{1}{c}{$D_{\mathrm{top\text{-}1}}$} & \multicolumn{1}{c}{$D_{\mathrm{best}}$} & \multicolumn{1}{c}{VPS} & \multicolumn{1}{c}{}  \\ \hline
dim64  & 29.99   & 68.17  & 49.08            & 10.97 & =     & 10.97  & 30.03   \\
dim128 & 31.49   & 66.60  & 49.05            & 10.14 & =     & 10.14  & 29.59   \\
dim256 & 39.97   & 68.40  & 54.19   & 22.56 & =     & 22.56  & \textbf{38.37}   \\   \hline
noise1 & 25.32   & 70.19  & 47.76            & 22.01 & =     & 22.01  & 34.88   \\
noise2 & 39.97   & 68.40  & 54.19            & 22.56 & =     & 22.56  & \textbf{38.37}   \\
noise3 & 41.43   & 67.46  & 54.45   & 19.72 & =     & 19.72  & 37.08   \\ \hline
seed1  & 33.93   & 33.93  & 33.93            & 22.56 & =     & 22.56  & 28.25   \\
seed5  & 29.09   & 45.58  & 37.34            & 22.71 & 23.3  & 23.30  & 30.32   \\
seed10 & 37.02   & 56.86  & 46.94            & 22.83 & 23.63 & 23.63  & 35.29   \\
seed20 & 39.42   & 61.12  & 50.27            & 22.89 & 23.82 & 23.82  & 37.05   \\
seed30 & 38.93   & 68.19  & 53.56            & 22.86 & 23.89 & 23.89  & 38.73   \\
seed40 & 39.97   & 68.40  & 54.19   & 22.73 & 23.94 & 23.94  & \textbf{39.06}    \\ \bottomrule
\end{tabular}
\end{table}


\subsection{Reproducibility study}
To assess the reproducibility of our method, we retrained the model five times using different random seeds (0, 1, 2, 3, and 4) for both model initialization and data sampling. Tab.~\ref{tab:supp-reproducibility} summarizes the results, including mean, standard deviation, and range for each evaluated metric. Notably, the standard deviations are 3.50 for PROTAC top-1 DockQ, 1.36 for PROTAC best DockQ, and 1.47 for MG(D) top-1 DockQ. The largest variation was observed in the PROTAC top-1 DockQ metric, which ranged from 28.02 to 38.05. We also found that the RDKit version has a significant impact on performance; the results in Tab.~\ref{tab:supp-reproducibility} were obtained using \texttt{rdkit==2023.9.3}.

\subsection{Ligand pose accuracy}
In the main manuscript, we reported the DockQ score for ternary complexes following established studies. Although the DockQ score only assesses protein-protein docking performance, it depends on accurate ligand positioning for the ternary complexes. For example, as shown in the manuscript Fig.~\ref{fig:protac}f, complexes with the same protein pairs (e.g. PDB IDs 6W7O and 6W8I) can exhibit notable structural differences due to the variations in the PROTAC molecules. This observation is further supported by our analysis of BSAs in the BRD4-VHL and CRBN-BTK systems.

To directly evaluate ligand docking accuracy, we calculated the RMSD between the predicted ligand positions and their corresponding crystal structures. We report both the RMSD for the top-ranked prediction (based on predicted alignment error, PAE) and the best RMSD observed across all generated conformations. For PROTACs, the mean top-ranked RMSD is 3.43 Å, with 43\% of predictions achieving an RMSD below 2 Å. By contrast, MG(D) predictions exhibit a significantly higher mean top-ranked RMSD of 13.14 Å, with only 1.9\% of predictions falling below 2 Å. These results underscore the substantial challenge in accurately predicting MGD binding poses and highlight the need for further methodological development in this area.


\begin{table}
\centering
\label{tab:supp-reproducibility}
\caption{\added{Reproducibility study of model performance across five training runs with different random seeds. Reported are the mean, standard deviation, minimum, and maximum values for key performance metrics.}}
\begin{tabular}{cccc}
\toprule
      & \multicolumn{2}{c}{PROTAC} & MGD        \\ \cmidrule(lr){2-3} \cmidrule(lr){4-4}
      & Top-1 DockQ   & Best DockQ  & Top-1 DockQ \\ \hline
Seed0 & 29.54        & 67.21       & 22.34      \\
Seed1 & 28.02        & 65.73       & 18.89      \\
Seed2 & 38.05        & 64.74       & 22.61      \\
Seed3 & 31.22        & 66.23       & 21.85      \\
Seed4 & 33.5         & 63.22       & 19.85      \\ \hline
Mean  & 32.07        & 65.43       & 21.11      \\
Std   & 3.50         & 1.36        & 1.47       \\
Min   & 28.02        & 63.22       & 18.89      \\
Max   & 38.05        & 67.21       & 22.61     \\
\bottomrule
\end{tabular}
\end{table}


\begin{figure}
\centering
\includegraphics[width=\linewidth,page=1]{imgs/figure-revision1.pdf}
\caption{\added{Ligand pose accuracy on the test set of  (\textbf{a}) PROTAC and (\textbf{b}) MG(D).
}}
\label{sup:fig:lig_accuracy}
\end{figure}



\subsection{Comparison with AlphaFold3 and Chai-1}

During the submission period of this work, AlphaFold3 (AF3)~\cite{abramsonAF32024} and Chai-1~\cite{discoveryChai-12024} were proposed to tackle joint structure prediction, with both models capable of handling complexes involving proteins and small molecules. However, their training datasets differ from ours—AF3 was trained on PDB entries released before September 30, 2021, while Chai-1 used a cutoff of January 12, 2021—resulting in the inclusion of some of our test samples. To ensure a fair comparison, we filtered out PROTAC and MG(D) test clusters that were present in the training data of AF3 and Chai-1.

For PROTACs, three test complexes (7JTO\_L\_B\_VKA, 7JTP\_L\_A\_X6M, and 7Q2J\_C\_D\_8KH) were not part of AF3’s training set. We then performed MSA and template searches (to align with our unbound prediction setting as much as possible) and generated 40 predictions for each complex using different random seeds. The best DockQ scores for these three complexes were 0.12, 0.25, and 0.48 with AF3, compared to 0.56, 0.67, and 0.53 with our model (Tab.~\ref{tab:sub:af3}), indicating a clear decrease in performance of AF3. It is also worth noting that AF3 was trained on other 19 test complexes whereas our model never seen PROTAC-like structures during training. Furthermore, one complex (7KHH\_C\_D\_WEP) was not included in Chai-1’s training data; although Chai-1 achieved a high DockQ score of up to 0.81 on this complex, its performance on other PROTAC complexes was inferior.

For MG(D)s, all test set clusters were included in AF3’s training data—either directly or through highly similar samples. As a result, AF3 achieved a high mean DockQ score of 0.52 on the MG(D) test set, based on one sampled random ligand conformation. There was only one MG(D) complex 7LRD\_B\_A\_X5M that is not trained by Chai-1. For this complex, Chai-1 produced a DockQ score of just 0.009 compared to 0.014 from our method.

These results indicate that despite the greater resources used to train Chai-1 and AF3, their poor performance on unseen PROTAC and MG(D) complexes highlights the superior generalization capability of our model.

\begin{table}
\centering
\caption{Comparison of DockQ with Chai-1 and AlphaFold3 (AF3) on the PROTAC test set. Our DeepTernary illustrates great generalization to unseen PROTAC and MG(D). – indicates that AF3 is trained on this complex cluster.}
\label{tab:sub:af3}
\begin{tabular}{ccccccc}
\toprule
Type                    & Complex ID      & Chai-1        & AF3 & DeepTernary    &  &   \\ \midrule
\multirow{4}{*}{PROTAC} & 7JTP\_L\_A\_X6M & 0.40          & 0.25 & \textbf{0.67}  &  &   \\
                        & 7JTO\_L\_B\_VKA & 0.04          & 0.12 & \textbf{0.56}  &  &   \\
                        & 7Q2J\_C\_D\_8KH & 0.06          & 0.48 & \textbf{0.53}  &  &   \\
                        & 7KHH\_C\_D\_WEP & \textbf{0.81} & -    & 0.38           &  &   \\ \midrule
MG(D)                   & 7LRD\_B\_A\_X5  & 0.009         & -    & \textbf{0.014} &  &   \\
\bottomrule
\end{tabular}
\end{table}


\subsection{PAE can be used as a confidence score for screening}

Fig.~\ref{sup:fig:paevsdockq} illustrates the correlation between DockQ scores and PAE values for both intra- and inter-complex predictions of PROTACs and MG(D)s. Overall, our results reveal a strong negative correlation—complexes with lower PAE scores tend to exhibit higher DockQ scores, reflecting more accurate predictions. Although several cases (e.g., 6BN7\_B\_C\_RN3, 6BOY\_B\_C\_RN6, 6HAX\_B\_A\_FWZ, 6HAY\_F\_E\_FX8, 6W7O\_C\_A\_TL7, and 6ZHC\_A\_D\_QL8) do not show a clear trend, the overall pattern supports the use of PAE scores as a reliable confidence metric and an effective filter for selecting high-quality predictions in drug discovery applications.




\begin{figure}
\centering
\includegraphics[width=\linewidth,page=3]{imgs/figure-revision1.pdf}
\caption{\added{\textbf{Correlation between PAE and DockQ scores for predicted ternary complexes.}
\textbf{a, }Intra-complex correlation for PROTACs. Scatter plots illustrate the relationship between PAE and DockQ scores across 40 initial conformations for each PROTAC test complex. Each point represents a single conformation. Most complexes display a negative correlation, indicating that lower PAE values generally correspond to higher DockQ scores. This suggests that PAE can serve as a useful indicator of prediction accuracy within a given complex.
\textbf{b, }Scatter plot for the best-predicted conformation (i.e., the one with the highest DockQ) for each PROTAC test complex. The plot demonstrates a clear trend: complexes with PAE scores below 4 tend to have higher DockQ scores (\textgreater{} 0.5), further supporting the use of PAE as a confidence metric.
\textbf{c, }Across-Complex Correlation for top-1 PROTAC predictions (i.e., the predictions with the lowest PAE). Despite some false positives, the overall trend remains negatively correlated.
\textbf{d, }Correlation for MG(D) predictions. Similar to PROTACs, a clear negative correlation is observed, with lower PAE values associated with higher DockQ scores, suggesting that PAE is also an effective confidence metric for MG(D) predictions.
}}
\label{sup:fig:paevsdockq}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=\linewidth,page=4]{imgs/figure-revision1.pdf}
\caption{\added{\textbf{Protein length distribution in the MG(D) training set.}
\textbf{a, }The joint distribution of sequence lengths for interacting chain pairs.
\textbf{b, }The overall distribution of sequence lengths across all chains.
The training set includes many proteins with sequence lengths between 200 to 600 residues, alongside a notable fraction of  shorter proteins (20 - 40 residues). Additionally, the joint distribution reveals that the most common complex involves a longer protein interacting with a shorter protein--mirroring the characteristics of Group 2 complexes in the test set.
}}
\label{sup:fig:MGD_seq_length}
\end{figure}




\begin{table}
\centering
\caption{Comparison of SmRMSD on PROTACs. None indicates the item failed to generate an result.}
\label{tab:smRMSD}
\begin{tabular}{@{}c|cc|cc@{}}
\toprule
\multirow{2}{*}{PDB ID} & \multicolumn{2}{c}{Ignatov \etal \cite{ignatovHighAccuracyPrediction2023}} & \multicolumn{2}{c}{Ours} \\ \cmidrule(l){2-5}
         & SmRMSD   & Best Rank   & SmRMSD   & Best Rank   \\ \cmidrule(l){1-5}
5T35\_D\_A & 2.01 & 1    & 0.61 & 3    \\
5T35\_H\_E &      &      & 0.70 & 1    \\
6BN7\_B\_C & 2.19 & 3    & 1.02 & 5    \\
6BN8     & 2.21 & 1    &      &      \\
6BN9     & 1.35 & 1    &      &      \\
6BNB     & 1.63 & 5    &      &      \\
6BOY\_B\_C & 5.24 & 3    & 2.94 & 4    \\
6HAX\_B\_A & 1.56 & 2    & 1.83 & 3    \\
6HAX\_F\_E &      &      & 1.68 & 3    \\
6HAY\_B\_A & 1.29 & 5    & 1.60 & 2    \\
6HAY\_F\_E &      &      & 1.35 & 5    \\
6HR2\_B\_A & 1.52 & 6    & 1.27 & 4    \\
6HR2\_F\_E &      &      & 1.68 & 3    \\
6XHC     & None & None &      &      \\
6SIS\_D\_A &      &      & 0.67 & 5    \\
6SIS\_H\_E &      &      & 0.84 & 2    \\
6W7O\_C\_A &      &      & 2.70 & 2    \\
6W7O\_D\_B &      &      & 1.12 & 2    \\
6W8I\_F\_C &      &      & 3.67 & 3    \\
6W8I\_D\_A &      &      & 1.34 & 2    \\
6W8I\_E\_B &      &      & 1.62 & 4    \\
6ZHC\_A\_D &      &      & 4.21 & 3    \\
7JTO\_L\_B &      &      & 2.62 & 5    \\
7JTP\_L\_A & 1.86 & 6    & 1.34 & 5    \\
7KHH\_C\_D & 2.41 & 4    & 4.63 & 3    \\
7KHH\_2  &      &      &      &      \\
7Q2J\_C\_D &      &      & 2.59 & 1    \\
7PI4     & 1.97 & 4.00 &      &      \\ \hline
Mean     & 2.12 & 3.36 & 1.91 & 3.18 \\
\bottomrule
\end{tabular}
\end{table}




\begin{table}
\centering
\caption{Top-1 DockQ scores with different numbers of sampled random conformations on the PROTAC test set. The results are tested on the same checkpoint.}
\label{tab:supp:top1_dockq}
\begin{tabular}{cc}
\toprule
Sample Number & Top-1 DockQ  \\ \midrule
1             & 0.33         \\
10            & 0.37         \\
20            & 0.40         \\
40            & 0.40        \\ \bottomrule
\end{tabular}
\end{table}



\begin{figure}
\centering
\includegraphics[width=\linewidth,page=2]{imgs/figure-revision1.pdf}
\caption{\added{\textbf{Buried surface area (BSA) analysis of PROTAC-induced ternary complexes.} \textbf{a,} BSA distribution in the training dataset, showing a peak around 1000 \AA{}$^2$. \textbf{b,} BSA distribution for known PROTAC-induced complexes. \textbf{c,} Correlation between BSA and $ln(DC50)$ for BRD4-VHL and CRBN-BTK complexes, revealing an optimal BSA range for high degradation potential, rather than a linear relationship. The distinct BSA distribution in the training set compared to known complexes indicates the model learns generalizable principles beyond training set bias, suggesting its ability to predict degradation potential from predicted structures.
}}
\label{sup:fig:bsa}
\end{figure}



\begin{table}
\centering
\caption{Hyperparameters of the model.}
\begin{tabular}{ccc}
\toprule
Hyperparameter             & PROTAC & MG(D)  \\ \midrule
feature dim                & 256    & 256    \\
encoder depth              & 8      & 8      \\
decoder depth              & 1      & 4      \\
number of pocket points    & -      & 40     \\
noise initial              & 2      & 2      \\
batch size                 & 64     & 64     \\
optimizer                  & AdamW  & AdamW  \\
learning rate              & 1e-4   & 1e-4   \\
weight decay               & 1e-4   & 1e-4   \\
gradient clip              & 9      & 9      \\
number of epochs           & 1000   & 1000  \\ \bottomrule
\end{tabular}
\end{table}


\begin{figure}
\centering
\includegraphics[width=\linewidth,page=1]{imgs/AF3_result.png}
\caption{
Predicted structure of 7BQU\_A\_B from AlphaFold3, shown with pLDDT scores from two viewing angles. The Predicted Aligned Error (PAE) is displayed on the right.
}
\label{tab:hyperparameters}
\end{figure}



\begin{table}
\centering
\caption{\added{\textbf{DeepTernary Forward Pass Time.}
The execution times reported in the main manuscript include both the model's forward pass time and the time required for data preprocessing.  This table specifically presents the forward pass time to allow for a more detailed analysis of model performance.  *For PROTAC calculations, 40 conformations were used for each test sample. }}
\label{tab-supp-forward-time}
\begin{tabular}{ccc}
\toprule
Time (s)             & w/o GPU & w/ GPU  \\ \midrule
PROTAC*                & 4.79    & 1.85    \\
MG(D)              & 0.15      & 0.05      \\ \bottomrule
\end{tabular}
\end{table}

\end{appendices}


\end{document}
