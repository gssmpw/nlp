\section{Proposed Metric: \textit{NovelSum}}
Extending previous findings, we derive some insights on how to design a more reliable metric: (1) \textbf{The uniqueness of individual samples should be a key factor in measuring dataset diversity.} This uniqueness stems from sufficient inter-sample distances, providing diverse information that helps the model learn more generalized patterns. (2) \textbf{When quantifying a sample's uniqueness, its distance to nearby and distant samples should be balanced.} Differences with nearby samples define uniqueness and should hold greater importance, with weights assigned smoothly. (3) \textbf{When calculating inter-sample distances, both semantic differences and local information density should be considered.} In practical applications of instruction fine-tuning, semantic space varies in information density, with scenarios like math and code having denser data and information. Focusing only on semantics overlooks valuable fine-grained information for the model.

Following these principles, we introduce \textit{NovelSum}, a diversity metric that jointly considers distance and distribution. Specifically, we define dataset diversity as the sum of each sample's uniqueness---its unique contribution to overall information, which we later term "novelty":
\begin{equation}
\label{eq:def}
    \mathcal{M}_{NovelSum}(\mathcal{X}) = \sum_{x_i \in \mathcal{X}} v(x_i)
\end{equation}
Figure \ref{fig:novelsum} and the following paragraphs illustrate how each sample's novelty is computed.

\paragraph{Proximity-Weighted Sum}
In contrast to \textit{DistSum}, which calculates a sampleâ€™s uniqueness as a simple sum of distances to other points, we propose a proximity-weighted sum. This method assigns higher weights to closer points, giving them a larger influence on the uniqueness score:
\begin{equation}
\label{eq:pws}
    v(x_i) = \sum_{x_j \in \mathcal{X},\ x_j \neq x_i} w(x_i, x_j)^{\alpha} \cdot \Delta(x_i, x_j),
\end{equation}
where the proximity weight is defined as:
\begin{equation*}
    w(x_i, x_j) = \phi(\pi_i(j))
\end{equation*}
Here, \( \pi_i(j) \) is the rank of \( x_j \) in the sorted list of distances from \( x_i \) to all other points in \( \mathcal{X} \), with \( \pi_i(j) = 1 \) indicating that \( x_j \) is the nearest neighbor of \( x_i \). The function \( \phi(\cdot) \) is monotonically decreasing, smoothing the weights according to the proximity, for example, we set \( \phi(\pi_i(j)) = \frac{1}{\pi_i(j)} \). The hyperparameter \( \alpha \) controls the degree to which proximity impacts the uniqueness score.

\paragraph{Density-Aware Distance}
To account for the local information density when calculating \( \Delta(x_i, x_j) \), we introduce a density-aware distance that multiplies the original semantic distance by a density factor \( \sigma(x_j) \):
\begin{equation}
\label{eq:dad}
    \Delta(x_i, x_j) = \sigma(x_j)^{\beta} \cdot d(x_i, x_j)
\end{equation}
Since the probablistic density of the overall sample distribution is intractable, we approximate the density factor by the inverse of the average distance to the \( K \)-nearest neighbors of \( x_j \) in \( \mathcal{X}^{all} \):
\begin{equation*}
    \sigma(x_j) = \frac{1}{\sum_{k=1}^{K} d(x_j, N_k(x_j))}
\end{equation*}
Here, \( d(\cdot, \cdot) \) represents the distance between the embeddings of two samples (e.g., cosine distance), and \( N_k(x) \) denotes the \( k \)-th nearest neighbor of \( x \). The hyperparameter \( \beta \) controls the extent to which density influences the distance. 
The computational complexity is discussed in Appendix \ref{app:complexity}.

\begin{figure}[t!]
    \centering
        \includegraphics[width=\linewidth]{latex/figures/novelsum3_cropped.pdf}
    \caption{\textit{NovelSum} computes each sample's novelty as a proximity-weighted sum of its density-aware distances to other samples, where closer points have greater influence and high-density regions produce larger distances.}
    \label{fig:novelsum}
    \vspace{-2mm}
\end{figure}

This approach mirrors how novelty is assessed in academic papers: a paper's novelty depends on its difference from closely related work, and this difference should be considered within the context of its field for a more accurate measure. Therefore, we consider each sample's quantified uniqueness as "novelty" and name our approach "NovelSum."






