% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{li2024vision,
  title={Vision-language models in remote sensing: Current progress and future trends},
  author={Li, Xiang and Wen, Congcong and Hu, Yuan and Yuan, Zhenghang and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Magazine},
  year={2024},
  publisher={IEEE}
}

@article{dai2023instructblip,
  title={Instructblip: Towards general-purpose vision-language models with instruction tuning. arxiv 2023},
  author={Dai, Wenliang and Li, Junnan and Li, D and Tiong, AMH and Zhao, J and Wang, W and Li, B and Fung, P and Hoi, S},
  journal={arXiv preprint arXiv:2305.06500},
  volume={2},
  year={2023}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}

@article{hu2023rsgpt,
  title={Rsgpt: A remote sensing vision language model and benchmark},
  author={Hu, Yuan and Yuan, Jianlong and Wen, Congcong and Lu, Xiaonan and Li, Xiang},
  journal={arXiv preprint arXiv:2307.15266},
  year={2023}
}

@inproceedings{kuckreja2024geochat,
  title={Geochat: Grounded large vision-language model for remote sensing},
  author={Kuckreja, Kartik and Danish, Muhammad Sohail and Naseer, Muzammal and Das, Abhijit and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={27831--27840},
  year={2024}
}

@article{cheng2022nwpu,
  title={NWPU-captions dataset and MLCA-net for remote sensing image captioning},
  author={Cheng, Qimin and Huang, Haiyan and Xu, Yuan and Zhou, Yuzhuo and Li, Huanying and Wang, Zhongyuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--19},
  year={2022},
  publisher={IEEE}
}

@article{zhang2023rs5m,
  title={Rs5m: A large scale vision-language dataset for remote sensing vision-language foundation model},
  author={Zhang, Zilun and Zhao, Tiancheng and Guo, Yulong and Yin, Jianwei},
  journal={arXiv preprint arXiv:2306.11300},
  year={2023}
}

@article{liu2024remoteclip,
  title={Remoteclip: A vision language foundation model for remote sensing},
  author={Liu, Fan and Chen, Delong and Guan, Zhangqingyun and Zhou, Xiaocong and Zhu, Jiale and Ye, Qiaolin and Fu, Liyong and Zhou, Jun},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@article{zhang2024earthgpt,
  title={Earthgpt: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain},
  author={Zhang, Wei and Cai, Miaoxin and Zhang, Tong and Zhuang, Yin and Mao, Xuerui},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2024},
  publisher={IEEE}
}

@inproceedings{qu2016deep,
  title={Deep semantic understanding of high resolution remote sensing image},
  author={Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang},
  booktitle={2016 International conference on computer, information and telecommunication systems (Cits)},
  pages={1--5},
  year={2016},
  organization={IEEE}
}

@article{lu2017exploring,
  title={Exploring models and data for remote sensing image caption generation},
  author={Lu, Xiaoqiang and Wang, Binqiang and Zheng, Xiangtao and Li, Xuelong},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={56},
  number={4},
  pages={2183--2195},
  year={2017},
  publisher={IEEE}
}

@article{yuan2022exploring,
  title={Exploring a fine-grained multiscale method for cross-modal remote sensing image retrieval},
  author={Yuan, Zhiqiang and Zhang, Wenkai and Fu, Kun and Li, Xuan and Deng, Chubo and Wang, Hongqi and Sun, Xian},
  journal={arXiv preprint arXiv:2204.09868},
  year={2022}
}

@article{zhan2023rsvg,
  title={Rsvg: Exploring data and models for visual grounding on remote sensing data},
  author={Zhan, Yang and Xiong, Zhitong and Yuan, Yuan},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={61},
  pages={1--13},
  year={2023},
  publisher={IEEE}
}

@article{long2021creating,
  title={On creating benchmark dataset for aerial image interpretation: Reviews, guidances, and million-aid},
  author={Long, Yang and Xia, Gui-Song and Li, Shengyang and Yang, Wen and Yang, Michael Ying and Zhu, Xiao Xiang and Zhang, Liangpei and Li, Deren},
  journal={IEEE Journal of selected topics in applied earth observations and remote sensing},
  volume={14},
  pages={4205--4230},
  year={2021},
  publisher={IEEE}
}

@inproceedings{christie2018functional,
  title={Functional map of the world},
  author={Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6172--6180},
  year={2018}
}

@inproceedings{sumbul2019bigearthnet,
  title={Bigearthnet: A large-scale benchmark archive for remote sensing image understanding},
  author={Sumbul, Gencer and Charfuelan, Marcela and Demir, Beg{\"u}m and Markl, Volker},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={5901--5904},
  year={2019},
  organization={IEEE}
}

@inproceedings{li2024sardet100k,
title={SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection},
author={Yuxuan Li and Xiang Li and Weijie Li and Qibin Hou and Li Liu and Ming-Ming Cheng and Jian Yang},
year={2024},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS)},
}
%%%%%%%%%新增的数据集部分引用
@article{DBLP:journals/remotesensing/WangWZDW19a,
  author    = {Yuanyuan Wang and
               Chao Wang and
               Hong Zhang and
               Yingbo Dong and
               Sisi Wei},
  title     = {A {SAR} Dataset of Ship Detection for Deep Learning under Complex
               Backgrounds},
  journal   = {Remote. Sens.},
  volume    = {11},
  number    = {7},
  pages     = {765},
  year      = {2019},
  url       = {https://doi.org/10.3390/rs11070765},
  doi       = {10.3390/rs11070765},
}

@ARTICLE{9127939,
  author={Wei, Shunjun and Zeng, Xiangfeng and Qu, Qizhe and Wang, Mou and Su, Hao and Shi, Jun},
  journal={IEEE Access}, 
  title={HRSID: A High-Resolution SAR Images Dataset for Ship Detection and Instance Segmentation}, 
  year={2020},
  volume={8},
  number={},
  pages={120234-120254},
  keywords={Marine vehicles;Radar polarimetry;Image segmentation;Imaging;Synthetic aperture radar;Detectors;Image resolution;High-resolution SAR images dataset;ship detection;instance segmentation;deep learning;convolutional neural network},
  doi={10.1109/ACCESS.2020.3005861}}

@article{chen2022large,
  title={Large-scale multi-class SAR image target detection dataset-1.0 [OL]},
  author={Chen, Jie and Huang, Zhixiang and Xia, Runfan and Wu, Bocai and Sheng, Lei and Sun, Long and Yao, Baidong},
  journal={Journal of Radars},
  number={1},
  year={2022}
}

@Article{rs13183690,
AUTHOR = {Zhang, Tianwen and Zhang, Xiaoling and Li, Jianwei and Xu, Xiaowo and Wang, Baoyou and Zhan, Xu and Xu, Yanqin and Ke, Xiao and Zeng, Tianjiao and Su, Hao and Ahmad, Israr and Pan, Dece and Liu, Chang and Zhou, Yue and Shi, Jun and Wei, Shunjun},
TITLE = {SAR Ship Detection Dataset (SSDD): Official Release and Comprehensive Data Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {3690},
URL = {https://www.mdpi.com/2072-4292/13/18/3690},
ISSN = {2072-4292},
DOI = {10.3390/rs13183690}
}

@article{zhirui2023sar,
  title={SAR-AIRcraft-1.0: High-resolution SAR aircraft detection and recognition dataset},
  author={Zhirui, Wang and Yuzhuo, Kang and Xuan, Zeng and Yuelei, WANG and Ting, ZHANG and Xian, SUN},
  journal={Journal of Radars},
  volume={12},
  number={4},
  pages={906--922},
  year={2023},
  publisher={Journal of Radars}
}

@article{wang2019sar,
  title={A SAR dataset of ship detection for deep learning under complex backgrounds},
  author={Wang, Yuanyuan and Wang, Chao and Zhang, Hong and Dong, Yingbo and Wei, Sisi},
  journal={remote sensing},
  volume={11},
  number={7},
  pages={765},
  year={2019},
  publisher={MDPI}
}

@article{zhang2021sar,
  title={SAR ship detection dataset (SSDD): Official release and comprehensive data analysis},
  author={Zhang, Tianwen and Zhang, Xiaoling and Li, Jianwei and Xu, Xiaowo and Wang, Baoyou and Zhan, Xu and Xu, Yanqin and Ke, Xiao and Zeng, Tianjiao and Su, Hao and others},
  journal={Remote Sensing},
  volume={13},
  number={18},
  pages={3690},
  year={2021},
  publisher={MDPI}
}

@article{wang2023category,
  title={Category-oriented localization distillation for sar object detection and a unified benchmark},
  author={Wang, Chao and Ruan, Rui and Zhao, Zhicheng and Li, Chenglong and Tang, Jin},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  year={2023},
  publisher={IEEE}
}

@article{lin2023sived,
  title={SIVED: A SAR Image Dataset for Vehicle Detection Based on Rotatable Bounding Box},
  author={Lin, Xin and Zhang, Bo and Wu, Fan and Wang, Chao and Yang, Yali and Chen, Huiqin},
  journal={Remote Sensing},
  volume={15},
  number={11},
  pages={2825},
  year={2023},
  publisher={MDPI}
}

%%%%%%%%%%%%%%%%% 模型
@article{wang2024qwen2,
  title={Qwen2-vl: Enhancing vision-language model's perception of the world at any resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and others},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}

@article{chen2024expanding,
    title={Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling},
    author={Chen, Zhe and Wang, Weiyun and Cao, Yue and Liu, Yangzhou and Gao, Zhangwei and Cui, Erfei and Zhu, Jinguo and Ye, Shenglong and Tian, Hao and Liu, Zhaoyang and others},
    journal={arXiv preprint arXiv:2412.05271},
    year={2024}
  }

@misc{liu2023llava,
      title={Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      publisher={NeurIPS},
      year={2023},
}

@article{ye2024mplug,
  title={mplug-owl3: Towards long image-sequence understanding in multi-modal large language models},
  author={Ye, Jiabo and Xu, Haiyang and Liu, Haowei and Hu, Anwen and Yan, Ming and Qian, Qi and Zhang, Ji and Huang, Fei and Zhou, Jingren},
  journal={arXiv preprint arXiv:2408.04840},
  year={2024}
}

@misc{lu2024deepseekvl,
      title={DeepSeek-VL: Towards Real-World Vision-Language Understanding},
      author={Haoyu Lu and Wen Liu and Bo Zhang and Bingxuan Wang and Kai Dong and Bo Liu and Jingxiang Sun and Tongzheng Ren and Zhuoshu Li and Hao Yang and Yaofeng Sun and Chengqi Deng and Hanwei Xu and Zhenda Xie and Chong Ruan},
      year={2024},
      eprint={2403.05525},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Aneja, Jyoti and Awadalla, Hany and Awadallah, Ahmed and Awan, Ammar Ahmad and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Bao, Jianmin and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@article{glm2024chatglm,
  title={Chatglm: A family of large language models from glm-130b to glm-4 all tools},
  author={GLM, Team and Zeng, Aohan and Xu, Bin and Wang, Bowen and Zhang, Chenhui and Yin, Da and Zhang, Dan and Rojas, Diego and Feng, Guanyu and Zhao, Hanlin and others},
  journal={arXiv preprint arXiv:2406.12793},
  year={2024}
}

@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Wang, Guoyin and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@INPROCEEDINGS{7546397,
  author={Qu, Bo and Li, Xuelong and Tao, Dacheng and Lu, Xiaoqiang},
  booktitle={2016 International Conference on Computer, Information and Telecommunication Systems (CITS)}, 
  title={Deep semantic understanding of high resolution remote sensing image}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  keywords={Remote sensing;Feature extraction;Semantics;Recurrent neural networks;Logic gates;Visualization},
  doi={10.1109/CITS.2016.7546397}}

@misc{zhao2024swiftascalablelightweightinfrastructure,
      title={SWIFT:A Scalable lightWeight Infrastructure for Fine-Tuning},
      author={Yuze Zhao and Jintao Huang and Jinghan Hu and Xingjun Wang and Yunlin Mao and Daoze Zhang and Zeyinzi Jiang and Zhikai Wu and Baole Ai and Ang Wang and Wenmeng Zhou and Yingda Chen},
      year={2024},
      eprint={2408.05517},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.05517},
}