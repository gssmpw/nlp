\appendix

\section{Additional Experimental Results and Analysis}
\label{app:expts}

Please find the additional analysis and results below in the figures.


% \vspace{-0.2cm}
% \begin{algorithm}[H]
%     \caption{ZebraLogic Puzzle Generation.}
%     \label{alg:zebra_puzzle_generation}
%     \begin{algorithmic}[1]
%     \small 
%     \State \textbf{Define} a set of possible attributes $\mathcal{A}_{\text{all}}$ and their value sets $\mathcal{V}_a$ for each $a \in \mathcal{A}_{\text{all}}$
%     \State \textbf{Define} clue types $\mathcal{C} = \{c_1, \ldots, c_L\}$ with templates $T(c)$ for each $c \in \mathcal{C}$
%     \State \textbf{Input:} Number of houses $N$, number of attributes $M$
    
%     \State \textbf{Sample} $M$ attributes from $\mathcal{A}_{\text{all}}$ to form $\mathcal{A} = \{a_1, \ldots, a_M\}$
    
%     \State \textbf{Initialize} solution $S: H \times \mathcal{A} \rightarrow \bigcup_{a \in \mathcal{A}} \mathcal{V}_a$ by random assignment
%     \Statex \hrulefill
%     \State $C \gets \texttt{ClueGeneration}(S)$ \Comment{Initialize the clue set with all possible clues that describe the solution $S$.}
%     \While{$C \neq \emptyset$}
%         \State $p \gets \texttt{SampleClue}(C)$ \Comment{Sample a clue to remove}
%         \State $C' \gets C \setminus \{p\}$
%         \If{$|\text{Solutions}(C')| = 1$ and $\text{Solutions}(C') = \{S\}$}
%             \State $C \gets C'$ \Comment{Remove the clue if uniqueness is maintained}
%         \Else
%             \textbf{break} \Comment{Stop if removing leads to multiple solutions or unsolvability} 
%         \EndIf
%     \EndWhile
%     \State \textbf{Return} $(S, C)$ \Comment{Solution and a mimimal set of  clues. Then, we can create the final puzzle with templates.}
%     \end{algorithmic}
% \end{algorithm}
% \vspace{-0.2cm}

% \begin{algorithm}[H]
%     \caption{ZebraLogic Puzzle Generation.}
%     \label{alg:zebra_puzzle_generation}
%     \begin{algorithmic}[1]
%     \small 
%     \Require A set of possible attributes $\mathcal{A}_{\text{all}}$ and their value sets $\mathcal{V}_a$ for each $a \in \mathcal{A}_{\text{all}}$
%     \Require Clue types $\mathcal{C} = \{c_1, \ldots, c_L\}$ with templates $T(c)$ for each $c \in \mathcal{C}$
%     \Require Number of houses $N$, number of attributes $M$
    
%     \State Sample $M$ attributes from $\mathcal{A}_{\text{all}}$ to form $\mathcal{A} = \{a_1, \ldots, a_M\}$
%     \State Initialize solution $S: H \times \mathcal{A} \rightarrow \bigcup_{a \in \mathcal{A}} \mathcal{V}_a$ by random assignment
%     \State $C \gets \texttt{ClueGeneration}(S)$ \Comment{Initialize clue set}
%     \While{$C \neq \emptyset$}
%         \State $p \gets \texttt{SampleClue}(C)$ \Comment{Sample a clue to remove}
%         \State $C' \gets C \setminus \{p\}$
%         \If{$|\text{Solutions}(C')| = 1$ and $\text{Solutions}(C') = \{S\}$}
%             \State $C \gets C'$ \Comment{Remove if uniqueness is maintained}
%         \Else
%             \State \textbf{break} \Comment{Stop if multiple solutions possible}
%         \EndIf
%     \EndWhile
%     \State \Return $(S, C)$ \Comment{Return solution and minimal clue set}
%     \end{algorithmic}
% \end{algorithm}

\begin{figure}[h]
    \centering
    % \hspace{-5mm} 
    \includegraphics[width=1\linewidth]{assets/reasoning_tokens.pdf}
    \vspace{-0.7cm}
    \caption{
    Top: Distribution of hidden reasoning tokens generated by o1-mini and o1-preview models.
    Bottom: Distribution of visible reasoning tokens across GPT-4o-mini, GPT-4o, o1-mini, and o1-preview models.
    Mean hidden reasoning tokens per model: o1-mini generates 5,144.6 tokens and o1-preview generates 5,346.3 tokens.
    Mean visible reasoning tokens per model: GPT-4o-mini (502.9), GPT-4o (543.7), o1-mini (305.7), and o1-preview (402.4).
    }
    % \vspace{-1cm}
    \label{fig:o1_hidden_cot}
\end{figure}


% \begin{table*}[t]
%     \centering
%     \scalebox{0.92}{ % Adjust the scale factor as needed
%     \begin{tabular}{@{}r|l||l|l|l|l||l@{}}
%     \toprule
%     % \multicolumn{1}{c}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{Overall}} & \multicolumn{1}{c}{\textbf{Small}} & \multicolumn{1}{c}{\textbf{Medium}} & \multicolumn{1}{c}{\textbf{Large}} & \multicolumn{1}{c}{\textbf{X-Large}} & \multicolumn{1}{c}{\textbf{Cell Acc}} \\
%     \multicolumn{1}{c}{\textbf{Model}} & 
%     % \multicolumn{1}{c}{\textbf{Overall}} & 
%     \multicolumn{1}{c}{\makecell{\textbf{Overall} \\ \scriptsize{Grid-level acc.}}} &
%     \multicolumn{1}{c}{\makecell{\textbf{Small} \\ \scriptsize{$<10^3$}}} & 
%     \multicolumn{1}{c}{\makecell{\textbf{Medium} \\ \scriptsize{$10^3\sim10^6$}}} & 
%     \multicolumn{1}{c}{\makecell{\textbf{Large} \\ \scriptsize{$10^6\sim10^9$}}} & 
%     \multicolumn{1}{c}{\makecell{\textbf{X-Large} \\ \scriptsize{$>10^9$}}} & 
%     \multicolumn{1}{c}{\textbf{Cell Acc}} \\
%     \midrule
%     o1 (24-12-27)  {\tiny\faLock}  & \gradientcell{81.0} & \gradientcell{97.2} & \gradientcell{92.1} & \gradientcell{78.0} & \gradientcell{42.5} & \gradientcell{78.7} \\
%     DeepSeek-R1 {\tiny\faKey}  & \gradientcell{78.7} & \gradientcell{98.4} & \gradientcell{95.7} & \gradientcell{73.5} & \gradientcell{28.5} & \gradientcell{80.5} \\
%     o1-preview {\tiny\faLock} & \gradientcell{71.4} & \gradientcell{98.1} & \gradientcell{88.2} & \gradientcell{59.5} & \gradientcell{17.0} & \gradientcell{75.1} \\ 
%     o1-mini {\tiny\faLock} & \gradientcell{59.7} & \gradientcell{87.5} & \gradientcell{76.8} & \gradientcell{39.0} & \gradientcell{12.0} & \gradientcell{70.3} \\ \midrule 
%     Sonnet 3.5 {\tiny\faLock} & \gradientcell{36.2}  & \gradientcell{84.7} & \gradientcell{28.9} & \gradientcell{4.0} & \gradientcell{1.0} & \gradientcell{54.3} \\
%     Llama-3.1-405B {\tiny\faKey} & \gradientcell{32.6} & \gradientcell{81.3} & \gradientcell{22.5} & \gradientcell{1.5} & \gradientcell{0.0} & \gradientcell{45.8} \\
%     \underline{\textit{GPT-4o}} {\tiny\faLock} & \gradientcell{31.7} & \gradientcell{80.0} & \gradientcell{19.6} & \gradientcell{2.5} & \gradientcell{0.5} & \gradientcell{50.3} \\
%     Gemini-1.5-Pro {\tiny\faLock} & \gradientcell{30.5} & \gradientcell{75.3} & \gradientcell{20.7} & \gradientcell{3.0} & \gradientcell{0.0} & \gradientcell{50.8} \\
%     Mistral-Large-2 {\tiny\faKey} & \gradientcell{29.0} & \gradientcell{75.9} & \gradientcell{15.0} & \gradientcell{2.5} & \gradientcell{0.0} & \gradientcell{47.6} \\
%     Qwen2.5-72B {\tiny\faKey} & \gradientcell{26.6} & \gradientcell{72.5} & \gradientcell{12.1} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{40.9} \\
%     % Qwen2.5-32B {\tiny\faKey} & \gradientcell{26.1} & \gradientcell{72.2} & \gradientcell{10.4} & \gradientcell{0.5} & \gradientcell{0.0} & \gradientcell{43.4} \\
%     Gemini-1.5-Flash {\tiny\faLock} & \gradientcell{25.0} & \gradientcell{65.0} & \gradientcell{13.6} & \gradientcell{2.0} & \gradientcell{0.0} & \gradientcell{43.6} \\
%     Llama-3.1-70B {\tiny\faKey} & \gradientcell{24.9} & \gradientcell{67.8} & \gradientcell{10.4} & \gradientcell{1.5} & \gradientcell{0.0} & \gradientcell{28.0} \\
%     DeepSeek-v2.5 {\tiny\faKey} & \gradientcell{22.1} & \gradientcell{62.2} & \gradientcell{7.9} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{38.0} \\
%     \underline{\textit{GPT-4o-mini}} {\tiny\faLock} & \gradientcell{20.1} & \gradientcell{58.8} & \gradientcell{4.6} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{41.3} \\
%     Gemma-2-27B {\tiny\faKey} & \gradientcell{16.3} & \gradientcell{46.6} & \gradientcell{5.0} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{41.2} \\
%     Llama-3.1-8B {\tiny\faKey} & \gradientcell{12.8} & \gradientcell{39.4} & \gradientcell{0.7} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{13.7} \\
%     Gemma-2-9b {\tiny\faKey} & \gradientcell{12.8} & \gradientcell{37.8} & \gradientcell{2.5} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{36.8} \\
%     Qwen2.5-7B {\tiny\faKey} & \gradientcell{12.0} & \gradientcell{36.3} & \gradientcell{1.4} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{30.7} \\
%     Mixtral-8x7B {\tiny\faKey} & \gradientcell{8.7} & \gradientcell{26.3} & \gradientcell{1.1} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{26.5} \\
%     Llama-3.2-3B {\tiny\faKey} & \gradientcell{7.4} & \gradientcell{23.1} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{13.1} \\
%     Phi-3.5-4B {\tiny\faKey} & \gradientcell{6.4} & \gradientcell{19.4} & \gradientcell{0.7} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{6.0} \\
%     Qwen2.5-3B {\tiny\faKey} & \gradientcell{4.8} & \gradientcell{15.0} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{11.4} \\
%     Gemma-2-2B {\tiny\faKey} & \gradientcell{4.2} & \gradientcell{13.1} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{0.0} & \gradientcell{10.0} \\
%     \bottomrule
%     \end{tabular}
%     }
%     \caption{More results for the performance of LLMs on ZebraLogic. The overall accuracy is calculated based on the number of puzzles solved correctly. We also report the accuracy on small, medium, large, and x-large groups based on the size of the search space (as defined in Sec.~\ref{ssec:dataset_creation}).  
%     The cell accuracy indicates the percentage of individual cells filled correctly. 
%     Note that we have more results in the supplementary material.
%     }
%     \label{tab:model_performance_full}
% \end{table*}


\begin{figure}[t]
    \centering
    % \hspace{-4mm} 
    \includegraphics[width=1.\linewidth]{assets/sampling.png}
    % \vspace{-1mm}
    \caption{
    Analysis of inference-time compute scaling using Best-of-N (BoN) sampling across different ZebraLogic puzzle size groups. The curves demonstrate how increasing the number of samples affects model performance, with separate plots for Small, Medium, Large, and X-Large puzzle categories.
    }
    % \vspace{-2mm}
    \label{fig:sampling}
\end{figure}





\begin{figure*}[h!]
    \centering
    %\includegraphics[width=0.9\linewidth]{figures/KK_data_generation.pdf}
    \includegraphics[width=0.9\linewidth]{assets/heatmap.pdf}
    \vspace{-1mm}
    \caption{
    \small  Heatmaps illustrating puzzle complexity metrics across different ZebraLogic problem sizes. The left heatmap represents the log-scaled search space size, categorized from Small to X-Large based on the grid configurations (houses × attributes). The right heatmap shows the average number of Z3 conflicts encountered during solving, with higher counts indicating greater logical complexity.}    % The color gradient in each map reflects an increase in either search space size or Z3 conflicts as the number of houses and attributes grows, highlighting how complexity scales with problem size.
    % \vspace{-2mm}
    \label{fig:heatmap}
\end{figure*}

\section{Details of the ZebraLogic Dataset}
\label{app:details}
All possible attribute types:
\textit{Name, Color, Nationality, Animal, Drink, Cigar, Food, Flower, PhoneModel, Children, Smoothie, Birthday, Occupation, Height, CarModel, FavoriteSport, MusicGenre, BookGenre, HairColor, Mother, HouseStyle, Education, Hobby, Vacation, Pet}



Each problem instance is characterized by two complimentary complexity metrics: the search space size as well as the average number of Z3 conflicts that the SMT solver takes to solve a puzzle. Figure~\ref{fig:heatmap} illustrates how both metrics vary across different number of houses ($N$) and number of attributes ($M$).



\section{Additional Analysis}


\textbf{GPT-4o tends to generate more \textit{visible} reasoning tokens than o1.}
Interestingly, we find that the GPT4o model tends to generate more visible reasoning tokens than o1, especially when the search space is large, which is shown in the lower part of Figure~\ref{fig:o1_hidden_cot}.
The visible reasoning tokens are generated by the model and displayed in their outputs before the final solution grids.
We can see that until the search space reaches the Large category (especially when the search space size is $<10^5$), the four models generate similar numbers of visible reasoning tokens. However, when the search space size is larger, GPT4o generates more visible reasoning tokens yet still fails to solve the puzzles.
o1 models, which have used more hidden CoT tokens, tend to output fewer visible reasoning tokens for describing their reasoning process.


\subsection{Human Evaluation of o1's Reasoning} 
Here we present several case studies to understand the reasoning process of o1. 
We selected a few representative examples from the ZebraLogic dataset and analyzed the reasoning steps taken by o1-preview to arrive at the final solution.


% this is the summary of the hidden CoT tokens 
\begin{comment}
Taking a closer look
Analyzing the provided puzzle’s constraints, I focus on the three houses, their unique occupants, drinks, and hobbies. Each person has distinct attributes, guiding me through the solution steps methodically.
Piecing together the clues
Starting by organizing a table for houses 1 to 3, listing attributes: Name, Drink, Hobby. Progress involves placing Arnold (not in house 1) and Eric (milk).
Pinpointing preferences
I’m working through the clues to identify who likes milk, cooking, and water. Eric enjoys milk, Arnold drinks water, and they can’t be in certain houses.
Placing roles and likes
OK, let me see. The photography enthusiast is in either house 2 or 3. Eric, who likes milk, cannot be in house 2. This suggests he must be in house 1 or 3, with a cook immediately to his left.
Nailing down house positions
OK, let me see. Eric’s in house 3 with milk. Cooking’s in house 2, next to Eric. Photography’s in house 2 or 3.
Figuring out Arnold’s role
OK, let me see. Arnold can’t be in house 1 since Clue 1 rules it out. So, Arnold’s either in house 2 or 3. Clearly, Arnold is in house 2 with a cooking passion and water as his drink.
Mapping out the assignment
I’m organizing the details: Peter is in house 1, Arnold is in house 2, and Eric is in house 3. Peter drinks tea, Arnold drinks water, and Eric drinks milk, with Peter’s hobby being gardening, Arnold’s being cooking, and Eric’s being photography.
Piecing together clues
I traced the deduction that Arnold is in house 2, Eric likes milk and lives in house 3, and Arnold drinks water, consistent with the clues.
Locating Arnold
I’ve figured out that Arnold is in house 2, loves cooking, and drinks water. Meanwhile, Eric is in house 3, drinks milk, and is into photography.


--->


public  output:


{
    “reasoning”: “First, from Clue 2 and Clue 6, we know that Eric likes milk and is not in the second house. Therefore, Eric must be in House 3. According to Clue 4, the person who loves cooking is directly left of the person who likes milk, so the cooking enthusiast must be in House 2. Clue 5 tells us that Arnold drinks water. Since Arnold is not in the first house (Clue 1), he must be in House 2. Thus, Arnold is in House 2, drinks water, and loves cooking. Clue 3 states that the photography enthusiast is not in the first house; since House 2 is occupied by Arnold who loves cooking, the photography enthusiast must be Eric in House 3. This leaves Peter for House 1, who by elimination drinks tea and enjoys gardening.”,
    “solution”: {
        “House 1”: {
            “Name”: “Peter”,
            “Drink”: “tea”,
            “Hobby”: “gardening”
        },
        “House 2”: {
            “Name”: “Arnold”,
            “Drink”: “water”,
            “Hobby”: “cooking”
        },
        “House 3”: {
            “Name”: “Eric”,
            “Drink”: “milk”,
            “Hobby”: “photography”
        }
    }
}


--->
2nd try:


Analyzing clues
I’m working through the puzzle by carefully reading and understanding the clues. Each house has unique traits including different people, drinks, and hobbies.

Assigning attributes
I’m mapping out the puzzle by listing houses, names, drinks, and hobbies. The goal is to match each attribute to a specific house while adhering to the given clues.

Figuring out the layout
I’ve established that Arnold isn’t in house 1. Since Eric enjoys milk and is not in house 2, he must be in house 1. Arnold, who only drinks water, must be in house 2 or house 3.

Piecing together house assignments
OK, let’s figure out Peter’s house. Since Eric prefers milk and Arnold uses water, Peter lands in house 2, making clues align perfectly. This confirms all the drink preferences.

Pinpointing Eric’s house
Eric can’t be in house 1, so he must be in house 3. Since house 2 houses the cooking lover, the photographer is in house 1 or 3.

Mapping out the allocation
I’m placing Eric in house 3, Arnold in house 2, and Peter in house 1 based 
on the provided clues. Progress is being made move by move and step by step.

Identifying roles
I’m working through the arrangement of house inhabitants, assigning them hobbies and drinks like Arnold with cooking, Peter with tea, and Eric with photography.

Assigning hobbies
Prince Peter’s hobby is gardening, which means Arnold enjoys cooking and Eric engages in photography, assigning beverages and hobbies to each house accordingly.

Linking the clues
Taking a closer look, Arnold in house 2 loves cooking. He’s directly left of Eric in house 3, who enjoys milk. The clue fits: Arnold drinks water.

Piecing together clues
First, Eric is in house 3. Arnold is in house 2, loves cooking, and drinks water. Peter, in house 1, enjoys gardening and drinks tea.

Mapping clues
I’m thinking through how Eric in house 3 fits clues 2, 4, and 6. Arnold, in house 2, drinks water, while Peter in house 1 enjoys tea.

{
    "reasoning": "Given Clue 2, Eric likes milk. Clue 6 states that the person who likes milk is not in the second house, so Eric must be in either house 1 or 3. Clue 4 says the person who loves cooking is directly left of the person who likes milk. If Eric were in house 1, there would be no house to its left, so Eric cannot be in house 1. Therefore, Eric is in house 3. Clue 1 says Arnold is not in the first house, so he must be in house 2, leaving Peter in house 1. Clue 5 tells us that Arnold drinks water. Since drinks are unique and Eric drinks milk, Peter must drink tea. Clue 4 states that the person who loves cooking is directly left of the person who likes milk. Therefore, Arnold in house 2 loves cooking. Clue 3 says the photography enthusiast is not in the first house. Since Arnold loves cooking, Eric must be the photography enthusiast. The remaining hobby, gardening, must belong to Peter in house 1.",
    "solution": {
        "House 1": {
            "Name": "Peter",
            "Drink": "tea",
            "Hobby": "gardening"
        },
        "House 2": {
            "Name": "Arnold",
            "Drink": "water",
            "Hobby": "cooking"
        },
        "House 3": {
            "Name": "Eric",
            "Drink": "milk",
            "Hobby": "photography"
        }
    }
}

==== wrong examples 
 



\end{comment}




\begin{comment}
    GPT4o's reasoning for the example puzzle in Fig1 
    {
    "reasoning": "Based on Clues 1, 2, and 6, we placed Eric, who drinks milk, in House 3. Since Arnold is not in the first house (Clue 1) and drinks water (Clue 5), he must be in House 2. The person in House 2 loves cooking (Clue 4), which aligns with Arnold’s position. By elimination, Peter is in House 1, with tea as his drink and gardening as his hobby. The photography enthusiast is also in House 2, as per Clue 3, matching Arnold’s profile.",
    "solution": {
        "House 1": {
            "Name": "Peter",
            "Drink": "tea",
            "Hobby": "gardening"
        },
        "House 2": {
            "Name": "Arnold",
            "Drink": "water",
            "Hobby": "cooking"
        },
        "House 3": {
            "Name": "Eric",
            "Drink": "milk",
            "Hobby": "photography"
        }
    }
}
\end{comment}


\subsection{Comparison with LMSYS Arena Rankings.}
While the overall performance rankings on ZebraLogic generally align with those from the LMSYS Arena (a platform for evaluating LLMs across various tasks), we observe some notable discrepancies that highlight ZebraLogic's distinct evaluation perspective. For instance, GPT-4o-mini-0718 achieves a higher Elo score (1273) in LMSYS Arena (24-11-11) compared to Llama-3.1-405B (1266), GPT-4o-0806(1264), Mistral-Large-2 (1251), and Llama-3.1-70B (1247). However, on ZebraLogic, GPT-4o-mini only achieves 20.1\% accuracy while Llama-3.1-405B reaches 32.6\%. These differences suggest that ZebraLogic offers a more focused assessment of logical reasoning capabilities, providing valuable insights that complement general-purpose evaluations.





% \begin{comment}
    
    \subsection{o1 generates large-scale hidden reasoning tokens.}
    \label{app:hidden_cot_analysis}
    One of the key differences between o1 and other LLMs is the way they use more test-time compute to decode much more hidden chain-of-thoughts (CoT) tokens during inference time, which are not directly visible to users.
    Figure~\ref{fig:o1_hidden_cot} shows how the number of hidden CoT tokens varies with the search space size for both o1-mini and o1-preview. 
    In each sub-figure on the top, we plot 1,000 points, each representing a puzzle. 
    The color and shape of the points indicate whether the model produced a correct solution (blue dots) or an incorrect one (red crosses).
    The y-axis shows the number of hidden CoT tokens generated by the model, while the x-axis shows the search space size in logarithmic scale. The definition of search space size is provided in Section~\ref{ssec:dataset_creation}, and a larger search space usually indicates a more complex puzzle. 
    
    
    We can see that the number of hidden CoT tokens generated by o1 is scaling with the search space size, indicating that o1 is able to leverage more reasoning steps when faced with more complex puzzles. 
    On average, we find that o1-mini generates 5,144.6 hidden reasoning tokens, while o1-preview generates 5,346.3 hidden reasoning tokens. Both are about 10 times more than the average number of reasoning tokens generated by GPT-4o-mini (502.9) and GPT-4o (543.7), showing that scaling reasoning tokens can be an effective way to improve the performance of LLMs on logical reasoning tasks.   
% \end{comment}

\section{Further Discussion on o1's Reasoning}
\label{sec:o1_reason}




We have seen that o1 generates more hidden reasoning tokens than other LLMs, and the hidden reasoning tokens scale up with search space size, indicating that o1 is able to leverage more reasoning steps when faced with more complex puzzles. 
%In this section, we further analyze the reason why O1 can solve complex problems with large search spaces while other LLMs fail, and how O1 reasons for complex problems. \ashish{The last sentence is not aligned with what you say in the rest of the section. Instead, I would replace it with something like: Since the hidden reasoning tokens are not accessible, we investigate whether O1's visible output tokens or its summary of hidden tokens can explain its higher performance.} \ronan{great, thx!}
Since the hidden reasoning tokens are not accessible, we investigate whether o1's visible output tokens or its summary of hidden tokens can explain its higher performance.

% \subsection{How does O1 reason? Deciphering O1's Reasoning Process from Visible to Hidden Tokens}

\textbf{Visible outputs from o1 cannot fully explain its reasoning for complex problems.}
To understand how o1 reasons, we have to focus on their public reasoning steps that we can extract from the model's visible outputs. 
From our human evaluation on their reasoning steps, we find that o1's reasoning steps are not necessarily rigorous or complete, even when they arrive at the correct solution.
For small-to-medium search spaces, o1-preview's reasoning chains tend to be complete, while o1-mini sometimes can skip some steps to directly reach the solution.
For problems with larger search spaces, o1's visible reasoning chains tend to be very incomplete, and sometimes even incorrect, especially when the reasoning process requires backtracking.
For example, o1's visible reasoning may contain steps such as ``Bob cannot be in Houses 1, 4, or 5, so he must be in House 3'' without explaining why Bob cannot be in House 2, although it will indeed lead to the correct solution. Note that such cases also happen for other LLMs such as GPT-4o. 
We thus describe that the reasoning process of LLMs and o1 models are sometimes based on guessing without formal logic, especially for complex problems with large search spaces, rater than rigorous logical reasoning.

Such incomplete reasoning steps are very common in o1's outputs, especially for puzzles with larger search spaces, leading to unreliable explanations of their reasoning process.
Thus, we argue that the visible reasoning steps from o1 cannot help us understand how o1 reasons for complex problems.
Furthermore, knowledge distillation from o1's reasoning steps is not necessarily helpful for improving the performance of other LLMs, as the reasoning steps are often incomplete and sometimes incorrect. This raises questions about the concern of hidden CoT tokens in their reasoning process that are not visible in the output.



\textbf{Will the summary of hidden tokens help us understand o1's reasoning?}
Although the hidden CoT tokens are not visible from the OpenAI APIs, we can see an overview summary of the hidden reasoning tokens on ChatGPT's user interface for o1's hidden reasoning steps.
By manually analyzing the overview summary of hidden reasoning tokens, we find it is still hard to clearly understand how o1 reasons for complex problems.
We can sometimes see some intermediate results in the overview but not any explanations for the decision.
Interestingly, we can see some behaviors of recognizing the contradictions of previous assumptions and revisiting the clues to refine the solution.
Such an in-context reflection behavior is hardly noticeable in other LLMs such as GPT-4o's reasoning, and it may be a key factor for o1's success in solving complex problems.
Typical steps in o1's hidden reasoning include: ``Laying out the options'', ``Piecing together clues'', ``Pinpointing the clues'', ``Reevaluating assumptions'', ``Revisiting clues.'', ``Mapping out connections'', ``Tracking movement'', etc.
We provide case studies in the Appendix to better understand how o1 reasons. 




\subsection{Prompt template to evaluate ZebraLogic} 
\label{app:prompt_template}
\begin{Verbatim}[breaklines=true, 
    breakanywhere=true,
    fontsize=\small,
    baselinestretch=0.65,
    frame=single,
    commandchars=none]

# Example Puzzle 

There are 3 houses, numbered 1 to 3 from left to right, as seen from across the street. Each house is occupied by a different person. Each house has a unique attribute for each of the following characteristics:
    - Each person has a unique name: `Peter`, `Eric`, `Arnold`.
    - Each person has a unique favorite drink: `tea`, `water`, `milk`

## Clues for the Example Puzzle

1. Peter is in the second house.
2. Arnold is directly left of the one who only drinks water.
3. The one who only drinks water is directly left of the person who likes milk.

## Answer to the Example Puzzle

{
    "reasoning": "Given Clue 1, we know Peter is in House 2. According to Clue 2, Arnold is directly left of the one who only drinks water. The person in House 3 cannot be on the left of anyone, so Arnold must be in House 1. Thus, Peter drinks water, and Eric lives in House 3. Then, according to Clue 3, Eric drinks milk. Therefore, Arnold drinks tea.",
    "solution": {
        "House 1": {
            "Name": "Arnold",
            "Drink": "tea"
        },
        "House 2": {
            "Name": "Peter",
            "Drink": "water"
        },
        "House 3": {
            "Name": "Eric",
            "Drink": "milk"
        }
    }
}

# Puzzle to Solve 

There are 3 houses, numbered 1 to 3 from left to right, as seen from across the street. Each house is occupied by a different person. Each house has a unique attribute for each of the following characteristics:
    - Each person has a unique name: `Eric`, `Peter`, `Arnold`
    - Each person has a unique favorite drink: `milk`, `water`, `tea`
    - Each person has a unique hobby: `photography`, `cooking`, `gardening`

## Clues:
1. Arnold is not in the first house.
2. The person who likes milk is Eric.
3. The photography enthusiast is not in the first house.
4. The person who loves cooking is directly left of the person who likes milk.
5. The one who only drinks water is Arnold.
6. The person who likes milk is not in the second house.



# Instruction

Now please solve the above puzzle. Present your reasoning and solution in the following json format:

{
    "reasoning": "___",
    "solution": {
        "House 1": {
            "Name": "___",
            "Drink": "___",
            "Hobby": "___"
        },
        "House 2": {
            "Name": "___",
            "Drink": "___",
            "Hobby": "___"
        },
        "House 3": {
            "Name": "___",
            "Drink": "___",
            "Hobby": "___"
        }
    }
}
\end{Verbatim}
 