





\vspace{-0.2cm}
\section{Problem Formulation of Logical Reasoning}
\label{sec:zebralogic}
\vspace{-0.2cm}
Constraint Satisfaction Problems (CSPs) provide a powerful framework for modeling and solving logical reasoning tasks. In CSPs, solutions must satisfy a set of constraints over variables and their possible values. 
% Many important AI challenges can be formulated as CSPs.
This framework is particularly valuable for evaluating systematic reasoning capabilities, as it requires explicit handling of logical relationships and dependencies. We leverage this framework through logic grid puzzles in our ZebraLogic dataset to assess LLMs' deductive reasoning abilities.




\subsection{Logic Grid Puzzles}

% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. 
% Thus, we introduce ZebraLogic, a dataset using these puzzles to evaluate LLMs' logical reasoning capabilities.

% \yuchen{Argue that many other difficult AI problems are also essentially CSPs or contain CSPs as subproblems. For example, Sodoku, crossword puzzles, Chess, Go, etc.
% --
% Many difficult AI problems can indeed be argued to be CSPs or contain CSPs as subproblems. While not all aspects of complex games like Chess and Go are best modeled as CSPs, certain components within these games can be approached using CSP techniques. The CSP framework is powerful due to its generality and the availability of robust solving methods, making it a fundamental tool in AI for tackling problems that involve satisfying complex sets of constraints.
% --
% Understanding problems through the CSP lens allows researchers and practitioners to apply a wide range of algorithmic strategies and to generalize solutions across different domains. This perspective is valuable for both theoretical insights and practical applications in artificial intelligence.
% }

% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. CSPs represent a fundamental framework in artificial intelligence, encompassing many challenging problems such as Sudoku, crossword puzzles, and certain aspects of complex games like Chess and Go. While not all components of these complex games are best modeled as CSPs, the framework's power lies in its generality and the availability of robust solving methods for handling complex sets of constraints.

% CSPs represent a fundamental framework in artificial intelligence, appearing in crucial applications. The framework's power lies in its ability to explicitly represent logical relationships and dependencies, making it particularly suitable for evaluating an LLM's capacity for systematic reasoning and constraint satisfaction across a wide range of problems and domains.
% This makes CSPs particularly valuable for both theoretical research and practical applications in artificial intelligence. Given these advantages, we introduce ZebraLogic, a dataset using logic grid puzzles to evaluate LLMs' logical reasoning capabilities.
% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. 



% \subsection{Logic Grid Puzzles}
% \label{sec:zebra_puzzles}

% Logic grid puzzles (also known as Zebra puzzles) represent a specific class of CSPs that are particularly well-suited for evaluating logical reasoning capabilities. 
% These puzzles require pure deductive reasoning to determine the correct assignment of values to variables based on given constraints, without requiring domain knowledge or mathematical computation. 

% To systematically study LLMs' logical reasoning abilities using this framework, we have created ZebraLogic, a benchmark dataset of logic grid puzzles.
Each puzzle in ZebraLogic consists of $N$ houses (numbered 1 to $N$ from left to right) and $M$ different attributes for each house. There are $N$ distinct values for each attribute, and each house must have a unique value for each attribute. Given a list of $K$ clues, one must use logical deduction to determine the unique correct assignment of values. Figure \ref{fig:lgp_example} illustrates an example of such a puzzle, as well as a reasoning chain for solving it. 
Importantly, while some ZebraLogic puzzles can be solved through straightforward linear deduction, many require more complex \textit{non-monotonic} reasoning strategies, such as counterfactual reasoning that involves backtracking and revising assumptions. This is particularly true as the search space grows larger and the clues become more intricate -- a key aspect of our study on the scaling behavior of LLMs.
 
%  Puzzle [lgp-test-3x3-2]




\subsection{Problem Formulation}
 
We provide a detailed mathematical formulation of logic grid puzzles as a CSP.
This formulation not only clarifies the underlying structure of the puzzles in ZebraLogic but also highlights how our study can be generalized to various reasoning problems.
The example shown in Fig.~\ref{fig:lgp_example} illustrates this formulation.

% \textbf{Background.} Consider three houses on a street, numbered 1 to 3. Each house has a different occupant with unique \textbf{attributes}: \texttt{Name} (\(\mathcal{V}_{\text{Name}} = \{ \text{Eric},\text{Peter},\text{Arnold} \}\)), \texttt{Drink} (\(\mathcal{V}_{\text{Drink}} = \{ \text{milk},\text{water},\text{tea} \}\)), and \texttt{Hobby} (\(\mathcal{V}_{\text{Hobby}} = \{ \text{photography},\text{cooking},\text{gardening} \}\)).
% Each attribute \( a \in \mathcal{A} \) represents a category of characteristics (i.e., an attribute), and each value in \(\mathcal{V}_{a}\) is a possible assignment for that attribute.
% To model the puzzle as a Constraint Satisfaction Problem, we define variables representing the assignment of values to attributes for each house.

\textbf{Background.} Consider $N$ houses numbered 1 to $N$. Each house has a different occupant with a set $\mathcal{A}$ of $M$ unique attributes such as name, favorite drink, hobby, etc. Each attribute $a \in \mathcal{A}$ represents a category of characteristics and takes values in a set $\mathcal{V}_a$ of $N$ possible values. 
For example, for the attribute \texttt{Name}, we might have $\mathcal{V}_{\text{Name}} = \{ \text{Eric},\text{Peter},\text{Arnold} \}$ in a puzzle with $N=3$ houses. 
As illustrated in Fig.~\ref{fig:lgp_example}, other attributes might include \texttt{Drink} with values like milk, water, and tea, or \texttt{Hobby} with values like photography, cooking, and gardening.
To model the puzzle as a Constraint Satisfaction Problem, we define variables representing the assignment of values to attributes for each house.


\vspace{-0.2cm}
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=1em]
    \small 
    \item Let $H = \{1, 2, 3, \cdots\}$ be the set of houses, $|H| = N$.
    \item Let $\mathcal{A} = \{\text{Name}, \text{Drink}, \cdots \}$ be the set of attributes, $|\mathcal{A}| = M$.
    \item Define $x_{a,k} \in \mathcal{V}_{a}$ for each attribute $a \in \mathcal{A}$ and house $k \in H$.
    % e.g., $x_{\text{Drink},k}$ is the Drink for house $k$.
\end{itemize}
\vspace{-0.2cm}
 

% todo: 

\textbf{Uniqueness Constraints:}
The constraints ensure that each value is assigned exactly once, as described in the Background part in Figure~\ref{fig:lgp_example}.
For each attribute, the set of assigned values across all houses must exactly match the set of possible values. That is:  $\{ x_{a, k} \mid k \in H \} = \mathcal{V}_{a}$.

% \textbf{Unique Attributes per House:} Additionally, for each house \( k \in H \), each house must have one unique value for each attribute. This means that each house must have one unique name, one unique drink, and one unique hobby.



\textbf{Clue-Based Constraints:} 
Each clue in the puzzle introduces additional constraints that must be satisfied by any valid assignment\footnote{Note that there are also several implicit positional constraints that must be considered. For example, the leftmost house cannot be on the right of any other house, and the rightmost house cannot be on the left of any other house (as relevant in Clue 4). These spatial constraints, combined with the explicit clues, translate the verbal descriptions into precise logical conditions to be satisfied.}. Under the hood, these clues are translated into formal logic formulas that constrain the relationships between variables. For our example puzzle in Figure~\ref{fig:lgp_example}, the constraints can be formulated as follows:

\vspace{-0.3cm}
\begin{AIbox}{Clue-based Constraints (Example in Figure~2.}
    \small 
    \begin{enumerate}[label=\textbf{Clue \arabic*.}, leftmargin=2.2em, itemsep=0em]
        \item \textit{``Arnold is not in the first house''}: \textcolor{purple}{\( x_{\text{Name},1} \ne \text{Arnold} \)}
        \item \textit{``The person who likes milk is Eric''}:  
            \textcolor{purple}{$\forall k \in H,(x_{\text{Name},k} = \text{Eric}) \iff (x_{\text{Drink},k} = \text{milk})$}
        \item \textit{``The photography enthusiast is not in the first house''}: \textcolor{purple}{\( x_{\text{Hobby},1} \ne \text{photography} \)}
        \item \textit{``The person who loves cooking is directly left of the person who likes milk''}: \textcolor{purple}{\(\forall k\in{H}_{<N},(x_{\text{Hobby},k} = \text{cooking})\implies(x_{\text{Drink},k+1} = \text{milk})\)} 
            % \begingroup
            % \setlength{\abovedisplayskip}{0pt}
            % \setlength{\belowdisplayskip}{0pt}
            % \[ \textcolor{purple}{\forall k \in H,k < N,(x_{\text{Hobby},k} = \text{cooking}) \implies (x_{\text{Drink},k+1} = \text{milk})} \] 
            % \endgroup 
        \item \textit{``The one who only drinks water is Arnold''}: \textcolor{purple}{$\forall k \in H,(x_{\text{Name},k} = \text{Arnold}) \iff (x_{\text{Drink},k} = \text{water})$}
        \item \textit{``The person who likes milk is not in the second house''}: \textcolor{purple}{\( x_{\text{Drink},2} \ne \text{milk} \)}
    \end{enumerate}
\end{AIbox}
\vspace{-0.1cm}

% Note that there are also several implicit constraints about positions such as the leftmost house cannot be on the right of any other house, and the rightmost house cannot be on the left of any other house, as we can see in Clue 4. These constraints translate the verbal clues into precise mathematical conditions that any valid assignment must satisfy.  
 





\textbf{Task.}
% Each variable $x_{a,k}$ can take any value from its attribute's possible values:
% $x_{a,k} \in \mathcal{V}_{a} $
The task is to find an assignment of attributes to houses via assigning values to variables $x_{a,k}$
 that is consistent with all constraints. These constraints, defined above, include both the uniqueness requirements for attribute values and the logical conditions derived from the specific clues provided. 
The result is guaranteed to be unique, and can be usually presented as a table as shown in Fig.~\ref{fig:lgp_example}. 


% \section{ZebraLogic: Examining the Challenges in Logical Reasoning for LLMs}
% % \vspace{-0.2cm}
% \label{sec:zebralogic}

\subsection{ZebraLogic Dataset Creation} 
\label{ssec:dataset_creation}

% Zebra puzzles can be synthetically generated by programs. 

% \begin{algorithm}[H]
%     \caption{ZebraLogic Puzzle Generation}
%     \begin{algorithmic}[1]
%     \State \textbf{Define} a set of attributes $\mathcal{A}$ and their possible values $\mathcal{V}_a$ for each attribute $a \in \mathcal{A}$
%     \State \textbf{Establish} clue types and language templates with placeholders for values
%     \State \textbf{Initialize} a solution table by randomly assigning values on a sampled grid
%     \State \textbf{Enumerate} all possible clues that describe relations among variables
%     \State \textbf{Assign} weights to clues based on complexity and number of variables involved
%     \While{puzzle does not have a unique solution}
%         \State \textbf{Sample} clues based on their weights
%         \State \textbf{Check} if the sampled clues uniquely lead to the solution
%         \If{not unique}
%             \State \textbf{Remove} clues through weighted sampling
%         \EndIf
%     \EndWhile
%     \State \textbf{Represent} the puzzle with prompting templates for LLM inputs
%     \end{algorithmic}
% \end{algorithm}
    

 
% We start by defining a set of attributes and their possible values (e.g., the feature CarModel might have values like Tesla Model 3, Ford F150, etc.). 
% Next, we establish the clue types and their language templates, which include placeholders for values to be filled in. 
% Each clue type is logically structured to describe a type of constraint that can involve multiple variables. 
% To create a ZebraLogic example, we randomly assign values on a sampled grid as the solution table. 
% Then, we enumerate all possible clues that can describe the relation among variables. 
% To construct a valid puzzle with a unique solution, we sample clues based on their weights, which are determined by their complexity and the number of variables involved.
% By iteratively removing clues through weighted sampling, we continuously check if the remaining set of clues can uniquely lead to the above solution. Finally, we represent the puzzle with prompting templates to form the inputs for the LLMs.

To create puzzles, we first define a set of attributes and their corresponding value sets. We also establish some clue types, each with its own language templates containing placeholders for values. 


\textbf{Attributes and Values.} 
We construct the attribute set $\mathcal{A}$, which includes the many elements (see Appendix~\ref{app:details}). Each attribute is associated with a minimum of 6 possible values, ensuring a rich and diverse set of puzzles. Importantly, we always include the \texttt{Name} attribute in our samples, as it serves as a crucial element in the puzzle-solving process. 

\textbf{Clue Types.} 
The possible clue types are categorized into several types, including \textsc{FoundAt}, \textsc{SameHouse}, \textsc{NotAt}, \textsc{DirectLeft/Right}, \textsc{SideBySide}, \textsc{Left/RightOf}, and \textsc{One/TwoBetween}. Each clue type captures a specific relationship between variables, providing a diverse set of constraints for the puzzles. More details are in Appendix~\ref{app:details}.

\begin{AIbox}{Clue Types and Illustrative Examples.}
    \small
    \begin{itemize}[leftmargin=0em,itemsep=0pt]
        \item \textsc{\textbf{FoundAt}}: The tea drinker lives in House 3.
        \item \textsc{\textbf{SameHouse}}: The musician drinks tea.
        \item \textsc{\textbf{NotAt}}: The musician does not drink tea (not at the same house).
        \item \textsc{\textbf{DirectLeft/Right}}: The greenhouse is directly to the left/right of the white house.
        \item \textsc{\textbf{SideBySide}}: The coffee drinker and the tea drinker are next to each other.
        \item \textsc{\textbf{Left/RightOf}}: A is somewhere to the left/right of B.
        \item \textsc{\textbf{One/TwoBetween}}:  1/2 houses are between A \& B.
    \end{itemize}
\end{AIbox}

\definecolor{commentcolor}{RGB}{165,42,42} % Define brown color
\newcommand{\algcomment}[1]{\hfill{\textcolor{commentcolor}{// #1}}}

\begin{algorithm}[t]
    \caption{ZebraLogic Puzzle Generation.}
    \label{alg:zebra_puzzle_generation}
    \begin{algorithmic}[1]
    \small 
    \Require A set of possible attributes $\mathcal{A}_{\text{all}}$ and their value sets $\mathcal{V}_a$ for each $a \in \mathcal{A}_{\text{all}}$
    \Require Clue types $\mathcal{C} = \{c_1, \ldots, c_L\}$ with templates $T(c)$ for each $c \in \mathcal{C}$
    \Require Number of houses $N$, number of attributes $M$
    
    \State Sample $M$ attributes from $\mathcal{A}_{\text{all}}$ to form $\mathcal{A} = \{a_1, \ldots, a_M\}$
    \State Initialize solution $S: H \times \mathcal{A} \rightarrow \bigcup_{a \in \mathcal{A}} \mathcal{V}_a$ randomly
    \State $C \gets \texttt{ClueGeneration}(S)$ \algcomment{Initialize clue set}
    \While{$C \neq \emptyset$}
        \State $p \gets \texttt{SampleClue}(C)$ \algcomment{Sample a clue to remove}
        \State $C' \gets C \setminus \{p\}$
        \If{$|\text{Solutions}(C')| = 1$}
            \State $C \gets C'$ \algcomment{Remove until $S$ is the unique solution}
            \State \textbf{break} 
        \EndIf
    \EndWhile
    \State \Return $(S, C)$ \algcomment{Return solution and minimal clue set}
    \end{algorithmic}
\end{algorithm}




\textbf{Task Generation Algorithm.}
Algo.~\ref{alg:zebra_puzzle_generation} outlines our approach for generating ZebraLogic puzzles. 
The process starts by sampling $M$ attributes from the full attribute set and creating an initial solution grid $S$ through random value assignments. 
From this solution, we generate a comprehensive set of clues $\mathcal{C}$ that capture all valid relationships between values in the grid. 
The algorithm then employs an iterative minimization procedure - at each step, it randomly samples a clue $p \in \mathcal{C}$ and attempts to remove it. Using a SAT solver, it verifies whether the reduced clue set $\mathcal{C}' = \mathcal{C} \setminus \{p\}$ still uniquely determines the original solution $S$. If uniqueness is preserved, $p$ is permanently removed and the process continues. This iteration terminates when no any additional clue can be removed without augmenting the solution space.

We employ weighted sampling during clue selection, assigning higher probabilities to simpler clue types (e.g., \textsc{FoundAt}-type clues are more likely to be sampled than \textsc {NotAt}) to balance puzzle complexity, such that we can efficiently reduce the clue set while maintaining the difficulty of the puzzles.
% named PicoSAT~\citep{Biere2008PicoSATE} 
The result is a minimal set of clues that, when combined with the background information about the attributes and their possible values, forms a logically sound puzzle with a single, unique solution.
This approach ensures that each generated puzzle is both solvable and challenging, requiring a combination of logical deduction and non-monotonic reasoning strategies to solve.
Finally, we use predefined one-shot prompting templates to format the puzzle and instruct the LLMs to generate their reasoning steps and final results in a JSON format (see Appendix~\ref{app:prompt_template}).
%  the application of logical reasoning skills without relying on external knowledge or complex mathematical computations.

\textbf{Dataset Statistics.}
The dataset consists of 1,000 puzzles where the size of the search space varies significantly. The puzzles are based on $N \times M$ grids where $N,M \in \{2,...,6\}$ (i.e., 25 sizes in total, with 40 puzzles per size), covering a wide range of complexity. The average and median number of clues per instance is $10.4$ and $9$, respectively. %The median number of clues for 2x2 grids is $2$, while it is $25$ for 6x6 grids.
%\ashish{Can we give some stats about the number of clues? In general, or even just some specific puzzle size, e.g., a 4 x 5 puzzle has an average of X constraints.}
%\ronan{good idea. Working on this.}
% The dataset is publicly available at \url{https://huggingface.co/datasets/allenai/ZebraLogicBench}.




\subsection{Theoretical Problem Complexity} 
\label{ssec:problem_complexity}

By reduction from the Quasigroup (or Latin square) Completion Problem (QCP)~\citep{Colbourn1984TheCO,Gomes2002CompletingQO}, the ZebraLogic problem is proven to be NP-complete \citep{Sempolinski2009AutomaticSO}. While the problem definition includes a rich set of clue types that can be further expanded, a sufficient condition for the NP-completeness result is to at least include the \textsc{FoundAt} and \textsc{NotAt} clue types. As a result, while a solution to a ZebraLogic puzzle can be easily verified, solving ZebraLogic puzzles for large instances may become intractable within reasonable time frames using current computational methods. This implies that, for a fixed LLM size, the required number of reasoning tokens may increase exponentially with the size of the puzzle.



\subsection{Measuring Effective Instance Complexity}
\label{ssec:complexity_metrics}

\textbf{Search space size.} 
We define the solution space of a ZebraLogic puzzle as the total number of possible configurations that can satisfy the uniqueness constraints of the puzzle. That is, a $N \times M$ grid has a solution space of $(N!)^M$, where $N$ is the number of houses and $M$ is the number of attributes. The complexity of the search space increases factorially with the size of the grid, leading to a combinatorial explosion in the number of possible configurations.\footnote{For example, a 3x4 grid has a solution space of $(3!)^4 = 1296$, while a 4x3 grid has a solution space of $(4!)^3 = 13824$.}
% A 6x4 grid has a solution space of $720^4 \approx 2.7 \times 10^{11}$.
To better group the puzzles based on their complexity, we categorize them into four groups based on the size of the search space $|\mathcal{S}|$:
% \vspace{-0.3cm}
% \begin{itemize}[leftmargin=0.9cm]
%     \small
%     \item \textbf{Small}     \hspace{1.5em} $(1 \leq \text{search space} < 10^3)$  \hspace{2.2em} \small{Grids: 2×2, 2×3, 2×4, 2×5, 2×6, 3×2, 3×3, 4×2}
%     \item \textbf{Medium}    \hspace{0.3em} $(10^3 \leq \text{search space} < 10^6)$               \hspace{1.3em} \small{Grids: 3×4, 3×5, 3×6, 4×3, 4×4, 5×2, 6×2}
%     \item \textbf{Large}     \hspace{1.5em} $(10^6 \leq \text{search space} < 10^{10})$            \hspace{0.9em} \small{Grids: 4×5, 5×3, 4×6, 5×4, 6×3}
%     \item \textbf{X-Large}   \hspace{0.5em} $(\text{search space} \geq 10^{10})$                   \hspace{3.8em} \small{Grids: 5×5, 6×4, 5×6, 6×5, 6×6}
% \end{itemize}
% \vspace{-0.2cm}

\vspace{-0.3cm}
\begin{itemize}[leftmargin=0.15cm,itemsep=-1ex,label={}]
    % \small
    \item\begin{tikzpicture}
        \fill[white] (0,0) -- (0.1,0.1) -- (0,0.2) -- (-0.1,0.1) -- cycle;
        \end{tikzpicture} 
        \greendot{}
        \textbf{\small ~Small}
          {\small $(|\mathcal{S}| < 10^3)$:}
          \scriptsize{2×2, 2×3, 2×4, 2×5, 2×6, 3×2, 3×3, 4×2}
     \item \begin{tikzpicture}
        \fill[white] (0,0) -- (0.1,0.1) -- (0,0.2) -- (-0.1,0.1) -- cycle;
        \end{tikzpicture} 
        \bluedot{}
        \textbf{\small ~Medium}      {\small $(10^3 \leq |\mathcal{S}| < 10^6)$:}
          \scriptsize{3×4, 3×5, 3×6, 4×3, 4×4, 5×2, 6×2} 
     \item  \begin{tikzpicture}
        \fill[white] (0,0) -- (0.1,0.1) -- (0,0.2) -- (-0.1,0.1) -- cycle;
        \end{tikzpicture} \blackdot{}  \textbf{\small ~Large}      {\small $(10^6 \leq |\mathcal{S}| < 10^{10})$:}
          \scriptsize{4×5, 5×3, 4×6, 5×4, 6×3}
    \item \blackdot{}\blackdot{} \textbf{\small ~X-Large}
          {\small $(|\mathcal{S}| \geq 10^{10})$:}
          \scriptsize{5×5, 6×4, 5×6, 6×5, 6×6}
\end{itemize}
\vspace{-0.2cm}

% \yuchen{TODO: describe the Z3 conflicts and how we use them to measure the complexity of the puzzles. Bscially, we run z3 solver on the puzzles for multiple times and take the average number of conflicts as the complexity measure. Z3 is based on the DPLL algorithm, which is a backtracking algorithm. The number of conflicts is a good measure of the complexity of the problem. A puzzle with 0 conflicts can be solved by forward chaining, while a puzzle with a large number of conflicts requires backtracking.
% Therefore, we can use the number of conflicts as a measure of the complexity of the puzzle.}

% \textbf{Z3 conflicts.}
% While the search space size provides a useful measure of puzzle scale, it is not the only indicator of a puzzle's complexity.
% To provide an additional measure of puzzle complexity, we utilize the Z3 SMT solver's conflict metric. When solving a puzzle, Z3~\citep{Z3} employs the DPLL (Davis-Putnam-Logemann-Loveland) algorithm, a backtracking-based approach for solving boolean satisfiability problems. During solving, Z3 records the number of conflicts encountered - situations where the solver must backtrack due to contradictions in its current assignment. We run Z3 multiple times on each puzzle and take the average number of conflicts as a complexity measure. Puzzles with zero conflicts can typically be solved through simple forward chaining, while those with many conflicts require extensive backtracking, indicating higher logical complexity. This provides a new measure of puzzle complexity that complements the search space size.



\textbf{Z3 conflicts.}
While search space size provides a useful measure of puzzle scale, it is not the only indicator of complexity.
To complement it, we also use the Z3 SMT solver's conflict metric. Z3 \citep{demoura2008z3} uses the Conflict Driven Clause Learning (CDCL) algorithm, a backtracking approach based on the DPLL (Davis-Putnam-Logemann-Loveland) algorithm. When solving a puzzle, Z3 records the number of conflicts encountered - situations where the solver must backtrack due to contradictions in its current assignment. We run Z3 on each puzzle for 32 times and take the average number of conflicts as a measure of complexity. 
Puzzles with zero conflicts can typically be solved through simple forward chaining, whereas puzzles with more conflicts require extensive backtracking, indicating higher logical complexity. %This metric offers a complementary perspective on puzzle complexity alongside the search space size.





While search space size captures the number of candidate assignments (given uniqueness constraints), Z3 conflicts quantify the solver’s difficulty in reaching a valid solution. Together, these metrics offer a complementary view of how the difficulty of the puzzles scales with the problem size. %, highlighting the challenges posed by larger and more complex puzzles.
%Fig.~\ref{fig:heatmap} shows heatmaps illustrating the search space size and average number of Z3 conflicts encountered during solving for different ZebraLogic problem sizes, which are highly correlated with each other.
Appendix~\ref{app:details} provides additional details on how these two metrics vary as a function of the puzzle parameters ($N$, $M$). 
%As illustrated in Fig.~\ref{fig:heatmap}, both measures rise as puzzle size grows and strongly correlate with one another.




% \subsection{Challenges in Logical Reasoning with LLMs}
% \yuchen{TODO: talk about the non-monotic reasoning abilities and the potential real applications in AI.}





% \begin{itemize}
%     \item \textbf{\texttt{found\_at}}
    
%     \textbf{Description:} A literal is known to be at a specific house.
    
%     \textbf{Example:} The tea drinker lives in the middle house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{not\_at}}
    
%     \textbf{Description:} A literal is known \emph{not} to be at a specific house.
    
%     \textbf{Example:} The musician is not in the third house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{same\_house}}
    
%     \textbf{Description:} Two values are known to be at the same house.
    
%     \textbf{Example:} The musician drinks tea.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{consecutive}}
    
%     \textbf{Description:} The first value is directly to the left of the second value.
    
%     \textbf{Example:} The green house is directly to the left of the white house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{beside}}
    
%     \textbf{Description:} The two values occur side-by-side (either left or right).
    
%     \textbf{Example:} The coffee drinker and the tea drinker are next to each other.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{relative\_position}}
    
%     \textbf{Description:} The first value is somewhere to the left or right of the second value.
    
%     \textbf{Example:} The tea drinker is somewhere to the left of the musician.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{one\_between}}
    
%     \textbf{Description:} The values are separated by one house.
    
%     \textbf{Example:} There is one house between the cat and the tea drinker.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{two\_between}}
    
%     \textbf{Description:} The values are separated by two houses.
    
%     \textbf{Example:} There are two houses between the dog and the red house.
% \end{itemize}


 

% \subsection{Evaluation Metrics}

% \subsection{Understanding the difficulty of ZebraLogic}
