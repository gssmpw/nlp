\vspace{-0.2cm}
\section{Logical Reasoning as Constraint Satisfaction Problems}
\label{sec:background}
\vspace{-0.2cm}

Logical reasoning is a fundamental aspect of human intelligence and a key challenge in artificial intelligence research. While large language models (LLMs) have demonstrated impressive capabilities across many tasks, their ability to perform systematic logical reasoning remains an open question. To study this systematically, we need a framework that allows us to:
\begin{itemize}[leftmargin=*,itemsep=0pt,parsep=0pt,topsep=0pt,partopsep=0pt]
    \item isolate logical reasoning from other cognitive abilities, domain knowledge or math computation;
    \item precisely control the complexity of reasoning required; and
    \item objectively evaluate the correctness of the reasoning process;
\end{itemize}

In this work, we focus on using constraint satisfaction problems (CSPs) as a controlled framework for evaluating LLMs' logical reasoning capabilities. By framing reasoning tasks as CSPs, we can systematically assess how well LLMs follow logical constraints and deduce valid conclusions, independent of domain knowledge or mathematical computation.
CSPs provide an ideal framework as they are mathematically well-defined, can be scaled in complexity and search space size, and have verifiable solutions that we can automatically evaluate. 
We focus specifically on logic grid puzzles, a class of CSPs that requires pure deductive reasoning while remaining accessible enough to serve as an effective testbed for studying LLM capabilities and their scaling behavior.


\subsection{Logic Grid Puzzles}

% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. 
% Thus, we introduce ZebraLogic, a dataset using these puzzles to evaluate LLMs' logical reasoning capabilities.

% \yuchen{Argue that many other difficult AI problems are also essentially CSPs or contain CSPs as subproblems. For example, Sodoku, crossword puzzles, Chess, Go, etc.
% --
% Many difficult AI problems can indeed be argued to be CSPs or contain CSPs as subproblems. While not all aspects of complex games like Chess and Go are best modeled as CSPs, certain components within these games can be approached using CSP techniques. The CSP framework is powerful due to its generality and the availability of robust solving methods, making it a fundamental tool in AI for tackling problems that involve satisfying complex sets of constraints.
% --
% Understanding problems through the CSP lens allows researchers and practitioners to apply a wide range of algorithmic strategies and to generalize solutions across different domains. This perspective is valuable for both theoretical insights and practical applications in artificial intelligence.
% }

% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. CSPs represent a fundamental framework in artificial intelligence, encompassing many challenging problems such as Sudoku, crossword puzzles, and certain aspects of complex games like Chess and Go. While not all components of these complex games are best modeled as CSPs, the framework's power lies in its generality and the availability of robust solving methods for handling complex sets of constraints.

% CSPs represent a fundamental framework in artificial intelligence, appearing in crucial applications. The framework's power lies in its ability to explicitly represent logical relationships and dependencies, making it particularly suitable for evaluating an LLM's capacity for systematic reasoning and constraint satisfaction across a wide range of problems and domains.
% This makes CSPs particularly valuable for both theoretical research and practical applications in artificial intelligence. Given these advantages, we introduce ZebraLogic, a dataset using logic grid puzzles to evaluate LLMs' logical reasoning capabilities.
% Logic grid puzzles are a type of deductive reasoning task that is a typical Constraint Satisfaction Problem (CSP). They are used in exams like the Law School Admission Test (LSAT) and can model many real-world problems like meeting planning, scheduling, and resource allocation. 

Logic grid puzzles are a type of deductive reasoning task that represents a typical Constraint Satisfaction Problem (CSP). These puzzles, which appear in exams like the Law School Admission Test (LSAT), can model many real-world problems including meeting planning, scheduling, and resource allocation. CSPs represent a fundamental framework in artificial intelligence, with their power lying in the ability to explicitly represent logical relationships and dependencies. This makes them particularly suitable for evaluating an LLM's capacity for systematic reasoning and constraint satisfaction across a wide range of problems and domains. Given these advantages, we introduce ZebraLogic, a dataset using logic grid puzzles to evaluate LLMs' logical reasoning capabilities.



\begin{figure}[t]
    \centering
    %\includegraphics[width=0.9\linewidth]{figures/KK_data_generation.pdf}
    \includegraphics[width=1\linewidth]{assets/lgp_example_only.pdf}
    \vspace{-1mm}
    \caption{
    \small This example from the ZebraLogic dataset features 3 houses (N=3) and 3 attributes (M=3), with 6 clues (K=6). The Background outlines the attributes, their possible values, and the uniqueness constraints. The Clues provide additional constraints regarding the attributes. The task for the model is to determine the correct assignment of attributes to each house based on these clues, as illustrated in the Solution grid.
    }
    % \vspace{-2mm}
    \label{fig:lgp_example}
\end{figure}

% \subsection{Logic Grid Puzzles}
% \label{sec:zebra_puzzles}

% Logic grid puzzles (also known as Zebra puzzles) represent a specific class of CSPs that are particularly well-suited for evaluating logical reasoning capabilities. 
% These puzzles require pure deductive reasoning to determine the correct assignment of values to variables based on given constraints, without requiring domain knowledge or mathematical computation. 

% To systematically study LLMs' logical reasoning abilities using this framework, we have created ZebraLogic, a benchmark dataset of logic grid puzzles.
Each puzzle in ZebraLogic consists of $N$ houses (numbered 1 to $N$ from left to right) and $M$ different attributes for each house. There are $N$ distinct values for each attribute, and each house must have a unique value for each attribute. Given a list of $K$ clues, a reasoning model must use logical deduction to determine the unique correct assignment of values. Figure \ref{fig:lgp_example} illustrates an example of such a puzzle.
In the bottom part of Figure \ref{fig:lgp_example}, a reasoning chain for solving the puzzle is shown. 
Importantly, while some ZebraLogic puzzles can be solved through straightforward linear deduction, many require more complex \textit{non-monotonic} reasoning strategies, such as counterfactual reasoning that involves backtracking and revising assumptions. This is particularly true as the search space grows larger and the clues become more intricate -- a key aspect of our study on the scaling behavior of LLMs.
 
%  Puzzle [lgp-test-3x3-2]




\subsection{Problem Formulation}
 
We provide a detailed mathematical formulation of logic grid puzzles as a CSP.
This formulation not only clarifies the underlying structure of the puzzles in ZebraLogic but also highlights how our study can be generalized to various reasoning problems.
We use the example in Fig.~\ref{fig:lgp_example} for illustration.

\textbf{Background.} Consider three houses on a street, numbered 1 to 3. Each house has a different occupant with unique \textbf{attributes}: \texttt{Name} (\(\mathcal{V}_{\text{Name}} = \{ \text{Eric},\ \text{Peter},\ \text{Arnold} \}\)), \texttt{Drink} (\(\mathcal{V}_{\text{Drink}} = \{ \text{milk},\ \text{water},\ \text{tea} \}\)), and \texttt{Hobby} (\(\mathcal{V}_{\text{Hobby}} = \{ \text{photography},\ \text{cooking},\ \text{gardening} \}\)).
Each attribute \( a \in \mathcal{A} \) represents a category of characteristics (i.e., an attribute), and each value in \(\mathcal{V}_{a}\) is a possible assignment for that attribute.
To model the puzzle as a Constraint Satisfaction Problem, we define variables representing the assignment of values to attributes for each house.

\vspace{-0.2cm}
\begin{itemize}[noitemsep,topsep=0pt,leftmargin=3em]
    \item Let $H = \{1, 2, 3, \cdots\}$ be the set of houses, $|H| = N$.
    \item Let $\mathcal{A} = \{\text{Name}, \text{Drink}, \text{Hobby}, \cdots \}$ be the set of attributes, $|\mathcal{A}| = M$.
    \item Define variables $x_{a,\ k} \in \mathcal{V}_{a}$ for each attribute $a \in \mathcal{A}$ and house $k \in H$.
    % e.g., $x_{\text{Drink},\ k}$ is the Drink for house $k$.
\end{itemize}
\vspace{-0.2cm}
 


\textbf{Uniqueness Constraints:}
The constraints ensure that each value is assigned exactly once, as described in the Background part in Figure~\ref{fig:lgp_example}.
For each attribute, the set of assigned values across all houses must exactly match the set of possible values. This is expressed as:  $\{ x_{a,\ k} \mid k \in H \} = \mathcal{V}_{a}$.

% \textbf{Unique Attributes per House:} Additionally, for each house \( k \in H \), each house must have one unique value for each attribute. This means that each house must have one unique name, one unique drink, and one unique hobby.



\textbf{Clue-Based Constraints:} 
Each clue in the puzzle introduces additional constraints that must be satisfied by any valid assignment. Under the hood, these clues are translated into first-order logic formulas that constrain the relationships between variables. For our example puzzle in Figure~\ref{fig:lgp_example}, the constraints can be formulated as follows:
 
\begin{AIbox}{Clue-based Constraints (Example in Figure~\ref{fig:lgp_example}).}
    \small 
    \begin{enumerate}[label=\textbf{Clue \arabic*.}, leftmargin=3em, itemsep=0em]
        \item \textit{``Arnold is not in the first house''}: \textcolor{purple}{\( x_{\text{Name},\ 1} \ne \text{Arnold} \)}
        \item \textit{``The person who likes milk is Eric''}:  
            \textcolor{purple}{$\forall k \in H,\ (x_{\text{Name},\ k} = \text{Eric}) \iff (x_{\text{Drink},\ k} = \text{milk})$}
        \item \textit{``The photography enthusiast is not in the first house''}: \textcolor{purple}{\( x_{\text{Hobby},\ 1} \ne \text{photography} \)}
        \item \textit{``The person who loves cooking is directly left of the person who likes milk''}:  
            \begingroup
            \setlength{\abovedisplayskip}{0pt}
            \setlength{\belowdisplayskip}{0pt}
            \[ \textcolor{purple}{\forall k \in H,\ k < N,\ (x_{\text{Hobby},\ k} = \text{cooking}) \implies (x_{\text{Drink},\ k+1} = \text{milk})} \] 
            \endgroup 
        \item \textit{``The one who only drinks water is Arnold''}: \textcolor{purple}{$\forall k \in H,\ (x_{\text{Name},\ k} = \text{Arnold}) \iff (x_{\text{Drink},\ k} = \text{water})$}
        \item \textit{``The person who likes milk is not in the second house''}: \textcolor{purple}{\( x_{\text{Drink},\ 2} \ne \text{milk} \)}
    \end{enumerate}
\end{AIbox}

% Note that there are also several implicit constraints about positions such as the leftmost house cannot be on the right of any other house, and the rightmost house cannot be on the left of any other house, as we can see in Clue 4. These constraints translate the verbal clues into precise mathematical conditions that any valid assignment must satisfy.  
 
Note that there are also several implicit positional constraints that must be considered. For example, the leftmost house cannot be on the right of any other house, and the rightmost house cannot be on the left of any other house (as relevant in Clue 4). These spatial constraints, combined with the explicit clues, translate the verbal descriptions into precise logical conditions to be satisfied.




\textbf{Objective.}
Each variable $x_{a,\ k}$ can take any value from its attribute's possible values:
$x_{a,\ k} \in \mathcal{V}_{a} $
The objective is to determine the assignment of attributes to each house such that all the given constraints are satisfied, which are defined above.
Constraints are conditions that any valid assignment must satisfy. They are derived from the uniqueness of values and the specific clues provided.


% \section{ZebraLogic: Examining the Challenges in Logical Reasoning for LLMs}
% % \vspace{-0.2cm}
% \label{sec:zebralogic}


\subsection{ZebraLogic Dataset Creation Process} 
\label{ssec:dataset_creation}

% Zebra puzzles can be synthetically generated by programs. 

% \begin{algorithm}[H]
%     \caption{ZebraLogic Puzzle Generation}
%     \begin{algorithmic}[1]
%     \State \textbf{Define} a set of attributes $\mathcal{A}$ and their possible values $\mathcal{V}_a$ for each attribute $a \in \mathcal{A}$
%     \State \textbf{Establish} clue types and language templates with placeholders for values
%     \State \textbf{Initialize} a solution table by randomly assigning values on a sampled grid
%     \State \textbf{Enumerate} all possible clues that describe relations among variables
%     \State \textbf{Assign} weights to clues based on complexity and number of variables involved
%     \While{puzzle does not have a unique solution}
%         \State \textbf{Sample} clues based on their weights
%         \State \textbf{Check} if the sampled clues uniquely lead to the solution
%         \If{not unique}
%             \State \textbf{Remove} clues through weighted sampling
%         \EndIf
%     \EndWhile
%     \State \textbf{Represent} the puzzle with prompting templates for LLM inputs
%     \end{algorithmic}
% \end{algorithm}
    

 
% We start by defining a set of attributes and their possible values (e.g., the feature CarModel might have values like Tesla Model 3, Ford F150, etc.). 
% Next, we establish the clue types and their language templates, which include placeholders for values to be filled in. 
% Each clue type is logically structured to describe a type of constraint that can involve multiple variables. 
% To create a ZebraLogic example, we randomly assign values on a sampled grid as the solution table. 
% Then, we enumerate all possible clues that can describe the relation among variables. 
% To construct a valid puzzle with a unique solution, we sample clues based on their weights, which are determined by their complexity and the number of variables involved.
% By iteratively removing clues through weighted sampling, we continuously check if the remaining set of clues can uniquely lead to the above solution. Finally, we represent the puzzle with prompting templates to form the inputs for the LLMs.

To create puzzles, we first define a set of attributes and their corresponding value sets. We also establish some clue types, each with its own language templates containing placeholders for values. 


\textbf{Attributes and Values.} 
We construct the attribute set $\mathcal{A}$, which includes the following elements: \textit{Name, Color, Nationality, Animal, Drink, Cigar, Food, Flower, PhoneModel, Children, Smoothie, Birthday, Occupation, Height, CarModel, FavoriteSport, MusicGenre, BookGenre, HairColor, Mother, HouseStyle, Education, Hobby, Vacation, Pet}. Each attribute is associated with a minimum of 6 possible values, ensuring a rich and diverse set of puzzles. Importantly, we always include the \texttt{Name} attribute in our samples, as it serves as a crucial element in the puzzle-solving process. 

\textbf{Clue Types.} 
The possible clue types are categorized into several types, including:
\begin{AIbox}{Clue Types and Illustrative Examples.}
    \small 
    \begin{itemize}[leftmargin=0.5em]
        \item \texttt{\textbf{Found\_At}}: the tea drinker lives in House 3
        \item \texttt{\textbf{Same\_House}}: the musician drinks tea
        \item \texttt{\textbf{Not\_At}}: the musician does not drink tea (not at the same house)
        \item \texttt{\textbf{Direct\_Left/Right}}: the greenhouse is directly to the left/right of the white house
        \item \texttt{\textbf{Side\_By\_Side}}: the coffee drinker and the tea drinker are next to each other
        \item \texttt{\textbf{Left/Right\_Of}}: A is somewhere to the left/right of B
        \item \texttt{\textbf{One/Two\_between}}: There is one/two houses between A and B
    \end{itemize}
\end{AIbox}

\begin{algorithm}[H]
    \caption{ZebraLogic Puzzle Generation.}
    \label{alg:zebra_puzzle_generation}
    \begin{algorithmic}[1]
    \small 
    \State \textbf{Define} a set of possible attributes $\mathcal{A}_{\text{all}}$ and their value sets $\mathcal{V}_a$ for each $a \in \mathcal{A}_{\text{all}}$
    \State \textbf{Define} clue types $\mathcal{C} = \{c_1, \ldots, c_L\}$ with templates $T(c)$ for each $c \in \mathcal{C}$
    \State \textbf{Input:} Number of houses $N$, number of attributes $M$
    
    \State \textbf{Sample} $M$ attributes from $\mathcal{A}_{\text{all}}$ to form $\mathcal{A} = \{a_1, \ldots, a_M\}$
    
    \State \textbf{Initialize} solution $S: H \times \mathcal{A} \rightarrow \bigcup_{a \in \mathcal{A}} \mathcal{V}_a$ by random assignment
    \Statex \hrulefill
    \State $C \gets \texttt{ClueGeneration}(S)$ \Comment{Initialize the clue set with all possible clues that describe the solution $S$.}
    \While{$C \neq \emptyset$}
        \State $p \gets \texttt{SampleClue}(C)$ \Comment{Sample a clue to remove}
        \State $C' \gets C \setminus \{p\}$
        \If{$|\text{Solutions}(C')| = 1$ and $\text{Solutions}(C') = \{S\}$}
            \State $C \gets C'$ \Comment{Remove the clue if uniqueness is maintained}
        \Else
            \textbf{break} \Comment{Stop if removing leads to multiple solutions or unsolvability} 
        \EndIf
    \EndWhile
    \State \textbf{Return} $(S, C)$ \Comment{Solution and a mimimal set of  clues. Then, we can create the final puzzle with templates.}
    \end{algorithmic}
\end{algorithm}

\textbf{Puzzle Generation Algorithm.}
Algorithm~\ref{alg:zebra_puzzle_generation} outlines our approach for generating ZebraLogic puzzles. 
The process starts by sampling $M$ attributes from the full attribute set and creating an initial solution grid $S$ through random value assignments. 
From this solution, we generate a comprehensive set of clues $\mathcal{C}$ that capture all valid relationships between values in the grid. 
The algorithm then employs an iterative minimization procedure - at each step, it randomly samples a clue $p \in \mathcal{C}$ and attempts to remove it. Using a SAT solver, it verifies whether the reduced clue set $\mathcal{C}' = \mathcal{C} \setminus \{p\}$ still uniquely determines the original solution $S$. If uniqueness is preserved, $p$ is permanently removed and the process continues. This iteration terminates when removing any additional clue would either make the puzzle unsolvable or introduce multiple valid solutions.
We employ weighted sampling during clue selection, assigning higher probabilities to simpler clue types to balance puzzle complexity.
% named PicoSAT~\citep{Biere2008PicoSATE} 

The result is a minimal set of clues that, when combined with the background information about the attributes and their possible values, forms a logically sound puzzle with a single, unique solution. Finally, we use predefined prompting templates to format the puzzle, creating suitable inputs for LLMs to solve.
This approach ensures that each generated puzzle is both solvable and challenging, requiring a combination of logical deduction and non-monotonic reasoning strategies to solve.
%  the application of logical reasoning skills without relying on external knowledge or complex mathematical computations.

\textbf{Dataset Statistics.}
The dataset has 1,000 puzzles where the size of the search space varies significantly, ranging from 2x2 to 6x6 grids (i.e., 25 different sizes in total), 
leading to a combinatorial explosion in complexity. There are 40 randomly sampled puzzles for each grid size. 

% The dataset is publicly available at \url{https://huggingface.co/datasets/allenai/ZebraLogicBench}.


\subsection{Measuring Puzzle Complexity}

\textbf{Search space.} 
We define the solution space of a ZebraLogic puzzle as the total number of possible configurations that can satisfy the uniqueness constraints of the puzzle. That is, a $N \times M$ grid has a solution space of $(N!)^M$, where $N$ is the number of houses and $M$ is the number of attributes. The complexity of the search space increases factorially with the size of the grid, leading to a combinatorial explosion in the number of possible configurations.
For example, a 3x4 grid has a solution space of $(3)^4 = 1296$, while a 4x3 grid has a solution space of $(4!)^3 = 13824$; A 6x4 grid has a solution space of $720^4 \approx 2.7 \times 10^{11}$.
To better group the puzzles based on their complexity, we categorize them into four groups based on the size of the search space:
\vspace{-0.2cm}
\begin{itemize}[leftmargin=0.9cm]
    \small
    \item \textbf{Small}     \hspace{1.5em} $(1 \leq \text{search space} < 10^3)$  \hspace{2.3em} \small{Grids: 2×2, 2×3, 2×4, 2×5, 2×6, 3×2, 3×3, 4×2}
    \item \textbf{Medium}    \hspace{0.3em} $(10^3 \leq \text{search space} < 10^6)$               \hspace{1.3em} \small{Grids: 3×4, 3×5, 3×6, 4×3, 4×4, 5×2, 6×2}
    \item \textbf{Large}     \hspace{1.5em} $(10^6 \leq \text{search space} < 10^{10})$            \hspace{1.0em} \small{Grids: 4×5, 4×6, 5×3, 5×4, 6×3}
    \item \textbf{X-Large}   \hspace{0.5em} $(\text{search space} \geq 10^{10})$                   \hspace{3.3em} \small{Grids: 4×6, 5×5, 5×6, 6×4, 6×5, 6×6}
\end{itemize}
\vspace{-0.2cm}

% \yuchen{TODO: describe the Z3 conflicts and how we use them to measure the complexity of the puzzles. Bscially, we run z3 solver on the puzzles for multiple times and take the average number of conflicts as the complexity measure. Z3 is based on the DPLL algorithm, which is a backtracking algorithm. The number of conflicts is a good measure of the complexity of the problem. A puzzle with 0 conflicts can be solved by forward chaining, while a puzzle with a large number of conflicts requires backtracking.
% Therefore, we can use the number of conflicts as a measure of the complexity of the puzzle.}

\textbf{Z3 conflicts.}
While the search space size provides a useful measure of puzzle scale, it is not the only indicator of a puzzle's complexity.
To provide an additional measure of puzzle complexity, we utilize the Z3 SMT solver's conflict metric. When solving a puzzle, Z3~\citep{Z3} employs the DPLL (Davis-Putnam-Logemann-Loveland) algorithm, a backtracking-based approach for solving boolean satisfiability problems. During solving, Z3 records the number of conflicts encountered - situations where the solver must backtrack due to contradictions in its current assignment. We run Z3 multiple times on each puzzle and take the average number of conflicts as a complexity measure. Puzzles with zero conflicts can typically be solved through simple forward chaining, while those with many conflicts require extensive backtracking, indicating higher logical complexity. This provides a new measure of puzzle complexity that complements the search space size.





% \subsection{Challenges in Logical Reasoning with LLMs}
% \yuchen{TODO: talk about the non-monotic reasoning abilities and the potential real applications in AI.}





% \begin{itemize}
%     \item \textbf{\texttt{found\_at}}
    
%     \textbf{Description:} A literal is known to be at a specific house.
    
%     \textbf{Example:} The tea drinker lives in the middle house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{not\_at}}
    
%     \textbf{Description:} A literal is known \emph{not} to be at a specific house.
    
%     \textbf{Example:} The musician is not in the third house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{same\_house}}
    
%     \textbf{Description:} Two values are known to be at the same house.
    
%     \textbf{Example:} The musician drinks tea.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{consecutive}}
    
%     \textbf{Description:} The first value is directly to the left of the second value.
    
%     \textbf{Example:} The green house is directly to the left of the white house.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{beside}}
    
%     \textbf{Description:} The two values occur side-by-side (either left or right).
    
%     \textbf{Example:} The coffee drinker and the tea drinker are next to each other.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{relative\_position}}
    
%     \textbf{Description:} The first value is somewhere to the left or right of the second value.
    
%     \textbf{Example:} The tea drinker is somewhere to the left of the musician.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{one\_between}}
    
%     \textbf{Description:} The values are separated by one house.
    
%     \textbf{Example:} There is one house between the cat and the tea drinker.
    
%     \vspace{1em}
    
%     \item \textbf{\texttt{two\_between}}
    
%     \textbf{Description:} The values are separated by two houses.
    
%     \textbf{Example:} There are two houses between the dog and the red house.
% \end{itemize}


 

% \subsection{Evaluation Metrics}

% \subsection{Understanding the difficulty of ZebraLogic}
