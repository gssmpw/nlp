\section{Related Works}
\subsection{Instruction Following in LLMs}

Instruction following is a crucial task in LLMs, requiring them to generate responses aligned with user intent~\cite{zhou2023instruction}. 
%As this task has become central to the utility of LLMs, numerous open-ended instruction tuning algorithms have been developed to improve model performance. 
The rapid advancement of instruction tuning algorithms~\cite{wang2022self, ouyang2022training,xu2023wizardlm}, along with strategic data selection~\cite{wang2024survey}, has enabled LLM to achieve impressive zero-shot performances across various downstream tasks~\cite{peng2023instruction, wang2023aligning}.

Despite this progress, several studies highlight the limitations of LLMs when dealing with complex instructions~\cite{xu2023wizardlm,zhou2023instruction,he2024complex}. 
For example,~\citet{wen2024benchmarking} and~\citet{he2024can} each introduce a benchmark aimed at evaluating the performance of LLMs on complex instructions that consist of multiple constraints. 
Also,~\citet{jiang2023followbench} introduce FollowBench, an instruction-following benchmark designed with multi-level fine-grained constraints. 
Additionally, \citet{wallace2024instruction} explore the concept of instruction hierarchy, revealing that models struggle when presented with instructions of conflicting priorities, and propose the notion of instruction privilege as a guideline to direct model behavior in such scenarios.
%They proposed the notion of instruction privilege as a rule to guide model behavior in such scenarios, suggesting how LLMs should act when prioritizing between conflicting instructions.
Instruction conflict differs from instructional distraction in that the former involves multiple instructions with a defined priority order, while the latter offers a single instruction, with the input text serving as distractors that mimic an instructional format. However, no benchmark currently evaluates LLMs in \textit{instructional distraction} scenarios, and this paper is the first to introduce a benchmark aimed at evaluating LLMs in such contexts.
%providing a novel perspective on their robustness and adaptability in such challenging contexts.

\subsection{LLM-powered Data Generation and Processing}

LLMs have gained significant attention in data generation and processing tasks~\cite{gandhi2024better,long2024llms,guo2024generative}. 
Their ability to produce coherent and contextually relevant text makes them invaluable for augmenting training datasets~\cite{gilardi2023chatgpt,rosenbaum2023using,he2023annollm,singh2023beyond,macias2024finetuning}. 
For example, existing data can be paraphrased using LLMs to enhance diversity, thus improving model robustness. 
Moreover, to ensure data quality, tasks such as proofreading and filtering are commonly performed using LLMs~\cite{lin2024criticbench}.
Furthermore, as acquiring annotated data for low-resource languages poses significant challenges~\cite{magueresse2020low}, researchers leverage LLMs' superior translation capabilities~\cite{vilar2022prompting,zhang2023prompting} to translate the available data into target languages~\cite{zhang2021bstc,yang2023bigtranslate}. 
%These steps help maintain data integrity and ensure the suitability of the data for training purposes. 
LLMs are also utilized for style transfer tasks~\cite{jin2022deep,mukherjee2024text}, generating variations of text in different styles while preserving the underlying content. 
However, when the target input data to be processed contains embedded instructions, \textit{instructional distraction} can occur. This study analyzes how various LLMs respond to instructional distractions in various data generation and processing tasks.


