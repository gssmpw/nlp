
\begin{figure*}[t]
\centering
\begin{tikzpicture}

\node[inner sep = 0pt] (1) at (0,0) {\(\bullet\)};
\node[inner sep = 0pt] (2) at (1,0) {\(\bullet\)};
\node[inner sep = 0pt] (3) at (1.5,0.866) {\(\bullet\)};
\node[inner sep = 0pt] (4) at (1,1.732) {\(\bullet\)};
\node[color=red, inner sep = 0pt] (5) at (0,1.732) {\(\bullet\)};
\node[inner sep = 0pt] (6) at (-0.5,0.866) {\(\bullet\)};

\node[inner sep = 0pt] (7) at (3,0) {\(\bullet\)};
\node[inner sep = 0pt] (8) at (4,0) {\(\bullet\)};
\node[inner sep = 0pt] (9) at (4,-1) {\(\bullet\)};
\node[inner sep = 0pt] (10) at (3,-1) {\(\bullet\)};

\node[color=red, inner sep = 0pt] (11) at (5,0.7) {\(\bullet\)};
\node[inner sep = 0pt] (12) at (6,0.7) {\(\bullet\)};
\node[inner sep = 0pt] (13) at (4.68,1.65) {\(\bullet\)};
\node[inner sep = 0pt] (14) at (6.32,1.65) {\(\bullet\)};
\node[inner sep = 0pt] (15) at (5.5,2.34) {\(\bullet\)};

\begin{scope}[on background layer]
\fill[gray!15] (0.5,0.866) circle (1.15);
\fill[gray!15] (3.5,-0.5) circle (0.85);
\fill[gray!15] (5.5,1.45) circle (1.05);

\draw[line width=2mm, red!15, line cap=round] (5) -- (2) -- (3) -- (7) -- (8) -- (13) -- (14) -- (11);
\end{scope}


\draw[->] (1) edge (2) edge (3) edge (5);
\draw[color=red, ->] (2) edge (3);
\draw[->] (3) edge (4) edge (6);
\draw[->] (4) edge (5);
\draw[color=red, ->] (5) edge (2);
\draw[->] (6) edge (1);

\draw[color=red, ->] (7) edge (8);
\draw[<->] (7) edge (9);
\draw[->] (8) edge (9);
\draw[->] (9) edge (10);
\draw[->] (10) edge (7);

\draw[->] (11) edge (12) edge (13);
\draw[->] (15) edge (11) edge (14);
\draw[->] (12) edge (15);
\draw[color=red, ->] (13) edge (14);
\draw[color=red, ->] (14) edge (11);

\draw[color=red, line width=0.3mm, dashed, ->] (3) edge (7);
\draw[color=red, line width=0.3mm, dashed, ->] (8) edge (13);

\node[draw, circle, line width=1pt, minimum size=5mm, fill=gray!15] (A) at (9,0.7) {};
\node[draw, circle, line width=1pt, minimum size=5mm, fill=gray!15] (B) at (10.7,-0.3) {};
\node[draw, circle, line width=1pt, minimum size=5mm, fill=gray!15] (C) at (11.4,1.3) {};

\draw[dashed, ->, line width=0.3mm] (A) edge (B);
\draw[dashed, ->, line width=0.3mm] (B) edge (C);

\draw[-{Triangle[width=10pt,length=8pt]}, line width=5pt] (7.0,0.5) -- (8.1,0.5) node[midway, above, yshift=2.5pt] {{\small distillation}};

\node[color=red] at (0,2.05) {$X_{\inn}$};
\node[color=red] at (5,0.4) {$X_{\out}$};
 
\end{tikzpicture}
\caption{\small \textit{(Left)} Example of metastable graph with three clusters. Each state represents a logical assertion and edges correspond to reasoning steps. Solid and dashed arrows indicate easy (within-cluster) and hard (inter-cluster) reasoning steps, respectively. The goal of the reasoner is to retrieve a valid CoT path from $X_{\inn}$ to $X_{\out}$ (highlighted). Search aims to use CoT generated from the pretrained model to explore the linguistic model and identify hard steps, which can then be used to fine-tune the pretrained model via RL to improve its generation. \textit{(Right)} The coarse-grained dynamics of CoT at long timescales can be represented by a meta-chain on the set of clusters and distilled into a smaller model, which can generate reasoning paths more efficiently.}
\label{introfig}
\end{figure*}

\section{Introduction}

Pretraining and inference constitute two distinct computational phases in large language models (LLMs). The pretraining phase, during which the model learns from vast amounts of text data through next-token prediction \citep{radford2018improving}, is well known for its high computational demands, and its scaling behavior has been extensively studied \citep{kaplan2020scaling,hoffmann2022training,dubey2024llama}. 
On the other hand, inference (running the trained model to generate responses) was traditionally considered computationally inexpensive, until a recent paradigm shift demonstrating that model reasoning capabilities can drastically improve by allocating more computational resources during inference time \citep{jaech2024openai,guo2025deepseek,team2025kimi}. Hence it is crucial to understand the advantages scaling inference computation can provide beyond those achieved through pretraining \citep{jones2021scaling,snell2024scaling,wu2024inference}. 

Reasoning LLMs follow the chain-of-thought (CoT) \citep{nye2021show,wei2022chain} format where intermediate reasoning steps are iteratively generated before arriving at a final answer. Various reinforcement learning (RL) based approaches \citep{bai2022constitutional} have been proposed to improve CoT quality at inference time, such as process reward modeling \citep{lightman2023let,uesato2022solving}, Monte-Carlo Tree Search (MCTS)  \citep{silver2018general,feng2023alphazero,trinh2024solving,Xie24}, and data self-generation \citep{zelikman2022star,kumar2024training}. Theoretically, the benefit of (sufficiently long) CoT has been studied in terms of expressive power and statistical efficiency \citep{merrill2023expresssive,li2024chain,kim2024transformers,wen2024sparse}. 

Motivated by the discrete and sequential nature of CoT, we follow \citet{xu2019can,sanford2024understanding,abbe2024far,besta2024graph} and consider learning on graphs as an ideal abstraction of complex reasoning tasks. We model pretraining as the process of discovering the graph structure, or the \textit{linguistic} (world) model, upon which a \textit{reasoning} (inference) component is implemented to search for a valid path between states. Building on the observation that intermediate reasoning steps vary in difficulty, we assume the underlying graph consists of dense clusters connected by sparse, low-probability edges representing ``hard" reasoning steps. At a high level, this division parallels the System 1 vs. System 2 distinction discussed in \citet{kahneman2011thinking,xiang2025towards}. We further model CoT generation as a Markov process and characterize hitting/escape times by leveraging \emph{metastability theory} \citep{Bovier02,Betz16}, which describes systems with multiple locally stable states separated by high energy barriers, leading to a timescale separation between local and global transitions (e.g., a reasoner may become stuck at a critical reasoning step for an extended period). Our toy model captures key phenomena observed in the training of reasoning LLMs:

\begin{itemize}
    \item \textit{Benefit of search and RL.} Inference-time search elicits reasoning capabilities beyond pretraining \citep{jones2021scaling,yao2024tree,snell2024scaling}. Roughly speaking, running search on the pretrained graph identifies important reasoning steps, and then RL can improve the base linguistic model by modifying the graph and reweighting the corresponding transition probabilities. 
    \item \textit{Benefit of distillation.} Reasoning patterns can be distilled into a smaller model \citep{hsieh2023distilling,gandhi2024stream,guo2025deepseek}. By training on curated CoT data of the larger model, we can efficiently represent the reasoning dynamics with a much smaller meta-chain that compresses the dense clusters (representing ``easy'' steps). 
\end{itemize}



\subsection{Our Contributions}

We study the metastable Markov process underlying CoT generation (see Figure~\ref{fig1}) which provides insights into the roles of pretraining, search, RL, and distillation. Our contributions are summarized as follows. 

\begin{itemize}
\item In Section~\ref{sec:metastable}, we introduce a perturbed Markov chain model for CoT reasoning that differentiates between easy and hard reasoning steps through a dense-sparse structure. We develop a quantitative analysis of its metastable dynamics over long timescales by deriving tight bounds on the expected hitting times of target states. 
\item In Section~\ref{sec:search}, we demonstrate that inference-time search based on intrinsic reward improves hitting times by identifying key reasoning steps, whose generation can be enhanced directly or by fine-tuning the base model with RL. Moreover, optimization guarantees for pretraining and RL (PPO-Clip) are provided for a simple softmax model.
\item In Section~\ref{sec:distill}, we show that a compressed version of the CoT dynamics can be distilled to a smaller model by only learning the macroscopic cluster transitions. We prove that this representation efficiently maps out paths through clusters while preserving essential dynamical quantities of the original chain.
\item Finally, in Section~\ref{sec:hard} we prove that large test time compute (unbounded search) is necessary to solve a computational version of the path-finding task, by introducing a new statistical query (SQ) complexity measure that accounts for additional information the learner can access (e.g., CoT path, local search data).
\end{itemize}

All proofs are deferred to the appendix. A discussion of additional related works is provided in Appendix~\ref{app:related}. Metastable dynamics and hitting times are studied in Appendices~\ref{app:prelim}-\ref{app:perturb}, optimization dynamics are analyzed in Appendix~\ref{app:opt}, and learning-theoretic lower bounds are given in Appendix~\ref{app:hard}.