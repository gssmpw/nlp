\section{Related Works}
\subsubsection{Direct Model Editing Works} These approaches include aforementioned works ____. Other works use a hypernetwork to predict parameter updates for a model ____ 

\subsubsection{Retrieval Based Works} Outside of direct model editing approaches ____, other approaches have sought to adapt to changing knowledge via storing external edit memories and employing various in-context learning and retrieval mechanisms. IKE and others add all edits in the LLM context ____; SERAC identifies if a related fact has been edited and retrieves it ____; MeLLo and DeepEdit iteratively retrieve edited memories during the generation and decoding process ____. 
    
We note that these retrieval-based editing approaches are fundamentally different than direct model editing approaches. Direct model editing leaves the model architecture and code entirely the same with the only change being to parameter weights. This means any system developed to use the original model can use the updated model with no other changes. In contrast, retrieval-based editing systems fundamentally change how the model is used and functions. For example, MeLLo requires setting up a retrieval database, iteratively prompting the LLM, making multiple calls to the database, and prompting the LLM to create further sub-questions ____. This fundamentally changes the characteristics of the model, increases latency, and alters model behavior for non-QA tasks. An alternate line of work aims to supplement the parametric knowledge of LLMs by augmenting the model prompt with information retrieved from an indexed corpus ____ or Knowledge Graphs ____. 

\subsubsection{Additional Aspects of Model Editing} Other papers have looked into other aspects of contextual knowledge for edits such as reversibility ____, multi-linguality ____, or other implied logical conditions given an edit ____.