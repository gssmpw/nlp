\begin{figure*}[t!]
    \centering
    \includegraphics[width=\linewidth]{figures/data_generation/data_generation_v7.pdf}
    \caption{
        \textbf{\dataname data engine.} Our data generation process consists of three key steps: (a) We predict object segments for each RGB frame using state-of-the-art image segmentation models~\cite{sam,ravi2024sam,zou2024segment}. (b) We pass the images and predicted masks to a region-aware vision-language model~\cite{yuan2024osprey} to generate descriptive captions for each region. (c) We project the 2D segmentation masks onto 3D points using camera parameters to create (d) 3D mask-text pairs. This pipeline enables us to generate a large-scale dataset of 3D mask-text pairs.
    }
    \label{fig:data_pipeline}
\end{figure*}
