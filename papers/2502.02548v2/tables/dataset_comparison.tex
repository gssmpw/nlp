\begin{table}[t]%
    \centering
    \resizebox{\linewidth}{!}{
        \setlength\tabcolsep{2pt}
        \begin{tabular}{@{}l|c|rrr|c|r|rrr@{}}
            \multirow{2}{*}{Train dataset} & Used & \multicolumn{3}{c|}{Mask-Caption Quality} & ScanNet20 & \multicolumn{4}{c}{ScanNet200} \\
            & ScanNet GT & \# Nouns & Coverage & Entropy & f-mIoU & f-mIoU & Head & Com. & Tail \\
            \midrule
            \multicolumn{7}{l}{\textit{Datasets using only ScanNet as source}} \\
            OV3D & \xmark & 2.5K & 70.6 & 72.8 & 45.6 & 7.0 & 18.6 & 2.1 & 0.1 \\
            RegionPLC & \xmark & 1.4K & 77.3 & 81.0 & 50.4 & 8.5 & 21.1 & 3.6 & 0.7 \\
            \rowcolor{gray!15} Mosaic3D-SN\tablefootnote{A subset of Mosaic3D-5.6M using only ScanNet as source dataset.} & \xmark & \underline{9.0K} &  \underline{92.6} & \textbf{60.7} & 65.0 & 13.0 & 30.2 & 6.9 & \underline{1.4} \\
            \midrule
            \multicolumn{7}{l}{\textit{Datasets using multiple sources}} \\
            LEO & \checkmark & 2.6K & 66.2 & - & 65.9 & \underline{14.8} & \textbf{34.3} & \underline{8.3} & \underline{1.4} \\
            SceneVerse & \checkmark & 8.8K & 60.0 & - & \underline{67.3} & 13.6 & 32.4 & 7.3 & 0.8 \\
            EmbodiedScan & \checkmark & 0.3K & 14.0 & - & 44.8 & 6.7 & 16.1 & 3.6 & 0.2 \\
            MMScan & \checkmark & 6.0K & 48.0 & - & 64.1 & 11.7 & 26.1 & 7.9 & 0.7 \\
            \rowcolor{gray!15} Mosaic3D-5.6M & \xmark & \textbf{29.9K} & \textbf{93.7} & - & \textbf{68.1} & \textbf{15.7} & \underline{32.9} & \textbf{10.8} & \textbf{2.7} \\
        \end{tabular}
    }
    \vspace{-4mm}
    \caption{\textbf{Dataset comparison.} We analyze mask-caption quality metrics and annotation-free 3D semantic segmentation performance of different training datasets, while keeping the same model architecture (SpUNet-34C), CLIP model (Recap-CLIP), and loss function (Contrastive).}
    \label{tab:existing_dataset}
    \vspace{-2mm}
\end{table}
