\section{Previous Work}
\label{sec:previous_work}

Adversarial attacks challenge the robustness of machine learning models, particularly in critical applications like image classification and object detection \citep{finlayson2019adversarial,guo2019simple,lapid2022evolutionary,alter2024robustness,carlini2017towards,lapid2023patch,lapid2023see,lapid2024open,carlini2017adversarial,vitracktamam2023foiling}.

To counter these threats, adversarial detection methods have been widely explored. Many rely on adversarial examples during training, while others operate without them to improve generalization and reduce computational costs \citep{roth2019odds,li2017adversarial,dathathri2018detecting,ma2018characterizing,carrara2017detecting,metzen2022detecting}. This paper primarily focuses on unsupervised approaches, with a brief overview of supervised methods.

\subsection{Supervised Adversarial Detection}
\label{subsec:previous_supervised}

Supervised methods train on labeled datasets to distinguish adversarial from benign inputs, leveraging explicit attack examples to refine detection.  \citet{carrara2018adversarial} introduce a feature distanceâ€“based technique using deep neural networks. By extracting representations from multiple layers, they compute input distances to detect adversarial shifts. An LSTM \citep{graves2012long} processes these distance patterns to classify inputs as adversarial or benign. \citet{lee2018simple} propose a framework that models class-wise feature activations as multivariate Gaussian distributions. Mahalanobis distances measure input deviations, and a logistic regression detector (trained on both benign and adversarial data) aggregates layer-wise distances to enhance detection reliability.

\subsection{Unsupervised Adversarial Detection}
\label{subsec:previous_unsupervised}

Unsupervised methods detect adversarial inputs without pre-training on labeled attack examples, relying on intrinsic data properties or model representations. These approaches often reduce complexity and improve generalization across attack types. \citet{xu2017feature} introduce Feature Squeezing (FS), which applies transformations like bit-depth reduction and spatial smoothing to simplify input features. Detection then is based on prediction discrepancies between original and squeezed inputs. Deep Neural Rejection (DNR) \citep{sotgiu2020deep} enhances networks with auxiliary RBF-SVM classifiers at intermediate layers. An aggregator SVM combines their outputs to reject adversarial inputs with inconsistent layer-wise representations. This method behaves as if the target model would have an additional classification neuron that determines whether to reject the sample or not. \citet{papernot2018deep} propose Deep k-NN (DKNN), which estimates feature-space density using $k$-nearest neighbors across layers. Then, they produce P-values based on those DKNN results with respect to a set of calibration benign images they store. Low p-values indicate low credibility of the input sample, maybe adversarial anomalies, enabling robust detection without attack-specific training.

\subsection{Key Differences from Prior Work}
Our methodology builds on intermediate representations for adversarial detection but introduces key differences:
\begin{enumerate}
    \item \textbf{No dependence on adversarial data.} Unlike supervised methods \citep{lee2018simple,carrara2018adversarial}, which require adversarial examples for training, our approach is fully unsupervised, eliminating computational overhead and bias from adversarial training.
    \item \textbf{Auxiliary networks with ArcFace-based feature refinement.} Rather than relying solely on raw feature statistics \citep{papernot2018deep,carrara2018adversarial,sotgiu2020deep}, we introduce auxiliary networks that refine feature spaces. These networks include: (1) a projection layer that maps features to a lower-dimensional space, and (2) an ArcFace layer that enforces margin-based separation on a hypersphere, enhancing feature discrimination.
    \item \textbf{Layer-wise modularity for fine-grained detection.} Prior works often aggregate final-layer statistics \citep{lee2018simple,sotgiu2020deep}. In contrast, we integrate auxiliary networks across multiple layers ($L_{s}, L_{s+1}, \dots, L_{N}$), capturing diverse feature granularity and improving detection effectiveness without requiring supervised external classifiers such as LSTMs or logistic regression \citep{carrara2018adversarial,lee2018simple}.
\end{enumerate}