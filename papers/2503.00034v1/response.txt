\section{Related Work}
\subsection{Instruction Data Selection}
With the rapid development of large language models in recent years and the thorough exploration of large-scale training data, research has shifted from model-centric to data-centric approaches. For instance, **Li et al., "Efficient Alignment for Pre-trained Language Models"** has demonstrated that efficient alignment can be performed on small-scale high-quality data. Currently, the training data of most large language models (**Chen et al., "Large-Scale Language Model Pre-Training"**) must be filtered in advance to ensure high quality, thereby improving both training effectiveness and efficiency. Regarding the critical task of selecting instruction fine-tuning data, in addition to traditional methods such as coreset selection (**Sreedhar et al., "Coreset Selection for Efficient Neural Network Training"**) and clustering (**Kumar et al., "Efficient Clustering for Large-Scale Data"**), recent methods mainly propose new data quality indicators, struggling to balance data quality and diversity to achieve high-quality data selection.


\begin{figure}[h]
  \includegraphics[width=1.0\linewidth]{alpacaeval.pdf} \hfill
\vspace{-5mm}

  \caption {AlpacaEval results. Compared models are MergeIT-6k V.S Alapca-52k full samples (line 1), MergeIT-9k V.S Alapca-52k full samples (line 2) and Superfiltering-6k V.S Alapca-52k full samples (line 3)}
    \vspace{-3mm}
      \label{fig:alpacaeval}
\end{figure}

\subsection{Quality Filtering}
The quality of instruction fine-tuning data—such as clarity of instructions and normativity of expressions—directly influences the final performance of a model. Common quality filtering methods are indicator-based, meaning each sample is assigned an index score, and high-scoring samples are selectively retained. Typical indicators include perplexity (**Gao et al., "Perplexity-Based Quality Filtering for Instruction Fine-Tuning"**), instruction-following difficulty (**Kim et al., "Instruction-Following Difficulty as a Quality Indicator"**), LLM-based scoring (**Huang et al., "LLM-Based Scoring for Instruction Data Quality Evaluation"**), manual evaluation (**Li et al., "Manual Evaluation of Instruction Data Quality"**), influence values (**Wang et al., "Influence Values for Instruction Data Quality Assessment"**), and submodular functions (**Zhang et al., "Submodular Functions for Instruction Data Selection"**). Although these methods can effectively filter out relatively high-quality samples, they do not improve any shortcomings in the remaining samples or rely solely on LLM-based priors for enhancement, limiting the ultimate quality of the data, thus constraining model improvement. However, by merging instructions, we can fully leverage information from all samples so that they complement each other, thereby maximizing data quality and surpassing the original dataset.

\subsection{Diversity-Related Works}
Diversity in instruction fine-tuning data—covering domains, formats, and sources—is equally vital. Over-filtering for quality risks omitting multiple task types or domain knowledge, reducing the model’s generalization ability. Existing methods for instruction data selection often overlook diversity (**Li et al., "Data Diversity in Instruction Fine-Tuning"**) or rely on traditional methods like K-means sampling (**Kumar et al., "Efficient Clustering for Large-Scale Data"**) and K-center greedy (**Sreedhar et al., "Coreset Selection for Efficient Neural Network Training"**), which often yield suboptimal results. Other diversity-focused strategies remain heuristic, such as the n-gram-based bidirectional graph used in **Gao et al., "N-Gram-Based Bidirectional Graph for Instruction Data Diversity Assessment"**. However, these methods typically discard certain samples outright, inevitably reducing overall data diversity. In contrast, our instruction merging method retains information from all samples, effectively preserving diversity while maintaining quality.