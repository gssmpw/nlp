% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\DeclareMathOperator*{\argmin}{arg\,min}

% Essential math packages


% For better looking math symbols
\usepackage{mathtools}

% For itemize and enumerate environments
\usepackage{enumitem}

% For custom spacing
\usepackage{setspace}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

\usepackage{colortbl} 
\usepackage{amssymb}
% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{hyperref}

\newcommand{\fyq}[1]{\textcolor{black}{#1}}
\newcommand{\todo}[1]{\textcolor{red}{#1}}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{\fyq{From Selection to Merging: A Novel LLM-based Merging Strategy for Better Instruction Tuning}}
\title{\fyq{MergeIT: From Selection to Merging for Efficient Instruction Tuning}  }
% \title{\fyq{MergeIT: From Selection to Merging for Better Instruction Tuning}}
% \title{\fyq{From Selection to Synthesis: A Novel LLM-based Merging Strategy for Better Instruction Tuning}}

% \title{\fyq{From Selection to Merging: Improving Data Efficiency of Instruction Tuning}}

%\title{Merging for Better Instruction Tuning: A Data-Centric Approach for Fast Instruction Tuning}

% \title{Filtering then Merging: Representation-aware Pertinent Data Blending for Fast Instruction-tuning}

% Representation-aware pertinent data blending for fast instruction-tuning

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}



\author{
% Anonymous ACL submission
 \textbf{Hongyi Cai\textsuperscript{1,2}\thanks{This work is done during internship at Shanghai Jiao Tong University.}},
  \textbf{Yuqian Fu\textsuperscript{3}},
  \textbf{Hongming Fu\textsuperscript{1}},
 \textbf{Bo Zhao\textsuperscript{1}\thanks{Corresponding Author: Bo Zhao}}
\\
% %  \textbf{Fifth Author\textsuperscript{1,2}},
% %  \textbf{Sixth Author\textsuperscript{1}},
% %  \textbf{Seventh Author\textsuperscript{1}},
% %  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
% % \\
% %  \textbf{Ninth Author\textsuperscript{1}},
% %  \textbf{Tenth Author\textsuperscript{1}},
% %  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
% %  \textbf{Twelfth Author\textsuperscript{1}},
% % \\
% %  \textbf{Thirteenth Author\textsuperscript{3}},
% %  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
% %  \textbf{Fifteenth Author\textsuperscript{1}},
% %  \textbf{Sixteenth Author\textsuperscript{1}},
% % \\
% %  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
% %  \textbf{Eighteenth Author\textsuperscript{3,4}},
% %  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
% %  \textbf{Twentieth Author\textsuperscript{1}}
% % \\
% \\
 \textsuperscript{1}Shanghai Jiao Tong University, \;
 \textsuperscript{2}Universiti Malaya \\
 \textsuperscript{3}INSAIT, Sofia University "St. Kliment Ohridski"\\
 \small{{s2175463@siswa.um.edu.my}, {bo.zhao@sjtu.edu.cn}}
}

\begin{document}
\maketitle
\begin{abstract}
\fyq{Instruction tuning is crucial for optimizing Large Language Models (LLMs), yet mainstream data selection methods heavily rely on LLMs as instruction quality scorers, leading to high computational costs and reduced data diversity. To address these limitations, we propose \textbf{MergeIT}, a novel LLM-based \textbf{Merging} strategy for better \textbf{I}nstruction \textbf{T}uning that shifts the focus from selection to synthesis.
MergeIT operates in two stages: first, topic-aware filtering clusters and refines the dataset, preserving diversity while eliminating redundancy without relying on LLM-based scoring. Second, LLM-based merging synthesizes semantically similar instructions into more informative and compact training data, enhancing data richness while further reducing dataset size.
Experimental results demonstrate that MergeIT enables efficient, diverse, and scalable instruction selection and synthesis, establishing LLM-based merging as a promising alternative to conventional scoring-based selection methods for instruction tuning. Our source code and datasets are now available at \href{https://github.com/XcloudFance/MergeIT}{https://github.com/XcloudFance/MergeIT}}
\end{abstract}



\section{Introduction}
\fyq{Instruction tuning has emerged as a key technique for enhancing the adaptability and performance of Large Language Models (LLMs) \cite{dubey2024llama, jiang2023mistral}. By fine-tuning LLMs on carefully curated instruction datasets, e.g. \texttt{Alpaca\_52k} \cite{alpaca}, a dataset of 52,000 instructions and demonstrations generated by \texttt{text-davinci-003} \cite{gpt}., models can generalize across diverse tasks and prompts. However, selecting high-quality instruction data remains a critical challenge, as the choice of data directly affects fine-tuning outcomes.
}

\fyq{Existing selection methods \cite{chen2023alpagasus} primarily rely on LLMs as instruction quality \textbf{scorers}, ranking and filtering instructions based on predefined metrics \cite{deita,li2024superfiltering}. While this approach retains high-quality instructions, it introduces two major limitations. First, LLM-based scoring is computationally expensive, making large-scale selection infeasible. Second, scoring-based methods often prioritize high-ranked instructions at the expense of diversity, leading to redundant datasets that lack broader generalization. These trade-offs limit the scalability and effectiveness of instruction tuning.
}


\begin{figure}[t]
  \includegraphics[width=1.0\linewidth]{teaser.pdf} \hfill
  \caption{
  %Illustrated is the comparison between our method, Merging for Better Instruction Tuning (MergeIT) and other common baselines.
  Comparison between our method and prior works. 
  %We build a faster and stronger data selection method that considers both quality and diversity.
  \fyq{Unlike prior works that primarily use LLMs as scorers, we novelly explore their role as mergers, enhancing diversity and time efficiency.}
  }
  \vspace{-5mm}
      \label{fig:intro}
\end{figure}

\fyq{To overcome these challenges, we introduce \textbf{MergeIT}, \textit{a novel LLM-based merging strategy for better instruction tuning that moves beyond selection and leverages LLMs as \textbf{synthesizers} rather than mere \textbf{scorers}.} As illustrated in Fig.~\ref{fig:intro}, instead of scoring every single instruction, MergeIT merges semantically related instructions to create more informative, compact, and diverse samples. Comapred to the prior selection-based approaches, MergeIT improves dataset diversity while reducing time cost.
}

\fyq{Particularly, Our approach consists of two core stages: 1) Topic-aware Instruction Filtering – Instead of relying on LLM-based scoring, we first cluster the dataset into semantically meaningful topics and remove redundant instructions within each topic, ensuring diversity while preserving informativeness. 2) LLM-based Instruction Merging – Rather than eliminating similar instructions, we use LLMs to synthesize richer instructions by merging them into a more expressive and information-dense version. This step enhances dataset quality while reducing its size, making fine-tuning both more efficient and effective. 
By integrating topic-aware filtering with LLM-based merging, MergeIT achieves a faster, stronger, and more diverse instruction selection process, improving both the quality and efficiency of instruction tuning.}

\fyq{Extensive experiments are conducted to validate the effectiveness of MergeIT. Our method achieves state-of-the-art (SOTA) performance across six datasets, demonstrating significant improvements over existing approaches. Notably, our results highlight the feasibility and advantages of leveraging LLMs for instruction merging, a novel direction beyond traditional scoring-based selection. Our main contributions can be summarized as follows,}

\fyq{
\begin{itemize}
    \item 
    We propose \textbf{MergeIT}, a novel instruction data optimization framework that shifts from \textit{selection to synthesis}, integrating topic-aware filtering and LLM-based merging to enhance instruction tuning.
    \item 
   For the first time, we explore the use of LLMs to generate new instructions by merging two similar ones, offering novel insights for the instruction selection and generation.
    \item 
   Extensive experiments demonstrate the efficacy of our method, achieving high-quality, diverse instruction selection with reduced computational cost.
\end{itemize}
}


%---

%p1: Instruction tuning and data selection
% \fyq{Instruction Tuning,  a standardized post-training process for Large Language Models (LLMs), is a crucial step in enhancing models' ability to handle diverse conversational and domain-specific tasks. Different from relying on large-scale instruction data, one prior work LIMA~\cite{} reveals that models could be fine-tuned well with much less carefully curated examples, making the data selection for LLM instruction an arising research direction. }


%p2: related works
% \fyq{According to the criteria used for data selection, existing works can be broadly categorized into two types: internal information-based and external information-based approaches. Internal information-based methods filter samples based on their intrinsic relationships, such as similarities among data points. Since these methods analyze and compare data across the entire dataset, they naturally excel at selecting diverse instructions. However, they may lack a deep semantic understanding of individual instructions. In contrast, external information-based approaches leverage additional sources, such as other large language models (LLMs) like ChatGPT~\cite{} and LLaMA~\cite{}, to score and rank instruction quality. These methods prioritize retaining high-quality instructions while filtering out lower-quality ones. Subsets selected by these external information-based approaches usually have good quantity while may come at the cost of reduced diversity and high computation time.}




%p3: motivation of our method
% \fyq{Thus, we are motivated to build an efficient data selection approach that could generate both diverse and high-quantity instructions for tuning LLMs via addressing two key questions: a) Can we \textit{integrate both internal and external information} to leverage their respective advantages? b) Are there \textit{more effective ways to utilize LLMs} beyond simply using them as scorers?}



%p4: our method
% \fyq{To this end, we propose a novel data selection method, termed \textbf{M}erging for \textbf{B}etter \textbf{I}nstruction \textbf{T}uning (\textbf{MergeIT}), in this paper. Our method is designed in two stages: The first stage clusters the original corpus into various topics and filters samples within each topic. By adhering to the internal-informal paradigm, our topic-aware filtering produces a structured, less redundant, and more diverse subset. In the second stage, we introduce an innovative step of using additional LLMs to merge two instructions into a new one. This step leverages the high semantic understanding ability of LLMs, ensuring that the final generated data maintains both high quality and a further reduced number of subsets. As illustrated briefly in Fig.~\ref{fig:intro}, compared to prior methods that focus either on quality or diversity, our MergeIT method considers both factors during data selection.}





%p5: exp, most highlight part
% \fyq{Extensive experiments are conducted to validate the effectiveness of our method. New state-of-the-art (SOTA) performance are established across \todo{six} different benchmarks, with significant improvements over previous competitors. Notably, we highlight the feasibility and advantages of using LLMs to merge instructions. Ablation studies further confirm the benefit of combining both internal and external information for enhanced data selection.}

% ---
% p1: importance of instruction tuning (IT)
%\fyq{Instruction Tuning (IT), a standardized post-training process for Large Language Models (LLMs), is a crucial step to enhance models' ability to handle diverse conversational and domain-specific tasks. By fine-tuning models on high-quality instruction-response pairs, IT improves their adaptability and generalization across various natural language processing (NLP) applications, enabling more accurate and context-aware responses. Traditionally, making such high-quality instruction-response data requires human efforts traditionally which is inherently costly and time-consuming, limiting its practice. }

%p2: introduce Alpaca\_52k dataset 
%\fyq{To broaden the deployment of IT, recent studies have explored the automatic generation of instruction data by leveraging powerful LLMs. One of the most notable works in this area is Alpaca~\cite{}, which utilizes \texttt{text-davinci-003} to generate self-instruction data, resulting in 52K instruction-following samples, collectively known as \texttt{Alpaca\_52k}.} 

%p3: limitations of data and importance of selection
%\fyq{However, despite its advantages, the quality of LLM automated instruction data is not guaranteed, it may contain redundant and low-quality samples, reducing instruction tuning efficiency. The t-SNE visualization shown in Fig.1 also reveals the data quality of \texttt{Alpaca\_52k} fluctuates significantly.  This naturally highlighted the importance of more \textbf{efficient and intelligent instruction selection mechanisms} to ensure high-quality IT data.}
%An ideal approach should balance quality and diversity, reducing redundancy while preserving information density to maximize training efficiency.

%\fyq{Recent studies also validate that data quality outweighs quantity for LLM instruction tuning. For example, LIMA~\cite{} reveals that carefully curated high-complexity training contexts can lead to superior model performance with much less data e.g., 1000. Other existing research on instruction data selection data could be briefly grouped into two types:}

%Instruction-tuning (IT), a standardized post-training process for Large Language Models (LLMs), is typically trained using expert knowledge to further improve conversational ability and specialized question-answering. Earlier studies introduced a teacher LLM with larger parameter scales, as involving human experts requires significant time and resources. A similar approach can be found in the \texttt{Alpaca\_52k} dataset, which generates self-instruction data from \texttt{text-davinci-003}.

%However, assistance with LLMs leads to inconsistent data quality, coupled with redundancy in the set of data, increasing the unnecessary fine-tuning costs. 
%To quantize the quality distribution of IT data, \texttt{DEITA} highlights the importance of complexity and quality and thus introduce two scoring models, to define the characteristics of “good data” for instruction tuning, distilled the ability from teacher LLMs like ChatGPT. 
%Fig. 1 illustrates the fluctuation of \texttt{Alpaca\_52k}. 

%p4: related work
%Recent studies have also reached the consensus that data quality outweighs quantity in LLM training. \texttt{LIMA} demonstrates that carefully curated high-complexity training contexts can lead to superior model performance \fyq{with much less data}. Following this insight, two predominant approaches have emerged in the \fyq{instrcution data selection} field: 
%(1) score-based methods leveraging Large Language Models (LLMs) for data selection and (2) rule-driven approaches utilizing deterministic filtering mechanisms. 
%\fyq{1) Rule-based filtering methods; 2) LLM score-based filtering methods.}Both streams aim to curate high-quality training subsets while maintaining model performance. 

% p5: limitations of related work
%\fyq{Typically, rule-based methods xxx, LLM score-based methods xxx.}



%In our work, we aim to bridge the gap between \textbf{quality} and \textbf{diversity}, ensuring both efficiency and effectiveness in the refined subset. In \texttt{Alpaca\_52k}, several challenges remain, as highlighted by the majority of studies: (1) rule-based methods are more effective at identifying diverse and representative data, but often lack the ability to ensure high quality; (2) the score-based process, while capable of selecting high-quality data, is often time-consuming and costly due to the computational demands of LLM, and its efficiency decreases as the size of the original data pool increases. Moreover, a simple selection approach is severely limited by the quality of the original dataset, resulting in subsets that are less effective for training language models.



%To that end, a novel data filtering method termed as  is proposed in this paper. Specifically,to take full advantage of both internal and external information, we initially integrate clustering for the original corpus and fuses similar data points based on semantic and structural features, producing a smaller, less redundant, and information-dense subset. We find out that \texttt{Alpaca\_52k} is naturally categorized in some specific topics and thus suitable for clustering. This strategy allows us to extract related contexts together, so that we can introduce other LLMs with larger parameters to merge most relatable pairs or sets, considering the imbalance of quality distribution. 



%We conduct extensive experiments to validate the efficacy of our filtering paradigm, by utilizing only 10\% of the original volume. Our main contributions can be summarized as follows.

% \begin{itemize}
%     \item We seek to cluster the instruction tuning data in terms of clusters to select best representative subsets, which brings the speedups of whole pipeline.
%     \item We further intuitively merge the contexts by larger LLMs within the smaller subsets, taking full advantage of semantics between each pairs within the subsets.
%     \item Extensive experiments are conducted to validate the efficacy of our data filtering method, outperforming other baseline methods in multiple benchmarks.
% \end{itemize}

%p6: contri
% \fyq{Our main contributions can be summarized as,
% \begin{itemize}
%     \item 
%     A new data selection approach, MergeIT, is proposed, leveraging both internal and external information in a two-stage process for improved instruction tuning.
%     \item 
%    For the first time, we explore the use of LLMs to generate new instructions by merging two similar ones, offering novel insights into the instruction selection and generation community.
%     \item 
%    Extensive experiments demonstrate the efficacy of our method, achieving high-quality, diverse instruction selection with reduced computational cost.
% \end{itemize}}






% \section{Problem Setting}   
% Given an initial instruction dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$, where $x_i$ represents the input instruction and $y_i$ denotes the corresponding output, our goal is to select a high-quality subset $\mathcal{D}' \subseteq \mathcal{D}$ for instruction tuning, such that $|\mathcal{D}'| \leq K$ where $K$ is the desired subset size.

\section{Methodology}
% \section{Problem Setting}   
\noindent\textbf{Problem Setup:} Given an initial instruction dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$ from \texttt{Alpaca\_52k}, where $x_i$ represents the input instruction and $y_i$ denotes the corresponding output, our goal is to select a high-quality subset $\mathcal{D}' \subseteq \mathcal{D}$ for instruction tuning, 
%such that $|\mathcal{D}'| \leq K$ where $K$ is the desired subset size.
\fyq{such that $|\mathcal{D}'| \ll |\mathcal{D}|$.}


\subsection{Overview}\label{sec:overview}
\fyq{To ensure both diversity and quality in the selected subset while maintaining an efficient selection process, we propose \textbf{MergeIT} (\textbf{LLM-based Merging Strategy for Better Instruction Tuning}). The overview of our MergeIT method is illustrated in Fig.~\ref{fig:pipeline}. Our approach consists of two main steps: 1) Topic-aware Filtering; 2) LLM-based Merging.}


\fyq{Given an initial dataset $\mathcal{D}$, the first step filters out redundant examples by selecting only the most informative ones within each topic. This topic-aware strategy naturally ensures that the remaining samples $\mathcal{D}'$ are semantically diverse. Furthermore, by avoiding the use of large LLMs in this stage, we achieve an efficient filtering process. To further compress the data, the second step leverages LLMs to merge similar instances. By harnessing the strong comprehension and generation capabilities of LLMs, we synthesize high-quality and information-rich merged instructions. As a result, the size of $\mathcal{D}'$ is approximately halved, forming the final subset $\hat{\mathcal{D}}$. Unlike prior methods that utilize LLMs solely as scorers , we are the first to explore their potential in a merging framework.}




\subsection{Topic-aware Filtering}
\fyq{As stated in Sec.\ref{sec:overview}, our first step aims to remove redundant examples while preserving the diverse structural semantics of the initial dataset $\mathcal{D}$. To achieve this, our topic-aware filtering first clusters the instructions into specific topics (detailed in Sec.\ref{K-means}) and then selects the most representative subset from each topic, as described in Sec.~\ref{facility}.}

% To maintain the diversity of \texttt{Alpaca\_52k}, we delve into the \textit{de facto} instruction pairs and categorize them into specific topics in the manner of aligning with different instructional tasks, with the details in \ref{K-means}. Further, \ref{facility} discusses a number of subsets within each topic are selected to extract most representative data.


%In this section, we explore into curating a new subset of data in the manner of introducing both LLM-based idea and topic-aware settings to diversity in Section \ref{diversity} and quality in Section \ref{MergeIT}. 
% \subsection{Preliminaries}
% \label{diversity}

% To maintain the diversity of \texttt{Alpaca\_52k}, we delve into the \textit{de facto} instruction pairs and categorize them into specific topics in the manner of aligning with different instructional tasks, with the details in \ref{K-means}. Further, \ref{facility} discusses a number of subsets within each topic are selected to extract most representative data.



\subsubsection{K-means Clustering}
\label{K-means}
 We construct the initial clusters of data by introducing K-means algorithm to group pairs according to their instructions. All sentences are represented in embeddings space calculated from \texttt{all-MiniLM-L6-v2}, mapping into 384 dimensional features to calculate distances between samples. Given the instruction dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$, we first represent each instruction-output pair as a feature vector $f(x,y) \in \mathbb{R}^d$. To partition $\mathcal{D}$ into $m$ topically coherent clusters, we optimize:

\begin{align}
   \min_{\{\mathcal{D}_j\}_{j=1}^m} &\sum_{j=1}^m \sum_{(x,y) \in \mathcal{D}_j} \|f(x,y) - \mu_j\|_2^2 \nonumber \\
   \text{s.t.} \quad &\bigcup_{j=1}^m \mathcal{D}_j = \mathcal{D} \nonumber \\
   &\mathcal{D}_i \cap \mathcal{D}_j = \emptyset, \quad \forall i \neq j
\end{align}

where $\mu_j = \frac{1}{|\mathcal{D}_j|}\sum_{(x,y) \in \mathcal{D}_j} f(x,y)$ is the centroid of topic $t_j$.

\begin{equation}
   t(x,y) = \argmin_{j} \|f(x,y) - \mu_j\|_2^2
\end{equation}

This provides the topic partitioning $\mathcal{T} = \{t_1, t_2, ..., t_m\}$ that maximizes intra-topic semantic coherence while ensuring clear boundaries between different instruction categories. To validate the feasibility of topic-based partitioning, we visualize the instruction embeddings using t-SNE \cite{vanDerMaaten2008} dimensionality reduction in Fig. \ref{fig:K-means}. 




\subsubsection{Facility Location Function}
\label{facility}
To control the number of samples, we leverage facility location function as submodular function to select top $K$ representative data in each topic. For each topic cluster $\mathcal{D}_j$, the facility location function is defined as:

\begin{equation}
   F(\mathcal{D}'_j) = \sum_{(x,y) \in \mathcal{D}_j} \max_{(x',y') \in \mathcal{D}'_j} \text{sim}(f(x,y), f(x',y'))
\end{equation}

where $\mathcal{D}'_j \subseteq \mathcal{D}_j$ is the selected subset and $\text{sim}(\cdot, \cdot)$ measures the similarity between two instruction-output pairs in the feature space. This formulation aims to maximize:

\begin{align}
   \max_{\mathcal{D}'_j \subseteq \mathcal{D}_j} &\quad F(\mathcal{D}'_j) \nonumber \\
   \text{s.t.} &\quad |\mathcal{D}'_j| \leq K \nonumber \\
   &\quad Q(x,y) \geq q_j, \quad \forall (x,y) \in \mathcal{D}'_j
\end{align}

The facility location objective ensures each instruction in $\mathcal{D}_j$ is well-related their topics and remains representativeness in the selected subset $\mathcal{D}'_j$.


\begin{figure}[t]
  \includegraphics[width=.95\linewidth]{cluster2.png} \hfill
  \caption {
  %Illustrated is the t-SNE visualization of K-means algorithm applied in \texttt{Alpaca\_52k}. It is worth noting that the original dataset instructions naturally form distinguishable clusters, suggesting that our dataset exhibits inherent topical structure that can be effectively captured through clustering.
  t-SNE visualization of K-means on \fyq{\texttt{Alpaca\_52k}. The instructions naturally form distinct clusters, indicating an inherent topical structure effectively captured by clustering.}
  }
    \vspace{-2mm}
      \label{fig:K-means}
\end{figure}



\begin{figure*}[t]
  \includegraphics[width=1.0\linewidth]{pipeline.pdf} \hfill
  \caption {
  %The illustration of MergeIT. We first tap into encoding sentences in instruction pairs with mean pooling to curb potential length biases. Afterwards, embeddings are projected into lower dimension and applied K-means clustering as well as facility location function to decrease the corpus to 20\%\textasciitilde 30\%. Subsequently, we calculate each sample pair-wise similarity in each cluster. Lastly, we pair all samples and merge them to further decrease 50\% of data according to their similarity. Open-source LLMs are fine-tuned in LoRA or full parameters in the merged subsets. 
  \fyq{Overview of MergeIT: 1) Topic-aware filtering clusters instructions into topics and filters redundant samples within each topic. 2) LLM-based merging synthesizes new instructions by combining similar pairs.}
  }
    \label{fig:pipeline}
\end{figure*}
% \subsection{LLM-based Merging strategy for better Instruction  Tuning}
\subsection{LLM-based Merging}
\label{MergeIT}
Following topic-based alignment and initial subset extraction $\mathcal{D}'_j$, the data volume reduces to approximately 20\% of the original corpus, effectively mitigating computational overhead for subsequent LLM processing. However, the resulting subset may still be less effective for LLM fine-tuning due to potential verbosity in remaining samples and quality inconsistencies arising from selection based solely on topical alignment without considering semantic relationships or response quality. 
%To address this, we propose \textbf{LLM-based Merging strategy for better Instruction  Tuning (MergeIT)} – 
\fyq{To address this, we for the first time propose the LLM-based merging,} a cluster-aware methodology that strategically combines semantically related instruction pairs from each topic $\{t_j\}_{j=1}^m$ through third-party LLMs. 
%\fyq{To address this, we propose LLM-based merging, which strategically combines semantically related instruction pairs from each topic $\{t_j\}_{j=1}^m$ through third-party LLMs.}

%We illustrate the overview of sample merging pipeline in Fig. \ref{fig:pipeline}.

\fyq{As illustrated in Fig. \ref{fig:pipeline},}
starting with the %\todo{inital subset} 
$\mathcal{D}'_j$ \fyq{from the first filtering stage}, for each topic cluster $t_j$, we establish semantic equivalence classes through:

\begin{align}
  \mathcal{P}_j = \{&((x_i, y_i), (x_k, y_k)) \mid \nonumber \\
  &\text{sim}(f(x_i), f(x_k)) \geq \tau, \nonumber \\
  &(x_i, y_i), (x_k, y_k) \in \mathcal{D}'_j\}
\end{align}

where $\mathcal{P}_j$ denotes the set of instruction pairs in topic $t_j$ that exceed the similarity threshold $\tau$, $f(\cdot)$ denotes instruction embedding projection and $\text{sim}(\cdot,\cdot)$ computes cosine similarity. The merging operator $M:\mathcal{D}'_j \times \mathcal{D}'_j \rightarrow \hat{\mathcal{D}}$ employs an LLM-based synthesizer:

\begin{align}
   &M((x_i, y_i), (x_k, y_k)) = \text{LLM}_{\text{merge}}(\mathbf{c}_{ik}) = (\hat{x}, \hat{y})
\end{align}

where $\mathbf{c}_{ik} = [x_i; y_i; x_k; y_k]$ denotes the concatenated instruction-output context.




The final training protocol comprises:

\begin{align}
   \hat{\mathcal{D}} &= \bigcup_{j=1}^m \{M(p) \mid p \in \mathcal{P}_j\} \\
   \mathcal{L}(\theta) &= \mathbb{E}_{(\hat{x}, \hat{y}) \sim \hat{\mathcal{D}}} [-\log p_{\theta}(\hat{y}|\hat{x})]
\end{align}

where $\hat{\mathcal{D}}$ represents the merged instruction set from all topics and $\mathcal{L}(\theta)$ defines the fine-tuning objective for model parameters $\theta$.

\textbf{Quality Checking.} To prevent possible degradation during the merging process, we propose a quality preservation constraint:

\begin{equation}
    \pi'_{quality}(M_{i,j}) > \alpha(\pi_{quality}(S_i) + \pi_{quality}(S_j))
\end{equation}

\noindent where $M_{i,j}$ represents the merged result of samples $S_i$ and $S_j$, $\pi'_{quality}$ denotes the quality score after merging, $\pi_{quality}$ represents the quality score before merging, and $\alpha \in (0,1)$ is a parameter controlling the quality threshold, which we set by default at 0.75. This efficient quality checking mechanism ensures that merging operations only proceed when the resultant quality surpasses the weighted quality of the original samples. Our empirical evaluation demonstrates that this quality assessment process incurs negligible time consuming (0.5-1.0 seconds per sample pair), making it particularly suitable for integration into the main merging pipeline without introducing significant processing delays.


This cluster-constrained merging owns two computational advantages. First, it eliminates the $O(n^2)$ pairwise similarity bottleneck by restricting comparisons within pre-clustered topics ($|\mathcal{D}'_j| \ll |\mathcal{D}|$). The localized processing enables: (1) efficient identification of task-specific instruction patterns through intra-cluster analysis, and (2) context-aware merging of logically compatible samples – for instance, consolidating parallelizable tasks into batched instructions or combining complementary reasoning steps into coherent workflows. Second, the synthesis process inherently compresses lexical redundancies through LLM-based paraphrasing, simultaneously enhancing dataset density and instruction quality – a critical improvement over naive concatenation approaches. Additional examples and analysis are provided in Sec. \ref{sec4}.


\input{merging_example}






% \begin{figure}[t]
%   \includegraphics[width=\columnwidth]{example-image-golden}
%   \caption{A figure with a caption that runs for more than one line.
%     Example image is usually available through the \texttt{mwe} package
%     without even mentioning it in the preamble.}
%   \label{fig:experiments}
% \end{figure}



\section{Does Merging Really Make the Data Better for Training?}
\label{sec4}
In this section, we further delve into the real examples of merging in \texttt{Alpaca\_52k}, to demonstrate the post-processed outcomes, as well as providing analysis to its practical feasibility.
As mentioned before, we introduce \texttt{Deita} scorer \cite{deita} as the measurement of quality of training data from the instruction and its response. To clearly reveal the examples of language tasks, we 
%\todo{cherry-picked} 
picked three instruction groups (e.g., Translation, Language Analysis, and Calculation), shown in Tab.~\ref{tab:merge-comparison}. 


%To our concerns, we aim to seek the effectiveness of %\todo{data merge} instruction merging in three-fold questions: 
\fyq{To further validate our approach of instruction merging, we explore three key questions:}
1) Does instruction merge improve the overall quality? 2) How does %\todo{task merge} 
the merged data
impact the explanation depth of responses? 3) Does %\todo{task merge} 
LLM
effectively integrate knowledge from different components?

\textbf{Quality Enhancement.} Our empirical analysis reveals a consistent pattern of quality improvement across all examined task groups. As shown in Tab.~\ref{tab:merge-comparison}, the quality scores of merged instructions consistently surpass 
%their pre-merge counterparts. 
\fyq{the initial ones.}
Specifically, in the \textit{Translation Task Group}, we observe an increase from an average score of 1.90 to 2.57, representing a 35.2\% improvement. Similar enhancements are evident in \textit{Language Analysis} (141.7\% increase) and \textit{Calculation} (15.8\% increase) tasks. These substantial improvements in quality scores suggest that our merge strategy effectively combines individual instructions while maintaining coherence.

\textbf{Response Depth.} A notable outcome of our merging process is the improvement in response depth and completeness. Post-merge responses demonstrate a marked increase in explanatory content and reasoning clarity. 

For instance, in \textit{Language Analysis Task Group}, since pre-merge instructions are logically coherent with each other, like "categorize part of speech" and "identify sentence structure" all related to the analytical of sentences, LLMs not only connect instructions by simply adding "and" in between, but also emerge to provide more comprehensive outputs. In addition, the Task 1 in the Group is promoted to perform analysis for the whole sentences, rather than merely focusing on a single word, which provides more insights to increment the quality from its original plain requests.

\textbf{Knowledge Integration.} Our analysis further demonstrates the effectiveness of knowledge integration across different task components. The merge process successfully preserves the essential elements of individual tasks while creating cohesive instructions. This is particularly evident in the \textit{Calculation Task Group}, where the merged instruction seamlessly combines number property analysis (odd/even) with prime number verification. The resulting quality score of 3.08 and comprehensive response ("The number 48 is even. It is not a prime number because it has divisors other than 1 and itself") validates that this integration not only maintains but enhances the overall task effectiveness.



\section{Experiments}

In this section, we evaluate two open-source and commonly used models: \texttt{Mistral-7b-v0.3} \cite{jiang2023mistral} and \texttt{LLaMA3-8b} \cite{dubey2024llama} with two types of benchmarks: LLM-based (MT-Bench \cite{mtbench}, AlpacaEval \cite{instructeval}), and Huggingface Open LLM Leaderboard (Hellaswag \cite{hellaswag}, MMLU \cite{mmlu}, GSM8k \cite{gsm8k}, ARC \cite{arc}, and TruthfulQA \cite{truthfulqa}). 
%We provide several baseline methods: Alpaca-52k (full dataset), Superfiltering \cite{li2024superfiltering}, Random, Perplexity, K-means, LIMA to compare their performance.
\fyq{Several baseline methods, including Alpaca-52k (full dataset), Superfiltering \cite{li2024superfiltering}, Random selection, Perplexity, K-means, and LIMA, are included for comparison.}

\begin{table*}[t]
    \centering
    \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{l|c|cccccc}
        \hline
        {Model} & MT-Bench & \multicolumn{5}{c}{Huggingface Open LLM Leaderboard (Acc.) $\uparrow$}   \\
        & Score & Hellaswag & MMLU & GSM8k & ARC & TruthfulQA & Average \\
        \hline
        Mistral-7b-v0.3 & 3.639 & 60.94 & 58.96 & 36.62 & 48.81 & 22.44 & 45.55 \\
        \hline
        Alpaca-52k & 4.018 & 61.18 & 57.73 & 31.61 & 53.07 & 28.76 & 46.47 \\
        SuperFiltering-10\% & 3.963 & 60.98 & 59.34 & 35.71 & 49.83 & 29.99 & 47.17 \\
        Random-6k & 4.314 & 60.83 & 58.75 & 35.03 & 53.07 & 32.19 & 47.97 \\
        Perplexity-6k & 4.352 & \textbf{61.64} & 58.48 & \underline{37.00} & 51.88 & 31.21 & \underline{48.04} \\
        K-means-6k & 4.283 & 60.86 & 58.45 & 35.10 & 52.05 & 32.46 & 47.78 \\
        LIMA-6k & \underline{4.440} & 60.58 & \textbf{59.34} & 34.34 & \underline{53.33} & 31.82 & 47.88 \\
        \hline
        \rowcolor{gray!30} \textbf{MergeIT-6k (Ours)} & \textbf{4.481} & \underline{61.40} & \underline{59.01} & \textbf{37.30} & \textbf{54.95} & \textbf{33.41} & \textbf{49.21} \\
        \hline
        LLaMA3-8b & 3.418 & 60.17 & \textbf{62.13} & \underline{50.42} & 50.26 & 26.93 & 49.98 \\
        \hline  
        Alpaca-52k & 3.718 & 60.57 & 61.36 & 46.10 & \underline{53.41} & 30.72 & 50.43 \\
        SuperFiltering-10\% & 3.968 & 60.38 & \textbf{61.95} & 50.34 & 51.54 & 29.87 & 50.82 \\
        Random-6k & 3.912 & 60.83 & 58.75 & 35.03 & 53.07 & 32.44 & 48.02 \\
        Perplexity-6k & 4.120 & \underline{61.14} & 61.09 & 50.87 & 53.50 & 31.33 & \underline{51.58} \\
        K-means-6k & 3.731 & 60.86 & 58.45 & 35.10 & 53.07 & 32.31 & 47.96 \\
        LIMA-6k & \underline{4.450} & 60.58 & 61.28 & 50.34 & 51.11 & \underline{34.27} & 51.51 \\
       \rowcolor{gray!30}\textbf{MergeIT-6k (Ours)} & \textbf{4.525} & \textbf{61.96} & \underline{61.49} & \textbf{51.87} & \textbf{54.95} & \textbf{34.52} & \textbf{52.96} \\
        \hline
    \end{tabular}
    \caption{Performance comparison on standard benchmarks (Experiment A). The best results are highlighted in \textbf{bold}, and the second-best results are \underline{underlined}.}
    \label{experiment}
\end{table*}






\subsection{Experimental Setup}
We adopt LLaMA-Factory\footnote{https://github.com/hiyouga/LLaMA-Factory}  as our training base. All fine-tuning experiments utilize LoRA \cite{hu2021lora} with the learning rate $2 \times 10^{-5}$, 3 epochs, a batch size of 4, and Cosine scheduler with warmup ratio 0.5. Additionally, we apply 4 pieces of Huawei Ascend 910b 64GB, to train the models. To evaluate Open LLM Leaderboard, we use lm-evaluation-harness\footnote{https://github.com/EleutherAI/lm-evaluation-harness} as it integrates all of the required benchmarks.

\textbf{Baselines Setup.} For selected baseline models, we extensively experimented with some traditional data selection paradigms. Specifically, K-means baseline clustered the data into 120 groups and selected the most distant samples from each centroid of clusters to realize diversity manner. Perplexity-based method calculates the perplexity score from LLaMa3-8b, formulated below: %\todo{some baselines are missing?}
\begin{equation}
    PP(W) = 2^{-\frac{1}{N}\sum_{i=1}^{N}\log_2P(w_i|w_1,...,w_{i-1})} ,
\end{equation}
where $PP(W)$ represents the perplexity score for sequence $W$, $N$ is the sequence length, and $P(w_i|w_1,...,w_{i-1})$ denotes the conditional probability of predicting the current word $w_i$ given all previous words. For SuperFiltering, we reuse their 10\% filtered data from their Instruction-Following Difficulty score.

\subsection{Data Scaling}
To validate the most applicable number of instruction tuning samples, we implement experiments on testing different data scaling. We include approximately 1k, 6k and 8k of merged data as training subsets and also evaluate on  MT-Bench, Hellaswag, ARC and TruthfulQA, as illustrated in Fig. \ref{fig:scaling}. In the given graph, we finalize our corpus size into 6k since it reveals the best trade-off between performance and efficiency, while 9k however demonstrates reverse effects even if the data scales up and 1k data is likely causing the lack of robustness and understanding. 

\subsection{Main Results}
\textbf{LLM as a Judge.}
As shown in Table \ref{experiment}, MergeIT-6k achieves the highest performance in LLM scoring, reaching 4.481 and outperforming other baselines by up to 0.518 on Mistral-7b-v0.3 (a 0.842 improvement from base model), while achieving 4.525 on LLaMA3-8b (a 1.107 improvement from base model), surpassing other methods by up to 0.807. Further evaluation on AlpacaEval \cite{alpaca_eval} in Fig. \ref{fig:alpacaeval} using GPT-4 shows MergeIT-6k winning in 485 out of 800 comparisons against SuperFiltering-6k's 355 wins, confirming its effectiveness across different judges. 


\textbf{Huggingface Open LLM Leaderboard.} Our MergeIT achieves state-of-the-art performance (49.21\% average score) across all five tasks, outperforming strong baselines LIMA-6k (47.88\%) and K-means-6k (47.78\%). The improvements are particularly notable on ARC (54.95\%) and TruthfulQA (33.41\%). When trained on LLaMA-generated data, MergeIT further  %improves to 
obtains 52.96\% average score, with significant gains on GSM8k (51.87\%) and ARC (54.95\%), demonstrating its effectiveness across diverse tasks.


\begin{table*}[htbp]
    \centering
    \scalebox{0.9}{  % 添加缩放命令
    \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{ccc|c|c|ccccc}
        \hline
         Merging & K-means & Quality & \# Samples & MT-Bench & Hellaswag & MMLU & GSM8k & ARC &  \\
        & & Checking & & Score & (Acc.) & (Acc.) & (Acc.) & (Acc.) & $\mu_{avg}$ \\
        \hline
          \checkmark & \checkmark & \checkmark & 6000  & 4.481 & 61.40 & 59.01 & 37.30 & 53.33 & 52.76 \\
        \hline
          & \checkmark & \checkmark & 12000 & 4.300 & 60.31 & 59.06 & 34.42 & 51.37 & 51.29 \\
         \checkmark & & \checkmark & 6000 & 4.112 & 59.68 & 58.75 & 30.29 & 50.01 & 49.68 \\
         \checkmark & \checkmark & & 6000 & 4.081 & 59.81 & 58.76 & 33.16 & 49.56 & 50.32 \\
        \hline
    \end{tabular}
    }  % 闭合缩放命令

    \caption{Ablation studies on different components of our method.}
    \label{tab:ablation}

\end{table*}

\begin{table*}[htbp]
    \centering
    \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{l|c|ccccc}
        \hline
         Merging Methods & MT-Bench & Hellaswag & MMLU & GSM8k & ARC &  \\
        & Score & (Acc.) & (Acc.) & (Acc.) & (Acc.) & $\mu_{avg}$ \\
        \hline
         MergeIT Merging - Mistral-7b & 4.481 & 61.40 & 59.01 & 37.30 & 53.33 & 52.76 \\
         \hline
        Random Select within Topics & 4.198 & 59.98 & 59.05 & 35.25 & 50.68 & 51.24 \\
        \hline
         Concat Merging & 4.200 & 60.16 & 58.76  & 36.47 & 50.85 & 51.56 \\
        \hline
    \end{tabular}
    \caption{Ablation studies on different merging methods.}
    \label{tab:ablation2}
\end{table*}


\subsection{Ablation Study}
To better understand the contribution of each component in our method, we conduct comprehensive ablation studies as shown in Tab.~\ref{tab:ablation} and Tab. \ref{tab:ablation2}. Our full model with all three components (6000 samples) achieves the best overall performance with an average accuracy of 52.76\% and MT-Bench score of 4.481.

\textbf{Merging Samples from Given Pairs.} We first investigate the impact of our merging strategy. When removing the merging component (12000 samples), the average accuracy drops by 0.84\% and MT-Bench score decreases to 4.300, suggesting that our merging strategy effectively enhances model performance by providing more diverse training samples.

\textbf{Diversity in Topics.} The K-means clustering plays a crucial role in maintaining diversity. Without K-means but keeping quality checking (second row), the model's performance drops significantly across all metrics, particularly on GSM8k (-7.01\%) and ARC (-3.32\%). This indicates that K-means clustering helps ensure a balanced representation of different topics in the training data.

\textbf{Quality Assurance.} 
%When removing the quality checking component (last row), we observe the largest performance degradation, with MT-Bench score dropping to 4.081 and average accuracy decreasing by 2.44\%. The decline is particularly notable in reasoning-heavy tasks like ARC (-3.77\%) and GSM8k (-4.14\%), demonstrating that quality checking is essential for maintaining high-quality training samples and ensuring robust model performance.
\fyq{Removing the quality-checking component (last row) results in the most significant performance drop, with the MT-Bench score decreasing to 4.081 and average accuracy declining by 2.44\%. The impact is particularly pronounced in reasoning-heavy tasks such as ARC (-3.77\%) and GSM8K (-4.14\%), highlighting the critical role of quality checking in maintaining high-quality training samples and ensuring robust model performance.}

\textbf{Different Merging Strategies.} 
%We further compare our MergeIT merging with two alternative strategies in Tab.~\ref{tab:ablation2}: random selection within topics and simple concatenation-based merging. Random selection maintains topic awareness but without merging, leading to a performance drop (51.24\% average accuracy). Simple concatenation using "and" as the connector performs slightly better (51.56\%) but still falls behind MergeIT merging (52.76\%), demonstrating that LLM-guided merging is essential for creating high-quality training samples.
\fyq{We further compare MergeIT's merging with two alternative strategies in Tab.~\ref{tab:ablation2}: random selection within topics and simple concatenation-based merging. While random selection preserves topic awareness, it lacks merging, resulting in a performance drop (51.24\% average accuracy). Simple concatenation using "and" as the connector performs slightly better (51.56\%) but still lags behind MergeIT's merging (52.76\%), validating our idea of using LLM-guided merging for generating high-quality samples.}

\begin{figure}[h!]
% \vspace{-3}
  \includegraphics[width=1.0\linewidth]{datascaling.pdf} \hfill
%\vspace{-5mm}
  \caption {The figure shows the comparison between different scales of number of data in instruction tuning. }
  \vspace{-5mm}
      \label{fig:scaling}
\end{figure}








\section{Related Work}

\subsection{Instruction Data Selection}
With the rapid development of large language models in recent years and the thorough exploration of large-scale training data, research has shifted from model-centric to data-centric approaches. For instance, \citealp{zhou2024lima} has demonstrated that efficient alignment can be performed on small-scale high-quality data. Currently, the training data of most large language models (\citealp{dubey2024llama}) must be filtered in advance to ensure high quality, thereby improving both training effectiveness and efficiency. Regarding the critical task of selecting instruction fine-tuning data, in addition to traditional methods such as coreset selection (\citealp{zhang2024tagcos}) and clustering (\citealp{he2024efficient}), recent methods mainly propose new data quality indicators, struggling to balance data quality and diversity to achieve high-quality data selection.


\begin{figure}[h]
  \includegraphics[width=1.0\linewidth]{alpacaeval.pdf} \hfill
\vspace{-5mm}

  \caption {AlpacaEval results. Compared models are MergeIT-6k V.S Alapca-52k full samples (line 1), MergeIT-9k V.S Alapca-52k full samples (line 2) and Superfiltering-6k V.S Alapca-52k full samples (line 3)}
    \vspace{-3mm}
      \label{fig:alpacaeval}
\end{figure}

\subsection{Quality Filtering}
The quality of instruction fine-tuning data—such as clarity of instructions and normativity of expressions—directly influences the final performance of a model. Common quality filtering methods are indicator-based, meaning each sample is assigned an index score, and high-scoring samples are selectively retained. Typical indicators include perplexity (\citealp{ankner2024perplexed, mekala2024smaller}), instruction-following difficulty (\citealp{li2023quantity, li2024superfiltering, li2024selective}), LLM-based scoring (\citealp{deita, song2024iterselecttune}), manual evaluation (\citealp{liu2024coachlm}), influence values (\citealp{xia2024less, liu2024less, yu2024mates}), and submodular functions (\citealp{agarwal2024delift, renduchintala2024smart}). Although these methods can effectively filter out relatively high-quality samples, they do not improve any shortcomings in the remaining samples or rely solely on LLM-based priors for enhancement, limiting the ultimate quality of the data, thus constraining model improvement. However, by merging instructions, we can fully leverage information from all samples so that they complement each other, thereby maximizing data quality and surpassing the original dataset.

\subsection{Diversity-Related Works}
Diversity in instruction fine-tuning data—covering domains, formats, and sources—is equally vital. Over-filtering for quality risks omitting multiple task types or domain knowledge, reducing the model’s generalization ability. Existing methods for instruction data selection often overlook diversity (\citealp{shen2024rethinking}) or rely on traditional methods like K-means sampling (\citealp{li2023quantity, ge2024clustering, maharana2024adapt}) and K-center greedy (\citealp{deita, wang2024your}), which often yield suboptimal results. Other diversity-focused strategies remain heuristic, such as the n-gram-based bidirectional graph used in \citealp{wu2024best}. However, these methods typically discard certain samples outright, inevitably reducing overall data diversity. In contrast, our instruction merging method retains information from all samples, effectively preserving diversity while maintaining quality.



\section{Conclusion}
%In this paper, we introduce a framework with LLM-based strategy for efficient Instruction Tuning. With the techniques of topic-aware filtering and llm-based merging, we present our work MergeIT, which effectively filter and seek to combine instruction pairs to reduce the dataset size while increasing the informative richness. The evaluated results affirm the effectiveness of our merging strategy, outperforming all other baselines, while mitigating the computational overheads from large datasets. 
%\fyq{In this paper, we introduce MergeIT, a novel LLM-based framework for efficient instruction tuning. By integrating topic-aware filtering and LLM-based merging, MergeIT effectively filters and strategically combines instruction pairs, reducing dataset size while enhancing informational richness. Experimental results confirm the effectiveness of our merging strategy, achieving superior performance over all baselines.}
\fyq{In this paper, we introduce MergeIT, a novel framework for efficient instruction tuning. By integrating topic-aware filtering and LLM-based merging, MergeIT effectively filters and combines instruction pairs, reducing dataset size while enhancing informational richness. Notably, we pioneer the use of LLMs for instruction merging, leveraging their generative capabilities to synthesize more informative and compact training data. Experimental results confirm the effectiveness of our merging strategy, achieving superior performance over all baselines and demonstrating the potential of LLMs beyond traditional scoring-based selection.}

\section{Limitation}
Our work remains several challenge to be resolved: 1) Our work remains inevitable clustering process to maintain the diversity in the context, which is still served as a less stable method when it comes to larger datasets. 2) Merging process occasionally loses the information given from the samples, which potentially harms the information from the original corpus.
% \section*{Acknowledgments}

% This document has been adapted
% by Steven Bethard, Ryan Cotterell and Rui Yan
% from the instructions for earlier ACL and NAACL proceedings, including those for
% ACL 2019 by Douwe Kiela and Ivan Vuli\'{c},
% NAACL 2019 by Stephanie Lukin and Alla Roskovskaya,
    % ACL 2018 by Shay Cohen, Kevin Gimpel, and Wei Lu,
% NAACL 2018 by Margaret Mitchell and Stephanie Lukin,
% Bib\TeX{} suggestions for (NA)ACL 2017/2018 from Jason Eisner,
% ACL 2017 by Dan Gildea and Min-Yen Kan,
% NAACL 2017 by Margaret Mitchell,
% ACL 2012 by Maggie Li and Michael White,
% ACL 2010 by Jing-Shin Chang and Philipp Koehn,
% ACL 2008 by Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui,
% ACL 2005 by Hwee Tou Ng and Kemal Oflazer,
% ACL 2002 by Eugene Charniak and Dekang Lin,
% and earlier ACL and EACL formats written by several people, including
% John Chen, Henry S. Thompson and Donald Walker.
% Additional elements were taken from the formatting instructions of the \emph{International Joint Conference on Artificial Intelligence} and the \emph{Conference on Computer Vision and Pattern Recognition}.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\clearpage
\appendix

\section{Merging Examples}
We further cherry-pick some merging examples as well as corresponding pre-merge instructions to observe the effects brought by LLMs. More groups and scenarios are provided, shown in Tab. \ref{tab:merging2}


\section{Small-parameter Models for Merging}
\label{sec:appendix}

Even though MergeIT has saved the most budgets of invoking LLMs API vastly, it still incurs burdens from expensive API calling costs. To solve this challenge, we finetuned a small open-source model, Gemma2-9b from a small portion of data generated by GPT-4o examples. The evaluated results are shown in Tab. \ref{tab:mergingappend}. From the given table, Gemma2-9b holds same ability even if the size of model is rather smaller than GPT-4o, which proves the process is possible to be migrated to smaller LLMs.


\input{merging_example2}

\begin{table*}[htbp]
    \centering
    \renewcommand{\arraystretch}{1.1}
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{l|c|ccccc}
        \hline
         Merging Methods & MT-Bench & Hellaswag & MMLU & GSM8k & ARC &  \\
        & Score & (Acc.) & (Acc.) & (Acc.) & (Acc.) & $\mu_{avg}$ \\
        \hline
         GPT-4o merging & 4.481 & 61.40 & 59.01 & 37.30 & 53.33 & 52.76 \\
        \hline
         Gemma2-9b merging & 4.370 & 59.05 & 60.98  & 36.25 & 50.68 & 51.74 \\
        \hline
        Concat Merging & 4.200 & 60.16 & 58.76  & 36.47 & 50.85 & 51.56 \\

        \hline
    \end{tabular}
    \caption{Merging methods comparisons. All generated subset of data are trained on Mistral-7b-v0.3.}
    \label{tab:mergingappend}
\end{table*}
\end{document}


