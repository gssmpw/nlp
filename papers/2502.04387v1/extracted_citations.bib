@inproceedings{Conneau2019UnsupervisedCR,
  title={{Unsupervised Cross-lingual Representation Learning at Scale}},
  author={Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzm{\'a}n and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019},
}

@inproceedings{DEPT,
  title={{DEPT: Decoupled Embeddings for Pre-training Language Models}},
  author={Iacob, Alex and Sani, Lorenzo and Kurmanji, Meghdad and Shen, William F and Qiu, Xinchi and Cai, Dongqi and Gao, Yan and Lane, Nicholas D},
  booktitle={International Conference on Learning Representations},
  year={2025}
}

@article{FedAMoLE,
  title={{Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures}},
  author={Zhang, Yicheng and Qin, Zhen and Wu, Zhaomin and Deng, Shuiguang},
  journal={arXiv preprint arXiv:2411.19128},
  year={2024}
}

@inproceedings{FedDPA,
  title={{Dual-Personalizing Adapter for Federated Foundation Models}},
  author={Yang, Yiyuan and Long, Guodong and Shen, Tao and Jiang, Jing and Blumenstein, Michael},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}

@inproceedings{FedPerC,
  title={{FedPerC: Federated Learning for Language Generation with Personal and Context Preference Embeddings}},
  author={Silva, Andrew and Tambwekar, Pradyumna and Gombolay, Matthew},
  booktitle={Findings of the Association for Computational Linguistics},
  year={2023}
}

@inproceedings{adalora,
   title={{AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning}},
   author={Qingru Zhang and Minshuo Chen and Alexander Bukharin and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao},
   booktitle={The Eleventh International Conference on Learning Representations},
   year={2023},
}

@article{apfl,
  title={{Adaptive Personalized Federated Learning}},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2003.13461},
  year={2020}
}

@inproceedings{artetxe2020cross,
  title={{On the Cross-lingual Transferability of Monolingual Representations}},
  author={Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  year={2020},
}

@inproceedings{autolora,
  title={{AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning}},
  author={Zhang, Ruiyi and Qiang, Rushi and Somayajula, Sai Ashish and Xie, Pengtao},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year={2024}
}

@inproceedings{capaboost2024iclr,
    title={{Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning}},
    author={Haobo Song and Hao Zhao and Soumajit Majumder and Tao Lin},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
}

@inproceedings{chung2020improving,
  title={{Improving Multilingual Models with Language-Clustered Vocabularies}},
  author={Chung, Hyung Won and Garrette, Dan and Tan, Kiat Chuan and Riesa, Jason},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}

@inproceedings{conneau-etal-2020-unsupervised,
    title = "Unsupervised Cross-lingual Representation Learning at Scale",
    author = "Conneau, Alexis  and
      Khandelwal, Kartikay  and
      Goyal, Naman  and
      Chaudhary, Vishrav  and
      Wenzek, Guillaume  and
      Guzm{\'a}n, Francisco  and
      Grave, Edouard  and
      Ott, Myle  and
      Zettlemoyer, Luke  and
      Stoyanov, Veselin",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    year = "2020",
}

@inproceedings{dylora2023eacl,
  title={{DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation}},
  author={Valipour, Mojtaba and Rezagholizadeh, Mehdi and Kobyzev, Ivan and Ghodsi, Ali},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics (EACL)},
  year={2023}
}

@article{fedem,
  title={{Federated Multi-Task Learning Under a Mixture of Distributions}},
  author={Marfoq, Othmane and Neglia, Giovanni and Bellet, Aur{\'e}lien and Kameni, Laetitia and Vidal, Richard},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{fedex,
  title={{Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing}},
  author={Khodak, Mikhail and Tu, Renbo and Li, Tian and Li, Liam and Balcan, Maria-Florina F and Smith, Virginia and Talwalkar, Ameet},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{fedllm-bench,
  title={{FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models}},
  author={Ye, Rui and Ge, Rui and Zhu, Xinyu and Chai, Jingyi and Du, Yaxin and Liu, Yang and Wang, Yanfeng and Chen, Siheng},
  booktitle={Advances in Neural Information Processing Systems},
  year={2024}
}

@article{fedmeta,
  title={{Federated Meta-Learning with Fast Convergence and Efficient Communication}},
  author={Chen, Fei and Luo, Mi and Dong, Zhenhua and Li, Zhenguo and He, Xiuqiang},
  journal={arXiv preprint arXiv:1802.07876},
  year={2018}
}

@article{fedper,
  title={{Federated Learning with Personalization Layers}},
  author={Arivazhagan, Manoj Ghuhan and Aggarwal, Vinay and Singh, Aaditya Kumar and Choudhary, Sunav},
  journal={arXiv preprint arXiv:1912.00818},
  year={2019}
}

@inproceedings{flora,
  title={{Single-shot General Hyper-parameter Optimization for Federated Learning}},
  author={Zhou, Yi and Ram, Parikshit and Salonidis, Theodoros and Baracaldo, Nathalie and Samulowitz, Horst and Ludwig, Heiko},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{fml,
  title={{Federated Mutual Learning}},
  author={Shen, Tao and Zhang, Jie and Jia, Xinkang and Zhang, Fengda and Huang, Gang and Zhou, Pan and Kuang, Kun and Wu, Fei and Wu, Chao},
  journal={arXiv preprint arXiv:2006.16765},
  year={2020}
}

@inproceedings{holly2022evaluation,
  title={{Evaluation of Hyperparameter-Optimization Approaches in an Industrial Federated Learning System}},
  author={Holly, Stephanie and Hiessl, Thomas and Lakani, Safoura Rezapour and Schall, Daniel and Heitzinger, Clemens and Kemnitz, Jana},
  booktitle={Data Science--Analytics and Applications},
  year={2022},
}

@inproceedings{hpolorallm2024aaaiw,
      title={Hyperparameter Optimization for Large Language Model Instruction-Tuning}, 
      author={Christophe Tribes and Sacha Benarroch-Lelong and Peng Lu and Ivan Kobyzev},
      year={2024},
      booktitle={Edge Intelligence Workshop AAAI},
}

@article{llama3,
  title={{The Llama 3 Herd of Models}},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@inproceedings{pfedhn,
  title={{Personalized Federated Learning Using Hypernetworks}},
  author={Shamsian, Aviv and Navon, Aviv and Fetaya, Ethan and Chechik, Gal},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@inproceedings{pfeiffer2020mad,
  title={{MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer}},
  author={Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}

@article{royson2023fedl2p,
  title={{FedL2P: Federated Learning to Personalize}},
  author={Lee, Royson and Kim, Minyoung and Li, Da and Qiu, Xinchi and Hospedales, Timothy and Husz√°r, Ferenc and Lane, Nicholas},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@inproceedings{sora2023emnlp,
    title={{Sparse Low-rank Adaptation of Pre-trained Language Models}},
    author={Ning Ding and Xingtai Lv and Qiaosen Wang and Yulin Chen and Bowen Zhou and Zhiyuan Liu and Maosong Sun},
    booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
    year={2023},
}

@inproceedings{wang2020extending,
  title={{Extending Multilingual BERT to Low-Resource Languages}},
  author={Wang, Zihan and Karthikeyan, K and Mayhew, Stephen and Roth, Dan},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP},
  year={2020}
}

@inproceedings{wang2020negative,
  title={{On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment}},
  author={Wang, Zirui and Lipton, Zachary C and Tsvetkov, Yulia},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}

@article{xu2024survey,
  title={{A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias}},
  author={Xu, Yuemei and Hu, Ling and Zhao, Jiayi and Qiu, Zihan and Ye, Yuqi and Gu, Hanwen},
  journal={arXiv preprint arXiv:2404.00929},
  year={2024}
}

@inproceedings{yao2024layer,
  title={{Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models}},
  author={Yao, Kai and Gao, Penglei and Li, Lichun and Zhao, Yuan and Wang, Xiaofeng and Wang, Wei and Zhu, Jianke},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  year={2024}
}

@inproceedings{zhao2023breaking,
  title={{Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages}},
  author={Zhao, Wanru and Chen, Yihong and Lee, Royson and Qiu, Xinchi and Gao, Yan and Fan, Hongxiang and Lane, Nicholas Donald},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

