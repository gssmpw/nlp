\vspace{-0.5em}
\section{Conclusion}\label{sec:conclusion}

In this work, we tackle language personalization through \method{}, a federated learning method that learns how to perform PEFT on heterogeneous data. We show that our proposed federated {\em learning-to-personalize} approach is easily pluggable to off-the-shelf LLMs and standard and personalized FL methods alike, surpassing other personalized fine-tuning baselines in most cases. Our results show that \method{} automatically learns model- and task-specific language-agnostic LoRA rank structures as well as effective cross-lingual transfers, where both diverse low- and high-resource languages can share similar LoRA rank magnitudes. Despite clear advantages, our approach falls short in personalizing for each client's minority languages, as the personalized solution is skewed towards their predominant language. Nonetheless, our work is a significant step towards successfully merging the benefits of multilingual learning and personalized FL.