\begin{table*}[t]
\caption{Average METEOR/ROUGE-1/ROUGE-L of each language for \seen{} clients of our Fed-Aya setup. The pretrained MobileLLaMA-1.4B model is trained using Standard FL with LoRA following FedLLM-Bench~\cite{fedllm-bench} and the resulting \basemodel{} is personalized to each client given a baseline approach.}
\vspace{0.5em}
\label{tab:mobilellama_fedaya_unseen}
\begin{scriptsize}\resizebox{0.98\textwidth}{!}{
\begin{tabular}{c|l|l|l|l|l|l|l|l|l|c}
\toprule
\textbf{$\mathbf{r}$}  & \multicolumn{1}{c|}{\textbf{Approach}} & \multicolumn{1}{c|}{\textbf{te}} & \multicolumn{1}{c|}{\textbf{ar}} & \multicolumn{1}{c|}{\textbf{es}} & \multicolumn{1}{c|}{\textbf{en}} & \multicolumn{1}{c|}{\textbf{fr}} & \multicolumn{1}{c|}{\textbf{zh}} & \multicolumn{1}{c|}{\textbf{pt}} & \multicolumn{1}{c|}{\textbf{ru}} & \textbf{Wins} \\ \midrule
% \multirow{5}{*}{1}  & LoRA                                   & 0.0344/0.0000/0.0000                   & 0.1004/0.0564/0.0539             & 0.3329/0.4252/0.3809             & 0.1987/0.2339/0.1988             & 0.0505/0.0000/0.0000                   & 0.1457/0.0041/0.0034             & 0.1714/0.1907/0.1792             & \textbf{0.1174/0.0556/0.0556}    & 1             \\ % \cline{2-11} 
%                     & AdaLoRA                              & 0.0342/0.0042/0.0042             & 0.0941/0.0581/0.0556             & 0.3607/0.4708/0.4256             & 0.196/0.232/0.2011               & 0.049/0.0000/0.0000                    & \textbf{0.154/0.0092/0.0092}     & 0.1804/0.2222/0.2102             & 0.1075/0.0556/0.0556             & 2             \\ % \cline{2-11} 
%                     & BayesTune-LoRA                            & 0.0202/0.0000/0.0000                   & 0.0741/0.0461/0.0461             & 0.3357/0.3817/0.349              & 0.1912/0.2252/0.1858             & 0.0521/0.0000/0.0000                   & 0.1156/0.002/0.002               & 0.1592/0.164/0.151               & 0.0963/0.0556/0.0556             & 0             \\ % \cline{2-11} 
%                     & FedL2P                               & \textbf{0.1107/0.0075/0.0075}    & \textbf{0.1695/0.0391/0.0391}    & 0.3691/0.4312/0.4055             & 0.2432/0.2668/0.2291             & \textbf{0.0595/0.019/0.019}      & 0.1016/0.0101/0.0101             & \textbf{0.2085/0.2337/0.2237}    & 0.0746/0.0556/0.0556             & \textbf{3}    \\ % \cline{2-11} 
%                     & \method{}                                 & 0.1057/0.0042/0.0042             & 0.1191/0.0587/0.0587             & \textbf{0.3718/0.4349/0.4045}    & \textbf{0.2993/0.3342/0.297}     & 0.049/0.0000/0.0000                    & 0.1153/0.0049/0.0049             & 0.1928/0.2301/0.2169             & 0.0912/0.0556/0.0556             & 2             \\ \hline
\multirow{5}{*}{2}  & LoRA                                   & 0.0531/0.0042/0.0042             & 0.1032/\textbf{0.0524/0.0524}            & 0.3547/0.4490/0.4020               & 0.2385/0.2713/0.2356             & 0.0490/0.0000/0.0000                    & 0.1381/0.0088/0.0088             & 0.1865/0.2184/0.2070              & 0.0921/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & AdaLoRA                              & 0.0312/0.0000/0.0000                   & 0.1000/0.0520/0.0520                  & 0.3244/0.4250/0.3821              & 0.2165/0.2606/0.2197             & 0.0490/\textbf{0.0513/0.0513}              & \textbf{0.1609}/0.0089/0.0089    & 0.1904/0.2258/0.2129             & \textbf{0.0992}/0.0556/0.0556    & 1             \\ % \cline{2-11} 
                    & BayesTune-LoRA                            & 0.0276/0.0000/0.0000                   & 0.0934/0.0501/0.0476             & 0.3560/0.4084/0.3716              & 0.1786/0.2024/0.1688             & 0.0450/0.0000/0.0000                    & 0.1566/0.0109/0.0092             & 0.1469/0.1628/0.1500               & 0.0873/0.0556/0.0556             & 0             \\ % \cline{2-11} 
                    & FedL2P                               & \textbf{0.1199}/0.0042/0.0042    & \textbf{0.1399}/0.0206/0.0206    & \textbf{0.3923/0.4587}/0.4194    & 0.2688/0.3049/0.2650              & 0.0024/0.0011/0.0011             & 0.0888/\textbf{0.0121/0.0121}             & \textbf{0.2022}/0.2170/0.2063     & 0.0850/0.0556/0.0556              & 2             \\ % \cline{2-11} 
                    & \method{}                                 & 0.1105/\textbf{0.0132/0.0114}             & 0.1127/0.0483/0.0483             & 0.3812/0.4546/\textbf{0.4209}             & \textbf{0.3047/0.3354/0.3006}    & 0.0490/0.0000/0.0000                    & 0.0650/0.0069/0.0069              & 0.1997/\textbf{0.2505/0.2384}             & 0.0956/0.0556/0.0556             & \textbf{3}    \\ \hline
\multirow{5}{*}{4}  & LoRA                                   & 0.0687/0.0075/0.0075             & 0.0989/0.0581/0.0556             & 0.3244/0.4086/0.3749             & 0.2297/0.2726/0.2370              & 0.0490/0.0513/0.0513              & 0.1530/0.0089/0.0089              & 0.1872/0.2267/0.2124             & 0.0974/0.0556/0.0556             & 0             \\ % \cline{2-11} 
                    & AdaLoRA                              & 0.0263/0.0000/0.0000                   & 0.0894/\textbf{0.0634}/0.0610              & 0.3336/0.4322/0.3883             & 0.1762/0.2105/0.1765             & 0.0490/0.0000/0.0000                    & \textbf{0.1630}/0.0066/0.0049     & 0.1832/0.2096/0.1980              & 0.1156/0.0556/0.0556             & 0             \\ % \cline{2-11} 
                    & BayesTune-LoRA                            & 0.0471/0.0075/0.0075             & 0.0938/0.0544/0.0544             & 0.3357/0.4058/0.3629             & 0.1657/0.1964/0.1647             & 0.1155/0.0635/0.0635             & 0.1557/\textbf{0.0115/0.0099}             & 0.1511/0.1636/0.1517             & 0.0858/0.0222/0.0222             & 1             \\ % \cline{2-11} 
                    & FedL2P                               & 0.0569/0.0075/0.0075             & 0.1002/0.0610/\textbf{0.0610}               & 0.3098/0.4066/0.3837             & 0.2494/0.2901/0.2569             & \textbf{0.1157/0.0741/0.0741}    & 0.1585/0.0041/0.0041             & 0.1724/0.1920/0.1806              & 0.0804/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & \method{}                                 & \textbf{0.1121/0.0212/0.0212}    & \textbf{0.1537}/0.0333/0.0333    & \textbf{0.3725/0.4622/0.4273}    & \textbf{0.2945/0.3276/0.2821}    & 0.0490/0.0000/0.0000                    & 0.0722/0.0069/0.0069             & \textbf{0.1903/0.2547/0.2438}    & \textbf{0.1258/0.0556/0.0556}    & \textbf{5}    \\ \hline
\multirow{5}{*}{8}  & LoRA                                   & 0.1022/0.0042/0.0042             & 0.1206/0.0549/0.0549             & 0.3401/0.4382/0.3977             & 0.2722/\textbf{0.3127/0.2726}             & 0.0490/0.0000/0.0000                    & 0.1241/0.0089/0.0089             & 0.1879/0.2331/0.2202             & 0.0761/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & AdaLoRA                              & 0.0218/0.0000/0.0000                   & 0.0897/0.0364/0.0364             & 0.3383/0.4295/0.3920              & 0.1786/0.2150/0.1795              & 0.1221/\textbf{0.0833/0.0833}             & 0.1470/0.0066/0.0049              & 0.1773/0.1909/0.1770              & 0.1124/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & BayesTune-LoRA                            & 0.0529/0.0042/0.0042             & 0.0970/\textbf{0.0557/0.0557}              & 0.3544/0.4257/0.3789             & 0.1891/0.2235/0.1860              & \textbf{0.1262}/0.0784/0.0784    & \textbf{0.1522}/0.0068/0.0068    & 0.1365/0.1603/0.1483             & 0.0895/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & FedL2P                               & 0.0934/0.0042/0.0042             & 0.1138/0.0495/0.0495             & 0.3237/0.4366/0.4068             & 0.2438/0.2849/0.2451             & 0.0490/0.0000/0.0000                    & 0.1408/\textbf{0.0139/0.0139}             & 0.1946/0.2280/0.2130               & \textbf{0.1187}/0.0556/0.0556    & 1             \\ % \cline{2-11} 
                    & \method{}                                 & \textbf{0.1099/0.0132/0.0114}    & \textbf{0.1565}/0.0082/0.0082    & \textbf{0.4471/0.5240/0.4876}     & \textbf{0.2798}/0.2851/0.2475    & 0.0490/0.0000/0.0000                    & 0.1071/0.0069/0.0069             & \textbf{0.2160/0.2700/0.2559}       & 0.0862/0.0465/0.0465             & \textbf{3}    \\ \hline
\multirow{5}{*}{16} & LoRA                                   & 0.1193/0.0042/0.0042             & \textbf{0.1418/0.0587/0.0587}    & 0.3647/0.4240/0.3927              & 0.2939/\textbf{0.3164/0.2753}             & 0.0490/0.0000/0.0000                    & 0.0962/0.0089/0.0089             & 0.1916/0.2438/0.2320              & \textbf{0.1403/0.0556/0.0556}    & \textbf{3}    \\ % \cline{2-11} 
                    & AdaLoRA                              & 0.0079/0.0000/0.0000                   & 0.0848/0.0386/0.0361             & 0.3548/0.4216/0.3864             & 0.1814/0.2158/0.1750              & 0.1443/0.1333/0.1333             & 0.1408/\textbf{0.0115/0.0099}             & 0.1828/0.1892/0.1793             & 0.0957/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & BayesTune-LoRA                            & 0.0674/0.0075/0.0075             & 0.0887/0.0420/0.0420               & 0.3508/0.4174/0.3788             & 0.2088/0.2442/0.2106             & 0.1681/\textbf{0.1905/0.1905}             & \textbf{0.1594}/0.0089/0.0089    & 0.1877/0.2362/0.2225             & 0.0972/0.0556/0.0556             & 1             \\ % \cline{2-11} 
                    & FedL2P                               & 0.1093/\textbf{0.0673/0.0673}             & 0.1171/0.0320/0.0296              & 0.3895/0.4515/0.4131             & 0.2629/0.2606/0.2150              & 0.1349/0.1026/0.1026             & 0.1335/0.0041/0.0020              & 0.2011/0.2149/0.2027             & 0.0645/0.0253/0.0253             & 1             \\ % \cline{2-11} 
                    & \method{}                                 & \textbf{0.1289}/0.0165/0.0147    & 0.1215/0.0166/0.0166             & \textbf{0.4048/0.4910/0.4520}      & \textbf{0.2968}/0.3065/0.2678    & \textbf{0.2887}/0.1667/0.1667    & 0.0960/0.0069/0.0069              & \textbf{0.2359/0.2863/0.2704}    & 0.0791/0.0222/0.0222             & 2             \\ \bottomrule
\end{tabular}
}
\end{scriptsize}
\vspace{-1.5em}
\end{table*}