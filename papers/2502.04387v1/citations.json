[
  {
    "index": 0,
    "papers": [
      {
        "key": "xu2024survey",
        "author": "Xu, Yuemei and Hu, Ling and Zhao, Jiayi and Qiu, Zihan and Ye, Yuqi and Gu, Hanwen",
        "title": "{A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "conneau-etal-2020-unsupervised",
        "author": "Conneau, Alexis  and\nKhandelwal, Kartikay  and\nGoyal, Naman  and\nChaudhary, Vishrav  and\nWenzek, Guillaume  and\nGuzm{\\'a}n, Francisco  and\nGrave, Edouard  and\nOtt, Myle  and\nZettlemoyer, Luke  and\nStoyanov, Veselin",
        "title": "Unsupervised Cross-lingual Representation Learning at Scale"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "wang2020negative",
        "author": "Wang, Zirui and Lipton, Zachary C and Tsvetkov, Yulia",
        "title": "{On Negative Interference in Multilingual Models: Findings and A Meta-Learning Treatment}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "artetxe2020cross",
        "author": "Artetxe, Mikel and Ruder, Sebastian and Yogatama, Dani",
        "title": "{On the Cross-lingual Transferability of Monolingual Representations}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "pfeiffer2020mad",
        "author": "Pfeiffer, Jonas and Vuli{\\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian",
        "title": "{MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "llama3",
        "author": "Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others",
        "title": "{The Llama 3 Herd of Models}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "chung2020improving",
        "author": "Chung, Hyung Won and Garrette, Dan and Tan, Kiat Chuan and Riesa, Jason",
        "title": "{Improving Multilingual Models with Language-Clustered Vocabularies}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "wang2020extending",
        "author": "Wang, Zihan and Karthikeyan, K and Mayhew, Stephen and Roth, Dan",
        "title": "{Extending Multilingual BERT to Low-Resource Languages}"
      },
      {
        "key": "Conneau2019UnsupervisedCR",
        "author": "Alexis Conneau and Kartikay Khandelwal and Naman Goyal and Vishrav Chaudhary and Guillaume Wenzek and Francisco Guzm{\\'a}n and Edouard Grave and Myle Ott and Luke Zettlemoyer and Veselin Stoyanov",
        "title": "{Unsupervised Cross-lingual Representation Learning at Scale}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "zhao2023breaking",
        "author": "Zhao, Wanru and Chen, Yihong and Lee, Royson and Qiu, Xinchi and Gao, Yan and Fan, Hongxiang and Lane, Nicholas Donald",
        "title": "{Breaking Physical and Linguistic Borders: Multilingual Federated Prompt Tuning for Low-Resource Languages}"
      },
      {
        "key": "DEPT",
        "author": "Iacob, Alex and Sani, Lorenzo and Kurmanji, Meghdad and Shen, William F and Qiu, Xinchi and Cai, Dongqi and Gao, Yan and Lane, Nicholas D",
        "title": "{DEPT: Decoupled Embeddings for Pre-training Language Models}"
      },
      {
        "key": "fedllm-bench",
        "author": "Ye, Rui and Ge, Rui and Zhu, Xinyu and Chai, Jingyi and Du, Yaxin and Liu, Yang and Wang, Yanfeng and Chen, Siheng",
        "title": "{FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "fedper",
        "author": "Arivazhagan, Manoj Ghuhan and Aggarwal, Vinay and Singh, Aaditya Kumar and Choudhary, Sunav",
        "title": "{Federated Learning with Personalization Layers}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "fedmeta",
        "author": "Chen, Fei and Luo, Mi and Dong, Zhenhua and Li, Zhenguo and He, Xiuqiang",
        "title": "{Federated Meta-Learning with Fast Convergence and Efficient Communication}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "fedem",
        "author": "Marfoq, Othmane and Neglia, Giovanni and Bellet, Aur{\\'e}lien and Kameni, Laetitia and Vidal, Richard",
        "title": "{Federated Multi-Task Learning Under a Mixture of Distributions}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "pfedhn",
        "author": "Shamsian, Aviv and Navon, Aviv and Fetaya, Ethan and Chechik, Gal",
        "title": "{Personalized Federated Learning Using Hypernetworks}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "fml",
        "author": "Shen, Tao and Zhang, Jie and Jia, Xinkang and Zhang, Fengda and Huang, Gang and Zhou, Pan and Kuang, Kun and Wu, Fei and Wu, Chao",
        "title": "{Federated Mutual Learning}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "apfl",
        "author": "Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad",
        "title": "{Adaptive Personalized Federated Learning}"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "FedDPA",
        "author": "Yang, Yiyuan and Long, Guodong and Shen, Tao and Jiang, Jing and Blumenstein, Michael",
        "title": "{Dual-Personalizing Adapter for Federated Foundation Models}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "FedPerC",
        "author": "Silva, Andrew and Tambwekar, Pradyumna and Gombolay, Matthew",
        "title": "{FedPerC: Federated Learning for Language Generation with Personal and Context Preference Embeddings}"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "FedAMoLE",
        "author": "Zhang, Yicheng and Qin, Zhen and Wu, Zhaomin and Deng, Shuiguang",
        "title": "{Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "flora",
        "author": "Zhou, Yi and Ram, Parikshit and Salonidis, Theodoros and Baracaldo, Nathalie and Samulowitz, Horst and Ludwig, Heiko",
        "title": "{Single-shot General Hyper-parameter Optimization for Federated Learning}"
      },
      {
        "key": "holly2022evaluation",
        "author": "Holly, Stephanie and Hiessl, Thomas and Lakani, Safoura Rezapour and Schall, Daniel and Heitzinger, Clemens and Kemnitz, Jana",
        "title": "{Evaluation of Hyperparameter-Optimization Approaches in an Industrial Federated Learning System}"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "fedex",
        "author": "Khodak, Mikhail and Tu, Renbo and Li, Tian and Li, Liam and Balcan, Maria-Florina F and Smith, Virginia and Talwalkar, Ameet",
        "title": "{Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "royson2023fedl2p",
        "author": "Lee, Royson and Kim, Minyoung and Li, Da and Qiu, Xinchi and Hospedales, Timothy and Husz\u00e1r, Ferenc and Lane, Nicholas",
        "title": "{FedL2P: Federated Learning to Personalize}"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "adalora",
        "author": "Qingru Zhang and Minshuo Chen and Alexander Bukharin and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao",
        "title": "{AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning}"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "sora2023emnlp",
        "author": "Ning Ding and Xingtai Lv and Qiaosen Wang and Yulin Chen and Bowen Zhou and Zhiyuan Liu and Maosong Sun",
        "title": "{Sparse Low-rank Adaptation of Pre-trained Language Models}"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "capaboost2024iclr",
        "author": "Haobo Song and Hao Zhao and Soumajit Majumder and Tao Lin",
        "title": "{Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "autolora",
        "author": "Zhang, Ruiyi and Qiang, Rushi and Somayajula, Sai Ashish and Xie, Pengtao",
        "title": "{AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning}"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "hpolorallm2024aaaiw",
        "author": "Christophe Tribes and Sacha Benarroch-Lelong and Peng Lu and Ivan Kobyzev",
        "title": "Hyperparameter Optimization for Large Language Model Instruction-Tuning"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "dylora2023eacl",
        "author": "Valipour, Mojtaba and Rezagholizadeh, Mehdi and Kobyzev, Ivan and Ghodsi, Ali",
        "title": "{DyLoRA: Parameter-Efficient Tuning of Pre-trained Models using Dynamic Search-Free Low-Rank Adaptation}"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "yao2024layer",
        "author": "Yao, Kai and Gao, Penglei and Li, Lichun and Zhao, Yuan and Wang, Xiaofeng and Wang, Wei and Zhu, Jianke",
        "title": "{Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models}"
      }
    ]
  }
]