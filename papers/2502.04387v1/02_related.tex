\section{Related Work}\label{sec:related}

\noindent\textbf{Multilingual LLMs (MLLMs).}~Existing efforts in multilingual LLMs often underperform on low-resource languages due to \textit{1)}~data scarcity~\cite{xu2024survey}, \textit{2)}~the model's limited capacity to learn the intricacies of multiple languages~\cite{conneau-etal-2020-unsupervised}, and \textit{3)}~negative transfer learning among languages~\cite{wang2020negative}.
Common ways to counteract these challenges include the use of separate vocabulary and embeddings~\cite{artetxe2020cross}, hand-crafted adapters~\cite{pfeiffer2020mad}, automatic data annotation~\cite{llama3}, clustering and merging languages with similar representations~\cite{chung2020improving}, among other contributions~\cite{wang2020extending,Conneau2019UnsupervisedCR}. Our work is orthogonal to these approaches and builds upon recent FL-based MLLMs~\cite{zhao2023breaking,DEPT,fedllm-bench}, which utilize FL to tap into previously inaccessible low-resource data sources.

\noindent\textbf{Personalized Federated Learning.}~To obtain personalized client-specific models, various approaches have been proposed, including the use of personalized layers~\cite{fedper}, meta-learning~\cite{fedmeta}, model mixtures~\cite{fedem}, hypernetworks~\cite{pfedhn}, transfer learning between global and local models~\cite{fml}, among other contributions~\cite{apfl}. Some of these techniques have also been adopted for LLMs, \textit{e.g.},~personalized LoRAs~\cite{FedDPA}, hypernetworks for client embeddings~\cite{FedPerC}, and mixtures of LoRA experts~\cite{FedAMoLE}. Our work complements these approaches as personalized models can benefit from further fine-tuning as shown in Section~\ref{sec:eval_complement}.

\noindent\textbf{Federated Hyperparameter Optimization (HPO).}~Most federated approaches to HPO do not utilize the client dataset for personalized hyperparameters. Instead, they employ a single set of hyperparameters across all clients based on the local validation loss evaluated before FL~\cite{flora,holly2022evaluation} or sample from federatedly learnt hyperparameter categorical distributions for each client~\cite{fedex}. An exception to this is FedL2P~\cite{royson2023fedl2p} which utilizes a PSG for personalized per-layer learning rates and batch normalization hyperparameters. We compare with FedL2P in our experiments.
% %FedL2P proposed federatedly learning a PS generator (PSG) which takes in as input, the client features conditioned on the base model, and outputs per-layer layer-wise and batch normalization hyparams. While FedL2P has been shown to work well in standard small-scale image and speech benchmarks, their applicability to LLMs is unclear: i) LLMs don't use BN, ii) LLMs often use adaptive optimizers, making learning rate a less sensitive hyparam for downstream performance. Learning the learning rates also require FedL2P to adopt expensive 2nd-order optimization methods as the learning rate is not a direct gradient of the loss, a limitation that is further aggravated with LLMs.

\noindent\textbf{PEFT Structure Learning.}~Contrary to the conventional approach of distributing uniform adapter modules across all layers, a recent line of work allows different LoRA ranks to be used across a model's weight matrices. Using fine-grained per-layer rank selection, existing methods include SVD-based LoRA reformulation followed by importance-based rank assignment~\cite{adalora}, trainable rank-gating units~\cite{sora2023emnlp}, selectively employing parallel weight modules~\cite{capaboost2024iclr}, meta-learning-based~\cite{autolora} and black-box optimization techniques~\cite{hpolorallm2024aaaiw}, specialized training recipes for multi-rank LoRA modules that allow flexible extraction of a range of ranks~\cite{dylora2023eacl}, and coarse-grained dropping of LoRA-enhanced layers~\cite{yao2024layer}. While these methods can be effective in centralized setups, they typically require an excessive number of optimization steps, which is prone to overfitting in FL settings, where clients have limited amount of data.
