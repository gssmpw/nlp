% Good

\section{Zero Testing}
\label{sec:zero-testing}

In this section, we consider the zero-testing problem with Kronecker measurements.  That is, we suppose that we have a nonzero tensor $\tA \in (\R^{n})^{\otimes q}.$ How many Kronecker structured measurements of the form $v_1 \otimes \ldots \otimes v_q$ do we need to show that $\tA$ is nonzero?

As it turns out, the most difficult case for zero-testing is when $\tA$ itself has Kronecker structure.  When we can write $\tA = \va_1 \otimes \ldots \otimes \va_q$, then each measurement of $\tA$ gives a result of the form $\prod_i (\vv_i^\intercal \va_i),$ which is $0$ as long as at least one of the terms in the product is $0.$   This suggests that we should first study the zero-testing problem in the non-Kronecker setting.

Here, we make the additional assumption that the entries of each $\va_i$ come from a fixed ``alphabet" that we call $\alphabet \subseteq \C.$  This assumption may seem strange at first, but one motivation is that in the non-Kronecker setting, trace estimators such as Hutchinson typically only require that one sketch using Rademacher random vectors.  If one attempts to use a Kronecker product of Rademacher vectors, then trace estimation turns out to require a number of measurements that is exponential in $q.$  The zero-testing problem gives a simpler setting in which to observe this exponential dependence.  Indeed the reason is quite similar to our norm-estimation results -- Kronecker products of Rademacher can be orthogonal to a fixed tensor with high probability, just as how Kronecker products of Gaussians are typically very nearly orthogonal to one another.


To set up some notation, suppose we have a tensor $\tA \in (\R^{n})^{\otimes q}.$  For $\vv \in \R^{n}$ say that the measurement of $\tA$ along mode $i$ by $\vv$ is the tensor in $(\R^{n})^{\otimes q-1}$ that results from taking the inner product of $\vv$ against each of the mode $i$ fibers.
We use the notation $\tA \times_i \vv.$
This is the \emph{Modal Product} as defined in \cite{golub2013matrix}.

The following definitions will be useful for writing our upper and lower bounds with respect to given alphabets.

\begin{definition}
For a given alphabet $\alphabet$, and a field $\mathbb{F}$, either $\R$ or $\C$, let 
\[
P_{\mathbb{F}}(\alphabet, n) = \min_{\mathcal{D}} \max_{\vu \in \alphabet^n} \Pr_{\vv \sim \mathcal{D}}[\vv^\intercal \vu \neq 0],
\]
where $\mathcal{D}$ ranges over all probability distributions on the nonzero vectors in $\mathbb{F}^n.$ When $\mathbb{F}$ is not specified, we assume that $\mathbb{F} = \R.$

Similarly, we define
\[
Q_{\mathbb{F}}(\Sigma, n) = \max_{\mathcal{D}_{\alphabet}} \min_{\vv \in \mathbb{F}^n} \Pr_{\vu \sim \mathcal{D}_{\alphabet}}[\vv^\intercal \vu \neq 0],
\]
where $\mathcal{D}_{\alphabet}$ ranges over distributions on $\alphabet^n.$
\end{definition}

Intuitively, $P$ captures highest success probability that we can achieve for zero-testing on the hardest input distribution.  So upper-bounding $P$ can be used to give a zero-testing lower bound.

Similarly a lower bound on $Q$ shows that there is a distribution over measurements that has good success probability of giving a nonzero measurement on all inputs.  So a lower bound on $Q$ can be used to give an upper bound for the zero-testing problem.


\begin{theorem}
\label{thm:alphabet_lower_bounds}
We have the following.
\begin{enumerate}
\item $P(\{-1,1\}, 2) \leq \frac12$
\item For an arbitrary finite alphabet $\alphabet$, $P(\alphabet, n) \leq 1 - \frac{1}{{\abs{\alphabet}}}\frac{n-{\abs{\alphabet}}}{n-1}$
\item For an arbitrary finite alphabet $\alphabet$, $Q(\alphabet, n) \geq 1 - \frac{1}{\abs{\alphabet}}$


\item $P_{\mathbb{C}}(\{-1,1,i,-i\}, 2) = Q_{\mathbb{C}}(\{-1,1,i,-i\}, 2) = 3/4$

\end{enumerate}

\end{theorem}

\begin{proof}
\begin{enumerate}

\item Choose $\mathcal{D}$ to be uniform over $\{(1,1), (1,-1)\}.$ Then any vector $\vu$ in $\{-1,1\}^2$ has dot product $0$ with one element of $\{(1,1), (1,-1)\}.$ So if $\vv$ is uniform from $\{(1,1), (1,-1)\}$, then with probability $1/2$, $\vv^\intercal \vu = 0.$

\item Choose $\mathcal{D}$ to be the uniform distribution over vectors of support size $2$ whose first nonzero value is $1$ and whose second nonzero value is $-1$.
Let $\vv$ be drawn from $\mathcal{D}$ and let $i,j$ be the coordinates of its support. Now suppose that $\vu$ has entries in $\alphabet.$  Then $\vv^\intercal \vu = 0$ precisely when $[\vu]_i = [\vu]_j$.

For each \(k\in\alphabet\), let \(n_k\) denote the number of entries of \vu that take value \(k\).
The probability that $[\vu]_i = [\vu]_j$ is then
\[
\dbinom{n}{2}^{-1}\left(\dbinom{n_1}{2} + \dbinom{n_2}{2} + \ldots + \dbinom{n_L}{2}\right).
\]
We can bound this sum as
\begin{align*}
\sum_{i=1}^{\abs{\alphabet}} &\dbinom{n_i}{2} 
= \frac{1}{2}\sum_{i=1}^{\abs{\alphabet}} (n_i^2 - n_i) \\
&= \frac{1}{2}(\sum_{i=1}^{\abs{\alphabet}} n_i^2 - n)%\\
\geq \frac{1}{2}(\frac{n^2}{{\abs{\alphabet}}} - n).
\end{align*}

In the last line we used the bound 
\(
\sum_{i=1}^{\abs{\alphabet}} n_i^2 \geq \frac{1}{\abs{\alphabet}}\left( \sum_{i=1}^{\abs{\alphabet}} {n_i}\right)^2,
\)
which is a special case of Cauchy-Schwarz.
% 
It follows that
\[
\Pr([\vu]_i = [\vu]_j) \geq \frac{1}{{\abs{\alphabet}}}\frac{n-{\abs{\alphabet}}}{n-1}.
\]

\item Choose $\mathcal{D}_{\alphabet}$ to to have i.i.d. entries over $\alphabet$ and let $\vu$ be drawn from $\mathcal{D}_{\alphabet}$  Let $i$ be the first nonzero coordinate of $\vv.$ Conditioned on all coordinates of $\vu$ except $i,$ the value of $\vv^\intercal \vu$ is uniform over a set of size $\abs{\alphabet}.$ Therfore $\vv^\intercal \vu$ is $0$ with probability at most $\frac{1}{\abs{\alphabet}}.$

\item To bound $P_{\mathcal{C}}$, choose the distribution $\mathcal{D}$ to be uniform over $\{(1,1), (1,-1) (1,i), (1,-i)\}.$  Now observe that any two-dimensional vector with entries in $\{\pm 1, \pm i\}$ is orthogonal to one of these four vectors.  So $P_{\mathcal{C}} \leq \frac{3}{4}.$

Similarly, for $Q_{\mathcal{C}}$ we choose our measurement distribution $\mathcal{D}_{\alphabet}$ to be uniform over $\{(1,1), (1,-1) (1,i), (1,-i)\}.$ These vectors are pairwise linearly independent, so any fixed $\vu$ is orthogonal to at most one of them.  Thus $Q_{\mathcal{C}} \geq 3/4.$

\end{enumerate}
\end{proof}


The following gives a general lower bound for the zero-testing problem via Kronecker measurements.  The idea is effectively to boost the analogous lower bound for non-Kronecker-structured measurements.  We also give a corresponding upper bound that works by reducing to the analogous upper bound for non-Kronecker-structured measurements inductively along each mode.



\begin{theorem}
\label{thm:zero_testing_from_general_to_kronecker}
\begin{enumerate}[label=(\roman*)]
\item Zero-testing of an arbitrary vector $\vv \in (\R^n)^{\otimes q}$ with $\frac23$ success probability, using Kronecker structured measurements in $(\alphabet^n)^{\otimes q}$ requires at least $\frac23\Omega(P_{\bbF}(\alphabet, n)^{-q})$ measurements.

\item Suppose that $\alphabet \subseteq \mathbb{F}.$ There is a zero-tester using Kronecker-structured measurements over the alphabet $\Sigma$, that succeeds with $\frac23$ probability and uses $2 Q_{\mathbb{F}}(\alphabet, n)^{-q}$ measurements.
\end{enumerate}

\end{theorem}
\begin{proof}
For the lower bound, let $\mathcal{D}$ be the distribution that achieves the minimum in the definition of $p(\alphabet, n).$  Let $\vv_1, \ldots, \vv_q$ be drawn independently from $\mathcal{D}.$  Let $\vx_1, \ldots, \vx_q$ be arbitrary fixed vectors in $\alphabet^n.$  Then we have
\[
(\vx_1 \otimes \ldots \otimes \vx_q)^\intercal (\vv_1 \otimes \ldots \otimes \vv_q) 
= (\vx_1^\intercal \vv_1)\ldots (\vx_q^\intercal \vv_q).
\]
Note that $\vx_i^\intercal \vv_i \neq 0$ with probability at most $p(\alphabet, n).$  Each of the terms $\vx_i^\intercal \vv_i$ is independent, and so the probability that the product is nonzero is at most $p(\alphabet, n)^q.$

Suppose that an algorithm makes $m$ Kronecker-structured measurements.  Then by a union bound, the probability that at least one of the measurements is nonzero is at most $m p(\alphabet, n)^q.$  The claim follows.

For the upper bound, choose our measurement vectors to be of the form $\vu_1 \otimes \ldots \otimes \vu_q$ where the $\vu_i$'s are i.i.d. from the distribution $\mathcal{D}_{\alphabet}.$  Then for a nonzero tensor $\tA$ have
\[
\inner{\tA}{\vu_1 \otimes \ldots \otimes \vu_q}
= \tA \times_1 \vu_1 \times_2 \vu_2 \ldots \times_q \vu_q.
\]
Since $\tA$ is nonzero, $\tA$ has some nonzero fiber along mode $1$, and therefore $\tA \times_1 \vu_1$ is nonzero with probability at least $Q_{\mathbb{F}}(\alphabet, n).$  Continuing inductively, the measurement above is nonzero with probability at least $Q_{\mathbb{F}}(\alphabet, n)^q.$  Given $m$ measurements of this form, the probability that all of them are $0$ is at most
\[
(1 - Q_{\mathbb{F}}(\alphabet, n)^q)^m
\leq \exp(-m Q_{\mathbb{F}}(\alphabet, n)^q),
\]
which is at most $1/4$ for $m\geq 2 Q_{\mathbb{F}}(\alphabet, n)^{-q}.$
\end{proof}


\iffalse
Let $\mathcal{U}$ and $\mathcal{V}$ be two collections of vectors in $\mathcal{C}^N.$  Define 
\[
p(\mathcal{U}, \mathcal{V}) = \max_{\mathcal{D}_{\mathcal{U}}} \min_{\mathcal{D}_{\mathcal{V}}} \Pr_{u \sim \mathcal{D}_{\mathcal{U}}, v \sim \mathcal{D}_{\mathcal{V}}} u^\intercal v \neq 0.
\]
Intuitively $\mathcal{D}_{\mathcal{V}}$ represent the worst 

\begin{lemma}

\end{lemma}
\fi


\begin{lemma}
\label{lem:from_zero_testing_to_trace_estimation}
An algorithm that performs constant-factor trace estimation requires at least $\frac{2}{3} P_{\mathbb{F}}(\alphabet, n)^{-q}$
Kronecker-structured vector-matrix-vector queries.
\end{lemma}
\begin{proof}
Let $\vx_1, \ldots, \vx_q$ be drawn from the distribution $\mathcal{D}$ in the definition of $P_{\mathbb{F}}(\alphabet, n).$
Set $\vx = \vx_1 \otimes \ldots \otimes \vx_q$.
Take our matrix $\mA$ to be $\vx\vx^\intercal$.

Suppose that we make \(t\) measurements of the form \(\mA\vv^{(i)}\), where \(\vv^{(i)}\) for \(i\in[t]\) has Kronecker structure and uses the alphabet \alphabet.
The result of the measurement is nonzero precisely when \(\vx^\intercal\vv^{(i)} \neq 0\).
The probability that this is nonzero is exactly \((P_{\bbF}(\alphabet,n))^q\).
By a union bound, the probability that at least one of the matrix-vector products is nonzero is at most \(t (P_{\bbF}(\alphabet,n))^q\).
On the other hand, a constant factor trace estimator must distinguish \mA from the \(\mat0\) matrix with probability \(\frac23\), so we need $t (P_{\bbF}(\alphabet, n))^q \geq \tsfrac23.$
from which the claim follows.
\end{proof}

Combining the previous results give the following bounds for zero-testing.

\begin{corollary}
\label{cor:zero_testing_lower_bound_special_cases}
Zero testing for a tensor in $(\R^n)^{\otimes q}$ with success probability $\frac23$
\begin{enumerate}
\item requires at least $\Omega(2^q)$ measurements over the alphabet $\{-1,1\}$ when $n=2.$
\item Requires at least $\Omega((1 - \frac{1}{\abs{\alphabet}} \frac{n-\abs{\alphabet}}{n-1})^q)$ for an arbitrary alphabet $\alphabet.$
\end{enumerate}
For zero testing for a tensor in \((\bbC^{n})^{\otimes q}\), it is necessary and sufficient to use $\Theta ((4/3)^q)$ measurements for the alphabet $\{-1, 1, i, -i\}$ when $n=2$.
\end{corollary}
\begin{proof}
Combine Theorem~\ref{thm:alphabet_lower_bounds} with Theorem~\ref{thm:zero_testing_from_general_to_kronecker}.
\end{proof}



We obtain a similar corollary for trace estimation.
\begin{corollary}
\label{cor:trace_estimation_lower_bound}
Constant-factor trace estimation of a real PSD matrix requires $\Omega(2^{q})$ measurements when \(n=2\) and when using Rademacher Kronecker-structured matrix-vector queries, i.e. with vectors in $(\{-1,1\}^2)^{\otimes q}.$

Constant-factor trace estimation of a complex PSD matrix requires $\Omega((4/3)^{q})$ measurements when \(n=2\) and when using complex Rademacher Kronecker-structured matrix-vector queries, i.e. with vectors in $(\{-1,1,i,-i\}^2)^{\otimes q}.$
\end{corollary}

\begin{proof}
Combine Corollary~\ref{cor:zero_testing_lower_bound_special_cases} with Lemma~\ref{lem:from_zero_testing_to_trace_estimation}.
\end{proof}







\iffalse
\begin{theorem}
Let $\mathcal{A}\subseteq\R$ be an fixed alphabet of size $\abs{\mathcal{A}} = L.$  A zero-testing algorithm that makes Kronecker structured measurements using entries from $\mathcal{A}$ requires at least FILL measurements.  Moreover there are algorithms using FILL measurements.
\end{theorem}
\begin{proof}

For the lower bound, let $x\in\R^n$ have two coordinates of opposite signs in uniformly random pair of positions $(i,j)$.  Suppose that $v$ has entries drawn from $\mathcal{A}.$  Then $\inner{v}{x} = 0$ precisely when $v_i = v_j$.

Suppose that $v$ has $n_k$ entries from value $k$ in $\mathcal{A}.$ The probability that $v_i = v_j$ is then
\[
\dbinom{n}{2}^{-1}\left(\dbinom{n_1}{2} + \dbinom{n_2}{2} + \ldots + \dbinom{n_L}{2}\right).
\]
We can bound this sum as
\[
\sum_{i=1}^L \dbinom{n_i}{2} 
= \frac{1}{2}\sum_{i=1}^L (n_i^2 - n_i)
= \frac{1}{2}(\sum_{i=1}^L n_i^2 - n)
\geq \frac{1}{2}(\frac{n^2}{L} - n).
\]
It follows that
\[
\Pr(v_i = v_j) \geq \frac{1}{L}\frac{n-L}{n-1}.
\]
This in turn implies that 
\[\inner{v^{(1)} \otimes \ldots \otimes v^{(q)}}{x^{(1)} \otimes \ldots \otimes x^{(q)}} \neq 0
\] with probability at most $\left(1 - \frac{1}{L}\frac{n-L}{n-1}\right)^q.$


\end{proof}

\Raph{Todo: add corollary for trace est, one in large alphabet in in small alphabet (for both real and complex)}

\fi

