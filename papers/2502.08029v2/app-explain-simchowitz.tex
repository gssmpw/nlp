% Good


\section{Connecting to the Simchowitz et. al Lower Bounds}
\label{app:explain-simchowitz}

In \cite{simchowitz2017gap}, the authors prove a lower bound against the number of matrix-vector products needed to detect if there is a rank-one matrix planted on a random Wigner matrix.
Their techniques and proofs are all written to consider the generic matrix-vector model, where we can compute \(\mA\vv\) for any vector \(\vv\in\bbR^D\).
However, with minor alteration, their proof techniques can be significantly generalized to allow matrix-vector products with a limited matrix-vector model.
To start, we define a generic notion of a limited matrix-vector model.

\begin{definition}
    Fix a set \(\cV^t \in (\bbS^{D})^{t}\).
    A matrix-vector algorithm \cA is \(\cV^t\) limited if it always computed exactly \(t\) matrix vector products and if, for all input matrices \(\mA\in\bbR^{D \times D}\) the algorithm only computes (possibly adaptive) query vectors \(\vv^{(1)},\ldots,\vv^{(t)}\) such that the sequence \((\vv^{(1)},\ldots,\vv^{(t)}) \in \cV^t\).
\end{definition}

The proof methods of \cite{simchowitz2017gap} rely on assuming that the matrix-vector queries computed are orthonormal.
We do not want to assume that the queries admissible in \(\cV^t\) are orthonormal, so we instead will make an assumption on \(\cV^t\) that measure how far \(\cV^t\) is from having orthonormal queries:
\begin{definition}
    For each \((\vv^{(1)},\ldots,\vv^{(t)}) \in \cV^t\), let \(\mV = \sbmat{\vv^{(1)} & \cdots & \vv^{(t)}} \in \bbR^{D \times t}\).
    If, for all \((\vv^{(1)},\ldots,\vv^{(t)}) \in \cV^t\) we know that the condition number of \mV is at most \(\kappa\), then we say that \(\cV^t\) is \emph{\(\kappa-\)conditioned}.
\end{definition}

We can now setup the instance of the lower bound problem considered in \cite{simchowitz2017gap}.

\begin{setting}
    \label[setting]{setting:abstract-simchowitz}
	Fix \(D\in\bbN\) and \(\lambda > 1\).
    Fix a \(\cV^t\) limited matrix-vector algorithm \cA.
	Let \cP be a isotropic prior distribution over planted vectors \(\vu\in\bbS^{D-1}\), so that \(\E[\vu]=\vec0\) and \(\E[\vu\vu^\intercal]=\mI\).
	Let \(\mW = \frac12(\mG+\mG^\intercal)\) where \(\mG\in\bbR^{D \times D}\) is a matrix with iid \(\cN(0,1)\) entries.
	Let \(\mA_0 \defeq \frac{1}{\sqrt D}\mW\) and \(\mA_1 = \frac{1}{\sqrt D}\mW + \lambda \vu\vu^\intercal\).
	Nature picks \(i \in \{0,1\}\) uniformly at random.
    \cA then computes \(t\) matrix vector products with \(\mA \defeq \mA_i\) and returns a guess of the value of \(i\).
\end{setting}

In this setting, we will show that \cite{simchowitz2017gap} proves the following lower bounding mechanism:

\begin{theorem}
	\label{thm:abstract-simchowitz-requirements}
	Consider \Cref{setting:abstract-simchowitz}.
	Fix any \(0 \leq \tau_1 \leq \ldots \leq \tau_t\) and \(\kappa > 1\).
	Let \(f(\tau)\) be the probability that the best possible blind guess for \(\vu\) in \(\cV^t\) has squared inner product at least \(\frac{\tau}{D}\):
	\[
		f(\tau) \defeq \sup_{(\vv^{(1)},\ldots,\vv^{(t)})\in\cV^t} \sup_{i\in[t]} \Pr[\langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau}{D}}].
	\]
	Suppose that for some \(z\in(0,1)\)
	\[
		f(\tau_1) + 2 \sum_{i=1}^t e^{\frac{\lambda^2\kappa}2 \sum_{j=1}^{i-1}\tau_j}\sqrt{f(\tau_j)} \leq z
	\]
	and that
	\[
		\E_{\vu,\vu'\sim\cP}[e^{\lambda^2 \kappa^2 |\langle \vu, \vu'\rangle|\sum_{i=1}^t \tau_i + \frac{\lambda^2\kappa^4}{D}(\sum_{i=1}^t \tau_i)^2}] \leq 1+z.
	\]
	Then, \cA can distinguish \(\mA_0\) from \(\mA_1\) with probability at most \(\frac12 + \frac12 \sqrt{3z}\).
	In particular, if \(z \leq \frac1{27}\), then any such algorithm \cA cannot correctly guess if \(i=0\) or \(i=1\) with probability at least \(\frac23\).
\end{theorem}

In \Cref{app:formal-kronmatvec-lower}, we show how to use \Cref{thm:abstract-simchowitz-requirements} to lower bound Kronecker matrix-vector complexity.
In this section, we instead will show how \Cref{thm:abstract-simchowitz-requirements} follow from \cite{simchowitz2017gap}.
To start, we will use the notion of \emph{Truncated Probability Distributions} from \cite{simchowitz2017gap}.
\begin{definition}
Let \(\bbP\) be a probability measure.
Let \(A\) be an event.
Then, the truncated probability measure of \(\bbP\) with respect to \(A\) is defined by saying for all events \(B\),
\[
	P[B ; A] \defeq P[B \cap A]
\]
\end{definition}
This is not a probability distribution as its integral is less than 1 for any nontrivial event \(A\).
For discussion as to why the truncated probability distribution is helpful in proving information-theoretic lower bounds, see \cite{simchowitz2017gap,simchowitz2018tight}.
We will also need the idea of the marginal of truncated distributions.
\begin{definition}
    Let \cP be a distribution over a space \(\Theta\).
    Let \(\{\bbP_{\theta}\}_{\theta\in\Theta}\) be a family of probability measures on space \((\cX,\cF)\).
    For each \(\theta\), let \(A_\theta\) be an event on \cF.
    For any event \(B\) on \cF we can then define the \emph{marginal truncated distribution} \(\bar\bbP[\cdot;\bar A]\) as
    \[
        \bar\bbP[B;\bar A] \defeq \E_{\theta \sim \cP} \bbP_\theta[B;A_\theta].
    \]
    Notice that the total measure of \(\bar\bbP[\cdot,\bar A]\) is \(\bar\bbP[\cX;\bar A] = \E_{\theta\sim\cP}\bbP_\theta[\cX;A_\theta] = \Pr_{\theta\sim\cP}[A_\theta]\).
    Without truncation, we write \(\bar\bbP \defeq \bar\bbP[\cdot;\cX]\).
\end{definition}

We will concretely take \(\bbQ\) and \(\bar\bbP\) to be distributions over transcripts of matrix-vector products between \cA and \mA.
That is, we let \(\cZ_t \defeq (\vv^{(1)},\mA\vv^{(1)},\ldots,\vv^{(t)},\mA\vv^{(t)})\) be the transcript of \(t\) matrix-vector products.
Then, we take \bbQ to be the distribution of \(\cZ_t\) given \(i=0\), so that \(\mA = \frac1{\sqrt D}\mW\).
We then will take \(\vu\sim\cP\) as our prior distribution, so that \(\theta = \vu\).
Then, we let \(\bbP_{\vu}\) be the distribution of \(\cZ_t\) given both \(i=1\) and a fixed value of \(\vu\), so that \(\mA = \frac{1}{\sqrt D} \mW + \lambda\vu\vu^\intercal\) for a fixed \vu.
For any fixed \(\vu\), we will take our truncation event to be \(\mA_\theta = \cV_{\vu}^t \defeq \{(\vv^{(1)},\ldots,\vv^{(t)})\in\cV^t ~:~ \langle \vv^{(i)},\vu\rangle^2 \leq \frac{\tau_i}{D} ~ \forall i\in[t]\}\), using the constants \(0 \leq \tau_1 \leq \ldots \leq \tau_t\) as given in \Cref{thm:abstract-simchowitz-requirements}.
In words, this truncation set \(\cV_{\vu}^t\) is the set of all queries that fail to find nontrivial information about the vector \vu.
Lastly, this means that \(\bar\bbP\) is the marginal distribution of all the truncated distributions.
That is, \(\bar\bbP\) is the distribution of \(\cZ_t\) given \(i=1\) but not given any particular value of \(\vu\), and \(\bar\bbP[\cdot,\bar A]\) is \(\bar\bbP\) truncated to the cases where our algorithm has not computed any matrix-vector products that achieve nontrivial inner product with \vu.

Our main goal is to bound the total variation distance between \(\bbQ\) and \(\bar\bbP\).
\cite{simchowitz2017gap} bound this distance by truncating \(\bar\bbP\) and bounding both the probability of the truncated event not happening and the distance between \(\bbQ\) and the truncated \(\bar\bbP[\cdot;\bar A]\).
This is formalized by Proposition 6.1 from \cite{simchowitz2017gap}, whose proof has a fixable error.
We provide and prove the fixed version below:


\begin{importedlemma}[Proposition 6.1 of \cite{simchowitz2017gap}]
    \label{lem:corrected-truncated-dtv}
    Let \(\cP,\{\bbP_\theta\}_{\theta\in\Theta},\) and \(A_\theta\) define a marginal truncated distribution \(\bar\bbP[\cdot,\bar A]\) on \((\cX,\cF)\).
    Let \(\bbQ\) be a probability distribution on \((\cX,\cF)\).
    Then, letting \(p \defeq \bar \bbP[\cX; \bar A] = \Pr_{\theta\sim\cP}[A_\theta]\), we have
    \[
        D_{TV}(\bar \bbP, \bbQ) \leq \frac12 \sqrt{\E_{x \sim \bbQ}\left[\left(\frac{d\bar \bbP[x; \bar A]}{d\bbQ(x)}\right)^2\right]+1-2p} + \frac{1-p}{2}.
    \]
    In particular, if we have \(\E_{x\sim \bbQ}\left[\left(\frac{d\bar \bbP[x; \bar A]}{d\bbQ(x)}\right)^2\right] \leq 1+z\) and \(1-p < z\) for some \(z\in(0,1)\), then we can bound \(D_{TV}(Q, \bar P) \leq \sqrt{3z}\).
\end{importedlemma}
\begin{proof}
\emph{This proof is a close copy of the result in \cite{simchowitz2017gap}, but avoids errors in algebra.}
For ease of notation, let \(\bar \bbP_A := \bar \bbP[\cdot, \bar A]\).
Note that \(\bar \bbP - \bar \bbP_A \geq 0\), which implies that
\[
    \int \abs{d\bar \bbP - d \bar \bbP_A}
    = \int d\bar \bbP - d \bar \bbP_A
    = 1 - p
\]
so by the triangle inequality,
\begin{align*}
    &D_{TV}(\bbQ, \bar \bbP)
    = \frac12  \int \abs{d \bbQ(x) - d \bar \bbP(x)} \\
    \leq & \frac12 \int \abs{d \bbQ(x) - d \bar \bbP_A(x)} + \frac12 \int \abs{d \bar \bbP(x) - d \bar \bbP_A(x)} \\
    = & \frac12 \int \abs{d \bbQ(x) - d \bar \bbP_A(x)} + \frac{1-p}{2}.
\end{align*}
Next, since \(\bbQ\) is a probability measure,
\begin{align*}
    \int \abs{d \bbQ(x) - d \bar \bbP_A(x)}
    &= \E_{\bbQ}\abs{\tsfrac{d \bar \bbP_A(x)}{d\bbQ(x)} - 1}
    \leq \sqrt{\E_{\bbQ}\abs{\tsfrac{d \bar \bbP_A(x)}{d\bbQ(x)} - 1}^2} \\
    &= \sqrt{\E_{\bbQ}\abs{\tsfrac{d \bar \bbP_A(x)}{d\bbQ(x)}}^2 + 1 - 2 \bar P_A(\cX)}
    = \sqrt{\E_{\bbQ}\abs{\tsfrac{d \bar \bbP_A(x)}{d\bbQ(x)}}^2 + 1 - 2 p}.
\end{align*}
Combining what we've shown, we conclude the first result, that
\[
D_{TV}(\bbQ, \bar \bbP) \leq \frac12 \sqrt{\E_{\bbQ} \left|\frac{d \bar \bbP_A(x)}{d\bbQ(x)}\right|^2 + 1 - 2 p} + \frac{1-p}{2}.
\]
Now, we move onto the second result.
Directly substituting our values for \(z\) and \(1+z\), we get
\begin{align*}
    D_{TV}(\bbQ, \bar \bbP)
    &\leq \frac12 \sqrt{1+z + 1 - 2 p} + \frac{1-p}{2} \\
    &= \frac12 \sqrt{z + 2(1-p)} + \frac{1-p}{2} \\
    &\leq \frac12 \sqrt{z + 2z} + \frac{z}{2} \\
    &\leq \frac{1}2 \sqrt{3z} + \frac{1}{2}\sqrt{z} \\
    &\leq \sqrt{3z}
\end{align*}
\end{proof}

We next import the results that \cite{simchowitz2017gap} used to bound \(\E_{\cZ_t\sim \bbQ}\left[\left(\frac{d\bar \bbP[\cZ_t;\cV_{\vu}^t]}{d\bbQ(\cZ_t)}\right)^2\right]\) and \(1-p = 1-\Pr[\cV_{\vu}^t] = \Pr[\exists i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau_i}{D}}]\).
Starting with \(1-p\), we import Theorem 5.3:





\begin{importedtheorem}[Theorem 5.3 from \cite{simchowitz2017gap}]
    \label{thm:simchowitz-iterative-chisquared-unrolled}
    Consider \Cref{setting:abstract-simchowitz}.
    Fix \(0 \leq \tau_1 \leq \ldots \leq \tau_t\).
    Let \(f(\tau)\) be the probability that the best possible blind guess for \(\vu\) using a vector in \(\cV^t\) achieves squared inner product at least \(\frac{\tau}D\):
    \[
		f(\tau) \defeq \sup_{(\vv^{(1)},\ldots,\vv^{(t)})\in\cV^t} \sup_{i\in[t]} \Pr[\langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau}{D}}].
    \]
    Then, \(\Pr[\exists i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau_i}{D}}]\) is at most
    \begin{align*}
        f(\tau_1) + 2\sum_{i=1}^t
        \E_{\vu\sim\cP}
        \left[\sqrt{
            f(\tau_i)
            \sup_{(\tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})\in\cV^t_{\vu}}
            \prod_{j=1}^i \E\left[ \left(\frac{d\bbP_{\vu}(\mA\tilde\vv^{(j)} | \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})}{d\bbQ(\mA\tilde\vv^{(j)} | \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})}\right)^2 
            \mid
            \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)}
            \right]
        } \right]
    \end{align*}
\end{importedtheorem}
This theorem exactly matches Theorem 5.3 from \cite{simchowitz2017gap} if we make two changes.
First, we do not yet apply the inequality (5.25) for reasons we will discuss momentarily.
Second, we change their set \(\cV_{\theta}^k\) into our set \(\cV_{\vu}^t\) in Lemma 5.2 so that we only consider queries that belong to \(\cV^t\) as opposed to arbitrary query vectors in \(\bbS^D\).
The proof of Lemma 5.2 does not change from this redefinition of \(\cV_{\vu}^t\).
Next, we must bound this big expectation that appears on the right hand side above.
In inequality (5.25), \cite{simchowitz2017gap} bounds this expectation under the assumption that \(\vv^{(1)},\ldots,\vv^{(t)}\) are orthonormal.
We cannot make this assumption, as an orthonormal basis for vectors in \(\cV^t\) might not belong to \(\cV^t\).
So, we rephrase Lemma C.3 from \cite{simchowitz2017gap}, making this orthonormality reduction explicit:
\begin{importedlemma}[Lemma C.3 from \cite{simchowitz2017gap}]
    \label{lem:orthonormal-chisquared-likelihood-ratio}
    Consider \Cref{thm:simchowitz-iterative-chisquared-unrolled}.
    Let \(\tilde\vx^{(1)},\ldots,\tilde\vx^{(t)}\) be orthonormal vectors such that \(\text{span}\{\tilde\vx^{(1)},\ldots,\tilde\vx^{(i)}\} = \text{span}\{\tilde\vv^{(1)},\ldots,\tilde\vv^{(i)}\}\) for all \(i\in[t]\).
    Then,
    \[
        \E\left[ \left(\frac{d\bbP_{\vu}(\mA\tilde\vv^{(j)} | \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})}{d\bbQ(\mA\tilde\vv^{(j)} | \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})}\right)^2 
        \mid
        \tilde\vv^{(1)},\ldots,\tilde\vv^{(t)}
        \right]
        \leq e^{\lambda^2 D\langle \vu, \tilde\vx^{(i)}\rangle^2}
    \]
\end{importedlemma}
\noindent
Applying this result to \Cref{thm:simchowitz-iterative-chisquared-unrolled}, we see that we need to upper bound the expression
\[
    \sup_{(\tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})\in\cV^t_{\vu}}
    e^{\lambda^2 D\langle \vu,\tilde\vx^{(i)}\rangle^2}
\]
Unfortunately, it is not immediately obvious how to relate \(\langle \vu,\tilde\vx^{(i)}\rangle\) to \(\tilde\vv^{(1)},\ldots\tilde\vv^{(i)}\) or \(\tau_1,\ldots,\tau_i\).
In the non-Kronecker case, when \(\cV^t\) covers all vectors in \(\bbS^D\), we can take \(\tilde\vx^{(i)}=\tilde\vv^{(i)}\) without loss of generality.
However, if \(\cV^t\) covers Kronecker-structured query vectors, then we do not know what the worst-case relationship between these terms is.
So, we make an assumption on \(\cV^t\) to proceed.
In particular, we assume that \(\cV^t\) is well conditioned.
\begin{lemma}
    \label{lem:conditioning-gives-p}
    Consider \Cref{thm:simchowitz-iterative-chisquared-unrolled}.
    Under the assumption that \(\cV^t\) is \(\kappa\)-conditioned, we know that
    \[
    \Pr[\exists i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau_i}{D}}]
        \leq
        f(\tau_1) + 2\sum_{i=1}^t
        e^{\frac{\lambda^2\kappa^2}{2}\kappa\sum_{j=1}^{i-1}\tau_j}
        \sqrt{f(\tau_i)}
    \]
\end{lemma}
\begin{proof}
From the definition of the conditioning of \(\cV^t\), we know that for all \((\tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})\in\cV_{\vu}^t\) that \(\tilde\mV \defeq \bmat{\tilde\vv^{(1)} & \cdots & \tilde\vv^{(t)}}\) has condition number at most \(\kappa\).
Therefore, by \Cref{lem:conditioning-to-ortho-inner-prod}, we know that \(\langle \vu, \tilde\vx^{(i)} \rangle^2 \leq \kappa^2 \sum_{j=1}^i \langle \vu,\tilde\vv^{(j)}\rangle^2\).
By our definition of \(\cV_{\vu}^t\), we further know that \(\langle \vu,\tilde\vv^{(j)}\rangle^2 \leq \frac{\tau_j}{D}\).
So, we get that
\[
    \sup_{(\tilde\vv^{(1)},\ldots,\tilde\vv^{(t)})\in\cV^t_{\vu}}
    e^{\frac{\lambda^2}{2} D\langle \vu,\tilde\vx^{(i)}\rangle^2}
    \sqrt{f(\tau_i)}
    \leq
    e^{\frac{\lambda^2}{2} \kappa^2 \sum_{j=1}^i \tau_j}
    \sqrt{f(\tau_i)}
\]
Overall, going back to \Cref{thm:simchowitz-iterative-chisquared-unrolled}, we find that
\[
     \Pr[\exists i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau_i}{D}}]
    \leq
    f(\tau_1) + 2\sum_{i=1}^t
    e^{\frac{\lambda^2\kappa^2}{2} \sum_{j=1}^i \tau_j}\sqrt{f(\tau_i)},
\]
completing the proof.
\end{proof}

This suffices to bound the term \(1-p\) in \Cref{lem:corrected-truncated-dtv}.
However, we still have do bound the expected squared likelihood ratio term.
Lemma C.3 from \cite{simchowitz2017gap} is analogous to \Cref{lem:orthonormal-chisquared-likelihood-ratio} but instead applies to this context:
\begin{importedlemma}[Lemma C.3 from \cite{simchowitz2017gap}]
    \label{lem:simchowitz-generic-chisquared-testing}
    Consider \Cref{thm:simchowitz-iterative-chisquared-unrolled}.
    Let \(\bar\bbP\) be the distribution of \(\cZ_t\) conditioned on \(i=1\) but not conditioned on a specific value of \(\vu\sim\cP\).
    Let \(\tilde\vx^{(1)},\ldots,\tilde\vx^{(t)}\) be orthonormal vectors such that \(\text{span}\{\tilde\vx^{(1)},\ldots,\tilde\vx^{(i)}\} = \text{span}\{\tilde\vv^{(1)},\ldots,\tilde\vv^{(i)}\}\) for all \(i\in[t]\).
    Then,
    \begin{align*}
        &\E_{\cZ_t\sim\bbQ} \left[ \left( \frac{d\bar\bbP[\cZ_t;\cV_{\vu}^t]}{d\bbQ(\cZ_t)} \right)^2 \right] \\
        &\leq
        \E_{\vu,\vu'\sim\cP}\left[
        \sup_{(\tilde\vv^{(1)},\ldots,\tilde\vv^{(t)}) \in \cV_{\vu}^t\cap\cV_{\vu'}^t}
        e^{D \lambda^2
            \sum_{i=1}^t
            \langle\tilde\vx^{(i)},\vu\rangle
            \langle\tilde\vx^{(i)},\vu'\rangle
            \left(
                \langle\vu,\vu'\rangle
                -
                \frac12
                \langle\tilde\vx^{(i)},\vu\rangle
                \langle\tilde\vx^{(i)},\vu'\rangle
                -
                \sum_{j=1}^{i-1}
                \langle\tilde\vx^{(j)},\vu\rangle
                \langle\tilde\vx^{(j)},\vu'\rangle
            \right)
        }\right]
    \end{align*}
\end{importedlemma}
Again, Lemma C.4 is not phrased exactly this way in \cite{simchowitz2017gap}.
This result follows from the proof of Lemma C.4 without substituting the final inequality on page 30.
In order to resolve the impact of orthonormality on this proof, we again appeal to conditioning:
\begin{lemma}
    \label{lem:conditioning-gives-chisquared-ratio}
    Consider \Cref{lem:simchowitz-generic-chisquared-testing}.
    Under the assumption that \(\cV^t\) is \(\kappa-\)conditioned, we know that
    \[
        \E_{\cZ_t\sim\bbQ} \left[\left(\frac{d\bar\bbP[\cZ_t;\cV_{\vu}^t]}{d\bbQ(\cZ_t)}\right)^2\right]
        \leq \E_{\vu,\vu'\sim\cP}\left[
            e^{
                \lambda^2 \kappa^2 \langle\tilde\vu,\vu'\rangle \sum_{i=1}^t \tau_i
                +
                \frac{\lambda^2 \kappa^4}{D} (\sum_{i=1}^t \tau_i)^2
        }\right]
    \]
\end{lemma}
\begin{proof}
    As in the proof of \Cref{lem:conditioning-gives-p}, we know that \(|\langle \tilde\vx^{(i)},\vu\rangle|\leq\kappa\frac{\sqrt{\tau_i}}{\sqrt{D}}\) and \(|\langle \tilde\vx^{(i)},\vu'\rangle|\leq\kappa\frac{\sqrt{\tau_i}}{\sqrt{D}}\).
    So, directly bounding the terms in \Cref{lem:simchowitz-generic-chisquared-testing},
    \begin{align*}
        &D\sum_{i=1}^t
        \langle\tilde\vx^{(i)},\vu\rangle
        \langle\tilde\vx^{(i)},\vu'\rangle
        \left(
            \langle\vu,\vu'\rangle
            -
            \frac12
            \langle\tilde\vx^{(i)},\vu\rangle
            \langle\tilde\vx^{(i)},\vu'\rangle
            -
            \sum_{j=1}^{i-1}
            \langle\tilde\vx^{(j)},\vu\rangle
            \langle\tilde\vx^{(j)},\vu'\rangle
        \right) \\
        &\leq
        D\sum_{i=1}^t
        \frac{\kappa^2 \tau_i}{D}
        \left(
            |\langle\vu,\vu'\rangle|
            +
            \frac{\kappa^2 \tau_i}{2D}
            +
            \sum_{j=1}^{i-1}
            \frac{\kappa^2 \tau_j}{D}
        \right) \\
        &\leq
        D\sum_{i=1}^t
        \frac{\kappa^2 \tau_i}{D}
        \left(
            |\langle\vu,\vu'\rangle|
            +
            \sum_{j=1}^{i}
            \frac{\kappa^2 \tau_j}{D}
        \right) \\
        &= \kappa^2 |\langle\vu,\vu'\rangle| \sum_{i=1}^t \tau_i 
        + \frac{\kappa^4}{D} \left(\sum_{i=1}^t \tau_i\right)^2
    \end{align*}
Which completes the proof by substituting this back into \Cref{lem:simchowitz-generic-chisquared-testing}:
\[
    \E_{\cZ_t\sim\bbQ} \left[ \left( \frac{d\bar\bbP[\cZ_t;\cV_{\vu}^t]}{d\bbQ(\cZ_t)} \right)^2 \right]
    \leq 
    \E_{\vu,\vu'\sim\cP}\left[
        e^{\lambda^2 \kappa^2 |\langle\vu,\vu'\rangle| \sum_{i=1}^t \tau_i 
        + \frac{\lambda^2 \kappa^4}{D} \left(\sum_{i=1}^t \tau_i\right)^2}\right]
\]
\end{proof}

We can now prove the overall lower bound \Cref{thm:abstract-simchowitz-requirements}.
\begin{proof}[Proof of \Cref{thm:abstract-simchowitz-requirements}]
We apply \Cref{lem:corrected-truncated-dtv} to the distribution \(\bar\bbP\) truncated to \(\cV_{\vu}^t\).
We get that
\[
    p
    = \bar\bbP[\cV_{\vu}^t]
    = \Pr_{\cZ_t\sim\bar\bbP}[\forall i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 \leq {\tsfrac{\tau_i}{D}}]
\]
so that
\[
    1-p
    = \Pr_{\cZ_t\sim\bar\bbP}[\exists i \in [t] ~:~ \langle \vv^{(i)}, \vu\rangle^2 > {\tsfrac{\tau_i}{D}}].
\]
By \Cref{lem:conditioning-gives-p}, we therefore know that
\[
    1-p
    \leq f(\tau_1) + 2\sum_{i=1}^t
        e^{\frac{\lambda^2\kappa^2}{2}\kappa\sum_{j=1}^{i-1}\tau_j}
        \sqrt{f(\tau_i)}
\]
which we are told is at most \(z\).
We similarly know by \Cref{lem:conditioning-gives-chisquared-ratio} that
\[
    \E_{\cZ_t\sim\bbQ} \left[\left(\frac{d\bar\bbP[\cZ_t;\cV_{\vu}^t]}{d\bbQ(\cZ_t)}\right)^2\right]
        \leq \E_{\vu,\vu'\sim\cP}\left[
            e^{
                \lambda^2 \kappa \langle\tilde\vu,\vu'\rangle \sum_{i=1}^t \tau_i
                +
                \frac{\lambda^2 \kappa^2}{D} (\sum_{i=1}^t \tau_i)^2
        }\right]
\]
we are told is at most \(1+z\).
So, by \Cref{lem:corrected-truncated-dtv}, we complete the proof.
\end{proof}

\subsection{Unrolling Lemma}

Partially unrelated to the above, we will also need to mildly generalize a technical result from \cite{simchowitz2017gap} that helps handle adaptivity when resolving the adaptive lower bound against L2 estimation.
The following is very similar to Lemma C.2 from \cite{simchowitz2017gap}:
\begin{lemma}[Unrolling Lemma]
    \label{lem:unrolling-lemma}
    Let \(\bbP_a\), \(\bbP_b\), and \(\bbC\) be distributions over a random variable \(\cZ_t = (z_1, \cdots, z_t)\) for some arbitrary sample space \(z_i \in \Omega\).
    Let \(\cZ_i = (z_1, \cdots, z_i)\) for all \(i\in[t]\).
    Let \(\{A^i\}_{i\in[t]}\) be a sequence of events such that \(A^i\) is deterministic in \(\cZ_{i}\) and such that \(A^i \subseteq A^{i-1}\).
    Let \(g_i(\cZ_{i-1})\) be the expected likelihood ratio between our three distributions at timestep \(i\) given \(\cZ_{i-1}\):
    \[
        g_i(\cZ_{i-1}) = \E\left[
            \frac{d\bbP_a(z_i \mid \cZ_{i-1}) d\bbP_b(z_i \mid \cZ_{i-1})}{(d\bbQ(z_i \mid \cZ_{i-1}))^2} \big| \cZ_{i-1}
        \right].
    \]
    Then,
    \[
        \E\left[
            \frac{d\bbP_a(\cZ_t) d\bbP_b(\cZ_t)}{(d\bbQ(\cZ_t))^2}
            \mathbbm1_{[A^{t-1}]}
        \right]
        \leq
        \sup_{\cZ_t\in A^{t-1}}
        \prod_{i=1}^t
        g_i(\cZ_{i-1}).
    \]
\end{lemma}
\begin{proof}
    We start by defining the tail set \(B^i(\cZ_i)\) as the set of all \(\tilde z_{i+1},\cdots, \tilde z_t\) such that \((z_1,\cdots,z_i,\tilde z_{i+1},\cdots,\tilde z_t) \in A^t\).
    We will also define
    \[
        G_i(\cZ_{i}) \defeq \sup_{\tilde\cZ_t\in B^i(\cZ_i)} \prod_{j=i+2}^t g_{j}(\tilde\cZ_{j-1}).
    \]
    Notice that \(G_0(\cZ_0) = \sup_{\cZ_t\in A^t} \prod_{i=2}^t g_i(\cZ_{i-1})\), and take \(G_{t-1}(\cZ_{t-1}) \defeq 1\).
    Further, notice that for any \(\cZ_{i-1}\) where the event \(A^{i-1}\) holds,
    \begin{align*}
        G_{i-1}(\cZ_{i-1}) g_i(\cZ_{i-1})
        \leq \sup_{\tilde\cZ_t\in B^{i-2}(\cZ_{i-2})} G_{i-1}(\tilde\cZ_{i-1}) g_i(\tilde\cZ_{i-1})
        = G_{i-2}(\cZ_{i-2}).
    \end{align*}
    Then, for any \(i\in[t]\), we use tower rule to expand
    \begin{align*}
        &\E\left[
            \frac{d\bbP_a(\cZ_i) d\bbP_b(\cZ_i)}{(d\bbQ(\cZ_i))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-1}(\cZ_{i-1})
        \right] \\
        &= \E\left[ \E\left[
            \frac{d\bbP_a(\cZ_i) d\bbP_b(\cZ_i)}{(d\bbQ(\cZ_i))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-1}(\cZ_{i-1})
        \mid \cZ_{i-1} \right]\right] \\
        &= \E\left[ \E\left[
            \frac{d\bbP_a(\cZ_i \mid \cZ_{i-1}) d\bbP_b(\cZ_i \mid \cZ_{i-1})}{(d\bbQ(\cZ_i \mid \cZ_{i-1}))^2}
            \frac{d\bbP_a(\cZ_{i-1}) d\bbP_b(\cZ_{i-1})}{(d\bbQ(\cZ_{i-1}))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-1}(\cZ_{i-1})
        \mid \cZ_{i-1} \right]\right] \\
        &= \E\left[
            \frac{d\bbP_a(\cZ_{i-1}) d\bbP_b(\cZ_{i-1})}{(d\bbQ(\cZ_{i-1}))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-1}(\cZ_{i-1})
            \E\left[
            \frac{d\bbP_a(\cZ_i \mid \cZ_{i-1}) d\bbP_b(\cZ_i \mid \cZ_{i-1})}{(d\bbQ(\cZ_i \mid \cZ_{i-1}))^2}
        \mid \cZ_{i-1} \right]\right] \\
        &= \E\left[
            \frac{d\bbP_a(\cZ_{i-1}) d\bbP_b(\cZ_{i-1})}{(d\bbQ(\cZ_{i-1}))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-1}(\cZ_{i-1})
            g_i(\cZ_{i-1}) \right] \\
        &\leq \E\left[
            \frac{d\bbP_a(\cZ_{i-1}) d\bbP_b(\cZ_{i-1})}{(d\bbQ(\cZ_{i-1}))^2}
            \mathbbm1_{[A^{i-1}]}
            G_{i-2}(\cZ_{i-2})\right] \\
        &\leq \E\left[
            \frac{d\bbP_a(\cZ_{i-1}) d\bbP_b(\cZ_{i-1})}{(d\bbQ(\cZ_{i-1}))^2}
            \mathbbm1_{[A^{i-2}]}
            G_{i-2}(\cZ_{i-2})\right]
    \end{align*}
So, by induction, we find that
\[
    \E\left[
        \frac{d\bbP_a(\cZ_t) d\bbP_b(\cZ_t)}{(d\bbQ(\cZ_t))^2}
        \mathbbm1_{[A^{t-1}]}
    \right]
    = \E\left[
        \frac{d\bbP_a(\cZ_t) d\bbP_b(\cZ_t)}{(d\bbQ(\cZ_t))^2}
        \mathbbm1_{[A^{t-1}]}
        G_{t-1}(\cZ_{t-1})
    \right]
    \leq \E\left[
        \frac{d\bbP_a(\cZ_1) d\bbP_b(\cZ_1)}{(d\bbQ(\cZ_1))^2}
        \mathbbm1_{[A^{0}]}
        G_{0}(\cZ_{0})
    \right].
\]
We take \(A^{0}\) to be the whole space, so \(\mathbbm1_{[A^{0}]}=1\).
Also, \(G_{0}(\cZ_{0}) = \sup_{\cZ_t\in A^t} \prod_{i=2}^t g_i(\cZ_{i-1})\).
So, we find
\[
    \E\left[
        \frac{d\bbP_a(\cZ_t) d\bbP_b(\cZ_t)}{(d\bbQ(\cZ_t))^2}
        \mathbbm1_{[A^{t-1}]}
    \right]
    \leq 
    \left(\sup_{\cZ_t\in A^t} \prod_{i=2}^t g_i(\cZ_{i-1})\right)
    \E\left[\frac{d\bbP_a(\cZ_1) d\bbP_b(\cZ_1)}{(d\bbQ(\cZ_1))^2}\right]
    = \left(\sup_{\cZ_t\in A^t} \prod_{i=1}^t g_i(\cZ_{i-1})\right),
\]
completing the proof.
\end{proof}



