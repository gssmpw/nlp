@article{Bai2024DigiRLTI,
  title={DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning},
  author={Hao Bai and Yifei Zhou and Mert Cemri and Jiayi Pan and Alane Suhr and Sergey Levine and Aviral Kumar},
  journal={ArXiv},
  year={2024},
  volume={abs/2406.11896},
  url={https://api.semanticscholar.org/CorpusID:270562229}
}

@inproceedings{Cheng2024SeeClickHG,
  title={SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents},
  author={Kanzhi Cheng and Qiushi Sun and Yougang Chu and Fangzhi Xu and Yantao Li and Jianbing Zhang and Zhiyong Wu},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:267069082}
}

@article{Hong2023CogAgentAV,
  title={CogAgent: A Visual Language Model for GUI Agents},
  author={Wenyi Hong and Weihan Wang and Qingsong Lv and Jiazheng Xu and Wenmeng Yu and Junhui Ji and Yan Wang and Zihan Wang and Yuxuan Zhang and Juan-Zi Li and Bin Xu and Yuxiao Dong and Ming Ding and Jie Tang},
  journal={ArXiv},
  year={2023},
  volume={abs/2312.08914},
  url={https://api.semanticscholar.org/CorpusID:273102270}
}

@article{Liu2024VisualWebBenchHF,
  title={VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?},
  author={Junpeng Liu and Yifan Song and Bill Yuchen Lin and Wai Lam and Graham Neubig and Yuanzhi Li and Xiang Yue},
  journal={ArXiv},
  year={2024},
  volume={abs/2404.05955},
  url={https://api.semanticscholar.org/CorpusID:269009925}
}

@article{OmniParser,
  author    = {Yadong Lu and Jianwei Yang and Yelong Shen and Ahmed Awadallah},
  title     = {OmniParser},
  journal   = {arXiv preprint arXiv:2408.00203},
  year      = {2024},
  archivePrefix = {arXiv},
  eprint    = {2408.00203},
  primaryClass = {cs.CV}
}

@article{Xie2024OSWorldBM,
  title={OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
  author={Tianbao Xie and Danyang Zhang and Jixuan Chen and Xiaochuan Li and Siheng Zhao and Ruisheng Cao and Toh Jing Hua and Zhoujun Cheng and Dongchan Shin and Fangyu Lei and Yitao Liu and Yiheng Xu and Shuyan Zhou and Silvio Savarese and Caiming Xiong and Victor Zhong and Tao Yu},
  journal={ArXiv},
  year={2024},
  volume={abs/2404.07972},
  url={https://api.semanticscholar.org/CorpusID:269042918}
}

@article{Yan2023GPT4VIW,
  title={GPT-4V in Wonderland: Large Multimodal Models for Zero-Shot Smartphone GUI Navigation},
  author={An Yan and Zhengyuan Yang and Wanrong Zhu and Kevin Qinghong Lin and Linjie Li and Jianfeng Wang and Jianwei Yang and Yiwu Zhong and Julian J. McAuley and Jianfeng Gao and Zicheng Liu and Lijuan Wang},
  journal={ArXiv},
  year={2023},
  volume={abs/2311.07562},
  url={https://api.semanticscholar.org/CorpusID:265149992}
}

@inproceedings{You2024FerretUIGM,
  title={Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs},
  author={Keen You and Haotian Zhang and Eldon Schoop and Floris Weers and Amanda Swearngin and Jeffrey Nichols and Yinfei Yang and Zhe Gan},
  booktitle={European Conference on Computer Vision},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:269005503}
}

@article{blip2,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@misc{fan2024readpointedlayoutawaregui,
      title={Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding}, 
      author={Yue Fan and Lei Ding and Ching-Chen Kuo and Shan Jiang and Yang Zhao and Xinze Guan and Jie Yang and Yi Zhang and Xin Eric Wang},
      year={2024},
      eprint={2406.19263},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19263}, 
}

@software{yolov8_ultralytics,
  author = {Glenn Jocher and Ayush Chaurasia and Jing Qiu},
  title = {Ultralytics YOLOv8},
  version = {8.0.0},
  year = {2023},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}

@article{zheng2023seeact,
    title={GPT-4V(ision) is a Generalist Web Agent, if Grounded},
    author={Boyuan Zheng and Boyu Gou and Jihyung Kil and Huan Sun and Yu Su},
    journal={arXiv preprint arXiv:2401.01614},
    year={2024},
}

