\section{Related Works}
\subsubsection{Structured Pruning}
\label{sec:structured}
MPF____ considers the geometric distance between filters and neighboring filters to guide the pruning process. CPMC____ leverages relationships between filters in the current layer and subsequent layers for pruning decisions. HRank____ compresses models by constructing low-rank matrices using information from the same batch. Scop____ reduces filters based on their deviation from the expected network behavior. 
GDP____ employs gates with differentiable polarization, learning whether gates are zero during training for pruning purposes. EEMC____ uses a multivariate Bernoulli distribution along with stochastic gradient Hamiltonian Monte Carlo for pruning. SRR-GR____ identifies redundant structures within CNNs. FTWT____ predicts pruning strategies using a self-supervised mask. DECORE____ assigns an agent to each filter and uses lightweight learning to decide whether to keep or discard each filter. EPruner____ employs Affinity Propagation for efficient pruning. DPFPS____ directly learns the network with structural sparsity for pruning. CC____ combines tensor decomposition for filter pruning. NPPM____ trains the network to predict the performance of the pruned model, guiding the pruning process. LRF-60____ uses Linearly Replaceable Filters to aid pruning decisions. AutoBot____ tests each filter one-by-one to ensure pruning precision. 
PGMPF____ utilizes prior masks as the basis for pruning masks. DLRFC____ uses Receptive Field Criterion to measure filter importance. FSM____ aggregates feature and filter information to evaluate their relevance for shifting. Rrandom____ employs random search strategies for pruning.  The study ____ employs activation statistics, foundations in information theory, and statistical analysis with designed regularizations for pruning. CSD____ uses channel spatial dependability metric and leverages feature characteristics for pruning. However, the statistical learning information considered by these methods may not be precise enough.



\subsubsection{Information Bottleneck and Lasso Principle}

The Information Bottleneck (IB)____ method extracts the most relevant output information by considering the input. Aside from the previous mentioned methods, the works____ were the first to use IB for compressing CNNs. FPGM____ employs the geometric median for pruning. L1____ illustrates the correspondence between Lasso and IB for pruning. The approach in____ utilizes a two-step optimization process incorporating Lasso for pruning. Papers____ leverage the $l_2$ lasso (e.g., group lasso) for pruning, with analyzed complexity____. APIB____ integrates IB with the Hilbert-Schmidt Independence Criterion Lasso for exploration. The paper____ also shows through analysis that layer-level pruning, based on the Hilbert-Schmidt independence criterion, is preferable to end-to-end pruning.

However, none of these methods account for class-wise information. To address this, from the information bottleneck perspective, we employ state-of-the-art techniques like graph-structured lasso____ and tree-guided lasso____ to aggregate class-wise information effectively to propose our novel methods and prune filters inside CNNs.
% Dorador2024TheoreticalAE foreset