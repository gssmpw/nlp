\section{Related Work}
\subsection{Multi-Hop Reasoning in LLMs}
Improving the reasoning ability of LLMs has become a key focus of recent research ____. ____ use chain-of-thought to enhance the reasoning ability by articulating intermediate steps. ____ propose complexity-based prompting, showing that selecting and generating reasoning chains with higher complexity significantly improves reasoning accuracy. ____ combine chain-of-thought with the self-consistency decoding strategy, achieving significant improvements by sampling diverse reasoning paths and selecting the most consistent answer. ____ propose self-play fine-tuning, which enhances LLMs' reasoning abilities by refining their outputs through self-generated data, thereby reducing reliance on human-annotated datasets. ____ propose scaling inference compute by increasing the number of generated samples, demonstrating significant improvements across tasks like coding and math. ____ use tree-based methods to improve the performance.

\subsection{Mechanistic Interpretability}
Mechanistic interpretability ____ aims to reverse engineer the internal mechanisms of LLMs. Logit lens ____ is a widely used method ____ to analyze the information of hidden states, by multiplying the vectors with the unembedding matrix. A commonly used localization method is causal mediation analysis ____, whose core idea is to compute the change of the output when modifying a hidden state. Another types of studies focus on constructing the circuit in the model ____. Due to the superposition phenomenon ____, sparse auto-encoder (SAE) is useful for interpreting the features ____. A useful characteristic is the residual stream ____, revealing that the final embedding can be represented as the sum of layer outputs. Furthermore, ____ find that the FFN output is the weighted sum of FFN neurons. ____ find that the attention head outputs can also be regarded as the weighted sum of attention neurons. 

While previous neuron-level studies primarily focus on ``localization''—identifying which neurons are important—they often lack a deeper ``analysis'' of how these neurons influence predictions. By applying our logit flow method, we gain a clearer understanding of how neurons are activated and contribute to the final prediction.