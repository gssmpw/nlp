\documentclass[11pt]{iopart}
\expandafter\let\csname equation*\endcsname\relax
\expandafter\let\csname endequation*\endcsname\relax
\usepackage{times,amsmath,amssymb,graphicx,cite,multirow,color,subfigure,booktabs}
\usepackage[lined,ruled,boxed]{algorithm2e}


\begin{document}
\title{Revisiting Euclidean Alignment for Transfer Learning in EEG-Based Brain-Computer Interfaces}

\author{Dongrui~Wu$^{1,2,*}$}
\address{$^1$ Ministry of Education Key Laboratory of Image Processing and Intelligent Control, Huazhong University of Science and Technology, Wuhan, 430074 China}
\address{$^2$ Hubei Key Laboratory of Brain-inspired Intelligent Systems, Huazhong University of Science and Technology, Wuhan, 430074, China.}
\address{$^*$ Author to whom any correspondence should be addressed.}
\ead{drwu09@gmail.com.}

\maketitle


\begin{abstract}
Due to the non-stationarity and large individual differences of EEG signals, EEG-based brain-computer interfaces (BCIs) usually need subject-specific calibration to tailor the decoding algorithm for each new subject, which is time-consuming and user-unfriendly, hindering their real-world applications. Transfer learning (TL) has been extensively used to expedite the calibration, by making use of EEG data from other subjects/sessions. An important consideration in TL for EEG-based BCIs is to reduce the data distribution discrepancies among different subjects/session, to avoid negative transfer. Euclidean alignment (EA) was proposed in 2020 to address this challenge. Numerous experiments from 10 different BCI paradigms demonstrated its effectiveness and efficiency. This paper revisits the EA, explaining its procedure and correct usage, introducing its applications and extensions, and pointing out potential new research directions. It should be very helpful to BCI researchers, especially those who are working on EEG signal decoding.
\end{abstract}

\noindent{\it Keywords}: Brain-computer interface, EEG, Euclidean alignment, label alignment, transfer learning


\section{Introduction}

Brain-computer interfaces (BCIs) enable direct communication between the brain and external devices, which can be used in text input \cite{Nakanishi2020}, device control \cite{Leeb2007}, neuro-rehabilitation \cite{Mane2020}, emotion recognition and regularization \cite{drwuPIEEE2023}, speech decoding \cite{Moses2021}, restoring walking abilities \cite{Lorach2023}, etc. It is an important component of Brain Initiatives/Projects all over the world, particularly China \cite{Liu2023} and the IEEE\footnote{https://brain.ieee.org/}. It was selected by Nature as one of seven technologies to watch in 2024 \cite{Eisenstein2024}, and again one of eight technology events to watch for in 2025 \cite{Naddaf2025}, and also selected by IEEE Computer Society in 2025 as one of ``\emph{22 breakthrough technologies set to redefine industries and shape the future of our world for decades to come}" \cite{Milojicic2025}.

According to the input signals, BCIs can be broadly classified into invasive ones and non-invasive ones. The former use surgery to implant electrodes into the brain, which are mainly used for patients. Non-invasive BCIs do not need surgery, and hence are more convenient and preferred by able-bodied users. EEG is the most frequently used input signal for non-invasive BCIs.

EEG signals are non-stationary, e.g., the same subject may have different EEG responses to the same stimulus in different sessions, and exhibit significant individual differences, i.e., different subjects have significantly different EEG responses to the same stimulus. As a result, it is very challenging, if not impossible, to design an EEG-based non-invasive BCI system that is plug-and-play and fits all subjects. Usually, for each new subject, we need to collect some subject-specific calibration data to tailor the parameters of the decoding algorithm, which is time-consuming and user-unfriendly.

Transfer learning (TL), which utilizes data/knowledge from other subjects (sessions) to facilitate the calibration for a new subject (session), has been extensively used in EEG-based BCIs to expedite the calibration \cite{drwuTLBCI2022}. An important consideration in TL is how to reduce the data distribution discrepancies among different subjects (sessions) to avoid negative transfer \cite{drwuNTL2023}.

Euclidean Alignment (EA) \cite{drwuEA2020} was proposed in 2020 to address this challenge. It uses two simple, efficient and closed-form formulas to align the raw EEG trials from different subjects/sessions, greatly facilitating TL \cite{drwuMITLBCI2022}. It has been cited 261 times in WoS and 373 times in Google Scholar (as of 2/9/2025), ranking 2/344 of all papers published in IEEE Transactions on Biomedical Engineering\footnote{https://webofscience.clarivate.cn/wos/alldb/summary/fd21b6a6-bdf1-4dcd-bae6-45d4041b195f-014738bfd9/times-cited-descending/1} (TMBE) in 2020, and 3/1810 of all papers published in IEEE TBME\footnote{https://webofscience.clarivate.cn/wos/alldb/summary/5e219ca8-1532-4637-a27d-6c70f9cbbca2-014738a148/times-cited-descending/1} between 2020 and 2025. It was one of the only two Highly Cited Papers of IEEE TBME in 2020. It was also the number one contributor to the 2022 impact factor (4.6) of IEEE TBME\footnote{https://jcr.clarivate.com/jcr-jp/journal-profile?journal=IEEE\%20T\%20BIO-MED\%20ENG\&year=2022\&fromPage=\%2Fjcr\%2Fhome}, among all 695 citable items published in 2020 and 2021.

EA has achieved remarkable performance in BCI competitions. By integrating it into our TL algorithms, the author's team won nine National Championships in China BCI Competition (the most prestigious BCI competition in China, organized jointly by the National Natural Science Foundation of China, Chinese Institute of Electronics, and Tsinghua University) between 2019 and 2024. In the Benchmarks for EEG Transfer Learning\footnote{https://beetl.ai/challenge} (BEETL) competition organized at NeurIPS 2021, the champion team's approach \cite{Wei2022} ``\emph{for improving subject-independence is to align the latent feature distributions of the deep learning models between different subjects and sessions. This is similar to the Euclidean Alignment method, which performs spatial whitening with the average covariance matrix per subject, although the methods are not constrained to be applied on the model input.}" In the runner-up's approach \cite{Wei2022}, ``\emph{Euclidean Alignment is used to close the gap between subjects in source domains and target domain. All trials of each subject are aligned such that the mean covariance matrices of all subjects are equal to the identity matrix after alignment. After alignment, data set distribution in both source domains and target domain are more similar.}"

After five years of the publication of the EA paper \cite{drwuEA2020}, we now have deeper and more comprehensive understanding on how to properly use EA. Its applicable BCI paradigms have also been greatly expanded. This paper revisits the EA approach, explaining its procedure and correct usage, introducing its applications and extensions, and pointing out potential new research directions. It should be very helpful to BCI researchers, especially those who are working on EEG signal decoding.

The remainder of this paper is organized as follows: Section~\ref{sect:EA} introduces the procedure, correct usage, and applications of EA. Section~\ref{sect:ext} introduces an extension of EA. Section~\ref{sect:future} points out potential future research directions. Finally, Section~\ref{sect:conclusions} draws conclusions.


\section{Euclidean Alignment (EA)} \label{sect:EA}

This section introduces the EA approach \cite{drwuEA2020}. It was inspired by Riemannian Alignment \cite{Zanini2018} proposed in 2018 in IEEE TBME, which has been cited 258 times in WoS and 370 times in Google Scholar (as of 2/9/2025) and is one of the five Highly Cited Papers of IEEE TBME in 2018.

\subsection{The EA Algorithm}

The goal of EA is to make EEG data distributions from different subjects (sessions) more consistent (i.e., to reduce the inter-subject/session discrepancies), facilitating TL. In fact, after EA, often the EEG data from auxiliary subjects/sessions (called source domains in TL) can be combined directly with the limited amount of calibration data from the new subject/session (called target domain in TL) to train a classifier; the performance is usually quite good even without incorporating any other sophisticated TL techniques.

Fig.~\ref{fig:EALA} illustrates the flowchart of EA, using only one source domain. Most materials in this subsection are adapted from \cite{drwuEA2020}.

\begin{figure}[htpb]\centering
\includegraphics[width=.8\linewidth,clip]{EALA.eps}
\caption{Illustration of EA and LA. } \label{fig:EALA}
\end{figure}

Assume a domain (either source or target; different domains are processed identically) has $N$ EEG trials $\{X_n\}_{n=1}^N$, where $X_n\in \mathbb{R}^{c\times t}$, in which $c$ is the number of EEG channels, and $t$ the number of time-domain sampling points. EA first computes the symmetric and semi positive-definite reference matrix $\bar{R}\in\mathbb{R}^{c\times c}$ as
\begin{align}
  \bar{R}=\frac{1}{N}\sum_{n=1}^N X_nX_n^\top, \label{eq:R}
\end{align}
i.e., $\bar{R}$ is the arithmetic mean of all $N$ covariance matrices from that domain. It then performs the alignment by
\begin{align}
  \tilde{X}_n=\bar{R}^{-1/2}X_n,\quad n=1,...,N. \label{eq:EA}
\end{align}
After EA, the mean covariance matrix of all $N$ aligned trials, $\{\tilde{X}_n\}_{n=1}^N$, becomes:
\begin{align}
\frac{1}{N}\sum_{n=1}^N\tilde{X}_n\tilde{X}_n^\top  &=\frac{1}{N}\sum_{n=1}^N\bar{R}^{-1/2}X_nX_n^\top\bar{R}^{-1/2}\nonumber \\
&=\bar{R}^{-1/2}\left(\frac{1}{N}\sum_{n=1}^N X_nX_n^\top\right)\bar{R}^{-1/2}\nonumber\\
&=\bar{R}^{-1/2}\bar{R}\bar{R}^{-1/2}=I, \label{eq:meanC}
\end{align}
i.e., the mean covariance matrix of each domain equals the identity matrix after EA, and hence the EEG data distributions from different domains become more consistent.

EA has the following desirable characteristics \cite{drwuEA2020}:
\begin{enumerate}
\item \emph{Flexible}: It transforms and aligns the EEG trials in the Euclidean space, so any Euclidean space signal processing, feature extraction and machine learning algorithms (most algorithms in the literature belong to the Euclidean space) can then be subsequently applied to them.
\item \emph{Efficient}: It includes only two simple closed-form formulas, which can be computed very fast.
\item \emph{Unsupervised}: It does not need any label information from any domain, so it has much broader applications than supervised algorithms.
\end{enumerate}

\subsection{Where to Place EA in the BCI TL Pipeline}

As proposed in our previous research \cite{drwuMITLBCI2022}, EA should be placed between the temporal filtering block and the spatial filtering block. This subsection performs experiments to demonstrate that this placement indeed leads to better performance.

\begin{figure}[htpb]\centering
\includegraphics[width=.7\linewidth,clip]{TL.eps}
\caption{The optimal location to place EA in the BCI TL pipeline.} \label{fig:TL}
\end{figure}

We used the motor imagery Dataset 1 from BCI Competition IV\footnote{http://www.bbci.de/competition/iv/desc\_1.html.} in our experiment, which was also extensively used in our previous research \cite{drwuEA2020,drwuLA2020,drwuMITLBCI2022}. It was recorded from seven healthy subjects using 59 EEG channels at 1000 Hz, and later downsampled to 100 Hz. Each subject performed two classes of motor imagery tasks (100 trials per class) in the calibration session, selected from three options: left hand, right hand, and both feet. Only data from Subjects 2, 3, 4, 5 and 7 were used, as their imagined classes were consistent (left hand and right hand). As in \cite{drwuEA2020}, each trial consisted of EEG data between $[0.5, 3.5]$ seconds after the cue appearance, i.e., each trial was a matrix with dimensionality $59\times 300$.

We performed leave-one-subject-out cross-validation in TL: each time, we picked one subject as the test subject (target domain), and combined all trials from the remaining four subjects as the auxiliary data (source domain). The goal was to facilitate the classifier training for the target subject using the source data. The number of labeled calibration trials in the target domain, $M$, increased from 0 to 20, with step size 4. The $M$ trials were randomly selected in a continuous block, to avoid the block-design pitfall in BCIs \cite{Li2021b}. The performance of different approaches was evaluated using the classification accuracy on the remaining $100-M$ target domain samples. The experiments were repeated 30 times to cope with randomness.

We compared three different EA placements, using the best-performing TL pipeline in \cite{drwuMITLBCI2022}:
\begin{enumerate}
\item No EA, as shown in Fig.~\ref{fig:TL1}.

\begin{figure}[htpb] \centering
\subfigure[]{\label{fig:TL1} \includegraphics[width=.6\linewidth,clip]{TL1}}
\subfigure[]{\label{fig:TL2} \includegraphics[width=.75\linewidth,clip]{TL2}}
\caption{Different configurations of the TL pipeline for motor imagery based BCIs. (a) No EA; (b) placement of EA after both temporal filtering and spatial filtering.}
\end{figure}

More specifically, we performed [8,30] Hz band-pass temporal filtering (TF) for each subject's EEGs, epoched them into 3-second trials, combined the (unaligned) trials from all four source subjects as a single source domain, performed regularized common spatial pattern (RCSP) filtering \cite{Lu2010}, extracted the corresponding log-variance features, and finally used weighted adaptation regularization (wAR) \cite{drwuTHMS2017} for classification. This approach is denoted as TF-RCSP-wAR in our analysis.

The above TL pipeline did not re-reference the EEG channels. We also investigated if performing average re-referencing (AR) after temporal filtering can further improve the TL performance. This approach is denoted as TF-AR-RCSP-wAR.

\item The recommended placement, between temporal filtering and spatial filtering, as shown in Fig.~\ref{fig:TL}.

More specifically, we performed [8,30] Hz band-pass temporal filtering for each subject's EEGs, epoched them into 3-second trials, performed EA for each subject individually, combined aligned trials from all four source subjects as a single source domain, performed RCSP filtering \cite{Lu2010}, extracted the corresponding log-variance features, and finally used wAR \cite{drwuTHMS2017} for classification. This approach is denoted as TF-EA-RCSP-wAR in our analysis.

The above TL pipeline did not re-reference the EEG channels. We also evaluated another slightly modified pipeline that performed AR immediately after temporal filtering, which is denoted as TF-AR-EA-RCSP-wAR.

\item Placing EA after both temporal filtering and spatial filtering, as shown in Fig.~\ref{fig:TL2}.

More specifically, we performed [8,30] Hz band-pass temporal filtering for each subject's EEGs, epoched them into 3-second trials, combined (unaligned) trials from all four source subjects as a single source domain, performed RCSP filtering \cite{Lu2010}, performed EA for each subject individually, extracted the log-variance features, and finally used wAR \cite{drwuTHMS2017} for classification. This approach is denoted as TF-RCSP-EA-wAR in our analysis.

Again, the above TL pipeline did not re-reference the EEG channels. We also evaluated another slightly modified pipeline that performed AR immediately after temporal filtering, which is denoted as TF-AR-RCSP-EA-wAR.
\end{enumerate}


Fig.~\ref{fig:TLresults} shows the TL performance of the six pipelines, averaged over 30 repeated runs. The last subfigure shows the TL performance, further averaged across the five subjects. We can observe that:

\begin{figure}[htpb] \centering
\includegraphics[width=\linewidth,clip]{TLresults}
\caption{The motor imagery classification performance of six different TL pipelines.} \label{fig:TLresults}
\end{figure}

\begin{enumerate}
\item Performing EA, not matter whether it was between temporal filtering and spatial filtering, or after both temporal filtering and spatial filtering, always improved the TL performance, i.e., TF-EA-RCSP-wAR and TF-RCSP-EA-wAR always outperformed TF-RCSP-wAR, and TF-AR-EA-RCSP-wAR and TF-AR-RCSP-EA-wAR always outperformed TF-AR-RCSP-wAR. This is because EA always reduces the data distribution discrepancies among the subjects, no matte where it is placed, and reducing these discrepancies always benefit TL.

\item Performing EA between temporal filtering and spatial filtering almost always achieved better performance than performing EA after both temporal filtering and spatial filtering, i.e., on average TF-EA-RCSP-wAR outperformed TF-RCSP-EA-wAR, and TF-AR-EA-RCSP-wAR outperformed TF-AR-RCSP-EA-wAR. This suggests that EA should enter the TL pipeline early to achieve maximum benefits.

\item Performing average re-referencing often led to performance improvement, i.e., TF-AR-RCSP-wAR outperformed TF-RCSP-wAR for four of the five subjects and on average, TF-AR-EA-RCSP-wAR slightly outperformed TF-EA-RCSP-wAR on average, and TF-AR-RCSP-EA-wAR always outperformed TF-RCSP-EA-wAR. This is because average referencing helps reduce the magnitude differences between EEGs from different subjects.
\end{enumerate}
In summary, we confirmed through experiments that EA should be placed between temporal filtering and spatial filtering in motor imagery based BCIs, as in Fig.~\ref{fig:TL}, for maximum benefits; and, performing average referencing immediately after temporal filtering could further improve the performance.


\subsection{Applications of EA}

In the original paper \cite{drwuEA2020}, the effectiveness of EA was only demonstrated in two classic BCI paradigms, motor imagery and P300 visual evoked potentials, using traditional classifiers. In the past five years, researchers from all over the world have applied it to eight additional BCI paradigms, including mental imagery, rapid series visual presentation (RSVP), error-related negativity, sleep stage classification, stress detection, emotion recognition, motor execution, and seizure detection, using both traditional classifiers and deep neural networks, all achieving performance improvements, as summarized in Table~\ref{tab:EA}. These 10 BCI paradigms cover almost all non-invasive BCI applications, i.e., EA has very broad applicability.

\begin{table*}[htbp]\centering \scriptsize \setlength{\tabcolsep}{2mm}
\caption{Performance improved by EA in 10 different BCI paradigms.} \label{tab:EA}
\begin{tabular}{c|c|c|c|c|c}
\toprule
\multirow{2.5}{*}{BCI Paradigm} & \multirow{2.5}{*}{Classifier}& \multicolumn{3}{c|}{Accuracy (\%)} & \multirow{2.5}{*}{Reference}\\ \cmidrule(lr){3-5}
& & without EA & with EA & Improvement & \\ \midrule
\multirow{39}{*}{Motor Imagery}
& CSP-LDA & 59.71 & 79.79 & \textbf{20.08} & He and Wu, IEEE TBME 2020 \cite{drwuEA2020} \\
& CSP-LDA & 51.10  & 64.01  & \textbf{12.91} & He and Wu, IEEE TNSRE 2020 \cite{drwuLA2020} \\
& TS-SVM & 56.65 & 64.32 & \textbf{7.67} & He and Wu, IEEE TNSRE 2020 \cite{drwuLA2020} \\
& TIDNet & 61.53 & 70.44 & \textbf{8.91} & Kostas and Rudzicz, JNE 2020 \cite{Kostas2020} \\
& CSP-LDA & 63.73 & 76.66 & \textbf{12.93} & Zhang and Wu, IEEE TNSRE 2020 \cite{drwuMEKT2020}\\
& EEGInception & 63.72 & 72.44 & \textbf{8.72} & Bakas et al., NeurIPS 2021 \cite{Bakas2021NIPS} \\
& CSP-LDA & 67.59 & 73.77 & \textbf{6.18} & Zhang et al., CMPB 2021 \cite{Zhang2021CMPB} \\
& CSP-LDA & 67.75 & 73.53 & \textbf{5.78} & Liang et al., IROS 2021 \cite{Liang2021IROS} \\
& CSP-SVM & 71.08 & 75.17 & \textbf{4.09} & Togha et al., BSPC 2021 \cite{Togha2021BSPC}  \\
& AdaBN & 66.40 & 73.80 & \textbf{7.40} & Xu et al., JNE 2021 \cite{Xu2021JNE} \\
& CSP-SVM & 65.78 & 75.56 & \textbf{9.78} & Demsy et al., IEEE SMC 2021 \cite{Demsy2021SMC} \\
& TCA-W & 68.39 & 74.89 & \textbf{6.50} & Demsy, et al., IEEE SMC 2021 \cite{Demsy2021SMC} \\
& CSP-LDA & 68.40 & 73.60 & \textbf{5.20} & Peterson et al., IEEE TBME 2021 \cite{Peterson2021TBME}  \\
& EEGNet & 63.20 & 69.61 & \textbf{6.41} & Wu et al., NN 2022 \cite{drwuTLBCI2022} \\
& ShallowCNN & 65.90 & 74.50 & \textbf{8.60} & Wu et al., NN 2022 \cite{drwuTLBCI2022} \\
& CSP-LDA & 63.73 & 76.66 & \textbf{12.93} & Cai et al., JNM 2022 \cite{Cai2022JNM}  \\
& CSP-LDA & 63.00 & 70.00 & \textbf{7.00} & Chen et al., JNUNS 2022 \cite{Chen2022JNUNS}  \\
& NeuCube & 69.98 & 75.36 & \textbf{5.38} & Wu et al., NeuroComp. 2023 \cite{Wu2023NeuroCom} \\
& EA-IISCSP & 79.75 & 81.93 & \textbf{2.18} & Wei and Ding, IEEE TNSRE 2023 \cite{Wei2023TNSRE} \\
& RAVE & 79.20 & 82.90 & \textbf{3.70} & Pan et al., JNE 2023 \cite{Pan2023JNE} \\
& CSP-LDA & 42.09 & 52.55 & \textbf{10.46} & Zhu et al., IEEE TIM 2023 \cite{Zhu2023TIM} \\
& DSTL & 67.50 & 80.00 & \textbf{12.50} & Gao et al., IEEE TNSRE 2023 \cite{Gao2023TNSRE}  \\
& MEIS & 59.11 & 66.91 & \textbf{7.80} & Liang et al., BSPC 2024 \cite{Liang2024BSPC}  \\
& TLA-ACTL & 65.68 & 73.53 & \textbf{7.85} & Xu et al., BSPC 2024 \cite{Liang2024BSPC}  \\
& TSL-SRT & 64.57 & 74.43 & \textbf{9.86} & Gao et al., CN 2024 \cite{Gao2024CogNeuro}   \\
& CSP-LDA & 75.36 & 81.54 & \textbf{6.18} & Wang et al., KBS 2025 \cite{drwuTFT2025} \\
& EEGNet & 43.80 & 48.90 & \textbf{5.10} & Bakas et al., JNE 2025 \cite{Bakas2025JNE} \\
& FBCSP & 52.62 & 79.98 & \textbf{27.36} & Amorim et al., BRACIS 2024 \cite{Amorim2024BRACIS} \\
& EEGNet & 59.70 & 65.20 & \textbf{5.50} & Li et al., ArXiv 2025 \cite{Li2024spdim} \\
& TSMNet & 60.00 & 65.30 & \textbf{5.30} & Li et al., ArXiv 2025 \cite{Li2024spdim} \\
& TCNet & 74.38 & 77.70 & \textbf{3.32} & Wang et al., IEEE TBME 2025 \cite{Wang2024TBME}  \\
& EEGNet & 69.70 & 72.10 & \textbf{2.40} & Wang et al., IEEE JBHI 2025 \cite{Wang2024JBHI} \\
& CSP-LDA & 54.31 & 65.75 & \textbf{11.44} & Zhang et al., IEEE TIM 2024 \cite{Zhang2024TIM}  \\
& FRCN & 57.64 & 70.41 & \textbf{12.77} & Xu et al., IEEE TIM 2024 \cite{Xu2024TIM}  \\
& CSP-LDA & 57.55 & 67.06 & \textbf{9.51} & Zhu et al., RSI 2024 \cite{Zhu2024RSI} \\
& CSP-LDA & 64.39 & 75.92 & \textbf{11.53} & Gao et al., NeuroComp. 2024 \cite{Gao2025NeuroCom}  \\
& CSP-LDA & 67.45 & 71.44 & \textbf{3.99} & Jin et al., JNE 2024 \cite{Jin2024JNE}\\
& SSCL-CSD & 64.15 & 67.32 & \textbf{3.17} & Li et al., JNE 2024 \cite{Li2024JNE} \\ \midrule
Mental Imagery & MDM & 56.02 & 66.08 & \textbf{10.06} & Kumar et al., BCI 2019 \cite{Kumar2019BCI}  \\ \midrule
Event-Related Potential & xDAWN-SVM & 64.60 & 68.80 & \textbf{4.20} & He and Wu, IEEE TBME 2020 \cite{drwuEA2020} \\ \midrule
RSVP & CSP-LDA & 65.36 & 69.07 & \textbf{3.71} & \multirow{2}{*}{Zhang and Wu, IEEE TNSRE 2020 \cite{drwuMEKT2020}} \\ \cline{1-5}
Error-Related Negativity & CSP-LDA & 61.87 & 64.63 & \textbf{2.76} & \\ \midrule
Sleep Stage Classification & EEGInception & 56.87 & 67.70 & \textbf{10.83} & Bakas et al., NeurIPS 2021 \cite{Bakas2021NIPS}  \\ \midrule
Stress Detection & SDCAN & 45.69 & 48.17 & \textbf{2.48} & Fu et al., IEEE TNSRE 2022 \cite{Fu2022TNSRE}  \\ \midrule
Emotion Recognition & AM-MSFFN & 88.00 & 93.51 & \textbf{5.51} & Jiang et al., IEEE SJ 2023 \cite{Jiang2023IEEESJ} \\ \midrule
SSVEP & SUTL & 72.28 & 74.04 & \textbf{1.76} & Li et al., ESWA 2024 \cite{Li2024ESWA} \\ \midrule
Motor Execution & EEGNet & 52.10 & 62.50 & \textbf{10.40} & Bakas et al., JNE 2025 \cite{Bakas2025JNE} \\ \midrule
Seizure Detection & EEGNet & 68.43 & 75.86 & \textbf{7.43} & Wang et al., NSR 2025 \cite{drwuNSR2025} \\ \bottomrule
\end{tabular}
\end{table*}
\normalsize

EA was also given very high evaluations in the literature.

For example, Kostas and Rudzicz \cite{Kostas2020} from the University of Toronto integrated EA, mixup data augmentation with their proposed TIDNet for EEG-based motor imagery classification, and found that ``\emph{while TIDNet alone or with only mixup shows mixed results, once alignment is included there is a nearly universal performance benefit to the deeper network (TIDNet), this improvement is much more consistent when both mixup and EA are used, with only a single (statistically insignificant) case showing very mildly worse performance. ... Focusing on the largest increase in performance, we find a significant 8.91\% increase in 4-way classification performance using EA, jumping from 61.53\% to 70.44\%. ... in terms of both trend and peak performance, EA seems consistently beneficial to EEGNet as well as TIDNet. ... Our empirical results are clear that using both (EA and mixup) consistently increases performance but, in terms of magnitude of increase, EA alone is many times better performing.}"

Junqueira et al. \cite{Junqueira2024} performed comprehensive experiments and comparisons on using EA in deep learning based motor imagery classification in their Journal of Neural Engineering publication entitled ``A systematic evaluation of Euclidean alignment with deep learning for EEG decoding." They found that ``\emph{EA improved the mean accuracy for all cross-subject models and datasets evaluated and led to a 70\% acceleration in convergence in the shared models. Consequently, we believe that EA should be a standard pre-processing step when training cross-subject models.}"


\section{Extension of EA} \label{sect:ext}

This section introduces LA, an extension of the unsupervised EA to supervised EEG data alignment.

LA \cite{drwuLA2020} was also proposed by the author's group in 2020, primarily for EEG-based motor imagery classification. LA assumes all source domain samples are labeled, and the target domain also has a small number of labeled calibration samples. The label information could be properly used for better EEG trial alignment.

The idea of LA is shown in Fig.~\ref{fig:EALA}. It essentially performs class-wise EA.

For simplicity, assume the source domain and the target domain have the same label space, e.g., for motor imagery, the source domain has two classes (left hand and right hand), and the target domain has the same two classes. For a given class, assume the source domain has $N_\mathrm{s}$ labeled EEG trials $\{(X_n^\mathrm{s},y_n^\mathrm{s})\}_{n=1}^{N_\mathrm{s}}$, and the target domain has $N_\mathrm{t}$ labeled EEG trials $\{(X_n^\mathrm{t},y_n^\mathrm{t})\}_{n=1}^{N_\mathrm{t}}$.

LA first computes class-wise mean covariance matrices $\bar{R}_\mathrm{s}$ and $\bar{R}_\mathrm{t}$:
\begin{align}
  \bar{R}_\mathrm{s}&=\frac{1}{N_\mathrm{s}}\sum_{n=1}^{N_\mathrm{s}} X_n^\mathrm{s} (X_n^\mathrm{s})^\top, \\
  \bar{R}_\mathrm{t}&=\frac{1}{N_\mathrm{t}}\sum_{n=1}^{N_\mathrm{t}} X_n^\mathrm{t} (X_n^\mathrm{t})^\top.
\end{align}
Note that both $\bar{R}_\mathrm{s}$ and $\bar{R}_\mathrm{t}$ are symmetric and semi-positive definite.

LA then performs the alignment only to the source domain EEG trials:
\begin{align}
  \tilde{X}_n^\mathrm{s}=\bar{R}_\mathrm{t}^{1/2}\bar{R}_\mathrm{s}^{-1/2}X_n^\mathrm{s},\quad n=1,...,N_\mathrm{s}.
\end{align}

After LA, the class-wise mean covariance matrix of all $N_\mathrm{s}$ aligned source domain trials $\{\tilde{X}_n^\mathrm{s}\}_{n=1}^{N_\mathrm{s}}$ equals the class-wise mean covariance matrix of the $N_\mathrm{t}$ target domain trials $\{\tilde{X}_n^\mathrm{t}\}_{n=1}^{N_\mathrm{t}}$:
\begin{align}
\frac{1}{N_\mathrm{s}}\sum_{n=1}^{N_\mathrm{s}}\tilde{X}_n^\mathrm{s}(\tilde{X}_n^\mathrm{s})^\top  &=\frac{1}{N_\mathrm{s}}\sum_{n=1}^{N_\mathrm{s}}\bar{R}_\mathrm{t}^{1/2} \bar{R}_\mathrm{s}^{-1/2} X_n^\mathrm{s}
(X_n^\mathrm{s})^\top\bar{R}_\mathrm{s}^{-1/2}\bar{R}_\mathrm{t}^{1/2}\nonumber \\
&=\bar{R}_\mathrm{t}^{1/2}\bar{R}_\mathrm{s}^{-1/2} \bar{R}_\mathrm{s} \bar{R}_\mathrm{s}^{-1/2}\bar{R}_\mathrm{t}^{1/2}\nonumber\\
&=\bar{R}_\mathrm{t}^{1/2} \bar{R}_\mathrm{t}^{1/2}\nonumber\\
&=\bar{R}_\mathrm{t}\nonumber\\
&=\frac{1}{N_\mathrm{t}}\sum_{n=1}^{N_\mathrm{t}}X_n^\mathrm{t}(X_n^\mathrm{t})^\top
\end{align}
i.e., for each class, the mean covariance matrices of both domain are equal, and hence the class-wise EEG data distributions from different domains become more consistent.

LA performs the above alignment for each class in the source domain separately. Note that it transforms the source domain trials to match the target domain trials. Unlike in EA that all EEG trials in the same domain share the same reference matrix, in LA different classes in the same domain use different reference matrices. When LA is used in testing, we do not know the class label (this is to be predicted) for an incoming EEG trial, so we cannot determine which reference matrix to use. By transforming the known source domain trials only, we can avoid this problem.

We \cite{drwuLA2020} showed that LA can also be used when the source and target domains have different label spaces. For example, when the source domain has two classes of left hand and right hand, and the target domain has two classes of feet and tongue, we can align the source domain left hand class with the target domain feet class, and the source domain right hand class with the target domain tongue class, still achieving effective TL. Of course, EA could also be used in this challenging scenario, as it does not distinguish among the classes at all.

Generally, LA outperforms EA, as it exploits the useful label information to make aligned trials from different classes more separable.

LA has also demonstrated its effectiveness in multiple BCI paradigms, including motor imagery classification \cite{drwuLA2020,Wei2022,Xu2023,Ma2024}, emotion recognition \cite{Peng2023,Ren2024,Zhang2024}, mental workload classification \cite{Wang2024}, speech imagery classification \cite{Zhan2022}, and traumatic brain injury classification \cite{Vishwanath2022}.


\section{New Research Directions} \label{sect:future}

This section introduces some potential new research directions based on EA.

\subsection{Improvements to EA}

Though EA has achieved promising performance in 10 different BCI paradigms, it still has some limitations, which could be address to further improve its performance:
\begin{enumerate}
\item EA needs to compute the inverse of a matrix, i.e., $\bar{R}^{-1/2}$ in (\ref{eq:EA}), which may be unstable when the number of channels is large.

\item The original EEG trials from different subjects have consistent channel configurations before alignment, because they use the same EEG headset. For example, for the MI trials in our experiments, the first channel was always AF3, the second channel was AF4, and the 59th channel was O2. However, after EA, the aligned channels are no longer consistent, e.g., the first aligned channel of Subject~1 may be obtained by applying weights $[0.1, 0.2, ..., 0.5]$ to the 59 original channels, whereas the first aligned channel of Subject~2 may be obtained by applying weights $[0.3, 0.1,...,0.2]$ to the 59 original channels. This channel location shifting may impact the subsequent classification performance.
\end{enumerate}

\subsection{Applicability of EA to Other Multi-Channel Physiological Signals}

The original EA was proposed for aligning multi-channel EEG signals from different subjects/sessions. It may also be used in aligning other multi-channel physiological signals.

For example, Wang et al. \cite{drwuNSR2025} used EA as a standard preprocessing step on two intracranial EEG datasets (eight humans and four canines in the Kaggle UPenn and Mayo Clinic's Seizure Detection Challenge \cite{Baldassano2017}, and 21 human patients in the Freiburg dataset \cite{Ihle2012}), to address the heterogeneities in electrode placements across subjects, and hence to enable cross-species and cross-modality epileptic seizure detection.

Since many other physiological signals, e.g., Magnetoencephalography (MEG) \cite{drwuMEG2025}, Electrocardiography (ECG) \cite{drwuASECG2020} and stereo-Electroencephalography (sEEG) \cite{drwuFR2025}, also have multiple channels and large individual differences, it is interesting to study if EA can also be applied to them to reduce the data distribution discrepancies among subjects.

\subsection{Large Models for EEG Decoding}

As large models have achieved great successes in natural language processing and computer vision, they have also started to find applications in EEG-based BCIs \cite{Jiang2024,Zhang2024a}. For example, Jiang et al. \cite{Jiang2024} showed that their large brain model, pre-trained on about 2,500 hours of various types of EEG signals from around 20 datasets, outperformed all compared SOTA in EEG-based abnormal detection, event type classification, emotion recognition, and gait prediction.

However, Jiang et al. \cite{Jiang2024} also pointed out that one challenge in training large models for EEG decoding is the lack of sufficient EEG data. This could be alleviated by making use of relevant data from other species and/or modalities, as our recent work \cite{drwuNSR2025} has shown that canines's scalp/intracranial EEG data could be used to facilitate scalp/intracranial EEG based seizure classification for humans, and vice versa. However, as mentioned in the previous subsection, this was impossible without using EA to align the trials.

Another important consideration in training large models for EEG-based BCIs is the efficiency. Without speaking, the faster the better. Junqueira et al. \cite{Junqueira2024} pointed out in their evaluation of EA with deep learning for EEG decoding that ``\emph{when using single shared models with training data from all individuals, using EA allowed us to achieve the same level of accuracy as the models without EA using 70\% fewer iterations and a final level of accuracy 4.33\% higher when using the same number of iterations.}" Since large models are also deep neural network based, EA could be used as a pre-processing step to align EEG data from different subjects/sessions/species/modalities to accelerate the training.

\subsection{Extension from Classification to Regression}

So far, the applications of EA exclusively focused on BCI classification problems, such as motor imagery, event related potential, seizure classification, etc., as shown in Table~\ref{tab:EA}. However, there are also many important regression problems in BCIs \cite{drwuTLBCI2022}, such as primitive emotion estimation \cite{drwuPIEEE2023}, driver drowsiness estimation \cite{drwuFWET2019}, user reaction time estimation \cite{drwuRG2017}, etc. As in BCI classification problems, EEG signal stationarity and large individual differences also exist in BCI regression problems. So, TL could also be used to facilitate the calibration \cite{drwuTFS2017}.

Our previous research has extended some blocks in the TL pipeline for motor imagery classification (Fig.~\ref{fig:TL}), e.g., common spatial pattern filtering \cite{drwuSF2018}, wAR classifier \cite{drwuTFS2017}, and more traditional and deep TL classifiers \cite{drwuTFS2024}, to BCI regression problems, using fuzzy sets. It is interesting to study if EA, and also LA, could be extended from classification to regression, also using fuzzy sets.

\subsection{Accurate and Robust EEG Decoding}

Most BCI decoding research so far only focused on accurate decoding of the brain signals. However, studies have shown that the decoding algorithms may suffer from adversarial attacks \cite{drwuBCIAttack2019,drwuTAR2019,drwuNSO2022,drwuSCIS2022,drwuAP2023,drwuBackdoor2023,drwuIF2024}, i.e., a small perturbation, which may be too small to be detected by human eyes or computer algorithms, can be added to the benign EEG signal to mislead the decoding algorithm.

Various adversarial attack approaches have been proposed for motor imagery classification \cite{drwuBCIAttack2019,drwuAP2023,drwuBackdoor2023,drwuIF2024}, P300 event related potential classification \cite{drwuBCIAttack2019,drwuAP2023,drwuBackdoor2023,drwuIF2024}, feedback error-related negativity classification \cite{drwuAP2023,drwuBackdoor2023,drwuIF2024}, steady-state visual evoked potential classification \cite{drwuSCIS2022,drwuNSR2021}, and also regression problems \cite{drwuTAR2019}. They could cause various forms of damage. For example, attacking a BCI speller could mis-interpret the user's opinion, and attacking a motor imagery BCI controlled wheelchair could intentionally drive the user into danger. More seriously, as pointed out in \cite{RAND2020}, ``\emph{adversary hacking into BCI devices that influence the motor cortex of human operators could theoretically send false directions or elicit unintended actions, such as friendly fire.}"

Thus, it is urgent to consider how to defend against adversarial attacks to BCIs. As demonstrated in our benchmark studies \cite{drwuFGCS2023}, a promising approach is adversarial training, i.e., to add adversarial samples into the training dataset so that the decoding algorithm is less vulnerable to them in testing. However, while increasing the robustness on adversarial samples, adversarial training usually deteriorates the decoding performance on the benign samples, as the training dataset is polluted. It is desirable to increase the decoding performance on both benign and adversarial EEG trials, i.e., to achieve simultaneously accurate and robust decoding.

Our recently proposed alignment based adversarial training (ABAT) algorithm \cite{drwuABAT2024} solved this challenging problem. Its flowchart is shown in Fig.~\ref{fig:ABAT}. Essentially, it first uses EA to reduce the data distribution discrepancies among different domains, and hence to improve the classification accuracy on benign EEG trials; it then performs adversarial training to improve the robustness on adversarial samples.

\begin{figure}[htpb] \centering
\includegraphics[width=.9\linewidth,clip]{ABAT}
\caption{Alignment based adversarial training (ABAT).} \label{fig:ABAT}
\end{figure}

More recently, we \cite{drwuBenchmark2024} showed that simultaneously integrating EA, data augmentation and adversarial training can further improve both the accuracy and robustness of EEG-based BCIs.

In summary, EA is essential in adversarial training to simultaneously improve the decoding accuracy and adversarial robustness of EEG-based BCIs. It is expected that more sophisticated and comprehensive TL pipeline, like the one shown in Fig.~\ref{fig:TL}, can be integrated with adversarial training to achieve better performance.

\subsection{Accurate, Robust, and Privacy-Preserving EEG Decoding}

In addition to adversarial security, privacy protection is another important ethic consideration in BCIs. Our survey \cite{drwuTCSS2023} shows that many types of private information, e.g., personal identify, age, emotions, brain-related diseases, etc., could be mined from EEG signals. Multiple laws and regularization all over the world, particularly the General Data Protection Regularization (GDPR) \cite{GDPR2016} of the European Union, and the Personal Information Protection Law of China, impose strict privacy protection requirements. Ideally, for privacy-preserving TL, there should be no sharing of authentic EEG data among the source domains, and also between the source domains and the target domain.

Various approaches, including security multiparty computation \cite{drwuPrivacy2019}, synthetic data generation \cite{Debie2020,Pascual2021}, homomorphic encryption \cite{Popescu2021}, source-free TL \cite{drwuTBME2022,drwuMSDT2022,drwuSFDA2023,drwuLSFT2023}, federated learning \cite{drwuFed2024}, machine unlearning \cite{Shao2024}, and data perturbation \cite{drwuPrivacySMC2024}, have been proposed for privacy-preserving BCIs.

A very challenging problem is how to simultaneously achieve accurate decoding, adversarial robustness and privacy-protection in EEG-based BCIs. To our knowledge, aligned and augmented adversarial ensemble (A3E) \cite{drwuA3E2024} was the only solution so far, where EA also plays a very important role.

The flowchart of using A3E in EEG-based motor imagery classification is shown in Fig.~\ref{fig:A3E}. Each source domain uses EA to align their EEG trials first. Since EA uses information from its own domain only, there is no privacy issues. Three privacy protection scenarios are then considered:

\begin{figure}[htpb] \centering
\includegraphics[width=.8\linewidth,clip]{A3E}
\caption{The aligned and augmented adversarial ensemble (A3E) approach for simultaneously accurate decoding, adversarial robustness and privacy-protection in motor imagery BCIs.} \label{fig:A3E}
\end{figure}

\begin{enumerate}
\item \emph{Centralized source-free TL}, in which the source domains trust each other, so they can combine their EEG data together to train a single source model.
\item \emph{Federated source-free TL}, in which the source domains do not trust each other, so federated learning is used to isolate data from different source domains but still trains a single source model.
\item \emph{Source data perturbation}, in which a domain-specific perturbation is added to each domain to hide its private information (e.g., user identity), without hurting the motor imagery classification performance.
\end{enumerate}
The source model in the first two scenarios, or the perturbed and privacy protected source data in the last scenario, can then be provided to the target domain for TL. In this way, the source domain data privacy is protected. During TL, the A3E algorithm performs first EA and data augmentation in the target domain to increase the decoding accuracy on the benign samples, and then adversarial training to increase the robustness on the adversarial samples.

In this way, we can simultaneously achieve accurate decoding, adversarial robustness and privacy-protection in EEG-based BCIs. We expect EA will also play an important role in future such approaches.


\section{Conclusions} \label{sect:conclusions}

Due to the non-stationarity and large individual differences of EEG signals, EEG-based BCIs usually need subject-specific calibration to tailor the decoding algorithm for each new subject, which is time-consuming and user-unfriendly, hindering their real-world applications. TL has been extensively used to expedite the calibration, by making use of EEG data from other subjects/sessions. An important consideration in TL for EEG-based BCIs is to reduce the data distribution discrepancies among different subjects/session, to avoid negative transfer. EA was proposed in 2020 to address this challenge. Numerous experiments from 10 different BCI paradigms demonstrated its effectiveness and efficiency. This paper has revisited the EA, explaining its procedure and correct usage, introducing its applications and extensions, and pointing out potential new research directions. It should be very helpful to BCI researchers, especially those who are working on EEG signal decoding.

Due to its effectiveness and efficiency, as suggested by Junqueira et al. \cite{Junqueira2024}, ``\emph{EA should be a standard pre-processing step when training cross-subject models.}"



\section*{References}

\begin{thebibliography}{100}

\bibitem{Nakanishi2020}
Masaki Nakanishi, Yu-Te Wang, Chun-Shu Wei, Kuan-Jung Chiang, and Tzyy-Ping
  Jung.
\newblock Facilitating calibration in high-speed {BCI} spellers via leveraging
  cross-device shared latent responses.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 67(4):1105--1113, 2020.

\bibitem{Leeb2007}
Robert Leeb, Doron Friedman, Gernot~R M{\"u}ller-Putz, Reinhold Scherer, Mel
  Slater, and Gert Pfurtscheller.
\newblock Self-paced (asynchronous) {BCI} control of a wheelchair in virtual
  environments: a case study with a tetraplegic.
\newblock {\em Computational Intelligence and Neuroscience}, 2007(1):079642,
  2007.

\bibitem{Mane2020}
Ravikiran Mane, Tushar Chouhan, and Cuntai Guan.
\newblock {BCI} for stroke rehabilitation: motor and beyond.
\newblock {\em Journal of Neural Engineering}, 17(4):041001, 2020.

\bibitem{drwuPIEEE2023}
Dongrui Wu, Bao-Liang Lu, Bin Hu, and Zhigang Zeng.
\newblock Affective brain-computer interfaces ({aBCIs}): A tutorial.
\newblock {\em Proc. of the IEEE}, 11(10):1314--1332, 2023.

\bibitem{Moses2021}
David~A. Moses, Sean~L. Metzger, Jessie~R. Liu, Gopala~K. Anumanchipalli,
  Joseph~G. Makin, Pengfei~F. Sun, Josh Chartier, Maximilian~E. Dougherty,
  Patricia~M. Liu, Gary~M. Abrams, et~al.
\newblock Neuroprosthesis for decoding speech in a paralyzed person with
  anarthria.
\newblock {\em New England Journal of Medicine}, 385(3):217--227, 2021.

\bibitem{Lorach2023}
Henri Lorach, Andrea Galvez, Valeria Spagnolo, Felix Martel, Serpil Karakas,
  Nadine Intering, Molywan Vat, Olivier Faivre, Cathal Harte, Salif Komi,
  et~al.
\newblock Walking naturally after spinal cord injury using a brain-spine
  interface.
\newblock {\em Nature}, 618(7963):126--133, 2023.

\bibitem{Liu2023}
Xiaoxing Liu, Teng Gao, Tangsheng Lu, Gunter Schumann, and Lin Lu.
\newblock China brain project: from bench to bedside.
\newblock {\em Science Bulletin}, 68(5):444--447, 2023.

\bibitem{Eisenstein2024}
Michael Eisenstein.
\newblock Seven technologies to watch in 2024.
\newblock {\em Nature}, 625(7996):844--848, 2024.

\bibitem{Naddaf2025}
Miryam Naddaf.
\newblock Science in 2025: the events to watch for in the coming year.
\newblock {\em Nature}, 637(8044):9--11, 2025.

\bibitem{Milojicic2025}
Dejan Milojicic.
\newblock Technology predictions 2025.
\newblock {\em Computer}, 58(1):88--90, 2025.

\bibitem{drwuTLBCI2022}
Dongrui Wu, Yifan Xu, and Bao-Liang Lu.
\newblock Transfer learning for {EEG}-based brain-computer interfaces: A review
  of progress made since 2016.
\newblock {\em IEEE Trans. on Cognitive and Developmental Systems},
  14(1):4--19, 2022.

\bibitem{drwuNTL2023}
Wen Zhang, Lingfei Deng, Lei Zhang, and Dongrui Wu.
\newblock A survey on negative transfer.
\newblock {\em IEEE/CAA Journal of Automatica Sinica}, 10(2):305--329, 2023.

\bibitem{drwuEA2020}
He~He and Dongrui Wu.
\newblock Transfer learning for brain-computer interfaces: A {Euclidean} space
  data alignment approach.
\newblock {\em {IEEE} Trans. on Biomedical Engineering}, 67(2):399--410, 2020.

\bibitem{drwuMITLBCI2022}
Dongrui Wu, Xue Jiang, and Ruimin Peng.
\newblock Transfer learning for motor imagery based brain-computer interfaces:
  A tutorial.
\newblock {\em Neural Networks}, 153:235--253, 2022.

\bibitem{Wei2022}
Xiaoxi Wei, A.~Aldo Faisal, Moritz Grosse-Wentrup, Alexandre Gramfort, Sylvain
  Chevallier, Vinay Jayaram, Camille Jeunet, Stylianos Bakas, Siegfried Ludwig,
  Konstantinos Barmpas, et~al.
\newblock 2021 {BEETL} competition: Advancing transfer learning for subject
  independence and heterogenous {EEG} data sets.
\newblock In {\em {NeurIPS} 2021 Competitions and Demonstrations Track}, pages
  205--219, 2022.

\bibitem{Zanini2018}
Paolo Zanini, Marco Congedo, Christian Jutten, Salem Said, and Yannick
  Berthoumieu.
\newblock Transfer learning: a {R}iemannian geometry framework with
  applications to brain-computer interfaces.
\newblock {\em {IEEE} Trans. on Biomedical Engineering}, 65(5):1107--1116,
  2018.

\bibitem{drwuLA2020}
He~He and Dongui Wu.
\newblock Different set domain adaptation for brain-computer interfaces: A
  label alignment approach.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  28(5):1091--1108, 2020.

\bibitem{Li2021b}
Ren Li, Jared~S. Johansen, Hamad Ahmed, Thomas~V. Ilyevsky, Ronnie~B. Wilbur,
  Hari~M. Bharadwaj, and Jeffrey~Mark Siskind.
\newblock The perils and pitfalls of block design for {EEG} classification
  experiments.
\newblock {\em IEEE Trans. on Pattern Analysis and Machine Intelligence},
  43(1):316--333, 2021.

\bibitem{Lu2010}
Haiping Lu, How-Lung Eng, Cuntai Guan, Konstantinos~N. Plataniotis, and
  Anastasios~N. Venetsanopoulos.
\newblock Regularized common spatial pattern with aggregation for {EEG}
  classification in small-sample setting.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 57(12):2936--2946, 2010.

\bibitem{drwuTHMS2017}
Dongrui Wu.
\newblock Online and offline domain adaptation for reducing {BCI} calibration
  effort.
\newblock {\em IEEE Trans. on Human-Machine Systems}, 47(4):550--563, 2017.

\bibitem{Kostas2020}
Demetres Kostas and Frank Rudzicz.
\newblock Thinker invariance: enabling deep neural networks for {BCI} across
  more people.
\newblock {\em Journal of Neural Engineering}, 17(5):056008, 2020.

\bibitem{drwuMEKT2020}
Wen Zhang and Dongrui Wu.
\newblock Manifold embedded knowledge transfer for brain-computer interfaces.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  28(5):1117--1127, 2020.

\bibitem{Bakas2021NIPS}
Stylianos Bakas, Siegfried Ludwig, Konstantinos Barmpas, Mehdi Bahri, Yannis
  Panagakis, Nikolaos Laskaris, Dimitrios~A. Adamos, and Stefanos Zafeiriou.
\newblock Team cogitat at neurips 2021: Benchmarks for {EEG} transfer learning
  competition.
\newblock {\em arXiv preprint arXiv:2202.03267}, 2022.

\bibitem{Zhang2021CMPB}
Xianxiong Zhang, Qingshan She, Yun Chen, Wanzeng Kong, and Congli Mei.
\newblock Sub-band target alignment common spatial pattern in brain-computer
  interface.
\newblock {\em Computer Methods and Programs in Biomedicine}, 207:106150, 2021.

\bibitem{Liang2021IROS}
Zilin Liang, Zheng Zheng, Weihai Chen, Jianhua Wang, Jianbin Zhang, Jianer
  Chen, and Zuobing Chen.
\newblock Manifold trial selection to reduce negative transfer in motor
  imagery-based brain--computer interface.
\newblock In {\em IEEE/RSJ Int'l Conf. on Intelligent Robots and Systems},
  pages 4144--4149, Prague, Czech Republic, Sep. 2021.

\bibitem{Togha2021BSPC}
Mohammad~Mahdi Togha, Mohammad~Reza Salehi, and Ebrahim Abiri.
\newblock An improved version of local activities estimation to enhance motor
  imagery classification.
\newblock {\em Biomedical Signal Processing and Control}, 66:102485, 2021.

\bibitem{Xu2021JNE}
Lichao Xu, Minpeng Xu, Zhen Ma, Kun Wang, Tzyy-Ping Jung, and Dong Ming.
\newblock Enhancing transfer performance across datasets for brain-computer
  interfaces using a combination of alignment strategies and adaptive batch
  normalization.
\newblock {\em Journal of Neural Engineering}, 18(4):0460e5, 2021.

\bibitem{Demsy2021SMC}
Orvin Demsy, David Achanccaray, and Mitsuhiro Hayashibe.
\newblock Inter-subject transfer learning using {Euclidean} alignment and
  transfer component analysis for motor imagery-based {BCI}.
\newblock In {\em IEEE Int'l Conference on Systems, Man, and Cybernetics},
  pages 3176--3176, Melbourne, Australia, Oct. 2021.

\bibitem{Peterson2021TBME}
Victoria Peterson, Nicol{\'a}s Nieto, Dominik Wyser, Olivier Lambercy, Roger
  Gassert, Diego~H. Milone, and Rub{\'e}n~D. Spies.
\newblock Transfer learning based on optimal transport for motor imagery
  brain-computer interfaces.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 69(2):807--817, 2021.

\bibitem{Cai2022JNM}
Yinhao Cai, Qingshan She, Jiyue Ji, Yuliang Ma, Jianhai Zhang, and Yingchun
  Zhang.
\newblock Motor imagery {EEG} decoding using manifold embedded transfer
  learning.
\newblock {\em Journal of Neuroscience Methods}, 370:109489, 2022.

\bibitem{Chen2022JNUNS}
Li~Chen, Anmin Gong, Peng Ding, and et~al.
\newblock {EEG} signal decoding of motor imagination based on euclidean
  space-weighted logistic regression transfer learning.
\newblock {\em Journal of Nanjing University}, 58(2):264--274, 2022.

\bibitem{Wu2023NeuroCom}
Xuanyu Wu, Yixiong Feng, Shanhe Lou, Hao Zheng, Bingtao Hu, Zhaoxi Hong, and
  Jianrong Tan.
\newblock Improving {NeuCube} spiking neural network for {EEG}-based pattern
  recognition using transfer learning.
\newblock {\em Neurocomputing}, 529:222--235, 2023.

\bibitem{Wei2023TNSRE}
Qingguo Wei and Xinjie Ding.
\newblock Intra-and inter-subject common spatial pattern for reducing
  calibration effort in {MI}-based {BCI}.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  31:904--916, 2023.

\bibitem{Pan2023JNE}
Lincong Pan, Kun Wang, Lichao Xu, Xinwei Sun, Weibo Yi, Minpeng Xu, and Dong
  Ming.
\newblock Riemannian geometric and ensemble learning for decoding cross-session
  motor imagery electroencephalography signals.
\newblock {\em Journal of Neural Engineering}, 20(6):066011, 2023.

\bibitem{Zhu2023TIM}
Jian Zhu, Ganxi Xu, Qintai Hu, Boyu Wang, Teng Zhou, and Jing Qin.
\newblock Dual contrastive training and transferability aware adaptation for
  multi-source privacy-preserving motor imagery classification.
\newblock {\em IEEE Trans. on Instrumentation and Measurement}, 2023.

\bibitem{Gao2023TNSRE}
Yunyuan Gao, Mengting Li, Yun Peng, Feng Fang, and Yingchun Zhang.
\newblock Double stage transfer learning for brain--computer interfaces.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  31:1128--1136, 2023.

\bibitem{Liang2024BSPC}
Zilin Liang, Zheng Zheng, Weihai Chen, Zhongcai Pei, Jianhua Wang, and Jianer
  Chen.
\newblock Manifold embedded instance selection to suppress negative transfer in
  motor imagery-based brain--computer interface.
\newblock {\em Biomedical Signal Processing and Control}, 88:105556, 2024.

\bibitem{Gao2024CogNeuro}
Yunyuan Gao, Congrui Zhang, Jincheng Huang, and Ming Meng.
\newblock {EEG} multi-domain feature transfer based on sparse regularized
  {Tucker} decomposition.
\newblock {\em Cognitive Neurodynamics}, 18(1):185--197, 2024.

\bibitem{drwuTFT2025}
Ziwei Wang, Siyang Li, Xiaoqing Chen, and Dongrui Wu.
\newblock Time-frequency transform based cross-subject {EEG} data augmentation.
\newblock {\em Knowledge Based Systems}, 311:113074, 2025.

\bibitem{Bakas2025JNE}
Stylianos Bakas, Siegfried Ludwig, Dimitrios~A. Adamos, Nikolaos Laskaris,
  Yannis Panagakis, and Stefanos Zafeiriou.
\newblock Latent alignment in deep learning models for {EEG} decoding.
\newblock {\em Journal of Neural Engineering}, 2025.
\newblock in press.

\bibitem{Amorim2024BRACIS}
Marcelo~M. Amorim, Leonardo Prata, Jo{\~a}o~Stephan Maur{\'\i}cio, Alex Borges,
  Heder Bernardino, and Gabriel de~Souza.
\newblock Euclidean alignment for transfer learning in multi-band common
  spatial pattern.
\newblock In {\em Brazilian Conf. on Intelligent Systems}, pages 430--443,
  Belm do Par, Brazil, Dec. 2024.

\bibitem{Li2024spdim}
Shanglin Li, Motoaki Kawanabe, and Reinmar~J. Kobler.
\newblock {SPDIM}: {S}ource-free unsupervised conditional and label shifts
  adaptation in {EEG}.
\newblock {\em arXiv preprint arXiv:2411.07249}, 2024.

\bibitem{Wang2024TBME}
Yihan Wang, Jiaxing Wang, Weiqun Wang, Jianqiang Su, Chayut Bunterngchit, and
  Zeng-Guang Hou.
\newblock {TFTL}: {A} task-free transfer learning strategy for {EEG}-based
  cross-subject \& cross-dataset motor imagery {BCI}.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 72:810--821, 2024.

\bibitem{Wang2024JBHI}
Huiyang Wang, Hongfang Han, John~Q. Gan, and Haixian Wang.
\newblock Lightweight source-free domain adaptation based on adaptive
  {Euclidean} alignment for brain-computer interfaces.
\newblock {\em IEEE Journal of Biomedical and Health Informatics}, 29:909--922,
  2024.

\bibitem{Zhang2024TIM}
Jia Zhang, Jinglong Fang, Siwei Liu, Dezheng Liu, Hanrui Wu, and Jinyi Long.
\newblock Towards cross-brain computer interface: {A} prototype-supervised
  adversarial transfer learning approach with multiple sources.
\newblock {\em IEEE Trans. on Instrumentation and Measurement}, 73:2528113,
  2024.

\bibitem{Xu2024TIM}
Jiacan Xu, Donglin Li, Peng Zhou, Yuxian Zhang, Zinan Wang, and Dazhong Ma.
\newblock A relation feature comparison network for cross-domain recognition of
  motion intention.
\newblock {\em IEEE Trans. on Instrumentation and Measurement}, 73:4008513,
  2024.

\bibitem{Zhu2024RSI}
Fenfang Zhu, Jicheng Cai, Hao Zheng, Zilin Liang, and Yue Zhang.
\newblock Suppression of negative transfer in motor imagery brain--computer
  interface based on mutual information and {Pearson} correlation coefficient.
\newblock {\em Review of Scientific Instruments}, 95(7), 2024.

\bibitem{Gao2025NeuroCom}
Yunyuan Gao, Yici Liu, Ming Meng, Feng Fang, Michael Houston, and Yingchun
  Zhang.
\newblock A novel multi-morphological representation approach for multi-source
  {EEG} signals.
\newblock {\em Neurocomputing}, 617:129010, 2025.

\bibitem{Jin2024JNE}
Jing Jin, Guanglian Bai, Ren Xu, Ke~Qin, Hao Sun, Xingyu Wang, and Andrzej
  Cichocki.
\newblock A cross-dataset adaptive domain selection transfer learning framework
  for motor imagery-based brain-computer interfaces.
\newblock {\em Journal of Neural Engineering}, 21(3):036057, 2024.

\bibitem{Li2024JNE}
Wenjie Li, Haoyu Li, Xinlin Sun, Huicong Kang, Shan An, Guoxin Wang, and
  Zhongke Gao.
\newblock Self-supervised contrastive learning for {EEG}-based cross-subject
  motor imagery recognition.
\newblock {\em Journal of Neural Engineering}, 21(2):026038, 2024.

\bibitem{Kumar2019BCI}
Satyam Kumar, Florian Yger, and Fabien Lotte.
\newblock Towards adaptive classification using {Riemannian} geometry
  approaches in brain-computer interfaces.
\newblock In {\em Int'l Winter Conference on Brain-Computer Interface}, pages
  1--6, Gangwon, South Korea, Feb. 2019.

\bibitem{Fu2022TNSRE}
Ruiqi Fu, Yi-Feng Chen, Yongqi Huang, Shuping Chen, Feiyan Duan, Jiewei Li,
  Jianhui Wu, Dongmei Jiang, Junling Gao, Jason Gu, et~al.
\newblock Symmetric convolutional and adversarial neural network enables
  improved mental stress classification from {EEG}.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  30:1384--1400, 2022.

\bibitem{Jiang2023IEEESJ}
Yiye Jiang, Songyun Xie, Xinzhou Xie, Yujie Cui, and Hao Tang.
\newblock Emotion recognition via multiscale feature fusion network and
  attention mechanism.
\newblock {\em IEEE Sensors Journal}, 23(10):10790--10800, 2023.

\bibitem{Li2024ESWA}
Jingjing Li, Yanhong Zhou, Tiange Liu, Tzyy-Ping Jung, Xianglong Wan, Dingna
  Duan, Danyang Li, Hao Yu, Haiqing Song, Xianling Dong, et~al.
\newblock A radial basis deformable residual convolutional neural model
  embedded with local multi-modal feature knowledge and its application in
  cross-subject classification.
\newblock {\em Expert Systems with Applications}, 257:125089, 2024.

\bibitem{drwuNSR2025}
Ziwei Wang, Siyang Li, and Dongrui Wu.
\newblock Canine {EEG} helps human: Cross-species and cross-modality epileptic
  seizure detection via multi-space alignment.
\newblock {\em National Science Review}, 2025.
\newblock in press.

\bibitem{Junqueira2024}
Bruna Junqueira, Bruno Aristimunha, Sylvain Chevallier, and Raphael~Y
  de~Camargo.
\newblock A systematic evaluation of euclidean alignment with deep learning for
  {EEG} decoding.
\newblock {\em Journal of Neural Engineering}, 21(3):036038, 2024.

\bibitem{Xu2023}
Dong-Qin Xu, Yan-Jun Sun, and Ming-Ai Li.
\newblock An adaptive cross-class transfer learning framework with two-level
  alignment.
\newblock {\em Biomedical Signal Processing and Control}, 86:105155, 2023.

\bibitem{Ma2024}
Sufan Ma and Dongxiao Zhang.
\newblock A cross-attention-based class alignment network for cross-subject
  {EEG} classification in a heterogeneous space.
\newblock {\em Sensors}, 24(21):7080, 2024.

\bibitem{Peng2023}
Yong Peng, Honggang Liu, Wanzeng Kong, Feiping Nie, Bao-Liang Lu, and Andrzej
  Cichocki.
\newblock Joint {EEG} feature transfer and semisupervised cross-subject emotion
  recognition.
\newblock {\em IEEE Trans. on Industrial Informatics}, 19(7):8104--8115, 2023.

\bibitem{Ren2024}
Chao Ren, Jinbo Chen, Rui Li, Weihao Zheng, Yijiang Chen, Yikun Yang, Xiaowei
  Zhang, and Bin Hu.
\newblock Semi-supervised pairwise transfer learning based on multi-source
  domain adaptation: A case study on {EEG}-based emotion recognition.
\newblock {\em Knowledge-Based Systems}, 305:112669, 2024.

\bibitem{Zhang2024}
Hanzhong Zhang, Tienyu Zuo, Zhiyang Chen, Xin Wang, and Poly~Z.H. Sun.
\newblock Evolutionary ensemble learning for {EEG}-based cross-subject emotion
  recognition.
\newblock {\em IEEE Journal of Biomedical and Health Informatics},
  28(7):3872--3881, 2024.

\bibitem{Wang2024}
Tao Wang, Yufeng Ke, Yichao Huang, Feng He, Wenxiao Zhong, Shuang Liu, and Dong
  Ming.
\newblock Using semi-supervised domain adaptation to enhance {EEG}-based
  cross-task mental workload classification performance.
\newblock {\em IEEE Journal of Biomedical and Health Informatics},
  28(12):7032--7039, 2024.

\bibitem{Zhan2022}
Qianqian Zhan, Li~Wang, Lingling Ren, and Xuewen Huang.
\newblock A novel heterogeneous transfer learning method based on data
  stitching for the sequential coding brain computer interface.
\newblock {\em Computers in Biology and Medicine}, 151:106220, 2022.

\bibitem{Vishwanath2022}
Manoj Vishwanath, Nikil Dutt, Amir~M. Rahmani, Miranda~M. Lim, and Hung Cao.
\newblock Label alignment improves {EEG}-based machine learning-based
  classification of traumatic brain injury.
\newblock In {\em Proc. 44th Annual Int'l Conf. of the IEEE Engineering in
  Medicine \& Biology Society (EMBC)}, pages 3546--3549, Glasgow, UK, July
  2022.

\bibitem{Baldassano2017}
Steven~N Baldassano, Benjamin~H Brinkmann, Hoameng Ung, Tyler Blevins, Erin~C
  Conrad, Kent Leyde, Mark~J Cook, Ankit~N Khambhati, Joost~B Wagenaar,
  Gregory~A Worrell, et~al.
\newblock Crowdsourcing seizure detection: Algorithm development and validation
  on human implanted device recordings.
\newblock {\em Brain}, 140(6):1680--1691, 2017.

\bibitem{Ihle2012}
Matthias Ihle, Hinnerk Feldwisch-Drentrup, C{\'e}sar~A Teixeira, Adrien Witon,
  Bj{\"o}rn Schelter, Jens Timmer, and Andreas Schulze-Bonhage.
\newblock {EPILEPSIAE}--{A} {E}uropean epilepsy database.
\newblock {\em Computer Methods and Programs in Biomedicine}, 106(3):127--138,
  2012.

\bibitem{drwuMEG2025}
Zhihong Jia, Hongbin Wang, Yuanzhong Shen, Feng Hu, Jiayu An, Kai Shu, and
  Dongrui Wu.
\newblock Magnetoencephalography ({MEG}) basednon-invasive chinese speech
  decoding.
\newblock {\em IEEE Trans. on Cognitive and Developmental Systems}, 2025.
\newblock submitted.

\bibitem{drwuASECG2020}
Dongrui Wu, Chenfeng Guo, Feifei Liu, and Chengyu Liu.
\newblock Active stacking for heart rate estimation.
\newblock In {\em Proc. Int'l Joint Conf. on Neural Networks}, Glasgow, UK,
  August 2020.

\bibitem{drwuFR2025}
Hongbin Wang, Zhihong Jia, Yuanzhong Shen, Kai Shu, Ziwei Wang, Siyang Lia,
  Feng Hu, and Dongrui Wu.
\newblock {SACM}: {sEEG} and audio contrastive matching framework for {C}hinese
  speech decoding.
\newblock {\em Foundamental Research}, 2025.
\newblock submitted.

\bibitem{Jiang2024}
Wei-Bang Jiang, Li-Ming Zhao, and Bao-Liang Lu.
\newblock Large brain model for learning generic representations with
  tremendous {EEG} data in {BCI}.
\newblock In {\em Proc. Int'l Conf. on Learning Representations}, Vienna,
  Austria, May 2024.

\bibitem{Zhang2024a}
Yuhong Zhang, Qin Li, Sujal Nahata, Tasnia Jamal, Shih-Kuen Cheng, Gert
  Cauwenberghs, and Tzyy-Ping Jung.
\newblock Integrating large language model, {EEG}, and eye-tracking for
  word-level neural state classification in reading comprehension.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  32:3465--3475, 2024.

\bibitem{drwuFWET2019}
Yuqi Cui, Yifan Xu, and Dongrui Wu.
\newblock {EEG}-based driver drowsiness estimation using feature weighted
  episodic training.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  27(11):2263--2273, 2019.

\bibitem{drwuRG2017}
Dongrui Wu, Vernon~J. Lawhern, Brent~J. Lance, Stephen Gordon, Tzyy-Ping Jung,
  and Chin-Teng Lin.
\newblock {EEG}-based user reaction time estimation using {R}iemannian geometry
  features.
\newblock {\em {IEEE} Trans. on Neural Systems and Rehabilitation Engineering},
  25(11):2157--2168, 2017.

\bibitem{drwuTFS2017}
Dongrui Wu, Vernon~J. Lawhern, Stephen Gordon, Brent~J. Lance, and Chin-Teng
  Lin.
\newblock Driver drowsiness estimation from {EEG} signals using online weighted
  adaptation regularization for regression ({OwARR}).
\newblock {\em {IEEE} Trans. on Fuzzy Systems}, 25(6):1522--1535, 2017.

\bibitem{drwuSF2018}
Dongrui Wu, Jung-Tai King, Chun-Hsiang Chuang, Chin-Teng Lin, and Tzyy-Ping
  Jung.
\newblock Spatial filtering for {EEG}-based regression problems in
  brain-computer interface ({BCI}).
\newblock {\em {IEEE} Trans. on Fuzzy Systems}, 26(2):771--781, 2018.

\bibitem{drwuTFS2024}
Zhenyao Cui, Siyuan Kai, Siyang Li, and Dongrui Wu.
\newblock A fuzzy set based classification-to-regression extension framework
  for transfer learning and its application to brain-computer interfaces.
\newblock {\em IEEE Trans. on Fuzzy Systems}, 2024.
\newblock submitted.

\bibitem{drwuBCIAttack2019}
Xiao Zhang and Dongrui Wu.
\newblock On the vulnerability of {CNN} classifiers in {EEG}-based {BCIs}.
\newblock {\em {IEEE} Trans. on Neural Systems and Rehabilitation Engineering},
  27(5):814--825, 2019.

\bibitem{drwuTAR2019}
Lubin Meng, Chin-Teng Lin, Tyzz-Ping Jung, and Dongrui Wu.
\newblock White-box target attack for {EEG}-based {BCI} regression problems.
\newblock In {\em Proc. Int'l Conf. on Neural Information Processing}, Sydney,
  Australia, December 2019.

\bibitem{drwuNSO2022}
Dongrui Wu, Jiaxin Xu, Weili Fang, Yi~Zhang, Liuqing Yang, Hanbin Luo, Xiaodong
  Xu, and Xiang Yu.
\newblock Adversarial attacks and defenses in physiological computing: A
  systematic review.
\newblock {\em National Science Open}, 2(1):20220023, 2023.

\bibitem{drwuSCIS2022}
Rui Bian, Lubin Meng, and Dongrui Wu.
\newblock {SSVEP}-based brain-computer interfaces are vulnerable to square wave
  attacks.
\newblock {\em Science China Information Sciences}, 65(4):140406, 2022.

\bibitem{drwuAP2023}
Xue Jiang, Lubin Meng, Siyang Li, and Dongrui Wu.
\newblock Active poisoning: efficient backdoor attacks on transfer
  learning-based brain-computer interfaces.
\newblock {\em Science China Information Sciences}, 66:182402, 2023.

\bibitem{drwuBackdoor2023}
Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping Jung,
  Chin-Teng Lin, Ricardo Chavarriaga, and Dongrui Wu.
\newblock {EEG}-based brain-computer interfaces are vulnerable to backdoor
  attacks.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  31:2224--2234, 2023.

\bibitem{drwuIF2024}
Lubin Meng, Xue Jiang, Xiaoqing Chen, Wenzhong Liu, Hanbin Luo, and Dongrui Wu.
\newblock Adversarial filtering based evasion and backdoor attacks to
  {EEG}-based brain-computer interfaces.
\newblock {\em Information Fusion}, 107:102316, 2024.

\bibitem{drwuNSR2021}
Xiao Zhang, Dongrui Wu, Lieyun Ding, Hanbin Luo, Chin-Teng Lin, Tzyy-Ping Jung,
  and Ricardo Chavarriaga.
\newblock Tiny noise, big mistakes: Adversarial perturbations induce errors in
  brain-computer interface spellers.
\newblock {\em National Science Review}, 8(4):nwaa233, 2021.

\bibitem{RAND2020}
Anika Binnendijk, Timothy Marler, and Elizabeth~M. Bartels.
\newblock {\em Brain-Computer Interfaces: {U.S.} Military Applications and
  Implications, An Initial Assessment}.
\newblock RAND Corporation, Santa Monica, CA, 2020.

\bibitem{drwuFGCS2023}
Lubin Meng, Xue Jiang, and Dongrui Wu.
\newblock Adversarial robustness benchmark for {EEG}-based brain-computer
  interfaces.
\newblock {\em Future Generation Computer Systems}, 143:231--247, 2023.

\bibitem{drwuABAT2024}
Xiaoqing Chen, Ziwei Wang, and Dongrui Wu.
\newblock Alignment-based adversarial training ({ABAT}) for improving the
  robustness and accuracy of {EEG}-based {BCIs}.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  32:1703--1714, 2024.

\bibitem{drwuBenchmark2024}
Xiaoqing Chen, Jiayu An, and Dongrui Wu.
\newblock Data alignment based adversarial defense benchmark for {EEG}-based
  bcis.
\newblock {\em Neural Networks}, 2024.
\newblock submitted.

\bibitem{drwuTCSS2023}
Kun Xia, Wlodzislaw Duch, Yu~Sun, Kedi Xu, Weili Fang, Hanbin Luo, Yi~Zhang,
  Dong Sang, Xiaodong Xu, Fei-Yue Wang, and Dongrui Wu.
\newblock Privacy-preserving brain-computer interfaces: A systematic review.
\newblock {\em IEEE Trans. on Computational Social Systems}, 10(5):2312--2324,
  2023.

\bibitem{GDPR2016}
{General Data Protection Regulation}.
\newblock Regulation ({EU}) 2016/679 of the {European} parliament and of the
  council of 27 {April} 2016 on the protection of natural persons with regard
  to the processing of personal data and on the free movement of such data, and
  repealing directive 95/46.
\newblock {\em Official Journal of the European Union}, 59(1-88):294, 2016.

\bibitem{drwuPrivacy2019}
Anisha Agarwal, Rafael Dowsley, Nicholas~D. McKinney, Dongrui Wu, Chin-Teng
  Lin, Martine De~Cock, and Anderson C.~A. Nascimento.
\newblock Protecting privacy of users in brain-computer interface applications.
\newblock {\em {IEEE} Trans. on Neural Systems and Rehabilitation Engineering},
  27(8):1546--1555, 2019.

\bibitem{Debie2020}
Essam Debie, Nour Moustafa, and Monica~T. Whitty.
\newblock A privacy-preserving generative adversarial network method for
  securing {EEG} brain signals.
\newblock In {\em Proc. Int'l Joint Conf. on Neural Networks}, pages 1--8,
  Glasgow, UK, July 2020.

\bibitem{Pascual2021}
Damin Pascual, Alireza Amirshahi, Amir Aminifar, David Atienza, Philippe
  Ryvlin, and Roger Wattenhofer.
\newblock {EpilepsyGAN}: Synthetic epileptic brain activities with privacy
  preservation.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 68(8):2435--2446, 2021.

\bibitem{Popescu2021}
Andreea~Bianca Popescu, Loana~Antonia Taca, Cosmin~Ioan Nita, Anamaria Vizitiu,
  Robert Demeter, Constantin Suciu, and Lucian~Mihai Itu.
\newblock Privacy preserving classification of {EEG} data using machine
  learning and homomorphic encryption.
\newblock {\em Applied Sciences}, 11(16):7360, 2021.

\bibitem{drwuTBME2022}
Kun Xia, Lingfei Deng, W.~Duch, and Dongrui Wu.
\newblock Privacy-preserving domain adaptation for motor imagery-based
  brain-computer interfaces.
\newblock {\em IEEE Trans. on Biomedical Engineering}, 69(11):3365--3376, 2022.

\bibitem{drwuMSDT2022}
Wen Zhang, Ziwang Wang, and Dongrui Wu.
\newblock Multi-source decentralized transfer for privacy-preserving {BCIs}.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  30:2710--2720, 2022.

\bibitem{drwuSFDA2023}
Changming Zhao, Ruimin Peng, and Dongrui Wu.
\newblock Source-free domain adaptation ({SFDA}) for privacy-preserving seizure
  subtype classification.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  31:2315--2325, 2023.

\bibitem{drwuLSFT2023}
Wen Zhang and Dongrui Wu.
\newblock Lightweight source free transfer for privacy-preserving unsupervised
  motor imagery classification.
\newblock {\em IEEE Trans. on Cognitive and Developmental Systems},
  15(2):938--949, 2023.

\bibitem{drwuFed2024}
Tianwang Jia, Lubin Meng, Siyang Li, Jiajing Liu, and Dongrui Wu.
\newblock Federated motor imagery classification for privacy-preserving
  brain-computer interfaces.
\newblock {\em IEEE Trans. on Neural Systems and Rehabilitation Engineering},
  32:3442--3451, 2024.

\bibitem{Shao2024}
Chenghao Shao, Chang Li, Rencheng Song, Xiang Liu, Ruobing Qian, and Xun Chen.
\newblock Machine unlearning for seizure prediction.
\newblock {\em IEEE Trans. on Cognitive and Developmental Systems},
  16(6):1969--1981, 2024.

\bibitem{drwuPrivacySMC2024}
Lubin Meng, Xue Jiang, Tianwang Jia, and Dongrui Wu.
\newblock Protecting multiple types of privacy simultaneously in {EEG}-based
  brain-computer interfaces.
\newblock In {\em Proc. {IEEE} Int'l Conf. on Systems, Man and Cybernetics},
  Kuching, Malaysia, October 2024.

\bibitem{drwuA3E2024}
Xiaoqing Chen, Tianwang Jia, and Dongrui Wu.
\newblock {A3E}: Aligned and augmented adversarial ensemble for accurate,
  robust and privacy-preserving {EEG} decoding.
\newblock {\em Science China Information Sciences}, 2024.
\newblock submitted.

\end{thebibliography}


\end{document}
