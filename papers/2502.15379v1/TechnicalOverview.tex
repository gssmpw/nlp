\section{Technical Overview}
\label{sec:tech-overview}
In this section, we give a broad overview of the techniques used in this work. We denote by $\numtriangle_\edge$ the number of triangles the edge $\edge$ participates in, and by $\degree{\edge}$ \remove{the degree of the vertex of smaller degree in the edge,} $=\degree{\fbrac{\altvertex,\vertex}} = \min{\sbrac{\degree{\altvertex},\degree{\vertex}}}$.

%\subsection{Upper Bound}
%\label{ssec:overview-upper-bound}
\paragraph*{Upper Bound.} Our starting point is to use the \randedgeq{} to obtain a random sample of edges $\samplededges$ and try to estimate the number of triangles $\numtriangle$ incident on the edges of $\samplededges$. However, an edge $\edge$ can participate in $\bigomega{\degree{\edge}}$ triangles. Thus, counting the number of triangles each edge participate in will be too expensive.  Also, $\numtriangle_\edge$ can grow up to $\bigomega{\numtriangle}$, requiring $\size{\samplededges}$ to be large to obtain a good estimate. To circumvent this issue, we consider only the edges that participate in $\leq \threshold$ triangles, called \emph{light edges}. We denote the edges that are not light to be \emph{heavy edges}. We call the triangles containing at least one light edge \emph{light triangles}, and the triangles consisting entirely of heavy edges to be \emph{heavy triangles}. Fixing the threshold $\threshold$ appropriately based on the arboricity $\arboricity$ of the graph will ensure that the number of light triangles $\lighttriangles{\threshold}$ is a sufficiently good approximation of the number of triangles, $\numtriangle$. For now, assume we are given access to an oracle \heavyoracle{} to decide whether an edge is light or heavy. However, this criteria may cause triangles to be sampled with different probabilities, depending on the number of light edges it contains. 

If we can design a way to assign each of the light triangles to one of its constituent light edges, we can sample all light triangles with equal probability. We define a valid weight function under which estimation of the sum of weight function over all edges gives us a good estimate of $\numtriangle$.
\remove{
If we can design a way to assign each of the light triangles to one of its constituent light edges, we can sample all light triangles with equal probability. We define a valid weight function, denoted $\weightfunc$ to be defined by such an assignment. Given a valid assignment, for an edge $\edge$, $\weightfunc(\edge)$ is the number of triangles assigned to the edge $\edge$. Under this definition, we have $\sum_{\edge \in \edgeset} \weightfunc(\edge) = \lighttriangles{\threshold}$, i.e. estimating the sum of weight function over all edges will give us a good estimate of $\numtriangle$. Observe that there can be many such valid assignments, and each valid assignment defines a valid weight function. Thus there can be many valid weight functions. Obtaining an estimate for any weight function will give us an estimate for $\numtriangle$.
}

To obtain this estimate, we obtain samples of triangles the light edges in $\samplededges$ participates in. We assign each sampled triangle to one of its constituent edges, ensuring that the assignment can be extended to a valid assignment, and hence a valid weight function. Based on this assignment, we obtain an estimate of the corresponding weight function, which, given an appropriately fixed threshold $\threshold$, will give an $\appcon$ estimate of $\numtriangle$.

To design the oracle $\heavyoracle{}$ for a given edge $\edge$, we estimate the number of triangles each edge participates in. This estimation can be made using i.i.d. draws. Hence, the heavy edges, having high probability of obtaining a triangle, can be well-approximated using sufficiently small number of queries. For the light edges, observe that lower number of triangles, i.e. lower probability of obtaining triangles, allows for high approximation error. We then design a bucketing trick to exploit this trade-off to implement an efficient algorithm to decide whether an edge is heavy or light.
\remove{
\red{
\begin{itemize}
    \item Highlight Conceptual Difference Compared to recent works (e.g. ~\citep{assadi2018simple, Dana_Ron_Triangle_Counting, DBLP:conf/soda/EdenRS20})
    \item Our analysis is much simpler compared to the only case of arboricity incorporating property testing algorithm~\citep{DBLP:conf/soda/EdenRS20}.
    \item Ours is the only case where heavy edge is defined purely in terms of number of triangles.
    \item Place the work in context of long list of works related to arboricity. Place the usage of random edge queries and subgraphs generated within that context.
\end{itemize}}

\begin{idea}[Broad Idea]
    The easiest approach would be to directly sample triangles through the edges. However, the samples(triangles) are not independent, and to use Chebyshev we need control on the variance. To do that, we need to eleminate \blue{heavy} edges that participates in too many triangles. This gives rise to two main problems:
    \begin{itemize}
        \item \textbf{Deciding Heavy:} We need to decide heavy edges, and correspondingly light edges through small ($\bigo{1}$) number of samples . Some light edges have very few triangles and thus difficult to control using Chernoff, even using additive Chernoff bound. We use the bucketed approximation to take care of this using the fact that low number of triangles allow higher approximation factor to design our oracle (See Lemma~\ref{Lemma: Heavy Oracle Algorithm Correctness}). 
        \item \textbf{Non-uniform Sample:} Sampling through light edges may cause the triangle to be sampled at disproportionate rates, depending on the number of light edges that it contains. We manage this issue by selecting a charging from each triangle to a constituent light edge of that triangle. The main idea is there are many such possible assignments and any such assignment would be fine for our purpose. We find such an assignment/weight function through finding a partial assignment that can be extended to a valid assignment.
    \end{itemize}
\end{idea}
}

%\subsection{Lower Bound}
%\label{ssec:overview-lower-bound}

\paragraph*{Lower Bound.} For our lower bound, we use the lower bound on number of samples required to solve the Popcount Thresholding Problem[\ptp{}] presented in~\citep{DBLP:conf/approx/AssadiN22}. We defer the details of this problem to Section~\ref{sec:lower-bound}. To establish the lower bound, we show that for any value of arboricity $\arboricity$, we can design a graph $\graph$ with arboricity $\arboricity$ such that finding an $\appcon$ estimate $\emptriangle$ of the number of triangles $\numtriangle$ of the graph using $\bigomega{\frac{\edgecount\arboricity\log{\fbrac{1/\confidence}}}{\approxerror^2\numtriangle}}$ queries would violate the lower bound of \ptp{}.