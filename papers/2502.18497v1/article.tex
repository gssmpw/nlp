\RequirePackage{etex}
\documentclass[12pt]{elsarticle}
\usepackage[utf8]{inputenc}

\usepackage{amsmath, amsthm, amssymb, stmaryrd, enumitem, array, float}
\usepackage{tikz, tikz-network}
\usepackage{algorithm, algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{color}
\usepackage{tablefootnote}
\usepackage[multiple]{footmisc}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\textwidth=165mm \textheight=237mm \oddsidemargin=4.6mm \topmargin=-7.4mm \headheight=0mm \headsep=0mm
\righthyphenmin=2
\sloppy

%------------------------------- New theorems

% These will be typeset in italics
%

% These will be typeset in Roman
\theoremstyle{definition}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\newtheorem{definition}{Definition}
\newtheorem{fact}{Fact}
\newtheorem{conjecture}{Conjecture}
\newtheorem*{problem}{Problem}
\newtheorem{example}{Example}

%------------------------------- Macros

\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\lstset{frame=tb,
  language=bash,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newcommand{\GG}{\mathcal{G}}
\newcommand{\CC}{\mathcal{C}}
\newcommand{\Del}{{\Delta}}
\newcommand{\dE}{{\Delta E}}
\newcommand{\pp}{\mathsf{p}}
\newcommand{\cc}{\mathsf{c}}
\newcommand{\ww}{\mathsf{w}}
\newcommand{\mm}{m}
\newcommand{\dd}{d}

\newcommand{\NN}{\mathcal{N}}
\newcommand{\EE}{\mathcal{E}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\WW}{\mathcal{W}}
\newcommand{\KK}{\mathcal{K}}
\newcommand{\VV}{\mathcal{V}}
\newcommand{\QQ}{\mathcal{Q}}
\newcommand{\TT}{\mathcal{T}}

%-------------------------------

% \journal{Expert Systems with Applications}

%-------------------------------

\begin{document}

\begin{frontmatter}

\title{A Parallel Hierarchical Approach for Community Detection on Large-scale Dynamic Networks}

\author[msu]{Grigoriy Bokov\corref{cor}}
\ead{bokovgrigoriy@gmail.com}
\cortext[cor]{Corresponding author.}

\author[msu]{Aleksandr Konovalov}
\ead{alexandr.konoval@gmail.com}

\author[msu]{Anna Uporova}
\ead{annuporova2003@gmail.com}

\author[msu]{Stanislav Moiseev}
\ead{stanislav.moiseev@gmail.com}

\author[hse]{Ivan Safonov}
\ead{isafonov27@gmail.com}

\author[mitl]{Alexander Radionov}
\ead{alex.radionov89@gmail.com}

\affiliation[msu]{
    organization={Lomonosov Moscow State University},
    addressline={1 Leninskiye Gory},
    city={Moscow},
    postcode={119991},
    country={Russia}}

\affiliation[hse]{
    organization={National Research University Higher School of Economics},
    addressline={11 Pokrovksy Bulvar},
    city={Moscow},
    postcode={109028},
    country={Russia}}

\affiliation[mitl]{
    organization={Moscow Infocommunication Technology Laboratory},
    addressline={1-75b Leninskiye Gory},
    city={Moscow},
    postcode={119234},
    country={Russia}}

\begin{abstract} 
In this paper, we propose a novel parallel hierarchical Leiden-based algorithm for dynamic community detection. The algorithm, for a given batch update of edge insertions and deletions, partitions the network into communities using only a local neighborhood of the affected nodes. It also uses the inner hierarchical graph-based structure, which is updated incrementally in the process of optimizing the modularity of the partitioning. The algorithm has been extensively tested on various networks. The results demonstrate promising improvements in performance and scalability while maintaining the modularity of the partitioning.
\end{abstract}

\begin{highlights}
\item A new parallel Leiden-based algorithm for dynamic community detection algorithm. 
\item The algorithm uses only a local neighborhood of the affected nodes.
\item A new hierarchical, incrementally updated graph-based structure for node coalitions.
\item Better performance while maintaining the modularity of the partitioning.
\item The parallel implementation shows no loss of modularity.
\end{highlights}

\begin{keyword}
Community detection \sep modularity \sep dynamic networks \sep parallel implementation
\end{keyword}

\end{frontmatter}

%----------------------------------------------------------------------------------------
\section{Introduction} \label{S:1}

Modern complex networks~\cite{N03}, a model for phenomena such as social communication, can reach enormous scales with complex time-varying structures consisting of many strongly interconnected components~\cite{SF09,POM09}, usually called communities. Their effective detection is an actual problem for Big Data tasks.

A broad family of community detection algorithms based on maximization of modularity~\cite{NG04}. This quality function shows how much a network differs from the random, and its optimization is an NP-hard problem~\cite{BDG08}. Many heuristic algorithms have been developed to overcome complexity, including hierarchical agglomeration~\cite{CNM04}, extremal optimization~\cite{DA05}, simulated annealing~\cite{RB06}, spectral algorithms~\cite{New06}, etc. (for a comparative analysis, see ~\cite{LF09,YAT16}).

One of the most well-known algorithms for optimizing modularity is the Louvain algorithm~\cite{BGL08}. It uses a two-stage approach, consisting of a local moving stage and an aggregation stage, to iteratively improve the modularity. Despite its popularity, the Louvain algorithm may yield arbitrarily badly connected communities. Another popular algorithm is the Leiden algorithm~\cite{TWE19}. It introduces an additional refinement stage between the local-moving and aggregation stages, which allows nodes to form subcommunities within the communities identified during the local-moving stage. This enables the Leiden algorithm to identify well-connected communities. However, applying the original Leiden algorithm, similar to the Louvain method, to huge dynamic networks has raised computational bottlenecks, mainly due to its inherently sequential and static nature~\cite{HKT17}. 

Many real-world networks are large-scale and dynamic. They have a large number of nodes and edges that change rapidly, and only a small number of them are added or removed over time. It is not efficient to treat an updated network as a completely new network and run the community detection algorithm again from the beginning. Instead, it is essential to monitor the evolution of communities incrementally as the network changes. In this regard, the dynamic community detection is one of the most challenging problems~\cite{RC17, HHC22}.

One straightforward strategy for dynamic community detection is to use the community membership of nodes from a previous snapshot of the network~\cite{AG10,CT13,SLX14,ZCL19}. Alternatively, more advanced techniques have been developed to reduce computational costs by identifying a smaller subset of the network that has been affected by changes, for example, updating only changed nodes~\cite{ATO15,YCF16}, processing nodes within a specified threshold distance of updated edges~\cite{HKK16}, using a dynamic modularity metric to recompute community memberships~\cite{MTL16}, or identifying a subset of nodes that are affected by changes in the network using delta modularity~\cite{ZK21}. Recently, a new approach called the Dynamic Frontier~\cite{SLu24,SLe24} has been proposed, which, upon receiving a batch update containing edge deletions and insertions, incrementally identifies and processes an approximate set of affected nodes incrementally. 

Most of the algorithms reported~\cite{AG10,CT13,ZCL19,MTL16,ZK21} are sequential. Parallel algorithms for network analysis on dynamic networks are an active area of research. Examples of parallel dynamic algorithms include those for updating centrality scores~\cite{STS23,SGG20}, maintaining shortest paths~\cite{KSB21,ZCY17}, and dynamic network coloring~\cite{BCH18,YQL17}. The only known parallel algorithm for dynamic community detection that we are aware of is the Dynamic Frontier~\cite{SLe24} based on GVE-Leiden~\cite{Sah23}, which is a parallel implementation of the Static Leiden algorithm.

In this report, we present our parallel implementation of the Leiden algorithm. It incorporates several optimizations, including the decoupling of movable nodes~\cite{SSF18}, a preallocated hierarchical graph-based data structure for the identification of node communities and the storage of the supernode graph during aggregation, the absence of hash tables for edge storage, the local moving and aggregation phases, and the prevention of unnecessary aggregations, allowing it to run significantly faster than existing implementations.

This article is organized as follows. In the next section, we give an overview of the literature on the community detection problem in large dynamic networks, and also describe some approaches that we will compare with our algorithm. In Section 3, we introduce the basic terminology and notation, define how we understand static and dynamic networks, and also recall the main stages of the Leiden algorithm, on which our algorithm is based. Next, we present our dynamic community detection algorithm in Section 4. Section 5 provides a detailed comparison of our algorithm with other solutions. Finally, Section 6 concludes with some final comments and suggestions for future research.

%----------------------------------------------------------------------------------------
\section{Related works} \label{S:2}
Classical static community detection algorithms recalculate all changes in the global network structure at each step, while dynamic approaches focus on identifying and tracking local changes within specific substructures. To improve efficiency, several approaches have been developed to solve the community detection problem in large dynamic networks.

One of the most common approaches for community detection in dynamic networks is to use a static algorithm based on the community membership of nodes from a previous snapshot of the network~\cite{AG10}. In this approach, nodes are assigned to communities based on the previous snapshot of the network and are processed regardless of the edge deletions and insertions in the batch update. The widely used implementation of the Leiden algorithm based on this approach is Leidenalg\footnote{https://github.com/vtraag/libleidenalg}. In addition to the relative flexibility, this implementation also scales well and can be used on networks with millions of nodes, as long as they can be stored in memory. The Leiden algorithm also supports multiplex partition optimization, enabling community detection on both positive and negative links~\cite{TB09}, as well as across multiple time slices~\cite{MRM10}. Furthermore, it allows partial partition optimization, where some community assignments can be fixed~\cite{ZBJ19}, providing greater flexibility in the analysis of complex networks.

In order to compare the accuracy of the modularity of dynamic algorithms, we also considered two static algorithms in the following scenario: after each batch update, a static algorithm runs on the entire network starting from a singleton partition. The first is Grappolo\footnote{https://github.com/ECP-ExaGraph/grappolo}. It is a parallel implementation of the Louvain algorithm that uses several heuristics to speed up the computation~\cite{LHK14}. It has a larger memory requirement and a slight loss in accuracy due to the random order in which the nodes are processed and the use of a different heuristic method. Additionally, the Grappolo algorithm allows the processing of large networks and has a distributed memory version available for extremely large datasets~\cite{GHT18}. The other is NetworKit\footnote{https://github.com/networkit/networkit}, a tool for high-performance network analysis. It supports large networks in the size range from thousands to billions of edges. It implements efficient graph algorithms that are parallelized to make use of parallel architectures. NetworKit includes the development of a parallel variant of the Louvain and Leiden algorithm~\cite{SM13}.

%Another approach is the Grappolo algorithm~\cite{HKT17}, which is a parallel implementation\footnote{https://github.com/ECP-ExaGraph/grappolo} of the Louvain algorithm that uses several heuristics to speed up computation~\cite{LHK14}. It may have a larger memory requirement and a slight loss in accuracy due to the random order in which the nodes are processed and the use of a different heuristic method. Additionally, the Grappolo algorithm allows the processing of large networks and has a distributed memory version available for extremely large datasets~\cite{GHT18}.

%Also, we mention the open-source tool\footnote{https://github.com/networkit/networkit} NetworKit~\cite{AGH23,SSM16} for high-performance network analysis that supports large networks in the size range from thousands to billions of edges. It implements efficient graph algorithms that are parallelized to make use of multicore architectures. NetworKit includes the development of a parallel variant of the Louvain and Leiden algorithm~\cite{SM13}.

A more efficient approach to identifying communities in dynamic graphs involves incremental expansion of the affected nodes of the network after receiving a batch of updates that include edge deletions and insertions. The newly developed Dynamic Frontier algorithm~\cite{SLe24} is a parallel implementation\footnote{https://github.com/puzzlef/leiden-communities-openmp-dynamic} of the Leiden algorithm (called DF-Leiden) that incrementally identifies and processes an approximate set of affected nodes. It follows a graph traversal-like process until the nodes' community assignments converge.

%There are various algorithms that optimize modularity. One such algorithm presented in \cite{ZB15} incrementally updates the local community of a seed set as the underlying network changes. This algorithm performs best when low-latency updates are required. The speedup achieved varies depending on the size of the local community, with larger communities performing relatively better. \cite{ZCL21} proposes DynaMo, an adaptive algorithm designed to maximize modularity gain incrementally while updating the community structure in dynamic networks. A comprehensive comparison of DynaMo with Louvain (a static algorithm) and 5 other dynamic algorithms was conducted in the experimental evaluation. Extensive experiments were conducted on 6 real-world and 10,000 synthetic networks.. It has been demonstrated that DynaMo surpasses all other five dynamic algorithms in terms of efficiency and is two to five times (on average) faster than the Louvain algorithm.

There are a variety of algorithms that use alternative methods to optimize modularity, such as stabilized label propagation~\cite{XCS13}, game theory~\cite{JX15}, local community detection~\cite{ZB15}, online iterative procedure~\cite{RPP17}, adaptive strategies~\cite{ZCL19} or node disassembly techniques~\cite{RKN24}. However, all of these methods have a number of significant drawbacks that prevent them from competing with faster and more precise algorithms for large dynamic networks.

Furthermore, there are often challenges with the efficient parallelization of dynamic algorithms. For example, load imbalance can lead to uneven workload distribution, which can cause certain processors to become idle, resulting in decreased efficiency. Another challenge is shared memory, as accessing shared memory by multiple threads requires coordination, which increases complexity and overhead. Additionally, scalability limitations can arise when adding more processors, as synchronization delays may not always improve performance. To address these challenges, some heuristics have been proposed to solve them in the Louvain algorithm using OpenMP multithreading~\cite{LHK14}. In addition, ideas have been suggested to parallelize and accelerate the Leiden algorithm without sacrificing the quality of the solution~\cite{US21,VTT19}. Specifically, the authors of~\cite{US21} describe a technique for parallelizing the local moving phase. This involves integrating a queue of active nodes into the Leiden algorithm and analyzing how the refinement phase can be carried out efficiently.

%----------------------------------------------------------------------------------------
\section{Preliminaries} \label{S:3}

Let $G = (V, E, W)$ be a directed graph, where $V \subseteq \mathbb{N}$ denotes the set of nodes, $E \subseteq V \times V$ denotes the set of edges, and $W = (w_{i,j}) \subseteq \mathbb{R}^2$ denotes the weights of the edges in the graph. We assume that each edge in the graph has a non-zero weight and each edge in an unweighted graph has the weight of one ($w_{i,j} = 1$). In the case of an undirected graph, we assume that $w_{i,j} = w_{j,i}$. In addition, we use $|V|$ to denote the total number of nodes and $|E|$ to denote the total number of edges called the \textit{graph size}. We also use $\mm = \sum_{i,j \in V} w_{i,j}$ to denote the total sum of the edge weights.

\subsection{Graph's Partitioning}

A \textit{partition} of $G$ is a set of communities $P = \{c_{1},\ldots ,c_{k}\}$, where each \textit{community} $c_i \subseteq V$ consists of a set of nodes such that $V = \bigcup_{i} c_i$ and $c_i \cap c_j = \emptyset$ for all $i \neq j$.
We call a partition $P$ \textit{singleton} if each community $c_i$ contains exactly one node.
For a given community $c \in P$, we denote the sum of weights of incoming and outgoing edges within $c$ as 
\begin{equation*}
  K_c^{in} = \sum_{i \in V, j \in c} w_{i,j} \ \text{ and } \ 
  K_c^{out} = \sum_{i \in c, j \in V} w_{i,j},
\end{equation*}
and the total edge weight of $c$ as $e_c = \sum_{i,j \in c} w_{i,j}$.

\subsection{Modularity}

Modularity is a metric used to measure the quality of a graph's partition. It is calculated as the difference between the fraction of edges within partition's communities and the expected fraction of edges if they were distributed randomly~\cite{Has17}. Modularity with higher values indicates better quality~\cite{BDG08}. Optimizing this function leads to the best possible partitioning~\cite{New04,TVN11}. The modularity $\QQ$ of a partition $P$ is defined as follows:
\begin{equation*}
  \QQ = \frac{1}{\mm} \sum_{c \in P} \left(e_c - \gamma \frac{K_c^{in}  K_c^{out}}{\mm} \right),
\end{equation*}
where $\gamma \geq 0$ is a \textit{resolution parameter}.

\subsection{Static vs Dynamic Graphs}

In accordance with~\cite{SLe24,ZK21}, a \textit{dynamic} graph is represented as a sequence of graphs $G_t$, where $G_t = (V_t, E_t, W_t)$ denotes the graph in a discrete time step $t \geq 0$, $V_t \subseteq V$, $E_t \subseteq E$, and $W_t = (w_{i,j}^t) \subseteq \mathbb{R}^2$. We consider a scenario where the changes between graphs $G_{t-1}$ and $G_t$ at consecutive time steps $t-1$ and $t$ are represented as a \textit{batch update}
\begin{equation*}
\Delta_t =  \{ (i,j,\delta_{i,j}) \mid i,j \in V, \delta_{i,j} \in \mathbb{R} \}
\end{equation*}
at time step $t$. This batch update is divided into a set of edge deletions 
\begin{equation*}
  E_{t-1} \setminus E_t = \{ (i,j) \mid i,j \in V,\ w_{i,j}^{t-1} + \delta_{i,j} = 0 \}
\end{equation*}
and a set of the next time step edges
\begin{equation*}
  E_t = \{ (i,j) \mid i,j \in V,\ w_{i,j}^{t} = w_{i,j}^{t-1} + \delta_{i,j} \neq 0 \}.
\end{equation*}
We associate a \textit{static} graph $G$ with a sequence of graphs $G_0, G_1$, where $G_0$ is an empty graph, and $G_1 = G$.

\subsection{Dynamic Community Detection}

Given a sequence of graphs $G_0,\ldots,G_l$ defined by a sequence of batch updates $\Delta_1,\ldots,\Delta_l$. A \textit{dynamic} community detection algorithm $A$ at each step $t \geq 1$ takes the graph $G_{t-1}$ with a partition $P_A(t-1)$ and a batch update $\Delta_t$ as input and returns a partition $P_A(t)$ of the graph $G_t$, where $P_A(0)$ is the singleton partition. Let $\QQ_A(t)$ be the modularity of the partition $P_A(t)$, and $\TT_A(t)$ the processing time\footnote{The processing time $\TT_A(t)$ is the computational complexity that describes the amount of computer time it takes to run an algorithm $A$.} of the algorithm $A$ called its \textit{complexity} at time step $t$.

Normally, the complexity of a dynamic algorithm depends on the size of the update of the graph $|\Delta_t|$, and tends to zero when $|\Delta_t|$ is close to zero. This makes it possible to control the processing time required for one batch update. Another good property is that the complexity of a dynamic algorithm does not depend on the size of the graph $|G_t|$, or depends only on it in logarithmic or $o(|G_t|)$ terms. This makes it possible to control the processing time required for one batch of data update without knowing the current graph size $|G_t|$. In addition, a dynamic algorithm that has this property in practice will be fast, no matter how large the original graph $G_t$ is. 

Let us call a dynamic algorithm $A$ \textit{local} if it uses only a limited neighborhood of modified nodes in $\Delta_t$ and $\TT_A(t)$ tends to zero when $|\Delta_t| \to 0$.

\subsection{Leiden algorithm}

The Leiden algorithm~\cite{TWE19} is a quite simple and elegant method that optimizes modularity through an iterative process that consists of three stages: (1) local movement of nodes, (2) refinement of the partition, and (3) aggregation of the network based on the refined partition. 

In the local moving stage, all nodes in the network are placed in a queue and sequentially moved to neighboring communities to maximize the gain in modularity from each node move. If a node's community has changed, its neighbors that do not belong to the new community will be added to the queue for further examination. This process continues until the queue becomes empty. If all communities become singletons (that is, they contain only one node), the algorithm stops and returns an improved partition of the network. Otherwise, the next stage of the algorithm is executed.

The main goal of the refinement stage is to improve the partition obtained in the previous stage by splitting each community into smaller, more well-connected parts. This process is similar to the Move stage, but with a few differences. Only edges within communities are considered, and a node can change its subcommunity only once. Each node is placed into a singleton subcommunity. All nodes are filtered under the condition that they should have sufficient connectivity to their parent communities. Filtered singleton subcommunities are merged with other subcommunities of the same community if the target subcommunity is well connected with the parent community and merging with the subcommunity gives the best modularity increase of the subcommunity.

In the aggregation stage, all the nodes of each refined subcommunity are merged into one node, so that all edges located within a subcommunity are transformed into self-loops with a weight equal to the sum of the weights of the merged edges. After the aggregation, the algorithm continues from the beginning, using the non-refined partition to create an initial partition for the aggregate network.

The Leiden algorithm offers several significant advantages. First, it stands out due to its ability to achieve a higher modularity compared to other algorithms, such as Louvain~\cite{LF09}. Secondly, the algorithm quickly reaches an optimal partition due to the division of communities into smaller subcommunities. This simplifies the network and reduces its complexity, allowing the algorithm to operate more efficiently.

%----------------------------------------------------------------------------------------
\section{Local Dynamic Leiden Algorithm} \label{S:4}

In this section, we will introduce the LD-Leiden algorithm, which is a local dynamic community detection algorithm based on the previously introduced Leiden algorithm~\cite{TWE19}. The LD-Leiden algorithm also takes advantage of the idea of decoupling local movement of nodes for better parallelism and efficient parallel implementation~\cite{SSF18}. 

The LD-Leiden algorithm performs several iterations of the inner Leiden algorithm consisting of three stages: local movement of the updated nodes and their neighbors, local refinement of the partition for the updated and moved nodes, and local aggregation of the network based on the refined partition. The LD-Leiden algorithm is significantly more complex than the Leiden algorithm. It uses an inner hierarchical graph-based structure that is updated incrementally at each stage. The algorithm is described in pseudocode in~\ref{app1} of the Supplementary Information.

The hierarchical inner structure of the LD-Leiden algorithm is a directed graph, denoted by $\mathcal{G}$, whose nodes are subsets of the nodes in the input graph $G$. The nodes of $\mathcal{G}$ are arranged by levels, and the edges can only connect nodes of the same level. The edges in $\mathcal{G}$ are inherited from $G$, and the weights of multiple edges between the same pair of nodes are added together. The nodes of level 0 are called \textit{ground} and the other nodes are called \textit{refined}. The ground nodes represent singleton sets of nodes in $G$, while the refined nodes correspond to sets of nodes that belong to the same community within $G$. Each node $v$ has a reference to the \textit{parent} node $u$ at the next level or to a community $c$ in $G$. In this regard, we claim that $v \subseteq u$ and $v \subseteq c$. The inner structure is schematically depicted in Fig.~\ref{fig:graph}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{graph.jpg}
\caption{Inner graph structure of the LD-Leiden algorithm. The green arrows on each level indicate which nodes are connected by edges. The gray lines represent the parent-child relationship.}
\label{fig:graph}
\end{figure}

To improve the parallelization of the LD-Leiden algorithm, we implemented the idea of decoupled local node movement~\cite{SSF18}. In the original sequential implementation of the Leiden algorithm, one node is selected, moved, and updated in each iteration. This allows the solution to converge, according to the modularity increase formula. In the decoupled approach, the nodes are selected and moved simultaneously and in parallel with their community labels. However, this can lead to breaking the convergence.
Decoupling is a technique that separates possible moves from other moves, limiting communities to only emitting or accepting nodes. This means that a community can only grow (by accepting nodes) or shrink (by emitting nodes). We used a greedy approach to decoupling, where we first collect all possible node moves in a distributed manner. Next, we sort these moves by decreasing the increments in modularity. Then, we mark the first move with the largest modularity increment as decoupled. Its current and new communities are then marked as emitter and acceptor, respectively.
Starting with the next move, we continue to mark moves as decoupled if they do not leave the acceptor communities of previously decoupled moves or enter the emitter communities of those moves. We also mark their current and new communities as emitters and acceptors, as described above.
After completing the marking of moves from the collection, we mark all moves from that collection as decoupled. Finally, we update the nodes' community labels in a distributed manner based on the discovered decoupled moves. The decouple process is schematically depicted in Fig.~\ref{fig:decouple}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{decouple.jpg}
\caption{Decouple process. The boundaries of communities are marked with dashed lines, and their nodes are painted in unique colors. Red crosses indicate the current nodes that are being considered. Red and dashed grey arrows show possible ways to move nodes to other communities. The labels of such arrows indicate modularity increments from the moving of nodes. The red arrows indicate the moves that will be applied.}
\label{fig:decouple}
\end{figure}

An inner Leiden iteration of the LD-Leiden algorithm is illustrated in Figure~\ref{fig:moving}. It is applied on each level of the inner hierarchical graph-based structure $\mathcal{G}$. The algorithm starts from a current partition and affected nodes (a) and finds decoupled moves in a distributed manner (b). The found nodes are moved in parallel simultaneously. After the move, the neighboring nodes of the moved ones are marked as affected and then the nodes that are suitable for moving are found from them. In this case, nodes and their neighbors are moved as long as the modularity increases. After moving individual nodes and their neighbors, we obtain a new partition of the graph nodes (c). The initially affected nodes, as well as the moved nodes and their neighbors, have been marked as affected. Next, the algorithm finds refining moves for the affected nodes in the same communities and applies the decoupling (d). The found moves are also applied simultaneously in parallel. Unlike moving nodes between communities, after the refinement, only the neighbors of the moved nodes from the same refined communities are marked as affected. After the refinement process, we obtain a new refined partition for each community with the affected nodes (e). Finally, aggregate nodes are created based on the refined partition by combining nodes with the same notches (f). The aggregate nodes form the nodes of the inner hierarchical graph-based structure $\mathcal{G}$ at the next level. The aggregate nodes that contain affected nodes are marked as affected. We use the non-refined partition for new aggregate nodes to create an initial partition for the aggregate graph at the next level. These steps are repeated until there are no more improvements that can be made or we have reached the maximum level specified by a user.

%Note that if we limit the maximum degree of the vertices in the graph to a fixed value $\dd$, then
The inner Leiden iteration uses a local neighborhood of the affected nodes, which consists of at most $\dd^{2M} q$ nodes.
Here,
$q$ is the number of nodes initially affected,
$M$ is the number of iterations in the process of moving and refinement,
and $\dd$ is the maximum degree of a node at the current level of the structure $\mathcal{G}$.
The computational complexity of the inner Leiden iteration is equal to $O\big(n \cdot (\dd + \log_2 n)\big)$,
where $n \le \dd^{2M} q$.
The proofs of the mathematical statements are provided in~\ref{app1}.


\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{moving.jpg}
\caption{An inner Leiden iteration of the LD-Leiden algorithm. The boundaries of communities are indicated by dashed lines, and their nodes are represented by unique colors. Refined communities are depicted by notches on the nodes. Nodes without notches represent singleton refined communities. Red crosses indicate the affected nodes, blue arrows represent the edges at the current level, and red arrows show possible ways to move nodes to other communities.}
\label{fig:moving}
\end{figure}

%----------------------------------------------------------------------------------------
\section{Experimental Results} \label{S:5}

\subsection{Experimental Environment}

In our experiments, we used a Huawei TaiShan 200 (model 2280) server equipped with a Kunpeng 920 5250 processor containing 2 x 48 cores. It operates at 2.6 GHz and is paired with 512 GB of DDR4 system memory, 2933 MT/s. Each core integrates a 64 KB L1 instruction cache, a 64 KB L1 data cache, a 512 KB L2 cache, and a 24576 KB L3 cache. The server runs on CentOS Linux 7 (AltArch).

We utilize the 32-bit unsigned integer format for node IDs and the 32-bit signed integer representation for edge weights. However, for total edge weight calculations, modularity computation, and any instances requiring aggregation or multiplication of 32-bit signed integer values, we employ the 64-bit signed integer and the 64-bit floating-point format. Note that our approach supports the floating-point format for representing edge weights. However, in experiments, the 32-bit signed integer representation was used to place huge datasets in available memory constraints.

The implementation used the C++17 threading library for parallelization. The only sequential step is the decoupling procedure. We use spin locks and atomic data types instead of slower mutexes. Compilation is carried out using GCC 10.2.1.

\subsection{Baseline Approaches}

For performance comparison, we selected the fastest static and dynamic algorithms based on the Louvain and Leiden algorithms with multithreading and shared memory support.
%For the dynamic case, we selected all release versions of algorithms that we managed to compile and build without errors.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|C{0.1\linewidth}|C{0.1\linewidth}|C{0.2\linewidth}|}
        \hline
        Solution& Base algorithm & Type & Multi-threaded & Directed graphs \\% & Weighted graphs \\ 
        \hline
        Grappolo & Louvain & Static & Yes & No \\% & Yes \\
        \hline
        NetworKit &  Louvain & Static & Yes & No \\% & Yes \\
        \hline
        % sLeidenalg &  Leiden & Static & No & Yes \\% & Yes \\
        % \hline
        Leidenalg &  Leiden & Dynamic & No & Yes \\% & Yes \\
        \hline
        DF-Leiden &  Leiden & Dynamic & Yes & No \\% & Yes \\
        \hline
        % Ndleiden &  Leiden & Dynamic & Yes & No \\% & Yes \\
        % \hline
        % Ddsleiden &  Leiden & Dynamic & Yes & No \\% & Yes \\
        % \hline
        %Mage & LabelRankT & Dynamic & No & Yes \\% & Yes \\
        %\hline
        LD-Leiden
\textit{(*this paper)}&  Leiden & Dynamic & Yes & Yes \\% & Yes \\
        \hline
    \end{tabular}

    \caption{Algorithm solutions selected for performance comparison}
    \label{T:1}
\end{table}

Leidenalg is a sequential implementation,
while the other solutions are parallel implementations of the Louvain/Leiden algorithm.
Leidenalg is static, but we use it dynamically by taking the final partition from the previous step and using it as the initial partition for the current step.
All solutions support weighted graphs.
Grappolo, NetworKit, and DF-Leiden do not support directed graphs.
LD-Leiden supports all types of graph.

Note that we have combined the C++ codes of all solutions into a unified benchmark and used a unified interface to initialize graph updates from a file. Since we have removed the original inner structure initialization for DF-Leiden, NetworKit, and Grappolo, we implemented our own interfaces to initialize and update the inner structure, which we did not take into account when calculating the total run-time for these solutions. In contrast, for LD-Leiden, we include the time it takes to update internal structures in the total runtime.

Since all solutions were based on the Leiden/Louvain algorithms, we used the same values for common parameters across all solutions. This included the number of aggregation phases and the number of iterations in the external phase.

\subsection{Experimental Networks}

To carry out experiments on large static and dynamic graphs,
we employ 12 large real-world graphs listed in Table~\ref{T:2},
obtained from the Koblenz Network Collection\footnote{http://doi.org/10.17616/R3SW65}
and the Stanford Large Network Dataset Collection\footnote{https://snap.stanford.edu}.
These graphs have between 28.1 thousand and 214 million nodes, and 3.15 million to 3.30 billion edges. 

For experiments involving real-world dynamic graphs, we use five temporal networks. The number of nodes in these networks ranges from 28.1 thousand to 3.22 million, with temporal edges ranging from 4.60 million to 63.5 million, and static edges ranging from 3.15 million to 40.0 million. However, these temporal graphs are too small, limiting their usefulness for studying our proposed parallel algorithm. Therefore, we also consider seven large static networks with hundreds of millions of nodes and billions of edges.

\begin{table}[H]
    \centering
    \small
    \begin{tabular}{|c|c|c|c|c|c|c|c|C{0.11\linewidth}|C{0.11\linewidth}|}
        \hline
        \textbf{Network} & $|V|$ & $|E|$ & $|E'|$ & $d_{max}$ & $d_{avr}$ & Directed & Timestamps \\
        \hline
        ca-cit-HepPh\tablefootnote{http://konect.cc/networks/ca-cit-HepPh}
            & 28.1K & 3.15M & 4.60M & 11K & 327 & No  & Yes\\
        wikipedia-growth\tablefootnote{http://konect.cc/networks/wikipedia-growth}
            & 1.87M & 40.0M & 40.0M & 227K & 43 & Yes  & Yes \\
        flickr-growth\tablefootnote{http://konect.cc/networks/flickr-growth}
            & 2.30M & 33.1M & 33.1M & 34K & 29 & Yes  & Yes \\ 
        sx-stackoverflow\tablefootnote{http://konect.cc/networks/sx-stackoverflow}
            & 2.60M & 36.2M & 63.5M & 195K & 49 & Yes  & Yes \\
        youtube-u-growth\tablefootnote{http://konect.cc/networks/youtube-u-growth}
            & 3.22M & 9.38M & 9.38M & 91K & 6 & No  & Yes \\
        
        com-orkut\tablefootnote{https://snap.stanford.edu/data/com-Orkut.html}
            & 3.07M & 117M & 117M & 33K & 76 & No  & No \\
        com-lj\tablefootnote{https://snap.stanford.edu/data/com-LiveJournal.html}
            & 4.00M & 34.7M & 34.7M & 15K & 17 & No  & No \\
        asia\_osm\tablefootnote{https://networkrepository.com/asia-osm.php}
            & 12.0M & 12.7M & 12.7M & 9 & 2 & No  & No \\
        europe\_osm\tablefootnote{https://networkrepository.com/europe\_osm.php}
            & 50.9M & 54.1M & 54.1M & 13 & 1 & No  & No \\
        
        friendster\tablefootnote{http://konect.cc/networks/friendster}
            & 68.4M & 2.59B & 2.59B & 7K & 76 & No  & No \\
        dimacs10-uk-2007-05\tablefootnote{http://konect.cc/networks/dimacs10-uk-2007-05}
            & 105M & 3.30B & 3.30B & 975K & 63 & No  & No \\
        kmer\_V1r\tablefootnote{https://sparse.tamu.edu/GenBank/kmer\_V1r}
            & 214M & 465M & 465M & 8 & 2 & No  & No \\
        \hline
    \end{tabular}
    \caption{Experimental Networks. Here, $|V|$ denotes the number of unique nodes, $|E|$ denotes the number of unique edges (excluding duplicates), $|E'|$ denotes the total number of temporal edges (including duplicates), and $d_{max}$ ($d_{avr}$) denotes maximum (average) node degree.}
    \label{T:2}
\end{table}

For each network that we consider, we divide all its edges into $10$, $100$ and $1000$ equal-length batch updates.
For networks with timestamps, we first sort the edges by their timestamps, and then, within each batch update, we randomly shuffle the edges.
In the case of static networks, we first shuffle the edges randomly.

\subsection{Performance in the single-threaded mode}

Due to the fact that static solutions such as Leidenalg and Grappolo can be quite slow when dealing with larger networks, we have limited our comparison to networks with a maximum of 200 million edges.
Figure~\ref{fig:runtime comparence} presents
the runtime of LD-Leiden, Leidenalg, DF-Leiden, NetworKit, and Grappolo on networks divided into 100 batches of equal length.
Figure~\ref{fig:runtime comparence} shows that LD-Leiden is significantly faster than all other solutions.
It achieves mean speed-ups $49{\times}$, $43{\times}$, $10{\times}$, $7{\times}$
for a given batch update, compared to Leidenalg, Grappolo, DF-Leiden, NetworKit, respectively.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_main_brief.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{wikipedia-growth}
    \includegraphics[width=\textwidth]{mini.wikipedia-growth.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{flickr-growth}
    \includegraphics[width=\textwidth]{mini.flickr-growth.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{sx-stackoverflow}
    \includegraphics[width=\textwidth]{mini.sx-stackoverflow.time.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.ca-cit-HepPh.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.youtube-u-growth.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.asia_osm.time.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.europe_osm.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.com-lj.time.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.com-orkut.time.jpeg}
\end{subfigure}
\caption{ Runtime in seconds (logarithmic scale) of the single-thread mode for LD-Leiden, Leidenalg, DF-Leiden, NetworKit, Grappolo for each batch update on the networks divided into 100 equal-length batches.}
\label{fig:runtime comparence}
\end{figure}

Figure~\ref{fig:modularity comparence}
shows the modularity of the communities obtained using each solution. The LD-Leiden algorithm achieves communities with a level of modularity similar to that of Leidenalg. On average, LD-Leiden obtains about 3\% higher modularity for the final communities compared to DF-Leiden and NetworKit and about 4\% higher modularity compared to Grappolo.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_main_brief.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{wikipedia-growth}
    \includegraphics[width=\textwidth]{mini.wikipedia-growth.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{flickr-growth}
    \includegraphics[width=\textwidth]{mini.flickr-growth.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{sx-stackoverflow}
    \includegraphics[width=\textwidth]{mini.sx-stackoverflow.modularity.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.ca-cit-HepPh.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.youtube-u-growth.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.asia_osm.modularity.jpeg}
\end{subfigure}
\par
\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.europe_osm.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.com-lj.modularity.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.com-orkut.modularity.jpeg}
\end{subfigure}
\caption{Modularity of the single-thread mode for LD-Leiden, Leidenalg, DF-Leiden, NetworKit, Grappolo for each batch update on the networks divided into 100 equal-length batches.}
\label{fig:modularity comparence}
\end{figure}

Detailed tables of experimental results are presented in~\ref{app2:1}.

\subsection{Dependence on batch update size}

We analyze the impact of batch size on runtime and modularity for the communities obtained after applying a series of batch updates to a graph. An ``ideal'' dynamic algorithm could potentially achieve an improvement in k-fold performance while reducing batch size by a factor of k. In contrast, a static algorithm would not see any significant improvement in this scenario. 

We vary the batch size for updating the graph as a fraction of the total size of the graph, using the following values: 1 (the entire graph), 0.1 (10\%), 0.01 (1\%) and 0.001 (0.1\%).
Note that Grappolo failed to work on the graphs asia\_osm and europe\_osm with batch size 0.1\% due to memory limitations.

Figure~\ref{runtime - varying batch updates size} shows that LD-Leiden is significantly better than the baseline solutions in this scenario, achieving an average performance improvement of $4.9{\times}$.
This is compared to Leidenalg ($1.5{\times}$), DF-Leiden ($1.8{\times}$), NetworKit ($1.1{\times}$) and Grappolo ($2.0{\times}$).

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_main_brief.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{wikipedia-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.wikipedia-growth.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{flickr-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.flickr-growth.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{sx-stackoverflow}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.sx-stackoverflow.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.ca-cit-HepPh.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.youtube-u-growth.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.asia_osm.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.europe_osm.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.com-lj.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.time.com-orkut.jpeg}
\end{subfigure}
\caption{Mean runtime in seconds (logarithmic scale) for each batch update when LD-Leiden and other solutions are applied in the single-threaded mode, depending on the size of the batch update (expressed as a fraction of the total graph size).}
\label{runtime - varying batch updates size}
\end{figure}

Figure~\ref{modularity - varying batch updates size} shows that LD-Leiden maintains its modularity on average when the graphs are divided into smaller batches. For all batch sizes considered, our algorithm shows a modularity comparable to that of static methods.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_main_brief.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{wikipedia-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.wikipedia-growth.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{sx-stackoverflow}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.sx-stackoverflow.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{flickr-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.flickr-growth.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.ca-cit-HepPh.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.youtube-u-growth.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.asia_osm.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.europe_osm.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.com-lj.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.batch_percent_size.modularity.com-orkut.jpeg}
\end{subfigure}
\caption{Modularity of the final communities obtained by LD-Leiden, Leidenalg, DF-Leiden, NetworKit, and Grappolo (the single-thread mode), depending on the size of the batch updates (expressed as a fraction of the total graph size).}
\label{modularity - varying batch updates size}
\end{figure}

Detailed tables of experimental results are presented in~\ref{app2:2}.

\subsection{Multi-threaded Scalability}

We evaluated the scalability of LD-Leiden by comparing it with other multithreaded algorithms: DF-Leiden, NetworKit, and Grappolo. Since DF-Leiden, NetworKit, and Grappolo currently do not support directed networks, this comparison will only be done for undirected networks. In this analysis, we varied the number of threads from 1 to 64, in increments of 2, for each input graph, and measured the total time taken to identify communities.

Note that Grappolo and NetworKit experienced problems with larger graphs. Both Grappolo and NetworKit were unable to run on the friendster and dimacs10-uk-2007-05 networks due to memory limitations. Additionally, Grappolo failed to work on the kmer\_V1r network, while NetworKit was able to run this network, but encountered memory problems in the 32- and 64-threaded modes.

Figure~\ref{fig: runtime Scaling} shows that LD-Leiden runs faster than all baseline solutions for each number of threads. In addition, on the networks asia\_osm, europe\_osm and kmer\_V1r, LD-Leiden runs faster in single-threaded mode than the baseline solutions in 64-threaded mode. For each number of threads, LD-Leiden achieves an average speedup of 4-7 times compared to DF-Leiden, an average speedup of 8-26 compared to NetworKit, and a speedup between 26 and 43 compared to Grappolo, respectively.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_4_col_4.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.threads.time.ca-cit-HepPh.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.threads.time.youtube-u-growth.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.threads.time.asia_osm.100.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.threads.time.europe_osm.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.threads.time.com-lj.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.threads.time.com-orkut.100.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{kmer\_V1r}
    \includegraphics[width=\textwidth]{mini.threads.time.kmer_V1r.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{friendster}
    \includegraphics[width=\textwidth]{mini.threads.time.friendster.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{dimacs10-uk-2007-05}
    \includegraphics[width=\textwidth]{mini.threads.time.dimacs10-uk-2007-05.100.jpeg}
\end{subfigure}
\caption{The mean runtime in seconds, on a logarithmic scale, for each batch update, when LD-Leiden and other solutions are applied to networks divided into 100 equal-length batches, is shown, depending on the number of threads used.}
\label{fig: runtime Scaling}
\end{figure}

Figure~\ref{fig: modularity Scaling}
shows that LD-Leiden achieves better modularity than the baseline methods for each number of threads.
DF-Leiden loses the modularity of the final communities for networks with a large maximum node degree, whereas LD-Leiden retains it.
On average, LD-Leiden achieves 2\% higher modularity than DF-Leiden in the 1 and 2 threaded modes,
3\% higher in the 4 and 8 threaded modes,
5\% higher in the 16 and 32 threaded modes, and
8\% higher in the 64 threaded mode.
As the number of threads used by NetworKit increases, the quality of the communities it produces improves.
However, LD-Leiden still achieves 2-4\% more modularity than NetworKit on average in the 1- to 8-threaded modes,
and 1\% higher in the 16 to 64-threaded modes.
On average, LD-Leiden achieves a 4\% higher modularity score than Grappolo for each number of threads.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
    %\caption*{Baseline}
    \centering
    \includegraphics[scale=0.7]{legend_4_col_4.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{ca-cit-HepPh}
    \includegraphics[width=\textwidth]{mini.threads.modularity.ca-cit-HepPh.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{youtube-u-growth}
    \includegraphics[width=\textwidth]{mini.threads.modularity.youtube-u-growth.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{asia\_osm}
    \includegraphics[width=\textwidth]{mini.threads.modularity.asia_osm.100.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{europe\_osm}
    \includegraphics[width=\textwidth]{mini.threads.modularity.europe_osm.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-lj}
    \includegraphics[width=\textwidth]{mini.threads.modularity.com-lj.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{com-orkut}
    \includegraphics[width=\textwidth]{mini.threads.modularity.com-orkut.100.jpeg}
\end{subfigure}

\begin{subfigure}{0.31\textwidth}
    \caption*{kmer\_V1r}
    \includegraphics[width=\textwidth]{mini.threads.modularity.kmer_V1r.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{friendster}
    \includegraphics[width=\textwidth]{mini.threads.modularity.friendster.100.jpeg}
\end{subfigure}
\hfill
\begin{subfigure}{0.31\textwidth}
    \caption*{dimacs10-uk-2007-05}
    \includegraphics[width=\textwidth]{mini.threads.modularity.dimacs10-uk-2007-05.100.jpeg}
\end{subfigure}
\caption{Modularity for the final communities is obtained when LD-Leiden and other solutions are applied to networks divided into 100 equal-length batches, depending on the number of threads used.}
\label{fig: modularity Scaling}
\end{figure}

The scalability of LD-Leiden is limited due to its internal hierarchical graph-based structure.
This structure leads to NUMA (NonUniform Memory Access) effects in the multithreaded mode.
On average, LD-Leiden achieves a performance improvement of $1.33{\times}$ for every doubling of the number of threads.
This is compared to DF-Leiden ($1.37{\times}$), NetworKit ($1.16{\times}$) and Grappolo ($1.34{\times}$).
Detailed tables of experimental results are presented in~\ref{app2:3}.

%----------------------------------------------------------------------------------------
\section{Conclusion} \label{S:6}

Community detection is an important task in the analysis of complex networks. Finding communities in large dynamic networks is far from trivial: algorithms need to be fast, but they also need to provide high-quality results. One of the most widely used algorithms is the Leiden algorithm~\cite{TWE19}. However, it can only be applied to the entire graph, even if the update affects only a small number of nodes. At the same time, newly developed algorithms~\cite{SLe24} for dynamic networks have not yet allowed us to achieve a level of modularity comparable to that of the Leiden algorithm.

To overcome the problem of large dynamic networks, we introduced a new algorithm, which we refer to as the LD-Leiden algorithm. This algorithm provides a number of explicit advantages. In particular, it can be applied to huge dynamic networks and partitions the network into communities using only a local neighborhood of the affected nodes. As shown by the experimental analysis presented in this paper, the algorithm has modularity comparable to the original Leiden algorithm and convincingly outperforms all other considered community detection algorithms for dynamic networks, both in terms
of speed and quality of the results, as well as scalability.
    
%----------------------------------------------------------------------------------------

%TODO: Проверить использование всех источников
%TODO: У    нифицировать ссылки на источники
\begin{thebibliography}{00}
    \bibitem{N03}
        Newman, M.E.J. (2003). The structure and function of complex networks. \textit{SIAM Review}, 45(2), 167--256. https://doi.org/10.1137/S003614450342480.
    \bibitem{SF09}
        Fortunato, S. (2010). Community detection in graphs. \textit{Physics Reports}, 486(3--5), 75--174. https://doi.org/10.1016/j.physrep.2009.11.002.
    \bibitem{POM09}
        Porter, M. A., Onnela, J.P., \& Mucha, P. J. (2009). Communities in Networks. \textit{Notices of the American Mathematical Society}, 56(9), 1082--1097. https://doi.org/10.48550/arXiv.0902.3788.
    \bibitem{BDG08}
        Brandes, U., Delling, D., \& Gaertler M. et al. (2008). On Modularity Clustering. \textit{IEEE Transactions on Knowledge and Data Engineering}, 20(2), 172--188. https://doi.org/10.1109/TKDE.2007.190689.
    \bibitem{CNM04}
        Clauset, A., Newman, M.E.J., \& Moore C. (2004). Finding community structure in very large networks. \textit{Physical Review E}, 70(6), 066111. https://doi.org/10.1103/PhysRevE.70.066111.
    \bibitem{DA05}
        Duch, J., Arenas, A. (2005). Community detection in complex networks using extremal optimization. \textit{Physical Review E}, 72(2), 027104. https://doi.org/10.1103/PhysRevE.72.027104.
    \bibitem{New06}
        Newman, M.E.J. (2006). Finding community structure in networks using the eigenvectors of matrices. \textit{Physical Review E}, 74(3), 036104. https://doi.org/10.1103/PhysRevE.74.036104.
    \bibitem{LF09}
        Lancichinetti, A., Fortunato, S. (2009). Community detection algorithms: A comparative analysis. Physical Review E, 80 (5), 056117. https://doi.org/10.1103/PhysRevE.80.056117.
    \bibitem{YAT16}
        Yang, Z., Algesheimer, R., \& Tessone, C. J. (2016). A Comparative Analysis of Community Detection Algorithms on Artificial Networks. \textit{Scientific Reports}, 6, Article 30750. https://doi.org/10.1038/srep30750.
    \bibitem{BGL08}
        Blondel, V., Guillaume, J., Lambiotte, R., \& Lefebvre, E. (2008). Fast unfolding of communities in large networks. \textit{Journal of Statistical Mechanics: Theory and Experiment}, P10008. https://doi.org/10.1088/1742-5468/2008/10/P10008.
    \bibitem{TWE19}
        Traag, V. A., Waltman, L., Van Eck, N.J. (2019). From Louvain to Leiden: guaranteeing well-connected communities. \textit{Scientific reports}, 9, Article 5233. https://doi.org/10.1038/s41598-019-41695-z.
    \bibitem{HKT17}
        Halappanavar, M., Lu, H., Kalyanaraman, A., \& Tumeo, A. (2017). Scalable static and dynamic community detection using Grappolo. \textit{Proceedings of the IEEE High Performance Extreme Computing Conference (HPEC)}, 1--6. https://doi.org/10.1109/HPEC.2017.8091047.
    \bibitem{NG04}
        Newman, M.E.J., Girvan, M. (2004). Finding and evaluating community structure in networks. \textit{Physical Review E}, 69(2), 026113. https://doi.org/10.1103/PhysRevE.69.026113.
    \bibitem{RC17}
        Rossetti, G., Cazabet, R. (2017). Community Discovery in Dynamic Networks: A Survey. \textit{ACM Computing Surveys}, 51(2), 1--37. https://doi.org/10.1145/3172867.
    \bibitem{HHC22}
        Hanauer, K., Henzinger, M., \& Schulz, Ch. (2022). Recent Advances in Fully Dynamic Graph Algorithms – A Quick Reference Guide. \textit{ACM J. Exp. Algorithmics}, 27, 1--45. https://doi.org/10.1145/3555806.
    \bibitem{AG10}
        Aynaud, T., Guillaume, J. (2010). Static community detection algorithms for evolving networks. WiOpt'10: Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, May 2010, Avignon, France. pp.508--514. https://inria.hal.science/inria-00492058v1.
    \bibitem{CT13}
        Chong, W., Teow, L. (2013). An incremental batch technique for community detection. \textit{Proceedings of the IEEE 16th International Conference on Information Fusion}, pp. 750--757.
    \bibitem{SLX14}
        Shang, J., Liu, L., Xie, F., Chen, Z., Miao, J., Fang, X., \& Wu, C. (2014). A real-time detecting algorithm for tracking community structure of dynamic networks. \textit{arXiv preprint}. https://doi.org/10.48550/arXiv.1407.2683.
    \bibitem{ZCL19}
        Zhuang, D., Chang, J., \& Li, M. (2019). DynaMo: Dynamic community detection by incrementally maximizing modularity. \textit{IEEE Transactions on Knowledge and Data Engineering}, 33(5), 1934--1945. https://doi.org/10.1109/TKDE.2019.2951419.
    \bibitem{ATO15}
        Aktunc, R., Toroslu, I., Ozer, M., \& Davulcu, H. (2015). A dynamic modularity based community detection algorithm for large-scale networks: DSLM. \textit{Proceedings of the IEEE/ACM international conference on advances in social networks analysis and mining}, pp.1177--1183. https://doi.org/10.1145/2808797.2808822.
    \bibitem{YCF16}
        Yin, S., Chen, S., Feng, Z., Huang, K., He, D., Zhao, P., \& Yang, M. (2016). Node-grained incremental community detection for streaming networks. \textit{Proceedings of the IEEE 28th International Conference on Tools with Artificial Intelligence (ICTAI)}, pp.585--592. https://doi.org/10.1109/ICTAI.2016.0095.
    \bibitem{HKK16}
        Held, P., Krause, B., \& Kruse, R. (2016). Dynamic clustering in social networks using louvain and infomap method. \textit{Proceedings of the IEEE Third European Network Intelligence Conference (ENIC)}, pp.61–68. https://doi.org/10.1109/ENIC.2016.017.
    \bibitem{MTL16}
        Meng, X., Tong, Y., Liu, X., Zhao, S., Yang, X., \& Tan, S. (2016). A novel dynamic community detection algorithm based on modularity optimization. \textit{Proceedings of the IEEE 7th international conference on software engineering and service science (ICSESS)}, pp.72–75. https://doi.org/10.1109/ICSESS.2016.7883018.
    \bibitem{ZK21}
        Zarayeneh, N., Kalyanaraman, A. (2021). Delta-Screening: A Fast and Efficient Technique to Update Communities in Dynamic Graphs. \textit{IEEE transactions on network science and engineering}, 8(2), 1614--1629. https://doi.org/10.1109/TNSE.2021.3067665.
    \bibitem{SLu24}
        Sahu, S. (2024). DF Louvain: Fast Incrementally Expanding Approach for Community Detection on Dynamic Graphs. \textit{arXiv preprint}. https://doi.org/10.48550/arXiv.2404.19634.
    \bibitem{SLe24}
        Sahu, S. (2024). A Starting Point for Dynamic Community Detection with Leiden Algorithm. \textit{arXiv preprint}. https://doi.org/10.48550/arXiv.2405.11658.
    \bibitem{STS23}
        Regunta, S., Tondomker, S., Shukla, K., \& Kothapalli, K. (2023). Efficient parallel algorithms for dynamic closeness-and betweenness centrality. \textit{Concurrency and Computation: Practice and Experience}, 35(17), e6650. https://doi.org/10.1002/cpe.6650.
    \bibitem{SGG20}
        Shao, Z., Guo, N., Gu, Y., Wang, Z., Li, F., \& Yu, G. (2020). Efficient closeness centrality computation for dynamic graphs. \textit{Database Systems for Advanced Applications}, pp.534--550. https://doi.org/10.1007/978-3-030-59416-9\_32.
    \bibitem{KSB21}
        Khanda, A., Srinivasan, S., Bhowmick, S., Norris, B., \& Das, S. (2021). A parallel algorithm template for updating single-source shortest paths in large-scale dynamic networks. \textit{IEEE TPDS}, 33(4), 929–940. https://doi.org/10.1109/TPDS.2021.3084096.
    \bibitem{ZCY17}
        Zhang, X., Chan, F.T., Yang, H., \& Deng, Y. (2017). An adaptive amoeba algorithm for shortest path tree computation in dynamic graphs. \textit{Information Sciences}, 405, 123--140. https://doi.org/10.1016/j.ins.2017.04.021.
    \bibitem{BCH18}
        Bhattacharya, S., Chakrabarty, D., Henzinger, M., \& Nanongkai, D. (2018). Dynamic algorithms for graph coloring. \textit{Proceedings of the 29th ACM-SIAM SODA}, pp.1--20. https://doi.org/10.1137/1.9781611975031.1.
    \bibitem{YQL17}
        Yuan, L., Qin, L., Lin, X., Chang, L., \& Zhang, W. (2017). Effective and efficient dynamic graph coloring. \textit{Proceedings of the VLDB Endowment}, 11(3), 338--351. https://doi.org/10.14778/3157794.3157802.
    \bibitem{Sah23}
        Sahu, S. (2023v). GVE-Leiden: Fast Leiden Algorithm for Community Detection in Shared Memory Setting. \textit{arXiv preprint}. https://doi.org/10.48550/arXiv.2312.13936.
    \bibitem{SSF18}
        Smirnov, V.V., Slesarenko, A.V., \& Filippov, A.N. (2018). Systems and methods of hierarchical community detection in graphs. Patent WO 2018/222064 A1, PCT/RU2017/000365.
     \bibitem{GHT18}
        Ghosh, S., Halappanavar, M., Tumeo, A., et al. (2018). Distributed Louvain Algorithm for Graph Community Detection. \textit{Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, pp.885--895. https://doi.org/10.1109/IPDPS.2018.00098.
    \bibitem{RPP17}
        Rossetti, G., Pappalardo, L., Pedreschi, D., et. al. (2017). Tiles: an online algorithm for community discovery in dynamic social networks. \textit{Machine Learning}, 106(8), 1213--1241. https://doi.org/10.1007/s10994-016-5582-8.
    \bibitem{JX15}
        Jiang, F., Xu, J. (2015). Dynamic community detection based on game theory in social networks. \textit{Proceedings of the IEEE International Conference on Big Data (Big Data)}, pp.2368--2373. https://doi.org/10.1109/BigData.2015.7364029.
    \bibitem{XCS13}
        Xie, J., Chen, M., \& Szymanski, B.K. (2013). LabelRankT: incremental community detection in dynamic networks via label propagation. \textit{DyNetMM: the Workshop on Dynamic Networks Management and Mining}, pp.25--32. https://doi.org/10.1145/2489247.2489249.
    \bibitem{ZB15}
        Zakrzewska, A., Bader, D.A. (2015). A Dynamic Algorithm for Local Community Detection in Graphs. \textit{Proceedings of the IEEE/ACM International Conference}, pp.559–564. https://doi.org/10.1145/2808797.2809375.
    \bibitem{RKN24}
        Rustamaji, H.C., Kusuma, W.A., Nurdiati, S. et al. (2024). Community detection with Greedy Modularity disassembly strategy. \textit{Scientific Reports}, 14, Article 4694. https://doi.org/10.1038/s41598-024-55190-7.
    \bibitem{LHK14}
        Lu, H., Halappanava, M., \& Kalyanaraman, A. (2015). Parallel Heuristics for Scalable Community Detection. \textit{Parallel Computing}, 47, 19--37. https://doi.org/10.1016/j.parco.2015.03.003.
    \bibitem{US21}
        Ueckerdt, T., Sanders, P., et al. (2021). Leiden-Based Parallel Community Detection. \textit{Zenodo preprint}. https://doi.org/10.5281/zenodo.5544283.
    \bibitem{Has17}
        Hofstad, R. (2017). \textit{Random Graphs and Complex Networks. Vol. 1.} New York: Cambridge University Press, 321 pages, ISBN: 978-1-107-17287-6.
    \bibitem{New04}
        Newman, M. (2004). Detecting community structure in networks. \textit{The European Physical Journal B}, 38(2), 321--330. https://doi.org/10.1140/epjb/e2004-00124-y.
    \bibitem{TVN11}
        Traag, V.A., Van Dooren, P., \& Nesterov, Y. (2011). Narrow scope for resolution-limit-free community detection. \textit{Physical Review E}, 84(1), 016114. https://doi.org/10.1103/PhysRevE.84.016114.
    \bibitem{VTT19}
        Verweij, G., Takes, F., \& Traag, V. (2020). Faster Community Detection Without Loss of Quality: Parallelizing the Leiden Algorithm. Master's Thesis. Leiden University, 2020.
    \bibitem{RB06}
        Reichardt, J., Bornholdt, S. (2006). Statistical mechanics of community detection. \textit{Physical Review E}, 74(1), 016110. https://doi.org/10.1103/PhysRevE.74.016110.
    \bibitem{TB09}
        Traag, V.A., Bruggeman, J. (2009). Community detection in networks with positive and negative links. \textit{Physical Review E}, 80(3), 036115. https://doi.org/10.1103/PhysRevE.80.036115.
    \bibitem{MRM10}
        Mucha, P.J., Richardson, T., Macon, K., et al. (2010). Community structure in time-dependent, multiscale, and multiplex networks. \textit{Science}, 328(5980), 876--878. https://doi.org/10.1126/science.1184819.
    \bibitem{ZBJ19}
        Zanini, F., Berghuis, B.A., Jones, R.C., et al. (2020). Northstar enables automatic classification of known and novel cell types from tumor samples. \textit{Scientific Reports}, 10, Article 15251. https://doi.org/10.1038/s41598-020-71805-1.
    \bibitem{SM13}
        Staudt, C., Meyerhenke, H. (2013). Engineering high-performance community detection heuristics for massive graphs. \textit{Proceedings of the IEEE ICPP}, pp.180--189. https://doi.org/10.1109/ICPP.2013.27.
\end{thebibliography}

   
%----------------------------------------------------------------------------------------
\newpage
\appendix
\section{Pseudocode and mathematical notation}
\label{app1}

The LD-Leiden algorithm is based on the following parameters:
\begin{itemize}
    \item $\gamma\in\mathbb{R}$ is a modularity resolution parameter whose meaning is the same as in the original Leiden algorithm.
    \item $L \geq 1$ is the maximum number of levels in the inner hierarchical graph-based structure.
    \item $N \geq 1$ is the number of iterations of the inner Leiden algorithm (algorithm~\ref{alg:LD-Leiden}).
    \item $M \geq 1$ is the number of iterations in the Move Stage (algorithm~\ref{alg:MoveStage}) and in the Refine Stage (algorithm~\ref{alg:RefineStage}).
    \item $\alpha\in\mathbb{R}$,  $0 \leq \alpha < 1$,
    is the threshold for improving modularity in the inner loop of the Move Stage (algorithm~\ref{alg:MoveStage}).
    \item $\beta\in\mathbb{R}$, $0 \leq \beta < 1$,
    is the threshold for the proportion of moved nodes compared to all nodes considered in the inner loop of the Move Stage (algorithm~\ref{alg:MoveStage})
    and in the inner loop of the Refine Stage (algorithm~\ref{alg:RefineStage}).
\end{itemize}
In our experiments, we used the resolution parameter $\gamma=1$ and the following settings:
$N = 2$, $L = 4$, $M = 5$, $\alpha = 0.001$ and $\beta = 0.01$.

The hierarchical inner structure of the LD-Leiden algorithm is a directed graph $\GG$ such that each node $u$ in $\GG$ represents a subset $V_u$ in the input graph $G$.
The nodes of $\GG$ are arranged by levels, and the edges can only connect nodes of the same level.
Nodes on the same level represent disjoint sets.
The level of a node $u$ is denoted by $l(u)$.
%The set of all nodes of a level $l$ we denote by $\VV_l$.
The nodes of level $0$ are called \textit{ground}, and the other nodes are called \textit{refined} or \textit{community}.
The ground nodes represent the singleton sets of nodes in $G$, 
while the community nodes correspond to subsets in $G$ that are considered communities.
The refined nodes represent subcommunities within these communities.
The set of ground nodes and community nodes are denoted by $\VV_{ground}$ and $\VV_{top}$, respectively.

Each node $u$ has a reference either to the \textit{parent} node $p$ at the next level or to a community node $c$.
In this regard, we claim that $V_u \subseteq V_{p}$ and $V_u \subseteq V_{c}$.
We denote the parent node of $u$ by $\pp(u)$, if it exists.
Thus, for each node $u$ in $\GG$,
there is a unique community node $c$ and a unique (possibly empty) chain of refined nodes $p_1 = \pp(u), ..., p_k = \pp(p_{k-1})$
such that $p_k$ has a reference to the community node $c$.
We denote the community node $c$ by $\cc(u)$.
We do not store the value of $\cc(u)$ permanently for each node $u$.
Instead, we calculate the chain of nodes $p_1, ..., p_k$ once when necessary
and then save and reuse the value of $\cc(u)$ until the next aggregation phase.


The weight of an edge $(u, v)$ in $\GG$ is denoted by
\begin{equation*}
\ww(u, v) = \sum_{i \in V_u, j \in V_v} w_{i,j}.
\end{equation*}
We store the weights of all edges in $\GG$. Denote by 
\begin{equation*}
  K_u^{in} = \sum_{i \in V, j \in V_u} w_{i,j} \ \text{ and } \ 
  K_u^{out} = \sum_{i \in V_u, j \in V} w_{i,j}.
\end{equation*}
the sum of the weights of the incoming and outgoing edges in $V_u$.
For each node $u$ of the graph $\GG$, we store the values $K_{u}^{in}$ and $K_{u}^{out}$.
The set of all neighbors for a node $u$ in $\GG$ is denoted by $\NN_u$.
We denote the set of all the incoming and outgoing edges in $\GG$ incident to a node $u$ as $\EE_u$.

The \textsc{modularity} $\QQ$ of the partition $\{V_c \mid c \in \VV_{top}\}$ in $G$ is equal to
\begin{equation*}
    \frac{1}{\mm} \WW  - \frac{\gamma}{\mm^2} \KK,
\end{equation*}
where
\begin{itemize}
    \item $\mm = \sum_{u,v \in \VV_{ground}} \ww(u, v) = \sum_{i,j \in V} w_{i,j}$ is the total sum of edge weights in $G$;
    \item $\WW = \sum_{c \in \VV_{top}} \ww(c, c)$ is the sum of $\ww(c, c)$ for all community nodes $c$ in $\GG$;
    \item $\KK = \sum_{c \in \VV_{top}} K_{c}^{in} K_{c}^{out}$ is the sum of $K_{c}^{in} \cdot K_{c}^{out}$ for all community nodes $c$ in $\GG$.
\end{itemize}
We store the numbers $\mm,\ \WW,\ \KK$. This allows us to recalculate the modularity locally only for changed communities.

Let $\dd$ be the maximum degree of the node in the graph $\GG$.
The value of $\dd$ is an important factor that affects the computational complexity of our method.
In a real-world scenario, $\dd$ does not exceed the maximum degree of the node in the input graph $G$.

\begin{algorithm}[H]
    \caption{LD-Leiden}
    \begin{algorithmic}[1]
    \Function{LD-Leiden}{BatchUpdate $\Delta G$}
        \State $V_0,\ \Del \gets$ \textsc{UpdateGround}($\Delta G$)
        \For{$i \gets 1, \ldots, N$}
            \State $U \gets V_0$
            \For{$l \gets 0, \ldots, L-1$}
                \State $\Del \gets$ \textsc{Up}($\Del$)
                \State $U,\ \Del \gets$ \textsc{MoveStage}($U$, $\Del$)
                \State $U,\ \Del \gets$ \textsc{RefineStage}($U$, $\Del$)
                \State $U \gets \{\pp(u) \mid u \in U \}$
            \EndFor
            \State $U,\ \Del \gets$ \textsc{MoveStage}($U$, $\varnothing$)
            \State $\Del \gets \varnothing$
        \EndFor
        \State \textbf{return} $\{V_c \mid c \in \VV_{top}\}$
    \EndFunction
    \end{algorithmic}
    \label{alg:LD-Leiden}
\end{algorithm}


\begin{algorithm}[H]
    \caption*{The function \textsc{UpdateGround}($\Delta G$) apply the batch update $\Delta G$ to the level $0$ of the graph $\GG$,
creates new community nodes for the new nodes in $\Delta G$ and adds edges for these community nodes. }
    \begin{algorithmic}[1]
    \Function{UpdateGround}{BatchUpdate $\Delta G$}
        \State $V_0 \gets \{\{i\} \mid (i, j, w) \in \Delta G \text{ or } (j, i, w) \in \Delta G \text{ for some } j, w\}$
        \State $V_{new} \gets V_0 - \VV_{ground}$
        \State $V_{old} \gets V_0 \cap \VV_{ground}$
        \State $\CC_1 \gets \{ \cc(v) \mid v \in V_{old}\}$
        \State $\WW_1 \gets \sum\limits_{c \in C_1} \ww(c, c)$
        \State $\KK_1 \gets \sum\limits_{c \in C_1} K_{c}^{in} K_{c}^{out}$ 
        \For{$v \in V_{new}$}
            \State \textsc{AddGroundNode}($v$)
            \State $c \gets$ \textsc{AddCommunityNode}()
            \State \textsc{SetReferenceToCommunity}($v$, $c$)
        \EndFor
        \State $\Del \gets$ empty list
        \For{$(i, j, w) \in \Delta G$}
            \State $u,\ v \gets \{i\}, \{j\}$
            \State $\Del \gets \Del + (u, v, w)$
            \State \textsc{SetEdge}\big($(u, v)$, $\ww(u, v) + w$\big)
            \State $K^{out}_{u},\ K^{in}_{v} \gets K^{out}_{u} + w$,\ $K^{in}_{v} + w$
            \State $c,\ b \gets \cc(u),\ \cc(v)$
            \State \textsc{SetEdge}\big($(c, b)$, $\ww(c, b) + w$\big)
            \State $K^{out}_{c},\ K^{in}_{b} \gets K^{out}_{c} + w$,\ $K^{in}_{b} + w$
        \EndFor
        \State $\CC_2 \gets \{ \cc(v) \mid v \in V_{old} \cup V_{new}\}$
        \State $\WW_2 \gets \sum\limits_{c \in C_2} \ww(c, c)$
        \State $\KK_2 \gets \sum\limits_{c \in C_2} K_{c}^{in} K_{c}^{out}$
        \State $\mm \gets \mm + \sum_{(u, v, w) \in \Del}\, w$
        \State $\WW \gets \WW + (\WW_2 - \WW_1)$
        \State $\KK \gets \KK + (\KK_2 - \KK_1)$
        \State \textbf{return} $V_0$,\ $\Del$
    \EndFunction
    \end{algorithmic}
\end{algorithm}
The function \textsc{AddGroundNode}(v) adds the new node $v$ to the level $0$ of the graph $\GG$.
The function \textsc{AddCommunityNode}() adds a new community node to the graph $\GG$ at level $l$.
For all new nodes $u$ the values $K^{in}_u$ and $K^{out}_u$ are set to $0$.
The function \textsc{SetParent}($v$, $v'$) assigns node $v'$ as the parent node for $v$.
The function \textsc{SetParent}($v$, $v'$) remove the reference to the old parent node for $v$, if it exists.
The function \textsc{SetReferenceToCommunity}($v$, $v'$) set the reference from the node $v$ to the community node $v'$.
The function \textsc{SetReferenceToCommunity}($v$, $v'$) remove the reference to the old community node for $v$, if it exists.
The function \textsc{SetEdge}($(u, v)$, $w$) adds a new edge with weight $w$ between the nodes $u$ and $v$ in the graph $\GG$.
If there is already an edge between these nodes, the function updates the weight of the existing edge to the new value $w$.

%It is evident that $m \leq dn$.
The computational complexity of \textsc{UpdateGround}($\Delta G$) is equal to
\begin{equation*}
O\big(|\Delta G| + n + n + Ln + n + n + n + |\Delta G| + Ln + n + n + |\Delta G|\big) =
O\big(Ln + |\Delta G|\big),
\end{equation*}
where $n$ is the number of unique nodes in $\Delta G$.

\begin{algorithm}[H]
    \caption*{The function \textsc{Up}($\Del$) aggregates the nodes and the edges in the update $\Del$,
    adding new parent nodes to the graph $\GG$ if necessary.}
    \begin{algorithmic}[1]
    \Function{Up}{Update $\Del$}
        \State $V_{touched} \gets \{u \mid (u, v, w) \in \Del \text{ or } (v, u, w) \in \Del \text{ for some } v, w\}$
        \State $V_{new} \gets \{u \in V_{touched} \mid \pp(u) \text{ is not define}\}$
        \For{$u \in V_{new}$}
            \State $p \gets$ \textsc{AddNode}($l(u)+1$)
            \State \textsc{SetParent}($u$, $p$)
            \State \textsc{SetReferenceToCommunity}($p$, $\cc(u)$)
        \EndFor
        \State $E \gets$ empty dictionary
        \For{$(u, v, w) \in \Del$}
            \State $p,\ q \gets \pp(u),\ \pp(v)$
            \If{$\langle p, q\rangle \not\in E$}
                \State $E(p, q) \gets w$
            \Else
                \State $E(p, q) \gets E(p, q) + w$
            \EndIf
            \State \textsc{SetEdge}($(p, q)$, $\ww(p, q) + w$)
            \State $K^{out}_{p},\ K^{in}_{q} \gets K^{out}_{p} + w,\ K^{in}_{q} + w$
        \EndFor
        \State $\Del \gets$ list$[(p, q, w') \mid E(p, q) = w']$    
        \State \textbf{return} $\Del$
    \EndFunction
    \end{algorithmic}
\end{algorithm}
The function \textsc{AddNode}($l$) adds a new node to the graph $\GG$ at the level $l$.

It is easy to see that
the computational complexity of \textsc{Up}($\Del$) is $O(|\Del|).$

\begin{algorithm}[H]
    \caption{MoveStage}
    \begin{algorithmic}[1]
    \Function{MoveStage}{Nodes $U$, Update $\Del$}
        %\State $S \gets U \cup \bigcup_{u \in U} \NN_u$
        \State $S \gets U \cup \{v \mid v \in \NN_u \text{ for some $u \in U$}\}$
        \For{$i \gets 1, \ldots, M$}
            \State $\MM_0 \gets$ \textsc{FindMoves}($S$)
            %\Comment{in parallel;}
            \State $\MM \gets$ \textsc{Decouple}($\MM_0$)
            \State $V_0 \gets \{u \mid \langle u, c_{from}, c_{to}, r\rangle \in \MM_0\}$
            \State $V \gets \{u \mid \langle u, c_{from}, c_{to}, r\rangle \in \MM\}$
            \State $W \gets
                \bigcup\limits_{v \in V}\{u \mid u \in \NN_v
                                                            \:\mathbf{and}\:
                                                            \pp(u) = \pp(v)\}$
            \State $\QQ \gets$ \textsc{Modularity}$()$
                \Comment{calculate using $\mm, \WW, \KK$}
            \State $\Del \gets$ \textsc{ApplyMoves}($\MM$, $\Del$)
            \State $\Delta\QQ \gets$ $\text{\textsc{Modularity}()} - \QQ$
            \If{$\Delta\QQ < 0$}
                \State $\MM_{reverse} \gets \{ \langle u, c_{to}, c_{from}, -r\rangle \mid \langle u, c_{from}, c_{to}, r \rangle \in \MM\}$
                \State $\Del \gets$ \textsc{ApplyMoves}($\MM_{reverse}$, $\Del$)
                \Comment{undo moves in $\MM$}
                \State \textit{break}
            \EndIf
            \State $U \gets U \cup V \cup W$
            \If{$(\Delta\QQ < \alpha \cdot \QQ)$ \textbf{or} ($|V| < \beta \cdot |S|$)}
                \State \textit{break}
            \EndIf
            \If{$i \not= M$}
                \State $S \gets (V_0 - V) \cup \bigcup\limits_{v \in V}\{u \mid u \in \NN_v \:\mathbf{and}\:\cc(u) \not= \cc(v)\}$
            \EndIf
        \EndFor
        \State \textbf{return} $U,\ \Del$
    \EndFunction
    \end{algorithmic}
    \label{alg:MoveStage}
\end{algorithm}


\begin{algorithm}[H]
    \caption*{The function \textsc{FindMoves}($S$) searches the best moves that have a non-zero reward for each node from $S$.}
    \begin{algorithmic}[1]
    \Function{FindMoves}{Nodes $S$}
        \State $\MM_0 \gets \varnothing$
        \For{$u \in S$}
            \State $m_{best} \gets None$
            \State $r_{best} \gets 0$
            \State $c_{from} \gets \cc(u)$
            \State $\CC \gets \{\cc(v) \mid v \in \NN_u \text{ for some } v\} - \{c_{from}\}$
            \State $D \gets$ empty dictionary
            \For{$v \in \NN_u$}
                \State $c \gets \cc(v)$
                \If{$\langle u, c\rangle \not\in D$}
                    \State $D(u, c) \gets \ww(u, v) + \ww(v, u)$
                \Else
                    \State $D(u, c) \gets D(u, c) + \ww(u, v) + \ww(v, u)$
                \EndIf
            \EndFor
            \For{$c \in \CC$}
                \State $r \gets$ \textsc{Reward}($D$, $u$, $c_{from}$, $c$)
                \If{$r > r_{best}$}
                    \State $r_{best} \gets r$
                    \State $m_{best} \gets \langle u, c_{from}, c, r_{best}\rangle$
                \EndIf
            \EndFor
            \State $r \gets$ \textsc{Reward}($D$, $u$, $c_{from}$, $\varnothing$)
            \Comment{reward of moving $u$ to a new community}
            \If{$r > r_{best}$}
                \State $r_{best} \gets r$
                \State $m_{best} \gets \langle u, c_{from}, \text{``new"}, r_{best}\rangle$
            \EndIf
            \If{$m_{best} \not= None$}
                \State $\MM_0 \gets \MM_0 \cup \{m_{best}\}$
            \EndIf
        \EndFor
        \State \textbf{return} $\MM_0$
    \EndFunction
    \end{algorithmic}
\end{algorithm}


The \textit{reward} \textsc{Reward}($D$, $u$, $c$, $b$)
of moving a node $u$ from a community (subcommunity) $c$ to a community (subcommunity) $b$ is equal to
\begin{equation*}
    \frac{1}{\mm}\big(D(u, b) - D(u, c)\big) + \frac{\gamma}{\mm^2}
    \Big(\big(K^{in}_{c} - K^{in}_{b}\big) K^{out}_u +
    \big(K^{out}_{c} - K^{out}_{b}\big) K^{in}_u -
    2\,K^{in}_u K^{out}_u\Big),
\end{equation*}
where
\begin{equation*}
D(u, z) = \sum\limits_{v \in \NN_u(z)}\big(\ww(u, v) + \ww(v, u)\big),
\end{equation*}
where $\NN_u(z) =\{v \in \NN_u \mid V_v \subseteq V_z\}$
are the neighbors of a node $u$ belonging to a community (subcommunity) $z$.
The computational complexity of \textsc{Reward}($D$, $u$, $c$, $b$) is $O(1)$,
if the values of the form $K^{in}_x, K^{out}_x, D(u, z)$ have been previously calculated.
It is easy to see that the computational complexity of \textsc{FindMoves}($S$) is equal to $O(\dd \cdot |S|)$.

\begin{algorithm}[H]
    \caption*{The function \textsc{Decouple}($\MM_0$)
            orders the found moves $\MM_0$ in the descending order of the modularity reward and then filters them using $acceptor$/$emitter$ markers for communities.}
    \begin{algorithmic}[1]
    \Function{Decouple}{Moves $\MM_0$}
        \State $\MM_0 \gets$ \textsc{Sort}($\MM_0$)
        \Comment{sort in descending order by reward (fourth element in the tuple)}
        \State $\MM \gets \varnothing$
        \State $\CC_{from} \gets \varnothing$
        \State $\CC_{to} \gets \varnothing$
        \For{$\langle u, c_{from}, c_{to}, r \rangle \in \MM_0$}
            \If{($c_{from} \in \CC_{to}$) \textbf{or} ($c_{to} \in \CC_{from}$)}
                \State $break$;
            \EndIf
            \State $\MM \gets \MM \cup \{\langle u, c_{from}, c_{to}, r \rangle\}$
            \State $\CC_{from} \gets \CC_{from} \cup \{c_{from}\}$
            \State $\CC_{to} \gets \CC_{to} \cup \{c_{to}\}$
        \EndFor
        \State \textbf{return} $\MM$
    \EndFunction
    \end{algorithmic}
\end{algorithm}
It is easy to see that the computational complexity of \textsc{Decouple}($\MM_0$) is equal to
$O\big(n \log_2 n\big)$, where $n = |\MM_0|$.

\begin{algorithm}[H]
    \caption*{The function \textsc{ApplyMoves}($\MM$, $\Del$) applies the moves $\MM$ to the graph $\GG$.}
    \begin{algorithmic}[1]
    \Function{ApplyMoves}{Moves $\MM$, Update $\Del$}
        \State $\CC \gets \bigcup\limits_{\langle u, c_{from}, c_{to}, r\rangle \in \MM}\{c_{from}, c_{to}\}$
        \State $\WW_1 \gets \sum\limits_{c \in C} \ww(c, c)$
        \State $\KK_1 \gets \sum\limits_{c \in C} K_{c}^{in} K_{c}^{out}$ 
        \For{$\langle u, c_{from}, c_{to}, r\rangle \in \MM$}
            \For{$(v_1, v_2) \in \EE_u$}
                \State $\Del \gets$ \textsc{UpEdge}($\Del$, $(v_1, v_2)$, $-\ww(v_1, v_2))$ 
            \EndFor
            %\State mark $\pp(u)$ to delete (if it has not children)
            \If{$c_{to} = \text{ ``new"}$}
                \State $c_{to} \gets $ \textsc{AddCommunityNode}()
                \State $\CC \gets \CC \cup \{c_{to}\}$
            \EndIf
            \If{$l(u) \not= L$}
                \State $p \gets $ \textsc{AddNode}\big($l(u)+1$\big)
                \State \textsc{SetParent}($u$, $p$)
                \State \textsc{SetReferenceToCommunity}($p$, $c_{to}$)
            \Else
                \State \textsc{SetReferenceToCommunity}($u$, $c_{to}$)
            \EndIf
            \For{$(v_1, v_2) \in \EE_u$}
                \State $\Del \gets$ \textsc{UpEdge}($\Del$, $(v_1, v_2)$, $\ww(v_1, v_2))$
            \EndFor
        \EndFor
        \State $\WW_2 \gets \sum\limits_{c \in C} \ww(c, c)$
        \State $\KK_2 \gets \sum\limits_{c \in C} K_{c}^{in} K_{c}^{out}$ 
        \State $\WW \gets \WW + (\WW_2 - \WW_1)$
        \State $\KK \gets \KK + (\KK_2 - \KK_1)$
        \State \textbf{return} $\Del$
    \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption*{The function \textsc{UpEdge}($\Del$, $(v_1, v_2)$, $w$) updates the weights of the edges
                $(\pp(v_1), \pp(v_2))$ and $(\cc(v_1), \cc(v_2))$ by the $w$.}
    \begin{algorithmic}[1]
    \Function{UpEdge}{Update $\Del$, Edge $(v_1, v_2)$, Weight $w$}
        \State $c,\ b \gets \cc(v_1),\ \cc(v_2)$
        \State \textsc{SetEdge}($(c, b)$, $\ww(c, b) + w$)
        \State $K^{out}_{c},\ K^{in}_{b} \gets K^{out}_{c} + w,\ K^{in}_{b} + w$
        \If{$l(v_1) \not= L$}
            \State $p,\ q \gets \pp(v_1),\ \pp(v_2)$
            \State \textsc{SetEdge}($(p, q)$, $\ww(p, q) + w$)
            \State $K^{out}_{p},\ K^{in}_{q}  \gets K^{out}_{p} + w,\ K^{in}_{q} + w$
            \State $\Del \gets \Del + (p, q, w)$
        \EndIf
        \State \textbf{return} $\Del$
    \EndFunction
    \end{algorithmic}
\end{algorithm}
It is easy to see that
the computational complexity of \textsc{UpEdge}($\Del$,  $(v_1, v_2)$,  $w$) is $O(1).$
The computational complexity of \textsc{ApplyMoves}($\MM$) is equal to
$O(\dd \cdot |\MM|)$.

\begin{algorithm}[H]
    \caption{RefineStage}
    \begin{algorithmic}[1]
    \Function{RefineStage}{Nodes $U$, Update $\Del$}
        \State $S \gets U$
        \For{$i \gets 1, \ldots, M$}
            \State $\MM_0 \gets$ \textsc{FindRefineMoves}($S$)
            \State $\MM \gets$ \textsc{Decouple}($\MM_0$)
            \State $V \gets \{u \mid \langle u, c_{from}, c_{to}, r\rangle \in \MM\}$
            \State $W \gets
                    \bigcup\limits_{v \in V}
                    \{u \mid u \in \NN_v \:\mathbf{and}\:
                             u \not\in V \:\mathbf{and}\:
                             \pp(u) = \pp(v)\}$
            \State $\Del \gets$ \textsc{ApplyRefineMoves}($\MM$, $\Del$)
            \State $U \gets U \cup V$
            \If{$|V| < \beta \cdot |S|$}
                \State \textit{break}
            \EndIf
            \State $S \gets (S - V) \cup W$
        \EndFor
        \State \textbf{return} $U,\ \Del$
    \EndFunction
    \end{algorithmic}
    \label{alg:RefineStage}
\end{algorithm}

\begin{algorithm}[H]
    %\caption{FindRefineMoves}
    \begin{algorithmic}[1]
    \Function{FindRefineMoves}{Nodes $S$}
        \State $\MM_0 \gets \varnothing$
        \For{$u \in S$}
            \State $m_{best} \gets None$
            \State $r_{best} \gets 0$
            \State $p_{from} \gets \pp(u)$
            \State $\mathcal{P} \gets \{\pp(v) \mid v \in \NN_u \text{ and } \cc(v) = \cc(u) \text{ for some } v\} - \{p_{from}\}$
            \State $D \gets$ empty dictionary
            \State $D(u, p_{from}) \gets 0$
            \For{$v \in \NN_u$}
                \State $p \gets \pp(v)$
                \If{$\langle u, p\rangle \not\in D$}
                    \State $D(u, p) \gets \ww(u, v) + \ww(v, u)$
                \Else
                    \State $D(u, p) \gets D(u, p) + \ww(u, v) + \ww(v, u)$
                \EndIf
            \EndFor
            \For{$p \in \mathcal{P}$}
                \State $r \gets$ \textsc{Reward}($D$, $u$, $p_{from}$, $p$)
                \If{$r > r_{best}$}
                    \State $r_{best} \gets r$
                    \State $m_{best} \gets \langle u, p_{from}, p, r_{best}\rangle$
                \EndIf
            \EndFor
            \State $r \gets$ \textsc{Reward}($D$, $u$, $p_{from}$, $\varnothing$)
            \Comment{reward of moving $u$ to a new subcommunity}
            \If{$r > r_{best}$}
                \State $r_{best} \gets r$
                \State $m_{best} \gets \langle u, p_{from}, \text{``new"}, r_{best}\rangle$
            \EndIf
            \If{$m_{best} \not= None$}
                \State $\MM_0 \gets \MM_0 \cup \{m_{best}\}$
            \EndIf
        \EndFor
        \State \textbf{return} $\MM_0$
    \EndFunction
    \end{algorithmic}
\end{algorithm}

The computational complexity of \textsc{FindRefineMoves}($S$) is
$O(\dd \cdot |S|)$.

\begin{algorithm}[H]
    %\caption{ApplyRefineMoves}
    \begin{algorithmic}[1]
    \Function{ApplyRefineMoves}{Moves $\MM$, Update $\Del$}
        \For{$\langle u, p_{from}, p_{to}, r\rangle \in \MM$}

            \For{$(v_1, v_2) \in \EE_u$}
                \State $\Del \gets$ \textsc{UpEdge}($\Del$, $(v_1, v_2)$, $-\ww(v_1, v_2))$ 
            \EndFor

            \If{$p_{to} = \text{ ``new"}$}
                \State $p_{to} \gets $ \textsc{AddNode}($l+1$)
                \State \textsc{SetReferenceToCommunity}($p_{to}$, $\cc(u)$)
            \EndIf
            \State \textsc{SetParent}($u$, $p_{to}$)
            
            
            \For{$(v_1, v_2) \in \EE_u$}
                \State $\Del \gets$ \textsc{UpEdge}($\Del$, $(v_1, v_2)$, $\ww(v_1, v_2))$
            \EndFor
        \EndFor
        \State \textbf{return} $\Del$
    \EndFunction
    \end{algorithmic}
\end{algorithm}
The computational complexity of \textsc{ApplyRefineMoves}($\MM$) is
$O(\dd \cdot |\MM|)$.


Let $A$ be a set of nodes at some level in the graph $\GG$.
We define a $i$-neighborhood $(A)_i$ as follows:
\begin{equation*}
(A)_0 = A,\quad (A)_{i+1} = \{v \mid v \in \NN_u \text{ for some } u \in (A)_i\}.
\end{equation*}
%We denote $|(A)_i|$ by $n_i$ if $n = |A|$.
\begin{lemma}\label{l:move:com}
    The computational complexity of \textsc{MoveStage}($U$) is
\begin{equation*}
O\big(n \cdot (\dd + \log_2 n)\big),
\end{equation*}
    where $n \leq \dd^M |U|$.
\end{lemma}
\begin{proof}
It is easy to see that the set $S$ before the $i$-th iteration in \textsc{MoveStage} is a subset of $(U)_i$
for $i = 1, \ldots, M$.
We denote the number of nodes in $S$ before the $i$-th iteration by $n_i$.
Note that $n_i \leq |(U)_i| \leq \dd^i |U|$.
The computational complexity of the $i$-th iteration is
\begin{equation*}
O(\dd n_i + n_i\log_2n_i + n_i + n_i + \dd n_i + \dd n_i + \dd n_i + 2n_i + \dd n_i)
    = O\big(n_i \cdot (\dd + \log_2 n_i)\big).
\end{equation*}
Thus, the computational complexity of \textsc{MoveStage}($U$) is
\begin{equation*}
        O\left(\sum\limits^{M}_{i=1} n_i \cdot \big(\dd + \log_2 n_i\big)\right)
        = O\big(n' \cdot (\dd + \log_2 n_M)\big)
        = O\big(n \cdot (\dd + \log_2 n)\big),
\end{equation*}
    where $n' = \sum\limits^{M}_{i=1} n_i \leq \frac{\dd^{M+1} - 1}{\dd - 1} |U| \leq \dd^M (1 + \frac{1}{\dd - 1}) |U|$
    and $n = \max( n' / 2,\ n_M)$.
\end{proof}

\begin{lemma}\label{l:refine:com}
    The computational complexity of \textsc{RefineStage}($U$) is
\begin{equation*}
O\big(n \cdot (\dd + \log_2 n)\big),
\end{equation*}
    where $n \leq \dd^{M-1}|U|$.
\end{lemma}
\begin{proof}
Note that the set $S$ before the $i$-th iteration in \textsc{RefineStage} is a subset of $(U)_{i-1}$,
for $i = 1, \ldots, M$.
We denote the number of nodes in $S$ before the $i$-th iteration by $n_i$.
Note that $n_i \leq |(U)_{i-1}| \leq \dd^{i-1} |U|$.
The computational complexity of the $i$-th iteration is
\begin{equation*}
O(\dd n_i + n_i\log_2 n_i + \dd n_i) = O\big(n_i \cdot (\dd + \log_2 n_i)\big).
\end{equation*}
Thus, we obtain
\begin{equation*}
        O\left(\sum\limits^{M}_{i=1} n_i \cdot (\dd + \log_2 n_i)\right)
        = O\big(n' \cdot (\dd + \log_2 n_M)\big)
        = O\big(n \cdot (\dd + \log_2 n)\big),
\end{equation*}
where $n' = \sum\limits^{M}_{i=1} n_i \leq \dd^{M-1}(1 + \frac{1}{\dd - 1})|U|$
and $n = \max( n' / 2,\ n_M)$.
\end{proof}

\begin{theorem}\label{t:dynalg:com}
    The computational complexity of \textsc{LD-Leiden}($\Delta G$) is
\begin{equation*}
O\Big(
            N \cdot n \cdot \big(\dd + \log_2 n\big)
        \Big),
\end{equation*}
    where
    $n \leq \dd^{(2L+1)M}\, \delta$,
    and $\delta$ is the number of unique nodes in $\Delta G$.
\end{theorem}
\begin{proof}
We denote the number of nodes in the set $U$ before $MoveStage$ at the $l$-th level of the aggregation by $n_{l,\, 0}$.
Note that $n_{0,\, 0}$ is equal to $\delta$.
We denote the number of nodes in the set $U$ after $MoveStage$ at the $l$-th level of the aggregation by $n_{l,\, 1}$.
We denote the number of nodes in the set $U$ after $RefineStage$ at the $l$-th level of the aggregation by $n_{l,\, 2}$.
It is easy to see that 
\begin{equation*}
n_{l,\, 2} \leq \dd^{M-1}n_{l,\, 1} \leq \dd^{M-1} \dd^{M+1} n_{l,\, 0} = \dd^{2M} n_{l,\, 0}.
\end{equation*}
Using Lemma~\ref{l:move:com} and \ref{l:refine:com}, we obtain that
the computational complexity of $MoveStage$ and $RefineStage$ at the $l$-th level of the aggregation is equal to
\begin{equation*}
    O\Big(
    \dd n'_l + n'_l\log_2 n'_l +
    \dd n_l + n_l\log_2 n_l
    \Big) =
    O\Big(n_l \cdot (\dd + \log_2 n_l)\Big),
\end{equation*}
%where $n_{l,\, 1} \leq n'_l \leq \dd^{M} n_{l,\, 0}$ and $n_{l,\, 2} \leq n_l \leq \dd^{(M-1)} n_{l,\, 1} \leq \dd^{2M} n_{l,\, 0}$.
where $n'_l \leq \dd^{M} n_{l,\, 0}$ and $n_l \leq \dd^{(M-1)} n_{l,\, 1} \leq \dd^{2M} n_{l,\, 0}$.

Thus, we obtain that
the computational complexity of \textsc{LD-Leiden} is
\begin{equation*}
O\left(
L n_0 + |\Delta G| +
N \left(\sum\limits_{l=0}^{L-1}\,
    \big(n_l \cdot (\dd + \log_2 n_l)\big) +
    n'_L \cdot (\dd + \log_2 n'_L)
    \right)
\right).
\end{equation*}
Note that
$n_{l,\, 0} \leq n_{l-1,\, 2}$ for $l=1, \cdots, L-1$.
Thus, 
\begin{equation*}
n_l \leq \dd^{2M(l+1)}\,n_{0,\, 0}
\end{equation*} 
for $l=0,\cdots,L-1$
and $n'_L \leq \dd^{2ML + M} n_{0,\, 0}$.
We obtain that the computational complexity of \textsc{LD-Leiden} is equal to
\begin{equation*}
O\Big(N \cdot n' \cdot \big(\dd + \log_2 n''\big)\Big)
= O\Big(N \cdot n \cdot \big(\dd + \log_2 n\big)\Big),
\end{equation*}
where
\begin{equation*}
n' = \sum\limits^{L-1}_{l=0} n_l + n'_L
    \leq \left(\sum\limits^{L-1}_{l=0} \dd^{2M(l+1)} + \dd^{M (2L + 1)}\right) n_{0,\, 0}
    \leq (2 \dd^{2ML} + \dd^{M (2L + 1)}) n_{0,\, 0}
    \leq 3\,\dd^{M (2L + 1)} n_{0,\, 0},
\end{equation*}
$n'' = \max(n_0, \ldots, n_{L-1}, n'_L)$
and $n = \max(n' / 3, n'')$.
\end{proof}

\newpage
\section{Experimental Results}
\label{app2}

Let a solution $OUR$ be compared with a baseline solution $BASE$ on a network divided into $B$ equal length batch updates.
We denote the ratio of arithmetic means
\begin{equation*}
\sum\limits^{B}_{t=1} \,\TT_{BASE}(t) \Big/ \sum\limits^{B}_{t=1} \,\TT_{OUR}(t)
\end{equation*}
by $\partial \TT$
and the ratio $\QQ_{OUR}(B) / \QQ_{BASE}(B)$ at the final time point $B$ by $\partial\QQ$.
The values of $\partial \TT$ and $\partial\QQ$ being greater than $1.00$ indicate that
the solution $OUR$ is better than the baseline solution $BASE$.
Note that $\partial\TT$, $\partial\QQ$ are equal to $\TT_{BASE}(1) / \TT_{OUR}(1)$
and $\QQ_{OUR}(1) / \QQ_{BASE}(1)$, respectively, in the static case $B=1$.

\subsection{Single-thread mode}
\label{app2:1}

\subsubsection{Static case}
\input{ameanT_1}
\input{lastM_1}

\subsubsection{Division into 10 batch updates}
\input{ameanT_10}
\input{lastM_10}

\subsubsection{Division into 100 batch updates}
\input{ameanT_100}
\input{lastM_100}

\subsubsection{Division into 1000 batch updates}
\input{ameanT_1000}
\input{lastM_1000}

\subsection{Dependence on batch update size}
\label{app2:2}

\subsubsection{Speedup}
\input{oblivius.time.LD-leiden}
\input{oblivius.time.leidenalg}
\input{oblivius.time.dfleiden}
\input{oblivius.time.networkit}
\input{oblivius.time.grappolo}

\subsubsection{Modularity Improvement}
\input{oblivius.modularity.LD-leiden}
\input{oblivius.modularity.leidenalg}
\input{oblivius.modularity.dfleiden}
\input{oblivius.modularity.networkit}
\input{oblivius.modularity.grappolo}

\subsection{Multi-thread mode}
\label{app2:3}

\subsubsection{Comparison with DF-Leiden}

\input{scalling_ameanT.dfleiden.100}
\input{scalling_lastM.dfleiden.100}

\subsubsection{Comparison with NetworKit}

\input{scalling_ameanT.networkit.100}
\input{scalling_lastM.networkit.100}

\subsubsection{Comparison with Grappolo}

\input{scalling_ameanT.grappolo.100}
\input{scalling_lastM.grappolo.100}

\subsubsection{Scalability}
\input{speedup_relative.LD-leiden.100}
\input{speedup_relative.dfleiden.100}
\input{speedup_relative.networkit.100}
\input{speedup_relative.grappolo.100}


\end{document}
