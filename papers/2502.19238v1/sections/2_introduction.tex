\section{Introduction}
A four dimensional (4-D) light field (LF) is a simplified form of the seven-dimensional plenoptic function~\cite{Ade1991,Zhan2003} that completely describes the light emanating from a scene. An LF captures both geometric and textural information of a static scene in contrast to a two-dimensional (2-D) image which captures only textural information of a static scene. These additional information available with an LF paves the way to accomplish novel tasks such as depth estimation~\cite{wanner2013variational,tao2013depth,wang2015depth} and occlusion suppression~\cite{vaish2004occlusion,Dan2007,Liyanageocclusion} that are not generally possible with 2-D images. Furthermore, LFs have been employed for multiple applications in computer vision systems such as mobile robotics~\cite{Dong2013,Tsai2017,Baj2018} and underwater imaging~\cite{Piza2013,Dan2014}.


%are becoming popular due to their attractive characteristics over the two dimensional (2D) images. While a 2D image capture only the spatial details of light rays, a 4D LF can captures angular information as well. Therefore, 4D LFs are prefered over the conventional 2D images in several computer vision tasks. Depth estimation \cite{wanner2013variational,tao2013depth,wang2015depth}, visual odometry \cite{2021unsupervised,dansereau2011odometry}, occlusion suppression \cite{Liyanageocclusion,vaish2004occlusion} are few of them. 

\begin{figure}[!t]
    \centering
    \begin{subfigure}[c]{0.49\columnwidth}
    \vspace{1mm}
        \centering
         \includegraphics[width=\textwidth]{images/1st_page_img/single_depth/bush_single_refocusd_img.png}
        \label{fig:single_depth_refocus_img}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[c]{0.49\columnwidth}
    \vspace{-3mm}
        \centering
        \includegraphics[width=\textwidth]{images/1st_page_img/multi_depth/multi_depth_refocus.pdf}

        \label{fig:multi_depth_sakila_akka}
    \end{subfigure}
    
    \vspace{-3mm}
    \begin{subfigure}[c]{0.49\columnwidth}
        \centering
        % \includegraphics[width=\textwidth]{images/1st_page_img/dense/bush_multi_refocusd_img.jpg}
        \resizebox{1\columnwidth}{!}{%
            \centering
            \includegraphics[height=3cm]{images/1st_page_img/single_depth/slice1.png}
            \includegraphics[height=3cm]{images/1st_page_img/single_depth/slice2.png}
            \includegraphics[height=3cm]{images/1st_page_img/single_depth/slice3.png}

            \hspace{-3mm}
        }
        \caption{}
        \label{fig:single_depth_refocused_img_slices}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[c]{0.49\columnwidth}
        \centering
        \resizebox{1\columnwidth}{!}{%
            \centering
            \includegraphics[height=3cm]{images/1st_page_img/multi_depth/slice1.pdf}
            \includegraphics[height=3cm]{images/1st_page_img/multi_depth/slice2.pdf}
            \includegraphics[height=3cm]{images/1st_page_img/multi_depth/slice3.pdf}

            \hspace{-3mm}
        }
        \caption{}
        \label{fig:multi_depth_sakila_akka_refocused_img_slices}
    \end{subfigure}
    
    \begin{subfigure}[c]{0.49\columnwidth}
    \vspace{1mm}
        \centering
         \includegraphics[width=\textwidth]{images/1st_page_img/dense/bush_multi_refocusd_img.jpg}
        \label{fig:dense_multi_refocused_img}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[c]{0.49\columnwidth}
    \vspace{-3mm}
        \centering
        \includegraphics[width=\textwidth]{images/1st_page_img/sparse/bush_multi_refocusd_img.jpg}

        \label{fig:sparse_multi_refocused_img}
    \end{subfigure}
    
    \vspace{-3mm}
    \begin{subfigure}[c]{0.49\columnwidth}
        \centering
        % \includegraphics[width=\textwidth]{images/1st_page_img/dense/bush_multi_refocusd_img.jpg}
        \resizebox{1\columnwidth}{!}{%
            \centering
            \includegraphics[height=3cm]{images/1st_page_img/dense/bush_refocused_slice_0.jpg}
            \includegraphics[height=3cm]{images/1st_page_img/dense/bush_refocused_slice_2.jpg} 
            \includegraphics[height=3cm]{images/1st_page_img/dense/bush_refocused_slice_1.jpg}
            \hspace{-3mm}
        }
        \caption{}
        \label{fig:dense_multi_refocused_img_slices}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[c]{0.49\columnwidth}
        \centering
        % \includegraphics[width=\textwidth]{images/1st_page_img/sparse/bush_multi_refocusd_img.jpg}
        \resizebox{1\columnwidth}{!}{%
            \centering
            \includegraphics[height=3cm]{images/1st_page_img/sparse/bush_refocused_slice_0.jpg}
            \includegraphics[height=3cm]{images/1st_page_img/sparse/bush_refocused_slice_2.jpg} 
            \includegraphics[height=3cm]{images/1st_page_img/sparse/bush_refocused_slice_1.jpg}
            \hspace{-3mm}
        }
        \caption{}
        \label{fig:sparse_multi_refocused_img_slices}
    \end{subfigure}


    \caption{Refocusing of ``Bush" LF; (a) single planar refocus~\cite{ng2005light}; (b) two volumetric regions~\cite{multivolume}; (c) proposed arbitrary volumetric refocusing using a dense LF; (d) proposed arbitrary volumetric refocusing using a sparse LF having cross-shaped SAIs. For (c) and (d), narrow-depth and wide-depth regions are shown in boxes with green- and red-colored outlines, respectively.}
    \label{fig:dense_sparse_multi_refocus}
\end{figure}


Post-capture refocusing---ability to change the focused regions of a scene after capturing---is another exciting application of LFs. This was first demonstrated by Ng \textit{et al.} in the seminal work~\cite{ng2005light}, where refocusing over a narrow depth range (called planar refocusing) was achieved by appropriately shifting the pixels of sub-aperture images (SAIs) of an LF and subsequently summing these shifted SAIs. The required shifts are determined by the depth (or disparity) of the region to be focused. Even though planar refocusing created a paradigm shift in LF photography, inability to refocus over a wide depth range was a drawback. Refocusing over a wide depth range (called volumetric refocusing) was demonstrated by Dansereau \textit{et al.} in~\cite{volumetric} using a 4-D linear and shift-invariant filter having a hyperfan passband. The depth range of a scene that should be refocused is determined by the angle of the hyperfan, and the planar refocusing is a special case of the volumetric refocusing. Jayaweera \textit{et al.}~\cite{multivolume} demonstrated multi-volumetric refocusing, where multiple regions having wide depth ranges were simultaneously refocused using a 4-D linear and shift-invariant filter having multiple hyperfan passbands. Such multi-volumetric refocusing adds novel features in LF photography and cinematography~\cite{Tro2019}. Furthermore, multi-volumetric refocusing can achieve single planar or volumetric region as a special case. However, all these methods cannot refocus a planar or volumetric region while keeping a planar or volumetric region having same depth range out-of-focus. In other words, these methods refocuses whole region corresponding to a given depth range, as shown in Fig.~\ref{fig:single_depth_refocused_img_slices} and \ref{fig:multi_depth_sakila_akka_refocused_img_slices}. Furthermore, all these methods have been developed for dense light fields, captured from camera arrays or lenselet-based LF cameras (shown in Figs.~\ref{fig:camera_array} and \ref{fig:lytro_camera}, respectively) leading to higher memory and computational complexities.  

%Post-capture refocusing which alter the focal plane after capturing is a widely researched task which can be achieved with LFs. In the beginning, refocusing to a single planar depth was achieved by \cite{ng2005light,ng2005fourier}. Then, refocusing to a wide-depth range or more commonly, volumetric refocusing was achieved by \cite{volumetric}. This is quite useful as nonplanar scenes are required for most of the applications. Improving further, \cite{multivolume} could achieve refocusing on multiple volumes simultaneously. With the recent development in deep learning, convolutional neural network (CNN) based LF refocusing methods are also introduced \cite{deep_sparse,machinelearning_multi_refocus}. But all these methods are only capable of refocusing the LF to a predefined depth or depths. All the objects fall within that depth range or ranges will be in refocus while rest of the area will be in out-of-focus. Solving this problem and generalizing the concept of multi-volumetric refocusing, enabling to refocus only to an arbitrarily selected region of interest (ROI) or multiple ROIs would be a novel addition to the existing LF post-capture refocusing methods.
% Shifting and averaging the sub-aperture images (SAIs) in spatial domain \cite{ng2005light}, Fourier Slice Photography Theorem in frequency domain \cite{ng2005fourier} \hl{are the fundamental LF refocusing methods}. Based on them, several variations of refocusing methods \cite{tilt_shift,volumetric,multivolume} were introduced. With the recent improvement in deep learning, convolutional neural network (CNN) based refocusing methods are also introduced \cite{deep_sparse, machinelearning_multi_refocus}.

% Using the full LF requires considerable memory usage and computational cost. Instead of using dense LFs, by selecting a subset of sub-aperture images the operation takes a low memory usage and post processing takes a less time.

\begin{figure}[t]
    \centering
    \resizebox{1\columnwidth}{!}{%
        \centering
        \subcaptionbox{\label{fig:camera_array}}{\centering \includegraphics[height=3cm]{images/LF_cameras/LF_video_camera_array.jpg}}
        \subcaptionbox{\label{fig:lytro_camera}}{\centering \includegraphics[height=3cm]{images/LF_cameras/Lytro_Illum_Camera.jpg}}
        \subcaptionbox{\label{fig:epiModule}}{\centering \includegraphics[height=3cm]{images/LF_cameras/epimodule.png}}
    }
     \hfill

    \caption{Different types of LF cameras; (a) LF video camera array~\cite{LFVideoCamera}, (b) Lytro Illum dense LF camera from Lytro, Inc, (c) EPIModule Sparse LF camera from EPIImaging LLC.}
    \label{fig:LFcameras}
\end{figure}

Sparse LFs consisting of a subset of SAIs of dense LFs drastically reduces the amount of data captured. For example, a cross-shaped sparse LF captured with a sparse camera array EPIModule shown in \figurename~\ref{fig:epiModule} consists of only $17$ SAIs whereas its dense counterpart consists of $81$ SAIs leading to $79\%$ reduction in data. Such sparse LFs pave the way to implement LF processing methods in resource-constrained devices to achieve real-time processing with low energy consumption. Sparse LFs have been employed in several computer vision applications~\cite{jiang2018sparse_depth,learning_view_synthesis}. Furthermore, several methods to refocus sparse LFs~\cite{2015fast_real,alain2021spatio_sparse} have recently been developed. However, all these methods achieve only the planar refocusing for a whole narrow depth range. Therefore,
novel methods for refocusing of multi volumetric regions of a sparse LF without generating dense LFs as intermediate step is essential to fully exploit the advantages of sparse LFs in LF photography and cinematography.    
%\textcolor{red}{generate dense LFs from a sparse LFs through preprocessing before refocusing and}
%Sparse LFs which consist of subsets of sub-aperture images (SAIs) of dense LFs are becoming more popular due to their low computational cost and low storage requirement over the dense LFs captured from large camera arrays (\figurename \ref{fig:camera_array}) and lenslet based cameras (\figurename \ref{fig:lytro_camera}). Specially, sparse LFs make it possible for resource-constrained devices to achieve real-time performance with low energy consumption. Therefore, sparse LF cameras like EPIModule (\figurename \ref{fig:epiModule}) and sparse LF based computer vision tasks \cite{jiang2018sparse_depth,learning_view_synthesis} are being introduced. Sparse LF refocusing is one of them. Existing sparse LF refocusing algorithms are still limited to refocus on single planar depth \cite{2015fast_real,alain2021spatio_sparse} and preprocessing methods to generate dense LFs via sparse LFs takes additional time. These problems limit the usage of sparse LFs to fewer applications invoking the requirement of an algorithm of sparse LF refocuing on multiple arbitrary volumes.



In this paper, we propose an end-to-end pipeline to simultaneously refocus multiple arbitrary planar or volumetric regions of both dense and sparse LFs. Our method employs the shift-and-sum method proposed in \cite{ng2005light} for dense LFs. However, we employ \emph{pixel-dependent} depth (or disparity) to determine the shifts of pixels of SAIs in contrast to the pixel-independent depth employed in \cite{ng2005light} to determine shifts. This enables to achieve pixel-dependent refocusing, where a desired planar or volumetric region can be refocused while keeping another region having the same depth range out-of-focus, as shown in Figs.~\ref{fig:dense_multi_refocused_img_slices} and \ref{fig:sparse_multi_refocused_img_slices}. To the best of our knowledge, our method is the \emph{first refocusing method} that achieves simultaneous refocusing of the interested regions while keeping other regions having the same depth ranges out-of-focus in LFs. We then extend the proposed refocusing method to \emph{sparse LFs} having \emph{cross-shaped} SAIs, similar to an LF captured from EPIModule shown in \figurename~\ref{fig:epiModule}. Due to the sparsity of the LF, the shift-and-sum method produces ghosting artifacts in out-of-focus regions even though in-focus regions appear without noticeable artifacts. We employ a U-Net~\cite{unet} based deep learning model to almost completely eliminate the ghosting artifacts, producing refocused sparse LFs having almost the same fidelity as those obtained with dense LFs. Furthermore, our method works as an end-to-end pipeline. That is, once a user selects one or more regions to refocus, our method first generates the depth map of the LF. The required shifts for dense LFs are generated using the generated depth map. For sparse LFs, our method determines the required shifts through an exhaustive search from a feasible range of depths, i.e., without explicitly employing a depth map. The experimental results obtained with several LF datasets confirm the effectiveness of the proposed method. Furthermore, our method is fast and the processing time for a dense LF of size of the $9\times9\times512\times512$ dataset is $3.64$ s, and that for the corresponding cross-shaped sparse LF is $0.71$ s.
% Therefore, we believe that our work will be useful LF photography and cinematography.

%Providing solutions to above problems, in this paper, we propose two real-time, interactive  \hl{multi arbitrary-volume} post-capture refocusing algorithms for dense LFs and sparse LFs. Our algorithms are based on popular shift-and-sum algorithm (section \ref{sec:shiftSumReview}). We also utilize image restoration U-Net \cite{unet} CNN to minimize aliasing artifacts due to undersampling for sparse LFs. \hl{Following the structure of the EPIModule LF camera} (\figurename \ref{fig:epiModule}), \hl{we consider only the SAIs on perpendicular $X$ and $Y$ axes passing through the center of the dense LF as a sparse LF}. To the best of our knowledge, this paper is the first which provides such algorithms to refocus both dense and sparse LFs on multiple arbitrary-volumes and planar surfaces simultaneously making existing methods non-comparable. \figurename \ref{fig:dense_multi_refocused_img_slices}, \ref{fig:sparse_multi_refocused_img_slices} respectively shows refocused dense and sparse LFs on arbitrarily selected regions. ROIs in green color boxes have narrow-depth ranges hence are planar refocused whereas ROI in red colored box has a wide-depth range hence is volumetric refocused. The rest of the area kept out-of-focus. 
% Our work is the first of this kind in LF post-capture refocusing which is capable of refocusing multiple arbitrary-volumes simultaneously, that makes other methods non-comparable.
%
%The proposed algorithms in this paper can be used to emphasize any interested regions or multiple objects in the LF simultaneously. Furthermore, this method is capable of keeping all the unintended objects and regions out-of-focus which may not satisfied by the existing methods. \hl{Therefore, we believe that this work will be useful not only for LF photography but also in industries like medicine and cinematography}. Specially the applicability for sparse LFs, make it possible to design low cost and resource limited devices.  


% We use shift and sum algorithm to refocus at required depth. This image is then sent through an image restoration CNN to remove the ghosting artifacts in unfocused areas. There are existing methods that use deep learning based approaches for sparse light field refocusing. But to the best of our knowledge, we are the first to suggest this kind image restoration approach for sparse light field refocusing.


The rest of this paper is organized as follows. In Sec.~\ref{sec:relatedWork}, we review the background on existing LF refocusing algorithms. A brief review of the shift-and-sum LF refocusing algorithm and its simplification for digital domain is presented in Sec.~\ref{sec:shiftSumReview}. Then, we describe the proposed arbitrary multi-volumetric LF refocusing method in Sec.~\ref{sec:methodology}. In Sec.~\ref{sec:experiments}, we present the experimental results. Finally, we conclude and present future work in Sec.~\ref{sec:conclusion}.

