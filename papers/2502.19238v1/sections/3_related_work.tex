\section{Related Work}\label{sec:relatedWork}
 
%LF post-capture refocusing is a popular area of research that can be mainly performed either in spatial domain or in frequency domain. 
Refocusing of an LF is first demonstrated by Ng \textit{et al.}~\cite{ng2005light}, where SAIs of an LF are shifted appropriately and summed to generate a refocused LF. Here, refocusing was limited to a narrow depth range parallel to the camera plane. This method was further extended to be implemented in the frequency domain in \cite{ng2005fourier}. They showed that the shift-and-sum in the spatial domain~\cite{ng2005light} is equivalent to the generalized Fourier slice theorem in the frequency domain. Furthermore, with the pre-computed spectra on LFs, the computational complexity can be substantially reduced compared to the shift-and-sum method thanks to the fast Fourier transform. Generalizing shift-and-sum method, Martin \textit{et al.}~\cite{tilt_shift} achieved refocusing along non-parallel planes to the camera plane. Furthermore, their method is interactive and the parameters related to the user selected refocus plane are found using a pre-computed depth information. 

%These integration based spatial-domain calculations are quite computationally expensive.
% These algorithms are most suitable for dense light fields captured using lightfield cameras with micro-lens system, like Lytro Illum. Using bokeh rendering and super-resolution \cite{wang2018selective} achieved refocusing for LFs captured using camera arrays which have wider baselines and sparser angular samplings.
%The shift-and-sum algorithm is the fundamental spatial-domain post capture refocusing methodology which was first introduced in \cite{levoy2004synthetic,vaish2004using} and mathematically derived in \cite{ng2005light}. This method refocuses a LF to a single planar depth which is parallel to the camera's sensor plane. Generalizing this algorithm, \cite{tilt_shift} introduced refocusing to a non-parallel plane to the camera's sensor plane (non-frontoparallel) interactively. These integration based spatial-domain calculations are quite computationally expensive.
% These algorithms are most suitable for dense light fields captured using lightfield cameras with micro-lens system, like Lytro Illum. Using bokeh rendering and super-resolution \cite{wang2018selective} achieved refocusing for LFs captured using camera arrays which have wider baselines and sparser angular samplings.
%Frequency domain LF refocusing was first introduced by \cite{ng2005fourier} using Fourier Slice Photography Theorem. Computations become more efficient in frequency domain over the spatial domain as they are based on multi dimensional fast Fourier transform. In our proposed method, we utilize spatial domain shift-and-sum algorithm by introducing simplifications and approximations to reduce its computational complexity which will be further described in Section \ref{sec:shiftSumReview} and Section \ref{sec:implementationDetails}.

%The above methods, however, are limited to perform refocusing to narrow-depth ranges only.

Refocusing of wide-depth ranges was first proposed in \cite{volumetric} using a 4-D linear and shift-invariant hyperfan filter. Rather than shifting-and-summing, the 4-D filter was designed so that the passband occupies the spectral region corresponding to the depth range needs to be focused, and the stopband occupies the other depth ranges. The width the focused depth range is determined by the angle of the hyferpan-shaped passband. Reducing computational complexity further, \cite{volumeSparseFIR} introduced a 4-D sparse hyperfan filter for volumetric refocusing. Breaking the limit of refocusing to a single depth range, \cite{multivolume} introduced LF refocusing on multiple volumetric regions, allowing to refocus at several objects at different depth ranges. In all these methods, if the objects that should not be focused are within the same depth range that the LF is refocussed, then they too will be in focus. Our approach  overcomes this issue. Specially, it can refocus LFs at any arbitrary-volume or multiple arbitrary-volumes which opens new avenues in LF photography. 

%Additionally, the interactive end-to-end pipeline without manual parameter selection makes it possible to be used in developing intuitive designs.
% \cite{marichal2011fast,fu2015implementing}. Refocusing to a selected larger depth range was achieved by \cite{volumetric}.
% \textcolor{red}{Mention the stance of our work in terms of volumetric region refocusing? How we are introduicing refocusing to an arbitrary volume - the novel thing in terms of volumentric refocusing is there is.}

% Expecting good quality results, most of the early works were based on dense LFs. However, capturing dense LFs is quite expensive. Also, to deal with dense LFs, a larger storage is necessary while the required computational power is high as well. As an alternative, sparse LFs with less number of SAIs can be introduced since they have less effect due to above issues.
Sparse LFs become more common due to their advantages over dense LFs.
However, sparse LF refocusing requires more sophisticated algorithms to overcome the aliasing artifact due to undersampling. In \cite{2015fast_real}, SAIs of sparse LFs are logically interpolated to generate the missing SAIs during the refocus. In \cite{alain2021spatio_sparse}, an anti-aliasing filter is added to conventional shift-and-sum LF refocusing algorithm to reduce aliasing. In our sparse LF multi arbitrary-volume refocusing method, much faster image restoration U-Net CNN~\cite{unet} is used to address this problem.

The recent development in deep learning paved ways to significantly improve the LF applications. For example, \cite{2021unsupervised} demonstrated depth estimation and visual odometry, using a sparse LF camera and unsupervised learning. More specifically, \cite{deep_sparse} proposes a CNN-based LF refocusing algorithm using only four shifted SAIs. Using a CNN, \cite{machinelearning_multi_refocus} extract 16 refocused images at different depths at once, from a $7 \times 7$ LF. These methods can perform in real-time with low computational complexity. However, unlike to our method, they are not capable of refocusing LFs at multiple regions simultaneously.
% \textcolor{red}{How our work is superior to these should be highlighted. Why should others use our work instead of these past work need to be said at each juncture.}


