\section{Proposed Multi Arbitrary-Volume Refocusing Algorithm} \label{sec:methodology}

\begin{figure*}[!ht]
    \centering
    \begin{subfigure}[c]{0.5\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/dense_architecture.pdf}
         \caption{ }
         \label{fig:dense_refocus_pipeline}
     \end{subfigure}
     \hfill
    \begin{subfigure}[c]{1\textwidth}
         \centering
         \includegraphics[width=0.8\textwidth]{images/sparse_architecture.pdf}
         \caption{ }
         \label{fig:sparse_refocus_pipeline}
     \end{subfigure}
     \hfill
    
    \caption{The flow charts of (a) dense LF refocusing algorithm and (b) sparse LF refocusing algorithm. The user can interactively select an ROI or multiple ROIs on middle SAI which are needed to be refocused. For dense LFs, first, the depth map is estimated. Then generate the $\mathcal{M}_{\alpha}(n_x,n_y)$. Finally refocus each region with different $\alpha$ value separately and concatenate together to get the final refocused image. For sparse LFs, first suitable $\alpha$ value search is done for each ROI. Then create the $\mathcal{M}_{\alpha}(n_x,n_y)$ and refocus each region with different $\alpha$ value and concatenate. Finally, send through the image restoration CNN to remove the aliasing artifacts and get the final refocused image.}
    \label{fig:architecture}
\end{figure*}


In this section, we propose algorithms for interactive refocusing of arbitrarily selected $N$ $(\geq 1)$ regions of interest (ROIs) of dense LFs and cross-shaped sparse LFs. Both algorithms are initiated by the user by providing the required ROIs to be refocused on the middle SAI and their visible depth ranges. Let's denote the selected $N$ ROIs as $\mathcal{R}^1, \mathcal{R}^2, ..., \mathcal{R}^N$ and their visible depth ranges as $\phi^1, \phi^2, ..., \phi^N$ where each $\phi^i$ denotes whether $\mathcal{R}^i \in \mathfrak{R}_{n}$ (narrow-depth) or $\mathcal{R}^i \in \mathfrak{R}_{w}$ (wide-depth). This prior information improves the efficiency of the algorithms as the amount of calculations for $\mathcal{R}^i \in \mathfrak{R}_{n}$ is relatively low.

\subsection{Refocusing of Dense Light Fields}\label{sec:dense_refocus}

The proposed refocusing algorithm for dense LFs consists of 2 steps. \figurename~\ref{fig:dense_refocus_pipeline} shows the overall pipeline of the process. First, the disparity map $D(n_x,n_y)$ is estimated. To this end, we utilize fast implementable, LF epipolar plane image analysis in~\cite{wanner2013variational} to generate a smooth $D(n_x,n_y)$. Here, we first estimate gradients of epipolar lines $d_{x,u}$ and $d_{y,v}$ passing through  $(n_u,n_x)$ and $(n_v,n_y)$ points, respectively, and their corresponding confidences. We then point-wise select the most confident estimate among them and apply smoothing to attenuate noise. Incorporating $D(n_x,n_y)$, we can find $\alpha$ values to refocus each $(n_x,n_y)$ pixel of the LF as 
\begin{align}\label{eq:disparity}
\alpha(n_x,n_y) = D(n_x,n_y) -1,
\end{align}
where $\alpha(n_x,n_y)$ denotes the corresponding $\alpha$ value for the pixel $(n_x,n_y)$. Then, for each ROI $\in \mathfrak{R}_{n}$, we select the mode of $\alpha$ values as the suitable $\alpha$ value in~\eqref{eq:LF_refocus_simple} to refocus that ROI, whereas each ROI $\in \mathfrak{R}_{w}$ are divided into smaller patches $(p^1, p^2, ..., p^M)$ and find the mode of $\alpha$ values for each patch. To emphasize the selected in-focus regions, we set a relatively smaller $\alpha$ value on uninterested regions which makes those regions out-of-focus. Concatenating these $\alpha$ values, we create the $\alpha$ mask $\mathcal{M}_{\alpha}(n_x,n_y)$. In order to ensure a smooth transition between regions with different $\alpha$ values, we apply a $15 \times 15$ Gaussian Filter with $\mu=0$ and $\sigma=5$ on $\mathcal{M}_{\alpha}(n_x,n_y)$ and remove sharp changes. \figurename~\ref{fig:alpha_mask} shows sections of $\mathcal{M}_{\alpha}(n_x,n_y)$ around the ROIs as heat map parts. Note that the smooth transitions between focused and out-of-focus regions, and continuous change of $\alpha$ value within ROI $\in \mathfrak{R}_{w}$ (upper right ROI). Using the constructed $\mathcal{M}_{\alpha}(n_x,n_y)$, we identify the regions with unique $\alpha$ values, then separately refocus using~\eqref{eq:LF_refocus_simple} and concatenate together to get the final multi arbitrary-volume refocused image $\mathcal{I}_f$ (\figurename~\ref{fig:dense_multi_refocused_img_slices}). The overall algorithm for dense LF refocusing is presented in Algorithm \ref{alg:dense_LF_refocus}. Note that, though we can find $\alpha$ value and refocus each pixel individually, we find a single $\alpha$ value for whole ROI $(\in \mathfrak{R}_{n})$ or patch $(\in \mathfrak{R}_{w})$ and refocus at once, as in such regions $\alpha$ values have less variances. So that the computational efficiency can be further improved.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\columnwidth]{images/1st_page_img/slope_mask_slices.pdf}
    \caption{Sections of $\mathcal{M}_{\alpha}(n_x,n_y)$ of multi arbitrary-volume refocused LF shown in \figurename~\ref{fig:dense_multi_refocused_img_slices} as a heatmap.}
    \label{fig:alpha_mask}
\end{figure}


\begin{algorithm}[!h]
\scriptsize
\caption{Dense LF multi arbitrary-volume refocusing}\label{alg:dense_LF_refocus}

\hspace*{\algorithmicindent} \textbf{Input:} Original Light Field ($\mathcal{I}_{LF}$) \\
\hspace*{\algorithmicindent} \hspace{.9cm} Default $\alpha$ ($\alpha_d$)\\ 
\hspace*{\algorithmicindent} \textbf{Output:} Refocused Light Field ($\mathcal{I}_f$)
\begin{algorithmic}[1]
\Procedure{Dense\_LF\_Multi\_Arbitrary\_Volume\_Refocus}{$\alpha_{d}$, $\mathcal{I}_{LF}$}
    \State $\mathcal{R}_{ROI} \gets  [\mathcal{R}^1, \mathcal{R}^2, ..., \mathcal{R}^N]$
    \Comment{User selected ROIs}
    \State $\Phi \gets [\phi^1, \phi^2, ..., \phi^N],~\phi^i \in \{\mathfrak{R}_{n}, \mathfrak{R}_{w}\}$
    \Comment{Mode of refocus}
    \State $\mathcal{I}_f \gets \{0:\forall(n_x,n_y)\}$ \Comment{Initialize $\mathcal{I}_f$ to zeros}
    \State $\mathcal{M}_{\alpha}$ $\gets$ \Call{Generate\_Alpha\_Mask}{$\alpha_{d}$, $\mathcal{R}_{ROI}$, $\Phi$, $\mathcal{I}_{LF}$};
    
    \ForEach{$\alpha$ in $\mathcal{M}_\alpha$}
        \State $I_{\alpha}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}_{LF}$, $\alpha$} \Comment{~\eqref{eq:LF_refocus_simple}}
        \State $\mathcal{K} \gets \{(n_x,n_y):\mathcal{M}_{{\alpha}_{(n_x,n_y)}}=\alpha\}$
        \State $\mathcal{I}_f[n_x,n_y]$ $\gets$ $I_{\alpha}[n_x,n_y] \;\forall(n_x,n_y)\in\mathcal{K}$

    \EndFor
    \State \textbf{return} $\mathcal{I}_f$
\EndProcedure

% \algstore{algo_cont_0} 
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[!h]
% \begin{algorithmic}[1]
% \algrestore{algo_cont_0} 
% \scriptsize

\Procedure{Generate\_Alpha\_Mask}{$\alpha_{d}$, $\mathcal{R}_{ROI}$, $\Phi$, $\mathcal{I}_{LF}$}
    \State Generate disparity map $D(n_x,n_y)$
    \State $D(n_x,n_y) \gets D(n_x,n_y) + 1$ \Comment{~\eqref{eq:disparity}}
    \State $\mathcal{M}_\alpha \gets \{\alpha_d:\forall(n_x,n_y)\}$ \Comment{Initialize $\mathcal{M}_\alpha$ to $\alpha_d$} %of what shape?
    % \State N = length\{ROIs\}
    \For{$i \gets 1$ to $N$}
    \State $\mathcal{R}_{c} \gets \mathcal{R}_{ROI}[i]$
    \State $\phi_{c} \gets \Phi[i]$
    % \ForEach{($\mathcal{R}^i \in \mathcal{R}_{ROI}$ \& $\phi^i \in \Phi$)}
        \If{($\phi_c == \mathfrak{R}_{n}$)}
            \State $\alpha$ $\gets$ mode($\alpha$ $\in$ $D$[$\mathcal{R}_c$])
            \State $\mathcal{M}_\alpha$[$\mathcal{R}_c$] $\gets$ $\alpha$
        \Else  \Comment{$\phi_c \in \mathfrak{R}_{w}$}
        
        \Comment{Divide $\mathcal{R}_c$ into smaller patches $p^j$, $j=1,2,..,M$}
        \State $\mathcal{P}_c \gets$ $[p^1, p^2, ..., p^M]$ 
            % \State Divide $\mathcal{R}^i$ ROI into  smaller $\mathcal{P}^j$ patches.
        \For{$j \gets 1$ to $M$}  
        \State $p_c \gets$ $\mathcal{P}_c[j]$
        \Comment{$j^{th}$ patch in $\mathcal{R}_c$}
        % \ForEach{$\mathcal{P}^j$ in $\mathcal{R}^i$}

                \State $\alpha$ $\gets$ mode($\alpha$ $\in$ $D$[$p_c$])
                \State $\mathcal{M}_\alpha$[$p_c$] $\gets$ $\alpha$
            \EndFor
        \EndIf
    \EndFor
    \State Apply Gaussian filter on $\mathcal{M}_\alpha$
    \State \textbf{return} $\mathcal{M}_\alpha$
\EndProcedure

\end{algorithmic}
\end{algorithm}


% \FloatBarrier
\subsection{Sparse Light Field Refocusing}\label{sec:sparse_refocus}

In this paper, we consider a cross-shaped SAIs of a dense LF as a sparse LF. The structure of the EPIModule sparse LF camera~(\figurename~\ref{fig:epiModule}) motivated us to consider this specific shape.
% \textcolor{red}{Is there any particular savings/benefits from following the EPIModule?-IF YES, mention here.}
So that, our sparse LF refocusing algorithm can be directly implemented using sparse LFs acquired from this kind of cameras, without depending on much expensive dense LFs.

Our proposed sparse LF post-capture refocusing algorithm consists of 3 steps. \figurename~\ref{fig:sparse_refocus_pipeline} shows the overall pipeline. First, for each ROI $\in \mathfrak{R}_{n}$, a suitable $\alpha$ value which can be used to refocus that region is searched. ROIs $\in \mathfrak{R}_{w}$ are divided into smaller patches $(p^1, p^2, ..., p^M)$ and find a suitable $\alpha$ value for each patch separately. For this $\alpha$ value search, we extract the corresponding LF slice $(\mathcal{S}_{LF})$ of an ROI or patch and refocus with different $\alpha$ values using~\eqref{eq:LF_refocus_simple}. We measure the similarity between resulting refocused image slices and the corresponding area of the LF's middle SAI $(\mathcal{S}_{SAI})$ using \emph{multi scale structural similarity} (MS\_SSIM)~\cite{ms_ssim} metric. The $\alpha$ value which gives the highest similarity is selected as the best $\alpha$ value. This method is repeatedly applied for all the ROIs or patches to identify the set of best $\alpha$ values. This is done in two steps. In the first step, a range that the best $\alpha$ value exists is identified using the fact that the similarity score has a concave shape and global maxima is at the best $\alpha$ value. Then, the best $\alpha$ value is identified by exhaustively searching within identified range.

Following the dense LF refocusing algorithm, we create a $\mathcal{M}_{\alpha}(n_x,n_y)$ consists of corresponding $\alpha$ values for each region. After that, each region with an unique $\alpha$ value is separately refocused using~\eqref{eq:LF_refocus_simple} and concatenate together to get the intermediate multi arbitrary-volume refocused image $\mathcal{I}_t$. But this result suffers from ghosting artifacts in out-of-focus regions due to the undersampling of LF. To reduce this artifact, we post-process  $\mathcal{I}_t$ using an image restoration CNN to get the final refocused image  $\mathcal{I}_f$ (\figurename~\ref{fig:sparse_multi_refocused_img_slices}). The overall algorithm for sparse LF refocusing is presented in Algorithm \ref{alg:sparse_LF_refocus}. The proposed aliasing reduction method is discussed in the following section \ref{sec:cnn}.

\begin{algorithm}[!h]
\scriptsize
\caption{Sparse LF multi arbitrary-volume refocusing}\label{alg:sparse_LF_refocus}

\hspace*{\algorithmicindent} \textbf{Input:} Original Light Field ($\mathcal{I}_{LF}$) \\
\hspace*{\algorithmicindent} \hspace{.9cm} Default $\alpha$ ($\alpha_d$)\\ 
\hspace*{\algorithmicindent} \textbf{Output:} Refocussed Light Field ($\mathcal{I}_f$)

\begin{algorithmic}[1]

\Procedure{Sparse\_LF\_Multi\_Volume\_Refocus}{$\alpha_{d}$, $\mathcal{I}_{LF}$}
\State $\mathcal{R}_{ROI} \gets  [\mathcal{R}^1, \mathcal{R}^2, ..., \mathcal{R}^N]$
    \Comment{User selected ROIs}
    \State $\Phi \gets [\phi^1, \phi^2, ..., \phi^N],~\phi^i \in \{\mathfrak{R}_{n}, \mathfrak{R}_{w}\}$
    \Comment{Mode of refocus}
    \State $\mathcal{I}_t \gets \{0:\forall(n_x,n_y)\}$ \Comment{Initialize $\mathcal{I}_t$ to zeros}
    \State $\mathcal{M}_\alpha$ $\gets$ \Call{Generate\_Alpha\_Mask}{$\alpha_{d}$, $\mathcal{R}_{ROI}$, $\Phi$, $\mathcal{I}_{LF}$}

    \ForEach{$\alpha$ in $\mathcal{M}_\alpha$}
        \State $I_{\alpha}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}_{LF}$, $\alpha$} \Comment{Eq.~\ref{eq:LF_refocus_simple}}
        \State $\mathcal{K} \gets \{(n_x,n_y):\mathcal{M}_{{\alpha}_{(n_x,n_y)}}=\alpha\}$
        \State $\mathcal{I}_f[n_x,n_y]$ $\gets$ $I_{\alpha}[n_x,n_y] \;\forall(n_x,n_y)\in\mathcal{K}$;

    \EndFor
    \State $\mathcal{I}_f \gets$ \Call{Remove\_Aliasing\_Artifacts}{$\mathcal{I}_t$}
    \State \textbf{return} $\mathcal{I}_f$
\EndProcedure

% \algstore{algo_cont_1} 
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[H]
% \begin{algorithmic}[1]
% \algrestore{algo_cont_1} 
% \scriptsize

\Procedure{Generate\_Alpha\_Mask}{$\alpha_{d}$, $\mathcal{R}_{ROI}$, $\Phi$, $\mathcal{I}_{LF}$}
    \State $\mathcal{M}_\alpha \gets \{\alpha_d:\forall(n_x,n_y)\}$ \Comment{Initialize $\mathcal{M}_\alpha$ to $\alpha_d$} %of what shape?
    % \State N = length\{ROIs\};
    % \ForEach{($\mathcal{R}^i \in \mathcal{R}_{ROI}$ \& $\phi^i \in \Phi$)}
    \For{$i \gets 1$ to $N$}
        \State $\mathcal{R}_{c} \gets \mathcal{R}_{ROI}[i]$
        \State $\phi_{c} \gets \Phi[i]$
        % \State Get the $LF\_S^{\mathfrak{R}}$ LF's slice of $\mathfrak{R}$ ROI.
        % \State Get the $SAI\_S^{\mathfrak{R}}$ middle SAI's slice of $\mathfrak{R}$ ROI.
        \If{($\phi_c == \mathfrak{R}_{n}$)}
            \State $\mathcal{S}_{LF} \gets Slice(\mathcal{I}_{LF},\mathcal{R}_c) $;
            \State $\mathcal{S}_{SAI} \gets Slice(\mathcal{I}_{SAI},\mathcal{R}_c) $
            \State $[\alpha_{min},\alpha_{max}]$ $\gets$ \Call{Get\_Alpha\_Range}{$\mathcal{S}_{LF}$, $\mathcal{S}_{SAI}$}
            \State $\alpha$ $\gets$ \Call{Get\_Alpha}{$\mathcal{S}_{LF}$, $\mathcal{S}_{SAI}$, $\alpha_{min}$, $\alpha_{max}$};
            \State $\mathcal{M}_\alpha$[$\mathcal{R}_c$] $\gets$ $\alpha$
        % \Else  \Comment{$\phi_c \in \mathfrak{R}_{w}$} 
        \Else  \Comment{$\mathcal{R}_c \in \mathfrak{R}_{w}$, Divide $\mathcal{R}_c$ into smaller patches $p^j$, $j=1,2,..,M$} 
        
        
        \State $\mathcal{P}_c \gets$ $[p^1, p^2, ..., p^M]$ 
            % \State Divide $\mathcal{R}^i$ ROI into  smaller $\mathcal{P}^j$ patches.
            % \ForEach{$\mathcal{P}^j$ in $\mathcal{R}^i$}
                % \State $LF\_S^{\mathcal{P}^j}$ = LF[$\mathcal{P}^j$];
                % \State $SAI\_S^{\mathcal{P}^j}$ = $SAI\_S^{\mathfrak{R}}$[$\mathcal{P}^j$];
        \For{$j \gets 1$ to $M$}  
        \State $p_c \gets$ $\mathcal{P}_c[j]$
        \Comment{$j^{th}$ patch in $\mathcal{R}_c$}
        \State ${\mathcal{S}_{LF}} \gets Slice(\mathcal{I}_{LF}, p_c) $
        \State ${\mathcal{S}_{SAI}} \gets Slice(\mathcal{I}_{SAI}, p_c) $
        \State $[\alpha_{min},\alpha_{max}]$ $\gets$ \Call{Get\_Alpha\_Range}{${\mathcal{S}_{LF}}$, ${\mathcal{S}_{SAI}}$}
                \State $\alpha$ $\gets$ \Call{Get\_Alpha}{${\mathcal{S}_{LF}}$, ${\mathcal{S}_{SAI}}$, $\alpha_{min}$, $\alpha_{max}$}
                \State $\mathcal{M}_\alpha$[$p_c$] $\gets$ $\alpha$;
            \EndFor
        \EndIf
    \EndFor
    \State \textbf{return} $\mathcal{M}_\alpha$
\EndProcedure

% \algstore{algo_cont_2} 
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[H]
% \begin{algorithmic}[1]
% \algrestore{algo_cont_2} 
% \scriptsize

\Procedure{Get\_Alpha\_Range}{$\mathcal{I}^S_{LF}$, $\mathcal{I}^S_{SAI}$}
    \State $\alpha_{l} \gets 0.0$; $\alpha_{m} \gets 1.0$; $\alpha_{r} \gets 2.0$; \Comment{Initialize}
    
    \While {True}
        \State $\mathcal{I}_{l}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}^S_{LF}$, $\alpha_{l}$} \Comment{Eq.~\ref{eq:LF_refocus_simple}}
        \State $\mathcal{I}_{m}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}^S_{LF}$, $\alpha_{m}$} \Comment{Eq.~\ref{eq:LF_refocus_simple}}
        \State $\mathcal{I}_{r}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}^S_{LF}$, $\alpha_{r}$} \Comment{Eq.~\ref{eq:LF_refocus_simple}}
        
        \State $SIM_{\alpha_{l}}$ $\gets$ \Call{MS\_SSIM}{$\mathcal{I}_{l}$, $\mathcal{I}^S_{SAI}$}
        \State $SIM_{\alpha_{m}}$ $\gets$ \Call{MS\_SSIM}{$\mathcal{I}_{m}$, $\mathcal{I}^S_{SAI}$}
        \State $SIM_{\alpha_{r}}$ $\gets$ \Call{MS\_SSIM}{$\mathcal{I}_{r}$, $\mathcal{I}^S_{SAI}$}
        \vspace{.1cm}
        \If{($SIM_{\alpha_{l}}<SIM_{\alpha_{m}}$ \& $SIM_{\alpha_{m}} < SIM_{\alpha_{r}}$)}
            \State $\alpha_{l}\gets\alpha_{l}+1; \alpha_{m}\gets\alpha_{m}+1; \alpha_{r}\gets\alpha_{r}+1;$
        
        \ElsIf {($SIM_{\alpha_{l}}>SIM_{\alpha_{m}}$ \& $SIM_{\alpha_{m}}>SIM_{\alpha_{r}}$)} 
            \State $\alpha_{l}\gets\alpha_{l}-1; \alpha_{m}\gets\alpha_{m}-1; \alpha_{r}\gets\alpha_{r}-1;$
        \Else  \Comment{($SIM_{\alpha_{l}} < SIM_{\alpha_{m}}$ \& $SIM_{\alpha_{r}} > SIM_{\alpha_{m}}$)}
            \State \textbf{return} [$\alpha_{l},\alpha_{r}$]
        \EndIf
    \EndWhile
\EndProcedure

% \algstore{algo_cont_3} 
% \end{algorithmic}
% \end{algorithm}

% \begin{algorithm}[!h]
% \begin{algorithmic}[1]
% \algrestore{algo_cont_3} 
% \scriptsize

\Procedure{Get\_Alpha}{$\mathcal{I}^S_{LF}$, $\mathcal{I}^S_{SAI}$,  $\alpha_{min}$, $\alpha_{max}$}
    \State $SIM_{prev} \gets 0.0$; $\alpha_{best} \gets 0.0$; \Comment{Initialize}
    \For{($\alpha \gets \alpha_{min}$ : $\alpha \leq \alpha_{max}$ : $\alpha \mathrel{{+}{=}} \Delta\alpha$)}
        \State $\overline{\mathcal{I}_t}$ $\gets$ \Call{LF\_Refocus}{$\mathcal{I}^S_{LF}$, $\alpha$} \Comment{Eq.~\ref{eq:LF_refocus_simple}}
        \State $SIM_{\alpha}$ $\gets$ \Call{MS\_SSIM}{$\overline{\mathcal{I}_t}$, $\mathcal{I}^S_{SAI}$}
        \If{$SIM_{\alpha}\geq SIM_{prev}$}
            \State $\alpha_{best} \gets \alpha$
            \State $SIM_{prev} \gets SIM_{\alpha}$
        \EndIf
    \EndFor
    \State \textbf{return} $\alpha_{best}$
\EndProcedure
\end{algorithmic}
\end{algorithm}



\subsection{Reducing Aliasing Artifacts using Image Restoration CNN} \label{sec:cnn}

\begin{figure*}[!t]
    \centering

    \begin{subfigure}[c]{0.64\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{images/multi_area/multi_refocused_dense_2.jpg}
         \caption{}
         \label{fig:dense_refocused_img}
     \end{subfigure}
     \hfill
    \begin{subfigure}[c]{0.64\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{images/multi_area/multi_refocus_sparse_before_2.jpg}
         \caption{}
         \label{fig:sparse_before_cnn}
     \end{subfigure}
     \hfill
     \begin{subfigure}[c]{0.64\columnwidth}
         \centering
         \includegraphics[width=\textwidth]{images/multi_area/multi_refocus_sparse_after_2.jpg}
         \caption{}
         \label{fig:sparse_after_cnn}
     \end{subfigure}
    \caption{Refocused image quality comparison between dense and sparse LF refocusing methods; (a) refocused using the dense LF; (b) refocused cross-shaped sparse LF without post-processing; (c) refocused using cross-shaped sparse LF with post-processing.}
    \label{fig:denseSparsPostProcess}
\end{figure*}

The ghosting artifacts due to undersampling of LF makes $\mathcal{I}_t$ image unnatural. Therefore, these artifacts should be minimized. To this end, we approach this problem as an image restoration task. The  $\mathcal{I}_t$ is post-processed using an image restoration CNN to remove the ghosting artefacts and further improve the quality and generate $\mathcal{I}_f$. As an example \figurename~\ref{fig:dense_refocused_img} shows the ``Mirabelle Prune Tree" dense LF from EPFL LF dataset~\cite{epfldataset} refocused using~\eqref{eq:LF_refocus_simple} for single ROI. It has been properly refocused to the required depth while out-of-focus regions are blurred. \figurename~\ref{fig:sparse_before_cnn} shows the same refocused image but using the corresponding sparse LF. Due to the undersampling, this image has clearly visible ghosting artifact in out-of-focus regions. After post-processing this refocused image using the image restoration CNN, ghosting artifact is reduced significantly as shown in \figurename~\ref{fig:sparse_after_cnn}. 

%  The blind/referenceless image spatial quality evaluator (BRISQUE) score \cite{brisque} is quite high with respect to BRISQUE score of refocused image from dense LF.

Out of the many state-of-the-art data-driven methodologies~\cite{hinet,mprnet} that perform the image restoration have been derived from U-Net~\cite{unet}, a base network which is used predominantly for medical image restoration. Modern image restoration algorithms~\cite{swinir} have shifted towards the adoption of vision transformer-based (ViT) principles, however, with the requirement of vast amount of data to learn the restoration patterns. This is, however, a bottleneck for us as the number of LFs available are too little to learn a robust image restoration ViT. Therefore, we adopt U-Net~\cite{unet} architecture with some modifications for our image restoration CNN.

% \textbf{Architecture:}
\subsubsection{Ground Truth and Input Generation}
The inputs to the image restoration network are generated using our proposed sparse LF refocusing algorithm that is discussed in Section \ref{sec:sparse_refocus}. To perform supervised training to remove the aliasing artefacts present in the inputs, a corresponding ground truth is generated using our proposed dense LF refocusing algorithm that is discussed in Section \ref{sec:dense_refocus}. 

% \textcolor{red}{Check the above whether it make sense - I rewrote the below passage.}
% The ground truths to be used to reduce the ghost artifacts using the image restoration network are d  and input refocused images for the network are generated using the dense LF refocusing and sparse LF refocusing methods discussed in section \ref{sec:dense_refocus}, \ref{sec:sparse_refocus} respectively. 

To address the lack of data to learn the general patterns to restore a given  $\mathcal{I}_t$ refocused image with ghosting effects present, we utilize patch-wise training. Following \cite{deep_sparse}, the patches are generated by cropping $m \times m$ areas of the input in a non-overlapping manner. In our method, we used $m=100$ to reduce the computational complexity required to run through an entire input. 

% \vspace{-1cm}
\subsubsection{Loss Function}

Modifying the traditional loss function for image restoration, we propose a loss function $\mathcal{L}$ that combines conventional \emph{mean squared error loss} ($\mathcal{L}_{MSE}$), \emph{$L_1$ loss} ($\mathcal{L}_{L_1}$) with MS\_SSIM~\cite{ms_ssim} and PSNR~\cite{psnr} to preserve image quality. The loss function $\mathcal{L}$ is defined as   
\begin{align} \label{loss_func}
    \mathcal{L} = \mathcal{L}_{MSE} + \beta\mathcal{L}_{SSIM} + (1 - \beta)\mathcal{L}_{L_1} + \gamma\mathcal{L}_{PSNR},
\end{align}
where
\begin{align}
\mathcal{L}_{SSIM} &= 1-\mathrm{MS\_SSIM}( P_{g} ,P_{p}) \\
\mathcal{L}_{PSNR} &= 1/\mathrm{PSNR}( P_{g} ,P_{p}),
\end{align}
Here, $P_{g}$ and $P_{p}$ denote ground truth patch and predicted patch. $\beta, \gamma$ are the tuning parameters. Similar type of loss function is used in \cite{machinelearning_multi_refocus}. In our work, we utilize  0.65 and 500 for $\beta$ and $\gamma$, respectively.
% \textcolor{red}{Mention "In our worked, we utilized, " the values of tuning parameters.}

% \textcolor{red}{Can we write something on how our loss is different to theirs? Or is it the same?}.:- (It is almost same)
% \textcolor{red}{COMMENT: PSNR definition - cite a paper with the equation or define it in the paper before $\mathcal{L}_{PSNR}$ is defined.}

% \textcolor{red}{Will need a figure on how U-Net is trained/tested. -- Starting with Input --> Patch creating --> Modified U-Net --> Loss}

