\section{Experiments and Results}
\label{sec:experiments}

This section presents the real-world evaluation of DEFT, covering:
1) A quantitative accuracy comparison with state-of-the-art methods, including scenarios where grasping occurs at various points along the BDLO, such as parent-branch ends and midpoints;
2) An assessment of DEFT’s inference speed;
3) An ablation study exploring parameter auto-tuning, residual learning, and a naive multi-branch approach that connects multiple single-DLO models;
4) Shape-matching manipulation demonstrations, highlighting DEFT’s real-world manipulation efficacy;
5) Thread insertion manipulation demonstrations, showcasing DEFT’s versatility.
Code and data will be made publicly available upon final paper acceptance. 
To the best of our knowledge, this will be the first publicly available dataset and code for modeling BDLOs.

\subsection{Hardware Setup}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/experiment_setup.png}
    \caption{An illustration of experiment setup.
    Top: Data collection setup with a dual-arm robot. 
    Bottom: An illustration of the BDLOs used to evaluate and compare the performance of DEFT against baseline methods. 
    To increase dataset diversity, we vary the BDLOs’ stiffness, length, weights, number of vertices, and junction structures.}    
    \label{fig:experimentsetup}
\end{figure}


\begin{table*}[t]
\centering
\caption{A summary of each BDLO's material properties and marker count used in the real-world experiment. Stiffness is estimated based on a relative scale.}
\label{mat_prop}
\begin{tabular}{c|| c |c | c| c |c}
\toprule
BDLO & \makecell{Parent\\ Stiffness / \#Markers} & \makecell{Child1\\ 
Stiffness / \#Markers} & \makecell{Child2\\ Stiffness / \#Markers} & \makecell{Dataset 1 \\ Time (s)} & \makecell{Dataset 2 \\ Time (s)} \\
\hline 

1 & Medium / 13 & Medium / 4 & Medium / 3 & 505 & 440 \\
2 & Low / 12    & Low / 4    & Low / 4    & 735  & N/A\\
3 & Medium / 12 & Low / 2    & High / 3   & 645 & 445\\
4 & Medium / 12 & High / 2   & High / 2   & 495 & N/A \\
\bottomrule
\end{tabular}
\end{table*}

\subsubsection{Hardware Setup}
Four distinct BDLOs were constructed to validate DEFT’s modeling accuracy as shown at the bottom of Figure \ref{fig:experimentsetup}. 
The material stiffness description of each BDLO is outlined in Table~\ref{mat_prop}. 
Note that we introduced stiff child branches attached to the parent branch in BDLO3 and BDLO4. 
These branches represent the rigid components (e.g., fixations) commonly used in BDLO construction~\cite{wireharnesinstruction}.
These attachments help ensure secure mounting, preserve structural integrity, and manage loads in real‐world applications.
Spherical markers were attached to each BDLO to facilitate dataset creation for both training and evaluation, with the number of vertices set equal to the number of MoCap markers. 
Because the markers are present during both training and evaluation, their impact on the BDLO dynamics is inherently accounted within all subsequent analyses.
If one wishes to obtain a BDLO dataset without relying on real-world motion capture, a finite element method-based simulator could be employed. 
Note that the markers are \emph{only} used to create training and evaluation datasets, as well as evaluate the performance of \DEFTn by providing the ground truth. 
However, for real-world applications, the markers are not needed.
For dual manipulation, a Franka Emika Research 3 robot and a Kinova Gen3 robot were used. 
An illustration of the experimental setup is shown in Figure \ref{fig:experimentsetup}.
We used an OptiTrack motion capture system to record ground-truth vertex locations. 
Note in our implementation of DEFT we set $\epsilon = 0.1$ (Theorem \ref{thm:junctionconstraint}) and $\kappa = 0.02$ (Algorithm \ref{alg:constraints enforcement}).

\subsubsection{Dataset Collection and Training}

We collected dynamic trajectory data for selected BDLOs in the real world using a motion capture system operating at 100 Hz, capturing both slow and fast BDLO motions, as illustrated at the top of Figure \ref{fig:experimentsetup}.
We split our data collection into two categories: 
\begin{itemize}
  \item Dataset 1: each robot grasps one end of the BDLO.  
  Data from this category were collected for all BDLOs.
  \item Dataset 2:
  One robot grasped one end of the BDLO while the other robot grasped the BDLO at its midpoint.
  This dataset is collected for BDLOs 1 and 3.
\end{itemize}
Total collection times are provided in Table \ref{mat_prop}.
The dataset is split with \(\sim \)75\% for training and \(\sim \)25\% for evaluation.
The model for each of the four BDLOs is trained separately using the trajectory data collected from our real-world experiments.
During training, models are trained using the same 100 steps (i.e., 1s) of dynamic motion
Each method's performance is evaluated when predicting the state of the wire over a 500 step (i.e. 5s) prediction horizon using just the state of the wire at the initial time and the orientation and position of the two end effectors at each time step. 


\subsection{Baseline Comparisons} 
 Only a limited number of papers have investigated the dynamic behavior of BDLOs, and none provide a differentiable framework for learning real-world dynamics from real-world datasets.
Moreover, no public code repositories are available for these approaches, making direct replication infeasible. 
% Furthermore, no robotics-related paper has presented a quantitative evaluation of BDLO modeling.
We select two available implementations, Tree-LSTM \cite{treeLSTM} and GCN \cite{GCN} as baseline prediction models for BDLOs.
Tree-LSTM and GCN both capture structured relationships.
Specifically, Tree-LSTM leverages hierarchical tree representations, while GCN excels in graph-based modeling. 
Because BDLOs can be described by nodes and edges, these architectures are naturally able to incorporate a BDLO's dynamics.

\subsection{Modeling Results}
Table \ref{tab:model accuracy end points1} summarizes the average RMSE loss when comparing DEFT to baseline methods for two categories of dataset. 
Performance is evaluated over a 5 second prediction horizon for four different BDLOs. 
Note that DEFT outperforms all baselines across all four BDLOs.
An illustration of the performance of DEFT, Tree-LSTM, and an ablation of DEFT, which is described in more detail in the next subsection, can be found in Figure \ref{fig:modeling_vis}.
A video of related experiments can be found in the supplementary material.
\begin{table}[t]
\centering
\caption{Modeling Results Over a $5$s Horizon}
\begin{tabular}{l||cccc|cc}
    \toprule
    & \multicolumn{6}{c}{Modeling Accuracy (RMSE, $10^{-2}$ m)}  \\     
    & \multicolumn{4}{c|}{Dataset 1}& \multicolumn{2}{c}{Dataset 2}  \\ 
    Method & 1 & 2 & 3 & 4 & 1 & 3    \\
    \hline
    GCN \cite{GCN} & 6.70 & 6.42  & 5.25 & 4.20 & 7.33 & 4.24 \\
    Tree-LSTM \cite{treeLSTM} & 5.32 & 4.50 & 2.46 & 2.71 & 7.08 & 4.55 \\
    DEFT & \textbf{1.87} &  \textbf{2.82} &  \textbf{1.51} &  \textbf{1.41} & \textbf{1.49} &  \textbf{1.80}\\
    \bottomrule
\end{tabular}
\label{tab:model accuracy end points1}
\end{table}

% \begin{table}[h]
% \centering
% \caption{Modeling Accuracy ($10^{-2}$m)}
% \begin{tabular}{l|cccc}
%     \toprule
%     & \multicolumn{4}{c}{Middle Clamp}  \\         
%     Method & 1 & 3     \\
%     \midrule
%     GNN & 0.0733 & 0.0424 \\
%     Tree-LSTM & 0.0708 & 0.0455 \\
%     DEFT & \textbf{0.0149} & \textbf{0.0180} \\
%     \bottomrule
% \end{tabular}
% \label{tab:model accuracy mid points2}
% \end{table}
\begin{figure*}[t]
    \centering
    \includegraphics[width=0.78
    \textwidth]{figures/modeling_vis.pdf}
    \caption{Visualization of the predicted trajectories for BDLO 1 under two manipulation scenarios, using DEFT, a DEFT ablation that leaves out the constraint described in Theorem \ref{thm:junctionconstraint}, and Tree-LSTM. The ground-truth initial position of the vertices are colored in blue, the ground-truth final position of the vertices are colored in pink, and the gradient between these two colors is used to denote the ground truth location over time. 
    The predicted vertices are colored as green circles (DEFT), orange circles (DEFT ablation), and light red circles (Tree-LSTM), respectively.
    A gradient is used for these predictions to depict the evolution of time, starting from dark and going to light.
    Note that the ground truth is only provided at $t$=0s and prediction is constructed until $t$=8s.
    The prediction is performed recursively, without requiring additional ground-truth data or perception inputs throughout the entire process.}    
    \label{fig:modeling_vis}
\end{figure*}



\subsection{Compuational Experiment}
\label{sec:computationaltime}


\begin{table}[t]
    \caption{One Step Inference Time with Dataset 1}
    \begin{tabular}{c||cccc}
        \toprule
        & \multicolumn{4}{c}{Time ($10^{-2}$ s)} \\         
        Method & 1 & 2 & 3 & 4   \\
        \hline
        GCN \cite{GCN} & \textbf{0.20} & \textbf{0.19} & \textbf{0.13} & \textbf{0.13} \\
        Tree-LSTM \cite{treeLSTM} & 1.81 & 2.44 & 1.79 & 1.89 \\
        DEFT & 0.76 & 0.70 & 0.91 & 0.93  \\
        \bottomrule
    \end{tabular}
    \label{tab:computational speed1}
        \centering
\end{table}

This section evaluates the computational efficiency of DEFT when compared to baseline methods. 
It also examines how employing the analytical gradient derived from Theorem \ref{thm:potential_energy_gradient} to compute \eqref{eq:innerloop} and the parallel programming approach detailed in Section \ref{section:parallelprogramming}, impacts overall computational time. 
All experiments in this section were conducted in Python on an Ubuntu 20.04 equipped with an AMD Ryzen PRO 5995WX CPU, 256GB of RAM, and 128 cores.
\subsubsection{Computational Speed Comparison}
We compare computational speed for one step inference. 
Table \ref{tab:computational speed1} indicates that GCN has the fastest speed. 
DEFT is the second fastest and is able to generate single step predictions at a 100Hz frequency.
\subsubsection{Computational Speed with Analytical Gradient}
We compare the computational speed of using analytical gradients when compared to using numerical gradients. 
As summarized in Table \ref{tab:computational speed2}, computing \eqref{eq:innerloop} with the analytical gradient is approximately twice as fast as using numerical gradients.

\begin{table}[t]
        \centering
    \caption{Compuational Time for \eqref{eq:innerloop} with Dataset 1}
    \begin{tabular}{l||cccc}
        \toprule
        & \multicolumn{4}{c}{Time ($10^{-2}$ s)} \\         
        Method & 1 & 2 & 3 & 4   \\
        \hline
        Analytical Gradient & \textbf{0.34} & \textbf{0.27} & \textbf{0.41} & \textbf{0.46}  \\
        Numerical Gradient & 0.74 & 0.65 & 0.84 & 0.91 \\
        \bottomrule
    \end{tabular}
    \label{tab:computational speed2}
    \centering
\end{table}
\begin{figure*}[t]
    \centering
    \includegraphics[width=1\textwidth]{figures/planning_fig.pdf}
    \caption{Visualization of planning for BDLO 1 for two manipulation tasks, using DEFT, a DEFT ablation that leaves out the constraint described in Theorem \ref{thm:junctionconstraint}, and Tree-LSTM.
    The BDLO’s goal configuration is highlighted in yellow, while the target hole is shown in red. 
    The DEFT model enables the planning algorithm to successfully complete the task, whereas the ablation approach of DEFT and the Tree-LSTM model both fail to finish tasks.}    
    \label{fig:planning_demo}
\end{figure*}
\subsubsection{Computational Speed with Parallel Programming}
We compare the computational performance of using parallel programming approach described in Section \ref{section:parallelprogramming} to a naive (sequential) implementation, in which each branch is simulated one after the other. 
In this experiment, we use the material properties of BDLO1 and gradually increase the number of children branches from 1 to 8. 
As shown in Figure \ref{fig:computational speed3}, the naive implementation’s computation time grows more rapidly than that of the parallel approach.
However, a certain increase in computational time is still expected with parallelization. 
As illustrated in Figure \ref{fig:deft_contribution_diagram}, constraints at each junction between the parent branch and its child branches prevent a fully batch-based operation, thereby resulting in an increase in the computational time.
\begin{table*}[t]
    \centering
    \caption{Ablation Study with Dataset 1}
    \begin{tabular}{l||cccc|cc}
        \toprule
        & \multicolumn{6}{c}{Modeling Accuracy (RSME, $10^{-2}$ m)$\downarrow$}  \\ 
        & \multicolumn{4}{c|}{Dataset 1}& \multicolumn{2}{c}{Dataset 2}  \\ 
        Method & 1 & 2 & 3 & 4  & 1 & 2 \\
        \hline 
        W/O Constraints.\ref{theorem:inextensibility}, \ref{theorem:constraint_attachement} and \ref{thm:junctionconstraint} & $7.66\times10^8$ & $6.10\times 10^8$ & $6.56\times 10^6$ & $1.77\times10^8$ & $3.81\times 10^7$ & $1.23\times10^8$\\
        W/O Constraints.\ref{theorem:constraint_attachement} and \ref{thm:junctionconstraint} & $1.36 \times 10^2$ & $1.81 \times 10^2$& $1.51\times10^2$ & $7.64 \times 10^1$ & $8.72\times10^1$ & $3.38\times10^2$\\
        W/O Constraint.\ref{thm:junctionconstraint} & 3.95 & 3.49 & 2.03 & 2.15 & 4.01 & 4.88\\
        W/O Learning + System ID & 2.46 & 3.53 & 1.85 & 1.77 & 2.03 & 2.21\\
        W/O System ID & 2.24 & 3.00 & 1.67 & 1.50 & 1.66 & 1.95\\
        W/O Residual Learning & 1.93 & 3.19 & 1.70 & 1.62 & 1.86 & 1.89\\        
        % W Naive Coupling: \\
        Full Model & \textbf{1.87} &  \textbf{2.82} &  \textbf{1.51} &  \textbf{1.41} & \textbf{1.49} &  \textbf{1.80}\\
        \bottomrule
    \end{tabular}
    \label{tab:ablation}
\end{table*}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/Computaional_time_parallel.png}
    \caption{Computational speed comparison: parallel programming versus a naive (sequential) implementation.
    }
    \label{fig:computational speed3}
\end{figure}

\subsection{Ablation Study}
The results presented in Table \ref{tab:ablation} demonstrate the contribution of each DEFT component. 
Notably, excluding Theorems \ref{theorem:inextensibility}, \ref{theorem:constraint_attachement}, and \ref{thm:junctionconstraint} causes a significant increase in prediction loss. 
This outcome is primarily driven by the absence of Theorem \ref{theorem:inextensibility}, which leads to simulation instability. 
Although residual learning is used to mitigate errors, directly modeling stiff behaviors, such as the inextensibility of DLOs, remains challenging, making the learning process highly sensitive to inputs and hampering effective gradient propagation.
A key challenge in using neural networks to learn position-based constraints is that constraints such as inextensibility confine the system to a low-dimensional manifold within a high-dimensional space. 
Without these constraints, it becomes difficult for the network alone to keep the system on that manifold.
Over multiple open-loop predictions, even minor errors can accumulate and push the system state off the manifold, causing reduce of residual learning's effect.
Similarly, removing Theorem \ref{theorem:constraint_attachement} allows the children branch to detach from parent branch, and therefore fall freely under gravity, leading to a substantial increase in loss. 
Moreover, excluding Theorem \ref{thm:junctionconstraint} reduces accuracy, demonstrating the importance of introducing rigidity at junctions to allow dynamic propagation across branches.

Despite these challenges, auto-tuning the material properties provides the most substantial improvement over the baseline, illustrating DEFT’s ability to leverage real-world data for parameter identification. 
Residual learning also yields a non-trivial performance gain. 
By contrast, the model that do not learn from real-world data underperforms those that do, illustrating the importance of differentiability in this framework.

\subsection{Planning Results}


This section demonstrates how these BDLO models can be used for planning tasks, including shape matching and thread insertion. 
We compare three approaches: 
DEFT, which is our proposed method; 
DEFT without the constraint described in Theorem \ref{thm:junctionconstraint}, an ablation approach that removes rigidity at junctions and thus limits dynamic propagation across branches;
Tree-LSTM, the baseline model with performance closest to DEFT. 
In these experiments, we employ ARMOUR \cite{ARMOUR}, a receding-horizon trajectory planner and tracking controller, to manipulate BDLOs. 
ARMOUR relies on each model’s predicted BDLO states to guide the BDLO to a desired final configuration. 
Further details on integrating ARMOUR with BDLO simulators are provided in Appendix \ref{armour_appendix}.
The results are summarized in Table~\ref{tab:planning}, and Figure \ref{fig:planning_demo} shows one of the real-world results.
% An illustration of the results of this comparison experiment can be found in Figure \ref{fig:shape_control_exp}.
A video of these experiments can be found in the supplementary material.

\begin{table}[t]
    \caption{Real-World Trajectory Planning Results}
            \centering
    \begin{tabular}{l||c|c}
        \toprule
        & \multicolumn{2}{c}{Successful Rate}  \\     
        & \multicolumn{1}{c}{Shape Matching} & \multicolumn{1}{c}{Thread Insertion} \\         
        \hline
        Tree-LSTM \cite{treeLSTM} & 2/40 & 0/35\\
        DEFT w/o Theorem \ref{thm:junctionconstraint} & 27/40 & 16/35 \\
        DEFT & \textbf{35/40} & \textbf{29/35} \\
        \bottomrule
    \end{tabular}
    \label{tab:planning}
            \centering
\end{table}
\subsubsection{Shape Matching}
In this experiment a goal configuration for the wire is specified and a random initial condition for the wire is chosen. 
 A trial is considered successful if the Euclidean distance between each ground-truth vertex and its corresponding target vertex after planning is less than 0.05 m.
If the task is not completed within 30 seconds, the trial is marked as a failure. 
As summarized in Table ~\ref{tab:planning} (left column), DEFT achieves a higher success rate than the other two models.
Note that these experiments were all conducted in the real-world which further demonstrates the practical applicability of DEFT.

\subsubsection{Thread Insertion}
In this experiment, the planning algorithm must insert the end of the BDLO into a hole of radius $2.5$cm which is placed in arbitrary location. 
The process consists of two stages—shape matching and thread insertion—which together require two goal configurations for the wire.
Unlike the previous experiment, in which the robot grasps the branch end, the robot’s end effector clamps the third vertex from the branch’s insertion point.
The trial is deemed successful if the BDLO branch successfully passes through the torus while also matching the user-specified wire shape successfully. 
As shown in Table ~\ref{tab:planning} (right column), DEFT again achieves a higher success rate than the other two models.
Note that these experiments were all conducted in the real-world which further demonstrates the practical applicability of DEFT.


