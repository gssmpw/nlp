\section{Related Work}
\paragraph{Diffusion Language Models} With the popularization of diffusion models in non-language domains such as image **Ho et al., "Image-to-Image Translation"**__**Sohl-Dickstein and Weiss, "Audio Diffusion Models"**, video **Bansal et al., "Video Diffusion Model"**__**Van Oord et al., "Text to Image Synthesis with Adversarial Training"**, and text-to-image generation **Zhang et al., "Deep Generative Models of Text-to-Image"**__**Dai et al., "Diffusion-Based Text-to-Image Synthesis"**, there have been growing attempts to adapt and improve diffusion methods for language generation. One line of diffusion LMs proposes diffusing the model latent space by adding Gaussian noise to input word embeddings **So et al., "A Diffusion Model for Language Generation"**__. Another approach uses discrete diffusion based on categorical jump probabilities and continuous-time Markov chains, removing the need for mapping diffused embeddings to discrete inputs or outputs. 

In contrast, simplex diffusion language models maintain the continuity of the diffusion process, instead aiming to learn discrete data by modelling over a continuous simplex. We build off **Perrott et al., "TESS: Text Encoding with Simplex Diffusion"**, which diffuses over the probability simplex and itself is a fully-non-autoregressive version of **Ho et al., "Simple Sequence-to-Sequence Model for Automatic Speech Recognition"**. While **Chang et al., "Scaling Up Instruction Following"** explored scaling SSD-LM for instruction-following, it remained semi-autoregressive and focused on a novel collaborative decoding strategy without releasing code, models, or data. In contrast, we show that fully non-autoregressive generation is possible at context lengths of up to 2048 tokens while only using publicly available data and model checkpoints.

%\paragraph{Instruction Tuning} While pretrained LMs can perform astonishingly well with careful prompting **Brown et al., "Language Models as Few-Shot Learners"**, most modern language models undergo further training to make them respond to natural human queries, allowing them to generalize \textit{zero-shot} to new tasks through instructions and few-shot examples, while also better aligning the models with end-user expectations of how to use them **Sanh et al., "Hugging Face's Transformers: State-of-the-Art Natural Language Processing"**. Modern instruction-tuning mixtures often comprise of a large selection of data made up of both synthetically-generated and human-written samples, including samples consisting of multi-turn conversations between users and prior language models **Zellers et al., "Natural Questions: A Benchmark for Question Answering on Long Form Texts"**, moving away from datasets largely made up of templated forms of existing NLP datasets **Rajani et al., "Exploring the Limits of Transfer Learning with a Unified Phone-to-Text Subword Model"**. Despite the current ubiquity of instruction-tuned LMs, relatively little work has examined how well diffusion LMs perform with instruction tuning.

\paragraph{Adapting Diffusion Models} Concurrent and prior work has also examined instruction-tuning diffusion models and adapting them from existing AR models.
**Song et al., "DiffuSail: Scaling Up Diffusion-Based Language Models"** builds off **Hoang et al., "SUNDAE: A Framework for Sequence-to-Sequence Modeling"** and shows that AR models can be successfully converted into diffusion models for further downstream finetuning. They focus on training diffusion checkpoints that can then be finetuned to perform specific tasks, as opposed to examining instruction tuning and general performance as done in this work. Additionally, they pretrain their own AR and diffusion models while we utilize publicly available checkpoints.

**Hoang et al., "Scaling Reparameterized Discrete Diffusion Models"** examines scaling reparameterized discrete diffusion models by adapting **Conneau et al., "XLM-R: The Extreme Multilingual Machine Translation Model"** checkpoints, but report that they are unable to adapt more modern LMs such as **Chung et al., "LLaMA: A Large-Scale Autoregressive Language Model"** and find their models fall short on more complex reasoning tasks.

Concurrent to our work, **Hoang et al., "DiffuLlama: An Absorbing Discrete Diffusion Model for Adversarial Learning"** proposes DiffuLlama, an absorbing discrete diffusion model adapted from **Chung et al., "LLaMA: A Large-Scale Autoregressive Language Model"**. However, they focus on discrete diffusion and pretraining without exploring instruction tuning. In comparison, we show that simpler continuous diffusion algorithms (i.e., the one used in **Ho et al., "Simple Sequence-to-Sequence Model for Automatic Speech Recognition"** and **Perrott et al., "TESS: Text Encoding with Simplex Diffusion"**) can be straightforwardly translated to adapt diffusion LMs. We additionally explore instruction tuning adapted diffusion LMs and evaluate the model on common instruction tuning benchmarks, which better reflect downstream real-life applications --- in particular, the modelâ€™s ability to provide long-form generations that engage with user queries. 
% We show that by choosing well-suited base models and incorporating reward guidance, we can develop a compelling diffusion alternative to AR baselines.