\section{Related Work}
\paragraph{Diffusion Language Models} With the popularization of diffusion models in non-language domains such as image~\citep{nichol2021improved}, audio~\citep{kong2020diffwave,tae2022editts,Shen2023NaturalSpeech2L}, video~\citep{ho2022video}, and text-to-image generation~\citep{saharia2022photorealistic, ramesh2022hierarchical}, there have been growing attempts to adapt and improve diffusion methods for language generation. One line of diffusion LMs proposes diffusing the model latent space by adding Gaussian noise to input word embeddings \cite{li2022diffusion,gulrajani2023likelihoodbased}. Another approach uses discrete diffusion based on categorical jump probabilities and continuous-time Markov chains~\citep{lou2024discrete,richemond2022categorical,gong2024scalingdiffusionlm}, removing the need for mapping diffused embeddings to discrete inputs or outputs. 

In contrast, simplex diffusion language models maintain the continuity of the diffusion process, instead aiming to learn discrete data by modelling over a continuous simplex. We build off TESS~\citep{karimi-mahabadi-etal-2024-tess}, which diffuses over the probability simplex and itself is a fully-non-autoregressive version of SSD-LM~\citep{han2022ssd}. While \citet{han-etal-2024-david} explored scaling SSD-LM for instruction-following, it remained semi-autoregressive and focused on a novel collaborative decoding strategy without releasing code, models, or data. In contrast, we show that fully non-autoregressive generation is possible at context lengths of up to 2048 tokens while only using publicly available data and model checkpoints.

%\paragraph{Instruction Tuning} While pretrained LMs can perform astonishingly well with careful prompting~\citep{NEURIPS2020_1457c0d6}, most modern language models undergo further training to make them respond to natural human queries, allowing them to generalize \textit{zero-shot} to new tasks through instructions and few-shot examples, while also better aligning the models with end-user expectations of how to use them~\citep{mishra-etal-2022-cross,wei2022finetuned,sanh2022multitask}. Modern instruction-tuning mixtures often comprise of a large selection of data made up of both synthetically-generated and human-written samples, including samples consisting of multi-turn conversations between users and prior language models~\citep{wang2023how}, moving away from datasets largely made up of templated forms of existing NLP datasets~\citep{wei2022finetuned,sanh2022multitask}. Despite the current ubiquity of instruction-tuned LMs, relatively little work has examined how well diffusion LMs perform with instruction tuning.

\paragraph{Adapting Diffusion Models} Concurrent and prior work has also examined instruction-tuning diffusion models and adapting them from existing AR models.
\citet{han2024transferlearningtextdiffusion} builds off SUNDAE~\citep{savinov2022stepunrolled} and shows that AR models can be successfully converted into diffusion models for further downstream finetuning. They focus on training diffusion checkpoints that can then be finetuned to perform specific tasks, as opposed to examining instruction tuning and general performance as done in this work. Additionally, they pretrain their own AR and diffusion models while we utilize publicly available checkpoints.

\citet{ye2023diffusionlanguagemodelsperform} examines scaling reparameterized discrete diffusion models~\citep{zheng2024reparameterizeddiscretediffusionmodel} by adapting XLM-R checkpoints~\citep{conneau-etal-2020-unsupervised}, but report that they are unable to adapt more modern LMs such as Llama and find their models fall short on more complex reasoning tasks.

Concurrent to our work, \citet{gong2024scalingdiffusionlm} proposes DiffuLlama, an absorbing discrete diffusion model~\citep{austin2021structured} adapted from Llama~\cite{touvron2023llama2openfoundation}. However, they focus on discrete diffusion and pretraining without exploring instruction tuning. In comparison, we show that simpler continuous diffusion algorithms (i.e., the one used in SSD-LM and TESS) can be straightforwardly translated to adapt diffusion LMs. We additionally explore instruction tuning adapted diffusion LMs and evaluate the model on common instruction tuning benchmarks, which better reflect downstream real-life applications --- in particular, the modelâ€™s ability to provide long-form generations that engage with user queries. 
% We show that by choosing well-suited base models and incorporating reward guidance, we can develop a compelling diffusion alternative to AR baselines.