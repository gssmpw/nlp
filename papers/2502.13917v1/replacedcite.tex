\section{Related Work}
\paragraph{Diffusion Language Models} With the popularization of diffusion models in non-language domains such as image____, audio____, video____, and text-to-image generation____, there have been growing attempts to adapt and improve diffusion methods for language generation. One line of diffusion LMs proposes diffusing the model latent space by adding Gaussian noise to input word embeddings ____. Another approach uses discrete diffusion based on categorical jump probabilities and continuous-time Markov chains____, removing the need for mapping diffused embeddings to discrete inputs or outputs. 

In contrast, simplex diffusion language models maintain the continuity of the diffusion process, instead aiming to learn discrete data by modelling over a continuous simplex. We build off TESS____, which diffuses over the probability simplex and itself is a fully-non-autoregressive version of SSD-LM____. While ____ explored scaling SSD-LM for instruction-following, it remained semi-autoregressive and focused on a novel collaborative decoding strategy without releasing code, models, or data. In contrast, we show that fully non-autoregressive generation is possible at context lengths of up to 2048 tokens while only using publicly available data and model checkpoints.

%\paragraph{Instruction Tuning} While pretrained LMs can perform astonishingly well with careful prompting____, most modern language models undergo further training to make them respond to natural human queries, allowing them to generalize \textit{zero-shot} to new tasks through instructions and few-shot examples, while also better aligning the models with end-user expectations of how to use them____. Modern instruction-tuning mixtures often comprise of a large selection of data made up of both synthetically-generated and human-written samples, including samples consisting of multi-turn conversations between users and prior language models____, moving away from datasets largely made up of templated forms of existing NLP datasets____. Despite the current ubiquity of instruction-tuned LMs, relatively little work has examined how well diffusion LMs perform with instruction tuning.

\paragraph{Adapting Diffusion Models} Concurrent and prior work has also examined instruction-tuning diffusion models and adapting them from existing AR models.
____ builds off SUNDAE____ and shows that AR models can be successfully converted into diffusion models for further downstream finetuning. They focus on training diffusion checkpoints that can then be finetuned to perform specific tasks, as opposed to examining instruction tuning and general performance as done in this work. Additionally, they pretrain their own AR and diffusion models while we utilize publicly available checkpoints.

____ examines scaling reparameterized discrete diffusion models____ by adapting XLM-R checkpoints____, but report that they are unable to adapt more modern LMs such as Llama and find their models fall short on more complex reasoning tasks.

Concurrent to our work, ____ proposes DiffuLlama, an absorbing discrete diffusion model____ adapted from Llama____. However, they focus on discrete diffusion and pretraining without exploring instruction tuning. In comparison, we show that simpler continuous diffusion algorithms (i.e., the one used in SSD-LM and TESS) can be straightforwardly translated to adapt diffusion LMs. We additionally explore instruction tuning adapted diffusion LMs and evaluate the model on common instruction tuning benchmarks, which better reflect downstream real-life applications --- in particular, the modelâ€™s ability to provide long-form generations that engage with user queries. 
% We show that by choosing well-suited base models and incorporating reward guidance, we can develop a compelling diffusion alternative to AR baselines.