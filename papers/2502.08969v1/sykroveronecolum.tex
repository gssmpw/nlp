\documentclass[11pt]{article}
\usepackage{fullpage,graphicx,psfrag,amsmath,amsfonts,verbatim}
\usepackage{xcolor}
\usepackage{amsthm}
\usepackage[small,bf]{caption}
\usepackage{authblk}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
% \usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}
\usepackage{subcaption}

%\hypersetup{
%    colorlinks = true,
%    allcolors = {purple},
%    linkbordercolor = {white},
%}

%\input defs.tex
\allowdisplaybreaks

\bibliographystyle{alpha}

\title{\texttt{SkyRover}: A Modular Simulator for Cross-Domain Pathfinding}
\author[1]{Wenhui Ma\thanks{\texttt{wenhuima@stu.ecnu.edu.cn}}}
\author[2]{Wenhao Li\thanks{\texttt{whli@tongji.edu.cn}}}
\author[2]{Bo Jin\thanks{\texttt{bjin@tongji.edu.cn}}}
\author[3,4]{Changhong Lu\thanks{\texttt{chlu@math.ecnu.edu.cn}}}
\author[1,4]{Xiangfeng Wang\thanks{\texttt{xfwang@cs.ecnu.edu.cn}}}

\affil[1]{School of Computer Science and Technology, East China Normal University}
\affil[2]{School of Computer Science and Technology, Tongji University}
\affil[3]{School of Mathematical Sciences, East China Normal University}
\affil[4]{Key Laboratory of Mathematics and Engineering Applications, MoE}

\date{}
\begin{document}
\maketitle

\begin{abstract}

Unmanned Aerial Vehicles (UAVs) and Automated Guided Vehicles (AGVs) increasingly collaborate in logistics, surveillance, inspection tasks and etc. 
However, existing simulators often focus on a single domain, limiting cross-domain study. 
This paper presents the \texttt{SkyRover}, a modular simulator for UAV-AGV multi-agent pathfinding (MAPF). 
\texttt{SkyRover} supports realistic agent dynamics, configurable 3D environments, and convenient APIs for external solvers and learning methods. 
By unifying ground and aerial operations, it facilitates cross-domain algorithm design, testing, and benchmarking. 
Experiments highlight \texttt{SkyRover}’s capacity for efficient pathfinding and high-fidelity simulations in UAV-AGV coordination.
% We believe the \texttt{SkyRover} fills a key gap in MAPF research. 
Project is available at \url{https://sites.google.com/view/mapf3d/home}.

\end{abstract}

\section{Introduction}\label{sec:intro}

The rapid growth of automation and artificial intelligence has significantly broadened unmanned systems’ application domains, especially in logistics and transportation. 
Companies like Amazon, JD, and Cainiao routinely deploy automated guided vehicles (AGVs) in large-scale warehouses\cite{qin2022jd,wurman2008coordinating,zhang2020learning}, while autonomous taxi services from Waymo and Baidu Apollo Go have begun trial operations globally\cite{sun2020scalability,wang2024recent}. 
Meanwhile, the low-altitude economy has gained momentum with drone-based package delivery, low-altitude tourism, and urban air mobility. 
Commercial drone delivery services by Amazon Prime Air and Meituan already enhance last-mile logistics\cite{dorling2016vehicle,engesser2023autonomous,sun2024uav}.

% Alongside these developments, collaborative UAV and AGV systems are attracting growing interest in diverse scenarios\cite{munasinghe2024comprehensive}, such as freight transportation\cite{gao2020commanding}, search and rescue\cite{zhang2024air}, precision agriculture\cite{tokekar2016sensor}, and infrastructure inspection\cite{wu2020cooperative}.
% In these settings, UAVs and AGVs operate in complementary domains: 
% AGVs are constrained to terrestrial routes and rely on road networks, while UAVs navigate in 3D or restricted airspaces.
% Their collaboration can improve operational efficiency and expand the range of tasks that each system can individually handle.
% For instance, UAVs may handle rapid transportation of small, lightweight cargo, and AGVs can handle heavier goods or perform guided operations at designated sites.
% Yet, effectively integrating two vehicle systems calls for carefully orchestrated scheduling and planning.

Alongside these developments, collaborative UAV–AGV systems are increasingly vital in freight transportation\cite{gao2020commanding}, search and rescue\cite{zhang2024air}, precision agriculture\cite{tokekar2016sensor}, and infrastructure inspection\cite{wu2020cooperative}, among other domains\cite{munasinghe2024comprehensive}. 
AGVs follow terrestrial routes, while UAVs operate in three-dimensional or restricted airspaces. 
Their synergy can boost operational capacity: UAVs excel in rapid transport of lightweight cargo, whereas AGVs handle heavier loads or site-specific tasks. 
However, integrating these systems demands careful scheduling and planning.

% Multi-Agent Path Finding\cite{stern2019multi} is a critical tool in coordinating large numbers of autonomous agents.
% It seeks collision-free and resource-efficient routes for all agents, ensuring minimal interference and high throughput.
% Substantial progress has been made in solving MAPF for purely guided-based or aerial vehicles, leveraging classical graph-based search, learning-based methods, or hybrid approaches\cite{salzman2020research,surynek2022problem,ma2022graph,alkazzi2024comprehensive}.
% However, significant challenges arise when UAVs and AGVs share the same operational space or when their flight plans and route schedules intersect.
% Heterogeneous motion characteristics, varying speed limits, distinct energy requirements, and environmental constraints further complicate the planning process.
% For example, UAV operations in outdoor may be sensitive to weather conditions, whereas AGVs in industrial or warehouse settings navigate dynamically changing floor layouts.

Multi-Agent Path Finding (MAPF)\cite{stern2019multi} is essential for collision-free, resource-efficient routing of large autonomous fleets. 
Although significant progress has been made for purely ground- or aerial-based MAPF\cite{alkazzi2024comprehensive,ma2022graph,salzman2020research,surynek2022problem}, new complexities arise when UAVs and AGVs share or intersect operational zones. 
Their heterogeneity (in motion patterns, energy consumption, and environmental constraints) further complicates joint planning; 
for instance, UAVs are more weather-sensitive, whereas AGVs often contend with dynamically changing indoor settings.

% The design, training, and testing of MAPF algorithms for UAV-AGV collaboration require robust simulation tools.
% Such tools must not only model realistic agent dynamics but also maintain computational efficiency to facilitate large-scale experiments.
% High-fidelity simulators are particularly valuable for learning-based MAPF algorithms, as they provide essential data for supervised or imitation learning and crucial feedback loops for reinforcement learning.
% Existing MAPF simulators offer solid support for single-domain movements\cite{nguyen2019generalized,okumura2021iterative,mavswarm2022,skrynnik2024pogema,WangICAPS24mapf3d}.
% Yet, to the best of our knowledge, few simulators natively support integrated UAV-AGV scenarios.
% A specialized simulator is needed to bridge this gap and enable systematic research and development of collaborative MAPF approaches.

Robust simulation tools are key to designing, training, and testing MAPF algorithms for UAV–AGV scenarios, especially for data-intensive learning-based approaches.
Existing simulators handle single-domain movements effectively\cite{mavswarm2022,nguyen2019generalized,okumura2021iterative,skrynnik2024pogema,WangICAPS24mapf3d}, but few offer native support for UAV–AGV collaboration.

% In this paper, we introduce \texttt{SkyRover}, a modular simulator designed for cross-domain pathfinding with UAV and AGV coordination.
% To our knowledge, it is the first environment to provide a unified toolkit for UAV-AGV MAPF research.
% Our simulator enables users to design complex scenarios, such as warehouse and park environments, with adjustable fidelity.
% It also incorporates high-fidelity physics models and user-friendly APIs to facilitate algorithmic testing and rapid prototyping.
% Through customizable and extensible interfaces, \texttt{SkyRover} aims to support a broad range of use-cases, from basic scheduling experiments to sophisticated learning-based methods.

To fill this gap, we introduce \texttt{SkyRover}, a modular simulator for cross-domain pathfinding with UAV and AGV coordination. 
To our knowledge, it is the first environment providing a unified toolkit for UAV–AGV MAPF research. 
\texttt{SkyRover} allows users to build complex scenarios (e.g., warehouses and park environments) with adjustable fidelity and integrates high-fidelity physics models alongside user-friendly APIs for algorithmic testing and rapid prototyping. 
Through customizable and extensible interfaces, \texttt{SkyRover} supports a wide spectrum of use cases—from basic scheduling experiments to sophisticated learning-based methods.

% \noindent\textbf{Paper Organization.}
% Section~\ref{sec:related} briefly reviews related work in MAPF and simulation tools. 
% Section~\ref{sec:simulator} describes the \texttt{SkyRover} architecture and major components. 
% Section~\ref{sec:exp} shows empirical results in warehouse and park worlds, demonstrating both classical search and learning-based MAPF. 
% Section~\ref{sec:conclusion} concludes with a discussion on limitations and future directions.


\section{Related Work}

Extensive progress has been made in solving MAPF for single-domain vehicles\cite{ma2022graph,salzman2020research,surynek2022problem}. 
Previous simulators such as \cite{mavswarm2022,nguyen2019generalized,okumura2021iterative,skrynnik2024pogema,WangICAPS24mapf3d} have tackled various forms of agent-based simulation, yet few focus on integrated UAV-AGV scenarios. 
Moreover, many existing platforms concentrate on either 2D grids or simplified 3D representations, limiting the study of aerial and ground interactions. 
By contrast, \texttt{SkyRover} explicitly targets these cross-domain concerns, offering realistic physics, 3D occupancy grids, and unified APIs. 
To our knowledge, it is the first environment to natively support collaborative UAV-AGV MAPF under a single, modular framework.


\section{\texttt{SkyRover} Simulator}\label{sec:simulator}

Following the motivations outlined in Section~\ref{sec:intro}, we present \texttt{SkyRover}, a modular simulator designed to address cross-domain pathfinding for UAV-AGV coordination. 
It aims to unify the modeling of ground and aerial vehicles in 3D grids while maintaining ease of use, modularity, and compatibility with third-party robotic frameworks. 
Figure~\ref{fig:skyrover} depicts its overall architecture, which comprises five main modules: 
1) the \textit{Sim World Zoo};
2) the \textit{3D Grid Generator};
3) the \textit{Unified Algorithm Wrapper};
4) the \textit{Plan Executor};
5) the \textit{System Interface}. 
This section details each module and explain how they collectively enable rapid experimentation and deployment of cross-domain MAPF solutions.

\begin{figure}[htb!]
    \centering
    \includegraphics[width=\linewidth]{skyrover.pdf}
    \caption{Main Architecture. \texttt{SkyRover} comprises multiple modules to support cross-domain MAPF.}
    \label{fig:skyrover}
\end{figure}

\subsection{\bf{Sim World Zoo}}

The \textit{Sim World Zoo} houses multiple Gazebo simulation worlds\cite{koenig2004design}, along with 3D models for UAVs and AGVs. 
Unlike simulators that rely solely on matrix-based grids, \texttt{SkyRover} offers more realistic environments by integrating detailed 3D worlds. 
Currently, \texttt{SkyRover} includes a warehouse and a park scenario, each featuring UAV and AGV models. 
These environments and virtual robots, sourced from \url{https://app.gazebosim.org/fuel/models}, can be further customized via the Gazebo UI. 
This design decision ensures that \texttt{SkyRover} users can scale from simple grid representations to complex settings that approximate real-world operational constraints.


\subsection{\bf{3D Grid Generator}}

Although \texttt{SkyRover} supports high-fidelity worlds, it also maintains a 3D grid representation for MAPF algorithms. 
The \textit{3D Grid Generator} automatically derives discrete map information from Gazebo environments. 
To achieve this, it employs a Gazebo plugin that creates a ROS2 service\cite{macenski2022robot} for capturing a 2D \texttt{.pgm} map and a 3D \texttt{.pcd} (point cloud) file. 
These files reflect the layout of objects and obstacles in the environment. 
Subsequently, the point cloud data is parsed to mark grid cells as free or occupied, generating a 3D occupancy grid suitable for both search- and learning-based algorithms.


\subsection{\bf{Unified Algorithm Wrapper}}

MAPF algorithms generally fall into either search-based or learning-based categories\cite{hart1968formal,sharon2015conflict,ma2021learning}. 
They also vary in their internal map structures, with some operating on matrices and others on more general graphs. 
To standardize these approaches, \texttt{SkyRover} provides a \textit{Unified Algorithm Wrapper} that abstracts the environment as a 3D grid with consistent interface calls, such as \textit{init}: initializes the environment, obstacle data, agent start states, and goal locations; \textit{step}: advances the simulation by one timestep, updating agent positions; and \textit{reset}: resets the simulation for new tasks or training episodes.
% \begin{itemize}
%     \item \textbf{init:} Initializes the environment, obstacle data, agent start states, and goal locations. 
%     \item \textbf{step:} Advances the simulation by one timestep, updating agent positions. 
%     \item \textbf{reset:} Resets the simulation for new tasks or training episodes. 
% \end{itemize}
We provide 3D versions of popular MAPF algorithms, including 3D A*\cite{hart1968formal}, 3D CBS\cite{sharon2015conflict}, and a 3D extension of DCC\cite{ma2021learning}, ensuring that researchers and practitioners can rapidly evaluate both classical search and modern learning paradigms in a unified simulator.


\subsection{\bf{Plan Executor}}

High-level path planners often produce routes in discrete grids or graphs, but real robots need continuous control inputs. 
The \textit{Plan Executor} bridges this gap by translating each agent’s planned trajectory into commands interpretable by low-level controllers. 
% Figure~\ref{fig:executor} illustrates this process. 
The executor tracks each agent’s path, communicates with external control frameworks (e.g., PX4\cite{meier2015px4} or Navigation2\cite{nav2docs}), and updates agent positions in the simulator. 
This arrangement allows \texttt{SkyRover} to support both abstract, high-level pathfinding and more realistic, hardware-oriented simulations.

% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\linewidth]{plan-executor.pdf}
%     \caption{The Plan Executor invokes algorithms through their wrappers, then sends the resulting waypoints or motions to low-level controllers (e.g., PX4, Navigation2).}
%     \label{fig:executor}
% \end{figure}


\subsection{\bf{System Interface}}

The \texttt{SkyRover} also offers multiple external interfaces to integrate with established robotics tools. 
Users can manipulate Gazebo models via Gazebo topics, visualize 3D occupancies with RViz\cite{kam2015rviz}, and command PX4-based drones through ROS2 topics and MicroXRCE\cite{microxrcedds}. 
This flexibility supports varied applications, ranging from hardware-in-the-loop testing to large-scale simulation. 
Ultimately, \texttt{SkyRover} allows researchers and practitioners to incorporate realistic dynamics, robust visualization, and real-time interactivity into customized UAV-AGV cooperative scenarios.

\section{Experiment}\label{sec:exp}

In this section, we demonstrate how \texttt{SkyRover} supports diverse experimental setups. 
We showcase the simulator using two distinct Gazebo worlds: a warehouse (Figure~\ref{fig:detail_warehouse}) and a park (Figure~\ref{fig:gazebo_building}). 
These worlds serve as representative testbeds, featuring varied layouts that allow us to highlight the simulator’s 3D mapping, pathfinding, and visualization capabilities. We define two typical AGV-UAV interaction tasks: 
\begin{itemize}
    \item \textbf{Inventory Scanning Task}: The AGV transports cargo to point A, where a UAV hovers above the AGV to scan and inventory the cargo. After the scanning process is completed, the AGV continues transporting the cargo to point B;
    \item \textbf{Aerial Cargo Transfer Task}: The AGV transports cargo to point A, where a UAV arrives and hovers above the AGV to pick up the cargo. The UAV then lifts the cargo and transports it to an elevated point B.
\end{itemize}

These tasks demonstrate the seamless coordination between AGVs and UAVs in different scenarios, showcasing the effectiveness of \texttt{SkyRover} in simulating complex robotic interactions.


\subsection{\bf{Environment Setup}}

We begin by loading the chosen Gazebo world and generating a 3D occupancy grid using the gazebo-map-creator plugin\cite{arshad2022}. 
This plugin extracts a point cloud of the environment, which is converted into a $0$--$1$ grid where each cell spans \(1\)\,meter. 
Cells containing point cloud particles are treated as obstacles and labeled ``1,'' while free cells remain ``0.'' 
The resulting 3D grid is published to RViz for real-time visualization (Figure~\ref{fig:rviz_warehouse}). 

% \begin{figure}[htb!]
% \centering
% \includegraphics[width=0.8\linewidth]{detail_warehouse.png}
% \caption{The warehouse Gazebo world, featuring multiple Holybro X500 drones and delivery AGVs.}
% \label{fig:detail_warehouse}
% \end{figure}

% \begin{figure}[htb!]
% \centering
% \includegraphics[width=0.8\linewidth]{gazebo_building.png}
% \caption{The park scenario, offering more open space for UAV operations.}
% \label{fig:gazebo_building}
% \end{figure}

% \begin{figure}[htb!]
% \centering
% \includegraphics[width=0.8\linewidth]{rviz_warehouse.png}
% \caption{The 3D occupancy grid in RViz. Each dark cell has point cloud data and is thus considered an obstacle.}
% \label{fig:rviz_warehouse}
% \end{figure}

% \begin{figure}[htb!]
% \centering
% \includegraphics[width=0.8\linewidth]{low-level.png}
% \caption{Example of integrating \texttt{SkyRover} with hardware-oriented controllers. Here, PX4 executes drone flight commands, while Navigation2 governs the TurtleBot.}
% \label{fig:low-level}
% \end{figure}

\begin{figure}[htb!]
\centering
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{detail_warehouse.png}
        \caption{}
        \label{fig:detail_warehouse}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{gazebo_building.png}
        \caption{}
        \label{fig:gazebo_building}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\linewidth}
        \centering  
        \includegraphics[width=\linewidth]{rviz_warehouse.png}
        \caption{}
        \label{fig:rviz_warehouse}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{low-level.png}
        \caption{}
        \label{fig:low-level}
    \end{subfigure}
    \caption{(a) The warehouse Gazebo world, featuring multiple Holybro X500 drones and delivery AGVs; (b) The park scenario, offering more open space for UAV operations; (c) The 3D occupancy grid in RViz. Each dark cell has point cloud data and is thus considered an obstacle; (d) Example of integrating \texttt{SkyRover} with hardware-oriented controllers. PX4 executes drone flight commands and Navigation2 governs the TurtleBot.}
    \label{fig:scenarios}
\end{figure}


% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\linewidth]{detail_warehouse.png}
%     \caption{The warehouse Gazebo world, featuring multiple Holybro X500 drones and delivery AGVs.}
%     \label{fig:detail_warehouse}
% \end{figure}

% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\linewidth]{gazebo_building.png}
%     \caption{The park scenario, offering more open space for UAV operations.}
%     \label{fig:gazebo_building}
% \end{figure}

% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\linewidth]{rviz_warehouse.png}
%     \caption{The 3D occupancy grid in RViz. Each dark cell has point cloud data and is thus considered an obstacle.}
%     \label{fig:rviz_warehouse}
% \end{figure}


\subsection{\bf{3D MAPF Examples}}

After generating the occupancy grid, we deploy $6$ Holybro X500 drones and $16$ AGVs. 
We assign each agent a unique start and goal location in the warehouse world. 
Via the \textit{init} interface of algorithm wrapper, we load the 3D-A* and 3D-CBS solvers. 
During initialization, these solvers compute complete, conflict-free paths for all agents. 
At each timestep, the \textit{step} function moves every agent to its next waypoint, ensuring collision-free navigation. 

We also implement a 3D version of the learning-based method, DCC\cite{ma2021learning}. 
Here, we adapt the original 2D convolution layers to 3D, and employ curriculum learning to train for \(70{,}000\) episodes in a random \(40\times40\times40\) grid. 
This trained model reaches $100\%$ success under test conditions with sixteen agents. 
Unlike search-based algorithms, which plan entire routes beforehand, the learning-based approach invokes the \textit{step} function to infer actions online after loading the model file. 
This approach suits dynamic environments where complete pre-planning is less feasible.


\subsection{\bf{Motion Control Integration}}

For many studies, abstract position updates are sufficient for benchmarking algorithmic performance. 
In these cases, we simply invoke Gazebo’s model-position service to teleport each agent, bypassing detailed dynamics. 
However, \texttt{SkyRover} also supports low-level motion control through PX4\cite{meier2015px4} and Navigation2\cite{nav2docs}. 
Figure~\ref{fig:low-level} shows an example involving a drone controlled by PX4 and a TurtleBot commanded by Navigation2. 
% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\linewidth]{low-level.png}
%     \caption{Example of integrating \texttt{SkyRover} with hardware-oriented controllers. Here, PX4 executes drone flight commands, while Navigation2 governs the TurtleBot.}
%     \label{fig:low-level}
% \end{figure}
These finer-grained simulations accurately capture kinematic and dynamic constraints, which are essential for hardware-in-the-loop testing. 
Although more computationally intensive, these setups are valuable for research on real-time control, multi-robot coordination, and safety validation. 
Users can choose the approach—abstract or low-level—based on the complexity of their experiments and available computing resources.


\subsection{\bf{Preliminary Results and Comparison}}

We conduct all experiments on Ubuntu 24.04 with ROS 2 Jazzy, Gazebo Harmonic, and the main branch of PX4, using a PC with an Intel i7 CPU and 32\,GB RAM. 
Table~\ref{tab:sim_results} presents preliminary performance metrics comparing 3D variants of A*, CBS and DCC on the warehouse world when $22$ total agents ($6$ drones, $16$ AGVs) must reach randomly assigned goals. 
\textbf{Computation time} measures the total time to compute or infer a path before the first move, while \textbf{Success rate} indicates the percentage of agents reaching their target without collision in a single run. 
% While 3D-A* is generally faster to converge for small problem sizes, 3D-DCC shows promise for larger or dynamic scenarios, aligning with previous results in 2D MAPF\cite{ma2021learning}.

\begin{table}[ht]
\centering
\caption{Preliminary Results in the Warehouse (22 Agents).}
\label{tab:sim_results}
\resizebox{.7\linewidth}{!}{%
\begin{tabular}{lcc}
\hline
\textbf{Algorithm} & \textbf{Comp. Time (s)} & \textbf{Success Rate ($\%$)}\\
\hline
3D-A*   & 54.7 & 100 \\
3D-CBS & 92.4 & 100 \\
3D-DCC (Well-trained) & 0.6 & 100 \\
\hline
\end{tabular}%
}
\end{table}

These initial comparisons highlight \texttt{SkyRover}’s ability to benchmark MAPF algorithms in a unified and consistent framework. 
Future work could involve more in-depth evaluations, including scaling to larger agent teams and investigating runtime on different hardware setups.

\section{Conclusion and Future Directions}\label{sec:conclusion}

In this paper, we introduce \texttt{SkyRover}, a modular simulator paving the way for integrated UAV-AGV MAPF in 3D environments. 
It combines realistic Gazebo worlds, a robust 3D grid generator, unified wrappers for classical and learning-based algorithms, and seamless integration with external robotics software. 
Experiments in the warehouse and park worlds confirmed its flexibility for discrete pathfinding and low-level control simulations.

\paragraph{Limitations}
Current limitations include partial modeling of real-world effects (e.g., weather, sensor noise) and the computational load of large-scale simulations. 
Learning-based methods also require extensive training data, and the hyperparameter optimization might be time-intensive.

\paragraph{Future Directions}
Going forward, we plan to integrate more realistic physics (wind perturbations, complex friction models), advanced sensor types (LiDAR, radar), and dynamic obstacle handling. 
Collaborations with urban air traffic simulators would further expand scenario possibilities, such as multi-lane sky corridors for UAV delivery. 
Additionally, a systematic approach to large-scale distributed training could support RL methods that tackle hundreds of agents in real time.


\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{Wur08}
    \bibitem[Wur{\etalchar{+}}08]{wurman2008coordinating}
    Peter R. Wurman, Raffaello D'Andrea, and Mick Mountz.
    \newblock Coordinating hundreds of cooperative, autonomous vehicles in warehouses.
    \newblock {\em AI Magazine}, 29(1):9, 2008.

    \bibitem[Qin{\etalchar{+}}22]{qin2022jd}
    Hengle Qin, Jun Xiao, Dongdong Ge, Linwei Xin, Jianjun Gao, Simai He, Haodong Hu, and John Gunnar Carlsson.
    \newblock JD.com: Operations research algorithms drive intelligent warehouse robots to work.
    \newblock {\em INFORMS Journal on Applied Analytics}, 52(1):42--55, 2022.

    \bibitem[Zha{\etalchar{+}}20]{zhang2020learning}
    Yi Zhang, Yu Qian, Yichen Yao, Haoyuan Hu, and Yinghui Xu.
    \newblock Learning to cooperate: Application of deep reinforcement learning for online AGV path finding.
    \newblock In {\em AAMAS}, 2020.

    \bibitem[Sun{\etalchar{+}}20]{sun2020scalability}
    Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, and others.
    \newblock Scalability in perception for autonomous driving: Waymo open dataset.
    \newblock In {\em CVPR}, 2020.

    \bibitem[Wan{\etalchar{+}}24]{wang2024recent}
    Shiqi Wang, Zhouye Zhao, Yuhang Xie, Mingchuan Ma, Zirui Chen, Zeyu Wang, Bohao Su, Wenrui Xu, and Tianyi Li.
    \newblock Recent surge in public interest in transportation: Sentiment analysis of Baidu Apollo Go using Weibo data.
    \newblock {\em arXiv:2408.10088}, 2024.

    \bibitem[Dor{\etalchar{+}}16]{dorling2016vehicle}
    Kevin Dorling, Jordan Heinrichs, Geoffrey G. Messier, and Sebastian Magierowski.
    \newblock Vehicle routing problems for drone delivery.
    \newblock {\em IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 47(1):70--85, 2016.

    \bibitem[Eng{\etalchar{+}}23]{engesser2023autonomous}
    Valeska Engesser, Evy Rombaut, Lieselot Vanhaverbeke, and Philippe Lebeau.
    \newblock Autonomous delivery solutions for last-mile logistics operations: A literature review and research agenda.
    \newblock {\em Sustainability}, 15(3):2774, 2023.

    \bibitem[Sun{\etalchar{+}}24]{sun2024uav}
    Xuting Sun, Minghao Fang, Shu Guo, and Yue Hu.
    \newblock UAV-rider coordinated dispatching for the on-demand delivery service provider.
    \newblock {\em Transportation Research Part E: Logistics and Transportation Review}, 186:103571, 2024.

    \bibitem[Mun{\etalchar{+}}24]{munasinghe2024comprehensive}
    Isuru Munasinghe, Asanka Perera, and Ravinesh C. Deo.
    \newblock A comprehensive review of UAV-UGV collaboration: Advancements and challenges.
    \newblock {\em Journal of Sensor and Actuator Networks}, 13(6):81, 2024.

    \bibitem[Wu{\etalchar{+}}20]{wu2020cooperative}
    Yu Wu, Shaobo Wu, and Xinting Hu.
    \newblock Cooperative path planning of UAVs \& UGVs for a persistent surveillance task in urban environments.
    \newblock {\em IEEE Internet of Things Journal}, 8(6):4906--4919, 2020.

    \bibitem[Gao{\etalchar{+}}20]{gao2020commanding}
    Wei Gao, Junren Luo, Wanpeng Zhang, Weilin Yuan, and Zhiyong Liao.
    \newblock Commanding cooperative UGV-UAV with nested vehicle routing for emergency resource delivery.
    \newblock {\em IEEE Access}, 8:215691--215704, 2020.

    \bibitem[Zha{\etalchar{+}}24]{zhang2024air}
    Ying Zhang, Haibao Yan, Danni Zhu, Jiankun Wang, Cui-Hua Zhang, Weili Ding, Xi Luo, Changchun Hua, and Max Q-H Meng.
    \newblock Air-Ground Collaborative Robots for Fire and Rescue Missions: Towards Mapping and Navigation Perspective.
    \newblock {\em arXiv:2412.20699}, 2024.

    \bibitem[Tok{\etalchar{+}}16]{tokekar2016sensor}
    Pratap Tokekar, Joshua Vander Hook, David Mulla, and Volkan Isler.
    \newblock Sensor planning for a symbiotic UAV and UGV system for precision agriculture.
    \newblock {\em IEEE Transactions on Robotics}, 32(6):1498--1511, 2016.

    \bibitem[Ste{\etalchar{+}}19]{stern2019multi}
    Roni Stern, Nathan Sturtevant, Ariel Felner, Sven Koenig, Hang Ma, Thayne Walker, Jiaoyang Li, Dor Atzmon, Liron Cohen, TK Kumar, and others.
    \newblock Multi-agent pathfinding: Definitions, variants, and benchmarks.
    \newblock In {\em SoCS}, 2019.

    \bibitem[Sur22]{surynek2022problem}
    Pavel Surynek.
    \newblock Problem Compilation for Multi-Agent Path Finding: a Survey.
    \newblock In {\em IJCAI}, 2022.

    \bibitem[Sal{\etalchar{+}}20]{salzman2020research}
    Oren Salzman and Roni Stern.
    \newblock Research challenges and opportunities in multi-agent path finding and multi-agent pickup and delivery problems.
    \newblock In {\em AAMAS}, 2020.

    \bibitem[Ma22]{ma2022graph}
    Hang Ma.
    \newblock Graph-based multi-robot path finding and planning.
    \newblock {\em Current Robotics Reports}, 3(3):77--84, 2022.

    \bibitem[Alk{\etalchar{+}}24]{alkazzi2024comprehensive}
    Jean-Marc Alkazzi and Keisuke Okumura.
    \newblock A Comprehensive Review on Leveraging Machine Learning for Multi-Agent Path Finding.
    \newblock {\em IEEE Access}, 12:57390--57409, 2024.

    \bibitem[Oku{\etalchar{+}}21]{okumura2021iterative}
    Keisuke Okumura, Yasumasa Tamura, and Xavier D{\'e}fago.
    \newblock Iterative refinement for real-time multi-robot path planning.
    \newblock In {\em IROS}, 2021.

    \bibitem[Ng{\etalchar{+}}19]{nguyen2019generalized}
    Van Nguyen, Philipp Obermeier, Tran Son, Torsten Schaub, and William Yeoh.
    \newblock Generalized target assignment and path finding using answer set programming.
    \newblock In {\em SoCS}, 2019.

    \bibitem[Skry{\etalchar{+}}24]{skrynnik2024pogema}
    Alexey Skrynnik, Anton Andreychuk, Anatolii Borzilov, Alexander Chernyavskiy, Konstantin Yakovlev, and Aleksandr Panov.
    \newblock POGEMA: A benchmark platform for cooperative multi-agent navigation.
    \newblock {\em arXiv:2407.14931}, 2024.

    \bibitem[Wan{\etalchar{+}}24]{WangICAPS24mapf3d}
    Qian Wang, Rishi Veerapaneni, Yu Wu, Jiaoyang Li, and Maxim Likhachev.
    \newblock MAPF in 3D Warehouses: Dataset and Analysis.
    \newblock In {\em ICAPS}, 2024.

    \bibitem[Mal22]{mavswarm2022}
    Malintha Fernando.
    \newblock Mavswarm: A Lightweight Multi-Aerial Vehicle Simulator.
    \newblock {\em GitHub}, 2022.
    \newblock \url{https://github.com/malintha/multi_uav_simulator}.

    \bibitem[Ars22]{arshad2022}
    Arshad Mehmood.
    \newblock R{OS}2 {G}azebo World 2D/3D Map Generator.
    \newblock {\em GitHub}, 2022.
    \newblock \url{https://github.com/arshadlab/gazebo_map_creator}.

    \bibitem[Nav25]{nav2docs}
    Navigation2 Contributors.
    \newblock Navigation2 Documentation.
    \newblock {\em GitHub}, 2025.
    \newblock \url{https://github.com/ros-navigation/docs.nav2.org}.
    \newblock \url{https://docs.nav2.org}.

    \bibitem[Pro24]{microxrcedds}
    eProsima.
    \newblock e{P}rosima {M}icro {XRCE}-{DDS}: A {DDS}-{XRCE} Protocol Implementation for Resource Constrained Environments.
    \newblock {\em GitHub repository}, 2024.
    \newblock \url{https://github.com/eProsima/Micro-XRCE-DDS}, version 3.0.0.

    \bibitem[Har68]{hart1968formal}
    Peter E. Hart, Nils J. Nilsson, and Bertram Raphael.
    \newblock A formal basis for the heuristic determination of minimum cost paths.
    \newblock {\em IEEE Transactions on Systems Science and Cybernetics}, 4(2):100--107, 1968.

    \bibitem[Sha{\etalchar{+}}15]{sharon2015conflict}
    Guni Sharon, Roni Stern, Ariel Felner, Nathan R. Sturtevant.
    \newblock Conflict-based search for optimal multi-agent pathfinding.
    \newblock {\em Artificial Intelligence}, 219:40--66, 2015.

    \bibitem[Ma21]{ma2021learning}
    Ziyuan Ma, Yudong Luo, and Jia Pan.
    \newblock Learning selective communication for multi-agent path finding.
    \newblock {\em IEEE Robotics and Automation Letters}, 7(2):1455--1462, 2021.

    \bibitem[Koe04]{koenig2004design}
    Nathan Koenig and Andrew Howard.
    \newblock Design and use paradigms for gazebo, an open-source multi-robot simulator.
    \newblock In {\em IROS}, 2004.

    \bibitem[Kam15]{kam2015rviz}
    Hyeong Ryeol Kam, Sung-Ho Lee, Taejung Park, and Chang-Hun Kim.
    \newblock Rviz: a toolkit for real domain data visualization.
    \newblock {\em Telecommunication Systems}, 60:337--345, 2015.

    \bibitem[Mei15]{meier2015px4}
    Lorenz Meier, Dominik Honegger, and Marc Pollefeys.
    \newblock PX4: A node-based multithreaded open source robotics framework for deeply embedded platforms.
    \newblock In {\em ICRA}, 2015.

    \bibitem[Mac22]{macenski2022robot}
    Steven Macenski, Tully Foote, Brian Gerkey, Chris Lalancette, and William Woodall.
    \newblock Robot operating system 2: Design, architecture, and uses in the wild.
    \newblock {\em Science robotics}, 7(66):eabm6074, 2022.
\end{thebibliography}


\end{document}


