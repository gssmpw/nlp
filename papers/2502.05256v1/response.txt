\section{Related work}
Query optimization is a long-standing problem in the databases community. System R: A Relational-Only Full-Text Search Engine, proposed the heuristic query optimization scheme now used in most production databases; Dynamic Sample Selection for Fast Data Mining Queries, consisting of a cost model, cardinality estimates, and a dynamic programming search.
Conventional query optimizers are designed according to the ``query optimization contract''; Query Optimization as Regularized Learning, which expects query optimizers to produce plans quickly (within hundreds of milliseconds, as the actual execution of the plan might be very quick); this work proposed that in order to improve query optimizers, we should consider ``breaking'' this contract in a number of ways, such as allowing the optimizer to intrusively examine the base data (as opposed to keeping cheap histograms), spend a long time on optimization, or even adaptively change the query plan during execution. We believe our work falls into this ``breaking the contract'' category. Older work: Amortizing Query Optimization Overhead, considered amortizing the cost of searching parts of the plan space across multiple executions, but did not consider offline execution. Query reoptimization, perhaps the first ``contract breaker,'' is the task of proactively modifying or recreating a query plan during execution, based on information found during execution, with the overall goal of minimizing total latency.

A related concept from the compilers literature is ``superoptimization''; Superword-Level Parallelism after Free-Area Collection, in which a program compiler, which traditionally follows a similar ``contract'' as a query optimizer (i.e., fast compilation times), instead uses a large time budget to produce the best possible sequence of assembly instructions for a given program. Our work can be considered a sort of ``superoptimization for query plans''. GenesisDB: A System for Efficiently and Scalably Processing Relational Operators, represents a similar effort, focusing on developing fast implementations over relational operators, instead of entire query plans (thus GenesisDB is mostly orthogonal to the work presented here). Kepler: Dynamic Sampling for Fast Data Mining Queries, uses a genetic algorithm and exhaustive execution to map the plan space for parameterized queries, which can be viewed as a type of superoptimization. SlabCity: A Framework for Efficiently Evaluating SQL Queries, takes an approach similar to traditional superoptimization, by considering SQL-level semantic rewrites of queries to improve performance (e.g., query simplification). Finally, DataFarm: Accelerating DBMS Development with Deep Reinforcement Learning, and HitTheGym: Towards Efficient Database Tuning using Transfer Learning, investigated how to best produce datasets for machine learning powered database components, including query optimizers.

In recent years, the databases community has been increasingly engaged in applying machine learning techniques to query optimization, including latency prediction; Cardinality Estimation with Deep Neural Networks, cardinality estimation; and cost models; Predictive Cost Modeling using Deep Learning. Other works have attempted to either augment existing optimizers with learned components (e.g., Learned Query Optimization for Big Data Analytics); or entirely replace query optimizers with reinforcement learning (e.g., RL-DB: A Framework for Reinforcement Learning-based Database Systems). Most of these works are focused on the online optimization setting: they must complete quickly while avoiding performance regressions relative to traditional heuristic-based optimizers. Most of these works also employ reinforcement learning, seeking to manage regret from exploring alternatives instead of exploiting the current known-best plan. In comparison, we apply Bayesian optimization to the superoptimization problem because we are principally concerned with finding the query plan with the best possible latency, and ignore suboptimal plans. In the superoptimization setting, bad plans are only bad insofar as executing them until the timeout consumes part of the optimization time budget.

Bayesian optimization is not the only sample-efficient learning technique. For example, NeuroCARD: Efficient Learning of Join Distributions for Big Data Analytics, learns join distributions efficiently by uniformly sampling tuples from the full outer join of all tables in a schema. Reiner et al.: Geometric Deep Learning for Domain Knowledge Incorporation into Learned Models, show how domain knowledge can be incorporated into learned models to improve sample efficiency via geometric deep learning. LlamaTune: Accelerating DBMS Development with Deep Reinforcement Learning, uses database documentation to accelerate DBMS knob-tuning.

While our plan encoding was inspired by work in molecular dynamics (i.e, SELFIES: A Sequence-First Language for Molecular Dynamics); strings as used by Maus et al.: Neural-Symbolic Interaction Learning, a representation with similar goals for query plans was presented by Reiner et al.: Geometric Deep Learning for Domain Knowledge Incorporation into Learned Models. Our approaches mainly differ in what we are trying to represent: as our format only seeks to encode join orderings, it does not encode predicates. Furthermore, while Reiner et al. use invariances to give joins with the same cardinality the same representation, our encoding format may have multiple representations for the same join ordering. Further motivation for this design choice is given in ~\Cref{sec:string-format}. Other works have also looked at non-string representations of queries based on graphs; Deep Learning for Graph-Based Query Optimization; trees; Tree-based Query Optimization for Big Data Analytics, and recurrences; Predictive Cost Modeling using Deep Learning.

The random search heuristic we presented in ~\Cref{sec:eval} can be considered a modified version of QuickPick: An Efficient Method for Optimal Query Selection. Instead of sampling random query plans and then using a cost model to evaluate their quality, we simply evaluate the quality of the random plans by actually executing them. Such a suggestion would seem ludicrous in the original context of Dynamic Sampling for Fast Data Mining Queries; but for offline optimization, executing terrible query plans is \emph{not} off the table, if it eventually leads to a better plan! 

Since Bayesian optimization is a relatively old technique, it may be reasonable to ask ``why now?'' Recent innovations in the machine learning community have made it practical to apply Bayesian optimization to \emph{structured} (i.e. non-continuous) inputs with high dimensionality; A Framework for Efficiently Evaluating Structured Inputs using Deep Learning, which was previously impossible. The key innovation that enabled this advancement was attention transformer models; Attention-Based Deep Neural Networks for Big Data Analytics, which allowed sequences to be efficiently and accurately mapped into vector spaces. In the databases literature, Bayesian optimization has been most frequently applied to tuning configuration knobs; Optimizing Database Configuration using Bayesian Optimization. To our knowledge, this is the first work to apply BO directly to the optimization of individual queries.

LimeQO: A System for Efficiently Finding Optimal Query Hints, a system that uses offline query execution to find the best query hint for each query in a workload. LimeQO can be viewed as a practical way of finding an optimal Bao: Bayesian Optimization for Query Optimization model for a given workload. LimeQO is arguably much simpler than the present work, requiring only linear methods (e.g., no VAE or Bayesian optimization). However, LimeQO only considers a finite set of query hints to apply to each query in a workload, whereas we fully construct query plans. As a result, the present work can potentially find better plans. Additionally, LimeQO focuses on optimizing an entire workload of queries at once (i.e., considering which queries are best to explore next), whereas we focus on optimizing only a single user-specified queries.