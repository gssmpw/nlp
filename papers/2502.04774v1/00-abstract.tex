\begin{abstract}
The rapid evolution of Large Language Models (LLMs) has enabled the industry to develop various AI-based services. 
Instruction tuning is considered essential in adapting foundation models for target domains to provide high-quality services to customers.
A key challenge in instruction tuning is obtaining high-quality
instruction data. Self-Instruct, which automatically 
generates instruction data using ChatGPT APIs, 
alleviates the data scarcity problem. To improve the
quality of instruction data, Self-Instruct discards 
many of the instructions generated from ChatGPT, 
even though it is inefficient in terms of cost owing 
to many useless API calls.
To generate high-quality instruction data at a low cost,
we propose a novel data generation framework, \textbf{Se}lf-\textbf{Di}rect
\textbf{Instruct}ion generation (\ours{}), which employs diversity-based filtering and iterative feedback task generation.
Diversity-based filtering maintains model accuracy 
without excessively discarding low-quality generated instructions 
by enhancing the diversity of instructions in a batch. 
This reduces the cost of synthesizing instruction data.
The iterative feedback task generation integrates
instruction generation and training tasks and utilizes information
obtained during the training to create high-quality instruction
sets.
%, which does not require human verification anymore.
Our results show that \ours{} enhances the accuracy 
of AI models by 5.2\%, compared with traditional methods, 
while reducing data generation costs by 36\%.    
\end{abstract}

