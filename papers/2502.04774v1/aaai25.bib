@inproceedings{InstructGPT,
    title = {Training language models to follow instructions with human feedback},
    author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
    booktitle = {Advances in Neural Information Processing Systems},
    pages = {27730--27744},
    year = {2022}
}


@inproceedings{alpagasus,
    title={AlpaGasus: Training a Better Alpaca with Fewer Data},
    author={Lichang Chen and Shiyang Li and Jun Yan and Hai Wang and Kalpa Gunaratna and Vikas Yadav and Zheng Tang and Vijay Srinivasan and Tianyi Zhou and Heng Huang and Hongxia Jin},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
}

@inproceedings{8215530,
  author={Yin, Changchang and Qian, Buyue and Cao, Shilei and Li, Xiaoyu and Wei, Jishang and Zheng, Qinghua and Davidson, Ian},
  booktitle={2017 IEEE International Conference on Data Mining}, 
  title={Deep Similarity-Based Batch Mode Active Learning with Exploration-Exploitation}, 
  year={2017},
  pages={575-584},
}

@inproceedings{
    alpacafarm,
    title={AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback},
    author={Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori Hashimoto},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023}
}

@misc {chatgpt,
    author = {OpenAI},
    title = {ChatGPT},
    howpublished = {\url{https://chatgpt.com/}},
    year = {{2023}}
}

@misc{chatgptuser,
    author = {AIPRM},
    title = {100+ ChatGPT Statistics 2024},
    howpublished = {\url{https://www.aiprm.com/chatgpt-statistics/}},
    year = {2024},
}

@misc{datasetprice,
    author = {Milica Panić},
    title = {How to Define the Right Price for a Language Dataset},
    howpublished = {\url{https://www.taus.net/resources/blog/how-to-define-the-right-price-for-a-language-dataset}},
    year = {2021},
}

@inproceedings{eda,
    title = {{EDA}: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks},
    author = {Wei, Jason  and Zou, Kai},
    booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
    year = {2019},
}

@inproceedings{backtranslation,
    title = {Data augmentation using back-translation for context-aware neural machine translation},
    author = {Sugiyama, Amane and Yoshinaga, Naoki},
    booktitle = {Proceedings of the Fourth Workshop on Discourse in Machine Translation},
    year = {2019},
    pages = {35--44},
}

@inproceedings{data-efficient,
  title={Deepspeed data efficiency: Improving deep learning model quality and training efficiency via efficient data sampling and routing},
  author={Li, Conglong and Yao, Zhewei and Wu, Xiaoxia and Zhang, Minjia and Holmes, Connor and Li, Cheng and He, Yuxiong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={18490--18498},
  year={2024}
}

@incollection{torrey2010transfer,
    title={Transfer Learning},
    author={Lisa Torrey and Jude Shavlik},
    booktitle={Handbook of research on machine learning applications and trends: algorithms, methods, and techniques},
    pages={242--264},
    year={2010},
  publisher={IGI global}
}

@inproceedings{self-instruct,
    title = {Self-Instruct: Aligning Language Models with Self-Generated Instructions},
    author = {Wang, Yizhong  and
      Kordi, Yeganeh  and
      Mishra, Swaroop  and
      Liu, Alisa  and
      Smith, Noah A.  and
      Khashabi, Daniel  and
      Hajishirzi, Hannaneh},
    booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics},
    year = {2023},
    pages = {13484--13508},
}

@inproceedings{batchdiversity2,
    title = {Diversity-Aware Batch Active Learning for Dependency Parsing},
    author = {Shi, Tianze  and Benton, Adrian  and Malioutov, Igor  and {\.I}rsoy, Ozan},

    booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    year = {2021},
    publisher = {Association for Computational Linguistics},
    pages = {2616--2626},
}

@article{batchdiversity3,
      title={Batch Active Learning Using Determinantal Point Processes}, 
      author={Erdem Bıyık and Kenneth Wang and Nima Anari and Dorsa Sadigh},
      year={2019},
      eprint={1906.07975},
      journal={arXiv preprint arXiv:1906.07975},
}


@article{scalingllm,
  author  = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  title   = {Scaling Instruction-Finetuned Language Models},
  journal = {Journal of Machine Learning Research},
  year    = {2024},
  volume  = {25},
  number  = {70},
  pages   = {1--53},
}

@inproceedings{promptsafety,
  title={On prompt-driven safeguarding for large language models},
  author={Zheng, Chujie and Yin, Fan and Zhou, Hao and Meng, Fandong and Zhou, Jie and Chang, Kai-Wei and Huang, Minlie and Peng, Nanyun},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{gpt3,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      booktitle={Advances in neural information processing systems},
      volume={33},
      pages={1877--1901},
      year={2020}
}

@article{palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{sitgpt4,
    author = {Baolin Peng and Chunyuan Li and Pengcheng He and Michel Galley and Jianfeng Gao},
    title = {Instruction tuning with gpt-4},
    journal={arXiv preprint arXiv:2304.03277},
    year = {2023}
}

@article{llama3,
  title={The Llama 3 Herd of Models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  year={2024},
  journal={arXiv preprint arXiv:2407.21783}
}

@article{FLAM,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{gemmait,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  year={2024},
  journal={arXiv preprint arXiv:2403.08295}
}

@article{alpaca,
  title={Alpaca: A strong, replicable instruction-following model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
  volume={3},
  number={6},
  pages={7},
  year={2023}
}

@article{alpacaeval,
      title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators}, 
      author={Yann Dubois and Balázs Galambosi and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      journal={https://arxiv.org/abs/2404.04475}, 
}

@inproceedings{
MMLU,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=d7KBjmI3GmQ}
}

@inproceedings{hellaswag,
  title={HellaSwag: Can a Machine Really Finish Your Sentence?},
  author={Rowan Zellers and Ari Holtzman and Yonatan Bisk and Ali Farhadi and Yejin Choi},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:159041722}
}

@article{DROP,
  title={Think you have solved question answering? try arc, the ai2 reasoning challenge},
  author={Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal={arXiv preprint arXiv:1803.05457},
  year={2018}
}


@misc{vicuna1,
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    howpublished = {\url{https://lmsys.org/blog/2023-03-30-vicuna/}},
    year = {{2023}}
}

@inproceedings{
vicuna2,
 author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {46595--46623},
 title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
 volume = {36},
 year = {2023}
}

@article{helpful,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      journal={https://arxiv.org/abs/2204.05862}, 
}

@misc{koala,
  author = {Xinyang Geng and Arnav Gudibande and Hao Liu and Eric Wallace and Pieter Abbeel and Sergey Levine and Dawn Song},
  title = {Koala: A Dialogue Model for Academic Research},
  howpublished = {\url{https://bair.berkeley.edu/blog/2023/04/03/koala/}},
  year = {{2023}},
}

@inproceedings{
oasst,
title = {OpenAssistant Conversations Democratizing Large Language Model Alignment},
author={Andreas K{\"o}pf and Yannic Kilcher and Dimitri von R{\"u}tte and Sotiris Anagnostidis and Zhi Rui Tam and Keith Stevens and Abdullah Barhoum and Duc Minh Nguyen and Oliver Stanley and Rich{\'a}rd Nagyfi and Shahul ES and Sameer Suri and David Alexandrovich Glushkov and Arnav Varma Dantuluri and Andrew Maguire and Christoph Schuhmann and Huu Nguyen and Alexander Julian Mattick},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
}

@misc {gpt3.5-api,
    author = {OpenAI},
    title = {gpt-3-5-turbo},
    howpublished = {\url{https://platform.openai.com/docs/models/gpt-3-5-turbo}},
    year = {{2023}}
}

@article{
    modelcollapse1,
    title={Beyond Model Collapse: Scaling Up with Synthesized Data Requires Reinforcement}, 
    author={Yunzhen Feng and Elvis Dohmatob and Pu Yang and Francois Charton and Julia Kempe},
    year={2024},
    journal={https://arxiv.org/abs/2406.07515}
}

@article{modelcollapse2,
  title={The curse of recursion: Training on generated data makes models forget},
  author={Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
  year={2023},
  journal={arXiv preprint arXiv:2305.17493},
}

@article{modelcollapse3,
      title={Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data}, 
      author={Matthias Gerstgrasser and Rylan Schaeffer and Apratim Dey and Rafael Rafailov and Henry Sleight and John Hughes and Tomasz Korbak and Rajashree Agrawal and Dhruv Pai and Andrey Gromov and Daniel A. Roberts and Diyi Yang and David L. Donoho and Sanmi Koyejo},
      year={2024},
      journal={arXiv preprint arXiv:2404.01413},
}

@article{rlhf,
      title={A Survey of Reinforcement Learning from Human Feedback}, 
      author={Timo Kaufmann and Paul Weng and Viktor Bengs and Eyke Hüllermeier},
      year={2024},
      journal={arXiv preprint arXiv:2312.14925},
}

@inproceedings{
    sft1,
    title={Finetuned Language Models are Zero-Shot Learners},
    author={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=gEZrGCozdqR}
}

@inproceedings{
    sft2,
    title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
    author={Victor Sanh and Albert Webson and Colin Raffel and Stephen Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Teven Le Scao and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M Rush},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=9Vrb9D0WI4}
}

@inproceedings{sft3,
    title = {Super-{N}atural{I}nstructions: Generalization via Declarative Instructions on 1600+ {NLP} Tasks},
    author = {Wang, Yizhong  and Mishra, Swaroop  and Alipoormolabashi, Pegah  and Kordi, Yeganeh  and Mirzaei, Amirreza  and Naik, Atharva  and Ashok, Arjun  and Dhanasekaran, Arut Selvan  and Arunkumar, Anjana  and Stap, David  and Pathak, Eshaan  and Karamanolakis, Giannis  and Lai, Haizhi  and Purohit, Ishan  and Mondal, Ishani  and Anderson, Jacob  and Kuznia, Kirby  and Doshi, Krima  and Pal, Kuntal Kumar  and Patel, Maitreya  and Moradshahi, Mehrad  and Parmar, Mihir  and Purohit, Mirali  and Varshney, Neeraj  and Kaza, Phani Rohitha  and Verma, Pulkit  and Puri, Ravsehaj Singh  and Karia, Rushang  and Doshi, Savan  and Sampat, Shailaja Keyur  and Mishra, Siddhartha  and Reddy A, Sujan  and Patro, Sumanta  and Dixit, Tanay  and Shen, Xudong},
    booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
    year = {2022},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/2022.emnlp-main.340},
    pages = {5085--5109},
}

@article{llama2prompt,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      journal={arXiv preprint arXiv:2307.09288},
}

@article{instruction-tuning,
  title={Instruction Tuning for Large Language Models: A Survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  year={2023},
  journal={arXiv preprint arXiv:2308.10792},
}
