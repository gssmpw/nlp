Based on the findings in Section~\ref{sec:scenario}, we propose a novel taxonomy of VFL algorithms across four dimensions: keys, features, communication, and trustworthiness, as illustrated in Figure~\ref{fig:app-guide}. Table~\ref{tab:vfl_algorithms} further summarizes existing algorithms according to this taxonomy. The following section provides a detailed explanation of the taxonomy and an overview of the existing algorithms.


\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{fig/application-guide.pdf}
    \caption{Taxonomy of VFL algorithms based on feature balance, key alignment, communication, and trustworthy.}
    \label{fig:app-guide}
\end{figure*}

        

    
    
    


\begin{table*}[ht]
    \centering
    \caption{Representative VFL algorithms are categorized by feature balance, key alignment, communication, and trustworthiness. \cmark\;and \xmark\; indicate whether the algorithms include techniques supporting the corresponding VFL category or evaluate it in their experiments. "Contr." denotes contribution fairness. The prevalance of some VFL categories and the ratio of supported algorithms are also presented.}
    \renewcommand{\arraystretch}{1.4}
    \setlength{\tabcolsep}{4pt}
    \resizebox{\textwidth}{!}{
    \begin{tabular}{@{}c|cc|cccc|ccc|ccc@{}}
    \toprule
    \multirow{3}{*}{\textbf{Algorithm}} & \multicolumn{2}{c|}{\textbf{Feature Balance}} & \multicolumn{4}{c|}{\textbf{Key Alignment}} & \multicolumn{3}{c|}{\textbf{Communication}} & \multicolumn{3}{c}{\textbf{Trustworthy}} \\
    \cmidrule(lr){2-3} \cmidrule(lr){4-7} \cmidrule(lr){8-10} \cmidrule(lr){11-13}
    & \makecell{Balanced\\(33.51\%)} & \makecell{Skewed\\(66.49\%)} & \makecell{Precise\\(0.2\%)} & \makecell{Semi-precise\\(3.5\%)} & \makecell{Fuzzy\\(70.9\%)} & \makecell{Latent\\(25.4\%)} & Compressed & Async. & One-shot & Data & Model & Contr. \\
    \midrule
    \cite{hardy2017private} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{chen2020vafl} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{zhang2021asysqn} & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{castiglia2022compressed} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{wu2022coupled} & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{wu2022practical} & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark & \xmark \\
    \cite{kang2022fedcvt} & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{sun2023communication} & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark & \xmark \\
    \cite{attack:backdoor:baiyijie2023_villain} & \cmark & \xmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark \\
    \cite{irureta2024towards} & \cmark & \xmark & \cmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{sun2024mi} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{wang2024online} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{wang2024computation} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{valdeira2024communication} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{wu2024federated} & \cmark & \cmark & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{zhang2024asynchronous} & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{10.1109/TIFS.2024.3361813} & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark \\
    \cite{attack:dra:zhao_loki_2024} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark \\
    \cite{attack:backdoor:badvfl} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark \\
    \cite{attack:backdoor:hijack} & \cmark & \cmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \cmark \\
    \cite{attack:contribution:ace_2024} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark \\
    \cite{wang2024unified} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \cmark & \xmark & \cmark & \xmark & \xmark \\
    \cite{attack:dra:fu_privacy_2025} & \cmark & \xmark & \cmark & \xmark & \xmark & \xmark & \xmark & \xmark & \xmark & \cmark & \cmark & \xmark \\
    \midrule
    \makecell{Ratio of \;\cmark} & 100\% & 39\% & 100\% & 26\% & 9\% & 0\% & 30\% & 17\% & 9\% & 100\% & 26\% & 9\% \\
    \bottomrule
    \end{tabular}
    }
    \label{tab:vfl_algorithms}
\end{table*}

\subsection{Key Alignment}\label{sec:vfl-keys}

The quality of key alignment is a critical factor in VFL preprocessing. Based on our observations in Section~\ref{sec:scenario}, we categorize VFL frameworks into four types based on their assumptions about key alignment: Precise, Semi-Precise, Fuzzy, and Latent VFL.

\subsubsection{Precise VFL (0.2\%)}

Precise VFL refers to scenarios where all keys are perfectly matched, typically through unique identifiers like user IDs. While uncommon in practice according to Table~\ref{tab:record-matching}, most existing VFL frameworks assume this setting. It applies when each data record corresponds to a user whose ID can be aligned across parties, as seen in some VFL applications using phone numbers as unique IDs~\cite{chen2021homomorphic}. However, precise VFL is rare due to two strict constraints: \textit{all} and \textit{precise}. The \textit{all} constraint is particularly restrictive, requiring both parties to share the exact same set of instances. Studies and benchmarks indicate that cross-party data overlap is generally limited~\cite{qiu2024diverfed,yan2024cross,wu2022coupled,wei2023fedads}.

Precise VFL has been extensively studied and discussed in other surveys \cite{liu2024vertical}. These studies generally follow the PPRL and VFL learning pipeline. Due to the precise key alignment, most research treats PPRL as an orthogonal problem, often addressed by Private Set Intersection (PSI) \cite{morales2023private}, while focusing on the learning aspect. In precise VFL, significant progress has been achieved in various aspects, including accuracy \cite{wang2025pravfed}, efficiency \cite{li2023efficient}, communication \cite{sun2023communication}, and privacy \cite{jin2021cafe}.


\subsubsection{Semi-Precise VFL (3.5\%)}
Semi-precise (a.k.a. semi-supervised) VFL addresses scenarios where only a subset of keys are precisely matched. This scenario encompasses a broader range of real-world applications compared to precise VFL. For instance, in VFL across hospitals, each patient may not undergo all examinations and have records in all hospitals, a situation commonly referred to as ``missing-modal'' in multimodal learning \cite{zong2024self}.

Semi-precise VFL generally follows the PPRL and VFL learning pipeline but incorporates additional methods for handling missing features or label estimation. The specific estimation techniques employed significantly influence the performance of semi-precise VFL. For example, FedCVT \cite{kang2022fedcvt} estimates representations of missing features using scaled dot-product attention (SDPA) and generates pseudo-labels from existing labels. Similarly, \cite{sun2023communication} utilizes analogous techniques but reduces the communication rounds to one or a few. Furthermore, FedAds \cite{wei2023fedads} provides a real-world benchmark for semi-precise VFL. The technical details of semi-precise VFL have been comprehensively summarized in a recent survey \cite{song2024systematic}.



\subsubsection{Fuzzy VFL (70.9\%)}
Fuzzy VFL represents a more challenging scenario where all keys are not precisely matched but the key similarity indicates the probability of match. This situation is common in real-world applications where data records correspond to objects other than identifiable users, such as houses, routes, or products \cite{antoni2019past,wu2022coupled}. In such cases, keys might include GPS coordinates or product descriptions, which are related but not precise enough for direct alignment.

A straightforward approach to fuzzy VFL is to match the top similar pairs of data records and proceed with traditional VFL training \cite{hardy2017private,nock2021impact}. However, these methods often result in suboptimal performance due to the loss of information from less similar pairs. To mitigate this issue, FedSim \cite{wu2022coupled} considers key similarity as a special feature to guide the training of k-nearest-neighbor records, enabling two-party fuzzy VFL. FeT \cite{wu2024federated} further extends fuzzy VFL to multi-party scenarios by encoding keys into representations and employing transformers to identify relationships between these representations. Despite the progress, existing studies on fuzzy VFL still focus on low-dimensional numerical keys, and the performance of high-dimensional keys, such as text embeddings or image features, remains an open problem.



\subsubsection{Latent VFL (25.4\%)}
Latent VFL addresses scenarios where keys are unavailable due to privacy concerns or the absence of shared features. For instance, Singapore's Personal Data Protection Act (PDPA)\footnote{https://www.pdpc.gov.sg/} prohibits clinics from sharing identifiable medical data for research purposes without consent. Another example is a collaboration between a bitcoin transaction company and a bank to detect money laundering. In such cases, because bitcoin wallets are anonymous, there are no keys available to align data across parties. These challenging scenarios necessitate the development of new methods to align data based on their distributions rather than relying on keys. To the best of our knowledge, no existing VFL algorithm supports latent VFL. 








\subsection{Feature Balance}\label{sec:vfl-feature-imbalance}
Feature balance is critical for model performance and stability, as shown by a recent benchmark study~\cite{wu2023vertibench}. Figure~\ref{fig:feature-skew} reveals that real-world datasets often exhibit highly imbalanced feature distributions, posing challenges for existing VFL algorithms. Metrics such as Gini impurity~\cite{li2023efficient} and Dirichlet distribution~\cite{wu2023vertibench} evaluate this imbalance. This section categorizes VFL methods into balanced and imbalanced VFL based on a feature balance ratio threshold of 0.5.

\subsubsection{Balanced VFL (33.51\%)}
A balanced feature distribution is ideal for VFL, and most studies~\cite{irureta2024towards,wu2022practical,valdeira2024communication} simulate this by evenly splitting features among parties. However, this setting may not reflect real-world applications. A recent benchmark~\cite{wu2023vertibench} indicates that some methods~\cite{diao2022gal} experience performance degradation under imbalanced feature distributions.

\subsubsection{Imbalance VFL (66.49\%)}
In real VFL scenarios, datasets are distributed across parties with unique and uneven feature characteristics, leading to feature imbalance. This imbalance can significantly affect the performance of VFL \cite{wu2023vertibench}. To address feature imbalance, several algorithms have been developed to mitigate the effects of skewed feature distributions by re-weighting features or adjusting training algorithms. VertiBench~\cite{wu2023vertibench} shows that both SplitNN~\cite{vepakomma2018split} and FedTree~\cite{li2023fedtree} maintain stable performance under imbalanced conditions. A VFL framework~\cite{feng2022vertical} leverages local non-overlapping samples for feature selection, and a Gini impurity-based method~\cite{li2023efficient} accelerates training by filtering out noisy features. Despite these advancements, feature imbalance remains an underexplored challenge in VFL.

\subsection{Communication}
We categorize VFL studies into five types based on communication requirements: one-shot or multi-round VFL, transmission-compressed or uncompressed VFL, and synchronous or asynchronous VFL, as illustrated in Figure~\ref{fig:app-guide}. Since uncompressed and synchronous VFL are the most common, we focus on the remaining three types that address the specific challenges involved with communication.

\subsubsection{One-Shot VFL}
Traditional VFL requires reliable communication channels between the server and the participating clients, which, to some extent, narrows the scope of VFL applications, thereby raising the demand for reducing the number of communication rounds \cite{khan2022communication}. 
The introduction of one-shot VFL has minimized the average number of communication rounds required at the client side \cite{liu2024vertical}. 

Existing works focus on reducing VFL communication costs through unsupervised or semi-supervised learning to generate effective local representations. For example, combining semi-supervised learning with gradient clustering allows clients to learn local feature extractors using overlapping but unaligned samples and share these with the server in a single communication round~\cite{sun2023communication}. FedOnce uses unsupervised learning to generate client-side representations for server-side training in a single round~\cite{wu2022practical}, while APC-VFL integrates representation learning and knowledge distillation to achieve efficient training through aligned sample features~\cite{irureta2024towards}. 

These methods reduce communication rounds by up to hundreds of times, improving VFL's feasibility for clients with limited communication capacity. However, one-shot VFL may impact model accuracy and generalization, particularly under imbalanced data or low sample overlap. Multi-round training allows for gradual optimization, which one-shot approaches may struggle to achieve. Enhancing accuracy through relaxed constraints and few-shot learning algorithms offers a potential solution~\cite{sun2023communication}.

\subsubsection{Transmission-Compressed VFL}
When clients have limited communication budgets, it is common to apply transmission compression between the server and clients, especially for the collaborative training of deep neural networks, which are typically over-parameterized in both their model and feature parameters \cite{xiao2023smoothquant}.

For example, existing works alleviate the burden of data transmission using dimensionality-reduction algorithms \cite{sun2024mi}, quantization \cite{wang2024online}, both quantization and top-k sparsification \cite{castiglia2022compressed}, and pruning applied to both feature model and feature embeddings \cite{wang2024computation}.
Given that existing compression approaches are generally lossy, EFVFL has been proposed to leverage feedback on compression errors, achieving a high convergence rate \cite{valdeira2024communication}.

Although these works demonstrate promising performance in communication efficiency, there is still room for further optimization of data transmission. 
Promising directions include exploring zero-order optimization for VFL and gradient encoding using random seeds to achieve significant reductions in communication overhead \cite{qin24full}.

\subsubsection{Asynchronous VFL}
Traditional synchronous VFL requires all clients to update models simultaneously, creating inefficiencies in practical scenarios where clients have varying computational and network capacities. Asynchronous VFL improves flexibility and efficiency by allowing clients to update local models independently, enhancing the practicality of VFL. 

VAFL~\cite{chen2020vafl} introduces an asynchronous training framework that allows clients to perform stochastic gradient updates independently. AsySQN~\cite{zhang2021asysqn} uses approximate Hessians and a tree-structured collaboration paradigm to reduce communication rounds. VFL-CZOFO~\cite{wang2024unified} applies a hybrid zero-order and first-order optimization, while AVFKAM~\cite{zhang2024asynchronous} asynchronously updates kernel models using pairwise loss functions and random feature approximations. Despite these improvements, asynchronous VFL amplifies client drift~\cite{karimireddy2020scaffold}, as clients may update with outdated global parameters, leading to parameter divergence. Faster clients may dominate training contributions, raising fairness concerns. Addressing these challenges is crucial to ensuring VFL's effectiveness in real deployments.


\subsection{Trustworthy}\label{sec:vfl-attack-model}

VFL applications may involve varying types of sensitive information that require protection. We categorize trustworthiness concerns into three key areas: data privacy, model security, and contribution fairness.

\subsubsection{Data Privacy}
Data privacy is a key concern in VFL, which aims to prevent the exposure of each party's training data. While VFL provides some privacy by transmitting gradients or representations instead of raw data, it does not fully mitigate risks. Effective data protection requires addressing three major vulnerabilities: feature, label, and membership privacy.

\paragraph{Feature.} Existing feature inference attacks~\cite{attack:fia:luo2021} can extract individual features from transmitted embeddings, posing a significant privacy risk. Additionally, data reconstruction attacks can even recreate the original data from these embeddings~\cite{attack:dra:unifv_yang2025uifvdatareconstructionattack}. To mitigate these risks, techniques such as Falcon~\cite{attack:fia:luo2021} and model inconsistency defense~\cite{10.1145/3548606.3560557} should be adopted to secure the aggregation of intermediate embeddings.

\paragraph{Label.} Labels often contain sensitive information that requires protection from unauthorized access. Label inference attacks can deduce labels by analyzing gradient updates during training~\cite{liu2024label}. Advanced techniques like gradient inversion enable attackers to recover labels from batch-averaged local gradients~\cite{attack:lia:liuyang_yangqiang_blackbox}. Both passive and active LIA approaches have been demonstrated, where adversaries can exploit trained bottom models or manipulate gradients to maximize label leakage~\cite{attack:lia:fu2022}. To mitigate these risks, solutions like differential privacy~\cite{abadi2016deep} and encryption-based aggregation~\cite{attack:backdoor:baiyijie2023_villain} are essential to protect labels.

\paragraph{Membership.} While membership inference attacks (MIA) are well-studied in centralized learning to determine whether specific samples were used in training~\cite{attack:mia:survey_bai2024}, their impact on VFL is limited. This is because VFL's mandatory entity alignment process inherently reveals sample membership information between parties~\cite{yu2024survey}, making traditional MIA approaches less effective in the VFL context.


\subsubsection{Model Security}
In real-world VFL applications, adversarial attacks exploit system vulnerabilities, posing risks at both inference and training stages. At inference time, adversaries can craft inputs to induce misclassifications, even with limited access to features or labels~\cite{attack:backdoor:hijack}. These attacks are categorized as either targeted or untargeted. Targeted attacks manipulate specific tasks (e.g., classifying ``striped cars'' as ``birds'' while maintaining overall accuracy)~\cite{attack:backdoor:fool}, whereas untargeted attacks degrade overall model performance by corrupting training data~\cite{attack:backdoor:hijack}. These risks underscore the need for robust security measures to protect both inference and training processes in VFL.

Effective defense methods vary depending on the type of attack. To counter inference-time risks, techniques such as Differential Privacy~\cite{abadi2016deep} help safeguard sensitive data by limiting the information leakage from model outputs. For training-time attacks, including backdoor attacks that embed hidden vulnerabilities into the model~\cite{attack:backdoor:badvfl}, anomaly detection methods such as FreqAnalysis~\cite{safesplit}, originally developed for HFL, show promise in detecting and mitigating malicious updates. By integrating these defense, real-world VFL applications can better ensure both data privacy and model reliability.

\subsubsection{Contribution Fairness}
Protecting intellectual property in VFL requires safeguarding fair contribution evaluation, reward distribution, and preventing attacks like free-riding and contribution fraud. Free-rider attacks involve contributing random or inferred data to obtain a model without meaningful input, making detection difficult~\cite{lin2019freeridersfederatedlearningattacks}. Contribution fraud manipulates evaluation mechanisms to inflate importance and secure unfair rewards, posing a risk in incentive-based systems like Web3 federated learning~\cite{attack:contribution:ofl_w3_linshan}.

Defense mechanisms remain underdeveloped. Free-rider defenses, such as STD-DAGMM~\cite{lin2019freeridersfederatedlearningattacks}, are mainly designed for HFL and are less explored in VFL. Spy~\cite{attack:dra:fu_privacy_2025} highlights new free-rider threats in VFL, but no solution fully prevents these attacks. Fairness-focused methods~\cite{cui2024survey,attack:contribution:vfl_fan2024fair} offer some protection against contribution fraud, though attacks like ACE~\cite{attack:contribution:ace_2024} remain an unaddressed threat. Addressing these gaps is essential to enhance security and fairness in VFL.









