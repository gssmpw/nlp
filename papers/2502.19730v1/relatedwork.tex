\section{Related Work}
\label{sec:rw}

\subsection{Impact of AI Explanation Content on Decision-Making}\label{subsec:rw1}

With the spread of AI, decision-making support systems are increasingly being used in various fields such as e-commerce~\cite{schafer2001commerce,linden2003amazon}, law~\cite{angwin2022machine,grgic2019human,dressel2018accuracy}, medicine~\cite{cai2019human,tsai2021exploring}, and finance~\cite{hase2020evaluating,yang2024fair,binns2018s}.
Specifically in high-risk areas, where potential for significant losses remains, full automation is often undesirable. 
AI systems commonly provide predictions or advice for decision-making tasks; however, the final decision is left to humans.
Additionally, for recommendation systems, providing explanations for suggested items is crucial for helping users understand and trust the recommendations~\cite{zhang2020explainable,cramer2008effects}.

According to the literature~\cite{lai2023towards,miller2019explanation,zhang2020explainable}, the information presented is not limited to predictions or suggestions, but can be categorized into prediction- and model-related information.
Prediction-related information includes uncertainty of the predictions~\cite{guo2019visualizing,lee2021human}, local feature importance~\cite{alqaraawi2020evaluating,chromik2021think}, rule-based explanations~\cite{lim2009and,lakkaraju2016interpretable}, and example-based explanations~\cite{binns2018s,cai2019human}.
Model-related information includes model accuracy~\cite{lai2020chicago,yang2020visual}, global feature importance~\cite{dodge2019explaining,wang2021explanations}, and the data used for training~\cite{bhattacharya2024exmos}.
Providing these types of information improves task performance and efficiency, as well as the understanding and trust of users in AI systems~\cite{lai2023towards,miller2019explanation,zhang2020explainable}.


% The impact of explanation content on decision-making has been demonstrated in various studies.
Various studies have demonstrated the impact of explanatory content on decision-making.
Gedikli et al.~\cite{gedikli2014should} demonstrated that including elements such as authority and social proof of explanations for movie recommendations can increase consumption intentions for items initially perceived as less appealing.
Similarly, Oyebode et al.~\cite{oyebode2021tailoring} found that for smoking cessation, different types of content are effective depending on the stage of behavioral change.
In decision-making tasks involving AI-provided advice, the content of explanations influence the trust of users in the system and its advice, which affects their acceptance of the advice.
At the same time, the effectiveness of explanation content depends on factors such as the accuracy of the AI system~\cite{kahr2023seems}, user’s domain knowledge~\cite{wang2021explanations}, data format of the task~\cite{hase2020evaluating}, and presentation format of the explanation.~\cite{herlocker2000explaining,kouki2019personalized}.
Moreover, incorrect explanations can induce trust in high-difficulty tasks, leading users to follow inaccurate advice~\cite{sadeghi2024explaining}.
However, perceived trust in AI systems or their advice does not always translate into users accepting the advice.
% On the other hand, it has been reported that perceived trust in the AI system or its advice does not always translate into users accepting the advice.
This discrepancy is more likely when users have extensive domain knowledge, the scenario involves high-risk decision-making~\cite{kim2023humans}, or users report high familiarity with the task~\cite{Schaffer2019iui}.




\subsection{Impact of AI Explanation Expression on Decision-Making}\label{subsec:rw2}

Previous research has explored the impact of various expression styles in AI explanations, particularly focusing on warmth, metaphor, anthropomorphism, and tone, and how they influence user perceptions and behavior.
Several studies have investigated the relationship between warmth and competence in explanations.
Gilad et al.~\cite{gilad2021effects} showed that warmth tends to be prioritized over competence in AI system selection.
Similarly, Khadpe et al.~\cite{khadpe2020conceptual} found that in cooperative tasks, AI agents perceived as high in warmth but low in competence increased the ease of use, intention to use, and willingness to cooperate.
Mckee et al.~\cite{mckee2024warmth} demonstrated that users’ perceptions of agents are influenced more by warmth and competence than by objective performance.
Additionally, a literature review~\cite{jung2023female} indicated that female chatbots are more likely to evoke warmth and empathy, suggesting the importance of constructing metaphors that emphasize warmth rather than relying on binary gender distinctions.
In the context of home healthcare triage, G{\'o}mez et al.~\cite{gomez4797707large} found that the effect of the profile of an agent (rational vs. empathetic) on its advice was insignificant.


Regarding other methods of expression, Jung et al.~\cite{jung2022great} examined the impact of conceptual metaphors on crowdworkers in conversational agents.
They found that animal metaphors elicited higher engagement than inanimate metaphors, although no significant differences were noted in trust across metaphors.
Yang et al.~\cite{yang2024role} found that users react negatively when AI recommends vice products, but anthropomorphizing AI mitigates these negative reactions.
On voice assistants for older users, Chin et al.~\cite{chin2024like} found that those with lower agreeableness preferred informal conversational styles.
Additionally, in recommendation systems, Okoso et al.~\cite{okoso2024impact} demonstrated that the tone of explanations (formal or humorous) affects users’ perceptions of trustworthiness and persuasiveness, with these effects varying based on user attributes.
Moreover, several studies demonstrated that tailoring advertisements using LLMs to match the personality traits of users increases the likelihood of persuasion~\cite{meguellati2024good,matz2024potential}.



\subsection{Research Gaps}\label{subsec:gap}

As previously mentioned, extensive studies have been conducted on the explanations provided by AI systems in various decision-making support scenarios.
These studies have primarily focused on the types of explanation content that are effective and how they influence task performance and trust in the system, often discussing explanation content and expression separately.
Although studies focusing on explanation expressions have been increasing, most of these studies emphasize user perceptions, such as trust and understandability of the system, rather than their actual impact on decision-making.

Interestingly, perception and decision-making are not necessarily aligned; even when users claim to trust or understand an AI system, they do not always follow its suggestions~\cite{Schaffer2019iui,rechkemmer2022confidence,papenmeier2022s,wang2021explanations,hase2020evaluating}.
Whether these discrepancies also occur in explanation expressions remains unexplored.
Furthermore, existing studies on explanation expressions have mainly been limited to specific scenarios~\cite{yang2024fair,sivaraman2023ignore,bansal2021does,kahr2023seems,wang2021explanations}, leaving a lack of discussion on how these expressions influence decision-making across scenarios with different AI system roles.
Similarly, studies addressing user attributes remain limited~\cite{okoso2024impact,chin2024like}, and whether the impact of explanation expressions differs among user groups with varying attributes remains insufficiently understood.
To address these gaps, our study aims to investigate the impact of explanation expressions on decision-making by considering multiple scenarios with varying AI system roles and incorporating user attributes.


\begin{table*}[ht]
\centering
\small
\caption{Definitions of each tone}
\label{tb:tone_definitions}
\begin{tabular}{ll}
\toprule
\textbf{Tone} & \textbf{Definition} \\
\midrule
neutral & Objective and factual expression with a restrained emotional tone. Simple and direct language. \\
formal & Polite and sophisticated language. Professional and official tone. Courteous and cautious expression. \\
authoritative & Confident and assertive language. Persuasive and commanding expression. \\
casual & Relaxed and informal language. Friendly and conversational tone, often using colloquial expressions. \\
humorous & Incorporates humor and light-hearted expression. Casual tone with playful language. \\
romantic & Passionate and emotionally rich expression. Poetic and beautiful language. \\
\bottomrule
\end{tabular}
\end{table*}