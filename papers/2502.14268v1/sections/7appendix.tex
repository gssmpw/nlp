\cleardoublepage

\appendix
% \section{Notation Table}

\def \TabNotation{
\begin{table}[]
\centering
\resizebox{!}{0.18\textwidth}{
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Notation} & \textbf{Explanation} \\ 
\midrule
$\mathcal{M}$ & Language model \\ 
$\Sigma$ & Vocabulary \\
$\xInput$ & Input prompt \\ 
$\predSeq$ & Output responds \\ 
$A= \{ a_i,...a_m\}$ & Set of reference answers \\ 
$C_{\mathcal{M}}(\xInput,\predSeq)$ & Confidence score of $\predSeq$ \\ 
$f(\predSeq,\xInput)$ & Correctness function \\
$sim(\predSeq,A)$ & Similarity score \\
$\tau$ & LLM predefined threshold \\
$n$ & Number of open-form responses \\
$o_i$ & Options in QA dataset \\
$K$ & Number of options \\
\bottomrule
\end{tabular}}
\vspace{-1mm}
\caption{The notation used in this paper}
\vspace{-5mm}
\label{tab:notations}
\end{table}
}
%\TabNotation

% \section{Example Appendix}
% \label{sec:appendix}

\section{Experiments Details}\label{appendix:sec:exp_imp}

\subsection{Dataset Description}\label{sec:datasetDes}


\begin{itemize}
    \item \textbf{C-QA} A multiple-choice dataset designed for commonsense question answering. Each question requires world knowledge and reasoning to determine the correct answer from 5 given choices. The dataset consists of 1,221 test questions.
    
    \item \textbf{QASC} A multiple-choice commonsense reasoning dataset with 8 answer choices per question. Compared to C-QA, QASC presents a higher level of difficulty. While the dataset was originally designed for multi-hop reasoning, our focus is not on evaluating the reasoning capabilities of LLMs. Therefore, we do not provide the supporting facts to the model and instead present only the question. For our experiments, we use the original validation set, which includes 926 questions.
    
    \item \textbf{MedQA} A multiple-choice dataset with 5 options for answers, specifically designed for medical QA. 
    It covers three languages: English, simplified Chinese, and traditional Chinese, and contains 12,723, 34,251, and 14,123 questions for the three languages, respectively.
    The questions are sourced from professional medical board exams, making this dataset particularly challenging due to its reliance on specialized medical knowledge. 
    For our experiments, we randomly selected the first 1,000 questions from the English dataset.
    
    \item \textbf{RACE-m and RACE-h} used in this paper are derived from the RACE (\textbf{R}e\textbf{A}ding \textbf{C}omprehension dataset from \textbf{E}xaminations) dataset, a large-scale machine reading comprehension dataset introduced by Lai et al~\cite{lai2017race}. 
    RACE comprises 27,933 passages and 97,867 questions collected from English examinations for Chinese students aged 12–18. 
    These datasets evaluate a model’s ability to comprehend complex passages and answer questions based on contextual reasoning. 
    Each question is accompanied by four answer choices, with only one correct option. 
    For our experiments, we randomly sampled 1,000 questions from the entire dataset using a fixed random seed of 42 to ensure reproducibility.
\end{itemize}

% \textbf{RACE datasets:} The RACE-h and RACE-m datasets used in this paper are derived from the RACE (\textbf{R}e\textbf{A}ding \textbf{C}omprehension dataset from \textbf{E}xaminations) dataset, a large-scale machine reading comprehension dataset introduced by Lai et al~\cite{lai2017race}. 
% RACE comprises 27,933 passages and 97,867 questions collected from English examinations for Chinese students aged 12–18. 
% The dataset is split into two subsets: RACE-M, which includes 28,293 questions from middle school exams, and RACE-H, containing 69,574 questions from high school exams. Each question in the dataset is paired with four candidate answers, only one of which is correct. Unlike other machine reading comprehension datasets generated through heuristics or crowdsourcing, RACE's questions are designed by domain experts to test human reading and comprehension skills, making it a unique resource for evaluating large language understanding of models. For our specific study, since collecting responses and conducting evaluations is relatively time-consuming, so we conducted a random sample of 1,000 questions extracted from the entire dataset using a random seed of 42 to ensure reproducibility.


% \begin{table}[t!]
%     \centering
%     \begin{tabular}{lcc}
%         \toprule
%         Method & Description & \\
%         \midrule
%         \multicolumn{3}{c}{\textbf{Black-Box Methods}} \\
%         \midrule
%         Ecc(C) & \multicolumn{1}{c}{..} \\ 
%         Deg(C) & \multicolumn{1}{c}{..} \\ 
%         Ecc(E) & \multicolumn{1}{c}{..} \\ 
%         Deg(E) & \multicolumn{1}{c}{..} \\ 
%         Ecc(J) & \multicolumn{1}{c}{..} \\ 
%         Deg(J) & \multicolumn{1}{c}{..} \\ 
%         \midrule
%         \multicolumn{3}{c}{\textbf{White-Box Methods}} \\
%         \midrule
%         P(true) & \multicolumn{1}{c}{..} \\ 
%         CSL & \multicolumn{1}{c}{..} \\ 
%         CSL-next & \multicolumn{1}{c}{..} \\ 
%         SL & \multicolumn{1}{c}{..} \\ 
%         SL(norm) & \multicolumn{1}{c}{..} \\ 
%         TokenSAR & \multicolumn{1}{c}{..} \\ 
%         \bottomrule
%     \end{tabular}
%     \caption{All the baseline methods}
%     \vspace{-5mm}
%     \label{tab:similarity_matrix_stat}
% \end{table}
%\section{Implement Confidence Estimation Methods}


\subsection{Prompt Details}
\label{sec:appendix_prompt}
\begin{itemize}
    \item We use the following prompt to collect open-form responses for each of the 5 datasets separately.
    
\includegraphics[width=.9\columnwidth]{figures/generate_prompt.png}

    \item We use the following prompt to elicit P(True) confidence score.
    The ``Possible Answer'' is an option from the multiple-choice dataset.
    
\includegraphics[width=.9\columnwidth]{figures/ptrue_prompt.png}
\end{itemize}






\subsection{Computation Resources}
To efficiently process multiple queries, we used vLLM~\cite{kwon2023efficientvllm} for parallel inference.
All experiments were conducted on a Linux server running Ubuntu, equipped with an A100 80GB GPU.


\subsection{Response Generation }
For black-box methods, we mostly adopt the experimental configurations from~\citet{lin2024generating}. 
Sampling-based black-box confidence measures use $n=20$ open-form responses per question. 
The temperature settings for different LLMs are kept at their default values.


\section{Additional Experiments Results}\label{sec:full_results}

\subsection{Full Results of Different Evaluation Metrics}
In the main text, due to space constraints, we only show a subset of the AUROC results.
Here, \cref{appendix:tab:bb:auc,appendix:tab:wb:auc} show the AUROC and AUARC for black-box and white-box confidence measures, respectively. 
Similarly, \cref{appendix:tab:bb:calib,appendix:tab:wb:calib} present RCE and ECE results.
Note that all ECE are based on \textit{calibrated} confidence measures for fair comparisons, as some original confidence measures are not even constrained to $[0,1]$.
For the calibration step, we applied histogram binning method~\cite{KDD_HistogramBinning} on all methods.%, and compute the adaptive calibration error (ACE)~\cite{Nixon_2019_CVPR_Workshops}.


% full table
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%white
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}[h!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{llcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{AUROC $\Uparrow$}} & \multicolumn{6}{c}{\textbf{AUARC} $\Uparrow$} \\ 
\cmidrule(lr){3-8} \cmidrule(lr){9-14}
 &  & Ecc(C) & Deg(C) & Ecc(E) & Deg(E) & Ecc(J) & Deg(J) & Ecc(C) & Deg(C) & Ecc(E) & Deg(E) & Ecc(J) & Deg(J) \\ 
\midrule
\multirow{4}{*}{C-QA}
 & Llama2-7b   & 60.981 & 66.651 & 78.629 & 72.771 & 67.081 & 71.668 & 29.386 & 33.266 & 38.221 & 35.858 & 34.681 & 36.915 \\
 & Llama3-8b   & 57.590 & 62.592 & 80.004 & 73.734 & 65.886 & 76.583 &32.062 & 33.232 & 38.414 & 32.648 & 37.150 & 38.596\\
 & Phi4        & 67.879 & 68.413 & 80.712 & 69.976 & 71.447 & 75.278 & 32.123 & 31.596 & 19.294 & 30.032 & 28.570 & 24.739 \\
 & Qwen2.5-32b & 71.409 & 73.931 & 81.885 & 77.087 & 69.473 & 74.645 & 34.775 & 37.399 & 39.926 & 37.964 & 36.776 & 38.808 \\
\midrule
\multirow{4}{*}{QASC}
 & Llama2-7b   & 58.949 & 61.978 & 73.221 & 69.200 & 61.659 & 66.877 & 17.509 & 19.628 & 25.724 & 23.556 & 21.469 & 23.251 \\
 & Llama3-8b   & 55.121 & 55.446 & 74.912 & 72.033 & 64.124 & 72.657 & 15.785 & 15.952 & 25.199 & 24.163 & 23.198 & 25.786 \\
 & Phi4        & 65.100 & 65.553 & 76.980 & 67.692 & 68.496 & 71.209 & 20.297 & 21.063 & 26.740 & 21.422 & 24.067 & 24.308 \\
 & Qwen2.5-32b & 62.218 & 61.611 & 74.546 & 71.702 & 64.658 & 69.131 & 19.522 & 19.830 & 25.695 & 24.306 & 23.182 & 24.510  \\
\midrule
\multirow{4}{*}{MedQA}
 & Llama2-7b   & 53.683 & 54.129 & 52.076 & 52.963 & 53.137 & 53.778 & 21.956 & 23.105 & 21.160 & 22.863 & 23.454 & 23.371 \\
 & Llama3-8b   & 52.824 & 53.971 & 51.641 & 53.523 & 55.257 & 59.552 & 21.125 & 22.103 & 20.390 & 22.164 & 25.598 & 26.617 \\
 & Phi4        & 60.055 & 59.512 & 54.945 & 55.261 & 57.815 & 65.067 & 25.081 & 25.410 & 22.077 & 22.940 & 27.573 &29.201 \\
 & Qwen2.5-32b & 60.071 & 61.737 & 54.727 & 58.454 & 61.564 & 63.783 & 24.998 & 28.045 & 22.246 & 26.331 & 29.848 & 30.054 \\
\midrule
\multirow{4}{*}{RACE-m}
 & Llama2-7b  & 65.473 & 64.304 & 61.022 & 59.245 & 67.480 & 67.760 & 34.147 & 36.637 & 32.570 & 33.994 & 38.844 & 38.904 \\
 & Llama3-8b & 62.385 & 63.351 & 61.872 & 58.711 & 68.391 & 73.267 & 30.774 & 35.054 & 31.639 & 32.491 & 41.231 & 43.055 \\
 & Phi4     & 66.461 & 64.344 & 64.492 & 58.981 & 68.124 & 72.304 & 34.312 & 35.355 & 32.903 & 32.232 & 41.311 & 41.895  \\
 & Qwen2.5-32b & 65.425 & 67.627 & 60.268 & 61.309 & 75.420 & 75.746 & 34.393 & 37.409 & 32.092 & 34.850 & 44.281 & 44.585 \\
\midrule
\multirow{4}{*}{RACE-h}
 & Llama2-7b    & 58.991 & 53.597 & 57.178 & 54.037 & 59.300 & 59.856 & 34.147 & 36.637 & 32.570 & 33.994 & 38.844 & 38.904 \\
 & Llama3-8b  & 56.372 & 53.560 & 58.456 & 54.004 & 57.488 & 63.788 & 27.959 & 28.483 & 29.120 & 27.823 & 33.912 & 36.139 \\
 & Phi4    & 60.550 & 53.867 & 61.263 & 54.442 & 59.639 & 64.385 & 30.733 & 28.641 & 31.411 & 28.157 & 34.519 & 35.710    \\
 & Qwen2.5-32b   & 60.012 & 54.781 & 55.984 & 55.657 & 64.985 & 66.130 & 31.049 & 29.180 & 30.459 & 28.921 & 37.620 & 37.734 \\
\bottomrule
\end{tabular}%
}
\caption{AUROC and AUARC for black-box methods, across different models and datasets}
\label{appendix:tab:bb:auc}
\end{table*}


% only roc
% \begin{table*}[h!]
% \centering
% \resizebox{0.5\textwidth}{!}{%
% \begin{tabular}{llcccccc}
% \toprule
% \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{AUROC $\Uparrow$}} \\
% \cmidrule(lr){3-8}
%  &  & Ecc(C) & Deg(C) & Ecc(E) & Deg(E) & Ecc(J) & Deg(J) \\
% \midrule
% \multirow{4}{*}{C-QA}
%  & Llama2-7b   & 60.981 & 66.651 & 78.629 & 72.771 & 67.081 & 71.668 \\
%  & Llama3-8b   & 57.590 & 62.592 & 80.004 & 73.734 & 65.886 & 76.583 \\
%  & Phi4        & 67.879 & 68.413 & 80.712 & 69.976 & 71.447 & 75.278 \\
%  & Qwen2.5-32b & 71.409 & 73.931 & 81.885 & 77.087 & 69.473 & 74.645 \\
% \midrule
% \multirow{4}{*}{QASC}
%  & Llama2-7b   & 58.949 & 61.978 & 73.221 & 69.200 & 61.659 & 66.877 \\
%  & Llama3-8b   & 55.121 & 55.446 & 74.912 & 72.033 & 64.124 & 72.657 \\
%  & Phi4        & 65.100 & 65.553 & 76.980 & 67.692 & 68.496 & 71.209 \\
%  & Qwen2.5-32b & 62.218 & 61.611 & 74.546 & 71.702 & 64.658 & 69.131 \\
% \midrule
% \multirow{4}{*}{MedQA}
%  & Llama2-7b   & 53.683 & 54.129 & 52.076 & 52.963 & 53.137 & 53.778 \\
%  & Llama3-8b   & 52.824 & 53.971 & 51.641 & 53.523 & 55.257 & 59.552 \\
%  & Phi4        & 60.055 & 59.512 & 54.945 & 55.261 & 57.815 & 65.067 \\
%  & Qwen2.5-32b & 60.071 & 61.737 & 54.727 & 58.454 & 61.564 & 63.783 \\
% \midrule
% \multirow{4}{*}{RACE-m}
%  & Llama2-7b   & 65.473 & 64.304 & 61.022 & 59.245 & 67.480 & 67.760 \\
%  & Llama3-8b   & 62.385 & 63.351 & 61.872 & 58.711 & 68.391 & 73.267 \\
%  & Phi4        & 66.461 & 64.344 & 64.492 & 58.981 & 68.124 & 72.304 \\
%  & Qwen2.5-32b & 65.425 & 67.627 & 60.268 & 61.309 & 75.420 & 75.746 \\
% \midrule
% \multirow{4}{*}{RACE-h}
%  & Llama2-7b   & 58.991 & 53.597 & 57.178 & 54.037 & 59.300 & 59.856 \\
%  & Llama3-8b   & 56.372 & 53.560 & 58.456 & 54.004 & 57.488 & 63.788 \\
%  & Phi4        & 60.550 & 53.867 & 61.263 & 54.442 & 59.639 & 64.385 \\
%  & Qwen2.5-32b & 60.012 & 54.781 & 55.984 & 55.657 & 64.985 & 66.130 \\
% \bottomrule
% \end{tabular}%
% }
% \caption{Black Box Methods Performance Metrics Across Different Models and Datasets (AUROC)}
% \label{tab:metrics_table}
% \end{table*}



% \begin{table*}[h!]
% \centering

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%black
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{table*}[h!]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{llcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{AUROC} $\Uparrow$} & \multicolumn{6}{c}{\textbf{AUARC} $\Uparrow$} \\ \cmidrule(lr){3-8} \cmidrule(lr){9-14}
 &  & P(true) & CSL & CSL-next & SL & Perplexity & TokenSAR & P(true) & CSL & CSL-next & SL & Perlexity & TokenSAR \\ \midrule
\multirow{4}{*}{C-QA}
 & Llama2-7b   & 62.278 & 78.253 & 74.799 & 81.390 & 76.958 & 77.888 &  28.401 & 38.231 & 36.213 & 40.178 & 37.579 & 37.450 \\
 & Llama3-8b   & 82.760 & 78.423 & 73.068 & 81.731 & 75.503 & 75.385 & 40.235 & 38.191 & 35.096 & 40.152 & 36.368 & 35.453  \\
 & Phi4        & 86.184 & 77.382 & 73.477 & 78.903 & 75.471 & 75.722 & 42.447 & 37.984 & 35.749 & 38.452 & 36.928 & 36.630  \\
 & Qwen2.5-32b & 89.892 & 82.486 & 77.087 & 82.143 & 78.964 & 79.064 & 45.449 & 40.802 & 38.003 & 40.596 & 38.674 & 38.215\\%[1ex]
 \midrule
\multirow{4}{*}{QASC}
 & Llama2-7b   & 66.198 & 77.535 & 76.053 & 79.589 & 77.637 & 77.696 &  19.815 & 25.986 & 25.494 & 27.632 & 26.324 & 25.921\\
 & Llama3-8b   & 86.069 & 77.970 & 73.090 & 80.718 & 74.531 & 75.006 &  30.127 & 26.215 & 24.251 & 28.253 & 24.442 & 24.308 \\
 & Phi4        & 84.478 & 77.556 & 74.596 & 78.661 & 75.678 & 76.222 & 29.977 & 26.068 & 25.246 & 27.064 & 25.463 &25.307 \\
 & Qwen2.5-32b & 88.998 & 79.324 & 73.895 & 78.598 & 74.485 & 75.175 & 32.992 & 26.810 & 24.608 & 27.387 & 24.069 & 23.992  \\%[1ex]
  \midrule
\multirow{4}{*}{MedQA}
 & Llama2-7b   & 54.660 & 55.144 & 55.852 & 54.766 & 55.766 & 55.703 & 22.414 & 24.437 & 24.888 & 24.246 & 24.848 & 24.795  \\
 & Llama3-8b   & 77.493 & 57.384 & 57.894 & 57.919 & 57.592 & 57.530 & 36.884 & 24.072 & 25.225 & 25.879 & 24.973 & 24.803 \\
 & Phi4 & 86.888 & 65.550 & 64.284 & 63.287 & 65.588 & 65.696 &42.615 & 31.671 & 31.050 & 30.888 &31.752 & 31.775  \\
 & Qwen2.5-32b & 80.131 & 63.264 & 63.712 & 63.109 & 62.564 & 62.164 &40.197 & 27.495 & 27.754 & 29.382 & 27.440 & 27.221  \\%[1ex]
  \midrule
\multirow{4}{*}{RACE-m}
 & Llama2-7b  & 63.965 & 69.194 & 70.819 & 67.568 & 71.823 & 71.984 & 35.543 & 38.429 & 39.404 & 38.870 & 40.030 & 40.133 \\
 & Llama3-8b   & 82.118 & 67.317 & 70.875 & 69.321 & 69.851 & 70.029 & 47.145 & 36.953 & 40.206 & 40.508 & 39.144 & 39.232 \\
 & Phi4        & 90.543 & 68.334 & 69.5354 & 68.8049 & 69.025 & 69.188 & 52.457 & 36.638 & 38.717 & 40.314 & 37.972 & 38.057 \\
 & Qwen2.5-32b  & 56.049 &67.294 & 69.102 & 73.267 & 69.147 & 69.279 & 29.283 & 34.913 & 36.873 & 42.373 & 36.220 & 36.318 \\%[1ex]
  \midrule
\multirow{4}{*}{RACE-h}
 & Llama2-7b   & 61.265 & 61.905 & 62.481 & 59.889 & 63.486 & 63.465 & 35.543 & 38.429 & 39.404 & 38.870 & 40.030 & 40.133 \\
 & Llama3-8b    & 79.466 & 60.775 & 63.868 & 61.253 & 64.134 & 64.146 & 44.910 & 31.300 & 34.086 & 33.463 & 33.973 & 33.974 \\
 & Phi4       & 87.172 & 62.253 & 62.680 & 60.178 & 63.391 & 63.383 &  50.250 & 32.395 & 33.484 & 33.243 & 33.547 & 33.537 \\
 & Qwen2.5-32b   & 52.811 & 61.837 & 64.047 & 63.555 & 64.050 & 64.024 & 27.605 & 31.279 & 32.714 & 34.462 & 32.462 & 32.458 \\
\bottomrule
\end{tabular}%
}
\caption{AUROC and AUARC for white-box methods, across different models and datasets}
\label{appendix:tab:wb:auc}
\end{table*}

% \begin{table*}[h!]
% \centering
% \resizebox{0.5\textwidth}{!}{%
% \begin{tabular}{llcccccc}
% \toprule
% \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{AUROC} $\Uparrow$} \\
% \cmidrule(lr){3-8}
%  &  & P(true) & CSL & CSL-next & SL & Perplexity & TokenSAR \\ 
% \midrule
% \multirow{4}{*}{C-QA}
%  & Llama2-7b   & 62.278 & 78.253 & 74.799 & 81.390 & 76.958 & 77.888 \\
%  & Llama3-8b   & 82.760 & 78.423 & 73.068 & 81.731 & 75.503 & 75.385 \\
%  & Phi4        & 86.184 & 77.382 & 73.477 & 78.903 & 75.471 & 75.722 \\
%  & Qwen2.5-32b & 89.892 & 82.486 & 77.087 & 82.143 & 78.964 & 79.064 \\
% \midrule
% \multirow{4}{*}{QASC}
%  & Llama2-7b   & 66.198 & 77.535 & 76.053 & 79.589 & 77.637 & 77.696 \\
%  & Llama3-8b   & 86.069 & 77.970 & 73.090 & 80.718 & 74.531 & 75.006 \\
%  & Phi4        & 84.478 & 77.556 & 74.596 & 78.661 & 75.678 & 76.222 \\
%  & Qwen2.5-32b & 88.998 & 79.324 & 73.895 & 78.598 & 74.485 & 75.175 \\
% \midrule
% \multirow{4}{*}{MedQA}
%  & Llama2-7b   & 54.660 & 55.144 & 55.852 & 54.766 & 55.766 & 55.703 \\
%  & Llama3-8b   & 77.493 & 57.384 & 57.894 & 57.919 & 57.592 & 57.530 \\
%  & Phi4        & 86.888 & 65.550 & 64.284 & 63.287 & 65.588 & 65.696 \\
%  & Qwen2.5-32b & 80.131 & 63.264 & 63.712 & 63.109 & 62.564 & 62.164 \\
% \midrule
% \multirow{4}{*}{RACE-m}
%  & Llama2-7b   & 63.965 & 69.194 & 70.819 & 67.568 & 71.823 & 71.984 \\
%  & Llama3-8b   & 82.118 & 67.317 & 70.875 & 69.321 & 69.851 & 70.029 \\
%  & Phi4        & 90.543 & 68.334 & 69.5354 & 68.8049 & 69.025 & 69.188 \\
%  & Qwen2.5-32b & 56.049 & 67.294 & 69.102 & 73.267 & 69.147 & 69.279 \\
% \midrule
% \multirow{4}{*}{RACE-h}
%  & Llama2-7b   & 61.265 & 61.905 & 62.481 & 59.889 & 63.486 & 63.465 \\
%  & Llama3-8b   & 79.466 & 60.775 & 63.868 & 61.253 & 64.134 & 64.146 \\
%  & Phi4        & 87.172 & 62.253 & 62.680 & 60.178 & 63.391 & 63.383 \\
%  & Qwen2.5-32b & 52.811 & 61.837 & 64.047 & 63.555 & 64.050 & 64.024 \\
% \bottomrule
% \end{tabular}%
% }
% \caption{White Box Methods Performance Metrics Across Different Models and Datasets (AUROC)}
% \label{tab:metrics_table}
% \end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%next
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{llcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{RCE}} & \multicolumn{6}{c}{\textbf{Calibration ECE}} \\ \cmidrule(lr){3-8} \cmidrule(lr){9-14}
 &  & Ecc(C) & Deg(C) & Ecc(E) & Deg(E) & Ecc(J) & Deg(J) & Ecc(C) & Deg(C) & Ecc(E) & Deg(E) & Ecc(J) & Deg(J) \\ \midrule
\multirow{4}{*}{C-QA} 
 & Llama2-7b    & 0.2857  & 0.143722 & 0.117486 & 0.084357 & 0.271789 & 0.198744 & 0.014457 & 0.064792 & 0.025161 & 0.009014 & 0.009546 & 0.031801 \\
 & Llama3-8b    & 0.28071 & 0.15255  & 0.06311  & 0.041246 & 0.362527 & 0.153761 & 0.013865 & 0.044074 & 0.031566 & 0.016865 & 0.008845 & 0.060919 \\
 & Phi4         & 0.18881 & 0.115068 & 0.067507 & 0.038771 & 0.225698 & 0.218135 & 0.017734 & 0.059135 & 0.040364 & 0.024237 & 0.019987 & 0.056875 \\
 & Qwen2.5-32b  & 0.16192 & 0.114378 & 0.080021 & 0.055613 & 0.278165 & 0.198222 & 0.0111   & 0.087857 & 0.043406 & 0.016647 & 0.014439 & 0.051092 \\%[1ex]
  \midrule
\multirow{4}{*}{QASC} 
 & Llama2-7b    & 0.25132 & 0.162559 & 0.193186 & 0.121908 & 0.331258 & 0.252667 & 0.013984 & 0.020481 & 0.019263 & 0.012321 & 0.003108 & 0.022164 \\
 & Llama3-8b    & 0.28697 & 0.231308 & 0.083146 & 0.057512 & 0.401264 & 0.230094 & 0.003117 & 0.005336 & 0.004844 & 0.009398 & 0.010951 & 0.022145 \\
 & Phi4         & 0.19064 & 0.104986 & 0.066258 & 0.063753 & 0.23061  & 0.225091 & 0.004181 & 0.015734 & 0.012447 & 0.01108  & 0.003271 & 0.026654 \\
 & Qwen2.5-32b  & 0.25004 & 0.142512 & 0.091264 & 0.084393 & 0.31938  & 0.272657 & 0.010503 & 0.020774 & 0.012144 & 0.009716 & 0.004127 & 0.023387 \\%[1ex]
  \midrule
\multirow{4}{*}{MedQA} 
 & Llama2-7b    & 0.19817 & 0.188788 & 0.231296 & 0.243174 & 0.263178 & 0.213793 & 0.005909 & 0.006271 & 0.006057 & 0.01008  & 0.007157 & 0.008915 \\
 & Llama3-8b    & 0.21067 & 0.190038 & 0.286932 & 0.194414 & 0.290058 & 0.146904 & 0.006035 & 0.006757 & 0.006424 & 0.006872 & 0.01166  & 0.007277 \\
 & phi4         & 0.09127 & 0.09877  & 0.208792 & 0.132527 & 0.308812 & 0.087518 & 0.008327 & 0.018021 & 0.0156   & 0.008231 & 0.020912 & 0.016443 \\
 & Qwen2.5-32b  & 0.09064 & 0.089393 & 0.194414 & 0.087518 & 0.234422 & 0.118149 & 0.006312 & 0.01598  & 0.011337 & 0.021417 & 0.014092 & 0.021119 \\%[1ex]
  \midrule
\multirow{4}{*}{RACE-m} 
 & Llama2-7b  & 0.09876 & 0.31881 & 0.17315 & 0.27630 & 0.14502 & 0.16065 & 0.04523 & 0.07009 & 0.01980 & 0.01965  & 0.00778 & 0.01433 \\
 & Llama3-8b  & 0.10252 & 0.32068 & 0.12877 & 0.27005 & 0.21254 & 0.04500 & 0.00939 & 0.08513 & 0.00962 & 0.04675 & 0.025705  & 0.03261 \\
 & phi4          & 0.06001 & 0.31756  & 0.11252 & 0.26817 & 0.150655 & 0.07501 & 0.01699 & 0.07599 & 0.03366   & 0.01936 & 0.016385 &  0.01542 \\
 & Qwen2.5-32b  & 0.19378 &  0.32756 &  0.18253 & 0.27505 & 0.09689 & 0.1187 & 0.024623 & 0.10445  & 0.02922 & 0.05540 & 0.01300 & 0.02171 \\%[1ex]
  \midrule
\multirow{4}{*}{RACE-h} 
 & Llama2-7b  & 0.12565 & 0.36069 & 0.22441 & 0.40383 & 0.29568 & 0.30881 & 0.01702 & 0.06116 & 0.01635 & 0.01577  & 0.020679 & 0.01569 \\
 & Llama3-8b   & 0.20316 & 0.37007 & 0.18816 & 0.42070 & 0.26192 & 0.05938 & 0.01754 & 0.06838 & 0.01672 & 0.02324 & 0.02597  & 0.02622\\
 & phi4        & 0.09751 & 0.36757  & 0.14627 & 0.38820 &  0.26880 & 0.15878 & 0.01928 & 0.06393 & 0.021709   & 0.02191 & 0.02294 & 0.02502 \\
 & Qwen2.5-32b  & 0.11564 & 0.35069 & 0.21441 & 0.35569 & 0.28505 & 0.205666 & 0.01679 & 0.06562  & 0.01794 &0.02833 & 0.015137 & 0.01438 \\[1ex]
\bottomrule
\end{tabular}%
}
\caption{RCE and (calibrated) ECE for black-box methods, across different models and datasets}
\label{appendix:tab:bb:calib}
\end{table*}




\begin{table*}[t]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{llcccccccccccc}
\toprule
\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Model}} & \multicolumn{6}{c}{\textbf{RCE}} & \multicolumn{6}{c}{\textbf{Calibration ECE}} \\ \cmidrule(lr){3-8} \cmidrule(lr){9-14}
 &  & P(true) & CSL & CSL-next & SL & SL(norm) & TokenSAR & P(true) & CSL & CSL-next & SL & SL(norm) & TokenSAR \\ \midrule
\multirow{4}{*}{C-QA} 
 & Llama2-7b    & 0.084386 & 0.0506   & 0.041895  & 0.041267     & 0.038126 & 0.034997 & 0.0102   & 0.035637  & 0.041958  & 0.023881        & 0.04454 & 0.027278 \\
 & Llama3-8b    & 0.040614 & 0.03563  & 0.068102  & 0.031902     & 0.057489 & 0.038742 & 0.01871  & 0.034739  & 0.050008  & 0.022294        & 0.04291 & 0.026352 \\
 & Phi4         & 0.043731 & 0.04626  & 0.046892  & 0.043771     & 0.041858 & 0.03501  & 0.0583   & 0.034232  & 0.055943  & 0.019535        & 0.04302 & 0.030655 \\
 & Qwen2.5-32b  & 0.058105 & 0.02999  & 0.044359  & 0.032513     & 0.044363 & 0.059406 & 0.0369   & 0.022175  & 0.046935  & 0.021905        & 0.03671 & 0.021438 \\%[1ex]
  \midrule
\multirow{4}{*}{QASC} 
 & Llama2-7b    & 0.077448 & 0.04685  & 0.078796  & 0.051258     & 0.043136 & 0.045007 & 0.01119  & 0.024505  & 0.037871  & 0.023245        & 0.0326  & 0.023127 \\
 & Llama3-8b    & 0.030627 & 0.04811  & 0.117522  & 0.050664     & 0.08503  & 0.043753 & 0.00894  & 0.020665  & 0.038958  & 0.025687        & 0.03274 & 0.020785 \\
 & Phi4         & 0.082518 & 0.04437  & 0.116905  & 0.066942     & 0.088115 & 0.049376 & 0.02122  & 0.021401  & 0.0415    & 0.028242        & 0.02548 & 0.033083 \\
 & Qwen2.5-32b  & 0.11997  & 0.04878  & 0.062505  & 0.081237     & 0.073773 & 0.041861 & 0.03096  & 0.014358  & 0.040047  & 0.025111        & 0.02665 & 0.023483 \\%[1ex]
   \midrule
\multirow{4}{*}{MedQA} 
 & Llama2-7b    & 0.181911 & 0.19254  & 0.19879   & 0.191288     & 0.228796 & 0.238798 & 0.00606  & 0.015623  & 0.007533  & 0.00791         & 0.00669 & 0.007449 \\
 & Llama3-8b    & 0.028131 & 0.08939  & 0.121274  & 0.207542     & 0.163158 & 0.178161 & 0.0166   & 0.012721  & 0.008949  & 0.03            & 0.00861 & 0.010613 \\
 & phi4         & 0.05126  & 0.09127  & 0.115648  & 0.176285     & 0.119399 & 0.116273 & 0.02853  & 0.046391  & 0.05184   & 0.058272        & 0.05787 & 0.05535  \\
 & Qwen2.5-32b  & 0.078141 & 0.06126  & 0.07314   & 0.128151     & 0.088143 & 0.075015 & 0.03067  & 0.020881  & 0.033491  & 0.047763        & 0.03295 & 0.032673 \\%[1ex]
   \midrule
\multirow{4}{*}{RACE-m} 
 & Llama2-7b  & 0.16253 & 0.26130 & 0.22254 & 0.13502     & 0.24317 & 0.24567 & 0.00741 & 0.01935 & 0.03113 & 0.01820  & 0.061396 & 0.062452 \\
 & Llama3-8b    & 0.05938 & 0.18003 & 0.09814 & 0.12752     & 0.10252 & 0.12189 & 0.05006 & 0.05534 & 0.04303 & 0.04812        & 0.01986  & 0.02156 \\
 & phi4        & 0.09689 & 0.15753  & 0.09314 & 0.09689     & 0.13127 & 0.13565 & 0.02585 & 0.04808 &0.02775  & 0.032335        & 0.01727 & 0.01938 \\
 & Qwen2.5-32b  & 0.16940 & 0.17566 & 0.17691 & 0.17691     & 0.24567 & 0.25255 &0.00695& 0.04720  & 0.05091 &  0.07564        & 0.07986 &  0.08066 \\%[1ex]
   \midrule
\multirow{4}{*}{RACE-h} 
 & Llama2-7b & 0.17566 & 0.31818 & 0.32318 & 0.33256     & 0.31818 & 0.32256 & 0.01748 & 0.02600 & 0.01719 & 0.01613         & 0.021382 & 0.021339 \\
 & Llama3-8b   & 0.05563 & 0.22316 & 0.12189 & 0.15565     & 0.163782 & 0.149404 & 0.045399 & 0.01684 & 0.031577 & 0.034098        & 0.030134  & 0.030341 \\
 & phi4       & 0.08939 & 0.19566  & 0.150030 & 0.13315     & 0.19316 & 0.19566 & 0.019294 & 0.035576 &  0.02874   & 0.03037        & 0.02238 & 0.040637 \\
 & Qwen2.5-32b    & 0.24754 & 0.22254 & 0.21754 & 0.21316     & 0.29505 & 0.30006 & 0.016826 & 0.02004  &0.02105 & 0.022801        & 0.03156 & 0.04110 \\
\bottomrule
\end{tabular}%
}
\caption{RCE and (calibrated) ECE for white-box methods, across different models and datasets}
\label{appendix:tab:wb:calib}
\end{table*}







\subsection{Additional Visualizations for ROC Curves}
\cref{appendix:fig:ROC} presents the ROC curves for \phiName.
\baselinePTrue achieves much better performance than other confidence measures on the more challenging datasets, likely because \phiName is a relatively advanced model.
On the easier datasets, where we could observe a bigger performance gap between different confidence measures, it is also interesting to see that the general shapes (and rankings at different FPR) are relatively consistent across C-QA and QASC, suggesting stability of \uqeval.



\def \FigAUROCVisHorizontalBar{
\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/qasc_blackbox.png}
    \caption{AUROC of different black-box methods.}
    \label{fig:cqa_blackbox}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/qasc_whitebox.png}
    \caption{AUROC of different white-box methods.}
    \label{fig:another_dataset}
  \end{subfigure}

  \caption{(a) and (b) show the performance of 4 different LLMs and 12 different confidence estimation methods on the QASC dataset. A higher AUROC indicates better performance.}
  \label{fig:llm_perspective}
\end{figure}

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/medqa_blackbox.png}
    \caption{AUROC of different black-box methods.}
    \label{fig:cqa_blackbox}
  \end{subfigure}
  \begin{subfigure}[b]{\columnwidth}
    \centering
    \includegraphics[width=\columnwidth]{figures/medqa_whitebox.png}
    \caption{AUROC of different white-box methods.}
    \label{fig:another_dataset}
  \end{subfigure}

  \caption{(a) and (b) show the performance of 4 different LLMs and 12 different confidence estimation methods on the MedQA dataset. A higher AUROC indicates a better performance.}
  \label{fig:llm_perspective}
\end{figure}
}
%/FigAUROCVisHorizontalBar


% \begin{figure*}
%     \centering
%     \includegraphics[width=0.99\linewidth]{figures/comparison_qwen.pdf}
%     \caption{The comparison of different evaluation metrics using our method to quantify Qwen-2.5-32b model's uncertainty on datasets: RACE-h (harder) and RACE-m (easier).}
%     \label{fig:compareQwen}
% \end{figure*}

% \begin{figure*}
%     \centering
%     \includegraphics[width=0.99\linewidth]{figures/comparison_llama7b.pdf}
%     \caption{The comparison of different evaluation metrics using our method to quantify Llama2-7b model's uncertainty on datasets: RACE-h (harder) and RACE-m (easier).}
%     \label{fig:compareLlama2}
% \end{figure*}

% \begin{figure*}
%     \centering
%     \includegraphics[width=0.99\linewidth]{figures/comparison_llama8b.pdf}
%     \caption{The comparison of different evaluation metrics using our method to quantify Llama3-8b model's uncertainty on datasets: RACE-h (harder) and RACE-m (easier).}
%     \label{fig:compareLlama3}
% \end{figure*}

\begin{figure*}[htbp]
    \centering
    % Row 1: Two subfigures side by side
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/c-qa.png}
        \caption{C-QA Dataset}
        \label{fig:subfig1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/qasc.png}
        \caption{QASC Dataset}
        \label{fig:subfig2}
    \end{subfigure}

    % Row 2: Two subfigures side by side
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/extra/phi4_cqa_race_m_10_update1.png}
        \caption{RACE-m Dataset}
        \label{fig:subfig3}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/extra/phi4_cqa_race_h_10_update1.png}
        \caption{RACE-h Dataset}
        \label{fig:subfig4}
    \end{subfigure}

    % Row 3: One subfigure occupying most of the width
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/medqa.png}
        \caption{MedQA Dataset}
        \label{fig:subfig5}
    \end{subfigure}
    
    \caption{Comparison of different evaluation metrics using our method to quantify the \phiName model's confidence scores across five datasets (C-QA, QASC, RACE-m, RACE-h, MedQA), with increasing difficulty.}
    \label{appendix:fig:ROC}
\end{figure*}

% \section{AI Assistant Usage}

% We used GPT for grammar checking and Copilot as an assistive tool.