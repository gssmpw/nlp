@inproceedings{bau2020concept,
  title={Understanding the Role of Individual Neurons in Deep Learning},
  author={Bau, David and Zhu, Jun-Yan and others},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  url={https://arxiv.org/abs/2005.13194}
}

@article{belinkov-2022-probing,
    title = "Probing Classifiers: Promises, Shortcomings, and Advances",
    author = "Belinkov, Yonatan",
    journal = "Computational Linguistics",
    volume = "48",
    number = "1",
    month = mar,
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.cl-1.7/",
    doi = "10.1162/coli_a_00422",
    pages = "207--219",
    abstract = "Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple{---}a classifier is trained to predict some linguistic property from a model`s representations{---}and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This squib critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances."
}

@article{belrose2023tunedlens,
  author = {Nora Belrose and Zach Furman and Logan Smith and Danny Halawi and Igor Ostrovsky and Lev McKinney and Stella Biderman and Jacob Steinhardt},
  title = {Eliciting Latent Predictions from Transformers with the Tuned Lens},
  journal = {arXiv preprint},
  volume = {arXiv:2303.08112},
  year = {2023}
}

@misc{braun2024identifyingfunctionallyimportantfeatures,
      title={Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning}, 
      author={Dan Braun and Jordan Taylor and Nicholas Goldowsky-Dill and Lee Sharkey},
      year={2024},
      eprint={2405.12241},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.12241}, 
}

@inproceedings{bricken2023interpretable,
  title={Towards Monosemanticity: Decomposing Language Models With Dictionary Learning},
  author       = {Trenton Bricken and Adly Templeton and Joshua Batson and Brian Chen and Adam Jermyn and Tom Conerly and Nicholas L. Turner and Cem Anil and Carson Denison and Amanda Askell and Robert Lasenby and Yifan Wu and Shauna Kravec and Nicholas Schiefer and Tim Maxwell and Nicholas Joseph and Alex Tamkin and Karina Nguyen and Brayden McLean and Josiah E. Burke and Tristan Hume and Shan Carter and Tom Henighan and Chris Olah},
  booktitle={Transformer Circuits Thread},
  year={2023},
  url={}
}

@misc{chaudhary2024evaluatingopensourcesparseautoencoders,
      title={Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small}, 
      author={Maheep Chaudhary and Atticus Geiger},
      year={2024},
      eprint={2409.04478},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.04478}, 
}

@misc{cunningham2023sparseautoencodershighlyinterpretable,
      title={Sparse Autoencoders Find Highly Interpretable Features in Language Models}, 
      author={Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey},
      year={2023},
      eprint={2309.08600},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2309.08600}, 
}

@inproceedings{dai2022knowledge,
  author    = {Dai, D. and Dong, L. and Hao, Y. and Sui, Z. and Chang, B. and Wei, F.},
  title     = {Knowledge Neurons in Pretrained Transformers},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2022},
  pages     = {8493--8502}
}

@article{elhage2022toy,
  author    = {Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah},
  title     = {Toy Models of Superposition},
  journal   = {Transformer Circuits Thread},
  year      = {2022},
  url       = {https://transformercircuits.pub/2022/toy_model/index.html}
}

@misc{geva_transformer_2022,
	title = {Transformer {Feed}-{Forward} {Layers} {Build} {Predictions} by {Promoting} {Concepts} in the {Vocabulary} {Space}},
	url = {http://arxiv.org/abs/2203.14680},
	doi = {10.48550/arXiv.2203.14680},
	abstract = {Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50\%, and for improving computation efficiency with a simple early exit rule, saving 20\% of computation on average.},
	language = {en},
	urldate = {2024-12-30},
	publisher = {arXiv},
	author = {Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav},
	month = oct,
	year = {2022},
	note = {arXiv:2203.14680 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: EMNLP 2022},
	file = {Geva et al. - 2022 - Transformer Feed-Forward Layers Build Predictions .pdf:/Users/swu/Zotero/storage/ACKBXX66/Geva et al. - 2022 - Transformer Feed-Forward Layers Build Predictions .pdf:application/pdf},
}

@article{goh2021multimodal,
  title={Multimodal Neurons in Artificial Neural Networks},
  author={Goh, Gabriel and others},
  journal={Distill},
  year={2021},
  url={https://distill.pub/2021/multimodal-neurons/}
}

@misc{gurnee2023findingneuronshaystackcase,
      title={Finding Neurons in a Haystack: Case Studies with Sparse Probing}, 
      author={Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas},
      year={2023},
      eprint={2305.01610},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.01610}, 
}

@misc{karvonen2024evaluatingsparseautoencoderstargeted,
      title={Evaluating Sparse Autoencoders on Targeted Concept Erasure Tasks}, 
      author={Adam Karvonen and Can Rager and Samuel Marks and Neel Nanda},
      year={2024},
      eprint={2411.18895},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2411.18895}, 
}

@misc{marks2024sparsefeaturecircuitsdiscovering,
      title={Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models}, 
      author={Samuel Marks and Can Rager and Eric J. Michaud and Yonatan Belinkov and David Bau and Aaron Mueller},
      year={2024},
      eprint={2403.19647},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.19647}, 
}

@misc{miller2023neuron,
  title={We Found An Neuron in GPT-2},
  author={Miller, Joseph and Neo, Clement},
  year={2023},
  month={February},
  day={11},
  howpublished={AI Alignment Forum},
  note={Linkpost from \url{https://clementneo.com}}
}

@misc{mu2021compositionalexplanationsneurons,
      title={Compositional Explanations of Neurons}, 
      author={Jesse Mu and Jacob Andreas},
      year={2021},
      eprint={2006.14032},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.14032}, 
}

@article{nguyen2016synthesizing,
  title={Synthesizing the preferred inputs for neurons in neural networks via deep generator networks},
  author={Nguyen, Anh and Dosovitskiy, Alexey and others},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2016},
  url={https://arxiv.org/abs/1605.09304}
}

@article{olah2020circuits,
  title={An overview of early vision in InceptionV1},
  author={Olah, C. and Cammarata, N. and Schubert, L. and Goh, G. and Petrov, M. and Carter, S.},
  journal={Distill},
  year={2020},
  note={\url{https://distill.pub/2020/circuits/early-vision}}
}

@article{olah2020neuron,
  title={Zoom In: An Interpretability Method for Deep Neural Networks},
  author={Olah, Chris and Satyanarayan, Arvind and Carter, Shan and others},
  journal={Distill},
  year={2020},
  url={https://distill.pub/2020/circuits/}
}

@article{pal2023futurelens,
  author = {Koyena Pal and Jiuding Sun and Andrew Yuan and Byron C Wallace and David Bau},
  title = {Future Lens: Anticipating Subsequent Tokens from a Single Hidden State},
  journal = {arXiv preprint},
  volume = {arXiv:2311.04897},
  year = {2023}
}

@misc{radford2017learninggeneratereviewsdiscovering,
      title={Learning to Generate Reviews and Discovering Sentiment}, 
      author={Alec Radford and Rafal Jozefowicz and Ilya Sutskever},
      year={2017},
      eprint={1704.01444},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1704.01444}, 
}

@article{tao_e_2012,
    author = {Tao, Terence},
    title = {E pluribus unum: From Complexity, Universality},
    journal = {Daedalus},
    volume = {141},
    number = {3},
    pages = {23-34},
    year = {2012},
    month = {07},
    abstract = {In this brief survey, I discuss some examples of the fascinating phenomenon of universality in complex systems, in which universal macroscopic laws of nature emerge from a variety of different microscopic dynamics. This phenomenon is widely observed empirically, but the rigorous mathematical foundation for universality is not yet satisfactory in all cases.},
    issn = {0011-5266},
    doi = {10.1162/DAED_a_00158},
    url = {https://doi.org/10.1162/DAED\_a\_00158},
    eprint = {https://direct.mit.edu/daed/article-pdf/141/3/23/1830458/daed\_a\_00158.pdf},
}

@misc{voita2023neuron,
      title={Neurons in Large Language Models: Dead, N-gram, Positional}, 
      author={Elena Voita and Javier Ferrando and Christoforos Nalmpantis},
      year={2023},
      eprint={2309.04827},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.04827}, 
}

@misc{wang2022interpretabilitywildcircuitindirect,
      title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small}, 
      author={Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
      year={2022},
      eprint={2211.00593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.00593}, 
}

@misc{wang2024largelanguagemodelsinterpretable,
      title={Large Language Models are Interpretable Learners}, 
      author={Ruochen Wang and Si Si and Felix Yu and Dorothea Wiesmann and Cho-Jui Hsieh and Inderjit Dhillon},
      year={2024},
      eprint={2406.17224},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.17224}, 
}

@article{yomdin2023jump,
  author = {Alexander Yom Din and Taelin Karidi and Leshem Choshen and Mor Geva},
  title = {Jump to Conclusions: Short-Cutting Transformers with Linear Transformations},
  journal = {arXiv preprint},
  volume = {arXiv:2303.09435},
  year = {2023}
}

@misc{zou_representation_2023,
	title = {Representation {Engineering}: {A} {Top}-{Down} {Approach} to {AI} {Transparency}},
	shorttitle = {Representation {Engineering}},
	url = {http://arxiv.org/abs/2310.01405},
	abstract = {We identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places representations, rather than neurons or circuits, at the center of analysis, equipping us with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). We provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving our understanding and control of large language models. We showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power-seeking, and more, demonstrating the promise of top-down transparency research. We hope that this work catalyzes further exploration of RepE and fosters advancements in the transparency and safety of AI systems. Code is available at github.com/andyzoujm/representation-engineering.},
	language = {en},
	urldate = {2024-10-14},
	publisher = {arXiv},
	author = {Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and Goel, Shashwat and Li, Nathaniel and Byun, Michael J. and Wang, Zifan and Mallen, Alex and Basart, Steven and Koyejo, Sanmi and Song, Dawn and Fredrikson, Matt and Kolter, J. Zico and Hendrycks, Dan},
	month = oct,
	year = {2023},
	note = {arXiv:2310.01405 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	annote = {Comment: Code is available at https://github.com/andyzoujm/representation-engineering},
	file = {Zou et al. - 2023 - Representation Engineering A Top-Down Approach to.pdf:/Users/swu/Zotero/storage/C7IMTJ7Q/Zou et al. - 2023 - Representation Engineering A Top-Down Approach to.pdf:application/pdf},
}

