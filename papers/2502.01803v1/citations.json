[
  {
    "index": 0,
    "papers": [
      {
        "key": "geva_transformer_2022",
        "author": "Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav",
        "title": "Transformer {Feed}-{Forward} {Layers} {Build} {Predictions} by {Promoting} {Concepts} in the {Vocabulary} {Space}"
      },
      {
        "key": "zou_representation_2023",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and Goel, Shashwat and Li, Nathaniel and Byun, Michael J. and Wang, Zifan and Mallen, Alex and Basart, Steven and Koyejo, Sanmi and Song, Dawn and Fredrikson, Matt and Kolter, J. Zico and Hendrycks, Dan",
        "title": "Representation {Engineering}: {A} {Top}-{Down} {Approach} to {AI} {Transparency}"
      },
      {
        "key": "belinkov-2022-probing",
        "author": "Belinkov, Yonatan",
        "title": "Probing Classifiers: Promises, Shortcomings, and Advances"
      },
      {
        "key": "belrose2023tunedlens",
        "author": "Nora Belrose and Zach Furman and Logan Smith and Danny Halawi and Igor Ostrovsky and Lev McKinney and Stella Biderman and Jacob Steinhardt",
        "title": "Eliciting Latent Predictions from Transformers with the Tuned Lens"
      },
      {
        "key": "pal2023futurelens",
        "author": "Koyena Pal and Jiuding Sun and Andrew Yuan and Byron C Wallace and David Bau",
        "title": "Future Lens: Anticipating Subsequent Tokens from a Single Hidden State"
      },
      {
        "key": "yomdin2023jump",
        "author": "Alexander Yom Din and Taelin Karidi and Leshem Choshen and Mor Geva",
        "title": "Jump to Conclusions: Short-Cutting Transformers with Linear Transformations"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "olah2020neuron",
        "author": "Olah, Chris and Satyanarayan, Arvind and Carter, Shan and others",
        "title": "Zoom In: An Interpretability Method for Deep Neural Networks"
      },
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "wang2022interpretabilitywildcircuitindirect",
        "author": "Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
      },
      {
        "key": "marks2024sparsefeaturecircuitsdiscovering",
        "author": "Samuel Marks and Can Rager and Eric J. Michaud and Yonatan Belinkov and David Bau and Aaron Mueller",
        "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models"
      },
      {
        "key": "bau2020concept",
        "author": "Bau, David and Zhu, Jun-Yan and others",
        "title": "Understanding the Role of Individual Neurons in Deep Learning"
      },
      {
        "key": "goh2021multimodal",
        "author": "Goh, Gabriel and others",
        "title": "Multimodal Neurons in Artificial Neural Networks"
      },
      {
        "key": "nguyen2016synthesizing",
        "author": "Nguyen, Anh and Dosovitskiy, Alexey and others",
        "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"
      },
      {
        "key": "mu2021compositionalexplanationsneurons",
        "author": "Jesse Mu and Jacob Andreas",
        "title": "Compositional Explanations of Neurons"
      },
      {
        "key": "radford2017learninggeneratereviewsdiscovering",
        "author": "Alec Radford and Rafal Jozefowicz and Ilya Sutskever",
        "title": "Learning to Generate Reviews and Discovering Sentiment"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "bricken2023interpretable",
        "author": "Trenton Bricken and Adly Templeton and Joshua Batson and Brian Chen and Adam Jermyn and Tom Conerly and Nicholas L. Turner and Cem Anil and Carson Denison and Amanda Askell and Robert Lasenby and Yifan Wu and Shauna Kravec and Nicholas Schiefer and Tim Maxwell and Nicholas Joseph and Alex Tamkin and Karina Nguyen and Brayden McLean and Josiah E. Burke and Tristan Hume and Shan Carter and Tom Henighan and Chris Olah",
        "title": "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning"
      },
      {
        "key": "braun2024identifyingfunctionallyimportantfeatures",
        "author": "Dan Braun and Jordan Taylor and Nicholas Goldowsky-Dill and Lee Sharkey",
        "title": "Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning"
      },
      {
        "key": "cunningham2023sparseautoencodershighlyinterpretable",
        "author": "Hoagy Cunningham and Aidan Ewart and Logan Riggs and Robert Huben and Lee Sharkey",
        "title": "Sparse Autoencoders Find Highly Interpretable Features in Language Models"
      },
      {
        "key": "chaudhary2024evaluatingopensourcesparseautoencoders",
        "author": "Maheep Chaudhary and Atticus Geiger",
        "title": "Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small"
      },
      {
        "key": "karvonen2024evaluatingsparseautoencoderstargeted",
        "author": "Adam Karvonen and Can Rager and Samuel Marks and Neel Nanda",
        "title": "Evaluating Sparse Autoencoders on Targeted Concept Erasure Tasks"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "zou_representation_2023",
        "author": "Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and Goel, Shashwat and Li, Nathaniel and Byun, Michael J. and Wang, Zifan and Mallen, Alex and Basart, Steven and Koyejo, Sanmi and Song, Dawn and Fredrikson, Matt and Kolter, J. Zico and Hendrycks, Dan",
        "title": "Representation {Engineering}: {A} {Top}-{Down} {Approach} to {AI} {Transparency}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "tao_e_2012",
        "author": "Tao, Terence",
        "title": "E pluribus unum: From Complexity, Universality"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "wang2024largelanguagemodelsinterpretable",
        "author": "Ruochen Wang and Si Si and Felix Yu and Dorothea Wiesmann and Cho-Jui Hsieh and Inderjit Dhillon",
        "title": "Large Language Models are Interpretable Learners"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "radford2017learninggeneratereviewsdiscovering",
        "author": "Alec Radford and Rafal Jozefowicz and Ilya Sutskever",
        "title": "Learning to Generate Reviews and Discovering Sentiment"
      },
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "wang2022interpretabilitywildcircuitindirect",
        "author": "Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
      },
      {
        "key": "dai2022knowledge",
        "author": "Dai, D. and Dong, L. and Hao, Y. and Sui, Z. and Chang, B. and Wei, F.",
        "title": "Knowledge Neurons in Pretrained Transformers"
      },
      {
        "key": "voita2023neuron",
        "author": "Elena Voita and Javier Ferrando and Christoforos Nalmpantis",
        "title": "Neurons in Large Language Models: Dead, N-gram, Positional"
      },
      {
        "key": "miller2023neuron",
        "author": "Miller, Joseph and Neo, Clement",
        "title": "We Found An Neuron in GPT-2"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "mu2021compositionalexplanationsneurons",
        "author": "Jesse Mu and Jacob Andreas",
        "title": "Compositional Explanations of Neurons"
      },
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "olah2020circuits",
        "author": "Olah, C. and Cammarata, N. and Schubert, L. and Goh, G. and Petrov, M. and Carter, S.",
        "title": "An overview of early vision in InceptionV1"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "gurnee2023findingneuronshaystackcase",
        "author": "Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas",
        "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "gurnee2023findingneuronshaystackcase",
        "author": "Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas",
        "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "olah2020neuron",
        "author": "Olah, Chris and Satyanarayan, Arvind and Carter, Shan and others",
        "title": "Zoom In: An Interpretability Method for Deep Neural Networks"
      },
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "wang2022interpretabilitywildcircuitindirect",
        "author": "Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
      },
      {
        "key": "marks2024sparsefeaturecircuitsdiscovering",
        "author": "Samuel Marks and Can Rager and Eric J. Michaud and Yonatan Belinkov and David Bau and Aaron Mueller",
        "title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models"
      },
      {
        "key": "bau2020concept",
        "author": "Bau, David and Zhu, Jun-Yan and others",
        "title": "Understanding the Role of Individual Neurons in Deep Learning"
      },
      {
        "key": "goh2021multimodal",
        "author": "Goh, Gabriel and others",
        "title": "Multimodal Neurons in Artificial Neural Networks"
      },
      {
        "key": "nguyen2016synthesizing",
        "author": "Nguyen, Anh and Dosovitskiy, Alexey and others",
        "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"
      },
      {
        "key": "mu2021compositionalexplanationsneurons",
        "author": "Jesse Mu and Jacob Andreas",
        "title": "Compositional Explanations of Neurons"
      },
      {
        "key": "radford2017learninggeneratereviewsdiscovering",
        "author": "Alec Radford and Rafal Jozefowicz and Ilya Sutskever",
        "title": "Learning to Generate Reviews and Discovering Sentiment"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "radford2017learninggeneratereviewsdiscovering",
        "author": "Alec Radford and Rafal Jozefowicz and Ilya Sutskever",
        "title": "Learning to Generate Reviews and Discovering Sentiment"
      },
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "wang2022interpretabilitywildcircuitindirect",
        "author": "Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt",
        "title": "Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small"
      },
      {
        "key": "dai2022knowledge",
        "author": "Dai, D. and Dong, L. and Hao, Y. and Sui, Z. and Chang, B. and Wei, F.",
        "title": "Knowledge Neurons in Pretrained Transformers"
      },
      {
        "key": "voita2023neuron",
        "author": "Elena Voita and Javier Ferrando and Christoforos Nalmpantis",
        "title": "Neurons in Large Language Models: Dead, N-gram, Positional"
      },
      {
        "key": "miller2023neuron",
        "author": "Miller, Joseph and Neo, Clement",
        "title": "We Found An Neuron in GPT-2"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "elhage2022toy",
        "author": "Nelson Elhage and Tristan Hume and Catherine Olsson and Nicholas Schiefer and Tom Henighan and Shauna Kravec and Zac Hatfield-Dodds and Robert Lasenby and Dawn Drain and Carol Chen and Roger Grosse and Sam McCandlish and Jared Kaplan and Dario Amodei and Martin Wattenberg and Christopher Olah",
        "title": "Toy Models of Superposition"
      },
      {
        "key": "gurnee2023findingneuronshaystackcase",
        "author": "Wes Gurnee and Neel Nanda and Matthew Pauly and Katherine Harvey and Dmitrii Troitskii and Dimitris Bertsimas",
        "title": "Finding Neurons in a Haystack: Case Studies with Sparse Probing"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "bricken2023interpretable",
        "author": "Trenton Bricken and Adly Templeton and Joshua Batson and Brian Chen and Adam Jermyn and Tom Conerly and Nicholas L. Turner and Cem Anil and Carson Denison and Amanda Askell and Robert Lasenby and Yifan Wu and Shauna Kravec and Nicholas Schiefer and Tim Maxwell and Nicholas Joseph and Alex Tamkin and Karina Nguyen and Brayden McLean and Josiah E. Burke and Tristan Hume and Shan Carter and Tom Henighan and Chris Olah",
        "title": "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning"
      }
    ]
  }
]