\section{Conclusion and Future Work}
\label{sec:conclusion}
We introduced and analyzed the trade-off between the generalizability and explainability of predictive models, highlighting their often conflicting nature. Specifically, we demonstrated that the degree of model overfitting is positively correlated with its ability to generate counterfactual examples. 
Building on this insight, we proposed CF-Reg, a novel regularization technique that integrates a counterfactual regularization term into the training objective, to balance between predictive performance and interpretability.

Through extensive experiments across multiple datasets and model architectures, we showed that CF-Reg generally outperforms existing regularization techniques, improving generalization while maintaining the ability to generate meaningful counterfactual explanations. Our results suggest that counterfactual-based regularization can serve as a principled approach to improving model robustness without sacrificing interpretability.

However, we acknowledge that there is significant room for improvement, and we outline several promising directions for future research. First, we plan to explore more sophisticated counterfactual generation methods, which could enhance the effectiveness of our regularization strategy by generating more informative perturbations. Second, we aim to investigate adaptive weighting strategies that dynamically adjust the regularization strength for each training instance based on its proximity to the decision boundary. %, ensuring a more targeted and efficient application of CF-Reg.
% We introduced and analyzed the trade-off between the generalizability and explainability of predictive models. Specifically, we showed that the degree of model overfitting positively correlates with its ability to generate counterfactual examples. Building on this insight, we proposed CF-Reg, a novel regularization technique that incorporates a counterfactual regularization term into the training objective to balance these competing aspects effectively. 

% Extensive experiments conducted across multiple datasets and models showed the general superiority of our method compared to existing regularization techniques. However, we acknowledge that there is significant room for improvement, and we have identified at least the following avenues for future research. First, we plan to experiment with more complex counterfactual generation methods to be incorporated into the proposed regularized training loss. Second, we will explore more refined weighting strategies that adapt the magnitude of regularization for each training point based on its proximity to the decision boundary.