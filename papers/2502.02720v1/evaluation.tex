In this section, we present a detailed performance evaluation of the proposed heuristics with various values of $s$ (the sensitivity parameter of the Zipfian distribution), the number of virtual resources $m$, and the number of roles $n$. %The results are organized in three categories based on classification of cloud datacenters i.e. \textit{HSD}, \textit{MSD}, and \textit{LSD} as mentioned in Section~\ref{ch4:sec:sensitivity}. For each category, we present the performance results of three heuristic algorithms  for the metrics $RISK$, $\Delta$ and $DI$.Delta

 \begin{table}[t!]
      \centering
       \begin{tabular}{| c | c | c | c |}
        \hline 
            x & Location type & x & Location type \\ \hline \hline
            1 & Accomodations & 9 &  Religious buildings\\ \hline
            2 & Governmental & 10 & City buildings  \\ \hline
            3 & Cemeteries & 11 & Shops  \\ \hline
            4 & Educational & 12 & Stadiums  \\ \hline
            5 & Restaurants & 13 & Recreational \\ \hline
            6 & Health centers & 14 & Transportation stops \\ \hline
            7 & Parks & 15 & Dams and towers \\ \hline
            8 & Banks  &&\\
            \hline
        \end{tabular}
        \caption{POI Location types}
        \label{tab:loc}
\end{table}
\begin{table}[t!]
      \centering
       \begin{tabular}{|c| c|}
        \hline
            y & Time slot \\ \hline \hline
            1 & 6:00 AM to 11:59 AM \\ \hline
            2 & 12:00 PM to 4:59 PM \\ \hline
            3 & 5:00 PM to 7:59 PM \\\hline
            4 & 8:00 PM to 5:59 AM\\\hline
        \end{tabular}
        \caption{Time slots}
        \label{tab:time}
\end{table}

\begin{figure*}[t]
%trim option's parameter order: left bottom right top
    \begin{center}
        \subfloat[Global p.m.f]{\label{fig:global}
        \includegraphics[width=0.33\textwidth]{fig/gnuplot/property/global.eps}
        } 
     \subfloat[$D_1$ p.m.f]{\label{fig:role1}
        \includegraphics[width=0.33\textwidth]{fig/gnuplot/property/r1.eps}

        } 
            \subfloat[$D_2$ p.m.f]{\label{fig:role2}
        \includegraphics[width=0.33\textwidth]{fig/gnuplot/property/r2.eps}
        }
        \caption{Global and local p.m.f.}
\label{fig:pmf}        
       \end{center}         
\end{figure*} 



\subsection{Check-in Dataset}
In this section we present a detailed discussion about the dataset and the sensitive properties used in evaluating the proposed heuristics. The experiments have been conducted using a  real life check-in dataset collected from \textbf{Gowalla} social networking website \footnote{https://snap.stanford.edu/data/loc-gowalla.html}. The Gowalla dataset has around 6.5 million check-in entries for about 200,000 users around the world over. The data was collected over a period of 20 months. The dataset contains information about time and geo-coordinates of the check-ins. In order to introduce location semantic in the dataset, we have extracted a list of Point-Of-Interests (POI) from \textbf{OpenStreetMap} \footnote{https://www.openstreetmap.org/} and map each check-in entry to the nearest POI based on geo-coordinates. The mapping is conducted as the following. The area of the check-in entry is increased to a circle of around 111 $m$ in radius by truncating the values of the latitude and longitude to 3 decimal digits. The candidate POIs are those which have the same values of the first 3 decimal digits. The POI with the smallest value in the 4th decimal digits of latitude and longitude is used. Each entry in the mapped dataset contains the time of check-in, the type of POI, and user ID. For the experiments in this paper, a subset of the mapped dataset that belongs to the US Midwest region is used. For this region of 12 US states, the overall size is about 250,000 entries.

\subsubsection{Definition of Sensitive Properties}

Two discrete random variables in the dataset is defined; $X$ and $Y$. Let $X$ be a discrete random variable that indicates the type of location of the check-in entry, and $Y$ a discrete random variable that indicates the time slot. The probability $Pr(X=x)$ (or $P_X(x)$) is the probability of check-in at a location of type x. The probability computed as the following:
\begin{equation*}
P_X(x) = \frac{\text{\# of check-ins in locations of type x}}{\text{Total number of check-ins}}
\end{equation*}

Similarly, $Pr(Y=y)$ (or $P_Y(y)$) is the probability of check-in during time slot y. The probability is computed as the following:
\begin{equation*}
P_Y(y) = \frac{\text{\# of check-ins during slot y}}{\text{Total number of check-ins}}
\end{equation*}
The joint probability $Pr(X=x,Y=y)$ (or $P_{X,Y}(x,y)$) is the probability of check-in at a locations of type x during time slot y. The joint probability is computed as the following: 
{\small
\begin{equation*}
P_{X,Y}(x,y) = \frac{\text{\# of check-ins in locations of type x during slot y}}{\text{Total number of check-ins}}
\end{equation*}
}
Note, that there are many ways to define the random variables $X$, $Y$, and their joint pmf. The above definition is used in order to study the correlation between the random variables representing the location and time of check-ins.

In our experiments, we categorize POIs into 15 categories and time into 4 slots. Tables \ref{tab:loc} and \ref{tab:time} summarize the discrete values of $X$ and $Y$. For the dataset associated with the Midwest region, Figure \ref{fig:global} depicts the joint pmf $p(x,y)$ for the random variables  $X$ and $Y$ taking values according to Table \ref{tab:loc} and Table \ref{tab:time}, respectively. To exemplify the effect of RBAC policy on the pmf, suppose there are two roles, $R_1$ and $R_2$, with dataset $D_1$ and $D_2$, respectively. The size of $D_1$ is 30400, while the size of $D_2$ is 138276. Note, $D_1$ and $D_2$ can be overlapping, i.e., can share some check-in entries. Figures \ref{fig:role1} and \ref{fig:role2} depict the pmfs of $D_1$ and $D_2$, respectively. For example, the probability of check-in in restaurants between 5 PM and 8 PM is 0.079, 0.098, and 0.083, for the entire dataset,  $D_1$, and  $D_2$, respectively.

\subsubsection{Monotonicity of the Sensitive Properties}

Figure \ref{fig:mono} show the relationship between the size and the embedded sensitive property of the check-in dataset. In this experiment, we vary the size of dataset between 10\% to 100\% with an increase of 10\% and choose check-in entries randomly. The sensitive property of the subset is computed. The experiment is repeated 10 times and the average values of divergence and mutual information are reported. We note that the divergence and mutual information are monotonically decreasing as the size of the dataset increasing. Note that this behavior might not hold for other dataset. 

\begin{figure}[t!]
%trim option's parameter order: left bottom right top
    \begin{center}
        \subfloat[Divergence]{\label{fig:divMono}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/submodular/divSubmodular.eps}
        }
                \hskip 0.05truein
     \subfloat[Mutual information]{\label{fig:MImono}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/submodular/MIsubmodular.eps}

        }
        \caption{Monotonicity of the divergence and mutual information in check-in dataset.}
\label{fig:mono}
       \end{center}         
\end{figure} 

\subsection{Evaluation Metrics}
In this section, we introduce three evaluation metrics to compare the performance of the proposed heuristics. The first two metrics evalaute with the overall disclosure risk exhibited by all roles. The third metric focuses on the disclosure risk incurred per role. The first metric is the \textit{disclosure risk}, i.e., $Risk$ Equation \ref{eq:cost}. This metric depends on the sensitive property function used in the cost function. The risk metric associated with the $KLD$-based sensitive property measures the risk incurred due to the reduction of the divergence between the attacker's pmf and the global pmf. On the other hand, the risk metric corresponding to the $MI$-based sensitive property measures the risk incurred due to the reduction in the difference between the estimated $MI$ by a role and the global $MI$. 

The second measure is the \emph{quality of risk-reduction} $(\Delta)$ that measures the ability of the proposes heuristics to reduce the disclosure risk by assigning roles to virtual resources. In order to compute $\Delta$, we define the property attackability ($PA$) as the maximum disclosure risk of the sensitive property for a given policy. Formally, $PA$ is given as the following: 
\begin{equation}
PA = \sum_{r_i \in R} f(r_i)
\end{equation}
 Accordingly, the quality of risk-reduction is the relative difference between $PA$ and the disclosure risk of the sensitive properties, i.e., $KLD$-based sensitive property or $MI$-based sensitive property. Formally, $\Delta$ is given as the following:
\begin{equation}
\label{eq:QoR}
\Delta = \frac{PA - Risk}{PA}
\end{equation}
Note, $ 1 \le \Delta \le 0$.

The third metric is the \textit{discriminator index} ($DI$)  which evaluates the performance of the heuristics at the role level. In particular, $DI$ is an indirect indicator of the performance in terms of risk reduction per role. Semantically, $DI$ not only indicates the quality of reducing the risk at the role level but also implies the disproportionality in terms of risk management among the roles. DI is an extension of the generic discriminator index \cite{jain1984quantitative}, and is given as the following:
\begin{equation}
\label{eq:DI}
 DI = 1- \frac{(\sum_{i=1}^n \Delta_i)^2}{n\times \sum_{i=1}^{n}(\Delta_i)^2} 
\end{equation}
where $\Delta_i$ is given as the following:
\begin{eqnarray*}
\Delta_i &= &\frac{f(r_i) - Risk(r_i)}{f(r_i)}
\end{eqnarray*}
and $Risk(r_i)$ is given in Equation \ref{eq:cost}.
%
%\begin{definition}
%Given a scheduling heuristic, DI for a heuristic can be formally defined by extending the definition of generic discriminator index in . For this purpose, given a role $r_i$, we define the property attackability ($PA_i $), the associated risk ($RISK(r_i) $), and the role quality of risk reduction $\Delta_i$ as follows:\\


\subsection{Experimental Setup}
In this experiment, we simulate up to 6 clusters of virtual resources, i.e., VMs. The size of a each cluster ranges from 1 to 32 VMs. A cluster of VMs can be hosted by one or more physical servers. However, in our experiment, we consider one physical server per virtual cluster. The inter-vulnerabilities across virtual clusters are zeros, thus reflecting  physical isolation. The intra-vulnerabilities among VMs within a cluster are randomly generated. All intra-VM vulnerabilities are non-zeros and thus higher than inter-VM vulnerabilities. This is correct because the fact that, in general, physical isolation is more secure than VM isolation. Two sensitive properties functions, i.e., $KLD$-based and $MI$-based, are used for the performance evaluation. Finally, we use the RBAC policy sensitive property profile truncated up to level 3.


\subsection{Performance Results for $KLD$-based Sensitive Property}
In this section, we discuss the performance of the proposed assignment heuristics for a $KLD$-based sensitive property with respect to the aforementioned performance metrics i.e. $Risk$, $\Delta$, and $DI$. 

\subsubsection{Total Risk ($RISK_{KLD}$)}
For both proposed heuristics, we observe that $RISK_{KLD}$ increases as we move from \textit{LSD} to \textit{HSD} case as shown in Figure \ref{fig:30vRiskDiv}. In other words, for the same value of divergence risk, the number of roles in $LSD$ required to obtain the risk value is more than the number of roles in $HSD$ as shown with the dotted horizontal lines in Figure \ref{fig:30vRiskDiv}. The reason can be explained using the monotonicity property shown in Figure \ref{fig:mono}. In particular, a role in $HSD$ workload gain more information by attacking other roles in compared to an $LSD$ workload. This is because that roles in $HSD$ workload share less data compared to $LSD$ workload and thus the data size increases. In general, we notice that $TDH$ outperforms $NBH$ since $TDH$ assigns role clusters based on aggregated risk  in contrast to $NBH$ which assigns each role independently. Figure \ref{fig:30vRiskDiv} shows that as we increase the number of roles, the resulting risk $RISK_{KLD}$ increases. This is expected as the total risk is the sum of  the risk from all the roles. 

However, $RISK_{KLD}$  decreases as the number of VMs used in the experiment increases as depicted in Figure \ref{fig:150rRiskDiv}. This behavior is expected as increasing the number of available resources, i.e. VMs, reduces the number of roles assigned to the same VM which reduces the intra VM attack. Also, we can notice for Figure \ref{fig:150rRiskDiv} that for the case of $HSD$ the decrease in $RISK_{KLD}$ is more  prominent than for the case of $LSD$. The reason being the parameter $PA$ has a higher value for $HSD$ due to low sharing of data among the roles. Therefore, increasing the number of VMs is more beneficial for the case of $HSD$ than for  the case of $LSD$.


 \begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/RiskDiv/30vRiskDiv.eps}
        \caption{Total Divergence Risk $(RISK_{KLD})$ with a problem size of 30 VMs  for LSD and HSD datacenters.} 
        \label{fig:30vRiskDiv}     
             \end{center}          
                \vspace{-1.0em}
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/RiskDiv/150rRiskDiv.eps}
        \caption{Total Divergence Risk $(RISK_{KLD})$ with a problem size of 150 roles for LSD and HSD datacenters.} 
        \label{fig:150rRiskDiv}
     \end{center}         
             \vspace{-1.0em}
\end{figure} 



%We can notice that when the number of VMs approaches the number of roles, both heuristic result the same assignment as shown in Figure \ref{}. The reason is that in this case $TDH$ clusters contains one role and therefore assignment is based on  role independently of other roles as in $NBH$. Consequently both $NBH$ and $TDH$ have same performance.  

\subsubsection{Quality of Risk-Reduction($\Delta$)}
For a given heuristic, $\Delta$  decreases with $n$ as depicted in Figure \ref{fig:30vQoRDiv}. The reason being that by increasing the value of $n$, $PA$ of the RBAC policy increases relatively at a faster rate than the rate at which  $RISK_{KLD}$ increases. In addition, as shown in Figure \ref{fig:30vQoRDiv}, $TDH$  outperforms  $NBH$ for both LSD and HSD cases since  $TDH$ extensively searches for better assignments to improve  $RISK_{KLD}$. However in the case of HSD since the size of roles in term of  data items is smaller as compared to LSD, "partial sensitive property" possessed by a role is relatively small for $HSD$.  Therefore it is expected that the value of $\Delta$ is relatively low for HSD as compared to LSD; a phenomenon clearly observable from Figure \ref{fig:30vQoRDiv}. 


In Figure \ref{fig:150rQoRDiv}, we observe that for given RBAC policy the increase in the number of VMs improves  $\Delta$ due to reduction in  $RISK_{KLD}$  while the value of parameter $PA$ for the policy does not change.   The behavior of the curves in terms of HSD and LSD in the Figure \ref{fig:150rQoRDiv} can be reasoned similar to reasons given for the Figure \ref{fig:30vQoRDiv}. 



 \begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/delta/30vQoRDiv.eps}
        \caption{Quality of Risk-Reduction  $\Delta$ with a problem size of 30 VMs  for LSD, and HSD datacenters.} 
        \label{fig:30vQoRDiv}
        \vspace{-1.0em}
     \end{center}         
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/delta/150rQoRDiv.eps}
        \caption{Quality of Risk-Reduction  $\Delta$ with a problem size of 150 roles  for LSD and HSD datacenters.} 
        \label{fig:150rQoRDiv}
        \vspace{-1.0em}
     \end{center}         
\end{figure} 

\subsubsection{Discrimination Index ($DI$)}
The $DI$ metric captures the behavior of both  heuristics  in terms of  $RISK(r_i)$. Intuitively, a low value of $DI$ indicates that the $RISK(r_i)$ is {\color{red}proportional} to $PA_i$.  On other hand, a high value of $DI$ indicates that the resulting $RISK(r_i)$ is {\color{red}disproportional} to $PA_i$ and, in essence, provides  an indication about  bad scheduling decisions.   Figure \ref{fig:30vDIDiv} depicts the performance of both heuristics for the cases of LSD and HSD as we increase the number of roles. Both heuristics tend to perform well in terms of $DI$. The reason being that increasing the number of roles tend to disperse the global sensitive property over large number of rules. As a consequence, the $PA_i$s tend to be close to each other, thus reducing the discrimination effect. In particular, we  note  that $DI$  for both heuristics improves (decreases) and eventually stays steady with no further improvement. A noticeable observation is that for $HSD$,  $DI$ always yields better results than $LSD$ since for small number of roles in $HSD$, $PA_i$'s have high values which making it  easier to generate  good scheduling decision in the initial assignment for the case of NBH as it uses a greedy strategy.  In fact,  for the case of HSD such "good decisions" are consistently made by $NBH$ with increasing value of $n$ as noticed by the green curve for 30 roles in Figure \ref{fig:30vDIDiv}. Similar reasoning can be provided for the behavior of TDH algorithm as shown in Figure \ref{fig:30vDIDiv}.

As we increase the number of VMs for both $LSD$ and $HSD$ datacenters,   $NBH$ tends to improve its $DI$ performance as depicted in Figure \ref{fig:150rDIDiv}., in contrast to $TDH$ where $DI$ is not  effected by the number of VMs. The reason is that  $NBH$ schedules roles using  a greedy approach  based on the $PA_i$ related to the roles. Therefore, increasing the number of VMs alway improves  $DI$ based performance of $NBH$.  In contrast, $TDH$  makes its  scheduling decisions using a more extensive search to generate a solution and  does not consider $PA_i$ during its assignment step.


\subsection{Performance Results for Mutual Information $MI$}

The performance of  of $NBH$ and $TDH$ for the sensitive property  $MI$ in terms of  $RISK_{MI}$,  $\Delta$, and $DI$ parameters is similar to the performance observed of the  $Div$ property. For example \textit{TDH} consistently outperforms $NBH$ as the number of roles and the number of VMs increase as shown in  Figures~\ref{fig:20vRiskMI},~\ref{fig:70rRiskMI}, and~\ref{fig:20vQoRMI}.  However,  we observe a higher value of $\Delta$ for $Div$ property (see Figure \ref{fig:20vQoRDiv}) as compared to value of $\Delta$ yields by $MI$ property. The main reason for  this difference is  the truncated  (up to level 3) sensitive property profile of RBAC policy  used for the evaluation of the proposed heuristics.


\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/DI/30vDIDiv.eps}
        \caption{Discrimination Index  $DI$ with a problem size of 30 VMs  for LSD and  HSD datacenters.} 
        \label{fig:30vDIDiv}
        \vspace{-1.0em}
     \end{center}         
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/DI/150rDIDiv.eps}
        \caption{Discrimination Index  $DI$ with a problem size of 150 roles  for LSD and  HSD datacenters.} 
        \label{fig:150rDIDiv}
        \vspace{-2.0em}
     \end{center}         
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/MIRisk/20vRiskMI.eps}

        \caption{Mutual Information Risk $(RISK_{MI})$ with a problem size of 30 VMs  for LSD and HSD datacenters.} 
        \label{fig:20vRiskMI}
        \vspace{-1.0em}
     \end{center}         
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/MIRisk/70rRiskMI.eps}

        \caption{Mutual Information Risk $(RISK_{MI})$ with a problem size of 150 roles for LSD and HSD datacenters.} 
        \label{fig:70rRiskMI}
        \vspace{-2.0em}
     \end{center}         
\end{figure} 

\begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/Qor/20vQoRMI.eps}

        \caption{Quality of Risk-Reduction  $\Delta$ with a problem size of 30 VMs  for LSD, and HSD datacenters.} 
        \label{fig:20vQoRMI}
        \vspace{-2.0em}
     \end{center}         
\end{figure} 

 \begin{figure}[t!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/Qor/20vQoRDiv.eps}

        \caption{Quality of Risk-Reduction  $\Delta$ with a problem size of 30 VMs  for LSD, and HSD datacenters.} 
        \label{fig:20vQoRDiv}
        \vspace{-2.0em}
     \end{center}         
\end{figure}  

\begin{figure}[h!]
    \begin{center}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/MIRisk/20vDIMI.eps}

        \caption{Discrimination Index  $DI$ with a problem size of 30 VMs  for LSD and  HSD datacenters.} 
        \label{fig:20vDIMI}
        \vspace{-2.0em}
     \end{center}         
\end{figure} 

In Figure \ref{fig:20vDIMI}, we note that irrespective of the heuristic, the value of $DI$ for the case of \textit{HSD} is higher when $n=50$ as compared to $n=30$ and $n=70$. To elaborate on this behavior, we show the $PA_i$  histograms for all roles in these three  cases of RBAC policy ($n=30$, $n=50$, and $n=70$)  for HSD as well as for LSD. Figures \ref{fig:LSDAttackMI},  and \ref{fig:HSDAttackMI}  provide these histograms. We sort the roles based on their $PA_i$ from large to small. The behavior of $DI$ curve in Figure 6.17 can be explained within the context of $PA_i$'s as following. The histogram for HSD for the case of n=50 shows a sharp drop of $PA_i$'s and a "piece-wise uniform" clusters of $PA_i$'s.  If two roles belong to the same  uniform cluster  are assigned to different type of VMs (in terms of vulnerability), it is expected  to increase the $DI$ metric.  As noted from  Figure 6.19 the uniform clustering phenomenon is more pronounced for the case of $n=50$; it is less pronounced for the case of $n=30$; and it is negligible for the case $n=70$. This results in the convex shaped behavior of the $DI$ graph of the HSD case. Similarly, for the case of LSD, as can be noticed from Figure 6.18, the uniform cluster behavior $PA_i$   is more noticeable  for smaller values of $n$ ( n=30 and n=50) and is negligible for $n=70$. 

 

\begin{figure}[t!]
%trim option's parameter order: left bottom right top
    \begin{center}
        \subfloat[n=30, LSD datacenter]{\label{fig:30rLSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/LSD/30rLSDPA.eps}
        }
        \hskip 0.05truein

     \subfloat[n=50, LSD datacenter]{\label{fig:50rLSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/LSD/50rLSDPA.eps}

        }
        \hskip 0.05truein
            \subfloat[n=70, LSD datacenter]{\label{fig:70rLSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/LSD/70rLSDPA.eps}
        }
        \vspace{-1.0em}
        \caption{Attackability per role vs. $DI$ for LSD datacenter with mutual information sensitive property.}
\label{fig:LSDAttackMI}        
        \vspace{-2.0em}
       \end{center}         
\end{figure} 

\begin{figure}[h!]
%trim option's parameter order: left bottom right top
    \begin{center}
        \subfloat[n=30, HSD datacenter]{\label{fig:30rHSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/HSD/30rHSDPA.eps}
        }
        \hskip 0.05truein

     \subfloat[n=50, HSD datacenter]{\label{fig:50rHSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/HSD/50rHSDPA.eps}

        }
        \hskip 0.05truein
            \subfloat[n=70, HSD datacenter]{\label{fig:70rHSDPA}
        \includegraphics[width=0.4\textwidth]{fig/gnuplot/attack/HSD/70rHSDPA.eps}

        }

        \vspace{-1.0em}
        \caption{Attackability per role vs. $DI$ for HSD datacenter with mutual information sensitive property.}
\label{fig:HSDAttackMI}        
        \vspace{-2.0em}
       \end{center}         
\end{figure} 
