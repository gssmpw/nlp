In this section, we describe the risk associated with the data leakage that is caused by the assignment of access control roles to virtual resources in cloud datacenters. A statistical model of the access control policy with sensitive properties for cloud datacenters is introduced to control the assignment with the objective to reduce the risk of data leakage. 


%As illustrated in Figure \ref{fig:arch}, VRM consists of workload estimation, resource vulnerability estimation, and resource assignment components. The workload estimation component estimates the sharing of data among different roles of the access control policy. While the resource vulnerability estimation component of VRM uses security analysis tools \cite{balduzzi2012security} to estimate the virtual resource vulnerability. Subsequently, this component can be used to characterize a virtual resource with respect to different vulnerability security measurements  e.g. a highly secure or an insecure virtual resource. Finally, the resource assignment component uses the workload and vulnerability estimations to assign virtual resources to cloud customers application with a goal to minimize the total risk of data leakage.

%In addition, data leakage can be caused by other attacks like side-channel attack or Virtual Machine (VM) escape \cite{pearce2013virtualization}.

%In the next subsections we discuss a generalized model for RBAC policy and  provide a motivation example for the protection of the global knowledge/sensitive properties associated with data items in a cloud datacenter.


%\subsection{Global Knowledge and Security Challenges}
%In \cite{rekatsinas2013sparsi}, the authors have proposed the notion of sensitive properties to model implicit private information in the data set. Such private information can be inferred when analyzing a group of dependent data entries collectively. However, the quality of the disclosed private information associated with a subset of data entries degrades as some of the entries are restricted. An examples of sensitive property is the inference of social relation using check-in dataset \cite{cho2011friendship}. Another example of sensitive properties in check-in dataset, is the correlation between point of interest (POI) locations and the time of visit to these locations. The inference may be performed using statistical \cite{pham2013ebm}, or machine learning techniques \cite{cranshaw2010bridging}. The sensitive properties can be viewed as a form of global knowledge associated with the entire dataset that needs to be protected. 


%In this section, we provide a detailed discussion about the components in Figure \ref{fig:arch}.
%A role can access data either within an enterprise or across enterprises according to some Service Level Agreement (SLA)


\begin{figure}[t!]
%trim option's parameter order: left bottom right top
    \begin{center}
            \includegraphics[ width=0.5\textwidth]{fig/archeticture.pdf}
        \caption{Virtual resource management architecture.}
        \vspace{-2.0em}
        \label{fig:arch}
       \end{center}         
\end{figure} 


\begin{figure*}[t!]
%trim option's parameter order: left bottom right top
    \begin{center}
        \subfloat[Example of RBAC permission assignment.]{\label{fig:rbac}
        \includegraphics[trim = 2mm 50mm 2mm 50mm, clip, width=0.4\textwidth]{fig/converted/rbac.pdf}
        }
        \hskip 0.4truein
        \subfloat[Sensitive property profile of RBAC.]{\label{fig:lattice}
            \includegraphics[ clip, width=0.4\textwidth]{fig/kplattice.pdf}
        }
        \caption{RBAC policy representation.}
        \vspace{-2.0em}
       \end{center}         
\end{figure*} 


\subsection{Cloud Vulnerability and Data Leakage Risk Model}
We take the perspective of Platform as a Service (PaaS) that allows developers to deploy Big Data applications. Examples of such applications can be found in healthcare, e-government, and enterprises \cite{kim2014big}. Virtualization technology is used to ensure isolation of applications while allowing efficient utilization of the physical resources provided by a single or multiple Infrastructure as a Service (IaaS) providers, i.e., Amazon Elastic Cloud Computing (EC2). Shared physical resources are provisioned to VMs such that the Quality Of Service (QoS) guarantees are satisfied. The QoS guarantees provided to the cloud customers is often documented in the Service Level Agreement (SLA). VMs are used to wrap the provisioned applications PaaS customers. 

In multitenant datacenters, the confidentiality of shared data is preserved using access control mechanisms, e.g., RBAC policy, that control the operations on data \cite{alcaraz10}. Under RBAC policy, a user can perform an action on the shared data if the user is assigned a role and the role has the authorization to perform the action. In \cite{almutairi2012distributed}, a distributed access control architecture that assigns virtual resources to cloud customers is proposed. The assignment is performed such that the cost of provisioning for PaaS cloud providers is minimized while satisfying the SLA for each cloud customer. Figure \ref{fig:arch} provides a system view of the cloud architecture for the virtual resource management. It consists of the datastore, Virtual Resource Manager (VRM), and Access Control Module (ACM). VRM consists of workload estimation, virtual resource vulnerability estimation, and resource assignment components. In this paper, we adopt the proposed architecture in  \cite{almutairi2012distributed} in order to develop a risk-aware sensitive property-driven virtual resource assignment framework.

Information security risk is defined by ISO 27005 as the following: \textit{"The potential that a given threat will exploit vulnerability of an asset or group of assets and thereby cause harm to the organization"}. Accordingly, the risk is qualitatively expressed as the product of the likelihood of the attack and its impact \cite{djemame2016risk}. The likelihood of an attack depends on the vulnerabilities of the system and the attacker threat, while the impact of data leakage depends on the quality or quantity of the leaked data. Formally, the data leakage risk can be formulated as the following:
\begin{equation}
Risk = Vulnerability \times Threat \times Assets 
\label{eq:risk}
\end{equation}
In particular, the vulnerability is the probability of data leakage between virtual resources. There are many software vulnerabilities that can cause data leakage across tenants, e.g., VM escape, SQL injection, and cross-site scripting \cite{pearce2013virtualization}. Such vulnerabilities have different levels of criticality which are calculated based on the Common Vulnerability Scoring System (CVSS) scores \cite{grobauer2011understanding}. The probabilities of finding each of these vulnerabilities are estimated using statistical methods such as Vulnerability Discovery Models (VDMs) \cite{ristenpart2009hey}. Consequently, the vulnerability probability is weighted based on its criticality and used to find the overall probability of data leakage. We model the vulnerabilities among virtual resources as a vulnerability matrix $\mathcal{D}$, where $d_{ij}$ is the data leakage vulnerability between the $i$-th and $j$-th resources. To capture the worst-case scenario for risk assessment, we assume that the threat is equal 1 for all roles. In other words, each cloud customer poses the same threat in accessing other customers' data objects, and vice versa. The assets are the data stored in the cloud datastore. The value of the assets in Eq. \ref{eq:risk} can be the number of leaked data items \cite{almutairi2015risk}. In this paper, however, the value of the assets is quantified as the amount of information gained about the sensitive property as a result of the attack. We use information-theoretic measure to quantify such information gain. More discussion is provided in Section \ref{sec:SP}.



\subsection{Context-aware Role-Based Access Control}
RBAC policy defines permissions on objects based on employee roles in an organization. The policy configuration is composed of a set of Users ($U$), a set of Roles ($R$), a set of Permissions ($P$), a user-to-role assignment relation ($UA$), and a role-to-permission assignment relation ($PA$). In a cloud datacenter, the RBAC policy defines the permissions to access data objects for roles assumed by the cloud users \cite{ferraiolo2001proposed}. A leading practical example of using RBAC in cloud datacenters is Microsoft Azure, which uses RBAC to authorize access to its resources through the Azure Active Directory. In addition, Azure controls its data operations using RBAC for performing create/read/update/delete operations in SQL DB \cite{Azure}. Another example is Oracle Sales Cloud that uses RBAC to secure the access to its data and functionalities \cite{oracle}. RBAC policy is modeled as a bi-partite graph as the following:
\begin{definition}
 Given an RBAC policy $ \mathcal{P}$ for a datacenter where $R$ is the set of roles and given $O$ being the set of data objects,  the role-to-permission assignment $PA$ can be represented as a directed bipartite graph $G(V,E)$, where $V=R\cup O$ s.t. $R\cap O=\phi$. The edges $e_{r_i o_j}\in E$ in $G$ represents the existence of role-to-permission assignment $(r_i\times o_j)\in PA$  in the RBAC policy $\mathcal{P}$, where $r_i \in R$ and $o_j \in O$.
\end{definition}

The out-degree of a role vertex  represents the cardinality of the role and the in-degree of a data object vertex represents the degree of sharing of that object among roles. In Figure \ref{fig:rbac}, an RBAC policy with $|R|=4$ and $|O|=10$ is represented as bipartite graph model. We can notice that the cardinality of role $r_1$ is $out$-$degree(r_1) = 6$. Also, the degree of sharing of data object $o_{10}$ is $in$-$degree(o_{10}) = 4$.

CRBAC is proposed to capture context parameters, such as location and time, in the access control policy \cite{samuel2008context}. Accordingly, the assignment of permissions to users are based on the context in order to provide a comprehensive approach for security management. For example, CRBAC is used for spatial and temporal access control for mobile devices \cite{shebaro2015context}. Spatial extensions have also been proposed to RBAC. One such extension is GEO-RBAC that defines spatial roles. A spatial role can be assumed within a specified spatial boundary. However, GEO-RBAC specifies one spatial extent for each role, which implies that each spatial location in an organization needs to have its own role. The GST-RBAC \cite{Arjmand15} is proposed to express the spatial information as spatial constraints which can be attached to any role already existed in an access control policy. 


\subsection{Sensitive Property Profile (SPP) of RBAC}

In previous work, an alternative representation for RBAC, called Spectral Model (SM), is proposed \cite{almutairi2015risk}. In SM, data objects that are accessed by different roles is grouped into a set of non-overlapping partitions. Unlike the bipartite model, SM can be used to characterize the sensitivity of a datacenter using a single parameter, i.e., the degree of sharing among roles. An elaborated discussion about datacenter sensitivity will be provided in Section \ref{subsec:sens}. To model the information disclosure of each set of roles, we modify SM by augmenting the information disclosure of the sensitive property perceived by each set of roles and create the Sensitive Property Profile (SPP). Formally, the SPP is defined as follows:

\begin{definition}
Given a set of RBAC policy roles $R$ and its bipartite graph representation $G(V,E)$, let $\mathcal{P}(R)$ be the power set of $R$ excluding the null set  $\phi$. The sensitive property profile of the RBAC policy is the vector  $\mathcal{W}$, indexed by $\mathcal{P}(R)$ and lexicographically ordered. Formally, let $p \in \mathcal{P}(R)$ be a set of roles, then $w_p \in \mathcal{W}$ is defined as follows:
\begin{equation}
\begin{split}
&w_p= \{ C(w_p), c_1,\dots, c_{k} \} \nonumber
\end{split}
\end{equation}  
Where $C(w_p) = |\{o_k : o_k \in O | \forall r_i \in p \quad \exists  e_{r_i o_k} \in E \}$ is the cardinality of the set $w_p$ with $C(\mathcal{W}) = 2^n -1$, and $\{ c_1,\dots,c_k\}$ is a set of characteristics of $w_p$. There are no restrictions on the definition of the roles characteristics of the set of roles. However, it uniquely identifies the set $w_p$ from other sets.
\end{definition}  

In the following section, we provide detailed discussion about estimating the cardinality of each set $w_p$ in SPP. Then, we provide information-theoretic representations of the characteristics.

\subsection{Statistical Model for Cardinality Estimation of Roles}
\begin{algorithm}[t!]
\small
\SetNlSty{normal}{}{.}
\KwIn{Number of data objects ${|O|}$, number of roles $n$, constant$s$.}
\KwOut{spectral representation of RBAC $\mathcal{W}$.}
    Let $\mathcal{B} = \{B_1, \ldots, B_n\}$\  bucket array\; 
    \ForEach {$i = 1, \ldots, {|O|}$}{
       $\alpha$ = zipf($n$,$s$)\;
       $B_{\alpha}=B_{\alpha}+1$\;
    }
    \ForEach {$i = 1, \ldots, n$}{
%	Let $P= \{1,\dots,i\},\dots,\{1,\dots,n-i\},\dots,\{$\; 
     	\ForEach {$j = 1,\ldots, B_i$}{
		$\alpha$ = zipf(${n \choose i}$,$s$)\;
		map $\alpha$ to random partition in level $i$ call it $\hat{p}$\;
		$w_{\hat{p}}$ = $w_{\hat{p}}$ +1\;
	}
        add $w_{\hat{p}}$  to $\mathcal{W}$
    }
    return $\mathcal{W}$
   
\caption{Workload generation algorithm}

\label{alg:workload}
\end{algorithm}


In a datacenter with RBAC policy, specifying the exact cardinality of $w_p$ is a computationally intensive problem. One practical approach is to use a cardinality estimation technique \cite{zhang2009psalm}. In this paper, however, we assume that the data objects in a datacenter are accessed following a Zipfian distribution \cite{cooper2010benchmarking}. According to this distribution, the number of objects shared by roles exemplifies a power-law behavior, in which few objects are shared by a large number of roles while most of the objects are shared among a smaller number of roles; hence it can provide a heterogeneous workload for RBAC. The Zipfian distribution is given as follows:
\begin{equation}
\label{eq:zipf}
\begin{split}
&z(\alpha;s,N) = \frac{\alpha^{-s}}{\sum_{i=1}^N i^{-s}} \\
\end{split}
\end{equation}
where $N$ is the number of objects, $\alpha$ is the object rank, and $s \geq 1$ is the sensitivity parameter. If the sensitivity parameter $s=1$, then the probability that data object is assigned to a single role, i.e., with rank  $\alpha= 1$, is double the probability of that data object is assigned to two roles, i.e., with rank $\alpha =2$. As the value of $s$ increases, the number of data objects assigned to single roles becomes larger. 
%as shown in Figure \ref{fig:lattice_graph}. 

The Zipfian distribution is used to generate heterogeneous RBAC-based workload in two steps as proposed in Algorithm \ref{alg:workload}.  In the first step, data objects are classified into $n$ buckets where each bucket represents the number of total data objects assigned to a lattice level. For example, data objects in bucket 1 are exclusively  accessed by only one role.  On the other hand, data objects in bucket $n$ are shared by all roles.  The number of data objects in each bucket follow Zipfian distribution. In the second step, we assign data objects of bucket  $i$ to randomly selected partitions at level $i$ of the lattice. Note, the number of partitions at level $i$ is $n \choose i$. 


\subsubsection{Modeling Sensitivity of Cloud Datacenter}
\label{subsec:sens}
Based on the statistical property of the cardinality of roles in RBAC policy, we propose the notion of \textit{sensitivity} to classify cloud datacenters. The classification of cloud datacenters is dependent on the level of sharing of data objects among the roles. In particular, we define the sensitivity of a datacenter as the average degree of sharing among its data objects. In case the degree of sharing on average is low, we term the datacenter to have a \textit{high sensitivity}. On the contrary, if extensive sharing of data objects among roles is present, we term this datacenter to have a \textit{low sensitivity}. The \textit{medium sensitivity} class falls in the  middle. It can be noticed that the sharing of data objects and the classification of a datacenter can be modeled using the scalar parameter $s$ of the Zipfian density function shown in Equation \ref{eq:zipf}. As shown in Figure \ref{fig:lattice_graph}, for a smaller value of $s$, more data objects are uniformly distributed in the $\mathcal{W}$ vector of the spectral model of RBAC. In the following example, we illustrate how Zipfian parameter $s$ can be used to classify the sensitivity of datacenter. 

\begin{figure}[t!]
  \centering 
  %trim option's parameter order: left bottom right top
	\includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.5\textwidth]{fig/gnuplot/property/zip.eps}
  \caption{A statistical characterization of sensitivity of cloud datacenters}
  \vspace{-1.0em}
  \label{fig:lattice_graph}
\end{figure}

%For example in Figure \ref{fig:rbac}, the datacenter average degree of sharing equals to $\frac{10\times 1 + 4\times 2 + 8\times 3 + 2\times 4}{20} = 2.5$.

\begin{ex}
\label{ex:sensitivity}
For datacenter with $0.5 \times 10^6$ data objects, suppose we have three RBAC policies $(P_1,P_2,P_3)$ each with $n=30$ roles. Figure \ref{fig:lattice_graph} shows a histogram of object across the spectral lattice. Depending on the Zipfian distribution, the three classes of datacenters, namely; High Sensitive Datacenter (HSD), Medium Sensitive Datacenter (MSD), and Low Sensitive Datacenter (LSD), can be identified with respect to policies $P_1$, $P_2$, and $P_3$. For example, HSD has a large value of $s$  ($s \ge 2$) since the sharing of data objects among $P_1$ roles is very small. On other hand, LSD has a small value of $s$  ($1.5 > s \ge 1$) depicting the case of extensive sharing of data objects among roles of policy $P_3$. The MSD has a value of $s$ which falls in the  middle  ($2 > s \ge1.5$ ). Note, the number of data objects at level 1 in HSD is double the number of data objects at level 1 in LSD. 
\end{ex}  



\subsection{Information-Theoretic Modeling of Sensitive Properties}
\label{sec:SP}

In this section, we present information-theoretic measures to quantify the information gain of the data leakage. The measures are used to quantify the assets in Eq. \ref{eq:risk}. The VRM component of Figure \ref{fig:arch} uses SPP to assign the RBAC policy roles to virtual resources. In essence, a function $f(.)$ that quantifies the disclosure of the global sensitive property is used along with the cardinality to characterize the set of roles. The function $f: \mathcal{P}(R) \rightarrow \mathbb{R}$ is a quantitative measure of the relative difference between the global sensitive property and local sensitive property obtained by accessing data according to the role set $A \in \mathcal{P}(R)$. In this paper, we consider two information-theoretic measures to model sensitive properties; Kullback-Leibler divergence ($KLD$) and Mutual Information ($MI$)  \cite{cover2012elements}. An important measure in information-theory is Entropy, which is the measure of \textit{uncertainty} in probability distributions. Let X be a random variable with probability distribution $P(X)$. The entropy $H(X)$ is defined as the following:
\begin{equation*}
H(X) = - \underset{x \in X}{\sum} p(x) \ \text{log} \ p(x)
\end{equation*}
 
\subsubsection{$KLD$-based Representation of Sensitive Property}

Given two discrete pmfs, $P(X)$ and $Q(X)$, $KLD$ is a non-symmetric measure of the difference between these two pms. Intuitively, $KLD$ measures the amount of information loss when $Q$ is used to approximate $P$. Formally, $KLD$ between two pmfs as the following:
\begin{equation*}
D(P||Q) = \sum_{x \in X} P(x) \  \text{log} \ \frac{P(x)}{Q(x)}
\end{equation*}

%{\color{red}
%\begin{ex}
%Let X and Y be two discrete random variables where X=$\{ 0,1\}$ and Y=$\{ 0,1\}$. Let $P(X,Y)$ be a uniform joint probability distribution, i.e., $p(x,y) = 0.25 \ ,\forall x \in X, \forall y \in Y$. Assume that an approximate distribution $Q(X,Y)$ is defined such that the probability of $X=Y$ is twice as the probability of $X \neq Y$, i.e. $P(X=0,Y=0) = P(X=1,Y=1) = 2P(X=1,Y=0) = 2P(X=0,Y=1)$. The KL divergence is $D(P||Q) = 0.1$. 
%\label{ex:div}
%\end{ex}
%}

Using the definition of $KLD$, we define $KLD$-based property as the following:
\begin{equation}
f(A) = D(P_A || P_G)
\label{eq:f_div}
\end{equation}
Where $P_A$ is the joint probability distribution defined over data accessed by the set of roles $A$ and $P_G$ is the joint probability distribution over the entire dataset.

\begin{ex}
In Figure \ref{fig:lattice}, the general spectral model of the RBAC policy using $KLD$-based property is shown. It can be noticed that $w_{\{1,4\}} =\{ 2,0.4\}$, i.e., the cardinality of $w_{\{1,4\}}$ is 2 because $o_5$ and $o_{6}$ are accessed by both $r_1$ and $r_4$, while $f(w_{\{1,4\}})=0.4$ indicates that the probability distribution created using tuples $o_5$ and $o_6$ has a 0.4 KL divergence from the probability distribution created using $O$.  
\end{ex}

%%%%%%%%% add this somewhere %%%%%%%%%%%%
%For the above example,  the divergence of the p.m.f. associated with data subset  $D_1$ and p.m.f. of global data set is  0.121 while the divergence in the case of $D_2$ is 0.003. \textit{Increasing the size of the accessed dataset can result in reducing the divergence from the global p.m.f.} In this particular example, accessing a little more than 50\% of data almost yield the same p.m.f. as for the  entire dataset. 
%Note,  this sensitive property ($Div$) represents the inference function $f$  as per Definition \ref{def:SPRAP}.



\subsubsection{$MI$-based Representation of Sensitive Property}
$MI$ is a measure that quantifies the dependency between two or more random variables. Intuitively, it measures the reduction of entropy in one random variable by observing the other. Formally, mutual information is the divergence between the joint pmf of two random variables and the product of their respective pmfs as defined below:
\begin{eqnarray*}\label{eq:mi}
MI(X;Y) &= &D(P(X,Y)||P(X)P(Y))\\
&=& \sum_{x \in X}\sum_{y \in Y} p(x,y) \text{log}\frac{p(x,y)}{p(x)p(y)}\\
& = & H(X) - H(X|Y)\\	
\end{eqnarray*}
It can be shown that the $MI$ approaches zero when the two random variables are independent, i.e., $H(X|Y) = H(X)$. On the other hand, strong dependency between $X$ and $Y$ results in a higher value of $MI$. 

Using the definition of $MI$, we define $MI$-based property as the following:
\begin{equation}
f(A) = |MI_A(X;Y) - MI_G(X;Y)|
\label{eq:f_mi}
\end{equation}
Where $MI_A(X,Y)$ is the mutual information between $X$ and $Y$ defined over data accessed by the set of roles $A$, and $MI_G(X,Y)$ is the mutual information between $X$ and $Y$ defined over the entire data set.


%
%We now define the Attackability (AT) of a spectral partition. Attackability measures the maximum amount data that the adversaries (roles) can potentially access in an unauthorized manner. Formally, this parameter is defined as follows.
%
%\begin{definition}
%  Given spectral representation of access control $\mathcal{W}$, the Attackability of  $ w_p \in \mathcal{W}$ is:\\
%  $AT(w_p) = w_p \times (n-|p|)$
%  \end{definition}
%
%\begin{ex}
%In Figure \ref{fig:lattice}, the Attackability for $w_{\{2\}}$ and $w_{\{1,2,4\}}$ is as follows:\\
%\begin{math}
%\label{eq:AT}
%AT(w_{\{2\}} )= 2 \times 3 = 6; \quad AT(w_{\{1,2,4\}}) = 1 \times 1 = 1
%\end{math}
%\end{ex}
%
%We can notice that as more roles have access permissions of a partition, its Attackability decreases. 
%Note, that in the spectral representation of RBAC, the tuples with highest $AT$ belong to a partition in level $\frac{n}{2}$.





%%%%%%%%%%%%%%% add this somewhere %%%%%%%%%%%%%%%
%In our experiments, we use $MI$ as an indicator of the quality of the dataset in accurately capturing the dependency between the random variables $X$ and $Y$. For our example, the entropy of X in the check-in dataset is $-\underset{x \in X}{\sum} p(x) log (p(x))= 0.913$ and the mutual information at the global level is $MI_G = 0.005$. In other words, knowing the value of $Y$ can improve the uncertainty about X to $0.913-0.005 = 0.908$. The mutual information of $D_1$ and $D_2$ are $MI_{D_1} = 0.017$ and $MI_{D_2} = 0.007$, respectively. 
%
%Note,  this sensitive property ($MI$) represents the inference function $f$ as per Definition \ref{def:SPRAP}.
%\begin{figure}[h!]
%\centering
%\subfloat[MI profile]{\includegraphics[width=\linewidth]{fig/profile/10rLSDMI-profile.pdf}\label{fig:10rMIProfile}}
%\newline
%\centering
%\subfloat[Div profile]{\includegraphics[width=\linewidth]{fig/profile/10rLSDDiv-profile.pdf}\label{fig:10rDivProfile}}
%\caption{Maximum, minimum, and average of sensitive property profile  with size of 10 roles.} 
%\label{fig:10profile}
%\end{figure}
%
%
%
%\begin{figure}[h!]
%\centering
%\subfloat[MI profile]{\includegraphics[width=\linewidth]{fig/profile/20rLSDMI-profile.pdf}\label{fig:20rMIProfile}}
%\newline
%\centering
%\subfloat[Div profile]{\includegraphics[width=\linewidth]{fig/profile/20rLSDDiv-profile.pdf}\label{fig:20rDivProfile}}
%\caption{Maximum, minimum, and average of sensitive property profile  with size of 20 roles with cutoff at 10.} 
%\label{fig:20profile}
%\end{figure}




%\begin{figure*}[h!]
%%trim option's parameter order: left bottom right top
%    \begin{center}
%        \subfloat[MI profile]{\label{fig:MIProfile}
%        \includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.75\textwidth]{ch6/fig/profile/20rHSDMI-profile.pdf}
%        }
%        \hskip 0.1truein
%        \subfloat[Div profile]{\label{ch6:fig:DivProfile}
%            \includegraphics[trim = 0mm 0mm 0mm 0mm, clip, width=0.75\textwidth]{ch6/fig/profile/20rHSDDiv-profile.pdf}
%        }
%    	\caption{Maximum, minimum, and average of sensitive property profile  with size of 20 roles with cutoff 10.}
%        \label{ch6:fig:profile}
%        \vspace{-2.0em}
%       \end{center}         
%\end{figure*}


%%%%%%%%% To be added somewhere %%%%%%%%%%%%
%In Figures \ref{fig:10profile}, and \ref{fig:20profile}, we depict  profiles of the two sensitive properties $MI$ and $Div$ which are associated with check-in dataset \cite{cho2011friendship} by assuming an CC-RBAC policy with 10 and 20 roles for LSD and HSD. The max (min) plot represents the maximum (minimum) values of inference function associated with these properties at any given level of the lattice. The average is taken over all nodes at a given level of the knowledge profile lattice $\mathcal{P}(R)$ associated with RBAC policy. We can note that both sensitive properties converge to the global knowledge as number of level increases in the lattice. The reason is that  increasing the level (number of roles) used  to infer the knowledge results in reducing the error in the estimation of sensitive property. The convergence is more pronounced for \textit{Div} profile as compared to \textit{MI} profile.  These profiles provide an insight into the performance of the scheduling heuristics as discussed later in this paper.






%One limitation of the mutual information is that it gives an average quantification of dependency over all values of both random variables. For some applications, it is important to know which values have the most contribution to the global information. One way is to decompose mutual information into its non-negative components known as \textit{j-measure}, or $I_1(x,Y)$\cite{see the end of document}, 
%\begin{equation*}
%MI_1(x,Y) = \sum_{y \in Y} p(y|x) log_2 \frac{p(y|x)}{p(y)}
%\end{equation*}
%
%This quantity measures the deviation between the conditional probability distribution $p(y|x)$ and the marginal distribution $p(y)$. It is clearly averages to the mutual information, i.e., $\underset{x \in X}{\sum} p(x) MI_1(x;Y) = MI(X;Y)$. To illustrate the j-measure, Figure \ref{fig:py} show the the probability of Y while Figure \ref{fig:py_x} show the conditional probability $p(y|x)$ for all $x \in X$. Figure \ref{fig:jm} depict the j-measure for all $x \in X$. Large values of j-measure, for example when X=4, means that $p(Y|x=4)$ diverges from $p(Y)$ which indicates that knowing the values of $X$ improves the information gained about $Y$. On the other hand, small values of j-measure, for example X=7, indicates that the divergence is small and hence knowing the value of $X$ does not provide much information about $Y$. Figure \ref{fig:comp} show the j-measure components of the mutual information of the entire dataset, $D_1$, and $D_2$. Is it clearly shown that $X=15$ is an essential factor of the difference between the global and $D_1$'s mutual information which can be explained by the zero probability of $x=15$ in $D_1$ for $y=1$.
%
%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.5]{Ch6/fig/property/py.png}
%\caption{Probability plot of $p(y)$}
%\label{fig:py}
%\end{figure}
%
%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.5]{Ch6/fig/property/py_x.png}
%\caption{Probability plot of p$(y|x)$}
%\label{fig:py_x}
%\end{figure}
%
%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.5]{Ch6/fig/property/j-meas.png}
%\caption{Probability plot of p$(y|x)$}
%\label{fig:jm}
%\end{figure}
%
%\begin{figure}[h!]
%\centering
%\includegraphics[scale=0.9]{Ch6/fig/property/comp.png}
%\caption{J-measure Components of Global, $D_1$, and $D_2$}
%\label{fig:comp}
%\end{figure}
%
%

