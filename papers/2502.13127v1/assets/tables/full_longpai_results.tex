\begin{table*}[t]
\small
\centering  
\renewcommand{\arraystretch}{1}
\resizebox{\textwidth}{!}{
\begin{tabular}{llcccccccccc}
\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{Context}} & \multicolumn{2}{c}{\textbf{Spotlight Locating}} & \multicolumn{2}{c}{\textbf{Comparison}} & \multicolumn{2}{c}{\textbf{Clustering}} & \multicolumn{2}{c}{\textbf{Chain of Reasoning}} & \multicolumn{2}{c}{\textbf{Overall}}\\ \cmidrule(r){3-4} \cmidrule(r){5-6} \cmidrule(r){7-8} \cmidrule(r){9-10} \cmidrule(r){11-12}
 & \multicolumn{1}{c}{\textbf{Length}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} \\

\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textbf{$\mathtt{All\ Set}$ (10K-250K)}}  \\
DeepSeek-R1-Qwen-32B & 128K &  53.66 & 0.46 & 52.19 & 0.39 & 39.76 & 0.17 & 65.15 & 0.51 & 49.92 & 0.34 \\
Qwen2-72B-Instruct & 128K &  59.80 & 0.47 & 61.12 & 0.43 & 34.32 & 0.06 & 74.68 & 0.50 & 53.20 & 0.32  \\
Qwen2.5-72B-Instruct & 128K &  71.07 & 0.63 & 59.14 & 0.41 & 38.23 & 0.08 & 81.09 & 0.60 & 57.36 & 0.36  \\
LLaMA-3-8B-Instruct-262K & 262K  &  58.60 & 0.41 & 33.12 & 0.16 & 20.04 & 0.01 & 35.10 & 0.09 & 34.41 & 0.15 \\
GLM4-9B-Chat & 1000K & 72.69 & 0.60 & 49.31 & 0.32 & 23.41 & 0.02 & 60.77 & 0.28 & 46.71 & 0.27 \\
Qwen-2.5-14B-Instruct-1M & 1000K & 78.83 & 0.72 & 65.27 & 0.50 & 36.24 & 0.07 & 79.10 & 0.64 & 59.78 & 0.41 \\
GPT-4o & 128K &  88.23 & 0.84 & 62.90 & 0.48 & 45.51 & 0.17 & 69.40 & 0.43 & 63.05 & 0.44 \\
GPT-4o-mini (Base) & 128K & 70.90 & 0.59 & 59.37 & 0.38 & 36.33 & 0.06 & 79.58 & 0.58 & 56.50 & 0.34 \\
GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{mygreen}91.07 & \cellcolor{mygreen}0.83 & \cellcolor{mygreen}74.40 & \cellcolor{mygreen}0.58 & \cellcolor{mygreen}61.55 & \cellcolor{mygreen}0.32 & \cellcolor{mygreen}89.63 & \cellcolor{mygreen}0.78 & \cellcolor{mygreen}75.56 & \cellcolor{mygreen}0.57 \\
\midrule
LLaMA-3.1-8B-Instruct (Base) & 128K & 67.84 & 0.56 & 47.12 & 0.30 & 24.62 & 0.02 & 63.63 & 0.34 & 45.88 & 0.26 \\ 
LongPAI (\textit{ours}) & 262K & \cellcolor{mygreen}87.02 & \cellcolor{mygreen}0.78 & \cellcolor{mygreen}64.50 & \cellcolor{mygreen}0.48 & \cellcolor{mygreen}60.95 & \cellcolor{mygreen}0.32 & \cellcolor{mygreen}81.89 & \cellcolor{mygreen}0.71 & \cellcolor{mygreen}70.54 & \cellcolor{mygreen}0.52 \\ 



\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textbf{$\mathtt{Set1}$ (10K-50K)}}  \\
DeepSeek-R1-Qwen-32B & 128K &  41.73 & 0.33 & 39.56 & 0.23 & 25.67 & 0.06 & 55.14 & 0.37 & 37.35 & 0.21 \\
Qwen2-72B-Instruct & 128K &  88.04 & 0.83 & 89.33 & 0.83 & 43.00 & 0.17 & 93.50 & 0.80 & 71.46 & 0.57  \\
Qwen2.5-72B-Instruct & 128K &  88.70 & 0.87 & 84.67 & 0.80 & 43.92 & 0.10 & 88.00 & 0.80 & 70.07 & 0.54  \\
LLaMA-3-8B-Instruct-262K & 262K  &  75.82 & 0.64 & 40.83 & 0.23 & 20.68 & 0.03 & 68.00 & 0.40 & 43.14 & 0.25 \\
GLM4-9B-Chat & 1000K & 88.26 & 0.83 & 73.17 & 0.57 & 24.65 & 0.00 & 87.30 & 0.50 & 59.07 & 0.40 \\
Qwen-2.5-14B-Instruct-1M & 1000K &  96.09 & 0.96 & 88.67 & 0.80 & 49.00 & 0.20 & 100.00 & 1.00 & 76.02 & 0.62 \\
GPT-4o & 128K &  100.00 & 1.00 & 88.50 & 0.80 & 55.25 & 0.28 & 98.50 & 0.90 & 79.13 & 0.65 \\
GPT-4o-mini (Base) & 128K & 97.39 & 0.96 & 81.83 & 0.67 & 46.50 & 0.15 & 100.00 & 1.00 & 73.35 & 0.56 \\
GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{myred}95.87 & \cellcolor{myred}0.91 & \cellcolor{mygreen}91.50 & \cellcolor{mygreen}0.83 & \cellcolor{mygreen}78.38 & \cellcolor{mygreen}0.60 & \cellcolor{myred}96.80 & \cellcolor{myred}0.70 & \cellcolor{mygreen}87.89 & \cellcolor{mygreen}0.75 \\
\midrule
LLaMA-3.1-8B-Instruct  (Base) & 128K & 89.13 & 0.87 & 72.33 & 0.60 & 31.77 & 0.05 & 74.00 & 0.60 & 60.50 & 0.45 \\ 
LongPAI (\textit{ours}) & 262K & \cellcolor{myred}85.00 & \cellcolor{myred}0.74 & \cellcolor{mygreen}90.00 & \cellcolor{mygreen}0.83 & \cellcolor{mygreen}69.12 & \cellcolor{mygreen}0.47 & \cellcolor{mygreen}98.30 & \cellcolor{mygreen}0.80 & \cellcolor{mygreen}81.58 & \cellcolor{mygreen}0.67 \\

\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textbf{$\mathtt{Set2}$ (50K-100K)}}  \\
DeepSeek-R1-Qwen-32B & 128K &  41.73 & 0.33 & 39.56 & 0.23 & 25.67 & 0.06 & 55.14 & 0.37 & 37.35 & 0.21 \\
Qwen2-72B-Instruct & 128K &  74.88 & 0.65 & 68.60 & 0.51 & 40.70 & 0.09 & 87.00 & 0.72 & 62.38 & 0.41  \\
Qwen2.5-72B-Instruct & 128K &  86.00 & 0.82 & 61.64 & 0.41 & 46.94 & 0.16 & 93.12 & 0.85 & 65.36 & 0.46  \\
LLaMA-3-8B-Instruct-262K & 262K  &  72.44 & 0.54 & 44.03 & 0.26 & 24.11 & 0.02 & 37.25 & 0.12 & 40.40 & 0.20 \\
GLM4-9B-Chat & 1000K & 82.12 & 0.68 & 52.73 & 0.36 & 26.04 & 0.04 & 76.83 & 0.42 & 51.66 & 0.31 \\
Qwen-2.5-14B-Instruct-1M & 1000K &  88.75 & 0.85 & 74.07 & 0.61 & 39.06 & 0.09 & 96.38 & 0.90 & 67.24 & 0.51 \\
GPT-4o & 128K &  95.75 & 0.95 & 72.87 & 0.57 & 54.94 & 0.27 & 73.38 & 0.47 & 70.10 & 0.51 \\
GPT-4o-mini  (Base) & 128K & 82.65 & 0.70 & 58.77 & 0.41 & 40.89 & 0.08 & 92.50 & 0.78 & 61.61 & 0.40 \\
GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{mygreen}89.38 & \cellcolor{mygreen}0.85 & \cellcolor{mygreen}70.73 & \cellcolor{mygreen}0.51 & \cellcolor{mygreen}64.37 & \cellcolor{mygreen}0.36 & \cellcolor{mygreen}94.62 & \cellcolor{mygreen}0.90 & \cellcolor{mygreen}75.34 & \cellcolor{mygreen}0.57 \\
\midrule
LLaMA-3.1-8B-Instruct (Base) & 128K & 80.58 & 0.70 & 51.11 & 0.33 & 27.39 & 0.02 & 75.12 & 0.47 & 51.13 & 0.30 \\ 
LongPAI (\textit{ours}) & 262K & \cellcolor{mygreen}92.88 & \cellcolor{mygreen}0.88 & \cellcolor{mygreen}69.40 & \cellcolor{mygreen}0.56 & \cellcolor{mygreen}67.57 & \cellcolor{mygreen}0.42 & \cellcolor{mygreen}87.38 & \cellcolor{mygreen}0.80 & \cellcolor{mygreen}75.49 & \cellcolor{mygreen}0.60\\ 

\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textbf{$\mathtt{Set3}$ (100K-200K)}}  \\
DeepSeek-R1-Qwen-32B & 128K &  41.73 & 0.33 & 39.56 & 0.23 & 25.67 & 0.06 & 55.14 & 0.37 & 37.35 & 0.21 \\
Qwen2-72B-Instruct & 128K &  47.00 & 0.33 & 48.07 & 0.27 & 25.79 & 0.00 & 69.37 & 0.34 & 42.98 & 0.20  \\
Qwen2.5-72B-Instruct & 128K &  60.47 & 0.48 & 49.00 & 0.28 & 30.61 & 0.01 & 76.54 & 0.46 & 48.99 & 0.26  \\
LLaMA-3-8B-Instruct-262K & 262K  &  54.14 & 0.40 & 22.93 & 0.05 & 15.43 & 0.00 & 29.00 & 0.00 & 28.58 & 0.11 \\
GLM4-9B-Chat & 1000K & 74.75 & 0.65 & 41.63 & 0.24 & 21.99 & 0.01 & 49.86 & 0.17 & 43.58 & 0.25 \\
Qwen-2.5-14B-Instruct-1M & 1000K &  74.33 & 0.68 & 54.64 & 0.35 & 30.72 & 0.01 & 73.71 & 0.51 & 53.47 & 0.33 \\
GPT-4o & 128K &  87.25 & 0.83 & 46.00 & 0.31 & 36.68 & 0.08 & 64.57 & 0.40 & 54.79 & 0.36 \\
GPT-4o-mini (Base) & 128K & 63.05 & 0.53 & 53.48 & 0.24 & 29.80 & 0.01 & 72.37 & 0.46 & 50.03 & 0.26 \\
GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{mygreen}94.08 & \cellcolor{mygreen}0.83 & \cellcolor{mygreen}74.13 & \cellcolor{mygreen}0.63 & \cellcolor{mygreen}55.78 & \cellcolor{mygreen}0.20 & \cellcolor{mygreen}87.71 & \cellcolor{mygreen}0.77 & \cellcolor{mygreen}74.21 & \cellcolor{mygreen}0.55\\
\midrule
LLaMA-3.1-8B-Instruct (Base) & 128K & 63.38 & 0.47 & 36.04 & 0.19 & 20.28 & 0.00 & 62.49 & 0.26 & 40.45 & 0.20 \\ 
LongPAI (\textit{ours}) & 262K & \cellcolor{mygreen}88.00 & \cellcolor{mygreen}0.80 & \cellcolor{mygreen}50.07 & \cellcolor{mygreen}0.28 & \cellcolor{mygreen}55.01 & \cellcolor{mygreen}0.21 & \cellcolor{mygreen}84.03 & \cellcolor{mygreen}0.69 & \cellcolor{mygreen}65.10 & \cellcolor{mygreen}0.43 \\ 


\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textbf{$\mathtt{Set4}$ (200K-250K)}}  \\
DeepSeek-R1-Qwen-32B & 128K &  18.33 & 0.11 & 10.25 & 0.05 & 11.27 & 0.00 & 26.00 & 0.07 & 15.52 & 0.05 \\
Qwen2-72B-Instruct & 128K &  41.85 & 0.19 & 39.75 & 0.15 & 29.17 & 0.03 & 41.67 & 0.07 & 37.23 & 0.11  \\
Qwen2.5-72B-Instruct & 128K &  57.48 & 0.44 & 49.50 & 0.30 & 27.33 & 0.00 & 55.00 & 0.13 & 45.51 & 0.22  \\
LLaMA-3-8B-Instruct-262K & 262K  &  34.19 & 0.07 & 20.00 & 0.05 & 20.31 & 0.00 & 20.71 & 0.00 & 24.61 & 0.03 \\
GLM4-9B-Chat & 1000K & 40.85 & 0.19 & 29.50 & 0.05 & 18.13 & 0.00 & 25.73 & 0.00 & 28.51 & 0.07 \\
Qwen-2.5-14B-Instruct-1M & 1000K &  59.44 & 0.41 & 37.00 & 0.20 & 27.33 & 0.00 & 31.67 & 0.00 & 39.57 & 0.16 \\
GPT-4o & 128K &  69.26 & 0.56 & 50.50 & 0.35 & 30.70 & 0.00 & 50.67 & 0.07 & 49.58 & 0.25 \\
GPT-4o-mini (Base) & 128K & 48.37 & 0.26 & 50.00 & 0.30 & 28.70 & 0.00 & 48.33 & 0.07 & 42.30 & 0.15 \\
GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{mygreen}82.78 & \cellcolor{mygreen}0.70 & \cellcolor{mygreen}63.50 & \cellcolor{mygreen}0.35 & \cellcolor{mygreen}48.00 & \cellcolor{mygreen}0.17 & \cellcolor{mygreen}76.00 & \cellcolor{mygreen}0.53 & \cellcolor{mygreen}66.14 & \cellcolor{mygreen}0.42\\
\midrule
LLaMA-3.1-8B-Instruct (Base) & 128K & 40.74 & 0.30 & 35.85 & 0.20 & 19.77 & 0.00 & 28.73 & 0.00 & 30.88 & 0.13 \\ 
LongPAI (\textit{ours})  & 262K & \cellcolor{mygreen}77.89 & \cellcolor{mygreen}0.63 & \cellcolor{mygreen}62.00 & \cellcolor{mygreen}0.45 & \cellcolor{mygreen}48.00 & \cellcolor{mygreen}0.17 & \cellcolor{mygreen}51.33 & \cellcolor{mygreen}0.47 & \cellcolor{mygreen}60.36 & \cellcolor{mygreen}0.41 \\ 

\bottomrule
\end{tabular}
}
\caption{Full results of Table~\ref{tab:longpai_results}. \textit{AS} represents \textit{Avg Scores (0\textasciitilde100)} and \textit{{PR}} denotes \textit{Perfect Rate} (0\textasciitilde1). \colorbox{mygreen}{Green} indicates improvements compared to the base model; \colorbox{myred}{Red} denotes a decrease compared to the base model.}
\label{tab:full_longpai_results}
\end{table*}