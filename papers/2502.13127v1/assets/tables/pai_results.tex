\begin{table*}[t]
\centering  
\caption{Data quality assessment for the long-context synthetic dataset (\textit{LongFinanceQA}) by measuring the performance of PAI on the Loong benchmark. \textit{AS} denotes \textit{Average Scores (0-100)}, and \textit{{PR}} represents the \textit{Perfect Rate} (0-1). \colorbox{mygreen}{Green} highlights the remarkable improvements over the base model (GPT-4o-mini).}\label{tab:pai_results}\vspace{-3mm}
\renewcommand{\arraystretch}{0.93}
\resizebox{\textwidth}{!}{
\begin{tabular}{llcccccccccc}
\toprule
\multirow{2}{*}{\textbf{Model}} & \multicolumn{1}{c}{\textbf{Context}} & \multicolumn{2}{c}{\textbf{Spotlight Locating}} & \multicolumn{2}{c}{\textbf{Comparison}} & \multicolumn{2}{c}{\textbf{Clustering}} & \multicolumn{2}{c}{\textbf{Chain of Reasoning}} & \multicolumn{2}{c}{\textbf{Overall}}\\ \cmidrule(r){3-4} \cmidrule(r){5-6} \cmidrule(r){7-8} \cmidrule(r){9-10} \cmidrule(r){11-12}
 & \multicolumn{1}{c}{\textbf{Length}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} & \textbf{\textit{AS}} & \textbf{\textit{PR}} \\

\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textit{Open-Source Long-Context Large Language Models}}  \\
LLaMA-3.1-8B-Instruct & 128K & 62.42 & 0.52 & 39.13 & 0.21 & 25.96 & 0.01 & 44.20 & 0.22 & 38.79 & 0.18 \\ 
DeepSeek-R1-Qwen-32B & 128K & 51.68 & 0.41 & 49.25 & 0.34 & 41.53 & 0.16 & 45.00 & 0.30 & 45.45 & 0.27 \\ 
Qwen2-72B-Instruct & 128K & 54.17 & 0.36 &42.38 & 0.20 & 36.71 & 0.04 & 47.76 & 0.18 & 43.29 & 0.15 \\ 
Qwen2.5-72B-Instruct & 128K & 65.08 & 0.55 & 51.90 & 0.30 & 46.07 & 0.08 & 64.43 & 0.40 & 54.83 & 0.28  \\ 
% LLaMA-3-8B-Instruct-262K & 262K & 48.77 & 0.30 & 29.33 & 0.11 & 19.93 & 0.01 & 21.27 & 0.07 & 27.52 & 0.10 \\ 
% GLM4-9B-Chat & 1000K & 57.35 & 0.47 & 40.38 & 0.20 & 28.52 & 0.02 & 39.94 & 0.16 & 38.31 & 0.16\\ 
Qwen2.5-14B-Instruct-1M & 1000K &  67.50 & 0.58 & 55.12 & 0.35 & 39.05 & 0.04 & 57.81 & 0.31 & 51.30 & 0.25  \\ 

\midrule
\multicolumn{12}{>{\columncolor[gray]{.88}}c}{\textit{Closed-Source Long-Context Large Language Models}}  \\

Kimi-Chat & 200K & 60.98 & 0.50 & 34.74 & 0.13 & 28.76 & 0.04 & 38.52 & 0.15 & 37.49 & 0.16 \\

% Claude3-Haiku & 200K & 68.68 & 0.59 & 42.10 & 0.21 & 35.04 & 0.02 & 47.59 & 0.17 & 44.88 & 0.19\\

Claude3.5-Sonnet & 200K & 58.45 & 0.49 & 54.21 & 0.35 & 45.77 & 0.07 & 43.92 & 0.25 & 48.85 & 0.23\\

GPT-4o & 128K & 73.95 &0.62 & 50.50 &0.28 &44.29 &0.09 &57.95 &0.28 &53.47 &0.26 \\

Gemini-1.5-pro & 1000K & 75.02 & 0.56 & 49.94 & 0.27 & 44.10 & 0.09 & 64.97 & 0.37 & 55.37 & 0.27 \\


\midrule
GPT-4o-mini (Base) & 128K & 59.46 & 0.49 & 51.90 & 0.27 & 34.55 & 0.04 & 64.28 & 0.39 & 49.25& 0.24 \\

GPT-4o-mini w/ PAI (\textit{ours}) & 128K & \cellcolor{mygreen}{\textbf{79.74}} & \cellcolor{mygreen}\textbf{0.67} & \cellcolor{mygreen}\textbf{67.60} & \cellcolor{mygreen}\textbf{0.46} & \cellcolor{mygreen}\textbf{62.80} & \cellcolor{mygreen}\textbf{0.27} & \cellcolor{mygreen}\textbf{75.46} & \cellcolor{mygreen}\textbf{0.57} & \cellcolor{mygreen}\textbf{69.58} & \cellcolor{mygreen}\textbf{0.44} \\
% \midrule
% LLaMA-3.1-8B-Instruct & 128K & 62.42 & 0.52 & 39.13 & 0.21 & 25.96 & 0.01 & 44.20 & 0.22 & 38.79 & 0.18\\ 
% \hspace{4mm} FT on LongFinance w/o Reasoning & 256K &  &  &  &  &  &  &  &  &  &  \\
% \hspace{4mm} FT on LongFinance w/ Reasoning & 256K &  &  &  &  &  &  &  &  &  &  \\
\bottomrule
\end{tabular}
}\vspace{-3mm}
\end{table*}