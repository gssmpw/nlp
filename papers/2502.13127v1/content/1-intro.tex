\section{Introduction} \label{sec:intro}
\vspace{-2mm}

\input{assets/figures/length_score}

% bg: Long context understanding is challenging and important.
Long context understanding remains an evolving challenge~\cite{kocisky2018narrativeqa,wu2021recursively,bai2024longbench,wang2024leave} in natural language processing (NLP). 
Achieving long-context understanding requires processing long-form textual information, thereby enhancing a modelâ€™s ability to generate coherent, accurate, and contextually relevant responses~\cite{ibm2024llmcontext}.
Practical long context understanding has a potential impact on numerous applications, such as private document analysis~\cite{mukherjee2023feasibility}, large codebase understanding~\cite{nam2024using}, and multimodal content understanding~\cite{chandrasegaran2024hourvideo,lin2023videoxum,tang2023video,chen2023fine}.
Recent advancements in large language models~\cite{ouyang2022training,reid2024gemini,dubey2024llama} have significantly extended the input sequence length, ranging from 2K to 2M tokens, as shown in Figure~\ref{fig:trend} in Appendix \ref{sec:appendix}.

%% limitation
However, simply increasing the input sequence length does not necessarily improve the ability to comprehend the long content~\cite{yang2024qwen2,goldman2024really}. In particular, Figure~\ref{fig:length_score} presents the performance of various long-context LLMs on the Loong benchmark~\cite{wang2024leave}. The results suggest that, regardless of the maximum sequence length models can process, their performance remains similar, typically between 45\% and 55\%. This phenomenon exposes a hype that despite considerably enlarging context window size, the state-of-the-art LLMs still fail to perform satisfactorily in practical long-context problem-solving tasks.
%% Motivation
Therefore, instead of merely increasing the input sequence length, achieving effective long-context understanding remains an open challenge.

In parallel with advanced long-context architectures and techniques~\cite{peng2024yarn,liu2024ringattention,dao2024transformers}, constructing high-quality long-context training data remains essential yet underexplored.
Given the scarcity and high annotation costs of long-context data, generating high-quality synthetic data for long-context modeling is valuable and urgent. Early attempts~\cite{raffel2020exploring,fu2024data} simply pack all short-length data into long-context chunks without considering document boundaries.
Later works~\cite{zhang2024extending,he2024never} have introduced long-context QA tasks from both single- and multi-source perspectives.
Qwen-Agent~\cite{yang2024qwen2} develops an agentic system to further improve the quality of synthetic answers.

However, existing synthetic long-context data typically pair challenging questions with brief final answers for model training. This way overlooks a key difference between long-context and traditional QA tasks: practical long-context questions often require multi-step reasoning throughout the long content.
Without intermediate reasoning, LLMs struggle to learn effective patterns from the paired complex questions and brief answers.
We hypothesize that \emph{directly guiding models to generate brief answers without intermediate reasoning steps for long-context modeling will lead to suboptimal training}.
Instead, incorporating intermediate reasoning into synthetic data will help LLMs learn effective patterns and enhance training optimization.

% method
To validate this hypothesis, we introduce \emph{LongFinanceQA}, a novel long-context synthetic dataset constructed using financial data. Each sample in this dataset consists of a practical long-context question and the corresponding augmented answer along with intermediate chain-of-thought (CoT) reasoning steps.
In particular, we first collect 6,911 bilingual financial annual reports (\ie, English and Chinese) published before 2022. We then build a financial metric pool comprising key metrics commonly found in these reports, such as profit, cash flow, and debt. 
Based on these financial metrics, we generate 46,457 long-context questions that require single- or multi-source evidence. 
To generate reliable reasoning-augmented answers, we propose Property-driven Agentic Inference (PAI), a comprehensive agentic framework. PAI leverages LLM-based agents to simulate human-like reasoning and operates in three steps:
1) \textbf{a property extraction agent} decomposes complex queries by identifying key properties, where each property consists of a metric and the corresponding subject;
2) \textbf{a property-based retrieval agent} retrieves relevant information from long documents for each identified property, and then generates intermediate findings by leveraging the property-based retrieved content;
3) \textbf{a summarization agent} synthesizes the intermediate findings into a coherent conclusion.
The synthetic reasoning results are formed by integrating outputs from the property extraction and retrieval stages, while the conclusion is derived from the summarization stage.
Finally, \emph{LongFinanceQA} comprises 46,457 long-context QA pairs with CoT reasoning over 6,911 financial reports.

Although PAI performs human-like reasoning in long-context scenarios, it relies on human-crafted design and multi-step inference. To simplify this inference process, we intend to transfer PAI's long-context reasoning ability to a large language model, LLaMA-3.1, via supervised fine-tuning on LongFinanceQA. The enhanced model, LongPAI, leverages CoT reasoning to handle long-context problems in a single step. This fine-tuning procedure is termed as \emph{Supervised CoT Reasoning}.

Empirically, we first evaluate the outcome of PAI on the Loong benchmark~\cite{wang2024leave}, involving challenging long-context tasks on three different domains. The results show that equipping GPT-4o-mini with PAI achieves a substantial 20\% improvement on the Loong as shown in Figure~\ref{fig:length_score}. Moreover, the effectiveness of PAI guarantees the quality of the synthetic data in LongFinanceQA. Meanwhile, the enhanced LLaMA-3.1 model, LongPAI, achieves a 24.6\% improvement on the \textit{Financial} subset of Loong.
Notably, in several scenarios, LongPAI even surpasses its teacher model PAI. This phenomenon emphasizes the importance of long-context modeling, contradicting recent arguments that \textit{the long-context problem can be solved by short language models}~\cite{qian2024long,chen2024long}.

Our main contributions are three-fold: 1) we introduce \emph{LongFinanceQA}, a long-context synthetic dataset for fine-tuning with 46,457 QA pairs featuring high-quality CoT reasoning from 6,911 bilingual financial annual reports; 2) to generate reasoning-augmented answers, we propose an agentic framework, \emph{Property-driven Agentic Inference}, to mimic human behaviors; and 3) empirical results validate the effectiveness of PAI and supervised CoT reasoning, the quality of LongFinanceQA, and the importance of long-context modeling.
