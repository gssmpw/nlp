\section{Related Work}

\noindent \textbf{Long-context Synthetic Data}.
The scarcity of well-annotated long-context data makes high-quality synthetic data generation a valuable research direction. 
Early works~\cite{raffel2020exploring,fu2024data} concatenate short data into long-context fragments without considering the boundaries of the document. Large World Model~\cite{liu2024world} addresses this boundary issue with masked sequence packing to keep attention within documents. 
Subsequent studies~\cite{zhang2024extending,he2024never} construct single- and multi-source long-context QA pairs requiring evidence retrieval across multiple document positions.
Qwen2-Agent~\cite{yang2024qwen2} leverages multiple agents to enhance answer quality. Beyond conventional QA pairs, our study augments answers with intermediate reasoning steps, explicitly guiding language models in learning reasoning abilities for practical long-context scenarios.

\noindent \textbf{Long-context Large Language Models}. 
Two main approaches enhance long-context problem-solving: reduction-based and extension-based methods. Reduction-based methods compress input by preserving essential information, allowing LLMs to focus on relevant content. Techniques like Retrieval-Augmented Generation (RAG)~\cite{lewis2020retrieval} and task decomposition for book summarization\cite{wu2021recursively} follow this approach.
Extension-based methods expand the context window directly. RoPE~\cite{su2024roformer} introduces a foundational positional encoding widely used in long-context LLMs~\cite{peng2024yarn, yang2024qwen2, dubey2024llama}. Parallelism techniques~\cite{ren2021zero, liu2024ringattention} scale context capacity, enabling fully fine-tuning for long-context LLMs. This study leverages parallelism techniques to achieve long-context training.

%% Difference:
\noindent \textbf{Chain-of-Thought Resoning}. 
The coT technique improves the reasoning abilities of language models by incorporating intermediate reasoning steps.
Early works~\cite{wei2022chain} present that prompting LLMs with step-by-step reasoning significantly improves performance on complex reasoning tasks. Following works~\cite{zelikman2022star,yao2024tree} explore structured CoT approaches, such as tree-based and self-consistent reasoning. This work incorporates CoT reasoning steps into fine-tuning data instead of well-crafted prompts. This approach enables the augmented data to explicitly supervise language models in reasoning skills.