% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
% \usepackage[review]{acl}
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{orcidlink}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{booktabs}
\usepackage{subfig}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% \title{Instructions for *ACL Proceedings}
\title{Affinity and Diversity: A Unified Metric for Demonstration Selection via Internal Representations}

\author{Mariko Kato\orcidlink{0009-0000-3184-0334}${}^{1}$\phantom{111}
Hakaze Cho\orcidlink{0000-0002-7127-1954}${}^{1}$\phantom{111}
Yoshihiro Sakai${}^{1}$\phantom{111}
\textbf{Naoya Inoue}${}^{1,2}$\\
${}^{1}$Japan Advanced Institute of Science and Technology\phantom{111}${}^{2}$RIKEN\\
\texttt{mariko.k@jaist.ac.jp}}

%同じ単語を別の意味で使わない

\begin{document}
\maketitle

%
\begin{abstract}
% \textbf{I}n-\textbf{C}ontext \textbf{L}earning is an emerging learning paradigm on the causal language modeling operation, from a concatenation of a few-shot demonstrations as the training samples and the query as the test sample. The performance of ICL depends on the selected demonstrations, therefore existing works attempt to select better demonstrations for better performance by optimizing different objectives towards inconsistent results. To unify and explain the demonstrations individually optimized, we propose a new joint metric: Affinity and Diversity. In detail, we define affinity as the mean of the cosine similarity of representations between the query and demonstrations, and diversity as the covariance between the representations of all demonstrations. In our experiments, we show that affinity and diversity have a strong correlation to the test accuracies, suggesting that it is a good metric to guide the demonstration selection. Moreover, our analysis indicates that affinity and diversity correlate with various previous methods of demonstration selection, suggesting that affinity and diversity are the unified metrics for demonstration selection.
The performance of \textbf{I}n-\textbf{c}ontext \textbf{L}earning (ICL) is highly sensitive to the selected demonstrations. Existing approaches to demonstration selection optimize different objectives, yielding inconsistent results. To address this, we propose a unified metric--affinity and diversity--that leverages ICL model's internal representations. Our experiments show that both affinity and diversity strongly correlate with test accuracies, indicating their effectiveness for demonstration selection. Moreover, we show that our proposed metrics align well with various previous works to unify the inconsistency.
% Moreover, we show that these metrics align well with various previous methods of demonstration selection.
\end{abstract}

\section{Introduction}
% \textbf{L}anguage \textbf{M}odels (LMs) show \textbf{I}n-\textbf{C}ontext \textbf{L}earning (ICL) ability~\cite{dong2024surveyincontextlearning}, learning to solve tasks without updating model parameters by processing a query along with demonstrations of input-label pairs.


% [BG] ICL ではデモの与え方が重要であることが示されている。先行研究では様々なデモの良さの指標が検討されている。クエリとデモの類似度や、デモの順序の良さなど。本研究では、クエリとデモの類似度に基づくデモ選択に着目する。
% [Problem Statement] クエリとデモの類似度の計算方法は様々。言語モデルの埋め込みを使う方法、tf-idfベースのベクトルなど。しかし、これらの指標は互いに相補的であり、指標Aで捉えられるデモの良さが、他の指標Bでは捉えられない、逆もあり (予備実験)。これは、ICLを行うモデルとは別のモデルの情報から類似度を計算していることに起因していると推測する。これらをうまく統合できるようなmetricを開発できれば、ICLの性能向上や、クエリとデモの相性の良さの本質の解明に寄与することが期待できる。

% [Solution] そこで本研究では、既存のどの指標とも高い相関を示し、かつデモの良さを適切に捉えられる指標を検討する。具体的には、まず、ICLに重要なattention headを同定し、headのvalue空間における内部表現を用いてデモの良さをモデル化する。良さを、クエリとデモの関係であるAff, デモ間の関係であるDiv に分解し、これらを組み合わせて用いることで、前述の手法に共通する本質的なデモの良さを捉えられると仮説する。本研究の貢献は下記の通り。
% [Contributions]
% - LLM の内部表現に基づく Aff. と Div. という新たな指標を提案する (\S\ref{sec:proposal})。
% - これらが既存のクエリ-デモ類似度に基づくデモ選択指標と相関すること (\S\ref{sec:corrwithpreviousmethods})、 Aff. と Div. の高いデモに基づくICLは、downstream task における正解率も高いことを示す(\S\ref{sec:corrwithacc})。

% It has been shown that the performance of ICL severely depends on the demonstration selection and causes the performance to vary from random to state-of-the-art~\cite{liu2021makesgoodincontextexamples}. Therefore, previous work~\cite{luo2024incontextlearningretrieveddemonstrations} attempts to select better demonstrations to achieve better performance. Previous works~\cite{rubin2022learningretrievepromptsincontext} based on the similarity between query and demonstrations optimize the properties of demonstrations from other models instead of the model used for inference, such as by the encoder-model~\cite{chen2024bgem3embeddingmultilingualmultifunctionality} and off-the-shelf retriever~\cite{bm25}. Moreover, these previous works have been successful in improving the performance of ICL despite using various objectives and optimization methods among works, but causing a disjoint of the best choice and selecting the different best demonstrations among the works.

\textbf{L}anguage \textbf{M}odels (LMs) show \textbf{I}n-\textbf{C}ontext \textbf{L}earning (ICL) ability~\cite{dong2024surveyincontextlearning}, learning to solve tasks without updating model parameters by processing a query along with demonstrations of input-label pairs.
The performance of ICL is highly sensitive to the quality of demonstrations~\cite{liu2021makesgoodincontextexamples}, and previous work has proposed several strategies for selecting better demonstrations.

One prominent approach is to select demonstrations based on their similarity to queries.
Here, the similarity is computed by models \emph{independent of the ICL-executed LMs}, e.g., off-the-shelf document retrievers~\cite{rubin2022learningretrievepromptsincontext}, such as BM25~\cite{bm25}, fine-tuned document retrievers~\cite{luo2024incontextlearningretrieveddemonstrations}, and encoder-based pretrained LMs~\cite{chen2024bgem3embeddingmultilingualmultifunctionality}.
While these previous methods have improved ICL performance, we find that they capture different aspects of demonstration quality and do not converge on a consensus measure (Fig.~\ref{fig:analysis}, Left).
Developing a unified metric that integrates various metrics leads to a deeper understanding of demonstration quality and further enhances ICL performance.

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{Figure/fig1.pdf}
    \caption{The Affinity and Diversity of the demonstrations in TREC, SST5, TEE on $k=16$. The colors of the circles refer to the accuracy of the classification tasks. The line and background color refer to the decision boundary to predict labels by affinity and diversity. The larger the affinity and diversity, the higher the accuracy tends to be.  }
    \label{fig:Llama3-8b_Affinity-Diversity_scatter}
\end{figure}

% However, previous works use various objectives and optimization methods, causing a disjoint of the best choice among different works despite focusing on the same property which is the similarity between query and demonstration. 
%（事実）既存のデモ選択手法はさまざまな目的や手法で最適化され、特に類似度に基づく選択手法では、推論とは異なるモデルからデモの表現を獲得したり、既存のスコアを使用する。（問題）手法によって異なる最適なデモが選択され手法間で一貫性がない、良いデモへのインサイトが得られない。（仮説）推論に使うモデルの内部表現であれば”良いデモ”の表現をうまくキャッチでき、ICLの性能向上や、クエリに対するデモの良さに対するインサイトが得られるのではないか。
%（提案）既存手法を統合、推論に使うモデル以外の表現を用いて行うさまざまな最適化がされている既存のデモ選択がうまくいくことへの説明を行うために、インダクション回路の内部表現を使ってデモ選択指標を提案する。
% We assume that the metric unified the demonstration individually optimized may improve ICL performance and provide insight into the quality of the demo for the query.
% We assume that designing the unified metric of the previous disjoint metric could contribute to explaining the essential goodness of queries and demonstrations.

% To unify the metric, we decompose the goodness of demonstrations into Affinity between query and demonstrations and Diversity among demonstrations, and propose the joint metric combined them as selection metrics. In detail, we focus on the induction circuit contained well the information of demonstrations instead of the other model's representations, and we define the affinity as the mean of the cosine similarity of representations between label tokens of demonstrations and \textit{forerunner tokens} (e.g. the colon in ``Label:'') of query, and diversity as the covariance between the label token representations of all demonstrations.

% As a brief overview, Fig.~\ref{fig:Llama3-8b_Affinity-Diversity_scatter} shows affinity and diversity and decision boundary to prediction, where a tendency that simultaneously greater affinity and diversity cause better accuracy. That is, affinity and diversity are a joint metric to evaluate the demonstration selection.

Therefore, in this paper, we propose a novel approach that \emph{leverages the ICL model’s internal representations} to unify previous selection methods.
We first identify a self-attention head that is critical for ICL, and on the subspace defined by the $W_Q^\top W_K$ of this attention head, we define two new metrics: (i) \emph{affinity} between a query and demonstrations and (ii) \emph{diversity} among demonstrations.
Our experiments show that proposed metrics correlate with existing demonstration selection methods (Fig.\ref{fig:analysis}, Left) and are useful for identifying better demonstrations (Fig.~\ref{fig:Llama3-8b_Affinity-Diversity_scatter}).

\vspace{0.5\baselineskip}
\noindent\textbf{Our contributions are:}

% Furthermore, we also show that the objectives from previous demonstration selection methods are not always positively correlated with other selection methods. That is, they select different optimal demonstrations and use the disjoint metric. While we suggest that affinity and diversity are consistently correlated to previous methods and work as the joint metric unified the various previous methods for task performance. 

%\vspace{0.5em}

% \noindent\textbf{Our contributions can be summarized as:}

\begin{itemize}
    \item We propose internal representation-based affinity and diversity as a better joint metric on ICL for demonstration selection (\S\ref{sec:mainresults}), which unifies the previous selection methods (\S\ref{sec:correlation_between_aff/div_previous}).
    \item We empirically show that previous demonstration selection methods focus on different aspects of selected demonstrations, showing that they are not always positively correlated with other selection methods (\S\ref{sec:correlation_among_previous}).
\end{itemize}

\begin{figure}[t]
    \centering
    \includegraphics[width=1\linewidth]{Figure/fig2.pdf}
    \caption{The correlation coefficient between affinity and accuracy}
    \label{fig:Llama3-8b_affinity_accuracy_heatmap}
\end{figure}

\section{Background}
%exampleを追加
\subsection{In-context Learning}
Given $k$ input-label pairs (\textit{demonstrations}) and a \textit{query} for a classification task, the demonstrations and query are concatenated in natural language form and fed to LMs (e.g., for $k=2$, ``Good movies. Label: Positive. That's too cruel. Label: Negative. I like it. Label: ''). Here, ``: '' serves as a \textit{forerunner token} to concatenate inputs and labels, and trigger the prediction of the label tokens.
 % In this paper, the demonstration label that matches the query label is referred to as the ``correct label''.
The LMs return a probability distribution over the next tokens, and ICL selects the token with the highest probability as the final prediction. 

% form with 
\subsection{Induction Circuit}  
An induction circuit is an abstraction of some attention heads to lead the inference of ICL~\cite{elhage2021mathematical}, which consists of several interacting attention heads across different layers: (i) \textit{previous token heads}, which copy information from previous tokens to the current token, and (ii) \textit{induction heads}, which attend to tokens based on context and boost the probability of predicting token $[B]$ when $[A][B]...[A']$ is provided as input. In this paper, we find the most effective induction head, and define the affinity-diversity metrics on the $W_Q^\top W_K$ mappings of this head.




\subsection{Demonstration Selection Methods}
There are two main approaches for retrieving demonstrations. One is to use off-the-shelf retrievers, such as BM25~\cite{bm25} or BGE M3~\cite{chen2024bgem3embeddingmultilingualmultifunctionality}. Off-the-shelf retrievers approaches may be sub-optimal since they are not finetuned for specific tasks.
Another approach is to train retrievers, e.g., using encoder-based LMs, based on supervision signals from ICL models. To optimize such retrievers, various loss functions (e.g., List-wise Ranking Loss~\cite{li2023unifieddemonstrationretrieverincontext} and InfoNCE Loss~\cite{rubin2022learningretrievepromptsincontext}) and training strategies (e.g., iterative training or contrastive training) are employed. Note that while learning-based methods learn signals from ICL models during training, they solely rely on the trained retriever during ICL. However, in \S\ref{sec:correlation_among_previous}, we show that there is no consistent correlation between these previous approaches, leading to disagreement in the selected demonstrations across different objectives and optimization methods, that should be unified for consistent demonstration selection.
%objectiveが違いますよという指摘をする
\begin{figure}[t]
    \centering
    \includegraphics[width=0.97\linewidth]{Figure/fig3.pdf}
    \caption{The coefficient of determination between diversity and accuracy}
    \label{fig:Llama3-8b_diversity_accyract_heatmap}
\end{figure}


\begin{figure*}
    \centering
    \begin{minipage}[b]{0.68\linewidth}
    \centering
        \includegraphics[width=1\linewidth]{Figure/fig4.pdf}
    \end{minipage}
    \hspace{0.05\linewidth}
    \begin{minipage}[b]{0.255\linewidth}
    \centering
        \includegraphics[width=1\linewidth]{Figure/fig5.pdf}
    \end{minipage}
    
    \caption{\textbf{Left}: The tendency of diversity to accuracy on $k=16$. \textbf{Right}: The tendency of affinity to accuracy on $k=16$. }
    \label{fig:sec4-scatter}
\end{figure*}

\section{Proposed Metrics: Affinity, Diversity}

 % To propose a consistent metric for demonstration selection, we define the affinity and diversity on the subspace of the aforementioned induction head.
Since induction circuits play a crucial role in ICL,
we hypothesize that induction circuits can also be used to assess the quality of demonstrations.
We first identify induction heads (\S\ref{sec:step1}) and then compute affinity and diversity in their subspace (\S\ref{sec:step2}).

\subsection{Step 1: Extract Internal Representation}
\label{sec:step1}

% Following~\citet{cho2024revisitingincontextlearninginference}, we mark the self-attention head with the highest total attention score from the last token of the input (as the attention query, where the prediction is conducted) to all the correct label token, as the ``most correct induction head''. 
To identify induction heads, we follow \citet{cho2024revisitingincontextlearninginference}:
for each attention head $h$ at layer $l$, we compute $s(h)$, the sum of attention scores from the last token of the query to all the correct label tokens (i.e., tokens that match the ground-truth label of the query) in the demonstrations, and identify ``the best induction head'' as the head $\hat{h}$ at layer $\hat{l}$ with the highest $s(\hat{h})$.

We then extract the label token representations $\left\{\bm{d}_\mathrm{label}^{(i)}\right\}_{i=1}^{k}$ of each demonstration $i$ and the last token's representation $\bm{d}_\mathrm{q}$ of the query from the best induction head $\hat{h}$. In detail, given a token index $j$ and the hidden state $\bm{h}_j^{\hat{l}}$ of $j$-th token from the previous layer of $\hat{h}$ after the layer normalization, we extract the inner representation of $j$-th token as follows:
%
\begin{equation}
    \bm{d}_j = W_Q^{\hat{h},\top} W_K^{\hat{h}} \bm{h}_j^{\hat{l}},
\end{equation}
%
where $W_Q^{\hat{h}}$ and $W_K^{\hat{h}}$ are the query projection and key projection of attention head $\hat{h}$.


\subsection{Step 2: Compute Affinity and Diversity}
\label{sec:step2}

\subsubsection{Affinity}
We define affinity as the mean of the cosine similarity between all the label token representations and the query representation as follows:
\begin{equation}\label{eq:aff}
    \mathrm{Aff}\left[\bm{d}_\mathrm{q}, \left\{\bm{d}_{\mathrm{label}}^{(i)}\right\}_{i=1}^k\right] = \frac{1}{k}\sum_{i=1}^k \mathrm{cos}\left[\bm{d}_\mathrm{q},\bm{d}_\mathrm{label}^{(i)}\right]
\end{equation}



\subsubsection{Diversity}
We define diversity as the variance (the trace of the covariance matrix) across the label token representations of all demonstrations as follows:
\begin{equation}\label{eq:cov}
    \mathrm{Div}\left[\left\{\bm{d}_{\mathrm{label}}^{(i)}\right\}_{i=1}^k\right] = \frac{1}{k}\mathrm{tr}\left[\mathop{\mathbb{D}}\limits_{i\in[1, k]}\left[\bm{d}_{\mathrm{label}}^{(i)}\right]\right]
\end{equation}
Here, $\mathbb{D}$ represents the covariance operator.

\begin{figure*}
    \centering
    \begin{minipage}[b]{0.29\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/fig8.pdf}

    \end{minipage}
    \hspace{0.05\linewidth}
    \begin{minipage}[b]{0.6\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figure/fig7.pdf}

    \end{minipage}

    \vspace{-0.3\baselineskip}
    \caption{\textbf{Left}: The Spearman's rank correlation coefficient of the similarity scores, affinity, diversity, and accuracy of $k=16$ on SST2. \textbf{Middle}: The affinity of selected demonstrations by each selection method on $k=2$. \textbf{Right}: The diversity of selected demonstrations by each selection method on $k=2$.}
    \label{fig:analysis}
    \vspace{-0.8\baselineskip}
\end{figure*}

\section{Experiments}

We demonstrate that affinity and diversity serve as effective metrics for demonstration selection.


\subsection{Experimental Settings}
\label{sec:settings}

\paragraph{Model.} We conduct experiments on Llama 3 8B~\cite{llama3modelcard}. The model parameters are loaded from \verb|HuggingFace|.

\paragraph{Dataset.} For all experiments, we use 10 classification datasets. For details of the dataset, please refer to Appendix~\ref{appendix:dataset}. We use $k = 2, 4, 8, 12, 16$, and input sequences are built by library StaICC~\cite{cho2025staicc}.

\paragraph{Evaluation.} For each test instance, we randomly sample $k$ demonstrations, run ICL, and record the prediction. Next, we sort all instances based on their affinity or diversity values and group them into bins of 30 instances each. For each bin, we calculate the average affinity or diversity, and also the accuracy. These averages and accuracies are then used to compute the correlation between the proposed metrics and accuracy. For affinity, we use Spearman's rank correlation coefficient. For diversity, we apply Ridge regression with a Laplacian kernel to capture non-linear relationships, with the $R^2$ coefficient as the measure of goodness-of-fit.



%相関係数やR^2の数字で、accuracyと良い関係があることを示して、scatterのほうでその様相を確認し、affinityやdiversityがaccuracyとデモのよい関係が捉えられていることを示す。
\subsection{Main Results: Affinity and Diversity Measure the Effectiveness of Demonstrations}
\label{sec:mainresults}

The Spearman's rank correlation coefficient for affinity and $R^2$ coefficient for diversity are shown in Fig.~\ref{fig:Llama3-8b_affinity_accuracy_heatmap} and Fig.~\ref{fig:Llama3-8b_diversity_accyract_heatmap}.
These indicate that affinity shows a positive correlation across various tasks, and diversity achieves a high $R^2$ coefficient in nearly all tasks. Fig.~\ref{fig:sec4-scatter} (Left) and Fig.~\ref{fig:sec4-scatter} (Right) provide examples of diversity/affinity-accuracy scatter plots, which further support these trends.

%diversityはfigure 4から非線形だがdiversityがあがるとaccuracyがあがる傾向は確認できる。sst5みたいな怪しいデータセットもいるが。



\section{Analysis}

% In this section, we compare affinity and diversity to previous work and show that (1) affinity and diversity have a correlation to previous work, addressing the inconsistency issue in the previous works, and (2) previous methods mainly and only focus on affinities but not diversities.

Next, we show that affinity and diversity strongly correlate with the scores from previous demonstration selection methods, addressing the inconsistency issue in the previous work (\S\ref{sec:correlation_between_aff/div_previous}).
We also show that the scores from previous demonstration selection methods disagree with each other (\S\ref{sec:correlation_among_previous}).  Moreover, the demonstrations selected by previous work practically improve affinity, but not diversity. These observations suggest that it is required a new demonstration selection method based on affinity and diversity (\S\ref{sec:previous_improve_aff}).


\subsection{Experimental Setup}
We use three previous methods to compare affinity and diversity, BM25 and BGE-M3 for training-free methods, and EPR for training methods. For details of the previous methods, please refer to Appendix~\ref{appendix:previous-methods}. Other settings are the same as \S\ref{sec:settings}.

% \begin{itemize}
%     \item BM25: selecting the demonstrations with the similarity score to query, by an expanded TF-IDF (BM25). 
%     \item BGE M3: selecting the demonstrations with the most cosine similarity between the encoding vectors of the demonstrations and query, by BGE M3. The model parameters are loaded from \verb|HuggingFace|.
%     \item \textbf{E}fficient \textbf{P}rompt \textbf{R}etrieval (EPR)~\cite{rubin2022learningretrievepromptsincontext}: selecting the same way as BGE M3, by the dense encoder trained to retrieve a better demonstration with each ICL datasets. 
% \end{itemize}


\subsection{Affinity and Diversity Correlate with the Score of Previous Methods}
\label{sec:correlation_between_aff/div_previous}
We measure the similarity scores from the previous methods using the same prompts described in \S\ref{sec:settings} and compute the Spearman's rank correlation among these similarity scores, accuracy, affinity, and diversity. The results of $k=16$ on SST2 are shown in Fig.~\ref{fig:analysis} (Left), where both affinity and diversity show a positive correlation with the similarity scores and accuracy. This indicates that affinity and diversity consistently measure the effectiveness of the demonstrations in terms of accuracy. 

\subsection{Previous Methods are Not Always Positively Correlated with Each Other}
\label{sec:correlation_among_previous}
Meanwhile, no consistent positive correlation is observed among the similarity scores from previous selection methods. Even worse, in some cases, negative correlations (e.g., EPR and BM25) are observed, suggesting that they may not consistently produce optimal results.
EPR shows a positive correlation with BGE, likely due to their reliance on a BERT-based encoder.

% The similarity score of previous methods still correlates to accuracy, that is they select different good demonstrations. 

\subsection{Better Selection of Demonstrations Improves Affinity and Diversity}
\label{sec:previous_improve_aff}
In this section, we evaluate the previous demonstration selection methods on the proposed affinity and diversity, and show that affinity and diversity are improved by the previous methods. We build prompts with the same query as \S\ref{sec:settings} select demonstrations by previous methods and input them into an LM to measure the accuracy, affinity, and diversity.

The results are shown in Fig.~\ref{fig:analysis} (Middle) for the affinity and accuracy, where better accuracy co-occurrence with greater affinity, while, when no improvement is observed in the affinity, then no accuracy can be observed in the accuracy, on some of the scenarios. Moreover, the results of diversity are shown in Fig.~\ref{fig:analysis} (Left), with a less significant co-occurrence between better accuracy and greater diversity. We infer that the reason is: existing methods select demonstrations based on their similarity to the query, without a focus on the diversity, showing a possibility towards better selection methods based on the joint metric of affinity and diversity. Due to space limitations and computational resources, we leave the demonstration selection method as future work.

\section{Conclusion}
In summary, we propose affinity and diversity to evaluate demonstration selections in the ICL scenario. Our experiments show that affinity and diversity consistently measure the effectiveness of the demonstration well, raising the possibility of better demonstration selection methods.
%%\paragraph{Conclusion.} 
%[TODO:other discussion]

% \newpage
\section{Limitations}
Due to computability limitations, we are not able to compare the performance of affinity and diversity with the learning-based retriever for diversity or order of demonstrations.


\newpage
% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\newpage
\appendix
\section{Experimental Details}
\subsection{Datasets}
\label{appendix:dataset}
We build ICL-formed test inputs from 10 classification tasks datasets: GLUE-SST2 (SST2)~\cite{sst2}, Rotten tomatoes (Rott.T)~\cite{rotten}, Finacial Phrasebank (Fina.P)~\cite{fp}, Stanford Sentiment Treebank (SST5)~\cite{sst2}, TREC (TREC)~\cite{trec1, trec2}, AGNews (AGNews)~\cite{agnews}, Subjective (Subjective)~\cite{subj}, Tweet Eval Emotion (TEE)~\cite{tee}, Tweet Eval Hate (TEH)~\cite{teh}, Hate Speech 18 (HS18)~\cite{hs18}.

\subsection{Previous methods}
\label{appendix:previous-methods}
We conduct experiments to compare affinity and diversity using previous methods:
\begin{itemize}
    \item BM25: selecting the demonstrations with the similarity score to query, by an expanded TF-IDF (BM25). 
    \item BGE M3: selecting the demonstrations with the most cosine similarity between the encoding vectors of the demonstrations and query, by BGE M3. The model parameters are loaded from \verb|HuggingFace|.
    \item \textbf{E}fficient \textbf{P}rompt \textbf{R}etrieval (EPR)~\cite{rubin2022learningretrievepromptsincontext}: selecting the same way as BGE M3, by the dense encoder trained to retrieve a better demonstration with each ICL datasets. 
\end{itemize}

\section{Other datasets experiment results}
The results of most experiments in the main text on other datasets are shown in Fig.~\ref{fig:apd_1},~\ref{fig:apd_4},~\ref{fig:apd_5},~\ref{fig:apd_7},~\ref{fig:apd_8}.

\section{Statements}
\subsection{License for Artifacts}
\paragraph{Models}
Llama 3 8B is under its specific license.
\paragraph{Datasets}
We list the open-source license for the datasets used in this paper as follows:
\begin{itemize}
    \item CC-by4.0: Tweet eval emotions, Tweet eval hate
    \item CC-BY-NC-SA-3.0: Financial phrasebank
    \item CC-BY-SA-3.0: Hate speech 18
    \item BSD: TREC, Subjective
    \item Unknown: GLUE-SST2, Rotten tomatoes, Stanford sentiment treebank, AGNews
\end{itemize}
\subsection{Statistics For Data}
%StaICCを参照する
We list the number of examples of datasets used in this paper as follows Table ~\ref{tab:dataset-size}.

\begin{table*}[t]
\caption{Raw dataset split size for each sub-dataset.}
\label{tab:dataset-size}
\resizebox{\textwidth}{!}{
\begin{tabular}{rllllllllll}
\toprule
 & SST2 & Rott.T & Fina.P & SST5 & TREC & AGNews & Subj. & TEE & TEH & HS18 \\ \midrule
Demonstration Set & 4096 & 4096 & 512 & 4096 & 4096 & 4096 & 4096 & 4096 & 3192 & 4096 \\
Test Set & 512 & 512 & 512 & 512 & 512 & 512 & 512 & 512 & 512 & 512 \\ \bottomrule
\end{tabular}}
\end{table*}

\subsection{AI Agent Usage}
AI Agents are only used for writing improving and grammar checking in this paper.

\begin{figure*}[h]
    \centering
    \includegraphics[width=1\linewidth]{Figure/appendix_1.pdf}
    \caption{The Affinity and Diversity of the demonstrations. Colors refer to the accuracy of all classification tasks on $k=16$.}
    \label{fig:apd_1}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figure/appendix_4.pdf}
    \caption{The tendency of diversity to accuracy on $k=16$. }
    \label{fig:apd_4}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figure/appndeix_5.pdf}
    \caption{The tendency of affinity to accuracy on $k=16$.}
    \label{fig:apd_5}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figure/appendix_7.pdf}
    \caption{\textbf{Right}: The affinity of selected demonstrations by each selection method on $k=2$. \textbf{Right}: The diversity of selected demonstrations by each selection method on $k=2$.}
    \label{fig:apd_7}
\end{figure*}

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Figure/appendix_8.pdf}
    \caption{The Spearman's rank correlation coefficient of the similarity scores, affinity, diversity, and accuracy of $k=16$}
    \label{fig:apd_8}
\end{figure*}


\end{document}
