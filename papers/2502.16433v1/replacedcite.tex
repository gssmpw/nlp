\section{Related work}
LLMs trained with next token prediction loss ____ have demonstrated many fascinating capabilities, including the ability to perform zero-shot or few-shot tasks ____ and the ability to reason ____. 

Several works have investigated the shortcomings of MLE and exposure bias. ____ measured the accumulation of errors in language generation due to exposure bias. ____ connected exposure bias to generalization. ____ studied how exposure bias leads to hallucination in neural machine translation. To mitigate exposure bias, there exists a long line of work that has explored sequence-level training methods. ____ proposed to train RNN with RL or RL-related algorithms rather than teacher-forcing. BRIO ____ targeted the summarization task with the ROUGE signal. ____ trained the language models with an offline RL algorithm. There also exists a line of works that generate samples during training and mix the samples with ground truth data ____. 

Recently, RLHF ____ and its supervised version DPO ____ were developed for alignment. They are effectively sequence-level training techniques. These algorithms require a pair of preferred and rejected samples, which are usually gathered by human labeling. The RL approach to language modeling is also closely related to energy-based models (EBM) ____. This EBM form has also been studied in controlled text generation ____. ____ also consider synthetic data generation, but their purpose is to improve reward modeling in RLHF rather than sequence-level training. 
%____ discuss pitfalls of next token prediction from an algorithmic perspective, while we tackle the same point from a sequence-level verses token-level signal perspective.