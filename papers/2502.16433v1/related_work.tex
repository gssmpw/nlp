\section{Related work}

LLMs trained with next token prediction loss \citep{radford2019language,chung2022scaling,sanh2021multitask,zhou2023lima} have demonstrated many fascinating capabilities, including the ability to perform zero-shot or few-shot tasks \citep{radford2019language,brown2020language} and the ability to reason \citep{wei2022chain}. 

Several works have investigated the shortcomings of MLE and exposure bias. \citet{arora2022exposure} measured the accumulation of errors in language generation due to exposure bias. \citet{schmidt2019generalization} connected exposure bias to generalization. \citet{wang2020exposure} studied how exposure bias leads to hallucination in neural machine translation. To mitigate exposure bias, there exists a long line of work that has explored sequence-level training methods. \citet{bengio2015scheduled,ranzato2015sequence} proposed to train RNN with RL or RL-related algorithms rather than teacher-forcing. BRIO \citet{liu2022brio} targeted the summarization task with the ROUGE signal. \citet{pang2020text} trained the language models with an offline RL algorithm. There also exists a line of works that generate samples during training and mix the samples with ground truth data \citep{shen2015minimum,zhang2019bridging,duckworth2019parallel}. 

Recently, RLHF \citep{stiennon2020learning,ouyang2022training} and its supervised version DPO \citep{rafailov2023direct} were developed for alignment. They are effectively sequence-level training techniques. These algorithms require a pair of preferred and rejected samples, which are usually gathered by human labeling. The RL approach to language modeling is also closely related to energy-based models (EBM) \citep{korbak2022rl, deng2020residual}. This EBM form has also been studied in controlled text generation \citet{kumar2022gradient}. \citet{pace2024west} also consider synthetic data generation, but their purpose is to improve reward modeling in RLHF rather than sequence-level training. 
%\citet{bachmann2024pitfalls} discuss pitfalls of next token prediction from an algorithmic perspective, while we tackle the same point from a sequence-level verses token-level signal perspective.