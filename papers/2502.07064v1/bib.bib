@misc{predetor,
      title={Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning}, 
      author={Subhojyoti Mukherjee and Josiah P. Hanna and Qiaomin Xie and Robert Nowak},
      year={2024},
      eprint={2406.05064},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{barron1998minimum,
  title={The minimum description length principle in coding and modeling},
  author={Barron, Andrew and Rissanen, Jorma and Yu, Bin},
  journal={IEEE transactions on information theory},
  year={1998},
  publisher={IEEE}
}

@article{dawid1984present,
  title={Present position and potential developments: Some personal views statistical theory the prequential approach},
  author={Dawid, A Philip},
  journal={Journal of the Royal Statistical Society: Series A (General)},
  volume={147},
  number={2},
  pages={278--290},
  year={1984},
  publisher={Wiley Online Library}
}

@inproceedings{bubeck2015bandit,
  title={Bandit convex optimization:$\backslash$sqrtt regret in one dimension},
  author={Bubeck, S{\'e}bastien and Dekel, Ofer and Koren, Tomer and Peres, Yuval},
  booktitle={Conference on Learning Theory},
  pages={266--278},
  year={2015},
  organization={PMLR}
}

@inproceedings{bubeck2016multi,
  title={Multi-scale exploration of convex functions and bandit convex optimization},
  author={Bubeck, S{\'e}bastien and Eldan, Ronen},
  booktitle={Conference on Learning Theory},
  pages={583--589},
  year={2016},
  organization={PMLR}
}

@book{Imbens_Rubin_2015, 
    place={Cambridge}, 
    title={Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction}, 
    publisher={Cambridge University Press}, 
    author={Imbens, Guido W. and Rubin, Donald B.}, year={2015}
} 

@article{bastani2022meta,
  title={Meta dynamic pricing: Transfer learning across experiments},
  author={Bastani, Hamsa and Simchi-Levi, David and Zhu, Ruihao},
  journal={Management Science},
  volume={68},
  number={3},
  pages={1865--1881},
  year={2022},
  publisher={INFORMS}
}

@article{fortini2023prediction,
  title={Prediction-based uncertainty quantification for exchangeable sequences},
  author={Fortini, Sandra and Petrone, Sonia},
  journal={Philosophical Transactions of the Royal Society A},
  volume={381},
  number={2247},
  pages={20220142},
  year={2023},
  publisher={The Royal Society}
}
@article{osband2019deep,
  title={Deep exploration via randomized value functions},
  author={Osband, Ian and Van Roy, Benjamin and Russo, Daniel J and Wen, Zheng},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={124},
  pages={1--62},
  year={2019}
}
@inproceedings{riquelme2018deep,
  title={Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling},
  author={Riquelme, Carlos and Tucker, George and Snoek, Jasper},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{wu2020mind,
  title={Mind: A large-scale dataset for news recommendation},
  author={Wu, Fangzhao and Qiao, Ying and Chen, Jiun-Hung and Wu, Chuhan and Qi, Tao and Lian, Jianxun and Liu, Danyang and Xie, Xing and Gao, Jianfeng and Wu, Winnie and others},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={3597--3606},
  year={2020}
}


@inproceedings{de1929funzione,
  title={Funzione caratteristica di un fenomeno aleatorio},
  author={De Finetti, Bruno},
  booktitle={Atti del Congresso Internazionale dei Matematici: Bologna del 3 al 10 de settembre di 1928},
  pages={179--190},
  year={1929}
}


@inproceedings{cella2020meta,
  title={Meta-learning with stochastic linear bandits},
  author={Cella, Leonardo and Lazaric, Alessandro and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning},
  year={2020},
  organization={PMLR}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{emmons2021rvs,
  title={Rvs: What is essential for offline rl via supervised learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{yang2023foundation,
  title={Foundation models for decision making: Problems, methods, and opportunities},
  author={Yang, Sherry and Nachum, Ofir and Du, Yilun and Wei, Jason and Abbeel, Pieter and Schuurmans, Dale},
  journal={arXiv preprint arXiv:2303.04129},
  year={2023}
}

@article{ding2019goal,
  title={Goal-conditioned imitation learning},
  author={Ding, Yiming and Florensa, Carlos and Abbeel, Pieter and Phielipp, Mariano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{cella2022meta,
  title={Meta representation learning with contextual linear bandits},
  author={Cella, Leonardo and Lounici, Karim and Pontil, Massimiliano},
  journal={arXiv preprint arXiv:2205.15100},
  year={2022}
}

@article{wan2021metadata,
  title={Metadata-based multi-task bandits with bayesian hierarchical models},
  author={Wan, Runzhe and Ge, Lin and Song, Rui},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29655--29668},
  year={2021}
}

@article{zhu2023non,
  title={Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble Sampling},
  author={Zhu, Zheqing and Liu, Yueyang and Kuang, Xu and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2310.07786},
  year={2023},
}

@article{mukherjee2024pretraining,
  title={Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning},
  author={Mukherjee, Subhojyoti and Hanna, Josiah P and Xie, Qiaomin and Nowak, Robert},
  journal={arXiv preprint arXiv:2406.05064},
  year={2024}
}

@inproceedings{malenica2023causality,
  title={Causality in Goal Conditioned RL: Return to No Future?},
  author={Malenica, Ivana and Murphy, Susan},
  booktitle={NeurIPS 2023 Workshop on Goal-Conditioned Reinforcement Learning},
  year={2023}
}

@article{wang2022deep,
  title={Deep Meta-learning in Recommendation Systems: A Survey},
  author={Wang, Chunyang and Zhu, Yanmin and Liu, Haobing and Zang, Tianzi and Yu, Jiadi and Tang, Feilong},
  journal={arXiv preprint arXiv:2206.04415},
  year={2022}
}

@inproceedings{zheng2021cold,
  title={Cold-start sequential recommendation via meta learner},
  author={Zheng, Yujia and Liu, Siyi and Li, Zekun and Wu, Shu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={5},
  pages={4706--4713},
  year={2021}
}

@article{ober2019benchmarking,
  title={Benchmarking the neural linear model for regression},
  author={Ober, Sebastian W and Rasmussen, Carl Edward},
  journal={arXiv preprint arXiv:1912.08416},
  year={2019}
}

@article{zahavy2019neural,
  title={Neural Linear Bandits: Overcoming Catastrophic Forgetting through Likelihood Matching},
  author={Zahavy, Tom and Mannor, Shie},
  year={2019}
}

@InProceedings{pmlr-v119-zhou20a,
  title = 	 {Neural Contextual Bandits with {UCB}-based Exploration},
  author =       {Zhou, Dongruo and Li, Lihong and Gu, Quanquan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {11492--11502},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/zhou20a/zhou20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/zhou20a.html},
  abstract = 	 {We study the stochastic contextual bandit problem, where the reward is generated from an unknown function with additive noise. No assumption is made about the reward function other than boundedness. We propose a new algorithm, NeuralUCB, which leverages the representation power of deep neural networks and uses a neural network-based random feature mapping to construct an upper confidence bound (UCB) of reward for efficient exploration. We prove that, under standard assumptions, NeuralUCB achieves $\tilde O(\sqrt{T})$ regret, where $T$ is the number of rounds. To the best of our knowledge, it is the first neural network-based contextual bandit algorithm with a near-optimal regret guarantee. We also show the algorithm is empirically competitive against representative baselines in a number of benchmarks.}
}



@inproceedings{zhang2021model,
  title={A model of two tales: Dual transfer learning framework for improved long-tail item recommendation},
  author={Zhang, Yin and Cheng, Derek Zhiyuan and Yao, Tiansheng and Yi, Xinyang and Hong, Lichan and Chi, Ed H},
  booktitle={Proceedings of the web conference 2021},
  pages={2220--2231},
  year={2021}
}


@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@inproceedings{attentionisallyouneed,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{
lin2024transformers,
title={Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining},
author={Licong Lin and Yu Bai and Song Mei},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=yN4Wv17ss3}
}

@article{simchowitz2021bayesian,
  title={Bayesian decision-making under misspecified priors with applications to meta-learning},
  author={Simchowitz, Max and Tosh, Christopher and Krishnamurthy, Akshay and Hsu, Daniel J and Lykouris, Thodoris and Dudik, Miro and Schapire, Robert E},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3-4},
  pages={285--294},
  year={1933},
  publisher={Oxford University Press}
}


@article{brandfonbrener2022does,
  title={When does return-conditioned supervised learning work for offline reinforcement learning?},
  author={Brandfonbrener, David and Bietti, Alberto and Buckman, Jacob and Laroche, Romain and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={1542--1553},
  year={2022}
}

@inproceedings{agrawal2012analysis,
  title={Analysis of thompson sampling for the multi-armed bandit problem},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Conference on learning theory},
  pages={39--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{neu2022lifting,
  title={Lifting the information ratio: An information-theoretic analysis of thompson sampling for contextual bandits},
  author={Neu, Gergely and Olkhovskaia, Iuliia and Papini, Matteo and Schwartz, Ludovic},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9486--9498},
  year={2022}
}

@inproceedings{zhu2023scalable,
  title={Scalable neural contextual bandit for recommender systems},
  author={Zhu, Zheqing and Van Roy, Benjamin},
  booktitle={Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
  pages={3636--3646},
  year={2023}
}

@article{dong2018information,
  title={An information-theoretic analysis for thompson sampling with many actions},
  author={Dong, Shi and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{russo2016information,
  title={An information-theoretic analysis of thompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={68},
  pages={1--30},
  year={2016}
}

@inproceedings{agrawal2013thompson,
  title={Thompson sampling for contextual bandits with linear payoffs},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={International conference on machine learning},
  pages={127--135},
  year={2013},
  organization={PMLR}
}

@article{ryzhov2012knowledge,
  title={The knowledge gradient algorithm for a general class of online learning problems},
  author={Ryzhov, Ilya O and Powell, Warren B and Frazier, Peter I},
  journal={Operations Research},
  volume={60},
  number={1},
  pages={180--195},
  year={2012},
  publisher={INFORMS}
}

@article{tran2020practical,
  title={Practical uncertainty estimation and out-of-distribution robustness in deep learning},
  author={Tran, Dustin and Snoek, Jasper and Lakshminarayanan, Balaji},
  journal={NeurIPS Tutorial, Google Brain},
  year={2020}
}

@article{goan2020bayesian,
  title={Bayesian neural networks: An introduction and survey},
  author={Goan, Ethan and Fookes, Clinton},
  journal={Case Studies in Applied Bayesian Data Science: CIRM Jean-Morlet Chair, Fall 2018},
  year={2020},
  publisher={Springer}
}

@inproceedings{kaufmann2012bayesian,
  title={On Bayesian upper confidence bounds for bandit problems},
  author={Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  booktitle={Artificial intelligence and statistics},
  pages={592--600},
  year={2012},
  organization={PMLR}
}

@article{russo2018learning,
  title={Learning to optimize via information-directed sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Operations Research},
  volume={66},
  number={1},
  pages={230--252},
  year={2018},
  publisher={INFORMS}
}


@InProceedings{metalearningSong,
  title = 	 {Towards Scalable and Robust Structured Bandits: A Meta-Learning Framework},
  author =       {Wan, Runzhe and Ge, Lin and Song, Rui},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  year = 	 {2023},
  pdf = 	 {https://proceedings.mlr.press/v206/wan23a/wan23a.pdf},
  abstract = 	 {Online learning in large-scale structured bandits is known to be challenging due to the curse of dimensionality. In this paper, we propose a unified meta-learning framework for a wide class of structured bandit problems where the parameter space can be factorized to item-level, which covers many popular tasks. Compared with existing approaches, the proposed solution is both scalable to large systems and robust by utilizing a more flexible model. At the core of this framework is a Bayesian hierarchical model that allows information sharing among items via their features, upon which we design a meta Thompson sampling algorithm. Three representative examples are discussed thoroughly. Theoretical analysis and extensive numerical results both support the usefulness of the proposed method.}
}



@article{jha2022neural,
  title={The neural process family: Survey, applications and perspectives},
  author={Jha, Saurav and Gong, Dong and Wang, Xuesong and Turner, Richard E and Yao, Lina},
  journal={arXiv preprint arXiv:2209.00517},
  year={2022}
}

@InProceedings{condNeuralProcesses,
  title = 	 {Conditional Neural Processes},
  author =       {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1704--1713},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/garnelo18a.html},
  abstract = 	 {Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet, GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.}
}


@article{garnelo2018neural,
  title={Neural processes},
  author={Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J and Eslami, SM and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1807.01622},
  year={2018}
}

@article{heath1976finetti,
  title={De Finetti's theorem on exchangeable variables},
  author={Heath, David and Sudderth, William},
  journal={The American Statistician},
  volume={30},
  number={4},
  pages={188--189},
  year={1976},
  publisher={Taylor \& Francis}
}

@book{finetti1972probability,
  title={Probability, induction and statistics},
  author={Finetti, Bruno},
  year={1972},
  publisher={John Wiley and Sons}
}


@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{liu2023nonstationary,
  title={Nonstationary bandit learning via predictive sampling},
  author={Liu, Yueyang and Van Roy, Benjamin and Xu, Kuang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={6215--6244},
  year={2023},
  organization={PMLR}
}

@article{madeka2022deep,
  title={Deep inventory management},
  author={Madeka, Dhruv and Torkkola, Kari and Eisenach, Carson and Luo, Anna and Foster, Dean P and Kakade, Sham M},
  journal={arXiv preprint arXiv:2210.03137},
  year={2022}
}

@inproceedings{
agarwal2021persim,
title={PerSim: Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators},
author={Anish Agarwal and Abdullah Omar Alomar and Varkey Alumootil and Devavrat Shah and Dennis Shen and Zhi Xu and Cindy Yang},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=v2w7CVZGHeA}
}

@Article{a15080255,
AUTHOR = {Trella, Anna L. and Zhang, Kelly W. and Nahum-Shani, Inbal and Shetty, Vivek and Doshi-Velez, Finale and Murphy, Susan A.},
TITLE = {Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-Implementation Guidelines},
JOURNAL = {Algorithms},
VOLUME = {15},
YEAR = {2022},
NUMBER = {8},
ARTICLE-NUMBER = {255},
URL = {https://www.mdpi.com/1999-4893/15/8/255},
ISSN = {1999-4893},
DOI = {10.3390/a15080255}
}



@misc{russo2020tutorial,
      title={A Tutorial on Thompson Sampling}, 
      author={Daniel Russo and Benjamin Van Roy and Abbas Kazerouni and Ian Osband and Zheng Wen},
      year={2020},
      eprint={1707.02038},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{lee2023martingale,
      title={Martingale Posterior Neural Processes}, 
      author={Hyungi Lee and Eunggu Yun and Giung Nam and Edwin Fong and Juho Lee},
      year={2023},
      eprint={2304.09431},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{
lee2023incontext,
title={In-Context Decision-Making from Supervised Pretraining},
author={Jonathan Lee and Annie Xie and Aldo Pacchiano and Yash Chandak and Chelsea Finn and Ofir Nachum and Emma Brunskill},
booktitle={ICML Workshop on New Frontiers in Learning, Control, and Dynamical Systems},
year={2023}
}


@InProceedings{pmlr-v80-garnelo18a,
  title = 	 {Conditional Neural Processes},
  author =       {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1704--1713},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/garnelo18a/garnelo18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/garnelo18a.html},

}

@article{osband2024epistemic,
  title={Epistemic neural networks},
  author={Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Ibrahimi, Morteza and Lu, Xiuyuan and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{
osband2023epistemic,
title={Epistemic Neural Networks},
author={Ian Osband and Zheng Wen and Seyed Mohammad Asghari and Vikranth Dwaracherla and Morteza Ibrahimi and Xiuyuan Lu and Benjamin Van Roy},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=dZqcC1qCmB}
}

@misc{standev2018stancore,
title = {{The Stan Core Library}},
author = {{Stan Development Team}},
note = {Version 2.18.0},
year = {2018},
url = {http://mc-stan.org/ 17},
}

@article{cook06,
author = {Samantha R Cook, Andrew Gelman and Donald B Rubin},
title = {Validation of Software for Bayesian Models Using Posterior Quantiles},
journal = {Journal of Computational and Graphical Statistics},
volume = {15},
number = {3},
pages = {675-692},
year = {2006},
publisher = {Taylor & Francis},
doi = {10.1198/106186006X136976},
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{barber2023finetti,
  title={De Finetti's Theorem and Related Results for Infinite Weighted Exchangeable Sequences},
  author={Barber, Rina Foygel and Candes, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:2304.03927},
  year={2023}
}
@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}
@online{hfsentiment,
  author = {Bhadresh Savani},
  title = {distilbert-base-uncased-sentiment-sst2},
year={2022},
  url = {https://huggingface.co/bhadresh-savani/distilbert-base-uncased-sentiment-sst2},
  urldate = {2025-01-30}
}
@InProceedings{hfformality,
  author="Babakov, Nikolay
  and Dale, David
  and Gusev, Ilya
  and Krotova, Irina
  and Panchenko, Alexander",
  title="Don't Lose the Message While Paraphrasing: A Study on Content Preserving Style Transfer",
  booktitle="Natural Language Processing and Information Systems",
  year="2023",
  publisher="Springer Nature Switzerland",
  address="Cham",
  pages="47--61",
  isbn="978-3-031-35320-8"
}
@article{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S},
  journal={A Bradford Book},
  year={2018}
}
@misc{uncertaintyTutorial,
  title={Practical Uncertainty Estimation &
Out-of-Distribution Robustness in
Deep Learning},
  author={Tran, Dustin and Snoek, Jasper and Lakshminarayanan, Balaji},
  note={NeurIPS Tutorial},
  year={2020},
  url={https://neurips.cc/media/neurips-2020/Slides/16649.pdf}
}

@article{gawlikowski2021survey,
  title={A survey of uncertainty in deep neural networks},
  author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
  journal={arXiv preprint arXiv:2107.03342},
  year={2021}
}

@article{lu2017ensemble,
  title={Ensemble sampling},
  author={Lu, Xiuyuan and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}



@inproceedings{ensembleSampling,
 author = {Qin, Chao and Wen, Zheng and Lu, Xiuyuan and Van Roy, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 title = {An Analysis of Ensemble Sampling},
 year = {2022}
}

@inproceedings{kveton2021meta,
  title={Meta-thompson sampling},
  author={Kveton, Branislav and Konobeev, Mikhail and Zaheer, Manzil and Hsu, Chih-wei and Mladenov, Martin and Boutilier, Craig and Szepesvari, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={5884--5893},
  year={2021},
  organization={PMLR}
}

@article{cesa2017boltzmann,
  title={Boltzmann exploration done right},
  author={Cesa-Bianchi, Nicol{\`o} and Gentile, Claudio and Lugosi, G{\'a}bor and Neu, Gergely},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{decisionTransformer,
 author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
 year = {2021}
}


@article{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}


@article{dai2022sample,
  title={Sample-then-optimize batch neural Thompson sampling},
  author={Dai, Zhongxiang and Shu, Yao and Low, Bryan Kian Hsiang and Jaillet, Patrick},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23331--23344},
  year={2022}
}


@misc{li2024ensemble++,
 archiveprefix = {arXiv},
 author = {Li, Yingru and Xu, Jiawei and Baoxiang Wang and Luo, Zhi-Quan},
 eprint = {2407.13195},
 howpublished = {Preprint},
 note = {An early version "Adaptive Foundation Models for Online Decisions: HyperAgent with Fast Incremental Uncertainty Estimation" presented at ICML 2024 Workshops: (1) "Aligning Reinforcement Learning Experimentalists and Theorists"; (2) "Automated Reinforcement Learning: Exploring Meta-Learning, AutoML, and LLMs"},
 primaryclass = {cs.LG},
 title = {Scalable Exploration via Ensemble++}
}

@inproceedings{li2024hyperagent,
  title         = {{Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent}},
  author        = {Li, Yingru and Xu, Jiawei and Han, Lei and Luo, Zhi-Quan},
  booktitle     = {The 41st International Conference on Machine Learning (ICML)},
  year          = {2024},
  series        = {Proceedings of Machine Learning Research},
  eprint        = {2402.10228},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{osband2015bootstrapped,
  title={Bootstrapped thompson sampling and deep exploration},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1507.00300},
  year={2015}
}


@InProceedings{local-uncertainty,
  title = 	 {Thompson Sampling via Local Uncertainty},
  author =       {Wang, Zhendong and Zhou, Mingyuan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10115--10125},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  abstract = 	 {Thompson sampling is an efficient algorithm for sequential decision making, which exploits the posterior uncertainty to address the exploration-exploitation dilemma. There has been significant recent interest in integrating Bayesian neural networks into Thompson sampling. Most of these methods rely on global variable uncertainty for exploration. In this paper, we propose a new probabilistic modeling framework for Thompson sampling, where local latent variable uncertainty is used to sample the mean reward. Variational inference is used to approximate the posterior of the local variable, and semi-implicit structure is further introduced to enhance its expressiveness. Our experimental results on eight contextual bandit benchmark datasets show that Thompson sampling guided by local uncertainty achieves state-of-the-art performance while having low computational complexity.}
}



@article{zhang2020neural,
  title={Neural thompson sampling},
  author={Zhang, Weitong and Zhou, Dongruo and Li, Lihong and Gu, Quanquan},
  journal={arXiv preprint arXiv:2010.00827},
  year={2020}
}

@article{jospin2022hands,
  title={Hands-on Bayesian neural networks—A tutorial for deep learning users},
  author={Jospin, Laurent Valentin and Laga, Hamid and Boussaid, Farid and Buntine, Wray and Bennamoun, Mohammed},
  journal={IEEE Computational Intelligence Magazine},
  volume={17},
  number={2},
  pages={29--48},
  year={2022},
  publisher={IEEE}
}

@article{casella1985introduction,
  title={An introduction to empirical Bayes data analysis},
  author={Casella, George},
  journal={The American Statistician},
  volume={39},
  number={2},
  pages={83--87},
  year={1985},
  publisher={Taylor \& Francis}
}

@article{hullermeier2021aleatoric,
  title={Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods},
  author={H{\"u}llermeier, Eyke and Waegeman, Willem},
  journal={Machine Learning},
  volume={110},
  pages={457--506},
  year={2021},
  publisher={Springer}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  year={2015},
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}


@inproceedings{foster2020beyond,
  title={Beyond ucb: Optimal and efficient contextual bandits with regression oracles},
  author={Foster, Dylan and Rakhlin, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={3199--3210},
  year={2020},
  organization={PMLR}
}

@article{foster2020instance,
  title={Instance-dependent complexity of contextual bandits and reinforcement learning: A disagreement-based perspective},
  author={Foster, Dylan J and Rakhlin, Alexander and Simchi-Levi, David and Xu, Yunzong},
  journal={arXiv preprint arXiv:2010.03104},
  year={2020}
}

@book{gelman2013bayesian,
  title={Bayesian Data Analysis, Third Edition},
  author={Gelman, A. and Carlin, J.B. and Stern, H.S. and Dunson, D.B. and Vehtari, A. and Rubin, D.B.},
  isbn={9781439840955},
  lccn={2013039507},
  series={Chapman \& Hall/CRC Texts in Statistical Science},
  url={https://books.google.com/books?id=ZXL6AQAAQBAJ},
  year={2013},
  publisher={Taylor \& Francis}
}

@article{efron2014two,
  title={Two modeling strategies for empirical Bayes estimation},
  author={Efron, Bradley},
  journal={Statistical science: a review journal of the Institute of Mathematical Statistics},
  volume={29},
  number={2},
  pages={285},
  year={2014},
  publisher={NIH Public Access}
}

@incollection{robbins1992empirical,
  title={An empirical Bayes approach to statistics},
  author={Robbins, Herbert E},
  booktitle={Breakthroughs in Statistics: Foundations and basic theory},
  pages={388--394},
  year={1992},
  publisher={Springer}
}

 @book{pml1Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: An introduction",
 publisher = "MIT Press",
 year = 2022,
 url = "probml.ai"
}



@article{normand1999meta,
  title={Meta-analysis: formulating, evaluating, combining, and reporting},
  author={Normand, Sharon-Lise T},
  journal={Statistics in medicine},
  volume={18},
  number={3},
  pages={321--359},
  year={1999},
  publisher={Wiley Online Library}
}

@misc{SASpackage,
  title={SAS/STAT 15.1 User’s Guide The MIXED Procedure},
  publisher={SAS Institute Inc.},
  year={2018},
  url={https://documentation.sas.com/api/collections/pgmsascdc/9.4_3.4/docsets/statug/content/mixed.pdf?locale=en#nameddest=statug_mixed_details01}
}

@inproceedings{osband2023approximate,
  title={Approximate thompson sampling via epistemic neural networks},
  author={Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Ibrahimi, Morteza and Lu, Xiuyuan and Van Roy, Benjamin},
  booktitle={Uncertainty in Artificial Intelligence},
  year={2023},
  organization={PMLR}
}

@book{rubin:1987,
  added-at = {2009-10-28T04:42:52.000+0100},
  author = {Rubin, D. B.},
  biburl = {https://www.bibsonomy.org/bibtex/20a72dbca78fbd5bc8ba192f31f5d5f2f/jwbowers},
  date-added = {2007-09-03 22:45:16 -0500},
  date-modified = {2007-09-03 22:45:16 -0500},
  interhash = {ec0d6b5ac7fe288d46c91a4158ed0777},
  intrahash = {0a72dbca78fbd5bc8ba192f31f5d5f2f},
  keywords = {Bayesian Missing Sample approach data; survey;},
  pages = 258,
  publisher = {Wiley},
  timestamp = {2009-10-28T04:43:19.000+0100},
  title = {Multiple Imputation for Nonresponse in Surveys},
  year = 1987
}

@article{gawlikowski2023survey,
  title={A survey of uncertainty in deep neural networks},
  author={Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and others},
  journal={Artificial Intelligence Review},
  volume={56},
  number={Suppl 1},
  pages={1513--1589},
  year={2023},
  publisher={Springer}
}

@article{dwaracherla2020hypermodels,
  title={Hypermodels for exploration},
  author={Dwaracherla, Vikranth and Lu, Xiuyuan and Ibrahimi, Morteza and Osband, Ian and Wen, Zheng and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2006.07464},
  year={2020}
}

@inproceedings{hyperagent,
  title={Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent},
  author={Li, Yingru and Xu, Jiawei and Han, Lei and Luo, Zhi-Quan},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{osband2022neural,
  title={The neural testbed: Evaluating joint predictions},
  author={Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Lu, Xiuyuan and Ibrahimi, Morteza and Lawson, Dieterich and Hao, Botao and O'Donoghue, Brendan and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12554--12565},
  year={2022}
}

@article{azur2011multiple,
  title={Multiple imputation by chained equations: what is it and how does it work?},
  author={Azur, Melissa J and Stuart, Elizabeth A and Frangakis, Constantine and Leaf, Philip J},
  journal={International journal of methods in psychiatric research},
  volume={20},
  number={1},
  pages={40--49},
  year={2011},
  publisher={Wiley Online Library}
}

@inproceedings{liu2016prior,
  title={On the prior sensitivity of thompson sampling},
  author={Liu, Che-Yu and Li, Lihong},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={321--336},
  year={2016},
  organization={Springer}
}
@article{wen2021predictions,
  title={From predictions to decisions: The importance of joint predictive distributions},
  author={Wen, Zheng and Osband, Ian and Qin, Chao and Lu, Xiuyuan and Ibrahimi, Morteza and Dwaracherla, Vikranth and Asghari, Mohammad and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2107.09224},
  year={2021}
}

@article{qin2022analysis,
  title={An analysis of ensemble sampling},
  author={Qin, Chao and Wen, Zheng and Lu, Xiuyuan and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21602--21614},
  year={2022}
}

@book{ramachandran2020mathematical,
  title={Mathematical statistics with applications in R},
  author={Ramachandran, Kandethody M and Tsokos, Chris P},
  year={2020},
  publisher={Academic Press}
}


@article{sutton2019bitter,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  volume={13},
  number={1},
  pages={38},
  year={2019}
}

@article{li2021multi,
  title={A multi-resolution theory for approximating infinite-p-zero-n: Transitional inference, individualized predictions, and a world without bias-variance tradeoff},
  author={Li, Xinran and Meng, Xiao-Li},
  journal={Journal of the American Statistical Association},
  year={2021},
  publisher={Taylor \& Francis}
}




@article{GargTsLiVa22,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume=35,
  pages={30583--30598},
  year=2022
}

@article{XieRaLiMa21,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv:2111.02080 [cs.CL]},
  year=2021
}

@book{DeFinetti17,
  title={Theory of probability: A critical introductory treatment},
  author={De Finetti, Bruno},
  volume=6,
  year=2017,
  publisher={John Wiley \& Sons}
}

@inproceedings{DeFinetti37,
  title={La pr{\'e}vision: ses lois logiques, ses sources subjectives},
  author={De Finetti, Bruno},
  booktitle={Annales de l'institut Henri Poincar{\'e}},
  volume=7,
  number=1,
  pages={1--68},
  year=1937
}


@article{ZhangZhYaWa23,
  title={What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization},
  author={Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv:2305.19420 [stat.ML]},
  year={2023}
}

@article{Roberts65,
  title={Probabilistic prediction},
  author={Roberts, Harry V},
  journal={Journal of the American Statistical Association},
  volume={60},
  number={309},
  pages={50--62},
  year={1965},
  publisher={Taylor \& Francis}
}

@article{Ericson69,
  title={Subjective Bayesian models in sampling finite populations},
  author={Ericson, William A},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={31},
  number={2},
  pages={195--224},
  year={1969},
  publisher={Oxford University Press}
}


@article{zhou2021semi,
  title={Semi-supervised learning},
  author={Zhou, Zhi-Hua and Zhou, Zhi-Hua},
  journal={Machine Learning},
  year={2021},
  publisher={Springer}
}

@article{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  publisher={University of Wisconsin-Madison Department of Computer Sciences}
}

@article{jonsson1998automated,
  title={Automated covariate model building within NONMEM},
  author={Jonsson, E Niclas and Karlsson, Mats O},
  journal={Pharmaceutical research},
  volume={15},
  pages={1463--1468},
  year={1998},
  publisher={Springer}
}

@article{langford2007epoch,
  title={The epoch-greedy algorithm for contextual multi-armed bandits},
  author={Langford, John and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={20},
  number={1},
  pages={96--1},
  year={2007},
  publisher={Citeseer}
}

@inproceedings{agarwal2017corralling,
  title={Corralling a band of bandit algorithms},
  author={Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  booktitle={Conference on Learning Theory},
  pages={12--38},
  year={2017},
  organization={PMLR}
}

@inproceedings{foster2020open,
  title={Open problem: Model selection for contextual bandits},
  author={Foster, Dylan J and Krishnamurthy, Akshay and Luo, Haipeng},
  booktitle={Conference on Learning Theory},
  pages={3842--3846},
  year={2020},
  organization={PMLR},
}

@article{foster2019model,
  title={Model selection for contextual bandits},
  author={Foster, Dylan J and Krishnamurthy, Akshay and Luo, Haipeng},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{papamarkou2022challenges,
  title={Challenges in Markov chain Monte Carlo for Bayesian neural networks},
  author={Papamarkou, Theodore and Hinkle, Jacob and Young, M Todd and Womble, David},
  journal={Statistical Science},
  volume={37},
  number={3},
  pages={425--442},
  year={2022},
  publisher={Institute of Mathematical Statistics}
}


@article{magris2023bayesian,
  title={Bayesian learning for neural networks: an algorithmic survey},
  author={Magris, Martin and Iosifidis, Alexandros},
  journal={Artificial Intelligence Review},
  volume={56},
  number={10},
  pages={11773--11823},
  year={2023},
  publisher={Springer}
}

@article{sauer1972density,
  title={On the density of families of sets},
  author={Sauer, Norbert},
  journal={Journal of Combinatorial Theory, Series A},
  volume={13},
  number={1},
  pages={145--147},
  year={1972},
  publisher={Elsevier}
}

@article{shelah1972combinatorial,
  title={A combinatorial problem; stability and order for models and theories in infinitary languages},
  author={Shelah, Saharon},
  journal={Pacific Journal of Mathematics},
  volume={41},
  number={1},
  pages={247--261},
  year={1972},
  publisher={Mathematical Sciences Publishers}
}

@inproceedings{beygelzimer2011contextual,
  title={Contextual bandit algorithms with supervised learning guarantees},
  author={Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={19--26},
  year={2011},
}

@article{psar2024,
  title = {Active Exploration via Autoregressive Generation of Missing Data},
  author = {Cai, Tiffany (Tianhui) and Namkoong, Hongseok and Russo, Daniel and Zhang, Kelly W},
  journal={arXiv preprint arXiv:2405.19466},
  year = {2024},
}


@inproceedings{
gouverneur2024an,
title={An Information-Theoretic Analysis of Thompson Sampling for Logistic Bandits},
author={Amaury Gouverneur and Borja Rodr{\'\i}guez G{\'a}lvez and Tobias Oechtering and Mikael Skoglund},
booktitle={NeurIPS Workshop on Bayesian Decision-making and Uncertainty},
year={2024},
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  year={2020}
}



@InProceedings{infotheoreticNonstationary,
  title = 	 {An Information-Theoretic Analysis of Nonstationary Bandit Learning},
  author =       {Min, Seungki and Russo, Daniel},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  year = 	 {2023},
  series = 	 {Proceedings of Machine Learning Research},
  pdf = 	 {https://proceedings.mlr.press/v202/min23c/min23c.pdf},
  abstract = 	 {In nonstationary bandit learning problems, the decision-maker must continually gather information and adapt their action selection as the latent state of the environment evolves. In each time period, some latent optimal action maximizes expected reward under the environment state. We view the optimal action sequence as a stochastic process, and take an information-theoretic approach to analyze attainable performance. We bound per-period regret in terms of the entropy rate of the optimal action process. The bound applies to a wide array of problems studied in the literature and reflects the problem’s information structure through its information-ratio.}
}
