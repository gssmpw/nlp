@inproceedings{decisionTransformer,
 author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Decision Transformer: Reinforcement Learning via Sequence Modeling},
 year = {2021}
}

@article{dwaracherla2020hypermodels,
  title={Hypermodels for exploration},
  author={Dwaracherla, Vikranth and Lu, Xiuyuan and Ibrahimi, Morteza and Osband, Ian and Wen, Zheng and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2006.07464},
  year={2020}
}

@inproceedings{ensembleSampling,
 author = {Qin, Chao and Wen, Zheng and Lu, Xiuyuan and Van Roy, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 title = {An Analysis of Ensemble Sampling},
 year = {2022}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@misc{li2024ensemble++,
 archiveprefix = {arXiv},
 author = {Li, Yingru and Xu, Jiawei and Baoxiang Wang and Luo, Zhi-Quan},
 eprint = {2407.13195},
 howpublished = {Preprint},
 note = {An early version "Adaptive Foundation Models for Online Decisions: HyperAgent with Fast Incremental Uncertainty Estimation" presented at ICML 2024 Workshops: (1) "Aligning Reinforcement Learning Experimentalists and Theorists"; (2) "Automated Reinforcement Learning: Exploring Meta-Learning, AutoML, and LLMs"},
 primaryclass = {cs.LG},
 title = {Scalable Exploration via Ensemble++}
}

@inproceedings{li2024hyperagent,
  title         = {{Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent}},
  author        = {Li, Yingru and Xu, Jiawei and Han, Lei and Luo, Zhi-Quan},
  booktitle     = {The 41st International Conference on Machine Learning (ICML)},
  year          = {2024},
  series        = {Proceedings of Machine Learning Research},
  eprint        = {2402.10228},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{liu2016prior,
  title={On the prior sensitivity of thompson sampling},
  author={Liu, Che-Yu and Li, Lihong},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={321--336},
  year={2016},
  organization={Springer}
}

@InProceedings{local-uncertainty,
  title = 	 {Thompson Sampling via Local Uncertainty},
  author =       {Wang, Zhendong and Zhou, Mingyuan},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10115--10125},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  abstract = 	 {Thompson sampling is an efficient algorithm for sequential decision making, which exploits the posterior uncertainty to address the exploration-exploitation dilemma. There has been significant recent interest in integrating Bayesian neural networks into Thompson sampling. Most of these methods rely on global variable uncertainty for exploration. In this paper, we propose a new probabilistic modeling framework for Thompson sampling, where local latent variable uncertainty is used to sample the mean reward. Variational inference is used to approximate the posterior of the local variable, and semi-implicit structure is further introduced to enhance its expressiveness. Our experimental results on eight contextual bandit benchmark datasets show that Thompson sampling guided by local uncertainty achieves state-of-the-art performance while having low computational complexity.}
}

@article{lu2017ensemble,
  title={Ensemble sampling},
  author={Lu, Xiuyuan and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{mukherjee2024pretraining,
  title={Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning},
  author={Mukherjee, Subhojyoti and Hanna, Josiah P and Xie, Qiaomin and Nowak, Robert},
  journal={arXiv preprint arXiv:2406.05064},
  year={2024}
}

@article{osband2015bootstrapped,
  title={Bootstrapped thompson sampling and deep exploration},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1507.00300},
  year={2015}
}

@inproceedings{osband2023approximate,
  title={Approximate thompson sampling via epistemic neural networks},
  author={Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Ibrahimi, Morteza and Lu, Xiuyuan and Van Roy, Benjamin},
  booktitle={Uncertainty in Artificial Intelligence},
  year={2023},
  organization={PMLR}
}

@inproceedings{riquelme2018deep,
  title={Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling},
  author={Riquelme, Carlos and Tucker, George and Snoek, Jasper},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{zhang2020neural,
  title={Neural thompson sampling},
  author={Zhang, Weitong and Zhou, Dongruo and Li, Lihong and Gu, Quanquan},
  journal={arXiv preprint arXiv:2010.00827},
  year={2020}
}

