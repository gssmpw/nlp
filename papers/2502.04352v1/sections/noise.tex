\section{Framework for Evaluating Robustness in Logical Deduction Tasks}
\label{sec:robust}
\textbf{Task definition.} Deductive reasoning is commonly formatted as binary \ac{QA} over a given context. 

The task input consists of a \ac{NL} question $q$ and a set of logical premises transformed into an \ac{NL} context $c$. The output of the task $a$ is one of the two possible answers: true or false, indicating whether the context supports or refutes the question. % $\{true,false\}$.

Formally, an \ac{NL} deductive reasoning task defines a function $f: (c,q) \rightarrow \{true, false\}$. 

\noindent \textbf{Robustness types.} Following prior work on investigating the robustness of \ac{LLM}s~\cite{sarlin2020superglue,liu2023recall}, we conceptualize two families of context perturbations.
First, inspired by adversarial robustness studies~\cite{nakamura-etal-2023-logicattack}, we posit that a reasoning system must be robust to adversarial \textbf{noise} (distractions), i.e., including irrelevant information in the context should not alter its prediction. 
Noise can shift the focus of a text, making it more difficult for an \ac{LLM} to capture the relevant context.
Second, a reasoning system must be robust to \textbf{counterfactual} shifts in the context. Namely, the system must be faithful to the provided context without including biases from implicit world models~\cite{liu2023recall}. 
If the context states that \emph{men are immortal}, the reasoning must overwrite its belief of men as mortal. 
By introducing counterfactual perturbations contradicting common sense, we investigate whether \ac{LLM}-based logical deduction methods use reasoning shortcuts or perform genuine reasoning.
We focus our perturbations on the \ac{NL} context $c$ rather than the question $q$ because it corresponds to background knowledge sources, which tend to vary significantly in real-world applications (e.g., compare reasoning based on a research article to reasoning over a list of facts). The perturbed task can be formalised as $f': (c',q) \rightarrow \{true, false\}$. 

Next, we detail our framework for evaluating the robustness of \ac{LLM}-based deduction methods to noise and counterfactual shifts.

\subsection{Adversarial Noise}
\textbf{Formalisation.} As monotonic reasoning, deductive reasoning must remain invariant to newly added irrelevant information, i.e., additional text that does not change the semantics of the premises used to derive the conclusion from the context.
% should not change when new irrelevant information is added. 
Let us consider a perturbed context that includes noisy information: $c' = d_1 \dots d_k c$, where each $d_i$ denotes a noisy sentence concatenated to $c$ for $k \in \{1,2,4\}$. The task function $f'$ must resolve to the same output as the original function $f$ for its proof to remain valid. To avoid any distractions that might change the original semantics (e.g., by breaking inter-sentence co-references), we append distractions only to the beginning of the context. %This avoids  

\noindent \textbf{Design of adversarial noise.}
We define three types of noise relevant to logical deduction tasks, which vary in their degree of referential content, formalisation complexity, and depth of logical reasoning. All noise sentences are sampled in a way that guarantees they do not impact the semantics of the context and the original proof. Figure \ref{fig:perturbation_example} (bottom-left) shows examples of the three noise types.

\paragraph{1.} \textbf{Encyclopedic (E)} perturbations are \ac{NL} sentences expressing factual information such as \textit{It is 21 km from Karimnagar, on the highway from Karimnagar to Peddapa}. They express real-world information following pragmatic principles of language~\cite{grice1975logic}.
Encyclopedic sentences are often difficult or even impossible to formalize in first-order logic. At the same time, encyclopedic facts are not connected by complex logical relations and lack the linguistic structure typical for reasoning contexts.  In summary, they represent world information, have a high formalisation complexity, and have low logical reasoning depth.
\paragraph{2.} \textbf{Logical (L)} statements provide a typical structure of reasoning contexts and contain only knowledge that can be natively formalised, such as \textit{All dresses are clothes}. Logical sentences include information about the world, albeit in a fictional form. The required formalisation usually requires more complex reasoning, like multi-hop inferences. Thus, logical perturbations introduce limited world information, have low formalisation complexity, and high reasoning depth.
\paragraph{3.} \textbf{Tautological (T)} perturbations are easily recognisable general statements, e.g., \emph{True is not false}. They may include negations and a small number of disjunctions or conjunctions. As such, they contain no referential information and require simple reasoning. However, their formalisation is often difficult because many first-order logic syntaxes do not consider predefined truth constants, like $\bot$, $\top$. In summary, tautologies in \ac{NL} contain no referential information, have high formalisation complexity, and have low reasoning depth.

\begin{figure}[!t]
    \centering
    \scriptsize
    \begin{tikzpicture}[node distance=1em and 0.5em, 
        every node/.style={align=left},
        label_style/.style={rectangle, rounded corners, fill=white}
        ]
        \node[text width=0.35\linewidth, rectangle, rounded corners, fill=lightgray] (original) {If an individual drinks water, they will be hydrated.};
        \node[label_style, above= 0.3em of original.north west, anchor=west, draw=gray]{ \tiny Original (O)};

        \node[draw, text width=0.275\linewidth, below= 1.4em of original.south west, anchor=north west, xshift=2.1em] (folio) {All dresses are clothes. If an individual ...};
        \node[label_style, above= 0.3em of folio.north west, anchor=west](folio_label){\tiny Logical (L)};
        \node[draw, text width=0.8\linewidth, below= of folio.south west, anchor=north west] (tautology) {Not true or false is not true. If an individual ...};
        \node[label_style, above=0.3em of tautology.north west, anchor=west]{\tiny Tautological (T)};
        \node[draw, text width=0.8\linewidth, below= of tautology.south west, anchor=north west] (wiki) {It is 21 km from Karimnagar, on the highway from Karimnagar to Peddapalli. If an individual ...};
        \node[label_style, above=0.35em of wiki.north west, anchor=west]{\tiny Encyclopedic (E)};
        \node[rotate=90, left= 1em of folio, xshift=1.5em] (label_distractions) {\textbf{Adversarial noise}};
        
        \node[draw, text width=0.475\linewidth, right= of original] (original_counter) {If an individual drinks water, they will not be hydrated.};
        \node[label_style, above= 0.4em of original_counter.north west, anchor=west]{\tiny Original ($\text{O}_C$)};
        \node[draw, label_style, below= 0.5em of original_counter, xshift=-3em](folio_counter){\tiny Logical ($\text{L}_C$)};
         \node[draw, label_style, right=of folio_counter](tautology_counter){\tiny Tautological ($\text{T}_C$)};
        \node[draw, label_style, below= 0.1em of folio_counter, xshift=2.5em](wiki_counter){\tiny Encyclopedic ($\text{E}_C$)};
  
        \node[above= 0.3em of original_counter] (counter_label) {\textbf{Counterfactual}};
        \node[draw,  fit={(counter_label)(original_counter)(tautology_counter)(wiki_counter)} ] (counter) {}; 
        \node[draw,  fit={(label_distractions)(folio_label)(wiki)(tautology_counter)(tautology)} ] (distractions) {}; 
    \end{tikzpicture}
    \caption{Example of a premise and its perturbations.}
    \label{fig:perturbation_example}
\end{figure}


\subsection{Counterfactual Shifts}


\textbf{Formalisation.}
We consider common sense contradictions by altering original statements in $c$ into counterfactual ones. The inclusion of counterfactual statements is motivated by the requirement for faithful reasoning. Namely, the validity of a deduction depends only on the structure of the logical form, which in turn should follow the original task description in the context and the question. To introduce counterfactual premises, we do not add new sentences; instead, we negate sentences from the original context $c$. Since original premises often state common sense knowledge, their negation naturally contradicts world knowledge. For example, in the modus ponens inference in Figure \ref{fig:overview}, we negate $mortal(X)$, stating that \emph{All men are immortal}. The altered context $c'$ is formalized as follows: $c'=neg(c)$, where $neg(c)$ negates one of the terms in the original context. The label of the resulting function $f'$ is opposite from that of the original function $f$.

\noindent \textbf{Design of counterfactual perturbations.} 
We assume a deductive reasoning dataset where the natural language form corresponds to a logical formula. Then, we introduce counterfactual perturbations by altering each logical formula using predefined rules that negate the formula (see full list of rules in the Appendix).
For example, we negate the consequent $\mathsf{q}(a)$ for the first implication of a constructive dilemma and adapt the inference to $\neg \mathsf{q}(a) \vee \mathsf{s}(a)$. 
Then, the negation to create the context $c'$ is manually added before the relevant terms in $c$, thus guaranteeing high data quality. 
Since the inference results in the opposite label for $f'$, we adapt the target label accordingly. Figure \ref{fig:perturbation_example} (top-right) shows an example of such a contradiction. Importantly, all counterfactual perturbations can be combined with noise perturbations, leading to counterfactual versions of the original ($O_C$), encyclopedic ($E_C$), logical ($L_C$), and tautological ($L_T$) sets.