\section{Experimental Setup}
\paragraph{Dataset details.}
The robustness evaluation is based on the \ac{FOL} part of the LogicBench (Eval)~\cite{mihir_parmar_logicbench_2023} dataset, containing $520$ samples with $180$ unique contexts. LogicBench systematically covers nine different inference rules. The samples are automatically generated by prompting GPT-3.5 and manually verified. $340$ of the total of $520$ samples are negative examples constructed by negating the conclusion. If the conclusion is a disjunction, each part of the disjunction is negated, resulting in a slight class imbalance. The authors report a mean accuracy of around $90\%$ for three human annotators. By applying our robustness framework from ยง\ref{sec:robust}, we obtain seven perturbed variants of LogicBench.

\paragraph{Perturbations.}
The noise sentences are randomly sampled from a source $s$. We sample encyclopedic perturbation sentences from $10,000$ abstracts of Wikipedia articles gathered via its API.
As a logical reasoning source, we use sentences from $1001$ contexts of the deduction \ac{QA} benchmark FOLIO~\cite{han_folio_2022}. 
As tautologies, we manually write $22$ sentences. All sentences use negations and, at most, one disjunction or conjunction. A complete list can be found in  Appendix~\ref{app:tautology}.
We randomly sample noise perturbations and add them to each sample. We do not alter the class distribution, i.e., we keep LogicBench's original class imbalance.

We consider unique contexts for eight out of the nine logical forms to create counterfactual statement perturbations, resulting in $160$ samples. We create a balanced dataset by altering between valid and invalid queries from LogicBench. 

\paragraph{Metrics.} We use \emph{accuracy} as a standard metric for classification tasks. We report \emph{execution rate} as the fraction of parsable texts and \emph{valid accuracy} as the accuracy on these parsable samples in the Appendix~\ref{app:experiments} due to space limitations. 

\paragraph{LLMs.} 
We test GPT 4o-mini, as well as a smaller and a larger variant for the three open-source \ac{LLM} families: Gemma-2 (9b and 27b), Mistral (7b and Small), and Llama 3.1 (8b and 70b).