\section{Methodological Framework}
We consider three key design dimensions: reasoning format, syntax, and error recovery mechanism to systematically analyse robust deductive reasoning capabilities for \ac{LLM}-based methods. We describe each of these dimensions and their representative approaches studied in this work. 

\subsection{Reasoning Format}
\ac{LLM}-based methods can either: a) operate without any explicit formalisation as informal reasoning systems and generate the answer based on their internal representation, or b) generate a formal representation of the given input, which is fed into a theorem prover to find a valid proof.   


The \textbf{informal} reasoning method instructs an \ac{LLM} to answer $q$ with \emph{Yes} or \emph{No} based on a context.
We employ few-shot prompting using three manually engineered in-context examples. To make the model more robust, two of the three in-context examples include distractions with irrelevant information. We explicitly note in the instruction part of the prompt that the provided contexts may contain irrelevant details.
The model is evaluated in two modes: \textit{direct} prompting, where it answers directly, and \textit{\ac{CoT}} prompting, where it generates step-by-step reasoning in natural language before generating an answer. To support \ac{CoT} prompting, we manually created in-context examples with fine-grained natural language reasoning steps designed to improve performance~\cite{wei_chain_2022}. 
The modelâ€™s answers are extracted using a regular expression (details in  Appendix~\ref{app:prompts}).


We include an \textbf{autoformalisation} method combining a symbolic theorem prover with an \ac{LLM}. This approach follows Logic-LM~\cite{liangming_pan_logiclm_2023} to formalise the context and query into symbolic representations, which are then deterministically evaluated. 
The process is divided into two subtasks: First, the model generates formal representations of the context and query, referred to as $c_{LF}$ (context logical form) and $q_{LF}$ (query logical form). Second, a symbolic theorem prover evaluates these logical forms to determine whether $q_{LF}$ can be derived from $c_{LF}$, producing a \emph{true} or \emph{false} outcome. This approach allows for a transparent and verifiable reasoning process grounded in logical consistency.
In practice, we prompt the \ac{LLM} to create the logical forms using the same three in-context examples as in the informal reasoning approach. The prompt is extended with instructions describing the formalisation syntax, following the methodology of Logic-LM. The resulting logical forms are parsed and combined into an \ac{AST}, which provides the input for a theorem prover. 


\subsection{Formalisation Syntax}
\label{subsec:syntax}

While the reasoning performance should be independent of the particular formalisation syntax, models may perform better with specific syntaxes, e.g., because of their frequency in the training data~\cite{razeghi2022impact}.
It is an open question whether the choice of syntax for formal reasoning impacts the model's translation performance and the robustness of its reasoning. Although all the syntaxes we consider represent \ac{FOL}, their surface form variations may influence the formalisation ability of \acp{LLM}.
The three evaluated syntaxes, illustrated in Figure~\ref{fig:formalisation_example}, contain identical information and are interchangeable, which ensures flexibility and allows the framework to include other syntaxes in the future:

\paragraph{FOL} is widely used in logic classes and academic papers. It incorporates mathematical symbols such as $\forall$ and $\exists$ and implicitly distinguishes between variables and individuals. This syntax is employed by Logic-LM~\cite{liangming_pan_logiclm_2023}.
\paragraph{R-FOL} is a variation of \ac{FOL} that explicitly differentiates variables and individuals by requiring variables to start with a question mark. This \emph{resolves} the syntax ambiguity in \ac{FOL}. 
\paragraph{TPTP} as the abbreviation of \emph{Thousands of Problems for Theorem Provers} is a Prolog-like formalisation language developed for theorem provers. It avoids mathematical symbols and mandates that variables begin with an uppercase letter. While TPTP supports higher-order logic, we limit our scope to its first-order fragment (fof), using a syntax derived from its official specification~\cite{Sut24}.

\begin{figure}[t]
    \centering
    \scriptsize
    \begin{tikzpicture}[node distance=0.2em and 0.2em,
        every node/.style={align=left,},
        fnode/.style={draw, },
        label_style/.style={rectangle, rounded corners, fill=white}
        ]        
        \node[text width=0.825\linewidth, rectangle, rounded corners, fill=lightgray,] (NL) {If an individual drinks water, they will be hydrated.};
        
        \node[fnode, text width=0.4\linewidth, below= 3em of NL.west, anchor=west] (FOL) {$\forall~x~drinkWater(x) \implies hydrated(x)$};
        \node[label_style, above= 1.6em of FOL.west, anchor=west]{\tiny FOL};
        
        \node[fnode, text width=0.4\linewidth, right= of FOL, anchor=west] (RFOL) {$\forall~?x~drinkWater(?x) \implies hydrated(?x)$};
        \node[label_style, above= 1.6em of RFOL.west, anchor=west]{\tiny R-FOL};

        \node[fnode, text width=0.825\linewidth, below= 3.2em of FOL.west, anchor=west] (TPTP) { \ttfamily fof(a0,axiom,![X]:drinkWater(X) => hydrated(X)). }; 
        \node[label_style, above= 1.1em of TPTP.west, anchor=west]{\tiny TPTP};
    \end{tikzpicture}
    \caption{Examples of the three syntaxes: FOL, R-FOL, and TPTP.}
    \label{fig:formalisation_example}
\end{figure}

\subsection{Error Recovery Mechanism}
To make autoformalisation more robust, we synthesise strategies for handling syntactic and semantic errors. Syntactic errors occur when the logical forms generated by \acp{LLM} do not follow the required syntax. Syntactic errors are easy to detect as logical forms cannot be parsed if they violate grammatical rules. In contrast, semantic errors, such as incomplete context representation, are more challenging to identify and resolve. We apply task-specific heuristics to identify suspicious constructs that lead to semantic errors and generate warnings. Unknown predicates as part of $q_{LF}$ are one example of such a construct, because they indicate an incomplete context. 
We consider four strategies for handling these errors:

\paragraph{No recovery.} The baseline approach does not attempt to correct errors. Instead, we predict a random value, \emph{true} or \emph{false}, as a fallback strategy. We avoid introducing an evaluation bias associated with more complex strategies, such as \ac{CoT}-based refinement, which is commonly done in prior work~\cite{liangming_pan_logiclm_2023,kirtania_logic-lm_2024}, as this would blur the comparison with other methods.
\paragraph{Error type feedback.} The \ac{LLM} is prompted to refine the logical form using a generic parsing error message, such as \emph{'parsing error'}. This type of message does not need a parser with an error handler, though it fails to point to specific errors in the logical form. 
Prior work has shown the effectiveness of this simple feedback method~\cite{liangming_pan_logiclm_2023}.
\paragraph{Error message feedback.} A more detailed approach where the \ac{LLM} is given specific feedback, highlighting the exact parts of the logical form that violate the syntax. Creating this kind of feedback necessitates an error-handling strategy for the parser. For example, the missing argument in $man \wedge mortal(Socrates)$ results in the error message: \emph{mismatched input '$\wedge$' expecting '('}.
Using error messages from parsers as feedback to improve \acp{LLM} performance when synthesizing a formal language has shown promising results in code generation~\cite{zhang-etal-2023-self,jiang-etal-2024-leanreasoner}.
\paragraph{Warning feedback.} This strategy extends the error message with warnings generated from heuristics to recognize semantic errors, inspired by the ``soft'' critics in the LLM-modulo method~\cite{kambhampati2024llms}, where it has been shown to enhance robustness. Notably, soft critics have not been incorporated in prior \ac{LLM}-based methods for logical deduction.