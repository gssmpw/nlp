\section{Related works}
Parameter-efficient fine-tuning (PEFT) entails selectively optimizing a subset of parameters within a large pre-trained model while leaving the core model architecture intact for adaptation purposes \cite{liu2024alora,tian2024fanlora,zheng2024sca,zhang2024milora,Ding2022DeltaTA,Zhang2023LearnedAA,zhu-tan-2023-spt,Cui2023UltraFeedbackBL,zheng2024nat4at,zhu2023acf,gao2023f,zuo-etal-2022-continually,zhang-etal-2022-pcee,sun-etal-2022-simple,zhu-etal-2021-gaml,Zhu2021MVPBERTMP,li-etal-2019-pingan,zhu2019panlp,zhu2019dr,zhou2019analysis}. In contrast, addition-based techniques involve integrating extra neural components or parameters into the existing model framework. Notable contributions in this domain include Adapter \cite{houlsby2019parameter,Rckl2020AdapterDropOT,Zhang2023LearnedAA}, Prefix tuning \cite{Li2021PrefixTuningOC}, Prompt tuning \cite{lester2021power}, P-tuning V2 \cite{Liu2022PTuningPT,zhu2024iapt}, (IA)$^{3}$ \cite{Liu2022FewShotPF}, and BitFit \cite{BenZaken2021BitFitSP}. Conversely, specification-based methods involve the explicit designation of parameters that are either adjustable or subject to pruning \cite{BenZaken2021BitFitSP,guo-etal-2021-parameter,zhao-etal-2020-masking,zheng2024chimera}. The reparameterization-based strategies have garnered significant interest \cite{hu2021lora}. These approaches convert the parameters being optimized into a format that is both low-rank and parameter-efficient. Such PEFT methods are underpinned by the insight that the dimensionality intrinsic to fine-tuning is relatively low \cite{aghajanyan-etal-2021-intrinsic}. LoRA \cite{hu2021lora}, for instance, posits that the variation in weights during tuning is characterized by a low intrinsic rank, and thus focuses on optimizing the low-rank factorization of the weight matrix changes. PEFT techniques have found broad application, particularly with the rise of open-source large-scale language models \cite{2023arXiv230318223Z} and the trend of tailoring these models to specific use cases through instruction tuning \cite{alpaca,2023arXiv230514314D}.


In this research, we introduce a novel framework known as PARA, which is designed for the parameter-efficient fine-tuning of Large Language Models (LLMs). This approach not only enhances efficiency during LLM inference but also delivers superior performance across various downstream applications.