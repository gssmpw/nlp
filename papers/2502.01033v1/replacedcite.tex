\section{Related works}
Parameter-efficient fine-tuning (PEFT) entails selectively optimizing a subset of parameters within a large pre-trained model while leaving the core model architecture intact for adaptation purposes ____. In contrast, addition-based techniques involve integrating extra neural components or parameters into the existing model framework. Notable contributions in this domain include Adapter ____, Prefix tuning ____, Prompt tuning ____, P-tuning V2 ____, (IA)$^{3}$ ____, and BitFit ____. Conversely, specification-based methods involve the explicit designation of parameters that are either adjustable or subject to pruning ____. The reparameterization-based strategies have garnered significant interest ____. These approaches convert the parameters being optimized into a format that is both low-rank and parameter-efficient. Such PEFT methods are underpinned by the insight that the dimensionality intrinsic to fine-tuning is relatively low ____. LoRA ____, for instance, posits that the variation in weights during tuning is characterized by a low intrinsic rank, and thus focuses on optimizing the low-rank factorization of the weight matrix changes. PEFT techniques have found broad application, particularly with the rise of open-source large-scale language models ____ and the trend of tailoring these models to specific use cases through instruction tuning ____.


In this research, we introduce a novel framework known as PARA, which is designed for the parameter-efficient fine-tuning of Large Language Models (LLMs). This approach not only enhances efficiency during LLM inference but also delivers superior performance across various downstream applications.