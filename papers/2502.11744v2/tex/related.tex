\section{Related Work}

\subsection{One-Shot Imitation Learning}
OSIL has been explored in various domains, such as image recognition \cite{vinyals2016matching, santoro2016meta}, generative models \cite{edwards2017towards}, and reinforcement learning \cite{duan2016rl}. The objective is to generalize the demonstrated behavior to novel instances or variations of the task with minimal prior knowledge or additional training.

In robotics, early OSIL works \cite{finn2017one, duan2017one, yu2018one} propose to leverage prior knowledge through meta-learning across a diverse set of robot tasks or skills. Following a ``pre-training and adapting" strategy, Wen et al. \cite{wen2022you, wen2022catgrasp} learn a category-level canonical representation during the pre-training stage and adapt it to new instances at inference. Similarly, Zhang et al. \cite{zhang2024one} conduct in-domain pre-training of a graph-based invariant region matching network and generalize to geometrically similar tools with a single demonstration. However, these methods face two major limitations: (1) they require in-domain pre-training, and (2) their generalization is restricted to geometrically or visually similar tools, struggling to handle out-of-domain tools with significant intra-function variations. Meanwhile, there has been a growing trend of using behavioral cloning (BC) models \cite{chi2023diffusion, zhao2023learning, ze20243d}, pre-trained on massive expert demonstrations, to generalize to unseen tools and configurations. We will later experimentally show that by clearly articulating the functional correspondences between tools, FUNCTO achieves better generalization performance compared to state-of-the-art BC methods, even with significantly less data.

Similar to our setup, \cite{heppert2024ditto} utilizes a transformer-based local feature matching model to compute the relative pose transformations between demonstration and test tools. Meanwhile, \cite{vitiello2023one} and \cite{di2024dinobot} leverage the off-the-shelf vision foundation model DINO \cite{oquabdinov2} to establish semantic correspondences between visually similar tools. In parallel, \cite{zhu2024vision} and \cite{li2024okami} employ global point set registration \cite{choi2015robust} to align demonstration and test tools. Similarly,  \cite{biza2023one} adopts shape warping \cite{rodriguez2018transferring} to correspond instances within the same category. Nevertheless, these methods assume that demonstration and test tools share highly similar shapes or appearances, limiting their generalization to novel tools with large geometric variations. In contrast, FUNCTO can handle significant intra-function variations to enable generalization to novel tools.

\subsection{Keypoint Representation for Tool Manipulation}
Keypoint representation has been extensively studied in tool manipulation \cite{manuelli2019kpam, manuelli2021keypoints, qin2020keto, xu2021affordance, liu2024moka, huangrekep, gao2023k, gao2024bi}, as it provides a compact and expressive way of encoding object information in terms of both semantics and actionability. For instance, KETO \cite{qin2020keto} introduces a task-specific keypoint generator trained with self-supervision for planar tool manipulation. KPAM \cite{manuelli2019kpam} uses 3D semantic keypoints as the tool representation to accomplish category-level manipulation tasks. Similarly, K-VIL \cite{gao2023k, gao2024bi} leverages a categorical correspondence model \cite{florence2018dense} to extract keypoint-based geometric constraints from one or few-shot human demonstrations.
% Similarly, AffKP \cite{xu2021affordance}, trained on UMD dataset \cite{myers2015affordance}, jointly performs affordance segmentation and keypoint detection. 

More recent works leverage foundation models to predict semantic keypoints in zero-shot and generate corresponding tool manipulation motions. MOKA \cite{liu2024moka} generates planar manipulation motions via mark-based visual prompting \cite{nasirianypivot}. While FUNCTO also employs a similar technique for functional keypoint detection, it can predict tool trajectories in 3D, enabling it to handle more complex tool manipulation tasks. ReKep \cite{huangrekep} proposes to represent a manipulation task as a list of task-specific keypoint constraints and predict semantic keypoints in a zero-shot manner. However, these constraints require significant manual effort, and the zero-shot keypoint extraction strategy is highly error-prone. In contrast, FUNCTO effortlessly extracts tool manipulation constraints and functional keypoints from human demonstration videos and does not require any object/task-specific knowledge to define the constraints. Furthermore, compared to the zero-shot keypoint proposal as in \cite{liu2024moka, huangrekep}, human demonstrations provide valuable cues for keypoint localization. Leveraging these cues enhances task performance, as demonstrated in the experiment section.


\subsection{Visual Correspondence in Robotics}
The ability to establish correspondences \cite{zhang2024tale} between seen and unseen scenarios is essential for robots to generalize. Techniques from the computer vision community, such as pose estimation \cite{wen2024foundationpose}, optical flow estimation \cite{bailer2017cnn}, and point tracking \cite{karaev2025cotracker}, have been widely adopted in robotic tasks and applications. In robotic manipulation, DON \cite{florence2018dense} learns dense visual correspondences with self-supervision for transferring grasps across visually similar object instances. Building on this concept, TransGrasp \cite{wen2022transgrasp} adopts Deformed Implicit Field \cite{deng2021deformed} to build shape correspondences within the same object category for grasp transfer. More recently, NDF \cite{simeonov2022neural} proposes a neural implicit representation to learn categorical descriptors from few-shot demonstrations. While these approaches focus on building visual correspondences within the same category, FUNCTO extends this capability to establishing functional correspondences, even in the presence of significant intra-function variations. 

FUNCTO is also closely related to affordance theory \cite{gibson1977theory} and the functional correspondence problem \cite{lai2021functional}. A common principle shared by FUNCTO and these works is that correspondences should extend beyond geometric or visual similarity to incorporate functional relevance.



















