\documentclass[conference]{IEEEtran}
\usepackage{times}

% numbers option provides compact numerical references in the text. 
\usepackage[numbers]{natbib}
\usepackage{multicol}
\usepackage[bookmarks=true]{hyperref}

% % Figures packages -------------------------------
\usepackage{graphicx}	      % allows figures
\usepackage{float}
% \usepackage{caption}
% \usepackage{subcaption}
\usepackage{xcolor}



% % Math Packages ----------------------------------
% \usepackage{amsmath}
\usepackage{newtxmath}        % font for math

% \pdfinfo{
%    /Author (Homer Simpson)
%    /Title  (Robots: Our new overlords)
%    /CreationDate (D:20101201120000)
%    /Subject (Robots)
%    /Keywords (Robots;Overlords)
% }
\newcommand{\GG}[1]{{\color{blue}{GG: #1}}}
\newcommand{\DP}[1]{{\color{green}{DP: #1}}}

\setlength{\belowcaptionskip}{0pt}

\begin{document}

% paper title
\title{Vision-based Geo-Localization of Future Mars Rotorcraft in Challenging Illumination Conditions}
%\title{Geometry-aided Map-based Localization of Future Mars Rotorcraft in Challenging Illumination Conditions}

% You will get a Paper-ID when submitting a pdf file to the conference system
%\author{Author Names Omitted for Anonymous Review. Paper-ID 636}

% \author{\authorblockN{Michael Shell}
% \authorblockA{School of Electrical and\\Computer Engineering\\
% Georgia Institute of Technology\\
% Atlanta, Georgia 30332--0250\\
% Email: mshell@ece.gatech.edu}
% \and
% \authorblockN{Homer Simpson}
% \authorblockA{Twentieth Century Fox\\
% Springfield, USA\\
% Email: homer@thesimpsons.com}
% \and
% \authorblockN{James Kirk\\ and Montgomery Scott}
% \authorblockA{Starfleet Academy\\
% San Francisco, California 96678-2391\\
% Telephone: (800) 555--1212\\
% Fax: (888) 555--1212}}

% \makeatletter
% \def\blfootnote{\xdef\@thefnmark{}\@footnotetext}
% \makeatother

% \author{
% \authorblockN{Dario Pisanti\authorrefmark{1},
% Robert Hewitt\authorrefmark{2}*,
% Roland Brockers\authorrefmark{1}
% Georgios Georgakis\authorrefmark{1}}
% \authorblockA{\authorrefmark{1}Jet Propulsion Lab, California Institute of Technology\\
% \authorblockA{\authorrefmark{2}Torc Robotics}}
% }

% \author{
% \authorblockN{Dario Pisanti\textsuperscript{1},
% Robert Hewitt\textsuperscript{2*},
% Roland Brockers\textsuperscript{1},
% Georgios Georgakis\textsuperscript{1}}
% \authorblockA{\textsuperscript{1}Jet Propulsion Lab, California Institute of Technology\\
% \authorblockA{\textsuperscript{2}Torc Robotics}
% }
% }

\author{
\authorblockN{Dario Pisanti\textsuperscript{1},
Robert Hewitt\textsuperscript{1},
Roland Brockers\textsuperscript{1},
Georgios Georgakis\textsuperscript{1}}
\authorblockA{\textsuperscript{1}Jet Propulsion Lab, California Institute of Technology\\
%\authorblockA{\textsuperscript{2}Torc Robotics}
}
}

% avoiding spaces at the end of the author lines is not a problem with
% conference papers because we don't use \thanks or \IEEEmembership


% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\authorblockN{Michael Shell\authorrefmark{1},
%Homer Simpson\authorrefmark{2},
%James Kirk\authorrefmark{3}, 
%Montgomery Scott\authorrefmark{3} and
%Eldon Tyrell\authorrefmark{4}}
%\authorblockA{\authorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: mshell@ece.gatech.edu}
%\authorblockA{\authorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\authorblockA{\authorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\authorblockA{\authorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}


\maketitle

\begin{abstract}
Planetary exploration using aerial assets has the potential for unprecedented scientific discoveries on Mars. While NASA's Mars helicopter Ingenuity proved flight in Martian atmosphere is possible, future Mars rotocrafts will require advanced navigation capabilities for long-range flights. One such critical capability is Map-based Localization (MbL) which registers an onboard image to a reference map during flight in order to mitigate cumulative drift from visual odometry. However, significant illumination differences between rotocraft observations and a reference map prove challenging for traditional MbL systems, restricting the operational window of the vehicle. 
In this work, we investigate a new MbL system and propose Geo-LoFTR, a geometry-aided deep learning model for image registration that is more robust under large illumination differences than prior models. The system is supported by a custom simulation framework that uses real orbital maps to produce large amounts of realistic images of the Martian terrain. Comprehensive evaluations show that our proposed system outperforms prior MbL efforts in terms of localization accuracy under significant lighting and scale variations. Furthermore, we demonstrate the validity of our approach across a simulated Martian day.

%The new aerial mobility dimension enabled by Ingenuity has unlocked unprecedented potential for groundbreaking science investigations in astrobiology, geology and climate on Mars. The next generation of Martian rotorcraft will need advanced navigation capabilities to conduct long-range flights over diverse and challenging terrains. Accurate geo-localization within a global reference frame is essential to mitigate cumulative drift from on-board visual odometry, ensuring precise navigation during extended traverses. Absolute visual localization can be achieved in a map-based approach by matching real-time images from the rotorcraft's navigation camera with pre-referenced orbital maps stored on-board. However, significant illumination differences between query observations and on-board maps can challenge visual geo-localization performance, restricting the mission's operation envelope to certain times of day. This work investigates deep-learning-based methods to perform robust Map-based Localization (MbL) in challenging lighting. We proposed a novel multi-modal deep-learning framework that utilizes cross-attention mechanisms to fuse visual and depth data from ortho-projected maps and Digital Terrain Models (DTMs) obtained from orbital assets, effectively leveraging geometric context to learn illumination and scale invariance. To support training and validation, we developed a custom rendering framework to generate a synthetic Mars dataset with HiRISE ortho-images and DTMs, simulating aerial observations under varying lighting and altitude. Comprehensive evaluations show that our multi-modal method improves localization accuracy and robustness to a wide range of lighting offsets between maps and observations compared to single-modality models, including both deep-learning-based and traditional methods. Additionally, the integration of depth information has been shown to provide a degree of scale invariance.
\end{abstract}

\IEEEpeerreviewmaketitle

\input{sections/1_introduction}
\input{sections/2_related_work}
\input{sections/3_methodology}
%\input{sections/4_training_data}
\input{sections/5_mbl_eval}
\input{sections/6_limitations}
\input{sections/7_conclusion}
\input{sections/acknowledgements}

% \section*{Acknowledgments}
% The research was carried out at the Jet Propulsion Laboratory, California Institute of Technology, under a contract with the National Aeronautics and Space Administration (80NM0018D0004). For this review version: \textcopyright2025. All rights reserved.

%% Use plainnat to work nicely with natbib. 

\bibliographystyle{plainnat}
%\bibliography{references}
\bibliography{paper}

\end{document}


