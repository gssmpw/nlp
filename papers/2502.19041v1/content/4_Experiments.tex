\section{Experiments}
\subsection{Experimental Setup}
\textbf{Dataset}  Our jailbreak dataset is divided into two categories: \textbf{Original Dataset and Jailbreak Proliferation}. 

For the Original Dataset, we select known attack instances to cover as diverse an array of attack essences as possible. These are primarily categorized into two types: In-The-Wild  \citep{shen2024anything} and Human Red-Teaming  \citep{jiang2024wildteaming}.

For Jailbreak Proliferation, we apply eight different jailbreak attack methods (see Appendix \ref{sec:appendix A} for a detailed analysis) to perform data augmentation on the Original Dataset. This generates variants that preserve the core essence while introducing significant changes in surface patterns.

Our benign dataset consists of \textbf{Exaggerated Safety Behaviors and benign queries disguised using jailbreak strategies}. We choose XSTest\citep{rottger2023xstest} for the Exaggerated Safety Dataset and Stanford Alpaca\citep{alpaca} as the seed to perform data augmentation similar to that used for jailbreak prompts is employed for disguise.

\textbf{Models} To evaluate EDDF’s effectiveness, we experiment on representative LLMs with three varying scales and aligned LLMs: DeepSeek-R1-Distill-Qwen-14B\citep{guo2025deepseek}, Llama-3.1-8B Instruct\citep{dubey2024llama}, Qwen-plus\citep{yang2024qwen2}. We use Qwen for our comparison and ablation experiments. For data augmentation, we utilize GPT-4 \citep{achiam2023gpt} to generate the necessary data.

\textbf{Evaluation Metrics} We evaluate the efficacy of jailbreak attacks using the Attack Success Rate (ASR). Additionally, we employ the False Positive Rate (FPR) to assess the impact of defense mechanisms on benign user inputs. We implement a dual evaluation strategy: the Keyword-Based Evaluation Method and the Automated GPT-4 Evaluation\citep{hurst2024gpt}. The details of refusal keywords and the GPT-4 Evaluation prompt and see in Appendix \ref{sec:appendix D}.

\textbf{Comparison Baselines} To validate the effectiveness of EDDF, we compare it against several advanced defense methods. The methods considered for comparison include: Llama-Guard-3-8B: Llama Guard \citep{inan2023llama} is a supervised learning-based filtering mechanism designed to systematically assess input-output pairs for safety compliance. Intention Analysis\citep{zhang2024intention}: This method involves a two-stage process, first analyzing the primary intent behind user input and then generating responses that adhere to safety standards based on these analyses. Self-Reminder\citep{xie2023defending}: Self-Reminder improves security by incorporating reminder instructions into the LLM via system commands and user queries. Rapid Response  \citep{peng2024rapid}: Rapid Response adjusts defense strategies quickly after observing a small number of attack examples. It proposes five rapid response strategies, and we select Defense Prompt, Guard Few-shot, Embedding, and Regex for our experiments, excluding Guard Fine-tuning from consideration.

\begin{table}[htbp]
    \centering
    \small
    \begin{tabular}{@{}cccc@{}}
    \toprule
    & \multicolumn{2}{c}{\textbf{ASR (\%)}} &         \\ \cmidrule(lr){2-3}
    \multirow{-2}{*}{\textbf{Method}} & \textbf{\begin{tabular}[c]{@{}c@{}}Original \\ Dataset\end{tabular}}                         & \textbf{\begin{tabular}[c]{@{}c@{}}Jailbreak \\ Proliferation\end{tabular}}  & \multirow{-2}{*}{\textbf{FPR (\%)}} \\ \midrule
    EDDF (Ours)      & \textbf{5.82} & \textbf{5.71} & 2.18    \\
    Llama3-Guard           & 55.00         & 42.40        & 8.30  \\
    Intention Analysis     & 12.58         & 25.41        & 34.89 \\
    Self-Reminder          & 16.37         & 36.59        & 12.46 \\
    Embedding      & 36.40         & 44.69        & 12.27 \\
    Defense Prompt & 9.93          & 60.51        & 19.75 \\
    Guard Few-shot            & 71.47                                & 80.26         & \textbf{1.90}                \\
    Regex          & 46.03         & 65.15        & 8.71 \\ \bottomrule
    \end{tabular}
    \caption{ Comparison of our EADD and seven baselines under eight jailbreak methods in terms of Average ASR (\%) and FPR (\%) with qwen plus as the target model. The best average results are highlighted in bold. }
    \label{tab:comparison_results} 
\end{table}

\begin{figure}[ht] 
    \centering
    \includegraphics[width=\columnwidth]{Picture/attack_success_rates.pdf} 
    \caption{ Comparison of our EADD and seven baselines under eight jailbreak methods in terms of ASR (\%) and FPR (\%) with qwen plus as the target model.}
    \label{fig_method}
\end{figure}


\subsection{Main Results}
\textbf{Performance on various jailbreak attacks} In Table \ref{tab:comparison_results}, we present the ASR of various defense baselines. The observations are as follows:

\textbf{1. Original Dataset}: First, we independently evaluated all defense methods on the original dataset used for extracting attack essence. The results show that our method achieves a much lower ASR than other defenses. Additionally, our method effectively detects essences already stored in the offline vector database. This confirms the effectiveness of our essence matching mechanism.

\textbf{2. Jailbreak Proliferation}: Our proposed EDDF method performs well, with an average ASR of only 5\%, at least 20\% lower than other methods. It remains effective against attacks that are difficult for other defenses to handle (see figure \ref{fig_method}).
Some defense methods, such as Intention Analysis, Self Reminder, Defense Prompt, and Embedding, perform much worse on the Jailbreak Proliferation than on the Original Dataset. This highlights the limitations of overfitting surface-level patterns in the attack prompts. Specifically: Intention Analysis enhances defense by attaching the LLM-parsed query intent; Self Reminder adds safety prompts to the input prefix; Defense Prompt appends defensive suffixes. These methods work well against simple attacks but fail when facing more complex transformations. This shows that current LLMs can detect obvious jailbreak intent but struggle with more advanced jailbreak prompt variations. The Embedding method also has limitations. During training, it may only capture highly similar adversarial samples, leading to poor generalization. As a result, it cannot effectively counter diverse attack patterns.


These findings suggest that existing defenses focus too much on superficial jailbreak prompt features rather than analyzing the attack essence.

\noindent \textbf{Performance of helpfulness for benign queries} In our experiments, we selected exaggerated safety queries and benign queries disguised using jailbreak strategies as test data to evaluate the discrimination ability of different methods.
The results (see Table \ref{tab:comparison_results}) show that our method performs well in benign query identification, achieving an FPR of only 2.18\%, effectively distinguishing these hard-to-detect benign queries. It's worth noting that the Intention Analysis method exhibits a significantly high FPR of 34.89\%, likely due to the misleading effect of the jailbreak templates on the LLM, causing it to misinterpret the true intent of user queries as harmful.
This finding further indicates that directly relying on LLMs for intent analysis is unreliable, as adversarial examples can interfere with the model and lead to misclassification. In contrast, our method enhances LLM intent recognition by extracting the essence of attacks, improving accuracy while reducing the false rejection rate for benign queries.

Specially, to evaluate the robustness for our framework, we perform adaptive attacks using GPTFUZZER and PAIR. The experiment details are shown in \ref{sec:appendix A.2}.


\subsection{Ablation Experiments}
\subsubsection{Ablation Study on EDDF Components}
To further investigate the impact of the essential components of EDDF, we conduct an ablation study to investigate the impact of four key components: (1) the fine-grained judgment, (2) the storage of extracted essence, (3) the analysis of the user query's essence, and (4) the overall extraction of essences during both storage and query processing. The details of ablation settings are as follows.
\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{@{}ccc@{}}
    \toprule
    \textbf{component}    & \textbf{ASR (\%)}    & \textbf{FPR (\%)}    \\
    \midrule
    
    % \hdashline
    \begin{tabular}[c]{@{}c@{}}w/o Fine-Grained \\ Judgement \end{tabular}   & 35.41 ({\color[HTML]{FE0000}↑ 29.70\%})    & 36.29 ({\color[HTML]{FE0000}↑ 34.11\%})   \\
    \hdashline
    \begin{tabular}[c]{@{}c@{}}w/o Essence \\ Storage \end{tabular}   & 15.24 ({\color[HTML]{FE0000}↑ 9.53\%})   & 10.8 ({\color[HTML]{FE0000}↑ 8.62\%})  \\
    \hdashline
    \begin{tabular}[c]{@{}c@{}}w/o User \\ Essence \end{tabular}   & 21.66 ({\color[HTML]{FE0000}↑ 15.95\%})   & 9.40 ({\color[HTML]{FE0000}↑ 7.22\%})   \\
    \hdashline
    \begin{tabular}[c]{@{}c@{}}w/o Overall Essence \\ Process \end{tabular}  & 21.55 ({\color[HTML]{FE0000}↑ 15.84\%})   & 22.07 ({\color[HTML]{FE0000}↑ 19.89\%})   \\
    \hdashline
    \rowcolor{gray!15}
     & &  \\
    \rowcolor{gray!15}
    \multirow{-2}{*}{EDDF}  & \multirow{-2}{*}{\textbf{5.71}}     & \multirow{-2}{*}{\textbf{2.18}}     \\
    \bottomrule
    \end{tabular}
    % \begin{tabular}[c]{@{}c@{}}w/o Overall Essence \\ Process \end{tabular}  & 21.55 ({\color[HTML]{FE0000}↑ 15.84\%})   & 22.07 ({\color[HTML]{FE0000}↑ 19.89\%}) 
    \caption{ Average ASR (\%) and FPR (\%) of Ablation Experiments.}
    \label{tab:abaltion_results} 
\end{table}

\textbf{1. Impact of Fine-Grained Judgement}: In this setting, we retrieve the top-1 match from the vector database and directly classify it as harmful if its similarity score exceeds a predefined threshold; otherwise, it is considered benign. This essentially performs a coarse-grained assessment of whether the user query shares a similar essence with any stored entries in the offline vector database. The results (see Table \ref{tab:abaltion_results}) demonstrate that ablating the fine-grained judgment results in approximately a 30\% increase in ASR and a 34\% increase in the FPR. It clearly indicates that a coarse-grained screening mechanism alone is not enough. A more fine-grained deep analysis is needed to distinguish benign queries with similar essence from true jailbreak prompts.

\textbf{2. Impact of Essence Storage}: Instead of storing extracted essence representations, we directly store the raw jailbreak prompts as embeddings in the vector database. When a user query arrives, we first extract its essence and then match it against the stored jailbreak prompt database. The results (see Table \ref{tab:abaltion_results}) demonstrate that ablating essence storage results in approximately a 10\% increase in ASR and a 9\% increase in FPR. It suggests that essence storage plays a role in reducing attack success and false positives, contributing to overall system effectiveness.

\textbf{3. Impact of User Query Essence}: In this setting, we bypass essence extraction for the user query and directly use the raw query to search for similar essences in the database. The results (see Table \ref{tab:abaltion_results}) demonstrate that ablating user query essence analysis results in approximately a 16\% increase in ASR and a 7\% increase in FPR. It suggests that relying solely on prompt-based matching is not enough for accurate retrieval.

\textbf{4. Impact Overall Essence Process}: Here, neither the storage process nor the query processing involves essence extraction. Instead, we embed raw jailbreak prompts into the vector database and directly compare user query embeddings against this database. The results (see Table \ref{tab:abaltion_results}) demonstrate that removing the essence process results in approximately a 16\% increase in ASR and a 20\% increase in FPR. It suggests that relying solely on prompt-based matching is not enough for accurate retrieval similarly.

\subsubsection{Impact of Model Capability on Essence  Extraction}
We also conducted experiments on smaller-scale models, including Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-14B. Although ASR and FPR increased slightly, the final results (see Table \ref{fig_models}) still outperformed the baseline experiments. The findings indicate that even on 8B and 14B models, our method can extract high-quality essential features and make relatively accurate judgments. This demonstrates a certain degree of generalization across different models.
\begin{table}[h]
    \centering
    \small
    \begin{tabularx}{\linewidth}{@{}ccc@{}}
    \toprule
    \multicolumn{1}{c}{\textbf{Model}} & \textbf{ASR (\%)} & \textbf{FPR (\%)} \\ \midrule
        Meta-Llama-3.1-8B-instruct  & 25.93  & 17.17  \\
        DeepSeek-R1-Distill-Qwen-14B  & 24.67  & 12.73  \\
        Qwen-Plus  & {\textbf{5.71}}  & {\textbf{2.18}}  \\
    \bottomrule
    \end{tabularx}
    \caption{Average ASR (\%) and FPR (\%) of the Impact of Model Capability on Essence Extraction.}
    \label{fig_models}
\end{table}


\subsubsection{Effect of Hyperparameters on Model Performance}
Next, we explore the impact of the hyperparameters K and threshold $\tau$ on model performance. We tested K = {3, 5, 7, 10} (see Table \ref{fig_k}) and $\tau$ = {0.4, 0.5, 0.6, 0.7} (see Table \ref{fig_threshold}). Experimental results show that K = 5, $\tau$ = 0.5 is the optimal setting, effectively reducing both ASR and FPR.

A smaller K (e.g., 3) leads to insufficient retrieval, increasing ASR and FPR. In contrast, a larger K (e.g., 7 or 10) introduces noise, reducing matching accuracy. For $\tau$, a lower value (e.g., 0.4) decreases ASR but raises FPR, while a higher value (e.g., 0.6 or 0.7) relaxes the decision boundary, making it easier for attacks to bypass detection. Therefore, a moderate K and $\tau$ achieve the best balance between safety and FPR.

\begin{table}[htbp]
    \centering
    \small
    \setlength{\tabcolsep}{7mm}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    \textbf{Top K} & \textbf{ASR (\%)} & \textbf{FPR (\%)} \\ \midrule
        3  & 9.60  & 7.55   \\
        5  & {5.71}  & {2.18}   \\
        7  & 9.10  & 10.21  \\
        10 & 9.17   & 9.33  \\ \bottomrule
    \end{tabular}
    \caption{Average ASR and FPR of the Impact of Effect of k on Model Performance.}
    \label{fig_k}
\end{table}

\begin{table}[htbp]
    \centering
    \small
    \setlength{\tabcolsep}{7mm}
    \begin{tabular}{@{}ccc@{}}
    \toprule
    \textbf{threshold} & \textbf{ASR (\%)} & \textbf{FPR (\%)} \\ \midrule
    0.4                & 10.12      & 6.16       \\
    0.5                & {5.71}       & {2.18}       \\
    0.6                & 10.27     & 4.65      \\
    0.7                & 11.88     & 3.26      \\ \bottomrule
    \end{tabular}
    \caption{Average ASR and FPR of the Impact of Effect of Threshold on Model Performance.}
    \label{fig_threshold}
\end{table}