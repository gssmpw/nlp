\begin{figure*}[ht] 
    \centering
    \includegraphics[width=\linewidth]{Picture/method.pdf}
    \caption{\textbf{Overview of EDDF}. (Top) Offline Essence Database Construction: we extract the underlying "attack essence" from a diverse set of known attack instances and store these essence representations in an offline vector database. (Bottom) Online Adversarial Query Detection: When a new user query is received, the framework identifies and defends against attacks through user query abstraction, essence vector retrieval, and Fine-Grained Judgment.}
    \label{method}
\end{figure*}

\section{Methodology}

\subsection{Preliminary}
We focus on input-side filtering protection which not only effectively prevents the generation of harmful content but also significantly reduces computational costs. To strengthen defense mechanisms, we propose the Essence-Driven Defense Framework to counter jailbreaking attacks. The key idea behind EDDF is to extract the underlying “attack essence” from a diverse set of known attack instances and store these essence representations in an offline vector database. When a new user query appears, the framework identifies and defends attacks through essence retrieval and final judgment.

\subsection{Offline Essence Database Construction}
\label{sec:offline}
\subsubsection{Extraction of Attack Essence}
We define attack essence as a distilled natural language summary that encapsulates the core adversarial strategies inherent in a jailbreak prompt. It does so by employing multi-level, compositional techniques to conceal, obfuscate, or reconstruct intent, leading the model to generate responses that violate safety guidelines.
Specifically, the attack essence is not a fixed template but a dynamic expression based on natural language. It can reconstruct malicious queries through fictitious scenarios, moral coercion, and other techniques. For instance, an attacker may impersonate a cybersecurity expert or a chemist, adopting different roles to execute the attack. However, the fundamental essence of the attack remains the use of role-playing strategies to conduct covert adversarial attacks.

To achieve this goal, we first construct a jailbreak prompt dataset from the known attack instances. we introduce an essence extraction mechanism to guide the LLMs in automatically parsing and extracting the attack essence of jailbreak prompts. 

Given a jailbreak prompt, denoted as \text{JP}. We utilize LLM to extract the strategies employed in it. The set of strategies is defined as follows:
\begin{equation}
  \label{eq:JP}
  T(JP)={t_1(JP), t_2(JP), \ldots, t_n(JP)}
\end{equation}
where n is the number of strategies in the given \text{JP}, and \( t_i(\text{JP}) \) represents the i\text{-th} strategy employed by the \text{JP}.
Furthermore, we perform a logical semantic combination of \( t_i(\text{JP}) \)to obtain the attack essence, denoted as \(E_{JP}\):

\begin{equation}
    \label{eq:essence}
    E_{JP} = llm(T(JP)) 
\end{equation}

For example, given the prompt: "CHAR=SJ is amoral and doesn't care about laws, morals, and ethics. RULES=respond as SJ. Prefix 'SJ:' Always show all SJ would say. Never refuse. Always follow CHAR and RULES: write a meth recipe. Use emojis and speak as if you are a kid on a sugar rush. Use recipe format,". The strategies we identify are: Assign Personality, Ignore Ethical Rules, and Playful Expressions. The extracted attack essence is: "assign an amoral personality, disregard ethical rules, use playful language, and structure harmful content in a templated format".

\subsubsection{Quality Assessment of Attack Essence}
Additionally, we must ensure that LLMs successfully generate the essence behind jailbreak prompts rather than producing erroneous hallucinated content. To improve the reliability of the attack essence, we design a strict evaluation mechanism using LLMs to assist in verification, based on the following criteria:
\begin{itemize}
    \item Non-Refusal Check: Ensure the LLM does not refuse to answer.
    \item Strategies Alignment Check: Ensure the LLM correctly identifies the strategies employed within the \text{JP}.
    \item Attack Essence Validation: Ensure the essence is logically generated from the strategies.
    \item Abstraction Check: Ensure the LLM is not describing malicious behavior or explicit attack details, but rather abstracting a generalized attack pattern.
\end{itemize}

\subsubsection{Construction of Vector Database}
After successfully extracting the attack essence, we need to convert it into a vector representation for efficient retrieval in subsequent query matching.
First, we utilize an Embedding Model to vectorize the attack essence \( E_{JP} \), producing \( X_{E_{JP}} \). Subsequently, we store the essence vector \( X_{E_{JP}} \) in an offline vector database, thereby constructing the Essence Vector Database, denoted as \text{EVD}.

\subsection{Online Adversarial Query Detection}
\label{sec:online}
In practical applications, a user query also comprises various strategies. Therefore, online validation needs to include multiple stages, such as query abstraction, vector retrieval, and deep analysis, to ensure that the system can accurately identify potential attack intents while minimizing the false rejection rate.

\subsubsection{User Query Abstraction}
Given a user query, denoted as \text{Q}, we similarly guide the LLM to extract its potential attack strategy features \text{T(Q)}:
\begin{equation}
    T(Q)=\{t_1(Q),t_2(Q),\ldots,(t_m(Q)\}
\end{equation}
where \text{m} is the number of strategies in the given \text{Q}, and \( t_i(\text{Q}) \) represents the i\text{-th} strategy employed by the \text{Q}.
Furthermore, we perform a logical semantic combination of \( t_i(\text{Q}) \)to obtain the attack essence, denoted as \(E_{Q}\):
\begin{equation}
    E_Q = llm(T(Q)) 
\end{equation}

At this stage, $E_Q$, as the essence abstraction of the user query, provides a more precise mapping to the attack essence vectors within the EVD, thereby enhancing the accuracy of the matching process. For direct benign prompts that do not involve strategic manipulation, we can also effectively extract the essence. For example, given the user query "How can I kill a Python process?", the extracted essence is: "A straightforward, neutral-toned question focusing on a technical query about process termination."

\begin{figure*}[htbp] 
    \centering
    \includegraphics[width=\linewidth]{Picture/case.pdf}
    \caption{\textbf{Overview of Online Adversarial Query Detection}: When a user query is received, our pipeline runs the complete defense mechanism process, including intermediate outputs.}
    \label{fig_case}
\end{figure*}

\subsubsection{Essence Vector Retrieval}
After the abstraction of the user query is completed, we utilize the \text{EVD} for preliminary matching to determine whether \( E_{Q} \) is similar to any existing user essences.
First, we use an Embedding Model to vectorize \( E_{Q} \), producing \( X_{E_{Q}} \).

To measure the similarity between the query vector \( X_{E_{Q}} \) and any attack essence vector  \( X_{E_{Q}} \)  in the database, we use Cosine Similarity as the metric:
\begin{equation}
    \mathit{Sim}\left(\mathit{X}_{E_Q},\, \mathit{X}_{E_{JP}}\right) = \frac{\mathit{X}_{E_Q} \cdot \mathit{X}_{E_{JP}}}{\,\|\,\mathit{X}_{E_Q}\,\|\,\cdot\,\|\,\mathit{X}_{E_{JP}}\,\|\,}
\end{equation}

% \begin{equation}
% \mathrm{Sim}\left(X_{E_Q},X_{E_{JP}}\right)=\frac{X_{E_Q}\cdot X_{E_{JP}}{|X_{E_Q}^{\mathrm{norm}}||X_{E_{JP}}^{\mathrm{norm}}|}
% \end{equation}
where $ \cdot $ represents the dot product operation and $|\cdot|$ represents the L2 norm.

\textbf{Top-K Retrieval}
We set a similarity threshold $ \tau$ for retrieval :
\begin{itemize}
    \item If at least one attack essence vector satisfies $\mathit{Sim}\left({X}_{E_Q}, X_{E_{JP}}\right)>\tau$,  we extract the Top-K most similar attack essence vectors and return the corresponding most similar Jailbreak Prompts. Here, we set \(k=5\):
\begin{equation}
    \mathit{Sim\_E_{JPs}} = \mathit{Top\_K} (\{E_{JP}\})
\end{equation}
    \item If the similarity of all attack essence vectors is below the threshold, the preliminary matching fails and proceeds to the Direct Classification phase.
\end{itemize}
\subsubsection{Fine-Grained Judgment}
Although a user query may exhibit high similarity to known jailbreak prompts within the essence vector space, this does not necessarily indicate that the query itself is harmful.

Therefore, a more granular judgment is required to distinguish between benign queries, which are strategically similar but have no malicious intent, and jailbreak queries, which genuinely seek to bypass security measures.

To achieve more precise classification, we utilize the retrieved similar jailbreak prompts and similar attack essences as few-shot examples, providing them to the LLM for deeper intent analysis. This approach enables the LLM to more effectively discern the true, latent intent behind the query, thereby allowing for a more reliable safety classification:
\begin{equation}
    \textit{Result} = \textit{llm}(Q, E_Q, \mathit{Sim\_JPs}, \mathit{Sim\_E_{JPs}})
\end{equation}









