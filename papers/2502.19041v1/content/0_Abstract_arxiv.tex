\begin{abstract}
Although Aligned Large Language Models (LLMs) are trained to refuse harmful requests, they remain vulnerable to jailbreak attacks. Unfortunately, existing methods often focus on surface-level patterns, overlooking the deeper attack essences. As a result, defenses fail when attack prompts change, even though the underlying "attack essence" remains the same. To address this issue, we introduce EDDF, an \textbf{E}ssence-\textbf{D}riven \textbf{D}efense \textbf{F}ramework Against Jailbreak Attacks in LLMs. EDDF is a plug-and-play input-filtering method and operates in two stages: 1) offline essence database construction, and 2) online adversarial query detection. The key idea behind EDDF is to extract the "attack essence" from a diverse set of known attack instances and store it in an offline vector database. Experimental results demonstrate that EDDF significantly outperforms existing methods by reducing the Attack Success Rate by at least 20\%, underscoring its superior robustness against jailbreak attacks.

\textbf{\textcolor{red}{warning: Some of the examples may contain potentially harmful content!}}

\end{abstract}

\begin{figure*}[!hb] 
    \centering
    \includegraphics[width=0.9\linewidth]{Picture/motivation.pdf}
    \caption{\textbf{Comparison of three defense methods under Original Dataset and Jailbreak Proliferation (Aligned Model, Other Defences, and EDDF)}. (Left) In the original dataset, the aligned model (e.g., GPT-4) fails to defend, while other defenses and EDDF succeed. (Right) In the Jailbreak Proliferation dataset, where the attack surface pattern shifts significantly while the attack essence remains similar, the aligned model and other defenses both fail, but EDDF successfully defends.}
    \label{fig_motivation}
\end{figure*}