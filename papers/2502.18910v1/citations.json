[
  {
    "index": 0,
    "papers": [
      {
        "key": "baumgartNotAllFederated2024",
        "author": "Baumgart, Gustav A. and Shin, Jaemin and Payani, Ali and Lee, Myungjin and Kompella, Ramana Rao",
        "title": "Not {{All Federated Learning Algorithms Are Created Equal}}: {{A Performance Evaluation Study}}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "liFederatedOptimizationHeterogeneous",
        "author": "Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia",
        "title": "Federated {{Optimization}} in {{Heterogeneous Networks}}"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "karimireddySCAFFOLDStochasticControlled2020",
        "author": "Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha",
        "title": "{{SCAFFOLD}}: {{Stochastic Controlled Averaging}} for {{Federated Learning}}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "di2024survey",
        "author": "Di, Sheng and Liu, Jinyang and Zhao, Kai and Liang, Xin and Underwood, Robert and Zhang, Zhaorui and Shah, Milan and Huang, Yafan and Huang, Jiajun and Yu, Xiaodong and others",
        "title": "A survey on error-bounded lossy compression for scientific datasets"
      },
      {
        "key": "huang2024optimized",
        "author": "Huang, Jiajun and Di, Sheng and Yu, Xiaodong and Zhai, Yujia and Zhang, Zhaorui and Liu, Jinyang and Lu, Xiaoyi and Raffenetti, Ken and Zhou, Hui and Zhao, Kai and others",
        "title": "An optimized error-controlled mpi collective framework integrated with lossy compression"
      },
      {
        "key": "huang2023c",
        "author": "Huang, Jiajun and Di, Sheng and Yu, Xiaodong and Zhai, Yujia and Liu, Jinyang and Raffenetti, Ken and Zhou, Hui and Zhao, Kai and Chen, Zizhong and Cappello, Franck and others",
        "title": "C-Coll: Introducing error-bounded lossy compression into MPI collectives"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "acarFederatedLearningBased2021a",
        "author": "Acar, Durmus Alp Emre and Zhao, Yue and Navarro, Ramon Matas and Mattina, Matthew and Whatmough, Paul N. and Saligrama, Venkatesh",
        "title": "Federated {{Learning Based}} on {{Dynamic Regularization}}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "baumgartNotAllFederated2024",
        "author": "Baumgart, Gustav A. and Shin, Jaemin and Payani, Ali and Lee, Myungjin and Kompella, Ramana Rao",
        "title": "Not {{All Federated Learning Algorithms Are Created Equal}}: {{A Performance Evaluation Study}}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "liFederatedOptimizationHeterogeneous",
        "author": "Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia",
        "title": "Federated {{Optimization}} in {{Heterogeneous Networks}}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "karimireddySCAFFOLDStochasticControlled2020",
        "author": "Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha",
        "title": "{{SCAFFOLD}}: {{Stochastic Controlled Averaging}} for {{Federated Learning}}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "reddiAdaptiveFederatedOptimization2021",
        "author": "Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\\v c}n{\\'y}, Jakub and Kumar, Sanjiv and McMahan, H. Brendan",
        "title": "Adaptive {{Federated Optimization}}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "acarFederatedLearningBased2021a",
        "author": "Acar, Durmus Alp Emre and Zhao, Yue and Navarro, Ramon Matas and Mattina, Matthew and Whatmough, Paul N. and Saligrama, Venkatesh",
        "title": "Federated {{Learning Based}} on {{Dynamic Regularization}}"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "raffelExploringLimitsTransfer2023",
        "author": "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.",
        "title": "Exploring the {{Limits}} of {{Transfer Learning}} with a {{Unified Text-to-Text Transformer}}"
      },
      {
        "key": "zhangOPTOpenPretrained2022",
        "author": "Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke",
        "title": "{{OPT}}: {{Open Pre-trained Transformer Language Models}}"
      },
      {
        "key": "touvronLLaMAOpenEfficient2023",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume",
        "title": "{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "raffelExploringLimitsTransfer2023",
        "author": "Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.",
        "title": "Exploring the {{Limits}} of {{Transfer Learning}} with a {{Unified Text-to-Text Transformer}}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "zhangOPTOpenPretrained2022",
        "author": "Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke",
        "title": "{{OPT}}: {{Open Pre-trained Transformer Language Models}}"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "touvronLLaMAOpenEfficient2023",
        "author": "Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\\'e}e and Rozi{\\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume",
        "title": "{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "hanParameterEfficientFineTuningLarge2024",
        "author": "Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Jeff and Zhang, Sai Qian",
        "title": "Parameter-{{Efficient Fine-Tuning}} for {{Large Models}}: {{A Comprehensive Survey}}"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "heUnifiedViewParameterEfficient2022",
        "author": "He, Junxian and Zhou, Chunting and Ma, Xuezhe and {Berg-Kirkpatrick}, Taylor and Neubig, Graham",
        "title": "Towards a {{Unified View}} of {{Parameter-Efficient Transfer Learning}}"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "guoParameterEfficientTransferLearning2021",
        "author": "Guo, Demi and Rush, Alexander M. and Kim, Yoon",
        "title": "Parameter-{{Efficient Transfer Learning}} with {{Diff Pruning}}"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "valipourDyLoRAParameterEfficient2023",
        "author": "Valipour, Mojtaba and Rezagholizadeh, Mehdi and Kobyzev, Ivan and Ghodsi, Ali",
        "title": "{{DyLoRA}}: {{Parameter Efficient Tuning}} of {{Pre-trained Models}} Using {{Dynamic Search-Free Low-Rank Adaptation}}"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "maoUniPELTUnifiedFramework2022",
        "author": "Mao, Yuning and Mathias, Lambert and Hou, Rui and Almahairi, Amjad and Ma, Hao and Han, Jiawei and Yih, Wen-tau and Khabsa, Madian",
        "title": "{{UniPELT}}: {{A Unified Framework}} for {{Parameter-Efficient Language Model Tuning}}"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "liPrefixTuningOptimizingContinuous2021",
        "author": "Li, Xiang Lisa and Liang, Percy",
        "title": "Prefix-{{Tuning}}: {{Optimizing Continuous Prompts}} for {{Generation}}"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "zakenBitFitSimpleParameterefficient2022",
        "author": "Zaken, Elad Ben and Ravfogel, Shauli and Goldberg, Yoav",
        "title": "{{BitFit}}: {{Simple Parameter-efficient Fine-tuning}} for {{Transformer-based Masked Language-models}}"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "luFederatedLearningNonIID2024",
        "author": "Lu, Zili and Pan, Heng and Dai, Yueyue and Si, Xueming and Zhang, Yan",
        "title": "Federated {{Learning With Non-IID Data}}: {{A Survey}}"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "hsuMeasuringEffectsNonIdentical2019",
        "author": "Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew",
        "title": "Measuring the {{Effects}} of {{Non-Identical Data Distribution}} for {{Federated Visual Classification}}"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "liFederatedLearningNonIID2022a",
        "author": "Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng",
        "title": "Federated {{Learning}} on {{Non-IID Data Silos}}: {{An Experimental Study}}"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "shenRethinkingDataSelection2024",
        "author": "Shen, Ming",
        "title": "Rethinking {{Data Selection}} for {{Supervised Fine-Tuning}}"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "touvronLlamaOpenFoundation2023",
        "author": "Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas",
        "title": "Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "liuWhatMakesGood2024",
        "author": "Liu, Wei and Zeng, Weihao and He, Keqing and Jiang, Yong and He, Junxian",
        "title": "What {{Makes Good Data}} for {{Alignment}}? {{A Comprehensive Study}} of {{Automatic Data Selection}} in {{Instruction Tuning}}"
      }
    ]
  }
]