\section{Background and Related Works}
%This section is mainly about the existing popular Federated Learning algorithms and their characteristics, followed by an exploration of LLMs and the PEFT methods. 

%The LLM section will provide a detailed account of the OPT model, which will be utilized in the forthcoming experiments. Lastly, the section will delve into the pertinent research on data heterogeneity within the context of federated learning.

\subsection{Federated Learning Systems}

The federated learning system is an innovative machine learning paradigm that addresses the growing concerns of data privacy and security by enabling decentralized model training across multiple client devices without the need to share raw data \cite{baumgartNotAllFederated2024}. Unlike traditional centralized approaches, where data is aggregated into a central repository for model training, federated learning systems allow each client to train a local model using its own data and subsequently share only the model updates with a central server. This collaborative approach not only preserves data privacy but also leverages the computational power of edge devices, thereby reducing latency and enhancing scalability \cite{liFederatedOptimizationHeterogeneous}. Despite its numerous advantages, federated learning faces challenges such as handling heterogeneous data distributions, managing communication overhead, and ensuring the security and integrity of model updates \cite{karimireddySCAFFOLDStochasticControlled2020}. Lots of existing work focuses on data compression to reduce the communication overhead \cite{di2024survey,huang2024optimized,huang2023c}. As research in this field progresses, federated learning holds the potential to revolutionize various domains, including healthcare, finance, and smart devices, by enabling privacy-preserving and efficient machine learning solutions \cite{acarFederatedLearningBased2021a}.

%The central server then aggregates these updates to form a global model, which is redistributed to the clients for further refinement. 

%Federated Averaging, often abbreviated as FedAvg, stands as the predominant method in federated learning \cite{baumgartNotAllFederated2024}. Its resilience is well-documented against data distributions that are both unbalanced and non-IID. Research indicates that increasing the count of local training epochs per communication round does not enhance model efficacy. Furthermore, the research suggests that there is a threshold after which the inclusion of additional clients yields insignificant improvements within the same communication round. In contrast, FedProx introduces a proximal term as an extra regularisation during the client training phase, which has been shown to bolster both the stability and the accuracy of models within diverse network environments, outperforming FedAvg \cite{liFederatedOptimizationHeterogeneous}. SCAFFOLD solves the ‘client-drift’ problem in FedAvg b using control variates \cite{karimireddySCAFFOLDStochasticControlled2020}. It also needs fewer communication rounds to acquire the same performance. FedOpt is a framework that uses many existing federated optimization methods and provides adaptive server optimization to improve FL convergence \cite{reddiAdaptiveFederatedOptimization2021}. FedDyn introduces a dynamic regulariser for each device in each round. The regulariser aligns global and device solutions over time \cite{acarFederatedLearningBased2021a}.

\subsection{LLMs and PEFT Methods}
Language models that have undergone pre-training and possess a substantial number of parameters, along with comprehensive training datasets, are commonly referred to as Large Language Models (LLMs) \cite{raffelExploringLimitsTransfer2023, zhangOPTOpenPretrained2022, touvronLLaMAOpenEfficient2023}. Most LLMs are based on the transformer architecture, and their parameter count is generally from 6 to 10 billion. %liuUnderstandingLLMsComprehensive2024

%In 2019, Google AI unveiled T5, a model pre-trained to enhance text fluency by predicting missing words and generating coherent text \cite{raffelExploringLimitsTransfer2023}. It excels in machine translation, summarisation, question-answering, and sentiment analysis tasks. The following year, OpenAI introduced GPT-3, which utilises next-word prediction training. It uniquely requires only a few examples, or "few-shot demonstrations," to perform tasks through text-based interactions. In 2022, Meta AI released the OPT series, a collection of decoder-only transformers with sizes ranging from 125 million to 175 billion parameters \cite{zhangOPTOpenPretrained2022}. The training involved a vast corpus of approximately 180 billion tokens, focusing on learning robust representations through context and missing token prediction. Notably, the OPT 175B model has demonstrated performance on par with GPT-3. The subsequent year, Meta AI launched LLaMA, with the LLaMA-13B variant surpassing GPT-3 in most benchmark assessments \cite{touvronLLaMAOpenEfficient2023}.

The parameter-efficient fine-tuning (PEFT) strategies, based on operational approaches, can be categorized into four main types: additive, selective, re-parameterised, and hybrid PEFT \cite{hanParameterEfficientFineTuningLarge2024}. 

\textit{Additive PEFT} enhances the model's architecture by adding new trainable components or parameters. Within this category, methods such as Serial Adapter and Parallel Adapter \cite{heUnifiedViewParameterEfficient2022} are prominent. The former integrates adapters behind the transformer module, while the latter aligns them parallel to the module. \textit{Selective PEFT} focuses on training a subset of the model's parameters without increasing them. An example is Diff Pruning, which employs a diff vector to adaptively prune the model during training, using a differentiable approximation to the L0-norm penalty to promote sparsity \cite{guoParameterEfficientTransferLearning2021}. \textit{Re-parameterised PEFT} involves creating a lower-dimensional representation of the original model parameters. LoRA, a method under this category, achieves this through low-rank factorization by splitting the attention layers' weight matrices into two smaller matrices, thus significantly reducing the number of parameters to be fine-tuned. Unlike LoRA, which uses a fixed rank, DyLoRA \cite{valipourDyLoRAParameterEfficient2023} dynamically adjusts the rank of the low-rank matrix during fine-tuning, depending on the task's complexity by modifying the matrix's dimensions. \textit{Hybrid Fine-tuning}, as the name suggests, combines different PEFT methods when commonalities are identified. UniPELT \cite{maoUniPELTUnifiedFramework2022}, for instance, supports various methods including Prefix-tuning \cite{liPrefixTuningOptimizingContinuous2021}, Adapter, LoRA, BitFit \cite{zakenBitFitSimpleParameterefficient2022}, and their combinations. It utilizes a gating mechanism to activate the appropriate sub-modules for the given data or task.


%Figure \ref{fig:peft} shows a more detailed breakdown.

%\begin{figure*}
%    \centering
%    \includegraphics[width=0.8\textwidth]{peft2.png}
%    \caption{The category of PEFT strategies}
%    \label{fig:peft}
%\end{figure*}


\subsection{Non-IID Data in Federated Learning}
Substantial research has been conducted on federated learning with non-IID data, where data heterogeneity significantly impacts the performance of the aggregated model. The study \cite{luFederatedLearningNonIID2024} identifies three factors affecting model performance: data distribution imbalance, heterogeneous data characteristics, and differences in data volume. \cite{hsuMeasuringEffectsNonIdentical2019} employs a Dirichlet distribution to create unbalanced labels across clients using the CIFAR-10 dataset to evaluate the FedAvg algorithm. \cite{liFederatedLearningNonIID2022a} conducts a comprehensive study of five federated learning algorithms and nine visual datasets to assess the impact of non-IID data, utilizing three partitioning strategies: label distribution skew, feature distribution skew, and quantity skew. Although not directly related to federated learning, \cite{shenRethinkingDataSelection2024} demonstrates the influence of length and diversity on accuracy during supervised fine-tuning using LLaMA-2-7B \cite{touvronLlamaOpenFoundation2023}. Similarly, \cite{liuWhatMakesGood2024} introduces DEITA, a framework that measures data across three dimensions, including complexity, quality, and diversity, and evaluates training outcomes using multiple metrics. Although most of them are not focused on federated learning systems, these works provide valuable insights into assessing textual data diversity.

%\vspace{-12pt}