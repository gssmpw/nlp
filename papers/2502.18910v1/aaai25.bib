@misc{acarFederatedLearningBased2021a,
  title = {Federated {{Learning Based}} on {{Dynamic Regularization}}},
  author = {Acar, Durmus Alp Emre and Zhao, Yue and Navarro, Ramon Matas and Mattina, Matthew and Whatmough, Paul N. and Saligrama, Venkatesh},
  year = {2021},
  month = nov,
  number = {arXiv:2111.04263},
  eprint = {2111.04263},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning}
}

@misc{bahriniChatGPTApplicationsOpportunities2023,
  title = {{{ChatGPT}}: {{Applications}}, {{Opportunities}}, and {{Threats}}},
  shorttitle = {{{ChatGPT}}},
  author = {Bahrini, Aram and Khamoshifar, Mohammadsadra and Abbasimehr, Hossein and Riggs, Robert J. and Esmaeili, Maryam and Majdabadkohne, Rastin Mastali and Pasehvar, Morteza},
  year = {2023},
  month = apr,
  number = {arXiv:2304.09103},
  eprint = {2304.09103},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society}
}

@misc{baumgartNotAllFederated2024,
  title = {Not {{All Federated Learning Algorithms Are Created Equal}}: {{A Performance Evaluation Study}}},
  shorttitle = {Not {{All Federated Learning Algorithms Are Created Equal}}},
  author = {Baumgart, Gustav A. and Shin, Jaemin and Payani, Ali and Lee, Myungjin and Kompella, Ramana Rao},
  year = {2024},
  month = mar,
  number = {arXiv:2403.17287},
  eprint = {2403.17287},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning}
}

@misc{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = jul,
  number = {arXiv:2005.14165},
  eprint = {2005.14165},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@inproceedings{gliwaSAMSumCorpusHumanannotated2019,
  title = {{{SAMSum Corpus}}: {{A Human-annotated Dialogue Dataset}} for {{Abstractive Summarization}}},
  shorttitle = {{{SAMSum Corpus}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{New Frontiers}} in {{Summarization}}},
  author = {Gliwa, Bogdan and Mochol, Iwona and Biesek, Maciej and Wawer, Aleksander},
  year = {2019},
  eprint = {1911.12237},
  primaryclass = {cs},
  pages = {70--79},
  doi = {10.18653/v1/D19-5409},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@misc{guoParameterEfficientTransferLearning2021,
  title = {Parameter-{{Efficient Transfer Learning}} with {{Diff Pruning}}},
  author = {Guo, Demi and Rush, Alexander M. and Kim, Yoon},
  year = {2021},
  month = jun,
  number = {arXiv:2012.07463},
  eprint = {2012.07463},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{hanParameterEfficientFineTuningLarge2024,
  title = {Parameter-{{Efficient Fine-Tuning}} for {{Large Models}}: {{A Comprehensive Survey}}},
  shorttitle = {Parameter-{{Efficient Fine-Tuning}} for {{Large Models}}},
  author = {Han, Zeyu and Gao, Chao and Liu, Jinyang and Zhang, Jeff and Zhang, Sai Qian},
  year = {2024},
  month = apr,
  number = {arXiv:2403.14608},
  eprint = {2403.14608},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning}
}

@misc{heUnifiedViewParameterEfficient2022,
  title = {Towards a {{Unified View}} of {{Parameter-Efficient Transfer Learning}}},
  author = {He, Junxian and Zhou, Chunting and Ma, Xuezhe and {Berg-Kirkpatrick}, Taylor and Neubig, Graham},
  year = {2022},
  month = feb,
  number = {arXiv:2110.04366},
  eprint = {2110.04366},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@inproceedings{houlsbyParameterEfficientTransferLearning2019,
  title = {Parameter-{{Efficient Transfer Learning}} for {{NLP}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and Laroussilhe, Quentin De and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  year = {2019},
  month = may,
  pages = {2790--2799},
  publisher = {PMLR},
  issn = {2640-3498},
  langid = {english}
}

@misc{hsuMeasuringEffectsNonIdentical2019,
  title = {Measuring the {{Effects}} of {{Non-Identical Data Distribution}} for {{Federated Visual Classification}}},
  author = {Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  year = {2019},
  month = sep,
  number = {arXiv:1909.06335},
  eprint = {1909.06335},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and {Allen-Zhu}, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  year = {2021},
  month = oct,
  number = {arXiv:2106.09685},
  eprint = {2106.09685},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{kaddourChallengesApplicationsLarge2023,
  title = {Challenges and {{Applications}} of {{Large Language Models}}},
  author = {Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  year = {2023},
  month = jul,
  number = {arXiv:2307.10169},
  eprint = {2307.10169},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{kairouzAdvancesOpenProblems2021,
  title = {Advances and {{Open Problems}} in {{Federated Learning}}},
  author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D'Oliveira, Rafael G. L. and Eichner, Hubert and Rouayheb, Salim El and Evans, David and Gardner, Josh and Garrett, Zachary and Gasc{\'o}n, Adri{\`a} and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Kone{\v c}n{\'y}, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancr{\`e}de and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and {\"O}zg{\"u}r, Ayfer and Pagh, Rasmus and Raykova, Mariana and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tram{\`e}r, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
  year = {2021},
  month = mar,
  number = {arXiv:1912.04977},
  eprint = {1912.04977},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1912.04977},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@inproceedings{karimireddySCAFFOLDStochasticControlled2020,
  title = {{{SCAFFOLD}}: {{Stochastic Controlled Averaging}} for {{Federated Learning}}},
  shorttitle = {{{SCAFFOLD}}},
  booktitle = {Proceedings of the 37th {{International Conference}} on {{Machine Learning}}},
  author = {Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  year = {2020},
  month = nov,
  pages = {5132--5143},
  publisher = {PMLR},
  issn = {2640-3498},
  langid = {english}
}

@inproceedings{kimClientCustomizedAdaptationParameterEfficient2023,
  title = {Client-{{Customized Adaptation}} for {{Parameter-Efficient Federated Learning}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2023},
  author = {Kim, Yeachan and Kim, Junho and Mok, Wing-Lam and Park, Jun-Hyung and Lee, SangKeun},
  editor = {Rogers, Anna and {Boyd-Graber}, Jordan and Okazaki, Naoaki},
  year = {2023},
  month = jul,
  pages = {1159--1172},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.findings-acl.75},
  langid = {english}
}

@inproceedings{liFederatedLearningNonIID2022a,
  title = {Federated {{Learning}} on {{Non-IID Data Silos}}: {{An Experimental Study}}},
  shorttitle = {Federated {{Learning}} on {{Non-IID Data Silos}}},
  booktitle = {2022 {{IEEE}} 38th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  year = {2022},
  month = may,
  pages = {965--978},
  issn = {2375-026X},
  doi = {10.1109/ICDE53745.2022.00077},
  langid = {english},
  keywords = {Benchmark,Collaborative work,Data privacy,Distributed databases,Federated Learning,Machine learning,Machine learning algorithms,Organizations,Training data}
}

@article{liFederatedOptimizationHeterogeneous,
  title = {Federated {{Optimization}} in {{Heterogeneous Networks}}},
  author = {Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  langid = {english}
}

@misc{liPrefixTuningOptimizingContinuous2021,
  title = {Prefix-{{Tuning}}: {{Optimizing Continuous Prompts}} for {{Generation}}},
  shorttitle = {Prefix-{{Tuning}}},
  author = {Li, Xiang Lisa and Liang, Percy},
  year = {2021},
  month = jan,
  number = {arXiv:2101.00190},
  eprint = {2101.00190},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@misc{liuRecentAdvancesFederated2023,
  title = {Recent {{Advances}} on {{Federated Learning}}: {{A Systematic Survey}}},
  shorttitle = {Recent {{Advances}} on {{Federated Learning}}},
  author = {Liu, Bingyan and Lv, Nuoyan and Guo, Yuanchun and Li, Yawen},
  year = {2023},
  month = jan,
  number = {arXiv:2301.01299},
  eprint = {2301.01299},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.01299},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning}
}

@misc{liuTrainingDataInfluence2024,
  title = {On {{Training Data Influence}} of {{GPT Models}}},
  author = {Liu, Qingyi and Chai, Yekun and Wang, Shuohuan and Sun, Yu and Peng, Qiwei and Wang, Keze and Wu, Hua},
  year = {2024},
  month = apr,
  number = {arXiv:2404.07840},
  eprint = {2404.07840},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{liuUnderstandingLLMsComprehensive2024,
  title = {Understanding {{LLMs}}: {{A Comprehensive Overview}} from {{Training}} to {{Inference}}},
  shorttitle = {Understanding {{LLMs}}},
  author = {Liu, Yiheng and He, Hao and Han, Tianle and Zhang, Xu and Liu, Mengyuan and Tian, Jiaming and Zhang, Yutong and Wang, Jiaqi and Gao, Xiaohui and Zhong, Tianyang and Pan, Yi and Xu, Shaochen and Wu, Zihao and Liu, Zhengliang and Zhang, Xin and Zhang, Shu and Hu, Xintao and Zhang, Tuo and Qiang, Ning and Liu, Tianming and Ge, Bao},
  year = {2024},
  month = jan,
  number = {arXiv:2401.02038},
  eprint = {2401.02038},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@misc{liuWhatMakesGood2024,
  title = {What {{Makes Good Data}} for {{Alignment}}? {{A Comprehensive Study}} of {{Automatic Data Selection}} in {{Instruction Tuning}}},
  shorttitle = {What {{Makes Good Data}} for {{Alignment}}?},
  author = {Liu, Wei and Zeng, Weihao and He, Keqing and Jiang, Yong and He, Junxian},
  year = {2024},
  month = apr,
  number = {arXiv:2312.15685},
  eprint = {2312.15685},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.15685},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@article{luFederatedLearningNonIID2024,
  title = {Federated {{Learning With Non-IID Data}}: {{A Survey}}},
  shorttitle = {Federated {{Learning With Non-IID Data}}},
  author = {Lu, Zili and Pan, Heng and Dai, Yueyue and Si, Xueming and Zhang, Yan},
  year = {2024},
  month = jun,
  journal = {IEEE Internet of Things Journal},
  volume = {11},
  number = {11},
  pages = {19188--19209},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2024.3376548},
  langid = {english},
  keywords = {Adaptation models,Communication efficiency,Convergence,Data models,Distributed databases,federated learning (FL),Internet of Things,Internet of Things (IoT),nonindependent and identically distributed (non-IID) data,privacy preservation,Servers,survey,Training}
}

@misc{mammenFederatedLearningOpportunities2021,
  title = {Federated {{Learning}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Federated {{Learning}}},
  author = {Mammen, Priyanka Mary},
  year = {2021},
  month = jan,
  number = {arXiv:2101.05428},
  eprint = {2101.05428},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning}
}

@misc{maoUniPELTUnifiedFramework2022,
  title = {{{UniPELT}}: {{A Unified Framework}} for {{Parameter-Efficient Language Model Tuning}}},
  shorttitle = {{{UniPELT}}},
  author = {Mao, Yuning and Mathias, Lambert and Hou, Rui and Almahairi, Amjad and Ma, Hao and Han, Jiawei and Yih, Wen-tau and Khabsa, Madian},
  year = {2022},
  month = sep,
  number = {arXiv:2110.07577},
  eprint = {2110.07577},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.07577},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{mcmahanCommunicationEfficientLearningDeep2023,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Ag{\"u}era},
  year = {2023},
  month = jan,
  number = {arXiv:1602.05629},
  eprint = {1602.05629},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1602.05629},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning}
}

@misc{raffelExploringLimitsTransfer2023,
  title = {Exploring the {{Limits}} of {{Transfer Learning}} with a {{Unified Text-to-Text Transformer}}},
  author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  year = {2023},
  month = sep,
  number = {arXiv:1910.10683},
  eprint = {1910.10683},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@misc{reddiAdaptiveFederatedOptimization2021,
  title = {Adaptive {{Federated Optimization}}},
  author = {Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v c}n{\'y}, Jakub and Kumar, Sanjiv and McMahan, H. Brendan},
  year = {2021},
  month = sep,
  number = {arXiv:2003.00295},
  eprint = {2003.00295},
  primaryclass = {cs, math, stat},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning}
}

@misc{shenRethinkingDataSelection2024,
  title = {Rethinking {{Data Selection}} for {{Supervised Fine-Tuning}}},
  author = {Shen, Ming},
  year = {2024},
  month = feb,
  number = {arXiv:2402.06094},
  eprint = {2402.06094},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.06094},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@misc{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023},
  month = feb,
  number = {arXiv:2302.13971},
  eprint = {2302.13971},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language}
}

@misc{touvronLlamaOpenFoundation2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.09288},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
}

@misc{valipourDyLoRAParameterEfficient2023,
  title = {{{DyLoRA}}: {{Parameter Efficient Tuning}} of {{Pre-trained Models}} Using {{Dynamic Search-Free Low-Rank Adaptation}}},
  shorttitle = {{{DyLoRA}}},
  author = {Valipour, Mojtaba and Rezagholizadeh, Mehdi and Kobyzev, Ivan and Ghodsi, Ali},
  year = {2023},
  month = apr,
  number = {arXiv:2210.07558},
  eprint = {2210.07558},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@inproceedings{wangGLUEMultiTaskBenchmark2018,
  title = {{{GLUE}}: {{A Multi-Task Benchmark}} and {{Analysis Platform}} for {{Natural Language Understanding}}},
  shorttitle = {{{GLUE}}},
  booktitle = {Proceedings of the 2018 {{EMNLP Workshop BlackboxNLP}}: {{Analyzing}} and {{Interpreting Neural Networks}} for {{NLP}}},
  author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  year = {2018},
  pages = {353--355},
  publisher = {Association for Computational Linguistics},
  address = {Brussels, Belgium},
  doi = {10.18653/v1/W18-5446},
  langid = {english}
}

@misc{zakenBitFitSimpleParameterefficient2022,
  title = {{{BitFit}}: {{Simple Parameter-efficient Fine-tuning}} for {{Transformer-based Masked Language-models}}},
  shorttitle = {{{BitFit}}},
  author = {Zaken, Elad Ben and Ravfogel, Shauli and Goldberg, Yoav},
  year = {2022},
  month = sep,
  number = {arXiv:2106.10199},
  eprint = {2106.10199},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.10199},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{zhangOPTOpenPretrained2022,
  title = {{{OPT}}: {{Open Pre-trained Transformer Language Models}}},
  shorttitle = {{{OPT}}},
  author = {Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Shuster, Kurt and Simig, Daniel and Koura, Punit Singh and Sridhar, Anjali and Wang, Tianlu and Zettlemoyer, Luke},
  year = {2022},
  month = jun,
  number = {arXiv:2205.01068},
  eprint = {2205.01068},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.01068},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@article{zhangSurveyFederatedLearning2021,
  title = {A Survey on Federated Learning},
  author = {Zhang, Chen and Xie, Yu and Bai, Hang and Yu, Bin and Li, Weihong and Gao, Yuan},
  year = {2021},
  month = mar,
  journal = {Knowledge-Based Systems},
  volume = {216},
  pages = {106775},
  issn = {09507051},
  doi = {10.1016/j.knosys.2021.106775},
  langid = {english}
}

@misc{zhangWhenScalingMeets2024,
  title = {When {{Scaling Meets LLM Finetuning}}: {{The Effect}} of {{Data}}, {{Model}} and {{Finetuning Method}}},
  shorttitle = {When {{Scaling Meets LLM Finetuning}}},
  author = {Zhang, Biao and Liu, Zhongtao and Cherry, Colin and Firat, Orhan},
  year = {2024},
  month = feb,
  number = {arXiv:2402.17193},
  eprint = {2402.17193},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{zhongSeq2SQLGeneratingStructured2017,
  title = {{{Seq2SQL}}: {{Generating Structured Queries}} from {{Natural Language}} Using {{Reinforcement Learning}}},
  shorttitle = {{{Seq2SQL}}},
  author = {Zhong, Victor and Xiong, Caiming and Socher, Richard},
  year = {2017},
  month = nov,
  number = {arXiv:1709.00103},
  eprint = {1709.00103},
  primaryclass = {cs},
  publisher = {arXiv},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
}

@article{zhuFederatedLearningNonIID2021,
  title = {Federated Learning on Non-{{IID}} Data: {{A}} Survey},
  shorttitle = {Federated Learning on Non-{{IID}} Data},
  author = {Zhu, Hangyu and Xu, Jinjin and Liu, Shiqing and Jin, Yaochu},
  year = {2021},
  month = nov,
  journal = {Neurocomputing},
  volume = {465},
  pages = {371--390},
  issn = {09252312},
  doi = {10.1016/j.neucom.2021.07.098},
  langid = {english}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{openai2023gpt,
  title={GPT-4 technical report},
  author={OpenAI},
  journal={arXiv},
  pages={2303--08774},
  year={2023}
}

@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@inproceedings{zeng2022glm,
  title={GLM-130B: An Open Bilingual Pre-trained Model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{penedo2023refinedweb,
  title={The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only},
  author={Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
  journal={arXiv preprint arXiv:2306.01116},
  year={2023}
}

@article{togetherai,
  title={Redpajama-data-v2: An open dataset with 30 trillion tokens for training large language models},
  author={Together.AI},
  journal={https://www.together.ai/blog/red pajama-data-v2.},
  year={2023}
}

@misc{kaplan2020scaling,
      title={Scaling Laws for Neural Language Models}, 
      author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
      year={2020},
      eprint={2001.08361},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hoffmann2022training,
      title={Training Compute-Optimal Large Language Models}, 
      author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
      year={2022},
      eprint={2203.15556},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{villalobosposition,
  title={Position: Will we run out of data? Limits of LLM scaling based on human-generated data},
  author={Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{longpre2024consent,
  title={Consent in Crisis: The Rapid Decline of the AI Data Commons},
  author={Longpre, Shayne and Mahari, Robert and Lee, Ariel and Lund, Campbell and Oderinwale, Hamidah and Brannon, William and Saxena, Nayan and Obeng-Marnu, Naana and South, Tobin and Hunter, Cole and others},
  journal={arXiv preprint arXiv:2407.14933},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Ichter, Brian and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and others},
  journal={arXiv preprint arXiv:2303.03378},
  year={2023}
}

@article{anil2023palm,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@inproceedings{cho2023heterogeneous,
  title={Heterogeneous lora for federated fine-tuning of on-device foundation models},
  author={Cho, Yae Jee and Liu, Luyang and Xu, Zheng and Fahrezi, Aldi and Barnes, Matt and Joshi, Gauri},
  booktitle={International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023},
  year={2023}
}

@article{meta2024introducing,
  title={Introducing meta llama 3: The most capable openly available llm to date},
  author={Meta, AI},
  journal={Meta AI},
  year={2024}
}

@article{abdin2024phi,
  title={Phi-3 technical report: A highly capable language model locally on your phone},
  author={Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and others},
  journal={arXiv preprint arXiv:2404.14219},
  year={2024}
}

@article{javaheripi2phi,
  title={Phi-2: the surprising power of small language models (2023)},
  author={Javaheripi, Mojan and Bubeck, Sebastien and others},
  journal={URL https://www. microsoft. com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models}
}

@article{xu2024fedfa,
  title={FedFa: A Fully Asynchronous Training Paradigm for Federated Learning},
  author={Xu, Haotian and Zhang, Zhaorui and Di, Sheng and Liu, Benben and Khalid, Alharthi and Cao, Jiannong},
  journal={arXiv preprint arXiv:2404.11015},
  year={2024}
}

@article{zhang2022mipd,
  title={MIPD: An adaptive gradient sparsification framework for distributed DNNs training},
  author={Zhang, Zhaorui and Wang, Choli},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={33},
  number={11},
  pages={3053--3066},
  year={2022},
  publisher={IEEE}
}

@article{zhang2021sapus,
  title={SaPus: Self-adaptive parameter update strategy for DNN training on Multi-GPU clusters},
  author={Zhang, Zhaorui and Wang, Choli},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={33},
  number={7},
  pages={1569--1580},
  year={2021},
  publisher={IEEE}
}

@article{zhang2022momentum,
  title={Momentum-driven adaptive synchronization model for distributed DNN training on HPC clusters},
  author={Zhang, Zhaorui and Ji, Zhuoran and Wang, Choli},
  journal={Journal of Parallel and Distributed Computing},
  volume={159},
  pages={65--84},
  year={2022},
  publisher={Elsevier}
}


@article{di2024survey,
  title={A survey on error-bounded lossy compression for scientific datasets},
  author={Di, Sheng and Liu, Jinyang and Zhao, Kai and Liang, Xin and Underwood, Robert and Zhang, Zhaorui and Shah, Milan and Huang, Yafan and Huang, Jiajun and Yu, Xiaodong and others},
  journal={arXiv preprint arXiv:2404.02840},
  year={2024}
}

@inproceedings{huang2024optimized,
  title={An optimized error-controlled mpi collective framework integrated with lossy compression},
  author={Huang, Jiajun and Di, Sheng and Yu, Xiaodong and Zhai, Yujia and Zhang, Zhaorui and Liu, Jinyang and Lu, Xiaoyi and Raffenetti, Ken and Zhou, Hui and Zhao, Kai and others},
  booktitle={2024 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={752--764},
  year={2024},
  organization={IEEE}
}

@article{huang2023c,
  title={C-Coll: Introducing error-bounded lossy compression into MPI collectives},
  author={Huang, Jiajun and Di, Sheng and Yu, Xiaodong and Zhai, Yujia and Liu, Jinyang and Raffenetti, Ken and Zhou, Hui and Zhao, Kai and Chen, Zizhong and Cappello, Franck and others},
  journal={arXiv preprint arXiv:2304.03890},
  year={2023}
}