\section{Conclusion}

In this work, we introduce \textsc{Reference-Level Feedback}, a novel framework for enhancing synthetic data quality. Our approach leverages feedback collected from high-quality reference samples to identify and propagate desirable characteristics through the synthesized data. LLMs finetuned on our generated dataset, \textsc{REFED}, achieve strong performance on instruction-following benchmarks. By modeling and incorporating desirable characteristics from carefully curated reference samples, we demonstrate a powerful and efficient approach for creating high-quality instruction-tuning datasets.

Our work opens up several promising directions for future applications. Recent developments in language models like DeepSeek-R1 \citep{deepseekai2025deepseekr1incentivizingreasoningcapability} and OpenAI's o1 \citep{openai2024openaio1card} demonstrate that high-quality synthetic data plays a crucial role in achieving state-of-the-art performance. The feedback introduced in our paper can be naturally integrated with various existing data synthesis approaches, such as preference data creation, to further build upon them. By demonstrating the effectiveness of \textsc{Reference-Level Feedback} in this context, this work establishes a foundation for developing more comprehensive approaches for data synthesis.