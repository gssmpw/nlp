\section{Limitations}

\paragraph{Reliance on a Stronger LLM. }
Our framework relies on a stronger LLM to synthesize data. While this enables the synthesis of high quality data, removing this dependency could help lead to a more robust and independent framework, possibly at the cost of performance degradation. Additionally, LLM-generated data may amplify existing biases or include inappropriate content.

\paragraph{Seed Data Quality. }
The quality of our synthesized data is tied to that of our seed data. We select concise, high-quality datasets from prior works to use as the seed data. A more comprehensive exploration of seed data selection and its impact on synthetic data remains an important direction for future work.

Furthermore, our work does not fully address the scalability our framework. There likely exists a limit to how much data we can synthesize from our seed data, until the synthesized data becomes repetitive and lacks diversity.

\paragraph{LLM-Based Evaluation. }
Our evaluation relies on benchmarks that use LLMs as a judge. Although they correlate highly with human judgments, it is important to acknowledge that they may still have limitations, such as biases towards longer responses or their own outputs.


\section{Acknowledgments}
This work has benefited from the Microsoft Accelerate Foundation Models Research (AFMR) grant program, through which leading foundation models hosted by Microsoft Azure and access to Azure credits were provided to conduct the research.
