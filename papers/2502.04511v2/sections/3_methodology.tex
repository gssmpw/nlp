\section{Method}

\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{figures/pipeline.png} \hfill

    \caption{An overview of our data synthesis pipeline. Starting from our seed data, we select a reference sample and collect \textsc{Reference-Level Feedback} on both the instruction and response. Instruction feedback is used to synthesize new instructions. We generate their corresponding responses, and then improve it using the response feedback.}
    \label{fig:pipeline}
\end{figure*}

In this section, we present our data synthesis pipeline that leverages \textsc{Reference-Level Feedback} to generate high-quality instruction-response pairs. An overview of the pipeline is presented in Figure \ref{fig:pipeline}, and the steps are detailed in the following subsections. Complete examples for each step can be found in Appendix \ref{sec:appendix_examples}, and the prompts used for each section can be found in Appendix \ref{sec:appendix_prompt_templates}.


\subsection{Feedback Collection}

Our pipeline begins with a seed dataset -- a small collection of carefully curated instruction-response pairs that serve as exemplars for synthesized data samples. It can be either manually crafted by human annotators or automatically selected using quality-based criteria. These reference samples are high-quality and exhibit desirable characteristics such as clarity and relevance, which we aim to replicate in our synthetic data. For \textsc{Reference-Level Feedback}, we systematically identify and capture such qualities through a framework that identifies the strength of each sample, as well as potential areas for improvement.

Unlike traditional approaches that collect feedback on generated responses at the sample-level, our method identifies the qualities that make reference samples high-quality and uses it for feedback. This feedback captures a richer signal than feedback collected at the sample-level, establishing higher quality standards for synthesis and providing more effective guidance for generating training data that exhibits similar properties to the reference samples.

For each reference sample in the seed dataset, we collect \textsc{Reference-Level Feedback} from both the instruction and the response:

\textbf{Instruction Feedback.} To collect feedback from a reference instruction and capture essential features that make it effective for training, we analyze key attributes (e.g., clarity and actionability). We also ensure comprehensive coverage along a wide breadth by collecting feedback along two dimensions: relevant subject areas (e.g. cellular biology, csv file manipulation, legislative processes) and relevant skills necessary to respond to the instruction (e.g. understanding of specific tools, knowledge of processes, analysis). This enables us to systematically identify desirable characteristics of instructions while maximizing the breadth of instruction types.

\textbf{Response Feedback.} When collecting feedback from a reference response, we identify key qualities that make it an effective response to the instruction. We evaluate along multiple critical dimensions, including factual accuracy, relevance to the instruction, and comprehensiveness. This feedback captures both the strengths of the reference response and specific areas where it can be improved upon.


\subsection{Data Synthesis}
Now, we use the collected \textsc{Reference-Level Feedback} from the previous stage to synthesize new data samples, while maintaining the quality standards established by our reference data. For each reference sample and its corresponding feedback, we employ a two-phase synthesis process, as illustrated in Figure \ref{fig:pipeline}:

\begin{enumerate}
    \item \textbf{Instruction Synthesis.} We provide an LLM the reference instruction as an example and the instruction feedback as guidelines to synthesize new instructions that maintain the qualities specified in the feedback. As depicted in Step 2 of Figure \ref{fig:pipeline}, we synthesize 10 new instructions for \textbf{subject-based} feedback, which produces instructions that align with the subject areas of the reference response. We also synthesize 10 new instructions for \textbf{skill-based} feedback, which produces instructions that align with the skills needed to respond to the reference instruction.
    
    \item \textbf{Response Synthesis and Refinement.} For each synthesized instruction, we first generate an initial response. We then enhance this response using the reference response feedback, instructing the language model to analyze the feedback and incorporate the relevant aspects. This process is shown in Step 3 of Figure \ref{fig:pipeline}.
    
    \paragraph{Note on relevance of response feedback.}
    Although the response feedback was originally collected for the reference response, many aspects of it can still remain applicable because of the shared characteristics between the reference and synthesized instructions. We acknowledge that not all feedback elements may transfer, and to account for this, we explicitly instruct the model to selectively apply only the relevant aspects of the feedback and ignore the irrelevant aspects. An example of this can be found in \ref{sec:appendix_examples}.
\end{enumerate}

This synthesis process enables us to synthesize new data, while systematically propagating the high-quality characteristics of reference samples.

\subsection{Theoretical Efficiency Analysis}
Our presented pipeline for data synthesis with \textsc{Reference-Level Feedback} is significantly more efficient than using traditional sample-level feedback methods, specifically in the frequency of feedback collection. While sample-level approaches require feedback for every synthesized sample, our method only requires feedback once for every reference sample. This translates to a reduction from $O(n)$ feedback collections, where $n$ represents the number of synthesized samples, to $O(1)$. However, it is also important to note that this efficiency gain comes with an initial fixed cost of collecting and curating seed data.