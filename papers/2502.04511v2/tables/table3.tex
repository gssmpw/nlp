\begin{table*}[t]
    \centering
    \small
    \setlength{\tabcolsep}{4pt}
    
    \begin{tabular}{c l c c c c c c} \toprule
        \multicolumn{2}{c}{\multirow{2}[3]{*}{\makecell{\textbf{Model} \\ }}}
        & \multicolumn{4}{c}{\textbf{AlpacaEval 2}} & \multicolumn{2}{c}{\textbf{Arena-Hard}} \\ \cmidrule(lr){3-6} \cmidrule(lr){7-8}
        & & LC (\%) & WR (\%) & SE & Len. & WR (\%) & Tok. \\ \midrule

        & Mistral-7B-v0.3 & - & - & - & - & - & - \\ 
        & \quad + \textsc{REFED} & 16.97 & 17.70 &  1.34  &  2070  & 3.6 & 669 \\ 

        \midrule
        & Mistral-7B-Instruct-v0.3 & 20.61 & 16.69 & 1.11 & 1581 & 12.6 & 541 \\ 
        & \quad + \textsc{REFED} & $41.10_{\textcolor{darkgreen}{\uparrow 20.49}}$ & $40.55_{\textcolor{darkgreen}{\uparrow 23.86}}$  &  1.73  &  2069  &  $25.0_{\textcolor{darkgreen}{\uparrow 12.4}}$  &  648 \\ 

        \midrule
        & Llama-3.1-8B & - & - & - & - & - & - \\ 
        & \quad + \textsc{REFED} & 29.63 & 30.10 & 1.62 & 2095 &  12.7 & 633 \\ 

        \midrule
        & Llama-3.1-8B-Instruct & 22.90 & 23.44 & 1.49 & 2181 & 21.3 & 861 \\ 
        & \quad + \textsc{REFED} & \textbf{43.96$_{\textcolor{darkgreen}{\uparrow 21.06}}$} & \textbf{42.24$_{\textcolor{darkgreen}{\uparrow 18.80}}$} & \textbf{1.74} & \textbf{1950} & \textbf{35.9$_{\textcolor{darkgreen}{\uparrow 14.6}}$} & \textbf{670} \\ 
        
        \bottomrule
    \end{tabular}
    
    \caption{Evaluation results of finetuning \textsc{REFED} on the base and instruct variants of Llama-3.1-8B and Mistral-7B models. Green subscripts indicate improvements after finetuning. Note that we do not report base model performance because they are not instruction-tuned.}
    \label{tab:table3}
\end{table*}