\section{Conclusion}

In this work, we introduce \name, a unified modular benchmark explicitly designed for robust RL. Unlike existing RL benchmarks, \name aims to evaluate the resilience of RL algorithms across a wide range of disruptions. These disruptions include perturbations at every stage of the entire agent-environment interaction process, affecting agent observations, actions, rewards, and environmental dynamics.
\name provides a comprehensive platform for benchmarking RL algorithms, featuring over 60 diverse task environments across domains such as robotics, multi-agent systems, and safe RL. Additionally, we benchmark various SOTA RL algorithms, including PPO, MAPPO, OMPO, RSC, and IPPO, across a wide array of robust RL tasks in \name. The results highlight the deficiencies of current algorithms and motivate the development of new ones. This work represents a significant step forward in standardizing and advancing the field of robust RL, promoting the creation of more reliable, generalizable, and robust learning algorithms.


\section*{Acknowledgments}

The work of S. Gu is supported by funds from Prof. Spanosâ€™ Andrew S. Grove Endowed Chair.  The work of L. Shi is supported in part by the Resnick Institute and Computing, Data, and Society Postdoctoral Fellowship at California Institute of Technology. The work of Y. Chi is supported in part by the grant NSF CCF-2106778. The work of E. Mazumdar is supported in part from NSF-2240110. The work of A. Wierman is supported in part from the NSF through CCF-2326609, CNS-2146814, CPS-2136197, CNS-2106403, NGSDI-2105648, and the Resnick Institute. The work of M. Jin is supported from NSF ECCS-233177, IIS-2312794, the Amazon-Virginia Tech Initiative for Efficient and Robust Machine Learning, and the Commonwealth Cyber Initiative. We extend our sincere appreciation to Weirui Ye, Pieter Abbeel, Banghua Zhu, and Carmelo Sferrazza for their insightful and valuable discussions.
 
% \paragraph{Ethics Statement.} This work is conducted without involving human subjects or personal data that might raise ethical concerns. There are no conflicts of interest, privacy issues, or potential for harm associated with this work.

% \paragraph{Reproducibility Statement.} To facilitate the reproducibility of our experiments, we have provided the source code at the link: \url{https://robust-rl.online/}. Detailed descriptions of algorithm parameters are included in Appendix~\ref{appendix-parameters-settings-experiments}. 