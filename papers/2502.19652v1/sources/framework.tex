\section{\name: a unified robust RL benchmark}

We now introduce our main contribution, a modular benchmark (\name) designed for evaluating Robust RL policies in robotics and control tasks. Each task is constructed from three main components: an agent model (the robot object), an environment (the agent's workspace), and a task objective (such as navigation or manipulation). \name offers robust RL tasks by integrating various disruptors of different types, modes, and frequencies with these task bases. Not all task bases support every type of disruption. A detailed list of the robust RL tasks implemented in this benchmark is available in Figure~\ref{fig:tasks+disruptors}. In the following sections, we introduce over 60 task bases from eleven sets, outline the design of the disruptors, and describe the construction of a \fname --- robust RL tasks.

\subsection{Task and Environment Bases}\label{sec:task-base}

% \begin{wrapfigure}{r}{0.2\textwidth}
% \centering
% \vspace{-4mm}
% \includegraphics[%scale=1
%                  width=1.0\linewidth]{figures/framework/box2d.png} 
% \label{fig:per-task}
% \end{wrapfigure}







% \setlength{\intextsep}{12pt}


\paragraph{Gymnasium-Box2D}{\em  (three relative simple control tasks in games).} 
\FloatBarrier
\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-8mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/box2d.png} 
\label{fig:per-task}
 \vspace{-5mm}
\end{minipage}
\end{wrapfigure}

\vspace{-2mm}
These tasks are from Gymnasium \citep{towers2024gymnasium}, including three robot models from different games, such as the Bipedal Walker --- a 4-joint walking robot designed to move forward and Car Racing --- navigating a track by learning from pixel inputs \citep{parberry2017introduction, brockman2016openai}. 
% These tasks are from Gymnasium \citep{towers2024gymnasium} based on the widely-used Openai Gym \citep{brockman2016openai}.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-3mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/mujoco.png} 
\label{fig:per-task}
 \vspace{-7mm}
\end{minipage}
\end{wrapfigure}

\paragraph{Gymnisium-MuJoCo} {\em  (eleven control tasks).}

\vspace{-2mm}
It includes various robot models, such as bipedal and quadrupedal robots. This benchmark is widely used in various RL problems, including standard online and offline RL, with representative examples like Hopper, Ant, and HalfCheetah \citep{todorov2012mujoco,brockman2016openai}. 


\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-2mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/maze.png} 
\label{fig:per-task}
\vspace{-4mm}
\end{minipage}
\end{wrapfigure}


\paragraph{Maze} {\em (two navigation environments).} 

\vspace{-2mm}
Maze comprises environments where an agent must reach a specified goal within a maze \citep{gupta2020relay}. Two types of agents are available: a 2-degrees of freedom (DoF) ball (Point-Maze) and a more complex 8-DoF quadruped robot (Ant-Maze) from Gymnasium-MuJoCo. Various goals and maze configurations can be generated to create tasks of varying difficulty.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-4mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/fetch.png}
\vspace{-10mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}

\paragraph{Fetch} {\em  (four tasks for Fetch Mobile Manipulator robot arm).} 

\vspace{-2mm}
Fetch features a 7-degrees of freedom (DoF) \href{https://fetchrobotics.borealtech.com/robotics-platforms/fetch-mobile-manipulator/?lang=en}{Fetch Mobile Manipulator arm} with a two-fingered parallel gripper \citep{plappert2018multi}. The environment consists of a table with various objectives, resulting in four tasks: Reach, Push, Slide, and PickAndPlace, which involve picking up or moving the objects to specified locations.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-1mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/kitchen.png}
\vspace{-4mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{Franka Kitchen} {\em  (tasks need long-horizon, multi-task planning for a robot arm).} 

\vspace{-2mm}
This environment is based on a 9-degrees of freedom (DoF) \href{https://franka.de/}{Franka} robot situated in a kitchen containing common household items like a microwave and cabinets \citep{gupta2020relay}. The task goal is to achieve a specified configuration, which may involve planning and completing multiple sub-tasks. For example, a goal state could have the microwave open, a kettle inside, and the light over the burners turned on. 

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    % \vspace{-2mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/dexterous.png} 
\vspace{-4mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{Dexterous Hand} {\em (five dexterous hand manipulation tasks).} 

\vspace{-2mm}
It is based on the Shadow Dexterous Hand --- an anthropomorphic 24-DoF robotic hand with 92 touch sensors at palm and phalanges of the fingers \citep{plappert2018multi, melnik2021using}. The tasks involve manipulating various objects, such as a pen, egg, or blocks.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-5mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/adroit.png} 
\vspace{-4mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{Adroit} {\em  (four manipulation tasks for a dexterous hand attached to a free arm).} 

\vspace{-2mm}
This environment features a free arm equipped with a Shadow Dexterous Hand, providing up to 30-DoF \citep{rajeswaran2018learning}. The high degree of freedom enables the robot to perform more complex tasks, such as opening a door with a latch (AdroitHandDoor).

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-4mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/humanoid2.png} 
\vspace{-4mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{HumanoidBench} {\em (four tasks for a high-dimensional humanoid).} 

\vspace{-2mm}
We incorporate four tasks from the recent HumanoidBench \citep{sferrazza2024humanoidbench} designed mainly for a Unitree H1 humanoid robot \footnote{https://www.unitree.com/h1/}, which is equipped with two dexterous Shadow Hands. Specifically, we include two manipulation tasks (push, truck) and two locomotion tasks (reach, slide), all of which require sophisticated coordination among various body parts.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-3mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/robosuite2.png} 
\vspace{-10mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{Robosuite} {\em  (twelve tasks for various modular robot platforms).} 

\vspace{-2mm}
Robosuite is a popular modular benchmark \citep{zhu2020robosuite} that supports seven robot arms, eight grippers, and six controller modes. The manipulation tasks are conducted in environments with doors, tables, and multiple robot arms, with goals such as wiping tables or coordinating to transfer a hammer. Additionally, we introduce a new task—MultiRobustDoor—featuring an adversarial arm that impedes another arm's success to test robustness.

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-4mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/safemujoco.png} 
\vspace{-4mm}
\label{fig:per-task}
\end{minipage}
\end{wrapfigure}


\paragraph{Safety MuJoCo} {\em (nine control tasks with additional safety constraints).} 

\vspace{-2mm}
Built on standard robot models in Gymnasium-MuJoCo, the Safety MuJoCo tasks are designed for scenarios that prioritize both long-term returns and safety. These tasks incorporate safety constraints, such as limiting velocity and preventing robots from falling \citep{gu2024balance}.



\paragraph{MAMuJoCo} {\em (twelve multi-agent cooperation tasks).} 

\begin{wrapfigure}{r}{0.17\textwidth}
\begin{minipage}{\linewidth}
    \centering
    \vspace{-7mm}
\includegraphics[%scale=1
                 width=1.0\linewidth]{figures/framework/mamujoco.png} 
\label{fig:per-task}
\vspace{-7mm}
\end{minipage}
\end{wrapfigure}

\vspace{-2mm}
MAMuJoCo is based on a multi-agent platform from the factorizations of Gymnisium-MuJoCo robot models \citep{peng2021facmac}. The tasks need to be solved by cooperations of multiple agents. This set of tasks are vulnerable to disturbance like one leg of a quadruped robot is malfunctioning, or all dynamics of legs are contaminated by system noise.
\FloatBarrier

\subsection{Disruptor design: modes and frequencies}\label{sec:benchmark-disruptor-modes}

In a \fname, disruptors affecting various stages of the agent-environment interaction can operate in different modes. We typically consider four common modes found in the robust RL literature, each driven by specific real-world scenarios and robustness requirements. These modes allow the construction of tasks with varying levels of difficulty:
\begin{itemize}
     \item  {\em Random disturbance: for all disruptors.} Stochastic noise is ubiquitous in sensors, mechanical hardware, and random events, often modeled as random noise added to nominal components in the interaction process \citep{duan2016benchmarking}. The noise typically follows a distribution such as Gaussian or uniform. This mode can be applied to all disruptors, affecting the agent's observed state, observed reward, action, and environment.

     We offer Gaussian distribution $\cN(\cdot,\cdot)$ \citep{zhang2018natural} and bounded uniform distribution $\cU(\cdot,\cdot)$ \citep{zouitine2024rrls} as default options. For instance, the environment-disruptor can introduce noise to robot dynamics (e.g., mass, torso length) or external factors (e.g., gravity, wind), as shown in  Fig.~\ref{fig:attack-distributions-mujoco-ant-wind-humanoid-gravity}. The observation-disruptor can add noise to the observed state and/or reward, namely, $\widetilde{s}_t = s_t + \mathcal{N}(\mu_s, \sigma_s)$ ($\mu_s$ and $\sigma_s$ are the mean and variance) or $\widetilde{s}_t = s_t + \mathcal{U}(a_s, b_s)$ ($a_s, b_s$ are the min and max thresholds). The action-disruptor can also introduce noise to the action sent to the environment.
     
    \item {\em Adversarial disturbance: for all disruptors.} In real-world applications, adversarial disturbances occur when external forces deliberately attempt to degrade the agent's performance. This mode is also relevant when prioritizing safety, ensuring the agent can perform well in worst-case scenarios within certain predefined sets. It can be applied to all three disruptors.

    This mode can be viewed as a two-player zero sum game between the agent and an adversarial player \citep{tanabe2022max}. Any algorithms can acts as the adversarial player through this interface to adversarially attack the process. This mode is applicable to all disruptors; for instance, the observation-disruptor generates a fake state that falls within the prescribed set around the true state, or the environment-disruptor adjusts parameters within a neighborhood of the nominal values; 

    Notably, in our benchmark, we implement and feature an algorithm leveraging LLM to determine the disturbance. In particular, the LLM is told of the task and uses the current state and reward signal as the input. It directly outputs the disturbed results like a fake state for the agent. See more details in the code \ref{lst:python-llms-adversary-example} in Appendix \ref{appendix-framework:benchmark-features}. 
    
    \item  {\em Internal dynamic shift: for the environment-disruptor.} This mode captures variations in the agent's internal model between training and testing, caused by factors such as the sim-to-real gap, measurement noise, or accidental malfunctions. The environment-disruptor introduces biases to dynamic parameters within a prescribed uncertainty set. For example, the torso length  (Fig.~\ref{fig:attack-distributions-mujoco-ant-wind-humanoid-gravity} (c)) might shift from $0.3$ to $0.5$.

    For tasks in control and robotics, the environment disruptor can alter the robot model, changing the system's internal dynamics \citep{zhang2020robust, zouitine2024rrls}. Using Gymnasium-MuJoCo as an example,  Fig.~\ref{fig:environment-shift-examples}(b)-(c) depict the consequences of such disruption by altering the Ant robot's head and legs around its original model (Fig.~\ref{fig:environment-shift-examples}(a)).
    
    \item {\em External disturbance: for the environment-disruptor.} Nonstationarity in the external workspace can result from variability in the physical world or human behavior, such as changes in wind, friction, or human intervention. The environment-disruptor uses this mode to modify the external task environment by altering properties and configurations within the robot's workspace or by introducing abrupt external interventions \citep{luoompo2024, pinto2017robust, ding2024seeing}. 
    
    For example, in robosuite, Fig.~\ref{fig:environment-shift-examples}(e)-(f) illustrate disrupted tasks compared to the original reference in Fig.~\ref{fig:environment-shift-examples}(d). In these tasks, the environment disruptor changes the distance between the table and the arm, or even introduces an additional arm to actively interfere with the yellow-black robot's ability to accomplish its goal.
 
\end{itemize}

\paragraph{Timing of operations for disruptors.}
We support perturbations occurring at any stage of the process and at different frequencies. Users can choose to apply perturbations at any time step or episode during the training process, or exclusively during testing.



 \begin{figure}[tb]
     \centering
     \includegraphics[width=1.0\linewidth]{figures/framework/env-shift-examples.png}
     \caption{Illustration of two disruption modes of the environment-disruptor: internal dynamic shift and external disturbance.}
     % \vspace{-15pt}
     \label{fig:environment-shift-examples}
 \end{figure}





\subsection{Constructing robust RL tasks}
\name is a modular benchmark that offers flexible methods for constructing robust RL tasks through three main steps. First, we select a task base from the eleven options outlined in Sec.~\ref{sec:task-base}. Second, we choose a disruptor from the observation, action, and environment categories introduced in  Sec.~\ref{sec:benchmark-disruptor-modes}), and specify its operation modes (random disturbance, adversarial disturbance, internal dynamic shift, and external disturbance, as detailed in Sec.~\ref{sec:benchmark-disruptor-modes}). Finally, we determine the interaction process and frequencies between the disruptor, agent, and environment. 

In addition to these basic construction methods, our benchmark supports advanced modes:  {\em A combination of disruptors} allows users to select multiple disruptors, such as an observation-disruptor and an environment-disruptor, to simulate conditions where perception sensors have system noise and external disturbances from human occur; {\em Varying operation frequencies} enables disruptors to operate intermittently during interactions, either at fixed intervals or in a random pattern to characterize accidental events and uncertainties.





% \begin{itemize}
% \item Random disturbance: single, safe, + multi-agent: MujoCo, 
% \item adversarial (LLM): include MuJoCo
% \item dynamic shift: MuJoCo \citep{luoompo2024}
% \item external: add wind in MuJoCo, robosuite + arm
% \end{itemize}




% \begin{figure}[htbp!]
%  \centering
%   \subcaptionbox{}
%   {
% \includegraphics[width=0.22\linewidth]{figures/mujoco-dynamics/ant-original.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.265\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.225\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics-02.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.225\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics-03.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.22\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics-04.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.25\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics-05.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.22\linewidth]{figures/mujoco-dynamics/robust-ant-dynamics-06.png}
% }    
%  	\caption{\normalsize Examples of robust MuJoCo dynamics: Robust Ant tasks.
%  	} 
%   \label{fig:robust-mujoco-dynamics-ant}
%  \end{figure} 


% \begin{figure}[htbp!]
%  \centering
% %  \subcaptionbox{}
% %   {
% % \includegraphics[width=0.205\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-01.png}
% % }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.265\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-02.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.225\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-03.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.27\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-04.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.18\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-05.png}
% }    
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.3\linewidth]{figures/mujoco-dynamics/halfcheetah/halfcheetah-06.png}
% }    
%  	\caption{\normalsize Examples of robust MuJoCo dynamics: Robust HalfCheetah tasks.
%  	} 
%   \label{fig:robust-mujoco-dynamics-halfcheetah}
%  \end{figure} 
 







% \begin{figure}[htbp!]
%  \centering
%   \subcaptionbox{}
%   {
% \includegraphics[width=0.17\linewidth]{figures/robosuite/door-07.png}
% }   
%   \subcaptionbox{}
%   {
% \includegraphics[width=0.14\linewidth]{figures/robosuite/door-02.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.14\linewidth]{figures/robosuite/door-03.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.132\linewidth]{figures/robosuite/door-04.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.147\linewidth]{figures/robosuite/door-05.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.228\linewidth]{figures/robosuite/door-06.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.12\linewidth]{figures/robosuite/door-08.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.14\linewidth]{figures/robosuite/door-09.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.233\linewidth]{figures/robosuite/door-01.png}
% }    
%  	\caption{\normalsize Examples of robust Robosuite: Random attack on environments.
%  	} 
%   \label{fig:robust-robosuite-door-random-attack-environments}
%  \end{figure} 




% \paragraph{Robust Semantic-Domain Shifted Robot Manipulation Tasks:}
% Figures \ref{fig:robust-robosuite-door-semantic-sttack}(a)-(d) illustrate semantic-domain shifted attacks in robot manipulation tasks, specifically in door-opening scenarios. These figures demonstrate a dynamic environment where the position of the door handles changes based on the robot's proximity to the door:

% (1) When the robot is far from the door, the handle is consistently positioned on the bottom right side of the door.
% As the robot approaches within a certain proximity threshold to the door, the handle's position shifts unpredictably to either the top left or top right side of the door.
% (2) This semantic-domain shift presents a unique challenge for robotic systems, requiring adaptive decision-making capabilities. The robot must recognize the change in the handle's position and adjust its approach and manipulation strategy accordingly. Such scenarios test the robustness of the robot's visual processing, spatial awareness, and RL algorithms in the face of dynamic, context-dependent environmental changes.

% These examples underscore the importance of developing robust and adaptable robotic systems capable of handling unexpected semantic changes in their operational environment, a crucial factor for successful deployment in real-world, dynamic settings.

% % Robust Semantic-Domain Shifted Robot Manipulation Tasks: As shown in Figures \ref{fig:robust-robosuite-door-semantic-sttack}(a)-(d), which are semantic-domain shifted attack robot manipulation in door open tasks. Specifically, if the robot is far from the door, the door handle will appear on the bottom right side. However, if the robot is within a certain distance from the door, the handle will appear on either the top left or top right side.

%  \begin{figure}[htbp!]
%  \centering
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.11\linewidth]{figures/robosuite/door-10.png}
% }    
%   \subcaptionbox{}
%   {
% \includegraphics[width=0.155\linewidth]{figures/robosuite/door-11.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.145\linewidth]{figures/robosuite/door-12.png}
% }   
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.165\linewidth]{figures/robosuite/door-13.png}
% }   
%  	\caption{\normalsize Examples of robust Robosuite---semantic attacks.
%  	} 
%   \label{fig:robust-robosuite-door-semantic-sttack}
%  \end{figure} 

%  \paragraph{Robust Random Attack and Set Attack on all Robot Tasks:} As illustrated in \ref{fig:random-set-arbitrary-tasks}, these tasks encompass a variety of robust challenges: (1) Robust Box2D Tasks: Engage with 2D physics environments specifically designed for robustness evaluation. (2) Robust Robot Manipulation Tasks: Conduct robust manipulation using Kuka and Franka robots. (3) Robust Safety Tasks: Emphasize safety within robustness assessments. (4) Robust Android Hand Tasks: Tackle sophisticated hand manipulation challenges in robust settings. (5) Robust Dexterous Tasks: Enhance robust capabilities in dexterous robotics. (6) Robust Fetch Manipulation Tasks: Perform robust object manipulation with Fetch robots. (7) Robust Robot Kitchen Tasks: Execute robust manipulations in kitchen environments using robots. (8) Robust Maze Tasks: Navigate mazes with robust robots. (9) Robust Multi-Agent Tasks: Promote robust coordination among multiple agents.



%  \begin{figure}[htbp!]
%  \centering
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.3\linewidth]{figures/non-stationary/different-task-settings.pdf}
% } 
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.3\linewidth]{figures/non-stationary/different-road.pdf}
% } 
%  \subcaptionbox{}
%   {
% \includegraphics[width=0.3\linewidth]{figures/non-stationary/task-disturbance.pdf}
% } 
%  	\caption{\normalsize Examples of robust non-stationary tasks \citep{luoompo2024}.
%  	} 
%   \label{fig:robust-non-stationary-ours}
%  \end{figure} 




 