\section{Problem Formulation}
\subsection{System Overview}
\label{subsec:sys-overview}

%\xiaoxi{Please replace the crowdsensing task to Scenario I: large-model fine-tuning tasks and change the AoI metric to test accuracy. The large-model driven task can be for entertainment supported by future IVI systems. For each vehicle, it can collect data at a PoI, either does local fine-tuning (meaning it has to pull from the RSU and store a large-language model and LoRA adapters), or uploads data to the RSU for fine-tuning at the RSU. The input data for fine-tuning has temporal-spacial heterogeneity. Specifically, the data at different PoI locations are non-IID and have different data sizes. Therefore, the sequence of locations each vehicle arrives to collect the data affects the accuracy, similar to conventional training. Here, we consider fine-tuning because vehicles can't do entire model training due to resource limits.} 

%\xiaoxi{Section \ref{subsec:sys-overview} should describe a problem overview with system architecture, where AI-defined ride-hailing vehicles can do a traditional task, which is serving orders by picking up passengers, and performing AI tasks when moving around. The considered AI tasks include LLM tasks that need continuous fine-tuning and inference for various future infotainment services, e.g., large-model based recommendation or generative AR/VR gaming. Given the storage and computation capacities, vehicles can do light-weight LoRA-based fine-tuning when encountering task shift or inference accuracy decay.}
\begin{table}[t]

\caption{Key Notations with Description.}
\label{table:notation}
\centering
\begin{threeparttable}
\begin{tabular}{c p{6cm}}
\toprule
Notation & Explanation \\
\midrule
{$m$, $M$, $\mathcal{M}$} & Vehicle index, number of vehicles, Vehicle set \\

\midrule
{$g$, $G$, $\mathcal{G}$} & Grid index, number of grids, Grid set\\

\midrule
{$t$, $T$, $\mathcal{T}$} & Time slot index, number of time slots, time slot set\\

\midrule
{$o$, $\mathcal{O}_t$} & Order index, Order set\\

\midrule
{$p$, $\mathcal{P}_t$} & PoI index, PoI set\\

\midrule
{$g_t^m$} & Index of grid vehicle $m$ is located\\

\midrule
{$\mathcal{N}(g)$} & Neighboring grids set of grid $g$\\

\midrule
{$\sigma(o)$} & Price of order $o$\\

\midrule
{$d\left(p\right)$} & Data volume of PoI $p$\\

\midrule
{$\eta$} & The rank of the low-rank matrices in LoRA\\

\midrule
{$\lambda_{t}^p$} & Data AoI of PoI $p$\\

\midrule
{$u_{t}^p$} & The data utility of the PoI $p$\\

\midrule
{$\textbf{x}$, $\textbf{y}$, $\textbf{z}$} & Vehicle dispatching, order accepting, data collecting\\


\midrule
{$s_{m,t}$, $a_{m,t}$, $r_{m,t}$} & State, action and reward of vehicle $m$\\

\bottomrule
\end{tabular}
\begin{tablenotes}   
        \footnotesize               
        \item[1] $\bullet$ We omit descriptions such as ``at time slot $t$".     
      \end{tablenotes}           
    \end{threeparttable}

\end{table}

In this section, we provide a detailed description of our scenario. We consider a vehicular network, consisting of a large number of moving ride-hailing vehicles that are managed by a cloud platform (such as DiDi or Urber) within a certain geographical range and can interact with RSUs equipped with edge servers. Beyond the routine operations of picking up and dropping off passengers, each vehicle actively engages in urban sensing tasks. Leveraging the installed professional sensors and smartphones, the vehicles can collect data from PoIs distributed across the designated area. We define $\mathcal{M} \triangleq \left\{m | m = 1,2,\cdots, M\right\}$ to represent the set of vehicles in the system. The activity range of each vehicle is limited to the target area. Similar to many prior studies \cite{KDD18, KDD22}, we discretize the target area into $G$ grids, represented by set $\mathcal{G} \triangleq \left\{g|g = 1, 2, \cdots, G \right\}$. Similarly, the time horizon is also divided into several discrete time slots, represented by $\mathcal{T} \triangleq \left\{t| t = 1, 2, \cdots, T \right\}$. The set of orders and the set of PoIs at time slot $t$ are $\mathcal{O}_t$ and $\mathcal{P}_t$, respectively. At time slot \( t \), the set of orders is denoted as \( \mathcal{O}_t \), and the set of Points of Interest (PoIs) is represented as \( \mathcal{P}_t \). 
% \broken{
To account for task-specific requirements, \( \mathcal{P}_t \) can be decomposed into subsets, where each subset corresponds to a distinct type of data PoI associated with a particular task. Formally, this decomposition can be expressed as:  
\begin{align}
    \mathcal{P}_t = \bigcup_{k \in \mathcal{K}} \mathcal{P}_{t,k}, \quad \mathcal{P}_{t,k} \cap \mathcal{P}_{t,j} = \emptyset, \, \forall k \neq j,
\end{align}
where \( \mathcal{K} \) is the set of task types, and \( \mathcal{P}_{t,k} \) denotes the subset of PoIs related to task \( k \). For instance, \( \mathcal{P}_{t,1} \) represent PoIs contributing to Vision Transformers (ViT)\cite{dosovitskiy2020image} based tasks such as image classification, while \( \mathcal{P}_{t,2} \) corresponds to PoIs relevant to SAM-based tasks like image segmentation. 
% }
% \xiaoxi{Should be further decompose $\mathcal{P}_t$ into subsets, each of which represents a set of data PoIs for a distinct task, e.g., ViT-based tasks should be different from BERT-based??}
Since the number of orders and PoIs change at each time slot, the size of $\mathcal{O}_t$ and $\mathcal{P}_t$ can be distinct across $t$. We consider vehicles that currently not serving orders or collecting data as available vehicles. For grid $g$, we use $\mathcal{O}_t^g$, $\mathcal{M}_t^g$ and $\mathcal{P}_t^g$ respectively to represent the set of orders, the set of available vehicles, and the set of PoIs in grid $g$ at time slot $t$. The index of the grid (interchangeable with location in this paper) where vehicle $m$ is located at time slot $t$ is $g_t^m$, where we have $g_t^m \in \mathcal{G}$. To maximize the effectiveness of order-serving and data collection, each available vehicle $m$ needs to decide whether to accept an order $o \in \mathcal{O}_t^{g_t^m}$, collect data from a PoI $p \in \mathcal{P}_t^{g_t^m}$, or travel to another grid. Once an available vehicle 
$m$ accepts an order or collects data from a PoI, it becomes unavailable and will revert to being available again after completing passenger drop-off or data collection. For convenience, some of the important notations used in the paper are listed in Table \ref{table:notation}.

\subsection{Primer on Model Fine-tuning with LoRA}
\label{ssec:primer-lora}
% \broken{
Low-Rank Adaptation (LoRA) is a powerful technique designed to efficiently fine-tune large pre-trained models, without the need to retrain all model parameters. Traditional fine-tuning methods often involve updating the entire model’s weights, which can be computationally expensive and resource-intensive, especially with massive models. LoRA addresses this by observing that the difference between the pre-trained weights and the fine-tuned weights often lies in a low-dimensional subspace. Thus, LoRA introduces a low-rank approximation to model these changes, significantly reducing the number of parameters that need to be updated. The benefits of LoRA include a substantial reduction in memory and computational costs, as well as the ability to adapt large models to new tasks with minimal overhead.
Formally, LoRA modifies the weight matrix $W_0 \in \mathbb{R}^{d \times k}$ of a pre-trained model by introducing a low-rank update, represented as $W_0 + \Delta W = W_0 + BA$, where $B \in \mathbb{R}^{d \times \eta}$ and $A \in \mathbb{R}^{\eta \times k}$, with $\eta \ll \min(d, k)$. The matrices $B$ and $A$ are the only trainable parameters, while the original weights $W_0$ are frozen.  The model input is denoted as $x$, and the output is represented as $h$. The forward pass incorporating the LoRA module is given by:
\begin{align}
h = W_0 x + \gamma \eta BA x,
\end{align}
where \( \gamma \) is a scaling factor, and \( \eta \) is the rank of the low-rank matrices. This formulation shows how LoRA modifies the original model by adding a low-rank update in parallel to the pre-trained weights. The rank \( \eta \) controls the capacity of the low-rank adaptation, allowing for efficient fine-tuning with minimal changes to the original model. Additionally, LoRA preserves computational efficiency during inference, making it particularly useful for deployment in resource-constrained environments.
% }
% \bo{Need to add: $x$ is the model input, $h$ is output}
% \xiaoxi{Boken, please add a basic introduction (a short paragraph) to describe the LoRA technique (its goal, benefits, and so on), and then add some basic formulations for the readers to learn what LoRA is.}


\subsection{QoS and Optimization Modeling for Vehicular Joint Tasks}
\label{ssec:optimization-qos}

Subsequently, we define the Accumulated Driver Income (ADI), the Accumulated Data Utility (ADU), and the QoS. Following this, we give the mathematical form of the problem and the optimization goal.

\noindent\textbf{Definition 1. (ADI)} We use $\mathcal{O}_t^{'g}$ to denote the set of orders accepted by vehicles in grid $g$ at time slot $t$. For order $o$ within the set $\mathcal{O}_t^{'g}$, we denote by $\sigma(o)$ the price of order $o$. ADI represents the total income of all drivers over all time slots, so the expression for ADI is as follows: 
\begin{align}
ADI 
    = \sum\limits^{T}_{t=1} \sum\limits^{G}_{g=1}\sum\limits^{}_{o \in \mathcal{O}_t^{'g}} \sigma(o).
\end{align}

There are several PoIs distributed within each grid, and vehicles can collect data from these PoIs. Each PoI $p \in \mathcal{P}_t$  is associated with a certain volume of data $d(p)$ that needs to be collected. To maintain data integrity and prevent excessive bandwidth usage, we assume that an available vehicle can collect data from only one PoI at a time, and the collection process continues until the pending data volume at the PoI is reduced to 0. 




%%%%%%%%%%%%% AoI and CDV %%%%%%%%%%%%%%%%%%%%%%%%%%%


% In numerous tasks emphasizing the timeliness of data, age-of-information (AoI) is commonly employed to characterize data freshness \cite{introduce_AoI1, introduce_AoI2}. In this study, we utilize the elapsed time from data generation to the current time slot as the representation of data AoI. In detail, $\lambda_t^{p}$ represents the AoI of the PoI $p$ at time slot $t$. We establish that the AoI for a newly generated PoI is 1, with the AoI incrementing by 1 for each subsequent time slot, i.e.,
% \begin{align}
%     \lambda_{t+1}^p = \lambda_t^p + 1.
%     \label{equ:aoi increase}
% \end{align}
% When the AoI reaches a certain threshold, the PoI data will be cleared.

% We define CDV to denote the total volume of data collected by vehicles over all time slots, which is expressed as:
% \begin{align}
% CDV = \sum\limits^{T}_{t=1} \sum\limits^{G}_{g=1}
% \sum\limits^{}_{p \in \mathcal{P}_t^{'g}}
% b\left(p\right).
% \end{align}
%{and the volume of data collected in a grid will not be greater than the volume of data in the grid, i.e.:
%\begin{align}
%\sum \limits^{}_{m \in {\mathcal{C}_t^g}}d_t^{m} \leq b_t^g,\quad %\forall g \in \mathcal{G} \quad \forall t \in \mathcal{T}.
%\end{align}
%}



% \textbf{Definition 3. (AoI)} In many tasks that focus on data timeliness, AoI is often used to describe the freshness of data. In this paper, we use the time elapsed from the generation of the data to the current time slot to represent the AoI of the data. In detail, $\lambda_t^{p}$ represents the AoI of the PoI $p$ at time slot $t$. We set that the AoI of the newly generated PoI is 1, and the AoI increases by 1 for each time slot, i.e.,
% \begin{align}
%     \lambda_{t+1}^p = \lambda_t^p + 1.
%     \label{equ:aoi increase}
% \end{align}

%We define an indicator $u$ to comprehensively evaluate the volume and AoI of the collected data. The utility of the data collected from PoI $p$ is denoted as $u_t^p$, which is the ratio of data volume to AoI, i.e.,
% \begin{align}
% \label{equation: data utility}
% u_t^{p} = \frac{d(p)}{\lambda_t^{p}}.
% \end{align}


%%%%%%%%%%%%% END: AoI and CDV %%%%%%%%%%%%%%%%%%%%%%%%%%%




\noindent\textbf{Definition 2. (ADU)} We define ADU as the sum of the data utility collected by all vehicles in all time slots. The expression for ADU is defined as:
\begin{align}
ADU =  \sum\limits^{T}_{t=1} \sum\limits^{G}_{g=1} \sum\limits^{}_{p \in {\mathcal{P}}_t^{'g}} u_t^p,
\end{align}
where $\mathcal{P}_t^{'g}$ is the set of PoIs collected in grid $g$ at time slot $t$. We use ADU to indicate the quality of VCS in the following sections.

\begin{figure}[t]
\hspace{-1cm}  % 向左调整图片的位置
\subfigure[Accuracy as a function of data freshness or AOI for two different tasks.]{
\label{fig: sub.1 aoi}
\includegraphics[width=0.5\textwidth]{figure/aoi.png}}
\subfigure[Accuracy as a function of data volume for the same tasks.]{
\label{fig: sub.2 data_volume}
\hspace{-0.4cm}  % 向左调整图片的位置
\includegraphics[width=0.5\textwidth]{figure/data_volume.png}}
\caption{The impact of data freshness and data volume on the fine-tuning accuracy of different tasks under different UFMs.}
\label{fig: impact_on_fine-tune}
\end{figure}

\noindent{\bf Freshness and quantity based data utility.} Many existing studies tend to overlook the importance of data freshness in model fine-tuning, yet we explicitly take into account the effects of using various freshness degrees of collected data to fine-tune the foundation model using LoRA techniques, and we focus on the inference accuracy of such fine-tuned models varying data freshness. Intuitively, the freshness of data should hold significant relevance in numerous real-time VCS tasks \cite{the_reason_why_data_freshness_is_important}. For instance, in traffic monitoring, the most recent traffic data is more beneficial for intelligent transportation systems \cite{a_example_for_the_reason_why_data_freshness_is_important}. But these works are not foundation fine-tuning tasks and the task performance has different metrics from ours. 
% \broken{
To verify this intuition, we conducted a series of experiments on various large model fine-tuning tasks, including LoRA-based fine-tuning for image classification using ViT and image segmentation using SAM. As Fig.~\ref{fig: impact_on_fine-tune} show, the relationship between fine-tuning accuracy and data freshness exhibits a complex and often unpredictable pattern. Specifically, accuracy tends to follow a concave or even linear decay as data freshness decreases, though the exact functional form is task-dependent and difficult to predict. This underscores the challenge of modeling data freshness in real-world applications. To address this uncertainty, we propose leveraging DRL to learn optimal fine-tuning strategies for varying data freshness. Additionally, our experiments reveal that accuracy improves with the volume of data, but the relationship is not linear. As the amount of data increases, the fine-tuning accuracy shows a logarithmic growth, and beyond a certain threshold, further increases in data volume yield diminishing returns. This phenomenon is consistent with the scaling laws for neural language models\cite{kaplan2020scaling}, which highlights the diminishing impact of additional training data after reaching a critical dataset size. These results emphasize the importance of considering both data freshness and quantity when fine-tuning UFMs, and highlight the potential of DRL in optimizing these factors for improved task performance.
% }
% \xiaoxi{Please elaborate that we did our own experiments to verify this intuition for various large model fine-tuning tasks, and highlight the specific function forms (e.g., maybe concave or convex, or linear decay) are uncertain and hard to predict, so as to motivate using DRL to learn. Maybe put two figures showing the curves of acc w.r.t. staleness of two different tasks here; then put two figures of curves of acc w.r.t. data volumes of two corresponding tasks here.} %Considering these factors, we establish an inverse relationship between data utility and AoI in equation (\ref{equation: data utility}) to depict the impact of AoI. 

\smallskip
\noindent{\bf Spatio-temporal heterogeneity and task differences.} 
% ~\broken{
Data collection for fine-tuning tasks exhibits significant spatio-temporal heterogeneity and task-specific variations. Spatially, different PoIs are associated with distinct distributions of collected datasets, influenced by factors such as regional activity patterns, environmental features, and task-specific requirements. These datasets are further tied to varying types of tasks and corresponding base models, such as image classification using ViT or image segmentation with SAM. This spatial diversity necessitates careful consideration of the data's regional context when fine-tuning models. Temporally, the heterogeneity arises from the varying arrival times of vehicles at PoIs. As vehicles may visit a PoI at different times, the freshness of the collected data naturally declines over time, as discussed in the previous section. This temporal decay in data freshness introduces additional complexity to tasks that rely on timely and accurate data for model fine-tuning. Balancing these temporal factors is critical for maintaining the relevance and utility of the collected data.
% }
% \xiaoxi{First, please emphasize different locations of data PoI have different distribution of fine-tuning datasets. Also, these datasets may be associated with different tasks and base models (ViT, SAM, etc.) Then, the temporal heterogeneity is reflected in that vehicles may come to any given PoI at different times; if they come later, the data freshness may be decreased, as introduced in the above paragraph. Then, talk about the utility function of order serving is different from that of fine-tuning tasks:}
For better comprehension, we consider the price of an order as the utility of the order. The utility of an order remains constant from the time of its creation until its expiration, during which the utility that a driver can obtain by accepting the order is equivalent to the order's price. If the order expires, its utility abruptly drops to 0. The variation trends in the utility of orders and PoIs are distinct, implying that accepting orders or collecting data at suitable times and locations may potentially minimize the impact between the profit generated from passenger transportation and the utility derived from data collection. 
% \begin{figure}[t]
% \centerline{\includegraphics[width=0.6\linewidth]{figure/difference rewrd.png}}
% \caption{The value of orders and data changes over time.
% }
% \label{fig: order and data change}
% \end{figure}


\noindent\textbf{Definition 3. (QoS)} To finally capture the overall performance of order-serving and fine-tuning tasks, we propose a QoS function to evaluate the overall utility of all the vehicles in the network that accomplish both order serving and model fine-tuning tasks, i.e.,
\begin{align}
QoS = \alpha ADI + \beta ADU, \label{equ: qos def}
\end{align}
where $\alpha$ and $\beta$ are importance factors that balance the contributions of ADI and ADU, respectively. These weights are determined collaboratively by stakeholders, such as government entities or organizations overseeing vehicle-sensing coordination tasks and ride-hailing companies responsible for passenger service. By setting these hyperparameters in advance, the system adapts to operational priorities and ensures alignment with strategic objectives.

In our settings, the operations that each available vehicle can perform are denoted as \textbf{x}, \textbf{y}, and \textbf{z}, corresponding to dispatching, order acceptance, and data collection, respectively. The dispatching decision \textbf{x} exerts a certain impact on both \textbf{y} and \textbf{z}, and has a long-term impact on QoS. Specifically, in real-world applications, the distribution of orders in the city is non-uniform, and a sequence of dispatch decisions for a vehicle will allocate the vehicle to grids with varying order quantities. The vehicle assigned to grids with a lower supply-demand ratio has more opportunity to match an order successfully. Although the distribution of PoIs is often related to the type of VCS task, in some cases the distribution of PoIs is not uniform and the data utility of different PoIs in different grids is also different. We express the mathematical form of our optimization problem as follows.
\begin{align}
\underset{\mathbf{\textbf{x},\textbf{y},\textbf{z}}}{\text{Max}}
 &\hspace{3mm}
 {QoS(\textbf{x}, \textbf{y}, \textbf{z})}& \label{max obj}\\
 \text{S.t.} 
 &\quad x_t^{m, g} \in \left\{0,1\right\}, \forall m \in \mathcal{M}, \ t \in \mathcal{T}, \ g \in \mathcal{N}(g_t^m) \label{cst: x binary}\\
 & \quad y_t^{m} \in \left\{0,1\right\}, \forall m \in \mathcal{M}, \ t \in \mathcal{T} \label{cst: y binary}\\
 & \quad z_t^{m} \in \left\{0,1\right\}, \forall m \in \mathcal{M}, \ t \in \mathcal{T} \label{cst: z binary}\\
 & 0 \leq \sum\limits^{}_{g \in {\mathcal{N}(g_t^m)} } x_t^{m, g} \leq 1, \forall m \in \mathcal{M}, \ t \in \mathcal{T} \label{cst: one x} \\
 & \sum\limits^{}_{g \in {\mathcal{N}(g_t^m)} } x_t^{m, g} + y_t^m + z_t^m = 1, \forall m \in \mathcal{M}, \ t \in \mathcal{T} \label{cst: one choice}
\end{align}

Here, constraints (\ref{cst: x binary}), (\ref{cst: y binary}), and (\ref{cst: z binary}) denote that vehicle dispatching decision $x_t^{m,g}$, order-accepting decision $y_t^{m}$, and data-collecting decision $z_t^m$ are binary. In constraint (\ref{cst: x binary}), $g_t^m$ represents the grid where vehicle $m$ is currently located, and $\mathcal{N}(g)$ represents the set of grids adjacent to grid $g$ (including grid $g$ itself). For each vehicle, $x_t^{m,g}$ is only positive (= 1) when vehicle $m$ is dispatched to grid $g$ at time slot $t$, otherwise it is 0 (constraint (\ref{cst: x binary})). When $x_t^{m,g_t^m} = 1$, it means that vehicle $m$ decides to stay in its current grid $g_t^m$. $y_t^{m}$ is 1 only when $m$ decide to accept an order at time slot $t$, otherwise 0 (constraint (\ref{cst: y binary})). Similarly, $z_t^{m}$ is 1 only when $m$ decides to collect data from a PoI at time slot $t$, otherwise 0 (constraint (\ref{cst: z binary})).
Inequality (\ref{cst: one x}) denotes that vehicle $m$ has only one dispatch destination at a time slot. Equation (\ref{cst: one choice}) denotes that at each time slot, vehicles choose one of three choices: traveling to the dispatching destination $g \in \mathcal{N}(g_t^m)$, accepting an order, and collecting data. Note that the vehicles we mention in this section refer to the ones that are available at the current time slot.

Our mathematical models (\ref{max obj})-(\ref{cst: one choice}) describe the joint ride-hailing vehicles dispatching and crowdsensing scenarios. This is an online and sequential decision-making problem where decisions need to be made in real-time based on available information. Reinforcement learning emerges as a superior approach for addressing such problems. Our method is introduced in the next section.





 