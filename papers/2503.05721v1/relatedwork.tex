\section{Related work}
Research on data filtering strategies for harm reduction has been propelled by the research on biases in LLMs \cite{bender2021dangers} and in pretraining datasets \cite{jo2020lessons}. However, critical studies on strategies focused on specific datasets rather than the impact of strategies themselves. \citet{luccioni2021s} analyzed the presence of Hate Speech in the Common Crawl dataset. \citet{dodge2021documenting} documented the C4 corpus \cite{raffel2020exploring}, showing that its filtering correlates with a reduction of terms defining vulnerable groups to discrimination in datasets. \citet{longpre-etal-2024-pretrainers} tested the correlation between removing toxic contents from pretraining datasets and LLMs performance in toxicity classification, showing that filtering has a negative impact on this task. The survey of \citet{albalak2024survey} on data selection for LLMs provide a marginal and non-systematic analysis of strategies. Finally, the work of \citet{lucy-etal-2024-aboutme} on language filtering strategies provide insightful results on the cultural biases embedded in language filters that can determine the exclusion of certain categories of people from pretraining datasets.