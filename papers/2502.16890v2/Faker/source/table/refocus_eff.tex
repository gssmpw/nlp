\begin{table}[!h]
\centering
\caption{\small{Model efficiency analysis. We evaluated the \textbf{parameter count}, and the \textbf{inference time} (average of 5 runs on a single NVIDIA 4090 24GB GPU) with $batch\_size= 1$ on \textbf{ECL} dataset. We set the dimension of layer $ dim \in \{256, 512\}$, and the number of network layers $N=2$. The task is \textbf{input-96-forecast-720}. \textbf{*} means `former.' \textbf{Para} means `Parameter count(M).' \textbf{Time} means `inference time(ms).'}}
\phantomsection
\label{tab:efficiency}
\renewcommand{\arraystretch}{0.85} 
\centering
\renewcommand{\multirowsetup}{\centering}
\setlength{\tabcolsep}{1.45pt}
\resizebox{0.5\textwidth}{!}{
\begin{small}
\renewcommand{\multirowsetup}{\centering}
\setlength{\tabcolsep}{1.45pt}
\begin{tabular}{c|cc|cc|cc|cc|cc}
\toprule
\multirow{2}{*}{Dim} & \multicolumn{2}{c}{\textbf{EKPB}} & \multicolumn{2}{c}{Cross*} & \multicolumn{2}{c}{iTrans*} & \multicolumn{2}{c}{TSMixer} & \multicolumn{2}{c}{FECAM}\\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}\cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11}
& Param & Time & Para & Time & Para & Time & Para & Time & Para & Time  \\
\midrule
256 & \boldres{0.29}	& \boldres{68.91}	& 0.93	& 98.37	& 1.27	& 192.12 & 13.66	& 432.40	& 1.39	& 205.66 \\
512 & \boldres{0.97}	& \boldres{84.54}	& 1.78	& 118.29	& 4.63	& 249.60	& 43.04	& 507.54	& 5.14	& 277.43
\\
\bottomrule
  \end{tabular}
    \end{small}
}
\end{table}