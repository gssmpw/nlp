\section{Introduction}

Accurate forecasting of time series offers reference for decision-making across various domains~\citep{Lim2021tsfsurvey,torres2021tsfsurvey}, including weather~\citep{du2022preformer}, economics~\citep{Oreshkin2020nbeats}, and energy~\citep{dong2023simmtm,Liu2021pyraformer}. Especially, long-term multivariate time series forecasting (LMTSF) emerges as a prominent area of interest in academic research~\citep{Wangtslb2024,wen2022transformersurvey} and industrial applications~\citep{cirstea2022triformer}, offering the advantage of capturing complex interdependencies and trends across multiple variables. 

Recently, the powerful representation capabilities of neural networks, such as Multi-Layer perception (MLPs)~\citep{yi2023fremlp,han2024softs}, Transformers~\citep{zhou2022fedformer,Nie2022patchtst}, and Temporal Convolution Network (TCNs)~\citep{tslanet,Liu2021scinet}, have significantly advanced deep learning-based LMTSF. These approaches can be broadly categorized into two/three folds: time-domain-based~\citep{han2024softs,Nie2022patchtst,Liu2021scinet} and frequency-domain-based~\citep{yi2023fremlp,zhou2022fedformer,tslanet} methods, or mixed time \& frequency. Time-domain methods are intuitive, handling nonlinearity and non-periodic signals directly from the raw sequence~\citep{Li2023rlinear} using Transformers~\citep{Zhou2020informer}, TCN~\citep{donghao2024moderntcn}, or MLP~\citep{wang2023timemixer}.
The latest study~\cite {yi2024filternet} highlights that time-domain forecasters face challenges such as vulnerability to high-frequency noise, and computational inefficiencies.
While frequency-domain-based methods usually transform the time-domain data to the frequency spectrum by Fast Fourier transform (FFT)~\citep{yi2023freqsurvey}. Then other operations (Self-attention~\citep{zhou2022fedformer}, Linear mapping~\citep{xu2024fits,yi2023fremlp}, etc.) are employed to extract frequency information.
These methods benefit from advantages such as computational efficiency~\citep{fan2024efficiency,xu2024fits}, periodic patterns extracting~\citep{wu2022timesnet,dai2024pdf}, and energy compaction~\citep{yi2023fremlp,yi2023fouriergnn}. 

\begin{figure*}[!h]
  \centering
  \includegraphics[width=0.9\linewidth]{Faker/source/assets/jpg/intro.jpg}
  \caption{\small{The \textbf{Mid-Frequency Spectrum Gap} and the shared \textbf{Key-Frequency} (high similarity in frequency spectra across variables) on Weather dataset. VPmax means `Maximum Vapor Pressure' and VPact means `Actual Vapor Pressure'.}}
  \label{fig:intro}
\end{figure*}

However, existing frequency-domain-based forecasters usually face TWO significant challenges when dealing with real-world long-term time series:
the \textbf{Mid-Frequency Spectrum Gap} and the shared \textbf{Key-Frequency modeling}. 
\begin{itemize}
\item \textbf{Mid-Frequency Spectrum Gap}~(Figure~\ref{fig:intro} \textcolor[RGB]{255,0,0}{Red} box) refers to a condition where the energy of the spectrum is concentrated in the low-frequency regions, resulting in the mid-frequency band being negligible. 
%
Low-frequency components capture long-term trends, often contributing to mean shifts when overly concentrated~\citep{stock2002low,granger1974low,chatfield2019low}. So this Mid-Frequency Spectrum Gap will introduce \textbf{Nonstationarity}~\citep{cheng2015nonstationarity,liu2022non}, where the mean and variance of time series change over time, and make time series less predictable. 
%
Furthermore, such uneven energy distribution challenges existing deep-learning models to extract critical patterns~\citep{Tishby2015full,xu2024full,rahaman2019full}. So, addressing this Mid-Frequency Spectrum Gap is crucial for enhancing the feature extraction capabilities of deep learning-based forecasters~\citep{park2019mid,bai2018mid,guo2019mid}. 
Currently, widely used methods for processing spectra, such as Filters~\citep{asselin1972frequencyfilter}, and \textbf{RevIN}~\citep{Kim_revin,liu2022non}—a technique previously applied to address nonstationarity—are not effective in resolving this issue. Conversely, convolution with residual connections has effectively handled spectral information~\citep{can2018conv,chakraborty2021conv}, providing a potential solution.
\item Meanwhile, the second challenge: the shared \textbf{Key-Frequency Modeling} (Figure~\ref{fig:intro} \textcolor[RGB]{255, 102, 255}{Pink} box) has the disadvantage that distinct time series can exhibit indistinguishable frequency patterns, potentially leading to challenges in accurately differentiating and analyzing individual series within a multivariate context~\citep{yu2023dsformer,Piao2024fredformer}.
% 
However, existing approaches have largely overlooked this critical characteristic. Meanwhile, energy, which is the square of the amplitude of the spectrum, is proven as an effective tool for identifying certain frequency patterns in the multivariate case~\citep{bogalo2024ekpb,chekroun2017ekpb,sundararajan2023ekpb}.
\end{itemize}

Based on the above observations, this work mainly addresses two critical questions: (1) How can the Mid-Frequency Spectrum Gap be resolved to achieve a more evenly dispersed spectrum? (2) How can inter-series dependencies be efficiently modeled by leveraging the shared Key-Frequency?  
%
To tackle challenge 1, we propose the `\textbf{A}daptive \textbf{M}id-Frequency \textbf{E}nergy \textbf{O}ptimizer' (AMEO), a convolution- and residual learning-based solution. It adaptively scales the frequency spectrum by assigning higher scaling factors to lower frequencies, thereby dispersing the spectrum. 
%
To address challenge 2, For the second challenge, we introduce the `\textbf{E}nergy-based \textbf{K}ey-Frequency \textbf{P}icking \textbf{B}lock (EKPB)', which features fewer parameters and faster inference speeds compared to the Transformer Encoder~\citep{LiuiTransformer} and MLP-Mixer~\citep{chen2023tsmixer}. EKPB extracts shared frequency information across channels effectively.  We also propose a `\textbf{K}ey-Frequency \textbf{E}nhanced \textbf{T}raining' strategy 
(KET) which incorporates spectral information from other channels during training to enhance extraction of shared Key-Frequency that may not be included in the training set.

Our contributions are summarized as follows. 
\vspace{-0.25cm}
\begin{itemize}
\item We theoretically and empirically demonstrate that existing RevIN and high/low-pass filters fail to address the Mid-Frequency Spectrum Gap. We propose AMEO, a novel approach based on convolution and residual learning that significantly enhances mid-frequency feature extraction. 
\vspace{-0.25cm}
\item We propose EKPB to capture shared Key-Frequency across channels, which achieves superior inter-series modeling capacity with lower parameters. 
\vspace{-0.25cm}
\item We propose KET, where spectral information from other channels is randomly introduced into each channel, to enhance the extraction of the shared Key-Frequency.
\vspace{-0.25cm}
\item Our approach outperforms the previous SOTA iTransformer by reducing MSE by 4\%, 6\%, and 5\% on the challenging Traffic, ECL, and Solar datasets, respectively, establishing new benchmarks in multivariate time series forecasting. 
\end{itemize}
