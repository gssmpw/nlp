\section{Related work}
\textbf{Advancement in Recent Deep Learning-based Time Series Forecasting \quad} Recent advancements in deep learning-based time series forecasting can be broadly categorized into three key areas: (1) the application of sequential models to time series data, (2) the tokenization of time series, and (3) the exploration of intrinsic patterns within time series. 
%
Efforts in the first area have focused on deploying various architectures for time series forecasting, including Transformer~\citep{Wu2021autoformer,wang2024card}, Mamba~\citep{4mamba,wang2024mamba}, MLPs~\citep{wang2023timemixer,Das2023TiDE,yu2024lino}, RNNs~\citep{lin2023segrnn}, Graph Neural Networks~\citep{shangada2024tsfgnn}, TCNs~\citep{wang2023micn}, and even Large Language Models (LLMs)~\citep{jin2023timellm,liu2024timellm,liu2024autotimes}.
%
The second direction has witnessed groundbreaking developments, particularly in Patch Embedding~\citep{Nie2022patchtst} and Variate Embedding~\citep{LiuiTransformer}.
%
The final area explores modeling complex relationships, including the inter-series dependencies~\citep{Ng2022graphformer, chen2024similarity}, the dynamic evolution within a sequence~\citep{du2022preformer,Zhang2022lightts}, or both~\citep{yu2024leddam,liu2024unitst}. 

\textbf{Time Series Modeling with Frequency \quad} Frequency as a key feature of time series data, has inspired numerous works~\citep{yi2023freqsurvey}.
%
FITS~\citep{xu2024fits} employs a simple frequency-domain linear, getting results comparable to SOTA models with 10K parameters.
%
Autoformer~\citep{Wu2021autoformer} introduces the auto-correlation mechanism, leveraging FFT to improve self-attention. FEDformer~\citep{zhou2022fedformer} further calculates attention weights from the spectrum of queries and keys. FiLM~\citep{Zhou2022film} applies Fourier analysis to preserve historical information while filtering out noise. FreTS~\citep{yi2023fremlp} incorporates frequency-domain MLP to model both channel and temporal dependencies. TimesNet~\citep{wu2022timesnet} utilizes FFT to extract periodic patterns. FilterNet~\citep{yi2024filternet} proposes a filter-based method from the perspective of signal processing. 

However, they do not address the Mid-Frequency Spectrum Gap and shared Key-Frequency modeling. In contrast, our method employs `Adaptive Mid-Frequency Energy Optimizer' to improve mid-frequency feature extraction and introduces `Energy-based Key-Frequency Picking Block' with `Key-Frequency Enhanced Training' strategy to capture shared Key-Frequency across channels.