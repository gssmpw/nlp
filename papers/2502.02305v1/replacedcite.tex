\section{Background and Related Work}
Diffusion sampling has become very popular for generative models due to its amazing performance on collections of digital images from the Web.
An important component of these models is that the generation is conditional (e.g., on a text prompt) and this corresponds to the functions $f_k$ depending on that prompt.
In 2022, the Imagen text-to-image model based on conditional diffusion sampling was released and widely celebrated____.
The results were clearly better than the groundbreaking DALLE-1 text-to-image model, released in 2021, which is based instead on transformers that generate visual tokens____.
This encouraged many researchers to focus on diffusion sampling.
In particular, the DALLE-2 model, released in 2022, is based on diffusion sampling____.

But, the current interest in generative diffusion models actually traces back to a 2015 paper____ that was improved by a sequence of follow-on papers____. In particular, the first papers worked in pixel space____. Later, significant speedups were achieved by performing the diffusion in latent space (e.g., the diffusion process operates in the latent space defined by a model trained for image recognition and reconstruction)____. Significant gains were also seen with larger language models for prompts, hierarchical generation, and upsampling____.

Theoretically, this early work led to analyses based on stochastic differential equations____ and connections to an older related idea known as stochastic localization____.
More recently, these ideas have been connected to information theory____. Recent work on convergence rates includes ____. 
Acceleration methods have been recently proposed in  ____.