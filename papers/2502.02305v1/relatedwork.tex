\section{Background and Related Work}
Diffusion sampling has become very popular for generative models due to its amazing performance on collections of digital images from the Web.
An important component of these models is that the generation is conditional (e.g., on a text prompt) and this corresponds to the functions $f_k$ depending on that prompt.
In 2022, the Imagen text-to-image model based on conditional diffusion sampling was released and widely celebrated~\cite{Saharia-neurips22}.
The results were clearly better than the groundbreaking DALLE-1 text-to-image model, released in 2021, which is based instead on transformers that generate visual tokens~\cite{Ramesh-icml21}.
This encouraged many researchers to focus on diffusion sampling.
In particular, the DALLE-2 model, released in 2022, is based on diffusion sampling~\cite{ramesh-arxiv22}.

But, the current interest in generative diffusion models actually traces back to a 2015 paper~\cite{Sohl-icml15} that was improved by a sequence of follow-on papers~\cite{Ho-neurips20,Nichol-icml22,Rombach-cvpr22}. In particular, the first papers worked in pixel space~\cite{Ho-neurips20,Nichol-icml22}. Later, significant speedups were achieved by performing the diffusion in latent space (e.g., the diffusion process operates in the latent space defined by a model trained for image recognition and reconstruction)~\cite{Rombach-cvpr22}. Significant gains were also seen with larger language models for prompts, hierarchical generation, and upsampling~\cite{Saharia-neurips22}.

Theoretically, this early work led to analyses based on stochastic differential equations~\cite{Song-iclr21} and connections to an older related idea known as stochastic localization~\cite{Eldan-gafa13,Chen-focs22}.
More recently, these ideas have been connected to information theory~\cite{Alaoui-it22,Montanari-arxiv23}. Recent work on convergence rates includes \cite{lee:2023convergence,chen:2023sampling,chen:2023improved,benton:2024nearly,li:2024towards,li:2024accelerating}. 
Acceleration methods have been recently proposed in  \cite{wu2024:stochastic,li:2024provable}.