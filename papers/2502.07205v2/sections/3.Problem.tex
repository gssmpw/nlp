\section{Signal Model and Task Description}
\label{sec:problem_formulation}
In this section, we will introduce the signal model and define two tasks we aim to address: speech dereverberation and blind RIR identification.

\subsection{Signal Model}
% This signal model depicts the relationship between the anechoic source speech signal and the reverberant recording signal.

Considering the scenario of a single static speaker and stationary noise, the reverberant speech signal (observation) received by a distant microphone can be modeled in the time domain as
\begin{equation}
    \label{eq:signal_model_time}
    x(n)=h(n)*s(n)+w(n),
\end{equation}
where $*$ is the convolution operator, $n$ is the index of sampling points, $x(n)$ is the observation signal, $s(n)$ is the anechoic source speech signal, $h(n)$ is the RIR which describes a time-invariant linear filter, and $w(n)$ is the background additive noise.
Without loss of generality, we assume that the RIR begins with the impulse response of the direct-path propagation, followed with reflections and reverberation.

Analyzing and processing speech signals in the time domain poses significant challenges.
After performing short-time Fourier transform (STFT), 
according to the CTF approximation~\cite{talmon2009relative}, the observation model in the T-F domain becomes
\begin{equation}
    \label{eq:signal_model_stft}
    \begin{aligned}
        X(f,t)&\approx\sum_{l=0}^{L-1}H_l(f)S(f,t-l)+W(f,t) \\
        &=\mathbf{H}(f)\mathbf{S}(f,t)+W(f,t),\\
    \end{aligned}
\end{equation}
where $f$ and $t$ are the indices of frequency band and STFT frame, respectively; $L$ is the length of CTF filter; $X(f,t)$, $S(f,t)$, $W(f,t)$, and $H_l(f)$ are the complex-valued observation signal, source speech signal, noise signal, and CTF coefficient, respectively; 
$\mathbf{H}(f)=\left[H_{L-1}(f),\cdots,H_0(f)\right]\in\mathbb{C}^{1 \times L}$, $\mathbf{S}(f,t)=\left[S(f,t-L+1),\cdots,S(f,t)\right]^T\in \mathbb{C}^{L \times 1}$.
% Since there is no cross-band filter in the CTF approximation, the probabilistic graph model is independently built in each frequency band.
% In the following VBI procedure, these bands are also processed separately.
% Therefore, we will omit the frequency index $f$ in the signal model and VBI procedure.


% \subsection{Probabilistic Model}

Furthermore, the observation $X(f,t)$, anechoic source $S(f,t)$, and noise $W(f,t)$ are modeled as random signals.
We have the following assumptions regarding their distributions.

\begin{itemize}
\item Assumption 1: The anechoic source speech signal $S(f,t)$ follows a time-variant zero-mean complex-valued Gaussian distribution, while the noise signal $W(f,t)$ follows a time-invariant zero-mean complex-valued Gaussian distribution. 
Therefore, we have their prior distributions as
\begin{equation}
\left\{
\begin{aligned}
    &S(f,t)\sim\mathcal{CN}\left(0,\alpha^{-1}(f,t)\right)\\
    &W(f,t)\sim\mathcal{CN}\left(0,\delta^{-1}(f)\right),\\
\end{aligned}
\right.
\end{equation}
where $\alpha(f,t)$ and $\delta(f)$ are the precisions of the Gaussian distributions.
% The assumption of zero mean is based on the randomness of the phase.
% Assumption 1 also indicates that the noise signal is generally stationary.

\item Assumption~2: 
The anechoic source speech signal $S(f,t)$ and noise signal $W(f,t)$ are respectively independent for all T-F bins.
Defining $\mathbf{S}=[S(1,1),\cdots,S(1,T),\cdots,S(F,T)]^T\in \mathbb{C}^{1\times FT}$ and $\mathbf{W} = [W(1,1),\cdots,W(1,T),\cdots,W(F,T)]^T\in \mathbb{C}^{1\times FT}$, we have
\begin{equation}
\left\{
\begin{aligned}
    &\mathbf{S} \sim \prod_{f=1}^F\prod_{t=1}^T p\left(S(f,t)\right)\\
    &\mathbf{W}\sim\prod_{f=1}^F\prod_{t=1}^T p\left(W(f,t)\right).\\
\end{aligned}
\right.
\end{equation}

\item Assumption~3:
The anechoic source speech signal $\mathbf{S}$ and noise signal $\mathbf{W}$ are independent of each other, which means
\begin{equation}
    \mathbf{S},\mathbf{W} \sim p(\mathbf{S})p(\mathbf{W}).
\end{equation}

\end{itemize}

With all the aforementioned assumptions, the conditional probability of the observation signal can be expressed as follows.
\begin{equation}
\left\{
\begin{aligned}
    &X(f,t)|\mathbf{S}(f,t)\sim\mathcal{CN}\left(\mathbf{H}(f)\mathbf{S}(f,t),\delta^{-1}(f)\right) \\
    &\mathbf{X}|\mathbf{S}\sim\prod_{f=1}^F\prod_{t=1}^T p\left(X(f,t)|\mathbf{S}(f,t)\right).\\
\end{aligned}
\right.
\end{equation}
The probabilistic graphical model is summarized in Fig. \ref{fig:prob_model}.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.32\textwidth]{figs/prob_model.pdf}
    \caption{Probabilistic graphical generation model of reverberant microphone recording (observation).}
    \label{fig:prob_model}
\end{figure}



% \subsection{Signal Model of RIR}

% According to the time-domain model proposed by Polack et al.~\cite{polack1988transmission,jot1997analysis}, the RIR $h(n)$ is described as a realization of a non-stationary stochastic process
% \begin{equation}
%     h(n)=b(n)e^{- \beta n}, n \geq 0,
% \end{equation}
% where $b(n)$ is a centered stationary Gaussian noise with the variance of $\sigma^2_b$, $\beta$ is related to RT60 (marked as $T_{60}$) by
% \begin{equation}
%     20\log_{10}\left(e^{- \beta T_{60}}\right)=-60.
% \end{equation}
% Furthermore, the ensemble average energy envelope of the RIR in the time domain can be expressed as
% \begin{equation}
%     \left<h^2(n)\right>\approx \sigma_{b}^2 e^{-2\beta n}.
% \end{equation}
% 
% 
% In practice, given a measured RIR $\hat h(n)$, 

% Moreover, Schroederâ€™s integrated energy decay curve (EDC) is traditionally used to show how the energy level decreases after the sound source stops emitting sound.
% EDC is defined as the remaining energy in the RIR as~\cite{schroeder1965new}
% \begin{equation}
% \label{eq:edc}
%     \mathrm{EDC}(n)=\sum_{m=n}^{\infty}h^2(m).
% \end{equation}
% % RT60 is usually calculated by the slope of the logarithmic EDC curve through linear fitting.

\subsection{Task Description}

In this work, we aim to jointly complete speech dereverberation and blind RIR identification by solving all hidden variables and parameters in Fig. \ref{fig:prob_model} through VBI.

For speech dereverberation, we care about the anechoic spectrum, which is a hidden variable in our probabilistic graphical model.
We aim to get its maximum a posteriori (MAP) estimation given the reverberant microphone recording, written as
\begin{equation}
    \hat{\mathbf{S}}=\argmax\limits_{\mathbf{S}}p(\mathbf{S}|\mathbf{X}),
\end{equation}
where the posterior distribution of anechoic source signal can be represented according to the Bayes rule as 
\begin{equation}
    \label{eq:posterior}
    p(\mathbf{S}|\mathbf{X})=\frac{p(\mathbf{S})p(\mathbf{X}|\mathbf{S})}{\int p(\mathbf{S})p(\mathbf{X}|\mathbf{S}) \mathrm{d}\mathbf{S}}.
\end{equation}

% The CTF filter is a representation of RIR in the T-F domain.
For blind RIR identification, we care about the CTF filter, which is a model parameter in our probabilistic graphical model.
Defining the CTF filter for all frequency bands as $\mathbf{H}=\left[\mathbf{H}(1),\cdots,\mathbf{H}(F)\right]$, we aim to get its maximum likelihood (ML) estimation, written as
\begin{equation}
    \hat{\mathbf{H}}=\argmax\limits_{\mathbf{H}}p(\mathbf{S},\mathbf{X}).
\end{equation}
The CTF filter is a representation of RIR in the T-F domain.
We transform the CTF filter into the RIR waveform through a pseudo measurement process, a process that will be elaborated upon later.


% the RIR waveform $\hat h(n)$ can be recovered according to the CTF filter $\mathbf{H}$.
