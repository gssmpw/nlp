\section{Auxiliary tools}

\subsection{Probability inequalities for sums of bounded random variables}

In this paper, we utilize the following inequalities, which are provided for the sake of completeness.

\begin{theorem}[Chebyshev's Inequality]
    Let $X$ be any random variable with expected value $\mu =\mathbb{E}[X]$ and finite variance $\Var(X)$. Then, for any real number $\varepsilon >0$:
    \begin{equation}
        \mathbb{P}(|X -\mu| \geq \varepsilon) \leq \frac{\Var(X)}{\varepsilon^2}.
    \end{equation}
\end{theorem}

\begin{theorem}[Hoeffding's Inequality]
     If $X_1, X_2, ...,X_n$ are independent with $\mathbb{P}(a \leq X_i \leq b) = 1$ and common mean $\mu$ then for any $\varepsilon > 0$ 
    \begin{equation}
        \mathbb{P}\left( \left|\frac{1}{n} \sum_{i=1}^n X_i - \mu\right| > \varepsilon\right) \leq 2 \exp\left(\frac{-2n\varepsilon^2}{(b-a)^2}\right).
    \end{equation}
\end{theorem}

\begin{theorem}[Bernstein's Inequality]
    If $X_1,...,X_n$ are independent bounded random variables such that $\mathbb{E}[X_i] = 0$ for all $i \in \{1,...,n\}$ and $\mathbb{P}(|X_i| \leq c) =1$ then, for any $\epsilon>0$,
    \begin{equation}
        \mathbb{P}\left(\left|\frac{1}{n}\sum_{i=1}^n \right| \geq \varepsilon\right) \leq \exp\left(-\frac{n\varepsilon^2}{2 \sigma^2 + 2c\epsilon /3}\right),
    \end{equation}
    where $\sigma^2 = \frac{1}{n}\sum_{i=1}^n \Var(X_i)$.
\end{theorem}

\subsection{Properties of Haar unitary matrix}

For a locally compact topological group, its Haar measure is a unique nonzero left-invariant measure  (or right-invariant, depending on the formulation) under group operations. The Haar unitary matrix is the Haar measure on the unitary matrix group and is the concept of drawing unitary matrices uniformly at random. The formal definition of Haar unitary matrix is as follows:

\begin{definition}
    The Haar unitary matrix is the unique probability measure $\mu_{H}$ that is both left and right invariant over the unitary matrix group, i.e., for all integrable functions $f$ and for all unitary matrix $V$, we have:
    \begin{equation}
        \int_{U \sim \Haar}f(U)dU = \int_{U \sim \Haar}f(UV)dU = \int_{U \sim \Haar}f(VU)dU.
    \end{equation}
\end{definition}

For any unit column vector $\bx \in \mathbb{C}^d$, we have 
\begin{equation}
    \mathbb{E}_{U \sim \Haar}\left[f(U\bx)\right] = \mathbb{E}_{\psi \sim \mathbb{C}^d}\left[f(|\psi\rangle)\right].
\end{equation}

We will use the following lemma to complete our proofs in this paper.

\begin{lemma}[see Lemma 22 of Ref.\cite{anshu2022distributed}]
    \label{lem:Haar_meausrement_expectation}
    Let $A,B,C$ be Hermitian matrices. Then
    \begin{equation}
        \mathbb{E}_{\psi \sim \mathbb{C}^d} \langle \psi| A | \psi \rangle = \frac{1}{d}\Tr(A)
    \end{equation}
    and
    \begin{equation}
        \mathbb{E}_{\psi \sim \mathbb{C}^d} \langle \psi| A | \psi \rangle \langle \psi| B | \psi \rangle = \frac{1}{d(d+1)}(\Tr(A)\Tr(B)+\Tr(AB))
    \end{equation}
    and
    \begin{equation}
        \begin{aligned}
            \mathbb{E}_{\psi \sim \mathbb{C}^d} \langle \psi| A | \psi \rangle \langle \psi| B | \psi \rangle \langle \psi| C | \psi \rangle & = \frac{1}{d(d+1)(d+2)}(\Tr(A)\Tr(B)\Tr(C)+\Tr(AB)\Tr(C) \\
            &+ \Tr(A)\Tr(BC) + \Tr(CA)\Tr(B) + \Tr(ABC)).
        \end{aligned}
    \end{equation}
\end{lemma}