\section{Theoretical Results}
\label{section:theory}

In this section, we sketch the derivation of \Cref{cor:main} for \algname{ATA} and \algname{ATA-Empirical}, through a regret analysis on the proxy losses.
We define the expected cumulative regret of the proxy loss $\ell(\cdot, \bm{\mu})$ after $K$ rounds
\begin{equation}\label{eq:proxy_loss}
	\mathcal{R}_K := \sum \limits_{k=1}^{K} \E{\ell(\bm{a}_k, \bm{\mu})} - K \cdot \ell(\bar{\bm{a}}, \bm{\mu}),
\end{equation}
where $\bar{\bm{a}} \in \argmin_{\bm{a} \in \mathcal{A}} \ell(\bm{a}, \bm{\mu})$ represents the optimal allocation over the workers. If multiple optimal actions exist, we consider the one returned by the optimization sub-routine used in \algname{ATA} (line 5 of Algorithm \ref{alg:sgd-ata}).

We derive upper bounds on the expected cumulative regret $\mathcal{R}_K$. Based on these bounds, we provide the guarantees on the expected total computation time required to complete $K$ iterations of the optimization process.

\subsection{Guarantees for \algname{ATA}}

For each worker $i \in [n]$, recall that $\bar{a}_i$ denote the prescribed allocation of the optimal action $\bar{\ba}$. Define $k_i$ as the smallest integer satisfying
\begin{equation}\label{def:ki}
	(\bar{a}_i + k_i) \mu_i > \ell(\bar{\bm{a}}, \bm{\mu})~.
\end{equation}
From the definition above, it follows that if the learner plays an action $\bm{a}_k$ at round $k$ such that $a_{k,i} \ge \bar{a}_i + k_i$, then $\ell(\bm{a}_k, \bm{\mu}) \ge \ell(\bar{\bm{a}}, \bm{\mu})$. Thus, $k_i$ can be interpreted as the smallest number of additional units allocated to worker $i$ that result in a suboptimal loss. Moreover, for every worker $i \in [n]$, we have $k_{i} \in \{1, 2\}$ (see Lemma~\ref{lem:1} in the Appendix).

The next result provides an upper bound on the expected regret of \algname{ATA}.
\begin{theorem}
	\label{thm:main}
	Suppose that \Cref{a:sube} holds.
	Then, the expected regret of \algname{ATA} with inputs $(B, \alpha)$ satisfies
	\begin{align*}
		\mathcal{R}_K &\le 2n\max_{i \in [n]} \{B\mu_i -\ell(\bar{\bm{a}}, \bm{\mu})\}\\
		& \qquad+c \cdot\sum \limits_{i=1}^{n} \frac{\alpha^2(\bar{a}_i+k_i)(B \mu_i - \ell(\bar{\bm{a}}, \bm{\mu})) }{\left((\bar{a}_i+k_i)\mu_i - \ell(\bar{\bm{a}}, \bm{\mu})\right)^2}\cdot \ln K,
	\end{align*}
	where $\alpha \ge \max_{i \in [n]} \norm{X_i}_{\psi_1}$, and $c$ is a constant.
\end{theorem}
The first term in the regret upper bound is independent on the number of rounds $K$.
The second term, however, grows logarithmically with $K$, which aligns with the behavior observed in stochastic bandit problems in the literature.
%This logarithmic scaling arises from the exponential concentration bounds satisfied by the considered class of arms distributions.

In the case where $B=1$, our setting reduces to the problem of regret minimization for the standard multi-armed bandits.
Observe that in this case $\ell(\bar{\bm{a}}, \bm{\mu}) = \min_{i\in[n]}\mu_i$, $k_i=1$ for all $i \in [n]$.
Therefore, the guarantees of \Cref{thm:main} recover the known optimal bound $\cO\(\sum_i \ln(K)/\Delta_i\)$ of the standard MAB setting, where $\Delta_i := \mu_i-\min_j \mu_j$.


\begin{proof}[Proof sketch]
	
The full proof is in \Cref{proof:thm:main}. In standard and combinatorial MAB problems, regret bounds are typically derived by controlling the number of rounds in which the learner selects suboptimal arms. These bounds are often of the order $\ln(K)/\Delta^2$, where $\Delta$ denotes the suboptimality gap and quantifies the exploration cost required to distinguish optimal actions from suboptimal ones.

In our setting, the problem is more complex since the learner must not only choose which arms to pull but also determine the allocation of resources across selected arms. With this in mind, we develop the following key arguments leading to the bound in Theorem~\ref{thm:main}.  

We define \textit{over-allocation} for worker $i$ at round $k$ as the event where $a_{i,k} \geq \bar{a}_i + k_i$. By definition of $k_i$ (see \eqref{def:ki}), this implies that $\ell(\bm{a}_k, \bm{\mu}) > \ell(\bar{\bm{a}}, \bm{\mu})$. We define a \textit{bad round} as a round where $\ell(\bm{a}_k, \bm{\mu}) > \ell(\bar{\bm{a}}, \bm{\mu})$, and we say that a bad round is \textit{triggered by arm $i$} when $a_{i,k} \mu_i = \ell(\bm{a}_k, \bm{\mu}) > \ell(\bar{\bm{a}}, \bm{\mu})$. Then, the proof revolves around establishing an upper bound on the total number of bad rounds.

To derive this bound, we consider the number of samples required to verify that the mean computation time of worker $i$ under over-allocation exceeds the optimal waiting time $\ell(\bar{\bm{a}}, \bm{\mu})$. Specifically, we need to test whether the mean of the corresponding distribution, at least $(\bar{a}_i + k_i)\mu_i$, surpasses the threshold $\ell(\bar{\bm{a}}, \bm{\mu})$. This is equivalent to testing whether 
$$
\{ \mu_i > \frac{\ell(\bar{\bm{a}}, \bm{\mu})}{\bar{a}_i + k_i}\}~.
$$
Using the concentration inequality applied in our analysis, the number of samples required for this test is of the order:  
\begin{equation}\label{eq:n_rounds}
	\textstyle
	\alpha_i^2 \left(\mu_i - \frac{\ell(\bar{\bm{a}}, \bm{\mu})}{\bar{a}_i + k_i}\right)^{-2} = \frac{\alpha_i^2 (\bar{a}_i + k_i)^2}{\left((\bar{a}_i + k_i)\mu_i - \ell(\bar{\bm{a}}, \bm{\mu})\right)^2}~.
\end{equation}
During rounds where worker $i$ is over-allocated, the learner collects at least $\bar{a}_i + k_i$ samples from the corresponding distribution. Therefore, the total number of rounds required to accumulate enough samples to stop over-allocating worker $i$ can be upper-bounded by 
$$
	\frac{\alpha_i^2 (\bar{a}_i + k_i)}{\left((\bar{a}_i + k_i)\mu_i - \ell(\bar{\bm{a}}, \bm{\mu})\right)^2}~.
$$

In the regret bound of \Cref{thm:main}, the term $\alpha^2$ appears instead of $\alpha_i^2$ because the learner's prior knowledge is limited to an upper bound $\alpha \ge \max_i \norm{X_i}_{\psi_1}$ on the maximal Orlicz norm of the arm distributions.
Finally, considering that the worst-case excess loss incurred when over-allocating worker $i$ is $B\mu_i - \ell(\bar{\bm{a}}, \bm{\mu})$, we obtain the stated bound.
\end{proof}


\begin{figure*}[t]
    \centering
    \begin{tabular}{cccc}
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=17/plot1_runtime_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=17/plot2_total_worker_time_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=17/plot3_iterations_vs_average_iteration_time.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=17/plot4_iterations_vs_proxy_avg_regret.pdf} \\
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=51/plot1_runtime_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=51/plot2_total_worker_time_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=51/plot3_iterations_vs_average_iteration_time.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=51/plot4_iterations_vs_proxy_avg_regret.pdf} \\
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=153/plot1_runtime_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=153/plot2_total_worker_time_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=153/plot3_iterations_vs_average_iteration_time.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=153/plot4_iterations_vs_proxy_avg_regret.pdf} \\
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=459/plot1_runtime_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=459/plot2_total_worker_time_vs_grad.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=459/plot3_iterations_vs_average_iteration_time.pdf} &
        \includegraphics[width=0.234\textwidth]{plots/sqrt/n=459/plot4_iterations_vs_proxy_avg_regret.pdf} \\
    \end{tabular}
    \caption{
        Each row increases the number of workers by a factor of 3, starting from $17$, that is, $n = 17, 51, 153, 459$ from top to bottom.
        The first column shows runtime vs. suboptimality.  
        The second column also plots suboptimality, but against total worker time, i.e., $\sum_{i=1}^n T_{i,k}$ in \Cref{alg:ata}.
        The third column presents the average iteration time, given by $C_k / k$ over all iterations $k$.  
        The last column displays the averaged cumulative regret, as defined in \eqref{eq:proxy_loss}.
    }
    \label{fig:sqrt}
\end{figure*}

\subsection{Guarantees for \algname{ATA-Empirical}}

We present theoretical guarantees for \algname{ATA-Empirical} by providing an upper bound on the expected cumulative regret \eqref{eq:proxy_loss}. As discussed in \Cref{section:ata}, \algname{ATA-Empirical} leverages lower confidence bounds derived from a novel data-dependent concentration inequality introduced below. The proof of this result is detailed in \Cref{sec:technical}.
\begin{lemma}\label{lem:0}
	Let $X_1, \dots, X_n$ be i.i.d.\ positive random variables with mean $\mu$ and variance $\sigma^2$, such that $\norm{X_1}_ {\psi_1}<+\infty$. Let $\hat{X}_n$ denote the empirical mean. For $\delta \in (0,1)$, let
	$
		C_{n,\delta} := 4e\xi \sqrt{\frac{\log(2/\delta)}{n}}+4e\xi \frac{\log(2/\delta)}{n}
	$,
	where $\xi = (1+\sqrt{4\eta^2+5})/2$ and $\eta \ge \sigma/\mu$. Then, with probability at least $1-\delta$, we have
	$$
		\mu \ge \hat{X}_n \left(1- C_{n,\delta}\right)_{+}~.
	$$
	Moreover, if $C_{n,\delta} \le \frac{1}{4}$, then, we have with probability at least $1-\delta$, we have
	$$
		\hat{X}_n \left(1- C_{n,\delta}\right)_{+} \le \mu \le \hat{X}_n \left(1+\frac{4}{3}C_{n,\delta}\right)~.
	$$
\end{lemma}
 
Using the concentration inequality above, we construct the lower confidence bounds $\hat{s}_{i,k}$ as defined in \eqref{def:s}. The following theorem provides an upper bound on the regret of \algname{ATA-Empirical}.

\begin{theorem}[Proof in \Cref{proof:thm:main2}]
	\label{thm:main2}
	Suppose that \Cref{a:sube} holds.
	%Let $\bar{\bm{a}} \in \argmin_{\bm{a} \in \mathcal{A}} \ell(\bm{a}, \bm{\mu})$.
	Then, the expected regret of \algname{ATA-Empirical} with inputs $(B, \eta)$, satisfies
	\begin{align*}
		\mathcal{R}_K &\le 2n\max_{i \in [n]} \{B\mu_i -\ell(\bar{\bm{a}}, \bm{\mu})\}\\
		& +c (1+\eta^2)\cdot\sum \limits_{i=1}^{n} \frac{\alpha_i^2(\bar{a}_i+k_i)(B \mu_i - \ell(\bar{\bm{a}}, \bm{\mu})) }{\left((\bar{a}_i+k_i)\mu_i - \ell(\bar{\bm{a}}, \bm{\mu})\right)^2}\cdot \ln K,
	\end{align*}
	where $\alpha_i =  \norm{X_i}_{\psi_1}$ and $c$ is a constant.
\end{theorem}

Comparing the bounds for \algname{ATA-Empirical} and \algname{ATA}, we observe two key differences. First, unlike the bound in Theorem~\ref{thm:main}, which incurs a squared maximal Orlicz norm penalty of $\alpha^2$ for all terms in the upper bound, \algname{ATA-Empirical} benefits from its adaptive nature, leading to a term-specific factor of $\alpha_i^2$. Second, \algname{ATA-Empirical} introduces a multiplicative factor of $1+\eta^2$, which remains close to one for common distributions modeling computation time, as discussed in \Cref{sec:setup}.







