\section{Introduction}
\label{section:introduction}

In this work, we address a very general yet fundamental and important problem arising in various contexts and fields. In particular, there are $n$ workers/nodes/devices collaborating to run some iterative algorithm which has the following structure: \\
\phantom{X} $\bullet$ In order to perform a single iteration of the algorithm, a certain number ($B$) of {\em tasks} needs to be performed.\\
\phantom{X} $\bullet$ Each task can be computed by any worker, and the tasks are not temporally related. That is, they can be computed in any order, in parallel, and so on. \\
\phantom{X} $\bullet$ Whenever  a worker is asked to perform a single task, the task will take a certain amount of time, modeled as a nonnegative random variable drawn from an unknown distribution specific to that worker. The stochastic assumption makes sense because in real systems computation times are not fixed and can vary with each iteration \citep{dean2013tail,chen2016revisiting, dutta2018slow, maranjyan2024mindflayer}. \\
\phantom{X} $\bullet$ Each worker can only work on a single task at a time. That is, a worker processes all tasks it has to perform sequentially.  Different workers work in parallel.


% {\em Remark:} Typically, the number of tasks is a hyper-parameter, and can be adjusted. The algorithm ``works'' as soon as at least one task is performed in each iteration, but will in some sense become ``more powerful'' if more tasks are performed. However, this detail is not important for the purposes of this introduction.

%\subsection{Greedy Task Allocation}

A natural goal in this setup is to make sure all tasks are completed as fast as possible (in expectation), which minimizes the (expected) time it takes for a single iteration of the algorithm to be performed provided that the task completion time is the dominant time factor of the iteration. Provided we are willing to waste resources, there is a simple solution to this problem, a Greedy Task Allocation (\algname{GTA}) strategy, which follows this principle:
{\em Make sure all workers are always busy working on some task, and stop once $B$ tasks have been completed.}
In \algname{GTA}, we initially ask all $n$ workers to start working on a task, and as soon as some worker is done with a task, we ask it to start completing another task. This process is repeated until $B$ tasks have been completed.

%\subsection{Wastefulness of \algname{GTA}}

While \algname{GTA} minimizes the completion time, it can be immensely wasteful in terms of the total worker utilization time needed to collect all $B$ tasks. Indeed, consider the scenario with $n=1000$ workers and $B=10$ tasks. In this case, \algname{GTA} will lead to at least $n-B = 990$ unnecessary tasks being run in each iteration! This is highly undesirable in situations where the workers are utilized across multiple other jobs besides running the iterative algorithm mentioned above.

%\subsection{Goal of this work}

The goal of our work is to design new task allocation strategies, with rigorous theoretical support, that would attempt to minimize the expected completion time subject to the {\em constraint} that such wastefulness is completely eliminated. That is, we ensure that no more than $B$ tasks are completed in each round.

% \paragraph{A motivating example: Optimal parallel SGD.}
\subsection{A motivating example: Optimal parallel SGD}

A key inspiration for our work, and the prime example of the general task collection problem described above, relates to  recent development in the area of parallel stochastic gradient descent (\algname{SGD}) methods.
Consider the problem of finding an approximate stationary point of the optimization problem
$$
    \min_{\bx \in \R^d} \left\{f(\bx) \eqdef \ExpSub{\bm{\xi} \sim {\cal D}}{f_{\bm{\xi}}(\bx)}\right\},
$$
where $f_{\bm{\xi}}:\R^d\to \R$ are smooth nonconvex functions, and $f$ is assumed to be bounded from below. We assume that $\mathbb{E}_{\bm{\xi} \sim {\cal D}}\left[ \|f_{\bm{\xi}}(\bx) - \nabla f(\bx)\|^2\right] \leq \sigma^2$ for all $\bx\in \R^d$.

In a recent breakthrough, \citet{tyurin2024optimal} recently developed a parallel \algname{SGD} method, {\em optimal} in terms of a novel notion of complexity called {\em time complexity}, for solving the above problem with $n$ parallel workers, assuming that  it takes $\tau_i>0$ seconds to worker $i$ to compute a stochastic gradient of $f$ (this corresponds to a task). Their method, \algname{Rennala SGD}, corresponds to \algname{Minibatch SGD} of minibatch size $B$ (which depends on the target accuracy and $\sigma$ only), with the $B$ tasks (stochastic gradients) completed via \algname{GTA}. While minimax optimal in terms of time complexity, the \algname{GTA} task allocation strategy employed within \algname{Rennala SGD} can be wasteful, as explained above.

Recently, \citet{maranjyan2025ringmasterasgdasynchronoussgd} proposed \algname{Ringmaster ASGD}, a fully asynchronous \algname{SGD} method, matching the optimal time complexity of \algname{Rennala SGD} and achieving optimality for arbitrary compute time patterns associated with the tasks (stochastic gradients), including random, as considered in our setup. However, \algname{Ringmaster ASGD} also employs a greedy task allocation strategy, leading to wastefulness.

Numerous other parallel/distributed methods involve the implementation of a task allocation strategy, including stochastic proximal point methods (task = evaluation of the stochastic prox operator), higher-order methods (task = evaluation of stochastic Hessian), and beyond. So, by addressing the general task allocation problem, we aim to tame the inherent resource wastefulness of all these methods.









%Lets make the problem a bit concrete.
%Consider Minibatch SGD. Lets say we need to collect $B$ gradients in each iteration.
%And it does not matter from which worker we collect the gradients.
%This is an interesting setup because \dots
%We can also reduce the heterogeneous problem to this, \dots
%
%If one cares only about the runtime and want the smallest possible runtime, then we need an allocation strategy that does the collection as fast as possible.
%
%If one knew the distribution of computational times than a better - resource efficient approach could be designed.
%In some cases this efficient approach would be as fast as the greedy approach.


%\subsection{Examples}
%
%For simplicity, assume we want to collect $B=1$ gradient. 
%The examples below can be generalized to any $1 \le B \le n$.
%
%\paragraph{Heterogeneous worker compute times}
%
%Assume we have the following computation time distributions:
%$$
%\tau_1 = \mathrm{Uniform}[a,3a], \quad \tau_j = \mathrm{Uniform}[3a,b] \quad j>1
%$$
%for some $a > 0$ and $b > 3a$.
%
%The fastest way to collect 1 gradient is to ask the first worker.
%Of course we don't know the computation times in advance, so we can't do this.
%
%So our goal is to design an algorithm that adaptively finds the best task allocation...


% \paragraph{Contributions.}
\subsection{Contributions}

In this work, we formalize the task allocation problem as a \emph{combinatorial online learning problem with partial feedback and non-linear losses}. Then, we introduce \algname{ATA}, a lower-confidence bound-based algorithm designed to solve the proposed allocation problem. \algname{ATA} is agnostic to workers' computation times, and our theoretical analysis demonstrates that the total computation time achieved by our methods remains within a small multiplicative factor of the optimal computation time (i.e., the one attainable with full knowledge of the workers' arm distributions).
Additionally, we present \algname{ATA-Empirical}, a variant of \algname{ATA} that leverages a novel data-dependent concentration inequality and achieves better empirical results.
Finally, we validate our approach through numerical simulations.




%In this work, we introduce two algorithms, \algname{ATA} and \algname{ATA-Empirical}, designed to minimize the expected cumulative regret \eqref{def:regret}. Both methods are detailed in \Cref{section:ata}. \algname{ATA} requires only an upper bound on the maximal Orlicz norm of the arm distributions as prior knowledge, while \algname{ATA-Empirical} requires only an upper bound of the quantity $\eta$ defined in \eqref{def:eta}. Theoretical guarantees for both procedures are established in \Cref{section:theory}, demonstrating that they achieve a logarithmic regret in the total number of rounds. Finally, we present numerical experiments in \Cref{section:experiments} to validate our theoretical results.
