

\begin{table*}[h]
	\centering
 \caption{Zero-shot performance in average NDCG@10 on BEIR datasets. 
%Row ``SPLADE Diff.'' is the mean relative performance compared to the SPLADE-HT1 performance.
}
		\resizebox{\columnwidth}{!}{
		%\begin{small}
		\begin{tabular}{r r r lr  |lllll|llllll}
			\hline\hline
                 &  & &  & &  \multicolumn{5}{c|}{SPLADE-HT1+SimLM} & \multicolumn{5}{c}{SPLADE-HT1+RetroMAE}\\
                  &  & &  & {SPLADE}  &  & &  \textbf{CluSD} & \textbf{CluSD} & \textbf{CluSD} & & &  \textbf{CDFS} & \textbf{CluSD} & \textbf{CluSD} & \textbf{CluSD}
\\
		    & \small{BM25} &{SimLM}  &  {RetroMAE} &{-HT1} & \small{$\blacktriangle$ 
 flat} &rrk&\textbf{flat}& \textbf{m=128}& \textbf{m=64}& \small{$\blacktriangle$ flat} &rrk &\textbf{flat}&  \textbf{flat}& \textbf{m=128}& \textbf{m=64}
\\
              \hline

\comments{
              \multicolumn{15}{c}{\bf{Search Tasks}}\\
               \hline
                {DBPedia}	& 0.313	& 0.351 &  0.390&0.447	& 0.426 &0.442& 0.429 & 0.425 & 0.422 & 0.446 & 0.411 & 0.446 & 0.445&0.436 \\
                                {FiQA} &	0.236	& 0.298 &  0.316&0.355 & 0.355 &0.355 &0.365 & 0.361 &0.359 & 0.365 & 0.333 & 0.366 & 0.359& 0.353\\
                {NQ}	& 0.329   & 0.502  &	 0.518&0.550 & 0.568 &0.549&0.568 & 0.566 & 0.560 & 0.563 & 0.520 & 0.564 & 0.553& 0.538\\
                {HotpotQA} & 0.603 & 0.568 &  0.635& {0.681} & 0.672 &0.668&  0.672 & 0.669 & 0.661 & 0.702 & 0.642 & 0.702 & 0.693&0.672 \\
                {NFCorpus}  & 0.325 & 0.318  &  0.308&0.351 & 0.353 &0.347&  0.360 & 0.358 & 0.359 & 0.345 &0.331 & 0.351 & 0.349& 0.346 \\
                {T-COVID}	& 0.656 & 0.515  &  0.772&0.705 & 0.726 &0.692&  0.745 & 0.741 & 0.725 & 0.780 & 0.699 &0.747 &0.740& 0.726\\
                {Touche}	& {0.367}  & 0.292  &  0.237&0.291 & 0.336 &0.292 &0.333 & 0.336 & 0.332 & 0.292 &0.316 & 0.295 &0.288& 0.283\\
                \hline
                \multicolumn{15}{c}{\bf{Semantic Relatedness Tasks}}\\
                 \hline
                {ArguAna} & 0.315 & 0.376  &  0.433&0.446 & 0.481 &0.427&  0.492 & 0.489 & 0.486 & 0.459 & 0.434 & 0.455 &0.455 & 0.451\\
                {C-Fever}	& 0.213 & 0.171  &  0.232&0.234 & {0.239} &0.236&  0.241 & 0.250 & 0.242 & 0.260 &0.198 &0.260 &0.267& 0.262\\
                {Fever} & 0.753  &0.689  &	 0.774& {0.781} & 0.793 &0.784&  0.794 & 0.783 & 0.789 & 0.820 &0.774 &0.820 &0.814& 0.800\\
                {Quora} & 0.789 & 0.797  &	 0.847&0.817 &	0.847 &0.816&  0.847 & 0.849 &0.848 & 0.856 &0.814 &0.855 &0.854& 0.849\\
                {Scidocs}	& 0.158 &0.137  &	 0.15&0.155 &	{0.165} &0.152&  0.166 & 0.166 & 0.165 & 0.167 &0.142 &0.169&0.166& 0.164\\
                {SciFact}	& 0.665 & 0.559  &  0.653& {0.682} & 0.674 &0.682&  0.694 & 0.689 & 0.693 & 0.706  &0.661 &0.703 &0.699& 0.694\\
}
                            \hline
                \textbf{Avg.} & 0.440 & 0.429  &  0.482&0.500 & 0.518 &0.496&  0.516 & 0.514 & 0.511 & 0.520 &0.483 &0.517& 0.518 &0.514& 0.506 \\
                %\textbf{BM25 Diff} & -- & -2.6\%  &	13.6\% &17.7\% &  6.1\%&12.7\%&14.8\% &  \textbf{15.7\%} \\
%                \textbf{{Splade Diff}} & -12.0 \% &  -14.2\%  &	 -3.6\% &-- & 3.6\% & -0.8\% &3.2\% & 2.8\% & 2.2\% &4.0\%& -3.5\%& 3.5\%&2.8\%&1.2\%\\
            \hline\hline
		\end{tabular}
		%\end{small}
		}
%\vspace*{-5mm}
	
 \vspace*{-5mm}
%For quantization approaches, we adopt M=16, K=256, i.e. compression rate 32$\times$ compared to ColBERT.
	\label{tab:beir}

\end{table*}



\comments{
\begin{table}[h]
	\centering
     \caption{Zero-shot retrieval performance 
    %in average NDCG@10 
    on 13 BEIR datasets 
    %Row ``SPLADE Diff.'' is the mean relative performance compared to the SPLADE-HT1 performance.
    }
		\resizebox{1\columnwidth}{!}{
		%\begin{small}
		\begin{tabular}{r r r r  |lllll}
              \hline
              \hline
	\multicolumn{4}{c|}{\bf Average NDCG@10}
                     &  \multicolumn{5}{c}{SPLADE-HT1+SimLM}\\
                  &  & & {SPLADE}  & Full  & &  \textbf{CluSD} & \textbf{CluSD} & \textbf{CluSD} \\
		    Dataset & \smaller{BM25} &{SimLM}  &{-HT1} & \smaller{$\blacktriangle$ 
 flat} &rrk&\textbf{flat}& \textbf{m=128}& \textbf{m=64}\\
              \hline
              \multicolumn{9}{c}{\bf{Search Tasks}}\\
               \hline
                {DBPedia}	& 0.313	& 0.351 &0.447	& 0.426 &0.442& 0.429 & 0.425 & 0.422 \\
                                {FiQA} &	0.236	& 0.298 &0.355 & 0.355 &0.355 &0.365 & 0.361 &0.359 \\
                {NQ}	& 0.329   & 0.502  &0.550 & 0.568 &0.549&0.568 & 0.566 & 0.560 \\
                {HotpotQA} & 0.603 & 0.568 & {0.681} & 0.672 &0.668&  0.672 & 0.669 & 0.661 \\
                {NFCorpus}  & 0.325 & 0.318  &0.351 & 0.353 &0.347&  0.360 & 0.358 & 0.359 \\
                {T-COVID}	& 0.656 & 0.515  &0.705 & 0.726 &0.692&  0.745 & 0.741 & 0.725 \\
                {Touche}	& {0.367}  & 0.292  &0.291 & 0.336 &0.292 &0.333 & 0.336 & 0.332 \\
                \hline
                \multicolumn{9}{c}{\bf{Semantic Relatedness Tasks}}\\
                 \hline
                {ArguAna} & 0.315 & 0.376  &0.446 & 0.481 &0.427&  0.492 & 0.489 & 0.486 \\
                {C-Fever}	& 0.213 & 0.171  &0.234 & {0.239} &0.236&  0.241 & 0.250 & 0.242 \\
                {Fever} & 0.753  &0.689  & {0.781} & 0.793 &0.784&  0.794 & 0.783 & 0.789 \\
                {Quora} & 0.789 & 0.797  &0.817 &	0.847 &0.816&  0.847 & 0.849 &0.848 \\
                {Scidocs}	& 0.158 &0.137  &0.155 &	{0.165} &0.152&  0.166 & 0.166 & 0.165 \\
                {SciFact}	& 0.665 & 0.559  & {0.682} & 0.674 &0.682&  0.694 & 0.689 & 0.693 \\
                            \hline
                \textbf{Avg.} & 0.440 & 0.429  &0.500 & 0.518 &0.496&  0.516 & 0.514 & 0.511 \\
                %\textbf{BM25 Diff} & -- & -2.6\%  &	13.6\% &17.7\% &  6.1\%&12.7\%&14.8\% &  \textbf{15.7\%} \\
                \textbf{{Splade Diff}} & -12.0 \% &  -14.2\%  &-- & 3.6\% & -0.8\% &3.2\% & 2.8\% & 2.2\% \\
            \hline\hline
		\end{tabular}
		%\end{small}
		}
%\vspace*{-5mm}
	
  \vspace*{-5mm}
%For quantization approaches, we adopt M=16, K=256, i.e. compression rate 32$\times$ compared to ColBERT.
	\label{tab:beir}

\end{table}

}


%\subsection{Zero-shot retrieval performance with BEIR}
\textbf{ Detailed zero-shot performance with BEIR}.
\label{sect:evalbeir}
Table~\ref{tab:beir} lists  the performance of  CluSD  
with  SimLM and  RetroMAE after SPLADE-HT1 retrieval in searching each of 13 BEIR datasets.
% that contain out-of-domain documents.
The LSTM model of CluSD  is trained with the  MS MARCO training set,
and it is directly applied to each BEIR  dataset to select clusters without further tuning. 
%Zero-shot out-of-domain performance is important since a large dataset can contain document content from many domains.
% to unseen models and datasets, we evaluate the pipeline on out-domain data. For this experiment, we use the BEIR benchmarks which consists 13 released document 
%sets on various semantic relatedness tasks. 
%We directly apply the CluSD model trained on MSMARCO training set to predict the clusters on the BEIR queries and BEIR specific clusters. 
As a baseline, column ``$\blacktriangle$ flat'' is to fuse  the uncompressed full dense retrieval  with SPLADE-HT1 sparse  retrieval.
Column marked ``rrk'' is to rerank   top 1,000  sparse retrieval results interpolated with their dense scores. 
%The final score are the interpolation of the sparse ranked list and dense re-ranked list. 
Columns with ``CluSD-flat'', ``CluSD-m=128'' and ``CluSD-m=64''  are  CluSD results  using uncompressed or compressed embeddings with
m=128 or m=64. 
This table also includes a column marked with ``CDFS-flat'' which is  the  selective fusion outcome with CDFS using uncompressed RetroMAE embeddings. 

%\begin{itemize} [leftmargin=*]
%\item 
%Even SimLM underperforms SPLADE retriever for BEIR,  
Table~\ref{tab:beir} shows
that the relevance of CluSD with selective fusion of sparse and dense results is higher than each individual retriever,
and CluSD with limited dense retrieval   performs  closely to   oracle ``$\blacktriangle$ flat'',
and delivers good NDCG@10 under two compression settings. CluSD is competitive to CDFS for the fusion of SPLADE and RetroMAE.
%While embedding compression affects relevance,  CluSD still performs fairly well for the BEID datasets.  
%This indicates good zero-shot performance of our proposed LSTM based strategy.
%\end{itemize}
  
