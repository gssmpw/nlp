%\subsection{Design options for CluSD}
%\subsection{Design options and parameters for CluSD}
% \vspace*{-2mm}
{\bf Design options for CluSD}.
\label{sect:evalLSTM}
% In this section, we discuss \textbf{RQ3} and \textbf{RQ4}.
Table~\ref{tab:cluster_feat} investigates the impact of the following design options 
for cluster selection in CluSD with  the MS MARCO Dev set. 
For Stage I selection, we explore two options:
1) SortByDist: Choose top clusters sorted by the distance of their  centroids to  the  query embedding.
2)  SortByOverlap:  Choose top  clusters sorted  by $P(C_i, B_j)$ features discussed in Section~\ref{sec:clusd}.
Namely, use the overlap degree of clusters with top result bins of sparse retrieval. 
For Stage II selection, we explore three options:
    1) XGBoost: Use the boosting tree XGBoost model to detect if a cluster should be visited.
The features used are the same ones discussed in Section~\ref{sec:clusd}. This is a pointwise approach, as we view query-cluster pairs as independent samples, and the decision on one cluster does not affect other clusters for the same query.
    2) RNN: Use a vanilla RNN model. The feature and sequence setup is the same as our LSTM model. 
    3) LSTM: the model we used in CluSD.
 We also assess  the impact  of removing a  feature group used in CluSD:
1) w/o inter-cluster dist: removing  the inter-cluster distance feature group;
2) w/o S-C overlap: removing  the overlap-degree feature of top sparse results with each cluster.



%\textbf{Impact of feature groups}.  

%  vs. Dense'' has a visible drop in relevance, indicating that the features we use are useful. Especially the sparse vs. dense feature, model performance has a significant drop without the feature group.

\begin{table}
\caption{Design options for  CluSD. $\blacktriangle$ is the default choice.}
\centering
\resizebox{0.8\columnwidth}{!}{%
  \begin{tabular}{ r |r r| r r| r }
			\hline\hline
			 Avg \#clusters targeted  & \multicolumn{2}{c}{3} & \multicolumn{2}{c}{5} & Time \\
			& MRR@10 & R@1K& MRR@10 & R@1K & ms\\
                   \hline
                 %RNN+prune & 0.401 & 0.919 & 0.411 & 0.961 & 2.8 \\
                 \multicolumn{6}{l}{\it{Stage II is removed. Stage I options only}}\\
                 SortByDist & 0.297 & 0.655 & 0.331 & 0.740  & 0 \\
                $\blacktriangle$ SortByOverlap & 0.384 & 0.867 & 0.401 & 0.917 & 0.2 \\
                   \hline
                \multicolumn{6}{l}{\it{Stage I=SortByDist;  Stage II model options}}\\
                 XGBoost& 0.398 & 0.888 & 0.404 & 0.929 & 192 \\
                 RNN & 0.404 & 0.908 & 0.406 & 0.938 & 2.8 \\
                 LSTM & 0.406 & 0.923 & 0.406 &0.943 & 2.8\\
                   \hline
             \multicolumn{5}{l}{\it{ Stage II=SortByOverlap;  Stage II LSTM feature group options}}\\
             w/o inter-cluster  dist& 0.402 & 0.915 & 0.406 & 0.941 & --\\
             %w/o Centroid Distance& 0.389 & 0.898 & 0.410 & 0.959 & --\\
             %w/o Sparse vs. Dense& 0.378 & 0.866 & 0.404 & 0.943 & --\\
             w/o  S-C overlap& 0.289 & 0.638 & 0.325 & 0.730 & --\\
             \hline 
             $\blacktriangle$  Default   &  0.408 & 0.943 & 0.410 & 0.953 & 2.8 \\
             %$-$ Query vs. Centroid & 0.405 & 0.925 & 0.406 & 0.941 & --\\
              \hline\hline
		\end{tabular}
}
        \label{tab:cluster_feat}
\vspace{-5mm}
\end{table}

The last row marked ``Default'' is the final version used by CluSD with SortByOverlap and LSTM.
To have a fair comparison, this table assumes on average either 3 or 5 clusters are targeted by CluSD.
%We compare the performance of different strategies to select dense clusters.  
For XGBoost, RNN or LSTM, we set their prediction threshold so that 
the average number of clusters is close to the targeted number.
The last column of this table is the time spent to select clusters. 
%chosen depends  on the model prediction thresholds. 
%where top 3 or 5 clusters are selected. 
%In order to compare under same budget, we set the thresholds where on average around 3 or 5 clusters are used averaged over all queries. 
Table~\ref{tab:cluster_feat} shows that  the RNN or LSTM based prediction achieves  higher MRR@10 and recall compared to 
XGBoost. 
%point-wise tree based model. 
%It is reasonable as the tree model doesn't take  into account of incremental the inter-cluster relationships.
%Row  marked ``LSTM+prune'' of Table~\ref{tab:cluster_feat}, we 
%SortbyOverlap in Stage I in CluSD can significantly  decrease  the decision time by reducing the length of input cluster sequence, and can  actually lead a visible relevance increase.
Feature exploration indicates that the overlap degree is important for  cluster selection
while the inter-cluster distance feature group is also useful. 



\textbf{Impact of  cluster partitioning size}.
%The cluster selection technique is built on top of a group of defined clusters. It is important to understand how the cluster selection works and a good rule of thumb to 
%determine the model prediction threshold given different number of clusters. 
CluSD pre-partitions the embeddings into $N$ clusters. 
Figure~\ref{fig:ncluster} shows the impact when $N$ is  4096 and  8192 for MS MARCO Dev.
% we plot three scenarios where the total number of clusters is 1024, 4096 and 8192 respectively. 
Stage I of CluSD uses  $n=128$ in this figure. 
%to depict the impact of selecting different numbers of clusters on average in a wider range.
A  solid line refers to the use of uncompressed dense embeddings while  a dash-dot line refers to OPQ quantization with m=128, 
and a dotted line refers to OPQ quantization  with m=64. The x-axis is the average number of clusters selected by CluSD.
We vary the selection threshold parameter $\Theta$ in CluSD to achieve the different 
average number of clusters selected. 
%Figure~\ref{fig:ncluster} shows that 
With both $N$ values,
%MRR@10 reaches above 0.420 when above    $<$ 10 clusters 
MRR@10 exceeds 0.420 when more than 10 clusters are selected.
As more clusters are selected,  the recall ratio increases. 
%Note that when total number of clusters increases, the percentage of documents search will be different given a fixed number of clusters are selected. 
%Given a fixed number of selected clusters,  the latency impact is different with different $n$ values.
%This result in difference in average latency. 
%For  a fixed average number of selected clusters, 
Different $N$ values impact latency. 
For example, when 10 clusters are selected on average, 
CluSD  scans through 0.1\% and  0.2\% of embeddings, corresponding to N=4096 and 8192, respectively. 
%As we can see in the bottom two sub-figures, 
When $N= 8192$, its latency is reduced
%in milliseconds 
%is smaller  with a  smaller size per cluster
because CluSD time complexity is proportional  to  the size per cluster and the number of clusters selected.
%With $N$ becomes much bigger,  the overhead of clusters in stage II optimization starts to offset or outweigh latency benefits of small clusters. 
% while the overall CluSD time is still  
 \vspace*{-5mm}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.18]{plot2.pdf}
    \caption{CluSD relevance and latency vs.  the average  number of clusters selected }
    \label{fig:ncluster}
 %\vspace*{-10mm}
 \vspace*{-4mm}
\end{figure}

\comments{
Lastly, as CluSD makes a query-specific decision to dynamically select  clusters, each query has  a  different number of clusters visited
given a fixed threshold value and query latency can vary. 
The bottom right subfigure shows that the 99\textsuperscript{th}
percentile latency is around 2x longer than the mean latency, which is reasonable by
looking at the previous retrieval latency studies (e.g. ~\cite{mallia2019pisa, 2022ACMTransAnytime}).
%mackenzie2021anytime
}



\comments{
%\subsection{Impact of  selection threshold $\Theta$}
\label{sect:threshold}

\textbf{Impact of  selection threshold $\Theta$}.
%\label{sect:threshold}
The left portion of Figure~\ref{fig:thresholds} shows
the average number of SimLM dense clusters selected by CluSD for MS MARCO Dev set under different threshold $\Theta$ values  when
the input sequence length $n$ for Stage II LSTM is 32.
%Model prediction threshold refers to the threshold which we use to determine the selection of a cluster. 
A threshold can be chosen for CluSD to follow a  time budget. 
%As we can see, there is a variety in the number of clusters selected. 
%While the median number of clusters selected is  10 clusters, the 75th percentile is around 18 clusters. 
In our experiments,  the default setting of
CluSD is to use threshold 0.02  for MS MARCO passages and the average number of clusters selected by CluSD using this threshold is 22.3.

The right portion of Figure~\ref{fig:thresholds} 
shows  the mean number of clusters selected for MS MARCO Dev set and averaged over 
the zero-shot BEIR datasets.
This subfigure shows that for a fixed $\Theta$ value, CluSD  adaptively chooses a fewer number of clusters for a
BEIR dataset compared to the MS MARCO Dev set.  
%This aligns with our expectation that  
This is intuitive as
SimLM underperforms SPLADE on the BEIR datasets in general. Thus, it is unnecessary to evaluate a lot of clusters. 
%CluSD adaptively selects fewer clusters for BEIR% to conduct selective dense retrieval. 
}
