%\section{Limitations and Future Work}
\section{Concluding Remarks}

The main contribution of this work is  to  show  how 
a lightweight cluster-based partial dense retrieval 
with competitive  relevance can be made possible
to deliver fast response time on affordable computing platforms, without the need of an expensive  document-wise  proximity graph.
%CluSD carries with minimal space overhead compared to the orginal dense retrieval
%and incurrs a small amount of CPU latency time due to the limited dense computation.
\comments{
CluSD uses  an LSTM-based  model and  leverages sparse retrieval results to effectively identify  a small number of 
clusters that can supplement and boost the relevance of partial dense  retrieval.  
With this lightweight low-cost design,  
CluSD is suitable for a CPU-only low-cost server while delivering  a fairly strong  in-domain and out-of-domain relevance.  
For example, CluSD delivers 0.423 MRR@10  for searching 8.8M MS MARCO passages 
with 11.4ms  latency and  1.13GB space mainly for compressed dense embeddings, to augment sparse retrieval under
a fraction of its  cost. The same  CluSD version  reaches  0.514 average NDCG@10 for BEIR with compression.
That represents state-of-the-art relevance performance for a retriever that  runs on a CPU-only server. 
}
Guided by sparse retrieval, CluSD  outperforms  previous cluster-based partial dense retrieval with IVF 
search significantly in relevance under the same time budget.
For example, CluSD delivers 0.431 MRR@10  for searching 8.8M MS MARCO passages on its Dev test set taking only tens of milliseconds on a low-end CPU server
and reaches  0.516 average NDCG@10 for BEIR.  That represents a state-of-the-art relevance performance for a retriever that  runs on 
a CPU-only server. 
%The othe recent efficient retrievers reported 0.426  for MS MARCO Dev, and 0.48 for BEIR by LexMAE.
Its MRR@10 number is close to one reported recently using an expensive cross-encoder RankT5 which reaches 0.434~\cite{2023SIGIR-ZhuangRankT5}. 
%ClusD's BEIR performance is close to  that  of  Promptagator++~\cite{dai2023promptagator}.  Both  RankT5 and Promptagtor++h employ an expensive cross-encoder.
Noted that user search experience is highly impacted by the ranking order and its relevance thus a relatively small percentage point increase  
in metrics for the standard public test benchmarks used in this paper is viewed to be hard and valuable in the IR research literature.

%For example,
%Table ~\ref{tab:mainspace} shows CluSD is as fast as IVFOPQ top 2\% search at m=64 and 2x fast at m=128 while its MRR@10  is 11.5\% and 9.5\% higher 
%that only use query-centroid distances to select clusters. 

Compared to LADR and HNSW, our evaluation demonstrates that without a document-levelproximity graph, CluSD can 
deliver a similar or higher 
relevance under the same time budget
with negligible extra space overhead when embeddings are available in memory  and  is  much faster by avoiding fine-grained document-level disk I/O
when embeddings do not fit in  memory.  
Thus the lightweight with low-space overhead  and low-I/O cost is the main advantage of CluSD compared to a graph navigation approach.
\comments{
For example, Table ~\ref{tab:maintime} shows
CluSD has 2\% higher MRR@10  than LADR and 1.2\% higher than HNSW under a time budget of 25ms.
%It is attractive to run such an algorithm on a first-stage retrieval low-cost machine
%that can significantly reduce the overall infrastructure cost when scaling  data size and search traffic. 
}
Compared to several on-disk nearest-search efforts  with DiskANN and SPANN~\cite{NEURIPS2019_DiskANN,2023Web-Filtered-DiskANN},
like HNSW, they are targeted for a stand-alone and general ANN problem while our
work takes advantage of sparse retrieval for much shorter latency and similar or better relevance in the context of text document search.

Simple re-ranking does surprisingly well if sparse results are strong. But as stated in~\cite{2022CIKM-MacAvaneyGraphReRank,2023SIGIR-LADR},
when the sparse retriever doesn’t achieve high relevance, re-ranking is too 
restrictive and recall@1k does not increase as shown in Table 5. 
\comments{
For example, after 
sparse retrieval with SPLADE-effi-HT3 with 0.944 recall@1k, re-ranking does not increase it while CluSD increases it to 0.984.
While re-ranking restricts candidate documents to the top sparse results, CluSD adds more diversified results from selected dense clusters. 
}
CluSD’s advantage becomes more significant in zero-shot retrieval as shown in Table 6 with 13 BEIR datasets. CluSD’s average NDCG number is 
7.2\% higher than re-ranking with RetroMAE. With SimLM, CluSD is 4\% higher than re-ranking.
In addition to this, when embeddings are not available in memory, re-ranking becomes very slow with a large number of document-level random I/O operations. 

Our evaluation uses OPQ in FAISS. 
Switching to a different quantization affects the compression ratio and  the relevance outcome. 
However, we expect that our findings remain similar and  the recent  quantization 
methods~\cite{2021CIKM-JPQ-Zhan,  2022WSDM-Zhan-RepCONC, Xiao2022Distill-VQ}
also have  a significant relevance drop pattern when the compression ratio increases.
%A limitation of the current  CluSD work is that the training of the LSTM model has a dependence on the sparse retrieval model used. 
%While  CluSD can  boost the relevance of a weaker sparse retriever model such as BM25, the augmented relevance still has not reached a level
%comparable  to the one where CluSD is coupled with a stronger sparse retriever. There is room for improvement in future work.
\comments{
}

%the dependency on a training dataset. Unlike rule-based or unsupervised pipelines, our pipeline requires labeled data on at least one search task. However, the number of queries with labels is not large and a trained model is robust on never-seen corpus and tasks. 
%
%Another limitation is the dependency on the sparse retrieval model performance. CluSD benefit from a good sparse retrieval top results. When using a BM25 based retrieval, the quality of the clusters selected degrades slightly. 
