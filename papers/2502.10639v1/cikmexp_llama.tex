%\subsection{CluSD with LLaMA-2 based dense retrieval}
{\bf CluSD with LLaMA-2 based dense retrieval}.
%\label{sect:llama}
Table~\ref{tab:RepLLaMA}
demonstrates that CluSD can effectively support selective RepLLaMA dense retrieval~\cite{ma2023finetuning} 
 when taking advantage of  a larger language model  on a low-cost platform for MS MARCO Dev. 
The ``Latency'' column includes sparse retrieval CPU time when ``S+'' is marked in the method name. 
S=SPLADE-HT1.
%This LLaMA-2~\cite{touvron2023llama} based model  
This LLaMA-2 based model uses 145GB embedding space with 4K dimensionality.
% for MS MARCO passages. 
All rows except the last row  conduct in-memory search assuming data fits into memory.
Row 1 shows  it takes 7.9 second CPU time to conduct in-memory full RepLLaMA  retrieval. 
Row 2  shows the performance of RepLLaMA using OPQ quantization but without IVF selective search.
Row 3  shows the performance of RepLLaMA using OPQ and  IVF selective search.
Use  of these optimization techniques leads to  a significant relevance degradation. 
As a reference, Row 4 lists the fusion of sparse results and  full dense retrieval. 
%Rows 5 and 6 are CluSD with SPLADE-HT1 retrieval without or with disk data.
%The latency includes sparse retrieval. 





\comments{
\begin{verbatim}
MRR@10	R@1K	CPU Latency	Space
(1) RepLLaMA	0.412	0.990	7.9s	145GB
(2) RepLLaMA-ivfopq	0.365	0.915	97ms	6.1GB
(3) S + CluSD	0.424	0.986	60ms	149GB
(4) S + RepLLaMA	0.426	0.994	7.9s	149GB
(5) RepLLaMA-OPQ	0.384	0.990	666ms	2.4GB

\end{verbatim}
}

\begin{table}[htbp]
\vspace*{-1em}
\small
        \centering
                \begin{tabular}{r r |l l|l l}
                        \hline\hline 
     &Method    & MRR@10 & R@1K & Latency & Space \\
                        \hline
1.  & RepLLaMA     & 0.412$^\dag$& 	0.990& 	7.9 s& 	145 GB\\
2.   &RepLLaMA-OPQ& 	0.384$^\dag$& 	0.990& 	666 ms& 	2.4 GB \\
3.  & RepLLaMA-IVFOPQ & 	0.365$^\dag$ & 	0.915$^\dag$ & 	97 ms & 	6.1 GB\\
4.   & S + RepLLaMA  & 	0.426& 	0.994& 	7.9 s& 	149 GB\\
5.   & S+CluSD & 0.424	& 0.986& 	39 ms& 	149 GB\\
6.   & S+CluSD (on-disk)& 	0.424	& 0.986& 	60 ms& 	149 GB\\
                \hline\hline
                \end{tabular}  
        \caption{CluSD with  dense RepLLaMA and  sparse SPLADE} 
\vspace*{-2em}
        \label{tab:RepLLaMA}
\end{table}


CluSD applies SPLADE sparse retrieval and then visits  a small number of clusters from 60,000 dense RepLLaMA clusters. 
CluSD  with SPLADE-HT1 takes about 39ms with in-memory search shown in  
Row 5, and  60ms with on-disk search shown in Row 6.  
%The latency time includes both sparse and dense retrieval on a CPU server. 
To use GPU, RepLLaMA inference would require five Nvidia V100 GPUs (each with 32GB) to host data and take 37ms GPU time. 
Thus CluSD  can deliver 1 or 2 order of magnitudes of improvement in total latency or infrastructure cost.

RepLLaMA does very well for zero-shot retrieval on BEIR datasets with average NDCG 
0.561 and CluSD can deliver fast with average NDCG 0.541.
Our LSTM model for RepLLaMA was a zero-short version trained using  BERT-based SimLM on MS MARCO passage 
data and then applied to search MS MARCO Dev and BEIR datasets and we expect that further improvement is possible in the future.
%(a 3.6\% NDCG degradation) 

