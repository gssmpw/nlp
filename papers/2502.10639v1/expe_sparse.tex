\subsection{CluSD under  different sparse models}
\label{sect:evalsparse}

%We explore the model performance when we interpolate different sparse model with SimLM with cluster selection in 
Table~\ref{tab:sparse} examines the outcome  of CluSD when employing
three sparse retrievers with different efficiency/relevance tradeoffs. 
These sparse models accomplish  different relevance  scores: 
the fastest BM25 model 
delivers the lowest MRR number
while the slowest Splade-HT1 takes more time but has a higher MRR@10 number.
For all three models, CluSD supplements sparse results and boosts the overall retrieval relevance.
The final relevance outcome of using two SPLADE models is better  than that for BM25 retriever.
%That is partially caused by dependence of LSTM training where  the positive clusters are identified by the overlap of top 10 SPLADE results with these  clusters.
It is because the LSTM model uses  the overlap feature  of top sparse results with dense clusters,
the quality of top sparse results still has an impact on the final outcome.  
%consists of the distribution of sparse top results into clusters. 
%When the sparse model doesn't identify good top candidates, the input features to the LSTM model becomes more noisy which affect performance. 
\comments{
From left to right, the model performance degrades. 
We can observe that when sparse model performance degrades, 
the performance of S + CluSD degrades as well on the flat index. 
For example, on Splade-HT1-fast, the relevance is around the same as S $+$ D on MRR@10, and 0.6\% degradation on recall@1k. 
When we use BM25-T5 model, the degradation is 1.7\% and 1.5\% respectively on MRR@10 and recall@1k. 
This indicates that when the Splade model model does not perform well, CluSD becomes less effective. 
It is expected because the input to the LSTM model consists of the distribution of sparse top results into clusters. 
When the sparse model does not identify good top candidates, the input features to the LSTM model become more noisy which affects performance.
}

\begin{table}[htbp]
	\centering
		\resizebox{\columnwidth}{!}{%
		\begin{tabular}{ r l l  |ll |ll |r }
			\hline\hline
                Sparse Model& \multicolumn{2}{c|}{\bf{Splade-HT1-fast}} & \multicolumn{2}{c|}{\bf{Splade\_effi-HT3}}   & \multicolumn{2}{c|}{\bf{BM25-T5}} & Extra\\ 
%\cline{1-7}
                Latency & \multicolumn{2}{c|}{22.4ms} & \multicolumn{2}{c|}{12.4 ms}   & \multicolumn{2}{c|}{9.2 ms} & Latency\\ 
\cline{1-7}
			& {MRR@10} & {R@1k}  & {MRR@10} & {R@1k}   & {MRR@10} & R@1k  & ms \\
   \hline
   \multicolumn{8}{c}{\bf{uncompressed flat embedding. Embedding space  27.2 GB}}\\
			\hline
			S & 0.385$^\dag$& 0.949$^\dag$& 0.380$^\dag$& 0.944$^\dag$& 0.259$^\dag$& 0.935$^\dag$& -\\
                $\blacktriangle$  S $+$ D & 0.416 & 0.986 & 0.413 & 0.984 & 0.415 & 0.985  & +1674.1\\
                {\textbf{S $+$ CluSD}} & 0.415 & 0.981$^\dag$& 0.411 & 0.979$^\dag$& 0.408& 0.970$^\dag$& +12.1 \\
                \hline
                \multicolumn{8}{c}{\bf{OPQ m=128. Embedding space  1.1 GB}}\\
%, Report S+*
\hline
                S $+$ D-IVFOPQ & 0.384$^\dag$& 0.981$^\dag$& 0.381$^\dag$& 0.978$^\dag$& 0.369$^\dag$& 0.975$^\dag$& +21.9 \\
                %S $+$ D=HNSWOPQ & & & & & & &  \\
                \bf{S $+$ CluSD} & 0.413& 0.984& 0.412& 0.984& 0.402$^\dag$& 0.975$^\dag$& +9.8  \\
                %\hline
                %\multicolumn{8}{c}{OPQ M=64. Embedding space  0.6 GB}\\
%, Report S+*
                % S $+$ IVFOPQ-5\% & 0.389 & 0.981 & 0.389 & 0.980 & 0.370 & 0.975 & 23.7 \\
                %S $+$ HNSWOPQ & & & & & & &  \\
                %S $+$ \bf{CS} & 0.402& 0.981& 0.402& 0.981& 0.380& 0.973& 10.2 \\
            \hline\hline
		\end{tabular}
		}
	\caption{CluSD performance  under  three  sparse models}

\vspace*{-5mm}
	\label{tab:sparse}
\end{table}
% For all three sparse models, we use the same dense model configuration so for each row we only report one latency number. 


\comment{
\begin{table}[htbp]
	\centering
		\resizebox{\columnwidth}{!}{%
		\begin{tabular}{ r r r r r  r r r}
			\hline\hline
			& \multicolumn{2}{c}{MSMARCO Dev}& \multicolumn{2}{c}{DL19}& 
\multicolumn{2}{c}{DL20} \\
			& \% n& MRR@10 & R@1k & NDCG@10 & R@1k &  NDCG@10 & R@1k\\
   			\hline
 D& -- & 0.416& 0.988& 0.720& 0.744& 0.703&0.755\\
            $\blacktriangle$  S $+$ D & -- & 0.425 & 0.988 &  0.740& 0.816&   0.731& 0.819\\
            \bf S $+$ \bf{CluSD} & 0.5 &  0.426 & 0.987 &  0.744&  0.820& 0.734&  0.818\\
            \hline
            \multicolumn{8}{c}{OPQ M=128 setting, Storage 1.1GB, Report S+*}\\
            \hline
            IVFOPQ &10 & 0.404 & 0.987 & 0.713 & 0.818 & 0.722 & 0.817 \\
            & 5 & 0.394 & 0.987 & 0.687 & 0.817 & 0.706 & 0.817 \\
            & 2 & 0.374 & 0.986 & 0.656 & 0.815 & 0.700 & 0.817 \\
            HNSWOPQ & & & & & & \\
            \bf{CS} & 0.5 & 0.417& 0.986& 0.742 & 0.818 & 0.735  &0.815 \\
            \hline
            \multicolumn{8}{c}{OPQ M=64, Storage 0.6 GB, Report S+*}\\
            \hline
            IVFOPQ & 10 & 0.393 & 0.986 & 0.676 & 0.814 & 0.730 & 0.818 \\
            & 5 & 0.384 & 0.985 & 0.659 & 0.814 & 0.717 & 0.817 \\
            & 2 & 0.368 & 0.985 & 0.643 & 0.814 & 0.707 & 0.816 \\
            HNSWOPQ & & & & & & & \\
            \bf{CS} & 0.5  & 0.403& 0.987& 0.729 & 0.812 &0.724 & 0.814 \\           
			\hline\hline
		\end{tabular}
		}
	\caption{RetroMAE
%For quantization methods on top of ColBERT, we also report \% degradation from ColBERT.
}
	\label{tab:retromae}
\end{table}
}

