\comment{
\begin{table*}[htbp]
	\centering
		\begin{small}
		\begin{tabular}{ r r r |r r  |r r  |r r}
			\hline\hline
			& \multicolumn{2}{c|}{MSMARCO Dev}& \multicolumn{2}{c|}{DL19}& 
\multicolumn{2}{c|}{DL20}& Latency  & Storage  \\
			& MRR@10 & R@1k & NDCG@10 & R@1k &  NDCG@10 & R@1k & ms & GB\\
			\hline
            \multicolumn{9}{c}{Retrieval Depth = 1000}\\
           D=SimLM & 0.411 & 0.985 & 0.714 & 0.767 &  0.697 & 0.773 & 1674.1 & 27.2 \\
            D-IVF-6\% & 0.400  & 0.942 & 0.673 & 0.679 & 0.694 & 0.684 &  100.4 & 27.2 \\
            D-OPQ-m32 & 0.314 & 0.957  & 0.619 & 0.671 & 0.608 & 0.683 & 109.1 & 0.3 \\
            D-IVFOPQ-m128-15\% & 0.397 & 0.965 & 0.699 & 0.708 & 0.699 &0.720 &102.4 & 1.2 \\
            D-HNSW & 0.409 & 0.978 & 0.669 & 0.722 & 0.695 & 0.760 & 127.8 & 36.4 \\
            S=SPLADE-HT1 & 0.396 & 0.980 & 0.732   &  0.811 & 0.721    &  0.815  &   62.3 & \\
            S $+$ rerank-D &  0.412 & 0.980    &0.715  & 0.811 & 0.698 & 0.815 & $+$2.3 \\
            LADR & 0.412 & 0.983 & 0.714 &  0.785 &0.697  & 0.799& $+$ 19.1 & \\
            S $+$ D  & 0.424 & 0.989 & 0.740 & 0.767  & 0.726 & 0.773 & $+$ 1674.1 & \\
           S $+$ D-IVF-2\% & 0.398 & 0.987  & 0.674 & 0.816 & 0.720 & 0.813 &  $+$ 33.5 & \\
           S $+$ D-IVFOPQ-m128-5\% & 0.407 & 0.987 & 0.717 & 0.820 & 0.733 & 0.817 &  $+$ 38.1 & \\
            %\bf S $+$ CS-D &  0.420 & 0.985 & 0.734 & 0.816 & 0.722 & 0.818 & +19.4 & \\
             %\bf S $+$ QF-CS-D &  0.415 & 0.983 & 0.735 & 0.815 & 0.722 & 0.817 & $+$ 11.6 & \\
             \bf S $+$ CS-D $+$  rrk10 & 0.425 & 0.986 & 0.740 & 0.815 & 0.727 & 0.819 & $+$ 20.5 & \\
            \bf S $+$ CS-D $+$  rrk10 & 0.425 & 0.985 & 0.739 & 0.817 & 0.726 & 0.819 & $+$ 15.9 & \\
       \bf S $+$ QF-CS-D + rrk10 &  0.417 & 0.983 &  0.738 & 0.815 & 0.722 & 0.818 & $+$ 10.3 & \\
       \bf S $+$ QF-CS-D + rrk10 &  0.417 & 0.983 &  0.738 & 0.813 & 0.722 & 0.817 & $+$ 12.7 & \\
       \hline
       \multicolumn{9}{c}{Retrieval Depth = 10}\\
       D=SimLM & 0.411 & 0.696 & 0.714 & 0.169 &  0.697 &        0.225 &  \\
            D-IVF-6\% &  0.400 & 0.671 & 0.673 & 0.145 & 0.694 & 0.223 & 100.4 & 27.2 \\
            D-OPQ-m32 & 0.314 & 0.571 & 0.619 & 0.134 & 0.608 & 0.207 & 109.1 & 0.3 \\
            D-IVFOPQ-m128-15\% & 0.397 & 0.675 & 0.699 & 0.158 & 0.699 & 0.221 & 102.4 & 1.2 \\
            D-HNSW & 0.409 & 0.691 & 0.669 & 0.142 & 0.695 & 0.225 & 127.8 & 36.4  \\
            LADR & 0.412 & 0.696 & 0.722 & 0.701 & 0.697 & 0.696 & splade 200T $+$ 3.9 &  \\
           S=SPLADE-HT1 & 0.396 & 0.514 &  0.732   &  0.175 & 0.721    & 0.245 &  \\
          S $+$ D  & 0.421 & 0.704 & 0.732 & 0.175 & 0.721 & 0.245 & & \\
            S $+$ rerank-D &  0.410 & 0.674 & 0.733 & 0.175 & 0.726 & 0.245  &  \\
            %S $+$ rerank-D-itp &  0.413 & 0.674 & 0.736 & 0.175 & 0.726 & 0.245 &   \\
            S $+$ D-IVF-2\% & 0.399 & 0.682  & 0.676 & 0.153 & 0.693 & 0.213 &  $+$ 33.5 & \\
           S $+$ D-IVFOPQ-m128-5\% & 0.404 & 0.682 & 0.695 & 0.149 & 0.707 & 0.220 &  $+$ 38.1 & \\
            %\bf S $+$ CS-D &  0.418 &0.701&0.724&0.172&0.725&0.247 & \\
             %\bf S $+$ QF-CS-D &  0.413 &0.695&0.729 &0.173&0.731&0.249&\\
            \bf S $+$ CS-D $+$  rrk10 & 0.418 & 0.703 & 0.722 & 0.173 & 0.710 & 0.228 & $+$ 15.9 &  \\
       \bf S $+$ QF-CS-D + rrk10 &  0.413 & 0.695 & 0.726 & 0.173 & 0.719 & 0.244 & $+$ 10.3 & \\

			\hline\hline
		\end{tabular}
		\end{small}
	\caption{Model relevance and Latency Under Different Search Settings with Retrieval Depth 1000 and 10
%For quantization methods on top of ColBERT, we also report \% degradation from ColBERT.
}
	\label{tab:main1k}
\end{table*}
}

\comment{
\begin{table*}[htbp]
	\centering
		\begin{small}
		\begin{tabular}{ r r r |r r  |r r  |r}
			\hline\hline
			& \multicolumn{2}{c}{MSMARCO Dev}& \multicolumn{2}{c}{DL19}& 
\multicolumn{2}{c}{DL20}& Latency   \\
			& MRR@10 & R@1k & NDCG@10 & R@1k &  NDCG@10 & R@1k & ms \\
			\hline
              \multicolumn{7}{l}{\it S: BM25-T5-B, D: SimLM}&  \\
            S & 0.259 & 0.935 & 0.578 & 0.755 & 0.588 &       0.761 & 9.2 \\
              S $+$ flat-D  & 0.415 & 0.985 & 0.718 & 0.808 & 0.705 & 0.813 & $+$ 1674.1 \\
             S $+$  rerank-D &  0.409 & 0.935  & 0.714 & 0.755 & 0.698 & 0.761 & $+$ 2.3\\
             S $+$  rerank-D-itp & 0.413 & 0.935 & 0.721 & 0.755 & 0.705 & 0.761 & $+$ 2.3\\
           %S $+$ LADR& 0.412& 0.983& 0.712& 0.788& 0.692& 0.787& $+$ 19.1 \\
  %S $+$ LADR-itp& & & & & & &\\
            S $+$ LADR& 0.412& 0.983& 0.712& 0.788& 0.692& 0.787& $+$ 19.1 \\
           S \textbf{ $+$ CS-D} &0.408 & 0.977 & 0.713 & & 0.689 & 0.797  & $+$ 18.2 \\
           S \textbf{ $+$ CS-D + rrk10} &0.412 & 0.977 & 0.713 & 0.801 & 0.699 & 0.796  & $+$ 18.2 \\
           \multicolumn{7}{l}{\it S: BM25-T5-B, D: RetroMAE}&  \\
     S $+$ flat-D  & 0.416 & 0.986 &  & & &  & $+$ 1677.9 \\
           S $+$  rerank-D &  0.413 & 0.935  &  & & & & $+$ 2.3\\
            S $+$  rerank-D-itp &  0.416 & 0.935  &  & & & & $+$ 2.3\\
            S \textbf{$+$ CS-D} & 0.404 & 0.978  &&  && & $+$ 21.4 \\
            S  \textbf{$+$ CS-D $+$ rrk10} & 0.415 & 0.978  &&  && & $+$ 21.4 \\
            \hline
   %        \multicolumn{11}{l}{\it  S: SPLADE-effi-HT3-2GT,  D: SimLM}  \\
    %        S & 0.391 & 0.846 &  0.976 & 0.724 &     0.429  & 0.813  & 0.731  &  0.505   &  0.805  & 14.2 \\
    %       S $+$ flat-D  & 0.421 & 0.860 & 0.985 & 0.724 & 0.432 & 0.815 & 0.735 & 0.516 & 0.775 & $+$ 1674.1 \\
    %       S + rerank-D &  0.411 & 0.879 & 0.976   & 0.713 & 0.422 & 0.813 & 0.686 & 0.493 & 0.805 & $+$23.4 \\
    %         S $+$ IVF-D & 0.380 & 0.771 & 0.985 & & & & & & &  $+$ 25.6\\
    %     \bf S  $+$ CS-D & 0.415 & 0.874 & 0.985 & 0.728 & 0.430 & 0.818 & 0.726 & 0.505 & 0.811 & $+$ 18.1 \\
    %        \bf S $+$ QF-CS-D & 0.407 & 0.866 & 0.982 & 0.715 & 0.438 & 0.817 & 0.720 & 0.496 & 0.807 & 15.3  \\
    %        \multicolumn{11}{l}{\it  S: SPLADE-effi-HT3-2GT,  D: RetroMAE}  \\
     %      S $+$ flat-D  & 0.425 & 0.891 & 0.988 &  & & & & &  & $+$ 1677.9 \\
     %      S + rerank-D &  0.416 & 0.883 & 0.976   &  & & &  & &  & $+$23.4 \\
     %       S $+$ IVF-D & 0.350 & 0.716 & 0.985 & & & & & & &  $+$ 37.2\\
     %       \bf  $+$ CS-D & 0.413 & 0.877 & 0.986 &&&  &&& & $+$ 22.2 \\
      %      \bf $+$ QF-CS-D & 0.404 & 0.866 & 0.981 &&&  &&& & $+$ 16.8  \\
      %      \hline
            \multicolumn{7}{l}{\it  S: SPLADE-HT1, D: SimLM}&  \\
            S & 0.396 & 0.980 & 0.732   &  0.811 & 0.721    &  0.815  &   62.3 \\
          S $+$ flat-D-itp  & 0.424 & 0.989 & 0.740 & 0.767  & 0.726 & 0.773 & $+$ 1674.1 \\
            S $+$ rerank-D &  0.412 & 0.980    &0.715  & 0.811 & 0.698 & 0.815 & $+$2.3 \\
            S $+$ rerank-D-itp &  0.421 & 0.980 & 0.745 & 0.811 & 0.728 & 0.815 & $+$2.3 \\
           S $+$ IVF-D & 0.384 & 0.987 & & & & &  $+$ 25.6\\
           S  $+$ LADR & 0.412& 0.983& 0.697&0.799&& & $+$42.8 \\
 S $+$ LADR-itp& 0.422& 0.969& & & & &\\
            \bf S $+$ CS-D &  0.420 & 0.985 & 0.734 & 0.816 & 0.722 & 0.818 & +17.2 \\
             \bf S $+$ QF-CS-D &  0.415 & 0.983 & 0.735 & 0.815 & 0.722 & 0.817 & $+$ 8.9 \\
            \bf S $+$ CS-D $+$  rrk10 & 0.425 & 0.985 & 0.739 & 0.817 & 0.726 & 0.819 & $+$ 17.2 \\
       \bf S $+$ QF-CS-D + rrk10 &  0.417 & 0.983 &  0.738 & 0.815 & 0.722 & 0.818 & $+$ 9.9 \\
            \it  S: SPLADE-HT1, D: RetroMAE&&&&&&&  \\
            S $+$ flat-D-itp  & 0.425 & 0.988 &  & & &  & $+$ 1677.9 \\
            S $+$ rerank-D &  0.416 & 0.980    & & & &  & $+$2.3 \\
            S $+$ rerank-D-itp &  0.422 & 0.980    & & & &  & $+$2.3 \\
            S $+$ IVF-D & 0.350 & 0.987 & & & & &  $+$ 37.2\\
            \bf $+$ CS-D &  0.414 & 0.987 &  &  & & & $+$ 19.7 \\
            \bf $+$ QF-CS-D &  0.410 & 0.985 &  & & &  & $+$ 9.8 \\
           \bf $+$ CS-D $+$ rrk10 &  0.424 & 0.987 &  &  & & & $+$ 20.7 \\
            \bf $+$ QF-CS-D $+$ rrk10 &  0.412 & 0.985 &  & & &  & $+$ 10.2 \\
            \hline
           \multicolumn{7}{l}{\it  Dense Retrieval Options}&  \\
             SimLM-flat & 0.411 & 0.985 & 0.714 & 0.767 &  0.697 & 0.773 & 1674.1\\
             SimLM-IVF-2\% &  0.388 &  &&  && &33.5 \\
             SimLM-IVF-10\% &  0.403 &  &&  && &164.3 \\
             SimLM-OPQ-m16 & 0.221 &  &&  && & 59.0 \\
             SimLM-OPQ-m32 & 0.325 &  &&  && & 109.1 \\
            SimLM-IVFOPQ-m128-5\% & 0.379 &  &&  && &13.7 \\
            SimLM-IVFOPQ-m256,10\% & 0.399 &  &&  && & 143.8 \\
              RetroMAE-flat & 0.416 & 0.988 &&  && & 1677.9 \\
               RetroMAE-IVF-2\% &  0.367 &  &&  && &48.1 \\
              RetroMAE-IVF-10\% &  0.406 &  &&  && &299.0 \\
              RetroMAE-OPQ-m16 & 0.171 &  &&  && & 59.4 \\
             SimLM-OPQ-m256 & 0.404 &  &&  && & 1586.5 \\
             RetroMAE-IVFOPQ-m256,10\% & 0.395 &  &&  && & 180.5 \\
			\hline\hline
		\end{tabular}
		\end{small}
	\caption{Model relevance and Latency Under Different Search Settings with Retrieval Depth 1000
%For quantization methods on top of ColBERT, we also report \% degradation from ColBERT.
}
	\label{tab:main1k}
\end{table*}
}
\comment{
\begin{table*}[htbp]
	\centering
		\begin{small}
		\begin{tabular}{ r r r | r r | r r | r}
			\hline\hline
			& \multicolumn{2}{c|}{MSMARCO Dev} & \multicolumn{2}{c|}{DL19 } & 
\multicolumn{2}{c}{DL20} & Latency   \\
			& MRR@10 & R@10 & NDCG@10 & R@10 & NDCG@10 & R@10  & ms \\
			\hline
              \multicolumn{8}{l}{\it S: BM25-T5-B, D: SimLM}  \\
            S & 0.259 &  0.514  & 0.578 &  & 0.588 &      &  \\
              S $+$ flat-D  &0.411 & 0.686 & 0.724 & 0.171 & 0.730 & 0.246 & \\
             S $+$  rerank-D &  0.354 & 0.514 & 0.622 & 0.152 & 0.630 & 0.209 & \\
             S $+$  rerank-D-itp &0.355 & 0.514 & 0.623 & 0.152 & 0.629 & 0.209 &  \\
           S $+$ LADR & 0.408 & 0.689 & & & & & \\
           S \textbf{ $+$ CS-D} & &&&&&&\\
           S \textbf{ $+$ CS-D + rrk10} &&&&&&&\\
           \multicolumn{8}{l}{\it S: BM25-T5-B, D: RetroMAE}  \\
     S $+$ flat-D  & 0.416 & 0.710 &   & & & & \\
           S $+$  rerank-D &  0.356 & 0.514 & &&&&  \\
             S $+$  rerank-D-itp &  0.356 & 0.514 & &&&& \\
            S \textbf{$+$ CS-D} & &&&&&&\\
            S  \textbf{$+$ CS-D $+$ rrk10} &&&&&&&\\
            \hline
            \multicolumn{8}{l}{\it  S: SPLADE-HT1, D: SimLM}  \\
            S & 0.396 & 0.514 &  0.732   &  & 0.721    &        &  \\
          S $+$ flat-D-itp  & 0.421 & 0.704 & 0.732 & 0.175 & 0.721 & 0.245 & 
\\
            S $+$ rerank-D &  0.410 & 0.674 & 0.733 & 0.175 & 0.726 & 0.245  &  \\
            S $+$ rerank-D-itp &  0.413 & 0.674 & 0.736 & 0.175 & 0.726 & 0.245 &   \\
            S $+$ LADR & 0.412 & & &&&& 2.2 \\
            \bf S $+$ CS-D &  0.418 &0.701&0.724&0.172&0.725&0.247 & \\
             \bf S $+$ QF-CS-D &  0.413 &0.695&0.729 &0.173&0.731&0.249&\\
            \bf S $+$ CS-D $+$  rrk10 & 0.418 & 0.703 & 0.722 & 0.173 & 0.710 & 0.228 &  \\
       \bf S $+$ QF-CS-D + rrk10 &  0.413 & 0.695 & 0.726 & 0.173 & 0.719 & 0.244 & \\
 \multicolumn{ 8}{l}{\it  S: SPLADE-HT1, D: RetroMAE}  \\
            S $+$ flat-D-itp  & 0.422 & 0.706 & &&&& \\
            S $+$ rerank-D &  0.412 & 0.674 &&&&&  \\
            S $+$ rerank-D-itp &  0.413 & 0.674 &&&&&  \\
            \bf $+$ CS-D &  0.418 & 0.701 &  &  &  & & \\
            \bf $+$ QF-CS-D &  0.413 & 0.695 &  &   & & & \\
           \bf $+$ CS-D $+$ rrk10 &  0.418 & 0.703 &  &  & &  & \\
            \bf $+$ QF-CS-D $+$ rrk10 &  0.413 & 0.695 &&&&& \\
            \hline
			\hline\hline
		\end{tabular}
		\end{small}
	\caption{Model relevance and Latency Under Different Search Settings with Retrieval Depth 10
%For quantization methods on top of ColBERT, we also report \% degradation from ColBERT.
}
	\label{tab:main10}
\end{table*}
}

\comment{
\begin{table*}[htbp]
	\centering
		\begin{tabular}{ r r r |r r  |r r  |r r}
			\hline\hline
			& \multicolumn{2}{c|}{MSMARCO Dev}& \multicolumn{2}{c|}{DL19}& 
\multicolumn{2}{c|}{DL20}& Latency  & Storage  \\
			& MRR@10 & R@1k & NDCG@10 & R@1k &  NDCG@10 & R@1k & ms & GB\\
			\hline
        \multicolumn{9}{c}{Time Budget = 70 ms}\\
        \hline
            D=SimLM & 0.411 & 0.985 & 0.714 & 0.767 &  0.697 & 0.773 & 1674.1 & 27.2 \\
          S=SPLADE-HT1 & 0.396 & 0.980 & 0.732   &  0.811 & 0.721    &  0.815  &   31.2 & 2.8 \\
           S $+$ rerank-D &  0.421 & 0.980 & 0.745 & 0.811 & 0.728 & 0.815 & 34.6 & 30.0 \\
             $\blacktriangle$  S $+$ D  & 0.424 & 0.989 & 0.740 & 0.767  & 0.726 & 0.773 & 1705.0 & 30.0 \\
              \hline
            D-IVF-6\% & 0.398  & 0.938 & 0.673 & 0.679 & 0.694 & 0.684 &  100.3& 27.2 \\
            D-OPQ-m32 & 0.314 & 0.957  & 0.619 & 0.671 & 0.608 & 0.683 & 109.1 & 0.3 \\
            D-IVFOPQ-m128-15\% & 0.397 & 0.965 & 0.699 & 0.708 & 0.699 &0.720 &102.4 & 1.2 \\
            D-HNSW & 0.409 & 0.978 & 0.669 & 0.722 & 0.695 & 0.760 & 127.8 & 36.4 \\
            %S $+$ rerank-D &  0.412 & 0.980    &0.715  & 0.811 & 0.698 & 0.815 & $+$2.3 \\
            S $+$ LADR & 0.423& 0.987 & 0.745 &  0.804&0.724  & 0.815 & 59.9& 34.3 \\
           S $+$ D-IVF-2\% & 0.398 & 0.987  & 0.674 & 0.816 & 0.720 & 0.813 & 70.2& 30.0 \\
           S $+$ D-IVFOPQ-m128-5\% & 0.407 & 0.987 & 0.717 & 0.820 & 0.733 & 0.817 &  70.8& 4.0 \\
             \bf S $+$ CS-D & 0.426& 0.987 & 0.744 & 0.823 & 0.724 & 0.819 &47.3& 45.6 \\
       \hline       
            %\multicolumn{9}{c}{Time Budget = 30 ms}\\
            %s=SPLADE-HT1-fast & 0.385 & 0.949 & 0.730& 0.806&  0.722&0.793& 22.4 & 3.0 \\
            %$\blacktriangle$  S + D & 0.416 & 0.986 & 0.743& 0.827&  0.724&0.830& 22.4 & 30.2  \\
            %S + rerank-D & 0.409 & 0.949 & & &  && 25.1 & 30.2 \\
            %D-HNSW & 0.403 & 0.965 & 0.675 & 0.723 & 0.694 & 0.752 & 34.3 & 36.4 \\
            %S $+$ LADR & 0.409 & 0.986 & \boldred{0.745} & \boldred{0.837} & \boldred{0.729} & \boldred{0.834} & 32.2 & 34.5 \\
            %\bf S $+$ CS-D & 0.415 & 0.982 & 0.725 & 0.816 & 0.733 & 0.828 & 32.1 & 30.2 \\
            %\hline
            \multicolumn{9}{c}{Time Budget = 30 ms}\\
            \hline
            s=SPLADE-effi-HT3 & 0.380 & 0.944 & 0.721 & 0.806 &  0.726 &0.790& 12.4 & 3.0 \\
             S + rerank-D & 0.406 & 0.944 & 0.728 &  0.806 & 0.738 & 0.790 & 15.1 & 30.2 \\
            $\blacktriangle$  S + D & 0.413 & 0.984 & 0.721 & 0.806 &0.729 & 0.824 & -- & 30.2  \\
            \hline
            D-HNSW & 0.403 & 0.965 & 0.675 & 0.723 & 0.694 & 0.752 & 34.3 & 36.4 \\
            S $+$ LADR & 0.404 & 0.984 & 0.728 & \boldred{0.838} &  \boldred{0.736} & \boldred{0.829} & 24.2 & 34.5 \\
            \bf S $+$ CS-D & 0.412 & 0.984 & 0.733 & 0.833 & 0.728 & 0.822 & 23.1 & 30.2 \\
			\hline\hline
		\end{tabular}
	\caption{Comparing Dense Options Under Time Budget 70 and 30 ms}
	\label{tab:main1k}
\end{table*}
}


\comments{\textbf{Query Selective Fusion}
For query selection model we plot the relevance against the \% of query used for Different Feature Options against random baseline in Table~\ref{tab:query_level}. For fair comparison, instead of using the same model prediction thresholds, we report the result where around 50\% of queries and 75\% of queries are evaluated. For queries using dense model, we calculate the fusion results. For queries without dense evaluation, we use the splade only ranked list. 

The row ``w/o Query Quality" refers to the model trained without query quality features. The row ``w/o Sparse vs Dense" refers to the model trained without features describing the distribution of sparse results in the dense clusters. 


\textbf{Cluster Selection Model}
For cluster selection model we plot the relevance against the \% of query used for different feature options against random baseline in Table~\ref{tab:cluster_feat}. In this table, we only report the dense evaluation without interpolation with SPLADE to get a clear picture on the performance differences. 

The row ``w/o Centroid Distance" refers to the model trained without inter centroid distance features. The row ``w/o Sparse vs. Dense" refers to the model trained without features describing the distribution of sparse results in the dense clusters. 

We also report the LSTM model trained with different length of input. We train a model that only consider top 64, 84, 128 or 256 top clusters. In the Time column, we report the model inference time with different input sequence length. Longer sequence with bigger candidate sets generally yield better performance.
}

\comment{
\begin{table*}[h]
	\centering
		%\resizebox{1.07\columnwidth}{!}{
		%\begin{small}
		\begin{tabular}{r r r r  |r r r llr }
			\hline\hline
                 &  & & &  \multicolumn{6}{c}{SPLADE-HT1+SimLM}\\
		    Dataset & \smaller{BM25} &\footnotesize{SimLM}  & \footnotesize{SPLADE-HT1} & \smaller{$\blacktriangle$ 
 flat} &  rrk &rrk-itp&  LADR&LADR-itp&{CS} \\
              \hline
              \multicolumn{10}{c}{Search Tasks}\\
                DBPedia	& 0.313	& 0.351 & 0.447	& 0.426 &  0.413 &0.442&  0.351&0.429&0.429\\
                FiQA &	0.236	& 0.298 & 0.355 & 0.355 &   0.335&0.355&  0.297&0.358&0.365\\
                NQ	& 0.329   & 0.502  &	0.550 & 0.568 &	  0.535&0.549&  0.503&0.568&0.568\\
                HotpotQA & 0.603 & 0.568 & \textbf{0.681} & 0.672 &   0.605&0.668&  0.569&0.674&0.672\\
                NFCorpus  & 0.325 & 0.318  & 0.351 & 0.353 &	  0.332&0.347&  0.319&0.352&0.360\\
                T-COVID	& 0.656 & 0.515  & 0.705 & 0.726 &  0.597&0.692&  0.533&0.732&0.745\\
                Torche-2020	& \textbf{0.367}  & 0.292  & 0.291 & 0.336 &   0.277&0.292&  0.292&0.335&0.333\\
                \hline
                \multicolumn{10}{c}{Semantic Relatedness Tasks}\\
                ArguAna & 0.315 & 0.376  & 0.446 & 0.481 &   0.388&0.427&  0.283&0.487&0.492\\
                C-FEVER	& 0.213 & 0.171  & 0.234 & \textbf{0.239} &   0.214&0.236&  0.173&0.243&0.241\\
                FEVER & 0.753  &0.689  &	\textbf{0.781} & 0.793 &   0.771&0.784&  0.692&0.796&0.794\\
                Quora & 0.789 & 0.797  &	0.817 &	0.847 &   0.801&0.816&  0.800&0.847&0.847\\
                SCIDOCS	& 0.158 &0.137  &	0.155 &	\textbf{0.165} &   0.138&0.152&  0.137&0.165&0.166\\
                SciFact	& 0.665 & 0.559  & \textbf{0.682} & 0.674 &   0.668&0.682&  0.559&0.675&0.694\\
                            \hline
                \textbf{Avg.} & 0.440 & 0.429  & 0.500 & 0.511 &    0.467&0.496&  0.424&0.512&0.516\\
                %\textbf{BM25 Diff} & -- & -2.6\%  &	13.6\% &17.7\% &  6.1\%&12.7\%&14.8\% &  \textbf{15.7\%} \\
                \textbf{SPLADE Diff} & -12.0 \% &  -14.2\%  &	-- & 2.2\% &  -6.6\%& -0.8\%&   -15.3\%&2.5\%&3.2\%\\
            \hline\hline
		\end{tabular}
		%\end{small}
		%}
%\vspace{-0.5em}
	\caption{Zero-shot performance (NDCG@10) on BEIR }
%For quantization approaches, we adopt M=16, K=256, i.e. compression rate 32$\times$ compared to ColBERT.
	\label{tab:zero-shot}
\vspace{-1em}
\end{table*}

}

\comment{
\textbf{In-domain Data, Different Sparse Model}
\begin{table}
  \begin{tabular}{ r r r r r }
			\hline\hline
	          & \multicolumn{2}{c}{Zero-shot} & \multicolumn{2}{c}{Trained} \\
			& MRR@10 & R@10 & MRR@10 & R@10\\
              \hline
             \multicolumn{5}{c}{Splade-HT1-fast} \\
             S $+$ QF & 0.410 & 0.981 & 0.412  & 0.976 \\ %0.3 / 0.1, % = 0.730
             CS-D & & &  & \\ %0.1, 4.7 cluster
             S $+$ CS-D & & & 0.415 & 0.981 \\
             S $+$ QF-CS-D & & & 0.410 & 0.972 \\
             \multicolumn{5}{c}{Splade-effi-HT3} \\
             S $+$ QF & 0.407 & 0.977 & 0.407 & 0.975 \\%0.05, %0.79
             CS-D & & & & \\
             S $+$ CS-D & & & 0.411 & 0.978\\ % 
             S $+$ QF-CS-D & & & 0.406 & 0.969\\ 
             \multicolumn{5}{c}{BM25-T5} \\
             CS-D & & & 0.403 & 0.927 \\ %0.1, 5.6
             S $+$ CS-D & & & 0.406 & 0.967 \\
              \hline\hline
		\end{tabular}
	\caption{S $+$ D relevance using partial queries evaluated by D.}
	\label{tab:zero-shot}
\end{table}
}


\comments{
\begin{table}
      \begin{tabular}{ r r r r r  }
			\hline\hline
			\% Queries Kept & \multicolumn{2}{c}{50\%} & \multicolumn{2}{c}{75\%} \\
			& MRR@10 & R@10 & MRR@10 & R@10\\
              \hline
             \multicolumn{5}{l}{\it{Feature Group Removal}}\\
             default & 0.417 & 0.702 & 0.422 & 0.709 \\
             w/o Sparse vs. Dense & 0.413 & 0.697 & 0.419 & 0.706 \\
 w/t sparse/dense score& 0.414& 0.700& 0.420&0.706\\
 w/t sparse/dense number& 0.416& 0.704& 0.421&0.708\\ %0.0.2
             w/o Query Quality& 0.414 & 0.700 & 0.422& 0.707 \\ % 0.0.1
             Random Removal & 0.411 & 0.693 & 0.418 &0.700 \\
              \hline\hline
		\end{tabular}
	\caption{S $+$ D relevance using partial queries evaluated by D.}
	\label{tab:query_level}
\end{table}
}
\comments{
\subsection{Effect of Merging}




\subsection{Feature List Query-level Model}

We compute the following features based on the orginal query and its expanded query using a sparse retriever's  encoder. 
When computing the embedding of each token or the original query, we use the denser retriever's encoder. 
\begin{enumerate}
    \item The length of the original query and the expanded query in terms of  the  number of words or tokens, respectively. 
    \item The token-based similarity between the expanded query and the original query. 
For each query token in the expanded query, we evaluate the similarity between its token embedding and  the oringal query embedding. 
Based on their similarity to the query, we map these tokens into five bins with  ranges <0.5, 0.5-0.6, 0.6-0.7, 0.7-0.8, >0.8.
We derive a similarity count vector after this mapping?
    \item The matching score of the whole query.??? The similarity between the CLS embeddings of the orginal query and the expanded query.
    \item The sum of matching scores of a token group/  The matching score of whole query. The token groups are the tokens with similarities in each bin.
    \item The sum of matching scores of tokens not in NLTK english corpus /  The matching score of whole query. 
    \item number of overlapping tokens between expanded and original query / number of all unique queries in both expanded and original query.
    \item number of  tokens only in expanded query / number of all unique queries in both expanded and original query.
    \item overall/mean/max of token weight of overlapping tokens between expanded and original query in the expanded query.
    \item max/min/mean of token weights of expanded query tokens.
\end{enumerate}

Sparse Matching score distribution:
\begin{enumerate}
    \item sparse scores of top 1-10 results
    \item mean sparse score of top 10-20/20-30/30-40/40-50/50-100/100-400/400-700/700-1000 documents.
\end{enumerate}


Sparse and Dense relational features:
\begin{enumerate}
    \item The number of dense clusters containing top 5/10/20/50/100/1000 results from sparse system
\end{enumerate}


\subsection{Feature List for Each Centroid in Cluster-Select Model}

\begin{enumerate}
    \item query-centroid similarities
    \item the distance between this centroid and the other top k centroids for this query (k=128)
    \item mean distance between this centroid and the rest of centroids (top 129+)
    \item Number of clusters containing top 10/25/50/100/200/500/1k documents in the sparse results
    \item mean sparse scores of top 10/25/50/100/200/500/1k documents 
\end{enumerate}

\begin{table}[ht]
    \centering
    \resizebox{1.05\columnwidth}{!}{

    \begin{tabular}{l |l}
        \hline
    Query    & "what is mechanical advantages in science terms"\\
    \hline
Relevance Doc & ["mechanical", 414.8], ["advantage", 226.3], ["advantages", 163.9], ["benefit", 97.9], \\
& ["definition", 82.2], [",", 64.1], ["is", 43.1], ["purpose", 15.5]  \\
Top 5 Doc & ["mechanical", 423.1], ["advantage", 228.9], ["advantages", 170.0], ["benefit", 95.3], \\
& ["definition", 83.4], [",", 65.0], ["is", 45.4], ["science", 24.6], ["purpose", 23.5], \\
& ["scientific", 15.0] \\
        \hline
    \end{tabular}
    }
\caption{Splade Expansion Example on Query Quality}
\label{tab:example}
\end{table}

\subsection{How to combine two ranked list}
There are two commonly used method to combine the sparse and dense ranked lists:
\begin{enumerate}
    \item linear combination
    \item reciprocal rank fusion
\end{enumerate}
For linear combination, the final ranking score of a document is the weighted sum of the ranking score of two systems perspectively. The weight on each system can be determined through grid search on a left-out training set or just use 1:1 combination. In this case, rescaling of the two ranked lists are necessary as the it largely affects the impact of a ranked list to the merged ranked list. 

On the other hand, reciprocal rank fusion alleviate the scoring distribution difference by only considering the ranking positions when merging. 

Another consideration is on the missing values. The two ranked lists are usually not fully overlap. Some documents only exists in one ranked lists. Thus the treatment on these documents affects model performance. We consider a few options
\begin{enumerate}
    \item Remove the documents when they only exist in one ranked list
    \item  Take the document and compute the score for only one ranked list
    \item Impute the missing document with rank K+1 or score as 0.95 * min(score) in the ranked list.
\end{enumerate}
}

