%\vspace*{-5mm}
%\subsection{Fast search with minimized space overhead}



\begin{table*}[htbp]

	\centering
     \caption{
    Cluster-based in-memory search  with and without space constraints
%    For MSMARCO Dev set, $^\dag$ is tagged when statistically significant drop is observed from the oracle $\blacktriangle$ at 95\% confidence level. 
    }
\label{tab:compare} 
		\resizebox{0.85\columnwidth}{!}{
		\begin{tabular}{  r| l  |llll l|r}
			\hline\hline
			  & 
%& \multicolumn{2}{c}{ {\bf MSMARCO Dev} }& {\bf DL19}& {\bf DL20} & {\bf BEIR} 
& \multicolumn{2}{c} { {\bf MSMARCO Dev} }& {\bf DL19}& {\bf DL20} & {\bf BEIR} 
& {\bf  Latency}    \\
			 &\% D
%& {MRR@10}& R@1K& {NDCG@10}&  {NDCG@10}& {NDCG@10}
& {MRR@10}& {R@1K}& {NDCG@10}&{NDCG@10}& {NDCG@10}& ms \\
%    \hline
%  S={\bf SPLADE-HT1} & --& 0.396& 0.980 & 0.732   & 0.721    & 0.500 & -- & --& --& --& --&31.2  \\
%& 
%	%& \multicolumn{5}{c|}{D=\textbf{SimLM}}
%& \multicolumn{5}{c|}{D=\textbf{RetroMAE}}&\\
   \hline

    \multicolumn{2}{c}{}
  & \multicolumn{5}{c}{\bf{Uncompressed flat setting. Embedding space  27.2GB}}\\
     \hline
 D=RetroMAE  & 100 
%& 0.411$^\dag$ & 0.985$^\dag$& 0.714 &  0.697  & 0.429 
& 0.416$^\dag$& 0.988& 0.720&0.703& 0.482 & 1674.1 \\
$\blacktriangle$ S $+$ D   &100 
%& 0.424 & 0.989 & 0.740 & 0.726  & 0.518 
& 0.425& 0.988& 0.740&0731& 0.520~&  1705.3 \\
  S $+$ CDFS &0.45
& 0.424& 0.987& --&-- & 0.517 & 46.0 \\
%  S $+$ Rerank &0.01 %& 0.421& 0.980& 0.745&0.728 & 0.483 &34.6 \\this row is for SimLM
  {\bf S $+$ CluSD} &0.3
%& 0.425 & 0.987 & 0.744 & 0.724  & 0.516 
& 0.426& 0.987& 0.744&0.734 & 0.518 & 44.4 \\
              \hline
    \multicolumn{2}{c}{} &
\multicolumn{5}{c}{\bf{OPQ $m=128$. Embedding space  1.1GB}}\\
              \hline
 $\blacktriangle$  S $+$ D-OPQ &100 
%& 0.420 & 0.988 & 0.735 &  0.719  & 0.508 
& 0.416 & 0.988 & 0.737 & 0.732 & 0.515& 600.1 \\
S$+$D-IVF &10
%& 0.414$^\dag$& 0.987 & 0.726 & 0.734  & 0.505 
& 0.404$^\dag$& 0.987& 0.713&0.722& 0.513 &  126.4 \\
S$+$D-IVF 
&5
%& 0.407$^\dag$& 0.987 & 0.717 & 0.733  & 0.499  
& 0.394$^\dag$& 0.987& 0.687&0.706&0.507&  80.0 \\
%D-IVF &2 & 0.370$^\dag$& 0.869$^\dag$& &&  & 13.7 \\
S$+$D-IVF 
&2
%& 0.392$^\dag$& 0.986$^\dag$& 0.691 & 0.738  & 0.467 
& 0.374$^\dag$& 0.986 & 0.656&0.700& 0.499 & 52.5 \\
            S$+$CDFS  &0.45& 0.415 & 0.986 & 0.740& 0.730 &- & 43.3 \\
 \textbf{S $+$ CluSD}  &0.3
%& 0.423 & 0.987 & 0.739& 0.725 &0.514 
& 0.417& 0.986& 0.742&0.735& 0.514  & 42.6  \\
             \hline
\comments{
    \multicolumn{2}{c}{} &
             \multicolumn{6}{c}{\bf{DistillVQ $m=128$. Embedding space  1.38GB}}\\
\hline
IVF  & 2  & 0.365$^\dag$ &     0.899$^\dag$ &  --& -- & -- &  20.8ms\\
CluSD & 0.3 & 0.393 &  0.977&  --&  -- & --&  9.7ms\\
S+ IVF & 2    &0.392$^\dag$ & 0.987&--&  -- & --&   52.0ms\\
S+CluSD &0.3 &   0.417 &        0.987 & --& -- & -- & 40.9 ms\\
\hline

             \hline
            & & \multicolumn{10}{c}{\bf{OPQ $m=64$. Embedding space 0.6GB}}\\
            \hline
           $\blacktriangle$  S $+$ D-OPQ  &100 & 0.409 & 0.986 & 0.718 &  0.721  &0.501 & 0.402 & 0.986 & 0.717 &  0.719 & 0.508 & 321.6 \\
           S$+$D-IVFOPQ &10& 0.405 & 0.986 & 0.716 & 0.734 & 0.502 & 0.393$^\dag$& 0.986& 0.676&0.730& 0.505& 75.6 \\
           &5& 0.397$^\dag$& 0.986 & 0.704 & 0.733  & 0.497 & 0.384$^\dag$& 0.985& 0.659&0.717& 0.500& 55.0 \\ 
            &2& 0.383$^\dag$& 0.985 & 0.680 & 0.738 & 0.487 & 0.368$^\dag$& 0.985 & 0.643&0.707& 0.493 & 42.4 \\
            \textbf{S $+$ CluSD}  &0.3& 0.414 & 0.986 & 0.743& 0.726 & 0.511 & 0.403 & 0.987& 0.729&0.724 & 0.506 & 40.8 \\

}
              \hline\hline
		\end{tabular}

		}
   \vspace*{-5mm}
\end{table*}

%\subsection{Cluster-based search with in-memory data}
%{\bf Cluster-based search with in-memory data}.
{\bf Cluster-based retrieval with in-memory data}.
%\subsection{CluSD vs. IVF  cluster search}
%\textbf{CluSD vs. IVF  cluster search}.
%\label{sect:eval0space}
Table~\ref{tab:compare} compares CluSD with a few baselines for cluster-based selective retrieval 
in searching MS MARCO and BEIR datasets with and without compression.  
%SPLADE-HT1 is  the sparse model, and two dense models used are SimLM and 
The dense model is RetroMAE and sparse model is SPLADE-HT1.
%We compare our models on uncompressed embeddings, as well as two quantization configurations.
%There are the uncompressed setting and  two quantization  configurations. 
%The sparse model used is SPLADE-HT1 while the dense models are SimLM and RetroMAE.
%IVFOPQ is compared against CluSD as it selects only top clusters and does not incur extra space overhead. 
%The top portion of this table reports the performance when compression is not used, which captures a peak possible performance.
%Compression uses  OPQ quantization  from FAISS.
IVFOPQ uses a proportion of top dense clusters sorted by the query-centroid distance.
%IVFOPQ is compared, which use some percentage of top dense clusters sorted by query to centroid clusters.
%against CluSD as it selects only top clusters and does not incur extra space overhead.
OPQ quantization from FAISS is configured with  the number of codebooks as $m=$ 128 or 64.
We report performance of IVF clustering using the top 10\%, 5\%, or 2\% clusters respectively.
%as a standard approach which performs   limited top cluster retrieval.
%CluSD execution is also based on the the same OPQ or  IVFOPQ index from  FAISS, but clusters are  selected  by our two step algorithm.
The notation ``S+D'' in Table~\ref{tab:compare} (and later in other tables)
reports the fused performance of a sparse model 
%and a full search of uncompressed dense model 
with linear interpolation.
Marker  ``\%D'' means the approximate percentage of document embeddings  evaluated based on the number of clusters selected.
The last column marked with  ``Latency'' is the mean single-query time for MS MARCO Dev set.
%We only report SimLM latency because the latency of RetroMAE is similar.
%When    prefix `+' is marked for a latency entry, it indicates  the extra milliseconds is spent for full or selective dense retrieval without counting   sparse retrieval time.
CluSD uses setting  $N=8192$ and 
$n=32$,
% Tables~\ref{tab:mainspace} and~\ref{tab:maintime} use
which results in  selection of 22.3 clusters on average per query
and allows CluSD to meet  the latency requirement.
%The main space cost for CluSD is to maintain the inter-cluster similar graph, which 
%takes about 32MB with quantization for $N=8192$. 
%Switching a quantization different  from OPQ  is might result in an improvement in relevance, but it is orthogonal to our proposal.
%The reported CluSD performance on the flat index uses the exact same IVF index.
% for CluSD uses on average 20-25 (0.25 - 0.3\%) clusters per query.
%For re-ranking, we report the results of re-ranking top 1000 results from the sparse model using the dense model.
%The mean latency and 99 percentile latency of CluSD are 13.2 ms and 18.1 ms for searching uncompressed flat index, respectively;
%11.4 ms and 14.6ms for searching OPQ m=128 index;  9.6 ms and 11.1ms for searching OPQ m=128 index.
The results in Table~\ref{tab:compare} shows that 
under the same time budget, CluSD outperforms partial dense retrieval with IVF search in relevance.
%CDFS's number is copied from ~\cite{2024SIGIR-CDFS-Yang} and CluSD  performs slightly better than CDFS. 
Additionally, CluSD performs slightly better than CDFS in terms of both relevance and latency because CluSD's LSTM effectively selects less clusters to search than CDFS.
% \vspace*{-5mm}
 
%and  delivers similar or higher relevance than methods that rely upon
%a document-level proximity graph, such as LADR and HNSW, with negligible extra space overhead.
%Simple reranking does surprisingly well if sparse results are strong. 
%But as stated in~\cite{2022CIKM-MacAvaneyGraphReRank,2023SIGIR-LADR},
%when the sparse retriever doesn’t achieve high relevance, reranking is too restrictive. 
%CluSD’s advantage becomes more significant in zero-shot retrieval with BEIR datasets. CluSD’s average NDCG number is 
%7.2\% higher than reranking with RetroMAE. 





\comments{
Rows 6 and 11 of Table ~\ref{tab:mainspace} 
 show that selective IVF cluster search using  query-centroid distances 
can be under 130ms  when the percentage of clusters searched  drops from 100\% to 10\%. But the relevance drop is significant.  
Moreover, CluSD is as  fast as IVFOPQ  top 2\% search at m=64 (Row 14 vs. Row 13) and 2x fast at m=128 while
its relevance is much higher (Row 9 vs. Row 8).
%CluSD  performs  closely as the oracle at each compression setting, which
There is no statistically significant difference between CluSD and the oracle at each compression setting, which 
indicates CluSD effectively minimizes visitation of unnecessary  dense clusters. 
}
 









%For pipelines with a time budget, we report the additional overhead in the Storage (GB) column. 
%\vspace*{-5mm}

%\subsection{CluSD vs. graph navigation and re-ranking} 
\textbf{CluSD vs. graph navigation}. 
%\label{sect:evaltimebudget}
Table~\ref{tab:maintime} compares  CluSD with  selective dense retrieval based on proximity graph navigation
including HNSW and LADR under time budget around 50ms.
HNSW's expansion factor parameter (ef) is set as 1024. 
%2048 for S$+$HNSW and HNSW. 
%Under 25ms time constraint, the expansion factor (ef) is  512 and  1024 respectively. 
%We include option ``S+Re-rank" which uses the top 1,000 sparse retrieval results and only compute dense scores of these top results, and merge the score with an interpolation.
%For HNSW, we fix the number of neighbors to be 128 and vary the expansion factor(ef) to meet the latency constraint.
For LADR, we use its default setting with seed = 200, number of neighbors = 128 and use an exploration depth of 50 to meet the latency budget.
%Table~\ref{tab:maintime}.
The takeaway from this table is that  relevance of CluSD is better than HNSW 
while CluSD has similar or slightly better relevance without incurring  significant  extra
space cost, compared to LADR.
When the time budget is around 25ms, the takeaway is similar.
%Simple reranking ``D-rerank'' achieves good MRR@10 but under-performs on recall.




 



\begin{table*}[htbp]
\vspace*{-5mm}
        \centering
        \caption{CluSD vs. graph navigation methods 
% under time budget but  no memory constraints 
}
 \resizebox{0.7\columnwidth}{!}{
		\begin{tabular}{r |ll|l|l|rr}
			\hline\hline
			& \multicolumn{2}{|c|}{\bf{MSMARCO Dev}}& \bf{DL19}& 
\bf{DL20}& \bf{Latency}& \bf{Space}\\
			 & {MRR@10}& {R@1K}& \small{NDCG} &   \small{NDCG} & Total(ms)& GB\\
			\hline
        \multicolumn{7}{c}{\bf{Time Budget = 50 ms, S=SPLADE-HT1}}\\
        \hline
            D=SimLM & 0.411$^\dag$ & 0.985$^\dag$& 0.714 &  0.697 & 1674.1 & 27.2 \\
          S& 0.396$^\dag$& 0.980$^\dag$& 0.732   & 0.721    &   31.2 & 3.9 \\
%           S $+$ D-rerank &  0.421 & 0.980$^\dag$& 0.745 & 0.728 & 34.6 & 31.1 \\
             $\blacktriangle$  S $+$ D  & 0.424 & 0.989 & 0.740 & 0.726 & 1705.0 & 31.1 \\
              \hline
              % D-IVF & 0.398$^\dag$& 0.935$^\dag$& 0.690 & 0.693 & 81.4 & $+$0.0\\
%            D-IVF & 0.389$^\dag$& 0.907$^\dag$& 0.671 & 0.676 & 49.5 & $+\sim$0\\
%            S $+$ D-IVF & 0.393$^\dag$& 0.987  & 0.678 & 0.715 & 56.5 & $+\sim$0\\
            %D-OPQ& 0.314$^\dag$& 0.957$^\dag$& 0.619 & 0.608 & 109.1 & 0.3 \\
           % D-IVFOPQ & 0.386$^\dag$& 0.929$^\dag$& 0.680 & 0.697 & 48.8 & 1.2\\
             HNSW & 0.409$^\dag$& 0.978$^\dag$& 0.669 & 0.695 & 54.4 & 40.3 \\
           S $+$ HNSW & 0.420 & 0.987 & 0.718 & 0.723 & 59.6 & 40.3 \\
            %S $+$ rerank-D &  0.412 & 0.980    &0.715  &  0.698 & 0.815 & $+$2.3 \\
            S $+$ LADR & 0.422 & 0.984$^\dag$& 0.743&0.728& 43.6& 35.4\\
%           7.1 &  S $+$ D-LADR & 0.423 & 0.987$^\dag$& 0.745 &0.728& 53.0 & $+$4.3\\
           % S $+$ D-IVF & 0.398$^\dag$& 0.987  & 0.674 & 0.720 & 64.7 & $+$0.0\\
           %S $+$ D-IVFOPQ & 0.392$^\dag$& 0.987 & 0.656 & 0.700 &  52.5 & 4.0\\
            \bf S $+$ CluSD & 0.426 & 0.987 & 0.744 & 0.724 &46.3& 31.1\\
			\hline\hline
		\end{tabular}  }
	\label{tab:maintime}
 \vspace*{-5mm}
\end{table*}
%For pipelines with a time budget, we report the additional overhead in the Storage (GB) column. 

%\subsection{CluSD vs. graph navigation and re-ranking} 

\comments{
\textbf{CluSD vs. graph navigation}. 
%\label{sect:evaltimebudget}
Table~\ref{tab:maintime} compares  CluSD with  selective dense retrieval based on proximity graph navigation
including HNSW and LADR under time budget around 50ms with dense model SimLM.
For HNSW, we set its expansion factor parameter (ef) as 1024, 
%2048 for S$+$HNSW and HNSW. 
%Under 25ms time constraint, the expansion factor (ef) is  512 and  1024 respectively. 
%We include option ``S+Re-rank" which uses the top 1,000 sparse retrieval results and only compute dense scores of these top results, and merge the score with an interpolation.
%For HNSW, we fix the number of neighbors to be 128 and vary the expansion factor(ef) to meet the latency constraint.
For LADR, we use its default setting with seed = 200, number of neighbors = 128 and use an exploration depth of 50 to meet the latency budget.
%Table~\ref{tab:maintime}.
The takeaways from this table is that 
CluSD has similar relevance as graph navigation without incurring  significant  extra
space cost, compared to HNSW and LADR.
%Simple reranking ``D-rerank'' achieves good MRR@10 but under-performs on recall.
}
