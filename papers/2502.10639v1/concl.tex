%\section{Limitations and Future Work}
\section{Concluding Remarks}

The contribution of this work is a cluster-based dense retrieval selection scheme  
to augment sparse retrieval with minimal space overhead and a small amount of extra latency  time.
CluSD optimizes an LSTM based model with cluster prioritization and pruning
to effectively identify  a small number of clusters that can supplement and boost  sparse retrieval. 
With this lightweight low-cost design,  
CluSD can deliver a strong in-domain and out-of-domain relevance  efficiently when searching  MS MARCO and BEIR datasets
on a CPU only server. %even though the sparse retriever used has its relevance tradeoff under a time efficiency constraint.
For example, CluSD delivers 0.423 MRR@10  for searching 8.8M MS MARCO passages 
with 11.4ms  latency and  1.13GB space mainly for compressed dense embeddings, to augment sparse retrieval under
a fraction of its  cost. The same  CluSD version  reaches  0.514 average NDCG@10 for BEIR with compression.

Compared to other baselines, the main advantage of CluSD is its capability in delivering the similar 
%or higher
relevance under the same time budget
with negligible extra space overhead. It is attractive to run such an algorithm on a first-stage retrieval low-cost machine
%to host  as many documents as possible and 
that can  significantly reduce the overall infrastructure cost when scaling  data size and  search traffic. 


Our evaluation uses OPQ in FAISS to compress embeddings. 
Switching to a different quantization affects the compression ratio and  the relevance outcome.  
However, we expect that our findings remain similar because  the recent  quantization 
methods~\cite{2021CIKM-JPQ-Zhan,  2022WSDM-Zhan-RepCONC, Xiao2022Distill-VQ}
also have  a significant relevance drop pattern when the compression ratio increases.
%A limitation of the current  CluSD work is that the training of the LSTM model has a dependence on the sparse retrieval model used. 
While  CluSD can  boost the relevance of a weaker sparse retriever model such as BM25, the augmented relevance still has not reached a level
comparable  to the one where CluSD is coupled with a stronger sparse retriever. There is room for improvement in future work.

%the dependency on a training dataset. Unlike rule-based or unsupervised pipelines, our pipeline requires labeled data on at least one search task. However, the number of queries with labels is not large and a trained model is robust on never-seen corpus and tasks. 
%
%Another limitation is the dependency on the sparse retrieval model performance. CluSD benefit from a good sparse retrieval top results. When using a BM25 based retrieval, the quality of the clusters selected degrades slightly. 
