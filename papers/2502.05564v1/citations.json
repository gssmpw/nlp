[
  {
    "index": 0,
    "papers": [
      {
        "key": "xieExplanationIncontextLearning2022",
        "author": "Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu",
        "title": "An {{Explanation}} of {{In-context Learning}} as {{Implicit Bayesian Inference}}"
      },
      {
        "key": "mullerTransformersCanBayesian2024",
        "author": "M{\\\"u}ller, Samuel and Hollmann, Noah and Arango, Sebastian Pineda and Grabocka, Josif and Hutter, Frank",
        "title": "Transformers {{Can Do Bayesian Inference}}"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "vonoswaldTransformersLearnIncontext2023",
        "author": "{von Oswald}, Johannes and Niklasson, Eyvind and Randazzo, Ettore and Sacramento, Jo{\\~a}o and Mordvintsev, Alexander and Zhmoginov, Andrey and Vladymyrov, Max",
        "title": "Transformers Learn In-Context by Gradient Descent"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "gargWhatCanTransformers2023",
        "author": "Garg, Shivam and Tsipras, Dimitris and Liang, Percy and Valiant, Gregory",
        "title": "What {{Can Transformers Learn In-Context}}? {{A Case Study}} of {{Simple Function Classes}}"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "chenXGBoostScalableTree2016a",
        "author": "Chen, Tianqi and Guestrin, Carlos",
        "title": "{{XGBoost}}: {{A Scalable Tree Boosting System}}"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "yeModernNeighborhoodComponents2024",
        "author": "Ye, Han-Jia and Yin, Huai-Hong and Zhan, De-Chuan",
        "title": "Modern {{Neighborhood Components Analysis}}: {{A Deep Tabular Baseline Two Decades Later}}"
      },
      {
        "key": "gorishniyTabMAdvancingTabular2024",
        "author": "Gorishniy, Yury and Kotelnikov, Akim and Babenko, Artem",
        "title": "{{TabM}}: {{Advancing Tabular Deep Learning}} with {{Parameter-Efficient Ensembling}}"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "zhuXTabCrosstablePretraining2023",
        "author": "Zhu, Bingzhao and Shi, Xingjian and Erickson, Nick and Li, Mu and Karypis, George and Shoaran, Mahsa",
        "title": "{{XTab}}: {{Cross-table Pretraining}} for {{Tabular Transformers}}"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kimCARTEPretrainingTransfer2024",
        "author": "Kim, Myung Jun and Grinsztajn, L{\\'e}o and Varoquaux, Ga{\\\"e}l",
        "title": "{{CARTE}}: {{Pretraining}} and {{Transfer}} for {{Tabular Learning}}"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "maInContextDataDistillation2024",
        "author": "Ma, Junwei and Thomas, Valentin and Yu, Guangwei and Caterini, Anthony",
        "title": "In-{{Context Data Distillation}} with {{TabPFN}}"
      },
      {
        "key": "feuerTuneTablesContextOptimization2024",
        "author": "Feuer, Benjamin and Schirrmeister, Robin Tibor and Cherepanova, Valeriia and Hegde, Chinmay and Hutter, Frank and Goldblum, Micah and Cohen, Niv and White, Colin",
        "title": "{{TuneTables}}: {{Context Optimization}} for {{Scalable Prior-Data Fitted Networks}}"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "xuMixtureInContextPrompters2024",
        "author": "Xu, Derek and Cirit, Olcay and Asadi, Reza and Sun, Yizhou and Wang, Wei",
        "title": "Mixture of {{In-Context Prompters}} for {{Tabular PFNs}}"
      },
      {
        "key": "thomasRetrievalFineTuningInContext2024",
        "author": "Thomas, Valentin and Ma, Junwei and Hosseinzadeh, Rasa and Golestan, Keyvan and Yu, Guangwei and Volkovs, Maksims and Caterini, Anthony",
        "title": "Retrieval \\& {{Fine-Tuning}} for {{In-Context Tabular Models}}"
      },
      {
        "key": "koshilLocalizationDataEmbedding",
        "author": "Koshil, Mykhailo and Nagler, Thomas and Feurer, Matthias and Eggensperger, Katharina",
        "title": "Towards {{Localization}} via {{Data Embedding}} for {{TabPFN}}"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "zeng2024tabflex",
        "author": "Zeng, Yuchen and Kang, Wonjun and Mueller, Andreas C",
        "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "mullerMotherNetFoundationalHypernetwork2023",
        "author": "M{\\\"u}ller, Andreas and Curino, Carlo and Ramakrishnan, Raghu",
        "title": "{{MotherNet}}: {{A Foundational Hypernetwork}} for {{Tabular Classification}}"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "breejenWhyInContextLearning2024",
        "author": "den Breejen, Felix and Bae, Sangmin and Cha, Stephen and Yun, Se-Young",
        "title": "Why {{In-Context Learning Transformers}} Are {{Tabular Data Classifiers}}"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "maTabDPTScalingTabular2024",
        "author": "Ma, Junwei and Thomas, Valentin and Hosseinzadeh, Rasa and Kamkari, Hamidreza and Labach, Alex and Cresswell, Jesse C. and Golestan, Keyvan and Yu, Guangwei and Volkovs, Maksims and Caterini, Anthony L.",
        "title": "{{TabDPT}}: {{Scaling Tabular Foundation Models}}"
      }
    ]
  }
]