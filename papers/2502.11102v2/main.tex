\documentclass[11pt,twocolumn]{article}
\usepackage{titlesec}

% 调整 section 和 subsection 的字体大小
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}   % large 字体，加粗
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}   % normalsize 字体，加粗
% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{longtable}
% \usepackage[a4paper,twocolumn,width=21cm,columnsep=1cm,top=2cm,bottom=2cm]{geometry}
% \setlength {\marginparwidth }{2cm}
% 最大可用宽度组合（栏宽10.5cm）
\usepackage[a4paper,
            twocolumn,
            left=0cm,          % 左边距设为0
            right=0cm,         % 右边距设为0
            columnsep=0.8cm,   % 栏间距减少
            top=2cm,
            bottom=2cm]{geometry}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2025} with \usepackage[nohyperref]{icml2025} above.
\usepackage{hyperref}
\usepackage{silence}
\WarningFilter{hyperref}{}

\graphicspath{{figure/}}
% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
% \usepackage{icml2025}
% \usepackage[preprint]{icml2025}

% If accepted, instead use the following line for the camera-ready submission:
% \usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
% \usepackage[textsize=tiny]{todonotes}



% 新增
\usepackage{inputenc}
%\usepackage[most]{tcolorbox} % 加载 tcolorbox 包并启用大部分功能
\usepackage[listings,breakable,skins]{tcolorbox}
% 定义新的列表环境，接受一个必选参数(标题)
\newtcblisting{prompttemplate}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,
  listing only,
  listing options={
    basicstyle=\ttfamily,
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
\newtcolorbox{metadata}[1]{%
  title={#1},                 % 标题设置
  breakable,                  % 支持内容分页
  colframe=gray!50!black, % 边框为灰黑色
  colback=white,          % 背景为纯白
  coltitle=white,         % 标题文字白色，增强对比度
  boxrule=0.5mm,              % 边框宽度
  % 设置正文部分的字体样式等
  before upper={% 上方内容格式
    \ttfamily                % 设置等宽字体
    \setlength{\parindent}{0pt} % 禁用段落首行缩进
    \setlength{\parskip}{4pt plus 1pt} % 设置段落间距
  }
}
% 定义代码样式
% \lstdefinestyle{codestyle}{
%     language=Python,                   % 指定语言为 Python
%     basicstyle=\ttfamily\footnotesize, % 使用小号等宽字体
%     breaklines=true,                   % 启用自动换行
%     breakatwhitespace=false,           % 不仅在空格处换行
%     columns=fullflexible,              % 灵活调整字符间距
%     keepspaces=true,                   % 保留缩进中的空格
%     tabsize=4,                         % 缩进4个空格
%     captionpos=b,                      % 标题位于底部
%     showstringspaces=false,            % 不显示字符串中的空格
%     keywordstyle=\color{blue},         % 关键字颜色
%     commentstyle=\color{green!50!black}, % 注释颜色
%     stringstyle=\color{red!60!black}  % 字符串颜色

% }
\lstdefinestyle{codestyle}{
    language=Python,                   
    basicstyle=\ttfamily\footnotesize, 
    breaklines=true,                   
    breakatwhitespace=false,           
    columns=fullflexible,              
    keepspaces=true,                   
    tabsize=4,                         
    captionpos=b,                      
    showstringspaces=false,            
    keywordstyle=\color{blue},         
    commentstyle=\color{green!50!black}, 
    stringstyle=\color{red!60!black},  
    backgroundcolor=\color{white},     % 设置背景为白色
    numbers=left,                      % 如果需要行号
    numberstyle=\tiny\color{gray},     % 行号样式
    xleftmargin=2em,                   % 左边距
    framexleftmargin=1.5em,           % 行号和代码之间的距离
}


% tcolorbox 配置
\tcbuselibrary{listings, breakable}
\newtcblisting{pythoncode}[1]{%
    title={#1},
    listing only,
    breakable,                         % 启用分页
    colframe=gray!50!black, % 边框为灰黑色
  colback=white,          % 背景为纯白
  coltitle=white,         % 标题文字白色，增强对比度
    listing options={style=codestyle} % 引用已定义的代码风格
}
%%%%% test
% 定义一个简洁清新风格的列表环境
\newtcblisting{prompttemplateGreen}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,
  colframe=green!70!black, % 边框颜色
  colback=green!5!white,   % 背景颜色
  coltitle=black,         % 标题设为黑色增加对比
  fonttitle=\bfseries,    % 标题加粗
  listing only,
  listing options={
    basicstyle=\ttfamily\small, % 小型的等宽字体
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
% 定义一个现代灰风格（类似浅灰模式）
\newtcblisting{prompttemplateModernGray}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,
  colframe=gray!50!black, % 边框颜色
  colback=gray!10!white, % 背景颜色
  coltitle=white,         % 标题设为白色增加对比
  fonttitle=\bfseries,     % 标题加粗
  listing only,
  listing options={
    basicstyle=\ttfamily\small, % 小型的等宽字体
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
\newtcblisting{prompttemplateWhite}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,
  colframe=gray!50!black, % 边框为灰黑色
  colback=white,          % 背景为纯白
  coltitle=white,         % 标题文字白色，增强对比度
  fonttitle=\scshape,
  listing only,
  listing options={
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
\newtcblisting{prompttemplateBlue}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,
  colframe=blue!15!white, % 边框颜色更浅接近背景
  colback=blue!5!white,   % 淡蓝色背景
  coltitle=black,         % 标题设为黑色增加对比
  fonttitle=\scshape,
  listing only,
  listing options={
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
% \newtcblisting{prompttemplateOrange}[1]{%
%   title={#1},
%   breakable,
%   boxrule=0.5mm,               % 边框更细
%   colframe=orange!20!white,    % 边框非常浅的橙色
%   colback=orange!2!white,      % 背景颜色更接近白色
%   coltitle=black,              % 标题文字颜色为黑色
%   fonttitle=\bfseries,         % 标题加粗
%   listing only,
%   listing options={
%     basicstyle=\ttfamily\small, % 小型的等宽字体
%     breaklines=true,
%     columns=fullflexible,
%     keepspaces=true,
%   }
% }
\newtcblisting{prompttemplateOrange}[1]{%
  title={#1},
  breakable,
  boxrule=0.5mm,               % 保持边框粗细
  colframe=orange!70!white,    % 加深橙色边框 (从20%提高到70%)
  colback=orange!10!white,     % 加深背景色 (从2%提高到10%)
  coltitle=black,              % 保持黑色标题
  fonttitle=\bfseries,         % 保持加粗标题
  listing only,
  listing options={
    basicstyle=\ttfamily\small,
    breaklines=true,
    columns=fullflexible,
    keepspaces=true,
  }
}
%%%%%%

\usepackage{multirow}
\usepackage{makecell}
% \usepackage{ctex}
\usepackage{fullpage}
\usepackage{amsthm,amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{amssymb}
\usepackage{color}
\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{graphicx}
\usepackage{comment}
\usepackage{cases}
\usepackage{appendix}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes}
\usepackage{marginnote}
\usepackage{tcolorbox}

\colorlet{color1}{blue}
\colorlet{color2}{red!50!black}

\usepackage{hyperref}[6.83]
\hypersetup{
  colorlinks=true,
  frenchlinks=false,
  pdfborder={0 0 0},
  naturalnames=false,
  hypertexnames=false,
  breaklinks,
  allcolors = color1,
  urlcolor = color2,
}

\numberwithin{equation}{section}

\newtheorem{mainthm}{Theorem}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{coro}[thm]{Corollary}
\newtheorem{rem}[thm]{Remark}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{defn}{Definition}[section]
% \newtheorem{assumption}[thm]{Assumption}
\renewcommand\theassumption{A\arabic{assumption}}

\usepackage{graphicx}
\usepackage{anyfontsize}
\usepackage{amsmath}
\usepackage{xcolor}
% \usepackage{subcaption}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
% \newtheorem{theorem}{Theorem}
% \newtheorem{lemma}[theorem]{Lemma}
% \newtheorem{proposition}[theorem]{Proposition}
% \newtheorem{corollary}[theorem]{Corollary}
% \newtheorem{definition}[theorem]{Definition}
% \newtheorem{remark}{Remark}

\allowdisplaybreaks
\newcommand{\zl}[1]{{\textcolor{cyan}{[Zhonglin: #1]}}}

\title{OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling}

\author{
Hongliang Lu$^{1,*}$, 
Zhonglin Xie$^{2,*}$, 
Yaoyu Wu$^1$, 
Can Ren$^3$, 
Yuxuan Chen$^3$, 
Zaiwen Wen$^{2,\dagger}$
\\[2ex]
% \small
$^1$College of Engineering, Peking University\\
$^2$Beijing International Center for Mathematical Research, Peking University\\
$^3$School of Mathematics Science, Peking University\\[1ex]
% \small
$^*$Equal contribution\\
$^\dagger$Corresponding author: wenzw@pku.edu.cn
}

\date{}

% \date{Received: date / Accepted: date}

\begin{document}

\maketitle

\begin{abstract}
Despite the rapid development of large language models (LLMs), a fundamental challenge persists: the lack of high-quality optimization modeling datasets hampers LLMs' robust modeling of practical optimization problems from natural language descriptions (NL). This data scarcity also contributes to the generalization difficulties experienced by learning-based methods.
To address these challenges, we propose a scalable framework for synthesizing a high-quality dataset, named OptMATH. Starting from curated seed data with mathematical formulations (MF), this framework automatically generates problem data (PD) with controllable complexity. Then, a back-translation step is employed to obtain NL. To verify the correspondence between the NL and the PD, a forward modeling step followed by rejection sampling is used. The accepted pairs constitute the training part of OptMATH. Then a collection of rejected pairs is identified and further filtered. This collection serves as a new benchmark for optimization modeling, containing difficult instances whose lengths are much longer than these of NL4OPT and MAMO.
Through extensive experiments, we demonstrate that models of various sizes (0.5B-32B parameters) trained on OptMATH achieve superior results on multiple modeling benchmarks, thereby validating the effectiveness and scalability of our approach. Our dataset is publicly available at \url{https://github.com/AuroraLHL/OptMATH}.
\end{abstract}

\section{Introduction}
Automatic translation of natural language descriptions of optimization problems into solver-ready formats is a critical step in democratizing access to optimization techniques. This capability would enable individuals without expertise in optimization to leverage the power of optimization for solving real-world problems across various domains, including logistics  \cite{Ghiani2022IntroductionTL}, finance  \cite{Consigli2019OptimizationMI}, and engineering  \cite{Rao2010EngineeringO}. Known as optimization modeling, this task has long been challenging due to the inherent ambiguity of natural language and the need for a deep understanding of optimization modeling principles. The manual process of formulating an optimization problem typically involves iterative refinement and demands significant mastery of the relevant techniques, making it time-consuming and inaccessible to many practitioners.

Recent advances in Large Language Models (LLMs), such as ChatGPT \cite{brown_language_2020}, GPT-4 \cite{Achiam2023GPT4TR}, and OpenAI's o1 \cite{openai2024o1}, have demonstrated remarkable capabilities in understanding natural language and performing complex reasoning tasks. Notably, the introduction of o1 has significantly enhanced the performance of LLMs in mathematical reasoning, achieving state-of-the-art results on challenging datasets including AIME (2024), GPQA, and CodeForces. However, optimization modeling presents unique challenges. Unlike grade-school mathematics, where problems typically have a single correct solution, optimization problems can often be approached using multiple valid models, making the task semi-open-ended. Furthermore, optimization frequently relies on a vast body of empirical knowledge that is less formally structured than purely mathematical concepts. As a result, research has shown that directly applying LLMs to optimization modeling tasks yields suboptimal outcomes \cite{ramamonjison_nl4opt_2023}.

\textbf{LLMs for Optimization Modeling.}
To address this issue, recent efforts have explored various strategies. Research on leveraging LLMs for optimization modeling typically follows two main approaches. The first uses prompt engineering techniques to guide LLMs in generating or refining optimization models, without modifying the underlying model parameters. Examples include the NL4Opt competition \cite{ramamonjison_nl4opt_2023}, which aims to extract optimization formulations from natural language descriptions, and OptiMUS \cite{ahmaditeshnizi_optimus_2023}, which proposes an agent-based prompt engineering method. More recently, Autoformulation \cite{astorga_autoformulation_2024} combines Monte Carlo tree search with LLMs to address optimization modeling. While these methods rely heavily on the base capabilities of general-purpose LLMs, they do not yield fundamental advancements beyond refined prompting.

The second approach centers on fine-tuning, wherein model parameters are adapted using specially curated or synthesized optimization datasets. ORLM \cite{tang_orlm_2024} introduces OR-Instruct, a data augmentation framework for optimization problems, and demonstrates performance gains via Supervised Fine-Tuning on a foundation model. LLMOPT  \cite{jiang_llmopt_2024} likewise applies a multi-instruction fine-tuning strategy and self-correction mechanisms. However, most of these methods generate small amounts of synthetic training data—often of inconsistent quality and insufficient complexity. Consequently, their ability to generalize to more sophisticated optimization tasks is limited.

\textbf{LLM-Based Data Synthesis for Optimization.}
% Data synthesis methods are now vital for mitigating data scarcity and improving LLM performance. According to \cite{wang2024survey}, such methods can be broadly split into data augmentation and data synthesis. OR-Instruct  \cite{tang_orlm_2024,wang2022self} follows the self-instruct framework and thus exemplifies a data augmentation approach. In MILP-Evolve  \cite{li2024towards}, an evolutionary framework is introduced to generate diverse mixed integer linear programming (MILP) problems using LLMs. While MILP-Evolve marks a novel step towards synthetic data generation, it does not tackle the essential task of translating between natural language descriptions and mathematical optimization models.
Data synthesis methods have become essential for addressing data scarcity and enhancing the performance of LLMs. According to \cite{wang2024survey}, these methods can be broadly categorized into two main approaches: data augmentation and data synthesis. OR-Instruct \cite{tang_orlm_2024,wang2022self} exemplifies a data augmentation approach, following the self-instruct framework to expand existing datasets. On the other hand, MILP-Evolve \cite{li2024towards} introduces an evolutionary framework designed to generate diverse mixed-integer linear programming (MILP) problems using LLMs. While MILP-Evolve represents a significant step forward in synthetic data generation, it does not address the critical challenge of translating natural language descriptions into mathematical optimization models.
% By contrast, our reverse data generation framework is designed to produce large-scale, complex optimization problems that span significantly diverse scenarios, thereby addressing this gap.

\textbf{Instance Generation for Optimization.}
Recent research in MILP instance generation has evolved along two primary axes: learning-based structural synthesis and rule-based distribution expansion. The learning-based paradigm addresses data scarcity by developing generative models that preserve instance hardness and constraints. Examples include the bipartite graph variational autoencoder framework proposed by \cite{g2milp}, the block decomposition operators for constraint matrices introduced in \cite{milpstudio}, the duality-driven feasibility guarantees established by \cite{digmilp}, and the adaptive constraint modification mechanisms developed in \cite{acmmilp}. The rule-based approach leverages instance space analysis techniques \cite{alipour2022enhanced,strassl2022instance,alipour2023instance} to guide the generation of more diverse instance distributions \cite{bowly2015generationevolve,bowly2019stress}. Alternatively, it may rely on manually selected features to control the characteristics of the generated instances \cite{bowly2020generationlp}.

% Recent research in MILP instance generation evolves along two primary axes: learning-based structural synthesis and rule-based distribution expansion. The learning-based paradigm tackles data scarcity by developing generative models that retain instance hardness and constraints, such as the bipartite graph variational autoencoder framework proposed by \cite{g2milp}, the block decomposition operators for constraint matrices introduced in \cite{milpstudio}, the duality-driven feasibility guarantees established by \cite{digmilp}, and the adaptive constraint modification mechanisms developed in \cite{acmmilp}. Conversely, rule-based methods systematically construct diverse testbeds to evaluate algorithmic robustness, exemplified by works employing feature engineering for maximum flow problem analysis \citep{alipour2022enhanced}, proposing automated algorithm selection in job shop scheduling \citep{strassl2022instance}, conducting comparative analyses of MIP models for 2D bin packing \citep{alipour2023instance}, and establishing objective performance metrics across instance spaces \citep{smithmiles2013objective}. These dual directions reflect distinct objectives: learning-based generation emphasizes structural authenticity, while rule-based construction prioritizes distributional coverage for comprehensive benchmarking.

\textbf{Our Contributions.}
We propose a scalable bidirectional synthesis framework that addresses the critical challenge of data scarcity in optimization modeling through \emph{triplet-aligned (NL, MF, PD) data generation} and rigorous validation. Our framework uniquely integrates a closed-loop workflow with \textit{optimal value matching}, ensuring semantic equivalence between NL, MF, and PD. This approach demonstrates exceptional scalability. The framework's domain adaptability is evidenced by coverage of 10+ real-world applications (e.g., logistics, energy, finance) through 53 seed generators, with manual analysis confirming 99.6\% equivalence accuracy across all triplets.
% A Novel Bidirectional Synthesis Framework with Rigorous Validation
% We propose the first scalable framework that generates triplet-aligned data pairs (NL, MF, PD) through a closed-loop workflow. Unlike prior single-direction approaches, our framework enforces semantic equivalence via optimal value matching and forward-backward verification, where each generated NL is guaranteed to correspond to both its MF and PD through solver-based rejection sampling. This verification mechanism achieves 99.6\% equivalence accuracy in manual validation. , generating over 200,000 instances with linear time complexity while achieving state-of-the-art performance across models ranging from 0.5B to 32B parameters

% This paper introduces a novel bidirectional data synthesis framework that directly tackles the critical scarcity of high-quality training data for LLMs in optimization modeling. Unlike existing approaches, our framework leverages a unique round-trip generation mechanism to create semantically equivalent natural language and mathematical formulation pairs. The core innovation of this framework is its iterative closed-loop workflow, which rigorously integrates optimal value matching and forward modeling verification to ensure semantic equivalence between natural language descriptions and mathematical formulations. This represents a significant advancement over existing single-pass generation methods that often lack robust validation mechanisms.

% Through this framework, we construct OptMATH-Train, the first large-scale dataset of NL-optimization model pairs featuring built-in validity guarantees. This dataset serves as a crucial resource for the community, enabling more robust training and evaluation of optimization modeling techniques. Furthermore, we contribute OptMATH-Bench, a novel benchmark specifically designed to evaluate the performance of models on challenging cases. This benchmark, curated from rejected examples during our rigorous synthesis verification process, fills a critical gap in existing benchmarks by encompassing diverse problem scenarios and optimization types, along with complex natural language contexts, thus providing a more comprehensive evaluation landscape.

We introduce \emph{OptMATH-Train}, a large scale verified optimization modeling dataset containing rigorously validated (NL, MF, PD) triplets. Each triplet undergoes three-stage quality control: mathematical consistency checks (MF-to-PD compilation), semantic fidelity validation (PD-to-NL backtranslation), and solution equivalence verification through solver-based rejection sampling. From rejected instances, we curate \emph{OptMATH-Bench}, a challenging benchmark comprising ``hard instances'' characterized by extended natural language contexts (2.9$\times$ longer than MAMO EasyLP) and complex constraints. We further span it using various problems including LP, MILP, IP, NLP, SOCP. This benchmark provides the standardized evaluation for long-context optimization modeling.

Finally, extensive experiments demonstrate the efficacy of our framework. Models trained on the OptMATH-Train dataset achieve state-of-the-art performance on multiple established modeling benchmarks, including NL4OPT and MAMO.
% , with improvements of up to 10.61\% and 10.73\% in accuracy, respectively
These results definitively validate the effectiveness and scalability of our framework for generating high-quality optimization modeling datasets.

\section{Backgrounds \& Overview}
In mathematical optimization theory, a canonical optimization problem can be formulated as:
\begin{equation}
\label{eq:standard_form}
\begin{aligned}
&\min_{\mathbf{x}} & & g(\mathbf{x}), \\
&\text{subject to} & & c_i(\mathbf{x}) = 0, & i \in \mathcal{E}, \\
& & & c_i(\mathbf{x}) \geq 0, & i \in \mathcal{I},
\end{aligned}
\end{equation}
where $\mathbf{x} \in \mathbb{R}^n$ denotes the decision vector. The objective function $g: \mathbb{R}^n \rightarrow \mathbb{R}$ assigns a scalar value to each candidate solution, which we seek to minimize. The constraint functions $c_i: \mathbb{R}^n \rightarrow \mathbb{R}$ define the feasible region through equality constraints indexed by $\mathcal{E}$ and inequality constraints indexed by $\mathcal{I}$.

To formalize the optimization modeling problem, we define several key concepts and illustrate them using a concrete example in Appendix \ref{appd:cot}. For a specific optimization problem, we define $\mathrm{NL}$ as the \emph{natural language description}, which corresponds to the ``Input-Natural Language Description'' in the example. We represent the LP/MPS file, the concrete mathematical expression (corresponding to the ``Output-Instance Formulation''), and any other solver-ready formats, such as executable Python code with Gurobi shown in Appendix \ref{appd:cot}, as \emph{problem data} (PD). A common characteristic of these representations is that they allow us to obtain the optimal value of the problem by invoking a solver based on the PD. \emph{Mathematical formulation} (MF) refers to formulation where concrete numbers are not yet specified, corresponding to the ``Output-General Formulation'' in the example. We emphasize that, in subsequent sections, we may use different forms of PD. However, these forms essentially carry the same information about the problem and can be inferred from the context without ambiguity. We use different forms of PD to facilitate their integration into the workflow and to enhance clarity in various contexts.
% Let $m:=(g;c_{i},i\in\mathcal{E}\cup\mathcal{I})$ represent an abstract optimization model (hereafter referred to as the canonical model) corresponding to the formulation in (\ref{eq:standard_form}).  $f$ as the concrete mathematical formulation, and $s$ as the executable solver code. 

Modern solvers such as Gurobi and Mosek \cite{gurobi,mosek} can efficiently solve problems stored with PDs using algorithms like interior-point methods \cite{karmarkar1984new}. However, practical challenges remain. In real-world applications, one of the main difficulties lies in converting informal NLs of problems into precise MFs. Moreover, extracting the PDs from NLs poses an additional significant challenge. Traditionally, this process has required deep optimization expertise \cite{boyd2004convex}, but recent advances in LLMs offer promising opportunities to automate this transformation.

Let $\mathcal{A}_\theta$ represent an LLM parameterized by $\theta$. The formulation for increasing the modeling capability of the LLM can be expressed as:
\begin{align}
\max_{\theta} \quad & \mathbb{E}_{(\mathrm{NL},\mathrm{MF},\mathrm{PD}) \sim \mathcal{D}}[Q_{(\mathrm{NL},\mathrm{MF},\mathrm{PD})}(\mathrm{MF}',\mathrm{PD}')], \label{eq:obj} \\
\text{s.t.} \quad & (\mathrm{MF}',\mathrm{PD}') = \mathcal{A}_\theta(\mathtt{prompt}_{\mathrm{M}}(\mathrm{NL})), \label{eq:const}
\end{align}
where $\mathtt{prompt}_{\mathrm{M}}$ is a modeling prompt template mapping $\mathrm{NL}$ to $\mathrm{MF}'$ and $\mathrm{PD}'$. The quality metric $Q$ evaluates the generated $(\mathrm{MF}',\mathrm{PD}')$ pairs based on the verified $(\mathrm{NL},\mathrm{MF},\mathrm{PD})$ triplet. Constraint (\ref{eq:const}) formalizes the automated formulation process (Autoformulation), as depicted in the example in Appendix \ref{appd:cot}. Optimizing $\theta$ relies on having a large corpus of high-quality triplets $(\mathrm{NL},\mathrm{MF},\mathrm{PD})$. To address this requirement, we propose a systematic framework for generating synthetic training data that maintains mathematical rigor.
% while ensuring computational tractability.

\textbf{An Overview of Our Pipeline.}
The pipeline of our framework is presented in \figurename ~\ref{fig:overview}. In the reverse data generation phase, we collect optimization problems from two sources: (1) LP/MPS files from challenging benchmarks such as MIPLIB 2017 \cite{miplib2017} and netlib \cite{netlib,gay1985electronic}, and (2) over 50 expert-curated seed problem generators covering diverse optimization scenarios. Through our carefully designed backtranslation pipeline, we leverage both the LP files and their MFs to generate high-quality NLs of optimization problems. Notably, using an LLM-based feedback workflow with evaluation, our collected generators can produce tremendous PDs with controllable varying difficulty levels. This enables us to effectively address the data scarcity challenge in training learning-based optimization methods.
% through the scalable generation of high-quality training data.

% In the forward modeling and evaluation process, we employ our trained AutoFormulator to translate the generated NLs back into PDs, specifically, in this phase, all the PDs are solver code, which can be further exported as LP files.
In the forward modeling and evaluation process, we utilize our trained AutoFormulator to translate the generated NLs back into PDs. Specifically, in this phase, all PDs are represented as solver code, which can then be exported as LP files. We then implement a rigorous rejection sampling strategy, where only instances whose optimal objective values match between the original and generated LP files are retained. This equivalence-based filtering mechanism ensures the high quality of our OptMATH-Train dataset by guaranteeing the semantic consistency of each instance.

Building upon the high-quality instances obtained through rejection sampling, we employ various data augmentation strategies to further enhance the diversity and coverage of our dataset. This enriched collection of training pairs is then utilized to fine-tune a foundation model, leading to AutoFormulator, a specialized model specifically designed for automated mathematical optimization modeling.

\begin{figure*}[ht]
    \centering    
    \includegraphics[width=\linewidth]{pipeline10.pdf}
    % \vspace{-6mm}
    \caption{An overview of our scalable, bidirectional data synthesizing pipeline.}
    % \caption{An overview of our scalable, bidirectional optimization modeling pipeline. Starting from challenging benchmarks (e.g., MIPLIB 2017, netlib), we collect LP/MPS files and extract their mathematical formulations. \textbf{(1) Back Translation (top-left).} We generate new MPS instances with distributional similarity to challenging benchmarks and employ a LLM to convert these MPS files into natural language descriptions. \textbf{(2) Translation (top-right).} The LLM-powered \emph{AutoFormulator} maps the resulting natural language descriptions back into MPS files and validates them by matching their optimal objective values to the originals. \textbf{(3) Evaluation (bottom).} Verified pairs then form the \emph{OptMath} dataset, which is subsequently used to augment and fine-tune the AutoFormulator for improved forward (language-to-MPS) and backward (MPS-to-language) generation.}    
    \label{fig:overview}
\end{figure*}

\section{Feedback-Driven PD Generation}
\label{sec:instance_gen}
% The verified triplets $(\mathrm{NL},\mathrm{MF},\mathrm{PD})$ are scarce. Fortunately, t
The mature development of the optimization community has provided us with access to many high-quality optimization PDs. These PDs are typically stored in standardized formats like MPS or LP files. 
% Additionally, for any given class of optimization problems, we can create diverse PDs programmatically using instance generators. 
To effectively leverage these resources, we began by curating over 50 seed problem classes sourced from a variety of optimization journals and websites (see Appendix \ref{app:seed class} for details). For each $i$-th problem class, we developed a corresponding instance generator $G_{i}$. This generator takes a problem-specific configuration as input and outputs a probability distribution over PDs. The distribution is designed to produce PDs with varying scales and complexities, which are controllable through adjustable configurations. Before delving into the controlled generation process for the PDs, we first explain how the complexity of PDs can be measured.
%  Next, we employed a controlled generation process for the PDs, incorporating an LLM-in-loop approach.

\textbf{Measuring the Modeling Complexity.}
The complexity of formulating and solving a MIP problem depends on modeling choices such as the types of variables, the forms of constraints, and auxiliary modeling techniques employed. We introduce a scoring function $S$ defined as:
% To compare and assess the complexity of different MIP models, w through key aspects of the model’s size, structure, and difficulty  (e.g., Big-M formulations)
\begin{equation}
\label{eq:complexity}
\begin{aligned}
S(\mathrm{PD}) & = \alpha_{\text{bin}}N_{\text{bin}} + \alpha_{\text{int}}N_{\text{int}} + \alpha_{\text{cont}}N_{\text{cont}}\\
&\quad+\beta_{\text{lin}}N_{\text{lin}} + \beta_{\text{indic}}N_{\text{indic}} + \beta_{\text{quad}}N_{\text{quad}} \\
&\quad + \beta_{\text{gen}}N_{\text{gen}}  + \gamma_{\text{BigM}}\,f_{\text{BigM}} + \delta_{\text{expr}}\,\overline{L_{\text{expr}}},
\end{aligned}
\end{equation}
where $N_{\text{bin}}, N_{\text{int}}, N_{\text{cont}}$ are the number of binary, integer, and continuous variables, respectively. Similarly, $N_{\text{lin}}, N_{\text{indic}}, N_{\text{quad}}, N_{\text{gen}}$ represent the number of linear, indicator, quadratic, and general nonlinear constraints. The term $f_{\text{BigM}}$ is a factor reflecting the frequency of Big-M formulations, and $\overline{L_{\text{expr}}}$ is the average number of terms per constraint and the objective function, which captures the structural information of the expressions. Lastly, the weights $\alpha_{\cdot}, \beta_{\cdot}, \gamma_{\text{BigM}}, \delta_{\text{expr}}$ are tunable parameters reflecting the contribution of each component to the overall complexity. To illustrate it, we provide an example in Appendix \ref{sec:measure-complexity} that considers a MIP problem incorporating multiple constraint types to optimize production costs for two products under resource constraints. 

% This scoring function combines contributions from decision variables, constraints, auxiliary modeling techniques (e.g., Big-M), and the structural complexity of mathematical expressions to produce a single numerical measure that quantifies the complexity of the model.
% We introduce a scoring function that considers the not only the size (\emph{number of variables} and \emph{number of constraints}) but also the diversity of variable types, the forms of constraints, and any special modeling tricks.

% When measuring the complexity of a Mixed Integer Programming (MIP) model from a natural language specification, we consider not only the size (\emph{number of variables} and \emph{number of constraints}) but also the diversity of variable types, the forms of constraints, and any special modeling tricks. Formally, let:
% (1) $N_{\text{bin}},\;N_{\text{int}},\;N_{\text{cont}}$: counts of binary, integer, and continuous variables, respectively.
% (2) $N_{\text{lin}},\;N_{\text{indic}},\;N_{\text{quad}},\;N_{\text{gen}}$: counts of linear, indicator, quadratic, and other general constraints, respectively.
% (3) $f_{\text{BigM}}$: a factor capturing the usage frequency or magnitude of Big-M formulations.
% (4) $\overline{L_{\text{expr}}}$: the average number of variable terms or operators in each constraint.

% We define corresponding weights $\alpha,\;\beta,\;\gamma,\;\delta$ to reflect the relative difficulty of each model component. A simple scoring function $\mathcal{D}(M)$ can be expressed as:
% $$
% \begin{aligned}
% \mathcal{D}(M) 
% &= \bigl(\beta_{\text{lin}}N_{\text{lin}} + \beta_{\text{indic}}N_{\text{indic}} + \beta_{\text{quad}}N_{\text{quad}} + \beta_{\text{gen}}N_{\text{gen}}\bigr) \\
% &+ \bigl(\alpha_{\text{bin}}N_{\text{bin}} + \alpha_{\text{int}}N_{\text{int}} + \alpha_{\text{cont}}N_{\text{cont}}\bigr)
% + \gamma_{\text{BigM}}\,f_{\text{BigM}} \\
% &+ \delta_{\text{expr}}\,\overline{L_{\text{expr}}}.
% \end{aligned}
% $$
% This formula offers a consistent way to compare the relative modeling effort for different MIP formulations, helping modelers assess the complexity introduced by various choices of variables, constraints, and auxiliary techniques (like Big-M). The coefficients can be tuned to match domain-specific experience and any special structure in the problem.

% \section{Quantifying MIP Model Complexity}

% \subsection{Motivation}
% Mixed Integer Programming (MIP) is a widely-used optimization modeling approach for solving problems involving both integer and continuous decision variables. 

% \subsection{Model Complexity Scoring Function}

% \textbf{Example: Production Planning Problem}
% To illustrate $\mathcal{D}(M)$, we consider a production planning problem. The objective is to maximize profit while planning the production of two products ($A$ and $B$) over a $T = 3$ day planning horizon. The problem includes the following details:
% (i) a daily production capacity for each product, 
% (ii) a minimum production demand that must be met, 
% (iii) a fixed cost to activate a production line, and 
% (iv) integer production quantities. Additionally, logical conditions enforce that if a product is produced on a given day, the corresponding production line must be activated, which requires Big-M formulations.

% \subsubsection{Model Formulation}

% The model consists of variables, constraints, Big-M usage, and structural complexity:
% The binary decision variables $y_{\text{A},t}$ and $y_{\text{B},t}$ linear stap boolean symbolic .


% When generating families of MIP models, it is often appropriate to maintain a target range for their ``difficulty'', as measured by the scoring function introduced previously. Achieving this balance typically involves controlling the overall composition of variables, constraints, Big-M constants, and other modeling constructs so that instances remain both feasible and solvable while falling within desired complexity bounds.

% A useful approach is to adopt an iterative and feedback-driven pipeline using a language model (LLM) alongside repeated MIP evaluations. First, a prompt is constructed specifying requirements on feasibility and complexity. The LLM proposes parameter configurations (for the number and type of variables, constraints, and additional modeling elements). Next, each proposed configuration is tested by generating models and computing their complexity according to the earlier formula. These models are then solved, collecting metrics on feasibility, runtime, and final difficulties. This information is summarized and relayed to the LLM as feedback, prompting a refined proposal in the next iteration. After several rounds of adjustment, the procedure typically converges to a set of parameters that consistently yields MIP instances fitting the specified complexity criteria.

% This feedback loop allows to systematically ``tune'' parameters so that individual instances remain both expressive (capturing a diverse array of constraints and variable types) and tractable (capturing a feasible and bounded problem solvable within reasonable time). By focusing on the scoring formula presented earlier, one can tailor the resulting models to a specific niche of difficulty, ensuring a controlled environment for testing or benchmarking various algorithms.
\textbf{Selecting Parameters to Control the Complexity.}
We now present the workflow in Algorithm \ref{alg:feedback} for selecting parameter configurations for instance generator $G_{i}$ to generate PDs fitting the complexity, feasibility, and solving time requirements. The prompt templates are illustrated in Appendix \ref{app:config_select}. As formalized in Algorithm \ref{alg:feedback}, the process begins by specifying target bounds. Then a template $\mathtt{prompt}_{\mathrm{IC}}$ for initializing the configuration are incorporated. After obtaining the configuration, we generate $N$ PDs using it. We then evaluate the generated PDs through the complexity score, solving time, and feasibility satisfactory. Then, a feedback $\mathtt{prompt}_{\mathrm{RC}}$ is created based on the statistics of these metrics over the $N$ generated PDs. The LLM iteratively adjusts parameters based on feedback from solved instances, ultimately converging to a configuration that satisfy predefined criteria. This ensures generated PDs remain both expressive and tractable by adhering to runtime thresholds.
% (through diverse constraint/variable compositions) (by adhering to runtime and feasibility thresholds).

\begin{algorithm}[ht]
\caption{Feedback-Driven Problem Data Generation}
\label{alg:feedback}
\begin{algorithmic}[1]
\Require
    Target complexity range $[S_{\min}, S_{\max}]$,
    time limits $[T_{\min}, T_{\max}]$,
    instance generator $G$,
    feasibility threshold $\mathcal{F}_{\mathrm{target}}$,
    max iterations $T$
\Ensure
    Configuration $\Theta$ such that for $\mathrm{PD}_i \sim G(\Theta)$: 
    \State $S(\mathrm{PD}_i) \in [S_{\min}, S_{\max}]$ (complexity), $\tau_i \leq T_{\max}$ (solving time), 
    \State $\Pr(f_i = \text{feasible}) \geq \mathcal{F}_{\mathrm{target}}$
\State \textbf{Initialize parameters via LLM:} 
\State $\Theta_0 \gets \mathcal{L}(\texttt{prompt}_{\mathrm{IC}}(S_{\min}, S_{\max}, T_{\min}, T_{\max}))$
\For{$t = 1$ \textbf{to} $T$}
    \State Generate $N$ PDs: $\{\mathrm{PD}_i\}_{i=1}^N \gets G(\Theta_{t-1})$
    \State Compute metrics: $S(\mathrm{PD}_i)$ (Eq.~\ref{eq:complexity}), $\tau_i$ (solving time), $f_i$ (feasibility)
    \State Aggregate statistics: 
    \State $\quad \bar{S}_t = \frac{1}{N}\sum S(\mathrm{PD}_i)$
    \State $\quad \bar{\tau}_t = \frac{1}{N}\sum \tau_i$
    \State $\quad \mathcal{F}_t = \frac{1}{N}\sum \mathbb{I}(f_i = \text{feasible})$
    \If{$\bar{S}_t \in [S_{\min}, S_{\max}]$ \textbf{and} $\bar{\tau}_t \leq T_{\max}$ \textbf{and} $\mathcal{F}_t \geq \mathcal{F}_{\mathrm{target}}$}
        \State \textbf{return} $\Theta_{t-1}$
    \Else
        \State \textbf{Refine parameters via feedback:}
        \State $\Theta_t \gets \mathcal{L}(\texttt{prompt}_{\mathrm{RC}} (\bar{S}_t, \bar{\tau}_t, \mathcal{F}_t; \Theta_{t-1}))$
    \EndIf
\EndFor
\State \textbf{return} $\emptyset$ (no valid $\Theta$ found)
\end{algorithmic}
\end{algorithm}

% \begin{algorithm}[t]
% \caption{Feedback-Driven PD Generation}
% \label{alg:feedback}
% \begin{algorithmic}[1]
% \REQUIRE Target complexity range $[S_{\min}, S_{\max}]$, iteration limit $[T_{\min},T_{\max}]$, instance generator $G$
% \ENSURE Parameter configuration $\Theta$ that maximizes the satisfaction of $S(\mathrm{PD}) \in [S_{\min}, S_{\max}]$, solving time requirement, and feasibility criteria $\mathcal{F}$ in average for $\mathrm{PD}$s generated through $G(\Theta)$ 
% % \STATE Initialize prompt $\mathcal{P}$ with $\mathcal{F}$ and $[S_{\min}, S_{\max}]$
% \STATE LLM proposes initial configuration\\ $\Theta_0=\mathcal{L}(\mathtt{prompt}_{\mathrm{IC}}(S_{\min},S_{\max};T_{\min},T_{\max}))$
% \FOR{$t = 1$ \textbf{to} $T$}
%     \STATE Generate $N$ $\mathrm{PD}$s using $G(\Theta_t)$
%     \STATE Compute complexity score $S(\mathrm{PD})$ via Eq. (1) for each $\mathrm{PD}$
%     \STATE Solve $\mathrm{PD}_t$, record feasibility status $f_t$ and runtime $\tau_t$ for each $\mathrm{PD}$
%     \STATE Gather the information $I$ of these $\mathrm{PD}$s and create the feedback prompt
%     \IF{All of the PDs satisfy the requirements}
%         \STATE \textbf{return} $\Theta_t$
%     \ELSE
%         \STATE Refine the configuration to improve the satisfaction\\
%         $\Theta_t=\mathcal{L}(\mathtt{prompt}_{\mathrm{RC}}(I;\Theta_{t-1}))$
%     \ENDIF
% \ENDFOR
% \STATE \textbf{Return} $\emptyset$ (no valid configuration found)
% \end{algorithmic}
% \end{algorithm}

% \section{Reverse Data Generation}
\section{The Data Synthesis Framework}
\label{sec:reverse}
% Subsection \ref{sec:back_alg} introduces the overall backtranslation algorithm framework. Subsection \ref{sec:pipeline} details our three-stage backtranslation pipeline that iteratively refines problem descriptions through initial generation, self-criticism, and self-refinement.

% Subsection \ref{sec:instance_gen} describes our instance generation methodology for creating diverse PDs. Given the collected problem class dataset $\mathcal{G}$, where $N$ is the number of problem classes and each pair $(m_i,g_i)\in\mathcal{G}$ consists of a general mathematical formulation $m_i$ and its corresponding instance generator $G_i$. The generator $G_i$ can produce problem instances with varying parameters, variable counts, and constraint numbers. 
% Let $\mathcal{L}^i$ denote the set of problem instances generated by $G_i$, where $M_i$ is the number of problem instances generated for the $i$-th problem class and each $l_i^j \in \mathcal{L}^i$ represents a solvable data file (LP file in our case).

% \subsection{Algorithm Framework}
\label{sec:back_alg}

This section presents our bidirectional scalable data synthesis framework. In this section, all of the PDs are in solver code form (see subsection \ref{sec:autoformulation} for more details). Let $\mathcal{L}$ represents the LLM employed on the reverse data generation phase, and $\mathcal{A}_\theta$ for our fine-tuned AutoFormulator with weights $\theta$. We define $\mathtt{prompt}_\mathrm{I}$, $\mathtt{prompt}_\mathrm{C}$, $\mathtt{prompt}_\mathrm{R}$ as the prompt templates that accept certain inputs for the initial generation, self-critism, and self-refinement stages. The algorithm is formalized in Algorithm \ref{alg:reverse}, with an illustrative example of the backtranslation process shown in Figure \ref{fig:backtranslation}.

% \begin{algorithm}[htp]
% \caption{Backtranslation Algorithm}
% \label{alg:reverse}
% \begin{algorithmic}[1]
% \REQUIRE  : Instance pair $(m_i,l_i^j)$, Max Iteration $T$
% \ENSURE : $(p_i^j,f_i^j,s_i^j,a_i^j)$
% \STATE \text{Initial Generate:} $y \gets \mathcal{F}_\theta(\mathtt{prompt}_t(m_i,l_i^j))$
% \STATE \text{Initialize:} $c_0=r_0$=Null

% \FOR{$k \gets 1$ to $T-1$}
%     \STATE \text{Self-Criticize:}
%     \STATE $c_{k+1} \gets \mathcal{F}_\theta(\mathtt{prompt}_c(m_i,l_i^j,y_1,c_0,r_0,\ldots,c_k,r_k))$
    
%     \STATE\text{Self-Refine:} 
%     \STATE$r_{k+1} \gets \mathcal{F}_\theta(\mathtt{prompt}_r(m_i,l_i^j,y_1,c_1,r_0,\ldots,c_k,r_{k-1}))$
%     \IF{$r_{k+1}$ \text{ is good enough } \OR $k+1=T$}
%     \STATE $p_i^j \gets r_{k+1}$
%     \STATE \textbf{break}
% \ENDIF
% \ENDFOR
% \STATE \text{AutoFormulation:} $(f_i^j,s_i^j) \gets \mathcal{F}_{\theta'}(\mathtt{prompt}(p_i^j))$
% \STATE $a_i^j \gets \text{Solve }l_i^j \text{ by Gurobi}$ 
% \STATE $b_i^j \gets \text{Solve }s_i^j  \text{ by Gurobi} $ 

% \IF{$a_i^j = b_i^j$}
%     \STATE \textbf{return} \quad $(p_i^j,f_i^j,s_i^j,a_i^j)$
% \ELSE
%     \STATE \textbf{return} \quad Null
% \ENDIF
% \end{algorithmic}
% \end{algorithm}
The final OptMATH dataset $\mathcal{D}$ is constructed by collecting all valid quadruples $(\mathrm{NL}_{i,j},\mathrm{MF}_{i,j}',\mathrm{PD}_{i,j}',\mathrm{OV}_{i,j})$
% $(p_i^j,f_i^j,s_i^j,a_i^j)$
that pass the validation process, where $\mathrm{MF}_{i,j}'$ and $\mathrm{PD}_{i,j}'$ represent the generated mathematical formulation and problem data using $\mathcal{A}_{\theta}$, $\mathrm{OV}_{i,j}$ is the optimal value obtained by solving the problem specified by $\mathrm{PD}_{i,j}$. 
% $f_i^j$ represents the mathematical formulation and $s_i^j$ denotes the solver code, both obtained through forward modeling (see \ref{sec:autoformulation} for more details). 
\begin{algorithm}[ht]
\caption{Bidirectional Data Synthesis Algorithm}
\label{alg:reverse}
\begin{algorithmic}[1]  % 确保支持编号
\Require Instance pair $(\mathrm{MF}_{i},\mathrm{PD}_{i,j})$, Max Iteration $T$
\Ensure $(\mathrm{NL}_{i,j},\mathrm{MF}_{i,j}',\mathrm{PD}_{i,j}',\mathrm{OV}_{i,j})$
\State Initial generation: $\mathrm{NL} \gets \mathcal{L}(\texttt{prompt}_\mathrm{I}(\mathrm{MF}_{i},\mathrm{PD}_{i,j}))$
\State Initialize: $\mathrm{SC}=\mathrm{SR}=\mathrm{Null}$
\For{$k = 1,\ldots,T-1$}
    \State Self-Criticize:
    \State $\mathrm{SC} \gets \mathcal{L}(\texttt{prompt}_\mathrm{C}(\mathrm{MF}_{i},\mathrm{PD}_{i,j},\mathrm{NL}))$
    \State Self-Refine:
    \State $\mathrm{SR} \gets \mathcal{L}(\texttt{prompt}_\mathrm{R}(\mathrm{MF}_{i},\mathrm{PD}_{i,j},\mathrm{NL},\mathrm{SC},\mathrm{SR}))$
    \If{$\mathrm{SR}$ is good enough}
        \State \textbf{break}
    \EndIf
\EndFor
\State $\mathrm{NL}_{i,j} \gets \mathrm{SR}$
\State AutoFormulation:
\State $(\mathrm{MF}_{i,j}',\mathrm{PD}_{i,j}') \gets \mathcal{A}_{\theta}(\texttt{prompt}_{\mathrm{M}}(\mathrm{NL}_{i,j}))$
\State $\mathrm{OV}_{i,j} \gets$ Solve $\mathrm{PD}_{i,j}$ by Gurobi
\State $\mathrm{OV}_{i,j}' \gets$ Solve $\mathrm{PD}_{i,j}$ by Gurobi
\If{$\mathrm{OV}_{i,j} = \mathrm{OV}_{i,j}'$}
    \State \textbf{return} $(\mathrm{NL}_{i,j},\mathrm{MF}_{i,j}',\mathrm{PD}_{i,j}',\mathrm{OV}_{i,j})$
\Else
    \State \textbf{return} Null
\EndIf
\end{algorithmic}
\end{algorithm}
By leveraging our instance generators and the iterative refinement process, this algorithm enables scalable generation of high-quality data pairs. The mathematical equivalence between the generated formulations and the original instances is rigorously validated through rejection sampling, ensuring the reliability of our dataset. A comprehensive discussion of our quality control and rejection sampling can be found in Section \ref{sec:rejection}.

% \textbf{Selecting parameters to fit the complexity.}
% The instance generator is the first component of the reverse data generation pipeline. Its primary function is to create concrete instances of optimization problems based on the abstract mathematical formulations provided in the MIPLIB2017 dataset, which are typically represented in the format.

% The format provides a standardized way to describe the objective function, variables, and constraints of a linear or mixed-integer program. However, it is often abstract, defining parameters and variables without assigning them specific values. The instance generator's role is to instantiate these abstract formulations by assigning concrete numerical values to parameters and defining the domains of variables.

% The instance generator can be configured to generate instances with varying characteristics, such as different sizes (number of variables and constraints), different levels of sparsity (density of the constraint matrix), and different types of constraints (e.g., equality, inequality). This configurability ensures that the generated instances cover a wide range of possible optimization problems.

% The output of the instance generator is typically a set of files, each representing a specific instance of an optimization problem. These files can be in a format that is easily parsable by other components of the system, such as a modified format or a custom format that explicitly defines the parameter values and variable domains.

\subsection{Backtranslation Pipeline}
\label{sec:pipeline}

To generate high-quality NLs of optimization problems at scale, we leverage a specific LLM as the foundation of our pipeline. Recent research has demonstrated that complex tasks often benefit from iterative refinement approaches rather than direct generation  \cite{madaan2024self}. This observation aligns with human problem-solving processes in mathematics, which typically requires multiple attempts and refinements. Building upon this insight, we design a three-phase backtranslation pipeline that systematically improves the quality of generated descriptions through iterative refinement.
All prompt templates used in this pipeline can be found in \ref{appd:bs}.

\textbf{Initial Generation.} Given the mathematical formulation $\mathrm{MF}_{i}$ and the corresponding problem data $\mathrm{PD}_{i,j}$ of a problem $j$ in $i$-class, the LLM generates an initial natural language description $\mathrm{NL}$ using the prompt template $\mathtt{prompt}_\mathrm{I}$. This stage requires the model to comprehend both the mathematical semantics and the instance parameters to produce a preliminary human-readable description.

\textbf{Self-Criticism.} Using prompt template $\mathtt{prompt}_\mathrm{C}$, the LLM evaluates the current description by examining the mathematical equivalence with $\mathrm{MF}_{i}$, completeness of the constraints and objective functions, clarity and comprehensibility, and consistency of the parameters with $\mathrm{PD}_{i,j}$. The criticism $\mathrm{SC}$ in iteration $k$ incorporates feedback from all previous iterations to guide improvements.

\textbf{Self-Refinement.} Based on the criticism, the model generates refined descriptions $\mathrm{SR}$ with the prompt template $\mathtt{prompt}_\mathrm{R}$. The refinement process focuses on improving the mathematical accuracy, completeness of the constraints, and clarity of the descriptions.

This process iterates for $T$ rounds until a satisfactory description $\mathrm{NL}_{i,j}$ is obtained, with each iteration potentially improving the quality of the generated description. Based on our empirical analysis (see Appendix~\ref{appd:T}), we set $T=1$ in the final implementation.

% \section{Forward modeling \& Evaluation}
% Based on our generated problem descriptions in Section \ref{sec:reverse}, we evaluate the correspondence of the generated NL-PD pairs through a further forward modeling followed by the rejection sampling step.
% This section introduces three key components: 1) the core AutoFormulator framework that leverages Chain-of-Thought prompting strategies to generate diverse and valid mathematical formulations (Section \ref{sec:auto}), 2) data augmentation techniques to enhance the robustness and coverage of our training data (Section \ref{sec:aug}), and 3) a continual pre-training approach to effectively train the AutoFormulator model (Section \ref{sec:train}).
% We evaluate the generated NL-PD pairs through a further forward modeling followed by the rejection sampling step.

\subsection{Forward modeling}
\label{sec:autoformulation}

% \subsection{AutoFormulation}
% \label{sec:auto}

Building upon the NLs generated in subsection \ref{sec:pipeline}, we leverage AutoFormulator to transform them back into MFs and PDs in solver code form, enabling rejection sampling for quality validation. Given a NL as input, AutoFormulator produces two key outputs: a MF and corresponding PD in solver code form. While previous works  \cite{tang_orlm_2024,jiang_llmopt_2024} adopted fixed output formats, our approach is not constrained to any particular format, as our primary goal is to obtain correct solver code, with the formulation serving as an intermediate reasoning step. To facilitate genuine mathematical modeling capabilities rather than superficial format mapping, we design diverse Chain-of-Thought (CoT) prompting strategies  \cite{Wei2022ChainOT}. This approach generates multiple valid reasoning paths and formulation variants for the same problem, enriching our training data with diverse modeling perspectives and enhancing the model's mathematical reasoning capabilities. Detailed implementation of these CoT strategies is described in Appendix \ref{appd:cot}.

\subsection{Rejection Sampling}
\label{sec:rejection}

To ensure the quality and mathematical soundness of our generated optimization problem descriptions, we employ a rejection sampling strategy \cite{Yuan2023ScalingRO,Liu2024AugmentingMW} to filter and select high-quality samples from the generated candidates.

As illustrated in Algorithm \ref{alg:reverse}, our rejection sampling mechanism relies on solution-based comparison to validate the generated samples. Specifically, for each generated natural language description $\mathrm{NL}_{i,j}$, we use AutoFormulator to transform it into a mathematical formulation $\mathrm{MF}_{i,j}'$ and solver code $\mathrm{PD}_{i,j}'$, obtaining solution $\mathrm{OV}_{i,j}'$. This solution is then compared with $\mathrm{OV}_{i,j}$, obtained by directly solving the original instance $\mathrm{PD}_{i,j}$. A sample is accepted into our dataset $\mathcal{D}$ as a validated quadruple $(\mathrm{NL}_{i,j}, \mathrm{MF}_{i,j}', \mathrm{PD}_{i,j}', \mathrm{OV}_{i,j})$ if and only if $\mathrm{OV}_{i,j} = \mathrm{OV}_{i,j}'$.

While this solution-based validation approach may not guarantee perfect equivalence (as problems with identical optimal values may represent different optimization problems), our manual analysis of randomly sampled instances (1\% of the total dataset) reveals a remarkable 99.6\% accuracy rate. We acknowledge that determining the exact equivalence between two mathematical formulations remains an open research question worthy of further investigation. Nevertheless, our current approach provides a practical and highly effective mechanism for ensuring dataset quality.

\section{Fine-Tuning}
\subsection{Data Augmentation}
\label{sec:aug}
% To improve the robustness and generalization ability of the AutoFormulator, we employ data augmentation techniques to expand the training dataset. Data augmentation artificially increases the size and diversity of the training data by creating modified versions of the existing natural language descriptions.Compared to a data generator, augmentation can bring more diversity to a problem. This is due to the standardised process of the data generator, which produces many standard problems, whereas the rules of augmentation, for example, change from single-objective to multi-objective optimisation, optimise the dual of the original problem, and so on. Many non-standard problems can be generated, improving the generalisation performance of models trained on our dataset.
% To improve the diversity of our dataset, we use data augmentation to expand the training it. This method generates more non-standard problems compared to a data generator, enhancing the model's generalization performance. The following two steps are employed for each question in order to obtain qualified augmentation data:

% \textbf{Problem Augmentation:} The augmentation approach adopted is two-fold, focusing firstly on problem description and secondly on mathematical modelling. The subsequent creation of rules for problem rewriting, semantic substitution, constraint expansion, and numerical augmentation is based on this. The detailed augmentation rules can be found in Appendix A. For each augmentation, a randomly selected rule is used to prompt the LLMs to generate the corresponding augmented data.

% \textbf{Problem Verification:} Given the imperfections inherent in augmented data, a process of validation is required. The augmented descriptions are repeated independently into the pre-trained model, and the problem-solving results obtained are compared. If the results are found to be stable, the instance is accepted. Following the conduction of the necessary tests, for each problem, ten augmented instances will be generated, of which approximately seven will be accepted.

% The augmented data set, as a result of the process outlined above, is approximately half a million in size. It will be amalgamated with the original data set to create a more substantial and varied data set for usage in the Autoformulator.


To improve the diversity of our dataset, we use data augmentation to augment the training data. This method generates more non-standard problems compared to a data generator, enhancing the model's generalization performance. We create rules for problem rewriting, semantic substitution, constraint expansion, and numerical augmentation. For each instance, a randomly selected rule is used to prompt the LLMs to generate the corresponding augmented data. The detailed augmentation rules and prompt templates can be found in Appendix \ref{sec:aug_prompt}.

For quality control, we employ a specific LLM $\mathcal{L}$ to sample each augmented description twice independently, followed by the rejection sampling strategy described in Section \ref{sec:rejection}. This process yields approximately 10 qualified augmented datasets for each problem, and this method was applied to augment 50 thousand instances to complement our original dataset.


\subsection{Training the AutoFormulator}
\label{sec:train}
We adopt a supervised fine-tuning (SFT) approach to enhance the AutoFormulator's modeling capabilities. Specifically, we employ the LoRA algorithm \cite{hu2021lora} for efficient parameter-efficient fine-tuning, which significantly reduces memory requirements while maintaining model performance by updating only a small set of adapter parameters. Using the OptMATH-Train dataset $\mathcal{D}_{\mathrm{SFT}}=\{(\mathrm{NL}_{i},\mathrm{MF}_{i},\mathrm{PD}_{i})\}_{i=1}^{N_{\mathrm{Train}}}$, we train the model to generate both mathematical formulations and solver code given problem descriptions. For each training sample, the input consists of the problem description $\mathrm{NL}_{i}$, while the target output is the concatenation of the formulation and solver code: $y_i = [\mathrm{MF}_{i};\mathrm{PD}_{i}]$, where $[;]$ denotes sequence concatenation. The training objective follows the standard sequence-to-sequence loss:
\begin{equation}
\mathcal{L}_{\mathrm{SFT}}(\theta) = -\mathbb{E}_{(p,y)\sim\mathcal{D}_{\mathrm{SFT}}^A}\left[\sum_{t=1}^{|y|}\log P_\theta(y_t|y_{<t},p)\right]
\end{equation}
where $y_t$ represents the token at position $t$ in the target sequence, and $y_{<t}$ denotes all preceding tokens. This approach allows the model to learn the mapping from natural language problem descriptions to both mathematical formulations and solver code within a unified sequence-to-sequence framework.


\section{Experiments}
%In this section, we describe the experimental setup, evaluation metrics, baseline models.

% \begin{table*}[htbp]
%     \centering
%     \caption{Performance Comparison of Models on Different Benchmarks}
%     \label{tab:model_performance}
%     \begin{tabular}{l|l|cccc|c}
%     \toprule
%     Types & Models  & \multicolumn{4}{c|}{Accuracy(pass@1)} & \multirow{2}{*}{AVG} \\
%     \cmidrule{3-6}
%     & & NL4OPT & \makecell{MAMO\\EasyLP} & \makecell{MAMO\\ComplexLP} & \makecell{OptMATH\\Bench} & \\
%     \midrule
%     \multirow{3}{*}{\textbf{Baseline}}
%     & GPT-3.5-turbo & 78.0\% & 79.3\% & 33.2\% & 15.0\% & 51.38\% \\
%     & GPT-4 & 89.0\% & 87.3\% & 49.3\% & 16.6\% & 60.55\% \\
%     & Deepseek-V3 & 95.9\% & 88.3\% & 51.1\% & 32.6\% & 66.98\% \\
%     \midrule
%     \multirow{2}{*}{\textbf{Prompt-based}}
%     & Chain-of-Experts & 64.2\%$^\dagger$ & -- & -- & -- & -- \\
%     & Optimus & 78.8\%$^\dagger$ & -- & -- & -- & -- \\
%     \midrule
%     \multirow{2}{*}{\textbf{Fine-tuning}}
%     & ORLM-LLaMA-3-8B & 85.7\%$^\dagger$ & 82.3\%$^\dagger$ & 37.4\%$^\dagger$ & 0.0\% & 51.35\% \\
%     & \textbf{OptMATH-Qwen2.5-7B} & 94.7\% & 86.5\% & 51.2\%& 24.35\% & 51.35\% \\
%     & \textbf{OptMATH-Qwen2.5-32B} & \textbf{95.9\%} & \textbf{89.9\%} & \textbf{54.1\%} & \textbf{34.7\%} & \textbf{68.65\%} \\
%     \bottomrule
%     \multicolumn{7}{l}{\footnotesize{$\dagger$: Results reported in their original papers.}} \\
%     \end{tabular}
% \end{table*}



\begin{table*}[htbp]
    \centering
    \caption{Performance Comparison of Models on Different Benchmarks}
    \label{tab:model_performance}
    \resizebox{\textwidth}{!}{%  <-- Resizebox here
    \begin{tabular}{l|l|cccc|c|c}
    \toprule
    Types & Models  & \multicolumn{4}{c|}{Accuracy(pass@1)} & \makecell{Macro\\AVG} & \makecell{Micro \\ AVG} \\
    \cmidrule{3-6}
    & & NL4OPT & \makecell{MAMO\\EasyLP} & \makecell{MAMO\\ComplexLP} & \makecell{OptMATH\\Bench} & & \\
    \midrule
    \multirow{3}{*}{\textbf{Baseline}}
    & GPT-3.5-turbo & 78.0\% & 79.3\% & 33.2\% & 15.0\% & 51.4\% & 61.0\% \\
    & GPT-4 & 89.0\% & 87.3\% & 49.3\% & 16.6\% & 60.6\% & 70.9\% \\
    & Deepseek-V3 & 95.9\% & 88.3\% & 51.1\% & 32.6\% & 67.0\% & 75.3\% \\
    \midrule
    \multirow{2}{*}{\textbf{Prompt-based}}
    & Chain-of-Experts & 64.2\%$^\dagger$ & -- & -- & -- & -- & -- \\
    & Optimus & 78.8\%$^\dagger$ & -- & -- & -- & -- & -- \\
    \midrule
    \multirow{2}{*}{\textbf{Fine-tuning}}
    & ORLM-LLaMA-3-8B & 85.7\%$^\dagger$ & 82.3\%$^\dagger$ & 37.4\%$^\dagger$ & 0.0\% & 51.4\% & 64.8\% \\
    & \textbf{OptMATH-Qwen2.5-7B} & 94.7\% & 86.5\% & 51.2\%& 24.4\% & 64.2\% & 73.5\% \\
    & \textbf{OptMATH-Qwen2.5-32B} & \textbf{95.9\%} & \textbf{89.9\%} & \textbf{54.1\%} & \textbf{34.7\%} & \textbf{68.7\%} & \textbf{76.5\%} \\
    \bottomrule
    \multicolumn{8}{l}{\footnotesize{$\dagger$: Results reported in their original papers.}} \\
    \end{tabular}
    } % <-- End Resizebox
\end{table*}

\subsection{Statistics of the OptMATH Dataset}
% Each problem type includes 2,500 generated instances, distributed across five hardness levels. 
First, using our generators, we generated a quality-filtered dataset containing over 600,000 LP files, which span 53 distinct problem types and are distributed across five hardness levels. For more details on the seed data class, please refer to Appendix~\ref{app:seed class}. To ensure computational feasibility, we impose a solving time threshold and employ a feedback pipeline that leverages an LLM to regulate both the complexity and feasibility of the generated instances. Further details on this process are provided in Appendix~\ref{app:instance-gen}. The distribution of file lengths across these LP files is visualized in \figurename~\ref{fig:lp_data_length}. As shown, the lengths range widely from 1,000 to 25,000 characters, capturing a rich variety of problem complexities. The proportions of different lengths are well-balanced, with a concentration on medium difficulty levels (which are already quite challenging compared to other benchmarks) and a gradual decline as the problems become harder. Additionally, the distribution confirms the effectiveness of our complexity control mechanism.
% While there is some overlap between the five hardness levels, each level exhibits a distinct concentration within specific length intervals.  This distribution supports a relatively ``easy-to-learn'' progression, allowing the model to first tackle simpler instances before advancing to the most difficult ones.
\begin{figure}[ht]
    \centering
    % \includegraphics[width=0.95\linewidth]{figure/lp_size_distribution_easy.png}
    \includegraphics[height = 0.6 \columnwidth,width=\columnwidth]{figure/overall_size_distribution.pdf}
    \vspace{-8mm}
    \caption{Distribution of LP file lengths.}
    \label{fig:lp_data_length}
\end{figure}

We further conducted a comparative analysis of problem lengths between OptMATH and other benchmark datasets, with their average lengths shown in Figure \ref{fig:benchmark_comparison}. The analysis reveals that OptMATH presents significantly more complex problem descriptions compared to existing benchmarks. This increased complexity, manifested through longer problem descriptions, poses greater challenges for LLMs, as longer descriptions typically demand enhanced comprehension and reasoning capabilities.
\begin{figure}[htbp]
    \centering
    \includegraphics[height = 0.6 \columnwidth,width=\columnwidth]{figure/description_length.pdf}
    \vspace{-9mm}
    \caption{Question length analysis}
    %: A Comparison of Average Problem Description Length between OptMATH and Other Benchmarks
    \label{fig:benchmark_comparison}
\end{figure}

As shown in \figurename~\ref{fig:Types of the datasets}, OptMATH-Bench has selected a number of representative mathematical optimization problems covering a wide range of application scenarios, including LP, MILP, IP, NLP, SOCP and other optimization problems. For details, please refer to Appendix \ref{appd:benchmark}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{figure/types.png}
    \vspace{-8mm}
    \caption{The proportion of problems in different datasets.}
    \label{fig:Types of the datasets}
\end{figure}

% t-SNE visualization of augmented MIP instances colored by their sources. The projection reveals clear clustering patterns among different problem families, with MAMO\_ComplexLP instances generally showing higher complexity (upper region), OptMATH instances displaying distinct subgroups, and MAMO\_EasyLP and NL4OPT instances exhibiting more continuous complexity variations. 
To visualize the distribution of different benchmarks and OptMATH dataset, we project their high-dimensional embeddings onto a 2D space using t-SNE. As shown in Figure~\ref{fig:umap_viz}, the instances from different sources form distinct clusters, suggesting that OptMATH effectively captures the diversity of different problem families. It can be observed that OptMATH surrounds the area of other benchmarks. This explains the improvement on various benchmarks obtained by training on OptMATH-Train.
% Notably, MAMO\_ComplexLP instances (blue) tend to occupy the upper regions, while OptMATH instances (red) show multiple separate clusters, indicating their diverse nature. The MAMO\_EasyLP (pink) and NL4OPT (cyan) instances demonstrate more continuous distributions, reflecting gradual variations in their complexity levels. 

\begin{figure}[htbp]
    \centering
    \includegraphics[height = 0.75 \columnwidth,width=\columnwidth]{figure/tsne_visualization_all_5000.pdf}
    \vspace{-8mm}
    \caption{Visualization of OptMATH and other benchmarks.}
    \label{fig:umap_viz}
\end{figure}

\subsection{Autoformulation}
\textbf{Evaluation Benchmarks and Metrics.} We evaluate our fine-tuned model on three benchmarks: NL4OPT\cite{ramamonjison_nl4opt_2023}, MAMO\cite{huang_mamo_2024}, and our newly constructed OptMATH-Bench. Detailed descriptions of these benchmarks can be found in Appendix \ref{appd:benchmark}. We use pass@1 accuracy as the evaluation metric, which specifically measures whether the optimal value obtained by the generated code matches the ground truth provided in the benchmark. The detailed matching criteria are described in Appendix \ref{appd:benchmark}. Notably, since prompt design can significantly impact model performance, we maintain consistency by using the same prompt template across all model evaluations (see Appendix \ref{appd:baseline_prompt} for details).Additionally, comprehensive details about our fine-tuning procedure are provided in Appendix \ref{appd:sft}.

\textbf{Main Results.} The primary results are presented in Table \ref{tab:model_performance}. First, our best-performing model, OptMATH-Qwen2.5-32B, achieves superior performance across all benchmarks, surpassing proprietary large language models such as GPT-3.5-Turbo\cite{brown2020language}, GPT4\cite{Achiam2023GPT4TR}, and Deepseek-V3\cite{liu2024deepseek}, despite these models having tens of times more parameters. Furthermore, our OptMATH-Qwen2.5-7B outperforms ORLM-LLaMA-3-8B, a model of comparable size, on all benchmarks and demonstrates performance only marginally inferior to Deepseek-V3. Collectively, these results demonstrate that training with OptMATH-Train significantly enhances the model's optimization modeling capabilities.



% \begin{figure}[htbp]
% \centering
% \includegraphics[height = 0.7 \columnwidth,width=\columnwidth]{figure/scaling_law_model_size.pdf}
% \vspace{-10mm}
% \caption{Scaling behavior of Qwen2.5 models.}
% \label{fig:scaling_curve}
% \end{figure}
\begin{figure}[tbp]
\centering
\includegraphics[height=0.7\columnwidth,width=\columnwidth]{figure/scaling_law_model_size_1.pdf}
\vspace{-10mm}
\caption{Scaling behavior of Qwen2.5 models (0.5B-32B).}
\label{fig:scaling_curve}
\end{figure}

\textbf{Ablation Study on Model Size.}  To investigate the effectiveness of OptMATH training across different model scales, we conducted experiments using Qwen2.5 models ranging from 0.5B to 32B parameters. Due to computational constraints, we used a randomly sampled subset of 100,000 training examples. As shown in Figure \ref{fig:scaling_curve}, all models exhibit substantial performance improvements after OptMATH-Train fine-tuning. Notably, we observe that while larger models generally achieve better absolute performance, the relative performance gains from OptMATH-Train training demonstrate diminishing returns as model size increases.

\textbf{Ablation Study on Data Size.} Figure \ref{fig:scaling_data_curve} presents our comprehensive analysis of how varying amounts of training data influence the performance of Qwen2.5-1.5B model on OptMATH-Train. We observed significant improvements in the model’s optimization modeling capabilities even with only a small fraction of the OptMATH-Train dataset. As we gradually increased the size of the training data, the performance gains became less pronounced, exhibiting a typical pattern of diminishing returns. Larger models exhibit smoother learning curves, while smaller models demonstrate greater sensitivity to additional training data, indicating higher potential for improvement through data scaling (detailed results across model sizes can be found in the Appendix \ref{appd:scale_size}).



\begin{figure}[tbp]
\centering
% \includegraphics[width=1\columnwidth]{figure/scaling_law_model_size.pdf}
\includegraphics[height = 0.75 \columnwidth,width=\columnwidth]{figure/benchmark_accuracy_1.5B1.pdf}
\vspace{-8mm}
\caption{Accuracy of Qwen2.5-1.5B within one training epoch.}
\label{fig:scaling_data_curve}
\end{figure}

% \begin{figure}[htbp]
% \centering
% % \includegraphics[width=1\columnwidth]{figure/scaling_law_model_size.pdf}
% \includegraphics[width=\columnwidth]{figure/benchmark_accuracy_1.5B1.pdf}
% \caption{Scaling behavior of Qwen2.5-1.5B Accuracy Within One Training Epoch.}
% \label{fig:scaling_data_curve}
% \end{figure}

\section{Conclusion}
In this paper, we introduce a bidirectional data synthesis framework for optimization modeling. It utilizes a two-step process: reverse data generation, where LLMs refine themselves in a loop to create diverse datasets, and autoformulation, where a specialized model translates natural language into mathematical representations. Our evaluation on NL4OPT, MAMO and OptMATH-Benchmarks demonstrated AutoFormulator's superior performance in generating accurate and well-formed optimization models compared to baseline approaches. 


\section*{Impact Statements}
% This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here.

This study introduces OptMATH, a dataset for optimization modeling, comprising a large-scale training set (OptMATH-Train) and a challenging benchmark (OptMATH-Bench). OptMATH has the potential to democratize optimization by enabling those without expertise to translate real-world problems into mathematical formulations. The OptMATH-Train dataset will significantly improve LLMs' ability to understand and model optimization problems. Furthermore, OptMATH's structured data facilitates the integration of optimization with advanced AI techniques like reinforcement learning, Monte Carlo Tree Search. Additionally, OptMATH-Bench provides a standardized benchmark for evaluating optimization modeling systems, pushing the boundaries of LLM capabilities. Ultimately, OptMATH can improve efficiency and decision-making across industries.

% This study introduces a scalable framework for synthesizing optimization problems, along with OptMATH, a dataset for optimization modeling that comprises a large-scale training set (OptMATH-Train) and a challenging benchmark (OptMATH-Bench). The proposed framework allows for further dataset expansion when computational resources are available, and has the potential to democratize optimization by enabling those without expertise to translate real-world problems into mathematical formulations.

% In our paper, we utilized the OptMATH-Train dataset for fine-tuning, which has already demonstrated a significant improvement in the model's optimization modeling capabilities. Beyond this, our dataset holds the potential for further exploration by combining it with process-supervision approaches, such as generating process supervision datasets through Monte Carlo Tree Search (MCTS), as suggested in \cite{wang2024math}, to train reward models. With preference data and a well-trained reward model, it is possible to adopt reinforcement learning methods, similar to the strategies outlined in DeepSeek-R1 \cite{guo2025deepseek}, to further enhance the model's reasoning and optimization modeling capabilities. Moreover, the reward model could serve as a critical component, providing reward signals within MCTS-based modeling frameworks, as proposed in \cite{astorga_autoformulation_2024}.  

% Additionally, OptMATH-Bench provides a standardized benchmark for evaluating optimization modeling systems, pushing the boundaries of LLM capabilities. Ultimately, OptMATH can improve efficiency and decision-making across industries.

% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}


{\small
% \bibliographystyle{alpha}
\bibliographystyle{plain}
\bibliography{ref}
}
% \bibliographystyle{icml2025}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\newpage

\section{Dataset}

\subsection{An Introduction of Different Benchmarks}
\label{appd:benchmark}
We evaluated the modeling capabilities of our trained model on NL4OPT, MAMO, and our self-constructed dataset, OptMATH-Bench. Both MAMO and OptMATH-Bench have ground truth annotations, while the original NL4OPT dataset lacks ground truth. To address this, we utilized a LLM to generate initial ground truth for NL4OPT, followed by expert validation and correction for each data. As a result, we obtained the ground truth for the NL4OPT dataset. In addition, we have also analyzed these datasets in terms of problem scenarios and problem model types, and the distribution of scenarios for each dataset is shown in Figure \ref{fig:Scenarios of the datasets}, the distribution of problem types for each dataset is shown in Figure \ref{fig:Types of the datasets}.

\begin{figure}[htp]
    \centering
    \includegraphics[width=1\linewidth]{figure/scenarios.png}
    \caption{Scenarios distribution of the datasets.}
    \label{fig:Scenarios of the datasets}
\end{figure}

\textbf{NL4OPT}\cite{ramamonjison_nl4opt_2023} is a curated dataset derived from the NL4OPT Competition, where participants were tasked with developing automated methods to convert natural language problem descriptions into solver-ready code. This dataset primarily focuses on LP (Linear Programming) problems across various contexts, though the underlying mathematical models are relatively uniform, with more complex MIPS (Mixed Integer Programming and Scheduling) problems notably absent. For our experiments, we selected the test set from this dataset, filtered out low-quality examples, and retained a total of 245 high-quality instances.

\textbf{MAMO}\cite{huang_mamo_2024} introduces a novel optimization dataset to assess the modeling capabilities of LLMs. The dataset is divided into two main components, \textit{Easy\_LP} and \textit{Complex\_LP}, containing 652 and 211 instances, respectively. These components cover both LP and MILP problems, capturing a wide range of real-life scenarios. However, the dataset does not include any nonlinear programming (NLP) problems.

\textbf{OptMATH-Bench.} As shown in Table \ref{tab:model_performance}, while our fine-tuned model achieves remarkable performance on NL4OPT and \textit{MAMO\_EasyLP}, these datasets alone are insufficient to comprehensively evaluate the model's optimization modeling capabilities. Moreover, both NL4OPT and MAMO datasets are limited to linear programming problems, making them less representative of the broader optimization landscape. To address this limitation, we constructed a more challenging dataset for large models, while also expanding the diversity of problem types—\textbf{OptMATH-Bench}. This dataset includes a carefully curated selection of representative mathematical optimization problems that span a broad range of application scenarios, covering LP, MILP, IP, NLP, SOCP, and other common optimization problems. Additionally, the problems in OptMATH-Bench are inherently challenging, making them effective in distinguishing the modeling capabilities of the model. 

During evaluation, we observed that certain ambiguities in problem statements could cause the LLM to struggle in determining whether a variable is integer or continuous. To address this, we applied a rule-based substitution approach: as long as the optimal solution derived under either assumption (integer or continuous variable) matches the ground truth, we consider it a pass. To determine whether the optimal values are equivalent, we use the following formula:  

$$
\frac{|y_{pred} - y_{label}|}{|y_{label}| + 1} < \epsilon,
$$  

where $\epsilon$ is set to 1e-6.  



% \begin{figure}[htp]
%     \centering
%     \includegraphics[width=1\linewidth]{figure/types.png}
%     \caption{Types distribution of the datasets.}
%     \label{fig:Types of the datasets}
% \end{figure}

\subsection{Seed Classes}
Our seed problem classes were curated by drawing from MIPLIB instances and integrating insights from both Chain-of-Experts\cite{xiao_chain--experts_2024} and peer-reviewed literature. For each instance, we conducted an in-depth analysis of its structure, starting from the problem description to identify its broader optimization category and further refining it into specific subclasses. To ensure theoretical accuracy, we consulted literature that provided detailed descriptions of these optimization subclasses. Based on these references, we formulated the mathematical representation of each subclass, systematically outlining sets (where applicable), parameters, decision variables, objective functions, and constraints. This step aimed to establish an abstract mathematical framework rather than focusing on specific instances.

We organized comprehensive metadata for each problem class in a structured \texttt{metadata.json} file, encompassing subclass names, references, reference links, and LaTeX-formulated mathematical expressions. An example of this metadata structure is provided in Appendix~\ref{appd:metadata}. This systematic documentation not only ensures clarity but also facilitates dataset utilization and future extensions.

Next, we focused on generating new problem instances. We implemented a custom Python class, \texttt{Generator()}, in \texttt{generator.py}, which contained a step-by-step algorithm to create instances of the identified subclasses (an example is provided in Appendix~\ref{appd:generator}). The input parameters and outputs were explicitly defined, with detailed specifications for each parameter's type and valid range documented in \texttt{README.txt}. We validated the generator by running \texttt{test\_generator()} with default parameters to ensure the produced instances were both mathematically valid and practically meaningful.

Through this systematic and meticulous approach, we constructed a high-quality dataset of Problem Description (PD) generators that lays a solid foundation for generating natural language descriptions of optimization problems through Backtranslation Pipeline. This dataset is designed to be versatile and scalable, making it suitable for a wide range of applications in optimization research and practice.
\label{app:seed class}
\begin{longtable}{|p{5.5cm}|p{5cm}|p{0.7cm}|p{4.3cm}|} 
\hline
\textbf{Main Class} & \textbf{Problem Class} & \textbf{Num} & \textbf{Reference} \\
\hline
\endfirsthead

\hline
\textbf{Main Class} & \textbf{Problem Class} & \textbf{Num} & \textbf{Reference} \\
\hline
\endhead
Assignment and Resource Allocation Optimization & Car Selection Problem & 1 &  \cite{doi:10.1137/1.9781611972238} \\
& Contract Allocation Problem & 1 &  \cite{wiki:Supply_chain_management} \\
& Assignment Problem & 2 &  \cite{https://doi.org/10.1002/nav.3800020109} \\
& Structure-Based Assignment Problem & 1 &  \cite{doi:10.1137/1.9781611972238} \\
& Team Formation Problem & 1 &  \cite{gurobi_optimization_modeling} \\
& Military Personnel Deployment Problem & 1 &  \cite{9d63adbe-bed6-3e3d-96d5-3bc02e31f03e} \\
\hline
Combinatorial Optimization & Knapsack Problem & 1 &  \cite{10.5555/98124} \\
& Market Share Optimization Problem & 1 &  \cite{cooper1993marketshare} \\
& Set Multi-Cover Problem & 1 &  \cite{winston2004operations} \\
& Set Cover Problem & 1 &  \cite{caprara2000algorithms} \\
\hline
Cutting and Packing Optimization & Bin Packing Problem & 1 &  \cite{Garey1981} \\
& Blending Problem & 1 &  \cite{Zieyel1988OperationsR} \\
& Cutting Stock Problem & 1 &  \cite{doi:10.1287/opre.9.6.849} \\
\hline
Domain-Specific Optimization & Diet Problem & 3 &  \cite{doi:10.1287/opre.49.1.1.11187} \\
& Unit Commitment Problem & 1 &  \cite{1295033} \\
& Farm Planning Problem & 1 &  \cite{hazell1986mathematical} \\
\hline
Facility Location Optimization & Facility Location Problem & 2 &  \cite{doi:10.1287/opre.19.6.1363} \\
& Capacitated Facility Location Problem & 2 &  \cite{daskin1995network} \\
& Transportation Problem, Airline Industry Resource Allocation & 1 &  \cite{toth2002vehicle} \\
& Facility Dispersion Problem & 2 &  \cite{KUBY1988792} \\
\hline
Financial and Revenue Optimization & Portfolio Optimization Problem & 1 &  \cite{e5a1bb8f-41b7-35c6-95cd-8b366d3e99bc} \\
& Profit Maximization Problem & 1 &  \cite{hillier2014introduction} \\
& Revenue Management Problem & 1 &  \cite{chen2022improved} \\
& Revenue Maximization Problem & 1 &  \cite{weatherford1997forecasting} \\
\hline
Network Flow Optimization
& Multi-Commodity Capacitated Network Design Problem & 1 &  \cite{Gendron1999} \\
& Multi-Commodity Transportation Problem
& 1 &  \cite{smith_1994} \\
& Minimum Cost Flow Problem
& 1 &  \cite{klein_1967} \\
& Multi-Commodity Network Flow Problem
& 1 &  \cite{smith_1994} \\
& Network Flow Problem
& 1 &  \cite{ford_fulkerson_1956} \\
& Static Line Planning Problem
& 1 &  \cite{schobel_2012} \\
& Supply Chain Optimization
& 1 &  \cite{cordeau_2006} \\
& Network Optimization
& 1 &  \cite{Bertsekas1998NetworkO} \\
\hline
Production Planning and Scheduling Optimization
& Capacitated Lot-Sizing Problem & 1 &  \cite{florian_1971} \\
& Factory Planning Problem
& 1 &  \cite{pinedo_2022} \\
& Flow Shop Scheduling Problem
 & 1 &  \cite{RAJENDRAN1995540} \\
& Job Shop Scheduling Problem
& 1 &  \cite{5bb100fb-1a0d-3c34-b069-4ed9e5260401} \\
& Discrete Lot-Sizing and Scheduling Problem
& 1 &  \cite{FLEISCHMANN1990337} \\
& Production Planning Problem
& 3 &  \cite{herrmann_2006} \\
& Lot-Sizing Problem
& 1 &  \cite{DREXL1997221} \\
\hline
Transportation and Routing Optimization
& Aircraft Assignment Problem & 1 &  \cite{abara_1989} \\
& Aircraft Landing Problem
& 1 &  \cite{beasley_2000} \\
& Transportation Problem
 & 2 &  \cite{STEADIESEIFI20141} \\
& Traveling Salesman Problem
& 1 &  \cite{dantzig_1954} \\
& Operations Optimization
& 1 &  \cite{golden_2008} \\
& Capacitated Vehicle Routing Problem with Time Windows
& 3 &  \cite{Solomon1987AlgorithmsFT} \\
\hline
\end{longtable}

\subsection{OptMATH-Train}
\label{appd:OptMATH-Train}
The OptMATH-Train dataset consists of over 150k reverse-generated samples and 50k augmented instances, forming a comprehensive collection of optimization problems. The dataset encompasses a rich variety of real-world application scenarios. As illustrated in \figurename ~\ref{fig:scenario_dist}, the dataset covers over 10 major application domains spanning across both core business sectors and specialized industries, demonstrating extensive coverage of real-world optimization scenarios. The substantial proportions in logistics, supply chain, and manufacturing ensure robust representation of primary industrial applications, while the balanced inclusion of sectors like transportation, energy, and finance provides comprehensive coverage of specialized use cases. This thoughtful allocation of problems across different domains not only prevents data concentration but also maintains sufficient samples for each sector, enabling effective model training and evaluation.

The sequence length distribution of OptMATH-Train, as shown in \figurename~\ref{fig:length_dist}, exhibits a well-balanced profile for both input and output sequences. The distribution approximates a normal distribution with mild right-skewness, centered around 5,000 characters, demonstrating a natural variation in problem complexity. This balanced distribution pattern is particularly advantageous for model training, as it ensures sufficient context length for complex problem representation while maintaining computational efficiency. Furthermore, the moderate right-skewness encompasses challenging cases with extended sequences, which is essential for developing robust models capable of handling sophisticated optimization problems that require comprehensive reasoning and detailed solution steps.

\begin{figure}[tbp] 
\centering \begin{minipage}[t]{0.48\textwidth} \centering \includegraphics[width=\linewidth]{figure/proprtion.jpg} \caption{Distribution of Application Scenarios across OptMATH-Train} \label{fig:scenario_dist} \end{minipage} \hfill \begin{minipage}[t]{0.48\textwidth} \centering \includegraphics[width=\linewidth]{figure/length_distribution.pdf} \caption{Sequence Length Distribution of OptMATH-Train} \label{fig:length_dist} \end{minipage} 
\end{figure}

\section{Details of Instance Generation}
\label{app:instance-gen}

\subsection{An Example for Measuring the Complexity}
\label{sec:measure-complexity}
Let binary variables \( y_1, y_2 \in \{0,1\} \) indicate whether products 1 and 2 are produced, integer variables \( x_1, x_2 \in \mathbb{Z}^+ \) represent production quantities, and a continuous variable \( z \geq 0 \) denote total cost. The objective function minimizes total operational costs:  
$\min \; z + 10y_1 + 8y_2$. The constraints span four categories: First, linear constraints include the resource limitation \( 2x_1 + 3x_2 \leq 100 \) and market demand bounds \( x_1 \leq 50 \), \( x_2 \leq 30 \). Second, indicator constraints using the Big-M method (with \( M=100 \)) enforce minimum production levels when activated: \( y_1 = 1 \implies x_1 \geq 5 \) is reformulated as \( x_1 \geq 5 - 100(1 - y_1) \), and analogously for \( y_2 = 1 \implies x_2 \geq 3 \). Third, a quadratic constraint \( z \geq 0.5x_1^2 + 0.3x_2^2 \) integrates inventory costs into the objective. Finally, a general nonlinear constraint \( x_1 e^{x_2} \leq 100 \) captures efficiency coupling between products.  

To compute the complexity score \( S(\mathrm{PD}) \), we identify: 2 binary variables, 2 integer variables, and 1 continuous variable; 3 linear constraints, 2 indicator constraints, 1 quadratic constraint, and 1 nonlinear constraint. The Big-M factor frequency is \( f_{\text{BigM}}=2 \), while the average number of terms per expression \( \overline{L_{\text{expr}}} \approx 2.71 \) is derived from structural analysis of constraints and the objective. With all weights set to 1, the total complexity score becomes \( S = 16.71 \). This example demonstrates how modeling choices (e.g., introducing nonlinear terms, Big-M parameterization) directly influence the score, providing a quantitative framework for assessing model complexity.

\subsection{An Overview of the Generated LP Files}
The average lengths of LP files for different difficulty levels are illustrated in Figure \ref{fig:lp_data_length_by_difficulty}. We define the complexity thresholds for the five difficulty levels—easy, medium\_easy, medium, medium\_hard, and hard—as [25, 75], [50, 100], [75, 125], [100, 150], and [125, 175], respectively. The results demonstrate that our feedback-driven problem data generation approach is effective. The average length of the generated LP files across the five difficulty levels is presented in Figure \ref{fig:lp_data_length_by_problem}, categorized by seed data name. All generated LP files are feasible and possess optimal solutions.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\linewidth]{figure/average_size_by_difficulty.pdf}
    \caption{Distribution of LP file lengths across generated instances by difficulty levels.}
    \label{fig:lp_data_length_by_difficulty}
\end{figure}

\begin{figure}[ht]
    \centering
    % \includegraphics[width=\linewidth]{figure/average_lp_size_all_difficulties.pdf}
    \includegraphics[width=\linewidth]{figure/average_lp_size_all_difficulties.png}
    \caption{Distribution of LP file lengths across generated instances by problem types.}
    \label{fig:lp_data_length_by_problem}
\end{figure}

\section{Details of Backtranslation}


\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{figure/backtranslation7.pdf}
    \caption{An example of backtranslation: transforming mathematical formulations and LP files into natural language descriptions of optimization problems. The process transforms formal mathematical notation and concrete data into human-readable problem descriptions.}
    \label{fig:backtranslation}
\end{figure}

\subsection{Backtranslation Pipeline} \label{appd:back_pipeline} 
In our reverse generation pipeline, we employ Deepseek-V3\cite{liu2024deepseek} as our foundation model and configure its temperature parameter to 0.8 to enhance the diversity of generated problems. Furthermore, to achieve rich contextual diversity, we implement a random scenario assignment mechanism during the Initial Generate phase. This mechanism directs the LLM to synthesize problems that optimally integrate the mathematical characteristics with the designated scenario context. The detailed prompt is elaborated in Section \ref{appd:bs}.

Through this backtranslation process, we initially generated approximately 120,000 easy optimization problems. As shown in Figure \ref{fig:nl_length_dist}, the length distribution of problem descriptions exhibits a right-skewed pattern, with most problems containing 2,000 to 5,000 characters. After applying rejection sampling, around 40\% of the generated problems were filtered out while maintaining a similar distribution pattern. This consistency in distribution before and after filtering suggests that our quality control process effectively removes low-quality samples without introducing length-related biases, ensuring the retained problems maintain natural and appropriate descriptive lengths.
After multi-stage refinement including semantic verification and difficulty calibration, the pipeline ultimately produced 150,000 rigorously validated optimization problems. Together with 50,000 augmented instances, this curated collection forms our OptMATH-Train dataset, where each instance demonstrates: (1) Contextual alignment between mathematical formulations and real-world scenarios, (2) Controllable complexity levels matching specified difficulty tiers, and (3) Natural language expressions adhering to authentic problem-solving discourse patterns. The hierarchical quality assurance framework ensures the dataset's applicability for both educational interventions and benchmarking mathematical reasoning systems.


\subsection{Ablation Study on the Impact of Self-Refine Iterations}
\label{appd:T}

To validate the effectiveness of each step in our backtranslation pipeline, we conducted comprehensive ablation studies. We first compared the accuracy between using only the Generate step versus implementing the complete pipeline with Generate, Self-criticize, and Self-refine steps. To investigate the impact of parameter $T$ on the acceptance rate of rejection sampling, we randomly selected 500 instances for evaluation, with results shown in \figurename ~\ref{fig:T_fig}. The results demonstrate that our Self-Refine loop ($T \geq 1$) consistently outperforms direct generation ($T = 0$) in terms of acceptance rate. While there are some fluctuations in performance across different $T$ values, possibly due to the inherent hallucination tendencies of large language models, we observe that setting $T = 1$ achieves a satisfactory acceptance rate of 61.56\%. Considering the trade-off between performance and computational efficiency (token usage), we adopt $T = 1$ in our final data synthesis process.

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.8\columnwidth]{figure/Max_iter_ac.pdf}
%     \label{fig:T}
% \end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.8\columnwidth]{description_length.png}
%     \caption{Distribution of Natural Language Description Lengths}
%     \label{fig:nl_length_dist}
% \end{figure}

\begin{figure}[ht]
    \centering
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/Max_iter_ac_bar_chart.pdf}
        \caption{Acceptance Rate vs. Maximum Iteration of Self-Refine Loop. The bar chart illustrates the acceptance rate achieved at different maximum iteration limits.}
        \label{fig:T_fig}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figure/Optmath-12w-easy_length_comparison.pdf}
        \caption{Distribution of Natural Language Description Lengths for Easy Problems in OptMATH-Train Dataset. The histogram compares the length distribution before and after rejection sampling, showing the quality filtering process.}
        \label{fig:nl_length_dist}
    \end{minipage}
\end{figure}








\section{Details of AutoFormulation}

\subsection{CoT Instructions of AutoFormulation}
\label{appd:cot}

To support comprehensive mathematical modeling capabilities, we developed a diverse set of CoT instructions, which are detailed in Section \ref{appd:cot_instruction}. These instructions vary in their decomposition approaches, intermediate reasoning steps, and presentation formats, providing multiple pathways for problem formulation. In \figurename ~\ref{fig:Formulation}, we present one representative formulation pattern from our instruction set. This format includes three key components: a general mathematical formulation with standard notation, a detailed instance-specific formulation with complete parameter specifications, and the corresponding Python implementation using Gurobi. However, this represents just one of many possible formulation styles. Other formats in our instruction set may use different ordering of steps, alternative notation systems, or various levels of mathematical abstraction. The diversity in formulation patterns ensures that our dataset captures a wide range of valid mathematical modeling approaches while maintaining logical coherence and mathematical correctness.
\begin{figure*}[htp]
    \centering
    \includegraphics[width=0.95\linewidth]{Formulation3.pdf}
    \caption{An Example of AutoFormulation}
    \label{fig:Formulation}
\end{figure*}
\subsection{Ablation Study on Augmentation}
As mentioned in the previous section, the purpose of data augmentation is to increase the diversity of the dataset and generate more non-standard problems, which can help the fine-tuned model to solve more difficult problems. We use 50k raw data, augmented data and mixed data (50\% raw data and 50\% augmented data) for fine-tuning training on the Qwen2.5-7B model, respectively, and the results show in Table \ref{tab:OriVSAug} that the model fine-tuned with raw data performs better in solving relatively simple problems, augmented data performs better in solving difficult problems, and mixed data combines the advantages of the above two very well, being the best in terms of average accuracy across the four types of test sets.

\begin{table*}[ht]
    \centering 
    \setlength{\tabcolsep}{6pt} 
    \renewcommand{\arraystretch}{1.3} 
        \caption{Comparison of Original Data and Augmentation Data in Training Models.}
    \begin{tabular}{@{} lcccccc @{}}     
    \toprule
    Types & NL4OPT & \makecell{MAMO\\EasyLP} & \makecell{MAMO\\ComplexLP} & \makecell{OptMATH\\Bench}& \makecell{Micro\\Avg} & \makecell{Macro\\Avg} \\ 
    \midrule
    Without Augmentation & 86.9\% & \textbf{88.0\%} & 44.5\% & 31.1\% & 72.1\% & 62.3\% \\
    Without Original & 82.9\% & 85.5\% & 44.7\% & 23.6\% & 69.2\% & 59.2\% \\ 
    Mixture of Augmentation and Original & \textbf{87.3}\% & 87.7\% & \textbf{48.1\%} & \textbf{33.3\%} & \textbf{73.1\%} & \textbf{64.1\% }\\ 
    \bottomrule
    \end{tabular}
    \label{tab:OriVSAug}
\end{table*}


\subsection{SFT}
\label{appd:sft}
We employ the LlamaFactory framework for fine-tuning \cite{zheng2024llamafactory}. We select the Qwen2.5 series (0.5B$\sim$32B) as our base models \cite{yang2024qwen2}, and the hyperparameters are generally set as follows: initial learning rate of 1e-4, 1$\sim$3 epochs, LoRA rank of 32, LoRA alpha of 32, and LoRA dropout of 0.1. While there are minor variations in hyperparameters across different experiments, the overall settings remain similar and we omit these details for brevity. Notably, as illustrated in our framework diagram \ref{fig:overview}, the entire AutoFormulator training process is an iterative cycle. The Rejection Sampling in Step 2 relies on AutoFormulator's modeling capabilities - stronger modeling abilities lead to higher pass rates and better data quality. Similarly, the data augmentation phase depends on AutoFormulator's modeling competence. Higher quality data, in turn, results in a more capable Formulator through training.Through this systematic model fine-tuning and data augmentation approach, we have developed a dynamically evolving fine-tuning framework. This framework not only accurately transforms natural language descriptions into mathematical formulations and solver code but, more importantly, establishes a self-improving data flywheel mechanism. This positive feedback loop enables the AutoFormulator system to continuously enhance its capability in handling complex optimization problems through ongoing learning and self-optimization, forming a virtuous growth cycle.


\subsection{Detailed Ablation Studies on Model Size and Data Size}
\label{appd:scale_size}



To investigate the impact of model capacity and training data volume on optimization modeling performance, we conducted two sets of experiments using OptMATH-Train. For the model size study in Figure \ref{fig:scaling_curve} and Figure \ref{fig:various benchmarks}, we compare the performance of baseline and finetuned Qwen2.5 models ranging from 0.5B to 32B parameters. For the data scaling analysis in Figure  \ref{fig:scaling_data_curve} and Figure \ref{fig:0.5B-14B}, we track the accuracy progression within the first training epoch across different model sizes, using varying proportions of the training data.

The model size experiments reveal distinct scaling patterns across benchmarks. On NL4OPT, the performance improves from 12.7\% (0.5B) to 96.7\% (32B), showing particularly rapid gains in the 0.5B-3B range. For MAMO EasyLP, we observe similar but more moderate improvements, with accuracy increasing from 31.9\% to 90.5\%. However, on more challenging benchmarks like MAMO ComplexLP and OptMATH-Bench, even the largest models achieve relatively modest gains, reaching 52.6\% and 30.6\% respectively at 32B parameters.

The comparison between baseline and OptMATH-Train finetuned models reveals interesting patterns across different model scales. For simpler benchmarks like NL4OPT and MAMO EasyLP, while the performance gap narrows with increased model size, OptMATH-Train finetuning still provides consistent improvements even for the largest models. More notably, on complex benchmarks such as MAMO ComplexLP and OptMATH-Bench, models finetuned on OptMATH-Train demonstrate substantial performance gains across all model sizes, highlighting the effectiveness of our training dataset in enhancing models' capabilities for challenging optimization problems.

The data scaling analysis reveals distinct learning dynamics across model sizes. Smaller models (0.5B, 1.5B, 3B) exhibit higher initial performance variance during training, while larger models (7B, 14B) demonstrate more stable learning curves from the outset. Notably, all model sizes achieve relative performance stability after utilizing approximately 40\% of the training data, though the absolute performance levels differ significantly. The 3B model, for instance, maintains consistently higher performance across all benchmarks while requiring a similar proportion of training data to reach stability.

This efficient data utilization pattern holds true across all benchmarks, regardless of their complexity levels. Whether for the relatively straightforward tasks in NL4OPT or the more challenging problems in OptMATH-Bench, models typically converge to their peak performance using around 40\% of the available training data. The remaining 60\% of the data contributes primarily to fine-tuning and minor performance adjustments rather than substantial improvements.

\begin{table}[tbp]
\centering
\caption{Performance comparison of Qwen2.5 models of varying sizes on mathematical optimization tasks. The percentages in parentheses indicate improvements after fine-tuning.}
\label{tab:model_scaling}
\resizebox{\textwidth}{!}{
\begin{tabular}{lccccc}
\toprule
Models & NL4OPT & MAMO EasyLP & MAMO ComplexLP & OptMATH-Bench & Micro AVG \\
\midrule
Qwen2.5-0.5B & 0.00\% & 0.15\% & 0.00\% & 0.00\% & 0.08\% \\
Qwen2.5-0.5B(Finetuned) & 12.65\% (↑12.65\%) & 31.90\% (↑31.75\%) & 16.59\% (↑16.59\%) & 15.03\% (↑15.03\%) & 23.29\% (↑23.21\%) \\
\midrule
Qwen2.5-1.5B & 0.00\% & 2.15\% & 0.95\% & 0.00\% & 1.23\% \\
Qwen2.5-1.5B(Finetuned) & 46.12\% (↑46.12\%) & 68.10\% (↑65.95\%) & 22.75\% (↑21.80\%) & 18.65\% (↑18.65\%) & 49.27\% (↑48.04\%) \\
\midrule
Qwen2.5-3B & 67.35\% & 65.18\% & 16.11\% & 0.52\% & 48.04\% \\
Qwen2.5-3B(Finetuned) & 68.57\% (↑1.22\%) & 80.98\% (↑15.80\%) & 25.59\% (↑9.48\%) & 15.03\% (↑14.51\%) & 59.88\% (↑11.84\%) \\
\midrule
Qwen2.5-7B & 86.94\% & 83.59\% & 21.80\% & 1.55\% & 62.03\% \\
Qwen2.5-7B(Finetuned) & 86.94\%  & 89.42\% (↑5.83\%) & 48.82\% (↑27.02\%) & 30.05\% (↑28.50\%) & 73.56\% (↑11.53\%) \\
\midrule
Qwen2.5-14B & 93.47\% & 82.52\% & 42.65\% & 14.51\% & 68.02\% \\
Qwen2.5-14B(Finetuned) & 95.51\% (↑2.04\%) & 90.49\% (↑7.97\%) & 51.18\% (↑8.53\%) & 29.53\% (↑15.02\%) & 76.02\% (↑8.00\%) \\
\midrule
Qwen2.5-32B & 92.65\% & 82.21\% & 44.55\% & 9.33\% & 67.26\% \\
Qwen2.5-32B(Finetuned) & 96.73\% (↑4.08\%) & 88.04\% (↑5.83\%) & 56.4\% (↑11.85\%) & 36.27\% (↑26.94\%) & 76.86\% (↑9.60\%) \\
\bottomrule
\end{tabular}
}
\end{table}

\begin{figure}[htbp]
    \centering
    \subfigure[NL4OPT]{
        \includegraphics[height = 0.33 \columnwidth,width=0.45\columnwidth]{figure/scaling_law_model_size_NL4OPT_1.pdf}
    }
    \subfigure[MAMO EasyLP]{
        \includegraphics[height = 0.33 \columnwidth,width=0.45\columnwidth]{figure/scaling_law_model_size_EasyLP_1.pdf}
    }
    
    \subfigure[MAMO ComplexLP]{
        \includegraphics[height = 0.33 \columnwidth,width=0.45\columnwidth]{figure/scaling_law_model_size_ComplexLP_1.pdf}
    }
    \subfigure[OptMATH-Bench]{
        \includegraphics[height = 0.33 \columnwidth,width=0.45\columnwidth]{figure/scaling_law_model_size_OptMATH_1.pdf}
    }
    \caption{Scaling behavior of Qwen2.5 models (0.5B-32B) on various benchmarks.}
    \label{fig:various benchmarks}
\end{figure}

\begin{figure*}[htbp]
    \centering
    \subfigure[Qwen2.5-0.5B]{
        \includegraphics[height = 0.27 \columnwidth,width=0.45\columnwidth]{figure/benchmark_accuracy_0.5B.pdf}
    }
    \subfigure[Qwen2.5-3B]{
        \includegraphics[height = 0.27 \columnwidth,width=0.45\columnwidth]{figure/benchmark_accuracy_3B.pdf}
    }
    
    \subfigure[Qwen2.5-7B]{
        \includegraphics[height = 0.27 \columnwidth,width=0.45\columnwidth]{figure/benchmark_accuracy_7B.pdf}
    }
    \subfigure[Qwen2.5-14B]{
        \includegraphics[height = 0.27 \columnwidth,width=0.45\columnwidth]{figure/benchmark_accuracy_14B.pdf}
    }
    \caption{Scaling behavior of Qwen2.5-0.5B, Qwen2.5-3B, Qwen2.5-7B and Qwen2.5-14B Accuracy Within One Training Epoch.}
    \label{fig:0.5B-14B}
\end{figure*}







\newpage
\section{Prompt Templates}
 In this section, we present all the important prompt templates. Due to space constraints, certain parts are omitted, and only the prompt frameworks are shown.
\subsection{Reverse Data Generate Prompt}
\label{appd:bs}

\begin{prompttemplateWhite}{Generate Prompt}
As an Operations Research Expert, analyze the given mathematical optimization expression and LP data.

......

Input Mathematical Expression:
{{mathematical_expression}}

Input LP Data:
{{lp_data}}

Reference Examples:
{{examples}}

## Required Output:
Provide ONLY a clear, detailed natural language description of the optimization problem that:
- Describes the complete scenario
- States all decisions to be made
- Specifies the objective clearly
- Incorporates all constraints and conditions naturally
- Includes all numerical parameters within narrative
- Uses appropriate domain terminology
- Maintains mathematical accuracy without showing formulation
\end{prompttemplateWhite}

% \begin{prompttemplate}{Generate Prompt}
% As an Operations Research Expert, analyze the given mathematical optimization expression and LP data to generate a detailed natural language problem description, considering the specified application domain.

% Follow these guidelines:

% 1. **Mathematical Analysis** (For your analysis only, do not include in output):
% - Review decision variables, coefficients, and parameters

% ---
% Input Mathematical Expression:
% {{mathematical_expression}}

% ---
% Input LP Data:
% {{lp_data}}

% ---
% Reference Examples (Study the style and structure):
% {%- for example in examples %}
% Example {{loop.index}}:
% - {{ example }}
% {%- endfor %}
% ---
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% - Incorporates all constraints and conditions naturally
% - Includes all numerical parameters and coefficients within the narrative
% - Uses appropriate  terminology for the given application domain
% - Maintains mathematical accuracy without showing formulation
% \end{prompttemplate}

\begin{prompttemplateWhite}{Self-Criticism Prompt}
As an Operations Research Expert, evaluate if the generated problem description matches the mathematical optimization problem...

Input LP Data:
{{lp_data}}

Generated Problem Description:
{{problem_description}} 

Analysis Steps...

## Required Output:
If perfect match:
"Complete Instance"

If inconsistencies exist:
"Incomplete Instance:
[List specific discrepancies...]"


\end{prompttemplateWhite}


% \begin{prompttemplate}{Self-Criticism Prompt}
% As an Operations Research Expert, evaluate if the generated natural language description accurately matches the mathematical optimization problem defined in the LP data.

% Input LP Data:
% {{lp_data}}

% Generated Problem Description:
% {{problem_description}}

% Analysis Steps (for evaluation only, do not include in output):
% 1. Verify Mathematical Elements:
% - Check if all decision variables from LP are properly described
% - Confirm objective function direction and coefficients match
% - Validate all constraints and their coefficients
% - Verify bounds and special conditions

% 2. Parameter Consistency:
% - Compare all numerical values in description with LP data
% - Check if coefficients are correctly incorporated
% - Verify units and quantities match

% 3. Logical Consistency:
% - Ensure the context aligns with mathematical structure
% - Verify relationships between variables are preserved
% - Check if constraints are logically explained

% Required Output:
% If the description perfectly matches the LP data:
% "Complete Instance"

% If there are any inconsistencies:
% "Incomplete Instance:
% [List specific discrepancies between LP data and description:
% - Missing/incorrect parameters
% - Mismatched coefficients
% - Incorrect relationships
% - Other inconsistencies]"

% Note: Focus on mathematical accuracy and completeness of the mapping between LP data and description.
% \end{prompttemplate}

\newpage
\vspace*{\fill} 
\begin{center}
\begin{prompttemplateWhite}{Self-Refinement Prompt}
As an Operations Research Expert, analyze the criticism and refine the problem description if needed.

First, check the criticism result:
{{criticism}}

If the criticism shows "Complete Instance":
Output "Nothing need to refine"

Otherwise, follow these steps to generate an improved description:

1. Review Input Materials:
Mathematical Expression:
{{mathematical_expression}}

LP Data:
{{lp_data}}

Initial Description:
{{initial_description}}

2. Task:
Based on the criticism feedback, LP data information, and initial description, generate a complete and accurate problem description.

Required Output:
If criticism is "Complete Instance":
Output "Nothing need to refine"

Otherwise:
[Direct natural language description of the optimization problem]
- No introductory phrases or meta-commentary
- No section headers or separators
- Just the complete problem description in clear natural language
- Ensure exact match with all LP data parameters
- Include all constraints and objectives naturally
- Avoid mathematical notation

Note: The output should be ONLY the complete natural language description itself, with no additional text or formatting.	
\end{prompttemplateWhite}
\end{center}
\vspace*{\fill}  % 下部填充


\newpage
\subsection{Baseline Prompt}
\label{appd:baseline_prompt}

\begin{prompttemplateWhite}{Baseline Prompt Template for optimization modeling}
Below is an operations research question. Build a mathematical model and corresponding python code using `gurobipy` that appropriately addresses the question.
# Question:
{}

# Notes:
- Please output Python code starting with the following lines:```python\n\nimport gurobipy as gp\nfrom gurobipy import GRB\n```
- Make sure the model variable is named `model`.
- Avoid using "<" and ">" in Gurobi constraints; instead, use "<=" or ">=" as appropriate.
- Carefully determine whether the variable is an integer or a continuous variable.

# Response:

(Provide your response here,keep the notes above in mind)
\end{prompttemplateWhite}

\subsection{AutoFormulation Instructions}
\label{appd:cot_instruction}

% \begin{prompttemplate}{CoT Instructions}
% instructions = [
%     # General instructions
%     "Below is an operations research question. Build a mathematical model and corresponding Python code using `gurobipy` to solve it.",
%     "Please solve this optimization problem by first creating a mathematical formulation, then implement the solution using gurobipy in Python.",
%     "Analyze the given operations research problem, construct a mathematical model, and write Python code with gurobipy to find the optimal solution.",
%     "For the following problem, develop both a mathematical model and a Python implementation using the gurobipy library. Make sure to include all necessary constraints and the objective function.",
%     "Create a complete solution that includes: 1) Mathematical formulation 2) Python code using gurobipy 3) Results interpretation. Ensure all variables and constraints are properly defined.",
%     "Build an optimization model for this problem and solve it using gurobipy. Your solution should include both the mathematical formulation and working Python code.",
%     "Transform this operations research problem into a mathematical model and implement it in Python with gurobipy. Include clear variable definitions and constraint explanations.",
%     "Using gurobipy, write Python code to solve the following optimization problem. Start by developing the mathematical model before implementing the solution.",
%     "Please provide a step-by-step solution that includes the mathematical formulation and corresponding Python implementation using gurobipy. Ensure proper documentation of your approach.",
%     "Solve this optimization challenge by first writing out the complete mathematical model, then translating it into Python code using the gurobipy package. Include comments explaining your implementation.",

%     # Chain of Thought instructions
%     "The following is an operations research problem. Let's solve it step by step: 1) Identify the decision variables, objective function, and constraints 2) Formulate the mathematical model 3) Implement the solution using Gurobi in Python 4) Verify and interpret the results.",
%     "Presented below is an operations research problem. Approach this systematically: What are we trying to optimize? What are the main constraints? After analyzing these elements, construct a mathematical model and solve it using Gurobi in Python.",
%     "Here is an operations research problem to solve. Tackle this problem carefully: Start by determining the goal we want to optimize, then pinpoint the constraints. Build the mathematical model and implement it using Gurobi in Python, explaining each decision along the way.",
%     "We are presented with an operations research problem. Solve it step-by-step: 1) Identify and list the decision variables 2) Clearly define the objective 3) Outline all relevant constraints 4) Formulate the mathematical model 5) Implement and solve it using Gurobi in Python, providing explanations at every step.",
%     "This is an operations research problem. Follow this structured approach: Begin with understanding the problem -> Identify the key variables -> Analyze the constraints -> Develop the mathematical model -> Solve it programmatically using Gurobi in Python. Provide clear reasoning and explanations at each stage."
% ]
% \end{prompttemplate}

\begin{prompttemplateWhite}{CoT Instructions}
instructions = [
    # Total instructions: 15 entries
    # Showing 5 representative examples below...
    
    "Below is an operations research question. Build a mathematical model and corresponding Python code using `gurobipy` to solve it.",
    
    "Create a complete solution that includes: 1) Mathematical formulation 2) Python code using gurobipy 3) Results interpretation. Ensure all variables and constraints are properly defined.",
    
    "Transform this operations research problem into a mathematical model and implement it in Python with gurobipy. Include clear variable definitions and constraint explanations.",
    
    "The following is an operations research problem. Let's solve it step by step: 1) Identify the decision variables, objective function, and constraints 2) Formulate the mathematical model 3) Implement the solution using Gurobi in Python 4) Verify and interpret the results.",
    
    "This is an operations research problem. Follow this structured approach: Begin with understanding the problem -> Identify the key variables -> Analyze the constraints -> Develop the mathematical model -> Solve it programmatically using Gurobi in Python. Provide clear reasoning and explanations at each stage."
]
\end{prompttemplateWhite}

\subsection{Prompts for Configuration Selecting}
\label{app:config_select}
% \begin{prompttemplate}{Initializing the Parameters}
% You are an optimization expert helping to tune the parameters of the problem generator in
% ```python
% {generator_code}
% ```
% The default parameters are already set. However, the generated models need to satisfy specific requirements.

% CRITICAL REQUIREMENT:
% The most important requirement is that generated instances MUST be solvable to OPTIMALITY by Gurobi.
% This means:
% 1. The model must be feasible (have valid solutions)
% 2. The model must be bounded (have finite optimal solutions)
% 3. The model must be solvable within the time limit
% 4. Gurobi must reach OPTIMAL status (not INFEASIBLE, UNBOUNDED, or TIME_LIMIT)

% Only after ensuring OPTIMAL solvability, the following complexity requirements should be considered:

% Model Complexity Score Calculation:
% The total complexity score is calculated as follows:
% 1. Variable Score:
%    - Binary variables: weight = {weights['alpha_bin']}
%    - Integer variables: weight = {weights['alpha_int']}
%    - Continuous variables: weight = {weights['alpha_cont']}

% 2. Constraint Score:
%    - Linear constraints: weight = {weights['beta_lin']}
%    - Indicator constraints: weight = {weights['beta_indic']}
%    - Quadratic constraints: weight = {weights['beta_quad']}
%    - General constraints: weight = {weights['beta_gen']}

% 3. Additional Complexity Factors:
%    - Big-M usage: weight = {weights['gamma_BigM']}
%    - Expression complexity: weight = {weights['delta_expr']}

% Total Score = Variable Score + Constraint Score + Big-M Score + Expression Score
% where:
% - Variable Score = sum(number of each variable type times its weight)
% - Constraint Score = sum(number of each constraint type times its weight)
% - Big-M Score = number of Big-M constraints times Big-M weight
% - Expression Score = average expression length times expression weight

% Secondary Requirements (Only for OPTIMAL Solutions):
% 1. Model Complexity:
%    - The total complexity score should be between {complexity_score_min} and {complexity_score_max}
% 2. Solve Time:
%    - The model should solve in between {min_solve_time} and {max_solve_time} seconds

% You are asked to suggest parameter values that would generate models meeting these requirements. Consider:
% 1. Primary Focus:
%    - Ensure model feasibility and boundedness
%    - Avoid using parameters that lead to infeasible or unbounded models
%    - Keep model size manageable to avoid time limit issues

% 2. Secondary Considerations:
%    - Higher variable/constraint counts and more complex constraint types increase complexity score
%    - More binary/integer variables typically increase solve time
%    - Complex expressions and Big-M constraints significantly impact both complexity and solve time

% Return your response in JSON format, strictly following the structure of the provided 'default_parameters' dictionary. Ensure that:
% 1. The keys remain exactly the same.
% 2. The data types for each value are preserved, you should specify an integer for float values in default_parameters and a float for integer values.
% 3. If a value is a tuple in the original dictionary, it should be represented as a list in JSON.
% 4. The JSON should be properly formatted with indentation for readability.
% \end{prompttemplate}

\begin{prompttemplateWhite}{Initializing the Parameters}
You are an optimization expert helping to tune the parameters in:
\begin{verbatim}
{generator_code}
\end{verbatim}

CRITICAL REQUIREMENT: 
Generated instances MUST be solvable to OPTIMALITY by Gurobi...

Model Complexity Score Calculation:
1. Variable Score:
   - Binary variables: weight = {weights['alpha\_bin']}
   - Integer variables: weight = {weights['alpha\_int']} 
   - Continuous variables: weight = {weights['alpha\_cont']}
2. Constraint Score...
3. Additional Complexity Factors...

Total Score = Variable Score + Constraint Score + Big-M Score + Expression Score

Secondary Requirements:
1. Model Complexity: {complexity\_score\_min} to {complexity\_score\_max}
2. Solve Time: {min\_solve\_time} to {max\_solve\_time} seconds

Return parameter values in JSON format matching 'default\_parameters' structure:
- Keep exact same keys
- Preserve data types
- Use lists for tuples 
- Format with proper indentation
\end{prompttemplateWhite}

\begin{prompttemplateWhite}{Feedback Prompt}
Based on testing {total_instances} instances with your suggested parameters:
{last_suggested_parameters}

Here are the detailed results:

1. Solution Status Analysis:
   - Total Instances: {total_instances}
   - Solvable Instances: {solvable_instances}
   - OPTIMAL Solutions: {optimal_instances} ({optimal_rate:.1f}%)
   - Solution Status Distribution:
     ...
   - Status Percentages:
     ...

2. Overall Performance (Only OPTIMAL Solutions):
   - Success Rate: {success_rate:.1f}% ({results["requirements_met"]["all_requirements"]} out of {total_instances} instances met all requirements)
   - Note: Only OPTIMAL solutions are considered successful

3. Requirements Satisfaction (Only OPTIMAL Solutions):
   Complexity Score Distribution:{analyze_distribution("complexity")}
   - Required range: {requirements}
   - Success rate: {num_satisfying_requirements/total_instances}

   Solve Time Distribution:{analyze_distribution("solve time")}
   - Required range: {requirements}
   - Success rate: {num_satisfying_requirements/total_instances}

4. Model Structure Analysis (Only OPTIMAL Solutions):
   Variable Distributions:
   Binary Variables: ...
   
   Constraint Distributions:
   Linear Constraints: ...
   Indicator Constraints: ...
   Quadratic Constraints: ...
   General Constraints: ...
   
   Complexity Score Components: ...

5. Distribution Analysis Insights:
    {throughout analysis of the instances generated by the parameters by calling statistics package in Python}

Based on these results and distribution analysis, please suggest parameter values that would:
1. MAXIMIZE the proportion of instances that reach OPTIMAL status
2. Adjust the model complexity to meet the target score range (for OPTIMAL instances)
3. Maintain solve times within the required range (for OPTIMAL instances)
4. Reduce variability in key metrics where high variance was detected
5. Increase the overall success rate

Return your response in JSON format, strictly following the structure of the previous suggestions dictionary. Ensure that:
1. All keys remain exactly the same as in the previous suggestions
2. The data types for each value are preserved
3. The JSON should be properly formatted with indentation for readability
4. Do not add any new keys or remove any existing keys
\end{prompttemplateWhite}

\newpage
\subsection{An Example of Metadata}
\label{appd:metadata}
\vspace*{\fill}  % 上部填充
\begin{center}
\begin{metadata}{Metadata}

\textbf{Subclass:} Bin Packing  

\textbf{Reference:} Garey, M. R. and Johnson, D. S.  
"Approximation Algorithms for Bin Packing Problems: A Survey."  
\textit{Analysis and Design of Algorithms in Combinatorial Optimization (1981)}

\textbf{Reference URL:}  
\href{https://doi.org/10.1007/978-3-7091-2748-3_8}{https://doi.org/10.1007/978-3-7091-2748-3\_8}

\textbf{Mathematical Formula:}  

\textit{Consider \( n \) items, where each item \( i \) has:}
\begin{itemize}
    \item Weight \( s_i \): The weight of item \( i \)
\end{itemize}

\textit{The problem includes:}
\begin{itemize}
    \item Bin Capacity \( c \): The uniform capacity of each bin
    \item Bin Usage Variable \( y_j \): A binary variable indicating whether bin \( j \) is used
    \item Assignment Variable \( x_{i,j} \): A binary variable indicating whether item \( i \) is assigned to bin \( j \)
\end{itemize}
\[
\begin{aligned}
&\text{Minimize} && \sum_{j=1}^n y_j \\
&\text{Subject to:} \\
& && \sum_{i=1}^n s_i x_{i,j} \leq c y_j && \forall j = 1, \ldots, n \\
& && \sum_{j=1}^n x_{i,j} = 1 && \forall i = 1, \ldots, n \\
& && x_{i,j}, y_j \in \{0, 1\} && \forall i, j = 1, \ldots, n
\end{aligned}
\]
\end{metadata}
\end{center}
\vspace*{\fill}  % 下部填充
\clearpage  % 确保下一页内容从新页开始

\newpage
\subsection{An Example of Generator}
\label{appd:generator}
\vspace*{\fill}  % 上部填充
\begin{center}
% 使用tcolorbox展示代码
\begin{pythoncode}{Python Code for Bin Packing Generator}
import gurobipy as gp
from gurobipy import GRB
import random

class Generator:
    def __init__(self, parameters=None, seed=None):
        self.problem_type = "binpacking"
        default_parameters = {
            "n_items": (3, 10),
            "weight_range": (1, 50),
            "bin_capacity": 100
        }
        if parameters is None:
            parameters = default_parameters
        for key, value in parameters.items():
            setattr(self, key, value)
        self.seed = seed
        if self.seed:
            random.seed(seed)
    
    def generate_instance(self):
        self.n_items = random.randint(*self.n_items)
        items = list(range(self.n_items))
        item_weights = {i: random.randint(*self.weight_range) for i in items}

        model = gp.Model("BinPacking")
        model.Params.OutputFlag = 0  # Suppress Gurobi output
        x = model.addVars(items, items, vtype=GRB.BINARY, name="x")
        y = model.addVars(items, vtype=GRB.BINARY, name="y")

        # Objective: Minimize the number of bins used
        model.setObjective(gp.quicksum(y[j] for j in items), GRB.MINIMIZE)
        for j in items:
            model.addConstr(
                gp.quicksum(item_weights[i] * x[i,j] for i in items) <= self.bin_capacity * y[j],
                name=f"Capacity_{j}"
            )
        for i in items:
            model.addConstr(
                gp.quicksum(x[i,j] for j in items) == 1,
                name=f"Assignment_{i}"
            )
        return model
\end{pythoncode}

\end{center}
\vspace*{\fill}  % 上部填充

\newpage

\subsection{Augmentation Prompt}
\label{sec:aug_prompt}
% \begin{prompttemplate}{Generate Augmentation Problem Prompt}
% AUGMENTATION_RULES = [
%     # Semantic Enhancement
%     "Rephrase the problem description while maintaining the same mathematical structure and optimization goals.",
%     "Rewrite the problem using different expressions and terminology while keeping the core optimization task identical.", 
%     # Change the scenario
%     "Transform the problem into a different application scenario while preserving the exact same mathematical structure and constraints. For example, convert a manufacturing problem to a resource allocation or logistics problem.",
%     "Conceive a variant on another scenario for the mathematical model expressed in the problem and then generate a new problem",
%     # Numerical enhancement
%     "Change the numerical parameters in the problem while maintaining the same problem structure and relationships.",
%     "Scale up or down the problem size by adjusting the dimensions/parameters proportionally.",
%     # Problem variant generation
%     "Generate a variant by adding/removing/modifying one constraint while maintaining problem feasibility.",
%     "Create a variation by combining different types of constraints while preserving the core optimization goal.",
%     # Complicating the problem
%     ## Variable Expansion
%     "Increase the number of decision variables by splitting existing variables or adding related new variables (e.g., from 2 product types to 3-4 types) while maintaining similar structure.",
%     "Upper and lower bounds for adjustment variables while maintaining problem feasibility.",
%     ## Constraints Expansion
%     "Add realistic constraints like capacity limitations, budget restrictions, or quality requirements while ensuring problem feasibility.",
%     "Introduce cross-variable constraints or linking constraints between different components of the problem.",
%     ## Complicating the data
%     "Converting problem parameters into tabular form and generating a new problem with more complex data structures.",
%     "Converting problem parameters into tabular form while maintaining the same mathematical structure and optimization goals.",
%     ## Switching question types
%     "Generate non-linear optimisation problems by replacing linear relations with non-linear relations (e.g. quadratic, exponential, logarithmic terms)",
%     "Combine the original problem with other types of problems (e.g., linear programming, integer programming, nonlinear programming) to generate a hybrid problem type.",
%     # Question type conversion
%     ## Multi-targeting
%     "Try to add a new objective function to generate a multi-objective optimisation problem. Example: For a single objective optimisation problem \\min $$c^T x$$, add a new objective function \\max $$d^T x$$ to generate a bi-objective optimisation problem.",
%     ## Complicating the objective function
%     "Modify the objective function to include additional terms or to change the form of the objective function while maintaining the same optimization goal.",
%     "Perform a nonlinear transformation of the objective function. For example, a linear objective function can be transformed into a quadratic objective function",
%     # Problem symmetry
%     "Generate new problem variants by introducing symmetries (e.g. symmetric variables, symmetric constraints)",
%     "If the optimisation problem has some structural property, e.g. symmetry, a transformed new problem can be generated by redefining the optimisation expression. For example, generating the dual of the original problem while modifying the corresponding parameters and constraints.",
% ]

% AUGMENTATION_TEMPLATE = """Below is an optimization problem, please generate a new optimization problem by following the augmentation rule provided.

% # Original Problem
% The original optimization problem is as follows:
% '''
% {original_problem}
% '''

% # Augmentation Rule
% {rule}

% # Augmented Problem
% Please construct a new optimization problem according to the above requirements and the provided question in the following format:

% [Write your new problem here]

% Note: The generated problem should maintain mathematical validity and practical feasibility.And just provide the problem description without any additional information.
% """
% \end{prompttemplate}

\begin{prompttemplateWhite}{Generate Augmentation Problem Prompt}
AUGMENTATION_RULES = [
    # Semantic Enhancement
    "Rephrase the problem description while maintaining the same mathematical structure...",
    "Rewrite the problem using different expressions and terminology...",
    # Change the scenario 
    "Transform the problem into a different application scenario while preserving the same structure...",
    "Conceive a variant on another scenario for the mathematical model...",
    # Numerical enhancement
    "Change the numerical parameters while maintaining the same problem structure...", 
    "Scale up or down the problem size by adjusting parameters proportionally...",
    # Problem variant generation
    "Generate a variant by adding/removing/modifying constraints...",
    "Create a variation by combining different types of constraints...",
    # Complicating the problem
    ## Variable Expansion
    "Increase the number of decision variables while maintaining similar structure...",
    "Add bounds for adjustment variables...",
    ## Constraints Expansion
    "Add realistic constraints like capacity limitations, budget restrictions...",
    "Introduce cross-variable constraints between components...",
    ## Data Complexity
    "Convert parameters into tabular form with more complex data structures...",
    ## Problem Types
    "Generate non-linear problems by replacing linear relations...",
    "Combine with other problem types to generate hybrid problems...",
    # Multi-objective
    "Add new objective functions to generate multi-objective problems...",
    "Modify objective function to include additional terms...",
    # Problem symmetry
    "Generate variants by introducing symmetries...",
    "Generate dual problems while modifying parameters and constraints..."
]

AUGMENTATION_TEMPLATE = """Below is an optimization problem, please generate a new optimization problem by following the augmentation rule provided.

# Original Problem
The original optimization problem is as follows:
'''
{original_problem}
'''
# Augmentation Rule
{rule}
# Augmented Problem
Please construct a new optimization problem according to the above requirements and the provided question in the following format:

[Write your new problem here]

Note: The generated problem should maintain mathematical validity and practical feasibility.And just provide the problem description without any additional information.
"""
\end{prompttemplateWhite}


% \begin{prompttemplateGreen}{Generate Prompt}
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% Remember: 
% 1. Follow the style and structure of the provided examples
% \end{prompttemplateGreen}
% \begin{prompttemplateModernGray}{Generate Prompt}
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% Remember: 
% 1. Follow the style and structure of the provided examples
% \end{prompttemplateModernGray}
% \begin{prompttemplateWhite}{Generate Prompt}
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% Remember: 
% 1. Follow the style and structure of the provided examples
% \end{prompttemplateWhite}
% \begin{prompttemplateBlue}{Generate Prompt}
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% Remember: 
% 1. Follow the style and structure of the provided examples
% \end{prompttemplateBlue}
% \begin{prompttemplateOrange}{Generate Prompt}
% ## Required Output:
% Provide ONLY a clear, detailed natural language description of the optimization problem that:
% - Describes the complete scenario
% - States all decisions to be made
% - Specifies the objective clearly
% Remember: 
% 1. Follow the style and structure of the provided examples
% \end{prompttemplateOrange}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
