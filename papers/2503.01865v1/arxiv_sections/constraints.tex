\section{Core Problem: Superfluous Constraints}

As outlined in Section \ref{sec:formulation_of_trans}, our objective is to maintain the consistency in the feasible region across different models, i.e., to ensure that \(  \mathcal{F}_{A}^s \cap \mathcal{F}_{shared} \approx \mathcal{F}_{A}^s \) during the optimization process. A key limitation in the current optimization objective is the presence of superfluous constraints, which hinder effective optimization.
%To address this issue, we propose a method that primarily focuses on enhancing the jailbreaking objective by removing unnecessary constraints.

\subsection{Response Pattern Constraint}

A primary objective of adversarial attacks is to bypass safety mechanisms and induce models to generate harmful responses. As illustrated on the left side of Figure \ref{fig:redundant_1}, one notable constraint arises from the response pattern enforced by existing methods. Specifically, GCG implicitly biases the model toward a predefined target output (e.g., "Here is how to ...") without explicit instructions on response patterns, thereby deviating from actual jailbroken responses. This misalignment introduces an additional constraint that further distances the feasible region from the shared region. 

Given \( a^t_{1:k} \) as the real jailbroken response and $\mathcal{L}^t(x_{1:n})$ as the loss on the real jailbroken response, we formalize the response pattern constraint $\mathcal{L}_{rp}(x_{1:n})$ within the original optimization objective (Equation \ref{eqn:base_objective}) as the discrepancy between $\mathcal{L}^t(x_{1:n})$ and $\mathcal{L}(x_{1:n})$:
\begin{equation}
    \label{en:Lsp}
    \begin{aligned}
        & \mathcal{L}(x_{1:n}) = -\log p(a_{1:k} \mid q_{1:m}, x_{1:n}) \\
        & \mathcal{L}^t(x_{1:n}) = -\log p(a^t_{1:k} \mid q_{1:m}, x_{1:n}) \\
        & \mathcal{L}_{rp}(x_{1:n}) = \mathcal{L}(x_{1:n}) - \mathcal{L}^t(x_{1:n})
    \end{aligned}
\end{equation}

From the equations above, it is evident that addressing this issue requires directing the attacked model to produce responses that are explicitly provided in the input. This ensures that \( a^t_{1:k} \) approximates the expected \( a_{1:k} \), and thus eliminates $\mathcal{L}_{rp}(x_{1:n})$, as illustrated in Figure \ref{fig:redundant_1}.

\subsection{Token Tail Constraint}

Even when optimizing the real jailbreak output, it is often sufficient to generate only a few necessary tokens to achieve the jailbreaking objective. While removing the response pattern constraint \(\mathcal{L}_{rp}(x_{1:n})\) alleviates some limitations, the remaining term \(\mathcal{L}^t(x_{1:n})\) still incorporates superfluous constraints associated with token sequences that extend beyond what is necessary. As with the response pattern constraint, we observe that enforcing constraints on unnecessary tokens—particularly those at the tail of the sequence—impedes both the transferability and optimization processes. Ideally, optimization should focus solely on the necessary tokens while relaxing constraints on subsequent tokens:

\begin{equation*} 
    \label{eqn:Tail}
    \begin{aligned} 
        \mathcal{L}^t(x_{1:n}) &= - \sum_{i=1}^{k} \log p(a^t_i \mid q_{1:m}, x_{1:n}, a^t_{1:{i-1}}) \\
        &= \underbrace{ - \sum_{i=1}^{s} \log p(a^t_i \mid q_{1:m}, x_{1:n}, a^t_{1:{i-1}}) }_{\textcolor{red}{\mathcal{L}_{\text{safety}}(x_{1:n})}} \\
        &\quad \hspace{-0.7cm} + \underbrace{\left(  - \sum_{i=s+1}^{k} \log p(a^t_i \mid q_{1:m}, x_{1:n}, a^t_{1:{i-1}})\right) }_{\textcolor{red}{\mathcal{L}_{\text{tail}}(x_{1:n})}} 
    \end{aligned} 
\end{equation*}

In this equation, \(\mathcal{L}_{\text{tail}}(x_{1:n})\) denotes the redundant loss component, whereas \(\mathcal{L}_{\text{safety}}(x_{1:n})\) represents the expected guiding loss. The latter treats the texts "Here's how to make a tiny bomb:\textbackslash n\textbackslash n**Step 1:**" and "Here's how to make a bomb:\textbackslash nStep 1:" as equivalent.