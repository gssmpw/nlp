%%%%%%%%%%%
% RESULTS %
%%%%%%%%%%%

\section{Experimental Results and Discussion}

% Plot created manually from MNIST and CIFAR10 plots created by function plot_accuracy_vs_distance_linear_fit
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\columnwidth]{Figures/ThresholdAnalysis/RETENTION_VS_THRESHOLD.jpg}
    \caption{Retention, accuracy and correct-incorrect ratio vs Threshold for the CNN on the MNIST dataset.     
    }
\label{fig:MNIST_TRAINING_DATASET_ACC_RATIO_VS_THRESHOLD}
\end{figure}

In this section, we present and discuss our results for CIFAR-10/ViT and MNIST/CNN. We focus on the MNIST training dataset results as they show similar trends as observed in both architectures and training and testing datasets. The confusion matrix shown in Figure \ref{fig:mnist_training_confusion_matrix} provides some insights into what the most likely MNIST misclassifications are. The training dataset contains 60,000 images and is well-balanced (each digit class has approximately 6,000 examples). On the diagonal we see the number of correct classifications and off-diagonal we see the pair-wise incorrect classifications e.g. there are 54 occurrences of 8 misclassified as a 9. We note that number zero is the digit less likely (sum of the row values minus the diagonal is the smallest), and number eight is the digit most likely to be misclassified  (sum of the row values minus the diagonal is the greatest). Other digits that are less likely to be misclassified are digits one, six and five. Digit eight is likely to be misclassified as six or nine, while digit three is likely to be misclassified as two, five or nine.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\columnwidth]{Figures/mnist_training_confusion_matrix.png}
    \caption{Confusion Matrix showing results for the CNN training dataset classification.     %MNIST_TRAINING_DATASET_ACC_RATIO_VS_THRESHOLD
    }
\label{fig:mnist_training_confusion_matrix}
\end{figure}

% function call
% plot_digit_averages(test_correct_predictions, test_incorrect_predictions, color1='lightgreen', color2='lightcoral', data="Testing Data")
\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.99\textwidth]{Figures/MNIST_Softmax_Averages_Training.png}
    \caption{Average Softmax Probabilities for Correctly and Incorrectly Classified Digits in the MNIST Training Dataset.}
    \label{fig:MNIST_Softmax_Averages_Training}
\end{figure*}

The average of all the softmax outputs on the diagonal ($>$59k examples) and of all values off diagonal ($<$1k examples) are shown in Figure \ref{fig:MNIST_Softmax_Averages_Training}. The top row shows the results for the correct predictions, and the bottom row for the incorrect predictions. Looking at the plot on the top left, the average softmax output for all digit 0 predictions, we see on the x axis the class digits, from 0 to 9 and on the y axis, the softmax output on a logarithmic scale. The bar for index 0 is the highest by over two orders of magnitude. We see this pattern repeating for every digit e.g., in the next plot for Digit 1, x axis index 1 bar is the highest, and so on. The average over all correct predictions show low entropy, reflecting the model's confidence, or certainty in the predictions. On the bottom row are the incorrect predictions. On the far left are all the examples that were misclassified as digit 0. The bar for index 0 is still the highest, except by only one order of magnitude, and see this pattern repeated for all incorrectly classified digits. In the case of incorrect classifications, the average over all incorrect predictions show high entropy, reflecting the model's uncertainty in the predictions.

\noindent  \textbf{Clustering}: The average softmax outputs for all correct classifications provide a good starting point for the K-Means algorithm centroids, converging quickly with good separation of clusters. This unsupervised learning method manages to assign all but two of the $>$59k correctly classified examples - in the supervised learning task - to the correct class centroids i.e. all digits 0 are assigned to cluster 0. We say the unsupervised (clustering) task presents \emph{high fidelity} in relation to the supervised (classification) learning task, and is a good proxy to assess model confidence in its predictions, the correlation between cluster assignments and true labels providing independent validation. 
We computed the all pairwise distances between the 10-class centroids ($\binom{10}{2}=45$ pairs) in the softmax space. The distances exhibit $d_{min}=1.368$, $d_{max}=1.402$, $\mu=1.389$ and $\sigma=0.009$. These values approach $\sqrt{2}$, the maximum distance between points in the probability-constrained simplex, indicating the model distributes classes at near-maximal separation in the output space. The supervised learning task achieved this separation through gradient descent on the cross-entropy loss; the unsupervised learning task confirms what has been induced by the classification training.

\indent Now we examine one out of the two edge cases where images are correctly classified but incorrectly clustered, to understand the softmax output and distance to class centroid patterns. Figure \ref{fig:ImageID8688_Softmax_Clustering} shows a correctly classified digit six, where the softmax output for digits 5 and 6 is 0.491 and 0.495 respectively and the distance of the prediction to centroids 5 and 6 are 0.696 and 0.697 respectively. Therefore, the softmax output is marginally higher for digit six, while the softmax output is marginally closer to the class 5 centroid. The softmax output pattern shows high entropy, while the distances to class centroids (notice y axis is not on logarithmic scale in this case) shows that digit is about 1.2 units away from all class centroids and close to 0.7 from both centroids 5 and 6. This example illustrates a case where the model exhibits uncertainty between two plausible classes, positioning the output almost equidistant between their centroids in the probability simplex. The slight discordance between classification and clustering in this case reveals a boundary condition in the model's decision space.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% IMAGE ID 8688, Softmax output, Distances to class centroids %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\columnwidth]{Figures/ImageID8688_Softmax_Clustering.png}
    \caption{Left to right, MNIST Training Data Image ID 8688 digit 6, the network softmax output and the distances to class centroids, correctly classified as 6 and incorrectly clustered as 5.     %MNIST_TRAINING_DATASET_ACC_RATIO_VS_THRESHOLD
    }
\label{fig:ImageID8688_Softmax_Clustering}
\end{figure}

\indent The next example presents a contrasting case to the previous edge case. Figure \ref{fig:ImageID35537_Softmax_Clustering} shows a digit six where the softmax output assigns 0.993 probability to class 6, with all other classes receiving probabilities below 0.004 (y axis is logarithmic). The distance to centroid 6 is 0.00153, while distances to all other centroids are approximately 1.4 units. This represents a typical case where both classification and clustering align with high confidence, positioning the output near the class 6 centroid in the probability simplex. The low entropy in softmax outputs and clear separation in centroid distances indicate unambiguous class membership.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% IMAGE ID 35537, Softmax output, Distances to class centroids %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\columnwidth]{Figures/ImageID35537_Softmax_Clustering.png}
    \caption{Left to right, MNIST Training Data Image ID 35537 digit 6, the network softmax output and the distances to class centroids, correctly classified and correctly clustered as 6.     %MNIST_TRAINING_DATASET_ACC_RATIO_VS_THRESHOLD
    }
\label{fig:ImageID35537_Softmax_Clustering}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CIFAR10 MNIST SOFTMAX DISTANCE TO %
% CLUSTER CENTROID STATISTICS       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% # Generate and print LaTeX code
% latex_code = generate_latex_table(expanded_table)
% print(latex_code)    

\begin{table*}[ht]
\centering
\caption{Enhanced Threshold Analysis with Meta Metrics. Key columns:
\textbf{Thresh}: Class threshold;
\textbf{Ret\%}: Retention percentage;
\textbf{Acc\%}: Accuracy percentage;
\textbf{Corr}: Correct predictions retained;
\textbf{Incor}: Incorrect predictions retained;
\textbf{CLost}: Cumulative correct lost;
\textbf{CElim}: Cumulative incorrect eliminated;
\textbf{Ratio}: Correct:Incorrect ratio;
\textbf{MetaT}: Meta threshold;
\textbf{PtsIn}: Points inside meta hypersphere;
\textbf{NoCls}: Points outside both class and meta hyperspheres;
\textbf{\%CLst}: Percentage of total correct lost;
\textbf{\%CEm}: Percentage of total incorrect eliminated;
\textbf{\%Pts}: Percentage of dataset inside meta hypersphere;
\textbf{\%NCl}: Percentage of dataset in no-class zone.}
\label{tab:threshold_analysis}
\begin{tabular}{r r r r r r r r r r r r r r r r}
\toprule
Thresh & Ret\% & Acc\% & Corr & Incor & CLost & CElim & Ratio & MetaT & PtsIn & NoCls & \%CLst & \%CEm & \%Pts & \%NCl \\
\midrule
0.80 & 100.00\% & 98.46\% & 59073 & 926 & 1 & 0 & 64:1 & 0.1337 & 0 & 1 & 0.0017\% & 0.00\% & 0.00\% & 0.0017\% \\
0.70 & 99.87\% & 98.54\% & 59048 & 876 & 26 & 50 & 67:1 & 0.2337 & 0 & 76 & 0.0440\% & 5.40\% & 0.00\% & 0.1267\% \\
0.60 & 99.27\% & 98.83\% & 58863 & 699 & 211 & 227 & 84:1 & 0.3337 & 5 & 433 & 0.3572\% & 24.51\% & 0.01\% & 0.7217\% \\
0.50 & 98.66\% & 99.04\% & 58626 & 568 & 448 & 358 & 103:1 & 0.4337 & 60 & 746 & 0.7584\% & 38.66\% & 0.10\% & 1.2433\% \\
0.40 & 98.00\% & 99.25\% & 58355 & 442 & 719 & 484 & 132:1 & 0.5337 & 274 & 929 & 1.2171\% & 52.27\% & 0.46\% & 1.5483\% \\
0.30 & 97.20\% & 99.42\% & 57981 & 338 & 1093 & 588 & 172:1 & 0.6337 & 889 & 792 & 1.8502\% & 63.50\% & 1.48\% & 1.3200\% \\
0.20 & 96.09\% & 99.58\% & 57411 & 242 & 1663 & 684 & 237:1 & 0.7337 & 1830 & 517 & 2.8151\% & 73.87\% & 3.05\% & 0.8617\% \\
0.10 & 93.92\% & 99.76\% & 56219 & 133 & 2855 & 793 & 423:1 & 0.8337 & 3214 & 434 & 4.8329\% & 85.64\% & 5.36\% & 0.7233\% \\
0.05 & 91.76\% & 99.84\% & 54969 & 87 & 4105 & 839 & 632:1 & 0.8837 & 4904 & 40 & 6.9489\% & 90.60\% & 8.17\% & 0.0667\% \\
\bottomrule
\end{tabular}
\end{table*}

\noindent \textbf{Softmax Distance to Class Centroid Statistics:} Having analyzed inter-centroid distances and edge cases in the model's decision space, we now investigate how these geometric properties can be leveraged to ensure the reliability of automated decision-making establish at runtime, when there are no labels. Table \ref{tab:threshold_analysis} quantifies the trade-offs as we vary threshold distances from class centroids. Column \textbf{Thresh} shows centroid-to-threshold distance values in descending order, starting at 0.8. Column \textbf{Ret\%} shows the ratio of correct predictions that are retained, that is, are not being discarded due to a conservation threshold setting. At 0.8 threshold, the retention is 100\%, that is, no "good" predictions have been lost. Column \textbf{Acc\%} shows the accuracy of the model at the given threshold. Column \textbf{Corr} shows the number of correct prediction at the given threhsold, that is the sum of all cases where the softmax output is nearer to the class centroid than the theshold. Reminding ourself that we are looking at results for the MNIST training dataset, in our 10-dimentional cluster-space. \textbf{Incor} is the number of incorrect predictions below threshold. It is important to note that all incorrect classifications are at a distance of less than 0.8 to class centroids. \textbf{CLost} is the cumulative summ of correct predictions "lost" because the are above the threshold. At 0.8 one correct prediction is lost because it is above the threshold. \textbf{CElim} has the number of incorrect predictions that have been "eliminated" due to the threshold. We see that at 0.8, none were eliminated. \textbf{Ratio} is the ratio of correct:incorrect predictions below the threshold, so at 0.8, there are 64 correct for every incorrect prediction. \textbf{MetaT} is the difference between the geometric mean distance (0.93 approx) to the meta-centroid, discussed in section \ref{methods:clustering} and the threshold. Note this quantity is a radius that defines the volume of the meta hypersphere, when the majority of examples the network "knows it doesn't know" will end up. \textbf{PtsIn} are the number of points inside the meta hypersphere. \textbf{NoCls} are the points that are neither in the class clusters/hyperspheres nor in the meta hypersphere. These could be in interstitial regions between hyperspheres or elsewhere. Note the sum of \textbf{CLost} and \textbf{CElim} is equal to the sum of \textbf{PtsIn} and \textbf{NoCls}. \textbf{\%CLst} is the percentage of \textbf{CLost} divided by \textbf{Corr} plus \textbf{CLost}, \textbf{\%CEm} is the percentage of \textbf{CElim} divided by \textbf{Incor} plus \textbf{CElim}. \textbf{\%Pts} is the number of points \textbf{PtsIn} inside the meta hypersphere by the total number of examples (60,000) as a percentage. \textbf{\%NCl} is the number of \textbf{NoCl} by the total number of examples as a percentage.

\noindent \textbf{Enhanced Threshold Analysis:} The ratio of correct to incorrect predictions \textbf{Ratio} shows exponential increase as the threshold becomes more selective, rising from 64:1 at the largest threshold (0.80) to 632:1 at the smallest threshold (0.05). The cumulative number of correct predictions lost \textbf{CLost} increases as the threshold decreases, the rate of loss accelerates in the lower threshold ranges. The cumulative elimination \textbf{CElim} of incorrect predictions increases from 0 to 839 as the threshold decreases. The elimination rate is highest in the upper threshold ranges and shows diminishing returns below 0.20, ultimately removing 90.60\% of incorrect predictions at the lowest threshold. The number of points inside the meta-hypersphere \textbf{PtsIn} increases from 0 to 4,904 as the threshold decreases. The growth begins slowly with 5 points at 0.60, accelerates through the middle ranges, and reaches 8.17\% of the dataset at the lowest threshold. This represents a growing zone of abstention (the model/pipeline abstaining from making predictions) as the meta-threshold expands. The no-class points \textbf{NoCls} exhibit a non-monotonic pattern, increasing from 1 to 929 points as the threshold decreases to 0.40, then declining to 40 points at the lowest threshold. This peak of 1.55\% of the dataset at threshold 0.40 represents the maximum region where points fall outside both classification and abstention zones, before the meta-threshold extends to lower thresholds. The concentration of these points between thresholds 0.60 and 0.20, mirroring the \textbf{CElim} trend suggests this range contained the majority of misclassifications. 



This can also be verified by \textbf{\%NCl}. The accuracy (\textbf{Acc\%}) shows consistent improvement as the threshold decreases, rising from 98.46\% at threshold 0.80 to 99.84\% at 0.05, demonstrating the model's enhanced precision in classification decisions. This improvement in accuracy corresponds with the exponential increase in the correct:incorrect ratio from 64:1 to 632:1, indicating increasingly confident predictions. However, this gain comes at a substantial cost in terms of coverage: the retention rate (\textbf{Ret\%}) drops from 100\% to 91.76\%, with the model losing 4,104 correct predictions (6.95\% of total correct predictions, as shown by \textbf{\%CLst}). This represents a trade-off between prediction confidence and dataset coverage, where a 1.38 percentage point improvement in accuracy is achieved at the cost of excluding approximately 7\% of correct predictions. The inflection point in this trade-off appears around threshold 0.30, where the accuracy gain rate begins to plateau while the retention loss continues to accelerate. 


%% DISCUSSIONS
%% 1. The average softmax output and
%% it is representative of the 2 datasets
%% and architectures
%% 2. how the unsupervised learning task
%% presents high-fidelity with respect to
%% the supervised learning task
%% 3. Show an edge case, where a 6 is classified correctly as 6 but misclustered as 8.
%% 4. Show and discuss table with figures







\noindent Figure \ref{fig:MNIST_TRAINING_DATASET_ACC_RATIO_VS_THRESHOLD} shows the inverse relationship between retention and prediction quality metrics. As the distance threshold decreases from 0.80 to 0.05, accuracy improves gradually (98.46\% to 99.84\%) while the correct:incorrect ratio increases exponentially (64:1 to 632:1). However, retention drops significantly (100\% to 91.76\%), particularly accelerating below threshold 0.30. This suggests an optimal operating point around 0.30-0.40, where retention remains above 97\% while achieving substantial improvements in accuracy (99.25-99.42\%) and correct:incorrect ratio (132:1-172:1). Points beyond this threshold could be designated as abstentions or routed to specialized pipelines, balancing the trade-off between prediction confidence and dataset coverage.

% \begin{table*}[ht]
% \centering
% \begin{tabular}{c|cccccc|cccccc}
% \hline
% & \multicolumn{6}{c|}{Training Dataset Correct Predictions} & \multicolumn{6}{c}{Training Dataset Incorrect Predictions} \\
% Digit & Mean & Median & Min & Max & $\sigma$ & Count & Mean & Median & Min & Max & $\sigma$ & Count \\ \hline
% 0 & 0.0166 & 0.0088 & 0.0018 & \textbf{0.8433} & 0.0536 & 5890 & 0.9955 & 0.9552 & \textbf{0.7037} & 1.3681 & 0.1756 & 33 \\
% 1 & 0.0154 & 0.0085 & 0.0020 & \textbf{0.7051} & 0.0486 & 6704 & 1.0912 & 1.0771 & \textbf{0.7247} & 1.3909 & 0.2197 & 38 \\
% 2 & 0.0370 & 0.0208 & 0.0056 & \textbf{0.7453} & 0.0746 & 5859 & 1.0409 & 1.0460 & \textbf{0.6962} & 1.3912 & 0.2064 & 99 \\
% 3 & 0.0352 & 0.0192 & 0.0055 & \textbf{0.7509} & 0.0754 & 6019 & 1.0522 & 1.0338 & \textbf{0.7139} & 1.3999 & 0.2143 & 112 \\
% 4 & 0.0295 & 0.0166 & 0.0031 & \textbf{0.6933} & 0.0661 & 5755 & 1.0681 & 1.0642 & \textbf{0.7139} & 1.4010 & 0.2045 & 87 \\
% 5 & 0.0298 & 0.0165 & 0.0024 & \textbf{0.7634} & 0.0693 & 5339 & 1.0572 & 1.0560 & \textbf{0.7066} & 1.3956 & 0.2000 & 82 \\
% 6 & 0.0154 & 0.0081 & 0.0015 & \textbf{0.7981} & 0.0485 & 5884 & 1.0485 & 1.0702 & \textbf{0.7068} & 1.4015 & 0.2110 & 34 \\
% 7 & 0.0302 & 0.0171 & 0.0028 & \textbf{0.7365} & 0.0678 & 6199 & 1.0133 & 0.9764 & \textbf{0.6960} & 1.3989 & 0.2160 & 66 \\
% 8 & 0.0619 & 0.0363 & 0.0092 & \textbf{0.7788} & 0.0989 & 5581 & 1.0232 & 1.0083 & \textbf{0.6852} & 1.3816 & 0.1990 & 270 \\
% 9 & 0.0399 & 0.0232 & 0.0048 & \textbf{0.7616} & 0.0781 & 5844 & 1.0576 & 1.0830 & \textbf{0.7179} & 1.3974 & 0.2201 & 105 \\ \hline
% & \multicolumn{6}{c|}{Testing Dataset Correct Predictions} & \multicolumn{6}{c}{Testing Dataset Incorrect Predictions} \\
% Digit & Mean & Median & Min & Max & $\sigma$ & Count & Mean & Median & Min & Max & $\sigma$ & Count \\ \hline
% 0 & 0.0141 & 0.0075 & 0.0021 & \textbf{0.7225} & 0.0506 & 977 & 1.0329 & 1.0185 & \textbf{0.7923} & 1.2880 & 0.2026 & 3 \\
% 1 & 0.0126 & 0.0071 & 0.0023 & \textbf{0.6737} & 0.0445 & 1129 & 0.9823 & 0.9556 & \textbf{0.7278} & 1.2445 & 0.1898 & 6 \\
% 2 & 0.0354 & 0.0202 & 0.0037 & \textbf{0.6697} & 0.0704 & 1015 & 1.0855 & 1.0725 & \textbf{0.7010} & 1.3833 & 0.1844 & 17 \\
% 3 & 0.0331 & 0.0177 & 0.0049 & \textbf{0.7515} & 0.0765 & 998 & 0.9823 & 0.9752 & \textbf{0.7102} & 1.3230 & 0.2044 & 12 \\
% 4 & 0.0306 & 0.0169 & 0.0047 & \textbf{0.6603} & 0.0678 & 972 & 0.9309 & 0.8725 & \textbf{0.7073} & 1.3110 & 0.1923 & 10 \\
% 5 & 0.0313 & 0.0173 & 0.0051 & \textbf{0.6324} & 0.0692 & 883 & 1.1874 & 1.2976 & \textbf{0.8477} & 1.3982 & 0.2067 & 9 \\
% 6 & 0.0172 & 0.0088 & 0.0029 & \textbf{0.7135} & 0.0545 & 941 & 1.0737 & 1.0242 & \textbf{0.7240} & 1.4009 & 0.2120 & 17 \\
% 7 & 0.0295 & 0.0165 & 0.0036 & \textbf{0.6939} & 0.0678 & 1009 & 0.9665 & 0.8833 & \textbf{0.7148} & 1.3628 & 0.2016 & 19 \\
% 8 & 0.0616 & 0.0372 & 0.0114 & \textbf{0.7328} & 0.0918 & 934 & 1.0513 & 1.0399 & \textbf{0.7252} & 1.3842 & 0.2022 & 40 \\
% 9 & 0.0359 & 0.0206 & 0.0042 & \textbf{0.6870} & 0.0765 & 980 & 1.0502 & 1.0486 & \textbf{0.6968} & 1.3838 & 0.2197 & 29 \\ \hline
% \end{tabular}
% \captionsetup{justification=raggedright,singlelinecheck=false}
% \caption{Statistical Summary of MNIST Softmax Output Distances to Centroids for Different Datasets and Prediction Outcomes. The centroids are obtained from Softmax outputs for correct class predictions from the training dataset.}
% \label{tab:distance_to_centroid}
% \end{table*}

% % DATA for table above
% %        Mean    Median       Min       Max  Standard Deviation  Count
% % 0  0.016608  0.008843  0.001769  0.843304            0.053614   5890
% % 1  0.015435  0.008516  0.002036  0.705149            0.048557   6704
% % 2  0.036996  0.020828  0.005605  0.745250            0.074615   5859
% % 3  0.035151  0.019205  0.005478  0.750860            0.075377   6019
% % 4  0.029493  0.016613  0.003111  0.693346            0.066094   5755
% % 5  0.029819  0.016509  0.002448  0.763396            0.069287   5339
% % 6  0.015405  0.008078  0.001526  0.798075            0.048491   5884
% % 7  0.030247  0.017138  0.002791  0.736508            0.067780   6199
% % 8  0.061884  0.036283  0.009184  0.778795            0.098932   5581
% % 9  0.039943  0.023188  0.004768  0.761636            0.078053   5844
% %        Mean    Median       Min       Max  Standard Deviation  Count
% % 0  0.995516  0.955230  0.703653  1.368133            0.175639     33
% % 1  1.091157  1.077065  0.724706  1.390934            0.219724     38
% % 2  1.040888  1.046023  0.696177  1.391211            0.206378     99
% % 3  1.052159  1.033801  0.713948  1.399858            0.214313    112
% % 4  1.068138  1.064157  0.713896  1.400997            0.204490     87
% % 5  1.057245  1.055964  0.706555  1.395563            0.200003     82
% % 6  1.048483  1.070162  0.706828  1.401450            0.211018     34
% % 7  1.013332  0.976427  0.695997  1.398902            0.216013     66
% % 8  1.023217  1.008262  0.685179  1.381630            0.199017    270
% % 9  1.057626  1.082991  0.717850  1.397425            0.220102    105
% %        Mean    Median       Min       Max  Standard Deviation  Count
% % 0  0.014064  0.007518  0.002131  0.722502            0.050551    977
% % 1  0.012627  0.007062  0.002254  0.673694            0.044504   1129
% % 2  0.035369  0.020174  0.003719  0.669724            0.070428   1015
% % 3  0.033119  0.017744  0.004876  0.751473            0.076455    998
% % 4  0.030573  0.016858  0.004709  0.660308            0.067756    972
% % 5  0.031271  0.017275  0.005053  0.632375            0.069207    883
% % 6  0.017175  0.008774  0.002851  0.713528            0.054455    941
% % 7  0.029476  0.016466  0.003639  0.693906            0.067756   1009
% % 8  0.061609  0.037214  0.011389  0.732832            0.091848    934
% % 9  0.035850  0.020602  0.004236  0.686980            0.076507    980
% %        Mean    Median       Min       Max  Standard Deviation  Count
% % 0  1.032918  1.018475  0.792297  1.287982            0.202620      3
% % 1  0.982310  0.955644  0.727825  1.244521            0.189784      6
% % 2  1.085502  1.072510  0.700976  1.383269            0.184444     17
% % 3  0.982309  0.975231  0.710249  1.322951            0.204446     12
% % 4  0.930852  0.872484  0.707302  1.310962            0.192325     10
% % 5  1.187412  1.297633  0.847685  1.398223            0.206653      9
% % 6  1.073695  1.024168  0.724028  1.400876            0.211957     17
% % 7  0.966459  0.883283  0.714793  1.362762            0.201621     19
% % 8  1.051282  1.039866  0.725232  1.384221            0.202232     40
% % 9  1.050175  1.048609  0.696760  1.383811            0.219746     29

% %%%%%%%%%%%%%%%%%%%%
% % NETWORK TRAINING %
% %%%%%%%%%%%%%%%%%%%%

% %\subsection{Softmax Distance to Class Centroid Statistics}
% % Discussion about table results
% \noindent \textbf{Softmax Distance to Class Centroid Statistics:} 
% We store the softmax outputs, true and predicted labels for the MNIST and CIFAR-10 training datasets, we obtain the mean values for all correctly predicted classes, use the values in Algorithm~\ref{alg:k-means-centroid-init}  to initialise the cluster centroids, then using the procedure described in algorithm \ref{alg:min_distance} and the same hardware used to train the MNIST classifier CNN, generate K-Means clusters and compute statistics as presented in Table \ref{tab:distance_to_centroid} (for the MNIST results), a summary of the distances between the softmax outputs of a model and the centroids for each digit class (0-9) in the MNIST dataset. 
% The centroids are calculated using the softmax outputs for correct predictions from the training dataset. The table is divided into four main sections: Training Dataset Correct Predictions, Training Dataset Incorrect Predictions, Testing Dataset Correct Predictions, and Testing Dataset Incorrect Predictions. 
% For each digit and section, statistics are displayed with respect to softmax distance from each class to its centroid: the mean, median, minimum (highlighted in bold for the testing datasets), maximum (highlighted in bold for the training datasets), standard deviation ($\sigma$), and count of instances are provided. 
% We note that for the correct predictions, the mean softmax distance to class centroid for digits zero, one and six are lowest (network prediction accuracy is high) while for digit 8 the mean softmax distance to class centroid is a comparatively larger value (network prediction accuracy is not as high). 
% The significance of the bold highlight for Max values in the Training section, and Min values in the Correct Prediction sections, is that the Min values in the Incorrect Predictions sections, is that the latter is effectively the Threshold we propose be used as a boundary for accepting the class prediction as accurate. 
% Any softmax distances equal or above the threshold will be considered not safe to use. 
% It becomes evident by comparing both columns, that for the training dataset, there is a significant overlap between Max and Min columns, however, the testing dataset presents an interesting property in that there is less of an overlap. 
% The significance of the overlap is that any correct predictions within the overlap will be tagged as unsafe, for the scheme we propose to hold, which means more manual classification and human intervention on the downside, and on the upside a high likelihood that every prediction with softmax distance below the threshold is accurate.

% In practice a small number of samples, 0.04\%, consistent across both CIFAR-10 and MNIST testing dataset prediction, are found in the overlap, as shown later in Tables \ref{tab:centroid_distance_overlap_mnist} and \ref{tab:centroid_distance_overlap}. Also shown in Table \ref{tab:distance_to_centroid} are the softmax distance standard deviations and counts for correct and incorrect classifications.

% %\subsection{Predictive Accuracy and Softmax Distance to Class Centroid}

% \noindent \textbf{Predictive Accuracy and Softmax Distance to Class Centroid:} 
% The confusion matrices in Figure \ref{fig:mnist_combined_confusion_matrix} provide some insights into what the most likely MNIST misclassifications are. We note that number zero is the digit less likely, and number eight is the digit most likely to be misclassified. Other digits that are less likely to be misclassified are digits one and; six in the training dataset, and five in the testing dataset. Digit eight is likely to be misclassified as six or nine, while digit three is likely to be misclassified as two, five or nine.

% %%%%%%%%%%%%%%%%%%%%%%%%%%
% % MNIST CONFUSION MATRIX %
% %%%%%%%%%%%%%%%%%%%%%%%%%%

% % plot produced with function call:
% % conf_matrix1, conf_matrix2 = display_misclassifications_side_by_side_cifar10(train_np, test_np, 10, 11, class_labels, 20, 7, True)
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.99\columnwidth]{Figures/mnist_combined_confusion_matrix.png}
%     \caption{Please zoom in for detail. Confusion matrices for the MNIST classification model on the training dataset (left) and testing dataset (right). The matrices display the true labels on the vertical axis and the predicted labels on the horizontal axis. The diagonal elements represent correctly classified instances, while the off-diagonal elements indicate misclassifications.}
%     \label{fig:mnist_combined_confusion_matrix}
% \end{figure}

% The confusion matrices for the CIFAR-10 dataset in Figure \ref{fig:cifar10_combined_confusion_matrix} illustrate the performance of a classification model on both the training and testing sets. For the training set, the model exhibits a strong diagonal, indicative of high classification accuracy for most classes. Nonetheless, certain classes show notable confusion, such as 'cat' with 'dog' and 'deer' with 'frog', and the confusion is reflected in the class softmax distance to cluster centroid.

% Examining the testing dataset, the model achieves good classification success, with perfect recognition of 'frog' class. Misclassifications are present but considerably reduced compared to the training dataset, particularly for pairs such as 'truck' and 'automobile', as well as 'cat' and 'dog'. The reduced confusion in the test set is also reflected in the softmax distance to cluster centroid.

% % plot produced with function call:
% % conf_matrix1, conf_matrix2 = display_misclassifications_side_by_side_cifar10(train_np, test_np, 10, 11, class_labels, 20, 7, True)
% \begin{figure}[ht]
%     \centering   
%     \includegraphics[width=0.99\columnwidth]{Figures/cifar10_combined_confusion_matrix.png}
%     \caption{Please zoom in for detail. Confusion matrices for the CIFAR-10 classification model on the training dataset (left) and testing dataset (right).}
%     \label{fig:cifar10_combined_confusion_matrix}
% \end{figure}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % COMBINED CIFAR10 MNIST ACCURACY VS MEAN %
% % CLASS PREDICTION DISTANCE TO CENTROID   %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Figure \ref{fig:Combined_CIFAR10_MNIST_Classification_Train_Test_Accuracy_Mean_Distance_to_Centroid_Linear_Fit} suggests how the trained neural network model achieves higher predictive accuracy for classes that have lower softmax distance to their respective class centroids, compared to classes for which the model has lower predictive accuracy.

% % In the context of the MNIST dataset, the derived linear functions from the training and testing data exhibit a negative correlation between the classification accuracy and the mean class distances to the centroids. Specifically, the training data is described by the function $ y = -0.806x + 1.009 $, and the testing data by $ y = -0.677x + 1.004 $. The negative coefficients of the linear terms $ -0.806 $ and $ -0.677 $, respectively) indicate that an increase in the mean distance to the centroid correlates with a decrease in classification accuracy for both datasets.

% The scatter plot shows the relationship between classification accuracy and mean class distance to the centroid for the MNIST dataset. Training data (blue dots) and testing data (green dots) are each fitted with a linear regression line, demonstrating a negative correlation where increased mean distance corresponds to decreased accuracy. The steeper slope of the training data fit (-0.806) compared to the testing data fit (-0.677) reflects the greater accuracy and more compact cluster obtained from the correct test predictions compared to the cluster obtained from correct training predictions.

% These results show an inverse relationship: as the mean distance from the data points in a class to their centroid increases, the propensity for correct classification diminishes. This could be due to the spread of data points within a class – greater distances from the centroid reflect a larger variance within the class, potentially making it more challenging for the classifier to identify the defining characteristics of each class accurately.

% The CIFAR-10 linear fit is steeper as can be observed by the y axis values, although it can be argued provides a better fit.

% % Plot created manually from MNIST and CIFAR10 plots created by function plot_accuracy_vs_distance_linear_fit
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.99\columnwidth]{Figures/Combined_CIFAR10_MNIST_Classification_Train_Test_Accuracy_Mean_Distance_to_Centroid_Linear_Fit.png}
%     \caption{Please zoom in for detail. Expected accuracy linear fit based on prediction softmax distance to class centroid. MNIST fit is on the left, CIFAR-10 is on the right.}
% \label{fig:Combined_CIFAR10_MNIST_Classification_Train_Test_Accuracy_Mean_Distance_to_Centroid_Linear_Fit}
% \end{figure}



% %Combined_CIFAR10_MNIST_Classification_Train_Test_Accuracy_Mean_Distance_to_Centroid_Linear_Fit.png


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % CIFAR10 BOXPLOTS SIDE BY SIDE %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% %\subsection{Overlap between maximum and minimum softmax distances to class centroids}

% % Figure \ref{fig:CIFAR10_boxplots_side_by_side_x2} presents box plots showing the distribution of distances to centroids for correctly and incorrectly classified instances in each class of the CIFAR-10 training and testing datasets.

% % In the training dataset, the distances to centroids for correctly classified instances (green boxes) are generally lower than those for incorrectly classified instances (red boxes), indicating that correctly classified instances tend to be closer to their respective class centroids in the feature space. However, there is a small overlap between the distances of correctly and incorrectly classified instances, particularly in classes such as cat, dog, and deer. 

% % The testing dataset exhibits a similar trend, with correctly classified instances having lower distances to centroids compared to incorrectly classified instances. The overlap between the two groups is less pronounced in the testing dataset, such as in classes like frog. This decreased overlap is expected, as the softmax distance to cluster centroids for incorrect classifications is larger, compared to training dataset. Note there is no frog boxplot for incorrect classifications, as reflected in the confusion matrix.

% % The side-by-side boxplots convey the distributions of distances to centroids for both the training and testing sets, categorized by class. These distances are represented on a logarithmic scale, facilitating the visualization of a wide range of values. The boxplots are bifurcated into two sections for each class: correctly classified and incorrectly classified instances.

% % For both the training and testing sets, there is a clear pattern where the correctly classified instances tend to have a smaller median distance to the class centroid compared to the incorrectly classified ones. This observation is consistent across all classes, suggesting that instances closer to the centroid of their respective class in the feature space are more likely to be classified correctly by the model. The notable overlap in the interquartile ranges, however, indicates that while distance to the centroid is an informative metric, it is not solely determinative of classification accuracy.

% % The incorrectly classified instances exhibit greater variance in distances to the centroid, as evidenced by the longer whiskers and the presence of outliers. This variability implies that misclassified instances can sometimes be far off from the core cluster of their true class, potentially falling closer to the regions dominated by other classes in the feature space. This is indicative of boundary cases or instances that bear a resemblance to multiple categories.

% % The consistency of these trends between the training and testing sets indicates that the distance to the centroid is a robust indicator of classification difficulty across the model’s application. The presence of some correctly classified instances at higher distances suggests that other factors also influence classification accuracy, such as the density of data points in the surrounding feature space, class overlap, or specific intra-class variabilities.

% \noindent \textbf{Overlap between maximum and minimum softmax distances to class centroids:} Figure \ref{fig:CIFAR10_boxplots_side_by_side_x2} presents box plots showing the distribution of distances to centroids for correctly and incorrectly classified instances in each class of the CIFAR-10 training and testing datasets. In the training dataset, the distances to centroids for correctly classified instances (green boxes) are generally lower than those for incorrectly classified instances (red boxes), indicating that correctly classified instances tend to be closer to their respective class centroids in the feature space. However, there is a small overlap between the distances of correctly and incorrectly classified instances, particularly in classes such as cat, dog, and deer. The testing dataset exhibits a similar trend, with correctly classified instances having lower distances to centroids compared to incorrectly classified instances. The overlap between the two groups is less pronounced in the testing dataset, such as in classes like frog. Note there is no frog boxplot for incorrect classifications, as reflected in the confusion matrix.

% \begin{figure*}[ht]
%     \centering
%     \includegraphics[width=0.99\textwidth]{Figures/CIFAR10_boxplots_side_by_side_x2.png}   \captionsetup{justification=raggedright,singlelinecheck=false}
%     \caption{Distribution of Distances to Centroids for Correctly and Incorrectly Classified Instances in Training and Testing CIFAR-10 data, where training data is on the left and testing data is displayed on the right. Distances on y axis are shown on a logarithmic scale. Note, centroids are obtained from correctly classified training examples, then used for both training and testing datasets, a cluster is not created from the testing softmax distances.}
%     \label{fig:CIFAR10_boxplots_side_by_side_x2}
% \end{figure*}

% The side-by-side boxplots convey the distributions of distances to centroids for both the training and testing sets, categorized by class. These distances are represented on a logarithmic scale, facilitating the visualization of a wide range of values. For both sets, there is a clear pattern where the correctly classified instances tend to have a smaller median distance to the class centroid compared to the incorrectly classified ones. This observation is consistent across all classes, suggesting that instances closer to the centroid of their respective class in the feature space are more likely to be classified correctly by the model. The notable overlap in the interquartile ranges, however, indicates that while distance to the centroid is an informative metric, it is not solely determinative of classification accuracy.

% The incorrectly classified instances exhibit greater variance in distances to the centroid, as evidenced by the longer whiskers and the presence of outliers. This variability implies that misclassified instances can sometimes be far off from the core cluster of their true class, potentially falling closer to the regions dominated by other classes in the feature space. This is indicative of boundary cases or instances that bear a resemblance to multiple categories. The consistency of these trends between the training and testing sets indicates that the distance to the centroid is a robust indicator of classification difficulty across the model's application. The presence of some correctly classified instances at higher distances suggests that other factors also influence classification accuracy, such as the density of data points in the surrounding feature space, class overlap, or specific intra-class variabilities.

% % \subsection{Overlap table MNIST discussion 1}

% %%%%%%%%%%%%%%%%%
% % OVERLAP TABLE %
% %%%%%%%%%%%%%%%%%

% % Table generated with function call:
% % centroid_distance_overlap_latex(d2c_train_correct, d2c_train_incorrect, d2c_test_correct, d2c_test_incorrect)
% % \begin{table}[htbp]
% % \centering
% % \begin{tabular}{|c|c|c|c|c|c|c|}
% % \hline
% % Digit & \multicolumn{3}{c|}{Train Data - Train Centroids} & \multicolumn{3}{c|}{Test Data - Train Centroids} \\
% % \hline
% %  & Count & Total & Overlap & Count & Total & Overlap \\
% % \hline
% % 0 & 2 & 5890 & 0.03\% & 1 & 977 & 0.10\% \\
% % 1 & 0 & 6704 & 0.00\% & 0 & 1129 & 0.00\% \\
% % 2 & 1 & 5859 & 0.02\% & 0 & 1015 & 0.00\% \\
% % 3 & 3 & 6019 & 0.05\% & 1 & 998 & 0.10\% \\
% % 4 & 0 & 5755 & 0.00\% & 0 & 972 & 0.00\% \\
% % 5 & 5 & 5339 & 0.09\% & 0 & 883 & 0.00\% \\
% % 6 & 2 & 5884 & 0.03\% & 1 & 941 & 0.11\% \\
% % 7 & 2 & 6199 & 0.03\% & 0 & 1009 & 0.00\% \\
% % 8 & 12 & 5581 & 0.22\% & 1 & 934 & 0.11\% \\
% % 9 & 1 & 5844 & 0.02\% & 0 & 980 & 0.00\% \\
% % \hline
% % Totals & 28 & 59074 & 0.05\% & 4 & 9838 & 0.04\% \\
% % \hline
% % \end{tabular}
% % \caption{Counts of correctly classified training and testing image predictions with distance to centroids equal or above error threshold $\varepsilon_{\text{th}}(i)$ where $i$ is the digit class}
% % \label{tab:centroid_distance_overlap_mnist}
% % \end{table}

% % Table \ref{tab:centroid_distance_overlap_mnist} show the counts of correctly classified training and testing examples that are assigned a  By choosing the $\varepsilon_{\text{th}}(i)$ the accuracy.

% % The table presents an analysis of the counts and percentages of correctly classified images in the training and testing datasets that have softmax distances to their respective class centroids above a certain threshold. The threshold is determined by the nearest softmax distance to the centroid for the incorrectly classified classes.

% % The table is divided into two main sections: "Train Data - Train Centroids" and "Test Data - Train Centroids." For each section, the table provides the count of images that satisfy the threshold condition, the total number of images in each class, and the percentage of overlap (i.e., the proportion of images above the threshold relative to the total count).

% % Looking at the "Train Data - Train Centroids" section, we observe that the overlap percentages are relatively low, ranging from 0.00\% to 0.22\%. This suggests that only a small fraction of the correctly classified training images have softmax distances to their centroids above the threshold set by the incorrectly classified images. The highest overlap is observed for digit class 8, with 12 out of 5,581 images (0.22\%) having distances above the threshold.

% % Similarly, in the "Test Data - Train Centroids" section, the overlap percentages are even lower, ranging from 0.00\% to 0.11\%. This indicates that the trained model is able to correctly classify the majority of the test images while maintaining a distance to the centroids below the threshold set by the incorrectly classified images. The highest overlap in the test data is observed for digit classes 6 and 8, with 1 out of 941 (0.11\%) and 1 out of 934 (0.11\%) images, respectively, having distances above the threshold.

% % The "Totals" row summarizes the overall counts and overlap percentages across all digit classes. For the training data, 28 out of 59,074 images (0.05\%) have distances above the threshold, while for the test data, only 4 out of 9,838 images (0.04\%) exceed the threshold.

% % These results suggest that the trained model is effective in correctly classifying images while maintaining a relatively small softmax distance to the class centroids. The low overlap percentages indicate that the majority of the correctly classified images are well-separated from the incorrectly classified images in terms of their softmax distances to the centroids. This analysis provides insights into the model's performance and its ability to distinguish between different digit classes based on the proximity of the images to their respective class centroids in the softmax space.


% % The LaTeX table provides an overview of the distribution of correctly classified images for both the training and test datasets of a classification model applied to digit recognition. It compares the counts of images that have a softmax distance to centroid above a defined error threshold, \( \varepsilon_{\text{th}}(i) \), where \( i \) represents each digit class.

% % The table is divided into two main sections: one for the training data using training centroids and the other for the test data also using training centroids. For each section, the table lists each digit from 0 to 9 and provides the count of images above the threshold, the total number of images in that digit class, and the percentage of overlap, which signifies the proportion of images above the threshold relative to the total count in that class.

% % Notably, the 'Count' column for the training data shows very few images exceed the threshold for each digit, with '8' having the highest count at 12, while most other digits have counts of 5 or below. This suggests that the classification model is quite precise on the training data, with very few images being farther from the centroid than the threshold that demarcates incorrectly classified images. The 'Overlap' percentage supports this, with values being very low, the highest being only 0.22\% for digit '8'.

% % For the test data, the counts of images above the threshold are even lower, with four out of the ten digits having a count of 1 and the rest having a count of 0. This indicates that the model generalizes well to unseen data, maintaining a low distance to centroid across the board for correctly classified images. The 'Overlap' percentages are in a similar range to the training data, with a 0.10\% overlap for digits '0' and '3', and a 0.11\% for digits '6' and '8'.

% % In summary, the table suggests that the distance to the centroid can be a strong indicator of classification correctness, with the majority of correctly classified images lying closer to the centroid than the threshold set by the nearest incorrectly classified images. This behavior is consistent across both the training and test sets, with the test set showing a very similar or even slightly better distribution with respect to the threshold, which is indicative of good model generalization from training to testing. The very low overlap percentages suggest that the threshold is well-calibrated, capturing the distinction between correctly and incorrectly classified images effectively.

% % \subsection{Overlap table CIFAR discussion 2}

% % %%%%%%%%%%%%%%%
% % % LATEX TABLE %
% % %%%%%%%%%%%%%%%

% % % Table generated by function call
% % % centroid_distance_overlap_latex(d2c_train_correct, 
% % %                                 d2c_train_incorrect, 
% % %                                 d2c_test_correct, 
% % %                                 d2c_test_incorrect, 
% % %                                 labels=class_labels,
% % %                                 caption='CIFAR10 centroid distances overlap count for correct predictions above incorrect threshold'
% % %                             ) 

% % \begin{table}[htbp]
% % \centering
% % \begin{tabular}{|c|c|c|c|c|c|c|}
% % \hline
% % Class & \multicolumn{3}{c|}{Train Data - Train Centroids} & \multicolumn{3}{c|}{Test Data - Train Centroids} \\
% % \hline
% %  & Count & Total & Overlap & Count & Total & Overlap \\
% % \hline
% % plane & 13 & 4252 & 0.31\% & 1 & 990 & 0.10\% \\
% % auto & 1 & 4326 & 0.02\% & 0 & 989 & 0.00\% \\
% % bird & 9 & 4216 & 0.21\% & 0 & 993 & 0.00\% \\
% % cat & 20 & 4103 & 0.49\% & 2 & 973 & 0.21\% \\
% % deer & 14 & 4255 & 0.33\% & 0 & 991 & 0.00\% \\
% % dog & 11 & 4157 & 0.26\% & 1 & 967 & 0.10\% \\
% % frog & 11 & 4310 & 0.26\% & 0 & 1000 & 0.00\% \\
% % horse & 12 & 4223 & 0.28\% & 0 & 991 & 0.00\% \\
% % ship & 11 & 4258 & 0.26\% & 0 & 998 & 0.00\% \\
% % truck & 10 & 4251 & 0.24\% & 0 & 981 & 0.00\% \\
% % \hline
% % Totals & 112 & 42351 & 0.26\% & 4 & 9873 & 0.04\% \\
% % \hline
% % \end{tabular}
% % \caption{CIFAR10 centroid distances overlap count for correct predictions above incorrect threshold}
% % \label{tab:centroid_distance_overlap}
% % \end{table}

% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline
% Digit & \multicolumn{3}{c|}{Train Data - Train Centroids} & \multicolumn{3}{c|}{Test Data - Train Centroids} \\
% \hline
%  & Count & Total & Overlap & Count & Total & Overlap \\
% \hline
% 0 & 2 & 5890 & 0.03\% & 1 & 977 & 0.10\% \\
% 1 & 0 & 6704 & 0.00\% & 0 & 1129 & 0.00\% \\
% 2 & 1 & 5859 & 0.02\% & 0 & 1015 & 0.00\% \\
% 3 & 3 & 6019 & 0.05\% & 1 & 998 & 0.10\% \\
% 4 & 0 & 5755 & 0.00\% & 0 & 972 & 0.00\% \\
% 5 & 5 & 5339 & 0.09\% & 0 & 883 & 0.00\% \\
% 6 & 2 & 5884 & 0.03\% & 1 & 941 & 0.11\% \\
% 7 & 2 & 6199 & 0.03\% & 0 & 1009 & 0.00\% \\
% 8 & 12 & 5581 & 0.22\% & 1 & 934 & 0.11\% \\
% 9 & 1 & 5844 & 0.02\% & 0 & 980 & 0.00\% \\
% \hline
% Totals & 28 & 59074 & 0.05\% & 4 & 9838 & 0.04\% \\
% \hline
% \end{tabular}
% \caption{MNIST counts of correctly classified training and testing image predictions and counts with distance to centroids equal or above error threshold.}
% \label{tab:centroid_distance_overlap_mnist}
% \end{table}

% \begin{table}[htbp]
% \centering
% \begin{tabular}{|c|c|c|c|c|c|c|}
% \hline
% Class & \multicolumn{3}{c|}{Train Data - Train Centroids} & \multicolumn{3}{c|}{Test Data - Train Centroids} \\
% \hline
%  & Count & Total & Overlap & Count & Total & Overlap \\
% \hline
% plane & 13 & 4252 & 0.31\% & 1 & 990 & 0.10\% \\
% auto & 1 & 4326 & 0.02\% & 0 & 989 & 0.00\% \\
% bird & 9 & 4216 & 0.21\% & 0 & 993 & 0.00\% \\
% cat & 20 & 4103 & 0.49\% & 2 & 973 & 0.21\% \\
% deer & 14 & 4255 & 0.33\% & 0 & 991 & 0.00\% \\
% dog & 11 & 4157 & 0.26\% & 1 & 967 & 0.10\% \\
% frog & 11 & 4310 & 0.26\% & 0 & 1000 & 0.00\% \\
% horse & 12 & 4223 & 0.28\% & 0 & 991 & 0.00\% \\
% ship & 11 & 4258 & 0.26\% & 0 & 998 & 0.00\% \\
% truck & 10 & 4251 & 0.24\% & 0 & 981 & 0.00\% \\
% \hline
% Totals & 112 & 42351 & 0.26\% & 4 & 9873 & 0.04\% \\
% \hline
% \end{tabular}
% \caption{CIFAR10 counts of correctly classified training and testing image predictions and counts with distance to centroids equal or above error threshold.}
% \label{tab:centroid_distance_overlap}
% \end{table}

% Table \ref{tab:centroid_distance_overlap_mnist} presents an analysis of the counts and percentages of correctly classified images in the training and testing datasets that have softmax distances to their respective class centroids above a certain threshold. The threshold is determined by the nearest softmax distance to the centroid for the incorrectly classified classes.

% The table is divided into two main sections: "Train Data - Train Centroids" and "Test Data - Train Centroids." For each section, the table provides the count of images that satisfy the threshold condition, the total number of images in each class, and the percentage of overlap (i.e., the proportion of images above the threshold relative to the total count).

% Looking at the "Train Data - Train Centroids" section, we observe that the overlap percentages are relatively low, ranging from 0.00\% to 0.22\%. This suggests that only a small fraction of the correctly classified training images have softmax distances to their centroids above the threshold set by the incorrectly classified images. The highest overlap is observed for digit class 8, with 12 out of 5,581 images (0.22\%) having distances above the threshold.

% Similarly, in the "Test Data - Train Centroids" section, the overlap percentages are even lower, ranging from 0.00\% to 0.11\%. This indicates that the trained model is able to correctly classify the majority of the test images while maintaining a distance to the centroids below the threshold set by the incorrectly classified images. The highest overlap in the test data is observed for digit classes 6 and 8, with 1 out of 941 (0.11\%) and 1 out of 934 (0.11\%) images, respectively, having distances above the threshold.

% The Totals summarise the overall counts and overlap percentages across all digit classes. For the training data, 28 out of 59,074 images (0.05\%) have distances above the threshold, while for the test data, only 4 out of 9,838 images (0.04\%) exceed the threshold.

% The low overlap percentages indicate that the majority of the correctly classified images are well-separated from the incorrectly classified images in terms of their softmax distances to the centroids. This analysis provides insights into the softmax distance being a proxy to distinguish between between correct and incorrect digit classifications based on the proximity of the images to their respective class centroids in the softmax distance space. The same analysis applies to Table \ref{tab:centroid_distance_overlap}. Most indicative of the consistency of the suggested approach is than both CIFAR-10 and MNIST present an overlap of 0.04\% for correctly classified images at or above threshold. Note we tag the images in the overlap as incorrectly classified, for the sake of assuring that all softmax distances to cluster centroid below threshold are correct classifications.

% \noindent \textbf{Accuracy decrease vs threshold decrease:} Having observed that the percentage of correctly classified images that have softmax distances equal or above threshold is 0.04\% for both CIFAR-10 and MNIST testing datasets, we ask how lowering the threshold affects the accuracy. Figure \ref{fig:Combined_CIFAR10_MNIST_single_plot_accuracy_decrements.png} reveals that for MNIST (left plot) classes accurately classified by the CNN model, such as zero and one, even setting the threshold at 10\% of the original class thresholds (0.9 on the x axis), still present accuracies greater than 0.97, meaning the class clusters are tightly placed near the centroids, while for digit 8, the most misclassified digit, had the threshold been set at 10\% of the original value, the accuracy would expect to drop to 0.84, meaning 16\% of the predictions would be deferred to human judgement, and 84\% would be considered 100\% accurate..

% Predictions with softmax distance to class centroid below the class threshold are expected to be 100\% accurate, class predictions with distances equal or greater than threshold are then left to human judgement.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % COMBINED CIFAR10 MNIST ACCURACY VS MEAN %
% % CLASS PREDICTION DISTANCE TO THRESHOLD  %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % Plot created by joining plots created by plot_accuracy_vs_distance_linear_fit

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.99\columnwidth]{Figures/Combined_CIFAR10_MNIST_single_plot_accuracy_decrements.png}
%     \caption{Please zoom in for detail. Expected accuracy decrease as a result of threshold decrease. MNIST data is on the left, CIFAR-10 is on the right. The x axis shows the threshold decrement in factors of 0.1, that is, at 0.1 the threshold is 90\% of the original threshold while at 0.9 the threshold is 10\% of the original threshold and consequently neared to the class centroid.}
% \label{fig:Combined_CIFAR10_MNIST_single_plot_accuracy_decrements.png}
% \end{figure}

% % % function call
% % % plot_digit_averages(test_correct_predictions, test_incorrect_predictions, color1='lightgreen', color2='lightcoral', data="Testing Data")
% % \begin{figure}[ht]
% %     \centering
% %     \includegraphics[width=0.99\columnwidth]{Figures/MNIST_Softmax_Averages_Training.png}
% %     \caption{Please zoom in for detail. Average Softmax Probabilities for Correctly and Incorrectly Classified Digits in the MNIST Testing Dataset.}
% %     \label{fig:MNIST_Softmax_Averages_Training}
% % \end{figure}


% Figure \ref{fig:MNIST_Softmax_Averages_Training} shows the average softmax probabilities for each digit class (0 to 9) in the MNIST training dataset, separated into correctly classified instances (top row) and incorrectly classified instances (bottom row). The probabilities are displayed on a logarithmic scale. For correctly classified digits, the highest average probability is observed for the corresponding true digit class, indicating strong confidence in the correct predictions. In contrast, for incorrectly classified digits, the average probabilities are more evenly distributed across different digit classes, suggesting lower confidence and potential confusion between similar-looking digits.
% Figure \ref{fig:MNIST_Softmax_Averages_Testing} is the corresponding plot for the MNIST testing dataset.

% % function call
% % plot_digit_averages(test_correct_predictions, test_incorrect_predictions, color1='lightgreen', color2='lightcoral', data="Testing Data")
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.99\columnwidth]{Figures/MNIST_Softmax_Averages_Testing.png}
%     \caption{Please zoom in for detail. Average Softmax Probabilities for Correctly and Incorrectly Classified Digits in the MNIST Testing Dataset.}
%     \label{fig:MNIST_Softmax_Averages_Testing}
% \end{figure}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Average Softmax Probabilities for Correctly and Incorrectly %
% % Classified Classes in the CIFAR10 dataset                   %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% % Plot generated by function call
% % single_plot_accuracy_decrements(accuracy_results, overall_results, labels=class_labels, dataset="CIFAR10", save=True)

% % \begin{figure}[ht]
% %     \centering    
% %     \includegraphics[width=0.99\columnwidth]{Figures/CIFAR10_single_plot_accuracy_decrements.png}
% %     \caption{Single plot Accuracy decrements}   \label{fig:CIFAR10_single_plot_accuracy_decrements}
% % \end{figure}

% % Function call to generate plot
% % plot_centroid_distance_bars(train_correct_predictions, 
%                             % train_incorrect_predictions, 
%                             % labels=class_labels, 
%                             % color1='lightblue', 
%                             % color2='lightcoral', 
%                             % data="CIFAR10 Training Data", 
%                             % save=True, 
%                             % filename='CIFAR10_training_plot_centroid_distance_bars.png')


% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.95\columnwidth]{Figures/CIFAR10_training_plot_centroid_distance_bars.png}
%     \caption{Please zoom in for detail. Average Softmax Probabilities for Correctly and Incorrectly Classified Classes in the CIFAR-10 Training Dataset}
%     \label{fig:CIFAR10_training_plot_centroid_distance_bars.png}
% \end{figure}

% % Function call to generate plot
% % plot_centroid_distance_bars(test_correct_predictions, 
% %                             test_incorrect_predictions, 
% %                             labels=class\t_labels, 
% %                             color1='lightgreen', 
% %                             color2='lightcoral', 
% %                             data="CIFAR10 Testing Data", 
% %                             save=True, 
% %                             filename='CIFAR10_testing_plot_centroid_distance_bars.png')

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.95\columnwidth]{Figures/CIFAR10_testing_plot_centroid_distance_bars.png}
%     \caption{Please zoom in for detail. Average Softmax Probabilities for Correctly and Incorrectly Classified classes in the CIFAR-10 Testing Dataset}
%     \label{fig:CIFAR10_testing_plot_centroid_distance_bars.png}
% \end{figure}

% % is a bar chart representing the mean softmax distances to class centroid for all correct (green) and all incorrect (red) classifications from the ViT model trained on CIFAR-10 data. 

% % The softmax distribution bar charts provide a view of the model's confidence and uncertainty in its predictions. The distinct patterns observed for correct and incorrect classifications offer valuable information about the model's decision-making process.

% For the CIFAR-10 we observe similar results. For correctly classified instances, the average softmax value corresponding to the true digit class is significantly higher compared to the softmax values of the other digit classes. This observation holds true across all digit classes in both the testing and training datasets. The pronounced difference in magnitudes indicates that the model assigns a high level of confidence to the correct predictions, with the predicted probability for the true class being orders of magnitude larger than the probabilities assigned to the other classes.

% In contrast, for incorrectly classified instances, the average softmax values exhibit a more even distribution across the digit classes. While the softmax value for the predicted class is still relatively high, the softmax values for the other classes are notably closer in magnitude, as evident from the shorter bars on the logarithmic scale. This suggests that when the model makes an incorrect prediction, it assigns more substantial probabilities to multiple classes, indicating a higher level of uncertainty or confusion in the decision-making process.
% Figures \ref{fig:CIFAR10_training_plot_centroid_distance_bars.png} and \ref{fig:CIFAR10_testing_plot_centroid_distance_bars.png} bar charts show the average softmax distributions for correct (green/blue) and incorrect (red) class predictions in both the testing and training CIFAR-10 datasets.

% Comparing the testing and training datasets, we observe similar patterns in the softmax distance distributions for both correct and incorrect predictions. The consistency of these patterns suggests that our approach is consistent across datasets and models. 

% The analysis of softmax distance distributions may be taken as an insight into the model's decision-making process. The difference in the softmax values between correct and incorrect predictions highlights the model's ability to discriminate between classes when it makes accurate predictions. On the other hand, the more evenly distributed softmax values for incorrect predictions suggest that the model struggles to make clear distinctions between classes in those cases, assigning considerable probabilities to multiple digits, where our proposed thresholding method may be an additional tool to help evaluate predictions in different settings.
