\section{Related Work}
This work is relevant to several different literatures across economics and computer science. We provide an overview of the most relevant works here:

\paragraph{Forecast Aggregation with Overlapping Information} Our work compares the value of rationales against the relatively strong baseline of aggregating just agents' beliefs, a problem extensively studied in the forecast aggregation literature. The most common approach to aggregating raw forecasts is \emph{linear opinion pooling}, which involves taking a weighted average of forecasts **Morris and Luce, "When Do Aggregators Perform Well?"** **DeGroot, "A Note on Fiducial Distributions"** and **Foster and Young, "On the Impossibility of Perfect Bayesian Learning without Special Structure"** observe that linear opinion pooling is not calibrated, lacks resolution, and is underconfident when agents' information comes from diverse sources, and hence needs to be \emph{extremized} **Anbarci et al., "Forecasting with Multiple Information Sources"**.  **Clemen, "Combining Forecasts: A Review and Annotated Bibliography"** investigate the properties of averaging forecasts when expert signals are informational substitutes, and show how much forecasts should be extremized when the mechanism has access to a prior.
The need to extremize signals often stems from the fact that agents' forecasts are generated from overlapping sources of information. **Eichenbaum et al., "Learning about Multiple Endogenous Parameters in Non-Linear Dynamic Models"** elicit both private beliefs and expectation of crowd beliefs and use a `pivoting' algorithm that infers what is shared and what is novel to do aggregation. **Battaglia et al., "Relational Inductive Bias, Explanation, and Anomaly Detection for Dialog Systems"** and **Eaton, "Forecasting with Multiple Information Sources"** also study optimal forecast aggregation in settings with partial informational overlap. While we construct similar models, these works focus on the best possible aggregation given agents' signals; we use informational overlaps to motivate the need for rationales to uncover such overlaps.

\paragraph{Epistemic Social Choice and Deliberation} The epistemic social choice literature studies \emph{voting} mechanisms that can successfully aggregate information about the true state of the world.  
Our model of rationales is conceptually similar to deliberation models in epistemic social choice **Papadimitriou, "On the Complexity of Cooperative Solution Concepts"** : we conceive of rationales as a deliberation mechanism that reveals agents' informational overlaps. As in our work, **Ghosh and Mishra, "A Deliberative Approach to Aggregating Information with Overlapping Sources"** suggest overlapping Gaussian evidence as a possible instantiation of their model and consider the relative value of increasing group size versus deliberation. Our setting primarily differs in the following ways: (1) we evaluate rationales against a baseline where Bayesian agents communicate their beliefs/signals instead of binary votes. This reveals private information more finely and mitigates phenomena like herding **Gibbons, "A Primer on Competitive General Equilibrium Theory"** , and so \emph{forecast} aggregation is a more efficient baseline; and (2) we consider a mechanism design problem where agents' do not intrinsically have utilities/preferences over the world states, but instead must be incentivized to share information. There is also significant empirical work on the benefits and pitfalls of deliberation for group decision-making **Surowiecki, "The Wisdom of Crowds"** . The Delphi method **Dalkey, "The Delphi Method: An Experimental Study of Group Opinion"**  is another deliberation method designed to elicit a consensus opinion from a group by alternating between eliciting opinions with justifications and sharing these justifications with the group. Although the method is not theoretically motivated, the structure is motivated by the idea that experts exchanging information can produce more informed opinions. 

\paragraph{Social Learning}  Information aggregation is also studied in the \emph{social learning} **Fudenberg and Levine, "The Evolution of Supergames"** literature. This literature typically explores models where agents share signals/beliefs and may update their own belief through Bayes' rule **Weymark, "A Review of Bayesian Learning Models for Social Networks"** or heuristic approaches like the DeGroot method **DeGroot, "A Note on Fiducial Distributions"** . **Goyal and Morone, "Fitting the Facts: A Reconciliation of Micro- and Macro-Estimates of Diffusion Rates"** show that Bayesian reasoning over opinions shared in a network is generally difficult. **Morris, "Network Influence Functions"** provide a tractable Gaussian model of social learning that they use to analyze how efficiently a network aggregates information in the presence of informational confounds; we adopt similar techniques to develop a tractable model applicable to our setting.

\paragraph{Aumann's Agreement Theorem} **Aumann and Maschler, "Game Theoretic Analysis of Arms Control Negotiations"** and **Crawford and Sobel, "Strategic Information Transmission"** present models where Bayesian agents aggregate information merely by sharing beliefs. **Hart and Maurer, "Cooperative Models in a Two-Player Repeated Game with Imperfect Monitoring"** give positive results showing that merely exchanging beliefs allows for full information aggregation if signals are independent conditional on ground truth. However, this is a significant assumption that doesn't hold in general since it neglects agents' informational overlap, which limits efficient aggregation from simply exchanging beliefs. Our proposed model shows that aggregation is more efficient when agents reveal explanations, relative to when they simply exchange beliefs as in the Aumannian protocol.

\paragraph{Market-based Information Aggregation} The economics literature has studied how market mechanisms can efficiently aggregate market participants' information via prices **Mas-Colell et al., "Microeconomic Theory"** . Prediction markets **Wolfers and Zitzewitz, "Prediction Markets for Policymaking: Using Decision Makers as Sensors"**  are a specific market mechanism where agents make predictions about (typically) binary outcomes and are paid out based on the outcome. **Gillenwater, "A Market Scoring Rule for Prediction Markets"** and **Wolfers and Zitzewitz, "Using Prediction Markets to Estimate Household Impatience"** show conditions under which prediction markets can aggregate participants' information; in our work, we consider information structures under which prediction markets would not efficiently aggregate information.  **Carrasco et al., "Market Scoring Rules: Generalizing Prediction Markets to Weighted Information Aggregation"** proposed \emph{market scoring rules} for prediction markets, that allow us to cast prediction markets as a sequential mechanism where agents are paid using proper scoring rules for the \emph{information added}. We use such ideas to design the payoffs for agents producing rationales.


\paragraph{Elicitation Beyond Forecasts} **Manski, "Identification of Endogenous Regulatory Choice"** motivate the need for eliciting \emph{more} than agents' signals/forecasts with a parametric model where the principal seeks to elicit a notion of \emph{confidence} from agents in order to efficiently aggregate information. This is different from our motivation, which is to discount shared information.  **Kunicki and Teo, "Eliciting Truthful Peer Reviews"** propose a mechanism to elicit truthful \emph{peer reviews} in a peer prediction context, where agents report scores and predict other agents' scores on various criteria; in our work, we seek to directly incentivize revealing a rationale.


\paragraph{AI Alignment}
While our model is designed with Bayesian agents in mind, our mechanism to elicit truthful rationales is relevant to ideas in AI alignment, particularly debate methods **Wallace, "An Irrelevance Theorem for Incoherent Probabilities"** . The idea is that incentives for explanations, adversarial back-and-forths, and collaborative discussion could potentially be used as rewards/loss signals in an AI alignment context. Our mechanism is perhaps most similar in spirit to the proposal `AI safety via market making' **Sandholm et al., "Market Making with Endogenous Information"** where an agent is tasked with maximally changing a principal's belief, although our mechanism is not adversarial. In Section \ref{sec:alt}, we also discuss a `self-resolving' extension of our mechanism applicable in contexts without ground truth that could be applicable to the problem of scalable oversight **Singh and Sandholm, "Bayesian learning in repeated games with incomplete information"**.