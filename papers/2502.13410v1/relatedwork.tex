\section{Related Work}
This work is relevant to several different literatures across economics and computer science. We provide an overview of the most relevant works here:

\paragraph{Forecast Aggregation with Overlapping Information} Our work compares the value of rationales against the relatively strong baseline of aggregating just agents' beliefs, a problem extensively studied in the forecast aggregation literature. The most common approach to aggregating raw forecasts is \emph{linear opinion pooling}, which involves taking a weighted average of forecasts \citep{armstrong2001combining}. \citet{ranjan2010combining} and \citet{satopaa2014combining} observe that linear opinion pooling is not calibrated, lacks resolution, and is underconfident when agents' information comes from diverse sources, and hence needs to be \emph{extremized} \citep{satopaa2015combining}.  \citet{Neyman2021AreYS} investigate the properties of averaging forecasts when expert signals are informational substitutes, and show how much forecasts should be extremized when the mechanism has access to a prior.
The need to extremize signals often stems from the fact that agents' forecasts are generated from overlapping sources of information. \citet{palley2019extracting} elicit both private beliefs and expectation of crowd beliefs and use a `pivoting' algorithm that infers what is shared and what is novel to do aggregation. \citet{satopaa2016modeling,satopaa2017partial} and \citet{babichenko2021learning} also study optimal forecast aggregation in settings with partial informational overlap. While we construct similar models, these works focus on the best possible aggregation given agents' signals; we use informational overlaps to motivate the need for rationales to uncover such overlaps.

\paragraph{Epistemic Social Choice and Deliberation} The epistemic social choice literature studies \emph{voting} mechanisms that can successfully aggregate information about the true state of the world.  
Our model of rationales is conceptually similar to deliberation models in epistemic social choice \citep{dietrich2024deliberation, ding2021deliberation}\@: we conceive of rationales as a deliberation mechanism that reveals agents' informational overlaps. As in our work, \citet{dietrich2024deliberation} suggest overlapping Gaussian evidence as a possible instantiation of their model and consider the relative value of increasing group size versus deliberation. Our setting primarily differs in the following ways: (1) we evaluate rationales against a baseline where Bayesian agents communicate their beliefs/signals instead of binary votes. This reveals private information more finely and mitigates phenomena like herding \citep{banerjee1992simple, bikhchandani1998learning}, and so \emph{forecast} aggregation is a more efficient baseline; and (2) we consider a mechanism design problem where agents' do not intrinsically have utilities/preferences over the world states, but instead must be incentivized to share information. There is also significant empirical work on the benefits and pitfalls of deliberation for group decision-making \citep{navajas2018aggregated, graeber2024explanations, lorenz2011social, moshman1998collaborative}. The Delphi method \citep{dalkey1963experimental, helmer1967analysis} is another deliberation method designed to elicit a consensus opinion from a group by alternating between eliciting opinions with justifications and sharing these justifications with the group. Although the method is not theoretically motivated, the structure is motivated by the idea that experts exchanging information can produce more informed opinions. 

\paragraph{Social Learning}  Information aggregation is also studied in the \emph{social learning} \citep{golub2017learning} literature. This literature typically explores models where agents share signals/beliefs and may update their own belief through Bayes' rule \citep{acemoglu2011bayesian} or heuristic approaches like the DeGroot method \citep{degroot1974reaching}. \citet{hkazla2021bayesian} show that Bayesian reasoning over opinions shared in a network is generally difficult. \citet{dasaratha2019aggregative} provide a tractable Gaussian model of social learning that they use to analyze how efficiently a network aggregates information in the presence of informational confounds; we adopt similar techniques to develop a tractable model applicable to our setting.

\paragraph{Aumann's Agreement Theorem} \citet{aumann1976agreeing} and \citet{geanakoplos1982we} present models where Bayesian agents aggregate information merely by sharing beliefs. \citet{kong2022false} give positive results showing that merely exchanging beliefs allows for full information aggregation if signals are independent conditional on ground truth. However, this is a significant assumption that doesn't hold in general since it neglects agents' informational overlap, which limits efficient aggregation from simply exchanging beliefs. Our proposed model shows that aggregation is more efficient when agents reveal explanations, relative to when they simply exchange beliefs as in the Aumannian protocol.

\paragraph{Market-based Information Aggregation} The economics literature has studied how market mechanisms can efficiently aggregate market participants' information via prices \citep{fama1970efficient}. Prediction markets \citep{wolfers2004prediction, chen2010gaming} are a specific market mechanism where agents make predictions about (typically) binary outcomes and are paid out based on the outcome. \citet{ostrovsky2009information} and \citet{kong2022false} show conditions under which prediction markets can aggregate participants' information; in our work, we consider information structures under which prediction markets would not efficiently aggregate information.  \citet{hanson2003combinatorial} proposed \emph{market scoring rules} for prediction markets, that allow us to cast prediction markets as a sequential mechanism where agents are paid using proper scoring rules for the \emph{information added}. We use such ideas to design the payoffs for agents producing rationales.


\paragraph{Elicitation Beyond Forecasts} \citet{frongillo2015elicitation} motivate the need for eliciting \emph{more} than agents' signals/forecasts with a parametric model where the principal seeks to elicit a notion of \emph{confidence} from agents in order to efficiently aggregate information. This is different from our motivation, which is to discount shared information.  \citet{srinivasan2021auctions} propose a mechanism to elicit truthful \emph{peer reviews} in a peer prediction context, where agents report scores and predict other agents' scores on various criteria; in our work, we seek to directly incentivize revealing a rationale.


\paragraph{AI Alignment}
While our model is designed with Bayesian agents in mind, our mechanism to elicit truthful rationales is relevant to ideas in AI alignment, particularly debate methods \citep{khan2024debating, michael2023debate, irving2018ai}. The idea is that incentives for explanations, adversarial back-and-forths, and collaborative discussion could potentially be used as rewards/loss signals in an AI alignment context. Our mechanism is perhaps most similar in spirit to the proposal `AI safety via market making' \citep{hubinger2020ai} where an agent is tasked with maximally changing a principal's belief, although our mechanism is not adversarial. In Section \ref{sec:alt}, we also discuss a `self-resolving' extension of our mechanism applicable in contexts without ground truth that could be applicable to the problem of scalable oversight \citep{bowman2022measuring}.


%-------------------------------------------------%