\subsection{Deep Learning Based HSI Classification}

According to the different learning paradigms, deep learning-based HSI classification approaches can be categorized into patch-based methods and patch-free methods~\cite{FPGA}. Patch-based methods focus on modeling local spectral-spatial information mapping functions:
\begin{equation}
    P_{pb}:R^{S{\times}S}{\rightarrow}R,
    \label{eq:patch_based_framework}
\end{equation}
where a neural network is trained with patches of size $S{\times}S$ extracted from the HSI imagery~\cite{10400402,10050427,9785505}. In contrast, patch-free methods aim to capture global spectral-spatial information mapping functions:
\begin{equation}
    P_{pf}:R^{H{\times}W{\times}C}{\rightarrow}R^{H{\times}W},
    \label{eq:patch_free_framework}
\end{equation}
where $H{\times}W$ represents the spatial size of the HSI imagery and $C$ denotes the number of spectral bands~\cite{8737729,HU2022147,9347487}.
Due to avoiding the utilization of patches, compared with patch-based methods, the GFLOPs of patch-free methods significantly decrease, and the inference time of patch-free methods has significantly improved hundreds of times~\cite{FPGA}.

Most of the existing HSI classifiers are based on the closed-set assumption, which is designed to classify known classes. In contrast, this work focuses on open-set HSI classification, which extends the capability of closed-set based HSI classifiers to not only classify known classes but also reject unknown classes.

\subsection{Open-Set Classification}

The objective of open-set classification is to simultaneously classify known classes and reject unknown classes~\cite{9040673}. Compared to closed-set classification, open-set classification is more challenging due to the incomplete supervision available for rejecting unknown classes~\cite{9857485}. Therefore, this section reviews open-set classification methods from the perspective of unknown classes rejection.

A rich line of method focuses on designing scoring functions for detecting unknown classes, such as the maximum predicted softmax probability (MSP)~\cite{MSP}, OpenMax~\cite{OpenMax}, ODIN score~\cite{ODIN}, Energy score~\cite{Energy}, Entropy score~\cite{Entropy}, MaxLogit score~\cite{KLMatching}, and KL Matching~\cite{KLMatching}. Recent researches have demonstrated that reconstruction loss~\cite{8953952,MDL4OW,Fang_OpenSet} and prototype distance~\cite{Kang_OpenSet,9296325,CACLoss,10415443} can also serve as metrics for rejecting unknown classes. However, these methods are typically trained with known data, and this paper demonstrates that a more robust open-set classifier can be achieved by incorporating naturally occurring wild data from the real-world environments, which can be collected freely.

Another line of research tries to reject unknown classes by using regularization during training~\cite{OE,EOS,Energy,Entropy,WOODS}. These methods typically require an auxiliary unknown classes dataset that is disjoint from $\mathbb{P}_{k}$. For example, models are encouraged to produce lower confidence~\cite{OE,Entropy} or higher energy scores~\cite{Energy} for these auxiliary unknown samples. Similar to this paper, WOODS~\cite{WOODS} also tries to leverage wild data from $\mathbb{P}_{wild}$ by formulating a constrained optimization problem. However, the performance of WOODS is limited by the scarcity of training samples and the significant spectral overlap in HSI.

Different from the abovementioned, this work pioneers the exploration of addressing the open-set HSI classification problem from the perspective of PU learning. Extensive comparisons and ablations demonstrate the clear superiority of the proposed framework.

\subsection{PU Learning}

Early PU learning methods rely on the two-step approach~\cite{FOODY20061,Gong_Wang_Ye_Xu_Lin_2018}, which first extracts reliable negative samples from unlabeled data, and then trains a supervised binary classifier by these positive and selected negative samples. However, the performance of these two-step classifiers is constrained by the reliability of the selected negative samples.

Recent research has shifted towards addressing PU learning using one-step approaches, such as cost-sensitive learning~\cite{9201373,LU2021112584}, label disambiguation~\cite{ijcai2019p590}, and density ratio estimation~\cite{kato2018learning}. What's more, the risk estimation-based methods have proven to be some of the most theoretically and practically effective~\cite{nnPU,ITreeDet,LI2022102947,HOneCls,PUET,DistPU}. However, most of these methods assume that the class prior is known beforehand, which is actually difficult to estimate due to the spectral overlap characteristic in HSI~\cite{T-HOneCls}.

Several researches are striving towards the PU learning without class prior. The generator in the generative adversarial network is replaced by a classifier to learn from PU data in PAN~\cite{PAN}. vPU~\cite{vPU} and T-HOneCls~\cite{T-HOneCls} formalize the PU learning task as the variational problem. P3Mix~\cite{p3mix} proposes a heuristic mixup approach to select partners for positive samples from unlabeled data.

In contrast to these methods, this paper focuses on the challenge of open-set classification. Additionally, in the aspect of class prior-free PU learning, this paper originates from a nontrivial perspective: the abnormal gradient weights associated with wild data.