\subsection{Overview}

The objective of open-set HSI classification is to classify known classes while simultaneously rejecting unknown classes. To achieve this, the proposed \textit{HOpenCls} is designed as a multi-task learning framework, as illustrated in Fig.~\ref{fig:hopencls_framework}. The \textit{HOpenCls} framework is highly flexible and can be implemented by integrating the proposed PU learning classifier with an existing multi-class HSI classifier. The PU learning classifier handles the task of rejecting unknown classes, while the known class classification task is addressed by the existing multi-class HSI classifier.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{framework.png}
    \caption{The proposed \emph{HOpenCls} framework. This framework can effectively leverage the wild data for open-set HSI classification. This framework includes multi-PU head, gradient contraction (Grad-C) and gradient expansion (Grad-E) PU learning algorithm. The PU learning component handles the rejection of unknown classes, while the classification of known classes is performed using an existing multi-class HSI classifier.}
    \label{fig:hopencls_framework}
\end{figure*}

\noindent \textbf{Problem Settings:}
Let $\mathcal{X}=\{\mathcal{X}_{k}, \mathcal{X}_{u}\} \in \mathbb{R}^{d}$ represent the input space, where $\mathcal{X}_{k}$ and $\mathcal{X}_{u}$ are the input space of known classes and unknown classes, respectively. The output space for the known classes classification task is denoted by $\mathcal{Y}_{k}=\{1,\dots,C\}$, where $C$ is the number of known classes. Additionally, let $\mathcal{Y}_{u}=\{0,1\}$ indicate the output space for the unknown classes rejection task, where 1 corresponds to known classes and 0 corresponds to unknown classes. Suppose the known classes training dataset is denoted as $\mathcal{D}_{k}=\{(\boldsymbol{x}^{i}_{k},y^{i}_{k},y^{i}_{u})\}_{i=1}^{n_{k}}\stackrel{\text{i.i.d}}{\sim}\mathbb{P}_{k}$, where $\boldsymbol{x}^{i}_{k} \in \mathcal{X}_{k}$, $y^{i}_{k} \in \mathcal{Y}_{k}$ is the classification label corresponding to the data $\boldsymbol{x}^{i}_{k}$ of known classes , $y^{i}_{u}=1 \in \mathcal{Y}_{u}$ indicate that $\boldsymbol{x}^{i}_{k}$ belongs to a known class, $n_{k}$ is the number of known classes training samples. The wild training dataset is represented as $\mathcal{D}_{wild}=\{\boldsymbol{x}^{i}_{wild}\}_{i=1}^{n_{wild}}\stackrel{\text{i.i.d}}{\sim}\mathbb{P}_{wild}$, where $\boldsymbol{x}^{i}_{wild} \in \mathcal{X}$, $n_{wild}$ is the number of wild training samples.

Let $q$ and $f$ denote the classifiers for known classes classification and unknown classes rejection, respectively. To reduce computational complexity, a global spectral-spatial feature extractor~\cite{FPGA} is shared by $q$ and $f$. For any test-time data $\boldsymbol{x} \in \mathcal{X}$, the open-set classification result $y$ can be obtained by:
\begin{equation}
    y=Q(\boldsymbol{x}){\otimes}F(\boldsymbol{x}),
\end{equation}
where $\otimes$ is the pointwise multiplication operator. $Q(\boldsymbol{x})$ and $F(\boldsymbol{x})$ are the classification results of $q(\boldsymbol{x})$ and $f(\boldsymbol{x})$, respectively.

\noindent \textbf{Known classes Classification:}
The goal of classifying known classes is to develop a classifier $q$, which can be obtained by minimizing the multi-class classification risk $\mathcal{R}_{k}$:
\begin{equation}
    \mathcal{R}_{k}(q)=\mathbb{E}_{(\boldsymbol{x}_{k},y_{k}){\sim}\mathbb{P}_{k}}\left[\mathcal{L}_{k}(q(\boldsymbol{x}_{k}),y_{k})\right],
    \label{eq:known_classes_risk}
\end{equation}
where $\mathcal{L}_{k}$ is the loss function for multi-class classification. In this paper, for generality, cross entropy (CE) loss ($\mathcal{L}_{ce}$) is used as $\mathcal{L}_{k}$. Eqn.~\ref{eq:known_classes_risk} can be estimated using the empirical averages over the dataset $\mathcal{D}_{k}$:
\begin{equation}
    \hat{\mathcal{R}}_{k}(q)=\frac{1}{n_{k}}\sum_{i=1}^{n_{k}}\mathcal{L}_{ce}(q(\boldsymbol{x}_{k}^{i}),y_{k}^{i}).
    \label{eq:known_classes_average_loss}
\end{equation}

\noindent \textbf{Unknown Classes Rejection:}
The task of rejecting unknown classes involves constructing a binary classifier $f$ that can determine whether a test-time data $\boldsymbol{x}$ belongs to known classes or not. Ideally, the $f$ is obtained by minimizing the unknown classes rejection risk $\mathcal{R}_{u}$:
\begin{equation}
    \mathcal{R}_{u}(f)=\frac{1}{2}\left(\mathcal{R}^{+}_{k}(f)+\mathcal{R}^{-}_{u}(f)\right),
    \label{eq:unknown_classes_risk}
\end{equation}
where $\mathcal{R}^{+}_{k}(f)=\mathbb{E}_{(\boldsymbol{x}_{k},1){\sim}{\mathbb{P}_{k}}}\left[\mathcal{L}_{u}(f(\boldsymbol{x}_{k}),1)\right]$ and $\mathcal{R}^{-}_{u}(f)=\mathbb{E}_{(\boldsymbol{x}_{u},0){\sim}{\mathbb{P}_{u}}}\left[\mathcal{L}_{u}(f(\boldsymbol{x}_{u}),0)\right]$, with $\mathcal{L}_{u}$ representing a binary classification loss function, such as the binary cross entropy (BCE) loss ($\mathcal{L}_{bce}$). $\boldsymbol{x}_{u}$ is the data from unknown classes. However, Eqn.~\ref{eq:unknown_classes_risk} cannot be directly computed in open-set HSI classification due to the absence of training data from unknown classes. Therefore, we focus on designing the multi-PU head, Grad-C module and Grad-E module to reject unknown classes trained by known classes and wild data in the following.

\subsection{Multi-PU Head}

The multi-PU head is designed to introduce the multi-label strategy into the \textit{HOpenCls}. The detailed structure multi-PU head is illustrated in the Fig.~\ref{fig:hopencls_framework}. Based on this design, the original task of unknown classes rejection is decomposed into multiple sub-PU learning tasks: The $c$-th sub-PU learning task is responsible for classifying the $c$-th known class against all other classes. Compared to the original unknown classes rejection task, each sub-PU learning task exhibits reduced intra-class variance of positive class, and the class prior of the $c$-th sub-PU learning task is $\pi_{task}^{c}=\pi_{c}<\pi$, more theoretical analysis about class prior can be found in Theorem ~\ref{theorem}.

In the $c$-th sub-PU learning task, the risk is defined as $\mathcal{R}_{pu}^{c}(f^{c})$:
\begin{equation}
    \mathcal{R}_{pu}^{c}(f^c)=\frac{1}{2}\left({\mathcal{R}^{c}_{k}}^{+}(f^c)+{\mathcal{R}_{wild}}^{-}(f^c)\right),
    \label{eq:cth_class_unknown_classes_risk}
\end{equation}
where ${\mathcal{R}^{c}_{k}}^{+}(f^c)=\mathbb{E}_{(\boldsymbol{x},1){\sim}{\mathbb{P}_{k}^{c}}}\left[\mathcal{L}_{u}(f^{c}(\boldsymbol{x}),1)\right]$, ${\mathcal{R}_{wild}}^{-}(f^c)=\mathbb{E}_{(\boldsymbol{x},0){\sim}{\mathbb{P}_{wild}}}\left[\mathcal{L}_{u}(f^{c}(\boldsymbol{x}),0)\right]$. Here, $\mathbb{P}_{k}^{c}$ represents the margin distribution of the $c$-th known class. The function $f^{c}$ is the binary classifier for the $c$-th sub-PU learning task.

The Eqn.~\ref{eq:cth_class_unknown_classes_risk} can be estimated using the empirical averages over the dataset $\mathcal{D}_{k}$ and the wild dataset $\mathcal{D}_{wild}$:
\begin{equation}
    \begin{aligned}
        \hat{\mathcal{R}}_{pu}^{c}(f^c)=&\frac{1}{2}(\frac{1}{n_{k}^{c}}\sum_{i=1}^{n_{k}^{c}}\mathcal{L}_{u}(f^{c}(\boldsymbol{x}^{ci}_{k}),1)+\\&\frac{1}{n_{wild}}\sum_{i=1}^{n_{wild}}\mathcal{L}_{u}(f^{c}(\boldsymbol{x}^{i}_{wild}),0)),
    \end{aligned}
    \label{eq:cth_class_unknown_classes_average_loss}
\end{equation}
where $\boldsymbol{x}^{ci}_{k}$ is the training sample of known class $c$ from the $\mathcal{D}_{k}$ and $n_{k}^{c}$ is the number of training data of known class $c$. The overall risk for unknown classes rejection with multi-PU head can be estimated as follows:
\begin{equation}
    \hat{\mathcal{R}}_{mpu}(f)=\sum_{c=1}^{C}\hat{\mathcal{R}}_{pu}^{c}(f^{c}).
    \label{eq:unknown_classes_risk_multi_pu_head_average_loss}
\end{equation}

As illustrated in Fig.~\ref{fig:hopencls_framework}, a sample $\boldsymbol{x}$ will be classified as belonging to known classes if any of the sub-PU learning classifiers identify it as known:
\begin{equation}
    F(\boldsymbol{x})=F^{1}(\boldsymbol{x}) \vee \dots \vee F^{c}(\boldsymbol{x}) \vee \dots \vee F^{C}(\boldsymbol{x}),
    \label{eq:unknown_rejection_multi_pu_head}
\end{equation}
where $F^{c}(\boldsymbol{x})$ is the classification result of $f^{c}(\boldsymbol{x})$, the symbol $\vee$ represents the logical OR operation.

\subsection{Grad-C and Grad-E Modules for PU Learning}

The Grad-C and Grad-E modules are designed to reject unknown classes from the perspective of PU learning. First, this paper reveals that the negative impact of replacing a pure unknown dataset by wild data stems from the larger gradient weights associated with wild data. Then, the Grad-C and Grad-E modules are designed to mitigate the adverse effects of these abnormal gradient weights. The comparison of different modules in the aspect of gradient weights is shown in Fig.~\ref{fig:grad}.

\begin{figure}[!t]
    \centering
    \includegraphics[width=0.98\columnwidth]{grad.png}
    \caption{Comparison of different modules against to wild known data. (a) The negative impact of unknown classes data replaced by wild data stems from the larger gradient weights associated with wild known data. (b) The Grad-C module reduces the gradient weights associated with both wild known and unknown data. (c) The Grad-E module restores the gradient weights for the wild unknown data by weighting mechanism.}
    \label{fig:grad}
\end{figure}

\noindent \textbf{Gradient Analysis:}
A commonly used choice for $\mathcal{L}_{u}$ in binary classification is the $\mathcal{L}_{bce}$:
\begin{equation}\nonumber
    \mathcal{L}_{bce}(f(\boldsymbol{x}),y_{u})=-y_{u}\log(f(\boldsymbol{x}))-(1-y_{u})\log(1-f(\boldsymbol{x})).
    \label{eq:binary_cross_entropy}
\end{equation}
The gradient of the $\mathcal{L}_{bce}$ with respect to the parameters $\boldsymbol{\theta}$ of the binary classifier $f$ is given by:
\begin{equation}
    \frac{\partial \mathcal{L}_{bce}(f(\boldsymbol{x}),y_{u})}{\partial \boldsymbol{\theta}}=(\frac{1-y_{u}}{1-f(\boldsymbol{x})}-\frac{y_{u}}{f(\boldsymbol{x})})\nabla_{\boldsymbol{\theta}}f({\boldsymbol{x}}).
    \label{eq:gradient_binary_cross_entropy}
\end{equation}

When the unknown data ($\boldsymbol{x}_{u},0$) is replaced with wild data ($\boldsymbol{x}_{wild},0$), a wild known data will be assigned a larger gradient weight (Eqn.~\ref{eq:gradient_wild_bce}) if it is predicted as known classes with high confidence ($f(\boldsymbol{x}_{wild}) \rightarrow 1$). The $f$ will overfit all wild known data as unknown classes, which disrupts the training process for rejecting unknown classes, as shown in Fig.~\ref{fig:grad}..
\begin{equation}
    \frac{\partial \mathcal{L}_{bce}(f(\boldsymbol{x}_{wild}),0)}{\partial \boldsymbol{\theta}}={\frac{1}{1-f(\boldsymbol{x}_{wild})}}\nabla_{\boldsymbol{\theta}}f(\boldsymbol{x}_{wild}).
\label{eq:gradient_wild_bce}
\end{equation}

\noindent \textbf{Grad-C Module:}
The Grad-C module---Taylor binary cross entropy (TBCE) loss ($\mathcal{L}_{tbce}$)---is proposed to mitigate the larger gradient weights problem, which contracts the gradient weights of all wild data by Taylor series expansion in $\mathcal{L}_{bce}$. Simultaneously, the effectiveness of the $\mathcal{L}_{tbce}$ for rejecting unknown classes can be theoretically proven.

Given a function $t(x)$, if this function is differentiable to order $o$ at $x=x_0$, this function can be expressed as:
\begin{equation}\nonumber
    t(x)=\sum_{o=0}^{\infty}\frac{t^{o}(x_0)}{o!}(x-x_0)^o,
\end{equation}
where $t^{o}(x_0)$ is the $o$-th order derivative of $t(x)$ at $x=x_0$.

Let $t(f(\boldsymbol{x}))=-\log(1-f(\boldsymbol{x}))$ and $f(\boldsymbol{x}_{0})=0$. For $\forall o \geq 1$, the $t(f(\boldsymbol{x}))$ can be expressed as:
\begin{equation}\nonumber
    t(f(\boldsymbol{x}))=\sum_{o=1}^{\infty}\frac{f(\boldsymbol{x})^o}{o}.
\end{equation}
Then, the $\mathcal{L}_{tbce}$ is formalized as:
\begin{equation}
    \mathcal{L}_{tbce}(f(\boldsymbol{x}),y_{u})=-y_{u}\log(f(\boldsymbol{x}))+(1-y_{u})\sum_{o=1}^{t}\frac{{f(\boldsymbol{x})}^{o}}{o},
    \label{eq:taylot_binary_cross_entropy}
\end{equation}
where $t \in \mathcal{N}^+$ is the truncation order of the Taylor series expansion.

The gradient of $\mathcal{L}_{tbce}$ with respect to $\boldsymbol{\theta}$ for a wild sample ($\boldsymbol{x}_{wild},0$) is:
\begin{equation}
    \frac{\partial \mathcal{L}_{tbce}(f(\boldsymbol{x}_{wild}),0)}{\partial \boldsymbol{\theta}}={\frac{1-f(\boldsymbol{x}_{wild})^{t}}{1-f(\boldsymbol{x}_{wild})}}\nabla_{\boldsymbol{\theta}}f(\boldsymbol{x}_{wild}).
    \label{eq:gradient_wild_tbce}
\end{equation}
From Eqn.\ref{eq:gradient_wild_bce} and Eqn.\ref{eq:gradient_wild_tbce}, the gradient weight of a wild data in $\mathcal{L}_{tbce}$ is lower than that in $\mathcal{L}_{bcc}$, effectively mitigating the problem of larger gradient weights:
\begin{equation}
    {\frac{1-f(\boldsymbol{x}_{wild})^{t}}{1-f(\boldsymbol{x}_{wild})}} < {\frac{1}{1-f(\boldsymbol{x}_{wild})}}.
\end{equation}

Let $\mathcal{R}_{pu}(f)$ denote the risk where the unknown data is replaced by the wild data in $\mathcal{R}_{u}(f)$:
\begin{equation}
    \mathcal{R}_{pu}(f)=\frac{1}{2}\left(\mathcal{R}^{+}_{k}(f)+\mathcal{R}^{-}_{wild}(f)\right),
    \label{eq:unknown_classes_risk_pu}
\end{equation}
where $\mathcal{R}^{-}_{wild}(f)=\mathbb{E}_{(\boldsymbol{x}_{wild},0){\sim}{\mathbb{P}_{wild}}}\left[\mathcal{L}_{u}(f(\boldsymbol{x}_{wild}),0)\right]$. Let $\hat{f}$ and $f^{*}$ be the global minimizers of $\mathcal{R}_{pu}(f)$ and $\mathcal{R}_{u}(f)$, respectively. The theoretical property of $\mathcal{L}_{tbce}$ is stated in Theorem~\ref{theorem}, which demonstrates the reliability of estimating the rejection risk using wild data and $\mathcal{L}_{tbce}$. A detailed proof is provided in Appendix.
\begin{theorem}\label{theorem}
    The $\mathcal{R}_{u}(\hat{f})-\mathcal{R}_{u}(f^{*})$ and $\mathcal{R}_{pu}(f^{*})-\mathcal{R}_{pu}(\hat{f})$ are bounded when $\mathcal{L}_{tbce}$ is used as the loss function:
    \begin{equation}
        \begin{aligned}
            0 \leq {\mathcal{R}_{u}(\hat{f})-\mathcal{R}_{u}(f^*)} \leq {\pi\mathcal{N}_t},
        \end{aligned}
    \end{equation}
    \begin{equation}
        \begin{aligned}
            0 \leq {\mathcal{R}_{pu}(f^*)-\mathcal{R}_{pu}(\hat{f})} \leq {\pi\mathcal{N}_t},
        \end{aligned}
    \end{equation}
    where $\mathcal{N}_{t}={\sum_{o=1}^{t}}\frac{1}{o}$ is a constant releated to the truncation order $t$.
\end{theorem}

Based on this theoretical analysis, the performance of $\mathcal{R}_{pu}$ can be further improved by reducing both $\mathcal{N}_{t}$ and ${\pi}$. A lower $\mathcal{N}_{t}$ can be obtained by decreasing the truncation order $t$. Although the $\pi$ is a fixed constant for a given open-set HSI classification task, the original task can be decoupled into multiple sub-PU learning tasks via the proposed multi-PU head, and each sub-task would have a lower class prior.

\noindent \textbf{Grad-E Module:}
As previously mentioned, the Grad-C module reduces the gradient weights associated with both wild known and unknown samples, which would lead to $f$ underfitting the wild unknown data. To address this issue, as illustrated in Fig.~\ref{fig:grad}, the Grad-E module is designed to restore the gradient weights for the wild unknown data by weighting mechanism.

As illustrated in Fig.~\ref{fig:hopencls_framework}, two deep neural networks are used to contract and expand the gradient weights of wild data, respectively. In the Grad-E module, the $\mathcal{L}_{bce}$ is utilized to restore the gradient weights of wild unknown data with the confidence scores output by the network trained with Grad-C module. Moreover, the performance can be further enhanced by incorporating the confidence scores produced by the network trained with Grad-E module into the $\mathcal{L}_{tbce}$.

The weighted binary cross entropy (\textit{w}BCE) loss ($\mathcal{L}_{bce}^{w}$) is defined as follows:
\begin{equation}\nonumber
    \mathcal{L}^{w}_{bce}(f(\boldsymbol{x}),y_{u})=-y_{u}\log(f(\boldsymbol{x}))-(1-y_{u}){w_{e}}\log(1-f(\boldsymbol{x})),
    \label{eq:weight_binary_cross_entropy}
\end{equation}
where $w_{e}$ is the confidence score of data $\boldsymbol{x}$ output by the network trained with Grad-C module.
Similarly, the weighted Taylor binary cross entropy (\textit{w}TBCE) loss ($\mathcal{L}^{w}_{tbce}$) can be formulated as:
\begin{equation}\nonumber
    \mathcal{L}^{w}_{tbce}(f(\boldsymbol{x}),y_{u})=-y_{u}\log(f(\boldsymbol{x}))+(1-y_{u}){w_{c}}\sum_{o=1}^{t}\frac{{f(\boldsymbol{x})}^{o}}{o},
    \label{eq:weight_taylor_binary_cross_entropy}
\end{equation}
where $w_{c}$ is the confidence of data $\boldsymbol{x}$ output by the network trained with Grad-E module. The wild unknown samples are expected to receive higher confidence scores, with a maximum value of $1$. The following describes the way for obtaining the confidence scores, which involves both confidence score updates and probability mixing.

In the process of updating confidence scores, both $w_{c}$ and $w_{e}$ are optimized during model training, with an exponential moving average applied to stabilize the training. Two strategies are proposed for updating the confidence scores: \textbf{continuous updating} (Eqn.~\ref{eq:continuous_updating}) and \textbf{discrete updating} (Eqn.~\ref{eq:discrete_updating}):
\begin{equation}
    \begin{aligned}
    w_{c}={\alpha}w_{c}+(1-{\alpha})p_{e}\\
    w_{e}={\alpha}w_{e}+(1-{\alpha})p_{c},
    \end{aligned}
    \label{eq:continuous_updating}
\end{equation}
\begin{equation}
    \begin{aligned}
        &w_{c}={\alpha}w_{c}+(1-{\alpha})\mathbb{I}(p_{e} \geq \tau)\\
        &w_{e}={\alpha}w_{e}+(1-{\alpha})\mathbb{I}(p_{c} \geq \tau),
    \end{aligned}
    \label{eq:discrete_updating}
\end{equation}
where $\mathbb{I}(\bullet)$ is the indicator function, the initial values of $w_{c}$ and $w_{e}$ are both $1$, and $\tau$ is set to $0.95$. More experiments about $\tau$ are discussed in the experiment section. Experiments demonstrate that $w_{e}$ is more suitable for discrete updating and $w_{c}$ is better suited for continuous updating.

A straightforward way to compute $p_{c}$ and $p_{e}$ is by directly using the probability outputs from $f$ (\textbf{Pro}):
\begin{equation}
    \begin{aligned}
        p_{c}=1-f_{c}(\boldsymbol{x})\\
        p_{e}=1-f_{e}(\boldsymbol{x}),
    \end{aligned}
    \label{eq:pro}
\end{equation}
where $f_{c}(\boldsymbol{x})$ and $f_{e}(\boldsymbol{x})$ are the binary classifiers trained with $\mathcal{L}_{tbce}^{w}$ and $\mathcal{L}_{bce}^{w}$, respectively. However, this simplistic approach ignores the consistency between $q$ and $f$ (with multi-PU head): data from known classes should exhibit high probability outputs in both classifiers simultaneously. Therefore, a probability mixture strategy is proposed to incorporate the ability of classifying known classes of multi-class classifier into the multiple unknown rejection classifiers (\textbf{MixPro}):
\begin{equation}
    \begin{aligned}
        &p_{c}=1-(q_{c}^{c}(\boldsymbol{x}){\times}f_{c}^{c}(\boldsymbol{x}))\\
        &p_{e}=1-(q_{e}^{c}(\boldsymbol{x}){\times}f_{e}^{c}(\boldsymbol{x})),
    \end{aligned}
    \label{eq:mixpro}
\end{equation}
where $q_{\bullet}^{c}(\boldsymbol{x})$ is the probability output of the $c$-th class from the known classes classifier, $f_{\bullet}^{c}(\boldsymbol{x})$ is the probability output of the $c$-th sub-PU task. $q_{c}$ and $f_{c}$ share the same feature extractor, while $q_{e}$ and $f_{e}$ also share the same feature extractor. Moreover, the outputs of the $f_{c}^{c}(\boldsymbol{x})$ and $f_{e}^{c}(\boldsymbol{x})$ are aligned using KL divergence in the unknown rejection task, enabling the two networks to act as mutual teachers~\cite{T-HOneCls}.

\subsection{Overall Risk}

The risks for the two networks are defined as follows:
\begin{equation}
    \begin{aligned}
        &\hat{\mathcal{R}}_{c}(q_{c},f_{c})=\hat{\mathcal{R}}_{k}(q_{c})+\hat{\mathcal{R}}_{mpu}(f_{c},\mathcal{L}^{w}_{tbce})\\
        &\hat{\mathcal{R}}_{e}(q_{e},f_{e})=\hat{\mathcal{R}}_{k}(q_{e})+\hat{\mathcal{R}}_{mpu}(f_{e},\mathcal{L}^{w}_{bce}),
    \end{aligned}
\end{equation}
where $\hat{\mathcal{R}}_{mpu}(\bullet,\mathcal{L}^{w}_{tbce})$ and $\hat{\mathcal{R}}_{mpu}(\bullet,\mathcal{L}^{w}_{bce})$ represent that the loss function $\mathcal{L}^{w}_{tbce}$ and $\mathcal{L}^{w}_{bce}$ are used in Eqn.~\ref{eq:unknown_classes_risk_multi_pu_head_average_loss}, respectively.

The overall risk for the \textit{HOpnCls} framework can be formulated as follows:
\begin{equation}\nonumber
    \hat{\mathcal{R}}_{all}(q_{c},f_{c},q_{e},f_{e}) = \hat{\mathcal{R}}_{c}(q_{c},f_{c})+\hat{\mathcal{R}}_{e}(q_{e},f_{e})+\beta\hat{\mathcal{R}}_{kl}(f_{c},f_{e}),
\end{equation}
where the risk from KL divergence is denoted as $\hat{\mathcal{R}}_{kl}(f_{c},f_{e})$ and $\beta$ is a hyperparameter.