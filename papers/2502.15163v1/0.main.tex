\documentclass[lettersize,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{rotating}
\usepackage{ragged2e}
\usepackage{tablefootnote}
\usepackage{hhline}
\usepackage[switch]{lineno}
\newtheorem{lemma}{\bf Lemma}
\newtheorem{theorem}{\bf Theorem}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\begin{document}
% \linenumbers

\title{HOpenCls: Training Hyperspectral Image Open-Set Classifiers in Their Living Environments}

\author{Hengwei~Zhao, Xinyu~Wang, Zhuo~Zheng, Jingtao~Li, Yanfei~Zhong% <-this % stops a space

\thanks{This work was supported by the National Natural Science Foundation of China under Grant No. 42325105.}
% \textit{(Corresponding author: Yanfei Zhong, Xinyu Wang)}}% <-this % stops a space
\thanks{Hengwei Zhao, Jingtao Li and Yanfei Zhong are with the State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, China (e-mail:whu\_zhaohw@whu.edu.cn; jingtaoli@whu.edu.cn; zhongyanfei@whu.edu.cn).}
\thanks{Zhuo Zheng is with the Department of Computer Science, Stanford University, United States (e-mail: zhuozheng@cs.stanford.edu).}
\thanks{Xinyu Wang is with the School of Remote Sensing and Information Engineering, Wuhan University, China (e-mail: wangxinyu@whu.edu.cn).}
}

% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

% \IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
Hyperspectral image (HSI) open-set classification is critical for HSI classification models deployed in real-world environments, where classifiers must simultaneously classify known classes and reject unknown classes. Recent methods utilize auxiliary unknown classes data to improve classification performance. However, the auxiliary unknown classes data is strongly assumed to be completely separable from known classes and requires labor-intensive annotation. To address this limitation, this paper proposes a novel framework, \textit{HOpenCls}, to leverage the unlabeled wild data---that is the mixture of known and unknown classes. Such wild data is abundant and can be collected freely during deploying classifiers in their \textit{living environments}. The key insight is reformulating the open-set HSI classification with unlabeled wild data as a positive-unlabeled (PU) learning problem. Specifically, the multi-label strategy is introduced to bridge the PU learning and open-set HSI classification, and then the proposed gradient contraction and gradient expansion module to make this PU learning problem tractable from the observation of abnormal gradient weights associated with wild data. Extensive experiment results demonstrate that incorporating wild data has the potential to significantly enhance open-set HSI classification in complex real-world scenarios.
\end{abstract}

\begin{IEEEkeywords}
Hyperspectral image classification, Open-set classification, Positive-unlabeled learning.
\end{IEEEkeywords}

\section{Introduction}
\input{1.Intro.tex}

\section{Related Works}
\input{2.Releated_work.tex}

\section{Methodology}\label{sec:Methodology}
\input{3.Method.tex}

\section{Experimental Results}
\input{4.Rsults.tex}

\section{Conclusion}
This paper proposes a novel open-set HSI classification framework utilizing wild data. Wild data holds significant promise due to its abundance, ease of collection, and better alignment with real-world data distributions. However, the mixed margin distribution of wild data, comprising both $\mathbb{P}_{k}$ and $\mathbb{P}_{u}$, presents challenges for its effective utilization. To overcome this challenge, this paper formulates it as a PU learning problem and specifically proposes a multi-PU head, Grad-C module, and Grad-E module to make it tractable. The results demonstrate that wild data can dramatically promote open-set HSI classification in practice, thereby helping to expedite the deployment of trustworthy models in complex real-world scenarios.

% \section*{Acknowledge}
% The authors would like to thank Dr. Wenzhe Jiao for his valuable comments and suggestions, which greatly enhanced the manuscript.

\appendix
\section*{Proof of the Theorem.\ref{theorem}}
\input{5.appendix.tex}

{\small
% \bibliographystyle{ieee_fullname}
\bibliographystyle{IEEEtran}
\bibliography{HOpenCls_ref}
}

\end{document}