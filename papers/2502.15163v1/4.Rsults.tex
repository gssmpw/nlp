\subsection{Experimental Settings}
\noindent \textbf{Datasets:}
To evaluate the performance of different methods, four HSI datasets are utilized: the University of Pavia dataset (Fig.~\ref{fig:open_set_example}) and the WHU-Hi series datasets~\cite{WHU-Hi} (Fig.~\ref{fig:datasets}): WHU-Hi-HongHu, WHU-Hi-LongKou, and WHU-Hi-Hanchuan. Notably, the WHU-Hi series datasets present significant spectral overlap~\cite{WHU-Hi}, making open-set HSI classification particularly challenging.

In the University of Pavia dataset, the original 9 classes are treated as known classes, while pixels that differ significantly from these known classes, such as buildings with notable reflective differences, are labeled as unknown classes, following the settings in~\cite{MDL4OW}. For the WHU-Hi series datasets, certain crop categories are considered as known classes, while other categories are labeled as unknown. This aligns with practical crop mapping scenarios, where the labeling workload is substantially reduced by focusing on crop categories, minimizing the need for annotating non-crop classes.

To simulate limited training sample conditions, only 100 samples per class are selected from each dataset for model training, with an additional 4000 wild samples randomly drawn from the imagery. Detailed information about the datasets is provided in Table~\ref{tab:datasets}.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{dataset.png}
    \caption{The WHU-Hi series HSI datasets: WHU-Hi-HongHu, WHU-Hi-LongKou, and WHU-Hi-HanChuan.}
    \label{fig:datasets}
\end{figure*}

\input{tab/datasets}

\noindent \textbf{Compared Methods:}
Two groups of methods are compared for thorough comparison: (1) trained with only $\mathbb{P}_{k}$ data: OpenMax~\cite{OpenMax}, CAC Loss~\cite{CACLoss}, MDL4OW~\cite{MDL4OW}, KL Matching~\cite{KLMatching}, MSP~\cite{MSP}, Energy~\cite{Energy} and Entropy~\cite{Entropy}; (2) trained with both $\mathbb{P}_{k}$ data and an additional dataset: DS3L~\cite{DS3L}, WOODS~\cite{WOODS}, OE~\cite{OE} and EOS~\cite{EOS}. Specifically, in addition to wild data, pure unknown classes data from $\mathbb{P}_{u}$ and wild data excluding unknown classes from $\mathbb{P}_{wild}-\mathbb{P}_{u}$ are used as the auxiliary data to demonstrate the robustness of \textit{HOpenCls} with respect to varying auxiliary data sources. To ensure a fair comparison, an equal amount of data (4000) from both distributions in the auxiliary dataset is randomly selected for model training.

Moreover, \textit{HOpenCls} is also compared with recently proposed PU learning methods (HOneCls~\cite{HOneCls} and T-HOneCls~\cite{T-HOneCls}) to demonstrate its effectiveness in PU learning tasks.

\noindent \textbf{Training Details:}
For patch-free methods, FreeNet~\cite{FPGA} is used as the spectral-spatial feature extractor. In the patch-based approaches, the encoder of FreeNet is used for the same purpose, with patch sizes increased to 9 to counteract the underutilization of spatial information caused by smaller spatial blocks. The \textit{HOpenCls} model was trained by 130 epoches (lr=$3{\times}10^{-4}$, momentum=0.9, weight\_decay=$10^{-4}$) with a ``CosineAnnealingLR'' learning rate policy. The default values for the weight $\beta$ and the Taylor expansion order $o$ were set to $1$ and $2$, respectively.

\noindent \textbf{Metrics:}
Following standard practice, Overall Accuracy (OA) is used to evaluate classifier performance. OA with and without unknown classes is referred to as Open OA and Closed OA, respectively. To evaluate the modelâ€™s ability to reject unknown classes, the F1 score (F1\textsuperscript{u}) and the Area Under the Curve (AUC\textsuperscript{u}) are also reported. All experiments were repeated 5 times, and the mean and standard deviation values are reported.

\subsection{Main Results}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{results_HH.png}
    \caption{Open-set classification maps of WHU-Hi-HongHu dataset.}
    \label{fig:result_HH}
\end{figure*}

\input{tab/main_results}

\input{tab/closed_oa}

\noindent \textbf{\textit{HOpenCls} Achieves Superior Performance:}
\textit{HOpenCls} achieves the highest scores across all metrics and datasets. The results for Open OA, F1\textsuperscript{u}, and AUC\textsuperscript{u} are detailed in Table~\ref{tab:main_results}, while the closed OA results are presented in Table~\ref{tab:closed_OA}. Classification maps generated by different methods can be found in Fig.~\ref{fig:result_HH}-Fig.~\ref{fig:result_PU}. Compared to the second-best method, \textit{HOpenCls} shows improvements in Open OA of 8.20, 3.46, 4.99, and 3.05 on the WHU-Hi-HongHu, WHU-Hi-LongKou, WHU-Hi-HanChuan, and University of Pavia, respectively. Notably, for unknown class rejection tasks, \textit{HOpenCls} exhibits significant improvements in F1\textsuperscript{u}, with gains of 38.91, 3.66, 3.56, and 20.93 on the same datasets, respectively.

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{results_LK.png}
    \caption{Open-set classification maps of WHU-Hi-LongKou dataset.}
    \label{fig:result_LK}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{results_HC.png}
    \caption{Open-set classification maps of WHU-Hi-HanChuan dataset.}
    \label{fig:result_HC}
\end{figure*}

\input{tab/additional_data}

\begin{figure*}[!t]
    \centering
    \includegraphics[width=0.98\textwidth]{results_PU.png}
    \caption{Open-set classification maps of University of Pavia dataset.}
    \label{fig:result_PU}
\end{figure*}

Several observations should be highlighted: (1) A significant bottleneck in the development of HSI classifiers is the challenge of rejecting unknown classes. Different classifiers show substantial variation in their performance on this task, take the WHU-Hi-HongHu HSI dataset as an example, with some suffering from under-recognition (e.g., KL Matching, MSP, Entropy, and DS3L) and others from over-recognition (e.g., Energy, WOODS, OE, and EOS). The proposed \textit{HOpenCls} effectively balances these issues, achieving a 38.91 and 20.93 improvement in F1\textsuperscript{u} on the WHU-Hi-HongHu and University of Pavia datasets, respectively. (2) \textit{HOpenCls} not only excels at unknown classes rejection but also improves classification performance on known classes. The task of unknown classes rejection has the ability to improve the classification performance of known classes in the proposed framework, which exhibits the effectiveness of the multi-task architecture. (3) The use of additional data can negatively affect classifier performance. For example, on the WHU-Hi-HongHu dataset, WOODS underperforms compared to OpenMax and CAC Loss, both of which do not incorporate additional data. Additionally, classifiers like OE and EOS experience significant degradation due to the influence of known class components in wild data. This suggests that while wild data is easily accessible, it introduces greater challenges for algorithm design.

\noindent \textbf{\textit{HOpenCls} is Robust to the Sources of Auxiliary Dataset:}
Three types of extra datasets are used to evaluate the robustness of the proposed \textit{HOpenCls} concerning the sources of the extra dataset. Wild data, which is the focus of this paper, can be obtained from the living environments of the classifiers with almost no cost, the results are shown in Table~\ref{tab:main_results}. Pure unknown classes data represents the ideal extra data but is labor-intensive to obtain, originating from the distribution of $\mathbb{P}_{u}$. Wild data without unknown classes poses the greatest challenge, providing no information about unknown classes and coming from the distribution of $\mathbb{P}_{wild}-\mathbb{P}_{u}$. The results of the models trained with pure unknown data or wild data excluding unknown classes are shown in Table~\ref{tab:additional_data}.

Some conclusions can be drawn from the results: (1) \textit{HOpenCls} demonstrates robustness to the source of extra data, and the performance of the proposed model does not significantly decrease compared to other methods when wild data excluding unknown classes is used as extra data. (2) The use of pure unknown data significantly enhances performance, indicating that it is the most effective form of extra data. However, acquiring unknown data is labor-intensive, and the collected unknown data is usually difficult to cover all the unknown classes. (3) Wild data is the potential extra data that can be almost freely collected, but the wild data propose higher demands on the algorithm design due to the wild data is the mixture of known and unknown classes. Due to the influence of known classes in the wild data, both OE and EOS suffer from significant performance degradation. (4) The proposed \textit{HOpenCls} achieves the best metrics across all datasets when using wild data excluding unknown classes, suggesting that it excels at discovering novel classes because this dataset does not contain any information about unknown classes.

\noindent \textbf{The combination of Grad-C and Grad-E Modules is a Powerful Classifier for PU Learning:}
Compared to other HSI PU learning methods, the combination of Grad-C and Grad-E modules, referred to as \textit{HOpenCls(PU)}, achieves better performance in PU learning tasks (Table~\ref{tab:pu_results}). Due to the limitations of inaccurate class priors, the performance of HOneCls significantly decreases. Compared to the class prior-free method (T-HOneCls), the proposed method gets better performance, particularly in high class prior scenarios, such as for Cotton and Broad-leaf soybean.

\input{tab/pu_results}

Furthermore, the performance of other loss function for the HSI PU learning task is also analyzed within the \textit{HOpenCls} framework, the proposed $\mathcal{L}_{tbce}$ get the best performance (Table~\ref{tab:diff_loss_results}).

\input{tab/different_pu_loss_results}

\subsection{Ablation Experiments Analysis}

Ablation experiments are conducted to evaluate the effectiveness of each module in the proposed \textit{HOpenCls}. The results are presented in Table~\ref{tab:ablation_experiments}. More detailed analysis can be found in the following:

\noindent \textbf{Multi-PU Head:}
The comparison between exp.1 and exp.2 highlights the significant role of the multi-PU head in the proposed \textit{HOpenCls}. For example, on the WHU-Hi-HongHu dataset, the Open OA, F1\textsuperscript{u}, and AUC\textsuperscript{u} scores improved by 27.66, 11.82, and 27.65, respectively. Similar improvements can also be observed in the comparison between exp.3 and exp.4.

\noindent \textbf{Grad-C Module:}
The comparison betweent exp.2 and exp.4 demonstrates that the Grad-C module is an effective solution for addressing the rejection of unknown classes in HSI. According to the Theorem~\ref{theorem}, the proposed $\mathcal{L}_{tbce}$ achieves better performance when the probability of the positive class is lower. Therefore, based on the combined experimental results of exp.1 to exp.4, greater improvements are observed when combining the multi-PU head with $\mathcal{L}_{tbce}$.

\noindent \textbf{Grad-E Module:}
Building upon $\mathcal{L}_{tbce}$, better open-set HSI classification results can be achieved by selectively restoring the gradient for wild unknown data, as demonstrated by the comparison between exp.4 and exp.5. Additionally, ensuring consistency between the two networks (exp.4 and exp.6) and applying the $\mathcal{L}_{tbce}^{w}$ (exp.6 and exp.7) further improves the performance of \textit{HOpenCls}.

\input{tab/ablation_experiments.tex}

\begin{figure*}[!t]
    \centering
    \subfloat[\small{Analysis of the order of Taylor series}]{
    \label{fig:taylor_series_analysis}
    \includegraphics[width=0.33\textwidth]{taylor_series.png}}
    \subfloat[\small{Analysis of the $\beta$}]{
    \label{fig:beta_analysis}
    \includegraphics[width=0.33\textwidth]{beta.png}}
    \subfloat[\small{Analysis of the $\tau$}]{
    \label{fig:tao_analysis}
    \includegraphics[width=0.33\textwidth]{tao.png}}
    \caption{Parametric Analysis of the HOpenCls framework.}
    \label{fig:parametric_analysis}
\end{figure*}

\noindent \textbf{Confidence Score Updating:}
Additional experiments were conducted to analyze the confidence scores updating strategies in the Grad-C and Grad-E modules, with results shown in Table~\ref{tab:confidence_update_stargeies}. The results demonstrate that discrete updating is more suited to the Grad-E module, while continuous updating works better for the Grad-C module. This suggests that less ambiguous information is more beneficial for the Grad-E module.

\input{tab/confidence_update_strategies.tex}

\noindent \textbf{MixPro:}
Compared to the straightforward approach (Pro), MixPro leverages the consistency between the known classes classifier and multiple sub-PU classifiers. This strategy integrates the classification capability of the known classes classifier into the unknown classes rejection task, further enhancing the performance of the proposed \textit{HOpenCls}. (Table~\ref{tab:probability_mixture}).

\input{tab/probability_mixture_strategy.tex}

\input{tab/number_of_networks.tex}

\noindent \textbf{Two Networks Cooperative Optimization:}
In the proposed \textit{HOpenCls}, two networks are optimized cooperatively to mitigate discrepancies (such as low-probability predictions) between $\mathcal{L}_{tbce}^{w}$ and $\mathcal{L}_{bce}^{w}$. As shown in Table~\ref{tab:number_of_networks}, optimizing a single network yields worse performance compared to the proposed \textit{HOpenCls}.

\noindent \textbf{Parametric Analysis}
Experiments were conducted to analyze the parametric sensitivity of \textit{HOpenCls}, with the results presented in Fig.~\ref{fig:parametric_analysis}. Several key observations can be made from the results: (1) The proposed \textit{HOpenCls} is robust to variations in $o$, $\beta$, and $\tau$; (2) Better unknown classes rejection results (F1\textsuperscript{u}) are achieved with lower-order Taylor series expansions, consistent with Theorem~\ref{theorem}; (3) Increasing $\tau$ leads to higher Open OA and F1\textsuperscript{u}, suggesting that the Grad-E module benefits from more accurate unknown classes data.