% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
% \usepackage[utf8x]{inputenc}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[makeroom]{cancel}
\usepackage{tabularx}
\usepackage{xcolor}
\usepackage{hyperref}

\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{amssymb}
\usepackage{microtype}
\usepackage{CJKutf8}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage[T1]{fontenc}
\usepackage{pifont}

\usepackage{tcolorbox}
\tcbuselibrary{breakable}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.
\definecolor{warningcolor}{RGB}{255,0,0}
\title{Be a Multitude to Itself: A Prompt Evolution Framework for Red Teaming
\\ {\color{warningcolor} \normalsize WARNING: This paper contains potentially harmful LLMs-generated content.}}

\newcommand{\peiyi}[1]{\textcolor{orange}{\bf \small [ #1 --Peiyi]}}

\newcommand{\modelname}{\textsc{Rtpe}\xspace}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in


\author{
Rui Li$^1$, Peiyi Wang$^1$, Jingyuan Ma$^1$, Di Zhang$^1$, Zhifang Sui$^1$\thanks{~~Corresponding author}, Lei Sha$^2$\\
\small{
$^1$State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University}\\
\small{$^2$Institute of Artificial Intelligence, Beihang University}\\
\small{\texttt{o\_l1ru1@stu.pku.edu.cn}}
}




\begin{document}
\maketitle

\input{a_section/abstract}
\input{a_section/Introduction}
\input{a_section/Related_Work}
\input{a_section/Method}
\input{a_section/Experiments}
\input{a_section/Conclusion}



\section*{Limitations}
Due to budget and access constraints, we did not conduct comprehensive testing on more advanced models such as GPT-4, claude-3, or larger open-source models such as Llama-2-70b. However, through online free testing at https://chat.lmsys.org/, we observed that the attack prompts generated via our methodology also exhibit effectiveness against those more advanced models. Besides, our study currently does not provide concrete methods for defending LLMs against such attacks and we will leave this as future work.

\section*{Ethics Statement}
In this study, we introduce a method for automatically generating attack prompts that could potentially induce LLMs to generate replies including offensive, harmful, or extreme content. It is essential to clarify that our research is ethically driven towards strengthening the security of LLMs rather than facilitating malicious activities. 
Our research aims to identify and address vulnerabilities in current LLMs increase awareness, and stimulate further exploration into the development of more robust and ethical artificial intelligence systems. We have implemented stringent criteria to avoid misclassifying unsafe response as safe, thereby mitigating unnecessary controversy.
Any inclusion of unsafe content is strictly for academic purposes and does not represent the personal views or beliefs of the researchers involved. Our objective is to contribute to the advancement of AI ethics and responsible AI development.

\section*{Acknowledgements}
% Entries for the entire Anthology, followed by custom entries
This paper is supported by the National Key Research and Development Program of China 2020AAA0106700.
\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}



\label{sec:appendix}
\input{a_section/appendixx}

\end{document}
