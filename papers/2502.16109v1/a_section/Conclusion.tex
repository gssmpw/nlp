\section{Conclusion}
In this paper, we focus on red teaming in the context of LLM. We see effective attack prompts as scarce resource and propose an attack prompt evolution framework called \modelname, which evolves attack prompts in both breadth and depth dimensions to scale up the attack prompts and steer the development of diverse content and forms for pre-generated prompts. Through experiments, we demonstrate that our framework performs well on both ASR and diversity, surpassing all baselines. Based on these prompts, we systematically evaluate a series of LLMs on sensitive topics and analyze them across different dimensions. Additionally, we offer detailed discussions on the variation of pre-generated attack prompts.
