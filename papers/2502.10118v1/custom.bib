@misc{li2022blipbootstrappinglanguageimagepretraining,
      title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation}, 
      author={Junnan Li and Dongxu Li and Caiming Xiong and Steven Hoi},
      year={2022},
      eprint={2201.12086},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.12086}, 
}

@misc{radford2021learningtransferablevisualmodels,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2103.00020}, 
}

@misc{wang2022imageforeignlanguagebeit,
      title={Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks}, 
      author={Wenhui Wang and Hangbo Bao and Li Dong and Johan Bjorck and Zhiliang Peng and Qiang Liu and Kriti Aggarwal and Owais Khan Mohammed and Saksham Singhal and Subhojit Som and Furu Wei},
      year={2022},
      eprint={2208.10442},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2208.10442}, 
}

@misc{chen2023learningdistinctrepresentativestyles,
      title={Learning Distinct and Representative Styles for Image Captioning}, 
      author={Qi Chen and Chaorui Deng and Qi Wu},
      year={2023},
      eprint={2209.08231},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2209.08231}, 
}

@inproceedings{yuksekgonul2022and,
  title={When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?},
  author={Yuksekgonul, Mert and Bianchi, Federico and Kalluri, Pratyusha and Jurafsky, Dan and Zou, James},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@misc{bianco2023improvingimagecaptioningdescriptiveness,
      title={Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion}, 
      author={Simone Bianco and Luigi Celona and Marco Donzella and Paolo Napoletano},
      year={2023},
      eprint={2306.11593},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.11593}, 
}

@misc{aneja2019sequentiallatentspacesmodeling,
      title={Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning}, 
      author={Jyoti Aneja and Harsh Agrawal and Dhruv Batra and Alexander Schwing},
      year={2019},
      eprint={1908.08529},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1908.08529}, 
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}


@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@InProceedings{Goyal_2017_CVPR,
author = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
title = {Making the v in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@inproceedings{hosang2017learning,
  title={Learning non-maximum suppression},
  author={Hosang, Jan and Benenson, Rodrigo and Schiele, Bernt},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4507--4515},
  year={2017}
}

@article{xie2019visual,
  title={Visual entailment: A novel task for fine-grained image understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint arXiv:1901.06706},
  year={2019}
}

@inproceedings{suhr2019corpus,
  title={A Corpus for Reasoning about Natural Language Grounded in Photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={6418--6428},
  year={2019}
}





@inproceedings{xu2021towards,
  title={Towards accurate text-based image captioning with content diversity exploration},
  author={Xu, Guanghui and Niu, Shuaicheng and Tan, Mingkui and Luo, Yucheng and Du, Qing and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12637--12646},
  year={2021}
}

@INPROCEEDINGS{cider,
  author={Vedantam, Ramakrishna and Zitnick, C. Lawrence and Parikh, Devi},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CIDEr: Consensus-based image description evaluation}, 
  year={2015},
  volume={},
  number={},
  pages={4566-4575},
  keywords={Measurement;Protocols;Accuracy;Training;Testing;Silicon;Correlation},
  doi={10.1109/CVPR.2015.7299087}}



@inproceedings{yao2019hierarchy,
  title={Hierarchy parsing for image captioning},
  author={Yao, Ting and Pan, Yingwei and Li, Yehao and Mei, Tao},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2621--2629},
  year={2019}
}

@inproceedings{cornia2020meshed,
  title={Meshed-memory transformer for image captioning},
  author={Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10578--10587},
  year={2020}
}

@inproceedings{zhang2021rstnet,
  title={Rstnet: Captioning with adaptive attention on visual and non-visual words},
  author={Zhang, Xuying and Sun, Xiaoshuai and Luo, Yunpeng and Ji, Jiayi and Zhou, Yiyi and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={15465--15474},
  year={2021}
}


@inproceedings{ji2021step,
  title={Step-Wise Hierarchical Alignment Network for Image-Text Matching},
  author={Ji, Zhong and Chen, Kexin and Wang, Haoran},
  booktitle={IJCAI},
  year={2021},
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@misc{Align_before_Fuse,
      title={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation}, 
      author={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},
      year={2021},
      eprint={2107.07651},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}









@inproceedings{agrawal2019nocaps,
  title={Nocaps: Novel object captioning at scale},
  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8948--8957},
  year={2019}
}


@article{bao2022vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}








@inproceedings{holtzman2019curious,
  title={The Curious Case of Neural Text Degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@misc{wang2023samclip,
      title={SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding}, 
      author={Haoxiang Wang and Pavan Kumar Anasosalu Vasu and Fartash Faghri and Raviteja Vemulapalli and Mehrdad Farajtabar and Sachin Mehta and Mohammad Rastegari and Oncel Tuzel and Hadi Pouransari},
      year={2023},
      eprint={2310.15308},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{cha2023honeybee,
  title={Honeybee: Locality-enhanced projector for multimodal llm},
  author={Cha, Junbum and Kang, Wooyoung and Mun, Jonghwan and Roh, Byungseok},
  journal={arXiv preprint arXiv:2312.06742},
  year={2023}
}










@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}



@article{bianco2023improving,
  title={Improving Image Captioning Descriptiveness by Ranking and LLM-based Fusion},
  author={Bianco, Simone and Celona, Luigi and Donzella, Marco and Napoletano, Paolo},
  journal={arXiv preprint arXiv:2306.11593},
  year={2023}
}















@article{wallace1991jpeg,
  title={The JPEG still picture compression standard},
  author={Wallace, Gregory K},
  journal={Communications of the ACM},
  volume={34},
  number={4},
  pages={30--44},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@misc{liu2024llavanext,
    title={LLaVA-NeXT: Improved reasoning, OCR, and world knowledge},
    url={https://llava-vl.github.io/blog/2024-01-30-llava-next/},
    author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Li, Bo and Zhang, Yuanhan and Shen, Sheng and Lee, Yong Jae},
    month={January},
    year={2024}
}

@misc{liu2023improvedllava,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}

@inproceedings{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4015--4026},
  year={2023}
}

@article{testoni2024naming,
  title={Naming, Describing, and Quantifying Visual Objects in Humans and LLMs},
  author={Testoni, Alberto and Sprott, Juell and Pezzelle, Sandro},
  journal={arXiv preprint arXiv:2403.06935},
  year={2024}
}

@inproceedings{aneja2019sequential,
  title={Sequential latent spaces for modeling the intention during diverse image captioning},
  author={Aneja, Jyoti and Agrawal, Harsh and Batra, Dhruv and Schwing, Alexander},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4261--4270},
  year={2019}
}

@misc{chiang2023large,
      title={Can Large Language Models Be an Alternative to Human Evaluations?}, 
      author={Cheng-Han Chiang and Hung-yi Lee},
      year={2023},
      eprint={2305.01937},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{liu2023geval,
      title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment}, 
      author={Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
      year={2023},
      eprint={2303.16634},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{chen2022learning,
  title={Learning distinct and representative modes for image captioning},
  author={Chen, Qi and Deng, Chaorui and Wu, Qi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9472--9485},
  year={2022}
}

@inproceedings{
lee2023can,
title={Can Large Language Models Capture Dissenting Human Voices?},
author={Noah Lee and Na Min An and James Thorne},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=iipuAqcPGL}
}

@article{chen2023challenges,
  title={Challenges and Contributing Factors in the Utilization of Large Language Models (LLMs)},
  author={Chen, Xiaoliang and Li, Liangbin and Chang, Le and Huang, Yunhe and Zhao, Yuxuan and Zhang, Yuxiao and Li, Dinuo},
  journal={arXiv preprint arXiv:2310.13343},
  year={2023}
}

@article{yarbus1967eye,
  title={Eye Movements and Vision},
  author={Yarbus, Alfred L},
  journal={Eye movements and vision.},
  pages={171},
  year={1967},
  publisher={Springer US}
}

@article{tatler2011eye,
  title={Eye guidance in natural vision: Reinterpreting salience},
  author={Tatler, Benjamin W and Hayhoe, Mary M and Land, Michael F and Ballard, Dana H},
  journal={Journal of vision},
  volume={11},
  number={5},
  pages={5--5},
  year={2011},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{oliva2006building,
  title={Building the gist of a scene: The role of global image features in recognition},
  author={Oliva, Aude and Torralba, Antonio},
  journal={Progress in brain research},
  volume={155},
  pages={23--36},
  year={2006},
  publisher={Elsevier}
}

@article{navon1977forest,
  title={Forest before trees: The precedence of global features in visual perception},
  author={Navon, David},
  journal={Cognitive psychology},
  volume={9},
  number={3},
  pages={353--383},
  year={1977},
  publisher={Elsevier}
}

@article{mokady2021clipcap,
  title={ClipCap: CLIP Prefix for Image Captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{kim2020learning,
  title={Learning loss for test-time augmentation},
  author={Kim, Ildoo and Kim, Younghoon and Kim, Sungwoong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4163--4174},
  year={2020}
}

@inproceedings{kimura2021understanding,
  title={Understanding test-time augmentation},
  author={Kimura, Masanari},
  booktitle={International Conference on Neural Information Processing},
  pages={558--569},
  year={2021},
  organization={Springer}
}

@article{wallace1992jpeg,
  title={The JPEG still picture compression standard},
  author={Wallace, Gregory K},
  journal={IEEE transactions on consumer electronics},
  volume={38},
  number={1},
  pages={xviii--xxxiv},
  year={1992},
  publisher={IEEE}
}




@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}



@InProceedings{Goyal_2017_CVPR,
author = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
title = {Making the v in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}



@inproceedings{hendrycks2018benchmarking,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{papineni2002bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@article{xie2019visual,
  title={Visual entailment: A novel task for fine-grained image understanding},
  author={Xie, Ning and Lai, Farley and Doran, Derek and Kadav, Asim},
  journal={arXiv preprint arXiv:1901.06706},
  year={2019}
}

@inproceedings{suhr2019corpus,
  title={A Corpus for Reasoning about Natural Language Grounded in Photographs},
  author={Suhr, Alane and Zhou, Stephanie and Zhang, Ally and Zhang, Iris and Bai, Huajun and Artzi, Yoav},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={6418--6428},
  year={2019}
}

@article{grabinski2022robust,
  title={Robust models are less over-confident},
  author={Grabinski, Julia and Gavrikov, Paul and Keuper, Janis and Keuper, Margret},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={39059--39075},
  year={2022}
}


@inproceedings{banerjee-lavie-2005-meteor,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    editor = "Goldstein, Jade  and
      Lavie, Alon  and
      Lin, Chin-Yew  and
      Voss, Clare",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W05-0909",
    pages = "65--72",
}



@inproceedings{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3982--3992},
  year={2019}
}




@article{lo2023modeling,
  title={Modeling uncertainty for low-resolution facial expression recognition},
  author={Lo, Ling and Ruan, Bo-Kai and Shuai, Hong-Han and Cheng, Wen-Huang},
  journal={IEEE transactions on affective computing},
  year={2023},
  publisher={IEEE}
}

@inproceedings{upadhyay2023probvlm,
  title={Probvlm: Probabilistic adapter for frozen vison-language models},
  author={Upadhyay, Uddeshya and Karthik, Shyamgopal and Mancini, Massimiliano and Akata, Zeynep},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1899--1910},
  year={2023}
}

@article{fuhl2017fast,
  title={Fast camera focus estimation for gaze-based focus control},
  author={Fuhl, Wolfgang and Santini, Thiago and Kasneci, Enkelejda},
  journal={arXiv preprint arXiv:1711.03306},
  year={2017}
}


@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{cheng2023improving,
  title={Improving Contrastive Learning of Sentence Embeddings from AI Feedback},
  author={Cheng, Qinyuan and Yang, Xiaogui and Sun, Tianxiang and Li, Linyang and Qiu, Xipeng},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={11122--11138},
  year={2023}
}

@inproceedings{an-etal-2024-capturing,
    title = "Capturing the Relationship Between Sentence Triplets for {LLM} and Human-Generated Texts to Enhance Sentence Embeddings",
    author = "An, Na Min  and
      Waheed, Sania  and
      Thorne, James",
    editor = "Graham, Yvette  and
      Purver, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2024",
    month = mar,
    year = "2024",
    address = "St. Julian{'}s, Malta",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-eacl.43",
    pages = "624--638",
    abstract = "Deriving meaningful sentence embeddings is crucial in capturing the semantic relationship between texts. Recent advances in building sentence embedding models have centered on replacing traditional human-generated text datasets with those generated by LLMs. However, the properties of these widely used LLM-generated texts remain largely unexplored. Here, we evaluate the quality of the LLM-generated texts from four perspectives (Positive Text Repetition, Length Difference Penalty, Positive Score Compactness, and Negative Text Implausibility) and find that there exists an inherent difference between human and LLM-generated datasets. To further enhance sentence embeddings using both human and LLM-generated datasets, we propose a novel loss function that incorporates Positive-Negative sample Augmentation (PNA) within the contrastive learning objective. Our results demonstrate that PNA effectively mitigates the sentence anisotropy problem in Wikipedia corpus (-7{\%} compared to CLHAIF) and simultaneously improves the Spearman{'}s correlation in standard Semantic Textual Similarity (STS) tasks (+1.47{\%} compared to CLHAIF).",
}

@article{zhang2023multi,
  title={Multi-feature fusion enhanced transformer with multi-layer fused decoding for image captioning},
  author={Zhang, Jing and Fang, Zhongjun and Wang, Zhe},
  journal={Applied Intelligence},
  volume={53},
  number={11},
  pages={13398--13414},
  year={2023},
  publisher={Springer}
}

@article{ma2023towards,
  title={Towards local visual modeling for image captioning},
  author={Ma, Yiwei and Ji, Jiayi and Sun, Xiaoshuai and Zhou, Yiyi and Ji, Rongrong},
  journal={Pattern Recognition},
  volume={138},
  pages={109420},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{yang2018attention,
  title={Attention to refine through multi scales for semantic segmentation},
  author={Yang, Shiqi and Peng, Gang},
  booktitle={Advances in Multimedia Information Processing--PCM 2018: 19th Pacific-Rim Conference on Multimedia, Hefei, China, September 21-22, 2018, Proceedings, Part II 19},
  pages={232--241},
  year={2018},
  organization={Springer}
}

@inproceedings{chen2016attention,
  title={Attention to scale: Scale-aware semantic image segmentation},
  author={Chen, Liang-Chieh and Yang, Yi and Wang, Jiang and Xu, Wei and Yuille, Alan L},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3640--3649},
  year={2016}
}

@inproceedings{yuan2020object,
  title={Object-contextual representations for semantic segmentation},
  author={Yuan, Yuhui and Chen, Xilin and Wang, Jingdong},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part VI 16},
  pages={173--190},
  year={2020},
  organization={Springer}
}

@inproceedings{cheng2020panoptic,
  title={Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation},
  author={Cheng, Bowen and Collins, Maxwell D and Zhu, Yukun and Liu, Ting and Huang, Thomas S and Adam, Hartwig and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12475--12485},
  year={2020}
}

@article{tao2020hierarchical,
  title={Hierarchical multi-scale attention for semantic segmentation},
  author={Tao, Andrew and Sapra, Karan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:2005.10821},
  year={2020}
}

@inproceedings{najibi2019autofocus,
  title={Autofocus: Efficient multi-scale inference},
  author={Najibi, Mahyar and Singh, Bharat and Davis, Larry S},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9745--9755},
  year={2019}
}

@article{zhang2022memo,
  title={Memo: Test time robustness via adaptation and augmentation},
  author={Zhang, Marvin and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={38629--38642},
  year={2022}
}

@inproceedings{
luo2024controlling,
title={Controlling Vision-Language Models for Universal Image Restoration},
author={Ziwei Luo and Fredrik K. Gustafsson and Zheng Zhao and Jens Sj{\"o}lund and Thomas B. Sch{\"o}n},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=t3vnnLeajU}
}

@article{chang2019x,
  title={X-bert: extreme multi-label text classification with bert},
  author={Chang, Wei-Cheng and Yu, Hsiang-Fu and Zhong, Kai and Yang, Yiming and Dhillon, Inderjit},
  journal={arXiv preprint arXiv:1905.02331},
  year={2019}
}

@inproceedings{an2023maximum,
  title={Maximum Entropy Information Bottleneck for Uncertainty-aware Stochastic Embedding},
  author={An, Sungtae and Jammalamadaka, Nataraj and Chong, Eunji},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3808--3817},
  year={2023}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{wang2023semantic,
  title={Semantic Embedding Uncertainty Learning for Image and Text Matching},
  author={Wang, Yan and Su, Yu-Ting and Li, Wenhui and Yan, Chenggang and Zheng, Bolun and Li, Xuanya and Liu, An-An},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={864--869},
  year={2023},
  organization={IEEE}
}

@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2641--2649},
  year={2015}
}

@inproceedings{li2021learning,
  title={Learning probabilistic ordinal embeddings for uncertainty-aware regression},
  author={Li, Wanhua and Huang, Xiaoke and Lu, Jiwen and Feng, Jianjiang and Zhou, Jie},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13896--13905},
  year={2021}
}

@article{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}



@article{mao2022enhance,
  title={Enhance the visual representation via discrete adversarial training},
  author={Mao, Xiaofeng and Chen, Yuefeng and Duan, Ranjie and Zhu, Yao and Qi, Gege and Li, Xiaodan and Zhang, Rong and Xue, Hui and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7520--7533},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}



@misc{wang2022ofa,
      title={OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework}, 
      author={Peng Wang and An Yang and Rui Men and Junyang Lin and Shuai Bai and Zhikang Li and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
      year={2022},
      eprint={2202.03052},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{wang2022image,
  title={Image as a foreign language: Beit pretraining for all vision and vision-language tasks},
  author={Wang, Wenhui and Bao, Hangbo and Dong, Li and Bjorck, Johan and Peng, Zhiliang and Liu, Qiang and Aggarwal, Kriti and Mohammed, Owais Khan and Singhal, Saksham and Som, Subhojit and others},
  journal={arXiv preprint arXiv:2208.10442},
  year={2022}
}

@misc{guo2023images,
      title={From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models}, 
      author={Jiaxian Guo and Junnan Li and Dongxu Li and Anthony Meng Huat Tiong and Boyang Li and Dacheng Tao and Steven C. H. Hoi},
      year={2023},
      eprint={2212.10846},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{tang2023context,
  title={Context-I2W: Mapping Images to Context-dependent Words for Accurate Zero-Shot Composed Image Retrieval},
  author={Tang, Yuanmin and Yu, Jing and Gai, Keke and Jiamin, Zhuang and Xiong, Gang and Hu, Yue and Wu, Qi},
  journal={arXiv preprint arXiv:2309.16137},
  year={2023}
}


@misc{liu2023hidden,
      title={On the Hidden Mystery of OCR in Large Multimodal Models}, 
      author={Yuliang Liu and Zhang Li and Hongliang Li and Wenwen Yu and Yang Liu and Biao Yang and Mingxin Huang and Dezhi Peng and Mingyu Liu and Mingrui Chen and Chunyuan Li and Xucheng Yin and Cheng-lin Liu and Lianwen Jin and Xiang Bai},
      year={2023},
      eprint={2305.07895},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{bao2022vlmo,
  title={Vlmo: Unified vision-language pre-training with mixture-of-modality-experts},
  author={Bao, Hangbo and Wang, Wenhui and Dong, Li and Liu, Qiang and Mohammed, Owais Khan and Aggarwal, Kriti and Som, Subhojit and Piao, Songhao and Wei, Furu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={32897--32912},
  year={2022}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@inproceedings{chen2023understanding,
  title={Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks},
  author={Chen, Hao and Wang, Jindong and Shah, Ankit and Tao, Ran and Wei, Hongxin and Xie, Xing and Sugiyama, Masashi and Raj, Bhiksha},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{shukor2022efficient,
  title={Efficient Vision-Language Pretraining with Visual Concepts and Hierarchical Alignment},
  author={Shukor, Mustafa and Couairon, Guillaume and Cord, Matthieu},
  booktitle={33rd British Machine Vision Conference (BMVC)},
  year={2022}
}


@article{wu2022learning,
  title={Learning transferable perturbations for image captioning},
  author={Wu, Hanjie and Liu, Yongtuo and Cai, Hongmin and He, Shengfeng},
  journal={ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)},
  volume={18},
  number={2},
  pages={1--18},
  year={2022},
  publisher={ACM New York, NY}
}

@article{qiu2023benchmarking,
  title={Benchmarking Robustness of Multimodal Image-Text Models under Distribution Shift},
  author={Qiu, Jielin and Zhu, Yi and Shi, Xingjian and Wenzel, Florian and Tang, Zhiqiang and Zhao, Ding and Li, Bo and Li, Mu},
  journal={Journal of Data-centric Machine Learning Research},
  year={2023}
}

@misc{wang2023samclip,
      title={SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding}, 
      author={Haoxiang Wang and Pavan Kumar Anasosalu Vasu and Fartash Faghri and Raviteja Vemulapalli and Mehrdad Farajtabar and Sachin Mehta and Mohammad Rastegari and Oncel Tuzel and Hadi Pouransari},
      year={2023},
      eprint={2310.15308},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}



@article{tu2024closer,
  title={A closer look at the robustness of contrastive language-image pre-training (clip)},
  author={Tu, Weijie and Deng, Weijian and Gedeon, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{tiong2022plug,
  title={Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training},
  author={Tiong, Anthony Meng Huat and Li, Junnan and Li, Boyang and Savarese, Silvio and Hoi, Steven CH},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={951--967},
  year={2022}
}

@inproceedings{fang2022injecting,
  title={Injecting semantic concepts into end-to-end image captioning},
  author={Fang, Zhiyuan and Wang, Jianfeng and Hu, Xiaowei and Liang, Lin and Gan, Zhe and Wang, Lijuan and Yang, Yezhou and Liu, Zicheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={18009--18019},
  year={2022}
}

@article{chen2019variational,
  title={Variational structured semantic inference for diverse image captioning},
  author={Chen, Fuhai and Ji, Rongrong and Ji, Jiayi and Sun, Xiaoshuai and Zhang, Baochang and Ge, Xuri and Wu, Yongjian and Huang, Feiyue and Wang, Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{hu2022scaling,
  title={Scaling up vision-language pre-training for image captioning},
  author={Hu, Xiaowei and Gan, Zhe and Wang, Jianfeng and Yang, Zhengyuan and Liu, Zicheng and Lu, Yumao and Wang, Lijuan},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={17980--17989},
  year={2022}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25278--25294},
  year={2022}
}

@inproceedings{wang2016image,
  title={Image captioning with deep bidirectional LSTMs},
  author={Wang, Cheng and Yang, Haojin and Bartz, Christian and Meinel, Christoph},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={988--997},
  year={2016}
}

@inproceedings{zhang2019multi,
  title={Multi-scale cropping mechanism for remote sensing image captioning},
  author={Zhang, Xueting and Wang, Qi and Chen, Shangdong and Li, Xuelong},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={10039--10042},
  year={2019},
  organization={IEEE}
}

@inproceedings{wu2023cora,
  title={Cora: Adapting clip for open-vocabulary detection with region prompting and anchor pre-matching},
  author={Wu, Xiaoshi and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7031--7040},
  year={2023}
}

@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14},
  pages={382--398},
  year={2016},
  organization={Springer}
}

@inproceedings{wang2020compare,
  title={Compare and reweight: Distinctive image captioning using similar images sets},
  author={Wang, Jiuniu and Xu, Wenjia and Wang, Qingzhong and Chan, Antoni B},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part I 16},
  pages={370--386},
  year={2020},
  organization={Springer}
}

@article{wang2022distinctive,
  title={On distinctive image captioning via comparing and reweighting},
  author={Wang, Jiuniu and Xu, Wenjia and Wang, Qingzhong and Chan, Antoni B},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={2},
  pages={2088--2103},
  year={2022},
  publisher={IEEE}
}

@inproceedings{shi-etal-2021-enhancing,
    title = "Enhancing Descriptive Image Captioning with Natural Language Inference",
    author = "Shi, Zhan  and
      Liu, Hui  and
      Zhu, Xiaodan",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.36",
    doi = "10.18653/v1/2021.acl-short.36",
    pages = "269--277",
    abstract = "Generating \textit{descriptive} sentences that convey non-trivial, detailed, and salient information about images is an important goal of image captioning. In this paper we propose a novel approach to encourage captioning models to produce more detailed captions using natural language inference, based on the motivation that, among different captions of an image, descriptive captions are more likely to entail less descriptive captions. Specifically, we construct directed inference graphs for reference captions based on natural language inference. A PageRank algorithm is then employed to estimate the descriptiveness score of each node. Built on that, we use reference sampling and weighted designated rewards to guide captioning to generate descriptive captions. The results on MSCOCO show that the proposed method outperforms the baselines significantly on a wide range of conventional and descriptiveness-related evaluation metrics.",
}

@inproceedings{yao2023capenrich,
  title={Capenrich: Enriching caption semantics for web images via cross-modal pre-trained knowledge},
  author={Yao, Linli and Chen, Weijing and Jin, Qin},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={2392--2401},
  year={2023}
}

@article{yue2024learning,
  title={Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation},
  author={Yue, Zihao and Hu, Anwen and Zhang, Liang and Jin, Qin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{wang2019describing,
  title={Describing like humans: on diversity in image captioning},
  author={Wang, Qingzhong and Chan, Antoni B},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4195--4203},
  year={2019}
}

@article{wang2020diversity,
  title={On diversity in image captioning: Metrics and methods},
  author={Wang, Qingzhong and Wan, Jia and Chan, Antoni B},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={2},
  pages={1035--1049},
  year={2020},
  publisher={IEEE}
}

@article{mahajan2020diverse,
  title={Diverse image captioning with context-object split latent spaces},
  author={Mahajan, Shweta and Roth, Stefan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3613--3624},
  year={2020}
}





@article{oquab2023dinov2,
  title={Dinov2: Learning robust visual features without supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={arXiv preprint arXiv:2304.07193},
  year={2023}
}

@article{kirillov2023segany,
  title={Segment Anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Doll{\'a}r, Piotr and Girshick, Ross},
  journal={arXiv:2304.02643},
  year={2023}
}


@InProceedings{Shao2023ICCV,
    author    = {Shao, Bin and Liu, Jianzhuang and Pei, Renjing and Xu, Songcen and Dai, Peng and Lu, Juwei and Li, Weimian and Yan, Youliang},
    title     = {HiVLP: Hierarchical Interactive Video-Language Pre-Training},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {13756-13766}
}



@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}




@misc{fu2023gptscore,
      title={GPTScore: Evaluate as You Desire}, 
      author={Jinlan Fu and See-Kiong Ng and Zhengbao Jiang and Pengfei Liu},
      year={2023},
      eprint={2302.04166},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{hessel2021clipscore,
  title={CLIPScore: A Reference-free Evaluation Metric for Image Captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Le Bras, Ronan and Choi, Yejin},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={7514--7528},
  year={2021}
}

@misc{karpathy2015deep,
      title={Deep Visual-Semantic Alignments for Generating Image Descriptions}, 
      author={Andrej Karpathy and Li Fei-Fei},
      year={2015},
      eprint={1412.2306},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{BLEU,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{wang2016studying,
  title={Studying very low resolution recognition using deep networks},
  author={Wang, Zhangyang and Chang, Shiyu and Yang, Yingzhen and Liu, Ding and Huang, Thomas S},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4792--4800},
  year={2016}
}

@article{yin2019fourier,
  title={A fourier perspective on model robustness in computer vision},
  author={Yin, Dong and Gontijo Lopes, Raphael and Shlens, Jon and Cubuk, Ekin Dogus and Gilmer, Justin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{zhang2021global,
  title={Global visual feature and linguistic state guided attention for remote sensing image captioning},
  author={Zhang, Zhengyuan and Zhang, Wenkai and Yan, Menglong and Gao, Xin and Fu, Kun and Sun, Xian},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  volume={60},
  pages={1--16},
  year={2021},
  publisher={IEEE}
}

@inproceedings{singh2022revisiting,
  title={Revisiting weakly supervised pre-training of visual perception models},
  author={Singh, Mannat and Gustafson, Laura and Adcock, Aaron and de Freitas Reis, Vinicius and Gedik, Bugra and Kosaraju, Raj Prateek and Mahajan, Dhruv and Girshick, Ross and Doll{\'a}r, Piotr and Van Der Maaten, Laurens},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={804--814},
  year={2022}
}
@article{stefanini2022show,
  title={From show to tell: A survey on deep learning-based image captioning},
  author={Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={45},
  number={1},
  pages={539--559},
  year={2022},
  publisher={IEEE}
}

@article{li2023monkey,
  title={Monkey: Image resolution and text label are important things for large multi-modal models},
  author={Li, Zhang and Yang, Biao and Liu, Qiang and Ma, Zhiyin and Zhang, Shuo and Yang, Jingxu and Sun, Yabo and Liu, Yuliang and Bai, Xiang},
  journal={arXiv preprint arXiv:2311.06607},
  year={2023}
}

@inproceedings{nurhopipah2023image,
  title={Image Captioning for Visual Surveillance System},
  author={Nurhopipah, Ade and Sholikhatin, Siti Alvi and Widianto, Anan},
  booktitle={2023 IEEE 7th International Conference on Information Technology, Information Systems and Electrical Engineering (ICITISEE)},
  pages={376--381},
  year={2023},
  organization={IEEE}
}

@article{ye2023mplug,
  title={mplug-owl: Modularization empowers large language models with multimodality},
  author={Ye, Qinghao and Xu, Haiyang and Xu, Guohai and Ye, Jiabo and Yan, Ming and Zhou, Yiyang and Wang, Junyang and Hu, Anwen and Shi, Pengcheng and Shi, Yaya and others},
  journal={arXiv preprint arXiv:2304.14178},
  year={2023}
}

@inproceedings{testolina2023jpeg,
  title={Jpeg aic-3 dataset: Towards defining the high quality to nearly visually lossless quality range},
  author={Testolina, Michela and Hosu, Vlad and Jenadeleh, Mohsen and Lazzarotto, Davi and Saupe, Dietmar and Ebrahimi, Touradj},
  booktitle={2023 15th International Conference on Quality of Multimedia Experience (QoMEX)},
  pages={55--60},
  year={2023},
  organization={IEEE}
} 
@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}

@article{liu2023llava,
  title={Llava-plus: Learning to use tools for creating multimodal agents},
  author={Liu, Shilong and Cheng, Hao and Liu, Haotian and Zhang, Hao and Li, Feng and Ren, Tianhe and Zou, Xueyan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={arXiv preprint arXiv:2311.05437},
  year={2023}
}

@inproceedings{nguyen2022grit,
  title={Grit: Faster and better image captioning transformer using dual visual features},
  author={Nguyen, Van-Quang and Suganuma, Masanori and Okatani, Takayuki},
  booktitle={European Conference on Computer Vision},
  pages={167--184},
  year={2022},
  organization={Springer}
}

@article{taori2020measuring,
  title={Measuring robustness to natural distribution shifts in image classification},
  author={Taori, Rohan and Dave, Achal and Shankar, Vaishaal and Carlini, Nicholas and Recht, Benjamin and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18583--18599},
  year={2020}
}

@inproceedings{geirhos2018imagenet,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{cheng2019low,
  title={Low-resolution face recognition},
  author={Cheng, Zhiyi and Zhu, Xiatian and Gong, Shaogang},
  booktitle={Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part III 14},
  pages={605--621},
  year={2019},
  organization={Springer}
}


@inproceedings{rusak2020simple,
  title={A simple way to make neural networks robust against diverse image corruptions},
  author={Rusak, Evgenia and Schott, Lukas and Zimmermann, Roland S and Bitterwolf, Julian and Bringmann, Oliver and Bethge, Matthias and Brendel, Wieland},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part III 16},
  pages={53--69},
  year={2020},
  organization={Springer}
}

@inproceedings{xiao2023multimodal,
  title={Multimodal data augmentation for image captioning using diffusion models},
  author={Xiao, Changrong and Xu, Sean Xin and Zhang, Kunpeng},
  booktitle={Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
  pages={23--33},
  year={2023}
}

@inproceedings{cubuk2019autoaugment,
  title={Autoaugment: Learning augmentation strategies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={113--123},
  year={2019}
}

@article{michaelis2019benchmarking,
  title={Benchmarking robustness in object detection: Autonomous driving when winter is coming},
  author={Michaelis, Claudio and Mitzkus, Benjamin and Geirhos, Robert and Rusak, Evgenia and Bringmann, Oliver and Ecker, Alexander S and Bethge, Matthias and Brendel, Wieland},
  journal={arXiv preprint arXiv:1907.07484},
  year={2019}
}

@inproceedings{recht2019imagenet,
  title={Do imagenet classifiers generalize to imagenet?},
  author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  booktitle={International conference on machine learning},
  pages={5389--5400},
  year={2019},
  organization={PMLR}
}

@article{barbu2019objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{idrissi2022imagenet,
  title={ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations},
  author={Idrissi, Badr Youbi and Bouchacourt, Diane and Balestriero, Randall and Evtimov, Ivan and Hazirbas, Caner and Ballas, Nicolas and Vincent, Pascal and Drozdzal, Michal and Lopez-Paz, David and Ibrahim, Mark},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{chai2023recognizability,
  title={Recognizability embedding enhancement for very low-resolution face recognition and quality estimation},
  author={Chai, Jacky Chen Long and Ng, Tiong-Sik and Low, Cheng-Yaw and Park, Jaewoo and Teoh, Andrew Beng Jin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9957--9967},
  year={2023}
}

@article{wang2019learning,
  title={Learning robust global representations by penalizing local predictive power},
  author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{hendrycks2021many,
  title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8340--8349},
  year={2021}
}

@article{nguyen2022quality,
  title={Quality not quantity: On the interaction between dataset design and robustness of clip},
  author={Nguyen, Thao and Ilharco, Gabriel and Wortsman, Mitchell and Oh, Sewoong and Schmidt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21455--21469},
  year={2022}
}

@article{mckinzie2024mm1,
  title={MM1: Methods, Analysis \& Insights from Multimodal LLM Pre-training},
  author={McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and others},
  journal={arXiv preprint arXiv:2403.09611},
  year={2024}
}

@article{tu2024empirical,
  title={An Empirical Study Into What Matters for Calibrating Vision-Language Models},
  author={Tu, Weijie and Deng, Weijian and Campbell, Dylan and Gould, Stephen and Gedeon, Tom},
  journal={arXiv preprint arXiv:2402.07417},
  year={2024}
}

@article{gao2024sphinx,
  title={SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models},
  author={Gao, Peng and Zhang, Renrui and Liu, Chris and Qiu, Longtian and Huang, Siyuan and Lin, Weifeng and Zhao, Shitian and Geng, Shijie and Lin, Ziyi and Jin, Peng and others},
  journal={arXiv preprint arXiv:2402.05935},
  year={2024}
}
