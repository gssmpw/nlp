@article{Zheng2023ARD,
  title={A Reparameterized Discrete Diffusion Model for Text Generation},
  author={Lin Zheng and Jianbo Yuan and Lei Yu and Lingpeng Kong},
  journal={ArXiv},
  year={2023},
  volume={abs/2302.05737},
}

@article{austin2021structured,
  title={Structured denoising diffusion models in discrete state-spaces},
  author={Austin, Jacob and Johnson, Daniel D and Ho, Jonathan and Tarlow, Daniel and Van Den Berg, Rianne},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17981--17993},
  year={2021}
}

@article{campbell2022continuous,
  title={A continuous time framework for discrete denoising models},
  author={Campbell, Andrew and Benton, Joe and De Bortoli, Valentin and Rainforth, Thomas and Deligiannidis, George and Doucet, Arnaud},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28266--28279},
  year={2022}
}

@inproceedings{chang2022maskgit,
  title={Maskgit: Masked generative image transformer},
  author={Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11315--11325},
  year={2022}
}

@article{chang2023muse,
  title={Muse: Text-to-image generation via masked generative transformers},
  author={Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2301.00704},
  year={2023}
}

@article{chen2022analog,
  title={Analog bits: Generating discrete data using diffusion models with self-conditioning},
  author={Chen, Ting and Zhang, Ruixiang and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2208.04202},
  year={2022}
}

@article{chen2023fast,
  title={Fast Sampling via De-randomization for Discrete Diffusion Models},
  author={Chen, Zixiang and Yuan, Huizhuo and Li, Yongqian and Kou, Yiwen and Zhang, Junkai and Gu, Quanquan},
  journal={arXiv preprint arXiv:2312.09193},
  year={2023}
}

@article{dieleman2022continuous,
  title={Continuous diffusion for categorical data},
  author={Dieleman, Sander and Sartran, Laurent and Roshannai, Arman and Savinov, Nikolay and Ganin, Yaroslav and Richemond, Pierre H and Doucet, Arnaud and Strudel, Robin and Dyer, Chris and Durkan, Conor and others},
  journal={arXiv preprint arXiv:2211.15089},
  year={2022}
}

@article{gat2024discrete,
  title={Discrete Flow Matching},
  author={Gat, Itai and Remez, Tal and Shaul, Neta and Kreuk, Felix and Chen, Ricky TQ and Synnaeve, Gabriel and Adi, Yossi and Lipman, Yaron},
  journal={arXiv preprint arXiv:2407.15595},
  year={2024}
}

@article{gong2022diffuseq,
  title={Diffuseq: Sequence to sequence text generation with diffusion models},
  author={Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, LingPeng},
  journal={arXiv preprint arXiv:2210.08933},
  year={2022}
}

@article{gong2024scaling,
  title={Scaling Diffusion Language Models via Adaptation from Autoregressive Models},
  author={Gong, Shansan and Agarwal, Shivam and Zhang, Yizhe and Ye, Jiacheng and Zheng, Lin and Li, Mukai and An, Chenxin and Zhao, Peilin and Bi, Wei and Han, Jiawei and others},
  journal={arXiv preprint arXiv:2410.17891},
  year={2024}
}

@article{graves2023bayesian,
  title={Bayesian flow networks},
  author={Graves, Alex and Srivastava, Rupesh Kumar and Atkinson, Timothy and Gomez, Faustino},
  journal={arXiv preprint arXiv:2308.07037},
  year={2023}
}

@article{gulrajani2024likelihood,
  title={Likelihood-based diffusion language models},
  author={Gulrajani, Ishaan and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{han2022ssd,
  title={Ssd-lm: Semi-autoregressive simplex-based diffusion language model for text generation and modular control},
  author={Han, Xiaochuang and Kumar, Sachin and Tsvetkov, Yulia},
  journal={arXiv preprint arXiv:2210.17432},
  year={2022}
}

@article{he2022diffusionbert,
  title={Diffusionbert: Improving generative masked language models with diffusion models},
  author={He, Zhengfu and Sun, Tianxiang and Wang, Kuanning and Huang, Xuanjing and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2211.15029},
  year={2022}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{hoogeboom2021argmax,
  title={Argmax flows and multinomial diffusion: Learning categorical distributions},
  author={Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\'e}, Patrick and Welling, Max},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12454--12465},
  year={2021}
}

@article{hoogeboom2021autoregressive,
  title={Autoregressive diffusion models},
  author={Hoogeboom, Emiel and Gritsenko, Alexey A and Bastings, Jasmijn and Poole, Ben and Berg, Rianne van den and Salimans, Tim},
  journal={arXiv preprint arXiv:2110.02037},
  year={2021}
}

@article{kitouni2023disk,
  title={DiSK: A Diffusion Model for Structured Knowledge},
  author={Kitouni, Ouail and Nolte, Niklas and Hensman, James and Mitra, Bhaskar},
  journal={arXiv preprint arXiv:2312.05253},
  year={2023}
}

@article{kou2024cllms,
  title={Cllms: Consistency large language models},
  author={Kou, Siqi and Hu, Lanxiang and He, Zhezhi and Deng, Zhijie and Zhang, Hao},
  journal={arXiv preprint arXiv:2403.00835},
  year={2024}
}

@article{li2022diffusion,
  title={Diffusion-lm improves controllable text generation},
  author={Li, Xiang and Thickstun, John and Gulrajani, Ishaan and Liang, Percy S and Hashimoto, Tatsunori B},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4328--4343},
  year={2022}
}

@inproceedings{lin2023text,
  title={Text generation with diffusion language models: A pre-training approach with continuous paragraph denoise},
  author={Lin, Zhenghao and Gong, Yeyun and Shen, Yelong and Wu, Tong and Fan, Zhihao and Lin, Chen and Duan, Nan and Chen, Weizhu},
  booktitle={International Conference on Machine Learning},
  pages={21051--21064},
  year={2023},
  organization={PMLR}
}

@article{lou2023discrete,
  title={Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution},
  author={Lou, Aaron and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2310.16834},
  year={2023}
}

@misc{lou2023reflected,
      title={Reflected Diffusion Models}, 
      author={Aaron Lou and Stefano Ermon},
      year={2023},
      eprint={2304.04740},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{mahabadi2024tess,
      title={TESS: Text-to-Text Self-Conditioned Simplex Diffusion}, 
      author={Rabeeh Karimi Mahabadi and Hamish Ivison and Jaesung Tae and James Henderson and Iz Beltagy and Matthew E. Peters and Arman Cohan},
      year={2024},
      eprint={2305.08379},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{meng2022concrete,
  title={Concrete score matching: Generalized score matching for discrete data},
  author={Meng, Chenlin and Choi, Kristy and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={34532--34545},
  year={2022}
}

@article{nie2024scaling,
  title={Scaling up Masked Diffusion Models on Text},
  author={Nie, Shen and Zhu, Fengqi and Du, Chao and Pang, Tianyu and Liu, Qian and Zeng, Guangtao and Lin, Min and Li, Chongxuan},
  journal={arXiv preprint arXiv:2410.18514},
  year={2024}
}

@article{ou2024your,
  title={Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data},
  author={Ou, Jingyang and Nie, Shen and Xue, Kaiwen and Zhu, Fengqi and Sun, Jiacheng and Li, Zhenguo and Li, Chongxuan},
  journal={arXiv preprint arXiv:2406.03736},
  year={2024}
}

@misc{reid2022diffuser,
      title={DiffusER: Discrete Diffusion via Edit-based Reconstruction}, 
      author={Machel Reid and Vincent J. Hellendoorn and Graham Neubig},
      year={2022},
      eprint={2210.16886},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{richemond2022categorical,
      title={Categorical SDEs with Simplex Diffusion}, 
      author={Pierre H. Richemond and Sander Dieleman and Arnaud Doucet},
      year={2022},
      eprint={2210.14784},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{sahoo2024simple,
  title={Simple and Effective Masked Diffusion Language Models},
  author={Sahoo, Subham Sekhar and Arriola, Marianne and Schiff, Yair and Gokaslan, Aaron and Marroquin, Edgar and Chiu, Justin T and Rush, Alexander and Kuleshov, Volodymyr},
  journal={arXiv preprint arXiv:2406.07524},
  year={2024}
}

@article{shi2024simplified,
  title={Simplified and Generalized Masked Diffusion for Discrete Data},
  author={Shi, Jiaxin and Han, Kehang and Wang, Zhe and Doucet, Arnaud and Titsias, Michalis K},
  journal={arXiv preprint arXiv:2406.04329},
  year={2024}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International conference on machine learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{strudel2022self,
  title={Self-conditioned embedding diffusion for text generation},
  author={Strudel, Robin and Tallec, Corentin and Altch{\'e}, Florent and Du, Yilun and Ganin, Yaroslav and Mensch, Arthur and Grathwohl, Will and Savinov, Nikolay and Dieleman, Sander and Sifre, Laurent and others},
  journal={arXiv preprint arXiv:2211.04236},
  year={2022}
}

@article{sun2022score,
  title={Score-based continuous-time discrete diffusion models},
  author={Sun, Haoran and Yu, Lijun and Dai, Bo and Schuurmans, Dale and Dai, Hanjun},
  journal={arXiv preprint arXiv:2211.16750},
  year={2022}
}

@article{wang2024diffusion,
  title={Diffusion Language Models Are Versatile Protein Learners},
  author={Wang, Xinyou and Zheng, Zaixiang and Ye, Fei and Xue, Dongyu and Huang, Shujian and Gu, Quanquan},
  journal={arXiv preprint arXiv:2402.18567},
  year={2024}
}

@article{wang2024dplm,
  title={Dplm-2: A multimodal diffusion protein language model},
  author={Wang, Xinyou and Zheng, Zaixiang and Ye, Fei and Xue, Dongyu and Huang, Shujian and Gu, Quanquan},
  journal={arXiv preprint arXiv:2410.13782},
  year={2024}
}

@misc{wu2023ardiffusion,
      title={AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation}, 
      author={Tong Wu and Zhihao Fan and Xiao Liu and Yeyun Gong and Yelong Shen and Jian Jiao and Hai-Tao Zheng and Juntao Li and Zhongyu Wei and Jian Guo and Nan Duan and Weizhu Chen},
      year={2023},
      eprint={2305.09515},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{xu2025show,
  title={Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation},
  author={Xu, Chenkai and Wang, Xu and Liao, Zhenyi and Li, Yishun and Hou, Tianqi and Deng, Zhijie},
  journal={arXiv preprint arXiv:2502.05415},
  year={2025}
}

@article{xue2024unifying,
  title={Unifying Bayesian Flow Networks and Diffusion Models through Stochastic Differential Equations},
  author={Xue, Kaiwen and Zhou, Yuhao and Nie, Shen and Min, Xu and Zhang, Xiaolu and Zhou, Jun and Li, Chongxuan},
  journal={arXiv preprint arXiv:2404.15766},
  year={2024}
}

@article{ye2023diffusion,
  title={Diffusion language models can perform many tasks with scaling and instruction-finetuning},
  author={Ye, Jiasheng and Zheng, Zaixiang and Bao, Yu and Qian, Lihua and Gu, Quanquan},
  journal={arXiv preprint arXiv:2308.12219},
  year={2023}
}

@article{ye2023dinoiser,
  title={Dinoiser: Diffused conditional sequence learning by manipulating noises},
  author={Ye, Jiasheng and Zheng, Zaixiang and Bao, Yu and Qian, Lihua and Wang, Mingxuan},
  journal={arXiv preprint arXiv:2302.10025},
  year={2023}
}

@misc{zheng2024maskeddiffusionmodelssecretly,
      title={Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling}, 
      author={Kaiwen Zheng and Yongxin Chen and Hanzi Mao and Ming-Yu Liu and Jun Zhu and Qinsheng Zhang},
      year={2024},
      eprint={2409.02908},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.02908}, 
}

