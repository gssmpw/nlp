[
  {
    "index": 0,
    "papers": [
      {
        "key": "sohl2015deep",
        "author": "Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya",
        "title": "Deep unsupervised learning using nonequilibrium thermodynamics"
      },
      {
        "key": "ho2020denoising",
        "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter",
        "title": "Denoising diffusion probabilistic models"
      },
      {
        "key": "song2020score",
        "author": "Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben",
        "title": "Score-based generative modeling through stochastic differential equations"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "li2022diffusion",
        "author": "Li, Xiang and Thickstun, John and Gulrajani, Ishaan and Liang, Percy S and Hashimoto, Tatsunori B",
        "title": "Diffusion-lm improves controllable text generation"
      },
      {
        "key": "gong2022diffuseq",
        "author": "Gong, Shansan and Li, Mukai and Feng, Jiangtao and Wu, Zhiyong and Kong, LingPeng",
        "title": "Diffuseq: Sequence to sequence text generation with diffusion models"
      },
      {
        "key": "han2022ssd",
        "author": "Han, Xiaochuang and Kumar, Sachin and Tsvetkov, Yulia",
        "title": "Ssd-lm: Semi-autoregressive simplex-based diffusion language model for text generation and modular control"
      },
      {
        "key": "strudel2022self",
        "author": "Strudel, Robin and Tallec, Corentin and Altch{\\'e}, Florent and Du, Yilun and Ganin, Yaroslav and Mensch, Arthur and Grathwohl, Will and Savinov, Nikolay and Dieleman, Sander and Sifre, Laurent and others",
        "title": "Self-conditioned embedding diffusion for text generation"
      },
      {
        "key": "chen2022analog",
        "author": "Chen, Ting and Zhang, Ruixiang and Hinton, Geoffrey",
        "title": "Analog bits: Generating discrete data using diffusion models with self-conditioning"
      },
      {
        "key": "dieleman2022continuous",
        "author": "Dieleman, Sander and Sartran, Laurent and Roshannai, Arman and Savinov, Nikolay and Ganin, Yaroslav and Richemond, Pierre H and Doucet, Arnaud and Strudel, Robin and Dyer, Chris and Durkan, Conor and others",
        "title": "Continuous diffusion for categorical data"
      },
      {
        "key": "richemond2022categorical",
        "author": "Pierre H. Richemond and Sander Dieleman and Arnaud Doucet",
        "title": "Categorical SDEs with Simplex Diffusion"
      },
      {
        "key": "wu2023ardiffusion",
        "author": "Tong Wu and Zhihao Fan and Xiao Liu and Yeyun Gong and Yelong Shen and Jian Jiao and Hai-Tao Zheng and Juntao Li and Zhongyu Wei and Jian Guo and Nan Duan and Weizhu Chen",
        "title": "AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation"
      },
      {
        "key": "mahabadi2024tess",
        "author": "Rabeeh Karimi Mahabadi and Hamish Ivison and Jaesung Tae and James Henderson and Iz Beltagy and Matthew E. Peters and Arman Cohan",
        "title": "TESS: Text-to-Text Self-Conditioned Simplex Diffusion"
      },
      {
        "key": "ye2023dinoiser",
        "author": "Ye, Jiasheng and Zheng, Zaixiang and Bao, Yu and Qian, Lihua and Wang, Mingxuan",
        "title": "Dinoiser: Diffused conditional sequence learning by manipulating noises"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "lou2023reflected",
        "author": "Aaron Lou and Stefano Ermon",
        "title": "Reflected Diffusion Models"
      },
      {
        "key": "graves2023bayesian",
        "author": "Graves, Alex and Srivastava, Rupesh Kumar and Atkinson, Timothy and Gomez, Faustino",
        "title": "Bayesian flow networks"
      },
      {
        "key": "lin2023text",
        "author": "Lin, Zhenghao and Gong, Yeyun and Shen, Yelong and Wu, Tong and Fan, Zhihao and Lin, Chen and Duan, Nan and Chen, Weizhu",
        "title": "Text generation with diffusion language models: A pre-training approach with continuous paragraph denoise"
      },
      {
        "key": "xue2024unifying",
        "author": "Xue, Kaiwen and Zhou, Yuhao and Nie, Shen and Min, Xu and Zhang, Xiaolu and Zhou, Jun and Li, Chongxuan",
        "title": "Unifying Bayesian Flow Networks and Diffusion Models through Stochastic Differential Equations"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "gulrajani2024likelihood",
        "author": "Gulrajani, Ishaan and Hashimoto, Tatsunori B",
        "title": "Likelihood-based diffusion language models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "austin2021structured",
        "author": "Austin, Jacob and Johnson, Daniel D and Ho, Jonathan and Tarlow, Daniel and Van Den Berg, Rianne",
        "title": "Structured denoising diffusion models in discrete state-spaces"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "hoogeboom2021argmax",
        "author": "Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\\'e}, Patrick and Welling, Max",
        "title": "Argmax flows and multinomial diffusion: Learning categorical distributions"
      },
      {
        "key": "hoogeboom2021autoregressive",
        "author": "Hoogeboom, Emiel and Gritsenko, Alexey A and Bastings, Jasmijn and Poole, Ben and Berg, Rianne van den and Salimans, Tim",
        "title": "Autoregressive diffusion models"
      },
      {
        "key": "he2022diffusionbert",
        "author": "He, Zhengfu and Sun, Tianxiang and Wang, Kuanning and Huang, Xuanjing and Qiu, Xipeng",
        "title": "Diffusionbert: Improving generative masked language models with diffusion models"
      },
      {
        "key": "campbell2022continuous",
        "author": "Campbell, Andrew and Benton, Joe and De Bortoli, Valentin and Rainforth, Thomas and Deligiannidis, George and Doucet, Arnaud",
        "title": "A continuous time framework for discrete denoising models"
      },
      {
        "key": "meng2022concrete",
        "author": "Meng, Chenlin and Choi, Kristy and Song, Jiaming and Ermon, Stefano",
        "title": "Concrete score matching: Generalized score matching for discrete data"
      },
      {
        "key": "reid2022diffuser",
        "author": "Machel Reid and Vincent J. Hellendoorn and Graham Neubig",
        "title": "DiffusER: Discrete Diffusion via Edit-based Reconstruction"
      },
      {
        "key": "sun2022score",
        "author": "Sun, Haoran and Yu, Lijun and Dai, Bo and Schuurmans, Dale and Dai, Hanjun",
        "title": "Score-based continuous-time discrete diffusion models"
      },
      {
        "key": "kitouni2023disk",
        "author": "Kitouni, Ouail and Nolte, Niklas and Hensman, James and Mitra, Bhaskar",
        "title": "DiSK: A Diffusion Model for Structured Knowledge"
      },
      {
        "key": "Zheng2023ARD",
        "author": "Lin Zheng and Jianbo Yuan and Lei Yu and Lingpeng Kong",
        "title": "A Reparameterized Discrete Diffusion Model for Text Generation"
      },
      {
        "key": "chen2023fast",
        "author": "Chen, Zixiang and Yuan, Huizhuo and Li, Yongqian and Kou, Yiwen and Zhang, Junkai and Gu, Quanquan",
        "title": "Fast Sampling via De-randomization for Discrete Diffusion Models"
      },
      {
        "key": "ye2023diffusion",
        "author": "Ye, Jiasheng and Zheng, Zaixiang and Bao, Yu and Qian, Lihua and Gu, Quanquan",
        "title": "Diffusion language models can perform many tasks with scaling and instruction-finetuning"
      },
      {
        "key": "gat2024discrete",
        "author": "Gat, Itai and Remez, Tal and Shaul, Neta and Kreuk, Felix and Chen, Ricky TQ and Synnaeve, Gabriel and Adi, Yossi and Lipman, Yaron",
        "title": "Discrete Flow Matching"
      },
      {
        "key": "zheng2024maskeddiffusionmodelssecretly",
        "author": "Kaiwen Zheng and Yongxin Chen and Hanzi Mao and Ming-Yu Liu and Jun Zhu and Qinsheng Zhang",
        "title": "Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling"
      },
      {
        "key": "sahoo2024simple",
        "author": "Sahoo, Subham Sekhar and Arriola, Marianne and Schiff, Yair and Gokaslan, Aaron and Marroquin, Edgar and Chiu, Justin T and Rush, Alexander and Kuleshov, Volodymyr",
        "title": "Simple and Effective Masked Diffusion Language Models"
      },
      {
        "key": "shi2024simplified",
        "author": "Shi, Jiaxin and Han, Kehang and Wang, Zhe and Doucet, Arnaud and Titsias, Michalis K",
        "title": "Simplified and Generalized Masked Diffusion for Discrete Data"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "lou2023discrete",
        "author": "Lou, Aaron and Meng, Chenlin and Ermon, Stefano",
        "title": "Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "ou2024your",
        "author": "Ou, Jingyang and Nie, Shen and Xue, Kaiwen and Zhu, Fengqi and Sun, Jiacheng and Li, Zhenguo and Li, Chongxuan",
        "title": "Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "nie2024scaling",
        "author": "Nie, Shen and Zhu, Fengqi and Du, Chao and Pang, Tianyu and Liu, Qian and Zeng, Guangtao and Lin, Min and Li, Chongxuan",
        "title": "Scaling up Masked Diffusion Models on Text"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "gong2024scaling",
        "author": "Gong, Shansan and Agarwal, Shivam and Zhang, Yizhe and Ye, Jiacheng and Zheng, Lin and Li, Mukai and An, Chenxin and Zhao, Peilin and Bi, Wei and Han, Jiawei and others",
        "title": "Scaling Diffusion Language Models via Adaptation from Autoregressive Models"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "chang2022maskgit",
        "author": "Chang, Huiwen and Zhang, Han and Jiang, Lu and Liu, Ce and Freeman, William T",
        "title": "Maskgit: Masked generative image transformer"
      },
      {
        "key": "chang2023muse",
        "author": "Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others",
        "title": "Muse: Text-to-image generation via masked generative transformers"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2024diffusion",
        "author": "Wang, Xinyou and Zheng, Zaixiang and Ye, Fei and Xue, Dongyu and Huang, Shujian and Gu, Quanquan",
        "title": "Diffusion Language Models Are Versatile Protein Learners"
      },
      {
        "key": "wang2024dplm",
        "author": "Wang, Xinyou and Zheng, Zaixiang and Ye, Fei and Xue, Dongyu and Huang, Shujian and Gu, Quanquan",
        "title": "Dplm-2: A multimodal diffusion protein language model"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "kou2024cllms",
        "author": "Kou, Siqi and Hu, Lanxiang and He, Zhezhi and Deng, Zhijie and Zhang, Hao",
        "title": "Cllms: Consistency large language models"
      },
      {
        "key": "xu2025show",
        "author": "Xu, Chenkai and Wang, Xu and Liao, Zhenyi and Li, Yishun and Hou, Tianqi and Deng, Zhijie",
        "title": "Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation"
      }
    ]
  }
]