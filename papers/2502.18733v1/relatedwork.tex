\section{Related Works}
Stress detection utilizing physiological signals has been extensively investigated through various machine learning (ML) and deep learning (DL) approaches. Research has focused on optimizing model architectures, feature engineering, and dataset preprocessing to enhance classification performance. This section reviews studies employing different physiological signals and particularly discusses those using the WESAD dataset for stress classification.

\subsection{Traditional and Early Machine Learning Approaches}
Early studies in stress detection utilized conventional machine learning techniques that required significant feature engineering. For instance, Heyat et al. \cite{bios12060427} demonstrated stress classification using decision trees applied to ECG signals collected from a smart T-shirt with an embedded cardiac electrode, while AlShorman et al. \cite{alshorman2022frontal} employed methods such as Support Vector Machines and Naive Bayes on features extracted via Fast Fourier Transform. Andric et al. \cite{andric2024anticipating} employed a Random Forest classifier on WESAD and the Stress-Predict dataset, achieving $96\%$ accuracy. While their preprocessing and feature extraction methods increase computational complexity, the approach in this study achieves high precision and recall with minimal preprocessing. Nazeer et al. \cite{nazeer2024improved} explored preprocessing strategies, context modeling, and branch classifiers using XGBoost for stress detection. Their feature extraction pipeline is comprehensive, but this study achieves comparable accuracy with less preprocessing. Mazumdar et al. \cite{mazumdarml} analyzed various classifiers and identified ECG, EDA, and temperature as key features, with XGBoost achieving the highest accuracy. Bhanushali et al. \cite{9184466} employed Decision Tree, Random Forest, and XGBoost classifiers for stress classification on WESAD. Although pioneering, these approaches frequently necessitated carefully designed preprocessing pipelines to address noise and variability in physiological data. 

\subsection{Deep Learning Approaches}

With the advent of deep learning and its aptness in ingesting raw unstructured data, researchers initiated investigations into Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs) and Transformer models to automatically learn representations from raw or minimally processed signals. Narwat et al. \cite{10463214} evaluated KNN, XGBoost, and CNN on WESAD, demonstrating the advantages of deep learning. Investigations such as those conducted by Mohapatra \cite{9964761} and Gil-Martin et al. \cite{9669993} used CNN models for stress detection on speech data across seven emotional categories from a Kaggle dataset and combined CNNs with Fourier Transform preprocessing and Leave-One-Subject-Out cross-validation, for classification across multiple stress and emotional states. 


LSTM-based models have demonstrated improvements over CNNs in capturing longitudinal relationships, as reported by Nigam et al. \cite{nigam2021improved} utilized Respiban chest sensors with LSTM to classify stress, optimizing hyperparameters to improve performance. Similarly, Nath et al. \cite{nath2022machine} implemented an LSTM-based stress detection model for older adults using BVP and EDA signals, comparing its performance to  traditional machine learning approaches of logistic regression, KNN, SVM, and Random Forest. Malviya and Mal et al. \cite{malviya2022novel} developed hybrid a CNN-BLSTM model incorporating Discrete Wavelet Transform (DWT) for stress classification, while Song et al. \cite{song2024stress} employed a combination of LSTM and Xception models to fuse 1D and spectrogram-based ECG features, achieving $99.51\%$ accuracy. While their approach slightly outperforms others in ECG classification, it requires higher computational resources. Additionally, Kumar et al. \cite{kumar2024deep} employed CNNs and time-frequency representations (TFRs), such as Short-Time Fourier Transformation (STFT) and Continuous Wavelet Transform (CWT) for ECG and EDA-based stress classification. More recently, transformer architectures have emerged as a promising alternative, primarily due to their capacity to capture long-range dependencies without substantial reliance on handcrafted features. Wu et al. \cite{wu2023transformer} proposed a multimodal transformer incorporating EDA, BVP, and temperature signals for stress classification across multiple datasets. Self-supervised learning (SSL) has been investigated for emotion recognition by Gotz et al. \cite{gotz2023self} who proposed a modality-agnostic Transformer (MATS2L) trained on ECG and EDA signals, demonstrating the benefits of SSL for feature extraction, while mitigating the necessity for extensive preprocessing.

To facilitate generalization and transferability, Albaladejo-Gonzales et al. \cite{albaladejo2023evaluating} examined transfer learning for stress detection using heart rate data from WESAD and SWELL-KW datasets, with a Multilayer Perceptron (MLP) demonstrating superior performance. Fang et al. \cite{fang2022towards} introduced a domain generalization framework trained on WESAD and BioVid to improve model transferability. Although their method enhances generalizability, it does not achieve the same accuracy as models trained without multi-dataset adaptation. On the other hand, Li et al. \cite{li2024comparison} analyzed both approaches and found that personalized models tend to perform better.

\subsection{Gaps and the Current Contribution}

The extant literature demonstrates significant advancements from traditional methodologies to sophisticated deep learning models. However, the majority of prior research exhibits two notable limitations. First, there exists a substantial reliance on complex feature extraction and preprocessing for traditional machine learning approaches, which may impede real-time application. Second, existing studies predominantly focus on optimizing performance within individual modalities, resulting in a paucity of understanding regarding cross-modal generalization. In contrast, this study not only adapts transformer models for direct application to raw physiological data but also systematically evaluates both intramodality accuracy and cross-modality generalization. Through the utilization of UMAP visualizations and quantitative variance analysis, this research provides novel insights into the transferability of learned representations across diverse sensor types, thereby addressing a critical gap in stress detection research.