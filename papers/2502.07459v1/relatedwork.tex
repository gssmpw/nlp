\section{Related Work}
LLM evaluation has expanded significantly in recent years, covering aspects such as reasoning~\cite{llm_bench_1_rm, llm_bench_4_rm}, knowledge and language understanding~\cite{llm_bench_3_k, llm_bench_5_k}, and instruction following~\cite{llm_bench_0_if, llm_bench_6_if}. As LLMs have dramatically improved in capability, the focus of benchmarking has shifted towards more challenging tasks, such as cultural awareness. Despite numerous attempts to develop cultural benchmarks for English~\cite{cultural_en_1_2024, cultural_en_2_2024, cultural_en_4_2024, cultural_en_5_2024} and other widely spoken languages~\cite{blend_2024, cultural_us_egypt_2024, cultural_multi_1_2024, cultural_korean_2024, acegpt_2024, cultural_en_3_2023}, a gap remains in evaluations of less-studied languages and cultures, such as Persian.

Most existing Persian benchmarks focus on language understanding tasks such as textual entailment and question answering~\cite{farstail_2023, pquad_2023, parsquad_2021, parsinlu_2021}, or the evaluation of factual/scientific knowledge of LLMs~\cite{khayyam_2024, persian_bench_2024}. 
For instance, the Khayyam-Challenge~\cite{khayyam_2024} proposes a set of 20K Persian questions divided into 38 tasks, but these tasks are mainly school-level examinations, primarily covering mathematical and scientific subjects. Although this is useful for evaluating the capabilities of LLMs to solve scientific problems in Persian, it fails to assess LLMs' understanding of Persian culture. This also applies to the work of~\cite{persian_bench_2024} which introduces two new datasets to evaluate LLM abilities in solving Persian mathematical and scientific questions.

Among works on Persian culture, PSN~\cite{psn_2024} provides pairs of social norms and contexts along with a label for each pair describing the appropriateness of each pair. However, it is limited to social norms, leaving out other important aspects such as \textit{Visible Behavior} or \textit{Rituals}. BLEnD~\cite{blend_2024} and CulturalBench~\cite{cultural_en_5_2024} are multi-cultural datasets that despite the inclusion of certain questions about Persian culture, present crucial limitations. BLEnD primarily features questions that focus on non-Persian cultural events and traditions, such as {\it Thanksgiving} or {\it Christmas}, making it less relevant for assessing cultures where these events are not celebrated, such as Persian. CulturalBench, while contains question relevant to Persian culture, is small in size.


\begin{figure*}[!ht]
  \centering
  \includegraphics[width=\textwidth]{dataset.png}
  \caption{\textsc{PerCul} was generated through a stepwise process: (1) identifying cultural categories using Hall's Triad of Culture, (2) native annotators generating facets, topics, and metadata, (3) generating storylines with capable LLMs, (4) rigorous human correction and selection of stories, (5) creating comprehension options with heuristic rules, and (6) dataset compilation.}
  \label{fig:dataset_generation}
\end{figure*}