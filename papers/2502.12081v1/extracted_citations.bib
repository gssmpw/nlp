@article{chatspot,
  title={Chatspot: Bootstrapping multimodal llms via precise referring instruction tuning},
  author={Zhao, Liang and Yu, En and Ge, Zheng and Yang, Jinrong and Wei, Haoran and Zhou, Hongyu and Sun, Jianjian and Peng, Yuang and Dong, Runpei and Han, Chunrui and others},
  journal={arXiv preprint arXiv:2307.09474},
  year={2023}
}

@article{chen2023cosa,
  title={Cosa: Concatenated sample pretrained vision-language foundation model},
  author={Chen, Sihan and He, Xingjian and Li, Handong and Jin, Xiaojie and Feng, Jiashi and Liu, Jing},
  journal={arXiv preprint arXiv:2306.09085},
  year={2023}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{goodhart1984monetary,
  title={Monetary theory and practice: The UK experience},
  author={Goodhart, Charles Albert Eric},
  journal={(No Title)},
  year={1984}
}

@article{laidlaw2024preventing,
  title={Preventing reward hacking with occupancy measure regularization},
  author={Laidlaw, Cassidy and Singhal, Shivam and Dragan, Anca},
  journal={arXiv preprint arXiv:2403.03185},
  year={2024}
}

@article{leike2017ai,
  title={AI safety gridworlds},
  author={Leike, Jan and Martic, Miljan and Krakovna, Victoria and Ortega, Pedro A and Everitt, Tom and Lefrancq, Andrew and Orseau, Laurent and Legg, Shane},
  journal={arXiv preprint arXiv:1711.09883},
  year={2017}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{li2024reward,
  title={Reward guided latent consistency distillation},
  author={Li, Jiachen and Feng, Weixi and Chen, Wenhu and Wang, William Yang},
  journal={arXiv preprint arXiv:2403.11027},
  year={2024}
}

@article{llava,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@misc{llavanext-video,
  title={LLaVA-NeXT: A Strong Zero-shot Video Understanding Model},
  url={https://llava-vl.github.io/blog/2024-04-30-llava-next-video/},
  author={Zhang, Yuanhan and Li, Bo and Liu, haotian and Lee, Yong jae and Gui, Liangke and Fu, Di and Feng, Jiashi and Liu, Ziwei and Li, Chunyuan},
  month={April},
  year={2024}
}

@inproceedings{merlin,
  title={Merlin: Empowering multimodal llms with foresight minds},
  author={Yu, En and Zhao, Liang and Wei, Yana and Yang, Jinrong and Wu, Dongming and Kong, Lingyu and Wei, Haoran and Wang, Tiancai and Ge, Zheng and Zhang, Xiangyu and others},
  booktitle={European Conference on Computer Vision},
  pages={425--443},
  year={2024},
  organization={Springer}
}

@misc{minigpt4,
      title={MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models}, 
      author={Deyao Zhu and Jun Chen and Xiaoqian Shen and Xiang Li and Mohamed Elhoseiny},
      year={2023},
      eprint={2304.10592},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{pan2022effects,
  title={The effects of reward misspecification: Mapping and mitigating misaligned models},
  author={Pan, Alexander and Bhatia, Kush and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2201.03544},
  year={2022}
}

@article{pllava,
  title={Pllava: Parameter-free llava extension from images to videos for video dense captioning},
  author={Xu, Lin and Zhao, Yilin and Zhou, Daquan and Lin, Zhijie and Ng, See Kiong and Feng, Jiashi},
  journal={arXiv preprint arXiv:2404.16994},
  year={2024}
}

@misc{rewardhacking,
  title={Specification Gaming: The Flaw in the Reward},
  author={DeepMind},
  url = {https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/},
  year={2018}
}

@article{video-llama,
  title={Video-llama: An instruction-tuned audio-visual language model for video understanding},
  author={Zhang, Hang and Li, Xin and Bing, Lidong},
  journal={arXiv preprint arXiv:2306.02858},
  year={2023}
}

@article{videollama2,
  title={VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio Understanding in Video-LLMs},
  author={Cheng, Zesen and Leng, Sicong and Zhang, Hang and Xin, Yifei and Li, Xin and Chen, Guanzheng and Zhu, Yongxin and Zhang, Wenqi and Luo, Ziyang and Zhao, Deli and others},
  journal={arXiv preprint arXiv:2406.07476},
  year={2024}
}

@article{wang2023internvid,
  title={Internvid: A large-scale video-text dataset for multimodal understanding and generation},
  author={Wang, Yi and He, Yinan and Li, Yizhuo and Li, Kunchang and Yu, Jiashuo and Ma, Xin and Li, Xinhao and Chen, Guo and Chen, Xinyuan and Wang, Yaohui and others},
  journal={arXiv preprint arXiv:2307.06942},
  year={2023}
}

@article{wang2024cosmo,
  title={COSMO: COntrastive Streamlined MultimOdal Model with Interleaved Pre-Training},
  author={Wang, Alex Jinpeng and Li, Linjie and Lin, Kevin Qinghong and Wang, Jianfeng and Lin, Kevin and Yang, Zhengyuan and Wang, Lijuan and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2401.00849},
  year={2024}
}

@article{wang2024tarsier,
  title={Tarsier: Recipes for Training and Evaluating Large Video Description Models},
  author={Wang, Jiawei and Yuan, Liping and Zhang, Yuchen},
  journal={arXiv preprint arXiv:2407.00634},
  year={2024}
}

@article{wei2024small,
  title={Small language model meets with reinforced vision vocabulary},
  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yu, En and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2401.12503},
  year={2024}
}

@inproceedings{wei2024vary,
  title={Vary: Scaling up the vision vocabulary for large vision-language model},
  author={Wei, Haoran and Kong, Lingyu and Chen, Jinyue and Zhao, Liang and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Han, Chunrui and Zhang, Xiangyu},
  booktitle={European Conference on Computer Vision},
  pages={408--424},
  year={2024},
  organization={Springer}
}

@article{zhang2024large,
  title={Large-scale reinforcement learning for diffusion models},
  author={Zhang, Yinan and Tzeng, Eric and Du, Yilun and Kislyuk, Dmitry},
  journal={arXiv preprint arXiv:2401.12244},
  volume={4},
  year={2024}
}

