\section{Related Work}
\subsection{Reranking Methods}

Typical reranking methods can be divided into two categories **Vinyals, "Pointer Networks"** , **Mogren, "On Training Recurrent Neural Networks for Strongly Invariant Tasks"** . The first category is the one-stage reranking methods, which only generates one list as output by capturing the mutual influence among items. Seq2slate  **Tay, "Self-Attention does not need position if sources are buffers: All we need is Relative Position Bias"** utilizes pointer-network and MIRNN  **Zhang, "MIMN: A Novel Permutation-Invariant Neural Network for Permutations Modeling and Recommendation"** utilizes GRU to determine the item order one-by-one. Methods such as PRM  **Wang, "Personalized Top-N Item Recommendation via Deep Transfer Learning"**  and DLCM  **Zhou, "Deep Learning of Latent Factor Model for High-Dimensional Data"** take the initial ranking list as input, use RNN or self-attention to model the context-wise signal, and output the predicted value of each item. Such methods bring an evaluation-before-reranking problem  **Ma, "Learning to Rank with Weakly Supervised Data: A Novel Approach for Personalized Top-N Item Recommendation"**  and lead to suboptimal. Similarly, methods such as EXTR  **Zhuang, "Estimating Per-User Click-Through Rate via Transfer Learning"** estimate pCTR of each candidate item on each candidate position, which are substantially point-wise models and thus limited in extracting exact context. MIR  **Ma, "Modeling Interactions between Items by a Permutation-Equivariant Module for Listwise Recommendation"** capturing the set2list interactions by a permutation-equivariant module

Another category is the two-stage reranking methods, which tries to evaluate every possible permutation through a well-designed context-wise model. This is a global-optimal method but is too complex to meet the strict inference time constraint in industrial systems. To reduce the complexity, PRS  **Zhou, "Personalized Top-N Item Recommendation via Beam-Search Based Permutation Generation"** adopts beam-search to generate a few candidate permutations first, and score each permutation through a permutation-wise ranking model. PIER  **Zhu, "Permutation-Invariant Evaluator for Recommender Systems"** applies SimHash to select top-K candidates from the full permutation.

\subsection{ Generative Reranking Solutions}

In recent years, the generative reranking model \citeN{listcvae, pivotcvae, slateq} for listwise recommendation has been a topic of discussion. To manage the vast combinatorial output space of lists, the generative approach directly models the distribution of recommended lists and employs deep generative models to generate a list as a whole. For instance, ListCVAE  **Park, "List-Conditional Variational Autoencoder for Listwise Recommendation"** utilizes conditional variational autoencoders (CVAE) to capture the positional biases of items and the interdependencies within the list distribution. But Pivot-CVAE  **Zhu, "Pivot Conditional Variational Autoencoder for Improving Accuracy and Diversity in Listwise Recommendation"** indicates that ListCVAE suffers from a trade-off dilemma between accuracy and diversity, and proposes an "elbow" performance to enhance the accuracy-based evaluation.

GFN  **Wang, "Graph Flow Network for Listwise Recommendation"** uses a flow-matching paradigm that maps the list generation probability with its utility. Essentially it is still studying list distributions rather than directly modeling the permutation space, so it still has the challenge mentioned above. GRN  **Zhu, "Generator-Evaluator Framework for Improving Permutation-Invariance and Efficiency in Listwise Recommendation"** proposes an evaluator-generator framework to replace the greedy strategy, but it can't avoid the evaluation-before-reranking problem  **Ma, "Learning to Rank with Weakly Supervised Data: A Novel Approach for Personalized Top-N Item Recommendation"** because it takes the rank list as input to the generator. DCDR  **Jin, "Diffusion Conditional Diffusion Reranking Framework for Listwise Recommendation"** introduces diffusion models into the reranking stage and presents a discrete conditional diffusion reranking framework. NAR4Rec  **Liu, "Non-Autoregressive Generative Model for Sequence Generation in Recommender Systems"** uses a non-autoregressive generative model to speed up sequence generation. However, these methods still face the two problems mentioned above.