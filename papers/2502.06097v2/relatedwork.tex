\section{Related Work}
\subsection{Reranking Methods}

Typical reranking methods can be divided into two categories \cite{pier}. The first category is the one-stage reranking methods, which only generates one list as output by capturing the mutual influence among items. Seq2slate \cite{seq2slate} utilizes pointer-network and MIRNN \cite{zhuang2018globally} utilizes GRU to determine the item order one-by-one. Methods such as PRM \cite{prm} and DLCM \cite{ai2018learning} take the initial ranking list as input, use RNN or self-attention to model the context-wise signal, and output the predicted value of each item. Such methods bring an evaluation-before-reranking problem \cite{xi2021context} and lead to suboptimal. Similarly, methods such as EXTR \cite{extr} estimate pCTR of each candidate item on each candidate position, which are substantially point-wise models and thus limited in extracting exact context. MIR \cite{mir} capturing the set2list interactions by a permutation-equivariant module
Another category is the two-stage reranking methods, which tries to evaluate every possible permutation through a well-designed context-wise model. This is a global-optimal method but is too complex to meet the strict inference time constraint in industrial systems. To reduce the complexity, PRS \cite{feng2021revisit} adopts beam-search to generate a few candidate permutations first, and score each permutation through a permutation-wise ranking model. PIER \cite{pier} applies SimHash to select top-K candidates from the full permutation.  

\subsection{ Generative Reranking Solutions}

In recent years, the generative reranking model \citeN{listcvae, pivotcvae, slateq} for listwise recommendation has been a topic of discussion. To manage the vast combinatorial output space of lists, the generative approach directly models the distribution of recommended lists and employs deep generative models to generate a list as a whole. For instance, ListCVAE \cite{listcvae} utilizes conditional variational autoencoders (CVAE) to capture the positional biases of items and the interdependencies within the list distribution. But Pivot-CVAE \cite{pivotcvae} indicates that ListCVAE suffers from a trade-off dilemma between accuracy and diversity, and proposes an "elbow" performance to enhance the accuracy-based evaluation. 


GFN \cite{gfn} uses a flow-matching paradigm that maps the list generation probability with its utility. Essentially it is still studying list distributions rather than directly modeling the permutation space, so it still has the challenge mentioned above. GRN \cite{grn} proposes an evaluator-generator framework to replace the greedy strategy, but it can't avoid the evaluation-before-reranking problem \cite{xi2021context} because it takes the rank list as input to the generator. DCDR \cite{dcdr} introduces diffusion models into the reranking stage and presents a discrete conditional diffusion reranking framework. NAR4Rec \cite{nar4rec} uses a non-autoregressive generative model to speed up sequence generation. However, these methods still face the two problems mentioned above.