\section{Related Work}
\textit{Parallax mapping} renders depth details by offsetting texture samples based on parallax (shifted occlusion) **Kang, "A Survey of Parallax Mapping"**. \textit{Parallax occlusion mapping} iteratively samples the height field to ensure correct depth while also supporting occlusion shadows **Lefebvre et al., "Parallax Occlusion Mapping"**. \textit{Prism parallax occlusion} mapping enhances this with correct silhouettes by intersecting view rays with extruded prisms split into three tetrahedra **Kang and Lee, "Prism Parallax Occlusion Mapping"**. \textit{Relief maps} encode the displaced surface as a color texture with an additional depth channel. The original method was an image-warping technique  **Crow, "Shadow Maps"**, whereas later methods traverse the relief map to cover arbitrary base meshes **Lefebvre et al., "Parallax Occlusion Mapping"**. Quadric surfaces may also be covered by relief maps by using ray-quadric intersection before relief stepping **Wang et al., "Ray-Quadric Intersection"**. Intended for raster pipelines, parallax and relief mapping do not utilize BVHs or support general ray tracing.

\textit{Cone step mapping} accelerates the intersection search by precomputing a cone map to skip features based on occlusion angle  **Kang et al., "Cone Step Mapping"**, employing binary search **Lefebvre, "Binary Search for Cone Step Mapping"**, or using a min-max texture **Wang et al., "Min-Max Texture"**. However, anti-aliasing cone maps introduces overhead since they cannot be hardware interpolated. These methods are view-dependent, making them unsuitable for ray tracing arbitrary base meshes.

\textit{Curved rays} map the 3D volume of the displaced surface to nonlinear texture space **Kang and Lee, "Nonlinear Rays"**. Tangent-space methods compute the curved mapping between world and depth texture space at each sample, approximating curved rays with piecewise segments **Wang et al., "Tangent-Space Methods"**. We avoid this transform per sample by designing a parallel offset prism with a linear projection to texture space. **Kang et al., "Parallel Offset Prisms"** develops nonlinear rays by solving cubic equations that map world rays into canonical prism volumes. In their work, multiple data structures are provided for acceleration: BVHs for broad phase, and min-max mipmaps for local displacement or BVHs for instanced meso-geometry **Wang et al., "Instanced Meso-Geometry"**. Rays are transformed at the leaf nodes (prisms) of the broad-phase BVH, where they become nonlinear in rectified canonical space (see Fig. \ref{fig:prisms}, top right). Although optimizations are mentioned, the pre-computation of data structures and solving cubic equations preclude our goals for interactive editing.

\textit{Parametric surfaces} may be exactly evaluated through root-finding with Newton’s method, whereas complex surfaces must be divided into multiple intervals **Kang et al., "Interval Division"**. To guarantee convergence, the intervals must be chosen to locally bound the surface at minima and maxima. **Wang et al., "Surface Trees"** construct a tree structure to efficiently traverse the surface. Caching surface trees enables fast parallel ray tracing of parametric surfaces by sharing information with neighboring rays **Lefebvre, "Caching Surface Trees"**.

\textit{Affine intervals} have been shown to provide better local bounds than min-max intervals **Kang and Lee, "Affine Intervals"**. **Wang et al., "D-BVHs"** construct a D-BVH as a min-max mipmap over affine intervals of the base geometry. Displaced bounds are generated dynamically from quad-tree nodes, requiring significant computation for intersection. Recent work improves performance with a hierarchical data structure, RMIP, over the displacement map using a bidirectional mapping between 2D depth texture and 3D object space **Lefebvre et al., "RMIP"**. Rectangular regions in RMIP allow for acceleration of anisotropic ray sampling. Since D-BVH and RMIP can be costly during traversal, we explore a direct sampling approach for quality and performance during editing.

\textit{Shell mapping} constructs a bijective map between texture space and shell space - the region between two offset surfaces - where meso-geometry will be rendered locally **Kang et al., "Shell Mapping"**. Rays are traced in shell space and transformed back to world space, mapping a 3D volume onto a surface. Real-time rendering is achieved by **Wang et al., "Distance Maps"** utilizing a distance map to accelerate ray tracing within the shell space of the primary object and a volumetric texture to encode the meso-geometry. Both techniques precompute the shell space prism as three tetrahedra **Lefebvre, "Tetrahedral Prisms"**. \textit{Curved shell mapping} removes discontinuities by modeling Coons patches within each prism at the cost of solving a cubic equation per ray step **Wang et al., "Cubic Equations"**.

A different approach to meso-geometry finds ways to precompute intersections through suitable encodings. One such encoding uses singular value decomposition **Kang and Lee, "Singular Value Decomposition"**, while others use neural networks to evaluate intersections **Lefebvre et al., "Neural Networks"**. Their work handles meso-geometries yet encoding requires considerable pre-processing that we avoid in favor of interactive performance and editability.

\textit{Tessellation} is an intuitive approach to displacement mapping, generating additional geometry for detail as needed  **Kang et al., "Tessellated Surfaces"**. **Wang et al., "Adaptive Hardware Tessellation"** accelerate fully tessellated surfaces with uniform spatial grids. Full tessellation is memory-intensive, thus research shifted to localized, micro-tessellation techniques, such as geometry caching of sub-triangles **Lefebvre, "Geometry Caching"**. \textit{Adaptive hardware tessellation} was introduced as a shader pipeline stage with DirectX 11  **Kang et al., "DirectX 11"** enabling real-time adaptive displacement and higher-order surfaces **Wang et al., "Higher-Order Surfaces"**.  The tessellation stage can be used to adaptively render displacement-mapped surfaces **Lefebvre, "Adaptive Rendering"**. However, direct hardware tessellation is generally poorly suited to ray tracing since non-view facing reflections and refractions are not easily handled.

\textit{Higher order surfaces} are a commonly tessellated, including Bézier patches  **Kang et al., "Bézier Patches"**, Catmull-Clark surfaces **Wang et al., "Catmull-Clark Surfaces"**, Gregory patches **Lefebvre, "Gregory Patches"**, and Loop subdivision surfaces **Kang et al., "Loop Subdivision Surfaces"**. These surfaces provide smoothness guarantees with $C^1$ or $C^2$ continuity. We introduce a novel adjustment to the displaced shading normal that achieves visual continuity when ray tracing arbitrary base meshes without an intermediate $C^1$ surface.

\textit{Locally adaptive tessellation} is a recent trend whereby GPU tessellation is applied to increase detail locally on arbitrary base meshes. Nanite introduced virtual geometry to compress source geometry into small triangle clusters which are loaded and rendered as dynamic, regional levels of detail (LOD) on-the-fly **Kang et al., "Nanite"**. To support ray tracing, **Wang et al., "Dynamic BVHs"** insert triangle clusters into a dynamic, GPU-accelerated BVH per frame. These methods depend on a high-resolution source mesh which is preprocessed through clustering and decimation of triangle groups **Lefebvre, "Triangle Clustering"**.  **Kang et al., "Explicit Subdivision"** introduces locally adaptive ray tracing which does not split the mesh but instead refines each triangle through an explicit one-to-four triangle subdivision. Pre-computed acceleration is achieved by inserting each division into a custom tessellation tree, which can be used to select per-triangle LODs on-the-fly.

Micro-Meshes **Wang et al., "Micro-Meshes"** is an API for rendering highly detailed objects as locally adaptive subdivided triangles with data compression via barycentric maps. This eliminates the need for UV mapping since sampling is implicit. Primarily  intended to compress detailed base models, displacement mapping is supported by remapping from a depth texture to the barycentric map. Although this precludes interactive editing we examine Micro-Meshes in terms of rendering quality compared to our approach.

Modern techniques for locally adaptive tessellation can give good rendering performance over highly detailed source meshes, yet this is often at the cost of complex data structures utilizing the most recent GPU hardware.

\begin{figure}
  \includegraphics[width=\textwidth]{fig_overview}
  \caption{\textbf{Method overview}. Our technique starts with a low-poly base mesh, from which we pre-compute parallel offset prisms with positive and negative extents. Prisms and their AABBs are used to build the geometry graph and hardware-accelerated BVH. A custom program implements prism intersection and the Projective Displacement algorithm described in text.}
 \label{fig:overview}