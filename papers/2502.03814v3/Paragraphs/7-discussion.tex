\section{Challenges, and Opportunities}\label{sec:7-discussion}
Despite the progress in integrating LLMs into MRS, significant challenges that limit their broader adoption and effectiveness remain. These challenges span areas such as reasoning capabilities, real-time performance, and adaptability to dynamic environments. Addressing these issues is critical to unlocking the full potential of LLMs in MRS. This section identifies key challenges the field faces and outlines promising opportunities for future research, offering a roadmap for enhancing the utility and robustness of LLM-driven MRS.

\subsection{Challenges}

\textbf{Insufficient Mathematical Capability.}
LLMs struggle with tasks requiring precise calculations or logical reasoning, such as multi-robot path planning or trajectory optimization. This limitation reduces their effectiveness in scenarios where quantitative accuracy is critical. Mirzadeh \etal~\cite{mirzadeh_gsm-symbolic_2024} performed a detailed comparison and investigation on the mathematical understanding and problem-solving ability of several state-of-art LLMs. Specifically, LLMs exhibit noticeable variance when responding to different variations of the same question, with performance declining significantly when only the numerical values are altered. Furthermore, their reasoning capabilities are fragile; they often mimic patterns observed in training data rather than performing genuine logical deduction. This fragility is exacerbated by an increase in the number of clauses within a question, even when the added clauses are irrelevant to the reasoning chain, leading to performance drops of up to 65\% in state-of-the-art models. These vulnerabilities present serious challenges for MRS, where precise calculations and robust reasoning are essential for collision-free trajectories, spatial planning, and efficient task execution. Addressing these limitations is critical for deploying LLMs reliably in mathematically intensive applications.\\


\noindent\textbf{Hallucination.}
LLMs are prone to generating content that appears plausible but lacks factual accuracy, a phenomenon known as hallucination. This issue is particularly concerning in MRS, where precise and reliable output is crucial for effective collaboration and operation. According to a comprehensive survey on hallucination in LLMs by Huang \etal~\cite{huang2023survey}, hallucination can be categorized into two main types: actuality hallucinations and faithfulness hallucinations. Factuality hallucinations involve discrepancies between generated content and verifiable real-world facts, leading to incorrect outputs. Faithful hallucinations occur when the generated content diverges from the user's instructions or the provided context, resulting in outputs that do not accurately reflect the intended information. In the context of MRS, such hallucinations can lead to misinterpretations, faulty decision-making, and coordination errors among robots, potentially compromising mission success and safety. Addressing these challenges requires developing methods to detect and mitigate hallucinations, ensuring that LLMs produce outputs that are both factually accurate and contextually appropriate.\\

\noindent\textbf{Difficulties in Field Deployment.}
Current options for using LLMs include server-based models, which are usually close-sourced, and open-source models that individuals can deploy locally. Examples of server-based models include OpenAI GPT~\cite{achiam2023gpt}, Anthropic Claude~\cite{claude}, and Google Gemini (formerly known as Bard)~\cite{googleGemini}, and open-sourced LLMs that individuals can run locally includes Meta Llama~\cite{dubey2024llama}, Falcon~\cite{almazrouei2023falcon},  Alibaba Qwen~\cite{qwen2.5}, and DeepSeek V3~\cite{liu2024deepseek} and R1~\cite{guo2025deepseek}. The server-based models require a reliable internet connection to send inquiries and receive responses, thus making deploying the MRS with LLMs in remote locations unachievable, which is typical for field robot systems. Moreover, server-based LLMs heavily rely on the performance of the server, where the server outage can interrupt the systems built on LLMs entirely. This issue is especially vital for multi-robot teams as the LLM guides the inter-robot collaboration and decision-making. On the other hand, local models can avoid using the servers but require hardware onboard that is powerful enough to run LLMs locally. \\

\noindent\textbf{Relatively High Latency.}
Real-time information exchange and decision-making are critical for the effective operation of MRS in real-world scenarios. However, a notable challenge of using LLMs lies in their relatively high and variable response times, which can depend on model complexity, hardware capabilities, and server availability. For example, Chen \etal~\cite{chen_why_2024} reported that in a multi-agent path finding scenario utilizing GPT-4 from OpenAI, the response time per step ranged between 15 and 30 seconds, significantly impacting real-time feasibility. While local processing on more powerful hardware can reduce latency, this approach is costly and becomes less scalable as the number of robots increases. Addressing this challenge requires exploring optimized LLM architectures, efficient inference techniques, and scalable solutions that balance computational demands with real-time operational requirements.\\

\noindent\textbf{Lack of Benchmarks.}
Performance evaluation is essential for the new research on MRS with LLMs. However, existing benchmarking systems are primarily designed for indoor environments and household applications, which limits their applicability to the diverse and evolving scenarios where MRS operates. As current research often represents initial efforts to apply LLMs to MRS, performance comparisons typically focus on demonstrating feasibility by contrasting LLMs with traditional methods. While this approach is valuable for establishing a baseline, future advancements will likely yield significant performance and functionality improvements. A unified benchmarking framework tailored to multi-robot applications would provide researchers with consistent metrics to evaluate and quantify progress. Such a system would not only facilitate a clearer understanding of the impact of new research but also promote standardization and comparability across studies, accelerating innovation in this emerging field.


\subsection{Opportunities}

\textbf{Fine-tuning and RAG.}
Fine-tuning LLMs on domain-specific datasets and incorporating RAG techniques are promising avenues for improving their performance in multi-robot applications. Fine-tuning allows researchers to adapt pre-trained LLMs to specific tasks, enhancing their contextual understanding and reducing issues like hallucination. RAG complements this by integrating external knowledge retrieval mechanisms, enabling LLMs to access relevant information dynamically during runtime. Together, these techniques can significantly improve LLMs' accuracy, reliability, and adaptability in diverse and complex multi-robot scenarios.\\

\noindent\textbf{High-quality Task-specific Datasets.}
Creating high-quality and task-specific datasets is essential for advancing LLM capabilities in MRS. Leveraging more capable models, such as the latest LLMs, to generate synthetic datasets can accelerate the development of training materials tailored to specific tasks or environments. These datasets should include diverse scenarios, reasoning-focused labels, and context-specific knowledge to improve LLMs' problem-solving and decision-making capabilities. Task-specific datasets are particularly important for preparing MRS to operate in unstructured or open-world environments.\\

\noindent\textbf{Advanced Reasoning Techniques.}
Improving the reasoning capabilities of LLMs is critical for addressing their current limitations in logical and mathematical tasks. Techniques such as Chain of Thought (CoT) prompting, fine-tuning with explicit reasoning labels, integrating symbolic reasoning, and training with RL can enhance the ability of LLMs to handle complex multi-step problems. By advancing reasoning methods, LLMs can better support tasks that require precision and logical deduction, such as multi-robot path planning and coordination.\\

\noindent\textbf{Task-specific and Lightweight Models.}
While large-scale LLMs offer superior performance, they are often impractical for resource-constrained environments. Developing task-specific and lightweight models tailored for multi-robot applications can mitigate this issue. Models like SmolVLM, Moondream 2B, PaliGemma 3B, and Qwen2-VL 2B demonstrate how smaller architectures can reduce computational demands and latency while maintaining adequate performance for specific tasks. Model distillation is another approach to make small models more capable by distilling knowledge from a more capable LLM, like DeepSeek-R1-Distill-Qwen-1.5B, where the knowledge from DeepSeek R1 is distilled into a small Qwen2.5-Math-1.5B model. Balancing efficiency and effectiveness is key to enabling scalable deployments of LLMs in field robotics.\\

\noindent\textbf{Expanding to Unstructured Environments.}
Most current applications and benchmarks focus on indoor or structured environments, leaving significant gaps in outdoor and unstructured scenarios. Research should prioritize expanding MRS capabilities to include operations in open-world contexts, such as agricultural fields, disaster zones, and remote exploration sites. Addressing the unique challenges of these environments, including variability, noise, and unpredictable dynamics, will broaden the applicability of LLM-enabled MRS.\\

\noindent\textbf{Latest More Capable LLMs.}
The continued development of state-of-the-art LLMs opens new possibilities for MRS. Models such as PaliGemma, Qwen, GPT o3 (mini), and DeepSeek V3 and R1 offer enhanced reasoning, understanding, and multitasking capabilities. Incorporating these advanced models into MRS research can accelerate progress by providing improved baseline performance and enabling innovative applications. Exploring their integration with robotics systems can further push the boundaries of what multi-robot teams can achieve.