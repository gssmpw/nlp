\section{Backgrounds}\label{sec:2-back}
This section provides background knowledge on MRS and LLMs. While several other research papers have discussed on the applications of LLMs in robotic systems, they do not specifically focus on the MRS. We will summarize their contributions and discuss why our survey on facilitating LLMs with MRS is necessary and impactful.

%%%%%%%% Multi-Robot Systems %%%%%%%%
\subsection{Multi-Robot Systems}

A MRS consists of multiple robots that collaborate to complete specific tasks. Unlike single-robot systems, MRS leverages the combined capabilities of multiple robots to perform complex tasks more efficiently, reliably, and flexibly~\cite{alonso2016distributed, rizk2019cooperative,zhou2021multi}. These systems are commonly employed in applications such as search and rescue~\cite{baxter2007multi,luo2011multi,kumar2012opportunities,queralta2020collaborative}, target tracking~\cite{zhou2018active,zhou2019sensor,zahroof2023multi,li2023assignment,liu2024multi}, environmental monitoring~\cite{schwager2011eyes, grocholsky2006cooperative}, coverage and exploration~\cite{burgard2005coordinated,shi2021communication,sharma2023d2coplan,liu2023active,cai2024energy}, and warehouse automation~\cite{alonso2015local, wurman2008coordinating}, where the task's scale or complexity exceeds a single robot's capabilities. When all robots in the team are identical and share the same functionality, the team is called a \textbf{homogeneous} multi-robot team. In contrast, a \textbf{heterogeneous} multi-robot team consists of different types of robots~\cite{parker2008handbook,sharma2020risk,cai2024energy}.
The advantages of MRS include enhanced scalability, as tasks can be distributed among robots~\cite{liu2022decentralized,zhou2022graph,chen2024learning}, and increased resilience, as the failure of one robot can often be mitigated by the others~\cite{zhou2018resilient,zhou2018approximation,ramachandran2020resilient,liu2021distributed,mayya2022adaptive,zhou2022risk,zhou2022distributed,zhou2023robust,shi2023robust,li2024resilient}. In contrast to designing a single, highly versatile robot, MRS usually relies on more uncomplicated, task-specific robots, reducing the cost and complexity of individual units while benefiting from collective intelligence~\cite{jones2004principled}. However, these systems also present unique challenges, particularly in communication, coordination, and decision-making, as robots must operate cohesively in dynamic and uncertain environments~\cite{queralta2020collaborative}. 
Two primary control paradigms are commonly employed to manage the interaction and task distribution within an MRS: centralized and decentralized controllers~\cite{yan2013survey, cortes2017coordinated}. In a \textbf{centralized} controller, a single controller receives all the information and directs the actions of all robots in the system, allowing for optimized coordination and global planning. However, centralized systems can become a bottleneck when the group size increases and are vulnerable to single points of failure~\cite{luna2011efficient}. On the other hand, a \textbf{decentralized} controller distributes decision-making among the roots, enabling the robots to operate resiliently~\cite{rizk2019cooperative}. This approach enhances scalability and resilience but often introduces additional complexity to ensure seamless communication and coordination between robots. The choice between centralized and decentralized control depends on the specific application requirements, environmental conditions, and the desired balance between efficiency and robustness~\cite{yan2013survey}.

%%%%%%% LLMs %%%%%%%%
\subsection{Large Language Models}
LLMs are deep learning models with millions to billions of parameters~\cite{zeng_large_2023}. Initially, the application of the LLMs is for text completion based on the context or text generation from the user's instruction~\cite{zhao2023survey}. LLMs are trained using an extensive collection of text from books, articles, websites, and other written sources. During this training process, LLMs learn to predict the next word in a sentence or fill in missing information using the \textbf{attention} mechanism~\cite{vaswani2017attention}. This pre-training phase enables LLMs to develop a broad understanding of language, grammar, factual knowledge, and reasoning skills~\cite{naveed2023comprehensive}. 

\subsubsection{Fine-tuning and RAG}
While LLMs are pre-trained on a diverse dataset for general tasks, the performance in specialized cases can be unideal since the training dataset might not fully cover the special usages~\cite{ding2023parameter, ziegler2019fine}. People can prepare a dataset dedicated to the specialized tasks and retrain the model. However, retraining the entire model is often challenging due to the limited computing resources and numerous parameters within the model~\cite{ding2023parameter}. One solution to address this issue is to use techniques like low-rank adaptation (LoRA) to \textbf{fine-tune} the LLMs with limited computational resources~\cite{hu_lora_2021}. LoRA freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture~\cite{vaswani2017attention}, significantly reducing the number of trainable parameters for the downstream tasks.

On the other hand, retrieval-augmented generation (\textbf{RAG}) is an alternative technique that integrates external knowledge sources to increase the zero-shot accuracy of the LLMs on specialized tasks~\cite{lewis2020retrieval, huang2023survey}. RAG addresses a key limitation of LLMs' reliance on pre-trained, static knowledge, which may not include domain-specific or up-to-date information. By combining a retrieval mechanism with the generative capabilities of LLMs, RAG allows the model to query external databases or knowledge repositories to retrieve relevant information during runtime~\cite{gao2023retrieval}. This retrieved data is then used to guide the model's response, enhancing its accuracy and applicability in specialized contexts. For instance, RAG can provide real-time access to task-specific knowledge or environmental updates for robots, enabling better decision-making in dynamic scenarios~\cite{zhu2024retrieval}. Although RAG introduces additional complexity, such as managing retrieval latency and ensuring data relevance, it offers a powerful method for bridging the gap between static pre-trained knowledge and the dynamic requirements of real-world applications.


\subsubsection{Multimodal LLMs}
Traditional LLMs excel at processing and generating text but fall short in scenarios where understanding multiple data types is essential. Recent progress on multimodal LLMs addresses this limitation by incorporating diverse modalities, enabling them to combine textual inputs with visual, auditory, or other sensory data~\cite{yin2023survey}. These models align information from different modalities into a shared semantic space, allowing for seamless integration and contextual understanding. For instance, a multimodal LLM can process visual data from a robot's camera alongside textual commands to identify objects, navigate environments, or perform complex tasks~\cite{kim_survey_2024, wang2024large_survey}. This ability to synthesize information across modalities significantly enhances their applicability, especially in robotics, where real-world interactions demand integrating various data types. By leveraging multimodal capabilities, these models push the boundaries of what LLMs can achieve, offering a new level of flexibility and adaptability.

\subsection{Related Survey Papers}
Several survey papers have applied LLMs in the robotics and multi-agent field.
Firoozi \etal~\cite{firoozi_foundation_2023}, Zeng \etal~\cite{zeng_large_2023}, and Kim \etal~\cite{kim_survey_2024} all explored how LLMs and foundation models could enhance robotics in areas like perception, decision-making, and control. While they share this focus, their approaches and scopes differ. Firoozi \etal~\cite{firoozi_foundation_2023} provided a broad overview of foundation models in robotics, emphasizing their adaptability across various tasks but without specific attention to MRS. Zeng \etal~\cite{zeng_large_2023} focused on the applications of LLMs in robotics, categorizing their impact on single-robot systems in areas like control and interaction without exploring collaborative systems. Wang \etal~\cite{wang2024large_survey} concentrated on summarizing the applications of LLMs for manipulation tasks for a single robot. Kim \etal~\cite{kim_survey_2024} divided LLM applications into communication, perception, planning, and control, offering practical guidelines for integration, but their work is also centered on single-robot applications. Hunt \etal~\cite{hunt_survey_2024} explored the use of language-based communication in robotics, categorizing applications of LLMs based on their roles in robotic systems, such as tasking robots, inter-robot communication, and human-robot interaction. Their focus is primarily on language as a medium for interaction without addressing the unique challenges of MRS. Guo \etal~\cite{guo_large_2024} reviewed LLM-based multi-agent systems, exploring their applications in problem-solving and world simulation. Although their work included embodied agents, their emphasis is on general multi-agent frameworks, which focus on abstract roles and interactions within systems that may not require physical embodiment or real-world interaction. Kawaharazuka \etal~\cite{kawaharazuka_real-world_2024} examined real-world applications of foundation models in robotics, focusing on replacing components within robotic systems but without addressing inter-robot collaboration or the collective intelligence of MRS.

None of these surveys address the challenges and opportunities of integrating LLMs into MRS. While multi-agent systems provide a generalized framework for understanding roles and interactions, they are often abstract and virtual, lacking the physical embodiment and real-world constraints that characterize MRS~\cite{guo_large_2024}. MRS requires actual physical robots to collectively perceive, decide, and act within dynamic and uncertain environments, posing unique challenges in communication, coordination, and decision-making that go beyond the scope of virtual agents~\cite{wallkotter2021explainable}. Moreover, MRS uniquely benefits from improved scalability, failure resilience, and cost-effective collective operations, making them fundamentally different from single-robot systems or general multi-agent frameworks. This gap highlights the need for a dedicated survey that explores how LLMs can facilitate communication, coordination, and collaborative task execution in MRS, providing critical insights into this emerging and impactful area of research.