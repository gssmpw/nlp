\section{LLMs for Multi-robot Systems}\label{sec:4-LLM-MRS}
In this section, we categorize the applications of LLMs in MRS into high-level task allocation, mid-level motion planning, low-level action generation, and human intervention scenarios. High-level task planning involves tasks that demand a higher degree of intelligence, such as task allocation and planning among multiple robots, where the LLM is required to exhibit logical reasoning and decision-making capabilities. Mid-level motion planning refers to navigation or path-planning scenarios. Low-level action generation uses LLMs to generate and directly control robots' posture or motion. On the other hand, human intervention involves using LLMs to interact with human operators and guide task planning and execution. Table~\ref{tab:table1} shows the list of papers based on those four categories.
\subsection{High-Level Task Allocation and Planning}
High-level task planning leverages LLMs' advanced reasoning and decision-making capabilities to handle complex and strategic tasks. This scenario often requires allocating tasks among robot teams, developing comprehensive task plans, or solving problems requiring contextual understanding and logic. Here, we explore studies illustrating LLMs' capability in these sophisticated domains.

Recent work has demonstrated that LLMs are capable of allocating tasks among multiple robots. Wu \etal~\cite{wu_hierarchical_2024} proposed a hierarchical LLMs framework consisting of two layers to solve the multi-robot multi-target tracking problem. In this scenario, the LLMs assign targets to each robot for tracking based on the current relative positions, velocities, and other relevant information between the robots and targets. As shown in Fig.~\ref{fig:llm_wu}, the outer task LLM receives human instruction and the long horizon information as inputs to provide strategic guidance and reconfiguration to the robot team. Meanwhile, the inner action LLM takes short horizon information as input and outputs control parameters for the controller. The outputs of the two LLMs are transformed into executable actions through the optimization solver.
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{figures/llm.png}
    \caption{The target tracking architecture proposed by Wu \etal~\cite{wu_hierarchical_2024}. The optimization solver acts as the controller for the multi-robot team. The ``Task LLM" is a high-level task planner, while the ``Action LLM" is a mid-level motion planner integrated with the optimization solver.}
    \label{fig:llm_wu}
\end{figure}
In addition, Brienza \etal~\cite{brienza_llcoach_2024} applied VLM and LLM to generate actionable plans for the robotic soccer team. Their approach involved providing the VLM coach with a training set comprising video frames paired with corresponding textual prompts, detailing tasks and constraints. The VLM coach generated schematic descriptions of the video frames along with high-level natural language plans. Two distinct LLMs further refined and synchronized these high-level plans to produce executable strategies suitable for various scenarios. In practical applications, the system selected pre-collected plans based on their similarity to the real-world situation. Additionally, RAG minimizes prompt size and mitigates hallucination, ensuring more reliable outputs. 
Moreover, Lykov \etal~\cite{lykov_llm-mars_2023} developed an MRS to collect and sort colored object sets and count spherical objects. Their approach utilized a fine-tuned LLM to generate Behavior Trees (BTs) for robots to execute tasks and provide feedback to human operators regarding their behaviors. They implemented a single LLM with two LoRA adapters, each handling specific functionalities to enhance efficiency and resource compactness. 
In addition, Ahn \etal~\cite{ahn_vader_2024} introduced an MRS framework featuring a recovery mechanism. The LLM controller received natural language instructions and a library of low-level robot skills to generate plans for task execution. A key innovation in their system was detecting deviations from the expected task progression and performing error recovery by replanning or seeking assistance from other robots or human operators. The remaining studies in this domain can be further categorized into two key areas: multi-robot multi-task coordination and complex task decomposition, highlighting the breadth of LLM applications in MRS.

\subsubsection{Multi-Robot Multi-Task} 
In the multi-robot multi-task scenarios, a team of robots is tasked with completing multiple objectives simultaneously. LLMs play a critical role in devising actionable and efficient task distribution strategies in such settings. By interpreting high-level instructions and understanding the context of each task, LLMs can dynamically allocate tasks among robots, ensuring optimal utilization of resources and effective collaboration. This capability enables multi-robot teams to handle complex, multi-faceted operations with increased precision and adaptability. 

Lakhnati \etal~\cite{lakhnati_exploring_2024} proposed a framework where three heterogeneous robots aim to accomplish complex tasks instructed by human operators in VR simulation. First, each robot LLM is given an initial prompt to clarify its role and abilities. A central controller LLM analyzes human descriptions of the task and distributes them to the respective robots. Instructions from human operators can either directly specify what each robot should do (e.g., ``Jupiter needs to move to the dumbbell and pick it up, Neptune and Pluto have to move to the fridge.") or describe the tasks without assigning to specific robots (e.g., ``Three dinner plates have to be put into the trash, and all agents need to end up next to the garbage bin.").
Following this line, Chen \etal~\cite{chen_emos_2024} proposed a centralized framework where an LLM controller distributes the human instructions to a multi-robot team. They aim to make a heterogeneous multi-robot team accomplish multiple heterogeneous household tasks. However, the task distribution process they introduced is in the form of a discussion between the ``Central Planner" LLM and the robot-dedicated agent LLM on each robot. The original task information is a geometric representation from a SLAM system. It is constructed into a scene context to prompt LLM. The ``Central Planner" LLM first assigns each task to each robot according to its analysis. Then, each robot-dedicated agent LLM provides feedback according to the assigned task, and its robot resume is generated from the robot's URDF code by the robot-dedicated agent LLM. If the task does not match the robot's resume, it prompts the ``Central Planner" for a reassignment. This discussion between LLMs continues until no reassignments are required. 
Chen \etal~\cite{chen_scalable_2024} took a step further to investigate the scalability of an LLM-based heterogeneous multi-task planning system. The efficiency and accuracy of four different communication architectures are compared, as shown in Fig.~\ref{fig:scalable_sec3} under four distinct environments, including BoxNet, warehouse, and BoxLift. The results demonstrate that the HMAS-2 structure achieves the highest success rate while CMAS is the most token-efficient. 
On the other hand, Gupte \etal~\cite{gupte_rebel_2024} proposed an LLM-based framework to solve Initial Task Allocation for a multi-robot multi-human system. In this centralized framework, LLM first generates prescriptive rules for each user's objective and then generates experiences based on those rules for each objective. After acquiring a practical knowledge of the rules generated, the LLM's performance is evaluated by inferencing, where the user provides instructions, and the LLM allocates the task according to the rules and experiences. Two distinct RAG workflows are leveraged in the inferencing stage to use the acquired knowledge fully.
Moreover, Huang \etal~\cite{huang2024words} tested the ability of LLMs to solve the multi-robot Traveling Salesman Problem (TSP). By providing appropriate prompts, the LLM plans the optimal paths for multiple robots and generates Python code to control their movements. The study set up three frameworks: single attempt, self-debugging, where the LLM checks whether the generated Python code can be executed, and self-debugging with self-verification, where the LLM checks code executability and verifies whether the execution produces correct results. Their work reveals that LLMs perform poorly in handling such problems, with higher success rates that can only be observed in specific cases, such as the min-max multi-robot TSP. 

\subsubsection{Complex Task Decomposition}
 Task decomposition refers to scenarios where MRS must collaborate to complete one or more complex tasks that require careful planning and division of labor. In such cases, LLM can be leveraged to break down the overall task into smaller, manageable subtasks that align with the capabilities of each robot in the team. By designing effective prompts, LLMs can generate logical and actionable task decompositions, ensuring that the workload is distributed efficiently and that the robots cooperate seamlessly to achieve the overarching objective.

Kannan \etal~\cite{kannan_smart-llm_2024} introduced \textbf{SMART-LLM}, a framework that utilizes LLMs to decompose high-level human instruction into subtasks and allocate them to heterogeneous robots based on their predefined skill sets. Unlike Chen \etal~\cite{chen_emos_2024}, where robot capabilities are inferred from their URDF code using LLMs, SMART-LLM adopts a more conventional approach by explicitly defining each robot's skill set for heterogeneous task allocation. The process involves decomposing instructions into sub-tasks, analyzing the required skills for each sub-task to form coalitions, and distributing robots accordingly to ensure efficient task execution.
Wang \etal~\cite{wang_dart-llm_2024} propose Dependency-Aware Multi-Robot Task Decomposition and Execution LLMs (\textbf{DART-LLM}), a system designed to address complex task dependencies and parallel execution problems for MRS, as shown in Fig.~\ref{fig:dart-llm}. The framework utilizes LLMs to parse high-level natural language instructions, decompose them into interconnected subtasks, and define their dependencies using a Directed Acyclic Graph (DAG). DART-LLM facilitates logical task allocation and coordination by establishing dependency-aware task sequences, enabling efficient collaboration among robots. Notably, the system demonstrates robustness even with smaller models, such as Llama 3.1 8B, while excelling in handling long-horizon and collaborative tasks. This capability enhances the intelligence and efficiency of MRS in managing complex composite problems. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{figures/Wang_DART_System.pdf}
    \caption{The framework of DART-LLM proposed by Wang \etal~\cite{wang_dart-llm_2024}. The system consists of three modules: Sensor Module, Intelligent Command Interface Module, and Actuation Module. The task decomposition process happens in the Intelligent Command Interface Module.}
    \label{fig:dart-llm}
\end{figure}
Xu \etal~\cite{xu_scaling_2024} proposed a two-step framework that leverages LLMs to translate complex natural language instructions into a hierarchical linear temporal logic (LTL) representation for MRS. In the first step, the LLM decomposes the instruction into a hierarchical task tree, capturing logical and temporal dependencies between subtasks to avoid errors in sequence. In the second step, a fine-tuned LLM translates each subtask into flat LTL formulas, enabling precise execution using off-the-shelf planners. This framework emphasizes the importance of temporal reasoning in decomposing complex instructions, ensuring accurate task allocation and execution for long-horizon and interdependent multi-robot tasks.
In contrast to the abovementioned approaches, Obata \etal~\cite{obata_lip-llm_2024} adopted a slightly different approach and proposed \textbf{LiP-LLM}, a framework integrating LLMs with linear programming for multi-robot task planning. Instead of providing end-to-end task allocation and execution, LiP-LLM utilizes LLMs to generate a skill set and a dependency graph that maps relationships and sequential constraints among tasks. The task allocation is then solved using linear programming to optimize task distribution among robots. This hybrid approach enhances task execution efficiency and success rates by combining LLMs' interpretative capabilities with the precision of optimization techniques. The results demonstrate the potential of integrating LLMs with traditional optimization techniques to improve the performance and coordination of MRS.
On the other hand, Liu \etal~\cite{liu_coherent_2024} proposed the \textbf{COHERENT} framework, which utilizes a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism for task planning in heterogeneous MRS. The PEFA process involves a centralized task assigner LLM that decomposes high-level human instructions into subgoals and assigns them to individual robots. Each robot evaluates the assigned subgoal, determines its feasibility, and provides feedback to the task assigner, enabling dynamic adjustments and iterative refinements in the task plan. This process bears similarities to the robot discussion mechanism in the EMOS framework proposed by Chen \etal~\cite{chen_emos_2024}, where task decomposition and assignment leverage embodiment-aware reasoning based on robot resumes. However, COHERENT emphasizes a real-time, feedback-driven approach to handle task allocation and execution, making it particularly suited for dynamic and complex multi-robot environments.
Differently, Mandi \etal~\cite{mandi_roco_2024} proposed RoCo, a decentralized communication architecture for multi-robot collaboration, focusing on both high-level task planning and low-level motion planning. In the RoCo framework, each robot is equipped with an LLM that engages in dialogue with other robots to discuss and refine task strategies. This dialogue process results in a proposed sub-task plan, which is validated by the environment for feasibility. If the plan fails (e.g., due to collisions or invalid configurations), feedback is incorporated into subsequent dialogues to improve the plan iteratively. Once validated, the sub-task plan generates goal configurations for robot arms, with a centralized motion planner computing collision-free trajectories. RoCo emphasizes flexibility and adaptability in multi-robot collaboration and has been evaluated using the RoCoBench benchmark, demonstrating robust performance across diverse task scenarios. This approach highlights the synergy between decentralized LLM-driven reasoning and centralized motion planning for complex, dynamic environments.

\subsection{Mid-Level Motion Planning}
Mid-level motion planning in MRS encompasses tasks such as navigation and path planning, where the focus lies on enabling robots to traverse or coordinate within an environment efficiently. These scenarios are more direct and practical than high-level applications but critical for multi-robot teams' seamless operation. LLMs contribute significantly to this domain by leveraging their contextual understanding and learned patterns to generate robust and adaptive solutions. By interpreting environmental data and dynamically adapting to changes, LLMs enable robots to collaboratively plan paths, avoid obstacles, and optimize movement within shared spaces. Integrating LLMs into mid-level motion planning enhances efficiency and resilience, making MRS more capable in dynamic and unpredictable environments. 

Yu \etal~\cite{yu_co-navgpt_2023} proposed \textbf{Co-NavGPT} framework to integrate LLMs as a global planner for multi-robot cooperative visual semantic navigation, as shown in Fig.~\ref{fig:Co-NavGPT}. Each robot captures RGB-D vision data, which is converted into semantic maps. These maps are merged and combined with the task instructions and robot states to construct prompts for the LLMs. The LLMs then assign unexplored frontiers to individual robots for efficient target exploration. By leveraging semantic representations, Co-NavGPT enhances the comprehension of the environment and guides collaborative exploration. 
\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{figures/yu_CoNavGPT_Systems.pdf}
    \caption{The framework of Co-NavGPT proposed by Yu \etal~\cite{yu_co-navgpt_2023}.}
    \label{fig:Co-NavGPT}
\end{figure}
In this framework, the LLMs are limited to allocating unexplored frontiers to each robot for navigation, serving primarily as a task allocation mechanism. 
Morad \etal~\cite{morad_language-conditioned_2024} took a step further and proposed a novel framework combining LLMs with offline reinforcement learning (RL) to address path-finding challenges in MRS. Their approach involves leveraging LLMs to translate natural language commands into latent embeddings, which are then encoded with agent observations to create state-task representations. Using offline RL, policies are trained on these representations to generate navigation strategies that understand and follow high-level natural language tasks. A key advantage of this framework is its ability to train policies entirely on real-world data without requiring simulators, ensuring direct applicability to physical robots. The integration of LLMs enhances the flexibility of task instruction interpretation, while RL facilitates the generation of low-latency and reactive control policies, enabling efficient multi-robot navigation.
Following this line, Godfrey \etal~\cite{godfrey_marlin_2024} developed \textbf{MARLIN} (Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation), a framework combining LLMs with Multi-Agent Proximal Policy Optimization (MAPPO) to enhance training efficiency and transparency in multi-robot navigation tasks. In MARLIN, robots equipped with LLMs engage in natural language negotiations to collaboratively generate task plans, which are then used to guide policy training. This hybrid approach dynamically switches between LLM-guided planning and standard MAPPO-based reinforcement learning, leveraging the reasoning capabilities of LLMs to improve training speed and sample efficiency without sacrificing performance. Experimental results demonstrate MARLIN's ability to achieve faster convergence and more consistent performance compared to conventional MARL approaches, with applications validated in both simulation and physical robot environments. This integration of negotiation-based planning highlights the potential of combining LLMs with MARL for scalable, explainable multi-robot coordination.
On the other hand, Garg \etal~\cite{garg_foundation_2024} leveraged LLMs for deadlock resolution in connected multi-robot navigation systems. In obstacle-laden environments, such systems can experience deadlocks that low-level control policies cannot resolve. To address this, the LLM selects a leader robot and plans waypoints for it to reach the target. The system reconfigures into a leader-follower formation, with a GNN-based low-level controller guiding the leader along the waypoints. 
Similarly, Wu \etal~\cite{wu_hierarchical_2024} proposed a mid-level action LLM that uses short-horizon inputs, such as tracking errors and control costs, to generate parameters for an optimization-based robot controller, enabling it to follow planned waypoints effectively.
While the aforementioned research primarily employs centralized systems where LLMs handle planning for all robots, Wu \etal~\cite{wu_camon_2024} developed a decentralized multi-robot navigation system for household tasks. In this framework, each robot is equipped with an LLM to enable communication and collaboration. Robots dynamically recognize and approach target objects distributed across multiple rooms. Leadership is dynamically assigned through a communication-triggered mechanism, with the leader robot issuing orders based on the global information it gathers. This flexible and decentralized leadership strategy enhances adaptability and efficiency in collaborative navigation scenarios.


\subsection{Low-Level Action Generation}
Low-level action generation focuses on controlling robot motion or posture at the hardware level, translating high-level goals into precise control commands. These tasks are critical for ensuring smooth and efficient operations in dynamic environments. While LLMs offer contextual reasoning and adaptability, their performance in low-level tasks, which demand high precision and real-time responsiveness, is often limited compared to traditional control methods. Hybrid approaches, combining LLMs with optimization-based controllers or reinforcement learning, show promise in leveraging LLMs' flexibility while maintaining the precision required for reliable robot actions.

\begin{figure}[tb!]
\centering
    \includegraphics[width=0.85\columnwidth, trim={1cm 4cm 0.6cm 5.6cm},clip]{figures/flock_1.pdf}
    \includegraphics[width=0.85\columnwidth, trim={1cm 4cm 0.6cm 5.6cm},clip]{figures/flock_2.pdf}
    \includegraphics[width=0.85\columnwidth, trim={1cm 4cm 0.6cm 5.6cm},clip]{figures/flock_3.pdf}

    \vspace{2mm}
    \caption{Snapshots of five agents forming a circle~\cite{li_challenges_2024}. The desired distance between each agent is 5 units. The decision of Agent 4's LLM is tracked.}
    \label{fig:Li}
\end{figure}

Chen \etal~\cite{chen_why_2024} leveraged LLMs to address the Multi-Agent Path Finding (MAPF) problem, where LLMs actively navigate robots by generating actions incrementally. Each step concludes with a high-level conflict checker to identify collisions with robots or obstacles. While effective in obstacle-free environments, LLMs face challenges in maze-like maps due to limited reasoning capabilities, restricted context length, and difficulty understanding obstacle locations. Besides path finding, most studies on using LLMs for action generation focus on the problem of formation control. For example, Venkatesh \etal~\cite{venkatesh_zerocap_2024} proposed a centralized architecture where LLMs translate natural language instructions into robotic configurations, enabling swarms to form specific patterns. Despite their strengths as centralized controllers, Li \etal~\cite{li_challenges_2024} highlighted the limitations of LLMs in decentralized systems. In a decentralized setup, each robot operates with its own LLM to achieve a desired formation through coordination with other robots. However, LLMs still face challenges in this task. In a test scenario shown in Fig.~\ref{fig:Li} where agents were tasked with forming a circle with a desired spacing of 5 units, the agent's LLM misinterpreted the instruction, moving to the circle's center instead of the perimeter. This misunderstanding caused the agent to perform consensus-based behavior rather than the intended flocking behavior, revealing the difficulties that LLMs face in this distributed coordination.

Strobel \etal~\cite{strobel_llm2swarm_2024} introduced \textbf{LLM2Swarm}, a system that integrates LLMs with robot swarms through two approaches: centralized controller synthesis and decentralized direct integration. In the centralized approach, LLMs are used to design and validate controllers prior to deployment, enabling efficient and adaptive behavior generation. In the decentralized approach, each robot has its own LLM instance, enabling localized reasoning, planning, and collaboration for enhanced flexibility in dynamic environments. The results highlight the potential of LLMs in swarm robotics, demonstrating their applicability to both centralized and decentralized control paradigms. Lykov \etal~\cite{lykov2024flockgpt} further showcased the potential of LLMs in swarm control with \textbf{FlockGPT}, a framework for orchestrating UAV flocks to achieve desired geometric formations. In this system, the LLM generates a signed distance function (SDF) to guide UAV movements relative to a target surface, while a dedicated control algorithm manages practical constraints such as collision avoidance. These studies underscore the versatility of LLMs in enhancing both centralized and decentralized swarm behaviors.



\subsection{Human Intervention}
In MRS, LLMs typically focus on executing tasks based on human-provided instructions, emphasizing the interpretation of instructions and autonomous task completion. Once the instructions are delivered, human involvement is often minimized. However, emerging research explores scenarios that require continuous interaction between LLMs and humans, emphasizing cooperation, decision-making, or external observation throughout task execution. These studies highlight the potential for dynamic human intervention to address unexpected challenges, refine task strategies, or ensure safety in critical applications. By enabling iterative human-robot collaboration, such approaches enhance the adaptability and reliability of LLM-driven MRS.
The simplest form of human-robot interaction is demonstrated by Lakhnati \etal~\cite{lakhnati_exploring_2024}, where robots operate in a straightforward cycle: receiving a human command, executing the corresponding task, reporting the completion status, and awaiting the next instruction.
Building on this, Lykov \etal~\cite{lykov_llm-mars_2023} introduced the LLM-MARS framework, which enables humans to inquire about each robot's current state and task progress at any time. In this system, both response generation and task execution are handled by a single LLM, enhanced with distinct LoRA adapters for efficiency.
Hunt \etal~\cite{hunt2024conversational} proposed a more interactive approach, requiring human approval before executing any plan generated through LLM-driven discussions. If the proposed plan is deemed unreasonable, the human supervisor can provide feedback, prompting the LLMs to refine their approach through further dialogue.
Ahn \etal~\cite{ahn_vader_2024} introduced the VADER system, further enhancing human involvement. When a robot encounters a task-related issue, it posts a request for assistance on the Human-Robot Fleet Orchestration Service (HRFS), a shared platform accessible to both human operators and robotic agents. Any agent or human can respond to the request, and once the issue is resolved, the robot resumes its task.
These examples illustrate the varying degrees of human involvement in LLM-driven MRS, ranging from simple command execution to active collaboration and dynamic problem-solving.

%%%%%%%%%%%%% Table %%%%%%%%%%%%%%%%%%
% \begin{landscape}
% \begin{sidewaystable}[!ht] 
\begin{table}[!ht]
\centering
% \afterpage{\clearpage}

\makebox[\textwidth]{
% \tiny

\resizebox{1.45\textwidth}{!}{
% \begin{tabular}{@{\hspace{0.5mm}}lcccccc>{\fontsize{4}{1}\selectfont}c@{\hspace{0.5mm}}}
\begin{tabular}{@{\hspace{0.5mm}}lccccccc@{\hspace{0.5mm}}}
\toprule
\textbf{Work} & \textbf{Communication} & \textbf{MRS Type} & \textbf{Modality} & \parbox[c]{1.5cm}{\centering \textbf{Human \\ Intervention}} & \textbf{Evaluation} & \textbf{Application} & \textbf{Model Type} \\
\midrule
\multicolumn{8}{l}{\textbf{High level Task Allocation and Task Planning}} \\
\midrule
Wu \etal~\cite{wu_hierarchical_2024}& Cent & Homo & T &  & Sim(ROS,RViz), Real & Target Tracking & GPT-4o, GPT-3.5 Turbo\\
Brienza \etal~\cite{brienza_llcoach_2024}& Cent & Homo & T, I &  & Sim(SimRobot) & Game & V: GPT-4 Turbo, L: GPT-3.5 Turbo \\
Lykov \etal~\cite{lykov_llm-mars_2023} & Cent & Homo & T, A & \checkmark & Real & General Purpose & Falcon \\
Ahn \etal~\cite{ahn_vader_2024} & Dec & Hetero & T, I & \checkmark & Real & General Purpose & V: CLIP, ViLD, PaLI, L: PaLM \\
Lakhnati \etal~\cite{lakhnati_exploring_2024} & Hier & Hetero & T, A & \checkmark & Sim(VR) & General Purpose & GPT-4\\
Chen \etal~\cite{chen_emos_2024} & Hier & Hetero & T &  & Sim & Household & GPT-4o\\
Chen \etal~\cite{chen_scalable_2024} & Hier & Hetero & T &  & Sim(AI2THOR) & General Purpose & GPT-4, GPT-3.5 Turbo\\
Gupte \etal~\cite{gupte_rebel_2024} & Cent & Hetero & T &  & Sim(GAMA) & General Purpose & -\\
Huang \etal~\cite{huang2024words} & Cent & Homo & T & & Sim & General Purpose & GPT-4 Turbo\\
Kannan \etal~\cite{kannan_smart-llm_2024} & Cent & Homo & T &  & Sim(AI2THOR), Real & Household & GPT-4, GPT-3.5, Llama2, Claude3\\
Wang \etal~\cite{wang_dart-llm_2024} & Cent & Hetero & T, I &  & Sim & Construction & L: Llama-3.1, Claude 3.5, GPT-4o,GPT-3.5 Turbo, V: CLIP\\
Xu \etal~\cite{xu_scaling_2024} & Cent & Homo & T &  & Sim(AI2THOR+ALFRED), Real & Household & Minstral, GPT-4\\
Obata \etal~\cite{obata_lip-llm_2024} & Cent & Hetero & T &  & Sim(ROS) & General Purpose & GPT\\
Liu \etal~\cite{liu_coherent_2024} & Hier & Hetero & T &  & Sim(BEHAVIOR-1K), Real & General Purpose & GPT-4\\
Mandi \etal~\cite{mandi_roco_2024} & Dec & Homo & T &  & Sim,Real & Household & GPT-4\\
Yu \etal~\cite{yu_mhrc_2024} & Dec & Hetero & T &  & Sim(PyBullet) & Household & GPT-3.5 Turbo, GPT-4o, Llama3.1\\
Sueoka \etal~\cite{sueoka_adaptivity_nodate} & Dec & Hetero & T, I &  & Real & Construction & V: GPT-4v, L: GPT-4\\
Hunt \etal~\cite{hunt2024conversational} & Cent & Homo & T & \checkmark & Real & General Purpose & GPT-4\\
Yoshida \etal~\cite{yoshida_verification_nodate} & Dec & Hetero & T, I & & - & General Purpose & - \\
Wang \etal~\cite{wang_safe_2024} & Cent & Hetero & T & \checkmark & Sim(AI2THOR) & General Purpose & GPT-3.5, Llama-2, Llama-3\\
Guzman-Merino \etal~\cite{guzman-merino_llm_2024} & Cent & Hetero & T & & - & General Purpose & GPT-4o\\
\midrule
\multicolumn{8}{l}{\textbf{Mid level Motion Planning}} \\
\midrule
Yu \etal~\cite{yu_co-navgpt_2023} & Cent & Homo & T &  & Sim(HM3D) & Household & GPT-3.5 Turbo\\
Morad \etal~\cite{morad_language-conditioned_2024} & Dec & Homo & T &  & Real & General Purpose & GTE-Based\\
Godfrey \etal~\cite{godfrey_marlin_2024} & Cent & Homo & T &  & Sim, Real & General Purpose & Llama-3.1\\
Garg \etal~\cite{garg_foundation_2024} & Cent & Homo & T, I &  & Sim, Real & General Purpose & V: Claude-3 Sonnet/Opus, GPT-4 Turbo, GPT-4o, L: GPT-4, GPT-3.5, Claude-2, Claude-3\\
Wu \etal~\cite{wu_hierarchical_2024}& Cent & Homo & T &  & Sim(ROS, RViz), Real & Target Tracking & GPT-4o, GPT-3.5 Turbo\\
Wu \etal~\cite{wu_camon_2024} & Dec & Homo & T &  & Sim & Household & GPT-4o\\
\midrule
\multicolumn{8}{l}{\textbf{Low level Action Execution}} \\
\midrule
Chen \etal~\cite{chen_why_2024} & Cent & Homo & T &  & Sim & General Purpose & GPT-4\\
Venkatesh \etal~\cite{venkatesh_zerocap_2024} & Cent & Homo & T, I &  & Sim(Pygame), Real & General Purpose & GPT-4, Llama-2, Claude-3 Opus\\
Li \etal~\cite{li_challenges_2024} & Dec & Homo & T &  & Sim & General Purpose & GPT-3.5 Turbo\\
Strobel \etal~\cite{strobel_llm2swarm_2024} & Dec & Homo & T &  & Sim(ARGoS), Real & General Purpose & GPT-3.5, GPT-4\\
Lykov \etal~\cite{lykov2024flockgpt} & Cent & Homo & T &  & Sim & Formation & GPT-4\\
\bottomrule
\end{tabular}
}
} \vspace{2mm}
\caption{Comparison of LLM-based MRS. Abbreviations: Communication: Cent (Centralized), Dec (Decentralized), Hier (Hierarchical); System: Homo (Homogeneous), Hetero (Heterogeneous); Modal: T (Text), I (Image/Video), A (Audio); Evaluation: Sim (Simulation), Real (Real-world experiments); Model Type: V (VLM), L (LLM).}
% \end{sidewaystable}
\label{tab:table1}

\end{table}
% \end{landscape}