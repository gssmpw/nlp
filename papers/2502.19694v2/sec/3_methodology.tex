\begin{figure*}[ht!]
    \centering
    \includegraphics[width=1.0\textwidth]{figures/bevdiffuser.png}
    \caption{Left: A sketch of common BEV models that generate BEV feature maps from sensor inputs through a BEV encoder. BEV feature maps are usually optimized for downstream task performance. Right: Overview of BEVDiffuser, which consists of a U-Net that predicts the clean BEV features from the noisy ones, conditioned on the ground-truth layout. It is trained on BEV feature maps produced by BEV models with multiple steps of noise added, and is optimized using a joint loss composed of a diffusion loss and a downstream task loss. }
    \label{fig:bevdiffuser}
\end{figure*}

\section{Methodology}
\label{sec:methodology}
\subsection{Preliminary}
\textbf{BEV Model.} Though various types of BEV models have been proposed as we described in Sec.~\ref{sec:bev}, their workflow can be summarized by the sketch shown in Fig.~\ref{fig:bevdiffuser} (Left). First, a BEV encoder is usually designed to generate a BEV feature map given sensor inputs, e.g., cameras \cite{bevformer}, LiDAR \cite{52_yin2021center} or both \cite{liu2023bevfusion}. The produced BEV feature map is then fed into curated task heads to solve downstream tasks, such as 3D object detection. Due to the lack of supervision on the BEV feature map, the BEV feature map is learned indirectly by optimizing the whole model to minimize the task loss $\mathcal{L}_{task}$ and enhance the task performance.

\noindent\textbf{Diffusion Model.} Diffusion model learns to generate data from random noise $\mathcal{N}(\bm{0}, \bm{I})$ by first destroying the structure of a data distribution through gradual addition of noise to the data samples, and then learning a reverse denoising process to restore the data structure. Specifically, given a timestep $t \sim Uniform(\{1, ...,T\})$, it adds $t$-step noise to a data sample $\bm{x}_0$ to get a noisy sample $\bm{x}_t$:
\begin{equation}
    \bm{x}_t = \sqrt{\bar{\alpha_t}}\bm{x_0} + \sqrt{1-\bar{\alpha_t}}\bm{\epsilon}_t,
\end{equation}
\noindent where $\bm{\epsilon}_t \sim \mathcal{N}(\bm{0}, \bm{I})$ and $\bar{\alpha_t}=\prod_{i=1}^{t}(1-\beta_t)$ in which $\beta_t \in (0, 1)$ is a hyperparameter that controls the noise strength. Diffusion model then learns a function $f_\theta(\bm{x}_t, t)$, typically modeled by a U-Net \cite{ronneberger2015u}, to estimate the $\bm{\epsilon}_t$ by minimizing the diffusion loss:
\begin{equation}
    \mathcal{L}_{diffusion} = \mathbb{E}_{\bm{x}_0, \bm{\epsilon}_t,t}\parallel\bm{\epsilon}_t-f_\theta(\bm{x}_t, t)\parallel_2^2.
\end{equation}
\noindent After training, a new data $\bm{x}_0$ can be generated from the random noise $\bm{x}_T\sim\mathcal{N}(\bm{0}, \bm{I})$ through the iterative sampling process, which is formulated as: 
\begin{equation}
\label{eq:iter}
    \bm{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}}(\bm{x}_t -\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha_t}}}\bm{\epsilon}_t) + \sigma_t\bm{z},
\end{equation}
\noindent where $\bm{\epsilon}_t$ is estimated by the learned function $f_\theta(\bm{x}_t, t)$, $\bm{z}\sim\mathcal{N}(\bm{0}, \bm{I})$, and $\sigma_t$ is usually set to $\beta_t$ or scaled form of $\beta_t$.

More recently, to have a control over the denoising process and generate data of interest, conditional diffusion model with classifier-free guidance is often used because of its efficiency \cite{ho2022classifier}. In particular, a condition $y$ is fed into $f_\theta$ with a certain probability during training to get the conditional estimation of the noise $\bm{\epsilon}_t$. During sampling, the noise $\bm{\epsilon}_t$ is estimated by $(1+w)f_\theta(\bm{x}_t, t, y) - wf_\theta(\bm{x}_t, t, y=\phi)$ with the weight $w$ being set to balance the conditional and unconditional estimations.

\subsection{BEVDiffuser with Ground-Truth Guidance}

We introduce BEVDiffuser, a diffusion model denoising BEV feature maps using ground-truth guidance (see Fig.~\ref{fig:bevdiffuser} Right).  Without loss of generality, given a potentially noisy BEV feature map $\bm{x}_{t_0} (0 \leq t_0 \ll T)$ generated by the BEV encoder of any BEV models, we aim to get a denoised BEV feature map $\bm{x}_0$. Following the procedure of standard diffusion model, we learn the function $f_\theta$ to estimate the noise $\bm{\epsilon}_t$ used to form $\bm{x}_t$ under the ground-truth guidance $y$.


\noindent\textbf{Ground-Truth Guidance.} BEV feature map, as its name implies, is expected to provide a holistic top-town view of the environment that clearly presents locations and scales of objects in the environment. To get such desired BEV feature map, inspired by the layout-to-image generation task \cite{zhao2019image,zheng2023layoutdiffusion} that generates images following a specified image layout, i.e. a set of objects annotated with categories and bounding boxes, we formulate our BEV denoising problem as a layout-to-BEV generation task. Particularly, we define the BEV layout $l$ using ground-truth object annotations and condition the function $f_\theta$ on the layout $l$, namely $y=l$.

Formally, we define the BEV layout $l=\{o_0, o_1, ..., o_n\}$ to represent at most $n$ objects in the environment. Each object $o_i (1\leq i \leq n) = \{c_i, b_i\}$ is represented by its category id $c_i \in [0, \mathcal{C}+1]$ and normalized 3D bounding box $b_i \in [0,1]^{d}$. Specifically, $o_0$ is a virtual unit cube that covers the whole environment with $c_0 = 0$ . In case fewer than $n$ objects are present in the environment, we pad the layout with points $o_p$, i.e., empty objects that have no shape or appearance. We define their category id as $c_p =\mathcal{C}+1$, and the 3D bounding box $b_p$ is located at position $(0, 0, 0)$, with size, orientation and velocity are all set to $0$. 

To better fuse the BEV feature map and the layout condition, we adopt LayoutDiffusion model proposed by \cite{zheng2023layoutdiffusion} as the function $f_\theta$. Specifically, a transformer-based layout fusion module is first adopted to fuse the category and bounding box information of each object and model the relationship among them. Then the embedding of the object $o_0$ that contains the information of the entire layout is used for global conditioning. Meanwhile, the embedding of all the objects is fed into an object-aware cross attention mechanism for local conditioning. In this way, the model has better control over all the objects specified in the layout. More details can be found in supplementary materials.


\noindent\textbf{Training.} In the absence of ground-truth BEV feature map $\bm{x}_0$, we add noise $\bm{\hat{\epsilon}}_t$ to the predicted BEV  $\bm{x}_{t_0} (0 \leq t_0 \ll T)$ to get $\bm{x}_t$. In this case, we don't have access to the true noise $\bm{\epsilon}_t$, which is supposed to be added to  $\bm{x}_0$ to generate $\bm{x}_t$. As a result, instead of using $f_\theta$ to estimate the unknown $\bm{\epsilon}_t$, we propose to optimize $f_\theta$ towards $\bm{x}_0$. Since $\bm{x}_{t_0}$ is already a good estimation of $\bm{x}_0$ with bounded task errors, we first optimize $f_\theta$ towards $\bm{x}_{t_0}$ by minimizing the diffusion loss $\mathcal{L}_{diffusion}$ defined in Equation~\ref{eq:loss_diff}. To further improve the estimation accuracy, we attach task heads to consume the outputs of $f_\theta$ and generate task-specific predictions. In this way, $f_\theta$ can also be optimized through the task-specific loss $\mathcal{L}_{task}$. To sum up, we adopt the weighted sum of both losses as the overall loss $\mathcal{L}_{total}^{\scriptscriptstyle diff}$ to train $f_\theta$. Equation~\ref{eq:loss} defines the loss $\mathcal{L}_{total}^{\scriptscriptstyle diff}$ where $\lambda$ denotes a weight.

\begin{equation}
\label{eq:loss_diff}
    \mathcal{L}_{diffusion} = \mathbb{E}_{\bm{x}_{t_0}, \bm{\hat{\epsilon}}_t,t}\parallel\bm{x}_{t_0}-f_\theta(\bm{x}_t, t, y)\parallel_2^2
\end{equation}
\begin{equation}
\label{eq:loss}
    \mathcal{L}_{total}^{\scriptscriptstyle diff} = \mathcal{L}_{diffusion} + \lambda \mathcal{L}_{task}
\end{equation}

\noindent\textbf{Sampling.} We adopt classifier-free guidance in sampling process where we interpolate between conditional and unconditional outputs of $f_\theta$ to get the final estimation of $\bm{x}_0$ as Equation~\ref{eq:x0} calculates. The unconditional estimation of $\bm{x}_0$ is obtained by replacing the conditioning layout $l$ with the empty layout $l_\phi = \{o_0, o_p, ..., o_p\}$ that only contains points $o_p$. We then derive $\bm{\epsilon}_t$ from the estimated $\bm{x}_0$ by Equation~\ref{eq:epsilon} for the iterative sampling process (Equation~\ref{eq:iter}).

\begin{equation}
\label{eq:x0}
    \bm{x}_0 = (1+w)f_\theta(\bm{x}_t, t, y=l) - wf_\theta(\bm{x}_t, t, y=l_\phi)
\end{equation}
\begin{equation}
\label{eq:epsilon}
    \bm{\epsilon}_t = (\bm{x}_t - \sqrt{\bar{\alpha_t}}\bm{x}_0) / \sqrt{1-\bar{\alpha_t}}
\end{equation}

\subsection{Plug-and-Play BEVDiffuser}

BEVDiffuser can be used in a plug-and-play manner. It can be easily plugged into any BEV models during training time without changing their model architectures. During inference time, BEVDiffuser is deactivated and removed, yielding an enhanced BEV model with the same architecture to be deployed. As a result, comparing to the original BEV model, our BEVDiffuser enhanced model provides improved performance without necessitating any adaptation efforts or introducing additional computational overhead.

\begin{figure}[t!]
    \centering
    \includegraphics[width=0.47\textwidth]{figures/plug-and-play.png}
    \caption{BEVDiffuser can be plugged into the training process of a BEV model. It denoises the BEV feature maps produced by existing BEV encoders over $K$ steps and provides the denoised BEV as supervision for BEV predictions.}
    \vspace{-20pt}
    \label{fig:plug-and-play}
\end{figure}

To be specific, as Fig.~\ref{fig:plug-and-play} depicts, given an existing BEV encoder that is originally learned with the task heads through task-specific loss $\mathcal{L}_{task}$, we denote its produced BEV feature map as $\bm{x}^{\scriptscriptstyle BEV}_K$. We adopt the trained BEVDiffuser to denoise $\bm{x}^{\scriptscriptstyle BEV}_K$ for $K$ steps and obtain the denoised BEV feature map $\bm{x}^{\scriptscriptstyle BEV}_0$. To train a new BEV model, we take $\bm{x}^{\scriptscriptstyle BEV}_0$ as a proxy ground truth of BEV and use it to supervise the new predicted BEV feature map $\bm{x}^{\scriptscriptstyle BEV}$ through loss $\mathcal{L}_{BEV}$.  $\mathcal{L}_{BEV}$ is an MSE loss defined in Equation~\ref{eq:loss_bev}. Together with the task-specific loss $\mathcal{L}_{task}$, we train the new BEV model end-to-end through the overall loss $\mathcal{L}_{total}^{\scriptscriptstyle BEV}$ shown in Equation~\ref{eq:loss_total_bev}, where $\lambda_{BEV}$ is a scaling factor.
\begin{equation}
\label{eq:loss_bev}
    \mathcal{L}_{BEV} = \mathbb{E}_{\bm{x}^{\scriptscriptstyle BEV}}\parallel\bm{x}^{\scriptscriptstyle BEV}_0-\bm{x}^{\scriptscriptstyle BEV}\parallel_2^2
\end{equation}
\begin{equation}
\label{eq:loss_total_bev}
    \mathcal{L}_{total}^{\scriptscriptstyle BEV} = \mathcal{L}_{task} + \lambda_{BEV}\mathcal{L}_{BEV}
\end{equation}