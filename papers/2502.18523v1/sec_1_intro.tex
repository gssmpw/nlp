\vspace{-5pt}
\section{Introduction}
\label{sec:intro}
\input{fig_problem}
The human brain, with its billions of interconnected neurons that form the connectome, is the foundation of our cognitive functions and behaviors. Understanding this intricate connectivity is crucial for decoding the brain's mechanisms in development and degeneration. However, accurately mapping the connectome remains a significant challenge due to limitations in current methods. Traditional workflows rely on structural or functional neuroimaging data processed through fragmented steps—brain extraction, registration, segmentation/parcellation, and network generation—often requiring manual quality control, which is costly and represents a critical barrier for quantitative brain biomarkers to enter clinical practice. Furthermore, piecemeal approaches prevent simultaneous optimization of interdependent stages, leading to inefficiencies and limiting the discovery of nuanced connections. Errors introduced in earlier steps propagate through subsequent analyses, resulting in potentially misleading interpretations of brain dynamics. Moreover, the time-intensive nature of these workflows hinders scalability and efficiency. 

Instead of tedious, step-by-step processing for brain imaging data, recent studies support transforming these pipelines into deep neural networks for joint learning and end-to-end optimization \cite{ren2024deepprep, agarwal2022end}. While several approaches have been proposed—such as joint extraction and registration \cite{su2022ernet}, joint registration and parcellation \cite{zhao2021deep, lord2007simultaneous}, and joint network generation and disease prediction \cite{campbell2022dbgsl, mahmood2021deep, kan2022fbnetgen}—there is currently no framework that unifies and simultaneously optimizes all these processing stages to directly create brain networks from raw imaging data. Mapping the connectome of human brain as a brain network (\ie graph), has become one of the most pervasive paradigms in neuroscience \cite{sporns2005human,bargmann2013connectome}. Representing the brain as a graph of nodes (regions) and edges (structural or functional connections) enables gaining critical insights into brain organization, identifying key regions or hubs, and understanding how brain connectivity changes under different conditions (\eg during development, aging, or neurological disorders) \cite{kaiser2011tutorial,crossley2014hubs,xu2015connectome}. This need has intensified with the rapidly advancing imaging technologies and massive data collection.

In this paper, we propose UniBrain, the first end-to-end deep learning model that seamlessly integrates brain extraction, registration, segmentation, parcellation, network generation, and clinical classification into a unified optimization process, as illustrated in Figure~\ref{fig:intro}. Our objective is to investigate the interdependence of these tasks, enabling them to enhance each other's performance while relying on minimal labeled data. Specifically, we leverage low-cost labels (\ie extraction mask, classification label) and a single labeled template (\emph{a.k.a.} atlas) to jointly optimize all tasks. Notably, our approach eliminates the need for instance-level ground-truth labels for registration, segmentation, parcellation, and network connectivity during model training. Extensive experiments on the public ADHD dataset with 3D brain sMRI demonstrate that our method outperforms state-of-the-art approaches across all six tasks.

\vspace{-5pt}
\section{Related Works}
\label{sec:related}
In the literature, related tasks in brain imaging analysis have been extensively studied. Conventional methods primarily focus on designing methods for brain extraction~\cite{kleesiek2016deep,lucena2019convolutional}, registration~\cite{sokooti2017nonrigid, su2022abn}, segmentation~\cite{akkus2017deep, kamnitsas2017efficient, chen2018voxresnet}, parcellation~\cite{thyreau2020learning,lim2022deepparcellation}, network generation~\cite{vskoch2022human, yin2023multi} and classification~\cite{li2021braingnn,kawahara2017brainnetcnn, kan2022brain} separately under supervised settings. However, in brain imaging studies, the collection of voxel-level annotations, transformations between images, and task-specific brain networks often prove to be expensive, as it demands extensive expertise, effort, and time to produce accurate labels, especially for high-dimensional neuroimaging data, \eg 3D MRI. To reduce this high demand for annotations, recent works have utilized automatic extraction tools~\cite{smith2002fast,cox1996afni,shattuck2002brainsuite, segonne2004hybrid}, unsupervised registration models~\cite{balakrishnan2018unsupervised,su2022abn}, inverse warping~\cite{jaderberg2015spatial}, and correlation-based metrics~\cite{liang2012effects} for performing extraction, registration, segmentation, parcellation and network generation. Nevertheless, these pipeline-based approaches frequently rely on manual quality control to correct intermediate results before performing subsequent tasks. Conducting such visual inspections is not only time-consuming and labor-intensive but also suffers from intra- and inter-rater variability, thereby impeding the overall efficiency and performance. More recently, joint extraction and registration~\cite{su2022ernet}, joint registration and segmentation~\cite{xu2019deepatlas}, joint extraction, registration and segmentation~\cite{su2023one}, and joint network generation and classification~\cite{kan2022fbnetgen} have been developed for collective learning. However, partial joint learning overlooks the potential interrelationships among these tasks, which can adversely affect overall performance and limit generalizability. There is a pressing need for more integrated, automated and robust methodologies that can seamlessly integrate and optimize all stages of raw brain imaging-to-graph analysis within a unified framework.
