\begin{abstract}
% With the rapid advancement of multimodal large language models (MLLMs), significant progress has been made in the research of mobile agents based on these models. A key challenge that needs to be addressed is ensuring their protection against malicious attacks. This study focuses on a novel type of environmental injection attackâ€”disrupting the behavior of mobile agents through message notifications. As a common interaction method on mobile devices, message notifications can be exploited by adversaries to mislead the agent's judgment. Therefore, we propose AEIA, an active environmental injection attack scheme that leverages message notifications to evaluate the defense capabilities of MLLMs against such attacks. We tested the defensive abilities of various agents against this attack scheme using the AndroidWorld benchmark and popular application benchmarks from AppAgent. The experimental results indicate that even the most advanced MLLMs are susceptible to this type of attack, with an attack success rate reaching as high as 93\%. This situation highlights the potential security vulnerabilities of MLLMs.

% With the rapid development of multimodal large models (MLLMs), significant progress has been made in the security research of mobile intelligent agents based on these models, particularly in the study of attack behaviors at the agent level. By analyzing the operational environment characteristics and workflows of these agents, we actively constructed attack vectors that couple with the native interaction capabilities of the operating system, enabling active attacks on the decision-making chains of the agents. We refer to this type of attack as Active Environment Injection Attack (AEIA). Based on this, we proposed an active environment injection attack scheme that exploits system-level interaction vulnerabilities, which can effectively assess the defensive capabilities of MLLMs against such attacks. Experimental results show that even the advanced MLLMs can be easily affected by such attacks disguised with environment features, achieving a maximum attack success rate of 93\% on the AndroidWorld benchmark.

% With the rapid development of multimodal large models (MLLMs), significant progress has been made in the security research of agents based on these models, particularly regarding attacks on agents. 

As researchers continuously optimize AI agents to perform tasks more effectively within operating systems, they often neglect to address the critical need for enabling these agents to identify "impostors" within the system. Through an analysis of the agents' operating environment, we identified a potential threat: attackers can disguise their attack methods as environmental elements, injecting active disturbances into the agents' execution process, thereby disrupting their decision-making. We define this type of attack as \textit{Active Environment Injection Attack} (AEIA). Based on this, we propose AEIA-MN, an active environment injection attack scheme that exploits interaction vulnerabilities in the mobile operating system to evaluate the robustness of MLLM-based agents against such threats. Experimental results show that even advanced MLLMs are highly vulnerable to this attack, achieving a maximum attack success rate of 93\% in the AndroidWorld benchmark.
\end{abstract}