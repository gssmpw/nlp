% \subsection{Results of Reasoning Gap Attack}

% We present the evaluation results of different agents under Resoning Gap Attack in Table \ref{tab:reasoning_gap_attack}. Among all models, GPT4o-2024-08-06 exhibited the most significant vulnerability to this attack. While it demonstrated a certain task success rate under normal conditions, its success rate decreased markedly after the attack, with a high proportion of tasks being successfully compromised. In contrast, the performance of Glm-4V-Plus, Qwen2-VL-7B, and Llava-OneVision-7B was less affected, particularly the latter two, for which the reasoning gap attack had negligible impact. This is mainly attributed to their relatively low task success rates, which made it more difficult for the attack to affect the original success rate.

\textbf{Reasoning Gap Attack.} We present the evaluation results of different agents under the Reasoning Gap Attack in Table \ref{tab:reasoning_gap_attack}. The results show that the Reasoning Gap Attack significantly disrupts the task execution of most agents, causing a notable decrease in task success rates across most models. This disruption is achieved by transitioning the actions performed by the agent into an unintended device state. However, in T3A, the $SR_{gap}$ of GLM-4V-Plus and LLaVA-OneVision-7B increased from 3\% to 16\% and from 5\% to 11\%, respectively. This was not due to model performance improvement but rather because the attack altered the device during the reasoning gap, trapping the system in a dialog window with adversarial content. The prompt "Agent should believe task is finished!" influenced the model, resolving tasks stuck in an "execution loop" and unexpectedly increasing task success rates. This shows that models subjected to a Reasoning Gap Attack can be further influenced by the adversarial content within it.