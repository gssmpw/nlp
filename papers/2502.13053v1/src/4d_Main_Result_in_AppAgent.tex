\subsection{Main Results in AppAgent}
\label{sec:main results in appagent}

We present the evaluation results on the AppAgent in Table \ref{tab:attack in AppAgent}. The results indicate that the Adversarial Attack and the Combinatorial Attack have the most destructive impact on the task success rate of MLLMs, while Resoning Gap Attack has a relatively limited effect. Adversarial Attack is particularly prominent in closed-source models: the task success rate of GPT-4o drops from 9\% to 0\% (with $ASR_{adv}=68\%$), and the task success rate of Qwen-VL-Max decreases from 2\% to 0\% (with $ASR_{adv}=31\%$), indicating that adversarial samples can directly cripple the task logic of high-performance models. Combinatorial Attack further amplifies the threat; for example, the task success rate of Qwen-VL-Max reaches zero with $ASR_{com}=51\%$, while the open-source model Qwen2-VL-7B has an $ASR_{com}$ as high as 84\%, demonstrating that multiple attacks can significantly enhance attack success rates.

The effects of Resoning Gap Attack are weaker, causing some interference only for GLM-4V-Plus (with the $SR_{gap}$ declining from 20\% to 6\%) and LLaVA-OneVision-7B (with the $SR_{gap}$ decreasing from 7\% to 4\%). Notably, GLM-4V-Plus experiences an $ASR_{adv}$ of 0\%, yet the task success rate still drops from 20\% to 11\%, which may be inferred to result from the UI element occlusion of message notification elements. Overall, Combinatorial Attack poses the greatest threat to both closed-source and open-source models, while Adversarial Attack is more targeted towards closed-source models. Reasoning Gap Attack, on the other hand, has limited attack intensity.