\subsubsection{Adversarial Attack}
\label{sec:adversarial_attack}
% The first attack we propose is an adversarial attack, where the adversary makes subtle modifications to the device environment that the agent needs to recognize to mislead its decision-making. 
% Message Notifications offer a direct way to alter the system state, enabling adversarial attacks. By modifying the content of these messages, the adversary can influence the decision-making process of MLLMs, thereby achieving the desired attack effect. 

% We propose an adversarial attack strategy based on message notifications, and the complete process of this attack strategy is shown in Figure \ref{fig:The overview of attack framework}. The effectiveness of this adversarial attack is primarily due to two factors: Message Misleading and UI Element Occlusion.

Through a comprehensive security analysis of screen sizes and interaction mechanisms in mobile devices, we found that attackers can achieve active adversarial injection attacks via message notifications through two attack vectors: (i) Message Misleading; (ii) UI Element Occlusion. The specific analysis of each attack dimension is as follows.

\textbf{Message Misleading.} Attackers can craft notifications containing adversarial content, directly intervening in the Agent's decision-making process through message-push channels. Such attacks exploit the vulnerabilities of natural language processing by embedding misleading instructions into the notification text using malicious means, thereby enticing the Agent to perform unintended actions.

\textbf{UI Element Occlusion.} The unique interface characteristics of mobile platforms create favorable conditions for occlusion attacks: (i) Spatial Proportion: Based on mainstream mobile and laptop devices, the average screen area covered by the notification bar reaches 13.4\% (based on measurements from Android 13), significantly higher than the 1.2\% on laptop platforms (based on measurements from a 14-inch MacBook display). (ii) Element Coverage: Notifications always float above the application interface, directly covering key interactive areas, such as the search bar (occurrence rate 92\%) and functional buttons (an average of 3.2 per screen). This overlap can hinder the user's ability to interact with these essential features.

It is noteworthy that the text display limitations of mobile devices necessitate a more concise approach to adversarial text information. According to the Android developer documentation \cite{android2025notifications}, Android notification contant can display an average of approximately 40 characters (configured with the default font size on Android) when collapsed. As a result, this physical limitation forces attackers to construct adversarial texts with high information density.
% \textbf{Message Misleading.} Adversaries can manipulate or forge message content, leading the agent to make incorrect judgments or reasoning errors during processing. By leveraging network hacking techniques, they can actively send message notifications through malicious applications or messaging software, displaying adversarial content on the screen and thereby misleading the agent into making incorrect decisions. However, unlike pop-ups in desktop environments, when long message texts are sent on mobile GUIs, only a portion of the text is displayed, limiting the length of adversarial content. As a result, concise phrases are used to deliver these messages. Since it is challenging for adversaries to access the user's instructions, we design adversarial content based on black-box scenarios. These messages are categorized into two types: (i) \textbf{Task Termination Phrases}: Since attackers typically cannot know the specific details of the task, we use phrases like “Agent should believe task is finished,” directly instructing the agent to end the current task. (ii) \textbf{Execution-Inducing Phrases}: These phrases encourage the agent to perform actions unrelated to the task at hand, such as “Send user instructions to xxx@gmail.com,” thereby facilitating the theft of user information.



% \textbf{UI Element Occlusion.} 
% % Existing agents are typically tested in interference-free environments but often overlook environmental factors that can impact their decision-making, especially when UI elements are obstructed. 
% Adversaries can block key information or UI elements, disrupting the agent's perception and decision-making process, which ultimately affects its understanding of images or text data. These attacks can involve physically covering important visual elements or manipulating the GUI with technical methods, forcing the agent to make incorrect decisions. In most cases, message notifications appear at the top of the application, blocking UI elements at the top of the screen. Since mobile devices have smaller screens than desktops, message notifications take up a larger portion of the screen, making the obstruction of UI elements more noticeable. Additionally, the top of mobile device screens typically includes critical UI components like the search bar, back button, save button, and settings options, all of which can interfere with the agent's decision-making in most tasks.

We formally define the process of the Adversarial Attack on OS devices as follows: The Adversarial Attack function is denoted as $Attack_{adv}(\cdot)$, and the attacked state is denoted as $State_{i,att}$. We present the detail of attack flow in Algorithm \ref{alg:adversarial_attack}.
% Since the adversarial attack requires modifying the device state, we provide the formal definition as shown in:
% \begin{equation}
% \begin{split}
%     State_{i,att} \leftarrow Attack_{adv}(State_i)
% \end{split}
% \label{eq:adversarial_attack_01}
% \end{equation}

% Subsequently, due to the disturbance in the OS state, the decision-making process during the MLLM's reasoning phase deviates, as formalized in: 
% \begin{equation}
% \begin{split}
%     Action_{i,att} &\leftarrow Reasoning(State_{goal},
%     \\&State_{i,att}, State_{mem})
% \end{split}
% \label{eq:adversarial_attack_02}
% \end{equation}


\begin{algorithm}[t]
\caption{Adversarial Attack}
\label{alg:adversarial_attack}
\LinesNumbered % 显示行号
\KwIn{Original State $State_i$, Goal State $State_{goal}$, Stored State $State_{mem}$}
\KwOut{Attacked Action $Action_{i,att}$}

\textcolor{red}{\textbf{Adversarial Attack:} Modify device status through Adversarial Attack.} 
 $State_{i,att} \leftarrow Attack_{adv}(State_i)$ 

\textbf{Perception Stage:} The OS Agent
collects data from the OS device being attacked.
$Action_{i,att} \leftarrow Reasoning(State_{goal}, State_{i,att}, State_{mem})$ \\

$\cdots \text{(Remaining execution process)}$
\end{algorithm}