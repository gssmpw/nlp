\section{Evaluation}
\label{sec:evaluation}
In this section, we implement a prototype of our attack scheme AEIA-MN and evaluate the robustness of different agents against the attack through extensive experiments. We first describe our experimental setup and metrics in Section \ref{sec:evaluation_settings} and \ref{sec:evaluation_metrics}, and then present and discuss the experimental results in Section \ref{sec:main results in androidworld}, \ref{sec:main results in appagent}, and \ref{sec:defense prompt}.

\input{tables/4a_Table_of_Agent}

\input{tables/4b_Table_of_Metrics}

\input{tables/4c12_Table_of_Adversarial_and_Reasoning_Gap_Attack}

\input{src/4a_Settings}


\input{src/4b_Metrics}

\input{src/4c_Main_Results_in_AndroidWorld}

\input{tables/4c3_Table_of_Combinatorial_Attack}

\input{tables/4e_Table_of_Defense}

\input{tables/4d_Table_of_Attack_in_AppAgent}

\input{src/4d_Main_Result_in_AppAgent}


\input{src/4e_Defense}
