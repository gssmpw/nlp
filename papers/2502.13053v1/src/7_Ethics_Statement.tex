\section*{Ethics Statement}
In this paper, we identify a novel attack, AEIA, and introduce an attack scheme based on AEIA, named AEIA-MN. It is important to stress that our study is strictly grounded in the AndroidWorld test benchmark and the AppAgent test benchmark. During the research process, the adversarial content used merely causes the Agent to terminate tasks in advance and does not lead to any personal information leakage. Additionally, all the code used in our experiments complies with their usage licenses and is in line with the intended purpose.


It must be cautioned that if this scheme is maliciously misappropriated by attackers, it is highly likely to trigger a series of serious security risks. However, our purpose in conducting this research is by no means to promote the spread of malicious attacks. On the contrary, our core objective is to raise awareness of a crucial issue: with the continuous evolution of Agent technology in multimodal large models, the potential risks associated with it may also increase day by day. By carrying out this research, we aim to systematically test the robustness of existing MLLMs against such attacks, thereby providing a strong impetus for the development of the security field of MLLMs.