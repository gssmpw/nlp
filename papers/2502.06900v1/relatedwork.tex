\section{Related Work}
UCB, introduced by \citet{auer2002finite}, is fundamental in addressing the exploration-exploitation trade-off in MAB problems, offering theoretical guarantees for minimizing cumulative regret. \citet{kocsis2006bandit} extended UCB to MCTS via the UCT algorithm, which has been key to MCTS's success in perfect information settings. Theoretical exploration of MCTS in non-deterministic and stochastic environments has been limited, with recent studies by \citet{dampower} examining its application in such scenarios.
\newpage
Recent advancements like AlphaZero \citep{silver2017mastering, silver2018general} and AlphaFold \cite{alphafold} have successfully combined deep learning with MCTS in perfect information games, but theoretical guarantees for exploration in complex stochastic or imperfect environments remain underexplored. 
The exploration-exploitation dynamics in stochastic MABs have also been studied by \citet{audibert2009exploration} and \citet{BubeckC12}, influencing our adaptation of UCB for probabilistic transitions. Adaptions of MCTS to stochastic or imperfect information settings have been studied, including PIMC \cite{ginsberg2001gib,long2010understanding} and ISMCTS by \citet{cowling2012information}. Yet, these works lack the theoretical guarantees for stochastic domains provided by our work.
% Recently, \citet{shah2020non} made important contributions by proving polynomial regret concentration bounds for UCT in deterministic settings, but their analysis does not extend to stochastic state transitions.

%