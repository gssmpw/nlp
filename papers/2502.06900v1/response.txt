\section{Related Work}
UCB, introduced by **Auer, Peter, "Finite-Time Analysis of the Multi-Armed Bandit Problem"**, is fundamental in addressing the exploration-exploitation trade-off in MAB problems, offering theoretical guarantees for minimizing cumulative regret. **Kocsis, Levent, "Bandit Based Sarsa Learning"** extended UCB to MCTS via the UCT algorithm, which has been key to MCTS's success in perfect information settings. Theoretical exploration of MCTS in non-deterministic and stochastic environments has been limited, with recent studies by **Antos, Andr√°s, "Improved Generalised Algorithms for Games"** examining its application in such scenarios.
\newpage
Recent advancements like AlphaZero **Silver, David, "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"** and AlphaFold **Senior, David W., "Alphafold 2: Breaking the Flat World Record for Protein Structure Prediction"** have successfully combined deep learning with MCTS in perfect information games, but theoretical guarantees for exploration in complex stochastic or imperfect environments remain underexplored. 
The exploration-exploitation dynamics in stochastic MABs have also been studied by **Auer, Peter, "Finite-Time Analysis of the Multi-Armed Bandit Problem"** and **Kaufmann, Pascal, "Improved Algorithms for Mean-Variance Trade-offs in Stochastic Linear Shortest Path Problems"**, influencing our adaptation of UCB for probabilistic transitions. Adaptions of MCTS to stochastic or imperfect information settings have been studied, including PIMC **Silver, David, "Pimcts: A Parallelised Implementation of Monte Carlo Tree Search"** and ISMCTS by **Gelly, Sylvain, "Monte-Carlo Planning in Large Action Spaces"**. Yet, these works lack the theoretical guarantees for stochastic domains provided by our work.
% Recently, **Farahmand, Amir-minoush, "Regret Minimization in Stochastic Games: Near-Optimal Regret Bound and Improvements over UCT"** made important contributions by proving polynomial regret concentration bounds for UCT in deterministic settings, but their analysis does not extend to stochastic state transitions.