\section{Introduction}
\label{sec:intro}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{fig/intro_fig7.pdf}
    \caption{Examples of the various challenges in RefDrone dataset.}
    \label{fig:intro-figure}
\end{figure}
\input{table/dataset_ann}

Drones/UAVs have become increasingly popular in our daily lives, serving both personal and professional purposes, such as entertainment, package delivery, traffic surveillance, and emergency rescue. Their ability to move freely and their broad observation capabilities make them important platforms for Embodied AI~\cite{fan-etal-2023-aerial, liu2023aerialvln, lee2024citynav, gao2024embodied, liu2024coherent}. A crucial capability in Embodied AI is Referring Expression Comprehension (REC)~\cite{sima2023embodied, Wang_2024_CVPR, cai2024bridging, wang2024polaris}, which serves as a critical bridge between natural language understanding and visual perception. REC requires drones to localize specific objects in images based on natural language expressions. However, existing REC datasets primarily focus on ground-level perspectives, such as the RefCOCO~\cite{refcoco,refcocog} dataset. The application of REC in drone-based scenarios presents unique challenges, including extreme viewpoint variations, occlusions, and scale variations across objects.\par 

In this work, we introduce RefDrone, a challenging benchmark designed for REC in drone scenes. The RefDrone dataset contains 17,900 referring expressions across 8,536 images, comprising 63,679 object instances. As illustrated in Figure~\ref{fig:intro-figure}, RefDrone poses three key challenges that distinguish it from existing datasets: (1) multi-scale and small-scale target detection, with 31\% small objects and 14\% large objects; (2) multi-target and no-target samples, where expressions can refer to any number of objects from 0 to 242; and (3) complex environment with rich contextual expressions. The environmental complexity manifests in varied viewpoints, diverse lighting conditions, and complex backgrounds. The contextual richness is reflected in expressions that describe spatial relations, attributes, and interactive relationships. 



To efficiently construct this comprehensive dataset, we develop RDAgent (referring drone annotation framework with multi-agent system), a semi-automated annotation pipeline. RDAgent restructures traditional annotation workflows into an interactive system of multiple agents and human annotators. In this framework, agents with diverse roles collaborate through feedback loops to generate and verify annotations, while human involvement is minimized to quality control and minor adjustments. RDAgent significantly reduces annotation costs while maintaining high-quality standards for complex expressions, and it can be extended to generate annotations for other REC tasks.\par


Furthermore, we propose a novel method called Number GroundingDINO (NGDINO). Our key insight is that utilizing the number information of referred objects enhances the handling of multi-target and no-target samples. NGDINO comprises three key components: (1) a number prediction head that estimates target object quantities, (2) a set of learnable number-queries encoding numerical patterns across different quantity samples, and (3) a number cross-attention module that integrates number queries with detection queries. Extensive experiments on both our drone-specific RefDrone benchmark and the general-domain gRefCOCO~\cite{grefcoco} dataset reveal that leveraging the number information greatly improves performance on multi-target and no-target samples. \par


In summary, our contributions are listed as follows:
\begin{enumerate}

    \item \textbf{RefDrone Benchmark}: The first comprehensive benchmark for referring expression comprehension in drone scenes. RefDrone poses three key challenges and provides comprehensive baseline evaluations across both specialized models and large multimodal models.

    
    \item \textbf{RDAgent Annotation Framework}: A novel semi-automated annotation framework employs a multi-agent system. RDAgent reduces annotation costs while ensuring high-quality referring expressions.
        
    \item \textbf{NGDINO Method}: A novel method specifically designed to handle multi-target and no-target samples through three components: a number prediction head, learnable number-queries, and number cross-attention. NGDINO achieves superior performance on both RefDrone and gRefCOCO datasets.
    
    
\end{enumerate}

