@misc{arditi2024refusallanguagemodelsmediated,
      title={Refusal in Language Models Is Mediated by a Single Direction}, 
      author={Andy Arditi and Oscar Obeso and Aaquib Syed and Daniel Paleka and Nina Panickssery and Wes Gurnee and Neel Nanda},
      year={2024},
      eprint={2406.11717},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.11717}, 
}

@misc{asai2023selfraglearningretrievegenerate,
      title={Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection}, 
      author={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},
      year={2023},
      eprint={2310.11511},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.11511}, 
}

@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread}
}

@article{elhage2022superposition,
   title={Toy Models of Superposition},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread}
}

@misc{gao2024retrievalaugmentedgenerationlargelanguage,
      title={Retrieval-Augmented Generation for Large Language Models: A Survey}, 
      author={Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Meng Wang and Haofen Wang},
      year={2024},
      eprint={2312.10997},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.10997}, 
}

@misc{gould2023successorheadsrecurringinterpretable,
      title={Successor Heads: Recurring, Interpretable Attention Heads In The Wild}, 
      author={Rhys Gould and Euan Ong and George Ogden and Arthur Conmy},
      year={2023},
      eprint={2312.09230},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.09230}, 
}

@misc{hanna2023doesgpt2computegreaterthan,
      title={How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model}, 
      author={Michael Hanna and Ollie Liu and Alexandre Variengien},
      year={2023},
      eprint={2305.00586},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.00586}, 
}

@misc{huang2024citationkeybuildingresponsible,
      title={Citation: A Key to Building Responsible and Accountable Large Language Models}, 
      author={Jie Huang and Kevin Chen-Chuan Chang},
      year={2024},
      eprint={2307.02185},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.02185}, 
}

@misc{khalifa2024sourceawaretrainingenablesknowledge,
      title={Source-Aware Training Enables Knowledge Attribution in Language Models}, 
      author={Muhammad Khalifa and David Wadden and Emma Strubell and Honglak Lee and Lu Wang and Iz Beltagy and Hao Peng},
      year={2024},
      eprint={2404.01019},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.01019}, 
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}

@misc{li2023surveylargelanguagemodels,
      title={A Survey of Large Language Models Attribution}, 
      author={Dongfang Li and Zetian Sun and Xinshuo Hu and Zhenyu Liu and Ziyang Chen and Baotian Hu and Aiguo Wu and Min Zhang},
      year={2023},
      eprint={2311.03731},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.03731}, 
}

@misc{lieberum2023doescircuitanalysisinterpretability,
      title={Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chinchilla}, 
      author={Tom Lieberum and Matthew Rahtz and János Kramár and Neel Nanda and Geoffrey Irving and Rohin Shah and Vladimir Mikulik},
      year={2023},
      eprint={2307.09458},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.09458}, 
}

@misc{mallen2023trustlanguagemodelsinvestigating,
      title={When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories}, 
      author={Alex Mallen and Akari Asai and Victor Zhong and Rajarshi Das and Daniel Khashabi and Hannaneh Hajishirzi},
      year={2023},
      eprint={2212.10511},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.10511}, 
}

@misc{mcdougall2023copysuppressioncomprehensivelyunderstanding,
      title={Copy Suppression: Comprehensively Understanding an Attention Head}, 
      author={Callum McDougall and Arthur Conmy and Cody Rushing and Thomas McGrath and Neel Nanda},
      year={2023},
      eprint={2310.04625},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.04625}, 
}

@misc{meng2023locatingeditingfactualassociations,
      title={Locating and Editing Factual Associations in GPT}, 
      author={Kevin Meng and David Bau and Alex Andonian and Yonatan Belinkov},
      year={2023},
      eprint={2202.05262},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.05262}, 
}

@misc{prakash2024finetuningenhancesexistingmechanisms,
      title={Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking}, 
      author={Nikhil Prakash and Tamar Rott Shaham and Tal Haklay and Yonatan Belinkov and David Bau},
      year={2024},
      eprint={2402.14811},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.14811}, 
}

@misc{turner2024activationadditionsteeringlanguage,
      title={Activation Addition: Steering Language Models Without Optimization}, 
      author={Alexander Matt Turner and Lisa Thiergart and Gavin Leech and David Udell and Juan J. Vazquez and Ulisse Mini and Monte MacDiarmid},
      year={2024},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.10248}, 
}

@misc{wang2022interpretabilitywildcircuitindirect,
      title={Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small}, 
      author={Kevin Wang and Alexandre Variengien and Arthur Conmy and Buck Shlegeris and Jacob Steinhardt},
      year={2022},
      eprint={2211.00593},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2211.00593}, 
}

@misc{wang2023causalviewentitybias,
      title={A Causal View of Entity Bias in (Large) Language Models}, 
      author={Fei Wang and Wenjie Mo and Yiwei Wang and Wenxuan Zhou and Muhao Chen},
      year={2023},
      eprint={2305.14695},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.14695}, 
}

@misc{wu2024clashevalquantifyingtugofwarllms,
      title={ClashEval: Quantifying the tug-of-war between an LLM's internal prior and external evidence}, 
      author={Kevin Wu and Eric Wu and James Zou},
      year={2024},
      eprint={2404.10198},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.10198}, 
}

@misc{xu2024knowledgeconflictsllmssurvey,
      title={Knowledge Conflicts for LLMs: A Survey}, 
      author={Rongwu Xu and Zehan Qi and Zhijiang Guo and Cunxiang Wang and Hongru Wang and Yue Zhang and Wei Xu},
      year={2024},
      eprint={2403.08319},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.08319}, 
}

@misc{xu2024searchinthechaininteractivelyenhancinglarge,
      title={Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks}, 
      author={Shicheng Xu and Liang Pang and Huawei Shen and Xueqi Cheng and Tat-Seng Chua},
      year={2024},
      eprint={2304.14732},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.14732}, 
}

@misc{ye2024effectivelargelanguagemodel,
      title={Effective Large Language Model Adaptation for Improved Grounding and Citation Generation}, 
      author={Xi Ye and Ruoxi Sun and Sercan O. Arik and Tomas Pfister},
      year={2024},
      eprint={2311.09533},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.09533},
}

@misc{zhang2024knowledgealignmentproblembridging,
      title={The Knowledge Alignment Problem: Bridging Human and External Knowledge for Large Language Models}, 
      author={Shuo Zhang and Liangming Pan and Junzhou Zhao and William Yang Wang},
      year={2024},
      eprint={2305.13669},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.13669}, 
}

@misc{zheng2024promptdrivensafeguardinglargelanguage,
      title={On Prompt-Driven Safeguarding for Large Language Models}, 
      author={Chujie Zheng and Fan Yin and Hao Zhou and Fandong Meng and Jie Zhou and Kai-Wei Chang and Minlie Huang and Nanyun Peng},
      year={2024},
      eprint={2401.18018},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.18018}, 
}

@misc{zou2023representationengineeringtopdownapproach,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.01405}, 
}

