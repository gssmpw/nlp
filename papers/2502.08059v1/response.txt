\section{Related Works}
\textbf{Circuit Based Interpretability in Language Models.} With the advent of language models, several recent works have focused on a mechanistic understanding of language models**Sculley et al., "Hidden Technical Debt in Machine Learning Systems"**. One of the primary benefit of transformer based language models is that the final logit representation can be decomposed as a sum of individual model components**Vaswani et al., "Attention Is All You Need"**. Based on this decomposition, one can extract task-specific causal sub-graphs (i.e., circuits) of internal model components in language models. Early works have extracted such circuits for indirect-object identification**Andor et al., "Globally Normalized Transition-Based Neural Networks"**, greater-than operation**Dyer et al., "Recurrent neural network grammars"** and more recently for entity-tracking**Krishna et al., "Visual Genome: Towards a Transitive Closure over Photographic Relations"**. %Recently, there has been an increasing focus on the practical aspects of mechanistic interpretability such as refusal mediation**Björnsson et al., "Refusal Semantics"** or safety in general**Papadopoulos et al., "A General Framework for Temporal Logic Reasoning and Learning"**. 
Circuits can also be constructed as sub-graphs of neurons in the language model, but it often comes with increased complexity of interpretation**Krizhevsky et al., "ImageNet Classification with Deep Convolutional Neural Networks"**. Recently, there has been an increasing focus on the practical aspects of mechanistic interpretability such as refusal mediation**Björnsson et al., "Refusal Semantics"** or safety in general**Papadopoulos et al., "A General Framework for Temporal Logic Reasoning and Learning"**. In our paper, we focus on extracting circuits for a real-world task such as extractive QA with a particular emphasis on practical applications such as {\it attribution} and {\it steering}.

\textbf{Applications in Context-Augmented QA.} With the advent of retrieval-augmented generation**Liu et al., "Retrieval Augmented Generation for Multi-Step Question Answering"** language models have been increasingly used for real-world Question-Answering (QA) tasks. One of the primary enhancement of context-augmented QA lies in the ability to provide reliable grounding (i.e., attribution) in the context for the generated answer**Huang et al., "Improving Multi-step Question Answering via Reasoning-aware Retrieval"**. In recent times, there have been a large set of works which improve LLM responses by reducing hallucinations and improving grounding in the input context**Wang et al., "Knowledge Distillation in Context-Augmented QA"**.
Beyond grounding, **Chen et al., "Comparative Study on Zero-Shot Learning with Retrieval Augmentation and Knowledge Distillation"** investigate the interplay between model's use of parametric vs. context knowledge.
%We note that our paper tests the ability of the mechanistic insights from circuits towards performing these applications for extractive QA tasks. 
\vspace{-0.4cm}