\section{Related work}
\label{sec:relatedwork}

The integration of machine learning (ML) and deep learning (DL) into robotics \cite{murphy2019introduction} has accelerated the capabilities of autonomous systems across various fields. Particularly within assistive and social robotics, the objective has evolved from simple navigation to enabling safe and interpretable decision-making around people. Early works on ML for robotics primarily focused on object detection and recognition \cite{Pierson2017DeepLI,DLrobotics}, yet more recent efforts leverage DL algorithms to enhance contextual understanding and adaptive navigation. These advancements have led to behavioral AI models capable of dynamically adjusting to complex, changing environments, such as crowded indoor spaces while ensuring user safety.

The concept of explainable AI (XAI) \cite{dwivedi2023explainable,saeed2023explainable,longo2024explainable} has emerged as a necessary framework to improve AI transparency and trustworthiness \cite{kaur2022trustworthy}, particularly in safety-critical applications like social robotics. In this context, several studies propose the use of simulation and validation techniques to evaluate ML models before deployment in real-world scenarios, emphasizing safety and reliability in decision-making \cite{anjomshoae2019explainable,atakishiyev2024explainable}. Additionally, explainability and interpretability enhance user trust, as evidenced in approaches like rule-based reinforcement learning and fuzzy logic systems for robotic risk mitigation, which incorporate predefined standards and probabilistic safety regions to guide exploration while minimizing risk and redundant actions \cite{carlevaro2023probabilistic,10.1007/978-3-031-63803-9_22}.

To address this, topological data analysis (TDA) provides novel tools for examining complex data structures, making it possible to extract and interpret information about the underlying structure of navigational spaces. TDA techniques, such as persistent homology \cite{hatcher2005algebraic,carlsson2020topological,edelsbrunner2022computational}, have been applied to analyze spatial connectivity and the evolving structures within navigation environments \cite{TopMapsRobotNavg,ESTEVE2024101953,TopoNav}, offering a quantifiable approach to characterize 
%the stability of 
spatial and behavioral patterns over time. Persistent entropy \cite{chintakunta2015entropy}, a summarization of persistent homology, quantifies the complexity of topological features over time, and is especially useful in scenarios where robots may need to navigate shared spaces while avoiding collisions and deadlocks to ensure safe and efficient navigations.

Moreover, persistent entropy has demonstrated its effectiveness in a variety of other applications such as characterizing idiotypic immune networks \cite{rucco2016characterisation}, analyzing similarities in piecewise linear functions and time series \cite{rucco2017new}, and separating topological features from noise in Vietoris-Rips complexes \cite{atienza2019persistent}. These successful applications underscore its versatility and potential to provide robust insights across diverse domains.


The integration of TDA into the analysis of robotic systems marks a step forward in developing explainable models for safe navigation. This approach allows us to detect, quantify, and analyze safety regions, focusing on spatial structures formed by robots in motion \cite{lum2013extracting}. By combining TDA with simulated environments, we contribute to the growing field of XAI for robotics by facilitating a more interpretable approach to parameter tuning within navigation models. This directly contributes to improving safety and reliability in socially aware robotic systems, offering the potential for broader applications in real-world, and human-centric environments  \cite{hassija2024interpreting}.