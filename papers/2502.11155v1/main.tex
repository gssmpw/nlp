% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[preprint]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{makecell}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algorithm, algorithmicx}
\usepackage[noend]{algpseudocode}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem*{definition*}{Definition}

\newcommand{\yufei}[1]{{ \color{red} [yufei says ``#1'']}}

\usepackage{todonotes}
\newcommand\todoin[2][]{\todo[inline, caption={2do}, #1]{
\begin{minipage}{\textwidth-4pt}#2\end{minipage}}}


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Uncertainty-Aware Search and Value Models: \\ Mitigating Search Scaling Flaws in LLMs}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Fei Yu, Yingru Li\textsuperscript{$\dagger$}, Benyou Wang\textsuperscript{$\dagger$} \\
  The Chinese University of Hong Kong, Shenzhen, China \\
  yufei21@outlook.com, szrlee@gmail.com,  wangbenyou@cuhk.edu.cn \\
}
% \thanks{Corresponding to Yingru Li and Benyou Wang.}

% \author{%
%   Author A\textsuperscript{\dagger} \\
%   Author B\textsuperscript{\dagger,\ddagger}
% }
% \date{}



%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
\renewcommand{\thefootnote}{$\dagger$}
\footnotetext{Corresponding to Yingru Li and Benyou Wang.}
\renewcommand{\thefootnote}{\arabic{footnote}}

  
\begin{abstract}
Value model-guided search is effective in steering the generation but suffers from scaling flaws: Its superiority diminishes with larger sample sizes, underperforming non-search baselines. This limitation arises from reliability degradation in value models in unseen reasoning paths. To address this, we propose an uncertainty-aware search framework that includes two key components: (1) uncertainty-aware value models that incorporate uncertainty into predictions, and (2) an uncertainty-aware selection process using the proposed efficient Group Thompson Sampling algorithm. Experiments on GSM8K show that our method mitigates search scaling flaws, achieving 90.5\% coverage at 16 samples compared to 85.8\% for conventional value-guided search. This work establishes the first systematic integration of uncertainty quantification in LLM search paradigms.
% ~\footnote{The code will be released after acceptance.}

% \todoin{
% While value model-guided search effectively steers LLM generation, it suffers from diminishing returns at scale - a critical limitation where performance plateaus as computational resources increase. This phenomenon, termed "search scaling flaws," stems from reliability degradation in value models when encountering out-of-distribution reasoning paths. We present an uncertainty-aware framework that fundamentally addresses this limitation through:

% \begin{itemize}
%     \item Uncertainty-quantified value models using our novel Ensemble++ architecture
%     \item Group Thompson Sampling for efficient uncertainty-aware path selection
% \end{itemize}

% Extensive experiments on GSM8K demonstrate our method's ability to maintain scaling effectiveness, achieving 90.5\% coverage at 16 samples compared to 85.8\% for conventional value-guided search. This work establishes the first systematic integration of uncertainty quantification in LLM search paradigms, with implications for resource-efficient reasoning across AI systems.~\footnote{Code release pending acceptance.}
% }
\end{abstract}


\section{Introduction}
\label{sec:intro}

\begin{figure*}[ht]
    \centering
    \subfigbottomskip=-5pt
    \subfigcapskip=-2pt
    \subfigure[\label{fig:scaling_flaws_beam}Scaling Sample Size]{
        \includegraphics[width=0.4\linewidth]{figs/gsm8k_scaling_flaws_beam_uvm.pdf}}
    \subfigure[\label{fig:scaling_flaws_candidate}Scaling Candidate Size]{
        \includegraphics[width=0.4\linewidth]{figs/gsm8k_scaling_flaws_candidate_uvm.pdf}}
    \caption{\label{fig:scaling_flaws}Comparison of scaling laws between OVM-guided search and UVM-guided search. Our proposed uncertainty-aware search framework alleviates search scaling flaws and coverages to higher coverage than the conventional VM-guided search.}
\end{figure*}

Test-time scaling~\cite{RS24, Snell24, wu2024inference} boosts performance significantly on multi-step mathematical reasoning tasks~\cite{GSM8K21,MATH21}. Value Model (VM)-guided search~\cite{OVM23,Wan24} efficiently solves more problems by steering the generation toward more effective reasoning paths.

% \textbf{Test-time scaling} via repeated sampling~\cite{RS24, Snell24, wu2024inference} has recently gained attention to improve LLM performance on multi-step reasoning tasks~\cite{GSM8K21,MATH21}. Research has developed to efficiently solve more problems by steering toward more effective reasoning paths via search~\cite{Snell24, wu2024inference}, e.g. Value Model (VM)-guided search~\cite{OVM23}.
% Research has shown that LLMs can solve more problems by making multiple attempts through repeated sampling~\cite{RS24}. Along this line, search-based methods~\cite{Snell24, wu2024inference}, such as Value Model (VM)-guided search~\cite{OVM23}, have been developed to steer toward more efficient reasoning paths. 

However, a recent study~\cite{yu2025scaling} identifies \textbf{scaling flaws} in conventional VM-guided search: it outperforms repeated sampling (i.e. non-search baseline) at small sample sizes but improves more slowly, leading to inferior performance at larger sample sizes. As shown in Table~\ref{tab:example_coverage}, VM-guided search surpasses repeated sampling at a sample size of 1 (75.4\% v.s. 52.9\%), but loses the superiority as the sample sizes increase to 8 and 16 (85.8\% v.s. 90.8\%).


\begin{table}[h]
\caption{Comparison of coverage on GSM8K: Conventional VM-guided search faces search scaling flaws, underperforming the non-search baseline (repeated sampling). Our proposed uncertainty-aware search effectively enhances the effectiveness of the search scaling.}
\label{tab:example_coverage}
\begin{center}
\setlength{\tabcolsep}{0.8mm}
\scriptsize
\begin{tabular}{@{}l lll@{}}
\toprule
\textit{Sample Size} & 1 & 8 & 16 \\
\midrule
Repeated Sampling & 52.9\% ± 0.6\% & 84.7\% ± 0.8\% & 90.8\% ± 0.1\% \\
VM-Guided Search & 75.4\% ± 0.6\% & \textit{84.0\% ± 0.4\%} & \textit{85.8\% ± 0.3\%} \\
\makecell[l]{Uncertainty-Aware Search \\(Ours)} & 67.8\% ± 0.4\% & \textbf{87.5\% ± 0.6\%} & \textbf{90.5\% ± 0.1\%} \\
\bottomrule
\end{tabular}
\end{center}
\vspace{-0.1in}
% \begin{flushleft}
% \small
% \textit{Note:} VM-guided search faces search scaling flaws, underperforming the non-search baseline (repeated sampling). Our proposed uncertainty-aware search effectively enhances the effectiveness of the search scaling.
% \end{flushleft}
\end{table}


According to~\citet{yu2025scaling}, this issue arises from VM failures during the evaluation and selection of candidates in the search process. When VMs underestimate the values of promising candidates and misidentify them, the selection fails, ultimately leading to search failures.


% According to~\citet{yu2025scaling}, this issue arises from \textbf{VM failures}. VMs, used to evaluate, select and prune candidates during search, rely heavily on training data. When encountering unseen data during inference, VMs may provide unreliable predictions, underestimating the values of promising candidates. This can lead to improper pruning of all promising paths and, ultimately, search failures.


\paragraph{Uncertainty-Aware Modeling}

To mitigate scaling flaws, it is crucial to address unreliable VM predictions at the selection stage. Since VMs rely heavily on training data, they are more likely to provide unreliable predictions when encountering unseen data during inference. This can be addressed by incorporating \textbf{uncertainty} to reflect the reliability of VM evaluations, particularly for candidates underrepresented in the training data. Intuitively, candidates less frequently seen during training have higher uncertainty, indicating lower VM reliability and greater risk of selection failures. 
% Our preliminary studies show that improperly pruned correct paths tend to have higher uncertainty compared to successfully identified ones.

To capture uncertainty and develop \textbf{Uncertainty-Aware Value Models (UVMs)}, we employ Ensemble++ architecture~\cite{hyperagent24,li2024ensemble++} to model value distributions, which encapsulate the inherent uncertainty, with a more dispersed distribution indicating higher uncertainty. The trained UVM allows us to evaluate candidates while accounting for uncertainty by sampling from the value distribution.


% To capture uncertainty and develop \textbf{Uncertainty-Aware Value Models (UVMs)}, we employ Ensemble++~\cite{hyperagent24,li2024ensemble++} to model value distributions, rather than relying on single-point estimates. These distributions encapsulate the uncertainty inherent in each prediction, with a more dispersed distribution indicating higher uncertainty. With a trained UVM, we can sample from the value distribution and evaluate each candidate with an awareness of the associated uncertainty.

\paragraph{Uncertainty-Aware Selection During Search} 
Leveraging the accessibility to uncertainty-aware value distributions, we develop an efficient algorithm for uncertainty-aware candidate selection. We propose the \textbf{Group Thompson Sampling} algorithm, an innovative extension of Thompson Sampling~\cite{thompson1933likelihood, ThompsonTutorial18}. This algorithm selects candidates based on their probability of being the optimal choice within the candidate set, i.e. top-1 probability. This method is effective and remains efficient, without the need for explicit top-1 probability estimation. As shown in Table~\ref{tab:example_coverage} and Figure~\ref{fig:scaling_flaws}, our approach outperforms the conventional VM in search scaling effectiveness.

% Given access to the uncertainty-aware value distribution, we aim to leverage it to perform uncertainty-aware candidate selection. However, the lack of an explicit formalization of the value distribution introduces an efficiency challenge, as we must sample multiple times from the distribution to measure uncertainty. To address this challenge, we propose the \textbf{Group Thompson Sampling} algorithm, which efficiently selects candidates without multiple samples from the value distribution.



% \paragraph{Experimental Results}
% We validate our uncertainty-aware search framework through extensive experiments on GSM8K. The results demonstrate that our method effectively mitigates search scaling flaws. Specifically, while performance of conventional VM-guided search saturates after 20 sampled paths, underperforming the baseline without search, the uncertainty-aware search continues to scale and surpasses the baseline. Ultimately, our uncertainty-aware search converges to 3.4\%-5.0\% higher pass@k over uncertainty-agnostic baselines. Moreover, our method consistently outperforms traditional VM-guided search. For instance, it achieves the same performance as VM-guided search using only 16.2\% of the sampled paths in GSM8K. 

In summary, our \textbf{contributions} are as follows: (1) We introduce an uncertainty-aware search framework that incorporates uncertainty quantification into the selection stages during the search process, enhancing the search scaling effectiveness (2) We develop uncertainty-aware value models, equipping VMs with uncertainty quantification (3) We propose the Group Thompson Sampling algorithm, enabling efficient uncertainty-aware candidate selection.


% \todoin{
% \section{Introduction}
% \label{sec:intro}

% \textbf{The Scaling Paradox in LLM Reasoning:} Modern LLMs achieve remarkable performance on mathematical reasoning through test-time computation scaling~\cite{RS24}. However, as Figure~\ref{fig:scaling_flaws} reveals, conventional value-guided search exhibits a paradoxical behavior - while outperforming naive sampling at low compute budgets (75.4\% vs 52.9\% at 1 sample), it becomes increasingly inefficient as resources grow, ultimately underperforming simple repeated sampling (85.8\% vs 90.8\% at 16 samples).

% \textbf{Architectural Limitations:} We identify the root cause as brittle point estimates in conventional value models (VMs). These models, trained on finite datasets:  
% \begin{itemize}
%     \item Fail to account for epistemic uncertainty in unseen reasoning paths
%     \item Make overconfident predictions leading to premature path pruning
%     \item Lack mechanisms to recover from early-stage prediction errors
% \end{itemize}

% \textbf{Our Uncertainty-Aware Solution:} We bridge this gap through:
% \begin{itemize}
%     \item \textit{Distributional Value Modeling}: Ensemble++ architecture producing uncertainty-quantified predictions
%     \item \textit{Group Thompson Sampling}: Computationally efficient selection leveraging value distributions
% \end{itemize}

% \textbf{Experimental Validation:} Our framework demonstrates:
% \begin{itemize}
%     \item 5.0\% absolute improvement over conventional search at scale
%     \item Robust performance across candidate pool sizes (Figure~\ref{fig:scaling_flaws_candidate})
%     \item Effective mitigation of high-sparsity failures (Section~\ref{sec:analysis})
% \end{itemize}
% }

\section{Background}
\label{sec:background}

This section first defines the problem and introduces the primary solution framework -- search. Then, we introduce outcome value models employed in search, and highlight the issues associated with search and value models.

\paragraph{Problem definition} 
A mathematical reasoning question $q$ requires both the intermediate steps and the final answer as output: The solution path is represented as $S=[s^1, \dots, s^T, a]$, where $s^i$ is the i-th step, $a$ is the answer, and $T$ is the step count.


\paragraph{Search} 
Search explores correct solutions more efficiently by guiding the process towards more effective paths during the generation. This is achieved through alternating generation and selection stages. In each generation stage, $K$ partial path candidates $\mathbb{S}^{(1:t)} = \bigl\{S^{(1:t)}_k \bigl\}_{k=1}^{K}$ are produced, where $S^{(1:t)}_k=[s^1_k,\dots,s^t_k]$ is the $k$-th partial path, and these candidates are then sent to the selection stage. The selection stage then evaluates and selects promising candidates while pruning unpromising ones. The selected candidates are passed to the next generation stage. This process continues until completion. Following~\citet{yu2025scaling}, we adopt the step-level beam search framework in this paper, which parallel explores and finally produces $b$ solution paths. See details in Appendix~\ref{app:beam_search}. 

\paragraph{Scaling flaws} 
Scaling sample size $b$ or candidate size $K$ are expected to handle more problems. However,~\citet{yu2025scaling} observed that search suffers from scaling flaws: (1) the performance increases at a slower rate than the non-search baseline as $b$ grows, ultimately converging to a much lower point (2) the performance remains unimproved and even degrades as $K$ scale. 

These issues stem from the failures in the selection stage, where promising paths among candidates are not identified and are improperly pruned. These arise due to the use of imperfect value models for candidate evaluation~\cite{yu2025scaling}.


\paragraph{OVM and VM failures} 
The Outcome-supervised Value Model~\cite{OVM23} trains a value model to evaluate each candidate by predicting the probability of it reaching a correct answer. Then, it selects candidates with the highest predicted values from the set $\mathbb{S}^{(1:t)}$.

However, imperfect value models may misidentify and incorrectly rank promising paths, which leads to selection failures and search scaling flaws~\cite{yu2025scaling}.

% The training of OVM is conducted on an automatically constructed dataset, eliminating the need for step annotations. Further details can be found in~\ref{app:vm_training}.

\begin{figure*}[t]
% \vskip -0.2in
\begin{center}
\centerline{\includegraphics[width=2\columnwidth]{figs/model_structure.pdf}}
\caption{Illustration of the \textbf{\textcolor[HTML]{E69A55}{UVM}} structure, value learning process, and its relationship to \textbf{\textcolor[HTML]{6FA3EF}{OVM}}: (i) This figure shows how \textbf{\textcolor[HTML]{E69A55}{UVM}} extends \textbf{\textcolor[HTML]{6FA3EF}{OVM}} by adding uncertainty with minimal additional parameters. The blue branch represents \textbf{\textcolor[HTML]{6FA3EF}{OVM}}, which computes a mean value for a sequence. The orange branch introduces the uncertainty term in \textbf{\textcolor[HTML]{E69A55}{UVM}}, calculated using parameters $\mathbf{W}$ and $\mathbf{W}_0$. This uncertainty term varies with the input index $\boldsymbol{\zeta}$, leading to diverse posterior value samples. The process of using \textbf{\textcolor[HTML]{E69A55}{UVM}} is simple: \textbf{\textcolor[HTML]{E69A55}{UVM}} derives a mean value like \textbf{\textcolor[HTML]{6FA3EF}{OVM}}, but also samples from a fixed distribution and adds the uncertainty term. (ii)-(iii) For training, \textbf{\textcolor[HTML]{E69A55}{UVM}} uses the same training set as \textbf{\textcolor[HTML]{6FA3EF}{OVM}}, but samples 2m posterior values $[v_1,\dots,v_{2m}]$ using a discrete coordinate distribution $[\boldsymbol{e}_1,\dots,\boldsymbol{e}_{2m}]$, rather than estimating a single value. The model is trained by averaging the MSE over these posterior samples.}
\label{fig:model_structure}
\end{center}
% \vskip -0.2in
\end{figure*}

\section{Uncertainty-Aware Value Modelling}

In this section, we first explain the motivation for uncertainty-aware value modelling. Then, we describe the technique used to implement the uncertainty-aware value model in Section~\ref{sec:uvm} and how to utilize it in Section~\ref{sec:uvm_sampling}. Finally, we introduce the training process in Section~\ref{sec:value_learning}.


\paragraph{Motivation}
The performance of VMs heavily depends on the training data. Quantifying uncertainty can reveal the sufficiency of similar training data. Specifically, when sufficient similar data is available in training, the VM offers low-uncertainty, reliable predictions during testing. Conversely, scarce similar data leads to high uncertainty and reduced prediction reliability. By quantifying this uncertainty and evaluating candidates in an uncertainty-aware manner, we can make more informed decisions during the search process.


\subsection{Uncertainty-Aware Value Model}
\label{sec:uvm}

\paragraph{Ensemble++} 
Ensemble++~\cite{hyperagent24,li2024ensemble++} is an ensemble-based approach that captures data uncertainty by modelling the posterior distribution. When test data resembles sufficiently seen data, the posterior distribution is concentrated; otherwise, it is more dispersed. This approach is simple to implement, requiring only a learnable linear transformation of the existing representation $\mathbf{x}$. It learns to map a predefined distribution $p_{\boldsymbol{\zeta}}$, like a Gaussian, to the target posterior distribution. 


% When the posterior distribution is more dispersed, the samples show greater variation. 


\paragraph{UVM} 
We borrow Ensemble++~\cite{hyperagent24,li2024ensemble++} to model uncertainty-aware values as illustrated in Figure~\ref{fig:model_structure} (i). There are three processes involved in UVM: (1) representation encoding (2) index sampling (3) index mapping

\textbf{Representation encoding}: The last hidden states from a LLM backbone (parameterized by $\boldsymbol{\theta}$) serve as the representation $\mathbf{x}$. Specifically, for a given question $q$ and a partial path $S^{(1:t)}$, the representation $\mathbf{x}$ is obtained as:
\begin{equation}\label{equa:x}
    % \mathbf{x} = g(q,S^{(1:t)};\boldsymbol{\theta})
    \mathbf{x} = \operatorname{LLM}(q,S^{(1:t)};\boldsymbol{\theta})
\end{equation}

\textbf{Index sampling}: This process samples an index from the predefined distribution, i.e. $\boldsymbol{\zeta}\sim p_{\boldsymbol{\zeta}}$

\textbf{Index mapping}: 
The index is mapped to the posterior value by summing a mean value term and an uncertainty term:~\footnote{For simplicity, we present the main expression and omit the hyperparameters involved in the practical implementation. Details on the practical implementation can be found in~\ref{app:uvm_structure}.}
\begin{equation}\label{equa:v}
v=\underbrace{\mathbf{x}\mathbf{b}}_{\text{mean estimator}}+\underbrace{\mathbf{x}(\mathbf{W}+\mathbf{W}_0)\boldsymbol{\zeta}^T}_{\text{uncertainty estimator}}
    % v=\mathbf{x}(\underbrace{u(\mathbf{W}+p_0\mathbf{W}_0)\boldsymbol{\zeta}^T}_{\text{Beyond OVM}}+\mathbf{b})
\end{equation}

Through these processes, a trained UVM maps the predefined distribution $p_{\boldsymbol{\zeta}}$ to the posterior value distribution $p(v|q,S^{(1:t)})$. 

\paragraph{Additional parameters}
Here, $\mathbf{W}^{d\times m}$ and $\mathbf{b}^{d\times 1}$ are learnable parameters, while $\mathbf{W}_0^{d\times m}$ are frozen parameters that are randomly initialized. $d$ represents the dimension of the backbone's hidden states $\mathbf{x}^{1\times d}$. $m$ is a hyperparameter for the dimension of the index $\boldsymbol{\zeta}^{1\times m}$. Notably, UVM is simple and straightforward to implement on top of OVM, requiring only an additional linear transformation.

\paragraph{UVM architectural insight}  
It extends conventional approaches through a dual-branch architecture, as shown in Figure~\ref{fig:model_structure}:
\begin{itemize}
    \item \textit{Deterministic Branch (blue)}: Maintain standard value estimation, equivalent to OVM
    \item \textit{Uncertainty Branch (orange)}: Learn distribution through ensemble perturbations
\end{itemize}
% This enables efficient uncertainty quantification without costly Monte Carlo sampling - a single forward pass generates both value estimate and uncertainty signature through our novel index projection mechanism.


\paragraph{Intuitive explanation} 
UVM can be regarded as a last-layer ensemble of $m$ components, controlled by the index vector $\boldsymbol{\zeta}^{1\times m}$: (1) When $\boldsymbol{\zeta}^{1\times m}$ is a zero vector $[0,\dots,0]$, UVM retains only the deterministic branch, degenerating to OVM (2) When $\boldsymbol{\zeta}^{1\times m}$ is a one-shot index vector, with a 1 in the $i$-th position and 0s elsewhere, it queries the $i$-th component for the prediction (3) When $\boldsymbol{\zeta}^{1\times m}$ is a non-one-shot vector, it is equivalent to use a linear combination of the $m$ components.


% \begin{itemize}
%     \item A one-shot index vector, with a 1 in the $i$-th position and 0s elsewhere, queries the $i$-th component for the prediction.
%     \item A non-one-shot index vector uses a linear combination of the $m$ components.
%     \item When the index is a zero vector, i.e. $\boldsymbol{\zeta}=[0,\dots,0]$, UVM reduces to $v=\mathbf{x}\mathbf{b}$, equivalent to OVM.
% \end{itemize}


\subsection{Accessing Values}
\label{sec:uvm_sampling}
Although the explicit formalization of $p(v|q,S^{(1:t)})$ is unavailable, we can sample values and compute the distribution's mean and standard deviation.


\paragraph{Sampling from posterior value distribution} 
To derive a posterior value, we (1) sample an index $\boldsymbol{\zeta}\sim p_{\boldsymbol{\zeta}}$ and (2) map it to the value sample $v$ using Equation~\ref{equa:x}-\ref{equa:v}. Notably, deriving multiple posterior values only requires one-time representation encoding, i.e. forward pass through the LLM backbone (Equation~\ref{equa:x}), followed by multiple posterior value mappings (Equation~\ref{equa:v}) with repeated index sampling and mapping.

\paragraph{Capturing the distribution's mean and standard deviation} 
The mean is obtained by using a zero vector as the index $\boldsymbol{\zeta}$ and mapping it. The standard deviation is estimated by sampling multiple posterior values, which involves repeated index sampling and mapping.


\subsection{Uncertainty-Aware Value Learning}
\label{sec:value_learning}

UVM does not require any additional training data and can use the same training dataset as OVM. The training dataset construction is described in Appendix~\ref{app:vm_training}, which consists of $(q, S^{(1:T)}, y)$ tuples, where $y$ denotes the correctness of the final answer.

Given the same training dataset, the key difference in value learning between OVM and UVM lies in their training objectives:

% The key difference in value learning between OVM and UVM lies in their training objectives, despite both models using the same dataset involving $(q,S^{(1:T)},y)$ tuples constructed as described in Appendix~\ref{app:vm_training}.


% \paragraph{Training objective} 
% The objective of uncertainty-aware value learning is to minimize the expected mean squared error over the posterior distribution:
% \begin{equation}
% \mathop{\mathrm{minimize}}\limits_{\boldsymbol{\theta},\mathbf{W}, \mathbf{b}} \sum_{(q,S^{(1:T)},y)}\sum_{t=1}^T\mathbb{E}_{\boldsymbol{\zeta}\sim p_{\boldsymbol{\zeta}}}\left[(f^{UVM}(q,S^{(1:t)},\boldsymbol{\zeta})-y)^2\right]
% \end{equation}
% \todoin{No need to mention this general training objective. no need for (3) (4). (5) with $e_i$ is enough.}

\paragraph{Training loss of OVM} 
OVM learns single-point estimates (Figure~\ref{fig:model_structure} (ii)). Its loss is the Mean Squared Error (MSE) with respect to the binary label $y$, for each $(q,S^{(1:T)},y)$ tuple:
\begin{equation}
    L^{\operatorname{OVM}}(q,S^{(1:T)},y)= \sum_{t=1}^T(\operatorname{OVM}(q,S^{(1:t)})-y)^2
\end{equation}
where $\operatorname{OVM}(\cdot)$ evaluates and maps a given partial path $S^{(1:T)}$ and the question $q$ to a value scalar.


\paragraph{Training loss of UVM}
UVM is learning a posterior value distribution, which complicates its learning (Figure~\ref{fig:model_structure} (iii)). Following Ensemble++~\cite{hyperagent24,li2024ensemble++}, a discrete coordinate distribution is used in training. This distribution consists of $2m$ one-hot index vectors 
$[\boldsymbol{e}_1,\dots,\boldsymbol{e}_m,\boldsymbol{e}_{m+1},\dots,\boldsymbol{e}_{2m}]$. For each $i=1,\dots,m$, the $i$-position of $\boldsymbol{e}_i$ is 1, while of $\boldsymbol{e}_{m+i}$ is -1, with 0s elsewhere.
%$[\boldsymbol{\zeta}_1,\dots,\boldsymbol{\zeta}_m,\boldsymbol{\zeta}_{m+1},\dots,\boldsymbol{\zeta}_{2m}]$
% For each $i=1,\dots,m$, $\boldsymbol{\zeta}_i$ has a 1 in the $i$-th position and 0s elsewhere, while $\boldsymbol{\zeta}_{m+i}$ has a -1 in the $i$-th position and 0s elsewhere.
% as shown below:
% \begin{equation}
% \begin{aligned}
%     \boldsymbol{\zeta}_1=&\;[1,0,\dots,0,0] \\
%     &\dots \\
%     \boldsymbol{\zeta}_m=&\;[0,0,\dots,0,1] \\
%     \boldsymbol{\zeta}_{m+1}=\;&[-1,0,\dots,0,0] \\
%     &\dots \\
%     \boldsymbol{\zeta}_{2m}=\;&[0,0,\dots,0,-1] \\
% \end{aligned}
% \end{equation}
% \todoin{Can be more concise using one-hot basis vector $e_i$.}
The training loss for each $(q,S^{(1:T)},y)$ tuple is
\begin{equation}
    \scriptsize
    L^{\operatorname{UVM}}(q,S^{(1:T)},y)= \sum_{t=1}^T\frac{1}{2m}\sum_{i=1}^{2m}(\operatorname{UVM}(q,S^{(1:t)},\boldsymbol{e}_i)-y)^2
\end{equation}
Notably, the gradients of the term $\mathbf{W}$ are stopped to prevent them from propagating to the backbone parameters $\boldsymbol{\theta}$. 

\paragraph{Explanation on the learning process}
Under this objective, the posterior uncertainty term $\mathbf{W}$ learns to offset the random prior $\mathbf{W}_0$, while the parameters $\mathbf{b}$ focus on modeling the mean of the posterior distribution. When posterior learning is sufficient, the posterior uncertainty term $\mathbf{W}$ reduces the noise introduced by the prior $\mathbf{W}_0$, leading to a low-variance posterior distribution. If learning is insufficient, the prior $\mathbf{W}_0$ dominates, causing a high-variance posterior distribution.



\section{Uncertainty-Aware Selection}

This section describes (1) the implementation of posterior value sampling during inference and (2) uncertainty-aware selection with the accessibility to the posterior value distribution. We propose a novel algorithm, Group Thompson Sampling, to effectively and efficiently select multiple candidates.


\paragraph{Posterior value sampling of UVM during inference}
Following Ensemble++~\cite{hyperagent24,li2024ensemble++}, a $m$-dimensional continuous Gaussian distribution is used as the index distribution $p_{\boldsymbol{\zeta}}$ to access the expressive posterior value distribution during inference, as described in Section~\ref{sec:uvm_sampling}. Intuitively, we are training $m$ individual components during value learning, and then combine them linearly to make predictions during inference.


\paragraph{Top-1 probability for candidate selection} 
For each step $t$, we evaluate and rank $K$ candidates in the set $\mathbb{S}^{(1:t)}$ based on their posterior value distribution. Specifically, we assess the probability of each candidate being the best, i.e. the likelihood of it having the highest value, within the set, referred to as the top-1 probability
\begin{equation}\label{equa:top1_prob}
\small
\begin{aligned}
    &p(S_i^{(1:t)} \text{ is the best among }\mathbb{S}^{(1:t)}) \\
    &=\mathbb{E}_{v_i\sim p (v|q,S_i^{(1:t)}),v_j\sim p(v|q,S_j^{(1:t)}) \ \forall j \neq i} \left[ \prod_{j \neq i} \mathbb{I}(v_i \ge v_j ) \right]
\end{aligned}
\end{equation} 
We perform candidate selection by sampling from the top-1 probability distribution
\begin{equation}
    S^{(1:t)}\sim p(S^{(1:t)}\text{ is the best among }\mathbb{S}^{(1:t)})
\end{equation}

We use top-1 probability for candidate selection instead of the well-known Upper Confidence Bound (UCB)~\footnote{UCB scores each candidate using the sum of an exploitation term and an exploration term, i.e. the sum of mean values and standard variation in our case.} for two main reasons: 
\begin{itemize}
    \item \textit{Top-1 probability better captures the distribution's characteristics, balancing mean and variance}. In candidate selection, it is important to balance the predicted mean value with the uncertainty (i.e., the distribution's variance). Candidates with extreme uncertainty will be prioritized by UCB, potentially overlooking the mean value prediction in such cases. In contrast, top-1 probability provides a more balanced approach that not overemphasizes uncertainty. 
    \item \textit{Top-1 probability inherently ranks candidates against each other}. UCB evaluates each candidate independently, without considering its relation to others. In contrast, top-1 probability intrinsically compares each candidate to all others in the set, ranking them based on the likelihood of being the best in the set. 
\end{itemize}
However, explicitly estimating the top-1 probability for each candidate requires multiple posterior value samples, which involves repeated index sampling and mapping. This process can be computationally expensive.


\paragraph{Group Thompson Sampling: An efficient algorithm for group selection based on top-1 probability} 
Group Thompson Sampling is an extension of the Thompson sampling algorithm, designed to efficiently select a group of candidates based on their top-1 probability. Thompson sampling~\cite{thompson1933likelihood,ThompsonTutorial18} is a straightforward method for selecting a single candidate, by performing one posterior sampling and choosing the one with the highest sampled value
\begin{equation}
\begin{aligned}
    v_i\sim p(v|q,S_i^{(1:t)}),\forall i \\
    S_i^{(1:t)}=\mathop{\mathrm{argmax}}\limits_{i} v_i
\end{aligned}
\end{equation}
To extend this for selecting multiple candidates, we introduce Group Thompson Sampling algorithm in Algorithm~\ref{algo:group_thompson}. This method repeats Thompson sampling $b$ times to select $b$ candidates, incorporating a mechanism to avoid duplication.



\begin{algorithm}[h]
\small
\caption{\label{algo:group_thompson} \textbf{Group Thompson Sampling}}

\begin{algorithmic}[1]
\Statex $\textbf{Input:}$ Question $q$, candidates $\{S_1,\dots,S_K\}$, sample size $b$
\Statex $\textbf{Output:}$ $b$ selected candidates
\Statex $\textbf{Model:}$ $\operatorname{UVM}$
\Statex $\textbf{Hyperparameter:}$ Maximum tries $T^{max}$
\State Sample index $\xi\sim p_\xi$ and select $i=\mathop{\mathrm{argmax}}\limits_{i=1,\dots,K} \;\operatorname{UVM}(S_i;q,\xi)$
\State Initialize selected set $\mathcal{I} \gets \{i\}$
\Repeat
    \State Sample $\xi\sim p_\xi$ and select $i=\mathop{\mathrm{argmax}}\limits_{i=1,\dots,K} \;\operatorname{UVM}(S_i;q,\xi)$ \label{line:repeat}
    \State Add $i$ to $\mathcal{I}$ if $i\notin\mathcal{I}$; otherwise try~\ref{line:repeat} again
    \State After $T^{max}$ tries, instead sample non-repeated $i$ uniformly
\Until{there are $b$ selected candidates}
\Statex \Return $\{S_i|i\in\mathcal{I}\}$
\end{algorithmic}
\end{algorithm}

\paragraph{Algorithmic innovation}
Group Thompson Sampling addresses two key challenges in uncertainty-aware search:
\begin{itemize}
    \item \textit{Computational efficiency}: Avoid explicit top-1 probability estimation through smart sampling
    \item \textit{Comprehensive selection range}: Ensure that candidates with varying levels of uncertainty are appropriately considered for selection through an uncertainty-aware stochastic selection mechanism
\end{itemize}


\section{Experiment Results}
This section outlines our experiment settings and presents the results of overall performance and ablation studies.


\subsection{Experimental Settings}

\paragraph{Benchmarks and models} 
We conduct experiments on GSM8K~\cite{GSM8K21} using Mistral 7B~\cite{Mistral7B-23}. We use the official training split and test split for all the experiments.

\paragraph{Baselines} 
We compare our method, UVM-guided search, with two baselines: (1) repeated sampling, which directly samples multiple solution paths without any search mechanism, and (2) conventional OVM-guided search, which does not incorporate uncertainty.


\paragraph{Evaluation} 
Following the study of search scaling flaws~\cite{yu2025scaling}, we evaluate our method using coverage -- the fraction of problems whose correct solutions for which the correct solution is covered by the generated paths, i.e., at least one sampled path is correct. This metric is also referred to as pass@k, where $k$ denotes the number of generated paths.~\footnote{In our paper, $K$ represents the candidate size during the intermediate search process, rather than the number of final produced paths. To avoid confusion, we use the term ``coverage''.}

\paragraph{Scaling beam search} 
~\citet{yu2025scaling} observes scaling flaws related to both sample sizes and candidate sizes. We also investigate the effectiveness of our methods on with respect to these two factors:

\textbf{Sample size}: 
This refers to the number of complete solution paths generated by the algorithm. For beam search, it corresponds to the beam size $b$, while for repeated sampling, it is the number of attempts. We consider sample sizes of 1, 2, 4, 8, 16, and 32. For beam search experiments, we fix the number of generated paths per beam $K/b$ at 8.

\textbf{Candidate size}: 
This represents the number of candidates considered during the search process. In these experiments, we fix the sample size at 16, where OVM-guided search underperforms repeated sampling. We conduct experiments with candidate sizes of 32, 64, 128, and 256.

Each experiment is repeated three times, and we report the average coverage along with its standard deviation.


\subsection{Implementation}
\paragraph{Training generators} 
We train the base models (i.e. Mistral 7B) on the official training set. We use the newline character as the marker for the end of each step. Supervised fine-tuning is performed for 2 epochs with a batch size of 128. We use a linear learning rate scheduler with a maximum learning rate of 2e-6. The AdamW optimizer~\cite{AdamW19} is used for training. 


\paragraph{Building training dataset for UVMs} 
The dataset construction process is introduced in Appendix~\ref{app:vm_training}. We sample 50 solution paths per problem in the training set. We use a decoding temperature of 0.7 and top-k set to 50 for dataset collection. The maximum new token length is 400. We apply vllm~\cite{VLLM23} to accelerate the generation process. 


\paragraph{Training UVMs/OVMs} To construct UVMs, we set the number of components to 10. UVMs are initialized from the corresponding generator checkpoints and trained for one epoch, using the same backbone learning rate scheduler. The maximum learning rate for the uncertainty-aware value head is set to 2e-3, with a batch size of 128. The optimizer used for training is AdamW. After training, we derive OVMs by setting $\boldsymbol{\zeta}=\mathbf{0}$.



\paragraph{Step-level beam search} 
The hyperparameters for decoding are consistent with those used in the UVMs' training dataset collection. The maximum number of steps is 10. 



\subsection{Overall Performance}

We present the overall performance in Figure~\ref{fig:scaling_flaws}, showing that UVM-guided search consistently outperforms conventional OVM-guided search both when scaling sample sizes and scaling candidate sizes.

\paragraph{Scaling flaws} 
\textit{UVM-guided search mitigates the scaling flaws of conventional VM-guided search}. 
As shown in Figure~\ref{fig:scaling_flaws_beam}, VM-guided search leads to over 20\% higher coverage than repeated sampling when the sample size is 1. However, its advantage diminishes as the sample size scales to 8. In contrast, our UVM-guided search continues to outperform repeated sampling at this sample size and remains comparable even at a sample size of 16. 

Moreover, as shown in Figure~\ref{fig:scaling_flaws_candidate}, the performance of conventional VM-guided search deteriorates significantly as the candidate size scales. In contrast, UVM-guided search efficiently mitigates this issue, resulting in a 5.5\% performance improvement over VM-guided search at the largest tested candidate size, 256.


\paragraph{Convergent points of coverage} 
\textit{UVM-guided search ultimately converges to higher coverage than conventional VM-guided search}. 
As illustrated in Figure~\ref{fig:scaling_flaws_beam}, UVM-guided search outperforms conventional VM-guided search once the sample size increases to 4. It reaches the performance comparable to the best result of conventional VM-guided search (among all tested sample sizes) using only 25\% of its budget. Furthermore, it ultimately achieves 4.2\% higher coverage at the largest tested sample size, 32.

These results highlight the effectiveness of our method in enhancing search scaling.



\subsection{Ablation Study}
In this section, we conduct ablation studies on the design choices of uncertainty-aware selection and demonstrate the superiority of the Group Thompson Sampling algorithm in Figure~\ref{fig:uncertainty_ablation}.

\paragraph{Baselines} We consider two deterministic baselines for uncertainty-aware selection: UCB ranking and the naive top-1 probability ranking.

\textbf{UCB ranking}: UCB scores each candidate by summing the mean and standard deviation of the posterior value distribution, which are computed using 100,000 sampled posterior values. Then, candidates with the highest UCB scores are selected.

\textbf{Naive top-1 probability ranking}: This method explicitly calculates the probability of each candidate being the best, as described in Equation~\ref{equa:top1_prob}, using 100,000 sampled posterior values. It ranks and selects candidates based on the highest probabilities, rather than sampling from the probability distribution.

% \textbf{OVM + softmax (stochastic)}: This method introduces the randomness into OVM-guided search by applying the softmax function to the OVM-predicted scores and sampling from the resulting distribution. Higher temperatures reduce the reliance on OVM-predicted scores.

\paragraph{Top-1 probability ranking v.s. UCB ranking} 
\textit{Top-1 probability is better for candidate evaluation}. 
As shown in Figure~\ref{fig:uncertainty_ablation}, UCB ranking performs poorly, even underperforming the conventional OVM baseline. In contrast, the top-1 probability ranking surpasses the UCB, highlighting the effectiveness of using top-1 probability for candidate evaluation.


\paragraph{Group Thompson Sampling v.s. top-1 probability ranking} 
\textit{Group Thompson Sampling is an effective algorithm for uncertainty-aware selection}. 
As illustrated in Figure~\ref{fig:uncertainty_ablation}, our proposed Group Thompson Sampling algorithm achieves higher coverage than the naive top-1 probability ranking. Furthermore, by sampling candidates according to the underlying top-1 probability distribution, Group Thompson Sampling eliminates the need for explicit top-1 probability estimation, making it more efficient.

These results show the superiority of our Group Thompson Sampling algorithm: It achieves significantly higher coverage than the other baselines while requiring fewer computations.



\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=0.9\columnwidth]{figs/gsm8k_uvm_ablation.pdf}}
\caption{Ablation on design choices of uncertainty-aware selection}
\label{fig:uncertainty_ablation}
\end{center}
\end{figure}

% \paragraph{Stochastic selection} 
% \textit{Incorporating uncertainty measurement is stronger than simply introducing randomness into the naive value estimation}. 
% As shown in Figure~\ref{fig:stochastic}, introducing randomness into OVM selection could lead to higher coverage when sample sizes become large. However, this method underperforms our proposed algorithm. This suggests that 



% \begin{figure*}[ht]
%     \centering
%     \subfigbottomskip=-5pt
%     \subfigcapskip=-2pt
%     \subfigure[\label{fig:uncertainty_ablation}]{
%         \includegraphics[width=0.4\linewidth]{figs/gsm8k_uvm_ablation.pdf}}
%     \subfigure[\label{fig:stochastic}]{
%         \includegraphics[width=0.4\linewidth]{figs/gsm8k_uvm_stochastic.pdf}}
%     \caption{\label{fig:ablation}Ablation on design choices of uncertainty-aware selection: (a) Compare with two deterministic selection algorithms, i.e. ranking with explicit top-1 probability estimation or UCB (b) Compare with stochastic selection based on OVM-predicted scores}
% \end{figure*}


\section{Analysis}

In this section, we conduct in-depth analyses of VM selection failures, which are the underlying causes of search scaling flaws~\cite{yu2025scaling}. Specifically, we investigate the effectiveness of UVM in mitigating selection failures across various sparsity of correct paths among candidates.

\paragraph{Selection stages} 
We define a selection stage as comprising three key components: (1) the candidate set (2) the evaluation scores assigned to each candidate (3) the selected candidates from the set. 

The presence of correct paths within the candidate set depends on the quality of candidates generated during the generation stage. In this section, we focus on the effectiveness of the selection stages and exclude issues related to the generation stages. Therefore, we only consider those selection stages where correct paths are present within the candidate set.


\paragraph{Selection failures}
When correct paths are present in the candidate set, a selection failure is identified if none of the correct paths are selected.

In this section, we analyze the distribution of selection failures and compare the effectiveness of UVM and OVM across various scenarios.


\paragraph{Experimental Setup}

We extract all selection stages during the OVM-guided search with $b=8, K=64$, as this setup begins to experience scaling issues while retaining a reasonable computational cost for correct path labeling and target selection stage identification.

\textbf{Correct path labeling} 
To identify the correct candidate paths, we complete each partial path by rolling out 4 samples and checking whether any of them reach the correct answer. A candidate is deemed a correct path if at least one of its rollouts leads to the correct final answer.

\textbf{Target selection stage identification} 
Given the correctness of all candidate paths across all selection stages, we can filter all the selection stages where correct paths are available among the candidate set for the subsequent studies.



\paragraph{Analysis on Correct Path Sparsity} 
\emph{Correct path sparsity} refers to the fraction of correct paths within the candidate set. As sparsity increases—i.e., fewer correct paths are present among the candidates—identifying the correct paths becomes more challenging for VMs~\cite{yu2025scaling}.

Similar to the analysis in~\citet{yu2025scaling}, we categorize the correct path sparsity of all targeted selection stages (where correct paths are available) into three uniform groups. We then apply both OVM and UVM selection to the candidate sets within these stages. Then we plot the distribution of selection failures, where no correct path is identified, across the three sparsity groups in Figure~\ref{fig:frac_valid_path}.

\textit{UVM is effective across all correct path sparsity groups}. 
As shown in Figure~\ref{fig:frac_valid_path}, UVM consistently reduces the frequency of selection failures across all sparsity groups. Specifically, it reduces selection failures by 6\% in the low-sparsity group, 6\% in the medium-sparsity group, and 14\% in the high-sparsity group. 

\textit{UVM is most effective in high-sparsity regimes}.
Notably, although higher correct path sparsity increases the difficulty of the selection task, UVM continues to perform well, and even offers greater benefits in reducing selection failures in high-sparsity regimes (14\% failure reduction). This demonstrates its ability to retain high-uncertainty yet potentially correct paths that conventional models would typically discard prematurely.



% \todoin{
% \paragraph{Uncertainty-Value Correlation}  
% Figure~\ref{fig:frac_valid_path} reveals an inverse relationship between path sparsity and selection success. Our UVM's superior performance in high-sparsity regimes (14\% failure reduction) confirms its ability to detect and preserve low-confidence but potentially correct paths that conventional models prematurely discard.
% }

\begin{figure}[ht]
\begin{center}
\centerline{\includegraphics[width=0.9\columnwidth]{figs/gsm8k_frac_valid_path_distribution_mistral_uvm.pdf}}
\caption{Comparison of failures frequency between OVM selection and UVM selection, across various correct path sparsity}
\label{fig:frac_valid_path}
\end{center}
\end{figure}



% \subsection{Analysis on Uncertainty Levels}
% In this subsection, we investigate the effectiveness of UVM across varying levels of uncertainty.

% We measure the \emph{uncertainty} as the dispersiveness of the value distribution, specifically the variance of sampled posterior values. As uncertainty increases, the reliability of VM predictions decreases. Similar to the previous subsection, we categorize the uncertainty of all targeted selection stages into three uniform groups and apply both OVM and UVM selection to these groups.

% \textit{UVM is effective across all uncertainty levels, though its effectiveness diminishes as uncertainty increases}. 
% As shown in Figure~\ref{fig:uncertainty_level}, UVM consistently reduces the selection failures across all uncertainty levels. Specifically, it reduces selection failures by 11\% at low uncertainty, 7\% at medium uncertainty, and 4\% at high uncertainty. Notably, the advantage of UVM diminishes as the uncertainty level increases. This aligns with the intuition that while higher uncertainty reflects lower reliability in VM predictions, uncertainty alone cannot guarantee correct predictions. 


% \begin{figure}[ht]
% \begin{center}
% \centerline{\includegraphics[width=0.9\columnwidth]{figs/gsm8k_uncertainty_distribution_mistral_uvm.pdf}}
% \caption{Comparison of failures frequency between OVM selection and UVM selection, across various uncertainty levels}
% \label{fig:uncertainty_level}
% \end{center}
% \end{figure}



% \section{Related Work}

% \textbf{Uncertainty Quantification in LLMs:}
% The quantification of current uncertainty in deep neural networks is primarily based on methods such as Bayesian neural networks and deep ensembles \cite{lakshminarayanan2017simple, osband2023epistemic}. These approaches effectively estimate uncertainty in classification tasks but face limitations in the context of open-ended language generation. Techniques like information-theoretic metrics, iterative prompting \cite{yadkori2024believe}, and conformal prediction \cite{ye2024benchmarking} have advanced uncertainty estimation in multiple-choice scenarios but struggle with open-ended outputs.

% \textbf{Uncertainty-aware Selections in LLMs:}

% Recent studies show that increasing test-time computation, such as through repeated sampling, can significantly improve reasoning performance in LLMs. Repeated sampling has been shown to scale coverage (pass@k), allowing smaller models to outperform larger ones in some cases.

% Building on this, search-based approaches have emerged to guide computation toward more effective reasoning paths. These methods narrow down possible solutions by selecting the most promising candidates based on a scoring mechanism. Search algorithms typically rely on score models, such as value models, reward models, and advantage models, to evaluate the quality of reasoning paths.

% Despite their potential, current search methods struggle as computation scales. The involved score models may fail to identify high-quality paths accurately, leading to improper pruning due to imbalanced training data or limited exposure to diverse data. As a result, the effectiveness of current search-based methods diminishes as sample sizes grow, limiting their scalability.

\section{Discussion}

Quantifying uncertainty in current search-based methods has several practical implications for LLM reasoning tasks as follows: (1) \textit{Discovering correct solutions}: Correct solutions may lie along paths that are underrepresented in the training data. By incorporating uncertainty, our approach increases the likelihood of discovering these solutions. (2) \textit{Improved performance with limited resources}: Uncertainty-aware search methods enhance performance without a significant increase in computational resources. This is because the process of quantifying uncertainty is computationally inexpensive. (3) \textit{Adaptability to real-world applications}: Real-world applications often encounter out-of-distribution data. Methods that account for uncertainty are better equipped to handle such cases, enabling more reliable performance in deployment scenarios where the data may differ from training distributions.


\section{Conclusion}

VM-guided search suffers from search scaling flaws due to the use of imperfect VMs, which could produce unreliable predictions when the evaluated data is underrepresented in the training data. To address these issues, we propose an uncertainty-aware search framework, including training uncertainty-aware VMs and applying uncertainty-aware selection during the search. Experiment results in GSM8K show the effectiveness of our methods.

\section*{Limitation}
While uncertainty can indicate the reliability of VM predictions, it alone cannot guarantee correct predictions. This highlights that, although uncertainty can be useful, effective selection still heavily depends on the performance of the VMs. In scenarios where VMs perform poorly, such as in the more challenging MATH dataset~\cite{MATH21}, uncertainty alone offers limited assistance and proves ineffective. In such scenarios, improving the quality of the VMs should be prioritized over merely equipping them with uncertainty qualifications. Besides, uncertainty does not fully capture the accuracy of value predictions. It is possible for a low-uncertainty prediction to still be incorrect, a scenario that is not addressed in this paper.


% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{anthology,custom}
% Custom bibliography entries only
\bibliography{custom}

\newpage
\appendix


\section{Appendix}
\label{sec:appendix}

\begin{table}[h]
\centering
\caption{Summary of Notations Used in the Paper}
\resizebox{0.45\textwidth}{!}{%
\begin{tabular}{cl}
\toprule
\textbf{Notation} & \textbf{Description} \\ 
\midrule
$q$ & Mathematical reasoning question requiring a sequence of steps \\
$S$ & Solution path for a question, $S=[s^1, \dots, s^T,a]$ \\
$s^i$ & $i$-th step in a solution path \\
$a$ & Final answer in a solution path \\
$T$ & Number of steps in a solution path \\
$y$ & Binary label (0 or 1) indicating the correctness of $a$ \\
% $\mathbb{S}$ & Set of candidate complete paths $\mathbb{S} = \{S_k\}_{k=1}^{K}$ \\
$S^{(1:t)}$ & Partial solution path up to step $t$, $S^{(1:t)}=[s^1, \dots, s^t]$ \\
$\mathbb{S}^{(1:t)}$ & Set of candidate partial paths $\mathbb{S}^{(1:t)} = \{S_k^{(1:t)}\}_{k=1}^{K}$ \\
$K$ & Candidate size \\
$b$ & Beam size \\
% $N$ & Number of search processes \\
% $n$ & Number of sampled paths per question for training value models \\
% $\Phi$ & Language model generator \\
% ${\operatorname{RM}}$ & Reward model mapping a complete path to a scalar \\
% $f^{\mathrm{OVM}}$ & Outcome-supervised value model mapping a partial path to a scalar \\
% $\operatorname{UVM}$ & Uncertainty-aware value model mapping a partial path and index to a scalar \\
% $g$ & LLM backbone of value model mapping a partial path to a hidden state \\
$v$ & Value (scalar) of a partial path \\
$p(v|q,S^{(1:t)})$ & Posterior distribution of values for a partial path \\
$m$ & Number of components in UVM head \\
$\mathbf{W},\mathbf{b}$ & Learnable parameters of UVM head \\
$\mathbf{W}_0$ & Fixed parameters of UVM head \\
% $u$ & Hyperparameter of Ensemble++/UVM to tradeoff between $\mathbf{W},\mathbf{W_0}$ and $\mathbf{b}$ \\
% $p_0$ & Hyperparameter of Ensemble++/UVM to tradeoff between $\mathbf{W}$ and $\mathbf{W}_0$ \\
$\boldsymbol{\theta}$ & Parameters of the value model backbone \\
$d$ & Dimension of value model backbone's hidden states \\
$\mathbf{x}$ & Last hidden states output by VM's backbone \\
$\boldsymbol{\zeta}$ & Index vector of dimension $m$ \\
$p_{\boldsymbol{\zeta}}$ & Index distribution \\
% OVM & Outcome Value Model (trained with outcome supervision) \\
% UVM & Uncertainty-aware Value Model \\
\bottomrule
\end{tabular}%
}
\label{tab:notations}
\end{table}



\subsection{Construction of VMs' Training Dataset}
\label{app:vm_training}

The training dataset is created using the generator and the question-answer pairs. For each pair $(q,a)\in\mathcal{Q}$, the generator produces $n$ solution paths, resulting in a total of $|\mathcal{Q}|\times n$ question-solution pairs. The label $y$ for each solution $S$ is assigned based on the correctness of the final answer, which is determined by comparing it to the ground truth answer $a$. A label of 1 indicates the answer is correct, while 0 indicates it is incorrect. This process forms a training dataset consisting of $(q, S, y)$ tuples for value model training.


\subsection{Detailed UVM Structure}
\label{app:uvm_structure}

Given the representation $\mathbf{x}$, the sampled index $\boldsymbol{\zeta}$ is mapped to the posterior value sample as:
\begin{equation}\label{equa:vd}
    v=\underbrace{\mathbf{x}\mathbf{b}}_{\text{mean estimator}}+\underbrace{\mathbf{x}(u\mathbf{W}+p_0\mathbf{W}_0)\boldsymbol{\zeta}^T}_{\text{uncertainty estimator}}
    % v=\mathbf{x}(u(\mathbf{W}+p_0\mathbf{W}_0)\boldsymbol{\zeta}^T+\mathbf{b})
    % v=\mathbf{x}(\underbrace{u(\mathbf{W}+p_0\mathbf{W}_0)\boldsymbol{\zeta}^T}_{\text{Beyond OVM}}+\mathbf{b})
\end{equation}
Here, $u$ and $p_0$ are hyperparameters. Specifically, $u$ controls the tradeoff between the uncertainty terms $\mathbf{W},\mathbf{W}_0$ and the mean value term $\mathbf{b}$, and $p_0$ controls the tradeoff between the posterior term $\mathbf{W}$ and the prior term $\mathbf{W}_0$. 


\subsection{Step-Level Beam Search}
\label{app:beam_search}

The algorithm is shown in Algorithm~\ref{algo:beam_search}.

\begin{algorithm}[h]
\small
\caption{\label{algo:beam_search}Step-Level Beam Search}
\begin{algorithmic}[1]

\Statex $\textbf{Input:}$ Question $q$, Beam size $b$, Candidate size $K$, Maximum step count $T^{max}$
\Statex $\textbf{Output:}$ $b$ solution sequences for $q$
\Statex $\textbf{Model:}$ $\operatorname{Generator}$ and $\operatorname{VM}$

    \State Initialize sequences $\mathbb{S} \gets \{\}$
    \State Sample the first steps $\{s_1^1,\dots,s_K^1\}$
    \State Select $b$ steps via \Call{Selection}{$q$, $\{s_1^1,\dots,s_K^1\}$, $b$, $\operatorname{VM}$} and add to $\mathbb{S}$
    \State $t \gets 1$
    \While{any sequence of $\mathbb{S}$ is not complete and $t < T^{max}$}
        \State $\mathbb{S}_{\text{next}} \gets \{\}$
        \For{$S^{(1:t)}$ in $\mathbb{S}$}
            \For{$i = 1$ to $K/b$}
                \State $S^{(1:t+1)}_i=\operatorname{Generator}(S_i^{(1:t)};q)$
                \State $\mathbb{S}_{\text{next}} \gets \mathbb{S}_{\text{next}}+S^{(1:{t+1})}_i$
            \EndFor
        \EndFor

        \State $\mathbb{S} \gets$ \Call{Selection}{$q$, $\mathbb{S}_{\text{next}}$, $b$, $\operatorname{VM}$}
        \State $t \gets t+1$
    \EndWhile
% \Statex \Return sequence with highest final reward in $\mathbb{S}$
\Statex \Return $\mathbb{S}$
\end{algorithmic}

\end{algorithm}

\end{document}
