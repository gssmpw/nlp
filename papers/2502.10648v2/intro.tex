% TODO: Discuss bottle necks of conventional LLM feature selection methods. Use LLM as a stand-alone feature selector can be ad-hoc especially when authors demonstrate its superior performance on well-studied datasets, where memorization is likely the key at play behind the performance.
Feature selection remains a cornerstone of statistical learning, enabling models to focus on the most relevant predictors while reducing complexity and improving interpretability \citep{guyon2007feature, chandrashekar2014survey, li2015feature}. Among the various methods for feature selection, Lasso regression has gained widespread adoption for various reasons. It delivers a feature selection approach while simultaneously building a predictive model. The Lasso approach is interpretable and computationally efficient because it automatically selects a suitable linear model with a sparse set of coefficients. Selection is performed by solving a straightforward convex optimization problem that promotes sparsity by penalizing the size of the regression coefficients \citep{tibshirani1996LASSO, buhlmann2011LASSO,hastie2015statistical}. As with any supervised learning model, the traditional Lasso approach is based only on the training data. It is natural to consider expert knowledge to inform the feature selection task. However, this is challenging to do in a systematic and scalable way that safeguards against introducing potential biases. \textit{The goal of this paper is to meet this challenge. We do this by taking advantage of current advances in generative AI.} 

%to determine the penalty term.  which result in suboptimal feature selection in scenarios where external domain-specific knowledge is available and paramount to the prediction performance but not incorporated.

The development of large language models (LLMs) trained on a large scale of unstructured text offers a transformative opportunity to augment traditional feature selection techniques in systematic and scalable way.  Transformer-based pre-trained LLMs, such as GPT-4 \citep{openai2023gpt4} and LLaMA-2 \citep{touvron2023llama}  have demonstrated impressive abilities in encoding domain knowledge and contextual relationships and generalizing to a wide range of unseen tasks in a variety of domains \citep{vaswani2017attention,brown2020gpt3,radford2019language,manikandan2023language}, including various challenging reasoning tasks \citep{wei2022chain,lewkowycz2022solving,suzgun2023challenging}, prediction tasks that require domain-specific knowledge \citep{petroni2019language,dinh2022lift,chen2024embeddings,theodoris2023transfer,cui2024scgpt}, and, more recently, feature selection \citep{choi2022lmpriorspretrainedlanguagemodels,jeong2024llmselectfeatureselectionlarge,li2024exploringlargelanguagemodels, liu2024ice_search, han2024largelanguagemodelsautomatically}. 
Based on the idea that LLMs might possess relevant knowledge for the task at hand, \cite{dinh2022lift} proposed fine-tuning an LLM with training data, feature names, and task descriptions and showed improvements in prediction performance.
Specific to feature selection, \cite{choi2022lmpriorspretrainedlanguagemodels} introduces the LMPriors framework, which selects features by analyzing log-probability differences when generating ``Y" (Yes) or ``N" tokens, effectively admitting or rejecting certain features based solely on task descriptions, feature names, and a few-shot examples. Based on this, \cite{jeong2024llmselectfeatureselectionlarge} and \cite{liu2024ice_search} enable feature selection with proprietary LLMs where internal token probabilities are inaccessible. Specifically, \cite{jeong2024llmselectfeatureselectionlarge} proposes three prompting strategies that rely only on textual information, bypassing the need for data access, to directly utilize the output of the generated text without further processing. Meanwhile, \cite{liu2024ice_search} introduces a framework that leverages LLMs for direct feature filtering based on test scores. These methods for incorporating LLMs into feature selection have demonstrated promising results, showing that LLMs can rival leading statistical feature selection techniques, even in zero-shot settings where they lack direct access to the data \citep{choi2022lmpriorspretrainedlanguagemodels, jeong2024llmselectfeatureselectionlarge}. Collectively, these studies underscore the potential of LLMs to encode a rich set of relevant, task-specific information, augmenting traditional supervised learning approaches and enabling their application across a wide range of downstream tasks. % double check liu2024ice-search: data-based prompting?

In this work, we build on these insights by introducing LLM-Lasso, a novel framework for LLM-powered feature selection that integrates LLM-derived penalty factors into Lasso penalty terms, allowing the seamless fusion of knowledge-based insights with traditional data-driven supervised learning methodologies. LLM-Lasso focuses on feature selection in the context of a specific family of models (the ones in the Lasso framework). This strategy allows us to ensure that the feature selection approach is effective for the downstream task of selecting a model in the family. Using other feature selection approaches that are not aligned with the downstream task of interest could result in features that are not relevant to the task. For example, the use of random forests could result in the choice of a feature that is perceived relevant because of its non-linear interactions with other features. But if the task at hand is to select a linear model, such a feature may not be useful.  

LLM-Lasso assumes black-box access to the LLMs and utilizes an optional retrieval-augmented generation (RAG) pipeline \citep{lewis2020retrieval,shuster2022fact,wu2024retrievalaugmentedgenerationnaturallanguage,siriwardhana-etal-2023-improving} to extract domain-specific knowledge via LLMs, which is then used to inform Lasso regularization. This approach enables fine-tuning through cross-validation, ensuring adaptability and robustness. Although previous research on the adoption of LLMs for feature selection has shown promising results, these methods face a major bottleneck: they rely solely on context descriptions of the task and features to make standalone feature selection decisions, without incorporating data-driven safeguards to ensure robustness against inaccuracies in the generated responses. This limitation makes these methods vulnerable to LLM hallucinations, that is, fabricating nonexistent facts, a common weakness even in the most advanced LLMs \citep{Huang_2024, yao2024llmlieshallucinationsbugs}. This can also raise concerns about their reliability, particularly in scenarios where the data is unexpected or errors have occurred during data collection. All of the aforementioned inaccuracies can be especially detrimental in fields such as biomedicine, where precision and reliability are critical. 
%Second, existing LLM-based feature selection methods often rely on extensive prompting, making them difficult to scale with high-dimensional data due to token limits in both closed-source and open-source LLMs. 
%Furthermore, the challenge of constructing a pipeline to batch-query the LLM in a way that ensures scores from each batch are correctly integrated has yet to be systematically addressed. 

\paragraph{Main Contributions.} In this paper, we address the key bottleneck of robustness and demonstrate the effectiveness of LLM-Lasso through experiments focused on various tasks, including an unpublished biomedical dataset with feature dimensions that are at least an order of magnitude larger than those in previous studies.  Focused on logistic regression classification tasks, our results show that LLM-Lasso outperforms standard Lasso in feature selection accuracy and predictive performance. While biomedicine is a key use case, our framework is broadly applicable to other domains where external knowledge aids feature selection and extends to general supervised learning methods.
Our main contributions are as follows.
\begin{enumerate}
\item We introduce LLM-Lasso, a scalable and robust framework for LLM-powered feature selection that effectively combines contextual knowledge with data-driven insights, enabling the direct integration of LLMs into traditional supervised learning methods.
\item We build into  LLM-Lasso  an internal validation step that determines how much to trust the contextual knowledge in our prediction pipeline. This validation step is tested using adversarial examples.
\item We show that LLM-Lasso consistently outperforms standard Lasso and other popular feature selection methods across various datasets.
\item We demonstrate LLM-Lasso's clinical applicability by identifying key diagnostic factors distinct from those selected by traditional Lasso or standard LLM-based methods, enhancing precision and facilitating scientific discovery.
%We highlight the potential impact of our approach on healthcare and biomedical applications, showcasing its utility in clinical domains where precision is essential.
%Our experiments show that integrating LLMs and traditional data-driven methods in a robust framework may yield novel paths for scientific discovery. This is illustrated in experiments in which LLM-Lasso selects relevant genes as distinctive features for certain types of medical diagnosis tasks.
\end{enumerate}

The paper is structured as follows: Section \ref{prelim} reviews Lasso, RAG, and presents a schematic of our procedure. Section \ref{mthd} details our methodology. Section \ref{sec:sim} determines penalty factor selection via simulations and exemplify robustness of LLM-Lasso through adversarial experiments. Section \ref{experiment} evaluates LLM-Lasso across diverse datasets and LLMs. Finally, Section \ref{conclude} summarizes our findings

%By embedding contextual insights into the regularization process, LLASSO advances the integration of LLMs into traditional statistical frameworks. This work underscores the potential of LLM-augmented methodologies to redefine feature selection, paving the way for more informed, interpretable, and effective machine learning models across a variety of disciplines.
