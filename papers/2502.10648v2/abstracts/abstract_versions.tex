%Version 1: Technically oriented explaining more details about what we actually do.
We introduce LLM-lasso, a novel framework that enhances variable selection in lasso regression by leveraging large language models (LLMs). Traditional machine learning models use predictors as statistical variables, whereas LLMs facilitate the access and manipulation of information expressed in natural language. In weighted lasso, each coefficient is penalized by a weight inversely related to its variable's importance, where a larger weight induces a smaller coefficient, indicating lower importance. We propose a simple model for these importance weights and integrate it with a retrieval-augmented generator (RAG) methodology to estimate weights using domain-specific knowledge relevant to downstream tasks. This integration significantly improves the predictive performance compared to using lasso or LLM-based selection alone and surpasses existing GPT-based model selection methods. We demonstrate the effectiveness of LLM-lasso in various biomedical applications, including cancer studies, ensuring that the LLM does not access the datasets beforehand. Additionally, our importance weight model can be fine-tuned through cross-validation to mitigate incorrect LLM predictions or hallucinations. By addressing scalability challenges in the RAG model design, our approach supports model selection for thousands of variables, achieving at least an order of magnitude improvement over previous studies.


%Version 2, it is (hopefully) easier to read than Version 1, but we talk a bit less about what we actually do (attempts to combine Erica's version below) with the above version, trying to explain what we actually mean by "metadata", which I think could have a meaning that is less informative than what we actually use (in fact, scientific observations and insights). Also, tries to explain what we actually do in terms of methods. 
We introduce \textbf{LLM-lasso}, a new framework that uses large language models (LLMs) to guide feature selection in lasso regression. Unlike traditional approaches that rely solely on numerical data, LLM-Lasso incorporates domain-specific information extracted from natural language (e.g., research articles or clinical guidelines). Concretely, the LLM provides \textbf{importance scores} for each feature, which we translate, via a simple model with a tunable parameter, into weights in the lasso penalty. Features deemed more relevant by the LLM are penalized less and are therefore more likely to remain in the final model, whereas features considered less relevant are penalized more and tend to be zeroed out.

Our proposed methodology overcomes scalability and robustness issues making applicable to datasets with thousands of features. A cross-validation procedure fine-tunes the LLM-predicted weights, helping correct for mistakes or “hallucinations” that the LLM might produce. In multiple biomedical case studies, LLM-Lasso \textbf{outperforms standard lasso and existing feature-selection methods}, all while ensuring that the LLM operates without prior access to the datasets. By blending the interpretability of natural language insights with rigorous, data-driven models, LLM-lasso highlights a promising and versatile way for enhancing the performance of machine learning methods with domain-specific information encoded in the form of natural language.

%  I think we need to mention RAG somewhere in the abstract.

% Comments by Ryan: 
% *Should we briefly mention RAG in the abstract?
% *We do have many more features than previous studies, but our max dataset size is 1592 ... so maybe replace "thousands" with something like "high-dimensional"? 

% Erica's abstract:
% We introduce LLM-Lasso, a novel framework that enhances variable selection in lasso regression by combining metadata-informed insights from large language models (LLMs) with traditional data-driven methods. To the best of our knowledge, this is the first approach to integrate conventional feature selection techniques with LLM-based reasoning, seamlessly incorporating domain-specific natural language knowledge into a robust, data-driven learning framework for variable importance estimation.

% LLM-Lasso effectively addresses key challenges in scalability and robustness, enabling the analysis of datasets with high-dimensional features. Fine-tuning via cross-validation ensures reliability by mitigating potential inaccuracies or hallucinations from the LLM. Our experimental results demonstrate the effectiveness of LLM-Lasso across various biomedical applications, where it consistently outperforms traditional lasso and existing feature selection baselines, all while ensuring that the LLM operates without prior access to the datasets. This work underscores the potential of LLM-Lasso to bridge metadata-informed reasoning with traditional statistical models in high-dimensional, domain-specific tasks and establishes a versatile framework for integrating LLMs into supervised learning methods.

Notes for abstract:
%* [Framework / Why?] Traditional lasso promotes sparsity by adding an L1-norm-penalty term for the regression coefficients. LLM enables the use of scientific information summarized in the form of text

% but its penalty term is typically determined solely by the training data, overlooking the potential to incorporate valuable metainformation.

%* [Why/how we do it? Merge this and the next paragraph] Explain the next sentence using more direct terms e.g. inserting the notion of expert knowledge or side information.] Traditional LASSO promotes sparsity by penalizing regression coefficients, but its penalty term is typically determined solely by the training data, overlooking the potential to incorporate valuable metainformation. Recent advances in LLMs make it possible to bridge this gap. Using importance scores generated from an expert LLM, empowered through a retrieval-augmented generation (RAG) pipeline, we create a task-specific data-driven regularization strategy. 

%* This approach integrates domain-specific knowledge alongside training data to improve performance. However, the approach safeguards feature selection using only the LLM model directly. We demonstrate the effectiveness of this framework with a particular focus on biomedicine, highlighting its performance and relevance in real-world applications. Our experiments reveal that regularized LLM LASSO consistently outperforms traditional LASSO in feature selection accuracy and predictive performance in a diverse range of biomedical dataset.

%*[What are the contributions?]

%* synergy between data-driven statistical models and expert knowledge using LLMs.
%* protecting against hallucination.
%* better performance to state-of-the-art.
%* scaled to thousands of features (this cannot be done in any of the current applications of LLMs for feature selection because of engineering limitatons).
%* potentially generalizable to other supervised learning methods (Lasso, neural nets (deep NNs), random forests, etc.) .

%* [For Introduction apply STAR.]
%* Say explicitly that we don't allow LLM access to the data

% introduction (recycled piece)
Our work situates itself within a growing body of research that seeks to bridge the gap between data-driven learning methods and domain expertise. For example, \cite{jeong2024llmselectfeatureselectionlarge} demonstrated that LLMs can achieve feature selection performance comparable to data-driven methods without accessing training data, while growing research in biomedical field such as \cite{chen2024embeddings, theodoris2023transfer, cui2024scgpt} highlighted the utility of LLM embeddings for biological prediction tasks. However, these approaches have not explored the direct integration of LLM-derived information into classical statistical models, a gap L-LASSO aims to address.

We establish a robust, interpretable, and task-specific framework for feature selection, particularly valuable in domains like biomedical sciences, where the interplay between data and prior scientific knowledge is often crucial for a wide range of tasks. 