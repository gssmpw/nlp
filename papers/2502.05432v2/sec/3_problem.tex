\begin{figure*}[h]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{fig/GT.png}
        \caption{Ground truth heatmap skeleton}
        \label{fig:gt}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{\textwidth}
        \includegraphics[width=\textwidth]{fig/dVAE.png}
        \caption{Reconstructed heatmap skeleton.}
        \label{fig:dvae}
    \end{subfigure}
    \caption{Comparison of heatmap skeletons: (a) Ground truth heatmap skeleton used as input for \dV; (b) Reconstructed heatmap skeleton generated by \dV. A ghosting effect is observed for moving joints in the \dV~ output.}
    \label{fig:combined_frames}
\end{figure*}

\section{Problem Formulation}
The objective of this work is to develop a robust foundational model, MoFM, that learns the semantics of human motion using representations called thermal cubes and pose tokens, enabling an efficient and generalized understanding of human motion for downstream tasks. This process begins by constructing a spatio-temporal heatmap, \( U \), for a sequence of \( F \) frames in the 2D pose skeleton \( P = \{P_i\}_{i=0}^{F-1} \). Subsequently, \( U \) is divided into Thermal Cubes, denoted as \( C = \{C_i\}_{i=0}^{K-1} \), where \( K \) represents the number of tokens MoFM backbone can process simultaneously. 

To facilitate self-supervised training, we first employ the Thermal Cubes \( C \) to train a dVED, generating a ``MotionBook" vocabulary \(\mathcal{V}\). With the vocabulary size configured as the transformer head (T-Head) dimension and applying pose-aware BERT-style masked modeling, we train the task-agnostic MoFM backbone to capture motion semantics across tokens. Subsequently, the pretrained MoFM backbone serves as encoder for downstream applications. \cref{fig:self_trans} illustrates this framework, with detailed steps provided in the following sections.

