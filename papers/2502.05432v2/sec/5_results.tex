\section{Experimental Results}
\label{sec:results}

% \hl{Do not hate me, but should we also visualized the heatmap of pre-trained transformer. I believe it would be very insightful!}
This section presents experimental results to demonstrate the capabilities of the pretrained MoFM when used as a backbone for various downstream tasks. While MoFM is applicable to a wide range of applications, we have selected DT1: action classification, DT2: one-shot action classification, DT3: self-supervised human anomaly detection, and DT4: supervised human anomaly detection to showcase its versatility. In all these tasks, we have only added a basic fully connected linear head on top of MoFM to form a simple baseline. 

All training used six NVIDIA A6000 GPUs. Other experimental setup and hyper parameters for each downstream task are fully explained in the supplementary material.


%\subsection{Experimental setup}
%\hl{each subsection should have a short paragraph explaining the details of the setup. later on if we do not have room, we will move it to appendix.}
% The training process runs for approximately 623,000 steps (around 20 epochs) with a batch size of 8. We use the AdamW optimizer \cite{loshchilov2018decoupled} with \(\beta_1 = 0.9\) and \(\beta_2 = 0.999\), and a weight decay of 3e-4. The learning rate is set to 1.5e-4, with a warmup period of 5 epochs, followed by cosine learning rate decay. Dropout is set to 40\%. The 623,000 training steps take about seven days to complete using 1 Nvidia Tesla A6000 48GB GPU.

\subsection{DT1: Action Classification} \label{sec:dt1}
We explore the potential of MoFM’s pretrained human motion representations as a backbone for learning action semantics. For this, we utilize the NTU-RGB+D \cite{ntu60Paper} dataset, containing 57K videos across 60 action classes, following the Cross-Subject (X-Sub) and Cross-View (X-View) splits. We also leverage the extended NTU-RGB+D-120 \cite{ntu120paper} dataset, which includes 114K videos covering 120 action classes with Cross-Subject (X-Sub) and Cross-Setup (X-Set) splits. For both datasets, we extract 2D skeletons using HRNet \cite{hrnet} as described in \cite{PoseConv3D}. As shown in \cref{tab:ntu_60} and \cref{tab:ntu_120}, our methods achieve performance on par with or surpassing SOTA approaches, underscoring MoFM’s capability to generalize effectively to the downstream task of human action recognition.
\input{tab/NTU_60}
\input{tab/NTU_120}

\subsection{DT2: One-shot Action Classification}\label{sec:dt2}
We further assess MoFM's capability in recognizing one-shot actions by adding a fully connected layer that embeds the given action onto a $\delta$-dimensional hypersphere, where $\delta = 2048$ for this experiment. Following NTU-RGB+D-120 \cite{ntu120paper} guidelines, we trained the model on an \textit{auxiliary set} of 100 labeled samples using supervised contrastive learning \cite{khosla2020supervised}. In each batch, \( m \) samples of the same class were randomly selected from the auxiliary set, and a supervised contrastive loss was applied to cluster samples of the same class while separating samples of different classes. Evaluation was conducted by calculating cosine similarity between the test set and 20 exemplars for each remaining class. \cref{tab:ntu_120_one} presents the accuracy comparison of MoFM with recent approaches, demonstrating MoFM's effectiveness in handling one-shot action classification, similar to the DT1 experiments.

\input{tab/NTU_120_One_Shot}


% \begin{figure}[h]
%   \centering
%   \includegraphics[width=0.48\textwidth]{fig/xview_comp.pdf}
%   \caption{Comparison of convergence curves between training \memt~from scratch and the pretrained model}
%   \label{fig:convg_speed}
% \end{figure}

% \subsubsection{Convergence curve}
% Figure \ref{fig:convg_speed} shows the training performance of \memt~from scratch compared to its multi-stage training on the NTU-60 dataset. The results indicate that fine-tuning \memt~achieves satisfactory performance levels within a remarkably small number of training epochs. As illustrated, the pretrained model reaches an accuracy of 66.35\% at 4800 iterations, whereas training the model from scratch only achieves 48.72\% accuracy. Furthermore, fine-tuning \memt~not only delivers superior performance, with approximately a 4\% improvement in Top-1 accuracy at plateau, but also converges significantly faster than training from scratch. 

% \subsubsection{Model size}
%  Table \ref{tab:model_size} summarizes and compares the model size of \memt~against the ViT model. As shown, with a negligible 2.4\% increase in the base model size (ViT), we enable \memt~to function as a motion transformer for the general understanding of human motion. The slight increase in model size is primarily due to the inclusion of the 3D ResBlock in the spatio-temporal embedding layer.

% \input{tab/model_size}


\subsection{DT-3: Self-supervised Human Anomaly Detection}
\label{sec:sht}
In self-supervised human video anomaly detection, the objective is to enable models to discern patterns of typical human behavior and identify deviations as anomalous \cite{10.1145/3645101}. Self-supervised methods typically formulate proxy tasks, such as reconstruction \cite{morais2019learning} or future prediction \cite{morais2019learning, rodrigues2020multi, zeng2021hierarchical}, training the model exclusively on normal data. This encourages the model to internalize the underlying dynamics of normal human motion. During inference, the model's ability to perform these tasks serves as an indicator of abnormality detection.

\input{tab/unsupervised_anomaly}

Inspired by \cite{jigsaw}, we define a self-supervised jigsaw puzzle task at the token level, rather than at the pixel level as in \cite{jigsaw}. A simple fully connected layer with 12 neurons is added as the task head. Tokens are grouped into 12 puzzle pieces, which are shuffled during training, and the network is fine-tuned with multi-label supervision using cross-entropy loss to predict the correct positions of the pieces. During inference, no shuffling occurs; instead, the model's predictions are used to compute a normality score. For abnormal behavior, prediction accuracy declines, resulting in a non-diagonal probability matrix. The lowest probability along the diagonal is taken as the normality score. If multiple individuals are present in the scene, the frame’s overall normality score is determined by the minimum of their individual scores.

To evaluate our model, we use the widely adopted ShanghaiTech Campus (SHT) dataset \cite{liu2018future}. Following previous SOTA methods \citep{markovitz2020graph, hirschorn2023normalizing, yu2023regularity}, we use AlphaPose \citep{li2019crowdpose} for pose extraction and tracking to ensure fair comparison. We also report results on the Human-Related SHT subset \cite{morais2019learning}, which focuses exclusively on human activities. We report results in terms of frame level Area Under the Receiver Operating Characteristic Curve (AUC-ROC). 
%For fine-tuning, we trained the pre-trained backbone and the head for only 1 epoch with the Adam optimizer \cite{loshchilov2018decoupled}, with a base learning rate set to 1e-8 and a weight decay of 6e-4, employing a OneCycle Learning Rate schedule with a maximum learning rate of 1e-4.

As shown in \cref{tab:sht}, MoFM-FC achieves an AUC-ROC of 76.56\% on SHT \cite{liu2018future} and 77.26\% on HR-SHT \cite{morais2019learning}, demonstrating performance comparable to other SOTA models. These results underscore the adaptability and versatility of the MoFM as a backbone, demonstrating that with the addition of a simple linear head, it can be effectively utilized for self-supervised anomaly detection.

\subsection{DT4: Supervised Human Anomaly Detection}
\label{sec:sup_anomaly}
In supervised human anomaly detection, the task is framed as a binary classification problem. Similar to previous downstream tasks, we add a fully connected layer as the head. During inference, the probability assigned to the normal class serves as the normality score. In line with the self-supervised approach, if multiple individuals are present, the frame's overall normality score is determined by the minimum of their individual scores.

\input{tab/supervised_anomaly}

For evaluation, we utilize the UBnormal dataset \cite{Acsintoae_CVPR_2022} and measure the model's performance using frame-level AUC-ROC, consistent with prior SOTA approaches \cite{georgescu2021background, bertasius2021space, yan2018spatial, shi2019two, cheng2020skeleton, liu2020disentangling, hirschorn2023normalizing}. To address data imbalance in the training set, we apply data augmentation techniques, including random scaling, jitter noise, and horizontal flipping, to increase the representation of abnormal samples. Additionally, we use a weighted cross-entropy loss, giving 2$\times$ greater weight to abnormal samples to further mitigate class imbalance.

\cref{tab:ub} demonstrates the effectiveness of MoFM-FC compared to other SOTA models. Our model achieves an AUC-ROC of 69.55\%, showing performance comparable to other models and highlighting the capability of the MoFM backbone for supervised anomaly detection.

%We fine-tuned the backbone and the head for only 8 epochs with the Adam optimizer \cite{loshchilov2018decoupled}, with a base learning rate set to 1e-8 and a weight decay of 3e-4, employing a OneCycle Learning Rate schedule with a maximum learning rate of 1e-4.