\section{Experiments}

\subsection{Experimental Setup}


\noindent \textbf{Training.~} 
Following the previous work~\cite{zou2022devil}, we train the proposed CMamba model on the OpenImages dataset~\cite{krasin2017openimages}. 
Our CMamba is trained for 50 epochs using the Adam optimizer~\cite{kingma2014adam}.
Each batch contains 8 patches with the size of $256 \times 256$ randomly cropped from the training images.
The learning rate is initialized as $1e^{-4}$. 
After 40 epochs, the learning rate is reduced to $1e^{-5}$ for 5 epochs. 
Finally, we train the model for the last 5 epochs with a larger crop size of $512 \times 512$, maintaining the learning rate at $1e^{-5}$.


Our model is optimized by the rate-distortion loss as illustrated in Eqn.~\eqref{eq3}.
The distortion $D$ is quantified by two quality metrics, \ie, mean square error (MSE) and multi-scale structural similarity index (MS-SSIM)\footnote[3]{Here, we represent the MS-SSIM by $-10\log_{10}\left( 1-\textit{MS-SSIM} \right)$ for a clearer comparison.}.
The Lagrangian multipliers used for training MSE-optimized models are $\left\{25, 35, 67, 130, 250, 500 \right\}\times1e^{-4}$, and those for MS-SSIM-optimized models are $\left\{3, 5, 8, 16, 36, 64 \right\}$.

\noindent \textbf{Evaluation.~}
We evaluate our model on three benchmark datasets, \ie, Kodak dataset~\cite{franzen1999kodak} with the image size of $768 \times 512$, Tecnick testset~\cite{asuni2014testimages} with the image size of $1200 \times 1200$, and CLIC Professional Validation dataset~\cite{theis2020clic} with 2K resolution. 
PSNR and MS-SSIM are used to evaluate the quality of reconstructed images, and bits per pixel (bpp) is used to evaluate Bitrate.
Besides rate-distortion curves, we also evaluate different models using BD-Rate~\cite{tan2015video}, which describes the average Bitrate savings for the same reconstruction quality.
All experiments are conducted on an NVIDIA GeForce RTX 3090 Ti and an Intel i9-12900.


\subsection{Rate-Distortion Performance}


\begin{figure*}[t]
  \centering
   \includegraphics[width=0.95\linewidth]{figs/fig3.pdf}
   \vspace{-1em}
   \caption{
   PSNR-Bitrate curves evaluated on Kodak, Tecnick, and CLIC datasets.
   The compared methods include state-of-the-art LIC models and handcrafted codecs.
   LIC models are optimized with MSE.
   }
   \vspace{-1em}
   \label{fig3}
\end{figure*}

\input{tabs/tab1}


We compare our method with state-of-the-art (SoTA) image compression algorithms, including traditional image codecs Better Portable Graphics (BPG)~\cite{bellard2018bpg} and Versatile Video Coding (VVC) intra (VTM 17.0)~\cite{bross2020versatile}, as well as LIC models~\cite{minnen2018joint, cheng2020learned, qian2021entroformer, he2022elic, zou2022devil, jiang2023mlic, liu2023learned, li2024frequency, jiang2023mlicpp}. 


Fig.~\ref{fig3} and Table~\ref{tab1} present the MSE optimized rate-distortion performance on Kodak, Tecnick, and CLIC datasets. Fig.~\ref{fig5} demonstrates the performance optimized by MS-SSIM on the Kodak dataset.
These results demonstrate that our method outperforms prior methods across all three datasets. 
To get quantitative results, we present the BD-Rate~\cite{tan2015video} computed from PSNR-Bitrate curves as the quantitative metric.
The anchor rate-distortion performance is set as the benchmark achieved by Versatile Video Coding (VVC) intra (VTM 17.0)~\cite{bross2020versatile} on different datasets (BD-Rate = 0\%). 
Our method achieves improvements of 14.95\%, 18.83\%, and 13.89\% in BD-Rate compared to VVC on Kodak, Tecnick, and CLIC datasets, respectively.
We also provide the BD-Rate for several SoTA image compression methods in Fig.~\ref{fig3} and Fig.~\ref{fig5}.
As seen in these figures, our CMamba outperforms other SoTA methods in rate-distortion performance.


Furthermore, we conduct comparative experiments to validate the efficiency of the proposed CMamba across multiple metrics, including latency, parameters, and FLOPs.
As shown in Table~\ref{tab1}, our method demonstrates substantial improvements on the Kodak dataset, achieving 51.8\% reduction in parameters, 28.1\% decrease in FLOPs, and 71.4\% reduction in decoding time compared to the SoTA LIC method~\cite{jiang2023mlicpp}.
Overall, our CMamba attains superior rate-distortion performance and significantly reduces computational complexity compared to the state-of-the-art.

\begin{figure*}[t]
  \centering
   \includegraphics[width=.85\linewidth]{figs/fig4.pdf}
   \vspace{-1em}
   \caption{
    Visual comparison of the decompressed \textit{kodim24.png} image from the Kodak dataset using various compression methods. 
    Opt.MSE and Opt.MS-SSIM indicate that a model is optimized with MSE and MS-SSIM, respectively. 
    More visual comparisons are provided in the supplementary materials.
   }
   \label{fig4}
\end{figure*}


\begin{figure}[t]
  \centering
   \includegraphics[width=.75\linewidth]{figs/fig5.pdf}
   \vspace{-1em}
   \caption{
   Rate-distortion performance evaluated on the Kodak dataset.
   All the models are optimized with MS-SSIM.
   }
   \vspace{-1em}
   \label{fig5}
\end{figure}


\subsection{Qualitative Results}

To demonstrate that our method can produce visually appealing results, we provide visualizations of decompressed images for a qualitative comparison in Fig.~\ref{fig4}. 
The PSNR, MS-SSIM, and Bitrate values are indicated along with each sub-image label for additional quantitative reference.
Compared to TCM~\cite{liu2023learned}, CMamba~[Opt.MSE] preserves more details with a smaller Bitrate, such as sharper textures of the balcony railing (\textcolor[RGB]{244, 0, 0}{red box}) and mural details (\textcolor[RGB]{223, 165, 0}{yellow box}).
In the corresponding quantitative results, CMamba~[Opt.MSE] achieves a PSNR of 28.35 dB, an MS-SSIM of 12.56 dB, and a bitrate of 0.224 bpp, outperforming TCM, which achieves a PSNR of 28.34 dB, an MS-SSIM of 12.54 dB, and a bitrate of 0.246 bpp, respectively.
More importantly, the CMamba~[Opt.MS-SSIM] achieves better visual quality with a lower Bitrate (0.139 bpp) compared to other methods.


\subsection{Ablation Studies}

\input{tabs/tab2}


We conduct ablation studies to demonstrate the effectiveness of our CA-SSM and CAE modules. 
Specifically, we replace the CA-SSM module and the CAE module with the VSS block~\cite{liu2024vmamba} and ChARM~\cite{minnen2020channel} to serve as the baseline model. 
As shown in Table~\ref{tab2}, the proposed CA-SSM module significantly improves the rate-distortion performance, saving 12.91\% BD-Rate, while maintaining low encoding (94 ms) and decoding (50 ms) time by dynamically integrating the advantages of SSMs and CNNs. 
Furthermore, the CAE module further improves the rate-distortion performance to -14.95\% BD-Rate with fewer parameters (56.21M) and fewer computational costs (355.29G FLOPs) compared to ChARM.
This implies that the combination of CA-SSM and CAE not only achieves superior rate-distortion performance but also attains efficiency in terms of computational complexity and inference speed.
In addition, we further analyze the contributions of each component in our CA-SSM and CAE modules.


\subsubsection{Analysis of the CA-SSM Module Design}

To further verify the design of the CA-SSM module, we conduct experiments with other architectures (\ie, CNN, Swin, SSM, and Swin \& CNN) and fusion methods (\ie, Summation and Concatenation), as presented in Table~\ref{tab3}.
In our experimental configuration, \textit{CNN}, \textit{Swin}, and \textit{SSM} denote that the CA-SSM module is replaced with the corresponding layer, respectively, while maintaining approximately the same number of parameters.
The \textit{Swin \& CNN} indicates that the VSS block within the CA-SSM module is substituted with the Swin Transformer block~\cite{liu2021swin}. 
For fusion methods, \textbf{\textit{Sum}} and \textbf{\textit{Concat}} refer to configurations where features are fused via summation or concatenation operations, rather than dynamic fusion.
All configurations utilize ChARM~\cite{minnen2020channel} as the entropy module.
The comparison demonstrates that our CA-SSM module outperforms all alternatives, achieving the best performance with a 12.91\% BD-Rate saving and 64.33M parameters.


\input{tabs/tab3}
\input{tabs/tab4}


\begin{figure}[t]
  \centering
   \includegraphics[width=.95\linewidth]{figs/fig7.pdf}
   \vspace{-1em}
   \caption{
   The spatial correlation map of $(y-\mu)/\sigma$ with models trained at $\lambda=0.013$. 
   The value with index $(i, j)$ corresponds to the normalized cross-correlation of latent representation at spatial locations $(w, h)$ and $(w + i, h + j)$, averaged across all latent elements of all images on the Kodak dataset.
   $w/o$ denotes the substitution of the CAE module with ChARM.
   }
   \vspace{-1em}
   \label{fig7}
\end{figure}


\subsubsection{Analysis of the CAE Module Design}

To demonstrate the superiority of our CAE module in entropy modeling, we conduct experiments with other entropy models~\cite{minnen2020channel, he2022elic, liu2023learned, li2024frequency}, as shown in Table~\ref{tab4}. 
The CAE module harnesses an SSM-enhanced hyperprior and group-wise conditioning to enhance compression efficiency and reduce redundancy. 
In Table~\ref{tab4}, the CAE module achieves superior rate-distortion performance and much fewer parameters compared to the second-best entropy model, \ie, TCM~\cite{liu2023learned}.
This experiment indicates that the CAE module not only outperforms existing entropy models in terms of rate-distortion performance but also improves compression effectiveness.


\input{tabs/tab5}

Furthermore, we conduct experiments to carefully verify the efficacy of the CAE module, as presented in Table~\ref{tab5}. 
In particular, we compare different approaches, including CNNs, Swin Transformers, and SSMs, to capture spatial dependencies.
Meanwhile, we also evaluate the effectiveness of channel dependencies.
The channel dependencies are captured in an autoregressive manner.
\textit{w/o} CAR means to directly estimate the distribution parameters of latent representation $y$ via a Mean \& Scale Hyperprior~\cite{minnen2018joint}.
This experiment highlights that the CAE module achieves significant improvements in compression performance by jointly modeling spatial and channel dependencies while maintaining efficiency.


In addition, our CAE module estimates the mean $\mu$ and scale $\sigma$ of latent representation $y$ via a hyperprior to eliminate the redundancy of latent representation $y$~\cite{balle2018variational, cheng2020learned}.
Therefore, we conduct the following analysis for latent correlation.
The latent correlation reflects the redundancy in $(y - \mu) / \sigma$. 
The spatial correlation maps in Fig.~\ref{fig7} illustrate the capabilities of different models in redundancy reduction. 
STF~(Fig.~\ref{fig7}(a)) and TCM~(Fig.~\ref{fig7}(b)) show higher correlations indicating less effective redundancy removal. 
In contrast, CMamba (\textit{w/o} CAE)~(Fig.~\ref{fig7}(c)) demonstrates improved redundancy reduction. 
Notably, our CMamba~(Fig.~\ref{fig7}(d)) achieves the lowest correlation across spatial positions benefiting from its global Effective Receptive Field and the integration of the CAE module. 
These results confirm the superiority of CMamba in decorrelating latent representations, thus leading to better compression performance with a lower Bitrate (0.42 bpp) and higher PSNR (34.38 dB).
