\section{Conclusion}

In this paper, we introduced CMamba, a hybrid image compression framework that combines the strengths of Convolutional Neural Networks (CNNs) and State Space Models (SSMs) to achieve a balance between high rate-distortion performance and low computational complexity. 
The proposed Content-Adaptive SSM (CA-SSM) module effectively integrates global content from SSMs with local details from CNNs, ensuring the preservation of critical image features during compression. 
Additionally, the Context-Aware Entropy (CAE) module enhances spatial and channel compression efficiency by reducing redundancies in latent representations, leveraging SSMs for spatial parameterization and an autoregressive approach for channel redundancy reduction. 
Notably, CMamba achieved substantial reductions in parameters, FLOPs, and decoding time, reinforcing its practical applicability in scenarios requiring efficient and high-performance image compression. 
By advancing the integration of SSMs and CNNs via the CA-SSM and CAE modules, CMamba represents a meaningful step forward in the field of learned image compression.
