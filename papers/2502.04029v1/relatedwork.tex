\section{Related Work}
% 주홍
\subsection{Social Robotics for Autistic Students} % (or special education)

The field of robotics has been widely explored to enhance skill development in autistic children. These technologies are primarily used to support learning and social development, with a particular focus on improving and assessing social communication skills. A variety of robotic forms, including both physical and virtual robots, have been utilized for this purpose \cite{Mohammed2020robot}.

Socially Assistive Robotics (SAR) represents a rapidly growing research field that focuses on designing and implementing robots that assist users through social interaction rather than physical engagement \cite{Diehl2012cu}\cite{Ricks2010tc}\cite{Syriopoulou-Delli2020ra}. SARs employed in autism intervention programs vary widely in form and function, including humanoid, animal-like, and machine-like systems, each differing in physical design and realism. Notable SARs include KASPAR, ZENO, Probo, and ZECA, which have been used in multiple studies \cite{Syriopoulou-Delli2020ra}. Additionally, commercial AI-powered robots, such as Nao and Pepper, have been introduced as communicative facilitators to assist autistic children in social interactions \cite{10.1145/3461615.3485421}\cite{Lemaignan2024pepper}. However, due to the limited availability of commercially suitable robotic platforms for autism intervention, many research groups have opted to develop custom-designed robots tailored to specific intervention needs. 

Studies have demonstrated positive effects of SARs on social behaviors in autistic children, including increased eye contact, enhanced verbal communication, improved imitation skills, greater physical engagement, enriched play interactions, reduced stereotypical behaviors, and heightened emotional responses \cite{Scassellati2012ar}.

Despite the promising potential of Socially Assistive Robotics (SARs) for autistic children, only a limited number of studies have investigated their long-term, continuous application \cite{conti2017dd}\cite{vagnetti2024social}. Most research has focused on short-term interventions, leaving gaps in understanding their sustained effectiveness in real-world environments. Therefore, ongoing evaluation of their reliability, adaptability, and usability in daily educational and therapeutic settings is essential. Further studies are needed to examine SAR effectiveness across diverse demographic factors, including sex, age, and cognitive ability \cite{Mohammed2020robot}. In addition, to ensure broad accessibility and widespread adoption, SARs must be affordable, scalable, and designed for everyday use in practical learning environments with daily settings. 

% 웅기
\subsection{Large Language Model for Robotics}

Recent advancements in robotics have increasingly leveraged Large Language Models (LLMs) to enhance robotic capabilities across various domains. LLMs such as GPT-4 and similar models are now being integrated into key robotic functions, including communication, perception, planning, and control \cite{wang2024large}\cite{kim2024survey}\cite{zeng2023large}. These integrations aim to equip robots with advanced cognitive abilities, enabling them to understand, process, and execute complex tasks based on natural language instructions.

Several notable examples highlight the transformative role of LLMs in robotics. RT-1, SayCan, and PaLM-E have demonstrated how robots can perform manipulation tasks, such as picking up, placing, and moving objects based on human instructions. The RT series (RT-1, RT-2, RT-X) has shown that robots can learn from large-scale data to generalize across a wide range of tasks \cite{DBLP:conf/rss/BrohanBCCDFGHHH23}\cite{pmlr-v229-zitkovich23a}\cite{vuong2023open}. SayCan integrates LLMs with robotic affordances, enabling context-aware task planning and execution in real-world environments \cite{Ahn2022DoAI}. PaLM-E further extends this by incorporating visual and perceptual inputs, allowing robots to reason and act based on both textual and environmental cues \cite{Driess2023PaLMEAE}.

Beyond research prototypes, companies like Figure AI and Tesla have introduced advanced humanoid robots, such as Figure AI’s autonomous humanoid and Tesla’s Optimus Gen 2, which demonstrate high-performance robotic interactions that may be enhanced by LLMs \cite{figure_ai}\cite{tesla_optimus_gen2}. These developments reflect a growing trend toward integrating LLMs into robotic systems, allowing for more natural, interactive, and intelligent behaviors.

In educational settings, studies have explored the use of LLMs to teach robotics-related content, enhancing learning experiences through interactive dialogues, personalized tutoring, and real-time explanations \cite{Kahl2024}\cite{shu2024llms}. However, research on integrating LLMs directly into educational robotics remains limited. The potential for LLMs to personalize learning, simulate complex robotic behaviors, and facilitate real-time problem-solving in robotics education remains a largely unexplored but promising area for future research.