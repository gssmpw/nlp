@inproceedings{10.1145/3657604.3662042,
author = {Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Williams, Joseph Jay and Rafferty, Anna N. and Stamper, John and Liut, Michael},
title = {Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662042},
doi = {10.1145/3657604.3662042},
abstract = {Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.}

@article{Liu2023LLMPEL,
  title={LLM+P: Empowering Large Language Models with Optimal Planning Proficiency},
  author={B. Liu and Yuqian Jiang and Xiaohan Zhang and Qian Liu and Shiqi Zhang and Joydeep Biswas and Peter Stone},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.11477},
  url={https://api.semanticscholar.org/CorpusID:258298051}
}

@inproceedings{Liu2024EvolutionOH,
  title={Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model},
  author={Fei Liu and Xialiang Tong and Mingxuan Yuan and Xi Lin and Fu Luo and Zhenkun Wang and Zhichao Lu and Qingfu Zhang},
  booktitle={International Conference on Machine Learning},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:266755732}
}

@article{article,
author = {Romera-Paredes, Bernardino and Barekatain, Mohammadamin and Novikov, Alexander and Balog, Matej and Kumar, M. and Dupont, Emilien and Ruiz, Francisco and Ellenberg, Jordan and Wang, Pengming and Fawzi, Omar and Kohli, Pushmeet and Fawzi, Alhussein},
year = {2023},
month = {12},
pages = {},
title = {Mathematical discoveries from program search with large language models},
volume = {625},
journal = {Nature},
doi = {10.1038/s41586-023-06924-6}
}

@inproceedings{cheng-etal-2022-improving,
    title = "Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning",
    author = "Cheng, Yi  and
      Liu, Wenge  and
      Li, Wenjie  and
      Wang, Jiashuo  and
      Zhao, Ruihui  and
      Liu, Bang  and
      Liang, Xiaodan  and
      Zheng, Yefeng",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.195",
    doi = "10.18653/v1/2022.emnlp-main.195",
    pages = "3014--3026",
    abstract = "Providing Emotional Support (ES) to soothe people in emotional distress is an essential capability in social interactions. Most existing researches on building ES conversation systems only considered single-turn interactions with users, which was over-simplified. In comparison, multi-turn ES conversation systems can provide ES more effectively, but face several new technical challenges, including: (1) how to adopt appropriate support strategies to achieve the long-term dialogue goal of comforting the user{'}s emotion; (2) how to dynamically model the user{'}s state. In this paper, we propose a novel system MultiESC to address these issues. For strategy planning, drawing inspiration from the A* search algorithm, we propose lookahead heuristics to estimate the future user feedback after using particular strategies, which helps to select strategies that can lead to the best long-term effects. For user state modeling, MultiESC focuses on capturing users{'} subtle emotional expressions and understanding their emotion causes. Extensive experiments show that MultiESC significantly outperforms competitive baselines in both dialogue generation and strategy planning.",
}

@misc{huang2022innermonologueembodiedreasoning,
      title={Inner Monologue: Embodied Reasoning through Planning with Language Models}, 
      author={Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and Pierre Sermanet and Noah Brown and Tomas Jackson and Linda Luu and Sergey Levine and Karol Hausman and Brian Ichter},
      year={2022},
      eprint={2207.05608},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2207.05608}, 
}

@misc{shinn2023reflexionlanguageagentsverbal,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.11366}, 
}

@inproceedings{vath-etal-2023-conversational,
    title = "Conversational Tree Search: A New Hybrid Dialog Task",
    author = {V{\"a}th, Dirk  and
      Vanderlyn, Lindsey  and
      Vu, Ngoc Thang},
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.91",
    doi = "10.18653/v1/2023.eacl-main.91",
    pages = "1264--1280",
    abstract = "Conversational interfaces provide a flexible and easy way for users to seek information that may otherwise be difficult or inconvenient to obtain. However, existing interfaces generally fall into one of two categories: FAQs, where users must have a concrete question in order to retrieve a general answer, or dialogs, where users must follow a pre-defined path but may receive a personalized answer. In this paper, we introduce Conversational Tree Search (CTS) as a new task that bridges the gap between FAQ-style information retrieval and task-oriented dialog, allowing domain-experts to define dialog trees which can then be converted to an efficient dialog policy that learns only to ask the questions necessary to navigate a user to their goal. We collect a dataset for the travel reimbursement domain and demonstrate a baseline as well as a novel deep Reinforcement Learning architecture for this task. Our results show that the new architecture combines the positive aspects of both the FAQ and dialog system used in the baseline and achieves higher goal completion while skipping unnecessary questions.",
}

