\section{Related Work}
\subsection{LLMs for Optimization}

LLMs have recently been used to address optimization problems through prompt engineering for specific issues____. However, relying solely on prompt engineering has proven to have limited effectiveness in complex optimization scenarios. Inspired by the automatic generation of heuristics, researchers have explored combining evolutionary computation~(EC) with LLMs to generate and refine heuristics. FunSearch____ presents a novel approach that searches within the function space, using LLMs to iteratively improve the quality of generated heuristics within an evolutionary framework. Evolution of Heuristics~(EoH)____ employs natural language to represent heuristic ideas; LLMs first generate natural language descriptions of heuristics, which are then used to produce executable heuristic code. This evolutionary search framework allows for the simultaneous improvement of both the descriptions and the code, contributing to EoH's effectiveness and efficiency. Similarly, Reflective Evolution (ReEvo)____ enhances the efficiency of heuristic evolution by combining evolutionary search with the self-reflection capabilities of LLMs.
\subsection{LLMs with Self-reflection and Planning}

Self-reflection is a cognitive process where an individual contemplates their own thoughts, feelings, and actions, enabling the recognition of mistakes during problem-solving and the continuous adjustment of strategies. Similarly, guiding LLMs to engage in self-reflection, allowing them to evaluate their generated content, can effectively improve their problem solving performance____.

Planning is a crucial tool for agents operating in complex and dynamic environments and making high-quality decisions. Traditional planning methods, which represent problems in a structured format, can leverage efficient search algorithms to generate the correct and optimal solutions____. This motivates research that combines LLMs with planning techniques, such as using MCTS to explore more comprehensive reasoning paths____.

However, existing LLM-based heuristic optimization methods often rely on evolutionary frameworks or incorporate reflection mechanisms, but typically employ direct iterative algorithms without principled strategies for guided exploration.  In contrast, our proposed PoH method synergistically combines self-reflection with planning, leveraging MCTS to efficiently search the vast heuristic space.