\section{How Do Tokens Contribute to Membership Inference Risks?}
\label{sec:analysis}
Compared to conventional classification problems, membership inference attacks in language modeling have significant differences. In particular, each query in traditional classification models requires only one prediction. On the other hand, each query to language models involves multiple token predictions due to the sequential nature of text. 
% This is because the input and output are sequences of tokens. 
This difference yields a question that how tokens contribute to overall sample-level membership inference risks. To answer this question, we perform a token-level analysis of membership inference risks. We calculate the MIA signal for each token as its prediction loss calibrated by a reference model~\cite{Carlini2020ExtractingTD}.
A smaller signal value indicates that the model has a significantly higher confidence than other reference model on predicting the token.
% Figure~\ref{fig:per-token-signal} illustrates the histogram of MIA signal values of tokens. More specifically, we perform a reference model-based attack~\cite{Carlini2020ExtractingTD}.

 \begin{figure}[htp]
    \centering
    \includegraphics[width=0.46\linewidth]{figs/per-token-signal-joint.pdf}
    \includegraphics[width=0.512\linewidth]{figs/mia-ranking.pdf}
    \caption{Token-level MIA signal analysis. The left figure presents the histogram of the MIA signals across tokens at the end of training, while the right figure illustrates the MIA signal ranking of tokens during training.}
    \label{fig:per-token-signal}
\end{figure}

Figure~\ref{fig:per-token-signal} (left) illustrates the histogram of MIA signal values of tokens of a sample (see Figure~\ref{fig:add-per-token-loss} in Appendix~\ref{sec:app-analysis} for additional histograms). 
% More specifically, we perform a reference model-based attack~\cite{Carlini2020ExtractingTD}. 
The non-member sample distribution centers around zero, while the member sample skews to the negative side. Consequently, the average aggregated MIA signal is below zero for members but around zero for non-members, leading to membership inference risks. Moreover, the MIA signal values vary for different tokens, so some tokens contribute more to the membership inference risks than the others. Figure~\ref{fig:per-token-signal} (right) illustrates the MIA signal ranking of tokens of a member sample over training steps (see Figure~\ref{fig:add-per-token-dynamics} in Appendix~\ref{sec:app-analysis} for additional samples). There is a complex changing dynamic in ranking between tokens before it becomes more stable at the end when the training converges. Overall, the analysis suggests that the sample-level membership inference risk in language modeling stem from the cumulative effect of many tokens. This poses challenges for defense methods that need token-level granularity to isolate and mitigate specific sources of leakage. Additionally, it is non-trivial to develop a defense method that widely affects a large number of tokens without disrupting the complex token dependencies essential for model utility.


% Generally, there are no significant outliers that dominate the overall sample-aggregated signal. The distribution of the non-member sample is centered around zero, while the distribution of the member sample skews toward the negative side. This suggests that sample-level membership risks in language modeling stem from the cumulative effect of many tokens rather than a few highly sensitive ones. The overall membership signal is an aggregation of small contributions from many tokens. This poses a challenge for defense methods that requires token-level granularity to isolate and mitigate specific sources of leakage. Additionally, it is non-trivial to develop a defense method that widely affects to a large number of tokens without disrupting the complex token dependencies essential for model utility.
