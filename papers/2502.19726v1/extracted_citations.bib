@inproceedings{Miladadvereg,
author = {Nasr, Milad and Shokri, Reza and Houmansadr, Amir},
title = {Machine Learning with Membership Privacy using Adversarial Regularization},
year = {2018},
isbn = {9781450356930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3243734.3243855},
doi = {10.1145/3243734.3243855},
booktitle = {Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
pages = {634–646},
numpages = {13},
keywords = {adversarial process, data privacy, indistinguishability, inference attacks, machine learning, membership privacy, min-max game},
location = {Toronto, Canada},
series = {CCS '18}
}

@misc{amit2024sok,
      title={SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks}, 
      author={Guy Amit and Abigail Goldsteen and Ariel Farkash},
      year={2024},
      eprint={2403.08481},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.08481}, 
}

@misc{bu2023groupwise,
      title={On the accuracy and efficiency of group-wise clipping in differentially private optimization}, 
      author={Zhiqi Bu and Ruixuan Liu and Yu-Xiang Wang and Sheng Zha and George Karypis},
      year={2023},
      eprint={2310.19215},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.19215}, 
}

@article{bu2023zero,
  title={Zero redundancy distributed learning with differential privacy},
  author={Bu, Zhiqi and Chiu, Justin and Liu, Ruixuan and Zha, Sheng and Karypis, George},
  booktitle={ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML},
  journal={arXiv preprint arXiv:2311.11822},
  year={2023}
}

@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929--1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@inproceedings{duan2024membership,
  title={Do Membership Inference Attacks Work on Large Language Models?}, 
  author={Michael Duan and Anshuman Suri and Niloofar Mireshghallah and Sewon Min and Weijia Shi and Luke Zettlemoyer and Yulia Tsvetkov and Yejin Choi and David Evans and Hannaneh Hajishirzi},
  year={2024},
  booktitle={Conference on Language Modeling (COLM)},
}

@inproceedings{kandpal2022deduplicating,
  title={Deduplicating Training Data Mitigates Privacy Risks in Language Models},
  author={Kandpal, Nikhil and Wallace, Eric and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={10697--10707},
  year={2022},
  organization={PMLR}
}

@inproceedings{lee2022deduplicating,
  title={Deduplicating Training Data Makes Language Models Better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={8424--8445},
  year={2022},
  organization={Association for Computational Linguistics}
}

@misc{liu2024exp,
      title={ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation}, 
      author={Ruixuan Liu and Toan Tran and Tianhao Wang and Hongsheng Hu and Shuo Wang and Li Xiong},
      year={2024},
      eprint={2412.21123},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2412.21123}, 
}

@article{llmpbe,
author = {Li, Qinbin and Hong, Junyuan and Xie, Chulin and Tan, Jeffrey and Xin, Rachel and Hou, Junyi and Yin, Xavier and Wang, Zhun and Hendrycks, Dan and Wang, Zhangyang and Li, Bo and He, Bingsheng and Song, Dawn},
title = {LLM-PBE: Assessing Data Privacy in Large Language Models},
year = {2024},
issue_date = {July 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {11},
issn = {2150-8097},
doi = {10.14778/3681954.3681994},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {3201–3214},
numpages = {14}
}

@misc{lowy2024dptheo,
      title={Why Does Differential Privacy with Large Epsilon Defend Against Practical Membership Inference Attacks?}, 
      author={Andrew Lowy and Zhuohang Li and Jing Liu and Toshiaki Koike-Akino and Kieran Parsons and Ye Wang},
      year={2024},
      eprint={2402.09540},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2402.09540}, 
}

@article{miasurvey,
author = {Hu, Hongsheng and Salcic, Zoran and Sun, Lichao and Dobbie, Gillian and Yu, Philip S. and Zhang, Xuyun},
title = {Membership Inference Attacks on Machine Learning: A Survey},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {11s},
issn = {0360-0300},
url = {https://doi.org/10.1145/3523273},
doi = {10.1145/3523273},
journal = {ACM Comput. Surv.},
month = sep,
articleno = {235},
numpages = {37},
keywords = {Membership inference attacks, deep leaning, privacy risk, differential privacy}
}

@inproceedings{neighbourattack,
    title = "Membership Inference Attacks against Language Models via Neighbourhood Comparison",
    author = "Mattern, Justus  and
      Mireshghallah, Fatemehsadat  and
      Jin, Zhijing  and
      Schoelkopf, Bernhard  and
      Sachan, Mrinmaya  and
      Berg-Kirkpatrick, Taylor",
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.719/",
    doi = "10.18653/v1/2023.findings-acl.719",
    pages = "11330--11343",
}

@misc{p2022textanonymbench,
      title={The Text Anonymization Benchmark (TAB): A Dedicated Corpus and Evaluation Framework for Text Anonymization}, 
      author={Ildikó Pilán and Pierre Lison and Lilja Øvrelid and Anthi Papadopoulou and David Sánchez and Montserrat Batet},
      year={2022},
      eprint={2202.00443},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.00443}, 
}

@inproceedings{precurious,
author = {Liu, Ruixuan and Wang, Tianhao and Cao, Yang and Xiong, Li},
title = {PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690279},
doi = {10.1145/3658644.3690279},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3511–3524},
numpages = {14},
keywords = {language model, pre-training, privacy attack},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@misc{puerto2025smia,
      title={Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models}, 
      author={Haritz Puerto and Martin Gubri and Sangdoo Yun and Seong Joon Oh},
      year={2025},
      eprint={2411.00154},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.00154}, 
}

@inproceedings{shi2022just,
  title={Just Fine-tune Twice: Selective Differential Privacy for Large Language Models},
  author={Shi, Weiyan and Shea, Ryan and Chen, Si and Zhang, Chiyuan and Jia, Ruoxi and Yu, Zhou},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={6296--6311},
  year={2022},
  organization={Association for Computational Linguistics}
}

