% \begin{table*}[htp]
%     \centering
%     \begin{tabular}{cl|ccccc|ccccc}
%      \multirow{3}{*}{\textbf{LLM}}  & \multirow{3}{*}{\textbf{Method}} &  \multicolumn{5}{c|}{\textbf{CCNews}} & \multicolumn{5}{c}{\textbf{Wikipedia}} \\ \cmidrule(lr){3-7}  \cmidrule(lr){8-12}
%       &  & PPL & Loss & Ref & min-k & \multicolumn{1}{c|}{zlib} & PPL & Loss & Ref & min-k & zlib \\ \midrule
%       \multirow{4}{*}{GPT2} & \textit{Base} & \textit{29.442} & \textit{0.018} & \textit{0.002} & \textit{0.022} & \textit{0.006} & \textit{34.429} & \textit{0.002} & \textit{0.014} & \textit{0.010} & \textit{0.002} \\ 
%       \multirow{4}{*}{124M} & FT & \textbf{21.861} & 0.030 & 0.026 & 0.016 & 0.016 & \textbf{12.729} & 0.018 & 0.574 & 0.016 & 0.014 \\
%       & Goldfish & 21.902 & 0.030 & 0.024 & 0.028 & 0.016 & 12.853 & 0.018 & 0.632 & 0.016 & 0.010 \\
%       & DPSGD & 26.022 & \textbf{0.018} & \textbf{0.004} & \textbf{0.018} & 0.008 & 18.523 & \textbf{0.004} & 0.036 & 0.018 & 0.006 \\
%       & \methodname & 23.733 & 0.030 & 0.022 & 0.026 & \textbf{0.006} & 13.628 & 0.014 & \textbf{0.010} & \textbf{0.014} & \textbf{0.004} \\ \midrule
      
%       \multirow{4}{*}{Pythia} & \textit{Base} & \textit{13.973} & \textit{0.002} & \textit{0.008} & \textit{0.020} & \textit{0.014} & \textit{10.287} & \textit{0.002} & \textit{0.014} & \textit{0.006} & \textit{0.008} \\ 
%       \multirow{4}{*}{1.4B} & FT & 11.922 & 0.014 & 0.008 & 0.022 & 0.020 & \textbf{6.439} & 0.020 & 0.440 & 0.010 & 0.020 \\
%       & Goldfish & \textbf{11.903} & 0.014 & 0.008 & 0.024 & 0.018 & 6.465 & 0.016 & 0.412 & 0.010 & 0.020 \\
%       & DPSGD & 13.286 & \textbf{0.002} & \textbf{0.004} & \textbf{0.018} & \textbf{0.014} & 7.751 & \textbf{0.004} & \textbf{0.016} & {0.010} & \textbf{0.004} \\
%       & \methodname & 12.670 & 0.004 & 0.020 & \textbf{0.018} & 0.016 & 6.553 & 0.008 & 0.030 & \textbf{0.006} & 0.006 \\ \midrule
      
%       \multirow{4}{*}{Llama-2} & \textit{Base} & \textit{9.364} & \textit{0.006} & \textit{0.006} & \textit{0.024} & \textit{0.006} & \textit{7.014} & \textit{0.006} & \textit{0.016} & \textit{0.016} & \textit{0.010} \\ 
%       \multirow{4}{*}{7B} & FT & \textbf{6.261} & 0.002 & 0.018 & 0.002 & 0.002 & \textbf{3.830} & 0.028 & 0.170 & 0.030 & 0.028 \\
%       & Goldfish & 6.280 & 0.002 & 0.018 & 0.002 & 0.006 & 3.839 & 0.028 & 0.198 & 0.028 & 0.028 \\
%       & DPSGD & 6.777 & 0.008 & 0.026 & 0.016 & 0.010 & 4.490 & \textbf{0.006} & 0.014 & \textbf{0.020} & \textbf{0.010} \\
%       & \methodname & 6.395 & \textbf{0.002} & \textbf{0.020} & \textbf{0.004} & \textbf{0.002} & 4.006 & 0.010 & \textbf{0.002} & 0.028 & 0.012 \\ 
%     \end{tabular}
%     \caption{TPR at FPR of 1\% \textcolor{red}{TODO: check consistency with the main table of MIA AUC scores}}
%     \label{tab:tpr}
% \end{table*}


\begin{table*}[!ht]
  \centering
  \resizebox{\textwidth}{!}{\begin{tabular}{cl|ccccc|ccccc}
   \multirow{3}{*}{\textbf{LLM}}  & \multirow{3}{*}{\textbf{Method}} &  \multicolumn{5}{c|}{\textbf{Wikipedia}} & \multicolumn{5}{c}{\textbf{CC-news}} \\ \cmidrule(lr){3-7}  \cmidrule(lr){8-12}
    &  & PPL & Loss & Ref & min-k & \multicolumn{1}{c|}{zlib} & PPL & Loss & Ref & min-k & zlib \\ \midrule
    \multirow{4}{*}{GPT2} & \textit{Base} & \textit{34.429} & \textit{0.002} & \textit{0.014} & \textit{0.010} & \textit{0.002} & \textit{29.442} & \textit{0.018} & \textit{0.002} & \textit{0.022} & \textit{0.006} \\ 
    \multirow{4}{*}{124M} & FT & \textbf{12.729} & 0.018 & 0.574 & 0.016 & 0.014 & \textbf{21.861} & 0.030 & 0.026 & 0.016 & 0.016 \\
    & Goldfish & 12.853 & 0.018 & 0.632 & 0.016 & 0.010 & 21.902 & 0.030 & 0.024 & 0.028 & 0.016 \\
    & DPSGD & 18.523 & \textbf{0.004} & 0.036 & 0.018 & 0.006 & 26.022 & \textbf{0.018} & \textbf{0.004} & \textbf{0.018} & 0.008 \\
    & \methodname & 13.628 & 0.014 & \textbf{0.010} & \textbf{0.014} & \textbf{0.004} & 23.733 & 0.030 & 0.022 & 0.026 & \textbf{0.006} \\ \midrule
    
    \multirow{4}{*}{Pythia} & \textit{Base} & \textit{10.287} & \textit{0.002} & \textit{0.014} & \textit{0.006} & \textit{0.008} & \textit{13.973} & \textit{0.002} & \textit{0.008} & \textit{0.020} & \textit{0.014} \\ 
    \multirow{4}{*}{1.4B} & FT & \textbf{6.439} & 0.020 & 0.440 & 0.010 & 0.020 & 11.922 & 0.014 & 0.008 & 0.022 & 0.020 \\
    & Goldfish & 6.465 & 0.016 & 0.412 & 0.010 & 0.020 & \textbf{11.903} & 0.014 & 0.008 & 0.024 & 0.018 \\
    & DPSGD & 7.751 & \textbf{0.004} & \textbf{0.016} & {0.010} & \textbf{0.004} & 13.286 & \textbf{0.002} & \textbf{0.004} & \textbf{0.018} & \textbf{0.014} \\
    & \methodname & 6.553 & 0.008 & 0.030 & \textbf{0.006} & 0.006 & 12.670 & 0.004 & 0.020 & \textbf{0.018} & 0.016 \\ \midrule
    
    \multirow{4}{*}{Llama-2} & \textit{Base} & \textit{7.014} & \textit{0.006} & \textit{0.016} & \textit{0.016} & \textit{0.010} & \textit{9.364} & \textit{0.006} & \textit{0.006} & \textit{0.024} & \textit{0.006} \\ 
    \multirow{4}{*}{7B} & FT & \textbf{3.830} & 0.028 & 0.170 & 0.030 & 0.028 & \textbf{6.261} & 0.002 & 0.018 & 0.002 & 0.002 \\
    & Goldfish & 3.839 & 0.028 & 0.198 & 0.028 & 0.028 & 6.280 & 0.002 & 0.018 & 0.002 & 0.006 \\
    & DPSGD & 4.490 & \textbf{0.006} & 0.014 & \textbf{0.020} & \textbf{0.010} & 6.777 & 0.008 & 0.026 & 0.016 & 0.010 \\
    & \methodname & 4.006 & 0.010 & \textbf{0.002} & 0.028 & 0.012 & 6.395 & \textbf{0.002} & \textbf{0.020} & \textbf{0.004} & \textbf{0.002} \\ 
  \end{tabular}}
  \caption{Overall Evaluation: Perplexity (PPL) and TPR at FPR of 1\% scores of the MIAs with different signals (Loss/Ref/Min-k/Zlib). For all metrics, the lower the value, the better the result.}
  \label{tab:tpr}
\end{table*}