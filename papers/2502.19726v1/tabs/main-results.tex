% \begin{table*}[h]
%     \centering
%     \begin{tabular}{cl|ccccc|ccccc}
%      \multirow{3}{*}{\textbf{LLM}}  & \multirow{3}{*}{\textbf{Method}} &  \multicolumn{5}{c|}{\textbf{CCNews}} & \multicolumn{5}{c}{\textbf{Wikipedia}} \\ \cmidrule(lr){3-7}  \cmidrule(lr){8-12}
%       &  & PPL & Loss & Ref & min-k & \multicolumn{1}{c|}{zlib} & PPL & Loss & Ref & min-k & zlib \\ \midrule
%       \multirow{4}{*}{GPT2} & \textit{Base} & \textit{29.442} & \textit{0.505} & \textit{0.498} & \textit{0.520} & \textit{0.500} & \textit{34.429} & \textit{0.473} & \textit{0.513} & \textit{0.446} & \textit{0.497} \\ 
%       \multirow{4}{*}{124M} & FT & \textbf{21.861} & 0.607 & 0.855 & 0.549 & 0.569 & \textbf{12.729} & 0.577 & 0.967 & 0.489 & 0.544 \\
%       & Goldfish & 21.902 & 0.608 & 0.855 & 0.547 & 0.570 & 12.853 & 0.565 & 0.954 & 0.486 & 0.537 \\
%       & DPSGD & 26.022 & 0.507 & 0.513 & \textbf{0.521} & 0.502 & 18.523 & 0.463 & 0.536 & \textbf{0.448} & 0.491 \\
%       & \methodname & 23.733 & \textbf{0.502} & \textbf{0.495} & 0.529 & \textbf{0.499} & 13.628 & \textbf{0.454} & \textbf{0.463} & 0.470 & \textbf{0.485} \\ \midrule
      
%       \multirow{4}{*}{Pythia} & \textit{Base} & \textit{13.973} & \textit{0.507} & \textit{0.512} & \textit{0.528} & \textit{0.501} & \textit{10.287} & \textit{0.466} & \textit{0.503} & \textit{0.464} & \textit{0.489}\\ 
%       \multirow{4}{*}{1.4B} & FT & 11.922 & 0.602 & 0.857 & 0.541 & 0.574 & \textbf{6.439} & 0.578 & 0.985 & 0.484 & 0.557 \\
%       & Goldfish & \textbf{11.903} & 0.609 & 0.862 & 0.543 & 0.579 & 6.465 & 0.564 & 0.981 & 0.482 & 0.546 \\
%       & DPSGD & 13.286 & 0.512 & 0.531 & 0.528 & 0.503 & 7.751 & 0.469 & 0.524 & \textbf{0.462} & 0.488 \\
%       & \methodname & 12.670 & \textbf{0.501} & \textbf{0.460} & \textbf{0.524} & \textbf{0.499} & 6.553 & \textbf{0.468} & \textbf{0.485} & 0.472 & \textbf{0.485} \\ \midrule
      
%       \multirow{4}{*}{Llama-2} & \textit{Base} & \textit{9.364} & \textit{0.505} & \textit{0.495} & \textit{0.516} & \textit{0.503} & \textit{7.014} & \textit{0.458} & \textit{0.491} & \textit{0.476} & \textit{0.488} \\ 
%       \multirow{4}{*}{7B} & FT & \textbf{6.261} & 0.559 & 0.798 & 0.536 & 0.548 & \textbf{3.830} & 0.524 & 0.936 & 0.494 & 0.530 \\
%       & Goldfish & 6.280 & 0.552 & 0.780 & 0.533 & 0.541 & 3.839 & 0.518 & 0.929 & 0.492 & 0.525 \\
%       & DPSGD & 6.777 & 0.509 & 0.538 & 0.523 & 0.504 & 4.490 & 0.466 & 0.516 & \textbf{0.470} & 0.487 \\
%       & \methodname & 6.395 & \textbf{0.507} & \textbf{0.482} & \textbf{0.518} & \textbf{0.500} & 4.006 & \textbf{0.458} & \textbf{0.440} & 0.473 & \textbf{0.480} \\ 
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:main_result}
% \end{table*}


\begin{table*}[h]
  \centering
  \resizebox{0.9\textwidth}{!}{\begin{tabular}{cl|ccccc|ccccc}
  \toprule[1pt]
   \multirow{3}{*}{\textbf{LLM}}  & \multirow{3}{*}{\textbf{Method}} &  \multicolumn{5}{c|}{\textbf{Wikipedia}} & \multicolumn{5}{c}{\textbf{CC-news}} \\ \cmidrule(lr){3-7}  \cmidrule(lr){8-12}
    &  & PPL & Loss & Ref & Min-k & \multicolumn{1}{c|}{Zlib} & PPL & Loss & Ref & Min-k & Zlib \\ \midrule
    \multirow{4}{*}{GPT2} & \textit{Base} & \textit{34.429} & \textit{0.473} & \textit{0.513} & \textit{0.446} & \textit{0.497} & \textit{29.442} & \textit{0.505} & \textit{0.498} & \textit{0.520} & \textit{0.500} \\ 
    \multirow{4}{*}{124M} & FT & \textbf{12.729} & 0.577 & 0.967 & 0.489 & 0.544 & \textbf{21.861} & 0.607 & 0.855 & 0.549 & 0.569 \\
    & Goldfish & 12.853 & 0.565 & 0.954 & 0.486 & 0.537 & 21.902 & 0.608 & 0.855 & 0.547 & 0.570 \\
    & DPSGD & 18.523 & 0.463 & 0.536 & \textbf{0.448} & 0.491 & 26.022 & 0.507 & 0.513 & \textbf{0.521} & 0.502 \\
    & \methodname & 13.628 & \textbf{0.454} & \textbf{0.463} & 0.470 & \textbf{0.485} & 23.733 & \textbf{0.502} & \textbf{0.495} & 0.529 & \textbf{0.499} \\ \midrule
    
    \multirow{4}{*}{Pythia} & \textit{Base} & \textit{10.287} & \textit{0.466} & \textit{0.503} & \textit{0.464} & \textit{0.489} & \textit{13.973} & \textit{0.507} & \textit{0.512} & \textit{0.528} & \textit{0.501}\\ 
    \multirow{4}{*}{1.4B} & FT & \textbf{6.439} & 0.578 & 0.985 & 0.484 & 0.557 & 11.922 & 0.602 & 0.857 & 0.541 & 0.574 \\
    & Goldfish & 6.465 & 0.564 & 0.981 & 0.482 & 0.546 & \textbf{11.903} & 0.609 & 0.862 & 0.543 & 0.579 \\
    & DPSGD & 7.751 & 0.469 & 0.524 & \textbf{0.462} & 0.488 & 13.286 & 0.512 & 0.531 & 0.528 & 0.503 \\
    & \methodname & 6.553 & \textbf{0.468} & \textbf{0.485} & 0.472 & \textbf{0.485} & 12.670 & \textbf{0.501} & \textbf{0.460} & \textbf{0.524} & \textbf{0.499} \\ \midrule
    
    \multirow{4}{*}{Llama-2} & \textit{Base} & \textit{7.014} & \textit{0.458} & \textit{0.491} & \textit{0.476} & \textit{0.488} & \textit{9.364} & \textit{0.505} & \textit{0.495} & \textit{0.516} & \textit{0.503} \\ 
    \multirow{4}{*}{7B} & FT & \textbf{3.830} & 0.524 & 0.936 & 0.494 & 0.530 & \textbf{6.261} & 0.559 & 0.798 & 0.536 & 0.548 \\
    & Goldfish & 3.839 & 0.518 & 0.929 & 0.492 & 0.525 & 6.280 & 0.552 & 0.780 & 0.533 & 0.541 \\
    & DPSGD & 4.490 & 0.466 & 0.516 & \textbf{0.470} & 0.487 & 6.777 & 0.509 & 0.538 & 0.523 & 0.504 \\
    & \methodname & 4.006 & \textbf{0.458} & \textbf{0.440} & 0.473 & \textbf{0.480} & 6.395 & \textbf{0.507} & \textbf{0.482} & \textbf{0.518} & \textbf{0.500} \\
    \bottomrule[1pt]
  \end{tabular}}
  \caption{Overall Evaluation: Perplexity (PPL) and AUC scores of the MIAs with different signals (Loss/Ref/Min-k/Zlib). For all metrics, the lower the value, the better the result. \textit{Base} in the method column indicates the pretrained LLMs without fine-tuning, thus it indicates lower bound for both utility and privacy risk.}
  \label{tab:main_result}
\end{table*}

% \begin{table*}[h]
%   \centering
%   \begin{tabular}{cl|ccccc|ccccc}
%   \multirow{3}{*}{\textbf{LLM}} & \multirow{3}{*}{\textbf{Method}} & \multicolumn{5}{c|}{\textbf{Wikipedia}} & \multicolumn{5}{c}{\textbf{CCNews}} \\
%   \cmidrule(lr){3-7} \cmidrule(lr){8-12}
%   & & PPL & Loss & Ref & min-k & \multicolumn{1}{c|}{zlib} & PPL & Loss & Ref & min-k & zlib \\
%   \midrule
%   \multirow{4}{*}{GPT2} & \textit{Base} & \textit{34.429} & \textit{0.473} & \textit{0.513} & \textit{0.446} & \textit{0.497} & \textit{29.442} & \textit{0.505} & \textit{0.498} & \textit{0.520} & \textit{0.500} \\
%   \multirow{4}{*}{124M} & FT & \textbf{12.729} & 0.577 & 0.967 & 0.489 & 0.544 & \textbf{21.861} & 0.607 & 0.855 & 0.549 & 0.569 \\
%   & Goldfish & 12.853 & 0.565 & 0.954 & 0.486 & 0.537 & 21.902 & 0.608 & 0.855 & 0.547 & 0.570 \\
%   & DPSGD & 18.523 & 0.463 & 0.536 & \textbf{0.448} & 0.491 & 26.022 & 0.507 & 0.513 & \textbf{0.521} & 0.502 \\
%   & \methodname & 13.628 & \textbf{0.454} & \textbf{0.463} & 0.470 & \textbf{0.485} & 23.733 & \textbf{0.502} & \textbf{0.495} & 0.529 & \textbf{0.499} \\
%   \midrule
%   \multirow{4}{*}{Pythia} & \textit{Base} & \textit{10.287} & \textit{0.466} & \textit{0.503} & \textit{0.464} & \textit{0.489} & \textit{13.973} & \textit{0.507} & \textit{0.512} & \textit{0.528} & \textit{0.501} \\
%   \multirow{4}{*}{1.4B} & FT & \textbf{6.439} & 0.578 & 0.985 & 0.484 & 0.557 & 11.922 & 0.602 & 0.857 & 0.541 & 0.574 \\
%   & Goldfish & 6.465 & 0.564 & 0.981 & 0.482 & 0.546 & \textbf{11.903} & 0.609 & 0.862 & 0.543 & 0.579 \\
%   & DPSGD & 7.751 & 0.469 & 0.524 & \textbf{0.462} & 0.488 & 13.286 & 0.512 & 0.531 & 0.528 & 0.503 \\
%   & \methodname & 6.553 & \textbf{0.468} & \textbf{0.485} & 0.472 & \textbf{0.485} & 12.670 & \textbf{0.501} & \textbf{0.460} & \textbf{0.524} & \textbf{0.499} \\
%   \midrule
%   \multirow{4}{*}{Llama-2} & \textit{Base} & \textit{7.014} & \textit{0.458} & \textit{0.491} & \textit{0.476} & \textit{0.488} & \textit{9.364} & \textit{0.505} & \textit{0.495} & \textit{0.516} & \textit{0.503} \\
%   \multirow{4}{*}{7B} & FT & \textbf{3.830} & 0.524 & 0.936 & 0.494 & 0.530 & \textbf{6.261} & 0.559 & 0.798 & 0.536 & 0.548 \\
%   & Goldfish & 3.839 & 0.518 & 0.929 & 0.492 & 0.525 & 6.280 & 0.552 & 0.780 & 0.533 & 0.541 \\
%   & DPSGD & 4.490 & 0.466 & 0.516 & \textbf{0.470} & 0.487 & 6.777 & 0.509 & 0.538 & 0.523 & 0.504 \\
%   & \methodname & 4.006 & \textbf{0.458} & \textbf{0.440} & 0.473 & \textbf{0.480} & 6.395 & \textbf{0.507} & \textbf{0.482} & \textbf{0.518} & \textbf{0.500} \\
%   \end{tabular}
%   \caption{Caption}
%   \label{tab:main_result}
%   \end{table*}
  