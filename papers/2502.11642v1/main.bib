@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


%%added

%% nerf 
@article{shen2021deep,
  title={Deep marching tetrahedra: a hybrid representation for high-resolution 3d shape synthesis},
  author={Shen, Tianchang and Gao, Jun and Yin, Kangxue and Liu, Ming-Yu and Fidler, Sanja},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={6087--6101},
  year={2021}
}
@article{wang2021neus,
  title={Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction},
  author={Wang, Peng and Liu, Lingjie and Liu, Yuan and Theobalt, Christian and Komura, Taku and Wang, Wenping},
  journal={arXiv preprint arXiv:2106.10689},
  year={2021}
}

@article{mildenhall2021nerf,
  title={Nerf: Representing scenes as neural radiance fields for view synthesis},
  author={Mildenhall, Ben and Srinivasan, Pratul P and Tancik, Matthew and Barron, Jonathan T and Ramamoorthi, Ravi and Ng, Ren},
  journal={Communications of the ACM},
  volume={65},
  number={1},
  pages={99--106},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{barron2021mip,
  title={Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields},
  author={Barron, Jonathan T and Mildenhall, Ben and Tancik, Matthew and Hedman, Peter and Martin-Brualla, Ricardo and Srinivasan, Pratul P},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5855--5864},
  year={2021}
}
@inproceedings{hedman2021baking,
  title={Baking neural radiance fields for real-time view synthesis},
  author={Hedman, Peter and Srinivasan, Pratul P and Mildenhall, Ben and Barron, Jonathan T and Debevec, Paul},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5875--5884},
  year={2021}
}

@article{nerf++,
  title={Nerf++: Analyzing and improving neural radiance fields},
  author={Zhang, Kai and Riegler, Gernot and Snavely, Noah and Koltun, Vladlen},
  journal={arXiv preprint arXiv:2010.07492},
  year={2020}
}
@article{nerf--,
  title={NeRF--: Neural Radiance Fields Without Known Camera Parameters},
  author={Wang, Zirui and Wu, Shangzhe and Xie, Weidi and Chen, Min and Prisacariu, Victor Adrian},
  journal={arXiv preprint arXiv:2102.07064},
  year={2021}
}
@article{GRAF,
  title={GRAF: Generative radiance fields for 3d-aware image synthesis},
  author={Schwarz, Katja and Liao, Yiyi and Niemeyer, Michael and Geiger, Andreas},
  journal={arXiv preprint arXiv:2007.02442},
  year={2020}
}

@inproceedings{GIRAFFE,
  title={GIRAFFE: Representing scenes as compositional generative neural feature fields},
  author={Niemeyer, Michael and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11453--11464},
  year={2021}
}

@inproceedings{pigan,
  title={pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis},
  author={Chan, Eric R and Monteiro, Marco and Kellnhofer, Petr and Wu, Jiajun and Wetzstein, Gordon},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5799--5809},
  year={2021}
}

@inproceedings{gao2021dynamic,
  title={Dynamic view synthesis from dynamic monocular video},
  author={Gao, Chen and Saraf, Ayush and Kopf, Johannes and Huang, Jia-Bin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5712--5721},
  year={2021}
}
@inproceedings{pumarola2021d,
  title={D-nerf: Neural radiance fields for dynamic scenes},
  author={Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10318--10327},
  year={2021}
}
@inproceedings{li2021neural,
  title={Neural scene flow fields for space-time view synthesis of dynamic scenes},
  author={Li, Zhengqi and Niklaus, Simon and Snavely, Noah and Wang, Oliver},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6498--6508},
  year={2021}
}

%%humannerf 

@article{su2021nerf,
  title={A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering},
  author={Su, Shih-Yang and Yu, Frank and Zollhoefer, Michael and Rhodin, Helge},
  journal={arXiv preprint arXiv:2102.06199},
  year={2021}
}
@article{loper2015smpl,
  title={SMPL: A skinned multi-person linear model},
  author={Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J},
  journal={ACM transactions on graphics (TOG)},
  volume={34},
  number={6},
  pages={1--16},
  year={2015},
  publisher={ACM New York, NY, USA}
}

@inproceedings{weng2022humannerf,
  title={Humannerf: Free-viewpoint rendering of moving people from monocular video},
  author={Weng, Chung-Yi and Curless, Brian and Srinivasan, Pratul P and Barron, Jonathan T and Kemelmacher-Shlizerman, Ira},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16210--16220},
  year={2022}
}

@inproceedings{jiang2022neuman,
  title={Neuman: Neural human radiance field from a single video},
  author={Jiang, Wei and Yi, Kwang Moo and Samei, Golnoosh and Tuzel, Oncel and Ranjan, Anurag},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXII},
  pages={402--418},
  year={2022},
  organization={Springer}
}
@inproceedings{peng2021animatable,
  title={Animatable neural radiance fields for modeling dynamic human bodies},
  author={Peng, Sida and Dong, Junting and Wang, Qianqian and Zhang, Shangzhan and Shuai, Qing and Zhou, Xiaowei and Bao, Hujun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14314--14323},
  year={2021}
}

@article{weng2020vid2actor,
  title={Vid2actor: Free-viewpoint animatable person synthesis from video in the wild},
  author={Weng, Chung-Yi and Curless, Brian and Kemelmacher-Shlizerman, Ira},
  journal={arXiv preprint arXiv:2012.12884},
  year={2020}
}
@inproceedings{li2022tava,
  title={Tava: Template-free animatable volumetric actors},
  author={Li, Ruilong and Tanke, Julian and Vo, Minh and Zollh{\"o}fer, Michael and Gall, J{\"u}rgen and Kanazawa, Angjoo and Lassner, Christoph},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXII},
  pages={419--436},
  year={2022},
  organization={Springer}
}


@inproceedings{chen2021snarf,
  title={SNARF: Differentiable forward skinning for animating non-rigid neural implicit shapes},
  author={Chen, Xu and Zheng, Yufeng and Black, Michael J and Hilliges, Otmar and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11594--11604},
  year={2021}
}


@inproceedings{zheng2021deepmulticap,
  title={Deepmulticap: Performance capture of multiple characters using sparse multiview cameras},
  author={Zheng, Yang and Shao, Ruizhi and Zhang, Yuxiang and Yu, Tao and Zheng, Zerong and Dai, Qionghai and Liu, Yebin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6239--6249},
  year={2021}
}

@inproceedings{peng2021neural,
  title={Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans},
  author={Peng, Sida and Zhang, Yuanqing and Xu, Yinghao and Wang, Qianqian and Shuai, Qing and Bao, Hujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9054--9063},
  year={2021}
}
@article{ionescu2013human3,
  title={Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments},
  author={Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={36},
  number={7},
  pages={1325--1339},
  year={2013},
  publisher={IEEE}
}

% 3D meshes


@inproceedings{saito2019pifu,
  title={Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization},
  author={Saito, Shunsuke and Huang, Zeng and Natsume, Ryota and Morishima, Shigeo and Kanazawa, Angjoo and Li, Hao},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2304--2314},
  year={2019}
}
@article{zheng2021pamir,
  title={Pamir: Parametric model-conditioned implicit representation for image-based human reconstruction},
  author={Zheng, Zerong and Yu, Tao and Liu, Yebin and Dai, Qionghai},
  journal=PAMI,
  year={2021},
  publisher={IEEE}
}
@inproceedings{shim2022refu,
  title={ReFu: Refine and Fuse the Unobserved View for Detail-Preserving Single-Image 3D Human Reconstruction},
  author={Shim, Gyumin and Lee, Minsoo and Choo, Jaegul},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={6850--6859},
  year={2022}
}
@inproceedings{saito2020pifuhd,
  title={Pifuhd: Multi-level pixel-aligned implicit function for high-resolution 3d human digitization},
  author={Saito, Shunsuke and Simon, Tomas and Saragih, Jason and Joo, Hanbyul},
  booktitle=CVPR,
  pages={84--93},
  year={2020}
}
@article{he2020geo,
  title={Geo-pifu: Geometry and pixel aligned implicit functions for single-view human reconstruction},
  author={He, Tong and Collomosse, John and Jin, Hailin and Soatto, Stefano},
  journal=NIPS,
  volume={33},
  pages={9276--9287},
  year={2020}
}
@inproceedings{huang2017towards,
  title={Towards accurate marker-less human shape and pose estimation over time},
  author={Huang, Yinghao and Bogo, Federica and Lassner, Christoph and Kanazawa, Angjoo and Gehler, Peter V and Romero, Javier and Akhter, Ijaz and Black, Michael J},
  booktitle=TDV,
  pages={421--430},
  year={2017},
  organization={IEEE}
}

% Fewshot or generalization methods
@inproceedings{yu2021pixelnerf,
  title={pixelnerf: Neural radiance fields from one or few images},
  author={Yu, Alex and Ye, Vickie and Tancik, Matthew and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4578--4587},
  year={2021}
}
@inproceedings{wang2021ibrnet,
  title={Ibrnet: Learning multi-view image-based rendering},
  author={Wang, Qianqian and Wang, Zhicheng and Genova, Kyle and Srinivasan, Pratul P and Zhou, Howard and Barron, Jonathan T and Martin-Brualla, Ricardo and Snavely, Noah and Funkhouser, Thomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4690--4699},
  year={2021}
}

@inproceedings{yoon2021pose,
  title={Pose-guided human animation from a single image in the wild},
  author={Yoon, Jae Shin and Liu, Lingjie and Golyanik, Vladislav and Sarkar, Kripasindhu and Park, Hyun Soo and Theobalt, Christian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15039--15048},
  year={2021}
}
@article{huang2022one,
  title={One-shot Implicit Animatable Avatars with Model-based Priors},
  author={Huang, Yangyi and Yi, Hongwei and Liu, Weiyang and Wang, Haofan and Wu, Boxi and Wang, Wenxiao and Lin, Binbin and Zhang, Debing and Cai, Deng},
  journal={arXiv preprint arXiv:2212.02469},
  year={2022}
}

@misc{dietNeRF,
      title={Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis}, 
      author={Ajay Jain and Matthew Tancik and Pieter Abbeel},
      year={2021},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{xu2022sinnerf,
  title={Sinnerf: Training neural radiance fields on complex scenes from a single image},
  author={Xu, Dejia and Jiang, Yifan and Wang, Peihao and Fan, Zhiwen and Shi, Humphrey and Wang, Zhangyang},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXII},
  pages={736--753},
  year={2022},
  organization={Springer}
}
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@article{raj2021pva,
  title={Pva: Pixel-aligned volumetric avatars},
  author={Raj, Amit and Zollhoefer, Michael and Simon, Tomas and Saragih, Jason and Saito, Shunsuke and Hays, James and Lombardi, Stephen},
  journal={arXiv preprint arXiv:2101.02697},
  year={2021}
}

@article{kwon2021neural,
  title={Neural human performer: Learning generalizable radiance fields for human performance rendering},
  author={Kwon, Youngjoong and Kim, Dahun and Ceylan, Duygu and Fuchs, Henry},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24741--24752},
  year={2021}
}

@inproceedings{mihajlovic2022keypointnerf,
  title={KeypointNeRF: Generalizing image-based volumetric avatars using relative spatial encoding of keypoints},
  author={Mihajlovic, Marko and Bansal, Aayush and Zollhoefer, Michael and Tang, Siyu and Saito, Shunsuke},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XV},
  pages={179--197},
  year={2022},
  organization={Springer}
}


%기타 
@inproceedings{graham20183d,
  title={3d semantic segmentation with submanifold sparse convolutional networks},
  author={Graham, Benjamin and Engelcke, Martin and Van Der Maaten, Laurens},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9224--9232},
  year={2018}
}




%2023 
@inproceedings{chen2023gm,
  title={GM-NeRF: Learning generalizable model-based Neural Radiance Fields from multi-view images},
  author={Chen, Jianchuan and Yi, Wentao and Ma, Liqian and Jia, Xu and Lu, Huchuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20648--20658},
  year={2023}
}

@inproceedings{jayasundara2023flexnerf,
  title={FlexNeRF: Photorealistic free-viewpoint rendering of moving humans from sparse views},
  author={Jayasundara, Vinoj and Agrawal, Amit and Heron, Nicolas and Shrivastava, Abhinav and Davis, Larry S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21118--21127},
  year={2023}
}

@inproceedings{park2019deepsdf,
  title={Deepsdf: Learning continuous signed distance functions for shape representation},
  author={Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={165--174},
  year={2019}
}

@article{icsik2023humanrf,
  title={Humanrf: High-fidelity neural radiance fields for humans in motion},
  author={I{\c{s}}{\i}k, Mustafa and R{\"u}nz, Martin and Georgopoulos, Markos and Khakhulin, Taras and Starck, Jonathan and Agapito, Lourdes and Nie{\ss}ner, Matthias},
  journal={ACM Transactions on Graphics (TOG)},
  volume={42},
  number={4},
  pages={1--12},
  year={2023},
  publisher={ACM New York, NY, USA}
}
@inproceedings{weng2023personnerf,
  title={Personnerf: Personalized reconstruction from photo collections},
  author={Weng, Chung-Yi and Srinivasan, Pratul P and Curless, Brian and Kemelmacher-Shlizerman, Ira},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={524--533},
  year={2023}
}


@article{qian20233dgs,
  title={3dgs-avatar: Animatable avatars via deformable 3d gaussian splatting},
  author={Qian, Zhiyin and Wang, Shaofei and Mihajlovic, Marko and Geiger, Andreas and Tang, Siyu},
  journal={arXiv preprint arXiv:2312.09228},
  year={2023}
}
@article{kerbl20233d,
  title={3d gaussian splatting for real-time radiance field rendering},
  author={Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
  journal={ACM Transactions on Graphics},
  volume={42},
  number={4},
  pages={1--14},
  year={2023},
  publisher={ACM}
}

@inproceedings{jiang2023instantavatar,
  title={Instantavatar: Learning avatars from monocular video in 60 seconds},
  author={Jiang, Tianjian and Chen, Xu and Song, Jie and Hilliges, Otmar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16922--16932},
  year={2023}
}
@article{muller2022instant,
  title={Instant neural graphics primitives with a multiresolution hash encoding},
  author={M{\"u}ller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  journal={ACM transactions on graphics (TOG)},
  volume={41},
  number={4},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA}
}
@inproceedings{yu2021plenoctrees,
  title={Plenoctrees for real-time rendering of neural radiance fields},
  author={Yu, Alex and Li, Ruilong and Tancik, Matthew and Li, Hao and Ng, Ren and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5752--5761},
  year={2021}
}
@inproceedings{fridovich2022plenoxels,
  title={Plenoxels: Radiance fields without neural networks},
  author={Fridovich-Keil, Sara and Yu, Alex and Tancik, Matthew and Chen, Qinhong and Recht, Benjamin and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5501--5510},
  year={2022}
}



%%for rebuttal 

@inproceedings{hu2024gauhuman,
  title={Gauhuman: Articulated gaussian splatting from monocular human videos},
  author={Hu, Shoukang and Hu, Tao and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20418--20431},
  year={2024}
}
@article{zielonka2023drivable,
  title={Drivable 3d gaussian avatars},
  author={Zielonka, Wojciech and Bagautdinov, Timur and Saito, Shunsuke and Zollh{\"o}fer, Michael and Thies, Justus and Romero, Javier},
  journal={arXiv preprint arXiv:2311.08581},
  year={2023}
}
@inproceedings{lei2024gart,
  title={Gart: Gaussian articulated template models},
  author={Lei, Jiahui and Wang, Yufu and Pavlakos, Georgios and Liu, Lingjie and Daniilidis, Kostas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19876--19887},
  year={2024}
}
@inproceedings{hu2023sherf,
  title={Sherf: Generalizable human nerf from a single image},
  author={Hu, Shoukang and Hong, Fangzhou and Pan, Liang and Mei, Haiyi and Yang, Lei and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9352--9364},
  year={2023}
}
@article{gao2023neural,
  title={Neural novel actor: Learning a generalized animatable neural representation for human actors},
  author={Gao, Qingzhe and Wang, Yiming and Liu, Libin and Liu, Lingjie and Theobalt, Christian and Chen, Baoquan},
  journal={IEEE Transactions on Visualization and Computer Graphics},
  year={2023},
  publisher={IEEE}
}
@inproceedings{pan2023transhuman,
  title={Transhuman: A transformer-based human representation for generalizable neural human rendering},
  author={Pan, Xiao and Yang, Zongxin and Ma, Jianxin and Zhou, Chang and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF International conference on computer vision},
  pages={3544--3555},
  year={2023}
}

@inproceedings{ma2024humannerf,
  title={HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses},
  author={Ma, Caoyuan and Liu, Yu-Lun and Wang, Zhixiang and Liu, Wu and Liu, Xinchen and Wang, Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1460--1470},
  year={2024}
}
@inproceedings{li2021ai,
  title={Ai choreographer: Music conditioned 3d dance generation with aist++},
  author={Li, Ruilong and Yang, Shan and Ross, David A and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13401--13412},
  year={2021}
}



%new
@inproceedings{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3836--3847},
  year={2023}
}
@inproceedings{huang2024tech,
  title={Tech: Text-guided reconstruction of lifelike clothed humans},
  author={Huang, Yangyi and Yi, Hongwei and Xiu, Yuliang and Liao, Tingting and Tang, Jiaxiang and Cai, Deng and Thies, Justus},
  booktitle={2024 International Conference on 3D Vision (3DV)},
  pages={1531--1542},
  year={2024},
  organization={IEEE}
}
@article{kolotouros2024dreamhuman,
  title={Dreamhuman: Animatable 3d avatars from text},
  author={Kolotouros, Nikos and Alldieck, Thiemo and Zanfir, Andrei and Bazavan, Eduard and Fieraru, Mihai and Sminchisescu, Cristian},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{liao2024tada,
  title={Tada! text to animatable digital avatars},
  author={Liao, Tingting and Yi, Hongwei and Xiu, Yuliang and Tang, Jiaxiang and Huang, Yangyi and Thies, Justus and Black, Michael J},
  booktitle={2024 International Conference on 3D Vision (3DV)},
  pages={1508--1519},
  year={2024},
  organization={IEEE}
}
@inproceedings{cao2024dreamavatar,
  title={Dreamavatar: Text-and-shape guided 3d human avatar generation via diffusion models},
  author={Cao, Yukang and Cao, Yan-Pei and Han, Kai and Shan, Ying and Wong, Kwan-Yee K},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={958--968},
  year={2024}
}

@inproceedings{liu2024humangaussian,
  title={Humangaussian: Text-driven 3d human generation with gaussian splatting},
  author={Liu, Xian and Zhan, Xiaohang and Tang, Jiaxiang and Shan, Ying and Zeng, Gang and Lin, Dahua and Liu, Xihui and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6646--6657},
  year={2024}
}
@inproceedings{huang2024humannorm,
  title={Humannorm: Learning normal diffusion model for high-quality and realistic 3d human generation},
  author={Huang, Xin and Shao, Ruizhi and Zhang, Qi and Zhang, Hongwen and Feng, Ying and Liu, Yebin and Wang, Qing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4568--4577},
  year={2024}
}
@article{kao2023deceptive,
  title={Deceptive-Human: Prompt-to-NeRF 3D Human Generation with 3D-Consistent Synthetic Images},
  author={Kao, Shiu-hong and Liu, Xinhang and Tai, Yu-Wing and Tang, Chi-Keung},
  journal={arXiv preprint arXiv:2311.16499},
  year={2023}
}

@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv preprint arXiv:2209.14988},
  year={2022}
}

@article{wang2024prolificdreamer,
  title={Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation},
  author={Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Bao, Fan and Li, Chongxuan and Su, Hang and Zhu, Jun},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{hertz2023delta,
  title={Delta denoising score},
  author={Hertz, Amir and Aberman, Kfir and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2328--2337},
  year={2023}
}

@article{yi2023gaussiandreamer,
  title={Gaussiandreamer: Fast generation from text to 3d gaussian splatting with point cloud priors},
  author={Yi, Taoran and Fang, Jiemin and Wu, Guanjun and Xie, Lingxi and Zhang, Xiaopeng and Liu, Wenyu and Tian, Qi and Wang, Xinggang},
  journal={arXiv preprint arXiv:2310.08529},
  year={2023}
}
@article{tang2023dreamgaussian,
  title={Dreamgaussian: Generative gaussian splatting for efficient 3d content creation},
  author={Tang, Jiaxiang and Ren, Jiawei and Zhou, Hang and Liu, Ziwei and Zeng, Gang},
  journal={arXiv preprint arXiv:2309.16653},
  year={2023}
}

@article{wang2023steindreamer,
  title={Steindreamer: Variance reduction for text-to-3d score distillation via stein identity},
  author={Wang, Peihao and Fan, Zhiwen and Xu, Dejia and Wang, Dilin and Mohan, Sreyas and Iandola, Forrest and Ranjan, Rakesh and Li, Yilei and Wang, Zhangyang and Chandra, Vikas and others},
  year={2023}
}
@article{pan2023enhancing,
  title={Enhancing high-resolution 3d generation through pixel-wise gradient clipping},
  author={Pan, Zijie and Lu, Jiachen and Zhu, Xiatian and Zhang, Li},
  journal={arXiv preprint arXiv:2310.12474},
  year={2023}
}

@article{yu2023text,
  title={Text-to-3d with classifier score distillation},
  author={Yu, Xin and Guo, Yuan-Chen and Li, Yangguang and Liang, Ding and Zhang, Song-Hai and Qi, Xiaojuan},
  journal={arXiv preprint arXiv:2310.19415},
  year={2023}
}
@article{katzir2023noise,
  title={Noise-free score distillation},
  author={Katzir, Oren and Patashnik, Or and Cohen-Or, Daniel and Lischinski, Dani},
  journal={arXiv preprint arXiv:2310.17590},
  year={2023}
}


%% diffusions 

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}
@article{podell2023sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}
@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}
@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}
@inproceedings{lin2023magic3d,
  title={Magic3d: High-resolution text-to-3d content creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={300--309},
  year={2023}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}
@inproceedings{yuan2024gavatar,
  title={Gavatar: Animatable 3d gaussian avatars with implicit mesh learning},
  author={Yuan, Ye and Li, Xueting and Huang, Yangyi and De Mello, Shalini and Nagano, Koki and Kautz, Jan and Iqbal, Umar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={896--905},
  year={2024}
}

@article{huang2024dreamwaltz,
  title={Dreamwaltz: Make a scene with complex 3d animatable avatars},
  author={Huang, Yukun and Wang, Jianan and Zeng, Ailing and Cao, He and Qi, Xianbiao and Shi, Yukai and Zha, Zheng-Jun and Zhang, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{SMPL-X:2019,
  title = {Expressive Body Capture: {3D} Hands, Face, and Body from a Single Image},
  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {10975--10985},
  year = {2019}
}

%gaussian avatars 
@inproceedings{hu2024gaussianavatar,
  title={Gaussianavatar: Towards realistic human avatar modeling from a single video via animatable 3d gaussians},
  author={Hu, Liangxiao and Zhang, Hongwen and Zhang, Yuxiang and Zhou, Boyao and Liu, Boning and Zhang, Shengping and Nie, Liqiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={634--644},
  year={2024}
}
@article{moon2024expressive,
  title={Expressive whole-body 3D gaussian avatar},
  author={Moon, Gyeongsik and Shiratori, Takaaki and Saito, Shunsuke},
  journal={arXiv preprint arXiv:2407.21686},
  year={2024}
}
@article{jiang2024uv,
  title={UV Gaussians: Joint Learning of Mesh Deformation and Gaussian Textures for Human Avatar Modeling},
  author={Jiang, Yujiao and Liao, Qingmin and Li, Xiaoyu and Ma, Li and Zhang, Qi and Zhang, Chaopeng and Lu, Zongqing and Shan, Ying},
  journal={arXiv preprint arXiv:2403.11589},
  year={2024}
}
@inproceedings{sanghi2022clip,
  title={Clip-forge: Towards zero-shot text-to-shape generation},
  author={Sanghi, Aditya and Chu, Hang and Lambourne, Joseph G and Wang, Ye and Cheng, Chin-Yi and Fumero, Marco and Malekshan, Kamal Rahimi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18603--18613},
  year={2022}
}

@inproceedings{jain2022zero,
  title={Zero-shot text-guided object generation with dream fields},
  author={Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T and Abbeel, Pieter and Poole, Ben},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={867--876},
  year={2022}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}
@article{wu2023human,
  title={Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis},
  author={Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
  journal={arXiv preprint arXiv:2306.09341},
  year={2023}
}