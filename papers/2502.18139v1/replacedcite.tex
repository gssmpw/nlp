\section{Related Works}
\subsection{Query Rewriting}
Traditional RAG directly employs the user input as the query to the retriever to retrieve relevant information. However, the ambiguity of the user query and the misalignment between the query and the retriever prevent the retriever from retrieving supporting documents. To improve the retrieval accuracy, query rewriting techniques rephrase or extend the user query into a more precise and searchable query.
Specifically, ____ and ____ proposed to enhance the query by training a specialized rewriting model.
____ suggested that using pseudo contexts generated by large language models (LLMs) as queries can significantly improve the relevance of retrieved documents. Compared to the original user query, pseudo contexts contain more relevant information, thereby increasing the semantic overlap between the supporting documents and the initial query. To further refine the query, iterative refinement was introduced by ____ to employ the retrieved contexts as feedback. Additionally, query decomposition was proposed by ____ to convert the complex multi-hop question into multiple searchable sub-questions. 

\subsection{Hybrid Retrieval}
Different types of retrievers excel at retrieving specific kinds of information. For instance, sparse retrievers are particularly effective at identifying relevant content based on explicit entities mentioned in the query. Dense retrievers, on the other hand, are adept at handling fuzzy queries, and capturing semantic meanings. Web search engines leverage the vast breadth of information available online, offering extensive knowledge retrieval. Consequently, employing a combination of these retrievers allows for a more comprehensive search strategy, capitalizing on the strengths of each method and broadening the scope of retrieval.
Specifically, ____ employed both BM25 retriever and dense retriever to retrieve the relevant snippets for better code generation. ____ proposed leveraging large language models to route information from various sources, thereby enhancing the effectiveness of personalized knowledge-based dialogue systems. Different from simply concatenating all the retrievers, ____ employed a web search engine as the supplement of the dense retriever. Ensemble of Retrievers (EoR), introduced by ____, leverages ensemble learning to optimize collaboration among multiple retrievers. 

\subsection{Concurrent Work}
Similar to our proposed LevelRAG, MindSearch ____ also employs a two-level retrieval architecture. At the upper level, MindSearch utilizes WebPlanner, which decomposes the user query into a directed acyclic graph (DAG). The lower level, known as WebSearcher, performs hierarchical information retrieval using web search engines, gathering relevant information for the WebPlanner. While MindSearch shares similarities with our proposed LevelRAG, three key distinctions set them apart:

\begin{itemize}
    \item The motivation is different. MindSearch is designed to address the challenge of adapting the vast amount of web information to the limited context window of LLMs during internet searches. In contrast, LevelRAG is motivated by the need to overcome limitations in current query rewriting techniques that are inadequate for hybrid retrieval systems.
    \item The methods differ significantly in their implementation. MindSearch employs a code interpreter to decompose user queries, whereas LevelRAG leverages natural language processing for the decomposition process. Additionally, while MindSearch incorporates only a WebSearcher at the lower level, LevelRAG is capable of integrating multiple low-level searchers to gather valuable information.
    \item The contributions are fundamentally different. MindSearch introduces a multi-agent framework for complex web information-seeking and integration tasks, whereas our work presents a novel approach that combines the strengths of both hybrid retrieval and query rewriting techniques. Additionally, to the best of our knowledge, our proposed sparse searcher is the first rewriting framework designed for sparse retrievers.
\end{itemize}