\section{Experimental Setup}

We evaluate state-of-the-art IARs: VAR-\textit{d}\{16, 20, 24, 30\} (\textit{d} = model depth), RAR-\{B, L, XL, XXL\}, MAR-\{B, L, H\}, trained for class-conditioned generation. The IARs' sizes cover a broad spectrum between 208M for MAR-B, and 2.1B parameters for \varbig. We use IARs shared by the authors of their respective papers in their repositories, 
with details in~\cref{app:model_details}. As these models were trained on ImageNet-1k~\citep{deng2009imagenet} dataset, we use it to perform our privacy attacks. 
For MIA and DI, we take 10000 samples from the training set as members and also 10000 samples from the validation set as non-members. To perform data extraction attack, we use all images from the training data. Additionally, we leverage the known validation set to check for false positives.


