\subsection{Dataset Inference}
\label{sec:di}


\begin{table*}[h]
    \centering
    \newcommand{\tightcolsep}{\setlength{\tabcolsep}{2pt}} %
    \tightcolsep %
    \scriptsize
    \caption{\textbf{DI for IARs.} We report the reduction in the number of samples required to carry out DI. Our improvements allow to successfully run DI on IARs even with fewer than 10 samples. \textit{Baseline} refers to LLM DI~\citep{maini2024llmdatasetinferencedid}.
    }
   \begin{tabular}{cccccccccccc}
        \toprule
        \textbf{Model} & \textbf{VAR-\textit{d}16} & \textbf{VAR-\textit{d}20} & \textbf{VAR-\textit{d}24} & \textbf{VAR-\textit{d}30} & \textbf{MAR-B} & \textbf{MAR-L} & \textbf{MAR-H} & \textbf{RAR-B} & \textbf{RAR-L} & \textbf{RAR-XL} & \textbf{RAR-XXL} \\
        \midrule
        Baseline & 2000 & 300 & 60 & 20 & 5000 & 2000  & 900 & 500 & 200 & 40 & 30 \\
        \midrule
        +Optimized Procedure & 600 & 200 & 40 & 8 & 4000 & 2000 & 800 & 300 & 80 & 30 & 10 \\
       Improvement & -1400 & -100 & -20 & -12 & -1000 & 0 & -100 & -200 & -120 & -10 & -20 \\
        \midrule
        +Our MIAs for IARs & \textbf{200} & \textbf{40} & \textbf{20} & \textbf{6} & \textbf{2000} & \textbf{600} & \textbf{300} & \textbf{80} & \textbf{30} & \textbf{20} & \textbf{8} \\
                Improvement & -400 & -160 & -20 & -2 & -2000 & -1400 & -500 &-220 & -50 & -10 & -2 \\
        \bottomrule
    \end{tabular}
    \label{tab:di_naive_vs_ours}
\end{table*}








While our results in \cref{tab:mia_naive_vs_ours} demonstrate impressive MIA performance for large models (such as VAR-\textit{d}30 with 2.1B parameters), privacy risk assessment for smaller models (such as VAR-\textit{d}16 with 310M parameters) needs improvement. To address this, we draw on insights from previous work on DI~\citep{maini2024llmdatasetinferencedid,dubinski2024cdicopyrighteddataidentification}, which has proven effective when MIAs fail to achieve satisfactory performance. The advantage of DI over MIAs lies in its ability to aggregate signals across multiple data points while utilizing a statistical framework to amplify the overall membership signal, yielding more reliable privacy leakage assessment. We find that while the framework of DI is applicable to IARs, its crucial parts must be improved to boost DI's effectiveness on IARs. We now detail our improvements.
















\textbf{Improvement 1: Optimized DI Procedure.} Existing DI techniques for LLMs~\citep{maini2024llmdatasetinferencedid} and DMs~\citep{dubinski2024cdicopyrighteddataidentification} follow a four-stage process, with the third stage involving the training of a linear classifier. This classifier is used to weight, scale, aggregate, and strengthen signals from individual MIAs, where each MIA score serves as a separate feature. This step is crucial for selecting the most effective MIAs for a given dataset while suppressing ineffective ones that could introduce false results. However, we observe that MIA features for IARs are well-behaved, meaning that, on average, they are consistently higher for members than for non-members. Thus, instead of training a linear classifier on MIA features, which requires additional auditing data, we adopt a more efficient approach: we first normalize each feature using MinMaxScaler to the [0,1] interval, and then we sum them to obtain the final per-sample score, used by the t-test. This eliminates the need to allocate scarce auditing data for training a linear classifier.


Our results for the optimized DI procedure are presented in \cref{tab:di_naive_vs_ours}. We observe a significant reduction in the number of samples required to perform DI for smaller models, with reductions of up to 70\% for VAR-$\mathit{d}$16. 








\textbf{Improvement 2: Our MIAs for IARs.}
Our results in \cref{tab:di_naive_vs_ours} indicate that as model size increases, the membership signal is amplified, enabling DI to achieve better performance with fewer samples. However, the main problem is the mixed reliability of DI when utilizing baseline MIAs as feature extractors. This issue is especially evident for smaller models, such as \varsmall and MAR-B, where DI requires thousands of samples to successfully reject the null hypothesis when the suspect set is part of the training data. Building on the performance gains of our tailored MIAs (\cref{tab:mia_naive_vs_ours}) we apply them to the DI framework as the more powerful feature extractors to further strengthen DI for IARs.
Our improvements through stronger MIAs further enhance DI, fully exposing privacy leakage in IAR models. As a result, the number of required samples to execute DI drops to a few hundred, for example, down to only 200 for \varsmall.
Overall, as shown in \cref{tab:di_naive_vs_ours}, replacing the linear classification model with summation and transitioning to our MIAs for IARs as feature extractors significantly reduces the number of samples required to reject \(H_0\).




\begin{wrapfigure}{r}{0.6\linewidth} %
    \vspace{-5pt}
    \centering
    \includegraphics[width=\linewidth]{figures/pareto_di.pdf}
    \vspace{-10pt}
    \caption{\textbf{DI success for IARs vs DMs.} We report the generative quality expressed with the FID score vs the number of suspect samples \(P\) required to carry out DI.} 
    \vspace{-5pt}
    \label{fig:pareto_di}
\end{wrapfigure}

\textbf{Overall Performance and Comparison to DMs.}
We present our results in \Cref{fig:pareto_di}, evaluating the overall privacy leakage and comparing IARs to DMs based on the number of required samples ($P$) to perform DI. Recall that a lower $P$ under the DI framework indicates greater privacy vulnerability, as it means fewer data points are needed to reject the null hypothesis--\(H_0\). Our findings indicate that the same trend observed in MIAs extends to DI. 
Overall, models with a higher \tprat in \Cref{tab:mia_naive_vs_ours} for MIAs also require smaller suspect sets $P$ for DI.
Specifically, DI shows that larger models exhibit greater privacy leakage, with \varbig and RAR-XXL being the most vulnerable.
Crucially, our results clearly demonstrate that IARs are significantly more susceptible to privacy leakage than DMs. Similarly to~\cref{sec:membership}, results in~\cref{app:why_iars_leak_more,app:unified_mia} show that this difference might be attributed to inherent differences between DMs and IARs. While MDT shows lower generative quality (as indicated by a higher FID score), it requires substantially more samples for DI (higher $P$ value), resulting in much lower privacy leakage.





























