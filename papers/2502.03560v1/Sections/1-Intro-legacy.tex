\section{Introduction}

\begin{figure}[!t]
\centering
  \includegraphics[width=\textwidth]{Images/teaser-typing.png}
  \caption{
    The figures illustrate the trajectories of simulated gaze and finger movement from the model, showing how it makes errors, proofreads text, and corrects errors in touchscreen typing. There are three types of errors: a) Slip: Accidentally double-tapping while typing fast, which is detected through proofreading and corrected by backspacing. b) Lapse: Forgetting a finger movement due to memory issues. c) Mistake: Making a proofreading mistake by missing a typo and deciding not to correct it. In addition to the errors in the typed text, the model also predicts finger and gaze movements to better simulate human error behaviors, including spatial positions and timing.}
  \label{fig:teaser}
\end{figure}


% To err is human.

% We could motivate the paper by reminding that errors are one of the main factors that SLOW people down in typing. Thatâ€™s why we must know more about them. ALSO: eliminating errors in typing is a major topic of technical investigation (decoders, editing techniques etc).

Typing on touchscreen devices is prone to errors, which are a major factor impeding performance and differentiating users \cite{dhakal2018observations}. 
Users need to detect errors and, somehow, get them fixed, 
which results in wasted time, unintended messages, and frustration. 
Such errors are of three main types.
\emph{Slips} occur when the user intends to write something but fails in executing it.
For example, the ``fat finger'' problem refers to slips of finger to a neighboring key due to occlusion by the finger~\cite{siek2005fat}. 
\emph{Mistakes} occur when users have incorrect knowledge about what they should type, for example incorrect grammar or vocabulary.
User also show \emph{lapses}: They fail to remember what they have typed and may, for example, forget to type a letter or whole word. 
%
Understanding and minimizing such errors has been a longstanding goal in research on text entry systems. 
%However, current models do not adequately address the full spectrum of errors in typing. 

Modeling error-related behavior is challenging due to the various human factors contributing to it. They range from perceptual and cognitive limitations to motor control issues, each playing a distinct role in how errors manifest during the typing process. Beyond the errors in the output text, these factors affect detailed typing behavior, which is of greater importance for the HCI community. For instance, forgetting to tap a key or slipping the finger to tap to nowhere can result in identical text output but with totally different typing behavior.
The classification of typing errors is typically based solely on the edit distance~\cite{mackenzie2010text} of the output text. This approach does not consider detailed behavioral data, limiting its ability to understand user error-related behavior. Different underlying mechanisms could lead to the same errors in text. For instance, an omission error (missing a character in a word) could result from forgetting to type a character or accidentally tapping in an area without keys.
Recent typing models have started exploring eye-hand coordination in touchscreen typing~\cite{jokinen2021touchscreen, shi2024crtypist}, they pave a way to predict detailed gaze and finger movement behavior for proofreading and error correction.
Although valuable, these models only cover the spatial distance errors, which is a small portion of human errors in touchscreen typing which cannot represent how human types in their daily usage of touchscreen keyboards. 
Furthermore, this limitation also affects the diversity of model's error-handling behaviors as they only deal with a single type of errors.
To sum up, the research gap from the existing typing models is two-fold: First, covering diverse error distributions in the touchscreen-typing model is still unsolved; Second, it is still challenging to generate human-like error-handling behaviors over diverse errors.

To address this gap, this paper presents a computational model that can effectively simulate a wide range of human errors and the corresponding error-handling behavior in touchscreen typing. We have designed the model with the following goals in mind: Firstly, we seek to model the underlying causes of human errors, rather than just generating random errors in the text. Our approach uses glass-box modeling to ensure that each generated error is explainable in a transparent manner.
Secondly, humans can strategically adjust the resources they allocate to prevent errors or influence the likelihood of errors. Our goal is for the model to reflect the various strategies for handling errors.
Finally, error behaviors vary among different user groups~\cite{nicolau2012elderly, wang2021facilitating}. We aim for the model to encompass individual differences, while also ensuring that it can replicate the average performance of the target users, maintaining a general typing performance.

The theory of human errors categorizes errors into three main types~\cite{reason1990human}: \textit{Slips}, which occur when motor control errors lead to incorrect finger movements; \textit{Lapses}, resulting from memory failures that result in omitted steps; \textit{Mistakes}, which arise from incorrect decisions due to inaccurate observations. 
By incorporating these sources of errors in touchscreen typing, the model provides a more comprehensive errors-generating process based on the information process approach~\cite{wickens2021engineering}.
With these cognitive mechanisms, the model can cover all text errors based-on the text distance, including insertion, omission, substitution, and transposition errors.
Beyond the error production, the key feature of the model is its supervisory control of vision and finger over these errors. The key enabler of the architecture is the internal representation of the state, bridging the controller and the touchscreen via the belief of typed text and finger position.
The model is optimized to type the reference phrase, achieving a balance between speed and accuracy. It decides when to move the vision for the proofreading and when to tap backspace for error corrections for an optimal speed-accuracy tradeoff, making it adaptable to different user groups with varying needs and abilities.
We offer a visualization interface of the model for tuning the human parameters of errors to see the corresponding typing behavior, and the modeling approach also provides the optimization of parameters for fitting specific target users.

We conducted an analysis of human typing errors under three different error-correction conditions: 1) typing errors that cannot be corrected, 2) typing errors that can be manually corrected, and 3) typing errors with auto-correction available.
For these three scenarios, we developed a typing benchmark involving diverse user groups, including young adults, Parkinson's users, elderly users, and individuals using different types of keyboards, who may encounter varying error types and frequencies. The results of our study showed that our model can replicate human error distributions, whereas the state-of-the-art model was only able to reproduce a small portion of the errors.
Furthermore, our model was also able to capture the distribution of error correction across typing speeds, demonstrating its capability to account for individual differences. When compared with in-lab human gaze and finger movement data, our model exhibited more accurate human-like behavior in error handling and correction strategies than the baseline model.
Finally, our model demonstrated its effectiveness in reproducing human error behaviors in scenarios where auto-correction features were utilized. 

To sum up, the main contribution of this paper is the first supervisory control model that can simulate the majority of human errors and related error-handling behaviors, including proofreading and error corrections. 
The delta from the existing typing models~\cite{jokinen2021touchscreen, shi2024crtypist} is two-fold: 1) an errors-generating process is integrated to model the underlying cause of the errors. This process can account for various types of error-generating mechanisms based on the information-process theory; 2) a supervisory control model of vision and finger to deal with errors, leading to a more realistic, human-like approach to handling errors.
We build the typing benchmark extended from the latest study to cover the evaluation of errors in touchscreen typing and show the comparison among our approach, baselines, and human data.
The model and the application are open-source for further research and engineering\footnote{Anonymous URL}.