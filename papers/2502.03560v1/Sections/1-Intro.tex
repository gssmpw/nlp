
\section{Introduction}

\begin{figure*}[!t]
\centering
  \includegraphics[width=\textwidth]{Images/teaser-typing.png}
  \caption{
    We introduce the first model covering a wide spectrum of errors known to be commonplace in typing, ~\name, which simulates the way users move their eyes and fingers when they type. The figure illustrates the three main types of error covered by the model. a) Slip: accidentally double-tapping while typing rapidly, which is detected through proofreading and corrected by backspacing; b) Lapse: forgetting where the finger was. c) Mistake: missing a typo and believing it is correct.}
  \label{fig:teaser}
\end{figure*}

\rv{
Human beings make errors in all lines of work and spheres of life~\cite{donaldson2000err}. 
In touchscreen typing, human error creates a major hindrance to performance, one that manifests itself very differently between users~\cite{dhakal2018observations}.
Typing performance depends greatly on how quickly users can type and confirm the typed text, a process that errors can disrupt. Among common errors are hitting the wrong key, repeating a letter, forgetting what has been typed, and overlooking grammar mistakes.
The ``fat finger problem''~\cite{siek2005fat} is a well-known issue in typing. The term refers to the increased likelihood of hitting the wrong key when the keys are small.  As a result, users often have to slow down their movements to touch the screen more precisely~\cite{bi2013ffitts}.
Advanced features like autocorrect can assist with error management, but they may also significantly alter user behavior~\cite{banovic2019limits}. 
Detecting errors, deciding whether to correct them, and implementing corrections involve complex interactions of perceptual, cognitive, and motor control processes~\cite{jiang2020we}.
}
Not surprisingly, errors are perhaps the single most critical factor constraining typing performance ~\cite{palin2019people}. 
To improve text entry systems, we need to understand what causes errors. 

\emph{Computational models} have advanced both theorizing and practical efforts in the text entry domain.
They have explained how limitations of the human motor system lead to inaccuracies in input~\cite{zhai2004characterizing} and address how users exercise some strategic control over such errors \cite{guiard2015mathematical}.
Models of typing are of practical value too.
They have been used to optimize layouts, drive intelligent text entry techniques,  and personalize keyboards (e.g., \cite{bi2013bayesian,weir2014uncertain,zhai2000metropolis}).
However, even the most comprehensive simulation-based models have been limited mainly to a single error type: motor slips \cite{jokinen2017modelling,jokinen2021touchscreen, shi2024crtypist}.
%
This restricts these models' usefulness -- they need to be expanded.
In particular, they should cover the key mechanisms behind errors and their typographical consequences. 
The prevailing conception is that errors in typing, as do human errors in general, fall into three main types~\cite{reason1990human}: \textit{slips}, which occur when motor execution deviates from the intended outcome; \textit{lapses}, which are due to memory failures; and \textit{mistakes}, arising from incorrect or partial knowledge (see Figure~\ref{fig:teaser}).
%


The goal of this paper is to shed new light on mechanisms possibly underlying typing errors and, thereby, significantly increase the scope and realism of models' predictions. 
%
Our key insight is that the mechanisms that produce errors are partially under strategic control. 
Users almost always have \emph{some} strategic control over the probability of these.
They can reduce errors by allocating more time and resources. 
They can slow down and monitor what they do more closely.
Yet they might not always want to do that.
What is optimal for them depends on their preferences.
A user who just wants to send a message quickly may not care about possible typos. 
%
We want to capture this critical supervisory aspect of errors.
\rv{
One recent model~\cite{jokinen2021touchscreen} has sparked efforts to explore eye--hand coordination in touchscreen typing, illuminating how users decide to assign visual attention. %  to detecting errors in the text they have typed
These culminated in the latest model, CRTypist~\cite{shi2024crtypist}, a supervisory control model that reproduces people's cognitive processes, for more human-like touchscreen typing behavior.
Yet these previous models still only cover motor slips.
}

In this paper, we present ~\name, which contributes to capturing the interplay between two types of cognitive mechanism: those that produce errors and those that attempt to detect and fix them.
%
First, we cover three cognitive mechanisms that produce errors in typing.
%
~\name adds two sources of error: memory and perception. 
Our model's motor control system may forget commands sent to it;
likewise, its representation of vision is noisy and not always able to detect errors in text even upon reading it.
%
Secondly, 
the model exploits broader-based handling of the supervisory control process.
We model how it decides to allocate resources to two critical subtasks of typing: moving the fingers and checking the text (proofreading).
In contrast, information-processing-based models of cognition put less emphasis on the closed-loop aspect of errors ~\cite{wickens2021engineering}.
Specifically, we assume that supervisory control proceeds from \emph{beliefs} formed from perceptual samples.
At any given time, the model is looking at some portion of the display, thus obtaining a sample.
The beliefs formed depend on whether the agent has looked at the text that has been typed, its fingers, or the keys. Each such belief itself is, in turn, constrained: subject to forgetting.
%
Putting these two fundamental mechanisms together, our model can cover four main types of typographical errors: insertion, omission, substitution, and transposition errors.
% Previous models were only able to cover substitution errors.


\name exhibits practical utility. 
It can be given a phrase, a keyboard design, and assumptions about the user. From these, it simulates how the given user would type text while moving the eyes and fingers, and creating errors. 
At the moment, it covers standard touchscreen keyboards that utilize the QWERTY layout and offer an autocorrection feature.
We found that users with different capabilities can be simulated by changing the values of parameters that describe their capabilities. 
%
We offer an interactive tool for testing out parameter values and an optimization method for inferring parameters from a dataset.

%
To test the validity of the model, 
we developed the \benchmark benchmark, which involves diverse user groups, including young adults, users with Parkinson's, elderly users, and individuals using different types of keyboards, all of whom vary in the error types and frequencies faced. 
The model proved able to replicate key characteristics of real  error distributions, whereas the prior state-of-the-art model reproduces merely a small subset of the errors.
Furthermore, \name was able to capture the distribution of error correction across typing speeds, thus demonstrating an ability to account for individual-to-individual differences. When judged in light of in-lab gaze and finger movement data, it exhibited more accurate, realistic behavior in error handling and correction strategies than the baseline model.
Finally, it generated human-like behavior in scenarios that incorporate using autocorrection. 

In summary, the main contribution of our research is the extension of computational modeling of typing to simulate the majority of common typing errors in a touchscreen typing environment.  
\rv{
The advantages \name possesses over the latest typing model, CRTypist~\cite{shi2024crtypist}, include the following:
1) integrating three error-generating mechanisms (slips, lapses, and mistakes) into a unified model;   
2) upgrading the supervisory control model to support detecting and correcting diverse errors; and
3) improving the computational rationality modeling workflow, through joint parameter optimization, to achieve more human-like performance.
However, \name does not cover real-world behaviors involving advanced features. More work is needed to better handle complex dynamics in touchscreen typing.
\name is available via \texttt{\url{https://typoist.github.io/}}.
}



% An orienting example: This is what we model
% You are messaging your friend to note that you are going to be late from dinner.
% When everything goes well, your performance is limited mainly by the speed with which you can move your fingers and confirm that the typed text is fine.
% But what if everything does \emph{not} go as intended? 
% Different kinds of errors may impede performance.
% You may slip your finger to the wrong key or tap the same one twice.
% You may forget what you have typed so far and enter a word that does not make sense.
% You might also not know -- or care about -- the correct terms or grammar,
% or fail to detect such mistakes even if you see them.
% And autocorrect may erroneously change a word you typed to an unintended one.
% If any of such errors occur, you will need to detect the error, decide if it needs to be fixed, and fix it. 
% This is time-consuming.
% Not surprisingly, errors are perhaps the single most critical factor constraining typing performance ~\cite{palin2019people}. 
% To improve text entry systems, we need to understand what causes such errors. 
%

% The advance over the prior models ~\cite{jokinen2021touchscreen, shi2024crtypist} is two-fold: 1) we integrate three error-generating mechanisms into a unified model; 2) we design a supervisory control model that is able to detect and fix errors in a human-like way.
% Our benchmark dataset, the model, and the tool are open-sourced \footnote{\rv{https://typoist.github.io}}. 
% and made available upon publication\footnote{Anonymous URL}.


