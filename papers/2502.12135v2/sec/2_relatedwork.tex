% \vspace{-9pt}
\section{Related works}
\label{sec:related}
% \vspace{-6pt}
\subsection{Skeleton generation}
There are two categories of methods for creating skeletons in 3D models. The first category relies on predefined templates \cite{baran2007automatic, li2021learning} or additional annotations \cite{xu2022morig, de2008automatic, mixamo, james2005skinning}. Pinocchio \cite{baran2007automatic} is a pioneering method for automatically extracting an animation skeleton from an input 3D model. It fits a predefined skeleton template to the 3D model, evaluating the fitting cost for different templates and selecting the most suitable one for a given model. Li et al. \cite{li2021learning} proposed a deep learning-based method to estimate joint positions for a given human skeletal template. However, these template-based methods are limited to rigging characters whose articulation structures are compatible with the predefined templates, making it difficult to generalize to objects with distinct structures. 

There are also methods that rely on additional inputs or annotations to generate skeletons for 3D models, including point cloud sequences \cite{xu2022morig}, mesh sequences \cite{de2008automatic, james2005skinning}, and manual annotations \cite{mixamo}. Additionally, recent works \cite{yang2022banmo, song2024reacto, song2024moda, zhang2024s3o, zhang2024learning, zhang2024magicpose4d} have focused on learning the joints and bones of articulated objects directly from videos to reconstruct object motion. In contrast, our approach aims to generate skeletons using only 3D models as input.

The second category consists of template-free methods that operate without relying on predefined templates or additional annotations. Many approaches \cite{au2008skeleton, cao2010point, huang2013l1, tagliasacchi2012mean, lin2021point2skeleton} are designed to extract curve skeletons from meshes or point clouds by utilizing the medial axis or the centerline of shapes. These methods often result in densely packed joints that are unsuitable for effective articulation and animation. Recent deep-learning approaches have also been developed to learn skeletons directly from input shapes without relying on predefined templates. These methods are generally trained on datasets containing thousands of rigged characters, allowing them to generate skeletons that align with articulated components. For instance, Xu et al. \cite{xu2019predicting} introduced a volumetric network designed to generate skeletons for input 3D models. RigNet \cite{xu2020rignet} leverages graph convolutions to learn mesh representations, thereby enhancing the accuracy of skeleton extraction. However, it relies on the strong assumption that the input training and test shapes maintain a consistent upright and front-facing orientation.


In this work, we formulate skeleton generation as an auto-regressive problem to accommodate the varying number of bones in different 3D models. By generating bones auto-regressively, our method dynamically adapts to each model's specific requirements, ensuring flexibility and accuracy in skeleton creation.

\subsection{Skinning weight prediction}
To make 3D models ready for articulation, we also predict skinning weights conditioned on the 3D shape and corresponding skeleton, which define the influence of each joint on each vertex of the mesh.

Several geometric-based techniques have been introduced for skinning \cite{dionne2013geodesic, jacobson2011bounded, dodik2024robust, baran2007automatic}. These methods assign skinning weights based on the distance between joints and vertices. However, this distance-based assumption often fails when the 3D shape has a complex topology. Deep learning-based methods \cite{liu2019neuroskinning, xu2020rignet, liao2022skeleton, mosella2022skinningnet}, such as NeuroSkinning \cite{liu2019neuroskinning}, take a skeleton template as input and predict skinning weights using a learned graph neural network. RigNet \cite{xu2020rignet} utilizes intrinsic shape representations that capture geodesic distances between vertices and bones, often struggles with highly intricate mesh topologies and may require extensive feature engineering to maintain performance across varied object categories. SkinningNet \cite{mosella2022skinningnet} employs a two-stream graph neural network to compute skinning weights directly from input meshes and the corresponding skeletons. However, the performance of these GNN-based methods can degrade when applied to datasets with highly varying orientations, such as \ourdata{}, leading to reduced accuracy and robustness in complex and varied scenarios.

In this work, we predict skinning weights in a functional diffusion process by incorporating volumetric geodesic distance priors between vertices and joints. This approach effectively handles complex mesh topologies and diverse skeletal structures without the constraints of shape orientations.

\begin{figure*}[htbp]
  \centering
  % Subfigure (a)
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/fig2_wordcloud.pdf}
    \caption{\textbf{Word cloud of \ourdata{} categories.}}
    \label{fig:wordcloud}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.36\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/fig2_pie.pdf}
    \caption{\textbf{Breakdown of \ourdata{} categories.}}
    \label{fig:bing}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.32\textwidth}
    \centering
    \includegraphics[width=\textwidth]{fig/fig2_bonedis.pdf}
    \caption{\textbf{Bone number distributions of \ourdata{}.}}
    \label{fig:bone_distributions}
  \end{subfigure}
  
  \caption{\textbf{\ourdata{} statistics.}}
  \label{fig:combined_figure}
  \vspace{-15pt}

\end{figure*}

\subsection{Auto-regressive 3D generation}
Recently, auto-regressive models have been widely used in 3D mesh generation \cite{nash2020polygen, siddiqui2024meshgpt, chen2024meshanything, chen2024meshanythingv2, chen2024meshxl, tang2024edgerunner, weng2024pivotmesh}.
 MeshGPT \cite{siddiqui2024meshgpt} models meshes as sequences of triangles and tokenizes them using a VQ-VAE \cite{van2017neural}. It then employs an auto-regressive transformer to generate the token sequences. This approach enables the creation of meshes with varying face counts. However, most subsequent methods \cite{chen2024meshanything, chen2024meshxl, weng2024pivotmesh} are limited to generating meshes up to 800 faces, due to the computational cost of mesh tokenization. MeshAnythingV2 \cite{chen2024meshanythingv2} introduces Adjacent Mesh Tokenization (AMT), doubling the maximum face count to 1,600. EdgeRunner \cite{tang2024edgerunner} further increases this limit to 4,000 faces by enhancing mesh tokenization techniques. In this work, we explore the potential of auto-regressive models for shape-conditioned skeleton generation. To achieve this, we formulate skeletons as sequences of bones. Unlike mesh generation, which focuses on creating detailed and realistic shapes by utilizing a high number of faces, skeleton generation prioritizes accuracy over complexity. Accurate skeletons are crucial for realistic articulation and animation, and typically consist of fewer than 100 bones, as indicated by the statistics in \ourdata{}.
