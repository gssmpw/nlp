\section{Articulation-XL}
\label{arti-xl}

\begin{figure}
    \centering
    \includegraphics[scale=0.26]{fig/fig3_example.pdf}
    \caption{\textbf{Some examples from \ourdata{} alongside examples of poorly defined skeletons that were curated out.}}
    \label{fig:examples}
    \vspace{-16pt}
  \end{figure}




To facilitate large-scale learning of 3D model articulation, we present \ourdata{}, a comprehensive dataset curated from Objaverse-XL \cite{deitke2023objaverse, deitke2024objaverse}. Our dataset construction pipeline consists of three main stages: initial filtering, VLM-based filtering, and category annotation. 
\textbf{We will release our \ourdata{} to facilitate future work.}

\boldstartspace{Initial data collection.} We begin by identifying 3D models from Objaverse-XL that contain both skeleton and skinning weight annotations. To ensure data quality and practical utility, we apply the following filtering criteria: 1) we remove duplicate data based on both skeleton and mesh similarity; 2) we exclude models with only a single joint/bone structure; 3) we filter out data with more than 100 bones, which constitute a negligible portion of the dataset. This initial filtering yields 38.8k candidate models with articulation annotations.

\boldstartspace{VLM-based filtering.} However, we observe that many initial candidates contain poorly defined skeletons that may impair learning (see \Cref{fig:examples}). To ensure dataset quality, we further implement a Vision-Language Model (VLM)-based filtering pipeline: 1) we render each object with its skeleton from four viewpoints; 2) and then utilize GPT-4o \cite{openai_gpt4o} to assess skeleton quality based on specific criteria (detailed in supplementary).
This process results in a final collection of over 33k 3D models with high-quality articulation annotations, forming the curated dataset \ourdata{} \footnote{We have expanded the dataset to over 48K models in Articulation-XL2.0. For further details, please refer to \url{https://huggingface.co/datasets/chaoyue7/Articulation-XL2.0}.}. The dataset exhibits diverse structural complexity: the number of bones per model ranges from 2 to 100, and the number of joints ranges from 3 to 101. The distribution of bone numbers is illustrated in \Cref{fig:bone_distributions}. 

\boldstartspace{Category label annotation.} Additionally, we also leverage a Vision-Language Model (VLM) to automatically assign category labels to each model using specific instructions.
The distribution of these categories is illustrated via a word cloud and a pie chart, as shown in \Cref{fig:wordcloud} and \Cref{fig:bing}, respectively. We observe a rich diversity of object categories, with human-related models forming the largest subset. Detailed statistics and distribution analyses are provided in the supplementary material.
