\section{Related Work}
\subsection{Deep Learning on Longitudinal EHRs}
Applying deep learning models to longitudinal EHRs for predictive tasks centers around learning adequate patient representation ____. To model temporal disease progression patterns, Doctor AI ____ leveraged recurrent neural networks (RNNs), StageNet ____ employed a stage-aware long short-term memory (LSTM) module, and Hi-BEHRT ____ adopted a hierarchical Transformer effective for long visit histories. To account for irregular time gaps between visits, variants of LSTM and self-attention mechanisms that consider timestamps have been introduced ____. To utilize external medical knowledge, methods such as GRAM ____ infused information from medical ontologies into representation learning via attention mechanisms; PRIME ____ incorporated rule-based prior medical knowledge through posterior regularization; and SeqCare ____ employed online medical knowledge graphs with adaptive graph structure learning. To address low-quality data, methods such as GRASP ____, which utilized knowledge from similar patients through graph neural networks, and MedSkim ____, which filtered out noisy diagnoses using the Gumbel-Softmax trick, were developed. Existing approaches tried to enhance model interpretability by giving weights to every past diagnosis or visit: methods such as RETAIN achieved this with attention mechanisms ____; AdaCare ____ employed a scale-adaptive feature recalibration module. To mitigate data insufficiency in certain scenarios, ____ pre-trained BERT on a large EHR corpus and fine-tuned it on smaller datasets.

\subsection{Intrinsically Interpretable Models}
Intrinsic interpretability, which means that predictive models provide their own explanations, is favored over post-hoc interpretability that necessitates a separate model for explaining a black-box model, because the explanations provided by intrinsically interpretable models are exploited in the decision-making process and faithful to model predictions ____. SENN ____ is a class of self-explaining neural networks whose interpretability is enforced via regularization. A self-explaining deep learning model proposed by ____ utilizes an autoencoder and a prototype classifier network to provide case-based rationales. The attention mechanism has been employed to achieve intrinsic interpretability by using attention weights as explanations ____, but its reliability is arguable ____. SITE ____ emphasizes robust interpretations equivariant to geometric transformations. ProtoVAE ____ leverages a variational autoencoder to learn class-specific prototypes. The Bort optimizer ____ enhances model explainability by imposing boundedness and orthogonality constraints on model parameters.

Intrinsic interpretability has been studied in different domains such as recommender systems ____ and healthcare ____. However, unlike \method, existing self-explaining deep learning models for EHR-based diagnosis prediction fail to provide temporal explanations that reflect the distinct comorbidities of individual patients.

The related work on deep learning on hypergraphs is discussed in \appendixref{a0}.