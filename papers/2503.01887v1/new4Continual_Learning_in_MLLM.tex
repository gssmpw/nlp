



\begin{table*}[htbp]
\small
\renewcommand\arraystretch{1.2}
  \centering
  \caption{Innovations in MLModel CL Frameworks.}
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}m{2cm}|p{0.4\textwidth}|p{0.4\textwidth}}
    \hline
   \multicolumn{1}{c|}{Framework} & \multicolumn{1}{c|}{Starting point of the problem} & \multicolumn{1}{c}{How to solve} \\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{PathWeave}\\~\cite{yu2024llms}}} & 
To reduce the dependency on large-scale joint pre-training.& PathWeave enhances modality alignment and collaboration.\\
   
   \hline
   \multirow{2}{*}{\textbf{CLAP}~\cite{jha2024clap4clip}} & 
To enhance the model's uncertainty estimation capabilities.& CLAP is compatible with various prompt methods.\\
   
   \hline
   \multirow{2}{*}{\textbf{DIKI}~\cite{tang2025mind}} & 
To reduce catastrophic forgetting.& DIKI proposes a residual mechanism and distribution-aware calibration.\\
         
   \hline
   \multirow{2}{*}{\textbf{GMM}~\cite{cao2024generative}} & 
To reduce catastrophic forgetting.& GMM implements incremental learning through generated label text and feature matching.\\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{PriViLege}\\~\cite{park2024pre}}} & 
To address catastrophic forgetting and overfitting in MLLMs.& PriViLege proposes prompt functionality and knowledge distillation.\\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{ModalPrompt}\\~\cite{zeng2024modalprompt}}} & 
To address catastrophic forgetting and overfitting in MLLMs.& ModalPrompt proposes bi-modal guided prototype prompts and knowledge transfer.\\
         
   \hline
   \multirow{2}{*}{\textbf{CGIL}~\cite{frascaroli2024clip}} & 
To reduce catastrophic forgetting.& CGIL uses VAEs to learn class-conditioned distributions and generate synthetic samples.\\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{CoLeCLIP}\\~\cite{li2024coleclip}}} & 
To  reduce interference between tasks.& CoLeCLIP proposes joint learning of task prompts and cross-domain vocabularies.\\
         
   \hline
   \multirow{2}{*}{\textbf{ICL}~\cite{qi2024interactive}} & 
To enhance the efficiency of continual learning in MLLMs.& ICL enables interaction between a fast intuition model and a slow deep thinking model.\\
         
   \hline
   \multirow{2}{*}{\textbf{EMT}~\cite{zhai2023investigating}} & 
To evaluate catastrophic forgetting in MLLMs.& EMT offers a new perspective for improving fine-tuning strategies in MLLMs.\\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{Freeze-Omni}\\~\cite{wang2024freeze}}} & 
To reduce catastrophic forgetting.& Freeze-Omni implements a three-stage training strategy.\\
         
   \hline
   \multirow{2}{*}{\textbf{Adapt-$\infty$}~\cite{maharana2024adapt}} & 
To reduce catastrophic forgetting.& Adapt-$\infty$ proposes dynamic data selection and a clustering-based permanent pruning strategy.\\
         
   \hline
   \multirow{3}{*}{\makecell{\textbf{Mono-}\\ \textbf{InternVL}~\cite{luo2024mono}}} & 
To address the performance degradation and catastrophic forgetting issues that arise when expanding the visual and language capabilities of MLLMs.& Mono-InternVL integrates visual experts using a MOE structure and introduces endogenous visual pretraining.\\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{MoExtend}\\~\cite{zhong2024moextend}}} & 
To  address the issues of catastrophic forgetting and high training costs.& MoExtend designes a three-stage training process, including alignment, extension, and fine-tuning.\\


    \hline
    \end{tabularx}
  \label{CL_MLLM_Framework}%
  \vspace{-5mm} 
\end{table*}%



\section{Continual Learning in MLLMs}

\subsection{Preliminary}

Recent advancements in MLLMs have shown remarkable capabilities across various domains. However, as their scale grows, maintaining long-term effectiveness in dynamic environments is a critical challenge~\cite{young2014image,achiam2023gpt,anil2023palm,bai2023qwen,chen2015microsoft,chen2024internvl,panagopoulou2023x,dong2024internlm,fu2024video,goyal2017making,gurari2018vizwiz,liu2024llava}. CL addresses this by enabling models to learn new tasks without forgetting previously acquired knowledge in evolving data and task contexts. For MLLMs, continual learning is more complex due to the vast data and complex computations involved, requiring significant computational resources and storage. Although existing research provides valuable theoretical and experimental insights~\cite{liu2025mmbench,luo2024cheap,yang2023dawn,team2023gemini,team2023internlm,touvron2023llama,wang2023cogvlm,wu2024parameter,yue2024mmmu}, applying MLLMs to continual learning still faces many challenges. This section explores innovations in multimodal large model continual learning and the related evaluation benchmarks.


\subsection{Model Innovation}

As shown in Tables~\ref{CL_MLLM_Framework} and~\ref{CL_MLLM_Method}, to achieve multi-task CL in multimodal large models and avoid catastrophic forgetting, researchers have proposed numerous innovative frameworks and methods~\cite{li2024coleclip,qi2024interactive,maharana2024adapt,luo2024mono,lester2021power,yan2022generative,villa2023pivot,he2024towards}. These innovations not only facilitate knowledge sharing and transfer between multiple tasks but also effectively address challenges such as catastrophic forgetting, modality conflicts, and computational resource constraints. These efforts collectively advance the continual learning capabilities of multimodal large models in dynamic environments.
More details of the model innovation in the continual learning of MLLMs are provided in Section \ref{Appendix_MLLMCL} of the Appendix.

\begin{table*}[htbp]
\small
\renewcommand\arraystretch{1.2}
  \centering
  \caption{Innovations in MLLModel CL Methods.}
    \begin{tabularx}{\textwidth}{>{\centering\arraybackslash}m{2cm}|p{0.4\textwidth}|p{0.4\textwidth}}
    \hline
   \multicolumn{1}{c|}{Method} & \multicolumn{1}{c|}{Starting point of the problem} & \multicolumn{1}{c}{How to solve} \\
         
   \hline
   \multirow{2}{*}{\textbf{NoRGa}~\cite{yu2024llms}} & 
To enhance the continual learning performance of multimodal large language models. & NoRGa proposes the non-linear residual gate.\\
         
   \hline
   \multirow{2}{*}{\textbf{ZAF}~\cite{gaostabilizing}} & 
To reduce catastrophic forgetting.& ZAF preserves knowledge through zero-shot stability regularization. \\
         
   \hline
   \multirow{3}{*}{\makecell{\textbf{DualLoRA}\\~\cite{chen2024dual}}} & 
Improving the efficiency and effectiveness of continual learning in multimodal large language models.& DualLoRA utilizes orthogonal and residual low-rank adapters along with a dynamic memory mechanism to balance model stability and plasticity. \\
         
   \hline
   \multirow{3}{*}{\textbf{LPI}~\cite{yan2024low}} & 
To address the insufficient interaction between modalities and tasks.& LPI enhances inter-modal and inter-task interactions through low-rank decomposition and contrastive learning. \\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{Model Tailor}\\~\cite{zhu2024model}}} & 
To reduce catastrophic forgetting.& Retaining most of the pre-trained parameters and  replacing a small number of fine-tuned parameters. \\
         
   \hline
   \multirow{2}{*}{\textbf{HVCLIP}~\cite{vesdapunt2025hvclip}} & 
Enhancing the model's ability to retain critical information while adapting to new tasks or domains.& HVCLIP uses strategies such as forgetting reduction, discrepancy reduction, and feature enhancement. \\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{Continual}\\ \textbf{LLaVA}~\cite{cao2024continual}}} & 
Enhancing the ability to preserve knowledge from previous tasks while accommodating new ones..& Continual LLaVA proposes a parameter-efficient tuning method that does not require rehearsal. \\
         
   \hline
   \multirow{2}{*}{\textbf{LLaCA}~\cite{qiao2024llaca}} & 
To reduce forgetting and lower computational costs.& LLaCA dynamically adjusts the EMA weights and introduces an approximation mechanism. \\
         
   \hline
   \multirow{2}{*}{\textbf{CVM}~\cite{rebillard2024continually}} & 
To reduce forgetting and improve generalization.&CVM maps the representations of small visual models to the knowledge space of a fixed LLM. \\
         
   \hline
   \multirow{2}{*}{\textbf{RE-tune}~\cite{mistretta2024re}} & 
Addressing challenges related to computational resources, data privacy, and catastrophic forgetting.& RE-tune freezes the backbone of the model and trains adapters, using text prompts to guide training. \\
         
   \hline
   \multirow{2}{*}{\textbf{CluMo}~\cite{cai2024clumo}} & 
Enhancing the performance of MLLMs in CL and improving their ability to retain old knowledge.& CluMo employs a two-stage training and modality fusion prompt strategy. \\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{Fwd-Prompt}\\~\cite{zheng2024beyond}}} & 
To achieve anti-forgetting and positive transfer.& Fwd-Prompt utilizes gradient projection techniques and proposes a multimodal prompt pool. \\
         
   \hline
   \multirow{2}{*}{\makecell{\textbf{CPE-CLIP}\\~\cite{d2023multimodal}}} & 
Enhancing the performance of few-shot class incremental learning in MLLMs.& CPE-CLIP using learnable prompts and regularization strategies. \\
         
   \hline
   \multirow{2}{*}{\textbf{TG}~\cite{zhang2024preserving}} & 
To reduce catastrophic forgetting.& TG proposes the model-agnostic self-uncompression method. \\
         
   \hline
   \multirow{2}{*}{\textbf{LiNeS}~\cite{wang2024lines}} & 
Preserving the generalization ability of pretraining while improving fine-tuning task performance. & LiNeS proposes parameter updates with differentiated layer depth. \\
         
   \hline
   \multirow{2}{*}{\textbf{AttriCLIP}~\cite{wang2023attriclip}} & 
Enhancing the generalization and continual learning capabilities of MLLMs in multimodal tasks. & AttriCLIP adapts to new tasks using an attribute lexicon and textual prompts. \\
         
   \hline
   \multirow{2}{*}{\textbf{AttriCLIP}~\cite{wang2023attriclip}} & 
Enhancing the generalization and continual learning capabilities of MLLMs in multimodal tasks. & AttriCLIP adapts to new tasks using an attribute lexicon and textual prompts. \\
         
   \hline
   \multirow{2}{*}{\textbf{C-LoRA}~\cite{smith2023continual}} & 
To reduce catastrophic forgetting.& C-LoRA performs continual adaptive low-rank adjustments in the cross-attention layers of MLLMs. \\


    \hline
    \end{tabularx}
  \label{CL_MLLM_Method}%
  \vspace{-5mm} 
\end{table*}%

\subsection{Benchmarks}

As the application of multimodal large models in continual learning increases, evaluating their CL capability has become a key issue. To comprehensively assess the continual learning performance of multimodal large models, benchmarks and evaluation frameworks have emerged. However, benchmarks specifically designed for continual learning in multimodal large models are still relatively scarce, and the relevant evaluation standards are still in the process of development. Section~\ref{MLLMCLBenchmark} in the Appendix analyzes and lists the few existing benchmarks to evaluate the continual learning capability of multimodal large models, exploring their design concepts, evaluation metrics, and applicability in different application scenarios.

Existing benchmarks for multimodal large model continual learning provide some reference value for assessing a model's learning ability. However, due to the scarcity of such benchmarks, with only a few available for use, many issues and limitations remain to be addressed. In the future, there is a need to design more comprehensive, flexible, and scalable evaluation benchmarks to meet the evolving demands of multimodal large model continual learning technologies. 




% todo
% 1. 图标风格统一（格式统一）
% 2. 表格重新绘画一下
% 3. pipline