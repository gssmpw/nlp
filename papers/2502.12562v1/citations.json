[
  {
    "index": 0,
    "papers": [
      {
        "key": "zou2023universal",
        "author": "Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt",
        "title": "Universal and transferable adversarial attacks on aligned language models"
      },
      {
        "key": "liu2023autodan",
        "author": "Liu, Xiaogeng and Xu, Nan and Chen, Muhao and Xiao, Chaowei",
        "title": "Autodan: Generating stealthy jailbreak prompts on aligned large language models"
      },
      {
        "key": "chao2023jailbreaking",
        "author": "Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric",
        "title": "Jailbreaking black box large language models in twenty queries"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "gong2023figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "Figstep: Jailbreaking large vision-language models via typographic visual prompts"
      },
      {
        "key": "luo2024jailbreakv",
        "author": "Luo, Weidi and Ma, Siyuan and Liu, Xiaogeng and Guo, Xiaoyu and Xiao, Chaowei",
        "title": "Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "li2024images",
        "author": "Li, Yifan and Guo, Hangyu and Zhou, Kun and Zhao, Wayne Xin and Wen, Ji-Rong",
        "title": "Images are achilles\u2019 heel of alignment: Exploiting visual vulnerabilities for jailbreaking multimodal large language models"
      },
      {
        "key": "qi2024visual",
        "author": "Qi, Xiangyu and Huang, Kaixuan and Panda, Ashwinee and Henderson, Peter and Wang, Mengdi and Mittal, Prateek",
        "title": "Visual adversarial examples jailbreak aligned large language models"
      },
      {
        "key": "niu2024jailbreaking",
        "author": "Niu, Zhenxing and Ren, Haodong and Gao, Xinbo and Hua, Gang and Jin, Rong",
        "title": "Jailbreaking attack against multimodal large language model"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "schulman2017proximal",
        "author": "Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg",
        "title": "Proximal policy optimization algorithms"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "chakraborty2024cross",
        "author": "Chakraborty, Trishna and Shayegani, Erfan and Cai, Zikui and Abu-Ghazaleh, Nael and Asif, M Salman and Dong, Yue and Roy-Chowdhury, Amit K and Song, Chengyu",
        "title": "Cross-Modal Safety Alignment: Is textual unlearning all you need?"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "hu2024vlsbench",
        "author": "Hu, Xuhao and Liu, Dongrui and Li, Hao and Huang, Xuanjing and Shao, Jing",
        "title": "Vlsbench: Unveiling visual leakage in multimodal safety"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "liu2024mm",
        "author": "Liu, Xin and Zhu, Yichen and Gu, Jindong and Lan, Yunshi and Yang, Chao and Qiao, Yu",
        "title": "Mm-safetybench: A benchmark for safety evaluation of multimodal large language models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "shi2024assessment",
        "author": "Shi, Zhelun and Wang, Zhipin and Fan, Hongxing and Zhang, Zaibin and Li, Lijun and Zhang, Yongting and Yin, Zhenfei and Sheng, Lu and Qiao, Yu and Shao, Jing",
        "title": "Assessment of multimodal large language models in alignment with human values"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "chen2024dress",
        "author": "Chen, Yangyi and Sikka, Karan and Cogswell, Michael and Ji, Heng and Divakaran, Ajay",
        "title": "Dress: Instructing large vision-language models to align and interact with humans via natural language feedback"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "gong2023figstep",
        "author": "Gong, Yichen and Ran, Delong and Liu, Jinyuan and Wang, Conglei and Cong, Tianshuo and Wang, Anyu and Duan, Sisi and Wang, Xiaoyun",
        "title": "Figstep: Jailbreaking large vision-language models via typographic visual prompts"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "gu2024mllmguard",
        "author": "Gu, Tianle and Zhou, Zeyang and Huang, Kexin and Liang, Dandan and Wang, Yixu and Zhao, Haiquan and Yao, Yuanqi and Qiao, Xingge and Wang, Keqing and Yang, Yujiu and others",
        "title": "MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "luo2024jailbreakv",
        "author": "Luo, Weidi and Ma, Siyuan and Liu, Xiaogeng and Guo, Xiaoyu and Xiao, Chaowei",
        "title": "Jailbreakv-28k: A benchmark for assessing the robustness of multimodal large language models against jailbreak attacks"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yang2024audio",
        "author": "Yang, Hao and Qu, Lizhen and Shareghi, Ehsan and Haffari, Gholamreza",
        "title": "Audio Is the Achilles' Heel: Red Teaming Audio Large Multimodal Models"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "ying2024safebench",
        "author": "Ying, Zonghao and Liu, Aishan and Liang, Siyuan and Huang, Lei and Guo, Jinyang and Zhou, Wenbo and Liu, Xianglong and Tao, Dacheng",
        "title": "Safebench: A safety evaluation framework for multimodal large language models"
      }
    ]
  }
]