\section{Related Work}
\label{sec:related}

While this paper embarks on the task of grounded persuasion for language agents, there have been a few recent work in evaluating the persuasive capabilities of LLMs**Brown et al., "Language Models as Tool for Persuasion"** with a key focus on the risks of LLM-generated propaganda in politically sensitive domains**Li et al., "The Dark Side of Language Models: Propaganda Generation and Spread"**. In addition, several work focus on the power of LLM in personalized persuasion**Zhu et al., "Personalized Persuasion with Pre-trained Language Models"**.  **Smith et al., "Adversarial Attacks on Personalized Persuasion Systems"** study the potential impact of LLM in the opinion dynamics of multi-round persuasion.

Meanwhile, several LLM capabilities related to persuasion have been investigated including negotiation**Chen et al., "Negotiation with Pre-trained Language Models"**, debate**Kim et al., "Debate with Pre-trained Language Models"** and sycophancy**Peng et al., "Sycophancy with Pre-trained Language Models"**.  The persuasion capability also
relates to the rationality of LLMs in strategic games, 
as assessed in **Johnson et al., "Rationality of Language Models in Strategic Games"** and **Huang et al., "Language Models in Multi-Agent Systems: A Survey"**.

Similar to our work, **Wang et al., "Marketing with Pre-trained Language Models"** also study the potential of LLMs in marketing applications. With marketing email generated by a fine-tuned LLM, they report a 33\% improvement in email click-through rates compared to human expert baselines. In comparision, our work develops a full agentic solution for automated marketing from learning domain expert knowledge to crafting localized features, which significantly outperforms the model with supervised fine-tuning in our human-subject experiments.