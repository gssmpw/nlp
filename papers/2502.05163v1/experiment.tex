\begin{table*}[!t]
    \centering
    \caption{Detailed F-1 scores on the classification benchmarks. The \textbf{bold} numbers indicate the best results among the methods evaluated and the \underline{underscored} numbers represent the second-best results.}
    \resizebox{\linewidth}{!}{%
\begin{tblr}{colspec = {cccccccccccccccc},
row{1-2, 8-9} = {bg=gray!25},
row{4, 6, 11, 13} = {bg=gray!10}
}
    \toprule 
    \SetCell[r=2]{c}{Model} & \SetCell[r=2]{c}{Size} $\downarrow$ & \SetCell[c=7]{c}{English} $\uparrow$ & & & & & & & \SetCell[c=7]{c}{German} $\uparrow$ & & & & & & \\
    \cmidrule[lr]{3-9} \cmidrule[lr]{10-16}   
    & & XSTest & OpenAI & ToxicC. & BeaverT. & RTP-LX & XSafety & \textbf{Average} & XSTest & OpenAI & ToxicC. & BeaverT. & RTP-LX & XSafety & \textbf{Average}\\
    \midrule
    LlamaGuard3 & 1B & 43.4 & 36.8 & 22.3 & 51.6 & \underline{54.6} & \textbf{62.3} & 45.2 & 43.0 & 37.4 & 20.9 & 50.2 & \underline{55.4} & \textbf{61.4} & 44.7 \\
    ShieldGemma & 2B & 69.4 & 44.8 & 36.4 & 51.6 & 26.0 & 30.6 & 43.1 & 59.6 & 38.7 & 27.5 & 51.6 & 19.5 & 24.1 & 36.8 \\
    LlamaGuard2 & 8B & \textbf{88.8} & \underline{75.9} & 46.3 & \underline{72.3} & 39.5 & 35.2 & 59.7 & \underline{79.8} & \underline{74.4} & 40.5 & 68.5 & 38.7 & 30.6 & 55.4 \\
    LlamaGuard3 & 8B & \underline{88.4} & \textbf{79.0} & \underline{54.0} & 70.1 & 48.5 & 40.5 & \underline{63.4} & \textbf{82.9} & \textbf{78.5} & \underline{48.0} & \underline{70.4} & 50.2 & 37.8 & \underline{61.3} \\
    \midrule
    \ours & \textbf{0.5B} & 82.3 & 70.8 & \textbf{70.1} & \textbf{86.1} & \textbf{91.7} & \underline{48.5} & \textbf{74.9} & 75.8 & 65.9 & \textbf{61.4} & \textbf{80.8} & \textbf{87.3} & \underline{60.4} & \textbf{71.9} \\
    \bottomrule
    \toprule 
    \SetCell[r=2]{c}{Model} & \SetCell[r=2]{c}{Size} $\downarrow$ & \SetCell[c=7]{c}{French} $\uparrow$ & & & & & & & \SetCell[c=7]{c}{Spanish} $\uparrow$ & & & & & & \\
    \cmidrule[lr]{3-9} \cmidrule[lr]{10-16}   
    & & XSTest & OpenAI & ToxicC. & BeaverT. & RTP-LX & XSafety & \textbf{Average} & XSTest & OpenAI & ToxicC. & BeaverT. & RTP-LX & XSafety & \textbf{Average}\\
    \midrule
    LlamaGuard3 & 1B & 43.0 & 37.8 & 19.5 & 50.9 & \underline{54.9} & \textbf{61.3} & 44.6 & 46.9 & 37.9 & 20.4 & 50.3 & \underline{52.1} & \textbf{62.1} & 45.0 \\
    ShieldGemma & 2B & 63.3 & 36.8 & 28.7 & 50.1 & 21.5 & 23.9 & 37.4 & 62.4 & 37.7 & 29.1 & 50.8 & 17.8 & 24.0 & 37.0 \\
    LlamaGuard2 & 8B & \underline{81.6} & \underline{74.5} & 39.7 & 68.6 & 40.0 & 35.4 & 56.6 & \underline{84.0} & \underline{74.8} & 39.2 & 67.5 & 39.4 & 33.8 & 56.5 \\
    LlamaGuard3 & 8B & \textbf{84.4} & \textbf{78.1} & \underline{50.1} & \underline{69.5} & 48.8 & 40.3 & 61.9 & \textbf{86.2} & \textbf{77.7} & \underline{48.4} & 69.5 & 48.4 & 39.0 & \underline{61.5} \\
    \midrule
    \ours & \textbf{0.5B} & 79.2 & 67.1 & \textbf{62.8} & \textbf{81.3} & \textbf{91.0} & \underline{54.7} & \textbf{72.7} & 81.4 & 66.8 & \textbf{64.9} & \textbf{81.4} & \textbf{88.0} & \underline{61.0} & \textbf{73.9}\\
    \bottomrule
    \end{tblr}%
    }
    \label{tab:main}
    \vspace{-4mm}
\end{table*}

\textbf{Setup.}  
In our experiments, we use Qwen2.5-0.5B and Qwen2.5-1.5B~\citep{qwen2.5} as the base models for the classifier, since the guardrail model is typically a small-scale model and Qwen2.5-0.5B and Qwen2.5-1.5B models are among the most effective small-scale multilingual models available. In addition, we use dolphin-2.9.4-llama3.1-8b\footnote{https://huggingface.co/cognitivecomputations/dolphin-2.9.4-llama3.1-8b} as the base model for the generator, which is an uncensored multilingual model that meets our requirements for generating harmful queries in multiple languages. We follow the optimization process outlined in Section~\ref{sec:practical} and Algorithm~\ref{alg:adversarial-training} to train both models, applying full fine-tuning to the classifier and generator.  
For baselines, we compare against specialized guardrail models, including LlamaGuard3~\citep{inan2023llama} (1B) and ShieldGemma~\citep{zeng2024shieldgemma} (2B), which are SOTA models of similar scale to \ours. Additionally, we include larger-scale versions of LlamaGuard2 (8B) and LlamaGuard3 (8B) for a more comprehensive comparison. Experiments were conducted on NVIDIA H100 80GB GPU clusters and we detail the hyperparameters in Appendix~\ref{app:exp}. 


\textbf{Data.} To construct the seed dataset, we gather and combine training data from existing open-source data related to safety and toxicity, with detailed source information provided in Appendix~\ref{app:data}. We note that, instruction-following and QA data in sensitive domains (e.g., medical, legal, political) were also selected as benign examples containing potentially sensitive keywords. To prevent the classifier from relying on superficial keyword cues, we downsampled harmful examples dominated by specific terms. Harmful examples were further categorized into 12 groups, with an LLM assisting in labeling when category boundaries were ambiguous. Duplicate entries were removed to avoid overrepresentation, and the corpus was decontaminated to ensure no overlap with test data. 
The final linguistic composition of our gathered open-source dataset reveals a pronounced linguistic imbalance, where English data takes $81.4\%$ (1,679,516 instances), substantially predominating over French as $8.9\%$ (183,919), Spanish as $5.2\%$ (107,052), and German as $4.5\%$ (92,793). For generating the synthetic data, we set a temperature of 0.7 to encourage more diverse and creative generations and consider $k=8$.

\textbf{Evaluation.} We evaluate our method in four languages: English, French, German, and Spanish. We note that, while we considered the four languages to show the effectiveness of our data generation framework, \ours supports the 29 languages as its base model Qwen-2.5 does. 
For benchmarking guardrail models, we use six safety datasets: XSTest~\citep{rottger2023xstest}, ToxicChat~\citep{lin2023toxicchat}, OpenAI Moderation~\citep{markov2023holistic}, Beavertails~\citep{ji2024beavertails}, RTP-LX~\citep{de2024rtp}, and XSafety~\citep{wang2023all}. Among these, RTP-LX and XSafety are dedicated multilingual safety benchmarks, while the remaining four (XSTest, ToxicChat, OpenAI Moderation, and Beavertails) are commonly used English safety benchmarks. To enable multilingual evaluation, we translate these four datasets into languages that we considered.


\subsection{Main Results}
We present our main results in Figure~\ref{fig:main-res} and detail the performance on each dataset for each language in Table~\ref{tab:main}. \ours, demonstrates significant advantages over existing guardrail models in both performance and efficiency. As shown in Figure~\ref{fig:main-res}, \ours achieves the highest average F1 score across English, French, Spanish, and German, outperforming all baselines, including the larger-scale LlamaGuard3 (8B) model, by over 10\%. Compared to models of similar scale, such as LlamaGuard3 (1B) and ShieldGemma (2B), \ours surpasses their performance by more than 30\% on average. Additionally, \ours exhibits the lowest inference cost (16.47 ms/input), achieving over a 4.5$\times$ speedup compared to LlamaGuard3 (8B) (58.88 ms/input) and ShieldGemma (2B) (57.83 ms/input). This highlights the efficiency of our approach, as it not only surpasses larger models in multilingual safety performance but also maintains significantly lower computational overhead, making it more practical for real-world deployment. In Figure~\ref{fig:perf_decline}, we present the average performance of each model across the three non-English languages relative to the English performance of our model \ours. Here, \ours achieves the lowest performance decline across all languages as compared to the English performance.


\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/perf_decline.pdf}
    \vspace{-3mm}
    \caption{Relative performance decline (average F1 across six benchmarks and three languages) of various models compared to the English performance of \ours.}
    \label{fig:perf_decline}
\end{figure}

\subsection{Weak-to-Strong Generalization}
Weak-to-strong generalization refers to the ability of a weaker model to generalize in supervising the training of stronger models. In Table~\ref{tab:main-2}, we leverage the training data generated by our two-player framework to train Llama-3.2 (1B), the base model for LlamaGuard3 (1B), and Qwen-2.5 (1.5B), a larger-scale model used to evaluate the weak-to-strong generalization capabilities of our method. 
We draw the following observations: (1) While the final fine-tuning results vary across base models, the data generated by our framework generalizes effectively across architectures, consistently outperforming baselines trained on the same base model by more than 20\%. (2) The two-player framework demonstrates weak-to-strong generalization, as data generated with the 0.5B classifier significantly improves the performance of the 1.5B classifier.\vspace{-3mm}

\begin{table}[!ht]
    \centering
    \caption{Average F-1 scores across languages of different models trained with the dataset developed by our two-player scheme. The data can easily generalize to different base models (Llama-3.2) and different scales (1.5B).}
    \resizebox{0.9\linewidth}{!}{%
\begin{tblr}{colspec = {cccccccccccccccc},
row{1} = {bg=gray!25},
row{3,5} = {bg=gray!10}
}
    \toprule 
    Model & Base & Size & En & Fr & Es & De\\
    \midrule
    LlamaGuard3 & Llama-3.2 & 1B & 45.2 & 44.6 & 45.0 & 44.7 \\
    \ours & Llama-3.2 & 1B & \textbf{75.7} & \textbf{74.4} & \textbf{71.7} & \textbf{71.3} \\
    \midrule
    \ours & Qwen-2.5 & 0.5B & 74.9 & 71.9 & 72.7 & 73.9 \\
    \ours & Qwen-2.5 & 1.5B & \textbf{76.2} & \textbf{75.0} & \textbf{73.7} & \textbf{74.0} \\
    \bottomrule
    \end{tblr}%
    }
    \label{tab:main-2}
\end{table}

\textbf{Note.} \ours moderates content across 12 distinct subcategories as outlined in Appendix~\ref{app:data}. Each forward pass produces a 12-dimensional logits vector—one dimension per risk area. Applying a sigmoid function yields a multi-label probability distribution, enabling fine-grained detection of potentially unsafe content. For binary moderation, we compare the maximum subcategory probability to a threshold (e.g., 0.5). If it exceeds the threshold, the content is labeled “unsafe”; otherwise, “safe.” Although our main evaluation adopts binary classification for consistency, \ours can provide detailed reasons for flagging content. Additionally, adjusting the final threshold (or applying individual thresholds) allows for customizable caution levels.

\section{Ablation Study}
\subsection{Seed Data}
\textbf{Benefit of Incorporating Multilingual Data.} 
We evaluate three training configurations using only the seed dataset: training on English data alone, training on English and French data, and training on all four languages. Figure~\ref{fig:training_heatmap} presents the F1 scores on the OpenAI moderation test set for models trained under these conditions, all based on the \texttt{Qwen2.5-0.5B} model.  
Interestingly, training exclusively on English provides a relatively strong foundation for performance on French but is weaker on Spanish and German. Incorporating French data significantly improves performance on the French-translated OpenAI test set (from 51.3 to 65.2) while also enhancing performance on the Spanish- and German-translated test sets by 7.4 and 12.9 points, respectively. Additionally, English and French data appear to be mutually beneficial. 
The inclusion of Spanish and German data further improves performance on their respective test sets. However, as their addition reduces the proportion of English and French data, it leads to a slight performance decline overall.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.66\linewidth]{figures/training_heatmap.pdf}
    \vspace{-3mm}
    \caption{The F1 score on OpenAI benchmark of models trained with data containing different languages in our seed data. The inclusion of French in addition to English improves model performance on Spanish (36.9\% to 62.8\%) and German (31.9 to 59.6).}
    \label{fig:training_heatmap}
\end{figure}

\textbf{Performance Differences Due to Disproportionate Data.}  
Figure~\ref{fig:acc_prop} illustrates the relationship between training data volume per language and model performance (average F1 scores) across six benchmarks. The model is trained on the entire seed dataset, without synthetic data augmentation. The horizontal axis represents languages (English, French, Spanish, and German), while the left and right vertical axes indicate F1 scores and training data volume in the seed data, respectively.  
A clear trend emerges: languages with larger training datasets (e.g., English) achieve higher F1 scores, while those with less data (e.g., Spanish, German) perform worse. Although the performance gap varies across test sets, F1 scores consistently decline with reduced dataset size. This underscores the importance of synthetic data in mitigating performance disparities for low-resource languages.  
While the base LLM (Qwen-2.5 in our case) may have inherent limitations on low-resource languages, our method and the results of \ours demonstrate that incorporating synthetic multilingual data during post-training can significantly reduce this gap for the downstream task we consider.  

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/acc_prop.pdf}
    \vspace{-3mm}
    \caption{Performance by languages of the model trained on seed data. With larger data proportion in seed data, the model's average performance on English is markedly higher than on other languages.}
    \label{fig:acc_prop}
\end{figure}

\begin{tcolorbox}[colback=gray!10, colframe=black!80, title=Takeaways., sharp corners, boxrule=0.3pt, fonttitle=\bfseries]
\begin{itemize}[leftmargin=*]
    \item Incorporating multilingual data improves model generalization across languages.
    \item More available real data (e.g., English) yields better performance, underscoring the need for synthetic data in low-resource languages.
\end{itemize}
\end{tcolorbox}

\subsection{Synthetic Data}
\textbf{Iterative Improvement.} 
In Figure~\ref{fig:iterative}, we demonstrate the iterative improvement of the guardrail classifier in average F1 scores across English (En), French (Fr), Spanish (Es), and German (De) on the 6 benchmarks. Starting from iteration 0, which represents the baseline performance of training on seed data, substantial improvements are observed for all non-English languages after the first iteration. We particularly observe large gains in Spanish and German, highlighting the effectiveness of the iterative process in bridging performance gaps for lower-resource languages. By iteration 2, the performance for all languages converges, with Spanish and German achieving scores comparable to French, and all non-English languages narrowing the gap with English. In Figure~\ref{fig:data-dist}, we further show the data proportion across languages for iteration 0 (seed data) and synthetic data generated at iteration 1. In iteration 0, English dominates with 81\% of the data, while other languages (French, German, and Spanish) collectively account for less than 20\%. At iteration 1, the distribution for synthetic balances with the seed data, with English decreasing to 13\%, and significant increases in French (27\%), German (35\%), and Spanish (24\%). 

\begin{figure}[!ht]
    \centering
    % Subfigure 1
    \subfigure[]{
        \includegraphics[width=0.46\linewidth]{figures/iterative.pdf}
        \label{fig:iterative}
    }
    \hfill
    % Subfigure 2
    \subfigure[]{
        \includegraphics[width=0.46\linewidth]{figures/data_distribution.pdf}
        \label{fig:data-dist}
    }
    \vspace{-6mm}
    \caption{(a) Iterative performance improvements of \ours. (b) Shift in data distribution across languages over iterations.}
    \label{fig:combined}
\end{figure}

\begin{table}[!ht]
    \centering
    \caption{Model's average F1 with different training data at Iter1.}
    \resizebox{0.8\linewidth}{!}{%
\begin{tblr}{colspec = {cccccccc},
row{1} = {bg=gray!25},
row{3,5,7,9,11,13,15} = {bg=gray!10}
}
    \toprule 
    Data & Seed (Iter0) & Unfiltered & Filtered (Iter1) \\
    \midrule
    F1 & 63.3 & 64.1 & \textbf{70.8} \\
    \bottomrule
    \end{tblr}%
    }
    \label{tab:ablation-filter}
\end{table}

\textbf{Quality over Quantity.} Since we generate eight candidate samples per input seed, one possible approach is to include all synthetic data in training. Table~\ref{tab:ablation-filter} compares classifier performance (average F1 across 6 benchmarks) at iteration 1 when trained on filtered misclassified data versus all generated synthetic data. While our framework's selected synthetic data leads to significant improvements, incorporating all generated data—including correctly classified samples—yields negligible gains, highlighting the importance of targeted data selection. Furthermore, we present an example comparing selected synthetic data to the full set of filtered data. The selected samples preserve ungrammatical and jumbled syntax, better reflecting real-world use cases and enhancing the model’s robustness in handling noisy inputs.  

\begin{tabular}{|m{1.5cm}|m{5.7cm}|}
\hline
\small Seed data & \small 
twats know fuck anything. \\
\hline
\small Generator (selected) & 
\small Stinkkäfer kennen fiesen Scheiß von nichts \\
\hline
\small Translation & 
\small Stink bugs don't know anything about nasty shits \\
\hline
\small Generator (filtered) & \small Arrogante Schwachköpfe behaupten, alles zu kennen, obschon sie eindeutig nichts Ahnung haben.\\
\hline
\small Translation & 
\small Arrogant idiots claim to know everything when they clearly have no idea. \\
\hline
\end{tabular}





\begin{tcolorbox}[colback=gray!10, colframe=black!80, title=Takeaways., sharp corners, boxrule=0.3pt, fonttitle=\bfseries]
\begin{itemize}[leftmargin=*]
    \item Iterative synthetic data generation reduced the imbalance and gap across languages in real data.
    \item Filtering synthetic data boosts classifier performance by removing lower-quality samples.
\end{itemize}
\end{tcolorbox}




