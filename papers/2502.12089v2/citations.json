[
  {
    "index": 0,
    "papers": [
      {
        "key": "block2020generative",
        "author": "Block, Adam and Mroueh, Youssef and Rakhlin, Alexander",
        "title": "Generative modeling with denoising auto-encoders and Langevin sampling"
      },
      {
        "key": "oko2023diffusion",
        "author": "Oko, Kazusato and Akiyama, Shunta and Suzuki, Taiji",
        "title": "Diffusion models are minimax optimal distribution estimators"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "de2022convergence",
        "author": "De Bortoli, Valentin",
        "title": "Convergence of denoising diffusion models under the manifold hypothesis"
      },
      {
        "key": "chen2023score",
        "author": "Chen, Minshuo and Huang, Kaixuan and Zhao, Tuo and Wang, Mengdi",
        "title": "Score approximation, estimation and distribution recovery of diffusion models on low-dimensional data"
      },
      {
        "key": "yuan2023reward",
        "author": "Yuan, Hui and Huang, Kaixuan and Ni, Chengzhuo and Chen, Minshuo and Wang, Mengdi",
        "title": "Reward-directed conditional diffusion: Provable distribution estimation and reward improvement"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "biroli2023generative",
        "author": "Biroli, Giulio and M{\\'e}zard, Marc",
        "title": "Generative diffusion in very large dimensions"
      },
      {
        "key": "shah2023learning",
        "author": "Shah, Kulin and Chen, Sitan and Klivans, Adam",
        "title": "Learning mixtures of gaussians using the ddpm objective"
      },
      {
        "key": "Cui2023AnalysisOL",
        "author": "Cui, Hugo and Krzakala, Florent and Vanden-Eijnden, Eric and Zdeborov{\\'a}, Lenka",
        "title": "Analysis of learning a flow-based generative model from limited sample complexity"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "mei2023deep",
        "author": "Song Mei and Yuchen Wu",
        "title": "Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "kadkhodaie2023learning",
        "author": "Kadkhodaie, Zahra and Guth, Florentin and Mallat, St{\\'e}phane and Simoncelli, Eero P",
        "title": "Learning multi-scale local conditional probability models of images"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "okawa2023compositional",
        "author": "Okawa, Maya and Lubana, Ekdeep S and Dick, Robert and Tanaka, Hidenori",
        "title": "Compositional abilities emerge multiplicatively: Exploring diffusion models on a synthetic task"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "kamb2024analytic",
        "author": "Kamb, Mason and Ganguli, Surya",
        "title": "An analytic theory of creativity in convolutional diffusion models"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "sclocchi2024phase",
        "author": "Sclocchi, Antonio and Favero, Alessandro and Wyart, Matthieu",
        "title": "A phase transition in diffusion models reveals the hierarchical nature of data"
      },
      {
        "key": "sclocchi2024probing",
        "author": "Sclocchi, Antonio and Favero, Alessandro and Levi, Noam Itzhak and Wyart, Matthieu",
        "title": "Probing the latent hierarchical structure of data via diffusion models"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "mei2024unets",
        "author": "Song Mei",
        "title": "U-Nets as Belief Propagation: Efficient Classification, Denoising, and Diffusion in Generative Hierarchical Models"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "cagnetta2023deep",
        "author": "Cagnetta, Francesco and Petrini, Leonardo and Tomasini, Umberto M and Favero, Alessandro and Wyart, Matthieu",
        "title": "How deep neural networks learn compositional data: The random hierarchy model"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "cagnetta2024towards",
        "author": "Francesco Cagnetta and Matthieu Wyart",
        "title": "Towards a theory of how the structure of language is acquired by deep neural networks"
      },
      {
        "key": "allen2023physics",
        "author": "Allen-Zhu, Zeyuan and Li, Yuanzhi",
        "title": "Physics of Language Models: Part 1, Context-Free Grammar"
      },
      {
        "key": "garnier2024transformers",
        "author": "Garnier-Brun, J{\\'e}r{\\^o}me and M{\\'e}zard, Marc and Moscato, Emanuele and Saglietti, Luca",
        "title": "How transformers learn structured data: insights from hierarchical filtering"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "cagnetta2024towards",
        "author": "Francesco Cagnetta and Matthieu Wyart",
        "title": "Towards a theory of how the structure of language is acquired by deep neural networks"
      }
    ]
  }
]