\section{Related Work}
\textbf{o1-Like LLMs} Recently, o1-Like LLMs have shown exceptional performance in reasoning tasks, especially in mathematics and coding. Following OpenAI's O1 model~\cite{openai2024reasoning}, significant efforts have been made to replicate its success. \citealp{DBLP:journals/corr/abs-2410-18982} introduced journey learning, a training paradigm that enhances long-term reasoning with only 327 training samples. \citealp{DBLP:journals/corr/abs-2411-16489} demonstrated the effectiveness of data distillation from existing o1-Like models. \citealp{DBLP:journals/corr/abs-2411-14405} proposed the Marco-o1 model, combining Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), and reflection mechanisms to tackle open-ended problems. \citealp{guo2025deepseek} introduced the DeepSeek-R1 model, enhancing reasoning through multi-stage training and reinforcement learning (RL). QwQ~\cite{qwen2024qwq} model based on the Qwen architecture excel in mathematics and coding tasks but facing challenges like language mixing and circular reasoning. \citealp{DBLP:journals/corr/abs-2412-17498} proposed the DRT-o1 model, applying long CoT to MT, showing superior translation capabilities, especially with literature texts involving metaphors and similes.

\textbf{Machine Translation with Large Language Models (LLM-MT)}. Large language models, such as ChatGPT~\cite{ouyang2022training}, have shown significant effectiveness in machine translation across various language pairs~\cite{hendy2023good,jiao2023chatgpt,le2023bloom,DBLP:conf/wmt/IyerCB23,DBLP:journals/corr/abs-2311-02851,DBLP:conf/wmt/KarpinskaI23,DBLP:conf/wmt/MoslemRMKHW23,DBLP:conf/emnlp/WangLJZY0T23,DBLP:conf/wmt/IyerCB23,DBLP:conf/emnlp/FarinhasSM23}. Recent research has explored the performance of LLMs in machine translation, including control over formality in translation outputs~\cite{garcia2022using}, in-context translation abilities during pre-training ~\cite{shin2022effect}, and the impact of LLM-based machine translation on culturally sensitive texts~\cite{DBLP:journals/corr/abs-2305-14328}. Additionally, studies have examined the bilingual capabilities of LLMs to enhance translation performance~\cite{huang2024aligning}. For translation tasks requiring reasoning, multi-agent debates can effectively enhance the reasoning abilities of LLM-MT~\cite{liang2023encouraging}. These investigations further validate the research value of LLM-MT, offering diverse research directions for scholars.





% \textbf{Dataset}: We conduct experiments on two MT benchmarks: cultural MT and RTT test data. The cultural MT dataset \cite{DBLP:journals/corr/abs-2305-14328} introduces a culturally relevant parallel corpus, enriched with annotations of cultural-specific items. This dataset encompasses 6 language pairs: En$\rightarrow$Es, En$\rightarrow$Fr, En$\rightarrow$Hr, En$\rightarrow$Ta, En$\rightarrow$Te, and En$\rightarrow$Zh. It also encompasses over 7,000 cultural-specific items from 18 concept categories across more than 140 countries and regions. RTT test data is a new challenging test  set of English-German, increasing the average  constraint count per sentence from 1.1∼1.7 to  6.1 and the length per target constraint from  1.1∼1.2 words to 3.4 words.