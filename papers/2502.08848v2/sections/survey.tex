\begin{figure*}
\centerline{\includegraphics[width=0.7\linewidth]{images/survey/challenges.pdf}}
\caption{Participant responses to the question \emph{What are the biggest challenges with your current captioning or transcription device/technology? (select all that apply)?}}
\label{fig: survey-challenges}
\end{figure*}

\begin{figure*}
\centerline{\includegraphics[width=0.9\linewidth]{images/survey/scenarios_labels.pdf}}
\caption{Survey results of how often participants encountered challenging scenarios with today's transcription technology. The number of participants and percentage is shown for each choice.}
\label{fig: survey-scenarios}
\end{figure*}

\section{Challenges with mobile captioning: Large-Scale survey with 263 frequent users} \label{surveys_foundational}
As we were interested in exploring the potential for more advanced mobile speech perception, we conducted a brief large-scale survey to learn about the challenges of using captioning for speech understanding in in-person meetings and conversations. % and opportunities for more advanced mobile speech perception. 

\subsection{Participants}
We used Google Surveys \cite{GoogleSurveys} to deploy a survey to the general population in the US of all ages and genders (\emph{“Android users of the Google Opinion Rewards app”}), screening for individuals that use technology to understand speech in meetings and conversations, and are frequent users of captioning technology. Our goal was to recruit deaf or hard-of-hearing participants, as we believed that they would have the most relevant experience and insights around mobile captioning technology and interfaces. To mitigate spam, the survey system analyzes question response times. By considering the distribution of response times across questions, it adapts to different question types and response patterns, rejecting sessions with unusually fast responses.

We acknowledge that our survey's focus on frequent users of captioning technology and the growing user base for mobile captioning limits its relevance for other populations, such as individuals who identify with Deaf culture and might be less likely to rely on ASR technology \cite{deaf_community_questionnaires}. Unfortunately, we cannot quantify the representation in the survey since restrictions from our institution do not allow us to collect participant hearing levels or use of sign language. 

Of the 1502 respondents that met our criteria, we focus on the 263 participants (18\%), who reported that they used captioning technology to understand people (not TV/video) multiple times per week or more frequently, and for 2 hours or more on the days that they used it. For these 263 participants, the platform reported that 49.8\% were women, 48.7\% men, and 1.5\% unknown, across all age ranges (27\%: 18--24, 33\%: 25--34, 15\%: 35--44, 12\%: 45--54, 6\%: 55--64, 7\%: 65+). 

The participants were prompted to select challenges among the choices from the list in Figure~\ref{fig: survey-challenges}. The choices were synthesized by user feedback from our previous experience with mobile captioning and informed by previous work in mobile captioning~\cite{localization_glasses, wearable_subtitle}

\subsection{Survey results: The use of captioning to understand people in conversations}
64\% of the participants reported daily use of captions in meetings or conversations to understand people, whereas 36\% used it multiple times per week. Half of the participants (49\%) use technology to understand people face-to-face for 2-3 hours on the day of use. Almost a quarter (23\%) of participants use captions for 4-5 hours on the days of use and another quarter (28\%) for 6 or more hours. Real-time captions, such as CART (69\%), and the \emph{Android Live Transcribe and Sound Notifications} app (55\%) were the top two technologies that were used daily to understand people.  %See Figure \ref{fig: survey-usage}.

% \begin{figure}
% \centerline{\includesvg[width=0.75\columnwidth]{images/survey/usage.svg}}
% \caption{How often do you use captions/transcriptions in meetings/conversations to understand people? (e.g., CART, Live Transcribe - not including closed captions for TV/video)}.
% \label{fig: survey-usage}
% \end{figure}

The top two issues with current transcription technology, as reported by our participants, were background noise (60\%) and the combining of text from different speakers (46\%), without the ability to separate them. Participants selected all that apply from the choices shown in Figure ~\ref{fig: survey-challenges}.

Finally, we asked participants about scenarios that are known to be challenging with today's transcription technology but have the potential to be addressed with more advanced microphone arrays and speech perception algorithms. Scenarios of interest included conversations where ignoring music, noise, or adjacent speech would be critical. We were also interested in group conversations and situations where separating speech from two people is critical. 68-70\% of participants experienced these scenarios multiple times per week or more frequently, whereas only 11-12\% rarely or never experienced them, as shown in Figure \ref{fig: survey-scenarios}.

% 38-48\% of participants experienced these scenarios daily, and 25-29\% experienced them multiple times per week. 

\subsection{Discussion}

Our large-scale survey enabled us to identify essential challenges with current transcription technology for frequent users of captioning and shows that 68-70\% of the participants are frequently in situations that today's technology cannot adequately support. The findings suggest that more advanced speech technology for suppressing noise from adjacent speakers, music, or noise could help address those issues and that speech separation technology can potentially improve group conversations through more readable transcripts. 
