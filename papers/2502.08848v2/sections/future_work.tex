\section{Limitations and future work}
In this work, the microphone array topology was designed for experimentation and integration with mobile phones. In the future, we plan to explore other form factors such as smart glasses and smartwatches, where multiple microphones could also be used. To do so, we plan to create a microphone array platform for rapid prototyping where microphone topology can be easily reconfigured and customized with a user-friendly UI and software library.

Localization needs to be accurate in everyday scenarios that may suffer from external noise and interference sources. We plan to add machine learning approaches to improve the noise robustness of our current localization, which is based on classical linear signal processing. 

In our user studies, errors due to background noise were identified as a major issue with mobile ASR. In future work, background noise could be suppressed by using a steerable beamformer, which would benefit from more microphones. In our experimentation with classical beamforming techniques like filter-and-sum beamformer~\cite{benesty2008conventional} and Minimum Variance Distortionless Response (MVDR)~\cite{xiao2017mvdr}, we achieved a few dB SNR (signal-to-noise ratio) improvement with our microphone geometry. With the recent advances in neural beamformers~\cite{li2016neural, yang2024binaural}, which are trained beamformers, higher SNRs could be possible. 

\alex{added back the longitudinal research}
\jl{go deeper with user studies with more people -- more design and evaluation with more people --> add more about the why, e.g., larger study to improve and find best visualizations (validate)}
We are interested in scaling up the user evaluation, both with a larger set of participants and over longer time periods and in ecologically valid settings.
We therefore plan to conduct longitudinal user evaluations with frequent users of mobile ASR to further advance our understanding of the usability of this approach in the wild. 

%We also plan to conduct in-the-wild, long-term user evaluations with participants that use mobile speech-to-text today, to gather more insights into the usability of this approach. For such studies, we will also revise the LiveLocalizer phone-case for increased compactness and robustness for everyday use. 


%In this project, the geometry of the microphone array was fixed, which limits prototyping potential. In the future, we hope to explore other form factors such as smart glasses, and smartwatches, where multiple microphones could be used. To do so we plan to create a microphone array platform for fast prototyping that allows one to quickly change the geometry of the microphones and user-friendly software in a convenient environment such as Arduino.

%We have not explored all the spatial audio cues, that can be obtained from microphone arrays. For example, adding speaker distance estimation could be useful, as it would allow filtering speech-to-text based on the distance. For example, only transcribing people at the same table. Distance could be potentially estimated by measuring reverberance and classifying near and far field audio waves.   

%Localization and beamforming need to be accurate in everyday scenarios with a lot of external noise and interference sources. This is especially difficult for the classical linear signal processing approach that we show. We plan to add machine learning approaches to improve the noise robustness of localization and beamforming, as they can be trained for various scenarios. For example,  researchers have shown estimation of MVDR weights could be done effectively with machine learning.  

%The goal of the paper was to introduce multimicrophone technology to mobile speech-to-text applications, and our evaluation was done on the technology. We plan to conduct in-the-wild long-term user evaluation with the hearing accessibility population to fully understand the usability of this approach. For such studies, an engineering efford will be required to make the LiveLocalize phonecase slim enough and robust for everyday use. 

%Automatic Speech-to-text model switching

%Using multiple device to improve localization
%We can imagine a scenario where 





