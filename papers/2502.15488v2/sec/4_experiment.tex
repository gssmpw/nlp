\section{Experiment}

Detailed descriptions of benchmark, along with metric and further experimental details, are elaborated in Sup. \ref{sec:exp_setup}.

\subsection{Validation on PETR-series Methods}\label{sec:sota_exp}
We evaluate the effectiveness of our method on various PETR-series models from both FP and quantized performance perspectives, specifically considering single-frame PETR and temporal multi-frame StreamPETR models. \textbf{Firstly}, we analyze changes in floating-point performance (values in parentheses in Tab.~\ref{tab:validation_on_petr_series_methods}). In single-frame PETR models, mAP and NDS generally improve across configurations, except for a slight decrease of 0.06 in NDS when using V2-99’s P4 feature with 640×1600 resolution images. mAP increases range from 0.07 to 0.69, while NDS shows significant gains in all cases, ranging from 0.87 to 1.24. For temporal multi-frame StreamPETR models, both mAP and NDS consistently improve, with mAP gains of 0.93 and 0.94, and modest NDS increases of 0.46 and 0.58. Notably, NDS improvements in temporal methods are smaller than in single-frame methods, mainly due to performance degradation in mASE and mAOE, suggesting that our QDPE may not optimally capture scale and orientation information in temporal models. We plan to investigate this further in future work. Overall, QPETR shows significant improvements in most configuration metrics, demonstrating that our method surpasses the original PETR models in floating-point performance. \textbf{Secondly}, we analyze the quantized performance improvements. In single-frame PETR models, mAP and NDS drops are kept below 1\% using our QDPE and smoothing techniques. In temporal multi-frame StreamPETR models, mAP and NDS drops remain within 2.5\%, likely due to accumulated quantization errors during temporal fusion. Overall, quantized QPETR models maintain high performance with minimal drops in both settings, demonstrating the effectiveness of our quantization strategies in preserving accuracy while reducing computational and memory requirements. We intend to further mitigate quantization errors in temporal models through enhanced error correction or advanced quantization methods.

\subsection{Ablation Study}\label{sec:exp_ablation}

\textbf{Proof of Position Encoding Equivalence.}
We conducted experiments to verify whether the proposed QDPE enhances floating-point performance over the original camera-ray PE. As shown in Tab.~\ref{tab:floating_point_performance_comparison_of_different_3D_position_embedding}, QDPE provides performance improvements. On PETR, it slightly increases mAP by 0.07 but significantly boosts NDS and mATE by 1.09 and 1.67, respectively. For Stream-PETR, our method yields substantial and balanced enhancements, with increases of 0.94 in mAP, 0.46 in NDS, and 0.22 in mATE.


\begin{table}[htb] %{0.45\linewidth}
    \setlength{\tabcolsep}{3.5mm}
    \centering
    \footnotesize
    \begin{tabular}{lc|ccc}
    \toprule[1.5pt]
    \multicolumn{2}{c|}{Method} & mAP$\uparrow$ & NDS$\uparrow$ & mATE$\downarrow$ \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    \multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}PETR\end{tabular}}}
    & Camera-ray PE                  & 31.42 & 36.11 & 84.19  \\ 
    & QDPE          & \textbf{31.49} & \textbf{37.20} & \textbf{82.52}  \\
    \hline
    \multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}Stream\\-PETR\end{tabular}}}
    & Camera-ray PE                  & 48.19 & 57.11 & 60.99  \\ 
    & QDPE          & \textbf{49.13} & \textbf{57.57} & \textbf{60.77}  \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{FP Performance of different 3D position embedding.}
    \label{tab:floating_point_performance_comparison_of_different_3D_position_embedding}
    \vspace{-0.3cm}
\end{table}

\textbf{Quantization Performance Evaluation.} We evaluate the Camera-ray PE module on the nuScenes dataset under three configurations: FP32 Baseline (full precision as an upper bound), Standard 8-bit PTQ (per-tensor 8-bit post-training quantization), and PTQ4ViT (using the PTQ4ViT \cite{yuan2022ptq4vit} method to boost accuracy). As shown in Table~\ref{tab:quant_softmax_ptq4vit_comparison}, retaining the Softmax input in full precision (“No”) yields higher mAP and NDS than when it is quantized (“Yes”), underscoring the importance of careful Softmax treatment.

\begin{table}[htb] %{0.45\linewidth}
    \setlength{\tabcolsep}{2.0mm}
    \centering
    \footnotesize
    \vspace{0.1cm}
    \begin{tabular}{l|c|cc|cc}
    \toprule[1.5pt]
    \multirow{2}{*}{Method} & 
    \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Quant. Softmax\\ Input\end{tabular}} & 
    \multicolumn{2}{c|}{(PTQ) INT8} & 
    \multicolumn{2}{c}{(PTQ4ViT) INT8} \\
    \cline{3-6}
    & & mAP$\uparrow$ & NDS$\uparrow$ & mAP$\uparrow$ & NDS$\uparrow$ \\
    \midrule
    \multirow{3}{*}{{\begin{tabular}[c]{@{}c@{}}Camera-\\ray PE\end{tabular}}}
    & FP32 & 31.42 & 36.11 & 31.42 & 36.11 \\
    & No   & 24.90 & 32.10 & 27.10 & 33.60 \\
    & Yes  & 18.80 & 27.50 & 19.20 & 28.40 \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Quantization performance of Camera-ray PE on nuScenes. FP32, standard 8-bit PTQ, and PTQ4ViT \cite{yuan2022ptq4vit} methods are compared under different Softmax quantization settings.}
    \label{tab:quant_softmax_ptq4vit_comparison}
    \vspace{-0.1cm}
\end{table}


% \textbf{Compare with QAT.} Although QDPE requires retraining, its overall training cost is comparable to that of typical QAT approaches. To validate this, we replicate a distillation-based QAT procedure, following the idea of QD-BEV~\cite{zhang2023qd}, and apply it to the original Camera-ray PE model. As shown in Table~\ref{tab:qat_compare}, even with 24 or 36 epochs of QAT, the mAP and NDS remain lower than those of our QDPE under standard PTQ. This result indicates that QDPE not only achieves higher floating-point performance but also outperforms QAT in quantized accuracy at similar—or even greater—training cost, likely due to its amplitude-aware design that avoids the feature loss inherent in Camera-ray PE.
\textbf{Compare with QAT.} Although QDPE requires retraining, its cost is comparable to that of QAT. We implement a distillation-based QAT (inspired by QD-BEV~\cite{zhang2023qd}) on the original Camera-ray PE. As shown in Table~\ref{tab:qat_compare}, even after 24 or 36 epochs, QAT yields lower mAP and NDS than QDPE with standard PTQ. This confirms that our amplitude-aware design not only maintains high floating-point performance but also achieves superior quantized accuracy.
\begin{table}[htb] %{0.45\linewidth}
    \vspace{-2mm}
    \setlength{\tabcolsep}{0.35mm}
    \centering
    \footnotesize
    \begin{tabular}{cc|cc|cc|cc}
    \toprule[1.5pt]
    \multicolumn{2}{c|}{\textbf{Model}} & \multicolumn{2}{c|}{\textbf{12 epochs}} & \multicolumn{2}{c|}{\textbf{24 epochs}} & \multicolumn{2}{c}{\textbf{36 epochs}} \\
    \cline{3-8}
    & & mAP$\uparrow$ & NDS$\uparrow$ & mAP$\uparrow$ & NDS$\uparrow$ & mAP$\uparrow$ & NDS$\uparrow$ \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    Camera-ray PE
    & QAT (Distill) & 28.9 & 35.2 & 30.3 & 35.8 & 30.3 & 35.8 \\
    QDPE & PTQ    & \textbf{31.34} & \textbf{37.17} & \textbf{31.34} & \textbf{37.17} & \textbf{31.34} & \textbf{37.17} \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.2cm}
    \caption{Comparison of QAT with distillation vs.\ QDPE PTQ at different training epochs on the nuScenes dataset.}
    \label{tab:qat_compare}
    \vspace{-0.5cm}
\end{table}


% \begin{table}[thb]
%     \setlength{\tabcolsep}{3.8mm}
%     \footnotesize
%     \vspace{0.25cm}
%     \centering
%     \begin{tabular}{lc|p{1.1cm}p{1.1cm}p{1.1cm}}
%     \toprule[1.5pt]
%     \multicolumn{2}{c|}{\textbf{Method}} & \textbf{12 epochs} & \textbf{24 epochs} & \textbf{36 epochs} \\
%     \noalign{\smallskip}\hline
%     \noalign{\smallskip}
%     \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Camera-ray\\PE\end{tabular}}
%     & QAT (Distill) 
%       & 28.9 / 35.2 
%       & 30.3 / 35.8 
%       & 30.3 / 35.8 
%       \\
%     QDPE &  PTQ    
%       & \textbf{31.34 / 37.17} 
%       & \textbf{31.34 / 37.17} 
%       & \textbf{31.34 / 37.17} 
%       \\
%     \bottomrule[1.5pt]
%     \end{tabular}
%     \vspace{-0.3cm}
%     \caption{Comparison of QAT with distillation vs.\ QDPE PTQ at different training epochs on the nuScenes dataset. Each cell reports mAP / NDS. Even with longer QAT training, the Camera-ray PE remains inferior to QDPE, indicating that amplitude-related feature loss cannot be fully recovered by QAT.}
%     \label{tab:qat_compare}
% \end{table}


\textbf{Effect of Anchor Embedding Quantity.}
The QDPE uses three anchor embeddings per axis, obtained through linear interpolation. Experiments (Tab.~\ref{tab:sd}) demonstrate that setting the number of anchor embeddings to 3 achieves the highest NDS and mAP scores. Adjusting this number either up or down results in lower performance, confirming that 3 is the optimal choice.


\begin{table}[htb] %{0.45\linewidth}
\vspace{-2mm}
    \setlength{\tabcolsep}{4.7mm}
    \centering
    \footnotesize
    \centering
    \begin{tabular}{c|c|c|cc}
    \toprule[1.5pt]
    \multicolumn{3}{c|}{Quantity of Anchor Embedding} & \multirow{2}{*}{NDS$\uparrow$} & \multirow{2}{*}{mAP$\uparrow$}     \\ \cline{1-3}
    \multicolumn{1}{c|}{x-axis} & \multicolumn{1}{c|}{y-axis} & \multicolumn{1}{c|}{z-axis}  &  \\ 
    \midrule
    2 & 2 & 2 & 36.66 & 31.29 \\
    3 & 3 & 3 & \textbf{37.20} & \textbf{31.49} \\
    4 & 4 & 4 & 36.92 & 31.09 \\
    5 & 5 & 5 & 36.83 & 31.19 \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{
    Effect of Anchor Embedding Quantity.
    }
    \label{tab:sd}
    \vspace{-0.5cm}
\end{table}

%\vspace{-0.3cm}
\textbf{Quantization Performance of Different Position Encodings.}
To experimentally demonstrate the superior quantization performance of our proposed QDPE, we focus solely on quantizing the positional encoding, keeping all other modules in floating-point computation. Detailed results are shown in Tab.~\ref{tab:quantization_performance_comparison_of_different_3D_position_embedding}. The original camera-ray configuration loses up to 11.97\% in mAP and 5.04\% in NDS, whereas our QDPE experiences minimal losses of only \textbf{1.42\%} in mAP and \textbf{1.15\%} in NDS. Fig.~\ref{fig:cameraPE_and_lidarPE} further supports this finding; compared to the distribution in Fig.~\ref{fig:magnitude_distributions_of_image_feature_and_camera_ray_PE}, the distribution of our QDPE aligns more closely with that of image features, retaining sufficient useful information.





\begin{figure}[htb]
\centering
	\includegraphics[width=0.8\linewidth]{./figs/cameraPE_and_lidarPE.pdf}
    \vspace{-0.3cm}
	\caption{Illustration for distributions of image features and QDPE after symmetric quantization using the quantization
    parameters derived from the respectively 3D-aware K.}
	\label{fig:cameraPE_and_lidarPE}
    \vspace{-0.4cm}
\end{figure}

\begin{table}[thb]
    %\setlength{\tabcolsep}{0.0145\linewidth}
    \setlength{\tabcolsep}{3.8mm}
    \footnotesize
    \begin{tabular}{lc|p{0.6cm}p{0.6cm}p{0.8cm}}
    \toprule[1.5pt]
    \multicolumn{2}{c|}{Method} & NDS$\uparrow$ & mAP$\uparrow$ & mATE$\downarrow$ \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    \multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}PETR\end{tabular}}}
    & Camera-ray PE & 34.29 & 27.66 & 87.17  \\ 
    & QDPE          & \textbf{37.18} & \textbf{31.40} & \textbf{82.59}  \\
    \hline
    \multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}Stream\\-PETR\end{tabular}}}
    & Camera-ray PE & 53.74 & 40.23 & 69.39  \\ 
    & QDPE          & \textbf{56.81} & \textbf{47.65} & \textbf{61.53}  \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Quantization Performance Comparison of different 3D position embedding.}
    \label{tab:quantization_performance_comparison_of_different_3D_position_embedding}
    \vspace{-0.5cm}
\end{table}



%\vspace{-0.3cm}
\textbf{Impact of Different Scaled Dot Product Quantization Strategy.}
To validate our novel scaled dot-product quantization strategy—which searches for the optimal scaling factor by minimizing softmax output error—we focus solely on quantizing the softmax inputs while keeping all other modules in floating-point computation. As shown in Tab.~\ref{tab:performance_of_dfferent_scaled_dot_product_quantization_strategies}, the original quantization strategy results in significant losses of 40\% in NDS and 50\% in mAP. In contrast, our "quant after stabilization" approach greatly improves performance. An ablation study on the maximum candidate truncation range $N$ reveals that setting $N \geq 20$ yields optimal quantization performance with nearly no loss. Performance deteriorates when $N < 20$ due to increased truncation of feature information, while values of $N$ exceeding 20 offer no additional benefits. Therefore, setting $N = 20$ is sufficient to achieve the best performance. Additionally, in large language models, the attention inputs can reach extremely large values (see Fig.~\ref{fig:llm_softmax}), and we have validated the effectiveness of our method in such scenarios as well (see Tab.~\ref{tab:comparison_qwen_deepseek}).


\begin{table}[thb]
    \vspace{-3mm}
    %\setlength{\tabcolsep}{0.0145\linewidth}
    \setlength{\tabcolsep}{3.8mm}
    \footnotesize
    \begin{tabular}{lc|p{0.6cm}p{0.6cm}p{0.8cm}}
    \toprule[1.5pt]
    \multicolumn{2}{c|}{Method} & NDS$\uparrow$ & mAP$\uparrow$ & mATE$\downarrow$ \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    \multirow{1}{*}{{\begin{tabular}[c]{@{}c@{}}quant before ns\end{tabular}}}
    & -          & 25.31 & 13.79 & 107.94  \\
    \hline
    \multirow{6}{*}{{\begin{tabular}[c]{@{}c@{}}quant after ns\end{tabular}}}
    & N = 1\textcolor{white}{0}  & 3.45 & 1.23 & 150.34  \\ 
    & N = 5\textcolor{white}{0}  & 33.86 & 28.77 & 87.12  \\
    & N = 10 & 34.65 & 29.33 & 85.01  \\
    & N = 20 & 36.10 & 31.42 & 84.19  \\
    & N = 30 & 36.10 & 31.42 & 84.19  \\
    & N = 40 & 36.10 & 31.42 & 84.19  \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Performance of Different Scaled Dot Product Quantization Strategies.}
    \label{tab:performance_of_dfferent_scaled_dot_product_quantization_strategies}
    \vspace{-0.8cm}
\end{table}
%\vspace{-0.3cm}

\begin{table}[htb] %{0.45\linewidth}
    \centering
    \resizebox{0.99\linewidth}{!}{
    \footnotesize
    \begin{tabular}{l|cc|cc}
    \toprule[1.5pt]
    \multicolumn{1}{c|}{Model Name} 
    & \multicolumn{2}{c|}{qwen2.5-7b-instruct} 
    & \multicolumn{2}{c}{deepseek-r1-distill-qwen-7b} \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    & wikitext2$\downarrow$ & gsm8k$\uparrow$ & wikitext2$\downarrow$ & gsm8k$\uparrow$ \\
    \noalign{\smallskip}
    \hline
    \noalign{\smallskip}
    bfp16 & 7.46 & 80.21 & 25.04 & 85.97 \\
    quant before ns & 10000+ & 0.3 & 10000+ & 0.1 \\
    quant after ns(20) & 7.48 & 80.24 & 25.09 & 86.03 \\
    \bottomrule[1.5pt]
    \end{tabular}}
    \vspace{-2mm}
    \caption{Quant after ns in LLMs}
    \label{tab:comparison_qwen_deepseek}
    \vspace{-3mm}
\end{table}


\begin{figure}[htb]
\centering
	\includegraphics[width=1.0\linewidth]{./figs/llm_softmax.pdf}
    \vspace{-6mm}
	\caption{Softmax input distributions from two large language models (qwen2.5-7b at block0 on the left, and deepseek-r1-distill-qwen-7b at block27 on the right).}
	\label{fig:llm_softmax}
    \vspace{-0.5cm}
\end{figure}




\vspace{0.3cm}
\textbf{Superior Performance of DuLUT for Non-linear Functions.}\label{}
To validate the quantization advantages of our proposed DuLUT for nonlinear functions, 
we use "quant after stabilization (N=20)" from Tab.~\ref{tab:performance_of_dfferent_scaled_dot_product_quantization_strategies} as a baseline and evaluate the performance with different nonlinear function quantization methods applied on top of it. 
The specific results are shown in Tab.~\ref{tab:quantization_methods_for_nonlinear_functions}. 
We consider the carefully designed approximation methods I-Bert and I-Vit for different nonlinear functions. 
Due to the approximation errors introduced by these methods, 
many points are quantized away.
Additionally, we compare with the LUT-based table lookup method and find that 256 entries are required for lossless quantization, 
while 128 entries lead to severe performance losses of 0.54 NDS and 0.37 mAP. 
In contrast, our newly proposed DuLUT with 128 entries achieves lossless quantization. 
Even when the number of entries is further reduced to 64, 
the quantization only results in a negligible loss of 0.08\% NDS and 0.02\% mAP, 
which can be considered negligible. 
This further demonstrates the superior quantization performance of our proposed DuLUT.



\begin{table}[htb] %{0.45\linewidth}
    \setlength{\tabcolsep}{3mm}
    \centering
    \footnotesize
    \begin{tabular}{lc|ccc}
    \toprule[1.5pt]
    \multicolumn{2}{c|}{Method} & NDS$\uparrow$ & mAP$\uparrow$ & mATE$\downarrow$ \\
    \hline
    \multicolumn{2}{c|}{Quant after stabilization (N=20)} & 36.10  & 31.42 & 84.19 \\
    \hline
    \multicolumn{2}{c|}{I-Bert} & 34.87 & 29.34 & 88.41 \\
    \hline
    \multicolumn{2}{c|}{I-Vit} & 35.03 & 28.77 & 87.32 \\
    \hline
    \multirow{2}{*}{{\begin{tabular}[c]{@{}c@{}}LUT\end{tabular}}}
    & 256 entries & 36.10 & 31.42 & 84.19  \\ 
    & 128 entries & 35.56 & 31.05 & 85.61  \\
    \hline
    \multirow{4}{*}{{\begin{tabular}[c]{@{}c@{}}DuLUT\end{tabular}}}
    & (16,16) entries & 28.12 & 17.36 & 96.99  \\ 
    & (16,32) entries & 34.14 & 27.29 &  90.33 \\
    & (32,32) entries & 36.07 & 31.36 & 84.20  \\
    & (64,64) entries & 36.10 & 31.42 & 84.19  \\
    \bottomrule[1.5pt]
    \end{tabular}
    \vspace{-0.3cm}
    \caption{Performance comparison of different quantization methods for nonlinear functions.}
    \label{tab:quantization_methods_for_nonlinear_functions}
\vspace{-0.4cm}
\end{table}


\textbf{Practical Hardware Resource Savings.}
Tab.~\ref{tab:table} shows Q-PETR runs at 13.3~FPS (87\% faster) and 1.9\,GB memory (60\% less) vs.\ PETR’s 7.1\,FPS/4.8\,GB, demonstrating significant speedup and resource efficiency.
\begin{table}[htb]
\centering
\footnotesize
\setlength{\tabcolsep}{5mm}
\begin{tabular}{lccc}
\toprule[1.5pt]
Method & Mode & FPS & CUDA memory (G) \\
\hline
PETR & fp32 & 7.1 & 4.8 \\
Q-PETR & INT8 & 13.3 & 1.9 \\
\hline
\end{tabular}
  \vspace{-0.3cm}
\caption{\small FPS and CUDA Memory Comparison: PETR vs. Q-PETR (R50-DCN, 512×1408, RTX 4090).}
\label{tab:table}
\vspace{-0.5cm}
\end{table}




\vspace{-0.2cm}





