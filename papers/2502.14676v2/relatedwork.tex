\section{Related work}
\subsection{Trajectory Prediction}
\label{sec:future}

Deep learning models have driven the latest advancement of trajectory prediction. 
Social-LSTM \cite{Alexandre2016lstm} introduces RNN-based neural networks \cite{HochSchm1997lstm} to model the trajectories of pedestrians and a pooling window mechanism to describe the interactions among them. Social-GAN~\cite{gupta2018socialgan} incorporates the ideas of Generative Adversarial Networks \cite{goodfellow2014GAN} to predict multiple multi-modal trajectories with distance-based interaction modeling. \textcolor{black}{Diffusion models \cite{chang2023design} are adopted into trajectory prediction \cite{gu2022stochastic, mao2023leapfrog}, showing significant improvement.}

Graph representations are increasingly recognized for their prowess in modeling relational features. TrafficPredict \cite{ma2019trafficPredict} incorporates soft-attention-based interaction graphs with LSTM to represent social interactions. STGAT \cite{huang2019stgat} models the trajectories using Spatial-Temporal Graph Attention Networks based on the sequence-to-sequence architecture. Social-STGCNN \cite{Mohamed2020socialstgcnn} introduces weighted graph edges, providing an interpretable measurement of pedestrian interactions. STAR \cite{cunjun2020star} takes advantage of the Transformer \cite{vaswani2017transformer} to construct a spatial-temporal graph transformer for trajectory representation. SGCN \cite{shi2021sgcn} advances this by proposing sparse directed spatial-temporal graph representations to model spatial interactions and motion tendencies for each pedestrian. However, these methods primarily focus on modeling pedestrian interactions, overlooking the intricate interactions among heterogeneous agents.

\RCCC{Future trajectory or goal information enhances the trajectory prediction as it provides valuable insights into the long-term intentions of individual agents~\cite{mangalam2020PECNet, mangalam2021ynet, zhao2021ExpTraj, ye2021agentformer, gu2022stochastic, Xu2022GroupNetMH, sun2021PCCSNet, pei2022socialVAE, xu2022memonet, li2024GoalOriented}. %There are various strategies for integrating this type of information. For example, 
CVAE~\cite{sohn2015CVAE} based methods \cite{ye2021agentformer, pei2022socialVAE, Xu2022GroupNetMH} employ the future and past trajectory encoder during the training phase to train the latent representation for each agent.} Such latent is used to generate future trajectories during inference. Goal retrieval methods sample goal points and incorporate them as guides to model the prediction diversity~\cite{zhao2021ExpTraj, mangalam2021ynet, mangalam2020PECNet}. %While these methods are effective, the use of future trajectory or goal information is not the central focus of our work. Instead, 
We employs the goal retrieval approach proposed in~\cite{zhao2021ExpTraj}, as it does not require training a separate models as in the CVAE-based method.


\RCCC{As trajectories are influenced by their surroundings, some studies employ image contextual features as auxiliary information. Convolutional Neural Networks (CNN) are applied to extract such features to improve prediction accuracy \cite{lee2017desire, wong2022V2net}. Semantic segmentation is adapted on scene images to extract annotated image features \cite{mangalam2021ynet}. While acknowledging the potential benefits of these techniques, we do not utilize scene-based features in this research. The integration of such features typically requires an auxiliary image processing network \cite{fang2023HSG, wong2022V2net, guo2022end2end-grid}, which complicates the model architecture and detracts from our primary focus on exploring the impact of behavioral pseudo-labels. Our approach, although not incorporating scene-based data, is conceptually aligned with these methods in its attempt to capture the nuanced behaviors and interactions of traffic agents purely from trajectory data.
The proposed method is orthogonal and complementary to the use of scene-based features. The two methods can be combined in future work.}




\begin{figure}[H]
  \centering
  \includegraphics[width=0.48\textwidth]{figures/pedestrian_fig.png}
  %\vspace{-0.2cm}
  \caption{\RCC{Trajectory visualization on heterogeneous SSD dataset, where red, green and blue dots represent pedestrians, bikers and cars, respectively. (a) and (c) represent heterogeneous scenarios with all agent types, (b) and (d) represent the pedestrian-only scenarios commonly used by pedestrian trajectory predictions \cite{mangalam2020PECNet, mangalam2021ynet} by simply removing all non-pedestrian agents.}}
  \label{fig:pedestrian_traj}
  %%\vspace{-0.6cm}
\end{figure}
%\vspace{-0.3cm}
\subsection{Heterogeneous Trajectory Prediction}
Heterogeneous trajectory prediction considers traffic agents of all types. Adopting prediction approaches \cite{mangalam2021ynet, mohamed2022socialimplicit, Xu2022GroupNetMH} by simply ignoring non-pedestrian agents, or considering all agents to be of the same class, results in sub-optimal performance. Heterogeneous methods focus on modeling different agent behaviors. VP-LSTM~\cite{huikun2019JPKT} separately treats vehicles and pedestrians with LSTMs. Proposal-based approaches such as CoverNet \cite{Tung2020covernet} generate predefined multimodal trajectory anchors from observations of both vehicles and pedestrians. For better interpretability and representation of heterogeneous agent interactions, graph-based attention mechanisms \cite{vaswani2017transformer, huang2019stgat} are proposed. NLNI \cite{fang2021UNIN} presents a novel spatial-temporal category graph and proposed graph attention to capture the category-wise and agent-wise interactions. Multiclass-SGCN \cite{ruochen2022multiclassSGCN} and Semantic-STGCNN \cite{rainbow2021semanticStgcnn} introduce one-hot encoding to encode annotated class labels as part of node features. \RCCC{HIMRAE \cite{chen2024AEMTP} proposes dynamic interaction graphs among agents to reduce accumulated error for heterogeneous trajectory prediction. SMGCN \cite{zhang2024SMGCN} intorduces a sparse multi-relational GCN to learn heterogeneous interactions among agents.}

\RCCC{However, while these approaches achieve superior performance, most methods rely heavily on ground-truth labels to distinguish agent types. On the one hand, manual labeling is costly and error-prone, making the modelâ€™s performance overly dependent on label quality. On the other hand, focusing on semantic labels can overlook subtle behavioral differences among agents with the same semantic label. In this work, we propose learning behavioral pseudo-labels from agent motion dynamics, thereby reducing reliance on manual labels and capturing a broader spectrum of behaviors.}

\begin{figure*}[t]
  \includegraphics[width=\textwidth]{images/overview_structure_new.PNG}
  %\vspace{-0.4cm}
  \caption{\RCCC{The overview of BP-SGCN to learn the pseudo-labels for trajectory prediction, consisting of  the deep unsupervised clustering module and the pseudo-label informed trajectory prediction module. We propose a cascaded optimization scheme to first learn pseudo-labels in an unsupervised manner, and then fine-tune them in an end-to-end manner with trajectory prediction supervision.}}
  \label{fig:overview}
  %\vspace{-0.4cm}
\end{figure*}

\subsection{Motion Behavior Clustering}
\RCCC{The clustering of temporal trajectory patterns allows modeling the behavioral groups for better trajectory prediction \cite{fernando2018soft+, xue2020poppl}. Early works focus on the raw trajectory represented as 2D coordinates. 
Support vector clustering is introduced as a closed-loop method on motion vectors for motion behavior representations \cite{lawal2016support}. K-means on trajectory vectors or sequence key points obtain cluster centers to enhance trajectory prediction \cite{xue2020poppl, lui2021DDPTP}.}
% replace K-means with 
DBSCAN is proposed to avoid manually specifying cluster numbers, adding more flexibility and interpretability to behavior patterns \cite{fernando2018soft+}. GP-Graph directly uses the absolute distance among pedestrians to determine the division of group \cite{bae2022gpgraph}. The recent PCCSNet leverages BiLSTM network to encode coordinates prior to K-means clustering, identifying behavioral modalities \cite{sun2021PCCSNet}. In addition to modalities, FEND further applies 1D CNN and LSTM for trajectory encoding and employs the K-means for long-tail trajectory clustering to distinguish trajectory patterns \cite{wang2023fend}.

\RCCC{However, most existing methods rely on shallow trajectory representations, limiting their ability to capture nuanced, evolving behaviors. Additionally, distance-based clustering approaches often struggle with complex motion patterns. To address these issues, we propose a cascaded optimization scheme featuring an end-to-end Deep Embedded Clustering (DEC) \cite{junyuan2015DEC} module, which iteratively refines cluster assignments using a KL-divergence objective. This dynamic adaptation yields richer latent representations, enabling a more data-driven and expressive approach to modeling agent behaviors.}