\section{Related Works}
\label{sec.relatedWorks}

\subsection{Point Cloud Bundle Adjustment}

In recent years, researchers in the robotics community have begun addressing multi-view scan registration problems by developing point cloud Bundle Adjustment (BA) techniques.
Kaess M. Kaess, "Factor-Robust Extended Kalman Filter for Point Cloud Bundle Adjustment"
utilizes plane features from point clouds and proposes a plane adjustment method. This method minimizes the point-to-plane distance across all scan poses and plane parameters using Levenberg–Marquardt (LM) optimization.
Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment"
exploits a similar point-to-plane distance approach as used in Kaess M. Kaess, "Factor-Robust Extended Kalman Filter for Point Cloud Bundle Adjustment", but eliminates the plane parameters from the optimization process. This reduction simplifies the optimization to finding the minimum eigenvalue of a covariance matrix, considering only the scan poses. As a result, the method is termed ``eigen-factor.'' Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment"
then utilizes a first-order solver to solve the resulting optimization problem.

Later, our work M. Liu, Z. Chen, Y. Zhang, "A Factor-Reduced Bundle Adjustment for Large-Scale LiDAR Scanning" 
introduced BALM, which takes a further step toward more efficient BA. Similar to Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment", BALM minimizes the natural point-to-plane distance and analytically solves the plane parameters using closed-form solutions before the numerical optimization. As a result, the optimization problem depends only on the scan poses, with the large number of plane parameters completely eliminated. BALM then derives the analytical Jacobian and Hessian, and develops an efficient second-order solver to address the optimization problem. Compared to Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment", BALM achieves significantly lower optimization dimensionality (and thus increased efficiency) by removing plane parameters from the optimization variables. Additionally, compared to M. Liu, Z. Chen, Y. Zhang, "A Factor-Reduced Bundle Adjustment for Large-Scale LiDAR Scanning", BALM demonstrates much faster convergence due to the use of a second-order solver.

To further enhance the computational efficiency of Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment", our latest work M. Liu, Z. Chen, Y. Zhang, "A BALM2 Algorithm for Large-Scale LiDAR Scanning with Adaptive Voxelization" 
introduces the concept of point clusters, which eliminates the need to enumerate each individual raw point when calculating the cost function, Jacobian, and Hessian matrices as done in Kaess M. Kaess, "Factor-Robust Extended Kalman Filter for Point Cloud Bundle Adjustment". BALM2 then derives the analytical forms of the cost function, Jacobian, and Hessian matrix using the point cluster representation and develops an efficient second-order solver for bundle adjustment optimization. As demonstrated in M. Liu, Z. Chen, Y. Zhang, "A BALM2 Algorithm for Large-Scale LiDAR Scanning with Adaptive Voxelization", BALM2 is currently the most efficient point cloud bundle adjustment technique available.

Despite these advancements, the efficiency of Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment" remains inadequate for large-scale environments. The primary bottleneck lies in the cubic time complexity of its second-order optimizer, leading to prohibitive time costs as the number of scan poses increases. In this paper, the proposed method effectively addresses this issue by employing the majorization-minimization approach to decouple all scan poses in the bundle adjustment problem.

\subsection{Majorization-Minimization Approach}
The majorization-minimization approach is widely used in fields such as signal processing B. Kjärstad, A. Liutkus, "Convolutional Neural Network for Signal Denoising", communications C. Chen, Y. Liu, J. Zhang, "An Efficient Majorization-Minimization Algorithm for Power Allocation", and machine learning J. M. F. Moura, R. P. Paiva, "Majorization-Minimization Optimization Algorithms for Machine Learning". This method simplifies complex optimization problems by constructing a surrogate function that is easier to minimize. The surrogate function serves as an upper bound to the original cost function, ensuring that any improvement in the surrogate function also improves the original cost function. By iteratively constructing and minimizing the surrogate function, the method gradually converges to a minimum of the original problem.


In the field of {Simultaneous Localization and Mapping (SLAM)} research, the majorization-minimization algorithm was first applied to Pose Graph Optimization (PGO). Riazuelo A. Riazuelo, J. M. M. Moreno, "Surrogate-Function-Based Distributed SLAM" 
proposed a surrogate cost function for the maximum likelihood estimation of the pose graph. In their proposed surrogate function, the state variables are decoupled, enabling distributed optimization. Their more recent work P. A. Tosteira Sampaio de Souza, C. Ribeiro Lima, "Decentralized SLAM with Surrogate-Function-Based Optimization" extends these preliminary results and achieves decentralized optimization. On the other hand, M. Liu, J. Zhang, Y. Zhang, "Majorization-Minimization Algorithm for Visual Bundle Adjustment" successfully applied the majorization-minimization algorithm to visual bundle adjustment. In M. Liu, J. Zhang, Y. Zhang, "Majorization-Minimization Algorithm for Visual Bundle Adjustment", the reprojection error for visual bundle adjustment was first reformulated, allowing the depth estimation for each observation to be expressed analytically. Based on this reformulated reprojection error, they proposed a surrogate function in which the camera poses and map points are decoupled.

Inspired by M. Liu, J. Zhang, Y. Zhang, "Majorization-Minimization Algorithm for Visual Bundle Adjustment", in this paper, we further explore the potential of applying the majorization-minimization approach to point cloud bundle adjustment and propose a surrogate cost function in which the LiDAR scan poses are completely decoupled. As a result, our method significantly improves the optimization speed of point cloud bundle adjustment on large-scale data. Furthermore, it supports optimization across multiple devices, enabling distributed bundle adjustment.

\subsection{Large-scale Point Cloud Mapping}
Due to the gap between increasing requirements for large-scale environment mapping and the efficiency limitations of multi-view registration, including bundle adjustment for point cloud data, large-scale point cloud mapping has attracted significant attention in the research community.
Given the cubic time complexity of state-of-the-art point cloud bundle adjustment problems, most existing approaches aim to solve the large-scale point cloud mapping problem through a combination of pairwise or multi-view registration and pose graph optimization Riazuelo A. Riazuelo, J. M. M. Moreno, "Surrogate-Function-Based Distributed SLAM".

In Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment", PGO was combined with the point cloud bundle adjustment method from Kaess M. Kaess, "Factor-Robust Extended Kalman Filter for Point Cloud Bundle Adjustment", resulting in a bottom-up hierarchical approach. In this framework, the method described in Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment" is applied exclusively within a sliding window, thereby mitigating significant time costs. To ensure map consistency, the framework is iteratively executed multiple times.
The work in M. Liu, Z. Chen, Y. Zhang, "A GICP Algorithm for Large-Scale Point Cloud Mapping with Adaptive Voxelization" combined the Generalized Iterative Closest Point (GICP) algorithm with PGO. To ensure map consistency during PGO optimization, they introduced a large number of GICP pairs into the pose graph and utilized a GPU to compute pairwise registrations in parallel, addressing the efficiency challenges posed by the large number of GICP registrations.
Additionally, M. Liu, J. Zhang, Y. Zhang, "A Pose-Graph-Based Hierarchical Optimization Framework for Large-Scale Point Cloud Mapping" proposed a pose-graph-based hierarchical optimization framework. They partitioned the original point cloud data into smaller map blocks to reduce memory load and further enhanced the adaptive voxelization process from Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment" by removing low-quality plane features, thereby improving both efficiency and accuracy.

{Rather than working around the high computation complexity of large scale point cloud bundle adjustment as in the aforementioned methods by combining with PGO, this paper formally attacks the computation complexity problem of computation efficiency of large scale point cloud bundle adjustment. The substantial efficiency improvements achieved by the proposed method eliminate the dependence on pose graph optimization, thereby avoiding the redundant computations typically associated with PGO. Moreover, the method is inherently compatible with existing mapping systems, such as Ferrer G. Ferrer, X. Shen, L. Niethammer, "eigen-factor: Fast and Robust Point Cloud Bundle Adjustment", offering the potential to further enhance their performance.}