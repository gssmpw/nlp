\section{Related Works}
\label{sec.relatedWorks}

\subsection{Point Cloud Bundle Adjustment}

In recent years, researchers in the robotics community have begun addressing multi-view scan registration problems by developing point cloud Bundle Adjustment (BA) techniques.
Kaess \cite{pa, slamip, kfpslam} utilizes plane features from point clouds and proposes a plane adjustment method. This method minimizes the point-to-plane distance across all scan poses and plane parameters using Levenbergâ€“Marquardt (LM) optimization.
Ferrer \cite{ferrer2019eigen} exploits a similar point-to-plane distance approach as used in \cite{pa}, but eliminates the plane parameters from the optimization process. This reduction simplifies the optimization to finding the minimum eigenvalue of a covariance matrix, considering only the scan poses. As a result, the method is termed ``eigen-factor.'' Ferrer \cite{ferrer2019eigen} then utilizes a first-order solver to solve the resulting optimization problem.

Later, our work \cite{liu2021balm} introduced BALM, which takes a further step toward more efficient BA. Similar to \cite{pa, ferrer2019eigen}, BALM minimizes the natural point-to-plane distance and analytically solves the plane parameters using closed-form solutions before the numerical optimization. As a result, the optimization problem depends only on the scan poses, with the large number of plane parameters completely eliminated. BALM then derives the analytical Jacobian and Hessian, and develops an efficient second-order solver to address the optimization problem. Compared to \cite{pa, slamip, kfpslam}, BALM achieves significantly lower optimization dimensionality (and thus increased efficiency) by removing plane parameters from the optimization variables. Additionally, compared to Ferrer \cite{ferrer2019eigen}, BALM demonstrates much faster convergence due to the use of a second-order solver.

To further enhance the computational efficiency of \cite{liu2021balm}, our latest work, BALM2 \cite{liu2023efficient}, introduces the concept of point clusters, which eliminates the need to enumerate each individual raw point when calculating the cost function, Jacobian, and Hessian matrices as done in \cite{liu2021balm}. BALM2 then derives the analytical forms of the cost function, Jacobian, and Hessian matrix using the point cluster representation and develops an efficient second-order solver for bundle adjustment optimization. As demonstrated in \cite{liu2023efficient}, BALM2 is currently the most efficient point cloud bundle adjustment technique available.

Despite these advancements, the efficiency of \cite{liu2023efficient} remains inadequate for large-scale environments. The primary bottleneck lies in the cubic time complexity of its second-order optimizer, leading to prohibitive time costs as the number of scan poses increases. In this paper, the proposed method effectively addresses this issue by employing the majorization-minimization approach to decouple all scan poses in the bundle adjustment problem.

\subsection{Majorization-Minimization Approach}
The majorization-minimization approach is widely used in fields such as signal processing \cite{figueiredo2007majorization, bioucas2006total}, communications \cite{sun2016majorization, gong2020majorization}, and machine learning \cite{mairal2015incremental}. This method simplifies complex optimization problems by constructing a surrogate function that is easier to minimize. The surrogate function serves as an upper bound to the original cost function, ensuring that any improvement in the surrogate function also improves the original cost function. By iteratively constructing and minimizing the surrogate function, the method gradually converges to a minimum of the original problem.


In the field of {Simultaneous Localization and Mapping (SLAM)} research, the majorization-minimization algorithm was first applied to Pose Graph Optimization (PGO). \cite{fan2020majorization} proposed a surrogate cost function for the maximum likelihood estimation of the pose graph. In their proposed surrogate function, the state variables are decoupled, enabling distributed optimization. Their more recent work \cite{fan2023majorization} extends these preliminary results and achieves decentralized optimization. On the other hand, \cite{mmvba} successfully applied the majorization-minimization algorithm to visual bundle adjustment. In \cite{mmvba}, the reprojection error for visual bundle adjustment was first reformulated, allowing the depth estimation for each observation to be expressed analytically. Based on this reformulated reprojection error, they proposed a surrogate function in which the camera poses and map points are decoupled.

Inspired by \cite{mmvba}, in this paper, we further explore the potential of applying the majorization-minimization approach to point cloud bundle adjustment and propose a surrogate cost function in which the LiDAR scan poses are completely decoupled. As a result, our method significantly improves the optimization speed of point cloud bundle adjustment on large-scale data. Furthermore, it supports optimization across multiple devices, enabling distributed bundle adjustment.

\subsection{Large-scale Point Cloud Mapping}
Due to the gap between increasing requirements for large-scale environment mapping and the efficiency limitations of multi-view registration, including bundle adjustment for point cloud data, large-scale point cloud mapping has attracted significant attention in the research community.
Given the cubic time complexity of state-of-the-art point cloud bundle adjustment problems, most existing approaches aim to solve the large-scale point cloud mapping problem through a combination of pairwise or multi-view registration and pose graph optimization \cite{gpugicp, hba, pang2024lm}.

In \cite{hba}, PGO was combined with the point cloud bundle adjustment method from \cite{liu2023efficient}, resulting in a bottom-up hierarchical approach. In this framework, the method described in \cite{liu2023efficient} is applied exclusively within a sliding window, thereby mitigating significant time costs. To ensure map consistency, the framework is iteratively executed multiple times.
The work in \cite{gpugicp} combined the Generalized Iterative Closest Point (GICP) algorithm with PGO. To ensure map consistency during PGO optimization, they introduced a large number of GICP pairs into the pose graph and utilized a GPU to compute pairwise registrations in parallel, addressing the efficiency challenges posed by the large number of GICP registrations.
Additionally, \cite{pang2024lm} proposed a pose-graph-based hierarchical optimization framework. They partitioned the original point cloud data into smaller map blocks to reduce memory load and further enhanced the adaptive voxelization process from \cite{liu2021balm} by removing low-quality plane features, thereby improving both efficiency and accuracy.

{Rather than working around the high computation complexity of large scale point cloud bundle adjustment as in the aforementioned methods by combining with PGO, this paper formally attacks the computation complexity problem of computation efficiency of large scale point cloud bundle adjustment. The substantial efficiency improvements achieved by the proposed method eliminate the dependence on pose graph optimization, thereby avoiding the redundant computations typically associated with PGO. Moreover, the method is inherently compatible with existing mapping systems, such as \cite{hba, pang2024lm}, offering the potential to further enhance their performance.}