[
  {
    "index": 0,
    "papers": [
      {
        "key": "glass-etal-2022-re2g",
        "author": "Glass, Michael  and\nRossiello, Gaetano  and\nChowdhury, Md Faisal Mahbub  and\nNaik, Ankita  and\nCai, Pengshan  and\nGliozzo, Alfio",
        "title": "{R}e2{G}: Retrieve, Rerank, Generate"
      },
      {
        "key": "hofstatter2023fid",
        "author": "Hofst{\\\"a}tter, Sebastian and Chen, Jiecao and Raman, Karthik and Zamani, Hamed",
        "title": "Fid-light: Efficient and effective retrieval-augmented text generation"
      }
    ]
  },
  {
    "index": 1,
    "papers": [
      {
        "key": "dong2024don",
        "author": "Dong, Jialin and Fatemi, Bahare and Perozzi, Bryan and Yang, Lin F and Tsitsulin, Anton",
        "title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking"
      }
    ]
  },
  {
    "index": 2,
    "papers": [
      {
        "key": "mao-etal-2021-reader",
        "author": "Mao, Yuning  and\nHe, Pengcheng  and\nLiu, Xiaodong  and\nShen, Yelong  and\nGao, Jianfeng  and\nHan, Jiawei  and\nChen, Weizhu",
        "title": "Reader-Guided Passage Reranking for Open-Domain Question Answering"
      }
    ]
  },
  {
    "index": 3,
    "papers": [
      {
        "key": "ma-etal-2023-large",
        "author": "Ma, Yubo  and\nCao, Yixin  and\nHong, Yong  and\nSun, Aixin",
        "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!"
      }
    ]
  },
  {
    "index": 4,
    "papers": [
      {
        "key": "bgeembedding",
        "author": "Shitao Xiao and Zheng Liu and Peitian Zhang and Niklas Muennighoff",
        "title": "C-Pack: Packaged Resources To Advance General Chinese Embedding"
      }
    ]
  },
  {
    "index": 5,
    "papers": [
      {
        "key": "li2023angle",
        "author": "Li, Xianming and Li, Jing",
        "title": "AnglE-optimized Text Embeddings"
      }
    ]
  },
  {
    "index": 6,
    "papers": [
      {
        "key": "khattab2020colbert",
        "author": "Khattab, Omar and Zaharia, Matei",
        "title": "Colbert: Efficient and effective passage search via contextualized late interaction over bert"
      },
      {
        "key": "santhanam-etal-2022-colbertv2",
        "author": "Santhanam, Keshav  and\nKhattab, Omar  and\nSaad-Falcon, Jon  and\nPotts, Christopher  and\nZaharia, Matei",
        "title": "{C}ol{BERT}v2: Effective and Efficient Retrieval via Lightweight Late Interaction"
      }
    ]
  },
  {
    "index": 7,
    "papers": [
      {
        "key": "zhuang2023rankt5",
        "author": "Zhuang, Honglei and Qin, Zhen and Jagerman, Rolf and Hui, Kai and Ma, Ji and Lu, Jing and Ni, Jianmo and Wang, Xuanhui and Bendersky, Michael",
        "title": "Rankt5: Fine-tuning t5 for text ranking with ranking losses"
      }
    ]
  },
  {
    "index": 8,
    "papers": [
      {
        "key": "pradeep2023rankzephyr",
        "author": "Pradeep, Ronak and Sharifymoghaddam, Sahel and Lin, Jimmy",
        "title": "RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!"
      }
    ]
  },
  {
    "index": 9,
    "papers": [
      {
        "key": "sun-etal-2023-chatgpt",
        "author": "Sun, Weiwei  and\nYan, Lingyong  and\nMa, Xinyu  and\nWang, Shuaiqiang  and\nRen, Pengjie  and\nChen, Zhumin  and\nYin, Dawei  and\nRen, Zhaochun",
        "title": "Is {C}hat{GPT} Good at Search? Investigating Large Language Models as Re-Ranking Agents"
      }
    ]
  },
  {
    "index": 10,
    "papers": [
      {
        "key": "asai-etal-2022-evidentiality",
        "author": "Asai, Akari  and\nGardner, Matt  and\nHajishirzi, Hannaneh",
        "title": "Evidentiality-guided Generation for Knowledge-Intensive {NLP} Tasks"
      },
      {
        "key": "yoran2023making",
        "author": "Yoran, Ori and Wolfson, Tomer and Ram, Ori and Berant, Jonathan",
        "title": "Making retrieval-augmented language models robust to irrelevant context"
      },
      {
        "key": "asai2023self",
        "author": "Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh",
        "title": "Self-rag: Learning to retrieve, generate, and critique through self-reflection"
      }
    ]
  },
  {
    "index": 11,
    "papers": [
      {
        "key": "wang2023learning",
        "author": "Wang, Zhiruo and Araki, Jun and Jiang, Zhengbao and Parvez, Md Rizwan and Neubig, Graham",
        "title": "Learning to filter context for retrieval-augmented generation"
      },
      {
        "key": "hwang-etal-2024-dslr",
        "author": "Hwang, Taeho  and\nJeong, Soyeong  and\nCho, Sukmin  and\nHan, SeungYoon  and\nPark, Jong",
        "title": "{DSLR}: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation"
      }
    ]
  },
  {
    "index": 12,
    "papers": [
      {
        "key": "jin-etal-2024-bider",
        "author": "Jin, Jiajie  and\nZhu, Yutao  and\nZhou, Yujia  and\nDou, Zhicheng",
        "title": "{BIDER}: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented {LLM}s via Key Supporting Evidence"
      },
      {
        "key": "anderson-etal-2022-lingua",
        "author": "Anderson, Nathan  and\nWilson, Caleb  and\nRichardson, Stephen D.",
        "title": "Lingua: Addressing Scenarios for Live Interpretation and Automatic Dubbing"
      },
      {
        "key": "jiang-etal-2024-longllmlingua",
        "author": "Jiang, Huiqiang  and\nWu, Qianhui  and\nLuo, Xufang  and\nLi, Dongsheng  and\nLin, Chin-Yew  and\nYang, Yuqing  and\nQiu, Lili",
        "title": "{L}ong{LLML}ingua: Accelerating and Enhancing {LLM}s in Long Context Scenarios via Prompt Compression"
      }
    ]
  },
  {
    "index": 13,
    "papers": [
      {
        "key": "yan2024corrective",
        "author": "Yan, Shi-Qi and Gu, Jia-Chen and Zhu, Yun and Ling, Zhen-Hua",
        "title": "Corrective retrieval augmented generation"
      }
    ]
  },
  {
    "index": 14,
    "papers": [
      {
        "key": "liu2306reta",
        "author": "Liu, Jiongnan and Jin, Jiajie and Wang, Zihan and Cheng, Jiehan and Dou, Zhicheng and Wen, J",
        "title": "RETA-LLM: a retrieval-augmented large language model toolkit (2023)"
      }
    ]
  },
  {
    "index": 15,
    "papers": [
      {
        "key": "gao-etal-2023-rarr",
        "author": "Gao, Luyu  and\nDai, Zhuyun  and\nPasupat, Panupong  and\nChen, Anthony  and\nChaganty, Arun Tejasvi  and\nFan, Yicheng  and\nZhao, Vincent  and\nLao, Ni  and\nLee, Hongrae  and\nJuan, Da-Cheng  and\nGuu, Kelvin",
        "title": "{RARR}: Researching and Revising What Language Models Say, Using Language Models"
      }
    ]
  },
  {
    "index": 16,
    "papers": [
      {
        "key": "yan2024corrective",
        "author": "Yan, Shi-Qi and Gu, Jia-Chen and Zhu, Yun and Ling, Zhen-Hua",
        "title": "Corrective retrieval augmented generation"
      }
    ]
  },
  {
    "index": 17,
    "papers": [
      {
        "key": "liu2306reta",
        "author": "Liu, Jiongnan and Jin, Jiajie and Wang, Zihan and Cheng, Jiehan and Dou, Zhicheng and Wen, J",
        "title": "RETA-LLM: a retrieval-augmented large language model toolkit (2023)"
      }
    ]
  },
  {
    "index": 18,
    "papers": [
      {
        "key": "yu-etal-2024-chain",
        "author": "Yu, Wenhao  and\nZhang, Hongming  and\nPan, Xiaoman  and\nCao, Peixin  and\nMa, Kaixin  and\nLi, Jian  and\nWang, Hongwei  and\nYu, Dong",
        "title": "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models"
      }
    ]
  },
  {
    "index": 19,
    "papers": [
      {
        "key": "xu2024recomp",
        "author": "Fangyuan Xu and Weijia Shi and Eunsol Choi",
        "title": "{RECOMP}: Improving Retrieval-Augmented {LM}s with Context Compression and Selective Augmentation"
      }
    ]
  },
  {
    "index": 20,
    "papers": [
      {
        "key": "xu2024recomp",
        "author": "Fangyuan Xu and Weijia Shi and Eunsol Choi",
        "title": "{RECOMP}: Improving Retrieval-Augmented {LM}s with Context Compression and Selective Augmentation"
      }
    ]
  },
  {
    "index": 21,
    "papers": [
      {
        "key": "li-etal-2023-compressing",
        "author": "Li, Yucheng  and\nDong, Bo  and\nGuerin, Frank  and\nLin, Chenghua",
        "title": "Compressing Context to Enhance Inference Efficiency of Large Language Models"
      }
    ]
  },
  {
    "index": 22,
    "papers": [
      {
        "key": "jiang-etal-2024-longllmlingua",
        "author": "Jiang, Huiqiang  and\nWu, Qianhui  and\nLuo, Xufang  and\nLi, Dongsheng  and\nLin, Chin-Yew  and\nYang, Yuqing  and\nQiu, Lili",
        "title": "{L}ong{LLML}ingua: Accelerating and Enhancing {LLM}s in Long Context Scenarios via Prompt Compression"
      }
    ]
  },
  {
    "index": 23,
    "papers": [
      {
        "key": "cao2024survey",
        "author": "Cao, Yuji and Zhao, Huan and Cheng, Yuheng and Shu, Ting and Chen, Yue and Liu, Guolong and Liang, Gaoqi and Zhao, Junhua and Yan, Jinyue and Li, Yun",
        "title": "Survey on large language model-enhanced reinforcement learning: Concept, taxonomy, and methods"
      },
      {
        "key": "pternea2024rl",
        "author": "Pternea, Moschoula and Singh, Prerna and Chakraborty, Abir and Oruganti, Yagna and Milletari, Mirco and Bapat, Sayli and Jiang, Kebei",
        "title": "The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models"
      }
    ]
  },
  {
    "index": 24,
    "papers": [
      {
        "key": "schulman2015high",
        "author": "Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter",
        "title": "High-dimensional continuous control using generalized advantage estimation"
      }
    ]
  },
  {
    "index": 25,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 26,
    "papers": [
      {
        "key": "achiam2023gpt",
        "author": "Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others",
        "title": "Gpt-4 technical report"
      }
    ]
  },
  {
    "index": 27,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 28,
    "papers": [
      {
        "key": "adler2024nemotron",
        "author": "Adler, Bo and Agarwal, Niket and Aithal, Ashwath and Anh, Dong H and Bhattacharya, Pallab and Brundyn, Annika and Casper, Jared and Catanzaro, Bryan and Clay, Sharon and Cohen, Jonathan and others",
        "title": "Nemotron-4 340B Technical Report"
      }
    ]
  },
  {
    "index": 29,
    "papers": [
      {
        "key": "chu2024qwen2",
        "author": "Chu, Yunfei and Xu, Jin and Yang, Qian and Wei, Haojie and Wei, Xipin and Guo, Zhifang and Leng, Yichong and Lv, Yuanjun and He, Jinzheng and Lin, Junyang and others",
        "title": "Qwen2-audio technical report"
      }
    ]
  },
  {
    "index": 30,
    "papers": [
      {
        "key": "adler2024nemotron",
        "author": "Adler, Bo and Agarwal, Niket and Aithal, Ashwath and Anh, Dong H and Bhattacharya, Pallab and Brundyn, Annika and Casper, Jared and Catanzaro, Bryan and Clay, Sharon and Cohen, Jonathan and others",
        "title": "Nemotron-4 340B Technical Report"
      }
    ]
  },
  {
    "index": 31,
    "papers": [
      {
        "key": "deng-etal-2022-rlprompt",
        "author": "Deng, Mingkai  and\nWang, Jianyu  and\nHsieh, Cheng-Ping  and\nWang, Yihan  and\nGuo, Han  and\nShu, Tianmin  and\nSong, Meng  and\nXing, Eric  and\nHu, Zhiting",
        "title": "{RLP}rompt: Optimizing Discrete Text Prompts with Reinforcement Learning"
      },
      {
        "key": "ghalandari-etal-2022-efficient",
        "author": "Ghalandari, Demian  and\nHokamp, Chris  and\nIfrim, Georgiana",
        "title": "Efficient Unsupervised Sentence Compression by Fine-tuning Transformers with Reinforcement Learning"
      },
      {
        "key": "ramamurthy2022reinforcement",
        "author": "Ramamurthy, Rajkumar and Ammanabrolu, Prithviraj and Brantley, Kiant{\\'e} and Hessel, Jack and Sifa, Rafet and Bauckhage, Christian and Hajishirzi, Hannaneh and Choi, Yejin",
        "title": "Is reinforcement learning (not) for natural language processing: Benchmarks, baselines, and building blocks for natural language policy optimization"
      }
    ]
  },
  {
    "index": 32,
    "papers": [
      {
        "key": "zhang2022tempera",
        "author": "Zhang, Tianjun and Wang, Xuezhi and Zhou, Denny and Schuurmans, Dale and Gonzalez, Joseph E",
        "title": "Tempera: Test-time prompting via reinforcement learning"
      }
    ]
  },
  {
    "index": 33,
    "papers": [
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      }
    ]
  },
  {
    "index": 34,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      },
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      }
    ]
  },
  {
    "index": 35,
    "papers": [
      {
        "key": "bai2022training",
        "author": "Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others",
        "title": "Training a helpful and harmless assistant with reinforcement learning from human feedback"
      },
      {
        "key": "ouyang2022training",
        "author": "Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others",
        "title": "Training language models to follow instructions with human feedback"
      },
      {
        "key": "hu2023aligning",
        "author": "Hu, Jian and Tao, Li and Yang, June and Zhou, Chandler",
        "title": "Aligning language models with offline reinforcement learning from human feedback"
      }
    ]
  },
  {
    "index": 36,
    "papers": [
      {
        "key": "rafailov2024direct",
        "author": "Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea",
        "title": "Direct preference optimization: Your language model is secretly a reward model"
      }
    ]
  },
  {
    "index": 37,
    "papers": [
      {
        "key": "bai2022constitutional",
        "author": "Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others",
        "title": "Constitutional ai: Harmlessness from ai feedback"
      },
      {
        "key": "yuan2024self",
        "author": "Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason",
        "title": "Self-rewarding language models"
      }
    ]
  },
  {
    "index": 38,
    "papers": [
      {
        "key": "cui2023ultrafeedback",
        "author": "Cui, Ganqu and Yuan, Lifan and Ding, Ning and Yao, Guanming and Zhu, Wei and Ni, Yuan and Xie, Guotong and Liu, Zhiyuan and Sun, Maosong",
        "title": "Ultrafeedback: Boosting language models with high-quality feedback"
      },
      {
        "key": "park-etal-2024-offsetbias",
        "author": "Park, Junsoo  and\nJwa, Seungyeon  and\nMeiying, Ren  and\nKim, Daeyoung  and\nChoi, Sanghyuk",
        "title": "{O}ffset{B}ias: Leveraging Debiased Data for Tuning Evaluators"
      }
    ]
  },
  {
    "index": 39,
    "papers": [
      {
        "key": "kwon2023reward",
        "author": "Kwon, Minae and Xie, Sang Michael and Bullard, Kalesha and Sadigh, Dorsa",
        "title": "Reward design with language models"
      },
      {
        "key": "lee2023rlaif",
        "author": "Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie Ren and Mesnard, Thomas and Ferret, Johan and Bishop, Colton and Hall, Ethan and Carbune, Victor and Rastogi, Abhinav",
        "title": "Rlaif: Scaling reinforcement learning from human feedback with ai feedback"
      },
      {
        "key": "zhang2024generative",
        "author": "Zhang, Lunjun and Hosseini, Arian and Bansal, Hritik and Kazemi, Mehran and Kumar, Aviral and Agarwal, Rishabh",
        "title": "Generative verifiers: Reward modeling as next-token prediction"
      }
    ]
  },
  {
    "index": 40,
    "papers": [
      {
        "key": "yuan2024self",
        "author": "Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason",
        "title": "Self-rewarding language models"
      }
    ]
  },
  {
    "index": 41,
    "papers": [
      {
        "key": "ghalandari-etal-2022-efficient",
        "author": "Ghalandari, Demian  and\nHokamp, Chris  and\nIfrim, Georgiana",
        "title": "Efficient Unsupervised Sentence Compression by Fine-tuning Transformers with Reinforcement Learning"
      }
    ]
  },
  {
    "index": 42,
    "papers": [
      {
        "key": "ramamurthy2022reinforcement",
        "author": "Ramamurthy, Rajkumar and Ammanabrolu, Prithviraj and Brantley, Kiant{\\'e} and Hessel, Jack and Sifa, Rafet and Bauckhage, Christian and Hajishirzi, Hannaneh and Choi, Yejin",
        "title": "Is reinforcement learning (not) for natural language processing: Benchmarks, baselines, and building blocks for natural language policy optimization"
      },
      {
        "key": "wu2024beta",
        "author": "Wu, Junkang and Xie, Yuexiang and Yang, Zhengyi and Wu, Jiancan and Gao, Jinyang and Ding, Bolin and Wang, Xiang and He, Xiangnan",
        "title": "$beta$-DPO: Direct Preference Optimization with Dynamic $beta$"
      }
    ]
  },
  {
    "index": 43,
    "papers": [
      {
        "key": "bacciu2023rraml",
        "author": "Bacciu, Andrea and Cuconasu, Florin and Siciliano, Federico and Silvestri, Fabrizio and Tonellotto, Nicola and Trappolini, Giovanni",
        "title": "RRAML: reinforced retrieval augmented machine learning"
      }
    ]
  },
  {
    "index": 44,
    "papers": [
      {
        "key": "yang-etal-2023-prca",
        "author": "Yang, Haoyan  and\nLi, Zhitao  and\nZhang, Yong  and\nWang, Jianzong  and\nCheng, Ning  and\nLi, Ming  and\nXiao, Jing",
        "title": "{PRCA}: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter"
      }
    ]
  },
  {
    "index": 45,
    "papers": [
      {
        "key": "jin-etal-2024-bider",
        "author": "Jin, Jiajie  and\nZhu, Yutao  and\nZhou, Yujia  and\nDou, Zhicheng",
        "title": "{BIDER}: Bridging Knowledge Inconsistency for Efficient Retrieval-Augmented {LLM}s via Key Supporting Evidence"
      }
    ]
  }
]