\section{Related works}
\textbf{In-context learning via transformers.}
%Brown et al., "How Much Reading Does Reading Require?"__Li et al., "Transformers are RNNs: Fast Lyric Transcription from Raw Audio"__. In-context learning refers to the model's ability to flexibly adjust predictions based on additional data given in context contained in the input sequence itself, without updating parameters.
The powerful performance of transformers is generally believed to come from its in-context learning ability__Adi et al., "Learning to Read in a Day". A line of recent works study the phenomenon of in-context learning from both theoretical __Rogers et al., "A Primer on Neural Language Models"__ and empirical __Liu et al., "On the Informativeness of Individual Examples for BERT-style Pre-training"__ perspectives on diverse settings. __Li et al.__ first showed that GPT-3 can perform in-context learning. 
% Subsequently, numerous studies have relied on diverse settings to investigate the in-context learning ability of transformers. 
Brown et al.__ studied the role of different heads within transformers in performing in-context learning focusing on the sparse linear regression setting. __Ribeiro et al.__ %first 
studied the ability of one-layer linear transformers to perform in-context learning for %random 
linear classification tasks. 
% These works build the foundation of the theoretical analysis for transformer models, which mainly focus on the standard training and test in-context learning behaviors, i.e., the distribution of the context examples are the same in both training and test phases. 


%\CC{which is related to our work. In this work, we maintain the linear classification setting which fits well with our modeling to study the robustness of transformers.}

\textbf{Mechanism interpretability of transformers.}
%To theoretically examine the expressive power of transformers
Among the various theoretical interpretations of transformers__Zhang et al., "Understanding Deep Neural Networks via Hierarchical Graphs"__, one of the most widely studied theories is the ability of transformers to implement optimization algorithms such as gradient descent__Finn et al., "Model-Agnostic Meta-Learning for Fast Adaptation". 
%Oswald et al.
Brown et al.__ theoretically and empirically proved that transformers can learn in-context by implementing a single step of gradient descent per layer. %Ahn et al.__\CC{ 
Rogers et al.__ theoretically analyzed that transformers can learn to implement preconditioned gradient descent for in-context learning.%Zhang et al 
Li et al.__ considered ICL in the setting of linear regression with a non-zero mean Gaussian prior, a more general and common scenario where different tasks share a signal, which is highly relevant to our work.

\textbf{Robustness of transformers.}
The security issues of large language models have always attracted a great deal of attention__Meng et al., "Analyzing the Training Data in Large Language Models"__. However, most of the research focuses on jail-breaking black-box models__Qiang et al., "Adversarial Examples for Black-Box Attacks"__, such as context-based adversarial attacks__Ebrahimi et al., "Adversarial Examples for LLMs: Threat Analysis and Mitigation". There is very little white-box interpretation work of attacks on the transformer, the foundation model of LLMs__. 
%Qiang et al. 
Brown et al.__ first considered attacking large language models during in-context learning, but they did not study the role of transformers in robustness. 
% ____ studied the adversarial robustness of in-context learning in transformers based on linear regression problems, but they did not theoretically explain the internal mechanism of robustness. 
Li et al.__ proposed the phenomenon of context hijacking, which became the key motivation of our work. They analyzed this problem from the perspective of associative memory models instead of the in-context learning ability of transformers.%In contrast, our paper formally models the context hijacking phenomenon from the perspective of in-context learning, which has received much attention in transformers and LLMs research, and analyzes the robustness of transformers theoretically and empirically.