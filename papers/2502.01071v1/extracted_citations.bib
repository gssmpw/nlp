@misc{CLIPSeg,
      title={Image Segmentation Using Text and Image Prompts}, 
      author={Timo LÃ¼ddecke and Alexander S. Ecker},
      year={2022},
      eprint={2112.10003},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2112.10003}, 
}

@misc{SegmentA,
      title={Segment Anything}, 
      author={Alexander Kirillov and Eric Mintun and others},
      year={2023},
      eprint={2304.02643},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.02643}, 
}

@misc{alter3,
      title={From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"}, 
      author={Takahide Yoshida and Atsushi Masumori and others},
      year={2023},
      eprint={2312.06571},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2312.06571}, 
}

@misc{fewshotvqa,
      title={Few-Shot Image Classification and Segmentation as Visual Question Answering Using Vision-Language Models}, 
      author={Tian Meng and Yang Tao and others},
      year={2024},
      eprint={2403.10287},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2403.10287}, 
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and others},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{langreward,
      title={Language to Rewards for Robotic Skill Synthesis}, 
      author={Wenhao Yu and Nimrod Gileadi and others},
      year={2023},
      eprint={2306.08647},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2306.08647}, 
}

@misc{mujoco,
      title={Predictive Sampling: Real-time Behaviour Synthesis with MuJoCo}, 
      author={Taylor Howell and Nimrod Gileadi and others},
      year={2022},
      eprint={2212.00541},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2212.00541}, 
}

@misc{openvla,
      title={OpenVLA: An Open-Source Vision-Language-Action Model}, 
      author={Moo Jin Kim and Karl Pertsch and others},
      year={2024},
      eprint={2406.09246},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2406.09246}, 
}

@misc{palix,
      title={PaLI-X: On Scaling up a Multilingual Vision and Language Model}, 
      author={Xi Chen and Josip Djolonga and others},
      year={2023},
      eprint={2305.18565},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.18565}, 
}

@misc{palmee,
      title={PaLM-E: An Embodied Multimodal Language Model}, 
      author={Danny Driess and Fei Xia and others},
      year={2023},
      eprint={2303.03378},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.03378}, 
}

@misc{rt2,
      title={RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control}, 
      author={Anthony Brohan and Noah Brown and others},
      year={2023},
      eprint={2307.15818},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2307.15818}, 
}

@misc{rt2x,
      title={Open X-Embodiment: Robotic Learning Datasets and RT-X Models}, 
      author={Embodiment Collaboration and Abby O'Neill and Abdul Rehman and others},
      year={2024},
      eprint={2310.08864},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2310.08864}, 
}

@misc{yolo,
      title={You Only Look Once: Unified, Real-Time Object Detection}, 
      author={Joseph Redmon and Santosh Divvala and others},
      year={2016},
      eprint={1506.02640},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1506.02640}, 
}

