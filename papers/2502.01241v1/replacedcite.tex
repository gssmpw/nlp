\section{Related Work}
%-------------------------------------------------------------------------------

\mypara{Security Risks in LLMs}
The rapid advancement of LLMs provides users with significant convenience but also raises critical security concerns____.
Among these concerns, jailbreak attacks pose a major threat by bypassing built-in safety mechanisms, enabling models to generate restricted or harmful content that violates usage policies____.
Previous studies analyze existing jailbreak strategies, particularly focusing on in-the-wild jailbreak prompts that are manually crafted in real-world scenarios____.
More recent studies introduce automated jailbreak generators, such as AutoDAN____, GCG____, and TAP____, which optimize adversarial prompts to evade safety measures and maximize attack success rates.
Although model developers employ various safety alignment techniques, such as reinforcement learning from human feedback (RLHF)____, to train LLMs and mitigate these threats, attackers continuously refine their strategies, underscoring the persistent challenge.

\mypara{LLM Guardrails}
To better ensure the safe and responsible deployment of LLMs, researchers develop various guardrails that mitigate risks associated with both inputs and LLM-generated outputs to prevent policy-violating content.
Early online content moderation tools, such as Perspective API____ and OpenAI's Content Moderation API____, fall short due to the limited capacity of their backbone models and the inability of emerging policies to address evolving risks.
Recent studies introduce LlamaGuard____, which establishes a safety risk taxonomy encompassing a range of safety risks.
Built on Llama 2-7B, it is trained on a dataset constructed according to this taxonomy.
Subsequent versions, LlamaGuard2____ and LlamaGuard3____, further expand the safety risk taxonomy and dataset, leveraging state-of-the-art LLMs for fine-tuning, thereby strengthening their safeguard capabilities.
Similarly, WildGuard____, Aegis____, and ShieldGamma____ follow a comparable approach.
They define a broad safety risk taxonomy and develop dedicated data curation pipelines to construct fine-tuning datasets, thereby contributing essential resources for LLM guardrails.

\mypara{LLM Identification}
LLM identification aims to determine the origin LLM of LLM derivatives____.
A common approach to identifying the origin LLM, such as TRAP____ and ProFolingo____, is to leverage adversarial examples by optimizing a text prefix or suffix to query the model for a target response, which can then be utilized for model identification.
Guardrail identification and LLM identification share similarities, as state-of-the-art guardrails are often fine-tuned on top of LLMs using annotated datasets that cover a broad spectrum of safety risks____.
Inspired by LLM identification methods, we frame guardrail identification as an optimization problem.
Specifically, we optimize adversarial examples and analyze the behavioral patterns of guardrails in response to these inputs to identify candidate guardrails.

%-------------------------------------------------------------------------------