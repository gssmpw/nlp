\section{Related Work}
\label{sec:related}

\fakeparagraph{Traditional Path Data Generation}
Path generation is a fundamental building block for many spatiotemporal applications such as path planning \cite{NeurIPS23Xiao}, traffic prediction \cite{VLDB23Tian}, transportation simulation \cite{VLDB22Wang}, and others. 
Leveraging pattern mining from path data can significantly enhance modeling and prediction for these tasks.
Traditional methods often treat paths as sequences of vertices with a Markov property. 
However, a basic Markov chain model \cite{SuttonB98} can suffer from sparsity issues as the order of the Markov model increases. 
To address this, \cite{Ubicomp14Baratchi} proposed using hierarchical hidden states to mitigate the problem. 
Additionally, enhancements like adding contextual information (e.g., weather) have been used to improve performance \cite{TITS18Yin}.
Nevertheless, the strong assumption of the Markov property restricts the flexibility and usability of these traditional methods. 
Recent studies have shifted towards sequence-to-sequence models for better utility. 
Some studies use recurrent neural networks (RNNs) \cite{IJCAI17Wu}, while others employ transformer structures \cite{CIKM22Liang}. 
These neural network-based approaches help overcome the limitations of the Markov property.
To make better use of the graph structure for path generation, some works have explored hierarchical generation strategies \cite{KDD21Fu}, while others employ relay vertex prediction to ease the complexity of generating long paths \cite{VLDB22Wang}.

Recently, with the growing success of diffusion models in image and video generation \cite{ICCV23Peebles, CoRR24Esser}, diffusion-based path generation methods have emerged, as we will introduce next.


\fakeparagraph{Diffusion Models based Path Data Generation}
The diffusion process for generative modeling was first introduced by \cite{ICML15Dickstein}, which creatively employed a series of denoising autoencoders for generative tasks. 
Since then, many works have contributed to improving diffusion models, focusing on various aspects such as modeling the diffusion process \cite{NeurIPS20Ho, ICLR23Liu}, accelerating the sampling process \cite{ICLR21Song}, and enabling conditional generation \cite{CoRR24Ho}. 
These advances have largely targeted perceptual data generation, including images, videos, and audio, achieving significant success.

A major drawback of diffusion models is the high computational cost associated with the large number of timesteps required for the reverse generation process. 
This typically involves simulating ordinary or stochastic differential equations. 
To address this, \cite{ICLR21Song} broke the Markov property by directly modeling the marginal distribution, while some recent studies have moved away from score matching to flow matching \cite{ICLR23Lipman}, with rectified flow \cite{ICLR23Liu} aiming to generate nearly straight diffusion trajectories for one-step generation.

Despite these advancements, much of the focus has been on numerical values, with relatively little attention on categorical values. 
As a result, diffusion models designed for categorical values have lagged behind in adopting the latest innovations.
\cite{NeurIPS21Austin} proposed a general framework for categorical diffusion, while \cite{ICLR24Shi} was the first to design categorical diffusion models in graph space. 
However, these methods are tightly coupled with graph structures, leading to inflexibility and restricting their ability to incorporate the latest advances seen in numerical diffusion models.


% \TODO{refs} propose to adopt autoencoders and conduct diffusion process in latent space.
% Thanks to the autoencoders, the image data can be confined in a variance-restricted, low dimension space.
% This inspired us to devise a latent diffusion process for path data in graph space.