\subsection{Supporting Horizontal Pod Autoscaling in Kubernetes}
\label{hpa}

For effective implementation of Horizontal Pod Autoscaling (HPA) in Kubernetes, specifically for VK, it is crucial to establish accurate pod conditions. Accurate pod conditions are essential for the optimal functioning of HPA. This section provides essential insights and solutions to achieve this.

\subsubsection{Setting up the Kubernetes Metrics Server}

Prior to implementing the HPA, it is essential to ensure that the metrics server is installed within your Kubernetes cluster. Detailed installation instructions can be found in the official metrics server documentation \cite{metrics-server}.

\subsubsection{Understanding HPA through Code Analysis}

The HPA mechanism critically depends on specific Kubernetes code to evaluate pod readiness, particularly in the context of resource scaling. This essential logic ensures that only ready and appropriately initialized pods are considered for scaling actions based on CPU usage. The following snippet from the Kubernetes source code \cite{k8s-hpa} demonstrates this evaluation process:

\begin{verbatim}
if resource == v1.ResourceCPU {
    var unready bool
    _, condition := podutil.GetPodCondition(&pod.Status, v1.PodReady)
    if condition == nil || pod.Status.StartTime == nil {
        unready = true
    } else {
        if pod.Status.StartTime.Add(cpuInitializationPeriod).After(time.Now()) {
            unready = condition.Status == v1.ConditionFalse || 
                      metric.Timestamp.Before(condition.LastTransitionTime.Time
                      .Add(metric.Window))
        } else {
            unready = condition.Status == v1.ConditionFalse && 
                      pod.Status.StartTime.Add(delayOfInitialReadinessStatus)
                      .After(condition.LastTransitionTime.Time)
        }
    }
    if unready {
        unreadyPods.Insert(pod.Name)
        continue
    }
}
\end{verbatim}

\subsubsection{Implementing Correct Pod Conditions}

For HPA to function as intended, it is crucial to correctly set pod conditions upon creation and accurately update their status based on lifecycle events.

\paragraph{Pod Creation Phase}

The initial conditions for running and failed pods must reflect their true state to avoid misinterpretation by the HPA logic. This setup occurs when calling the method \texttt{CreatePod} (see Section~\ref{lifecycle}). The following details outline the process:

\begin{verbatim}
pod.Status.Conditions = []v1.PodCondition{
  {
    Type:               v1.PodScheduled,
    Status:             v1.ConditionTrue,
    LastTransitionTime: startTime,
  },
  {
    Type:               v1.PodReady,
    Status:             podReady,
    LastTransitionTime: startTime,
  },
  {
    Type:               v1.PodInitialized,
    Status:             v1.ConditionTrue,
    LastTransitionTime: startTime,
  },
}
\end{verbatim}

\paragraph{Pod Retrieving Phase}

\begin{verbatim}
Conditions: []v1.PodCondition{
  {
    Type:   v1.PodScheduled,
    Status: v1.ConditionTrue,
    LastTransitionTime: *prevPodStartTime,
  },
  {
    Type:   v1.PodInitialized,
    Status: v1.ConditionTrue,
    LastTransitionTime: *prevPodStartTime,
  },
  {
    Type:   v1.PodReady,
    Status: podReady,
    LastTransitionTime: prevContainerStartTime[firstContainerName],
  },
}
\end{verbatim}

\subsubsection{HPA Formula Explanation}

The HPA in Kubernetes determines the desired number of pod replicas using the following formula:

\begin{equation}
\texttt{Desired Replicas} = \left\lceil \text{Current Replicas} \times \left( \frac{\text{Current Metric}}{\text{Target Metric}} \right) \right\rceil
\end{equation}

\paragraph{Example}

Assume you have an application deployed with HPA configured to maintain an average CPU utilization of 50\%. If the current average CPU utilization is 90\% and there are 4 current replicas, the desired replicas calculation would be:

\begin{equation}
\texttt{Desired Replicas} = \left\lceil 4 \times \frac{90}{50} \right\rceil = \left\lceil 7.2 \right\rceil = 8
\end{equation}

\subsubsection{Evaluation of HPA using VK}

This section details the procedure for testing the HPA capabilities of pods running on VK. The HPA metric used for this assessment is CPU utilization, as provided by the metrics-server. The source code for this test is available on GitHub \cite{autoscaling-jiriaf}.

\paragraph{Setup}

The test setup includes an HTTP load balancer implemented in Go (\texttt{HPA/load/lb/load\_balancer.go}), which distributes HTTP requests across multiple HTTP servers implemented in Go (\texttt{HPA/load/server.go}). The Kubernetes deployment configuration for these HTTP servers specifies the number of replicas or pods. The HPA manages the scaling of these pods based on the defined metrics.

\paragraph{Load Generation}

HTTP request loads are generated using the \texttt{hey} application \cite{hey}, initiated by the bash script \texttt{HPA/load/add-load.sh}. To install \texttt{hey}, execute the following command:

\begin{verbatim}
go install github.com/rakyll/hey@latest
\end{verbatim}

\paragraph{Test Results}

The test results confirm that the HPA functions effectively with VK, including both the upscaling and downscaling of pods. As the load increases, the HPA scales up the number of pods to manage the additional load. Conversely, when the load decreases, the HPA scales down the number of pods after a five-minute interval from the last scaling operation.

\subsubsection{HTTP Server Deployment and HPA Configuration for Kubernetes}

Here is the deployment file \texttt{HPA/deploy.yaml} for the HTTP server:

\begin{verbatim}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: http-server
spec:
  selector:
    matchLabels:
      app: http-server
  template:
    metadata:
      labels:
        app: http-server
    spec:
      containers:
        - name: http-server
          image: http-server
          command: ["bash"]
          args: [""]
\end{verbatim}

Here is the HPA file \texttt{HPA/hpa.yaml}:

\begin{verbatim}
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: http-server-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: http-server
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 30
\end{verbatim}
