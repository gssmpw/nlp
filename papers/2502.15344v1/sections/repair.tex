\section{Program Repair}
\label{sec:program_repair}



We present an approach for repairing CTL violations via SEDL. 
We cannot directly leverage the existing implementation of SEDL, namely \Symlog, since it is limited to least fixed-point defined analyses, considering only positive Datalog programs. 
However, the CTL analysis involves nested least and greatest fixed points; thus, stratified negations frequently occur. 
In this section, we present our solution, enabling SEDL to repair CTL violations.
We also separate the computation of the constraints related to symbolic constants and symbolic signs.
The former is computed using an over-approximation method, while the latter is computed using ASP. 

\subsection{Symbolic Constants\label{sec:sym_const}}

% Seperate symbolic constants to the background section?
% All all Function's experiments (Table 1)
% Case study of RQ2.

The logical constraints related to symbolic constants involve assigning these symbolic constants to specific concrete constants, enabling the generation of the expected output facts. 
While a symbolic constant can represent any concrete constant, in practice, we only need to consider the concrete constants that can match the arguments in the existing facts through unification, called the \emph{domain} of a symbolic constant. 
% This set of concrete constants is the \emph{domain} of a symbolic constant.
%These set of concrete constants are in the \emph{domain} of a symbolic constant. 
% For example, given a fact \code{a(\alpha)} with the symbolic constant \code{\alpha}, a fact \code{b(1)}, and a rule \lstinline{c(X):-a(X),b(X)}, \code{\alpha} can be 1 to match with \plaincode{b(1)} to generate \plaincode{c(1)}.
For example, given facts \code{a(\alpha)} and \code{b(1)}, and rule \lstinline{c(X):-a(X),b(X)}, \code{\alpha} must be 1 to generate \code{c(1)} through unification with \code{b(1)}. 
% So, 1 should be in the domain of \code{\alpha}. 
Thus, 1 belongs in \code{\alpha}'s domain. 
For each constant \code{c} in \code{\alpha}'s domain, \code{\alpha{\,=\,}c} is a condition in the logical constraint \code{\psi}. 


\begin{figure}[!h]
\small
\[\begin{aligned}
& p(..., \alpha_i, ...) \in \mathcal{E} \Rightarrow   \mathrm{depend}(p, i, n)  & & [D0]\\
& \qquad \text{where n is a placeholder for $\alpha$} \\
& p(..., c_i, ...) \in \mathcal{E} \Rightarrow  \mathrm{depend}(p, i, c)  
& & [D1]\\
& \relation \datalogarrow  \,..., p(..., c_i, ...), .... \in \drule^{*}_{\m{pos}} \Rightarrow \mathrm{depend}(p, i, c) 
& & [D2]\\
& \relation \datalogarrow  \,..., p_1(..., X_i, ...), ..., p_2(..., X_j, ...), .... \in \drule^{*}_{\m{pos}},  X_i \equiv X_j \\
& \qquad \Rightarrow \forall c.\,\mathrm{depend}(p_1, i, c) \Leftrightarrow \mathrm{depend}(p_2, j, c) 
& & [D3]
\end{aligned}\]
  

  
  

\caption{The  ``\code{\mathrm{depend}}" relation. \code{\SE} is the symbolic EDB, 
\code{X_i \equiv X_j} denotes that \code{X_i} and \code{X_j} are identical variables.
\code{\alpha} is a symbolic constant, \code{c} is a concrete constant, and \code{n} is the placeholder for \code{\alpha}.
\label{fig:depend}}
\end{figure}

To estimate the domain of a symbolic constant, we first remove all the negative literals in the rules and then use \Symlog's method, which computes the "\code{\mathrm{depend}}" relations,  defined in \figref{fig:depend}. 
Here \code{\drule^{*}_{\m{pos}}} is the set of rules with all negative literals removed. 
We use \code{p(..., w_i, ...)} to mean that \code{w} appears at the \code{i}-th argument in a literal \code{p}, and \code{w} can be constants, symbolic constants, or variables. 
Relation ``\code{\mathrm{depend}(p, \ijk, c)}" says that the constant \code{c} may appear at the \code{\ijk}-th position of the fact \code{p} during evaluation, which 
%The \code{\mathrm{depend}} relation 
is designed to over-approximate the possible constants that appear at \code{i}-th argument of fact \code{p}.
This over-approximation is introduced because it is impractical to compute the exact set of constants at the position after introducing symbolic constants~\cite{DBLP:conf/sigsoft/LiuMSR23}. 

For any fact \code{p(..., \alpha_i, ...)}, rule \code{[D0]} generates \code{\mathrm{depend}(p, i, n)}, where \code{n} is the placeholder for \code{\alpha}. 
Every symbolic constant has a corresponding placeholder, which is useful for `inventing' new output facts whose arguments are unseen in the current EDB. 
Usually, the placeholders will be instantiated by the constants in the target facts. 
Similarly, rule \code{[D1]} generates \code{\mathrm{depend}(p, i, c)} for all the concrete constant arguments. 
Rule \code{[D2]} states that if there is a positive literal \code{p(..., c_i, ...)}, then \code{\mathrm{depend}(p, i, c)} is generated.
% which means \code{c} may appear at the \code{i}-th position of the fact \code{p} during evaluation. 
This is because the additional facts instantiated from symbolic constants may enable this occurrence.
Rule \code{[D3]} states that if variables \code{X_i} and \code{X_j} are identical across different literals in a rule, then any \code{c} that can appear at the position of \code{X_i} in a \code{p_1} fact may also appear at the position of \code{X_j} in a \code{p_2} fact. This propagation of potential constants happens regardless of whether the literals are in the head or body of the rule. 
% Such over-approximation is also introduced because other newly added facts may enable the generation of the facts required by the rule. 

\Symlog also over-approximates the positions where the instantiation of \code{\alpha} is used for unification with the constant in a fact for generating new output facts.
The over-approximation is computed using ``\code{\mathrm{pos(\alpha)}}" in the following \code{[Dom]} rule.
This is an over-approximation because the computed set of \code{(p, \ijk)} over-approximates all positions where \code{\alpha} may appear. 
% regardless of what conditions are placed on \code{\alpha}.
Those positions where \code{\alpha} may appear is a superset of the positions where its instantiation is used for unification.
% This is because unification determines whether \code{\alpha} can appear at a position, and \code{\alpha} appearing at a position implies that the unification succeeds.
For a symbolic constant \code{\alpha}, the over-approximation of its domain is defined as: 
{
\begin{alignat*}{2}
\mathrm{pos(\alpha)} & \triangleq \{(p, \ijk) \mid \mathrm{depend}(p, \ijk, n)  \}\\
\mathrm{domain}^\sharp(\alpha) & \triangleq  \{\,c\,|\,\mathrm{depend}(p, \ijk, c), (p, \ijk) \in \mathrm{pos}(\alpha)\,\}  \quad 
&&\, \m{[Dom]} 
\end{alignat*}
}


% \noindent The "\code{\mathrm{pos(\alpha)}}" function returns the set of pairs \code{(p, \ijk)} such that \code{\mathrm{depend}(p, \ijk, n)} holds. 
% The set returned by "\code{pos(\alpha)}" is an over-approximation of all the positions where the instantiation of \code{\alpha} is required to unify with the \code{\ijk}-th constant in \code{p} to generate the output fact.
% The reason is that the set of pairs \code{(p, \ijk)} is an over-approximation of all positions where \code{\alpha} may appear regardless of the condition on it.
% The positions where \code{\alpha} may appear is a superset of the positions where the instantiation of \code{\alpha} is required to generate output fact. 
% This set of pairs \code{(p, \ijk)} is an over-approximation of all positions where \code{\alpha}'s instantiation is required to unify with the \code{\ijk}-th constant in \code{p} to generate the output fact. 
% To generate the output fact, \code{\alpha = c} must hold.

\noindent \code{[Dom]} computes the over-approximation of \code{\alpha}'s domain by taking the union of all potential constants that \code{\alpha} is used for unification during the Datalog program evaluation. 


After removing all the negative literals, the \code{\mathrm{domain}^\sharp(\alpha)} computed by \code{[Dom]} is an over-approximation of the domain of \code{\alpha} in the original stratified Datalog program.
% The reason is that generating new facts for a rule \code{R^+} \syh{is \code{R^+} explained?} without negative literals requires less conditions than generating new facts for the rule \code{R} with negative literals.
A rule \code{\drule} containing negative literals is more restrictive than its positive-only version \code{\drule_{\m{pos}}} 
%(where all negative literals are removed) 
because \code{\drule_{\m{pos}}} only requires matching positive conditions. In contrast, \code{\drule} must ensure that no facts correspond to the negative literals. 
%A rule R with negative literals is more restrictive than its positive-only version R+ (with all negative literals removed) because R+ only needs to match positive conditions, while R must additionally ensure no facts match the negative literals. 
% The reason is that generating new facts for a rule without negative literals requires fewer conditions than generating new facts for the corresponding rule with negative literals.
So, given the same input facts, at each step during the evaluation, the set of facts that can be generated from \code{\drule^{*}_{\m{pos}}} is a superset of that from \code{\drule^{*}}.
Therefore, when other symbolic constants and symbolic signs are fixed, the set of constants that appear at each position \code{(p, i)}
% \syh{why two layers?}
in the facts generated from \code{\drule^{*}_{\m{pos}}} is a superset of that from \code{\drule^{*}} at each step of the evaluation.
% In stratified Datalog, it is possible for some literals corresponding to facts containing \code{\alpha} to be negative. 
% In such cases, the inference condition for the output fact should include non-equivalence conditions between \code{\alpha} and certain constants.
% While we cannot capture these non-equivalence conditions after removing all negative literals, this case is handled by the placeholder of \code{\alpha}.
% When \code{\alpha} equals its placeholder, it is by definition not equal to those certain constants.
% Not capturing the concrete non-equivalence conditions does not impair the repair process because the solution to a non-equivalence condition is to assign \code{\alpha} to a different constant, which can be satisfied by using the placeholder.
% We do not handle the symbolic signs at this stage.
% In stratified Datalog, the 
The set of positions \code{(p, \ijk)} where \code{\alpha} is used for unification with the \code{\ijk}-th argument in \code{p} in \code{\drule^{*}_{\m{pos}}} is also a superset of that in \code{\drule^{*}}.
This is also because the conditions for allowing \code{\alpha} to be propagated to a position in \code{\drule} 
% \syh{\code{R^+}}
are less than that of 
% \syh{\code{R}}.
\code{\drule_{\m{pos}}}.
% As mentioned above, the set of constants that appear at the each position (\code{(p, i)}) in the facts generated from \code{\drule^{*}_{\m{pos}}} is a superset of that from \code{\drule^{*}} at each step of the evaluation.
Due to both the superset relation of unification positions and the superset relation of constants at each position, the domain of \code{\alpha} in \code{\drule^{*}_{\m{pos}}} is a superset of that in \code{\drule^{*}}. Furthermore, since \code{\mathrm{domain}^\sharp(\alpha)} is an over-approximation of the domain of \code{\alpha} in \code{\drule^{*}_{\m{pos}}}, it is also an over-approximation of the domain of \code{\alpha} in \code{\drule^{*}}.
% Because of these two points, the domain of \code{\alpha} in \code{\drule^{*}_{\m{pos}}} is a superset of that in \code{\drule^{*}}.
% Since \code{\mathrm{domain}^\sharp(\alpha)} is an over-approximation of the domain of \code{\alpha} in \code{\drule^{*}_{\m{pos}}}, it is also an over-approximation of the domain of \code{\alpha} in \code{\drule^{*}}.


\paragraph*{\textbf{Example 2: Constraints over Symbolic Constants}} 
To illustrate how the domains of symbolic constants are computed, we use the first rule in \figref{fig:symbolic_sign_Example}, \lstinline[mathescape]{a(X):-b(X),c(X),!d(X),!e(X).}, as an example.
Assuming that the symbolic EDB is as follows: 
\[\mathcal{E}_0 = {\{\xi_1 \, b(\alpha_1), \xi_2 \, c(\alpha_2)\}}\]
\noindent 
and placeholders \lstinline[mathescape]`$n_1$` and \lstinline[mathescape]`$n_2$` 
are associated with symbolic constants \code{\alpha_1} and \code{\alpha_2}. 
%are introduced.
According to \code{[D0]}, \code{\mathrm{depend}(b, 0, n_1)} and \code{\mathrm{depend}(c, 0, n_2)} are first generated.
As positive literals \code{a(X)}, \code{b(X)} and \code{c(X)} share the same \code{X}, \code{\mathrm{depend}(a, 0, n_1)}, \code{\mathrm{depend}(a, 0, n_2)}, \code{\mathrm{depend}(b, 0, n_2)}, and \code{\mathrm{depend}(c, 0, n_1)} are further  generated according to \code{[D3]}.
Then, based on \code{[Dom]}, both \code{\mathrm{pos(\alpha_1)}} and \code{\mathrm{pos(\alpha_2)}} are \code{\{(a, 0), (b, 0), (c, 0)\}}, and 
\code{\mathrm{domain}^\sharp(\alpha_1)} is 
% \syh{change to the [Dom] form}
\code{\{ c \mid depend(p, i, c), (p,i) \in \mathrm{pos(\alpha_1}) \}}
= \code{\{n_1, n_2\}}.
Similarly, \code{\mathrm{domain}^\sharp(\alpha_2)} is also \code{\{n_1, n_2\}}. 
With these domains, we can concretize \code{\mathcal{E}_0} w.r.t. each concrete valuation of the symbolic constants. 
Given that \code{\{n_1, n_2\}} is the domain for both \code{\alpha_1} and \code{\alpha_2}, 
we can obtain four sets of concrete facts by replacing each symbolic constant with a constant from its domain:
\begin{align*}
\{\xi_1\,b(n_1), \xi_2\,c(n_1)\} &\quad \{\xi_1\,b(n_1), \xi_2\,c(n_2)\} \\
\{\xi_1\,b(n_2), \xi_2\,c(n_1)\} &\quad \{\xi_1\,b(n_2), \xi_2\,c(n_2)\} \\
\end{align*}
With the set \code{\{\xi_1\,b(n_1), \xi_2\,c(n_1)\}}, the fact \code{a(n_1)} can be generated.
With the set \code{\{\xi_1\,b(n_2), \xi_2\,c(n_2)\}}, the fact \code{a(n_2)} can be generated.
For the other two sets, no facts can be generated.
We do not consider the truth assignments for symbolic constants at this stage.
The derived facts and their corresponding constraints related to symbolic constants are:
\code{(a(n_1), \alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1)} and \code{(a(n_2), \alpha_1 {=} n_2 {\,\wedge\,} \alpha_2{=}n_2)}.

\subsection{Symbolic Signs}
% After estimating the domains of symbolic constants, we can derive facts with concrete constants for each assignment combination of symbolic constants.
% We can instantiate four sets of facts without symbolic constants from them.

After instantiating all the symbolic constants, 
% with concrete valuations, 
%After obtaining all the \syh{fact sets} without symbolic constants, 
%if the symbolic EDB contains symbolic signs,  
we next compute the Boolean values of the symbolic signs to generate the final $\psi$. 
\Symlog converts the problem 
into finding a set of dependent facts, such that the expected output fact can only be inferred when their signs are positive.
To find these dependent facts, \Symlog uses delta-debugging (DD) ~\cite{zeller1999yesterday}. 
However, this approach can lead to incorrect results for rules with negations.


\begin{figure}[!b]
\vspace{-4mm}
\begin{lstlisting}[xleftmargin=7em,numbers=none,basicstyle=\footnotesize\ttfamily]
a(X):-b(X),c(X),!d(X),!e(X).
a(X):-d(X).
a(X):-e(X),!c(X).
\end{lstlisting} 
\caption{Example for Illustrating the Incapacity of \Symlog}
\label{fig:symbolic_sign_Example}
\vspace{-1mm}
\end{figure}

\begin{figure}[!b]
\begin{lstlisting}[mathescape, xleftmargin=4em,numbers=none,basicstyle=\footnotesize\ttfamily]
a(X) :- b(X), c(X), not d(X), not e(X).
{b($n_1$); c($n_1$)}.
:- not a(1), not a($n_1$).
\end{lstlisting}
\caption{An ASP program computing the answer sets for generating at least one of \code{a(1)} or \code{a(n_1)}.
\{ \} is a choice structure representing any elements within it that can be included in the answer set. 
% "\lstinline{:- not a(1).}" is the constraint for generating \lstinline{a(1)}.
\label{fig:asp_program}
}
%
\end{figure}


\paragraph*{\textbf{Example 3: Incapacity of \Symlog}} 
In \figref{fig:symbolic_sign_Example},
assume that \code{\relation{=}}\code{a(1)} is the target output fact, and all the following facts are associated with symbolic signs: \code{\{b(1),c(1),e(1),d(1)\}}.
DD divides the fact set evenly and tests if the right half still can produce \code{\relation}.
The subset \code{\{e(1),d(1)\}} still can generate \code{\relation}, so DD further divides it to \code{\{d(1)\}}, which still produces \code{\relation} according to the second rule. 
Thus, DD returns \code{\{d(1)\}} as a dependent fact set. 
Since \Symlog needs to find all dependent fact sets, it iteratively selects one fact from the returned dependent facts and removes it from the fact set, then it searches for new dependent facts from the updated fact set, continuing this process until no new dependent facts can be found.
In this example, removing \code{d(1)} leaves \code{\{}\code{b(1),c(1),e(1)}\code{\}}, which cannot generate \code{\relation}, so DD 
concludes that \code{\{}\code{d(1)}\code{\}} is the only dependent fact set.
However, \code{\{}\code{b(1), c(1)}\code{\}} and \code{\{}\code{e(1)}\code{\}} are also dependent fact sets. 
If \code{\relation} represents a bug, removing only \code{d(1)} would not be able to disable it. 




%, which fits our case.
To support both positive rules and rules with stratified negations,  
%, we propose an ASP-based solution. 
%Specifically, 
we encode these  %original %Datalog 
rules using Answer Set Programming (ASP)~\cite{DBLP:books/sp/Lifschitz19}, a declarative programming for solving complex search problems.
ASP solvers can find sets of facts that satisfy given constraints, even if the rules are non-monotonic. 
An ASP program includes Prolog/Datalog-style rules and facts, and allows for specifying constraints with an empty head rule. 
It also supports \emph{choice} rules, enabling alternative solutions. 
A solution of the ASP program is referred to as an \emph{answer set}.

ASP can be used to compute the sets of facts that enable the target output fact \code{\relation}.
Specifically, given any concrete valuation of the symbolic constants, the procedure for computing dependent fact sets is: 
(i) transform the Datalog rules to ASP rules;
(ii) transform the facts instantiated with the valuation to ASP facts and surround the facts with symbolic signs using the choice structure; and
(iii) specify the expected output fact via \code{\relation} and the facts with placeholders.
The answer sets of the converted ASP program correspond to the sets of facts enabling \code{\relation}.
The union of answer sets gathered from each valuation is the complete dependent fact set for \code{\relation}. 


% \begin{table*}[htbp]
% \caption{\label{tab:comparewithFuntionT2} 
% {Accuracy comparison of different tools for CTL property verification. 
% For each property type, we show both the percentage and fraction of successfully verified properties, along with the number of files and representative examples.}
% } 
% \normalsize
% \renewcommand{\arraystretch}{1}
%   \setlength{\tabcolsep}{11.5pt}
%   \begin{tabular}{c|l|c|c|l|c|c}
%   \Xhline{1.5\arrayrulewidth}
%   \multicolumn{1}{l|}{\multirow{2}{*}{\textbf{}}} & \multirow{2}{*}{\textbf{Property Type}} & \multirow{2}{*}{\textbf{\#Files}} & \multirow{2}{*}{\textbf{LoC}} & \multirow{2}{*}{\textbf{Examples}} & \multicolumn{2}{c}{\textbf{Tool Performance}} \\ 
%   \cline{6-7}
%   \multicolumn{1}{l|}{} & & & & & \multicolumn{1}{c|}{\textbf{Function}} & \textbf{CTLExpert} \\
%   \Xhline{1.5\arrayrulewidth}
  
%   1 & Termination & 15 & 402 & AF(Exit()) & \multicolumn{1}{c|}{40.0\% (6/15)} & 66.7\% (10/15) \\

%   2 & Reachability & 25 & 470 & EF(resp{$\geq$}5), EF(r=1) & \multicolumn{1}{c|}{36.0\% (9/25)} & 68.0\% (17/25) \\
  
%   3 & Responsive & 32 & 1,027 & AG(t=0{$\rightarrow$}AF(o=1)) & \multicolumn{1}{c|}{18.8\% (6/32)} & 50.0\% (16/32) \\
  
%   4 & Invariance & 2 & 30 & AG(AF(t=1){$\wedge$}AF(t=0)) & \multicolumn{1}{c|}{0.0\% (0/2)} & 0.0\% (0/2) \\
  
%   5 & Until & 6 & 193 & AU(i=0)(AU(i=1)(AG(i=3))) & \multicolumn{1}{c|}{0.0\% (0/6)} & 33.3\% (2/6) \\
  
%   6 & Next & 3 & 18 & AX(AX(x=0)) & \multicolumn{1}{c|}{66.7\% (2/3)} & 66.7\% (2/3) \\
%   \Xhline{1.5\arrayrulewidth}
%   & \textbf{Total} & 83 & 2,140 & & \multicolumn{1}{c|}{27.7\% (23/83)} & 56.6\% (47/83) \\
%   \Xhline{1.5\arrayrulewidth}
%   \end{tabular}
%   \vspace{1mm}
%   \end{table*}


\begin{table*}[!t]
  \caption{\label{tab:comparewithFuntionT2} 
  {Accuracy comparison for CTL property verification. 
  For each property type, we show the percentage of successfully verified properties, the number of files, representative examples, and total verification time.}
  } 
  \vspace{-1mm}
  \normalsize
  \centering
  \renewcommand{\arraystretch}{0.95}
  \setlength{\tabcolsep}{2.5pt}  % Slightly reduced to accommodate longer column header
  \begin{tabular}{c|l|c|c|l|c|c|c|c}
  \Xhline{1.5\arrayrulewidth}
  \multicolumn{1}{l|}{\multirow{2}{*}{\textbf{}}} & \multirow{2}{*}{\textbf{Property Type}} & \multirow{2}{*}{\textbf{\#Files}} & \multirow{2}{*}{\textbf{LoC}} & \multirow{2}{*}{\textbf{Examples}} & \multicolumn{2}{c|}{\textbf{Function}} & \multicolumn{2}{c}{\textbf{CTLExpert}} \\
  \cline{6-9}
  \multicolumn{1}{l|}{} & & & & & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{Total Time(s)} & \multicolumn{1}{c|}{\textbf{Accuracy}} & \textbf{Total Time(s)} \\
  \Xhline{1.5\arrayrulewidth}
  
  1 & Termination & 15 & 402 & AF(Exit()) & \multicolumn{1}{c|}{40.0\% (6/15)} & 0.357 & \multicolumn{1}{c|}{66.7\% (10/15)} & 3.082 \\

  2 & Reachability & 25 & 470 & EF(resp{$\geq$}5), EF(r=1) & \multicolumn{1}{c|}{36.0\% (9/25)} & 0.303 & \multicolumn{1}{c|}{68.0\% (17/25)} & 2.423 \\
  
  3 & Responsive & 32 & 1,027 & AG(t=0{$\rightarrow$}AF(o=1)) & \multicolumn{1}{c|}{18.8\% (6/32)} & 3.279 & \multicolumn{1}{c|}{50.0\% (16/32)} & 0.937 \\
  
  4 & Invariance & 2 & 30 & AG(AF(t=1){$\wedge$}AF(t=0)) & \multicolumn{1}{c|}{0.0\% (0/2)} & 0.226 & \multicolumn{1}{c|}{0.0\% (0/2)} & 0.045 \\
  
  5 & Until & 6 & 193 & AU(i=0)(AU(i=1)(AG(i=3))) & \multicolumn{1}{c|}{0.0\% (0/6)} & 6.756 & \multicolumn{1}{c|}{33.3\% (2/6)} & 0.223 \\
  
  6 & Next & 3 & 18 & AX(AX(x=0)) & \multicolumn{1}{c|}{66.7\% (2/3)} & 0.006 & \multicolumn{1}{c|}{66.7\% (2/3)} & 0.299 \\
  \Xhline{1.5\arrayrulewidth}
  & \textbf{Total} & 83 & 2,140 & & \multicolumn{1}{c|}{27.7\% (23/83)} & 10.927 & \multicolumn{1}{c|}{56.6\% (47/83)} & 7.008 \\
  \Xhline{1.5\arrayrulewidth}
  \end{tabular}
  \vspace{1mm}
\end{table*}


\paragraph*{\textbf{Example 4: Constraints over Symbolic Signs}} 
% \syh{Continue from example 4?}
Continue from Example 3,
taking \code{\{\xi_1 b(n_1),}
\code{\xi_2 c(n_1)\}} instantiated from $\mathcal{E}_0$ and the first rule in \figref{fig:symbolic_sign_Example} as an example.
Assuming the target fact is \code{a(1)}, the corresponding ASP program is shown in \figref{fig:asp_program}. 
The choice structure, \lstinline!{}!, indicates that any of the enclosed facts can be selected for the answer set. 
The constraint ``\lstinline[mathescape]{:- not a(1), not a($n_1$)}" is to prevent all \code{a(1)} and \code{a(n_1)} from not being generated simultaneously, i.e., at least one of them should be generated.
Such a constraint eliminates any answer set that satisfies the constraint.
The fact \code{a(n_1)} is also included in the constraint, as it is possible that the target output cannot be produced by the `seen' constants in the given fact set, as shown in this example.
% By generating the fact with placeholders, 
The placeholders can be replaced with the constants in the target fact to generate the final dependent facts.
The solution of this constraint is \code{\{b(n_1),c(n_1)\}}.
In this example, \code{n_1} can be replaced with 1, and \code{a(n_1)}'s dependent fact set 
\code{\{b(n_1), c(n_1)\}} correspondingly becomes \code{\{b(1), c(1)\}}.
Since \code{b(n_1)} and \code{c(n_1)} are selected, the truth assignments for \code{\xi_1} and \code{\xi_2} are both \emph{true}. 
Combining the constraints related to symbolic constants, 
\code{\alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1}, and the truth assignments for \code{\xi_1} and \code{\xi_2}, the logical constraints for \code{a(1)} is 
\code{\psi:\alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1 {\,\wedge\,} n_1 {=} 1 {\,\wedge\,} \xi_1 {\,\wedge\,} \xi_2 }.
Computing \code{\psi} for \code{\{\xi_1\,b(n_2), \xi_2\,c(n_2)\}} similarly, our method returns:
\begin{align*}
  (a(1), & (\alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1 {\,\wedge\,} n_1 {=} 1 {\,\wedge\,} \xi_1 {\,\wedge\,} \xi_2) \,\vee \\
          & (\alpha_1 {=} n_2 {\,\wedge\,} \alpha_2{=}n_2 {\,\wedge\,} n_2 {=} 1 {\,\wedge\,} \xi_1 {\,\wedge\,} \xi_2))
\end{align*}

% With the truth assignments for \lstinline[mathescape]{$\xi_1$, $\xi_2$} being 
% { \code{\{\xi_1 {\mapsto} T}, \code{\xi_2 {\mapsto} T \}}}, the logical constraints \code{\psi} under \code{\{\xi_1 b(n_1), \xi_2 c(n_1)\}} is 
% \code{ \psi: \alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1 {\,\wedge\,} n_1 {=} 1 {\,\wedge\,} \xi_1 {\,\wedge\,} \xi_2 }.
% If we instruct the ASP solver to find all answer sets, there will be one output (with \code(a(1)) omitted): \lstinline[mathescape]`{b(1), c(1)}`.
% \code{d(1)} is not included as \code{d(X)} is negated in the rule.
% For the answer set, the truth assignments for \lstinline[mathescape]{$\xi_1$, $\xi_2$, $\xi_3$} are 
% { { \code{\{\xi_1 {\mapsto} T}, \code{\xi_2 {\mapsto} T}, 
% \code{\xi_3 {\mapsto} F\}}}}.
% Thus, for the above parital output, its complete version is: (\lstinline[mathescape]`$n_1$`, \code{\alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1 {\,\wedge\,} n_1 {=} 1 {\,\wedge\,} \xi_1 {\,\wedge\,} \xi_2 {\,\wedge\,} \neg \xi_3}).


%Similarly, t
To compute the truth assignments that prevent a given output fact from being generated, we can remove the `\lstinline{not}' in front of the ASP constraint.
% The resulting answer sets will be the sets of facts that ensure the output fact is not generated.
The ASP %solving 
results can directly serve our symbolic sign assignments, as the semantics of stratified Datalog coincide with the answer set semantics, where the facts cannot be inferred from existing facts are considered \emph{false}~\cite{tekle2019extended}.
% A potential performance issue is that the number of valuations for symbolic constants may be large, causing the ASP solver to be called necessarily many times. 
% We describe in \app{IX} \cite{tech_report} a pruning method which tracks dependencies of symbolic constants and symbolic signs.
% %Then 
% Any valuation that violates the dependencies is recognized as an invalid valuation, which can be safely pruned. 
% More details can be found in \app{IX} \cite{tech_report}. 
%Executing the meta-program identifies potentially valid valuations, thus reducing the search space by pruning invalid ones.
% \syh{we prune the search space by finding ... } 
%shows the method. 


\subsection{Patch Generation}
%1. strategey of selecting symbols/facts; fact handling -> map to source code (if re-run)
%2. patch selection
% \paragraph{\textbf{Repair Strategies}}

% We introduce three strategies for fact modifications.
% \begin{enumerate}[itemsep=0.1ex,leftmargin=2em]
%   \item Add facts which introduce additional assignments along existing paths; 
%   \item Update facts which revise current assignments on existing paths; 
%   \item Delete facts which represent symbolic paths.
% \end{enumerate}
\subsubsection{Atomic Templates}
We introduce three atomic templates for fact modifications:  
% Reasons
% map to source code
% selected symbols should related to them
(1) {Fact Addition} introduces facts along existing paths to satisfy the CTL property.
These added facts map to inserting assignments in the source code.
For this template, we inject symbolic constants only into ``assignment" facts without injecting any symbolic signs into the EDB.
(2) {Fact Update} revises current assignments on existing paths to satisfy the CTL property.
These fact modifications map to removing and adding assignments in the source code.
Similar to the first template, we only inject symbolic constants into ``assignment" facts, but we also associate symbolic signs with the existing ``assignment" facts.
(3) {Fact Deletion} highlights symbolic paths that do not satisfy the CTL property. These modifications essentially involve inserting conditional statements with early exits before the main logic of the program, which prevents the program from reaching the paths described by the deleted facts. 
In this template, we associate symbolic signs with facts which are generated to model the non-deterministic values of the program variables. Since the generated patches may impact the program's transition structures, \toolName must re-analyze the modified program to verify whether the CTL property is satisfied. 

\subsubsection{Repair Configuration}
After applying an atomic template, if the CTL property is still not satisfied, \toolName can switch to a different atomic template to either repair the original program or continue to address the updated, yet still incorrect, program. 
There are two common strategies for proceeding: applying atomic templates in a depth-first manner (where one template is exhaustively applied before moving on to another) or in a breadth-first manner (where all templates are applied to the program before addressing the updates). 
When multiple patches are generated from applying an atomic template, we select the ones requiring the fewest modifications. Among the selected patches that involve inserting assignments, we further choose the option where the inserted assignments are closest to the exit points. This approach minimizes the scope affected by the patch. 
