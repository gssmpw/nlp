\documentclass[acmsmall,screen,review,anonymous,nonacm]{acmart}
\let\Bbbk\relax
\usepackage{centernot} % for the comparison
\renewcommand*{\thesection}{App\,\roman{section}}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmicx}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{comment}
\usepackage{import} % subimport
\usepackage{xspace} % xspace
\usepackage{numprint} % numprint
\usepackage{ifthen}
\usepackage{listings}
\usepackage{subcaption} % subfigure
\usepackage{multirow}
\usepackage[nameinlink]{cleveref}
\usepackage{caption}
\usepackage{framed}
\usepackage{tikz}
\usepackage{tikz-qtree}
\usetikzlibrary{shapes.geometric, arrows, positioning}
\usepackage[epsilon,altpo]{backnaur}
\usepackage{bussproofs}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{pifont}
\usepackage{wasysym}
\usepackage{makecell}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{mdframed} % for creating framed boxes that can break across pages


\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{amsthm}
\usepackage{wrapfig}
\usepackage[utf8]{inputenc}
\usepackage{textcomp}
\usepackage{proof}
\usepackage{pmboxdraw}
\usepackage{amsmath}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{stmaryrd}
\usepackage{titlecaps}% http://ctan.org/pkg/titlecaps
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{wrapfig}
\usepackage{xspace}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage[normalem]{ulem}


\usepackage{ifthen} % for todos
% TODOs

\usepackage{stmaryrd}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{makecell, boldline}
\usepackage{mathtools}

\usepackage{xparse}
\usepackage{wrapfig}


\usepackage{thm-restate}
%\usepackage[capitalise]{cleveref}


\title{Reactive Program Repair}
\title{Reactive Program Repair using Computation Tree Logic}
\title{Computation Tree Logic guided Reactive Program Repair}
\title{\toolName: CTL guided Reactive Program Repair {\Large (Technical Report)}}
\title{Computation Tree Logic guided Program Repair \\{\Large (Supplementary Material)}
}
%With Precise Loop Summaries 


\usepackage{amsmath}
\usepackage{color,latexsym,graphics,wrapfig}
\usepackage{listings}
\usepackage{multirow}
\usepackage{lineno}
\usepackage{graphicx}
\usepackage{mathpartir}

% \newif\iftechreport
% \techreporttrue
% \newcommand*{\techreportonly}[1]{}


\algrenewcommand\algorithmicindent{0.6em} % or any other value as you wish
%\usepackage[bottom]{footmisc}

\input{utils.tex} % TODOs, English, etc


\begin{document}

\maketitle

% \thispagestyle{plain}
% \pagestyle{plain}



\section{The Gottlob Encoding for AF}
\label{appsec:AF_encoding}


\figref{fig:AF_encoding} presents the original AF encoding, which assumes that the target infinite system has a finite structure.  


\begin{figure}[!h]
\vspace{-3mm}
\begin{align*}
AFT_{\phi}(x, y) &\leftarrow \neg \phi(x), \mathtt{flow}(x, y)  
\\ 
AFT_{\phi}(x, z) &\leftarrow AFT_{\phi}(x, y), \neg \phi(y), \mathtt{flow}(y, z)  \\
AFS_{\phi}(x) &\leftarrow AFT_{\phi}(x, x) 
\\ 
AFS_{\phi}(x) &\leftarrow \neg \phi(x), \mathtt{flow}(x, y) , AFS_{\phi}(y) \\ 
AF_{\phi}(x) &\leftarrow \mathtt{State}(x), \neg AFS_{\phi}(x)
\end{align*}
\vspace{-2mm}

\caption{The original Datalog encoding for the AF operator \cite{gottlob2002datalog}}
\label{fig:AF_encoding}
\end{figure}

\section{Full Encoding for CTL to Datalog}
\label{appsec:full_encoding}

The complete set of encoding is shown in 
\figref{fig:comlete_ctl-datalog-translation-table-ctl}, which contains 8 rules corresponding to the 8 primitive CTL constructs. 
It is standard to encode the rest of the CTL operators using the core set, including $AX$, $AU$, $EG$, $AG$, and the implication operator, which are encoded using the core operators with the equivalence relations shown in \figref{fig:ctl-datalog-translation-table-deriv}. 
{\begin{figure}[!h]
\vspace{-3mm}
\small
\centering
\begin{gather*}
AX\,\phi {\,\equiv\,} \neg EX~\neg  \phi 
\qquad  
EG\,\phi {\,\equiv\,} \neg AF \neg \phi 
\qquad  
AG\,\phi {\,\equiv\,} \neg EF \neg \phi 
\\ 
A(\phi_{1}U\phi_{2}) {\equiv} \neg E  (\neg \phi_{2} U (\neg \phi_{1} \land \neg \phi_{2})) {\land} AF\phi_{2} 
\quad\ \   
\phi_1{\rightarrow} \phi_2 {\equiv} \neg \phi_{1} {\vee} \phi_{2}
\end{gather*} 
\vspace{-3mm}
\caption{Derivations for the rest CTL operators}
\label{fig:ctl-datalog-translation-table-deriv}
%\vspace{-1mm}
\end{figure}}

Taking the rule \code{[\CTLtoDKey\m{Neg}]} as an example, to produce the Datalog rules for a \code{\neg \phi} formula, it first generates the Datalog rules for \code{\phi}, denoted by \code{\drule^*}. Then it creates a new identifier \code{\nm_{\mathtt{new}}} to be ``\code{NOT\_}''\code{\concat p}, where the predicate \code{p} indicates the validity of \code{\phi}. 
And the top level rule for \code{\neg \phi} is written as \code{\drule^\prime{=}\nm_{\mathtt{new}}(S) \datalogarrow  \shortNeg\,  \nm(S).}
Finally, the predicate which indicate the validity of \code{\neg \phi} is \code{\nm_{\mathtt{new}}} and the reasoning rules are \code{\drule^* \concat [\drule^\prime]}. 
Another example is \code{[\CTLtoDKey\m{Disj}]}. 
To generate the Datalog rules for \code{\phi_1 \vee \phi_2}, it first generates the Datalog rules \code{\phi_1} and \code{\phi_2} separately, denoted by \code{ \drule^*_1} and \code{\drule^*_2}. 
Then it creates a new identifier \code{\nm_{\mathtt{new}}} to be 
\code{p_1\concat}``\code{\_OR\_}''\code{\concat p_2}, where the predicate \code{p_1} and \code{p_2} indicate the validity of \code{\phi_1} and \code{\phi_1} respectively. 
Finally, there are two rules generated for querying the disjunction, where either \code{\phi_1} holds or \code{\phi_2} holds. 


\begin{figure*}[!h]
\vspace{-3mm}
\small
\centering
\begin{gather*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% AP %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
[\CTLtoDKey\m{AP}]\\ 
\drule {=} \nm(S) \datalogarrow \pi(S).
\end{matrix}
}{\CTLToD{\nm,\pi}{\nm}{[\drule]}
}
\qquad 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Neg %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix} 
\CTLToD{\phi}{\nm}{\drule^*} 
\\  \nm_{\mathtt{new}} {=} ``NOT\_" \concat \nm \ \  \quad 
\drule^\prime {=} \nm_{\mathtt{new}}(S) \datalogarrow  \shortNeg\,  \nm(S). 
\end{matrix}
}{ 
\CTLToD{\neg\phi}{\nm_{\mathtt{new}}}{\drule^* \concat [\drule^\prime]}
} [\CTLtoDKey\m{Neg}]
\\[0.5em] 
{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% HIDEN Conj %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
  [\CTLtoDKey\m{Conj}] \\
\CTLToD{\phi_{1}}{\nm_{1}}{\drule^*_1} \quad 
\CTLToD{\phi_{2}}{\nm_{2}}{\drule^*_2}\\ 
\nm_{\mathtt{new}} {=} \nm_{1} \concat \ensuremath{``\_AND\_"} \concat \nm_{2}
 \\ 
\drule^* {=}  [\nm_{\mathtt{new}}(S) \datalogarrow   \nm_{1}(S),\nm_{2}(S).]
\end{matrix}
}{ 
\CTLToD{\phi_{1} \land \phi_{2} }{\nm_{\mathtt{new}}}{\drule^*_1 \concat \drule^*_2 \concat \drule^*}
    }
\quad 
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Disj %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
  [\CTLtoDKey\m{Disj}]\\
\CTLToD{\phi_{1}}{\nm_{1}}{\drule^*_1} \quad \CTLToD{\phi_{2}}{\nm_{2}}{\drule^*_2}\\ 
\nm_{\mathtt{new}} {=} \nm_{1} \concat \ensuremath{``\_OR\_"} \concat \nm_{2}
 \\  
\drule^* {=}  [\nm_{\mathtt{new}}(S) \datalogarrow \nm_{1}(S). \qquad \nm_{\mathtt{new}}(S) \datalogarrow \nm_{2}(S).]
\end{matrix}
}{ 
\CTLToD{\phi_{1} \lor \phi_{2} }{\nm_{\mathtt{new}}}{\drule^*_1 \concat \drule^*_2 \concat \drule^*}
} 
\\[0.5em] 
{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% hide EX %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
[\CTLtoDKey\m{EX}] \\
\CTLToD{\phi}{\nm}{\drule^*_1} \\   
\nm_{\mathtt{new}} {=}  ``EX\_" \concat \nm \\
\drule^* {=} \left[\nm_{\mathtt{new}}(S) \datalogarrow   \predFlow(S,S'), \ \nm(S'). \right]
\end{matrix}
}{\CTLToD{EX\,\phi}{\nm_{\mathtt{new}}}{\drule^*_1 \concat \drule^*}
}
\qquad
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% EF %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
\CTLToD{\phi}{\nm}{\drule^*_1} \quad  \nm_{\mathtt{new}} {=} ``EF\_" {\concat} \nm\\
\drule^* {=} \left[
\begin{matrix}
\nm_{\mathtt{new}}(S) \datalogarrow   \ \nm(S). \\
\nm_{\mathtt{new}}(S) \datalogarrow   \predFlow(S,S'), \nm_{\mathtt{new}}(S').
\end{matrix}
\right]
\end{matrix}
}{\CTLToD{EF\,\phi}{\nm_{\mathtt{new}}}{\drule^*_1 \concat \drule^*}
}[\CTLtoDKey\m{EF}] 
\\[0.5em] 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% AF %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
[\CTLtoDKey\m{AF}]\\
\CTLToD{\phi}{\nm}{\drule^*_1} \quad\   
\nm_{\mathtt{new}} {=} ``AF\_" \concat \nm \qquad   
\nm_{\mathtt{s}} {=} ``AFS\_" \concat \nm \qquad         
\nm_{\mathtt{t}} {=} ``AFT\_" \concat \nm
\\
\drule^* {=} 
    \left[\begin{matrix} 
        \nm_{\mathtt{t}}(S,S') {\datalogarrow} \shortNeg  \, \nm(S), \predFlow(S,S'). \qquad\nm_{\mathtt{t}}(S,S') {\datalogarrow}   \nm_{\mathtt{t}}(S,S''), \shortNeg  \ \nm(S''), \predFlow(S'',S'). \\
\nm_{\mathtt{s}}(S) \datalogarrow  \nm_{t}(S,S).
        \qquad  \nm_{\mathtt{s}}(S) \datalogarrow  \shortNeg \,  \nm(S) , \predFlow(S,S'), \nm_{\mathtt{s}}(S'). 
        \qquad 
        \nm_{\mathtt{new}}(S) \datalogarrow  \shortNeg \,  \nm_{\mathtt{s}}(S).
    \end{matrix} \right]
\end{matrix}
}{\CTLToD{AF\,\phi}{\nm_{\mathtt{new}}}{\drule^*_1 \concat \drule^*}
}
\\[0.5em] 
{\quad 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% hided EU %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frac{
\begin{matrix}
[\CTLtoDKey\m{EU}]\\
\CTLToD{\phi_{1}}{\nm_{1}}{\drule^*_1} \quad \CTLToD{\phi_{2}}{\nm_{2}}{\drule^*_2}\quad  
\nm_{\mathtt{new}} {=} \nm_{1} \concat \ensuremath{``\_EU\_"} \concat \nm_{2}\\ 
\drule^* {=}  
\left[ 
  \begin{matrix} 
    \nm_{\mathtt{new}}(S) \datalogarrow   \nm_{2}(S). \qquad 
    \nm_{\mathtt{new}}(S) \datalogarrow  \nm_{1}(S), \predFlow(S,S'), \nm_{\mathtt{new}}(S').
  \end{matrix} \right]
\end{matrix}
}{\CTLToD{E ( \phi_{1} \,U\, \phi_{2}) }{\nm_{\mathtt{new}}}{\drule^*_1 {\concat} \drule^*_2 {\concat} \drule^*}
}} 
\end{gather*}
\caption{A complete Datalog encoding for 
CTL formulas}
\label{fig:comlete_ctl-datalog-translation-table-ctl}
\end{figure*}


\begin{figure*}[!h]%{r}{0.65\textwidth}
{
\centering
\renewcommand{\arraystretch}{1.05}
$\begin{array}{lllll}
&[{\mathcal{S}}, {\bot}] \,{\centernot\longrightarrow}\ && \\
&\wreSemanticsmodel{\mathcal{S}}{\epsilon}{\mathcal{S}}{\epsilon}{[]} && \\
&\wreSemanticsmodel{\mathcal{S}}{\relation}{\mathcal{S}}{\epsilon}{[\relation]}  & & \\
&\wreSemanticsmodel{\mathcal{S}}{x{=}t}{\mathcal{S}^\prime}{\epsilon}{[]}  &\m{iff}& \mathcal{S}^\prime{=} 
\s{(x{=}t)} \cup (\mathcal{S}\text{\textbackslash} x)
\\
&\wreSemanticsmodel{\mathcal{S}}{[\pi]}{\mathcal{S}}{\epsilon}{[]}  &\m{iff}& \llbracket \pi\rrbracket_\mathcal{S} {=}\m{true} \\
&\wreSemanticsmodel{\mathcal{S}}{[\pi]}{\mathcal{S}}{\bot}{[]}  &\m{iff}& \llbracket \pi\rrbracket_\mathcal{S} {=}\m{false} \\
&\wreSemanticsmodel{\mathcal{S}}{\effect_1\cdot\effect_2}{\mathcal{S}^\prime}{\effect_1^\prime\cdot\effect_2}{\rho}  &\m{iff}&  
\wreSemanticsmodel{\mathcal{S}}{\effect_1}{\mathcal{S}^\prime}{\effect_1^\prime}{\rho}
\ \ \m{and} \ \  
\effect_1^\prime {\not=}\epsilon
\\
&\wreSemanticsmodel{\mathcal{S}}{\effect_1\cdot\effect_2}{\mathcal{S}^{\prime\prime}}{\effect_2^{\prime}}{\rho_1 {+}{+} \rho_2}  &\m{iff}&  
\wreSemanticsmodel{\mathcal{S}}{\effect_1}{\mathcal{S}^\prime}{\epsilon}{\rho_1}
\ \ \m{and} \ \  
\wreSemanticsmodel{\mathcal{S}^\prime}{\effect_2}{\mathcal{S}^{\prime\prime}}{\effect_2^\prime}{\rho_2}
\\
&\wreSemanticsmodel{\mathcal{S}}{\effect_1\vee\effect_2}{\mathcal{S}_3}{\effect^\prime}{\rho_3}  &\m{iff}&  
\wreSemanticsmodel{\mathcal{S}}{\effect_1}{\mathcal{S}_1}{\effect_1^\prime}{\rho_1}
\ \ \m{and} \ \  
\wreSemanticsmodel{\mathcal{S}}{\effect_2}{\mathcal{S}_2}{\effect_2^\prime}{\rho_2}
\\
&&&
(\mathcal{S}_3, \effect^\prime, \rho_3) \in \s{(\mathcal{S}_1, \effect_1^\prime, \rho_1). (\mathcal{S}_2, \effect_2^\prime, \rho_2)}
\\
&\wreSemanticsmodel{\mathcal{S}}{\effect^\omega}{\mathcal{S}^\prime}{\effect^\prime \cdot \effect^\omega}{\rho}  &\m{iff}&   
\wreSemanticsmodel{\mathcal{S}}{\effect}{\mathcal{S}^\prime}{\effect^\prime}{\rho}
\end{array}$
\caption{Semantics of Guarded $\omegaRE$}
\label{fig:emantics_of_Omega_RE}
}
\end{figure*}



\section{Semantics of Guarded $\omegaRE$}
\label{appsec:Semantics_wre}


\figref{fig:emantics_of_Omega_RE} defines a model relation  
$\wreSemanticsmodel{\mathcal{S}}{\effect}{\mathcal{S}^\prime}{\effect^\prime}{\rho}$ for our guarded $\omegaRE$. Here, $\mathcal{S}$ represents a stack, updated when there are (re-)assignments; and 
$\rho$ is a sequence of events, represented using abstract predicates. 
We use notation \code{\llbracket \pi\rrbracket_\mathcal{S}} to mean the valuation of constraint \code{\pi} upon the concrete stack \code{\mathcal{S}}. 



\section{The \textsc{existsCycle} function}
\label{appsec:existsCycle}


% {\begin{algorithm}[H]
% \caption{\textsc{existsCycle}}\label{alg:existsCycle}
% \begin{algorithmic}[1]
% \Require N, $\E$
% \Ensure {($\effect_{\m{repeat}}$, N$_{\m{nonCycleSucc}}$) option}
% \Switch{$\E$(N)} 
% \Case {[N$_{\m{false}}$\,;\,N$_{\m{true}}$] $\rightarrow$}  
% {\Switch{\textsc{detectCycle} (N$_{\m{true}}$, N)} 
% \Case{(\_,  false) $\rightarrow$}  \Return{None}
% \EndCase 
% \Case{($\effect_{\m{repeat}}$, true) $\rightarrow$}  
% \Return{Some($\effect_{\m{repeat}}$, N$_{\m{false}}$)}
% \EndCase 
% \EndSwitch}
% \EndCase 
% \Case{\_ $\rightarrow$} \Return{None}
% \EndCase 
% \EndSwitch
% \STATE
% \Function{{{detectCycle }}}{N, N$_{\m{join}}$}  
% \If{N=N$_{\m{join}}$} \Return{($\epsilon$, true)}
% \Else 
% \Switch{N} 
% \Case {$\m{Join(s)}$ $\rightarrow$}  
% {\Switch{\textsc{existsCycle} (N)} 
% \Case{None $\rightarrow$ }  {\textsc{moveForwardAux} (N)}
% \EndCase 
% \Case{Some ($\effect_{\m{repeat}}$, N$_{\m{f}}$) $\rightarrow$}  
% \STATE{$\effect_{\m{nonCycle}}$ = \textsc{moveForwardAux} (N$_{\m{f}}$, N$_{\m{join}}$)} 
% \STATE{$\effect_{\m{sum}} = \loopsummary~(\effect_{\m{repeat}},\effect_{\m{f}})$}
% \\
% \hspace{33pt} 
% \Return{($\effect_{\m{nonCycle}} \vee \effect_{\m{sum}}$, false)}%
% \EndCase 
% \EndSwitch}
% \EndCase 
% \Case{\_ $\rightarrow$} \textsc{moveForwardAux} (N, N$_{\m{join}}$)
% \EndCase 
% \EndSwitch
% \EndIf 
% \EndFunction
% \STATE
% \Function{{{moveForwardAux }}}{N, N$_{\m{join}}$}  
% \If{$\E$(N)=[]} \Return{($\nodeEv$(N), false)}
% \Else 
% \STATE{\textcolor{white}{....}$\effect_{\m{acc}}$ = $\bot$ ~;~ $B_{\m{acc}}$ = false}
% \ForEach {N$^\prime$ $\in$ $\E$(N)}
% \STATE{\hspace{15pt} ($\effect_{N'}$, B)  = \textsc{detectCycle} (N$^\prime$, N$_{\m{join}}$) }
% \STATE{\hspace{15pt}  $\effect_{\m{acc}}$ {=} $\effect_{\m{acc}}$ \,{$\vee$}\,  $\effect_{N'}$ ~;~ $B_{\m{acc}}$ = $B_{\m{acc}} ||$  $B$}
% \EndFor
% \\ \hspace{19pt} \Return{($\effect_{\m{acc}}$, $B_{\m{acc}}$)}
% \EndIf 
% \EndFunction
% \end{algorithmic}
% \end{algorithm}
% }

As shown in \algoref{alg:existsCycle}, \textsc{existsCycle}  
returns None if none of its successors leads to cycles; otherwise, it returns Some ($\effect_{\m{repeat}}$, $N_{\m{false}}$),  indicating that one successor of $N$ leads to a path that comes back to itself, and $\effect_{\m{repeat}}$ describes the behavior of the cycle body, 
and $N_{\m{false}}$ is the other successor, which does not directly lead to a cycle. 
The function \textsc{detectCycle} takes a node and a join node, which marks the position where the branches were diverged.
If it reaches the same join node by walking through the successors, then there exists a cycle. Otherwise, it continues to iterate the rest of the successors, and if, when reaching the end of the CFG, it never comes back to the join node, it returns false. 

\hide{As shown in \algoref{alg:moveForward},  if there are no successors, \textsc{Moveforward} terminates with the effects of the current node \code{\nodeEv}(N); otherwise, it 
goes through successors and applies \textsc{CFG2GWRE} 
to calculate the formulas for the remainder of the path. It then disjunctively combines the outcomes. 

{\begin{algorithm}[H]
\caption{\textsc{moveForward}}\label{alg:moveForward}
\begin{algorithmic}[1]
\Function{{{moveForward}}}{\code{N, \E}} 
\If{\code{\E}(N)=[]} \Return{\code{\nodeEv}(N)}
\Else\ \ \code{\effect_{\m{acc}}} = \code{\bot}
\ForEach {\code{N^\prime\in\E}(N)}
\STATE{\qquad \code{\effect_{\m{acc}}} {=} \code{\effect_{\m{acc}}} \,{\code{\vee}}\,  \textsc{CFG2GWRE} (\code{N^\prime}, \code{\E}) }
\EndFor
\\ 
\hspace{20pt} \Return{(\code{\nodeEv(N)} \code{\cdot~ \effect_{\m{acc}}})}
\EndIf 
\EndFunction
\end{algorithmic}
\end{algorithm}}}

\section{The soundness of the candidate ranking function generation process}
\label{app:soundlyChoosingRF}

{
\begin{definition}[Soundly generating Simple LRFs from Pure]
  \label{def:rankingFunction1}
  \input{guessingLRFs}
\end{definition}
\vspace{-3mm}
}

\begin{theorem}[Soundness of the generation of ranking functions]
If the generated ranking function, from \defref{def:rankingFunction1} is decreasing at each iteration of the loop, the loop does terminate. 
\begin{proof} 
By case analysis upon the loop guards: 
\begin{enumerate}
\item When \code{\pi{=} (t_1{\geq}t_2)}, and \code{\m{rf}{=}t_1\text{-}t_2}: to enter the loop, the state must satisfy \code{\m{rf}{\geq}0}, if \code{\m{rf}} is deceasing at each iteration, it will finally reach the state \code{\m{rf}{<}0}, \ie  
\code{t_1\text{-}t_2{<}0}, which no longer satisfy the loop guard; thus, the loop is terminating. 
\item When \code{\pi{=} (t_1{\leq}t_2)}, and \code{\m{rf}{=}t_2\text{-}t_1}: similar to (1). 

\item When \code{\pi{=} (t_1{>}t_2)}, and \code{\m{rf}{=}t_1\text{-}t_2\text{-}1}: to enter the loop, the state must satisfy \code{\m{rf}{\geq}0}, if \code{\m{rf}} is deceasing at each iteration, it will finally reach the state \code{\m{rf}{<}0}, \ie  
\code{t_1\text{-}t_2\text{-}1{<}0}, or \code{t_1{\leq}t_2},  which no longer satisfy the loop guard; thus, the loop is terminating. 

\item When \code{\pi{=} (t_1{<}t_2)}, and \code{\m{rf}{=}t_2\text{-}t_1\text{-}1}: similar to (3). 

\item When \code{\pi{=} (t_1{\not=}t_2)}, and 
\code{\m{rf}\in \s{(t_1\text{-}t_2\text{-}1); (t_2\text{-}t_1\text{-}1)}}: 
to enter the loop, the state must satisfy \code{t_1{\not=}t_2}, 
the exit condition of a loop with such a guard \code{\pi} is either (\code{t_1{\geq}t_2}) or (\code{t_1{\leq}t_2}); then if either the candidate ranking function is decreasing, it will reach either of the 
exit conditions and fall into cases (3) or (4); thus, the loop is terminating. 

\item When \code{\pi{=} (\pi_1\,{\wedge}\,\pi_2)}, and \code{\m{rf}\in \RF(\pi_1) \,{\cup}\, \RF(\pi_2)}: Similar to (5), the exit condition of a loop is either (\code{\neg\pi_1}) or (\code{\neg\pi_2}); then if any candidate ranking function is decreasing, it will reach either of the exit conditions; thus, the loop is terminating. 


\item When \code{\pi{=} (t_1{=}t_2)}, and \code{\m{rf}\in \s{(t_1\text{-}t_2); (t_2\text{-}t_1)}}: to enter the loop, the state must satisfy \code{t_1{=}t_2}, 
the exit condition of a loop with such a guard \code{\pi} is either (\code{t_1{>}t_2}) or (\code{t_1{<}t_2}); then if either the candidate ranking function is decreasing, it will reach either of the 
exit conditions and fall into cases (1) or (2); thus, the loop is terminating. 
\end{enumerate}
\end{proof}
\end{theorem}


\begin{wrapfigure}{R}{0.3\columnwidth}
\begin{lstlisting}[xleftmargin=0.5em,numbersep=6pt,basicstyle=\footnotesize\ttfamily]
(*@\textcolor{mGray}{//$AF(\m{Exit}())$}@*)
int m, n; int step=8; 
while (1) {
  m = 0;
  while (m < step){
    if (n<0) return; 
    else {
      m = m + 1;
      n = n - 1;}}}
\end{lstlisting} 
\caption{A terminating loop} 
\label{fig:Termination_analysis_without_the_tears}
\end{wrapfigure}


\paragraph*{\textbf{Precise Loop Summaries}} 
\label{sec:example:Infinite_Loops_1}

Existing loop summarization techniques \cite{DBLP:conf/tacas/TsitovichSWK11,DBLP:journals/tse/XieCZLLL19,DBLP:conf/sigsoft/XieCZLLL17} usually build on top of the invariants of the terminating loops, thus do not explicitly capture non-terminating behaviors. 
We aim to summarize both possibilities and show the benefits of such an innovation via the nested loops in \figref{fig:Termination_analysis_without_the_tears}, where we would like to prove termination. 
The outer loop is structurally non-terminating, and the inner loop terminates by either only exiting itself or completely exiting the program. 
\toolName initially represents the inner loop using the following cases \code{(1)\text{-}(3)}, where \code{[\pi]} denotes a guard upon a pure constraint, \code{\epsilon} is an empty trace, \code{m', n'} stand for the updated \code{m, n} after each iteration and \code{\star} stands for unknown number of repetition.

% \begin{wrapfigure}{R}{0.42\columnwidth}
% \begin{lstlisting}[xleftmargin=0.5em,numbersep=6pt,basicstyle=\footnotesize\ttfamily]
% (*@\textcolor{mGray}{//$AF(\m{Exit}())$}@*)
% int m, n; int step=8; 
% while (1) {
% m = 0;
% while (m < step){
% if (n<0) return; 
% else {
% m = m + 1;
% n = n - 1;}}}
% \end{lstlisting} 
% \caption{A terminating loop} 
% \label{fig:Termination_analysis_without_the_tears}
% \end{wrapfigure}

\code{\begin{cases}
[\m{m} {\geq} \m{step}]\cdot \epsilon
~\vee~& (1) \\
[\m{m} {<} \m{step} \wedge \m{n}{<}0]\cdot \m{Exit}() ~\vee~ & (2) \\ 
([\m{m} {<} \m{step} \wedge \m{n}{\geq}0] 
\cdot (m'{=}m{+}1) \cdot (n'{=}n\text{-}1))^\star 
&(3)
\end{cases}}
\\[0.2em]
Since (1) and (2) are terminating cases, our loop summary calculus obtains two decreasing \emph{ranking functions}: 
%\footnote{A \emph{ranking function} \cite{DBLP:journals/x/Turing37} is non-negative and decreases at each iteration. We generate candidate ranking functions based on \defref{def:rankingFunction}.}: 
\code{\m{step}\text{-}m\text{-}1} and \code{n} from the loop guard of (3), \ie\code{[\m{m} {<} \m{step} \wedge \m{n}{\geq}0]}.

Given these two ranking functions decrease in the same speed, i,e, \code{m'{=}m{+}1} and \code{n'{=}n\text{-}1}, we summarise the inner loop using a disjunction, depending on which is larger at the entry point: 
\\
\code{\effect_{\m{inner}}}{$\equiv$} 
\code{\begin{cases}
[(\m{step}\text{-}m\text{-}1) {\geq} n]\cdot (n'{<}0)\cdot \m{Exit}() ~\vee~\\
[(\m{step}\text{-}m\text{-}1) {<} n] \cdot (m'{\geq}\m{step})\cdot (n'{=}n \text{-} (\m{step}\text{-}m))\end{cases}}
\\[0.2em]
Next, combining with line 3 and 4, \ie with \code{m{=}0} instantiated, the outer loop is initially represented as follows: 
\\[0.2em] 
\code{\begin{cases}
[(\m{step}\text{-}1) \,{\geq}\, n]\cdot (n'{<}0)\cdot \m{Exit}()
~\vee~ & (4) \\
([(\m{step}\text{-}1) \,{<}\, n] \cdot (m'{\geq}\m{step})\cdot (n'{=}n \text{-} \m{step}))^\star & (5)
\end{cases}
}

Now, the loop summary calculus once again obtains the possible ranking function \code{\m{rf}{=}n\text{-}\m{step}}, from the 
guard of the repetitive case (5), \ie
\code{[(\m{step}\text{-}1) \,{<}\, n]}. 
To compute the termination condition \wrt \code{\m{rf}}, we obtain:
\code{\pi_{\m{wpc}} \,{=}\,\m{rf}\text{-}\m{rf}'{\geq}1}, as \code{\m{rf}}'s value has to decrease at least 1 in each iteration. 
Then, 
\code{\pi_{\m{wpc}}} is reduced to 
\code{(n\text{-}\m{step})\text{-}(n'\text{-}\m{step}) {\geq}1}, and finally 
\code{\pi_{\m{wpc}} {=} \m{step} {\geq} 1}. Thus the final summary of the outer loop is: 
\\[0.2em] 
{
\code{\effect_{\m{outer}}}{$\equiv$} 
\code{%\begin{cases}
[\m{step} {\geq} 1] \cdot (n'{<}0)\cdot \m{Exit}() 
~\vee~ %\\
([\m{step} {<} 1] \cdot (m'{\geq}\m{step}))^\omega
}
}
\\[0.2em] 
indicating that when \code{\m{step}{\geq}1} the nested loop always terminates; and \toolName proves {termination} since \code{\m{step}} is assigned to 8 prior to the loop, satisfying \code{\pi_{\m{wpc}}}. 
More importantly, with this summary, we can prove more properties beyond termination, such as `\code{\m{step}{\geq}1{\rightarrow} \m{AF}(n{<}0)}' or `\code{\m{step}{<}1{\rightarrow} \m{AG}(m{\geq}\m{step})}', etc. 

Intuitively, loops are handled by iteratively computing the guarded terminating and repetitive cases. Candidate ranking functions can then be discovered from the guards of the repetitive cases. 
\toolName next obtains a termination condition \wrt the candidate ranking function, and constructs the final loop summary with the termination condition. 
%We formalize the termination condition calculation in \secref{subsec:loop2wRE}. 

%dividing the loop body behaviors into \emph{leaking} paths and \emph{non-leaking} paths. Statements like \emph{break}, \emph{return}, or non-terminating behaviors would interrupt the loop cycle; thus, they lead to leaking paths, as opposed to the others, such as \emph{continue}, which stay in non-leaking paths.
%\toolName could look for possible ranking functions from the (negated) guards in leaking paths, here the first path of $\effect_{4\text{-}9} $. 






Multiphase ranking functions (M$\effect$RFs) \cite{DBLP:conf/cav/Ben-AmramG17} were proposed as a means to prove the termination of a loop in which the computation progresses through a number of ``phases'', and the progress of each phase is described by a different linear
ranking function. 
Using the first example, shown in \figref{fig:multiphase}, 
we illustrate how are loops with M$\effect$RFs handled in our approach. 
We obtain the initial representation of this loop to be:

\begin{center}
\code{\begin{cases}
[x{<}0] \cdot \epsilon
\\
([x{\geq}0] \cdot (x'{=}x\text{-}y) 
\cdot (y'{=}y{+}1))^\star
\end{cases}}
\end{center}

Next, we generate the candidate ranking function \code{x} from the guard of the receptive case \code{[x{\geq}0]}. 
Thus, we compute the weakest precondition for termination \wrt \code{x}: 
\code{\pi_{\m{wpc}}{=}x\text{-}x'{\geq}1}, reduced to 
\code{x\text{-}(x\text{-}y){\geq}1}, and finally \code{\pi_{\m{wpc}}{=}y{\geq}1}. 
Next, we generate a summary for the loop: 

\begin{center}
\code{\effect_{2\text{-}5} \equiv}
\code{\begin{cases}
[y{\geq}1] \cdot \epsilon
\\
([y{<}1] \cdot (y'{=}y{+}1))^\star
\end{cases}}
\end{center}


Here, when looking at this summary, we find that there exists another candidate ranking function \code{\text{-}y}, from the guard of the repetitive case, \ie  \code{[y{<}1]}. 
Therefore, we compute the weakest precondition for termination \wrt \code{\text{-}y}:  
\code{\pi^\prime_{\m{wpc}}{=}(\text{-}y)\text{-}(\text{-}(y{+}1)){\geq}1}, reduced to \code{(\text{-}y){+}y{+}1{\geq}1}, and finally 
\code{\pi^\prime_{\m{wpc}}{=}T}. 
Up to this point, we have proved that the with a \code{T} precondition, the loop terminates, \ie  the loop always terminates. 
%In fact, in this example, there are two phases of ranking function, denoted by \code{\langle \text{-}y, x \rangle}. 


\begin{wrapfigure}{R}{0.3\columnwidth}
\vspace{-8mm}
\begin{lstlisting}[xleftmargin=0.5em,numbersep=6pt,basicstyle=\footnotesize\ttfamily]
(*@\textcolor{mGray}{//$AF(\m{Exit}())$}@*) 
while(x>=-z){
  x=x+y;
  y=y+z;
  z=z-1; }
\end{lstlisting} 
\vspace{-1mm}
\caption{M$\effect$RF 2} 
\label{fig:multiphase_ex2}
\vspace{-5mm}
\end{wrapfigure}

The second example, shown in  \figref{fig:multiphase_ex2} is drawn from the prior work \cite{DBLP:conf/cav/Ben-AmramG17}. 
We obtain the initial representation of this loop to be: 


{
~\\
\code{\begin{cases}
[x{<}\text{-}z] \cdot \epsilon
\\
([x{\geq}\text{-}z] \cdot (x'{=}x{+}y)\cdot
(y'{=}y{+}z)\cdot
(z'{=}z\text{-}1))^\star
\end{cases}}
\\
}

Next, we generate the candidate ranking function \code{x{+}z} from the guard of the receptive case \code{[x{\geq}\text{-}z]}. 
Thus, we compute the weakest precondition for termination \wrt \code{x{+}z}: 
\code{\pi_{\m{wpc}}{=}(x{+}z)\text{-}(x'{+}z'){\geq}1}, reduced to 
\code{(x{+}z)\text{-}((x+y){+}(z\text{-}1)){\geq}1}, and finally \code{\pi_{\m{wpc}}{=}y{\leq}0}. 

Next, we generate the first summary for the loop: 

\begin{center}
\code{\effect_{2\text{-}6} \equiv}
\code{\begin{cases}
[y{\leq}0] \cdot \epsilon
\\
([y{>}0] \cdot (y'{=}y{+}z))^\star
\end{cases}}
\end{center}

Here, when looking at this summary, we find that there exists another candidate ranking function \code{y\text{-}1}, from the guard of the repetitive case, \ie  \code{[y{>}0]}. 
Therefore, we compute the weakest precondition for termination \wrt \code{y\text{-}1}:   
\code{\pi^\prime_{\m{wpc}}{=}(y\text{-}1)\text{-}(y{+}z\text{-}1){\geq}1}, reduced to 
\code{\pi^\prime_{\m{wpc}}{=}z{\leq}1}. 
Next, we generate the second summary for the loop: 

\begin{center}
\code{\effect_{2\text{-}6} \equiv}
\code{\begin{cases}
[z{\leq}1] \cdot \epsilon
\\
([z{>}1] \cdot (z'{=}z\text{-}1))^\star
\end{cases}}
\end{center}

Here, when looking at this summary, we find that there exists another candidate ranking function \code{z\text{-}2}, from the guard of the repetitive case, \ie  \code{[z{>}1]}. 
Therefore, we compute the weakest precondition for termination \wrt \code{z\text{-}2}:   
\code{\pi^{\prime\prime}_{\m{wpc}}{=}(z\text{-}2)\text{-}((z\text{-}1)\text{-}2){\geq}1}, reduced to 
\code{\pi^{\prime\prime}_{\m{wpc}}{=}T}. 
Up to this point, we have proved that the with a \code{T} precondition, the loop terminates, \ie  the loop always terminates.  


\section{Get Predicates from $\effect$ and $\phi$}


We use \code{\m{Pure}(\effect)}, defined in \defref{def:getPure_effect}, to extract the predicates from the guards in \code{\effect}, and use 
\code{\m{Pure}(\phi)}, defined in \defref{def:getPure_CTL},  to extract the atomic propositions in \code{\phi}. 
In total, they gather all the abstract predicates that of interest in the analysis. 

{\begin{definition}[Get Predicates from $\effect$]
  \label{def:getPure_effect}
Given any Guarded $\omegaRE$ formula \code{\effect}, 
we define: 
{\small
\begin{gather*}
\getPure{(\bot)} {\getPureop} \getPure{(\epsilon)} {\getPureop}
\getPure{(\pi_s)} {\getPureop}\emptyset
\qquad \qquad 
\getPure{([\pi]_s)} {\getPureop}\s{\pi} 
\\ 
\getPure{(\effect^\omega)} {\getPureop} \getPure{(\effect)}
\\
\getPure{(\effect_1 \cdot \effect_2)} {\getPureop}
\getPure{(\effect_1 \vee \effect_2)} {\getPureop}
\getPure{(\effect_1)} \cup \getPure{(\effect_2)}
\\[-0.9em]
\end{gather*}
}
\end{definition}
}
{\begin{definition}[Get Predicates from $\phi$]
  \label{def:getPure_CTL}
Given any core CTL formula \code{\phi}, 
we define: 
{\small
\begin{gather*}
\getPure{((nm, \pi))} = \s{\pi} 
\\
\getPure{(\neg\phi)}{=}  
\getPure{(EX\,\phi)}{=}\getPure{(EF\,\phi)}{=}\getPure{(AF\,\phi)} = \getPure(\phi)  
\\   
\getPure{(E(\phi_1 \,U\, \phi_2))}  = \getPure(\phi_1) \cup  \getPure(\phi_2)
\\   
\getPure{(\phi_1 \wedge \phi_2)}{=}\getPure{(\phi_1 \vee \phi_2)} = \getPure(\phi_1) \cup  \getPure(\phi_2)
\\[-0.9em]
\end{gather*}
}
\end{definition}
}




\section{Repair Correctness}
% The repair is sound, as any patch produced by \toolName ensures the target property holds, guarded by the ASP solver. 
% Additionally, the repair is complete -- \toolName guarantees finding a correct patch if it can be formed by instantiating the given symbolic constants and signs.
% The completeness consists of two aspects: (I) the domain calculation for symbolic constants, and (II) the truth assignment of symbolic signs. 
% For (II), our approach ensures identifying all assignments due to the completeness of the ASP solver we rely on~\cite{gebser2014clingo}.
% Now, we present the proof for (I).


% For (I), we present the definition and lemmas needed for proving that the computed domain of a symbolic constant over-approximates its exact domain. The complete proof can be found in~\cite{tech_report}.

% initially, in round 0, the dependent constants computed by the first and second constraints in \figref{fig:depend} are the exact constants of the variable $v$ at $(p, i)$ take during Datalog evaluation.
% In the step case, consider round i. 
% As an induction hypothesis, assume that in round i-1, the dependent constants of $v$ over-approximate its exact constants.
% In round i, according to the third constraint, the dependent constants of $v$ are the union of the set of dependent constants of the identical $v$ computed at i-1 round in the positive body literals.
% In Datalog semantics, the exact constants of $v$ at round i is the intersection of the exact constants of the identical $v$ in the positive literals of the rule body, minus those in the negative literals at round i-1.
% Thus, the computed dependent constants of $v$ at round i are a superset of its exact constants.
% \hfill \qed


% Thus, the dependent constants computed via the method in \secref{sec:sym_const} over-approximate the exact constants a symbolic constant can take during Datalog evaluation for generating output facts. 


% In Datalog semantics, the exact constants of a variable in $\relation$ is the intersection of the exact constants of the identical variables in the positive literals of the rule body, minus those in the negative literals. 
% In contrast, the third constraint computes the dependent constants of a variable in $\relation$ by taking the union of the constants that its identical variables in positive literals of the body depend on.
% The dependent constants from the first two constraints are the exact constants. 
% Thus, the dependent constants for a variable in $\relation$ over-approximate the exact constants it can take during Datalog evaluation.

% This semantics is referred to as the \emph{negation as failure}~\cite{clark1977negation}.

% \begin{theorem}[Repair Soundness]
% Any patch produced by \SymlogPlus makes the target (safety) property hold. 
% \end{theorem}

% \noindent\paragraph{\textbf{Correctness Discussion.}} %



The repair is sound, as any patch produced by \toolName inherently makes the target property hold, guarded by the ASP solver.  
Moreover, the repair is complete -- if a correct patch can be formed by instantiating given symbolic constants and signs, then our approach ensures to find this patch. 
%that this patch can be found.
The completeness is formed from two aspects: (I) the domain calculation for symbolic constants is complete, and (II) the truth assignment of symbolic signs is complete. 
The completeness of (I) is formulated in \theoref{theom:Completenessofthedomaincalculation}, which proves that the computed domains for symbolic constants are over-approximations of the exact domains. 
Regarding the completeness of (II), our approach ensures that all assignments are identified because the ASP solver we rely on is complete ~\cite{gebser2014clingo}.

\begin{figure}[!h]
  
  \begin{alignat*}{2}
    &p(..., c_i, ...) \in \mathcal{E} \Rightarrow \mathrm{depend}(p, i, c_i^\prime)  
    &&\, [D1]\\
    &\relation \datalogarrow \,..., p(..., c_i, ...), .... \in \drule^{*}_{\m{pos}} \Rightarrow \mathrm{depend}(p, i, c_i) 
    &&\, [D2]\\
    &\relation \datalogarrow\,..., p_1(..., X_i, ...), ..., p_2(..., X_j, ...), .... \in \drule^{*}_{\m{pos}}, X_i \equiv X_j 
    \; \Rightarrow \forall c.\,\mathrm{depend}(p_1, i, c) \Leftrightarrow \mathrm{depend}(p_2, j, c) 
    &&\, [D3]
\end{alignat*}
  
  \caption{The  ``\code{\mathrm{depend}}'' relation, where 
  %\code{\SE} is the symbolic EDB, 
  \code{c_i} and \code{X_i} are constants and variables appearing as the i-th parameter in a predicate. \code{X_i \equiv X_j} denotes that \code{X_i} and \code{X_j} are identical variables. 
  \label{fig:depend}}
\end{figure}

 
\begin{alignat*}{2}
 \mathrm{unifiable}(\alpha) & \triangleq  \bigcup_{(p, i)\in \m{loc}(\alpha)} \{\,c\,|\,\mathrm{depend}(p, i, c)\,\}  
 &&\, \m{[Dom]} \\
% \label{eq:domain_union}
\m{where }\ \,  \m{loc}(\alpha) & = \{(p_i,  i) \mid X_i \equiv X_{j}, 
\relation \datalogarrow  ..., p_i(..., X_i, ...), ..., 
p_j(..., X_{j}, ...),... \in \drule^{*}_{\m{pos}} \}
\end{alignat*}


% \syh{Notes for the completeness proof:} 
We define the \emph{exact domain} in \defref{def:exact_domain}, where $domain(X^*, \relation, \Datalog)$ captures all the instantiation of $X^*$, that can output instances of the predicate $\relation$. 

\begin{definition}[Exact Domain]
\label{def:exact_domain}
Given any Datalog program $\Datalog$, which contains a  
Datalog rule in a generalised form: $\drule=\relation_0{\datalogarrow}\relation_1,\dots,\relation_n, 
!\relation_{n+1}, \dots, !\relation_m$, 
let $\mathcal{J}$ be all the possible facts that can be derived from $\Datalog$, \ie  the union of IDB and EDB, and let $X^*$ be all the variables occurring in $\drule$, we define the exact domain of $X^*$ \wrt $\drule$ as follows: (where $\theta{=}[c^*/X^*]$ stands for each substitution)
\begin{align*}
\exactDoamin(X^*, \relation_0, \Datalog) =
\{c^* \mid~  & 
\relation_1\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge 
\relation_n\theta{\,\in\,}\mathcal{J} \,\wedge  
\relation_{n{+}1}\theta{\,\not\in\,}\mathcal{J} 
\wedge \dots \wedge 
\relation_m\theta{\,\not\in\,}\mathcal{J}\}. 
\end{align*}
\end{definition}


\begin{lemma} \label{lemma:negation_over_approx}
Given any Datalog program $\Datalog$, which contains rules:  
%$\drule$ and $\drule_{\m{pos}}$, 
%where \\
$\drule{=}\ \relation_0{\datalogarrow}\relation_1,\dots,\relation_n, 
!\relation_{n+1}, \dots, !\relation_m$ and 
$\drule_{\m{pos}}{=}\ \relation_0^+{\datalogarrow}\relation_1,\dots,\relation_n$, 
let $X^*$ be all the variables occurring in $\drule$ and $\drule_{\m{pos}}$, 
the exact domain of $X^*$ \wrt $\drule$ is a subset of the exact domain of $X^*$ \wrt $\drule_{\m{pos}}$, \ie  
$\exactDoamin\m{(X^*, \relation_0, \Datalog)} {\,\subseteq\,} \exactDoamin\m{(X^*, \relation_0^+, \Datalog)}$.
{
\small
\begin{proof}
Based on \defref{def:exact_domain}, we obtain: 
\\[-1em]
\begin{align*}
\exactDoamin\m{(X^*, \relation_0, \Datalog)} =
\m{
\{c^* \mid~ 
}
&\m{ 
\relation_1\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge 
\relation_n\theta{\,\in\,}\mathcal{J} \wedge \relation_{n{+}1}\theta{\,\not\in\,}\mathcal{J} 
\wedge \dots \wedge 
\relation_m\theta{\,\not\in\,}\mathcal{J}
\}
}
\end{align*}
\vspace{-8mm}

\begin{align*}
\exactDoamin\m{(X^*, \relation_0^+, \Datalog)} &=
\m{
\{c^* \mid 
\relation_1\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge 
\relation_n\theta{\,\in\,}\mathcal{J} 
\}
}
\end{align*}

Let $\mathcal{C}_1{\,=\,}\s{c^*\mid \relation_1\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge 
\relation_n\theta{\,\in\,}\mathcal{J}}$ and $\mathcal{C}_2{\,=\,}\s{c^*\mid \relation_{n{+}1}\theta{\,\not\in\,}\mathcal{J} 
\wedge \dots \wedge 
\relation_m\theta{\,\not\in\,}\mathcal{J}}$,  
then 
$\exactDoamin\m{(X^*, \relation_0, \Datalog)}$\\
${\,=\,}\mathcal{C}_1 \cap  \mathcal{C}_2 $ and 
$\exactDoamin\m{(X^*, \relation_0^+, \Datalog)}{\,=\,} \mathcal{C}_1 $, 
since $\mathcal{C}_1 \cap  \mathcal{C}_2  \subseteq \mathcal{C}_1 $; thus $\exactDoamin\m{(X^*, \relation_0, \Datalog)} {\,\subseteq\,} \exactDoamin\m{(X^*, \relation_0^+, \Datalog)}$. 
% \begin{comment}
% Now, we explain why the domains of the Datalog program, with all negative literals removed, are supersets of those in the original stratified Datalog program. 
% Let $\Datalog$ represent the original Datalog program with stratified negations, and $\Datalog^{+}$ represent the corresponding new Datalog program with all negative literals removed. 
% $\Datalog^{+}$ will produce at least as many output facts that $\Datalog$ could produce. 
% The reason is that for the same output fact, $\Datalog^+$ requires fewer facts to generate it.
% Consequently, the set of constants in $\Datalog^{+}$'s output is a superset of the set of constants in $\Datalog$'s output; 
% thereby there are more constants for each \code{\alpha} to unify with in $\Datalog^+$. 
% Formally: 
% Based on \defref{def:exact_domain}, we can obtain that 
% $\m{domain(\alpha, \drule^*) = 
% domain(\alpha, \drule^*_{\m{pos}})
% }$
% \end{comment}
\end{proof}}
\end{lemma}


\begin{lemma} 
\label{lemma:reasoning_over_approx}
Given any positive Datalog program $\Datalog^+$, which contains a top level rule $\drule_{\m{pos}}{=}\ \relation_0^+{\datalogarrow}\relation_1,\dots,\relation_n$, and the target predicate is $\relation_0$, the computed domain of $X^*$ is a superset of the exact domain of $X^*$, namely: 
$\exactDoamin(X^*, \relation_0^+, \Datalog^+) \subseteq \computedDoamin(X^*, \relation_0^+, \Datalog^+)$. 
{
\small
\begin{proof}
Given any $\drule_{\m{pos}}$ and \code{\SE}, the logical semantics of \figref{fig:depend} can be represented by the 
predicate \code{\m{dep\_p}}, where \code{\relation{=}p(X^*)}, \ie  $p$ is the relation name of $R$. 
Moreover, we use 
\code{\Datalog^+_{dep}} to denote the rules which generates all the facts \code{\m{dep\_p}}.  

{
\small
\begin{align*}
\frac{
p(c^*) \in \mathcal{E} 
}{
dep\_{p}(c^*)  
} \m{[Sem\text{-}D1]}
\quad 
\frac{
\relation \datalogarrow \,..., p(..., c_i, ...), .... \in \drule^{*}_{\m{pos}} 
}{
dep\_{p}(..., c_i,...) 
} \m{[Sem\text{-}D2]}
\\
\frac{
\begin{matrix}
{p_0}(X^*) \datalogarrow {p_1}(X^*),..., {p_n}(X^*) \in \drule^{*}_{\m{pos}} 
\\
dep\_{p_1}(X^*) \vee ... \vee dep\_{p_n}(X^*)
\end{matrix}
}{
dep\_{p_0}(X^*) 
} \m{[Sem\text{-}D3]}
\end{align*}}


% {\begin{align*}
%     & dep\_{p_0}(X^*) \leftarrow dep\_{p_1}(X^*) \vee,..., \vee dep\_{p_n}(X^*) \\
%     & dep\_{p}(..., c_i,...) \leftarrow p(..., c_i,...), \relation \datalogarrow \,..., p(..., c_i, ...), .... \in \drule^{*}_{\m{pos}} \in \drule_{\m{pos}}^* \\
%     & dep\_{p}(c^*) \leftarrow p(c^*) \in \mathcal{E} 
% \end{align*}}


According to the semantics of Datalog, $\mathcal{J}$ is obtained via a fixed-point computation:

\begin{align*}
   \mathcal{J} =  \mathcal{J}^{(N)} = T_{\Datalog^+}(\mathcal{J}^{(N-1)}) = T_{\Datalog^+}(T_{\Datalog^+}(\mathcal{J}^{(N\text{-}2)})) = \dots
\end{align*}

\noindent where $T_{\Datalog^+}$ is the \emph{immediate consequence operator}~\cite{DBLP:books/aw/AbiteboulHV95} of $\Datalog^+$ and the fixpoint is reached after at most $N$ steps.
Let $\mathcal{J}_{dep}$ denotes all the possible facts that can be derived from the $dep$ rules, and let $\mathcal{J}_{dep}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n]$ denote the facts with all relation names $dep\_{p_i}$ replaced with $p_i$. 

\noindent
\textbf{Base case:} 
At step 0, 
%according to the Datalog semantics, we have:
\begin{align*}
    \mathcal{J}^{(0)} = &\{p(c^*) \mid p(c^*) \in \mathcal{E} \} \\
    \mathcal{J}_{dep}^{(0)} = &\{dep\_{p}(c^*) \mid p(c^*) \in \mathcal{E} \vee p(...,c_i,...), \relation \datalogarrow \,...,p(..., c_i, ...), .... \in \drule^{*}_{\m{pos}}  \}
\end{align*}
Then, $\mathcal{J}_{dep}^{(0)}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n] \supseteq \mathcal{J}^{(0)}$ is inferred.
% Assume $\mathcal{J}_{dep}^{(i)}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n] \supseteq \mathcal{J}^{(i)}$ holds at step i. 
At step i, assume the following holds:
\begin{align}
\mathcal{J}_{dep}^{(i)}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n] \supseteq \mathcal{J}^{(i)}
\label{eq:assumption}
\end{align}

\noindent 
\textbf{Inductive case:} 
At step i+1, the $\mathcal{J}^{(i+1)}$ and $\mathcal{J}_{dep}^{(i+1)}$ are:
\begin{align*}
    & \mathcal{J}^{(i+1)} = \mathcal{J}^{(i)} \cup \{p_0(c^*) \mid p_1(c^*) \in \mathcal{J}^{(i)} \wedge \dots \wedge p_n(c^*) \in \mathcal{J}^{(i)} \} \\
    & \mathcal{J}_{dep}^{(i+1)} = \mathcal{J}_{dep}^{(i)} \cup \{dep\_{p_0}(c^*) \mid dep\_{p_1}(c^*) \in \mathcal{J}_{dep}^{(i)} \vee \dots \vee dep\_{p_n}(c^*) \in \mathcal{J}_{dep}^{(i)} \}
\end{align*}
Based on \Cref{eq:assumption} and the above formulas, where $\mathcal{J}_{dep}^{(i+1)}$ is computed via disjunctions, we can infer $\mathcal{J}_{dep}^{(i+1)}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n] \supseteq \mathcal{J}^{(i+1)}$.
Therefore, by induction, the following holds:
\begin{align}
\mathcal{J}_{dep}[dep\_{p_0} \mapsto p_0,...,dep\_{p_n} \mapsto p_n] \supseteq \mathcal{J}
\label{eq:conclusion}
\end{align}
Based on \defref{def:exact_domain}, we obtain:

\begin{align*}
& \exactDoamin\m{(X^*, p_0^+(X^*), \Datalog^+)} =
\m{
\{c^* \mid 
p_1(X^*)\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge p_n(X^*)\theta{\,\in\,}\mathcal{J} 
\} 
}
\\
& \exactDoamin\m{(X^*, dep\_{p_0}^+(X^*), \Datalog^+_{dep})} =
\m{
\{c^* \mid 
dep\_{p_1}(X^*)\theta^\prime \in \mathcal{J}_{dep} \vee
\dots \vee 
\m{dep\_{p_n}(X^*)\theta^\prime{\,\in\,}\mathcal{J}_{dep} 
\
}
}
\end{align*}
Based on the above, \Cref{eq:conclusion}, and $\m{[Dom]}$, we can infer:
\begin{align*}
& \exactDoamin\m{(X^*, p_0^+(X^*), \Datalog^+)} \subseteq \\
& \exactDoamin\m{(X^*, dep\_{p_0}^+(X^*), \Datalog^+_{dep})} \subseteq \\
& \exactDoamin\m{(X^*, dep\_{p_0}^+(X^*), \Datalog^+_{dep})} \cup  \bigcup_{i} \exactDoamin\m{(X^*, dep\_{p_i}^+(X^*), \Datalog^+_{dep})} \\
& = \computedDoamin\m{(X^*, p_0^+(X^*), \Datalog^+)}
\end{align*}

\noindent Since \code{\relation_0^+{=}p_0^+(X^*)}, we have proved that, 
$\exactDoamin(X^*, \relation_0^+, \Datalog^+) \subseteq \computedDoamin(X^*, \relation_0^+, \Datalog^+)$. 

Intuitively, we introduce two times of the over-approximations, \ie by the rules in \figref{fig:depend}, and by computing the 
\code{\mathrm{unifiable}}. Therefore overall, our computed domain for \code{X^*} \wrt $\drule_{\m{pos}}$ over-approximations its  exact domain. 

% Based on \defref{def:exact_domain} and \figref{fig:depend}, we obtain: 
% \\[-1.5em]
% \begin{align*}
% \exactDoamin\m{(X^*, \relation_0^+, \Datalog^+)} &=
% \m{
% \{c^* \mid 
% \relation_1\theta{\,\in\,}\mathcal{J} \wedge \dots \wedge 
% \relation_n\theta{\,\in\,}\mathcal{J} 
% \}
% }
% \\[-0.3em]
% \computedDoamin\m{(X^*, \relation_0^+, \Datalog^+)} &=
% \m{
% \{c^* \mid 
% \relation_1\theta{\,\in\,}\mathcal{J} \vee \dots \vee 
% \relation_n\theta{\,\in\,}\mathcal{J} 
% \}
% }
% \end{align*}
% Let $\mathcal{C}_1{\,=\,}\s{c^*\mid \relation_1\theta{\,\in\,}\mathcal{J}
% }$, \dots,  $\mathcal{C}_n{\,=\,}\s{\relation_n\theta{\,\in\,}\mathcal{J}}$, \\ then  
% $\exactDoamin\m{(X^*, \relation_0^+, \Datalog^+)} = \mathcal{C}_1 \cap \dots \cap \mathcal{C}_n$ and 
% $\computedDoamin\m{(X^*, \relation_0^+, \Datalog^+)} = \mathcal{C}_1 \cup \dots \cup \mathcal{C}_n$, \\
% since $\mathcal{C}_1 \cap \dots \cap \mathcal{C}_n \subseteq \mathcal{C}_1 \cup \dots \cup \mathcal{C}_n$; thus, 
% $\exactDoamin(X^*, \relation_0^+, \Datalog^+) \subseteq \computedDoamin(X^*, \relation_0^+, \Datalog^+)$.
\end{proof}
}
\begin{comment}
This over-approximation occurs because, for a symbolic constant \code{\alpha}, its exact domain \code{D}  
%set of constants that \code{\alpha} can be unified with %\code{\alpha} 
in a stratified Datalog program 
is a subset of its  
exact domain \code{D^\prime} in %set in 
the updated Datalog program where all negative literals have been removed, \ie  \code{D \,{\subseteq}\, D'}. 
Additionally, the method used for computing $\mathrm{unifiable}(\alpha)$ in a positive Datalog program is an over-approximation approach.
\end{comment}
\end{lemma}



\begin{theorem}[Completeness of the domain calculation] \label{theom:Completenessofthedomaincalculation}
Given any Datalog program $\Datalog$, 
to make the target predicate $\relation_0$ to be present, the computed the domains of a set of symbolic constants $\alpha^*$ is an over-approximation of its exact domain, namely: 
$
\exactDoamin(X^*, \relation_0, \Datalog)
\subseteq
\computedDoamin(X^*, \relation_0, \Datalog)$. 
(where $\relation_0{\datalogarrow}\relation_1,\dots,\relation_n, 
!\relation_{n+1}, \dots, !\relation_m$ $\in \Datalog$). 
{%\vspace{-2mm}
\small
\begin{proof}
Based on the definition of \figref{fig:depend}, 
we have: (1) ${\computedDoamin(X^*, \relation_0, \Datalog)} = \computedDoamin(X^*, \relation_0^+, \Datalog^+)$, 
where $\relation_0^+{\datalogarrow}\relation_1,\dots,\relation_n$.
Based on \lemmaref{lemma:reasoning_over_approx}, 
we have the following relation: (2) $\exactDoamin(X^*, \relation_0^+, \Datalog^+) \subseteq \computedDoamin(X^*, \relation_0^+, \Datalog^+)$.
Then based on \lemmaref{lemma:negation_over_approx}, we have the following relation: (3) ${\exactDoamin\m{(X^*, \relation_0, \Datalog)}} {\,\subseteq\,} \exactDoamin\m{(X^*, \relation_0^+, \Datalog)}
$.
Through the combination of (1)-(3), we prove that $
\exactDoamin(X^*, \relation_0, \Datalog)
\subseteq
\computedDoamin(X^*, \relation_0, \Datalog)$. 
\end{proof}}
\begin{comment}
For the set of symbolic constants  $\alpha^*$, its exact domain   
in a set of stratified Datalog rules  \code{\drule^*} is a subset of its  
exact domain in 
the updated Datalog rules  \code{\drule^{*}_{\m{pos}}} where all negative literals have been removed, \ie  \code{
\exactDoamin(\alpha, \drule^*) \,{\subseteq}\, 
\exactDoamin(\alpha, \drule^{*}_{\m{pos}}) }. 
The domain calculated by our method for each symbolic constant is a superset of its exact domain. 
We introduce extra placeholder constants to represent the 
constants that do not appear in the program, where such unseen constants can only come from the target output fact. 
%Meanwhile, all such constants are covered by the extra constants.
For the domain, based on the constants within the program, we over-approximate its range. 
Via  and \lemmaref{lemma:reasoning_over_approx} respectively. 
\end{comment}
\vspace{-2mm}
\end{theorem}




% and consequently, at least as many constants from the same input facts as $\Datalog$. 

%$\Datalog^{+}$ can produce more constants than $\Datalog$ with the same input facts, and 

\begin{comment}
For instance, given two Datalog rules \lstinline[mathescape]`L$_{0}$ :- L$_{1}$,...,L$_{k-1}$,L$_{k}$,L$_{k+1}$,...,L$_{n}$ (denoted as R$_1$)` and \lstinline[mathescape]`L$_{0}$ :- L$_{1}$,...,L$_{k-1}$,L$_{k+1}$,...,L$_{n}$ (denoted as R$_2$)`,
to produce the same output fact of \lstinline[mathescape]`L$_{0}$`, 
rule \lstinline[mathescape]`R$_1$` requires one more input fact of \lstinline[mathescape]`L$_{k}$ ` compared with \lstinline[mathescape]`R$_2$`.
Therefore, $\Datalog^{+}$ can produce more constants than $\Datalog$ with the same input facts, and thereby there are more constants for \code{\alpha} to unify in $\Datalog^+$.
\end{comment}
%can find all answer sets


\section{Method for pruning valuations for symbolic constants}
\label{sec:prune}

Not all valuations will contribute to generate the expected output fact.
To prune the invalid valuations, we adopt a method that encodes the original Datalog rules and facts into a meta-program whose execution outputs show the possibly valid valuations.

\begin{figure}[!h]
\vspace{-1mm}
\begin{lstlisting}[xleftmargin=5em,numbers=none,basicstyle=\footnotesize\ttfamily]
a(X):-b(X),c(X),!d(X),!e(X).
a(X):-d(X).
a(X):-e(X),!c(X).
\end{lstlisting} 
\vspace{-2mm}
\caption{Incapacity of \Symlog}
\label{fig:symbolic_sign_Example}
\vspace{-2mm}
\end{figure}

Specifically, the original Datalog program is transformed into a meta-program, where predicates are augmented with auxiliary variables storing \emph{symbolic bindings}, \ie, the assignment of symbolic constants to values from its domain, and a variable indicating the dependency of facts annotated with symbolic signs.
For each symbolic constant, an auxiliary variable \code{C_i} is introduced.
For each indicator variable \code{B_i} in the rule head, its relation with indicator variables in the body is \code{B_i=\lor_{j=1}^{n} B_{ij}}, where \code{B_{ij}} is in positive predicates.
Transforming the first rule in \figref{fig:symbolic_sign_Example} yields:
\begin{lstlisting}[mathescape, xleftmargin=0em, numbers=none, basicstyle=\footnotesize\ttfamily]
a(X,$C_1$,$C_2$,1):-b(X,$C_1$,$C_2$,$B_1$), c(X,$C_1$,$C_2$,$B_2$), 
              !d(X,$C_1$,$C_2$,0), d(X,$C_1$,$C_2$,1), 
              !e(X,$C_1$,$C_2$,0), e(X,$C_1$,$C_2$,1).
a(X,$C_1$,$C_2$, $B_1 \vee B_2$):-b(X,$C_1$,$C_2$,$B_1$), c(X,$C_1$,$C_2$,$B_2$), 
              !d(X,$C_1$,$C_2$,0), !d(X,$C_1$,$C_2$,1),
              !e(X,$C_1$,$C_2$,0), !e(X,$C_1$,$C_2$,1).
\end{lstlisting}
where $C_1$ and $C_2$ store bindings for \code{\alpha_1} and \code{\alpha_2}. 
The ``1'' in the first \code{a} is actually \code{B_1 \vee B_2 \vee 1 \vee 1}, and the ``$B_1 \vee B_2$'' in the second \code{a} is derived from the \code{b(X,C_1,C_2,B_1)} and \code{c(X,C_1,C_2,B_2)}.
Assume the symbolic EDB is \lstinline[mathescape]`{b($\alpha_1$), c($\alpha_2$), $\xi_1$ d(1)}`, then it is transformed to:
\begin{lstlisting}[mathescape, xleftmargin=0em, numbers=none, basicstyle=\footnotesize\ttfamily]
b($C_1$, $C_1$, $C_2$, 0):- dom_$\alpha_1$($C_1$), dom_$\alpha_2$($C_2$).
c($C_2$, $C_1$, $C_2$, 0):- dom_$\alpha_1$($C_1$), dom_$\alpha_2$($C_2$).  
d(1, 1).
\end{lstlisting}
where \lstinline[mathescape]`dom_$\alpha_i$` is true for all values from \code{\alpha_i}'s computed domain.
\code{d(1)} is appended with 1 to indicate that it is annotated with a symbolic sign, \code{\xi_1}.
\code{a(\alpha_1)} and \code{b(\alpha_2)} are appended with 0 since they are not annotated with symbolic signs, but they are transformed into rules with domains because they contain symbolic constants.
For each negative literal \code{!p(...,X_i,...)}, it is transformed into two pairs, (\code{!p(...,X_i,...,0)}, \code{p(...,X_i,...,1)}), and (\code{!p(...,X_i,...,0)}, \code{!p(...,X_i,...,1)}).
The first pair indicates that the head fact is possible to be generated, since there is no ground \code{p(...,0)} and the \code{p(...,1)} relying on symbolic sign facts is possible to be disabled.
The second pair shows that the head fact must be generated, since there is no ground \code{p(...,0)} and potential \code{p(...,1)}.
With unkown truthfulness of the facts with symbolic signs, this transformation computes an over-approximation of possible outputs.
As the computed domains for \code{\alpha_1} and \code{\alpha_2} are both \lstinline[mathescape]`{$n_1$, $n_2$}`, the domain facts are:
\begin{lstlisting}[mathescape, xleftmargin=0em, numbers=none, basicstyle=\footnotesize\ttfamily]
dom_$\alpha_1$($n_1$). dom_$\alpha_1$($n_2$). dom_$\alpha_2$($n_1$). dom_$\alpha_2$($n_2$).
\end{lstlisting}
Putting them together, the above transformed rules along with all facts constitute the transformed meta-program.
After executing the meta-program, \lstinline[mathescape]`a($n_1$, $n_1$, $n_1$, 0)` and \lstinline[mathescape]`a($n_2$, $n_2$, $n_2$, 0)` are derived.
There would be four valuations since the size of computed domains of \code{\alpha_1} and \code{\alpha_2} are both 2.
Therefore, 2 valuations are pruned.
Placeholders are useful for generating unseen values.
If there is a target fact \lstinline[mathescape]`a($1$)`, then \code{n_1} or \code{n_2} can be replaced with \code{1} to generate it. 
Consequently, we get two valuations:\code{\alpha_1 {=} n_1 {\,\wedge\,} \alpha_2{=}n_1 {\,\wedge\,} n_1 {=} 1} and \code{ \alpha_1 {=} n_2 {\,\wedge\,} \alpha_2{=}n_2 {\,\wedge\,} n_2 {=} 1}.


\section{More Examples}




As shown in \figref{fig:example:Infinite_Loops_1},   
we want to prove the following 
invariant: ``\emph{whenever x{=}1, then eventually x{=}0}''.
In CTL, it is expressed using \code{AG\,\phi}, which specifies that ``\emph{in all nondeterministic choices, \code{\phi} globally holds}''.  
Whether the property holds or not depends on whether the inner loop terminates. 
\begin{wrapfigure}{R}{0.4\columnwidth}
  \begin{lstlisting}[xleftmargin=0.5em,numbersep=5pt,basicstyle=\footnotesize\ttfamily]
  (*@\textcolor{mGray}{//$AG(x{=} 1 {\rightarrow} AF(x {=} 0))$}@*)
  while (1) {
    y = *;
    x = 1;
    n = *; 
    while (n>=0) {
      n = n - y;}
    x = 0; }
  \end{lstlisting} 
  \caption{An infinite loop} 
  \label{fig:example:Infinite_Loops_1}
  \end{wrapfigure}

The inner loop is initially summarised as 
\code{\effect^{\m{initial}}_{6\text{-}7}{\equiv}([n{\geq}0]\cdot n'{=}n\text{-}y) ^\star \vee([n{<}0]\cdot\epsilon)} where 
\code{[\pi]} denotes a guard upon a pure constraint, 
\code{n'} stands for the updated value of \code{n} for each iteration and \code{\star} stands for unknown number of repetition. 
%From this initial summary, 
Since \code{n} could be a \emph{ranking function}, \ie  \code{n}'s value is initially non-negative and decreasing,  
we derive the following \emph{weakest precondition for termination}: 
%(the termination condition \cite{DBLP:conf/cav/CookGLRS08})
\code{n\text{-}n'{\geq} 1}, \ie  
\code{n \text{-} (n\text{-}y) {\geq} 1}, as \code{n}'s value has to decrease at least 1 in each iteration, which is further reduced to \code{\pi_{\m{wpc}} \,{=}\,y {\geq}1}. 
%\yahui{I did not understand the meaning of this constraint}
With \code{\pi_{\m{wpc}}}, we summarise: 
\code{\effect_{6\text{-}7}^{\m{final}} {\equiv} ([y{\geq}1]\,{\cdot}\, n{<}0) \vee ([y {<}1] \,{\cdot}\, (n{\geq}0)^\omega)}. 
It describes that when \code{y{\geq}1}, the inner loop terminates with a final state \code{n{<}0}; otherwise, the program state remains \code{n{\geq}0} infinitely. 
We then compute the summary for the outer loop to be: \code{\effect_o{\equiv} 
[y{\geq}1]{\cdot}((x{=}1){\cdot}(n{<}0){\cdot}(x{=}0))^\omega \vee
[y{<}1]{\cdot}(x{=}1){\cdot}(n{\geq}0)^\omega
}. 
After encoding \code{\effect_o} and the invariant into Datalog, \toolName concludes that the property does not hold. 
Because if the inner loop does not terminate (when \code{y{<}1}), \code{x}'s value will never be set back to zero; and generates a patch that adds a fact  
\text{\lstinline|GtEq("y",1,|\loc{4}\lstinline|)|}, indicating that at line 4, the program state must be changed to satisfy \code{y{\geq}1}. 
%the constraint \code{y{\geq}1}, which guarantees the termination of the inner loop.  
%computing the summary \toolName encodes the above summary into Datalog, then translates the property into Datalog rules, and 
%to modify the nondeterminism choice at line 4, to be a constraint 


\paragraph*{\textbf{Repairing Real-world Termination Bugs}}
\label{sec:example:termination}
%interprocedural analysis
%intraprocedural
%an infinite loop 
%could cause unexpected consumption of CPU cycles or memory. Moreover, 
If an attacker can influence  loops in reactive systems, this vulnerability (CWE-835) could allow attackers to cause 
unexpected consumption of resources and, moreover, a denial of service. 
For instance, \figref{fig:example:real_lefe_termination} outlines such a termination bug (Cf. CVE-2018-7751, \url{https://github.com/FFmpeg/FFmpeg/commit/a6cba06}). 
%drawn from a real-world project. 
%The vulnerable implementation allows remote attackers to cause a denial of service. 




\begin{wrapfigure}{R}{0.48\linewidth}
\begin{lstlisting}[xleftmargin=0.5em,name=FFmpeg,numbersep=6pt,basicstyle=\footnotesize\ttfamily]
(*@\textcolor{mGray}{//$AF(\m{Exit}(\_))$}@*)
if(b<0||b>=end)return 0;
while (b < end) {
(*@\faultyCode{b += subtitles(b); } @*)
(*@\repaircode{int inc=subtitles(b);} @*) 
(*@\repaircode{if (!inc) break;} @*) 
(*@\repaircode{b += inc;}@*)}
\end{lstlisting}
%if (b >= end - 4) return 0;
\begin{comment}
\begin{minipage}[b]{0.52\linewidth}
\begin{lstlisting}[name=FFmpeg,basicstyle=\footnotesize\ttfamily]
int ff_subtitles_next_line(char *ptr){
  int n = *; // strcspn(ptr,"\r\n");
  ptr += n; 
  if (*ptr == '\r') { 
     ptr++; 
     n++; }
  if (*ptr == '\n') n++;
  return n; }
\end{lstlisting}
%
%https://ffmpeg.org/doxygen/3.2/subtitles_8h_source.html
\end{minipage}
\end{comment}
\caption{Extracted logic of a termination bug from FFmpeg} 
\label{fig:example:real_lefe_termination}
\end{wrapfigure}


Here, \code{b} and \code{end} are pointers pointing to a given buffer and a positive offset of the buffer. 
Inside of the loop, it calls an internal function ``{subtitles}'', which gets the number of characters to increment to jump to the next line. 
The attack happens if the given buffer is an empty string, as the return value at 
line 4 would be 0; therefore, the loop does not terminate as the position of \code{b} will never change. 
A fix provided by the developer is also shown, which checks the return value of the function call and breaks the loop if it returns 0. 

\toolName deploys an \emph{interprocedural analysis}, where procedures can be replaced by their summaries. 
For example, the summary of ``{subtitles}'' of its implementation (omitted here) is shown in the following formula: 
\code{\effect_{\m{subtitles(n)}}{\equiv} (n{=}*) \cdot \m{Exit}(n)}, where \code{n} is the formal argument, and by the time it is returned, it can be any value. 
%Thus, we obtain the 
%where all the external calls, here to \code{\m{strcspn}}, are abstracted using \code{*} \footnote{Better precision could be achieved by having specifications for library functions, which is left as an engineering issue.}. 
Then the loop summary is computed with the following result: 
\code{\effect_{3\text{-}4}  \equiv  (\m{tmp}{=}*) \,\cdot\, ([\m{tmp}{>}0] \cdot (b{\geq}end) \,\vee\, [\m{tmp}{\leq}0] \cdot (b{<}end)^\omega)}, 
where \code{\m{tmp}} is a temporary (fresh) variable referring to the return value of the call at line 4. 
Since there are two symbolic paths depending on whether \code{\m{tmp}} is positive or not , and the initial value of \code{\m{tmp}} is non-deterministic, \toolName generates two facts:  
\text{\lstinline|Gt("tmp",0,|\loc{3}\lstinline|)|} and  \text{\lstinline|LtEq("tmp",0,|\loc{3}\lstinline|)|} to represent both possibilities when entering the loop. 
After being composed with the context around the loop, the property \code{AF(\m{Exit}(\_))} fails to hold, as there exists an infinite path that will never reach a return statement. 
Then, the generated repair is to delete the fact \text{\lstinline|LtEq("tmp",0,|\loc{3}\lstinline|)|}, indicating a patch that shall either eliminate the possibility of \code{\m{tmp}} being non-positive or cut off the branch where the infinite path happens and the later corresponds to the developer-provided fix. 
%Although the automatically generated patch is not exactly the same as the developer-provided one, they hint at the same meaning towards the repair. 



\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}


\end{document}