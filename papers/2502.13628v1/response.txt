\section{Related Work}
Graph-based models have gained significant attention in various NLP tasks due to their ability to explicitly capture relational structures within data. GNNs have been effectively used in applications like node classification, link prediction, and graph classification by leveraging message-passing mechanisms to aggregate information from neighbors, thus capturing both local and global dependencies within graphs **Kipf, "Semi-Supervised Classification with Graph Convolutional Networks"**; **Wu et al., "Graph Attention Networks"**. Recent advancements have extended these models to more complex domains, including sentiment analysis and fake news detection, where the relational context is essential.

%In contrast to GNNs which operate in Euclidean space,
HGNNs extend the principles of GNNs into hyperbolic space, capturing long-range dependencies and hierarchical relations more naturally than their Euclidean counterparts **Nickel et al., "Learning Continuous Graph Representation with Hyperbolic Embeddings"**; **Chami et al., "Hyperbolic Graph Neural Networks"**. Hyperbolic spaces, characterized by their constant negative curvature, are particularly well-suited for capturing tree-like and hierarchical data, where relationships exhibit exponential growth in scale. This property has been shown to improve the representation of complex graph structures, such as those found in linguistic data, by preserving the hierarchical and relational intricacies often missed by Euclidean models.

The Poincar√© Ball Model **Nickel et al., "Learning Continuous Graph Representation with Hyperbolic Embeddings"** and the Lorentz Hyperboloid Model **Chami et al., "Hyperbolic Graph Neural Networks"** are among the most prominent hyperbolic models. These frameworks have demonstrated superior performance in embedding hierarchical data due to their ability to maintain structural integrity under hyperbolic constraints. 
%HGNNs extend the principles of GNNs into hyperbolic space, capturing long-range dependencies and hierarchical relations more naturally than their Euclidean counterparts. This approach has proven particularly effective for tasks requiring nuanced understanding of structural complexities, such as hierarchical classification and modeling dependency parsing graphs.