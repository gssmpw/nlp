\section{Related Work}
\paragraph{Legal LLM.}
Legal-domain LLMs have achieved astounding performance on legal tasks, such as legal information extraction~\cite{bommarito2018lexnlp}, case retrieval~\cite{ma2021lecard}, judgment prediction~\cite{huang2021dependency}, 
which offer broad applications that benefit different groups of the population.
Initial progress \cite{lawyerllama,yue2024lawllm,deng2023syllogistic} has been made by fine-tuning general LLMs to utilize legal knowledge for different legal tasks.
Specifically, Lawyer-LLaMa \cite{lawyerllama} and Interrogatory inject domain knowledge during continuous training. 
Fuzimingcha trained on a vast corpus of unsupervised Chinese legal texts and supervised judicial fine-tuning data.
LawLLM \cite{yue2023disc,yue2024lawllm} introduces legal retrieval capability to enhance factuality.
Previous approaches focused on static tasks, ignoring the dynamic properties of real-world legal tasks. To fill this gap, this study places emphasis on intensive legal interactions.


\paragraph{Role-playing Agent.}
The advancement of LLM-powered agents has greatly improved complex task resolution through anthropomorphic actions \cite{park2023generative,fan2024ai,yue2024synergistic}.
By mimicking human sense and vivid performance, role-playing agents present great potential in various fields \cite{mou2024agentsense,gao2024fine,lyu2024human,liu2024ai}.
However, in the legal field, the limited expertise of LLMs makes it challenging for existing role-playing methods \cite{xie2024can,jiang2024evaluating} to simulate legal attributes in multi-agent scenarios (\textit{e.g.}, clients and legal providers). This requires not only establishing legal attribute correspondences between different agents but also ensuring consistency in their profile and behavior under intensive interactions. To this end, we propose the MASER framework.


\begin{table}[]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tabular}{c|ccc|c}
\hline
Model                                          & INT            & PROF           & LOGI           & AVE            \\ \hline
Baichuan2-chat                                 & 72.58          & 65.33          & 70.37          & 69.42          \\
\multirow{2}{*}{SynthLaw $_{\mathrm{Baic}}$}   & \textbf{83.77} & \textbf{75.26} & \textbf{78.96} & \textbf{79.33} \\
                                               & (15.4\%$\uparrow$)             & (15.2\%$\uparrow$)             & (12.2\%$\uparrow$)             & (14.3\%$\uparrow$)       \\ \hdashline
Internlm2.5                                    & 64.35          & 60.18          & 63.81          & 62.78          \\
\multirow{2}{*}{SynthLaw $_{\mathrm{Intern}}$} & \textbf{84.93} & \textbf{76.19} & \textbf{80.07} & \textbf{80.40} \\
                                               & (32.0\%$\uparrow$)             & (26.6\%$\uparrow$)             & (25.5\%$\uparrow$)             & (28.1\%$\uparrow$)       \\ \hdashline
Qwen2.5-inst.                                  & 72.90          & 68.46          & 72.73          & 71.36          \\
\multirow{2}{*}{SynthLaw $_{\mathrm{Qwen}}$}   & \textbf{83.23} & \textbf{74.48} & \textbf{79.22} & \textbf{78.97} \\
                                               & (14.2\%$\uparrow$)             & (8.8\%$\uparrow$)             & (8.92\%$\uparrow$)             & (10.7\%$\uparrow$)       \\ \hline
\end{tabular}}
\caption{Performances of initial LLMs and their corresponding trained versions in the Interaction evaluation.}
\label{tab:vanilla-trained}
\end{table}