\section{MDMs Can Only Generate High-accuracy Sentence with A High Cost}
\label{sec:negative}

In this section, we analyze the inherent limitations of MDMs in accurately generating $n$-gram languages. Although perplexity is a widely adopted metric for evaluating text generation models, it provides an incomplete assessment of the quality of generated sequences. Specifically, perplexity measures the likelihood of observed sequences under the model but fails to evaluate the structural validity and fidelity of the generated samples. To address this shortcoming, we argue for the inclusion of \textit{accuracy} as a complementary metric to better assess the alignment of generated text with the target language.

\textbf{Accuracy.} Let $q$ denote an language defined over a vocabulary $\gV$, and let $\gL_q = \{\vx \in \gV^* \mid q(\vx) > 0\}$ represent the set of valid sequences under $q$. For a reverse model $p_\mathsf{\theta}$, the generation accuracy is defined as:
\begin{equation*}
    \operatorname{ACC}(p_\mathsf{\theta}) = \sum_{\vx \in \gL_q} p_\mathsf{\theta}(\vx).
\end{equation*}
This metric quantifies the probability mass assigned by $p_\mathsf{\theta}$ to valid sequences within the target language, thereby evaluating the model’s ability to generate syntactically and semantically valid outputs.Q

Natural languages exhibit complex grammatical structures, where the majority of possible sequences are either nonsensical or ungrammatical. Consequently, such sequences are assigned near-zero probability under the ground-truth distribution. The set $\gL_q$ encapsulates the valid sequences of the language—those that are both grammatically correct and structurally coherent. Accuracy, as defined above, measures the extent to which a language model assigns non-zero probability to these valid sequences and generates them faithfully within the target distribution. In practice, people usually use hidden markov model

We demonstrate that MDMs face significant challenges in generating valid sequences under the $n$-gram setting. By adopting accuracy as the central evaluation metric, we highlight fundamental limitations in the capacity of MDMs to faithfully model $n$-gram languages.

\begin{theorem}[Accuracy Bound for $n$-Gram Language Generation]
    \label{thm:negtive}
    There exists a $4$-gram language $q$ over a vocabulary of size $16$, such that for any reverse model $p_\mathsf{\theta}$ with an arbitrary masking schedule $\alpha$ satisfying \cref{ass:perfect_learning}, if the number of sampling steps satisfies $T = o(L)$, where $L$ is the sequence length, the accuracy of the generated text satisfies:
    \begin{equation*}
        \operatorname{ACC}(p_\mathsf{\theta}) < \frac{1}{2}.
    \end{equation*}
\end{theorem}

This result highlights a critical limitation: when the number of sampling steps $T$ scales sublinearly with the sequence length $L$, MDMs fail to assign sufficient probability mass to valid sequences, resulting in low accuracy. Consequently, achieving accurate generation with MDMs requires the number of sampling steps to scale linearly with the sequence length. However, this requirement undermines the efficiency gains commonly associated with non-autoregressive models. Moreover, each sampling step in MDMs incurs quadratic computational complexity, which is significantly higher than the linear complexity of autoregressive models. Thus, under conditions where accurate generation is essential, MDMs offer no computational advantage over their autoregressive counterparts, further limiting their practical utility.

\textbf{Why Do Perplexity and Accuracy Diverge?}  
The divergence between perplexity and accuracy stems from the distinct facets of model performance they evaluate. Perplexity measures the likelihood of observed sequences under the model’s distribution, quantifying its ability to capture statistical regularities in the data. However, it does not explicitly penalize the generation of invalid sequences, as long as the model assigns low probabilities to them. This limitation makes perplexity insensitive to structural or semantic errors in generated outputs. In contrast, accuracy directly evaluates the probability mass allocated to the set of valid sequences $\gL_q$, penalizing any probability assigned to invalid outputs. As a result, accuracy is a stricter and more task-specific metric that emphasizes the model's capacity to generate syntactically and semantically valid outputs. This distinction explains why MDMs can achieve low perplexity while exhibiting poor accuracy. Specifically, the parallel sampling mechanism in MDMs prioritizes distributional similarity over strict validity, leading to a decline in accuracy when the number of sampling steps $T$ scales sublinearly with the sequence length $L$. 

While perplexity may be a sufficient metric for standard text generation tasks, where the efficiency advantages of MDMs are desirable, certain applications—such as reasoning or formal language generation—demand strict adherence to grammatical and logical constraints. In such scenarios, even minor errors can render outputs unusable. Consequently, MDMs often fail to deliver computational efficiency relative to autoregressive models, underscoring their limitations in tasks requiring rigorous correctness.