@inproceedings{Du2024llm,
  author={Du, Yuyang and Chen, Kexin and You, Tao and Zhan, Yue and Low, Chang Han and Islam, Mobarakol and Guo, Ziyu and Jin, Yueming and Chen, Guangyong and Heng, Pheng-Ann},
  title={{LLM}-Assisted Multi-Teacher Continual Learning for Visual Question Answering in Robotic Surgery},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2024}
}

@article{bafghi2025fine,
  title={Fine Tuning without Catastrophic Forgetting via Selective Low Rank Adaptation},
  author={Bafghi, Reza Akbarian and Bagwell, Carden and Ravichandran, Avinash and Shrivastava, Ashish and Raissi, Maziar},
  journal={arXiv preprint arXiv:2501.15377},
  year={2025}
}

@article{balne2024parameter,
  title={Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications},
  author={Balne, Charith Chandra Sai and Bhaduri, Sreyoshi and Roy, Tamoghna and Jain, Vinija and Chadha, Aman},
  journal={arXiv preprint arXiv:2404.13506},
  year={2024}
}

@article{dettmers2024qlora,
    title={{QLoRA}: Efficient Finetuning of Quantized {LLM}s},
    author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
    journal={Advances in Neural Information Processing Systems},
    volume={36},
    year={2024}
}

@inproceedings{dosovitskiy2021image,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
    booktitle={International Conference on Learning Representations},
    year={2021}
}

@inproceedings{he2016deep,
    title={Deep Residual Learning for Image Recognition},
    author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={770--778},
    year={2016}
}

@inproceedings{he2024pitvqa,
  author={He, Runlong and Xu, Mengya and Das, Adrito and Khan, Danyal Z and Bano, Sophia and Marcus, Hani J and Stoyanov, Danail and Clarkson, Matthew J and Islam, Mobarakol},
  title={{PitVQA}: Image-Grounded Text Embedding {LLM} for Visual Question Answering in Pituitary Surgery},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={488--498},
  year={2024}
}

@inproceedings{hu2022lora,
  title={{LoRA}: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{huang2020pixel,
    title={Pixel-{BERT}: Aligning Image Pixels with Text by Deep Multi-Modal Transformers},
    author={Huang, Zhicheng and Zeng, Zhaoyang and Liu, Bei and Fu, Dongmei and Fu, Jianlong},
    booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
    year={2020}
}

@article{jiang2024mora,
  title={{MoRA}: High-Rank Updating for Parameter-Efficient Fine-Tuning},
  author={Jiang, Ting and Huang, Shaohan and Luo, Shengyue and Zhang, Zihan and Huang, Haizhen and Wei, Furu and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  journal={arXiv preprint arXiv:2405.12130},
  year={2024}
}

@article{li2019visualbert,
    title={Visual{BERT}: A Simple and Performant Baseline for Vision and Language},
    author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
    journal={arXiv preprint arXiv:1908.03557},
    year={2019}
}

@inproceedings{li2022blip,
    title={BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation},
    author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
    booktitle={International Conference on Machine Learning},
    pages={12888--12900},
    year={2022}
}

@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{liu2023llava,
    title={Visual Instruction Tuning},
    author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    booktitle={Advances in Neural Information Processing Systems},
    year={2023}
}

@inproceedings{liu2024alora,
  title={{ALoRA}: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models},
  author={Liu, Zequan and Lyn, Jiawen and Zhu, Wei and Tian, Xing and Graham, Yvette},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  volume={1},
  pages={571--583},
  year={2024}
}

@inproceedings{lu2019vilbert,
    title={Vi{LBERT}: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
    author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
    booktitle={Advances in Neural Information Processing Systems},
    volume={32},
    year={2019}
}

@inproceedings{radford2021learning,
    title={Learning Transferable Visual Models From Natural Language Supervision},
    author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
    booktitle={International Conference on Machine Learning},
    pages={8748--8763},
    year={2021}
}

@inproceedings{seenivasan2022surgical,
  author={Seenivasan, Lalithkumar and Islam, Mobarakol and Krishna, Adithya K and Ren, Hongliang},
  title={Surgical-{VQA}: Visual Question Answering in Surgical Scenes using Transformer},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={33--43},
  year={2022}
}

@inproceedings{seenivasan2023surgicalgpt,
  author={Seenivasan, Lalithkumar and Islam, Mobarakol and Kannan, Gokul and Ren, Hongliang},
  title={{SurgicalGPT}: End-to-End Language-Vision {GPT} for Visual Question Answering in Surgery},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={281--290},
  year={2023}
}

@inproceedings{su2020vl,
    title={{VL-BERT}: Pre-training of Generic Visual-Linguistic Representations},
    author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
    booktitle={International Conference on Learning Representations},
    year={2020}
}

@inproceedings{vaswani2017attention,
    title={Attention is All you Need},
    author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
    booktitle={Advances in Neural Information Processing Systems},
    volume={30},
    year={2017}
}

@article{xu2024correlating,
  title={Correlating measures of hierarchical structures in artificial neural networks with their performance},
  author={Xu, Zhuoying and Zhu, Yingjun and Hong, Binbin and Wu, Xinlin and Zhang, Jingwen and Cai, Mufeng and Zhou, Da and Liu, Yu},
  journal={npj Complexity},
  volume={1},
  number={1},
  pages={15},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{yuan2024advancing,
  author={Yuan, Kun and Kattel, Manasi and Lavanchy, Joel L and Navab, Nassir and Srivastav, Vinkle and Padoy, Nicolas},
  title={Advancing Surgical {VQA} with Scene Graph Knowledge},
  journal={International Journal of Computer Assisted Radiology and Surgery},
  pages={1--9},
  year={2024}
}

@article{zhang2023biomedclip,
  title={BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs},
  author={Zhang, Sheng and Xu, Yanbo and Usuyama, Naoto and Xu, Hanwen and Bagga, Jaspreet and Tinn, Robert and Preston, Sam and Rao, Rajesh and Wei, Mu and Valluri, Naveen and Wong, Cliff and Tupini, Andrea and Wang, Yu and Mazzola, Matt and Shukla, Swadheen and Liden, Lars and Gao, Jianfeng and Crabtree, Angela and Piening, Brian and Bifulco, Carlo and Lungren, Matthew P and Naumann, Tristan and Wang, Sheng and Poon, Hoifung},
  journal={arXiv preprint arXiv:2303.00915},
  year={2023}
}

