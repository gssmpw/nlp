\section{RELATED WORK}
\subsection{Visual Question Answering}
Early VQA methods relied on basic networks and simple fusion mechanisms, while subsequent approaches enhanced cross-modal interaction through question-guided attention and region-based representations. Latest research focuses on a broad Vision-Language Pre-training (VLP) paradigm based on the Transformer architecture ____. In this paradigm, approaches can be categorized into three types according to the ways of visual feature extraction: (I) Object-based methods (e.g., ViLBERT ____, VL-BERT ____, and VisualBERT ____) that utilize Faster R-CNN for ROI feature extraction; (II) Convolution-based methods like Pixel-BERT ____ that employ CNNs; and (III) Image-patch-based methods that divide images into sequences of patches for processing, such as CLIP ____, BLIP ____, and LLaVA ____. These models, trained on large-scale datasets to align visual and textual features into a shared embedding space, demonstrate strong few-shot transfer capabilities on downstream tasks such as VQA. Recent works ____ attempt to transfer general VQA models to the biomedical domain through post-training on domain datasets. These works require high computational cost and have not been considered for surgical applications.

\subsection{Surgical Visual Question Answering}
Recent studies mainly applied pre-trained visual and textual encoders on surgical VQA tasks____. Specifically, the visual features of surgical frames are extracted by CNNs (e.g., VGGNet, ResNet ____) or Vision transformer (ViT) ____, and the textual features of surgical questions are gained through stacked transformer layers ____. Early approaches, such as VisualBERT-RM ____ and SurgicalGPT ____, relied on concatenating visual and textual representations, followed by a self-attention layer. However, this concatenation leads to computational inefficiency due to the elongated embeddings, often requiring additional MLP layers for feature projections____. Yuan et al. ____ used scene graph generation for surgical VQA, but its multistage training is complex, computationally expensive, and reliant on prior task predictions. Existing methods primarily focus on close-ended surgical VQA, while there is a lack of datasets and approaches suitable for open-ended surgical VQA tasks.

With the rising interest in foundation models, researchers begin to apply large language models (LLMs) for surgical VQA tasks. He et al.____ employed cross-attention mechanism to model the correlations between visual and textual features, and a LLM to decode vision-language embeddings. However, fully fine-tuning foundation models on small domain datasets can lead to catastrophic forgetting, where the LLM may 'forget' its pre-trained general knowledge due to overfitting on limited data ____. Du et al.____ proposed a multi-teacher continual learning framework that balances knowledge from a frozen LLM and a medical expert model. While this approach attempts to mitigate catastrophic forgetting, it requires a carefully designed student model. Furthermore, the need to balance multiple objectives, including distillation and task-specific losses, increases the training complexity.

\subsection{Parameter-efficient Fine-tuning}
Parameter-efficient Fine-tuning (PEFT) updates only a small subset of model parameters while keeping the majority frozen. LoRA____ decomposes weight updates into low-rank matrices to enable efficient adaptation, but its low-rank updating mechanism may limit the model's ability to learn new knowledge effectively. MoRA____ addresses this limitation by employing a square matrix for matrix-rank updating while maintaining the same parameter count as LoRA, achieving better performance. DoRA____ decomposes pre-trained weights into magnitude and direction components, using LoRA for directional updates to bridge the performance gap with full fine-tuning while maintaining inference efficiency. ALoRA____ tackles the uniform rank limitation in LoRA by adaptively allocating different rank sizes across layers based on parameter importance, achieving better parameter efficiency. QLoRA____ further reduces memory requirements by combining 4-bit quantization with LoRA, enabling fine-tuning of large models on consumer GPUs at the cost of increased training time. However, these methods do not explicitly consider the inherent hierarchical structure of deep neural networks, where earlier layers extract general features with larger parameter spaces while later layers focus on task-specific features with more compact representations ____.