



\section{Approach}
\label{sec:approach}
% In the section, we first introduce our basic notions and then construct a complete graph connecting all of the conceptual nodes. Then, we convert the graph into a sparse conceptual space based on the revised connectivity hypothesis. Finally, we introduce global and local metrics to evaluate the space. The 
% % overall 
% pipeline is illustrated in Figure~\ref{fig:intro}.

% \begin{figure*}
%     \centering
%     \includegraphics[width=0.9\linewidth]{figs/intro.pdf}
%     \caption{ %Pipeline 
%     \lky{Outline}
%     of our construction to the conceptual space. We first extract the input word embeddings ($\mathcal{E}$) for vocabulary ($\mathcal{V}$) of LLMs. Then we construct the complete graph $\mathcal{C}$ by calculating the cosine similarity between any pair of embeddings. Finally, we reserve the edges with weights from highest to lowest until the graph $\mathcal{G}$ is connected. We focus on some connected subgraphs $\mathcal{G'}$ belonging to a specific domain.}
%     \label{fig:intro}
% \end{figure*}

In this section, we first introduce the basic notions and construct a complete graph connecting all conceptual nodes. We then sparsify the graph based on the revised connectivity hypothesis. Finally, we define global and local metrics to evaluate the conceptual space. The overall pipeline is illustrated in Figure~\ref{fig:intro}.

\subsection{Basic Notions}
We define a conceptual space $\mathcal{G} = \{V, E\}$, where $V$ and $E$ are sets of nodes and edges, respectively. Each node $v \in V$ represents a concept, which can be realized by a token, word, or sense. Each edge $e(u,v) \in E$ connects a pair of nodes $(u,v)$, reflecting their degree of association~\cite{guo2012concepts}. If a path $p(u,v)$ exists between nodes $u$ and $v$, they are connected, with path length $L$ defined as the number of edges along the path. If no path exists, $L = \infty$. A conceptual space is considered connected if every pair of nodes is connected.

A subgraph $\mathcal{G'} = \{V', E'\}$, where $V' \subset V$ and $E' \subset E$, reflects the local topology of $\mathcal{G}$ and typically represents a specific semantic domain, such as adverbs~\cite{zhang2017semantic}, color adjectives~\cite{gardenfors2014geometry}, or qualitative words~\cite{perrin2010polysemous}. Similarly, a subgraph is connected if every pair of nodes has a path.

We define a metric $M$ on $\mathcal{G}$ to measure the association or similarity between nodes. A common metric is cosine similarity~\footnote{While cosine distance violates the triangle inequality required by strict distances, we relax this constraint due to its simplicity and widespread use.}, widely applied in similarity-related tasks.

% Complete Graph
\subsection{Complete Graph}
% % We employ an LLM as language model to extract the input embeddings $\mathcal{E}$ for all the tokens in its vocabulary $\mathcal{V}$. Here, we regard each token - the minimal computational unit as the individual concept. After getting a vectorized numeric embedding to represent the concept, we calculate the cosine similarity of every pair of nodes as weights for each edge. We also apply the centering technique where each embedding minus the average vector across the samples due to the anisotropy issue~\cite{ethayarajh2019contextual}. This forms a complete graph $\mathcal{C}$ as any pair of concepts is connected. 
% \lky{We employ an LLM to extract input embeddings $\mathcal{E}$ for all tokens in its vocabulary $\mathcal{V}$. Here, we regard each token (i.e., the minimal computational unit) as the individual concept. After getting a vectorized numeric embedding for representing the concept, we calculate the cosine similarity of every pair of nodes as weights for each edge. We also apply the centering technique where each embedding minus the average vector across the samples to tackle anisotropy~\cite{ethayarajh2019contextual}. This forms a complete graph $\mathcal{C}$ as any pair of concepts is connected. }

We use an LLM to extract input embeddings $\mathcal{E}$ for all tokens in its vocabulary $\mathcal{V}$, treating each token (the minimal computational unit) as an individual concept. After obtaining the vectorized embeddings, we compute the cosine similarity between every pair of nodes to define edge weights. Additionally, we apply centering by subtracting the average vector from each embedding to address anisotropy~\cite{ethayarajh2019contextual}. This results in a complete graph $\mathcal{C}$, where every pair of concepts is connected.



% Conceptual Space
% \subsection{Conceptual Space}
% \label{Sec: CS}
% We obtain a sparsified graph as a conceptual space $\mathcal{G}$ from $\mathcal{C}$. We propose a minimum connectivity hypothesis, which states that $\mathcal{G}$ must be connected as a whole while reserving as less as possible edges. The ``connectivity'', as a sufficient condition, guarantees any pair of concepts has a path so that the overall concepts form a space. On the other hand, the ``minimum'' provides a necessary condition so that a sparse connection is preferred. This is motivated by the top-down construction of semantic map models, which even adopts a tree which has the least edges to meet the connectivity condition. To get less edges, we sort the edges by the weights, and obtain top $K$ ratio edges. Because higher weights indicate important ones.

% Note that a well-defined $\mathcal{G}$ is also a discrete topological space $\{\mathcal{G},  \mathcal{T}\}$, where $\mathcal{T}$ is a collection of all the subsets. Here, we define a subgraph $\mathcal{G'}$ as the subset of $\mathcal{G}$, which is also an open set. This is because the intersection and union of any two subgraph $\mathcal{G_A}$ and $\mathcal{G_B}$ still belongs to $\mathcal{T}$\lky{, i.e.,}
% % :
% \begin{equation}
%     \small \forall \mathcal{G}_A, \mathcal{G}_B \in \mathcal{T}, \quad  \mathcal{G}_A \cap \mathcal{G}_B \in \mathcal{T}, \quad \mathcal{G}_A \cup \mathcal{G}_B \in \mathcal{T}.
% \end{equation}
% Note that this is guaranteed by the ``connectivity'', and we require a ``minimum'' topological space. 

\subsection{Conceptual Space}
\label{Sec: CS}
We derive a sparsified graph, denoted as the conceptual space $\mathcal{G}$, from the complete graph $\mathcal{C}$. We propose a minimum connectivity hypothesis, which states that $\mathcal{G}$ must remain connected while using the fewest edges possible. The ``connectivity'' ensures that every pair of concepts is connected, forming a valid space. The ``minimum'' condition favors sparse connections, inspired by the top-down construction of semantic map models, which even use trees (with the least number of edges) to maintain connectivity. To achieve this sparsity, we rank edges by weight and retain the top $K$ ratio of edges, as higher weights indicate more important connections.

A well-defined $\mathcal{G}$ is also a discrete topological space $\{\mathcal{G}, \mathcal{T}\}$, where $\mathcal{T}$ is the collection of all subsets. We define a subgraph $\mathcal{G'}$ as a subset of $\mathcal{G}$, and it is considered an open set. This is because the intersection and union of any two subgraphs $\mathcal{G_A}$ and $\mathcal{G_B}$ still belong to $\mathcal{T}$:
\begin{equation}
    \small \forall \mathcal{G}_A, \mathcal{G}_B \in \mathcal{T}, \quad  \mathcal{G}_A \cap \mathcal{G}_B \in \mathcal{T}, \quad \mathcal{G}_A \cup \mathcal{G}_B \in \mathcal{T}.
\end{equation}
This is ensured by the ``connectivity'' condition, while a ``minimum'' topological space is required for the conceptual structure.


% % Evaluation
% \subsection{Evaluation}
% We evaluate the conceptual space from global and local perspective. In a global view, we calculate the statistics of a network. These show the basic properties, connectivity analysis and small-world characteristics of the spaces built by two models. The small-world statistics are mainly indicated by a larger clustering coefficient and a shorter shortest path. These are described detailedly in Section~\ref{section:GC}.


% Locally, we evaluate the subgraph $G'$ of a graph $\mathcal{G}$ in three designated scenarios. These scenarios includes common concepts, WordNet relations and a domain of qualitative words. Scenario 1 collects common concepts with ten semantic group. Each group has instances represented by monosemous words. Lengths of the shortest path within and among groups are compared for both models. Scenario 2 probes the shortest path connection for several WordNet relations. In the third scenario, we compare a conceptual space in a domain of qualitative words with the corresponding subgraph obtained from LLMs. Except the basic topology and connectivity information, we calculate correlation of degrees and accuracy (recall and precision) when referring to the ground-truth.

\subsection{Evaluation}
We evaluate the conceptual space from both global and local perspectives. 

Globally, we compute network statistics to analyze basic properties, connectivity, and small-world characteristics of the spaces built by two models. Small-world characteristics are indicated by a higher clustering coefficient and a shorter shortest path, which are described in detail in Section~\ref{section:GC}.

% Locally, we assess subgraph $\mathcal{G'}$ of the conceptual space $\mathcal{G}$ in three designated scenarios. Scenario 1 focuses on common concepts, grouped into ten semantic categories, with each group consisting of monosemous words. We compare the lengths of the shortest paths within and between groups for both models. Scenario 2 examines shortest-path connections for several WordNet relations. In Scenario 3, we evaluate a conceptual space in the domain of qualitative words, comparing it with the corresponding subgraph from LLMs. In addition to basic topology and connectivity information, we calculate the correlation of node degrees and evaluate accuracy in terms of recall and precision against the ground truth.

Locally, we analyze a subgraph \(\mathcal{G'}\) of the conceptual space \(\mathcal{G}\) in three scenarios. Scenario 1 examines common concepts across ten semantic categories, each containing monosemous words, comparing shortest paths within and between groups. Scenario 2 explores shortest-path connections for various WordNet relations. Scenario 3 evaluates a conceptual space of qualitative words, comparing it to the corresponding LLM subgraph. Beyond topology and connectivity, we assess node degree correlations and measure recall and precision against the ground truth.


% \begin{table}[h]
%     \centering
%     \small
%     \begin{tabular}{ccc}
%     \toprule
%         Metric & Description & Trend \\
%     \midrule
%         Size & Summed weights of edges & $\uparrow$ \\
%         Recall & Coverage rate of instances & $\uparrow$ \\
%         Precision & Accuracy of predicted instances & $\uparrow$ \\
%         Div\_D & Standard deviation of degrees & $\downarrow$ \\
%     \midrule
%     \midrule
%         Acc & Matched rate compared to GT & $\uparrow$ \\
%         \bottomrule
%     \end{tabular}
%     \caption{\textcolor{blue}{Different metrics for evaluating the conceptual space. The trend shows the optimal direction for a better network.}}
%     \label{tab:descirption}
% \end{table}