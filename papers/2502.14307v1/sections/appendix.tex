\section{Explanation of CPU Performance Events}\label{sec:hpc_descriptions}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
This section provides explanations for each of the CPU performance events listed in Table~\ref{tab:cpu_events}:

\begin{itemize}
    \item \textbf{UOPS\_ISSUED.ANY}: This event counts the total number of micro-operations (uops) issued by the front end of the processor. It helps to understand how often the CPU is generating work for the execution units.

    \item \textbf{UOPS\_RETIRED.RETIRE\_SLOTS}: This counter measures the number of micro-operations that have been retired, representing the slots used in the retirement stage. High values indicate effective utilization of the CPU pipeline.

    \item \textbf{INT\_MISC.RECOVERY\_CYCLES\_ANY}: This event counts the cycles the processor spends in recovery due to issues in the integer pipeline, such as branch mispredictions. It provides insight into potential inefficiencies in the execution flow.

    \item \textbf{MACHINE\_CLEARS.COUNT}: This counter tracks the total number of machine clears. Machine clears occur when the processor needs to flush the pipeline, often due to errors or interruptions, impacting overall performance.

    \item \textbf{MACHINE\_CLEARS.SMC}: This event counts machine clears specifically triggered by self-modifying code. Self-modifying code requires the processor to invalidate instructions and restart, which is costly in terms of performance.

    \item \textbf{MACHINE\_CLEARS.MEMORY\_ORDERING}: This counter registers machine clears due to memory ordering conflicts. Such conflicts require the CPU to reset and reorder memory accesses, which can degrade performance in multithreaded applications.

    \item \textbf{FP\_ASSIST.ANY}: This event counts floating-point assists, which are special handling operations needed to process floating-point instructions. High counts may indicate heavy floating-point computation workloads or suboptimal code for floating-point operations.

    \item \textbf{OTHER\_ASSISTS.ANY}: This counter registers other assist events, including exceptions and corrections for specific instructions or situations. This can give insight into issues like misaligned memory access or uncommon instruction usage.

    \item \textbf{CPU\_CLK\_UNHALTED.ONE\_THREAD\_ACTIVE}: This event measures the number of cycles during which at least one thread is active. This counter is useful for understanding overall CPU utilization, especially in multi-threaded environments.

    \item \textbf{CPU\_CLK\_UNHALTED.THREAD}: This counter measures the cycles during which a specific thread remains active. It provides data on individual thread activity and allows for a more granular view of CPU utilization.

    \item \textbf{HLE\_RETIRED.ABORTED\_UNFRIENDLY}: This event counts the hardware lock elision (HLE) transactions that were aborted due to “unfriendly” reasons, such as interference by other threads or incompatible instructions. High values can indicate issues with lock-based concurrency.

    \item \textbf{HW\_INTERRUPTS.RECEIVED}: This counter measures the number of hardware interrupts received by the processor. Hardware interrupts are signals from external devices that require immediate attention, potentially affecting processor performance by disrupting normal execution flow.
\end{itemize}
\section{Leakage Rates Analysis on Skylake}\label{sec:verw_skylake}

Leak rates for VERW measured in Skylake-X is given in Figure~\ref{fig:verwwww}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/VERW_all_leak_rate_vs_iter_leak_granularity_SKYLAKE.png}
    \caption{Leak rates for VERW measured in Skylake-X.}
    \label{fig:verwwww}
\end{figure}


\section{Other $\mu$RL-discovered Transient Execution Mechanisms}\label{sec:misc}

\paragraph{LAR}
The LAR instruction loads the access rights of a segment into a register, based on the segment selector provided. It is useful for managing memory segmentation and ensuring the correct privilege levels when accessing different memory regions.
Leak rates for LAR measured in Raptor Lake in Figure~\ref{fig:larrrrr}. Four instruction sequences with \texttt{LAR} leakage are given in Listing~\ref{lst:lar}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/LAR_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for LAR measured in Raptor Lake.}
    \label{fig:larrrrr}
\end{figure}



\begin{figure}[h]
\begin{lstlisting}[caption=Four instruction sequences with \texttt{LAR} leakage, label={lst:lar}]
; seq 1: leaks through LAR
%rep 500
LAR RAX, [R15]
MULX RAX, RAX, qword [R15]
%endrep
; seq 2: leaks through LAR
%rep 500
LAR RCX, [R15]
ADCX RCX, qword [R15]
CMOVNL EAX, EDX
%endrep
; seq 3: leaks through LAR
%rep 500
LAR AX, [R15]
RDTSCP
%endrep
; seq 4: more stable leakage with prefetchwt1
%rep 500
PREFETCHWT1 byte [R15]
LAR ESP, [R15]
LZCNT EBX, dword [R15]
%endrep
; seq 5: no dependency
%rep 500
LAR DX, DX
LOCK CMPXCHG16B [R15]
%endrep
; seq 6: no dependency
%rep 500
WRGSBASE RSP
CMPXCHG16B [R15]
LAR DX, AX
TZCNT RDX, qword [R15]
PEXT RBX, RDX, RAX
%endrep
\end{lstlisting}
\end{figure}

% \begin{figure}[h]
% \begin{lstlisting}[caption=LAR, label={lst:lar}]
% %rep 500
% LAR RCX, [R15]
% ADCX RCX, qword [R15]
% CMOVNL EAX, EDX
% %endrep
% \end{lstlisting}
% \end{figure}



% \begin{figure}[h]
% \begin{lstlisting}[caption=LAR, label={lst:lar}]
% %rep 500
% LAR AX, [R15]
% RDTSCP
% %endrep
% \end{lstlisting}
% \end{figure}

% \begin{figure}[h]
% \begin{lstlisting}[caption=leaks more stable with prefetchwt1, label={lst:lar}]
% %rep 500
% PREFETCHWT1 byte [R15]
% LAR ESP, [R15]
% LZCNT EBX, dword [R15]
% %endrep
% \end{lstlisting}
% \end{figure}

% \begin{figure}[h]
% \begin{lstlisting}[caption=no dependency, label={lst:lar}]
% %rep 500
% LAR DX, DX
% LOCK CMPXCHG16B [R15]
% %endrep
% \end{lstlisting}
% \end{figure}


% \begin{figure}[h]
% \begin{lstlisting}[caption=no dependency, label={lst:lar}]
% %rep 500
% WRGSBASE RSP
% CMPXCHG16B [R15]
% LAR DX, AX
% TZCNT RDX, qword [R15]
% PEXT RBX, RDX, RAX
% %endrep

% \end{lstlisting}
% \end{figure}



\paragraph{LSL+RDSP}
The LSL instruction loads the memory segment limit from a specified segment selector into a register, which is useful for segmentation tasks by providing the size of a memory segment, helping with boundary checks. Leak rates for LSL+RDTSCP measured in Raptor Lake.
Leak rates for LSL+RDTSCP measured in Raptor Lake are given in Figure~\ref{fig:lslllllll}.
\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/LSL_RDTSCP_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for LSL+RDTSCP measured in Raptor Lake.}
    \label{fig:lslllllll}
\end{figure}


\section{Leakage Rate Analysis on Previously Known Transient Execution Mechanisms}
Leakage rates for previously known mechanisms such as FP assist, MD, MO and SMC on Raptor lake are given in Figure~\ref{fig:11},~\ref{fig:12},~\ref{fig:13} and ~\ref{fig:14}.

\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/fp_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for FP assist measured in Raptor Lake.}
    \label{fig:11}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/md_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for Memory disambiguation measured in Raptor Lake.}
    \label{fig:12}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/mo_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for Memory ordering measured in Raptor Lake.}
    \label{fig:13}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/smc_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leak rates for SMC measured in Raptor Lake.}
    \label{fig:14}
\end{figure}




% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{figures/X87_all_leak_rate_vs_iter_leak_granularity.png}
%     \caption{X87 - ??? NOT SURE IF THIS IS CORRECTLY EXECUTED}
%     \label{fig:enter-label}
% \end{figure}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
\section{Instruction Sets}


\begin{table}[ht]
    \centering
    \footnotesize
    \begin{tabular}{|l|r|l|r|}
    \hline
    \textbf{Instruction Set} & \textbf{Count} & \textbf{Instruction Set} & \textbf{Count} \\
    \hline
    ADOX\_ADCX & 8 & AES & 12 \\
    AVX & 695 & AVX2 & 286 \\
    AVX2GATHER & 16 & AVX512F\_512 & 2192 \\
    AVX512F\_128 & 1816 & AVX512F\_256 & 1940 \\
    AVX512F\_SCALAR & 584 & AVX512DQ\_128 & 247 \\
    AVX512DQ\_256 & 281 & AVX512DQ\_512 & 357 \\
    AVX512BW\_128 & 467 & AVX512BW\_256 & 467 \\
    AVX512BW\_512 & 467 & AVX512F\_128N & 23 \\
    AVX512DQ\_SCALAR & 44 & AVX512CD\_512 & 38 \\
    AVX512CD\_128 & 38 & AVX512CD\_256 & 38 \\
    AVX512BW\_128N & 8 & AVX512DQ\_128N & 8 \\
    AVX512DQ\_KOP & 18 & AVX512BW\_KOP & 34 \\
    AVX512F\_KOP & 15 & AVXAES & 12 \\
    I86 & 809 & I386 & 196 \\
    I486REAL & 37 & CMOV & 96 \\
    PENTIUMREAL & 5 & I186 & 124 \\
    LONGMODE & 24 & LAHF & 2 \\
    I286PROTECTED & 26 & I286REAL & 10 \\
    FAT\_NOP & 3 & RDPMC & 1 \\
    PPRO & 2 & BMI1 & 26 \\
    BMI2 & 32 & CET & 2 \\
    F16C & 8 & FMA & 192 \\
    INVPCID & 1 & CMPXCHG16B & 2 \\
    LZCNT & 6 & PENTIUMMMX & 129 \\
    SSE & 97 & MOVBE & 6 \\
    PCLMULQDQ & 2 & RDRAND & 3 \\
    RDSEED & 3 & RDTSCP & 1 \\
    RDWRFSGS & 8 & FXSAVE & 2 \\
    FXSAVE64 & 2 & SSEMXCSR & 2 \\
    SSE2 & 264 & SSE2MMX & 6 \\
    SSE3 & 20 & SSE3X87 & 2 \\
    SSE4 & 96 & SSE42 & 25 \\
    POPCNT & 6 & SSSE3MMX & 32 \\
    SSSE3 & 32 & X87 & 119 \\
    FCMOV & 8 & FCOMI & 4 \\
    XSAVE & 6 & XSAVEC & 2 \\
    XSAVEOPT & 2 & XSAVES & 4 \\
    \hline
    \end{tabular}\label{tab:instruction_sets}
    \caption{Number of instructions per set used in the action space for Skylake-X.}
    \end{table}
% \section{Generic RL Problems}
% \begin{itemize}[nosep]
%     \item \textit{Credit Assignment Problem:}
%     What parts of the action sequence in a large episode contribute to the reward it gets?
%     \item \textit{Sparse Reward problem:} Agent gets the positive reward only after it is actually successful, which is extremely rare with random actions. Solution is Reward Shaping. Manually creating a reward function. Downside: This needs to be done for every new/custom environment.
%     \item \textit{The alignment problem:} The agents find a shortcut in the reward function to get all the positive rewards but not the intended behavior. Policy is overfitting.
%     \item \textit{Large Action Space}
%     Action space reduction - domain knowledge may be leveraged to define reasonable decision rules.
    
%     Metaheuristics -  To automate the search for good solutions, metaheuristics (e.g., simulated annealing, genetic algorithms) guide the search over the action space, for instance by occasionally accepting non-improving actions or by re-combining them
    
%     Matheuristics - A particular branch of heuristics merges metaheuristics with mathematical programming

%     \textbf{Learned action representations
% } Continuous-to-discrete mappings

% \url{https://archive.is/20231123221542/https://towardsdatascience.com/five-ways-to-handle-large-action-spaces-in-reinforcement-learning-8ba6b6ca7472}
% \end{itemize}

% \paragraph{Auxiliary Losses}
% Value Function Replay, Reward Prediction

% \paragraph{Curiosity Driven Exploration}
% $\epsilon$-greedy exploration

% \paragraph{Model-based RL}

% \paragraph{Trust Region PO}
% Don't go far away from the older policy.

% \section{Useful RL Topics}
% \paragraph{Offline Reinforcement Learning} To accelerate the training, we can start collecting data on the machine(s) using random fuzzing and then train the agent later. This way, we can also use the old data cumulatively whenever we want to train a new agent.

% \paragraph{POMDP -- Partially Observable Markov Decision Process}
% Since the agent cannot observe all of the $\mu$Arch state at the same time, we can say the whole problem is POMDP.

% \paragraph{Action Branching Architectures (ABAs)}
% Solves the combinatorial explosion problem in large discreet action spaces.

% \paragraph{Hierarchical Reinforcement Learning (HRL)}

% \section{Experiment Ideas}
% \begin{enumerate}
%     \item Without LLM, can we train an RL agent that optimizes/improves an existing attack \textbf{in the instruction space?}  (exploitation) It can be developed on top of Osiris.
%     \item Without RL, can we use LLM for exploration? Can we use GPT4 API run with Osiris tool?
% \end{enumerate}

% \section{Action Items}
% \begin{enumerate}
%     \item Setup a small experiment that shows RL can explore different attacks (maybe statically at first)
%     \item Categorize x86 instruction and attack primitives (can be similar to Osiris)
%     \item Prepare prompt templates for each attack primitive.
%     \item Categorize x86 instructions in the form of a decision tree for actions.
    
% \end{enumerate}

% \subsection{Challenges and Questions}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \paragraph{High-level}
% \begin{itemize}[nosep]
%     \item How can we narrow down the problem so we cover a good space in a limited time?
%     \item What will be the role of LLM? Are we going to train the LLM?
%     \item Are we going to use Reset/Trigger/Measure triples as Osiris?
%     \item What are all possible uArch primitives in x86? Which ones are used in attacks? (Categorization)
%     \item Which level are we going to work on, Assembly or LLVM IR level, or $\mu$OP level?
%     \item What is the state/observable in the system that the agents will see and generate actions? In Alpha-Dev, they use CPU Memory/Register state embeddings.
    
% \end{itemize}
% \paragraph{Practical}
% \begin{itemize}[nosep]
%     \item How are we going to consider the effect of HW and SW configuration? Such as Hyperthreading, TSX, SGX, AVX, HW prefetch, previous mitigations, Kernel Samepage Merging, ASLR etc.
%     \item What will be the reward function for a given action?

%     \item Which RL library/algorithm to use?
%     \item What kind of fuzzing operations are we gonna apply on LLM output without breaking the code?
%     \item What should be the maximum size for an attack sequence?
% \end{itemize}



% \subsection{Instructions that Cause Bad Speculation}
% In this section, we document the RL-generated instruction sequences that cause bad speculation measured by the performance counters.
% Note that most of these sequences have not been shown to be exploitable and we did not see observable byte leakage through transient execution. However, these sequences give insights into the behavior of the processor and the RL agent's ability to generate instruction sequences that cause bad speculation.

% \begin{table*}[h]
%     \centering
%     \begin{tabular}{l|l}
%         \toprule
%         \textbf{Instruction} & \textbf{Description or Reference} \\ 
%         \midrule
%         DIV & Attack Shown in~\cite{oleksenko2023hide} \\ 
%         VERW & \\ 
%         VERR & \\ 
%         LSL & Load Segment Limit \\ 
%         LAR & Load Access Rights \\ 
%         Floating Point Instructions & \\ 
%         VSCALEFSD & \\ 
%         VFMSUB213SD & Fused Multiply Subtract. Attack shown in~\cite{chakraborty2024shesha} \\ 
%         VSCALEFSS & Scale Scalar Float32 Value With Float32 Value \\ 
%         XADD +       VPSRAW & \\ 
%         CMPXCHG + VPLZCNTQ & \\ 
%         ADCX + VPCMPUB  & \\ 
%         RDTSCP + VREDUCESS  & \\ 
%         VSQRTSS & \\ 
%         \bottomrule
%     \end{tabular}
%     \caption{Instructions and Their Descriptions or References}\label{tab:instructions}
% \end{table*}


% \begin{enumerate}[nosep]
%     \item DIV (Attack Shown in~\cite{oleksenko2023hide})
    
%     \item VERW
%     \item VERR

%     \item LSL - load segment limit
%     \item LAR - load access rights
%     \item Floating Point Instructions + VSCALEFSD

%     \item VFMSUB213SD - Fused multiply substract Attack shown in~\cite{chakraborty2024shesha}
%     \item VSCALEFSS - Scale Scalar Float32 Value With Float32 Value

    
%     \item XADD + VPSRAW
    
% Leaks with GDS mitigation off

% does not leak with GDS mitigation on

% % section .data
% % align 64
% % addresses_US:
% %     times 4096*32 db 0x01
% % section .text
% % align 64
% % global victim_asm
% % victim_asm:

% % PUSH RAX
% % PUSH RDX
% % MOV    AX, 0xFF         ; Load 0xFF into a 16-bit register (AX)
% % KMOVW  K3, AX           ; Move the value from AX into K3 (16-bit operation)

% % LEA RAX, [addresses_US]
% % loop:
% % VPSRAW XMM1 {K3}{z}, [RAX], 2
% % JMP loop
% % POP RDX
% % POP RAX



%     \item CMPXCHG + VPLZCNTQ

% % LEA RAX, [addresses_US]
% % LOCK CMPXCHG qword [RAX], RCX
% % VPLZCNTQ XMM0 {K5}, qword [RAX] {1to2}

% % CMPXCHG16B + VPLZCNTQ

% % LEA RAX, [addresses_US]
% % CMPXCHG16B [RAX]
% % VPLZCNTQ XMM3 {K4}{z}, [RAX]

% \item ADCX + VPCMPUB
% % LEA RAX, [addresses_US]
% % ADCX RAX, qword [RAX]
% % VPCMPUB K1 {K4}, ZMM2, [RAX], 2



% \item RDTSCP + VREDUCESS
% % RDTSCP
% % VREDUCESS XMM2 {K5}{z}, XMM4, dword [RAX], 2

% \item VSQRTSS
% \end{enumerate}
