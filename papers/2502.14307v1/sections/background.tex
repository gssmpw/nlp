
\section{Background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Microarchitectural Attacks}
\subsubsection{Cache Timing Side Channel Attacks}

The state of the shared cache can be observed to detect the memory access patterns. Over the past years, different techniques have been developed to extract sensible data by using cache timing as a side-channel attack.

Flush+Reload~\cite{yarom2014flush+} leverages the Last-Level Cache (L3 cache) to monitor memory access patterns in shared pages. While it does not require the attacker and victim to share the same execution core, it flushes a potential victim address from the cache, and then measures the reload time if the target address is accessed. EVICT+RELOAD~\cite{gruss2015cache} is another work where an eviction technique is used when cache flushing is not available. Prime+Probe~\cite{liu2015last} exploits the eviction sets to detect access patterns and it does not require shared memory between attacker and victim.
%
The Flush+Flush attack~\cite{gruss2016flush+} exploits the timing variations of the \texttt{clflush}. The Evict+Time attack~\cite{osvik2006cache} uses timing differences between cache hits and misses to infer cache state, allowing an attacker to detect cache misses and deduce access patterns. %A more efficient version, Evict+Spec+Time~\cite{cheng2024evict+}, can pinpoint the exact location of a cache miss within the victim’s code. 
%
% Cache contention attacks involve filling a cache set and measuring re-access time, where other processes evict the attacker's cache lines, revealing cache activity. Prime+Probe~\cite{liu2015last} is a versatile side-channel attack that infers sensitive information by exploiting cache behavior in shared environments without needing shared memory between attacker and victim.

% Flush+Flush~\cite{gruss2016flush+} attack introduces a novel method for exploiting cache timing vulnerabilities that relies solely on the execution time of the flush instruction rather than memory accesses, setting it apart from traditional cache attacks.  Evict+Time~\cite{osvik2006cache} attack exploits the timing difference between cache hits and misses to infer cache state. By measuring execution time, an attacker can deduce if a cache miss occurred, revealing information about data access patterns. Evict+Spec+Time~\cite{cheng2024evict+}, a refined version of Evict+Time, allows attackers to determine not only the presence of a cache miss but also the exact location within the victim's code where it occurred. The new method proves highly effective, significantly outperforming Evict+Time in efficiency.

% Cache contention attacks fill a cache set and measure re-access time. Other processes using the set evict the attacker’s cache lines, causing higher latency, which reveals their cache activity. Prime+Probe~\cite{liu2015last} is a side-channel attack used to infer sensitive information by exploiting cache behavior, particularly in shared cache environments. It does not require shared memory between attacker and victim, making it more versatile across different environments.

Although more advanced cache side-channel attacks~\cite{irazoqui2015s, disselkoen2017prime+, purnal2021prime+}, in this work, we use Flush+Reload for its simplicity and effectiveness.

%The work~\cite{irazoqui2015s} presents cross-core cache attack that leverages access time variations in the last-level cache (L3) to retrieve sensitive information across virtual machine (VM) boundaries. The attack exploits huge pages to function without memory deduplication, requiring only machine co-location of the attacker and victim on separate cores. PRIME+ABORT~\cite{disselkoen2017prime+} attack introduces a novel approach to last-level cache (LLC) attacks by eliminating the need for timing side channels, which traditional LLC attacks rely on. Instead, PRIME+ABORT uses Intel’s Transactional Synchronization Extensions (TSX), allowing it to bypass many existing defenses that target timer-dependent attacks. Prime+Scope~\cite{purnal2021prime+} is a high-precision cross-core cache contention attack that enhances cache timing resolution by performing rapid, single-line cache contention measurements. It includes a novel approach for constructing eviction sets, surpassing previous techniques by two orders of magnitude.

\subsubsection{Transient Execution Attacks}

Transient execution attacks exploit speculative and out-of-order execution in CPUs to access restricted data temporarily, leaving traces in the cache that attackers can analyze. 

Spectre attacks~\cite{kocher2019spectre} exploit speculative execution and branch prediction in modern processors to leak confidential information across security boundaries. By inducing speculative operations that bypass normal execution flow, attackers can access sensitive memory and registers, creating side-channel leaks. NetSpectre~\cite{schwarz2019netspectre} is the first remote variant of the Spectre attack, extending its reach beyond local code execution. NetSpectre marks a significant shift from local to remote attacks, making Spectre a threat even to systems where no attacker-controlled code is executed, including cloud environments.

SgxPectre attack~\cite{chen2019sgxpectre} exploits CPU vulnerabilities to compromise the confidentiality and integrity of SGX enclaves. By manipulating branch prediction from outside the enclave, attackers can temporarily alter the enclave's control flow, producing cache-state changes that reveal sensitive information within the enclave.

Meltdown~\cite{Lipp2018meltdown} bypasses memory isolation by exploiting out-of-order execution in modern processors to access protected kernel memory. This enables attackers to read memory from other processes or virtual machines without permission, posing a severe risk to millions of users. Foreshadow~\cite{vanbulck2018foreshadow} is a microarchitectural attack exploiting speculative execution flaws in Intel processors to breach SGX security. Without needing kernel access or assumptions about enclave code, Foreshadow leaks enclave secrets from the CPU cache.

Rogue In-flight Data Load (RIDL)~\cite{van2019ridl} is a speculative execution attack that leaks data across address spaces and privilege boundaries. RIDL retrieves in-flight data directly from CPU components without relying on cache or translation structures, making it uniquely invasive and effective. Fallout~\cite{canella2019fallout} reveals that Meltdown-like attacks remain feasible on newer CPUs that are supposedly immune to Meltdown due to hardware fixes. By examining the behavior of the store buffer, they uncover vulnerabilities.

ZombieLoad~\cite{Schwarz2019ZombieLoad} is a Meltdown-type attack that exploits a vulnerability in the processor’s fill-buffer logic to leak data across logical CPU cores, even on CPUs with hardware mitigations against Meltdown and MDS. ZombieLoad uses faulting load instructions to transiently access unauthorized data in the fill buffer. Load Value Injection (LVI)~\cite{van2020lvi} is a technique that generalizes injection-based attacks to the memory hierarchy by injecting attacker-controlled values into a victim’s transient execution. Downfall~\cite{moghimi2023downfall} is a new class of transient execution attacks that exploit the gather instruction on x86 CPUs to leak sensitive data across security boundaries, including user-kernel, process, and virtual machine isolation, as well as trusted execution environments.

\subsection{Reinforcement Learning}

In RL, the objective is for an agent to learn a policy $\pi_\theta(a|s)$, parameterized by $\theta$, which maximizes the expected cumulative reward through its chosen actions in an environment. The policy gradient method~\cite{sutton1999policy} computes the gradient of the expected reward with respect to the policy parameters, allowing the agent to directly update the policy by following the gradient. Formally, the objective function $J(\theta)$ is defined as:
%
%\begin{equation}
\[
J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \sum_{t=0}^{T} r_t \right],
\]
%\end{equation}
%
where $r_t$ is the reward at time step $t$, and the expectation is over the trajectories induced by the policy $\pi_\theta$. The policy is updated by adjusting $\theta$ in the direction of the gradient $\nabla_\theta J(\theta)$ using gradient ascent. One of the major challenges with vanilla policy gradient methods is the high variance of the gradient estimates, which can lead to unstable learning. Additionally, large updates to the policy parameters $\theta$ can cause dramatic changes to the policy, potentially leading to performance collapse. 
%
Trust Region Policy Optimization (TRPO)~\cite{schulman2015trpo} was proposed to address this issue by enforcing a constraint on the size of policy updates using a trust region.
%
TRPO introduces the following constrained optimization problem:
%
%\begin{multline}
{\small
\[
 \max_\theta \mathbb{E}_{\pi_\theta} \left[ \frac{\pi_\theta(a|s)}{\pi_{\theta_\text{old}}(a|s)} \hat{A}(s,a) \right] 
 \quad \mbox{subject to} \quad \mathbb{E}_{s} \left[ D_{\text{KL}} \left( \pi_{\theta_\text{old}} \| \pi_\theta \right) \right] \leq \delta
\]
}
%\end{multline}
%   
where $D_{\text{KL}}$ is the Kullback-Leibler (KL) divergence, $\hat{A}(s,a)$ is the advantage estimate, and $\delta$ is a small positive value controlling the step size. However, TRPO is computationally expensive due to the need for second-order optimization to enforce the KL-divergence constraint.

Proximal Policy Optimization (PPO)~\cite{schulman2017ppo} simplifies TRPO by replacing the hard constraint on policy updates with a penalty or by using a clipped objective function. The key idea behind PPO is to ensure that policy updates are ``proximal'' to the current policy, preventing drastic updates that could lead to instability. 

In this work, we use PPO with \textit{clipped objective}. In this approach, PPO clips the probability ratio $\frac{\pi_\theta(a|s)}{\pi_{\theta_\text{old}}(a|s)}$ to lie within a small interval around 1, preventing large updates. The clipped objective is defined as:
{\small
\[
L^{\text{CLIP}}(\theta) = \mathbb{E} \bigg[ \min \big( r(\theta) \hat{A}(s,a), \text{clip}(r(\theta), 1 - \epsilon, 1 + \epsilon) \hat{A}(s,a) \big) \bigg],
\]
}
%\begin{multline}
%    L^{\text{CLIP}}(\theta) = \mathbb{E} \bigg[ \min \big( r(\theta) \hat{A}(s,a), \\
%    \text{clip}(r(\theta), 1 - \epsilon, 1 + \epsilon) \hat{A}(s,a) \big) \bigg],
%\end{multline}
%    
where $r(\theta) = \frac{\pi_\theta(a|s)}{\pi_{\theta_\text{old}}(a|s)}$ is the probability ratio, and $\epsilon$ is a small hyperparameter that limits how far the policy is allowed to change. By clipping the probability ratio, PPO discourages overly large updates while still allowing for sufficient exploration of the policy space.


