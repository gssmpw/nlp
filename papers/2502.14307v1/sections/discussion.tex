
\section{Discussion}

\subsection{Limitations}

While our RL framework demonstrates promising results in discovering microarchitectural vulnerabilities, it is important to acknowledge its current limitations:

\paragraph{Exploration Focus}
While the framework is effective at generating instruction sequences that trigger vulnerabilities, it does not account for the entire system's attack surface. For example, vulnerabilities involving interactions between hardware and software, such as operating system mitigations or compiler optimizations, are not explicitly explored.

In this work, we did not consider the impact of other system configurations such as Hyperthreading, TSX, SGX, AVX, HW prefetch, previous mitigations, Kernel Samepage Merging, ASLR, page table layout, etc. on the \Mi vulnerabilities. We leave this for future work.


\paragraph{Sparse and Delayed Rewards}
Within the search space, only a small fraction of instruction sequences would indicate a vulnerability, assuming the design went through a thorough security review previously. The delayed nature of rewards, which depends on the cumulative effect of multiple instructions, further complicates learning. Therefore, reward signal is sparse and delayed, making it challenging for the agent to learn the optimal policy.


\paragraph{Incomplete CPU State Observability}
Our framework relies on performance counters and partial state observations to infer microarchitectural behavior. However, it cannot directly access internal processor states or transient microarchitectural effects that are not captured by these counters. This black-box approach may miss vulnerabilities that require finer-grained or privileged insights into CPU internals. More subtle vulnerabilities can potentially be detected by the deployment of $\mu$RL on processors by the chip vendors for an internal security review.
%
% \paragraph{Limited Hardware and Configuration Coverage}
% Our experiments were conducted on a limited number of CPU models with specific configurations. Factors such as hyper-threading, TSX, SGX, prefetching, and cache hierarchy variations were not systematically explored. This restricts the generalizability of the results to untested hardware and configurations.
%
% \paragraph{Action Space Constraints}
% While the hierarchical action space reduces complexity, it may inadvertently omit combinations of instructions or operands that could lead to unique vulnerabilities. The reliance on vendor-documented instruction sets also excludes undocumented or proprietary instructions, potentially missing vulnerabilities that exploit these features.
%
%
% \paragraph{Impact of System Noise}
% External factors, such as OS-level noise, scheduling artifacts, and variability in power and thermal states, can affect the consistency of performance counter readings and reward calculations. Such variability can introduce noise into the learning process, reducing the reproducibility and accuracy of the results. 
%
% \paragraph{Vulnerability Prioritization}
% The framework does not inherently prioritize the discovered vulnerabilities based on their real-world exploitability or security impact. As a result, some vulnerabilities identified by the RL agent may have limited practical relevance or exploit potential.
%
Addressing these limitations in future work will further enhance the robustness and generalizability of $\mu$RL, enabling more comprehensive microarchitectural vulnerability discovery.

\subsection{Scalability}

% The scalability of the RL framework involves extending its application to different vulnerabilities, CPU microarchitectures, and hardware platforms such as GPUs. Below, we discuss strategies for scaling in each dimension:

\paragraph{Scaling Across Vulnerabilities}
The framework can be adapted to discover diverse classes of vulnerabilities (e.g., cache-based, transient execution) by modifying the reward function to prioritize unique microarchitectural signals and by incorporating domain-specific performance counters.

\paragraph{Scaling to Different CPU Microarchitectures}
Dynamic environment generation enables the framework to model distinct architectural features of various CPUs. Transfer learning can be employed to initialize RL agents using policies trained on similar architectures, reducing the computational overhead of adapting to new designs. Indeed, we have shown that some of the vulnerabilities discovered on one CPU can be transferred to another CPU, such as MMX-x87 and \texttt{VERW}.

\paragraph{Scaling to Heterogeneous Hardware}
To support hardware like GPUs, the action space and environment must be tailored to GPU-specific instruction sets and execution models. This involves building GPU-aware environments that simulate instruction behavior and adapting performance metrics, such as memory throughput and warp divergence, as observation signals.

\paragraph{Parallel and Distributed Execution}
Scaling the framework for large-scale exploration across diverse hardware is feasible through parallelization and distributed training. By leveraging multiple nodes and cores, the framework can simultaneously evaluate instruction sequences on varied architectures.

% \paragraph{Validation Across Platforms}
% Extensive validation on CPUs (e.g., Skylake-X, Raptor Lake) and GPUs demonstrates the framework's adaptability, enabling scalable vulnerability discovery across heterogeneous systems.
