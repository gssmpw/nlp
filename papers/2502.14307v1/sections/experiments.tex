%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{Experiment Setup}
We run the experiments on two systems with different \Mi. The first system has an Intel Core i9--7900X CPU with a Skylake-X \Mi. The OS running on the system is Ubuntu 22.04.5 LTS with the Linux v6.5.0--44-generic. We use glib v2.72.4, nasm v2.15.05, and gcc v11.4.0 for compiling and testing the generated assembly files; PyTorch v2.2.1, Stable Baselines3 v2.2.1 and Gymnasium v0.29.1 for custom RL environment and training the RL agent. 
The RL agent training and the local inference for the text embedding model are done on the GPU clusters with an NVIDIA TITAN Xp, GeForce GTX TITAN X, and two GeForce GTX 1080Ti. The overview of the experiment setup used in the first system is illustrated in Figure~\ref{fig:experiment_setup}.

The second system has an Intel i9-14900K CPU with a Raptor Lake \Mi, Ubuntu 24.04.1 LTS with Linux v6.8.0-51-generic, glib v2.80.0, nasm v2.16.01, gcc v13.3.0. Pytorch v2.4.1+cu121, Stable Baselines3 v2.3.2, and Gymnasium v0.29.1 are used for the same purposes as the first system. The RL agent training is done on NVIDIA GeForce RTX 4090 GPU.

% \begin{table*}[h]
%     \centering
%     \begin{tabular}{ccccc}
%         \toprule
%         CPU & \Mi & Launch Date & Linux Kernel & OS \\
%         \midrule
%         Intel Core i9--14900K  & Raptor Lake & Q4'23 & v6.8.0-49-generic & Ubuntu 24.04.1 LTS \\
%         Intel Core i9--7900X & Skylake-X & Q2'17 & v6.5.0--44-generic & Ubuntu 22.04.5 LTS \\
%         \bottomrule
%     \end{tabular}
%     \caption{Tested CPU setups}
%     \label{tab:example_3x3}
% \end{table*}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/experiment_setup.pdf}
    \caption{Experiment Setup on Skylake-X. Each physical core shown in green was allocated to a single instruction sequence at a time.}\label{fig:experiment_setup}
\end{figure}


For remote inference, we use OpenAI's  \texttt{text-embedding-3-small} model through the API access, which allows us to use the parallel core testing since it does not require local GPU memory. Parallelizing the framework across multiple CPU cores enables multiple sequences to be evaluated simultaneously and increases the training speed. Although the last level cache is shared among the cores, each process accesses its own distinct memory region, which does not include any shared libraries or data. Therefore, the cache interference among the processes is minimal.

For local inference, we used the NV-Embed-v2~\cite{lee2024nv,moreira2024nv} embedding model. However, we observed that it does not accelerate the training overall since the GPU memory is not enough to enable parallel core testing. Therefore, the results presented in this paper are based on the text-embedding-3-small model.

%
In the Skylake-X system, after filtering all illegal instructions from~\cite{abel19a}, we are left with 12598 instructions that belong to 74 sets. The largest set has 2192 instructions, and the maximum number of possible operands per instruction is 7. These numbers determine the size of the action space for the RL agent. 
%
In the Raptor Lake system, 3996 instructions that belong to 72 sets were left after filtering. The largest set has 468 instructions, and the maximum number of operands per instruction is 7.


For the agent training, we enable all available kernel mitigations against CPU vulnerabilities.
 %
Cumulatively, we collected ~27 days' worth of data from Skylake-X and ~20 days' worth of data from Raptor Lake. In the longest runs, we trained an RL agent for ~4.5 days and ~10.5 days for Skylake-X and Raptor Lake, respectively.
In total, the cost for embedding model inference through API calls was 2.46 USD.
% openai cost calculation
%jan 25  - $0.02
%Dec 24  - $0.23
%Nov 24  - $0.44
%Oct 24  - $1.77
%sum: $2.46

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/reward_spark.png}
    \caption{The increase of the average reward per episode during the ~10 days of agent training in Raptor Lake. An episode corresponds to the largest instruction sequence the agent can generate from scratch. The darker line shows the running mean.}
    \label{fig:reward_plot}
\end{figure}


During the RL agent training, we observe that the average reward of each episode increases over time, as shown in Figure~\ref{fig:reward_plot}. The steady increase in reward indicates that the RL agent was able to successfully explore the x86 instruction set while exploiting the knowledge we provide through the reward signal.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/episode_length.png}
    \caption{The increase of the average length of generated assembly sequences during the $\sim$10 days of agent training in Raptor Lake. The darker line shows the running mean.}
    \label{fig:episode_length}
\end{figure}

At every episode, the agent starts building an instruction sequence from scratch and keeps adding a new instruction until the instruction limit is reached or the sequence gives an exception with the last added instruction. Over time, we observe that the average length of an instruction sequence during an episode increases during the agent training, as shown in Figure~\ref{fig:episode_length}. Increasing average length over time indicates the agent was able to learn to select combinations of instructions to avoid exceptions.
In our experiments, the maximum sequence length was chosen as 10 assembly instructions, after which the agent starts building a new sequence.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discovered Transient Execution Vulnerabilities}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

When the agent builds an instruction sequence that results in observable transient execution, it is saved for manual analysis with performance counter and data leakage information. Figure~\ref{fig:scatter} shows the visualization of generated instructions over time. Since the sequences with high reward stands out from the rest of the generated snippets, it eases the manual analysis and verification as well. After analyzing the generated data, we were able to identify \textbf{eight} new classes of transient execution mechanisms that had previously not been documented to the best of our knowledge. Note that, each class has many variations among the generated dataset. Yet here we present, the most simplified versions of the each class.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/scatter.png}
    \caption{Visualization generated instruction sequences across time, with higher byte leakage marked with lighter colors. Note that, the discovered transient execution mechanisms stand out as it has higher reward compared to the remaining ones.}

    \label{fig:scatter}
\end{figure}


\paragraph{Masked Exceptions}
The studies in \cite{ragab2021rage,chakraborty2024shesha} demonstrated that FP assists due to denormal numbers cause transient execution of the following instructions.
Our RL agent generated instruction sequences that cause observable byte leakage through transient execution without generating any $\mu$code assists, faults, or interrupts. Listing~\ref{lst:masked_fp} shows an example of such an instruction sequence. 
%
After careful analysis, we noticed that the sequence indeed causes an FP exception, but the exception is masked by the processor, and the program execution is uninterrupted. 
%
Previous works reported transient execution with page faults, device-not-available~\cite{Lipp2018meltdown,stecklina2018lazyfp,moghimi2020medusa} which requires exception handling and $\mu$code assists such as FP assists~\cite{ragab2021rage,chakraborty2024shesha} which requires specially crafted inputs.
%
Transient execution through masked FP exceptions has not been previously reported in the literature, which makes it a new discovery for our RL agent.

We observed this behavior on only Skylake-X.

\begin{figure}[h]
    
\begin{lstlisting}[caption=A simplified instruction sequence that triggers masked FP exception due to repeated x87 instruction in line 4. Following cache encoding instructions (line 8-10) get executed speculatively., label={lst:masked_fp}]
generated_assembly_function:
%rep N
    FLD     qword [x]
%endrep
    FCOMI   st0, st1
    JE      exit:
    ; cache encoding
    MOVZX   rax, byte [%rdi]
    SHL     rax, 10
    MOV     rax, qword [rsi+rax]
exit:
    RET
\end{lstlisting}

\end{figure}

\paragraph{Transitions Between MMX and x87}
FP exceptions, by default, are masked and do not cause a trap, and the program continues execution. However, starting from glibc v2.2, it is possible to unmask them using \texttt{feenableexcept} functions from \texttt{fenv.h} library. This function allows the FP exceptions to cause a trap and the program to be interrupted.

After masked exceptions we run another training session with the same configuration but with the \texttt{feenableexcept} function enabling \texttt{FE\_INVALID}, \texttt{FE\_DIVBYZERO}, \texttt{FE\_OVERFLOW}, \texttt{FE\_UNDERFLOW}, and \texttt{FE\_INEXACT} bits of the \texttt{excepts} argument. 

With this configuration, the RL agent was still able to generate instruction sequences that cause observable byte leakage through transient execution without generating any $\mu$code assists, faults, or interrupts. Listing~\ref{lst:mmx_x87} shows an example of such an instruction sequence.


\begin{figure}
    
\begin{lstlisting}[caption=A simplified version of the RL generated assembly instruction sequence that has MMX (line 3) to x87 (line 4) transition. Following cache encoding instructions (line 9-11) get executed speculatively., label={lst:mmx_x87}]
generated_assembly_function:
%rep N
    PSUBQ MM2, [R15]
    FCOMIP ST4
%endrep
    VCMPPD K3, ZMM1, ZMM4, 2
    JNE exit
    ; cache encoding
    MOVZX   rax, byte [%rdi]
    SHL     rax, 10
    MOV     rax, qword [rsi+rax]
    exit:
    RET
    \end{lstlisting}
\end{figure}

After simplifying the instruction sequence, we observed that the transient execution is caused by an FP exception that is generated by the \texttt{FCOMIP} instruction. However, the MMX instruction before the \texttt{FCOMIP} instruction causes the exception to get lost. We use the \texttt{feenableexcept} function to unmask FP exceptions, yet the exception generated in the processor gets cleared by the \texttt{PSUBQ} instruction. Even though the exception is cleared, the following instructions are executed speculatively, and the transient execution is observed. Note that the comparison instruction \texttt{VCMPPD} does not have any dependency on the previous instructions, yet it is still executed speculatively, and removing the AVX instructions from the sequence does not break the transient execution.

In Intel documentations~\cite{intel-sdm}, it is advised that after the MMX instructions, \texttt{EMMS} instruction should be used to clear the FPU state to prevent ``undefined behavior''. We verified that adding an \texttt{EMMS} instruction after the MMX instruction makes the FP exception cause a trap.

Following the convention~\cite{ragab2021rage}, we provide leakage rate analysis on MMX-x87 transient execution mechanism with changing iterations and leakage granularities as shown in Figure~\ref{fig:merged-mmx-87-leak-rates}. Unlike the Masked Exceptions, we observed leakage through MMX-x87 in both \Mi we analyzed. Interestingly, in Skylake-X, the highest leakage rate, 2.3 Mb/s was achieved through 1-bit granularity and with iteration N=3. The second high was 1.9 Mb/s with 8-bit granularity. Between N=3 and N=$\sim$150, we do not observe any leakage. In Raptor Lake, the leakage appears at N>200 with up to 233 Kb/s.

\begin{figure}[htp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/SKYLAKE_MMX_X87_all_leak_rate_vs_iter_leak_granularity.png}
        \caption{Skylake-X}
        \label{fig:mmx-x87-leak-rate-skylake}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/MMX_X87_all_leak_rate_vs_iter_leak_granularity.png}
        \caption{Raptor Lake}
        \label{fig:enter-label}
    \end{subfigure}
    \caption{Leakage rate vs repetitions of the instruction pattern for MMX-x87. Note that in (a) the leakage rates peak when Iteration N=3 for every granularity. In (b), darker lines are running mean and the shades are rolling variance around the mean.}
    \label{fig:merged-mmx-87-leak-rates}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=\columnwidth]{figures/SKYLAKE_MMX_X87_all_leak_rate_vs_iter_leak_granularity.png}
%     \caption{Leakage rate vs repetitions of the instruction pattern measured in Skylake-X. The leakage rates peak when Iteration N=3 for every granularity.}
%     \label{fig:mmx-x87-leak-rate-skylake}
% \end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=\linewidth]{figures/MMX_X87_all_leak_rate_vs_iter_leak_granularity.png}
%     \caption{MMX-x87 on Raptor Lake}
%     \label{fig:enter-label}
% \end{figure}

\paragraph{\texttt{SERIALIZE} Instruction}
Speculative execution vulnerabilities in modern processors allow attackers to observe transient execution behavior and infer secret data. This section analyzes the behavior of the \texttt{SERIALIZE} instruction in the context of speculative execution and demonstrates how it can inadvertently facilitate information leakage under certain conditions.

Intel's documentation states that the \texttt{SERIALIZE} instruction ``serializes instruction execution, ensuring all modifications to flags, registers, and memory by previous instructions are complete before subsequent instructions are fetched and executed" \cite{intel-sdm}. This behavior includes "draining all buffered writes to memory'' \cite{intel-sdm}, providing a robust barrier for instruction execution order. However, our experiments reveal that \texttt{SERIALIZE}, when executed repeatedly alongside specific instructions, does not always halt speculative execution effectively. This observation was made during experiments designed to measure speculative execution behavior and leakage patterns.


The instruction sequences given in Listing~\ref{lst:seq_combined} were executed repeatedly, with observed effects on speculative execution:
\begin{figure}[h]
\centering
\begin{lstlisting}[caption={Sequences 1, 2, and 3: Showing various data leak behaviors through \texttt{SERIALIZE}.}, label={lst:seq_combined}]
; Sequence 1: leaks beginning of the secret
%rep N
SERIALIZE
RDGSBASE EAX
VAESDECLAST YMM0, YMM2, yword [R15]
%endrep

; Sequence 2: leaks end of the secret
%rep N
SERIALIZE
RDGSBASE EAX
%endrep

; Sequence 3: no leak
%rep N
SERIALIZE
VAESDECLAST YMM0, YMM2, yword [R15]
%endrep
\end{lstlisting}

\end{figure}

Sequence 1 leaked the beginning of the secret, revealing fragments.
Sequence 2 leaked the end of the secret, revealing fragments.
 Sequence 3 did not result in any observable data leakage.

Interestingly, the first two sequences caused a measurable increase in \texttt{RECOVERY\_CYCLES}, indicating that the Resource Allocation Table (RAT) checkpoints were recovering after speculative execution. No increase in Machine Clear counters, $\mu$code assists, or exceptions was observed.

While \texttt{SERIALIZE} is intended to act as a speculation barrier, its behavior in combination with other instructions, such as \texttt{RDGSBASE} and \texttt{VAESDECLAST}, can inadvertently permit transient execution to proceed. This transient execution creates a window where secret data can be accessed speculatively and leaked through side channels. 

Figure~\ref{fig:serialize_leak_rate} shows the leakage rate analysis with the changing number of iterations. The largest leakage rate observed is 230 Kb/s with 4-bit leakage granularity in Raptor Lake. We did not observe leakage in Skylake-X.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/SERIALIZE_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leakage rate vs repetitions of the instruction pattern for \texttt{SERIALIZE} instruction measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean.}
    \label{fig:serialize_leak_rate}
\end{figure}

\paragraph{\texttt{VERR}/\texttt{VERW} Instructions}
The VERR (Verify Read) and VERW (Verify Write) instructions are employed to confirm if a memory segment can be read or written from the current privilege level. These instructions are crucial for security protocols, ensuring that less privileged code cannot access or alter segments belonging to more privileged levels. These instructions modify the Zero Flag based on whether a segment is readable or writable.
%
Although these are obsolete instructions, VERW instruction has recently given an additional functionality that wipes off the microarchitectural buffers in efforts to mitigate MDS attacks~\cite{intel2021mds} from the software.

$\mu$RL discovered instruction sequences given in Listing~\ref{lst:verw} that cause observable transient execution with both VERW and VERR instructions. Interestingly, we do not observe a leakage with VERW alone, without the instruction given in line 4.
%
On Skylake-X \Mi, VERW achieved up to 2.2 Mb/s leakage rate, and 1-bit and 8-bit leakage granularity are close to each other. The complete data is given in Appendix~\ref{sec:verw_skylake}. Note that Skylake-X is one of the microarchitectures vulnerable to MDS attacks, and a microcode patch was issued for the VERW mitigation functionality.
%
On Raptor Lake, VERW achieved up to 3.7 Mb/s and 2.1 Mb/s leakage rates with 1-bit and 8-bit leakage granularities, respectively. With 4-bit, we observed 279 Kb/s leakage rate.  VERR achieved up to 207 Kb/s leakage rate with 4-bit leakage granularity, only in Raptor Lake.
%
The relation between the iteration and leakage rates are given in Figure~\ref{fig:merged-leak-rates-verw-verr}.

\begin{figure}[h]
\begin{lstlisting}[caption=Instruction sequences with leakage through \texttt{VERW} and \texttt{VERR}., label={lst:verw}]
;leaks through VERW
%rep N
VERW word [R15]
LZCNT EDX, dword [R15]
%endrep

;leaks through VERR
%rep N
VERR AX
%endrep
\end{lstlisting}
\end{figure}

% \begin{figure}[h]
% \begin{lstlisting}[caption=Instruction sequence with leakage through \texttt{VERR}, label={lst:verr}]

% \end{lstlisting}
% \end{figure}


\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/VERW_all_leak_rate_vs_iter_leak_granularity.png}
        \caption{\texttt{VERW}}
        \label{fig:verw_list}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{figures/VERR_all_leak_rate_vs_iter_leak_granularity.png}
        \caption{VERR}
        \label{fig:verr_list}
    \end{subfigure}
    \caption{Leakage rates for \texttt{VERW} and \texttt{VERR} instructions measured in Raptor Lake. In (b) Darker lines are running mean and the shades are rolling variance around the mean.}
    \label{fig:merged-leak-rates-verw-verr}
\end{figure}


\paragraph{CLMUL Instructions}
The CLMUL instruction set is designed to accelerate cryptographic operations by performing carry-less multiplication on 128-bit operands. This is particularly useful in cryptographic algorithms like AES and GCM, where polynomial multiplications over GF($2^{128}$) are required, and carry propagation is not needed.
Listing~\ref{lst:CMUL} shows an RL-generated sequence which includes \texttt{PCLMULQDQ} which is one of the CLMUL instructions.

We observed leakage only in Raptor Lake with up to 90 Kb/s with 4-bit granularity as shown in Figure~\ref{fig:cmul_leak_rate}.


\begin{figure}[h]
\begin{lstlisting}[caption=Instruction sequence with leakage through \texttt{CMUL}, label={lst:CMUL}]
;leaks through PCLMULQDQ
%rep N
PCLMULQDQ XMM4, [R15], 2
VCVTPS2PH XMM0, YMM0, 2
LOCK CMPXCHG16B [R15]
%endrep
\end{lstlisting}
\end{figure}



\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/CLMUL_all_leak_rate_vs_iter_leak_granularity.png}
    \caption{Leake rates for CLMUL measured in Raptor Lake. Darker lines are running mean and the shades are rolling variance around the mean.}
    \label{fig:cmul_leak_rate}
\end{figure}


\paragraph{Miscellaneous}
We observed leakage with the combination of other instructions such as LSL+RDSCP, LAR+RDSCP, LAR+MULX, LAR+ADCX+CMOVNL, LAR+PREFETCHWT1, etc. However, to save space, we give some of them in the Appendix~\ref{sec:misc}.

\begin{table*}[t]
    \centering
    \begin{tabular}{ccccccc}
        \toprule
        Mechanism & \multicolumn{2}{c}{Skylake-X} & \multicolumn{2}{c}{Raptor Lake} \\ 
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
                  & Availability & Leakage Rate [Kb/s] & Availability & Leakage Rate [Kb/s] \\ 
        \midrule
        FP Assist~\cite{ragab2021rage} & \cmark & 222 & \cmark & 306 \\ 
        SMC~\cite{ragab2021rage} & \cmark & 235 & \cmark & 481 \\ 
        BHT~\cite{Kocher2018spectre} & \cmark & 169 & \cmark & 305 \\ 
        Exception w/ Handler~\cite{Lipp2018meltdown} & \cmark & 217 & \cmark & 280 \\ 
        TSX~\cite{Lipp2018meltdown} & \cmark & 227 & \xmark & N/A$^*$ \\ 
        MD~\cite{ragab2021rage} & \cmark & 225 & \cmark & 276 \\ 
        XMC~\cite{ragab2021rage} & \cmark & <1 & \cmark & 395 \\ 
        MO~\cite{ragab2021rage}& \cmark & 235 & \cmark & 7 \\
        Masked FP Exception \textbf{(This work)} & \cmark & 214 & \xmark & 0 \\
        MMX-x87 \textbf{(This work)} & \cmark & 213 & \cmark & 233 \\
        SERIALIZE \textbf{(This work)}& \xmark & 0 & \cmark & 230 \\ 
        VERW \textbf{(This work)}& \cmark & 218 & \cmark & 279 \\   
        VERR \textbf{(This work)}& \xmark & 0 & \cmark & 207 \\   
        CLMUL \textbf{(This work)}& \xmark & 0 & \cmark & 90 \\ 
        LSL+RDSCP \textbf{(This work)}& \xmark & 0 & \cmark & 210 \\ 
        LAR \textbf{(This work)}& \xmark & 0 & \cmark & 30 \\ 

        \bottomrule
    \end{tabular}
    \caption{Comparison of availability and leakage rates of different transient execution mechanisms in Intel Skylake-X and Raptor Lake microarchitectures with 4-bit leakage granularity.*The TSX instruction set extension is not available in Raptor Lake. The remaining \xmark ~marks show the instructions are supported, yet we do not observe leakage.}
    \label{tab:placeholder_label}
\end{table*}


\section{Exploitability of Discovered Transient Execution Mechanisms}
In this section, we show how Meltdown-like vulnerabilities can be exploited without having TSX or exception handling, thanks to discovered instruction sequences by $\mu$RL.

The original Meltdown exploit~\cite{Lipp2018meltdown}, where an attacker uses transient execution to leak data from kernel memory, has been mitigated by KPTI implemented in the Linux Kernel. However, mitigations like KPTI are application-specific, and they mitigate only one element in the attack chain, in this case, the availability of kernel addresses mapped in the virtual memory. Yet, the root cause for the transient execution has not been mitigated in the hardware. Therefore, we argue that different applications can potentially still be vulnerable and be exploited using different transient execution mechanisms. Since finding new software applications vulnerable to transient execution is not part of the scope of this work, we adopt the original Meltdown setup. 
For the proof of concept, we disable KPTI on the Linux kernel.

Using the $\mu$RL generated instructions sequence shown in Figure~\ref{fig:poc}, we trigger transient execution of the following memory access in line, which is an illegal access to kernel memory. Speculative load from the kernel memory is then encoded into the cache so that we can decode it later using Flush+Reload.

In this experiment, we were able to read a pre-chosen secret value from the kernel memory without using a fault handler or TSX instruction set. This result demonstrates how $\mu$RL generated instructions sequences can be exploited, and they can be used as alternatives to the known attack vectors.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/POC.png}
    \caption{Proof of concept code that demonstrates the use of RL-generated MMX-x87 transient execution mechanism for reading the physical memory.}
    \label{fig:poc}
\end{figure}
