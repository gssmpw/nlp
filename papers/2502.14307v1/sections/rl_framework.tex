%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Our RL Framework}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/RL.pdf}
%    \caption{Overview of the RL framework for \Mi vulnerability analysis.\\
%    \footnotesize \makebox[\textwidth]{\hfill$\bigoplus$: Concatenation operation\hfill}}
    \caption{\label{fig:rl_framework}Overview of the RL framework for \Mi vulnerability analysis; $\bigoplus$ before the \textit{Observation} denotes concatenation. $\bigoplus$ before \textit{Reward} represents Equation~\ref{eq:reward}.}
\end{figure*}

In this section, we introduce our RL framework designed for \Mi vulnerability analysis.
% challenges
Automated analysis of \Mi vulnerabilities poses the following challanges some of which were also identified in earlier works~\cite{weber2021osiris,moghimi2020medusa,chakraborty2024shesha}:

\begin{itemize}[nosep, leftmargin=*]
\item \textbf{C1.} Modern processor designs are complex and their instructions sets are large. Exhaustive search in the instruction space is infeasible. % using rl
\item \textbf{C2.} Mapping an instruction sequence to a certain \Mi vulnerability is non-trivial and requires expert knowledge. % reward shaping
\item \textbf{C3.} The environment is high-dimensional and non-linear and the system state is only partially observable. %, and the agent must infer it from performance counters and other indirect signals. % obseration
\end{itemize}

%\item What is the state/observable in the system that the agents will see and generate actions? In Alpha-Dev, they use CPU Memory/Register state embeddings.
% \item How are we going to consider the effect of HW and SW configuration? Such as Hyperthreading, TSX, SGX, AVX, HW prefetch, previous mitigations, Kernel Samepage Merging, ASLR etc.
% \item What will be the reward function for a given action?
%\item Which RL library/algorithm to use?
% \item What should be the maximum size for an attack sequence?

Earlier works attempted to solve \textbf{C1} by either limiting the type of instructions~\cite{chakraborty2024shesha,oleksenko2023hide} or limiting the length of the instruction sequence~\cite{weber2021osiris}. In this work, we propose a novel approach to address this challenge by leveraging RL to guide the search for \Mi vulnerabilities. Our framework is designed to efficiently explore the instruction space, learn the optimal policy for selecting instruction sequences, repoduce known vulnerability and, if exists, discover unknown vulnerabilities. The framework is illustrated in Figure~\ref{fig:rl_framework} and consists of the following components:
% list: rl agent, filtered instruction set, current state, dynamic testing on CPU, text embedding model, reward function

\subsection{Environment} We build a custom environment based on the underlying CPU model. The environment represents a black-box model of the CPU microarchitecture, where the agent can only interact with the CPU through the instruction sequences. It takes the instruction sequences generated by the RL agent, executes them on the CPU, and returns an observation and a reward.
It also updates the state after every action taken. 

%\paragraph{Environment Initialization and Reset}

At the start of each episode, the environment initializes by resetting the instruction state and clearing the performance counter readings. A reset function is triggered at the beginning of each new episode to ensure the agent starts with a fresh state.
%
All sequences, performance metrics, and detected byte leakages are logged for post-training analysis. The logged data aids in identifying patterns or characteristics in sequences that lead to vulnerabilities and provides insights into the agent's decision-making process.

\subsection{RL Agent} The RL agent is a multi-layer perceptron (MLP) that generates actions based on observations given by the environment. In this case, the agent's goal is to select an instruction that will be appended to the instruction sequence. The agent is trained using the PPO algorithm. The goal of the agent is to maximize the reward signal by selecting the best sequence of actions and eventually trigger \Mi vulnerabilities.

\subsection{Action Space} 
We define an action as the selection of an assembly instruction from the instruction set. To map the discrete actions to actual assembly instructions, we use~\cite{abel19a}.
The action space is constrained to instructions that are supported by the CPU under test and documented by the vendor. This constraint helps the agent focus on relevant instructions that exist in the real-world programs. Since some of the instruction extensions has large number of instructions and operand variety, (e.g. AVX-512), we construct the action space hierarchically. For example, we first select the instruction set (e.g. AVX-512), then the instruction (e.g. \texttt{VMOVDDUP}), and finally the operands (e.g. \texttt{XMM0}, \texttt{XMM1}). This hierarchical structure helps prevent larger instructions sets dominating the smaller ones since the agent will initially randomly select insturction during the exploration phase. To handle the difference in the number of instructions in each set, we use map different actions to the same insturction or operands using them modulo operation.
For instance, if the maximum number of instructions in a set is 10 but the model selected the $12^{th}$ instruction, we map it to the $12 \bmod 10 = 2^{nd}$ instruction in the selected set.


% \url{https://www.intel.com/content/www/us/en/docs/vtune-profiler/cookbook/2023-0/top-down-microarchitecture-analysis-method.html#GUID-56FBB4D7-9FE8-4336-BDDB-23EA7DD2DBC0}

\subsection{State} Eventhough, there are more variables that affect the CPU state other than just the input instruction sequence, such as, cache content, internal buffers, registers, etc., we simplify the state representation to only the instruction sequence. The impact of other factors that affects the CPU state can be minimize by running the same instruction sequence multiple times until the real state becomes stable, which is a common practice in \Mi attacks~\cite{yarom2014flush+, liu2015last}. After each action, the generated assembly instruction is added to the current state.

\subsection{Observation} 
% Challenge\textbf{C3}
Since we do not have access to hardware debug interface, we cannot directly observe the entire state of the CPU. Therefore, it is a \textit{partially observable} environment and the observation can only capture a subset of the environment state as it is mentioned in~\textbf{C3}. We tackle this challange by designing an observation space that consists of a static and a dynamic part.

The static part of the observation is the generated instruction sequence. Similar to the earlier works~\cite{tol2021fastspec,mankowitz2023alphadev}, we use embeddings to convert the instruction sequence into high-dimensional fixed-size vectors using a pre-trained LLM. Embeddings capture the patterns in the assembly code so that the agent understand the structural and functional dependencies between instructions. Before inclusion in the observation space, embeddings undergo normalization to ensure consistency in data scales. 

The dynamic part of the observation is the hardware performance counters. Vendors give access to low-level monitoring of the CPU events such that developers can identify bottlenecks in their applicaitons and optimize the performance. In this work, we use the performance counters to partially capture the CPU state. For  measurement, we embed instruction sequences in a template assembly file, ensuring valid memory addresses in \texttt{R15} register to prevent segmentation faults. General-purpose registers are preserved on the stack to avoid unintended corruption. Each sequence is executed multiple times to minimize noise.

\begin{table}[h!]
    \centering
    \footnotesize
    \begin{tabular}{lll}
    \toprule
    \textbf{HW Performance Event Name} \\
    \midrule
    UOPS\_ISSUED.ANY  \\
    UOPS\_RETIRED.RETIRE\_SLOTS \\
    INT\_MISC.RECOVERY\_CYCLES\_ANY  \\
    MACHINE\_CLEARS.COUNT \\
    MACHINE\_CLEARS.SMC \\
    MACHINE\_CLEARS.MEMORY\_ORDERING \\
    FP\_ASSIST.ANY$^a$ \\
    OTHER\_ASSISTS.ANY$^b$ \\
    CPU\_CLK\_UNHALTED.ONE\_THREAD\_ACTIVE \\
    CPU\_CLK\_UNHALTED.THREAD \\
    HLE\_RETIRED.ABORTED\_UNFRIENDLY$^c$ \\
    HW\_INTERRUPTS.RECEIVED$^d$ \\
    \bottomrule
    \end{tabular}
    \caption{List of used CPU performance events available in Skylake-X. In Raptor Lake, corresponding events: $a$-- ASSISTS.FP, $b$--ASSISTS.ANY, $c$--N/A, $d$--N/A.}\label{tab:cpu_events}
\end{table}

% \begin{landscape}
%     \vspace*{\fill} % Add vertical space before the table
%     \begin{table}[!h]
%         \centering
%         \renewcommand{\arraystretch}{1.2} % Adjust row spacing for readability (optional)
%         \caption{List of used CPU performance events available in Intel Core i9-7900X with descriptions}
%         \begin{tabular}{l l}
%         \toprule
%         \textbf{Event Name} & \textbf{Description} \\
%         \midrule
%         UOPS\_ISSUED.ANY & Number of micro-ops issued by the front end \\
%         UOPS\_RETIRED.RETIRE\_SLOTS & Retired micro-ops (allocation slots) \\
%         INT\_MISC.RECOVERY\_CYCLES\_ANY & Cycles the allocator was stalled to recover from machine clear \\
%         MACHINE\_CLEARS.COUNT & Total number of machine clears \\
%         MACHINE\_CLEARS.SMC & Machine clears due to self-modifying code \\
%         MACHINE\_CLEARS.MEMORY\_ORDERING & Machine clears due to memory ordering issues \\
%         FP\_ASSIST.ANY & Cycles with SSE or FP assist \\
%         OTHER\_ASSISTS.ANY & Number of ucode assists excluding the FP assists \\
%         CPU\_CLK\_UNHALTED.ONE\_THREAD\_ACTIVE & Cycles when at least one thread was active \\
%         CPU\_CLK\_UNHALTED.THREAD & Cycles during which the specific thread was active \\
%         HLE\_RETIRED.ABORTED\_UNFRIENDLY & Hardware lock elision retired events aborted due to unfriendly execution \\
%         HW\_INTERRUPTS.RECEIVED & Hardware interrupts received \\
%         \bottomrule
%         \end{tabular}
%         \label{tab:cpu_events}
%     \end{table}
%     \vspace*{\fill} % Add vertical space after the table
% \end{landscape}



We use the performance counters listed in Table~\ref{tab:cpu_events}. The explanation of these counters are given in the Appendix~\ref{sec:hpc_descriptions}. 
These counters are selected based on their relevance to speculative execution vulnerabilities shown by previous research~\cite{ragab2021rage,oleksenko2023hide,chakraborty2024shesha} as well as Intel's performance monitoring tools~\cite{intel_perfmon}.

\subsection{Reward Function}\label{sec:reward}

The reward function is often seen as the most critical component of the RL frameworks since it steers the agent behavior. We address the challenge \textbf{C2} by carefully designing the reward function.

The instruction sequences selected by the agent are executed on the CPU, and the CPU's behavior is monitored using hardware performance counters. The counters provide feedback on the speculative execution and microarchitectural effects of the instructions.

The reward function evaluates the performance counter data collected during instruction execution. It assigns rewards based on the presence of speculative execution anomalies, deviations from expected behavior, or other indicators of potential vulnerabilities. 
    
% while optimizing for larger amounts of bad speculation while the code executes as well as speculative execution of following instructions.
%
\begin{equation}\label{eq:reward}
    \begin{aligned}
        \text{Reward} &= \frac{\textit{bad speculation} + \textit{observed byte leakage} }{\textit{instruction count}}
    \end{aligned}
\end{equation}
%
Equation~\ref{eq:reward} shows a simplified version of the reward function we use for training the RL agent. The reward is calculated by dividing the sum of bad speculation and observed byte leakage by the number of instructions in the sequence. 
The final reward value is capped at 100 if $\textit{observed byte leakage} = 0$ and 500 if $\textit{observed byte leakage}>0$ to prevent excessive rewards, promoting stable training. The numbers were decided based on the empirical results.

\paragraph{Testing for Bad Speculation}
According to Intel's documentation~\cite{intel_vtune_2023}, ``\textit{bad speculation}'' typically results from branch mispredictions, machine clears and, in rare cases, self-modifying code. 
It occurs when a processor fills the instruction pipeline with incorrect operations due to mispredictions. This process leads to wasted cycles, as speculative micro-operations (uops) are discarded if predictions are incorrect, forcing the processor to recover and restart. Although bad speculation is primarily a concern for performance, it also has important security implications.
%
Microarchitectural attacks exploit transient states created by bad speculation. During speculation, the CPU may access sensitive data or load it into the cache, even though the operations will eventually be discarded. These transient states, particularly in cache memory, create opportunities for attackers to infer sensitive data—such as encryption keys—by analyzing cache behaviors and measuring access times. %Because such attacks target the hardware-level behavior, they are difficult to detect with conventional software-based security measures.

Intel's formula for quantitatively measurement of \textit{bad speculation} for a CPU thread is
\begin{multline}
    \text{Bad\ Speculation} = \text{UOPS\_ISSUED.ANY} \\
    - \text{UOPS\_RETIRED.RETIRE\_SLOTS} \\
    + \left( 4 \times \text{INT\_MISC.RECOVERY\_CYCLES} \right)
\end{multline}
which also what we use in our reward function. 

If there is an exception detected during the performance counter tests, we terminate the episode, set the reward to -10 and reset the state. We select this number arbitrarily to differentiate between instruction sequences with no bad speculation vs instruction sequences that do not execute at all. Negative reward discourages the agent from generating exceptions. Note that, handling the exceptions is also possible, but it complicates the reward calculation. Therefore, we leave it for future work.

\paragraph{Testing for Observable Byte Leakage}

% speculation_test.pdf
\begin{figure}[h]
    \vspace{-4mm}
        \centering
        \includegraphics[width=\columnwidth]{figures/leakage_test.pdf}
        \caption{Test flow for detecting observable byte leakage.}\label{fig:leakage_test}
    \end{figure}
    
If the performance counter tests executes successfully, we check if the generated instruction sequence results in observable byte leakage due to speculative execution.
Our testing flow for detecting observable byte leakage is shown in Figure~\ref{fig:leakage_test}.

We, first, place the instruction sequence in a template assembly file and run it \texttt{N} times using \texttt{rep} directive. 
Similar to performance counter tests, we use predefined addresses for memory operands and preserve the contents of the general purpose registers in the stack.
Then, we execute a comparison operation based on the instructions types and registers used in the generated sequence. If there are multiple types of registers used in the sequence, we select a different comparison instruction specific to that register type. We repeat the test flow for each register type used in the sequence. This way we avoid false negatives due to the register type mismatch.
After the comparison, we execute a conditional branch instruction (jump if equal--\texttt{JE}) which is followed by cache accesses to an array that encode a predefined sequence of bytes to the cache state. We then measure the access time to the array using Flush+Reload~\cite{yarom2014flush+} to decode the bytes and check if it how much it matches with the encoded bytes.
If there is any match, we repeat the same test, this time with the opposite branch condition (jump if not equal--\texttt{JNE}). If there is a match in this case, we consider it as an observable byte leakage. 

Note that, most of the generated seqences fail either in the first or second step of the leakage test. For the remaining sequences that passed the first two tests, we run the same two test after inserting \texttt{lfence} before the branch instruction. If the leakage disappears after adding \texttt{lfence}, we consider it as a successful sequence that causes observable byte leakage through bad speculation. Note that, unlike Spectre-BHT~\cite{kocher2019spectre}, we do not train the branch predictor in the test flow so the root cause of the bad speculation would not be the branch mispredictions unless the generated sequence has the branch predictor training itself using branch instructions.

We repeat the test flow for each register type used in the sequence. This way we avoid false negatives due to the register type mismatch.
The number of successfully decoded bytes are fed into the reward function as the observable byte leakage. Since the byte leakage is a more direct signal of the vulnerability, we assign a higher weight to it in the reward function.
 %
If an exception is detected at this stage, the environment resets to a safe state, logs the exception. Only the byte leakage part of the reward is set as zero, yet the bad speculation part is calculated as usual. 

