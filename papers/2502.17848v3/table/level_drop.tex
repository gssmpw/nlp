\begin{table*}[t]
    \centering
    \resizebox{0.7\textwidth}{!}{
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{l|ccccc|ccccc}
        \toprule
        \multirow{2}{*}{\textbf{Model}} &  \multicolumn{5}{c|}{\textbf{Drop Quote - Easy}} & \multicolumn{5}{c|}{\textbf{Drop Quote - Hard}} \\
        \cmidrule(l){2-11}
        & CR & S-Acc & EM & PM-0.5 & Tokens & CR & S-Acc & EM & PM-0.5 & Tokens \\
        \midrule
        \rowcolor{gray!15} \multicolumn{11}{l}{\textit{\textbf{Open-source LLMs}}}\\
        \midrule 
Llama-3.1-8B-Instruct & 38.0 & 9.6 & 0.0 & 2.0 & 1692 & 50.0 & 12.8 & 0.0 & 0.0 & 2553 \\
Llama-3.1-70B-Instruct & 86.0 & 32.7 & 0.0 & 22.0 & 1298 & 78.0 & 22.7 & 0.0 & {\ul 2.0} & 1698 \\
Llama-3.3-70B-Instruct & {\ul 98.0} & 33.1 & 0.0 & 24.0 & 900 & \textbf{100.0} & 24.9 & 0.0 & {\ul 2.0} & 936 \\
Mistral-7B-Instruct-v0.3 & 72.0 & 8.9 & 0.0 & 2.0 & 2193 & 60.0 & 4.3 & 0.0 & 0.0 & 2480 \\
Mistral-Small-Instruct-2409 & {\ul 98.0} & 30.5 & 0.0 & 12.0 & 1357 & 96.0 & 23.3 & 0.0 & 0.0 & 1873 \\
Mistral-Large-Instruct-2411 & {\ul 98.0} & 29.4 & 0.0 & 18.0 & 1429 & {\ul 98.0} & 20.0 & 0.0 & 0.0 & 1702 \\
Qwen2.5-7B-Instruct & \textbf{100.0} & 24.9 & 0.0 & 8.0 & 1500 & 96.0 & 18.9 & 0.0 & 0.0 & 2204 \\
Qwen2.5-32B-Instruct & {\ul 98.0} & 33.5 & 0.0 & {\ul 26.0} & 1084 & 92.0 & 23.3 & 0.0 & {\ul 2.0} & 1310 \\
Qwen2.5-72B-Instruct & 96.0 & \textbf{35.5} & 0.0 & 24.0 & 1505 & 92.0 & {\ul 26.2} & 0.0 & {\ul 2.0} & 2009 \\
QwQ-32B-Preview & 32.0 & 9.6 & 0.0 & 14.0 & 5987 & 34.0 & 5.4 & 0.0 & {\ul 2.0} & 6169 \\
DeepSeek-R1 & \textbf{100.0} & \textbf{54.6} & \textbf{14.0} & \textbf{58.0} & 11202 & \textbf{100.0} & \textbf{40.1} & 0.0 & \textbf{26.0} & 11643 \\
        \midrule
        \rowcolor{blue!15} \multicolumn{11}{l}{\textit{\textbf{Closed-source LLMs}}}\\
        \midrule
Gemini-2.0-flash & 92.0 & 37.2 & 0.0 & 28.0 & 2149 & 92.0 & \textbf{31.3} & 0.0 & 6.0 & 3286 \\
Gemini-2.0-flash-thinking & {\ul 96.0} & 38.8 & 0.0 & {\ul 38.0} & 3621 & {\ul 96.0} & {\ul 30.0} & 0.0 & {\ul 8.0} & 3150 \\
GPT-4o & \textbf{98.0} & 34.8 & 0.0 & 24.0 & 1125 & \textbf{100.0} & 27.3 & 0.0 & 4.0 & 1205 \\
o1-mini & \textbf{98.0} & {\ul 41.4} & {\ul 4.0} & 36.0 & 14130 & 94.0 & 27.1 & 0.0 & 6.0 & 12380 \\
o1-preview & \textbf{98.0} & \textbf{49.6} & \textbf{18.0} & \textbf{56.0} & 13064 & {\ul 96.0} & 27.9 & \textbf{8.0} & \textbf{20.0} & 14126 \\
        \bottomrule
    \end{tabular}}    
    \caption{Performance (\%) of LLMs on Drop Quote across all difficulty levels. The best and second-best results are highlighted in \textbf{bold} and \underline{underlined}, respectively. "Tokens" denotes the average number of generated tokens.}
    \label{level_drop}
\end{table*}