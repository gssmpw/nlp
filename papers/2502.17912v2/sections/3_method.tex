% \vspace{-3mm}
\section{Methodology}
% \vspace{-3mm}
\subsection{Revisiting Graph EBM for OOD Detection}
\vspace{-2mm}
Different from image data, the graph data is neither continuous nor i.i.d. The inherent challenge is how to define and train an EBM over $(\rvx,\mathcal{N}(\rvx))$. 
Since $\mathcal{N}(\rvx)$ is discrete, potentially huge, and includes arbitrary neighbor nodes, it is hard to sample $\mathcal{N}(\rvx)$ by MCMC for training EBM.

\begin{wrapfigure}[12]{r}{0.3\textwidth}
\vspace{-4.5mm}
  \centering
  \includegraphics[width=0.95\linewidth]{Images/toy_ebm_new.jpg}
  \vspace{-10pt}
  \caption{Visualization comparison on 2D data.}
  \label{fig:toy_ebm}
\end{wrapfigure}

To avoid such challenge, GNNSafe~\citep{wu2023gnnsafe} proposes to train the EBMs by maximizing the conditional likelihood $\log p_\energy(y|\rvx) = \tfrac{\exp(-E_{\energy}(\rvx,y))}{\sum_{y'} \exp(-E_{\energy}(\rvx, y'))}$ via node classification, where $E_{\energy}(\rvx,y) = -f_{\energy}(\rvx, \mathcal{N}(\rvx))_{[y]}$ and $f_{\energy}(\cdot, \cdot)$ is a classifier. 
Finally, the energy score of each node can be regarded as OOD score, i.e., $\mathcal{S}(\rvx, \mathcal{N}(\rvx)) = E_{\energy}(\rvx)=-\log \sum_y \exp(-E_{\energy}(\rvx,y))$.

The EBMs trained in this way exhibit limitations in terms of capability and a heavy reliance on sufficient labeled data. In particular, it has not been trained for modeling the marginal data distribution, resulting in an inferior ability to capture the data distribution.
For instance, it may falter even when tasked with handling a simple 2D dataset, i.e., 8 Gaussians  (\cref{fig:toy_ebm}). This indicates that the energy constructed by the classification logits does not effectively capture the underlying data distribution. Consequently, such methods intuitively face challenges in addressing OOD detection for graph data, particularly when labeled data are scarce.



\vspace{-2mm}
\subsection{Overview of Our Method: \shortname}
\vspace{-2mm}
The framework of our proposed method is shown in \cref{fig:framework}. 
\shortname first utilizes a graph encoder trained by GCL algorithm~\citep{dgi} to extract node representations $\rvh = g_\enc(\rvx, \mathcal{N}(\rvx)) \in \R^{d}$. 
In this way, the topology information of the original graph is well-encoded into $\rvh$, such that the follow-up steps can be free from $\A$. 
Next, a $K$-step MCMC sampling is applied over the low-dimensional latent space $\Tilde{\rvh} \sim q_{\dec}(\Tilde{\rvh})$ to learn an energy function $f_{\dec}$, which is defined as an MLP. 
Please see~\cref{sec:training_clebm} for detailed training algorithm.

\vspace{-2mm}
\subsection{Our Design}
\vspace{-1mm}
\label{sec:our_design}
The powerful capability of EBM comes from its minimal restrictions on modeling, but at the same time, this is also a double-edged sword that leads to difficult learning. To address the difficulty of defining EBMs on graphs, we propose to restrict EBM modeling formulation to some extent. Specifically, we suggest decomposing EBM into two parts: the first part focuses on extracting graph structural information, and the second part is dedicated to learning the energy.

For node $\rvx$ and its neighbor $\mathcal{N}(\rvx)$, we can define the EBM as $E_\energy(\rvx) = f_\dec \circ g_\enc (\rvx,\mathcal{N}(\rvx))$, 
where $g_\enc(\rvx,\mathcal{N}(\rvx)) = \rvh \in \mathbb{R}^d$ is a graph encoder that focuses on extracting the graph structural information, 
and $f_\dec(\rvh)\in \mathbb{R}$ is an energy function that outputs the energy score. 

Suppose we have a fixed $g_\enc$ that learns graph structural information well, following~\cref{eq:ebm_loss}, the EBM loss for learning $f_{\dec}$ can be reformulated as:
\begin{equation*}
\begin{aligned}
    % \loss_\dec 
    \loss_{\text{ebm}}
    & = \E_{p_d(\rvx,\mathcal{N}(\rvx))} \Big[ f_\dec(\texttt{sg}[g_\enc(\rvx_i,\mathcal{N}(\rvx))]) \Big] - \E_{p_\energy(\rvx,\mathcal{N}(\rvx))} \Big[ f_\dec(\texttt{sg}[g_\enc(\rvx_i,\mathcal{N}(\rvx))]) \Big] \\
    & = \E_{p_\enc(\rvh)}\Big[ f_\dec(\texttt{sg}[\rvh]) \Big] - \E_{q_{\energy}(\rvh)} \Big[ f_\dec(\texttt{sg}[\rvh]) \Big]
    \iff \mathrm{KL} \Big( p_\enc(\rvh) \| q_\energy(\rvh) \Big),
 \end{aligned}
\end{equation*}
where $p_\enc(\rvh) = \int p_d(\rvx)\delta(\rvh - g_\enc(\rvx))d\rvx$ and $q_\energy(\rvh) = \int p_\paramf(\rvx)\delta(\rvh - g_\enc(\rvx))d\rvx$ are the aggregated distribution over latent space of real data and EBM samples, respectively.


It can be observed that the optimal solution is achieved at $p_\enc(\rvh)=q_\energy(\rvh)$, and optimizing the objective actually equals minimizing the KL divergence between two distributions over latent space. Hence we can formulate a surrogate optimization objective for directly learning a latent EBM $f_{\dec}$:
\begin{equation}
\label{eq:lebm_obj}
    \mathrm{KL} \Big( p_\enc(\rvh) \| q_\dec(\rvh) \Big) 
    \iff \E_{p_\enc(\rvh)} \Big[ f_{\dec}(\rvh) \Big] - \E_{q_\dec(\rvh)} \Big[ f_{\dec}(\rvh) \Big],
\end{equation}
where $q_\dec(\rvh) = \frac{\exp(-f_\dec(\rvh))}{Z_\dec}$. Sampling from $q_\dec(\rvh)$ can be achieved by running $K$-step MCMC sampling. 
By the surrogate objective, we can move the MCMC sampling from $(\rvx,\mathcal{N}(\rvx))$ space to the informative latent space, avoiding the awkward and challenging scenarios of needing to sample nodes under high-dimension and their neighbors.

A left challenge is obtaining a flexible $g_\enc$ to extract graph topology information. 
We suggest utilizing Graph Contrastive Learning (GCL) algorithm for training the graph encoder to extract node representations. 
This can not only extract informative features but also deal with the limited labeled data case. Among graph contrastive learning methods, we propose using DGI~\citep{dgi} as the learning algorithm for $g_\enc$. 
Intuitively, DGI contrasts between nodes and the whole graph, while the OOD detection task requires detecting the outliner nodes in a whole graph, the contrast between the local features and the global can bring more benefits. 
The effect of different GCL algorithms will be shown in~\cref{sec:ablation}.  


DGI first shuffles the rows of node features matrix to get an augmented graph $\{ \mathbf{X}', \A' \}$, 
then obtains node representations by $\rvh_i = g_\enc( \rvx_i, \mathcal{N}(\rvx_i) )$ and $\rvh'_j = g_\enc( \rvx'_j, \mathcal{N}(\rvx'_j) )$, respectively. 
The contrastive loss for learning $g_{\enc}$ is given by:
\begin{equation}
\begin{aligned}
\label{eq:cl_obj}
    \loss_{\text{cl}}(\rvh,\bm{s})  = - \frac{1}{2N} \left( \sum_{i=1}^{N}\log D_{\disc}(\rvh_i,\bm{s}) + \sum_{j=1}^{N}\log( 1-D_{\disc}(\rvh'_j,\bm{s}) ) \right),
\end{aligned}
\end{equation}
where $\bm{s} = \frac{1}{N}\sum_{i=1}^{N}\rvh_i \in \R^{d}$ is the summary readout of all the node representations, 
which can be regarded as a global view of the whole graph. 
Following DGI~\citep{dgi}, we use a bilinear scoring function for the discriminator $D_{\disc}(\cdot,\cdot)$, which is also learned by minimizing $\loss_{\text{cl}}$.


Additionally, the node representations $\rvh_i$ can be further enhanced by ID nodes classification with a prediction head $I_{\cls}$ (e.g., MLP) as $\hat{\rvy}_i = I_{\cls}(\rvh_i)$, 
and the cross-entropy loss $\loss_{\text{cls}}$ is used for learning the prediction head $I_{\cls}(\cdot)$ and also graph encoder $g_{\enc}(\cdot, \cdot)$. 

\spara{Multi-Hop (MH) Graph Feature Encoder}
Simply using a one-layer GCN, as in DGI~\citep{dgi}, cannot fully extract informative representations from original graph features. 
Additionally, similar nodes often lie in the distance in heterophilic graphs, so combining long-range information could bring positive effects in addressing heterophily issue. 
Therefore, a $L$-layer GNN is employed to learn graph node features in our proposed method. 
Furthermore, the weighted self-loops technique is used as a simple enhanced method for graph filter~\citep{fagcn2021,lsgnn}. 
Finally, all the intermediate features (the output of all the layers) are fused to obtain the final representations. 

First, a symmetric normalized adjacency with weighted self-loops is used for extracting node features: 
\begin{equation}
\begin{aligned}
    \mathbf{X}^{(\ell)} = \left( \beta \I + \D^{-\frac{1}{2}}\A\D^{-\frac{1}{2}} \right) \mathbf{X}^{(\ell-1)}, \ \ \ 
    \mathbf{X}^{(0)} = \mathbf{X}, 
    \label{eq:enc_1}
\end{aligned}
\end{equation}
where $\beta$ is a hyper-parameter. 
Note that this operation for the positive samples can be done in preprocessing since it does not involve any learnable parameters, which greatly reduce the running time. 
Then the intermediate features are transformed and fused to obtain the final representations: 
\begin{equation}
\begin{aligned}
    \hid = \left[ \hid^{(0)} \| \hid^{(1)} \| \cdots \| \hid^{(L)} \right] \W_{\text{enc}} + \bm{b}_{\text{enc}}, \ \ \ \hid^{(\ell)} = \mathbf{X}^{(\ell)}\W^{(\ell)} + \bm{b}^{(\ell)}, 
    \label{eq:enc_2}
\end{aligned}
\end{equation}
where $\W$ and $\bm{b}$ are learnable weights and bias. $\|$ is a concatenation operation. 
The combination of~\cref{eq:enc_1,eq:enc_2} is denoted by $\hid = g_\enc(\mathbf{X}, \A)$. 

\spara{Conditional Energy (CE)}
The readout summary $\bm{s}$ of ID dataset can be used as supervised information in energy function $f_{\dec}$, to compare between node representations and global representations when computing energy. 
For instance, $f_{\dec} (\rvh_i, \bm{s}) = \W[\rvh_i \| \rho\bm{s}]+\bm{b} $, $f_{\dec} (\rvh_i, \bm{s}) = \rvh_i^{\top} \W \bm{s}$, and etc., 
where $\rho$ is a hyper-parameter, $\W$ and $\bm{b}$ are learned parameters. The benefit of the global information introduced by the proposed CE is twofold: 1) It can guide MCMC sampling, reducing the sampling difficulty; 2) It can act as global prior information when detecting OOD nodes.


\spara{Energy Readout (ERo)}
In DGI, the readout summary $\bm{s}$ is obtained by simply averaging all the node representations $\bm{s} = \frac{1}{N}\sum_{i=1}^{N}\rvh_i$. 
However, the importance of each node may not be the same. Considering that the density of a node can represent the importance of the node to some extent and energy is un-normalized density, we propose to use energy for conducting the weighted readout:
\begin{equation}
\begin{aligned}
    \notag
    \bm{s}_p = \gamma\sum_{i=1}^{N}\bar{p}_i \rvh_i + \left(1-\gamma\right)\frac{1}{N}\sum_{i=1}^{N}\rvh_i
    =  \sum_{i=1}^{N} \left( \gamma\bar{p}_i + \frac{1-\gamma}{N} \right) \rvh_i, 
\end{aligned}
\end{equation}
where 
$\bar{p}_i = \operatorname{softmax} ( -f_{\dec} (\rvh_i) ) = \frac{\exp(-f_{\dec} (\rvh_i))}{\sum_{j=1}^{N}\exp(-f_{\dec} (\rvh_j))}\in\R$ is the weight, 
and $\gamma$ is a hyper-parameter for a trade-off between weight average and direct average. 

\subsection{Recurrent Update For Learning \shortname}
\label{sec:recur_update}
To apply CE and ERo simultaneously, the energy readout $\bm{s}_p$ and conditional energy $f_{\dec} (\rvh_i, \bm{s})$ should be updated recurrently. The Recurrent Update can make energy function $f_{\dec}$ and graph encoder $g_\enc$ promote each other, leading to better learning.
Next, we introduce the Recurrent Update in details. The weights of conditional energy are initialized as uniform distribution $\bar{\bm{p}}^{(0)} = \left[ \frac{1}{N}, \frac{1}{N}, \cdots, \frac{1}{N} \right] \in \R^{N}$. 
In the $e$-th epoch, node representations of original graph $\{ \mathbf{X}, \A \}$ and shuffled graph $\{ \mathbf{X}', \A' \}$ are first obtained by $\rvh_i = g_\enc( \rvx_i, \mathcal{N}(\rvx_i) )$ and $\rvh'_j = g_\enc( \rvx'_j, \mathcal{N}(\rvx'_j) )$, respectively, and $\Tilde{\rvh}_u\sim q_{\dec}(\Tilde{\rvh})$ is sampled by $K$-step MCMC sampling, then the final learning at each iteration is conducted as follows:


\noindent\textbf{Step 1: Learning energy head $f_{\dec}$ given graph encoder $g_{\enc}$}:
The energy head $f_{\dec}$ is learned by MLE over informative latent space by a surrogate objective given the well-trained graph encoder $g_{\enc}$ and according global representation $\bar{\bm{s}}_p^{(e)}$:
\vspace{-5pt}
\begin{equation*}
\begin{aligned}
    &\bar{\bm{s}}_p^{(e)} = \sum_{i=1}^{N} \left( \gamma\bar{p}_i^{(e-1)} + \frac{1-\gamma}{N} \right) \texttt{sg}[\rvh_i], \\
    &\loss_{\dec} = \loss_{\text{ebm}} = \frac{1}{N}\sum_{i=1}^{N} f_{\dec}(\texttt{sg}[ \rvh_i ], \bar{\bm{s}}_p^{(e)}) - \frac{1}{M}\sum_{u=1}^{M} f_{\dec}(\texttt{sg}[\Tilde{\rvh}_u], \bar{\bm{s}}_p^{(e)}). 
\end{aligned}
\end{equation*}
\vspace{-10pt}


\noindent\textbf{Step 2: Learning graph encoder $g_{\enc}$ given energy head $f_{\dec}$}:
The Graph Encoder $g_{\enc}$ is learned by the mix of graph contrastive learning and node classification given well-trained energy head $f_{\dec}$ for weighted readout as follows:
\vspace{-5pt}
\begin{equation*}
\begin{aligned}
    &\bar{p}_i^{(e)} = \operatorname{softmax} \Big( - f_{\dec}(\texttt{sg}[ \rvh_i ], \bar{\bm{s}}_p^{(e)}) \Big), \\
    &\bm{s}_p^{(e)} = \sum_{i=1}^{N} \left( \gamma\bar{p}_i^{(e)} + \frac{1-\gamma}{N} \right) \rvh_i, \\
    & \loss_{\enc,\disc,\cls} = \loss_{\text{cl}}(\rvh,\bm{s}_p^{(e)}) + \xi \loss_{\text{cls}}(I_{\cls}(\rvh), \rvy), 
\end{aligned}
\end{equation*}
\vspace{-10pt}

where $\xi$ is a hyper-parameter, $\loss_{\text{cls}}$ is the cross-entropy loss. See \cref{algo:training_clebm} for the detailed learning process.

\spara{Inference}
For an unknown node $\rvx_v$, its representation is obtained by $\rvh_v=g_{\enc}(\rvx_v, \mathcal{N}(\rvx_v))$, then the energy score $f_{\dec}(\rvh_v, \bm{s}^{(E)})$ serves as the OOD score, where $\bm{s}^{(E)}$ is the summary readout of ID dataset in the final training epoch, and its label prediction is computed by $\hat{\rvy}_v=I_{\cls}(\rvh_v)$. 

\subsection{Understanding of Using DGI for Learning Graph Encoder}
\label{sec:dgi_theory}
By comparing \cref{eq:cl_obj} and \cref{eq:lebm_obj}, it can be found that there are some similarities between these two objectives. Actually, the learning of DGI can be understood as learning an EBM with global condition by noise contrastive estimation~\citep{ncpvae,ncp} as the following form:
\vspace{-5pt}
\begin{equation}
    \notag
    \loss_{\text{cl}} = \E_{p_d(\rvx,\mathcal{N}(\rvx))} \Big[ r(\rvx,\mathcal{N}(\rvx)|\bm{s}) \Big] -  \E_{q(\rvx,\mathcal{N}(\rvx))} \Big[ r(\rvx,\mathcal{N}(\rvx)|\bm{s}) \Big],
\end{equation}
where $q(\rvx,\mathcal{N}(\rvx)) = \int q(\rvx,\mathcal{N}(\rvx)| \Tilde{\rvx},\mathcal{N}(\Tilde{\rvx}),\bm{s})p_d(\Tilde{\rvx},\mathcal{N}(\Tilde{\rvx}))d\Tilde{\rvx}$, $q(\rvx,\mathcal{N}(\rvx)| \Tilde{\rvx},\mathcal{N}(\Tilde{\rvx}),\bm{s})$ denotes the density of augmented samples given data samples, and $r(\rvx,\mathcal{N}(\rvx)|\bm{s}) = D_{\disc}( g_\enc(\rvx,\mathcal{N}(\rvx)), \bm{s})$. After perfectly training, the optimal $r$ has following form $r^*(\rvx,\mathcal{N}(\rvx)|\bm{s}) = \frac{p_d(\rvx,\mathcal{N}(\rvx)|\bm{s})}{p_d(\rvx,\mathcal{N}(\rvx)|\bm{s}) + q(\rvx,\mathcal{N}(\rvx)|\bm{s})}$. 
The inherent connection between DGI and EBM enables the effectiveness of constructing energy function by the learned $g_\enc$. However, the optimal DGI learns the density ratio between data distribution and randomly augmented data distribution, which is unsuitable for OOD detection, hence it still needs to learn $f_\dec$ for output energy.
