\documentclass[acmtog,authorversion,nonacm]{acmart}
\citestyle{acmauthoryear}
%anonymous,review
\usepackage{booktabs} % For formal tables

% TOG prefers author-name bib system with square brackets
\citestyle{acmauthoryear}
%\setcitestyle{nosort,square} % nosort to allow for manual chronological ordering

\usepackage{xcolor}  % 允许自定义颜色
\usepackage{hyperref} % 启用超链接支持

\usepackage{multirow}
\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\usepackage{float} 
% Metadata Information
\acmJournal{TOG}
\usepackage{graphicx}
\usepackage{booktabs} % For nicer tables
\usepackage{array} 


% Title portion
\def\mytitle{VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer}

\begin{document}

\begin{teaserfigure}
\centering
\includegraphics[width=1.0\textwidth]{Figs/teaser.pdf}
        \caption{\textbf{VFX Creator} is an efficient framework based on a Video Diffusion Transformer, enabling spatial and temporal control for visual effect (VFX) video generation. With minimal training data, a plug-and-play mask control module allows precise instance-level manipulation, while the integration of tokenized start-end motion timestamps with text space provides fine-grained temporal control over the VFX rhythm.
}
\label{fig:illustration}
\end{teaserfigure}

% DO NOT ENTER AUTHOR INFORMATION FOR ANONYMOUS TECHNICAL PAPER SUBMISSIONS TO SIGGRAPH 2019!
\author{Xinyu Liu}
\affiliation{%
 \institution{Hong Kong University of Science and Technology}
 \country{China}}
\email{xliugd@connect.ust.hk}
\author{Ailing Zeng}
\affiliation{%
 \institution{Tencent AI Lab}
 \country{China}
}
\email{ailingzengzzz@gmail.com}
\author{Wei Xue}
\affiliation{%
 \institution{Hong Kong University of Science and Technology}
 \country{China}
}
\email{weixue@ust.hk}
\author{Harry Yang}
\affiliation{%
\institution{Hong Kong University of Science and Technology}
\country{China}}
\email{yangharry@ust.hk}
\author{Wenhan Luo}
\affiliation{%
 \institution{Hong Kong University of Science and Technology}
 \country{China}
}
\email{whluo@ust.hk}
\author{Qifeng Liu}
\affiliation{%
 \institution{Hong Kong University of Science and Technology}
 \country{China}}
\email{liuqifeng@ust.hk}
\author{Yike Guo}
\affiliation{%
 \institution{Hong Kong University of Science and Technology}
 \country{China}
}
\email{yikeguo@ust.hk}
% \author{\noindent\textbf{Project Page:} \url{https://vfx-creator0.github.io/}}
%\renewcommand\shortauthors{Zhou, G. et al}
\makeatletter
\def\@mkboth#1#2{\@mkbothcustom{#1}}
\def\@mkbothcustom#1{\markboth {\mytitle}{\mytitle}}
\makeatother

\title{VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer}
\begin{abstract}

Crafting magic and illusions stands as one of the most thrilling facets of filmmaking, with visual effects (VFX) serving as the powerhouse behind unforgettable cinematic experiences. While recent advances in generative artificial intelligence have catalyzed progress in generic image and video synthesis, the domain of controllable VFX generation remains comparatively underexplored. More importantly, fine-grained spatial-temporal controllability in VFX generation is critical, but challenging due to data scarcity, complex dynamics, and precision in spatial manipulation. In this work, we propose a novel paradigm for animated VFX generation as image animation, where dynamic effects are generated from user-friendly textual descriptions and static reference images. Our work makes two primary contributions: \textbf{i) Open-VFX}, the first high-quality VFX video dataset spanning 15 diverse effect categories, annotated with textual descriptions, instance segmentation masks for spatial conditioning, and start–end timestamps for temporal control; This dataset features a wide range of subjects for the reference images, including characters, animals, products, and scenes. \textbf{ii) VFX Creator}, a simple yet effective controllable VFX generation framework based on a Video Diffusion Transformer. The model incorporates a spatial and temporal controllable LoRA adapter, requiring minimal training videos. Specifically, a plug-and-play mask control module enables instance-level spatial manipulation, while tokenized start-end motion timestamps are embedded in the diffusion process accompanied by the text encoder, allowing precise temporal control over effect timing and pace. Extensive experiments on the Open-VFX test set with unseen reference images demonstrate the superiority of the proposed system to generate realistic and dynamic effects, achieving state-of-the-art performance and generalization ability in both spatial and temporal controllability. Furthermore, we introduce a specialized metric to evaluate the precision of temporal control. By bridging traditional VFX techniques with generative techniques, the proposed VFX Creator unlocks new possibilities for efficient, user-friendly, and high-quality video effect generation, making advanced VFX accessible to a broader audience.

\end{abstract}


\maketitle
\input{samplebody-journals}



\end{document}
