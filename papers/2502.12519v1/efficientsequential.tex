%\subsection{Efficient Sequential Implementation}
\begin{lemma}\label{lem:efficient_test} For any $0 < \eta < 1$, all neighborhood similarity tests $|N[x] \Delta N[y]| \leq_{\eta} 2\phi$ for $xy \in E^{+}$ can be performed and with correct answers w.h.p.~in $O(\eta^{-2} m \log n)$ time. Therefore, $\Gsim$ can be constructed correctly w.h.p.~in $O(\eta^{-2} m \log n)$ time.\end{lemma}

\begin{proof}
By \Cref{lem:test}, it suffices to show that $||A \cdot \vec{N}[x] - A \cdot \vec{N}[y]||^2_{2}/k$ can be computed for all $xy \in E^{+}$ in $O(\eta^{-2} m \log n)$ time for $k = O(\log n /\eta^2)$, where $A$ is a $k \times n$ matrix drawn from $\{-1, +1\}^{k \times n}$ uniformly at random. 

For each node $v \in V$, we will sample a vector $A_v \in \{-1, +1\}^k$ and so $A = (A_{v_1} \cdots A_{v_n})$. Note that for each $x$, $A \cdot \vec{N}[x] = \sum_{v \in N[x]} A_v$ can be computed in $O(\deg(x)\cdot k)$ time and $A \cdot \vec{N}[x]$ is a $k$-dimension vector. For every edge $xy \in E^{+}$, $A\cdot \vec{N}[x] - A\cdot \vec{N}[y]$ can be computed in $O(k) = O(\eta^{-2} \log n)$ time. Therefore, $\Gsim$ can be constructed in $O(\eta^{-2 }m \log n)$ time.
\end{proof}


\begin{lemma}[Item \ref{itm:main1} of \Cref{thm:thmmain}]
\label{lemma:mainresultsequential}
Given a min-max correlation clustering instance $G = (V, E^{+})$, for any constant $\epsilon > 0$, there exists a randomized sequential algorithm that outputs a clustering that is a $(3 + \epsilon)$-approximation for min-max correlation clustering. This algorithm succeeds with high probability and runs in $O(m \log^2 n / \epsilon^2)$ time.
\end{lemma}
\begin{proof}
By \Cref{lem:efficienthighdeg}, Line \ref{ln:highdegstart}--Line \ref{ln:highdegend} of Algorithm~\ref{alg:lp} can be replaced by \Cref{alg:highdegclustering}, which computes a clustering $\mathcal{F} = \mathcal{L}$ for high-degree graphs provided $\OPT \leq \phi$. Let $\eta = \epsilon$, by \Cref{lem:efficient_test}, $\Gsim$ can be constructed in $O(m \log n /\epsilon^2)$ time. The rest of \Cref{alg:highdegclustering} can be performed in $O(m)$ time sequentially as they involve sending $O(1)$ messages along each edge of $\Gsim$. 

Line \ref{ln:upper}--Line \ref{ln:lower} of Algorithm~\ref{alg:lp} involves $O(m)$ neighborhood similarity tests in total, which can again, be done in $O(m \log n /\epsilon^2)$ time by \Cref{lem:efficient_test}. Line \ref{ln:checking} of Algorithm ~\ref{alg:lp} needs to compute the objective function of the clustering constructed. This can be done in $O(m)$ time by scanning through $N(u)$ for each $u \in G$.
Finally, the binary search on $\phi$ introduces at most $O(\log n)$ calls of \Cref{alg:lp}, so the total running time is $O(m \log^2 n / \epsilon^2)$.
\end{proof}

\exactthreeapprox*
\begin{proof}
Here we implement the algorithm with $\eta = 0$. The arguments are exactly the same with the proof of \Cref{lemma:mainresultsequential}, except that we will perform each neighborhood similarity query (with $\eta = 0$) in $O(D \log D)$ time. A query can be performed in such time, if we pre-build a balanced binary search tree that stores the neighborhood of each vertex, which takes $O(\sum_{u} d(u) \log d(u)) = O(m D \log D)$ time. Since there are at most $O(\log n)$ calls of \Cref{alg:lp} in the binary search of $\phi$ and we perform at most $O(m)$ such queries for each call, the total time is $O(m (D \log D)(\log n))$.
\end{proof}