\begin{abstract}
Zero-shot \ac{NER} aims to develop entity recognition systems from unannotated text corpora. 
This task presents substantial challenges due to minimal human intervention. 
Recent work has adapted \acfp{LLM} for zero-shot \ac{NER} by crafting specialized prompt templates.
And it advances models' self-learning abilities by incorporating self-annotated demonstrations. 
Two important challenges persist:
\begin{enumerate*}[label=(\roman*)]
\item Correlations between contexts surrounding entities are overlooked, leading to wrong type predictions or entity omissions. 
\item The indiscriminate use of task demonstrations, retrieved through shallow similarity-based strategies, severely misleads \acp{LLM} during inference.
\end{enumerate*}

In this paper, we introduce the \acfi{CMAS}, a novel framework for zero-shot \ac{NER} that uses the collective intelligence of multiple agents to address the challenges outlined above.
\Ac{CMAS} has four main agents:
\begin{enumerate*}[label=(\roman*), nosep,leftmargin=*]
    \item a self-annotator,
    \item a \acf{TRF} extractor,
    \item a demonstration discriminator, and
    \item an overall predictor.
\end{enumerate*}
To explicitly capture correlations between contexts surrounding entities, \ac{CMAS} reformulates \ac{NER} into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence.
To enable controllable utilization of demonstrations, a demonstration discriminator is established to incorporate the self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence.
Experimental results show that \ac{CMAS} significantly improves zero-shot \ac{NER} performance across six benchmarks, including both domain-specific and general-domain scenarios. Furthermore, \ac{CMAS} demonstrates its effectiveness in few-shot settings and with various \ac{LLM} backbones.\footnote{Our code is available at \url{https://github.com/WZH-NLP/WWW25-CMAS}.}
\end{abstract}