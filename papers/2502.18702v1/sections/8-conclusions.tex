\section{Conclusions}
We have focused on named entity recognition in the strict zero-shot setting, where no annotated data is available. Previous approaches still encounter two key challenges: they overlook contextual correlations and use task demonstrations indiscriminately, both of which impede the inference process. To tackle these challenges, we have introduced a new framework, \acfi{CMAS}, which uses the collective intelligence and specialized capabilities of agents. \ac{CMAS} explicitly captures correlations between contexts surrounding entities by decomposing the task into recognizing named entities and identifying entity type-related features. 
To enable controllable use of demonstrations, a demonstration discriminator is established to incorporate a self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence. 
Experiments on six benchmarks, spanning domain-specific and general datasets, show that \ac{CMAS} significantly improves zero-shot \ac{NER} performance and effectively corrects various errors.

Expanding \ac{CMAS} to support open \ac{NER} tasks would be a valuable direction for future research. Future work also includes developing interactive prompt designs, such as multi-turn question answering, to enable LLM-based agents to iteratively refine or assess responses.

% Additionally, pseudo-labels for \acp{TRF} are generated using mutual-information criteria without the need for human effort, thus enhancing the efficiency of the \ac{TRF} extractor. 
% Although \ac{CMAS} achieves state-of-the-art performance, it has limitations. 
% A limitation of \ac{CMAS} is that it primarily focuses on the individual \ac{NER} task.
% A promising direction for future work is extending our multi-agent system to handle multiple IE tasks like named entity recognition, relation extraction, and event extraction simultaneously. 
% A limitation of \ac{CMAS} is that it primarily focuses on a limited set of predefined entity labels. 

