\section{Introduction}
\label{sec:intro-chapter5}
In \ac{NER}, the task is to identify predefined named entities, such as persons, locations, and organizations, based on their contextual semantics within input texts.
\ac{NER} serves as a fundamental task in information extraction and is integral to various downstream natural language processing (NLP) applications, including question answering~\citep{DBLP:conf/aaai/LeeKK23,DBLP:conf/coling/SchmidtBV24}, document understanding~\citep{DBLP:conf/www/ItoN24}, and information retrieval~\citep{DBLP:conf/sigir/GuoXCL09,DBLP:conf/www/FanGMZLC21}. 
Current \ac{NER} methods primarily use fully supervised learning paradigms and show impressive performance across various benchmarks~\citep{DBLP:conf/aaai/WuKWLLC24,DBLP:journals/corr/abs-1909-10649,DBLP:conf/acl/PetersABP17}.
However, these fully-supervised paradigms rely heavily on large-scale, human-annotated data. In real-world scenarios, the availability of annotated data may be restricted to specific domains, severely hindering the generalizability and adaptability of \ac{NER} models~\citep{DBLP:conf/www/ZhangZGH24,DBLP:conf/emnlp/WangZCRRR23}.

\begin{figure*}
  \centering
  \subfigure[Overlooking correlated contexts surrounding entities.]{
    \label{fig:exp-correlations}
    \includegraphics[width=0.46\linewidth]{figures/example-TRFs.pdf}}
    \quad
   \subfigure[Proportions of demonstrations without target entity types.]{
    \label{fig:demonstrations}
    \includegraphics[width=0.46\linewidth]{figures/example-demonstrations.pdf}}
\caption[(a) Examples of incorrect type prediction and entity omission from an existing method~\citep{DBLP:conf/emnlp/XieLZZLW23} due to overlooking correlated contexts surrounding entities. Red texts represent wrongly recognized entities; golden labels are included in the brackets. Blue texts highlight entity \acfp{TRF}, i.e., contexts strongly associated with the entity types. (b) Proportions of selected demonstrations lacking target entity types in the CoNLL03, WikiGold, MSRA~\citep{DBLP:conf/acl-sighan/ZhangQWW06}, and OntoNotes datasets. More than 40\% of demonstrations do not contain any entity types within the target sentence.]{(a) Examples of incorrect type prediction and entity omission from an existing method~\citep{DBLP:conf/emnlp/XieLZZLW23} due to overlooking correlated contexts surrounding entities. Red texts represent wrongly recognized entities; golden labels are included in the brackets. Blue texts highlight entity \acfp{TRF}, i.e., contexts strongly associated with the entity types. (b) Proportions of selected demonstrations lacking target entity types in the WikiGold~\citep{DBLP:conf/acl-pwnlp/BalasuriyaRNMC09}, WNUT-17~\citep{DBLP:conf/aclnut/DerczynskiNEL17}, OntoNotes,\footnotemark{} and BioNLP11~\citep{DBLP:journals/bmcbi/PyysaloORSMWSTA12} datasets. More than 40\% of demonstrations do not contain any entity types within the target sentence.}
  \label{fig:examples}
\end{figure*}

Recently, \acp{LLM} have transformed natural language processing with their zero-shot or few-shot generalization abilities~\citep{meta2024introducing, openai_blog_22, chowdhery2022palm, DBLP:journals/corr/abs-2303-08774}. With their extensive search spaces and large-scale pre-training data, \acp{LLM} have the potential to overcome the challenges of data sparsity and generalizability faced by \ac{NER} models.
Motivated by these developments, one line of prior work explores  prompting techniques to enhance few-shot \ac{ICL} for \ac{NER}~\citep{wang2023gpt}. Other efforts use specialized knowledge to develop task-specific \acp{LLM} for \ac{NER}~\citep{DBLP:journals/corr/abs-2310-03668,DBLP:conf/www/ZhangZGH24,DBLP:conf/iclr/Zhou00CP24} or employ \acp{LLM} as data annotators or generators to augment smaller language models~\citep{DBLP:conf/aaai/MaWKBP024,DBLP:conf/emnlp/JosifoskiSP023}.
However, these approaches still require deliberately selected annotated task examples or external knowledge. The reasoning abilities of \acp{LLM} for zero-shot \ac{NER} remain underexplored.

To address zero-shot \ac{NER}, \citet{wei2023zero} transform this task, where no labeled data is available, into a two-stage question-answe-\\ring process by chatting with \acp{LLM}.
\citet{DBLP:conf/emnlp/XieLZZLW23} conduct a systematic empirical study on zero-shot \ac{NER} using \acp{LLM} and tailor prevalent reasoning methods, such as tool augmentation and majority voting, to adapt ChatGPT for zero-shot \ac{NER}.
Furthermore, to reduce reliance on external tools, \citet{DBLP:journals/corr/abs-2311-08921} enhance the self-learning capabilities of \acp{LLM} through a self-improvement mechanism. Specifically, \acp{LLM} initially annotate unlabeled corpora with self-consistency scores.
Subsequently, for each test input, inference is conducted using \acf{ICL} with demonstrations retrieved from the self-annotated dataset.

Despite these advances, current zero-shot \ac{NER} methods still encounter two challenging problems:

%\vspace*{1mm}
\noindent \textbf{Challenge 1: Overlooking correlations between contexts surrounding entities.}
Prior work~\citep{wei2023zero,DBLP:conf/emnlp/XieLZZLW23, DBLP:journals/corr/abs-2311-08921} focuses exclusively on recognizing entities within the target sentence. However, the contexts surrounding entities of the same type are correlated, and identifying contexts that are strongly associated with entity types plays a crucial role in facilitating the generalization of pretrained language models for the \ac{NER} task~\citep{DBLP:conf/emnlp/WangZCRRR23}. Neglecting these contextual correlations can lead to incorrect type predictions or entity omissions, severely impeding the adaptation of \acp{LLM} to zero-shot scenarios. For instance, as shown in Figure~\ref{fig:exp-correlations}, the existing method~\citep{DBLP:conf/emnlp/XieLZZLW23} fails to recognize ``member'' and ``teams,'' which are closely related to Person entities, in the target sentence, resulting in the omission of the entity ``Atessis.''
To tackle this issue, we propose redefining the traditional \ac{NER} task into two subtasks: recognizing named entities and identifying entity \emph{type-related features} (\acp{TRF}~\citep{DBLP:conf/emnlp/WangZCRRR23}, i.e., tokens strongly associated with entity types). 
% By establishing entity types and \acp{TRF} as code schemas in prompts, we universally transform the extraction process into a series of code generations.

\noindent \textbf{Challenge 2: Indiscriminate use of task demonstrations.}
To enhance task understanding and guide inference, recent zero-shot \ac{NER} methods~\citep{DBLP:conf/emnlp/XieLZZLW23,DBLP:journals/corr/abs-2311-08921} use both task instructions and task-specific demonstrations as input prompts for \acp{LLM}. 
However, these methods employ shallow strategies for demonstration retrieval, such as random sampling and $k$-nearest neighbors, resulting in the frequent emergence of low-quality demonstrations.
For instance, as illustrated in Figure~\ref{fig:demonstrations}, approximately 87.33\% and 76.94\% of selected demonstrations do not contain any target entity types in the test sentences from the WNUT-17 and OntoNotes datasets, respectively. 
The indiscriminate use of unhelpful or irrelevant demonstrations substantially misleads the inference process of \acp{LLM} and degrades models' prediction abilities.
To address this problem, we incorporate a self-reflection mechanism~\citep{DBLP:conf/iclr/AsaiWWSH24,DBLP:conf/nips/ShinnCGNY23}, enabling LLMs to reflect on the helpfulness of retrieved demonstrations and selectively learn from them.

\footnotetext{\url{https://catalog.ldc.upenn.edu/LDC2013T19}}

\noindent \textbf{Contributions.}
Note that existing \acp{LLM} suffer from severe performance degradation with long input contexts~\citep{DBLP:journals/tacl/LiuLHPBPL24,jinllm} and complex instruction following~\citep{DBLP:journals/corr/abs-2402-18243,DBLP:journals/corr/abs-2401-03601}. 
Thus, it is challenging to effectively capture contextual correlations and discriminative use retrieved demonstrations through single-turn or multi-turn dialogues with \acp{LLM}.
Inspired by the demonstrated complex problem-solving capabilities of multi-agent approaches~\citep{DBLP:journals/corr/abs-2309-07864,DBLP:journals/corr/abs-2402-01680}, in this paper, we present a framework, named the \acfi{CMAS} for zero-shot \ac{NER}, harnessing the collective intelligence of LLM-based agents to address the challenges listed.
As Figure~\ref{fig:framework-chapter5} illustrates, \ac{CMAS}  consists of four main agents: (i) a self-annotator, (ii) a type-related feature extractor, (iii) a demonstration discriminator, and (iv) an overall predictor.
First, adopting the self-improving strategy outlined in~\citep{DBLP:journals/corr/abs-2311-08921}, \ac{CMAS} employs an \ac{LLM} as the self-annotator to create self-annotated data through predictions on unlabeled corpora.
Then, to empower the simultaneous extraction of entities and contextual correlations, \ac{CMAS} redefines the \ac{NER} task into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence.
To achieve this, an \ac{LLM}-based type-related feature extractor is developed to pinpoint words or phrases closely related to different entity types from the surrounding contexts using specialized \acf{ICL}.
Additionally, pseudo-labels for \acp{TRF} are generated using mutual information criteria, streamlining the inference process of the \ac{TRF} extractor without requiring human interventions.
Given the entity type features relevant to the target sentence, the demonstration discriminator integrates a self-reflection mechanism~\citep{DBLP:conf/iclr/AsaiWWSH24} to automatically assess the helpfulness of each selected demonstration in making predictions on the target test sentences.
Finally, with the extracted \acp{TRF} and predicted helpfulness scores of demonstrations, the overall predictor performs inference on each incoming test sentence with a two-stage self-consistency strategy~\citep{wang2022self,DBLP:conf/emnlp/XieLZZLW23}, selectively learning from retrieved demonstrations while considering contextual correlations.
Additionally, external tools, such as a syntactic structure analyzer~\citep{DBLP:conf/emnlp/HeC21}, can be used to further enhance \ac{CMAS} (see Section~\ref{subsec:ablation studies}).
% Interestingly, previous \ac{LLM}-based zero-shot \ac{NER} methods~\citep{wei2023zero,DBLP:conf/emnlp/XieLZZLW23,DBLP:journals/corr/abs-2311-08921} can be formulated within the \ac{CMAS} framework (see Sec.~\ref{subsec:Discussions}).
% Besides, \ac{CMAS} is independent of prompt template styles, allowing the incorporation of various types, such as code-style prompts, across different agents (see Sec.~\ref{}).
% Distinct from previous methods, \ac{CMAS} recasts the structured input and output of the \ac{NER} task in the form of code, rather than natural language, to align the \ac{NER} task more closely with the pretraining tasks of 
% In the first stage, following~\citep{DBLP:journals/corr/abs-2311-08921}, we obtain entity predictions using \acp{LLM} through zero-shot prompting with self-consistency~\citep{DBLP:conf/iclr/0002WSLCNCZ23}.
% Moreover, to provide model with the explicit descriptions of unseen entity types, \ac{SRCG} automatically derives entity type definitions based on few-shot, self-annotated examples.
% In the second stage, to facilitate simultaneous extraction of entities and contextual correlations, we adopt Python classes to establish code schema for different entity types and \acp{TRF} in a universal manner.
% In this way, the extraction process is transformed into generating code for instances of predefined Python classes.
% In the third stage, \ac{CMAS} integrates the self-reflection mechanism by inserting a ``reflection'' flag into each code-style demonstration. By completing code for flag prediction functions, \ac{CMAS} automatically assesses the helpfulness of each demonstration to predictions on the target test sentences.

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.92\linewidth]{figures/framework.pdf}
    \caption{An overview of \ac{CMAS}.  The dotted red lines indicate the workflow of an existing method~\citep{DBLP:journals/corr/abs-2311-08921}, which leads to incorrect predictions. In contrast, the solid black lines illustrate the workflow of the proposed \ac{CMAS}, which consists of four key agents: (i) a self-annotator, (ii) a type-related feature extractor, (iii) a demonstration discriminator, and (iv) an overall predictor.}
    \label{fig:framework-chapter5}
\end{figure*}

Our contributions are summarized as follows:
\begin{enumerate*}[label=(\roman*),nosep,leftmargin=*]
    \item To the best of our knowledge, ours is the first study to design a cooperative multi-agent system for zero-shot \ac{NER} that harnesses the collaborations and unique roles of multiple agents to integrate contextual correlations and the self-reflection mechanism.
    \item We redefine \ac{NER} into two subtasks: recognizing named entities and identifying entity type-related features. In this way, \ac{CMAS} effectively captures contextual correlations between the contexts during entity recognition, thereby reducing incorrect type predictions and entity omissions.
    \item We incorporate a self-reflection mechanism into the demonstration discriminator. By evaluating the helpfulness scores for entity extractions in target sentences, \ac{CMAS} is capable of discriminately using and learning from selected demonstrations.
    \item Experimental results across six benchmarks demonstrate that our proposed \ac{CMAS} achieves state-of-the-art performance on zero-shot \ac{NER}  and exhibits strong robustness across varying numbers of task demonstrations.
\end{enumerate*}














