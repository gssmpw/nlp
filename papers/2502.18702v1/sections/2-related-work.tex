\section{Related Work}
% We investigate related work in three areas: (i) reasoning with \acp{LLM}, (ii) \acp{LLM} for IE, and (iii) LLM-based multi-agent systems.

\subsection{Reasoning with LLMs}
\acp{LLM} demonstrate strong zero-shot and few-shot reasoning capabilities, particularly when prompted to provide intermediate rationales for solving problems. Recent studies in both few-shot and zero-shot frameworks explore eliciting a chain-of-thought (CoT) process from LLMs. These studies encourage LLMs to refine their responses incrementally, enhancing the reasoning process step-by-step~\citep{wei2022chain,zhang2022automatic,wang2022towards,kojima2022large}.
Additionally, strategies like problem decomposition such as least-to-most prompting \cite{zhou2022least}, break down complex problems into manageable sub-problems, addressing them sequentially. 
The self-consistency approach \cite{wang2022self} involves generating a diverse array of responses from an LLM, subsequently selecting the optimal answer by averaging over these possibilities.
In this paper, we focus on investigating the zero-shot reasoning ability of \ac{LLM} on the \ac{NER} task. 

\subsection{LLMs for IE}
Evaluating the performance of \acp{LLM} on IE tasks is garnering significant attention~\citep{li2023evaluating,DBLP:conf/aaai/MaWKBP024,laskar2023systematic,DBLP:conf/www/ZhangZGH24,DBLP:conf/aaai/WuKWLLC24,wang2023gpt}. \citet{wei2023zero} propose a two-stage chatting paradigm for IE. In the first stage, ChatGPT is tasked with recognizing types of elements. In the second stage, it extracts mentions corresponding to each identified type. \citet{DBLP:journals/corr/abs-2305-14450} present a comprehensive analysis of \ac{LLM}s' capabilities in IE tasks, examining aspects such as performance, evaluation criteria, robustness, and prevalent errors. 

\citet{DBLP:conf/emnlp/XieLZZLW23} conduct a systematic empirical study on the reasoning abilities of \acp{LLM} in IE, particularly examining performance in zero-shot \ac{NER} tasks.
\citet{DBLP:journals/corr/abs-2311-08921} focus on enhancing the performance of zero-shot \ac{NER} using \acp{LLM} by introducing a training-free self-improving framework that uses an unlabeled corpus to stimulate the self-learning capabilities of \acp{LLM}.
\citet{wan2023gpt} employ the chain-of-thought (CoT) approach for relation extraction (RE), using \acp{LLM} to generate intermediate rationales based on demonstrations from the training set.

\subsection{LLM-based multi-agent systems}
\acp{LLM} exhibit useful capabilities in reasoning and planning, aligning with human expectations for autonomous agents capable of perceiving their environments, making decisions, and taking responsive actions~\citep{DBLP:journals/corr/abs-2309-07864,DBLP:journals/ker/WooldridgeJ95,DBLP:journals/corr/abs-2305-18365,DBLP:conf/emnlp/Liang0RC0K23}. Consequently, \ac{LLM}-based agents are increasingly designed to understand and generate human-like instructions, enhancing complex interactions and decision-making across various contexts~\citep{DBLP:conf/nips/YaoYZS00N23,DBLP:conf/nips/ShinnCGNY23,DBLP:conf/emnlp/LiZ000YLHL23}. Building on the abilities of individual \ac{LLM}-based agents, the concept of \ac{LLM}-based multi-agent systems has been introduced. Such systems use the collective intelligence and specialized skills of multiple agents, enabling collaborative engagement in planning, decision-making, and discussions, mirroring the cooperative nature of human teamwork in problem-solving. 
Recent research demonstrates the efficacy of \ac{LLM}-based agents in diverse applications, including game simulation~\citep{DBLP:journals/corr/abs-2310-18940,DBLP:journals/corr/abs-2310-01320}, software development~\citep{DBLP:conf/iclr/HongZCZCWZWYLZR24,DBLP:journals/corr/abs-2307-07924}, society simulation~\citep{DBLP:conf/uist/ParkOCMLB23,DBLP:conf/uist/ParkPCMLB22}, multi-robot systems~\citep{DBLP:journals/corr/abs-2307-04738,DBLP:journals/corr/abs-2307-02485}, and policy simulation~\citep{DBLP:journals/corr/abs-2311-06957}. 
Comprehensive updates on advances in \ac{LLM}-based agents are detailed in recent surveys~\citep{DBLP:journals/corr/abs-2309-07864,DBLP:journals/fcsc/WangMFZYZCTCLZWW24,DBLP:journals/corr/abs-2402-01680}.
To the best of our knowledge, ours is the first study to develop an \ac{LLM}-based cooperative multi-agent system tailored for zero-shot \ac{NER} tasks.

In this paper, we focus on the zero-shot \ac{NER} task. The work most closely related to ours is \citep{wei2023zero,DBLP:conf/emnlp/XieLZZLW23,DBLP:journals/corr/abs-2311-08921}. However, existing methods still face two challenging problems: (i) they overlook correlations between contexts surrounding entities, and (ii)  they make indiscriminate use of task demonstrations.
In our proposed \ac{CMAS}, to explicitly model contextual correlations within target sentences, both named entities and \acp{TRF} are simultaneously extracted using specialized \ac{ICL}. To enable controllable usage of demonstrations, a self-reflection mechanism is incorporated to automatically predict the helpfulness score of each selected demonstration for inference on the target sentences.
 
