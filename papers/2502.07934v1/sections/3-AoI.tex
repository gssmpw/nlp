\section{Age of Information Analysis} \label{aoi-S}



%In this section, we consider the AoI measure introduced in \cite{yates2012} as the performance metric to evaluate the timeliness of updates at the monitor. 


For analytical convenience, we first simplify the system by focusing solely on the relevance of the updates rather than their origin. In the considered system, the source sensor of the packet containing information about any arbitrary process $j$ is irrelevant from the monitor's perspective. Instead, what matters is whether the served packet contains information about process $j$, regardless of which sensor provided the update to track AoI. To formalize this, we label a status update as informative for process $j$ if it contains information on process $j$. Otherwise, it is labeled as uninformative. We build on this concept by defining two types of informative arrivals:
\begin{itemize}
    \item Informative arrivals that can preempt ongoing service.
    \item Informative arrivals that cannot preempt ongoing service.
\end{itemize}
Using this distinction, we define the informative arrival rate vectors as follows
\begin{equation}
\boldsymbol{\Tilde{\lambda}}^T = \begin{bmatrix}
\Tilde{\lambda}_{1} & \Tilde{\lambda}_{2} & \dots & \Tilde{\lambda}_{M}
\end{bmatrix} = (\boldsymbol{\lambda}^T \odot \bfp^T) \bfc,
\end{equation}
\begin{equation}
\boldsymbol{\dot{\lambda}}^T = \begin{bmatrix}
\dot{\lambda}_{1} & \dot{\lambda}_{2} & \dots & \dot{\lambda}_{M}
\end{bmatrix} = (\boldsymbol{\lambda}^T \odot (1-\bfp^T)) \bfc,
\end{equation}
%
where \(\boldsymbol{\Tilde{\lambda}}\) represents the informative arrival rate vector for packets that can preempt ongoing service, and \(\boldsymbol{\dot{\lambda}}\) represents the informative arrival rate vector for packets that cannot preempt ongoing service. The total channel arrival rate is given as:
\begin{equation}
\lambda_C = \Tilde{\lambda}_C + \dot{\lambda}_C,
\end{equation}
where
\begin{equation}
\Tilde{\lambda}_C = \sum_{i=1}^{N} \lambda_i \np_{i} \text{ and }
\dot{\lambda}_C = \sum_{i=1}^{N} \lambda_i (1 - \np_{i}).
\end{equation}
represent the channel arrival rates for packets that can and cannot preempt, respectively.

With the above quantities in mind, we analyze the system by reducing it to $M$ independent systems, each consisting of two sources as depicted in Figure \ref{fig:equiv_model}. The independence of these $M$ systems arises from the Poisson nature of packet arrivals. For any single process $j$, the arrivals of both informative and uninformative packets from all other processes collectively form Poisson streams, as shown in \ifthenelse{\boolean{withappendix}}
{Appendix~\ref{reduction-P}}
{Appendix A in \cite{technicalNote}}.%\ali{Can we put this in appendix instead of citing our work?}



\begin{figure}[!t]
  \centering
  \includegraphics[width=0.35\textwidth]{figures/simplification.png}
  \caption{Equivalent system model from process $j$'s perspective.}
  \vspace{-12pt}\label{fig:equiv_model}
\end{figure}

With this setup established, we now proceed to evaluate the evolution of AoI for a single process. The AoI of process \(j\) at time \(t\), denoted by \(\Delta_j(t)\), is defined as
\begin{equation}
\Delta_j(t) = t - T_j, \quad j=1,\ldots,M,
\end{equation}
where \(T_j\) represents the time at which the most recent \textit{informative} packet for process \(j\) was generated. The AoI for each process \(j\) evolves as follows: it increases linearly over time until an informative status update is successfully received, at which point a drop in the AoI occurs. However, whether an incoming packet contributes to reducing the AoI of a specific process depends on two key factors: (1) whether the packet contains information about process \(j\), and (2) the server's preemption dynamics.


To analyze this further, we model the server's operation through three states: \(0\) (idle), \(1\) (busy processing an informative packet), and \(2\) (busy processing an uninformative packet). In state \(0\), the server is not processing any packets, and the AoI for process \(j\) increases linearly due to the absence of updates. Upon transitioning to state \(1\), the server processes a packet containing relevant information for process \(j\), resulting in a decrease in the AoI after the packet's service time. Conversely, in state \(2\), the server is busy processing a packet that lacks relevant information, so the AoI for process \(j\) continues to increase linearly. Furthermore, when a new packet arrives at the busy server, incoming packets can interrupt ongoing service with a probability determined by the preemption matrix \(\bfp\). A transition from state \(2\) to state \(1\) via preemption leads to a linear increase in AoI during service time, followed by a decrease in AoI if the informative packet is successfully served, while a transition from state \(1\) to state \(2\) leads to a linear increase in AoI. The interaction between service states and preemption dynamics thus determines the AoI behavior over time. Lemma \ref{Lem1} provides the stationary distribution of these states and forms the foundation for deriving the closed-form expression of the AoI. %\ali{it feels like so much words, can we make this shorter? Also, why the results are given as a remark instead of a Lemma?}




%As per our system model, a served packet may or may not have information about process \(j\). If the served packet contains information on process \(j\), the AoI for process \(j\) decreases just after the service time of that packet. Conversely, if the served packet lacks information about process \(j\), the AoI for process \(j\) continues to increase linearly.

%Furthermore, the preemption mechanism impacts the AoI dynamics. Wrhen a new packet arrives at the server, it can preempt the currently served packet with a probability determined by the preemption matrix \(\bfp\). If preemption occurs, the ongoing service is interrupted, and the new packet is served instead. This can potentially reduce the AoI more effectively if the preempting packet contains relevant information for process \(j\). However, if the preempting packet lacks such information, the AoI will remain unaffected and continue its linear growth.



\begin{Lemma}\label{Lem1}
The stationary distribution of the states (\(0\), \(1\), \(2\)) can be derived as follows:
\begin{align}
\pi_0 = \frac{\mu}{(\lambda_C + \mu)}, \quad
\pi_1 = \frac{\lambda_C\Tilde{\lambda}_{1} + \dot{\lambda}_{1}\mu + \Tilde{\lambda}_{1}\mu}{(\lambda_C + \mu)(\Tilde{\lambda}_{C} + \mu)}, \\
\pi_2 = \frac{\Tilde{\lambda}_{C}\lambda_C + \lambda_C\mu -\lambda_C\Tilde{\lambda}_{1}  - \dot{\lambda}_{1}\mu - \Tilde{\lambda}_{1}\mu}{(\lambda_C + \mu)(\Tilde{\lambda}_{C} + \mu)}. 
\label{pi-distributions}
\end{align}
\begin{proof}
The illustration of the Markov chain states and the details of the proof can be found in \ifthenelse{\boolean{withappendix}}
{Appendix~\ref{spv-appendix}}
{Appendix B in \cite{technicalNote}}. %\ali{Perhaps you can mention here that an illustration of the Markov chain can also be found in the appendix}
\end{proof}
\end{Lemma}
With this model in place, we derive a closed-form expression for the AoI of each process, accounting for both informative and uninformative status updates with probabilistic preemption to comprehensively evaluate their impact on the system's dynamics. %as explained in Theorem \ref{The1}.

\begin{Theorem}\label{The1}
In the considered M/M/1/1 system, the average AoI for process $j$, denoted as $\Delta_j$, is

\footnotesize
\begin{align}
\Delta_j= \frac{\mu(\mu+\lambda_C)^2 + \sum_{i=1}^{N} \left(\mu\lambda_C \nc_{ij}(1-\np_{i}) + (\mu + \lambda_C)^2\np_{i}\right)\lambda_{i}}{
        \mu \sum_{i=1}^{N} \left(\mu + \lambda_C)(\lambda_C \np_{i} + \mu \right) \nc_{ij}\lambda_{i}}.
    \end{align}
\normalsize
    \end{Theorem}
\begin{proof} The proof leverages stochastic hybrid system modeling, focusing on state transitions (idle, busy with informative, or uninformative packets). Full details are provided in \ifthenelse{\boolean{withappendix}}
{Appendix~\ref{aoi-appendix}}
{Appendix C in \cite{technicalNote}}. 
\end{proof}
%\ali{both remark1 and theorem 1 have the same appendix?} \egemen{yes.}
Leveraging the above results, we examine two specific scenarios of interest:
\begin{itemize}

    \item \textbf{Preempt every packet} (\( \bfp = 1 \)):
    \begin{align}
    \Delta_j = \frac{{\lambda}_C+\mu}{\mu \tilde{\lambda}_j} .
    \end{align}
    
    \item \textbf{Preempt nothing} (\( \bfp = 0 \)):
    \begin{align}
    \Delta_j = \frac{{\lambda}_C}{\mu ({\lambda}_C + \mu)} + \frac{{\lambda}_C + \mu}{\mu \dot{\lambda}_j}.
    \end{align}


\end{itemize}


For these specific cases, both $\dot{\lambda}_j$ and $\tilde{\lambda}_j$ are equal to $\sum_{i=1}^{N} \nc_{ij}\lambda_i$. Therefore, the AoI in the no-preemption scenario is equal to the sum of a positive constant and the AoI in the full-preemption scenario. Thus, regardless of the correlation, preempting every packet guarantees a lower AoI than the no-preemption strategy. As the service rate approaches infinity, the average AoI difference between the two scenarios decreases because the system can accommodate updates almost instantaneously, which minimizes the necessity for preemption. Beyond these two special cases, we investigate the AoI-optimal preemption policy for our system in the following section.

