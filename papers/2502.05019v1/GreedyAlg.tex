\documentclass{article}
%\documentclass[anon,12pt]{colt2025}
\usepackage{graphicx} % Required for inserting images
 \usepackage{tikz}
 \usepackage{booktabs}
 \usepackage{natbib}
 \usepackage{pgfplots}
\usetikzlibrary{3d}
\usetikzlibrary{backgrounds}
\pgfdeclarelayer{bg}
\pgfsetlayers{bg,main}
\usepackage[left=1.5cm, right=2cm]{geometry}

 \newgeometry{left=3cm,bottom=4cm}

\tikzset{
  background/.style={%
    execute at begin node={\begin{pgfonlayer}{bg}},
    execute at end node={\end{pgfonlayer}}
  }
}

 %\usepackage{algorithm}
  %\usepackage{algorithmic}
 % \usepackage[square,comma,sort&compress]{natbib}
  \usepackage{algorithm,algpseudocode}
  \usepackage{tikz}
  \usetikzlibrary{calc}
  \usepackage{tkz-euclide}
  \usepackage{xcolor}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes.geometric, arrows.meta}
\usepackage{amsmath}
  
%\algnewcommand{\algorithmicforeach}{\textbf{for each}}
%\algdef{SE}[FOR]{ForEach}{EndForEach}[1]
  %{\algorithmicforeach\ #1\ \algorithmicdo}% \ForEach{#1}
  %{\algorithmicend\ \algorithmicforeach}% \EndForEach
 \usetikzlibrary{math}
\title{$O(\sqrt{T})$ Static Regret and Instance Dependent Constraint Violation for Constrained Online Convex Optimization}
\author{%
  Rahul Vaze, Abhishek Sinha,  \\
 School of Technology and Computer Science \\
  Tata Institute of Fundamental Research \\
  Mumbai 400005, India \\
  \texttt{rahul.vaze@gmail.com},
  \texttt{abhishek.sinha@tifr.res.in}
}
%\author{Rahul vaze, Abhishek Sinha}
%\date{October 2024}
\input{input.tex}
\begin{document}


\maketitle
\begin{abstract} The constrained version of the standard online convex optimization (OCO) framework, called COCO is considered, where on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round.
The objective is to simultaneously minimize the static regret and cumulative constraint violation (CCV). 
An algorithm is proposed that guarantees a static regret of $O(\sqrt{T})$ and a CCV of $\min\{\cV, O(\sqrt{T}\log T) \}$, where $\cV$ depends on the distance between the consecutively revealed constraint sets, the shape of constraint sets, dimension of action space and the diameter of the action space. For special cases of constraint sets, $\cV=O(1)$. Compared to the state of the art results, static regret of $O(\sqrt{T})$ and CCV of $O(\sqrt{T}\log T)$, that were universal, the new result on CCV is instance dependent, which is derived by exploiting the geometric properties of the constraint sets.
\end{abstract}
\input{Introduction}
\input{COCO}
\input{NeuRipsAlg}
%\input{NCBC}
\input{Algorithm}

\input{EquivalentConvexBodyProblem}
\input{recursiveUnsynched}
\input{Conclusions}
%\bibliographystyle{IEEEtran}
%\bibliography{../IEEEabrv,../Research}
\bibliography{OCO.bib} 
\input{App-ProofRegret}
\input{App-ProofAvgWidth}
\input{App-Switch}
\input{app-2D}


%\bibliographystyle{IEEE}

%  \def\rvara{2}
%\begin{tikzpicture}
%    % Define the center point and radii
%    \coordinate (center) at (0,0);
%  \def\avar{1}
%    \def\bvar{2}
%    \def\cvar{3}
%    \def\dvar{4}
%    \def\evar{5}
%
%    % Draw the concentric circles
%    \draw[thick] (center) circle (\avar);
%    \draw[thick] (center) circle (\bvar);
%    \draw[thick] (center) circle (\cvar);
%    \draw[thick] (center) circle (\dvar);
%    \draw[thick] (center) circle (\evar);
%
%    % Place the nodes
%    
%    
%    
%    
%    \node[circle,fill=black,inner sep=2pt] at (center) {};
%    \node[below] at (center) {$x_n$};
%
%    \node[circle,fill=black,inner sep=2pt] at (\avar,0) {};
%    \node[below] at (\avar,0) {$x_{n-1}$};
%
%    \node[circle,fill=black,inner sep=2pt] at (1,3.872) {};
%    \node[above] at (1,3.872) {$x_{\ell+2}$};
%
%    \node[circle,fill=black,inner sep=2pt] at (0,\evar) {};
%    \node[below] at (0,\evar) {$x_{\ell+1}$};
%    
%    \node[circle,fill=black,inner sep=2pt] at (-6,6) {};
%    \node[below] at (-6,6) {$x_{0}$};
%    
%    \node[circle,fill=black,inner sep=2pt] at (-5.5,5.5) {};
%    \node[below] at (-5.5,5.5) {$x_{1}$};
%    
%    \node[circle,fill=black,inner sep=2pt] at (-4, 4) {};
%    \node[below] at (-4, 4) {$x_{\ell}$};
%    
%    \draw (-6.5,6.5) -- (0,0)  -- (5,-5);
%    
%     \draw[dashed] (-4, 4) -- (0,\evar);
%     
%     \draw (0,\evar+1) -- (0,0)  -- (0,-6);
%    
%    \draw[dashed] (0,0)  -- (1,3.872);
%    
%    \draw (0.35,1.414) arc (60:75:1.5);
%    
%    \node[above] at (.35, 1.414) {$\alpha_{\ell+1}$};
%    
%      \draw (0,0) -- node[below] {$r_{\ell+1}$}  ++(-5,0);
%
%      \draw (0,0) -- node[below] {$r_{\ell+2}$}  ++(-3.75,1.39);
%
%    
%\end{tikzpicture}
%
%
%
%Consider the 2-D case alone for analyzing the greedy algorithm for Nested Convex Body Chasing. Let the starting point be $x_0$. Let at time $t=1, \dots, n$, a convex body $S_t \subseteq S_{t-1}$ is shown and the point chosen by Greedy by $x_t \in S_n$.
%
%Then $x_0, x_1, x_2, \dots, x_n$ is the sequence of points generated by the Greedy algorithm and let curve $C$ denote the line segments joining $x_0, x_1, x_2, \dots, x_n$.
%
%
%Let $x_1, x_2, \dots, x_\ell$ be such that they lie on the line joining $x_0$ and $x_n$. If there is no such $\ell$, then let $\ell =0$. This implies that the total length of $C$ from $x_0$ till $x_\ell$ is at most $D$, i.e., 
%\begin{equation}\label{eq:prefix}
%\sum_{i=0}^{\ell-1}d(x_i,x_{i+1}) \le D.
%\end{equation}
%
%
% 
%Let the $y$-axis be oriented along the line segment $x_{\ell+1}, x_n$ and $x$-axis be perpendicular to the $y$-axis. 
%
%{\bf Property 1:} First thing to note is that all convex bodies $S_{\ell+1}, S_{\ell+2}, \dots, S_n$ lie on one side of the $y$-axis, since otherwise it will contradict the convexity of  $S_t, t\ge \ell+1$.
%
%
% Let $r_i = d(x_i, x_n)$ be the distance between point $x_i$ and the final point $x_n$. As we discussed, because of successive projections, $r_i\le r_{i-1}$. 
%
%Consider $x_n$ as the center and draw $n-{\ell+1}$ concentric circles with radius $r_i, i=\ell+1, 2,\dots, n-1$. 
%Let $\alpha_i$ be the angle between line segments $(x_i,x_n)$ and $(x_{i+1},x_n)$. 
%\begin{lemma}\label{lem:angle}
%$\alpha_i\ge0$ for all $i=\ell+1, 2,\dots, n-1$.
%\end{lemma}
%Proof follows similar to Property 1.
%
%Then from triangle inequality we get 
%$d(x_i,x_{i+1}) \le r_{i} - r_{i+1} + \alpha_i d(x_i, x_n)$. 
%Therefore, the total distance of the curve $C$ from $x_{\ell+1}$ till $x_n$
%$$\sum_{i=\ell+1}^{n-1}d(x_i,x_{i+1}) \le \sum_{i=1}^{n-1} r_{i} - r_{i+1}+ \alpha_i d(x_i, x_n) \le D+  D \sum_{i=1}^{n-1} \alpha_i.$$ 
%From Lemma \ref{lem:angle} and Property 1, $\sum_{i=1}^{n-1} \alpha_i\le \pi$, 
%hence 
%$\sum_{i=\ell+1}^{n-1}d(x_i,x_{i+1}) \le D+D\pi$.
%Since the distance between $(x_{\ell},x_{\ell+1})$ is at most $D$, combining this with \eqref{eq:prefix}, we get that the total length of the curve $C$ is $3D + \pi D$.

%\input{NCBCtoConstraintViolation}
 
%\section{Introduction}
%Consider the 2-D case for the moment, so the first convex body $K_1 \subset \bbR^2$.
%Let the initial position of the Greedy algorithm be $x_1$, and $x_i$ be its location once $K_i \subset K_{i-1}$ has been revealed and the projection has been taken from $x_{i-1}$ onto $K_i$.
%Let the convex hull of the $x_1, \dots, x_i$ be $S_i$. 
%
%
%\section{Preliminaries}
%    Let a curve be called Lipschitz if the map $\gamma:I \rightarrow \bbR^n$ is Lipschitz.
%
%\begin{definition}\label{defn:se-curve} A Lipschitz curve $\gamma: I \rightarrow \bbR^n$  is called self-expanded, if for every $t$ where 
%$\gamma'(t)$ exists, we have 
%$$< \gamma'(t), \gamma(t)-\gamma(u)> \ \ge 0$$ for all $u\in I$ with $u \le t$. 
%In words, what this means is that if $\gamma$ starting in a point $x_0$ is self expanded, if for every $x\in \gamma$ for which there exists the tangent line $T$, the arc (sub-curve) $(x_0, x)$ is
%contained in one of the two half-spaces, bounded by the hyperplane through
%$x$ and orthogonal to $T$. 
%\end{definition}
%
%
%
%\begin{definition}
%Let $x=x(s)$ be the representation
%of $\gamma$ as a function of the arc length; let us define, $\gamma(s)= \{x\in \bbR^2, x=x(\sigma), 0 \le \sigma\le s\}$.
%$\gamma\in \Gamma$ is defined to 
%satisfy to be self-expanding if $\gamma'(s)$ exists for any $s$, then the 
%\end{definition}
%
%
%Consider $\bbR^2$, where in addition to the two orthogonal basis $x$ and $y$ axes, consider the rotation of $x,y$ axes by angle $\pi/4$, denoted by   $x'$ and $y'$, respectively, as another orthogonal basis pair.
%The set of total axes is $A = \{x,y, x', y'\}$.
%
%\begin{definition} Consider any convex body $B \subset \bbR^2$.
%For $a\in A$, let $W_a(i)$ be the minimum distance between any two supporting hyperplanes of $B$ that are perpendicular to $a$-axis.
%\end{definition}
%
%Clearly, for any $a\in A$, $W_a(B)$ is a non-increasing quantity as a function of $B$.  
%We will prove the following result for  self-expanding curves in $\bbR^2$.
% 
%\begin{theorem}\label{thm:mainresult}
%For any self-expanded curve in $\bbR^2$, let $\gamma^+$ be its convex hull. Then 
%$$\max_a\{W'_a(\gamma^+)\} \ge \frac{1}{\sqrt{2}}.$$
%\end{theorem}
% 
%The curved produced by the Greedy algorithm satisfies the self-contracting property that is defined as follows.
%
%  \begin{definition} A curve $\gamma: I \rightarrow \bbR^n$ is self-contracted if for every $t_1 \le t_2 \le t_3$ in $I$, 
%  $$d(\gamma(t_2), \gamma(t_3)) \le d(\gamma(t_1), \gamma(t_3)).$$
%  \end{definition}
%  
%  \begin{lemma} Let $\gamma$ be a self-contracted curve and let $\gamma$ be differentiable at point $t$, then 
%  $$< \gamma'(t), \gamma(u)-\gamma(t)> \ \ge 0$$ for all $u\in I$ with $u>t$. 
%\end{lemma}
%
%\begin{prop}\label{prop:scGreedy} The affine extension $C$ of the sequence of points  $\{x_1, x_2, \dots, x_m\}$ produced by the Greedy algorithm for the CBC problem with sets $\{K_1, K_2, \dots, K_m\}$ is a self-contracting curve because of the orthogonality principle of projections on convex bodies.
%\end{prop}
%Next, we connect the self-contracted and self-expanded curves as follows. 
%
%  \begin{definition} Given a curve $\gamma:I \rightarrow \bbR^n$, denote by $I^- = \{-t |  t\in I\}$ and define the reverse curve 
%  $\gamma^-:I^- \rightarrow \bbR^n$ as 
%  $$\gamma^-(t) = \gamma(-t), \ \text{for} \ t\in I^-.$$
%    \end{definition}
%    
%    Essentially, $\gamma^-$ is $\gamma$ traced backwards or in reverse order. See Fig. \ref{fig:cont-expand} for an example.
%    
%    \begin{lemma}\label{lem:se-scconnection}
%Let $\gamma:I \rightarrow \bbR^n$ be a Lipschitz curve. Then $\gamma$ is self-contracted if and only if $\gamma^-$ is self-expanded curve.
%\end{lemma}
%
%Lemma \ref{lem:se-scconnection} implies that the length of self-expanded and self-contracted curves is the same. 
%Thus, from Proposition \ref{prop:scGreedy}, to bound the length of curve $C$ produced by the Greedy algorithm, it is sufficient to bound the length of the self-expanded curve corresponding to $C$.  
%  
%Let  the diameter of $K_1$, the first convex body, be $D$. Then, Theorem \eqref{thm:mainresult} implies that the length of curve $C$ produced by the Greedy algorithm is at most $4\sqrt{2} D$.
%
 

%\begin{figure}[h]
%\centering
%\includegraphics[width=90mm]{greedyCBC.jpg}
%\caption{}
%\label{fig:greedy}
%\end{figure}
%Refer to Fig. \ref{fig:greedy}, where once the algorithm reaches $x_2$, in next step, either both $x$ and $y$ coordinates increase or only one of them does, i.e. $x_3$ belongs to either sector ABE or ACD. 
%Lets consider ABE. Because of the projection step to get to $x_2$ from $x_1$, we know that the angle $x_1x_2B$ is at least $\pi/2$. Therefore, angle $\theta_1\le \pi/4$, and thus the projection $\Delta_y$ of $\ell_1$ ( the distance moved by Greedy in the next step to get to $x_3$ from $x_2$) is at least $\ell_1/\sqrt{2}$. Even though the x-coordinate is decreasing between $x_3$ and $x_2$, we have $$\max\{W'_x(i), W'_y(i)\} \ge \frac{1}{\sqrt{2}}.$$
%
%The same idea works when $x_3$ belongs to sector ACD with roles reversed between $W_x$ and $W_y$.  Moreover, when $x_3$ belongs to the Good Area, both $x$ and $y$ coordinates increase with at least one of $W_x$ and $W_y$ having gradient at least as much as $1/\sqrt{2}$. Thus, we have 
%$$\max\{W'_x(i), W'_y(i)\} \ge \frac{1}{\sqrt{2}}$$ in each step.
%
%Now I want to claim that the total length $L$ of the curve followed by the greedy algorithm is at most $2\times \sqrt{2} \times \text{diameter}$. 
%
%Essentially, because of $$\max\{W'_x(i), W'_y(i)\} \ge \frac{1}{\sqrt{2}},$$ if $L > 2\times \sqrt{2} \times \text{diameter}$ then the curves has to leaves the body in at least one dimension. 
%
%\section{$d$-dimensions}
%{\bf Algorithm:} On arrival of convex $S_j \subseteq S_{j-1}$, choose $x_j$ as the projection of $x_{j-1}$ on to $S_t$.
%
%Let $x_j$ be the point chosen by the algorithm at time step $j$ on arrival of convex set $S_j$.
%Let the convex hull of the $x_1, \dots, x_j$ be $C_j$.
%At time step $j$, for $i=1,\dots, d$, let $W_i(j)$ be the minimum distance between any two hyperplanes parallel to the $i$-axis that contain $C_j$. $W_i(j)$ is essentially the $i$-axis diameter of $C_j$. %Similarly define  $W_y(i)$ to be the minimum distance between any two hyperplanes parallel to the x-axis that contain $C_i$. 
%
%\begin{lemma}
%Either $x_{j+1}=x_{j}$ or at each time step $j+1$, $\exists \ i$ such that $W_i(j+1)-W_i(j) > 0$ for $i=1,\dots, d$.
%\end{lemma}
%\begin{proof}
%Note that the angle between $x_{j+1} -x_t$ and $x_{t} -x_{t-1}$ is more than $\pi/4$ for any $t\le j$, since each point $x_t$ is found by projecting $x_{t-1}$ on to the convex set $S_t$. Moreover, $S_{t+1} \subseteq S_t$ $\forall \ t$. This implies that either $x_{j+1}=x_{j}$ or at each time step $j+1$, $||x_t-x_{j+1}||  >  ||x_j-x_{j+1}||$ for all $t < j$.
%Thus,  either $x_{j+1}=x_{j}$,
%or $\exists \ i$ such that $W_i(j+1)-W_i(j) > 0$ for $i=1,\dots, d$.
% 
%\end{proof}
%
%\begin{lemma}
%Among the indices $i$ for which $W_i(j+1)-W_i(j) > 0$ for $i=1,\dots, d$, $\exists \  i'$ such that $W_{i'}(j+1)-W_{i'}(j) \ge \frac{1}{\sqrt{d}} ||x_{j+1}-x_j||$.
%\end{lemma}
%
%\begin{proof}
%Consider a hyperplane $H$ passing through the origin. Let any vector $v$ lie in one of the half space $G$ corresponding to $H$. Let the projection of $v$ onto the $i^{th}$-axis be $P_i(v) = \frac{v_i}{||v||}$, and its length be $|P_i|$. Then clearly the  $\max_i\{|P_i(v)|\}\ge \frac{1}{\sqrt{d}}$.
%
%Moreover, if $v \in G'$ where $G'\subset G$ with dimension $d' < d$, then 
%\begin{equation}\label{eq:growth}
%\max_{i=1, \dots, d'}\{|P_i(v)|\}\ge \frac{1}{\sqrt{d'}}.
%\end{equation}
%
%Let the set of indices for which $W_i(j+1)-W_i(j) > 0$ be $\cM$ with cardinality $|\cM|$. Consider the supporting hyperplane $H_j$ of $S_j$ at point $x_j$ that is normal to $x_{j}-x_{j-1}$. Let $G_j$ be the half space of $H_j$ that contains $S_{j+1}$. Consider the restriction of $G_j$ onto the indices of $\cM$, and consider point $x_j$ as the origin. 
%Then from \eqref{eq:growth} we get that  
%$W_{i'}(j+1)-W_{i'}(j) \ge \frac{1}{\sqrt{|\cM|}} ||x_{j+1}-x_j||$.
%Since $|\cM|\le d$, we get the result.
%
%
%\end{proof} 
%
%%Extending the above argument to $d$ dimensions. Let $x_j$ be the most recent point found by the algorithm when convex body $C_j$ was revealed. Consider $H_j$ the supporting hyperplane of $C_j$ at $x_j$ that is normal to $x_j-x_i$. Let the halfspace of $H_j$ containing $x_j-x_i$ be $G_j$. 
%%
%%Given that $x_j$ was found by projection onto $C_j$, $C_{j+1} \cap G_j = \phi$. Thus, the vector $x_{j+1}-x_j$ lies in  $G_j^c$, and hence $W_i(j+1)$ increases by amount $P_i(x_{j+1}-x_j)$ $\forall \ i=1, \dots, d$. Given that the projection  satisfies
%%$\max_i\{|P_i(x_{j+1}-x_j)|\}\ge \frac{1}{\sqrt{d}}$, we get that 
%%$$\max_{i, i=1,\dots, d} \{W'_i(t)\} \ge \frac{1}{\sqrt{d}}$$ in each step $t$.
%%
%%Given that there are a total of $d$ dimensions, we will get $L \le  d \times \sqrt{d} \times \text{diameter}$.
%
 \end{document}