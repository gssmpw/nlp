@article{10.1162/tacl_a_00644,
    author = {Cohen, Roi and Biran, Eden and Yoran, Ori and Globerson, Amir and Geva, Mor},
    title = {Evaluating the Ripple Effects of Knowledge Editing in Language Models},
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {283-298},
    year = {2024},
}

@inproceedings{brinkmann-etal-2024-mechanistic,
    title = "A Mechanistic Analysis of a Transformer Trained on a Symbolic Multi-Step Reasoning Task",
    author = "Brinkmann, Jannik  and
      Sheshadri, Abhay  and
      Levoso, Victor  and
      Swoboda, Paul  and
      Bartelt, Christian",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    year = "2024",
    pages = "4082--4102",
}

@misc{deng2023implicitchainthoughtreasoning,
      title={Implicit Chain of Thought Reasoning via Knowledge Distillation}, 
      author={Yuntian Deng and Kiran Prasad and Roland Fernandez and Paul Smolensky and Vishrav Chaudhary and Stuart Shieber},
      year={2023},
      eprint={2311.01460},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.01460}, 
}

@misc{deng2024explicitcotimplicitcot,
      title={From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step}, 
      author={Yuntian Deng and Yejin Choi and Stuart Shieber},
      year={2024},
      eprint={2405.14838},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.14838}, 
}

@misc{fan2024loopedtransformerslengthgeneralization,
      title={Looped Transformers for Length Generalization}, 
      author={Ying Fan and Yilun Du and Kannan Ramchandran and Kangwook Lee},
      year={2024},
      eprint={2409.15647},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.15647}, 
}

@inproceedings{giannou2023looped,
  author    = {Angeliki Giannou and Shashank Rajput and Jy-yong Sohn and Kangwook Lee and Jason D Lee and Dimitris Papailiopoulos},
  title     = {Looped Transformers as Programmable Computers},
  booktitle = {Proceedings of the International Conference on Machine Learning},
  pages     = {11398--11442},
  year      = {2023},
}

@inproceedings{khot2023decomposedpromptingmodularapproach,
      title={Decomposed Prompting: A Modular Approach for Solving Complex Tasks}, 
      author={Tushar Khot and Harsh Trivedi and Matthew Finlayson and Yao Fu and Kyle Richardson and Peter Clark and Ashish Sabharwal},
booktitle={International Conference on Learning Representations },
year={2023},
}

@inproceedings{li-etal-2024-understanding,
    title = {Understanding and Patching Compositional Reasoning in {LLM}s},
    author = {Li, Zhaoyi  and
      Jiang, Gangwei  and
      Xie, Hong  and
      Song, Linqi  and
      Lian, Defu  and
      Wei, Ying},
    editor = {Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek},
    booktitle = {Findings of the Association for Computational Linguistics},
    year = {2024},
    pages = {9668--9688},
}

@inproceedings{merrill2024expressivepowertransformerschain,
      title={The Expressive Power of Transformers with Chain of Thought}, 
      author={William Merrill and Ashish Sabharwal},
      year={2024},
    booktitle={International Conference on Learning Representations },
}

@inproceedings{onoe-etal-2023-lms,
    title = "Can {LM}s Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge",
    author = "Onoe, Yasumasa  and
      Zhang, Michael  and
      Padmanabhan, Shankar  and
      Durrett, Greg  and
      Choi, Eunsol",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2023",
    pages = "5469--5485",
}

@InProceedings{pmlr-v80-lake18a,
  title = 	 {Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks},
  author =       {Lake, Brenden and Baroni, Marco},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2873--2882},
  year = 	 {2018},
}

@misc{prabhakar2024decipheringfactorsinfluencingefficacy,
      title={Deciphering the Factors Influencing the Efficacy of Chain-of-Thought: Probability, Memorization, and Noisy Reasoning}, 
      author={Akshara Prabhakar and Thomas L. Griffiths and R. Thomas McCoy},
      year={2024},
      eprint={2407.01687},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.01687}, 
}

@inproceedings{rai-yao-2024-investigation,
    title = "An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of {LLM}s",
    author = "Rai, Daking  and
      Yao, Ziyu",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    pages = "7174--7193",
}

@misc{shao2024deepseekmathpushinglimitsmathematical,
      title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}, 
      author={Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Xiao Bi and Haowei Zhang and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
      year={2024},
      eprint={2402.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.03300}, 
}

@inproceedings{stolfo-etal-2023-mechanistic,
    title = "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis",
    author = "Stolfo, Alessandro  and
      Belinkov, Yonatan  and
      Sachan, Mrinmaya",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
    pages = "7035--7052",
}

@inproceedings{vaswani2017attention,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}

@inproceedings{wang-etal-2024-math,
    title = "Math-Shepherd: Verify and Reinforce {LLM}s Step-by-step without Human Annotations",
    author = "Wang, Peiyi  and
      Li, Lei  and
      Shao, Zhihong  and
      Xu, Runxin  and
      Dai, Damai  and
      Li, Yifei  and
      Chen, Deli  and
      Wu, Yu  and
      Sui, Zhifang",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    pages = "9426--9439",
}

@misc{yang2024largelanguagemodelslatently,
      title={Do Large Language Models Latently Perform Multi-Hop Reasoning?}, 
      author={Sohee Yang and Elena Gribovskaya and Nora Kassner and Mor Geva and Sebastian Riedel},
      year={2024},
      eprint={2402.16837},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.16837}, 
}

@misc{yin2025enhancinggeneralizationchainthought,
      title={Enhancing Generalization in Chain of Thought Reasoning for Smaller Models}, 
      author={Maxwell J. Yin and Dingyi Jiang and Yongbing Chen and Boyu Wang and Charles Ling},
      year={2025},
      eprint={2501.09804},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.09804}, 
}

@misc{yu2024flowreasoningtrainingllmsdivergent,
      title={Flow of Reasoning:Training LLMs for Divergent Problem Solving with Minimal Examples}, 
      author={Fangxu Yu and Lai Jiang and Haoqiang Kang and Shibo Hao and Lianhui Qin},
      year={2024},
      eprint={2406.05673},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.05673}, 
}

@misc{yue2023mammothbuildingmathgeneralist,
      title={MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning}, 
      author={Xiang Yue and Xingwei Qu and Ge Zhang and Yao Fu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
      year={2023},
      eprint={2309.05653},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.05653}, 
}

@inproceedings{zhong-etal-2023-mquake,
    title = "{MQ}u{AKE}: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
    author = "Zhong, Zexuan  and
      Wu, Zhengxuan  and
      Manning, Christopher  and
      Potts, Christopher  and
      Chen, Danqi",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    year = "2023",
    pages = "15686--15702",
}

