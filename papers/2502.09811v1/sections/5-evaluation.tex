\section{Guideline Evaluation}

To evaluate the coverage, applicability, and actionability and further refine the guidelines, we conducted a heuristic evaluation study with 10 VR experts to solicit professional feedback.

\subsection{Participants}
We recruited 10 participants with professional experiences in AR/VR development with ages ranging from 24 to 52 years old ($mean$ = 33.5, $SD$ = 10.3). To ensure participants have sufficient avatar development experiences and valuable insights, we focused on recruiting AR/VR developers and designers with at least six months of full-time work experience. We used multiple channels for recruitment, including emailing AR/VR technology companies, posting recruitment messages on online developer forums (e.g., Meta Developer Forum) and business-focused social media platforms (e.g., LinkedIn), and referrals from participants. Interested participants would fill out a survey, asking about their age, current position, years of experiences as AR/VR practitioners, companies they have worked at, and experiences with avatar development. 

Our participants showed a variety of professional experiences with VR development. Five of them had over five years of experience, and six had held leadership roles within their teams. Their senior experiences offered strategic insights about guideline implementations. In addition, all participants had experiences with avatar development in 3D environments, including avatar modeling (e.g., EP1, EP3), 3D texturing (EP8, EP9), rigging (e.g., EP5, EP7), and designing avatar interactions in the social settings (EP1, EP2). EP1 specifically designed and developed avatars for people with depression. Moreover, six participants were employed at medium to large technology companies, while four participants worked at startups or local VR studios. Such diverse backgrounds of participants enabled us to gain feedback from different perspectives and improve our guidelines comprehensively. We detailed participants' demographics in Table \ref{tab:experts_demographics}.

\input{sections/tables/experts_demographics}

\subsection{Procedure}
To evaluate the guidelines, \change{we employed a modified heuristic evaluation method \cite{human_ai_guidelines}}. Heuristic evaluation is a common usability testing method where evaluators examine a user interface for violations based on a set of usability guidelines \cite{nielsen1990heuristic}. With the primary goal of evaluating the design guidelines rather than the interface, and inspired by prior work \cite{human_ai_guidelines}, we modified the heuristic evaluation by asking participants to identify both applications and violations of the guidelines in off-the-shelf social VR apps and reflect on the guidelines themselves.  %\yaxing{"a social VR platform" maybe too broad here - we should probably specify "in the avatar customization interfaces and the final avatar design"}

\change{Before the study, we emailed the guideline document to each participant, asking them to read through and get familiar with the guidelines.} %To prepare for the study, we first provided participants with a document containing all the guidelines to familiarize themselves with the guidelines \yuhang{did you do this before your study session? specify details}. 
%We attached the guideline document in Appendix Table \ref{tab:full_original}. %\yaxing{add a pointer to the guideline table in the appendix}
% Each guideline had four elements: 1) a statement instructing practitioners of what to do, 2) a paragraph detailing the statement and explaining why this guideline is important, 3) quotes from PWD in Phase 1 study, indicating the source of guideline, and 4) a visual example (e.g., an image or GIF) demonstrating the practical implementation of the guideline. 
We selected five widely used off-the-shelf social VR apps for participants to review (app selection is detailed in Section ~\ref{sec:appselect}). We randomly assigned one social VR app to each participant and ensured that each app was evaluated by two participants. 

After familiarizing themselves with the guidelines, participants started evaluating their assigned app in their own time. We emailed the study instruction and asked participants to thoroughly explore the avatar customization process of the app, including all design options and the avatar interface. During their explorations, participants filled a survey to evaluate how our guidelines may apply to the app, following the standard heuristic evaluation \cite{nielsen1990heuristic}. The survey took 1 to 2 hours to finish, and participants were given one week to fill out the survey on their own time, with the compensation of \$50 upon completion. We asked participants to video-record their exploration process to ensure the study rigor. 

When we received the participants' survey response, we invited them to a semi-structured interview to go through and discuss the evaluation results. The interview was conducted via Zoom and lasted about 1 hour, with compensation at a rate \$45/hour. We describe the study details of survey and interview below.


% ensure they understood the application well enough to identify examples of guideline applications or violations. %Participants were required to use the assigned application with their customized avatar and get familiar with any avatar-based interactions. %\yaxing{with the customized avatar? be clear here}.
% We endeavored to assign 2 participants to evaluate each social VR application for comprehensiveness and cost-effectiveness, following Nielsen's recommendation for heuristic evaluation \cite{nielsen1990heuristic}. 

%Our heuristic evaluation study contained two components: an online survey and a semi-structured interview. First, as participants went through the avatar customization process, they filled a survey to evaluate how our guidelines may apply to the process. The survey took 1 to 1.5 hours to finish, and participants were given about one week to fill out the survey on their own time, with the compensation of \$50 upon completion. 

%We then invited participants to a semi-structured interview to follow up and discuss the survey response. We also asked high-level feedback across different guidelines. The interview lasted about 1 hour, and we compensated participant at a rate of \$45/hour. We describe the study details below. %\yuhang{above two paragraphs need to be reframed... i started editing but then realize that these two paragraphs almost conflict with each other. When did participants do the heuristic evaluation---in-person or offline, and when did they do the interview? And when did you ask them to explore the interface--it reads like that you separate the exploration from the heuristic evaluation process? Why?}

\subsubsection{Heuristic Evaluation Survey}
%\yaxing{The heuristic evaluation survey and interview protocol section can be shortened by describing the major sections, then point readers to the appendix}
We instructed participants to evaluate their assigned \change{app} based on the guidelines and asked them to fill out a survey asking a series of questions. We implemented the survey in Qualtrics\footnote{Qualtrics. https://www.qualtrics.com/lp/experience-management/.}. We attached the consent form before the survey questions, and participants gave consent by continuing with the survey after reading the consent form.
% We asked questions about the 20 guidelines respectively. 
%Our survey design was inspired by the prior HCI work in evaluating a set of human-AI interaction design guidelines \cite{human_ai_guidelines}. 

%\yuhang{say something high level, that we modify the standard heuristic evaluation form by adding more questions about guideline in itself....currently it's not clear what is created by us and what is from heuristic evaluation standards.} 

\change{We modified the standard heuristic evaluation form by adding more questions asking about the guidelines themselves \cite{human_ai_guidelines}.} 
The survey started with the presentation of a guideline, and we first %presented it with all four elements described above. We then 
asked participants how they interpret it to check any misinterpretations or confusions. To evaluate guideline's applicability on the app, the survey asked participants to determine if the guideline ``apply'' (i.e., is relevant and should be implemented) to the avatars, and if not apply (i.e., irrelevant or out of scope), to explain why. If a participant found that a guideline should apply to the avatars, we further quantify the level of application by asking participants to rate on a 5-point semantic differential scale from ``clearly violated'' (1) to ``clearly applied'' (5). We also asked participants to explain their ratings with identified examples from the evaluated app, so that we got concrete evidence of applications and violations.
%along with an explanation of the rating and examples of applications or violations. Participants were encouraged to upload screenshots to illustrate the examples. 

In addition, participants answered a set of three questions to assess each guideline's clarity, actionability, and importance on a 5-point Likert scale, with 1 being the worst and 5 being the best. %For example, to evaluate the clarity, the question asked was, ``How clear and understandable is the guideline? (1 = very confusing, and 5 = very clear).'' 
Participants also filled an open-ended question to provide rationales for their ratings and other comments about the guidelines.
%\yaxing{we can talk about the length and payment for the interview and heuristic evaluation together, otherwise they sound like two different studies}
We asked the same set of questions to evaluate each guideline consistently. We attached the details of survey questions in Appendix \ref{heuristic_survey}.

\subsubsection{Semi-structured Interview} 
After completing the survey, participants did a semi-structured interview with us, which we asked follow-up questions to the survey responses and gathered cross-guidelines feedback. We began the interview by asking participants' background information to better understand their professional experiences, including demographics (age and gender), current position and the company they worked at, years of working experiences as a full-time position, and previous experiences with developing 3D avatars. We then went through the survey response with participants to resolve any confusions or questions they may have about the guidelines, and asked participants to further elaborate their ratings if needed. %For example, if participants input ``this guideline is actionable and important'' in the survey, we followed up in the interview by asking, ``if actionable, can you describe how you plan to implement this guideline in avatar development? and why do you think this guideline is important?'' 
Lastly, to identify any redundancies or conflicts across different guidelines, we asked participants to reflect on the overall guidelines. We also sought feedback about the language and structure of guidelines so that we could resolve any semantic confusion. A detailed protocol could be found \ref{protocol_experts}. % and the guideline's structure is clear to follow. Finally, we checked with participants to see if they have any additional suggestions to improve the guidelines.

\subsection{Apparatus: Selection of Mainstream Social VR Apps for Heuristic Evaluation}\label{sec:appselect}
To determine if and how the guidelines manifest in a variety of avatar platforms, we selected a set of commonly used social VR apps for participants to evaluate in the study. We adopted a maximum-variance sampling strategy \cite{maxwell2012qualitative, human_ai_guidelines} to select social VR apps that covered a wide range of avatar types. 

First, we conducted an exhaustive search on three mainstream VR app stores: \textit{Meta Horizon Store}, \textit{Steam}, and \textit{Viveport}. Our search focused on apps available in the United States in English from March to May 2024. We first searched for the keyword ``social'' in each store and identified a total of 527 apps (86 from \textit{Meta Horizon Store}, 234 from \textit{Steam}, and 163 from \textit{Viveport}). To narrow down the scope and focus on apps with embodied social nature, we filtered the results by checking the app descriptions, tags, and thumbnails to exclude the non-social apps (e.g., intense shooting games, sports), resulting in 25 social VR apps. 

Next, four researchers reviewed all apps independently. We adopted a depth-first traverse strategy, clicking through all available buttons and menu items in the avatar interface. During the review, researchers video-recorded and took notes of all avatar options and the interaction process, including avatar types (e.g., realistic human, cartoonish characters, animals), components (e.g., full body, upper body), customization options, and disability representation features. All researchers then discussed the review results to select apps with diverse avatar styles, enabling us to evaluate the guidelines on a broad range of avatar platforms.  
%For example, we removed Villa, MeetinVR, and Spatial from the list because they all adopted the third-party ReadyPlayerMe avatars. %; Minecraft and Roblox had similar blocky, cartoon-like avatars, so we only kept Roblox as it offers free access. 
As a result, we selected five social VR apps: \textit{VRChat}, \textit{Meta Horizon Worlds}, \textit{Rec Room}, \textit{Roblox}, and \textit{Multiverse}. \change{We characterized the avatar interface of each app in Appendix Table \ref{tab:vr_platforms}}. 

\subsection{Analysis}
We used descriptive statistical analysis to analyze the survey response. Specifically, we collected participants' Likert scale ratings on four dimensions for each guideline, including level of application, clarity, actionability, and importance. For each dimension, we calculated the mean and standard deviation of ratings to identify guidelines with low mean score or high deviation (meaning that participants had diverse opinions), which may indicate areas for improvement. We also counted the total number of examples of applications and violations identified by participants, understanding how well our guidelines were applied or implemented in mainstream social VR apps. 

We analyzed participants' open-ended responses via thematic analysis \cite{Braun2006Thematic}, similar to the method in Section \ref{analysis_phase1}. Three representative transcripts were selected as samples and coded independently by three researchers. Researchers discussed code discrepancies and created the initial codebook upon agreement. We then split up the remaining transcripts for individual coding. When new codes emerged, researchers discussed with each other and updated the codebook upon agreement. \change{The final codebook contained 137 codes. We categorized all the codes in to high-level themes using affinity diagram and achieved five themes with 17 sub-themes.}
%\yuhang{update on how you generate themes; and number of themes and subthemes.}

%After coding, one researcher conducted thematic analysis and received iterative feedback from all authors. 
%Our analysis resulted in xx themes with xxx sub-themes, and the details could be found in theme table in Appendix \ref{}. 

\subsection{Findings}
Our study resulted in both quantitative and qualitative data that reflected VR experts' feedback. Below, we first report quantitative results from the survey responses, providing an overview of participants' assessments on our guidelines. We then discuss the qualitative data to uncover their considerations and suggestions. 
%\yaxing{is it about evaluating avatars or the avatar customization process? }

\subsubsection{\change{Application Level of the Guidelines}.}
Across the five social VR apps, participants identified 109 violations, 47 applications, and 38 neutrals (i.e., with a rating of three in level of application). %\yaxing{add similar explanation to violations and applications}. 
Each participant identified at least one example of application or violation for each guideline, suggesting the relevance of our guidelines \cite{human_ai_guidelines}. By analyzing the mean rating of application level, we found 16 out of 20 guidelines had a mean rating below three. Figure \ref{fig:application} in Appendix showed the mean application level score of each guideline. Participants reported that the evaluated apps either lacked any customization options (e.g., \textit{Multiverse}) or the provided customization did not fully address the needs of disability representation (e.g., \textit{Horizon Worlds}, \textit{Roblox}, \textit{Rec Room}). For example, EP1 noted that \textit{Rec Room}'s avatar customization included a slider for adjusting eye sizes in line with G5.2 (i.e., use continuous controls for high-granularity customization), but it only allowed symmetrical changes, violating G1.3 (i.e., enable flexible customization of body parts as opposed to non-adjustable avatar templates). Another typical violation was lack of access to disability features (e.g., \textit{Rec Room}, \textit{VRChat}, \textit{Roblox}). For instance, EP5 found that \textit{Roblox} had a paywall in accessing the wheelchair options. These violations \change{highlighted the lack of inclusion in mainstream social VR apps.}
%highlighted that most mainstream social VR avatars had not implemented our guidelines, despite participants believed they should. %Fig. \ref{fig:application} in Appendix displayed the average adoption level for each guideline. 

\subsubsection{Clarity, Actionability, and Importance of the Guidelines.} %\kexin{ unsure about this title...HOLD} 
In addition to evaluating the social VR apps with the guidelines, participants also reflected on the guidelines themselves. In general, participants found our guidelines clear and easy to understand. Most guidelines had mean clarity ratings above four (Figure \ref{fig:clarity} in Appendix), %\yaxing{we shouldn't use mean to report likert scale questions, as they are ordinal data. Percentage would be appropriate to show the distribution.}
except for G1.4 ($mean =$ 3.65; i.e., prioritizing human avatars), where \change{five} participants \change{(e.g., EP4, EP5, EP7)} %\yuhang{how many participants? participant number.} 
were \change{unsure the meaning} of ``emphasize the `humanity' rather than disability,'' \change{wondering what could be a counterexample.} %and questioned its meaning \yuhang{can you explain more? how it was confusing? how should we improve?}. 

 Participants also found the majority of guidelines actionable \change{as each of them came with concrete implementation examples}. %\yuhang{discuss the reason? because of the concrete avatar examples we provided?} 
 Eighteen guidelines had mean actionability ratings above three (Figure \ref{fig:actionability}), with two exceptions of G2.4 ($mean =$ 2.90; i.e., leverage avatar posture to demonstrate PWD's lived experiences) and G3.5 ($mean =$ 2.80; i.e., demonstrate the liveliness of PWD through dynamic interactions with assistive technology). Although participants found these two guidelines leveraged the unique characteristics of embodied avatars, \change{seven of them (e.g., EP1, EP4, EP7, EP8)} %\yuhang{who? how many?} 
were unsure about how to implement them without considering the capabilities and limitations of VR devices (e.g., body tracking). \change{We explain in detail in Section \ref{improvements}.} %\yuhang{explain more... how participants explained that the VR device capability may affect implementation?}. 

Regarding the importance, all guidelines were rated at or above three on average (Figure \ref{fig:importance}), highlighting the importance of our guidelines. \change{We dive into the rationales in Section \ref{motivations}.}
%\yuhang{more qualitative data, why they think the guidelines are important?--- are the reasons all mentioned in 5.5.3? if so, refer to 5.5.3}

% Despite believing that the guidelines can greatly improve the user diversity, participants brought up a few trade-offs that they need to consider as developers and designers. We detail participants' considerations in the following sections.

\subsubsection{Motivations to Implement the Guidelines.} \label{motivations}
Eight participants (e.g., EP1, EP3, EP8, EP10) 
%\yuhang{exact number? you only have 10 participants, it's important to specify exact numbers across the whole finding section} 
praised the guidelines for providing comprehensive and novel suggestions for developing social VR avatars. They found the guidelines not only covered diverse user groups (EP8, EP9) but also inspired design ideas for under-explored avatar features, such as avatar peripherals and dynamics (EP1). \change{We elaborate on the factors that drive participants' motivations}. 

\change{\textbf{\textit{Increased Trust and Values by Engaging Disability Community.}}} Participants were particularly impressed by our inclusion of 60 PWD in generating the guidelines. As developers and designers, they highly valued the direct input from representative users and wanted to incorporate the community's voice in application development. However, this was often hard to achieve due to the limited resources (e.g., time and cost budget). As EP8 noted: \textit{``I love that you have your guidelines from 60 people with disabilities. [Because having] a representative sample size is really tricky. I am an indie developer, and I only have two people who care about my game...It's important to talk to your community, get their input, and then develop based on what your actual customers' needs and desires are.''} With active involvement of the disability community, participants trusted the guidelines and were motivated to follow them. %They also believed implementing guidelines would benefit multiple stakeholders \yuhang{where does this come from? there is no evidence. either expand or remove. if expand with evidence, it should be a separate paragraph with a subtitle.}. %We uncover participants' motivations below. 

\textbf{\textit{Expanded User Bases.}}
Six participants (e.g., EP2, EP4, EP8) found that implementing the guidelines would attract a broader range of users. \change{User inclusion is particularly important for social VR platforms due to their core purpose of fostering socialization and connection}, as EP10 explained: \textit{``For a social VR platform, it is important to appeal to a wide audience by having that wide variety of avatars. If they just had five different avatars, they wouldn't be able to appeal to many people, and I think that they would not thrive. It is very important to have something where people can create an avatar that it either fulfills their player fantasy or make them feel like they're represented and included.''}
%To boost the user bases of their applications, participants showed willingness to follow the guidelines. 
\change{Participants praised that our guidelines covered a variety of disabilities, including those that are commonly overlooked.} For example, EP1 was excited to see guidelines addressing the needs of people with mental health conditions (e.g., G2.2, G4.1). He commented on G4.1: \textit{``This guideline is really cool. I think it's especially helpful for people [with mental health conditions], since they've been traditionally underrepresented and are so hidden.''}

\textbf{\textit{Enhanced User Retention.}}
Participants believed that by following the guidelines, they could create more positive user experiences (EP1, EP2, EP4), contributing to the user retention rate \cite{ramli2022study}. Based on participants' professional experiences (EP1, EP2), users would develop a deeper attachment to their avatars when they well represented themselves. For example, EP1 pointed out the necessity of implementing G3.2 (i.e., allow detail customization of AT) to better engage the users: \textit{``I think if you are going to add assistive technology, you should allow a bit more customization over it to fit the particular personality or identity. [Because] it's going to make the users more engaged if they can have a more personalized avatar''}. %Since positive user experiences are closely related to good user retention %\cite{ramli2022study}, 
As a result, participants were motivated to implement the guidelines to enhance their apps and promote user retention. %As EP2 commented on the guidelines: \textit{``I found the guidelines and how to apply it is easy to understand. As a previous leader in VR projects, I would say [these guidelines are] very important if you want to keep your player base in a social VR application.''} \yaxing{no need for the last example}
%\kexin{have a conclusion statement for this subsection.}

\subsubsection{Determinants of Guidelines Implementation.} \label{determinants}
Although implementing guidelines introduced benefits, participants (e.g., EP2, EP4-6, EP8) had to consider \change{multiple} factors to decide the actual implementation practices and optimize the outcomes. As EP8 indicated: \textit{``As developers, we are limited to time, money, scope [of the applications], the platform limitations, and the hardware limitations, all of that.''} The implementation of guidelines is not an all-or-nothing choice. Instead, developers and designers may selectively follow guidelines that align with their goals and available resources. We reveal several factors that influence participants' decisions below.

%\textbf{\textit{Alignment with Application Use Cases \change{(D1)}.}}

\paragraph{\textbf{Alignment with Application Use Cases (D1)}}
Seven participants (e.g., EP5, EP6) indicated that guideline implementation should align with the application's use case, including its objectives (EP1, EP5) and design styles (EP3). For example, EP1 found that implementing G2.2 (i.e., enable expressive facial animations) was very important for apps that focused on VR therapy and mental health: \textit{``G2.2 is really relevant to my use case, where we're already showing internalized stigma in some patients' [avatar facial expressions]. The [avatar] may look like looking down, or being a little more hesitant to make eye contact when talking, or in general having muted body symptoms. I think this guideline is really important in that sense, because I've barely seen any of this being offered in some ways.''}
However, EP5 and EP7 believed G2.2 was only relevant to applications that focus on social communication. In other use cases like gaming, users may not pay attention to the avatar's facial expressions (EP5), making G2.2 a lower priority.

Moreover, three participants (EP1, EP3, EP5) mentioned that the guideline should match the overall \change{application theme and} artistic style. As EP1 commented on G1.4 (i.e., prioritize human avatars): \textit{``This guideline really depends on the use case. For some use cases, [using] human avatars might be totally illogical or contradictory to what [the application is] doing. For example, if it's a fantasy VR world about dragons, users might want to only have dragon avatars. Following the guideline of always [having a] human option could be overkill in some circumstances.''}

These examples suggest that guideline implementation is highly context-dependent. Participants considered a guideline important and actionable when it aligned well with both the objectives and \change{design style} of the application.

%\textbf{\textit{Size of \change{Affected} User Groups \change{(D2)}.}}
\paragraph{\textbf{Size of Affected User Groups (D2).}}
Although recognizing the importance of the guidelines, seven participants (e.g., EP6, EP7, EP9) emphasized the need to justify the use of guidelines based on the size of affected user groups. They reflected that many guidelines were \textit{``doable but just time consuming''} (EP9). Given the constraints on development resources, particularly time (EP9) and money (EP10), developers must ensure that the features they implement attract a viable number of users. As EP9 described: \textit{``These guidelines are important. They just need a justification for people to build them. Just being realistic, there have to be some reasons to put these many hours [to build a feature]. If you see your user demographics, and it's only one percentage of your audience, then [you would not want to spend that many hours].''} EP10 also indicated the limited budget in developing an application: \textit{``Games cost money to make, and they need to be able to appeal to a wide audience.''} When the development resources are limited, developers and designers would prioritize the guidelines that \change{impact a large amount of users}. 

\paragraph{\textbf{Noticeability of Features \change{(D3)}.}}
Four participants (EP1, EP2, EP3, EP4) prioritized implementing \change{guidelines that would deliver easy-to-notice features}. They see avatars as a medium to \change{attract attention} and stimulate social interactions. If other users cannot easily notice a feature on an avatar, they found no value in implementing it. For example, EP2 found the subtle behavior tracking in G2.1 was less important than the assistive technology design in G3.1: \textit{``If you are talking about slight movements like eye twitching, this is not something that is really noticeable. For example, if I have a prosthetic limb, I want to have it on my avatar. This is something that I can actually showcase, and [other people] will see... But if it is eye-twitching, it's not something that somebody is going to notice, and my importance rating is lower on things like that. Because in social VR, people go there to interact with other people and their environment. They are not just going to stare into the avatar's eyes or something else to see if it is twitching a little bit more or less.''}
As a result, participants generally preferred implementing the guidelines that suggested more visually dominant features (e.g., G3) than those with subtle features (e.g., G2.1, G2.2), unless the use cases required. 

\subsubsection{Suggested Improvements to the Guidelines.} \label{improvements}
While acknowledging the value of the guidelines and perceiving them as a great starting point, participants offered suggestions to improve the guidelines' clarity and actionability.

\paragraph{\textbf{\change{Provide a Concrete Scope} \change{(S1)}.}}
Eight participants (e.g., EP2, EP4, EP7) were concerned \change{about the wide coverage of certain guidelines (i.e., G1.3, G3.1, G3.2, G4.1) and the lack of concrete implementation scope. Such concerns primarily focused on guidelines that represent a broad range of disabilities, such as G3.1 (i.e., offer various types of assistive technology to cover a wide range of disabilities) and those promoting flexible customization, like G1.3 (i.e., enable customization of each body parts) and G3.2 (i.e., allow detailed customization of assistive technology). %the feasibility of representing all types of disabilities. 
Participants were unsure about to what extent they should implement these guidelines (e.g., what assistive technology to include, how many customization options to provide).}
As EP4 explained: \textit{``There are so many disabilities, and they have so many different [variations]. It's very hard for designers to just cover all of them, or even most of them.''} 

Five participants (e.g., EP4, EP5, EP9) suggested to better specify the implementation scope for these broad guidelines. For instance, EP4 and EP5 desired G1.3 to have a checklist of body parts to customize and EP10 wanted a list of symbol examples to include for G4.1 (i.e., provide suitable icons, logos, and slogans that represent disability communities). 

However, two participants (EP1, EP5) pointed out a potential \change{dilemma between implementation feasibility and inclusion}, as specifying a certain scope may inadvertently marginalize the user groups that are not included in the list. As EP5 described: \textit{``It's really difficult to try to define that scope because there are so many disabilities. Trying to narrow them down to which are the best to represent, I feel that might even be more hurtful than helpful to some of the communities. But as a developer, if I wanted to try to actually take an action on some of these guidelines, I would need a defined scope that I should try to follow.''} One way to mitigate this dilemma, as suggested by EP1, is to use the scope as baseline \change{but encourage practitioners to include more options if time and resources allow}. % follow. Taking G2.2 (i.e., enable facial expressions to deliver a spectrum of emotions) as an example, EP1 suggested to narrow it down by delivering the five basic emotions as the baseline standards. This approach provides a concrete starting point while also acknowledge the need for flexibility, encouraging practitioners to include a broader range of disabilities as insights evolve. 

%our recommendation levels are based on: time/money cost/size of user groups/number of use cases scenarios...

%Our observation also echoed this viewpoint, as we found participants' (e.g., EP3, EP5, EP8) concerns about displaying disabilities on avatars leading to harassment could be mitigated by G5.3 (i.e., offering an easy control to turn on and off disability features). However, some participants, like EP4, did not recognize that this guideline could be used as a protection mechanism until we pointed it out \yuhang{why this guideline is for protection mechanism? if more of flexibly adjusting disability disclosure. it's like that you are feeding the answer to participants}. In that sense, directly stating that G5.2 can help mitigate harassment makes the guideline straightforward for developers and designers to apply. \yuhang{this paragraph does not make sense... you started with talking about use cases---suitable applications, but the example does not match... the example did not mention any specific application, but only suggest to clarify the guideline purpose.}

\paragraph{\textbf{Diversify Implementation Examples \change{(S2)}.}}
Seven participants (e.g., EP4, EP8, EP10) found the guidelines on avatar body dynamics and assistive technologies (i.e., G2.2, G2.4, G3.3) %, and G3.5 \yuhang{how is G3.5 relevant... not mentioned in later description}) 
to be less actionable. Specifically, EP5 and EP9 found that G2.2 (i.e., enable expressive facial animations) and G2.4 (i.e., leverage avatar posture to demonstrate the lived experiences) were largely restricted to the VR device's tracking capabilities. As EP5 reflected: \textit{``G2.4 does not infer any action needs to be done by the developer. Avatar motion is captured through motion tracking of the VR devices. What can or should be influenced to meet this guideline?''} When reflecting on the avatar facial expression for G2.2, EP10 discussed the technical challenges of inadequate tracking and rendering accuracy: \textit{``It's difficult to implement facial expressions that are accurate. Because the thing you need to do is the accurate [reflection] of feelings, but everybody's emotions changed dramatically and constantly. I just think with the current VR [equipment] that we have, it's going to be an extremely difficult thing to pull off emotions consistently.''}
%\yuhang{these were mentioned in 5.5.2, make sure to refer to this section for details.}
Participants (EP1, EP2, EP4, EP5) thus recommended to diversify the avatar design examples for these guidelines to improve actionability. For example, EP5 would implement G2.2 by leveraging emotes and voice chat features to convey user status instead of relying on facial tracking. 

EP1 and EP5 also found that diversified examples can inspire them to generate more creative design ideas and learn more about the disability community.  %\yuhang{quote?}
\change{For example, EP1 found G3.3 (i.e., provide high-quality simulation of assistive technologies to avoid misuse) could be supplemented with more examples to educate practitioners the stereotypical portrays: \textit{``Many developers might be new to this kind of inclusive design feature. They [probably don't know] if they're sufficiently following the guideline through. For example, I don't know all the stereotypes of different types of assistive technologies. As a developer, I might just happen to know one or two and then wouldn't know to research more. So showing more examples in addition to the wheelchair could be helpful.''}} %\yuhang{this sounds to be G3.4 not 3.3; if so, need to fix prior paragraph too}

%Meanwhile, we emphasized that the goal of examples was to demonstrate the ideas of guidelines, leaving the practical implementation open-ended. We encouraged developers and designers to incorporate their creativity when applying the guidelines. For instance, 

\paragraph{\textbf{Add Applicable Use Cases \change{(S3)}.}} Beyond concrete avatar examples,  three participants (EP1, EP5, EP9) suggested to include the applicable use cases, guiding developers and designers to apply the guideline to suitable VR applications. As discussed in Section \ref{determinants}, use cases was a key factor influencing participants' implementation decision. EP1 found that clearly stating the suitable use cases for each guideline can enhance its applicability. %\change{EP9 emphasized the importance of identifying use cases: \textit{``One of my job [responsibilities] has been identifying use case scenarios, concepting them out, and making visuals for them, so that people actually understand how they are going to use a product [in this case, a guideline].''} \yuhang{the quote is not understandable...especially last sentence.} 

\change{To better inform decision making for implementation, EP1 hoped the guidelines to suggest applicable social VR applications, allowing practitioners to prioritize the guidelines that fit for their use cases: \textit{``I [think the] way you would eventually frame these guidelines is to choose the ones that definitely apply to your applications. There might be a few guidelines that don't actually apply to your particular use case. For example, G1.4 (i.e., prioritizing human avatars) works well for certain kinds of games, especially for socially-oriented applications. But it's less applied to hardcore skill training.''}} 

\input{sections/tables/revised/overview_revised}


\paragraph{\textbf{Merging to Condense Guidelines (S4).}}
\change{Three participants (EP1, EP2, EP10) found three guidelines about assistive technologies (i.e., G3.1, G3.3, G3.4) and two guidelines about avatar dynamics (i.e., G2.1 and G2.4) contained redundant information that could be merged.
Specifically, EP2 found G3.3 (i.e., providing high-quality simulation of assistive technologies to avoid misuse) can be integrated into G3.1 (i.e., offer various types of assistive tech to cover a wide range of disabilities) by adding `high quality' suggestion to its description. While EP1 found both G3.3 and G3.4 (i.e., focus on simulating assistive technologies that empower PWD) discussed avoiding stereotypical portrays of PWD and thus could be combined into one guideline.

Moreover, two participants (EP1 and EP10) believed G2.4 (i.e., leverage avatar posture to demonstrate PWD's lived experiences) could be merged into G2.1 (i.e., allow simulation or tracking of disability-related behaviors based on user preferences), as they found posture was just a type of disability-related behaviors.}

%\yuhang{add more suggestions to map to each of your update to the guidelines, e.g., the recommendation levels}
















% guideline provide many custonmization features -> worry too much freedom will lead to misuse of disability features , or other users misunderstand the disability representation features -> uncontrolled factors, but what guidelines can do is to 

%Participants agreed with guidelines by empowering users to...P10	Yeah, sliders are great, and that gives us the ability to say, here's the limit, so that you can't do something absurd and then misuse that like that's a good thing, I agree, and then offer easy control to turn on and off disability features. This is an interesting one. See, I hadn't really thought about that, because for me, I don't, I don't express myself differently depending on the people I'm around. So it's really good. This is one of those things that you only get when you do. I think, when you ask people what they want, yeah, and these people are, you know, people who were interviewed in this are saying, I'm proud of who I am, but I understand that at times, some people will make fun of me or abuse me for it, and so I would like to be able to quickly and seamlessly turn this off to look yes like everybody else, yeah, and I would immediately implement that feature if I was doing this, because that's a fantastic idea.	found G5.2 and G5.3 great controls; provide mechanism to mitigate misuse



%For Meta Horizon Store, we reviewed thumbnails and titles of each application, eliminating those with a strong depiction of competitive gaming, which reduced the list to 39 applications. For Steam, we applied the filtering tags of "multiplayer" and "casual," and excluded DLCs from our search results. This reduced the list to 29 applications. For Viveport, we applied the same filtering tags and manually excluded DLCs, reducing the list to 13 applications. After filtering, we merged the search results and identified a total of 73 unique applications. To further narrow down our search to find applications that fit more closely with the definition of social VR, we eliminated applications that are ports of their non-VR counterparts, including Instagram, Facebook, and YouTube. We also excluded more games that, while considered casual and social, do not fit the definition of social VR, such as role-playing games with a strong emphasis. This reduced the list to 25 applications. %Finally, for the purpose of this study, we aimed to examine avatar customizability and the customization process. Therefore, we eliminated applications that, while generally considered social VR, do not provide enough flexibility for our examination, such as Among Us VR and Half + Half. This created a final list of 20 applications. Two members of the research team discussed and consolidated the final list to reach an agreement.

% We conducted an evaluation to test and iterate on the initial set of 20 avatar design guidelines.

% Once the guidelines for disability representation in social VR were finalized, a heuristic evaluation was conducted with industry professionals focused on suitability and clarity of these guidelines. \scott{not sure yet how many or what format the assessments are going to take place.} Industry professionals were presented with the guidelines and asked to assess them using a selection of current VR applications which included a character customization system. These applications included the following: Rec Room, VRChat, Meta Horizon, and Roblox. Evaluations were conducted in both synchronous and asynchronous formats as requested by the industry professional. \scott{List the applications here. Evaluations might be asynchronous - need to wait for more info to continue.}

% \kexin{I think the whole list selection thing should take no more than three paragraphs - likely to be one para for how to select/inclusion criteria, and another para to introduce the selected five apps}

% To identify the social VR applications for this review, we conducted a comprehensive search on three mainstream VR application stores: Oculus, Viveport, and Steam. Our search focused on applications available in the United States from March to May 2024. We used the keyword “social” and identified a total of 528 VR applications: 130 from Oculus, 163 from Viveport, and 234 from Steam, with 23 applications available across multiple stores.

% To narrow down the scope, we applied several filtering criteria. First, we ensured that the applications were currently available to play, eliminating numerous games that, despite being listed on platforms like Steam, were not available, such as VAST. Next, we focused on applications featuring a relatively customizable social avatar, which reduced our pool by approximately half. Further, we filtered out applications that did not use a social avatar as the primary mode of socializing, excluding platforms like Instagram and Facebook, which, despite having social VR clients, are largely clones of their mobile counterparts. We also excluded applications that lacked a strong emphasis on socializing, such as sports-focused games like SHOOTOUT and Zenith: Nexus. After consideration of the popularity of certain applications, options such as Bigscreen Beta were excluded as well.

% In addition to VR applications, we surveyed non-VR games featuring extensive avatar customization based on comments from interviews. To avoid redundancy, we eliminated games with similar avatar creation processes or those that generally fell into the same categories. For instance, among the numerous VRChat clones like NeosVR, we selected only the most unique, original, or popular versions, specifically VRChat itself.

% Our goal was to incorporate social games that best represent various approaches to avatar creation. This thorough selection process resulted in a final list of five games: Meta Horizon Worlds, Minecraft, Roblox, Second Life, and VRChat.

% [place holder]

% The rationale for including each game is as follows: \kexin{the following are not rationale but review results - @Ang rewrite and reformat, should be in complete sentence in the main text; then attach a table for the five app with review results}