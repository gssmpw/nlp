\newcommand{\N}{{\mathcal{N}}}
\newcommand{\C}{{\mathcal{C}}}
\newcommand{\D}{{\mathcal{D}}}
\newcommand{\Hc}{{\mathcal{H}}}
\newcommand{\bmu}{{\boldsymbol\mu}}
\newcommand{\btheta}{{\boldsymbol\theta}}
\newcommand{\tlim}{{t \rightarrow \infty}}

\section{Convergence Analysis}\label{sec:convergence}

Our first result establishes that the dual problem always has a (finite) solution, and the optimal flow in response to such a solution is primal optimal.
\begin{lemma}\label{lem:strong_duality} For any instance of the primal problem \eqref{eq:primal_problem}, the corresponding dual problem \eqref{eq:dual_problem} has a solution, \textit{i.e.}, there exists $\lambda^* \in \mathbb{R}^E$ such that 
\(D(\lambda^*) = D^* \triangleq \inf_{\lambda \in \mathbb{R}^E} D(\lambda). \)
Further, the set $F(\lambda^*) = \argmax_{f \in A} L(f, \lambda^*)$ contains a solution to \eqref{eq:primal_problem}.
\end{lemma}
\begin{proof} The lemma follows immediately from Proposition 3.4.2 of \cite{bertsekas1999nonlinear}, which states sufficient conditions for strong duality to hold. Those conditions are satisfied by our problem because: 
\begin{itemize}
    \item \eqref{eq:primal_problem} has a solution $f^*$ because the set of feasible solutions is non-empty and compact.
    \item The constraint set $A$ is a convex polytope and the detailed balance condition is a linear constraint.
    \item The objective function $U(f) + H(f)$ can be extended for all $f \in \mathbb{R}^P$ in a continuously differentiable manner by defining each $U_{i,j}(\cdot)$ outside the interval $[0, a_{i,j}]$ to be appropriate affine functions.
\end{itemize}
By Proposition 3.4.2(a) of \cite{bertsekas1999nonlinear}, \eqref{eq:dual_problem} has a solution $\lambda^*$. Since $\lambda^*$ is a minimizer of $D(\lambda)$, it must be that $0 \in \partial D(\lambda^*)$. By Lemma \ref{lem:dual_subgradient}, this implies that there exists $f^* \in F(\lambda^*)$ such that $Rf^* = 0$, \textit{i.e.}, there exists a feasible $f^*$ in $F(\lambda^*)$. By Proposition 3.4.2(b), this $f^*$ is a solution to \eqref{eq:primal_problem}.
\end{proof}

Our next result is to establish conditions under which the dual function is smooth. We invoke standard properties of the Fenchel conjugate of convex functions to prove this result (see Section 2.7 of \cite{shalev2012online} for a reference).

\begin{assumption}\label{assumption_eta_positive}
    $\eta_{i,j} \geq \eta > 0 \ \forall \ (i,j) \in \N$. \newline
\end{assumption}

\begin{lemma}\label{lem:smoothness}
    Under Assumption \ref{assumption_eta_positive}:
    \begin{itemize}
        \item $F(\lambda) = \argmax_{f \in A} L(f, \lambda)$ is a singleton for all $\lambda$.
        \item The dual function is smooth with parameter $\Vert R \Vert_{op}^2/\eta$, where $\Vert \cdot \Vert_{op}$ denotes the operator norm of a matrix.
        \item $F(\lambda)$ is a continuous function of $\lambda$.
    \end{itemize}
\end{lemma}
\begin{proof}
    Under Assumption \ref{assumption_eta_positive}, the Lagrangian, $L(f, \lambda)$, is  $\eta$-strongly concave in $f$. This is because $L(f,\lambda)$ is the sum of an $\eta-$strongly concave function $H(f)$, a concave function $U(f)$, and a linear function $\lambda^TRf$. The strong concavity of $L$ implies the uniqueness of $F(\lambda)$.
    
    To show the smoothness of $D(\lambda)$ with respect to $\lambda$, define $\Tilde{D}(\mu) \triangleq \max_{f \in A} \Tilde{L}(f, -\mu)$, where $\Tilde{L}(f, \mu)$ is defined in \eqref{eq:lagrangian_f_mu}. By this construction, $\Tilde{D}(\mu)$ is the Fenchel conjugate of $-(H(f) + U(f))$. Since $-(H(f) + U(f))$ is an $\eta$-strongly convex function, $\Tilde{D}(\mu)$ is a $1/\eta$-smooth function of $\mu$ \cite{shalev2012online}. Since $D(\lambda) = \Tilde{D}(-R^T\lambda)$, it follows that $D(\lambda)$ is $\Vert R \Vert_{op}^2/\eta$-smooth function of $\lambda$.

    By Lemma \ref{lem:dual_subgradient}, $\nabla D(\lambda) = RF(\lambda)$. By definition of smoothness, $\nabla D(\lambda)$ is a continuous function of $\lambda$, which in turn, implies the continuity of $F(\lambda)$ with respect to $\lambda$.
\end{proof} 

We now present our main result, which states that with suitably small stepsizes, the DEBT control protocol converges to a solution of \eqref{eq:primal_problem}.

\begin{assumption}\label{assumption_small_stepsize}
    The stepsize of \eqref{eq:algorithm} satisfies $\gamma < \eta/\Vert R \Vert^2_{op}$.\newline
\end{assumption}

\begin{proposition}\label{prop:convergence}
    Under Assumptions \ref{assumption_eta_positive} and \ref{assumption_small_stepsize}:
    \begin{itemize}
        \item \(D(\lambda[t]) - D(\lambda^*) \leq \frac{\Vert \lambda^* \Vert}{2\gamma t}  \ \forall \ t \geq 1\).
        \item $\lambda[t] \rightarrow \lambda^{**}$ for some $\lambda^{**} \in \argmin_{\lambda \in \mathbb{R}^E} D(\lambda)$  as $t \rightarrow \infty$.
        \item {$f[t] \rightarrow f^*$ as $t \rightarrow \infty$}, where $f^*$ is the unique solution to \eqref{eq:primal_problem}.
    \end{itemize}
\end{proposition}
\begin{proof}
    The first point is a standard result in convex optimization, namely gradient descent with a constant stepsize, when applied to a smooth convex function, leads to the function value converging to its infimum at a rate of $O(1/t)$ (see Section 3.2 of \cite{bubeck2015convex}). In the proof of this result, a key step is to establish that for any $\lambda^{**} \in \argmin_{\lambda \in \mathbb{R}^E}D(\lambda)$, $\Vert \lambda[t] - \lambda^{**}\Vert$ is a nonincreasing sequence. This, coupled with the existence of a finite minimizer (Lemma \ref{lem:strong_duality}), implies the second point. The third point follows from the previous point on the convergence of $\lambda[t]$, the continuity of $F(\lambda)$ with respect to $\lambda$ (Lemma \ref{lem:smoothness}), and the fact that $f^* = F(\lambda^*)$ is primal optimal (Lemma \ref{lem:strong_duality}).
\end{proof}