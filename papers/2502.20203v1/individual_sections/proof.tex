\section{Proof of Lemma \ref{lem:finite_minimizer}}\label{sec:proof}
\newcommand{\RP}{\mathbb{R}^P}

For ease of exposition, we introduce some terminology and state some basic facts about sequences in a finite-dimensional Euclidean space. 
Let $P$ be a finite indexing set. 
%\textcolor{red}{We have used $P$ to denote the set of paths. Should we use the notation $\RP$ here, or should we switch to $\mathbb{R}^N$, where $N$ is an integer?}
Let $\bmu  = \{\bmu[t]\}_{t \in \mathbb{N}}$ denote a sequence in $\RP$. 
Let $(\bmu_p: p \in P)$ denote the components of $\bmu$; \emph{i.e.}, $\bmu_p$ is a scalar sequence. 
For any scalar sequence, there exists a subsequence that either converges or diverges; in the latter case, it may diverge to $\infty$ (we call such sequences by the term \textit{positively divergent}), or it may diverge to $-\infty$ (call such sequences by the term Let $P$ be a finite indexing set \textit{negatively} divergent). 
Therefore, for every sequence $\bmu \in \RP$, there exists a subsequence of $\bmu$, call it $\Tilde{\bmu}$, such that each of its components are either convergent, positively divergent, or negatively divergent. For any sequence $\bmu$, let $\C(\bmu), \D^+(\bmu)$ and $\D^-(\bmu)$ denote the set of convergent, positively divergent, and negatively divergent components respectively. %\textcolor{red}{convergent or converging, divergent or diverging, in the current usage here?}


Let $\mu^*_p$ denote the limit point of $\bmu_p$, for all $p \in \C(\mu)$. 
If all the components of $\bmu$ converge, then let $\mu^* = (\mu^*_p: p \in P)$ denote the limit point of $\bmu$. 
Let $\Hc$ denote a subspace of $\mathbb{R}^P$; its dimension could be anything from zero to $|P|$. 
We say $\bmu \in \Hc$ to denote that $\bmu[t] \in \Hc$ for all $t \in \N$. 
If $\bmu \in \Hc$, and $\bmu$ converges to $\mu^*$, then $\mu^* \in \Hc$.  
We use the terminology defined above to derive the following result, a key step in proving Lemma \ref{lem:finite_minimizer}.

\begin{lemma}\label{lem:finite_limit} Let $\Hc$ be a subspace of a finite-dimensional Euclidean space. Let $\bmu \in \Hc$ be a sequence such that each of its components are either convergent, positively divergent, or negatively divergent. Further, let $c > 0$ be a given constant. Then, there exists a point $\mu^* \in \Hc$ such that:
\begin{itemize}
    \item $\mu^*_m = \lim_{\tlim} \bmu_m[t] \ \forall \ m \in \C(\bmu)$
    \item $\mu^*_m \geq c \ \forall \ m \in \D^+(\bmu)$
    \item $\mu^*_m \leq -c \ \forall \ m \in \D^-(\bmu)$
\end{itemize}
\end{lemma}

\begin{proof}
We prove this result by an induction argument on the number of diverging components of $\bmu$: $|\D^+(\bmu)| + |\D^-(\bmu)|$. The base case, with zero diverging components, is trivial; the limit point of $\bmu$ itself satisfies the required conditions. For any $d \in \mathbb{N}$, assume the claim is true for all sequences with strictly less than $d$ diverging components. In what follows, consider a sequence $\bmu \in \Hc$ such that each component of $\bmu$ is either convergent or divergent and the number of diverging components is exactly $d$. 

%Further, assume the number of diverging components of $\bmu$ is $d$. \textcolor{red}{In your notes, I see a comment suggesting that we add the phrase ``by going going to a subsequence if necessary". However, I do not think that's necessary.} 
Given such a sequence, we can find a dominant diverging component $n$ such that $\lim \sup |\bmu_m/\bmu_n| \leq 1 \ \forall \ m \in [N]$. Without loss of generality, assume $n$ is a positively diverging component of $\mu$. Since $\bmu/\bmu_n$ is a bounded sequence, there exists a subsequence of $\bmu/\bmu_n$, call it $\btheta$, such that each of its components converges. Let $\theta^*$ denote the limit point of $\btheta$. It follows that:
\begin{itemize}
    \item $\theta^*_n = 1$
    \item $\theta^*_m \in [0, 1] \ \forall \ m \in \D^+(\bmu)$.
    \item $\theta^*_m \in [-1, 0] \ \forall \ m \in \D^-(\bmu)$.
    \item $\theta^*_m = 0 \ \forall \ m \in \C(\bmu)$.
\end{itemize}
We can also infer that $\theta^*$ is a point in $\Hc$, as follows:
\[\bmu \in \Hc \ \Rightarrow \ \bmu/\bmu_n \in \Hc \ \Rightarrow \ \btheta \in \Hc \ \Rightarrow \ \theta^* \in \Hc\]

Let $\Bar{\bmu}$ be a subsequence of $\bmu - \bmu_n\theta^*$ with either converging or diverging components. It follows that:
\begin{itemize}
    \item $\Bar{\bmu}$ is a sequence in $\Hc$. Indeed, $\bmu \in \Hc$ and $\theta^* \in \Hc$ implies $\bmu - \bmu_n\theta^* \in \Hc$, which implies $\Bar{\bmu} \in \Hc$.
    \item For any $m$ such that $\theta^*_m = 0$, $\Bar{\bmu}_m$ is a subsequence of $\bmu_m$. This is because $\theta^*_m = 0$ implies $(\bmu - \bmu_n \theta^*)_m = \mu_m$. 
    \item All converging components of $\bmu$ are also converging components of $\Bar{\bmu}$ and their limits agree. This follows from the point above and the fact that for all $m \in \C(\bmu)$, $\theta^*_m = 0$.
    \item $\Bar{\bmu}_n$ is a sequence that is identically zero. Therefore, $n$ is a converging component of $\Bar{\bmu}$ but a diverging component of $\bmu$. 
\end{itemize} 
These properties of $\Bar{\bmu}$ imply $\Bar{\bmu}$ is a sequence in $\Hc$ with strictly fewer than $d$ diverging components. By our induction hypothesis, we know that there exists a point $\Bar{\mu}^* \in \Hc$ such that:
\begin{itemize}
    \item $\Bar{\mu}^*_m \geq c$ for every $m \in \D^+(\Bar{\bmu})$ and $\Bar{\mu}^*_m \leq -c$ for every $m \in \D^-(\Bar{\bmu})$.
    \item $\Bar{\mu}^*_m = \lim_{\tlim} \Bar{\bmu}_m[t] \ \forall \ m \in \C(\Bar{\bmu})$.
    \item From the properties of $\Bar{\bmu}$ discussed above, it follows that $\Bar{\mu}^*_m = \lim_{\tlim} {\bmu}_m[t] \ \forall \ m \in \C({\bmu})$ and $\Bar{\mu}^*_n = 0$.
\end{itemize}

Let $a \in \mathbb{R}$ be sufficiently large such that for all $m$,
\[a\theta^*_m + \Bar{\mu}^*_m \geq c \text{ if } \theta^*_m > 0  \text{ and }
a\theta^*_m + \Bar{\mu}^*_m \leq -c \text{ if } \theta^*_m < 0\]
Let $\mu^* = a\theta^* + \Bar{\mu}^*$. We now show that the point $\mu^*$ satisfies the criteria of the claim. Firstly, $\mu^* \in \Hc$ because $\theta^* \in \Hc$ and $\Bar{\mu}^* \in \Hc$. Secondly, for any $m \in \C(\bmu)$, $\theta^*_m = 0$, which implies $\mu^*_m = \Bar{\mu}^*_m$. Thirdly, for any $m \in \D^+(\bmu)$, there could be one of two cases:
\begin{itemize}
    \item $\theta^*_m = 0$. As argued above, this implies $\Bar{\bmu}_m$ is a subsequence of $\bmu_m$. Therefore, $m \in \D^+(\bmu)$ $\Rightarrow m \in \D^+(\Bar{\bmu})$. 
    Further, $\theta^*_m = 0 \Rightarrow \mu^*_m = \Bar{\mu}^*_m$. By our choice of $\Bar{\mu}^*$, $\Bar{\mu}^*_m \geq c$. Therefore, $\mu^*_m \geq c$.
    \item $\theta^*_m \neq 0$. Since $m \in \D^+(\bmu)$, $\theta^*_m > 0$. By our choice of $a$, $\mu^*_m = a\theta^*_m + \Bar{\mu}^*_m \geq c$.
    \end{itemize}
The case where $m \in \D^-(\bmu)$ can be argued similarly to show that $\mu^*_m \leq -c$. Thus, $\mu^*$ is a point that satisfies the criteria in the induction hypothesis for the sequence $\bmu$ which has $d$ diverging components.
\end{proof}

Armed with the above result, we now proceed to prove the existence of a finite minimizer for $D(\lambda)$ over the entire space $\mathbb{R}^E$. It suffices to show that there exists $\mu^* \in \Hc$ such that 
\begin{align}
    D(\mu^*) &= \inf_{\mu \in \Hc} D(\mu), \text{ where } \\
    \Hc &\triangleq \{\mu \in \mathbb{R}^P: \mu = R^T \lambda \text{ for some } \lambda \in \mathbb{R}^E\}
\end{align}
From such a $\mu^*$, one can find a $\lambda^* \in \mathbb{R}^E$ such that $D(\lambda^*) = \inf_{\lambda \in \mathbb{R}^E} D(\lambda)$ (for example, by multiplying $\mu^*$ on the left with the pseudo-inverse of $R^T$).

% Thus, $D(\mu)$ is simply a sum of noninteracting scalar-valued functions $D_{i,j}(\cdot)$. Each $D_{i,j}(\mu_{i,j})$ is a convex, nonincreasing function of $\mu_{i,j}$. In fact, its domain can be split into three regions:
% \begin{itemize}
%     \item $D_{i,j}(\mu) = U_{i,j}(a_{i,j}) - a_{i,j}\mu$ if $\mu < U'_{i,j}(a_{i,j})$. Thus, in this region, the function is linear with a negative slope.
%     \item $D_{i,j}(\mu)$ is finite and bounded if $\mu \in [U'_{i,j}(a_{i,j}), U'_{i,j}(0))$. Here, $D_{i,j}(\mu)$ is nonlinear, decreasing, and convex.
%     \item $D_{i,j}(\mu)$ is identically zero for all $\mu \geq U'_{i,j}(0)$.
% \end{itemize}

% For some routing matrices $R$, $\Hc$ is equal to the whole space $\mathbb{R}^P$. In this case, the optimization problem is unconstrained. In this case, it is easy to see that $D(\mu)$ has a finite minimizer, because $D(\mu)$ is a sum of noninteracting scalar functions, each of which has a finite minimizer: $\mu_{i,j,k} = U'_{i,j}(0)$ for all $(i,j,k)$. Indeed, this choice of $\mu$ implies $\mu_{i,j} \geq U'_{i,j}(0)$, which implies $D_{i,j}(\mu_{i,j}) = 0$, which is the minimum value of $D_{i,j}(\cdot)$. However, in the general case, $\Hc$ is a subspace of the whole domain and the existence of a finite minimizer is not immediately obvious. 

% To show the desired result, we adopt the following approach. First, we show the existence of a sequence of a sequence $\bmu \in \Hc$ such that $D(\bmu)$ is decreases towards $D^*$. Next, we show that such a sequence either has converging components or components diverging to infinity. The crux of the argument is to use Lemma \ref{lem:finite_limit} to show that there exists a point $\mu^* \in \Hc$ that agrees with the limit of the converging components of $\mu$ and is sufficiently large for the diverging components of $\mu$. This implies that $D(\mu^*)$ equals the limit of $D(\bmu)$, thereby demonstrating that $\mu^*$ is a finite minimizer of $D(\cdot)$ over $\Hc$.

We begin by making some of observations about $D(\mu)$. For brevity, whenever clear from context, we suppress the indices $(i,j)$ and use abbreviated notations $p_k, f_k, \mu_k$ for paths, flows, and path prices between nodes $i$ and $j$.
\begin{enumerate}%[label=O\arabic*]
    \item The dual function can be written as the sum of noninteracting functions:
    \begin{equation}
        D(\mu) = \sum_{(i,j) \in \N} D_{i,j}(\mu_{i,j}),
    \end{equation}
    where $\mu_{i,j}$ denotes the vector comprised of prices of all paths from $i$ to $j$. This follows from the definition of the dual function (see \eqref{eq:dual_function}) and the separability of the Lagrangian (see \eqref{eq:lagrangian_f_mu})). %\textcolor{red}{(to be justified a bit more)}
    \item For any node-pair $(i,j)\in \N$, if $\mu_k \geq U'_{i,j}(0)$, then the path $p_k$ does not carry flow. Therefore, $D_{i,j}(\mu_{i,j})$ remains constant for all values of $\mu_k \geq U'_{i,j}(0)$ \textcolor{red}{(explain better)}
    \item If two paths $p_k$ and $p_{k'}$ carry strictly positive flows $f_k$ and $f_{k'}$, the following inequality holds:
    \[a_{i,j} \geq f_k - f_{k'} = (\mu_k - \mu_{k'})/2\eta_{i,j}\]
    \textcolor{red}{(refer to an earlier equation here).}
    Thus, two paths carrying strictly positive flows can differ in their price by at most $2\eta_{i,j}a_{i,j}$. It follows that 
    \[\mu_{k'} \geq \min_{k} \mu_k + 2\eta_{i,j}a_{i,j} \Rightarrow f_{k'}  = 0.\]
    \item If, for any $k$, $\mu_k \rightarrow -\infty$, then $D_{i,j}(\mu_{i,j}) \rightarrow \infty$. \textcolor{red}{(justify)}.
\end{enumerate}

The remaining proof follows in the following steps.

First, by the definition of the infimum over a set, we can produce a sequence $\boldsymbol{\mu}  \in \Hc$ such that $D(\bmu[t])_{t \in \mathbb{N}}$ is a nonincreasing sequence and 
\[D(\bmu[t]) \xrightarrow{t \rightarrow \infty} D^* = \inf_{\mu \in \Hc} D(\mu).\]

Second, since $D(\bmu[t])$ being a nonincreasing sequence, each component of $\bmu$ must remain bounded below. This follows from the last of the four observations above. Further, we can produce a subsequence of $\bmu$ which has either convergent or positive divergent components. It cannot have negative diverging components as each component is bounded below. With some abuse of notation, let $\bmu$ denote this subsequence for the remainder of the proof. 
 
Let $c$ be chosen as $\max_{(i,j) \in \N} U'_{i,j}(0)$. Invoking Lemma \ref{lem:finite_limit}, there exists $\mu^* \in \Hc$ such that:
\begin{itemize}
    \item for every $(i,j,k)$ such that $\bmu_{i,j,k}[t]$ converges, $\mu^*_{i,j,k} = \lim_{\tlim}\bmu_{i,j,k}[t]$. %Therefore, $D_{i,j}(\mu^*_{i,j,k}) = \lim_{\tlim}D_{i,j}(\bmu_{i,j,k}[t])$ (since $D_{i,j}(\cdot)$ is a convex, and therefore continuous function)
    \item for every $(i,j,k)$ such that $\bmu_{i,j,k}[t]$ diverges to $\infty$, $\mu^*_{i,j,k} \geq c$. %Therefore, $D_{i,j}(\mu^*_{i,j,k}) = 0 = \lim_{\tlim}D_{i,j}(\bmu_{i,j,k}[t])$.
\end{itemize}

We claim that this choice of $\mu^*$ is a finite minimizer of $D(\mu)$, i.e.,
$$D(\mu^*) = \lim_{\tlim}D(\bmu[t]) = D^*.$$
It follows from the observations above that
\begin{align*}
    D_{i,j}(\mu^*_{i,j}) = \lim_{\tlim}D_{i,j}(\bmu_{i,j}[t]) \ \forall \ (i,j) \in \N. \\
    \Rightarrow D(\mu^*) = \lim_{\tlim}D(\bmu[t]) = D^* = \inf_{\mu \in \Hc} D(\mu)
\end{align*}
This concludes the proof of Lemma \ref{lem:finite_minimizer}. \textcolor{red}{explain a little more!}

% There are three possible cases to consider for each $(i,j) \in \N$:
% \begin{itemize}
%     \item For each $k \in [|P_{i,j}|]$, $\bmu_{i,j,k}[t]$ converges to some finite value. In this case, $\mu^*_{i,j,k} = \lim_{\tlim}\bmu_{i,j,k}[t]$ by construction. Therefore,  $\mu^*_{i,j} = \lim_{\tlim}\bmu_{i,j}[t]$, because the optimization problem in \eqref{eq:softmin} gives a continuous mapping from $(\mu_{i,j,k})_k$ to $\mu_{i,j}$. This implies \eqref{eq:dual_limit2}, since the dual function is continuous.
%     \item For each $k \in [|P_{i,j}|]$, $\bmu_{i,j,k}[t]$ diverges to $\infty$, which implies $\bmu[t]$ diverges to $\infty$, which implies $D_{i,j}(\bmu[t])$ converges to zero. By our construction, each $\mu^*_{i,j,k} \geq c$. Since $\mu^*_{i,j} \geq \min_{k} \mu^*_{i,j,k}$, $\mu^*_{i,j} \geq c$. This implies $D_{i,j}(\mu^*_{i,j})$ equals zero, and therefore, \eqref{eq:dual_limit2} holds.
%     \item For some $k \in [|P_{i,j}|]$, $\bmu_{i,j,k}[t]$ diverges to $\infty$, while for others, $\bmu_{i,j,k}[t]$ converges to some finite value. Consider one of two subcases:
%     \begin{itemize}
%         \item Among the converging components of $\bmu_{i,j,k}$, there is at least one component which converges to a value less than $U'_{i,j}(0)$. Therefore $\min_k \mu^*_{i,j,k} < U'_{i,j}(0)$. For each of the diverging components, $\mu^*_{i,j,k} > U'_{i,j}(0) + 2\eta_{i,j}$. Therefore, in the solution to \eqref{eq:softmin}, these components will have $\Tilde{f_{i,j,k}} = 0$; this holds for both $(\mu^*_{i,j,k})_k$ as input as well as $\lim_{\tlim}(\bmu_{i,j,k}[t])_k$. Therefore, $\mu^*_{i,j} = \lim_{\tlim} \bmu_{i,j}[t]$, which implies \eqref{eq:dual_limit2}.

%         \item All the converging components of $\bmu_{i,j,k}$ converge to a value more than $U'_{i,j}(0)$. In this case, $\lim_{\tlim}\bmu_{i,j}[t] \geq U'_{i,j}(0)$ and $\mu^*_{i,j} \geq U'_{i,j}(0)$. Therefore, $\lim_{\tlim}D(\bmu_{i,j}[t]) = D(\mu^*_{i,j}) = 0$, which implies \eqref{eq:dual_limit2}.
%     \end{itemize}
% \end{itemize}
% % \textcolor{red}{
% % In summary, for every $(i,j,k) \in P$,
% % \begin{align*}
% %     D_{i,j}(\mu^*_{i,j,k}) &= \lim_{\tlim}D_{i,j}(\bmu_{i,j,k}[t]) \\
% %     \Rightarrow \min_{k} D_{i,j}(\mu^*_{i,j,k}) &= \min_{k} \lim_{\tlim}D_{i,j}(\bmu_{i,j,k}[t]) \\
% %     \Rightarrow D_{i,j}(\min_{k}  \mu^*_{i,j,k}) &=  \lim_{\tlim}D_{i,j}(\min_{k} \bmu_{i,j,k}[t]) \\
% %     \Rightarrow \sum_{(i,j) \in \N} D_{i,j}(\min_{k}  \mu^*_{i,j,k}) &=  \lim_{\tlim} \sum_{(i,j) \in \N}D_{i,j}(\min_{k} \bmu_{i,j,k}[t]) \\
% %     \Rightarrow D(\mu^*) &=  \lim_{\tlim} D(\bmu[t]) = D^*
% % \end{align*}
% % }
% For every $\mu^* \in \Hc$, there exists a $\lambda^* \in \mathbb{R}^E$ such that $\mu^* = R^T \lambda^*$ and therefore $D(\mu^*) = D (\lambda^*)$. Thus, a finite solution for the dual problem as stated in \eqref{eq:dual_problem_mu} implies a finite solution for the original formulation \eqref{eq:dual_problem}. This concludes the proof of Lemma \ref{lem:finite_minimizer}.


