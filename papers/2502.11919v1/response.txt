\section{Related Work}
\label{sec:related}
%\my{Beef up this section...could cover some grounds about AI explanations, and previous studies that highlight explanations need to be provided selectively/progressively, etc.}

\subsection{AI-Assisted Decision Making}
The increasing prevalence of AI-assisted decision making has led to a growing line of research to investigate how people engage with, trust in, and rely on AI models in this new collaboration paradigm \textbf{Amersfoort et al., "When Does the Human-AI Collaboration Improve?"}__. Early studies focus on empirically identifying factors that influence AI-assisted decision making, including the AI model's performance\textbf{~Kim et al., "The Impact of Model Performance on Human Trust"}____, the explanation of the model recommendation\textbf{~Ribeiro et al., "Model-Agnostic Interpretability of Machine Learning Predictions"}____,  the decision making workflow\textbf{~Marrer et al., "Designing AI-Driven Decision Support Systems for Complex Tasks"}____, and the influence of task complexity on human-AI interactions\textbf{~Kim et al., "The Role of Task Complexity in Human-AI Collaboration"}____.

While it is expected that the complementarity between AI models and humans could enable the human-AI team to outperform either party alone, in practice, the collaboration between humans and AI in decision making is widely observed to be suboptimal _____. It is observed that people usually exhibit inappropriate reliance on AI models\textbf{~Kim et al., "The Dark Side of Human-AI Collaboration"}____. For instance, the design of conversational interfaces can influence users' trust, sometimes causing overreliance on AI recommendations\textbf{~Gupta et al., "Designing Conversational Interfaces for Trust and Reliance"}____. In addition, people may also blindly rely on AI in time-pressured environments, where the presence of AI suggestions may speed up decision making at the cost of accuracy _____. In contrast, people could also reject the AI model recommendation even when it is correct, noted as underreliance on AI\textbf{~Ratcliff et al., "Human-AI Collaboration: A Study of Trust and Reliance"}____. Recent research has also discussed how misaligned AI outputs can contribute to people's underreliance on AI systems despite their accuracy _____. To help decision makers interact with and rely on the AI model more appropriately, a wide range of approaches was recently developed _____. For instance, the cognitive forcing function encourages people to engage with AI more cognitively, thus potentially reducing people's overreliance on the AI model\textbf{~Kiddon et al., "Cognitive Forcing Functions for Human-AI Collaboration"}____. \textbf{Ribeiro et al., "Explainable AI and the Case for Adversarial Training"}__ explored the calibration of user trust in AI-assisted decision making by inferring the correctness likelihood of both human and AI on a decision case, which informs the adaptive presentations of the AI model's decision recommendations. 

In addition, providing AI explanations generated by various post-hoc explainable AI (XAI) methods\textbf{~Kim et al., "The Impact of Model-Agnostic Interpretability on Human Trust"}____ that reveal the decision rationale of AI models is another popular approach used, %with the 
aiming to improve humans' understanding of the AI model's behavior and enable humans to calibrate their trust in AI. 
%, which in turn allows users to calibrate their trust in the AI model accordingly. 
However, many empirical studies have observed that people often struggle to process and comprehend these explanations\textbf{~Goyal et al., "Understanding the Limitations of Explainable AI"}____, letting alone utilize the insights revealed from these explanations to trust AI more appropriately. %which fails to meet designers' expectations of positively influencing human engagement with AI models. 
To realize the positive utility of explanations in AI-assisted decision making, recent research highlights the need to provide explanations selectively or progressively to aid human comprehension _____. For instance, \textbf{Kim et al., "Selective Highlighting of AI Explanations for Human-AI Collaboration"} demonstrated that selectively highlighting AI explanations, which align with the userâ€™s own decision rationale, can increase agreement between human decisions and AI model predictions and reduce human overreliance on AI recommendations. \textbf{Goyal et al., "Progressive Feedback for Human-AI Collaboration"} showed that users may benefit from
initially simplified feedback that hides potential AI system errors and assists users in building working heuristics about how the AI system operates progressively. In this work, we make an initial attempt to explore that \textit{in the absence of AI explanations}, whether the incorporation of the natural-language-based, LLM-powered analysis of the AI recommendations on decision making tasks %as a  explanation 
can promote more appropriate reliance behavior of humans on AI models in decision making, and how to present such analysis in the most effective way.


% explanations are a popularly employed method to improve joint decision making via revealing the AI model decision rationales to humans____\hx{, and research has shown that task complexity plays a key role in shaping trust and reliance on AI systems, requiring tailored interventions to manage uncertainty and reliance behavior____}. Moreover, a series of interventions____ are designed to influence humans in AI-assisted decision making____.  
%Well-designed training process, as another approach, also hold its promise to guide human decision makers better utilize the AI model____. Despite the great insight provided, the effectiveness of the approaches are either mixed (e.g., in price of under-reliance) or could only be applied to a specific population (e.g., AI literacy). Thus, there has been an universal approach for appropriate and effective AI-assisted decision making.

\subsection{Human-LLM Interaction}

% \my{You should discuss the TalkToModel paper somewhere in this section.}
Recently, large language models (LLMs) have demonstrated their exceptional capabilities across various applications to assist humans, including creative writing\textbf{~Holtzman et al., "The Curious Case of Adversarial Attacks on Language Models"}____, software engineering\textbf{~Zhu et al., "Automated Programming for Software Development"}____, and generative design ____ , which has sparked significant interest within the HCI community to investigate the interaction between humans and LLMs _____. On the one hand, LLMs are increasingly utilized to directly create content or solve problems, which is shown to match or even surpass humans' performance. For example, \textbf{Radford et al., "Improving Language Understanding by Generative Models"} presented the framework leveraging LLMs to create coherent scripts and screenplays with humans in the loop. 
% \my{What do you mean by ``with humans audition''?}. 
In other cases, LLM-based services provide foundational support for human creation, such as generating coding schemes for qualitative analysis____. 
In these human-LLM collaboration scenarios, a key challenge is that laypeople often lack the skill to effectively prompt LLMs to generate the outputs that they desire ____ . To address this challenge, novel approaches like AI Chains____, automatic prompting methods ____ , and interactive interfaces____ are developed to enhance the effectiveness of human-LLM interaction, either by improving LLMs' usability ____ or by guiding humans' engagement with LLMs.

%\my{To update.}
%However, effective human-LLM interaction requires careful design to optimize usability and outcomes. Without this, such collaborations can lead to suboptimal results. 
%Exemplified by the overreliance on LLM led 
Researchers have also explored the potential of LLMs in AI-assisted decision making. For example, LLMs could directly provide decision recommendations. However, it was found that the 
overconfident and seemingly convincing LLM outputs can mislead people to believe them to be correct____ and result in people's overreliance on LLM____. 
%, as the convincing yet incorrect outputs can potentially mislead users who may rely on them as if they were correct ____ . 
%\my{I'm not sure what does this sentence mean.}. 
%\my{This sentence is not grammatically correct.}. 
Recently, \textbf{Goyal et al., "Interactive Dialogue Systems for Human-AI Collaboration"} developed an interactive dialogue system that allows users to inquire about the reasons behind the AI model's predictions. This system leverages a LLM to parse user intent and match it with pre-specified, handcrafted answers, demonstrating significant potential to enhance user understanding and decision performance through conversational interactions with the AI model.
% \my{So in their paper, only human understanding is improved, not human decision performance? How is our work different from theirs? (Or what makes our setting different so that in the first experiment, we find providing LLM-powered analysis is not that helpful?)} \zy{they also see the improvements over the decision accuracy... In their work, the users have more freedom to chat with the system like why this prediction happens, how one feature affects the prediction, and what the typical errors the AI model would have; in addition, they used LLM mainly to identify user intent, they do not have LLM directly analyze the task and provide analysis. Their language-format explanations are directly parsing from the post0-hoc explanation. }. \my{Then, try to include these points in the text (in a succinct manner.} 
Different from the previous work, %which mostly relies on the heuristic design of human-LLM interaction flow, 
in this paper, we explore 
how to utilize LLMs to analyze an AI model's decision recommendations and augment them, and 
how to build an algorithmic framework to dynamically decide what information to present to humans from the rich information generated by LLMs.
%, thereby yielding enhanced human-AI team performance in decision making.