\section{Applying Insights to Real-World Tasks}
In real-world scenarios, manually annotating long-context instruction data is both complex and labor-intensive, making the synthesis of context-aware instruction data a critical research challenge.
Based on insights from our pilot study, we propose a novel method called \textit{context synthesis} (\S\ref{sec:context}) and discuss the limitations of existing instruction synthesis approach (\S\ref{sec:instruction}).
Additionally, we propose an analytic tool for measuring the quality of synthesized data, particularly the coherence between contexts and instructions (\S\ref{sec:context-free-tuning}).

\subsection{Previous Approach: Instruction Synthesis}
\label{sec:instruction}
The existing approach to data synthesis, known as ``instruction synthesis'' (Figure~\ref{fig:illustration}), starts with long text passages and uses off-the-shelf LLMs to generate instruction-answer pairs based on the given text~\cite{bai2024longalign}.
This method focuses primarily on context length when constructing instruction data for long-context tasks, while overlooking other critical factors such as instruction quality. 
The automatically generated instructions often lack quality guarantees, and the off-the-shelf LLMs may not have sufficient capacity to effectively process long contexts, compromising the coherence between contexts and synthetic instructions.
Furthermore, the source passages may lack complex or contradictory information that could serve as distractors, limiting the model's robustness in handling noisy real-world scenarios.

\subsection{Proposed Approach: Context Synthesis}
\label{sec:context}
Unlike the previous approach, our method starts from existing instruction-answer pairs and synthesizes the corresponding context.
This approach makes the synthetic content merely part of the input to the model, 
thus prioritizing the quality of the instruction-answer pairs because they are naturally occurring. 
Additionally, this design enables control over the context: we can deliberately incorporate complex distractors while maintaining tight coupling between instructions and contexts.
Furthermore, by generating manageable moderate-length contexts, our synthesis process avoids the paradox of relying on a strong long-context LLM for instruction data synthesis.

\begin{figure}[htb]
  \centering\small
  \textbf{System prompt:}
  \vspace{1ex}
  \noindent\framebox{%
  \parbox{0.44\textwidth}{
  \texttt{Please infer the missing context. Always start with ``Context:'' and do not provide any explanation.}
  }%
  }
  \vspace{1ex}
  \textbf{User content:}
  \vspace{1ex}
  \noindent\framebox{%
  \parbox{0.44\textwidth}{
  \texttt{Context: [MISSING]\\Question: <instruction>\\Answer: <answer>\\
  \\
  The above is a question-answer pair based on a context which is missing. Write the missing context to provide relevant background information that leads to both the question and the answer, ensuring that any necessary numerical or factual details are included. The context also should include relevant details about the character, their environment, aspirations, challenges, and relationships. It should  be sufficiently detailed to reach approximately 2,000 words.}
  }
  }
\caption{Our prompt template for synthesizing context from instruction-answer pairs. The template takes an instruction-answer pair as input, where \texttt{<instruction>} and \texttt{<answer>} are replaced with the actual instruction and answer text. The system prompt ensures the output follows a consistent format, while the user content guides the LLM to generate context that supports the given instruction-answer pair.}
\label{fig:prompt-template-context-synthesis}
\end{figure}

\noindent\paragraph{Instruction Collection}
At first, we collect instruction-answer pairs for context synthesis.
In this paper, our collection considers two key requirements.
The instructions should require in-context knowledge to answer, preventing models from relying solely on their parametric knowledge\footnote{We initially experiment with instruction-answer pairs from Alpaca~\cite{wang2023instruct}, but find them ineffective as those instructions primarily test parametric knowledge.}.
Additionally, we aim to employ a setup that allows for controlled comparison between synthetic and human-annotated data.
To meet these requirements, we source our instruction-answer pairs from human-annotated context-aware datasets while synthesizing new contexts rather than using the original paired ones.

\noindent\paragraph{Synthesizing Evidence Context}
Starting with a collection of instruction-answer pairs, we prompt off-the-shelf LLMs to synthesize background context for them.
The prompt template we designed is shown in Figure~\ref{fig:prompt-template-context-synthesis}.
Our prompt guides the LLM engine to generate context that supports the instruction and ensures the answer can be derived from the context.
From our observations\footnote{We present some example cases in Appendix \ref{sec:example-synthesized-context}.}, the synthesized context maintains a strong and coherent relationship with the given instruction while naturally including detailed and distracting information.

\noindent\paragraph{Extending Synthesized Context}
While training on shorter-context data generalize to longer ones, our pilot study still indicates that training on longer contexts yields better performance.
To extend context length, we investigate two approaches, depending on whether the extended portion remains coherent with the evidence context.
One approach is increasing the word count requirements in the prompt.
We set the target context length to 2,000 words, as recent studies have shown that current LLMs struggle to generate content beyond this length~\cite{bai2024longwriter,pham2024suri,quan2024language}.

The second approach is incorporating incoherent text into the context, similar to the method described in ~\citet{dubey2024llama}.
Specifically, we take contexts synthesized for other instruction-answer pairs and integrate them into the current one.
Our experiments demonstrate that both approaches are effective, with their combination yielding the best results.

\subsection{Quality Measurement for Synthetic Data}
\label{sec:context-free-tuning}
Beyond proposing a framework for data synthesis, we also introduce an analytical tool to verify the quality of synthesized data, especially the coherence between instruction and context.
For ideal context-aware instruction data, there should be strong interdependence between the context and instruction.
Based on this principle, we propose using the performance gap between context-free and context-included tuning as a quality indicator.
If context-free tuning yields results similar to context-included tuning, it indicates potential quality issues in the synthesized data.
We apply this analytical tool to reveal limitations in existing instruction synthesis approaches in our experiments (Section~\ref{sec:analysis}).