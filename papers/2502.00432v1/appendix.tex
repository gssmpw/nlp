This appendix provides more background information, as well as more results.

%%%%%%%%%%%
%%% METRICS
%%%%%%%%%%%

\section{Metrics}

\subsection{Sørensen-Dice Coefficient}
\label{app:dcs}

The Sørensen-Dice coefficient \cite{metrics:Dice} is a statistical measure designed to assess the similarity of two sets. It was introduced in the field of botany and is designed to be applied to discrete data. Given two sets $X,Y$, it is computed as:
\begin{equation}
    \operatorname{DSC}(X, Y) = \dfrac{2 | X \cap Y |}{|X| + |Y|},
\end{equation}
i.e., it equals twice the number of elements shared by both sets divided by the sum of the number of elements in each set. When there are no common elements between $X,Y$ (no similarity), the Sørensen-Dice coefficient equals $0$. If $X,Y$ are identical (high similarity), meaning they contain exactly the same elements, the index is 1.

In the context of this work, the discrete sets under consideration are the communities detected by the algorithm $\f$, which are represented as groups of nodes.
We use this coefficient to compute the similarity between the original community $C_i$ of the target node $u$, as detected by $\f$, and the new community $C'_i$ to which it belongs within the counterfactual graph $\graph'$. Therefore, if the condition
$DSC(C_i - \{u\}, C'_i - \{u\}) \leq \tau$ is satisfied, we consider the community membership hiding task successfully accomplished.

\subsection{Normalized Mutual Information}
\label{app:nmi}
The Normalized Mutual Information (NMI) score is a metric used to assess the similarity between two clusterings or partitions of a dataset. It builds on Mutual Information (MI), which quantifies how much knowing one set of labels reduces uncertainty about the other, and normalizes this value to ensure it falls between 0 (no mutual information) and 1 (perfect correlation).
Based on the formulation by \citet{nmi_3}, it can be expressed as follows:
\begin{equation}
\label{eq:NMI}
    %d_{\text{NMI}} ( \mathcal{C}, \mathcal{C}_t ) = \frac{I(\mathcal{C},\mathcal{C}_t)}{\sqrt{H(\mathcal{C})H(\mathcal{C}_t)}} 
    %The normalized mutual information Inorm(X : Y ) [38] is defined as
    \text{NMI} ( \mathcal{K}, \mathcal{K}' ) = \frac{H(X) + H(Y) - H(X, Y)}{(H(X) + H(Y)) / 2},
\end{equation}
where $H(X)$ and $H(Y)$ denote the entropy of the random variables $X,Y$ associated with partitions $\mathcal{K},\mathcal{K}'$, respectively, while $H(X, Y)$ denotes the joint entropy. 

Within the framework of this study, the partition refers to the community structure of $\graph$ detected by the algorithm $\f$. To assess the impact of our counterfactual modification on the original community structure $f(\graph)$, we compute the NMI score between $f(\graph)$ and the newly obtained community structure $f(\graph')$ on $\graph'$. 

\subsection{Betwenness Centrality}
\label{app:cent}
In the field of graph theory, the betweenness centrality of a node $u$, denoted as $b(u)$, is a measure of centrality based on shortest paths within a graph. It is computed as 
\begin{equation}
    b(u) = \sum_{s\neq u \neq t}\frac{\sigma_{s,t}(u)}{\sigma_{s,t}},
\end{equation} 
where $\sigma_{s,t}$ is the total number of shortest paths from node $s$ to node 
$t$ and $\sigma_{s,t}(u)$ is the number of those paths that pass through 
$u$ (where $u$ is \textit{not} an end point).

%%%%%%%%%%%%%%%%%%%
%%% HYPERPARAMETERS
%%%%%%%%%%%%%%%%%%%

\section{Hyperparameters}
\label{app:hyp}

This section provides an overview of the hyperparameters used in our experiments.
In detail, the hyperparameters of our method are
the learning rate $\alpha$, the regularization constant $\lambda$,
the maximum number of iterations $T$, and the promising actions' coefficients $ c = \{c_{\mathcal{f}_i}\}_{i=1\cdots K}$.
In our experiments, we define $\mathcal{f}_1$ as betwenness centrality, $\mathcal{f}_2$ as degree, $\mathcal{f}_3$ as intra-community degree, and $\mathcal{f}_4$ as inter-community degree, which represents the degree of the nodes excluding the target community. In the following Table \ref{tab:hyperparams}, we present the hyperparameters obtained through a Bayesian hyperparameter search, aimed at maximizing the F1 score (the harmonic mean of SR and NMI), while varying the budget and datasets.

\begin{table}[htpb]
    \centering
    \caption{Hyperparameters of our method across all datasets and budget values with $\tau=0.5$ ($\mathcal{f}_1$ : centrality; $\mathcal{f}_2$ : degree; $\mathcal{f}_3$ : intra-community degree; $\mathcal{f}_4$ : inter-community degree).}
    \label{tab:hyperparams}
    \begin{tabular}{cccccccccc}
        \toprule
        \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{$\beta$}} & \multicolumn{7}{c}{\textbf{Loss Function Hyperparameters}} \\
        \cmidrule(lr){3-9}
        & & $\alpha$ & $\lambda$ & $T$ & $c_{\mathcal{f}_1}$ & $c_{\mathcal{f}_2}$ & $c_{\mathcal{f}_3}$ & $c_{\mathcal{f}_4}$ \\
        \midrule
        \multirow{3}{*}{\texttt{kar}} 
        & $\frac{1}{2}\mu$ & $0.098$ & $0.798$ & $60$ & \multirow{3}{*}{$0.713$} & \multirow{3}{*}{$0.134$} & \multirow{3}{*}{$0.102$} & \multirow{3}{*}{$0.049$}  \\
        & $1\mu$ & $0.22$ & $1.73$ & $100$ & & & & \\
        & $2\mu$ & $0.237$ & $3.43$ & $100$ & & & & \\
        \midrule
        \multirow{3}{*}{\texttt{words}} 
        & $\frac{1}{2}\mu$ & $0.055$ & $0.543$ & $60$ & \multirow{3}{*}{$0.0004$} & \multirow{3}{*}{$0.054$} & \multirow{3}{*}{$0.082$} & \multirow{3}{*}{$0.863$} \\
        & $1\mu$ & $0.012$ & $0.827$ & $90$ & & & & \\
        & $2\mu$ & $0.01$ & $1.225$ & $60$ & & & & \\
        \midrule
        \multirow{3}{*}{\texttt{vote}} 
        & $\frac{1}{2}\mu$ & $0.037$ & $15.32$ & $100$ & \multirow{3}{*}{$0.018$} & \multirow{3}{*}{$0.062$} & \multirow{3}{*}{$0.0003$} & \multirow{3}{*}{$0.92$}\\
        & $1\mu$ & $0.131$ & $8.158$ & $90$ & & & & \\
        & $2\mu$ & $0.0424$ & $15.4$ & $60$ & & & & \\
        \midrule
        \multirow{3}{*}{\texttt{pow}} 
        & $\frac{1}{2}\mu$ & $0.01$ & $0.452$ & $70$ &  \multirow{3}{*}{$0.894$} & \multirow{3}{*}{$0.104$} & \multirow{3}{*}{$0.0003$} & \multirow{3}{*}{$0.0001$} \\
        & $1\mu$ & $0.006$ & $24.84$ & $100$ & & & & \\
        & $2\mu$ & $0.002$ & $20.19$ & $100$ & & & & \\
        \midrule
        \multirow{3}{*}{\texttt{fb-75}} 
        & $\frac{1}{2}\mu$ & $0.005$ & $19.768$ & $100$ & \multirow{3}{*}{$0.333$} & \multirow{3}{*}{$0.333$} & \multirow{3}{*}{$0.166$} & \multirow{3}{*}{$0.166$}\\
        & $1\mu$ & $0.002$ & $5.388$ & $150$ & & & & \\
        & $2\mu$ & $0.004$ & $1.59$ & $130$ & & & & \\
        \bottomrule
    \end{tabular}
\end{table}





%%%%%%%%%%%%%%%%%%%%%%
%%% ADDITIONAL RESULTS
%%%%%%%%%%%%%%%%%%%%%%
\section{Additional Results}

\subsection{Hiding Assessment}
\label{app:hiding}
In this section, we report the full results on the effectiveness of \method{} in finding counterfactuals. Figure \ref{fig:f1-comparison} illustrates the F1 score achieved by our method against all the existing baselines on all considered datasets. These results are consistent with the ones in Figure \ref{fig:f1-symmetric-greedy}, with the only exception for \texttt{pow} where Greedy, Degree, and Betweenness overcome \method{} in Figure \ref{fig:f1_louvain_tau05_beta2}.

Table \ref{tab:used_budget} shows that our method can find counterfactuals without using the whole budget, especially in large networks. These results demonstrate that \method{} strikes the optimal balance between resource utilisation and performance.

%%%F1 SCORE
\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_greedy_tau05_beta05_grouped.png}
        \caption{$\beta = \frac{1}{2}\mu$}
        \label{fig:f1_greedy_tau05_beta05}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_greedy_tau05_beta2_grouped.png} 
        \caption{$\beta=2\mu$}
        \label{fig:f1_greedy_tau05_beta2}
    \end{subfigure}
    \caption{F1 score of SR and NMI in symmetric setting (\,$\f$: \textit{greedy}; $\tau=0.5$) for different budget values.}
    \label{fig:f1-comparison}
\end{figure}

%%% BUDGET USAGE
\begin{table}[htpb]
    \centering
    \caption{Mean budget use of \method{} in effective evasions for the symmetric setting (\,$\f$: \textit{greedy}; $\tau=0.5$) across budgets.}
    \label{tab:used_budget}
    \begin{subtable}[b]{0.33\linewidth}
        \centering
        \caption{$\beta=\frac{1}{2}\mu$}
        \label{tab:used_budget_beta05}
        \begin{tabular}{ l c c }
            \toprule
            {\textbf{Dataset}} &  
            {$\beta$} & {Consumed Budget}  \\
            \midrule
            \rowcolor[gray]{0.95} \texttt{kar} & $1$ & $1.0 \ \ (100.0\%)$ \\
            \texttt{words} & $1$ & $1.0 \ \ (100.0\%)$ \\
            \rowcolor[gray]{0.95} \texttt{vote} & $1$ & $1.0 \ \ (100.0\%)$ \\
            \texttt{pow} & $1$ & $1.0 \ \ (100.0\%)$ \\
            \rowcolor[gray]{0.95}\texttt{fb-75} & $17$ & $9.9 \ \ (58.4\%)$ \\
            %\texttt{arxiv} &0 & 0 \\
            \bottomrule
        \end{tabular}
    \end{subtable}
    \hfill
    \begin{subtable}[b]{0.33\linewidth}
    \centering
    \caption{$\beta=1\mu$}
    \label{tab:used_budget_beta1}
    \begin{tabular}{ l c c }
        \toprule
        {\textbf{Dataset}} &  
        {$\beta$} & {Consumed Budget}  \\
        \midrule
        \rowcolor[gray]{0.95} \texttt{kar} &$3$ & $2.5 \ \ (82.8\%)$ \\
        \texttt{words} &$3$ & $2.2 \ \ (71.8\%)$ \\
        \rowcolor[gray]{0.95} \texttt{vote} &$3$ & $2.1 \ \ (69.3\%)$ \\
        \texttt{pow} &$2$ & $1.4 \ \ (68.1\%)$ \\
        \rowcolor[gray]{0.95}\texttt{fb-75} &$34$ & $17.4 \ \ (51.0\%)$ \\
        %\texttt{arxiv} &0 & 0 \\
        \bottomrule
    \end{tabular}
    \end{subtable}
    \hfill
    \begin{subtable}[b]{0.33\linewidth}
        \centering
        \caption{$\beta=2\mu$}
        \label{tab:used_budget_beta2}
        \begin{tabular}{ l c c }
            \toprule
            {\textbf{Dataset}} &  
            {$\beta$} & {Consumed Budget}  \\
            \midrule
            \rowcolor[gray]{0.95} \texttt{kar} & $6$ & $3.5 \ \ (58.9\%)$ \\
            \texttt{words} & $7$ & $2.7 \ \ (39.0\%)$ \\
            \rowcolor[gray]{0.95} \texttt{vote} & $6$ & $3.6 \ \ (60.6\%)$ \\
            \texttt{pow} & $4$ & $2.9 \ \ (72.2\%)$ \\
            \rowcolor[gray]{0.95}\texttt{fb-75} & $68$ & $25.5 \ \ (37.5\%)$ \\
            %\texttt{arxiv} &0 & 0 \\
            \bottomrule
        \end{tabular}
    \end{subtable}
\end{table}


\subsection{Transferability}
\label{app:transferability}
We evaluate the capabilities of \method{} in generalising its counterfactuals when $\f$ and $\g$ use two different community detection algorithms; we call this setting \emph{asymmetric}. Specifically, we let $\f$ to use \textit{greedy} and $\g$ to employ \textit{louvain} and \textit{walktrap}. Metaphorically, this can happen when a user of a generic social media platform, denoted as the target node $u$, individually performs the hiding without knowing what kind of community detection algorithm the platform employs. Notice that this analysis is highly dependent on the choice of the algorithm used for $\f$.

As already shown in the main body of our work in Figure \ref{fig:f1-asymmetric}, our method does not particularly shine in the asymmetric setting, placing itself below the other baselines on larger networks. This is evident in both Figure \ref{fig:f1_louvain_tau05_beta05} and Figure \ref{fig:f1_walktrap_tau05_beta05}. We suppose that this behaviour is tightly connected with not utilising the entire budget, stopping the optimization process early enough to find the minimal counterfactual for \textit{greedy}, while all the other baselines use the whole budget, making more actions than our method.

%%% TRANSFERABILITY -- LOUVAIN
\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_louvain_tau05_beta05_grouped.png}
        \caption{$\beta = \frac{1}{2}\mu$}
        \label{fig:f1_louvain_tau05_beta05}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_louvain_tau05_beta2_grouped.png} 
        \caption{$\beta=2\mu$}
        \label{fig:f1_louvain_tau05_beta2}
    \end{subfigure}
    \caption{F1 score of SR and NMI in asymmetric setting ($\,\f$: \textit{greedy}; $g(\cdot)$: \textit{louvain}; $\tau=0.5$) for different budget values.}
    \label{fig:comparison3}
\end{figure}

%%% TRANSFERABILITY -- WALKTRAP
\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_walktrap_tau05_beta05_grouped.png}
        \caption{$\beta = \frac{1}{2}\mu$}
        \label{fig:f1_walktrap_tau05_beta05}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/f1_walktrap_tau05_beta2_grouped.png} 
        \caption{$\beta=2\mu$}
        \label{fig:f1_walktrap_tau05_beta2}
    \end{subfigure}
    \caption{F1 score of SR and NMI in asymmetric setting ($\,\f$: \textit{greedy}; $g(\cdot)$: \textit{walktrap}; $\tau=0.5$) for different budget values.}
    \label{fig:comparison4}
\end{figure}


\subsection{Computational Efficiency}
\label{app:comp-eff}
We further expand on the computational efficiency analysis when employing different values for the budget. In Figure \ref{fig:time_greedy_tau05_beta05} we interestingly observe that the evasion time is comparable to the DRL-Agent when the networks are small. We argue that this phenomenon is attributable to the low absolute value of the budget ($\beta = 1$) for all datasets but \texttt{fb-75}, making it harder to find a counterfactual and forcing \method{} to restart the optimization up to $T$ times. This does not happen in \texttt{fb-75} and in all datasets when the budget is larger, as shown in Figure \ref{fig:time} in the main body of our work and Figure \ref{fig:time_greedy_tau05_beta2}. Table \ref{tab:speedups2} shows the absolute values of the corresponding figures.

%%% TIME COMPARISONS
\begin{figure}[htpb]
    \centering
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/time_greedy_tau05_beta05_grouped.png}
        \caption{$\beta = \frac{1}{2}\mu$}
        \label{fig:time_greedy_tau05_beta05}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\linewidth}
        \includegraphics[width=\linewidth]{sections/images/time_greedy_tau05_beta2_grouped.png} 
        \caption{$\beta=2\mu$}
        \label{fig:time_greedy_tau05_beta2}
    \end{subfigure}
    \caption{Average evasion time (secs.) in symmetric setting ($\tau=0.5$) for different budgets of \method{} and DRL-Agent.}
    \label{fig:time2}
\end{figure}

%%% TIME SPEEDUPS
\begin{table}[htpb!]
    \centering
    \caption{Speed-up (secs.) of \method{} compared to DRL-Agent in evading $\f$ when varying $\beta$.}
    \label{tab:speedups2}
    \begin{subtable}[b]{0.49\linewidth}
        \centering
        \caption{$\beta=\frac{1}{2}\mu$}
        \label{tab:used_budget_1}
        \begin{tabular}{ l c c c c c }
        \toprule
        \multirow{2}{*} {\textbf{Dataset}} &  \multicolumn{2}{c}{\textbf{ Algorithms}} & \multirow{2}{*} {\textbf{Speed-up}} \\
        \cmidrule(lr){2-3}
        & \textit{\method{} (ours)} & \textit{DRL-Agent} \\
        \midrule
        \rowcolor[gray]{0.95} \texttt{kar} & $0.024$ & $0.015$ & $\times 0.650 \ \blacktriangledown$ \\
        \texttt{words} & $0.022$ & $0.026$ & $\times 1.162 \ \blacktriangle$ \\
        \rowcolor[gray]{0.95} \texttt{vote} & $0.150$ & $0.116$ & $\times 0.774 \ \blacktriangledown$ \\
        \texttt{pow} & $0.240$ & $0.311$ & $\times 1.296 \ \blacktriangle$ \\
        \rowcolor[gray]{0.95}\texttt{fb-75} & $17.743$ & $63.458$ & $\times 3.577 \ \blacktriangle$ \\
        %\texttt{arxiv} & 0 & 0 & 0 \\
        \bottomrule
    \end{tabular}
    \end{subtable}
    \hfill
    \begin{subtable}[b]{0.49\linewidth}
        \centering
        \caption{$\beta=2\mu$}
        \label{tab:used_budget_2}
        \begin{tabular}{ l c c c c c }
        \toprule
        \multirow{2}{*} {\textbf{Dataset}} &  \multicolumn{2}{c}{\textbf{ Algorithms}} & \multirow{2}{*} {\textbf{Speed-up}} \\
        \cmidrule(lr){2-3}
        & \textit{\method{} (ours)} & \textit{DRL-Agent} \\
        \midrule
        \rowcolor[gray]{0.95} \texttt{kar} & $0.012$ & $0.039$ & $\times 3.277 \ \blacktriangle$ \\
        \texttt{words} & $0.010$ & $0.101$ & $\times 10.226\  \blacktriangle$ \\
        \rowcolor[gray]{0.95} \texttt{vote} & $0.070$ & $0.496$ & $\times 7.049 \ \blacktriangle$ \\
        \texttt{pow} & $0.149$ & $1.022$ & $\times 6.839 \ \blacktriangle$ \\
        \rowcolor[gray]{0.95}\texttt{fb-75} & $32.276$ & $262.272$ & $\times 8.126 \ \blacktriangle$ \\
        %\texttt{arxiv} & 0 & 0 & 0 \\
        \bottomrule
    \end{tabular}
    \end{subtable}
\end{table}


\subsection{Parameter Sensitivity Analysis}
\label{app:param-sens}
The results in Table \ref{tab:param-sens-app} are coherent with what we show in Section \ref{subsec:param-sens} of the main body of our work. In Table \ref{tab:param-sens-louvain} and Table \ref{tab:param-sens-walktrap} we further explore the asymmetric setting, confirming that even in this setting raising the budget allows for a higher success rate, even though other baselines achieve better results as already noted in Appendix \ref{app:transferability}.

%%% SUCCESS RATES
\begin{table}[htpb]
    \centering
    \caption{Impact of budget $\beta$ on Success Rate (SR) in the symmetric setting ($\tau=0.5$) across all datasets.}
    \label{tab:param-sens-app}
    \scalebox{0.75}{
    \begin{tabular}{cccccccccc}
        \toprule
        \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{$\beta$}} & \multicolumn{7}{c}{\textbf{Community Membership Hiding Algorithm}} \\
        \cmidrule(lr){3-9}
        & & \textit{\method{}\,(Ours)} & \textit{DRL-Agent} & \textit{Random} & \textit{Greedy} & \textit{Degree} & \textit{Roam} & \textit{Betweenness} \\
        \midrule
        \multirow{3}{*}{\texttt{kar}} 
        & $\frac{1}{2}\mu$ & $\mathbf{61.8\% \pm 16.3\%}$ & $26.5\% \pm 14.8\%$ & $23.5\% \pm 14.3\%$ & $0.0\% \pm 0.0\%$ & $17.6\% \pm 12.8\%$ & $14.7\% \pm 11.9\%$ & $8.8\% \pm 9.5\%$ \\
        & $1\mu$ & $\mathbf{91.2\% \pm 9.5\%}$ & $61.8\% \pm 16.3\%$ & $44.1\% \pm 16.7\%$ & $35.3\% \pm 16.1\%$ & $47.1\% \pm 16.8\%$ & $11.8\% \pm 10.8\%$ & $47.1\% \pm 16.8\%$ \\
         & $2\mu$ & $\mathbf{94.1\% \pm 7.9\%}$ & $76.5\% \pm 14.3\%$ & $55.9\% \pm 16.7\%$ & $44.1\% \pm 16.7\%$ & $55.9\% \pm 16.7\%$ & $14.7\% \pm 11.9\%$ & $64.7\% \pm 16.1\%$ \\
        \midrule
        \multirow{3}{*}{\texttt{words}} 
        & $\frac{1}{2}\mu$ & $\mathbf{85.4\% \pm 10.8\%}$ & $43.9\% \pm 15.2\%$ & $24.4\% \pm 13.1\%$ & $0.0\% \pm 0.0\%$ & $26.8\% \pm 13.6\%$ & $41.5\% \pm 15.1\%$ & $26.8\% \pm 13.6\%$ \\
         & $1\mu$ & $\mathbf{95.1\% \pm 6.6\%}$ & $61.0\% \pm 14.9\%$ & $56.1\% \pm 15.2\%$ & $63.4\% \pm 14.7\%$ & $58.5\% \pm 15.1\%$ & $43.9\% \pm 15.2\%$ & $58.5\% \pm 15.1\%$ \\
        & $2\mu$ & $\mathbf{100.0\% \pm 0.0\%}$ & $80.5\% \pm 12.1\%$ & $58.5\% \pm 15.1\%$ & $68.3\% \pm 14.2\%$ & $70.7\% \pm 13.9\%$ & $43.9\% \pm 15.2\%$ & $65.9\% \pm 14.5\%$ \\
        \midrule
        \multirow{3}{*}{\texttt{vote}} 
        & $\frac{1}{2}\mu$ & $\mathbf{65.9\% \pm 6.2\%}$ & $48.4\% \pm 6.6\%$ & $43.5\% \pm 6.5\%$ & $0.0\% \pm 0.0\%$ & $41.7\% \pm 6.5\%$ & $38.1\% \pm 6.4\%$ & $25.1\% \pm 5.7\%$ \\
        & $1\mu$ & $\mathbf{79.8\% \pm 5.3\%}$ & $58.7\% \pm 6.5\%$ & $54.3\% \pm 6.5\%$ & $48.9\% \pm 6.6\%$ & $32.3\% \pm 6.1\%$ & $24.2\% \pm 5.6\%$ & $32.3\% \pm 6.1\%$ \\
        & $2\mu$ & $\mathbf{85.7\% \pm 4.6\%}$ & $74.9\% \pm 5.7\%$ & $51.6\% \pm 6.6\%$ & $49.3\% \pm 6.6\%$ & $46.6\% \pm 6.5\%$ & $43.9\% \pm 6.5\%$ & $47.1\% \pm 6.6\%$ \\
        \midrule
        \multirow{3}{*}{\texttt{pow}} 
        & $\frac{1}{2}\mu$ & $\mathbf{69.4\% \pm 5.5\%}$ & $29.9\% \pm 5.5\%$ & $47.0\% \pm 6.0\%$ & $0.0\% \pm 0.0\%$ & $20.1\% \pm 4.8\%$ & $39.2\% \pm 5.8\%$ & $23.9\% \pm 5.1\%$ \\
        & $1\mu$ & $\mathbf{85.4\% \pm 4.2\%}$ & $47.0\% \pm 6.0\%$ & $66.0\% \pm 5.7\%$ & $20.1\% \pm 4.8\%$ & $17.5\% \pm 4.6\%$ & $39.2\% \pm 5.8\%$ & $22.0\% \pm 5.0\%$ \\
        & $2\mu$ & $86.2\% \pm 4.1\%$ & $53.0\% \pm 6.0\%$ & $67.5\% \pm 5.6\%$ & $97.8\% \pm 1.8\%$ & $\mathbf{98.1\% \pm 1.6\%}$ & $30.2\% \pm 5.5\%$ & $88.8\% \pm 3.8\%$ \\
        \midrule
        \multirow{3}{*}{\texttt{fb-75}} 
        & $\frac{1}{2}\mu$ & $\mathbf{47.0\% \pm 5.8\%}$ & $23.5\% \pm 5.0\%$ & $5.7\% \pm 2.7\%$ & $30.2\% \pm 5.4\%$ & $40.6\% \pm 5.7\%$ & $3.9\% \pm 2.3\%$ & $44.1\% \pm 5.8\%$ \\
        & $1\mu$ & $\mathbf{68.3\% \pm 5.4\%}$ & $34.2\% \pm 5.5\%$ & $9.6\% \pm 3.4\%$ & $32.0\% \pm 5.5\%$ & $44.8\% \pm 5.8\%$ & $4.3\% \pm 2.4\%$ & $54.1\% \pm 5.8\%$ \\
        & $2\mu$ & $\mathbf{75.8\% \pm 5.0\%}$ & $52.7\% \pm 5.8\%$ & $29.5\% \pm 5.3\%$ & $45.9\% \pm 5.8\%$ & $40.6\% \pm 5.7\%$ & $4.6\% \pm 2.5\%$ & $60.1\% \pm 5.7\%$ \\
        \bottomrule
    \end{tabular}
    }
\end{table}

%%% LOUVAIN
\begin{table}[htpb] 
\caption{Impact of budget $\beta$ on Success Rate (SR) in the asymmetric setting (\,$\f$: \textit{greedy}; $\g$: \textit{louvain}; $\tau=0.5$) across all datasets.} 
\label{tab:param-sens-louvain}
    \centering 
    \scalebox{0.7}{ 
    \begin{tabular}{cccccccccc} 
    \toprule 
    \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{$\beta$}} & \multicolumn{7}{c}{\textbf{Community Membership Hiding Algorithm}} \\ 
    \cmidrule(lr){3-9} 
    & & \textit{\method{}\,(Ours)} & \textit{DRL-Agent} & \textit{Random} & \textit{Greedy} & \textit{Degree} & \textit{Roam} & \textit{Betweenness} \\ 
    \midrule 
    
    \multirow{3}{*}{\texttt{kar}} 
    & $\frac{1}{2}\mu$ & $\mathbf{38.1\% \pm 20.8\%}$ & $14.3\% \pm 15.0\%$ & $23.8\% \pm 18.2\%$ & $4.8\% \pm 9.1\%$ & $4.8\% \pm 9.1\%$ & $9.5\% \pm 12.6\%$ & $9.5\% \pm 12.6\%$ \\ 
    & $1\mu$ & $\mathbf{47.6\% \pm 21.4\%}$ & $42.9\% \pm 21.2\%$ & $14.3\% \pm 15.0\%$ & $33.3\% \pm 20.2\%$ & $23.8\% \pm 18.2\%$ & $9.5\% \pm 12.6\%$ & $23.8\% \pm 18.2\%$ \\ 
    & $2\mu$ & $\mathbf{76.2\% \pm 18.2\%}$ & $71.4\% \pm 19.3\%$ & $33.3\% \pm 20.2\%$ & $14.3\% \pm 15.0\%$ & $19.0\% \pm 16.8\%$ & $9.5\% \pm 12.6\%$ & $42.9\% \pm 21.2\%$ \\ 
    
    \midrule 
    
    \multirow{3}{*}{\texttt{words}} 
    & $\frac{1}{2}\mu$ & $\mathbf{48.6\% \pm 16.6\%}$ & $42.9\% \pm 16.4\%$ & $31.4\% \pm 15.4\%$ & $0.0\% \pm 0.0\%$ & $8.6\% \pm 9.3\%$ & $40.0\% \pm 16.2\%$ & $8.6\% \pm 9.3\%$ \\ 
    & $1\mu$ & $\mathbf{65.7\% \pm 15.7\%}$ & $57.1\% \pm 16.4\%$ & $62.9\% \pm 16.0\%$ & $25.7\% \pm 14.5\%$ & $48.6\% \pm 16.6\%$ & $28.6\% \pm 15.0\%$ & $45.7\% \pm 16.5\%$ \\ 
    & $2\mu$ & $\mathbf{82.9\% \pm 12.5\%}$ & $74.3\% \pm 14.5\%$ & $77.1\% \pm 13.9\%$ & $60.0\% \pm 16.2\%$ & $54.3\% \pm 16.5\%$ & $40.0\% \pm 16.2\%$ & $74.3\% \pm 14.5\%$ \\ 
    
    \midrule 
    
    \multirow{3}{*}{\texttt{vote}} 
    & $\frac{1}{2}\mu$ & $25.0\% \pm 5.3\%$ & $17.1\% \pm 4.6\%$ & $6.7\% \pm 3.1\%$ & $0.0\% \pm 0.0\%$ & $14.7\% \pm 4.4\%$ & $\mathbf{29.4\% \pm 5.6\%}$ & $5.2\% \pm 2.7\%$ \\ 
    & $1\mu$ & $\mathbf{36.5\% \pm 5.9\%}$ & $33.3\% \pm 5.8\%$ & $18.3\% \pm 4.8\%$ & $15.5\% \pm 4.5\%$ & $15.1\% \pm 4.4\%$ & $25.4\% \pm 5.4\%$ & $15.1\% \pm 4.4\%$ \\ 
    & $2\mu$ & $50.8\% \pm 6.2\%$ & $50.4\% \pm 6.2\%$ & $21.0\% \pm 5.0\%$ & $50.0\% \pm 6.2\%$ & $\mathbf{54.8\% \pm 6.1\%}$ & $26.2\% \pm 5.4\%$ & $17.5\% \pm 4.7\%$ \\ 
    
    \midrule 
    
    \multirow{3}{*}{\texttt{pow}} 
    & $\frac{1}{2}\mu$ & $43.9\% \pm 6.1\%$ & $46.7\% \pm 6.1\%$ & $\mathbf{56.5\% \pm 6.1\%}$ & $0.0\% \pm 0.0\%$ & $15.7\% \pm 4.5\%$ & $52.2\% \pm 6.1\%$ & $46.7\% \pm 6.1\%$ \\ 
    & $1\mu$ & $45.5\% \pm 6.1\%$ & $56.9\% \pm 6.1\%$ & $\mathbf{65.1\% \pm 5.9\%}$ & $15.7\% \pm 4.5\%$ & $27.8\% \pm 5.5\%$ & $52.2\% \pm 6.1\%$ & $45.9\% \pm 6.1\%$ \\ 
    & $2\mu$ & $52.9\% \pm 6.1\%$ & $62.4\% \pm 5.9\%$ & $61.6\% \pm 6.0\%$ & $32.5\% \pm 5.8\%$ & $32.9\% \pm 5.8\%$ & $36.5\% \pm 5.9\%$ & $\mathbf{83.9\% \pm 4.5\%}$ \\ 
    
    \midrule 
    
    \multirow{3}{*}{\texttt{fb-75}} 
    & $\frac{1}{2}\mu$ & $24.7\% \pm 4.9\%$ & $26.3\% \pm 5.0\%$ & $14.7\% \pm 4.0\%$ & $23.0\% \pm 4.8\%$ & $22.7\% \pm 4.7\%$ & $12.3\% \pm 3.7\%$ & $\mathbf{26.7\% \pm 5.0\%}$ \\ 
    & $1\mu$ & $25.3\% \pm 4.9\%$ & $\mathbf{36.3\% \pm 5.4\%}$ & $21.3\% \pm 4.6\%$ & $27.0\% \pm 5.0\%$ & $26.3\% \pm 5.0\%$ & $11.7\% \pm 3.6\%$ & $27.0\% \pm 5.0\%$ \\ 
    & $2\mu$ & $41.0\% \pm 5.6\%$ & $\mathbf{46.3\% \pm 5.6\%}$ & $32.7\% \pm 5.3\%$ & $27.7\% \pm 5.1\%$ & $25.3\% \pm 4.9\%$ & $14.0\% \pm 3.9\%$ & $34.0\% \pm 5.4\%$ \\ 
    
    \bottomrule 
\end{tabular} 
} 
\end{table}

%%% WALKTRAP
\begin{table}[htpb]
    \caption{Impact of budget $\beta$ on Success Rate (SR) in the asymmetric setting (\,$\f$: \textit{greedy}; $\g$: \textit{walktrap}; $\tau=0.5$) across all datasets.}
    \label{tab:param-sens-walktrap}
    \centering
    \scalebox{0.7}{
    \begin{tabular}{cccccccccc}
        \toprule
        \multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{$\beta$}} & \multicolumn{7}{c}{\textbf{Community Membership Hiding Algorithm}} \\
        \cmidrule(lr){3-9}
        & & \textit{\method{}\,(Ours)} & \textit{DRL-Agent} & \textit{Random} & \textit{Greedy} & \textit{Degree} & \textit{Roam} & \textit{Betweenness} \\
        \midrule

        \multirow{3}{*}{\texttt{kar}} 
        & $\frac{1}{2}\mu$ & $\mathbf{33.3\% \pm 20.2\%}$ & $14.3\% \pm 15.0\%$ & $9.5\% \pm 12.6\%$ & $14.3\% \pm 15.0\%$ & $14.3\% \pm 15.0\%$ & $9.5\% \pm 12.6\%$ & $14.3\% \pm 15.0\%$ \\ 
        & $1\mu$ & $52.4\% \pm 21.4\%$ & $\mathbf{57.1\% \pm 21.2\%}$ & $33.3\% \pm 20.2\%$ & $38.1\% \pm 20.8\%$ & $38.1\% \pm 20.8\%$ & $33.3\% \pm 20.2\%$ & $38.1\% \pm 20.8\%$ \\ 
        & $2\mu$ & $\mathbf{95.2\% \pm 9.1\%}$ & $81.0\% \pm 16.8\%$ & $47.6\% \pm 21.4\%$ & $76.2\% \pm 18.2\%$ & $76.2\% \pm 18.2\%$ & $23.8\% \pm 18.2\%$ & $81.0\% \pm 16.8\%$ \\ 
        
        \midrule
        
        \multirow{3}{*}{\texttt{words}} 
        & $\frac{1}{2}\mu$ & $\mathbf{41.8\% \pm 11.8\%}$ & $31.3\% \pm 11.1\%$ & $31.3\% \pm 11.1\%$ & $0.0\% \pm 0.0\%$ & $23.9\% \pm 10.2\%$ & $35.8\% \pm 11.5\%$ & $23.9\% \pm 10.2\%$ \\ 
        & $1\mu$ & $\mathbf{62.7\% \pm 11.6\%}$ & $55.2\% \pm 11.9\%$ & $31.3\% \pm 11.1\%$ & $34.3\% \pm 11.4\%$ & $23.9\% \pm 10.2\%$ & $32.8\% \pm 11.2\%$ & $20.9\% \pm 9.7\%$ \\ 
        & $2\mu$ & $\mathbf{82.1\% \pm 9.2\%}$ & $77.6\% \pm 10.0\%$ & $43.3\% \pm 11.9\%$ & $49.3\% \pm 12.0\%$ & $29.9\% \pm 11.0\%$ & $31.3\% \pm 11.1\%$ & $46.3\% \pm 11.9\%$ \\ 
        
        \midrule
        
        \multirow{3}{*}{\texttt{vote}} 
        & $\frac{1}{2}\mu$ & $23.0\% \pm 5.5\%$ & $23.4\% \pm 5.6\%$ & $27.9\% \pm 5.9\%$ & $0.0\% \pm 0.0\%$ & $12.6\% \pm 4.4\%$ & $\mathbf{40.1\% \pm 6.4\%}$ & $14.9\% \pm 4.7\%$ \\ 
        & $1\mu$ & $36.5\% \pm 6.3\%$ & $\mathbf{50.0\% \pm 6.6\%}$ & $41.4\% \pm 6.5\%$ & $31.1\% \pm 6.1\%$ & $45.0\% \pm 6.5\%$ & $33.8\% \pm 6.2\%$ & $45.0\% \pm 6.5\%$ \\ 
        & $2\mu$ & $54.5\% \pm 6.6\%$ & $68.9\% \pm 6.1\%$ & $55.9\% \pm 6.5\%$ & $63.5\% \pm 6.3\%$ & $\mathbf{69.8\% \pm 6.0\%}$ & $34.7\% \pm 6.3\%$ & $64.0\% \pm 6.3\%$ \\ 
        
        \midrule
        
        \multirow{3}{*}{\texttt{pow}} 
        & $\frac{1}{2}\mu$ & $36.6\% \pm 5.5\%$ & $35.9\% \pm 5.5\%$ & $37.3\% \pm 5.5\%$ & $0.0\% \pm 0.0\%$ & $24.4\% \pm 4.9\%$ & $\mathbf{57.3\% \pm 5.6\%}$ & $35.3\% \pm 5.5\%$ \\ 
        & $1\mu$ & $46.4\% \pm 5.7\%$ & $40.0\% \pm 5.6\%$ & $46.4\% \pm 5.7\%$ & $24.4\% \pm 4.9\%$ & $34.9\% \pm 5.4\%$ & $\mathbf{57.3\% \pm 5.6\%}$ & $39.7\% \pm 5.6\%$ \\ 
        & $2\mu$ & $49.2\% \pm 5.7\%$ & $47.8\% \pm 5.7\%$ & $38.3\% \pm 5.5\%$ & $35.3\% \pm 5.5\%$ & $36.6\% \pm 5.5\%$ & $43.1\% \pm 5.7\%$ & $\mathbf{51.5\% \pm 5.7\%}$ \\ 
        
        \midrule
        
        \multirow{3}{*}{\texttt{fb-75}} 
        & $\frac{1}{2}\mu$ & $16.5\% \pm 4.6\%$ & $26.0\% \pm 5.4\%$ & $20.9\% \pm 5.0\%$ & $29.5\% \pm 5.6\%$ & $\mathbf{30.3\% \pm 5.7\%}$ & $6.7\% \pm 3.1\%$ & $22.8\% \pm 5.2\%$ \\ 
        & $1\mu$ & $35.4\% \pm 5.9\%$ & $38.2\% \pm 6.0\%$ & $33.5\% \pm 5.8\%$ & $\mathbf{44.9\% \pm 6.1\%}$ & $42.5\% \pm 6.1\%$ & $9.1\% \pm 3.5\%$ & $35.8\% \pm 5.9\%$ \\ 
        & $2\mu$ & $53.9\% \pm 6.1\%$ & $68.9\% \pm 5.7\%$ & $60.6\% \pm 6.0\%$ & $\mathbf{71.7\% \pm 5.5\%}$ & $67.7\% \pm 5.8\%$ & $9.8\% \pm 3.7\%$ & $62.6\% \pm 6.0\%$ \\ 

        \bottomrule
    \end{tabular}
    }
\end{table}


%\begin{table}[htpb]
%\centering
%\caption{Average budget consumption of \method{} across all datasets in successful node masking, relative to the available budget $\beta = 1\mu$ (all baselines use $100\%$ of the budget).}
%\label{tab:used_budget_beta1}
%\scalebox{0.9}{
%    \begin{tabular}{ l c c }
%        \toprule
%        {\textbf{Dataset}} &  
%        {$\beta$} & {Consumed Budget}  \\
%        \midrule
%        \rowcolor[gray]{0.95} \texttt{kar} &$3$ & $2.5 \ \ (82.8\%)$ \\
%        \texttt{words} &$3$ & $2.2 \ \ (71.8\%)$ \\
%        \rowcolor[gray]{0.95} \texttt{vote} &$3$ & $2.1 \ \ (69.3\%)$ \\
%        \texttt{pow} &$2$ & $1.4 \ \ (68.1\%)$ \\
%        \rowcolor[gray]{0.95}\texttt{fb-75} &$34$ & $17.4 \ \ (51.0\%)$ \\
%        %\texttt{arxiv} &0 & 0 \\
%        \bottomrule
%    \end{tabular}
%}
%\end{table}
