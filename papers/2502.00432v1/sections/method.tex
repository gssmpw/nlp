% TODO: Dire che non possiamo utilizzare il risultato di f(.) nella loss.
% siccome trattiamo f come una black box allora siamo in questo. ovviamente dal momento che abbiamo accesso ad f e il suo risultato è differenziabile, allora potremmo utilizzare f direttamente nella loss. TODO: scrivere assunzioni su f!!!

%\edo{Ho riscritto/aggiustato un po' di cose qui. Bisogna trovare una divisione in sottosezioni però.}

%The main obstacle of the Community Membership Hiding task is the non-differentiability of the loss function, so gradient-based methods are impossible to apply. Therefore, we propose a new differentiable loss function, which allows solving the community membership hiding problem through a pure optimization approach.

%To enable gradient-based optimization algorithms to work on graphs, we need to act on the adjacency matrix, but note that it is defined on binary values. The simplest method to smooth the values of $A$ is to relax them, i.e., by setting $A_{u,v} \in \mathbb{R}$ and thresholding each value after $t$ steps of the optimization. However, this method $\ldots$ (todo: explain why this does not work)

%%%%%%%%%%%%%%%%%
%%% PERTURBATION
%%%%%%%%%%%%%%%%
The community membership problem outlined in Section~\ref{sec:problem} is inherently discrete, rendering it unsuitable for direct optimization using gradient-based techniques.
To address this limitation, we adopt a strategy inspired by \citet{trappolini2023savage} by introducing a \textit{perturbation vector} $p$ that is applied to the adjacency vector $A_u$: 
%This modification effectively obscures $u$'s community membership as determined by the algorithm $f(\cdot)$.
% To address the problem outlined in Section \ref{sec:problem}, we propose a gradient-based approach that generates a perturbation vector $p$. When applied to the adjacency vector $A_u$, this perturbation changes the neighborhood of the target node $u$ and effectively obscures the community membership of $u$ as identified by the algorithm $f(\cdot)$.
% Similar to the work by \citet{trappolini2023savage}, 
%We define the perturbed adjacency vector as follows:
\begin{equation}
    A'_u = \operatorname{clamp}(A_u \oplus p),
\end{equation}
%\edo{Nota per il futuro: $p$ su grafi grandi diventa enorme, può aver senso ridurre la sua lunghezza.}
where $p \in \{-1,0,1\}^{|\mathcal{V}|}$. Intuitively, a value of $-1$ in $p$ corresponds to removing an existing edge or leaving a non-existent edge unaltered, $0$ preserves the edge as is, and $1$ either adds a new edge or retains an existing one. The function $\operatorname{clamp}(x) = \max (0, \min (x,1))$ ensures that the elements of $A'_u$ are contained to $\{0,1\}$, mapping the set $\{-2,-1,0,1,2\}$ to binary values.
%Roughly speaking, $-1$ corresponds to removing an edge or not adding a non-existent one, $0$ keeps the edge unaltered, and $1$ adds an edge, or keeps it. This reasoning is described by $\operatorname{clamp}(x) = \max (0, \min (x,1))$ that maps $\{-2,-1,0,1,2\}$ into $\{0,1\}$.

%However, the values in $p$ remain discrete. 
%To address this, we introduce an intermediate real-valued vector $\hat{p}$ with entries constrained in $ [-1,1]$ by applying a $\tanh$ transformation. Finally, we threshold the transformed entries to obtain the desired discrete perturbation vector $p$ as follows: 
However, the values in $p$ remain discrete, so we first introduce an intermediate real-valued vector $\hat{p}$, whose entries are constrained to the range $ [-1,1]$ using a $\tanh$ transformation. The entries of $\hat{p}$ are then thresholded to produce the discrete perturbation vector $p$, defined as:
%Finally, we threshold the transformed entries to obtain the desired discrete perturbation vector $p$ as follows:
%entries greater than or equal to $0.5$ become $1$, those less than or equal to $-0.5$ are set to $-1$, and entries between $-0.5$ and $0.5$ become $0$.
\begin{equation}
    p_{i} =
        \begin{cases} 
        +1 & \text{if } \hat{p}_{i} \geq t^+, \\
        -1 & \text{if } \hat{p}_{i} \leq t^-, \\
        0 & \text{otherwise.}
        \end{cases}
\end{equation}
A straightforward option for the thresholds is $t^+=0.5$ and $t^-=-0.5$.
As a result, $\hat{p}$ serves as the set of parameters to be optimized, which are subsequently discretized and added element-wise to the adjacency vector $A_u$.


%%%%%%%%%%%%%%%%%%%%%%%
%%% DIFFERENTIABLE LOSS
%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Designing a Differentiable Loss}
\label{subsec:loss}
The optimization operates on a 
%real-valued 
vector $\hat{p}$ initialized uniformly within $[-0.5, 0.5]^{|\mathcal{V}|}$, as this corresponds to start the process with a null perturbation. 
Since we assume no internal knowledge of $\f$, we cannot incorporate its results into the loss function to guide the optimization process. Consequently, we introduce a vector $\candlist{u}$, that represent what we call \emph{promising actions}, i.e., actions that $u$ should prioritize to escape the community. %Metaforically, $\candlist{u}$ is the ``true north" of the optimization process.
The simplest version of $\candlist{u}$ is $\lnot A_u$, but we discuss a more refined heuristic that takes into consideration the structural properties of the nodes within the network in Section \ref{subsec:candlist}.
%Then, we aim to guide the optimization toward a set of promising actions, captured by a vector denoted as $\candlist{u}$, which we describe later in Section \ref{subsec:candlist}.

Thus, we define the first term of the loss ($\ell_{\text{hide}}$) as:
\begin{equation}
    \small
    \ell_{\text{hide}}(\hat{p}; A_u, \candlist{u}, q, m) = || \candlist{u} - (A_u \oplus \hat{p})||_q^{m},
\end{equation}
where $q,m \geq 1$ and $\oplus$ is the element-wise vector sum.
%The optimization process follows a clear strategy: we begin with a null perturbation, initializing $\hat{p}$ uniformly within the range $[-0.5, 0.5]^{|\mathcal{V}|}$. The vector $\hat{p}$ is then adjusted to move the intermediate perturbed vector $\hat{A_u} = A_u \oplus \hat{p}$ closer to a \emph{promising adjacency vector} for node $u$, represented as $\candlist{u}$. The precise definition of ``promising" will be described later in this section.
%Therefore, the first component of the loss function is defined as follows:
%\begin{equation}
%    \ell_{hide}(\hat{p}; A_u, \candlist{u}, q, m) = || \candlist{u} - (A_u \oplus \hat{p})||_q^{m},
%\end{equation}
%Where $\hat{v}$ is a vector that guides the optimization to encourage $u$ to connect to promising nodes outside its original community while disconnecting to the ones inside. 
%with $q,m \geq 1$. 

The second component of the loss ($\ell_{\text{dist}}$), instead, is designed to discourage large perturbations, aiming to identify the minimal counterfactual graph that causes $u$ to belong to a different community, as determined by $\f$.
To this end, we assess the distance between the original and intermediate adjacency vectors:
\begin{equation}
    \ell_{\text{dist}}(\hat{p}; A_u, q, n) = || A_u - (A_u \oplus \hat{p}) || = || \hat{p} ||_q^{n},
\end{equation}
where $q,n \geq 1$. Overall, the loss becomes as follows:
\begin{equation}
\label{eq:ourloss}
    \small
    \mathcal{L}(\hat{p}; A_u, \candlist{u}, q, m, n) = || \candlist{u} - (A_u \oplus \hat{p})||_q^{m} + \lambda \, || \hat{p} ||_q^{n}.
\end{equation}
%The first term incentivizes changes to be applied in the graph, while the second term plays a regularization role, slowing down the process of changes. 
Therefore, the objective is to determine the optimal perturbation vector $p^*$, which is obtained by solving the following constrained optimization problem:
\begin{equation}
\label{eq:p_objective}
\begin{split} 
    p^* & = \underset{\hat{p}}{\text{arg min}} \bigg \lbrace  \mathcal{L}(\hat{p}; A_u, \candlist{u}, q, m, n) \bigg \rbrace \\
    & \text{subject to: } |\mathcal{B}_{u}| \leq \beta.
\end{split}
\end{equation}
%where $|\mathcal{B}_{u}|$ can be computed as $|| A_u - A'_u||_1$, that is, the number of distinct elements between the original and perturbed adjacency vectors.

%We now explain the concept of a ``promising" adjacency vector, as assumed in the definition of the loss.
%The vector $\candlist{u}$ employs the heuristic outlined in Section \ref{sec:objective}: it evades the detection algorithm by disconnecting intra-community edges and forming extra-community connections. Specifically, this process considers the properties of the graph, prioritizing actions that involve significant nodes. \\
%The significance of a node $v$ is quantified by a score $S_v$, ranging from $0$ to $1$, that is the result of any operation, such as a normalized ranking score representing specific features of the network, or the output of a graph convolutional network. In this paper, we focus on the former case, leaving the latter for future studies. Assuming that we have a score for every node in the graph, we can define the promising adjacency vector as follows:

%%%%%%%%%%%%%%%%%%%%%
%%% PROMISING ACTIONS
%%%%%%%%%%%%%%%%%%%%%

\subsection{Promising Actions}
\label{subsec:candlist}
%TODO: Dopo spiegare il framework generico, approfondire l'implementazione che ci permette di paragonarci alle baseline
As introduced in Section \ref{subsec:loss}, we use $\candlist{u}$ as a surrogate for the output of $\f$ which we cannot embed in the loss. $\candlist{u}$ is a vector that prioritizes certain actions, thus we have a wide range of possibilities to calculate it. In this work, we choose to use the following heuristic.
Specifically, we introduce the significance of a generic node $v$ by quantifying its priority with a real-valued score $S_v \in [0,1]$. Thus, each entry of $\candlist{u}$ is defined as:
%The vector $\candlist{u}$ is designed to prioritize actions towards significant nodes, with the significance of a node $v$ quantified by a score $S_v \in [0,1]$. Specifically, this vector is defined as:
\begin{equation}
\label{eq:candlist}
        \candlist{u,v} = 
        \begin{cases}
            \frac{1}{2}(1-S_v) & \text{if } v \in C_i,  \\
            \frac{1}{2}(1+S_v) & \text{if } v \notin C_i.    
        \end{cases}
\end{equation} 
If a node belongs to the same community of $u$ ($v \in C_i$) and has a high score ($S_v \approx 1$), then $\candlist{u,v} \approx 0$. As a consequence, the algorithm is inclined to disconnect from that node, if an edge already exists. Conversely, if a node is outside $C_i$ and has a high score, then $\candlist{u,v} \approx 1$, and the algorithm is likely to form a connection if one does not already exist. On the other hand, when a node has a low score ($S_v \approx 0$), $\candlist{u,v} \approx \frac{1}{2}$ in both scenarios. This indicates the absence of a strong preference for adding or removing a connection to that node, implying no changes.

%For the experiments of Section \ref{sec:experiments}, scores are calculated from specific features of the graph, as mentioned above.
%In particular, we considered structural properties such as degree, centrality and inter/intra-community degree.
We compute the scores based on the structural properties of nodes, including degree, betweenness centrality, and intra/inter-community degree.
For each node, we compute the values of these properties, denoted by $\{\mathcal{f_1},\dots,\mathcal{f}_K\}$, and we sort them in ascending order. Thus, we create a ranking vector $r^{\mathcal{f}_i}$, where each element represents a node's position in the sorting on $\mathcal{f}_i$. Then, we normalize the rankings:
\begin{equation}
    S_v^{\mathcal{f}_i} = \dfrac{r_v^{\mathcal{f}_i} - 1}{|\mathcal{V}| - 1} \quad \forall v \in \mathcal{V}, \forall i=1\dots K.
\end{equation}
Ultimately, the final scores are obtained by aggregating all the score vectors associated with each feature through a linear combination $S_v = \sum_{i=1}^K  c_i \, S_v^{\mathcal{f}_i} \ \forall v \in \mathcal{V}$, where $c_{\mathcal{f}_i} \in [0,1]$ and $\sum_{i=1}^K c_i = 1$.

Of course, more strategies can be devised to compute $S_v$. For example, node significance could be derived from node embeddings learned using a graph neural network.
%We leave the exploration of this and other alternatives for future work.


%%%%%%%%%%%%%
%%% ALGORITHM
%%%%%%%%%%%%%

\subsection{\method{}}
\label{subsec:alg}
In this section, we describe our method, which we refer to as \method{}, and provide an overview of how it works in Algorithm \ref{alg:pseudocode}. 
Unlike the method proposed by  \citet{bernini2024kdd}, which performs the maximum permitted actions without verifying the outcome of $\f$, our technique uses the budget more efficiently.
Specifically, we recalculate the community structure at each graph modification, i.e., a change to $A'_u$, which allows to potentially achieve the hiding objective \textit{before} fully consuming the budget.
%Each iteration does not correspond to a graph modification, meaning no change is made to $A'_u$. Therefore, we do not need to recalculate the community structure at each step, but only after an actual graph update on $\graph'$.
%This allows our technique to use the budget more efficiently, as we may achieve the hiding objective \textit{before} fully consuming the budget. In contrast, \citet{bernini2024kdd} perform the maximum permitted actions without verifying the outcome of $\f$.
Lastly, if our method exceeds the budget without achieving the hiding objective, it triggers a restart of the optimization process, enabling us to explore multiple counterfactuals. 
%These benefits stem from the computational efficiency of our method, as discussed in Section \ref{subsec:results}.


\begin{algorithm}
    \caption{\texttt{\method{}}}\label{alg:pseudocode} 
    \begin{algorithmic}[1]
        \REQUIRE graph $\mathcal{G} = (\mathcal{V}, \mathcal{E})$;
        target node $u$;
        community detection algorithm $f(\cdot)$; max iterations $T$;
        %regularization constant $\lambda$;
        learning rate $\alpha$;
        similarity function $sim(\cdot)$;
        similarity threshold $\tau$.
        \ENSURE Counterfactual graph $\mathcal{G'}$
        \STATE $\hat{p} \sim \mathcal{U}([-0.5,0.5])^{|\mathcal{V}|}$
        \STATE $f(\mathcal{G}) = \{C_0, \ldots, C_k\}$, \text{with} $u \in C_i$
        \STATE Compute $\candlist{u}$ as defined in Eq. \ref{eq:candlist}
        \STATE $t \gets 0$, $C'_j \gets C_i$, $A'_u \gets A_u$ , $\mathcal{G'} \gets \mathcal{G}$
        \WHILE {$sim(C_i - \{u\}, C'_i - \{u\}) > \tau$ \textbf{and} $t < T$}
        %\Comment{\tiny $f(\tilde{G}) \neq f(G)$ if the new community differs at least for $50\%$ of members ($\tau = 0.5$)}
            %\STATE $\mathcal{L}(h_{\hat{p}}; \mathcal{G}, f, u) = \mathcal{l}_{decept} + \lambda \,\mathcal{l}_{dist}$
            \STATE $\hat{p} \gets \tanh(\hat{p} + \alpha \nabla_{\hat{p}} \, \mathcal{L}(\hat{p}; A_u, \candlist{u}, q, m , n))$
            %\STATE $\hat{p} \gets \tanh{(\hat{p})}$
            \STATE $p \gets \operatorname{threshold}(\hat{p})$
            \STATE $A'_u \gets \operatorname{clamp}(A_u \oplus p)$
            \IF{$A'_u$ differs from previous iteration}
                \STATE Update $\mathcal{G'}$ using $A'_u$
                \STATE $f(\mathcal{G'}) = \{C'_0, \ldots, C'_r\}$, \text{with} $u \in C'_j$
            \ENDIF
            \IF{$b > \beta$}
                \STATE $\hat{p} \sim \mathcal{U}([-0.5,0.5])^{|\mathcal{V}|}$
            \ENDIF
            \STATE $t \gets t+1$
        \ENDWHILE
        \STATE \textbf{return} $\mathcal{G'}$
    \end{algorithmic}
\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% COMPUTATIONAL COMPLEXITY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Computational Complexity Analysis}
\label{subsec:time_complexity}
%TO DO:
We analyze the computational complexity of our proposed method to determine its feasibility for deployment in large-scale production environments. \\
For this study, we recall that $|\nodes| = n$ and $|\edges| = m$. The complexity of our method primarily depends on two operations outside the optimization process, as the others reduce to $O(n)$ vector operations. Let $F(n,m)$ denote the the cost of applying the  detection algorithm $\f$, and $\tilde{F}(n,m)$  the cost of constructing the vector $\candlist{u}$. 
With $T$ max iterations, the total computational cost is:
\begin{equation}
    O \bigg[ n + \tilde{F}(n,m) + F(n,m) + T ( n + F(n,m)) \bigg]
\end{equation}
In our implementation, $\tilde{F}(n,m) = O(mn)$, as centrality calculation dominates other operations. For community detection, $F(n,m)$ depends on the specific algorithm considered. Specifically, limiting our analysis to the community detection algorithms selected in this work, the complexity is $O[(n+m) \log n]$ for \textit{greedy}, $O(m)$ for \textit{louvain} and $O(mn^2)$ for \textit{walktrap}.






