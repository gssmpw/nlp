% RECAP:
% Performance superiori
% Maggiore efficienza computazionale
% Transferability (per far vedere che siamo comparabili, perché overfittiamo?)
% Esempio aneddotico sulple azioni rispetto all'agente


%%%%%%%%%%%%%%%%%%%%%%
%%% EXPERIMENTAL SETUP
%%%%%%%%%%%%%%%%%%%%%%

\subsection{Experimental Setup}

%%%% DATASETS

\textbf{\textit{Datasets.}} We validate our method on a variety of real-world undirected graphs, spanning several domains. These include collaboration networks (\texttt{kar}\footnote{\label{fn:konect}\href{http://konect.cc/}{http://konect.cc/}}, \texttt{words}\footref{fn:konect}, and Wikipedia's \texttt{vote}\footnote{\label{fn:networkrepo}\href{https://networkrepository.com}{https://networkrepository.com}}), %citation networks (Condensed Matter \texttt{arxiv}\footnote{\label{fn:arxiv}\href{https://snap.stanford.edu/data/}{https://snap.stanford.edu/data/}}), 
social networks (Facebook's \texttt{fb-75}\footref{fn:networkrepo}), and infrastructure networks (US Power Grid \texttt{pow}\footref{fn:konect}).

%%% DETECTION ALGS
\textbf{\textit{Community Detection Algorithms.}} 
We evaluate our approach on two modularity-based algorithms, namely  \textit{greedy} \cite{greedy_detection_alg} and \textit{louvain} algorithm \cite{louvain_detection_alg}, and the \textit{walktrap} algorithm \cite{walktrap_detection_alg}, which takes a distinct approach by leveraging random walks. \\
Table \ref{tab:datasets_and_communities} summarizes the datasets used in our evaluation, providing details on their sizes and the number of communities identified by each detection algorithm.

\begin{table}[htpb]
\centering
\vspace{-1mm}
\caption{Properties of the graph datasets considered in this work, including the number of communities identified by \textit{greedy}, \textit{louvain}, and \textit{walktrap}.}
\label{tab:datasets_and_communities}
\scalebox{0.9}{
    \begin{tabular}{l c c c c c}
        \toprule
        \multirow{2}{*} {\textbf{Dataset}} &  \multirow{2}{*} {$|\mathcal{V}|$} &  \multirow{2}{*} {$|\mathcal{E}|$} & \multicolumn{3}{c}{\textbf{Detected Communities}} \\
        \cmidrule(lr){4-6}
        & & & \textit{greedy} & \textit{louvain} & \textit{walktrap} \\
        \midrule
        \rowcolor[gray]{0.95} \texttt{kar} & 34 & 78 & 3 & 4 & 5 \\
        \texttt{words} & 112 & 425 & 7 & 7 & 25 \\
        \rowcolor[gray]{0.95} \texttt{vote} & 889 & 2,900 & 12 & 10 & 42 \\
        \texttt{pow} & 4,941 & 6,594 & 40 & 41 & 364 \\
        \rowcolor[gray]{0.95}\texttt{fb-75} & 6,386 & 217,662 & 29 & 19 & 357 \\
        %\texttt{arxiv} & 23,133 & 93,497 & 813 & 617 & 3000\\
        \bottomrule
    \end{tabular}
    }
    \vspace{-2mm}
\end{table}

%%% SIMILARITY METRIC
\textbf{\textit{Similarity Metric.}} 
To determine the success of obscuring community memberships, we  define the similarity function $sim(\cdot,\cdot)$ used in Algorithm \ref{alg:pseudocode}. Specifically, we employ the Sørensen-Dice coefficient \cite{metrics:Dice}, a measure of similarity between two sets, as detailed in Appendix \ref{app:dcs}. 
This metric outputs a value ranging from $0$ (no similarity) to $1$ (high similarity). If $sim(C_i - \{u\}, C'_i - \{u\}) \leq \tau$, we consider the community membership hiding objective successfully achieved.

%%% LOSS FUNCTION

\textbf{\textit{$\nabla$-CMH.}} We use Adam optimizer to solve the objective associated with our method (see Eq. \ref{eq:ourloss}). We set the three key parameters of this loss function as $q=2, m=2$, and $n=1$. In addition, we perform a comprehensive hyperparameter search for $\lambda, T, \alpha$ and $\{c_i\}_{i=1\dots K}$. The specific values identified through this process are detailed in Appendix \ref{app:hyp}. 
%The exploration of other norm types is left to future work.

%%% BASELINES

\textbf{\textit{Baselines.}} We compare the hiding assessment of our method (\method{}) against six baseline approaches.\\
\noindent \textit{1) DRL-Agent}. It is a deep reinforcement learning method, as detailed in Section \ref{sec:related}. \\
\noindent \textit{2) Random-based}. It selects an edge from $\mathcal{B}$ randomly, removing it if it exists or adding it otherwise. \\
%The randomness of these actions is designed to effectively conceal the node’s actual community membership.\\
\noindent \textit{3) Greedy-based}. This approach, proposed by \citet{bernini2024kdd}, selects between $(i)$ the node connected to the target node $u$ with the highest intra-community degree -- i.e. the node $w^* \in C_i\setminus\{u\}$ s.t. $(u,w^*) \in \edges$ and that maximizes $deg_C(w) = |\{(w,x)|x\in C\}|$, and $(ii)$ the  highest-degree node not connected to $u$. It computes the loss for removing or adding the connection and selects the optimal action.\\
\noindent \textit{4) Degree-based}. It selects an edge from $ \mathcal{B} $ that involves the highest-degree node, removing or adding its link. \\
\noindent \textit{5) Roam-based}. This method builds on the Roam heuristic \cite{deception_modularity_2}, which is originally developed to effectively reduce a node’s centrality within the network.\\
\noindent \textit{6) Betweenness-based}. It prioritizes disconnecting nodes with the highest betweenness centrality, calculated according to \citet{freeman1977betweenness} and detailed in Appendix \ref{app:cent}. 

%%% EVALUATION METRICS

\textbf{\textit{Evaluation Metrics.}}
We evaluate the effectiveness of each method 
%in addressing the community membership hiding problem 
using the following metrics.\\
\noindent \textit{1) Success Rate} (SR). This metric computes the success rate of the community membership hiding problem by measuring the percentage of instances where the target node is successfully concealed from its original community -- i.e $sim(C_i - \{u\}, C'_i - \{u\})  \leq \tau$. 
A higher value of this metric indicates better performance.\\
\noindent \textit{2) Normalized Mutual Information} (NMI). To evaluate the impact of the counterfactual graph $\graph'$ on the resulting community structure $f(\graph')$, we compute the NMI score 
%\cite{nmi_1,nmi_2} 
between $f(\graph')$ and the original structure $ f(\graph)$, 
%following the formulation by \citet{nmi_3}, 
as detailed in Appendix \ref{app:nmi}.
A higher value of this metric indicates greater similarity, corresponding to a lower cost. \\
In general, SR and NMI are inherently contrasting metrics, where higher SR often means lower NMI, and vice versa. To achieve the optimal trade-off between the two, we compute their harmonic mean using the formula $ \frac{2 \times \text{SR} \times \text{NMI}}{\text{SR} + \text{NMI}} $, analogous to how the F1 score balances precision and recall.


%%%%%%%%%%%
%%% RESULTS
%%%%%%%%%%%

\subsection{Results and Discussion}
\label{subsec:results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%Table of parameter sensitivity
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table*}[htpb]
    \centering
    \caption{Impact of $\tau$ and $\beta$ on Success Rate (SR) in the symmetric setting (\,$\f$: \textit{greedy}) on the \texttt{vote} dataset.}
    \label{tab:param_sens}
    \scalebox{0.8}{
    \begin{tabular}{cccccccccc}
        \toprule
        \multirow{2}{*}{\textbf{$\bm{\tau}$}} & \multirow{2}{*}{\textbf{$\bm{\beta}$}} & \multicolumn{7}{c}{\textbf{Community Membership Hiding Algorithm}} \\
        \cmidrule(lr){3-9}
        & & \textit{\method{}\,(ours)} & \textit{DRL-Agent} & \textit{Random} & \textit{Greedy} & \textit{Degree} & \textit{Roam} & \textit{Betweenness} \\
        \midrule
        \multirow{3}{*}{0.3} 
        & $\frac{1}{2}\mu$ & $\mathbf{49.8\% \pm 6.6\%}$ & $36.3\% \pm 6.3\%$ & $29.1\% \pm 6.0\%$ & $29.1\% \pm 6.0\%$ & $30.9\% \pm 6.1\%$ & $37.7\% \pm 6.4\%$ & $20.6\% \pm 5.3\%$ \\
        & $1\mu$ & $\mathbf{77.6\% \pm 5.5\%}$ & $46.6\% \pm 6.5\%$ & $44.8\% \pm 6.5\%$ & $32.3\% \pm 6.1\%$ & $23.3\% \pm 5.6\%$ & $24.2\% \pm 5.6\%$ & $23.3\% \pm 5.6\%$ \\
         & $2\mu$ & $\mathbf{84.8\% \pm 4.7\%}$ & $60.1\% \pm 6.4\%$ & $40.4\% \pm 6.4\%$ & $26.9\% \pm 5.8\%$ & $25.6\% \pm 5.7\%$ & $32.3\% \pm 6.1\%$ & $29.6\% \pm 6.0\%$ \\
        \midrule
        \multirow{3}{*}{0.5} 
        & $\frac{1}{2}\mu$ & $\mathbf{65.9\% \pm 6.2\%}$ & $48.4\% \pm 6.6\%$ & $43.5\% \pm 6.5\%$ & $0.0\% \pm 0.0\%$ & $41.7\% \pm 6.5\%$ & $38.1\% \pm 6.4\%$ & $25.1\% \pm 5.7\%$ \\
         & $1\mu$ & $\mathbf{79.8\% \pm 5.3\%}$ & $58.7\% \pm 6.5\%$ & $54.3\% \pm 6.5\%$ & $48.9\% \pm 6.6\%$ & $32.3\% \pm 6.1\%$ & $24.2\% \pm 5.6\%$ & $32.3\% \pm 6.1\%$ \\
        & $2\mu$ & $\mathbf{85.7\% \pm 4.6\%}$ & $74.9\% \pm 5.7\%$ & $51.6\% \pm 6.6\%$ & $49.3\% \pm 6.6\%$ & $46.6\% \pm 6.5\%$ & $43.9\% \pm 6.5\%$ & $47.1\% \pm 6.6\%$ \\
        \midrule
         \multirow{3}{*}{0.8} 
        & $\frac{1}{2}\mu$ & $\mathbf{83.9\% \pm 4.8\%}$ & $74.9\% \pm 5.7\%$ & $63.7\% \pm 6.3\%$ & $82.1\% \pm 5.0\%$ & $81.6\% \pm 5.1\%$ & $61.4\% \pm 6.4\%$ & $52.0\% \pm 6.6\%$ \\
        & $1\mu$ & $\mathbf{99.6\% \pm 0.9\%}$ & $88.8\% \pm 4.1\%$ & $91.0\% \pm 3.8\%$ & $91.0\% \pm 3.8\%$ & $58.7\% \pm 6.5\%$ & $27.4\% \pm 5.9\%$ & $58.3\% \pm 6.5\%$ \\
        & $2\mu$ & $\mathbf{99.6\% \pm 0.9\%}$ & $85.2\% \pm 4.7\%$ & $75.3\% \pm 5.7\%$ & $81.2\% \pm 5.1\%$ & $66.8\% \pm 6.2\%$ & $66.4\% \pm 6.2\%$ & $62.3\% \pm 6.4\%$ \\
        \bottomrule
    \end{tabular}
    }
    \vspace{-3mm}
\end{table*}

We evaluate three key aspects of  \method{}. First, we assess its effectiveness in hiding target nodes from their communities compared to all baseline methods. Second, we analyze its computational performance relative to DRL-Agent. Finally, we demonstrate the transferability of our method in an asymmetric setting, i.e., when $\f$ does not match with the actual community detection algorithm used by the social media platform.

Our analysis examines a range of parameter configurations, including different values for the similarity constraint $ \tau $ ($0.3, 0.5, 0.8$) and the fixed budget $ \beta $ ($ \frac{1}{2} \mu, 1\mu, 2\mu$, where $ \mu = \frac{|\edges|}{|\nodes|}$).\footnote{For \texttt{kar} and \texttt{pow}, we specifically use $ \mu = \frac{|\edges|}{|\nodes|} + 1$.} 
For each set of experiments, we select three communities of varying sizes -- approximately $0.3, 0.5, 0.8 $ of the largest community. Then, for every community we randomly choose up to $100$ nodes and
%, resulting in a maximum of $300$ experiments.
if a cluster contains fewer than $100$ nodes, we attempt to hide every member of that community. This approach avoids repeating experiments on the same nodes and ensures evaluation across diverse community types, providing a more comprehensive assessment. We also evaluate our method in two distinct setups: \emph{symmetric} and \emph{asymmetric}. In the symmetric setting, we use the same detection algorithm $\f$ both during optimization and evaluation. In the asymmetric scenario, we analyse our method on a detection algorithm $g(\cdot)$, different from the one used for optimization $\f$. This configuration allows us to assess the \emph{transferability} of our method to algorithms it was not exposed to during the hiding process. Specifically, we always use \textit{greedy} as $\f$, and in the asymmetric setting we use either \textit{louvain} or \textit{walktrap} as $g(\cdot)$.


%%%%%%%%%%%%%%%
%%% PERFORMANCE
%%%%%%%%%%%%%%%

\textbf{\textit{Hiding Assessment.}}
In the symmetric setting, our method consistently outperforms all baseline approaches by a significant margin, as depicted in Fig.\ref{fig:f1-symmetric-greedy}, demonstrating its effectiveness in addressing the problem.
Furthermore, \method{} demonstrates a significant advantage in resource efficiency. Unlike baseline methods that always exhaust the whole allocated budget, our approach employs resources more judiciously. As illustrated in Table \ref{tab:used_budget} in Appendix \ref{app:hiding}, which provides a comprehensive summary of budget usage across all datasets, our method successfully maintains strong performance without fully depleting the available budget. %This is especially evident in networks characterized by a high average degree.
This efficiency highlights our approach's ability to achieve an optimal balance between performance and resource utilisation, delivering robust results at a lower cost. \\
%For further insights into the performance of our method under various budget values, please refer to the detailed results presented in Appendix \ref{app:hiding}.

\begin{figure}[htpb]
    \centering
    \includegraphics[width=1\linewidth]{sections/images/f1_greedy_tau05_beta1_grouped.png}
    \caption{F1 score of SR and NMI in the symmetric setting (\,$\f$ : \textit{greedy}; $\tau=0.5$; $\beta=1\mu$).}
    \label{fig:f1-symmetric-greedy}
    %\vspace{-3mm}
\end{figure}

% Aggiunta in appendice
%\begin{table}[htpb]
%\centering
%\caption{Average budget consumption of \method{} across all datasets in successful node masking, relative to the available budget $\beta = 1\mu$ (all baselines use $100\%$ of the budget).}
%\label{tab:used_budget_beta1}
%\scalebox{0.9}{
%    \begin{tabular}{ l c c }
%        \toprule
%        {\textbf{Dataset}} &  
%        {$\beta$} & {Consumed Budget}  \\
%        \midrule
%        \rowcolor[gray]{0.95} \texttt{kar} &$3$ & $2.5 \ \ (82.8\%)$ \\
%        \texttt{words} &$3$ & $2.2 \ \ (71.8\%)$ \\
%        \rowcolor[gray]{0.95} \texttt{vote} &$3$ & $2.1 \ \ (69.3\%)$ \\
%        \texttt{pow} &$2$ & $1.4 \ \ (68.1\%)$ \\
%        \rowcolor[gray]{0.95}\texttt{fb-75} &$34$ & $17.4 \ \ (51.0\%)$ \\
%        %\texttt{arxiv} &0 & 0 \\
%        \bottomrule
%    \end{tabular}
%}
%\end{table}


%%%%%%%%%%%%%%%%%%%%
%%% TRANSFERABILITY
%%%%%%%%%%%%%%%%%%%%

\textbf{\textit{Transferability.}}
%In Figure \ref{fig:f1-grouped}, we present the harmonic mean (F1 score) between SR and NMI across all datasets for the asymmetric settings, with a fixed similarity threshold of $\tau = 0.5$ and a budget of $\beta = 1 \mu$.
%We observe notable transferability of our method, an essential attribute for Community Membership Hiding algorithms. Even in asymmetric settings, where the training and testing scenarios involve different community detection algorithms, our method achieves competitive results. However, it is worth noting that while our performance remains solid, it does not universally surpass all baseline methods, especially on large networks. This discrepancy underlines an inherent limitation of our method: its tendency to overfit the community detection algorithm used during training. This inclination highlights an avenue for future improvements, emphasizing the need for adaptations that enhance generalizability in asymmetric setups.
In the asymmetric setting, our method demonstrates solid performance. However, it does not consistently outperform all baseline methods across all scenarios. As shown in Fig. \ref{fig:f1-asymmetric}, this limitation becomes particularly apparent in larger networks, where certain baselines achieve comparable or even superior results. We conjecture that this disparity underscores a tendency of \method{} to overfit the community detection algorithm employed during the optimization process. Recognizing this challenge presents an opportunity for future enhancements. Specifically, adaptations are needed to improve the method's generalizability in asymmetric scenarios. See Appendix \ref{app:transferability} for more results on different budget values.

\begin{figure}[htpb]
    \centering
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{sections/images/f1_louvain_tau05_beta1_grouped.png}
        \subcaption{$\f$ : \textit{greedy}; $g(\cdot)$ : \textit{louvain}.}
        \label{fig:f1-louv}
    \end{subfigure}
    \vspace{5mm} % Adjust vertical spacing if necessary
    \begin{subfigure}{\linewidth}
        \centering
        \includegraphics[width=\linewidth]{sections/images/f1_walktrap_tau05_beta1_grouped.png}
        \subcaption{$\f$ : \textit{greedy}; $g(\cdot)$ : \textit{walktrap}.}
        \label{fig:f1-walk}
    \end{subfigure}
    \vspace{-10mm}
    \caption{F1 scores of SR and NMI in the asymmetric settings (\textit{louvain}, \textit{walktrap}) when $\tau=0.5$ and $\beta=1\mu$.}
    \label{fig:f1-asymmetric}
    \vspace{-3mm}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%Table of parameter sensitivity
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Spostata su
%\begin{table*}[htpb]
%    \centering
%    \caption{Impact of $\boldsymbol{\tau}$ and $\boldsymbol{\beta}$ on Success Rate (SR) in the symmetric setting on the \texttt{vote} dataset.}
%    \label{tab:param_sens}
%    \scalebox{0.8}{
%    \begin{tabular}{cccccccccc}
%        \toprule
%        \multirow{2}{*}{\textbf{$\bm{\tau}$}} & \multirow{2}{*}{\textbf{$\bm{\beta}$}} & \multicolumn{7}{c}{\textbf{Community Membership Hiding Algorithm}} \\
%        \cmidrule(lr){3-9}
%        & & \textit{\method{}\,(ours)} & \textit{DRL-Agent} & \textit{Random} & \textit{Greedy} & \textit{Degree} & \textit{Roam} & \textit{Betweenness} \\
%        \midrule
%        \multirow{3}{*}{0.3} 
%        & $\frac{1}{2}\mu$ & $\mathbf{49.8\% \pm 6.6\%}$ & $36.3\% \pm 6.3\%$ & $29.1\% \pm 6.0\%$ & $29.1\% \pm 6.0\%$ & $30.9\% \pm 6.1\%$ & $37.7\% \pm 6.4\%$ & $20.6\% \pm 5.3\%$ \\
%        & $1\mu$ & $\mathbf{77.6\% \pm 5.5\%}$ & $46.6\% \pm 6.5\%$ & $44.8\% \pm 6.5\%$ & $32.3\% \pm 6.1\%$ & $23.3\% \pm 5.6\%$ & $24.2\% \pm 5.6\%$ & $23.3\% \pm 5.6\%$ \\
%         & $2\mu$ & $\mathbf{84.8\% \pm 4.7\%}$ & $60.1\% \pm 6.4\%$ & $40.4\% \pm 6.4\%$ & $26.9\% \pm 5.8\%$ & $25.6\% \pm 5.7\%$ & $32.3\% \pm 6.1\%$ & $29.6\% \pm 6.0\%$ \\
%        \midrule
%        \multirow{3}{*}{0.5} 
%        & $\frac{1}{2}\mu$ & $\mathbf{65.9\% \pm 6.2\%}$ & $48.4\% \pm 6.6\%$ & $43.5\% \pm 6.5\%$ & $0.0\% \pm 0.0\%$ & $41.7\% \pm 6.5\%$ & $38.1\% \pm 6.4\%$ & $25.1\% \pm 5.7\%$ \\
%         & $1\mu$ & $\mathbf{79.8\% \pm 5.3\%}$ & $58.7\% \pm 6.5\%$ & $54.3\% \pm 6.5\%$ & $48.9\% \pm 6.6\%$ & $32.3\% \pm 6.1\%$ & $24.2\% \pm 5.6\%$ & $32.3\% \pm 6.1\%$ \\
%        & $2\mu$ & $\mathbf{85.7\% \pm 4.6\%}$ & $74.9\% \pm 5.7\%$ & $51.6\% \pm 6.6\%$ & $49.3\% \pm 6.6\%$ & $46.6\% \pm 6.5\%$ & $43.9\% \pm 6.5\%$ & $47.1\% \pm 6.6\%$ \\
%        \midrule
%         \multirow{3}{*}{0.8} 
%        & $\frac{1}{2}\mu$ & $\mathbf{83.9\% \pm 4.8\%}$ & $74.9\% \pm 5.7\%$ & $63.7\% \pm 6.3\%$ & $82.1\% \pm 5.0\%$ & $81.6\% \pm 5.1\%$ & $61.4\% \pm 6.4\%$ & $52.0\% \pm 6.6\%$ \\
%        & $1\mu$ & $\mathbf{99.6\% \pm 0.9\%}$ & $88.8\% \pm 4.1\%$ & $91.0\% \pm 3.8\%$ & $91.0\% \pm 3.8\%$ & $58.7\% \pm 6.5\%$ & $27.4\% \pm 5.9\%$ & $58.3\% \pm 6.5\%$ \\
%        & $2\mu$ & $\mathbf{99.6\% \pm 0.9\%}$ & $85.2\% \pm 4.7\%$ & $75.3\% \pm 5.7\%$ & $81.2\% \pm 5.1\%$ & $66.8\% \pm 6.2\%$ & $66.4\% \pm 6.2\%$ & $62.3\% \pm 6.4\%$ \\
%        \bottomrule
%    \end{tabular}
%    }
%\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%COMPUTATIONAL EFFICIENCY
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{\textit{Computational Efficiency.}}\footnote{All experiments were conducted on a GPU NVIDIA GeForce RTX 4090 and AMD Ryzen 9 7900 CPU 12-Core Processor.}
Lastly, our method exhibits notable computational efficiency, operating faster than DRL-Agent. This speed advantage further enhances its practical applicability in real-world scenarios. Figure \ref{fig:time} illustrates the average evasion time across datasets in the symmetric setting with $\tau=0.5$ and $\beta$, clearly showing that \method{} consistently outperforms the agent. For detailed performance metrics and relative speed-ups, refer to Table \ref{tab:speedups}. Additional results for other budget values are shown in Appendix \ref{app:comp-eff}.

\begin{figure}[htbp!]
    \centering
    \includegraphics[width=\linewidth]{sections/images/time_greedy_tau05_beta1_grouped.png}
    \caption{Average evasion time (secs.), comparing \method{} with DRL-Agent when $\tau=0.5$ and $\beta=1\mu$. }
    \label{fig:time}
    \vspace{-3mm}
\end{figure}

\begin{table}[htbp!]
\centering
\caption{Speed-up (secs.) of \method{} compared to DRL-Agent in evading $\f$ when $\tau=0.5$ and $\beta=1\mu$.}
\label{tab:speedups}
\scalebox{0.9}{
    \begin{tabular}{ l c c c c c }
        \toprule
        \multirow{2}{*} {\textbf{Dataset}} &  \multicolumn{2}{c}{\textbf{ Algorithms}} & \multirow{2}{*} {\textbf{Speed-up}} \\
        \cmidrule(lr){2-3}
        & \textit{\method{} (ours)} & \textit{DRL-Agent} \\
        \midrule
        \rowcolor[gray]{0.95} \texttt{kar} & $0.015$ & $0.019$ & $\times 1.226  \ \blacktriangle$ \\
        \texttt{words} & $0.013$ & $0.041$ & $\times 3.096  \ \blacktriangle$ \\
        \rowcolor[gray]{0.95} \texttt{vote} & $0.081$ & $0.261$ & $\times 3.214 \ \blacktriangle$ \\
        \texttt{pow} & $0.208$ & $0.549$ & $\times 2.645  \ \blacktriangle$ \\
        \rowcolor[gray]{0.95}\texttt{fb-75} & $23.988$ & $128.267$ & $\times 5.347 \ \blacktriangle$ \\
        %\texttt{arxiv} & 0 & 0 & 0 \\
        \bottomrule
    \end{tabular}
    }
    %\vspace{-3mm}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PARAMETER SENSITIVITY
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parameter Sensitivity Analysis}
\label{subsec:param-sens}
The performance of our method is influenced by two key parameters: $(i)$ the similarity threshold $\tau$ and $(ii)$ the budget $\beta$. In Table \ref{tab:param_sens}, we illustrate how changes in $\tau$ and $\beta$ impact the success rate in the community membership hiding task.
%, with the detection algorithm $\f$ and the dataset fixed
The reported results correspond to the symmetric setting on the \texttt{vote} dataset. As expected, increasing the threshold simplifies the achievement of the concealment goal, raising the success rate for a fixed budget by imposing less strict requirements on membership hiding. Similarly, a larger budget allows more significant neighborhood modifications, further boosting success rates. In Appendix \ref{app:param-sens}, we explore the sensitivity on all datasets and in two asymmetric settings.


\subsection{Potential Side Effects}
Solving the community membership hiding task for a node using {\method} by modifying the graph's structural properties may introduce unintended side effects for other nodes. For example, masking a node from its community could cause another node to leave its community or be reassigned to a different one. 
In such cases, the output of our method should be checked \textit{before} being put into practice. However, we believe that such post hoc checks are reasonable, as the actual implementation of {\method} would fall under the responsibility of the entity controlling the graph network rather than the individual node. For a deeper discussion of the practical implications of our method, refer to the ``Impact Statements'' section below.