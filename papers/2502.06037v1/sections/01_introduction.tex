Foundation models have demonstrated an exceptional ability to generalize in zero-shot prediction tasks. Inspired by the success of such models in Natural Language Processing, recent work has adapted Transformers to build time series foundation models (TSFM). Zero-shot inference is particularly important for time series models, which must handle complex patterns, seasonal variations, and emerging trends where little to no reference data may be available.

To achieve zero-shot generalization, TSFMs are trained on increasingly large and diverse datasets, aiming to expand coverage and minimize unseen patterns. This raises a critical question: \textbf{Do TSFMs succeed by memorizing training patterns, or do they possess an ability to reason?} If TSFMs rely primarily on memorization, their ability to generalize to unseen data may be limited. In such cases, these memorization-dependent models would become overly reliant on training data and suffer from inefficient knowledge storage, requiring progressively larger models to generalize effectively. We argue that a good TSFM should be capable of \emph{implicit reasoning}, enabling it to go beyond memorization and extrapolate unseen patterns. Such models would require fewer data points to generalize, utilize fewer parameters, and demonstrate greater robustness.

Although memorization and reasoning have been extensively studied in language models, their time series counterparts remain largely unexplored in these contexts and require investigation. 

In this work, we take an initial step toward assessing the implicit reasoning abilities of neural forecasting models, with a focus on compositional reasoning--the ability to leverage and compose learned patterns from simpler forecasting tasks to generalize to more complex, unseen patterns. This definition refines out-of-distribution (OOD) generalization by emphasizing how learning fundamental patterns equips models to handle logically derived, more intricate scenarios.

The main contributions of this paper are:
\begin{enumerate}[(i)]
\item \textbf{Reasoning Framework for Time Series.} We formally define compositional reasoning in time series and introduce a framework to evaluate neural models' reasoning capabilities in forecasting. Using spectral analysis, we assess various methods' capacity to \emph{logically} generalize to unseen periodic patterns through basis function extrapolation.

\item \textbf{Large-Scale Study of Model Architectures and Design Components.} We evaluate the performance of 23 popular deep learning forecasting models on both synthetic and real-world datasets, identifying architectures that consistently demonstrate generalization and reasoning abilities. Additionally, through controlled studies, we systematically examine which design choices in TSFMs contribute to improved reasoning abilities.

\item \textbf{Open-source Code and Data.}
We introduce a synthetic dataset with arbitrarily complex time series, designed to evaluate compositional reasoning. The model, training framework, and datasets are open-source, enabling reproducible experimentation and supporting future studies on model reasoning. Our code is available at %\url{https://anonymous.4open.science/r/reasoning_ICML_paper_submission}. 
\url{https://github.com/PotosnakW/neuralforecast/tree/tsfm_reasoning}.
\end{enumerate}

The rest of the paper is structured as follows. Section~\ref{section:related_work} reviews relevant literature. Section~\ref{section:methods} introduces generalization and compositional-reasoning tasks. Section~\ref{section:results} contains our empirical findings. Finally, Section~\ref{section:discussion} discusses future research directions
and concludes. Complementary material may be found in the Appendices.
