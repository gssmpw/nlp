\input{tables/main_table}
\input{figures/cd_figures}

\textbf{Patch-based Transformers \& MLP-based models show sparks of compositional reasoning.} Transformer-based models that `patch' input time series, including \PatchTST and the \Tfive, as well as MLP-based models, such as \MLP, \NHITS, and \NBEATS, achieve the highest number of wins as one of the top three models for compositional reasoning tasks on OOD data, as shown in Table~\ref{tab:composition_main} and Fig.~\ref{fig:cd_baselines_component_main}. Standard deviation results for all models in Table~\ref{tab:composition_main} are provided in Table~\ref{tab:composition_baseline_results_table} in Appendix~\ref{apd:composition_full_table_results}. Moreover, these models as well as \TimesNet and \TFT were the only models to outperform at least 2 basis function compositions on average across the datasets, indicating some implicit reasoning capacity through composition of basis signals. The top $k$ basis wins for ID and OOD data are shown in Table~\ref{tab:composition_main} and in Fig.~\ref{fig:topkwins}. Among these, the \Tfive and \NBEATS\ achieve the highest number of wins as one of the top three models as well as the highest number of average top $k$ basis function composition wins for OOD data. The composition win average for these two models achieved at least 18\% of their wins for ID data. Example forecasts for these models on the Subseasonal dataset shown in Fig.~\ref{fig:subseasonal_ood_forecast_example_main} highlights generalization achieved through compositional reasoning. Forecast examples for all 6 datasets are provided in Figs.~\ref{fig:forecast_examples1_apd} and~\ref{fig:forecast_examples2_apd} in Appendix~\ref{apd:forecast_examples}.

\textbf{Zero-shot T5 in OOD scenarios can improve upon statistical model baselines trained on ID data.} Zero-shot forecasts for the \Tfive, \NHITS, \NBEATS, and \MLP models in OOD scenarios via the compositional reasoning forecasting paradigm can outperform moving average forecasts for \ARIMA models trained on ID data across all 6 datasets. These same models can also outperform \ETS model forecasts for 2 of 6 datasets. All other models can outperform both statistical baselines for 1 of 6 datasets. This result underscores the effectiveness of \Tfive and residual-
ized MLP-based architectures in zero-shot forecasting for stationary OOD data. It also suggests that such models trained on various concepts, or basis functions, may serve as strong baseline candidates alongside statistical models for effective generalization in OOD scenarios.

% Zero-shot forecasts for the \Tfive as well as \NHITS, and \MLP models in OOD scenarios via the compositional reasoning forecasting paradigm can outperform both \ARIMA and \ETS models trained on ID data across all 6 datasets. \NBEATS and \PatchTST can outperform both statistical models across 5 datasets where all other models achieve lower win rates across datasets. 


\textbf{Better ``reasoners" can also be computational efficient.} The \Tfive, \MLP, \NHITS, and \NBEATS models demonstrate lower computational complexity in terms of floating-point operations per second (FLOPs) compared to many other Transformer, RNN, and CNN models. However, the \Tfive model exhibits the second largest size in terms of total trainable parameters, whereas models such as \MLP, \NHITS and \NBEATS have much smaller footprints, as shown in Fig.~\ref{fig:flops_model_comparison}. %\LSTM, \TCN, and \TimesNet had the highest FLOPs (see Fig.~\ref{fig:flops_component_with_timesnet}). 
Performance versus FLOPs plots for both ID and OOD scenarios are provided in Appendix~\ref{apd:flops_plots}.

\textbf{Input patching enables Transformer-based TSFMs, while other tokenization methods degrade performance.} We observe that the \Tfive with fixed-length patches significantly outperforms different tokenization methods in compositional reasoning tasks, as shown in Fig.~\ref{fig:cd_tokenization_ablation_component}. Patch-based tokenization also ranks highest for experiments on ID series. For other \Tfive model ablations, we observe that model size and projection layer also demonstrate statistically significant differences across methods as shown in Figs.~\ref{fig:cd_size_ablation_component},
~\ref{fig:cd_tokenization_ablation_component}, ~\ref{fig:cd_proj_ablation_component}, respectively. Other design decisions, such as attention type, token length, positional encoding, loss functions, input/output scaling functions, context length, input decomposition did not demonstrate statistically significant differences as shown in Fig.~\ref{fig:cd_diagrams_apd} in Appendix~\ref{apd:cd_diagrams}. 


\begin{figure}[htbp!]
    \centering
    \includegraphics[width=0.5\textwidth, trim=95 50 0 0, clip]{images/topkwins.pdf}
    \caption{The average number of top $k$ compositions that models can outperform across datasets for ID and OOD data. The difference in wins between ID and OOD data is shown in green, with lighter colors indicating larger deviations. As the average number of top $k$ compositions outperformed increases for OOD data, models demonstrate better generalization through compositional reasoning. Patch-based Transformers and MLP-based models outperform others in reason-based generalization for OOD scenarios. Models in the top right corner perform well on ID tasks but show less evidence of compositional reasoning capabilities.}
    \label{fig:topkwins}
\end{figure}

\textbf{Architecture choices that perform well for ID series do not necessarily perform well for OOD series.} Some models demonstrate consistently higher performance across both ID and OOD data, such as models like \NHITS, \NBEATS, \MLP and the \Tfive. However, our ablation studies with the \Tfive reveal that certain architecture components choices that that perform well for ID series do not necessarily perform well for OOD series. In particular, smaller models rank higher in performance than larger models in compositional reasoning tasks across datasets, whereas larger models outperform smaller models in the general train/test paradigm, as shown in Figs.~\ref{fig:cd_size_ablation_aggregate} and~\ref{fig:cd_size_ablation_component}. Similarly, while using residual networks for projection layers may improve performance for ID tasks it performs significantly worse for compositional reasoning tasks. CD diagrams for each architecture design component are included in Figs.~\ref{fig:cd_diagrams_baselines_apd} and~\ref{fig:cd_diagrams_apd} in Appendix~\ref{apd:cd_diagrams}. 

