
@article{wang_smartgpa:_2015,
	title = {{SmartGPA}: {How} smartphones can assess and predict academic performance of college students},
	issn = {2375-0529},
	doi = {10.1145/2750858.2804251},
	abstract = {Many cognitive, behavioral, and environmental factors im- pact student learning during college. The SmartGPA study uses passive sensing data and self-reports from students’ smartphones to understand individual behavioral differences between high and low performers during a single 10-week term. We propose new methods for better understanding study (e.g., study duration) and social (e.g., partying) behav- ior of a group of undergraduates. We show that there are a number of important behavioral factors automatically in- ferred from smartphones that significantly correlate with term and cumulative GPA, including time series analysis of ac- tivity, conversational interaction, mobility, class attendance, studying, and partying. We propose a simple model based on linear regression with lasso regularization that can accu- rately predict cumulative GPA. The predicted GPA strongly correlates with the ground truth from students’ transcripts (r = 0.81 and p {\textless} 0.001) and predicts GPA within ±0.179 of the reported grades. Our results open the way for novel interventions to improve academic performance.},
	number = {UbiComp},
	journal = {Proceedings of the ACM International Joint Conference on Pervasive and Ubiquitous Computing},
	author = {Wang, Rui and Harari, Gabriella and Hao, Peilin and Zhou, Xia and Campbell, Andrew T},
	year = {2015},
	pages = {1--13},
	file = {Wang et al_2015_SmartGPA.pdf:/Users/orsonxu/Zotero/storage/P2A98M8G/Wang et al_2015_SmartGPA.pdf:application/pdf;Wang et al_2015_SmartGPA.pdf:/Users/orsonxu/Zotero/storage/M5YR7D4B/Wang et al_2015_SmartGPA.pdf:application/pdf},
}

@article{arora_survey_2018,
	title = {A {Survey} of {Inverse} {Reinforcement} {Learning}: {Challenges}, {Methods} and {Progress}},
	url = {http://arxiv.org/abs/1806.06877},
	abstract = {Inverse reinforcement learning is the problem of inferring the reward function of an observed agent, given its policy or behavior. Researchers perceive IRL both as a problem and as a class of methods. By categorically surveying the current literature in IRL, this article serves as a reference for researchers and practitioners in machine learning to understand the challenges of IRL and select the approaches best suited for the problem on hand. The survey formally introduces the IRL problem along with its central challenges which include accurate inference, generalizability, correctness of prior knowledge, and growth in solution complexity with problem size. The article elaborates how the current methods mitigate these challenges. We further discuss the extensions of traditional IRL methods: (i) inaccurate and incomplete perception, (ii) incomplete model, (iii) multiple rewards, and (iv) non-linear reward functions. This discussion concludes with some broad advances in the research area and currently open research questions.},
	author = {Arora, Saurabh and Doshi, Prashant},
	year = {2018},
	keywords = {cs, edu, email addresses, function, generalization, imitation learning, inverse reinforcement learning, learning from demonstration, pdoshi, prashant, reinforcement learning, reward, sa08751, saurabh arora, uga},
	file = {Arora_Doshi_2018_A Survey of Inverse Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/7BHCWL4Z/Arora_Doshi_2018_A Survey of Inverse Reinforcement Learning.pdf:application/pdf;Arora_Doshi_2018_A Survey of Inverse Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/QGYC2WMG/Arora_Doshi_2018_A Survey of Inverse Reinforcement Learning.pdf:application/pdf},
}

@article{yao_deepsense:_2016,
	title = {{DeepSense}: {A} {Unified} {Deep} {Learning} {Framework} for {Time}-{Series} {Mobile} {Sensing} {Data} {Processing}},
	url = {http://arxiv.org/abs/1611.01942},
	doi = {10.1145/3038912.3052577},
	abstract = {Mobile sensing applications usually require time-series inputs from sensors. Some applications, such as tracking, can use sensed acceleration and rate of rotation to calculate displacement based on physical system models. Other applications, such as activity recognition, extract manually designed features from sensor inputs for classification. Such applications face two challenges. On one hand, on-device sensor measurements are noisy. For many mobile applications, it is hard to find a distribution that exactly describes the noise in practice. Unfortunately, calculating target quantities based on physical system and noise models is only as accurate as the noise assumptions. Similarly, in classification applications, although manually designed features have proven to be effective, it is not always straightforward to find the most robust features to accommodate diverse sensor noise patterns and user behaviors. To this end, we propose DeepSense, a deep learning framework that directly addresses the aforementioned noise and feature customization challenges in a unified manner. DeepSense integrates convolutional and recurrent neural networks to exploit local interactions among similar mobile sensors, merge local interactions of different sensory modalities into global interactions, and extract temporal relationships to model signal dynamics. DeepSense thus provides a general signal estimation and classification framework that accommodates a wide range of applications. We demonstrate the effectiveness of DeepSense using three representative and challenging tasks: car tracking with motion sensors, heterogeneous human activity recognition, and user identification with biometric motion analysis. DeepSense significantly outperforms the state-of-the-art methods for all three tasks. In addition, DeepSense is feasible to implement on smartphones due to its moderate energy consumption and low latency},
	author = {Yao, Shuochao and Hu, Shaohan and Zhao, Yiran and Zhang, Aston and Abdelzaher, Tarek},
	year = {2016},
	file = {Yao et al_2016_DeepSense.pdf:/Users/orsonxu/Zotero/storage/CV7BSGTR/Yao et al_2016_DeepSense.pdf:application/pdf;Yao et al_2016_DeepSense.pdf:/Users/orsonxu/Zotero/storage/FX85HNLA/Yao et al_2016_DeepSense.pdf:application/pdf},
}

@article{yao_sensegan_2018,
	title = {{SenseGAN} : {Enabling} {Deep} {Learning} for {Internet} of {Things} with a {Semi}-{Supervised} {Framework}},
	volume = {2},
	number = {3},
	author = {Yao, Shuochao and Zhao, Yiran and Shao, Huajie and Zhang, Chao and Zhang, Aston and Hu, Shaohan and Liu, Dongxin and Liu, Shengzhong and Su, L U and Abdelzaher, Tarek},
	year = {2018},
	file = {Yao et al_2018_SenseGAN.pdf:/Users/orsonxu/Zotero/storage/UTXYCY4S/Yao et al_2018_SenseGAN.pdf:application/pdf;Yao et al_2018_SenseGAN.pdf:/Users/orsonxu/Zotero/storage/L9FXJEKS/Yao et al_2018_SenseGAN.pdf:application/pdf},
}

@article{banovic_warming_2018,
	title = {Warming {Up} to {Cold} {Start} {Personalization}},
	volume = {1},
	issn = {24749567},
	url = {http://dl.acm.org/citation.cfm?doid=3178157.3161175},
	doi = {10.1145/3161175},
	abstract = {Smart agents face abandonment if they are unable to provide value to the users from the very first interaction. Existing smart agents take time to learn about new users before they can offer them personalized services. We present a method for learning personalization information about users quickly and without placing unnecessary hardship on them. Our method enables smart agents to pick which questions to ask the user when they first interact to maximize the agent's overall knowledge about the user. We demonstrate our method on two publically available US census datasets containing 172 user variables from 1,799,394 training and 1,618,489 testing users. The questions selected using our method improve the agent's accuracy when inferring information about future users, including information that they did not ask about. Our work enables smart agents that assist the user with personalized services soon after they start interacting.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Banovic, Nikola and Krumm, John},
	year = {2018},
	keywords = {wearable, acm reference format, personalization, 2017, cold start, krumm, mob, nikola banovic and john, pacm interact, start personalization, submodularity, warming up to cold},
	pages = {1--13},
	file = {Banovic_Krumm_2018_Warming Up to Cold Start Personalization.pdf:/Users/orsonxu/Zotero/storage/C82GR9FF/Banovic_Krumm_2018_Warming Up to Cold Start Personalization.pdf:application/pdf;Banovic_Krumm_2018_Warming Up to Cold Start Personalization.pdf:/Users/orsonxu/Zotero/storage/VKALQQ2Y/Banovic_Krumm_2018_Warming Up to Cold Start Personalization.pdf:application/pdf},
}

@article{wang_sensing_2018,
	title = {Sensing {Behavioral} {Change} over {Time} : {Using} {Within}-{Person} {Variability} {Features} from {Mobile} {Sensing} to {Predict} {Personality} {Traits}},
	volume = {2},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Wang, Weichen and HARARI, GABRIELLA M. and Wang, Rui and Muller, Sandrine R. and Mirjafari, Shayan and Masaba, Kizito and Campbell, Andrew T.},
	year = {2018},
	keywords = {Mobile Sensing, Personality Traits, Within-Person Variability},
	file = {Wang et al_2018_Sensing Behavioral Change over Time.pdf:/Users/orsonxu/Zotero/storage/T9IFMHCT/Wang et al_2018_Sensing Behavioral Change over Time.pdf:application/pdf;Wang et al_2018_Sensing Behavioral Change over Time.pdf:/Users/orsonxu/Zotero/storage/36ZXWZWQ/Wang et al_2018_Sensing Behavioral Change over Time.pdf:application/pdf},
}

@article{rizoiu_tutorial_2017,
	title = {A {Tutorial} on {Hawkes} {Processes} for {Events} in {Social} {Media}},
	url = {http://arxiv.org/abs/1708.06401},
	doi = {10.1145/3122865.3122874},
	abstract = {This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and the key concepts in point processes. We then introduce the Hawkes process, its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data - we show how to model retweet cascades using a Hawkes self-exciting process. We presents a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available as an online appendix},
	author = {Rizoiu, Marian-Andrei and Lee, Young and Mishra, Swapnil and Xie, Lexing},
	year = {2017},
	pages = {1--26},
	file = {Rizoiu et al_2017_A Tutorial on Hawkes Processes for Events in Social Media.pdf:/Users/orsonxu/Zotero/storage/WG38PF7G/Rizoiu et al_2017_A Tutorial on Hawkes Processes for Events in Social Media.pdf:application/pdf;Rizoiu et al_2017_A Tutorial on Hawkes Processes for Events in Social Media.pdf:/Users/orsonxu/Zotero/storage/YK2WYC9L/Rizoiu et al_2017_A Tutorial on Hawkes Processes for Events in Social Media.pdf:application/pdf},
}

@article{lester_hybrid_2005,
	title = {A hybrid discriminative/generative approach for modeling human activities},
	issn = {10450823},
	doi = {10.1.1.77.5776},
	abstract = {Accurate recognition and tracking of human activities is an important goal of ubiquitous computing. Recent advances in the development of multi-modal wearable sensors enable us to gather rich datasets of human activities. However, the problem of automatically identifying the most useful features for modeling such activities remains largely unsolved. In this paper we present a hybrid approach to recognizing activities, which combines boosting to discriminatively select useful features and learn an ensemble of static classifiers to recognize different activities, with hidden Markov models (HMMs) to capture the temporal regularities and smoothness of activities. We tested the activity recognition system using over 12 hours of wearable-sensor data collected by volunteers in natural unconstrained environments. The models succeeded in identifying a small set of maximally informative features, and were able identify ten different human activities with an accuracy of 95\%.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Lester, Jonathan and Choudhury, Tanzeem and Kern, Nicky and Borriello, Gaetano and Hannaford, Blake},
	year = {2005},
	pages = {766--772},
	file = {Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:/Users/orsonxu/Zotero/storage/JVT6NW2F/Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:application/pdf;Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:/Users/orsonxu/Zotero/storage/NJLESDTP/Lester et al_2005_A hybrid discriminative-generative approach for modeling human activities.pdf:application/pdf},
}

@article{ng_classification_2001,
	title = {Classification with {Hybrid} {Generative} / {Discriminative} {Models}},
	issn = {13704621},
	doi = {10.1007/s11063-008-9088-7},
	abstract = {Although discriminatively trained classifiers are usually more accurate when labeled training data is abundant, previous work has shown that when training data is limited, generative classifiers can out-perform them. This paper describes a hybrid model in which a high-dimensional subset of the parameters are trained to maximize generative likelihood, and another, small, subset of parameters are discriminatively trained to maximize conditional likelihood. We give a sample complexity bound showing that in order to fit the discriminative parameters well, the num- ber of training examples required depends only on the logarithm of the number of feature occurrences and feature set size. Experimental results show that hybrid models can provide lower test error and can produce better accuracy/coverage curves than either their purely generative or purely discriminative counterparts. We also discuss several advantages of hybrid models, and advocate further work in this area.},
	journal = {Proc of Neuro Information Processing Systems (NIPS)},
	author = {Ng, Andrew and Jordan, Michael},
	year = {2001},
	pages = {1--8},
	file = {Ng_Jordan_2001_Classification with Hybrid Generative - Discriminative Models.pdf:/Users/orsonxu/Zotero/storage/SHREJWV9/Ng_Jordan_2001_Classification with Hybrid Generative - Discriminative Models.pdf:application/pdf;Ng_Jordan_2001_Classification with Hybrid Generative - Discriminative Models.pdf:/Users/orsonxu/Zotero/storage/UIGUTV5R/Ng_Jordan_2001_Classification with Hybrid Generative - Discriminative Models.pdf:application/pdf},
}

@article{javier_ordonez_activity_2013,
	title = {Activity recognition using hybrid generative/discriminative models on home environments using binary sensors},
	volume = {13},
	issn = {14248220},
	doi = {10.3390/s130505460},
	abstract = {Activities of daily living are good indicators of elderly health status, and activity recognition in smart environments is a well-known problem that has been previously addressed by several studies. In this paper, we describe the use of two powerful machine learning schemes, ANN (Artificial Neural Network) and SVM (Support Vector Machines), within the framework of HMM (Hidden Markov Model) in order to tackle the task of activity recognition in a home setting. The output scores of the discriminative models, after processing, are used as observation probabilities of the hybrid approach. We evaluate our approach by comparing these hybrid models with other classical activity recognition methods using five real datasets. We show how the hybrid models achieve significantly better recognition performance, with significance level p \&lt; 0:05, proving that the hybrid approach is better suited for the addressed domain.},
	number = {5},
	journal = {Sensors (Switzerland)},
	author = {Javier Ordóñez, Fco and de Toledo, Paula and Sanchis, Araceli},
	year = {2013},
	keywords = {Activity recognition, Hidden Markov model, Hybrid schemes, Wireless sensor networks},
	pages = {5460--5477},
	file = {Javier Ordóñez et al_2013_Activity recognition using hybrid generative-discriminative models on home environments using binary sensors.pdf:/Users/orsonxu/Zotero/storage/VA5H4QTB/Javier Ordóñez et al_2013_Activity recognition using hybrid generative-discriminative models on home environments using binary sensors.pdf:application/pdf;Javier Ordóñez et al_2013_Activity recognition using hybrid generative-discriminative models on home environments using binary sensors.pdf:/Users/orsonxu/Zotero/storage/D95P7NGI/Javier Ordóñez et al_2013_Activity recognition using hybrid generative-discriminative models on home environments using binary sensors.pdf:application/pdf},
}

@article{bosch_scene_2008,
	title = {Scene classification using a hybrid generative / discriminative approach},
	volume = {30},
	number = {4},
	author = {Bosch, Anna and Zisserman, Andrew and Munoz, Xavier},
	year = {2008},
	pages = {43--90},
	file = {Bosch et al_2008_Scene classification using a hybrid generative - discriminative approach.pdf:/Users/orsonxu/Zotero/storage/L47ARIJC/Bosch et al_2008_Scene classification using a hybrid generative - discriminative approach.pdf:application/pdf;Bosch et al_2008_Scene classification using a hybrid generative - discriminative approach.pdf:/Users/orsonxu/Zotero/storage/6STYEDQH/Bosch et al_2008_Scene classification using a hybrid generative - discriminative approach.pdf:application/pdf},
}

@article{fujino_hybrid_2005,
	title = {A hybrid generative/discriminative approach to semi-supervised classifier design},
	issn = {1346-0714},
	doi = {10.1527/tjsai.21.301},
	journal = {Proceedings of the National Conference on …},
	author = {Fujino, Akinori and Ueda, Naonori and Saito, Kazumi},
	year = {2005},
	pages = {764--769},
	file = {Fujino et al_2005_A hybrid generative-discriminative approach to semi-supervised classifier design.pdf:/Users/orsonxu/Zotero/storage/IHCMVFDU/Fujino et al_2005_A hybrid generative-discriminative approach to semi-supervised classifier design.pdf:application/pdf;Fujino et al_2005_A hybrid generative-discriminative approach to semi-supervised classifier design.pdf:/Users/orsonxu/Zotero/storage/8TJFBFAK/Fujino et al_2005_A hybrid generative-discriminative approach to semi-supervised classifier design.pdf:application/pdf},
}

@article{namaki_discovering_2017,
	title = {Discovering {Graph} {Temporal} {Association} {Rules}},
	url = {http://dl.acm.org/citation.cfm?doid=3132847.3133014},
	doi = {10.1145/3132847.3133014},
	abstract = {See, stats, and : https : / / www . researchgate . net / publication / 320884739 Discovering Conference DOI : 10 . 1145 / 3132847 . 3133014 CITATION 1 READS 10 5 , including : Some : Knowledge Expressmind Mohammad Washington 6 SEE Song Beihang (BUAA) 4 SEE Tingjian University 44 SEE All . The . ABSTRACT Detecting regularities between complex events in temporal graphs is critical for emerging applications . This paper proposes graph temporal association rules (GTAR) . A GTAR extends traditional association rules to discover temporal associations for complex events captured by a class of temporal pattern queries . We intro - duce notions of support and conndence for GTARs , and formalize the discovery problem for GTARs . We show that despite the en - hanced expressive power , GTARs discovery is feasible over large temporal graphs . We develop an eeective rule discovery algorithm , which integrates event mining and rule discovery as a single pro - cess , and reduces the redundant computation by leveraging their interaction . Using real - life and synthetic data , we experimentally verify the eeectiveness and scalability of the algorithms . Our case study also veriies that GTARs demonstrate highly interpretable associations in real - world networks .},
	journal = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management  - CIKM '17},
	author = {Namaki, Mohammad Hossein and Wu, Yinghui and Song, Qi and Lin, Peng and Ge, Tingjian},
	year = {2017},
	pages = {1697--1706},
	file = {Namaki et al_2017_Discovering Graph Temporal Association Rules.pdf:/Users/orsonxu/Zotero/storage/BNSGJ3JH/Namaki et al_2017_Discovering Graph Temporal Association Rules.pdf:application/pdf;Namaki et al_2017_Discovering Graph Temporal Association Rules.pdf:/Users/orsonxu/Zotero/storage/MKW9CTL7/Namaki et al_2017_Discovering Graph Temporal Association Rules.pdf:application/pdf},
}

@article{casarrubea_t-pattern_2015,
	title = {T-pattern analysis for the study of temporal structure of animal and human behavior: {A} comprehensive review},
	volume = {239},
	issn = {1872678X},
	url = {http://dx.doi.org/10.1016/j.jneumeth.2014.09.024},
	doi = {10.1016/j.jneumeth.2014.09.024},
	abstract = {A basic tenet in the realm of modern behavioral sciences is that behavior consists of patterns in time. For this reason, investigations of behavior deal with sequences that are not easily perceivable by the unaided observer. This problem calls for improved means of detection, data handling and analysis. This review focuses on the analysis of the temporal structure of behavior carried out by means of a multivariate approach known as T-pattern analysis. Using this technique, recurring sequences of behavioral events, usually hard to detect, can be unveiled and carefully described. T-pattern analysis has been successfully applied in the study of various aspects of human or animal behavior such as behavioral modifications in neuro-psychiatric diseases, route-tracing stereotypy in mice, interaction between human subjects and animal or artificial agents, hormonal-behavioral interactions, patterns of behavior associated with emesis and, in our laboratories, exploration and anxiety-related behaviors in rodents. After describing the theory and concepts of T-pattern analysis, this review will focus on the application of the analysis to the study of the temporal characteristics of behavior in different species from rodents to human beings. This work could represent a useful background for researchers who intend to employ such a refined multivariate approach to the study of behavior.},
	journal = {Journal of Neuroscience Methods},
	author = {Casarrubea, M. and Jonsson, G. K. and Faulisi, F. and Sorbera, F. and Di Giovanni, G. and Benigno, A. and Crescimanno, G. and Magnusson, M. S.},
	year = {2015},
	keywords = {Behavioral disorder, Behavioral sequences, Multivariate analysis, Social interaction, T-pattern analysis},
	pages = {34--46},
	file = {Casarrubea et al_2015_T-pattern analysis for the study of temporal structure of animal and human behavior.pdf:/Users/orsonxu/Zotero/storage/LGFB8XJP/Casarrubea et al_2015_T-pattern analysis for the study of temporal structure of animal and human behavior.pdf:application/pdf;Casarrubea et al_2015_T-pattern analysis for the study of temporal structure of animal and human behavior.pdf:/Users/orsonxu/Zotero/storage/S2D6Z9P7/Casarrubea et al_2015_T-pattern analysis for the study of temporal structure of animal and human behavior.pdf:application/pdf},
}

@article{magnusson_discovering_2000,
	title = {Discovering hidden time patterns in behavior: {T}-patterns and their detection},
	volume = {118},
	issn = {21698996},
	doi = {10.1002/jgrd.503382013},
	abstract = {This article deals with the definition and detection of particular kinds of temporal patterns in behavior , which are sometimes obvious or well known, but other times difficult to detect, either directly or with standard statistical methods. Characteristics of well-known behavior patterns were abstracted and combined in order to define a scale-independent, hierarchical time pattern type, called aT-pattern. A corresponding detection algorithm was developed and implemented in a computer program, called Theme. The proposed pattern typology and detection algorithm are based on the definition and detection of a particular relationship between pairs of events in a time series, called a critical interval relation. The proposed bottom-up, level-by-level (or breadth-first) search algorithm is based on a binary tree of such relations. The algorithm first detects simpler patterns. Then, more complex and complete patterns evolve through the connection of simpler ones, pattern completeness competition, and pattern selection. lnterindividual T-patterns in a quarter-hour interaction between two children are presented , showing that complex hidden T-patterns may be found by Theme in such behavioral streams. Finally, implications for studies of complexity, self-organization, and dynamic patterns are discussed.},
	number = {9},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {MAGNUSSON, MAGNUS S.},
	year = {2000},
	pages = {3848--3868},
	file = {MAGNUSSON_2000_Discovering hidden time patterns in behavior.pdf:/Users/orsonxu/Zotero/storage/BECP58GG/MAGNUSSON_2000_Discovering hidden time patterns in behavior.pdf:application/pdf;MAGNUSSON_2000_Discovering hidden time patterns in behavior.pdf:/Users/orsonxu/Zotero/storage/BLVZ5F24/MAGNUSSON_2000_Discovering hidden time patterns in behavior.pdf:application/pdf},
}

@article{farrahi_extracting_2012,
	title = {Extracting mobile behavioral patterns with the distant {N}-gram topic model},
	issn = {15504816},
	doi = {10.1109/ISWC.2012.20},
	abstract = {Mining patterns of human behavior from large-scale mobile phone data has potential to understand certain phenomena in society. The study of such human-centric massive datasets requires new mathematical models. In this paper, we propose a probabilistic topic model that we call the distant n-gram topic model (DNTM) to address the problem of learning long duration human location sequences. The DNTM is based on Latent Dirichlet Allocation (LDA). We define the generative process for the model, derive the inference procedure and evaluate our model on real mobile data. We consider two different real-life human datasets, collected by mobile phone locations, the first considering GPS locations and the second considering cell tower connections. The DNTM successfully discovers topics on the two datasets. Finally, the DNTM is compared to LDA by considering log-likelihood performance on unseen data, showing the predictive power of the model on unseen data. We find that the DNTM consistantly outperforms LDA as the sequence length increases. © 2012 IEEE.},
	journal = {Proceedings - International Symposium on Wearable Computers, ISWC},
	author = {Farrahi, Katayoun and Gatica-Perez, Daniel},
	year = {2012},
	pages = {1--8},
	file = {Farrahi_Gatica-Perez_2012_Extracting mobile behavioral patterns with the distant N-gram topic model.pdf:/Users/orsonxu/Zotero/storage/24KZTUP2/Farrahi_Gatica-Perez_2012_Extracting mobile behavioral patterns with the distant N-gram topic model.pdf:application/pdf;Farrahi_Gatica-Perez_2012_Extracting mobile behavioral patterns with the distant N-gram topic model.pdf:/Users/orsonxu/Zotero/storage/IMDF24BD/Farrahi_Gatica-Perez_2012_Extracting mobile behavioral patterns with the distant N-gram topic model.pdf:application/pdf},
}

@article{kam_discovering_2000,
	title = {Discovering {Temporal} {Patterns} for {Interval}-based {Events}},
	issn = {18734235},
	url = {http://link.springer.com/chapter/10.1007%2F3-540-44466-1_32},
	doi = {10.1016/j.bios.2010.11.002},
	abstract = {This paper, we consider interval-based events where the duration of events is expressed in terms of endpoint values, and these are used to form temporal constraint in the discovery process. We introduce the notion of temporal representation which is capable of expressing the relationships between interval-based events. We develop new methods for finding such interesting patterns.},
	journal = {In: Proceedings of Second International Conference on Data Warehousing and Knowledge Discovery},
	author = {Kam, Po-shan and Fu, Ada Wai-chee},
	year = {2000},
	pages = {317--326},
	file = {Kam_Fu_2000_Discovering Temporal Patterns for Interval-based Events.pdf:/Users/orsonxu/Zotero/storage/KNTRPYGF/Kam_Fu_2000_Discovering Temporal Patterns for Interval-based Events.pdf:application/pdf;Kam_Fu_2000_Discovering Temporal Patterns for Interval-based Events.pdf:/Users/orsonxu/Zotero/storage/8SVZTZVV/Kam_Fu_2000_Discovering Temporal Patterns for Interval-based Events.pdf:application/pdf},
}

@article{ale_approach_2000,
	title = {An approach to discovering temporal association rules},
	url = {http://dl.acm.org/citation.cfm?id=335770%0Ahttp://portal.acm.org/citation.cfm?doid=335603.335770},
	doi = {10.1145/335603.335770},
	abstract = {The goal of discovering association rules is to discover all possible associations that accomplish certain restrictions (minimum support and confidence and interesting). However, it is possible to find interesting associations with a high confidence level but with little support. This problem is caused by the way support is calculated, as the denominator represents the total number of transactions in a time period when the involved items may have not existed. If, on the other hand, we limit the total transactions to the ones belonging to the items’ lifetime, those associations would be now discovered, as they would count on enough support. Another difficulty is the large number of rules that could be generated, for which many solutions have been proposed. Using age as an obsolescence factor for rules helps reduce the number of rules to be presented to the user. In this paper we expand the notion of association rules incorporating time to the frequent itemsets discovered. The concept of temporal support is introduced and, as an example, the known algorithm A priori is modified to incorporate the temporal notions.{\textbackslash}r{\textbackslash}n},
	number = {c},
	journal = {Proceedings of the 2000 ACM symposium on Applied computing - SAC '00},
	author = {Ale, Juan M. and Rossi, Gustavo H.},
	year = {2000},
	keywords = {association rules, data mining, temporal data mining},
	pages = {294--300},
	file = {Ale_Rossi_2000_An approach to discovering temporal association rules.pdf:/Users/orsonxu/Zotero/storage/5GXREWGI/Ale_Rossi_2000_An approach to discovering temporal association rules.pdf:application/pdf;Ale_Rossi_2000_An approach to discovering temporal association rules.pdf:/Users/orsonxu/Zotero/storage/TR8PAH5R/Ale_Rossi_2000_An approach to discovering temporal association rules.pdf:application/pdf},
}

@article{ozden_cyclic_1998,
	title = {Cyclic association rules},
	doi = {10.1109/ICDE.1998.655804},
	abstract = {We study the problem of discovering association rules that display regular cyclic variation over time. For example, if we compute association rules over monthly sales data, we may observe seasonal variation where certain rules are true at approximately the same month each year. Similarly, association rules can also display regular hourly, daily, weekly, etc., variation that is cyclical in nature. We demonstrate that existing methods cannot be naively extended to solve this problem of cyclic association rules. We then present two new algorithms for discovering such rules. The first one, which we call the sequential algorithm, treats association rules and cycles more or less independently. By studying the interaction between association rules and time, we devise a new technique called cycle pruning, which reduces the amount of time needed to find cyclic association rules. The second algorithm, which we call the interleaved algorithm, uses cycle pruning and other optimization techniques for discovering cyclic association rules. We demonstrate the effectiveness of the interleaved algorithm through a series of experiments. These experiments show that the interleaved algorithm can yield significant performance benefits when compared to the sequential algorithm. Performance improvements range from 5\% to several hundred percent},
	number = {March},
	journal = {Proc. of ICDE'98},
	author = {Ozden, B. and Ramaswamy, S. and Silberschatz, A.},
	year = {1998},
	pages = {412--421},
	file = {Ozden et al_1998_Cyclic association rules.pdf:/Users/orsonxu/Zotero/storage/HEXHJJEI/Ozden et al_1998_Cyclic association rules.pdf:application/pdf},
}

@article{radhakrishna_survey_2015,
	title = {A {Survey} on {Temporal} {Databases} and {Data} mining},
	author = {Radhakrishna, Vangipuram and Kumar, P V and Janaki, V},
	year = {2015},
	keywords = {conventional database, outliers, temporal database},
	file = {Radhakrishna et al_2015_A Survey on Temporal Databases and Data mining.pdf:/Users/orsonxu/Zotero/storage/DZLL2CZ5/Radhakrishna et al_2015_A Survey on Temporal Databases and Data mining.pdf:application/pdf;Radhakrishna et al_2015_A Survey on Temporal Databases and Data mining.pdf:/Users/orsonxu/Zotero/storage/78TCCT9U/Radhakrishna et al_2015_A Survey on Temporal Databases and Data mining.pdf:application/pdf},
}

@article{yoo_similarity-profiled_2009,
	title = {Similarity-{Profiled} {Temporal} {Association} {Mining}},
	volume = {21},
	url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624259},
	number = {8},
	author = {Yoo, Jin Soung and Shekhar, Shashi},
	year = {2009},
	pages = {1147--1161},
	file = {Yoo_Shekhar_2009_Similarity-Profiled Temporal Association Mining.pdf:/Users/orsonxu/Zotero/storage/CD3Z5I3W/Yoo_Shekhar_2009_Similarity-Profiled Temporal Association Mining.pdf:application/pdf;Yoo_Shekhar_2009_Similarity-Profiled Temporal Association Mining.pdf:/Users/orsonxu/Zotero/storage/X5TDW9DI/Yoo_Shekhar_2009_Similarity-Profiled Temporal Association Mining.pdf:application/pdf},
}

@article{chen_tutorial_2018,
	title = {A {Tutorial} on {Network} {Embeddings}},
	url = {http://arxiv.org/abs/1808.02590},
	doi = {arXiv:1808.02590v1},
	abstract = {Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. These representations can be used as features for a wide range of tasks on graphs such as classification, clustering, link prediction, and visualization. In this survey, we give an overview of network embeddings by summarizing and categorizing recent advancements in this research field. We first discuss the desirable properties of network embeddings and briefly introduce the history of network embedding algorithms. Then, we discuss network embedding methods under different scenarios, such as supervised versus unsupervised learning, learning embeddings for homogeneous networks versus for heterogeneous networks, etc. We further demonstrate the applications of network embeddings, and conclude the survey with future work in this area.},
	author = {Chen, Haochen and Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
	year = {2018},
	pages = {1--23},
	file = {Chen et al_2018_A Tutorial on Network Embeddings.pdf:/Users/orsonxu/Zotero/storage/8YCNZC6Y/Chen et al_2018_A Tutorial on Network Embeddings.pdf:application/pdf;Chen et al_2018_A Tutorial on Network Embeddings.pdf:/Users/orsonxu/Zotero/storage/7RNJWPWL/Chen et al_2018_A Tutorial on Network Embeddings.pdf:application/pdf},
}

@article{cui_survey_2018,
	title = {A {Survey} on {Network} {Embedding}},
	issn = {10414347},
	doi = {10.1109/TKDE.2018.2849727},
	abstract = {Network embedding assigns nodes in a network to low-dimensional representations and effectively preserves the network structure. Recently, a significant amount of progresses have been made toward this emerging network analysis paradigm. In this survey, we focus on categorizing and then reviewing the current development on network embedding methods, and point out its future research directions. We first summarize the motivation of network embedding. We discuss the classical graph embedding algorithms and their relationship with network embedding. Afterwards and primarily, we provide a comprehensive overview of a large number of network embedding methods in a systematic manner, covering the structure- and property-preserving network embedding methods, the network embedding methods with side information and the advanced information preserving network embedding methods. Moreover, several evaluation approaches for network embedding and some useful online resources, including the network data sets and softwares, are reviewed, too. Finally, we discuss the framework of exploiting these network embedding methods to build an effective system and point out some potential future directions.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Cui, Peng and Wang, Xiao and Pei, Jian and Zhu, Wenwu},
	year = {2018},
	keywords = {Computational complexity, data science, Distributed databases, graph embedding, Image reconstruction, Machine learning, network analysis, Network embedding, Network topology, Social network services, Task analysis},
	file = {Cui et al_2018_A Survey on Network Embedding.pdf:/Users/orsonxu/Zotero/storage/2REC8DTH/Cui et al_2018_A Survey on Network Embedding.pdf:application/pdf;Cui et al_2018_A Survey on Network Embedding.pdf:/Users/orsonxu/Zotero/storage/EJ4ZU8IF/Cui et al_2018_A Survey on Network Embedding.pdf:application/pdf},
}

@article{tang_line_2015,
	title = {{LINE} : {Large}-scale {Information} {Network} {Embedding}},
	issn = {9781450334693},
	doi = {10.1145/2736277.2741093},
	journal = {International World Wide Web Conference Committee (IW3C2)},
	author = {Tang, Jian and Qu, Meng},
	year = {2015},
	keywords = {dimension reduction, feature learn-, information network embedding, ing, scalability},
	pages = {1067--1077},
	file = {Tang_Qu_2015_LINE.pdf:/Users/orsonxu/Zotero/storage/B2EWHXBJ/Tang_Qu_2015_LINE.pdf:application/pdf;Tang_Qu_2015_LINE.pdf:/Users/orsonxu/Zotero/storage/VVIHVH4E/Tang_Qu_2015_LINE.pdf:application/pdf},
}

@article{perozzi_deepwalk:_2014,
	title = {{DeepWalk}: {Online} {Learning} of {Social} {Representations} {Bryan}},
	issn = {9781450329569},
	doi = {10.1145/2623330.2623732},
	journal = {KDD},
	author = {Perozzi, Bryan and Skiena, Steven},
	year = {2014},
	keywords = {deep learning, online learning, social networks, latent representations, learning with partial labels, network classification},
	pages = {701--710},
	file = {Perozzi_Skiena_2014_DeepWalk.pdf:/Users/orsonxu/Zotero/storage/598E3LX6/Perozzi_Skiena_2014_DeepWalk.pdf:application/pdf;Perozzi_Skiena_2014_DeepWalk.pdf:/Users/orsonxu/Zotero/storage/LDFJ54KB/Perozzi_Skiena_2014_DeepWalk.pdf:application/pdf},
}

@article{agrawal_fast_1994,
	title = {Fast {Algorithms} for {Mining} {Association} {Rules}},
	issn = {1000-9000},
	doi = {10.1007/BF02948845},
	abstract = {We consider the problem of discovering association rules between items in a large database of sales transactions. We present two new algorithms for solving this problem that are fundamentally di erent from the known algorithms. Experiments with synthetic as well as real-life data show that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. We also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called AprioriHybrid. Scale-up experiments show that AprioriHybrid scales linearly with the number of transactions. AprioriHybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.},
	journal = {Proceedings of the 20th VLDB Conference},
	author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
	year = {1994},
	pages = {487--499},
	file = {Agrawal_Srikant_1994_Fast Algorithms for Mining Association Rules.PDF:/Users/orsonxu/Zotero/storage/MQ9WMZG6/Agrawal_Srikant_1994_Fast Algorithms for Mining Association Rules.PDF:application/pdf},
}

@article{wang_mining_2018,
	title = {Mining temporal association rules with frequent itemsets tree},
	volume = {62},
	issn = {15684946},
	url = {https://doi.org/10.1016/j.asoc.2017.09.013},
	doi = {10.1016/j.asoc.2017.09.013},
	abstract = {A novel framework for mining temporal association rules by discovering itemsets with frequent itemsets tree is introduced. In order to solve the problem of handling time series by including temporal relation between the multi items into association rules, a frequent itemsets tree is constructed in parallel with mining frequent itemsets to improve the efficiency and interpretability of rule mining without generating candidate itemsets. Experimental results show that our algorithm can provide better efficiency and interpretability in mining temporal association rules in comparison with other algorithms and has good application prospects.},
	journal = {Applied Soft Computing Journal},
	author = {Wang, Ling and Meng, Jianyao and Xu, Peipei and Peng, Kaixiang},
	year = {2018},
	keywords = {Frequent itemsets tree, Interpretability, Temporal association rule, Temporal relationship},
	pages = {817--829},
	file = {Wang et al_2018_Mining temporal association rules with frequent itemsets tree.pdf:/Users/orsonxu/Zotero/storage/8NKYSS5Y/Wang et al_2018_Mining temporal association rules with frequent itemsets tree.pdf:application/pdf;Wang et al_2018_Mining temporal association rules with frequent itemsets tree.pdf:/Users/orsonxu/Zotero/storage/RWYM8ANP/Wang et al_2018_Mining temporal association rules with frequent itemsets tree.pdf:application/pdf},
}

@article{agrawal_mining_1995,
	title = {Mining sequential patterns},
	issn = {1532-0480},
	url = {http://ieeexplore.ieee.org/document/380415/},
	doi = {10.1109/ICDE.1995.380415},
	abstract = {We are given a large database of customer transactions, where each transaction consists of customer-id, transaction time, and the items bought in the transaction. We introduce the problem of mining sequential patterns over such databases. We present three algorithms to solve this problem, and empirically evaluate their performance using synthetic data. Two of the proposed algorithms, AprioriSome and AprioriAll, have comparable performance, albeit AprioriSome performs a little better when the minimum number of customers that must support a sequential pattern is low. Scale-up experiments show that both AprioriSome and AprioriAll scale linearly with the number of customer transactions. They also have excellent scale-up properties with respect to the number of transactions per customer and the number of items in a transaction},
	journal = {Proceedings of the Eleventh International Conference on Data Engineering},
	author = {Agrawal, R. and Srikant, R.},
	year = {1995},
	pages = {3--14},
	file = {Agrawal_Srikant_1995_Mining sequential patterns.pdf:/Users/orsonxu/Zotero/storage/AU3SU6EF/Agrawal_Srikant_1995_Mining sequential patterns.pdf:application/pdf},
}

@article{ramaswamy_discovery_1998,
	title = {On the discovery of interesting patterns in association rules},
	journal = {24th International conference on very large data bases},
	author = {Ramaswamy, Sridhar and Mahajan, Sameer and Silberschatz, Avi},
	year = {1998},
	pages = {368--379},
	file = {Ramaswamy et al_1998_On the discovery of interesting patterns in association rules.pdf:/Users/orsonxu/Zotero/storage/EMU7N59P/Ramaswamy et al_1998_On the discovery of interesting patterns in association rules.pdf:application/pdf},
}

@article{fournier-viger_cmrules:_2012,
	title = {{CMRules}: {Mining} {Sequential} {Rules}},
	volume = {25},
	author = {Fournier-viger, Philippe and Faghihi, Usef and Nkambou, Roger and Nguifo, Engelbert Mephu and Sciences, Computer},
	year = {2012},
	keywords = {association rule mining, sequence database, sequential rule mining, temporal rules},
	pages = {63--76},
	file = {Fournier-viger et al_2012_CMRules.pdf:/Users/orsonxu/Zotero/storage/VSN4KUV3/Fournier-viger et al_2012_CMRules.pdf:application/pdf;Fournier-viger et al_2012_CMRules.pdf:/Users/orsonxu/Zotero/storage/7677BP3N/Fournier-viger et al_2012_CMRules.pdf:application/pdf},
}

@article{morchen_unsupervised_2007,
	title = {Unsupervised pattern mining from symbolic temporal data},
	volume = {9},
	issn = {19310145},
	url = {http://portal.acm.org/citation.cfm?doid=1294301.1294302},
	doi = {10.1145/1294301.1294302},
	abstract = {Primary Classification: J. Computer Applications J.3 LIFE AND MEDICAL SCIENCES Subjects: Medical information systems Additional Classification: F. Theory of Computation F.2 ANALYSIS OF ALGORITHMS AND PROBLEM COMPLEXITY F.2.2 Nonnumerical Algorithms and Problems Subjects: Pattern matching H. Information Systems H.2 DATABASE MANAGEMENT H.2.8 Database applications Subjects: Data mining I. Computing Methodologies I.5 PATTERN RECOGNITION I.5.2 Design Methodology Subjects: Pattern analysis},
	number = {1},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Mörchen, Fabian},
	year = {2007},
	pages = {41--55},
	file = {Mörchen_2007_Unsupervised pattern mining from symbolic temporal data.pdf:/Users/orsonxu/Zotero/storage/5FQ4WGHK/Mörchen_2007_Unsupervised pattern mining from symbolic temporal data.pdf:application/pdf;Mörchen_2007_Unsupervised pattern mining from symbolic temporal data.pdf:/Users/orsonxu/Zotero/storage/57U5VKUY/Mörchen_2007_Unsupervised pattern mining from symbolic temporal data.pdf:application/pdf},
}

@article{kuok_mining_1998,
	title = {Mining fuzzy association rules in databases},
	volume = {27},
	issn = {01635808},
	url = {http://portal.acm.org/citation.cfm?doid=273244.273257},
	doi = {10.1145/273244.273257},
	abstract = {Data mining is the discovery of previously unknown, potentially useful and hidden knowledge in databases. In this paper, we concentrate on the discovery of association rules. Many algorithms have been proposed to find association rules in databases with binary attributes. We introduce the fuzzy association rules of the form, 'If X is A then Y is B', to deal with quantitative attributes. X, Y are set of attributes and A, B are fuzzy sets which describe X and Y respectively. Using the fuzzy set concept, the discovered rules are more understandable to human. Moreover, fuzzy sets handle numerical values better than existing methods because fuzzy sets soften the effect of sharp boundaries.},
	number = {1},
	journal = {ACM SIGMOD Record},
	author = {Kuok, Chan Man and Fu, Ada and Wong, Man Hon},
	year = {1998},
	pages = {41--46},
	file = {Kuok et al_1998_Mining fuzzy association rules in databases.pdf:/Users/orsonxu/Zotero/storage/JHD2PLBX/Kuok et al_1998_Mining fuzzy association rules in databases.pdf:application/pdf},
}

@article{pinto_multi-dimensional_2001,
	title = {Multi-dimensional {Sequential} {Pattern} {Mining}},
	journal = {Proceedings of the tenth international conference on Information and knowledge management - CIKM'01},
	author = {Pinto, Helen and Han, Jiawei and Pei, Jian and Wang, Ke and Chen, Qiming and Dayal, Umeshwar},
	year = {2001},
	file = {Pinto et al_2001_Multi-dimensional Sequential Pattern Mining.pdf:/Users/orsonxu/Zotero/storage/QL3BPRZB/Pinto et al_2001_Multi-dimensional Sequential Pattern Mining.pdf:application/pdf;Pinto et al_2001_Multi-dimensional Sequential Pattern Mining.pdf:/Users/orsonxu/Zotero/storage/NYRPGFHT/Pinto et al_2001_Multi-dimensional Sequential Pattern Mining.pdf:application/pdf},
}

@article{harms_sequential_2004,
	title = {Sequential {Association} {Rule} {Mining} with {Time} {Lags}},
	volume = {1621},
	issn = {16130073},
	doi = {10.1023/A},
	abstract = {New technologies for innovative interactive experience represent a powerful medium to deliver cultural heritage content to a wider range of users. Among them, Natural User Interfaces (NUI), i.e. non-intrusive technologies not requiring to the user to wear devices nor use external hardware (e.g. keys or trackballs), are considered a promising way to broader the audience of specific cultural heritage domains, like the navigation/interaction with digital artworks presented on wall-sized displays. Starting from a collaboration with a worldwide famous Italian designer, we defined a NUI to explore 360 panoramic artworks presented on wall-sized displays, like virtual reconstruction of ancient cultural sites, or rendering of imaginary places. Specifically, we let the user to "move the head" as way of natural interaction to explore and navigate through these large digital artworks. To this aim, we developed a system including a remote head pose estimator to catch movements of users standing in front of the wall-sized display: starting from a central comfort zone, as users move their head in any direction, the virtual camera rotates accordingly. With NUIs, it is difficult to get feedbacks from the users about the interest for the point of the artwork he/she is looking at. To solve this issue, we complemented the gaze estimator with a preliminary emotional analysis solution, able to implicitly infer the interest of the user for the shown content from his/her pupil size. A sample of 150 subjects was invited to experience the proposed interface at an International Design Week. Preliminary results show that the most of the subjects were able to properly interact with the system from the very first use, and that the emotional module is an interesting solution, even if further work must be devoted to address specific situations. © 2016 for this paper by its authors. Copying permitted for private and academic purposes.},
	number = {January 2004},
	journal = {Journal of Intelligent Information Systems},
	author = {Harms, SK and Deogun, JS},
	year = {2004},
	pages = {36--43},
	file = {Harms_Deogun_2004_Sequential Association Rule Mining with Time Lags.pdf:/Users/orsonxu/Zotero/storage/6UHWGAG6/Harms_Deogun_2004_Sequential Association Rule Mining with Time Lags.pdf:application/pdf;Harms_Deogun_2004_Sequential Association Rule Mining with Time Lags.pdf:/Users/orsonxu/Zotero/storage/SUAYE768/Harms_Deogun_2004_Sequential Association Rule Mining with Time Lags.pdf:application/pdf},
}

@article{kotsiantis_association_2006,
	title = {Association {Rules} {Mining}: {A} {Recent} {Overview}},
	volume = {32},
	issn = {09594752},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0959475217303985},
	doi = {10.1016/j.learninstruc.2017.11.004},
	abstract = {A B S T R A C T This study investigates when and how students activate co-and socially shared emotion and motivation reg-ulation in collaborative learning and whether the S-REG mobile application tool can support this regulation. In a mathematics course, 44 higher education students worked with a collaborative assignment. The S-REG tool traced groups' emotional and motivational states in different sessions, and the occurrence of co-regulation and shared regulation of motivation and emotions were coded from video-recorded collaborative work (44 h). The groups activated more co-regulation than shared regulation of emotions and motivation, but the shared-reg-ulation episodes were longer-lasting. The groups' emotional and motivational states were associated with the occurrence of co-regulation in the beginning of the learning sessions. The results suggest that the S-REG tool balanced collaboration by prompting the groups to regulate emotions and motivation right in the beginning of the motivationally and emotionally challenging learning sessions.},
	number = {1},
	journal = {International Transactions on Computer Science and Engineering},
	author = {Kotsiantis, Sotiris and Kanellopoulos, Dimitris},
	year = {2006},
	pages = {71--82},
	file = {Kotsiantis_Kanellopoulos_2006_Association Rules Mining.pdf:/Users/orsonxu/Zotero/storage/3BJT9SD5/Kotsiantis_Kanellopoulos_2006_Association Rules Mining.pdf:application/pdf;Kotsiantis_Kanellopoulos_2006_Association Rules Mining.pdf:/Users/orsonxu/Zotero/storage/DKBMP6TB/Kotsiantis_Kanellopoulos_2006_Association Rules Mining.pdf:application/pdf},
}

@article{yu_mining_2005,
	title = {Mining {Sequential} {Patterns} from {Multidimensional} {Sequence} {Data}},
	volume = {17},
	number = {1},
	author = {Yu, Chung-ching and Chen, Yen-liang},
	year = {2005},
	pages = {136--140},
	file = {Yu_Chen_2005_Mining Sequential Patterns from Multidimensional Sequence Data.pdf:/Users/orsonxu/Zotero/storage/IZ5L4AEM/Yu_Chen_2005_Mining Sequential Patterns from Multidimensional Sequence Data.pdf:application/pdf;Yu_Chen_2005_Mining Sequential Patterns from Multidimensional Sequence Data.pdf:/Users/orsonxu/Zotero/storage/K3L2NJRP/Yu_Chen_2005_Mining Sequential Patterns from Multidimensional Sequence Data.pdf:application/pdf},
}

@article{last_knowledge_2001,
	title = {Knowledge {Discovery} in {Time} {Series} {Databases}},
	volume = {31},
	number = {1},
	author = {Last, Mark and Klein, Yaron and Kandel, Abraham},
	year = {2001},
	pages = {160--169},
	file = {Last et al_2001_Knowledge Discovery in Time Series Databases.pdf:/Users/orsonxu/Zotero/storage/LA93YMRA/Last et al_2001_Knowledge Discovery in Time Series Databases.pdf:application/pdf;Last et al_2001_Knowledge Discovery in Time Series Databases.pdf:/Users/orsonxu/Zotero/storage/59526PHB/Last et al_2001_Knowledge Discovery in Time Series Databases.pdf:application/pdf},
}

@article{fu_review_2011,
	title = {A review on time series data mining},
	volume = {24},
	issn = {09521976},
	url = {http://dx.doi.org/10.1016/j.engappai.2010.09.007},
	doi = {10.1016/j.engappai.2010.09.007},
	abstract = {Time series is an important class of temporal data objects and it can be easily obtained from scientific and financial applications. A time series is a collection of observations made chronologically. The nature of time series data includes: large in data size, high dimensionality and necessary to update continuously. Moreover time series data, which is characterized by its numerical and continuous nature, is always considered as a whole instead of individual numerical field. The increasing use of time series data has initiated a great deal of research and development attempts in the field of data mining. The abundant research on time series data mining in the last decade could hamper the entry of interested researchers, due to its complexity. In this paper, a comprehensive revision on the existing time series data mining research is given. They are generally categorized into representation and indexing, similarity measure, segmentation, visualization and mining. Moreover state-of-the-art research issues are also highlighted. The primary objective of this paper is to serve as a glossary for interested researchers to have an overall picture on the current time series data mining development and identify their potential research direction to further investigation. © 2010 Elsevier Ltd. All rights reserved.},
	number = {1},
	journal = {Engineering Applications of Artificial Intelligence},
	author = {Fu, Tak Chung},
	year = {2011},
	keywords = {Visualization, Representation, Segmentation, Similarity measure, Time series data mining},
	pages = {164--181},
	file = {Fu_2011_A review on time series data mining.pdf:/Users/orsonxu/Zotero/storage/BCXN973R/Fu_2011_A review on time series data mining.pdf:application/pdf;Fu_2011_A review on time series data mining.pdf:/Users/orsonxu/Zotero/storage/4V9Y7JYZ/Fu_2011_A review on time series data mining.pdf:application/pdf},
}

@article{casas-garriga_summarizing_2005,
	title = {Summarizing {Sequential} {Data} with {Closed} {Partial} {Orders}},
	doi = {10.1137/1.9781611972757.34},
	abstract = {In this paper we address the task of summarizing a set of input sequences by means of local ordering relationships on items occurring in the sequences. Our goal is not mining these structures directly from the data, but going beyond the idea of closed sequential patterns and generalize it into a novel notion of closed partial order. We will show that just a simple (but not trivial) post-processing of the closed sequences found in the data leads to a compact set of informative closed partial orders. We analyze our proposal not only algorithmically but also theoretically, by showing the connection with Galois lattices. Finally, we illustrate the approach by applying it to real data.},
	journal = {SIAM International Conference on Data Mining (SDM-05)},
	author = {Casas-Garriga, Gemma},
	year = {2005},
	pages = {380--391},
	file = {Casas-Garriga_2005_Summarizing Sequential Data with Closed Partial Orders.pdf:/Users/orsonxu/Zotero/storage/EN8ZV8RD/Casas-Garriga_2005_Summarizing Sequential Data with Closed Partial Orders.pdf:application/pdf;Casas-Garriga_2005_Summarizing Sequential Data with Closed Partial Orders.pdf:/Users/orsonxu/Zotero/storage/2CGUEPC7/Casas-Garriga_2005_Summarizing Sequential Data with Closed Partial Orders.pdf:application/pdf},
}

@article{fournier-viger_survey_2017,
	title = {A {Survey} of {Sequential} {Pattern} {Mining}},
	volume = {1},
	issn = {2520-4165},
	url = {http://arxiv.org/abs/1805.10515},
	doi = {10.1109/ICDM.2007.75},
	abstract = {With the growing popularity of resource sharing and shared resources, large volumes of complex data of different types are collected automatically. Traditional data mining algorithms generally have problems and challenges including huge memory cost, low processing speed, and inadequate hard disk space. For sequential pattern mining (SPM), it is used in a wide variety of real-life applications. However, it is more complex and challenging than frequent itemset mining, and also suffers from the above challenges when handling the large-scale data. To solve these problems, mining sequential patterns in a parallel computing environment has emerged as an important issue with many applications. In this paper, an in-depth survey of the current status of parallel sequential pattern mining (PSPM) is investigated and provided, including detailed categorization of traditional serial SPM approaches, and state of the art parallel SPM. We review the related work of PSPM in detail, including partition-based algorithms for PSPM, Apriori-based PSPM, pattern growth based PSPM, and hybrid algorithms for PSPM, and provide deep description (i.e., characteristics, advantages, and disadvantages) of each parallel approach of PSPM. Some advanced topics for PSPM and the related open-source software are further reviewed in details. Finally, we summarize some challenges and opportunities of PSPM in the big data era.},
	number = {1},
	author = {Fournier-Viger, Philippe and Lin, Jerry Chun-Wei and Kiran, Rage Uday and Koh, Yun Sing},
	year = {2017},
	keywords = {data mining, frequent pattern mining, itemset, mining, sequences, sequential pattern mining},
	pages = {54--77},
	file = {Fournier-Viger et al_2017_A Survey of Sequential Pattern Mining.pdf:/Users/orsonxu/Zotero/storage/PCBKRKI9/Fournier-Viger et al_2017_A Survey of Sequential Pattern Mining.pdf:application/pdf;Fournier-Viger et al_2017_A Survey of Sequential Pattern Mining.pdf:/Users/orsonxu/Zotero/storage/IFUY733E/Fournier-Viger et al_2017_A Survey of Sequential Pattern Mining.pdf:application/pdf},
}

@article{jian_pei_prefixspan:_2001,
	title = {{PrefixSpan},: mining sequential patterns efficiently by prefix-projected pattern growth},
	issn = {1063-6382},
	url = {http://ieeexplore.ieee.org/document/914830/},
	doi = {10.1109/ICDE.2001.914830},
	abstract = {Not Available},
	journal = {Proceedings 17th International Conference on Data Engineering},
	author = {{Jian Pei} and {Jiawei Han} and Mortazavi-Asl, B. and Pinto, H. and {Qiming Chen} and Dayal, U. and {Mei-Chun Hsu}},
	year = {2001},
	pages = {215--224},
	file = {Jian Pei et al_2001_PrefixSpan,.pdf:/Users/orsonxu/Zotero/storage/E355HTLH/Jian Pei et al_2001_PrefixSpan,.pdf:application/pdf;Jian Pei et al_2001_PrefixSpan,.pdf:/Users/orsonxu/Zotero/storage/5BB5BM43/Jian Pei et al_2001_PrefixSpan,.pdf:application/pdf},
}

@article{srikant_mining_1996,
	title = {Mining {Sequential} {Patterns}: {Generalizations} and {Performance} {Improvements}},
	volume = {136},
	number = {1},
	journal = {Journal of Experimental Psychology: General},
	author = {Srikant, Ramakrishnan and Agrawal, Rakesh},
	year = {1996},
	keywords = {depression, autobiographical memory, executive control, overgeneral memory, working},
	pages = {23--42},
	file = {Srikant_Agrawal_1996_Mining Sequential Patterns.pdf:/Users/orsonxu/Zotero/storage/KHFXXIUP/Srikant_Agrawal_1996_Mining Sequential Patterns.pdf:application/pdf},
}

@article{morchen_time_2006,
	title = {Time {Series} {Knowledge} {Mining} - {Fabian} {Morchen} {Dissertation}},
	doi = {10.1145/1150402.1150485},
	abstract = {An important goal of knowledge discovery is the search for patterns in data that can help ex- plain the underlying process that generated the data. The patterns are required to be new, useful, and understandable to humans. In this work we present a new method for the under- standable description of local temporal relationships in multivariate data, called Time Series Knowledge Mining (TSKM). We define the Time Series Knowledge Representation (TSKR) as a new language for expressing temporal knowledge. The patterns have a hierarchical structure, each level corresponds to a single temporal concept. On the lowest level, intervals are used to represent duration. Overlapping parts of intervals represent coincidence on the next level. Several such blocks of intervals are connected with a partial order relation on the highest level. Each pattern element consists of a semiotic triple to connect syntactic and semantic information with pragmatics. The patterns are very compact, but offer details for each element on demand. In comparison with related approaches, the TSKR is shown to have advantages in robustness, expressivity, and comprehensibility. Efficient algorithms for the discovery of the patterns are proposed. The search for coincidence as well as partial order can be formulated as variants of the well known frequent itemset problem. One of the best known algorithms for this problem is therefore adapted for our purposes. Human interaction is used during the mining to analyze and validate partial results as early as possible and guide further processing steps. The efficacy of the methods is demonstrated using several data sets. In an application to sports medicine the results were recognized as valid and useful by an expert of the field.},
	journal = {Time},
	author = {Mörchen, Fabian},
	year = {2006},
	pages = {178},
	file = {Mörchen_2006_Time Series Knowledge Mining - Fabian Morchen Dissertation.pdf:/Users/orsonxu/Zotero/storage/ZXZFII7Q/Mörchen_2006_Time Series Knowledge Mining - Fabian Morchen Dissertation.pdf:application/pdf;Mörchen_2006_Time Series Knowledge Mining - Fabian Morchen Dissertation.pdf:/Users/orsonxu/Zotero/storage/QKUP6K7L/Mörchen_2006_Time Series Knowledge Mining - Fabian Morchen Dissertation.pdf:application/pdf},
}

@article{fradkin_mining_2015,
	title = {Mining sequential patterns for classification},
	volume = {45},
	issn = {02193116},
	doi = {10.1007/s10115-014-0817-0},
	abstract = {While a number of efficient sequential pattern mining algorithms were developed over the years, they can still take a long time and produce a huge number of patterns, many of which are redundant. These properties are especially frustrating when the goal of pattern mining is to find patterns for use as features in classification problems. In this paper, we describe BIDE-Discriminative, amodification of BIDE that uses class information for direct mining of predictive sequential patterns. We then perform an extensive evaluation on nine real-life datasets of the different ways in which the basic BIDE-Discriminative can be used in real multi-class classification problems, including 1-versus-rest and model-based search tree approaches. The results of our experiments show that 1-versus-rest provides an efficient solution with good classification performance.},
	number = {3},
	journal = {Knowledge and Information Systems},
	author = {Fradkin, Dmitriy and Mörchen, Fabian},
	year = {2015},
	keywords = {Information gain, Sequence classification, Sequential pattern mining},
	pages = {731--749},
	file = {Fradkin_Mörchen_2015_Mining sequential patterns for classification.pdf:/Users/orsonxu/Zotero/storage/8JFAEKKH/Fradkin_Mörchen_2015_Mining sequential patterns for classification.pdf:application/pdf;Fradkin_Mörchen_2015_Mining sequential patterns for classification.pdf:/Users/orsonxu/Zotero/storage/UCVL2669/Fradkin_Mörchen_2015_Mining sequential patterns for classification.pdf:application/pdf},
}

@article{chen_mining_2016,
	title = {Mining {Temporal} {Patterns} in {Interval}-{Based} {Data}},
	volume = {27},
	issn = {1041-4347},
	doi = {10.1109/TKDE.2015.2454515},
	number = {12},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Chen, Yi-cheng and Peng, Wen-chih and Lee, Suh-yin},
	year = {2016},
	keywords = {data mining, [Electronic Manuscript], interval-based event, representation, sequential pattern, temporal pattern},
	pages = {1506--1507},
	file = {Chen et al_2016_Mining Temporal Patterns in Interval-Based Data.pdf:/Users/orsonxu/Zotero/storage/JZPT44UX/Chen et al_2016_Mining Temporal Patterns in Interval-Based Data.pdf:application/pdf;Chen et al_2016_Mining Temporal Patterns in Interval-Based Data.pdf:/Users/orsonxu/Zotero/storage/S45QBPUB/Chen et al_2016_Mining Temporal Patterns in Interval-Based Data.pdf:application/pdf},
}

@article{cheng_discriminative_2007,
	title = {Discriminative {Frequent} {Pattern} {Analysis} for {Effective} {Classification}},
	issn = {1-4244-0802-4},
	url = {http://ieeexplore.ieee.org/document/4221720/},
	doi = {10.1109/ICDE.2007.367917},
	abstract = {The application of frequent patterns in classification{\textbackslash}nappeared in sporadic studies and achieved initial success in the{\textbackslash}nclassification of relational data, text documents and graphs. In this{\textbackslash}npaper, we conduct a systematic exploration of frequent pattern-based{\textbackslash}nclassification, and provide solid reasons supporting this methodology.{\textbackslash}nIt was well known that feature combinations (patterns) could capture{\textbackslash}nmore underlying semantics than single features. However, inclusion of{\textbackslash}ninfrequent patterns may not significantly improve the accuracy due to{\textbackslash}ntheir limited predictive power. By building a connection between pattern{\textbackslash}nfrequency and discriminative measures such as information gain and{\textbackslash}nFisher score, we develop a strategy to set minimum support in frequent{\textbackslash}npattern mining for generating useful patterns. Based on this strategy,{\textbackslash}ncoupled with a proposed feature selection algorithm, discriminative{\textbackslash}nfrequent patterns can be generated for building high quality{\textbackslash}nclassifiers. We demonstrate that the frequent pattern-based{\textbackslash}nclassification framework can achieve good scalability and high accuracy{\textbackslash}nin classifying large datasets. Empirical studies indicate that{\textbackslash}nsignificant improvement in classification accuracy is achieved (up to{\textbackslash}n12\% in UCI datasets) using the so-selected discriminative frequent{\textbackslash}npatterns.},
	journal = {2007 IEEE 23rd International Conference on Data Engineering},
	author = {Cheng, Hong and Yan, Xifeng and Han, Jiawei and Hsu, Chih-Wei},
	year = {2007},
	pages = {716--725},
	file = {Cheng et al_2007_Discriminative Frequent Pattern Analysis for Effective Classification.pdf:/Users/orsonxu/Zotero/storage/5ZDTXG7U/Cheng et al_2007_Discriminative Frequent Pattern Analysis for Effective Classification.pdf:application/pdf;Cheng et al_2007_Discriminative Frequent Pattern Analysis for Effective Classification.pdf:/Users/orsonxu/Zotero/storage/EV8QQD8P/Cheng et al_2007_Discriminative Frequent Pattern Analysis for Effective Classification.pdf:application/pdf},
}

@article{cheng_direct_2008,
	title = {Direct discriminative pattern mining for effective classification},
	issn = {10844627},
	doi = {10.1109/ICDE.2008.4497425},
	abstract = {— The application of frequent patterns in classification has demonstrated its power in recent studies. It often adopts a two-step approach: frequent pattern (or classification rule) min-ing followed by feature selection (or rule ranking). However, this two-step process could be computationally expensive, especially when the problem scale is large or the minimum support is low. It was observed that frequent pattern mining usually produces a huge number of " patterns " that could not only slow down the mining process but also make feature selection hard to complete. In this paper, we propose a direct discriminative pattern mining approach, DDPMine, to tackle the efficiency issue arising from the two-step approach. DDPMine performs a branch-and-bound search for directly mining discriminative patterns without generating the complete pattern set. Instead of selecting best patterns in a batch, we introduce a " feature-centered " mining approach that generates discriminative patterns sequentially on a progressively shrinking FP-tree by incrementally eliminating training instances. The instance elimination effectively reduces the problem size iteratively and expedites the mining process. Empirical results show that DDPMine achieves orders of magni-tude speedup without any downgrade of classification accuracy. It outperforms the state-of-the-art associative classification methods in terms of both accuracy and efficiency.},
	journal = {Proceedings - International Conference on Data Engineering},
	author = {Cheng, Hong and Yan, Xifeng and Han, Jiawei and Yu, Philip S.},
	year = {2008},
	pages = {169--178},
	file = {Cheng et al_2008_Direct discriminative pattern mining for effective classification.pdf:/Users/orsonxu/Zotero/storage/HRGBW7YP/Cheng et al_2008_Direct discriminative pattern mining for effective classification.pdf:application/pdf;Cheng et al_2008_Direct discriminative pattern mining for effective classification.pdf:/Users/orsonxu/Zotero/storage/MXYWZHQ3/Cheng et al_2008_Direct discriminative pattern mining for effective classification.pdf:application/pdf},
}

@article{liu_integrating_1998,
	title = {Integrating classification and association rule mining},
	issn = {09265805},
	doi = {10.1.1.48.8380},
	abstract = {Classification rule mining aims to discover a small set of rules in the database that forms an accurate classifier. Association rule mining finds all the rules existing in the database that satisfy some minimum support and minimum confidence constraints. For association rule mining, the target of discovery is not pre-determined, while for classification rule mining there is one and only one predetermined target. In this paper, we propose to integrate these two mining techniques. The integration is done by focusing on mining a special subset of association rules, called class association rules (CARs). An efficient algorithm is also given for building a classifier based on the set of discovered CARs. Experimental results show that the classifier built this way is, in general, more accurate than that produced by the state-of-the-art classification system C4.5. In addition, this integration helps to solve a number of problems that exist in the current classification systems. Introduction ...},
	journal = {Proceedings of the fourth international conference on knowledge discovery and data mining},
	author = {Liu, Bing and Hsu, Wynne and Ma, Yiming and Ma, Blwhy Bing Liu Wynne Hsu Yiming},
	year = {1998},
	keywords = {imported},
	pages = {80--86},
	file = {Liu et al_1998_Integrating classification and association rule mining.pdf:/Users/orsonxu/Zotero/storage/QZ7N8L3A/Liu et al_1998_Integrating classification and association rule mining.pdf:application/pdf},
}

@article{banaee_data-driven_2015,
	title = {Data-{Driven} {Rule} {Mining} and {Representation} of {Temporal} {Patterns} in {Physiological} {Sensor} {Data}},
	volume = {19},
	issn = {21682194},
	doi = {10.1109/JBHI.2015.2438645},
	abstract = {Mining and representation of qualitative patterns is a growing field in sensor data analytics. This paper leverages from rule mining techniques to extract and represent temporal relation of prototypical patterns in clinical data streams. The approach is fully data-driven, where the temporal rules are mined from physiological time series such as heart rate, respiration rate, and blood pressure. To validate the rules, a novel similarity method is introduced, that compares the similarity between rule sets. An additional aspect of the proposed approach has been to utilize natural language generation techniques to represent the temporal relations between patterns. In this study, the sensor data in the MIMIC online database was used for evaluation, in which the mined temporal rules as they relate to various clinical conditions (respiratory failure, angina, sepsis, ...) were made explicit as a textual representation. Furthermore, it was shown that the extracted rule set for any particular clinical condition was distinct from other clinical conditions.},
	number = {5},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Banaee, Hadi and Loutfi, Amy},
	year = {2015},
	keywords = {data-driven modelling, health informatics, linguistic representation, pattern abstraction, physiological sensor data, sensor data analysis, temporal rule mining},
	pages = {1557--1566},
	file = {Banaee_Loutfi_2015_Data-Driven Rule Mining and Representation of Temporal Patterns in Physiological Sensor Data.pdf:/Users/orsonxu/Zotero/storage/T5UWSUMQ/Banaee_Loutfi_2015_Data-Driven Rule Mining and Representation of Temporal Patterns in Physiological Sensor Data.pdf:application/pdf;Banaee_Loutfi_2015_Data-Driven Rule Mining and Representation of Temporal Patterns in Physiological Sensor Data.pdf:/Users/orsonxu/Zotero/storage/85PCJVTL/Banaee_Loutfi_2015_Data-Driven Rule Mining and Representation of Temporal Patterns in Physiological Sensor Data.pdf:application/pdf},
}

@article{dudek_measures_2010,
	title = {Measures for {Comparing} {Association} {Rule} {Sets}.pdf},
	author = {Dudek, Damian},
	year = {2010},
	keywords = {association rules, comparing rule sets, data set uniformity, data source stability, evaluation methods},
	pages = {315--322},
	file = {Dudek_2010_Measures for Comparing Association Rule Sets.pdf:/Users/orsonxu/Zotero/storage/BT2DFFVZ/Dudek_2010_Measures for Comparing Association Rule Sets.pdf:application/pdf;Dudek_2010_Measures for Comparing Association Rule Sets.pdf:/Users/orsonxu/Zotero/storage/N3DJVP7T/Dudek_2010_Measures for Comparing Association Rule Sets.pdf:application/pdf},
}

@article{chiu_probabilistic_2003,
	title = {Probabilistic discovery of time series motifs},
	issn = {00221694},
	url = {http://portal.acm.org/citation.cfm?doid=956750.956808},
	doi = {10.1145/956804.956808},
	abstract = {Several important time series data mining problems reduce to the core task of finding approximately repeated subsequences in a longer time series. In an earlier work, we formalized the idea of approximately repeated subsequences by introducing the notion of time series motifs. Two limitations of this work were the poor scalability of the motif discovery algorithm, and the inability to discover motifs in the presence of noise. Here we address these limitations by introducing a novel algorithm inspired by recent advances in the problem of pattern discovery in biosequences. Our algorithm is probabilistic in nature, but as we show empirically and theoretically, it can find time series motifs with very high probability even in the presence of noise or dont care symbols. Not only is the algorithm fast, but it is an anytime algorithm, producing likely candidate motifs almost immediately, and gradually improving the quality of results over time.},
	journal = {Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining  - KDD '03},
	author = {Chiu, Bill and Keogh, Eamonn and Lonardi, Stefano},
	year = {2003},
	keywords = {data mining, time series, application domains mentioned above, discovery can be very, in addition to the, motif, motifs, randomized algorithms, right as an exploratory, useful in its own},
	pages = {493},
	file = {Chiu et al_2003_Probabilistic discovery of time series motifs.pdf:/Users/orsonxu/Zotero/storage/XQZCJTP3/Chiu et al_2003_Probabilistic discovery of time series motifs.pdf:application/pdf;Chiu et al_2003_Probabilistic discovery of time series motifs.pdf:/Users/orsonxu/Zotero/storage/NZX2Y3K5/Chiu et al_2003_Probabilistic discovery of time series motifs.pdf:application/pdf},
}

@article{jessica_lin_finding_2008,
	title = {Finding {Motifs} in {Time} {Series}},
	number = {December},
	author = {{Jessica Lin} and Keogh, Eamonn and Lonardi, Stefano and Patel, Pranav},
	year = {2008},
	pages = {1--98},
	file = {Jessica Lin et al_2008_Finding Motifs in Time Series.pdf:/Users/orsonxu/Zotero/storage/3XQ3LYC9/Jessica Lin et al_2008_Finding Motifs in Time Series.pdf:application/pdf;Jessica Lin et al_2008_Finding Motifs in Time Series.pdf:/Users/orsonxu/Zotero/storage/YV4BJDKQ/Jessica Lin et al_2008_Finding Motifs in Time Series.pdf:application/pdf},
}

@article{choobdar_motif_2012,
	title = {Motif mining in weighted networks},
	doi = {10.1109/ICDMW.2012.111},
	abstract = {Unexpectedly frequent subgraphs, known as motifs, can help in characterizing the structure of complex networks. Most of the existing methods for finding motifs are designed for unweighted networks, where only the existence of connection between nodes is considered, and not their strength or capacity. However, in many real world networks, edges contain more information than just simple node connectivity. In this paper, we propose a new method to incorporate edge weight information in motif mining. We think of a motif as a subgraph that contains unexpected information, and we define a new significance measurement to assess this subgraph exceptionality. The proposed metric embeds the weight distribution in subgraphs and it is based on weight entropy. We use the gtrie data structure to find instances of k-sized subgraphs and to calculate its significance score. Following a statistical approach, the random entropy of subgraphs is then calculated, avoiding the time consuming step of random network generation. The discrimination power of the derived motif profile by the proposed method is assessed against the results of the traditional unweighted motifs through a graph classification problem. We use a set of labeled ego networks of co-authorship in the biology and mathematics fields. The new proposed method is shown to be feasible, achieving even slightly better accuracy. Since it does not require the generation of random networks, it is also computationally faster, and because we are able to use the weight information in computing the motif importance, we can avoid converting weighted networks into unweighted ones. © 2012 IEEE.},
	journal = {Proceedings - 12th IEEE International Conference on Data Mining Workshops, ICDMW 2012},
	author = {Choobdar, Sarvenaz and Ribeiro, Pedro and Silva, Fernando},
	year = {2012},
	keywords = {Complex networks, Entropy, Information theory, Network motifs, Weighted networks},
	pages = {210--217},
	file = {Choobdar et al_2012_Motif mining in weighted networks.pdf:/Users/orsonxu/Zotero/storage/277PIPKJ/Choobdar et al_2012_Motif mining in weighted networks.pdf:application/pdf;Choobdar et al_2012_Motif mining in weighted networks.pdf:/Users/orsonxu/Zotero/storage/9283E9YT/Choobdar et al_2012_Motif mining in weighted networks.pdf:application/pdf},
}

@article{rajendran_hybrid_2010,
	title = {Hybrid {Medical} {Image} {Classification} {Using} {Association} {Rule} {Mining} with {Decision} {Tree} {Algorithm}},
	volume = {2},
	abstract = {— The main focus of image mining in the proposed method is concerned with the classification of brain tumor in the CT scan brain images. The major steps involved in the system are: pre-processing, feature extraction, association rule mining and hybrid classifier. The pre-processing step has been done using the median filtering process and edge features have been extracted using canny edge detection technique. The two image mining approaches with a hybrid manner have been proposed in this paper. The frequent patterns from the CT scan images are generated by frequent pattern tree (FP-Tree) algorithm that mines the association rules. The decision tree method has been used to classify the medical images for diagnosis. This system enhances the classification process to be more accurate. The hybrid method improves the efficiency of the proposed method than the traditional image mining methods. The experimental result on prediagnosed database of brain images showed 97\% sensitivity and 95\% accuracy respectively. The physicians can make use of this accurate decision tree classification phase for classifying the brain images into normal, benign and malignant for effective medical diagnosis.},
	number = {1},
	journal = {Journal of Computing},
	author = {Rajendran, P and Madheswaran, M},
	year = {2010},
	pages = {2151--9617},
	file = {Rajendran_Madheswaran_2010_Hybrid Medical Image Classification Using Association Rule Mining with Decision Tree Algorithm.pdf:/Users/orsonxu/Zotero/storage/Q4Z64KH5/Rajendran_Madheswaran_2010_Hybrid Medical Image Classification Using Association Rule Mining with Decision Tree Algorithm.pdf:application/pdf;Rajendran_Madheswaran_2010_Hybrid Medical Image Classification Using Association Rule Mining with Decision Tree Algorithm.pdf:/Users/orsonxu/Zotero/storage/V8EM37VA/Rajendran_Madheswaran_2010_Hybrid Medical Image Classification Using Association Rule Mining with Decision Tree Algorithm.pdf:application/pdf},
}

@article{zhou_itemset_2013,
	title = {Itemset based sequence classification},
	volume = {8188 LNAI},
	issn = {03029743},
	doi = {10.1007/978-3-642-40988-2_23},
	abstract = {The genetic diversity of B. canis was investigated by restriction fragment length polymorphism analysis. For this purpose, we identified a Babesia canis specific DNA probe named pS8. This 1.2 kbp probe can detect as low as 20 pg of B. canis DNA. Results suggest that the pS8 probe is distributed in multiple copies throughout the genome though is probably not itself internally repetitious, i.e. not structured into blocks of tandem units. This probe reveals discrete hybridizing fragments in B. canis enzyme-digested genomic DNA. RFLP patterns obtained with the pS8 probe revealed a large genetic diversity between various isolates and led us to distinguish several clones derived from a single isolate. Results suggest that for a single isolate, the fingerprints obtained reflect those of a few quantitatively dominant clones. This technique can now be routinely applied and provides a convenient tool for the characterization and the identification of B. canis isolates, strains and clones.},
	number = {PART 1},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Zhou, Cheng and Cule, Boris and Goethals, Bart},
	year = {2013},
	pages = {353--368},
	file = {Zhou et al_2013_Itemset based sequence classification.pdf:/Users/orsonxu/Zotero/storage/5X6D8I3Z/Zhou et al_2013_Itemset based sequence classification.pdf:application/pdf;Zhou et al_2013_Itemset based sequence classification.pdf:/Users/orsonxu/Zotero/storage/8CJ9N3YR/Zhou et al_2013_Itemset based sequence classification.pdf:application/pdf},
}

@article{kianmehr_effective_2006,
	title = {Effective classification by integrating support vector machine and association rule mining},
	issn = {03029743},
	abstract = {In this study, we propose a new classification framework. CARSVM model, which integrates association rule mining and support vector machine. The aim is to take advantages of both knowledge represented by class association rules and the power of SVM algorithm to construct an efficient and accurate classifier model. Instead of using the original training set, a set of rule-based feature vectors, which are generated based on the discriminative ability of class association rules over the training samples, are presented to the learning process of the SVM algorithm. The reported test results demonstrate the applicability, efficiency and effectiveness of the proposed model.},
	journal = {Intelligent Data Engineering and Automated Learning–IDEAL 2006},
	author = {Kianmehr, Keivan and Alhajj, Reda},
	year = {2006},
	keywords = {machine learning, association rule mining, classification, associative classifiers, class association rules, support vector machine},
	pages = {920--927},
	file = {Kianmehr_Alhajj_2006_Effective classification by integrating support vector machine and association rule mining.pdf:/Users/orsonxu/Zotero/storage/84CN972R/Kianmehr_Alhajj_2006_Effective classification by integrating support vector machine and association rule mining.pdf:application/pdf;Kianmehr_Alhajj_2006_Effective classification by integrating support vector machine and association rule mining.pdf:/Users/orsonxu/Zotero/storage/TKG6U8KZ/Kianmehr_Alhajj_2006_Effective classification by integrating support vector machine and association rule mining.pdf:application/pdf},
}

@article{wang_implicit_2013,
	title = {Implicit feature identification via hybrid association rule mining},
	volume = {40},
	issn = {09574174},
	url = {http://dx.doi.org/10.1016/j.eswa.2012.12.060},
	doi = {10.1016/j.eswa.2012.12.060},
	abstract = {In sentiment analysis, a finer-grained opinion mining method not only focuses on the view of the product itself, but also focuses on product features, which can be a component or attribute of the product. Previous related research mainly relied on explicit features but ignored implicit features. However, the implicit features, which are implied by some words or phrases, are so significant that they can express the users' opinion and help us to better understand the users' comments. It is a big challenge to detect these implicit features in Chinese product reviews, due to the complexity of Chinese. This paper is mainly centered on implicit features identification in Chinese product reviews. A novel hybrid association rule mining method is proposed for this task. The core idea of this approach is mining as many association rules as possible via several complementary algorithms. Firstly, we extract candidate feature indicators based word segmentation, part-of-speech (POS) tagging and feature clustering, then compute the co-occurrence degree between the candidate feature indicators and the feature words using five collocation extraction algorithms. Each indicator and the corresponding feature word constitute a rule (feature indicator → feature word). The best rules in five different rule sets are chosen as the basic rules. Next, three methods are proposed to mine some possible reasonable rules from the lower co-occurrence feature indicators and non indicator words. Finally, the latest rules are used to identify implicit features and the results are compared with the previous. Experiment results demonstrate that our proposed approach is competent at the task, especially via using several expanding methods. The recall is effectively improved, suggesting that the shortcomings of the basic rules have been overcome to certain extent. Besides those high co-occurrence degree indicators, the final rules also contain uncommon rules. © 2012 Elsevier Ltd. All rights reserved.},
	number = {9},
	journal = {Expert Systems with Applications},
	author = {Wang, Wei and Xu, Hua and Wan, Wei},
	year = {2013},
	keywords = {Collocation extraction, Hybrid association rule mining, Implicit features, Opinion mining},
	pages = {3518--3531},
	file = {Wang et al_2013_Implicit feature identification via hybrid association rule mining.pdf:/Users/orsonxu/Zotero/storage/YGPAIUXT/Wang et al_2013_Implicit feature identification via hybrid association rule mining.pdf:application/pdf;Wang et al_2013_Implicit feature identification via hybrid association rule mining.pdf:/Users/orsonxu/Zotero/storage/N2RDSYFD/Wang et al_2013_Implicit feature identification via hybrid association rule mining.pdf:application/pdf},
}

@article{kamei_hybrid_2008,
	title = {A hybrid faulty module prediction using association rule mining and logistic regression analysis},
	url = {http://portal.acm.org/citation.cfm?doid=1414004.1414051},
	doi = {10.1145/1414004.1414051},
	abstract = {This paper proposes a fault-prone module prediction method that combines association rule mining with logistic regression analysis. In the proposed method, we focus on three key measures of interestingness of an association rule (support, confidence and lift) to select useful rules for the prediction. If a module satisfies the premise (i.e. the condition in the antecedent part) of one of the selected rules, the module is classified by the rule as either fault-prone or not. Otherwise, the module is classified by the logistic model. We experimentally evaluated the prediction performance of the proposed method with different thresholds of each rule interestingness measure (support, confidence and lift) using a module set in the Eclipse project, and compared it with three well-known fault-proneness models (logistic regression model, linear discriminant model and classification tree). The result showed that the improvement of the Fl-value of the proposed method was 0.163 at maximum compared to conventional models. Copyright 2008 ACM.},
	journal = {Proceedings of the Second ACM-IEEE international symposium on Empirical software engineering and measurement - ESEM '08},
	author = {Kamei, Yasutaka and Monden, Akito and Morisaki, Shuji and Matsumoto, Ken-ichi},
	year = {2008},
	keywords = {empirical study, mining, association rule, fault-prone module prediction, logistic regression analysis},
	pages = {279},
	file = {Kamei et al_2008_A hybrid faulty module prediction using association rule mining and logistic regression analysis.pdf:/Users/orsonxu/Zotero/storage/UGQH6KVY/Kamei et al_2008_A hybrid faulty module prediction using association rule mining and logistic regression analysis.pdf:application/pdf;Kamei et al_2008_A hybrid faulty module prediction using association rule mining and logistic regression analysis.pdf:/Users/orsonxu/Zotero/storage/IVBU6MCG/Kamei et al_2008_A hybrid faulty module prediction using association rule mining and logistic regression analysis.pdf:application/pdf},
}

@article{kasap_combining_2016,
	title = {Combining {Logistic} {Regression} {Analysis} and {Association} {Rule} {Mining} via {MLR} {Algorithm}},
	abstract = {—One of the keys in marketing is to recommend the right products to the right customers. This paper proposes a solution to this problem as a part of the development of a new data mining tool PROPCA (Proximus Optimum Canistro). The aim is to use logistic regression analysis and association rule mining together to make recommendations in marketing. An innovative approach in which combination of these two algorithms provides better results than algorithms used stand-alone is presented. While association rule mining searches all rules in the data set, logistic regression predicts a purchase probability of a product for customers. The combination of these two approaches are tested on a real-life banking data set. The results of combination are shown and their suitability in general is discussed.},
	number = {c},
	author = {Kasap, Ozge Yucel and Ekmekci, Nevzat and Ketenci, Utku Gorkem},
	year = {2016},
	keywords = {–Logistic Regression, Apriori, Association Rule Mining, Ensemble Learning, Logit, MLR, Stacking},
	pages = {154--159},
	file = {Kasap et al_2016_Combining Logistic Regression Analysis and Association Rule Mining via MLR Algorithm.pdf:/Users/orsonxu/Zotero/storage/J7MRUZL5/Kasap et al_2016_Combining Logistic Regression Analysis and Association Rule Mining via MLR Algorithm.pdf:application/pdf;Kasap et al_2016_Combining Logistic Regression Analysis and Association Rule Mining via MLR Algorithm.pdf:/Users/orsonxu/Zotero/storage/4F3NVYM4/Kasap et al_2016_Combining Logistic Regression Analysis and Association Rule Mining via MLR Algorithm.pdf:application/pdf},
}

@article{dumais_understanding_2014,
	title = {Understanding {User} {Behavior} {Through} {Log} {Data} and {Analysis}},
	doi = {10.1007/978-1-4939-0378-8},
	abstract = {This textbook brings together both new and traditional research methods in Human Computer Interaction (HCI). Research methods include interviews and observations, ethnography, grounded theory and analysis of digital traces of behavior. Readers will gain an understanding of the type of knowledge each method provides, its disciplinary roots and how each contributes to understanding users, user behavior and the context of use. The background context, clear explanations and sample exercises make this an ideal textbook for graduate students, as well as a valuable reference for researchers and practitioners.},
	journal = {Ways of Knowing in HCI},
	author = {Dumais, Susan and Jeffries, Robin and Russell, Daniel M. and Tang, Diane and Teevan, Jaime},
	year = {2014},
	pages = {1--472},
	file = {Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:/Users/orsonxu/Zotero/storage/6PMXQMIH/Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:application/pdf;Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:/Users/orsonxu/Zotero/storage/J2VQFVCI/Dumais et al_2014_Understanding User Behavior Through Log Data and Analysis.pdf:application/pdf},
}

@article{sarrafzadeh_characterizing_2019,
	title = {Characterizing and {Predicting} {Email} {Deferral} {Behavior}},
	url = {http://arxiv.org/abs/1901.04375%0Ahttp://dx.doi.org/10.1145/3289600.3291028},
	doi = {10.1145/3289600.3291028},
	abstract = {Email triage involves going through unhandled emails and deciding what to do with them. This familiar process can become increasingly challenging as the number of unhandled email grows. During a triage session, users commonly defer handling emails that they cannot immediately deal with to later. These deferred emails, are often related to tasks that are postponed until the user has more time or the right information to deal with them. In this paper, through qualitative interviews and a large-scale log analysis, we study when and what enterprise email users tend to defer. We found that users are more likely to defer emails when handling them involves replying, reading carefully, or clicking on links and attachments. We also learned that the decision to defer emails depends on many factors such as user's workload and the importance of the sender. Our qualitative results suggested that deferring is very common, and our quantitative log analysis confirms that 12\% of triage sessions and 16\% of daily active users had at least one deferred email on weekdays. We also discuss several deferral strategies such as marking emails as unread and flagging that are reported by our interviewees, and illustrate how such patterns can be also observed in user logs. Inspired by the characteristics of deferred emails and contextual factors involved in deciding if an email should be deferred, we train a classifier for predicting whether a recently triaged email is actually deferred. Our experimental results suggests that deferral can be classified with modest effectiveness. Overall, our work provides novel insights about how users handle their emails and how deferral can be modeled.},
	author = {Sarrafzadeh, Bahareh and Awadallah, Ahmed Hassan and Lin, Christopher H. and Lee, Chia-Jung and Shokouhi, Milad and Dumais, Susan T.},
	year = {2019},
	keywords = {acm reference format, bahareh sarrafzadeh and ahmed, christopher h, deferral, email management, hassan awadallah, lin, triage, users behavior modeling},
	file = {Sarrafzadeh et al_2019_Characterizing and Predicting Email Deferral Behavior.pdf:/Users/orsonxu/Zotero/storage/68SHXHY3/Sarrafzadeh et al_2019_Characterizing and Predicting Email Deferral Behavior.pdf:application/pdf;Sarrafzadeh et al_2019_Characterizing and Predicting Email Deferral Behavior.pdf:/Users/orsonxu/Zotero/storage/QXQHV36A/Sarrafzadeh et al_2019_Characterizing and Predicting Email Deferral Behavior.pdf:application/pdf},
}

@article{ai_characterizing_2017,
	title = {Characterizing {Email} {Search} using {Large}-scale {Behavioral} {Logs} and {Surveys}},
	doi = {10.1145/3038912.3052615},
	abstract = {As the number of email users and messages continues to grow, search is becoming more important for finding in-formation in personal archives. In spite of its importance, email search is much less studied than web search, particu-larly using large-scale behavioral log analysis. In this paper we report the results of a large-scale log analysis of email search and complement this with a survey to better un-derstand email search intent and success. We characterize email search behaviors and highlight differences from web search. When searching for email, people know many at-tributes about what they are looking for; they often look for specific known items; their queries are shorter and they click on fewer items than in web search. Although repeat queries are common in both email and web search, repeat visits to the same search result are much less common in email search suggesting that the same query is used for different search intents over time. We consider search intent from multiple angles. In email search logs, we find that people use email search not just to find information but also to perform tasks such as cleanup or organization, and that the distribution of actions they perform depends on the type of query. In our survey, people reported that they looked for specific infor-mation in both email search and web search, but they were much less likely to search for general information on a topic in email. The differences in overall behavior, re-finding pat-terns and search intents we observed between email and web search have important implications for the design of email search algorithms and interfaces.},
	author = {Ai, Qingyao and Dumais, Susan T. and Craswell, Nick and Liebling, Dan},
	year = {2017},
	keywords = {email search, query log anal-, re-finding, user evaluation},
	pages = {1511--1520},
	file = {Ai et al_2017_Characterizing Email Search using Large-scale Behavioral Logs and Surveys.pdf:/Users/orsonxu/Zotero/storage/2T2PI8V5/Ai et al_2017_Characterizing Email Search using Large-scale Behavioral Logs and Surveys.pdf:application/pdf;Ai et al_2017_Characterizing Email Search using Large-scale Behavioral Logs and Surveys.pdf:/Users/orsonxu/Zotero/storage/S64JFU43/Ai et al_2017_Characterizing Email Search using Large-scale Behavioral Logs and Surveys.pdf:application/pdf},
}

@article{zhang_explainable_2018,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	volume = {XX},
	issn = {1935-8237},
	doi = {10.1561/XXXXXXXXXX},
	number = {Xx},
	journal = {Foundations and Trends in Theoretical Computer Science},
	author = {Zhang, Yongfeng and Chen, Xu},
	year = {2018},
	pages = {1--87},
	file = {Zhang_Chen_2018_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/9P8EP32J/Zhang_Chen_2018_Explainable Recommendation.pdf:application/pdf;Zhang_Chen_2018_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/RD26CYPN/Zhang_Chen_2018_Explainable Recommendation.pdf:application/pdf},
}

@article{alrashed_lifetime_2018,
	title = {The {Lifetime} of {Email} {Messages}: {A} {Large}-{Scale} {Analysis} of {Email} {Revisitation}},
	url = {http://doi.acm.org/10.1145/3176349.3176398},
	doi = {10.1145/3176349.3176398},
	journal = {Proceedings of the 2018 Conference on Human Information Interaction\&\#38;Retrieval},
	author = {Alrashed, Tarfah and Awadallah, Ahmed Hassan and Dumais, Susan},
	year = {2018},
	keywords = {email interaction, email lifetime, email revisitation},
	pages = {120--129},
	file = {Alrashed et al_2018_The Lifetime of Email Messages.pdf:/Users/orsonxu/Zotero/storage/LQPW9VC9/Alrashed et al_2018_The Lifetime of Email Messages.pdf:application/pdf;Alrashed et al_2018_The Lifetime of Email Messages.pdf:/Users/orsonxu/Zotero/storage/BWZ8USI3/Alrashed et al_2018_The Lifetime of Email Messages.pdf:application/pdf},
}

@article{sarker_recencyminer_2019,
	title = {{RecencyMiner} : mining recency ‑ based personalized behavior from contextual smartphone data},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0211-6},
	doi = {10.1186/s40537-019-0211-6},
	journal = {Journal of Big Data},
	author = {Sarker, Iqbal H and Colman, Alan and Han, Jun},
	year = {2019},
	keywords = {machine learning, association rule learning, context-awareness, data, intelligent service, iot analytics, mobile data mining, Mobile data mining,Machine learning,Association ru, personalization, predictive modeling, recency, science, smartphone, user behavior modeling},
	file = {Sarker et al_2019_RecencyMiner.pdf:/Users/orsonxu/Zotero/storage/GDKS6WTL/Sarker et al_2019_RecencyMiner.pdf:application/pdf;Sarker et al_2019_RecencyMiner.pdf:/Users/orsonxu/Zotero/storage/QGT88757/Sarker et al_2019_RecencyMiner.pdf:application/pdf},
}

@article{kim_understanding_2017,
	title = {Understanding and {Modeling} {Success} in {Email} {Search}},
	doi = {10.1145/3077136.3080837},
	abstract = {Email has been a dominant form of communication for many years, and email search is an important problem. In contrast to other search setting, such as web search, there have been few studies of user behavior and models of email search success. Research in email search is challenging for many reasons including the personal and private nature of the collection. Third party judges can not look at email search queries or email message content requiring new modeling techniques. In this study, we built an opt-in client application which monitors a user's email search activity and then pops up an in-situ survey when a search session is finished. We then merged the survey data with server-side behavioral logs. This approach allows us to study the relationship between session-level outcome and user behavior, and then build a model to predict success for email search based on behavioral interaction patterns. Our results show that generative models (\{MarkovChain\}) of success can predict the session-level success of email search better than baseline heuristics and discriminative models (\{RandomForest\}). The success model makes use of email-specific log activities such as reply, forward and move, as well as generic signals such as click with long dwell time. The learned model is highly interpretable, and reusable in that it can be applied to unlabeled interaction logs in the future.},
	author = {Kim, Jin Young and Craswell, Nick and Dumais, Susan and Radlinski, Filip and Liu, Fang},
	year = {2017},
	keywords = {•Information systems  Evaluation of retrieval resu},
	pages = {265--274},
	file = {Kim et al_2017_Understanding and Modeling Success in Email Search.pdf:/Users/orsonxu/Zotero/storage/LN7TG6H9/Kim et al_2017_Understanding and Modeling Success in Email Search.pdf:application/pdf;Kim et al_2017_Understanding and Modeling Success in Email Search.pdf:/Users/orsonxu/Zotero/storage/F8AUTPX2/Kim et al_2017_Understanding and Modeling Success in Email Search.pdf:application/pdf},
}

@article{tata_quick_2017,
	title = {Quick {Access}: {Building} a {Smart} {Experience} for {Google} {Drive}},
	url = {http://dx.doi.org/10.1145/3097983.3098048%0Ahttp://www.kdd.org/kdd2017/papers/view/quick-access-building-a-smart-experience-for-google-drive},
	doi = {10.1145/3097983.3098048},
	abstract = {Google Drive is a cloud storage and collaboration service used by hundreds of millions of users around the world. Quick Access is a new feature in Google Drive that surfaces the most relevant documents when a user visits the home screen. Our metrics show that users locate their documents in half the time with this feature compared to previous approaches. The development of Quick Access illustrates many general challenges and constraints associated with practical machine learning such as protecting user privacy, working with data services that are not designed with machine learning in mind, and evolving product definitions. We believe that the lessons learned from this experience will be useful to practitioners tackling a wide range of applied machine learning problems.},
	journal = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17},
	author = {Tata, Sandeep and Popescul, Alexandrin and Najork, Marc and Colagrosso, Mike and Gibbons, Julian and Green, Alan and Mah, Alexandre and Smith, Michael and Garg, Divanshu and Meyer, Cayden and Kan, Reuben and Cola-grosso, Mike},
	year = {2017},
	pages = {1643--1651},
	file = {Tata et al_2017_Quick Access.pdf:/Users/orsonxu/Zotero/storage/SU2EHEXE/Tata et al_2017_Quick Access.pdf:application/pdf;Tata et al_2017_Quick Access.pdf:/Users/orsonxu/Zotero/storage/FXTVAD4E/Tata et al_2017_Quick Access.pdf:application/pdf},
}

@article{covington_deep_2016,
	title = {Deep {Neural} {Networks} for {YouTube} {Recommendations}},
	url = {http://arxiv.org/abs/1611.00591},
	abstract = {We propose novel methods of solving two tasks using Convolutional Neural Networks, firstly the task of generating HDR map of a static scene using differently exposed LDR images of the scene captured using conventional cameras and secondly the task of finding an optimal tone mapping operator that would give a better score on the TMQI metric compared to the existing methods. We quantitatively show the performance of our networks and illustrate the cases where our networks performs good as well as bad.},
	journal = {RecSys},
	author = {Covington, Paul and Adams, Jay and Sargin, Emre},
	year = {2016},
	keywords = {deep learning, scalability, recommender system},
	pages = {191--198},
	file = {Covington et al_2016_Deep Neural Networks for YouTube Recommendations.pdf:/Users/orsonxu/Zotero/storage/9V3LUYD9/Covington et al_2016_Deep Neural Networks for YouTube Recommendations.pdf:application/pdf;Covington et al_2016_Deep Neural Networks for YouTube Recommendations.pdf:/Users/orsonxu/Zotero/storage/DSVHIWWY/Covington et al_2016_Deep Neural Networks for YouTube Recommendations.pdf:application/pdf},
}

@article{rudovic_personalized_2018,
	title = {Personalized machine learning for robot perception of affect and engagement in autism therapy},
	volume = {3},
	issn = {24709476},
	doi = {10.1126/scirobotics.aao6760},
	abstract = {Robots have great potential to facilitate future therapies for children on the autism spectrum. However, existing robots lack the ability to automatically perceive and respond to human affect, which is necessary for establishing and maintaining engaging interactions. Moreover, their inference challenge is made harder by the fact that many individuals with autism have atypical and unusually diverse styles of expressing their affective-cognitive states. To tackle the heterogeneity in behavioral cues of children with autism, we use the latest advances in deep learning to formulate a personalized machine learning (ML) framework for automatic perception of the childrens affective states and engagement during robot-assisted autism therapy. The key to our approach is a novel shift from the traditional ML paradigm - instead of using 'one-size-fits-all' ML models, our personalized ML framework is optimized for each child by leveraging relevant contextual information (demographics and behavioral assessment scores) and individual characteristics of each child. We designed and evaluated this framework using a dataset of multi-modal audio, video and autonomic physiology data of 35 children with autism (age 3-13) and from 2 cultures (Asia and Europe), participating in a 25-minute child-robot interaction ({\textasciitilde}500k datapoints). Our experiments confirm the feasibility of the robot perception of affect and engagement, showing clear improvements due to the model personalization. The proposed approach has potential to improve existing therapies for autism by offering more efficient monitoring and summarization of the therapy progress.},
	number = {19},
	journal = {Science Robotics},
	author = {Rudovic, Ognjen and Lee, Jaeryoung and Dai, Miles and Schuller, Björn and Picard, Rosalind W.},
	year = {2018},
	file = {Rudovic et al_2018_Personalized machine learning for robot perception of affect and engagement in autism therapy.pdf:/Users/orsonxu/Zotero/storage/K384ECYB/Rudovic et al_2018_Personalized machine learning for robot perception of affect and engagement in autism therapy.pdf:application/pdf;Rudovic et al_2018_Personalized machine learning for robot perception of affect and engagement in autism therapy.pdf:/Users/orsonxu/Zotero/storage/9K2VYRDF/Rudovic et al_2018_Personalized machine learning for robot perception of affect and engagement in autism therapy.pdf:application/pdf},
}

@article{angelo_spacetime_2018,
	title = {Spacetime {Characterization} of {Real}-{Time} {Collaborative} {Editing}},
	author = {Angelo, Gabriele and Iorio, Angelo Di and Zacchiroli, Stefano and Angelo, Gabriele and Iorio, Angelo Di and Zacchiroli, Stefano and Characterization, Spacetime},
	year = {2018},
	keywords = {collaborative editing, conflict resolution, etherpad, real-time, simultaneous editing, user behavior},
	file = {Angelo et al_2018_Spacetime Characterization of Real-Time Collaborative Editing.pdf:/Users/orsonxu/Zotero/storage/Z5YJXCC5/Angelo et al_2018_Spacetime Characterization of Real-Time Collaborative Editing.pdf:application/pdf;Angelo et al_2018_Spacetime Characterization of Real-Time Collaborative Editing.pdf:/Users/orsonxu/Zotero/storage/DX6QUGV8/Angelo et al_2018_Spacetime Characterization of Real-Time Collaborative Editing.pdf:application/pdf},
}

@article{peake_explanation_2018,
	title = {Explanation {Mining}: {Post} {Hoc} {Interpretability} of {Latent} {Factor} {Models} for {Recommendation} {Systems}},
	doi = {10.1145/3219819.3220072},
	abstract = {The widescale use of machine learning algorithms to drive decision-making has highlighted the critical importance of ensuring the interpretability of such models in order to engender trust in their output. The state-of-the-art recommendation systems use black-box latent factor models that provide no explanation of why a recommendation has been made, as they abstract their decision processes to a high-dimensional latent space which is beyond the direct comprehension of humans. We propose a novel approach for extracting explanations from latent factor recommendation systems by training association rules on the output of a matrix factorisation black-box model. By taking advantage of the interpretable structure of association rules, we demonstrate that predictive accuracy of the recommendation model can be maintained whilst yielding explanations with high fidelity to the black-box model on a unique industry dataset. Our approach mitigates the accuracy-interpretability trade-off whilst avoiding the need to sacrifice flexibility or use external data sources. We also contribute to the ill-defined problem of evaluating interpretability. CCS CONCEPTS • Information systems → Recommender systems; • Computing methodologies → Learning latent representations; Rule learning; Learning from implicit feedback;},
	author = {Peake, Georgina and Wang, Jun},
	year = {2018},
	keywords = {explanations, association rules, acm reference format, black-box, factor models, interpretability, latent, latent factor models, recommendation systems, white-box},
	pages = {2060--2069},
	file = {Peake_Wang_2018_Explanation Mining.pdf:/Users/orsonxu/Zotero/storage/T2HMS2YU/Peake_Wang_2018_Explanation Mining.pdf:application/pdf;Peake_Wang_2018_Explanation Mining.pdf:/Users/orsonxu/Zotero/storage/SLNDN85H/Peake_Wang_2018_Explanation Mining.pdf:application/pdf},
}

@article{adar_large_2008,
	title = {Large scale analysis of web revisitation patterns},
	doi = {10.1145/1357054.1357241},
	abstract = {Our work examines Web revisitation patterns. Everybody revisits Web pages, but their reasons for doing so can differ depending on the particular Web page, their topic of interest, and their intent. To characterize how people revisit Web content, we analyzed five weeks of Web interaction logs of over 612,000 users. We supplemented these findings by a survey intended to identify the intent behind the observed revisitation. Our analysis reveals four primary revisitation patterns, each with unique behavioral, content, and structural characteristics. Through our analysis we illustrate how understanding revisitation patterns can enable Web sites to provide improved navigation, Web browsers to predict users' destinations, and search engines to better support fast, fresh, and effective finding and re-finding. Copyright 2008 ACM.},
	author = {Adar, Eytan and Teevan, Jaime and Dumais, Susan T.},
	year = {2008},
	pages = {1197},
	file = {Adar et al_2008_Large scale analysis of web revisitation patterns.pdf:/Users/orsonxu/Zotero/storage/4KIZA3IM/Adar et al_2008_Large scale analysis of web revisitation patterns.pdf:application/pdf;Adar et al_2008_Large scale analysis of web revisitation patterns.pdf:/Users/orsonxu/Zotero/storage/DPB5TP8G/Adar et al_2008_Large scale analysis of web revisitation patterns.pdf:application/pdf},
}

@article{singh_posthoc_2018,
	title = {Posthoc {Interpretability} of {Learning} to {Rank} {Models} using {Secondary} {Training} {Data}},
	issn = {0362-1340},
	doi = {10.1145/nnnnnnn.nnnnnnn},
	journal = {ExplainAble Recommendation and Search (EARS 2018)},
	author = {Singh, Jaspreet and Anand, Avishek},
	year = {2018},
	keywords = {algorithm, automated reasoning, constructivism, extensionality, mathematical proof, mathematics, nuprl, proof theory, type theory, undecidable problem},
	pages = {2016--2019},
	file = {Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:/Users/orsonxu/Zotero/storage/8PJ7HC85/Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:application/pdf;Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:/Users/orsonxu/Zotero/storage/ZLCCN53G/Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:application/pdf},
}

@article{singh_posthoc_2018-1,
	title = {Posthoc {Interpretability} of {Learning} to {Rank} {Models} using {Secondary} {Training} {Data}},
	issn = {0362-1340},
	doi = {10.1145/nnnnnnn.nnnnnnn},
	journal = {ACM SIGPLAN Notices},
	author = {Singh, Jaspreet and Anand, Avishek},
	year = {2018},
	keywords = {algorithm, automated reasoning, constructivism, extensionality, mathematical proof, mathematics, nuprl, proof theory, type theory, undecidable problem},
	file = {Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:/Users/orsonxu/Zotero/storage/E9YEMGJQ/Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data2.pdf:application/pdf;Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data.pdf:/Users/orsonxu/Zotero/storage/3S22EIPY/Singh_Anand_2018_Posthoc Interpretability of Learning to Rank Models using Secondary Training Data2.pdf:application/pdf},
}

@article{sato_explaining_2018,
	title = {Explaining {Recommendations} {Using} {Contexts}},
	doi = {10.1145/3172944.3173012},
	abstract = {© 2018 Copyright is held by the owner/author(s). Publication rights licensed to ACM. Recommender systems support user decision-making, and explanations of recommendations further facilitate their usefulness. Previous explanation styles are based on similar users, similar items, demographics of users, and contents of items. Contexts, such as "usage scenarios" and "accompanying persons," have not been used for explanations, although they influence user decisions. In this paper, we propose a context style explanation method, presenting contexts suitable for consuming recommended items. The expected impacts of context style explanations are 1) persuasiveness: recognition of suitable context for usage motivates users to consume items, and 2) usefulness: envisioning context helps users to make right choices because the values of items depend on contexts. We evaluate context style persuasiveness and usefulness by a crowdsourcing-based user study in a restaurant recommendation setting. The context style explanation is compared to demographic and content style explanations. We also combine context style and other explanation styles, confirming that hybrid styles improve persuasiveness and usefulness of explanation.},
	author = {Sato, Masahiro and Ahsan, Budrul and Nagatani, Koki and Sonoda, Takashi and Zhang, Qian and Ohkuma, Tomoko},
	year = {2018},
	pages = {659--664},
	file = {Sato et al_2018_Explaining Recommendations Using Contexts.pdf:/Users/orsonxu/Zotero/storage/K6IM6MB3/Sato et al_2018_Explaining Recommendations Using Contexts.pdf:application/pdf;Sato et al_2018_Explaining Recommendations Using Contexts.pdf:/Users/orsonxu/Zotero/storage/GQREAXAW/Sato et al_2018_Explaining Recommendations Using Contexts.pdf:application/pdf},
}

@article{blanco_you_2012,
	title = {You should read this! let me explain you why},
	doi = {10.1145/2396761.2398559},
	abstract = {Recommender systems have become ubiquitous in content-based web applications, from news to shopping sites. Nonetheless, an aspect that has been largely overlooked so far in the recommender system literature is that of automatically building explanations},
	author = {Blanco, Roi and Ceccarelli, Diego and Lucchese, Claudio and Perego, Raffaele and Silvestri, Fabrizio},
	year = {2012},
	keywords = {all or part of, or hard copies of, permission to make digital, markov logic networks, news recommendation, query log analysis, recommenda-, this work for, tion snippets},
	pages = {1995},
	file = {Blanco et al_2012_You should read this.pdf:/Users/orsonxu/Zotero/storage/9GRHPB5W/Blanco et al_2012_You should read this.pdf:application/pdf;Blanco et al_2012_You should read this.pdf:/Users/orsonxu/Zotero/storage/VMLQZV4B/Blanco et al_2012_You should read this.pdf:application/pdf},
}

@article{sharma_social_2013,
	title = {Do social explanations work? {Studying} and {Modeling} the {Effects} of {Social} {Explanations} in {Recommender} {Systems}},
	doi = {10.1145/2488388.2488487},
	abstract = {Recommender systems associated with social networks often use social explanations (e.g. "X, Y and 2 friends like this") to support the recommendations. We present a study of the effects of these social explanations in a music recommendation context. We start with an experiment with 237 users, in which we show explanations with varying levels of social information and analyze their effect on users' decisions. We distinguish between two key decisions: the likelihood of checking out the recommended artist, and the actual rating of the artist based on listening to several songs. We find that while the explanations do have some influence on the likelihood, there is little correlation between the likelihood and actual (listening) rating for the same artist. Based on these insights, we present a generative probabilistic model that explains the interplay between explanations and background information on music preferences, and how that leads to a final likelihood rating for an artist. Acknowledging the impact of explanations, we discuss a general recommendation framework that models external informational elements in the recommendation interface, in addition to inherent preferences of users.},
	author = {Sharma, Amit and Cosley, Dan},
	year = {2013},
	pages = {1133--1144},
	file = {Sharma_Cosley_2013_Do social explanations work.pdf:/Users/orsonxu/Zotero/storage/AVKQ4IYL/Sharma_Cosley_2013_Do social explanations work.pdf:application/pdf;Sharma_Cosley_2013_Do social explanations work.pdf:/Users/orsonxu/Zotero/storage/6D2HKC7I/Sharma_Cosley_2013_Do social explanations work.pdf:application/pdf},
}

@article{rana_explanations_2018,
	title = {Explanations that are {Intrinsic} to {Recommendations}},
	doi = {10.1145/3209219.3209230},
	abstract = {OBJECTIVE(S): Description of mothers' characteristics, obstetricians' practices, and PPROM-linked mortality in all 81 maternity hospitals in the Rhône-Alpes Region, over a period of 2 years.{\textbackslash}n{\textbackslash}nSTUDY DESIGN: Prospective cohort study of 598 women with PPROM between 24 and 34 weeks' gestation, leading to 680 births. At time of PPROM, collection of mothers' socio-economic characteristics, medical and obstetric histories and PPROM circumstances. Collection of perinatal management, neonates' medical status and postnatal referral.{\textbackslash}n{\textbackslash}nRESULTS: The birth rate after PPROM between 24 and 34 weeks' gestation was 0.47\% (95\% CI: 0.42-0.48). Sixty percent of PPROM occurred before 32 weeks' gestation and 98\% of births before 37 weeks. The incidence of previous PPROM was 14.3\%. Antibiotics, corticosteroids, and tocolytics were given to 82, 78, and 52\% of women, respectively. The rate of antibiotics and antenatal corticosteroids varied with gestational age (lower rates for antibiotics just after the limit of viability (23-24 weeks) and after 32 weeks, higher rates of corticosteroids between 26 and 30 weeks). The PPROM-birth interval became shorter as gestation advanced. The incidence of C-section was 58.7\% (n = 270), C-section before labour being the most frequent mode of delivery. Sixty-seven percent of neonates were born in Level-3 hospitals. The overall neonatal mortality rate at 28 days decreased with gestational age at PPROM, and was 17.2\% (16/93), 3\% (6/200), and 0.41\% (1/241) at 24-27, 28-31 and 32-33 weeks of PPROM, respectively.{\textbackslash}n{\textbackslash}nCONCLUSION(S): After PPROM, antibiotics and antenatal corticosteroids were widely used in our cohort, and C-section rates were elevated. With that up-to-date management, the perinatal mortality rate was less than 3\% following PPROM after 28 weeks' gestation.},
	author = {Rana, Arpit and Bridge, Derek},
	year = {2018},
	keywords = {acm reference format, 2018, arpit rana and derek, bridge, explanation, Explanation, explanations that are intrinsic, recommendation, Recommendation, to rec-, user trial, User Trial},
	pages = {187--195},
	file = {Rana_Bridge_2018_Explanations that are Intrinsic to Recommendations.pdf:/Users/orsonxu/Zotero/storage/V6XIEJCX/Rana_Bridge_2018_Explanations that are Intrinsic to Recommendations.pdf:application/pdf;Rana_Bridge_2018_Explanations that are Intrinsic to Recommendations.pdf:/Users/orsonxu/Zotero/storage/ZIBSLEN2/Rana_Bridge_2018_Explanations that are Intrinsic to Recommendations.pdf:application/pdf},
}

@article{kouki_user_2017,
	title = {User {Preferences} for {Hybrid} {Explanations}},
	doi = {10.1145/3109859.3109915},
	abstract = {Hybrid recommender systems combine several diierent sources of information to generate recommendations. These systems demon-strate improved accuracy compared to single-source recommen-dation strategies. However, hybrid recommendation strategies are inherently more complex than those that use a single source of information, and thus the process of explaining recommendations to users becomes more challenging. In this paper we describe a hybrid recommender system built on a probabilistic programming language, and discuss the beneets and challenges of explaining its recommendations to users. We perform a mixed model statis-tical analysis of user preferences for explanations in this system. Through an online user survey, we evaluate explanations for hybrid algorithms in a variety of text and visual, graph-based formats, that are either novel designs or derived from existing hybrid recom-mender systems.},
	author = {Kouki, Pigi and Schaffer, James and Pujara, Jay and O'Donovan, John and Getoor, Lise},
	year = {2017},
	keywords = {explanations, a subset of visualizations, figure 1, hybrid explanations, hybrid recommendations, presented in our user, study of hybrid explanations},
	pages = {84--88},
	file = {Kouki et al_2017_User Preferences for Hybrid Explanations.pdf:/Users/orsonxu/Zotero/storage/2YEN8MC8/Kouki et al_2017_User Preferences for Hybrid Explanations.pdf:application/pdf;Kouki et al_2017_User Preferences for Hybrid Explanations.pdf:/Users/orsonxu/Zotero/storage/32BRVKLY/Kouki et al_2017_User Preferences for Hybrid Explanations.pdf:application/pdf},
}

@article{schick_let_2014,
	title = {Let {Me} {Explain}: {Impact} of {Personal} and {Impersonal} {Explanations} on {Trust} in {Recommender} {Systems}},
	doi = {10.5840/tpm20053149},
	abstract = {Extracts from Pierre Teilhard's major works are presented to provide a basic understanding of his thought},
	number = {31},
	journal = {The Philosophers' Magazine},
	author = {Schick, Theodore},
	year = {2014},
	keywords = {explanations, acm reference format, counterfactual analysis, Counterfactual Analysis, Explanations, recommender systems, Recommender Systems, struc-, Structural Equation Modelling, trust, Trust, tural equation modelling, user study, User Study},
	pages = {57--59},
	file = {Schick_2014_Let Me Explain.pdf:/Users/orsonxu/Zotero/storage/VBDXNBTX/Schick_2014_Let Me Explain.pdf:application/pdf;Schick_2014_Let Me Explain.pdf:/Users/orsonxu/Zotero/storage/UIJJPRL8/Schick_2014_Let Me Explain.pdf:application/pdf},
}

@article{zanker_influence_2012,
	title = {The influence of knowledgeable explanations on users' perception of a recommender system},
	doi = {10.1145/2365952.2366011},
	abstract = {Recommender Systems (RS) help online customers in identifying those items from a variety of choices that best match their presumed needs and preferences. In this context explanations summarize the reasons why a specific item is proposed and are capable of increasing the users' trust in the system's results. This paper presents results from an online experiment on a real-world platform indicating that explanations are an essential piece of functionality of a recommendation system, that significantly increases users' perception of the utility of a recommender system, the intention to use it repeatedly as well as the commitment to recommend it to others. Copyright © 2012 by the Association for Computing Machinery, Inc. (ACM).},
	author = {Zanker, Markus},
	year = {2012},
	keywords = {explanations, knowledge-based recommendation},
	pages = {269},
	file = {Zanker_2012_The influence of knowledgeable explanations on users' perception of a recommender system.pdf:/Users/orsonxu/Zotero/storage/QEYZIITZ/Zanker_2012_The influence of knowledgeable explanations on users' perception of a recommender system.pdf:application/pdf;Zanker_2012_The influence of knowledgeable explanations on users' perception of a recommender system.pdf:/Users/orsonxu/Zotero/storage/8KRWIBXE/Zanker_2012_The influence of knowledgeable explanations on users' perception of a recommender system.pdf:application/pdf},
}

@article{mcinerney_explore_2018,
	title = {Explore, exploit, and explain: personalizing explainable recommendations with bandits},
	doi = {10.1145/3240323.3240354},
	abstract = {The multi-armed bandit is an important framework for balancing exploration with exploitation in recommendation. Exploitation recommends content (e.g., products, movies, music playlists) with the highest predicted user engagement and has traditionally been the focus of recommender systems. Exploration recommends content with uncertain predicted user engagement for the purpose of gathering more information. The importance of exploration has been recognized in recent years, particularly in settings with new users, new items, non-stationary preferences and attributes. In parallel, explaining recommendations ("recsplanations") is crucial if users are to understand their recommendations. Existing work has looked at bandits and explanations independently. We provide the first method that combines both in a principled manner. In particular, our method is able to jointly (1) learn which explanations each user responds to; (2) learn the best content to recommend for each user; and (3) balance exploration with exploitation to deal with uncertainty. Experiments with historical log data and tests with live production traffic in a large-scale music recommendation service show a significant improvement in user engagement.},
	journal = {12th ACM Conference on Recommender Systems},
	author = {McInerney, James and Lacker, Benjamin and Hansen, Samantha and Higley, Karl and Bouchard, Hugues and Gruson, Alois and Mehrotra, Rishabh},
	year = {2018},
	pages = {31--39},
	file = {McInerney et al_2018_Explore, exploit, and explain.pdf:/Users/orsonxu/Zotero/storage/8H6ZYTI9/McInerney et al_2018_Explore, exploit, and explain.pdf:application/pdf;McInerney et al_2018_Explore, exploit, and explain.pdf:/Users/orsonxu/Zotero/storage/2RZKJZMV/McInerney et al_2018_Explore, exploit, and explain.pdf:application/pdf},
}

@article{chen_explaining_2017,
	title = {Explaining {Recommendations} {Based} on {Feature} {Sentiments} in {Product} {Reviews}},
	doi = {10.1145/3025171.3025173},
	abstract = {The explanation interface has been recognized important in recommender systems as it can help users evaluate recommen-dations in a more informed way for deciding which ones are relevant to their interests. In different decision environments, the specific aim of explanation can be different. In high-investment product domains (e.g., digital cameras, laptops) for which users usually attempt to avoid financial risk, how to support users to construct stable preferences and make better decisions is particularly crucial. In this paper, we propose a novel explanation interface that emphasizes explaining the tradeoff properties within a set of recommendations in terms of both their static specifications and feature sentiments extracted from product reviews. The objective is to assist users in more effectively exploring and understanding product space, and being able to better formulate their preferences for products by learning from other customers' experiences. Through two user studies (in form of both before-after and within-subjects experiments), we empirically identify the practical role of feature sentiments in combination with static specifications in producing tradeoff-oriented explanations. Specifically, we find that our explanation interface can be more effective to increase users' product knowledge, preference certainty, per-ceived information usefulness, recommendation transparency and quality, and purchase intention.},
	author = {Chen, Li and Wang, Feng},
	year = {2017},
	pages = {17--28},
	file = {Chen_Wang_2017_Explaining Recommendations Based on Feature Sentiments in Product Reviews.pdf:/Users/orsonxu/Zotero/storage/ESYWKUP2/Chen_Wang_2017_Explaining Recommendations Based on Feature Sentiments in Product Reviews.pdf:application/pdf;Chen_Wang_2017_Explaining Recommendations Based on Feature Sentiments in Product Reviews.pdf:/Users/orsonxu/Zotero/storage/2C7AEACH/Chen_Wang_2017_Explaining Recommendations Based on Feature Sentiments in Product Reviews.pdf:application/pdf},
}

@article{chang_crowd-based_2016,
	title = {Crowd-{Based} {Personalized} {Natural} {Language} {Explanations} for {Recommendations}},
	doi = {10.1145/2959100.2959153},
	abstract = {Explanations are important for users to make decisions on whether to take recommendations. However, algorithm gen-erated explanations can be overly simplistic and unconvinc-ing. We believe that humans can overcome these limita-tions. Inspired by how people explain word-of-mouth rec-ommendations, we designed a process, combining crowd-sourcing and computation, that generates personalized nat-ural language explanations. We modeled key topical as-pects of movies, asked crowdworkers to write explanations based on quotes from online movie reviews, and personal-ized the explanations presented to users based on their rat-ing history. We evaluated the explanations by surveying 220 MovieLens users, finding that compared to personalized tag-based explanations, natural language explanations: 1) con-tain a more appropriate amount of information, 2) earn more trust from users, and 3) make users more satisfied. This paper contributes to the research literature by describing a scalable process for generating high quality and personalized natural language explanations, improving on state-of-the-art content-based explanations, and showing the feasibility and advantages of approaches that combine human wisdom with algorithmic processes.},
	author = {Chang, Shuo and Harper, F. Maxwell and Terveen, Loren Gilbert},
	year = {2016},
	keywords = {crowdsourcing, clustering, guage processing, natural lan-, recommendation explanations, word2vec},
	pages = {175--182},
	file = {Chang et al_2016_Crowd-Based Personalized Natural Language Explanations for Recommendations.pdf:/Users/orsonxu/Zotero/storage/HDG3PMLE/Chang et al_2016_Crowd-Based Personalized Natural Language Explanations for Recommendations.pdf:application/pdf;Chang et al_2016_Crowd-Based Personalized Natural Language Explanations for Recommendations.pdf:/Users/orsonxu/Zotero/storage/YSVDB6R6/Chang et al_2016_Crowd-Based Personalized Natural Language Explanations for Recommendations.pdf:application/pdf},
}

@article{garcia-chamizo_building_2015,
	title = {Building {Personalized} {Activity} {Recognition} {Models} with {Scarce} {Labeled} {Data} based on {Class} {Similarities}},
	volume = {9454},
	issn = {16113349},
	doi = {10.1007/978-3-319-26401-1},
	abstract = {Recent advancements in the fields of embedded systems, communication technologies and computer science open up to new appli- cation scenarios in the home environment. Anyway, many issues raised from the inherent complexity of this new application domain need to be properly tackled. This paper proposes the Cloud-assisted Agent-based Smart home Environment (CASE) architecture for activity recognition with sensors capturing the data related to activities being performed by humans and objects in the environment. Moreover, the potential of ana- lytics methods for discovering activity recognition in such environment has been investigated. CASE easily allows to implement Smart Home applications exploiting a distributed multi-agent system and the cloud technology. The work is mainly focused on activity recognition albeit CASE architecture permits an easy integration of other kinds of smart home applications such as home automation and energy optimization. The CASE effectiveness is shown through the design of a case study consisting of a daily activity recognition of an elder person in its home environment.},
	number = {January 2016},
	journal = {UCAmI 2015: Ubiquitous Computing and Ambient Intelligence. Sensing, Processing, and Using Environmental Information},
	author = {García-Chamizo, Juan M. and Fortino, Giancarlo and Ochoa, Sergio F.},
	year = {2015},
	file = {García-Chamizo et al_2015_Building Personalized Activity Recognition Models with Scarce Labeled Data based on Class Similarities.pdf:/Users/orsonxu/Zotero/storage/TZPI367W/García-Chamizo et al_2015_Building Personalized Activity Recognition Models with Scarce Labeled Data based on Class Similarities.pdf:application/pdf;García-Chamizo et al_2015_Building Personalized Activity Recognition Models with Scarce Labeled Data based on Class Similarities.pdf:/Users/orsonxu/Zotero/storage/TSBMTE29/García-Chamizo et al_2015_Building Personalized Activity Recognition Models with Scarce Labeled Data based on Class Similarities.pdf:application/pdf},
}

@article{sukor_hybrid_2019,
	title = {A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes},
	volume = {36},
	issn = {18758967},
	doi = {10.3233/JIFS-169976},
	number = {5},
	journal = {Journal of Intelligent and Fuzzy Systems},
	author = {Sukor, Abdul Syafiq Abdull and Zakaria, Ammar and Rahim, Norasmadi Abdul and Kamarudin, Latifah Munirah and Setchi, Rossi and Nishizaki, Hiromitsu},
	year = {2019},
	keywords = {Activity model, Activity recognition, Data-driven approaches, Hybrid reasoning, Knowledge-driven approaches},
	pages = {4177--4188},
	file = {Sukor et al_2019_A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes.pdf:/Users/orsonxu/Zotero/storage/XF37374U/Sukor et al_2019_A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes.pdf:application/pdf;Sukor et al_2019_A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes.pdf:/Users/orsonxu/Zotero/storage/S5ZQAFEZ/Sukor et al_2019_A hybrid approach of knowledge-driven and data-driven reasoning for activity recognition in smart homes.pdf:application/pdf},
}

@article{utsumil_personalized_2018,
	title = {Personalized {Gaussian} {Processes} for {Forecasting} of {Alzheimer}'s {Disease} {Assessment} {Scale}-{Cognition} {Sub}-{Scale} ({ADAS}-{Cog13})},
	volume = {2018-July},
	issn = {1557170X},
	doi = {10.1109/EMBC.2018.8513253},
	abstract = {In this paper, we introduce the use of a personalized Gaussian Process model (pGP) to predict per-patient changes in ADAS-Cog13 -- a significant predictor of Alzheimer's Disease (AD) in the cognitive domain -- using data from each patient's previous visits, and testing on future (held-out) data. We start by learning a population-level model using multi-modal data from previously seen patients using a base Gaussian Process (GP) regression. The personalized GP (pGP) is formed by adapting the base GP sequentially over time to a new (target) patient using domain adaptive GPs. We extend this personalized approach to predict the values of ADAS-Cog13 over the future 6, 12, 18, and 24 months. We compare this approach to a GP model trained only on past data of the target patients (tGP), as well as to a new approach that combines pGP with tGP. We find that the new approach, combining pGP with tGP, leads to large improvements in accurately forecasting future ADAS-Cog13 scores.},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	author = {Utsumil, Yuria and Rudovicl, Ognjen Oggi and Petersonl, Kelly and Guerrero, Ricardo and Picardl, Rosalind W.},
	year = {2018},
	pages = {4007--4011},
	file = {Utsumil et al_2018_Personalized Gaussian Processes for Forecasting of Alzheimer's Disease Assessment Scale-Cognition Sub-Scale (ADAS-Cog13).pdf:/Users/orsonxu/Zotero/storage/NX9L6DDA/Utsumil et al_2018_Personalized Gaussian Processes for Forecasting of Alzheimer's Disease Assessment Scale-Cognition Sub-Scale (ADAS-Cog13).pdf:application/pdf;Utsumil et al_2018_Personalized Gaussian Processes for Forecasting of Alzheimer's Disease Assessment Scale-Cognition Sub-Scale (ADAS-Cog13).pdf:/Users/orsonxu/Zotero/storage/IGZIT9C4/Utsumil et al_2018_Personalized Gaussian Processes for Forecasting of Alzheimer's Disease Assessment Scale-Cognition Sub-Scale (ADAS-Cog13).pdf:application/pdf},
}

@article{yang_personalized_2014,
	title = {Personalized modeling of facial action unit intensity},
	volume = {8888},
	issn = {16113349},
	abstract = {© Springer International Publishing Switzerland 2014. Facial expressions depend greatly on facial morphology and expressiveness of the observed person. Recent studies have shown great improvement of the personalized over non-personalized models in variety of facial expression related tasks, such as face and emotion recognition. However, in the context of facial action unit (AU) intensity estimation, personalized modeling has been scarcely investigated. In this paper, we propose a two-step approach for personalized modeling of facial AU intensity from spontaneously displayed facial expressions. In the first step, we perform facial feature decomposition using the proposed matrix decomposition algorithm that separates the person’s identity from facial expression. These two are then jointly modeled using the framework of Conditional Ordinal Random Fields, resulting in a personalized model for intensity estimation of AUs. Our experimental results show that the proposed personalized model largely outperforms non-personalized models for intensity estimation of AUs.},
	journal = {International Symposium on Visual Computing},
	author = {Yang, Shuang and Rudovic, Ognjen and Pavlovic, Vladimir and Pantic, Maja},
	year = {2014},
	pages = {269--281},
	file = {Yang et al_2014_Personalized modeling of facial action unit intensity.pdf:/Users/orsonxu/Zotero/storage/HL4H4VWL/Yang et al_2014_Personalized modeling of facial action unit intensity.pdf:application/pdf;Yang et al_2014_Personalized modeling of facial action unit intensity.pdf:/Users/orsonxu/Zotero/storage/8QE6BBJL/Yang et al_2014_Personalized modeling of facial action unit intensity.pdf:application/pdf},
}

@article{arapakis_comparison_2010,
	title = {A comparison of general vs personalised affective models for the prediction of topical relevance},
	doi = {10.1145/1835449.1835512},
	abstract = {Information retrieval systems face a number of challenges, originating mainly from the semantic gap problem. Implicit feedback techniques have been employed in the past to address many of these issues. Although this was a step towards the right direction, a need to personalise and tailor the search experience to the user-specific needs has become evident. In this study we examine ways of personalising affective models trained on facial expression data. Using personalised data we adapt these models to individual users and compare their performance to a general model. The main goal is to determine whether the behavioural differences of users have an impact on the models' ability to determine topical relevance and if, by personalising them, we can improve their accuracy. For modelling relevance we extract a set of features from the facial expression data and classify them using Support Vector Machines. Our initial evaluation indicates that accounting for individual differences and applying personalisation introduces, in most cases, a noticeable improvement in the models' performance.},
	journal = {SIGIR 2010 Proceedings - 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Arapakis, Ioannis and Athanasakos, Konstantinos and Jose, Joemon M.},
	year = {2010},
	keywords = {Human factors, Experimentation, Performance},
	pages = {371--378},
	file = {Arapakis et al_2010_A comparison of general vs personalised affective models for the prediction of topical relevance.pdf:/Users/orsonxu/Zotero/storage/SIFGHI46/Arapakis et al_2010_A comparison of general vs personalised affective models for the prediction of topical relevance.pdf:application/pdf;Arapakis et al_2010_A comparison of general vs personalised affective models for the prediction of topical relevance.pdf:/Users/orsonxu/Zotero/storage/2W25V2WR/Arapakis et al_2010_A comparison of general vs personalised affective models for the prediction of topical relevance.pdf:application/pdf},
}

@article{shrikumar_learning_2017,
	title = {Learning important features through propagating activation differences},
	volume = {7},
	abstract = {The purported "black box"' nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. A detailed video tutorial on the method is at http://goo.gl/qKb7pL and code is at http://goo.gl/RM8jvH.},
	journal = {34th International Conference on Machine Learning, ICML 2017},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	year = {2017},
	pages = {4844--4866},
	file = {Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:/Users/orsonxu/Zotero/storage/SJNUF7A6/Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:application/pdf;Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:/Users/orsonxu/Zotero/storage/Y6NZD2BJ/Shrikumar et al_2017_Learning important features through propagating activation differences.pdf:application/pdf},
}

@article{liu_deepfacelift:_2017,
	title = {{DeepFaceLIFT}: {Interpretable} {Personalized} {Models} for {Automatic} {Estimation} of {Self}-{Reported} {Pain}},
	volume = {66},
	url = {http://arxiv.org/abs/1708.04670},
	abstract = {Previous research on automatic pain estimation from facial expressions has focused primarily on "one-size-fits-all" metrics (such as PSPI). In this work, we focus on directly estimating each individual's self-reported visual-analog scale (VAS) pain metric, as this is considered the gold standard for pain measurement. The VAS pain score is highly subjective and context-dependent, and its range can vary significantly among different persons. To tackle these issues, we propose a novel two-stage personalized model, named DeepFaceLIFT, for automatic estimation of VAS. This model is based on (1) Neural Network and (2) Gaussian process regression models, and is used to personalize the estimation of self-reported pain via a set of hand-crafted personal features and multi-task learning. We show on the benchmark dataset for pain analysis (The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed personalized model largely outperforms the traditional, unpersonalized models: the intra-class correlation improves from a baseline performance of 19{\textbackslash}\% to a personalized performance of 35{\textbackslash}\% while also providing confidence in the model{\textbackslash}textquotesingle s estimates -- in contrast to existing models for the target task. Additionally, DeepFaceLIFT automatically discovers the pain-relevant facial regions for each person, allowing for an easy interpretation of the pain-related facial cues.},
	journal = {Journal of Machine Learning Research},
	author = {Liu, Dianbo and Peng, Fengjiao and Shea, Andrew and Ognjen, Rudovic and Picard, Rosalind},
	year = {2017},
	pages = {1--16},
	file = {Liu et al_2017_DeepFaceLIFT.pdf:/Users/orsonxu/Zotero/storage/DLYWT7C3/Liu et al_2017_DeepFaceLIFT.pdf:application/pdf;Liu et al_2017_DeepFaceLIFT.pdf:/Users/orsonxu/Zotero/storage/AISQZ6E8/Liu et al_2017_DeepFaceLIFT.pdf:application/pdf},
}

@article{lopez-martinez_physiological_2017,
	title = {Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning},
	url = {http://arxiv.org/abs/1711.04036},
	abstract = {Pain is a subjective experience commonly measured through patient's self report. While there exist numerous situations in which automatic pain estimation methods may be preferred, inter-subject variability in physiological and behavioral pain responses has hindered the development of such methods. In this work, we address this problem by introducing a novel personalized multitask machine learning method for pain estimation based on individual physiological and behavioral pain response profiles, and show its advantages in a dataset containing multimodal responses to nociceptive heat pain.},
	number = {i},
	author = {Lopez-Martinez, Daniel and Rudovic, Ognjen and Picard, Rosalind},
	year = {2017},
	pages = {1--6},
	file = {Lopez-Martinez et al_2017_Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning.pdf:/Users/orsonxu/Zotero/storage/VLY8M92P/Lopez-Martinez et al_2017_Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning.pdf:application/pdf;Lopez-Martinez et al_2017_Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning.pdf:/Users/orsonxu/Zotero/storage/NSAWK8F9/Lopez-Martinez et al_2017_Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning.pdf:application/pdf},
}

@article{rudovic_meta-weighted_2019,
	title = {Meta-{Weighted} {Gaussian} {Process} {Experts} for {Personalized} {Forecasting} of {AD} {Cognitive} {Changes}},
	volume = {2050},
	url = {http://arxiv.org/abs/1904.09370},
	abstract = {We introduce a novel personalized Gaussian Process Experts (pGPE) model for predicting per-subject ADAS-Cog13 cognitive scores -- a significant predictor of Alzheimer's Disease (AD) in the cognitive domain -- over the future 6, 12, 18, and 24 months. We start by training a population-level model using multi-modal data from previously seen subjects using a base Gaussian Process (GP) regression. Then, we personalize this model by adapting the base GP sequentially over time to a new (target) subject using domain adaptive GPs, and also by training subject-specific GP. While we show that these models achieve improved performance when selectively applied to the forecasting task (one performs better than the other on different subjects/visits), the average performance per model is suboptimal. To this end, we used the notion of meta learning in the proposed pGPE to design a regression-based weighting of these expert models, where the expert weights are optimized for each subject and his/her future visit. The results on a cohort of subjects from the ADNI dataset show that this newly introduced personalized weighting of the expert models leads to large improvements in accurately forecasting future ADAS-Cog13 scores and their fine-grained changes associated with the AD progression. This approach has potential to help identify at-risk patients early and improve the construction of clinical trials for AD.},
	author = {Rudovic, Ognjen and Utsumi, Yuria and Guerrero, Ricardo and Peterson, Kelly and Rueckert, Daniel and Picard, Rosalind W.},
	year = {2019},
	pages = {1--15},
	file = {Rudovic et al_2019_Meta-Weighted Gaussian Process Experts for Personalized Forecasting of AD Cognitive Changes.pdf:/Users/orsonxu/Zotero/storage/PCTQXA9Z/Rudovic et al_2019_Meta-Weighted Gaussian Process Experts for Personalized Forecasting of AD Cognitive Changes.pdf:application/pdf;Rudovic et al_2019_Meta-Weighted Gaussian Process Experts for Personalized Forecasting of AD Cognitive Changes.pdf:/Users/orsonxu/Zotero/storage/9SAW5HMD/Rudovic et al_2019_Meta-Weighted Gaussian Process Experts for Personalized Forecasting of AD Cognitive Changes.pdf:application/pdf},
}

@article{lockhart_benefits_2014,
	title = {The benefits of personalized smartphone-based activity recognition models},
	volume = {2},
	doi = {10.1137/1.9781611973440.71},
	abstract = {Activity recognition allows ubiquitous mobile devices like smartphones to be context-aware and also enables new applications, such as mobile health applications that track a user's activities over time. However, it is difficult for smartphonebased activity recognition models to perform well, since only a single body location is instrumented. Most research focuses on universal/impersonal activity recognition models, where the model is trained using data from a panel of representative users. In this paper we compare the performance of these impersonal models with those of personal models, which are trained using labeled data from the intended user, and hybrid models, which combine aspects of both types of models. Our analysis indicates that personal training data is required for high accuracybut that only a very small amount of training data is necessary. This conclusion led us to implement a self-training capability into our Actitracker smartphone-based activity recognition system [l], and we believe personal models can also benefit other activity recognition systems as well.},
	journal = {SIAM International Conference on Data Mining 2014, SDM 2014},
	author = {Lockhart, Jeffrey W. and Weiss, Gary M.},
	year = {2014},
	pages = {614--622},
	file = {Lockhart_Weiss_2014_The benefits of personalized smartphone-based activity recognition models.pdf:/Users/orsonxu/Zotero/storage/W3VQYNZN/Lockhart_Weiss_2014_The benefits of personalized smartphone-based activity recognition models.pdf:application/pdf;Lockhart_Weiss_2014_The benefits of personalized smartphone-based activity recognition models.pdf:/Users/orsonxu/Zotero/storage/TMJSK8XY/Lockhart_Weiss_2014_The benefits of personalized smartphone-based activity recognition models.pdf:application/pdf},
}

@article{abdullah_towards_2012,
	title = {Towards population scale activity recognition: {A} framework for handling data diversity},
	volume = {2},
	abstract = {The rising popularity of the sensor-equipped smartphone is changing the possible scale and scope of human activity inference. The diversity in user population seen in large user bases can overwhelm conventional one-size-fits-all classication approaches. Although personalized models are better able to handle population diversity, they often require increased effort from the end user during training and are computationally expensive. In this paper, we propose an activity classification framework that is scalable and can tractably handle an increasing number of users. Scalability is achieved by maintaining distinct groups of similar users during the training process, which makes it possible to account for the differences between users without resorting to training individualized classifiers. The proposed framework keeps user burden low by leveraging crowd-sourced data labels, where simple natural language processing techniques in combination with multiinstance learning are used to handle labeling errors introduced by low-commitment everyday users. Experiment results on a large public dataset demonstrate that the framework can cope with population diversity irrespective of population size. Copyright © 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.},
	journal = {Proceedings of the National Conference on Artificial Intelligence},
	author = {Abdullah, Saeed and Lane, Nicholas D. and Choudhury, Tanzeem},
	year = {2012},
	keywords = {Machine Learning (Main Track)},
	pages = {851--857},
	file = {Abdullah et al_2012_Towards population scale activity recognition.pdf:/Users/orsonxu/Zotero/storage/5TRN93C8/Abdullah et al_2012_Towards population scale activity recognition.pdf:application/pdf;Abdullah et al_2012_Towards population scale activity recognition.pdf:/Users/orsonxu/Zotero/storage/XPQP6IXR/Abdullah et al_2012_Towards population scale activity recognition.pdf:application/pdf},
}

@article{zhang_personalized_2010,
	title = {Personalized recommendation via integrated diffusion on user-item-tag tripartite graphs},
	volume = {389},
	issn = {03784371},
	doi = {10.1016/j.physa.2009.08.036},
	abstract = {Personalized recommender systems are confronting great challenges of accuracy, diversification and novelty, especially when the data set is sparse and lacks accessorial information, such as user profiles, item attributes and explicit ratings. Collaborative tags contain rich information about personalized preferences and item contents, and are therefore potential to help in providing better recommendations. In this article, we propose a recommendation algorithm based on an integrated diffusion on user-item-tag tripartite graphs. We use three benchmark data sets, Del.icio.us, MovieLens and BibSonomy, to evaluate our algorithm. Experimental results demonstrate that the usage of tag information can significantly improve accuracy, diversification and novelty of recommendations. © 2009 Elsevier B.V. All rights reserved.},
	number = {1},
	journal = {Physica A: Statistical Mechanics and its Applications},
	author = {Zhang, Zi Ke and Zhou, Tao and Zhang, Yi Cheng},
	year = {2010},
	keywords = {Complex networks, Diffusion, Folksonomy, Infophysics, Personalized recommendation},
	pages = {179--186},
	file = {Zhang et al_2010_Personalized recommendation via integrated diffusion on user-item-tag tripartite graphs.pdf:/Users/orsonxu/Zotero/storage/XLS6FFNE/Zhang et al_2010_Personalized recommendation via integrated diffusion on user-item-tag tripartite graphs.pdf:application/pdf;Zhang et al_2010_Personalized recommendation via integrated diffusion on user-item-tag tripartite graphs.pdf:/Users/orsonxu/Zotero/storage/8Q9HCC69/Zhang et al_2010_Personalized recommendation via integrated diffusion on user-item-tag tripartite graphs.pdf:application/pdf},
}

@article{hong_toward_2016,
	title = {Toward {Personalized} {Activity} {Recognition} {Systems} with a {Semipopulation} {Approach}},
	volume = {46},
	issn = {21682291},
	doi = {10.1109/THMS.2015.2489688},
	abstract = {Activity recognition is a key component of context-Aware computing to support people's physical activity, but conventional approaches often lack in their generalizability and scalability due to problems of diversity in how individuals perform activities, overfitting when building activity models, and collection of a large amount of labeled data from end users. To address these limitations, we propose a semipopulation-based approach that exploits activity models trained from other users; therefore, a new user does not need to provide a large volume of labeled activity data. Instead of relying on any additional information from users like their weight or height, our approach directly measures the fitness of others' models on a small amount of labeled data collected from the new user. With these shared activity models among users, we compose a hybrid model of Bayesian networks and support vector machines to accurately recognize the activity of the new user. On activity data collected from 28 people with a diversity in gender, age, weight, and height, our approach produced an average accuracy of 83.4\% (kappa: 0.852), compared with individual and (standard) population models that had accuracies of 77.3\% (kappa: 0.79) and 77.7\% (kappa: 0.743), respectively. Through an analysis on the performance of our approach and users' demographic information, our approach outperforms others that rely on users' demographic information for recognizing their activities, which may contradict the commonly held belief that physically similar people would have similar activity patterns.},
	number = {1},
	journal = {IEEE Transactions on Human-Machine Systems},
	author = {Hong, Jin Hyuk and Ramos, Julian and Dey, Anind K.},
	year = {2016},
	keywords = {ubiquitous computing, Pattern recognition, sensor systems and applications},
	pages = {101--112},
	file = {Hong et al_2016_Toward Personalized Activity Recognition Systems with a Semipopulation Approach.pdf:/Users/orsonxu/Zotero/storage/HV226XGB/Hong et al_2016_Toward Personalized Activity Recognition Systems with a Semipopulation Approach.pdf:application/pdf;Hong et al_2016_Toward Personalized Activity Recognition Systems with a Semipopulation Approach.pdf:/Users/orsonxu/Zotero/storage/8VIJFH9Z/Hong et al_2016_Toward Personalized Activity Recognition Systems with a Semipopulation Approach.pdf:application/pdf},
}

@article{lane_enabling_2011,
	title = {Enabling large-scale human activity inference on smartphones using {Community} {Similarity} {Networks} ({CSN})},
	doi = {10.1145/2030112.2030160},
	abstract = {Sensor-enabled smartphones are opening a new frontier in the development of mobile sensing applications. The recognition of human activities and context from sensor-data using classification models underpins these emerging applications. However, conventional approaches to training classifiers struggle to cope with the diverse user populations routinely found in large-scale popular mobile applications. Differences between users (e.g., age, sex, behavioral patterns, lifestyle) confuse classifiers, which assume everyone is the same. To address this, we propose Community Similarity Networks (CSN), which incorporates inter-person similarity measurements into the classifier training process. Under CSN every user has a unique classifier that is tuned to their own characteristics. CSN exploits crowd-sourced sensor-data to personalize classifiers with data contributed from other similar users. This process is guided by similarity networks that measure different dimensions of inter-person similarity. Our experiments show CSN outperforms existing approaches to classifier training under the presence of population diversity. © 2011 ACM.},
	journal = {UbiComp'11 - Proceedings of the 2011 ACM Conference on Ubiquitous Computing},
	author = {Lane, Nicholas D. and Xu, Ye and Lu, Hong and Hu, Shaohan and Choudhury, Tanzeem and Campbell, Andrew T. and Zhao, Feng},
	year = {2011},
	keywords = {activity recognition, community learning, mobile phone sensing},
	pages = {355--364},
	file = {Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:/Users/orsonxu/Zotero/storage/SJS7EG6U/Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:application/pdf;Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:/Users/orsonxu/Zotero/storage/QPUJ7B99/Lane et al_2011_Enabling large-scale human activity inference on smartphones using Community Similarity Networks (CSN).pdf:application/pdf},
}

@article{guy_personalized_2009,
	title = {Personalized recommendation of social software items based on social relations},
	doi = {10.1145/1639714.1639725},
	abstract = {We study personalized recommendation of social software items, including bookmarked web-pages, blog entries, and communities. We focus on recommendations that are derived from the user's social network. Social network information is collected and aggregated across different data sources within our organization. At the core of our research is a comparison between recommendations that are based on the user's familiarity network and his/her similarity network. We also examine the effect of adding explanations to each recommended item that show related people and their relationship to the user and to the item. Evaluation, based on an extensive user survey with 290 participants and a field study including 90 users, indicates superiority of the familiarity network as a basis for recommendations. In addition, an important instant effect of explanations is found - interest rate in recommended items increases when explanations are provided. Copyright 2009 ACM.},
	journal = {RecSys'09 - Proceedings of the 3rd ACM Conference on Recommender Systems},
	author = {Guy, Ido and Zwerdling, Naama and Carmel, David and Ronen, Inbal and Uziel, Erel and Yogev, Sivan and Ofek-Koifman, Shila},
	year = {2009},
	keywords = {Social media, Personalization, Recommender systems, Social networks, Social software},
	pages = {53--60},
	file = {Guy et al_2009_Personalized recommendation of social software items based on social relations.pdf:/Users/orsonxu/Zotero/storage/ZVIA2Y2K/Guy et al_2009_Personalized recommendation of social software items based on social relations.pdf:application/pdf;Guy et al_2009_Personalized recommendation of social software items based on social relations.pdf:/Users/orsonxu/Zotero/storage/JZSIT4BF/Guy et al_2009_Personalized recommendation of social software items based on social relations.pdf:application/pdf},
}

@article{yu_personalized_2014,
	title = {Personalized entity recommendation: {A} heterogeneous information network approach},
	doi = {10.1145/2556195.2556259},
	abstract = {Among different hybrid recommendation techniques, network-based entity recommendation methods, which utilize user or item relationship information, are beginning to attract increasing attention recently. Most of the previous studies in this category only consider a single relationship type, such as friendships in a social network. In many scenarios, the entity recommendation problem exists in a heterogeneous information network environment. Different types of relationships can be potentially used to improve the recommendation quality. In this paper, we study the entity recommendation problem in heterogeneous information networks. Specifically, we propose to combine heterogeneous relationship information for each user differently and aim to provide high-quality personalized recommendation results using user implicit feedback data and personalized recommendation models. In order to take full advantage of the relationship heterogeneity in information networks, we first introduce meta-path-based latent features to represent the connectivity between users and items along different types of paths. We then define recommendation models at both global and personalized levels and use Bayesian ranking optimization techniques to estimate the proposed models. Empirical studies show that our approaches outperform several widely employed or the state-of-the-art entity recommendation techniques. © 2014 ACM.},
	journal = {WSDM 2014 - Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
	author = {Yu, Xiao and Ren, Xiang and Sun, Yizhou and Gu, Quanquan and Sturt, Bradley and Khandelwal, Urvashi and Norick, Brandon and Han, Jiawei},
	year = {2014},
	keywords = {hybrid recommender system, information network},
	pages = {283--292},
	file = {Yu et al_2014_Personalized entity recommendation.pdf:/Users/orsonxu/Zotero/storage/A9AS79T3/Yu et al_2014_Personalized entity recommendation.pdf:application/pdf;Yu et al_2014_Personalized entity recommendation.pdf:/Users/orsonxu/Zotero/storage/BX8ENGME/Yu et al_2014_Personalized entity recommendation.pdf:application/pdf},
}

@article{zhao_cross-people_2011,
	title = {Cross-people mobile-phone based activity recognition},
	issn = {10450823},
	doi = {10.5591/978-1-57735-516-8/IJCAI11-423},
	abstract = {Activity recognition using mobile phones has great potential in many applications including mobile healthcare. In order to let a person easily know whether he is in strict compliance with the doctor's exercise prescription and adjust his exercise amount accordingly, we can use a smart-phone based activity reporting system to accurately recognize a range of daily activities and report the duration of each activity. A triaxial accelerometer embedded in the smart phone is used for the classification of several activities, such as staying still, walking, running, and going upstairs and downstairs. The model learnt from a specific person often cannot yield accurate results when used on a different person. To solve the cross-people activity recognition problem, we propose an algorithm known as TransEMDT (Transfer learning EMbedded Decision Tree) that integrates a decision tree and the k-means clustering algorithm for personalized activity-recognition model adaptation. Tested on a real-world data set, the results show that our algorithm outperforms several traditional baseline algorithms.},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	author = {Zhao, Zhongtang and Chen, Yiqiang and Liu, Junfa and Shen, Zhiqi and Liu, Mingjie},
	year = {2011},
	keywords = {Special Track on Integrated and Embedded Artificia},
	pages = {2545--2550},
	file = {Zhao et al_2011_Cross-people mobile-phone based activity recognition.pdf:/Users/orsonxu/Zotero/storage/5CNWYYKE/Zhao et al_2011_Cross-people mobile-phone based activity recognition.pdf:application/pdf;Zhao et al_2011_Cross-people mobile-phone based activity recognition.pdf:/Users/orsonxu/Zotero/storage/J9KFMW6E/Zhao et al_2011_Cross-people mobile-phone based activity recognition.pdf:application/pdf},
}

@article{sun_large-scale_2013,
	title = {Large-scale personalized human activity recognition using online multitask learning},
	volume = {25},
	issn = {10414347},
	doi = {10.1109/TKDE.2012.246},
	abstract = {Personalized activity recognition usually has the problem of highly biased activity patterns among different tasks/persons. Traditional methods face problems on dealing with those conflicted activity patterns. We try to effectively model the activity patterns among different persons via casting this personalized activity recognition problem as a multitask learning issue. We propose a novel online multitask learning method for large-scale personalized activity recognition. In contrast with existing work of multitask learning that assumes fixed task relationships, our method can automatically discover task relationships from real-world data. Convergence analysis shows reasonable convergence properties of the proposed method. Experiments on two different activity data sets demonstrate that the proposed method significantly outperforms existing methods in activity recognition. © 2013 IEEE.},
	number = {11},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Sun, Xu and Kashima, Hisashi and Ueda, Naonori},
	year = {2013},
	keywords = {data mining, conditional random fields, human activity recognition, Multitask learning, online learning},
	pages = {2551--2563},
	file = {Sun et al_2013_Large-scale personalized human activity recognition using online multitask learning.pdf:/Users/orsonxu/Zotero/storage/FBUQETKR/Sun et al_2013_Large-scale personalized human activity recognition using online multitask learning.pdf:application/pdf;Sun et al_2013_Large-scale personalized human activity recognition using online multitask learning.pdf:/Users/orsonxu/Zotero/storage/7MVLRCW9/Sun et al_2013_Large-scale personalized human activity recognition using online multitask learning.pdf:application/pdf},
}

@article{stikic_weakly_2011,
	title = {Weakly supervised recognition of daily life activities with wearable sensors},
	volume = {33},
	issn = {01628828},
	doi = {10.1109/TPAMI.2011.36},
	abstract = {This paper considers scalable and unobtrusive activity recognition using on-body sensing for context awareness in wearable computing. Common methods for activity recognition rely on supervised learning requiring substantial amounts of labeled training data. Obtaining accurate and detailed annotations of activities is challenging, preventing the applicability of these approaches in real-world settings. This paper proposes new annotation strategies that substantially reduce the required amount of annotation. We explore two learning schemes for activity recognition that effectively leverage such sparsely labeled data together with more easily obtainable unlabeled data. Experimental results on two public data sets indicate that both approaches obtain results close to fully supervised techniques. The proposed methods are robust to the presence of erroneous labels occurring in real-world annotation data. © 2011 IEEE.},
	number = {12},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Stikic, Maja and Larlus, Diane and Ebert, Sandra and Schiele, Bernt},
	year = {2011},
	keywords = {activity recognition, Wearable computing, semi-supervised learning, wearable sensing},
	pages = {2521--2537},
	file = {Stikic et al_2011_Weakly supervised recognition of daily life activities with wearable sensors.pdf:/Users/orsonxu/Zotero/storage/3GFRT95P/Stikic et al_2011_Weakly supervised recognition of daily life activities with wearable sensors.pdf:application/pdf;Stikic et al_2011_Weakly supervised recognition of daily life activities with wearable sensors.pdf:/Users/orsonxu/Zotero/storage/9T7KBFS7/Stikic et al_2011_Weakly supervised recognition of daily life activities with wearable sensors.pdf:application/pdf},
}

@article{yang_cross-domain_2007,
	title = {Cross-domain video concept detection using adaptive svms},
	doi = {10.1145/1291233.1291276},
	abstract = {Many multimedia applications can benefit from techniques for adapting existing classifiers to data with different distributions. One example is cross-domain video concept detection which aims to adapt concept classifiers across various video domains. In this paper, we explore two key problems for classifier adaptation: (1) how to transform existing classifier(s) into an effective classifier for a new dataset that only has a limited number of labeled examples, and (2) how to select the best existing classifier(s) for adaptation. For the first problem, we propose Adaptive Support Vector Machines (A-SVMs) as a general method to adapt one or more existing classifiers of any type to the new dataset. It aims to learn the "delta function" between the original and adapted classifier using an objective function similar to SVMs. For the second problem, we estimate the performance of each existing classifier on the sparsely-labeled new dataset by analyzing its score distribution and other meta features, and select the classifiers with the best estimated performance. The proposed method outperforms several baseline and competing methods in terms of classification accuracy and efficiency in cross-domain concept detection in the TRECVID corpus. Copyright 2007 ACM.},
	journal = {Proceedings of the ACM International Multimedia Conference and Exhibition},
	author = {Yang, Jun and Yan, Rong and Hauptmann, Alexander G.},
	year = {2007},
	keywords = {Adaptive SVMs, Classifier adaptation, Cross-domain video concept detection},
	pages = {188--197},
	file = {Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:/Users/orsonxu/Zotero/storage/U7SGUAG3/Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:application/pdf;Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:/Users/orsonxu/Zotero/storage/JF5K84G6/Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:application/pdf},
}

@article{pan_survey_2010,
	title = {A {Survey} on {Transfer} {Learning}},
	volume = {22},
	abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research. Index},
	number = {10},
	journal = {IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING},
	author = {Pan, Sinno Jialin and Yang, Qiang},
	year = {2010},
	pages = {1345--1359},
	file = {Pan_Yang_2010_A Survey on Transfer Learning.pdf:/Users/orsonxu/Zotero/storage/4MA2L9K9/Pan_Yang_2010_A Survey on Transfer Learning.pdf:application/pdf;Pan_Yang_2010_A Survey on Transfer Learning.pdf:/Users/orsonxu/Zotero/storage/ESHVHZ3C/Pan_Yang_2010_A Survey on Transfer Learning.pdf:application/pdf},
}

@article{gao_knowledge_2008,
	title = {Knowledge transfer via multiple model local structure mapping},
	doi = {10.1145/1401890.1401928},
	abstract = {The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribution that generates the training examples and the one from which test examples are to be drawn. The task can be especially difficult when the training examples are from one or several domains different from the test domain. In this paper, we propose a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model's predictive power on each test example. It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model, which can then be applied on a different domain. Importantly, different from many previously proposed methods, none of the base learning method is required to be specifically designed for transfer learning. We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer. We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain, and then weighting each model locally according to its consistency with the neighborhood structure around the test example. Experimental results on text classification, spam filtering and intrusion detection data sets demonstrate significant improvements in classification accuracy gained by the framework. On a transfer learning task of newsgroup message categorization, the proposed locally weighted ensemble framework achieves 97\% accuracy when the best single model predicts correctly only on 73\% of the test examples. In summary, the improvement in accuracy is over 10\% and up to 30\% across different problems. Copyright 2008 ACM.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Gao, Jing and Fan, Wei and Jiang, Jing and Han, Jiawei},
	year = {2008},
	keywords = {Algorithms},
	pages = {283--291},
	file = {Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:/Users/orsonxu/Zotero/storage/I7YVKMM6/Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:application/pdf;Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:/Users/orsonxu/Zotero/storage/BEKVX68Z/Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:application/pdf},
}

@article{dai_boosting_2007,
	title = {Boosting for transfer learning},
	volume = {227},
	doi = {10.1145/1273496.1273521},
	abstract = {Traditional machine learning makes a basic assumption: the training and test data should be under the same distribution. However, in many cases, this identical-distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this paper, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund \& Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be effectively transferred from the old data to the new. The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model.},
	journal = {ACM International Conference Proceeding Series},
	author = {Dai, Wenyuan and Yang, Qiang and Xue, Gui Rong and Yu, Yong},
	year = {2007},
	pages = {193--200},
	file = {Dai et al_2007_Boosting for transfer learning.pdf:/Users/orsonxu/Zotero/storage/5K27LSNV/Dai et al_2007_Boosting for transfer learning.pdf:application/pdf;Dai et al_2007_Boosting for transfer learning.pdf:/Users/orsonxu/Zotero/storage/5U32XF9B/Dai et al_2007_Boosting for transfer learning.pdf:application/pdf},
}

@inproceedings{amershi_guidelines_2019,
	address = {New York, New York, USA},
	title = {Guidelines for {Human}-{AI} {Interaction}},
	isbn = {978-1-4503-5970-2},
	url = {http://dl.acm.org/citation.cfm?doid=3290605.3300233},
	doi = {10.1145/3290605.3300233},
	abstract = {Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.},
	booktitle = {Proceedings of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems} - {CHI} '19},
	publisher = {ACM Press},
	author = {Amershi, Saleema and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N.},
	year = {2019},
	keywords = {AI-infused systems, Design guidelines, Human-AI interaction},
	pages = {1--13},
	file = {Amershi et al. - 2019 - Guidelines for Human-AI Interaction.pdf:/Users/orsonxu/Zotero/storage/U3V4Q3BR/Amershi et al. - 2019 - Guidelines for Human-AI Interaction.pdf:application/pdf},
}

@article{dawson_social_2014,
	title = {Social network analysis},
	doi = {10.4324/9781351044677-54},
	abstract = {The Third Edition of this best-selling text has been fully revised and updated to include coverage of the many developments on social network analysis (SNA) over the last decade. Written in a clear and accessible style, the book introduces these topics to newcomers and non-specialists and gives sufficient detail for more advanced users of social network analysis. Throughout the book, key ideas are discussed in relation to the principal software programs available for SNA. The book provides a comprehensive overview of the field, outlining both its theoretical basis and its key techniques. Drawing from the core ideas of points, lines and paths, John Scott builds a framework of network analysis that covers such measures as density, centrality, clustering, centralisation, and spatialisation. He identifies the various types of clique, component, and circle into which networks are formed, and he outlines an approach to socially structured positions within networks. A completely new chapter in this edition discusses recent work on network dynamics and methods for studying change over time. A final chapter discusses approaches to network visualisation. This is an excellent resource for researchers across the social sciences and for students of social theory and research methods.},
	journal = {A–Z of Digital Research Methods},
	author = {Dawson, Catherine and Dawson, Catherine},
	year = {2014},
	pages = {356--361},
	file = {Dawson_Dawson_2014_Social network analysis.pdf:/Users/orsonxu/Zotero/storage/HGSIKU3F/Dawson_Dawson_2014_Social network analysis.pdf:application/pdf;Dawson_Dawson_2014_Social network analysis.pdf:/Users/orsonxu/Zotero/storage/GXM3FCLI/Dawson_Dawson_2014_Social network analysis.pdf:application/pdf},
}

@article{dong_metapath2vec:_2017,
	title = {Metapath2vec: {Scalable} representation learning for heterogeneous networks},
	volume = {Part F1296},
	doi = {10.1145/3097983.3098036},
	abstract = {We study the problem of representation learning in heterogeneous networks. Its unique challenges come from the existence of multiple types of nodes and links, which limit the feasibility of the conventional network embedding techniques. We develop two scalable representation learning models, namely metapath2vec and metapath2vec++. The metapath2vec model formalizes meta-path-based random walks to construct the heterogeneous neighborhood of a node and then leverages a heterogeneous skip-gram model to perform node embeddings. The metapath2vec++ model further enables the simultaneous modeling of structural and semantic correlations in heterogeneous networks. Extensive experiments show that metapath2vec and metapath2vec++ are able to not only outperform state-of-the-art embedding models in various heterogeneous network mining tasks, such as node classification, clustering, and similarity search, but also discern the structural and semantic correlations between diverse network objects.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Dong, Yuxiao and Chawla, Nitesh V. and Swami, Ananthram},
	year = {2017},
	keywords = {Network embedding, Feature learning, Heterogeneous information networks, Heterogeneous representation learning, Latent representations},
	pages = {135--144},
}

@article{grover_node2vec:_2016,
	title = {Node2vec: {Scalable} feature learning for networks},
	volume = {13-17-Augu},
	doi = {10.1145/2939672.2939754},
	abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state of-the-art task-independent representations in complex networks.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Grover, Aditya and Leskovec, Jure},
	year = {2016},
	keywords = {Feature learning, Graph representations, Information networks, Node embeddings},
	pages = {855--864},
}

@article{visweswaran_learning_2010,
	title = {Learning instance-specific predictive models},
	volume = {11},
	issn = {15324435},
	abstract = {This paper introduces a Bayesian algorithm for constructing predictive models from data that are optimized to predict a target variable well for a particular instance. This algorithm learns Markov blanket models, carries out Bayesian model averaging over a set of models to predict a target variable of the instance at hand, and employs an instance-specific heuristic to locate a set of suitable models to average over. We call this method the instance-specific Markov blanket (ISMB) algorithm. The ISMB algorithm was evaluated on 21 UCI data sets using five different performance measures and its performance was compared to that of several commonly used predictive algorithms, including nave Bayes, C4.5 decision tree, logistic regression, neural networks, κ-Nearest Neighbor, Lazy Bayesian Rules, and AdaBoost. Over all the data sets, the ISMB algorithm performed better on average on all performance measures against all the comparison algorithms. © 2010 Shyam Visweswaran and Gregory F. Cooper.},
	journal = {Journal of Machine Learning Research},
	author = {Visweswaran, Shyam and Cooper, Gregory F.},
	year = {2010},
	keywords = {Bayesian model averaging, Bayesian network, Instance-specific, Markov blanket},
	pages = {3333--3369},
	file = {Visweswaran_Cooper_2010_Learning instance-specific predictive models.pdf:/Users/orsonxu/Zotero/storage/V8PII4S3/Visweswaran_Cooper_2010_Learning instance-specific predictive models.pdf:application/pdf;Visweswaran_Cooper_2010_Learning instance-specific predictive models.pdf:/Users/orsonxu/Zotero/storage/QENN2T3M/Visweswaran_Cooper_2010_Learning instance-specific predictive models.pdf:application/pdf},
}

@article{liu_personalized_2016,
	title = {Personalized characterization of diseases using sample-specific networks},
	volume = {44},
	issn = {13624962},
	doi = {10.1093/nar/gkw772},
	abstract = {A complex disease generally results not from malfunction of individual molecules but from dysfunction of the relevant system or network, which dynamically changes with time and conditions. Thus, estimating a condition-specific network from a single sample is crucial to elucidating the molecular mechanisms of complex diseases at the system level. However, there is currently no effective way to construct such an individual-specific network by expression profiling of a single sample because of the requirement of multiple samples for computing correlations. We developed here with a statistical method, i.e. a sample-specific network (SSN) method, which allows us to construct individual-specific networks based on molecular expressions of a single sample. Using this method, we can characterize various human diseases at a network level. In particular, such SSNs can lead to the identification of individual-specific disease modules as well as driver genes, even without gene sequencing information. Extensive analysis by using the Cancer Genome Atlas data not only demonstrated the effectiveness of the method, but also found new individual-specific driver genes and network patterns for various types of cancer. Biological experiments on drug resistance further validated one important advantage of our method over the traditional methods, i.e. we can even identify such drug resistance genes that actually have no clear differential expression between samples with and without the resistance, due to the additional network information. A complex disease generally results not from malfunction of individual molecules but from dysfunction of the relevant system or network, which dynamically changes with time and conditions. Thus, estimating a condition-specific network from a single sample is crucial to elucidating the molecular mechanisms of complex diseases at the system level. However, there is currently no effective way to construct such an individual-specific network by expression profiling of a single sample because of the requirement of multiple samples for computing correlations. We developed here with a statistical method, i.e. a sample-specific network (SSN) method, which allows us to construct individual-specific networks based on molecular expressions of a single sample. Using this method, we can characterize various human diseases at a network level. In particular, such SSNs can lead to the identification of individual-specific disease modules as well as driver genes, even without gene sequencing information. Extensive analysis by using the Cancer Genome Atlas data not only demonstrated the effectiveness of the method, but also found new individual-specific driver genes and network patterns for various types of cancer. Biological experiments on drug resistance further validated one important advantage of our method over the traditional methods, i.e. we can even identify such drug resistance genes that actually have no clear differential expression between samples with and without the resistance, due to the additional network information.},
	number = {22},
	journal = {Nucleic Acids Research},
	author = {Liu, Xiaoping and Wang, Yuetong and Ji, Hongbin and Aihara, Kazuyuki and Chen, Luonan},
	year = {2016},
	file = {Liu et al_2016_Personalized characterization of diseases using sample-specific networks.pdf:/Users/orsonxu/Zotero/storage/VAW7EUPF/Liu et al_2016_Personalized characterization of diseases using sample-specific networks.pdf:application/pdf;Liu et al_2016_Personalized characterization of diseases using sample-specific networks.pdf:/Users/orsonxu/Zotero/storage/A3GCRJMV/Liu et al_2016_Personalized characterization of diseases using sample-specific networks.pdf:application/pdf},
}

@article{lengerich_learning_2019,
	title = {Learning {Sample}-{Specific} {Models} with {Low}-{Rank} {Personalized} {Regression}},
	url = {http://arxiv.org/abs/1910.06939},
	abstract = {Modern applications of machine learning (ML) deal with increasingly heterogeneous datasets comprised of data collected from overlapping latent subpopulations. As a result, traditional models trained over large datasets may fail to recognize highly predictive localized effects in favour of weakly predictive global patterns. This is a problem because localized effects are critical to developing individualized policies and treatment plans in applications ranging from precision medicine to advertising. To address this challenge, we propose to estimate sample-specific models that tailor inference and prediction at the individual level. In contrast to classical ML models that estimate a single, complex model (or only a few complex models), our approach produces a model personalized to each sample. These sample-specific models can be studied to understand subgroup dynamics that go beyond coarse-grained class labels. Crucially, our approach does not assume that relationships between samples (e.g. a similarity network) are known a priori. Instead, we use unmodeled covariates to learn a latent distance metric over the samples. We apply this approach to financial, biomedical, and electoral data as well as simulated data and show that sample-specific models provide fine-grained interpretations of complicated phenomena without sacrificing predictive accuracy compared to state-of-the-art models such as deep neural networks.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lengerich, Benjamin and Aragam, Bryon and Xing, Eric P.},
	year = {2019},
	pages = {1--11},
	file = {Lengerich et al_2019_Learning Sample-Specific Models with Low-Rank Personalized Regression.pdf:/Users/orsonxu/Zotero/storage/XSCAK6B3/Lengerich et al_2019_Learning Sample-Specific Models with Low-Rank Personalized Regression.pdf:application/pdf;Lengerich et al_2019_Learning Sample-Specific Models with Low-Rank Personalized Regression.pdf:/Users/orsonxu/Zotero/storage/TARFNH6G/Lengerich et al_2019_Learning Sample-Specific Models with Low-Rank Personalized Regression.pdf:application/pdf},
}

@article{kallus_assessing_2019,
	title = {Assessing {Disparate} {Impacts} of {Personalized} {Interventions}: {Identifiability} and {Bounds}},
	url = {http://arxiv.org/abs/1906.01552},
	abstract = {Personalized interventions in social services, education, and healthcare leverage individual-level causal effect predictions in order to give the best treatment to each individual or to prioritize program interventions for the individuals most likely to benefit. While the sensitivity of these domains compels us to evaluate the fairness of such policies, we show that actually auditing their disparate impacts per standard observational metrics, such as true positive rates, is impossible since ground truths are unknown. Whether our data is experimental or observational, an individual's actual outcome under an intervention different than that received can never be known, only predicted based on features. We prove how we can nonetheless point-identify these quantities under the additional assumption of monotone treatment response, which may be reasonable in many applications. We further provide a sensitivity analysis for this assumption by means of sharp partial-identification bounds under violations of monotonicity of varying strengths. We show how to use our results to audit personalized interventions using partially-identified ROC and xROC curves and demonstrate this in a case study of a French job training dataset.},
	number = {NeurIPS},
	journal = {Advances in Neural Information Processing Systems},
	author = {Kallus, Nathan and Zhou, Angela},
	year = {2019},
	file = {Kallus_Zhou_2019_Assessing Disparate Impacts of Personalized Interventions.pdf:/Users/orsonxu/Zotero/storage/UB7CF5A9/Kallus_Zhou_2019_Assessing Disparate Impacts of Personalized Interventions.pdf:application/pdf;Kallus_Zhou_2019_Assessing Disparate Impacts of Personalized Interventions.pdf:/Users/orsonxu/Zotero/storage/6EFLTMS7/Kallus_Zhou_2019_Assessing Disparate Impacts of Personalized Interventions.pdf:application/pdf},
}

@article{alaa_bayesian_2017,
	title = {Bayesian inference of individualized treatment effects using multi-task {Gaussian} processes},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Predicated on the increasing abundance of electronic health records, we investigate the problem of inferring individualized treatment effects using observational data. Stemming from the potential outcomes model, we propose a novel multitask learning framework in which factual and counterfactual outcomes are modeled as the outputs of a function in a vector-valued reproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian method for learning the treatment effects using a multi-task Gaussian process (GP) with a linear coregionalization kernel as a prior over the vvRKHS. The Bayesian approach allows us to compute individualized measures of confidence in our estimates via pointwise credible intervals, which are crucial for realizing the full potential of precision medicine. The impact of selection bias is alleviated via a risk-based empirical Bayes method for adapting the multi-task GP prior, which jointly minimizes the empirical error in factual outcomes and the uncertainty in (unobserved) counterfactual outcomes. We conduct experiments on observational datasets for an interventional social program applied to premature infants, and a left ventricular assist device applied to cardiac patients wait-listed for a heart transplant. In both experiments, we show that our method significantly outperforms the state-of-the-art.},
	number = {Nips},
	journal = {Advances in Neural Information Processing Systems},
	author = {Alaa, Ahmed M. and Van Der Schaar, Mihaela},
	year = {2017},
	pages = {3425--3433},
	file = {Alaa_Van Der Schaar_2017_Bayesian inference of individualized treatment effects using multi-task Gaussian processes.pdf:/Users/orsonxu/Zotero/storage/JNPTHH5F/Alaa_Van Der Schaar_2017_Bayesian inference of individualized treatment effects using multi-task Gaussian processes.pdf:application/pdf;Alaa_Van Der Schaar_2017_Bayesian inference of individualized treatment effects using multi-task Gaussian processes.pdf:/Users/orsonxu/Zotero/storage/QV4ABYJW/Alaa_Van Der Schaar_2017_Bayesian inference of individualized treatment effects using multi-task Gaussian processes.pdf:application/pdf},
}

@article{ahuja_dpscreen:_2017,
	title = {{DPSCREEN}: {Dynamic} personalized screening},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Screening is important for the diagnosis and treatment of a wide variety of diseases. A good screening policy should be personalized to the features of the patient and to the dynamic history of the patient (including the history of screening). The growth of electronic health records data has led to the development of many models to predict the onset and progression of different diseases. However, there has been limited work to address the personalized screening for these different diseases. In this work, we develop the first framework to construct screening policies for a large class of disease models. The disease is modeled as a finite state stochastic process with an absorbing disease state. The patient observes an external information process (for instance, self-examinations, discovering comorbidities, etc.) which can trigger the patient to arrive at the clinician earlier than scheduled screenings. The clinician carries out the tests; based on the test results and the external information it schedules the next arrival. Computing the exactly optimal screening policy that balances the delay in the detection against the frequency of screenings is computationally intractable; this paper provides a computationally tractable construction of an approximately optimal policy. As an illustration, we make use of a large breast cancer data set. The constructed policy screens patients more or less often according to their initial risk - it is personalized to the features of the patient - and according to the results of previous screens - it is personalized to the history of the patient. In comparison with existing clinical policies, the constructed policy leads to large reductions (28-68\%) in the number of screens performed while achieving the same expected delays in disease detection.},
	number = {Nips},
	journal = {Advances in Neural Information Processing Systems},
	author = {Ahuja, Kartik and Zame, William R. and Van Der Schaar, Mihaela},
	year = {2017},
	pages = {1322--1333},
	file = {Ahuja et al_2017_DPSCREEN.pdf:/Users/orsonxu/Zotero/storage/YYYG4ZET/Ahuja et al_2017_DPSCREEN.pdf:application/pdf;Ahuja et al_2017_DPSCREEN.pdf:/Users/orsonxu/Zotero/storage/NENBQCKB/Ahuja et al_2017_DPSCREEN.pdf:application/pdf},
}

@article{schulam_framework_2015,
	title = {A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure},
	volume = {2015-Janua},
	issn = {10495258},
	abstract = {For many complex diseases, there is a wide variety of ways in which an individual can manifest the disease. The challenge of personalized medicine is to develop tools that can accurately predict the trajectory of an individual's disease, which can in turn enable clinicians to optimize treatments. We represent an individual's disease trajectory as a continuous-valued continuous-time function describing the severity of the disease over time. We propose a hierarchical latent variable model that individualizes predictions of disease trajectories. This model shares statistical strength across observations at different resolutions-the population, subpopulation and the individual level. We describe an algorithm for learning population and subpopulation parameters offline, and an online procedure for dynamically learning individual-specific parameters. Finally, we validate our model on the task of predicting the course of interstitial lung disease, a leading cause of death among patients with the autoimmune disease scleroderma. We compare our approach against state-of-the-art and demonstrate significant improvements in predictive accuracy.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Schulam, Peter and Saria, Suchi},
	year = {2015},
	pages = {748--756},
	file = {Schulam_Saria_2015_A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure.pdf:/Users/orsonxu/Zotero/storage/RER9ZAD7/Schulam_Saria_2015_A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure.pdf:application/pdf;Schulam_Saria_2015_A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure.pdf:/Users/orsonxu/Zotero/storage/7AYVJDEX/Schulam_Saria_2015_A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure.pdf:application/pdf},
}

@article{steeg_discovering_2014,
	title = {Discovering structure in high-dimensional data through correlation explanation},
	volume = {1},
	issn = {10495258},
	abstract = {We introduce a method to learn a hierarchy of successively more abstract representations of complex data based on optimizing an information-theoretic objective. Intuitively, the optimization searches for a set of latent factors that best explain the correlations in the data as measured by multivariate mutual information. The method is unsupervised, requires no model assumptions, and scales linearly with the number of variables which makes it an attractive approach for very high dimensional systems. We demonstrate that Correlation Explanation (CorEx) automatically discovers meaningful structure for data from diverse sources including personality tests, DNA, and human language.},
	number = {January},
	journal = {Advances in Neural Information Processing Systems},
	author = {Steeg, Greg Ver and Galstyan, Aram},
	year = {2014},
	pages = {577--585},
	file = {Steeg_Galstyan_2014_Discovering structure in high-dimensional data through correlation explanation.pdf:/Users/orsonxu/Zotero/storage/GZLGS8B9/Steeg_Galstyan_2014_Discovering structure in high-dimensional data through correlation explanation.pdf:application/pdf;Steeg_Galstyan_2014_Discovering structure in high-dimensional data through correlation explanation.pdf:/Users/orsonxu/Zotero/storage/2VKSL4BS/Steeg_Galstyan_2014_Discovering structure in high-dimensional data through correlation explanation.pdf:application/pdf},
}

@article{hofmann_kernel_2008,
	title = {Kernel methods in machine learning},
	volume = {36},
	issn = {00905364},
	doi = {10.1214/009053607000000677},
	abstract = {We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data. © Institute of Mathematical Statistics, 2008.},
	number = {3},
	journal = {Annals of Statistics},
	author = {Hofmann, Thomas and Schölkopf, Bernhard and Smola, Alexander J.},
	year = {2008},
	keywords = {Machine learning, Graphical models, Reproducing kernels, Support vector machines},
	pages = {1171--1220},
	file = {Hofmann et al_2008_Kernel methods in machine learning.pdf:/Users/orsonxu/Zotero/storage/AE6QGZTH/Hofmann et al_2008_Kernel methods in machine learning.pdf:application/pdf;Hofmann et al_2008_Kernel methods in machine learning.pdf:/Users/orsonxu/Zotero/storage/H593WLTK/Hofmann et al_2008_Kernel methods in machine learning.pdf:application/pdf},
}

@article{lan_beyond_2010,
	title = {Beyond actions: {Discriminative} models for contextual group activities},
	volume = {1},
	abstract = {We propose a discriminative model for recognizing group activities. Our model jointly captures the group activity, the individual person actions, and the interactions among them. Two new types of contextual information, group-person interaction and person-person interaction, are explored in a latent variable framework. Different from most of the previous latent structured models which assume a predefined structure for the hidden layer, e.g. a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. Our experimental results demonstrate that by inferring this contextual information together with adaptive structures, the proposed model can significantly improve activity recognition performance.},
	number = {c},
	journal = {Advances in Neural Information Processing Systems 23: 24th Annual Conference on Neural Information Processing Systems 2010, NIPS 2010},
	author = {Lan, Tian and Wang, Yang and Yang, Weilong and Mori, Greg},
	year = {2010},
	pages = {1--9},
	file = {Lan et al_2010_Beyond actions.pdf:/Users/orsonxu/Zotero/storage/A8M7DZSN/Lan et al_2010_Beyond actions.pdf:application/pdf;Lan et al_2010_Beyond actions.pdf:/Users/orsonxu/Zotero/storage/N4IFV8EH/Lan et al_2010_Beyond actions.pdf:application/pdf},
}

@article{yamada_localized_2017,
	title = {Localized lasso for high-dimensional regression},
	abstract = {We introduce the localized Lasso, which learns models that both are interpretable and have a high predictive power in problems with high dimensionality d and small sample size n. More specifically, we consider a function defined by local sparse models, one at each data point. We introduce sample-wise network regularization to borrow strength across the models, and sample-wise exclusive group sparsity (a.k.a., l1,2 norm) to introduce diversity into the choice of feature sets in the local models. The local models are interpretable in terms of similarity of their sparsity patterns. The cost function is convex, and thus has a globally optimal solution. Moreover, we propose a simple yet efficient iterative least-squares based optimization procedure for the localized Lasso, which does not need a tuning parameter, and is guaranteed to converge to a globally optimal solution. The solution is empirically shown to outperform alternatives for both simulated and genomic personalized/precision medicine data.},
	journal = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017},
	author = {Yamada, Makoto and Takeuchi, Koh and Iwata, Tomoharu and Shawe-Taylor, John and Kaski, Samuel},
	year = {2017},
	pages = {1--15},
	file = {Yamada et al_2017_Localized lasso for high-dimensional regression.pdf:/Users/orsonxu/Zotero/storage/9FVKVSPZ/Yamada et al_2017_Localized lasso for high-dimensional regression.pdf:application/pdf;Yamada et al_2017_Localized lasso for high-dimensional regression.pdf:/Users/orsonxu/Zotero/storage/Y58DRIED/Yamada et al_2017_Localized lasso for high-dimensional regression.pdf:application/pdf},
}

@article{xu_formula:_2015,
	title = {{FORMULA}: {FactORized} {MUlti}-task {LeArning} for task discovery in personalized medical models},
	doi = {10.1137/1.9781611974010.56},
	abstract = {Medical predictive modeling is a challenging problem due to the heterogeneous nature of the patients. In order to build effective medical predictive models we need to address such heterogeneous nature during modeling and allow patients to have their own personalized models instead of using a one-size-fits-all model. However, building a personalized model for each patient is computationally expensive and the over-parametrization of the model makes it susceptible to the model overfit-ting problem. To address these challenges, we propose a novel approach called FactORized MUlti-task LeArning model (Formula), which learns the personalized model of each patient via a sparse multi-task learning method. The personalized models are assumed to share a low-rank representation, known as the base models. Formula is designed to simultaneously learn the base models as well as the personalized model of each patien-t, where the latter is a linear combination of the base models. We have performed extensive experiments to evaluate the proposed approach on a real medical data set. The proposed approach delivered superior predictive performance while the personalized models offered many useful medical insights.},
	journal = {SIAM International Conference on Data Mining 2015, SDM 2015},
	author = {Xu, Jianpeng and Zhou, Jiayu and Tan, Pang Ning},
	year = {2015},
	pages = {496--504},
	file = {Xu et al_2015_FORMULA.pdf:/Users/orsonxu/Zotero/storage/BCLKNCK7/Xu et al_2015_FORMULA.pdf:application/pdf;Xu et al_2015_FORMULA.pdf:/Users/orsonxu/Zotero/storage/ICU5YGET/Xu et al_2015_FORMULA.pdf:application/pdf},
}

@article{zhan_learning_2009,
	title = {Learning instance specific distances using metric propagation},
	abstract = {In many real-world applications, such as image retrieval, it would be natural to measure the distances from one instance to others using instance specific distance which captures the distinctions from the perspective of the concerned instance. However, there is no complete framework for learning instance specific distances since existing methods are incapable of learning such distances for test instance and unlabeled data. In this paper, we propose the ISD method to address this issue. The key of ISD is metric propagation, that is, propagating and adapting metrics of individual labeled examples to individual unlabeled instances. We formulate the problem into a convex optimization framework and derive efficient solutions. Experiments show that ISD can effectively learn instance specific distances for labeled as well as unlabeled instances. The metric propagation scheme can also be used in other scenarios.},
	journal = {Proceedings of the 26th International Conference On Machine Learning, ICML 2009},
	author = {Zhan, De Chuan and Li, Ming and Li, Yu Feng and Zhou, Zhi Hua},
	year = {2009},
	pages = {1225--1232},
	file = {Zhan et al_2009_Learning instance specific distances using metric propagation.pdf:/Users/orsonxu/Zotero/storage/PWNZZBP8/Zhan et al_2009_Learning instance specific distances using metric propagation.pdf:application/pdf;Zhan et al_2009_Learning instance specific distances using metric propagation.pdf:/Users/orsonxu/Zotero/storage/N6XWMLD5/Zhan et al_2009_Learning instance specific distances using metric propagation.pdf:application/pdf},
}

@article{zheng_lazy_2000,
	title = {Lazy {Learning} of {Bayesian} {Rules}},
	issn = {1573-0565},
	doi = {10.1023/A:1007613203719},
	number = {1},
	journal = {Machine Learning},
	author = {Zheng, Zijian and Webb, Geoffrey I},
	year = {2000},
	keywords = {bayesian classification, decision rules, decision trees, lazy, semi-naive bayesian classification},
	pages = {3--5},
	file = {Zheng_Webb_2000_Lazy Learning of Bayesian Rules.pdf:/Users/orsonxu/Zotero/storage/YR734VPH/Zheng_Webb_2000_Lazy Learning of Bayesian Rules.pdf:application/pdf;Zheng_Webb_2000_Lazy Learning of Bayesian Rules.pdf:/Users/orsonxu/Zotero/storage/EIKHVZL7/Zheng_Webb_2000_Lazy Learning of Bayesian Rules.pdf:application/pdf},
}

@article{lane_automated_2017,
	title = {Automated {Selection} of {Robust} {Individual}-{Level} {Structural} {Equation} {Models} for {Time} {Series} {Data}},
	volume = {24},
	issn = {15328007},
	doi = {10.1080/10705511.2017.1309978},
	abstract = {In order to analyze intensive longitudinal data collected across multiple individuals, researchers frequently have to decide between aggregating all individuals or analyzing each individual separately. This paper presents an R package, gimme, which allows for the automatic specification of individual-level structural equation models that combine group-, subgroup-, and individual-level information. This R package is a complement of the GIMME program currently available via a combination of MATLAB and LISREL. By capitalizing on the flexibility of R and the capabilities of the existing structural equation modeling package lavaan, gimme allows for the automated specification and estimation of group-, subgroup-, and individual-level relations in time series data from within a structural equation modeling framework. Applications include daily diary data as well as functional magnetic resonance imaging data.},
	number = {5},
	journal = {Structural Equation Modeling},
	author = {Lane, Stephanie T. and Gates, Kathleen M.},
	year = {2017},
	keywords = {R, structural equation modeling, time series},
	pages = {768--782},
	file = {Lane_Gates_2017_Automated Selection of Robust Individual-Level Structural Equation Models for Time Series Data.pdf:/Users/orsonxu/Zotero/storage/UKXQDVBE/Lane_Gates_2017_Automated Selection of Robust Individual-Level Structural Equation Models for Time Series Data.pdf:application/pdf;Lane_Gates_2017_Automated Selection of Robust Individual-Level Structural Equation Models for Time Series Data.pdf:/Users/orsonxu/Zotero/storage/FJYJS3KW/Lane_Gates_2017_Automated Selection of Robust Individual-Level Structural Equation Models for Time Series Data.pdf:application/pdf},
}

@article{beltz_network_2017,
	title = {Network {Mapping} with {GIMME}},
	volume = {52},
	issn = {00273171},
	url = {https://doi.org/10.1080/00273171.2017.1373014},
	doi = {10.1080/00273171.2017.1373014},
	abstract = {Network science is booming! While the insights and images afforded by network mapping techniques are compelling, implementing the techniques is often daunting to researchers. Thus, the aim of this tutorial is to facilitate implementation in the context of GIMME, or group iterative multiple model estimation. GIMME is an automated network analysis approach for intensive longitudinal data. It creates person-specific networks that explain how variables are related in a system. The relations can signify current or future prediction that is common across people or applicable only to an individual. The tutorial begins with conceptual and mathematical descriptions of GIMME. It proceeds with a practical discussion of analysis steps, including data acquisition, preprocessing, program operation, a posteriori testing of model assumptions, and interpretation of results; throughout, a small empirical data set is analyzed to showcase the GIMME analysis pipeline. The tutorial closes with a brief overview of extensions to GIMME that may interest researchers whose questions and data sets have certain features. By the end of the tutorial, researchers will be equipped to begin analyzing the temporal dynamics of their heterogeneous time series data with GIMME.},
	number = {6},
	journal = {Multivariate Behavioral Research},
	author = {Beltz, Adriene M. and Gates, Kathleen M.},
	year = {2017},
	keywords = {Connectivity, idiographic vs. nomothetic methods, intensive longitudinal data, time series analysis, unified structural equation modeling},
	pages = {789--804},
	file = {Beltz_Gates_2017_Network Mapping with GIMME.pdf:/Users/orsonxu/Zotero/storage/XH68HZRS/Beltz_Gates_2017_Network Mapping with GIMME.pdf:application/pdf;Beltz_Gates_2017_Network Mapping with GIMME.pdf:/Users/orsonxu/Zotero/storage/ED7BTJ9N/Beltz_Gates_2017_Network Mapping with GIMME.pdf:application/pdf},
}

@article{mcfarland_sociology_2016,
	title = {Sociology in the {Era} of {Big} {Data}: {The} {Ascent} of {Forensic} {Social} {Science}},
	volume = {47},
	issn = {00031232},
	doi = {10.1007/s12108-015-9291-8},
	abstract = {The rise of big data—data that are not only large and massively multivariate but concern a dizzying array of phenomena—represents a watershed moment for the social sciences. These data have created demand for new methods that reduce/simplify the dimensionality of data, identify novel patterns and relations, and predict outcomes, from computational ethnography and computational linguistics to network science, machine learning, and in situ experiments. Such developments have led scholars to begin new lines of social inquiry. Company engineers, computer scientists, and social scientists have all converged on big data, creating the possibility of a vibrant “trading zone” for collaboration. However, strong differences in research frameworks help explain why big data may not be an egalitarian trading zone across fields, but rather—at least in the short term—a moment when engineering colonizes sociology more than vice versa. In the long term, however, we suggest there may be the possibility of a constructive synthesis across paradigms in what we term ‘forensic social science.’},
	number = {1},
	journal = {American Sociologist},
	author = {McFarland, Daniel A. and Lewis, Kevin and Goldberg, Amir},
	year = {2016},
	keywords = {Big data, Computational social science, Forensic social science, Sociology of science},
	pages = {12--35},
	file = {McFarland et al_2016_Sociology in the Era of Big Data.pdf:/Users/orsonxu/Zotero/storage/7I5HJBCL/McFarland et al_2016_Sociology in the Era of Big Data.pdf:application/pdf;McFarland et al_2016_Sociology in the Era of Big Data.pdf:/Users/orsonxu/Zotero/storage/H56RPWHI/McFarland et al_2016_Sociology in the Era of Big Data.pdf:application/pdf},
}

@article{min_toss_2014,
	title = {Toss '{N}' turn: {Smartphone} as sleep and sleep quality detector},
	doi = {10.1145/2556288.2557220},
	abstract = {The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06\% accuracy, daily sleep quality with 83.97\% accuracy, and overall sleep quality with 81.48\% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.},
	journal = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
	author = {Min, Jun Ki and Doryab, Afsaneh and Wiese, Jason and Amini, Shahriyar and Zimmerman, John and Hong, Jason I.},
	year = {2014},
	keywords = {Smartphone, Sleep, Machine learning, Sensors},
	pages = {477--486},
	file = {Min et al_2014_Toss 'N' turn.pdf:/Users/orsonxu/Zotero/storage/N8YY9W6Y/Min et al_2014_Toss 'N' turn.pdf:application/pdf;Min et al_2014_Toss 'N' turn.pdf:/Users/orsonxu/Zotero/storage/HHN3W2XG/Min et al_2014_Toss 'N' turn.pdf:application/pdf},
}

@article{horvitz_coordinate_2002,
	title = {Coordinate : {Probabilistic} {Forecasting} of {Presence} and {Availability}},
	volume = {67},
	issn = {17443091},
	doi = {10.1107/S1744309110050219},
	abstract = {We present methods employed in COORDINATE, a prototype service that supports collaboration and communication by learning predictive models that provide forecasts of users presence and availability. We describe how data is collected about user activity and proximity from multiple devices, in addition to analysis of the content of users calendars, the time of day, and day of week. We review applications of presence forecasting embedded in the PRIORITIES application and then present details of the COORDINATE service that was informed by the earlier efforts.},
	number = {Im},
	journal = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
	author = {Horvitz, Eric and Kadie, Carl M and Jacobs, Andy},
	year = {2002},
	pages = {224--233},
	file = {Horvitz et al_2002_Coordinate.pdf:/Users/orsonxu/Zotero/storage/2DZZGKQ9/Horvitz et al_2002_Coordinate.pdf:application/pdf;Horvitz et al_2002_Coordinate.pdf:/Users/orsonxu/Zotero/storage/WYLF6AG4/Horvitz et al_2002_Coordinate.pdf:application/pdf},
}

@article{horvitz_principles_1999,
	title = {Principles of mixed-initiative user interfaces},
	doi = {10.1145/302979.303030},
	abstract = {Recent debate has centered on the relative promise of focusing user-interface research on developing new metaphors and tools that enhance users' abilities to directly manipulate objects versus directing effort toward developing interface agents that provide automation. In this paper, we review principles that show promise for allowing engineers to enhance human-computer interaction through an elegant coupling of automated services with direct manipulation. Key ideas will be highlighted in terms of the Lookout system for scheduling and meeting management. Copyright © 2012 ACM, Inc.},
	number = {May},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	author = {Horvitz, Eric},
	year = {1999},
	keywords = {User modeling, Decision theory, Direct manipulation, Intelligent agents, Probability, UI design},
	pages = {159--166},
	file = {Horvitz_1999_Principles of mixed-initiative user interfaces.pdf:/Users/orsonxu/Zotero/storage/5DF8B3QE/Horvitz_1999_Principles of mixed-initiative user interfaces.pdf:application/pdf},
}

@article{cai_generalizability_2020,
	title = {Generalizability of machine learning for classification of schizophrenia based on resting-state functional {MRI} data},
	volume = {41},
	issn = {10970193},
	doi = {10.1002/hbm.24797},
	abstract = {Machine learning has increasingly been applied to classification of schizophrenia in neuroimaging research. However, direct replication studies and studies seeking to investigate generalizability are scarce. To address these issues, we assessed within-site and between-site generalizability of a machine learning classification framework which achieved excellent performance in a previous study using two independent resting-state functional magnetic resonance imaging data sets collected from different sites and scanners. We established within-site generalizability of the classification framework in the main data set using cross-validation. Then, we trained a model in the main data set and investigated between-site generalization in the validated data set using external validation. Finally, recognizing the poor between-site generalization performance, we updated the unsupervised algorithm to investigate if transfer learning using additional unlabeled data were able to improve between-site classification performance. Cross-validation showed that the published classification procedure achieved an accuracy of 0.73 using majority voting across all selected components. External validation found a classification accuracy of 0.55 (not significant) and 0.70 (significant) using the direct and transfer learning procedures, respectively. The failure of direct generalization from one site to another demonstrates the limitation of within-site cross-validation and points toward the need to incorporate efforts to facilitate application of machine learning across multiple data sets. The improvement in performance with transfer learning highlights the importance of taking into account the properties of data when constructing predictive models across samples and sites. Our findings suggest that machine learning classification result based on a single study should be interpreted cautiously.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Cai, Xin Lu and Xie, Dong Jie and Madsen, Kristoffer H. and Wang, Yong Ming and Bögemann, Sophie Alida and Cheung, Eric F.C. and Møller, Arne and Chan, Raymond C.K.},
	year = {2020},
	keywords = {machine learning, generalizability, reproducibility, schizophrenia spectrum disorders},
	pages = {172--184},
	file = {Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:/Users/orsonxu/Zotero/storage/L6UC782M/Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:application/pdf;Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:/Users/orsonxu/Zotero/storage/IWX2Z3I3/Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:application/pdf},
}

@article{wu_negations_2014,
	title = {Negation's not solved: {Generalizability} versus optimizability in clinical natural language processing},
	volume = {9},
	issn = {19326203},
	doi = {10.1371/journal.pone.0112774},
	abstract = {A review of published work in clinical natural language processing (NLP) may suggest that the negation detection task has been ''solved.'' This work proposes that an optimizable solution does not equal a generalizable solution. We introduce a new machine learning-based Polarity Module for detecting negation in clinical text, and extensively compare its performance across domains. Using four manually annotated corpora of clinical text, we show that negation detection performance suffers when there is no in-domain development (for manual methods) or training data (for machine learning-based methods). Various factors (e.g., annotation guidelines, named entity characteristics, the amount of data, and lexical and syntactic context) play a role in making generalizability difficult, but none completely explains the phenomenon. Furthermore, generalizability remains challenging because it is unclear whether to use a single source for accurate data, combine all sources into a single model, or apply domain adaptation methods. The most reliable means to improve negation detection is to manually annotate in-domain training data (or, perhaps, manually modify rules); this is a strategy for optimizing performance, rather than generalizing it. These results suggest a direction for future work in domain-adaptive and task-adaptive methods for clinical NLP. Copyright:},
	number = {11},
	journal = {PLoS ONE},
	author = {Wu, Stephen and Miller, Timothy and Masanz, James and Coarr, Matt and Halgrim, Scott and Carrell, David and Clark, Cheryl},
	year = {2014},
	file = {Wu et al_2014_Negation's not solved.pdf:/Users/orsonxu/Zotero/storage/T4FJMVZZ/Wu et al_2014_Negation's not solved.pdf:application/pdf;Wu et al_2014_Negation's not solved.pdf:/Users/orsonxu/Zotero/storage/QD6A5RAL/Wu et al_2014_Negation's not solved.pdf:application/pdf},
}

@article{wah_generalization_1999,
	title = {Generalization and generalizability measures},
	volume = {11},
	issn = {10414347},
	doi = {10.1109/69.755626},
	abstract = {In this paper, we define the generalization problem, summarize various approaches in generalization, identify the credit assignment problem, and present the problem and some solutions in measuring generalizability. We discuss anomalies in the ordering of hypotheses in a subdomain when performance is normalized and averaged, and show conditions under which anomalies can be eliminated. To generalize performance across subdomains, we present a measure called probability of win that measures the probability whether one hypothesis is better than another. Finally, we discuss some limitations in using probabilities of win and illustrate their application in finding new parameter values for TimberWolf, a package for VLSI cell placement and routing.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wah, Benjamin W.},
	year = {1999},
	pages = {175--186},
	file = {Wah_1999_Generalization and generalizability measures.pdf:/Users/orsonxu/Zotero/storage/CGIEU7I6/Wah_1999_Generalization and generalizability measures.pdf:application/pdf;Wah_1999_Generalization and generalizability measures.pdf:/Users/orsonxu/Zotero/storage/IKK93M2K/Wah_1999_Generalization and generalizability measures.pdf:application/pdf},
}

@article{finn_model-agnostic_2017,
	title = {Model-{Agnostic} {Meta}-{Learning} for {Fast} {Adaptation} of {Deep} {Networks} {Chelsea}},
	volume = {76},
	issn = {1884314X},
	doi = {10.5025/hansen.76.245},
	abstract = {Although Mycobacterium shlnshuense and M leprae infections are relatively rare in the fields of dermatology, an early diagnosis is one of the important prognostic factors of these infections. Applications of the genetical examinations such as PCR and 16S rDNA sequencing are helpful in early diagnosis with culture nagative cases. Short target PCR tests are available to detect DNA of M shlnshuense or M leprae from clinical specimens including formalin fixed-paraffin embedded samples. A partial 16s rDNA sequencing is functional with enough intact bacterial DNA. A similarity search based on the partial 16S rDNA sequences using RIDOM database is an easy and powerful tool to estimate the species of mycobacteria, however, it is not enough for the identification in some cases. For instance, a clinical isolate of M shlnshuense is clearly discriminated from M leprae (92.75\% sequence identity), however, difficult to be identified from M marInum and M ulcerans (99.77\% sequence identity). The phylogenetic tree based on 16S rDNA sequences is illustrating that both M leprae (closely related to M haemophllum) and M shlnshuense (closely related to M marmum and M. ulcerans, and also M. tuberculosis) are relatively related species and distantly related to rapidly growing species among 30 species of pathogenic mycobacteria which have been isolated in Japan.},
	number = {3},
	journal = {Proceedings of the International Conference on Machine Learning},
	author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	year = {2017},
	keywords = {16s rDNA sequence, Genetic examination, Mycobacterium leprae, Mycobacterium shinshuense, PCR},
	pages = {245--250},
	file = {Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks Chelsea.pdf:/Users/orsonxu/Zotero/storage/3E76LICT/Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks Chelsea.pdf:application/pdf;Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks Chelsea.pdf:/Users/orsonxu/Zotero/storage/GWHR6CAW/Finn et al_2017_Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks Chelsea.pdf:application/pdf},
}

@article{graves_neural_2016,
	title = {Neural {Turing} {Machines}},
	volume = {18},
	issn = {0028-0836},
	doi = {10.1038/nn.3924},
	abstract = {The striatum is required for the acquisition of procedural memories, but its contribution to motor control once learning has occurred is unclear. We created a task in which rats learned a difficult motor sequence characterized by fine-tuned changes in running speed adjusted to spatial and temporal constraints. After training and extensive practice, we found that the behavior was habitual, yet tetrode recordings in the dorsolateral striatum (DLS) revealed continuous integrative representations of running speed, position and time. These representations were weak in naive rats that were hand-guided to perform the same sequence and developed slowly after learning. Finally, DLS inactivation in well-trained animals preserved the structure of the sequence while increasing its trial-by-trial variability. We conclude that, after learning, the DLS continuously integrates task-relevant information to constrain the execution of motor habits. Our results provide a straightforward mechanism by which the basal ganglia may contribute to habit formation and motor control.},
	number = {3},
	journal = {arXiv},
	author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
	year = {2016},
	keywords = {Humans, Behavior, Behavior: physiology, Models, Animal, Animal: physiology, Animals, basal ganglia, Basal Ganglia, Basal Ganglia: physiology, cerebellum, computational models, cortex, electrode, electrophysiology, Fixatives, Formaldehyde, Goals, Habits, Habituation, motor cortex, Nerve Net, Neural Pathways, Neurological, optimal control, parietal, Parkinson Disease, Perfusion, Perfusion: methods, Polymers, Psychophysiologic, rat, Rats, reaching, reuniens, spike, Tissue Fixation, Tissue Fixation: methods},
	pages = {202--213},
	file = {Graves et al_2016_Neural Turing Machines.pdf:/Users/orsonxu/Zotero/storage/M9LSHXCI/Graves et al_2016_Neural Turing Machines.pdf:application/pdf;Graves et al_2016_Neural Turing Machines.pdf:/Users/orsonxu/Zotero/storage/CA2S27IQ/Graves et al_2016_Neural Turing Machines.pdf:application/pdf},
}

@article{bagnall_great_2016,
	title = {The {Great} {Time} {Series} {Classification} {Bake} {Off}: {An} {Experimental} {Evaluation} of {Recently} {Proposed} {Algorithms}. {Extended} {Version}},
	url = {http://arxiv.org/abs/1602.01711},
	abstract = {In the last five years there have been a large number of new time series classification algorithms proposed in the literature. These algorithms have been evaluated on subsets of the 47 data sets in the University of California, Riverside time series classification archive. The archive has recently been expanded to 85 data sets, over half of which have been donated by researchers at the University of East Anglia. Aspects of previous evaluations have made comparisons between algorithms difficult. For example, several different programming languages have been used, experiments involved a single train/test split and some used normalised data whilst others did not. The relaunch of the archive provides a timely opportunity to thoroughly evaluate algorithms on a larger number of datasets. We have implemented 18 recently proposed algorithms in a common Java framework and compared them against two standard benchmark classifiers (and each other) by performing 100 resampling experiments on each of the 85 datasets. We use these results to test several hypotheses relating to whether the algorithms are significantly more accurate than the benchmarks and each other. Our results indicate that only 9 of these algorithms are significantly more accurate than both benchmarks and that one classifier, the Collective of Transformation Ensembles, is significantly more accurate than all of the others. All of our experiments and results are reproducible: we release all of our code, results and experimental details and we hope these experiments form the basis for more rigorous testing of new algorithms in the future.},
	journal = {Data Mining and Knowledge Discovery},
	author = {Bagnall, Anthony and Bostrom, Aaron and Large, James and Lines, Jason},
	year = {2016},
	file = {Bagnall et al_2016_The Great Time Series Classification Bake Off.pdf:/Users/orsonxu/Zotero/storage/XHDEI7RV/Bagnall et al_2016_The Great Time Series Classification Bake Off.pdf:application/pdf;Bagnall et al_2016_The Great Time Series Classification Bake Off.pdf:/Users/orsonxu/Zotero/storage/KKSJGAWR/Bagnall et al_2016_The Great Time Series Classification Bake Off.pdf:application/pdf},
}

@article{madan_pervasive_2011,
	title = {Pervasive sensing to model political opinions in face-to-face networks},
	volume = {6696 LNCS},
	issn = {03029743},
	doi = {10.1007/978-3-642-21726-5_14},
	abstract = {Exposure and adoption of opinions in social networks are important questions in education, business, and government. We describe a novel application of pervasive computing based on using mobile phone sensors to measure and model the face-to-face interactions and subsequent opinion changes amongst undergraduates, during the 2008 US presidential election campaign. We find that self-reported political discussants have characteristic interaction patterns and can be predicted from sensor data. Mobile features can be used to estimate unique individual exposure to different opinions, and help discover surprising patterns of dynamic homophily related to external political events, such as election debates and election day. To our knowledge, this is the first time such dynamic homophily effects have been measured. Automatically estimated exposure explains individual opinions on election day. Finally, we report statistically significant differences in the daily activities of individuals that change political opinions versus those that do not, by modeling and discovering dominant activities using topic models. We find people who decrease their interest in politics are routinely exposed (face-to-face) to friends with little or no interest in politics. © 2011 Springer-Verlag.},
	journal = {International Conference on Pervasive Computing},
	author = {Madan, Anmol and Farrahi, Katayoun and Gatica-Perez, Daniel and Pentland, Alex},
	year = {2011},
	pages = {214--231},
	file = {Madan et al_2011_Pervasive sensing to model political opinions in face-to-face networks.pdf:/Users/orsonxu/Zotero/storage/FCGQ6BU9/Madan et al_2011_Pervasive sensing to model political opinions in face-to-face networks.pdf:application/pdf;Madan et al_2011_Pervasive sensing to model political opinions in face-to-face networks.pdf:/Users/orsonxu/Zotero/storage/CGXZFXXH/Madan et al_2011_Pervasive sensing to model political opinions in face-to-face networks.pdf:application/pdf},
}

@article{ismail_fawaz_deep_2019,
	title = {Deep learning for time series classification: a review},
	volume = {33},
	issn = {1573756X},
	url = {https://doi.org/10.1007/s10618-019-00619-1},
	doi = {10.1007/s10618-019-00619-1},
	abstract = {Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state-of-the-art performance for document classification and speech recognition. In this article, we study the current state-of-the-art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR/UEA archive) and 12 multivariate time series datasets. By training 8730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.},
	number = {4},
	journal = {Data Mining and Knowledge Discovery},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre Alain},
	year = {2019},
	keywords = {Deep learning, Review, Classification, Time series},
	pages = {917--963},
	file = {Ismail Fawaz et al_2019_Deep learning for time series classification.pdf:/Users/orsonxu/Zotero/storage/6BV2C9N8/Ismail Fawaz et al_2019_Deep learning for time series classification.pdf:application/pdf;Ismail Fawaz et al_2019_Deep learning for time series classification.pdf:/Users/orsonxu/Zotero/storage/88JIL7WU/Ismail Fawaz et al_2019_Deep learning for time series classification.pdf:application/pdf},
}

@article{taylor_business_2017,
	title = {Business {Time} {Series} {Forecasting} at {Scale}},
	volume = {35},
	issn = {2167-9843},
	doi = {10.7287/peerj.preprints.3190v2},
	abstract = {Forecasting is a common data science task that helps organizations with capacity planning, goal setting, and anomaly detection. Despite its importance, there are serious challenges associated with producing reliable and high quality forecasts – especially when there are a variety of time series and analysts with expertise in time series modeling are relatively rare. To address these challenges, we describe a practical approach to forecasting " at scale " that combines configurable models with analyst-in-the-loop performance analysis. We propose a modular regression model with interpretable parameters that can be intuitively adjusted by analysts with domain knowledge about the time series. We describe performance analyses to compare and evaluate forecasting procedures, and automatically flag forecasts for manual review and adjustment. Tools that help analysts to use their expertise most effectively enable reliable, practical forecasting of business time series.},
	number = {8},
	journal = {PeerJ Preprints 5:e3190v2},
	author = {Taylor, Sean J and Letham, Benjamin},
	year = {2017},
	keywords = {Nonlinear Regression, Statistical Practice, Time Series},
	pages = {48--90},
	file = {Taylor_Letham_2017_Business Time Series Forecasting at Scale.pdf:/Users/orsonxu/Zotero/storage/PRD7HJ89/Taylor_Letham_2017_Business Time Series Forecasting at Scale.pdf:application/pdf;Taylor_Letham_2017_Business Time Series Forecasting at Scale.pdf:/Users/orsonxu/Zotero/storage/7CMVPRXU/Taylor_Letham_2017_Business Time Series Forecasting at Scale.pdf:application/pdf},
}

@article{lee_meta-learning_2019,
	title = {Meta-{Learning} with {Differentiable} {Convex} {Optimization}},
	journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	author = {Lee, Kwonjoon and Maji, Subhransu and Ravichandran, Avinash and Soatto, Stefano},
	year = {2019},
	file = {Lee et al_2019_Meta-Learning with Differentiable Convex Optimization.pdf:/Users/orsonxu/Zotero/storage/9IZS3GRU/Lee et al_2019_Meta-Learning with Differentiable Convex Optimization.pdf:application/pdf;Lee et al_2019_Meta-Learning with Differentiable Convex Optimization.pdf:/Users/orsonxu/Zotero/storage/PYU4B7HR/Lee et al_2019_Meta-Learning with Differentiable Convex Optimization.pdf:application/pdf},
}

@article{sun_meta-transfer_2019,
	title = {Meta-{Transfer} {Learning} for {Few}-{Shot} {Learning}},
	journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	author = {Sun, Qianru and Liu, Yaoyao and Chua, Tat-seng and Schiele, Berent},
	year = {2019},
	pages = {403--412},
	file = {Sun et al_2019_Meta-Transfer Learning for Few-Shot Learning.pdf:/Users/orsonxu/Zotero/storage/ZEE433HL/Sun et al_2019_Meta-Transfer Learning for Few-Shot Learning.pdf:application/pdf;Sun et al_2019_Meta-Transfer Learning for Few-Shot Learning.pdf:/Users/orsonxu/Zotero/storage/DZ9JRTAB/Sun et al_2019_Meta-Transfer Learning for Few-Shot Learning.pdf:application/pdf},
}

@article{ribeiro_why_2016,
	title = {"{Why} should i trust you?" {Explaining} the predictions of any classifier},
	volume = {13-17-Augu},
	doi = {10.1145/2939672.2939778},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	year = {2016},
	keywords = {Unread},
	pages = {1135--1144},
	file = {Ribeiro et al_2016_Why should i trust you.pdf:/Users/orsonxu/Zotero/storage/547JULV7/Ribeiro et al_2016_Why should i trust you.pdf:application/pdf;Ribeiro et al_2016_Why should i trust you.pdf:/Users/orsonxu/Zotero/storage/QJFHN79Y/Ribeiro et al_2016_Why should i trust you.pdf:application/pdf},
}

@article{lee_explanation-based_2020,
	title = {Explanation-{Based} {Tuning} of {Opaque} {Machine} {Learners} with {Application} to {Paper} {Recommendation}},
	url = {http://arxiv.org/abs/2003.04315},
	abstract = {Research in human-centered AI has shown the benefits of machine-learning systems that can explain their predictions. Methods that allow users to tune a model in response to the explanations are similarly useful. While both capabilities are well-developed for transparent learning models (e.g., linear models and GA2Ms), and recent techniques (e.g., LIME and SHAP) can generate explanations for opaque models, no method currently exists for tuning of opaque models in response to explanations. This paper introduces LIMEADE, a general framework for tuning an arbitrary machine learning model based on an explanation of the model's prediction. We apply our framework to Semantic Sanity, a neural recommender system for scientific papers, and report on a detailed user study, showing that our framework leads to significantly higher perceived user control, trust, and satisfaction.},
	author = {Lee, Benjamin Charles Germain and Lo, Kyle and Downey, Doug and Weld, Daniel S.},
	year = {2020},
	file = {Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:/Users/orsonxu/Zotero/storage/PQV7AH7G/Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:application/pdf;Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:/Users/orsonxu/Zotero/storage/TAIACMZH/Lee et al_2020_Explanation-Based Tuning of Opaque Machine Learners with Application to Paper Recommendation.pdf:application/pdf},
}

@article{lundberg_unified_2017,
	title = {A unified approach to interpreting model predictions},
	volume = {2017-Decem},
	issn = {10495258},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	number = {Section 2},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lundberg, Scott M. and Lee, Su In},
	year = {2017},
	keywords = {Unread},
	pages = {4766--4775},
	file = {Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:/Users/orsonxu/Zotero/storage/Z5RGT97L/Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:application/pdf;Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:/Users/orsonxu/Zotero/storage/KFHPZATU/Lundberg_Lee_2017_A unified approach to interpreting model predictions.pdf:application/pdf},
}

@article{ziebart_maximum_2008,
	title = {Maximum {Entropy} {Inverse} {Reinforcement} {Learning}},
	volume = {9622},
	issn = {16113349},
	doi = {10.1007/978-3-662-49390-8_64},
	abstract = {This paper concerns online algorithms for online binary linear classification (OBLC) problems in Machine learning. In a sense of “online” classification, an instance sequence is given step by step and on each round, these problems consist in finding a linear classifier for predicting to which label a new instance belongs. In OBCL, the quality of predictions is assessed by a loss function, specifically 0–1 loss function. In fact, this loss function is nonconvex, nonsmooth and thus, such problems become intractable. In literature, Perceptron is a well-known online classification algorithm, in which one substitutes a surrogate convex loss function for the 0–1 loss function. In this paper, we investigate an efficient DC loss function which is a suitable approximation of the usual 0–1 loss function. Basing on Online DC (Difference of Convex functions) programming and Online DCA (DC Algorithms) [10], we develop an online classification algorithm. Numerical experiments on several test problems show the efficiency of our proposed algorithm with respect to Perceptron.},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J.Andrew and Dey, Anind K.},
	year = {2008},
	keywords = {DC programming, DCA, Online binary classification, Online DC optimization, Online DCA, Perceptron},
	pages = {661--670},
	file = {Ziebart et al_2008_Maximum Entropy Inverse Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/SQLEMWW2/Ziebart et al_2008_Maximum Entropy Inverse Reinforcement Learning.pdf:application/pdf;Ziebart et al_2008_Maximum Entropy Inverse Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/5V3XWZ58/Ziebart et al_2008_Maximum Entropy Inverse Reinforcement Learning.pdf:application/pdf},
}

@article{mirjafari_differentiating_2019,
	title = {Differentiating {Higher} and {Lower} {Job} {Performers} in the {Workplace} {Using} {Mobile} {Sensing}},
	volume = {3},
	issn = {2474-9567},
	doi = {10.1145/3328908},
	abstract = {Assessing performance in the workplace typically relies on subjective evaluations, such as, peer ratings, supervisor ratings and self assessments, which are manual, burdensome and potentially biased. We use objective mobile sensing data from phones, wearables and beacons to study workplace performance and offer new insights into behavioral patterns that distinguish higher and lower performers when considering roles in companies (i.e., supervisors and non-supervisors) and different types of companies (i.e., high tech and consultancy). We present initial results from an ongoing year-long study of N=554 information workers collected over a period ranging from 2-8.5 months. We train a gradient boosting classifier that can classify workers as higher or lower performers with AUROC of 0.83. Our work opens the way to new forms of passive objective assessment and feedback to workers to potentially provide week by week or quarter by quarter guidance in the workplace.},
	number = {2},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mirjafari, Shayan and Masaba, Kizito and Grover, Ted and Wang, Weichen and Audia, Pino and Campbell, Andrew T. and Chawla, Nitesh V. and Swain, Vedant Das and Choudhury, Munmun De and Dey, Anind K. and D'Mello, Sidney K. and Gao, Ge and Gregg, Julie M. and Jagannath, Krithika and Jiang, Kaifeng and Lin, Suwen and Liu, Qiang and Mark, Gloria and Martinez, Gonzalo J. and Mattingly, Stephen M. and Moskal, Edward and Mulukutla, Raghu and Nepal, Subigya and Nies, Kari and Reddy, Manikanta D. and Robles-Granda, Pablo and Saha, Koustuv and Sirigiri, Anusha and Striegel, Aaron},
	year = {2019},
	pages = {1--24},
	file = {Mirjafari et al_2019_Differentiating Higher and Lower Job Performers in the Workplace Using Mobile Sensing.pdf:/Users/orsonxu/Zotero/storage/HVNL7YNG/Mirjafari et al_2019_Differentiating Higher and Lower Job Performers in the Workplace Using Mobile Sensing.pdf:application/pdf;Mirjafari et al_2019_Differentiating Higher and Lower Job Performers in the Workplace Using Mobile Sensing.pdf:/Users/orsonxu/Zotero/storage/U4MH7EHX/Mirjafari et al_2019_Differentiating Higher and Lower Job Performers in the Workplace Using Mobile Sensing.pdf:application/pdf},
}

@article{gong_metasense_nodate,
	title = {{MetaSense} : {Few}-{Shot} {Adaptation} to {Untrained} {Conditions} in {Deep} {Mobile} {Sensing}},
	journal = {Proceedings of the Conference on Embedded Networked Sensor Systems},
	author = {Gong, Taesik and Kim, Yeonsu and Shin, Jinwoo and Lee, Sung-ju},
	keywords = {mobile sensing, acm reference format, deep learning, human activity recognition, learning, few-shot learning, meta},
	pages = {110--123},
	file = {Gong et al_MetaSense.pdf:/Users/orsonxu/Zotero/storage/R82DBEG9/Gong et al_MetaSense.pdf:application/pdf;Gong et al_MetaSense.pdf:/Users/orsonxu/Zotero/storage/DW6XIUZE/Gong et al_MetaSense.pdf:application/pdf},
}

@article{ziebart_modeling_2010,
	title = {Modeling interaction via the principle of maximum causal entropy},
	abstract = {The principle of maximum entropy provides a powerful framework for statistical models of joint, conditional, and marginal distributions. However, there are many important distributions with elements of interaction and feedback where its applicability has not been established. This work presents the principle of maximum causal entropy-an approach based on causally conditioned probabilities that can appropriately model the availability and influence of sequentially revealed side information. Using this principle, we derive models for sequential data with revealed information, interaction, and feedback, and demonstrate their applicability for statistically framing inverse optimal control and decision prediction tasks. Copyright 2010 by the author(s)/owner(s).},
	journal = {ICML 2010 - Proceedings, 27th International Conference on Machine Learning},
	author = {Ziebart, Brian D. and Bagnell, J. Andrew and Dey, Anind K.},
	year = {2010},
	pages = {1255--1262},
	file = {Ziebart et al_2010_Modeling interaction via the principle of maximum causal entropy.pdf:/Users/orsonxu/Zotero/storage/YBE2GGAP/Ziebart et al_2010_Modeling interaction via the principle of maximum causal entropy.pdf:application/pdf;Ziebart et al_2010_Modeling interaction via the principle of maximum causal entropy.pdf:/Users/orsonxu/Zotero/storage/QZ8LZAG9/Ziebart et al_2010_Modeling interaction via the principle of maximum causal entropy.pdf:application/pdf},
}

@article{abowd_what_2012,
	title = {What next, {Ubicomp}? {Celebrating} an intellectual disappearing act},
	doi = {10.1145/2370216.2370222},
	abstract = {Weiser's landmark Scientific American article inspired many researchers to explore an exciting socio-technical vision of a third generation of computing. At the 21st anniversary of that published vision, I want to assess ubicomp's maturity and explore the identity challenge it faces. Today, ubicomp as a niche research topic no longer makes sense; we must celebrate its " disappearance" as a well-scoped research agenda because it has become a profound agenda across most of computing, and beyond. This should not be surprising; the 2 nd generation of computing, the personal computer revolution, experienced the same profound disappearance. In celebration of this imminent disappearance, I will highlight the unique contributions of the ubicomp community, express some remaining intellectual challenges, and speculate on how to formulate new visions of computing that might succeed this third generation. Copyright 2012 ACM.},
	journal = {UbiComp'12 - Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
	author = {Abowd, Gregory D.},
	year = {2012},
	keywords = {Ubicomp as a field},
	pages = {31--40},
	file = {Abowd_2012_What next, Ubicomp.pdf:/Users/orsonxu/Zotero/storage/CWKCH4ZL/Abowd_2012_What next, Ubicomp.pdf:application/pdf;Abowd_2012_What next, Ubicomp.pdf:/Users/orsonxu/Zotero/storage/TYETMIW3/Abowd_2012_What next, Ubicomp.pdf:application/pdf},
}

@article{howard_mobilenets_2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	url = {http://arxiv.org/abs/1704.04861},
	abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
	journal = {arXiv},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	year = {2017},
	file = {Howard et al_2017_MobileNets.pdf:/Users/orsonxu/Zotero/storage/CPIWPLQH/Howard et al_2017_MobileNets.pdf:application/pdf;Howard et al_2017_MobileNets.pdf:/Users/orsonxu/Zotero/storage/LE7YGZNL/Howard et al_2017_MobileNets.pdf:application/pdf},
}

@article{sandler_mobilenetv2_2018,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	issn = {10636919},
	doi = {10.1109/CVPR.2018.00474},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang Chieh},
	year = {2018},
	pages = {4510--4520},
	file = {Sandler et al_2018_MobileNetV2.pdf:/Users/orsonxu/Zotero/storage/TX8JYU5J/Sandler et al_2018_MobileNetV2.pdf:application/pdf;Sandler et al_2018_MobileNetV2.pdf:/Users/orsonxu/Zotero/storage/FIU2L3GA/Sandler et al_2018_MobileNetV2.pdf:application/pdf},
}

@article{jacob_direct_1986,
	title = {Direct {Manipulation}.},
	volume = {08},
	abstract = {Direct manipulation is a new paradigm for designing user interfaces. At the core, this approach presents visual representations of a set of objects on a screen and provides a user with a standard repertoire of manipulations that can be performed on any of them. This means that the user has no command language to remember beyond the standard set of manipulations, few noticeable changes of mode (i. e. , most commands can be invoked at any time), and a continuous reminder of the available objects and their states on the display. The nature of direct-manipulation user interfaces and some issues associated with them are examined. A distinction is made between interfaces that operate directly on concrete visual objects and those that use visual metaphors to operate in more abstract domains. Two examples of direct-manipulation interfaces are described, and some benefits and drawbacks characteristic of direct manipulation are considered. It is concluded that, while the prospects for combining direct manipulation with 'intelligent' user interfaces are promising, little research has been conducted in this area to date.},
	author = {Jacob, Robert J.K.},
	year = {1986},
	pages = {384--388},
	file = {Jacob_1986_Direct Manipulation.pdf:/Users/orsonxu/Zotero/storage/KA8WTDJV/Jacob_1986_Direct Manipulation.pdf:application/pdf},
}

@article{min_survey_2018,
	title = {A {Survey} of {Clustering} {With} {Deep} {Learning}: {From} the {Perspective} of {Network} {Architecture}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8412085/},
	doi = {10.1109/ACCESS.2018.2855437},
	abstract = {Clustering is a fundamental problem in many data-driven application domains, and clustering performance highly depends on the quality of data representation. Hence, linear or non-linear feature transformations have been extensively used to learn a better data representation for clustering. In recent years, a lot of works focused on using deep neural networks to learn a clustering-friendly representation, resulting in a significant increase of clustering performance. In this paper, we give a systematic survey of clustering with deep learning in views of architecture. Specifically, we first introduce the preliminary knowledge for better understanding of this field. Then, a taxonomy of clustering with deep learning is proposed and some representative methods are introduced. Finally, we propose some interesting future opportunities of clustering with deep learning and give some conclusion remarks.},
	journal = {IEEE Access},
	author = {Min, Erxue and Guo, Xifeng and Liu, Qiang and Zhang, Gen and Cui, Jianjing and Long, Jun},
	year = {2018},
	keywords = {deep learning, Clustering, data representation, network architecture},
	pages = {39501--39514},
	file = {Min et al_2018_A Survey of Clustering With Deep Learning.pdf:/Users/orsonxu/Zotero/storage/YRT8RBWU/Min et al_2018_A Survey of Clustering With Deep Learning.pdf:application/pdf;Min et al_2018_A Survey of Clustering With Deep Learning.pdf:/Users/orsonxu/Zotero/storage/NDRBY3C9/Min et al_2018_A Survey of Clustering With Deep Learning.pdf:application/pdf},
}

@article{jing_self-supervised_2020,
	title = {Self-supervised {Visual} {Feature} {Learning} with {Deep} {Neural} {Networks}: {A} {Survey}},
	volume = {8828},
	issn = {0162-8828},
	url = {https://ieeexplore.ieee.org/document/9086055/},
	doi = {10.1109/TPAMI.2020.2992393},
	abstract = {—Large-scale labeled data are generally required to train deep neural networks in order to obtain better performance in visual feature learning from images or videos for computer vision applications. To avoid extensive cost of collecting and annotating large-scale datasets, as a subset of unsupervised learning methods, self-supervised learning methods are proposed to learn general image and video features from large-scale unlabeled data without using any human-annotated labels. This paper provides an extensive review of deep learning-based self-supervised general visual feature learning methods from images or videos. First, the motivation, general pipeline, and terminologies of this field are described. Then the common deep neural network architectures that used for self-supervised learning are summarized. Next, the schema and evaluation metrics of self-supervised learning methods are reviewed followed by the commonly used image and video datasets and the existing self-supervised visual feature learning methods. Finally, quantitative performance comparisons of the reviewed methods on benchmark datasets are summarized and discussed for both image and video feature learning. At last, this paper is concluded and lists a set of promising future directions for self-supervised visual feature learning.},
	number = {c},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Jing, Longlong and Tian, Yingli},
	year = {2020},
	keywords = {Convolutional Neural Network, Deep Learning, Self-supervised Learning, Transfer Learning, Unsupervised Learning},
	pages = {1--1},
	file = {Jing_Tian_2020_Self-supervised Visual Feature Learning with Deep Neural Networks.pdf:/Users/orsonxu/Zotero/storage/65GAST85/Jing_Tian_2020_Self-supervised Visual Feature Learning with Deep Neural Networks.pdf:application/pdf;Jing_Tian_2020_Self-supervised Visual Feature Learning with Deep Neural Networks.pdf:/Users/orsonxu/Zotero/storage/X2JM9XLL/Jing_Tian_2020_Self-supervised Visual Feature Learning with Deep Neural Networks.pdf:application/pdf},
}

@article{daume_frustratingly_2007,
	title = {Frustratingly easy domain adaptation},
	abstract = {We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough "target" data to do slightly better than just using only "source" data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof- the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains. © 2007 Association for Computational Linguistics.},
	journal = {ACL 2007 - Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics},
	author = {Daumé, Hal},
	year = {2007},
	pages = {256--263},
	file = {Daumé_2007_Frustratingly easy domain adaptation.pdf:/Users/orsonxu/Zotero/storage/HXQN78Y2/Daumé_2007_Frustratingly easy domain adaptation.pdf:application/pdf;Daumé_2007_Frustratingly easy domain adaptation.pdf:/Users/orsonxu/Zotero/storage/UDHP38V2/Daumé_2007_Frustratingly easy domain adaptation.pdf:application/pdf},
}

@article{qin_cross-dataset_2019,
	title = {Cross-{Dataset} {Activity} {Recognition} via {Adaptive} {Spatial}-{Temporal} {Transfer} {Learning}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3369818},
	doi = {10.1145/3369818},
	abstract = {Human activity recognition (HAR) aims at recognizing activities by training models on the large quantity of sensor data. Since it is time-consuming and expensive to acquire abundant labeled data, transfer learning becomes necessary for HAR by transferring knowledge from existing domains. However, there are two challenges existing in cross-dataset activity recognition. The first challenge is source domain selection. Given a target task and several available source domains, it is difficult to determine how to select the most similar source domain to the target domain such that negative transfer can be avoided. The second one is accurately activity transfer. After source domain selection, how to achieve accurate knowledge transfer between the selected source and the target domain remains another challenge. In this paper, we propose an Adaptive Spatial-Temporal Transfer Learning (ASTTL) approach to tackle both of the above two challenges in cross-dataset HAR. ASTTL learns the spatial features in transfer learning by adaptively evaluating the relative importance between the marginal and conditional probability distributions. Besides, it captures the temporal features via incremental manifold learning. Therefore, ASTTL can learn the adaptive spatial-temporal features for cross-dataset HAR and can be used for both source domain selection and accurate activity transfer. We evaluate the performance of ASTTL through extensive experiments on 4 public HAR datasets, which demonstrates its effectiveness. Furthermore, based on ASTTL, we design and implement an adaptive cross-dataset HAR system called Client-Cloud Collaborative Adaptive Activity Recognition System (3C2ARS) to perform HAR in the real environment. By collecting activities in the smartphone and transferring knowledge in the cloud server, ASTTL can significantly improve the performance of source domain selection and accurate activity transfer.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Qin, Xin and Chen, Yiqiang and Wang, Jindong and Yu, Chaohui},
	month = dec,
	year = {2019},
	keywords = {Transfer learning, Human activity recognition, Cross-dataset recognition, Domain adaptation},
	pages = {1--25},
	file = {Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:/Users/orsonxu/Zotero/storage/83BPB7PM/Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:application/pdf;Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:/Users/orsonxu/Zotero/storage/CG2NU5J9/Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:application/pdf},
}

@article{thambawita_extensive_2020,
	title = {An {Extensive} {Study} on {Cross}-{Dataset} {Bias} and {Evaluation} {Metrics} {Interpretation} for {Machine} {Learning} {Applied} to {Gastrointestinal} {Tract} {Abnormality} {Classification}},
	volume = {1},
	issn = {2691-1957},
	url = {https://dl.acm.org/doi/10.1145/3386295},
	doi = {10.1145/3386295},
	abstract = {Precise and efficient automated identification of Gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Towards this goal, we present comprehensive evaluations of five distinct machine learning models using Global Features and Deep Neural Networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics such as recall, precision, specificity, accuracy, F1-score, and Matthews Correlation Coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset, i.e., the performance metrics should always be interpreted together rather than relying on a single metric.},
	number = {3},
	journal = {ACM Transactions on Computing for Healthcare},
	author = {Thambawita, Vajira and Jha, Debesh and Hammer, Hugo Lewi and Johansen, Håvard D. and Johansen, Dag and Halvorsen, Pål and Riegler, Michael A.},
	month = jul,
	year = {2020},
	keywords = {Deep Learning, Computer Aided Diagnosis, Cross-dataset evaluations, CVC-12K, CVC-356, CVC-612, Gastrointestinal Tract Diseases, Global Features, Kvasir, Medical, Multi-class classification, Nerthus, Polyp classification},
	pages = {1--29},
	file = {Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:/Users/orsonxu/Zotero/storage/64YUWAZH/Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:application/pdf;Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:/Users/orsonxu/Zotero/storage/YH79YNF5/Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:application/pdf},
}

@incollection{tommasi_testbed_2015,
	title = {A {Testbed} for {Cross}-{Dataset} {Analysis}},
	volume = {8927},
	isbn = {978-3-319-16198-3},
	url = {http://link.springer.com/10.1007/978-3-319-16199-0_2},
	abstract = {Despite the increasing interest towards domain adaptation and transfer learning techniques to generalize over image collections and overcome their biases, the visual community misses a large scale testbed for cross-dataset analysis. In this paper we discuss the challenges faced when aligning twelve existing image databases in a unique corpus, and we propose two cross-dataset setups that introduce new interesting research questions. Moreover, we report on a first set of experimental domain adaptation tests showing the effectiveness of iterative self-labeling for large scale problems.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Tommasi, Tatiana and Tuytelaars, Tinne},
	year = {2015},
	keywords = {Domain adaptation, Dataset bias, Iterative self-labeling},
	pages = {18--31},
	file = {Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:/Users/orsonxu/Zotero/storage/4JH8J38W/Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:application/pdf;Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:/Users/orsonxu/Zotero/storage/ID3KT6E9/Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:application/pdf},
}

@article{zhang_transfer_2011,
	title = {A {Transfer} {Learning} {For} {Cross}-{Dataset} {Recognition}: {A} {Survey}},
	volume = {V},
	number = {July},
	author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip},
	year = {2011},
	file = {Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:/Users/orsonxu/Zotero/storage/L8SJ4EHE/Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:application/pdf;Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:/Users/orsonxu/Zotero/storage/TBMK4LQJ/Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:application/pdf},
}

@article{baltrusaitis_cross-dataset_2015,
	title = {Cross-dataset learning and person-specific normalisation for automatic {Action} {Unit} detection},
	volume = {2015-Janua},
	doi = {10.1109/FG.2015.7284869},
	abstract = {Automatic detection of Facial Action Units (AUs) is crucial for facial analysis systems. Due to the large individual differences, performance of AU classifiers depends largely on training data and the ability to estimate facial expressions of a neutral face. In this paper, we present a real-time Facial Action Unit intensity estimation and occurrence detection system based on appearance (Histograms of Oriented Gradients) and geometry features (shape parameters and landmark locations). Our experiments show the benefits of using additional labelled data from different datasets, which demonstrates the generalisability of our approach. This holds both when training for a specific dataset or when a generic model is needed. We also demonstrate the benefits of using a simple and efficient median based feature normalisation technique that accounts for person-specific neutral expressions. Finally, we show that our results outperform the FERA 2015 baselines in all three challenge tasks - AU occurrence detection, fully automatic AU intensity and pre-segmented AU intensity estimation.},
	journal = {2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015},
	author = {Baltrušaitis, Tadas and Mahmoud, Marwa and Robinson, Peter},
	year = {2015},
	file = {Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:/Users/orsonxu/Zotero/storage/S4WZYXGL/Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:application/pdf;Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:/Users/orsonxu/Zotero/storage/DYDWXQV6/Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:application/pdf},
}

@article{zhang_recent_2019,
	title = {Recent {Advances} in {Transfer} {Learning} for {Cross}-{Dataset} {Visual} {Recognition}},
	volume = {52},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3291124},
	doi = {10.1145/3291124},
	abstract = {This paper takes a problem-oriented perspective and presents a comprehensive review of transfer learning methods, both shallow and deep, for cross-dataset visual recognition. Specifically, it categorises the cross-dataset recognition into seventeen problems based on a set of carefully chosen data and label attributes. Such a problem-oriented taxonomy has allowed us to examine how different transfer learning approaches tackle each problem and how well each problem has been researched to date. The comprehensive problem-oriented review of the advances in transfer learning with respect to the problem has not only revealed the challenges in transfer learning for visual recognition, but also the problems (e.g. eight of the seventeen problems) that have been scarcely studied. This survey not only presents an up-to-date technical review for researchers, but also a systematic approach and a reference for a machine learning practitioner to categorise a real problem and to look up for a possible solution accordingly.},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip and Xu, Dong},
	month = feb,
	year = {2019},
	pages = {1--38},
	file = {Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:/Users/orsonxu/Zotero/storage/T749L47K/Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:application/pdf;Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:/Users/orsonxu/Zotero/storage/8K9KA7M8/Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:application/pdf},
}

@inproceedings{torralba_unbiased_2011,
	title = {Unbiased look at dataset bias},
	volume = {2011},
	isbn = {978-1-4577-0394-2},
	url = {http://ieeexplore.ieee.org/document/5995347/},
	doi = {10.1109/CVPR.2011.5995347},
	abstract = {You can't have missed them. Some smug idiot in a business suit, presumably an American, looks up from his seat on a city bench and poses an outrageous question: "Do Canadians really know anything about beer?" Instantly, all around him, dozens of everyday Canadians snap into hostile action. In the final sequence, the man sits duct-taped to a chair, babbling away obliviously, as the crowd hustles him onto a cargo plane bound for exotic parts unknown. It's an extraordinary rendition of sorts, but one with a distinctly Maple Leaf flavour. Engaging company but strikingly intense, [Linda McQuaig] is good at this sort of pointed analysis. It's not for nothing that she is sometimes called Canada's Michael Moore. But that's not an allusion she particularly welcomes, insisting that she's never flip in her criticisms and is always rigorous in her research. Some of the timely references in the book strike particularly close to home. Her final chapter, "Back from the Abyss," opens with an aborted appearance by U.S. Defense Secretary Donald Rumsfeld at a top-secret gathering of North American political, military and business leaders at the Banff Springs Hotel last September. The secrecy surrounding the meeting was extraordinary and McQuaig considers the summit the ultimate expression of the "treachery" of Canada's business and political elite.},
	booktitle = {{CVPR} 2011},
	publisher = {IEEE},
	author = {Torralba, Antonio and Efros, Alexei A.},
	month = jun,
	year = {2011},
	pages = {1521--1528},
	file = {Torralba_Efros_2011_Unbiased look at dataset bias.pdf:/Users/orsonxu/Zotero/storage/YPHIL7B9/Torralba_Efros_2011_Unbiased look at dataset bias.pdf:application/pdf;Torralba_Efros_2011_Unbiased look at dataset bias.pdf:/Users/orsonxu/Zotero/storage/S7PH6467/Torralba_Efros_2011_Unbiased look at dataset bias.pdf:application/pdf},
}

@incollection{saenko_adapting_2010,
	title = {Adapting {Visual} {Category} {Models} to {New} {Domains}},
	volume = {6314 LNCS},
	isbn = {3-642-15560-X},
	url = {http://link.springer.com/10.1007/978-3-642-15561-1_16},
	abstract = {Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions. © 2010 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
	year = {2010},
	pages = {213--226},
	file = {Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:/Users/orsonxu/Zotero/storage/XSDF9CDV/Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:application/pdf;Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:/Users/orsonxu/Zotero/storage/KTIR9QIT/Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:application/pdf},
}

@article{fernando_unsupervised_2013,
	title = {Unsupervised visual domain adaptation using subspace alignment},
	doi = {10.1109/ICCV.2013.368},
	abstract = {In this paper, we introduce a new domain adaptation (DA) algorithm where the source and target domains are represented by subspaces described by eigenvectors. In this context, our method seeks a domain adaptation solution by learning a mapping function which aligns the source subspace with the target one. We show that the solution of the corresponding optimization problem can be obtained in a simple closed form, leading to an extremely fast algorithm. We use a theoretical result to tune the unique hyper parameter corresponding to the size of the subspaces. We run our method on various datasets and show that, despite its intrinsic simplicity, it outperforms state of the art DA methods. © 2013 IEEE.},
	journal = {Proceedings of the IEEE International Conference on Computer Vision},
	author = {Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
	year = {2013},
	keywords = {object recognition, domain adaptation, subspace alignment},
	pages = {2960--2967},
	file = {Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:/Users/orsonxu/Zotero/storage/YPGDIB54/Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:application/pdf;Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:/Users/orsonxu/Zotero/storage/56A84CF8/Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:application/pdf},
}

@inproceedings{boqing_gong_geodesic_2012,
	title = {Geodesic flow kernel for unsupervised domain adaptation},
	isbn = {978-1-4673-1228-8},
	url = {http://ieeexplore.ieee.org/document/6247911/},
	doi = {10.1109/CVPR.2012.6247911},
	abstract = {In real-world applications of visual recognition, many factors such as pose, illumination, or image quality can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is computationally advantageous, automatically inferring important algorithmic parameters without requiring extensive cross-validation or labeled data from either domain. We also introduce a metric that reliably measures the adaptability between a pair of source and target domains. For a given target domain and several source domains, the metric can be used to automatically select the optimal source domain to adapt and avoid less desirable ones. Empirical studies on standard datasets demonstrate the advantages of our approach over competing methods. © 2012 IEEE.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {{Boqing Gong} and {Yuan Shi} and {Fei Sha} and Grauman, Kristen},
	month = jun,
	year = {2012},
	pages = {2066--2073},
	file = {Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:/Users/orsonxu/Zotero/storage/TRDFXB7S/Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:application/pdf;Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:/Users/orsonxu/Zotero/storage/WSC793L4/Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:application/pdf},
}

@article{sun_return_2016,
	title = {Return of frustratingly easy domain adaptation},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/10306},
	number = {1},
	journal = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
	author = {Sun, Baochen and Saenko, Kate},
	year = {2016},
	keywords = {Technical Papers: Machine Learning Methods},
	pages = {2058--2065},
	file = {Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:/Users/orsonxu/Zotero/storage/UTLUS3ZM/Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:application/pdf;Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:/Users/orsonxu/Zotero/storage/FMCJIS75/Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:application/pdf},
}

@inproceedings{church_understanding_2015,
	address = {New York, NY, USA},
	title = {Understanding the {Challenges} of {Mobile} {Phone} {Usage} {Data}},
	isbn = {978-1-4503-3652-9},
	url = {https://dl.acm.org/doi/10.1145/2785830.2785891},
	doi = {10.1145/2785830.2785891},
	abstract = {Driven by curiosity and our own three diverse smartphone application usage datasets, we sought to unpack the nuances of mobile device use by revisiting two recent Mobile HCI studies [1, 17]. Our goal was to add to our broader understanding of smartphone usage by investigating if differences in mobile device usage occurred not only across our three datasets, but also in relation to prior work. We found differences in the top-10 apps in each dataset, in the durations and types of interactions as well as in micro-usage patterns. However, it proved very challenging to attribute such differences to a specific factor or set of factors: Was it the time frame in which the studies were executed? The recruitment procedure? The experimental method? Using our somewhat troubled analysis, we discuss the challenges and issues of conducting mobile research of this nature and reflect on caveats related to the replicability and generalizability of such work.},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and Ferreira, Denzil and Banovic, Nikola and Lyons, Kent},
	month = aug,
	year = {2015},
	keywords = {Device usage, Evaluation, Generalizability, Methodology, Micro-usage, Mobile hci, Mobile usage, Replication, Smartphone usage, User studies},
	pages = {504--514},
	file = {Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:/Users/orsonxu/Zotero/storage/NKS7FVXN/Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:application/pdf;Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:/Users/orsonxu/Zotero/storage/TEQ8YIFF/Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:application/pdf},
}

@article{gordon_disagreement_2021,
	title = {The {Disagreement} {Deconvolution} : {Bringing} {Machine} {Learning} {Performance} {Metrics} {In} {Line} {With} {Reality}},
	journal = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems - CHI '21},
	author = {Gordon, Mitchell L and Zhou, Kaitlyn and Bernstein, Michael S},
	year = {2021},
	file = {Gordon et al_2021_The Disagreement Deconvolution.pdf:/Users/orsonxu/Zotero/storage/AA5TMKD8/Gordon et al_2021_The Disagreement Deconvolution.pdf:application/pdf;Gordon et al_2021_The Disagreement Deconvolution.pdf:/Users/orsonxu/Zotero/storage/SY7LZ2L4/Gordon et al_2021_The Disagreement Deconvolution.pdf:application/pdf},
}

@article{mishra_evaluating_2020,
	title = {Evaluating the reproducibility of physiological stress detection models},
	volume = {4},
	issn = {24749567},
	doi = {10.1145/3432220},
	abstract = {Recent advances in wearable sensor technologies have led to a variety of approaches for detecting physiological stress. Even with over a decade of research in the domain, there still exist many significant challenges, including a near-Total lack of reproducibility across studies. Researchers often use some physiological sensors (custom-made or off-The-shelf), conduct a study to collect data, and build machine-learning models to detect stress there is little effort to test the applicability of the model with similar physiological data collected from different devices, or the efficacy of the model on data collected from different studies, populations, or demographics. This paper takes the first step towards testing reproducibility and validity of methods and machine-learning models for stress detection. To this end, we analyzed data from 90 participants, from four independent controlled studies, using two different types of sensors, with different study protocols and research goals. We started by evaluating the performance of models built using data from one study and tested on data from other studies. Next, we evaluated new methods to improve the performance of stress-detection models and found that our methods led to a consistent increase in performance across all studies, irrespective of the device type, sensor type, or the type of stressor. Finally, we developed and evaluated a clustering approach to determine the stressed/not-stressed classification when applying models on data from different studies, and found that our approach performed better than selecting a threshold based on training data. This paper's thorough exploration of reproducibility in a controlled environment provides a critical foundation for deeper study of such methods, and is a prerequisite for tackling reproducibility in free-living conditions.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mishra, Varun and Sen, Sougata and Chen, Grace and Hao, Tian and Rogers, Jeffrey and Chen, Ching Hua and Kotz, David},
	year = {2020},
	keywords = {mental health, wearable sensing, mobile health (mHealth), Stress detection},
	file = {Mishra et al_2020_Evaluating the reproducibility of physiological stress detection models.pdf:/Users/orsonxu/Zotero/storage/2UNGR9R9/Mishra et al_2020_Evaluating the reproducibility of physiological stress detection models.pdf:application/pdf;Mishra et al_2020_Evaluating the reproducibility of physiological stress detection models.pdf:/Users/orsonxu/Zotero/storage/SSQR4RJ3/Mishra et al_2020_Evaluating the reproducibility of physiological stress detection models.pdf:application/pdf},
}

@article{nilizadeh_think_2019,
	title = {Think {Outside} the {Dataset}: {Finding} {Fraudulent} {Reviews} using {Cross}-{Dataset} {Analysis}},
	doi = {10.1145/3308558.3313647},
	author = {Nilizadeh, Shirin and Aghakhani, Hojjat and Gustafson, Eric and Kruegel, Christopher and Vigna, Giovanni},
	year = {2019},
	keywords = {acm reference format, analysis, change-point analysis, cross-dataset, fraudulent reviews and campaigns, review websites},
	pages = {3108--3115},
	file = {Nilizadeh et al_2019_Think Outside the Dataset.pdf:/Users/orsonxu/Zotero/storage/HPXS3RZK/Nilizadeh et al_2019_Think Outside the Dataset.pdf:application/pdf;Nilizadeh et al_2019_Think Outside the Dataset.pdf:/Users/orsonxu/Zotero/storage/L2TWKZJQ/Nilizadeh et al_2019_Think Outside the Dataset.pdf:application/pdf},
}

@article{wang_deep_2018,
	title = {Deep visual domain adaptation: {A} survey},
	volume = {312},
	issn = {18728286},
	url = {https://doi.org/10.1016/j.neucom.2018.05.083},
	doi = {10.1016/j.neucom.2018.05.083},
	abstract = {Deep domain adaptation has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaptation methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaptation, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaptation scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaptation approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted.},
	journal = {Neurocomputing},
	author = {Wang, Mei and Deng, Weihong},
	year = {2018},
	keywords = {Computer vision applications, Deep domain adaptation, Deep networks, Transfer learning},
	pages = {135--153},
	file = {Wang_Deng_2018_Deep visual domain adaptation.pdf:/Users/orsonxu/Zotero/storage/YNVLQ3A3/Wang_Deng_2018_Deep visual domain adaptation.pdf:application/pdf;Wang_Deng_2018_Deep visual domain adaptation.pdf:/Users/orsonxu/Zotero/storage/GP3NAZXV/Wang_Deng_2018_Deep visual domain adaptation.pdf:application/pdf},
}

@article{wu_one_2012,
	title = {One shot learning gesture recognition from {RGBD} images},
	issn = {21607508},
	doi = {10.1109/CVPRW.2012.6239179},
	abstract = {We present a system to classify the gesture from only one learning example. The inputs are duo-modality, i.e. RGB and depth sensor from Kinect. Our system performs morphological denoising on depth images and automatically segments the temporal boundaries. Features are extracted based on Extended-Motion-History- Image (Extended-MHI) and the Multi-view Spectral Embedding (MSE) algorithm is used to fuse duo modalities in a physically meaningful manner. Our approach achieves less than 0.3 in Levenshtein distance in CHALEARN Gesture Challenge validation batches [1]. © 2012 IEEE.},
	journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
	author = {Wu, Di and Zhu, Fan and Shao, Ling},
	year = {2012},
	pages = {7--12},
	file = {Wu et al_2012_One shot learning gesture recognition from RGBD images.pdf:/Users/orsonxu/Zotero/storage/3NMXWDNZ/Wu et al_2012_One shot learning gesture recognition from RGBD images.pdf:application/pdf;Wu et al_2012_One shot learning gesture recognition from RGBD images.pdf:/Users/orsonxu/Zotero/storage/M46X6UEF/Wu et al_2012_One shot learning gesture recognition from RGBD images.pdf:application/pdf},
}

@inproceedings{hossain_active_2019,
	address = {New York, NY, USA},
	title = {Active {Deep} {Learning} for {Activity} {Recognition} with {Context} {Aware} {Annotator} {Selection}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330688},
	doi = {10.1145/3292500.3330688},
	abstract = {Machine learning models are bounded by the credibility of ground truth data used for both training and testing. Regardless of the problem domain, this ground truth annotation is objectively manual and tedious as it needs considerable amount of human intervention. With the advent of Active Learning with multiple annotators, the burden can be somewhat mitigated by actively acquiring labels of most informative data instances. However, multiple annotators with varying degrees of expertise poses new set of challenges in terms of quality of the label received and availability of the annotator. Due to limited amount of ground truth information addressing the variabilities of Activity of Daily Living (ADLs), activity recognition models using wearable and mobile devices are still not robust enough for real-world deployment. In this paper, we first propose an active learning combined deep model which updates its network parameters based on the optimization of a joint loss function. We then propose a novel annotator selection model by exploiting the relationships among the users while considering their heterogeneity with respect to their expertise, physical and spatial context. Our proposed model leverages model-free deep reinforcement learning in a partially observable environment setting to capture the action-reward interaction among multiple annotators. Our experiments in real-world settings exhibit that our active deep model converges to optimal accuracy with fewer labeled instances and achieves ˜8\% improvement in accuracy in fewer iterations.},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Hossain, H M Sajjad and Roy, Nirmalya},
	month = jul,
	year = {2019},
	keywords = {Activity recognition, Active learning, Annotator selection},
	pages = {1862--1870},
	file = {Hossain_Roy_2019_Active Deep Learning for Activity Recognition with Context Aware Annotator Selection.pdf:/Users/orsonxu/Zotero/storage/RWJVNKQT/Hossain_Roy_2019_Active Deep Learning for Activity Recognition with Context Aware Annotator Selection.pdf:application/pdf;Hossain_Roy_2019_Active Deep Learning for Activity Recognition with Context Aware Annotator Selection.pdf:/Users/orsonxu/Zotero/storage/T4KY7ND7/Hossain_Roy_2019_Active Deep Learning for Activity Recognition with Context Aware Annotator Selection.pdf:application/pdf},
}

@inproceedings{fan_meta-learning-based_2020,
	title = {A {Meta}-{Learning}-{Based} {Approach} for {Hand} {Gesture} {Recognition} {Using} {FMCW} {Radar}},
	isbn = {978-1-72817-236-1},
	url = {https://ieeexplore.ieee.org/document/9299816/},
	doi = {10.1109/WCSP49889.2020.9299816},
	abstract = {In recent years, the frequency modulated continuous wave (FMCW) radar have been widely applied for hand gesture detection and recognition. In this paper, we propose a Meta-Learning-based multi-branch network with Range-Doppler-Angle multi-dimensional parameters (ML-RDA-Net) for FMCW radar based hand gesture recognition. Furthermore, we construct the Range-Frame-Map, Doppler-Frame-Map, and Angle-Frame-Map datasets for the proposed model. Finally, we carry out extensive experiments to evaluate the performance of the proposed scheme. The experimental results show that the proposed model with multidimensional parameter dataset can achieve a 3\%-7\% accuracy improvement with much fewer samples comparing with some existing methods.},
	booktitle = {2020 {International} {Conference} on {Wireless} {Communications} and {Signal} {Processing} ({WCSP})},
	publisher = {IEEE},
	author = {Fan, Zhongyu and Zheng, Haifeng and Feng, Xinxin},
	month = oct,
	year = {2020},
	keywords = {FMCW radar, Hand Gesture Recognition, Meta-Leaning, ML-RDA-Net},
	pages = {522--527},
	file = {Fan et al_2020_A Meta-Learning-Based Approach for Hand Gesture Recognition Using FMCW Radar.pdf:/Users/orsonxu/Zotero/storage/KTLCSBZP/Fan et al_2020_A Meta-Learning-Based Approach for Hand Gesture Recognition Using FMCW Radar.pdf:application/pdf;Fan et al_2020_A Meta-Learning-Based Approach for Hand Gesture Recognition Using FMCW Radar.pdf:/Users/orsonxu/Zotero/storage/UNLTCGIA/Fan et al_2020_A Meta-Learning-Based Approach for Hand Gesture Recognition Using FMCW Radar.pdf:application/pdf},
}

@incollection{wijekoon_personalised_2020,
	title = {Personalised {Meta}-{Learning} for {Human} {Activity} {Recognition} with {Few}-{Data}},
	volume = {12498 LNAI},
	isbn = {978-3-030-63798-9},
	url = {http://link.springer.com/10.1007/978-3-030-63799-6_6},
	abstract = {State-of-the-art methods of Human Activity Recognition (HAR) rely on a considerable amount of labelled data to train deep architectures. This becomes prohibitive when tasked with creating models that are sensitive to personal nuances in human movement, explicitly present when performing exercises and when it is infeasible to collect training data to cover the whole target population. Accordingly, learning personalised models with few data remains an open challenge in HAR research. We present a meta-learning methodology for learning-to-learn personalised models for HAR; with the expectation that the end-user only need to provide a few labelled data. These personalised HAR models benefit from the rapid adaptation of a generic meta-model using provided few end-user data. We implement the personalised meta-learning methodology with two algorithms, Personalised MAML and Personalised Relation Networks. A comparative study shows significant performance improvements against state-of-the-art deep learning algorithms and other personalisation algorithms in multiple HAR domains. Also, we show how personalisation improved meta-model training, to learn a generic meta-model suited for a wider population while using a shallow parametric model.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Wijekoon, Anjana and Wiratunga, Nirmalie},
	year = {2020},
	keywords = {Few-shot learning, Meta-learning, Human Activity Recognition, Personalisation},
	pages = {79--93},
	file = {Wijekoon_Wiratunga_2020_Personalised Meta-Learning for Human Activity Recognition with Few-Data.pdf:/Users/orsonxu/Zotero/storage/RL3I5ZIA/Wijekoon_Wiratunga_2020_Personalised Meta-Learning for Human Activity Recognition with Few-Data.pdf:application/pdf;Wijekoon_Wiratunga_2020_Personalised Meta-Learning for Human Activity Recognition with Few-Data.pdf:/Users/orsonxu/Zotero/storage/22TVMK7U/Wijekoon_Wiratunga_2020_Personalised Meta-Learning for Human Activity Recognition with Few-Data.pdf:application/pdf},
}

@article{ding_wi-fi-based_2021,
	title = {Wi-{Fi}-{Based} {Location}-{Independent} {Human} {Activity} {Recognition} via {Meta} {Learning}},
	volume = {21},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/8/2654},
	doi = {10.3390/s21082654},
	abstract = {Wi-Fi-based device-free human activity recognition has recently become a vital underpinning for various emerging applications, ranging from the Internet of Things (IoT) to Human–Computer Interaction (HCI). Although this technology has been successfully demonstrated for location-dependent sensing, it relies on sufficient data samples for large-scale sensing, which is enormously labor-intensive and time-consuming. However, in real-world applications, location-independent sensing is crucial and indispensable. Therefore, how to alleviate adverse effects on recognition accuracy caused by location variations with the limited dataset is still an open question. To address this concern, we present a location-independent human activity recognition system based on Wi-Fi named WiLiMetaSensing. Specifically, we first leverage a Convolutional Neural Network and Long Short-Term Memory (CNN-LSTM) feature representation method to focus on location-independent characteristics. Then, in order to well transfer the model across different positions with limited data samples, a metric learning-based activity recognition method is proposed. Consequently, not only the generalization ability but also the transferable capability of the model would be significantly promoted. To fully validate the feasibility of the presented approach, extensive experiments have been conducted in an office with 24 testing locations. The evaluation results demonstrate that our method can achieve more than 90\% in location-independent human activity recognition accuracy. More importantly, it can adapt well to the data samples with a small number of subcarriers and a low sampling rate.},
	number = {8},
	journal = {Sensors},
	author = {Ding, Xue and Jiang, Ting and Zhong, Yi and Huang, Yan and Li, Zhiwei},
	month = apr,
	year = {2021},
	keywords = {human activity recognition, learning, few-shot learning, claims in, location-independent, mdpi stays neutral, meta learning, metric, publisher, s note, wi-fi sensing, with regard to jurisdictional},
	pages = {2654},
	file = {Ding et al_2021_Wi-Fi-Based Location-Independent Human Activity Recognition via Meta Learning.pdf:/Users/orsonxu/Zotero/storage/2SR4BIFS/Ding et al_2021_Wi-Fi-Based Location-Independent Human Activity Recognition via Meta Learning.pdf:application/pdf;Ding et al_2021_Wi-Fi-Based Location-Independent Human Activity Recognition via Meta Learning.pdf:/Users/orsonxu/Zotero/storage/ZR4J9TC7/Ding et al_2021_Wi-Fi-Based Location-Independent Human Activity Recognition via Meta Learning.pdf:application/pdf},
}

@article{perrett_meta-learning_2020,
	title = {Meta-{Learning} with {Context}-{Agnostic} {Initialisations}},
	journal = {ACCV},
	author = {Perrett, Toby and Masullo, Alessandro and Burghardt, Tilo and Mirmehdi, Majid and Damen, Dima},
	year = {2020},
	pages = {1--17},
	file = {Perrett et al_2020_Meta-Learning with Context-Agnostic Initialisations.pdf:/Users/orsonxu/Zotero/storage/BQ7TDULV/Perrett et al_2020_Meta-Learning with Context-Agnostic Initialisations.pdf:application/pdf;Perrett et al_2020_Meta-Learning with Context-Agnostic Initialisations.pdf:/Users/orsonxu/Zotero/storage/HG5SEX8Z/Perrett et al_2020_Meta-Learning with Context-Agnostic Initialisations.pdf:application/pdf},
}

@incollection{gui_few-shot_2018,
	title = {Few-{Shot} {Human} {Motion} {Prediction} via {Meta}-learning},
	volume = {11212 LNCS},
	isbn = {978-3-030-01236-6},
	url = {http://link.springer.com/10.1007/978-3-030-01237-3_27},
	abstract = {Human motion prediction, forecasting human motion in a few milliseconds conditioning on a historical 3D skeleton sequence, is a long-standing problem in computer vision and robotic vision. Existing forecasting algorithms rely on extensive annotated motion capture data and are brittle to novel actions. This paper addresses the problem of few-shot human motion prediction, in the spirit of the recent progress on few-shot learning and meta-learning. More precisely, our approach is based on the insight that having a good generalization from few examples relies on both a generic initial model and an effective strategy for adapting this model to novel tasks. To accomplish this, we propose proactive and adaptive meta-learning (PAML) that introduces a novel combination of model-agnostic meta-learning and model regression networks and unifies them into an integrated, end-to-end framework. By doing so, our meta-learner produces a generic initial model through aggregating contextual information from a variety of prediction tasks, while effectively adapting this model for use as a task-specific one by leveraging learning-to-learn knowledge about how to transform few-shot model parameters to many-shot model parameters. The resulting PAML predictor model significantly improves the prediction performance on the heavily benchmarked H3.6M dataset in the small-sample size regime.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Gui, Liang-Yan and Wang, Yu-Xiong and Ramanan, Deva and Moura, José M. F.},
	year = {2018},
	keywords = {Few-shot learning, Human motion prediction, Meta-learning},
	pages = {441--459},
	file = {Gui et al_2018_Few-Shot Human Motion Prediction via Meta-learning.pdf:/Users/orsonxu/Zotero/storage/FQM5HT58/Gui et al_2018_Few-Shot Human Motion Prediction via Meta-learning.pdf:application/pdf;Gui et al_2018_Few-Shot Human Motion Prediction via Meta-learning.pdf:/Users/orsonxu/Zotero/storage/AVECDL7I/Gui et al_2018_Few-Shot Human Motion Prediction via Meta-learning.pdf:application/pdf},
}

@article{suarez-diaz_tutorial_2018,
	title = {A {Tutorial} on {Distance} {Metric} {Learning}: {Mathematical} {Foundations}, {Algorithms}, {Experimental} {Analysis}, {Prospects} and {Challenges} (with {Appendices} on {Mathematical} {Background} and {Detailed} {Algorithms} {Explanation})},
	url = {http://arxiv.org/abs/1812.05944},
	abstract = {Distance metric learning is a branch of machine learning that aims to learn distances from the data, which enhances the performance of similarity-based algorithms. This tutorial provides a theoretical background and foundations on this topic and a comprehensive experimental analysis of the most-known algorithms. We start by describing the distance metric learning problem and its main mathematical foundations, divided into three main blocks: convex analysis, matrix analysis and information theory. Then, we will describe a representative set of the most popular distance metric learning methods used in classification. All the algorithms studied in this paper will be evaluated with exhaustive testing in order to analyze their capabilities in standard classification problems, particularly considering dimensionality reduction and kernelization. The results, verified by Bayesian statistical tests, highlight a set of outstanding algorithms. Finally, we will discuss several potential future prospects and challenges in this field. This tutorial will serve as a starting point in the domain of distance metric learning from both a theoretical and practical perspective.},
	author = {Suárez-Díaz, Juan Luis and García, Salvador and Herrera, Francisco},
	year = {2018},
	keywords = {classification, dimensionality, distance metric learning, mahalanobis distance, similarity},
	file = {Suárez-Díaz et al_2018_A Tutorial on Distance Metric Learning.pdf:/Users/orsonxu/Zotero/storage/JBRTYBS2/Suárez-Díaz et al_2018_A Tutorial on Distance Metric Learning.pdf:application/pdf;Suárez-Díaz et al_2018_A Tutorial on Distance Metric Learning.pdf:/Users/orsonxu/Zotero/storage/28DM6KHS/Suárez-Díaz et al_2018_A Tutorial on Distance Metric Learning.pdf:application/pdf},
}

@article{lu_one-shot_2019,
	title = {One-shot learning hand gesture recognition based on modified 3d convolutional neural networks},
	volume = {30},
	issn = {14321769},
	url = {https://doi.org/10.1007/s00138-019-01043-7},
	doi = {10.1007/s00138-019-01043-7},
	abstract = {Though deep neural networks have played a very important role in the field of vision-based hand gesture recognition, however, it is challenging to acquire large numbers of annotated samples to support its deep learning or training. Furthermore, in practical applications it often encounters some case with only one single sample for a new gesture class so that conventional recognition method cannot be qualified with a satisfactory classification performance. In this paper, the methodology of transfer learning is employed to build an effective network architecture of one-shot learning so as to deal with such intractable problem. Then some useful knowledge from deep training with big dataset of relative objects can be transferred and utilized to strengthen one-shot learning hand gesture recognition (OSLHGR) rather than to train a network from scratch. According to this idea a well-designed convolutional network architecture with deeper layers, C3D (Tran et al. in: ICCV, pp 4489–4497, 2015), is modified as an effective tool to extract spatiotemporal feature by deep learning. Then continuous fine-tune training is performed on a sample of new classes to complete one-shot learning. Moreover, the test of classification is carried out by Softmax classifier and geometrical classification based on Euclidean distance. Finally, a series of experiments and tests on two benchmark datasets, VIVA (Vision for Intelligent Vehicles and Applications) and SKIG (Sheffield Kinect Gesture) are conducted to demonstrate its state-of-the-art recognition accuracy of our proposed method. Meanwhile, a special dataset of gestures, BSG, is built using SoftKinetic DS325 for the test of OSLHGR, and a series of test results verify and validate its well classification performance and real-time response speed.},
	number = {7-8},
	journal = {Machine Vision and Applications},
	author = {Lu, Zhi and Qin, Shiyin and Li, Xiaojie and Li, Lianwei and Zhang, Dinghao},
	year = {2019},
	keywords = {Transfer learning, Continuous fine-tune, Convolutional neural networks (CNN), Multimodal feature fusion, One-shot learning hand gesture recognition},
	pages = {1157--1180},
	file = {Lu et al_2019_One-shot learning hand gesture recognition based on modified 3d convolutional neural networks.pdf:/Users/orsonxu/Zotero/storage/CCXWVZS4/Lu et al_2019_One-shot learning hand gesture recognition based on modified 3d convolutional neural networks.pdf:application/pdf;Lu et al_2019_One-shot learning hand gesture recognition based on modified 3d convolutional neural networks.pdf:/Users/orsonxu/Zotero/storage/ZASNMBCZ/Lu et al_2019_One-shot learning hand gesture recognition based on modified 3d convolutional neural networks.pdf:application/pdf},
}

@article{lu_one-shot_2019-1,
	title = {One-{Shot} {Learning} {Hand} {Gesture} {Recognition} {Based} on {Lightweight} {3D} {Convolutional} {Neural} {Networks} for {Portable} {Applications} on {Mobile} {Systems}},
	volume = {7},
	issn = {21693536},
	doi = {10.1109/ACCESS.2019.2940997},
	abstract = {Though deep convolutional neural networks (CNNs) have made great breakthroughs in the field of vision-based gesture recognition, however it is challenging to deploy these high-performance networks to resource-constrained mobile platforms and acquire large numbers of labeled samples for deep training of CNNs. Furthermore, there are some application scenarios with only a few samples or even a single one for a new gesture class so that the recognition method based on CNNs cannot achieve satisfactory classification performance. In this paper, a well-designed lightweight network based on I3D with spatialoral separable 3D convolutions and Fire module is proposed as an effective tool for the extraction of discriminative features. Then some effective capacity by deep training of large samples from related categories can be transferred and utilized to enhance the learning ability of the proposed network instead of training from scratch. In this way, the implementation of one-shot learning hand gesture recognition (OSLHGR) is carried out by a rational decision with distance measure. Moreover, a kind of mechanism of discrimination evolution with innovation of new sample and voting integration based on multi-classifiers is established to improve the learning and classification performance of the proposed method. Finally, a series of experiments and tests on the IsoGD and Jester datasets are conducted to demonstrate the effectiveness of our improved lightweight I3D. Meanwhile, a specific dataset of gestures with variant angles and directions, BSG 2.0, and the ChaLearn gesture dataset (CGD) are used for the test of OSLHGR. The results on different experiment platforms verify and validate the performance advantages of satisfied classification and real-time response speed.},
	journal = {IEEE Access},
	author = {Lu, Zhi and Qin, Shiyin and Li, Lianwei and Zhang, Dinghao and Xu, Kuanhong and Hu, Zhongying},
	year = {2019},
	keywords = {3D convolutional neural networks, discrimination evolution, lightweight I3D, multimodal feature fusion, one-shot learning hand gesture recognition, similarity measure},
	pages = {131732--131748},
	file = {Lu et al_2019_One-Shot Learning Hand Gesture Recognition Based on Lightweight 3D Convolutional Neural Networks for Portable Applications on Mobile Systems.pdf:/Users/orsonxu/Zotero/storage/ISTQXKUC/Lu et al_2019_One-Shot Learning Hand Gesture Recognition Based on Lightweight 3D Convolutional Neural Networks for Portable Applications on Mobile Systems.pdf:application/pdf;Lu et al_2019_One-Shot Learning Hand Gesture Recognition Based on Lightweight 3D Convolutional Neural Networks for Portable Applications on Mobile Systems.pdf:/Users/orsonxu/Zotero/storage/HH3CTLTP/Lu et al_2019_One-Shot Learning Hand Gesture Recognition Based on Lightweight 3D Convolutional Neural Networks for Portable Applications on Mobile Systems.pdf:application/pdf},
}

@article{saraswat_incremental_2020,
	title = {An {Incremental} {Learning} {Based} {Gesture} {Recognition} {System} for {Consumer} {Devices} {Using} {Edge}-{Fog} {Computing}},
	volume = {66},
	issn = {0098-3063},
	url = {https://ieeexplore.ieee.org/document/8936677/},
	doi = {10.1109/TCE.2019.2961066},
	abstract = {Gesture based systems are attracting more and more researchers to develop a single point control for consumer devices. Most of the existing works use wearable devices or camera based solutions, thus requiring additional resources. This paper presents an incremental learning based gesture recognition system that uses gyroscope sensor of Edge device (mobile phone) to recognize gesture of user and select the function of consumer device. Accelerometer sensor of the mobile phone is then used to control the magnitude of the selected function. User also gives speech input along with the gesture, which is recognized by the Fog device (laptop) and its result is used by the system for incremental learning. The system is implemented by developing an application on the mobile phone and various experiments are performed for validating the accuracy of the system.},
	number = {1},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Saraswat, Surbhi and Gupta, Ashish and Gupta, Hari Prabhat and Dutta, Tanima},
	month = feb,
	year = {2020},
	keywords = {gesture recognition, Consumer devices, fog computing, incremental learning},
	pages = {51--60},
	file = {Saraswat et al_2020_An Incremental Learning Based Gesture Recognition System for Consumer Devices Using Edge-Fog Computing.pdf:/Users/orsonxu/Zotero/storage/RYBP8Y37/Saraswat et al_2020_An Incremental Learning Based Gesture Recognition System for Consumer Devices Using Edge-Fog Computing.pdf:application/pdf;Saraswat et al_2020_An Incremental Learning Based Gesture Recognition System for Consumer Devices Using Edge-Fog Computing.pdf:/Users/orsonxu/Zotero/storage/AN95DBD4/Saraswat et al_2020_An Incremental Learning Based Gesture Recognition System for Consumer Devices Using Edge-Fog Computing.pdf:application/pdf},
}

@inproceedings{yu_one-shot_2018,
	title = {One-{Shot} {Imitation} from {Observing} {Humans} via {Domain}-{Adaptive} {Meta}-{Learning}},
	isbn = {978-0-9923747-4-7},
	doi = {10.15607/RSS.2018.XIV.002},
	booktitle = {Robotics: {Science} and {Systems} {XIV}},
	publisher = {Robotics: Science and Systems Foundation},
	author = {Yu, Tianhe and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
	month = jun,
	year = {2018},
	file = {Yu et al_2018_One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning.pdf:/Users/orsonxu/Zotero/storage/8NF6UUKT/Yu et al_2018_One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning.pdf:application/pdf;Yu et al_2018_One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning.pdf:/Users/orsonxu/Zotero/storage/KVEGIE28/Yu et al_2018_One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning.pdf:application/pdf},
}

@article{siirtola_incremental_2019,
	title = {Incremental {Learning} to {Personalize} {Human} {Activity} {Recognition} {Models}: {The} {Importance} of {Human} {AI} {Collaboration}},
	volume = {19},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/19/23/5151},
	doi = {10.3390/s19235151},
	abstract = {This study presents incremental learning based methods to personalize human activity recognition models. Initially, a user-independent model is used in the recognition process. When a new user starts to use the human activity recognition application, personal streaming data can be gathered. Of course, this data does not have labels. However, there are three different ways to obtain this data: non-supervised, semi-supervised, and supervised. The non-supervised approach relies purely on predicted labels, the supervised approach uses only human intelligence to label the data, and the proposed method for semi-supervised learning is a combination of these two: It uses artificial intelligence (AI) in most cases to label the data but in uncertain cases it relies on human intelligence. After labels are obtained, the personalization process continues by using the streaming data and these labels to update the incremental learning based model, which in this case is Learn++. Learn++ is an ensemble method that can use any classifier as a base classifier, and this study compares three base classifiers: linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), and classification and regression tree (CART). Moreover, three datasets are used in the experiment to show how well the presented method generalizes on different datasets. The results show that personalized models are much more accurate than user-independent models. On average, the recognition rates are: 87.0\% using the user-independent model, 89.1\% using the non-supervised personalization approach, 94.0\% using the semi-supervised personalization approach, and 96.5\% using the supervised personalization approach. This means that by relying on predicted labels with high confidence, and asking the user to label only uncertain observations (6.6\% of the observations when using LDA, 7.7\% when using QDA, and 18.3\% using CART), almost as low error rates can be achieved as by using the supervised approach, in which labeling is fully based on human intelligence.},
	number = {23},
	journal = {Sensors},
	author = {Siirtola, Pekka and Röning, Juha},
	month = nov,
	year = {2019},
	keywords = {Personalization, Human activity recognition, Human AI collaboration, Incremental learning},
	pages = {5151},
	file = {Siirtola_Röning_2019_Incremental Learning to Personalize Human Activity Recognition Models.pdf:/Users/orsonxu/Zotero/storage/HFG92C2Q/Siirtola_Röning_2019_Incremental Learning to Personalize Human Activity Recognition Models.pdf:application/pdf;Siirtola_Röning_2019_Incremental Learning to Personalize Human Activity Recognition Models.pdf:/Users/orsonxu/Zotero/storage/UIC7MNPI/Siirtola_Röning_2019_Incremental Learning to Personalize Human Activity Recognition Models.pdf:application/pdf},
}

@article{kaya_deep_2019,
	title = {Deep {Metric} {Learning}: {A} {Survey}},
	volume = {11},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/11/9/1066},
	doi = {10.3390/sym11091066},
	abstract = {Metric learning aims to measure the similarity among samples while using an optimal distance metric for learning tasks. Metric learning methods, which generally use a linear projection, are limited in solving real-world problems demonstrating non-linear characteristics. Kernel approaches are utilized in metric learning to address this problem. In recent years, deep metric learning, which provides a better solution for nonlinear data through activation functions, has attracted researchers' attention in many different areas. This article aims to reveal the importance of deep metric learning and the problems dealt with in this field in the light of recent studies. As far as the research conducted in this field are concerned, most existing studies that are inspired by Siamese and Triplet networks are commonly used to correlate among samples while using shared weights in deep metric learning. The success of these networks is based on their capacity to understand the similarity relationship among samples. Moreover, sampling strategy, appropriate distance metric, and the structure of the network are the challenging factors for researchers to improve the performance of the network model. This article is considered to be important, as it is the first comprehensive study in which these factors are systematically analyzed and evaluated as a whole and supported by comparing the quantitative results of the methods.},
	number = {9},
	journal = {Symmetry},
	author = {Kaya, Mahmut and Bilge, H},
	month = aug,
	year = {2019},
	keywords = {Deep metric learning, Metric learning, Siamese network, Similarity, Triplet network},
	pages = {1066},
	file = {Kaya_Bilge_2019_Deep Metric Learning.pdf:/Users/orsonxu/Zotero/storage/7RGR4NDS/Kaya_Bilge_2019_Deep Metric Learning.pdf:application/pdf;Kaya_Bilge_2019_Deep Metric Learning.pdf:/Users/orsonxu/Zotero/storage/G6MQSAG7/Kaya_Bilge_2019_Deep Metric Learning.pdf:application/pdf},
}

@article{ma_practical_2020,
	title = {Practical device-free gesture recognition using {WiFi} signals based on metalearning},
	volume = {16},
	issn = {19410050},
	doi = {10.1109/TII.2019.2909877},
	abstract = {Device-free gesture recognition (DFGR) is a promising sensing technique, which can recognize a gesture by analyzing its influence on surrounding wireless signals. Most of the DFGR systems are designed based on machine learning. However, the recognition performance will drop dramatically when the testing condition is different with the training one. Inspired by the transferrable knowledge learning ability of humans, this paper develops a practical DFGR system based on metalearning to solve the aforementioned problem. Specifically, we design a deep network which could not only learn discriminative deep features, but also learn a transferrable similarity evaluation ability from the training set and apply the learned knowledge to the new testing conditions. Extensive experiments conducted by four users in two scenarios demonstrate that the proposed system could recognize new types of gestures, or gestures performed in new conditions, with an accuracy of more than 90\%, using very few number of new samples.},
	number = {1},
	journal = {IEEE Transactions on Industrial Informatics},
	author = {Ma, Xiaorui and Zhao, Yunong and Zhang, Liang and Gao, Qinghua and Pan, Miao and Wang, Jie},
	year = {2020},
	keywords = {gesture recognition, machine learning, Deep network, device-free, wireless sensing},
	pages = {228--237},
	file = {Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:/Users/orsonxu/Zotero/storage/4SKAQGBF/Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:application/pdf;Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:/Users/orsonxu/Zotero/storage/BYMJYDME/Ma et al_2020_Practical device-free gesture recognition using WiFi signals based on metalearning.pdf:application/pdf},
}

@article{ferrari_personalization_2020,
	title = {On the {Personalization} of {Classification} {Models} for {Human} {Activity} {Recognition}},
	volume = {8},
	issn = {21693536},
	doi = {10.1109/ACCESS.2020.2973425},
	abstract = {Recently, a significant amount of literature concerning machine learning techniques has focused on automatic recognition of activities performed by people. The main reason for this considerable interest is the increasing availability of devices able to acquire signals which, if properly processed, can provide information about human activities of daily living (ADL). The recognition of human activities is generally performed by machine learning techniques that process signals from wearable sensors and/or cameras appropriately arranged in the environment. Whatever the type of sensor, activities performed by human beings have a strong subjective characteristic that is related to different factors, such as age, gender, weight, height, physical abilities, and lifestyle. Personalization models have been studied to take into account these subjective factors and it has been demonstrated that using these models, the accuracy of machine learning algorithms can be improved. In this work we focus on the recognition of human activities using signals acquired by the accelerometer embedded in a smartphone. The contributions of this research are mainly three. A first contribution is the definition of a clear validation model that takes into account the problem of personalization and which thus makes it possible to objectively evaluate the performances of machine learning algorithms. A second contribution is the evaluation, on three different public datasets, of a personalization model which considers two aspects: the similarity between people related to physical aspects (age, weight, and height) and similarity related to intrinsic characteristics of the signals produced by these people when performing activities. A third and last contribution is the development of a personalization model that considers both the physical and signal similarities. The experiments show that the employment of personalization models improves, on average, the accuracy, thus confirming the soundness of the approach and paving the way for future investigations on this topic.},
	journal = {IEEE Access},
	author = {Ferrari, Anna and Micucci, Daniela and Mobilio, Marco and Napoletano, Paolo},
	year = {2020},
	keywords = {machine learning, Personalization, smartphone, similarity, human activity recognition, ADL},
	pages = {32066--32079},
	file = {Ferrari et al_2020_On the Personalization of Classification Models for Human Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/RRWU44KF/Ferrari et al_2020_On the Personalization of Classification Models for Human Activity Recognition.pdf:application/pdf;Ferrari et al_2020_On the Personalization of Classification Models for Human Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/I89K85NK/Ferrari et al_2020_On the Personalization of Classification Models for Human Activity Recognition.pdf:application/pdf},
}

@article{gong_metasense_2019,
	title = {{MetaSense}: {Few}-shot adaptation to untrained conditions in deep mobile sensing},
	doi = {10.1145/3356250.3360020},
	abstract = {Recent improvements in deep learning and hardware support offer a new breakthrough in mobile sensing; we could enjoy context-aware services and mobile healthcare on a mobile device powered by artificial intelligence. However, most related studies perform well only with a certain level of similarity between trained and target data distribution, while in practice, a specific user's behaviors and device make sensor inputs different. Consequently, the performance of such applications might suffer in diverse user and device conditions as training deep models in such countless conditions is infeasible. To mitigate the issue, we propose MetaSense, an adaptive deep mobile sensing system utilizing only a few (e.g., one or two) data instances from the target user. MetaSense employs meta learning that learns how to adapt to the target user's condition, by rehearsing multiple similar tasks generated from our unique task generation strategies in offline training. The trained model has the ability to rapidly adapt to the target user's condition when a few data are available. Our evaluation with real-world traces of motion and audio sensors shows that MetaSense not only outperforms the state-of-the-art transfer learning by 18\% and meta learning based approaches by 15\% in terms of accuracy, but also requires significantly less adaptation time for the target user.},
	journal = {SenSys 2019 - Proceedings of the 17th Conference on Embedded Networked Sensor Systems},
	author = {Gong, Taesik and Kim, Yeonsu and Shin, Jinwoo and Lee, Sung Ju},
	year = {2019},
	keywords = {Deep learning, Few-shot learning, Mobile sensing, Human activity recognition, Meta learning},
	pages = {110--123},
	file = {Gong et al_2019_MetaSense.pdf:/Users/orsonxu/Zotero/storage/CCLZH5NY/Gong et al_2019_MetaSense.pdf:application/pdf;Gong et al_2019_MetaSense.pdf:/Users/orsonxu/Zotero/storage/N32H9NEM/Gong et al_2019_MetaSense.pdf:application/pdf},
}

@inproceedings{wu_automated_2020,
	address = {New York, NY, USA},
	title = {Automated {Class} {Discovery} and {One}-{Shot} {Interactions} for {Acoustic} {Activity} {Recognition}},
	isbn = {978-1-4503-6708-0},
	url = {https://dl.acm.org/doi/10.1145/3313831.3376875},
	doi = {10.1145/3313831.3376875},
	abstract = {Acoustic activity recognition has emerged as a foundational element for imbuing devices with context-driven capabilities, enabling richer, more assistive, and more accommodating computational experiences. Traditional approaches rely either on custom models trained in situ, or general models pre-trained on preexisting data, with each approach having accuracy and user burden implications. We present Listen Learner, a technique for activity recognition that gradually learns events specific to a deployed environment while minimizing user burden. Specifically, we built an end-to-end system for self-supervised learning of events labelled through one-shot interaction. We describe and quantify system performance 1) on preexisting audio datasets, 2) on real-world datasets we collected, and 3) through user studies which uncovered system behaviors suitable for this new type of interaction. Our results show that our system can accurately and automatically learn acoustic events across environments (e.g., 97\% precision, 87\% recall), while adhering to users' preferences for non-intrusive interactive behavior.},
	booktitle = {Proceedings of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wu, Jason and Harrison, Chris and Bigham, Jeffrey P. and Laput, Gierad},
	month = apr,
	year = {2020},
	keywords = {acoustic activity recognition, automatic class discovery},
	pages = {1--14},
	file = {Wu et al_2020_Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/G9CH3SV6/Wu et al_2020_Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition.pdf:application/pdf;Wu et al_2020_Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition.pdf:/Users/orsonxu/Zotero/storage/G6Y4XNP7/Wu et al_2020_Automated Class Discovery and One-Shot Interactions for Acoustic Activity Recognition.pdf:application/pdf},
}

@article{hu_hidden_2014,
	title = {Hidden {Markov} models based dynamic hand gesture recognition with incremental learning method},
	doi = {10.1109/IJCNN.2014.6889632},
	abstract = {This paper proposes a real-time dynamic hand gesture recognition system based on Hidden Markov Models with incremental learning method (IL-HMMs) to provide natural human-computer interaction. The system is divided into four parts: hand detecting and tracking, feature extraction and vector quantization, HMMs training and hand gesture recognition, incremental learning. After quantized hand gesture vector being recognized by HMMs, incremental learning method is adopted to modify the parameters of corresponding recognized model to make itself more adaptable to the coming new gestures. Experiment results show that comparing with traditional one, the proposed system can obtain better recognition rates.},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	author = {Hu, Meng and Shen, Furao and Zhao, Jinxi},
	year = {2014},
	pages = {3108--3115},
	file = {Hu et al_2014_Hidden Markov models based dynamic hand gesture recognition with incremental learning method.pdf:/Users/orsonxu/Zotero/storage/WTENC3X2/Hu et al_2014_Hidden Markov models based dynamic hand gesture recognition with incremental learning method.pdf:application/pdf;Hu et al_2014_Hidden Markov models based dynamic hand gesture recognition with incremental learning method.pdf:/Users/orsonxu/Zotero/storage/2SRVLU29/Hu et al_2014_Hidden Markov models based dynamic hand gesture recognition with incremental learning method.pdf:application/pdf},
}

@inproceedings{rahimian_few-shot_2021,
	title = {Few-{Shot} {Learning} for {Decoding} {Surface} {Electromyography} for {Hand} {Gesture} {Recognition}},
	isbn = {978-1-72817-605-5},
	url = {https://ieeexplore.ieee.org/document/9413582/},
	doi = {10.1109/ICASSP39728.2021.9413582},
	booktitle = {{ICASSP} 2021 - 2021 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Rahimian, Elahe and Zabihi, Soheil and Asif, Amir and Atashzar, S. Farokh and Mohammadi, Arash},
	month = jun,
	year = {2021},
	pages = {1300--1304},
	file = {Rahimian et al_2021_Few-Shot Learning for Decoding Surface Electromyography for Hand Gesture Recognition.pdf:/Users/orsonxu/Zotero/storage/38HYNRE7/Rahimian et al_2021_Few-Shot Learning for Decoding Surface Electromyography for Hand Gesture Recognition.pdf:application/pdf;Rahimian et al_2021_Few-Shot Learning for Decoding Surface Electromyography for Hand Gesture Recognition.pdf:/Users/orsonxu/Zotero/storage/XSBVDCQR/Rahimian et al_2021_Few-Shot Learning for Decoding Surface Electromyography for Hand Gesture Recognition.pdf:application/pdf},
}

@article{wang_generalizing_2020,
	title = {Generalizing from a {Few} {Examples}: {A} {Survey} on {Few}-shot {Learning}},
	volume = {53},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3386252},
	doi = {10.1145/3386252},
	abstract = {Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research. 1},
	number = {3},
	journal = {ACM Computing Surveys},
	author = {Wang, Yaqing and Yao, Quanming and Kwok, James T. and Ni, Lionel M.},
	month = jul,
	year = {2020},
	keywords = {Few-shot learning, low-shot learning, meta-learning, one-shot learning, prior knowledge, small sample learning, Star},
	pages = {1--34},
	file = {Wang et al_2020_Generalizing from a Few Examples.pdf:/Users/orsonxu/Zotero/storage/MB67G252/Wang et al_2020_Generalizing from a Few Examples.pdf:application/pdf;Wang et al_2020_Generalizing from a Few Examples.pdf:/Users/orsonxu/Zotero/storage/HS2HYRRX/Wang et al_2020_Generalizing from a Few Examples.pdf:application/pdf},
}

@article{cai_weighted_2020,
	title = {Weighted {Meta}-{Learning}},
	url = {http://arxiv.org/abs/2003.09465},
	abstract = {Meta-learning leverages related source tasks to learn an initialization that can be quickly fine-tuned to a target task with limited labeled examples. However, many popular meta-learning algorithms, such as model-agnostic meta-learning (MAML), only assume access to the target samples for fine-tuning. In this work, we provide a general framework for meta-learning based on weighting the loss of different source tasks, where the weights are allowed to depend on the target samples. In this general setting, we provide upper bounds on the distance of the weighted empirical risk of the source tasks and expected target risk in terms of an integral probability metric (IPM) and Rademacher complexity, which apply to a number of meta-learning settings including MAML and a weighted MAML variant. We then develop a learning algorithm based on minimizing the error bound with respect to an empirical IPM, including a weighted MAML algorithm, \${\textbackslash}alpha\$-MAML. Finally, we demonstrate empirically on several regression problems that our weighted meta-learning algorithm is able to find better initializations than uniformly-weighted meta-learning algorithms, such as MAML.},
	journal = {arXiv},
	author = {Cai, Diana and Sheth, Rishit and Mackey, Lester and Fusi, Nicolo},
	month = mar,
	year = {2020},
	file = {Cai et al_2020_Weighted Meta-Learning.pdf:/Users/orsonxu/Zotero/storage/H44YTSW3/Cai et al_2020_Weighted Meta-Learning.pdf:application/pdf;Cai et al_2020_Weighted Meta-Learning.pdf:/Users/orsonxu/Zotero/storage/2ZEAIEXG/Cai et al_2020_Weighted Meta-Learning.pdf:application/pdf},
}

@article{zintgraf_fast_2019,
	title = {Fast context adaptation via meta-learning},
	volume = {2019-June},
	abstract = {We propose CAVIA for mcta-lcarning, a simple extension to MAML that is less prone to metaoverfitting, easier to parallelise, and more interpretable. CAVIA partitions the model parameters into two parts: context parameters that serve as additional input to the model and are adapted on individual tasks, and shared parameters that are meta-trained and shared across tasks. At test time, only the context parameters are updated, leading to a low-dimensional task representation. We show empirically that CAVIA outperforms MAML for regression, classification, and reinforcement learning. Our experiments also highlight weaknesses in current benchmarks, in that the amount of adaptation needed in some cases is small.},
	number = {2018},
	journal = {36th International Conference on Machine Learning, ICML 2019},
	author = {Zintgraf, Luisa and Shiarlis, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon},
	year = {2019},
	pages = {13262--13276},
	file = {Zintgraf et al_2019_Fast context adaptation via meta-learning.pdf:/Users/orsonxu/Zotero/storage/H3RV9JSR/Zintgraf et al_2019_Fast context adaptation via meta-learning.pdf:application/pdf;Zintgraf et al_2019_Fast context adaptation via meta-learning.pdf:/Users/orsonxu/Zotero/storage/UXPIMC3B/Zintgraf et al_2019_Fast context adaptation via meta-learning.pdf:application/pdf},
}

@inproceedings{achille_task2vec_2019,
	title = {{Task2Vec}: {Task} {Embedding} for {Meta}-{Learning}},
	isbn = {978-1-72814-803-8},
	url = {https://ieeexplore.ieee.org/document/9008292/},
	doi = {10.1109/ICCV.2019.00653},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	publisher = {IEEE},
	author = {Achille, Alessandro and Lam, Michael and Tewari, Rahul and Ravichandran, Avinash and Maji, Subhransu and Fowlkes, Charless and Soatto, Stefano and Perona, Pietro},
	month = oct,
	year = {2019},
	pages = {6429--6438},
	file = {Achille et al_2019_Task2Vec.pdf:/Users/orsonxu/Zotero/storage/FYW9B945/Achille et al_2019_Task2Vec.pdf:application/pdf;Achille et al_2019_Task2Vec.pdf:/Users/orsonxu/Zotero/storage/D2SSZZD6/Achille et al_2019_Task2Vec.pdf:application/pdf},
}

@article{killamsetty_reweighted_2020,
	title = {A {Reweighted} {Meta} {Learning} {Framework} {For} {Robust} {Few} {Shot} {Learning}},
	journal = {arXiv},
	author = {Killamsetty, Keishnateja and Li, Changbin and Zhao, Chen and Iyer, Rishabh and Chen, Feng},
	year = {2020},
	file = {Killamsetty et al_2020_A Reweighted Meta Learning Framework For Robust Few Shot Learning.pdf:/Users/orsonxu/Zotero/storage/WUJRQ68D/Killamsetty et al_2020_A Reweighted Meta Learning Framework For Robust Few Shot Learning.pdf:application/pdf;Killamsetty et al_2020_A Reweighted Meta Learning Framework For Robust Few Shot Learning.pdf:/Users/orsonxu/Zotero/storage/MJPSSLX6/Killamsetty et al_2020_A Reweighted Meta Learning Framework For Robust Few Shot Learning.pdf:application/pdf},
}

@article{antoniou_how_2019,
	title = {How to train your {MAML}},
	abstract = {The field of few-shot learning has recently seen substantial advancements. Most of these advancements came from casting few-shot learning as a meta-learning problem. Model Agnostic Meta Learning or MAML is currently one of the best approaches for few-shot learning via meta-learning. MAML is simple, elegant and very powerful, however, it has a variety of issues, such as being very sensitive to neural network architectures, often leading to instability during training, requiring arduous hyperparameter searches to stabilize training and achieve high generalization and being very computationally expensive at both training and inference times. In this paper, we propose various modifications to MAML that not only stabilize the system, but also substantially improve the generalization performance, convergence speed and computational overhead of MAML, which we call MAML++.},
	journal = {7th International Conference on Learning Representations, ICLR 2019},
	author = {Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
	year = {2019},
	pages = {1--11},
	file = {Antoniou et al_2019_How to train your MAML.pdf:/Users/orsonxu/Zotero/storage/NYF99TCE/Antoniou et al_2019_How to train your MAML.pdf:application/pdf;Antoniou et al_2019_How to train your MAML.pdf:/Users/orsonxu/Zotero/storage/TXSS48QA/Antoniou et al_2019_How to train your MAML.pdf:application/pdf},
}

@article{hoi_online_2018,
	title = {Online {Learning}: {A} {Comprehensive} {Survey}},
	shorttitle = {Online {Learning}},
	url = {http://arxiv.org/abs/1802.02871},
	abstract = {Online learning represents an important family of machine learning algorithms, in which a learner attempts to resolve an online prediction (or any type of decision-making) task by learning a model/hypothesis from a sequence of data instances one at a time. The goal of online learning is to ensure that the online learner would make a sequence of accurate predictions (or correct decisions) given the knowledge of correct answers to previous prediction or learning tasks and possibly additional information. This is in contrast to many traditional batch learning or offline machine learning algorithms that are often designed to train a model in batch from a given collection of training data instances. This survey aims to provide a comprehensive survey of the online machine learning literatures through a systematic review of basic ideas and key principles and a proper categorization of different algorithms and techniques. Generally speaking, according to the learning type and the forms of feedback information, the existing online learning works can be classified into three major categories: (i) supervised online learning where full feedback information is always available, (ii) online learning with limited feedback, and (iii) unsupervised online learning where there is no feedback available. Due to space limitation, the survey will be mainly focused on the first category, but also briefly cover some basics of the other two categories. Finally, we also discuss some open issues and attempt to shed light on potential future research directions in this field.},
	urldate = {2021-06-10},
	journal = {arXiv:1802.02871 [cs]},
	author = {Hoi, Steven C. H. and Sahoo, Doyen and Lu, Jing and Zhao, Peilin},
	month = oct,
	year = {2018},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/G5WPX5LI/1802.html:text/html;Hoi et al_2018_Online Learning.pdf:/Users/orsonxu/Zotero/storage/22SURLJL/Hoi et al_2018_Online Learning.pdf:application/pdf;Hoi et al_2018_Online Learning.pdf:/Users/orsonxu/Zotero/storage/GCX2ZCP5/Hoi et al_2018_Online Learning.pdf:application/pdf},
}

@article{stewart_online_2020,
	title = {Online {Few}-{Shot} {Gesture} {Learning} on a {Neuromorphic} {Processor}},
	volume = {10},
	issn = {2156-3365},
	doi = {10.1109/JETCAS.2020.3032058},
	abstract = {We present the Surrogate-gradient Online Error-triggered Learning (SOEL) system for online few-shot learning on neuromorphic processors. The SOEL learning system uses a combination of transfer learning and principles of computational neuroscience and deep learning. We show that partially trained deep Spiking Neural Networks (SNNs) implemented on neuromorphic hardware can rapidly adapt online to new classes of data within a domain. SOEL updates trigger when an error occurs, enabling faster learning with fewer updates. Using gesture recognition as a case study, we show SOEL can be used for online few-shot learning of new classes of pre-recorded gesture data and rapid online learning of new gestures from data streamed live from a Dynamic Active-pixel Vision Sensor to an Intel Loihi neuromorphic research processor.},
	number = {4},
	journal = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
	author = {Stewart, Kenneth and Orchard, Garrick and Shrestha, Sumit Bam and Neftci, Emre},
	month = dec,
	year = {2020},
	keywords = {Gesture recognition, online learning, few-shot learning, Artificial neural networks, Hardware, Neuromorphic computing, Neuromorphics, on-chip learning, spiking neural networks, Training},
	pages = {512--521},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/GMD9UX3M/9229141.html:text/html;Stewart et al_2020_Online Few-Shot Gesture Learning on a Neuromorphic Processor.pdf:/Users/orsonxu/Zotero/storage/V5AKJJP8/Stewart et al_2020_Online Few-Shot Gesture Learning on a Neuromorphic Processor.pdf:application/pdf;Stewart et al_2020_Online Few-Shot Gesture Learning on a Neuromorphic Processor.pdf:/Users/orsonxu/Zotero/storage/BMNZ9PK4/Stewart et al_2020_Online Few-Shot Gesture Learning on a Neuromorphic Processor.pdf:application/pdf},
}

@article{masana_class-incremental_2021,
	title = {Class-incremental learning: survey and performance evaluation on image classification},
	shorttitle = {Class-incremental learning},
	url = {http://arxiv.org/abs/2010.15277},
	abstract = {For future learning systems incremental learning is desirable, because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored -- also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main challenge for incremental learning is catastrophic forgetting, which refers to the precipitous drop in performance on previously learned tasks after learning a new one. Incremental learning of deep neural networks has seen explosive growth in recent years. Initial work focused on task-incremental learning, where a task-ID is provided at inference time. Recently, we have seen a shift towards class-incremental learning where the learner must discriminate at inference time between all classes seen in previous tasks without recourse to a task-ID. In this paper, we provide a complete survey of existing class-incremental learning methods for image classification, and in particular we perform an extensive experimental evaluation on thirteen class-incremental methods. We consider several new experimental scenarios, including a comparison of class-incremental methods on multiple large-scale image classification datasets, investigation into small and large domain shifts, and comparison of various network architectures.},
	urldate = {2021-06-10},
	journal = {arXiv:2010.15277 [cs]},
	author = {Masana, Marc and Liu, Xialei and Twardowski, Bartlomiej and Menta, Mikel and Bagdanov, Andrew D. and van de Weijer, Joost},
	month = may,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/MZ8I3L2L/2010.html:text/html;Masana et al_2021_Class-incremental learning.pdf:/Users/orsonxu/Zotero/storage/GV9P5RGK/Masana et al_2021_Class-incremental learning.pdf:application/pdf;Masana et al_2021_Class-incremental learning.pdf:/Users/orsonxu/Zotero/storage/R2WZ3WSV/Masana et al_2021_Class-incremental learning.pdf:application/pdf},
}

@article{masana_class-incremental_2021-1,
	title = {Class-incremental learning: survey and performance evaluation on image classification},
	shorttitle = {Class-incremental learning},
	url = {http://arxiv.org/abs/2010.15277},
	abstract = {For future learning systems incremental learning is desirable, because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored -- also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main challenge for incremental learning is catastrophic forgetting, which refers to the precipitous drop in performance on previously learned tasks after learning a new one. Incremental learning of deep neural networks has seen explosive growth in recent years. Initial work focused on task-incremental learning, where a task-ID is provided at inference time. Recently, we have seen a shift towards class-incremental learning where the learner must discriminate at inference time between all classes seen in previous tasks without recourse to a task-ID. In this paper, we provide a complete survey of existing class-incremental learning methods for image classification, and in particular we perform an extensive experimental evaluation on thirteen class-incremental methods. We consider several new experimental scenarios, including a comparison of class-incremental methods on multiple large-scale image classification datasets, investigation into small and large domain shifts, and comparison of various network architectures.},
	urldate = {2021-06-10},
	journal = {arXiv:2010.15277 [cs]},
	author = {Masana, Marc and Liu, Xialei and Twardowski, Bartlomiej and Menta, Mikel and Bagdanov, Andrew D. and van de Weijer, Joost},
	month = may,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Unread},
	file = {arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/LHMDNI8X/2010.html:text/html;Masana et al_2021_Class-incremental learning.pdf:/Users/orsonxu/Zotero/storage/S2ADH3JB/Masana et al_2021_Class-incremental learning2.pdf:application/pdf;Masana et al_2021_Class-incremental learning.pdf:/Users/orsonxu/Zotero/storage/IT7LKDPG/Masana et al_2021_Class-incremental learning2.pdf:application/pdf},
}

@inproceedings{tao_few-shot_2020,
	address = {Seattle, WA, USA},
	title = {Few-{Shot} {Class}-{Incremental} {Learning}},
	isbn = {978-1-72817-168-5},
	url = {https://ieeexplore.ieee.org/document/9157521/},
	doi = {10.1109/CVPR42600.2020.01220},
	abstract = {The ability to incrementally learn new classes is crucial to the development of real-world artiﬁcial intelligence systems. In this paper, we focus on a challenging but practical few-shot class-incremental learning (FSCIL) problem. FSCIL requires CNN models to incrementally learn new classes from very few labelled samples, without forgetting the previously learned ones. To address this problem, we represent the knowledge using a neural gas (NG) network, which can learn and preserve the topology of the feature manifold formed by different classes. On this basis, we propose the TOpology-Preserving knowledge InCrementer (TOPIC) framework. TOPIC mitigates the forgetting of the old classes by stabilizing NG’s topology and improves the representation learning for few-shot new classes by growing and adapting NG to new training samples. Comprehensive experimental results demonstrate that our proposed method signiﬁcantly outperforms other state-of-theart class-incremental learning methods on CIFAR100, miniImageNet, and CUB200 datasets.},
	language = {en},
	urldate = {2021-06-10},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Tao, Xiaoyu and Hong, Xiaopeng and Chang, Xinyuan and Dong, Songlin and Wei, Xing and Gong, Yihong},
	month = jun,
	year = {2020},
	keywords = {Unread},
	pages = {12180--12189},
	file = {Tao et al_2020_Few-Shot Class-Incremental Learning.pdf:/Users/orsonxu/Zotero/storage/XV6ZVIXL/Tao et al_2020_Few-Shot Class-Incremental Learning.pdf:application/pdf;Tao et al_2020_Few-Shot Class-Incremental Learning.pdf:/Users/orsonxu/Zotero/storage/SYLQAY2G/Tao et al_2020_Few-Shot Class-Incremental Learning.pdf:application/pdf},
}

@inproceedings{rajasegaran_itaml_2020,
	address = {Seattle, WA, USA},
	title = {{iTAML}: {An} {Incremental} {Task}-{Agnostic} {Meta}-learning {Approach}},
	isbn = {978-1-72817-168-5},
	shorttitle = {{iTAML}},
	url = {https://ieeexplore.ieee.org/document/9156383/},
	doi = {10.1109/CVPR42600.2020.01360},
	abstract = {Humans can continuously learn new knowledge as their experience grows. In contrast, previous learning in deep neural networks can quickly fade out when they are trained on a new task. In this paper, we hypothesize this problem can be avoided by learning a set of generalized parameters, that are neither speciﬁc to old nor new tasks. In this pursuit, we introduce a novel meta-learning approach that seeks to maintain an equilibrium between all the encountered tasks. This is ensured by a new meta-update rule which avoids catastrophic forgetting. In comparison to previous metalearning techniques, our approach is task-agnostic. When presented with a continuum of data, our model automatically identiﬁes the task and quickly adapts to it with just a single update. We perform extensive experiments on ﬁve datasets in a class-incremental setting, leading to signiﬁcant improvements over the state of the art methods (e.g., a 21.3\% boost on CIFAR100 with 10 incremental tasks). Speciﬁcally, on large-scale datasets that generally prove difﬁcult cases for incremental learning, our approach delivers absolute gains as high as 19.1\% and 7.4\% on ImageNet and MS-Celeb datasets, respectively. Our codes are available at: https://github.com/brjathu/iTAML .},
	language = {en},
	urldate = {2021-06-10},
	booktitle = {2020 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Rajasegaran, Jathushan and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Shah, Mubarak},
	month = jun,
	year = {2020},
	keywords = {Unread},
	pages = {13585--13594},
	file = {Rajasegaran et al_2020_iTAML.pdf:/Users/orsonxu/Zotero/storage/FLQ59MHI/Rajasegaran et al_2020_iTAML.pdf:application/pdf;Rajasegaran et al_2020_iTAML.pdf:/Users/orsonxu/Zotero/storage/B2GRHRNK/Rajasegaran et al_2020_iTAML.pdf:application/pdf},
}

@inproceedings{he_-device_2019,
	address = {Seoul, Korea (South)},
	title = {On-{Device} {Few}-{Shot} {Personalization} for {Real}-{Time} {Gaze} {Estimation}},
	isbn = {978-1-72815-023-9},
	url = {https://ieeexplore.ieee.org/document/9021975/},
	doi = {10.1109/ICCVW.2019.00146},
	abstract = {Building fast and accurate gaze estimation models without additional specialized hardware is a hard problem. In this paper, we present on-device few-shot personalization methods for 2D gaze estimation. The proposed supervised method achieves better accuracy using as few as 2-5 calibration points per user compared to prior methods that require more than 13 calibration points. In addition, we propose an unsupervised personalization method which uses only unlabeled facial images to improve gaze estimation accuracy. Our best personalized model achieves 24-26\% better accuracy (measured by mean error) on phones compared to the state-of-the-art using {\textless}=5 calibration points per user. It is also computationally efﬁcient, requiring 20x fewer FLOPS when compared to prior methods. This unlocks a variety of important real world applications such as using gaze for accessibility, gaming and human-computer interaction while running entirely on-device in real-time.},
	language = {en},
	urldate = {2021-06-10},
	booktitle = {2019 {IEEE}/{CVF} {International} {Conference} on {Computer} {Vision} {Workshop} ({ICCVW})},
	publisher = {IEEE},
	author = {He, Junfeng and Pham, Khoi and Valliappan, Nachiappan and Xu, Pingmei and Roberts, Chase and Lagun, Dmitry and Navalpakkam, Vidhya},
	month = oct,
	year = {2019},
	pages = {1149--1158},
	file = {He et al_2019_On-Device Few-Shot Personalization for Real-Time Gaze Estimation.pdf:/Users/orsonxu/Zotero/storage/VI88MJMN/He et al_2019_On-Device Few-Shot Personalization for Real-Time Gaze Estimation.pdf:application/pdf;He et al_2019_On-Device Few-Shot Personalization for Real-Time Gaze Estimation.pdf:/Users/orsonxu/Zotero/storage/I6ZFD3QV/He et al_2019_On-Device Few-Shot Personalization for Real-Time Gaze Estimation.pdf:application/pdf},
}

@inproceedings{tzeng_adversarial_2017,
	address = {Honolulu, HI},
	title = {Adversarial {Discriminative} {Domain} {Adaptation}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099799/},
	doi = {10.1109/CVPR.2017.316},
	abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we ﬁrst outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domainadversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difﬁcult cross-modality object classiﬁcation task.},
	language = {en},
	urldate = {2021-06-11},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
	month = jul,
	year = {2017},
	keywords = {Unread},
	pages = {2962--2971},
	file = {Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:/Users/orsonxu/Zotero/storage/MV2TZZKR/Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:application/pdf;Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:/Users/orsonxu/Zotero/storage/ISYLT75Z/Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:application/pdf},
}

@inproceedings{gidaris_dynamic_2018,
	address = {Salt Lake City, UT, USA},
	title = {Dynamic {Few}-{Shot} {Visual} {Learning} {Without} {Forgetting}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578557/},
	doi = {10.1109/CVPR.2018.00459},
	abstract = {The human visual system has the remarkably ability to be able to effortlessly learn novel concepts from only a few examples. Mimicking the same behavior on machine learning vision systems is an interesting and very challenging research problem with many practical advantages on real world vision applications. In this context, the goal of our work is to devise a few-shot visual learning system that during test time it will be able to efﬁciently learn novel categories from only a few training data while at the same time it will not forget the initial categories on which it was trained (here called base categories). To achieve that goal we propose (a) to extend an object recognition system with an attention based few-shot classiﬁcation weight generator, and (b) to redesign the classiﬁer of a ConvNet model as the cosine similarity function between feature representations and classiﬁcation weight vectors. The latter, apart from unifying the recognition of both novel and base categories, it also leads to feature representations that generalize better on “unseen” categories. We extensively evaluate our approach on Mini-ImageNet where we manage to improve the prior stateof-the-art on few-shot recognition (i.e., we achieve 56.20\% and 73.00\% on the 1-shot and 5-shot settings respectively) while at the same time we do not sacriﬁce any accuracy on the base categories, which is a characteristic that most prior approaches lack. Finally, we apply our approach on the recently introduced few-shot benchmark of Bharath and Girshick [4] where we also achieve state-of-the-art results.},
	language = {en},
	urldate = {2021-06-12},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Gidaris, Spyros and Komodakis, Nikos},
	month = jun,
	year = {2018},
	keywords = {Read, Star},
	pages = {4367--4375},
	file = {Gidaris_Komodakis_2018_Dynamic Few-Shot Visual Learning Without Forgetting.pdf:/Users/orsonxu/Zotero/storage/K8HPYIQL/Gidaris_Komodakis_2018_Dynamic Few-Shot Visual Learning Without Forgetting.pdf:application/pdf;Gidaris_Komodakis_2018_Dynamic Few-Shot Visual Learning Without Forgetting.pdf:/Users/orsonxu/Zotero/storage/98KLGA83/Gidaris_Komodakis_2018_Dynamic Few-Shot Visual Learning Without Forgetting.pdf:application/pdf},
}

@article{ren_incremental_2019,
	title = {Incremental {Few}-{Shot} {Learning} with {Attention} {Attractor} {Networks}},
	url = {http://arxiv.org/abs/1810.07218},
	abstract = {Machine learning classiﬁers are often trained to recognize a set of pre-deﬁned classes. However, in many applications, it is often desirable to have the ﬂexibility of learning additional concepts, with limited data and without re-training on the full training set. This paper addresses this problem, incremental few-shot learning, where a regular classiﬁcation network has already been trained to recognize a set of base classes, and several extra novel classes are being considered, each with only a few labeled examples. After learning the novel classes, the model is then evaluated on the overall classiﬁcation performance on both base and novel classes. To this end, we propose a meta-learning model, the Attention Attractor Network, which regularizes the learning of novel classes. In each episode, we train a set of new weights to recognize novel classes until they converge, and we show that the technique of recurrent back-propagation can back-propagate through the optimization process and facilitate the learning of these parameters. We demonstrate that the learned attractor network can help recognize novel classes while remembering old classes without the need to review the original training set, outperforming various baselines.},
	language = {en},
	urldate = {2021-06-12},
	journal = {arXiv:1810.07218 [cs, stat]},
	author = {Ren, Mengye and Liao, Renjie and Fetaya, Ethan and Zemel, Richard S.},
	month = oct,
	year = {2019},
	keywords = {Read},
	file = {Ren et al_2019_Incremental Few-Shot Learning with Attention Attractor Networks.pdf:/Users/orsonxu/Zotero/storage/DQADJICN/Ren et al_2019_Incremental Few-Shot Learning with Attention Attractor Networks.pdf:application/pdf;Ren et al_2019_Incremental Few-Shot Learning with Attention Attractor Networks.pdf:/Users/orsonxu/Zotero/storage/44G6KVNF/Ren et al_2019_Incremental Few-Shot Learning with Attention Attractor Networks.pdf:application/pdf},
}

@article{khosla_supervised_2021,
	title = {Supervised {Contrastive} {Learning}},
	url = {http://arxiv.org/abs/2004.11362},
	abstract = {Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or significantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4\% on the ImageNet dataset, which is 0.8\% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows benefits for robustness to natural corruptions and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement, and reference TensorFlow code is released at https://t.ly/supcon.},
	urldate = {2021-06-14},
	journal = {arXiv:2004.11362 [cs, stat]},
	author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
	month = mar,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/JUPVVRUT/Khosla et al. - 2021 - Supervised Contrastive Learning.pdf:application/pdf;arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/YHZ9N8RN/2004.html:text/html},
}

@article{schwartz_-encoder_2018,
	title = {∆-encoder: an effective sample synthesis method for few-shot object recognition},
	abstract = {Learning to classify new categories based on just one or a few examples is a long-standing challenge in modern computer vision. In this work, we propose a simple yet effective method for few-shot (and one-shot) object recognition. Our approach is based on a modiﬁed auto-encoder, denoted ∆-encoder, that learns to synthesize new samples for an unseen category just by seeing few examples from it. The synthesized samples are then used to train a classiﬁer. The proposed approach learns to both extract transferable intra-class deformations, or "deltas", between same-class pairs of training examples, and to apply those deltas to the few provided examples of a novel class (unseen during training) in order to efﬁciently synthesize samples from that new class. The proposed method improves the state-of-the-art of one-shot object-recognition and performs comparably in the few-shot case.},
	language = {en},
	journal = {32nd Conference on Neural Information Processing Systems},
	author = {Schwartz, Eli and Karlinsky, Leonid and Shtok, Joseph and Harary, Sivan and Marder, Mattias and Kumar, Abhishek and Feris, Rogerio and Giryes, Raja and Bronstein, Alex M},
	year = {2018},
	pages = {11},
	file = {Schwartz et al. - ∆-encoder an effective sample synthesis method fo.pdf:/Users/orsonxu/Zotero/storage/PD8ZY6K5/Schwartz et al. - ∆-encoder an effective sample synthesis method fo.pdf:application/pdf},
}

@article{khosla_supervised_nodate,
	title = {Supervised {Contrastive} {Learning}},
	abstract = {Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or signiﬁcantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4\% on the ImageNet dataset, which is 0.8\% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows beneﬁts for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement and reference TensorFlow code is released at https://t.ly/supcon 1.},
	language = {en},
	author = {Khosla, Prannay and Tian, Yonglong and Teterwak, Piotr and Wang, Chen and Isola, Phillip and Maschinot, Aaron and Krishnan, Dilip and Sarna, Aaron},
	pages = {13},
	file = {Khosla et al. - Supervised Contrastive Learning.pdf:/Users/orsonxu/Zotero/storage/VDKE2924/Khosla et al. - Supervised Contrastive Learning.pdf:application/pdf},
}

@article{polikar_learn_2001,
	title = {Learn++: an incremental learning algorithm for supervised neural networks},
	volume = {31},
	issn = {1558-2442},
	shorttitle = {Learn++},
	doi = {10.1109/5326.983933},
	abstract = {We introduce Learn++, an algorithm for incremental training of neural network (NN) pattern classifiers. The proposed algorithm enables supervised NN paradigms, such as the multilayer perceptron (MLP), to accommodate new data, including examples that correspond to previously unseen classes. Furthermore, the algorithm does not require access to previously used data during subsequent incremental learning sessions, yet at the same time, it does not forget previously acquired knowledge. Learn++ utilizes ensemble of classifiers by generating multiple hypotheses using training data sampled according to carefully tailored distributions. The outputs of the resulting classifiers are combined using a weighted majority voting procedure. We present simulation results on several benchmark datasets as well as a real-world classification task. Initial results indicate that the proposed algorithm works rather well in practice. A theoretical upper bound on the error of the classifiers constructed by Learn++ is also provided.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Polikar, R. and Upda, L. and Upda, S.S. and Honavar, V.},
	month = nov,
	year = {2001},
	keywords = {Neural networks, Pattern recognition, Classification algorithms, Costs, Knowledge acquisition, Multilayer perceptrons, Stability, Training data, Upper bound, Voting},
	pages = {497--508},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/UUFSDCP3/983933.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/HM5RQZ7X/Polikar et al. - 2001 - Learn++ an incremental learning algorithm for sup.pdf:application/pdf},
}

@article{caruana_multitask_1997,
	title = {Multitask {Learning}},
	doi = {https://doi.org/10.1023/A:1007379606734},
	abstract = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
	language = {en},
	journal = {Machine Learning},
	author = {Caruana, Rich},
	year = {1997},
	pages = {35},
	file = {Caruana - Multitask Learning.pdf:/Users/orsonxu/Zotero/storage/5TKDP6EV/Caruana - Multitask Learning.pdf:application/pdf},
}

@article{zhang_survey_2021,
	title = {A {Survey} on {Multi}-{Task} {Learning}},
	issn = {1558-2191},
	doi = {10.1109/TKDE.2021.3070203},
	abstract = {Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL from the perspective of algorithmic modeling, applications, and theoretical analyses. For algorithmic modeling, we give a definition of MTL and then classify different MTL algorithms into five categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach, and decomposition approach as well as discussing the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning, and graphical models. When the number of tasks is large or the data dimensionality is high, we review online, parallel, and distributed MTL models as well as dimensionality reduction and feature hashing to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works. Finally, we present theoretical analyses and discuss several future directions for MTL.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Zhang, Yu and Yang, Qiang},
	year = {2021},
	keywords = {Machine Learning, Task analysis, Transfer learning, Supervised learning, Training, Classification algorithms, Artificial Intelligence, Computational modeling, Data models, Multi-Task Learning},
	pages = {1--1},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/NA7RPUCV/9392366.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/45X5RKNG/Zhang and Yang - 2021 - A Survey on Multi-Task Learning.pdf:application/pdf},
}

@article{french_catastrophic_1999,
	title = {Catastrophic forgetting in connectionist networks},
	volume = {3},
	language = {en},
	number = {4},
	journal = {Trends in Cognitive Sciences},
	author = {French, Robert M},
	year = {1999},
	pages = {8},
	file = {French - 1999 - Catastrophic forgetting in connectionist networks.pdf:/Users/orsonxu/Zotero/storage/RQSIQVIV/French - 1999 - Catastrophic forgetting in connectionist networks.pdf:application/pdf},
}

@article{iwana_empirical_2021,
	title = {An empirical survey of data augmentation for time series classification with neural networks},
	volume = {16},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0254841},
	doi = {10.1371/journal.pone.0254841},
	abstract = {In recent times, deep artificial neural networks have achieved many successes in pattern recognition. Part of this success can be attributed to the reliance on big data to increase generalization. However, in the field of time series recognition, many datasets are often very small. One method of addressing this problem is through the use of data augmentation. In this paper, we survey data augmentation techniques for time series and their application to time series classification with neural networks. We propose a taxonomy and outline the four families in time series data augmentation, including transformation-based methods, pattern mixing, generative models, and decomposition methods. Furthermore, we empirically evaluate 12 time series data augmentation methods on 128 time series classification datasets with six different types of neural networks. Through the results, we are able to analyze the characteristics, advantages and disadvantages, and recommendations of each data augmentation method. This survey aims to help in the selection of time series data augmentation for neural network applications.},
	language = {en},
	number = {7},
	urldate = {2021-08-05},
	journal = {PLOS ONE},
	author = {Iwana, Brian Kenji and Uchida, Seiichi},
	editor = {Schwenker, Friedhelm},
	month = jul,
	year = {2021},
	pages = {e0254841},
	file = {Iwana and Uchida - 2021 - An empirical survey of data augmentation for time .pdf:/Users/orsonxu/Zotero/storage/45UHH2PM/Iwana and Uchida - 2021 - An empirical survey of data augmentation for time .pdf:application/pdf},
}

@article{goodfellow_explaining_2015,
	title = {Explaining and {Harnessing} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1412.6572},
	abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
	urldate = {2021-08-05},
	journal = {Proceedings of International Conference on Learning Representations (2015)},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	month = mar,
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/6YSSPGUU/Goodfellow et al. - 2015 - Explaining and Harnessing Adversarial Examples.pdf:application/pdf;arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/TG8PJBSU/1412.html:text/html},
}

@article{ma_towards_2018,
	title = {{TOWARDS} {DEEP} {LEARNING} {MODELS} {RESISTANT} {TO} {ADVERSARIAL} {ATTACKS}},
	abstract = {Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classiﬁed incorrectly by the network. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against a well-deﬁned class of adversaries. These methods let us train networks with signiﬁcantly improved resistance to a wide range of adversarial attacks. They also suggest robustness against a ﬁrst-order adversary as a natural security guarantee. We believe that robustness against such well-deﬁned classes of adversaries is an important stepping stone towards fully resistant deep learning models.},
	language = {en},
	journal = {Proceedings of International Conference on Learning Representations (2018)},
	author = {Ma, Aleksander},
	year = {2018},
	pages = {23},
	file = {Ma - 2018 - TOWARDS DEEP LEARNING MODELS RESISTANT TO ADVERSAR.pdf:/Users/orsonxu/Zotero/storage/PBQ64E2Q/Ma - 2018 - TOWARDS DEEP LEARNING MODELS RESISTANT TO ADVERSAR.pdf:application/pdf},
}

@inproceedings{tan_efficientnet_2019,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://proceedings.mlr.press/v97/tan19a.html},
	language = {en},
	urldate = {2021-08-05},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Tan, Mingxing and Le, Quoc},
	month = may,
	year = {2019},
	pages = {6105--6114},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/KLWMBJAN/Tan and Le - 2019 - EfficientNet Rethinking Model Scaling for Convolu.pdf:application/pdf},
}

@book{mamalet_simplifying_2012,
	title = {Simplifying {ConvNets} for {Fast} {Learning}},
	isbn = {978-3-642-33265-4},
	abstract = {In this paper, we propose different strategies for simplifying filters, used as feature extractors, to be learnt in convolutional neural networks (ConvNets) in order to modify the hypothesis space, and to speed-up learning and processing times. We study two kinds of filters that are known to be computationally efficient in feed-forward processing: fused convolution/sub-sampling filters, and separable filters. We compare the complexity of the back-propagation algorithm on ConvNets based on these different kinds of filters. We show that using these filters allows to reach the same level of recognition performance as with classical ConvNets for handwritten digit recognition, up to 3.3 times faster.},
	author = {Mamalet, Franck and Garcia, Christophe},
	month = sep,
	year = {2012},
}

@inproceedings{chollet_xception_2017,
	address = {Honolulu, HI},
	title = {Xception: {Deep} {Learning} with {Depthwise} {Separable} {Convolutions}},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Xception},
	url = {http://ieeexplore.ieee.org/document/8099678/},
	doi = {10.1109/CVPR.2017.195},
	abstract = {We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and signiﬁcantly outperforms Inception V3 on a larger image classiﬁcation dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efﬁcient use of model parameters.},
	language = {en},
	urldate = {2021-08-05},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Chollet, Francois},
	month = jul,
	year = {2017},
	pages = {1800--1807},
	file = {Chollet - 2017 - Xception Deep Learning with Depthwise Separable C.pdf:/Users/orsonxu/Zotero/storage/MMEDZMBC/Chollet - 2017 - Xception Deep Learning with Depthwise Separable C.pdf:application/pdf},
}

@article{hinton_distilling_2015,
	title = {Distilling the {Knowledge} in a {Neural} {Network}},
	url = {http://arxiv.org/abs/1503.02531},
	abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
	urldate = {2021-08-06},
	journal = {arXiv:1503.02531 [cs, stat]},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	month = mar,
	year = {2015},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/457GSYX5/Hinton et al. - 2015 - Distilling the Knowledge in a Neural Network.pdf:application/pdf;arXiv.org Snapshot:/Users/orsonxu/Zotero/storage/XG7L477T/1503.html:text/html},
}

@article{hecht-nielsen_theory_1992,
	title = {Theory of the {Backpropagation} {Neural} {Network}},
	language = {en},
	journal = {Neural networks for perception},
	author = {Hecht-Nielsen, Robert},
	year = {1992},
	pages = {13},
	file = {Hecht-Nielsen - Theory of the Backpropagation Neural Network.pdf:/Users/orsonxu/Zotero/storage/WT5ADWXN/Hecht-Nielsen - Theory of the Backpropagation Neural Network.pdf:application/pdf},
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classiﬁcation model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a signiﬁcant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classiﬁcation: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
	language = {en},
	journal = {Proceedings of the 32 nd International Conference on Machine Learning},
	author = {Ioffe, Sergey and Szegedy, Christian},
	year = {2015},
	pages = {9},
	file = {Ioffe and Szegedy - Batch Normalization Accelerating Deep Network Tra.pdf:/Users/orsonxu/Zotero/storage/S6IPEAIA/Ioffe and Szegedy - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf},
}

@article{gal_dropout_2016,
	title = {Dropout as a {Bayesian} {Approximation}:  {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classiﬁcation do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs –extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacriﬁcing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classiﬁcation, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and ﬁnish by using dropout’s uncertainty in deep reinforcement learning.},
	language = {en},
	journal = {Proceedings of the 33 rd International Conference on Machine Learning},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	year = {2016},
	pages = {10},
	file = {Gal and Ghahramani - Dropout as a Bayesian Approximation  Representing.pdf:/Users/orsonxu/Zotero/storage/4RHK5EMV/Gal and Ghahramani - Dropout as a Bayesian Approximation  Representing.pdf:application/pdf},
}

@article{nair_rectified_2010,
	title = {Rectified {Linear} {Units} {Improve} {Restricted} {Boltzmann} {Machines}},
	abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
	language = {en},
	journal = {Proceedings of the 27 th International Conference on Machine Learning},
	author = {Nair, Vinod and Hinton, Geoffrey E},
	year = {2010},
	pages = {8},
	file = {Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:/Users/orsonxu/Zotero/storage/KL6MKC6B/Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:application/pdf},
}

@book{goodfellow_deep_2016,
	title = {Deep learning},
	publisher = {MIT press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville,, Aaron},
	year = {2016},
	file = {Deep_learning__adaptive_computation_and_machine_learning__PDFDrive.com_20190819-23861-ck1r7v-with-cover-page-v2.pdf:/Users/orsonxu/Zotero/storage/DNWKE37W/Deep_learning__adaptive_computation_and_machine_learning__PDFDrive.com_20190819-23861-ck1r7v-with-cover-page-v2.pdf:application/pdf},
}

@article{miyato_virtual_2019,
	title = {Virtual {Adversarial} {Training}: {A} {Regularization} {Method} for {Supervised} and {Semi}-{Supervised} {Learning}},
	volume = {41},
	issn = {1939-3539},
	shorttitle = {Virtual {Adversarial} {Training}},
	doi = {10.1109/TPAMI.2018.2858821},
	abstract = {We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only “virtually” adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward-and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Miyato, Takeru and Maeda, Shin-Ichi and Koyama, Masanori and Ishii, Shin},
	month = aug,
	year = {2019},
	keywords = {deep learning, Artificial neural networks, Training, Computational modeling, Data models, adversarial examples, adversarial training, Perturbation methods, robustness, Robustness, Semi-supervised learning, Semisupervised learning, supervised learning},
	pages = {1979--1993},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/H2B3BZEF/8417973.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/WT57LGGU/Miyato et al. - 2019 - Virtual Adversarial Training A Regularization Met.pdf:application/pdf},
}

@article{ester_density-based_1996,
	title = {A {Density}-{Based} {Algorithm} for {Discovering} {Clusters} in {Large} {Spatial} {Databases} with {Noise}},
	abstract = {Clusteringalgorithmasreattractivefor the taskof classidentification in spatial databases.Howevetrh, e applicationto large spatial databasesrises the followingrequirementfsor clustering algorithms: minimalrequirementsof domain knowledgteo determinethe input parameters,discoveryof clusters witharbitraryshapeandgoodefficiencyonlarge databases. Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf theserequirementsI.n this paper, wepresent the newclustering algorithmDBSCAreNlying on a density-basednotionof clusters whichis designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one input parameterandsupportsthe user in determiningan appropriatevaluefor it. Weperformeadn experimentaelvaluation of the effectiveness and efficiency of DBSCAusNing synthetic data and real data of the SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms CLARANbyS factorof morethan100in termsof efficiency.},
	language = {en},
	journal = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
	author = {Ester, Martin and Kriegel, Hans-Peter and Xu, Xiaowei},
	year = {1996},
	pages = {6},
	file = {Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:/Users/orsonxu/Zotero/storage/86LZH6LU/Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:application/pdf},
}

@article{campello_hierarchical_2015,
	title = {Hierarchical {Density} {Estimates} for {Data} {Clustering}, {Visualization}, and {Outlier} {Detection}},
	volume = {10},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/2733381},
	doi = {10.1145/2733381},
	abstract = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
	language = {en},
	number = {1},
	urldate = {2021-08-07},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Zimek, Arthur and Sander, Jörg},
	month = jul,
	year = {2015},
	pages = {1--51},
	file = {Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:/Users/orsonxu/Zotero/storage/R6Y3MVQ6/Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:application/pdf},
}

@inproceedings{hershey_cnn_2017,
	title = {{CNN} architectures for large-scale audio classification},
	doi = {10.1109/ICASSP.2017.7952132},
	abstract = {Convolutional Neural Networks (CNNs) have proven very effective in image classification and show promise for audio. We use various CNN architectures to classify the soundtracks of a dataset of 70M training videos (5.24 million hours) with 30,871 video-level labels. We examine fully connected Deep Neural Networks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We investigate varying the size of both training set and label vocabulary, finding that analogs of the CNNs used in image classification do well on our audio classification task, and larger training and label sets help up to a point. A model using embeddings from these classifiers does much better than raw features on the Audio Set [5] Acoustic Event Detection (AED) classification task.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel P. W. and Gemmeke, Jort F. and Jansen, Aren and Moore, R. Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A. and Seybold, Bryan and Slaney, Malcolm and Weiss, Ron J. and Wilson, Kevin},
	month = mar,
	year = {2017},
	keywords = {Hidden Markov models, Neural networks, Training, Acoustic Event Detection, Acoustic Scene Classification, Computer architecture, Convolutional Neural Networks, Deep Neural Networks, Servers, Spectrogram, Video Classification, Videos},
	pages = {131--135},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/G6G35YCJ/7952132.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/U92X385U/Hershey et al. - 2017 - CNN architectures for large-scale audio classifica.pdf:application/pdf},
}

@article{li_federated_2020,
	title = {Federated {Learning}: {Challenges}, {Methods}, and {Future} {Directions}},
	volume = {37},
	issn = {1558-0792},
	shorttitle = {Federated {Learning}},
	doi = {10.1109/MSP.2020.2975749},
	abstract = {Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.},
	number = {3},
	journal = {IEEE Signal Processing Magazine},
	author = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
	month = may,
	year = {2020},
	keywords = {Distributed databases, Machine learning, Privacy, Training data, Data models, Data privacy, Predictive models},
	pages = {50--60},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/EJWATBUU/9084352.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/H2QB2C9M/Li et al. - 2020 - Federated Learning Challenges, Methods, and Futur.pdf:application/pdf},
}

@article{greenewald_action_2017,
	title = {Action {Centered} {Contextual} {Bandits}},
	volume = {30},
	issn = {1049-5258},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5719505/},
	abstract = {Contextual bandits have become popular as they offer a middle ground between very simple approaches based on multi-armed bandits and very complex approaches using the full power of reinforcement learning. They have demonstrated success in web applications and have a rich body of associated theoretical guarantees. Linear models are well understood theoretically and preferred by practitioners because they are not only easily interpretable but also simple to implement and debug. Furthermore, if the linear model is true, we get very strong performance guarantees. Unfortunately, in emerging applications in mobile health, the time-invariant linear model assumption is untenable. We provide an extension of the linear model for contextual bandits that has two parts: baseline reward and treatment effect. We allow the former to be complex but keep the latter simple. We argue that this model is plausible for mobile health applications. At the same time, it leads to algorithms with strong performance guarantees as in the linear model setting, while still allowing for complex nonlinear baseline modeling. Our theory is supported by experiments on data gathered in a recently concluded mobile health study.},
	urldate = {2021-11-10},
	journal = {Advances in neural information processing systems},
	author = {Greenewald, Kristjan and Tewari, Ambuj and Klasnja, Predrag and Murphy, Susan},
	month = dec,
	year = {2017},
	pages = {5973--5981},
	file = {Greenewald et al_2017_Action Centered Contextual Bandits.pdf:/Users/orsonxu/Zotero/storage/8R9JNA8H/Greenewald et al_2017_Action Centered Contextual Bandits.pdf:application/pdf;Greenewald et al_2017_Action Centered Contextual Bandits.pdf:/Users/orsonxu/Zotero/storage/IRJD7CEC/Greenewald et al_2017_Action Centered Contextual Bandits.pdf:application/pdf},
}

@article{li_deep_2018,
	title = {Deep {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1810.06339},
	abstract = {We discuss deep reinforcement learning in an overview style. We draw a big picture, filled with details. We discuss six core elements, six important mechanisms, and twelve applications, focusing on contemporary work, and in historical contexts. We start with background of artificial intelligence, machine learning, deep learning, and reinforcement learning (RL), with resources. Next we discuss RL core elements, including value function, policy, reward, model, exploration vs. exploitation, and representation. Then we discuss important mechanisms for RL, including attention and memory, unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and learning to learn. After that, we discuss RL applications, including games, robotics, natural language processing (NLP), computer vision, finance, business management, healthcare, education, energy, transportation, computer systems, and, science, engineering, and art. Finally we summarize briefly, discuss challenges and opportunities, and close with an epilogue.},
	urldate = {2021-11-10},
	journal = {arXiv:1810.06339 [cs, stat]},
	author = {Li, Yuxi},
	month = oct,
	year = {2018},
	file = {Li_2018_Deep Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/K7V74UMH/Li_2018_Deep Reinforcement Learning.pdf:application/pdf;Li_2018_Deep Reinforcement Learning.pdf:/Users/orsonxu/Zotero/storage/GRU4XNC7/Li_2018_Deep Reinforcement Learning.pdf:application/pdf},
}

@article{boruvka_assessing_2018,
	title = {Assessing {Time}-{Varying} {Causal} {Effect} {Moderation} in {Mobile} {Health}},
	volume = {113},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1305274},
	doi = {10.1080/01621459.2017.1305274},
	abstract = {In mobile health interventions aimed at behavior change and maintenance, treatments are provided in real time to manage current or impending high risk situations or promote healthy behaviors in near real time. Currently there is great scientiﬁc interest in developing data analysis approaches to guide the development of mobile interventions. In particular data from mobile health studies might be used to examine eﬀect moderators—individual characteristics, time-varying context or past treatment response that moderate the eﬀect of current treatment on a subsequent response. This paper introduces a formal deﬁnition for moderated eﬀects in terms of potential outcomes, a deﬁnition that is particularly suited to mobile interventions, where treatment occasions are numerous, individuals are not always available for treatment, and potential moderators might be inﬂuenced by past treatment. Methods for estimating moderated eﬀects are developed and compared. The proposed approach is illustrated using BASICS-Mobile, a smartphone-based intervention designed to curb heavy drinking and smoking among college students.},
	language = {en},
	number = {523},
	urldate = {2021-11-11},
	journal = {Journal of the American Statistical Association},
	author = {Boruvka, Audrey and Almirall, Daniel and Witkiewitz, Katie and Murphy, Susan A.},
	month = jul,
	year = {2018},
	pages = {1112--1121},
	file = {Boruvka et al. - 2018 - Assessing Time-Varying Causal Effect Moderation in.pdf:/Users/orsonxu/Zotero/storage/3GFLLN8U/Boruvka et al. - 2018 - Assessing Time-Varying Causal Effect Moderation in.pdf:application/pdf},
}

@inproceedings{mothilal_explaining_2020,
	address = {Barcelona Spain},
	title = {Explaining machine learning classifiers through diverse counterfactual explanations},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3372850},
	doi = {10.1145/3351095.3372850},
	abstract = {Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.},
	language = {en},
	urldate = {2021-11-23},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mothilal, Ramaravind K. and Sharma, Amit and Tan, Chenhao},
	month = jan,
	year = {2020},
	keywords = {Unread},
	pages = {607--617},
	file = {Mothilal et al. - 2020 - Explaining machine learning classifiers through di.pdf:/Users/orsonxu/Zotero/storage/25N37EPI/Mothilal et al. - 2020 - Explaining machine learning classifiers through di.pdf:application/pdf},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {15662535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	language = {en},
	urldate = {2021-11-30},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	pages = {82--115},
	file = {Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:/Users/orsonxu/Zotero/storage/MEXVF7WC/Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf},
}

@article{wang_exploring_2021,
	title = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}: {Meta}-{Modeling} and an {Analytic} {Framework}},
	issn = {1558-2191},
	shorttitle = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}},
	doi = {10.1109/TKDE.2021.3130762},
	abstract = {The Spatio-Temporal Traffic Prediction (STTP) problem is a classical problem with plenty of prior research efforts that benefit from traditional statistical learning and recent deep learning approaches. While STTP can refer to many real-world problems, most existing studies focus on quite specific applications, such as the prediction of taxi demand, ridesharing order, traffic speed, and so on. This hinders the STTP research as the approaches designed for different applications are hardly comparable, and thus how an application-driven approach can be generalized to other scenarios is unclear. To fill in this gap, this paper makes three efforts: (i) we propose an analytic framework, called STAnalytic, to qualitatively investigate STTP approaches regarding their design considerations on various spatial and temporal factors, aiming to make different application-driven approaches comparable; (ii) we design a spatio-temporal meta-model, called STMeta, which can flexibly integrate generalizable temporal and spatial knowledge identified by STAnalytic, (iii) we build an extensively large-scale STTP benchmark platform including ten datasets with five scenarios to quantitatively measure the generalizability of STTP approaches. In particular, we implement STMeta with different deep learning techniques, and STMeta demonstrates better generalizability than state-of-the-art approaches by achieving lower prediction error on average across all the datasets.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wang, Leye and Chai, Di and Liu, Xuanzhe and Chen, Liyue and Chen, Kai},
	year = {2021},
	pages = {1--1},
	file = {Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:/Users/orsonxu/Zotero/storage/XCIJMEDD/Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:application/pdf;Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:/Users/orsonxu/Zotero/storage/MC276AGY/Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:application/pdf},
}

@incollection{leibe_deep_2016,
	address = {Cham},
	title = {Deep {Reconstruction}-{Classification} {Networks} for {Unsupervised} {Domain} {Adaptation}},
	volume = {9908},
	isbn = {978-3-319-46492-3 978-3-319-46493-0},
	url = {http://link.springer.com/10.1007/978-3-319-46493-0_36},
	abstract = {In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Speciﬁcally, we design a new model called Deep ReconstructionClassiﬁcation Network (DRCN), which jointly learns a shared encoding representation for two tasks: (i) supervised classiﬁcation of labeled source data, and (ii) unsupervised reconstruction of unlabeled target data. In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks.},
	language = {en},
	urldate = {2021-12-18},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Ghifary, Muhammad and Kleijn, W. Bastiaan and Zhang, Mengjie and Balduzzi, David and Li, Wen},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	pages = {597--613},
	file = {Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:/Users/orsonxu/Zotero/storage/JMBAWMU6/Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:application/pdf},
}

@article{tzeng_deep_2014,
	title = {Deep {Domain} {Confusion}: {Maximizing} for {Domain} {Invariance}},
	shorttitle = {Deep {Domain} {Confusion}},
	url = {http://arxiv.org/abs/1412.3474},
	abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
	urldate = {2021-12-18},
	journal = {arXiv:1412.3474 [cs]},
	author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	month = dec,
	year = {2014},
	file = {Tzeng et al_2014_Deep Domain Confusion.pdf:/Users/orsonxu/Zotero/storage/ALNGH28P/Tzeng et al_2014_Deep Domain Confusion.pdf:application/pdf;Tzeng et al_2014_Deep Domain Confusion.pdf:/Users/orsonxu/Zotero/storage/2DQHFN37/Tzeng et al_2014_Deep Domain Confusion.pdf:application/pdf},
}

@article{wang_generalizing_2021,
	title = {Generalizing to {Unseen} {Domains}: {A} {Survey} on {Domain} {Generalization}},
	shorttitle = {Generalizing to {Unseen} {Domains}},
	url = {http://arxiv.org/abs/2103.03097},
	abstract = {Machine learning systems generally assume that the training and testing distributions are the same. To this end, a key requirement is to develop models that can generalize to unseen distributions. Domain generalization (DG), i.e., out-of-distribution generalization, has attracted increasing interests in recent years. Domain generalization deals with a challenging setting where one or several different but related domain(s) are given, and the goal is to learn a model that can generalize to an unseen test domain. Great progress has been made in the area of domain generalization for years. This paper presents the first review of recent advances in this area. First, we provide a formal definition of domain generalization and discuss several related fields. We then thoroughly review the theories related to domain generalization and carefully analyze the theory behind generalization. We categorize recent algorithms into three classes: data manipulation, representation learning, and learning strategy, and present several popular algorithms in detail for each category. Third, we introduce the commonly used datasets, applications, and our open-sourced codebase for fair evaluation. Finally, we summarize existing literature and present some potential research topics for the future.},
	urldate = {2021-12-19},
	journal = {arXiv:2103.03097 [cs]},
	author = {Wang, Jindong and Lan, Cuiling and Liu, Chang and Ouyang, Yidong and Qin, Tao and Lu, Wang and Chen, Yiqiang and Zeng, Wenjun and Yu, Philip S.},
	month = dec,
	year = {2021},
	file = {Wang et al_2021_Generalizing to Unseen Domains.pdf:/Users/orsonxu/Zotero/storage/JIGZC96Z/Wang et al_2021_Generalizing to Unseen Domains.pdf:application/pdf;Wang et al_2021_Generalizing to Unseen Domains.pdf:/Users/orsonxu/Zotero/storage/JAPH8S4I/Wang et al_2021_Generalizing to Unseen Domains.pdf:application/pdf},
}

@article{zhou_domain_2021,
	title = {Domain {Generalization} in {Vision}: {A} {Survey}},
	shorttitle = {Domain {Generalization} in {Vision}},
	url = {http://arxiv.org/abs/2103.02503},
	abstract = {Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d.{\textasciitilde}assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Since first introduced in 2011, research in DG has made great progresses. In particular, intensive research in this topic has led to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, just to name a few; and has covered various vision applications such as object recognition, segmentation, action recognition, and person re-identification. In this paper, for the first time a comprehensive literature review is provided to summarize the developments in DG for computer vision over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other research fields like domain adaptation and transfer learning. Second, we conduct a thorough review into existing methods and present a categorization based on their methodologies and motivations. Finally, we conclude this survey with insights and discussions on future research directions.},
	urldate = {2021-12-22},
	journal = {arXiv:2103.02503 [cs]},
	author = {Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
	month = jul,
	year = {2021},
	file = {Zhou et al_2021_Domain Generalization in Vision.pdf:/Users/orsonxu/Zotero/storage/3YPA9FCJ/Zhou et al_2021_Domain Generalization in Vision.pdf:application/pdf;Zhou et al_2021_Domain Generalization in Vision.pdf:/Users/orsonxu/Zotero/storage/FSHBJABJ/Zhou et al_2021_Domain Generalization in Vision.pdf:application/pdf},
}

@incollection{hutchison_undoing_2012,
	address = {Berlin, Heidelberg},
	title = {Undoing the {Damage} of {Dataset} {Bias}},
	volume = {7572},
	isbn = {978-3-642-33717-8 978-3-642-33718-5},
	url = {http://link.springer.com/10.1007/978-3-642-33718-5_12},
	abstract = {The presence of bias in existing object recognition datasets is now well-known in the computer vision community. While it remains in question whether creating an unbiased dataset is possible given limited resources, in this work we propose a discriminative framework that directly exploits dataset bias during training. In particular, our model learns two sets of weights: (1) bias vectors associated with each individual dataset, and (2) visual world weights that are common to all datasets, which are learned by undoing the associated bias from each dataset. The visual world weights are expected to be our best possible approximation to the object model trained on an unbiased dataset, and thus tend to have good generalization ability. We demonstrate the eﬀectiveness of our model by applying the learned weights to a novel, unseen dataset, and report superior results for both classiﬁcation and detection tasks compared to a classical SVM that does not account for the presence of bias. Overall, we ﬁnd that it is beneﬁcial to explicitly account for bias when combining multiple datasets.},
	language = {en},
	urldate = {2021-12-22},
	booktitle = {Computer {Vision} – {ECCV} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Khosla, Aditya and Zhou, Tinghui and Malisiewicz, Tomasz and Efros, Alexei A. and Torralba, Antonio},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
	year = {2012},
	pages = {158--171},
	file = {Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:/Users/orsonxu/Zotero/storage/EAF7RLGJ/Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:application/pdf},
}

@inproceedings{ismail_fawaz_transfer_2018,
	title = {Transfer learning for time series classification},
	doi = {10.1109/BigData.2018.8621990},
	abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network’s weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network’s generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the models predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = dec,
	year = {2018},
	pages = {1367--1376},
	file = {Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:/Users/orsonxu/Zotero/storage/PUFQTCMQ/Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:application/pdf;Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:/Users/orsonxu/Zotero/storage/H4IZLX7K/Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:application/pdf},
}

@article{ismail_fawaz_inceptiontime_2020,
	title = {{InceptionTime}: {Finding} {AlexNet} for time series classification},
	volume = {34},
	issn = {1384-5810, 1573-756X},
	shorttitle = {{InceptionTime}},
	url = {https://link.springer.com/10.1007/s10618-020-00710-y},
	doi = {10.1007/s10618-020-00710-y},
	abstract = {This paper brings deep learning at the forefront of research into time series classiﬁcation (TSC). TSC is the area of machine learning tasked with the categorization (or labelling) of time series. The last few decades of work in this area have led to signiﬁcant progress in the accuracy of classiﬁers, with the state of the art now represented by the HIVE-COTE algorithm. While extremely accurate, HIVE-COTE cannot be applied to many real-world datasets because of its high training time complexity in O(N 2 · T 4) for a dataset with N time series of length T . For example, it takes HIVE-COTE more than 8 days to learn from a small dataset with N = 1500 time series of short length T = 46. Meanwhile deep learning has received enormous attention because of its high accuracy and scalability. Recent approaches to deep learning for TSC have been scalable, but less accurate than HIVE-COTE. We introduce InceptionTime—an ensemble of deep Convolutional Neural Network models, inspired by the Inception-v4 architecture. Our experiments show that InceptionTime is on par with HIVE-COTE in terms of accuracy while being much more scalable: not only can it learn from 1500 time series in one hour but it can also learn from 8M time series in 13 h, a quantity of data that is fully out of reach of HIVE-COTE.},
	language = {en},
	number = {6},
	urldate = {2021-12-23},
	journal = {Data Mining and Knowledge Discovery},
	author = {Ismail Fawaz, Hassan and Lucas, Benjamin and Forestier, Germain and Pelletier, Charlotte and Schmidt, Daniel F. and Weber, Jonathan and Webb, Geoffrey I. and Idoumghar, Lhassane and Muller, Pierre-Alain and Petitjean, François},
	month = nov,
	year = {2020},
	pages = {1936--1962},
	file = {Ismail Fawaz et al. - 2020 - InceptionTime Finding AlexNet for time series cla.pdf:/Users/orsonxu/Zotero/storage/QJDN9P29/Ismail Fawaz et al. - 2020 - InceptionTime Finding AlexNet for time series cla.pdf:application/pdf},
}

@article{dempster_rocket_2020,
	title = {{ROCKET}: exceptionally fast and accurate time series classification using random convolutional kernels},
	volume = {34},
	issn = {1384-5810, 1573-756X},
	shorttitle = {{ROCKET}},
	url = {https://link.springer.com/10.1007/s10618-020-00701-z},
	doi = {10.1007/s10618-020-00701-z},
	abstract = {Most methods for time series classiﬁcation that attain state-of-the-art accuracy have high computational complexity, requiring signiﬁcant training time even for smaller datasets, and are intractable for larger datasets. Additionally, many existing methods focus on a single type of feature such as shape or frequency. Building on the recent success of convolutional neural networks for time series classiﬁcation, we show that simple linear classiﬁers using random convolutional kernels achieve state-of-the-art accuracy with a fraction of the computational expense of existing methods. Using this method, it is possible to train and test a classiﬁer on all 85 ‘bake off’ datasets in the UCR archive in {\textless} 2 h, and it is possible to train a classiﬁer on a large dataset of more than one million time series in approximately 1 h.},
	language = {en},
	number = {5},
	urldate = {2021-12-23},
	journal = {Data Mining and Knowledge Discovery},
	author = {Dempster, Angus and Petitjean, François and Webb, Geoffrey I.},
	month = sep,
	year = {2020},
	pages = {1454--1495},
	file = {Dempster et al. - 2020 - ROCKET exceptionally fast and accurate time serie.pdf:/Users/orsonxu/Zotero/storage/UCKJMWA2/Dempster et al. - 2020 - ROCKET exceptionally fast and accurate time serie.pdf:application/pdf},
}

@inproceedings{chen_simple_2020,
	title = {A {Simple} {Framework} for {Contrastive} {Learning} of {Visual} {Representations}},
	url = {https://proceedings.mlr.press/v119/chen20j.html},
	abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
	language = {en},
	urldate = {2022-01-04},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	month = nov,
	year = {2020},
	pages = {1597--1607},
	file = {Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:/Users/orsonxu/Zotero/storage/6KI7RT8I/Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:application/pdf;Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:/Users/orsonxu/Zotero/storage/MYKCZ9X8/Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:application/pdf;Supplementary PDF:/Users/orsonxu/Zotero/storage/GR29F3TD/Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Vis.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	urldate = {2022-01-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	file = {Vaswani et al_2017_Attention is All you Need.pdf:/Users/orsonxu/Zotero/storage/GTYFGY6G/Vaswani et al_2017_Attention is All you Need.pdf:application/pdf;Vaswani et al_2017_Attention is All you Need.pdf:/Users/orsonxu/Zotero/storage/XYB789UB/Vaswani et al_2017_Attention is All you Need.pdf:application/pdf},
}

@incollection{holzinger_explainable_2018,
	address = {Cham},
	title = {Explainable {AI}: {The} {New} 42?},
	volume = {11015},
	isbn = {978-3-319-99739-1 978-3-319-99740-7},
	shorttitle = {Explainable {AI}},
	url = {https://link.springer.com/10.1007/978-3-319-99740-7_21},
	abstract = {Explainable AI is not a new ﬁeld. Since at least the early exploitation of C.S. Pierce’s abductive reasoning in expert systems of the 1980s, there were reasoning architectures to support an explanation function for complex AI systems, including applications in medical diagnosis, complex multi-component design, and reasoning about the real world. So explainability is at least as old as early AI, and a natural consequence of the design of AI systems. While early expert systems consisted of handcrafted knowledge bases that enabled reasoning over narrowly well-deﬁned domains (e.g., INTERNIST, MYCIN), such systems had no learning capabilities and had only primitive uncertainty handling. But the evolution of formal reasoning architectures to incorporate principled probabilistic reasoning helped address the capture and use of uncertain knowledge.},
	language = {en},
	urldate = {2022-01-05},
	booktitle = {Machine {Learning} and {Knowledge} {Extraction}},
	publisher = {Springer International Publishing},
	author = {Goebel, Randy and Chander, Ajay and Holzinger, Katharina and Lecue, Freddy and Akata, Zeynep and Stumpf, Simone and Kieseberg, Peter and Holzinger, Andreas},
	editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
	year = {2018},
	pages = {295--303},
	file = {Goebel et al. - 2018 - Explainable AI The New 42.pdf:/Users/orsonxu/Zotero/storage/3KCB9T5W/Goebel et al. - 2018 - Explainable AI The New 42.pdf:application/pdf},
}

@article{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2022-01-06},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	file = {Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:/Users/orsonxu/Zotero/storage/Y69VA74H/Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:application/pdf;Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:/Users/orsonxu/Zotero/storage/ZM9UVMIA/Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:application/pdf},
}

@article{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be ﬁnetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspeciﬁc architecture modiﬁcations.},
	language = {en},
	urldate = {2022-01-06},
	journal = {arXiv:1810.04805 [cs]},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	file = {Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:/Users/orsonxu/Zotero/storage/BHLTLUW4/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf},
}

@article{volpi_generalizing_2018,
	title = {Generalizing to {Unseen} {Domains} via {Adversarial} {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1805.12018},
	abstract = {We are concerned with learning models that generalize well to different {\textbackslash}emph\{unseen\} domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from a single source distribution, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers that regularize towards zero (e.g., ridge or lasso). On digit recognition and semantic segmentation tasks, our method learns models improve performance across a range of a priori unknown target domains.},
	urldate = {2022-01-07},
	journal = {arXiv:1805.12018 [cs]},
	author = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John and Murino, Vittorio and Savarese, Silvio},
	month = nov,
	year = {2018},
	file = {Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:/Users/orsonxu/Zotero/storage/RCJERJMV/Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:application/pdf;Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:/Users/orsonxu/Zotero/storage/SISIP6LM/Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:application/pdf},
}

@article{shankar_generalizing_2018,
	title = {Generalizing {Across} {Domains} via {Cross}-{Gradient} {Training}},
	url = {http://arxiv.org/abs/1804.10745},
	abstract = {We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.},
	urldate = {2022-01-09},
	journal = {arXiv:1804.10745 [cs, stat]},
	author = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
	month = may,
	year = {2018},
	file = {Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:/Users/orsonxu/Zotero/storage/ENYXLWAQ/Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:application/pdf;Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:/Users/orsonxu/Zotero/storage/JITGZQ27/Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:application/pdf},
}

@article{li_learning_2017,
	title = {Learning to {Generalize}: {Meta}-{Learning} for {Domain} {Generalization}},
	shorttitle = {Learning to {Generalize}},
	url = {http://arxiv.org/abs/1710.03463},
	abstract = {Domain shift refers to the well known problem that a model trained in one source domain performs poorly when applied to a target domain with different statistics. \{Domain Generalization\} (DG) techniques attempt to alleviate this issue by producing models which by design generalize well to novel testing domains. We propose a novel \{meta-learning\} method for domain generalization. Rather than designing a specific model that is robust to domain shift as in most previous DG work, we propose a model agnostic training procedure for DG. Our algorithm simulates train/test domain shift during training by synthesizing virtual testing domains within each mini-batch. The meta-optimization objective requires that steps to improve training domain performance should also improve testing domain performance. This meta-learning procedure trains models with good generalization ability to novel domains. We evaluate our method and achieve state of the art results on a recent cross-domain image classification benchmark, as well demonstrating its potential on two classic reinforcement learning tasks.},
	urldate = {2022-01-15},
	journal = {arXiv:1710.03463 [cs]},
	author = {Li, Da and Yang, Yongxin and Song, Yi-Zhe and Hospedales, Timothy M.},
	month = oct,
	year = {2017},
	file = {Li et al_2017_Learning to Generalize.pdf:/Users/orsonxu/Zotero/storage/JRGE2GNQ/Li et al_2017_Learning to Generalize.pdf:application/pdf;Li et al_2017_Learning to Generalize.pdf:/Users/orsonxu/Zotero/storage/HGXJTB5C/Li et al_2017_Learning to Generalize.pdf:application/pdf},
}

@inproceedings{balaji_metareg_2018,
	title = {{MetaReg}: {Towards} {Domain} {Generalization} using {Meta}-{Regularization}},
	volume = {31},
	shorttitle = {{MetaReg}},
	url = {https://proceedings.neurips.cc/paper/2018/hash/647bba344396e7c8170902bcf2e15551-Abstract.html},
	urldate = {2022-01-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Balaji, Yogesh and Sankaranarayanan, Swami and Chellappa, Rama},
	year = {2018},
	file = {Balaji et al_2018_MetaReg.pdf:/Users/orsonxu/Zotero/storage/N6NZF56X/Balaji et al_2018_MetaReg.pdf:application/pdf;Balaji et al_2018_MetaReg.pdf:/Users/orsonxu/Zotero/storage/SLJIJG5R/Balaji et al_2018_MetaReg.pdf:application/pdf},
}

@inproceedings{li_feature-critic_2019,
	title = {Feature-{Critic} {Networks} for {Heterogeneous} {Domain} {Generalization}},
	url = {https://proceedings.mlr.press/v97/li19l.html},
	abstract = {The well known domain shift issue causes model performance to degrade when deployed to a new target domain with different statistics to training. Domain adaptation techniques alleviate this, but need some instances from the target domain to drive adaptation. Domain generalisation is the recently topical problem of learning a model that generalises to unseen domains out of the box, and various approaches aim to train a domain-invariant feature extractor, typically by adding some manually designed losses. In this work, we propose a learning to learn approach, where the auxiliary loss that helps generalisation is itself learned. Beyond conventional domain generalisation, we consider a more challenging setting of heterogeneous domain generalisation, where the unseen domains do not share label space with the seen ones, and the goal is to train a feature representation that is useful off-the-shelf for novel data and novel categories. Experimental evaluation demonstrates that our method outperforms state-of-the-art solutions in both settings.},
	language = {en},
	urldate = {2022-01-16},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Li, Yiying and Yang, Yongxin and Zhou, Wei and Hospedales, Timothy},
	month = may,
	year = {2019},
	pages = {3915--3924},
	file = {Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:/Users/orsonxu/Zotero/storage/IYDDVHZI/Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:application/pdf;Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:/Users/orsonxu/Zotero/storage/65ZI5VJB/Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:application/pdf},
}

@article{dou_domain_2019,
	title = {Domain {Generalization} via {Model}-{Agnostic} {Learning} of {Semantic} {Features}},
	url = {http://arxiv.org/abs/1910.13580},
	abstract = {Generalization capability to unseen domains is crucial for machine learning models when deploying to real-world conditions. We investigate the challenging problem of domain generalization, i.e., training a model on multi-domain source data such that it can directly generalize to target domains with unknown statistics. We adopt a model-agnostic learning paradigm with gradient-based meta-train and meta-test procedures to expose the optimization to domain shift. Further, we introduce two complementary losses which explicitly regularize the semantic structure of the feature space. Globally, we align a derived soft confusion matrix to preserve general knowledge about inter-class relationships. Locally, we promote domain-independent class-specific cohesion and separation of sample features with a metric-learning component. The effectiveness of our method is demonstrated with new state-of-the-art results on two common object recognition benchmarks. Our method also shows consistent improvement on a medical image segmentation task.},
	urldate = {2022-01-16},
	journal = {arXiv:1910.13580 [cs]},
	author = {Dou, Qi and Castro, Daniel C. and Kamnitsas, Konstantinos and Glocker, Ben},
	month = oct,
	year = {2019},
	file = {Dou et al_2019_Domain Generalization via Model-Agnostic Learning of Semantic Features.pdf:/Users/orsonxu/Zotero/storage/ZQPSUF7L/Dou et al_2019_Domain Generalization via Model-Agnostic Learning of Semantic Features.pdf:application/pdf;Dou et al_2019_Domain Generalization via Model-Agnostic Learning of Semantic Features.pdf:/Users/orsonxu/Zotero/storage/3LCDPSYV/Dou et al_2019_Domain Generalization via Model-Agnostic Learning of Semantic Features.pdf:application/pdf},
}

@article{xie_unsupervised_2016,
	title = {Unsupervised {Deep} {Embedding} for {Clustering} {Analysis}},
	abstract = {Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show signiﬁcant improvement over state-of-the-art methods.},
	language = {en},
	journal = {Proceedings of the 33 rd International Conference on Machine Learning},
	author = {Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
	year = {2016},
	pages = {10},
	file = {Xie et al. - Unsupervised Deep Embedding for Clustering Analysi.pdf:/Users/orsonxu/Zotero/storage/6INXWKC7/Xie et al. - Unsupervised Deep Embedding for Clustering Analysi.pdf:application/pdf},
}

@inproceedings{guo_improved_2017,
	address = {Melbourne, Australia},
	title = {Improved {Deep} {Embedded} {Clustering} with {Local} {Structure} {Preservation}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/243},
	doi = {10.24963/ijcai.2017/243},
	abstract = {Deep clustering learns deep feature representations that favor clustering task using neural networks. Some pioneering work proposes to simultaneously learn embedded features and perform clustering by explicitly deﬁning a clustering oriented loss. Though promising performance has been demonstrated in various applications, we observe that a vital ingredient has been overlooked by these work that the deﬁned clustering loss may corrupt feature space, which leads to non-representative meaningless features and this in turn hurts clustering performance. To address this issue, in this paper, we propose the Improved Deep Embedded Clustering (IDEC) algorithm to take care of data structure preservation. Speciﬁcally, we manipulate feature space to scatter data points using a clustering loss as guidance. To constrain the manipulation and maintain the local structure of data generating distribution, an under-complete autoencoder is applied. By integrating the clustering loss and autoencoder’s reconstruction loss, IDEC can jointly optimize cluster labels assignment and learn features that are suitable for clustering with local structure preservation. The resultant optimization problem can be effectively solved by mini-batch stochastic gradient descent and backpropagation. Experiments on image and text datasets empirically validate the importance of local structure preservation and the effectiveness of our algorithm.},
	language = {en},
	urldate = {2022-01-19},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Guo, Xifeng and Gao, Long and Liu, Xinwang and Yin, Jianping},
	month = aug,
	year = {2017},
	pages = {1753--1759},
	file = {Guo et al. - 2017 - Improved Deep Embedded Clustering with Local Struc.pdf:/Users/orsonxu/Zotero/storage/LGXLIGB2/Guo et al. - 2017 - Improved Deep Embedded Clustering with Local Struc.pdf:application/pdf},
}

@incollection{liu_deep_2017,
	address = {Cham},
	title = {Deep {Clustering} with {Convolutional} {Autoencoders}},
	volume = {10635},
	isbn = {978-3-319-70095-3 978-3-319-70096-0},
	url = {http://link.springer.com/10.1007/978-3-319-70096-0_39},
	abstract = {Deep clustering utilizes deep neural networks to learn feature representation that is suitable for clustering tasks. Though demonstrating promising performance in various applications, we observe that existing deep clustering algorithms either do not well take advantage of convolutional neural networks or do not considerably preserve the local structure of data generating distribution in the learned feature space. To address this issue, we propose a deep convolutional embedded clustering algorithm in this paper. Speciﬁcally, we develop a convolutional autoencoders structure to learn embedded features in an end-to-end way. Then, a clustering oriented loss is directly built on embedded features to jointly perform feature reﬁnement and cluster assignment. To avoid feature space being distorted by the clustering loss, we keep the decoder remained which can preserve local structure of data in feature space. In sum, we simultaneously minimize the reconstruction loss of convolutional autoencoders and the clustering loss. The resultant optimization problem can be eﬀectively solved by mini-batch stochastic gradient descent and back-propagation. Experiments on benchmark datasets empirically validate the power of convolutional autoencoders for feature learning and the eﬀectiveness of local structure preservation.},
	language = {en},
	urldate = {2022-01-19},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Guo, Xifeng and Liu, Xinwang and Zhu, En and Yin, Jianping},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M.},
	year = {2017},
	pages = {373--382},
	file = {Guo et al. - 2017 - Deep Clustering with Convolutional Autoencoders.pdf:/Users/orsonxu/Zotero/storage/PBGLDEBP/Guo et al. - 2017 - Deep Clustering with Convolutional Autoencoders.pdf:application/pdf},
}

@article{zhang_explainable_2020,
	title = {Explainable {Recommendation}: {A} {Survey} and {New} {Perspectives}},
	volume = {14},
	issn = {1554-0669, 1554-0677},
	shorttitle = {Explainable {Recommendation}},
	url = {http://arxiv.org/abs/1804.11192},
	doi = {10.1561/1500000066},
	abstract = {Explainable recommendation attempts to develop models that generate not only high-quality recommendations but also intuitive explanations. The explanations may either be post-hoc or directly come from an explainable model (also called interpretable or transparent model in some contexts). Explainable recommendation tries to address the problem of why: by providing explanations to users or system designers, it helps humans to understand why certain items are recommended by the algorithm, where the human can either be users or system designers. Explainable recommendation helps to improve the transparency, persuasiveness, effectiveness, trustworthiness, and satisfaction of recommendation systems. It also facilitates system designers for better system debugging. In recent years, a large number of explainable recommendation approaches -- especially model-based methods -- have been proposed and applied in real-world systems. In this survey, we provide a comprehensive review for the explainable recommendation research. We first highlight the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation on three perspectives: 1) We provide a chronological research timeline of explainable recommendation. 2) We provide a two-dimensional taxonomy to classify existing explainable recommendation research. 3) We summarize how explainable recommendation applies to different recommendation tasks. We also devote a chapter to discuss the explanation perspectives in broader IR and AI/ML research. We end the survey by discussing potential future directions to promote the explainable recommendation research area and beyond.},
	number = {1},
	urldate = {2022-01-25},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Zhang, Yongfeng and Chen, Xu},
	year = {2020},
	pages = {1--101},
	file = {Zhang_Chen_2020_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/IRQ5T486/Zhang_Chen_2020_Explainable Recommendation.pdf:application/pdf;Zhang_Chen_2020_Explainable Recommendation.pdf:/Users/orsonxu/Zotero/storage/SPBAXHQ7/Zhang_Chen_2020_Explainable Recommendation.pdf:application/pdf},
}

@article{muandet_domain_2013,
	title = {Domain {Generalization} via {Invariant} {Feature} {Representation}},
	abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classiﬁers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classiﬁer performance in practice.},
	language = {en},
	journal = {Proceedings of the 30 th International Conference on Machine Learning},
	author = {Muandet, Krikamol and Balduzzi, David and Scholkopf, Bernhard},
	year = {2013},
	pages = {9},
	file = {Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:/Users/orsonxu/Zotero/storage/2DFZWPP8/Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:application/pdf},
}

@inproceedings{li_domain_2018,
	address = {Salt Lake City, UT},
	title = {Domain {Generalization} with {Adversarial} {Feature} {Learning}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578664/},
	doi = {10.1109/CVPR.2018.00566},
	abstract = {In this paper, we tackle the problem of domain generalization: how to learn a generalized feature representation for an “unseen” target domain by taking the advantage of multiple seen source-domain data. We present a novel framework based on adversarial autoencoders to learn a generalized latent feature representation across domains for domain generalization. To be speciﬁc, we extend adversarial autoencoders by imposing the Maximum Mean Discrepancy (MMD) measure to align the distributions among different domains, and matching the aligned distribution to an arbitrary prior distribution via adversarial feature learning. In this way, the learned feature representation is supposed to be universal to the seen source domains because of the MMD regularization, and is expected to generalize well on the target domain because of the introduction of the prior distribution. We proposed an algorithm to jointly train different components of our proposed framework. Extensive experiments on various vision tasks demonstrate that our proposed framework can learn better generalized features for the unseen target domain compared with state-of-the-art domain generalization methods.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C.},
	month = jun,
	year = {2018},
	pages = {5400--5409},
	file = {Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:/Users/orsonxu/Zotero/storage/NKAX356P/Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:application/pdf},
}

@incollection{ferrari_deep_2018,
	address = {Cham},
	title = {Deep {Domain} {Generalization} via {Conditional} {Invariant} {Adversarial} {Networks}},
	volume = {11219},
	isbn = {978-3-030-01266-3 978-3-030-01267-0},
	url = {http://link.springer.com/10.1007/978-3-030-01267-0_38},
	abstract = {Domain generalization aims to learn a classiﬁcation model from multiple source domains and generalize it to unseen target domains. A critical problem in domain generalization involves learning domaininvariant representations. Let X and Y denote the features and the labels, respectively. Under the assumption that the conditional distribution P (Y {\textbar}X) remains unchanged across domains, earlier approaches to domain generalization learned the invariant representation T (X) by minimizing the discrepancy of the marginal distribution P (T (X)). However, such an assumption of stable P (Y {\textbar}X) does not necessarily hold in practice. In addition, the representation learning function T (X) is usually constrained to a simple linear transformation or shallow networks. To address the above two drawbacks, we propose an end-to-end conditional invariant deep domain generalization approach by leveraging deep neural networks for domain-invariant representation learning. The domain-invariance property is guaranteed through a conditional invariant adversarial network that can learn domain-invariant representations w.r.t. the joint distribution P (T (X), Y ) if the target domain data are not severely class unbalanced. We perform various experiments to demonstrate the eﬀectiveness of the proposed method.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	pages = {647--663},
	file = {Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:/Users/orsonxu/Zotero/storage/YXYLRSHK/Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:application/pdf},
}

@article{arjovsky_invariant_2020,
	title = {Invariant {Risk} {Minimization}},
	url = {http://arxiv.org/abs/1907.02893},
	abstract = {We introduce Invariant Risk Minimization (IRM), a learning paradigm to estimate invariant correlations across multiple training distributions. To achieve this goal, IRM learns a data representation such that the optimal classifier, on top of that data representation, matches for all training distributions. Through theory and experiments, we show how the invariances learned by IRM relate to the causal structures governing the data and enable out-of-distribution generalization.},
	language = {en},
	urldate = {2022-02-04},
	journal = {arXiv:1907.02893 [cs, stat]},
	author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
	month = mar,
	year = {2020},
	file = {Arjovsky et al. - 2020 - Invariant Risk Minimization.pdf:/Users/orsonxu/Zotero/storage/BWQUXK3W/Arjovsky et al. - 2020 - Invariant Risk Minimization.pdf:application/pdf},
}

@article{piratla_efficient_2020,
	title = {Efficient {Domain} {Generalization} via {Common}-{Specific} {Low}-{Rank} {Decomposition}},
	url = {http://arxiv.org/abs/2003.12815},
	abstract = {Domain generalization refers to the task of training a model which generalizes to new domains that are not seen during training. We present CSD (Common Specific Decomposition), for this setting,which jointly learns a common component (which generalizes to new domains) and a domain specific component (which overfits on training domains). The domain specific components are discarded after training and only the common component is retained. The algorithm is extremely simple and involves only modifying the final linear classification layer of any given neural network architecture. We present a principled analysis to understand existing approaches, provide identifiability results of CSD,and study effect of low-rank on domain generalization. We show that CSD either matches or beats state of the art approaches for domain generalization based on domain erasure, domain perturbed data augmentation, and meta-learning. Further diagnostics on rotated MNIST, where domains are interpretable, confirm the hypothesis that CSD successfully disentangles common and domain specific components and hence leads to better domain generalization.},
	urldate = {2022-02-08},
	journal = {arXiv:2003.12815 [cs, stat]},
	author = {Piratla, Vihari and Netrapalli, Praneeth and Sarawagi, Sunita},
	month = apr,
	year = {2020},
	file = {Piratla et al_2020_Efficient Domain Generalization via Common-Specific Low-Rank Decomposition.pdf:/Users/orsonxu/Zotero/storage/RAJPYFYV/Piratla et al_2020_Efficient Domain Generalization via Common-Specific Low-Rank Decomposition.pdf:application/pdf;Piratla et al_2020_Efficient Domain Generalization via Common-Specific Low-Rank Decomposition.pdf:/Users/orsonxu/Zotero/storage/W8L8EVWV/Piratla et al_2020_Efficient Domain Generalization via Common-Specific Low-Rank Decomposition.pdf:application/pdf},
}

@article{carlucci_domain_2019,
	title = {Domain {Generalization} by {Solving} {Jigsaw} {Puzzles}},
	url = {http://arxiv.org/abs/1903.06864},
	abstract = {Human adaptability relies crucially on the ability to learn and merge knowledge both from supervised and unsupervised learning: the parents point out few important concepts, but then the children fill in the gaps on their own. This is particularly effective, because supervised learning can never be exhaustive and thus learning autonomously allows to discover invariances and regularities that help to generalize. In this paper we propose to apply a similar approach to the task of object recognition across domains: our model learns the semantic labels in a supervised fashion, and broadens its understanding of the data by learning from self-supervised signals how to solve a jigsaw puzzle on the same images. This secondary task helps the network to learn the concepts of spatial correlation while acting as a regularizer for the classification task. Multiple experiments on the PACS, VLCS, Office-Home and digits datasets confirm our intuition and show that this simple method outperforms previous domain generalization and adaptation solutions. An ablation study further illustrates the inner workings of our approach.},
	urldate = {2022-02-08},
	journal = {arXiv:1903.06864 [cs]},
	author = {Carlucci, Fabio Maria and D'Innocente, Antonio and Bucci, Silvia and Caputo, Barbara and Tommasi, Tatiana},
	month = apr,
	year = {2019},
	file = {Carlucci et al_2019_Domain Generalization by Solving Jigsaw Puzzles.pdf:/Users/orsonxu/Zotero/storage/QTDSSAPM/Carlucci et al_2019_Domain Generalization by Solving Jigsaw Puzzles.pdf:application/pdf;Carlucci et al_2019_Domain Generalization by Solving Jigsaw Puzzles.pdf:/Users/orsonxu/Zotero/storage/8WN9K7S8/Carlucci et al_2019_Domain Generalization by Solving Jigsaw Puzzles.pdf:application/pdf},
}

@article{kim_selfreg_2021,
	title = {{SelfReg}: {Self}-{Supervised} {Contrastive} {Regularization} for {Domain} {Generalization}},
	abstract = {In general, an experimental environment for deep learning assumes that the training and the test dataset are sampled from the same distribution. However, in real-world situations, a difference in the distribution between two datasets, i.e. domain shift, may occur, which becomes a major factor impeding the generalization performance of the model. The research field to solve this problem is called domain generalization, and it alleviates the domain shift problem by extracting domain-invariant features explicitly or implicitly. In recent studies, contrastive learning-based domain generalization approaches have been proposed and achieved high performance. These approaches require sampling of the negative data pair. However, the performance of contrastive learning fundamentally depends on quality and quantity of negative data pairs. To address this issue, we propose a new regularization method for domain generalization based on contrastive learning, called selfsupervised contrastive regularization (SelfReg). The proposed approach use only positive data pairs, thus it resolves various problems caused by negative pair sampling. Moreover, we propose a class-specific domain perturbation layer (CDPL), which makes it possible to effectively apply mixup augmentation even when only positive data pairs are used. The experimental results show that the techniques incorporated by SelfReg contributed to the performance in a compatible manner. In the recent benchmark, DomainBed, the proposed method shows comparable performance to the conventional state-of-the-art alternatives.},
	language = {en},
	journal = {Proceedings of the IEEE/CVF International Conference on Computer Vision.},
	author = {Kim, Daehee and Yoo, Youngjun and Park, Seunghyun and Kim, Jinkyu and Lee, Jaekoo},
	year = {2021},
	pages = {10},
	file = {Kim et al. - SelfReg Self-Supervised Contrastive Regularizatio.pdf:/Users/orsonxu/Zotero/storage/L8B3LCML/Kim et al. - SelfReg Self-Supervised Contrastive Regularizatio.pdf:application/pdf},
}

@inproceedings{eldele_time-series_2021,
	address = {Montreal, Canada},
	title = {Time-{Series} {Representation} {Learning} via {Temporal} and {Contextual} {Contrasting}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/324},
	doi = {10.24963/ijcai.2021/324},
	abstract = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw timeseries data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classiﬁer on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efﬁciency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Eldele, Emadeldeen and Ragab, Mohamed and Chen, Zhenghua and Wu, Min and Kwoh, Chee Keong and Li, Xiaoli and Guan, Cuntai},
	month = aug,
	year = {2021},
	pages = {2352--2359},
	file = {Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:/Users/orsonxu/Zotero/storage/IBDJENHN/Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:application/pdf},
}

@incollection{ganin_domain-adversarial_2017,
	address = {Cham},
	title = {Domain-{Adversarial} {Training} of {Neural} {Networks}},
	isbn = {978-3-319-58346-4 978-3-319-58347-1},
	url = {http://link.springer.com/10.1007/978-3-319-58347-1_10},
	abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but diﬀerent distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for eﬀective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains.},
	language = {en},
	urldate = {2022-03-27},
	booktitle = {Domain {Adaptation} in {Computer} {Vision} {Applications}},
	publisher = {Springer International Publishing},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	year = {2017},
	pages = {189--209},
	file = {Ganin et al. - 2017 - Domain-Adversarial Training of Neural Networks.pdf:/Users/orsonxu/Zotero/storage/RNDG9IYJ/Ganin et al. - 2017 - Domain-Adversarial Training of Neural Networks.pdf:application/pdf},
}

@article{zhang_mixup_2018,
	title = {mixup: {Beyond} {Empirical} {Risk} {Minimization}},
	shorttitle = {mixup},
	url = {http://arxiv.org/abs/1710.09412},
	abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also ﬁnd that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
	language = {en},
	urldate = {2022-03-27},
	journal = {arXiv:1710.09412 [cs, stat]},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	month = apr,
	year = {2018},
	file = {Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf:/Users/orsonxu/Zotero/storage/SVVV6YNW/Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf:application/pdf},
}

@article{gulrajani_search_2021,
	title = {In {Search} of {Lost} {Domain} {Generalization}},
	abstract = {The goal of domain generalization algorithms is to predict well on distributions different from those seen during training. While a myriad of domain generalization algorithms exist, inconsistencies in experimental conditions—datasets, network architectures, and model selection criteria—render fair comparisons difﬁcult. The goal of this paper is to understand how useful domain generalization algorithms are in realistic settings. As a ﬁrst step, we realize that model selection is non-trivial for domain generalization tasks, and we argue that algorithms without a model selection criterion remain incomplete. Next we implement DOMAINBED, a testbed for domain generalization including seven benchmarks, fourteen algorithms, and three model selection criteria. When conducting extensive experiments using DOMAINBED we ﬁnd that when carefully implemented and tuned, ERM outperforms the state-of-the-art in terms of average performance. Furthermore, no algorithm included in DOMAINBED outperforms ERM by more than one point when evaluated under the same experimental conditions. We hope that the release of DOMAINBED, alongside contributions from fellow researchers, will streamline reproducible and rigorous advances in domain generalization.},
	language = {en},
	journal = {International Conference on Learning Representations 2021},
	author = {Gulrajani, Ishaan and Lopez-Paz, David},
	year = {2021},
	pages = {29},
	file = {Gulrajani and Lopez-Paz - 2021 - IN SEARCH OF LOST DOMAIN GENERALIZATION.pdf:/Users/orsonxu/Zotero/storage/CNB3K8U4/Gulrajani and Lopez-Paz - 2021 - IN SEARCH OF LOST DOMAIN GENERALIZATION.pdf:application/pdf},
}

@article{koch_siamese_2015,
	title = {Siamese {Neural} {Networks} for {One}-shot {Image} {Recognition}},
	abstract = {The process of learning good features for machine learning applications can be very computationally expensive and may prove difﬁcult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classiﬁcation tasks.},
	language = {en},
	journal = {Proceedings of the 32nd International Conference on Machine Learning},
	author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
	year = {2015},
	pages = {8},
	file = {Koch et al. - Siamese Neural Networks for One-shot Image Recogni.pdf:/Users/orsonxu/Zotero/storage/5DE8XGPU/Koch et al. - Siamese Neural Networks for One-shot Image Recogni.pdf:application/pdf},
}

@inproceedings{koh_wilds_2021,
	title = {{WILDS}: {A} {Benchmark} of in-the-{Wild} {Distribution} {Shifts}},
	shorttitle = {{WILDS}},
	url = {https://proceedings.mlr.press/v139/koh21a.html},
	abstract = {Distribution shifts—where the training distribution differs from the test distribution—can substantially degrade the accuracy of machine learning (ML) systems deployed in the wild. Despite their ubiquity in the real-world deployments, these distribution shifts are under-represented in the datasets widely used in the ML community today. To address this gap, we present WILDS, a curated benchmark of 10 datasets reflecting a diverse range of distribution shifts that naturally arise in real-world applications, such as shifts across hospitals for tumor identification; across camera traps for wildlife monitoring; and across time and location in satellite imaging and poverty mapping. On each dataset, we show that standard training yields substantially lower out-of-distribution than in-distribution performance. This gap remains even with models trained by existing methods for tackling distribution shifts, underscoring the need for new methods for training models that are more robust to the types of distribution shifts that arise in practice. To facilitate method development, we provide an open-source package that automates dataset loading, contains default model architectures and hyperparameters, and standardizes evaluations. The full paper, code, and leaderboards are available at https://wilds.stanford.edu.},
	language = {en},
	urldate = {2022-04-24},
	booktitle = {Proceedings of the 38th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and Lee, Tony and David, Etienne and Stavness, Ian and Guo, Wei and Earnshaw, Berton and Haque, Imran and Beery, Sara M. and Leskovec, Jure and Kundaje, Anshul and Pierson, Emma and Levine, Sergey and Finn, Chelsea and Liang, Percy},
	month = jul,
	year = {2021},
	pages = {5637--5664},
	file = {Koh et al_2021_WILDS.pdf:/Users/orsonxu/Zotero/storage/CIQF64CQ/Koh et al_2021_WILDS.pdf:application/pdf;Koh et al_2021_WILDS.pdf:/Users/orsonxu/Zotero/storage/EJ7MQ9DB/Koh et al_2021_WILDS.pdf:application/pdf;Supplementary PDF:/Users/orsonxu/Zotero/storage/AS8T8T4H/Koh et al. - 2021 - WILDS A Benchmark of in-the-Wild Distribution Shi.pdf:application/pdf},
}

@article{adadi_peeking_2018,
	title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Peeking {Inside} the {Black}-{Box}},
	doi = {10.1109/ACCESS.2018.2870052},
	abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
	journal = {IEEE Access},
	author = {Adadi, Amina and Berrada, Mohammed},
	year = {2018},
	pages = {52138--52160},
	file = {Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:/Users/orsonxu/Zotero/storage/K44JIPFC/Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:application/pdf;Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:/Users/orsonxu/Zotero/storage/MCSS2YU6/Adadi_Berrada_2018_Peeking Inside the Black-Box.pdf:application/pdf},
}

@inproceedings{bansal_does_2021,
	address = {Yokohama Japan},
	title = {Does the {Whole} {Exceed} its {Parts}? {The} {Effect} of {AI} {Explanations} on {Complementary} {Team} {Performance}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Does the {Whole} {Exceed} its {Parts}?},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445717},
	doi = {10.1145/3411764.3445717},
	language = {en},
	urldate = {2022-06-21},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
	month = may,
	year = {2021},
	pages = {1--16},
	file = {Bansal et al. - 2021 - Does the Whole Exceed its Parts The Effect of AI .pdf:/Users/orsonxu/Zotero/storage/2KSFDWD3/Bansal et al. - 2021 - Does the Whole Exceed its Parts The Effect of AI .pdf:application/pdf},
}

@misc{urbansky_comparison_2020,
	title = {Comparison of 7 image classification {APIs} for food pictures},
	url = {https://ddsky.medium.com/comparison-of-7-image-classification-apis-for-food-pictures-1d61b7293285},
	abstract = {This article compares 7 online image recognition services in the context of food recognition. In particular, my goal was to find out which…},
	language = {en},
	urldate = {2022-06-27},
	journal = {Medium},
	author = {Urbansky, David},
	month = apr,
	year = {2020},
	file = {Snapshot:/Users/orsonxu/Zotero/storage/WRJYZ5PX/comparison-of-7-image-classification-apis-for-food-pictures-1d61b7293285.html:text/html},
}

@inproceedings{lim_why_2009,
	address = {Boston MA USA},
	title = {Why and why not explanations improve the intelligibility of context-aware intelligent systems},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1519023},
	doi = {10.1145/1518701.1519023},
	abstract = {Context-aware intelligent systems employ implicit inputs, and make decisions based on complex rules and machine learning models that are rarely clear to users. Such lack of system intelligibility can lead to loss of user trust, satisfaction and acceptance of these systems. However, automatically providing explanations about a system‟s decision process can help mitigate this problem. In this paper we present results from a controlled study with over 200 participants in which the effectiveness of different types of explanations was examined. Participants were shown examples of a system‟s operation along with various automatically generated explanations, and then tested on their understanding of the system. We show, for example, that explanations describing why the system behaved a certain way resulted in better understanding and stronger feelings of trust. Explanations describing why the system did not behave a certain way, resulted in lower understanding yet adequate performance. We discuss implications for the use of our findings in real-world context-aware applications.},
	language = {en},
	urldate = {2022-07-11},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K. and Avrahami, Daniel},
	month = apr,
	year = {2009},
	pages = {2119--2128},
	file = {Lim et al. - 2009 - Why and why not explanations improve the in.pdf:/Users/orsonxu/Zotero/storage/HAWPC6QA/Lim et al. - 2009 - Why and why not explanations improve the in.pdf:application/pdf},
}

@article{bunt_are_2012,
	title = {Are explanations always important?: a study of deployed, low-cost intelligent interactive systems},
	abstract = {Intelligent interactive systems (IIS) have great potential to improve users' experience with technology by tailoring their behaviour and appearance to users’ individual needs; however, these systems, with their complex algorithms and dynamic behaviour, can also suffer from a lack of comprehensibility and transparency. We present the results of two studies examining the comprehensibility of, and desire for explanations with deployed, low-cost IIS. The first study, a set of interviews with 21 participants, reveals that i) comprehensibility is not always dependent on explanations, and ii) the perceived cost of viewing explanations tends to outweigh the anticipated benefits. Our second study, a two-week diary study with 14 participants, confirms these findings in the context of daily use, with participants indicating a desire for an explanation in only 7\% of diary entries. We discuss the implications of our findings for the design of explanation facilities.},
	language = {en},
	author = {Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
	year = {2012},
	pages = {10},
	file = {Bunt et al. - 2012 - Are explanations always important a study of dep.pdf:/Users/orsonxu/Zotero/storage/SUEFGDDA/Bunt et al. - 2012 - Are explanations always important a study of dep.pdf:application/pdf},
}

@article{langer_what_2021,
	title = {What do we want from {Explainable} {Artificial} {Intelligence} ({XAI})? – {A} stakeholder perspective on {XAI} and a conceptual model guiding interdisciplinary {XAI} research},
	volume = {296},
	issn = {00043702},
	shorttitle = {What do we want from {Explainable} {Artificial} {Intelligence} ({XAI})?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370221000242},
	doi = {10.1016/j.artint.2021.103473},
	language = {en},
	urldate = {2022-07-15},
	journal = {Artificial Intelligence},
	author = {Langer, Markus and Oster, Daniel and Speith, Timo and Hermanns, Holger and Kästner, Lena and Schmidt, Eva and Sesing, Andreas and Baum, Kevin},
	month = jul,
	year = {2021},
	pages = {103473},
	file = {Langer et al. - 2021 - What do we want from Explainable Artificial Intell.pdf:/Users/orsonxu/Zotero/storage/8JNPLSLM/Langer et al. - 2021 - What do we want from Explainable Artificial Intell.pdf:application/pdf},
}

@inproceedings{lim_toolkit_2010,
	address = {Copenhagen Denmark},
	title = {Toolkit to support intelligibility in context-aware applications},
	isbn = {978-1-60558-843-8},
	url = {https://dl.acm.org/doi/10.1145/1864349.1864353},
	doi = {10.1145/1864349.1864353},
	abstract = {Context-aware applications should be intelligible so users can better understand how they work and improve their trust in them. However, providing intelligibility is nontrivial and requires the developer to understand how to generate explanations from application decision models. Furthermore, users need different types of explanations and this complicates the implementation of intelligibility. We have developed the Intelligibility Toolkit that makes it easy for application developers to obtain eight types of explanations from the most popular decision models of context-aware applications. We describe its extensible architecture, and the explanation generation algorithms we developed. We validate the usefulness of the toolkit with three canonical applications that use the toolkit to generate explanations for end-users.},
	language = {en},
	urldate = {2022-08-28},
	booktitle = {Proceedings of the 12th {ACM} international conference on {Ubiquitous} computing},
	publisher = {ACM},
	author = {Lim, Brian Y. and Dey, Anind K.},
	month = sep,
	year = {2010},
	pages = {13--22},
	file = {Lim and Dey - 2010 - Toolkit to support intelligibility in context-awar.pdf:/Users/orsonxu/Zotero/storage/CY8QQ6C8/Lim and Dey - 2010 - Toolkit to support intelligibility in context-awar.pdf:application/pdf},
}

@inproceedings{sagawa_extending_2022,
	title = {Extending the {WILDS} {Benchmark} for {Unsupervised} {Adaptation}},
	url = {http://arxiv.org/abs/2112.05090},
	abstract = {Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as the evaluation metrics. On these datasets, we systematically benchmark state-of-the-art methods that leverage unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development and evaluation, we provide an open-source package that automates data loading and contains all of the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.},
	urldate = {2022-10-01},
	booktitle = {{ICLR}},
	publisher = {arXiv},
	author = {Sagawa, Shiori and Koh, Pang Wei and Lee, Tony and Gao, Irena and Xie, Sang Michael and Shen, Kendrick and Kumar, Ananya and Hu, Weihua and Yasunaga, Michihiro and Marklund, Henrik and Beery, Sara and David, Etienne and Stavness, Ian and Guo, Wei and Leskovec, Jure and Saenko, Kate and Hashimoto, Tatsunori and Levine, Sergey and Finn, Chelsea and Liang, Percy},
	month = apr,
	year = {2022},
	file = {Sagawa et al_2022_Extending the WILDS Benchmark for Unsupervised Adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sagawa et al_2022_Extending the WILDS Benchmark for Unsupervised Adaptation.pdf:application/pdf},
}

@inproceedings{sagawa_distributionally_2020,
	title = {Distributionally {Robust} {Neural} {Networks} for {Group} {Shifts}: {On} the {Importance} of {Regularization} for {Worst}-{Case} {Generalization}},
	shorttitle = {Distributionally {Robust} {Neural} {Networks} for {Group} {Shifts}},
	url = {http://arxiv.org/abs/1911.08731},
	abstract = {Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---a stronger-than-typical L2 penalty or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models.},
	urldate = {2022-10-01},
	booktitle = {{ICLR}},
	publisher = {arXiv},
	author = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B. and Liang, Percy},
	month = apr,
	year = {2020},
	file = {Sagawa et al_2020_Distributionally Robust Neural Networks for Group Shifts.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sagawa et al_2020_Distributionally Robust Neural Networks for Group Shifts.pdf:application/pdf},
}

@article{ribeiro_anchors_2018,
	title = {Anchors: {High}-{Precision} {Model}-{Agnostic} {Explanations}},
	volume = {32},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Anchors},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11491},
	doi = {10.1609/aaai.v32i1.11491},
	abstract = {We introduce a novel model-agnostic system that explains the behavior of complex models with high-precision rules called anchors, representing local, “sufﬁcient” conditions for predictions. We propose an algorithm to efﬁciently compute these explanations for any black-box model with high-probability guarantees. We demonstrate the ﬂexibility of anchors by explaining a myriad of different models for different domains and tasks. In a user study, we show that anchors enable users to predict how a model would behave on unseen instances with less effort and higher precision, as compared to existing linear explanations or no explanations.},
	language = {en},
	number = {1},
	urldate = {2022-11-22},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = apr,
	year = {2018},
	file = {Ribeiro et al. - 2018 - Anchors High-Precision Model-Agnostic Explanation.pdf:/Users/orsonxu/Zotero/storage/IUCP5G67/Ribeiro et al. - 2018 - Anchors High-Precision Model-Agnostic Explanation.pdf:application/pdf},
}

@inproceedings{mittelstadt_explaining_2019,
	address = {Atlanta GA USA},
	title = {Explaining {Explanations} in {AI}},
	isbn = {978-1-4503-6125-5},
	url = {https://dl.acm.org/doi/10.1145/3287560.3287574},
	doi = {10.1145/3287560.3287574},
	abstract = {Recent work on interpretability in machine learning and AI has focused on the building of simplified models that approximate the true criteria used to make decisions. These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break. However, when considering any such model it’s important to remember Box’s maxim that "All models are wrong but some are useful." We focus on the distinction between these models and explanations in philosophy and sociology. These models can be understood as a "do it yourself kit" for explanations, allowing a practitioner to directly answer "what if questions" or generate contrastive explanations without external assistance. Although a valuable ability, giving these models as explanations appears more difficult than necessary, and other forms of explanation may not have the same trade-offs. We contrast the different schools of thought on what makes an explanation, and suggest that machine learning might benefit from viewing the problem more broadly.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
	month = jan,
	year = {2019},
	pages = {279--288},
	file = {Mittelstadt et al. - 2019 - Explaining Explanations in AI.pdf:/Users/orsonxu/Zotero/storage/N4PVKJFM/Mittelstadt et al. - 2019 - Explaining Explanations in AI.pdf:application/pdf},
}

@inproceedings{koh_understanding_2017,
	title = {Understanding {Black}-box {Predictions} via {Influence} {Functions}},
	url = {https://proceedings.mlr.press/v70/koh17a.html},
	abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
	language = {en},
	urldate = {2022-11-22},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Koh, Pang Wei and Liang, Percy},
	month = jul,
	year = {2017},
	pages = {1885--1894},
	file = {Koh_Liang_2017_Understanding Black-box Predictions via Influence Functions.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Koh_Liang_2017_Understanding Black-box Predictions via Influence Functions.pdf:application/pdf;Supplementary PDF:/Users/orsonxu/Zotero/storage/CAZWQSVG/Koh and Liang - 2017 - Understanding Black-box Predictions via Influence .pdf:application/pdf},
}

@article{zhuang_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Transfer} {Learning}},
	volume = {109},
	issn = {1558-2256},
	doi = {10.1109/JPROC.2020.3004555},
	abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target-domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning research studies, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey article reviews more than 40 representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over 20 representative transfer learning models are used for experiments. The models are performed on three different data sets, that is, Amazon Reviews, Reuters-21578, and Office-31, and the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
	month = jan,
	year = {2021},
	pages = {43--76},
	file = {Zhuang et al_2021_A Comprehensive Survey on Transfer Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhuang et al_2021_A Comprehensive Survey on Transfer Learning.pdf:application/pdf},
}

@inproceedings{ganin_unsupervised_2015,
	title = {Unsupervised {Domain} {Adaptation} by {Backpropagation}},
	abstract = {Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled targetdomain data is necessary).},
	language = {en},
	booktitle = {Proceedings of the 32 nd {International} {Conference} on {Machine} {Learning}},
	author = {Ganin, Yaroslav and Lempitsky, Victor},
	year = {2015},
	pages = {10},
	file = {Ganin and Lempitsky - Unsupervised Domain Adaptation by Backpropagation.pdf:/Users/orsonxu/Zotero/storage/4RJW27C5/Ganin and Lempitsky - Unsupervised Domain Adaptation by Backpropagation.pdf:application/pdf},
}

@inproceedings{vinyals_matching_2016,
	title = {Matching {Networks} for {One} {Shot} {Learning}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/90e1357833654983612fb05e3ec9148c-Abstract.html},
	abstract = {Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 82.2\% to 87.8\% and from 88\% accuracy to 95\% accuracy on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.},
	urldate = {2022-12-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and kavukcuoglu, koray and Wierstra, Daan},
	year = {2016},
	file = {Vinyals et al_2016_Matching Networks for One Shot Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Vinyals et al_2016_Matching Networks for One Shot Learning.pdf:application/pdf},
}

@inproceedings{snell_prototypical_2017,
	title = {Prototypical {Networks} for {Few}-shot {Learning}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/cb8da6767461f2812ae4290eac7cbc42-Abstract.html},
	abstract = {We propose Prototypical Networks for the problem of few-shot classification, where a classifier must generalize to new classes not seen in the training set, given only a small number of examples of each new class. Prototypical Networks learn a metric space in which classification can be performed by computing distances to prototype representations of each class. Compared to recent approaches for few-shot learning, they reflect a simpler inductive bias that is beneficial in this limited-data regime, and achieve excellent results. We provide an analysis showing that some simple design decisions can yield substantial improvements over recent approaches involving complicated architectural choices and meta-learning. We further extend Prototypical Networks to zero-shot learning and achieve state-of-the-art results on the CU-Birds dataset.},
	urldate = {2022-12-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
	year = {2017},
	file = {Snell et al_2017_Prototypical Networks for Few-shot Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Snell et al_2017_Prototypical Networks for Few-shot Learning.pdf:application/pdf},
}

@misc{long_learning_2015,
	title = {Learning {Transferable} {Features} with {Deep} {Adaptation} {Networks}},
	url = {http://arxiv.org/abs/1502.02791},
	abstract = {Recent studies reveal that a deep neural network can learn transferable features which generalize well to novel tasks for domain adaptation. However, as deep features eventually transition from general to specific along the network, the feature transferability drops significantly in higher layers with increasing domain discrepancy. Hence, it is important to formally reduce the dataset bias and enhance the transferability in task-specific layers. In this paper, we propose a new Deep Adaptation Network (DAN) architecture, which generalizes deep convolutional neural network to the domain adaptation scenario. In DAN, hidden representations of all task-specific layers are embedded in a reproducing kernel Hilbert space where the mean embeddings of different domain distributions can be explicitly matched. The domain discrepancy is further reduced using an optimal multi-kernel selection method for mean embedding matching. DAN can learn transferable features with statistical guarantees, and can scale linearly by unbiased estimate of kernel embedding. Extensive empirical evidence shows that the proposed architecture yields state-of-the-art image classification error rates on standard domain adaptation benchmarks.},
	urldate = {2022-12-03},
	publisher = {arXiv},
	author = {Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I.},
	month = may,
	year = {2015},
	file = {Long et al_2015_Learning Transferable Features with Deep Adaptation Networks.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Long et al_2015_Learning Transferable Features with Deep Adaptation Networks.pdf:application/pdf},
}

@article{ravi_optimization_2017,
	title = {Optimization as {A} {Model} {For} {Few}-shot {Learning}},
	abstract = {Though deep neural networks have shown great success in the large data domain, they generally perform poorly on few-shot learning tasks, where a classiﬁer has to quickly generalize after seeing very few examples from each class. The general belief is that gradient-based optimization in high capacity classiﬁers requires many iterative steps over many examples to perform well. Here, we propose an LSTMbased meta-learner model to learn the exact optimization algorithm used to train another learner neural network classiﬁer in the few-shot regime. The parametrization of our model allows it to learn appropriate parameter updates speciﬁcally for the scenario where a set amount of updates will be made, while also learning a general initialization of the learner (classiﬁer) network that allows for quick convergence of training. We demonstrate that this meta-learning model is competitive with deep metric-learning techniques for few-shot learning.},
	language = {en},
	author = {Ravi, Sachin and Larochelle, Hugo},
	year = {2017},
	pages = {11},
	file = {Ravi and Larochelle - 2017 - OPTIMIZATION AS A MODEL FOR FEW-SHOT LEARNING.pdf:/Users/orsonxu/Zotero/storage/FXCZXS5J/Ravi and Larochelle - 2017 - OPTIMIZATION AS A MODEL FOR FEW-SHOT LEARNING.pdf:application/pdf},
}

@article{mehrabi_survey_2021,
	title = {A {Survey} on {Bias} and {Fairness} in {Machine} {Learning}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3457607},
	doi = {10.1145/3457607},
	abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	language = {en},
	number = {6},
	urldate = {2022-12-16},
	journal = {ACM Computing Surveys},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	month = jul,
	year = {2021},
	pages = {1--35},
	file = {Mehrabi et al. - 2021 - A Survey on Bias and Fairness in Machine Learning.pdf:/Users/orsonxu/Zotero/storage/5IGQBZST/Mehrabi et al. - 2021 - A Survey on Bias and Fairness in Machine Learning.pdf:application/pdf},
}

@inproceedings{dwork_fairness_2012,
	address = {Cambridge Massachusetts},
	title = {Fairness through awareness},
	isbn = {978-1-4503-1115-1},
	url = {https://dl.acm.org/doi/10.1145/2090236.2090255},
	doi = {10.1145/2090236.2090255},
	abstract = {We study fairness in classiﬁcation, where individuals are classiﬁed, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classiﬁer (the university). The main conceptual contribution of this paper is a framework for fair classiﬁcation comprising (1) a (hypothetical) task-speciﬁc metric for determining the degree to which individuals are similar with respect to the classiﬁcation task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of “fair aﬃrmative action,” which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classiﬁcation are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of diﬀerential privacy may be applied to fairness.},
	language = {en},
	urldate = {2023-01-24},
	booktitle = {Proceedings of the 3rd {Innovations} in {Theoretical} {Computer} {Science} {Conference}},
	publisher = {ACM},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
	month = jan,
	year = {2012},
	pages = {214--226},
	file = {Dwork et al. - 2012 - Fairness through awareness.pdf:/Users/orsonxu/Zotero/storage/7U76GATK/Dwork et al. - 2012 - Fairness through awareness.pdf:application/pdf},
}

@misc{pessach_algorithmic_2020,
	title = {Algorithmic {Fairness}},
	url = {http://arxiv.org/abs/2001.09784},
	abstract = {An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence (AI) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop AI algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision-making may be inherently prone to unfairness, even when there is no intention for it. This paper presents an overview of the main concepts of identifying, measuring and improving algorithmic fairness when using AI algorithms. The paper begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, towards a better understanding of which mechanisms should be used in different scenarios. The paper then describes the most commonly used fairness-related datasets in this field. Finally, the paper ends by reviewing several emerging research sub-fields of algorithmic fairness.},
	urldate = {2023-01-27},
	publisher = {arXiv},
	author = {Pessach, Dana and Shmueli, Erez},
	month = jan,
	year = {2020},
	file = {Pessach_Shmueli_2020_Algorithmic Fairness.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Pessach_Shmueli_2020_Algorithmic Fairness.pdf:application/pdf},
}

@article{kairouz_advances_2021,
	title = {Advances and {Open} {Problems} in {Federated} {Learning}},
	volume = {14},
	issn = {1935-8237, 1935-8245},
	url = {http://www.nowpublishers.com/article/Details/MAL-083},
	doi = {10.1561/2200000083},
	language = {en},
	number = {1–2},
	urldate = {2023-02-01},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Kairouz, Peter and McMahan, H. Brendan and Avent, Brendan and Bellet, Aurélien and Bennis, Mehdi and Nitin Bhagoji, Arjun and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and D’Oliveira, Rafael G. L. and Eichner, Hubert and El Rouayheb, Salim and Evans, David and Gardner, Josh and Garrett, Zachary and Gascón, Adrià and Ghazi, Badih and Gibbons, Phillip B. and Gruteser, Marco and Harchaoui, Zaid and He, Chaoyang and He, Lie and Huo, Zhouyuan and Hutchinson, Ben and Hsu, Justin and Jaggi, Martin and Javidi, Tara and Joshi, Gauri and Khodak, Mikhail and Konecný, Jakub and Korolova, Aleksandra and Koushanfar, Farinaz and Koyejo, Sanmi and Lepoint, Tancrède and Liu, Yang and Mittal, Prateek and Mohri, Mehryar and Nock, Richard and Özgür, Ayfer and Pagh, Rasmus and Qi, Hang and Ramage, Daniel and Raskar, Ramesh and Raykova, Mariana and Song, Dawn and Song, Weikang and Stich, Sebastian U. and Sun, Ziteng and Suresh, Ananda Theertha and Tramèr, Florian and Vepakomma, Praneeth and Wang, Jianyu and Xiong, Li and Xu, Zheng and Yang, Qiang and Yu, Felix X. and Yu, Han and Zhao, Sen},
	year = {2021},
	pages = {1--210},
	file = {Kairouz et al. - 2021 - Advances and Open Problems in Federated Learning.pdf:/Users/orsonxu/Zotero/storage/MP9YJIHY/Kairouz et al. - 2021 - Advances and Open Problems in Federated Learning.pdf:application/pdf},
}

@misc{caldas_leaf_2019,
	title = {{LEAF}: {A} {Benchmark} for {Federated} {Settings}},
	shorttitle = {{LEAF}},
	url = {http://arxiv.org/abs/1812.01097},
	abstract = {Modern federated networks, such as those comprised of wearable devices, mobile phones, or autonomous vehicles, generate massive amounts of data each day. This wealth of data can help to learn models that can improve the user experience on each device. However, the scale and heterogeneity of federated data presents new challenges in research areas such as federated learning, meta-learning, and multi-task learning. As the machine learning community begins to tackle these challenges, we are at a critical time to ensure that developments made in these areas are grounded with realistic benchmarks. To this end, we propose LEAF, a modular benchmarking framework for learning in federated settings. LEAF includes a suite of open-source federated datasets, a rigorous evaluation framework, and a set of reference implementations, all geared towards capturing the obstacles and intricacies of practical federated environments.},
	urldate = {2023-02-01},
	publisher = {arXiv},
	author = {Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Konečný, Jakub and McMahan, H. Brendan and Smith, Virginia and Talwalkar, Ameet},
	month = dec,
	year = {2019},
	file = {Caldas et al_2019_LEAF.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Caldas et al_2019_LEAF.pdf:application/pdf},
}

@inproceedings{smith_federated_2017,
	title = {Federated {Multi}-{Task} {Learning}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/6211080fa89981f66b1a0c9d55c61d0f-Abstract.html},
	abstract = {Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets.},
	urldate = {2023-02-12},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Smith, Virginia and Chiang, Chao-Kai and Sanjabi, Maziar and Talwalkar, Ameet S},
	year = {2017},
	file = {Smith et al_2017_Federated Multi-Task Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Smith et al_2017_Federated Multi-Task Learning.pdf:application/pdf},
}

@inproceedings{li_fair_2020,
	title = {Fair {Resource} {Allocation} in {Federated} {Learning}},
	url = {http://arxiv.org/abs/1905.10497},
	abstract = {Federated learning involves training statistical models in massive, heterogeneous networks. Naively minimizing an aggregate loss function in such a network may disproportionately advantage or disadvantage some of the devices. In this work, we propose q-Fair Federated Learning (q-FFL), a novel optimization objective inspired by fair resource allocation in wireless networks that encourages a more fair (specifically, a more uniform) accuracy distribution across devices in federated networks. To solve q-FFL, we devise a communication-efficient method, q-FedAvg, that is suited to federated networks. We validate both the effectiveness of q-FFL and the efficiency of q-FedAvg on a suite of federated datasets with both convex and non-convex models, and show that q-FFL (along with q-FedAvg) outperforms existing baselines in terms of the resulting fairness, flexibility, and efficiency.},
	urldate = {2023-02-12},
	booktitle = {The {International} {Conference} on {Learning} {Representations}},
	publisher = {arXiv},
	author = {Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
	month = feb,
	year = {2020},
	file = {Li et al_2020_Fair Resource Allocation in Federated Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Li et al_2020_Fair Resource Allocation in Federated Learning.pdf:application/pdf},
}

@article{yang_federated_2019,
	title = {Federated {Machine} {Learning}: {Concept} and {Applications}},
	volume = {10},
	issn = {2157-6904, 2157-6912},
	shorttitle = {Federated {Machine} {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3298981},
	doi = {10.1145/3298981},
	abstract = {Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.},
	language = {en},
	number = {2},
	urldate = {2023-02-12},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	author = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
	month = mar,
	year = {2019},
	pages = {1--19},
	file = {Yang et al. - 2019 - Federated Machine Learning Concept and Applicatio.pdf:/Users/orsonxu/Zotero/storage/ZTRPIT44/Yang et al. - 2019 - Federated Machine Learning Concept and Applicatio.pdf:application/pdf},
}

@article{kim_blockchained_2020,
	title = {Blockchained {On}-{Device} {Federated} {Learning}},
	volume = {24},
	issn = {1558-2558},
	doi = {10.1109/LCOMM.2019.2921755},
	abstract = {By leveraging blockchain, this letter proposes a blockchained federated learning (BlockFL) architecture where local learning model updates are exchanged and verified. This enables on-device machine learning without any centralized training data or coordination by utilizing a consensus mechanism in blockchain. Moreover, we analyze an end-to-end latency model of BlockFL and characterize the optimal block generation rate by considering communication, computation, and consensus delays.},
	number = {6},
	journal = {IEEE Communications Letters},
	author = {Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
	month = jun,
	year = {2020},
	pages = {1279--1283},
	file = {Kim et al_2020_Blockchained On-Device Federated Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Kim et al_2020_Blockchained On-Device Federated Learning.pdf:application/pdf},
}

@misc{bommasani_opportunities_2022,
	title = {On the {Opportunities} and {Risks} of {Foundation} {Models}},
	url = {http://arxiv.org/abs/2108.07258},
	abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
	urldate = {2023-02-12},
	publisher = {arXiv},
	author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
	month = jul,
	year = {2022},
	file = {Bommasani et al_2022_On the Opportunities and Risks of Foundation Models.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Bommasani et al_2022_On the Opportunities and Risks of Foundation Models.pdf:application/pdf},
}

@misc{ji_differential_2014,
	title = {Differential {Privacy} and {Machine} {Learning}: a {Survey} and {Review}},
	shorttitle = {Differential {Privacy} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/1412.7584},
	abstract = {The objective of machine learning is to extract useful information from data, while privacy is preserved by concealing information. Thus it seems hard to reconcile these competing interests. However, they frequently must be balanced when mining sensitive data. For example, medical research represents an important application where it is necessary both to extract useful information and protect patient privacy. One way to resolve the conﬂict is to extract general characteristics of whole populations without disclosing the private information of individuals.},
	language = {en},
	urldate = {2023-02-13},
	publisher = {arXiv},
	author = {Ji, Zhanglong and Lipton, Zachary C. and Elkan, Charles},
	month = dec,
	year = {2014},
	file = {Ji et al. - 2014 - Differential Privacy and Machine Learning a Surve.pdf:/Users/orsonxu/Zotero/storage/IBXNBIYE/Ji et al. - 2014 - Differential Privacy and Machine Learning a Surve.pdf:application/pdf},
}

@article{desfontaines_sok_2020,
	title = {{SoK}: {Differential} privacies},
	volume = {2020},
	issn = {2299-0984},
	shorttitle = {{SoK}},
	url = {https://petsymposium.org/popets/2020/popets-2020-0028.php},
	doi = {10.2478/popets-2020-0028},
	abstract = {Shortly after it was ﬁrst introduced in 2006, diﬀerential privacy became the ﬂagship data privacy deﬁnition. Since then, numerous variants and extensions were proposed to adapt it to diﬀerent scenarios and attacker models. In this work, we propose a systematic taxonomy of these variants and extensions. We list all data privacy deﬁnitions based on diﬀerential privacy, and partition them into seven categories, depending on which aspect of the original deﬁnition is modiﬁed.},
	language = {en},
	number = {2},
	urldate = {2023-02-13},
	journal = {Proceedings on Privacy Enhancing Technologies},
	author = {Desfontaines, Damien and Pejó, Balázs},
	month = apr,
	year = {2020},
	pages = {288--313},
	file = {Desfontaines and Pejó - 2020 - SoK Differential privacies.pdf:/Users/orsonxu/Zotero/storage/PRWWG6P4/Desfontaines and Pejó - 2020 - SoK Differential privacies.pdf:application/pdf},
}

@article{zhao_survey_2022,
	title = {A {Survey} on {Differential} {Privacy} for {Unstructured} {Data} {Content}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3490237},
	doi = {10.1145/3490237},
	abstract = {Huge amounts of unstructured data including image, video, audio, and text are ubiquitously generated and shared, and it is a challenge to protect sensitive personal information in them, such as human faces, voiceprints, and authorships. Differential privacy is the standard privacy protection technology that provides rigorous privacy guarantees for various data. This survey summarizes and analyzes differential privacy solutions to protect unstructured data content before it is shared with untrusted parties. These differential privacy methods obfuscate unstructured data after they are represented with vectors and then reconstruct them with obfuscated vectors. We summarize specific privacy models and mechanisms together with possible challenges in them. We also discuss their privacy guarantees against AI attacks and utility losses. Finally, we discuss several possible directions for future research.},
	language = {en},
	number = {10s},
	urldate = {2023-02-13},
	journal = {ACM Computing Surveys},
	author = {Zhao, Ying and Chen, Jinjun},
	month = jan,
	year = {2022},
	pages = {1--28},
	file = {Zhao and Chen - 2022 - A Survey on Differential Privacy for Unstructured .pdf:/Users/orsonxu/Zotero/storage/8IQZ2VYL/Zhao and Chen - 2022 - A Survey on Differential Privacy for Unstructured .pdf:application/pdf},
}

@article{meegahapola_generalization_2022,
	title = {Generalization and {Personalization} of {Mobile} {Sensing}-{Based} {Mood} {Inference} {Models}: {An} {Analysis} of {College} {Students} in {Eight} {Countries}},
	volume = {6},
	issn = {2474-9567},
	shorttitle = {Generalization and {Personalization} of {Mobile} {Sensing}-{Based} {Mood} {Inference} {Models}},
	url = {https://dl.acm.org/doi/10.1145/3569483},
	doi = {10.1145/3569483},
	abstract = {Mood inference with mobile sensing data has been studied in ubicomp literature over the last decade. This inference enables context-aware and personalized user experiences in general mobile apps and valuable feedback and interventions in mobile health apps. However, even though model generalization issues have been highlighted in many studies, the focus has always been on improving the accuracies of models using different sensing modalities and machine learning techniques, with datasets collected in homogeneous populations. In contrast, less attention has been given to studying the performance of mood inference models to assess whether models generalize to new countries. In this study, we collected a mobile sensing dataset with 329K self-reports from 678 participants in eight countries (China, Denmark, India, Italy, Mexico, Mongolia, Paraguay, UK) to assess the effect of geographical diversity on mood inference models. We define and evaluate country-specific (trained and tested within a country), continent-specific (trained and tested within a continent), country-agnostic (tested on a country not seen on training data), and multi-country (trained and tested with multiple countries) approaches trained on sensor data for two mood inference tasks with population-level (non-personalized) and hybrid (partially personalized) models. We show that partially personalized country-specific models perform the best yielding area under the receiver operating characteristic curve (AUROC) scores of the range 0.78--0.98 for two-class (negative vs. positive valence) and 0.76--0.94 for three-class (negative vs. neutral vs. positive valence) inference. Further, with the country-agnostic approach, we show that models do not perform well compared to country-specific settings, even when models are partially personalized. We also show that continent-specific models outperform multi-country models in the case of Europe. Overall, we uncover generalization issues of mood inference models to new countries and how the geographical similarity of countries might impact mood inference.},
	language = {en},
	number = {4},
	urldate = {2023-03-03},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Meegahapola, Lakmal and Droz, William and Kun, Peter and de Götzen, Amalia and Nutakki, Chaitanya and Diwakar, Shyam and Correa, Salvador Ruiz and Song, Donglei and Xu, Hao and Bidoglia, Miriam and Gaskell, George and Chagnaa, Altangerel and Ganbold, Amarsanaa and Zundui, Tsolmon and Caprini, Carlo and Miorandi, Daniele and Hume, Alethia and Zarza, Jose Luis and Cernuzzi, Luca and Bison, Ivano and Britez, Marcelo Rodas and Busso, Matteo and Chenu-Abente, Ronald and Günel, Can and Giunchiglia, Fausto and Schelenz, Laura and Gatica-Perez, Daniel},
	month = dec,
	year = {2022},
	pages = {1--32},
	file = {Meegahapola et al. - 2022 - Generalization and Personalization of Mobile Sensi.pdf:/Users/orsonxu/Zotero/storage/JFN5GMHT/Meegahapola et al. - 2022 - Generalization and Personalization of Mobile Sensi.pdf:application/pdf},
}

@article{zhang_quantifying_2021,
	title = {Quantifying the {Causal} {Effect} of {Individual} {Mobility} on {Health} {Status} in {Urban} {Space}},
	volume = {5},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3494990},
	doi = {10.1145/3494990},
	abstract = {How does individual mobility in the urban environment impact their health status? Previous works have explored the correlation between human mobility behaviour and individual health, yet the study on the underlying causal effect is woefully inadequate. However, the correlation analysis can sometimes be bewildering because of the confounding effects. For example, older people visit park more often but have worse health status than younger people. The common associations with age will lead to a counter-intuitive negative correlation between park visits and health status. Obtaining causal effects from confounded observations remains a challenge. In this paper, we construct a causal framework based on propensity score matching on multi-level treatment to eliminate the bias brought by confounding effects and estimate the total treatment effects of mobility behaviours on health status. We demonstrate that the matching procedure approximates a de-confounded randomized experiment where confounding variables are balanced substantially. The analysis on the directions of estimated causal effects reveals that fewer neighbouring tobacco shops and frequent visits to sports facilities are related with higher risk in health status, which differs from their correlation directions. Physical mobility behaviours and environment features have more significant estimated effects on health status than contextual mobility behaviours. Moreover, we embed our causal analysis framework in health prediction models to filter out features with superficial correlation but insignificant effects that might lead to over-fitting. This strategy achieves better model robustness with more features filtered out than L1-regularization. Our findings shed light on individual healthy lifestyle and mobility-related health policymaking.},
	language = {en},
	number = {4},
	urldate = {2023-03-13},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Zhang, Yunke and Xu, Fengli and Xia, Tong and Li, Yong},
	month = dec,
	year = {2021},
	pages = {1--30},
}

@article{liu_introduction_2013,
	title = {An {Introduction} to {Sensitivity} {Analysis} for {Unobserved} {Confounding} in {Nonexperimental} {Prevention} {Research}},
	volume = {14},
	issn = {1389-4986, 1573-6695},
	url = {http://link.springer.com/10.1007/s11121-012-0339-5},
	doi = {10.1007/s11121-012-0339-5},
	abstract = {Despite that randomization is the gold standard for estimating causal relationships, many questions in prevention science are left to be answered through non-experimental studies often because randomization is either infeasible or unethical. While methods such as propensity score matching can adjust for observed confounding, unobserved confounding is the Achilles heel of most nonexperimental studies. This paper describes and illustrates seven sensitivity analysis techniques that assess the sensitivity of study results to an unobserved confounder. These methods were categorized into two groups to reflect differences in their conceptualization of sensitivity analysis, as well as their targets of interest. As a motivating example we examine the sensitivity of the association between maternal suicide and offspring’s risk for suicide attempt hospitalization. While inferences differed slightly depending on the type of sensitivity analysis conducted, overall the association between maternal suicide and offspring’s hospitalization for suicide attempt was found to be relatively robust to an unobserved confounder. The ease of implementation and the insight these analyses provide underscores sensitivity analysis techniques as an important tool for non-experimental studies. The implementation of sensitivity analysis can help increase confidence in results from non-experimental studies and better inform prevention researchers and policymakers regarding potential intervention targets.},
	language = {en},
	number = {6},
	urldate = {2023-03-19},
	journal = {Prevention Science},
	author = {Liu, Weiwei and Kuramoto, S. Janet and Stuart, Elizabeth A.},
	month = dec,
	year = {2013},
	pages = {570--580},
	file = {Liu et al. - 2013 - An Introduction to Sensitivity Analysis for Unobse.pdf:/Users/orsonxu/Zotero/storage/EFJ9UPID/Liu et al. - 2013 - An Introduction to Sensitivity Analysis for Unobse.pdf:application/pdf},
}

@article{hernan_causal_nodate,
	title = {Causal {Inference}: {What} {If}},
	language = {en},
	author = {Hernan, Miguel A and Robins, James M},
	file = {Hernan and Robins - Causal Inference What If.pdf:/Users/orsonxu/Zotero/storage/WWSZAD3C/Hernan and Robins - Causal Inference What If.pdf:application/pdf},
}

@article{madan_when_2022,
	title = {When and how convolutional neural networks generalize to out-of-distribution category–viewpoint combinations},
	volume = {4},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-021-00437-5},
	doi = {10.1038/s42256-021-00437-5},
	language = {en},
	number = {2},
	urldate = {2023-03-23},
	journal = {Nature Machine Intelligence},
	author = {Madan, Spandan and Henry, Timothy and Dozier, Jamell and Ho, Helen and Bhandari, Nishchal and Sasaki, Tomotake and Durand, Frédo and Pfister, Hanspeter and Boix, Xavier},
	month = feb,
	year = {2022},
	pages = {146--153},
	file = {42256_2021_437_MOESM1_ESM.pdf:/Users/orsonxu/Zotero/storage/NLLUEZEZ/42256_2021_437_MOESM1_ESM.pdf:application/pdf;Madan et al. - 2022 - When and how convolutional neural networks general.pdf:/Users/orsonxu/Zotero/storage/UF74N8RJ/Madan et al. - 2022 - When and how convolutional neural networks general.pdf:application/pdf},
}

@misc{xu_how_2019,
	title = {How {Powerful} are {Graph} {Neural} {Networks}?},
	url = {http://arxiv.org/abs/1810.00826},
	abstract = {Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.},
	urldate = {2023-03-25},
	publisher = {arXiv},
	author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
	month = feb,
	year = {2019},
	file = {Xu et al_2019_How Powerful are Graph Neural Networks.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Xu et al_2019_How Powerful are Graph Neural Networks.pdf:application/pdf},
}

@article{wu_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	volume = {32},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2020.2978386},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.},
	number = {1},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2021},
	pages = {4--24},
	file = {Wu et al_2021_A Comprehensive Survey on Graph Neural Networks.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wu et al_2021_A Comprehensive Survey on Graph Neural Networks.pdf:application/pdf},
}

@misc{bubeck_sparks_2023,
	title = {Sparks of {Artificial} {General} {Intelligence}: {Early} experiments with {GPT}-4},
	shorttitle = {Sparks of {Artificial} {General} {Intelligence}},
	url = {http://arxiv.org/abs/2303.12712},
	abstract = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
	urldate = {2023-03-26},
	publisher = {arXiv},
	author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
	month = mar,
	year = {2023},
	file = {Bubeck et al_2023_Sparks of Artificial General Intelligence.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Bubeck et al_2023_Sparks of Artificial General Intelligence.pdf:application/pdf},
}

@misc{rudin_stop_2019,
	title = {Stop {Explaining} {Black} {Box} {Machine} {Learning} {Models} for {High} {Stakes} {Decisions} and {Use} {Interpretable} {Models} {Instead}},
	url = {http://arxiv.org/abs/1811.10154},
	abstract = {Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to explain black box models, rather than creating models that are interpretable in the ﬁrst place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward – it is to design models that are inherently interpretable. This manuscript clariﬁes the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identiﬁes challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.},
	language = {en},
	urldate = {2023-04-01},
	publisher = {arXiv},
	author = {Rudin, Cynthia},
	month = sep,
	year = {2019},
	file = {Rudin - 2019 - Stop Explaining Black Box Machine Learning Models .pdf:/Users/orsonxu/Zotero/storage/ED6S8LFD/Rudin - 2019 - Stop Explaining Black Box Machine Learning Models .pdf:application/pdf},
}

@misc{xiao_pac_2023,
	title = {{PAC} {Security}: {Automatic} {Privacy} {Measurement} and {Control} of {Data} {Processing}},
	shorttitle = {{PAC} {Security}},
	url = {http://arxiv.org/abs/2210.03458},
	abstract = {We propose and study a new privacy definition, termed Probably Approximately Correct (PAC) Security. PAC security characterizes the information-theoretic hardness to recover sensitive data given arbitrary information disclosure/leakage during/after any processing. Unlike the classic cryptographic definition and Differential Privacy (DP), which consider the adversarial (input-independent) worst case, PAC security is a simulatable metric that quantifies the instance-based impossibility of inference. A fully automatic analysis and proof generation framework is proposed: security parameters can be produced with arbitrarily high confidence via Monte-Carlo simulation for any black-box data processing oracle. This appealing automation property enables analysis of complicated data processing, where the worst-case proof in the classic privacy regime could be loose or even intractable. Moreover, we show that the produced PAC security guarantees enjoy simple composition bounds and the automatic analysis framework can be implemented in an online fashion to analyze the composite PAC security loss even under correlated randomness. On the utility side, the magnitude of (necessary) perturbation required in PAC security is not lower bounded by \${\textbackslash}Theta({\textbackslash}sqrt\{d\})\$ for a \$d\$-dimensional release but could be O(1) for many practical data processing tasks, which is in contrast to the input-independent worst-case information-theoretic lower bound. Example applications of PAC security are included with comparisons to existing works.},
	urldate = {2023-04-02},
	publisher = {arXiv},
	author = {Xiao, Hanshen and Devadas, Srinivas},
	month = feb,
	year = {2023},
	file = {arXiv Fulltext PDF:/Users/orsonxu/Zotero/storage/TJDQVMN6/Xiao and Devadas - 2023 - PAC Security Automatic Privacy Measurement and Co.pdf:application/pdf},
}

@misc{noauthor_flora_nodate,
	title = {Flora {Salid} \& {Yonchanok}\_App {Usage}\_11/28/22 - {UWEXP} {Anonymous} {Data} - {Google} {Drive}},
	url = {https://drive.google.com/drive/u/1/folders/1Gv13zyNNqg0B7bDB1_7lpCoC6wgG6sBE},
	urldate = {2023-04-04},
}

@misc{yang_evaluations_2023,
	title = {On the {Evaluations} of {ChatGPT} and {Emotion}-enhanced {Prompting} for {Mental} {Health} {Analysis}},
	url = {http://arxiv.org/abs/2304.03347},
	abstract = {Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, whereas the recent dominant methods utilized pre-trained language models (PLMs) as the backbone and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT's zero-shot performance for mental health analysis have limitations in inadequate evaluation, utilization of emotional information, and explainability of methods. In this work, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, including binary and multi-class mental health condition detection, cause/factor detection of mental health conditions, emotion recognition in conversations, and causal emotion entailment. We empirically analyze the impact of different prompting strategies with emotional cues on ChatGPT's mental health analysis ability and explainability. Experimental results show that ChatGPT outperforms traditional neural network methods but still has a significant gap with advanced task-specific methods. The qualitative analysis shows its potential in explainability compared with advanced black-box methods but also limitations on robustness and inaccurate reasoning. Prompt engineering with emotional cues is found to be effective in improving its performance on mental health analysis but requires the proper way of emotion infusion.},
	urldate = {2023-04-16},
	publisher = {arXiv},
	author = {Yang, Kailai and Ji, Shaoxiong and Zhang, Tianlin and Xie, Qianqian and Ananiadou, Sophia},
	month = apr,
	year = {2023},
	file = {Yang et al_2023_On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Yang et al_2023_On the Evaluations of ChatGPT and Emotion-enhanced Prompting for Mental Health Analysis.pdf:application/pdf},
}

@misc{ji_mentalbert_2021,
	title = {{MentalBERT}: {Publicly} {Available} {Pretrained} {Language} {Models} for {Mental} {Healthcare}},
	shorttitle = {{MentalBERT}},
	url = {http://arxiv.org/abs/2110.15621},
	abstract = {Mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without adequate treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. Recent advances in pretrained contextualized language representations have promoted the development of several domain-specific pretrained models and facilitated several downstream applications. However, there are no existing pretrained language models for mental healthcare. This paper trains and release two pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to benefit machine learning for the mental healthcare research community. Besides, we evaluate our trained domain-specific models and several variants of pretrained language models on several mental disorder detection benchmarks and demonstrate that language representations pretrained in the target domain improve the performance of mental health detection tasks.},
	urldate = {2023-04-16},
	publisher = {arXiv},
	author = {Ji, Shaoxiong and Zhang, Tianlin and Ansari, Luna and Fu, Jie and Tiwari, Prayag and Cambria, Erik},
	month = oct,
	year = {2021},
	file = {Ji et al_2021_MentalBERT.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Ji et al_2021_MentalBERT.pdf:application/pdf},
}

@misc{lamichhane_evaluation_2023,
	title = {Evaluation of {ChatGPT} for {NLP}-based {Mental} {Health} {Applications}},
	url = {http://arxiv.org/abs/2303.15727},
	abstract = {Large language models (LLM) have been successful in several natural language understanding tasks and could be relevant for natural language processing (NLP)-based mental health application research. In this work, we report the performance of LLM-based ChatGPT (with gpt-3.5-turbo backend) in three text-based mental health classification tasks: stress detection (2-class classification), depression detection (2-class classification), and suicidality detection (5-class classification). We obtained annotated social media posts for the three classification tasks from public datasets. Then ChatGPT API classified the social media posts with an input prompt for classification. We obtained F1 scores of 0.73, 0.86, and 0.37 for stress detection, depression detection, and suicidality detection, respectively. A baseline model that always predicted the dominant class resulted in F1 scores of 0.35, 0.60, and 0.19. The zero-shot classification accuracy obtained with ChatGPT indicates a potential use of language models for mental health classification tasks.},
	urldate = {2023-04-24},
	publisher = {arXiv},
	author = {Lamichhane, Bishal},
	month = mar,
	year = {2023},
	file = {Lamichhane_2023_Evaluation of ChatGPT for NLP-based Mental Health Applications.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Lamichhane_2023_Evaluation of ChatGPT for NLP-based Mental Health Applications.pdf:application/pdf},
}

@misc{amin_will_2023,
	title = {Will {Affective} {Computing} {Emerge} from {Foundation} {Models} and {General} {AI}? {A} {First} {Evaluation} on {ChatGPT}},
	shorttitle = {Will {Affective} {Computing} {Emerge} from {Foundation} {Models} and {General} {AI}?},
	url = {http://arxiv.org/abs/2303.03186},
	abstract = {ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilise three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results, and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where Word2Vec models achieve worse results due to noise. Results indicate that ChatGPT is a good generalist model that is capable of achieving good results across various problems without any specialised training, however, it is not as good as a specialised model for a downstream task.},
	urldate = {2023-04-24},
	publisher = {arXiv},
	author = {Amin, Mostafa M. and Cambria, Erik and Schuller, Björn W.},
	month = mar,
	year = {2023},
	file = {Amin et al_2023_Will Affective Computing Emerge from Foundation Models and General AI.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Amin et al_2023_Will Affective Computing Emerge from Foundation Models and General AI.pdf:application/pdf},
}

@inproceedings{suriyakumar_when_2023,
	title = {When {Personalization} {Harms}: {Reconsidering} the {Use} of {Group} {Attributes} in {Prediction}},
	shorttitle = {When {Personalization} {Harms}},
	url = {http://arxiv.org/abs/2206.02058},
	abstract = {Machine learning models are often personalized with categorical attributes that are protected, sensitive, self-reported, or costly to acquire. In this work, we show models that are personalized with group attributes can reduce performance at a group level. We propose formal conditions to ensure the "fair use" of group attributes in prediction tasks by training one additional model -- i.e., collective preference guarantees to ensure that each group who provides personal data will receive a tailored gain in performance in return. We present sufficient conditions to ensure fair use in empirical risk minimization and characterize failure modes that lead to fair use violations due to standard practices in model development and deployment. We present a comprehensive empirical study of fair use in clinical prediction tasks. Our results demonstrate the prevalence of fair use violations in practice and illustrate simple interventions to mitigate their harm.},
	urldate = {2023-05-17},
	booktitle = {{ICML}},
	publisher = {arXiv},
	author = {Suriyakumar, Vinith M. and Ghassemi, Marzyeh and Ustun, Berk},
	month = feb,
	year = {2023},
	note = {arXiv:2206.02058 [cs, stat]},
	file = {Suriyakumar et al_2023_When Personalization Harms.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Suriyakumar et al_2023_When Personalization Harms.pdf:application/pdf},
}

@inproceedings{suriyakumar_chasing_2021,
	address = {Virtual Event Canada},
	title = {Chasing {Your} {Long} {Tails}: {Differentially} {Private} {Prediction} in {Health} {Care} {Settings}},
	isbn = {978-1-4503-8309-7},
	shorttitle = {Chasing {Your} {Long} {Tails}},
	url = {https://dl.acm.org/doi/10.1145/3442188.3445934},
	doi = {10.1145/3442188.3445934},
	language = {en},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the 2021 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Suriyakumar, Vinith M. and Papernot, Nicolas and Goldenberg, Anna and Ghassemi, Marzyeh},
	month = mar,
	year = {2021},
	pages = {723--734},
	file = {Suriyakumar et al_2021_Chasing Your Long Tails.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Suriyakumar et al_2021_Chasing Your Long Tails.pdf:application/pdf},
}

@misc{chung_scaling_2022,
	title = {Scaling {Instruction}-{Finetuned} {Language} {Models}},
	url = {http://arxiv.org/abs/2210.11416},
	abstract = {Finetuning language models on a collection of datasets phrased as instructions has been shown to improve model performance and generalization to unseen tasks. In this paper we explore instruction finetuning with a particular focus on (1) scaling the number of tasks, (2) scaling the model size, and (3) finetuning on chain-of-thought data. We find that instruction finetuning with the above aspects dramatically improves performance on a variety of model classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM 540B by a large margin (+9.4\% on average). Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2\% on five-shot MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.},
	urldate = {2023-05-18},
	publisher = {arXiv},
	author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Castro-Ros, Alex and Pellat, Marie and Robinson, Kevin and Valter, Dasha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
	month = dec,
	year = {2022},
	note = {arXiv:2210.11416 [cs]},
	file = {Chung et al_2022_Scaling Instruction-Finetuned Language Models.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Chung et al_2022_Scaling Instruction-Finetuned Language Models.pdf:application/pdf},
}

@misc{nori_capabilities_2023,
	title = {Capabilities of {GPT}-4 on {Medical} {Challenge} {Problems}},
	url = {http://arxiv.org/abs/2303.13375},
	abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
	month = apr,
	year = {2023},
	note = {arXiv:2303.13375 [cs]},
	file = {Nori et al_2023_Capabilities of GPT-4 on Medical Challenge Problems.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Nori et al_2023_Capabilities of GPT-4 on Medical Challenge Problems.pdf:application/pdf},
}

@misc{wu_pmc-llama_2023,
	title = {{PMC}-{LLaMA}: {Further} {Finetuning} {LLaMA} on {Medical} {Papers}},
	shorttitle = {{PMC}-{LLaMA}},
	url = {http://arxiv.org/abs/2304.14454},
	abstract = {Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding in various domains. These models can usually behave well on daily dialog, or question answering scenarios, however, in areas that value precision, for example, in medical applications, they often exhibit unsatisfactory performance due to a lack of domain-specific knowledge. In this report, we introduce PMC-LLaMA, an open-source language model that is acquired by fine-tuning an open-source language model on a total of 4.8 million biomedical academic papers for further injecting medical knowledge, enhancing its capability in medical domain. Our preliminary evaluations are conducted on three biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing that the our model after finetuning, i.e., PMC-LLaMA, demonstrates better understanding of biomedical domain-specific concepts, thus achieving high performance on QA benchmarks. The model and codes, along with an online demo, are publicly available.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Wu, Chaoyi and Zhang, Xiaoman and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
	month = apr,
	year = {2023},
	note = {arXiv:2304.14454 [cs]},
	file = {Wu et al_2023_PMC-LLaMA.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wu et al_2023_PMC-LLaMA.pdf:application/pdf},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2023-05-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
	file = {Brown et al_2020_Language Models are Few-Shot Learners.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Brown et al_2020_Language Models are Few-Shot Learners2.pdf:application/pdf},
}

@misc{chowdhery_palm_2022,
	title = {{PaLM}: {Scaling} {Language} {Modeling} with {Pathways}},
	shorttitle = {{PaLM}},
	url = {http://arxiv.org/abs/2204.02311},
	abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
	month = oct,
	year = {2022},
	note = {arXiv:2204.02311 [cs]},
	file = {Chowdhery et al_2022_PaLM.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Chowdhery et al_2022_PaLM.pdf:application/pdf},
}

@misc{noauthor_introducing_2022,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/blog/chatgpt},
	abstract = {We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.},
	language = {en-US},
	urldate = {2023-05-19},
	year = {2022},
}

@misc{girdhar_imagebind_2023,
	title = {{ImageBind}: {One} {Embedding} {Space} {To} {Bind} {Them} {All}},
	shorttitle = {{ImageBind}},
	url = {http://arxiv.org/abs/2305.05665},
	abstract = {We present ImageBind, an approach to learn a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. We show that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient to bind the modalities together. ImageBind can leverage recent large scale vision-language models, and extends their zero-shot capabilities to new modalities just by using their natural pairing with images. It enables novel emergent applications 'out-of-the-box' including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation. The emergent capabilities improve with the strength of the image encoder and we set a new state-of-the-art on emergent zero-shot recognition tasks across modalities, outperforming specialist supervised models. Finally, we show strong few-shot recognition results outperforming prior work, and that ImageBind serves as a new way to evaluate vision models for visual and non-visual tasks.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
	month = may,
	year = {2023},
	note = {arXiv:2305.05665 [cs]},
	file = {Girdhar et al_2023_ImageBind.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Girdhar et al_2023_ImageBind.pdf:application/pdf},
}

@article{li_ethics_2023,
	title = {Ethics of large language models in medicine and medical research},
	volume = {0},
	issn = {2589-7500},
	url = {https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00083-3/fulltext},
	doi = {10.1016/S2589-7500(23)00083-3},
	language = {English},
	number = {0},
	urldate = {2023-05-19},
	journal = {The Lancet Digital Health},
	author = {Li, Hanzhou and Moon, John T. and Purkayastha, Saptarshi and Celi, Leo Anthony and Trivedi, Hari and Gichoya, Judy W.},
	month = apr,
	year = {2023},
	pmid = {37120418},
	note = {Publisher: Elsevier},
	file = {Li et al_2023_Ethics of large language models in medicine and medical research.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Li et al_2023_Ethics of large language models in medicine and medical research.pdf:application/pdf},
}

@article{liebrenz_generating_2023,
	title = {Generating scholarly content with {ChatGPT}: ethical challenges for medical publishing},
	volume = {5},
	issn = {25897500},
	shorttitle = {Generating scholarly content with {ChatGPT}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750023000195},
	doi = {10.1016/S2589-7500(23)00019-5},
	language = {en},
	number = {3},
	urldate = {2023-05-19},
	journal = {The Lancet Digital Health},
	author = {Liebrenz, Michael and Schleifer, Roman and Buadze, Anna and Bhugra, Dinesh and Smith, Alexander},
	month = mar,
	year = {2023},
	pages = {e105--e106},
	file = {Liebrenz et al. - 2023 - Generating scholarly content with ChatGPT ethical.pdf:/Users/orsonxu/Zotero/storage/HVMAYDHM/Liebrenz et al. - 2023 - Generating scholarly content with ChatGPT ethical.pdf:application/pdf},
}

@misc{wei_chain--thought_2023,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2201.11903},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
	month = jan,
	year = {2023},
	note = {arXiv:2201.11903 [cs]},
	file = {Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:/Users/orsonxu/Zotero/storage/435TFK9P/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf},
}

@misc{zhou_least--most_2023,
	title = {Least-to-{Most} {Prompting} {Enables} {Complex} {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2205.10625},
	abstract = {Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
	month = apr,
	year = {2023},
	note = {arXiv:2205.10625 [cs]},
	file = {Zhou et al_2023_Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhou et al_2023_Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.pdf:application/pdf},
}

@misc{lin_towards_2023,
	title = {Towards {Healthy} {AI}: {Large} {Language} {Models} {Need} {Therapists} {Too}},
	shorttitle = {Towards {Healthy} {AI}},
	url = {http://arxiv.org/abs/2304.00416},
	abstract = {Recent advances in large language models (LLMs) have led to the development of powerful AI chatbots capable of engaging in natural and human-like conversations. However, these chatbots can be potentially harmful, exhibiting manipulative, gaslighting, and narcissistic behaviors. We define Healthy AI to be safe, trustworthy and ethical. To create healthy AI systems, we present the SafeguardGPT framework that uses psychotherapy to correct for these harmful behaviors in AI chatbots. The framework involves four types of AI agents: a Chatbot, a "User," a "Therapist," and a "Critic." We demonstrate the effectiveness of SafeguardGPT through a working example of simulating a social conversation. Our results show that the framework can improve the quality of conversations between AI chatbots and humans. Although there are still several challenges and directions to be addressed in the future, SafeguardGPT provides a promising approach to improving the alignment between AI chatbots and human values. By incorporating psychotherapy and reinforcement learning techniques, the framework enables AI chatbots to learn and adapt to human preferences and values in a safe and ethical way, contributing to the development of a more human-centric and responsible AI.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Lin, Baihan and Bouneffouf, Djallel and Cecchi, Guillermo and Varshney, Kush R.},
	month = apr,
	year = {2023},
	note = {arXiv:2304.00416 [cs]},
	file = {Lin et al_2023_Towards Healthy AI.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Lin et al_2023_Towards Healthy AI.pdf:application/pdf},
}

@misc{liu_roberta_2019,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
	url = {http://arxiv.org/abs/1907.11692},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	language = {en},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
	note = {arXiv:1907.11692 [cs]},
	file = {Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:/Users/orsonxu/Zotero/storage/96JM9GP7/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:application/pdf},
}

@misc{hu_lora_2021,
	title = {{LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models}},
	shorttitle = {{LoRA}},
	url = {http://arxiv.org/abs/2106.09685},
	abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
	urldate = {2023-05-19},
	publisher = {arXiv},
	author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
	month = oct,
	year = {2021},
	note = {arXiv:2106.09685 [cs]},
	file = {Hu et al_2021_LoRA.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Hu et al_2021_LoRA.pdf:application/pdf},
}

@article{harrer_attention_2023,
	title = {Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine},
	volume = {90},
	issn = {23523964},
	shorttitle = {Attention is not all you need},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352396423000774},
	doi = {10.1016/j.ebiom.2023.104512},
	abstract = {Large Language Models (LLMs) are a key component of generative artiﬁcial intelligence (AI) applications for creating new content including text, imagery, audio, code, and videos in response to textual instructions. Without human oversight, guidance and responsible design and operation, such generative AI applications will remain a party trick with substantial potential for creating and spreading misinformation or harmful and inaccurate content at unprecedented scale. However, if positioned and developed responsibly as companions to humans augmenting but not replacing their role in decision making, knowledge retrieval and other cognitive processes, they could evolve into highly efﬁcient, trustworthy, assistive tools for information management. This perspective describes how such tools could transform data management workﬂows in healthcare and medicine, explains how the underlying technology works, provides an assessment of risks and limitations, and proposes an ethical, technical, and cultural framework for responsible design, development, and deployment. It seeks to incentivise users, developers, providers, and regulators of generative AI that utilises LLMs to collectively prepare for the transformational role this technology could play in evidence-based sectors.},
	language = {en},
	urldate = {2023-05-19},
	journal = {eBioMedicine},
	author = {Harrer, Stefan},
	month = apr,
	year = {2023},
	pages = {104512},
	file = {Harrer - 2023 - Attention is not all you need the complicated cas.pdf:/Users/orsonxu/Zotero/storage/MZXA34YP/Harrer - 2023 - Attention is not all you need the complicated cas.pdf:application/pdf},
}

@inproceedings{chen_why_2018,
	title = {Why {Is} {My} {Classifier} {Discriminatory}?},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/1f1baa5b8edac74eb4eaa329f14a0361-Abstract.html},
	abstract = {Recent attempts to achieve fairness in predictive models focus on the balance between fairness and accuracy. In sensitive applications such as healthcare or criminal justice, this trade-off is often undesirable as any increase in prediction error could have devastating consequences. In this work, we argue that the fairness of predictions should be evaluated in context of the data, and that unfairness induced by inadequate samples sizes or unmeasured predictive variables should be addressed through data collection, rather than by constraining the model. We decompose cost-based metrics of discrimination into bias, variance, and noise, and propose actions aimed at estimating and reducing each term. Finally, we perform case-studies on prediction of income, mortality, and review ratings, confirming the value of this analysis. We find that data collection is often a means to reduce discrimination without sacrificing accuracy.},
	urldate = {2023-05-20},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Chen, Irene and Johansson, Fredrik D and Sontag, David},
	year = {2018},
	file = {Chen et al_2018_Why Is My Classifier Discriminatory.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Chen et al_2018_Why Is My Classifier Discriminatory.pdf:application/pdf},
}

@article{irene_y_chen_ethical_2021,
	title = {Ethical {Machine} {Learning} in {Healthcare}},
	volume = {4},
	url = {https://doi.org/10.1146/annurev-biodatasci-092820-114757},
	doi = {10.1146/annurev-biodatasci-092820-114757},
	abstract = {The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges.},
	number = {1},
	urldate = {2023-05-20},
	journal = {Annual Review of Biomedical Data Science},
	author = {{Irene Y. Chen} and {Emma Pierson} and {Sherri Rose} and {Shalmali Joshi} and {Kadija Ferryman} and {Marzyeh Ghassemi}},
	year = {2021},
	note = {\_eprint: https://doi.org/10.1146/annurev-biodatasci-092820-114757},
	keywords = {Star},
	pages = {123--144},
	file = {Chen et al_2021_Ethical Machine Learning in Healthcare.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Chen et al_2021_Ethical Machine Learning in Healthcare.pdf:application/pdf},
}

@article{irene_y_chen_can_2019,
	title = {Can {AI} {Help} {Reduce} {Disparities} in {General} {Medical} and {Mental} {Health} {Care}?},
	volume = {21},
	issn = {2376-6980},
	url = {https://journalofethics.ama-assn.org/article/can-ai-help-reduce-disparities-general-medical-and-mental-health-care/2019-02},
	doi = {10.1001/amajethics.2019.167},
	abstract = {Background: As machine learning becomes increasingly common in health care applications, concerns have been raised about bias in these systems’ data, algorithms, and recommendations. Simply put, as health care improves for some, it might not improve for all.
Methods: Two case studies are examined using a machine learning algorithm on unstructured clinical and psychiatric notes to predict intensive care unit (ICU) mortality and 30-day psychiatric readmission with respect to race, gender, and insurance payer type as a proxy for socioeconomic status.
Results: Clinical note topics and psychiatric note topics were heterogenous with respect to race, gender, and insurance payer type, which reflects known clinical findings. Differences in prediction accuracy and therefore machine bias are shown with respect to gender and insurance type for ICU mortality and with respect to insurance policy for psychiatric 30-day readmission.
Conclusions: This analysis can provide a framework for assessing and identifying disparate impacts of artificial intelligence in health care.},
	language = {en},
	number = {2},
	urldate = {2023-05-20},
	journal = {AMA Journal of Ethics},
	author = {{Irene Y. Chen} and {Peter Szolovits} and {Marzyeh Ghassemi}},
	month = feb,
	year = {2019},
	pages = {E167--179},
	file = {2019 - Can AI Help Reduce Disparities in General Medical .pdf:/Users/orsonxu/Zotero/storage/G6DZI8D5/2019 - Can AI Help Reduce Disparities in General Medical .pdf:application/pdf},
}

@article{seyyed-kalantari_underdiagnosis_2021,
	title = {Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations},
	volume = {27},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-021-01595-0},
	doi = {10.1038/s41591-021-01595-0},
	abstract = {Abstract
            Artificial intelligence (AI) systems have increasingly achieved expert-level performance in medical imaging applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations such as female patients, Black patients, or patients of low socioeconomic status. Such biases are especially troubling in the context of underdiagnosis, whereby the AI algorithm would inaccurately label an individual with a disease as healthy, potentially delaying access to care. Here, we examine algorithmic underdiagnosis in chest X-ray pathology classification across three large chest X-ray datasets, as well as one multi-source dataset. We find that classifiers produced using state-of-the-art computer vision techniques consistently and selectively underdiagnosed under-served patient populations and that the underdiagnosis rate was higher for intersectional under-served subpopulations, for example, Hispanic female patients. Deployment of AI systems using medical imaging for disease diagnosis with such biases risks exacerbation of existing care biases and can potentially lead to unequal access to medical treatment, thereby raising ethical concerns for the use of these models in the clinic.},
	language = {en},
	number = {12},
	urldate = {2023-05-20},
	journal = {Nature Medicine},
	author = {Seyyed-Kalantari, Laleh and Zhang, Haoran and McDermott, Matthew B. A. and Chen, Irene Y. and Ghassemi, Marzyeh},
	month = dec,
	year = {2021},
	pages = {2176--2182},
	file = {Seyyed-Kalantari et al. - 2021 - Underdiagnosis bias of artificial intelligence alg.pdf:/Users/orsonxu/Zotero/storage/USTCAUDC/Seyyed-Kalantari et al. - 2021 - Underdiagnosis bias of artificial intelligence alg.pdf:application/pdf},
}

@inproceedings{balagopalan_road_2022,
	address = {Seoul Republic of Korea},
	title = {The {Road} to {Explainability} is {Paved} with {Bias}: {Measuring} the {Fairness} of {Explanations}},
	isbn = {978-1-4503-9352-2},
	shorttitle = {The {Road} to {Explainability} is {Paved} with {Bias}},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533179},
	doi = {10.1145/3531146.3533179},
	language = {en},
	urldate = {2023-05-21},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Balagopalan, Aparna and Zhang, Haoran and Hamidieh, Kimia and Hartvigsen, Thomas and Rudzicz, Frank and Ghassemi, Marzyeh},
	month = jun,
	year = {2022},
	pages = {1194--1206},
	file = {Balagopalan et al_2022_The Road to Explainability is Paved with Bias.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Balagopalan et al_2022_The Road to Explainability is Paved with Bias.pdf:application/pdf},
}

@article{balagopalan_judging_2023,
	title = {Judging facts, judging norms: {Training} machine learning models to judge humans requires a modified approach to labeling data},
	volume = {9},
	issn = {2375-2548},
	shorttitle = {Judging facts, judging norms},
	url = {https://www.science.org/doi/10.1126/sciadv.abq0701},
	doi = {10.1126/sciadv.abq0701},
	abstract = {As governments and industry turn to increased use of automated decision systems, it becomes essential to consider how closely such systems can reproduce human judgment. We identify a core potential failure, finding that annotators label objects differently depending on whether they are being asked a factual question or a normative question. This challenges a natural assumption maintained in many standard machine-learning (ML) data acquisition procedures: that there is no difference between predicting the factual classification of an object and an exercise of judgment about whether an object violates a rule premised on those facts. We find that using factual labels to train models intended for normative judgments introduces a notable measurement error. We show that models trained using factual labels yield significantly different judgments than those trained using normative labels and that the impact of this effect on model performance can exceed that of other factors (e.g., dataset size) that routinely attract attention from ML researchers and practitioners.
          , 
            Machine learning systems trained with factual features as labels do not reproduce human rule violation judgments on the same data.},
	language = {en},
	number = {19},
	urldate = {2023-05-22},
	journal = {Science Advances},
	author = {Balagopalan, Aparna and Madras, David and Yang, David H. and Hadfield-Menell, Dylan and Hadfield, Gillian K. and Ghassemi, Marzyeh},
	month = may,
	year = {2023},
	pages = {eabq0701},
	file = {Balagopalan et al_2023_Judging facts, judging norms.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Balagopalan et al_2023_Judging facts, judging norms.pdf:application/pdf},
}

@article{adam_mitigating_2022,
	title = {Mitigating the impact of biased artificial intelligence in emergency decision-making},
	volume = {2},
	issn = {2730-664X},
	url = {https://www.nature.com/articles/s43856-022-00214-4},
	doi = {10.1038/s43856-022-00214-4},
	abstract = {Background Prior research has shown that artiﬁcial intelligence (AI) systems often encode biases against minority subgroups. However, little work has focused on ways to mitigate the harm discriminatory algorithms can cause in high-stakes settings such as medicine.
Methods In this study, we experimentally evaluated the impact biased AI recommendations have on emergency decisions, where participants respond to mental health crises by calling for either medical or police assistance. We recruited 438 clinicians and 516 non-experts to participate in our web-based experiment. We evaluated participant decision-making with and without advice from biased and unbiased AI systems. We also varied the style of the AI advice, framing it either as prescriptive recommendations or descriptive ﬂags.
Results Participant decisions are unbiased without AI advice. However, both clinicians and non-experts are inﬂuenced by prescriptive recommendations from a biased algorithm, choosing police help more often in emergencies involving African-American or Muslim men. Crucially, using descriptive ﬂags rather than prescriptive recommendations allows respondents to retain their original, unbiased decision-making.
Conclusions Our work demonstrates the practical danger of using biased models in health contexts, and suggests that appropriately framing decision support can mitigate the effects of AI bias. These ﬁndings must be carefully considered in the many real-world clinical scenarios where inaccurate or biased models may be used to inform important decisions.},
	language = {en},
	number = {1},
	urldate = {2023-05-22},
	journal = {Communications Medicine},
	author = {Adam, Hammaad and Balagopalan, Aparna and Alsentzer, Emily and Christia, Fotini and Ghassemi, Marzyeh},
	month = nov,
	year = {2022},
	pages = {149},
	file = {Adam et al. - 2022 - Mitigating the impact of biased artificial intelli.pdf:/Users/orsonxu/Zotero/storage/PQBZYCV4/Adam et al. - 2022 - Mitigating the impact of biased artificial intelli.pdf:application/pdf},
}

@article{ghassemi_false_2021,
	title = {The false hope of current approaches to explainable artificial intelligence in health care},
	volume = {3},
	issn = {25897500},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750021002089},
	doi = {10.1016/S2589-7500(21)00208-9},
	language = {en},
	number = {11},
	urldate = {2023-05-23},
	journal = {The Lancet Digital Health},
	author = {Ghassemi, Marzyeh and Oakden-Rayner, Luke and Beam, Andrew L},
	month = nov,
	year = {2021},
	pages = {e745--e750},
	file = {Ghassemi et al. - 2021 - The false hope of current approaches to explainabl.pdf:/Users/orsonxu/Zotero/storage/M976SZGP/Ghassemi et al. - 2021 - The false hope of current approaches to explainabl.pdf:application/pdf},
}

@inproceedings{suresh_clinical_2017,
	title = {Clinical {Intervention} {Prediction} and {Understanding} with {Deep} {Neural} {Networks}},
	url = {https://proceedings.mlr.press/v68/suresh17a.html},
	abstract = {Real-time prediction of clinical interventions remains a challenge within intensive care units (ICUs). This task is complicated by data sources that are sparse, noisy, heterogeneous and outcomes that are imbalanced. In this work, we integrate data across many ICU sources — vitals, labs, notes, demographics — and focus on learning rich representations of this data to predict onset and weaning of multiple invasive interventions. In particular, we compare both long short-term memory networks (LSTM) and convolutional neural networks (CNN) for prediction of five intervention tasks: invasive ventilation, non-invasive ventilation, vasopressors, colloid boluses, and crystalloid boluses. Our predictions are done in a forward-facing manner after a six hour gap time to support clinically actionable planning. We achieve state-of-the-art results on these predictive tasks using deep architectures. Further, we explore the use of feature occlusion to interpret LSTM models, and compare this to the interpretability gained from examining inputs that maximally activate CNN outputs. We show that our models are able to significantly outperform baselines for intervention prediction, and provide insight into model learning.},
	language = {en},
	urldate = {2023-05-23},
	booktitle = {Proceedings of the 2nd {Machine} {Learning} for {Healthcare} {Conference}},
	publisher = {PMLR},
	author = {Suresh, Harini and Hunt, Nathan and Johnson, Alistair and Celi, Leo Anthony and Szolovits, Peter and Ghassemi, Marzyeh},
	month = nov,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {322--337},
	file = {Suresh et al_2017_Clinical Intervention Prediction and Understanding with Deep Neural Networks.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Suresh et al_2017_Clinical Intervention Prediction and Understanding with Deep Neural Networks.pdf:application/pdf},
}

@article{beam_challenges_2020,
	title = {Challenges to the {Reproducibility} of {Machine} {Learning} {Models} in {Health} {Care}},
	volume = {323},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2758612},
	doi = {10.1001/jama.2019.20866},
	language = {en},
	number = {4},
	urldate = {2023-05-23},
	journal = {JAMA},
	author = {Beam, Andrew L. and Manrai, Arjun K. and Ghassemi, Marzyeh},
	month = jan,
	year = {2020},
	pages = {305},
	file = {Beam et al. - 2020 - Challenges to the Reproducibility of Machine Learn.pdf:/Users/orsonxu/Zotero/storage/JL8JCW9J/Beam et al. - 2020 - Challenges to the Reproducibility of Machine Learn.pdf:application/pdf},
}

@techreport{doddaiah_explaining_2023,
	type = {preprint},
	title = {Explaining {Deep} {Multi}-{Class} {Time} {Series} {Classifiers}},
	url = {https://www.researchsquare.com/article/rs-2531572/v1},
	abstract = {Abstract
          Explainability helps users trust deep learning solutions for time series classification. However, existing explainability methods for multi-class time series classifiers focus on one class at a time, ignoring relationships between the classes. Instead, when a classifier is choosing between many classes, an effective explanation must show what sets the chosen class apart from the rest. We now formalize this notion, studying the open problem of class-specific explainability for deep time series classifiers, a challenging and impactful problem setting. We design a novel explainability method, DEMUX, which learns saliency maps for explaining deep multi-class time series classifiers by adaptively ensuring that its explanation spotlights the regions in an input time series that a model uses specifically to its predicted class. DEMUX adopts a gradient-based approach composed of three interdependent modules that combine to generate consistent, class-specific saliency maps that remain faithful to the classifier's behavior yet are easily understood by end users. We demonstrate that DEMUX outperforms nine state-of-the-art alternatives on seven popular datasets when explaining two types of deep time series classifiers. We analyze run time performance, show the impacts of hyperparameter selection, and introduce a detailed study of perturbation methods for time series. Further, through a case study, we demonstrate that DEMUX's explanations indeed highlight what separates the predicted class from the others in the eyes of the classifier.},
	language = {en},
	urldate = {2023-05-23},
	institution = {In Review},
	author = {Doddaiah, Ramesh and Parvatharaju, Prathyush and Rundensteiner, Elke and Hartvigsen, Thomas},
	month = feb,
	year = {2023},
	doi = {10.21203/rs.3.rs-2531572/v1},
	file = {Doddaiah et al. - 2023 - Explaining Deep Multi-Class Time Series Classifier.pdf:/Users/orsonxu/Zotero/storage/YCZAGY7H/Doddaiah et al. - 2023 - Explaining Deep Multi-Class Time Series Classifier.pdf:application/pdf},
}

@inproceedings{zhang_learning_2021,
	title = {Learning {Optimal} {Predictive} {Checklists}},
	url = {http://arxiv.org/abs/2112.01020},
	abstract = {Checklists are simple decision aids that are often used to promote safety and reliability in clinical applications. In this paper, we present a method to learn checklists for clinical decision support. We represent predictive checklists as discrete linear classifiers with binary features and unit weights. We then learn globally optimal predictive checklists from data by solving an integer programming problem. Our method allows users to customize checklists to obey complex constraints, including constraints to enforce group fairness and to binarize real-valued features at training time. In addition, it pairs models with an optimality gap that can inform model development and determine the feasibility of learning sufficiently accurate checklists on a given dataset. We pair our method with specialized techniques that speed up its ability to train a predictive checklist that performs well and has a small optimality gap. We benchmark the performance of our method on seven clinical classification problems, and demonstrate its practical benefits by training a short-form checklist for PTSD screening. Our results show that our method can fit simple predictive checklists that perform well and that can easily be customized to obey a rich class of custom constraints.},
	urldate = {2023-05-26},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {arXiv},
	author = {Zhang, Haoran and Morris, Quaid and Ustun, Berk and Ghassemi, Marzyeh},
	year = {2021},
	note = {arXiv:2112.01020 [cs]},
	file = {Zhang et al_2022_Learning Optimal Predictive Checklists.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhang et al_2022_Learning Optimal Predictive Checklists.pdf:application/pdf},
}

@misc{yang_towards_2023,
	title = {Towards {Interpretable} {Mental} {Health} {Analysis} with {ChatGPT}},
	url = {http://arxiv.org/abs/2304.03347},
	abstract = {Automated mental health analysis shows great potential for enhancing the efficiency and accessibility of mental health care, with recent methods using pre-trained language models (PLMs) and incorporated emotional information. The latest large language models (LLMs), such as ChatGPT, exhibit dramatic capabilities on diverse natural language processing tasks. However, existing studies on ChatGPT for mental health analysis bear limitations in inadequate evaluations, ignorance of emotional information, and lack of explainability. To bridge these gaps, we comprehensively evaluate the mental health analysis and emotional reasoning ability of ChatGPT on 11 datasets across 5 tasks, and analyze the effects of various emotion-based prompting strategies. Based on these prompts, we further explore LLMs for interpretable mental health analysis by instructing them to also generate explanations for each of their decisions. With an annotation protocol designed by domain experts, we convey human evaluations to assess the quality of explanations generated by ChatGPT and GPT-3. The annotated corpus will be released for future research. Experimental results show that ChatGPT outperforms traditional neural network-based methods but still has a significant gap with advanced task-specific methods. Prompt engineering with emotional cues can be effective in improving performance on mental health analysis but suffers from a lack of robustness and inaccurate reasoning. In addition, ChatGPT significantly outperforms GPT-3 on all criteria in human evaluations of the explanations and approaches to human performance, showing its great potential in explainable mental health analysis.},
	urldate = {2023-05-29},
	publisher = {arXiv},
	author = {Yang, Kailai and Ji, Shaoxiong and Zhang, Tianlin and Xie, Qianqian and Kuang, Ziyan and Ananiadou, Sophia},
	month = may,
	year = {2023},
	note = {arXiv:2304.03347 [cs]},
	file = {Yang et al_2023_Towards Interpretable Mental Health Analysis with ChatGPT.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Yang et al_2023_Towards Interpretable Mental Health Analysis with ChatGPT.pdf:application/pdf},
}

@inproceedings{liu_large_2023,
	title = {Large {Language} {Models} are {Few}-{Shot} {Health} {Learners}},
	abstract = {Large language models (LLMs) can capture rich representations of concepts that are useful for real-world tasks. However, language alone is limited. While existing LLMs excel at text-based inferences, health applications require that models be grounded in numerical data (e.g., vital signs, laboratory values in clinical domains; steps, movement in the wellness domain) that is not easily or readily expressed as text in existing training corpus. We demonstrate that with only few-shot tuning, a large language model is capable of grounding various physiological and behavioral time-series data and making meaningful inferences on numerous health tasks for both clinical and wellness contexts. Using data from wearable and medical sensor recordings, we evaluate these capabilities on the tasks of cardiac signal analysis, physical activity recognition, metabolic calculation (e.g., calories burned), and estimation of stress reports and mental health screeners.},
	language = {en},
	booktitle = {{arXiv}},
	author = {Liu, Xin and McDuff, Daniel and Kovacs, Geza and Galatzer-Levy, Isaac and Sunshine, Jacob and Zhan, Jiening and Poh, Ming-Zher and Liao, Shun and Achille, Paolo Di and Patel, Shwetak},
	year = {2023},
	file = {Liu et al. - Large Language Models are Few-Shot Health Learners.pdf:/Users/orsonxu/Zotero/storage/GMNN82KJ/Liu et al. - Large Language Models are Few-Shot Health Learners.pdf:application/pdf},
}

@article{liu_medical_2022,
	title = {The medical algorithmic audit},
	volume = {4},
	issn = {25897500},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750022000036},
	doi = {10.1016/S2589-7500(22)00003-6},
	language = {en},
	number = {5},
	urldate = {2023-06-22},
	journal = {The Lancet Digital Health},
	author = {Liu, Xiaoxuan and Glocker, Ben and McCradden, Melissa M and Ghassemi, Marzyeh and Denniston, Alastair K and Oakden-Rayner, Lauren},
	month = may,
	year = {2022},
	pages = {e384--e397},
	file = {Liu et al. - 2022 - The medical algorithmic audit.pdf:/Users/orsonxu/Zotero/storage/AZYDVMQE/Liu et al. - 2022 - The medical algorithmic audit.pdf:application/pdf},
}

@article{pierson_algorithmic_2021,
	title = {An algorithmic approach to reducing unexplained pain disparities in underserved populations},
	volume = {27},
	issn = {1078-8956, 1546-170X},
	url = {https://www.nature.com/articles/s41591-020-01192-7},
	doi = {10.1038/s41591-020-01192-7},
	language = {en},
	number = {1},
	urldate = {2023-06-24},
	journal = {Nature Medicine},
	author = {Pierson, Emma and Cutler, David M. and Leskovec, Jure and Mullainathan, Sendhil and Obermeyer, Ziad},
	month = jan,
	year = {2021},
	pages = {136--140},
	file = {Pierson et al. - 2021 - An algorithmic approach to reducing unexplained pa.pdf:/Users/orsonxu/Zotero/storage/I3QV7VCD/Pierson et al. - 2021 - An algorithmic approach to reducing unexplained pa.pdf:application/pdf},
}

@article{wang_bias_2022,
	title = {A bias evaluation checklist for predictive models and its pilot application for 30-day hospital readmission models},
	volume = {29},
	issn = {1527-974X},
	url = {https://academic.oup.com/jamia/article/29/8/1323/6586579},
	doi = {10.1093/jamia/ocac065},
	abstract = {Objective: Health care providers increasingly rely upon predictive algorithms when making important treatment decisions, however, evidence indicates that these tools can lead to inequitable outcomes across racial and socio-economic groups. In this study, we introduce a bias evaluation checklist that allows model developers and health care providers a means to systematically appraise a model’s potential to introduce bias. Materials and Methods: Our methods include developing a bias evaluation checklist, a scoping literature review to identify 30-day hospital readmission prediction models, and assessing the selected models using the checklist.
Results: We selected 4 models for evaluation: LACE, HOSPITAL, Johns Hopkins ACG, and HATRIX. Our assessment identiﬁed critical ways in which these algorithms can perpetuate health care inequalities. We found that LACE and HOSPITAL have the greatest potential for introducing bias, Johns Hopkins ACG has the most areas of uncertainty, and HATRIX has the fewest causes for concern. Discussion: Our approach gives model developers and health care providers a practical and systematic method for evaluating bias in predictive models. Traditional bias identiﬁcation methods do not elucidate sources of bias and are thus insufﬁcient for mitigation efforts. With our checklist, bias can be addressed and eliminated before a model is fully developed or deployed.
Conclusion: The potential for algorithms to perpetuate biased outcomes is not isolated to readmission prediction models; rather, we believe our results have implications for predictive models across health care. We offer a systematic method for evaluating potential bias with sufﬁcient ﬂexibility to be utilized across models and applications.},
	language = {en},
	number = {8},
	urldate = {2023-06-24},
	journal = {Journal of the American Medical Informatics Association},
	author = {Wang, H Echo and Landers, Matthew and Adams, Roy and Subbaswamy, Adarsh and Kharrazi, Hadi and Gaskin, Darrell J and Saria, Suchi},
	month = jul,
	year = {2022},
	pages = {1323--1333},
	file = {Wang et al. - 2022 - A bias evaluation checklist for predictive models .pdf:/Users/orsonxu/Zotero/storage/IL7WPMMX/Wang et al. - 2022 - A bias evaluation checklist for predictive models .pdf:application/pdf},
}

@article{vasey_reporting_2022,
	title = {Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: {DECIDE}-{AI}},
	volume = {28},
	issn = {1078-8956, 1546-170X},
	shorttitle = {Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence},
	url = {https://www.nature.com/articles/s41591-022-01772-9},
	doi = {10.1038/s41591-022-01772-9},
	abstract = {Provide a structured summary of the study.},
	language = {en},
	number = {5},
	urldate = {2023-06-24},
	journal = {Nature Medicine},
	author = {Vasey, Baptiste and Nagendran, Myura and Campbell, Bruce and Clifton, David A. and Collins, Gary S. and Denaxas, Spiros and Denniston, Alastair K. and Faes, Livia and Geerts, Bart and Ibrahim, Mudathir and Liu, Xiaoxuan and Mateen, Bilal A. and Mathur, Piyush and McCradden, Melissa D. and Morgan, Lauren and Ordish, Johan and Rogers, Campbell and Saria, Suchi and Ting, Daniel S. W. and Watkinson, Peter and Weber, Wim and Wheatstone, Peter and McCulloch, Peter and {the DECIDE-AI expert group} and Lee, Aaron Y. and Fraser, Alan G. and Connell, Ali and Vira, Alykhan and Esteva, Andre and Althouse, Andrew D. and Beam, Andrew L. and De Hond, Anne and Boulesteix, Anne-Laure and Bradlow, Anthony and Ercole, Ari and Paez, Arsenio and Tsanas, Athanasios and Kirby, Barry and Glocker, Ben and Velardo, Carmelo and Park, Chang Min and Hehakaya, Charisma and Baber, Chris and Paton, Chris and Johner, Christian and Kelly, Christopher J. and Vincent, Christopher J. and Yau, Christopher and McGenity, Clare and Gatsonis, Constantine and Faivre-Finn, Corinne and Simon, Crispin and Sent, Danielle and Bzdok, Danilo and Treanor, Darren and Wong, David C. and Steiner, David F. and Higgins, David and Benson, Dawn and O’Regan, Declan P. and Gunasekaran, Dinesh V. and Danks, Dominic and Neri, Emanuele and Kyrimi, Evangelia and Schwendicke, Falk and Magrabi, Farah and Ives, Frances and Rademakers, Frank E. and Fowler, George E. and Frau, Giuseppe and Hogg, H. D. Jeffry and Marcus, Hani J. and Chan, Heang-Ping and Xiang, Henry and McIntyre, Hugh F. and Harvey, Hugh and Kim, Hyungjin and Habli, Ibrahim and Fackler, James C. and Shaw, James and Higham, Janet and Wohlgemut, Jared M. and Chong, Jaron and Bibault, Jean-Emmanuel and Cohen, Jérémie F. and Kers, Jesper and Morley, Jessica and Krois, Joachim and Monteiro, Joao and Horovitz, Joel and Fletcher, John and Taylor, Jonathan and Yoon, Jung Hyun and Singh, Karandeep and Moons, Karel G. M. and Karpathakis, Kassandra and Catchpole, Ken and Hood, Kerenza and Balaskas, Konstantinos and Kamnitsas, Konstantinos and Militello, Laura and Wynants, Laure and Oakden-Rayner, Lauren and Lovat, Laurence B. and Smits, Luc J. M. and Hinske, Ludwig C. and ElZarrad, M. Khair and Van Smeden, Maarten and Giavina-Bianchi, Mara and Daley, Mark and Sendak, Mark P. and Sujan, Mark and Rovers, Maroeska and DeCamp, Matthew and Woodward, Matthew and Komorowski, Matthieu and Marsden, Max and Mackintosh, Maxine and Abramoff, Michael D. and De La Hoz, Miguel Ángel Armengol and Hambidge, Neale and Daly, Neil and Peek, Niels and Redfern, Oliver and Ahmad, Omer F. and Bossuyt, Patrick M. and Keane, Pearse A. and Ferreira, Pedro N. P. and Schnell-Inderst, Petra and Mascagni, Pietro and Dasgupta, Prokar and Guan, Pujun and Barnett, Rachel and Kader, Rawen and Chopra, Reena and Mann, Ritse M. and Sarkar, Rupa and Mäenpää, Saana M. and Finlayson, Samuel G. and Vollam, Sarah and Vollmer, Sebastian J. and Park, Seong Ho and Laher, Shakir and Joshi, Shalmali and Van Der Meijden, Siri L. and Shelmerdine, Susan C. and Tan, Tien-En and Stocker, Tom J. W. and Giannini, Valentina and Madai, Vince I. and Newcombe, Virginia and Ng, Wei Yan and Rogers, Wendy A. and Ogallo, William and Park, Yoonyoung and Perkins, Zane B.},
	month = may,
	year = {2022},
	pages = {924--933},
	file = {Vasey et al. - 2022 - Reporting guideline for the early-stage clinical e.pdf:/Users/orsonxu/Zotero/storage/WEJHTQ5N/Vasey et al. - 2022 - Reporting guideline for the early-stage clinical e.pdf:application/pdf},
}

@article{jiang_health_2023,
	title = {Health system-scale language models are all-purpose prediction engines},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06160-y},
	doi = {10.1038/s41586-023-06160-y},
	abstract = {Abstract
            
              Physicians make critical time-constrained decisions every day. Clinical predictive models can help physicians and administrators make decisions by forecasting clinical and operational events. Existing structured data-based clinical predictive models have limited use in everyday practice owing to complexity in data processing, as well as model development and deployment
              1–3
              . Here we show that unstructured clinical notes from the electronic health record can enable the training of clinical language models, which can be used as all-purpose clinical predictive engines with low-resistance development and deployment. Our approach leverages recent advances in natural language processing
              4,5
              to train a large language model for medical language (NYUTron) and subsequently fine-tune it across a wide range of clinical and operational predictive tasks. We evaluated our approach within our health system for five such tasks: 30-day all-cause readmission prediction, in-hospital mortality prediction, comorbidity index prediction, length of stay prediction, and insurance denial prediction. We show that NYUTron has an area under the curve (AUC) of 78.7–94.9\%, with an improvement of 5.36–14.7\% in the AUC compared with traditional models. We additionally demonstrate the benefits of pretraining with clinical text, the potential for increasing generalizability to different sites through fine-tuning and the full deployment of our system in a prospective, single-arm trial. These results show the potential for using clinical language models in medicine to read alongside physicians and provide guidance at the point of care.},
	language = {en},
	urldate = {2023-07-01},
	journal = {Nature},
	author = {Jiang, Lavender Yao and Liu, Xujin Chris and Nejatian, Nima Pour and Nasir-Moin, Mustafa and Wang, Duo and Abidin, Anas and Eaton, Kevin and Riina, Howard Antony and Laufer, Ilya and Punjabi, Paawan and Miceli, Madeline and Kim, Nora C. and Orillac, Cordelia and Schnurman, Zane and Livia, Christopher and Weiss, Hannah and Kurland, David and Neifert, Sean and Dastagirzada, Yosef and Kondziolka, Douglas and Cheung, Alexander T. M. and Yang, Grace and Cao, Ming and Flores, Mona and Costa, Anthony B. and Aphinyanaphongs, Yindalon and Cho, Kyunghyun and Oermann, Eric Karl},
	month = jun,
	year = {2023},
	file = {Jiang et al. - 2023 - Health system-scale language models are all-purpos.pdf:/Users/orsonxu/Zotero/storage/77PX86ZQ/Jiang et al. - 2023 - Health system-scale language models are all-purpos.pdf:application/pdf},
}

@misc{singhal_towards_2023,
	title = {Towards {Expert}-{Level} {Medical} {Question} {Answering} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2305.09617},
	abstract = {Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2\% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5\% on the MedQA dataset, improving upon Med-PaLM by over 19\% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p {\textless} 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p {\textless} 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.},
	urldate = {2023-07-13},
	publisher = {arXiv},
	author = {Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and Schaekermann, Mike and Wang, Amy and Amin, Mohamed and Lachgar, Sami and Mansfield, Philip and Prakash, Sushant and Green, Bradley and Dominowska, Ewa and Arcas, Blaise Aguera y and Tomasev, Nenad and Liu, Yun and Wong, Renee and Semturs, Christopher and Mahdavi, S. Sara and Barral, Joelle and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Azizi, Shekoofeh and Karthikesalingam, Alan and Natarajan, Vivek},
	month = may,
	year = {2023},
	note = {arXiv:2305.09617 [cs]},
	file = {Singhal et al_2023_Towards Expert-Level Medical Question Answering with Large Language Models.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Singhal et al_2023_Towards Expert-Level Medical Question Answering with Large Language Models.pdf:application/pdf},
}

@misc{li_chatdoctor_2023,
	title = {{ChatDoctor}: {A} {Medical} {Chat} {Model} {Fine}-{Tuned} on a {Large} {Language} {Model} {Meta}-{AI} ({LLaMA}) {Using} {Medical} {Domain} {Knowledge}},
	shorttitle = {{ChatDoctor}},
	url = {http://arxiv.org/abs/2303.14070},
	abstract = {The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice. We achieved this by adapting and refining the large language model meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases. The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses. Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.},
	urldate = {2023-07-13},
	publisher = {arXiv},
	author = {Li, Yunxiang and Li, Zihan and Zhang, Kai and Dan, Ruilong and Jiang, Steve and Zhang, You},
	month = jun,
	year = {2023},
	note = {arXiv:2303.14070 [cs]},
	file = {Li et al_2023_ChatDoctor.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Li et al_2023_ChatDoctor.pdf:application/pdf},
}

@misc{radford_improving_2018,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year = {2018},
	file = {Radford et al. - Improving Language Understanding by Generative Pre.pdf:/Users/orsonxu/Zotero/storage/K2TYS4H9/Radford et al. - Improving Language Understanding by Generative Pre.pdf:application/pdf},
}

@article{raffel_exploring_2020,
	title = {Exploring the {Limits} of {Transfer} {Learning} with a {Uniﬁed} {Text}-to-{Text} {Transformer}},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	year = {2020},
	file = {Raﬀel et al. - Exploring the Limits of Transfer Learning with a U.pdf:/Users/orsonxu/Zotero/storage/HMEDYBFD/Raﬀel et al. - Exploring the Limits of Transfer Learning with a U.pdf:application/pdf},
}

@misc{wei_finetuned_2022,
	title = {Finetuned {Language} {Models} {Are} {Zero}-{Shot} {Learners}},
	url = {http://arxiv.org/abs/2109.01652},
	abstract = {This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning -- finetuning language models on a collection of tasks described via instructions -- substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction-tune it on over 60 NLP tasks verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 tasks that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.},
	urldate = {2023-07-14},
	publisher = {arXiv},
	author = {Wei, Jason and Bosma, Maarten and Zhao, Vincent Y. and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M. and Le, Quoc V.},
	month = feb,
	year = {2022},
	note = {arXiv:2109.01652 [cs]},
	file = {Wei et al_2022_Finetuned Language Models Are Zero-Shot Learners.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wei et al_2022_Finetuned Language Models Are Zero-Shot Learners.pdf:application/pdf},
}

@misc{touvron_llama_2023,
	title = {{LLaMA}: {Open} and {Efficient} {Foundation} {Language} {Models}},
	shorttitle = {{LLaMA}},
	url = {http://arxiv.org/abs/2302.13971},
	abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
	urldate = {2023-07-14},
	publisher = {arXiv},
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	month = feb,
	year = {2023},
	note = {arXiv:2302.13971 [cs]},
	file = {Touvron et al_2023_LLaMA.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Touvron et al_2023_LLaMA.pdf:application/pdf},
}

@misc{taori_stanford_2023,
	title = {Stanford alpaca: {An} instruction-following llama model},
	author = {Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B.},
	year = {2023},
}

@misc{nori_capabilities_2023-1,
	title = {Capabilities of {GPT}-4 on {Medical} {Challenge} {Problems}},
	url = {http://arxiv.org/abs/2303.13375},
	abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation across various domains, including medicine. We present a comprehensive evaluation of GPT-4, a state-of-the-art LLM, on medical competency examinations and benchmark datasets. GPT-4 is a general-purpose model that is not specialized for medical problems through training or engineered to solve clinical tasks. Our analysis covers two sets of official practice materials for the USMLE, a three-step examination program used to assess clinical competency and grant licensure in the United States. We also evaluate performance on the MultiMedQA suite of benchmark datasets. Beyond measuring model performance, experiments were conducted to investigate the influence of test questions containing both text and images on model performance, probe for memorization of content during training, and study probability calibration, which is of critical importance in high-stakes applications like medicine. Our results show that GPT-4, without any specialized prompt crafting, exceeds the passing score on USMLE by over 20 points and outperforms earlier general-purpose models (GPT-3.5) as well as models specifically fine-tuned on medical knowledge (Med-PaLM, a prompt-tuned version of Flan-PaLM 540B). In addition, GPT-4 is significantly better calibrated than GPT-3.5, demonstrating a much-improved ability to predict the likelihood that its answers are correct. We also explore the behavior of the model qualitatively through a case study that shows the ability of GPT-4 to explain medical reasoning, personalize explanations to students, and interactively craft new counterfactual scenarios around a medical case. Implications of the findings are discussed for potential uses of GPT-4 in medical education, assessment, and clinical practice, with appropriate attention to challenges of accuracy and safety.},
	urldate = {2023-07-24},
	publisher = {arXiv},
	author = {Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
	month = apr,
	year = {2023},
	note = {arXiv:2303.13375 [cs]},
	file = {Nori et al_2023_Capabilities of GPT-4 on Medical Challenge Problems.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Nori et al_2023_Capabilities of GPT-4 on Medical Challenge Problems2.pdf:application/pdf},
}

@misc{lai_psy-llm_2023,
	title = {Psy-{LLM}: {Scaling} up {Global} {Mental} {Health} {Psychological} {Services} with {AI}-based {Large} {Language} {Models}},
	shorttitle = {Psy-{LLM}},
	url = {http://arxiv.org/abs/2307.11991},
	abstract = {The demand for psychological counseling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counseling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based system leveraging Large Language Models (LLMs) for question-answering in online psychological consultation. Our framework combines pre-trained LLMs with real-world professional Q\&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and extrinsic evaluation metrics, with human participant assessments of response helpfulness, fluency, relevance, and logic. The results demonstrate the effectiveness of the Psy-LLM framework in generating coherent and relevant answers to psychological questions. This article concludes by discussing the potential of large language models to enhance mental health support through AI technologies in online psychological consultation.},
	urldate = {2023-07-30},
	publisher = {arXiv},
	author = {Lai, Tin and Shi, Yukun and Du, Zicong and Wu, Jiajie and Fu, Ken and Dou, Yichao and Wang, Ziqi},
	month = jul,
	year = {2023},
	note = {arXiv:2307.11991 [cs]},
	file = {Lai et al_2023_Psy-LLM.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Lai et al_2023_Psy-LLM.pdf:application/pdf},
}

@techreport{kjell_beyond_2023,
	type = {preprint},
	title = {Beyond {Rating} {Scales}: {With} {Care} for {Validation} {Large} {Language} {Models} are {Poised} to {Change} {Psychological} {Assessment}},
	shorttitle = {Beyond {Rating} {Scales}},
	url = {https://osf.io/yfd8g},
	abstract = {We review recent empirical evaluations of AI-based language assessments and present a case for the technology of large language models, that are used for chatGPT and BERT, to be poised for changing standardized psychological assessment. Artificial intelligence has been undergoing a purported “paradigm shift” initiated by new machine learning models, large language models. These models have led to unprecedented accuracy over most computerized language processing tasks, from web search to automatic machine translation and question answering, while their dialogue-based forms like chatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of previous attempts to automate psychological assessment from language. While potential applications for automated therapy are beginning to be studied on the heels of chatGPT’s success, here we suggest that, with thorough validation of deployment scenarios, AI’s newest technology is already poised to move mental health assessment away from rating scales and to instead use how people naturally communicate, in language.},
	language = {en},
	urldate = {2023-07-30},
	institution = {PsyArXiv},
	author = {Kjell, Oscar Nils Erik and Kjell, Katarina and Schwartz, H. Andrew},
	month = jan,
	year = {2023},
	doi = {10.31234/osf.io/yfd8g},
	file = {Kjell et al. - 2023 - Beyond Rating Scales With Care for Validation Lar.pdf:/Users/orsonxu/Zotero/storage/KN7PYIQR/Kjell et al. - 2023 - Beyond Rating Scales With Care for Validation Lar.pdf:application/pdf},
}

@inproceedings{raji_fallacy_2022,
	address = {Seoul Republic of Korea},
	title = {The {Fallacy} of {AI} {Functionality}},
	isbn = {978-1-4503-9352-2},
	url = {https://dl.acm.org/doi/10.1145/3531146.3533158},
	doi = {10.1145/3531146.3533158},
	language = {en},
	urldate = {2023-08-11},
	booktitle = {2022 {ACM} {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {ACM},
	author = {Raji, Inioluwa Deborah and Kumar, I. Elizabeth and Horowitz, Aaron and Selbst, Andrew},
	month = jun,
	year = {2022},
	pages = {959--972},
	file = {Raji et al_2022_The Fallacy of AI Functionality.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Raji et al_2022_The Fallacy of AI Functionality.pdf:application/pdf},
}

@inproceedings{wei_chain--thought_2022,
	title = {Chain-of-{Thought} {Prompting} {Elicits} {Reasoning} in {Large} {Language} {Models}},
	abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—signiﬁcantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufﬁciently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even ﬁnetuned GPT-3 with a veriﬁer.},
	language = {en},
	booktitle = {36th {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H and Le, Quoc V and Zhou, Denny},
	year = {2022},
	file = {Wei et al. - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:/Users/orsonxu/Zotero/storage/RFSYL52A/Wei et al. - Chain-of-Thought Prompting Elicits Reasoning in La.pdf:application/pdf},
}

@inproceedings{kojima_large_2022,
	title = {Large {Language} {Models} are {Zero}-{Shot} {Reasoners}},
	abstract = {Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-bystep answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs’ ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding “Let’s think step by step” before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7\% to 78.7\% and GSM8K from 10.4\% to 40.7\% with large-scale InstructGPT model (text-davinci002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or few-shot exemplars.},
	language = {en},
	booktitle = {36th {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
	year = {2022},
	file = {Kojima et al. - Large Language Models are Zero-Shot Reasoners.pdf:/Users/orsonxu/Zotero/storage/39ZWMSZ6/Kojima et al. - Large Language Models are Zero-Shot Reasoners.pdf:application/pdf},
}

@misc{wang_aligning_2023,
	title = {Aligning {Large} {Language} {Models} with {Human}: {A} {Survey}},
	shorttitle = {Aligning {Large} {Language} {Models} with {Human}},
	url = {http://arxiv.org/abs/2307.12966},
	abstract = {Large Language Models (LLMs) trained on extensive textual corpora have emerged as leading solutions for a broad array of Natural Language Processing (NLP) tasks. Despite their notable performance, these models are prone to certain limitations such as misunderstanding human instructions, generating potentially biased content, or factually incorrect (hallucinated) information. Hence, aligning LLMs with human expectations has become an active area of interest within the research community. This survey presents a comprehensive overview of these alignment technologies, including the following aspects. (1) Data collection: the methods for effectively collecting high-quality instructions for LLM alignment, including the use of NLP benchmarks, human annotations, and leveraging strong LLMs. (2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment. Our exploration encompasses Supervised Fine-tuning, both Online and Offline human preference training, along with parameter-efficient training mechanisms. (3) Model Evaluation: the methods for evaluating the effectiveness of these human-aligned LLMs, presenting a multifaceted approach towards their assessment. In conclusion, we collate and distill our findings, shedding light on several promising future research avenues in the field. This survey, therefore, serves as a valuable resource for anyone invested in understanding and advancing the alignment of LLMs to better suit human-oriented tasks and expectations. An associated GitHub link collecting the latest papers is available at https://github.com/GaryYufei/AlignLLMHumanSurvey.},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Wang, Yufei and Zhong, Wanjun and Li, Liangyou and Mi, Fei and Zeng, Xingshan and Huang, Wenyong and Shang, Lifeng and Jiang, Xin and Liu, Qun},
	month = jul,
	year = {2023},
	note = {arXiv:2307.12966 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/WFRW3VHF/Wang et al. - 2023 - Aligning Large Language Models with Human A Survey.pdf:application/pdf},
}

@misc{gunasekar_textbooks_2023,
	title = {Textbooks {Are} {All} {You} {Need}},
	url = {http://arxiv.org/abs/2306.11644},
	abstract = {We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality" data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6\% on HumanEval and 55.5\% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45\% on HumanEval.},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio César Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and Salim, Adil and Shah, Shital and Behl, Harkirat Singh and Wang, Xin and Bubeck, Sébastien and Eldan, Ronen and Kalai, Adam Tauman and Lee, Yin Tat and Li, Yuanzhi},
	month = jun,
	year = {2023},
	note = {arXiv:2306.11644 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/R943CQ9I/Gunasekar et al. - 2023 - Textbooks Are All You Need.pdf:application/pdf},
}

@misc{mukherjee_orca_2023,
	title = {Orca: {Progressive} {Learning} from {Complex} {Explanation} {Traces} of {GPT}-4},
	shorttitle = {Orca},
	url = {http://arxiv.org/abs/2306.02707},
	abstract = {Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model’s capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca, a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100\% in complex zero-shot reasoning benchmarks like BigBench Hard (BBH) and 42\% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills.},
	language = {en},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Mukherjee, Subhabrata and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed},
	month = jun,
	year = {2023},
	note = {arXiv:2306.02707 [cs]},
	file = {Mukherjee et al. - 2023 - Orca Progressive Learning from Complex Explanation Traces of GPT-4.pdf:/Users/orsonxu/Zotero/storage/V7IKHCN4/Mukherjee et al. - 2023 - Orca Progressive Learning from Complex Explanation Traces of GPT-4.pdf:application/pdf},
}

@misc{chang_survey_2023,
	title = {A {Survey} on {Evaluation} of {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2307.03109},
	abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.},
	urldate = {2023-09-28},
	publisher = {arXiv},
	author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
	month = aug,
	year = {2023},
	note = {arXiv:2307.03109 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/9KSJ58AI/Chang et al. - 2023 - A Survey on Evaluation of Large Language Models.pdf:application/pdf},
}

@misc{mialon_augmented_2023,
	title = {Augmented {Language} {Models}: a {Survey}},
	shorttitle = {Augmented {Language} {Models}},
	url = {http://arxiv.org/abs/2302.07842},
	abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
	month = feb,
	year = {2023},
	note = {arXiv:2302.07842 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/TFM6Y9U9/Mialon et al. - 2023 - Augmented Language Models a Survey.pdf:application/pdf},
}

@misc{qiao_reasoning_2023,
	title = {Reasoning with {Language} {Model} {Prompting}: {A} {Survey}},
	shorttitle = {Reasoning with {Language} {Model} {Prompting}},
	url = {http://arxiv.org/abs/2212.09597},
	abstract = {Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Qiao, Shuofei and Ou, Yixin and Zhang, Ningyu and Chen, Xiang and Yao, Yunzhi and Deng, Shumin and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
	month = sep,
	year = {2023},
	note = {arXiv:2212.09597 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/CQX2DPSL/Qiao et al. - 2023 - Reasoning with Language Model Prompting A Survey.pdf:application/pdf},
}

@misc{huang_towards_2023,
	title = {Towards {Reasoning} in {Large} {Language} {Models}: {A} {Survey}},
	shorttitle = {Towards {Reasoning} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2212.10403},
	abstract = {Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models (LLMs) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent LLMs are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in LLMs, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Huang, Jie and Chang, Kevin Chen-Chuan},
	month = may,
	year = {2023},
	note = {arXiv:2212.10403 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/W5PYIFJI/Huang and Chang - 2023 - Towards Reasoning in Large Language Models A Survey.pdf:application/pdf},
}

@misc{chu_survey_2023,
	title = {A {Survey} of {Chain} of {Thought} {Reasoning}: {Advances}, {Frontiers} and {Future}},
	shorttitle = {A {Survey} of {Chain} of {Thought} {Reasoning}},
	url = {http://arxiv.org/abs/2309.15402},
	abstract = {Chain-of-thought reasoning, a cognitive process fundamental to human intelligence, has garnered significant attention in the realm of artificial intelligence and natural language processing. However, there still remains a lack of a comprehensive survey for this arena. To this end, we take the first step and present a thorough survey of this research field carefully and widely. We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail, we systematically organize the current research according to the taxonomies of methods, including XoT construction, XoT structure variants, and enhanced XoT. Additionally, we describe XoT with frontier applications, covering planning, tool use, and distillation. Furthermore, we address challenges and discuss some future directions, including faithfulness, multi-modal, and theory. We hope this survey serves as a valuable resource for researchers seeking to innovate within the domain of chain-of-thought reasoning.},
	urldate = {2023-09-29},
	publisher = {arXiv},
	author = {Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
	month = sep,
	year = {2023},
	note = {arXiv:2309.15402 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/EIPGEBBX/Chu et al. - 2023 - A Survey of Chain of Thought Reasoning Advances, Frontiers and Future.pdf:application/pdf},
}

@inproceedings{lin_gendered_2022,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Gendered {Mental} {Health} {Stigma} in {Masked} {Language} {Models}},
	url = {https://aclanthology.org/2022.emnlp-main.139},
	doi = {10.18653/v1/2022.emnlp-main.139},
	abstract = {Mental health stigma prevents many individuals from receiving the appropriate care, and social psychology studies have shown that mental health tends to be overlooked in men. In this work, we investigate gendered mental health stigma in masked language models. In doing so, we operationalize mental health stigma by developing a framework grounded in psychology research: we use clinical psychology literature to curate prompts, then evaluate the models' propensity to generate gendered words. We find that masked language models capture societal stigma about gender in mental health: models are consistently more likely to predict female subjects than male in sentences about having a mental health condition (32\% vs. 19\%), and this disparity is exacerbated for sentences that indicate treatment-seeking behavior. Furthermore, we find that different models capture dimensions of stigma differently for men and women, associating stereotypes like anger, blame, and pity more with women with mental health conditions than with men. In showing the complex nuances of models' gendered mental health stigma, we demonstrate that context and overlapping dimensions of identity are important considerations when assessing computational models' social biases.},
	urldate = {2023-10-05},
	booktitle = {Proceedings of the 2022 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Lin, Inna and Njoo, Lucille and Field, Anjalie and Sharma, Ashish and Reinecke, Katharina and Althoff, Tim and Tsvetkov, Yulia},
	month = dec,
	year = {2022},
	pages = {2152--2170},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/8UUJZM9K/Lin et al. - 2022 - Gendered Mental Health Stigma in Masked Language Models.pdf:application/pdf},
}

@misc{zhang_hurtful_2020,
	title = {Hurtful {Words}: {Quantifying} {Biases} in {Clinical} {Contextual} {Word} {Embeddings}},
	shorttitle = {Hurtful {Words}},
	url = {http://arxiv.org/abs/2003.11515},
	abstract = {In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender, language, ethnicity, and insurance status. Finally, we explore shortcomings of using adversarial debiasing to obfuscate subgroup information in contextual word embeddings, and recommend best practices for such deep embedding models in clinical settings.},
	urldate = {2023-10-05},
	publisher = {arXiv},
	author = {Zhang, Haoran and Lu, Amy X. and Abdalla, Mohamed and McDermott, Matthew and Ghassemi, Marzyeh},
	month = mar,
	year = {2020},
	note = {arXiv:2003.11515 [cs, stat]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/A6BSSJG2/Zhang et al. - 2020 - Hurtful Words Quantifying Biases in Clinical Contextual Word Embeddings.pdf:application/pdf},
}

@article{mittermaier_bias_2023,
	title = {Bias in {AI}-based models for medical applications: challenges and mitigation strategies},
	volume = {6},
	issn = {2398-6352},
	shorttitle = {Bias in {AI}-based models for medical applications},
	url = {https://www.nature.com/articles/s41746-023-00858-z},
	doi = {10.1038/s41746-023-00858-z},
	language = {en},
	number = {1},
	urldate = {2023-10-05},
	journal = {npj Digital Medicine},
	author = {Mittermaier, Mirja and Raza, Marium M. and Kvedar, Joseph C.},
	month = jun,
	year = {2023},
	pages = {113, s41746--023--00858--z},
	file = {Mittermaier et al. - 2023 - Bias in AI-based models for medical applications challenges and mitigation strategies.pdf:/Users/orsonxu/Zotero/storage/HHP8U8BK/Mittermaier et al. - 2023 - Bias in AI-based models for medical applications challenges and mitigation strategies.pdf:application/pdf},
}

@article{celi_sources_2022,
	title = {Sources of bias in artificial intelligence that perpetuate healthcare disparities—{A} global review},
	volume = {1},
	issn = {2767-3170},
	url = {https://dx.plos.org/10.1371/journal.pdig.0000022},
	doi = {10.1371/journal.pdig.0000022},
	abstract = {Background While artificial intelligence (AI) offers possibilities of advanced clinical prediction and decision-making in healthcare, models trained on relatively homogeneous datasets, and populations poorly-representative of underlying diversity, limits generalisability and risks biased AIbased decisions. Here, we describe the landscape of AI in clinical medicine to delineate population and data-source disparities.},
	language = {en},
	number = {3},
	urldate = {2023-10-05},
	journal = {PLOS Digital Health},
	author = {Celi, Leo Anthony and Cellini, Jacqueline and Charpignon, Marie-Laure and Dee, Edward Christopher and Dernoncourt, Franck and Eber, Rene and Mitchell, William Greig and Moukheiber, Lama and Schirmer, Julian and Situ, Julia and Paguio, Joseph and Park, Joel and Wawira, Judy Gichoya and Yao, Seth and {for MIT Critical Data}},
	editor = {Fraser, Hamish S.},
	month = mar,
	year = {2022},
	pages = {e0000022},
	file = {Celi et al. - 2022 - Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review.pdf:/Users/orsonxu/Zotero/storage/CFMH6A4Q/Celi et al. - 2022 - Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review.pdf:application/pdf},
}

@inproceedings{liu_dexperts_2021,
	address = {Online},
	title = {{DExperts}: {Decoding}-{Time} {Controlled} {Text} {Generation} with {Experts} and {Anti}-{Experts}},
	shorttitle = {{DExperts}},
	url = {https://aclanthology.org/2021.acl-long.522},
	doi = {10.18653/v1/2021.acl-long.522},
	abstract = {Despite recent advances in natural language generation, it remains challenging to control attributes of generated text. We propose DExperts: Decoding-time Experts, a decoding-time method for controlled text generation that combines a pretrained language model with “expert” LMs and/or “anti-expert” LMs in a product of experts. Intuitively, under the ensemble, tokens only get high probability if they are considered likely by the experts, and unlikely by the anti-experts. We apply DExperts to language detoxification and sentiment-controlled generation, where we outperform existing controllable generation methods on both automatic and human evaluations. Moreover, because DExperts operates only on the output of the pretrained LM, it is effective with (anti-)experts of smaller size, including when operating on GPT-3. Our work highlights the promise of tuning small LMs on text with (un)desirable attributes for efficient decoding-time steering.},
	urldate = {2023-10-05},
	booktitle = {Proceedings of the 59th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} and the 11th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Alisa and Sap, Maarten and Lu, Ximing and Swayamdipta, Swabha and Bhagavatula, Chandra and Smith, Noah A. and Choi, Yejin},
	month = aug,
	year = {2021},
	pages = {6691--6706},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/8KVZVY39/Liu et al. - 2021 - DExperts Decoding-Time Controlled Text Generation with Experts and Anti-Experts.pdf:application/pdf},
}

@inproceedings{hartvigsen_toxigen_2022,
	address = {Dublin, Ireland},
	title = {{ToxiGen}: {A} {Large}-{Scale} {Machine}-{Generated} {Dataset} for {Adversarial} and {Implicit} {Hate} {Speech} {Detection}},
	shorttitle = {{ToxiGen}},
	url = {https://aclanthology.org/2022.acl-long.234},
	doi = {10.18653/v1/2022.acl-long.234},
	abstract = {Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5\% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.},
	urldate = {2023-10-06},
	booktitle = {Proceedings of the 60th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Hartvigsen, Thomas and Gabriel, Saadia and Palangi, Hamid and Sap, Maarten and Ray, Dipankar and Kamar, Ece},
	month = may,
	year = {2022},
	pages = {3309--3326},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/XY4NXI4Y/Hartvigsen et al. - 2022 - ToxiGen A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection.pdf:application/pdf},
}

@article{hartmann_more_2023,
	title = {More than a {Feeling}: {Accuracy} and {Application} of {Sentiment} {Analysis}},
	volume = {40},
	issn = {01678116},
	shorttitle = {More than a {Feeling}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167811622000477},
	doi = {10.1016/j.ijresmar.2022.05.005},
	abstract = {Sentiment is fundamental to human communication. Countless marketing applications mine opinions from social media communication, news articles, customer feedback, or corporate communication. Various sentiment analysis methods are available and new ones have recently been proposed. Lexicons can relate individual words and expressions to sentiment scores. In contrast, machine learning methods are more complex to interpret, but promise higher accuracy, i.e., fewer false classiﬁcations. We propose an empirical framework and quantify these trade-offs for different types of research questions, data characteristics, and analytical resources to enable informed method decisions contingent on the application context. Based on a meta-analysis of 272 datasets and 12 million sentimentlabeled text documents, we ﬁnd that the recently proposed transfer learning models indeed perform best, but can perform worse than popular leaderboard benchmarks suggest. We quantify the accuracy-interpretability trade-off, showing that, compared to widely established lexicons, transfer learning models on average classify more than 20 percentage points more documents correctly. To form realistic performance expectations, additional context variables, most importantly the desired number of sentiment classes and the text length, should be taken into account. We provide a pre-trained sentiment analysis model (called SiEBERT) with open-source scripts that can be applied as easily as an off-the-shelf lexicon.},
	language = {en},
	number = {1},
	urldate = {2023-10-06},
	journal = {International Journal of Research in Marketing},
	author = {Hartmann, Jochen and Heitmann, Mark and Siebert, Christian and Schamp, Christina},
	month = mar,
	year = {2023},
	pages = {75--87},
	file = {Hartmann et al. - 2023 - More than a Feeling Accuracy and Application of Sentiment Analysis.pdf:/Users/orsonxu/Zotero/storage/K9RED82T/Hartmann et al. - 2023 - More than a Feeling Accuracy and Application of Sentiment Analysis.pdf:application/pdf},
}

@misc{yang_mentallama_2023,
	title = {{MentaLLaMA}: {Interpretable} {Mental} {Health} {Analysis} on {Social} {Media} with {Large} {Language} {Models}},
	shorttitle = {{MentaLLaMA}},
	url = {http://arxiv.org/abs/2309.13567},
	abstract = {With the development of web technology, social media texts are becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear the problem of low interpretability, the recent large language models have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions. The results show that ChatGPT can generate approaching-human explanations for its correct classifications. However, LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner. Domain-specific finetuning is an effective solution, but faces 2 challenges: 1) lack of high-quality training data. 2) no open-source LLMs for interpretable mental health analysis were released to lower the finetuning cost. To alleviate these problems, we build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset on social media, with 105K data samples. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We use expert-written few-shot prompts and collected labels to prompt ChatGPT and obtain explanations from its responses. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA, the first open-source LLM series for interpretable mental health analysis with instruction-following capability. We also evaluate the performance of MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their correctness for making predictions and the quality of explanations are examined. The results show that MentalLLaMA approaches state-of-the-art discriminative methods in correctness and generates high-quality explanations.},
	urldate = {2023-10-24},
	publisher = {arXiv},
	author = {Yang, Kailai and Zhang, Tianlin and Kuang, Ziyan and Xie, Qianqian and Ananiadou, Sophia and Huang, Jimin},
	month = oct,
	year = {2023},
	note = {arXiv:2309.13567 [cs]},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/W6KK3TY3/Yang et al. - 2023 - MentaLLaMA Interpretable Mental Health Analysis on Social Media with Large Language Models.pdf:application/pdf},
}

@misc{touvron_llama_2023-1,
	title = {Llama 2: {Open} {Foundation} and {Fine}-{Tuned} {Chat} {Models}},
	shorttitle = {Llama 2},
	url = {http://arxiv.org/abs/2307.09288},
	abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closedsource models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
	language = {en},
	urldate = {2023-11-08},
	publisher = {arXiv},
	author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
	month = jul,
	year = {2023},
	note = {arXiv:2307.09288 [cs]},
	file = {Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf:/Users/orsonxu/Zotero/storage/VE3SLJ79/Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Models.pdf:application/pdf},
}
