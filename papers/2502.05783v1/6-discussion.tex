\section{Discussion}
\label{sec:discussion}
In this work, we propose to leverage few-shot learning to enable users to self-define personal undesirable actions for personalized intervention on smartwatches.
We developed a three-stage pipeline that began with a self-supervised, pre-trained IMU model for robust feature extraction, then fine-tuned it for accurate human activity recognition, and finally enhanced it with data augmentation and synthesis that enabled rapid customization of new user-defined actions using only a small number of examples. 
We implemented this pipeline on a smartwatch as a real-time intervention system, \projectname, and demonstrated its effectiveness and advantages over the rule-based method through a multi-hour user study.
In this section, we discuss some interesting takeaways from our study, together with our vision of how \projectname can be generally applied to other health domains. We also briefly summarize the limitations of our work.


\subsection{Distorted Perception with AI-powered Intervention}
\label{sub:discussion:distorted}
During the study, we observed an interesting phenomenon where some participants developed a distorted perception towards their own actions or the intervention (see Sec.~\ref{sub:intervention_evaluation:qualitative_results}).
For instance, several participants felt \projectname's vibrations were stronger than the baseline (yet the actual strength of vibration remained constant), and some felt they did the target actions more frequently with \projectname (yet the objective data indicated otherwise).
There are several potential interpretations of such interesting observations.
The distorted perception might be caused by participants' heightened awareness of the AI-guided interventions: because \projectname more accurately and promptly caught the target actions, users started to pay extra and prolonged attention to any intervention. This could leave a stronger impression on them, and subsequently, they found it stronger or more frequent.
Another potential explanation is that the participants, often associating their personal and idiosyncratic undesirable actions with ``wrong-doing'' and thus responding with negative emotions, might have subconsciously perceived their undesirable actions as being more frequent due to the \projectname's more precise and timely feedback eliciting stronger negative emotions. This, combined with an emotional interpretation of being 'corrected', may have amplified their perception of the intervention's intensity (vibration strength) and created the mistaken impression of performing these actions excessively.

Meanwhile, it is an interesting open question of how long such perception will last from a longitudinal intervention perspective. Depending on the cases, the growing self-awareness and/or reliability of AI could potentially assist users in building a long-term habit to reduce the target action, or on the contrary, the effect may fade away due to the AI intervention method no longer being novel or enticing.
Future work can explore the lasting effect of the intervention, the corresponding perception, as well as user engagement in a long-term, field-based intervention study.~\cite{middleton2013long, short2018measuring, wei2020design}.


\subsection{Towards Human-AI Collaborative Interventions}
\label{sub:discussion:collaboration}
Users' mental models of \projectname varied significantly. Some viewed it as a passive watchdog, and some viewed it as a playful interactive system, while others sought to take greater agency in the moment of intervention delivery.
Our findings show the potential for and benefit of developing a collaborative relationship between humans and AI for behavioral intervention.
An AI system can provide appropriate support to users and help them achieve effective intervention outcomes.
Such collaboration is closely relevant to the vision of just-in-time adaptive interventions (JITAIs)~\cite{nahum-shani_translating_2021, nahum2018just}, where the delivery timing and methods of intervention are designed to be dynamically adapting to an individual's internal state and surrounding context.

For instance, for users who see the system as a passive monitor, the system can provide the option for them to configure the frequency and style of intervention (\eg higher/lower-intensity vibrations or consolidated notifications), ensuring the AI remains in the background but still provides supportive nudges.
Taking one step further, the AI system may analyze user behavior over time and suggest new setups or goals for users with transparency (\eg transitioning from nail-biting to managing stress). Users can accept, modify, or reject these suggestions, creating a dialogue where AI acts as a coach or collaborator rather than a rigid enforcer of predefined behaviors.
Meanwhile, for those who see AI as a proactive system, one promising avenue is to incorporate user feedback into the AI's learning process~\cite{orzikulova2024time2stop}. Users can label the AI's predictions as accurate or not, which could serve as input for the model to further adapt to the user and improve performance over time (\eg through reinforcement learning).
Combined with contextual information that can potentially be inferred from sensors~\cite{xu2023globem}, such feedback can enable more precise, context-sensitive and personalized JITIs.
In addition, the system would periodically prompt users to reassess their goals and update intervention targets, ensuring long-term relevance and efficacy.

It is noteworthy that such a human-AI collaboration paradigm needs to follow the principles of transparency and ethical design.
Other than the options mentioned above, namely custom configurations and continuous feedback, users should have visibility into the system's functionality and action logic regardless of the specific collaboration setup. This is important to provide users with agency and build their trust in the system.

\subsection{Beyond Smartwatch and Broader Customization}
In this work, our real-time intervention was implemented on a smartwatch. However, our proposed idea of empowering users to define any personal action and achieve a personalized intervention system can be more broadly applied to other domains.
Instead of relying solely on a watch-based IMU, we can explore other body-based sensor arrays (\eg headbands, rings, or joint sensors) to capture a more diverse range of behaviors in real time.
This would enable the system to accommodate a wide variety of undesirable actions or habits, such as posture corrections and fidgeting management.
In addition, beyond physical interventions, future customization can also delve into psychological or mental health support.
For instance, individuals dealing with obsessive-compulsive disorder (OCD) or other habitual thought/action patterns could define personal triggers (\eg a particular repetitive motion or behavioral cue) and receive timely AI-driven interventions.
Such holistic approaches highlight the flexibility and scalability of our pipeline.
By enabling user-defined actions, we open up possibilities for long-term and effective management of both physical and psychological well-being using a multitude of wearable and sensor-based platforms.

\subsection{Limitations}

Despite \projectname's positive outcome and the promising insights generated, we recognize some limitations in our study design.
As mentioned above, our current model relies solely on accelerometer data for action recognition, which may limit its ability to capture the full range of motion characteristics or other physiology. Future work can explore additional sensing modalities, such as gyroscope, photoplethysmography (PPG), joint locations, to enhance the accuracy and robustness of action recognition. 
Besides, the study was conducted with a relatively small number of participants and a limited set of actions, which may not fully capture the variability and diversity of human activities in real-world scenarios \cite{trapp2015individual, narayanan2013behavioral}.
Additionally, although we tried to simulate real-life scenarios, our intervention study was conducted over a limited duration and in controlled experimental settings, which may not fully reflect the complexities and dynamics of real-life environments. 
Real-world contexts introduce factors such as environmental noise, varying sensor placements, and user behavior changes over time \cite{trapp2015individual,truong2015deployment,mejia2023enhancing,mills2022development}, which were not thoroughly simulated in this study. Future research should conduct longitudinal field experiments with real-world deployment of the system.



